From radford at cs.toronto.edu  Thu Jan  1 15:49:21 2015
From: radford at cs.toronto.edu (Radford Neal)
Date: Thu, 1 Jan 2015 09:49:21 -0500
Subject: [Rd]  Unexpected behavior of debug() in step-wise mode
In-Reply-To: <mailman.17.1420110004.18862.r-devel@r-project.org>
References: <mailman.17.1420110004.18862.r-devel@r-project.org>
Message-ID: <20150101144921.GA25876@cs.toronto.edu>

41;309;0c> Why does debug() enter Browse[3] here at all, and why does it happen the
> first time and not the second? This seems unexpected to me, and has
> undesirable effects for ESS users (that I reported here -
> https://stat.ethz.ch/pipermail/ess-help/2013-June/009154.html - but just
> realized my post to r-devel didn't make it through when I tried to report
> it back then).
> 
> > Fun <- function(n) print(n)
> > debug(Fun)
> > Fun(2)
> debugging in: Fun(2)
> debug: print(n)
> Browse[2]> {n+2}
> debug at #1: n + 2

I think this is the result of debugging being implemented by setting
a flag in the environment of the function being debugged.  That's how
the debug status gets passed on to inner statements.  Your {n+2} 
expression looks like an inner statement, and of course has the 
environment of the call of Fun.  (In contrast, (n+2) doesn't do this, 
because "(" doesn't check for debugging.)

You could avoid it with some hack like using (function(){n+2})()
rather than {n+2}.  (I'm assuming there's some reason you're not
just using (n+2), with parentheses rather than curly brackets).

I've considered changing how this works in pqR, using pqR's "variant
return" mechanism to pass on the information that an inner statement
should be debugged.  This would also allow one to avoid entering the
debugger for "if" when it is used as an expression rather than a
statement (for example, a <- if (x>0) 3 else 4).

   Radford Neal


From murdoch.duncan at gmail.com  Thu Jan  1 17:00:50 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 01 Jan 2015 11:00:50 -0500
Subject: [Rd] Unexpected behavior of debug() in step-wise mode
In-Reply-To: <20150101144921.GA25876@cs.toronto.edu>
References: <mailman.17.1420110004.18862.r-devel@r-project.org>
	<20150101144921.GA25876@cs.toronto.edu>
Message-ID: <54A56F32.2060806@gmail.com>

On 01/01/2015 9:49 AM, Radford Neal wrote:
> 41;309;0c> Why does debug() enter Browse[3] here at all, and why does it happen the
>> first time and not the second? This seems unexpected to me, and has
>> undesirable effects for ESS users (that I reported here -
>> https://stat.ethz.ch/pipermail/ess-help/2013-June/009154.html - but just
>> realized my post to r-devel didn't make it through when I tried to report
>> it back then).
>>
>>> Fun <- function(n) print(n)
>>> debug(Fun)
>>> Fun(2)
>> debugging in: Fun(2)
>> debug: print(n)
>> Browse[2]> {n+2}
>> debug at #1: n + 2
> 
> I think this is the result of debugging being implemented by setting
> a flag in the environment of the function being debugged.  That's how
> the debug status gets passed on to inner statements.  Your {n+2} 
> expression looks like an inner statement, and of course has the 
> environment of the call of Fun.  (In contrast, (n+2) doesn't do this, 
> because "(" doesn't check for debugging.)

That makes sense, and suggests a simple fix:  when evaluating an
expression typed by the user at the prompt, temporarily turn off the
debug flag on the environment.  I'll try this out, but the trouble with
changes to the debugger is that most changes are hard to test, since
they depend on user interaction.  It's very easy to make a change that
fixes one problem and causes another.

> 
> You could avoid it with some hack like using (function(){n+2})()
> rather than {n+2}.  (I'm assuming there's some reason you're not
> just using (n+2), with parentheses rather than curly brackets).
> 
> I've considered changing how this works in pqR, using pqR's "variant
> return" mechanism to pass on the information that an inner statement
> should be debugged.  This would also allow one to avoid entering the
> debugger for "if" when it is used as an expression rather than a
> statement (for example, a <- if (x>0) 3 else 4).

I'd rather not make that change.  In the example you give it makes
sense, but what about if you replace the 3 and 4 with more substantial
braced expressions?  Then I'd probably want to step into whichever block
got chosen.

>From the interpreter's point of view, there's really little difference
between "if" as an expression and "if" as a statement.  In both cases it
needs to treat it as an expression with a value (because statement
values are returned as the value of functions or braced blocks).

Duncan Murdoch


From John.Christie at Dal.Ca  Thu Jan  1 17:56:21 2015
From: John.Christie at Dal.Ca (John Christie)
Date: Thu, 1 Jan 2015 16:56:21 +0000
Subject: [Rd] UCBAdmissions help link update request
Message-ID: <4619E0C1-13B7-4548-8422-4D7C2D1E7312@dal.ca>

Currently the help for UCBAdmissions has a link to Michael Friendly's old faculty page, <http://www.math.yorku.ca/SCS/friendly.html>

This goes to a redirect page. The new address is datavis.ca.

As it was, the link was vague. I don't actually see the direct connection to the data set on Friendly's page, only the visualization topic. I think the former is what a lot of people might be expecting given the current wording. Maybe there is a more direct link to an example using the funcion that could be used or maybe it should be reworded. Perhaps the link could be <http://www.datavis.ca/courses/VCD/vcd2-handout-2x2.pdf>.  Or, the rewording could be:

See Michael Friendly's page (http://datavis.ca) for further information on categorical data visualization. The search on that page can be used to find specific examples with this data set.

From greg at warnes.net  Fri Jan  2 00:35:23 2015
From: greg at warnes.net (Gregory R. Warnes)
Date: Thu, 1 Jan 2015 18:35:23 -0500
Subject: [Rd] Reimplement stats:::plotNode as iterative to avoid recursion
	limits?
Message-ID: <09472B94-FD68-421A-9A06-A29C5D5E6025@warnes.net>

Hi All,

I've gotten a number of reports from users about gplots::heatmap.2 generating 'node stack overflow' errors.  As it turns out, these errors originate in stats:::plotNode, and are triggered when it is passed a dendrogram that is too deeply nested.

While increasing the stack size (which is a compile-time option for byte coded functions) can allow a particular instance to succeed, a better solution would be to modify stats:::plotNode to use a recursive, rather than iterative algorithm.

Anyone want to take this up as a programming challenge?   

-Greg

From csardi.gabor at gmail.com  Fri Jan  2 18:02:57 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 2 Jan 2015 12:02:57 -0500
Subject: [Rd] Benchmark code, but avoid printing
Message-ID: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>

Dear all,

I am trying to benchmark code that occasionally prints on the screen
and I want to
suppress the printing. Is there an idiom for this?

If I do

sink(tempfile)
microbenchmark(...)
sink()

then I'll be also measuring the costs of writing to tempfile. I could
also sink to /dev/null, which is probably fast, but that is not
portable.

Is there a better solution? Is writing to a textConnection() better?

Thanks, Best,
Gabor


From edoardo.baldoni at gmail.com  Fri Jan  2 18:33:29 2015
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Fri, 2 Jan 2015 18:33:29 +0100
Subject: [Rd] Help in building R with minGW
Message-ID: <CAOcqoUM59ccz-AhG1gkngR_zox3r6VSWPosv8oQh4=v6Mt5TsQ@mail.gmail.com>

Dear R users,
I would need some help in building R using minGW in windows 8.1. After
using the command *configure *(./configure --enable-R-shlib
--with-readline=no --with-x=no), I use the command *make. *This results in
the following error:

[...]
make[2]: Leaving directory `/home/Edoardo/r-3.1.2/src/nmath'
make[2]: Entering directory `/home/Edoardo/r-3.1.2/src/unix'
make[3]: Entering directory `/home/Edoardo/r-3.1.2/src/unix'
gcc -std=gnu99 -I. -I../../src/include -I../../src/include
 -I/usr/local/include -DHAVE_CONFIG_H      -g -O2  -c dynload.c -o dynload.o
dynload.c: In function 'Rf_InitFunctionHashing':
dynload.c:69:32: warning: assignment from incompatible pointer type
[enabled by default]
     R_osDynSymbol->loadLibrary = loadLibrary;
                                ^
dynload.c:71:33: warning: assignment from incompatible pointer type
[enabled by default]
     R_osDynSymbol->closeLibrary = closeLibrary;
                                 ^
dynload.c: At top level:
dynload.c:97:13: error: conflicting types for 'closeLibrary'
 static void closeLibrary(HINSTANCE handle)
             ^
dynload.c:59:13: note: previous declaration of 'closeLibrary' was here
 static void closeLibrary(void *handle);
             ^
dynload.c:59:13: warning: 'closeLibrary' used but never defined [enabled by
default]
make[3]: *** [dynload.o] Error 1
make[3]: Leaving directory `/home/Edoardo/r-3.1.2/src/unix'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/home/Edoardo/r-3.1.2/src/unix'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/Edoardo/r-3.1.2/src'
make: *** [R] Error 1


I am not an expert programmer and would appreciate some help. My final
objective is to install R as shared library in order to use RHIPE.
Thanks

Edoardo

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jan  2 19:26:39 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Jan 2015 19:26:39 +0100
Subject: [Rd] Reimplement stats:::plotNode as iterative to avoid
	recursion	limits?
In-Reply-To: <09472B94-FD68-421A-9A06-A29C5D5E6025@warnes.net>
References: <09472B94-FD68-421A-9A06-A29C5D5E6025@warnes.net>
Message-ID: <21670.58079.665812.472494@stat.math.ethz.ch>

>>>>> Gregory R Warnes <greg at warnes.net>
>>>>>     on Thu, 1 Jan 2015 18:35:23 -0500 writes:

    > Hi All, I've gotten a number of reports from users
    > about gplots::heatmap.2 generating 'node stack
    > overflow' errors.  As it turns out, these errors
    > originate in stats:::plotNode, and are triggered when
    > it is passed a dendrogram that is too deeply nested.

    > While increasing the stack size (which is a
    > compile-time option for byte coded functions) can
    > allow a particular instance to succeed, a better
    > solution would be to modify stats:::plotNode to use a
    > recursive, rather than iterative algorithm.

of course you mean the contrary: reprogram stats:::plotNode() to
use a *non*-recursive algorithm {"iterative" as you say in the 'Subject' line}

    > Anyone want to take this up as a programming
    > challenge?

Yes, please,  patches are very welcome -- if they are tested.

Please start from
       https://svn.r-project.org/R/trunk/src/library/stats/R/dendrogram.R
i.e. send patches with respect to that,
i.e., the result of
      diff -ubBw <old-dendrogram>.R <new-dendrogram>.R

With thanks in advance,
Martin Maechler


From hb at biostat.ucsf.edu  Fri Jan  2 21:00:08 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 2 Jan 2015 12:00:08 -0800
Subject: [Rd] Benchmark code, but avoid printing
In-Reply-To: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>
References: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>
Message-ID: <CAFDcVCSe+tp=aW=xoVXW2p3eUuj6HKer6jd-e+86FHEG0LBdRw@mail.gmail.com>

On Fri, Jan 2, 2015 at 9:02 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Dear all,
>
> I am trying to benchmark code that occasionally prints on the screen
> and I want to
> suppress the printing. Is there an idiom for this?
>
> If I do
>
> sink(tempfile)
> microbenchmark(...)
> sink()
>
> then I'll be also measuring the costs of writing to tempfile. I could
> also sink to /dev/null, which is probably fast, but that is not
> portable.

Interesting problem.  On Windows NUL corresponds to /dev/NULL, e.g.
con <- file("NUL", open="wb").  Not that it's cross platform, but it
at least allows you to cover on more OS.  Maybe R should have a
built-in "null" device.  An easier solution is probably to go back to
the maintainers of the functions outputting text and ask them for an
option to disable that.

>
> Is there a better solution? Is writing to a textConnection() better?

For large number of output *lines* (not characters), textConnection()
is exponentially slow (at least in R 3.1.0).  Use rawConnection()
instead, cf. http://www.jottr.org/2014/05/captureOutput.html

/Henrik

>
> Thanks, Best,
> Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Jan  2 21:44:55 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 2 Jan 2015 15:44:55 -0500
Subject: [Rd] Benchmark code, but avoid printing
In-Reply-To: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>
References: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>
Message-ID: <DC70B272-B6C8-4692-AE73-399C8ED90489@r-project.org>

On Jan 2, 2015, at 12:02 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> Dear all,
> 
> I am trying to benchmark code that occasionally prints on the screen
> and I want to
> suppress the printing. Is there an idiom for this?
> 
> If I do
> 
> sink(tempfile)
> microbenchmark(...)
> sink()
> 
> then I'll be also measuring the costs of writing to tempfile. I could
> also sink to /dev/null, which is probably fast, but that is not
> portable.
> 
> Is there a better solution? Is writing to a textConnection() better?
> 

Define better - you're just trading off one output code for another - it will be still measuring the cost of the output, obviously, and since the output is part of the code you're profiling it's correctly so. Each output method has different beavior - e.g. text connection can be faster, but it can also trigger additional garbage collection so it will affect results. Example:

> f=textConnection("x", "w")
> sink(f)
> m=microbenchmark({ for (i in 1:100) { print("foo"); sum(rnorm(1e3)) } })
> sink()
> m
Unit: milliseconds
                                                                           expr
 {     for (i in 1:100) {         print("foo")         sum(rnorm(1000))     } }
      min       lq     mean   median       uq      max neval
 12.76462 15.34483 17.85341 17.02435 19.56384 63.09329   100
> sink("/dev/null")
> m=microbenchmark({ for (i in 1:100) { print("foo"); sum(rnorm(1e3)) } })
> sink()
> m
Unit: milliseconds
                                                                           expr
 {     for (i in 1:100) {         print("foo")         sum(rnorm(1000))     } }
     min       lq     mean  median       uq      max neval
 13.0191 13.03601 13.41815 13.0534 13.16496 16.25288   100

As you can see /dev/null is more predictable, because it's straight output, but text connection can be faster in the beginning and becomes progressively slower.

As Henrik said, you're probably best off using simply /dev/null - the only oddball is Windows, and that's a trivial condition on .Platform$OS.type.

Cheers,
S


From simon.urbanek at r-project.org  Fri Jan  2 21:47:21 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 2 Jan 2015 15:47:21 -0500
Subject: [Rd] Help in building R with minGW
In-Reply-To: <CAOcqoUM59ccz-AhG1gkngR_zox3r6VSWPosv8oQh4=v6Mt5TsQ@mail.gmail.com>
References: <CAOcqoUM59ccz-AhG1gkngR_zox3r6VSWPosv8oQh4=v6Mt5TsQ@mail.gmail.com>
Message-ID: <27F237D3-3DCF-4A79-8A3D-53E8DA059820@r-project.org>

Please read R-admin section 3.1 - as you'll notice it doesn't say anything about running ./configure since that's only for unix.

http://r.research.att.com/man/R-admin.html#Building-from-source

Cheers,
Simon



On Jan 2, 2015, at 12:33 PM, Edoardo Baldoni <edoardo.baldoni at gmail.com> wrote:

> Dear R users,
> I would need some help in building R using minGW in windows 8.1. After
> using the command *configure *(./configure --enable-R-shlib
> --with-readline=no --with-x=no), I use the command *make. *This results in
> the following error:
> 
> [...]
> make[2]: Leaving directory `/home/Edoardo/r-3.1.2/src/nmath'
> make[2]: Entering directory `/home/Edoardo/r-3.1.2/src/unix'
> make[3]: Entering directory `/home/Edoardo/r-3.1.2/src/unix'
> gcc -std=gnu99 -I. -I../../src/include -I../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H      -g -O2  -c dynload.c -o dynload.o
> dynload.c: In function 'Rf_InitFunctionHashing':
> dynload.c:69:32: warning: assignment from incompatible pointer type
> [enabled by default]
>     R_osDynSymbol->loadLibrary = loadLibrary;
>                                ^
> dynload.c:71:33: warning: assignment from incompatible pointer type
> [enabled by default]
>     R_osDynSymbol->closeLibrary = closeLibrary;
>                                 ^
> dynload.c: At top level:
> dynload.c:97:13: error: conflicting types for 'closeLibrary'
> static void closeLibrary(HINSTANCE handle)
>             ^
> dynload.c:59:13: note: previous declaration of 'closeLibrary' was here
> static void closeLibrary(void *handle);
>             ^
> dynload.c:59:13: warning: 'closeLibrary' used but never defined [enabled by
> default]
> make[3]: *** [dynload.o] Error 1
> make[3]: Leaving directory `/home/Edoardo/r-3.1.2/src/unix'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/home/Edoardo/r-3.1.2/src/unix'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/Edoardo/r-3.1.2/src'
> make: *** [R] Error 1
> 
> 
> I am not an expert programmer and would appreciate some help. My final
> objective is to install R as shared library in order to use RHIPE.
> Thanks
> 
> Edoardo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From csardi.gabor at gmail.com  Fri Jan  2 22:20:05 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 2 Jan 2015 16:20:05 -0500
Subject: [Rd] Benchmark code, but avoid printing
In-Reply-To: <DC70B272-B6C8-4692-AE73-399C8ED90489@r-project.org>
References: <CABtg=KmgV-6QEffrGc4HzOSUM-jvE3ExHFB1KefAgv16S=+oGA@mail.gmail.com>
	<DC70B272-B6C8-4692-AE73-399C8ED90489@r-project.org>
Message-ID: <CABtg=KnWkgny28U9pU96+RN5cnsO3DLawuWYyELfH2VSwYQtJw@mail.gmail.com>

Yes, thanks much, this makes a lot of sense.

Well, by "better" what I had in mind was something that is reliably
close to the time needed for printing. Without actually doing the
printing. But I realize this is too much to ask for, and I'll be fine
with /dev/null. Thanks for bringing up the textConnection() issue as
well, especially because I am using textConnection now. /dev/null is a
better option.

Best,
Gabor

On Fri, Jan 2, 2015 at 3:44 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Jan 2, 2015, at 12:02 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>
>> Dear all,
>>
>> I am trying to benchmark code that occasionally prints on the screen
>> and I want to
>> suppress the printing. Is there an idiom for this?
>>
>> If I do
>>
>> sink(tempfile)
>> microbenchmark(...)
>> sink()
>>
>> then I'll be also measuring the costs of writing to tempfile. I could
>> also sink to /dev/null, which is probably fast, but that is not
>> portable.
>>
>> Is there a better solution? Is writing to a textConnection() better?
>>
>
> Define better - you're just trading off one output code for another - it will be still measuring the cost of the output, obviously, and since the output is part of the code you're profiling it's correctly so. Each output method has different beavior - e.g. text connection can be faster, but it can also trigger additional garbage collection so it will affect results. Example:
>
>> f=textConnection("x", "w")
>> sink(f)
>> m=microbenchmark({ for (i in 1:100) { print("foo"); sum(rnorm(1e3)) } })
>> sink()
>> m
> Unit: milliseconds
>                                                                            expr
>  {     for (i in 1:100) {         print("foo")         sum(rnorm(1000))     } }
>       min       lq     mean   median       uq      max neval
>  12.76462 15.34483 17.85341 17.02435 19.56384 63.09329   100
>> sink("/dev/null")
>> m=microbenchmark({ for (i in 1:100) { print("foo"); sum(rnorm(1e3)) } })
>> sink()
>> m
> Unit: milliseconds
>                                                                            expr
>  {     for (i in 1:100) {         print("foo")         sum(rnorm(1000))     } }
>      min       lq     mean  median       uq      max neval
>  13.0191 13.03601 13.41815 13.0534 13.16496 16.25288   100
>
> As you can see /dev/null is more predictable, because it's straight output, but text connection can be faster in the beginning and becomes progressively slower.
>
> As Henrik said, you're probably best off using simply /dev/null - the only oddball is Windows, and that's a trivial condition on .Platform$OS.type.
>
> Cheers,
> S
>


From steven.ranney at gmail.com  Sat Jan  3 21:49:53 2015
From: steven.ranney at gmail.com (Steven Ranney)
Date: Sat, 3 Jan 2015 13:49:53 -0700
Subject: [Rd] Potential cross-platform package building issue
Message-ID: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>

I am using 32-bit R 3.1.2 on Windows 7.

I recently conducted an `R CMD check --as-cran` on a recently-developed
package and received only the 'New submission' note. Research on
StackOverflow and on R-devel suggested this could be ignored. I also used
devtools::build_win() and received no notes or warnings, other than the one
mentioned previously. Lastly, I conducted an `R CMD check` with the
development version of R.  Further, I built the package locally with `R CMD
build` and `R CMD INSTALL --build` and everything worked as it should,
including the PDF manual.

Upon submission to CRAN, I was told that a warning was thrown:

This fails to make its manual:
* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
LaTeX errors found:
! Missing $ inserted.
<inserted text>
$
l.682 }{}
! Missing } inserted.
<inserted text>
}
l.682
}{}
...

The line appears to be
\widehat{R_1} =
\frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}

I asked for assistance in resolving this issue as I could not replicate the
WARNING.  Another user could replicate the warning on Ubuntu 12.04 but was
able to resolve the issue by removing the DOS end-of-line markers (^M or
Ctrl-M) from the .Rd file.  Neither he nor I could find anything in the R
Extensions Manual that discussed removing end-of-line markers.

Link to the thread on StackOverflow.com:
http://stackoverflow.com/questions/27756679/cran-finds-an-warning-that-r-cmd-check-as-cran-does-not

Link to GitHub repository: http://www.github.com/stevenranney/creelSurvey

Is this an obscure cross platform issue?  If so, I would have thought that
someone else would have already discovered this.  If this is normal
behavior, is there a simple way to remove these end of line markers so I
can minimize WARNINGS from CRAN in the future?

Thanks -

Steven Ranney

	[[alternative HTML version deleted]]


From edd at debian.org  Sun Jan  4 00:53:02 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 3 Jan 2015 17:53:02 -0600
Subject: [Rd] Potential cross-platform package building issue
In-Reply-To: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
References: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
Message-ID: <21672.32990.619412.259184@max.nulle.part>


On 3 January 2015 at 13:49, Steven Ranney wrote:
| I am using 32-bit R 3.1.2 on Windows 7.
| 
| I recently conducted an `R CMD check --as-cran` on a recently-developed
| package and received only the 'New submission' note. Research on
| StackOverflow and on R-devel suggested this could be ignored. I also used
| devtools::build_win() and received no notes or warnings, other than the one
| mentioned previously. Lastly, I conducted an `R CMD check` with the
| development version of R.  Further, I built the package locally with `R CMD
| build` and `R CMD INSTALL --build` and everything worked as it should,
| including the PDF manual.
| 
| Upon submission to CRAN, I was told that a warning was thrown:
| 
| This fails to make its manual:
| * checking PDF version of manual ... WARNING
| LaTeX errors when creating PDF version.
| This typically indicates Rd problems.
| LaTeX errors found:
| ! Missing $ inserted.
| <inserted text>
| $
| l.682 }{}
| ! Missing } inserted.
| <inserted text>
| }
| l.682
| }{}
| ...
| 
| The line appears to be
| \widehat{R_1} =
| \frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}
| 
| I asked for assistance in resolving this issue as I could not replicate the
| WARNING.  Another user could replicate the warning on Ubuntu 12.04 but was
| able to resolve the issue by removing the DOS end-of-line markers (^M or
| Ctrl-M) from the .Rd file.  Neither he nor I could find anything in the R
| Extensions Manual that discussed removing end-of-line markers.
| 
| Link to the thread on StackOverflow.com:
| http://stackoverflow.com/questions/27756679/cran-finds-an-warning-that-r-cmd-check-as-cran-does-not
| 
| Link to GitHub repository: http://www.github.com/stevenranney/creelSurvey
| 
| Is this an obscure cross platform issue?  If so, I would have thought that
| someone else would have already discovered this.  If this is normal
| behavior, is there a simple way to remove these end of line markers so I
| can minimize WARNINGS from CRAN in the future?

Given that you pointed to a GH repo, I quickly fetched it as a zip archive.
This looks like a vanilla tex coding issue to me:

* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
LaTeX errors found:
! Missing $ inserted.
<inserted text> 
                $
l.682 }{}
         
! Missing } inserted.
<inserted text> 
                }
l.682 }{}
         
! Display math should end with $$.
<to be read again> 
                   \@@par 
l.682 }{}
         
! Extra }, or forgotten \endgroup.
\par ...m \@noitemerr {\@@par }\fi \else {\@@par }
                                                  \fi 
l.682 }{}
         
! Missing $ inserted.
<inserted text> 
                $
l.682 }{}
         
! Missing $ inserted.
<inserted text> 
                $
l.682 }{}
         
! Missing } inserted.
<inserted text> 
                }
l.682 }{}
         
! Extra }, or forgotten \endgroup.
\par ...m \@noitemerr {\@@par }\fi \else {\@@par }
                                                  \fi 
l.682 }{}
         
! LaTeX Error: Bad math environment delimiter.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
! Missing $ inserted.
<inserted text> 
                $
l.724 }{}
         
! Missing } inserted.
<inserted text> 
                }
l.724 }{}
         
! Display math should end with $$.
<to be read again> 
                   \@@par 
l.724 }{}
         
! Extra }, or forgotten \endgroup.
\par ...m \@noitemerr {\@@par }\fi \else {\@@par }
                                                  \fi 
l.724 }{}
         
! Missing $ inserted.
<inserted text> 
                $
l.724 }{}
         
! Missing $ inserted.
<inserted text> 
                $
l.724 }{}
         
! Missing } inserted.
<inserted text> 
                }
l.724 }{}
         
! Extra }, or forgotten \endgroup.
\par ...m \@noitemerr {\@@par }\fi \else {\@@par }
                                                  \fi 
l.724 }{}
         
! LaTeX Error: Bad math environment delimiter.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...                                              
* checking PDF version of manual without hyperrefs or index ... ERROR
edd at max:/tmp/creel$ 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd at debian.org  Sun Jan  4 01:05:44 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 3 Jan 2015 18:05:44 -0600
Subject: [Rd] Potential cross-platform package building issue
In-Reply-To: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
References: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
Message-ID: <21672.33752.811291.822728@max.nulle.part>


Steven,

Your error goes away when you write your \deqn{} in one line:

\deqn{\widehat{R_1} = \frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}}


[...]

\deqn{\widehat{E} = T\sum\limits_{i=1}^n{\frac{1}{w_{i}}}\sum\limits_{j=1}^m{\frac{e_{ij}}{\pi_{j}}}}


The quoted text here still has the silly ^M at the end as I didn't bother
converting your files from your somewhat OS-specific encoding.  

The combination of splitting a \deqn{} over several lines seems to be the
issue. You may notice that the Writing R Manual example itself uses the latex
trick of a trailing '%' before a line-break.  The odd line end convention 
Windows seems more of a distration than an issue -- and if you work with a
suitable editor you won't have to worry about either way.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org

From murdoch.duncan at gmail.com  Sun Jan  4 01:19:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 03 Jan 2015 19:19:18 -0500
Subject: [Rd] Potential cross-platform package building issue
In-Reply-To: <21672.32990.619412.259184@max.nulle.part>
References: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
	<21672.32990.619412.259184@max.nulle.part>
Message-ID: <54A88706.5010309@gmail.com>

On 03/01/2015 6:53 PM, Dirk Eddelbuettel wrote:
> 
> On 3 January 2015 at 13:49, Steven Ranney wrote:
> | I am using 32-bit R 3.1.2 on Windows 7.
> | 
> | I recently conducted an `R CMD check --as-cran` on a recently-developed
> | package and received only the 'New submission' note. Research on
> | StackOverflow and on R-devel suggested this could be ignored. I also used
> | devtools::build_win() and received no notes or warnings, other than the one
> | mentioned previously. Lastly, I conducted an `R CMD check` with the
> | development version of R.  Further, I built the package locally with `R CMD
> | build` and `R CMD INSTALL --build` and everything worked as it should,
> | including the PDF manual.
> | 
> | Upon submission to CRAN, I was told that a warning was thrown:
> | 
> | This fails to make its manual:
> | * checking PDF version of manual ... WARNING
> | LaTeX errors when creating PDF version.
> | This typically indicates Rd problems.
> | LaTeX errors found:
> | ! Missing $ inserted.
> | <inserted text>
> | $
> | l.682 }{}
> | ! Missing } inserted.
> | <inserted text>
> | }
> | l.682
> | }{}
> | ...
> | 
> | The line appears to be
> | \widehat{R_1} =
> | \frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}
> | 
> | I asked for assistance in resolving this issue as I could not replicate the
> | WARNING.  Another user could replicate the warning on Ubuntu 12.04 but was
> | able to resolve the issue by removing the DOS end-of-line markers (^M or
> | Ctrl-M) from the .Rd file.  Neither he nor I could find anything in the R
> | Extensions Manual that discussed removing end-of-line markers.
> | 
> | Link to the thread on StackOverflow.com:
> | http://stackoverflow.com/questions/27756679/cran-finds-an-warning-that-r-cmd-check-as-cran-does-not
> | 
> | Link to GitHub repository: http://www.github.com/stevenranney/creelSurvey
> | 
> | Is this an obscure cross platform issue?  If so, I would have thought that
> | someone else would have already discovered this.  If this is normal
> | behavior, is there a simple way to remove these end of line markers so I
> | can minimize WARNINGS from CRAN in the future?
> 
> Given that you pointed to a GH repo, I quickly fetched it as a zip archive.
> This looks like a vanilla tex coding issue to me:

But Steven didn't write any tex, R did.

I do think the problem is with the CR/LF line endings.  I think the
first error comes from this line in man/SimulateBusRoute.Rd:

\deqn{^M
\widehat{R_1} =
\frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}^M
}^M

(Those ^M's are really CR characters.)

This is translated by R to


\deqn{


\widehat{R_1} =
\frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}


}{}

and I think those extra blank lines are causing the problem.  The \deqn
macro is defined as

\newcommand{\deqn}[2]{\[#1\]}

and the \[ for display equations doesn't like the blank lines.

Generally R is good at reading text input in a variety of formats, but
in this context it doesn't.  (Since the input might be in some weird
encoding, it doesn't fix up the line endings.)  Steven should save his
files with Unix-style line endings, and R should have told him to do
this (or should have done it automatically when it built the tarball.)

Duncan Murdoch

> 
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.682 }{}
>          
> ! Missing } inserted.
> <inserted text> 
>                 }
> l.682 }{}
>          
> ! Display math should end with $$.
> <to be read again> 
>                    \@@par 
> l.682 }{}
>          
> ! Extra }, or forgotten \endgroup.
> \par ...m \@noitemerr {\@@par }\fi \else {\@@par }
>                                                   \fi 
> l.682 }{}
>          
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.682 }{}
>          
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.682 }{}
>          
> ! Missing } inserted.
> <inserted text> 
>                 }
> l.682 }{}
>          
> ! Extra }, or forgotten \endgroup.
> \par ...m \@noitemerr {\@@par }\fi \else {\@@par }
>                                                   \fi 
> l.682 }{}
>          
> ! LaTeX Error: Bad math environment delimiter.
> 
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help.
>  ...                                              
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.724 }{}
>          
> ! Missing } inserted.
> <inserted text> 
>                 }
> l.724 }{}
>          
> ! Display math should end with $$.
> <to be read again> 
>                    \@@par 
> l.724 }{}
>          
> ! Extra }, or forgotten \endgroup.
> \par ...m \@noitemerr {\@@par }\fi \else {\@@par }
>                                                   \fi 
> l.724 }{}
>          
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.724 }{}
>          
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.724 }{}
>          
> ! Missing } inserted.
> <inserted text> 
>                 }
> l.724 }{}
>          
> ! Extra }, or forgotten \endgroup.
> \par ...m \@noitemerr {\@@par }\fi \else {\@@par }
>                                                   \fi 
> l.724 }{}
>          
> ! LaTeX Error: Bad math environment delimiter.
> 
> See the LaTeX manual or LaTeX Companion for explanation.
> Type  H <return>  for immediate help.
>  ...                                              
> * checking PDF version of manual without hyperrefs or index ... ERROR
> edd at max:/tmp/creel$ 
> 
> Dirk
>


From murdoch.duncan at gmail.com  Sun Jan  4 01:44:54 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 03 Jan 2015 19:44:54 -0500
Subject: [Rd] Potential cross-platform package building issue
In-Reply-To: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
References: <CANDt99qftMTV9+-DEmi-9WUT1bQknzT+wCTxVFHBsWPU15OYCQ@mail.gmail.com>
Message-ID: <54A88D06.4060207@gmail.com>

On 03/01/2015 3:49 PM, Steven Ranney wrote:
> I am using 32-bit R 3.1.2 on Windows 7.
> 
> I recently conducted an `R CMD check --as-cran` on a recently-developed
> package and received only the 'New submission' note. Research on
> StackOverflow and on R-devel suggested this could be ignored. I also used
> devtools::build_win() and received no notes or warnings, other than the one
> mentioned previously. Lastly, I conducted an `R CMD check` with the
> development version of R.  Further, I built the package locally with `R CMD
> build` and `R CMD INSTALL --build` and everything worked as it should,
> including the PDF manual.
> 
> Upon submission to CRAN, I was told that a warning was thrown:
> 
> This fails to make its manual:
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Missing $ inserted.
> <inserted text>
> $
> l.682 }{}
> ! Missing } inserted.
> <inserted text>
> }
> l.682
> }{}
> ...
> 
> The line appears to be
> \widehat{R_1} =
> \frac{\sum\limits_{i=1}^n{c_i/n}}{\sum\limits_{i=1}^n{L_i/n}}
> 
> I asked for assistance in resolving this issue as I could not replicate the
> WARNING.  Another user could replicate the warning on Ubuntu 12.04 but was
> able to resolve the issue by removing the DOS end-of-line markers (^M or
> Ctrl-M) from the .Rd file.  Neither he nor I could find anything in the R
> Extensions Manual that discussed removing end-of-line markers.

I've looked more closely at the file:  it doesn't have either Unix or
DOS end-of-line markers, it has CR-CR-LF (or 0D 0D 0A in hex), and
that's what confused R.  Unix uses LF, DOS used CR-LF, but nobody uses
CR-CR-LF.  I've seen things like that caused by auto-conversion of
files, so maybe Github did this to you.  (The R sources all use LF, so
that's the safest choice, but CR-LF should work fine too.)

The likely reason that Linux systems detected the error while your
Windows systems didn't is because the LaTeX systems handle these line
endings differently.

So I think this has to be classed as user error.

Duncan Murdoch


> 
> Link to the thread on StackOverflow.com:
> http://stackoverflow.com/questions/27756679/cran-finds-an-warning-that-r-cmd-check-as-cran-does-not
> 
> Link to GitHub repository: http://www.github.com/stevenranney/creelSurvey
> 
> Is this an obscure cross platform issue?  If so, I would have thought that
> someone else would have already discovered this.  If this is normal
> behavior, is there a simple way to remove these end of line markers so I
> can minimize WARNINGS from CRAN in the future?
> 
> Thanks -
> 
> Steven Ranney
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From djsamperi at gmail.com  Tue Jan  6 06:59:21 2015
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 6 Jan 2015 00:59:21 -0500
Subject: [Rd] Rtools install on new Windows 8.1 desktop stalls with "Not
	responding"
Message-ID: <CADUbQ5h=UFeR=X-qWnAQ3ZeUOx7cbkAdtV7BmFpW8F8f7N2_nA@mail.gmail.com>

Hello,

When I try to install Rtools in the usual way into C:\Rtools on a new
Windows 8.1
desktop it stalls near the beginning of the "Extracting files..." step.

The Task Manager Status for the Setup app shows "Not responding" and it takes
a long time to complete the installation, in spite of the fact that
this is a fast machine
(Intel i7) with 16 GB if RAM.

There were no such stalls when R itself was installed.

Any ideas?

Thanks,
Dominick


From djsamperi at gmail.com  Tue Jan  6 08:38:12 2015
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 6 Jan 2015 02:38:12 -0500
Subject: [Rd] Rtools install on new Windows 8.1 desktop stalls with "Not
	responding"
In-Reply-To: <CADUbQ5h=UFeR=X-qWnAQ3ZeUOx7cbkAdtV7BmFpW8F8f7N2_nA@mail.gmail.com>
References: <CADUbQ5h=UFeR=X-qWnAQ3ZeUOx7cbkAdtV7BmFpW8F8f7N2_nA@mail.gmail.com>
Message-ID: <CADUbQ5iMMpYe7x0nmH6tw-Fmk_8uDpp+DTe0nBZGZ3-V2VvSvw@mail.gmail.com>

Please ignore, this was an antivirus issue, sorry.

On Tue, Jan 6, 2015 at 12:59 AM, Dominick Samperi <djsamperi at gmail.com> wrote:
> Hello,
>
> When I try to install Rtools in the usual way into C:\Rtools on a new
> Windows 8.1
> desktop it stalls near the beginning of the "Extracting files..." step.
>
> The Task Manager Status for the Setup app shows "Not responding" and it takes
> a long time to complete the installation, in spite of the fact that
> this is a fast machine
> (Intel i7) with 16 GB if RAM.
>
> There were no such stalls when R itself was installed.
>
> Any ideas?
>
> Thanks,
> Dominick


From hpages at fredhutch.org  Tue Jan  6 22:02:31 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 06 Jan 2015 13:02:31 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
Message-ID: <54AC4D67.7060302@fredhutch.org>

Hi,

Current implementation:

   setequal <- function (x, y)
   {
     x <- as.vector(x)
     y <- as.vector(y)
     all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
   }

First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L) > 0L'
with 'x %in% y' and 'y %in% x', respectively. They're strictly
equivalent but the latter form is a lot more readable than the former
(isn't this the "raison d'?tre" of %in%?):

   setequal <- function (x, y)
   {
     x <- as.vector(x)
     y <- as.vector(y)
     all(c(x %in% y, y %in% x))
   }

Furthermore, replacing 'all(c(x %in% y, y %in x))' with
'all(x %in% y) && all(y %in% x)' improves readability even more and,
more importantly, reduces memory footprint significantly on big vectors
(e.g. by 15% on integer vectors with 15M elements):

   setequal <- function (x, y)
   {
     x <- as.vector(x)
     y <- as.vector(y)
     all(x %in% y) && all(y %in% x)
   }

It also seems to speed up things a little bit (not in a significant
way though).

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From avraham.adler at gmail.com  Wed Jan  7 07:24:36 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Wed, 7 Jan 2015 01:24:36 -0500
Subject: [Rd] Failing lm-tests due to extra 0 in scientific notation?
Message-ID: <CAL6gwnKrTo7gG2e_pXeULSqH7bqaqOotjMsrJ5Q3R0nbg2j3Dw@mail.gmail.com>

Hello.

I've compiled R on Windows many times, and this is the first time I've
seen this error. While running make check-all (and using
testInstalledBasic("both")), the lm-tests routines fail, and, as far
as I can tell, the diff is failing because in one file, answers are
coming back like this "3.11e-004" while in the save file they are
"3.11e-04". Every value is the same, outside the extra 0 in the
scientific notation. I've never seen R put two 0s in a row like that
before, and I cannot think of why that would happen. Is there a way to
change that so that it passes the tests?

Thank you,

Avi


From murdoch.duncan at gmail.com  Wed Jan  7 17:00:15 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 07 Jan 2015 11:00:15 -0500
Subject: [Rd] New version of Rtools for Windows
Message-ID: <54AD580F.4030800@gmail.com>

I have just uploaded to CRAN a new version 3.2.0.1948 of Rtools for 
Windows.  This will become visible there in a few hours, and be copied 
to mirrors thereafter.  People who want to build packages that include 
compiled code can use this to supply the compilers, etc., that are 
necessary for the build.  It also includes some extra materials for 
people who want to build R itself.

This version includes only minor updates to the tools.  I indicated last 
summer that I was hoping to update GCC from the current version 4.6.3 
before the R 3.2.0 release, but this now looks unlikely, unless someone 
else with experience building it can help.
(I need a new build script for it that I can run, not just a binary 
copy.  So far I have been unsuccessful in updating the scripts 
inhttp://www.stats.ox.ac.uk/pub/Rtools/multilib/multi.zip , or finding 
other scripts online that work.)

Duncan Murdoch


From avraham.adler at gmail.com  Wed Jan  7 17:26:53 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Wed, 7 Jan 2015 11:26:53 -0500
Subject: [Rd] Failing lm-tests due to extra 0 in scientific notation?
In-Reply-To: <CAL6gwnKrTo7gG2e_pXeULSqH7bqaqOotjMsrJ5Q3R0nbg2j3Dw@mail.gmail.com>
References: <CAL6gwnKrTo7gG2e_pXeULSqH7bqaqOotjMsrJ5Q3R0nbg2j3Dw@mail.gmail.com>
Message-ID: <CAL6gwn+-FmZf9iGTOm19q_Tm9=o+dwxiiF2Uk4HxnMXrakzg2w@mail.gmail.com>

Please let me clarify. When I said "is there a way to change that," I
meant, does anyone know why R would respond that way, and does anyone have
any suggestions as to what I can do or what I should investigate to get my
compilation to conform. I did *not* mean, "can we change the reference." I
apologize for any unintentional implications.

Avi

On Wed, Jan 7, 2015 at 1:24 AM, Avraham Adler <avraham.adler at gmail.com>
wrote:

> Hello.
>
> I've compiled R on Windows many times, and this is the first time I've
> seen this error. While running make check-all (and using
> testInstalledBasic("both")), the lm-tests routines fail, and, as far
> as I can tell, the diff is failing because in one file, answers are
> coming back like this "3.11e-004" while in the save file they are
> "3.11e-04". Every value is the same, outside the extra 0 in the
> scientific notation. I've never seen R put two 0s in a row like that
> before, and I cannot think of why that would happen. Is there a way to
> change that so that it passes the tests?
>
> Thank you,
>
> Avi
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Wed Jan  7 17:35:09 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 07 Jan 2015 16:35:09 +0000
Subject: [Rd] Failing lm-tests due to extra 0 in scientific notation?
In-Reply-To: <CAL6gwnKrTo7gG2e_pXeULSqH7bqaqOotjMsrJ5Q3R0nbg2j3Dw@mail.gmail.com>
References: <CAL6gwnKrTo7gG2e_pXeULSqH7bqaqOotjMsrJ5Q3R0nbg2j3Dw@mail.gmail.com>
Message-ID: <54AD603D.6080208@stats.ox.ac.uk>

On 07/01/2015 06:24, Avraham Adler wrote:
> Hello.
>
> I've compiled R on Windows many times, and this is the first time I've
> seen this error. While running make check-all (and using
> testInstalledBasic("both")), the lm-tests routines fail, and, as far
> as I can tell, the diff is failing because in one file, answers are
> coming back like this "3.11e-004" while in the save file they are
> "3.11e-04". Every value is the same, outside the extra 0 in the
> scientific notation. I've never seen R put two 0s in a row like that
> before, and I cannot think of why that would happen. Is there a way to
> change that so that it passes the tests?

That is what the Windows runtime does, so it seems you did something  in 
your compilation that linked to the wrong printf function.  R on Windows 
should use that from the (modified version of) the trio library in the 
sources.

You failed to follow the posting guide: we do not even know the version 
of R nor if this is 32- or 64-bit nor the locale ....

But as one data point, a 64-bit build of current R-patched from SVN 
checked for me a couple of hours ago.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jeroenooms at gmail.com  Wed Jan  7 23:20:11 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 7 Jan 2015 14:20:11 -0800
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <54AD580F.4030800@gmail.com>
References: <54AD580F.4030800@gmail.com>
Message-ID: <CABFfbXsxyJA3uEMjaeh=z1V38MS9LCO9Ns7+pfQoX32J89tQWw@mail.gmail.com>

On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.

I have been looking into this a bit over the past few months, also
with mixed success. Nevertheless, below some experiences that might be
worth sharing.

The guys from mingw-w64 recommended (quite strongly) to move away from
multilib. They explained that the standard approach is to create two
separate toolchains; one that targets win32 and the other one that
targets win64 (both tool chains can compiled for win32). Hence the
only difference for R would be that instead of passing "-m64" and
"-m32", it would need to set the path to the proper compiler.

There are several initiatives that provide very complete suites of
precompiled mingw-w64 tools. I think the ideal scenario would be if we
could take advantage of an existing tool chain as we do on other
platforms, although perhaps I do not fully understand the R-specific
requirements on the windows compiler.

One project that looks very promising is msys2 [1,2]. It has a package
manager (port of pacman from arch linux) and comes with a pretty
complete set of msys [3] and other [4] packages that seems quite well
maintained.

The only issue I ran into with msys2 is that it uses a different c++
exception model (seh/dwarf) than the current Rtools (which uses sjlj).
See also [5]. Therefore, if a library uses exceptions, we cannot use
the current Rtools to link a static library that was created with
msys2  [6]. I am not sure if it also be a problem the other way
around, and if this is still the case for recent versions of
gcc/mingw.

Finally, Ruby has build very similar to Rtools called DevKit-mingw64
[7] that we might be able to borrow from.


[1] https://msys2.github.io/
[2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
[3] https://github.com/Alexpux/MSYS2-packages
[4] https://github.com/Alexpux/MINGW-packages
[5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
[6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
[7] http://rubyinstaller.org/downloads/


From dtenenba at fredhutch.org  Thu Jan  8 00:25:12 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Wed, 7 Jan 2015 15:25:12 -0800 (PST)
Subject: [Rd] gsub with perl=TRUE results in 'this version of PCRE is not
 compiled with Unicode property support' in R-devel
In-Reply-To: <2015227063.2704396.1420672747520.JavaMail.root@fredhutch.org>
Message-ID: <1545603508.2704628.1420673112345.JavaMail.root@fredhutch.org>

The following code:

res <- gsub("(*UCP)\\b(i)\\b", 
    "", "nhgrimelanomaclass", perl = TRUE)

results in:

Error in gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "", "nhgrimelanomaclass",  : 
  invalid regular expression '(*UCP)\b(i)\b'
In addition: Warning message:
In gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "", "nhgrimelanomaclass",  :
  PCRE pattern compilation error
	'this version of PCRE is not compiled with Unicode property support'
	at '(*UCP)\b(i)\b'

on

R Under development (unstable) (2015-01-01 r67290)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

And also on the same version of R-devel on Snow Leopard, Windows, and Linux. But it does not produce an error on

R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Dan


From murdoch.duncan at gmail.com  Thu Jan  8 02:31:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 07 Jan 2015 20:31:07 -0500
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <CABFfbXsxyJA3uEMjaeh=z1V38MS9LCO9Ns7+pfQoX32J89tQWw@mail.gmail.com>
References: <54AD580F.4030800@gmail.com>
	<CABFfbXsxyJA3uEMjaeh=z1V38MS9LCO9Ns7+pfQoX32J89tQWw@mail.gmail.com>
Message-ID: <54ADDDDB.4020500@gmail.com>

On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
> 
> I have been looking into this a bit over the past few months, also
> with mixed success. Nevertheless, below some experiences that might be
> worth sharing.
> 
> The guys from mingw-w64 recommended (quite strongly) to move away from
> multilib. They explained that the standard approach is to create two
> separate toolchains; one that targets win32 and the other one that
> targets win64 (both tool chains can compiled for win32). Hence the
> only difference for R would be that instead of passing "-m64" and
> "-m32", it would need to set the path to the proper compiler.
> 
> There are several initiatives that provide very complete suites of
> precompiled mingw-w64 tools. I think the ideal scenario would be if we
> could take advantage of an existing tool chain as we do on other
> platforms, although perhaps I do not fully understand the R-specific
> requirements on the windows compiler.

I feel quite strongly that we need to be able to build the toolchain,
rather than relying on binaries produced by others.  We may need to
customize the toolchain, or we may need to rebuild it when a bug is
identified.  Lots of binary builders abandon their builds and you can't
count on them to solve problems at a later date.

> 
> One project that looks very promising is msys2 [1,2]. It has a package
> manager (port of pacman from arch linux) and comes with a pretty
> complete set of msys [3] and other [4] packages that seems quite well
> maintained.

Do they post complete instructions for building?  That's what I'm
looking for.  I don't want to develop a build script (I don't know how),
but I would like to have one.

Duncan Murdoch

> 
> The only issue I ran into with msys2 is that it uses a different c++
> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
> See also [5]. Therefore, if a library uses exceptions, we cannot use
> the current Rtools to link a static library that was created with
> msys2  [6]. I am not sure if it also be a problem the other way
> around, and if this is still the case for recent versions of
> gcc/mingw.
> 
> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
> [7] that we might be able to borrow from.
> 
> 
> [1] https://msys2.github.io/
> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
> [3] https://github.com/Alexpux/MSYS2-packages
> [4] https://github.com/Alexpux/MINGW-packages
> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
> [7] http://rubyinstaller.org/downloads/
>


From maechler at stat.math.ethz.ch  Thu Jan  8 10:16:06 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Jan 2015 10:16:06 +0100
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
Message-ID: <21678.19158.736089.111281@stat.math.ethz.ch>

In November, we had a "bug repository conversation"
with Peter Hagerty and myself:

  https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065

where the bug report title started with

 --->>  "exists" is a bottleneck for dispatch and package loading, ...

Peter proposed an extra simplified and henc faster version of exists(),
and I commented

    > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch> ---
    > I'm very grateful that you've started exploring the bottlenecks of loading
    > packages with many S4 classes (and methods)...
    > and I hope we can make real progress there rather sooner than later.

    > OTOH, your `summaryRprof()` in your vignette indicates that exists() may use
    > upto 10% of the time spent in library(reportingTools),  and your speedup
    > proposals of exist()  may go up to ca 30%  which is good and well worth
    > considering,  but still we can only expect 2-3% speedup for package loading
    > which unfortunately is not much.

    > Still I agree it is worth looking at exists() as you did  ... and 
    > consider providing a fast simplified version of it in addition to current
    > exists() [I think].

    > BTW, as we talk about enhancements here, maybe consider a further possibility:
    > My subjective guess is that probably more than half of exists() uses are of the
    > form

    > if(exists(name, where, .......)) {
    >    get(name, whare, ....)
    >    ..
    > } else { 
    >     NULL / error() / .. or similar
    > }

    > i.e. many exists() calls when returning TRUE are immediately followed by the
    > corresponding get() call which repeats quite a bit of the lookup that exists()
    > has done.

    > Instead, I'd imagine a function, say  getifexists(name, ...) that does both at
    > once in the "exists is TRUE" case but in a way we can easily keep the if(.) ..
    > else clause above.  One already existing approach would use

    > if(!inherits(tryCatch(xx <- get(name, where, ...), error=function(e)e), "error")) {

    >   ... (( work with xx )) ...

    > } else  { 
    >    NULL / error() / .. or similar
    > }

    > but of course our C implementation would be more efficient and use more concise
    > syntax {which should not look like error handling}.   Follow ups to this idea
    > should really go to R-devel (the mailing list).

and now I do follow up here myself :

I found that  'getifexists()' is actually very simple to implement,
I have already tested it a bit, but not yet committed to R-devel
(the "R trunk" aka "master branch") because I'd like to get
public comments {RFC := Request For Comments}.

My version of the help file {for both exists() and getifexists()}
rendered in text is

---------------------- help(getifexists) -------------------------------
Is an Object Defined?

Description:

     Look for an R object of the given name and possibly return it

Usage:

     exists(x, where = -1, envir = , frame, mode = "any",
            inherits = TRUE)
     
     getifexists(x, where = -1, envir = as.environment(where),
                 mode = "any", inherits = TRUE, value.if.not = NULL)
     
Arguments:

       x: a variable name (given as a character string).

   where: where to look for the object (see the details section); if
          omitted, the function will search as if the name of the
          object appeared unquoted in an expression.

   envir: an alternative way to specify an environment to look in, but
          it is usually simpler to just use the ?where? argument.

   frame: a frame in the calling list.  Equivalent to giving ?where? as
          ?sys.frame(frame)?.

    mode: the mode or type of object sought: see the ?Details? section.

inherits: should the enclosing frames of the environment be searched?

value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
          exist.

Details:

     The ?where? argument can specify the environment in which to look
     for the object in any of several ways: as an integer (the position
     in the ?search? list); as the character string name of an element
     in the search list; or as an ?environment? (including using
     ?sys.frame? to access the currently active function calls).  The
     ?envir? argument is an alternative way to specify an environment,
     but is primarily there for back compatibility.

     This function looks to see if the name ?x? has a value bound to it
     in the specified environment.  If ?inherits? is ?TRUE? and a value
     is not found for ?x? in the specified environment, the enclosing
     frames of the environment are searched until the name ?x? is
     encountered.  See ?environment? and the ?R Language Definition?
     manual for details about the structure of environments and their
     enclosures.

     *Warning:* ?inherits = TRUE? is the default behaviour for R but
     not for S.

     If ?mode? is specified then only objects of that type are sought.
     The ?mode? may specify one of the collections ?"numeric"? and
     ?"function"? (see ?mode?): any member of the collection will
     suffice.  (This is true even if a member of a collection is
     specified, so for example ?mode = "special"? will seek any type of
     function.)

Value:

     ?exists():? Logical, true if and only if an object of the correct
     name and mode is found.

     ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
     is true, otherwise ?value.if.not?.

Note:

   With ?getifexists()?, instead of the easy to read but somewhat
   inefficient
     
       if (exists(myVarName, envir = myEnvir)) {
         r <- get(myVarName, envir = myEnvir)
         ## ... deal with r ...
       }

   you now can use the more efficient (and slightly harder to read)
     
       if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
         ## ... deal with r ...
       }

References:

     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
     Language_.  Wadsworth & Brooks/Cole.

See Also:

     ?get?.  For quite a different kind of ?existence? checking, namely
     if function arguments were specified, ?missing?; and for yet a
     different kind, namely if a file exists, ?file.exists?.

Examples:

     ##  Define a substitute function if necessary:
     if(!exists("some.fun", mode = "function"))
       some.fun <- function(x) { cat("some.fun(x)\n"); x }
     search()
     exists("ls", 2) # true even though ls is in pos = 3
     exists("ls", 2, inherits = FALSE) # false
     
     ## These are true (in most circumstances):
     identical(ls,   getifexists("ls"))
     identical(NULL, getifexists(".foo.bar.")) # default value.if.not = NULL(!)

----------------- end[ help(getifexists) ] -----------------------------


From murdoch.duncan at gmail.com  Thu Jan  8 12:38:59 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 08 Jan 2015 06:38:59 -0500
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <21678.19158.736089.111281@stat.math.ethz.ch>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
Message-ID: <54AE6C53.8030702@gmail.com>

On 08/01/2015 4:16 AM, Martin Maechler wrote:
> In November, we had a "bug repository conversation"
> with Peter Hagerty and myself:
> 
>   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
> 
> where the bug report title started with
> 
>  --->>  "exists" is a bottleneck for dispatch and package loading, ...
> 
> Peter proposed an extra simplified and henc faster version of exists(),
> and I commented
> 
>     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch> ---
>     > I'm very grateful that you've started exploring the bottlenecks of loading
>     > packages with many S4 classes (and methods)...
>     > and I hope we can make real progress there rather sooner than later.
> 
>     > OTOH, your `summaryRprof()` in your vignette indicates that exists() may use
>     > upto 10% of the time spent in library(reportingTools),  and your speedup
>     > proposals of exist()  may go up to ca 30%  which is good and well worth
>     > considering,  but still we can only expect 2-3% speedup for package loading
>     > which unfortunately is not much.
> 
>     > Still I agree it is worth looking at exists() as you did  ... and 
>     > consider providing a fast simplified version of it in addition to current
>     > exists() [I think].
> 
>     > BTW, as we talk about enhancements here, maybe consider a further possibility:
>     > My subjective guess is that probably more than half of exists() uses are of the
>     > form
> 
>     > if(exists(name, where, .......)) {
>     >    get(name, whare, ....)
>     >    ..
>     > } else { 
>     >     NULL / error() / .. or similar
>     > }
> 
>     > i.e. many exists() calls when returning TRUE are immediately followed by the
>     > corresponding get() call which repeats quite a bit of the lookup that exists()
>     > has done.
> 
>     > Instead, I'd imagine a function, say  getifexists(name, ...) that does both at
>     > once in the "exists is TRUE" case but in a way we can easily keep the if(.) ..
>     > else clause above.  One already existing approach would use
> 
>     > if(!inherits(tryCatch(xx <- get(name, where, ...), error=function(e)e), "error")) {
> 
>     >   ... (( work with xx )) ...
> 
>     > } else  { 
>     >    NULL / error() / .. or similar
>     > }
> 
>     > but of course our C implementation would be more efficient and use more concise
>     > syntax {which should not look like error handling}.   Follow ups to this idea
>     > should really go to R-devel (the mailing list).
> 
> and now I do follow up here myself :
> 
> I found that  'getifexists()' is actually very simple to implement,
> I have already tested it a bit, but not yet committed to R-devel
> (the "R trunk" aka "master branch") because I'd like to get
> public comments {RFC := Request For Comments}.
> 

I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
Journal) pointed out, R names are very inconsistent in naming
conventions, but lowerCamelCase is the most common choice.  Second most
common is period.separated, so an argument could be made for
get.if.exists, but there's still the possibility of confusion with S3
methods, and users of other languages where "." is an operator find it a
little strange.

If you don't like lowerCamelCase (and a lot of people don't), then I
think underscore_separated is the next best choice, so would use
get_if_exists.

Another possibility is to make no new name at all, and just add an
optional parameter to get() (which if present acts as your value.if.not
parameter, if not present keeps the current "object not found" error).

Duncan Murdoch


> My version of the help file {for both exists() and getifexists()}
> rendered in text is
> 
> ---------------------- help(getifexists) -------------------------------
> Is an Object Defined?
> 
> Description:
> 
>      Look for an R object of the given name and possibly return it
> 
> Usage:
> 
>      exists(x, where = -1, envir = , frame, mode = "any",
>             inherits = TRUE)
>      
>      getifexists(x, where = -1, envir = as.environment(where),
>                  mode = "any", inherits = TRUE, value.if.not = NULL)
>      
> Arguments:
> 
>        x: a variable name (given as a character string).
> 
>    where: where to look for the object (see the details section); if
>           omitted, the function will search as if the name of the
>           object appeared unquoted in an expression.
> 
>    envir: an alternative way to specify an environment to look in, but
>           it is usually simpler to just use the ?where? argument.
> 
>    frame: a frame in the calling list.  Equivalent to giving ?where? as
>           ?sys.frame(frame)?.
> 
>     mode: the mode or type of object sought: see the ?Details? section.
> 
> inherits: should the enclosing frames of the environment be searched?
> 
> value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
>           exist.
> 
> Details:
> 
>      The ?where? argument can specify the environment in which to look
>      for the object in any of several ways: as an integer (the position
>      in the ?search? list); as the character string name of an element
>      in the search list; or as an ?environment? (including using
>      ?sys.frame? to access the currently active function calls).  The
>      ?envir? argument is an alternative way to specify an environment,
>      but is primarily there for back compatibility.
> 
>      This function looks to see if the name ?x? has a value bound to it
>      in the specified environment.  If ?inherits? is ?TRUE? and a value
>      is not found for ?x? in the specified environment, the enclosing
>      frames of the environment are searched until the name ?x? is
>      encountered.  See ?environment? and the ?R Language Definition?
>      manual for details about the structure of environments and their
>      enclosures.
> 
>      *Warning:* ?inherits = TRUE? is the default behaviour for R but
>      not for S.
> 
>      If ?mode? is specified then only objects of that type are sought.
>      The ?mode? may specify one of the collections ?"numeric"? and
>      ?"function"? (see ?mode?): any member of the collection will
>      suffice.  (This is true even if a member of a collection is
>      specified, so for example ?mode = "special"? will seek any type of
>      function.)
> 
> Value:
> 
>      ?exists():? Logical, true if and only if an object of the correct
>      name and mode is found.
> 
>      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
>      is true, otherwise ?value.if.not?.
> 
> Note:
> 
>    With ?getifexists()?, instead of the easy to read but somewhat
>    inefficient
>      
>        if (exists(myVarName, envir = myEnvir)) {
>          r <- get(myVarName, envir = myEnvir)
>          ## ... deal with r ...
>        }
> 
>    you now can use the more efficient (and slightly harder to read)
>      
>        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>          ## ... deal with r ...
>        }
> 
> References:
> 
>      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>      Language_.  Wadsworth & Brooks/Cole.
> 
> See Also:
> 
>      ?get?.  For quite a different kind of ?existence? checking, namely
>      if function arguments were specified, ?missing?; and for yet a
>      different kind, namely if a file exists, ?file.exists?.
> 
> Examples:
> 
>      ##  Define a substitute function if necessary:
>      if(!exists("some.fun", mode = "function"))
>        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>      search()
>      exists("ls", 2) # true even though ls is in pos = 3
>      exists("ls", 2, inherits = FALSE) # false
>      
>      ## These are true (in most circumstances):
>      identical(ls,   getifexists("ls"))
>      identical(NULL, getifexists(".foo.bar.")) # default value.if.not = NULL(!)
> 
> ----------------- end[ help(getifexists) ] -----------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Thu Jan  8 13:06:38 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 08 Jan 2015 12:06:38 +0000
Subject: [Rd] gsub with perl=TRUE results in 'this version of PCRE is
 not compiled with Unicode property support' in R-devel
In-Reply-To: <1545603508.2704628.1420673112345.JavaMail.root@fredhutch.org>
References: <1545603508.2704628.1420673112345.JavaMail.root@fredhutch.org>
Message-ID: <54AE72CE.2040001@stats.ox.ac.uk>

Why are you reporting that your PCRE library does not have something 
which the R-admin manual says it should preferably have?  To wit, 
footnote 37 says

'and not PCRE2, which started at version 10.0. PCRE must be built with 
UTF-8 support (not the default) and support for Unicode properties is 
assumed by some R packages. Neither are tested by configure. JIT support 
is desirable.'

That certainly does not fail on my Linux, Windows and OS X builds of 
R-devel.  (Issues about pre-built binaries, if that is what you used, 
should be reported to their maintainers, not here.)

And the help does say in ?regex

      In UTF-8 mode, some Unicode properties may be supported via
      ?\p{xx}? and ?\P{xx}? which match characters with and without
      property ?xx? respectively.

Note the 'may'.




On 07/01/2015 23:25, Dan Tenenbaum wrote:
> The following code:
>
> res <- gsub("(*UCP)\\b(i)\\b",
>      "", "nhgrimelanomaclass", perl = TRUE)
>
> results in:
>
> Error in gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "", "nhgrimelanomaclass",  :
>    invalid regular expression '(*UCP)\b(i)\b'
> In addition: Warning message:
> In gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "", "nhgrimelanomaclass",  :
>    PCRE pattern compilation error
> 	'this version of PCRE is not compiled with Unicode property support'
> 	at '(*UCP)\b(i)\b'
>
> on
>
> R Under development (unstable) (2015-01-01 r67290)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.9.5 (Mavericks)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> And also on the same version of R-devel on Snow Leopard, Windows, and Linux. But it does not produce an error on
>
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Dan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From arunkumar.sriniv at gmail.com  Thu Jan  8 13:46:57 2015
From: arunkumar.sriniv at gmail.com (Arunkumar Srinivasan)
Date: Thu, 8 Jan 2015 13:46:57 +0100
Subject: [Rd] On base::rank
Message-ID: <CAJ=vYTHRCgOMbVZw1jmFN-fEwdZL1p8JW9nYS+8yBFhsrZoP-Q@mail.gmail.com>

Have a look at the following, taken from base::rank:

...
    if (!is.na(na.last) && any(nas)) {
        yy <- integer(length(x)) # <~~~~~~~~~
        storage.mode(yy) <- storage.mode(y) # <~~~~~~~~
        yy <- NA
        NAkeep <- (na.last == "keep")
        if (NAkeep || na.last) {
            yy[!nas] <- y
            if (!NAkeep)
                yy[nas] <- (length(y) + 1L):length(yy)
        }
...

Alternatively, look at lines 36 and 37 here:
https://github.com/wch/r-source/blob/fbf5cdf29d923395b537a9893f46af1aa75e38f3/src/library/base/R/rank.R#L36

There seems to be no need for those lines, IIUC. Isn't it? 'yy' is
replaced with NA in the ver next line.

Best,
Arun.


From avraham.adler at gmail.com  Thu Jan  8 14:18:49 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 8 Jan 2015 08:18:49 -0500
Subject: [Rd] New version of Rtools for Windows
Message-ID: <CAL6gwnJjXS_3G18vOYN8bcCG+aytaPP8CVjhuZa5ZOvXVtPZRg@mail.gmail.com>

Very timely, as this is how I got into the problem I posted about
earlier; maybe some of the problems I ran into will mean more to the
you and the experts on this thread, Dr. Murdoch.For reference, I run
Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.

As we discussed offline, Dr. Murdoch, I've been trying to build R
using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
(rubenvb) told me he is no longer developing his own builds of GCC,
but is focusing on MSYS2 and the mingw64 personal builds. So, similar
to what Jeroen said, I first installed MSYS2, whose initial
installation on windows is not so simple[1]. After the initial
install, the following packages need to be manually installed: make,
tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
is way more than necessary, but there may be packages in there which
are necessary.

I originally installed the most up-to-date version of GCC (4.9.2)[2],
and I did pick the -seh version, as since I install (almost) all
packages from source (the one exception being nloptr for now), the
exception handling should be consistent and it is supposed to up to
~15% faster[3].

The initial build crashed with the following error:

gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
-pedantic -mtune=core2   -c xmalloc.c -o xmalloc.o
ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
tre-mem.o tre-parse.o tre-stack.o xmalloc.o
gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=core2   -c compat.c -o compat.o
compat.c:65:5: error: redefinition of 'snprintf'
 int snprintf(char *buffer, size_t max, const char *format, ...)
     ^
In file included from compat.c:3:0:
F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
definition of 'snprintf' was here
 int snprintf (char * __restrict__ __stream, size_t __n, const char *
__restrict__ __format, ...)
     ^
compat.c:75:5: error: redefinition of 'vsnprintf'
 int vsnprintf(char *buffer, size_t bufferSize, const char *format,
va_list args)
     ^
In file included from compat.c:3:0:
F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
definition of 'vsnprintf' was here
   int vsnprintf (char * __restrict__ __stream, size_t __n, const char
* __restrict__ __format, va_list __local_argv)
       ^
../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
make[4]: *** [compat.o] Error 1
Makefile:120: recipe for target 'rlibs' failed
make[3]: *** [rlibs] Error 1
Makefile:179: recipe for target '../../bin/x64/R.dll' failed
make[2]: *** [../../bin/x64/R.dll] Error 2
Makefile:104: recipe for target 'rbuild' failed
make[1]: *** [rbuild] Error 2
Makefile:14: recipe for target 'all' failed
make: *** [all] Error 2

After doing some checking (for example see [4]), I asked Duncan about
the problem, and he suggested moving the #ifndef _W64 in compat.c up
above the offending lines (65-75). That did not work, so, I figured
(it seems mistakenly from the other thread) that if those functions
are included from stdio already, I can just delete them from compat.c.
The specific lines are:

int snprintf(char *buffer, size_t max, const char *format, ...)
{
    int res;
    va_list(ap);
    va_start(ap, format);
    res = trio_vsnprintf(buffer, max, format, ap);
    va_end(ap);
    return res;
}

int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
{
    return trio_vsnprintf(buffer, bufferSize, format, args);
}

Continuing the build using 4.9.2 crashed again at the following point:

gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
-DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=core2   -c malloc.c -o
malloc.o
windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
-lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
-lcomctl32 -lversion
collect2.exe: error: ld returned 5 exit status
Makefile:150: recipe for target 'R.dll' failed
make[3]: *** [R.dll] Error 1
Makefile:179: recipe for target '../../bin/x64/R.dll' failed
make[2]: *** [../../bin/x64/R.dll] Error 2
Makefile:104: recipe for target 'rbuild' failed
make[1]: *** [rbuild] Error 2
Makefile:14: recipe for target 'all' failed
make: *** [all] Error 2

As all those files existed in their correct places, the only reason I
could think of that this would fail here is that GCC version 4.9 did
make some changes to enhance link-time optimization [5], and probably
something isn't compatible. I then downgraded to GCC 4.8.4 [6], and,
with the deletion of those 10 or so lines from compat.c, I can
complete the build straight through rinstaller. However, I get that
failure issue due to the extra 0 in scientific notation [7].

It does not matter if I do the entire process in the MSYS2
environment, or if I do in in Windows with msys\usr\bin in my path.

Na?vely, it seems that if there were some what for stdio to be
included in compat.c, yet the versions of snprintf and vsprintf in
that file to "override" the standard, perhaps this method would work.
Of course, running make check-all may uncover more issues. I intend to
run the equivalent checks (from the tools library) inside of R with
kill on failure turned off to see if anything else is problematic.

Hopefully, something in this description resonates with one of the
readers here. If anyone has any ideas as to how to circumvent the
issues with compat.c, I'd be very grateful.

Thank you,

Avi


[1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
[2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
[3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
[4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
[5] https://gcc.gnu.org/gcc-4.9/changes.html
[6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
[7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html

Date: Wed, 07 Jan 2015 20:31:07 -0500
>
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: Jeroen Ooms <jeroenooms at gmail.com>
> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
> Subject: Re: [Rd] New version of Rtools for Windows
> Message-ID: <54ADDDDB.4020500 at gmail.com>
> Content-Type: text/plain; charset=utf-8
>
> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
> > On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >>
> >> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
> >
> > I have been looking into this a bit over the past few months, also
> > with mixed success. Nevertheless, below some experiences that might be
> > worth sharing.
> >
> > The guys from mingw-w64 recommended (quite strongly) to move away from
> > multilib. They explained that the standard approach is to create two
> > separate toolchains; one that targets win32 and the other one that
> > targets win64 (both tool chains can compiled for win32). Hence the
> > only difference for R would be that instead of passing "-m64" and
> > "-m32", it would need to set the path to the proper compiler.
> >
> > There are several initiatives that provide very complete suites of
> > precompiled mingw-w64 tools. I think the ideal scenario would be if we
> > could take advantage of an existing tool chain as we do on other
> > platforms, although perhaps I do not fully understand the R-specific
> > requirements on the windows compiler.
>
> I feel quite strongly that we need to be able to build the toolchain,
> rather than relying on binaries produced by others.  We may need to
> customize the toolchain, or we may need to rebuild it when a bug is
> identified.  Lots of binary builders abandon their builds and you can't
> count on them to solve problems at a later date.
>
> >
> > One project that looks very promising is msys2 [1,2]. It has a package
> > manager (port of pacman from arch linux) and comes with a pretty
> > complete set of msys [3] and other [4] packages that seems quite well
> > maintained.
>
> Do they post complete instructions for building?  That's what I'm
> looking for.  I don't want to develop a build script (I don't know how),
> but I would like to have one.
>
> Duncan Murdoch
>
> >
> > The only issue I ran into with msys2 is that it uses a different c++
> > exception model (seh/dwarf) than the current Rtools (which uses sjlj).
> > See also [5]. Therefore, if a library uses exceptions, we cannot use
> > the current Rtools to link a static library that was created with
> > msys2  [6]. I am not sure if it also be a problem the other way
> > around, and if this is still the case for recent versions of
> > gcc/mingw.
> >
> > Finally, Ruby has build very similar to Rtools called DevKit-mingw64
> > [7] that we might be able to borrow from.
> >
> >
> > [1] https://msys2.github.io/
> > [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
> > [3] https://github.com/Alexpux/MSYS2-packages
> > [4] https://github.com/Alexpux/MINGW-packages
> > [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
> > [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
> > [7] http://rubyinstaller.org/downloads/


From nilsson.henric at gmail.com  Thu Jan  8 15:01:05 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Thu, 08 Jan 2015 15:01:05 +0100
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <CAL6gwnJjXS_3G18vOYN8bcCG+aytaPP8CVjhuZa5ZOvXVtPZRg@mail.gmail.com>
References: <CAL6gwnJjXS_3G18vOYN8bcCG+aytaPP8CVjhuZa5ZOvXVtPZRg@mail.gmail.com>
Message-ID: <54AE8DA1.3080601@gmail.com>

On 2015-01-08 14:18, Avraham Adler wrote:

> Very timely, as this is how I got into the problem I posted about
> earlier; maybe some of the problems I ran into will mean more to the
> you and the experts on this thread, Dr. Murdoch.For reference, I run
> Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.
>
> As we discussed offline, Dr. Murdoch, I've been trying to build R
> using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
> (rubenvb) told me he is no longer developing his own builds of GCC,
> but is focusing on MSYS2 and the mingw64 personal builds. So, similar
> to what Jeroen said, I first installed MSYS2, whose initial
> installation on windows is not so simple[1]. After the initial
> install, the following packages need to be manually installed: make,
> tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
> is way more than necessary, but there may be packages in there which
> are necessary.
>
> I originally installed the most up-to-date version of GCC (4.9.2)[2],
> and I did pick the -seh version, as since I install (almost) all
> packages from source (the one exception being nloptr for now), the
> exception handling should be consistent and it is supposed to up to
> ~15% faster[3].
>
> The initial build crashed with the following error:
>
> gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
> -pedantic -mtune=core2   -c xmalloc.c -o xmalloc.o
> ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
> tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
> tre-mem.o tre-parse.o tre-stack.o xmalloc.o
> gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=core2   -c compat.c -o compat.o
> compat.c:65:5: error: redefinition of 'snprintf'
>   int snprintf(char *buffer, size_t max, const char *format, ...)
>       ^
> In file included from compat.c:3:0:
> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
> definition of 'snprintf' was here
>   int snprintf (char * __restrict__ __stream, size_t __n, const char *
> __restrict__ __format, ...)
>       ^
> compat.c:75:5: error: redefinition of 'vsnprintf'
>   int vsnprintf(char *buffer, size_t bufferSize, const char *format,
> va_list args)
>       ^
> In file included from compat.c:3:0:
> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
> definition of 'vsnprintf' was here
>     int vsnprintf (char * __restrict__ __stream, size_t __n, const char
> * __restrict__ __format, va_list __local_argv)
>         ^
> ../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
> make[4]: *** [compat.o] Error 1
> Makefile:120: recipe for target 'rlibs' failed
> make[3]: *** [rlibs] Error 1
> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
> make[2]: *** [../../bin/x64/R.dll] Error 2
> Makefile:104: recipe for target 'rbuild' failed
> make[1]: *** [rbuild] Error 2
> Makefile:14: recipe for target 'all' failed
> make: *** [all] Error 2
>
> After doing some checking (for example see [4]), I asked Duncan about
> the problem, and he suggested moving the #ifndef _W64 in compat.c up
> above the offending lines (65-75). That did not work, so, I figured
> (it seems mistakenly from the other thread) that if those functions
> are included from stdio already, I can just delete them from compat.c.
> The specific lines are:
>
> int snprintf(char *buffer, size_t max, const char *format, ...)
> {
>      int res;
>      va_list(ap);
>      va_start(ap, format);
>      res = trio_vsnprintf(buffer, max, format, ap);
>      va_end(ap);
>      return res;
> }
>
> int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
> {
>      return trio_vsnprintf(buffer, bufferSize, format, args);
> }
>
> Continuing the build using 4.9.2 crashed again at the following point:
>
> gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=core2   -c malloc.c -o
> malloc.o
> windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
> dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
> psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
> system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
> ../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
> ../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
> ../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
> ../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
> -lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
> -lcomctl32 -lversion
> collect2.exe: error: ld returned 5 exit status
> Makefile:150: recipe for target 'R.dll' failed
> make[3]: *** [R.dll] Error 1
> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
> make[2]: *** [../../bin/x64/R.dll] Error 2
> Makefile:104: recipe for target 'rbuild' failed
> make[1]: *** [rbuild] Error 2
> Makefile:14: recipe for target 'all' failed
> make: *** [all] Error 2
>
> As all those files existed in their correct places, the only reason I
> could think of that this would fail here is that GCC version 4.9 did
> make some changes to enhance link-time optimization [5], and probably
> something isn't compatible.

Right.  Just before Christmas, Hin-Tak Leung reported build failure with 
LTO:

https://stat.ethz.ch/pipermail/r-devel/2014-December/070286.html
https://stat.ethz.ch/pipermail/r-devel/2014-December/070319.html


Many thanks to you and others for looking into this,
Henric



> I then downgraded to GCC 4.8.4 [6], and,
> with the deletion of those 10 or so lines from compat.c, I can
> complete the build straight through rinstaller. However, I get that
> failure issue due to the extra 0 in scientific notation [7].
>
> It does not matter if I do the entire process in the MSYS2
> environment, or if I do in in Windows with msys\usr\bin in my path.
>
> Na?vely, it seems that if there were some what for stdio to be
> included in compat.c, yet the versions of snprintf and vsprintf in
> that file to "override" the standard, perhaps this method would work.
> Of course, running make check-all may uncover more issues. I intend to
> run the equivalent checks (from the tools library) inside of R with
> kill on failure turned off to see if anything else is problematic.
>
> Hopefully, something in this description resonates with one of the
> readers here. If anyone has any ideas as to how to circumvent the
> issues with compat.c, I'd be very grateful.
>
> Thank you,
>
> Avi
>
>
> [1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
> [3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
> [4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
> [5] https://gcc.gnu.org/gcc-4.9/changes.html
> [6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
> [7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html
>
> Date: Wed, 07 Jan 2015 20:31:07 -0500
>>
>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>> To: Jeroen Ooms <jeroenooms at gmail.com>
>> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
>> Subject: Re: [Rd] New version of Rtools for Windows
>> Message-ID: <54ADDDDB.4020500 at gmail.com>
>> Content-Type: text/plain; charset=utf-8
>>
>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>
>>> I have been looking into this a bit over the past few months, also
>>> with mixed success. Nevertheless, below some experiences that might be
>>> worth sharing.
>>>
>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>> multilib. They explained that the standard approach is to create two
>>> separate toolchains; one that targets win32 and the other one that
>>> targets win64 (both tool chains can compiled for win32). Hence the
>>> only difference for R would be that instead of passing "-m64" and
>>> "-m32", it would need to set the path to the proper compiler.
>>>
>>> There are several initiatives that provide very complete suites of
>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>> could take advantage of an existing tool chain as we do on other
>>> platforms, although perhaps I do not fully understand the R-specific
>>> requirements on the windows compiler.
>>
>> I feel quite strongly that we need to be able to build the toolchain,
>> rather than relying on binaries produced by others.  We may need to
>> customize the toolchain, or we may need to rebuild it when a bug is
>> identified.  Lots of binary builders abandon their builds and you can't
>> count on them to solve problems at a later date.
>>
>>>
>>> One project that looks very promising is msys2 [1,2]. It has a package
>>> manager (port of pacman from arch linux) and comes with a pretty
>>> complete set of msys [3] and other [4] packages that seems quite well
>>> maintained.
>>
>> Do they post complete instructions for building?  That's what I'm
>> looking for.  I don't want to develop a build script (I don't know how),
>> but I would like to have one.
>>
>> Duncan Murdoch
>>
>>>
>>> The only issue I ran into with msys2 is that it uses a different c++
>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>> the current Rtools to link a static library that was created with
>>> msys2  [6]. I am not sure if it also be a problem the other way
>>> around, and if this is still the case for recent versions of
>>> gcc/mingw.
>>>
>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>> [7] that we might be able to borrow from.
>>>
>>>
>>> [1] https://msys2.github.io/
>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>> [3] https://github.com/Alexpux/MSYS2-packages
>>> [4] https://github.com/Alexpux/MINGW-packages
>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>> [7] http://rubyinstaller.org/downloads/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jpnolan at american.edu  Thu Jan  8 15:03:17 2015
From: jpnolan at american.edu (John Nolan)
Date: Thu, 8 Jan 2015 09:03:17 -0500
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <54AE6C53.8030702@gmail.com>
References: <54AE6C53.8030702@gmail.com>,
	<bug-16065-16@http.bugs.r-project.org/bugzilla/>	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
Message-ID: <OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>

Adding an optional argument to get (and mget) like

val <- get(name, where, ..., value.if.not.found=NULL )   (*)

would be useful for many.  HOWEVER, it is possible that there could be 
some confusion here: (*) can give a NULL because either x exists and 
has value NULL, or because x doesn't exist.   If that matters, the user 
would need to be careful about specifying a value.if.not.found that cannot 
be confused with a valid value of x.  

To avoid this difficulty, perhaps we want both: have Martin's getifexists( ) 
return a list with two values: 
  - a boolean variable 'found'  # = value returned by exists( )
  - a variable 'value'

Then implement get( ) as:

get <- function(x,...,value.if.not.found ) {

  if( missing(value.if.not.found) ) {
    a <- getifexists(x,... )
    if (!a$found) error("x not found")
  } else {
    a <- getifexists(x,...,value.if.not.found )
  }
  return(a$value)
}

Note that value.if.not.found has no default value in above.
It behaves exactly like current get does if value.if.not.found 
is not specified, and if it is specified, it would be faster 
in the common situation mentioned below:   
     if(exists(x,...)) { get(x,...) }

John

P.S. if you like dromedaries call it valueIfNotFound ...

 ..............................................................
 John P. Nolan
 Math/Stat Department
 227 Gray Hall,   American University
 4400 Massachusetts Avenue, NW
 Washington, DC 20016-8050

 jpnolan at american.edu       voice: 202.885.3140          
 web: academic2.american.edu/~jpnolan
 ..............................................................


-----"R-devel" <r-devel-bounces at r-project.org> wrote: ----- 
To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
From: Duncan Murdoch 
Sent by: "R-devel" 
Date: 01/08/2015 06:39AM
Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}

On 08/01/2015 4:16 AM, Martin Maechler wrote:
> In November, we had a "bug repository conversation"
> with Peter Hagerty and myself:
> 
>   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
> 
> where the bug report title started with
> 
>  --->>  "exists" is a bottleneck for dispatch and package loading, ...
> 
> Peter proposed an extra simplified and henc faster version of exists(),
> and I commented
> 
>     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch> ---
>     > I'm very grateful that you've started exploring the bottlenecks of loading
>     > packages with many S4 classes (and methods)...
>     > and I hope we can make real progress there rather sooner than later.
> 
>     > OTOH, your `summaryRprof()` in your vignette indicates that exists() may use
>     > upto 10% of the time spent in library(reportingTools),  and your speedup
>     > proposals of exist()  may go up to ca 30%  which is good and well worth
>     > considering,  but still we can only expect 2-3% speedup for package loading
>     > which unfortunately is not much.
> 
>     > Still I agree it is worth looking at exists() as you did  ... and 
>     > consider providing a fast simplified version of it in addition to current
>     > exists() [I think].
> 
>     > BTW, as we talk about enhancements here, maybe consider a further possibility:
>     > My subjective guess is that probably more than half of exists() uses are of the
>     > form
> 
>     > if(exists(name, where, .......)) {
>     >    get(name, whare, ....)
>     >    ..
>     > } else { 
>     >     NULL / error() / .. or similar
>     > }
> 
>     > i.e. many exists() calls when returning TRUE are immediately followed by the
>     > corresponding get() call which repeats quite a bit of the lookup that exists()
>     > has done.
> 
>     > Instead, I'd imagine a function, say  getifexists(name, ...) that does both at
>     > once in the "exists is TRUE" case but in a way we can easily keep the if(.) ..
>     > else clause above.  One already existing approach would use
> 
>     > if(!inherits(tryCatch(xx <- get(name, where, ...), error=function(e)e), "error")) {
> 
>     >   ... (( work with xx )) ...
> 
>     > } else  { 
>     >    NULL / error() / .. or similar
>     > }
> 
>     > but of course our C implementation would be more efficient and use more concise
>     > syntax {which should not look like error handling}.   Follow ups to this idea
>     > should really go to R-devel (the mailing list).
> 
> and now I do follow up here myself :
> 
> I found that  'getifexists()' is actually very simple to implement,
> I have already tested it a bit, but not yet committed to R-devel
> (the "R trunk" aka "master branch") because I'd like to get
> public comments {RFC := Request For Comments}.
> 

I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
Journal) pointed out, R names are very inconsistent in naming
conventions, but lowerCamelCase is the most common choice.  Second most
common is period.separated, so an argument could be made for
get.if.exists, but there's still the possibility of confusion with S3
methods, and users of other languages where "." is an operator find it a
little strange.

If you don't like lowerCamelCase (and a lot of people don't), then I
think underscore_separated is the next best choice, so would use
get_if_exists.

Another possibility is to make no new name at all, and just add an
optional parameter to get() (which if present acts as your value.if.not
parameter, if not present keeps the current "object not found" error).

Duncan Murdoch


> My version of the help file {for both exists() and getifexists()}
> rendered in text is
> 
> ---------------------- help(getifexists) -------------------------------
> Is an Object Defined?
> 
> Description:
> 
>      Look for an R object of the given name and possibly return it
> 
> Usage:
> 
>      exists(x, where = -1, envir = , frame, mode = "any",
>             inherits = TRUE)
>      
>      getifexists(x, where = -1, envir = as.environment(where),
>                  mode = "any", inherits = TRUE, value.if.not = NULL)
>      
> Arguments:
> 
>        x: a variable name (given as a character string).
> 
>    where: where to look for the object (see the details section); if
>           omitted, the function will search as if the name of the
>           object appeared unquoted in an expression.
> 
>    envir: an alternative way to specify an environment to look in, but
>           it is usually simpler to just use the ?where? argument.
> 
>    frame: a frame in the calling list.  Equivalent to giving ?where? as
>           ?sys.frame(frame)?.
> 
>     mode: the mode or type of object sought: see the ?Details? section.
> 
> inherits: should the enclosing frames of the environment be searched?
> 
> value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
>           exist.
> 
> Details:
> 
>      The ?where? argument can specify the environment in which to look
>      for the object in any of several ways: as an integer (the position
>      in the ?search? list); as the character string name of an element
>      in the search list; or as an ?environment? (including using
>      ?sys.frame? to access the currently active function calls).  The
>      ?envir? argument is an alternative way to specify an environment,
>      but is primarily there for back compatibility.
> 
>      This function looks to see if the name ?x? has a value bound to it
>      in the specified environment.  If ?inherits? is ?TRUE? and a value
>      is not found for ?x? in the specified environment, the enclosing
>      frames of the environment are searched until the name ?x? is
>      encountered.  See ?environment? and the ?R Language Definition?
>      manual for details about the structure of environments and their
>      enclosures.
> 
>      *Warning:* ?inherits = TRUE? is the default behaviour for R but
>      not for S.
> 
>      If ?mode? is specified then only objects of that type are sought.
>      The ?mode? may specify one of the collections ?"numeric"? and
>      ?"function"? (see ?mode?): any member of the collection will
>      suffice.  (This is true even if a member of a collection is
>      specified, so for example ?mode = "special"? will seek any type of
>      function.)
> 
> Value:
> 
>      ?exists():? Logical, true if and only if an object of the correct
>      name and mode is found.
> 
>      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
>      is true, otherwise ?value.if.not?.
> 
> Note:
> 
>    With ?getifexists()?, instead of the easy to read but somewhat
>    inefficient
>      
>        if (exists(myVarName, envir = myEnvir)) {
>          r <- get(myVarName, envir = myEnvir)
>          ## ... deal with r ...
>        }
> 
>    you now can use the more efficient (and slightly harder to read)
>      
>        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>          ## ... deal with r ...
>        }
> 
> References:
> 
>      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>      Language_.  Wadsworth & Brooks/Cole.
> 
> See Also:
> 
>      ?get?.  For quite a different kind of ?existence? checking, namely
>      if function arguments were specified, ?missing?; and for yet a
>      different kind, namely if a file exists, ?file.exists?.
> 
> Examples:
> 
>      ##  Define a substitute function if necessary:
>      if(!exists("some.fun", mode = "function"))
>        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>      search()
>      exists("ls", 2) # true even though ls is in pos = 3
>      exists("ls", 2, inherits = FALSE) # false
>      
>      ## These are true (in most circumstances):
>      identical(ls,   getifexists("ls"))
>      identical(NULL, getifexists(".foo.bar.")) # default value.if.not = NULL(!)
> 
> ----------------- end[ help(getifexists) ] -----------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Jan  8 15:07:32 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Jan 2015 15:07:32 +0100
Subject: [Rd] On base::rank
In-Reply-To: <CAJ=vYTHRCgOMbVZw1jmFN-fEwdZL1p8JW9nYS+8yBFhsrZoP-Q@mail.gmail.com>
References: <CAJ=vYTHRCgOMbVZw1jmFN-fEwdZL1p8JW9nYS+8yBFhsrZoP-Q@mail.gmail.com>
Message-ID: <21678.36644.238206.536963@stat.math.ethz.ch>

>>>>> Arunkumar Srinivasan <arunkumar.sriniv at gmail.com>
>>>>>     on Thu, 8 Jan 2015 13:46:57 +0100 writes:

> Have a look at the following, taken from base::rank:

> ...
>     if (!is.na(na.last) && any(nas)) {
>         yy <- integer(length(x)) # <~~~~~~~~~
>         storage.mode(yy) <- storage.mode(y) # <~~~~~~~~
>         yy <- NA
>         NAkeep <- (na.last == "keep")
>         if (NAkeep || na.last) {
>             yy[!nas] <- y
>             if (!NAkeep)
>                 yy[nas] <- (length(y) + 1L):length(yy)
>         }
> ...

> Alternatively, look at lines 36 and 37 here:
> https://github.com/wch/r-source/blob/fbf5cdf29d923395b537a9893f46af1aa75e38f3/src/library/base/R/rank.R#L36

> There seems to be no need for those lines, IIUC. Isn't it? 
> 'yy' is replaced with NA in the ver next line.

Indeed.   Interesting that nobody has noticed till now,
even though that part has been world readable since at least 2008-08-25.

Note that the R source code is at 
     http://svn.r-project.org/R/
and the file in question at
     http://svn.r-project.org/R/trunk/src/library/base/R/rank.R

where you can already see the new code
(given that 'x' was no longer needed, there's no need for 'xx').

Martin Maechler, 
ETH Zurich


From murdoch.duncan at gmail.com  Thu Jan  8 15:36:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 08 Jan 2015 09:36:33 -0500
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
References: <54AE6C53.8030702@gmail.com>,
	<bug-16065-16@http.bugs.r-project.org/bugzilla/>	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>	<21678.19158.736089.111281@stat.math.ethz.ch>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
Message-ID: <54AE95F1.1050402@gmail.com>

On 08/01/2015 9:03 AM, John Nolan wrote:
> Adding an optional argument to get (and mget) like
>
> val <- get(name, where, ..., value.if.not.found=NULL )   (*)

That would be a bad idea, as it would change behaviour of existing uses 
of get().  What I suggested would not
give a default.  If the arg was missing, we'd get the old behaviour, if 
the arg was present, we'd use it.

I'm not sure this is preferable to the separate function 
implementation.  This makes the documentation and implementation of 
get() more complicated, and it would probably be slower for everyone.

Duncan Murdoch

>
> would be useful for many.  HOWEVER, it is possible that there could be
> some confusion here: (*) can give a NULL because either x exists and
> has value NULL, or because x doesn't exist.   If that matters, the user
> would need to be careful about specifying a value.if.not.found that cannot
> be confused with a valid value of x.
>
> To avoid this difficulty, perhaps we want both: have Martin's getifexists( )
> return a list with two values:
>    - a boolean variable 'found'  # = value returned by exists( )
>    - a variable 'value'
>
> Then implement get( ) as:
>
> get <- function(x,...,value.if.not.found ) {
>
>    if( missing(value.if.not.found) ) {
>      a <- getifexists(x,... )
>      if (!a$found) error("x not found")
>    } else {
>      a <- getifexists(x,...,value.if.not.found )
>    }
>    return(a$value)
> }
>
> Note that value.if.not.found has no default value in above.
> It behaves exactly like current get does if value.if.not.found
> is not specified, and if it is specified, it would be faster
> in the common situation mentioned below:
>       if(exists(x,...)) { get(x,...) }
>
> John
>
> P.S. if you like dromedaries call it valueIfNotFound ...
>
>   ..............................................................
>   John P. Nolan
>   Math/Stat Department
>   227 Gray Hall,   American University
>   4400 Massachusetts Avenue, NW
>   Washington, DC 20016-8050
>
>   jpnolan at american.edu       voice: 202.885.3140
>   web: academic2.american.edu/~jpnolan
>   ..............................................................
>
>
> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
> From: Duncan Murdoch
> Sent by: "R-devel"
> Date: 01/08/2015 06:39AM
> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>
> On 08/01/2015 4:16 AM, Martin Maechler wrote:
> > In November, we had a "bug repository conversation"
> > with Peter Hagerty and myself:
> >
> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
> >
> > where the bug report title started with
> >
> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
> >
> > Peter proposed an extra simplified and henc faster version of exists(),
> > and I commented
> >
> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch> ---
> >     > I'm very grateful that you've started exploring the bottlenecks of loading
> >     > packages with many S4 classes (and methods)...
> >     > and I hope we can make real progress there rather sooner than later.
> >
> >     > OTOH, your `summaryRprof()` in your vignette indicates that exists() may use
> >     > upto 10% of the time spent in library(reportingTools),  and your speedup
> >     > proposals of exist()  may go up to ca 30%  which is good and well worth
> >     > considering,  but still we can only expect 2-3% speedup for package loading
> >     > which unfortunately is not much.
> >
> >     > Still I agree it is worth looking at exists() as you did  ... and
> >     > consider providing a fast simplified version of it in addition to current
> >     > exists() [I think].
> >
> >     > BTW, as we talk about enhancements here, maybe consider a further possibility:
> >     > My subjective guess is that probably more than half of exists() uses are of the
> >     > form
> >
> >     > if(exists(name, where, .......)) {
> >     >    get(name, whare, ....)
> >     >    ..
> >     > } else {
> >     >     NULL / error() / .. or similar
> >     > }
> >
> >     > i.e. many exists() calls when returning TRUE are immediately followed by the
> >     > corresponding get() call which repeats quite a bit of the lookup that exists()
> >     > has done.
> >
> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that does both at
> >     > once in the "exists is TRUE" case but in a way we can easily keep the if(.) ..
> >     > else clause above.  One already existing approach would use
> >
> >     > if(!inherits(tryCatch(xx <- get(name, where, ...), error=function(e)e), "error")) {
> >
> >     >   ... (( work with xx )) ...
> >
> >     > } else  {
> >     >    NULL / error() / .. or similar
> >     > }
> >
> >     > but of course our C implementation would be more efficient and use more concise
> >     > syntax {which should not look like error handling}.   Follow ups to this idea
> >     > should really go to R-devel (the mailing list).
> >
> > and now I do follow up here myself :
> >
> > I found that  'getifexists()' is actually very simple to implement,
> > I have already tested it a bit, but not yet committed to R-devel
> > (the "R trunk" aka "master branch") because I'd like to get
> > public comments {RFC := Request For Comments}.
> >
>
> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
> Journal) pointed out, R names are very inconsistent in naming
> conventions, but lowerCamelCase is the most common choice.  Second most
> common is period.separated, so an argument could be made for
> get.if.exists, but there's still the possibility of confusion with S3
> methods, and users of other languages where "." is an operator find it a
> little strange.
>
> If you don't like lowerCamelCase (and a lot of people don't), then I
> think underscore_separated is the next best choice, so would use
> get_if_exists.
>
> Another possibility is to make no new name at all, and just add an
> optional parameter to get() (which if present acts as your value.if.not
> parameter, if not present keeps the current "object not found" error).
>
> Duncan Murdoch
>
>
> > My version of the help file {for both exists() and getifexists()}
> > rendered in text is
> >
> > ---------------------- help(getifexists) -------------------------------
> > Is an Object Defined?
> >
> > Description:
> >
> >      Look for an R object of the given name and possibly return it
> >
> > Usage:
> >
> >      exists(x, where = -1, envir = , frame, mode = "any",
> >             inherits = TRUE)
> >
> >      getifexists(x, where = -1, envir = as.environment(where),
> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
> >
> > Arguments:
> >
> >        x: a variable name (given as a character string).
> >
> >    where: where to look for the object (see the details section); if
> >           omitted, the function will search as if the name of the
> >           object appeared unquoted in an expression.
> >
> >    envir: an alternative way to specify an environment to look in, but
> >           it is usually simpler to just use the ?where? argument.
> >
> >    frame: a frame in the calling list.  Equivalent to giving ?where? as
> >           ?sys.frame(frame)?.
> >
> >     mode: the mode or type of object sought: see the ?Details? section.
> >
> > inherits: should the enclosing frames of the environment be searched?
> >
> > value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
> >           exist.
> >
> > Details:
> >
> >      The ?where? argument can specify the environment in which to look
> >      for the object in any of several ways: as an integer (the position
> >      in the ?search? list); as the character string name of an element
> >      in the search list; or as an ?environment? (including using
> >      ?sys.frame? to access the currently active function calls).  The
> >      ?envir? argument is an alternative way to specify an environment,
> >      but is primarily there for back compatibility.
> >
> >      This function looks to see if the name ?x? has a value bound to it
> >      in the specified environment.  If ?inherits? is ?TRUE? and a value
> >      is not found for ?x? in the specified environment, the enclosing
> >      frames of the environment are searched until the name ?x? is
> >      encountered.  See ?environment? and the ?R Language Definition?
> >      manual for details about the structure of environments and their
> >      enclosures.
> >
> >      *Warning:* ?inherits = TRUE? is the default behaviour for R but
> >      not for S.
> >
> >      If ?mode? is specified then only objects of that type are sought.
> >      The ?mode? may specify one of the collections ?"numeric"? and
> >      ?"function"? (see ?mode?): any member of the collection will
> >      suffice.  (This is true even if a member of a collection is
> >      specified, so for example ?mode = "special"? will seek any type of
> >      function.)
> >
> > Value:
> >
> >      ?exists():? Logical, true if and only if an object of the correct
> >      name and mode is found.
> >
> >      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
> >      is true, otherwise ?value.if.not?.
> >
> > Note:
> >
> >    With ?getifexists()?, instead of the easy to read but somewhat
> >    inefficient
> >
> >        if (exists(myVarName, envir = myEnvir)) {
> >          r <- get(myVarName, envir = myEnvir)
> >          ## ... deal with r ...
> >        }
> >
> >    you now can use the more efficient (and slightly harder to read)
> >
> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
> >          ## ... deal with r ...
> >        }
> >
> > References:
> >
> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
> >      Language_.  Wadsworth & Brooks/Cole.
> >
> > See Also:
> >
> >      ?get?.  For quite a different kind of ?existence? checking, namely
> >      if function arguments were specified, ?missing?; and for yet a
> >      different kind, namely if a file exists, ?file.exists?.
> >
> > Examples:
> >
> >      ##  Define a substitute function if necessary:
> >      if(!exists("some.fun", mode = "function"))
> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
> >      search()
> >      exists("ls", 2) # true even though ls is in pos = 3
> >      exists("ls", 2, inherits = FALSE) # false
> >
> >      ## These are true (in most circumstances):
> >      identical(ls,   getifexists("ls"))
> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not = NULL(!)
> >
> > ----------------- end[ help(getifexists) ] -----------------------------
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From arunkumar.sriniv at gmail.com  Thu Jan  8 15:37:33 2015
From: arunkumar.sriniv at gmail.com (Arunkumar Srinivasan)
Date: Thu, 8 Jan 2015 15:37:33 +0100
Subject: [Rd] On base::rank
In-Reply-To: <21678.36644.238206.536963@stat.math.ethz.ch>
References: <CAJ=vYTHRCgOMbVZw1jmFN-fEwdZL1p8JW9nYS+8yBFhsrZoP-Q@mail.gmail.com>
	<21678.36644.238206.536963@stat.math.ethz.ch>
Message-ID: <CAJ=vYTGTpqFwdBdbns4PCqek_1Gtex+h1gWY+D5d3d-Nn_h+qQ@mail.gmail.com>

> Indeed.   Interesting that nobody has noticed till now,
> even though that part has been world readable since at least 2008-08-25.

That was what made me a bit unsure :-).

> Note that the R source code is at
>      http://svn.r-project.org/R/
> and the file in question at
>      http://svn.r-project.org/R/trunk/src/library/base/R/rank.R

Okay, thanks.

> where you can already see the new code
> (given that 'x' was no longer needed, there's no need for 'xx').

Great! thanks again.

> Martin Maechler,
> ETH Zurich

Best,
Arun.


From kasperdanielhansen at gmail.com  Thu Jan  8 15:57:03 2015
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 8 Jan 2015 09:57:03 -0500
Subject: [Rd] gsub with perl=TRUE results in 'this version of PCRE is
 not compiled with Unicode property support' in R-devel
In-Reply-To: <54AE72CE.2040001@stats.ox.ac.uk>
References: <1545603508.2704628.1420673112345.JavaMail.root@fredhutch.org>
	<54AE72CE.2040001@stats.ox.ac.uk>
Message-ID: <CAC2h7us0d6rJGED2sT_9epNqp55=GTM0K6PL+YWsMupciH1izw@mail.gmail.com>

Dan, for OS X, there is a new pcre library posted at
http://r.research.att.com/libs/ with a date stamp of Dec 28.  This fixes
this problem.  You can test for this by running
  make check
post compilation.  It'll bang out with a failure if this is not in order.

(And I know that all of this is described in R-admin).

It would be helpful (time saving) if a message is posted to r-sig-mac
whenever a new (version of a) library is added to
http://r.research.att.com/libs/
I know it is adding more work to the helpful people who are doing all the
heavy lifting.

Kasper

On Thu, Jan 8, 2015 at 7:06 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> Why are you reporting that your PCRE library does not have something which
> the R-admin manual says it should preferably have?  To wit, footnote 37 says
>
> 'and not PCRE2, which started at version 10.0. PCRE must be built with
> UTF-8 support (not the default) and support for Unicode properties is
> assumed by some R packages. Neither are tested by configure. JIT support is
> desirable.'
>
> That certainly does not fail on my Linux, Windows and OS X builds of
> R-devel.  (Issues about pre-built binaries, if that is what you used,
> should be reported to their maintainers, not here.)
>
> And the help does say in ?regex
>
>      In UTF-8 mode, some Unicode properties may be supported via
>      ?\p{xx}? and ?\P{xx}? which match characters with and without
>      property ?xx? respectively.
>
> Note the 'may'.
>
>
>
>
>
> On 07/01/2015 23:25, Dan Tenenbaum wrote:
>
>> The following code:
>>
>> res <- gsub("(*UCP)\\b(i)\\b",
>>      "", "nhgrimelanomaclass", perl = TRUE)
>>
>> results in:
>>
>> Error in gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "",
>> "nhgrimelanomaclass",  :
>>    invalid regular expression '(*UCP)\b(i)\b'
>> In addition: Warning message:
>> In gsub(sprintf("(*UCP)\\b(%s)\\b", "i"), "", "nhgrimelanomaclass",  :
>>    PCRE pattern compilation error
>>         'this version of PCRE is not compiled with Unicode property
>> support'
>>         at '(*UCP)\b(i)\b'
>>
>> on
>>
>> R Under development (unstable) (2015-01-01 r67290)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.9.5 (Mavericks)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> And also on the same version of R-devel on Snow Leopard, Windows, and
>> Linux. But it does not produce an error on
>>
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> Dan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan  8 15:58:00 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 8 Jan 2015 06:58:00 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
Message-ID: <CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>

If we do add an argument to get(), then it should be named consistently
with the ifnotfound argument of mget(). As mentioned, the possibility of a
NULL value is problematic. One solution is a sentinel value that indicates
an unbound value (like R_UnboundValue).

But another idea (and one pretty similar to John's) is to follow the SYMSXP
design at the C level, where there is a structure that points to the name
and a value. We already have SYMSXPs at the R level of course (name
objects) but they do not provide access to the value, which is typically
R_UnboundValue. But this does not even need to be implemented with SYMSXP.
The design would allow something like:

binding <- getBinding("x", env)
if (hasValue(binding)) {
  x <- value(binding) # throws an error if none
  message(name(binding), "has value", x)
}

That I think it is a bit verbose but readable and could be made fast. And I
think binding objects would be useful in other ways, as they are
essentially a "named object". For example, when iterating over an
environment.

Michael




On Thu, Jan 8, 2015 at 6:03 AM, John Nolan <jpnolan at american.edu> wrote:

> Adding an optional argument to get (and mget) like
>
> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>
> would be useful for many.  HOWEVER, it is possible that there could be
> some confusion here: (*) can give a NULL because either x exists and
> has value NULL, or because x doesn't exist.   If that matters, the user
> would need to be careful about specifying a value.if.not.found that cannot
> be confused with a valid value of x.
>
> To avoid this difficulty, perhaps we want both: have Martin's getifexists(
> )
> return a list with two values:
>   - a boolean variable 'found'  # = value returned by exists( )
>   - a variable 'value'
>
> Then implement get( ) as:
>
> get <- function(x,...,value.if.not.found ) {
>
>   if( missing(value.if.not.found) ) {
>     a <- getifexists(x,... )
>     if (!a$found) error("x not found")
>   } else {
>     a <- getifexists(x,...,value.if.not.found )
>   }
>   return(a$value)
> }
>
> Note that value.if.not.found has no default value in above.
> It behaves exactly like current get does if value.if.not.found
> is not specified, and if it is specified, it would be faster
> in the common situation mentioned below:
>      if(exists(x,...)) { get(x,...) }
>
> John
>
> P.S. if you like dromedaries call it valueIfNotFound ...
>
>  ..............................................................
>  John P. Nolan
>  Math/Stat Department
>  227 Gray Hall,   American University
>  4400 Massachusetts Avenue, NW
>  Washington, DC 20016-8050
>
>  jpnolan at american.edu       voice: 202.885.3140
>  web: academic2.american.edu/~jpnolan
>  ..............................................................
>
>
> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
> From: Duncan Murdoch
> Sent by: "R-devel"
> Date: 01/08/2015 06:39AM
> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>
> On 08/01/2015 4:16 AM, Martin Maechler wrote:
> > In November, we had a "bug repository conversation"
> > with Peter Hagerty and myself:
> >
> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
> >
> > where the bug report title started with
> >
> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
> >
> > Peter proposed an extra simplified and henc faster version of exists(),
> > and I commented
> >
> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch>
> ---
> >     > I'm very grateful that you've started exploring the bottlenecks of
> loading
> >     > packages with many S4 classes (and methods)...
> >     > and I hope we can make real progress there rather sooner than
> later.
> >
> >     > OTOH, your `summaryRprof()` in your vignette indicates that
> exists() may use
> >     > upto 10% of the time spent in library(reportingTools),  and your
> speedup
> >     > proposals of exist()  may go up to ca 30%  which is good and well
> worth
> >     > considering,  but still we can only expect 2-3% speedup for
> package loading
> >     > which unfortunately is not much.
> >
> >     > Still I agree it is worth looking at exists() as you did  ... and
> >     > consider providing a fast simplified version of it in addition to
> current
> >     > exists() [I think].
> >
> >     > BTW, as we talk about enhancements here, maybe consider a further
> possibility:
> >     > My subjective guess is that probably more than half of exists()
> uses are of the
> >     > form
> >
> >     > if(exists(name, where, .......)) {
> >     >    get(name, whare, ....)
> >     >    ..
> >     > } else {
> >     >     NULL / error() / .. or similar
> >     > }
> >
> >     > i.e. many exists() calls when returning TRUE are immediately
> followed by the
> >     > corresponding get() call which repeats quite a bit of the lookup
> that exists()
> >     > has done.
> >
> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that
> does both at
> >     > once in the "exists is TRUE" case but in a way we can easily keep
> the if(.) ..
> >     > else clause above.  One already existing approach would use
> >
> >     > if(!inherits(tryCatch(xx <- get(name, where, ...),
> error=function(e)e), "error")) {
> >
> >     >   ... (( work with xx )) ...
> >
> >     > } else  {
> >     >    NULL / error() / .. or similar
> >     > }
> >
> >     > but of course our C implementation would be more efficient and use
> more concise
> >     > syntax {which should not look like error handling}.   Follow ups
> to this idea
> >     > should really go to R-devel (the mailing list).
> >
> > and now I do follow up here myself :
> >
> > I found that  'getifexists()' is actually very simple to implement,
> > I have already tested it a bit, but not yet committed to R-devel
> > (the "R trunk" aka "master branch") because I'd like to get
> > public comments {RFC := Request For Comments}.
> >
>
> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
> Journal) pointed out, R names are very inconsistent in naming
> conventions, but lowerCamelCase is the most common choice.  Second most
> common is period.separated, so an argument could be made for
> get.if.exists, but there's still the possibility of confusion with S3
> methods, and users of other languages where "." is an operator find it a
> little strange.
>
> If you don't like lowerCamelCase (and a lot of people don't), then I
> think underscore_separated is the next best choice, so would use
> get_if_exists.
>
> Another possibility is to make no new name at all, and just add an
> optional parameter to get() (which if present acts as your value.if.not
> parameter, if not present keeps the current "object not found" error).
>
> Duncan Murdoch
>
>
> > My version of the help file {for both exists() and getifexists()}
> > rendered in text is
> >
> > ---------------------- help(getifexists) -------------------------------
> > Is an Object Defined?
> >
> > Description:
> >
> >      Look for an R object of the given name and possibly return it
> >
> > Usage:
> >
> >      exists(x, where = -1, envir = , frame, mode = "any",
> >             inherits = TRUE)
> >
> >      getifexists(x, where = -1, envir = as.environment(where),
> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
> >
> > Arguments:
> >
> >        x: a variable name (given as a character string).
> >
> >    where: where to look for the object (see the details section); if
> >           omitted, the function will search as if the name of the
> >           object appeared unquoted in an expression.
> >
> >    envir: an alternative way to specify an environment to look in, but
> >           it is usually simpler to just use the ?where? argument.
> >
> >    frame: a frame in the calling list.  Equivalent to giving ?where? as
> >           ?sys.frame(frame)?.
> >
> >     mode: the mode or type of object sought: see the ?Details? section.
> >
> > inherits: should the enclosing frames of the environment be searched?
> >
> > value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
> >           exist.
> >
> > Details:
> >
> >      The ?where? argument can specify the environment in which to look
> >      for the object in any of several ways: as an integer (the position
> >      in the ?search? list); as the character string name of an element
> >      in the search list; or as an ?environment? (including using
> >      ?sys.frame? to access the currently active function calls).  The
> >      ?envir? argument is an alternative way to specify an environment,
> >      but is primarily there for back compatibility.
> >
> >      This function looks to see if the name ?x? has a value bound to it
> >      in the specified environment.  If ?inherits? is ?TRUE? and a value
> >      is not found for ?x? in the specified environment, the enclosing
> >      frames of the environment are searched until the name ?x? is
> >      encountered.  See ?environment? and the ?R Language Definition?
> >      manual for details about the structure of environments and their
> >      enclosures.
> >
> >      *Warning:* ?inherits = TRUE? is the default behaviour for R but
> >      not for S.
> >
> >      If ?mode? is specified then only objects of that type are sought.
> >      The ?mode? may specify one of the collections ?"numeric"? and
> >      ?"function"? (see ?mode?): any member of the collection will
> >      suffice.  (This is true even if a member of a collection is
> >      specified, so for example ?mode = "special"? will seek any type of
> >      function.)
> >
> > Value:
> >
> >      ?exists():? Logical, true if and only if an object of the correct
> >      name and mode is found.
> >
> >      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
> >      is true, otherwise ?value.if.not?.
> >
> > Note:
> >
> >    With ?getifexists()?, instead of the easy to read but somewhat
> >    inefficient
> >
> >        if (exists(myVarName, envir = myEnvir)) {
> >          r <- get(myVarName, envir = myEnvir)
> >          ## ... deal with r ...
> >        }
> >
> >    you now can use the more efficient (and slightly harder to read)
> >
> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
> >          ## ... deal with r ...
> >        }
> >
> > References:
> >
> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
> >      Language_.  Wadsworth & Brooks/Cole.
> >
> > See Also:
> >
> >      ?get?.  For quite a different kind of ?existence? checking, namely
> >      if function arguments were specified, ?missing?; and for yet a
> >      different kind, namely if a file exists, ?file.exists?.
> >
> > Examples:
> >
> >      ##  Define a substitute function if necessary:
> >      if(!exists("some.fun", mode = "function"))
> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
> >      search()
> >      exists("ls", 2) # true even though ls is in pos = 3
> >      exists("ls", 2, inherits = FALSE) # false
> >
> >      ## These are true (in most circumstances):
> >      identical(ls,   getifexists("ls"))
> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not =
> NULL(!)
> >
> > ----------------- end[ help(getifexists) ] -----------------------------
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Jan  8 16:02:50 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Jan 2015 16:02:50 +0100
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
References: <54AE6C53.8030702@gmail.com>
	<bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
Message-ID: <21678.39962.577881.546665@stat.math.ethz.ch>


> Adding an optional argument to get (and mget) like
> val <- get(name, where, ..., value.if.not.found=NULL )   (*)

> would be useful for many.  HOWEVER, it is possible that there could be 
> some confusion here: (*) can give a NULL because either x exists and 
> has value NULL, or because x doesn't exist.   If that matters, the user 
> would need to be careful about specifying a value.if.not.found that cannot 
> be confused with a valid value of x.  

Exactly -- well, of course: That problem { NULL can be the legit value of what you
want to get() } was the only reason to have a 'value.if.not' argument at all. 

Note that this is not about a universal replacement of 
the  if(exists(..)) { .. get(..) } idiom, but rather a
replacement of these in the cases where speed matters very much,
which is e.g. in the low level support code for S4 method dispatch.

'value.if.not.found':
Note that CRAN checks requires all arguments to be written in
full length.  Even though we have auto completion in ESS,
Rstudio or other good R IDE's,  I very much like to keep
function calls somewhat compact.

And yes, as you mention the dromedars aka 2-hump camels:  
getIfExist is already horrible to my taste (and "_" is not S-like; 
yes that's all very much a matter of taste and yes I'm from the
20th century).

> To avoid this difficulty, perhaps we want both: have Martin's getifexists( ) 
> return a list with two values: 
>   - a boolean variable 'found'  # = value returned by exists( )
>   - a variable 'value'

> Then implement get( ) as:

> get <- function(x,...,value.if.not.found ) {

>   if( missing(value.if.not.found) ) {
>     a <- getifexists(x,... )
>     if (!a$found) error("x not found")
>   } else {
>     a <- getifexists(x,...,value.if.not.found )
>   }
>   return(a$value)
> }

Interesting...
Note that the above get() implementation would just be "conceptually", as 
all of this is also quite a bit about speed, and we do the
different cases in C anyway [via 'op' code].

> Note that value.if.not.found has no default value in above.
> It behaves exactly like current get does if value.if.not.found 
> is not specified, and if it is specified, it would be faster 
> in the common situation mentioned below:   
>      if(exists(x,...)) { get(x,...) }

Good... Let's talk about your getifexists() as I argue we'd keep
get() exactly as it is now anyway, if we use a new 3rd function (I keep
calling 'getifexists()' for now):

I think in that case, getifexists() would not even *need* an argument 
'value.if.not' (or 'value.if.not.found'); it rather would return a 
  list(found = *, value = *)
in any case.
Alternatively, it could return
  structure(<found>, value = *)

In the first case, our main use case would be

      if((r <- getifexists(x, *))$found) {
         ## work with  r$value
      }

in the 2nd case {structure} :

      if((r <- getifexists(x, *))) {
         ## work with  attr(r,"value")
      }

I think that (both cases) would still be a bit slower (for the above
most important use case) but probably not much
and it would like slightly more readable than my

       if (!is.null(r <- getifexists(x, *))) {
          ## work with  r
       }

After all of this, I think I'd still somewhat prefer my original proposal,
but not strongly -- I had originally also thought of returning the
two parts explicitly, but then tended to prefer the version that
behaved exactly like get() in the case the object is found.

... Nice interesting ideas! ... 
let the proposals and consideration flow ...

Martin


> John

> P.S. if you like dromedaries call it valueIfNotFound ...

:-) ;-)  
I don't .. as I said above, I already strongly dislike more than one hump. 
[ Each capital is one key stroke ("Shift") more ,
  and each "_" is two key strokes more on most key boards...,
  and I do like identifiers that I can also quickly pronounce on
  the phone or in teaching .. ]

>  ..............................................................
>  John P. Nolan
>  Math/Stat Department
>  227 Gray Hall,   American University
>  4400 Massachusetts Avenue, NW
>  Washington, DC 20016-8050
>  ..............................................................


> -----"R-devel" <r-devel-bounces at r-project.org> wrote: ----- 
> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
> From: Duncan Murdoch 
> Sent by: "R-devel" 
> Date: 01/08/2015 06:39AM
> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}

> On 08/01/2015 4:16 AM, Martin Maechler wrote:
> > In November, we had a "bug repository conversation"
> > with Peter Hagerty and myself:
> > 
> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
> > 
> > where the bug report title started with
> > 
> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
> > 
> > Peter proposed an extra simplified and henc faster version of exists(),
> > and I commented
> > 
> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch> ---
> >     > I'm very grateful that you've started exploring the bottlenecks of loading
> >     > packages with many S4 classes (and methods)...
> >     > and I hope we can make real progress there rather sooner than later.
> > 
> >     > OTOH, your `summaryRprof()` in your vignette indicates that exists() may use
> >     > upto 10% of the time spent in library(reportingTools),  and your speedup
> >     > proposals of exist()  may go up to ca 30%  which is good and well worth
> >     > considering,  but still we can only expect 2-3% speedup for package loading
> >     > which unfortunately is not much.
> > 
> >     > Still I agree it is worth looking at exists() as you did  ... and 
> >     > consider providing a fast simplified version of it in addition to current
> >     > exists() [I think].
> > 
> >     > BTW, as we talk about enhancements here, maybe consider a further possibility:
> >     > My subjective guess is that probably more than half of exists() uses are of the
> >     > form
> > 
> >     > if(exists(name, where, .......)) {
> >     >    get(name, whare, ....)
> >     >    ..
> >     > } else { 
> >     >     NULL / error() / .. or similar
> >     > }
> > 
> >     > i.e. many exists() calls when returning TRUE are immediately followed by the
> >     > corresponding get() call which repeats quite a bit of the lookup that exists()
> >     > has done.
> > 
> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that does both at
> >     > once in the "exists is TRUE" case but in a way we can easily keep the if(.) ..
> >     > else clause above.  One already existing approach would use
> > 
> >     > if(!inherits(tryCatch(xx <- get(name, where, ...), error=function(e)e), "error")) {
> > 
> >     >   ... (( work with xx )) ...
> > 
> >     > } else  { 
> >     >    NULL / error() / .. or similar
> >     > }
> > 
> >     > but of course our C implementation would be more efficient and use more concise
> >     > syntax {which should not look like error handling}.   Follow ups to this idea
> >     > should really go to R-devel (the mailing list).
> > 
> > and now I do follow up here myself :
> > 
> > I found that  'getifexists()' is actually very simple to implement,
> > I have already tested it a bit, but not yet committed to R-devel
> > (the "R trunk" aka "master branch") because I'd like to get
> > public comments {RFC := Request For Comments}.
> > 

> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
> Journal) pointed out, R names are very inconsistent in naming
> conventions, but lowerCamelCase is the most common choice.  Second most
> common is period.separated, so an argument could be made for
> get.if.exists, but there's still the possibility of confusion with S3
> methods, and users of other languages where "." is an operator find it a
> little strange.

> If you don't like lowerCamelCase (and a lot of people don't), then I
> think underscore_separated is the next best choice, so would use
> get_if_exists.

> Another possibility is to make no new name at all, and just add an
> optional parameter to get() (which if present acts as your value.if.not
> parameter, if not present keeps the current "object not found" error).

> Duncan Murdoch


> > My version of the help file {for both exists() and getifexists()}
> > rendered in text is
> > 
> > ---------------------- help(getifexists) -------------------------------
> > Is an Object Defined?
> > 
> > Description:
> > 
> >      Look for an R object of the given name and possibly return it
> > 
> > Usage:
> > 
> >      exists(x, where = -1, envir = , frame, mode = "any",
> >             inherits = TRUE)
> >      
> >      getifexists(x, where = -1, envir = as.environment(where),
> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
> >      
> > Arguments:
> > 
> >        x: a variable name (given as a character string).
> > 
> >    where: where to look for the object (see the details section); if
> >           omitted, the function will search as if the name of the
> >           object appeared unquoted in an expression.
> > 
> >    envir: an alternative way to specify an environment to look in, but
> >           it is usually simpler to just use the ?where? argument.
> > 
> >    frame: a frame in the calling list.  Equivalent to giving ?where? as
> >           ?sys.frame(frame)?.
> > 
> >     mode: the mode or type of object sought: see the ?Details? section.
> > 
> > inherits: should the enclosing frames of the environment be searched?
> > 
> > value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
> >           exist.
> > 
> > Details:
> > 
> >      The ?where? argument can specify the environment in which to look
> >      for the object in any of several ways: as an integer (the position
> >      in the ?search? list); as the character string name of an element
> >      in the search list; or as an ?environment? (including using
> >      ?sys.frame? to access the currently active function calls).  The
> >      ?envir? argument is an alternative way to specify an environment,
> >      but is primarily there for back compatibility.
> > 
> >      This function looks to see if the name ?x? has a value bound to it
> >      in the specified environment.  If ?inherits? is ?TRUE? and a value
> >      is not found for ?x? in the specified environment, the enclosing
> >      frames of the environment are searched until the name ?x? is
> >      encountered.  See ?environment? and the ?R Language Definition?
> >      manual for details about the structure of environments and their
> >      enclosures.
> > 
> >      *Warning:* ?inherits = TRUE? is the default behaviour for R but
> >      not for S.
> > 
> >      If ?mode? is specified then only objects of that type are sought.
> >      The ?mode? may specify one of the collections ?"numeric"? and
> >      ?"function"? (see ?mode?): any member of the collection will
> >      suffice.  (This is true even if a member of a collection is
> >      specified, so for example ?mode = "special"? will seek any type of
> >      function.)
> > 
> > Value:
> > 
> >      ?exists():? Logical, true if and only if an object of the correct
> >      name and mode is found.
> > 
> >      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
> >      is true, otherwise ?value.if.not?.
> > 
> > Note:
> > 
> >    With ?getifexists()?, instead of the easy to read but somewhat
> >    inefficient
> >      
> >        if (exists(myVarName, envir = myEnvir)) {
> >          r <- get(myVarName, envir = myEnvir)
> >          ## ... deal with r ...
> >        }
> > 
> >    you now can use the more efficient (and slightly harder to read)
> >      
> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
> >          ## ... deal with r ...
> >        }
> > 
> > References:
> > 
> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
> >      Language_.  Wadsworth & Brooks/Cole.
> > 
> > See Also:
> > 
> >      ?get?.  For quite a different kind of ?existence? checking, namely
> >      if function arguments were specified, ?missing?; and for yet a
> >      different kind, namely if a file exists, ?file.exists?.
> > 
> > Examples:
> > 
> >      ##  Define a substitute function if necessary:
> >      if(!exists("some.fun", mode = "function"))
> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
> >      search()
> >      exists("ls", 2) # true even though ls is in pos = 3
> >      exists("ls", 2, inherits = FALSE) # false
> >      
> >      ## These are true (in most circumstances):
> >      identical(ls,   getifexists("ls"))
> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not = NULL(!)
> > 
> > ----------------- end[ help(getifexists) ] -----------------------------


From pgilbert902 at gmail.com  Thu Jan  8 16:45:24 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 08 Jan 2015 10:45:24 -0500
Subject: [Rd] unloadNamespace
Message-ID: <54AEA614.1050803@gmail.com>

In the documentation the closed thing I see to an explanation of this is 
that ?detach says "Unloading some namespaces has undesirable side effects"

Can anyone explain why unloading tseries will load zoo? I don't think 
this behavior is specific to tseries, it's just an example. I realize 
one would not usually unload something that is not loaded, but I would 
expect it to do nothing or give an error. I only discovered this when 
trying to clean up to debug another problem.

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
and
R Under development (unstable) (2015-01-02 r67308) -- "Unsuffered 
Consequences"
...
Type 'q()' to quit R.

 > loadedNamespaces()
[1] "base"      "datasets"  "graphics"  "grDevices" "methods"   "stats"
[7] "utils"
 > unloadNamespace("tseries") # loads zoo ?
 > loadedNamespaces()
  [1] "base"      "datasets"  "graphics"  "grDevices" "grid" 
"lattice"
  [7] "methods"   "quadprog"  "stats"     "utils"     "zoo"
 >

Somewhat related, is there an easy way to get back to a "clean" state 
for loaded and attached things, as if R had just been started? I'm 
trying to do this in a vignette so it is not easy to stop and restart R.

Paul


From htl10 at users.sourceforge.net  Thu Jan  8 16:48:48 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 8 Jan 2015 15:48:48 +0000
Subject: [Rd] New version of Rtools for Windows
Message-ID: <1420732128.19887.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>


The r.dll crash is easy - you need to be using gcc-ar for ar, and gcc-ranlib for ranlib. I also posted a patch to fix the check failure for stack probing, as lto optimizes away the stack probing code, as it should.

yes, lto build's speed gain is very impressive.



------------------------------
On Thu, Jan 8, 2015 2:01 PM GMT Henric Winell wrote:

>On 2015-01-08 14:18, Avraham Adler wrote:
>
>> Very timely, as this is how I got into the problem I posted about
>> earlier; maybe some of the problems I ran into will mean more to the
>> you and the experts on this thread, Dr. Murdoch.For reference, I run
>> Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.
>>
>> As we discussed offline, Dr. Murdoch, I've been trying to build R
>> using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
>> (rubenvb) told me he is no longer developing his own builds of GCC,
>> but is focusing on MSYS2 and the mingw64 personal builds. So, similar
>> to what Jeroen said, I first installed MSYS2, whose initial
>> installation on windows is not so simple[1]. After the initial
>> install, the following packages need to be manually installed: make,
>> tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
>> is way more than necessary, but there may be packages in there which
>> are necessary.
>>
>> I originally installed the most up-to-date version of GCC (4.9.2)[2],
>> and I did pick the -seh version, as since I install (almost) all
>> packages from source (the one exception being nloptr for now), the
>> exception handling should be consistent and it is supposed to up to
>> ~15% faster[3].
>>
>> The initial build crashed with the following error:
>>
>> gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
>> -pedantic -mtune=core2   -c xmalloc.c -o xmalloc.o
>> ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
>> tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
>> tre-mem.o tre-parse.o tre-stack.o xmalloc.o
>> gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=core2   -c compat.c -o compat.o
>> compat.c:65:5: error: redefinition of 'snprintf'
>>   int snprintf(char *buffer, size_t max, const char *format, ...)
>>       ^
>> In file included from compat.c:3:0:
>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
>> definition of 'snprintf' was here
>>   int snprintf (char * __restrict__ __stream, size_t __n, const char *
>> __restrict__ __format, ...)
>>       ^
>> compat.c:75:5: error: redefinition of 'vsnprintf'
>>   int vsnprintf(char *buffer, size_t bufferSize, const char *format,
>> va_list args)
>>       ^
>> In file included from compat.c:3:0:
>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
>> definition of 'vsnprintf' was here
>>     int vsnprintf (char * __restrict__ __stream, size_t __n, const char
>> * __restrict__ __format, va_list __local_argv)
>>         ^
>> ../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
>> make[4]: *** [compat.o] Error 1
>> Makefile:120: recipe for target 'rlibs' failed
>> make[3]: *** [rlibs] Error 1
>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>> make[2]: *** [../../bin/x64/R.dll] Error 2
>> Makefile:104: recipe for target 'rbuild' failed
>> make[1]: *** [rbuild] Error 2
>> Makefile:14: recipe for target 'all' failed
>> make: *** [all] Error 2
>>
>> After doing some checking (for example see [4]), I asked Duncan about
>> the problem, and he suggested moving the #ifndef _W64 in compat.c up
>> above the offending lines (65-75). That did not work, so, I figured
>> (it seems mistakenly from the other thread) that if those functions
>> are included from stdio already, I can just delete them from compat.c.
>> The specific lines are:
>>
>> int snprintf(char *buffer, size_t max, const char *format, ...)
>> {
>>      int res;
>>      va_list(ap);
>>      va_start(ap, format);
>>      res = trio_vsnprintf(buffer, max, format, ap);
>>      va_end(ap);
>>      return res;
>> }
>>
>> int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
>> {
>>      return trio_vsnprintf(buffer, bufferSize, format, args);
>> }
>>
>> Continuing the build using 4.9.2 crashed again at the following point:
>>
>> gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=core2   -c malloc.c -o
>> malloc.o
>> windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
>> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>> dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>> psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>> system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>> ../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>> ../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>> ../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>> ../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>> -lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>> -lcomctl32 -lversion
>> collect2.exe: error: ld returned 5 exit status
>> Makefile:150: recipe for target 'R.dll' failed
>> make[3]: *** [R.dll] Error 1
>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>> make[2]: *** [../../bin/x64/R.dll] Error 2
>> Makefile:104: recipe for target 'rbuild' failed
>> make[1]: *** [rbuild] Error 2
>> Makefile:14: recipe for target 'all' failed
>> make: *** [all] Error 2
>>
>> As all those files existed in their correct places, the only reason I
>> could think of that this would fail here is that GCC version 4.9 did
>> make some changes to enhance link-time optimization [5], and probably
>> something isn't compatible.
>
>Right.  Just before Christmas, Hin-Tak Leung reported build failure with
>LTO:
>
>https://stat.ethz.ch/pipermail/r-devel/2014-December/070286.html
>https://stat.ethz.ch/pipermail/r-devel/2014-December/070319.html
>
>
>Many thanks to you and others for looking into this,
>Henric
>
>
>
>> I then downgraded to GCC 4.8.4 [6], and,
>> with the deletion of those 10 or so lines from compat.c, I can
>> complete the build straight through rinstaller. However, I get that
>> failure issue due to the extra 0 in scientific notation [7].
>>
>> It does not matter if I do the entire process in the MSYS2
>> environment, or if I do in in Windows with msys\usr\bin in my path.
>>
>> Na?vely, it seems that if there were some what for stdio to be
>> included in compat.c, yet the versions of snprintf and vsprintf in
>> that file to "override" the standard, perhaps this method would work.
>> Of course, running make check-all may uncover more issues. I intend to
>> run the equivalent checks (from the tools library) inside of R with
>> kill on failure turned off to see if anything else is problematic.
>>
>> Hopefully, something in this description resonates with one of the
>> readers here. If anyone has any ideas as to how to circumvent the
>> issues with compat.c, I'd be very grateful.
>>
>> Thank you,
>>
>> Avi
>>
>>
>> [1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
>> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
>> [3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>> [4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
>> [5] https://gcc.gnu.org/gcc-4.9/changes.html
>> [6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
>> [7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html
>>
>> Date: Wed, 07 Jan 2015 20:31:07 -0500
>>
>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>> To: Jeroen Ooms <jeroenooms at gmail.com>
>> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
>> Subject: Re: [Rd] New version of Rtools for Windows
>> Message-ID: <54ADDDDB.4020500 at gmail.com>
>> Content-Type: text/plain; charset=utf-8
>>
>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>
>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>
>>> I have been looking into this a bit over the past few months, also
>>> with mixed success. Nevertheless, below some experiences that might be
>>> worth sharing.
>>>
>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>> multilib. They explained that the standard approach is to create two
>>> separate toolchains; one that targets win32 and the other one that
>>> targets win64 (both tool chains can compiled for win32). Hence the
>>> only difference for R would be that instead of passing "-m64" and
>>> "-m32", it would need to set the path to the proper compiler.
>>>
>>> There are several initiatives that provide very complete suites of
>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>> could take advantage of an existing tool chain as we do on other
>>> platforms, although perhaps I do not fully understand the R-specific
>>> requirements on the windows compiler.
>>
>> I feel quite strongly that we need to be able to build the toolchain,
>> rather than relying on binaries produced by others.  We may need to
>> customize the toolchain, or we may need to rebuild it when a bug is
>> identified.  Lots of binary builders abandon their builds and you can't
>> count on them to solve problems at a later date.
>>
>>>
>>> One project that looks very promising is msys2 [1,2]. It has a package
>>> manager (port of pacman from arch linux) and comes with a pretty
>>> complete set of msys [3] and other [4] packages that seems quite well
>>> maintained.
>>
>> Do they post complete instructions for building?  That's what I'm
>> looking for.  I don't want to develop a build script (I don't know how),
>> but I would like to have one.
>>
>> Duncan Murdoch
>>
>>>
>>> The only issue I ran into with msys2 is that it uses a different c++
>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>> the current Rtools to link a static library that was created with
>>> msys2  [6]. I am not sure if it also be a problem the other way
>>> around, and if this is still the case for recent versions of
>>> gcc/mingw.
>>>
>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>> [7] that we might be able to borrow from.
>>>
>>>
>>> [1] https://msys2.github.io/
>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>> [3] https://github.com/Alexpux/MSYS2-packages
>>> [4] https://github.com/Alexpux/MINGW-packages
>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>> [7] http://rubyinstaller.org/downloads/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From gmbecker at ucdavis.edu  Thu Jan  8 16:52:02 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 8 Jan 2015 07:52:02 -0800
Subject: [Rd] unloadNamespace
In-Reply-To: <54AEA614.1050803@gmail.com>
References: <54AEA614.1050803@gmail.com>
Message-ID: <CADwqtCN9efrX+-KKbd0_bkUk_meb-nz3OjpxOVPWb+1cJDKeKg@mail.gmail.com>

Paul,

My switchr package (https://github.com/gmbecker/switchr) has the
flushSession function which does what you want and seems to work (on my
test machine at least).

I havent tested it under a recent Rdevel, or with that specific package,
however I will soon, as the overarching model of switchr relies on this
working.

If you do try it before me with that package, please let me know whether it
works or not.

~G

On Thu, Jan 8, 2015 at 7:45 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:

> In the documentation the closed thing I see to an explanation of this is
> that ?detach says "Unloading some namespaces has undesirable side effects"
>
> Can anyone explain why unloading tseries will load zoo? I don't think this
> behavior is specific to tseries, it's just an example. I realize one would
> not usually unload something that is not loaded, but I would expect it to
> do nothing or give an error. I only discovered this when trying to clean up
> to debug another problem.
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> and
> R Under development (unstable) (2015-01-02 r67308) -- "Unsuffered
> Consequences"
> ...
> Type 'q()' to quit R.
>
> > loadedNamespaces()
> [1] "base"      "datasets"  "graphics"  "grDevices" "methods"   "stats"
> [7] "utils"
> > unloadNamespace("tseries") # loads zoo ?
> > loadedNamespaces()
>  [1] "base"      "datasets"  "graphics"  "grDevices" "grid" "lattice"
>  [7] "methods"   "quadprog"  "stats"     "utils"     "zoo"
> >
>
> Somewhat related, is there an easy way to get back to a "clean" state for
> loaded and attached things, as if R had just been started? I'm trying to do
> this in a vignette so it is not easy to stop and restart R.
>
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Alumnus
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Thu Jan  8 19:16:05 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 8 Jan 2015 13:16:05 -0500
Subject: [Rd] New version of Rtools for Windows
Message-ID: <CAL6gwnL+b9KY2ce4wok0GL9Ej=+Tyt7j4pZvf+O4b=-A58NeMA@mail.gmail.com>

On Thu, Jan 8, 2015 at 10:48 AM, Hin-Tak Leung
<htl10 at users.sourceforge.net> wrote:
>
> The r.dll crash is easy - you need to be using gcc-ar for ar, and gcc-ranlib for ranlib. I also posted a patch to fix the check failure for stack probing, as lto optimizes away the stack probing code, as it should.
>
> yes, lto build's speed gain is very impressive.
>
>


I apologize for my ignorance, but how would I do that? I tried by
changing the following in src/gnuwin32/MkRules.local:

# prefix for 64-bit: path or x86_64-w64-mingw32-
BINPREF64 = x86_64-w64-mingw32-gcc-

I added the gcc- as the suffix there, but I guess that is insufficient
as I still get the following error using 4.9.2:

windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
-lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
-lcomctl32 -lversion
collect2.exe: error: ld returned 5 exit status
Makefile:150: recipe for target 'R.dll' failed
make[3]: *** [R.dll] Error 1
Makefile:179: recipe for target '../../bin/x64/R.dll' failed
make[2]: *** [../../bin/x64/R.dll] Error 2
Makefile:104: recipe for target 'rbuild' failed
make[1]: *** [rbuild] Error 2
Makefile:14: recipe for target 'all' failed
make: *** [all] Error 2

I still had to delete those lines in compat.c, so this build, were it
to have completed, is still subject to the non-conformance of
scientfic notation printing that was discussed earlier.

Hin-tak, any suggestions for this error (and the compat.c for that
matter) that you, or any reader of this list, may have would be
greatly appreciated.

Thank you!

Avi



> ------------------------------
> On Thu, Jan 8, 2015 2:01 PM GMT Henric Winell wrote:
>
>>On 2015-01-08 14:18, Avraham Adler wrote:
>>
>>> Very timely, as this is how I got into the problem I posted about
>>> earlier; maybe some of the problems I ran into will mean more to the
>>> you and the experts on this thread, Dr. Murdoch.For reference, I run
>>> Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.
>>>
>>> As we discussed offline, Dr. Murdoch, I've been trying to build R
>>> using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
>>> (rubenvb) told me he is no longer developing his own builds of GCC,
>>> but is focusing on MSYS2 and the mingw64 personal builds. So, similar
>>> to what Jeroen said, I first installed MSYS2, whose initial
>>> installation on windows is not so simple[1]. After the initial
>>> install, the following packages need to be manually installed: make,
>>> tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
>>> is way more than necessary, but there may be packages in there which
>>> are necessary.
>>>
>>> I originally installed the most up-to-date version of GCC (4.9.2)[2],
>>> and I did pick the -seh version, as since I install (almost) all
>>> packages from source (the one exception being nloptr for now), the
>>> exception handling should be consistent and it is supposed to up to
>>> ~15% faster[3].
>>>
>>> The initial build crashed with the following error:
>>>
>>> gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
>>> -pedantic -mtune=core2   -c xmalloc.c -o xmalloc.o
>>> ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
>>> tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
>>> tre-mem.o tre-parse.o tre-stack.o xmalloc.o
>>> gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=core2   -c compat.c -o compat.o
>>> compat.c:65:5: error: redefinition of 'snprintf'
>>>   int snprintf(char *buffer, size_t max, const char *format, ...)
>>>       ^
>>> In file included from compat.c:3:0:
>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
>>> definition of 'snprintf' was here
>>>   int snprintf (char * __restrict__ __stream, size_t __n, const char *
>>> __restrict__ __format, ...)
>>>       ^
>>> compat.c:75:5: error: redefinition of 'vsnprintf'
>>>   int vsnprintf(char *buffer, size_t bufferSize, const char *format,
>>> va_list args)
>>>       ^
>>> In file included from compat.c:3:0:
>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
>>> definition of 'vsnprintf' was here
>>>     int vsnprintf (char * __restrict__ __stream, size_t __n, const char
>>> * __restrict__ __format, va_list __local_argv)
>>>         ^
>>> ../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
>>> make[4]: *** [compat.o] Error 1
>>> Makefile:120: recipe for target 'rlibs' failed
>>> make[3]: *** [rlibs] Error 1
>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>> Makefile:104: recipe for target 'rbuild' failed
>>> make[1]: *** [rbuild] Error 2
>>> Makefile:14: recipe for target 'all' failed
>>> make: *** [all] Error 2
>>>
>>> After doing some checking (for example see [4]), I asked Duncan about
>>> the problem, and he suggested moving the #ifndef _W64 in compat.c up
>>> above the offending lines (65-75). That did not work, so, I figured
>>> (it seems mistakenly from the other thread) that if those functions
>>> are included from stdio already, I can just delete them from compat.c.
>>> The specific lines are:
>>>
>>> int snprintf(char *buffer, size_t max, const char *format, ...)
>>> {
>>>      int res;
>>>      va_list(ap);
>>>      va_start(ap, format);
>>>      res = trio_vsnprintf(buffer, max, format, ap);
>>>      va_end(ap);
>>>      return res;
>>> }
>>>
>>> int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
>>> {
>>>      return trio_vsnprintf(buffer, bufferSize, format, args);
>>> }
>>>
>>> Continuing the build using 4.9.2 crashed again at the following point:
>>>
>>> gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=core2   -c malloc.c -o
>>> malloc.o
>>> windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
>>> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>>> dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>>> psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>>> system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>>> ../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>>> ../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>>> ../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>>> ../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>>> -lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>>> -lcomctl32 -lversion
>>> collect2.exe: error: ld returned 5 exit status
>>> Makefile:150: recipe for target 'R.dll' failed
>>> make[3]: *** [R.dll] Error 1
>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>> Makefile:104: recipe for target 'rbuild' failed
>>> make[1]: *** [rbuild] Error 2
>>> Makefile:14: recipe for target 'all' failed
>>> make: *** [all] Error 2
>>>
>>> As all those files existed in their correct places, the only reason I
>>> could think of that this would fail here is that GCC version 4.9 did
>>> make some changes to enhance link-time optimization [5], and probably
>>> something isn't compatible.
>>
>>Right.  Just before Christmas, Hin-Tak Leung reported build failure with
>>LTO:
>>
>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070286.html
>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070319.html
>>
>>
>>Many thanks to you and others for looking into this,
>>Henric
>>
>>
>>
>>> I then downgraded to GCC 4.8.4 [6], and,
>>> with the deletion of those 10 or so lines from compat.c, I can
>>> complete the build straight through rinstaller. However, I get that
>>> failure issue due to the extra 0 in scientific notation [7].
>>>
>>> It does not matter if I do the entire process in the MSYS2
>>> environment, or if I do in in Windows with msys\usr\bin in my path.
>>>
>>> Na?vely, it seems that if there were some what for stdio to be
>>> included in compat.c, yet the versions of snprintf and vsprintf in
>>> that file to "override" the standard, perhaps this method would work.
>>> Of course, running make check-all may uncover more issues. I intend to
>>> run the equivalent checks (from the tools library) inside of R with
>>> kill on failure turned off to see if anything else is problematic.
>>>
>>> Hopefully, something in this description resonates with one of the
>>> readers here. If anyone has any ideas as to how to circumvent the
>>> issues with compat.c, I'd be very grateful.
>>>
>>> Thank you,
>>>
>>> Avi
>>>
>>>
>>> [1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
>>> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
>>> [3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
>>> [5] https://gcc.gnu.org/gcc-4.9/changes.html
>>> [6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
>>> [7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html
>>>
>>> Date: Wed, 07 Jan 2015 20:31:07 -0500
>>>
>>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>>> To: Jeroen Ooms <jeroenooms at gmail.com>
>>> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
>>> Subject: Re: [Rd] New version of Rtools for Windows
>>> Message-ID: <54ADDDDB.4020500 at gmail.com>
>>> Content-Type: text/plain; charset=utf-8
>>>
>>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>>
>>>> I have been looking into this a bit over the past few months, also
>>>> with mixed success. Nevertheless, below some experiences that might be
>>>> worth sharing.
>>>>
>>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>>> multilib. They explained that the standard approach is to create two
>>>> separate toolchains; one that targets win32 and the other one that
>>>> targets win64 (both tool chains can compiled for win32). Hence the
>>>> only difference for R would be that instead of passing "-m64" and
>>>> "-m32", it would need to set the path to the proper compiler.
>>>>
>>>> There are several initiatives that provide very complete suites of
>>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>>> could take advantage of an existing tool chain as we do on other
>>>> platforms, although perhaps I do not fully understand the R-specific
>>>> requirements on the windows compiler.
>>>
>>> I feel quite strongly that we need to be able to build the toolchain,
>>> rather than relying on binaries produced by others.  We may need to
>>> customize the toolchain, or we may need to rebuild it when a bug is
>>> identified.  Lots of binary builders abandon their builds and you can't
>>> count on them to solve problems at a later date.
>>>
>>>>
>>>> One project that looks very promising is msys2 [1,2]. It has a package
>>>> manager (port of pacman from arch linux) and comes with a pretty
>>>> complete set of msys [3] and other [4] packages that seems quite well
>>>> maintained.
>>>
>>> Do they post complete instructions for building?  That's what I'm
>>> looking for.  I don't want to develop a build script (I don't know how),
>>> but I would like to have one.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> The only issue I ran into with msys2 is that it uses a different c++
>>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>>> the current Rtools to link a static library that was created with
>>>> msys2  [6]. I am not sure if it also be a problem the other way
>>>> around, and if this is still the case for recent versions of
>>>> gcc/mingw.
>>>>
>>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>>> [7] that we might be able to borrow from.
>>>>
>>>>
>>>> [1] https://msys2.github.io/
>>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>>> [3] https://github.com/Alexpux/MSYS2-packages
>>>> [4] https://github.com/Alexpux/MINGW-packages
>>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>>> [7] http://rubyinstaller.org/downloads/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>


From htl10 at users.sourceforge.net  Thu Jan  8 20:27:20 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 8 Jan 2015 19:27:20 +0000
Subject: [Rd] New version of Rtools for Windows
Message-ID: <1420745240.60250.YahooMailBasic@web172303.mail.ir2.yahoo.com>

Oh, I forgot to mention that besides setting AR, RANLIB and the stack probing fix, you also need a very up to date binutils. 2.25 was out in december. Even with that , if you linker's default is not what you are compiling for (i.e. a multiarch toolchain), you need to set GNUTARGET also, i.e. -m32/-m64 is not enough. Some fix to autodetect non-default targets went in after christmas before the new year, but I am not brave enough to try that on a daily basis yet (only tested it and reported it, then reverting the change - how gcc invokes the linker is rather complicated and it is not easy to have two binutils installed...)- setting GNUTARGET seems safer :-).
Whether you need that depends on whether you are compiling for your toolchain's default target architecture.

AR, RANLIB, GNUTARGET are all environment variables - you set them the usual way. The stack probing fix is for passing "make check", when you finish make.

------------------------------
On Thu, Jan 8, 2015 6:14 PM GMT Avraham Adler wrote:

>On Thu, Jan 8, 2015 at 10:48 AM, Hin-Tak Leung
><htl10 at users.sourceforge.net> wrote:
>>
>> The r.dll crash is easy - you need to be using gcc-ar for ar, and gcc-ranlib for ranlib. I also posted a patch to fix the check failure for stack probing, as lto optimizes away the stack probing code, as it should.
>>
>> yes, lto build's speed gain is very impressive.
>>
>
>
>I apologize for my ignorance, but how would I do that? I tried by
>changing the following in src/gnuwin32/MkRules.local:
>
># prefix for 64-bit: path or x86_64-w64-mingw32-
>BINPREF64 = x86_64-w64-mingw32-gcc-
>
>I added the gcc- as the suffix there, but I guess that is insufficient
>as I still get the following error using 4.9.2:
>
>windres -F pe-x86-64? -I../include -i dllversion.rc -o dllversion.o
>gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>-lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>-lcomctl32 -lversion
>collect2.exe: error: ld returned 5 exit status
>Makefile:150: recipe for target 'R.dll' failed
>make[3]: *** [R.dll] Error 1
>Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>make[2]: *** [../../bin/x64/R.dll] Error 2
>Makefile:104: recipe for target 'rbuild' failed
>make[1]: *** [rbuild] Error 2
>Makefile:14: recipe for target 'all' failed
>make: *** [all] Error 2
>
>I still had to delete those lines in compat.c, so this build, were it
>to have completed, is still subject to the non-conformance of
>scientfic notation printing that was discussed earlier.
>
>Hin-tak, any suggestions for this error (and the compat.c for that
>matter) that you, or any reader of this list, may have would be
>greatly appreciated.
>
>Thank you!
>
>Avi
>
>
>> ------------------------------
>> On Thu, Jan 8, 2015 2:01 PM GMT Henric Winell wrote:
>>
>>On 2015-01-08 14:18, Avraham Adler wrote:
>>
>>> Very timely, as this is how I got into the problem I posted about
>>> earlier; maybe some of the problems I ran into will mean more to the
>>> you and the experts on this thread, Dr. Murdoch.For reference, I run
>>> Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.
>>>
>>> As we discussed offline, Dr. Murdoch, I've been trying to build R
>>> using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
>>> (rubenvb) told me he is no longer developing his own builds of GCC,
>>> but is focusing on MSYS2 and the mingw64 personal builds. So, similar
>>> to what Jeroen said, I first installed MSYS2, whose initial
>>> installation on windows is not so simple[1]. After the initial
>>> install, the following packages need to be manually installed: make,
>>> tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
>>> is way more than necessary, but there may be packages in there which
>>> are necessary.
>>>
>>> I originally installed the most up-to-date version of GCC (4.9.2)[2],
>>> and I did pick the -seh version, as since I install (almost) all
>>> packages from source (the one exception being nloptr for now), the
>>> exception handling should be consistent and it is supposed to up to
>>> ~15% faster[3].
>>>
>>> The initial build crashed with the following error:
>>>
>>> gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H? -O3 -Wall
>>> -pedantic -mtune=core2???-c xmalloc.c -o xmalloc.o
>>> ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
>>> tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
>>> tre-mem.o tre-parse.o tre-stack.o xmalloc.o
>>> gcc -std=gnu99 -m64???-O3 -Wall -pedantic -mtune=core2???-c compat.c -o compat.o
>>> compat.c:65:5: error: redefinition of 'snprintf'
>>>???int snprintf(char *buffer, size_t max, const char *format, ...)
>>>? ? ???^
>>> In file included from compat.c:3:0:
>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
>>> definition of 'snprintf' was here
>>>???int snprintf (char * __restrict__ __stream, size_t __n, const char *
>>> __restrict__ __format, ...)
>>>? ? ???^
>>> compat.c:75:5: error: redefinition of 'vsnprintf'
>>>???int vsnprintf(char *buffer, size_t bufferSize, const char *format,
>>> va_list args)
>>>? ? ???^
>>> In file included from compat.c:3:0:
>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
>>> definition of 'vsnprintf' was here
>>>? ???int vsnprintf (char * __restrict__ __stream, size_t __n, const char
>>> * __restrict__ __format, va_list __local_argv)
>>>? ? ? ???^
>>> ../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
>>> make[4]: *** [compat.o] Error 1
>>> Makefile:120: recipe for target 'rlibs' failed
>>> make[3]: *** [rlibs] Error 1
>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>> Makefile:104: recipe for target 'rbuild' failed
>>> make[1]: *** [rbuild] Error 2
>>> Makefile:14: recipe for target 'all' failed
>>> make: *** [all] Error 2
>>>
>>> After doing some checking (for example see [4]), I asked Duncan about
>>> the problem, and he suggested moving the #ifndef _W64 in compat.c up
>>> above the offending lines (65-75). That did not work, so, I figured
>>> (it seems mistakenly from the other thread) that if those functions
>>> are included from stdio already, I can just delete them from compat.c.
>>> The specific lines are:
>>>
>>> int snprintf(char *buffer, size_t max, const char *format, ...)
>>> {
>>>? ? ? int res;
>>>? ? ? va_list(ap);
>>>? ? ? va_start(ap, format);
>>>? ? ? res = trio_vsnprintf(buffer, max, format, ap);
>>>? ? ? va_end(ap);
>>>? ? ? return res;
>>> }
>>>
>>> int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
>>> {
>>>? ? ? return trio_vsnprintf(buffer, bufferSize, format, args);
>>> }
>>>
>>> Continuing the build using 4.9.2 crashed again at the following point:
>>>
>>> gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD? -O3 -Wall -pedantic -mtune=core2???-c malloc.c -o
>>> malloc.o
>>> windres -F pe-x86-64? -I../include -i dllversion.rc -o dllversion.o
>>> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>>> dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>>> psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>>> system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>>> ../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>>> ../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>>> ../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>>> ../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>>> -lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>>> -lcomctl32 -lversion
>>> collect2.exe: error: ld returned 5 exit status
>>> Makefile:150: recipe for target 'R.dll' failed
>>> make[3]: *** [R.dll] Error 1
>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>> Makefile:104: recipe for target 'rbuild' failed
>>> make[1]: *** [rbuild] Error 2
>>> Makefile:14: recipe for target 'all' failed
>>> make: *** [all] Error 2
>>>
>>> As all those files existed in their correct places, the only reason I
>>> could think of that this would fail here is that GCC version 4.9 did
>>> make some changes to enhance link-time optimization [5], and probably
>>> something isn't compatible.
>>
>>Right.? Just before Christmas, Hin-Tak Leung reported build failure with
>>LTO:
>>
>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070286.html
>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070319.html
>>
>>
>>Many thanks to you and others for looking into this,
>>Henric
>>
>>
>>
>>> I then downgraded to GCC 4.8.4 [6], and,
>>> with the deletion of those 10 or so lines from compat.c, I can
>>> complete the build straight through rinstaller. However, I get that
>>> failure issue due to the extra 0 in scientific notation [7].
>>>
>>> It does not matter if I do the entire process in the MSYS2
>>> environment, or if I do in in Windows with msys\usr\bin in my path.
>>>
>>> Na?vely, it seems that if there were some what for stdio to be
>>> included in compat.c, yet the versions of snprintf and vsprintf in
>>> that file to "override" the standard, perhaps this method would work.
>>> Of course, running make check-all may uncover more issues. I intend to
>>> run the equivalent checks (from the tools library) inside of R with
>>> kill on failure turned off to see if anything else is problematic.
>>>
>>> Hopefully, something in this description resonates with one of the
>>> readers here. If anyone has any ideas as to how to circumvent the
>>> issues with compat.c, I'd be very grateful.
>>>
>>> Thank you,
>>>
>>> Avi
>>>
>>>
>>> [1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
>>> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
>>> [3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
>>> [5] https://gcc.gnu.org/gcc-4.9/changes.html
>>> [6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
>>> [7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html
>>>
>>> Date: Wed, 07 Jan 2015 20:31:07 -0500
>>>
>>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>>> To: Jeroen Ooms <jeroenooms at gmail.com>
>>> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
>>> Subject: Re: [Rd] New version of Rtools for Windows
>>> Message-ID: <54ADDDDB.4020500 at gmail.com>
>>> Content-Type: text/plain; charset=utf-8
>>>
>>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>
>>> This version includes only minor updates to the tools.? I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>
>>> I have been looking into this a bit over the past few months, also
>>> with mixed success. Nevertheless, below some experiences that might be
>>> worth sharing.
>>>
>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>> multilib. They explained that the standard approach is to create two
>>> separate toolchains; one that targets win32 and the other one that
>>> targets win64 (both tool chains can compiled for win32). Hence the
>>> only difference for R would be that instead of passing "-m64" and
>>> "-m32", it would need to set the path to the proper compiler.
>>>
>>> There are several initiatives that provide very complete suites of
>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>> could take advantage of an existing tool chain as we do on other
>>> platforms, although perhaps I do not fully understand the R-specific
>>> requirements on the windows compiler.
>>>
>>> I feel quite strongly that we need to be able to build the toolchain,
>>> rather than relying on binaries produced by others.? We may need to
>>> customize the toolchain, or we may need to rebuild it when a bug is
>>> identified.? Lots of binary builders abandon their builds and you can't
>>> count on them to solve problems at a later date.
>>>
>>>
>>> One project that looks very promising is msys2 [1,2]. It has a package
>>> manager (port of pacman from arch linux) and comes with a pretty
>>> complete set of msys [3] and other [4] packages that seems quite well
>>> maintained.
>>>
>>> Do they post complete instructions for building?? That's what I'm
>>> looking for.? I don't want to develop a build script (I don't know how),
>>> but I would like to have one.
>>>
>>> Duncan Murdoch
>>>
>>>
>>> The only issue I ran into with msys2 is that it uses a different c++
>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>> the current Rtools to link a static library that was created with
>>> msys2? [6]. I am not sure if it also be a problem the other way
>>> around, and if this is still the case for recent versions of
>>> gcc/mingw.
>>>
>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>> [7] that we might be able to borrow from.
>>>
>>>
>>> [1] https://msys2.github.io/
>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>> [3] https://github.com/Alexpux/MSYS2-packages
>>> [4] https://github.com/Alexpux/MINGW-packages
>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>> [7] http://rubyinstaller.org/downloads/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>


From luke-tierney at uiowa.edu  Thu Jan  8 20:57:22 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 8 Jan 2015 13:57:22 -0600
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1501081340590.24557@luke-Latitude>

On Thu, 8 Jan 2015, Michael Lawrence wrote:

> If we do add an argument to get(), then it should be named consistently
> with the ifnotfound argument of mget(). As mentioned, the possibility of a
> NULL value is problematic. One solution is a sentinel value that indicates
> an unbound value (like R_UnboundValue).

A null default is fine -- it's a default; if it isn't right for a
particular case you can provide something else.

>
> But another idea (and one pretty similar to John's) is to follow the SYMSXP
> design at the C level, where there is a structure that points to the name
> and a value. We already have SYMSXPs at the R level of course (name
> objects) but they do not provide access to the value, which is typically
> R_UnboundValue. But this does not even need to be implemented with SYMSXP.
> The design would allow something like:
>
> binding <- getBinding("x", env)
> if (hasValue(binding)) {
>  x <- value(binding) # throws an error if none
>  message(name(binding), "has value", x)
> }
>
> That I think it is a bit verbose but readable and could be made fast. And I
> think binding objects would be useful in other ways, as they are
> essentially a "named object". For example, when iterating over an
> environment.

This would need a lot more thought. Directly exposing the internals is
definitely not something we want to do as we may well want to change
that design. But there are lots of other corner issues that would have
to be thought through before going forward, such as what happens if an
rm occurs between obtaining a binding object and doing something with
it. Serialization would also need thinking through. This doesn't seem
like a worthwhile place to spend our efforts to me.

Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
an argument to get() with missing giving current behavior may be OK
too. Rewriting exists and get as .Primitives may be sufficient though.

Best,

luke


> Michael
>
>
>
>
> On Thu, Jan 8, 2015 at 6:03 AM, John Nolan <jpnolan at american.edu> wrote:
>
>> Adding an optional argument to get (and mget) like
>>
>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>>
>> would be useful for many.  HOWEVER, it is possible that there could be
>> some confusion here: (*) can give a NULL because either x exists and
>> has value NULL, or because x doesn't exist.   If that matters, the user
>> would need to be careful about specifying a value.if.not.found that cannot
>> be confused with a valid value of x.
>>
>> To avoid this difficulty, perhaps we want both: have Martin's getifexists(
>> )
>> return a list with two values:
>>   - a boolean variable 'found'  # = value returned by exists( )
>>   - a variable 'value'
>>
>> Then implement get( ) as:
>>
>> get <- function(x,...,value.if.not.found ) {
>>
>>   if( missing(value.if.not.found) ) {
>>     a <- getifexists(x,... )
>>     if (!a$found) error("x not found")
>>   } else {
>>     a <- getifexists(x,...,value.if.not.found )
>>   }
>>   return(a$value)
>> }
>>
>> Note that value.if.not.found has no default value in above.
>> It behaves exactly like current get does if value.if.not.found
>> is not specified, and if it is specified, it would be faster
>> in the common situation mentioned below:
>>      if(exists(x,...)) { get(x,...) }
>>
>> John
>>
>> P.S. if you like dromedaries call it valueIfNotFound ...
>>
>>  ..............................................................
>>  John P. Nolan
>>  Math/Stat Department
>>  227 Gray Hall,   American University
>>  4400 Massachusetts Avenue, NW
>>  Washington, DC 20016-8050
>>
>>  jpnolan at american.edu       voice: 202.885.3140
>>  web: academic2.american.edu/~jpnolan
>>  ..............................................................
>>
>>
>> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
>> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
>> From: Duncan Murdoch
>> Sent by: "R-devel"
>> Date: 01/08/2015 06:39AM
>> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>>
>> On 08/01/2015 4:16 AM, Martin Maechler wrote:
>> > In November, we had a "bug repository conversation"
>> > with Peter Hagerty and myself:
>> >
>> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
>> >
>> > where the bug report title started with
>> >
>> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
>> >
>> > Peter proposed an extra simplified and henc faster version of exists(),
>> > and I commented
>> >
>> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch>
>> ---
>> >     > I'm very grateful that you've started exploring the bottlenecks of
>> loading
>> >     > packages with many S4 classes (and methods)...
>> >     > and I hope we can make real progress there rather sooner than
>> later.
>> >
>> >     > OTOH, your `summaryRprof()` in your vignette indicates that
>> exists() may use
>> >     > upto 10% of the time spent in library(reportingTools),  and your
>> speedup
>> >     > proposals of exist()  may go up to ca 30%  which is good and well
>> worth
>> >     > considering,  but still we can only expect 2-3% speedup for
>> package loading
>> >     > which unfortunately is not much.
>> >
>> >     > Still I agree it is worth looking at exists() as you did  ... and
>> >     > consider providing a fast simplified version of it in addition to
>> current
>> >     > exists() [I think].
>> >
>> >     > BTW, as we talk about enhancements here, maybe consider a further
>> possibility:
>> >     > My subjective guess is that probably more than half of exists()
>> uses are of the
>> >     > form
>> >
>> >     > if(exists(name, where, .......)) {
>> >     >    get(name, whare, ....)
>> >     >    ..
>> >     > } else {
>> >     >     NULL / error() / .. or similar
>> >     > }
>> >
>> >     > i.e. many exists() calls when returning TRUE are immediately
>> followed by the
>> >     > corresponding get() call which repeats quite a bit of the lookup
>> that exists()
>> >     > has done.
>> >
>> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that
>> does both at
>> >     > once in the "exists is TRUE" case but in a way we can easily keep
>> the if(.) ..
>> >     > else clause above.  One already existing approach would use
>> >
>> >     > if(!inherits(tryCatch(xx <- get(name, where, ...),
>> error=function(e)e), "error")) {
>> >
>> >     >   ... (( work with xx )) ...
>> >
>> >     > } else  {
>> >     >    NULL / error() / .. or similar
>> >     > }
>> >
>> >     > but of course our C implementation would be more efficient and use
>> more concise
>> >     > syntax {which should not look like error handling}.   Follow ups
>> to this idea
>> >     > should really go to R-devel (the mailing list).
>> >
>> > and now I do follow up here myself :
>> >
>> > I found that  'getifexists()' is actually very simple to implement,
>> > I have already tested it a bit, but not yet committed to R-devel
>> > (the "R trunk" aka "master branch") because I'd like to get
>> > public comments {RFC := Request For Comments}.
>> >
>>
>> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
>> Journal) pointed out, R names are very inconsistent in naming
>> conventions, but lowerCamelCase is the most common choice.  Second most
>> common is period.separated, so an argument could be made for
>> get.if.exists, but there's still the possibility of confusion with S3
>> methods, and users of other languages where "." is an operator find it a
>> little strange.
>>
>> If you don't like lowerCamelCase (and a lot of people don't), then I
>> think underscore_separated is the next best choice, so would use
>> get_if_exists.
>>
>> Another possibility is to make no new name at all, and just add an
>> optional parameter to get() (which if present acts as your value.if.not
>> parameter, if not present keeps the current "object not found" error).
>>
>> Duncan Murdoch
>>
>>
>> > My version of the help file {for both exists() and getifexists()}
>> > rendered in text is
>> >
>> > ---------------------- help(getifexists) -------------------------------
>> > Is an Object Defined?
>> >
>> > Description:
>> >
>> >      Look for an R object of the given name and possibly return it
>> >
>> > Usage:
>> >
>> >      exists(x, where = -1, envir = , frame, mode = "any",
>> >             inherits = TRUE)
>> >
>> >      getifexists(x, where = -1, envir = as.environment(where),
>> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
>> >
>> > Arguments:
>> >
>> >        x: a variable name (given as a character string).
>> >
>> >    where: where to look for the object (see the details section); if
>> >           omitted, the function will search as if the name of the
>> >           object appeared unquoted in an expression.
>> >
>> >    envir: an alternative way to specify an environment to look in, but
>> >           it is usually simpler to just use the ?where? argument.
>> >
>> >    frame: a frame in the calling list.  Equivalent to giving ?where? as
>> >           ?sys.frame(frame)?.
>> >
>> >     mode: the mode or type of object sought: see the ?Details? section.
>> >
>> > inherits: should the enclosing frames of the environment be searched?
>> >
>> > value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
>> >           exist.
>> >
>> > Details:
>> >
>> >      The ?where? argument can specify the environment in which to look
>> >      for the object in any of several ways: as an integer (the position
>> >      in the ?search? list); as the character string name of an element
>> >      in the search list; or as an ?environment? (including using
>> >      ?sys.frame? to access the currently active function calls).  The
>> >      ?envir? argument is an alternative way to specify an environment,
>> >      but is primarily there for back compatibility.
>> >
>> >      This function looks to see if the name ?x? has a value bound to it
>> >      in the specified environment.  If ?inherits? is ?TRUE? and a value
>> >      is not found for ?x? in the specified environment, the enclosing
>> >      frames of the environment are searched until the name ?x? is
>> >      encountered.  See ?environment? and the ?R Language Definition?
>> >      manual for details about the structure of environments and their
>> >      enclosures.
>> >
>> >      *Warning:* ?inherits = TRUE? is the default behaviour for R but
>> >      not for S.
>> >
>> >      If ?mode? is specified then only objects of that type are sought.
>> >      The ?mode? may specify one of the collections ?"numeric"? and
>> >      ?"function"? (see ?mode?): any member of the collection will
>> >      suffice.  (This is true even if a member of a collection is
>> >      specified, so for example ?mode = "special"? will seek any type of
>> >      function.)
>> >
>> > Value:
>> >
>> >      ?exists():? Logical, true if and only if an object of the correct
>> >      name and mode is found.
>> >
>> >      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
>> >      is true, otherwise ?value.if.not?.
>> >
>> > Note:
>> >
>> >    With ?getifexists()?, instead of the easy to read but somewhat
>> >    inefficient
>> >
>> >        if (exists(myVarName, envir = myEnvir)) {
>> >          r <- get(myVarName, envir = myEnvir)
>> >          ## ... deal with r ...
>> >        }
>> >
>> >    you now can use the more efficient (and slightly harder to read)
>> >
>> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>> >          ## ... deal with r ...
>> >        }
>> >
>> > References:
>> >
>> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>> >      Language_.  Wadsworth & Brooks/Cole.
>> >
>> > See Also:
>> >
>> >      ?get?.  For quite a different kind of ?existence? checking, namely
>> >      if function arguments were specified, ?missing?; and for yet a
>> >      different kind, namely if a file exists, ?file.exists?.
>> >
>> > Examples:
>> >
>> >      ##  Define a substitute function if necessary:
>> >      if(!exists("some.fun", mode = "function"))
>> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>> >      search()
>> >      exists("ls", 2) # true even though ls is in pos = 3
>> >      exists("ls", 2, inherits = FALSE) # false
>> >
>> >      ## These are true (in most circumstances):
>> >      identical(ls,   getifexists("ls"))
>> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not =
>> NULL(!)
>> >
>> > ----------------- end[ help(getifexists) ] -----------------------------
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From jeroenooms at gmail.com  Thu Jan  8 21:52:54 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Thu, 8 Jan 2015 12:52:54 -0800
Subject: [Rd] Testing R packages on Solaris Studio
Message-ID: <CABFfbXvC0NbkOYUpopNP8BF5txio9Zw_KUtF1bWrMV0XEHq3rQ@mail.gmail.com>

I have setup a Solaris server to test packages before submitting to
CRAN, in order to catch problems that might not reveal themselves on
Fedora, Debian, OSX or Windows. The machine runs a Solaris 11.2 vm
with Solaris Studio 12.3.

I was able to compile current r-devel using the suggested environment
variables from "R Installation and Administration" and:

  ./configure --prefix=/opt/R-devel --with-blas='-library=sunperf' --with-lapack

All works great (fast too), except for some CRAN packages with c++
code won't build. The compiler itself works, most packages (including
e.g. MCMCpack) build OK. However packages like Rcpp and RJSONIO fail
with errors shown here:
https://gist.github.com/jeroenooms/f1b6a172320a32f59c82.

I tried installing with GNU make, but that does not seem to be the problem

  configure.vars = "MAKE=/opt/csw/bin/gmake"

I am aware that I can work around it by compiling with gcc instead of
solaris studio, but I would specifically like to replicate the setup
from CRAN.

Which additional args/vars/dependencies do I need to make Rcpp and
RJSONIO build as they do on the CRAN Solaris server?

> sessionInfo()
R Under development (unstable) (2015-01-07 r67351)
Platform: i386-pc-solaris2.11 (32-bit)
Running under: Solaris 11

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tcltk_3.2.0 tools_3.2.0


From jeroenooms at gmail.com  Thu Jan  8 22:21:53 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Thu, 8 Jan 2015 13:21:53 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <54AE95F1.1050402@gmail.com>
References: <54AE6C53.8030702@gmail.com>
	<bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<54AE95F1.1050402@gmail.com>
Message-ID: <CABFfbXuYMo9ejpfKqTmVp5hnuepYRW3smyauoQaofLCf0zMJeA@mail.gmail.com>

On Thu, Jan 8, 2015 at 6:36 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>
> That would be a bad idea, as it would change behaviour of existing uses of
> get().

Another approach would be if the "not found" behavior consists of a
callback, e.g. an expression or function:

  get(name, where, ..., not.found=stop("object ", name, " not found"))

This would cover the case of not.found=NULL, but also allows for
writing code with syntax similar to tryCatch

  obj <- get("foo", not.found = someDefaultValue())

Not sure what this would do to performance though.


From pdalgd at gmail.com  Thu Jan  8 22:30:47 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 8 Jan 2015 22:30:47 +0100
Subject: [Rd] setequal: better readability, reduced memory footprint,
	and minor speedup
In-Reply-To: <54AC4D67.7060302@fredhutch.org>
References: <54AC4D67.7060302@fredhutch.org>
Message-ID: <AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>

If you look at the definition of %in%, you'll find that it is implemented using match, so if we did as you suggest, I give it about three days before someone suggests to inline the function call... Readability of source code is not usually our prime concern.

The && idea does have some merit, though. 

Apropos, why is there no setcontains()?

-pd

> On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
> 
> Hi,
> 
> Current implementation:
> 
> setequal <- function (x, y)
> {
>  x <- as.vector(x)
>  y <- as.vector(y)
>  all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
> }
> 
> First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L) > 0L'
> with 'x %in% y' and 'y %in% x', respectively. They're strictly
> equivalent but the latter form is a lot more readable than the former
> (isn't this the "raison d'?tre" of %in%?):
> 
> setequal <- function (x, y)
> {
>  x <- as.vector(x)
>  y <- as.vector(y)
>  all(c(x %in% y, y %in% x))
> }
> 
> Furthermore, replacing 'all(c(x %in% y, y %in x))' with
> 'all(x %in% y) && all(y %in% x)' improves readability even more and,
> more importantly, reduces memory footprint significantly on big vectors
> (e.g. by 15% on integer vectors with 15M elements):
> 
> setequal <- function (x, y)
> {
>  x <- as.vector(x)
>  y <- as.vector(y)
>  all(x %in% y) && all(y %in% x)
> }
> 
> It also seems to speed up things a little bit (not in a significant
> way though).
> 
> Cheers,
> H.
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From haverty.peter at gene.com  Thu Jan  8 22:38:22 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 8 Jan 2015 13:38:22 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
Message-ID: <CAGh0NYoTCBhnfdjU-Dr-n8_C9YVYYL98OnHUKL1id-DzVgtioQ@mail.gmail.com>

For what it's worth, I think we would need a new function if the default
behavior changes.  Since we already have "get" and "mget", maybe "cget" for
"conditional get"?  "if get", "safe get", ...

I like the idea of keeping the original "not found" behavior if the
"if.not.found" arg is missing. However, it will be important to keep the
number of arguments down.  (I noticed that Martin's example lacks a "frame"
argument.)  I've heard rumors that there are plans to reduce the function
call overhead, so perhaps this matters less now.

I like Luke's idea of making exists/get/etc. .Primitives. I think that will
be necessary in order to go fast.  For my two cents, I also think
get/assign should just be synonyms for the "[[" .Primitive.  That could
actually simplify things a bit. One might add "inherits=FALSE" and
"if.not.found" arguments to the environment "[[" code, for example.

Regards,
Pete


Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:

> On Thu, 8 Jan 2015, Michael Lawrence wrote:
>
>  If we do add an argument to get(), then it should be named consistently
>> with the ifnotfound argument of mget(). As mentioned, the possibility of a
>> NULL value is problematic. One solution is a sentinel value that indicates
>> an unbound value (like R_UnboundValue).
>>
>
> A null default is fine -- it's a default; if it isn't right for a
> particular case you can provide something else.
>
>
>> But another idea (and one pretty similar to John's) is to follow the
>> SYMSXP
>> design at the C level, where there is a structure that points to the name
>> and a value. We already have SYMSXPs at the R level of course (name
>> objects) but they do not provide access to the value, which is typically
>> R_UnboundValue. But this does not even need to be implemented with SYMSXP.
>> The design would allow something like:
>>
>> binding <- getBinding("x", env)
>> if (hasValue(binding)) {
>>  x <- value(binding) # throws an error if none
>>  message(name(binding), "has value", x)
>> }
>>
>> That I think it is a bit verbose but readable and could be made fast. And
>> I
>> think binding objects would be useful in other ways, as they are
>> essentially a "named object". For example, when iterating over an
>> environment.
>>
>
> This would need a lot more thought. Directly exposing the internals is
> definitely not something we want to do as we may well want to change
> that design. But there are lots of other corner issues that would have
> to be thought through before going forward, such as what happens if an
> rm occurs between obtaining a binding object and doing something with
> it. Serialization would also need thinking through. This doesn't seem
> like a worthwhile place to spend our efforts to me.
>
> Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
> an argument to get() with missing giving current behavior may be OK
> too. Rewriting exists and get as .Primitives may be sufficient though.
>
> Best,
>
> luke
>
>
>  Michael
>>
>>
>>
>>
>> On Thu, Jan 8, 2015 at 6:03 AM, John Nolan <jpnolan at american.edu> wrote:
>>
>>  Adding an optional argument to get (and mget) like
>>>
>>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>>>
>>> would be useful for many.  HOWEVER, it is possible that there could be
>>> some confusion here: (*) can give a NULL because either x exists and
>>> has value NULL, or because x doesn't exist.   If that matters, the user
>>> would need to be careful about specifying a value.if.not.found that
>>> cannot
>>> be confused with a valid value of x.
>>>
>>> To avoid this difficulty, perhaps we want both: have Martin's
>>> getifexists(
>>> )
>>> return a list with two values:
>>>   - a boolean variable 'found'  # = value returned by exists( )
>>>   - a variable 'value'
>>>
>>> Then implement get( ) as:
>>>
>>> get <- function(x,...,value.if.not.found ) {
>>>
>>>   if( missing(value.if.not.found) ) {
>>>     a <- getifexists(x,... )
>>>     if (!a$found) error("x not found")
>>>   } else {
>>>     a <- getifexists(x,...,value.if.not.found )
>>>   }
>>>   return(a$value)
>>> }
>>>
>>> Note that value.if.not.found has no default value in above.
>>> It behaves exactly like current get does if value.if.not.found
>>> is not specified, and if it is specified, it would be faster
>>> in the common situation mentioned below:
>>>      if(exists(x,...)) { get(x,...) }
>>>
>>> John
>>>
>>> P.S. if you like dromedaries call it valueIfNotFound ...
>>>
>>>  ..............................................................
>>>  John P. Nolan
>>>  Math/Stat Department
>>>  227 Gray Hall,   American University
>>>  4400 Massachusetts Avenue, NW
>>>  Washington, DC 20016-8050
>>>
>>>  jpnolan at american.edu       voice: 202.885.3140
>>>  web: academic2.american.edu/~jpnolan
>>>  ..............................................................
>>>
>>>
>>> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
>>> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
>>> From: Duncan Murdoch
>>> Sent by: "R-devel"
>>> Date: 01/08/2015 06:39AM
>>> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>>>
>>> On 08/01/2015 4:16 AM, Martin Maechler wrote:
>>> > In November, we had a "bug repository conversation"
>>> > with Peter Hagerty and myself:
>>> >
>>> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
>>> >
>>> > where the bug report title started with
>>> >
>>> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
>>> >
>>> > Peter proposed an extra simplified and henc faster version of exists(),
>>> > and I commented
>>> >
>>> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch>
>>> ---
>>> >     > I'm very grateful that you've started exploring the bottlenecks
>>> of
>>> loading
>>> >     > packages with many S4 classes (and methods)...
>>> >     > and I hope we can make real progress there rather sooner than
>>> later.
>>> >
>>> >     > OTOH, your `summaryRprof()` in your vignette indicates that
>>> exists() may use
>>> >     > upto 10% of the time spent in library(reportingTools),  and your
>>> speedup
>>> >     > proposals of exist()  may go up to ca 30%  which is good and well
>>> worth
>>> >     > considering,  but still we can only expect 2-3% speedup for
>>> package loading
>>> >     > which unfortunately is not much.
>>> >
>>> >     > Still I agree it is worth looking at exists() as you did  ... and
>>> >     > consider providing a fast simplified version of it in addition to
>>> current
>>> >     > exists() [I think].
>>> >
>>> >     > BTW, as we talk about enhancements here, maybe consider a further
>>> possibility:
>>> >     > My subjective guess is that probably more than half of exists()
>>> uses are of the
>>> >     > form
>>> >
>>> >     > if(exists(name, where, .......)) {
>>> >     >    get(name, whare, ....)
>>> >     >    ..
>>> >     > } else {
>>> >     >     NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > i.e. many exists() calls when returning TRUE are immediately
>>> followed by the
>>> >     > corresponding get() call which repeats quite a bit of the lookup
>>> that exists()
>>> >     > has done.
>>> >
>>> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that
>>> does both at
>>> >     > once in the "exists is TRUE" case but in a way we can easily keep
>>> the if(.) ..
>>> >     > else clause above.  One already existing approach would use
>>> >
>>> >     > if(!inherits(tryCatch(xx <- get(name, where, ...),
>>> error=function(e)e), "error")) {
>>> >
>>> >     >   ... (( work with xx )) ...
>>> >
>>> >     > } else  {
>>> >     >    NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > but of course our C implementation would be more efficient and
>>> use
>>> more concise
>>> >     > syntax {which should not look like error handling}.   Follow ups
>>> to this idea
>>> >     > should really go to R-devel (the mailing list).
>>> >
>>> > and now I do follow up here myself :
>>> >
>>> > I found that  'getifexists()' is actually very simple to implement,
>>> > I have already tested it a bit, but not yet committed to R-devel
>>> > (the "R trunk" aka "master branch") because I'd like to get
>>> > public comments {RFC := Request For Comments}.
>>> >
>>>
>>> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
>>> Journal) pointed out, R names are very inconsistent in naming
>>> conventions, but lowerCamelCase is the most common choice.  Second most
>>> common is period.separated, so an argument could be made for
>>> get.if.exists, but there's still the possibility of confusion with S3
>>> methods, and users of other languages where "." is an operator find it a
>>> little strange.
>>>
>>> If you don't like lowerCamelCase (and a lot of people don't), then I
>>> think underscore_separated is the next best choice, so would use
>>> get_if_exists.
>>>
>>> Another possibility is to make no new name at all, and just add an
>>> optional parameter to get() (which if present acts as your value.if.not
>>> parameter, if not present keeps the current "object not found" error).
>>>
>>> Duncan Murdoch
>>>
>>>
>>> > My version of the help file {for both exists() and getifexists()}
>>> > rendered in text is
>>> >
>>> > ---------------------- help(getifexists) ------------------------------
>>> -
>>> > Is an Object Defined?
>>> >
>>> > Description:
>>> >
>>> >      Look for an R object of the given name and possibly return it
>>> >
>>> > Usage:
>>> >
>>> >      exists(x, where = -1, envir = , frame, mode = "any",
>>> >             inherits = TRUE)
>>> >
>>> >      getifexists(x, where = -1, envir = as.environment(where),
>>> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
>>> >
>>> > Arguments:
>>> >
>>> >        x: a variable name (given as a character string).
>>> >
>>> >    where: where to look for the object (see the details section); if
>>> >           omitted, the function will search as if the name of the
>>> >           object appeared unquoted in an expression.
>>> >
>>> >    envir: an alternative way to specify an environment to look in, but
>>> >           it is usually simpler to just use the 'where' argument.
>>> >
>>> >    frame: a frame in the calling list.  Equivalent to giving 'where' as
>>> >           'sys.frame(frame)'.
>>> >
>>> >     mode: the mode or type of object sought: see the 'Details' section.
>>> >
>>> > inherits: should the enclosing frames of the environment be searched?
>>> >
>>> > value.if.not: the return value of 'getifexists(x, *)' when 'x' does not
>>> >           exist.
>>> >
>>> > Details:
>>> >
>>> >      The 'where' argument can specify the environment in which to look
>>> >      for the object in any of several ways: as an integer (the position
>>> >      in the 'search' list); as the character string name of an element
>>> >      in the search list; or as an 'environment' (including using
>>> >      'sys.frame' to access the currently active function calls).  The
>>> >      'envir' argument is an alternative way to specify an environment,
>>> >      but is primarily there for back compatibility.
>>> >
>>> >      This function looks to see if the name 'x' has a value bound to it
>>> >      in the specified environment.  If 'inherits' is 'TRUE' and a value
>>> >      is not found for 'x' in the specified environment, the enclosing
>>> >      frames of the environment are searched until the name 'x' is
>>> >      encountered.  See 'environment' and the 'R Language Definition'
>>> >      manual for details about the structure of environments and their
>>> >      enclosures.
>>> >
>>> >      *Warning:* 'inherits = TRUE' is the default behaviour for R but
>>> >      not for S.
>>> >
>>> >      If 'mode' is specified then only objects of that type are sought.
>>> >      The 'mode' may specify one of the collections '"numeric"' and
>>> >      '"function"' (see 'mode'): any member of the collection will
>>> >      suffice.  (This is true even if a member of a collection is
>>> >      specified, so for example 'mode = "special"' will seek any type of
>>> >      function.)
>>> >
>>> > Value:
>>> >
>>> >      'exists():' Logical, true if and only if an object of the correct
>>> >      name and mode is found.
>>> >
>>> >      'getifexists():' The object-as from 'get(x, *)'- if 'exists(x, *)'
>>> >      is true, otherwise 'value.if.not'.
>>> >
>>> > Note:
>>> >
>>> >    With 'getifexists()', instead of the easy to read but somewhat
>>> >    inefficient
>>> >
>>> >        if (exists(myVarName, envir = myEnvir)) {
>>> >          r <- get(myVarName, envir = myEnvir)
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> >    you now can use the more efficient (and slightly harder to read)
>>> >
>>> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> > References:
>>> >
>>> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>>> >      Language_.  Wadsworth & Brooks/Cole.
>>> >
>>> > See Also:
>>> >
>>> >      'get'.  For quite a different kind of "existence" checking, namely
>>> >      if function arguments were specified, 'missing'; and for yet a
>>> >      different kind, namely if a file exists, 'file.exists'.
>>> >
>>> > Examples:
>>> >
>>> >      ##  Define a substitute function if necessary:
>>> >      if(!exists("some.fun", mode = "function"))
>>> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>>> >      search()
>>> >      exists("ls", 2) # true even though ls is in pos = 3
>>> >      exists("ls", 2, inherits = FALSE) # false
>>> >
>>> >      ## These are true (in most circumstances):
>>> >      identical(ls,   getifexists("ls"))
>>> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not =
>>> NULL(!)
>>> >
>>> > ----------------- end[ help(getifexists) ]
>>> -----------------------------
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Thu Jan  8 22:44:56 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 8 Jan 2015 13:44:56 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
Message-ID: <CAGh0NYpg7q8zBhVvHJ9OJcJy4E1nuOqChEBj0J1u73ddXht57A@mail.gmail.com>

Michael's idea has an interesting bonus that he and I discussed earlier.
It would be very convenient to have a container of key/value pairs.  I
imagine many people often write this:

x - mapply( names(x), x, FUN=function(k,v) { # work with key and value }

especially ex perl people accustomed to

while ( ($key, $value) = each( some_hash ) { }

Perhaps there is room for additional discussion of using lists of SYMSXPs
in this manner. (If SYMSXPs are not that safe, perhaps a looping construct
for named vectors that gave the illusion iterating over a list of
two-tuples.)



Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:

> On Thu, 8 Jan 2015, Michael Lawrence wrote:
>
>  If we do add an argument to get(), then it should be named consistently
>> with the ifnotfound argument of mget(). As mentioned, the possibility of a
>> NULL value is problematic. One solution is a sentinel value that indicates
>> an unbound value (like R_UnboundValue).
>>
>
> A null default is fine -- it's a default; if it isn't right for a
> particular case you can provide something else.
>
>
>> But another idea (and one pretty similar to John's) is to follow the
>> SYMSXP
>> design at the C level, where there is a structure that points to the name
>> and a value. We already have SYMSXPs at the R level of course (name
>> objects) but they do not provide access to the value, which is typically
>> R_UnboundValue. But this does not even need to be implemented with SYMSXP.
>> The design would allow something like:
>>
>> binding <- getBinding("x", env)
>> if (hasValue(binding)) {
>>  x <- value(binding) # throws an error if none
>>  message(name(binding), "has value", x)
>> }
>>
>> That I think it is a bit verbose but readable and could be made fast. And
>> I
>> think binding objects would be useful in other ways, as they are
>> essentially a "named object". For example, when iterating over an
>> environment.
>>
>
> This would need a lot more thought. Directly exposing the internals is
> definitely not something we want to do as we may well want to change
> that design. But there are lots of other corner issues that would have
> to be thought through before going forward, such as what happens if an
> rm occurs between obtaining a binding object and doing something with
> it. Serialization would also need thinking through. This doesn't seem
> like a worthwhile place to spend our efforts to me.
>
> Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
> an argument to get() with missing giving current behavior may be OK
> too. Rewriting exists and get as .Primitives may be sufficient though.
>
> Best,
>
> luke
>
>
>  Michael
>>
>>
>>
>>
>> On Thu, Jan 8, 2015 at 6:03 AM, John Nolan <jpnolan at american.edu> wrote:
>>
>>  Adding an optional argument to get (and mget) like
>>>
>>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>>>
>>> would be useful for many.  HOWEVER, it is possible that there could be
>>> some confusion here: (*) can give a NULL because either x exists and
>>> has value NULL, or because x doesn't exist.   If that matters, the user
>>> would need to be careful about specifying a value.if.not.found that
>>> cannot
>>> be confused with a valid value of x.
>>>
>>> To avoid this difficulty, perhaps we want both: have Martin's
>>> getifexists(
>>> )
>>> return a list with two values:
>>>   - a boolean variable 'found'  # = value returned by exists( )
>>>   - a variable 'value'
>>>
>>> Then implement get( ) as:
>>>
>>> get <- function(x,...,value.if.not.found ) {
>>>
>>>   if( missing(value.if.not.found) ) {
>>>     a <- getifexists(x,... )
>>>     if (!a$found) error("x not found")
>>>   } else {
>>>     a <- getifexists(x,...,value.if.not.found )
>>>   }
>>>   return(a$value)
>>> }
>>>
>>> Note that value.if.not.found has no default value in above.
>>> It behaves exactly like current get does if value.if.not.found
>>> is not specified, and if it is specified, it would be faster
>>> in the common situation mentioned below:
>>>      if(exists(x,...)) { get(x,...) }
>>>
>>> John
>>>
>>> P.S. if you like dromedaries call it valueIfNotFound ...
>>>
>>>  ..............................................................
>>>  John P. Nolan
>>>  Math/Stat Department
>>>  227 Gray Hall,   American University
>>>  4400 Massachusetts Avenue, NW
>>>  Washington, DC 20016-8050
>>>
>>>  jpnolan at american.edu       voice: 202.885.3140
>>>  web: academic2.american.edu/~jpnolan
>>>  ..............................................................
>>>
>>>
>>> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
>>> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
>>> From: Duncan Murdoch
>>> Sent by: "R-devel"
>>> Date: 01/08/2015 06:39AM
>>> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>>>
>>> On 08/01/2015 4:16 AM, Martin Maechler wrote:
>>> > In November, we had a "bug repository conversation"
>>> > with Peter Hagerty and myself:
>>> >
>>> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
>>> >
>>> > where the bug report title started with
>>> >
>>> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
>>> >
>>> > Peter proposed an extra simplified and henc faster version of exists(),
>>> > and I commented
>>> >
>>> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch>
>>> ---
>>> >     > I'm very grateful that you've started exploring the bottlenecks
>>> of
>>> loading
>>> >     > packages with many S4 classes (and methods)...
>>> >     > and I hope we can make real progress there rather sooner than
>>> later.
>>> >
>>> >     > OTOH, your `summaryRprof()` in your vignette indicates that
>>> exists() may use
>>> >     > upto 10% of the time spent in library(reportingTools),  and your
>>> speedup
>>> >     > proposals of exist()  may go up to ca 30%  which is good and well
>>> worth
>>> >     > considering,  but still we can only expect 2-3% speedup for
>>> package loading
>>> >     > which unfortunately is not much.
>>> >
>>> >     > Still I agree it is worth looking at exists() as you did  ... and
>>> >     > consider providing a fast simplified version of it in addition to
>>> current
>>> >     > exists() [I think].
>>> >
>>> >     > BTW, as we talk about enhancements here, maybe consider a further
>>> possibility:
>>> >     > My subjective guess is that probably more than half of exists()
>>> uses are of the
>>> >     > form
>>> >
>>> >     > if(exists(name, where, .......)) {
>>> >     >    get(name, whare, ....)
>>> >     >    ..
>>> >     > } else {
>>> >     >     NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > i.e. many exists() calls when returning TRUE are immediately
>>> followed by the
>>> >     > corresponding get() call which repeats quite a bit of the lookup
>>> that exists()
>>> >     > has done.
>>> >
>>> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that
>>> does both at
>>> >     > once in the "exists is TRUE" case but in a way we can easily keep
>>> the if(.) ..
>>> >     > else clause above.  One already existing approach would use
>>> >
>>> >     > if(!inherits(tryCatch(xx <- get(name, where, ...),
>>> error=function(e)e), "error")) {
>>> >
>>> >     >   ... (( work with xx )) ...
>>> >
>>> >     > } else  {
>>> >     >    NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > but of course our C implementation would be more efficient and
>>> use
>>> more concise
>>> >     > syntax {which should not look like error handling}.   Follow ups
>>> to this idea
>>> >     > should really go to R-devel (the mailing list).
>>> >
>>> > and now I do follow up here myself :
>>> >
>>> > I found that  'getifexists()' is actually very simple to implement,
>>> > I have already tested it a bit, but not yet committed to R-devel
>>> > (the "R trunk" aka "master branch") because I'd like to get
>>> > public comments {RFC := Request For Comments}.
>>> >
>>>
>>> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
>>> Journal) pointed out, R names are very inconsistent in naming
>>> conventions, but lowerCamelCase is the most common choice.  Second most
>>> common is period.separated, so an argument could be made for
>>> get.if.exists, but there's still the possibility of confusion with S3
>>> methods, and users of other languages where "." is an operator find it a
>>> little strange.
>>>
>>> If you don't like lowerCamelCase (and a lot of people don't), then I
>>> think underscore_separated is the next best choice, so would use
>>> get_if_exists.
>>>
>>> Another possibility is to make no new name at all, and just add an
>>> optional parameter to get() (which if present acts as your value.if.not
>>> parameter, if not present keeps the current "object not found" error).
>>>
>>> Duncan Murdoch
>>>
>>>
>>> > My version of the help file {for both exists() and getifexists()}
>>> > rendered in text is
>>> >
>>> > ---------------------- help(getifexists) ------------------------------
>>> -
>>> > Is an Object Defined?
>>> >
>>> > Description:
>>> >
>>> >      Look for an R object of the given name and possibly return it
>>> >
>>> > Usage:
>>> >
>>> >      exists(x, where = -1, envir = , frame, mode = "any",
>>> >             inherits = TRUE)
>>> >
>>> >      getifexists(x, where = -1, envir = as.environment(where),
>>> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
>>> >
>>> > Arguments:
>>> >
>>> >        x: a variable name (given as a character string).
>>> >
>>> >    where: where to look for the object (see the details section); if
>>> >           omitted, the function will search as if the name of the
>>> >           object appeared unquoted in an expression.
>>> >
>>> >    envir: an alternative way to specify an environment to look in, but
>>> >           it is usually simpler to just use the 'where' argument.
>>> >
>>> >    frame: a frame in the calling list.  Equivalent to giving 'where' as
>>> >           'sys.frame(frame)'.
>>> >
>>> >     mode: the mode or type of object sought: see the 'Details' section.
>>> >
>>> > inherits: should the enclosing frames of the environment be searched?
>>> >
>>> > value.if.not: the return value of 'getifexists(x, *)' when 'x' does not
>>> >           exist.
>>> >
>>> > Details:
>>> >
>>> >      The 'where' argument can specify the environment in which to look
>>> >      for the object in any of several ways: as an integer (the position
>>> >      in the 'search' list); as the character string name of an element
>>> >      in the search list; or as an 'environment' (including using
>>> >      'sys.frame' to access the currently active function calls).  The
>>> >      'envir' argument is an alternative way to specify an environment,
>>> >      but is primarily there for back compatibility.
>>> >
>>> >      This function looks to see if the name 'x' has a value bound to it
>>> >      in the specified environment.  If 'inherits' is 'TRUE' and a value
>>> >      is not found for 'x' in the specified environment, the enclosing
>>> >      frames of the environment are searched until the name 'x' is
>>> >      encountered.  See 'environment' and the 'R Language Definition'
>>> >      manual for details about the structure of environments and their
>>> >      enclosures.
>>> >
>>> >      *Warning:* 'inherits = TRUE' is the default behaviour for R but
>>> >      not for S.
>>> >
>>> >      If 'mode' is specified then only objects of that type are sought.
>>> >      The 'mode' may specify one of the collections '"numeric"' and
>>> >      '"function"' (see 'mode'): any member of the collection will
>>> >      suffice.  (This is true even if a member of a collection is
>>> >      specified, so for example 'mode = "special"' will seek any type of
>>> >      function.)
>>> >
>>> > Value:
>>> >
>>> >      'exists():' Logical, true if and only if an object of the correct
>>> >      name and mode is found.
>>> >
>>> >      'getifexists():' The object-as from 'get(x, *)'- if 'exists(x, *)'
>>> >      is true, otherwise 'value.if.not'.
>>> >
>>> > Note:
>>> >
>>> >    With 'getifexists()', instead of the easy to read but somewhat
>>> >    inefficient
>>> >
>>> >        if (exists(myVarName, envir = myEnvir)) {
>>> >          r <- get(myVarName, envir = myEnvir)
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> >    you now can use the more efficient (and slightly harder to read)
>>> >
>>> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> > References:
>>> >
>>> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>>> >      Language_.  Wadsworth & Brooks/Cole.
>>> >
>>> > See Also:
>>> >
>>> >      'get'.  For quite a different kind of "existence" checking, namely
>>> >      if function arguments were specified, 'missing'; and for yet a
>>> >      different kind, namely if a file exists, 'file.exists'.
>>> >
>>> > Examples:
>>> >
>>> >      ##  Define a substitute function if necessary:
>>> >      if(!exists("some.fun", mode = "function"))
>>> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>>> >      search()
>>> >      exists("ls", 2) # true even though ls is in pos = 3
>>> >      exists("ls", 2, inherits = FALSE) # false
>>> >
>>> >      ## These are true (in most circumstances):
>>> >      identical(ls,   getifexists("ls"))
>>> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not =
>>> NULL(!)
>>> >
>>> > ----------------- end[ help(getifexists) ]
>>> -----------------------------
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan  8 23:02:26 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 8 Jan 2015 14:02:26 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
Message-ID: <CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>

On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:

> On Thu, 8 Jan 2015, Michael Lawrence wrote:
>
>  If we do add an argument to get(), then it should be named consistently
>> with the ifnotfound argument of mget(). As mentioned, the possibility of a
>> NULL value is problematic. One solution is a sentinel value that indicates
>> an unbound value (like R_UnboundValue).
>>
>
> A null default is fine -- it's a default; if it isn't right for a
> particular case you can provide something else.
>
>
>> But another idea (and one pretty similar to John's) is to follow the
>> SYMSXP
>> design at the C level, where there is a structure that points to the name
>> and a value. We already have SYMSXPs at the R level of course (name
>> objects) but they do not provide access to the value, which is typically
>> R_UnboundValue. But this does not even need to be implemented with SYMSXP.
>> The design would allow something like:
>>
>> binding <- getBinding("x", env)
>> if (hasValue(binding)) {
>>  x <- value(binding) # throws an error if none
>>  message(name(binding), "has value", x)
>> }
>>
>> That I think it is a bit verbose but readable and could be made fast. And
>> I
>> think binding objects would be useful in other ways, as they are
>> essentially a "named object". For example, when iterating over an
>> environment.
>>
>
> This would need a lot more thought. Directly exposing the internals is
> definitely not something we want to do as we may well want to change
> that design. But there are lots of other corner issues that would have
> to be thought through before going forward, such as what happens if an
> rm occurs between obtaining a binding object and doing something with
> it. Serialization would also need thinking through. This doesn't seem
> like a worthwhile place to spend our efforts to me.
>
>

Just wanted to be clear that I was not suggesting to expose any internals.
We could implement the behavior using SYMSXP, or not. Nor would the binding
need to be mutable. The binding would be considered independent of the
environment from which it was retrieved. As Pete has mentioned, it could be
a useful abstraction to have in general.


> Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
> an argument to get() with missing giving current behavior may be OK
> too. Rewriting exists and get as .Primitives may be sufficient though.
>
> Best,
>
> luke
>
>
>  Michael
>>
>>
>>
>>
>> On Thu, Jan 8, 2015 at 6:03 AM, John Nolan <jpnolan at american.edu> wrote:
>>
>>  Adding an optional argument to get (and mget) like
>>>
>>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>>>
>>> would be useful for many.  HOWEVER, it is possible that there could be
>>> some confusion here: (*) can give a NULL because either x exists and
>>> has value NULL, or because x doesn't exist.   If that matters, the user
>>> would need to be careful about specifying a value.if.not.found that
>>> cannot
>>> be confused with a valid value of x.
>>>
>>> To avoid this difficulty, perhaps we want both: have Martin's
>>> getifexists(
>>> )
>>> return a list with two values:
>>>   - a boolean variable 'found'  # = value returned by exists( )
>>>   - a variable 'value'
>>>
>>> Then implement get( ) as:
>>>
>>> get <- function(x,...,value.if.not.found ) {
>>>
>>>   if( missing(value.if.not.found) ) {
>>>     a <- getifexists(x,... )
>>>     if (!a$found) error("x not found")
>>>   } else {
>>>     a <- getifexists(x,...,value.if.not.found )
>>>   }
>>>   return(a$value)
>>> }
>>>
>>> Note that value.if.not.found has no default value in above.
>>> It behaves exactly like current get does if value.if.not.found
>>> is not specified, and if it is specified, it would be faster
>>> in the common situation mentioned below:
>>>      if(exists(x,...)) { get(x,...) }
>>>
>>> John
>>>
>>> P.S. if you like dromedaries call it valueIfNotFound ...
>>>
>>>  ..............................................................
>>>  John P. Nolan
>>>  Math/Stat Department
>>>  227 Gray Hall,   American University
>>>  4400 Massachusetts Avenue, NW
>>>  Washington, DC 20016-8050
>>>
>>>  jpnolan at american.edu       voice: 202.885.3140
>>>  web: academic2.american.edu/~jpnolan
>>>  ..............................................................
>>>
>>>
>>> -----"R-devel" <r-devel-bounces at r-project.org> wrote: -----
>>> To: Martin Maechler <maechler at stat.math.ethz.ch>, R-devel at r-project.org
>>> From: Duncan Murdoch
>>> Sent by: "R-devel"
>>> Date: 01/08/2015 06:39AM
>>> Subject: Re: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
>>>
>>> On 08/01/2015 4:16 AM, Martin Maechler wrote:
>>> > In November, we had a "bug repository conversation"
>>> > with Peter Hagerty and myself:
>>> >
>>> >   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16065
>>> >
>>> > where the bug report title started with
>>> >
>>> >  --->>  "exists" is a bottleneck for dispatch and package loading, ...
>>> >
>>> > Peter proposed an extra simplified and henc faster version of exists(),
>>> > and I commented
>>> >
>>> >     > --- Comment #2 from Martin Maechler <maechler at stat.math.ethz.ch>
>>> ---
>>> >     > I'm very grateful that you've started exploring the bottlenecks
>>> of
>>> loading
>>> >     > packages with many S4 classes (and methods)...
>>> >     > and I hope we can make real progress there rather sooner than
>>> later.
>>> >
>>> >     > OTOH, your `summaryRprof()` in your vignette indicates that
>>> exists() may use
>>> >     > upto 10% of the time spent in library(reportingTools),  and your
>>> speedup
>>> >     > proposals of exist()  may go up to ca 30%  which is good and well
>>> worth
>>> >     > considering,  but still we can only expect 2-3% speedup for
>>> package loading
>>> >     > which unfortunately is not much.
>>> >
>>> >     > Still I agree it is worth looking at exists() as you did  ... and
>>> >     > consider providing a fast simplified version of it in addition to
>>> current
>>> >     > exists() [I think].
>>> >
>>> >     > BTW, as we talk about enhancements here, maybe consider a further
>>> possibility:
>>> >     > My subjective guess is that probably more than half of exists()
>>> uses are of the
>>> >     > form
>>> >
>>> >     > if(exists(name, where, .......)) {
>>> >     >    get(name, whare, ....)
>>> >     >    ..
>>> >     > } else {
>>> >     >     NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > i.e. many exists() calls when returning TRUE are immediately
>>> followed by the
>>> >     > corresponding get() call which repeats quite a bit of the lookup
>>> that exists()
>>> >     > has done.
>>> >
>>> >     > Instead, I'd imagine a function, say  getifexists(name, ...) that
>>> does both at
>>> >     > once in the "exists is TRUE" case but in a way we can easily keep
>>> the if(.) ..
>>> >     > else clause above.  One already existing approach would use
>>> >
>>> >     > if(!inherits(tryCatch(xx <- get(name, where, ...),
>>> error=function(e)e), "error")) {
>>> >
>>> >     >   ... (( work with xx )) ...
>>> >
>>> >     > } else  {
>>> >     >    NULL / error() / .. or similar
>>> >     > }
>>> >
>>> >     > but of course our C implementation would be more efficient and
>>> use
>>> more concise
>>> >     > syntax {which should not look like error handling}.   Follow ups
>>> to this idea
>>> >     > should really go to R-devel (the mailing list).
>>> >
>>> > and now I do follow up here myself :
>>> >
>>> > I found that  'getifexists()' is actually very simple to implement,
>>> > I have already tested it a bit, but not yet committed to R-devel
>>> > (the "R trunk" aka "master branch") because I'd like to get
>>> > public comments {RFC := Request For Comments}.
>>> >
>>>
>>> I don't like the name -- I'd prefer getIfExists.  As Baath (2012, R
>>> Journal) pointed out, R names are very inconsistent in naming
>>> conventions, but lowerCamelCase is the most common choice.  Second most
>>> common is period.separated, so an argument could be made for
>>> get.if.exists, but there's still the possibility of confusion with S3
>>> methods, and users of other languages where "." is an operator find it a
>>> little strange.
>>>
>>> If you don't like lowerCamelCase (and a lot of people don't), then I
>>> think underscore_separated is the next best choice, so would use
>>> get_if_exists.
>>>
>>> Another possibility is to make no new name at all, and just add an
>>> optional parameter to get() (which if present acts as your value.if.not
>>> parameter, if not present keeps the current "object not found" error).
>>>
>>> Duncan Murdoch
>>>
>>>
>>> > My version of the help file {for both exists() and getifexists()}
>>> > rendered in text is
>>> >
>>> > ---------------------- help(getifexists) ------------------------------
>>> -
>>> > Is an Object Defined?
>>> >
>>> > Description:
>>> >
>>> >      Look for an R object of the given name and possibly return it
>>> >
>>> > Usage:
>>> >
>>> >      exists(x, where = -1, envir = , frame, mode = "any",
>>> >             inherits = TRUE)
>>> >
>>> >      getifexists(x, where = -1, envir = as.environment(where),
>>> >                  mode = "any", inherits = TRUE, value.if.not = NULL)
>>> >
>>> > Arguments:
>>> >
>>> >        x: a variable name (given as a character string).
>>> >
>>> >    where: where to look for the object (see the details section); if
>>> >           omitted, the function will search as if the name of the
>>> >           object appeared unquoted in an expression.
>>> >
>>> >    envir: an alternative way to specify an environment to look in, but
>>> >           it is usually simpler to just use the ?where? argument.
>>> >
>>> >    frame: a frame in the calling list.  Equivalent to giving ?where? as
>>> >           ?sys.frame(frame)?.
>>> >
>>> >     mode: the mode or type of object sought: see the ?Details? section.
>>> >
>>> > inherits: should the enclosing frames of the environment be searched?
>>> >
>>> > value.if.not: the return value of ?getifexists(x, *)? when ?x? does not
>>> >           exist.
>>> >
>>> > Details:
>>> >
>>> >      The ?where? argument can specify the environment in which to look
>>> >      for the object in any of several ways: as an integer (the position
>>> >      in the ?search? list); as the character string name of an element
>>> >      in the search list; or as an ?environment? (including using
>>> >      ?sys.frame? to access the currently active function calls).  The
>>> >      ?envir? argument is an alternative way to specify an environment,
>>> >      but is primarily there for back compatibility.
>>> >
>>> >      This function looks to see if the name ?x? has a value bound to it
>>> >      in the specified environment.  If ?inherits? is ?TRUE? and a value
>>> >      is not found for ?x? in the specified environment, the enclosing
>>> >      frames of the environment are searched until the name ?x? is
>>> >      encountered.  See ?environment? and the ?R Language Definition?
>>> >      manual for details about the structure of environments and their
>>> >      enclosures.
>>> >
>>> >      *Warning:* ?inherits = TRUE? is the default behaviour for R but
>>> >      not for S.
>>> >
>>> >      If ?mode? is specified then only objects of that type are sought.
>>> >      The ?mode? may specify one of the collections ?"numeric"? and
>>> >      ?"function"? (see ?mode?): any member of the collection will
>>> >      suffice.  (This is true even if a member of a collection is
>>> >      specified, so for example ?mode = "special"? will seek any type of
>>> >      function.)
>>> >
>>> > Value:
>>> >
>>> >      ?exists():? Logical, true if and only if an object of the correct
>>> >      name and mode is found.
>>> >
>>> >      ?getifexists():? The object-as from ?get(x, *)?- if ?exists(x, *)?
>>> >      is true, otherwise ?value.if.not?.
>>> >
>>> > Note:
>>> >
>>> >    With ?getifexists()?, instead of the easy to read but somewhat
>>> >    inefficient
>>> >
>>> >        if (exists(myVarName, envir = myEnvir)) {
>>> >          r <- get(myVarName, envir = myEnvir)
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> >    you now can use the more efficient (and slightly harder to read)
>>> >
>>> >        if (!is.null(r <- getifexists(myVarName, envir = myEnvir))) {
>>> >          ## ... deal with r ...
>>> >        }
>>> >
>>> > References:
>>> >
>>> >      Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S
>>> >      Language_.  Wadsworth & Brooks/Cole.
>>> >
>>> > See Also:
>>> >
>>> >      ?get?.  For quite a different kind of ?existence? checking, namely
>>> >      if function arguments were specified, ?missing?; and for yet a
>>> >      different kind, namely if a file exists, ?file.exists?.
>>> >
>>> > Examples:
>>> >
>>> >      ##  Define a substitute function if necessary:
>>> >      if(!exists("some.fun", mode = "function"))
>>> >        some.fun <- function(x) { cat("some.fun(x)\n"); x }
>>> >      search()
>>> >      exists("ls", 2) # true even though ls is in pos = 3
>>> >      exists("ls", 2, inherits = FALSE) # false
>>> >
>>> >      ## These are true (in most circumstances):
>>> >      identical(ls,   getifexists("ls"))
>>> >      identical(NULL, getifexists(".foo.bar.")) # default value.if.not =
>>> NULL(!)
>>> >
>>> > ----------------- end[ help(getifexists) ]
>>> -----------------------------
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Thu Jan  8 23:18:27 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 8 Jan 2015 17:18:27 -0500
Subject: [Rd] latex warning
Message-ID: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>

Dear all,

I am getting an R CMD check warning about the PDF manual. I am having a
hard time finding out what is wrong, here is the log of the Rd2pdf call.

The full check (and other) log is at
https://api.travis-ci.org/jobs/46373922/log.txt?deansi=true if anybody is
interested, and the package itself is here:
https://github.com/metacran/r-builder/tree/bintex/rbuildertest

Thanks, Best,
Gabor


+cat ./rbuildertest.Rcheck/Rdlatex.log
Hmm ... looks like a package
This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (preloaded
format=pdflatex)
 restricted \write18 enabled.

kpathsea: Running mktexfmt pdflatex.fmt
fmtutil: running `pdftex -ini   -jobname=pdflatex -progname=pdflatex
-translate-file=cp227.tcx *pdflatex.ini' ...
This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (INITEX)
 restricted \write18 enabled.
 (/home/travis/R-bin/texlive/texmf-dist/web2c/cp227.tcx)
entering extended mode
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/latexconfig/pdflatex.ini
(/home/travis/R-bin/texlive/texmf-config/tex/generic/config/pdftexconfig.tex)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latex.ltx
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/texsys.cfg)
./texsys.aux found


\@currdir set to: ./.


Assuming \openin and \input
have the same search path.


Defining UNIX/DOS style filename parser.

catcodes, registers, compatibility for TeX 2,  parameters,
LaTeX2e <2014/05/01>
hacks, control, par, spacing, files, font encodings, lengths,
====================================

Local config file fonttext.cfg used

====================================
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fonttext.cfg
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fonttext.ltx
=== Don't modify this file, use a .cfg file instead ===

(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omlenc.def)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.def)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.def)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1cmr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmss.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmtt.fd)))
====================================

Local config file fontmath.cfg used

====================================
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontmath.cfg
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontmath.ltx
=== Don't modify this file, use a .cfg file instead ===

(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omlcmm.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omscmsy.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omxcmex.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ucmr.fd)))
====================================

Local config file preload.cfg used

=====================================
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/preload.cfg
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/preload.ltx)) page
nos.,
x-ref, environments, center, verbatim, math definitions, boxes, title,
sectioning, contents, floats, footnotes, index, bibliography, output,
===========================================
Local configuration file hyphen.cfg used
===========================================
(/home/travis/R-bin/texlive/texmf-dist/tex/generic/babel/hyphen.cfg
(/home/travis/R-bin/texlive/texmf-dist/tex/generic/babel/switch.def)
(/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/hyphen.tex)
(/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/dumyhyph.tex)
(/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/zerohyph.tex))
=================================
Applying patch file ltpatch.ltx
=================================
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ltpatch.ltx)
 ) )
Beginning to dump on file pdflatex.fmt
 (preloaded format=pdflatex 2015.1.8)
4976 strings of total length 68991
45099 memory locations dumped; current usage is 144&43215
3320 multiletter control sequences
\font\nullfont=nullfont
\font\OMX/cmex/m/n/10=cmex10
\font\tenln=line10
\font\tenlnw=linew10
\font\tencirc=lcircle10
\font\tencircw=lcirclew10
\font\OT1/cmr/m/n/5=cmr5
\font\OT1/cmr/m/n/7=cmr7
\font\OT1/cmr/m/n/10=cmr10
\font\OML/cmm/m/it/5=cmmi5
\font\OML/cmm/m/it/7=cmmi7
\font\OML/cmm/m/it/10=cmmi10
\font\OMS/cmsy/m/n/5=cmsy5
\font\OMS/cmsy/m/n/7=cmsy7
\font\OMS/cmsy/m/n/10=cmsy10
3633 words of font info for 14 preloaded fonts
14 hyphenation exceptions
Hyphenation trie of length 6081 has 183 ops out of 35111
  2 for language 1
  181 for language 0
0 words of pdfTeX memory
0 indirect objects
No pages of output.
Transcript written on pdflatex.log.
fmtutil: /home/travis/.texlive2014/texmf-var/web2c/pdftex/pdflatex.fmt
installed.
fmtutil: No errors, exiting successfully.
entering extended mode
(./Rd2.tex
LaTeX2e <2014/05/01>
Babel <3.9l> and hyphenation patterns for 2 languages loaded.

(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/book.cls
Document Class: book 2014/09/29 v1.4h Standard LaTeX document class
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/bk10.clo))
(/home/travis/R-bin/R-3.0.3/lib/R/share/texmf/tex/latex/Rd.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ifthen.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/longtable.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/bm.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/alltt.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/url/url.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/textcomp.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.def))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontenc.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/times.sty))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/inputenc.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.dfu))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latin1.def))
No file Rd2.aux.
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1ptm.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/ts1ptm.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1pcr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1phv.fd)
No file Rd2.toc.
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def)
[1{/home/travis
/R-bin/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}] (./Rd2.aux)
){/ho
me/travis/R-bin/texlive/texmf-dist/fonts/enc/dvips/base/8r.enc}</home/travis/R-
bin/texlive/texmf-dist/fonts/type1/urw/courier/ucrr8a.pfb></home/travis/R-bin/t
exlive/texmf-dist/fonts/type1/urw/helvetic/uhvr8a.pfb></home/travis/R-bin/texli
ve/texmf-dist/fonts/type1/urw/times/utmb8a.pfb></home/travis/R-bin/texlive/texm
f-dist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-dist/
fonts/type1/urw/times/utmri8a.pfb>
Output written on Rd2.pdf (1 page, 46322 bytes).
Transcript written on Rd2.log.
This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (preloaded
format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./Rd2.tex
LaTeX2e <2014/05/01>
Babel <3.9l> and hyphenation patterns for 2 languages loaded.

(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/book.cls
Document Class: book 2014/09/29 v1.4h Standard LaTeX document class
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/bk10.clo))
(/home/travis/R-bin/R-3.0.3/lib/R/share/texmf/tex/latex/Rd.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ifthen.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/longtable.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/bm.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/alltt.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/url/url.sty)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/textcomp.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.def))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontenc.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/times.sty))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/inputenc.sty
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.dfu)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.dfu))
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latin1.def))
(./Rd2.aux)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1ptm.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/ts1ptm.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1pcr.fd)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1phv.fd)
(./Rd2.toc)
(/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def)
[1{/home/travis
/R-bin/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}] [2]
(./Rd2.aux) )
{/home/travis/R-bin/texlive/texmf-dist/fonts/enc/dvips/base/8r.enc}</home/travi
s/R-bin/texlive/texmf-dist/fonts/type1/urw/courier/ucrr8a.pfb></home/travis/R-b
in/texlive/texmf-dist/fonts/type1/urw/helvetic/uhvr8a.pfb></home/travis/R-bin/t
exlive/texmf-dist/fonts/type1/urw/times/utmb8a.pfb></home/travis/R-bin/texlive/
texmf-dist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-d
ist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-dist/fon
ts/type1/urw/times/utmri8a.pfb>
Output written on Rd2.pdf (2 pages, 54276 bytes).
Transcript written on Rd2.log.
Saving output to 'rbuildertest-manual.pdf' ...
Done
You may want to clean up by 'rm -rf /tmp/RtmppU5OjJ/Rd2pdf10671bb8dd18'

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Jan  8 23:19:47 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 8 Jan 2015 14:19:47 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
Message-ID: <CAF8bMcYdWoihz+rz8SxjMwtMRrekaui8Muoz1ZbRBqym_FNPgQ@mail.gmail.com>

> why is there no setcontains()?

Several packages define is.subset(), which I am assuming is what you are
proposing, but it its arguments reversed.  E.g., package:algstat has
   is.subset <- function(x, y) all(x %in% y)
   containsQ <- function(y, x) all(x %in% y)
and package:rje has essentially the same is.subset.

package:arulesSequences and package:arules have an S4 generic called
is.subset, which is entirely different (it is not a predicate, but returns
a matrix).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jan 8, 2015 at 1:30 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> If you look at the definition of %in%, you'll find that it is implemented
> using match, so if we did as you suggest, I give it about three days before
> someone suggests to inline the function call... Readability of source code
> is not usually our prime concern.
>
> The && idea does have some merit, though.
>
> Apropos, why is there no setcontains()?
>
> -pd
>
> > On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
> >
> > Hi,
> >
> > Current implementation:
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
> > }
> >
> > First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L) >
> 0L'
> > with 'x %in% y' and 'y %in% x', respectively. They're strictly
> > equivalent but the latter form is a lot more readable than the former
> > (isn't this the "raison d'?tre" of %in%?):
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(c(x %in% y, y %in% x))
> > }
> >
> > Furthermore, replacing 'all(c(x %in% y, y %in x))' with
> > 'all(x %in% y) && all(y %in% x)' improves readability even more and,
> > more importantly, reduces memory footprint significantly on big vectors
> > (e.g. by 15% on integer vectors with 15M elements):
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(x %in% y) && all(y %in% x)
> > }
> >
> > It also seems to speed up things a little bit (not in a significant
> > way though).
> >
> > Cheers,
> > H.
> >
> > --
> > Herv? Pag?s
> >
> > Program in Computational Biology
> > Division of Public Health Sciences
> > Fred Hutchinson Cancer Research Center
> > 1100 Fairview Ave. N, M1-B514
> > P.O. Box 19024
> > Seattle, WA 98109-1024
> >
> > E-mail: hpages at fredhutch.org
> > Phone:  (206) 667-5791
> > Fax:    (206) 667-1319
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Thu Jan  8 23:06:46 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 8 Jan 2015 14:06:46 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
Message-ID: <CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>

How about unique them both and compare the lengths?  It's less work,
especially allocation.



Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Thu, Jan 8, 2015 at 1:30 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> If you look at the definition of %in%, you'll find that it is implemented
> using match, so if we did as you suggest, I give it about three days before
> someone suggests to inline the function call... Readability of source code
> is not usually our prime concern.
>
> The && idea does have some merit, though.
>
> Apropos, why is there no setcontains()?
>
> -pd
>
> > On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
> >
> > Hi,
> >
> > Current implementation:
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
> > }
> >
> > First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L) >
> 0L'
> > with 'x %in% y' and 'y %in% x', respectively. They're strictly
> > equivalent but the latter form is a lot more readable than the former
> > (isn't this the "raison d'?tre" of %in%?):
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(c(x %in% y, y %in% x))
> > }
> >
> > Furthermore, replacing 'all(c(x %in% y, y %in x))' with
> > 'all(x %in% y) && all(y %in% x)' improves readability even more and,
> > more importantly, reduces memory footprint significantly on big vectors
> > (e.g. by 15% on integer vectors with 15M elements):
> >
> > setequal <- function (x, y)
> > {
> >  x <- as.vector(x)
> >  y <- as.vector(y)
> >  all(x %in% y) && all(y %in% x)
> > }
> >
> > It also seems to speed up things a little bit (not in a significant
> > way though).
> >
> > Cheers,
> > H.
> >
> > --
> > Herv? Pag?s
> >
> > Program in Computational Biology
> > Division of Public Health Sciences
> > Fred Hutchinson Cancer Research Center
> > 1100 Fairview Ave. N, M1-B514
> > P.O. Box 19024
> > Seattle, WA 98109-1024
> >
> > E-mail: hpages at fredhutch.org
> > Phone:  (206) 667-5791
> > Fax:    (206) 667-1319
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Fri Jan  9 00:38:48 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 8 Jan 2015 15:38:48 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
	<CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>
Message-ID: <CAOQ5NyfmaZqwmRLkEp6CH2rkdQjj2M09qEV8btbwgPAUh-kTaQ@mail.gmail.com>

Currently unique() does duplicated() internally and then extracts. One
could make a countUnique that simply counts, rather than allocate the
logical return value of duplicated(). But so much of the cost is in the
hash operation that it probably won't help much, but that might depend on
the sizes of things. The more unique elements, the better it would perform.


On Thu, Jan 8, 2015 at 2:06 PM, Peter Haverty <haverty.peter at gene.com>
wrote:

> How about unique them both and compare the lengths?  It's less work,
> especially allocation.
>
>
>
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
> On Thu, Jan 8, 2015 at 1:30 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> > If you look at the definition of %in%, you'll find that it is implemented
> > using match, so if we did as you suggest, I give it about three days
> before
> > someone suggests to inline the function call... Readability of source
> code
> > is not usually our prime concern.
> >
> > The && idea does have some merit, though.
> >
> > Apropos, why is there no setcontains()?
> >
> > -pd
> >
> > > On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
> > >
> > > Hi,
> > >
> > > Current implementation:
> > >
> > > setequal <- function (x, y)
> > > {
> > >  x <- as.vector(x)
> > >  y <- as.vector(y)
> > >  all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
> > > }
> > >
> > > First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L)
> >
> > 0L'
> > > with 'x %in% y' and 'y %in% x', respectively. They're strictly
> > > equivalent but the latter form is a lot more readable than the former
> > > (isn't this the "raison d'?tre" of %in%?):
> > >
> > > setequal <- function (x, y)
> > > {
> > >  x <- as.vector(x)
> > >  y <- as.vector(y)
> > >  all(c(x %in% y, y %in% x))
> > > }
> > >
> > > Furthermore, replacing 'all(c(x %in% y, y %in x))' with
> > > 'all(x %in% y) && all(y %in% x)' improves readability even more and,
> > > more importantly, reduces memory footprint significantly on big vectors
> > > (e.g. by 15% on integer vectors with 15M elements):
> > >
> > > setequal <- function (x, y)
> > > {
> > >  x <- as.vector(x)
> > >  y <- as.vector(y)
> > >  all(x %in% y) && all(y %in% x)
> > > }
> > >
> > > It also seems to speed up things a little bit (not in a significant
> > > way though).
> > >
> > > Cheers,
> > > H.
> > >
> > > --
> > > Herv? Pag?s
> > >
> > > Program in Computational Biology
> > > Division of Public Health Sciences
> > > Fred Hutchinson Cancer Research Center
> > > 1100 Fairview Ave. N, M1-B514
> > > P.O. Box 19024
> > > Seattle, WA 98109-1024
> > >
> > > E-mail: hpages at fredhutch.org
> > > Phone:  (206) 667-5791
> > > Fax:    (206) 667-1319
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Fri Jan  9 00:50:24 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 8 Jan 2015 15:50:24 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
	<CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>
Message-ID: <CAGh0NYpDV6J8H5+YFHDTWgRwabeAxriHwyBDZ5zyjQUzYU=pKQ@mail.gmail.com>

I was thinking something like:

setequal <- function(x,y) {
xu = unique(x)
yu = unique(y)
if (length(xu) != length(yu)) { return FALSE; }
return (all( match( xu, yu, 0L ) > 0L ) )
}

This lets you fail early for cheap (skipping the allocation from the
">0L"s).  Whether or not this goes fast depends a lot on the uniqueness of
x and y and whether or not you want to optimize for the TRUE or FALSE case.
You'd do much better to make some real hashes in C and compare the keys,
but it's probably not worth the complexity.




Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Thu, Jan 8, 2015 at 2:06 PM, Peter Haverty <phaverty at gene.com> wrote:

> How about unique them both and compare the lengths?  It's less work,
> especially allocation.
>
>
>
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
> On Thu, Jan 8, 2015 at 1:30 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> If you look at the definition of %in%, you'll find that it is implemented
>> using match, so if we did as you suggest, I give it about three days before
>> someone suggests to inline the function call... Readability of source code
>> is not usually our prime concern.
>>
>> The && idea does have some merit, though.
>>
>> Apropos, why is there no setcontains()?
>>
>> -pd
>>
>> > On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
>> >
>> > Hi,
>> >
>> > Current implementation:
>> >
>> > setequal <- function (x, y)
>> > {
>> >  x <- as.vector(x)
>> >  y <- as.vector(y)
>> >  all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
>> > }
>> >
>> > First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L)
>> > 0L'
>> > with 'x %in% y' and 'y %in% x', respectively. They're strictly
>> > equivalent but the latter form is a lot more readable than the former
>> > (isn't this the "raison d'?tre" of %in%?):
>> >
>> > setequal <- function (x, y)
>> > {
>> >  x <- as.vector(x)
>> >  y <- as.vector(y)
>> >  all(c(x %in% y, y %in% x))
>> > }
>> >
>> > Furthermore, replacing 'all(c(x %in% y, y %in x))' with
>> > 'all(x %in% y) && all(y %in% x)' improves readability even more and,
>> > more importantly, reduces memory footprint significantly on big vectors
>> > (e.g. by 15% on integer vectors with 15M elements):
>> >
>> > setequal <- function (x, y)
>> > {
>> >  x <- as.vector(x)
>> >  y <- as.vector(y)
>> >  all(x %in% y) && all(y %in% x)
>> > }
>> >
>> > It also seems to speed up things a little bit (not in a significant
>> > way though).
>> >
>> > Cheers,
>> > H.
>> >
>> > --
>> > Herv? Pag?s
>> >
>> > Program in Computational Biology
>> > Division of Public Health Sciences
>> > Fred Hutchinson Cancer Research Center
>> > 1100 Fairview Ave. N, M1-B514
>> > P.O. Box 19024
>> > Seattle, WA 98109-1024
>> >
>> > E-mail: hpages at fredhutch.org
>> > Phone:  (206) 667-5791
>> > Fax:    (206) 667-1319
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Fri Jan  9 01:57:38 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 8 Jan 2015 16:57:38 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <CAGh0NYpDV6J8H5+YFHDTWgRwabeAxriHwyBDZ5zyjQUzYU=pKQ@mail.gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
	<CAGh0NYrpbig0EuPK80pK05fom60w7WwyUBdKzhKQaR+FKK=MZA@mail.gmail.com>
	<CAGh0NYpDV6J8H5+YFHDTWgRwabeAxriHwyBDZ5zyjQUzYU=pKQ@mail.gmail.com>
Message-ID: <CAGh0NYpX+bnbKUkxUjQAdxZLebGYejXkaeg62XgCLnS7ftNMgw@mail.gmail.com>

Try this out. It looks like a 2X speedup for some cases and a wash in
others.  "unique" does two allocations, but skipping the "> 0L" allocation
could make up for it.

library(microbenchmark)
library(RUnit)

x = sample.int(1e4, 1e5, TRUE)
y = sample.int(1e4, 1e5, TRUE)

set_equal <- function(x, y) {
    xu = .Internal(unique(x, FALSE, FALSE, NA))
    yu = .Internal(unique(y, FALSE, FALSE, NA))
    if (length(xu) != length(yu)) {
        return(FALSE);
    }
    return( all(match(xu, yu, 0L) > 0L) )
}

set_equal2 <- function(x, y) {
    xu = .Internal(unique(x, FALSE, FALSE, NA))
    yu = .Internal(unique(y, FALSE, FALSE, NA))
    if (length(xu) != length(yu)) {
        return(FALSE);
    }
    return( !anyNA(match(xu, yu)) )
}

microbenchmark(
    a = setequal(x, y),
    b = set_equal(x, y),
    c = set_equal2(x, y)
    )
checkIdentical(setequal(x, y), set_equal(x, y))
checkIdentical(setequal(x, y), set_equal2(x, y))

x = y
microbenchmark(
    a = setequal(x, y),
    b = set_equal(x, y),
    c = set_equal2(x, y)
    )
checkIdentical(setequal(x, y), set_equal(x, y))
checkIdentical(setequal(x, y), set_equal2(x, y))


Sorry, I'm probably over-posting today.

Regards,

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri Jan  9 07:21:12 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 08 Jan 2015 22:21:12 -0800
Subject: [Rd] setequal: better readability, reduced memory footprint,
 and minor speedup
In-Reply-To: <AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
References: <54AC4D67.7060302@fredhutch.org>
	<AAAD02BC-38AB-4C2B-A9C4-450D7428E54B@gmail.com>
Message-ID: <54AF7358.8070505@fredhutch.org>

On 01/08/2015 01:30 PM, peter dalgaard wrote:
> If you look at the definition of %in%, you'll find that it is implemented using match, so if we did as you suggest, I give it about three days before someone suggests to inline the function call...

But you wouldn't bet money on that right? Because you know you would
loose.

> Readability of source code is not usually our prime concern.

Don't sacrifice readability if you do not have a good reason for it.
What's your reason here? Are you seriously suggesting that inlining
makes a significant difference? As Michael pointed out, the expensive
operation here is the hashing. But sadly some people like inlining and
want to use it everywhere: it's easy and they feel good about it, even
if it hurts readability and maintainability (if you use x %in% y
instead of the inlined version, the day someone changes the
implementation of x %in% y for something faster, or fixes a bug
in it, your code will automatically benefit, right now it won't).

More simply put: good readability generally leads to better code.

>
> The && idea does have some merit, though.
>
> Apropos, why is there no setcontains()?

Wait... shouldn't everybody use all(match(x, y, nomatch = 0L) > 0L) ?

H.

>
> -pd
>
>> On 06 Jan 2015, at 22:02 , Herv? Pag?s <hpages at fredhutch.org> wrote:
>>
>> Hi,
>>
>> Current implementation:
>>
>> setequal <- function (x, y)
>> {
>>   x <- as.vector(x)
>>   y <- as.vector(y)
>>   all(c(match(x, y, 0L) > 0L, match(y, x, 0L) > 0L))
>> }
>>
>> First what about replacing 'match(x, y, 0L) > 0L' and 'match(y, x, 0L) > 0L'
>> with 'x %in% y' and 'y %in% x', respectively. They're strictly
>> equivalent but the latter form is a lot more readable than the former
>> (isn't this the "raison d'?tre" of %in%?):
>>
>> setequal <- function (x, y)
>> {
>>   x <- as.vector(x)
>>   y <- as.vector(y)
>>   all(c(x %in% y, y %in% x))
>> }
>>
>> Furthermore, replacing 'all(c(x %in% y, y %in x))' with
>> 'all(x %in% y) && all(y %in% x)' improves readability even more and,
>> more importantly, reduces memory footprint significantly on big vectors
>> (e.g. by 15% on integer vectors with 15M elements):
>>
>> setequal <- function (x, y)
>> {
>>   x <- as.vector(x)
>>   y <- as.vector(y)
>>   all(x %in% y) && all(y %in% x)
>> }
>>
>> It also seems to speed up things a little bit (not in a significant
>> way though).
>>
>> Cheers,
>> H.
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From avraham.adler at gmail.com  Fri Jan  9 08:54:51 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 9 Jan 2015 02:54:51 -0500
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <1420745240.60250.YahooMailBasic@web172303.mail.ir2.yahoo.com>
References: <1420745240.60250.YahooMailBasic@web172303.mail.ir2.yahoo.com>
Message-ID: <CAL6gwnK7uVs7MkBR_oqBzdemTC2QzYE-tgQ+qYE-6w=89qa0OQ@mail.gmail.com>

Regarding the redefinition error, I've asked on StackOverflow for
advice [1], but I have noticed the following; perhaps someone here can
understand what changed between the stdio.h of 4.6.3 and the stdio.h
of 4.8.4. In GCC 4.8.4, the section of stdio.h which is referenced in
the errors is the following:

#if !defined (__USE_MINGW_ANSI_STDIO) || __USE_MINGW_ANSI_STDIO == 0
/* this is here to deal with software defining
 * vsnprintf as _vsnprintf, eg. libxml2.  */
#pragma push_macro("snprintf")
#pragma push_macro("vsnprintf")
# undef snprintf
# undef vsnprintf
  int __cdecl __ms_vsnprintf(char * __restrict__ d,size_t n,const char
* __restrict__ format,va_list arg)
    __MINGW_ATTRIB_DEPRECATED_MSVC2005 __MINGW_ATTRIB_DEPRECATED_SEC_WARN;

  __mingw_ovr
  __MINGW_ATTRIB_NONNULL(3)
  int vsnprintf (char * __restrict__ __stream, size_t __n, const char
* __restrict__ __format, va_list __local_argv)
  {
    return __ms_vsnprintf (__stream, __n, __format, __local_argv);
  }

  int __cdecl __ms_snprintf(char * __restrict__ s, size_t n, const
char * __restrict__  format, ...);

#ifndef __NO_ISOCEXT
__mingw_ovr
__MINGW_ATTRIB_NONNULL(3)
int snprintf (char * __restrict__ __stream, size_t __n, const char *
__restrict__ __format, ...)
{
  register int __retval;
  __builtin_va_list __local_argv; __builtin_va_start( __local_argv, __format );
  __retval = __ms_vsnprintf (__stream, __n, __format, __local_argv);
  __builtin_va_end( __local_argv );
  return __retval;
}
#endif /* !__NO_ISOCEXT */

#pragma pop_macro ("vsnprintf")
#pragma pop_macro ("snprintf")
#endif

The corresponding section in 4.6.3 as found in the Rtools for Windows
installation is:

#if !defined (__USE_MINGW_ANSI_STDIO) || __USE_MINGW_ANSI_STDIO == 0
/* this is here to deal with software defining
 * vsnprintf as _vsnprintf, eg. libxml2.  */
#pragma push_macro("snprintf")
#pragma push_macro("vsnprintf")
# undef snprintf
# undef vsnprintf
  int __cdecl vsnprintf(char * __restrict__ d,size_t n,const char *
__restrict__ format,va_list arg)
    __MINGW_ATTRIB_DEPRECATED_MSVC2005 __MINGW_ATTRIB_DEPRECATED_SEC_WARN;

#ifndef __NO_ISOCEXT
  int __cdecl snprintf(char * __restrict__ s, size_t n, const char *
__restrict__  format, ...);
#ifndef __CRT__NO_INLINE
  __CRT_INLINE int __cdecl vsnprintf(char * __restrict__ d,size_t
n,const char * __restrict__ format,va_list arg)
  {
    return _vsnprintf (d, n, format, arg);
  }
#endif /* !__CRT__NO_INLINE */
#endif /* !__NO_ISOCEXT */
#pragma pop_macro ("vsnprintf")
#pragma pop_macro ("snprintf")
#endif

The latter does not have a direct redefinition of the two functions. I
still don't know why the #undef calls do not work [1].

Thank you,

Avi

[1] https://stackoverflow.com/questions/27853225/is-there-a-way-to-include-stdio-h-but-ignore-some-of-the-functions-therein

On Thu, Jan 8, 2015 at 2:27 PM, Hin-Tak Leung
<htl10 at users.sourceforge.net> wrote:
> Oh, I forgot to mention that besides setting AR, RANLIB and the stack probing fix, you also need a very up to date binutils. 2.25 was out in december. Even with that , if you linker's default is not what you are compiling for (i.e. a multiarch toolchain), you need to set GNUTARGET also, i.e. -m32/-m64 is not enough. Some fix to autodetect non-default targets went in after christmas before the new year, but I am not brave enough to try that on a daily basis yet (only tested it and reported it, then reverting the change - how gcc invokes the linker is rather complicated and it is not easy to have two binutils installed...)- setting GNUTARGET seems safer :-).
> Whether you need that depends on whether you are compiling for your toolchain's default target architecture.
>
> AR, RANLIB, GNUTARGET are all environment variables - you set them the usual way. The stack probing fix is for passing "make check", when you finish make.
>
> ------------------------------
> On Thu, Jan 8, 2015 6:14 PM GMT Avraham Adler wrote:
>
>>On Thu, Jan 8, 2015 at 10:48 AM, Hin-Tak Leung
>><htl10 at users.sourceforge.net> wrote:
>>>
>>> The r.dll crash is easy - you need to be using gcc-ar for ar, and gcc-ranlib for ranlib. I also posted a patch to fix the check failure for stack probing, as lto optimizes away the stack probing code, as it should.
>>>
>>> yes, lto build's speed gain is very impressive.
>>>
>>
>>
>>I apologize for my ignorance, but how would I do that? I tried by
>>changing the following in src/gnuwin32/MkRules.local:
>>
>># prefix for 64-bit: path or x86_64-w64-mingw32-
>>BINPREF64 = x86_64-w64-mingw32-gcc-
>>
>>I added the gcc- as the suffix there, but I guess that is insufficient
>>as I still get the following error using 4.9.2:
>>
>>windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
>>gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>>dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>>psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>>system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>>../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>>../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>>../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>>../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>>-lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>>-lcomctl32 -lversion
>>collect2.exe: error: ld returned 5 exit status
>>Makefile:150: recipe for target 'R.dll' failed
>>make[3]: *** [R.dll] Error 1
>>Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>make[2]: *** [../../bin/x64/R.dll] Error 2
>>Makefile:104: recipe for target 'rbuild' failed
>>make[1]: *** [rbuild] Error 2
>>Makefile:14: recipe for target 'all' failed
>>make: *** [all] Error 2
>>
>>I still had to delete those lines in compat.c, so this build, were it
>>to have completed, is still subject to the non-conformance of
>>scientfic notation printing that was discussed earlier.
>>
>>Hin-tak, any suggestions for this error (and the compat.c for that
>>matter) that you, or any reader of this list, may have would be
>>greatly appreciated.
>>
>>Thank you!
>>
>>Avi
>>
>>
>>> ------------------------------
>>> On Thu, Jan 8, 2015 2:01 PM GMT Henric Winell wrote:
>>>
>>>On 2015-01-08 14:18, Avraham Adler wrote:
>>>
>>>> Very timely, as this is how I got into the problem I posted about
>>>> earlier; maybe some of the problems I ran into will mean more to the
>>>> you and the experts on this thread, Dr. Murdoch.For reference, I run
>>>> Windows 7 64bit, and I am trying to build a 64 bit version of R-3.1.2.
>>>>
>>>> As we discussed offline, Dr. Murdoch, I've been trying to build R
>>>> using more recent tools than GCC4.6.3 prerelease. Ruben Von Boxen
>>>> (rubenvb) told me he is no longer developing his own builds of GCC,
>>>> but is focusing on MSYS2 and the mingw64 personal builds. So, similar
>>>> to what Jeroen said, I first installed MSYS2, whose initial
>>>> installation on windows is not so simple[1]. After the initial
>>>> install, the following packages need to be manually installed: make,
>>>> tar, zip, unzip, zlib, and rsync. I also installed base-devel, which
>>>> is way more than necessary, but there may be packages in there which
>>>> are necessary.
>>>>
>>>> I originally installed the most up-to-date version of GCC (4.9.2)[2],
>>>> and I did pick the -seh version, as since I install (almost) all
>>>> packages from source (the one exception being nloptr for now), the
>>>> exception handling should be consistent and it is supposed to up to
>>>> ~15% faster[3].
>>>>
>>>> The initial build crashed with the following error:
>>>>
>>>> gcc -std=gnu99 -m64 -I../../include -I. -DHAVE_CONFIG_H  -O3 -Wall
>>>> -pedantic -mtune=core2   -c xmalloc.c -o xmalloc.o
>>>> ar crs libtre.a regcomp.o regerror.o regexec.o tre-ast.o tre-compile.o
>>>> tre-match -approx.o tre-match-backtrack.o tre-match-parallel.o
>>>> tre-mem.o tre-parse.o tre-stack.o xmalloc.o
>>>> gcc -std=gnu99 -m64   -O3 -Wall -pedantic -mtune=core2   -c compat.c -o compat.o
>>>> compat.c:65:5: error: redefinition of 'snprintf'
>>>>   int snprintf(char *buffer, size_t max, const char *format, ...)
>>>>       ^
>>>> In file included from compat.c:3:0:
>>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:553:5: note: previous
>>>> definition of 'snprintf' was here
>>>>   int snprintf (char * __restrict__ __stream, size_t __n, const char *
>>>> __restrict__ __format, ...)
>>>>       ^
>>>> compat.c:75:5: error: redefinition of 'vsnprintf'
>>>>   int vsnprintf(char *buffer, size_t bufferSize, const char *format,
>>>> va_list args)
>>>>       ^
>>>> In file included from compat.c:3:0:
>>>> F:/MinGW64/x86_64-w64-mingw32/include/stdio.h:543:7: note: previous
>>>> definition of 'vsnprintf' was here
>>>>     int vsnprintf (char * __restrict__ __stream, size_t __n, const char
>>>> * __restrict__ __format, va_list __local_argv)
>>>>         ^
>>>> ../../gnuwin32/MkRules:218: recipe for target 'compat.o' failed
>>>> make[4]: *** [compat.o] Error 1
>>>> Makefile:120: recipe for target 'rlibs' failed
>>>> make[3]: *** [rlibs] Error 1
>>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>>> Makefile:104: recipe for target 'rbuild' failed
>>>> make[1]: *** [rbuild] Error 2
>>>> Makefile:14: recipe for target 'all' failed
>>>> make: *** [all] Error 2
>>>>
>>>> After doing some checking (for example see [4]), I asked Duncan about
>>>> the problem, and he suggested moving the #ifndef _W64 in compat.c up
>>>> above the offending lines (65-75). That did not work, so, I figured
>>>> (it seems mistakenly from the other thread) that if those functions
>>>> are included from stdio already, I can just delete them from compat.c.
>>>> The specific lines are:
>>>>
>>>> int snprintf(char *buffer, size_t max, const char *format, ...)
>>>> {
>>>>      int res;
>>>>      va_list(ap);
>>>>      va_start(ap, format);
>>>>      res = trio_vsnprintf(buffer, max, format, ap);
>>>>      va_end(ap);
>>>>      return res;
>>>> }
>>>>
>>>> int vsnprintf(char *buffer, size_t bufferSize, const char *format, va_list args)
>>>> {
>>>>      return trio_vsnprintf(buffer, bufferSize, format, args);
>>>> }
>>>>
>>>> Continuing the build using 4.9.2 crashed again at the following point:
>>>>
>>>> gcc -std=gnu99 -m64 -I../include -I. -I../extra -DHAVE_CONFIG_H
>>>> -DR_DLL_BUILD  -O3 -Wall -pedantic -mtune=core2   -c malloc.c -o
>>>> malloc.o
>>>> windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
>>>> gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
>>>> dynload.o editor.o embeddedR.o extra.o opt.o pager.o preferences.o
>>>> psignal.o rhome.o rt_complete.o rui.o run.o shext.o sys-win32.o
>>>> system.o dos_wglob.o malloc.o ../main/libmain.a ../appl/libappl.a
>>>> ../nmath/libnmath.a getline/gl.a ../extra/xdr/libxdr.a
>>>> ../extra/pcre/libpcre.a ../extra/bzip2/libbz2.a
>>>> ../extra/intl/libintl.a ../extra/trio/libtrio.a ../extra/tzone/libtz.a
>>>> ../extra/tre/libtre.a ../extra/xz/liblzma.a dllversion.o -fopenmp -L.
>>>> -lgfortran -lRblas -L../../bin/x64 -lRzlib -lRgraphapp -lRiconv
>>>> -lcomctl32 -lversion
>>>> collect2.exe: error: ld returned 5 exit status
>>>> Makefile:150: recipe for target 'R.dll' failed
>>>> make[3]: *** [R.dll] Error 1
>>>> Makefile:179: recipe for target '../../bin/x64/R.dll' failed
>>>> make[2]: *** [../../bin/x64/R.dll] Error 2
>>>> Makefile:104: recipe for target 'rbuild' failed
>>>> make[1]: *** [rbuild] Error 2
>>>> Makefile:14: recipe for target 'all' failed
>>>> make: *** [all] Error 2
>>>>
>>>> As all those files existed in their correct places, the only reason I
>>>> could think of that this would fail here is that GCC version 4.9 did
>>>> make some changes to enhance link-time optimization [5], and probably
>>>> something isn't compatible.
>>>
>>>Right.  Just before Christmas, Hin-Tak Leung reported build failure with
>>>LTO:
>>>
>>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070286.html
>>>https://stat.ethz.ch/pipermail/r-devel/2014-December/070319.html
>>>
>>>
>>>Many thanks to you and others for looking into this,
>>>Henric
>>>
>>>
>>>
>>>> I then downgraded to GCC 4.8.4 [6], and,
>>>> with the deletion of those 10 or so lines from compat.c, I can
>>>> complete the build straight through rinstaller. However, I get that
>>>> failure issue due to the extra 0 in scientific notation [7].
>>>>
>>>> It does not matter if I do the entire process in the MSYS2
>>>> environment, or if I do in in Windows with msys\usr\bin in my path.
>>>>
>>>> Na?vely, it seems that if there were some what for stdio to be
>>>> included in compat.c, yet the versions of snprintf and vsprintf in
>>>> that file to "override" the standard, perhaps this method would work.
>>>> Of course, running make check-all may uncover more issues. I intend to
>>>> run the equivalent checks (from the tools library) inside of R with
>>>> kill on failure turned off to see if anything else is problematic.
>>>>
>>>> Hopefully, something in this description resonates with one of the
>>>> readers here. If anyone has any ideas as to how to circumvent the
>>>> issues with compat.c, I'd be very grateful.
>>>>
>>>> Thank you,
>>>>
>>>> Avi
>>>>
>>>>
>>>> [1] http://sourceforge.net/p/msys2/wiki/MSYS2%20installation/
>>>> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download
>>>> [3] https://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>>> [4] http://www.tt-forums.net/viewtopic.php?p=1034657&sid=613fa47a379ffaa0b9a9fb182a4180e3#p1034657
>>>> [5] https://gcc.gnu.org/gcc-4.9/changes.html
>>>> [6] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.4/threads-win32/seh/x86_64-4.8.4-release-win32-seh-rt_v3-rev0.7z/download
>>>> [7] https://stat.ethz.ch/pipermail/r-devel/2015-January/070354.html
>>>>
>>>> Date: Wed, 07 Jan 2015 20:31:07 -0500
>>>>
>>>> From: Duncan Murdoch <murdoch.duncan at gmail.com>
>>>> To: Jeroen Ooms <jeroenooms at gmail.com>
>>>> Cc: "R-devel at r-project.org" <r-devel at r-project.org>
>>>> Subject: Re: [Rd] New version of Rtools for Windows
>>>> Message-ID: <54ADDDDB.4020500 at gmail.com>
>>>> Content-Type: text/plain; charset=utf-8
>>>>
>>>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>>
>>>> I have been looking into this a bit over the past few months, also
>>>> with mixed success. Nevertheless, below some experiences that might be
>>>> worth sharing.
>>>>
>>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>>> multilib. They explained that the standard approach is to create two
>>>> separate toolchains; one that targets win32 and the other one that
>>>> targets win64 (both tool chains can compiled for win32). Hence the
>>>> only difference for R would be that instead of passing "-m64" and
>>>> "-m32", it would need to set the path to the proper compiler.
>>>>
>>>> There are several initiatives that provide very complete suites of
>>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>>> could take advantage of an existing tool chain as we do on other
>>>> platforms, although perhaps I do not fully understand the R-specific
>>>> requirements on the windows compiler.
>>>>
>>>> I feel quite strongly that we need to be able to build the toolchain,
>>>> rather than relying on binaries produced by others.  We may need to
>>>> customize the toolchain, or we may need to rebuild it when a bug is
>>>> identified.  Lots of binary builders abandon their builds and you can't
>>>> count on them to solve problems at a later date.
>>>>
>>>>
>>>> One project that looks very promising is msys2 [1,2]. It has a package
>>>> manager (port of pacman from arch linux) and comes with a pretty
>>>> complete set of msys [3] and other [4] packages that seems quite well
>>>> maintained.
>>>>
>>>> Do they post complete instructions for building?  That's what I'm
>>>> looking for.  I don't want to develop a build script (I don't know how),
>>>> but I would like to have one.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>> The only issue I ran into with msys2 is that it uses a different c++
>>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>>> the current Rtools to link a static library that was created with
>>>> msys2  [6]. I am not sure if it also be a problem the other way
>>>> around, and if this is still the case for recent versions of
>>>> gcc/mingw.
>>>>
>>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>>> [7] that we might be able to borrow from.
>>>>
>>>>
>>>> [1] https://msys2.github.io/
>>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>>> [3] https://github.com/Alexpux/MSYS2-packages
>>>> [4] https://github.com/Alexpux/MINGW-packages
>>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>>> [7] http://rubyinstaller.org/downloads/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>


From maechler at stat.math.ethz.ch  Fri Jan  9 11:46:40 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2015 11:46:40 +0100
Subject: [Rd] latex warning
In-Reply-To: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>
References: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>
Message-ID: <21679.45456.375544.317066@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Thu, 8 Jan 2015 17:18:27 -0500 writes:

    > Dear all,

    > I am getting an R CMD check warning about the PDF manual. I am having a
    > hard time finding out what is wrong, here is the log of the Rd2pdf call.

    > The full check (and other) log is at
    >   https://api.travis-ci.org/jobs/46373922/log.txt?deansi=true if anybody is
    > interested, and the package itself is here:
    >   https://github.com/metacran/r-builder/tree/bintex/rbuildertest

    > Thanks, Best,
    > Gabor

I don't see any warning or error in your Rdlatex.log (below).

Could it be that the problem happens with the Travis "batch mode" checks,
not with regular  'R CMD check ..'  for your own installed
version of R and LaTeX ?

(I've seen .. but not investigated other cases where Travis
 would barf about things that were fine for me).

Martin

    > +cat ./rbuildertest.Rcheck/Rdlatex.log
    > Hmm ... looks like a package
    > This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (preloaded
    > format=pdflatex)
    > restricted \write18 enabled.

    > kpathsea: Running mktexfmt pdflatex.fmt
    > fmtutil: running `pdftex -ini   -jobname=pdflatex -progname=pdflatex
    > -translate-file=cp227.tcx *pdflatex.ini' ...
    > This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (INITEX)
    > restricted \write18 enabled.
    > (/home/travis/R-bin/texlive/texmf-dist/web2c/cp227.tcx)
    > entering extended mode
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/latexconfig/pdflatex.ini
    > (/home/travis/R-bin/texlive/texmf-config/tex/generic/config/pdftexconfig.tex)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latex.ltx
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/texsys.cfg)
    > ./texsys.aux found


    > \@currdir set to: ./.


    > Assuming \openin and \input
    > have the same search path.


    > Defining UNIX/DOS style filename parser.

    > catcodes, registers, compatibility for TeX 2,  parameters,
    > LaTeX2e <2014/05/01>
    > hacks, control, par, spacing, files, font encodings, lengths,
    > ====================================

    > Local config file fonttext.cfg used

    > ====================================
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fonttext.cfg
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fonttext.ltx
    > === Don't modify this file, use a .cfg file instead ===

    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omlenc.def)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.def)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.def)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1cmr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmss.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1cmtt.fd)))
    > ====================================

    > Local config file fontmath.cfg used

    > ====================================
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontmath.cfg
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontmath.ltx
    > === Don't modify this file, use a .cfg file instead ===

    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omlcmm.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omscmsy.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omxcmex.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ucmr.fd)))
    > ====================================

    > Local config file preload.cfg used

    > =====================================
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/preload.cfg
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/preload.ltx)) page
    > nos.,
    > x-ref, environments, center, verbatim, math definitions, boxes, title,
    > sectioning, contents, floats, footnotes, index, bibliography, output,
    > ===========================================
    > Local configuration file hyphen.cfg used
    > ===========================================
    > (/home/travis/R-bin/texlive/texmf-dist/tex/generic/babel/hyphen.cfg
    > (/home/travis/R-bin/texlive/texmf-dist/tex/generic/babel/switch.def)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/hyphen.tex)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/dumyhyph.tex)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/generic/hyphen/zerohyph.tex))
    > =================================
    > Applying patch file ltpatch.ltx
    > =================================
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ltpatch.ltx)
    > ) )
    > Beginning to dump on file pdflatex.fmt
    > (preloaded format=pdflatex 2015.1.8)
    > 4976 strings of total length 68991
    > 45099 memory locations dumped; current usage is 144&43215
    > 3320 multiletter control sequences
    > \font\nullfont=nullfont
    > \font\OMX/cmex/m/n/10=cmex10
    > \font\tenln=line10
    > \font\tenlnw=linew10
    > \font\tencirc=lcircle10
    > \font\tencircw=lcirclew10
    > \font\OT1/cmr/m/n/5=cmr5
    > \font\OT1/cmr/m/n/7=cmr7
    > \font\OT1/cmr/m/n/10=cmr10
    > \font\OML/cmm/m/it/5=cmmi5
    > \font\OML/cmm/m/it/7=cmmi7
    > \font\OML/cmm/m/it/10=cmmi10
    > \font\OMS/cmsy/m/n/5=cmsy5
    > \font\OMS/cmsy/m/n/7=cmsy7
    > \font\OMS/cmsy/m/n/10=cmsy10
    > 3633 words of font info for 14 preloaded fonts
    > 14 hyphenation exceptions
    > Hyphenation trie of length 6081 has 183 ops out of 35111
    > 2 for language 1
    > 181 for language 0
    > 0 words of pdfTeX memory
    > 0 indirect objects
    > No pages of output.
    > Transcript written on pdflatex.log.
    > fmtutil: /home/travis/.texlive2014/texmf-var/web2c/pdftex/pdflatex.fmt
    > installed.
    > fmtutil: No errors, exiting successfully.
    > entering extended mode
    > (./Rd2.tex
    > LaTeX2e <2014/05/01>
    > Babel <3.9l> and hyphenation patterns for 2 languages loaded.

    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/book.cls
    > Document Class: book 2014/09/29 v1.4h Standard LaTeX document class
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/bk10.clo))
    > (/home/travis/R-bin/R-3.0.3/lib/R/share/texmf/tex/latex/Rd.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ifthen.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/longtable.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/bm.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/alltt.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/url/url.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/textcomp.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.def))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontenc.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/times.sty))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/inputenc.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.dfu))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latin1.def))
    > No file Rd2.aux.
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1ptm.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/ts1ptm.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1pcr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1phv.fd)
    > No file Rd2.toc.
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def)
    > [1{/home/travis
    > /R-bin/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}] (./Rd2.aux)
    > ){/ho
    > me/travis/R-bin/texlive/texmf-dist/fonts/enc/dvips/base/8r.enc}</home/travis/R-
    > bin/texlive/texmf-dist/fonts/type1/urw/courier/ucrr8a.pfb></home/travis/R-bin/t
    > exlive/texmf-dist/fonts/type1/urw/helvetic/uhvr8a.pfb></home/travis/R-bin/texli
    > ve/texmf-dist/fonts/type1/urw/times/utmb8a.pfb></home/travis/R-bin/texlive/texm
    > f-dist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-dist/
    > fonts/type1/urw/times/utmri8a.pfb>
    > Output written on Rd2.pdf (1 page, 46322 bytes).
    > Transcript written on Rd2.log.
    > This is pdfTeX, Version 3.14159265-2.6-1.40.15 (TeX Live 2014) (preloaded
    > format=pdflatex)
    > restricted \write18 enabled.
    > entering extended mode
    > (./Rd2.tex
    > LaTeX2e <2014/05/01>
    > Babel <3.9l> and hyphenation patterns for 2 languages loaded.

    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/book.cls
    > Document Class: book 2014/09/29 v1.4h Standard LaTeX document class
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/bk10.clo))
    > (/home/travis/R-bin/R-3.0.3/lib/R/share/texmf/tex/latex/Rd.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ifthen.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/longtable.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/bm.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/alltt.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/url/url.sty)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/textcomp.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.def))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/fontenc.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.def))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/times.sty))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/inputenc.sty
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/t1enc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ot1enc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/omsenc.dfu)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1enc.dfu))
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/latin1.def))
    > (./Rd2.aux)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1ptm.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/ts1ptm.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1pcr.fd)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/psnfss/t1phv.fd)
    > (./Rd2.toc)
    > (/home/travis/R-bin/texlive/texmf-dist/tex/latex/base/utf8.def)
    > [1{/home/travis
    > /R-bin/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}] [2]
    > (./Rd2.aux) )
    > {/home/travis/R-bin/texlive/texmf-dist/fonts/enc/dvips/base/8r.enc}</home/travi
    > s/R-bin/texlive/texmf-dist/fonts/type1/urw/courier/ucrr8a.pfb></home/travis/R-b
    > in/texlive/texmf-dist/fonts/type1/urw/helvetic/uhvr8a.pfb></home/travis/R-bin/t
    > exlive/texmf-dist/fonts/type1/urw/times/utmb8a.pfb></home/travis/R-bin/texlive/
    > texmf-dist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-d
    > ist/fonts/type1/urw/times/utmr8a.pfb></home/travis/R-bin/texlive/texmf-dist/fon
    > ts/type1/urw/times/utmri8a.pfb>
    > Output written on Rd2.pdf (2 pages, 54276 bytes).
    > Transcript written on Rd2.log.
    > Saving output to 'rbuildertest-manual.pdf' ...
    > Done
    > You may want to clean up by 'rm -rf /tmp/RtmppU5OjJ/Rd2pdf10671bb8dd18'

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From nate at verse.com  Fri Jan  9 10:31:06 2015
From: nate at verse.com (Nathan Kurz)
Date: Fri, 9 Jan 2015 01:31:06 -0800
Subject: [Rd] Cost of garbage collection seems excessive
Message-ID: <CAFAN8vwG8tBipqKTbgrdSUKgxoQJqiWB-46qXhH+n4Zf_buqWg@mail.gmail.com>

When doing repeated regressions on large data sets, I'm finding that
the time spent on garbage collection often exceeds the time spent on
the regression itself.   Consider this test program which I'm running
on  an Intel Haswell i7-4470 processor under Linux 3.13 using R 3.1.2
compiled with ICPC 14.1:

nate at haswell:~$ cat > gc.R
  library(speedglm)
  createData <- function(n) {
      int <- -5
      x <- rnorm(n, 50, 7)
      e <- rnorm(n, 0, 1)
      y <- int + (1.2 * x) + e
      return(data.frame(y, x))
  }
 gc.time()
 data <- createData(500000)
 data.y <- as.matrix(data[1])
 data.x <- model.matrix(y ~ ., data)
 for (i in 1:100) speedglm.wfit(X=data.x, y=data.y, family=gaussian())
 gc.time()

nate at haswell:~$ time Rscript gc.R
 Loading required package: Matrix
 Loading required package: methods
 [1] 0 0 0 0 0
 [1] 10.410  0.024 10.441  0.000  0.000
real 0m17.167s
user 0m16.996s
sys 0m0.176s

The total execution time is 17 seconds, and the time spent on garbage
collection is almost 2/3 of that.  My actual use case is a package
that creates an ensemble from a variety of cross-validated
regressions, and exhibits the same poor performance. Is this expected
behavior?

I've found that I can reduce the garbage collection time to a
tolerable level by setting the R_VSIZE environment value to a large
enough value:

nate at haswell:~$ time R_VSIZE=1GB Rscript gc.R
Loading required package: Matrix
Loading required package: methods
[1] 0 0 0 0 0
[1] 0.716 0.025 0.739 0.000 0.000
real 0m7.694s
user 0m7.388s
sys 0m0.309s

I can do slightly better with even higher values, and by using
R_GC_MEM_GROW=3.  But while using the environment variables solves the
issue for me, I fear that the end users of my package won't be able to
set them.   Is there a way that I can achieve the higher performance
from within R rather than from the command line?

Thanks!

--nate


From edd at debian.org  Fri Jan  9 13:31:09 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 9 Jan 2015 06:31:09 -0600
Subject: [Rd] latex warning
In-Reply-To: <21679.45456.375544.317066@stat.math.ethz.ch>
References: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>
	<21679.45456.375544.317066@stat.math.ethz.ch>
Message-ID: <21679.51725.492837.897776@max.nulle.part>


On 9 January 2015 at 11:46, Martin Maechler wrote:
| (I've seen .. but not investigated other cases where Travis
|  would barf about things that were fine for me).

I often file that under "Travis has a screw loose for sticking with Ubuntu 12.04".

It's a fantastic service, but it has its warts. "Word" is that at some point
they'll switch to a new release "at some point".  For R, we are getting by
via eg R builds off the CRAN / PPA repos administered by Michael, but for
some other libraries it shows its age. One can code around it if one knows
how to prepare a matching .deb (cf [1] which I need to document/blog about).

Dirk

[1] https://github.com/eddelbuettel/rquantlib/blob/master/.travis.yml#L23:L26

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From maechler at stat.math.ethz.ch  Fri Jan  9 14:00:38 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2015 14:00:38 +0100
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
	<CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>
Message-ID: <21679.53494.724909.346806@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Thu, 8 Jan 2015 14:02:26 -0800 writes:

    > On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:
    >> On Thu, 8 Jan 2015, Michael Lawrence wrote:
    >> 
    >> If we do add an argument to get(), then it should be named consistently
    >>> with the ifnotfound argument of mget(). As mentioned, the possibility of a
    >>> NULL value is problematic. One solution is a sentinel value that indicates
    >>> an unbound value (like R_UnboundValue).
    >>> 
    >> 
    >> A null default is fine -- it's a default; if it isn't right for a
    >> particular case you can provide something else.
    >> 
    >> 
    >>> But another idea (and one pretty similar to John's) is to follow the
    >>> SYMSXP
    >>> design at the C level, where there is a structure that points to the name
    >>> and a value. We already have SYMSXPs at the R level of course (name
    >>> objects) but they do not provide access to the value, which is typically
    >>> R_UnboundValue. But this does not even need to be implemented with SYMSXP.
    >>> The design would allow something like:
    >>> 
    >>> binding <- getBinding("x", env)
    >>> if (hasValue(binding)) {
    >>>   x <- value(binding) # throws an error if none
    >>>   message(name(binding), "has value", x)
    >>> }
    >>> 
    >>> That I think it is a bit verbose but readable and could be made fast. And
    >>> I
    >>> think binding objects would be useful in other ways, as they are
    >>> essentially a "named object". For example, when iterating over an
    >>> environment.
    >>> 
    >> 
    >> This would need a lot more thought. Directly exposing the internals is
    >> definitely not something we want to do as we may well want to change
    >> that design. But there are lots of other corner issues that would have
    >> to be thought through before going forward, such as what happens if an
    >> rm occurs between obtaining a binding object and doing something with
    >> it. Serialization would also need thinking through. This doesn't seem
    >> like a worthwhile place to spend our efforts to me.
    >> 
    >> 

    > Just wanted to be clear that I was not suggesting to expose any internals.
    > We could implement the behavior using SYMSXP, or not. Nor would the binding
    > need to be mutable. The binding would be considered independent of the
    > environment from which it was retrieved. As Pete has mentioned, it could be
    > a useful abstraction to have in general.

It could be, indeed.   Luke's advice (above) and my own gut
feeling do tell me that this is a much larger step than solving
the "getIfExists()" problem.  
In the R development cycle I'd think that it should go to the
next (2015-2016) "3.3" cycle, rather than the current "3.2" one
with goal in April.

    >> Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
    >> an argument to get() with missing giving current behavior may be OK
    >> too. Rewriting exists and get as .Primitives may be sufficient though.

Thank you, Luke.  Given that, Duncan's and the other inputs,
I think we should go for a new function -- .Internal() for now.

To Pete's point about arguments, I did drop 'frame' on purpose 
and indeed we could try to do away with 'where/pos' as well and
have the environment only specified by 'envir'.

Name: I like  get0() for its brevity and prefer it to .get().

Let me expose my current implementation on R-devel ... and start
using it in the 'methods' package so we (Pete H. :-) can start
measuring its impact.

Martin


From csardi.gabor at gmail.com  Fri Jan  9 15:24:09 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 9 Jan 2015 09:24:09 -0500
Subject: [Rd] latex warning
In-Reply-To: <21679.51725.492837.897776@max.nulle.part>
References: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>
	<21679.45456.375544.317066@stat.math.ethz.ch>
	<21679.51725.492837.897776@max.nulle.part>
Message-ID: <CABtg=KkCj83Pqx9qD9=d3B7yCjgTMdg1Xo7BvwvFhSfVnXhwKw@mail.gmail.com>

Thanks for the answers, Travis CI indeed uses an outdated system, but I
actually use my own recent TeXLive installation on it, exactly because of
this reason (and because I want to avoid sudo).

Obviously, there is something wrong with this installation, but I am
puzzled by not seeing any LaTeX errors, and R CMD check still reporting
one. Maybe not all of the LaTeX output is included in the check log. Or the
check incorrectly detects an error when there is none.

Gabor

On Fri, Jan 9, 2015 at 7:31 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 9 January 2015 at 11:46, Martin Maechler wrote:
> | (I've seen .. but not investigated other cases where Travis
> |  would barf about things that were fine for me).
>
> I often file that under "Travis has a screw loose for sticking with Ubuntu
> 12.04".
>
> It's a fantastic service, but it has its warts. "Word" is that at some
> point
> they'll switch to a new release "at some point".  For R, we are getting by
> via eg R builds off the CRAN / PPA repos administered by Michael, but for
> some other libraries it shows its age. One can code around it if one knows
> how to prepare a matching .deb (cf [1] which I need to document/blog
> about).
>
> Dirk
>
> [1]
> https://github.com/eddelbuettel/rquantlib/blob/master/.travis.yml#L23:L26
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jan  9 16:37:43 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 9 Jan 2015 16:37:43 +0100
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <21679.53494.724909.346806@stat.math.ethz.ch>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
	<CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>
	<21679.53494.724909.346806@stat.math.ethz.ch>
Message-ID: <21679.62919.821760.990215@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 9 Jan 2015 14:00:38 +0100 writes:

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Thu, 8 Jan 2015 14:02:26 -0800 writes:

    >> On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:
    >>> On Thu, 8 Jan 2015, Michael Lawrence wrote:
    >>> 
    >>> If we do add an argument to get(), then it should be named consistently
    >>>> with the ifnotfound argument of mget(). 

You are right... I forgot to say so earlier in the thread.

The definition now is

get0 <- function (x, envir = pos.to.env(-1L), mode = "any", inherits = TRUE,
                  ifnotfound = NULL)
    .Internal(get0(x, envir, mode, inherits, ifnotfound))



    >>>> As mentioned, the possibility of a
    >>>> NULL value is problematic. One solution is a sentinel value that indicates
    >>>> an unbound value (like R_UnboundValue).
    >>>> 
    >>> 
    >>> A null default is fine -- it's a default; if it isn't right for a
    >>> particular case you can provide something else.
    >>> 

    [..................]

    >>> Adding getIfExists, or .get, or get0, or whatever seems fine. Adding
    >>> an argument to get() with missing giving current behavior may be OK
    >>> too. Rewriting exists and get as .Primitives may be sufficient though.

    > Thank you, Luke.  Given that, Duncan's and the other inputs,
    > I think we should go for a new function -- .Internal() for now.

    > To Pete's point about arguments, I did drop 'frame' on purpose 
    > and indeed we could try to do away with 'where/pos' as well and
    > have the environment only specified by 'envir'.

    > Name: I like  get0() for its brevity and prefer it to .get().

    > Let me expose my current implementation on R-devel ... and start
    > using it in the 'methods' package so we (Pete H. :-) can start
    > measuring its impact.

I have now committed  get0() to R-devel  (svn rev 67386) 

which is already using it in quite a few places:
in 'base', notably in base/R/namespace.R   where it may speedup, also
in 'methods' in quite a few places also in the hope of some S4
speedup.

{{Now I feel having deserved some weekend break ...}}

Martin


From nilsson.henric at gmail.com  Fri Jan  9 16:56:27 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 09 Jan 2015 16:56:27 +0100
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <54ADDDDB.4020500@gmail.com>
References: <54AD580F.4030800@gmail.com>
	<CABFfbXsxyJA3uEMjaeh=z1V38MS9LCO9Ns7+pfQoX32J89tQWw@mail.gmail.com>
	<54ADDDDB.4020500@gmail.com>
Message-ID: <54AFFA2B.4090309@gmail.com>

On 2015-01-08 02:31, Duncan Murdoch wrote:

> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>
>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>
>> I have been looking into this a bit over the past few months, also
>> with mixed success. Nevertheless, below some experiences that might be
>> worth sharing.
>>
>> The guys from mingw-w64 recommended (quite strongly) to move away from
>> multilib. They explained that the standard approach is to create two
>> separate toolchains; one that targets win32 and the other one that
>> targets win64 (both tool chains can compiled for win32). Hence the
>> only difference for R would be that instead of passing "-m64" and
>> "-m32", it would need to set the path to the proper compiler.
>>
>> There are several initiatives that provide very complete suites of
>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>> could take advantage of an existing tool chain as we do on other
>> platforms, although perhaps I do not fully understand the R-specific
>> requirements on the windows compiler.
>
> I feel quite strongly that we need to be able to build the toolchain,
> rather than relying on binaries produced by others.  We may need to
> customize the toolchain, or we may need to rebuild it when a bug is
> identified.  Lots of binary builders abandon their builds and you can't
> count on them to solve problems at a later date.
>
>>
>> One project that looks very promising is msys2 [1,2]. It has a package
>> manager (port of pacman from arch linux) and comes with a pretty
>> complete set of msys [3] and other [4] packages that seems quite well
>> maintained.
>
> Do they post complete instructions for building?  That's what I'm
> looking for.  I don't want to develop a build script (I don't know how),
> but I would like to have one.

Have you looked at nuwen's distro (http://nuwen.net/mingw.html)?  It's 
up-to-date (mingw-w64 3.3.0, binutils 2.25, GCC 4.9.2, ...) and includes 
the build scripts.


Henric



>
> Duncan Murdoch
>
>>
>> The only issue I ran into with msys2 is that it uses a different c++
>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>> the current Rtools to link a static library that was created with
>> msys2  [6]. I am not sure if it also be a problem the other way
>> around, and if this is still the case for recent versions of
>> gcc/mingw.
>>
>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>> [7] that we might be able to borrow from.
>>
>>
>> [1] https://msys2.github.io/
>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>> [3] https://github.com/Alexpux/MSYS2-packages
>> [4] https://github.com/Alexpux/MINGW-packages
>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>> [7] http://rubyinstaller.org/downloads/
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From craigcitro at gmail.com  Fri Jan  9 16:20:44 2015
From: craigcitro at gmail.com (Craig Citro)
Date: Fri, 9 Jan 2015 07:20:44 -0800
Subject: [Rd] latex warning
In-Reply-To: <21679.51725.492837.897776@max.nulle.part>
References: <CABtg=KmoDFv87r+drDsPwvXW+=p+Ern6QpqD7iG8ommHNm9HKg@mail.gmail.com>
	<21679.45456.375544.317066@stat.math.ethz.ch>
	<21679.51725.492837.897776@max.nulle.part>
Message-ID: <CAGA9EiuVnHNp_gcKuB5GeAuPPrnM2bLZ923hH5S5nijWebCXWA@mail.gmail.com>

>
> It's a fantastic service, but it has its warts. "Word" is that at some
> point
> they'll switch to a new release "at some point".
>
>
this is definitely at least on their roadmap:
https://github.com/travis-ci/travis-ci/issues/2046

there's also the prospect of docker support getting far enough along that
we can just bring our own container -- at which point dirk and carl's
rocker work makes life much easier. ;)

-- 

-cc

	[[alternative HTML version deleted]]


From winstonchang1 at gmail.com  Fri Jan  9 18:09:46 2015
From: winstonchang1 at gmail.com (Winston Chang)
Date: Fri, 9 Jan 2015 11:09:46 -0600
Subject: [Rd] unloadNamespace
In-Reply-To: <54AEA614.1050803@gmail.com>
References: <54AEA614.1050803@gmail.com>
Message-ID: <CAFOpNVFdHc3GY7rAS+QiW952MCLUF3x1ofsnE-4NhhyjcU1n9w@mail.gmail.com>

It's probably because the first thing that unloadNamespace does is this:
   ns <- asNamespace(ns, base.OK = FALSE)

If you call asNamespace("tseries"), it calls getNamespace("tseries"), which
has the side effect of loading that package (and its dependencies).

One way to work around this is to check loadedNamespaces() before you try
to unload a package.

-Winston

On Thu, Jan 8, 2015 at 9:45 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:

> In the documentation the closed thing I see to an explanation of this is
> that ?detach says "Unloading some namespaces has undesirable side effects"
>
> Can anyone explain why unloading tseries will load zoo? I don't think this
> behavior is specific to tseries, it's just an example. I realize one would
> not usually unload something that is not loaded, but I would expect it to
> do nothing or give an error. I only discovered this when trying to clean up
> to debug another problem.
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> and
> R Under development (unstable) (2015-01-02 r67308) -- "Unsuffered
> Consequences"
> ...
> Type 'q()' to quit R.
>
> > loadedNamespaces()
> [1] "base"      "datasets"  "graphics"  "grDevices" "methods"   "stats"
> [7] "utils"
> > unloadNamespace("tseries") # loads zoo ?
> > loadedNamespaces()
>  [1] "base"      "datasets"  "graphics"  "grDevices" "grid" "lattice"
>  [7] "methods"   "quadprog"  "stats"     "utils"     "zoo"
> >
>
> Somewhat related, is there an easy way to get back to a "clean" state for
> loaded and attached things, as if R had just been started? I'm trying to do
> this in a vignette so it is not easy to stop and restart R.
>
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Jan  9 18:19:39 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 09 Jan 2015 12:19:39 -0500
Subject: [Rd] New version of Rtools for Windows
In-Reply-To: <54AFFA2B.4090309@gmail.com>
References: <54AD580F.4030800@gmail.com>
	<CABFfbXsxyJA3uEMjaeh=z1V38MS9LCO9Ns7+pfQoX32J89tQWw@mail.gmail.com>
	<54ADDDDB.4020500@gmail.com> <54AFFA2B.4090309@gmail.com>
Message-ID: <54B00DAB.6020507@gmail.com>

On 09/01/2015 10:56 AM, Henric Winell wrote:
> On 2015-01-08 02:31, Duncan Murdoch wrote:
> 
>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>
>>> I have been looking into this a bit over the past few months, also
>>> with mixed success. Nevertheless, below some experiences that might be
>>> worth sharing.
>>>
>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>> multilib. They explained that the standard approach is to create two
>>> separate toolchains; one that targets win32 and the other one that
>>> targets win64 (both tool chains can compiled for win32). Hence the
>>> only difference for R would be that instead of passing "-m64" and
>>> "-m32", it would need to set the path to the proper compiler.
>>>
>>> There are several initiatives that provide very complete suites of
>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>> could take advantage of an existing tool chain as we do on other
>>> platforms, although perhaps I do not fully understand the R-specific
>>> requirements on the windows compiler.
>>
>> I feel quite strongly that we need to be able to build the toolchain,
>> rather than relying on binaries produced by others.  We may need to
>> customize the toolchain, or we may need to rebuild it when a bug is
>> identified.  Lots of binary builders abandon their builds and you can't
>> count on them to solve problems at a later date.
>>
>>>
>>> One project that looks very promising is msys2 [1,2]. It has a package
>>> manager (port of pacman from arch linux) and comes with a pretty
>>> complete set of msys [3] and other [4] packages that seems quite well
>>> maintained.
>>
>> Do they post complete instructions for building?  That's what I'm
>> looking for.  I don't want to develop a build script (I don't know how),
>> but I would like to have one.
> 
> Have you looked at nuwen's distro (http://nuwen.net/mingw.html)?  It's 
> up-to-date (mingw-w64 3.3.0, binutils 2.25, GCC 4.9.2, ...) and includes 
> the build scripts.
> 

No, I hadn't come across that one.  It looks quite promising. Thanks!

I also have another offer of help to put this together; I'll wait to see
how that goes before announcing it.  But having two builds is better
than one.

Duncan Murdoch


> 
> Henric
> 
> 
> 
>>
>> Duncan Murdoch
>>
>>>
>>> The only issue I ran into with msys2 is that it uses a different c++
>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>> the current Rtools to link a static library that was created with
>>> msys2  [6]. I am not sure if it also be a problem the other way
>>> around, and if this is still the case for recent versions of
>>> gcc/mingw.
>>>
>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>> [7] that we might be able to borrow from.
>>>
>>>
>>> [1] https://msys2.github.io/
>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>> [3] https://github.com/Alexpux/MSYS2-packages
>>> [4] https://github.com/Alexpux/MINGW-packages
>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>> [7] http://rubyinstaller.org/downloads/
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From gmbecker at ucdavis.edu  Fri Jan  9 18:34:59 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 9 Jan 2015 09:34:59 -0800
Subject: [Rd] unloadNamespace
In-Reply-To: <CAFOpNVFdHc3GY7rAS+QiW952MCLUF3x1ofsnE-4NhhyjcU1n9w@mail.gmail.com>
References: <54AEA614.1050803@gmail.com>
	<CAFOpNVFdHc3GY7rAS+QiW952MCLUF3x1ofsnE-4NhhyjcU1n9w@mail.gmail.com>
Message-ID: <CADwqtCNRoT1bafqSKLH-28Lz5RozC1VZ3-90LNMoDxeaSxvBKQ@mail.gmail.com>

Paul,

In the version of R I had trivially available, the flushSession function
from switchr seems to perform as expected when tseries is loaded.

> library(tseries)
library(tseries)

    ?tseries? version: 0.10-32

    ?tseries? is a package for time series analysis and computational
    finance.

    See ?library(help="tseries")? for details.

> library(switchr)
library(switchr)
> sessionInfo()
sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] switchr_0.4.7   tseries_0.10-32

loaded via a namespace (and not attached):
[1] BiocInstaller_1.16.1 bitops_1.0-6         grid_3.1.0
[4] lattice_0.20-29      quadprog_1.5-5       RCurl_1.95-4.5
[7] tcltk_3.1.0          tools_3.1.0          zoo_1.7-11
> flushSession()
flushSession()
NULL
Warning message:
In flushSession() : Unable to unload all namespaces
> sessionInfo()
sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] switchr_0.4.7

loaded via a namespace (and not attached):
[1] BiocInstaller_1.16.1 bitops_1.0-6         grid_3.1.0
[4] RCurl_1.95-4.5       tcltk_3.1.0          tools_3.1.0
>

Ignore the warning in the middle there, it is referring to BiocInstaller.
The rest of the packages which remain loaded are base packages (which it
doesn't attempt to unload by default, as doing so is dangerous).

I'll try to run the same test on the version of R you were using soon, but
I don't have it handy atm.

~G

On Fri, Jan 9, 2015 at 9:09 AM, Winston Chang <winstonchang1 at gmail.com>
wrote:

> It's probably because the first thing that unloadNamespace does is this:
>    ns <- asNamespace(ns, base.OK = FALSE)
>
> If you call asNamespace("tseries"), it calls getNamespace("tseries"), which
> has the side effect of loading that package (and its dependencies).
>
> One way to work around this is to check loadedNamespaces() before you try
> to unload a package.
>
> -Winston
>
> On Thu, Jan 8, 2015 at 9:45 AM, Paul Gilbert <pgilbert902 at gmail.com>
> wrote:
>
> > In the documentation the closed thing I see to an explanation of this is
> > that ?detach says "Unloading some namespaces has undesirable side
> effects"
> >
> > Can anyone explain why unloading tseries will load zoo? I don't think
> this
> > behavior is specific to tseries, it's just an example. I realize one
> would
> > not usually unload something that is not loaded, but I would expect it to
> > do nothing or give an error. I only discovered this when trying to clean
> up
> > to debug another problem.
> >
> > R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> > and
> > R Under development (unstable) (2015-01-02 r67308) -- "Unsuffered
> > Consequences"
> > ...
> > Type 'q()' to quit R.
> >
> > > loadedNamespaces()
> > [1] "base"      "datasets"  "graphics"  "grDevices" "methods"   "stats"
> > [7] "utils"
> > > unloadNamespace("tseries") # loads zoo ?
> > > loadedNamespaces()
> >  [1] "base"      "datasets"  "graphics"  "grDevices" "grid" "lattice"
> >  [7] "methods"   "quadprog"  "stats"     "utils"     "zoo"
> > >
> >
> > Somewhat related, is there an easy way to get back to a "clean" state for
> > loaded and attached things, as if R had just been started? I'm trying to
> do
> > this in a vignette so it is not easy to stop and restart R.
> >
> > Paul
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Alumnus
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Fri Jan  9 19:56:44 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Fri, 9 Jan 2015 10:56:44 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <21679.62919.821760.990215@stat.math.ethz.ch>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
	<CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>
	<21679.53494.724909.346806@stat.math.ethz.ch>
	<21679.62919.821760.990215@stat.math.ethz.ch>
Message-ID: <CAGh0NYoCsVfzZrhRej7FZa28qdcPRdUpuhuFHB1dF2uyXbudEg@mail.gmail.com>

Fantastic. I'm eager to try it out.  Thanks for seeing this through.

Regards,

Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Fri, Jan 9, 2015 at 7:37 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>     on Fri, 9 Jan 2015 14:00:38 +0100 writes:
>
> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Thu, 8 Jan 2015 14:02:26 -0800 writes:
>
>     >> On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:
>     >>> On Thu, 8 Jan 2015, Michael Lawrence wrote:
>     >>>
>     >>> If we do add an argument to get(), then it should be named
> consistently
>     >>>> with the ifnotfound argument of mget().
>
> You are right... I forgot to say so earlier in the thread.
>
> The definition now is
>
> get0 <- function (x, envir = pos.to.env(-1L), mode = "any", inherits =
> TRUE,
>                   ifnotfound = NULL)
>     .Internal(get0(x, envir, mode, inherits, ifnotfound))
>
>
>
>     >>>> As mentioned, the possibility of a
>     >>>> NULL value is problematic. One solution is a sentinel value that
> indicates
>     >>>> an unbound value (like R_UnboundValue).
>     >>>>
>     >>>
>     >>> A null default is fine -- it's a default; if it isn't right for a
>     >>> particular case you can provide something else.
>     >>>
>
>     [..................]
>
>     >>> Adding getIfExists, or .get, or get0, or whatever seems fine.
> Adding
>     >>> an argument to get() with missing giving current behavior may be OK
>     >>> too. Rewriting exists and get as .Primitives may be sufficient
> though.
>
>     > Thank you, Luke.  Given that, Duncan's and the other inputs,
>     > I think we should go for a new function -- .Internal() for now.
>
>     > To Pete's point about arguments, I did drop 'frame' on purpose
>     > and indeed we could try to do away with 'where/pos' as well and
>     > have the environment only specified by 'envir'.
>
>     > Name: I like  get0() for its brevity and prefer it to .get().
>
>     > Let me expose my current implementation on R-devel ... and start
>     > using it in the 'methods' package so we (Pete H. :-) can start
>     > measuring its impact.
>
> I have now committed  get0() to R-devel  (svn rev 67386)
>
> which is already using it in quite a few places:
> in 'base', notably in base/R/namespace.R   where it may speedup, also
> in 'methods' in quite a few places also in the hope of some S4
> speedup.
>
> {{Now I feel having deserved some weekend break ...}}
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Fri Jan  9 20:06:28 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Fri, 9 Jan 2015 11:06:28 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <21679.62919.821760.990215@stat.math.ethz.ch>
References: <bug-16065-16@http.bugs.r-project.org/bugzilla/>
	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>
	<21678.19158.736089.111281@stat.math.ethz.ch>
	<54AE6C53.8030702@gmail.com>
	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<CAOQ5Nyev+TiYXpsQwmMqYkigucc8UZ9=fHFS-H+r=Kixs=5_xg@mail.gmail.com>
	<alpine.DEB.2.02.1501081340590.24557@luke-Latitude>
	<CAOQ5NyfpRJGixySbgrJXKdkPfawJFUhAiDHKh4dVcg5HUOX3sQ@mail.gmail.com>
	<21679.53494.724909.346806@stat.math.ethz.ch>
	<21679.62919.821760.990215@stat.math.ethz.ch>
Message-ID: <CAGh0NYoHPy16Gw5yB45+5Hmcbz1XZcMmovmwxyX5jdZazzcWug@mail.gmail.com>

Here are some quick measurements of Martin's accomplishment with "get0":

In loading the package GenomicRanges, 30K calls to "exists" have been
skipped.  (However 99K still remain!)
Overall, the current usage of "get0" seems to save us 10% in package
loading time (no error bars on that measurement).
microbenchmark says that

env = asNamespace("base"); get0("match", env)

is a 6X speedup over the same call to "get", which is pretty neat by
itself.  It might be good to just generally use get0.
Unless of course, when one really doesn't need any "exists" checking and
NULL results are fine, then the .Primitive "[[" is 30X faster than "get".
Thanks everyone for your thoughts, code and time on this topic!





Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Fri, Jan 9, 2015 at 7:37 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>     on Fri, 9 Jan 2015 14:00:38 +0100 writes:
>
> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Thu, 8 Jan 2015 14:02:26 -0800 writes:
>
>     >> On Thu, Jan 8, 2015 at 11:57 AM, <luke-tierney at uiowa.edu> wrote:
>     >>> On Thu, 8 Jan 2015, Michael Lawrence wrote:
>     >>>
>     >>> If we do add an argument to get(), then it should be named
> consistently
>     >>>> with the ifnotfound argument of mget().
>
> You are right... I forgot to say so earlier in the thread.
>
> The definition now is
>
> get0 <- function (x, envir = pos.to.env(-1L), mode = "any", inherits =
> TRUE,
>                   ifnotfound = NULL)
>     .Internal(get0(x, envir, mode, inherits, ifnotfound))
>
>
>
>     >>>> As mentioned, the possibility of a
>     >>>> NULL value is problematic. One solution is a sentinel value that
> indicates
>     >>>> an unbound value (like R_UnboundValue).
>     >>>>
>     >>>
>     >>> A null default is fine -- it's a default; if it isn't right for a
>     >>> particular case you can provide something else.
>     >>>
>
>     [..................]
>
>     >>> Adding getIfExists, or .get, or get0, or whatever seems fine.
> Adding
>     >>> an argument to get() with missing giving current behavior may be OK
>     >>> too. Rewriting exists and get as .Primitives may be sufficient
> though.
>
>     > Thank you, Luke.  Given that, Duncan's and the other inputs,
>     > I think we should go for a new function -- .Internal() for now.
>
>     > To Pete's point about arguments, I did drop 'frame' on purpose
>     > and indeed we could try to do away with 'where/pos' as well and
>     > have the environment only specified by 'envir'.
>
>     > Name: I like  get0() for its brevity and prefer it to .get().
>
>     > Let me expose my current implementation on R-devel ... and start
>     > using it in the 'methods' package so we (Pete H. :-) can start
>     > measuring its impact.
>
> I have now committed  get0() to R-devel  (svn rev 67386)
>
> which is already using it in quite a few places:
> in 'base', notably in base/R/namespace.R   where it may speedup, also
> in 'methods' in quite a few places also in the hope of some S4
> speedup.
>
> {{Now I feel having deserved some weekend break ...}}
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri Jan  9 20:56:50 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 09 Jan 2015 11:56:50 -0800
Subject: [Rd] RFC: getifexists() {was [Bug 16065] "exists" ...}
In-Reply-To: <21678.39962.577881.546665@stat.math.ethz.ch>
References: <54AE6C53.8030702@gmail.com>	<bug-16065-16@http.bugs.r-project.org/bugzilla/>	<bug-16065-16-N2rAUyzVWO@http.bugs.r-project.org/bugzilla/>	<21678.19158.736089.111281@stat.math.ethz.ch>	<OF12891DEC.6A4C5E3F-ON85257DC7.004D34A7-85257DC7.004D34AB@american.edu>
	<21678.39962.577881.546665@stat.math.ethz.ch>
Message-ID: <54B03282.2020504@fredhutch.org>

Hi,

On 01/08/2015 07:02 AM, Martin Maechler wrote:
>
>> Adding an optional argument to get (and mget) like
>> val <- get(name, where, ..., value.if.not.found=NULL )   (*)
>
>> would be useful for many.  HOWEVER, it is possible that there could be
>> some confusion here: (*) can give a NULL because either x exists and
>> has value NULL, or because x doesn't exist.   If that matters, the user
>> would need to be careful about specifying a value.if.not.found that cannot
>> be confused with a valid value of x.
>
> Exactly -- well, of course: That problem { NULL can be the legit value of what you
> want to get() } was the only reason to have a 'value.if.not' argument at all.
>
> Note that this is not about a universal replacement of
> the  if(exists(..)) { .. get(..) } idiom,

FWIW, if(exists(..)) { x <- get(..) } is not safe because it's not
atomic. I've seen situations where exists() returns TRUE but then
get() fails to find the symbol (even if called immediately after
exists()).

After scratching my head for a while I found out that the symbol was
removed by some finalizer function defined somewhere (not on the 
environment exists() and gets() were looking at, of course). And
since garbage collection is triggered between the moment exists() sees
the symbol and get() tries to get it, the finalizer was executed and
the symbol removed.

After that, I started to systematically use x <- try(get(...)) instead
(which is atomic).

Cheers,
H.


From pgilbert902 at gmail.com  Fri Jan  9 22:41:03 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 09 Jan 2015 16:41:03 -0500
Subject: [Rd] unloadNamespace
In-Reply-To: <CAFOpNVFdHc3GY7rAS+QiW952MCLUF3x1ofsnE-4NhhyjcU1n9w@mail.gmail.com>
References: <54AEA614.1050803@gmail.com>
	<CAFOpNVFdHc3GY7rAS+QiW952MCLUF3x1ofsnE-4NhhyjcU1n9w@mail.gmail.com>
Message-ID: <54B04AEF.2050002@gmail.com>

Thanks Winston. That seems like a workaround that might be usefully 
included into unloadNamespace.

Paul

On 15-01-09 12:09 PM, Winston Chang wrote:
> It's probably because the first thing that unloadNamespace does is this:
>     ns <- asNamespace(ns, base.OK = FALSE)
>
> If you call asNamespace("tseries"), it calls getNamespace("tseries"),
> which has the side effect of loading that package (and its dependencies).
>
> One way to work around this is to check loadedNamespaces() before you
> try to unload a package.
>
> -Winston
>
> On Thu, Jan 8, 2015 at 9:45 AM, Paul Gilbert <pgilbert902 at gmail.com
> <mailto:pgilbert902 at gmail.com>> wrote:
>
>     In the documentation the closed thing I see to an explanation of
>     this is that ?detach says "Unloading some namespaces has undesirable
>     side effects"
>
>     Can anyone explain why unloading tseries will load zoo? I don't
>     think this behavior is specific to tseries, it's just an example. I
>     realize one would not usually unload something that is not loaded,
>     but I would expect it to do nothing or give an error. I only
>     discovered this when trying to clean up to debug another problem.
>
>     R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
>     and
>     R Under development (unstable) (2015-01-02 r67308) -- "Unsuffered
>     Consequences"
>     ...
>     Type 'q()' to quit R.
>
>      > loadedNamespaces()
>     [1] "base"      "datasets"  "graphics"  "grDevices" "methods"   "stats"
>     [7] "utils"
>      > unloadNamespace("tseries") # loads zoo ?
>      > loadedNamespaces()
>       [1] "base"      "datasets"  "graphics"  "grDevices" "grid" "lattice"
>       [7] "methods"   "quadprog"  "stats"     "utils"     "zoo"
>      >
>
>     Somewhat related, is there an easy way to get back to a "clean"
>     state for loaded and attached things, as if R had just been started?
>     I'm trying to do this in a vignette so it is not easy to stop and
>     restart R.
>
>     Paul
>
>     ________________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


From wdunlap at tibco.com  Fri Jan  9 23:50:32 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 9 Jan 2015 14:50:32 -0800
Subject: [Rd] as.hexmode(big number) fails in R-3.1.2
Message-ID: <CAF8bMcYx7gWO=7EM-x+1MTgKf_TO4Hkxd60aURCY-E0=usnK9w@mail.gmail.com>

There was recently a discussion here on how to tell if a number was
integral.
Did that prod someone into change as.hexmode in R-3.1.2 so that it aborts if
given a number to big to fit into a 32-bit integer?  It returned NA, with
two warnings
in R-3.1.1.

% R-3.1.2 --quiet --vanilla
> as.hexmode(c(10^c(0,9,18)))
Error in if (is.double(x) && all(is.na(x) | x == as.integer(x))) x <-
as.integer(x) :
  missing value where TRUE/FALSE needed
In addition: Warning message:
In as.hexmode(c(10^c(0, 9, 18))) : NAs introduced by coercion
> q()

% R-3.1.1 --quiet --vanilla
> as.hexmode(c(10^c(0,9,18)))
[1] "00000001" "3b9aca00" NA
Warning messages:
1: In as.hexmode(c(10^c(0, 9, 18))) : NAs introduced by coercion
2: In as.hexmode(c(10^c(0, 9, 18))) : NAs introduced by coercion

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Sun Jan 11 02:04:46 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 10 Jan 2015 17:04:46 -0800
Subject: [Rd] Shouldn't grDevices::quartz() give an error instead of a
 warning when not available?
Message-ID: <CAFDcVCTYTZZHVV13QABz7h7HeG_Q=KYGe-6_GhEA_KXzVaGspA@mail.gmail.com>

Compare:

> quartz(); cat("Should this have generated an error instead?\n")
Warning message:
In quartz() : Quartz device is not available on this platform
Should this have generated an error instead?

to:

> x11()
Error in .External2(C_X11, d$display, d$width, d$height, d$pointsize,  :
  unable to start device X11cairo
In addition: Warning message:
In x11() : unable to open connection to X11 display ''

Wouldn't it make sense that a failed call to quartz() would give an
error instead?

> sessionInfo()
R Under development (unstable) (2015-01-09 r67397)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

/Henrik


From thosjleeper at gmail.com  Sun Jan 11 14:34:34 2015
From: thosjleeper at gmail.com (Thomas J. Leeper)
Date: Sun, 11 Jan 2015 14:34:34 +0100
Subject: [Rd] Bug in URLencode and patch
Message-ID: <CAOC91MQM-bnWQsSnSxTQQjy9FtMtbvfr+uztgy3MByXa-Qd8EA@mail.gmail.com>

I believe the implementation of utils::URLencode is non-compliant with
RFC 3986, which it claims to implement
(http://tools.ietf.org/html/rfc3986). Specifically, its percent
encoding uses lowercase letters a-f, which it should use uppercase
letters A-F.

Here's what URLencode currently produces:

library("utils")
URLencode("*+,;=:/?", reserved = TRUE)
# "%2a%2b%2c%3b%3d%3a%2f%3f"

According to RFC 3986 (references below), these should be uppercase:

toupper(URLencode("*+,;=:/?", reserved = TRUE))
# "%2A%2B%2C%3B%3D%3A%2F%3F"


This is a problem for me because I'm working with a web API that
authenticates using, in part, a hashed version of the URL-escaped
query arguments and this bug yields different hashes even though the
URLs are substantively the same. Here's a trivial example using just a
colon:

library("digest")
URLencode(":", reserved = TRUE)
# [1] "%3a"
digest("%3a")
# [1] "77fff19a933ae715d006469545892caf"
digest("%3A")
# [1] "8f270f6ac6fe3260f52293ea1d911093"

As an aside, I know that RCurl::curlEscape implements this correctly,
but I don't see any reason why URLencode shouldn't comply with RFC
3986.


The fix should be relatively simple. Here's updated code for URLencode
that simply adds a call to `toupper`:

function (URL, reserved = FALSE)
{
    OK <- paste0("[^", if (!reserved)
        "][!$&'()*+,;=:/?@#", "ABCDEFGHIJKLMNOPQRSTUVWXYZ",
"abcdefghijklmnopqrstuvwxyz0123456789._~-",
        "]")
    x <- strsplit(URL, "")[[1L]]
    z <- grep(OK, x)
    if (length(z)) {
        y <- sapply(x[z], function(x) paste0("%",
toupper(as.character(charToRaw(x))),
            collapse = ""))
        x[z] <- y
    }
    paste(x, collapse = "")
}


The relevant parts of RFC 3986 are (emphasis added):
2.1: "The uppercase hexadecimal digits 'A' through 'F' are equivalent
to the lowercase digits 'a' through 'f', respectively.  If two URIs
differ only in the case of hexadecimal digits used in percent-encoded
octets, they are equivalent.  For consistency, URI producers and
normalizers should use **uppercase** hexadecimal digits for all
percent-encodings."

6.2.2.1: "For all URIs, the hexadecimal digits within a
percent-encoding triplet (e.g., "%3a" versus "%3A") are
case-insensitive and therefore should be normalized to use
**uppercase** letters for the digits A-F."


Best,
-Thomas


Thomas J. Leeper
http://www.thomasleeper.com


From luke-tierney at uiowa.edu  Sun Jan 11 20:25:01 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 11 Jan 2015 13:25:01 -0600
Subject: [Rd] Cost of garbage collection seems excessive
In-Reply-To: <CAFAN8vwG8tBipqKTbgrdSUKgxoQJqiWB-46qXhH+n4Zf_buqWg@mail.gmail.com>
References: <CAFAN8vwG8tBipqKTbgrdSUKgxoQJqiWB-46qXhH+n4Zf_buqWg@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1501111323470.24557@luke-Latitude>

This is a known issue that is being looked into. The primary culprit
seems to be the case labels that are created and need to be scanned by
the GC.

Best,

luke

On Fri, 9 Jan 2015, Nathan Kurz wrote:

> When doing repeated regressions on large data sets, I'm finding that
> the time spent on garbage collection often exceeds the time spent on
> the regression itself.   Consider this test program which I'm running
> on  an Intel Haswell i7-4470 processor under Linux 3.13 using R 3.1.2
> compiled with ICPC 14.1:
>
> nate at haswell:~$ cat > gc.R
>  library(speedglm)
>  createData <- function(n) {
>      int <- -5
>      x <- rnorm(n, 50, 7)
>      e <- rnorm(n, 0, 1)
>      y <- int + (1.2 * x) + e
>      return(data.frame(y, x))
>  }
> gc.time()
> data <- createData(500000)
> data.y <- as.matrix(data[1])
> data.x <- model.matrix(y ~ ., data)
> for (i in 1:100) speedglm.wfit(X=data.x, y=data.y, family=gaussian())
> gc.time()
>
> nate at haswell:~$ time Rscript gc.R
> Loading required package: Matrix
> Loading required package: methods
> [1] 0 0 0 0 0
> [1] 10.410  0.024 10.441  0.000  0.000
> real 0m17.167s
> user 0m16.996s
> sys 0m0.176s
>
> The total execution time is 17 seconds, and the time spent on garbage
> collection is almost 2/3 of that.  My actual use case is a package
> that creates an ensemble from a variety of cross-validated
> regressions, and exhibits the same poor performance. Is this expected
> behavior?
>
> I've found that I can reduce the garbage collection time to a
> tolerable level by setting the R_VSIZE environment value to a large
> enough value:
>
> nate at haswell:~$ time R_VSIZE=1GB Rscript gc.R
> Loading required package: Matrix
> Loading required package: methods
> [1] 0 0 0 0 0
> [1] 0.716 0.025 0.739 0.000 0.000
> real 0m7.694s
> user 0m7.388s
> sys 0m0.309s
>
> I can do slightly better with even higher values, and by using
> R_GC_MEM_GROW=3.  But while using the environment variables solves the
> issue for me, I fear that the end users of my package won't be able to
> set them.   Is there a way that I can achieve the higher performance
> from within R rather than from the command line?
>
> Thanks!
>
> --nate
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From avraham.adler at gmail.com  Mon Jan 12 18:40:22 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 12 Jan 2015 12:40:22 -0500
Subject: [Rd] New version of Rtools for Windows
Message-ID: <CAL6gwnLTKE=dKxwFYhiWxgpL+FT0RNkD4LqnsQMJwtPXTkdcaA@mail.gmail.com>

On Fri, Jan 9, 2015 at 12:19 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 09/01/2015 10:56 AM, Henric Winell wrote:
>> On 2015-01-08 02:31, Duncan Murdoch wrote:
>>
>>> On 07/01/2015 5:20 PM, Jeroen Ooms wrote:
>>>> On Wed, Jan 7, 2015 at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>>
>>>>> This version includes only minor updates to the tools.  I indicated last summer that I was hoping to update GCC from the current version 4.6.3 before the R 3.2.0 release, but this now looks unlikely, unless someone else with experience building it can help.
>>>>
>>>> I have been looking into this a bit over the past few months, also
>>>> with mixed success. Nevertheless, below some experiences that might be
>>>> worth sharing.
>>>>
>>>> The guys from mingw-w64 recommended (quite strongly) to move away from
>>>> multilib. They explained that the standard approach is to create two
>>>> separate toolchains; one that targets win32 and the other one that
>>>> targets win64 (both tool chains can compiled for win32). Hence the
>>>> only difference for R would be that instead of passing "-m64" and
>>>> "-m32", it would need to set the path to the proper compiler.
>>>>
>>>> There are several initiatives that provide very complete suites of
>>>> precompiled mingw-w64 tools. I think the ideal scenario would be if we
>>>> could take advantage of an existing tool chain as we do on other
>>>> platforms, although perhaps I do not fully understand the R-specific
>>>> requirements on the windows compiler.
>>>
>>> I feel quite strongly that we need to be able to build the toolchain,
>>> rather than relying on binaries produced by others.  We may need to
>>> customize the toolchain, or we may need to rebuild it when a bug is
>>> identified.  Lots of binary builders abandon their builds and you can't
>>> count on them to solve problems at a later date.
>>>
>>>>
>>>> One project that looks very promising is msys2 [1,2]. It has a package
>>>> manager (port of pacman from arch linux) and comes with a pretty
>>>> complete set of msys [3] and other [4] packages that seems quite well
>>>> maintained.
>>>
>>> Do they post complete instructions for building?  That's what I'm
>>> looking for.  I don't want to develop a build script (I don't know how),
>>> but I would like to have one.
>>
>> Have you looked at nuwen's distro (http://nuwen.net/mingw.html)?  It's
>> up-to-date (mingw-w64 3.3.0, binutils 2.25, GCC 4.9.2, ...) and includes
>> the build scripts.
>>
>
> No, I hadn't come across that one.  It looks quite promising. Thanks!



If it helps, after installing the nuwen distro and the latest version
of Rtools (for tar), both the release R-3.1.2 and R-patched (see [1])
builds stop on Windows7 64bit with the error below, probably related
to what Hin-Tak Leung said earlier. I can't even get to the point to
see if compat.c will fail.


windres -F pe-x86-64   -i dllversion.rc -o dllversion.o
comm: file 1 is not in sorted order
Makefile.win:29: recipe for target 'Rgraphapp.def' failed
make[4]: *** [Rgraphapp.def] Error 1
makefile:120: recipe for target 'rlibs' failed
make[3]: *** [rlibs] Error 1
makefile:179: recipe for target '../../bin/x64/R.dll' failed
make[2]: *** [../../bin/x64/R.dll] Error 2
makefile:104: recipe for target 'rbuild' failed
make[1]: *** [rbuild] Error 2
makefile:14: recipe for target 'all' failed
make: *** [all] Error 2

[1] https://stackoverflow.com/questions/12802723/comm-file-1-is-not-in-sorted-order-when-compiling-r-source-in-windows



>
> I also have another offer of help to put this together; I'll wait to see
> how that goes before announcing it.  But having two builds is better
> than one.
>
> Duncan Murdoch
>
>
>>
>> Henric
>>
>>
>>
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> The only issue I ran into with msys2 is that it uses a different c++
>>>> exception model (seh/dwarf) than the current Rtools (which uses sjlj).
>>>> See also [5]. Therefore, if a library uses exceptions, we cannot use
>>>> the current Rtools to link a static library that was created with
>>>> msys2  [6]. I am not sure if it also be a problem the other way
>>>> around, and if this is still the case for recent versions of
>>>> gcc/mingw.
>>>>
>>>> Finally, Ruby has build very similar to Rtools called DevKit-mingw64
>>>> [7] that we might be able to borrow from.
>>>>
>>>>
>>>> [1] https://msys2.github.io/
>>>> [2] http://stackoverflow.com/questions/25019057/how-are-msys-msys2-and-msysgit-related-to-each-other
>>>> [3] https://github.com/Alexpux/MSYS2-packages
>>>> [4] https://github.com/Alexpux/MINGW-packages
>>>> [5] http://stackoverflow.com/questions/15670169/what-is-difference-between-sjlj-vs-dwarf-vs-seh
>>>> [6] http://stackoverflow.com/questions/7751640/undefined-reference-to-gxx-personality-sj0
>>>> [7] http://rubyinstaller.org/downloads/
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fredhutch.org  Tue Jan 13 01:50:27 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 12 Jan 2015 16:50:27 -0800 (PST)
Subject: [Rd] R CMD build looking for texi2dvi in the wrong place (R-devel)
In-Reply-To: <1020728145.2843060.1421108526209.JavaMail.root@fredhutch.org>
Message-ID: <758779124.2843994.1421110227452.JavaMail.root@fredhutch.org>

R CMD build fails with recent R-devel because it is looking for texi2dvi in /usr/local/bin, but on this system, MacTex has installed it in /usr/bin.

$ R CMD build IRanges
* checking for file 'IRanges/DESCRIPTION' ... OK
* preparing 'IRanges':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to build vignettes
* creating vignettes ... ERROR
[...]
Warning in sub(object$syntax$docexpr, val, chunk[pos[1L]]) :
  argument 'replacement' has length > 1 and only the first element will be used
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
  Running 'texi2dvi' on 'IRangesOverview.tex' failed.
Messages:
sh: /usr/local/bin/texi2dvi: No such file or directory
Calls: <Anonymous> -> texi2pdf -> texi2dvi
Execution halted

That's with:

R Under development (unstable) (2015-01-11 r67421)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

The same command works without error on:

R Under development (unstable) (2014-11-11 r66970)
Platform: x86_64-apple-darwin13.4.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

Setting 
options(texi2dvi='/usr/bin/texi2dvi')

in my ~/.Rprofile did not help, I suspect because R CMD build runs buildVignettes() in a subprocess started with --vanilla. Creating a symlink from /usr/bin/texi2dvi to /usr/local/bin/texi2dvi gave me a "too many levels of symbolic links" error. Making it a hard link works, but seems like a real hack (what if the executable was not relocatable?). 

Thanks in advance,
Dan


From simon.urbanek at r-project.org  Tue Jan 13 02:50:35 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 12 Jan 2015 20:50:35 -0500
Subject: [Rd] R CMD build looking for texi2dvi in the wrong place
	(R-devel)
In-Reply-To: <758779124.2843994.1421110227452.JavaMail.root@fredhutch.org>
References: <758779124.2843994.1421110227452.JavaMail.root@fredhutch.org>
Message-ID: <9553C20C-9002-4960-99CE-0030655C948E@r-project.org>

Dan,

On Jan 12, 2015, at 7:50 PM, Dan Tenenbaum <dtenenba at fredhutch.org> wrote:

> R CMD build fails with recent R-devel because it is looking for texi2dvi in /usr/local/bin, but on this system, MacTex has installed it in /usr/bin.
> 

No, you're looking at the wrong package - texi2dvi comes from texinfo which is now mandatory in version 5.2+ located in /usr/local since OS X comes with an old version. You should install it from

http://r.research.att.com/libs/texinfo-5.2-darwin10.tar.gz

Cheers,
Simon



> $ R CMD build IRanges
> * checking for file 'IRanges/DESCRIPTION' ... OK
> * preparing 'IRanges':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * installing the package to build vignettes
> * creating vignettes ... ERROR
> [...]
> Warning in sub(object$syntax$docexpr, val, chunk[pos[1L]]) :
>  argument 'replacement' has length > 1 and only the first element will be used
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
>  Running 'texi2dvi' on 'IRangesOverview.tex' failed.
> Messages:
> sh: /usr/local/bin/texi2dvi: No such file or directory
> Calls: <Anonymous> -> texi2pdf -> texi2dvi
> Execution halted
> 
> That's with:
> 
> R Under development (unstable) (2015-01-11 r67421)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.9.5 (Mavericks)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base 
> 
> The same command works without error on:
> 
> R Under development (unstable) (2014-11-11 r66970)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> Setting 
> options(texi2dvi='/usr/bin/texi2dvi')
> 
> in my ~/.Rprofile did not help, I suspect because R CMD build runs buildVignettes() in a subprocess started with --vanilla. Creating a symlink from /usr/bin/texi2dvi to /usr/local/bin/texi2dvi gave me a "too many levels of symbolic links" error. Making it a hard link works, but seems like a real hack (what if the executable was not relocatable?). 
> 
> Thanks in advance,
> Dan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From dtenenba at fredhutch.org  Tue Jan 13 03:26:43 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 12 Jan 2015 18:26:43 -0800 (PST)
Subject: [Rd] R CMD build looking for texi2dvi in the wrong place
 (R-devel)
In-Reply-To: <9553C20C-9002-4960-99CE-0030655C948E@r-project.org>
Message-ID: <1345239248.2846099.1421116003796.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Simon Urbanek" <simon.urbanek at r-project.org>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Monday, January 12, 2015 5:50:35 PM
> Subject: Re: [Rd] R CMD build looking for texi2dvi in the wrong place (R-devel)
> 
> Dan,
> 
> On Jan 12, 2015, at 7:50 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
> wrote:
> 
> > R CMD build fails with recent R-devel because it is looking for
> > texi2dvi in /usr/local/bin, but on this system, MacTex has
> > installed it in /usr/bin.
> > 
> 
> No, you're looking at the wrong package - texi2dvi comes from texinfo
> which is now mandatory in version 5.2+ located in /usr/local since
> OS X comes with an old version. You should install it from
> 
> http://r.research.att.com/libs/texinfo-5.2-darwin10.tar.gz
> 

Thanks, was there an announcement that I missed about this and if so, where was it? 

Dan



> Cheers,
> Simon
> 
> 
> 
> > $ R CMD build IRanges
> > * checking for file 'IRanges/DESCRIPTION' ... OK
> > * preparing 'IRanges':
> > * checking DESCRIPTION meta-information ... OK
> > * cleaning src
> > * installing the package to build vignettes
> > * creating vignettes ... ERROR
> > [...]
> > Warning in sub(object$syntax$docexpr, val, chunk[pos[1L]]) :
> >  argument 'replacement' has length > 1 and only the first element
> >  will be used
> > Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
> > quiet,  :
> >  Running 'texi2dvi' on 'IRangesOverview.tex' failed.
> > Messages:
> > sh: /usr/local/bin/texi2dvi: No such file or directory
> > Calls: <Anonymous> -> texi2pdf -> texi2dvi
> > Execution halted
> > 
> > That's with:
> > 
> > R Under development (unstable) (2015-01-11 r67421)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > Running under: OS X 10.9.5 (Mavericks)
> > 
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> >   base
> > 
> > The same command works without error on:
> > 
> > R Under development (unstable) (2014-11-11 r66970)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > 
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> >   base
> > 
> > Setting
> > options(texi2dvi='/usr/bin/texi2dvi')
> > 
> > in my ~/.Rprofile did not help, I suspect because R CMD build runs
> > buildVignettes() in a subprocess started with --vanilla. Creating
> > a symlink from /usr/bin/texi2dvi to /usr/local/bin/texi2dvi gave
> > me a "too many levels of symbolic links" error. Making it a hard
> > link works, but seems like a real hack (what if the executable was
> > not relocatable?).
> > 
> > Thanks in advance,
> > Dan
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
>


From murdoch.duncan at gmail.com  Tue Jan 13 05:40:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 12 Jan 2015 20:40:07 -0800
Subject: [Rd] R CMD build looking for texi2dvi in the wrong place
	(R-devel)
In-Reply-To: <1345239248.2846099.1421116003796.JavaMail.root@fredhutch.org>
References: <1345239248.2846099.1421116003796.JavaMail.root@fredhutch.org>
Message-ID: <54B4A1A7.5020209@gmail.com>

On 12/01/2015 6:26 PM, Dan Tenenbaum wrote:
> 
> 
> ----- Original Message -----
>> From: "Simon Urbanek" <simon.urbanek at r-project.org>
>> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
>> Cc: "R-devel" <r-devel at r-project.org>
>> Sent: Monday, January 12, 2015 5:50:35 PM
>> Subject: Re: [Rd] R CMD build looking for texi2dvi in the wrong place (R-devel)
>>
>> Dan,
>>
>> On Jan 12, 2015, at 7:50 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
>> wrote:
>>
>>> R CMD build fails with recent R-devel because it is looking for
>>> texi2dvi in /usr/local/bin, but on this system, MacTex has
>>> installed it in /usr/bin.
>>>
>>
>> No, you're looking at the wrong package - texi2dvi comes from texinfo
>> which is now mandatory in version 5.2+ located in /usr/local since
>> OS X comes with an old version. You should install it from
>>
>> http://r.research.att.com/libs/texinfo-5.2-darwin10.tar.gz
>>
> 
> Thanks, was there an announcement that I missed about this and if so, where was it? 

It has been in the NEWS file since Jan 6.  You can see it there, and
would have seen it announced here:

http://developer.r-project.org/blosxom.cgi/R-devel/2015/01/06#n2015-01-06

Duncan Murdoch


From dtenenba at fredhutch.org  Tue Jan 13 05:47:37 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 12 Jan 2015 20:47:37 -0800 (PST)
Subject: [Rd] R CMD build looking for texi2dvi in the wrong place
 (R-devel)
In-Reply-To: <54B4A1A7.5020209@gmail.com>
Message-ID: <1797509364.2847735.1421124457846.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>, "Simon Urbanek" <simon.urbanek at r-project.org>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Monday, January 12, 2015 8:40:07 PM
> Subject: Re: [Rd] R CMD build looking for texi2dvi in the wrong place (R-devel)
> 
> On 12/01/2015 6:26 PM, Dan Tenenbaum wrote:
> > 
> > 
> > ----- Original Message -----
> >> From: "Simon Urbanek" <simon.urbanek at r-project.org>
> >> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> >> Cc: "R-devel" <r-devel at r-project.org>
> >> Sent: Monday, January 12, 2015 5:50:35 PM
> >> Subject: Re: [Rd] R CMD build looking for texi2dvi in the wrong
> >> place (R-devel)
> >>
> >> Dan,
> >>
> >> On Jan 12, 2015, at 7:50 PM, Dan Tenenbaum
> >> <dtenenba at fredhutch.org>
> >> wrote:
> >>
> >>> R CMD build fails with recent R-devel because it is looking for
> >>> texi2dvi in /usr/local/bin, but on this system, MacTex has
> >>> installed it in /usr/bin.
> >>>
> >>
> >> No, you're looking at the wrong package - texi2dvi comes from
> >> texinfo
> >> which is now mandatory in version 5.2+ located in /usr/local since
> >> OS X comes with an old version. You should install it from
> >>
> >> http://r.research.att.com/libs/texinfo-5.2-darwin10.tar.gz
> >>
> > 
> > Thanks, was there an announcement that I missed about this and if
> > so, where was it?
> 
> It has been in the NEWS file since Jan 6.  You can see it there, and
> would have seen it announced here:
> 
> http://developer.r-project.org/blosxom.cgi/R-devel/2015/01/06#n2015-01-06
> 

Thanks, I'll subscribe to these feeds.
Dan


> Duncan Murdoch
>


From balbi at kernel.org  Tue Jan 13 06:00:28 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 12 Jan 2015 23:00:28 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
Message-ID: <1421125228-5822-1-git-send-email-balbi@kernel.org>

git has an interface for cloning SVN repositories into git which
some users might decide to use. For those users' surprise, the
repository will always fail to build on svnonly target and it will
exit early.

The problem is simple enough to fix by just checking if a .git
directory exists in top_builddir and, if so, call git svn info insstead
of svn info.

Signed-off-by: Felipe Balbi <balbi at kernel.org>
---

Patch generated with git. Let me know if there are any formatting
changes you guys might want.

 Makefile.in | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/Makefile.in b/Makefile.in
index 44b0a3b4b99f..221c437972ad 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -9,6 +9,9 @@ top_builddir = .
 
 include $(top_builddir)/Makeconf
 
+GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
+	echo "git"; fi)
+
 distdir = $(PACKAGE)-$(VERSION)
 INSTFILES = COPYING
 NON_SVN_INSTFILES = SVN-REVISION
@@ -104,7 +107,7 @@ svnonly:
 	@if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
 	  (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
 	  touch non-tarball ; \
-	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
+	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \
 	    | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
 	    | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
 	  if test "`cat SVN-REVISION-tmp`" = "Revision: -99"; then \
-- 
2.2.0


From edd at debian.org  Tue Jan 13 16:30:47 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 13 Jan 2015 09:30:47 -0600
Subject: [Rd] Request for help with UBSAN and total absense of CRAN response
Message-ID: <21685.14887.946988.975035@max.nulle.part>


CRAN has a package of mine in upload limbo because it failed UBSAN.

I am not entirely ignorant on the topic of sanitizers and SAN / ASAN / UBSAN;
we created not one but two Docker containers with ASAN and USBAN:

   https://registry.hub.docker.com/u/rocker/r-devel-san/
   https://registry.hub.docker.com/u/rocker/r-devel-ubsan-clang/

as well as predecessors to them in earlier Docker repos.

Yet I fail to recreate the errors reported by CRAN:

   http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN-clang-trunk/RcppAnnoy/tests/runUnitTests.Rout
   http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN/RcppAnnoy/tests/runUnitTests.Rout

I asked politely (and twice) for help with the corresponding compiler
configuration(s).  But CRAN is of course way above communicating with mere
mortals such as yours truly.

So I have no recourse other than to spam all of you: if anybody here has a
working UBSAN setup which can replicate the issue seen in the (rather small)
RcppAnnoy package?

Erik (upstream for Annoy, CC'ed) and I would be most grateful.  We do not
like being held hostage on an error report we cannot replicate and for which
we do not receive any help (or even further communication) whatsoever.

Dirk
about to turn into yet another frustrated CRAN user

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From avraham.adler at gmail.com  Tue Jan 13 17:19:05 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 13 Jan 2015 11:19:05 -0500
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
	response
In-Reply-To: <21685.14887.946988.975035@max.nulle.part>
References: <21685.14887.946988.975035@max.nulle.part>
Message-ID: <CAL6gwnKEbABwcaK2FuEM_f18apteFPyWCon9h_GkYjkTMBeTTA@mail.gmail.com>

Hello, Dirk.

I have no experience with UBSAN etc., but as you mention not being
able to recreate the CRAN errors, it reminds me of the time I had
trouble getting my pacakge approved for CRAN as it passed all tets but
Win32, and I have a Win64 setup and could not test it. Have you tried
submitting the package to
<http://win-builder.r-project.org/upload.aspx> and seeing if the CRAN
errors get created there, or is the problem CRAN shows on platforms
other than Windows?

Avi

On Tue, Jan 13, 2015 at 10:30 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> CRAN has a package of mine in upload limbo because it failed UBSAN.
>
> I am not entirely ignorant on the topic of sanitizers and SAN / ASAN / UBSAN;
> we created not one but two Docker containers with ASAN and USBAN:
>
>    https://registry.hub.docker.com/u/rocker/r-devel-san/
>    https://registry.hub.docker.com/u/rocker/r-devel-ubsan-clang/
>
> as well as predecessors to them in earlier Docker repos.
>
> Yet I fail to recreate the errors reported by CRAN:
>
>    http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN-clang-trunk/RcppAnnoy/tests/runUnitTests.Rout
>    http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN/RcppAnnoy/tests/runUnitTests.Rout
>
> I asked politely (and twice) for help with the corresponding compiler
> configuration(s).  But CRAN is of course way above communicating with mere
> mortals such as yours truly.
>
> So I have no recourse other than to spam all of you: if anybody here has a
> working UBSAN setup which can replicate the issue seen in the (rather small)
> RcppAnnoy package?
>
> Erik (upstream for Annoy, CC'ed) and I would be most grateful.  We do not
> like being held hostage on an error report we cannot replicate and for which
> we do not receive any help (or even further communication) whatsoever.
>
> Dirk
> about to turn into yet another frustrated CRAN user
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fredhutch.org  Tue Jan 13 17:21:16 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Tue, 13 Jan 2015 08:21:16 -0800 (PST)
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
 response
In-Reply-To: <21685.14887.946988.975035@max.nulle.part>
Message-ID: <1772006589.2855908.1421166076221.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Dirk Eddelbuettel" <edd at debian.org>
> To: r-devel at r-project.org
> Cc: "Erik Bernhardsson" <erik at malfunction.org>, "Dirk Eddelbuettel" <edd at debian.org>
> Sent: Tuesday, January 13, 2015 7:30:47 AM
> Subject: [Rd] Request for help with UBSAN and total absense of CRAN response
> 
> 
> CRAN has a package of mine in upload limbo because it failed UBSAN.
> 
> I am not entirely ignorant on the topic of sanitizers and SAN / ASAN
> / UBSAN;
> we created not one but two Docker containers with ASAN and USBAN:
> 
>    https://registry.hub.docker.com/u/rocker/r-devel-san/
>    https://registry.hub.docker.com/u/rocker/r-devel-ubsan-clang/
> 
> as well as predecessors to them in earlier Docker repos.
> 
> Yet I fail to recreate the errors reported by CRAN:
> 
>    http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN-clang-trunk/RcppAnnoy/tests/runUnitTests.Rout
>    http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN/RcppAnnoy/tests/runUnitTests.Rout
> 
> I asked politely (and twice) for help with the corresponding compiler
> configuration(s).  But CRAN is of course way above communicating with
> mere
> mortals such as yours truly.
> 
> So I have no recourse other than to spam all of you: if anybody here
> has a
> working UBSAN setup which can replicate the issue seen in the (rather
> small)
> RcppAnnoy package?
> 

Where should the package source be downloaded from? I see it in CRAN (but presumably the latest version that causes the issue is not yet downloadable) and in github.

Dan

> Erik (upstream for Annoy, CC'ed) and I would be most grateful.  We do
> not
> like being held hostage on an error report we cannot replicate and
> for which
> we do not receive any help (or even further communication)
> whatsoever.
> 
> Dirk
> about to turn into yet another frustrated CRAN user
> 
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Tue Jan 13 17:34:52 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 13 Jan 2015 10:34:52 -0600
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
 response
In-Reply-To: <1772006589.2855908.1421166076221.JavaMail.root@fredhutch.org>
References: <21685.14887.946988.975035@max.nulle.part>
	<1772006589.2855908.1421166076221.JavaMail.root@fredhutch.org>
Message-ID: <21685.18732.472328.631906@max.nulle.part>


On 13 January 2015 at 08:21, Dan Tenenbaum wrote:
| Where should the package source be downloaded from? I see it in CRAN (but presumably the latest version that causes the issue is not yet downloadable) and in github.

The "presumable" assumption is incorrect AFAIK. 

The error should presumably came up in both versions as annoylib.h did not
change there.  Feel free to prove me wrong :) and just use whatever is easiest.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From keith at wehi.EDU.AU  Wed Jan 14 06:50:40 2015
From: keith at wehi.EDU.AU (Keith Satterley)
Date: Wed, 14 Jan 2015 16:50:40 +1100
Subject: [Rd] Is the tcltk failure in affylmGUI related to R bug 15957
Message-ID: <54B603B0.9090607@wehi.edu.au>

I maintain the package affylmGUI. It works when installed on many 
previous versions of R. I have today tested exactly the same code under 
R-2.15.3, R-3.0.2, R-3.1.0, R-3.1.1, R-3.1.2 and R-devel.

I have also tested the versions of affylmGUI downloaded by biocLite for 
each version of R and the same result applies.

I have no errors under 2.15.3, 3.0.2, 3.1.0 and 3.1.1. The following 
error occurs under 3.1.2 and R-devel.

I run affylmGUI and read a targets file which then causes affylmGUI to 
read the specified cel files. On attempting to display the RNA targets 
file in a Tk window using the "RNA Targets" option from the "RNA 
Targets" Menu item and the following errors occur:

Error text box 1: Error in eval(substitute(expr),enclos):could not find 
function "<-"   - pressed OK
Following error text box: Error in paste("::RTcl",n,sep=""): object 'n' 
not found   - pressed OK
Following error text box: Error in assign(name, NULL, environ = I$env): 
object 'name' not found   - pressed OK
Following error text box: Error in paste("set",name, "(0,0)\"\"",sep= 
""):object 'name' not found   - pressed OK

This then results in an unfilled Tk window.

I am testing on a Windows 7, 64 bit environment. My sessionInfo is:

R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
locale:
[1] LC_COLLATE=English_Australia.1252 LC_CTYPE=English_Australia.1252 
LC_MONETARY=English_Australia.1252
[4] LC_NUMERIC=C LC_TIME=English_Australia.1252
attached base packages:
  [1] stats4    parallel  tcltk     stats     graphics  grDevices 
utils     datasets  methods   base
other attached packages:
  [1] affylmGUI_1.40.0      AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4    
IRanges_2.0.1         S4Vectors_0.4.0
  [6] xtable_1.7-4          R2HTML_2.3.1 affyPLM_1.42.0        
preprocessCore_1.28.0 gcrma_2.38.0
[11] tkrplot_0.0-23        affyio_1.34.0 BiocInstaller_1.16.1  
affy_1.44.0           Biobase_2.26.0
[16] BiocGenerics_0.12.1   limma_3.22.3
loaded via a namespace (and not attached):
[1] Biostrings_2.34.1 DBI_0.3.1         RSQLite_1.0.0 splines_3.1.2     
XVector_0.6.0     zlibbioc_1.12.0

I think the relevant code that is resulting in the error is generated by 
this function in main.R:
tclArrayVar <- function(){
     Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))
     Try(name <- paste("::RTcl", n,sep = ""))
     Try(l <- list(env = new.env()))
     Try(assign(name, NULL, envir = l$env))
     Try(reg.finalizer(l$env, function(env) tcl("unset", ls(env))))
     Try(class(l) <- "tclArrayVar")
     Try(.Tcl(paste("set ",name,"(0,0) \"\"",sep="")))
     l  ### Investigate this line KS
} #end of tclArrayVar <- function()

This code is lines 877-886 in main.R

Despite the un-investigated last line in this function, it works fine in 
earlier versions of R as described above.

The original programmer has left our division some years ago and I have 
maintained the code since then. Consequently my understandings as to why 
the code was written the way it was is somewhat limited, so I have not 
touched anything unless it was broken.

My question is, do I need to do something with the affylmGUI code? I'd 
appreciate some advice if so.

Is this failure related to bug 15957 
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15957) that Duncan 
fixed on 2014-09-08.

cheers,

Keith
==============================
Keith Satterley
Bioinformatics Division
The Walter & Eliza Hall Institute of Medical Research
Melbourne, Victoria, Australia
==============================


______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From michal.burda at osu.cz  Wed Jan 14 08:42:41 2015
From: michal.burda at osu.cz (Michal Burda)
Date: Wed, 14 Jan 2015 08:42:41 +0100
Subject: [Rd] R CMD check: "..." used in a situation where it does not exist
Message-ID: <CAP4zaHMeGiRLP=ZB9Yg=dOjZLS3J4BG8kqHD2=t1g8S3fQKnxg@mail.gmail.com>

Dear R developers,

when running R CMD check, the R Under development (unstable)
(2015-01-13 r67453) gives me the following NOTE:


cbind.fsets: possible error in list(...): ... used in a situation
where it does not exist


The file that causes this note contains:


cbind.fsets <- function(..., deparse.level = 1) {
    dots <- list(...)

    res <- NULL
    resVars <- NULL
    resSpecs <- NULL

    for (i in seq_along(dots)) {
        arg <- dots[[i]]
        argName <- names(dots)[i]

        if (!is.null(arg)) {
            if (!is.fsets(arg)) {
                stop("Function 'cbind.fsets' cannot bind arguments
that are not valid 'fsets' objects")
            }
            class(arg) <- setdiff(class(arg), 'fsets')
            if (is.null(res)) {
                resVars <- vars(arg)
                resSpecs <- specs(arg)
                res <- arg
            } else {
                resVarNames <- c(names(resVars), names(vars(arg)))
                resVars <- c(resVars, vars(arg))
                names(resVars) <- resVarNames

                o1 <- matrix(0, nrow=nrow(resSpecs), ncol=ncol(specs(arg)))
                o2 <- matrix(0, nrow=nrow(specs(arg)), ncol=ncol(resSpecs))
                resSpecs <- rbind(cbind(resSpecs, o1),
                                  cbind(o2, specs(arg)))
                colnames(resSpecs) <- names(resVars)
                rownames(resSpecs) <- names(resVars)
                res <- cbind(res, arg)
            }
        }
    }

    return(fsets(res, resVars, resSpecs))
}



I want to avoid any NOTES prior submitting my package to CRAN, but I
cannot find any information what is wrong with my code and how to get
rid of that message during R CMD check process.

Does anybody of you know what is wrong with my code?

Thank you, in advance.



Best regards,


Michal Burda
junior researcher


IT4Innovations NSC
Institute for Research and Applications of Fuzzy Modeling   |
University of Ostrava   |   IT4Innovations National Supercomputing
Center
30. dubna 22   |   701 03  Ostrava   |   Czech Republic
e-mail: michal.burda at osu.cz  |   web IRAFM: irafm.osu.cz  |   web
IT4I: it4i.cz  |   phone: +420 597 09 1450


From h.wickham at gmail.com  Wed Jan 14 13:47:51 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 14 Jan 2015 06:47:51 -0600
Subject: [Rd] R CMD check: "..." used in a situation where it does not
	exist
In-Reply-To: <CAP4zaHMeGiRLP=ZB9Yg=dOjZLS3J4BG8kqHD2=t1g8S3fQKnxg@mail.gmail.com>
References: <CAP4zaHMeGiRLP=ZB9Yg=dOjZLS3J4BG8kqHD2=t1g8S3fQKnxg@mail.gmail.com>
Message-ID: <CABdHhvHzJB=oxpaSq4fmww691hk5yfc9oteMsqRbhSCaASToUA@mail.gmail.com>

I think this is bug in R CMD check code.  I get a similar error:

rule: possible error in paste0(...): ... used in a situation where it
  does not exist

for the simple:

rule <- function(..., pad = "-") {
  if (nargs() == 0) {
    title <- ""
  } else {
    title <- paste0(...)
  }
  width <- getOption("width") - nchar(title) - 1
  message(title, " ", paste(rep(pad, width, collapse = "")))
}

where ... clearly does exist.

I skimmed the commits for the last couple of days - the most relevant
would seem to be this one by Michael Lawrence:
https://github.com/wch/r-source/commit/d3a42dabccb23462aa1e0a1edad00450f0a6131c
(but I might've missed others - many of the commit messages are not
terribly explanatory)

Hadley

On Wed, Jan 14, 2015 at 1:42 AM, Michal Burda <michal.burda at osu.cz> wrote:
> Dear R developers,
>
> when running R CMD check, the R Under development (unstable)
> (2015-01-13 r67453) gives me the following NOTE:
>
>
> cbind.fsets: possible error in list(...): ... used in a situation
> where it does not exist
>
>
> The file that causes this note contains:
>
>
> cbind.fsets <- function(..., deparse.level = 1) {
>     dots <- list(...)
>
>     res <- NULL
>     resVars <- NULL
>     resSpecs <- NULL
>
>     for (i in seq_along(dots)) {
>         arg <- dots[[i]]
>         argName <- names(dots)[i]
>
>         if (!is.null(arg)) {
>             if (!is.fsets(arg)) {
>                 stop("Function 'cbind.fsets' cannot bind arguments
> that are not valid 'fsets' objects")
>             }
>             class(arg) <- setdiff(class(arg), 'fsets')
>             if (is.null(res)) {
>                 resVars <- vars(arg)
>                 resSpecs <- specs(arg)
>                 res <- arg
>             } else {
>                 resVarNames <- c(names(resVars), names(vars(arg)))
>                 resVars <- c(resVars, vars(arg))
>                 names(resVars) <- resVarNames
>
>                 o1 <- matrix(0, nrow=nrow(resSpecs), ncol=ncol(specs(arg)))
>                 o2 <- matrix(0, nrow=nrow(specs(arg)), ncol=ncol(resSpecs))
>                 resSpecs <- rbind(cbind(resSpecs, o1),
>                                   cbind(o2, specs(arg)))
>                 colnames(resSpecs) <- names(resVars)
>                 rownames(resSpecs) <- names(resVars)
>                 res <- cbind(res, arg)
>             }
>         }
>     }
>
>     return(fsets(res, resVars, resSpecs))
> }
>
>
>
> I want to avoid any NOTES prior submitting my package to CRAN, but I
> cannot find any information what is wrong with my code and how to get
> rid of that message during R CMD check process.
>
> Does anybody of you know what is wrong with my code?
>
> Thank you, in advance.
>
>
>
> Best regards,
>
>
> Michal Burda
> junior researcher
>
>
> IT4Innovations NSC
> Institute for Research and Applications of Fuzzy Modeling   |
> University of Ostrava   |   IT4Innovations National Supercomputing
> Center
> 30. dubna 22   |   701 03  Ostrava   |   Czech Republic
> e-mail: michal.burda at osu.cz  |   web IRAFM: irafm.osu.cz  |   web
> IT4I: it4i.cz  |   phone: +420 597 09 1450
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Wed Jan 14 14:30:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Jan 2015 05:30:18 -0800
Subject: [Rd] R CMD check: "..." used in a situation where it does not
 exist
In-Reply-To: <CABdHhvHzJB=oxpaSq4fmww691hk5yfc9oteMsqRbhSCaASToUA@mail.gmail.com>
References: <CAP4zaHMeGiRLP=ZB9Yg=dOjZLS3J4BG8kqHD2=t1g8S3fQKnxg@mail.gmail.com>
	<CABdHhvHzJB=oxpaSq4fmww691hk5yfc9oteMsqRbhSCaASToUA@mail.gmail.com>
Message-ID: <54B66F6A.5060905@gmail.com>

On 14/01/2015 4:47 AM, Hadley Wickham wrote:
> I think this is bug in R CMD check code.  I get a similar error:
> 
> rule: possible error in paste0(...): ... used in a situation where it
>   does not exist
> 
> for the simple:
> 
> rule <- function(..., pad = "-") {
>   if (nargs() == 0) {
>     title <- ""
>   } else {
>     title <- paste0(...)
>   }
>   width <- getOption("width") - nchar(title) - 1
>   message(title, " ", paste(rep(pad, width, collapse = "")))
> }
> 
> where ... clearly does exist.
> 
> I skimmed the commits for the last couple of days - the most relevant
> would seem to be this one by Michael Lawrence:
> https://github.com/wch/r-source/commit/d3a42dabccb23462aa1e0a1edad00450f0a6131c
> (but I might've missed others - many of the commit messages are not
> terribly explanatory)

Yes, it's a temporary bug in R-devel, not a problem in Michal's code.

Duncan Murdoch


From plummerm at iarc.fr  Wed Jan 14 16:49:05 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 14 Jan 2015 15:49:05 +0000
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
 response
In-Reply-To: <21685.18732.472328.631906@max.nulle.part>
References: <21685.14887.946988.975035@max.nulle.part>
	<1772006589.2855908.1421166076221.JavaMail.root@fredhutch.org>
	<21685.18732.472328.631906@max.nulle.part>
Message-ID: <1421250545.3943.43.camel@iarc.fr>

On Tue, 2015-01-13 at 10:34 -0600, Dirk Eddelbuettel wrote:
> On 13 January 2015 at 08:21, Dan Tenenbaum wrote:
> | Where should the package source be downloaded from? I see it in CRAN (but presumably the latest version that causes the issue is not yet downloadable) and in github.
> 
> The "presumable" assumption is incorrect AFAIK. 
> 
> The error should presumably came up in both versions as annoylib.h did not
> change there.  Feel free to prove me wrong :) and just use whatever is easiest.
> 
> Dirk

This is a curious case. 

Here is where the first error occurs:

Executing test function test01getNNsByVector  ... 
Breakpoint 1, 0x00000000009c0440 in __ubsan_handle_out_of_bounds ()
(gdb) frame 1
#1  0x00007fffe777935b in AnnoyIndex<int, float, Angular<int, float> >::_get_all_nns (this=0x3a7e8f0, v=0x37d95d0, n=3, result=0x7ffffffee1e8)
    at ../inst/include/annoylib.h:532
532		nns.insert(nns.end(), nd->children, &(nd->children[nd->n_descendants]));
(gdb) p nd->children
$48 = {0, 1}
(gdb) p nd->n_descendants
$49 = 3
(gdb) p nns
$50 = std::vector of length 0, capacity 0

So we are trying to insert 3 values from an array of length 2 into an
STL vector. 

Comments in the header file annoylib.h (lines 114-130) show that this is
a result of a "memory optimization". Small objects have a completely
different format but are allocated in the same memory. When the
optimization is used the array is deliberately allowed to overflow:

    S children[2]; // Will possibly store more than 2
    T v[1]; // We let this one overflow intentionally

A workaround is to turn off the optimization by reducing the threshold
for the alternate data format (_K) to such a low level that it is never
used (annoylib.h, line 259):

    //_K = (sizeof(T) * f + sizeof(S) * 2) / sizeof(S);
    _K = 2; //Turn off memory optimization

I think this is a case of "being too clever by half".

Martyn



-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From pdalgd at gmail.com  Wed Jan 14 20:04:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 14 Jan 2015 20:04:14 +0100
Subject: [Rd] Is the tcltk failure in affylmGUI related to R bug 15957
In-Reply-To: <54B603B0.9090607@wehi.edu.au>
References: <54B603B0.9090607@wehi.edu.au>
Message-ID: <9A2846D1-D6AF-4FC7-ABCC-D12270693C0F@gmail.com>

Seems unlikely that that particular bug is involved. I seem to recall some change related to inadvertent variable capture in .TkRoot$env (?). At any rate, we currently have

> parent.env(.TkRoot$env)
<environment: R_EmptyEnv>

which used to be

> parent.env(.TkRoot$env)
<environment: R_GlobalEnv>

as a result, this won't work any more because R_EmptyEnv has no operators and functions in it:

> evalq(x <- 1, .TkRoot$env)
Error in eval(substitute(expr), envir, enclos) : 
  could not find function "<-"

and consequently, you conk out at

   Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))

which presumably needs to be recoded in the same way as the current code in tclVar():

> tclVar
function (init = "") 
{
    n <- .TkRoot$env$TclVarCount <- .TkRoot$env$TclVarCount + 
        1L
    name <- paste0("::RTcl", n)
    l <- list(env = new.env())
    assign(name, NULL, envir = l$env)
    reg.finalizer(l$env, function(env) tcl("unset", ls(env)))
    class(l) <- "tclVar"
    tclvalue(l) <- init
    l
}

(The whole thing looks a bit odd: Your function clones a fair bit of tclVar, wrapping each line in Try() for no apparent reason (or?), with the apparent purpose of doing something that seems quite similar to what tclArray() already does...)

-pd


> On 14 Jan 2015, at 06:50 , Keith Satterley <keith at wehi.edu.au> wrote:
> 
> I maintain the package affylmGUI. It works when installed on many previous versions of R. I have today tested exactly the same code under R-2.15.3, R-3.0.2, R-3.1.0, R-3.1.1, R-3.1.2 and R-devel.
> 
> I have also tested the versions of affylmGUI downloaded by biocLite for each version of R and the same result applies.
> 
> I have no errors under 2.15.3, 3.0.2, 3.1.0 and 3.1.1. The following error occurs under 3.1.2 and R-devel.
> 
> I run affylmGUI and read a targets file which then causes affylmGUI to read the specified cel files. On attempting to display the RNA targets file in a Tk window using the "RNA Targets" option from the "RNA Targets" Menu item and the following errors occur:
> 
> Error text box 1: Error in eval(substitute(expr),enclos):could not find function "<-"   - pressed OK
> Following error text box: Error in paste("::RTcl",n,sep=""): object 'n' not found   - pressed OK
> Following error text box: Error in assign(name, NULL, environ = I$env): object 'name' not found   - pressed OK
> Following error text box: Error in paste("set",name, "(0,0)\"\"",sep= ""):object 'name' not found   - pressed OK
> 
> This then results in an unfilled Tk window.
> 
> I am testing on a Windows 7, 64 bit environment. My sessionInfo is:
> 
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> locale:
> [1] LC_COLLATE=English_Australia.1252 LC_CTYPE=English_Australia.1252 LC_MONETARY=English_Australia.1252
> [4] LC_NUMERIC=C LC_TIME=English_Australia.1252
> attached base packages:
> [1] stats4    parallel  tcltk     stats     graphics  grDevices utils     datasets  methods   base
> other attached packages:
> [1] affylmGUI_1.40.0      AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4    IRanges_2.0.1         S4Vectors_0.4.0
> [6] xtable_1.7-4          R2HTML_2.3.1 affyPLM_1.42.0        preprocessCore_1.28.0 gcrma_2.38.0
> [11] tkrplot_0.0-23        affyio_1.34.0 BiocInstaller_1.16.1  affy_1.44.0           Biobase_2.26.0
> [16] BiocGenerics_0.12.1   limma_3.22.3
> loaded via a namespace (and not attached):
> [1] Biostrings_2.34.1 DBI_0.3.1         RSQLite_1.0.0 splines_3.1.2     XVector_0.6.0     zlibbioc_1.12.0
> 
> I think the relevant code that is resulting in the error is generated by this function in main.R:
> tclArrayVar <- function(){
>    Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))
>    Try(name <- paste("::RTcl", n,sep = ""))
>    Try(l <- list(env = new.env()))
>    Try(assign(name, NULL, envir = l$env))
>    Try(reg.finalizer(l$env, function(env) tcl("unset", ls(env))))
>    Try(class(l) <- "tclArrayVar")
>    Try(.Tcl(paste("set ",name,"(0,0) \"\"",sep="")))
>    l  ### Investigate this line KS
> } #end of tclArrayVar <- function()
> 
> This code is lines 877-886 in main.R
> 
> Despite the un-investigated last line in this function, it works fine in earlier versions of R as described above.
> 
> The original programmer has left our division some years ago and I have maintained the code since then. Consequently my understandings as to why the code was written the way it was is somewhat limited, so I have not touched anything unless it was broken.
> 
> My question is, do I need to do something with the affylmGUI code? I'd appreciate some advice if so.
> 
> Is this failure related to bug 15957 (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15957) that Duncan fixed on 2014-09-08.
> 
> cheers,
> 
> Keith
> ==============================
> Keith Satterley
> Bioinformatics Division
> The Walter & Eliza Hall Institute of Medical Research
> Melbourne, Victoria, Australia
> ==============================
> 
> 
> ______________________________________________________________________
> The information in this email is confidential and =\ i...{{dropped:21}}


From peter.langfelder at gmail.com  Thu Jan 15 03:15:30 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 14 Jan 2015 18:15:30 -0800
Subject: [Rd] R under deveoplment CMD check note " ... used in a situation
 where it does not exist"
Message-ID: <CA+hbrhXRBGVoy54CEmyXhoWv-jWAtCSo7mG5BcxO5zRYVHCpgg@mail.gmail.com>

Hi all,

just installed the current version of R-devel (2015-01-13 r67453) from
CRAN. Package checking via CMD check suddenly prints a lot of notes
that complain of ... used in a situation where it does not exist. A
prototypical example is

fa = function(...)
{
  fb(...)
}

where fa and fb are defined and available functions.

I haven't seen this note before on my package, so something changed in
R-devel - did I miss something in the NEWS? I looked for something
relating to ... but didn't find anything relevant.

Thanks,

Peter


From peter.langfelder at gmail.com  Thu Jan 15 07:40:50 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 14 Jan 2015 22:40:50 -0800
Subject: [Rd] R under deveoplment CMD check note " ... used in a
 situation where it does not exist"
In-Reply-To: <CA+hbrhXRBGVoy54CEmyXhoWv-jWAtCSo7mG5BcxO5zRYVHCpgg@mail.gmail.com>
References: <CA+hbrhXRBGVoy54CEmyXhoWv-jWAtCSo7mG5BcxO5zRYVHCpgg@mail.gmail.com>
Message-ID: <CA+hbrhX8MrynBfFADcNn-YKt8Fq72ONue-cwzQHqGOUB37oUiA@mail.gmail.com>

Apologies... missed Michal's email and the discussion of the same topic.

Thanks,

Peter

On Wed, Jan 14, 2015 at 6:15 PM, Peter Langfelder
<peter.langfelder at gmail.com> wrote:
> Hi all,
>
> just installed the current version of R-devel (2015-01-13 r67453) from
> CRAN. Package checking via CMD check suddenly prints a lot of notes
> that complain of ... used in a situation where it does not exist. A
> prototypical example is
>
> fa = function(...)
> {
>   fb(...)
> }
>
> where fa and fb are defined and available functions.
>
> I haven't seen this note before on my package, so something changed in
> R-devel - did I miss something in the NEWS? I looked for something
> relating to ... but didn't find anything relevant.
>
> Thanks,
>
> Peter


From Stewart.Morris at igmm.ed.ac.uk  Thu Jan 15 13:45:50 2015
From: Stewart.Morris at igmm.ed.ac.uk (Stewart Morris)
Date: Thu, 15 Jan 2015 12:45:50 +0000
Subject: [Rd] Request to speed up save()
Message-ID: <54B7B67E.8080706@igmm.ed.ac.uk>

Hi,

I am dealing with very large datasets and it takes a long time to save a 
workspace image.

The options to save compressed data are: "gzip", "bzip2" or "xz", the 
default being gzip. I wonder if it's possible to include the pbzip2 
(http://compression.ca/pbzip2/) algorithm as an option when saving.

"PBZIP2 is a parallel implementation of the bzip2 block-sorting file 
compressor that uses pthreads and achieves near-linear speedup on SMP 
machines. The output of this version is fully compatible with bzip2 
v1.0.2 or newer"

I tested this as follows with one of my smaller datasets, having only 
read in the raw data:

============
# Dumped an ascii image
save.image(file='test', ascii=TRUE)

# At the shell prompt:
ls -l test
-rw-rw-r--. 1 swmorris swmorris 1794473126 Jan 14 17:33 test

time bzip2 -9 test
364.702u 3.148s 6:14.01 98.3%	0+0k 48+1273976io 1pf+0w

time pbzip2 -9 test
422.080u 18.708s 0:11.49 3836.2%	0+0k 0+1274176io 0pf+0w
============

As you can see, bzip2 on its own took over 6 minutes whereas pbzip2 took 
11 seconds, admittedly on a 64 core machine (running at 50% load). Most 
modern machines are multicore so everyone would get some speedup.

Is this feasible/practical? I am not a developer so I'm afraid this 
would be down to someone else...

Thoughts?

Cheers,

Stewart

-- 
Stewart W. Morris
Centre for Genomic and Experimental Medicine
The University of Edinburgh
United Kingdom

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From lists at sigg-iten.ch  Thu Jan 15 18:37:31 2015
From: lists at sigg-iten.ch (Christian Sigg)
Date: Thu, 15 Jan 2015 18:37:31 +0100
Subject: [Rd] Closing over Garbage
Message-ID: <B9BB7576-E6AB-4733-ABEB-6353FEBC81A1@sigg-iten.ch>

Given a large data.frame, a function trains a series of models by looping over two steps:

1. Create a model-specific subset of the complete training data
2. Train a model on the subset data

The function returns a list of trained models which are later used for prediction on test data.

Due to how models and closures work in R, each model contains a lot of data that is not necessary for prediction. The space requirements of all models combined can become prohibitive if the number of samples in the training data and the number of models is sufficiently large:

1. A trained linear model (and other models that follow the same conventions) contains the training data itself and related quantities (such as residuals). While this is convenient for some kinds of analysis, it negates the space saving effect of compacting the training data into the model parameters.

2. Any function created in the loop contains the training data in its enclosing environment. For example, a linearising transform defined as 

linearise <- function(x) {
    x^gamma
}

(where gamma is derived from the training data) does not only contain `gamma` but other objects in its enclosing environment as well (e.g. intermediate computations in the loop). If `linearise` is returned with the model, those objects are also returned implicitly.

The first point can be dealt with by removing those components of the model which are not necessary for prediction (e.g. model$residuals <- NULL). For the second point, more work and care is needed to clean up all enclosing environments of created functions (not only `linearise` but also model$terms etc.).

I have read that V8's garbage collector avoids this problem by distinguishing between local and context variables 

https://stackoverflow.com/questions/5326300/garbage-collection-with-node-js

Can something similar be done in R? Is there a programming technique that is less tedious than "manual" cleanup of all enclosing environments?

Thanks,
Christian 


From ripley at stats.ox.ac.uk  Thu Jan 15 18:54:58 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Jan 2015 17:54:58 +0000
Subject: [Rd] Request to speed up save()
In-Reply-To: <54B7B67E.8080706@igmm.ed.ac.uk>
References: <54B7B67E.8080706@igmm.ed.ac.uk>
Message-ID: <54B7FEF2.9000308@stats.ox.ac.uk>

On 15/01/2015 12:45, Stewart Morris wrote:
> Hi,
>
> I am dealing with very large datasets and it takes a long time to save a
> workspace image.

Sounds like bad practice on your part ... saving images is not 
recommended for careful work.

> The options to save compressed data are: "gzip", "bzip2" or "xz", the
> default being gzip. I wonder if it's possible to include the pbzip2
> (http://compression.ca/pbzip2/) algorithm as an option when saving.

It is not an 'algorithm', it is a command-line utility widely available 
for Linux at least.

> "PBZIP2 is a parallel implementation of the bzip2 block-sorting file
> compressor that uses pthreads and achieves near-linear speedup on SMP
> machines. The output of this version is fully compatible with bzip2
> v1.0.2 or newer"
>
> I tested this as follows with one of my smaller datasets, having only
> read in the raw data:
>
> ============
> # Dumped an ascii image
> save.image(file='test', ascii=TRUE)

Why do that if you are at all interested in speed?  A pointless (and 
inaccurate) binary to decimal conversion is needed.

>
> # At the shell prompt:
> ls -l test
> -rw-rw-r--. 1 swmorris swmorris 1794473126 Jan 14 17:33 test
>
> time bzip2 -9 test
> 364.702u 3.148s 6:14.01 98.3%    0+0k 48+1273976io 1pf+0w
>
> time pbzip2 -9 test
> 422.080u 18.708s 0:11.49 3836.2%    0+0k 0+1274176io 0pf+0w
> ============
>
> As you can see, bzip2 on its own took over 6 minutes whereas pbzip2 took
> 11 seconds, admittedly on a 64 core machine (running at 50% load). Most
> modern machines are multicore so everyone would get some speedup.

But R does not by default save bzip2-ed ASCII images ... and gzip is the 
default because its speed/compression tradeoffs (see ?save) are best for 
the typical R user.

And your last point is a common misunderstanding, that people typically 
have lots of spare cores which are zero-price.  Even on my 8 (virtual) 
core desktop when I typically do have spare cores, using them has a 
price in throttling turbo mode and cache contention.  Quite a large 
price: an R session may run 1.5-2x slower if 7 other tasks are run in 
parallel.

> Is this feasible/practical? I am not a developer so I'm afraid this
> would be down to someone else...

Not in base R.  For example one would need a linkable library, which the 
site you quote is not obviously providing.

Nothing is stopping you writing a sensible uncompressed image and 
optionally compressing it externally, but note that for some file 
systems compressed saves are faster because of reduced I/O.

> Thoughts?

>
> Cheers,
>
> Stewart
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From toth.denes at ttk.mta.hu  Thu Jan 15 19:06:48 2015
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Thu, 15 Jan 2015 19:06:48 +0100
Subject: [Rd] Request to speed up save()
In-Reply-To: <54B7B67E.8080706@igmm.ed.ac.uk>
References: <54B7B67E.8080706@igmm.ed.ac.uk>
Message-ID: <54B801B8.7000009@ttk.mta.hu>



On 01/15/2015 01:45 PM, Stewart Morris wrote:
> Hi,
>
> I am dealing with very large datasets and it takes a long time to save a
> workspace image.
>
> The options to save compressed data are: "gzip", "bzip2" or "xz", the
> default being gzip. I wonder if it's possible to include the pbzip2
> (http://compression.ca/pbzip2/) algorithm as an option when saving.
>
> "PBZIP2 is a parallel implementation of the bzip2 block-sorting file
> compressor that uses pthreads and achieves near-linear speedup on SMP
> machines. The output of this version is fully compatible with bzip2
> v1.0.2 or newer"
>
> I tested this as follows with one of my smaller datasets, having only
> read in the raw data:
>
> ============
> # Dumped an ascii image
> save.image(file='test', ascii=TRUE)
>
> # At the shell prompt:
> ls -l test
> -rw-rw-r--. 1 swmorris swmorris 1794473126 Jan 14 17:33 test
>
> time bzip2 -9 test
> 364.702u 3.148s 6:14.01 98.3%    0+0k 48+1273976io 1pf+0w
>
> time pbzip2 -9 test
> 422.080u 18.708s 0:11.49 3836.2%    0+0k 0+1274176io 0pf+0w
> ============
>
> As you can see, bzip2 on its own took over 6 minutes whereas pbzip2 took
> 11 seconds, admittedly on a 64 core machine (running at 50% load). Most
> modern machines are multicore so everyone would get some speedup.
>
> Is this feasible/practical? I am not a developer so I'm afraid this
> would be down to someone else...

Take a look at the gdsfmt package. It supports the superfast Lz4 
compression algorithm + it provides highly optimized functions to write 
to/read from disk.
https://github.com/zhengxwen/gdsfmt

>
> Thoughts?
>
> Cheers,
>
> Stewart
>


From simon.urbanek at r-project.org  Thu Jan 15 20:08:58 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Jan 2015 14:08:58 -0500
Subject: [Rd] Request to speed up save()
In-Reply-To: <54B7B67E.8080706@igmm.ed.ac.uk>
References: <54B7B67E.8080706@igmm.ed.ac.uk>
Message-ID: <337EA86A-4518-47D6-966E-E1A866BA8ACB@r-project.org>

In addition to the major points that others made: if you care about speed, don't use compression. With today's fast disks it's an order of magnitude slower to use compression:

> d=lapply(1:10, function(x) as.integer(rnorm(1e7)))
> system.time(saveRDS(d, file="test.rds.gz"))
   user  system elapsed 
 17.210   0.148  17.397 
> system.time(saveRDS(d, file="test.rds", compress=F))
   user  system elapsed 
  0.482   0.355   0.929 

The above example is intentionally well compressible, in real life the differences are actually even bigger. As people that deal with big data know well, disks are no longer the bottleneck - it's the CPU now.

Cheers,
Simon

BTW: why in the world would you use ascii=TRUE? It's pretty much the slowest possible serialization you can use - it will even overshadow compression:

> system.time(saveRDS(d, file="test.rds", compress=F))
   user  system elapsed 
  0.459   0.383   0.940 
> system.time(saveRDS(d, file="test-a.rds", compress=F, ascii=T))
   user  system elapsed 
 36.713   0.140  36.929 

and the same goes for reading:

> system.time(readRDS("test-a.rds"))
   user  system elapsed 
 27.616   0.275  27.948 
> system.time(readRDS("test.rds"))
   user  system elapsed 
  0.609   0.184   0.795 



> On Jan 15, 2015, at 7:45 AM, Stewart Morris <Stewart.Morris at igmm.ed.ac.uk> wrote:
> 
> Hi,
> 
> I am dealing with very large datasets and it takes a long time to save a workspace image.
> 
> The options to save compressed data are: "gzip", "bzip2" or "xz", the default being gzip. I wonder if it's possible to include the pbzip2 (http://compression.ca/pbzip2/) algorithm as an option when saving.
> 
> "PBZIP2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines. The output of this version is fully compatible with bzip2 v1.0.2 or newer"
> 
> I tested this as follows with one of my smaller datasets, having only read in the raw data:
> 
> ============
> # Dumped an ascii image
> save.image(file='test', ascii=TRUE)
> 
> # At the shell prompt:
> ls -l test
> -rw-rw-r--. 1 swmorris swmorris 1794473126 Jan 14 17:33 test
> 
> time bzip2 -9 test
> 364.702u 3.148s 6:14.01 98.3%	0+0k 48+1273976io 1pf+0w
> 
> time pbzip2 -9 test
> 422.080u 18.708s 0:11.49 3836.2%	0+0k 0+1274176io 0pf+0w
> ============
> 
> As you can see, bzip2 on its own took over 6 minutes whereas pbzip2 took 11 seconds, admittedly on a 64 core machine (running at 50% load). Most modern machines are multicore so everyone would get some speedup.
> 
> Is this feasible/practical? I am not a developer so I'm afraid this would be down to someone else...
> 
> Thoughts?
> 
> Cheers,
> 
> Stewart
> 
> -- 
> Stewart W. Morris
> Centre for Genomic and Experimental Medicine
> The University of Edinburgh
> United Kingdom
> 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From luke-tierney at uiowa.edu  Thu Jan 15 20:43:07 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 15 Jan 2015 13:43:07 -0600
Subject: [Rd] Closing over Garbage
In-Reply-To: <B9BB7576-E6AB-4733-ABEB-6353FEBC81A1@sigg-iten.ch>
References: <B9BB7576-E6AB-4733-ABEB-6353FEBC81A1@sigg-iten.ch>
Message-ID: <alpine.LFD.2.11.1501151337560.20538@itasca.stat.uiowa.edu>

On Thu, 15 Jan 2015, Christian Sigg wrote:

> Given a large data.frame, a function trains a series of models by looping over two steps:
>
> 1. Create a model-specific subset of the complete training data
> 2. Train a model on the subset data
>
> The function returns a list of trained models which are later used for prediction on test data.
>
> Due to how models and closures work in R, each model contains a lot of data that is not necessary for prediction. The space requirements of all models combined can become prohibitive if the number of samples in the training data and the number of models is sufficiently large:
>
> 1. A trained linear model (and other models that follow the same conventions) contains the training data itself and related quantities (such as residuals). While this is convenient for some kinds of analysis, it negates the space saving effect of compacting the training data into the model parameters.
>
> 2. Any function created in the loop contains the training data in its enclosing environment. For example, a linearising transform defined as
>
> linearise <- function(x) {
>    x^gamma
> }
>
> (where gamma is derived from the training data) does not only contain `gamma` but other objects in its enclosing environment as well (e.g. intermediate computations in the loop). If `linearise` is returned with the model, those objects are also returned implicitly.
>
> The first point can be dealt with by removing those components of the model which are not necessary for prediction (e.g. model$residuals <- NULL). For the second point, more work and care is needed to clean up all enclosing environments of created functions (not only `linearise` but also model$terms etc.).
>
> I have read that V8's garbage collector avoids this problem by distinguishing between local and context variables
>
> https://stackoverflow.com/questions/5326300/garbage-collection-with-node-js
>
> Can something similar be done in R? Is there a programming technique that is less tedious than "manual" cleanup of all enclosing environments?

R's semantics do not permit this sort of optimization in general --
there may be something we could do if users could provide annotations
that allow the semantics to be relaxed; that sort of thing is being
considered but won't be available anytime soon.

The approach I use in situations like this is to write top-level
functions that create closures. So for your example, replace

  linearise <- function(x) {
     x^gamma
  }

with

  makeLinearize(x, gamma),

where makeLinearize is defined at top level as

makeLinearize <- function(x, gamma) {
     function(x) {
         x^gamma
     }
}

Best,

luke

>
> Thanks,
> Christian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From nate at verse.com  Thu Jan 15 23:18:13 2015
From: nate at verse.com (Nathan Kurz)
Date: Thu, 15 Jan 2015 14:18:13 -0800
Subject: [Rd] Request to speed up save()
In-Reply-To: <337EA86A-4518-47D6-966E-E1A866BA8ACB@r-project.org>
References: <54B7B67E.8080706@igmm.ed.ac.uk>
	<337EA86A-4518-47D6-966E-E1A866BA8ACB@r-project.org>
Message-ID: <CAFAN8vzCFEcYYa-Pmdh-5nKMrBOUkj6r51Fw+-yDPdWXsBLKPg@mail.gmail.com>

On Thu, Jan 15, 2015 at 11:08 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> In addition to the major points that others made: if you care about speed, don't use compression. With today's fast disks it's an order of magnitude slower to use compression:
>
>> d=lapply(1:10, function(x) as.integer(rnorm(1e7)))
>> system.time(saveRDS(d, file="test.rds.gz"))
>    user  system elapsed
>  17.210   0.148  17.397
>> system.time(saveRDS(d, file="test.rds", compress=F))
>    user  system elapsed
>   0.482   0.355   0.929
>
> The above example is intentionally well compressible, in real life the differences are actually even bigger. As people that deal with big data know well, disks are no longer the bottleneck - it's the CPU now.

Respectfully, while your example would imply this, I don't think this
is correct in the general case.    Much faster compression schemes
exist, and using these can improve disk I/O tremendously.  Some
schemes that are so fast that it's even faster to transfer compressed
data from main RAM to CPU cache and then decompress to avoid being
limited by RAM bandwidth: https://github.com/Blosc/c-blosc

Repeating that for emphasis, compressing and uncompressing can be
actually be faster than a straight memcpy()!

Really, the issue is that 'gzip' and 'bzip2' are bottlenecks.   As
Steward suggests, this can be mitigated by throwing more cores at the
problem.  This isn't a bad solution, as there are often excess
underutilized cores.  But much better would be to choose a faster
compression scheme first, and then parallelize that across cores if
still necessary.

Sometimes the tradeoff is between amount of compression and speed, and
sometimes some algorithms are just faster than others.   Here's some
sample data for the test file that your example creates:

> d=lapply(1:10, function(x) as.integer(rnorm(1e7)))
> system.time(saveRDS(d, file="test.rds", compress=F))
   user  system elapsed
  0.554   0.336   0.890

nate at ubuntu:~/R/rds$ ls -hs test.rds
382M test.rds
nate at ubuntu:~/R/rds$ time gzip -c test.rds > test.rds.gz
real: 16.207 sec
nate at ubuntu:~/R/rds$ ls -hs test.rds.gz
35M test.rds.gz
nate at ubuntu:~/R/rds$ time gunzip -c test.rds.gz > discard
real: 2.330 sec

nate at ubuntu:~/R/rds$ time gzip -c --fast test.rds > test.rds.gz
real: 4.759 sec
nate at ubuntu:~/R/rds$ ls -hs test.rds.gz
56M test.rds.gz
nate at ubuntu:~/R/rds$ time gunzip -c test.rds.gz > discard
real: 2.942 sec

nate at ubuntu:~/R/rds$ time pigz -c  test.rds > test.rds.gz
real: 2.180 sec
nate at ubuntu:~/R/rds$ ls -hs test.rds.gz
35M test.rds.gz
nate at ubuntu:~/R/rds$ time gunzip -c test.rds.gz > discard
real: 2.375 sec

nate at ubuntu:~/R/rds$ time pigz -c --fast test.rds > test.rds.gz
real: 0.739 sec
nate at ubuntu:~/R/rds$ ls -hs test.rds.gz
57M test.rds.gz
nate at ubuntu:~/R/rds$ time gunzip -c test.rds.gz > discard
real: 2.851 sec

nate at ubuntu:~/R/rds$ time lz4c test.rds > test.rds.lz4
Compressed 400000102 bytes into 125584749 bytes ==> 31.40%
real: 1.024 sec
nate at ubuntu:~/R/rds$ ls -hs test.rds.lz4
120M test.rds.lz4
nate at ubuntu:~/R/rds$ time lz4 test.rds.lz4 > discard
Compressed 125584749 bytes into 95430573 bytes ==> 75.99%
real: 0.775 sec

Reading that last one more closely, with single threaded lz4
compression, we're getting 3x compression at about 400MB/s, and
decompression at about 500MB/s.   This is faster than almost any
single disk will be.  Multithreaded implementations will make even the
fastest RAID be the bottleneck.

It's probably worth noting that the speeds reported in your simple
example for the uncompressed case are likely the speed of writing to
memory, with the actual write to disk happening at some later time.
Sustained throughput will likely be slower than your example would
imply

If saving data to disk is a bottleneck, I think Stewart is right that
there is a lot of room for improvement.

--nate


From lawrence.michael at gene.com  Fri Jan 16 00:55:42 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 15 Jan 2015 15:55:42 -0800
Subject: [Rd] default min-v/nsize parameters
Message-ID: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>

Just wanted to start a discussion on whether R could ship with more
appropriate GC parameters. Right now, loading the recommended package
Matrix leads to:

> library(Matrix)
> gc()
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 1076796 57.6    1368491 73.1  1198505 64.1
Vcells 1671329 12.8    2685683 20.5  1932418 14.8

Results may vary, but here R needed 64MB of N cells and 15MB of V cells to
load one of the most important packages.

Currently, the default GC triggers are ~20MB (64 bit systems) for N cells
and ~6MB of V cells. Martin Morgan found that this leads to a lot of GC
overhead during package loading and at least in our tests can significantly
increase the load time of complex packages.

If we set the triggers at the command line beyond the reach of
library(Matrix) (--min-vsize=2048M --min-nsize=45M), then we see:

          used (Mb) gc trigger (Mb) max used  (Mb)
Ncells 1076859 57.6   47185920 2520  6260069 334.4
Vcells 1671431 12.8  268435456 2048  9010303  68.8

So by effectively disabling the GC, we let R consume 335MB N + 70MB of V,
but loading goes a lot faster:

Loading Matrix with default settings:
> system.time(library(Matrix))
   user  system elapsed
  1.600   0.011   1.610

With high GC triggers ():
> system.time(library(Matrix))
   user  system elapsed
  0.983   0.097   1.079

Given modern hardware capabilities and the need to efficiently load
software for the user to be able to do something, perhaps we should bump
the default settings so that the GC is fired sparingly when loading a large
package.

For users of Bioconductor, we see this for library(GenomicRanges):

          used (Mb) gc trigger (Mb) max used  (Mb)
Ncells 1322124 70.7   47185920 2520 15591302 832.7
Vcells 1216015  9.3  268435456 2048 13992181 106.8

So perhaps that user would want 900 MB of N and 100 MB of V as the trigger
(corresponding to --min-vsize=100M --min-nsize=16M).

Thoughts?

	[[alternative HTML version deleted]]


From rhelp at eoos.dds.nl  Fri Jan 16 15:21:42 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Fri, 16 Jan 2015 15:21:42 +0100
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
 response
In-Reply-To: <21685.14887.946988.975035@max.nulle.part>
References: <21685.14887.946988.975035@max.nulle.part>
Message-ID: <20150116152142.Horde.uxImQmEwhY5UuR52g4U0GfA@webmailnew.dds.nl>

Dirk,

The vagrant setup I use to test my packages with UBSAN also seems to  
replicate the error reported by CRAN (together with some other  
warnings). I have attached the files (I hope they get through the  
filters). I suppose you know what to do with them.

Jan





Dirk Eddelbuettel <edd at debian.org> schreef:

> CRAN has a package of mine in upload limbo because it failed UBSAN.
>
> I am not entirely ignorant on the topic of sanitizers and SAN / ASAN / UBSAN;
> we created not one but two Docker containers with ASAN and USBAN:
>
>    https://registry.hub.docker.com/u/rocker/r-devel-san/
>    https://registry.hub.docker.com/u/rocker/r-devel-ubsan-clang/
>
> as well as predecessors to them in earlier Docker repos.
>
> Yet I fail to recreate the errors reported by CRAN:
>
>     
> http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN-clang-trunk/RcppAnnoy/tests/runUnitTests.Rout
>     
> http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN/RcppAnnoy/tests/runUnitTests.Rout
>
> I asked politely (and twice) for help with the corresponding compiler
> configuration(s).  But CRAN is of course way above communicating with mere
> mortals such as yours truly.
>
> So I have no recourse other than to spam all of you: if anybody here has a
> working UBSAN setup which can replicate the issue seen in the (rather small)
> RcppAnnoy package?
>
> Erik (upstream for Annoy, CC'ed) and I would be most grateful.  We do not
> like being held hostage on an error report we cannot replicate and for which
> we do not receive any help (or even further communication) whatsoever.
>
> Dirk
> about to turn into yet another frustrated CRAN user
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



From pauljohn32 at gmail.com  Sat Jan 17 00:02:36 2015
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 16 Jan 2015 17:02:36 -0600
Subject: [Rd] S3 generic method dispatch on promises
Message-ID: <CAErODj-znZ7WU41-dcQt+7hf3+df0ByoLiBk0B6Nu_Pzyupt0Q@mail.gmail.com>

Dear R friends

I wanted a function to make a simple percent table that would be easy for
students to use. The goal originally was to have a simple thing people
would call like this

pctable(rowvar, colvar, data)

and the things "rowvar" and "colvar" might be names of variables in data. I
wanted to avoid the usage of "with" (as we now see in the table help).

Then some people wanted more features, and I agreed with the suggestion to
create a formula interface that people can call like so:

pctable(rowvar ~ colvar, data)

I end up with a generic function pctable and methods pctable.default,
pctable.formula, pctable.character.

I got that working, mostly I understand what's going on.

Except the following, which, actually, is a good lesson to me about
promises and method dispatch in R. An S3 generic will not send a call with
a promise in the first argument to pctable.default (as I had mistakenly
hoped). I'll paste in all the code below, but I think you will know the
answer even without running it.

pctable is a generic function.  In workspace, I have no objects x and y,
but there are variables inside data.frame dat named x and y.   Since y is
not an object, the method dispatch fails thus:

> pctable(y, x, dat)
Error in pctable(y, x, dat) (from #3) : object 'y' not found

This direct call on pctable.default works (recall  y and x are promises):

> pctable.default(y, x, dat)
Count (column %)
     x
y     1      2      3      4      Sum
  A   5(20%) 3(12%) 5(20%) 6(24%) 19
  B   9(36%) 5(20%) 4(16%) 6(24%) 24
  C   1(4%)  6(24%) 3(12%) 2(8%)  12
  D   4(16%) 4(16%) 6(24%) 5(20%) 19
  E   6(24%) 7(28%) 7(28%) 6(24%) 26
  Sum 25     25     25     25     100

All the methods work fine when the first argument is a language object.

This works (dispatches to pctable.formula)

> pctable(y ~ x, dat)
Count (column %)
     x
y     1      2      3      4      Sum
  A   5(20%) 3(12%) 5(20%) 6(24%) 19
  B   9(36%) 5(20%) 4(16%) 6(24%) 24
  C   1(4%)  6(24%) 3(12%) 2(8%)  12
  D   4(16%) 4(16%) 6(24%) 5(20%) 19
  E   6(24%) 7(28%) 7(28%) 6(24%) 26
  Sum 25     25     25     25     100


This works (dispatches to pctable.default)
> pctable(dat$y, dat$x)
Count (column %)
     dat$x
dat$y 1      2      3      4      Sum
  A   5(20%) 3(12%) 5(20%) 6(24%) 19
  B   9(36%) 5(20%) 4(16%) 6(24%) 24
  C   1(4%)  6(24%) 3(12%) 2(8%)  12
  D   4(16%) 4(16%) 6(24%) 5(20%) 19
  E   6(24%) 7(28%) 7(28%) 6(24%) 26
  Sum 25     25     25     25     100

However, this fails because y is not an object with a type

> pctable(y, x, dat)
Error in pctable(y, x, dat) (from #3) : object 'y' not found

Can R be tricked to send that call to pctable.default, where it does work?

Here's the code, I'm working on documentation, will put in package
rockchalk eventually, but hate to leave this problem until I fully
understand it.


pctable <- function(rv, ...)
{
    UseMethod("pctable")
}

## rv: row variable, quoted or not
## cv: column variable, quoted or not
pctable.default <- function(rv, cv, data = parent.frame(),
                            rvlab = NULL, cvlab = NULL,
                            colpct = TRUE, rowpct = FALSE,
                            exclude = c(NA, NaN), rounded = FALSE)
{
    rvlabel <- if (!missing(rv)) deparse(substitute(rv))
    cvlabel <- if (!missing(cv)) deparse(substitute(cv))
    rvlab <- if (is.null(rvlab)) rvlabel else rvlab
    cvlab <- if (is.null(cvlab)) cvlabel else cvlab

    rvin <- eval(substitute(rv), envir = data, enclos = parent.frame())
    cvin <- eval(substitute(cv), envir = data, enclos = parent.frame())

    t1 <- table(rvin, cvin, dnn = c(rvlab, cvlab), exclude = exclude)
    rownames(t1)[is.na(rownames(t1))] <- "NA" ## symbol to letters
    colnames(t1)[is.na(colnames(t1))] <- "NA"
    if (rounded) t1 <- round(t1, -1)
    t2 <- addmargins(t1, c(1,2))
    t1colpct <- round(100*prop.table(t1, 2), 1)
    t1rowpct <- round(100*prop.table(t1, 1), 1)
    t1colpct <- apply(t1colpct, c(1,2), function(x) gsub("NaN", "", x))
    t1rowpct <- apply(t1rowpct, c(1,2), function(x) gsub("NaN", "", x))
    res <- list("count" = t2, "colpct" = t1colpct, "rowpct" = t1rowpct,
call = match.call())
    class(res) <- "pctable"
    print(res, colpct = colpct, rowpct = rowpct)
    invisible(res)
}


pctable.formula <- function(formula, data = NULL,  rvlab = NULL,
                            cvlab = NULL, colpct = TRUE, rowpct = FALSE,
                            exclude = c(NA, NaN), rounded = FALSE,
                            ..., subset = NULL)

{
    if (missing(data) || !is.data.frame(data)) stop("pctable requires a
data frame")
    if (missing(formula) || (length(formula) != 3L))
        stop("pctable requires a two sided formula")
    mt <- terms(formula, data = data)
    if (attr(mt, "response") == 0L) stop("response variable is required")
    mf <- match.call(expand.dots = FALSE)
    keepers <- match(c("formula", "data", "subset", "na.action"),
names(mf), 0L)
    mf <- mf[c(1L, keepers)]
    mf$drop.unused.levels <- FALSE
    mf[[1L]] <- quote(stats::model.frame)
    mf <- eval(mf, parent.frame())
    ## response is column 1
    rvlab <- if (missing(rvlab)) colnames(mf)[1] else rvlab
    cvlab <- if (missing(cvlab)) colnames(mf)[2] else cvlab

    res <- pctable.default(mf[[1L]], mf[[2L]], data = mf,
                           rvlab = rvlab, cvlab = cvlab,
                           colpct = colpct, rowpct = rowpct,
                           exclude = exclude, rounded = rounded)
    invisible(res)
}

pctable.character <- function(rowvar, colvar, data = NULL, rvlab = NULL,
                            cvlab = NULL, colpct = TRUE,
                            rowpct = FALSE, exclude = c(NA, NaN), rounded =
FALSE,
                            ..., subset = NULL)

{
    if (missing(data) || !is.data.frame(data)) stop("pctable requires a
data frame")
    ## colvar <- if (!is.character(colvar)) deparse(substitute(colvar))
else colvar
    colvar <- as.character(substitute(colvar))[1L]

    rvlab <- if (missing(rvlab)) rowvar else rvlab
    cvlab <- if (missing(cvlab)) colvar else cvlab

    t1 <- with(data, table(data[[rowvar]], data[[colvar]], dnn = c(rvlab,
cvlab), exclude = exclude))
    rownames(t1)[is.na(rownames(t1))] <- "NA" ## symbol to letters
    colnames(t1)[is.na(colnames(t1))] <- "NA"
    if (rounded) t1 <- round(t1, -1)
    t2 <- addmargins(t1, c(1,2))
    t1colpct <- round(100*prop.table(t1, 2), 1)
    t1rowpct <- round(100*prop.table(t1, 1), 1)
    t1colpct <- apply(t1colpct, c(1,2), function(x) gsub("NaN", "", x))
    t1rowpct <- apply(t1rowpct, c(1,2), function(x) gsub("NaN", "", x))

    res <- list("count" = t2, "colpct" = t1colpct, "rowpct" = t1rowpct,
call = match.call())
    class(res) <- "pctable"
    print(res, colpct = colpct, rowpct = rowpct)
    invisible(res)
}


## OK, I see now I'm doing the same work over and over, will extract
## a middle chunk out of each of those methods.  And finally my cool print
method.

print.pctable <- function(tab, colpct = TRUE, rowpct = FALSE){
    count <- tab[["count"]]

    t3 <- count
    if (colpct && !rowpct) {
        cpct <- tab[["colpct"]]
        for(j in rownames(cpct)){
            for(k in colnames(cpct)){
                t3[j, k] <- paste0(count[j, k], "(", cpct[j, k], "%)")
            }
        }
        cat("Count (column %)\n")
        print(t3)
        return(invisible(t3))
    }

    ## rowpct == TRUE< else would have returned
    rpct <- tab[["rowpct"]]
    for(j in rownames(rpct)){
        for(k in colnames(rpct)){
            t3[j, k] <- paste0(count[j, k], "(", rpct[j, k], "%)")
        }
    }

    if (!colpct) {
        cat("Count (row %)\n")
        print(t3)
        return(invisible(t3))
    } else {
        cpct <- tab[["colpct"]]
        t4 <- array("", dim = c(1, 1) + c(2,1)*dim(tab$colpct))
        t4[seq(1, NROW(t4), 2), ] <- t3
        rownames(t4)[seq(1, NROW(t4), 2)] <- rownames(t3)
        rownames(t4)[is.na(rownames(t4))] <- ""
        colnames(t4) <- colnames(t3)
        for(j in rownames(tab[["colpct"]])) {
            for(k in colnames(tab[["colpct"]])){
                t4[1 + which(rownames(t4) == j) ,k] <-
paste0(tab[["colpct"]][j, k], "%")
            }

        }

        names(dimnames(t4)) <- names(dimnames(count))

        cat("Count (row %)\n")
        cat("column %\n")
        print(t4, quote = FALSE)
        return(invisible(t4))
    }
}


And usage examples



dat <- data.frame(x = gl(4, 25),
                  y = sample(c("A", "B", "C", "D", "E"), 100, replace=
TRUE))


## Here's what I was aiming for, in the beginning
pctable(y ~ x, dat)
pctable(y ~ x, dat, exclude = NULL)
pctable(y ~ x, dat, rvlab = "My Outcome Var", cvlab = "My Columns")
## People who like row percents asked for this
pctable(y ~ x, dat, rowpct = TRUE, colpct = FALSE)
## Some people want both. Tiresome.
pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE)
pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE, exclude = NULL)
tab <- pctable(y ~ x, dat, rvlab = "My Outcome Var", cvlab = "My Columns")
print(tab, rowpct = TRUE, colpct = FALSE)
print.pctable(tab, rowpct = TRUE, colpct = TRUE)




## I also wanted an interface that would allow calls like
## pctable(y, x, dat)
## which I was able to do, but not when pctable is a method.
## As long as one writes in an existing variable, this dispatches
## pctable.default and result is OK
pctable(dat$y, dat$x)
pctable(dat$y, dat$x, rowpct = TRUE, colpct = FALSE)
pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE)
pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = NULL)

tab <- pctable(dat$y, dat$x)
print(tab, rowpct = TRUE, colpct = FALSE)
print(tab, rowpct = TRUE, colpct = TRUE)

pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c(NA, "E"))
pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c("E"))
## Why do NA's get excluded
pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c("B", "2"))

## This succeeds
pctable.default(y, x, dat)
## Next causes error
pctable(y, x, dat)

## Error in pctable(y, x, dat) (from #3) : object 'y' not found


At one point yesterday, I was on the verge of comprehending the parse tree
:)

-- 
Paul E. Johnson
Professor, Political Science      Acting. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://crmda.ku.edu
<http://quant.ku.edu>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Jan 17 00:21:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Jan 2015 15:21:10 -0800
Subject: [Rd] S3 generic method dispatch on promises
In-Reply-To: <CAErODj-znZ7WU41-dcQt+7hf3+df0ByoLiBk0B6Nu_Pzyupt0Q@mail.gmail.com>
References: <CAErODj-znZ7WU41-dcQt+7hf3+df0ByoLiBk0B6Nu_Pzyupt0Q@mail.gmail.com>
Message-ID: <54B99CE6.8020203@gmail.com>

On 16/01/2015 3:02 PM, Paul Johnson wrote:
> Dear R friends
> 
> I wanted a function to make a simple percent table that would be easy for
> students to use. The goal originally was to have a simple thing people
> would call like this
> 
> pctable(rowvar, colvar, data)
> 
> and the things "rowvar" and "colvar" might be names of variables in data. I
> wanted to avoid the usage of "with" (as we now see in the table help).
> 
> Then some people wanted more features, and I agreed with the suggestion to
> create a formula interface that people can call like so:
> 
> pctable(rowvar ~ colvar, data)
> 
> I end up with a generic function pctable and methods pctable.default,
> pctable.formula, pctable.character.
> 
> I got that working, mostly I understand what's going on.
> 
> Except the following, which, actually, is a good lesson to me about
> promises and method dispatch in R. An S3 generic will not send a call with
> a promise in the first argument to pctable.default (as I had mistakenly
> hoped). I'll paste in all the code below, but I think you will know the
> answer even without running it.
> 
> pctable is a generic function.  In workspace, I have no objects x and y,
> but there are variables inside data.frame dat named x and y.   Since y is
> not an object, the method dispatch fails thus:
> 
>> pctable(y, x, dat)
> Error in pctable(y, x, dat) (from #3) : object 'y' not found
> 
> This direct call on pctable.default works (recall  y and x are promises):

I think you are using the word "promise" differently than the standard R
usage.  In a sense, all arguments are promises, but you seem to mean
something more.  I think you mean that you want nonstandard evaluation
for x and y.

> 
>> pctable.default(y, x, dat)
> Count (column %)
>      x
> y     1      2      3      4      Sum
>   A   5(20%) 3(12%) 5(20%) 6(24%) 19
>   B   9(36%) 5(20%) 4(16%) 6(24%) 24
>   C   1(4%)  6(24%) 3(12%) 2(8%)  12
>   D   4(16%) 4(16%) 6(24%) 5(20%) 19
>   E   6(24%) 7(28%) 7(28%) 6(24%) 26
>   Sum 25     25     25     25     100
> 
> All the methods work fine when the first argument is a language object.
> 
> This works (dispatches to pctable.formula)
> 
>> pctable(y ~ x, dat)
> Count (column %)
>      x
> y     1      2      3      4      Sum
>   A   5(20%) 3(12%) 5(20%) 6(24%) 19
>   B   9(36%) 5(20%) 4(16%) 6(24%) 24
>   C   1(4%)  6(24%) 3(12%) 2(8%)  12
>   D   4(16%) 4(16%) 6(24%) 5(20%) 19
>   E   6(24%) 7(28%) 7(28%) 6(24%) 26
>   Sum 25     25     25     25     100
> 
> 
> This works (dispatches to pctable.default)
>> pctable(dat$y, dat$x)
> Count (column %)
>      dat$x
> dat$y 1      2      3      4      Sum
>   A   5(20%) 3(12%) 5(20%) 6(24%) 19
>   B   9(36%) 5(20%) 4(16%) 6(24%) 24
>   C   1(4%)  6(24%) 3(12%) 2(8%)  12
>   D   4(16%) 4(16%) 6(24%) 5(20%) 19
>   E   6(24%) 7(28%) 7(28%) 6(24%) 26
>   Sum 25     25     25     25     100
> 
> However, this fails because y is not an object with a type

I would say it fails because object y does not exist in the evaluation
frame of the function, where you are implicitly evaluating it.

> 
>> pctable(y, x, dat)
> Error in pctable(y, x, dat) (from #3) : object 'y' not found
> 
> Can R be tricked to send that call to pctable.default, where it does work?

Yes, but it is probably a bad idea.  The idea of S3 dispatch is that it
depends on the type of the argument used for dispatching, by default the
first argument.  You don't have a variable named y, so you can't do that.

There are a few ways to do the tricking.  You could add a data parameter
to the generic function, and construct a new environment from it before
you evaluate the first argument.  Then y would be found in the data
parameter, and dispatch could work.

You could use exists() to find if the first argument exists, and make an
explicit call to pctable.default if it doesn't.  But this will fail if
you have a global variable named y, because the test will find that one
and use it for dispatch, rather than using dat$y.

So I would conclude:  don't do that.  If you want to use a data
argument, use the formula method.  That's what other functions do, and
so that's what your users would expect.  If you don't use a formula,
then the variables should all use standard evaluation, i.e. they should
exist in the frame where you are calling pctable.

One more comment inline below.

> 
> Here's the code, I'm working on documentation, will put in package
> rockchalk eventually, but hate to leave this problem until I fully
> understand it.
> 
> 
> pctable <- function(rv, ...)
> {
>     UseMethod("pctable")
> }
> 
> ## rv: row variable, quoted or not
> ## cv: column variable, quoted or not
> pctable.default <- function(rv, cv, data = parent.frame(),
>                             rvlab = NULL, cvlab = NULL,
>                             colpct = TRUE, rowpct = FALSE,
>                             exclude = c(NA, NaN), rounded = FALSE)
> {
>     rvlabel <- if (!missing(rv)) deparse(substitute(rv))
>     cvlabel <- if (!missing(cv)) deparse(substitute(cv))
>     rvlab <- if (is.null(rvlab)) rvlabel else rvlab
>     cvlab <- if (is.null(cvlab)) cvlabel else cvlab
> 
>     rvin <- eval(substitute(rv), envir = data, enclos = parent.frame())
>     cvin <- eval(substitute(cv), envir = data, enclos = parent.frame())
> 
>     t1 <- table(rvin, cvin, dnn = c(rvlab, cvlab), exclude = exclude)
>     rownames(t1)[is.na(rownames(t1))] <- "NA" ## symbol to letters
>     colnames(t1)[is.na(colnames(t1))] <- "NA"
>     if (rounded) t1 <- round(t1, -1)
>     t2 <- addmargins(t1, c(1,2))
>     t1colpct <- round(100*prop.table(t1, 2), 1)
>     t1rowpct <- round(100*prop.table(t1, 1), 1)
>     t1colpct <- apply(t1colpct, c(1,2), function(x) gsub("NaN", "", x))
>     t1rowpct <- apply(t1rowpct, c(1,2), function(x) gsub("NaN", "", x))
>     res <- list("count" = t2, "colpct" = t1colpct, "rowpct" = t1rowpct,
> call = match.call())
>     class(res) <- "pctable"
>     print(res, colpct = colpct, rowpct = rowpct)
>     invisible(res)
> }
> 
> 
> pctable.formula <- function(formula, data = NULL,  rvlab = NULL,
>                             cvlab = NULL, colpct = TRUE, rowpct = FALSE,
>                             exclude = c(NA, NaN), rounded = FALSE,
>                             ..., subset = NULL)
> 
> {
>     if (missing(data) || !is.data.frame(data)) stop("pctable requires a
> data frame")

This test seems too strong.  If x and y had been global variables of the
right shape in your example, then pctable(y ~ x) should work.  I would
let model.frame (which you call down below) establish the rules for what
is allowed.

Duncan Murdoch

>     if (missing(formula) || (length(formula) != 3L))
>         stop("pctable requires a two sided formula")
>     mt <- terms(formula, data = data)
>     if (attr(mt, "response") == 0L) stop("response variable is required")
>     mf <- match.call(expand.dots = FALSE)
>     keepers <- match(c("formula", "data", "subset", "na.action"),
> names(mf), 0L)
>     mf <- mf[c(1L, keepers)]
>     mf$drop.unused.levels <- FALSE
>     mf[[1L]] <- quote(stats::model.frame)
>     mf <- eval(mf, parent.frame())
>     ## response is column 1
>     rvlab <- if (missing(rvlab)) colnames(mf)[1] else rvlab
>     cvlab <- if (missing(cvlab)) colnames(mf)[2] else cvlab
> 
>     res <- pctable.default(mf[[1L]], mf[[2L]], data = mf,
>                            rvlab = rvlab, cvlab = cvlab,
>                            colpct = colpct, rowpct = rowpct,
>                            exclude = exclude, rounded = rounded)
>     invisible(res)
> }
> 
> pctable.character <- function(rowvar, colvar, data = NULL, rvlab = NULL,
>                             cvlab = NULL, colpct = TRUE,
>                             rowpct = FALSE, exclude = c(NA, NaN), rounded =
> FALSE,
>                             ..., subset = NULL)
> 
> {
>     if (missing(data) || !is.data.frame(data)) stop("pctable requires a
> data frame")
>     ## colvar <- if (!is.character(colvar)) deparse(substitute(colvar))
> else colvar
>     colvar <- as.character(substitute(colvar))[1L]
> 
>     rvlab <- if (missing(rvlab)) rowvar else rvlab
>     cvlab <- if (missing(cvlab)) colvar else cvlab
> 
>     t1 <- with(data, table(data[[rowvar]], data[[colvar]], dnn = c(rvlab,
> cvlab), exclude = exclude))
>     rownames(t1)[is.na(rownames(t1))] <- "NA" ## symbol to letters
>     colnames(t1)[is.na(colnames(t1))] <- "NA"
>     if (rounded) t1 <- round(t1, -1)
>     t2 <- addmargins(t1, c(1,2))
>     t1colpct <- round(100*prop.table(t1, 2), 1)
>     t1rowpct <- round(100*prop.table(t1, 1), 1)
>     t1colpct <- apply(t1colpct, c(1,2), function(x) gsub("NaN", "", x))
>     t1rowpct <- apply(t1rowpct, c(1,2), function(x) gsub("NaN", "", x))
> 
>     res <- list("count" = t2, "colpct" = t1colpct, "rowpct" = t1rowpct,
> call = match.call())
>     class(res) <- "pctable"
>     print(res, colpct = colpct, rowpct = rowpct)
>     invisible(res)
> }
> 
> 
> ## OK, I see now I'm doing the same work over and over, will extract
> ## a middle chunk out of each of those methods.  And finally my cool print
> method.
> 
> print.pctable <- function(tab, colpct = TRUE, rowpct = FALSE){
>     count <- tab[["count"]]
> 
>     t3 <- count
>     if (colpct && !rowpct) {
>         cpct <- tab[["colpct"]]
>         for(j in rownames(cpct)){
>             for(k in colnames(cpct)){
>                 t3[j, k] <- paste0(count[j, k], "(", cpct[j, k], "%)")
>             }
>         }
>         cat("Count (column %)\n")
>         print(t3)
>         return(invisible(t3))
>     }
> 
>     ## rowpct == TRUE< else would have returned
>     rpct <- tab[["rowpct"]]
>     for(j in rownames(rpct)){
>         for(k in colnames(rpct)){
>             t3[j, k] <- paste0(count[j, k], "(", rpct[j, k], "%)")
>         }
>     }
> 
>     if (!colpct) {
>         cat("Count (row %)\n")
>         print(t3)
>         return(invisible(t3))
>     } else {
>         cpct <- tab[["colpct"]]
>         t4 <- array("", dim = c(1, 1) + c(2,1)*dim(tab$colpct))
>         t4[seq(1, NROW(t4), 2), ] <- t3
>         rownames(t4)[seq(1, NROW(t4), 2)] <- rownames(t3)
>         rownames(t4)[is.na(rownames(t4))] <- ""
>         colnames(t4) <- colnames(t3)
>         for(j in rownames(tab[["colpct"]])) {
>             for(k in colnames(tab[["colpct"]])){
>                 t4[1 + which(rownames(t4) == j) ,k] <-
> paste0(tab[["colpct"]][j, k], "%")
>             }
> 
>         }
> 
>         names(dimnames(t4)) <- names(dimnames(count))
> 
>         cat("Count (row %)\n")
>         cat("column %\n")
>         print(t4, quote = FALSE)
>         return(invisible(t4))
>     }
> }
> 
> 
> And usage examples
> 
> 
> 
> dat <- data.frame(x = gl(4, 25),
>                   y = sample(c("A", "B", "C", "D", "E"), 100, replace=
> TRUE))
> 
> 
> ## Here's what I was aiming for, in the beginning
> pctable(y ~ x, dat)
> pctable(y ~ x, dat, exclude = NULL)
> pctable(y ~ x, dat, rvlab = "My Outcome Var", cvlab = "My Columns")
> ## People who like row percents asked for this
> pctable(y ~ x, dat, rowpct = TRUE, colpct = FALSE)
> ## Some people want both. Tiresome.
> pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE)
> pctable(y ~ x, dat, rowpct = TRUE, colpct = TRUE, exclude = NULL)
> tab <- pctable(y ~ x, dat, rvlab = "My Outcome Var", cvlab = "My Columns")
> print(tab, rowpct = TRUE, colpct = FALSE)
> print.pctable(tab, rowpct = TRUE, colpct = TRUE)
> 
> 
> 
> 
> ## I also wanted an interface that would allow calls like
> ## pctable(y, x, dat)
> ## which I was able to do, but not when pctable is a method.
> ## As long as one writes in an existing variable, this dispatches
> ## pctable.default and result is OK
> pctable(dat$y, dat$x)
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = FALSE)
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE)
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = NULL)
> 
> tab <- pctable(dat$y, dat$x)
> print(tab, rowpct = TRUE, colpct = FALSE)
> print(tab, rowpct = TRUE, colpct = TRUE)
> 
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c(NA, "E"))
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c("E"))
> ## Why do NA's get excluded
> pctable(dat$y, dat$x, rowpct = TRUE, colpct = TRUE, exclude = c("B", "2"))
> 
> ## This succeeds
> pctable.default(y, x, dat)
> ## Next causes error
> pctable(y, x, dat)
> 
> ## Error in pctable(y, x, dat) (from #3) : object 'y' not found
> 
> 
> At one point yesterday, I was on the verge of comprehending the parse tree
> :)
>


From luke-tierney at uiowa.edu  Sat Jan 17 17:39:35 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sat, 17 Jan 2015 10:39:35 -0600
Subject: [Rd] default min-v/nsize parameters
In-Reply-To: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
References: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1501171035190.2583@luke-Latitude>

Martin Morgan discussed this a year or so ago and as I recall bumped
up these values to the current defaults. I don't recall details about
why we didn't go higher -- maybe Martin does. I suspect the main
concern would be with small memory machines in student labs and less
developed countries. If there was a way on all platforms to identify
how much memory is available that might help to set a default, though
that isn't perfect since you want something different on a large
memory machine for one R process than for 16 R processes.

Best,

luke

On Thu, 15 Jan 2015, Michael Lawrence wrote:

> Just wanted to start a discussion on whether R could ship with more
> appropriate GC parameters. Right now, loading the recommended package
> Matrix leads to:
>
>> library(Matrix)
>> gc()
>          used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 1076796 57.6    1368491 73.1  1198505 64.1
> Vcells 1671329 12.8    2685683 20.5  1932418 14.8
>
> Results may vary, but here R needed 64MB of N cells and 15MB of V cells to
> load one of the most important packages.
>
> Currently, the default GC triggers are ~20MB (64 bit systems) for N cells
> and ~6MB of V cells. Martin Morgan found that this leads to a lot of GC
> overhead during package loading and at least in our tests can significantly
> increase the load time of complex packages.
>
> If we set the triggers at the command line beyond the reach of
> library(Matrix) (--min-vsize=2048M --min-nsize=45M), then we see:
>
>          used (Mb) gc trigger (Mb) max used  (Mb)
> Ncells 1076859 57.6   47185920 2520  6260069 334.4
> Vcells 1671431 12.8  268435456 2048  9010303  68.8
>
> So by effectively disabling the GC, we let R consume 335MB N + 70MB of V,
> but loading goes a lot faster:
>
> Loading Matrix with default settings:
>> system.time(library(Matrix))
>   user  system elapsed
>  1.600   0.011   1.610
>
> With high GC triggers ():
>> system.time(library(Matrix))
>   user  system elapsed
>  0.983   0.097   1.079
>
> Given modern hardware capabilities and the need to efficiently load
> software for the user to be able to do something, perhaps we should bump
> the default settings so that the GC is fired sparingly when loading a large
> package.
>
> For users of Bioconductor, we see this for library(GenomicRanges):
>
>          used (Mb) gc trigger (Mb) max used  (Mb)
> Ncells 1322124 70.7   47185920 2520 15591302 832.7
> Vcells 1216015  9.3  268435456 2048 13992181 106.8
>
> So perhaps that user would want 900 MB of N and 100 MB of V as the trigger
> (corresponding to --min-vsize=100M --min-nsize=16M).
>
> Thoughts?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From rhelp at eoos.dds.nl  Sat Jan 17 20:00:38 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Sat, 17 Jan 2015 20:00:38 +0100
Subject: [Rd] Request for help with UBSAN and total absense of CRAN
	response
In-Reply-To: <20150116152142.Horde.uxImQmEwhY5UuR52g4U0GfA@webmailnew.dds.nl>
References: <21685.14887.946988.975035@max.nulle.part>
	<20150116152142.Horde.uxImQmEwhY5UuR52g4U0GfA@webmailnew.dds.nl>
Message-ID: <54BAB156.40003@eoos.dds.nl>


... and they didn't make it through. I put the files in a gist:

https://gist.github.com/djvanderlaan/1e9beb75d2d595824efc

Jan



On 16-01-15 15:21, Jan van der Laan wrote:
> Dirk,
>
> The vagrant setup I use to test my packages with UBSAN also seems to
> replicate the error reported by CRAN (together with some other
> warnings). I have attached the files (I hope they get through the
> filters). I suppose you know what to do with them.
>
> Jan
>
>
>
>
>
> Dirk Eddelbuettel <edd at debian.org> schreef:
>
>> CRAN has a package of mine in upload limbo because it failed UBSAN.
>>
>> I am not entirely ignorant on the topic of sanitizers and SAN / ASAN /
>> UBSAN;
>> we created not one but two Docker containers with ASAN and USBAN:
>>
>>    https://registry.hub.docker.com/u/rocker/r-devel-san/
>>    https://registry.hub.docker.com/u/rocker/r-devel-ubsan-clang/
>>
>> as well as predecessors to them in earlier Docker repos.
>>
>> Yet I fail to recreate the errors reported by CRAN:
>>
>>
>> http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN-clang-trunk/RcppAnnoy/tests/runUnitTests.Rout
>>
>>
>> http://www.stats.ox.ac.uk/pub/bdr/memtests/UBSAN/RcppAnnoy/tests/runUnitTests.Rout
>>
>>
>> I asked politely (and twice) for help with the corresponding compiler
>> configuration(s).  But CRAN is of course way above communicating with
>> mere
>> mortals such as yours truly.
>>
>> So I have no recourse other than to spam all of you: if anybody here
>> has a
>> working UBSAN setup which can replicate the issue seen in the (rather
>> small)
>> RcppAnnoy package?
>>
>> Erik (upstream for Annoy, CC'ed) and I would be most grateful.  We do not
>> like being held hostage on an error report we cannot replicate and for
>> which
>> we do not receive any help (or even further communication) whatsoever.
>>
>> Dirk
>> about to turn into yet another frustrated CRAN user
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From keith at wehi.EDU.AU  Sun Jan 18 05:17:15 2015
From: keith at wehi.EDU.AU (Keith Satterley)
Date: Sun, 18 Jan 2015 15:17:15 +1100 (EST)
Subject: [Rd] Is the tcltk failure in affylmGUI related to R bug 15957
In-Reply-To: <9A2846D1-D6AF-4FC7-ABCC-D12270693C0F@gmail.com>
References: <54B603B0.9090607@wehi.edu.au>
	<9A2846D1-D6AF-4FC7-ABCC-D12270693C0F@gmail.com>
Message-ID: <718649604.114432406.1421554635376.JavaMail.root@wehi.edu.au>

Thanks Peter and Dan for your replies.
After learning a bit more about tcltk and environments etc. I have replaced

  Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))

with

  Try(n <- .TkRoot$env$TclVarCount <- .TkRoot$env$TclVarCount +1L)

as you suggest.

It now works for both R-3.1.1 and R-3.1.2+

(My understanding is that the Try function is there to put a GUI box around the error messages.)

I shall update affylmGUI versions accordingly soon.

cheers
Keith
PS> I have also changed the Depends in DESCRIPTION to Imports and added an import statement to the NAMESPACE file which is independent of this problem.
Consequently removed Require("tkrplot") statements as no longer needed.

----- peter dalgaard <pdalgd at gmail.com> wrote:
> Seems unlikely that that particular bug is involved. I seem to recall some change related to inadvertent variable capture in .TkRoot$env (?). At any rate, we currently have
> 
> > parent.env(.TkRoot$env)
> <environment: R_EmptyEnv>
> 
> which used to be
> 
> > parent.env(.TkRoot$env)
> <environment: R_GlobalEnv>
> 
> as a result, this won't work any more because R_EmptyEnv has no operators and functions in it:
> 
> > evalq(x <- 1, .TkRoot$env)
> Error in eval(substitute(expr), envir, enclos) : 
>   could not find function "<-"
> 
> and consequently, you conk out at
> 
>    Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))
> 
> which presumably needs to be recoded in the same way as the current code in tclVar():
> 
> > tclVar
> function (init = "") 
> {
>     n <- .TkRoot$env$TclVarCount <- .TkRoot$env$TclVarCount + 
>         1L
>     name <- paste0("::RTcl", n)
>     l <- list(env = new.env())
>     assign(name, NULL, envir = l$env)
>     reg.finalizer(l$env, function(env) tcl("unset", ls(env)))
>     class(l) <- "tclVar"
>     tclvalue(l) <- init
>     l
> }
> 
> (The whole thing looks a bit odd: Your function clones a fair bit of tclVar, wrapping each line in Try() for no apparent reason (or?), with the apparent purpose of doing something that seems quite similar to what tclArray() already does...)
> 
> -pd
> 
> 
> > On 14 Jan 2015, at 06:50 , Keith Satterley <keith at wehi.edu.au> wrote:
> > 
> > I maintain the package affylmGUI. It works when installed on many previous versions of R. I have today tested exactly the same code under R-2.15.3, R-3.0.2, R-3.1.0, R-3.1.1, R-3.1.2 and R-devel.
> > 
> > I have also tested the versions of affylmGUI downloaded by biocLite for each version of R and the same result applies.
> > 
> > I have no errors under 2.15.3, 3.0.2, 3.1.0 and 3.1.1. The following error occurs under 3.1.2 and R-devel.
> > 
> > I run affylmGUI and read a targets file which then causes affylmGUI to read the specified cel files. On attempting to display the RNA targets file in a Tk window using the "RNA Targets" option from the "RNA Targets" Menu item and the following errors occur:
> > 
> > Error text box 1: Error in eval(substitute(expr),enclos):could not find function "<-"   - pressed OK
> > Following error text box: Error in paste("::RTcl",n,sep=""): object 'n' not found   - pressed OK
> > Following error text box: Error in assign(name, NULL, environ = I$env): object 'name' not found   - pressed OK
> > Following error text box: Error in paste("set",name, "(0,0)\"\"",sep= ""):object 'name' not found   - pressed OK
> > 
> > This then results in an unfilled Tk window.
> > 
> > I am testing on a Windows 7, 64 bit environment. My sessionInfo is:
> > 
> > R version 3.1.2 (2014-10-31)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > locale:
> > [1] LC_COLLATE=English_Australia.1252 LC_CTYPE=English_Australia.1252 LC_MONETARY=English_Australia.1252
> > [4] LC_NUMERIC=C LC_TIME=English_Australia.1252
> > attached base packages:
> > [1] stats4    parallel  tcltk     stats     graphics  grDevices utils     datasets  methods   base
> > other attached packages:
> > [1] affylmGUI_1.40.0      AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4    IRanges_2.0.1         S4Vectors_0.4.0
> > [6] xtable_1.7-4          R2HTML_2.3.1 affyPLM_1.42.0        preprocessCore_1.28.0 gcrma_2.38.0
> > [11] tkrplot_0.0-23        affyio_1.34.0 BiocInstaller_1.16.1  affy_1.44.0           Biobase_2.26.0
> > [16] BiocGenerics_0.12.1   limma_3.22.3
> > loaded via a namespace (and not attached):
> > [1] Biostrings_2.34.1 DBI_0.3.1         RSQLite_1.0.0 splines_3.1.2     XVector_0.6.0     zlibbioc_1.12.0
> > 
> > I think the relevant code that is resulting in the error is generated by this function in main.R:
> > tclArrayVar <- function(){
> >    Try(n <- evalq(TclVarCount <- TclVarCount + 1, .TkRoot$env))
> >    Try(name <- paste("::RTcl", n,sep = ""))
> >    Try(l <- list(env = new.env()))
> >    Try(assign(name, NULL, envir = l$env))
> >    Try(reg.finalizer(l$env, function(env) tcl("unset", ls(env))))
> >    Try(class(l) <- "tclArrayVar")
> >    Try(.Tcl(paste("set ",name,"(0,0) \"\"",sep="")))
> >    l  ### Investigate this line KS
> > } #end of tclArrayVar <- function()
> > 
> > This code is lines 877-886 in main.R
> > 
> > Despite the un-investigated last line in this function, it works fine in earlier versions of R as described above.
> > 
> > The original programmer has left our division some years ago and I have maintained the code since then. Consequently my understandings as to why the code was written the way it was is somewhat limited, so I have not touched anything unless it was broken.
> > 
> > My question is, do I need to do something with the affylmGUI code? I'd appreciate some advice if so.
> > 
> > Is this failure related to bug 15957 (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15957) that Duncan fixed on 2014-09-08.
> > 
> > cheers,
> > 
> > Keith
> > ==============================
> > Keith Satterley
> > Bioinformatics Division
> > The Walter & Eliza Hall Institute of Medical Research
> > Melbourne, Victoria, Australia
> > ==============================
> > 
> > 
> > ______________________________________________________________________
> > The information in this email is confidential and intend...{{dropped:4}}
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From nate at verse.com  Sun Jan 18 08:40:44 2015
From: nate at verse.com (Nathan Kurz)
Date: Sat, 17 Jan 2015 23:40:44 -0800
Subject: [Rd] default min-v/nsize parameters
In-Reply-To: <alpine.DEB.2.02.1501171035190.2583@luke-Latitude>
References: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
	<alpine.DEB.2.02.1501171035190.2583@luke-Latitude>
Message-ID: <CAFAN8vyKyp-_mfExKu3p6fGSgxMP_L+=swcvFU7qca23ZXT4og@mail.gmail.com>

On Thu, Jan 15, 2015 at 3:55 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> Just wanted to start a discussion on whether R could ship with more
> appropriate GC parameters.

I've been doing a number of similar measurements, and have come to the
same conclusion.  R is currently very conservative about memory usage,
and this leads to unnecessarily poor performance on certain problems.
Changing the defaults to sizes that are more appropriate for modern
machines can often produce a 2x speedup.

On Sat, Jan 17, 2015 at 8:39 AM,  <luke-tierney at uiowa.edu> wrote:
> Martin Morgan discussed this a year or so ago and as I recall bumped
> up these values to the current defaults. I don't recall details about
> why we didn't go higher -- maybe Martin does.

I just checked, and it doesn't seem that any of the relevant values
have been increased in the last ten years.  Do you have a link to the
discussion you recall so we can see why the changes weren't made?

> I suspect the main concern would be with small memory machines in student labs
> and less developed countries.

While a reasonable concern, I'm doubtful there are many machines for
which the current numbers are optimal.  The current minimum size
increases for node and vector heaps are 40KB and 80KB respectively.
This grows as the heap grows (min + .05 * heap), but still means that
we do many more expensive garbage collections at while growing than we
need to.  Paradoxically, the SMALL_MEMORY compile option (which is
suggestd for computers with up to 32MB of RAM) has slightly larger at
50KB and 100KB.

I think we'd get significant benefit for most users by being less
conservative about memory consumption.    The exact sizes should be
discussed, but with RAM costing about $10/GB it doesn't seem
unreasonable to assume most machines running R have multiple GB
installed, and those that don't will quite likely be running an OS
that needs a custom compiled binary anyway.

I could be way off, but my suggestion might be a 10MB start with 1MB
minimum increments for SMALL_MEMORY, 100MB start with 10MB increments
for NORMAL_MEMORY, and 1GB start with 100MB increments for
LARGE_MEMORY might be a reasonable spread.

Or one could go even larger, noting that on most systems,
overcommitted memory is not a problem until it is used.  Until we
write to it, it doesn't actually use physical RAM, just virtual
address space.  Or we could stay small, but make it possible to
programmatically increase the granularity from within R.

For ease of reference, here are the relevant sections of code:

https://github.com/wch/r-source/blob/master/src/include/Defn.h#L217
(ripley last authored on Jan 26, 2000 / pd last authored on May 8, 1999)
217  #ifndef R_NSIZE
218  #define R_NSIZE 350000L
219  #endif
220  #ifndef R_VSIZE
221  #define R_VSIZE 6291456L
222  #endif

https://github.com/wch/r-source/blob/master/src/main/startup.c#L169
(ripley last authored on Jun 9, 2004)
157 Rp->vsize = R_VSIZE;
158 Rp->nsize = R_NSIZE;
166  #define Max_Nsize 50000000 /* about 1.4Gb 32-bit, 2.8Gb 64-bit */
167  #define Max_Vsize R_SIZE_T_MAX /* unlimited */
169  #define Min_Nsize 220000
170  #define Min_Vsize (1*Mega)

https://github.com/wch/r-source/blob/master/src/main/memory.c#L335
(luke last authored on Nov 1, 2000)
#ifdef SMALL_MEMORY
336  /* On machines with only 32M of memory (or on a classic Mac OS port)
337      it might be a good idea to use settings like these that are more
338      aggressive at keeping memory usage down. */
339  static double R_NGrowIncrFrac = 0.0, R_NShrinkIncrFrac = 0.2;
340  static int R_NGrowIncrMin = 50000, R_NShrinkIncrMin = 0;
341  static double R_VGrowIncrFrac = 0.0, R_VShrinkIncrFrac = 0.2;
342  static int R_VGrowIncrMin = 100000, R_VShrinkIncrMin = 0;
343#else
344  static double R_NGrowIncrFrac = 0.05, R_NShrinkIncrFrac = 0.2;
345  static int R_NGrowIncrMin = 40000, R_NShrinkIncrMin = 0;
346  static double R_VGrowIncrFrac = 0.05, R_VShrinkIncrFrac = 0.2;
347  static int R_VGrowIncrMin = 80000, R_VShrinkIncrMin = 0;
348#endif

static void AdjustHeapSize(R_size_t size_needed)
{
    R_size_t R_MinNFree = (R_size_t)(orig_R_NSize * R_MinFreeFrac);
    R_size_t R_MinVFree = (R_size_t)(orig_R_VSize * R_MinFreeFrac);
    R_size_t NNeeded = R_NodesInUse + R_MinNFree;
    R_size_t VNeeded = R_SmallVallocSize + R_LargeVallocSize +
size_needed + R_MinVFree;
    double node_occup = ((double) NNeeded) / R_NSize;
    double vect_occup = ((double) VNeeded) / R_VSize;

    if (node_occup > R_NGrowFrac) {
        R_size_t change = (R_size_t)(R_NGrowIncrMin + R_NGrowIncrFrac
* R_NSize);
        if (R_MaxNSize >= R_NSize + change)
           R_NSize += change;
    }
    else if (node_occup < R_NShrinkFrac) {
        R_NSize -= (R_NShrinkIncrMin + R_NShrinkIncrFrac * R_NSize);
        if (R_NSize < NNeeded)
             R_NSize = (NNeeded < R_MaxNSize) ? NNeeded: R_MaxNSize;
        if (R_NSize < orig_R_NSize)
             R_NSize = orig_R_NSize;
     }

    if (vect_occup > 1.0 && VNeeded < R_MaxVSize)
        R_VSize = VNeeded;
    if (vect_occup > R_VGrowFrac) {
        R_size_t change = (R_size_t)(R_VGrowIncrMin + R_VGrowIncrFrac
* R_VSize);
        if (R_MaxVSize - R_VSize >= change)
             R_VSize += change;
    }
    else if (vect_occup < R_VShrinkFrac) {
        R_VSize -= R_VShrinkIncrMin + R_VShrinkIncrFrac * R_VSize;
        if (R_VSize < VNeeded)
           R_VSize = VNeeded;
        if (R_VSize < orig_R_VSize)
           R_VSize = orig_R_VSize;
    }

    DEBUG_ADJUST_HEAP_PRINT(node_occup, vect_occup);
}

Rp->nsize is overridden at startup by environment variable R_NSIZE if
Min_Nsize <= $R_NSIZE <= Max_Nsize.  Rp->vsize is overridden at
startup by environment variable R_VSIZE if Min_Vsize <= $R_VSIZE <=
Max_Vsize.  These are then used to set the global variables R_Nsize
and R_Vsize with R_SetMaxVSize(Rp->max_vsize).


From nashjc at uottawa.ca  Sun Jan 18 15:03:10 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sun, 18 Jan 2015 09:03:10 -0500
Subject: [Rd] Help finding source of warnings
Message-ID: <54BBBD1E.5040808@uottawa.ca>

I've been implementing a wrapper to the 2011 Fortran version of 
L-BFGS-B. In optim(), R uses a C translation of a Fortran version (the 
version number does not appear to be documented by the original 
authors). The authors of the original Fortran code have updated it and 
published the reasons in ACM TOMS due to inefficiencies and a bug.

In running the checks on the resulting package (which is on R-forge 
under the optimizer project), I'm getting a number of warning messages 
of the type

Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
   problem copying /usr/lib/R/library/mgcv/DESCRIPTION to 
/tmp/Rtmp0kkeHo/RLIBS_1214765d1c5f/mgcv/DESCRIPTION: No such file or 
directory

which reference DESCRIPTIONs for a number of packages other than the one 
being checked -- here mgcv -- and which are not referenced in my package 
as far as I can determine.

Possibly unrelated, when I run the code on a problem, it works for one 
run, then gives a NAMESPACE error and failure on the second try. Apart 
from this, checks and unit tests appear to work correctly.

Does anyone have pointers where I might find some ideas on the origin of 
the issue(s)? I suspect the warning messages are not particularly 
indicative of the source of the warnings, but that I have some subtle 
glitch in the setup and call to the Fortran.

I suspect this is not platform dependent, but I'm running Linux Mint 
17.1 (ubuntu derivative), and  R 3.1.2.

Cheers, JN


From Kurt.Hornik at wu.ac.at  Sun Jan 18 15:27:00 2015
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Sun, 18 Jan 2015 15:27:00 +0100
Subject: [Rd] Help finding source of warnings
In-Reply-To: <54BBBD1E.5040808@uottawa.ca>
References: <54BBBD1E.5040808@uottawa.ca>
Message-ID: <21691.49844.36425.520348@fangorn.hornik.net>

>>>>> Prof J C Nash (U30A) writes:

> I've been implementing a wrapper to the 2011 Fortran version of 
> L-BFGS-B. In optim(), R uses a C translation of a Fortran version (the 
> version number does not appear to be documented by the original 
> authors). The authors of the original Fortran code have updated it and 
> published the reasons in ACM TOMS due to inefficiencies and a bug.

> In running the checks on the resulting package (which is on R-forge 
> under the optimizer project), I'm getting a number of warning messages 
> of the type

> Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
>    problem copying /usr/lib/R/library/mgcv/DESCRIPTION to 
> /tmp/Rtmp0kkeHo/RLIBS_1214765d1c5f/mgcv/DESCRIPTION: No such file or 
> directory

> which reference DESCRIPTIONs for a number of packages other than the one 
> being checked -- here mgcv -- and which are not referenced in my package 
> as far as I can determine.

> Possibly unrelated, when I run the code on a problem, it works for one 
> run, then gives a NAMESPACE error and failure on the second try. Apart 
> from this, checks and unit tests appear to work correctly.

> Does anyone have pointers where I might find some ideas on the origin of 
> the issue(s)? I suspect the warning messages are not particularly 
> indicative of the source of the warnings, but that I have some subtle 
> glitch in the setup and call to the Fortran.

> I suspect this is not platform dependent, but I'm running Linux Mint 
> 17.1 (ubuntu derivative), and  R 3.1.2.

John: maybe you did not install the recommended packages?
(On Debian, the corresponding package would be r-recommended.)

Best
-k

> Cheers, JN

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Sun Jan 18 15:28:01 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 Jan 2015 08:28:01 -0600
Subject: [Rd] Help finding source of warnings
In-Reply-To: <54BBBD1E.5040808@uottawa.ca>
References: <54BBBD1E.5040808@uottawa.ca>
Message-ID: <21691.49905.136042.745516@max.nulle.part>


On 18 January 2015 at 09:03, Prof J C Nash (U30A) wrote:
| I've been implementing a wrapper to the 2011 Fortran version of 
| L-BFGS-B. In optim(), R uses a C translation of a Fortran version (the 
| version number does not appear to be documented by the original 
| authors). The authors of the original Fortran code have updated it and 
| published the reasons in ACM TOMS due to inefficiencies and a bug.
| 
| In running the checks on the resulting package (which is on R-forge 
| under the optimizer project), I'm getting a number of warning messages 
| of the type

If you were so kind to share the __name of the subpackage__ you fail to test,
one could attempt to help you.
 
| Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
|    problem copying /usr/lib/R/library/mgcv/DESCRIPTION to 
| /tmp/Rtmp0kkeHo/RLIBS_1214765d1c5f/mgcv/DESCRIPTION: No such file or 
| directory
| 
| which reference DESCRIPTIONs for a number of packages other than the one 
| being checked -- here mgcv -- and which are not referenced in my package 
| as far as I can determine.

I've seen that when R tries to be too clever by half -- somehow .libPaths()
ends up being partial.  Following the high-level decision by Hornik, Leisch
and Eddelbuettel made circa 2003 in a pub in Vienna, the Debian packages use
three entries, and if you have recommended packages installed via apt, R may
now pretend they don't exist.  

I could work on an alternate setup via Github and Travis but as you managed
to make this non-reproducible I cannot actually try that ...

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From nashjc at uottawa.ca  Sun Jan 18 15:56:14 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sun, 18 Jan 2015 09:56:14 -0500
Subject: [Rd] Help finding source of warnings
In-Reply-To: <21691.49844.36425.520348@fangorn.hornik.net>
References: <54BBBD1E.5040808@uottawa.ca>
	<21691.49844.36425.520348@fangorn.hornik.net>
Message-ID: <54BBC98E.3090308@uottawa.ca>

Kurt pointed to the issue. Thanks. I did install r-recommended, but it 
seems something went wrong at some point. A reinstall got rid of the 
warnings.

Thanks to Dirk for his offer of help.

Now I'm still getting a namespace issue on the second run of an 
optimization problem. However, I think I need to do some more digging to 
narrow down where this issue is lurking. It may be some local matter, as 
with the r-recommended links failing.

Best, JN

On 15-01-18 09:27 AM, Kurt Hornik wrote:
>>>>>> Prof J C Nash (U30A) writes:
>
>> I've been implementing a wrapper to the 2011 Fortran version of
>> L-BFGS-B. In optim(), R uses a C translation of a Fortran version (the
>> version number does not appear to be documented by the original
>> authors). The authors of the original Fortran code have updated it and
>> published the reasons in ACM TOMS due to inefficiencies and a bug.
>
>> In running the checks on the resulting package (which is on R-forge
>> under the optimizer project), I'm getting a number of warning messages
>> of the type
>
>> Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
>>     problem copying /usr/lib/R/library/mgcv/DESCRIPTION to
>> /tmp/Rtmp0kkeHo/RLIBS_1214765d1c5f/mgcv/DESCRIPTION: No such file or
>> directory
>
>> which reference DESCRIPTIONs for a number of packages other than the one
>> being checked -- here mgcv -- and which are not referenced in my package
>> as far as I can determine.
>
>> Possibly unrelated, when I run the code on a problem, it works for one
>> run, then gives a NAMESPACE error and failure on the second try. Apart
>> from this, checks and unit tests appear to work correctly.
>
>> Does anyone have pointers where I might find some ideas on the origin of
>> the issue(s)? I suspect the warning messages are not particularly
>> indicative of the source of the warnings, but that I have some subtle
>> glitch in the setup and call to the Fortran.
>
>> I suspect this is not platform dependent, but I'm running Linux Mint
>> 17.1 (ubuntu derivative), and  R 3.1.2.
>
> John: maybe you did not install the recommended packages?
> (On Debian, the corresponding package would be r-recommended.)
>
> Best
> -k
>
>> Cheers, JN
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Sun Jan 18 16:53:47 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 Jan 2015 09:53:47 -0600
Subject: [Rd] [Resolved] (Was: Request for help with UBSAN and total absense
 of CRAN) response
In-Reply-To: <20150116152142.Horde.uxImQmEwhY5UuR52g4U0GfA@webmailnew.dds.nl>
References: <21685.14887.946988.975035@max.nulle.part>
	<20150116152142.Horde.uxImQmEwhY5UuR52g4U0GfA@webmailnew.dds.nl>
Message-ID: <21691.55051.421275.849136@max.nulle.part>


I would like to express my deepest gratitude to the CRAN Maintainers for
keeping up with their perfect record of never responding to questions from
mere mortals like myself. The ensuing utter and complete silence allowed me
to work with a much higher concentration level.

More seriously, I owe a big thank you to Martyn Plummer and Jan van der Laan
for replying here (and in off-list follow-ups), and to Jeff Horner who
offered help via Twitter and off-list emails.  Thanks to their help, I did
get to the bottom of this, and it seems that part of (either mine only, or a
more general) confusion was that I wanted the test to actually _abort_ on
error.  Which, as I found after too many failed tries, requires also setting
the -fno-sanitize-recover option as well.

Long story short, we now have a working "appliance" to test this via Docker.

This is building on some of the examples I showed at the end of my useR! 2014
presentation, the work Carl and I have been doing in the Rocker.org repo for
Docker containers for R, some experimentation, and an only-at-GitHub-yet new
script for littler.  I hope to blog about this in some more detail, but if
you have Docker set-up, pull the rocker/r-devel-ubsan-clang container.  

Then:

i)  to replicate the reported error:

    docker run --rm -ti -v $(pwd):/mnt rocker/r-devel-ubsan-clang \
           check.r --setwd /mnt --install-deps RcppAnnoy_0.0.5.tar.gz 

    which runs the container with 
      - post-run cleanup (--rm), 
      - terminal and interactive mode (-ti), 
      - the current directory mounted as /mnt in the container (-v ...),
      - invoking the check.r script (from littler as on GitHub, in the path in the
        container) with options to install package dependencies
      - the known-bad tarball

ii) to see a fix not triggering it

    docker run --rm -ti -v $(pwd):/mnt rocker/r-devel-ubsan-clang \
           check.r --setwd /mnt --install-deps RcppAnnoy_0.0.5.1.tar.gz 

    as above but using an updated tarball not showing the error.

This is generic: you can plug any of your R package tarballs in there
and it will run the test.  [ This assumes dependencies can be satisfied via
install.packages(); need to add a hook for apt-get as needed etc pp ]

The UBSAN config I settled on for now is close to what Martyn had sent me (in
off-list follow-up):

 CC="clang-3.5 -fsanitize=undefined \
      -fno-sanitize=float-divide-by-zero,vptr,function -fno-sanitize-recover" 
 CXX="clang++-3.5 -fsanitize=undefined \
      -fno-sanitize=float-divide-by-zero,vptr,function -fno-sanitize-recover"
 CXX1X="clang++-3.5 -fsanitize=undefined \
      -fno-sanitize=float-divide-by-zero,vptr,function -fno-sanitize-recover" 

We may want to turn on other options; Jeff Horner sent me his config which
has a lot more goodies enabled.  

I'd welcome follow-up by anyone interested in working on this, either by
(off-list) email or directly over at the GitHub repo for this container:
   https://github.com/rocker-org/r-devel-san-clang

Thanks,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From haverty.peter at gene.com  Mon Jan 19 17:50:08 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Mon, 19 Jan 2015 08:50:08 -0800
Subject: [Rd] default min-v/nsize parameters
In-Reply-To: <CAFAN8vyKyp-_mfExKu3p6fGSgxMP_L+=swcvFU7qca23ZXT4og@mail.gmail.com>
References: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
	<alpine.DEB.2.02.1501171035190.2583@luke-Latitude>
	<CAFAN8vyKyp-_mfExKu3p6fGSgxMP_L+=swcvFU7qca23ZXT4og@mail.gmail.com>
Message-ID: <CAGh0NYrDXaT35=TUiXB4Y-bHmzQJFMwu=3OSimipMKrH20KTYw@mail.gmail.com>

Hi All,

This is a very important issue. It would be very sad to leave most users
unaware of a free speedup of this size.  These options don't appear in the
R --help output. They really should be added there. Additionally, if the
garbage collector is working very hard, might it emit a note about better
setting for these variables?

It's not really my place to comment on design philosophy, but if there is a
configure option for small memory machines I would assume that would be
sufficient for the folks that are not on fairly current hardware.

Regards,


Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Sat, Jan 17, 2015 at 11:40 PM, Nathan Kurz <nate at verse.com> wrote:

> On Thu, Jan 15, 2015 at 3:55 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
> > Just wanted to start a discussion on whether R could ship with more
> > appropriate GC parameters.
>
> I've been doing a number of similar measurements, and have come to the
> same conclusion.  R is currently very conservative about memory usage,
> and this leads to unnecessarily poor performance on certain problems.
> Changing the defaults to sizes that are more appropriate for modern
> machines can often produce a 2x speedup.
>
> On Sat, Jan 17, 2015 at 8:39 AM,  <luke-tierney at uiowa.edu> wrote:
> > Martin Morgan discussed this a year or so ago and as I recall bumped
> > up these values to the current defaults. I don't recall details about
> > why we didn't go higher -- maybe Martin does.
>
> I just checked, and it doesn't seem that any of the relevant values
> have been increased in the last ten years.  Do you have a link to the
> discussion you recall so we can see why the changes weren't made?
>
> > I suspect the main concern would be with small memory machines in
> student labs
> > and less developed countries.
>
> While a reasonable concern, I'm doubtful there are many machines for
> which the current numbers are optimal.  The current minimum size
> increases for node and vector heaps are 40KB and 80KB respectively.
> This grows as the heap grows (min + .05 * heap), but still means that
> we do many more expensive garbage collections at while growing than we
> need to.  Paradoxically, the SMALL_MEMORY compile option (which is
> suggestd for computers with up to 32MB of RAM) has slightly larger at
> 50KB and 100KB.
>
> I think we'd get significant benefit for most users by being less
> conservative about memory consumption.    The exact sizes should be
> discussed, but with RAM costing about $10/GB it doesn't seem
> unreasonable to assume most machines running R have multiple GB
> installed, and those that don't will quite likely be running an OS
> that needs a custom compiled binary anyway.
>
> I could be way off, but my suggestion might be a 10MB start with 1MB
> minimum increments for SMALL_MEMORY, 100MB start with 10MB increments
> for NORMAL_MEMORY, and 1GB start with 100MB increments for
> LARGE_MEMORY might be a reasonable spread.
>
> Or one could go even larger, noting that on most systems,
> overcommitted memory is not a problem until it is used.  Until we
> write to it, it doesn't actually use physical RAM, just virtual
> address space.  Or we could stay small, but make it possible to
> programmatically increase the granularity from within R.
>
> For ease of reference, here are the relevant sections of code:
>
> https://github.com/wch/r-source/blob/master/src/include/Defn.h#L217
> (ripley last authored on Jan 26, 2000 / pd last authored on May 8, 1999)
> 217  #ifndef R_NSIZE
> 218  #define R_NSIZE 350000L
> 219  #endif
> 220  #ifndef R_VSIZE
> 221  #define R_VSIZE 6291456L
> 222  #endif
>
> https://github.com/wch/r-source/blob/master/src/main/startup.c#L169
> (ripley last authored on Jun 9, 2004)
> 157 Rp->vsize = R_VSIZE;
> 158 Rp->nsize = R_NSIZE;
> 166  #define Max_Nsize 50000000 /* about 1.4Gb 32-bit, 2.8Gb 64-bit */
> 167  #define Max_Vsize R_SIZE_T_MAX /* unlimited */
> 169  #define Min_Nsize 220000
> 170  #define Min_Vsize (1*Mega)
>
> https://github.com/wch/r-source/blob/master/src/main/memory.c#L335
> (luke last authored on Nov 1, 2000)
> #ifdef SMALL_MEMORY
> 336  /* On machines with only 32M of memory (or on a classic Mac OS port)
> 337      it might be a good idea to use settings like these that are more
> 338      aggressive at keeping memory usage down. */
> 339  static double R_NGrowIncrFrac = 0.0, R_NShrinkIncrFrac = 0.2;
> 340  static int R_NGrowIncrMin = 50000, R_NShrinkIncrMin = 0;
> 341  static double R_VGrowIncrFrac = 0.0, R_VShrinkIncrFrac = 0.2;
> 342  static int R_VGrowIncrMin = 100000, R_VShrinkIncrMin = 0;
> 343#else
> 344  static double R_NGrowIncrFrac = 0.05, R_NShrinkIncrFrac = 0.2;
> 345  static int R_NGrowIncrMin = 40000, R_NShrinkIncrMin = 0;
> 346  static double R_VGrowIncrFrac = 0.05, R_VShrinkIncrFrac = 0.2;
> 347  static int R_VGrowIncrMin = 80000, R_VShrinkIncrMin = 0;
> 348#endif
>
> static void AdjustHeapSize(R_size_t size_needed)
> {
>     R_size_t R_MinNFree = (R_size_t)(orig_R_NSize * R_MinFreeFrac);
>     R_size_t R_MinVFree = (R_size_t)(orig_R_VSize * R_MinFreeFrac);
>     R_size_t NNeeded = R_NodesInUse + R_MinNFree;
>     R_size_t VNeeded = R_SmallVallocSize + R_LargeVallocSize +
> size_needed + R_MinVFree;
>     double node_occup = ((double) NNeeded) / R_NSize;
>     double vect_occup = ((double) VNeeded) / R_VSize;
>
>     if (node_occup > R_NGrowFrac) {
>         R_size_t change = (R_size_t)(R_NGrowIncrMin + R_NGrowIncrFrac
> * R_NSize);
>         if (R_MaxNSize >= R_NSize + change)
>            R_NSize += change;
>     }
>     else if (node_occup < R_NShrinkFrac) {
>         R_NSize -= (R_NShrinkIncrMin + R_NShrinkIncrFrac * R_NSize);
>         if (R_NSize < NNeeded)
>              R_NSize = (NNeeded < R_MaxNSize) ? NNeeded: R_MaxNSize;
>         if (R_NSize < orig_R_NSize)
>              R_NSize = orig_R_NSize;
>      }
>
>     if (vect_occup > 1.0 && VNeeded < R_MaxVSize)
>         R_VSize = VNeeded;
>     if (vect_occup > R_VGrowFrac) {
>         R_size_t change = (R_size_t)(R_VGrowIncrMin + R_VGrowIncrFrac
> * R_VSize);
>         if (R_MaxVSize - R_VSize >= change)
>              R_VSize += change;
>     }
>     else if (vect_occup < R_VShrinkFrac) {
>         R_VSize -= R_VShrinkIncrMin + R_VShrinkIncrFrac * R_VSize;
>         if (R_VSize < VNeeded)
>            R_VSize = VNeeded;
>         if (R_VSize < orig_R_VSize)
>            R_VSize = orig_R_VSize;
>     }
>
>     DEBUG_ADJUST_HEAP_PRINT(node_occup, vect_occup);
> }
>
> Rp->nsize is overridden at startup by environment variable R_NSIZE if
> Min_Nsize <= $R_NSIZE <= Max_Nsize.  Rp->vsize is overridden at
> startup by environment variable R_VSIZE if Min_Vsize <= $R_VSIZE <=
> Max_Vsize.  These are then used to set the global variables R_Nsize
> and R_Vsize with R_SetMaxVSize(Rp->max_vsize).
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From balbi at kernel.org  Mon Jan 19 20:33:21 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 19 Jan 2015 13:33:21 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
Message-ID: <1421696001-21383-1-git-send-email-balbi@kernel.org>

git has an interface for cloning SVN repositories into git which
some users might decide to use. For those users' surprise, the
repository will always fail to build on svnonly target and it will
exit early.

The problem is simple enough to fix by just checking if a .git
directory exists in top_builddir and, if so, call git svn info insstead
of svn info.

Signed-off-by: Felipe Balbi <balbi at kernel.org>
---

Resending the patch as I believe the previous version didn't
reach the mailing list.

 Makefile.in | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/Makefile.in b/Makefile.in
index 44b0a3b4b99f..221c437972ad 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -9,6 +9,9 @@ top_builddir = .
 
 include $(top_builddir)/Makeconf
 
+GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
+	echo "git"; fi)
+
 distdir = $(PACKAGE)-$(VERSION)
 INSTFILES = COPYING
 NON_SVN_INSTFILES = SVN-REVISION
@@ -104,7 +107,7 @@ svnonly:
 	@if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
 	  (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
 	  touch non-tarball ; \
-	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
+	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \
 	    | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
 	    | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
 	  if test "`cat SVN-REVISION-tmp`" = "Revision: -99"; then \
-- 
2.2.0


From murdoch.duncan at gmail.com  Mon Jan 19 21:06:11 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Jan 2015 15:06:11 -0500
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <1421696001-21383-1-git-send-email-balbi@kernel.org>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
Message-ID: <54BD63B3.8090803@gmail.com>

On 19/01/2015 2:33 PM, Felipe Balbi wrote:
> git has an interface for cloning SVN repositories into git which
> some users might decide to use. For those users' surprise, the
> repository will always fail to build on svnonly target and it will
> exit early.
> 
> The problem is simple enough to fix by just checking if a .git
> directory exists in top_builddir and, if so, call git svn info insstead
> of svn info.
> 

I think we are unlikely to accept this change.  Nobody in R Core uses
git this way, so it would never be tested, and would likely soon fail.
Indeed, it already fails if someone were to try it on Windows, since you
didn't patch the makefiles for that platform.

The R sources are kept in an SVN repository, and as long as that's true,
we're only likely to support direct SVN access.

Duncan Murdoch




> Signed-off-by: Felipe Balbi <balbi at kernel.org>
> ---
> 
> Resending the patch as I believe the previous version didn't
> reach the mailing list.
> 
>  Makefile.in | 5 ++++-
>  1 file changed, 4 insertions(+), 1 deletion(-)
> 
> diff --git a/Makefile.in b/Makefile.in
> index 44b0a3b4b99f..221c437972ad 100644
> --- a/Makefile.in
> +++ b/Makefile.in
> @@ -9,6 +9,9 @@ top_builddir = .
>  
>  include $(top_builddir)/Makeconf
>  
> +GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
> +	echo "git"; fi)
> +
>  distdir = $(PACKAGE)-$(VERSION)
>  INSTFILES = COPYING
>  NON_SVN_INSTFILES = SVN-REVISION
> @@ -104,7 +107,7 @@ svnonly:
>  	@if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
>  	  (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
>  	  touch non-tarball ; \
> -	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
> +	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \
>  	    | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
>  	    | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
>  	  if test "`cat SVN-REVISION-tmp`" = "Revision: -99"; then \
>


From mmuurr at gmail.com  Mon Jan 19 21:20:31 2015
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 19 Jan 2015 13:20:31 -0700
Subject: [Rd] order(..., na.last = NA) performance hit
Message-ID: <CA+YV+HyRjMbB+A4wRxCm1woZSHmxCQerShLm10ynYgVeSqXHdg@mail.gmail.com>

I've just recently noticed that using the na.last = NA setting with
order incurs a HUGE performance hit.
It appears that much of order(...) (the R wrapper, not the internal
calls) is written in as general a manner as possible to handle the
large number of input types.
But the canonical case of ordering a single vector of numerics suffers
greatly with the current implementation.
Below is a single trivial example, but overall I've been noticing
somewhere on the order of a 10X performance hit when using na.last =
NA.
Would it be worth (i) attempting a re-write of the wrapping order(...)
function, or (ii) at least mentioning the performance implications in
the help page for order(...)?

Here's an example of the performance hit:

x <- runif(1e6)
x[runif(1e6) > 0.9] <- NA ## add some (~10%) NA values
order2 <- function(x) {
    iix <- order(x, na.last = TRUE)
    iix[!is.na(x[iix])]
}

system.time(y1 <- order(x, na.last = TRUE))
##    user  system elapsed
##    0.48    0.00    0.48

system.time(y2 <- order(x, na.last = NA))
##    user  system elapsed
##   3.060   0.056   3.118

system.time(y3 <- order2(x))
##    user  system elapsed
##   0.520   0.004   0.520

all(y2 == y3)
## [1] TRUE
identical(y2, y3)
## [1] TRUE


Cheers,

-murat


From balbi at kernel.org  Mon Jan 19 21:20:25 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 19 Jan 2015 14:20:25 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <54BD63B3.8090803@gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com>
Message-ID: <20150119202025.GA28274@saruman>

Hi,

On Mon, Jan 19, 2015 at 03:06:11PM -0500, Duncan Murdoch wrote:
> On 19/01/2015 2:33 PM, Felipe Balbi wrote:
> > git has an interface for cloning SVN repositories into git which
> > some users might decide to use. For those users' surprise, the
> > repository will always fail to build on svnonly target and it will
> > exit early.
> > 
> > The problem is simple enough to fix by just checking if a .git
> > directory exists in top_builddir and, if so, call git svn info insstead
> > of svn info.
> > 
> 
> I think we are unlikely to accept this change.  Nobody in R Core uses
> git this way, so it would never be tested, and would likely soon fail.

it will be tested by anybody using git svn clone, right ?

> Indeed, it already fails if someone were to try it on Windows, since you
> didn't patch the makefiles for that platform.

yeah, sorry about that, I wasn't aware there were windows-specific
Makefiles with duplicated logic in the repository.

> The R sources are kept in an SVN repository, and as long as that's true,
> we're only likely to support direct SVN access.

Fair enough. But don't you think it's a bit odd to couple the repository
compilation with the availability of a specific SCM tool ?

I mean, R just won't build unless you have svn info available, I think
that's pretty odd. Printing a warning would be another possibility, but
exitting build is almost an overreaction.

But fair enough, no need to spend days discussing $subject if the
community doesn't want to support git svn clone ;-)

cheers

-- 
balbi
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 819 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150119/b91c5deb/attachment.bin>

From murdoch.duncan at gmail.com  Mon Jan 19 21:31:32 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Jan 2015 15:31:32 -0500
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <20150119202025.GA28274@saruman>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
Message-ID: <54BD69A4.60600@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 19/01/2015 3:20 PM, Felipe Balbi wrote:
> Hi,
> 
> On Mon, Jan 19, 2015 at 03:06:11PM -0500, Duncan Murdoch wrote:
>> On 19/01/2015 2:33 PM, Felipe Balbi wrote:
>>> git has an interface for cloning SVN repositories into git 
>>> which some users might decide to use. For those users' 
>>> surprise, the repository will always fail to build on svnonly 
>>> target and it will exit early.
>>> 
>>> The problem is simple enough to fix by just checking if a .git
>>>  directory exists in top_builddir and, if so, call git svn
>>> info insstead of svn info.
>>> 
>> 
>> I think we are unlikely to accept this change.  Nobody in R Core 
>> uses git this way, so it would never be tested, and would likely 
>> soon fail.
> 
> it will be tested by anybody using git svn clone, right ?
> 
>> Indeed, it already fails if someone were to try it on Windows, 
>> since you didn't patch the makefiles for that platform.
> 
> yeah, sorry about that, I wasn't aware there were windows-specific
>  Makefiles with duplicated logic in the repository.
> 
>> The R sources are kept in an SVN repository, and as long as 
>> that's true, we're only likely to support direct SVN access.
> 
> Fair enough. But don't you think it's a bit odd to couple the 
> repository compilation with the availability of a specific SCM
> tool ?
> 
> I mean, R just won't build unless you have svn info available, I 
> think that's pretty odd. Printing a warning would be another 
> possibility, but exitting build is almost an overreaction.

That's just false.  Build from a tarball, and you can store it anyway
you like.

Duncan Murdoch

> 
> But fair enough, no need to spend days discussing $subject if the 
> community doesn't want to support git svn clone ;-)
> 
> cheers
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJUvWmkAAoJEHE2Kz23YMZyRJYIALwb51h1lpauxg3UN5gTzZg6
LIDyvK0s40wfVrXFLTPq43Zvisuzkp55+o2/3GMUDNjXqgESkODtk/uRBaMdON+b
875mzqNVYHGs3a2oGMlDpZJ3qfVmb4vdNPs7G6T5xuz+Xx29RjchKCWUFZ6L96y9
r69yYTh/18dlGk1KogwLdEfT2x+4qC4cukJ4YBuphY0gdm+zO6U/fsfsN1NG6bi5
Ogt89RslpMdKZ4sIG55XiW2S9qK2BJgXhlb2Lf/+sbkoXFOXsX3LVC3fLWr3gQtY
Ll+h2NW9fC2fHxXsECHY47sVtVV6kY5MQM3xWkJ9BIYN7Bw1glAdJS3NHNpqJzI=
=pxOh
-----END PGP SIGNATURE-----


From balbi at kernel.org  Mon Jan 19 21:34:19 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 19 Jan 2015 14:34:19 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <54BD69A4.60600@gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com>
Message-ID: <20150119203419.GA24996@saruman>

Hi,

On Mon, Jan 19, 2015 at 03:31:32PM -0500, Duncan Murdoch wrote:
> >>> git has an interface for cloning SVN repositories into git 
> >>> which some users might decide to use. For those users' 
> >>> surprise, the repository will always fail to build on svnonly 
> >>> target and it will exit early.
> >>> 
> >>> The problem is simple enough to fix by just checking if a .git
> >>>  directory exists in top_builddir and, if so, call git svn
> >>> info insstead of svn info.
> >>> 
> >> 
> >> I think we are unlikely to accept this change.  Nobody in R Core 
> >> uses git this way, so it would never be tested, and would likely 
> >> soon fail.
> > 
> > it will be tested by anybody using git svn clone, right ?
> > 
> >> Indeed, it already fails if someone were to try it on Windows, 
> >> since you didn't patch the makefiles for that platform.
> > 
> > yeah, sorry about that, I wasn't aware there were windows-specific
> >  Makefiles with duplicated logic in the repository.
> > 
> >> The R sources are kept in an SVN repository, and as long as 
> >> that's true, we're only likely to support direct SVN access.
> > 
> > Fair enough. But don't you think it's a bit odd to couple the 
> > repository compilation with the availability of a specific SCM
> > tool ?
> > 
> > I mean, R just won't build unless you have svn info available, I 
> > think that's pretty odd. Printing a warning would be another 
> > possibility, but exitting build is almost an overreaction.
> 
> That's just false.  Build from a tarball, and you can store it anyway
> you like.

I'm talking about the SVN repository. Building from a tarball prevents
me from tracking R's revisions, don't you think ? But as I said, if the
community doesn't want to support a git svn clone, that's all fine and
dandy.

-- 
balbi
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 819 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150119/7ecb4558/attachment.bin>

From kevinushey at gmail.com  Mon Jan 19 21:42:36 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 19 Jan 2015 12:42:36 -0800
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <20150119203419.GA24996@saruman>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
Message-ID: <CAJXgQP2JxTENCNngKHVw61CsXQ6fhs2Jj=1R3wwxHJvkBP2=Bw@mail.gmail.com>

On Mon, Jan 19, 2015 at 12:34 PM, Felipe Balbi <balbi at kernel.org> wrote:
> Hi,
>
> On Mon, Jan 19, 2015 at 03:31:32PM -0500, Duncan Murdoch wrote:
>> >>> git has an interface for cloning SVN repositories into git
>> >>> which some users might decide to use. For those users'
>> >>> surprise, the repository will always fail to build on svnonly
>> >>> target and it will exit early.
>> >>>
>> >>> The problem is simple enough to fix by just checking if a .git
>> >>>  directory exists in top_builddir and, if so, call git svn
>> >>> info insstead of svn info.
>> >>>
>> >>
>> >> I think we are unlikely to accept this change.  Nobody in R Core
>> >> uses git this way, so it would never be tested, and would likely
>> >> soon fail.
>> >
>> > it will be tested by anybody using git svn clone, right ?
>> >
>> >> Indeed, it already fails if someone were to try it on Windows,
>> >> since you didn't patch the makefiles for that platform.
>> >
>> > yeah, sorry about that, I wasn't aware there were windows-specific
>> >  Makefiles with duplicated logic in the repository.
>> >
>> >> The R sources are kept in an SVN repository, and as long as
>> >> that's true, we're only likely to support direct SVN access.
>> >
>> > Fair enough. But don't you think it's a bit odd to couple the
>> > repository compilation with the availability of a specific SCM
>> > tool ?
>> >
>> > I mean, R just won't build unless you have svn info available, I
>> > think that's pretty odd. Printing a warning would be another
>> > possibility, but exitting build is almost an overreaction.
>>
>> That's just false.  Build from a tarball, and you can store it anyway
>> you like.
>
> I'm talking about the SVN repository. Building from a tarball prevents
> me from tracking R's revisions, don't you think ? But as I said, if the
> community doesn't want to support a git svn clone, that's all fine and
> dandy.

The community does; R-Core doesn't. See
https://github.com/wch/r-source/wiki for information on workarounds,
and feel free to add your own workarounds for building R on Windows
from a git checkout (if you have such a thing -- get in touch with
Winston and he'd be happy to modify the wiki)

>
> --
> balbi
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Jan 19 21:44:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Jan 2015 15:44:45 -0500
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <20150119203419.GA24996@saruman>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
Message-ID: <54BD6CBD.8070304@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 19/01/2015 3:34 PM, Felipe Balbi wrote:
> Hi,
> 
> On Mon, Jan 19, 2015 at 03:31:32PM -0500, Duncan Murdoch wrote:
>>>>> git has an interface for cloning SVN repositories into git
>>>>>  which some users might decide to use. For those users' 
>>>>> surprise, the repository will always fail to build on
>>>>> svnonly target and it will exit early.
>>>>> 
>>>>> The problem is simple enough to fix by just checking if a
>>>>> .git directory exists in top_builddir and, if so, call git
>>>>> svn info insstead of svn info.
>>>>> 
>>>> 
>>>> I think we are unlikely to accept this change.  Nobody in R
>>>> Core uses git this way, so it would never be tested, and
>>>> would likely soon fail.
>>> 
>>> it will be tested by anybody using git svn clone, right ?
>>> 
>>>> Indeed, it already fails if someone were to try it on
>>>> Windows, since you didn't patch the makefiles for that
>>>> platform.
>>> 
>>> yeah, sorry about that, I wasn't aware there were
>>> windows-specific Makefiles with duplicated logic in the
>>> repository.
>>> 
>>>> The R sources are kept in an SVN repository, and as long as 
>>>> that's true, we're only likely to support direct SVN access.
>>> 
>>> Fair enough. But don't you think it's a bit odd to couple the 
>>> repository compilation with the availability of a specific SCM 
>>> tool ?
>>> 
>>> I mean, R just won't build unless you have svn info available,
>>> I think that's pretty odd. Printing a warning would be another
>>>  possibility, but exitting build is almost an overreaction.
>> 
>> That's just false.  Build from a tarball, and you can store it
>> anyway you like.
> 
> I'm talking about the SVN repository. Building from a tarball
> prevents me from tracking R's revisions, don't you think ? But as I
> said, if the community doesn't want to support a git svn clone,
> that's all fine and dandy.
> 

So why not make your patch locally, and publish it for any other git
user to incorporate?  If some change to the master copy breaks it,
you'll see it, and you'll fix it.  Then everyone's happy.  One of the
purported advantages of git is the fact that it doesn't require a
central repository for everything.

Duncan Murdoch
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJUvWy9AAoJEHE2Kz23YMZyHpsH/0qDIdD2ScjvK3HNC9icGhi/
yx0elSt7CuGI1zC35UNRewMHr9VAR+CfGKV6mtwulMKpbbEm6QEED7y6fV3z3g3L
uhW6adCiUBop/Q51SbjkBp30LJ4hjkvLPwuBjJfvjYm2XqbPkf5O1RYVDWgHDWGB
/GIsbHs/VOFDc8As6KzejuiUfL1yVK+SSyU/WaQ5SINRZdVLzDALt9DDOZooH4a8
l4zKGE/z12SfTRH1yaCK6zc5nTwCBCNU++xApAj4yjjw01sryTZQfIAgkUmoQJ2i
HpULugjVVsSvQ9tvs4GoYHHHLoeo5RmZ6/Al0gQMvkm2TSliFWfGi0FaMMXhrfI=
=f0N3
-----END PGP SIGNATURE-----


From balbi at kernel.org  Mon Jan 19 22:00:41 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 19 Jan 2015 15:00:41 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <54BD6CBD.8070304@gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com>
Message-ID: <20150119210041.GB25690@saruman>

Hi,

On Mon, Jan 19, 2015 at 03:44:45PM -0500, Duncan Murdoch wrote:
> >>>>> git has an interface for cloning SVN repositories into git
> >>>>>  which some users might decide to use. For those users' 
> >>>>> surprise, the repository will always fail to build on
> >>>>> svnonly target and it will exit early.
> >>>>> 
> >>>>> The problem is simple enough to fix by just checking if a
> >>>>> .git directory exists in top_builddir and, if so, call git
> >>>>> svn info insstead of svn info.
> >>>>> 
> >>>> 
> >>>> I think we are unlikely to accept this change.  Nobody in R
> >>>> Core uses git this way, so it would never be tested, and
> >>>> would likely soon fail.
> >>> 
> >>> it will be tested by anybody using git svn clone, right ?
> >>> 
> >>>> Indeed, it already fails if someone were to try it on
> >>>> Windows, since you didn't patch the makefiles for that
> >>>> platform.
> >>> 
> >>> yeah, sorry about that, I wasn't aware there were
> >>> windows-specific Makefiles with duplicated logic in the
> >>> repository.
> >>> 
> >>>> The R sources are kept in an SVN repository, and as long as 
> >>>> that's true, we're only likely to support direct SVN access.
> >>> 
> >>> Fair enough. But don't you think it's a bit odd to couple the 
> >>> repository compilation with the availability of a specific SCM 
> >>> tool ?
> >>> 
> >>> I mean, R just won't build unless you have svn info available,
> >>> I think that's pretty odd. Printing a warning would be another
> >>>  possibility, but exitting build is almost an overreaction.
> >> 
> >> That's just false.  Build from a tarball, and you can store it
> >> anyway you like.
> > 
> > I'm talking about the SVN repository. Building from a tarball
> > prevents me from tracking R's revisions, don't you think ? But as I
> > said, if the community doesn't want to support a git svn clone,
> > that's all fine and dandy.
> > 
> 
> So why not make your patch locally, and publish it for any other git
> user to incorporate?  If some change to the master copy breaks it,

heh, that's what I'll have to do of course.

> you'll see it, and you'll fix it.  Then everyone's happy.  One of the
> purported advantages of git is the fact that it doesn't require a

it's not purported, it's a real advantage, but this is not subject of
discussion in this forum

> central repository for everything.

Right, that's all fine, it'll still be an "unofficial" change.

I just thought that such a small patch which causes no visible change to
SVN users and allow for git users to build R would be acceptable, but if
it isn't, that's fine too.

-- 
balbi
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 819 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150119/00814392/attachment.bin>

From nate at verse.com  Mon Jan 19 22:13:30 2015
From: nate at verse.com (Nathan Kurz)
Date: Mon, 19 Jan 2015 13:13:30 -0800
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <20150119210041.GB25690@saruman>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
Message-ID: <CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>

On Mon, Jan 19, 2015 at 1:00 PM, Felipe Balbi <balbi at kernel.org> wrote:
> I just thought that such a small patch which causes no visible change to
> SVN users and allow for git users to build R would be acceptable, but if
> it isn't, that's fine too.

Felipe ---

It would appear that you are unaware that you are walking a minefield
of entrenched positions and personality conflicts.  For those like
myself who are mystified by the positions taken in this thread, a
partial back story may be helpful.

In 2012, Han-Tak Leung reported a problem compiling the development
version of R that he had checked out using git's svn compability
feature: https://stat.ethz.ch/pipermail/r-devel/2012-October/065133.html

In 2013, Brian Ripley applied a patch with the comment "trap HK Leung
misuse" explicitly to prevent users from being able to do this:
https://github.com/wch/r-source/commit/4f13e5325dfbcb9fc8f55fc6027af9ae9c7750a3

Shortly thereafter, Han-Tak tried to start discussion on this list
about that patch, suggesting that preventing the use of non-SVN
mirrors reduced the frequency with which development versions would be
tested:
https://stat.ethz.ch/pipermail/r-devel/2013-March/066128.html

The opinions expressed on the thread were universally against Leung.
Peter Dalgaard summarized as:
"The generic point is that you are given access to a working tool that
is internal to the core R developers. We are not putting restrictions
on what you do with that access, but if you want to play the game by
other rules than we do, you need to take the consequences. If things
don't work and you start complaining about them being "broken", steps
may be taken to make it clearer who broke them."
https://stat.ethz.ch/pipermail/r-devel/2013-March/066131.html

As a newcomer hoping to contribute to R who had already encountered
this same compilation issue and considered it was a bug, I am
astounded to learn that it is instead desired and intentional
behavior.

--nate


From josh.m.ulrich at gmail.com  Mon Jan 19 22:37:42 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 19 Jan 2015 15:37:42 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
Message-ID: <CAPPM_gQG9vidqhMWKG3z_jqz+zHpsXkKw0Ve=writQ5+OVh+uw@mail.gmail.com>

On Mon, Jan 19, 2015 at 3:13 PM, Nathan Kurz <nate at verse.com> wrote:
> On Mon, Jan 19, 2015 at 1:00 PM, Felipe Balbi <balbi at kernel.org> wrote:
>> I just thought that such a small patch which causes no visible change to
>> SVN users and allow for git users to build R would be acceptable, but if
>> it isn't, that's fine too.
>
> Felipe ---
>
> It would appear that you are unaware that you are walking a minefield
> of entrenched positions and personality conflicts.  For those like
> myself who are mystified by the positions taken in this thread, a
> partial back story may be helpful.
>
> In 2012, Han-Tak Leung reported a problem compiling the development
> version of R that he had checked out using git's svn compability
> feature: https://stat.ethz.ch/pipermail/r-devel/2012-October/065133.html
>
You forgot to mention that, in February of 2013, Hin-Tak reported that
Matrix did not build with the R trunk since October, 2012; but it
turned out not to build because he didn't have a subversion checkout.
https://mailman.stat.ethz.ch/pipermail/r-devel/2013-February/065858.html

> In 2013, Brian Ripley applied a patch with the comment "trap HK Leung
> misuse" explicitly to prevent users from being able to do this:
> https://github.com/wch/r-source/commit/4f13e5325dfbcb9fc8f55fc6027af9ae9c7750a3
>
> Shortly thereafter, Han-Tak tried to start discussion on this list
> about that patch, suggesting that preventing the use of non-SVN
> mirrors reduced the frequency with which development versions would be
> tested:
> https://stat.ethz.ch/pipermail/r-devel/2013-March/066128.html
>
> The opinions expressed on the thread were universally against Leung.
> Peter Dalgaard summarized as:
> "The generic point is that you are given access to a working tool that
> is internal to the core R developers. We are not putting restrictions
> on what you do with that access, but if you want to play the game by
> other rules than we do, you need to take the consequences. If things
> don't work and you start complaining about them being "broken", steps
> may be taken to make it clearer who broke them."
> https://stat.ethz.ch/pipermail/r-devel/2013-March/066131.html
>
> As a newcomer hoping to contribute to R who had already encountered
> this same compilation issue and considered it was a bug, I am
> astounded to learn that it is instead desired and intentional
> behavior.
>
> --nate
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From murdoch.duncan at gmail.com  Mon Jan 19 23:11:38 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Jan 2015 17:11:38 -0500
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
Message-ID: <54BD811A.5060309@gmail.com>

On 19/01/2015 4:13 PM, Nathan Kurz wrote:
> On Mon, Jan 19, 2015 at 1:00 PM, Felipe Balbi <balbi at kernel.org> wrote:
>> I just thought that such a small patch which causes no visible change to
>> SVN users and allow for git users to build R would be acceptable, but if
>> it isn't, that's fine too.
> 
> Felipe ---
> 
> It would appear that you are unaware that you are walking a minefield
> of entrenched positions and personality conflicts.  For those like
> myself who are mystified by the positions taken in this thread, a
> partial back story may be helpful.

I don't think there should be anything particularly mystifying here.
The people who would have to maintain the patch can't test it.  The
people who can test it can apply it themselves.  It's just a matter of
efficiency.  There's a very easy way for you to use the svn checkout,
and that is to check it out using svn.  If you want to use a tool that's
never tested, then you're on your own.

In another reply to you, Joshua pointed out one of the problems that
using untested tools causes.  It wasted a lot of Hin-Tak's and other
people's time.  That time could have been spent in a productive way, but
it wasn't.

Duncan Murdoch


> 
> In 2012, Han-Tak Leung reported a problem compiling the development
> version of R that he had checked out using git's svn compability
> feature: https://stat.ethz.ch/pipermail/r-devel/2012-October/065133.html
> 
> In 2013, Brian Ripley applied a patch with the comment "trap HK Leung
> misuse" explicitly to prevent users from being able to do this:
> https://github.com/wch/r-source/commit/4f13e5325dfbcb9fc8f55fc6027af9ae9c7750a3
> 
> Shortly thereafter, Han-Tak tried to start discussion on this list
> about that patch, suggesting that preventing the use of non-SVN
> mirrors reduced the frequency with which development versions would be
> tested:
> https://stat.ethz.ch/pipermail/r-devel/2013-March/066128.html
> 
> The opinions expressed on the thread were universally against Leung.
> Peter Dalgaard summarized as:
> "The generic point is that you are given access to a working tool that
> is internal to the core R developers. We are not putting restrictions
> on what you do with that access, but if you want to play the game by
> other rules than we do, you need to take the consequences. If things
> don't work and you start complaining about them being "broken", steps
> may be taken to make it clearer who broke them."
> https://stat.ethz.ch/pipermail/r-devel/2013-March/066131.html
> 
> As a newcomer hoping to contribute to R who had already encountered
> this same compilation issue and considered it was a bug, I am
> astounded to learn that it is instead desired and intentional
> behavior.
> 
> --nate
>


From tal.galili at gmail.com  Mon Jan 19 23:30:56 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 20 Jan 2015 00:30:56 +0200
Subject: [Rd] Link to NEWS.2 in NEWS is broken
Message-ID: <CANdJ3dWehs9T79z_DfHLGt6tan5ffi4w7mfXgaKA+8tbowz9NQ@mail.gmail.com>

I am not sure where to post this.

I am looking at the NEWS file here:
http://cran.r-project.org/bin/windows/base/NEWS.R-3.1.2.html
And the links at the bottom seem to be broken.
This link:
http://cran.r-project.org/bin/windows/NEWS.2

Should be this:
http://cran.r-project.org/doc/manuals/NEWS.2


CHANGES in previous versions

   -

   Older news can be found in text format in files NEWS.0
   <http://cran.r-project.org/bin/windows/NEWS.0>, NEWS.1
   <http://cran.r-project.org/bin/windows/NEWS.1> and NEWS.2
   <http://cran.r-project.org/bin/windows/NEWS.2> in the ?doc? directory.
   News in HTML format for *R* versions from 2.10.0 to 2.15.3 is in
   NEWS.2.html <http://cran.r-project.org/bin/windows/base/NEWS.2.html>.




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From edd at debian.org  Mon Jan 19 23:35:31 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 19 Jan 2015 16:35:31 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <54BD811A.5060309@gmail.com>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
	<54BD811A.5060309@gmail.com>
Message-ID: <21693.34483.729086.121918@max.nulle.part>


On 19 January 2015 at 17:11, Duncan Murdoch wrote:
| The people who would have to maintain the patch can't test it.  

I don't understand this.

The patch, as we may want to recall, was all of

   +GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
   +	echo "git"; fi)
   +

and

   -	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
   +	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \

I believe you can test that builds works before applying the patch, and
afterwards---even when you do not have git, or in this case a git checkout.
The idiom of expanding a variable to "nothing" if not set is used all over
the R sources and can be assumed common.  And if (hypothetically speaking)
the build failed when a .git directory was present?  None of R Core's concern
either as git was never supported.

I really do not understand the excitement over this.  The patch is short,
clean, simple, and removes an entirely unnecessary element of friction.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kmillar at google.com  Tue Jan 20 01:33:15 2015
From: kmillar at google.com (Karl Millar)
Date: Mon, 19 Jan 2015 16:33:15 -0800
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <21693.34483.729086.121918@max.nulle.part>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
	<54BD811A.5060309@gmail.com> <21693.34483.729086.121918@max.nulle.part>
Message-ID: <CABz6aZfbZq4_Fiuw_gSxzcVsExZ=XTuac3ZXb1Wx-ws5X5v9cw@mail.gmail.com>

Fellipe,

CXXR development has moved to github, and we haven't fixed up the build for
using git yet.  Could you send a pull request with your change to the repo
at https://github.com/cxxr-devel/cxxr/?

Also, this patch may be useful for pqR too.
https://github.com/radfordneal/pqR

Thanks

On Mon, Jan 19, 2015 at 2:35 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 19 January 2015 at 17:11, Duncan Murdoch wrote:
> | The people who would have to maintain the patch can't test it.
>
> I don't understand this.
>
> The patch, as we may want to recall, was all of
>
>    +GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
>    +    echo "git"; fi)
>    +
>
> and
>
>    -      (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision:
> -99") 2> /dev/null \
>    +      (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO)
> "Revision: -99") 2> /dev/null \
>
> I believe you can test that builds works before applying the patch, and
> afterwards---even when you do not have git, or in this case a git checkout.
> The idiom of expanding a variable to "nothing" if not set is used all over
> the R sources and can be assumed common.  And if (hypothetically speaking)
> the build failed when a .git directory was present?  None of R Core's
> concern
> either as git was never supported.
>
> I really do not understand the excitement over this.  The patch is short,
> clean, simple, and removes an entirely unnecessary element of friction.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From balbi at kernel.org  Tue Jan 20 01:49:49 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 19 Jan 2015 18:49:49 -0600
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <CABz6aZfbZq4_Fiuw_gSxzcVsExZ=XTuac3ZXb1Wx-ws5X5v9cw@mail.gmail.com>
References: <54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
	<54BD811A.5060309@gmail.com>
	<21693.34483.729086.121918@max.nulle.part>
	<CABz6aZfbZq4_Fiuw_gSxzcVsExZ=XTuac3ZXb1Wx-ws5X5v9cw@mail.gmail.com>
Message-ID: <20150120004949.GA11494@saruman>

Hi,

On Mon, Jan 19, 2015 at 04:33:15PM -0800, Karl Millar wrote:
> Felipe,
> 
> CXXR development has moved to github, and we haven't fixed up the build for
> using git yet.?? Could you send a pull request with your change to the repo at??
> https://github.com/cxxr-devel/cxxr/?
> 
> Also, this patch may be useful for pqR too. ??https://github.com/radfordneal/pqR

I'll have a look tomorrow.

-- 
balbi
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 819 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150119/cc0c4ff3/attachment.bin>

From maechler at stat.math.ethz.ch  Tue Jan 20 10:42:27 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Jan 2015 10:42:27 +0100
Subject: [Rd] default min-v/nsize parameters
In-Reply-To: <CAGh0NYrDXaT35=TUiXB4Y-bHmzQJFMwu=3OSimipMKrH20KTYw@mail.gmail.com>
References: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
	<alpine.DEB.2.02.1501171035190.2583@luke-Latitude>
	<CAFAN8vyKyp-_mfExKu3p6fGSgxMP_L+=swcvFU7qca23ZXT4og@mail.gmail.com>
	<CAGh0NYrDXaT35=TUiXB4Y-bHmzQJFMwu=3OSimipMKrH20KTYw@mail.gmail.com>
Message-ID: <21694.8963.940365.956366@stat.math.ethz.ch>

>>>>> Peter Haverty <haverty.peter at gene.com>
>>>>>     on Mon, 19 Jan 2015 08:50:08 -0800 writes:

    > Hi All, This is a very important issue. It would be very
    > sad to leave most users unaware of a free speedup of this
    > size.  These options don't appear in the R --help
    > output. They really should be added there.

Indeed, I've found that myself and had added them there about
24 hours ago. 
((I think they were accidentally dropped a while ago))

    > if the garbage collector is working very hard, might it
    > emit a note about better setting for these variables?

    > It's not really my place to comment on design philosophy,
    > but if there is a configure option for small memory
    > machines I would assume that would be sufficient for the
    > folks that are not on fairly current hardware.

There's quite a few more issues with this,
notably how the growth *steps* are done.
That has been somewhat experimental and for that reason is
_currently_ quite configurable via R_GC_* environment variables,
see the code in src/main/memory.c

This is currently discussed "privately" within the R core.
I'm somewhat confident that R 3.2.0 in April will have changes.

And -- coming back to the beginning -- at least the "R-devel" version now shows 

R --help | grep -e min-.size

  --min-nsize=N         Set min number of fixed size obj's ("cons cells") to N
  --min-vsize=N         Set vector heap minimum to N bytes; '4M' = 4 MegaB

--
Martin Maechler, ETH Zurich

    > On Sat, Jan 17, 2015 at 11:40 PM, Nathan Kurz <nate at verse.com> wrote:

    >> On Thu, Jan 15, 2015 at 3:55 PM, Michael Lawrence
    >> <lawrence.michael at gene.com> wrote:
    >> > Just wanted to start a discussion on whether R could ship with more
    >> > appropriate GC parameters.
    >> 
    >> I've been doing a number of similar measurements, and have come to the
    >> same conclusion.  R is currently very conservative about memory usage,
    >> and this leads to unnecessarily poor performance on certain problems.
    >> Changing the defaults to sizes that are more appropriate for modern
    >> machines can often produce a 2x speedup.
    >> 
    >> On Sat, Jan 17, 2015 at 8:39 AM,  <luke-tierney at uiowa.edu> wrote:
    >> > Martin Morgan discussed this a year or so ago and as I recall bumped
    >> > up these values to the current defaults. I don't recall details about
    >> > why we didn't go higher -- maybe Martin does.
    >> 
    >> I just checked, and it doesn't seem that any of the relevant values
    >> have been increased in the last ten years.  Do you have a link to the
    >> discussion you recall so we can see why the changes weren't made?
    >> 
    >> > I suspect the main concern would be with small memory machines in
    >> student labs
    >> > and less developed countries.
    >> 
    >> While a reasonable concern, I'm doubtful there are many machines for
    >> which the current numbers are optimal.  The current minimum size
    >> increases for node and vector heaps are 40KB and 80KB respectively.
    >> This grows as the heap grows (min + .05 * heap), but still means that
    >> we do many more expensive garbage collections at while growing than we
    >> need to.  Paradoxically, the SMALL_MEMORY compile option (which is
    >> suggestd for computers with up to 32MB of RAM) has slightly larger at
    >> 50KB and 100KB.
    >> 
    >> I think we'd get significant benefit for most users by being less
    >> conservative about memory consumption.    The exact sizes should be
    >> discussed, but with RAM costing about $10/GB it doesn't seem
    >> unreasonable to assume most machines running R have multiple GB
    >> installed, and those that don't will quite likely be running an OS
    >> that needs a custom compiled binary anyway.
    >> 
    >> I could be way off, but my suggestion might be a 10MB start with 1MB
    >> minimum increments for SMALL_MEMORY, 100MB start with 10MB increments
    >> for NORMAL_MEMORY, and 1GB start with 100MB increments for
    >> LARGE_MEMORY might be a reasonable spread.
    >> 
    >> Or one could go even larger, noting that on most systems,
    >> overcommitted memory is not a problem until it is used.  Until we
    >> write to it, it doesn't actually use physical RAM, just virtual
    >> address space.  Or we could stay small, but make it possible to
    >> programmatically increase the granularity from within R.
    >> 
    >> For ease of reference, here are the relevant sections of code:
    >> 
    >> https://github.com/wch/r-source/blob/master/src/include/Defn.h#L217
    >> (ripley last authored on Jan 26, 2000 / pd last authored on May 8, 1999)
    >> 217  #ifndef R_NSIZE
    >> 218  #define R_NSIZE 350000L
    >> 219  #endif
    >> 220  #ifndef R_VSIZE
    >> 221  #define R_VSIZE 6291456L
    >> 222  #endif
    >> 
    >> https://github.com/wch/r-source/blob/master/src/main/startup.c#L169
    >> (ripley last authored on Jun 9, 2004)
    >> 157 Rp->vsize = R_VSIZE;
    >> 158 Rp->nsize = R_NSIZE;
    >> 166  #define Max_Nsize 50000000 /* about 1.4Gb 32-bit, 2.8Gb 64-bit */
    >> 167  #define Max_Vsize R_SIZE_T_MAX /* unlimited */
    >> 169  #define Min_Nsize 220000
    >> 170  #define Min_Vsize (1*Mega)
    >> 
    >> https://github.com/wch/r-source/blob/master/src/main/memory.c#L335
    >> (luke last authored on Nov 1, 2000)
    >> #ifdef SMALL_MEMORY
    >> 336  /* On machines with only 32M of memory (or on a classic Mac OS port)
    >> 337      it might be a good idea to use settings like these that are more
    >> 338      aggressive at keeping memory usage down. */
    >> 339  static double R_NGrowIncrFrac = 0.0, R_NShrinkIncrFrac = 0.2;
    >> 340  static int R_NGrowIncrMin = 50000, R_NShrinkIncrMin = 0;
    >> 341  static double R_VGrowIncrFrac = 0.0, R_VShrinkIncrFrac = 0.2;
    >> 342  static int R_VGrowIncrMin = 100000, R_VShrinkIncrMin = 0;
    >> 343#else
    >> 344  static double R_NGrowIncrFrac = 0.05, R_NShrinkIncrFrac = 0.2;
    >> 345  static int R_NGrowIncrMin = 40000, R_NShrinkIncrMin = 0;
    >> 346  static double R_VGrowIncrFrac = 0.05, R_VShrinkIncrFrac = 0.2;
    >> 347  static int R_VGrowIncrMin = 80000, R_VShrinkIncrMin = 0;
    >> 348#endif
    >> 
    >> static void AdjustHeapSize(R_size_t size_needed)
    >> {
    >> R_size_t R_MinNFree = (R_size_t)(orig_R_NSize * R_MinFreeFrac);
    >> R_size_t R_MinVFree = (R_size_t)(orig_R_VSize * R_MinFreeFrac);
    >> R_size_t NNeeded = R_NodesInUse + R_MinNFree;
    >> R_size_t VNeeded = R_SmallVallocSize + R_LargeVallocSize +
    >> size_needed + R_MinVFree;
    >> double node_occup = ((double) NNeeded) / R_NSize;
    >> double vect_occup = ((double) VNeeded) / R_VSize;
    >> 
    >> if (node_occup > R_NGrowFrac) {
    >> R_size_t change = (R_size_t)(R_NGrowIncrMin + R_NGrowIncrFrac
    >> * R_NSize);
    >> if (R_MaxNSize >= R_NSize + change)
    >> R_NSize += change;
    >> }
    >> else if (node_occup < R_NShrinkFrac) {
    >> R_NSize -= (R_NShrinkIncrMin + R_NShrinkIncrFrac * R_NSize);
    >> if (R_NSize < NNeeded)
    >> R_NSize = (NNeeded < R_MaxNSize) ? NNeeded: R_MaxNSize;
    >> if (R_NSize < orig_R_NSize)
    >> R_NSize = orig_R_NSize;
    >> }
    >> 
    >> if (vect_occup > 1.0 && VNeeded < R_MaxVSize)
    >> R_VSize = VNeeded;
    >> if (vect_occup > R_VGrowFrac) {
    >> R_size_t change = (R_size_t)(R_VGrowIncrMin + R_VGrowIncrFrac
    >> * R_VSize);
    >> if (R_MaxVSize - R_VSize >= change)
    >> R_VSize += change;
    >> }
    >> else if (vect_occup < R_VShrinkFrac) {
    >> R_VSize -= R_VShrinkIncrMin + R_VShrinkIncrFrac * R_VSize;
    >> if (R_VSize < VNeeded)
    >> R_VSize = VNeeded;
    >> if (R_VSize < orig_R_VSize)
    >> R_VSize = orig_R_VSize;
    >> }
    >> 
    >> DEBUG_ADJUST_HEAP_PRINT(node_occup, vect_occup);
    >> }
    >> 
    Rp-> nsize is overridden at startup by environment variable R_NSIZE if
    >> Min_Nsize <= $R_NSIZE <= Max_Nsize.  Rp->vsize is overridden at
    >> startup by environment variable R_VSIZE if Min_Vsize <= $R_VSIZE <=
    >> Max_Vsize.  These are then used to set the global variables R_Nsize
    >> and R_Vsize with R_SetMaxVSize(Rp->max_vsize).
    >>


From maechler at stat.math.ethz.ch  Tue Jan 20 12:44:34 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Jan 2015 12:44:34 +0100
Subject: [Rd] [PATCH] Makefile: add support for git svn clones
In-Reply-To: <21693.34483.729086.121918@max.nulle.part>
References: <1421696001-21383-1-git-send-email-balbi@kernel.org>
	<54BD63B3.8090803@gmail.com> <20150119202025.GA28274@saruman>
	<54BD69A4.60600@gmail.com> <20150119203419.GA24996@saruman>
	<54BD6CBD.8070304@gmail.com> <20150119210041.GB25690@saruman>
	<CAFAN8vxnX5Bb-8rDP2mJZE0s4V7mjFBPBfPx2XO31gUtUccsUQ@mail.gmail.com>
	<54BD811A.5060309@gmail.com>
	<21693.34483.729086.121918@max.nulle.part>
Message-ID: <21694.16290.286981.607916@stat.math.ethz.ch>

>>>>> Dirk Eddelbuettel <edd at debian.org>
>>>>>     on Mon, 19 Jan 2015 16:35:31 -0600 writes:

    > On 19 January 2015 at 17:11, Duncan Murdoch wrote:
    > | The people who would have to maintain the patch can't test it.  

I agree that this is good reason to not add delicate code to the
R sources, indeed,  however, read on ..

    > I don't understand this.

    > The patch, as we may want to recall, was all of

    > +GIT := $(shell if [ -d "$(top_builddir)/.git" ]; then \
    > +	echo "git"; fi)
    > +

    > and

    > -	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
    > +	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \

the other thing needed -- apart from a similar patch to the Windows Makefile
is to make the above "portable" in the sense that it works for
standard make as opposed to just GNU make....
This requirement also helps portability to (albeit rare I think) platforms.
AFAICS, this simply needs replacement of  
	$(shell  <stuff>)
by      ` <stuff> `

    > I believe you can test that builds works before applying the patch, and
    > afterwards---even when you do not have git, or in this case a git checkout.

    > The idiom of expanding a variable to "nothing" if not set is used all over
    > the R sources and can be assumed common.  And if (hypothetically speaking)
    > the build failed when a .git directory was present?  None of R Core's concern
    > either as git was never supported.

    > I really do not understand the excitement over this.  The patch is short,
    > clean, simple, and removes an entirely unnecessary element of friction.

I agree partly - as I agree with Duncan's points -
and for this case, in spite of good reasons why such a patch can
be problematic to accept, I'm tending to think of  "sponsoring"
it, i.e., putting
it in *and* maintain it (if that maintenance is close to "nil" :-),
notably after you add the changes mentioned above.  

As, indeed, I don't see how it can harm, and you, the git users
among us (= "the people interested in tracking R development
sources") would keep some responsibility with it.

I would like to keep us in a good "community" spirit of
collaborating and focused on the advancement of Free Software in
general and of R in particular, and so help each other as much
as possible with the limited resources we have....

Best,
Martin


From maechler at stat.math.ethz.ch  Tue Jan 20 13:05:35 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Jan 2015 13:05:35 +0100
Subject: [Rd] Link to NEWS.2 in NEWS is broken
In-Reply-To: <CANdJ3dWehs9T79z_DfHLGt6tan5ffi4w7mfXgaKA+8tbowz9NQ@mail.gmail.com>
References: <CANdJ3dWehs9T79z_DfHLGt6tan5ffi4w7mfXgaKA+8tbowz9NQ@mail.gmail.com>
Message-ID: <21694.17551.505636.348829@stat.math.ethz.ch>

>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>     on Tue, 20 Jan 2015 00:30:56 +0200 writes:

    > I am not sure where to post this.

Maybe you could try to contact the CRAN maintainer by e-mail.
(E-mail: you know the thing people did before they "posted" everything :-) ;-))
but I agree that it is not easy to find e-mail addresses nowadays..

More seriously:  Thank you, Tal!

    > I am looking at the NEWS file here:
    > http://cran.r-project.org/bin/windows/base/NEWS.R-3.1.2.html
    > And the links at the bottom seem to be broken.
    > This link:
    > http://cran.r-project.org/bin/windows/NEWS.2

    > Should be this:
    > http://cran.r-project.org/doc/manuals/NEWS.2

well, there yes.

If you look at the more typical place of the NEWS,
which you get to quickly from the Main CRAN or R-project web
page, namely
      http://www.r-project.org/news.html
and its bottom link
    http://cran.r-project.org/src/base/NEWS.html

then on the bottom of that pakage, there, even the ...../NEWS.2.html fails.


    > CHANGES in previous versions
    > -
    > Older news can be found in text format in files NEWS.0
    > <http://cran.r-project.org/bin/windows/NEWS.0>, NEWS.1
    > <http://cran.r-project.org/bin/windows/NEWS.1> and NEWS.2
    > <http://cran.r-project.org/bin/windows/NEWS.2> in the ?doc? directory.
    > News in HTML format for *R* versions from 2.10.0 to 2.15.3 is in
    > NEWS.2.html <http://cran.r-project.org/bin/windows/base/NEWS.2.html>.

As you probably know these are all autogenerated from the
source file  <Rsrc>/doc/NEWS.Rd

  ((and so there is some reason why posting to R-devel may be somewhat ok))

and the relevant part of that is

\section{CHANGES in previous versions}{
  \itemize{
    \item Older news can be found in text format in files
    \ifelse{html}{\href{../NEWS.0}{NEWS.0}, \href{../NEWS.1}{NEWS.1}
      and \href{../NEWS.2}{NEWS.2}}{\file{NEWS.0}, \file{NEWS.1} and
      \file{NEWS.2}}
    in the \file{doc} directory.  News in HTML format for
    \R versions from 2.10.0 to 2.15.3 is in
    \ifelse{html}{\url{NEWS.2.html}}{\file{doc/html/NEWS.2.html}}.
  }
}

*and* that source produces a NEWS.html which works correctly in
the important use of R's "builtin HTML help",
i.e. for me what I get after help.start(),  I presume that's
also the toplevel help page Rstudio users see.
And there, the "../NEWS.O" (relative link) *is* the correct location.

Using relative links is a very good idea here, as all that
should work completely offline.

The task here is to adapt all the other "published" versions of the
generated NEWS.html files to point to a web (as opposed to
local/relative) URL.

Yes ``just another'' tweak for the CRAN web page generation
scripts...

Martin


From pdalgd at gmail.com  Tue Jan 20 13:49:16 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 20 Jan 2015 13:49:16 +0100
Subject: [Rd] Link to NEWS.2 in NEWS is broken
In-Reply-To: <21694.17551.505636.348829@stat.math.ethz.ch>
References: <CANdJ3dWehs9T79z_DfHLGt6tan5ffi4w7mfXgaKA+8tbowz9NQ@mail.gmail.com>
	<21694.17551.505636.348829@stat.math.ethz.ch>
Message-ID: <279EECA5-1E48-4870-94DA-E4D7B2B232A7@gmail.com>

I think Kurt has this in hand since the same issue affected src/base/NEWS.html. The fix seems to be just not to copy the html formatted NEWS to the file distribution folders and have any links in there point to doc/manuals/r-release/NEWS.html instead. The relative links to the parent directory would be a pain to sort out.

(Cc: Kurt, as he may not be aware that there is a fix to apply to bin/windows/base/index.html as well.)

-pd

On 20 Jan 2015, at 13:05 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>>    on Tue, 20 Jan 2015 00:30:56 +0200 writes:
> 
>> I am not sure where to post this.
> 
> Maybe you could try to contact the CRAN maintainer by e-mail.
> (E-mail: you know the thing people did before they "posted" everything :-) ;-))
> but I agree that it is not easy to find e-mail addresses nowadays..
> 
> More seriously:  Thank you, Tal!
> 
>> I am looking at the NEWS file here:
>> http://cran.r-project.org/bin/windows/base/NEWS.R-3.1.2.html
>> And the links at the bottom seem to be broken.
>> This link:
>> http://cran.r-project.org/bin/windows/NEWS.2
> 
>> Should be this:
>> http://cran.r-project.org/doc/manuals/NEWS.2
> 
> well, there yes.
> 
> If you look at the more typical place of the NEWS,
> which you get to quickly from the Main CRAN or R-project web
> page, namely
>      http://www.r-project.org/news.html
> and its bottom link
>    http://cran.r-project.org/src/base/NEWS.html
> 
> then on the bottom of that pakage, there, even the ...../NEWS.2.html fails.
> 
> 
>> CHANGES in previous versions
>> -
>> Older news can be found in text format in files NEWS.0
>> <http://cran.r-project.org/bin/windows/NEWS.0>, NEWS.1
>> <http://cran.r-project.org/bin/windows/NEWS.1> and NEWS.2
>> <http://cran.r-project.org/bin/windows/NEWS.2> in the ?doc? directory.
>> News in HTML format for *R* versions from 2.10.0 to 2.15.3 is in
>> NEWS.2.html <http://cran.r-project.org/bin/windows/base/NEWS.2.html>.
> 
> As you probably know these are all autogenerated from the
> source file  <Rsrc>/doc/NEWS.Rd
> 
>  ((and so there is some reason why posting to R-devel may be somewhat ok))
> 
> and the relevant part of that is
> 
> \section{CHANGES in previous versions}{
>  \itemize{
>    \item Older news can be found in text format in files
>    \ifelse{html}{\href{../NEWS.0}{NEWS.0}, \href{../NEWS.1}{NEWS.1}
>      and \href{../NEWS.2}{NEWS.2}}{\file{NEWS.0}, \file{NEWS.1} and
>      \file{NEWS.2}}
>    in the \file{doc} directory.  News in HTML format for
>    \R versions from 2.10.0 to 2.15.3 is in
>    \ifelse{html}{\url{NEWS.2.html}}{\file{doc/html/NEWS.2.html}}.
>  }
> }
> 
> *and* that source produces a NEWS.html which works correctly in
> the important use of R's "builtin HTML help",
> i.e. for me what I get after help.start(),  I presume that's
> also the toplevel help page Rstudio users see.
> And there, the "../NEWS.O" (relative link) *is* the correct location.
> 
> Using relative links is a very good idea here, as all that
> should work completely offline.
> 
> The task here is to adapt all the other "published" versions of the
> generated NEWS.html files to point to a web (as opposed to
> local/relative) URL.
> 
> Yes ``just another'' tweak for the CRAN web page generation
> scripts...
> 
> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tal.galili at gmail.com  Tue Jan 20 17:34:48 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 20 Jan 2015 18:34:48 +0200
Subject: [Rd] Link to NEWS.2 in NEWS is broken
In-Reply-To: <279EECA5-1E48-4870-94DA-E4D7B2B232A7@gmail.com>
References: <CANdJ3dWehs9T79z_DfHLGt6tan5ffi4w7mfXgaKA+8tbowz9NQ@mail.gmail.com>
	<21694.17551.505636.348829@stat.math.ethz.ch>
	<279EECA5-1E48-4870-94DA-E4D7B2B232A7@gmail.com>
Message-ID: <CANdJ3dVZOyz=4KNBhvvCbKsghVs4Vz6H7YsZpXSOQkROYKSn1w@mail.gmail.com>

Thanks Peter and Martin.

Cheers,
Tal



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Tue, Jan 20, 2015 at 2:49 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> I think Kurt has this in hand since the same issue affected
> src/base/NEWS.html. The fix seems to be just not to copy the html formatted
> NEWS to the file distribution folders and have any links in there point to
> doc/manuals/r-release/NEWS.html instead. The relative links to the parent
> directory would be a pain to sort out.
>
> (Cc: Kurt, as he may not be aware that there is a fix to apply to
> bin/windows/base/index.html as well.)
>
> -pd
>
> On 20 Jan 2015, at 13:05 , Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
> >>>>>> Tal Galili <tal.galili at gmail.com>
> >>>>>>    on Tue, 20 Jan 2015 00:30:56 +0200 writes:
> >
> >> I am not sure where to post this.
> >
> > Maybe you could try to contact the CRAN maintainer by e-mail.
> > (E-mail: you know the thing people did before they "posted" everything
> :-) ;-))
> > but I agree that it is not easy to find e-mail addresses nowadays..
> >
> > More seriously:  Thank you, Tal!
> >
> >> I am looking at the NEWS file here:
> >> http://cran.r-project.org/bin/windows/base/NEWS.R-3.1.2.html
> >> And the links at the bottom seem to be broken.
> >> This link:
> >> http://cran.r-project.org/bin/windows/NEWS.2
> >
> >> Should be this:
> >> http://cran.r-project.org/doc/manuals/NEWS.2
> >
> > well, there yes.
> >
> > If you look at the more typical place of the NEWS,
> > which you get to quickly from the Main CRAN or R-project web
> > page, namely
> >      http://www.r-project.org/news.html
> > and its bottom link
> >    http://cran.r-project.org/src/base/NEWS.html
> >
> > then on the bottom of that pakage, there, even the ...../NEWS.2.html
> fails.
> >
> >
> >> CHANGES in previous versions
> >> -
> >> Older news can be found in text format in files NEWS.0
> >> <http://cran.r-project.org/bin/windows/NEWS.0>, NEWS.1
> >> <http://cran.r-project.org/bin/windows/NEWS.1> and NEWS.2
> >> <http://cran.r-project.org/bin/windows/NEWS.2> in the ?doc? directory.
> >> News in HTML format for *R* versions from 2.10.0 to 2.15.3 is in
> >> NEWS.2.html <http://cran.r-project.org/bin/windows/base/NEWS.2.html>.
> >
> > As you probably know these are all autogenerated from the
> > source file  <Rsrc>/doc/NEWS.Rd
> >
> >  ((and so there is some reason why posting to R-devel may be somewhat
> ok))
> >
> > and the relevant part of that is
> >
> > \section{CHANGES in previous versions}{
> >  \itemize{
> >    \item Older news can be found in text format in files
> >    \ifelse{html}{\href{../NEWS.0}{NEWS.0}, \href{../NEWS.1}{NEWS.1}
> >      and \href{../NEWS.2}{NEWS.2}}{\file{NEWS.0}, \file{NEWS.1} and
> >      \file{NEWS.2}}
> >    in the \file{doc} directory.  News in HTML format for
> >    \R versions from 2.10.0 to 2.15.3 is in
> >    \ifelse{html}{\url{NEWS.2.html}}{\file{doc/html/NEWS.2.html}}.
> >  }
> > }
> >
> > *and* that source produces a NEWS.html which works correctly in
> > the important use of R's "builtin HTML help",
> > i.e. for me what I get after help.start(),  I presume that's
> > also the toplevel help page Rstudio users see.
> > And there, the "../NEWS.O" (relative link) *is* the correct location.
> >
> > Using relative links is a very good idea here, as all that
> > should work completely offline.
> >
> > The task here is to adapt all the other "published" versions of the
> > generated NEWS.html files to point to a web (as opposed to
> > local/relative) URL.
> >
> > Yes ``just another'' tweak for the CRAN web page generation
> > scripts...
> >
> > Martin
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Tue Jan 20 19:58:08 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 20 Jan 2015 10:58:08 -0800
Subject: [Rd] default min-v/nsize parameters
In-Reply-To: <21694.8963.940365.956366@stat.math.ethz.ch>
References: <CAOQ5NydF3Qv_7KNER5s0=0zqcLC9w--VkXbgnkT1WEk8OHiKrA@mail.gmail.com>
	<alpine.DEB.2.02.1501171035190.2583@luke-Latitude>
	<CAFAN8vyKyp-_mfExKu3p6fGSgxMP_L+=swcvFU7qca23ZXT4og@mail.gmail.com>
	<CAGh0NYrDXaT35=TUiXB4Y-bHmzQJFMwu=3OSimipMKrH20KTYw@mail.gmail.com>
	<21694.8963.940365.956366@stat.math.ethz.ch>
Message-ID: <CAFDcVCQQ2g9CttuFVJqbvfNAy5qjv7ZWRbzkGYLTfo59G7_HvQ@mail.gmail.com>

Thanks for this.

Anyone know how I can find what those initial settings are from within
R?  Do I need to parse/look at both environment variables R_NSIZE and
R_VSIZE and then commandArgs()?

/Henrik

On Tue, Jan 20, 2015 at 1:42 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Peter Haverty <haverty.peter at gene.com>
>>>>>>     on Mon, 19 Jan 2015 08:50:08 -0800 writes:
>
>     > Hi All, This is a very important issue. It would be very
>     > sad to leave most users unaware of a free speedup of this
>     > size.  These options don't appear in the R --help
>     > output. They really should be added there.
>
> Indeed, I've found that myself and had added them there about
> 24 hours ago.
> ((I think they were accidentally dropped a while ago))
>
>     > if the garbage collector is working very hard, might it
>     > emit a note about better setting for these variables?
>
>     > It's not really my place to comment on design philosophy,
>     > but if there is a configure option for small memory
>     > machines I would assume that would be sufficient for the
>     > folks that are not on fairly current hardware.
>
> There's quite a few more issues with this,
> notably how the growth *steps* are done.
> That has been somewhat experimental and for that reason is
> _currently_ quite configurable via R_GC_* environment variables,
> see the code in src/main/memory.c
>
> This is currently discussed "privately" within the R core.
> I'm somewhat confident that R 3.2.0 in April will have changes.
>
> And -- coming back to the beginning -- at least the "R-devel" version now shows
>
> R --help | grep -e min-.size
>
>   --min-nsize=N         Set min number of fixed size obj's ("cons cells") to N
>   --min-vsize=N         Set vector heap minimum to N bytes; '4M' = 4 MegaB
>
> --
> Martin Maechler, ETH Zurich
>
>     > On Sat, Jan 17, 2015 at 11:40 PM, Nathan Kurz <nate at verse.com> wrote:
>
>     >> On Thu, Jan 15, 2015 at 3:55 PM, Michael Lawrence
>     >> <lawrence.michael at gene.com> wrote:
>     >> > Just wanted to start a discussion on whether R could ship with more
>     >> > appropriate GC parameters.
>     >>
>     >> I've been doing a number of similar measurements, and have come to the
>     >> same conclusion.  R is currently very conservative about memory usage,
>     >> and this leads to unnecessarily poor performance on certain problems.
>     >> Changing the defaults to sizes that are more appropriate for modern
>     >> machines can often produce a 2x speedup.
>     >>
>     >> On Sat, Jan 17, 2015 at 8:39 AM,  <luke-tierney at uiowa.edu> wrote:
>     >> > Martin Morgan discussed this a year or so ago and as I recall bumped
>     >> > up these values to the current defaults. I don't recall details about
>     >> > why we didn't go higher -- maybe Martin does.
>     >>
>     >> I just checked, and it doesn't seem that any of the relevant values
>     >> have been increased in the last ten years.  Do you have a link to the
>     >> discussion you recall so we can see why the changes weren't made?
>     >>
>     >> > I suspect the main concern would be with small memory machines in
>     >> student labs
>     >> > and less developed countries.
>     >>
>     >> While a reasonable concern, I'm doubtful there are many machines for
>     >> which the current numbers are optimal.  The current minimum size
>     >> increases for node and vector heaps are 40KB and 80KB respectively.
>     >> This grows as the heap grows (min + .05 * heap), but still means that
>     >> we do many more expensive garbage collections at while growing than we
>     >> need to.  Paradoxically, the SMALL_MEMORY compile option (which is
>     >> suggestd for computers with up to 32MB of RAM) has slightly larger at
>     >> 50KB and 100KB.
>     >>
>     >> I think we'd get significant benefit for most users by being less
>     >> conservative about memory consumption.    The exact sizes should be
>     >> discussed, but with RAM costing about $10/GB it doesn't seem
>     >> unreasonable to assume most machines running R have multiple GB
>     >> installed, and those that don't will quite likely be running an OS
>     >> that needs a custom compiled binary anyway.
>     >>
>     >> I could be way off, but my suggestion might be a 10MB start with 1MB
>     >> minimum increments for SMALL_MEMORY, 100MB start with 10MB increments
>     >> for NORMAL_MEMORY, and 1GB start with 100MB increments for
>     >> LARGE_MEMORY might be a reasonable spread.
>     >>
>     >> Or one could go even larger, noting that on most systems,
>     >> overcommitted memory is not a problem until it is used.  Until we
>     >> write to it, it doesn't actually use physical RAM, just virtual
>     >> address space.  Or we could stay small, but make it possible to
>     >> programmatically increase the granularity from within R.
>     >>
>     >> For ease of reference, here are the relevant sections of code:
>     >>
>     >> https://github.com/wch/r-source/blob/master/src/include/Defn.h#L217
>     >> (ripley last authored on Jan 26, 2000 / pd last authored on May 8, 1999)
>     >> 217  #ifndef R_NSIZE
>     >> 218  #define R_NSIZE 350000L
>     >> 219  #endif
>     >> 220  #ifndef R_VSIZE
>     >> 221  #define R_VSIZE 6291456L
>     >> 222  #endif
>     >>
>     >> https://github.com/wch/r-source/blob/master/src/main/startup.c#L169
>     >> (ripley last authored on Jun 9, 2004)
>     >> 157 Rp->vsize = R_VSIZE;
>     >> 158 Rp->nsize = R_NSIZE;
>     >> 166  #define Max_Nsize 50000000 /* about 1.4Gb 32-bit, 2.8Gb 64-bit */
>     >> 167  #define Max_Vsize R_SIZE_T_MAX /* unlimited */
>     >> 169  #define Min_Nsize 220000
>     >> 170  #define Min_Vsize (1*Mega)
>     >>
>     >> https://github.com/wch/r-source/blob/master/src/main/memory.c#L335
>     >> (luke last authored on Nov 1, 2000)
>     >> #ifdef SMALL_MEMORY
>     >> 336  /* On machines with only 32M of memory (or on a classic Mac OS port)
>     >> 337      it might be a good idea to use settings like these that are more
>     >> 338      aggressive at keeping memory usage down. */
>     >> 339  static double R_NGrowIncrFrac = 0.0, R_NShrinkIncrFrac = 0.2;
>     >> 340  static int R_NGrowIncrMin = 50000, R_NShrinkIncrMin = 0;
>     >> 341  static double R_VGrowIncrFrac = 0.0, R_VShrinkIncrFrac = 0.2;
>     >> 342  static int R_VGrowIncrMin = 100000, R_VShrinkIncrMin = 0;
>     >> 343#else
>     >> 344  static double R_NGrowIncrFrac = 0.05, R_NShrinkIncrFrac = 0.2;
>     >> 345  static int R_NGrowIncrMin = 40000, R_NShrinkIncrMin = 0;
>     >> 346  static double R_VGrowIncrFrac = 0.05, R_VShrinkIncrFrac = 0.2;
>     >> 347  static int R_VGrowIncrMin = 80000, R_VShrinkIncrMin = 0;
>     >> 348#endif
>     >>
>     >> static void AdjustHeapSize(R_size_t size_needed)
>     >> {
>     >> R_size_t R_MinNFree = (R_size_t)(orig_R_NSize * R_MinFreeFrac);
>     >> R_size_t R_MinVFree = (R_size_t)(orig_R_VSize * R_MinFreeFrac);
>     >> R_size_t NNeeded = R_NodesInUse + R_MinNFree;
>     >> R_size_t VNeeded = R_SmallVallocSize + R_LargeVallocSize +
>     >> size_needed + R_MinVFree;
>     >> double node_occup = ((double) NNeeded) / R_NSize;
>     >> double vect_occup = ((double) VNeeded) / R_VSize;
>     >>
>     >> if (node_occup > R_NGrowFrac) {
>     >> R_size_t change = (R_size_t)(R_NGrowIncrMin + R_NGrowIncrFrac
>     >> * R_NSize);
>     >> if (R_MaxNSize >= R_NSize + change)
>     >> R_NSize += change;
>     >> }
>     >> else if (node_occup < R_NShrinkFrac) {
>     >> R_NSize -= (R_NShrinkIncrMin + R_NShrinkIncrFrac * R_NSize);
>     >> if (R_NSize < NNeeded)
>     >> R_NSize = (NNeeded < R_MaxNSize) ? NNeeded: R_MaxNSize;
>     >> if (R_NSize < orig_R_NSize)
>     >> R_NSize = orig_R_NSize;
>     >> }
>     >>
>     >> if (vect_occup > 1.0 && VNeeded < R_MaxVSize)
>     >> R_VSize = VNeeded;
>     >> if (vect_occup > R_VGrowFrac) {
>     >> R_size_t change = (R_size_t)(R_VGrowIncrMin + R_VGrowIncrFrac
>     >> * R_VSize);
>     >> if (R_MaxVSize - R_VSize >= change)
>     >> R_VSize += change;
>     >> }
>     >> else if (vect_occup < R_VShrinkFrac) {
>     >> R_VSize -= R_VShrinkIncrMin + R_VShrinkIncrFrac * R_VSize;
>     >> if (R_VSize < VNeeded)
>     >> R_VSize = VNeeded;
>     >> if (R_VSize < orig_R_VSize)
>     >> R_VSize = orig_R_VSize;
>     >> }
>     >>
>     >> DEBUG_ADJUST_HEAP_PRINT(node_occup, vect_occup);
>     >> }
>     >>
>     Rp-> nsize is overridden at startup by environment variable R_NSIZE if
>     >> Min_Nsize <= $R_NSIZE <= Max_Nsize.  Rp->vsize is overridden at
>     >> startup by environment variable R_VSIZE if Min_Vsize <= $R_VSIZE <=
>     >> Max_Vsize.  These are then used to set the global variables R_Nsize
>     >> and R_Vsize with R_SetMaxVSize(Rp->max_vsize).
>     >>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From htl10 at users.sourceforge.net  Wed Jan 21 01:40:22 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Wed, 21 Jan 2015 00:40:22 +0000
Subject: [Rd] updated R-cairo bridge, official R-3.1.*-mavericks.pkg crippled,
	snpMatrix 1.19.0.20
Message-ID: <1421800822.58227.YahooMailBasic@web172306.mail.ir2.yahoo.com>

R.framework-Versions-Resources-library-grDevices-libs-cairo_20150120.tgz in
http://sourceforge.net/projects/outmodedbonsai/files/R/
are dropped in replacement to the cairo.so's in the official R binaries (2.15.3, 3.0.3, 3.1.2).

updated to cairo-1.12.18 and freetype-2.5.4. The official R binaries' were
built with early freetype 2.4.x and cairo 1.11(?) and had a number of issues
with some windows and mac system fonts; also the one in the official binaries
were built with a freetype that's built differently from apple's and
and therefore can interfere with other GUI applications' use of dfonts on Mac OS X. (that
unfortunately means the most common typefaces like Time and Helvetica!).

While doing that, I found that the official R-3.1.*-mavericks.pkg are crippled, compared
to R-3.1.*-snowleopard.pkg. They have tiff functionality missing. Here are the sizes of
the official binaries':

3918832 ./R-3.1.2-snowleopard/R.framework/Versions/3.1/Resources/library/grDevices/libs/cairo.so
3778144 ./R-3.0.3/R.framework/Versions/3.0/Resources/library/grDevices/libs/cairo.so
3170596 ./R-3.1.2-mavericks/R.framework/Versions/3.1/Resources/library/grDevices/libs/cairo.so
3252656 ./R-2.15.3/R.framework/Versions/2.15/Resources/library/grDevices/libs/i386/cairo.so
3539992 ./R-2.15.3/R.framework/Versions/2.15/Resources/library/grDevices/libs/x86_64/cairo.so

"R-3.1.2-mavericks/R.framework/Versions/3.1/Resources/library/grDevices/libs/cairo.so" is so much smaller,
not because it is built with a better and newer compiler, but because tiff functionality is
missing.

The official R-3.1.*-mavericks.pkg is about 14MB smaller than
R-3.1.*-snowleopard.pkg (from 55MB-ish to 70MB-ish). Looking carefully, the size differently did
not come from better compilation - it is in 3 unrelated areas, one of the problematic:

- the snowleopard builds come the manuals in pdf's, mavericks don't. That's about 14MB.
- a few bundled gcc runtime libraries (libgcc/libfortran...) are quad arch in the former, and biarch in the latter.
  That's another 6 MB.
- the missing tiff functionality. That affects both R_X11.so and cairo.so, and add up to about 1.5MB.

And the 18-20MB difference compress down to 14MB.

I don't know whether it actually offers any speed advantage, but I'd probably suggest stay away from
the official mavericks builds, just because of missing functionality. It is missing from all of R 3.1.0, 3.1.1, and 3.1.2.

The next thing I am doing is building the replacement for the cairo.dll's in the offical R windows binaries.
Just watch out in the next few days in the same directory.

---------- not R-devel related below this point ------

I have finished with snpMatrix 1.19.0.20 5 days ago. Some of you may notice the documentations
are already out - 19 months about 400 commit since 1.19.0.19, it comes with a snpStats compatibility
mode; when that mode is on, about 1/3 of its internals are swapped to their snpStats-equivalent
versions. Initially synchronized to snpStats x.x.x.8 - and I already mentioned that it is because of another
GLM related bug, found on top of x.x.x.7. Sigh.

snpMatrix 1.19.0.20 and snpStats x.x.x.8 are now really just waiting for me to finish with the cairo
stuff (for R 3.1.x). The impatient can just read the new vignettes.


From haverty.peter at gene.com  Wed Jan 21 19:41:52 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Wed, 21 Jan 2015 10:41:52 -0800
Subject: [Rd] reducing redundant work in methods package
Message-ID: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>

Hi all,

The function call series genericForPrimitive -> .findBasicFuns -> .findAll
happens 4400 times while the GenomicRanges package is loading.  Each time
.findAll follows a chain of environments to determine that the methods
namespace is the only one that holds a variable called .BasicFunsList. This
accounts for ~10% of package loading time. I'm sure there is some history
to that design, but would it be possible shortcut this operation? Could
.BasicFunsList be initialized in the methods namespace at startup and might
genericForPrimitive just go straight there?

Does anyone on the list know why it works this way?

There are some other cases of seemingly redundant work, but this seems like
an easy one to address.

I have included some code below that was used to investigate some of the
above.

# Try this to count calls to a function

.count <-  0; trace(methods:::.findBasicFuns,tracer=function() { .count <<-
.count + 1 }); library(GenomicRanges); print(.count)

# Try this to capture the input and output of a set of functions you wish
to refactor

.init_test_data_collection <- function(ns = asNamespace("methods")) {

    funs = c("isClassUnion", "getClass", "genericForPrimitive",
"possibleExtends", ".dataSlot", ".requirePackage", ".classEnv",
"getClassDef", "outerLabels", ".getClassFromCache", "getFunction")

    message(paste0("\nCollecting data for unit tests on ", paste(funs,
collapse=", "), " ...\n"))

    # Make env with list to hold test input/output

    TEST_ENV <- new.env()

    for (fname in funs) {

        # Make placeholder for input/output for future runs of this function

        TEST_ENV[[fname]] = list()  # Actually probably not necessary, will
just be c(NULL, list(first result)) the first time

        # Construct test version of function

        unlockBinding(fname, ns)

        fun = get(fname, envir=ns, mode="function")

        funbody = deparse(body(fun))

        newfun <- fun

        newfun.body = c(

            sprintf("fname = '%s'", fname),

            "TEST_INFO = list()",

            "TEST_INFO$input = mget(names(formals(fname)))",

            c("realfun <- function()", funbody),

            "TEST_INFO$output = realfun()",

            "TEST_ENV[[fname]] = c(TEST_ENV[[fname]], list(TEST_INFO))",

            "return(TEST_INFO$output)")

        body(newfun) = as.call(c(as.name("{"),
as.list(parse(text=newfun.body))))

        assign(fname, newfun, envir=ns)

    }

    return(TEST_ENV)

}
# run code, print items in TEST_ENV

The relevant code is in methods/R/BasicFunsList.R and
methods/R/ClassExtensions.R
Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Wed Jan 21 23:26:55 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 21 Jan 2015 14:26:55 -0800
Subject: [Rd] reducing redundant work in methods package
In-Reply-To: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>
References: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>
Message-ID: <CAOQ5NycrmSKtRPwHDYnmOx72tL9M6iBnFO6mF7xgDrdyRACkPg@mail.gmail.com>

Note that setMethod() resolves .BasicFunsList in the methods namespace
directly when setting a method on a primitive. Somehow there should be
consistency between genericForPrimitive() and the check in setMethod().

Also, we can probably step away from the use of elNamed(), given that [[
now uses exact matching.

Have you tried patching methods to use .BasicFunsList directly as in
setMethod?


On Wed, Jan 21, 2015 at 10:41 AM, Peter Haverty <haverty.peter at gene.com>
wrote:

> Hi all,
>
> The function call series genericForPrimitive -> .findBasicFuns -> .findAll
> happens 4400 times while the GenomicRanges package is loading.  Each time
> .findAll follows a chain of environments to determine that the methods
> namespace is the only one that holds a variable called .BasicFunsList. This
> accounts for ~10% of package loading time. I'm sure there is some history
> to that design, but would it be possible shortcut this operation? Could
> .BasicFunsList be initialized in the methods namespace at startup and might
> genericForPrimitive just go straight there?
>
> Does anyone on the list know why it works this way?
>
> There are some other cases of seemingly redundant work, but this seems like
> an easy one to address.
>
> I have included some code below that was used to investigate some of the
> above.
>
> # Try this to count calls to a function
>
> .count <-  0; trace(methods:::.findBasicFuns,tracer=function() { .count <<-
> .count + 1 }); library(GenomicRanges); print(.count)
>
> # Try this to capture the input and output of a set of functions you wish
> to refactor
>
> .init_test_data_collection <- function(ns = asNamespace("methods")) {
>
>     funs = c("isClassUnion", "getClass", "genericForPrimitive",
> "possibleExtends", ".dataSlot", ".requirePackage", ".classEnv",
> "getClassDef", "outerLabels", ".getClassFromCache", "getFunction")
>
>     message(paste0("\nCollecting data for unit tests on ", paste(funs,
> collapse=", "), " ...\n"))
>
>     # Make env with list to hold test input/output
>
>     TEST_ENV <- new.env()
>
>     for (fname in funs) {
>
>         # Make placeholder for input/output for future runs of this
> function
>
>         TEST_ENV[[fname]] = list()  # Actually probably not necessary, will
> just be c(NULL, list(first result)) the first time
>
>         # Construct test version of function
>
>         unlockBinding(fname, ns)
>
>         fun = get(fname, envir=ns, mode="function")
>
>         funbody = deparse(body(fun))
>
>         newfun <- fun
>
>         newfun.body = c(
>
>             sprintf("fname = '%s'", fname),
>
>             "TEST_INFO = list()",
>
>             "TEST_INFO$input = mget(names(formals(fname)))",
>
>             c("realfun <- function()", funbody),
>
>             "TEST_INFO$output = realfun()",
>
>             "TEST_ENV[[fname]] = c(TEST_ENV[[fname]], list(TEST_INFO))",
>
>             "return(TEST_INFO$output)")
>
>         body(newfun) = as.call(c(as.name("{"),
> as.list(parse(text=newfun.body))))
>
>         assign(fname, newfun, envir=ns)
>
>     }
>
>     return(TEST_ENV)
>
> }
> # run code, print items in TEST_ENV
>
> The relevant code is in methods/R/BasicFunsList.R and
> methods/R/ClassExtensions.R
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Thu Jan 22 00:13:27 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Wed, 21 Jan 2015 15:13:27 -0800
Subject: [Rd] reducing redundant work in methods package
In-Reply-To: <CAOQ5NycrmSKtRPwHDYnmOx72tL9M6iBnFO6mF7xgDrdyRACkPg@mail.gmail.com>
References: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>
	<CAOQ5NycrmSKtRPwHDYnmOx72tL9M6iBnFO6mF7xgDrdyRACkPg@mail.gmail.com>
Message-ID: <CAGh0NYoPN0w2T1C5a0TLzADYGX5qjFb_FaXR7Pkxx55YVrCZHg@mail.gmail.com>

Doing it like this:

genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
= TRUE) {

    ans = .BasicFunsList[[f]]

    ## this element may not exist (yet, during loading), dom't test null

    if(mustFind && identical(ans, FALSE))

        stop(gettextf("methods may not be defined for primitive function %s
in this version of R",

                      sQuote(f)),

             domain = NA)

    ans

}

or this:

genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
= TRUE) {

    env = asNamespace("methods")

    funs <- env[[".BasicFunsList"]]

    ans = funs[[f]]

    ## this element may not exist (yet, during loading), dom't test null

    if(mustFind && identical(ans, FALSE))

        stop(gettextf("methods may not be defined for primitive function %s
in this version of R",

                      sQuote(f)),

             domain = NA)

    ans

}

Seems to work just fine.

Yes, "el" and "elNamed" can probably go now.

Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Wed, Jan 21, 2015 at 2:26 PM, Michael Lawrence <lawrence.michael at gene.com
> wrote:

> Note that setMethod() resolves .BasicFunsList in the methods namespace
> directly when setting a method on a primitive. Somehow there should be
> consistency between genericForPrimitive() and the check in setMethod().
>
> Also, we can probably step away from the use of elNamed(), given that [[
> now uses exact matching.
>
> Have you tried patching methods to use .BasicFunsList directly as in
> setMethod?
>
>
> On Wed, Jan 21, 2015 at 10:41 AM, Peter Haverty <haverty.peter at gene.com>
> wrote:
>
>> Hi all,
>>
>> The function call series genericForPrimitive -> .findBasicFuns -> .findAll
>> happens 4400 times while the GenomicRanges package is loading.  Each time
>> .findAll follows a chain of environments to determine that the methods
>> namespace is the only one that holds a variable called .BasicFunsList.
>> This
>> accounts for ~10% of package loading time. I'm sure there is some history
>> to that design, but would it be possible shortcut this operation? Could
>> .BasicFunsList be initialized in the methods namespace at startup and
>> might
>> genericForPrimitive just go straight there?
>>
>> Does anyone on the list know why it works this way?
>>
>> There are some other cases of seemingly redundant work, but this seems
>> like
>> an easy one to address.
>>
>> I have included some code below that was used to investigate some of the
>> above.
>>
>> # Try this to count calls to a function
>>
>> .count <-  0; trace(methods:::.findBasicFuns,tracer=function() { .count
>> <<-
>> .count + 1 }); library(GenomicRanges); print(.count)
>>
>> # Try this to capture the input and output of a set of functions you wish
>> to refactor
>>
>> .init_test_data_collection <- function(ns = asNamespace("methods")) {
>>
>>     funs = c("isClassUnion", "getClass", "genericForPrimitive",
>> "possibleExtends", ".dataSlot", ".requirePackage", ".classEnv",
>> "getClassDef", "outerLabels", ".getClassFromCache", "getFunction")
>>
>>     message(paste0("\nCollecting data for unit tests on ", paste(funs,
>> collapse=", "), " ...\n"))
>>
>>     # Make env with list to hold test input/output
>>
>>     TEST_ENV <- new.env()
>>
>>     for (fname in funs) {
>>
>>         # Make placeholder for input/output for future runs of this
>> function
>>
>>         TEST_ENV[[fname]] = list()  # Actually probably not necessary,
>> will
>> just be c(NULL, list(first result)) the first time
>>
>>         # Construct test version of function
>>
>>         unlockBinding(fname, ns)
>>
>>         fun = get(fname, envir=ns, mode="function")
>>
>>         funbody = deparse(body(fun))
>>
>>         newfun <- fun
>>
>>         newfun.body = c(
>>
>>             sprintf("fname = '%s'", fname),
>>
>>             "TEST_INFO = list()",
>>
>>             "TEST_INFO$input = mget(names(formals(fname)))",
>>
>>             c("realfun <- function()", funbody),
>>
>>             "TEST_INFO$output = realfun()",
>>
>>             "TEST_ENV[[fname]] = c(TEST_ENV[[fname]], list(TEST_INFO))",
>>
>>             "return(TEST_INFO$output)")
>>
>>         body(newfun) = as.call(c(as.name("{"),
>> as.list(parse(text=newfun.body))))
>>
>>         assign(fname, newfun, envir=ns)
>>
>>     }
>>
>>     return(TEST_ENV)
>>
>> }
>> # run code, print items in TEST_ENV
>>
>> The relevant code is in methods/R/BasicFunsList.R and
>> methods/R/ClassExtensions.R
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan 22 14:57:51 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 22 Jan 2015 05:57:51 -0800
Subject: [Rd] reducing redundant work in methods package
In-Reply-To: <CAGh0NYoPN0w2T1C5a0TLzADYGX5qjFb_FaXR7Pkxx55YVrCZHg@mail.gmail.com>
References: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>
	<CAOQ5NycrmSKtRPwHDYnmOx72tL9M6iBnFO6mF7xgDrdyRACkPg@mail.gmail.com>
	<CAGh0NYoPN0w2T1C5a0TLzADYGX5qjFb_FaXR7Pkxx55YVrCZHg@mail.gmail.com>
Message-ID: <CAOQ5NyfT1L0sYQgu9m78v=fag-ttfxNwe=X=Y5DAshzD8us+Nw@mail.gmail.com>

I also just noticed that there is a bug: identical(ans, FALSE) should
be is.null(ans).

So no error is thrown:
> methods:::genericForPrimitive("foo")
NULL

Will fix.

On Wed, Jan 21, 2015 at 3:13 PM, Peter Haverty <haverty.peter at gene.com> wrote:
> Doing it like this:
>
> genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
> = TRUE) {
>
>     ans = .BasicFunsList[[f]]
>
>     ## this element may not exist (yet, during loading), dom't test null
>
>     if(mustFind && identical(ans, FALSE))
>
>         stop(gettextf("methods may not be defined for primitive function %s
> in this version of R",
>
>                       sQuote(f)),
>
>              domain = NA)
>
>     ans
>
> }
>
> or this:
>
> genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
> = TRUE) {
>
>     env = asNamespace("methods")
>
>     funs <- env[[".BasicFunsList"]]
>
>     ans = funs[[f]]
>
>     ## this element may not exist (yet, during loading), dom't test null
>
>     if(mustFind && identical(ans, FALSE))
>
>         stop(gettextf("methods may not be defined for primitive function %s
> in this version of R",
>
>                       sQuote(f)),
>
>              domain = NA)
>
>     ans
>
> }
>
> Seems to work just fine.
>
> Yes, "el" and "elNamed" can probably go now.
>
>
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
> On Wed, Jan 21, 2015 at 2:26 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
>>
>> Note that setMethod() resolves .BasicFunsList in the methods namespace
>> directly when setting a method on a primitive. Somehow there should be
>> consistency between genericForPrimitive() and the check in setMethod().
>>
>> Also, we can probably step away from the use of elNamed(), given that [[
>> now uses exact matching.
>>
>> Have you tried patching methods to use .BasicFunsList directly as in
>> setMethod?
>>
>>
>> On Wed, Jan 21, 2015 at 10:41 AM, Peter Haverty <haverty.peter at gene.com>
>> wrote:
>>>
>>> Hi all,
>>>
>>> The function call series genericForPrimitive -> .findBasicFuns ->
>>> .findAll
>>> happens 4400 times while the GenomicRanges package is loading.  Each time
>>> .findAll follows a chain of environments to determine that the methods
>>> namespace is the only one that holds a variable called .BasicFunsList.
>>> This
>>> accounts for ~10% of package loading time. I'm sure there is some history
>>> to that design, but would it be possible shortcut this operation? Could
>>> .BasicFunsList be initialized in the methods namespace at startup and
>>> might
>>> genericForPrimitive just go straight there?
>>>
>>> Does anyone on the list know why it works this way?
>>>
>>> There are some other cases of seemingly redundant work, but this seems
>>> like
>>> an easy one to address.
>>>
>>> I have included some code below that was used to investigate some of the
>>> above.
>>>
>>> # Try this to count calls to a function
>>>
>>> .count <-  0; trace(methods:::.findBasicFuns,tracer=function() { .count
>>> <<-
>>> .count + 1 }); library(GenomicRanges); print(.count)
>>>
>>> # Try this to capture the input and output of a set of functions you wish
>>> to refactor
>>>
>>> .init_test_data_collection <- function(ns = asNamespace("methods")) {
>>>
>>>     funs = c("isClassUnion", "getClass", "genericForPrimitive",
>>> "possibleExtends", ".dataSlot", ".requirePackage", ".classEnv",
>>> "getClassDef", "outerLabels", ".getClassFromCache", "getFunction")
>>>
>>>     message(paste0("\nCollecting data for unit tests on ", paste(funs,
>>> collapse=", "), " ...\n"))
>>>
>>>     # Make env with list to hold test input/output
>>>
>>>     TEST_ENV <- new.env()
>>>
>>>     for (fname in funs) {
>>>
>>>         # Make placeholder for input/output for future runs of this
>>> function
>>>
>>>         TEST_ENV[[fname]] = list()  # Actually probably not necessary,
>>> will
>>> just be c(NULL, list(first result)) the first time
>>>
>>>         # Construct test version of function
>>>
>>>         unlockBinding(fname, ns)
>>>
>>>         fun = get(fname, envir=ns, mode="function")
>>>
>>>         funbody = deparse(body(fun))
>>>
>>>         newfun <- fun
>>>
>>>         newfun.body = c(
>>>
>>>             sprintf("fname = '%s'", fname),
>>>
>>>             "TEST_INFO = list()",
>>>
>>>             "TEST_INFO$input = mget(names(formals(fname)))",
>>>
>>>             c("realfun <- function()", funbody),
>>>
>>>             "TEST_INFO$output = realfun()",
>>>
>>>             "TEST_ENV[[fname]] = c(TEST_ENV[[fname]], list(TEST_INFO))",
>>>
>>>             "return(TEST_INFO$output)")
>>>
>>>         body(newfun) = as.call(c(as.name("{"),
>>> as.list(parse(text=newfun.body))))
>>>
>>>         assign(fname, newfun, envir=ns)
>>>
>>>     }
>>>
>>>     return(TEST_ENV)
>>>
>>> }
>>> # run code, print items in TEST_ENV
>>>
>>> The relevant code is in methods/R/BasicFunsList.R and
>>> methods/R/ClassExtensions.R
>>> Pete
>>>
>>> ____________________
>>> Peter M. Haverty, Ph.D.
>>> Genentech, Inc.
>>> phaverty at gene.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From lawrence.michael at gene.com  Thu Jan 22 15:50:09 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 22 Jan 2015 06:50:09 -0800
Subject: [Rd] reducing redundant work in methods package
In-Reply-To: <CAOQ5NyfT1L0sYQgu9m78v=fag-ttfxNwe=X=Y5DAshzD8us+Nw@mail.gmail.com>
References: <CAGh0NYoqK5ab68FjyVY9b0RDuy7eLtke4aUJpVK5+GEwhqyeYQ@mail.gmail.com>
	<CAOQ5NycrmSKtRPwHDYnmOx72tL9M6iBnFO6mF7xgDrdyRACkPg@mail.gmail.com>
	<CAGh0NYoPN0w2T1C5a0TLzADYGX5qjFb_FaXR7Pkxx55YVrCZHg@mail.gmail.com>
	<CAOQ5NyfT1L0sYQgu9m78v=fag-ttfxNwe=X=Y5DAshzD8us+Nw@mail.gmail.com>
Message-ID: <CAOQ5NyehuyBW7Gx3oRM=VqcLHkaJ3DJ5=+tg_kKG5hhL7y8BBQ@mail.gmail.com>

Actually, after reading the comment about it being OK for it being
NULL, it's not a bug after all.

On Thu, Jan 22, 2015 at 5:57 AM, Michael Lawrence <michafla at gene.com> wrote:
> I also just noticed that there is a bug: identical(ans, FALSE) should
> be is.null(ans).
>
> So no error is thrown:
>> methods:::genericForPrimitive("foo")
> NULL
>
> Will fix.
>
> On Wed, Jan 21, 2015 at 3:13 PM, Peter Haverty <haverty.peter at gene.com> wrote:
>> Doing it like this:
>>
>> genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
>> = TRUE) {
>>
>>     ans = .BasicFunsList[[f]]
>>
>>     ## this element may not exist (yet, during loading), dom't test null
>>
>>     if(mustFind && identical(ans, FALSE))
>>
>>         stop(gettextf("methods may not be defined for primitive function %s
>> in this version of R",
>>
>>                       sQuote(f)),
>>
>>              domain = NA)
>>
>>     ans
>>
>> }
>>
>> or this:
>>
>> genericForPrimitive <- function(f, where = topenv(parent.frame()), mustFind
>> = TRUE) {
>>
>>     env = asNamespace("methods")
>>
>>     funs <- env[[".BasicFunsList"]]
>>
>>     ans = funs[[f]]
>>
>>     ## this element may not exist (yet, during loading), dom't test null
>>
>>     if(mustFind && identical(ans, FALSE))
>>
>>         stop(gettextf("methods may not be defined for primitive function %s
>> in this version of R",
>>
>>                       sQuote(f)),
>>
>>              domain = NA)
>>
>>     ans
>>
>> }
>>
>> Seems to work just fine.
>>
>> Yes, "el" and "elNamed" can probably go now.
>>
>>
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> On Wed, Jan 21, 2015 at 2:26 PM, Michael Lawrence
>> <lawrence.michael at gene.com> wrote:
>>>
>>> Note that setMethod() resolves .BasicFunsList in the methods namespace
>>> directly when setting a method on a primitive. Somehow there should be
>>> consistency between genericForPrimitive() and the check in setMethod().
>>>
>>> Also, we can probably step away from the use of elNamed(), given that [[
>>> now uses exact matching.
>>>
>>> Have you tried patching methods to use .BasicFunsList directly as in
>>> setMethod?
>>>
>>>
>>> On Wed, Jan 21, 2015 at 10:41 AM, Peter Haverty <haverty.peter at gene.com>
>>> wrote:
>>>>
>>>> Hi all,
>>>>
>>>> The function call series genericForPrimitive -> .findBasicFuns ->
>>>> .findAll
>>>> happens 4400 times while the GenomicRanges package is loading.  Each time
>>>> .findAll follows a chain of environments to determine that the methods
>>>> namespace is the only one that holds a variable called .BasicFunsList.
>>>> This
>>>> accounts for ~10% of package loading time. I'm sure there is some history
>>>> to that design, but would it be possible shortcut this operation? Could
>>>> .BasicFunsList be initialized in the methods namespace at startup and
>>>> might
>>>> genericForPrimitive just go straight there?
>>>>
>>>> Does anyone on the list know why it works this way?
>>>>
>>>> There are some other cases of seemingly redundant work, but this seems
>>>> like
>>>> an easy one to address.
>>>>
>>>> I have included some code below that was used to investigate some of the
>>>> above.
>>>>
>>>> # Try this to count calls to a function
>>>>
>>>> .count <-  0; trace(methods:::.findBasicFuns,tracer=function() { .count
>>>> <<-
>>>> .count + 1 }); library(GenomicRanges); print(.count)
>>>>
>>>> # Try this to capture the input and output of a set of functions you wish
>>>> to refactor
>>>>
>>>> .init_test_data_collection <- function(ns = asNamespace("methods")) {
>>>>
>>>>     funs = c("isClassUnion", "getClass", "genericForPrimitive",
>>>> "possibleExtends", ".dataSlot", ".requirePackage", ".classEnv",
>>>> "getClassDef", "outerLabels", ".getClassFromCache", "getFunction")
>>>>
>>>>     message(paste0("\nCollecting data for unit tests on ", paste(funs,
>>>> collapse=", "), " ...\n"))
>>>>
>>>>     # Make env with list to hold test input/output
>>>>
>>>>     TEST_ENV <- new.env()
>>>>
>>>>     for (fname in funs) {
>>>>
>>>>         # Make placeholder for input/output for future runs of this
>>>> function
>>>>
>>>>         TEST_ENV[[fname]] = list()  # Actually probably not necessary,
>>>> will
>>>> just be c(NULL, list(first result)) the first time
>>>>
>>>>         # Construct test version of function
>>>>
>>>>         unlockBinding(fname, ns)
>>>>
>>>>         fun = get(fname, envir=ns, mode="function")
>>>>
>>>>         funbody = deparse(body(fun))
>>>>
>>>>         newfun <- fun
>>>>
>>>>         newfun.body = c(
>>>>
>>>>             sprintf("fname = '%s'", fname),
>>>>
>>>>             "TEST_INFO = list()",
>>>>
>>>>             "TEST_INFO$input = mget(names(formals(fname)))",
>>>>
>>>>             c("realfun <- function()", funbody),
>>>>
>>>>             "TEST_INFO$output = realfun()",
>>>>
>>>>             "TEST_ENV[[fname]] = c(TEST_ENV[[fname]], list(TEST_INFO))",
>>>>
>>>>             "return(TEST_INFO$output)")
>>>>
>>>>         body(newfun) = as.call(c(as.name("{"),
>>>> as.list(parse(text=newfun.body))))
>>>>
>>>>         assign(fname, newfun, envir=ns)
>>>>
>>>>     }
>>>>
>>>>     return(TEST_ENV)
>>>>
>>>> }
>>>> # run code, print items in TEST_ENV
>>>>
>>>> The relevant code is in methods/R/BasicFunsList.R and
>>>> methods/R/ClassExtensions.R
>>>> Pete
>>>>
>>>> ____________________
>>>> Peter M. Haverty, Ph.D.
>>>> Genentech, Inc.
>>>> phaverty at gene.com
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>


From mxkuhn at gmail.com  Thu Jan 22 16:20:52 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 22 Jan 2015 10:20:52 -0500
Subject: [Rd] Programming Tools CTV
Message-ID: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>

I've had a lot of requests for additions to the reproducible research
task view that fall into a grey area (to me at least).

For example, roxygen2 is a tool that broadly enable reproducibility
but I see it more as a tool for better programming. I'm about to check
in a new version of the task view that includes packrat and
checkpoint, as they seem closer to reproducible research, but also
feel like coding tools.

There are a few other packages that many would find useful for better
coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
pkgutils, etc.

This might be some overlap with the HPC task view. I would think that
rJava, Rcpp and the like are better suited there but this is arguable.

The last time I proposed something like this, Martin deftly convinced
me to be the maintainer. It is probably better for everyone if we
avoid that on this occasion.

* Does anyone else see the need for this?

* What other packages fit into this bin?

* Would anyone like to volunteer?

Thanks,

Max


From tobias.setz at rmetrics.org  Thu Jan 22 16:51:21 2015
From: tobias.setz at rmetrics.org (Tobias Setz)
Date: Thu, 22 Jan 2015 16:51:21 +0100
Subject: [Rd] R CMD check: Locale not set to C?
Message-ID: <014301d0365b$44bac8c0$ce305a40$@rmetrics.org>

Dear All

The "R CMD check" on the "zoo" (1.7-11) package results in an error on my
environment. It can be reduced to the following example:

----------------------------------------------------
> require(zoo)
> read.zoo(system.file("doc", "demo1.txt", package = "zoo"), sep = "|",
format="%d %b %Y")

Error in read.zoo(system.file("doc", "demo1.txt", package = "zoo"), sep =
"|",  :
  index has bad entries at data rows: 14 15 16 17 18 19 20
----------------------------------------------------

I am using the following environment (on Windows 7):

----------------------------------------------------
> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
----------------------------------------------------

The problem are the locale settings. In the "demo1.txt" the months are
abbreviated in English; while my environment would only accept German
abbreviations. The problem can be solved by setting the time locale:

> Sys.setlocale("LC_TIME", "English")
or
> Sys.setlocale("LC_TIME", "C")


Now; for "R CMD check", the manual
(http://cran.r-project.org/doc/manuals/r-release/R-exts.html) states the
following:

- "R CMD check and R CMD build run R processes with --vanilla..."
So no possibility to set the locales (in contrary to the environment
variables) through an "Rprofile" file...

- "All these tests are run with collation set to the C locale..."
If I set "LC_ALL" or only "LC_TIME" to "C" the example shown at the top
actually works if I run it manually.


However; if I run "R CMD check" I get the ERROR.
Therefore; are the locales really set to "C" for "R CMD check"?
If yes; why would the example above not work?
If no; how could I achieve custom locale settings?

Thanks!
Tobias



------------------------------------------
Tobias Setz
?
Rmetrics Association
tobias.setz at rmetrics.org
www.rmetrics.org


From greg at warnes.net  Thu Jan 22 18:23:12 2015
From: greg at warnes.net (Gregory R. Warnes)
Date: Thu, 22 Jan 2015 12:23:12 -0500
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
Message-ID: <42A162C6-9712-4EA4-BB94-C7D18180BE0C@warnes.net>

I second the motion for a Programming Tools CRAN Task View.

I would also think it could contain things like Rcpp, R6, etc. 

-Greg


> On Jan 22, 2015, at 10:20 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
> 
> I've had a lot of requests for additions to the reproducible research
> task view that fall into a grey area (to me at least).
> 
> For example, roxygen2 is a tool that broadly enable reproducibility
> but I see it more as a tool for better programming. I'm about to check
> in a new version of the task view that includes packrat and
> checkpoint, as they seem closer to reproducible research, but also
> feel like coding tools.
> 
> There are a few other packages that many would find useful for better
> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
> pkgutils, etc.
> 
> This might be some overlap with the HPC task view. I would think that
> rJava, Rcpp and the like are better suited there but this is arguable.
> 
> The last time I proposed something like this, Martin deftly convinced
> me to be the maintainer. It is probably better for everyone if we
> avoid that on this occasion.
> 
> * Does anyone else see the need for this?
> 
> * What other packages fit into this bin?
> 
> * Would anyone like to volunteer?
> 
> Thanks,
> 
> Max
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Thu Jan 22 18:33:08 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 22 Jan 2015 09:33:08 -0800
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
Message-ID: <CAFDcVCT9w+B0qjbb0Bw6TDj4M9XWh6TqNj8+9PV9W_AV9zDZOQ@mail.gmail.com>

On Thu, Jan 22, 2015 at 7:20 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
> I've had a lot of requests for additions to the reproducible research
> task view that fall into a grey area (to me at least).
>
> For example, roxygen2 is a tool that broadly enable reproducibility
> but I see it more as a tool for better programming. I'm about to check
> in a new version of the task view that includes packrat and
> checkpoint, as they seem closer to reproducible research, but also
> feel like coding tools.
>
> There are a few other packages that many would find useful for better
> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
> pkgutils, etc.
>
> This might be some overlap with the HPC task view. I would think that
> rJava, Rcpp and the like are better suited there but this is arguable.
>
> The last time I proposed something like this, Martin deftly convinced
> me to be the maintainer. It is probably better for everyone if we
> avoid that on this occasion.
>
> * Does anyone else see the need for this?
>
> * What other packages fit into this bin?
>
> * Would anyone like to volunteer?

Thanks for your work on this.

May I suggest a Git/GitHub repository for this?  That lowers the
barriers for contributions substantially, e.g. either via issues but
even better via pull requests (== point'n'click for you).  If you need
to mirror/push it to an SVN repository, I'm sure that's pretty easy to
do (and likely also to automate).

/Henrik

PS. Sorry, I'm not volunteering; too much on my plate.

>
> Thanks,
>
> Max
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lbraglia at gmail.com  Thu Jan 22 18:43:41 2015
From: lbraglia at gmail.com (Luca Braglia)
Date: Thu, 22 Jan 2015 18:43:41 +0100
Subject: [Rd] Programming Tools CTV
In-Reply-To: <42A162C6-9712-4EA4-BB94-C7D18180BE0C@warnes.net>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
	<42A162C6-9712-4EA4-BB94-C7D18180BE0C@warnes.net>
Message-ID: <CAFOm_+4g34ejGcRD8=Lm0VaxgNvTqMtZX8OFSWDfHecdgJUSxA@mail.gmail.com>

Hi,

this summer, after few mails on this list, i started something similar
(feeling the same need)... here is the repo

https://github.com/lbraglia/PackageDevelopmentTaskView

Currently it's quite freezed since i'm working on other projects in my
free software spare time (and likely i won't return to it) but could
be a starting point for someone else interested.


Best, Luca

PS in the case, following some mails with Dirk and Achim, HPC stuff
a-la Rcpp and friends should not be copied from Dirk's stuff, better
pointing... it was in my mental TODO

2015-01-22 18:23 GMT+01:00 Gregory R. Warnes <greg at warnes.net>:
> I second the motion for a Programming Tools CRAN Task View.
>
> I would also think it could contain things like Rcpp, R6, etc.
>
> -Greg
>
>
>> On Jan 22, 2015, at 10:20 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
>>
>> I've had a lot of requests for additions to the reproducible research
>> task view that fall into a grey area (to me at least).
>>
>> For example, roxygen2 is a tool that broadly enable reproducibility
>> but I see it more as a tool for better programming. I'm about to check
>> in a new version of the task view that includes packrat and
>> checkpoint, as they seem closer to reproducible research, but also
>> feel like coding tools.
>>
>> There are a few other packages that many would find useful for better
>> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
>> pkgutils, etc.
>>
>> This might be some overlap with the HPC task view. I would think that
>> rJava, Rcpp and the like are better suited there but this is arguable.
>>
>> The last time I proposed something like this, Martin deftly convinced
>> me to be the maintainer. It is probably better for everyone if we
>> avoid that on this occasion.
>>
>> * Does anyone else see the need for this?
>>
>> * What other packages fit into this bin?
>>
>> * Would anyone like to volunteer?
>>
>> Thanks,
>>
>> Max
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Achim.Zeileis at uibk.ac.at  Thu Jan 22 18:45:22 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 22 Jan 2015 18:45:22 +0100 (CET)
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>

On Thu, 22 Jan 2015, Max Kuhn wrote:

> I've had a lot of requests for additions to the reproducible research
> task view that fall into a grey area (to me at least).
>
> For example, roxygen2 is a tool that broadly enable reproducibility
> but I see it more as a tool for better programming. I'm about to check
> in a new version of the task view that includes packrat and
> checkpoint, as they seem closer to reproducible research, but also
> feel like coding tools.
>
> There are a few other packages that many would find useful for better
> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
> pkgutils, etc.
>
> This might be some overlap with the HPC task view. I would think that
> rJava, Rcpp and the like are better suited there but this is arguable.
>
> The last time I proposed something like this, Martin deftly convinced
> me to be the maintainer. It is probably better for everyone if we
> avoid that on this occasion.
>
> * Does anyone else see the need for this?
>
> * What other packages fit into this bin?
>
> * Would anyone like to volunteer?

Max, thanks for the suggestion. We had a somewhat related proposal on 
R-help from Luca Braglia a couple of months ago, suggesting a "Package 
Development" task view: 
https://mailman.stat.ethz.ch/pipermail/r-devel/2014-July/069454.html

He put up some ideas on Github:
https://github.com/lbraglia/PackageDevelopmentTaskView

When Luca asked me (ctv maintainer) and Dirk (HPC task view maintainer) 
for feedback off-list, I replied that it is important that task views are 
focused in order to be useful and maintainable. My feeling was that 
"PackageDevelopment" was too broad and also "ProgrammingTools" is still 
too board, I think. This could mean a lot of things/tools to a lot of 
people.

But maybe it would be to factor out some aspect that is sharp and 
clear(er)? Or split it up into bits where there are (more or less) 
objectively clear criteria for what goes in and what does not?

Best,
Z

> Thanks,
>
> Max
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mxkuhn at gmail.com  Thu Jan 22 18:54:27 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 22 Jan 2015 12:54:27 -0500
Subject: [Rd] Programming Tools CTV
In-Reply-To: <alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
	<alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>
Message-ID: <CAJ9CoWnRchvMv8y3tYq8cXo2kcBcX7g1ytTc6FtKM1iFNxSkxQ@mail.gmail.com>

On Thu, Jan 22, 2015 at 12:45 PM, Achim Zeileis
<Achim.Zeileis at uibk.ac.at> wrote:
> On Thu, 22 Jan 2015, Max Kuhn wrote:
>
>> I've had a lot of requests for additions to the reproducible research
>> task view that fall into a grey area (to me at least).
>>
>> For example, roxygen2 is a tool that broadly enable reproducibility
>> but I see it more as a tool for better programming. I'm about to check
>> in a new version of the task view that includes packrat and
>> checkpoint, as they seem closer to reproducible research, but also
>> feel like coding tools.
>>
>> There are a few other packages that many would find useful for better
>> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
>> pkgutils, etc.
>>
>> This might be some overlap with the HPC task view. I would think that
>> rJava, Rcpp and the like are better suited there but this is arguable.
>>
>> The last time I proposed something like this, Martin deftly convinced
>> me to be the maintainer. It is probably better for everyone if we
>> avoid that on this occasion.
>>
>> * Does anyone else see the need for this?
>>
>> * What other packages fit into this bin?
>>
>> * Would anyone like to volunteer?
>
>
> Max, thanks for the suggestion. We had a somewhat related proposal on R-help
> from Luca Braglia a couple of months ago, suggesting a "Package Development"
> task view:
> https://mailman.stat.ethz.ch/pipermail/r-devel/2014-July/069454.html
>
> He put up some ideas on Github:
> https://github.com/lbraglia/PackageDevelopmentTaskView
>
> When Luca asked me (ctv maintainer) and Dirk (HPC task view maintainer) for
> feedback off-list, I replied that it is important that task views are
> focused in order to be useful and maintainable. My feeling was that
> "PackageDevelopment" was too broad and also "ProgrammingTools" is still too
> board, I think. This could mean a lot of things/tools to a lot of people.
>
> But maybe it would be to factor out some aspect that is sharp and clear(er)?
> Or split it up into bits where there are (more or less) objectively clear
> criteria for what goes in and what does not?

It's funny that you said that. As I was updating the RR CTV, it
realized what a beast it is right now. I thought about making a github
project earlier today that would have more detailed examples and
information.

I see two problems with that as the *sole* solution.

First, it is divorced from CRAN CTV and that is a place that people
know and will look. I had no idea of Luca's work for this exact
reason.

Secondly, might be intimidating for new R users who, I think, are the
targeted cohort for the CTVs.

How about a relatively broad definition that is succinct in content
with a link to a github repos?

Thanks,

Max


From Achim.Zeileis at uibk.ac.at  Thu Jan 22 19:05:14 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 22 Jan 2015 19:05:14 +0100 (CET)
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAJ9CoWnRchvMv8y3tYq8cXo2kcBcX7g1ytTc6FtKM1iFNxSkxQ@mail.gmail.com>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
	<alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>
	<CAJ9CoWnRchvMv8y3tYq8cXo2kcBcX7g1ytTc6FtKM1iFNxSkxQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1501221858440.22244@paninaro.uibk.ac.at>

On Thu, 22 Jan 2015, Max Kuhn wrote:

> On Thu, Jan 22, 2015 at 12:45 PM, Achim Zeileis
> <Achim.Zeileis at uibk.ac.at> wrote:
>> On Thu, 22 Jan 2015, Max Kuhn wrote:
>>
>>> I've had a lot of requests for additions to the reproducible research
>>> task view that fall into a grey area (to me at least).
>>>
>>> For example, roxygen2 is a tool that broadly enable reproducibility
>>> but I see it more as a tool for better programming. I'm about to check
>>> in a new version of the task view that includes packrat and
>>> checkpoint, as they seem closer to reproducible research, but also
>>> feel like coding tools.
>>>
>>> There are a few other packages that many would find useful for better
>>> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
>>> pkgutils, etc.
>>>
>>> This might be some overlap with the HPC task view. I would think that
>>> rJava, Rcpp and the like are better suited there but this is arguable.
>>>
>>> The last time I proposed something like this, Martin deftly convinced
>>> me to be the maintainer. It is probably better for everyone if we
>>> avoid that on this occasion.
>>>
>>> * Does anyone else see the need for this?
>>>
>>> * What other packages fit into this bin?
>>>
>>> * Would anyone like to volunteer?
>>
>>
>> Max, thanks for the suggestion. We had a somewhat related proposal on R-help
>> from Luca Braglia a couple of months ago, suggesting a "Package Development"
>> task view:
>> https://mailman.stat.ethz.ch/pipermail/r-devel/2014-July/069454.html
>>
>> He put up some ideas on Github:
>> https://github.com/lbraglia/PackageDevelopmentTaskView
>>
>> When Luca asked me (ctv maintainer) and Dirk (HPC task view maintainer) for
>> feedback off-list, I replied that it is important that task views are
>> focused in order to be useful and maintainable. My feeling was that
>> "PackageDevelopment" was too broad and also "ProgrammingTools" is still too
>> board, I think. This could mean a lot of things/tools to a lot of people.
>>
>> But maybe it would be to factor out some aspect that is sharp and clear(er)?
>> Or split it up into bits where there are (more or less) objectively clear
>> criteria for what goes in and what does not?
>
> It's funny that you said that. As I was updating the RR CTV, it
> realized what a beast it is right now. I thought about making a github
> project earlier today that would have more detailed examples and
> information.
>
> I see two problems with that as the *sole* solution.
>
> First, it is divorced from CRAN CTV and that is a place that people
> know and will look. I had no idea of Luca's work for this exact
> reason.
>
> Secondly, might be intimidating for new R users who, I think, are the
> targeted cohort for the CTVs.

Yes, I agree. There should (an) additional task view(s) on CRAN related to 
this.

> How about a relatively broad definition that is succinct in content
> with a link to a github repos?

I think this doesn't fit well with the existing development model and 
might require duplicating changes in the <packagelist> of the task view. 
In order to be easily installable I need the <packagelist> in the task 
view on CRAN and not just in the linked list on Github.

Therefore, I would suggest splitting up the topic into things that are 
fairly sharp and clear. (Of course, it is impossible to avoid overlap 
completely.) For example, one could add "LanguageInterfaces" or something 
like that.

And the task views on CRAN can always include <links> to further 
documentation on Github and elsewhere. Especially when it comes to package 
development there are also clearly different preferences about what is 
good style or the right tools (say Github vs. R-Forge, knitr vs. Sweave, 
etc.)

> Thanks,
>
> Max
>


From haverty.peter at gene.com  Thu Jan 22 19:25:17 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 22 Jan 2015 10:25:17 -0800
Subject: [Rd] speedbump in library
Message-ID: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>

Hi all,

Profiling turned up a bit of a speedbump in the library function. I
submitted a patch to the R bug tracker as bug 16168 and I've also
included it below. The alternate code is simpler and easier to
read/maintain, I believe.  Any thoughts on other ways to write this?

Index: src/library/base/R/library.R
===================================================================
--- src/library/base/R/library.R    (revision 67578)
+++ src/library/base/R/library.R    (working copy)
@@ -688,18 +688,8 @@
     out <- character()

     for(pkg in package) {
-        paths <- character()
-        for(lib in lib.loc) {
-            dirs <- list.files(lib,
-                               pattern = paste0("^", pkg, "$"),
-                               full.names = TRUE)
-            ## Note that we cannot use tools::file_test() here, as
-            ## cyclic namespace dependencies are not supported.  Argh.
-            paths <- c(paths,
-                       dirs[dir.exists(dirs) &
-                            file.exists(file.path(dirs,
-                                                  "DESCRIPTION"))])
-        }
+        paths <- file.path(lib.loc, pkg)
+        paths <- paths[ file.exists(file.path(paths, "DESCRIPTION")) ]
         if(use_loaded && pkg %in% loadedNamespaces()) {
             dir <- if (pkg == "base") system.file()
             else getNamespaceInfo(pkg, "path")

Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


From haverty.peter at gene.com  Thu Jan 22 19:35:05 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 22 Jan 2015 10:35:05 -0800
Subject: [Rd] :: and ::: as .Primitives?
Message-ID: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>

Hi all,

When S4 methods are defined on base function (say, "match"), the
function becomes a method with the body "base::match(x,y)". A call to
such a function often spends more time doing "::" than in the function
itself.  I always assumed that "::" was a very low-level thing, but it
turns out to be a plain old function defined in base/R/namespace.R.
What would you all think about making "::" and ":::" .Primitives?  I
have submitted some examples, timings, and a patch to the R bug
tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
I'd be very interested to hear your thoughts on the matter.

Regards,
Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


From luke-tierney at uiowa.edu  Thu Jan 22 20:44:13 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 22 Jan 2015 13:44:13 -0600
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>

I'm not convinced that how to make :: faster is the right question. If
you are finding foo::bar being called often enough to matter to your
overall performance then to me the question is: why are you calling
foo::bar more than once? Making :: a bit faster by making it a
primitive will remove some overhead, but your are still left with a
lot of work that shouldn't need to happen more than once.

For default methods there ought to be a way to create those so the
default method is computed at creation or load time and stored in an
environment. For other cases if I want to use foo::bar many times, say
in a loop, I would do

foo_bar <- foo::bar

and use foo_bar, or something along those lines.

When :: and ::: were introduce they were intended primarily for
reflection and debugging, so speed was not an issue. ::: is still
really only reliably usable that way, and making it faster may just
encourage bad practice. :: is different and there are good arguments
for using it in code, but I'm not yet seeing good arguments for use in
ways that would be performance-critical, but I'm happy to be convinced
otherwise. If there is a need for a faster :: then going to a
SPECIALSXP is fine; it would also be good to make the byte code
compiler aware of it, and possibly to work on ways to improve the
performance further e.g. through cacheing.

Best,

luke

On Thu, 22 Jan 2015, Peter Haverty wrote:


> Hi all,
>
> When S4 methods are defined on base function (say, "match"), the
> function becomes a method with the body "base::match(x,y)". A call to
> such a function often spends more time doing "::" than in the function
> itself.  I always assumed that "::" was a very low-level thing, but it
> turns out to be a plain old function defined in base/R/namespace.R.
> What would you all think about making "::" and ":::" .Primitives?  I
> have submitted some examples, timings, and a patch to the R bug
> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
> I'd be very interested to hear your thoughts on the matter.
>
> Regards,
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From tkeitt at utexas.edu  Thu Jan 22 21:19:37 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 22 Jan 2015 14:19:37 -0600
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
Message-ID: <CANnL8goYcLfaWe=D3Kh9DftJwXCAs3Ui4JvHbqZkcZeE2=MbXw@mail.gmail.com>

On Thu, Jan 22, 2015 at 1:44 PM, <luke-tierney at uiowa.edu> wrote:

> I'm not convinced that how to make :: faster is the right question. If
> you are finding foo::bar being called often enough to matter to your
> overall performance then to me the question is: why are you calling
> foo::bar more than once? Making :: a bit faster by making it a
> primitive will remove some overhead, but your are still left with a
> lot of work that shouldn't need to happen more than once.
>
> For default methods there ought to be a way to create those so the
> default method is computed at creation or load time and stored in an
> environment. For other cases if I want to use foo::bar many times, say
> in a loop, I would do
>
> foo_bar <- foo::bar
>
> and use foo_bar, or something along those lines.
>
> When :: and ::: were introduce they were intended primarily for
> reflection and debugging, so speed was not an issue. ::: is still
> really only reliably usable that way, and making it faster may just
> encourage bad practice. :: is different and there are good arguments
> for using it in code, but I'm not yet seeing good arguments for use in
> ways that would be performance-critical, but I'm happy to be convinced
> otherwise. If there is a need for a faster :: then going to a
> SPECIALSXP is fine; it would also be good to make the byte code
> compiler aware of it, and possibly to work on ways to improve the
> performance further e.g. through cacheing.
>

I think you will find that no matter how much it does not matter in terms
of performance, folks will avoid :: out of principle if they think its
slower. We're conditioned to write efficient code even when it does not
really impact real world usage. As using :: is good practice in many
contexts, making it fast will encourage folks to use it.

THK


>
> Best,
>
> luke
>
>
> On Thu, 22 Jan 2015, Peter Haverty wrote:
>
>
>  Hi all,
>>
>> When S4 methods are defined on base function (say, "match"), the
>> function becomes a method with the body "base::match(x,y)". A call to
>> such a function often spends more time doing "::" than in the function
>> itself.  I always assumed that "::" was a very low-level thing, but it
>> turns out to be a plain old function defined in base/R/namespace.R.
>> What would you all think about making "::" and ":::" .Primitives?  I
>> have submitted some examples, timings, and a patch to the R bug
>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>> I'd be very interested to hear your thoughts on the matter.
>>
>> Regards,
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Thu Jan 22 21:51:45 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 22 Jan 2015 12:51:45 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
Message-ID: <CAFDcVCT9AnCaGg_fW96byDGNnCHXzosCN9zK4MdHwc9Mk2ojpQ@mail.gmail.com>

On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
> I'm not convinced that how to make :: faster is the right question. If
> you are finding foo::bar being called often enough to matter to your
> overall performance then to me the question is: why are you calling
> foo::bar more than once? Making :: a bit faster by making it a
> primitive will remove some overhead, but your are still left with a
> lot of work that shouldn't need to happen more than once.
>
> For default methods there ought to be a way to create those so the
> default method is computed at creation or load time and stored in an
> environment. For other cases if I want to use foo::bar many times, say
> in a loop, I would do
>
> foo_bar <- foo::bar
>
> and use foo_bar, or something along those lines.

While you're on the line: Do you think this is an optimization that
the 'compiler' package and it's cmpfun() byte compiler will be able to
do in the future?

/Henrik

>
> When :: and ::: were introduce they were intended primarily for
> reflection and debugging, so speed was not an issue. ::: is still
> really only reliably usable that way, and making it faster may just
> encourage bad practice. :: is different and there are good arguments
> for using it in code, but I'm not yet seeing good arguments for use in
> ways that would be performance-critical, but I'm happy to be convinced
> otherwise. If there is a need for a faster :: then going to a
> SPECIALSXP is fine; it would also be good to make the byte code
> compiler aware of it, and possibly to work on ways to improve the
> performance further e.g. through cacheing.
>
> Best,
>
> luke
>
>
> On Thu, 22 Jan 2015, Peter Haverty wrote:
>
>
>> Hi all,
>>
>> When S4 methods are defined on base function (say, "match"), the
>> function becomes a method with the body "base::match(x,y)". A call to
>> such a function often spends more time doing "::" than in the function
>> itself.  I always assumed that "::" was a very low-level thing, but it
>> turns out to be a plain old function defined in base/R/namespace.R.
>> What would you all think about making "::" and ":::" .Primitives?  I
>> have submitted some examples, timings, and a patch to the R bug
>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>> I'd be very interested to hear your thoughts on the matter.
>>
>> Regards,
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mxkuhn at gmail.com  Thu Jan 22 21:53:58 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 22 Jan 2015 15:53:58 -0500
Subject: [Rd] Programming Tools CTV
In-Reply-To: <alpine.DEB.2.11.1501221858440.22244@paninaro.uibk.ac.at>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
	<alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>
	<CAJ9CoWnRchvMv8y3tYq8cXo2kcBcX7g1ytTc6FtKM1iFNxSkxQ@mail.gmail.com>
	<alpine.DEB.2.11.1501221858440.22244@paninaro.uibk.ac.at>
Message-ID: <CAJ9CoWnEBbs9iY097PUxg4UH8LpF5WJP7AayNQ-oxuCkbEa7Gg@mail.gmail.com>

On Thu, Jan 22, 2015 at 1:05 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> On Thu, 22 Jan 2015, Max Kuhn wrote:
>
>> On Thu, Jan 22, 2015 at 12:45 PM, Achim Zeileis
>> <Achim.Zeileis at uibk.ac.at> wrote:
>>>
>>> On Thu, 22 Jan 2015, Max Kuhn wrote:
>>>
>>>> I've had a lot of requests for additions to the reproducible research
>>>> task view that fall into a grey area (to me at least).
>>>>
>>>> For example, roxygen2 is a tool that broadly enable reproducibility
>>>> but I see it more as a tool for better programming. I'm about to check
>>>> in a new version of the task view that includes packrat and
>>>> checkpoint, as they seem closer to reproducible research, but also
>>>> feel like coding tools.
>>>>
>>>> There are a few other packages that many would find useful for better
>>>> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
>>>> pkgutils, etc.
>>>>
>>>> This might be some overlap with the HPC task view. I would think that
>>>> rJava, Rcpp and the like are better suited there but this is arguable.
>>>>
>>>> The last time I proposed something like this, Martin deftly convinced
>>>> me to be the maintainer. It is probably better for everyone if we
>>>> avoid that on this occasion.
>>>>
>>>> * Does anyone else see the need for this?
>>>>
>>>> * What other packages fit into this bin?
>>>>
>>>> * Would anyone like to volunteer?
>>>
>>>
>>>
>>> Max, thanks for the suggestion. We had a somewhat related proposal on
>>> R-help
>>> from Luca Braglia a couple of months ago, suggesting a "Package
>>> Development"
>>> task view:
>>> https://mailman.stat.ethz.ch/pipermail/r-devel/2014-July/069454.html
>>>
>>> He put up some ideas on Github:
>>> https://github.com/lbraglia/PackageDevelopmentTaskView
>>>
>>> When Luca asked me (ctv maintainer) and Dirk (HPC task view maintainer)
>>> for
>>> feedback off-list, I replied that it is important that task views are
>>> focused in order to be useful and maintainable. My feeling was that
>>> "PackageDevelopment" was too broad and also "ProgrammingTools" is still
>>> too
>>> board, I think. This could mean a lot of things/tools to a lot of people.
>>>
>>> But maybe it would be to factor out some aspect that is sharp and
>>> clear(er)?
>>> Or split it up into bits where there are (more or less) objectively clear
>>> criteria for what goes in and what does not?
>>
>>
>> It's funny that you said that. As I was updating the RR CTV, it
>> realized what a beast it is right now. I thought about making a github
>> project earlier today that would have more detailed examples and
>> information.
>>
>> I see two problems with that as the *sole* solution.
>>
>> First, it is divorced from CRAN CTV and that is a place that people
>> know and will look. I had no idea of Luca's work for this exact
>> reason.
>>
>> Secondly, might be intimidating for new R users who, I think, are the
>> targeted cohort for the CTVs.
>
>
> Yes, I agree. There should (an) additional task view(s) on CRAN related to
> this.
>
>> How about a relatively broad definition that is succinct in content
>> with a link to a github repos?
>
>
> I think this doesn't fit well with the existing development model and might
> require duplicating changes in the <packagelist> of the task view. In order
> to be easily installable I need the <packagelist> in the task view on CRAN
> and not just in the linked list on Github.

Many of the task views are encyclopedic and still focused. Perhaps my
issues with RR are more related to how I currently organize it. I'll
try to solve it that way.

> Therefore, I would suggest splitting up the topic into things that are
> fairly sharp and clear. (Of course, it is impossible to avoid overlap
> completely.) For example, one could add "LanguageInterfaces" or something
> like that.

Looking at Luca's page, I think he does a great job of clustering
packages. My suggestions for focused topics are:

- Package Development*
- Foreign Languages Interfaces
- Code Analysis and Debugging
- Profiling and Benchmarking
- Unit Testing

* I would define the first one to be more narrow than the original definition.

I think that most of these would encompass less than 10 packages if we
don't include all the Rcpp depends =]

> And the task views on CRAN can always include <links> to further
> documentation on Github and elsewhere. Especially when it comes to package
> development there are also clearly different preferences about what is good
> style or the right tools (say Github vs. R-Forge, knitr vs. Sweave, etc.)

Yes. The comments above would not exclude this approach, which
is/was/might be my intention for RR.

Thanks,

Max


From lawrence.michael at gene.com  Thu Jan 22 21:54:38 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 22 Jan 2015 12:54:38 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
Message-ID: <CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>

On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>
> For default methods there ought to be a way to create those so the
> default method is computed at creation or load time and stored in an
> environment.

We had considered that, but we thought the definition of the function
would be easier to interpret if it explicitly specified the namespace,
instead of using tricks with environments. The same applies for
memoizing the lookup in front of a loop.

The implementation of these functions is almost simpler in C than it
is in R, so there is relatively little risk to this change. But I
agree the benefits are also somewhat minor.

> For other cases if I want to use foo::bar many times, say
> in a loop, I would do
>
> foo_bar <- foo::bar
>
> and use foo_bar, or something along those lines.
>
> When :: and ::: were introduce they were intended primarily for
> reflection and debugging, so speed was not an issue. ::: is still
> really only reliably usable that way, and making it faster may just
> encourage bad practice. :: is different and there are good arguments
> for using it in code, but I'm not yet seeing good arguments for use in
> ways that would be performance-critical, but I'm happy to be convinced
> otherwise. If there is a need for a faster :: then going to a
> SPECIALSXP is fine; it would also be good to make the byte code
> compiler aware of it, and possibly to work on ways to improve the
> performance further e.g. through cacheing.
>
> Best,
>
> luke
>
>
> On Thu, 22 Jan 2015, Peter Haverty wrote:
>
>
>> Hi all,
>>
>> When S4 methods are defined on base function (say, "match"), the
>> function becomes a method with the body "base::match(x,y)". A call to
>> such a function often spends more time doing "::" than in the function
>> itself.  I always assumed that "::" was a very low-level thing, but it
>> turns out to be a plain old function defined in base/R/namespace.R.
>> What would you all think about making "::" and ":::" .Primitives?  I
>> have submitted some examples, timings, and a patch to the R bug
>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>> I'd be very interested to hear your thoughts on the matter.
>>
>> Regards,
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Achim.Zeileis at uibk.ac.at  Thu Jan 22 22:17:46 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 22 Jan 2015 22:17:46 +0100 (CET)
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAJ9CoWnEBbs9iY097PUxg4UH8LpF5WJP7AayNQ-oxuCkbEa7Gg@mail.gmail.com>
References: <CAJ9CoWmTp_0UmL6UQ+iGBjbm-QXWxEyVsYWjhTWBj3YOXv3kKA@mail.gmail.com>
	<alpine.DEB.2.11.1501221838260.22244@paninaro.uibk.ac.at>
	<CAJ9CoWnRchvMv8y3tYq8cXo2kcBcX7g1ytTc6FtKM1iFNxSkxQ@mail.gmail.com>
	<alpine.DEB.2.11.1501221858440.22244@paninaro.uibk.ac.at>
	<CAJ9CoWnEBbs9iY097PUxg4UH8LpF5WJP7AayNQ-oxuCkbEa7Gg@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1501222215090.9677@paninaro.uibk.ac.at>

On Thu, 22 Jan 2015, Max Kuhn wrote:

> On Thu, Jan 22, 2015 at 1:05 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>> On Thu, 22 Jan 2015, Max Kuhn wrote:
>>
>>> On Thu, Jan 22, 2015 at 12:45 PM, Achim Zeileis
>>> <Achim.Zeileis at uibk.ac.at> wrote:
>>>>
>>>> On Thu, 22 Jan 2015, Max Kuhn wrote:
>>>>
>>>>> I've had a lot of requests for additions to the reproducible research
>>>>> task view that fall into a grey area (to me at least).
>>>>>
>>>>> For example, roxygen2 is a tool that broadly enable reproducibility
>>>>> but I see it more as a tool for better programming. I'm about to check
>>>>> in a new version of the task view that includes packrat and
>>>>> checkpoint, as they seem closer to reproducible research, but also
>>>>> feel like coding tools.
>>>>>
>>>>> There are a few other packages that many would find useful for better
>>>>> coding: devtools, testthat, lintr, codetools, svTools, rbenchmark,
>>>>> pkgutils, etc.
>>>>>
>>>>> This might be some overlap with the HPC task view. I would think that
>>>>> rJava, Rcpp and the like are better suited there but this is arguable.
>>>>>
>>>>> The last time I proposed something like this, Martin deftly convinced
>>>>> me to be the maintainer. It is probably better for everyone if we
>>>>> avoid that on this occasion.
>>>>>
>>>>> * Does anyone else see the need for this?
>>>>>
>>>>> * What other packages fit into this bin?
>>>>>
>>>>> * Would anyone like to volunteer?
>>>>
>>>>
>>>>
>>>> Max, thanks for the suggestion. We had a somewhat related proposal on
>>>> R-help
>>>> from Luca Braglia a couple of months ago, suggesting a "Package
>>>> Development"
>>>> task view:
>>>> https://mailman.stat.ethz.ch/pipermail/r-devel/2014-July/069454.html
>>>>
>>>> He put up some ideas on Github:
>>>> https://github.com/lbraglia/PackageDevelopmentTaskView
>>>>
>>>> When Luca asked me (ctv maintainer) and Dirk (HPC task view maintainer)
>>>> for
>>>> feedback off-list, I replied that it is important that task views are
>>>> focused in order to be useful and maintainable. My feeling was that
>>>> "PackageDevelopment" was too broad and also "ProgrammingTools" is still
>>>> too
>>>> board, I think. This could mean a lot of things/tools to a lot of people.
>>>>
>>>> But maybe it would be to factor out some aspect that is sharp and
>>>> clear(er)?
>>>> Or split it up into bits where there are (more or less) objectively clear
>>>> criteria for what goes in and what does not?
>>>
>>>
>>> It's funny that you said that. As I was updating the RR CTV, it
>>> realized what a beast it is right now. I thought about making a github
>>> project earlier today that would have more detailed examples and
>>> information.
>>>
>>> I see two problems with that as the *sole* solution.
>>>
>>> First, it is divorced from CRAN CTV and that is a place that people
>>> know and will look. I had no idea of Luca's work for this exact
>>> reason.
>>>
>>> Secondly, might be intimidating for new R users who, I think, are the
>>> targeted cohort for the CTVs.
>>
>>
>> Yes, I agree. There should (an) additional task view(s) on CRAN related to
>> this.
>>
>>> How about a relatively broad definition that is succinct in content
>>> with a link to a github repos?
>>
>>
>> I think this doesn't fit well with the existing development model and might
>> require duplicating changes in the <packagelist> of the task view. In order
>> to be easily installable I need the <packagelist> in the task view on CRAN
>> and not just in the linked list on Github.
>
> Many of the task views are encyclopedic and still focused. Perhaps my
> issues with RR are more related to how I currently organize it. I'll
> try to solve it that way.
>
>> Therefore, I would suggest splitting up the topic into things that are
>> fairly sharp and clear. (Of course, it is impossible to avoid overlap
>> completely.) For example, one could add "LanguageInterfaces" or something
>> like that.
>
> Looking at Luca's page, I think he does a great job of clustering
> packages. My suggestions for focused topics are:
>
> - Package Development*
> - Foreign Languages Interfaces
> - Code Analysis and Debugging
> - Profiling and Benchmarking
> - Unit Testing

Yes, good suggestions. Now we only need willing maintainers :-)

> * I would define the first one to be more narrow than the original 
> definition.

It's probably still the fuzziest one in the list above.

> I think that most of these would encompass less than 10 packages if we
> don't include all the Rcpp depends =]

:-)

>> And the task views on CRAN can always include <links> to further
>> documentation on Github and elsewhere. Especially when it comes to package
>> development there are also clearly different preferences about what is good
>> style or the right tools (say Github vs. R-Forge, knitr vs. Sweave, etc.)
>
> Yes. The comments above would not exclude this approach, which
> is/was/might be my intention for RR.

True.

thx,
Z


From haverty.peter at gene.com  Thu Jan 22 22:06:04 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Thu, 22 Jan 2015 13:06:04 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
Message-ID: <CAGh0NYq=XxvwMCZ=eLqTt6GewJR-6SOXQJOYfwJeODb=yRau+g@mail.gmail.com>

Hi all,

I use Luke's "::" hoisting trick often. I think it would be fantastic
if the JIT just did that for you.

The main trouble, for me, is in code I don't own.  When common
Bioconductor packages are loaded many, many base functions are saddled
with this substantial dispatch and "::" overhead.

While we have the hood up, the parser could help out a bit here too.
It already has special cases for "::" and ":::". Currently you get the
symbols "pkg" and "name" and have to go fishing in the calling
environment for the associated values.  It would be nice to have the
parser or JIT rewrite base::match as doubleColon("base","match") or
directly provide the symbols "base" and "match" to the subsequent
code.

I think it's also kind of entertaining that the comments in
base/R/namespace.R note that they are using ":::" for speed purposes
only.
Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


On Thu, Jan 22, 2015 at 12:54 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>>
>> For default methods there ought to be a way to create those so the
>> default method is computed at creation or load time and stored in an
>> environment.
>
> We had considered that, but we thought the definition of the function
> would be easier to interpret if it explicitly specified the namespace,
> instead of using tricks with environments. The same applies for
> memoizing the lookup in front of a loop.
>
> The implementation of these functions is almost simpler in C than it
> is in R, so there is relatively little risk to this change. But I
> agree the benefits are also somewhat minor.
>
>> For other cases if I want to use foo::bar many times, say
>> in a loop, I would do
>>
>> foo_bar <- foo::bar
>>
>> and use foo_bar, or something along those lines.
>>
>> When :: and ::: were introduce they were intended primarily for
>> reflection and debugging, so speed was not an issue. ::: is still
>> really only reliably usable that way, and making it faster may just
>> encourage bad practice. :: is different and there are good arguments
>> for using it in code, but I'm not yet seeing good arguments for use in
>> ways that would be performance-critical, but I'm happy to be convinced
>> otherwise. If there is a need for a faster :: then going to a
>> SPECIALSXP is fine; it would also be good to make the byte code
>> compiler aware of it, and possibly to work on ways to improve the
>> performance further e.g. through cacheing.
>>
>> Best,
>>
>> luke
>>
>>
>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>
>>
>>> Hi all,
>>>
>>> When S4 methods are defined on base function (say, "match"), the
>>> function becomes a method with the body "base::match(x,y)". A call to
>>> such a function often spends more time doing "::" than in the function
>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>> turns out to be a plain old function defined in base/R/namespace.R.
>>> What would you all think about making "::" and ":::" .Primitives?  I
>>> have submitted some examples, timings, and a patch to the R bug
>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>> I'd be very interested to hear your thoughts on the matter.
>>>
>>> Regards,
>>> Pete
>>>
>>> ____________________
>>> Peter M. Haverty, Ph.D.
>>> Genentech, Inc.
>>> phaverty at gene.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri Jan 23 00:26:41 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Jan 2015 15:26:41 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
Message-ID: <CAF8bMcaBMg568S6NXd6E5Oy-dyJ6KX2ebwP9oJ60+foBmaEu8g@mail.gmail.com>

> if I want to use foo::bar many times, say
> in a loop, I would do
>
> foo_bar <- foo::bar
>
> and use foo_bar, or something along those lines.

The foreach package does that with a function from the compiler package,
so that foreach can work on old version of R:
  comp <- if (getRversion() < "2.13.0") {
    function(expr, ...) expr
  } else {
    compiler::compile
  }
This results in foreach having its own copy of compiler::compile, with
namespace "compiler", but copied from the version of package:compile
existing on the machine that built the binary of foreach.  If you later
install
an updated version of the compiler package, then foreach still uses the old
compiler::compile, which may not work with the private functions in
the new version of package:compiler.

Making :: faster would not fix this particular problem (making 'comp' a
function that contained the if(getRVersion...) code would), but things
like this could cause problems when more people put 'myFunc <-
otherPackage::Func'
in their packages.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jan 22, 2015 at 11:44 AM, <luke-tierney at uiowa.edu> wrote:

> I'm not convinced that how to make :: faster is the right question. If
> you are finding foo::bar being called often enough to matter to your
> overall performance then to me the question is: why are you calling
> foo::bar more than once? Making :: a bit faster by making it a
> primitive will remove some overhead, but your are still left with a
> lot of work that shouldn't need to happen more than once.
>
> For default methods there ought to be a way to create those so the
> default method is computed at creation or load time and stored in an
> environment. For other cases if I want to use foo::bar many times, say
> in a loop, I would do
>
> foo_bar <- foo::bar
>
> and use foo_bar, or something along those lines.
>
> When :: and ::: were introduce they were intended primarily for
> reflection and debugging, so speed was not an issue. ::: is still
> really only reliably usable that way, and making it faster may just
> encourage bad practice. :: is different and there are good arguments
> for using it in code, but I'm not yet seeing good arguments for use in
> ways that would be performance-critical, but I'm happy to be convinced
> otherwise. If there is a need for a faster :: then going to a
> SPECIALSXP is fine; it would also be good to make the byte code
> compiler aware of it, and possibly to work on ways to improve the
> performance further e.g. through cacheing.
>
> Best,
>
> luke
>
>
> On Thu, 22 Jan 2015, Peter Haverty wrote:
>
>
>  Hi all,
>>
>> When S4 methods are defined on base function (say, "match"), the
>> function becomes a method with the body "base::match(x,y)". A call to
>> such a function often spends more time doing "::" than in the function
>> itself.  I always assumed that "::" was a very low-level thing, but it
>> turns out to be a plain old function defined in base/R/namespace.R.
>> What would you all think about making "::" and ":::" .Primitives?  I
>> have submitted some examples, timings, and a patch to the R bug
>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>> I'd be very interested to hear your thoughts on the matter.
>>
>> Regards,
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From willem.ligtenberg at openanalytics.eu  Fri Jan 23 11:13:26 2015
From: willem.ligtenberg at openanalytics.eu (Willem Ligtenberg)
Date: Fri, 23 Jan 2015 11:13:26 +0100 (CET)
Subject: [Rd]  Programming Tools CTV
In-Reply-To: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
Message-ID: <1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>

Hi all, 

Sorry if this doesn't end up in the thread.
Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.

It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
I myself am very interested in better/easier ways to develop faster and nicer code.

Kind regards,

Willem


From lbraglia at gmail.com  Fri Jan 23 12:49:37 2015
From: lbraglia at gmail.com (Luca Braglia)
Date: Fri, 23 Jan 2015 12:49:37 +0100
Subject: [Rd] Programming Tools CTV
In-Reply-To: <1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
Message-ID: <CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>

Hi Willem

thanks for volounteering.

To the best of my knowledge (regarding the machinery side), if you're
planning to use github (and maybe even if you don't) you can "stole"
ideas from

https://github.com/ropensci/webservices
https://github.com/lbraglia/PackageDevelopmentTaskView (minor
modifications from webservices)
https://github.com/eddelbuettel/ctv-finance or
https://github.com/eddelbuettel/ctv-hpc


HTH, Luca

2015-01-23 11:13 GMT+01:00 Willem Ligtenberg
<willem.ligtenberg at openanalytics.eu>:
> Hi all,
>
> Sorry if this doesn't end up in the thread.
> Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
> I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.
>
> It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
> I myself am very interested in better/easier ways to develop faster and nicer code.
>
> Kind regards,
>
> Willem
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lbraglia at gmail.com  Fri Jan 23 13:18:52 2015
From: lbraglia at gmail.com (Luca Braglia)
Date: Fri, 23 Jan 2015 13:18:52 +0100
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
	<CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
Message-ID: <CAFOm_+5F7yhto=GMz9Vv4f0v4GFn5paGv=hhv1j4Myd1ggn+mQ@mail.gmail.com>

... BTW you should install the ctv package and read the vignette at
first :)  ...

2015-01-23 12:49 GMT+01:00 Luca Braglia <lbraglia at gmail.com>:
> Hi Willem
>
> thanks for volounteering.
>
> To the best of my knowledge (regarding the machinery side), if you're
> planning to use github (and maybe even if you don't) you can "stole"
> ideas from
>
> https://github.com/ropensci/webservices
> https://github.com/lbraglia/PackageDevelopmentTaskView (minor
> modifications from webservices)
> https://github.com/eddelbuettel/ctv-finance or
> https://github.com/eddelbuettel/ctv-hpc
>
>
> HTH, Luca
>
> 2015-01-23 11:13 GMT+01:00 Willem Ligtenberg
> <willem.ligtenberg at openanalytics.eu>:
>> Hi all,
>>
>> Sorry if this doesn't end up in the thread.
>> Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
>> I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.
>>
>> It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
>> I myself am very interested in better/easier ways to develop faster and nicer code.
>>
>> Kind regards,
>>
>> Willem
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From dutangc at gmail.com  Fri Jan 23 14:05:11 2015
From: dutangc at gmail.com (Christophe Dutang)
Date: Fri, 23 Jan 2015 14:05:11 +0100
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
	<CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
Message-ID: <552FA8D9-D19D-4E53-A6BC-13277F94C897@gmail.com>

Dear Willem,

Personally, I use the R-forge project for the distribution CTV : https://r-forge.r-project.org/projects/ctv/

It?s an alternative option to github.

Regards, Christophe
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr

Le 23 janv. 2015 ? 12:49, Luca Braglia <lbraglia at gmail.com> a ?crit :

> Hi Willem
> 
> thanks for volounteering.
> 
> To the best of my knowledge (regarding the machinery side), if you're
> planning to use github (and maybe even if you don't) you can "stole"
> ideas from
> 
> https://github.com/ropensci/webservices
> https://github.com/lbraglia/PackageDevelopmentTaskView (minor
> modifications from webservices)
> https://github.com/eddelbuettel/ctv-finance or
> https://github.com/eddelbuettel/ctv-hpc
> 
> 
> HTH, Luca
> 
> 2015-01-23 11:13 GMT+01:00 Willem Ligtenberg
> <willem.ligtenberg at openanalytics.eu>:
>> Hi all,
>> 
>> Sorry if this doesn't end up in the thread.
>> Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
>> I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.
>> 
>> It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
>> I myself am very interested in better/easier ways to develop faster and nicer code.
>> 
>> Kind regards,
>> 
>> Willem
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From info at aghmed.fsnet.co.uk  Fri Jan 23 14:55:26 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 23 Jan 2015 13:55:26 +0000
Subject: [Rd] Programming Tools CTV
In-Reply-To: <552FA8D9-D19D-4E53-A6BC-13277F94C897@gmail.com>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>	<CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
	<552FA8D9-D19D-4E53-A6BC-13277F94C897@gmail.com>
Message-ID: <54C252CE.5090100@aghmed.fsnet.co.uk>

Dear Willem

I maintain the MetaAnalysis CTV.

I have found it quite practicable to do this without special tools. I 
use an editor for the XML. I use CRANberries to catch updates and I 
usually email people to check I have understood a new package. People 
also kindly email me occasionally with news about major changes.

On the other hand since it is the programming tools CTV I imagine you 
will want to try out the latest all-singing, all-dancing technology. And 
why not.

Michael

On 23/01/2015 13:05, Christophe Dutang wrote:
> Dear Willem,
>
> Personally, I use the R-forge project for the distribution CTV : https://r-forge.r-project.org/projects/ctv/
>
> It?s an alternative option to github.
>
> Regards, Christophe
> ---------------------------------------
> Christophe Dutang
> LMM, UdM, Le Mans, France
> web: http://dutangc.free.fr
>
> Le 23 janv. 2015 ? 12:49, Luca Braglia <lbraglia at gmail.com> a ?crit :
>
>> Hi Willem
>>
>> thanks for volounteering.
>>
>> To the best of my knowledge (regarding the machinery side), if you're
>> planning to use github (and maybe even if you don't) you can "stole"
>> ideas from
>>
>> https://github.com/ropensci/webservices
>> https://github.com/lbraglia/PackageDevelopmentTaskView (minor
>> modifications from webservices)
>> https://github.com/eddelbuettel/ctv-finance or
>> https://github.com/eddelbuettel/ctv-hpc
>>
>>
>> HTH, Luca
>>
>> 2015-01-23 11:13 GMT+01:00 Willem Ligtenberg
>> <willem.ligtenberg at openanalytics.eu>:
>>> Hi all,
>>>
>>> Sorry if this doesn't end up in the thread.
>>> Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
>>> I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.
>>>
>>> It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
>>> I myself am very interested in better/easier ways to develop faster and nicer code.
>>>
>>> Kind regards,
>>>
>>> Willem
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4260/8981 - Release Date: 01/23/15
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From h.wickham at gmail.com  Fri Jan 23 14:55:31 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 23 Jan 2015 05:55:31 -0800
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
	<CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
Message-ID: <CABdHhvGTNOVZ6OPLtsbKzPT=SWL_0DtHwYy8QmMM25d8iAc+rQ@mail.gmail.com>

I'd strongly second the notion of using github. The biggest advantage
is that others can easily contribute changes through pull requests
which lifts much of the burden from your shoulders.

Hadley

On Fri, Jan 23, 2015 at 3:49 AM, Luca Braglia <lbraglia at gmail.com> wrote:
> Hi Willem
>
> thanks for volounteering.
>
> To the best of my knowledge (regarding the machinery side), if you're
> planning to use github (and maybe even if you don't) you can "stole"
> ideas from
>
> https://github.com/ropensci/webservices
> https://github.com/lbraglia/PackageDevelopmentTaskView (minor
> modifications from webservices)
> https://github.com/eddelbuettel/ctv-finance or
> https://github.com/eddelbuettel/ctv-hpc
>
>
> HTH, Luca
>
> 2015-01-23 11:13 GMT+01:00 Willem Ligtenberg
> <willem.ligtenberg at openanalytics.eu>:
>> Hi all,
>>
>> Sorry if this doesn't end up in the thread.
>> Tobias Verbeke forwarded that e-mail to me, because he thought I would be interested in maintaining the Programming Tools CTV.
>> I wasn't subscribed to R-devel yet, but I would indeed like to volunteer to maintain the Programming Tools CTV.
>>
>> It will be my first time creating a CTV, so some guidance on getting it setup will be appreciated.
>> I myself am very interested in better/easier ways to develop faster and nicer code.
>>
>> Kind regards,
>>
>> Willem
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From Achim.Zeileis at uibk.ac.at  Fri Jan 23 15:37:08 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 23 Jan 2015 15:37:08 +0100 (CET)
Subject: [Rd] Programming Tools CTV
In-Reply-To: <1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
References: <1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
Message-ID: <alpine.DEB.2.11.1501231528360.8490@paninaro.uibk.ac.at>

Willem,

thanks for volunteering!

> Sorry if this doesn't end up in the thread. Tobias Verbeke forwarded 
> that e-mail to me, because he thought I would be interested in 
> maintaining the Programming Tools CTV. I wasn't subscribed to R-devel 
> yet, but I would indeed like to volunteer to maintain the Programming 
> Tools CTV.

As discussed in the other thread: A programming tools task view would be 
too broad and Max suggested splitting it up into sharper and more 
manageable portions. Maybe you want to pick up one of these sub-topics?

> It will be my first time creating a CTV, so some guidance on getting it 
> setup will be appreciated. I myself am very interested in better/easier 
> ways to develop faster and nicer code.

The process is usually the following:

- Someone proposes to set up a certain task view - often here in the list 
or in a direct e-mail to me.

- If the topic is deemed feasible for a task view, then the 
maintainer-to-be compiles a .ctv file following the advice in 
vignette("ctv", package = "ctv") and first sends it to me.

- If the maintainer-to-be and myself are satisfied with the result so far, 
we typically try to get some more feedback from the mailing list and then 
release it to CRAN.

As for version control:

The "ctv" package and all task view reside on R-Forge. All maintainers are 
invited to join the R-Forge project and thus get access to the SVN 
repository so that they can change their .ctv file directly. Most 
maintainers do so but a few maintainers have chose to either use no 
version control themselves or use some separate system (e.g., Github). In 
the latter cases, updates are sent by e-mail to me.

Best,
Z

> Kind regards,
>
> Willem
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From luke-tierney at uiowa.edu  Fri Jan 23 15:53:32 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 23 Jan 2015 08:53:32 -0600
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <CAFDcVCT9AnCaGg_fW96byDGNnCHXzosCN9zK4MdHwc9Mk2ojpQ@mail.gmail.com>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
	<CAFDcVCT9AnCaGg_fW96byDGNnCHXzosCN9zK4MdHwc9Mk2ojpQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1501230853040.10879@itasca.stat.uiowa.edu>

On Thu, 22 Jan 2015, Henrik Bengtsson wrote:

> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>> I'm not convinced that how to make :: faster is the right question. If
>> you are finding foo::bar being called often enough to matter to your
>> overall performance then to me the question is: why are you calling
>> foo::bar more than once? Making :: a bit faster by making it a
>> primitive will remove some overhead, but your are still left with a
>> lot of work that shouldn't need to happen more than once.
>>
>> For default methods there ought to be a way to create those so the
>> default method is computed at creation or load time and stored in an
>> environment. For other cases if I want to use foo::bar many times, say
>> in a loop, I would do
>>
>> foo_bar <- foo::bar
>>
>> and use foo_bar, or something along those lines.
>
> While you're on the line: Do you think this is an optimization that
> the 'compiler' package and it's cmpfun() byte compiler will be able to
> do in the future?

Most likely, at least at reasonable optimization levels.

Best,

luke

>
> /Henrik
>
>>
>> When :: and ::: were introduce they were intended primarily for
>> reflection and debugging, so speed was not an issue. ::: is still
>> really only reliably usable that way, and making it faster may just
>> encourage bad practice. :: is different and there are good arguments
>> for using it in code, but I'm not yet seeing good arguments for use in
>> ways that would be performance-critical, but I'm happy to be convinced
>> otherwise. If there is a need for a faster :: then going to a
>> SPECIALSXP is fine; it would also be good to make the byte code
>> compiler aware of it, and possibly to work on ways to improve the
>> performance further e.g. through cacheing.
>>
>> Best,
>>
>> luke
>>
>>
>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>
>>
>>> Hi all,
>>>
>>> When S4 methods are defined on base function (say, "match"), the
>>> function becomes a method with the body "base::match(x,y)". A call to
>>> such a function often spends more time doing "::" than in the function
>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>> turns out to be a plain old function defined in base/R/namespace.R.
>>> What would you all think about making "::" and ":::" .Primitives?  I
>>> have submitted some examples, timings, and a patch to the R bug
>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>> I'd be very interested to hear your thoughts on the matter.
>>>
>>> Regards,
>>> Pete
>>>
>>> ____________________
>>> Peter M. Haverty, Ph.D.
>>> Genentech, Inc.
>>> phaverty at gene.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke-tierney at uiowa.edu  Fri Jan 23 16:01:24 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 23 Jan 2015 09:01:24 -0600
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>

On Thu, 22 Jan 2015, Michael Lawrence wrote:

> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>>
>> For default methods there ought to be a way to create those so the
>> default method is computed at creation or load time and stored in an
>> environment.
>
> We had considered that, but we thought the definition of the function
> would be easier to interpret if it explicitly specified the namespace,
> instead of using tricks with environments. The same applies for
> memoizing the lookup in front of a loop.

interpret in what sense (human reader or R interpreter)? In either
case I'm not convinced.

> The implementation of these functions is almost simpler in C than it
> is in R, so there is relatively little risk to this change. But I
> agree the benefits are also somewhat minor.

I don't disagree, but it remains that even calling the C version has
costs that should not need to be paid. But maybe we can leave that to
the compiler/byte code engine. Optimizing references to symbols
resolved statically to name spaces and imports is on the to do list,
and with a little care that mechanism should work for foo::bar uses as
well.

Best,

luke

>
>> For other cases if I want to use foo::bar many times, say
>> in a loop, I would do
>>
>> foo_bar <- foo::bar
>>
>> and use foo_bar, or something along those lines.
>>
>> When :: and ::: were introduce they were intended primarily for
>> reflection and debugging, so speed was not an issue. ::: is still
>> really only reliably usable that way, and making it faster may just
>> encourage bad practice. :: is different and there are good arguments
>> for using it in code, but I'm not yet seeing good arguments for use in
>> ways that would be performance-critical, but I'm happy to be convinced
>> otherwise. If there is a need for a faster :: then going to a
>> SPECIALSXP is fine; it would also be good to make the byte code
>> compiler aware of it, and possibly to work on ways to improve the
>> performance further e.g. through cacheing.
>>
>> Best,
>>
>> luke
>>
>>
>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>
>>
>>> Hi all,
>>>
>>> When S4 methods are defined on base function (say, "match"), the
>>> function becomes a method with the body "base::match(x,y)". A call to
>>> such a function often spends more time doing "::" than in the function
>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>> turns out to be a plain old function defined in base/R/namespace.R.
>>> What would you all think about making "::" and ":::" .Primitives?  I
>>> have submitted some examples, timings, and a patch to the R bug
>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>> I'd be very interested to hear your thoughts on the matter.
>>>
>>> Regards,
>>> Pete
>>>
>>> ____________________
>>> Peter M. Haverty, Ph.D.
>>> Genentech, Inc.
>>> phaverty at gene.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From winstonchang1 at gmail.com  Fri Jan 23 17:15:53 2015
From: winstonchang1 at gmail.com (Winston Chang)
Date: Fri, 23 Jan 2015 10:15:53 -0600
Subject: [Rd] speedbump in library
In-Reply-To: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
Message-ID: <CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>

I think you can simplify a little by replacing this:
  pkg %in% loadedNamespaces()
with this:
  .getNamespace(pkg)

Whereas getNamespace(pkg) will load the package if it's not already
loaded, calling .getNamespace(pkg) (note the leading dot) won't load
the package.

I can't speak to whether there are any pitfalls in changing the
library path searching, though.

-Winston


On Thu, Jan 22, 2015 at 12:25 PM, Peter Haverty <haverty.peter at gene.com> wrote:
> Hi all,
>
> Profiling turned up a bit of a speedbump in the library function. I
> submitted a patch to the R bug tracker as bug 16168 and I've also
> included it below. The alternate code is simpler and easier to
> read/maintain, I believe.  Any thoughts on other ways to write this?
>
> Index: src/library/base/R/library.R
> ===================================================================
> --- src/library/base/R/library.R    (revision 67578)
> +++ src/library/base/R/library.R    (working copy)
> @@ -688,18 +688,8 @@
>      out <- character()
>
>      for(pkg in package) {
> -        paths <- character()
> -        for(lib in lib.loc) {
> -            dirs <- list.files(lib,
> -                               pattern = paste0("^", pkg, "$"),
> -                               full.names = TRUE)
> -            ## Note that we cannot use tools::file_test() here, as
> -            ## cyclic namespace dependencies are not supported.  Argh.
> -            paths <- c(paths,
> -                       dirs[dir.exists(dirs) &
> -                            file.exists(file.path(dirs,
> -                                                  "DESCRIPTION"))])
> -        }
> +        paths <- file.path(lib.loc, pkg)
> +        paths <- paths[ file.exists(file.path(paths, "DESCRIPTION")) ]
>          if(use_loaded && pkg %in% loadedNamespaces()) {
>              dir <- if (pkg == "base") system.file()
>              else getNamespaceInfo(pkg, "path")
>
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From haverty.peter at gene.com  Fri Jan 23 18:13:57 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Fri, 23 Jan 2015 09:13:57 -0800
Subject: [Rd] speedbump in library
In-Reply-To: <CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
Message-ID: <CAGh0NYobWb6CkEf_8kjR5W5U52uWUccjead0M8-+E0HJTaq_gw@mail.gmail.com>

Thanks Winston,

Yes, your version of that part is more direct. I guess it would need a
! is.null() too. I think we should use .getNamespace.

It It also occurred to me that this %in% check (which happens in a few
places) is kind of roundabout. It equates to

"foo" %in% ls(.Internal(getNamespaceRegistry()), all.names = TRUE)

We lack and R-level accessor for the namespace registry, but if we had
one we could do

getNamespaceRegistry()[["foo"]]

, which is just a hash lookup.



I'm getting a bit off topic here, but ...

"foo" %in% vector is a common pattern and reads well, but

any(vector == "foo")

is less work and much faster.  I wonder if there is room for a fast
path there ...



Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


On Fri, Jan 23, 2015 at 8:15 AM, Winston Chang <winstonchang1 at gmail.com> wrote:
> I think you can simplify a little by replacing this:
>   pkg %in% loadedNamespaces()
> with this:
>   .getNamespace(pkg)
>
> Whereas getNamespace(pkg) will load the package if it's not already
> loaded, calling .getNamespace(pkg) (note the leading dot) won't load
> the package.
>
> I can't speak to whether there are any pitfalls in changing the
> library path searching, though.
>
> -Winston
>
>
> On Thu, Jan 22, 2015 at 12:25 PM, Peter Haverty <haverty.peter at gene.com> wrote:
>> Hi all,
>>
>> Profiling turned up a bit of a speedbump in the library function. I
>> submitted a patch to the R bug tracker as bug 16168 and I've also
>> included it below. The alternate code is simpler and easier to
>> read/maintain, I believe.  Any thoughts on other ways to write this?
>>
>> Index: src/library/base/R/library.R
>> ===================================================================
>> --- src/library/base/R/library.R    (revision 67578)
>> +++ src/library/base/R/library.R    (working copy)
>> @@ -688,18 +688,8 @@
>>      out <- character()
>>
>>      for(pkg in package) {
>> -        paths <- character()
>> -        for(lib in lib.loc) {
>> -            dirs <- list.files(lib,
>> -                               pattern = paste0("^", pkg, "$"),
>> -                               full.names = TRUE)
>> -            ## Note that we cannot use tools::file_test() here, as
>> -            ## cyclic namespace dependencies are not supported.  Argh.
>> -            paths <- c(paths,
>> -                       dirs[dir.exists(dirs) &
>> -                            file.exists(file.path(dirs,
>> -                                                  "DESCRIPTION"))])
>> -        }
>> +        paths <- file.path(lib.loc, pkg)
>> +        paths <- paths[ file.exists(file.path(paths, "DESCRIPTION")) ]
>>          if(use_loaded && pkg %in% loadedNamespaces()) {
>>              dir <- if (pkg == "base") system.file()
>>              else getNamespaceInfo(pkg, "path")
>>
>> Pete
>>
>> ____________________
>> Peter M. Haverty, Ph.D.
>> Genentech, Inc.
>> phaverty at gene.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From Philippe.GROSJEAN at umons.ac.be  Fri Jan 23 18:14:59 2015
From: Philippe.GROSJEAN at umons.ac.be (Philippe GROSJEAN)
Date: Fri, 23 Jan 2015 17:14:59 +0000
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
	<alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>
Message-ID: <7966BBB5-0C22-4F2D-84B7-064DE118B6DC@umons.ac.be>

I tend to use this (in my own internal code *only*):

exported <- function (pkg) {
	if (pkg == "base") {
		function (fun) {
			fun <- as.character(substitute(fun))
			res <- .BaseNamespaceEnv[[fun]]
			if (is.null(res))
				stop(fun, " is not found in package base")
			res
		}
	} else {
		ns <- getNamespace(pkg)
		exports <- getNamespaceInfo(ns, "exports")
		function (obj) {
			obj <- as.character(substitute(obj))
			exportedObj <- exports[[obj]]
			if (is.null(exportedObj)) {
				if (is.null(ns[[obj]])) {
					stop(obj, " does not exists in package ", pkg)	
				} else {
					stop(obj, " is not exported from package ", pkg)
				}
			}
			ns[[exportedObj]]
		}
	}
}
stats <- exported("stats")
stats(acf)
stats("[.acf")
stats("inexistant")
exported("base")(ls)
exported("base")(inexistant)

## Performance tests for what it?s worth
microbenchmark::microbenchmark(stats::acf, (stats <- exported("stats"))(acf), stats(acf))
microbenchmark::microbenchmark(base::ls, (base <- exported("base"))(ls), base(ls), .BaseNamespaceEnv$ls)

So, `::` is slow and I can get better speed results thanks to binding both the namespace and the exports environments in the `stats` closure. Unless I miss something, this is not much a problem for base package that is never unloaded. Yet, .BaseNamespaceEnv$xxx, or baseenv()$xxx does the job faster and simpler. 

However, there is a vicious problem with my exported() function, which is, to say the least, dangerous under the hand of unaware users. Indeed:

stats <- exported(?stats?)

creates a new binding to both the namespace and the exports environments of the stats package. So, if I do:

detach(?package:stats?, unload = TRUE), then library(?stats?), I got two versions of the package in memory, and my `stats`closure refers to an outdated version of the package. This is particularly problematic if the package was recompiled in between (in the context of debugging).

Conclusion: much of the lost of performance in `::` is due to not caching the environments. This is fully justified to keep the dynamism of the language at full power and to avoid a messy state of R as described here above? Regarding dynamism, even `stats::acf`remains discutable.

Moreover, it is possible to do many other crazy things with these environments, once one got a grip on them. So, even getNamespace() and getNamespaceInfo() are dangerous. Perhaps this should be emphasised in the ?getNamespace man page?

This is also why the code above is not released in the wild? Well, now it is :-(

Best,

Philippe

..............................................<?}))><........
 ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
 ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

> On 23 Jan 2015, at 16:01, luke-tierney at uiowa.edu wrote:
> 
> On Thu, 22 Jan 2015, Michael Lawrence wrote:
> 
>> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>>> 
>>> For default methods there ought to be a way to create those so the
>>> default method is computed at creation or load time and stored in an
>>> environment.
>> 
>> We had considered that, but we thought the definition of the function
>> would be easier to interpret if it explicitly specified the namespace,
>> instead of using tricks with environments. The same applies for
>> memoizing the lookup in front of a loop.
> 
> interpret in what sense (human reader or R interpreter)? In either
> case I'm not convinced.
> 
>> The implementation of these functions is almost simpler in C than it
>> is in R, so there is relatively little risk to this change. But I
>> agree the benefits are also somewhat minor.
> 
> I don't disagree, but it remains that even calling the C version has
> costs that should not need to be paid. But maybe we can leave that to
> the compiler/byte code engine. Optimizing references to symbols
> resolved statically to name spaces and imports is on the to do list,
> and with a little care that mechanism should work for foo::bar uses as
> well.
> 
> Best,
> 
> luke
> 
>> 
>>> For other cases if I want to use foo::bar many times, say
>>> in a loop, I would do
>>> 
>>> foo_bar <- foo::bar
>>> 
>>> and use foo_bar, or something along those lines.
>>> 
>>> When :: and ::: were introduce they were intended primarily for
>>> reflection and debugging, so speed was not an issue. ::: is still
>>> really only reliably usable that way, and making it faster may just
>>> encourage bad practice. :: is different and there are good arguments
>>> for using it in code, but I'm not yet seeing good arguments for use in
>>> ways that would be performance-critical, but I'm happy to be convinced
>>> otherwise. If there is a need for a faster :: then going to a
>>> SPECIALSXP is fine; it would also be good to make the byte code
>>> compiler aware of it, and possibly to work on ways to improve the
>>> performance further e.g. through cacheing.
>>> 
>>> Best,
>>> 
>>> luke
>>> 
>>> 
>>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>> 
>>> 
>>>> Hi all,
>>>> 
>>>> When S4 methods are defined on base function (say, "match"), the
>>>> function becomes a method with the body "base::match(x,y)". A call to
>>>> such a function often spends more time doing "::" than in the function
>>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>>> turns out to be a plain old function defined in base/R/namespace.R.
>>>> What would you all think about making "::" and ":::" .Primitives?  I
>>>> have submitted some examples, timings, and a patch to the R bug
>>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>>> I'd be very interested to hear your thoughts on the matter.
>>>> 
>>>> Regards,
>>>> Pete
>>>> 
>>>> ____________________
>>>> Peter M. Haverty, Ph.D.
>>>> Genentech, Inc.
>>>> phaverty at gene.com
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> --
>>> Luke Tierney
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>   Actuarial Science
>>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>   Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Jan 23 18:55:41 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 23 Jan 2015 11:55:41 -0600
Subject: [Rd] Programming Tools CTV
In-Reply-To: <CABdHhvGTNOVZ6OPLtsbKzPT=SWL_0DtHwYy8QmMM25d8iAc+rQ@mail.gmail.com>
References: <350006315.44795.1422007613521.JavaMail.zimbra@openanalytics.eu>
	<1801660321.44909.1422008006375.JavaMail.zimbra@openanalytics.eu>
	<CAFOm_+6eJK8xbV8+SuqjSVOJMQoKVOm67d3b0ERXNnPfp+1Gew@mail.gmail.com>
	<CABdHhvGTNOVZ6OPLtsbKzPT=SWL_0DtHwYy8QmMM25d8iAc+rQ@mail.gmail.com>
Message-ID: <21698.35613.795767.889865@max.nulle.part>


On 23 January 2015 at 05:55, Hadley Wickham wrote:
| I'd strongly second the notion of using github. The biggest advantage
| is that others can easily contribute changes through pull requests
| which lifts much of the burden from your shoulders.

That's "The Theory".

"The Practice" for eight weeks having the High-Performance Computing and
Finance Task Views there (in "source" and a rendered markdown, see [1]) is a
single pull request fixing a one-char typo.

So the jury may still be out on that one.

Dirk

[1] As already shown in the email thread:
        https://github.com/eddelbuettel/ctv-hpc
        https://github.com/eddelbuettel/ctv-finance


-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From hpages at fredhutch.org  Fri Jan 23 19:11:47 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 23 Jan 2015 10:11:47 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
	<alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>
Message-ID: <54C28EE3.8070305@fredhutch.org>

Hi,

On 01/23/2015 07:01 AM, luke-tierney at uiowa.edu wrote:
> On Thu, 22 Jan 2015, Michael Lawrence wrote:
>
>> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>>>
>>> For default methods there ought to be a way to create those so the
>>> default method is computed at creation or load time and stored in an
>>> environment.
>>
>> We had considered that, but we thought the definition of the function
>> would be easier to interpret if it explicitly specified the namespace,
>> instead of using tricks with environments. The same applies for
>> memoizing the lookup in front of a loop.
>
> interpret in what sense (human reader or R interpreter)? In either
> case I'm not convinced.

 From a developer perspective, especially when debugging, when we do
selectMethod("match", ...) and it turns out that this returns the
default method, it's good to see:

   Method Definition (Class "derivedDefaultMethod"):

   function (x, table, nomatch = NA_integer_, incomparables = NULL,
       ...)
   base::match(x, table, nomatch = nomatch, incomparables = incomparables,
       ...)
   <environment: namespace:BiocGenerics>

   Signatures:
           x           table
   target  "DataFrame" "ANY"
   defined "ANY"       "ANY"

rather than some obscure/uninformative body. I hope we can keep that.

>
>> The implementation of these functions is almost simpler in C than it
>> is in R, so there is relatively little risk to this change. But I
>> agree the benefits are also somewhat minor.
>
> I don't disagree, but it remains that even calling the C version has
> costs that should not need to be paid. But maybe we can leave that to
> the compiler/byte code engine. Optimizing references to symbols
> resolved statically to name spaces and imports is on the to do list,
> and with a little care that mechanism should work for foo::bar uses as
> well.

That would be great. Thanks!

H.

>
> Best,
>
> luke
>
>>
>>> For other cases if I want to use foo::bar many times, say
>>> in a loop, I would do
>>>
>>> foo_bar <- foo::bar
>>>
>>> and use foo_bar, or something along those lines.
>>>
>>> When :: and ::: were introduce they were intended primarily for
>>> reflection and debugging, so speed was not an issue. ::: is still
>>> really only reliably usable that way, and making it faster may just
>>> encourage bad practice. :: is different and there are good arguments
>>> for using it in code, but I'm not yet seeing good arguments for use in
>>> ways that would be performance-critical, but I'm happy to be convinced
>>> otherwise. If there is a need for a faster :: then going to a
>>> SPECIALSXP is fine; it would also be good to make the byte code
>>> compiler aware of it, and possibly to work on ways to improve the
>>> performance further e.g. through cacheing.
>>>
>>> Best,
>>>
>>> luke
>>>
>>>
>>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>>
>>>
>>>> Hi all,
>>>>
>>>> When S4 methods are defined on base function (say, "match"), the
>>>> function becomes a method with the body "base::match(x,y)". A call to
>>>> such a function often spends more time doing "::" than in the function
>>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>>> turns out to be a plain old function defined in base/R/namespace.R.
>>>> What would you all think about making "::" and ":::" .Primitives?  I
>>>> have submitted some examples, timings, and a patch to the R bug
>>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>>> I'd be very interested to hear your thoughts on the matter.
>>>>
>>>> Regards,
>>>> Pete
>>>>
>>>> ____________________
>>>> Peter M. Haverty, Ph.D.
>>>> Genentech, Inc.
>>>> phaverty at gene.com
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Luke Tierney
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>    Actuarial Science
>>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From dtenenba at fredhutch.org  Fri Jan 23 21:50:19 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Fri, 23 Jan 2015 12:50:19 -0800 (PST)
Subject: [Rd] issue with update.packages()
In-Reply-To: <1122264420.3177209.1422046176399.JavaMail.root@fredhutch.org>
Message-ID: <1170831822.3177223.1422046219606.JavaMail.root@fredhutch.org>

Hello,

I see the following issue in R-devel since 'both' has become the default pkgType for binary platforms.

update.packages() fails when you set options(repos). Looks like it is trying to download a tgz file from the src/contrib section of a repository (on a mac).

To reproduce this you need to have an older version of AnnotationDbi installed, which I accomplished by faking it, installing pkgKitten and then doing:

library(pkgKitten)
kitten("AnnotationDbi")

Then exiting R and doing

R CMD INSTALL AnnotationDbi.

Here's the problem:

> packageVersion("AnnotationDbi")
[1] ?1.0?
> options(repos=structure(c("http://bioconductor.org/packages/3.1/bioc", "http://bioconductor.org/packages/3.1/data/annotation", 
+ "http://bioconductor.org/packages/3.1/data/experiment", "http://bioconductor.org/packages/3.1/extra", 
+ "http://cran.fhcrc.org"), .Names = c("BioCsoft", "BioCann", "BioCexp", 
+ "BioCextra", "CRAN")))
> update.packages(oldPkgs="AnnotationDbi")
AnnotationDbi :
 Version 1.0 installed in /Library/Frameworks/R.framework.develMav/Versions/3.2/Resources/library 
 Version 1.29.17 available at http://bioconductor.org/packages/3.1/bioc
Update (y/N/c)?  y
also installing the dependencies ?IRanges?, ?BiocGenerics?, ?Biobase?, ?GenomeInfoDb?, ?DBI?, ?RSQLite?, ?S4Vectors?

trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/IRanges_2.1.35.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/IRanges_2.1.35.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?IRanges? failed
trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/BiocGenerics_0.13.4.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/BiocGenerics_0.13.4.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?BiocGenerics? failed
trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/Biobase_2.27.1.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/Biobase_2.27.1.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?Biobase? failed
trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/GenomeInfoDb_1.3.12.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/GenomeInfoDb_1.3.12.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?GenomeInfoDb? failed
trying URL 'http://cran.fhcrc.org/src/contrib/DBI_0.3.1.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://cran.fhcrc.org/src/contrib/DBI_0.3.1.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?DBI? failed
trying URL 'http://cran.fhcrc.org/src/contrib/RSQLite_1.0.0.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://cran.fhcrc.org/src/contrib/RSQLite_1.0.0.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?RSQLite? failed
trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/S4Vectors_0.5.16.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/S4Vectors_0.5.16.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?S4Vectors? failed
trying URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/AnnotationDbi_1.29.17.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 'http://bioconductor.org/packages/3.1/bioc/src/contrib/AnnotationDbi_1.29.17.tgz'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?AnnotationDbi? failed
> sessionInfo()
R Under development (unstable) (2015-01-22 r67580)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.2.0

Thanks,
Dan


From murdoch.duncan at gmail.com  Fri Jan 23 21:59:29 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Jan 2015 15:59:29 -0500
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <CAGh0NYq=XxvwMCZ=eLqTt6GewJR-6SOXQJOYfwJeODb=yRau+g@mail.gmail.com>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
	<CAGh0NYq=XxvwMCZ=eLqTt6GewJR-6SOXQJOYfwJeODb=yRau+g@mail.gmail.com>
Message-ID: <54C2B631.8010600@gmail.com>

On 22/01/2015 4:06 PM, Peter Haverty wrote:
> Hi all,
> 
> I use Luke's "::" hoisting trick often. I think it would be fantastic
> if the JIT just did that for you.
> 
> The main trouble, for me, is in code I don't own.  When common
> Bioconductor packages are loaded many, many base functions are saddled
> with this substantial dispatch and "::" overhead.
> 
> While we have the hood up, the parser could help out a bit here too.
> It already has special cases for "::" and ":::". Currently you get the
> symbols "pkg" and "name" and have to go fishing in the calling
> environment for the associated values.  

I don't think the parser should do this, but it does seem like a
reasonable optimization for the compiler to do.

It would be nice to have the
> parser or JIT rewrite base::match as doubleColon("base","match") or
> directly provide the symbols "base" and "match" to the subsequent
> code.

Currently the parser provides the expression `::`(base, match), and the
`::` function converts those symbols to character strings "base" and
"match".  While the parser could have saved it some work by giving the
expression `::`("base", "match"), I think it's a bad idea to start
messing with things that way.  After all, a user could have defined
their own `::` function, and they should get what they typed.

Duncan Murdoch


From lawrence.michael at gene.com  Fri Jan 23 22:11:39 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 23 Jan 2015 13:11:39 -0800
Subject: [Rd] :: and ::: as .Primitives?
In-Reply-To: <54C28EE3.8070305@fredhutch.org>
References: <CAGh0NYotjwDf5JYGcTggJWhWUSVsmBAuhbtGzwqsO+nXBpthyQ@mail.gmail.com>
	<alpine.LFD.2.11.1501221330230.10879@itasca.stat.uiowa.edu>
	<CAOQ5NycWpawep=tFCEkVRbU-Hy-asCUowaQF9a1H41d5z7Owfw@mail.gmail.com>
	<alpine.LFD.2.11.1501230857400.10879@itasca.stat.uiowa.edu>
	<54C28EE3.8070305@fredhutch.org>
Message-ID: <CAOQ5NydmYocjFdG8z3je2rUdnTL_q0Euu_Rp_CpMc4mHaef67g@mail.gmail.com>

On Fri, Jan 23, 2015 at 10:11 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi,
>
> On 01/23/2015 07:01 AM, luke-tierney at uiowa.edu wrote:
>>
>> On Thu, 22 Jan 2015, Michael Lawrence wrote:
>>
>>> On Thu, Jan 22, 2015 at 11:44 AM,  <luke-tierney at uiowa.edu> wrote:
>>>>
>>>>
>>>> For default methods there ought to be a way to create those so the
>>>> default method is computed at creation or load time and stored in an
>>>> environment.
>>>
>>>
>>> We had considered that, but we thought the definition of the function
>>> would be easier to interpret if it explicitly specified the namespace,
>>> instead of using tricks with environments. The same applies for
>>> memoizing the lookup in front of a loop.
>>
>>
>> interpret in what sense (human reader or R interpreter)? In either
>> case I'm not convinced.
>
>
> From a developer perspective, especially when debugging, when we do
> selectMethod("match", ...) and it turns out that this returns the
> default method, it's good to see:
>
>   Method Definition (Class "derivedDefaultMethod"):
>
>   function (x, table, nomatch = NA_integer_, incomparables = NULL,
>       ...)
>   base::match(x, table, nomatch = nomatch, incomparables = incomparables,
>       ...)
>   <environment: namespace:BiocGenerics>
>
>   Signatures:
>           x           table
>   target  "DataFrame" "ANY"
>   defined "ANY"       "ANY"
>
> rather than some obscure/uninformative body. I hope we can keep that.

That was the goal of this patch. We want to keep that, and make
match() ~25% faster when falling back to the default method (for small
inputs). Right now, loading BiocGenerics, IRanges, etc, slows many
functions down by roughly that amount.

>
>>
>>> The implementation of these functions is almost simpler in C than it
>>> is in R, so there is relatively little risk to this change. But I
>>> agree the benefits are also somewhat minor.
>>
>>
>> I don't disagree, but it remains that even calling the C version has
>> costs that should not need to be paid. But maybe we can leave that to
>> the compiler/byte code engine. Optimizing references to symbols
>> resolved statically to name spaces and imports is on the to do list,
>> and with a little care that mechanism should work for foo::bar uses as
>> well.
>
>
> That would be great. Thanks!
>
>
> H.
>
>>
>> Best,
>>
>> luke
>>
>>>
>>>> For other cases if I want to use foo::bar many times, say
>>>> in a loop, I would do
>>>>
>>>> foo_bar <- foo::bar
>>>>
>>>> and use foo_bar, or something along those lines.
>>>>
>>>> When :: and ::: were introduce they were intended primarily for
>>>> reflection and debugging, so speed was not an issue. ::: is still
>>>> really only reliably usable that way, and making it faster may just
>>>> encourage bad practice. :: is different and there are good arguments
>>>> for using it in code, but I'm not yet seeing good arguments for use in
>>>> ways that would be performance-critical, but I'm happy to be convinced
>>>> otherwise. If there is a need for a faster :: then going to a
>>>> SPECIALSXP is fine; it would also be good to make the byte code
>>>> compiler aware of it, and possibly to work on ways to improve the
>>>> performance further e.g. through cacheing.
>>>>
>>>> Best,
>>>>
>>>> luke
>>>>
>>>>
>>>> On Thu, 22 Jan 2015, Peter Haverty wrote:
>>>>
>>>>
>>>>> Hi all,
>>>>>
>>>>> When S4 methods are defined on base function (say, "match"), the
>>>>> function becomes a method with the body "base::match(x,y)". A call to
>>>>> such a function often spends more time doing "::" than in the function
>>>>> itself.  I always assumed that "::" was a very low-level thing, but it
>>>>> turns out to be a plain old function defined in base/R/namespace.R.
>>>>> What would you all think about making "::" and ":::" .Primitives?  I
>>>>> have submitted some examples, timings, and a patch to the R bug
>>>>> tracker (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16134).
>>>>> I'd be very interested to hear your thoughts on the matter.
>>>>>
>>>>> Regards,
>>>>> Pete
>>>>>
>>>>> ____________________
>>>>> Peter M. Haverty, Ph.D.
>>>>> Genentech, Inc.
>>>>> phaverty at gene.com
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> --
>>>> Luke Tierney
>>>> Ralph E. Wareham Professor of Mathematical Sciences
>>>> University of Iowa                  Phone:             319-335-3386
>>>> Department of Statistics and        Fax:               319-335-3017
>>>>    Actuarial Science
>>>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From mario.annau at gmail.com  Sat Jan 24 09:58:29 2015
From: mario.annau at gmail.com (Mario Annau)
Date: Sat, 24 Jan 2015 09:58:29 +0100
Subject: [Rd] Proper way to define cbind, rbind for s4 classes in package
Message-ID: <54C35EB5.3060402@gmail.com>

Hi all,
this question has already been posted on stackoverflow, however without
success, see also
http://stackoverflow.com/questions/27886535/proper-way-to-use-cbind-rbind-with-s4-classes-in-package.

I have written a package using S4 classes and would like to use the
functions rbind, cbind with these defined classes.

Since it does not seem to be possible to define rbind and cbind directly
as S4 methods (see ?cBind) I defined rbind2 and cbind2 instead:

setMethod("rbind2", signature(x="ClassA", y = "ANY"),
    function(x, y) {
      # Do stuff ...
})

setMethod("cbind2", signature(x="ClassA", y = "ANY"),
    function(x, y) {
      # Do stuff ...
})

>From ?cbind2 I learned that these functions need to be activated using
methods:::bind_activation to replace rbind and cbind from base.

I included the call in the package file R/zzz.R using the .onLoad function:

.onLoad <- function(...) {
  # Bind activation of cbind(2) and rbind(2) for S4 classes
  methods:::bind_activation(TRUE)
}
This works as expected. However, running R CMD check I am now getting
the following NOTE since I am using an unexported function in methods:

* checking dependencies in R code ... NOTE
Unexported object imported by a ':::' call: 'methods:::bind_activation'
  See the note in ?`:::` about the use of this operator.
How can I get rid of the NOTE and what is the proper way to define the
methods cbind and rbind for S4 classes in a package?

Best,
mario


From lawrence.michael at gene.com  Sat Jan 24 15:39:37 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 24 Jan 2015 06:39:37 -0800
Subject: [Rd] Proper way to define cbind, rbind for s4 classes in package
In-Reply-To: <54C35EB5.3060402@gmail.com>
References: <54C35EB5.3060402@gmail.com>
Message-ID: <CAOQ5NyeRprfmr+RyUxnoz3JCy9jsz+hasWZN0A=KBrRbdkykRw@mail.gmail.com>

On Sat, Jan 24, 2015 at 12:58 AM, Mario Annau <mario.annau at gmail.com> wrote:
> Hi all,
> this question has already been posted on stackoverflow, however without
> success, see also
> http://stackoverflow.com/questions/27886535/proper-way-to-use-cbind-rbind-with-s4-classes-in-package.
>
> I have written a package using S4 classes and would like to use the
> functions rbind, cbind with these defined classes.
>
> Since it does not seem to be possible to define rbind and cbind directly
> as S4 methods (see ?cBind) I defined rbind2 and cbind2 instead:
>

This needs some clarification. It certainly is possible to define
cbind and rbind methods. The BiocGenerics package defines generics for
those and many methods are defined by e.g. S4Vectors, IRanges, etc.
The issue is that dispatch on "..." is singular, i.e., you can only
specify one class that all args in "..." must share (potentially
through inheritance). Thus, trying to combine objects from a different
hierarchy (or non-S4 objects) will not work. This has not been a huge
problem for us in practice. For example, we have a DataFrame object
that mimics data.frame. To cbind a data.frame with a DataFrame, the
user can just call the DataFrame() constructor. rbind() between
different data structures is much less common.

The cBind and rBind functions in Matrix (and the r/cbind that get
installed by bind_activation, the code is shared) work by recursing,
dropping the first argument until two are left, and then combining
with r/cbind2(). The Biobase package uses a similar strategy to mimic
c() via its non-standard combine() generic. The nice thing about the
combine() approach is the user entry point and the generic are the
same, instead of having methods on rbind2() and the user calling
rBind().

I would argue that bind_activation(TRUE) should be discouraged,
because it replaces the native rbind and cbind with recursive variants
that are going to cause problems, performance and otherwise. This is
why it is hidden. Perhaps a reasonable compromise would be for the
native cbind and rbind to check whether any arguments are S4 and if
so, resort to recursion. Recursion does seem to be a clean way to
implement "type promotion", i.e., to answer the question "which type
should the result be when faced with mixed-type args?".

Hopefully others have better ideas.

Michael




> setMethod("rbind2", signature(x="ClassA", y = "ANY"),
>     function(x, y) {
>       # Do stuff ...
> })
>
> setMethod("cbind2", signature(x="ClassA", y = "ANY"),
>     function(x, y) {
>       # Do stuff ...
> })
>
> >From ?cbind2 I learned that these functions need to be activated using
> methods:::bind_activation to replace rbind and cbind from base.
>
> I included the call in the package file R/zzz.R using the .onLoad function:
>
> .onLoad <- function(...) {
>   # Bind activation of cbind(2) and rbind(2) for S4 classes
>   methods:::bind_activation(TRUE)
> }
> This works as expected. However, running R CMD check I am now getting
> the following NOTE since I am using an unexported function in methods:
>
> * checking dependencies in R code ... NOTE
> Unexported object imported by a ':::' call: 'methods:::bind_activation'
>   See the note in ?`:::` about the use of this operator.
> How can I get rid of the NOTE and what is the proper way to define the
> methods cbind and rbind for S4 classes in a package?
>
> Best,
> mario
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mario.annau at gmail.com  Sat Jan 24 21:02:36 2015
From: mario.annau at gmail.com (Mario Annau)
Date: Sat, 24 Jan 2015 21:02:36 +0100
Subject: [Rd] Proper way to define cbind, rbind for s4 classes in package
In-Reply-To: <CAOQ5NyeRprfmr+RyUxnoz3JCy9jsz+hasWZN0A=KBrRbdkykRw@mail.gmail.com>
References: <54C35EB5.3060402@gmail.com>
	<CAOQ5NyeRprfmr+RyUxnoz3JCy9jsz+hasWZN0A=KBrRbdkykRw@mail.gmail.com>
Message-ID: <54C3FA5C.408@gmail.com>

>> I have written a package using S4 classes and would like to use the
>> functions rbind, cbind with these defined classes.
>>
>> Since it does not seem to be possible to define rbind and cbind directly
>> as S4 methods (see ?cBind) I defined rbind2 and cbind2 instead:
>>
> 
> This needs some clarification. It certainly is possible to define
> cbind and rbind methods. The BiocGenerics package defines generics for
> those and many methods are defined by e.g. S4Vectors, IRanges, etc.
> The issue is that dispatch on "..." is singular, i.e., you can only
> specify one class that all args in "..." must share (potentially
> through inheritance). Thus, trying to combine objects from a different
> hierarchy (or non-S4 objects) will not work. 
This is unfortunately an issue in my case since I would like to dispatch
on different classes.

To be more explicit than in the toy example, my actual method definition
is as follows:

setMethod("cbind2", signature(x="DataSet", y = "matrix"),
  function(x, y) {
	# Do stuff ...
}
setMethod("rbind2", signature(x="DataSet", y = "matrix"),
  function(x, y) {
	# Do stuff ...
}

The class DataSet actually wraps a pointer to a 2-dimensional HDF5
dataset. To make DataSet extensions more intuitive for the user I
thought that overloading cbind/rbind would be a good idea.

Best,
mario

> I would argue that bind_activation(TRUE) should be discouraged,
> because it replaces the native rbind and cbind with recursive variants
> that are going to cause problems, performance and otherwise. This is
> why it is hidden. Perhaps a reasonable compromise would be for the
> native cbind and rbind to check whether any arguments are S4 and if
> so, resort to recursion. Recursion does seem to be a clean way to
> implement "type promotion", i.e., to answer the question "which type
> should the result be when faced with mixed-type args?".
> 
> Hopefully others have better ideas.
> 
> Michael
> 
> 
> 
> 
>> setMethod("rbind2", signature(x="ClassA", y = "ANY"),
>>     function(x, y) {
>>       # Do stuff ...
>> })
>>
>> setMethod("cbind2", signature(x="ClassA", y = "ANY"),
>>     function(x, y) {
>>       # Do stuff ...
>> })
>>
>> >From ?cbind2 I learned that these functions need to be activated using
>> methods:::bind_activation to replace rbind and cbind from base.
>>
>> I included the call in the package file R/zzz.R using the .onLoad function:
>>
>> .onLoad <- function(...) {
>>   # Bind activation of cbind(2) and rbind(2) for S4 classes
>>   methods:::bind_activation(TRUE)
>> }
>> This works as expected. However, running R CMD check I am now getting
>> the following NOTE since I am using an unexported function in methods:
>>
>> * checking dependencies in R code ... NOTE
>> Unexported object imported by a ':::' call: 'methods:::bind_activation'
>>   See the note in ?`:::` about the use of this operator.
>> How can I get rid of the NOTE and what is the proper way to define the
>> methods cbind and rbind for S4 classes in a package?
>>
>> Best,
>> mario
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From haverty.peter at gene.com  Sun Jan 25 21:21:04 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Sun, 25 Jan 2015 12:21:04 -0800
Subject: [Rd] names function for environments?
Message-ID: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>

Hi all,

The "ls" function wears two hats. It allows users to inspect an
environment interactively and also serves deeper in code as the
accessor for an environment's names/keys. I propose that we separate
these two conflicting goals, keeping ls for interactive use and adding
names for a quick listing of the hash keys. This involves adding two
lines to do_names in attrib.c.

The 'ls' function and its 'objects' synonym appear very frequently in
performance-critical code like base/R/namespace.R and throughout the
methods package. These functions are currently among the major
contributors to execution time in package loading.

This two-line addition to attrib.c gives a significant speedup for
listing an environment's names/keys (2-60X depending on the 'sorted'
argument). It also simplifies the environment API by making it more
like the other basic types. We already have $ and [[ after all.

Rather than sprinkling sorted=FALSE throughout the methods and base
code, let's use names.

Would you be open to this change?

I have submitted a patch and some timings to the bug tracker as
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170

Regards,
Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


From john.maindonald at anu.edu.au  Mon Jan 26 00:25:37 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 25 Jan 2015 23:25:37 +0000
Subject: [Rd] R CMD check message: "The following files should probably not
 be installed"
Message-ID: <986A5055-890F-4E56-91C9-1006ADEB9599@anu.edu.au>

I am doing [R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?; Platform: x86_64-apple-darwin10.8.0 (64-bit)]

> R CMD build DAAGviz
> R CMD check DAAGviz_1.0.3.tar.gz

Without a .Rinstignore file, I get:

<<<
The following files should probably not be installed:
  ?figs10.pdf?, ?figs11.pdf?, ?figs12.pdf?, ?figs13.pdf?, ?figs14.pdf?,
  ?figs5.pdf?, ?figs6.pdf?, ?figs9.pdf?

Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
or move the vignette sources from ?inst/doc? to ?vignettes?.
>>>

The vignette sources were in ?vignettes? when DAAGviz_1.0.3.tar.gz was created.  There was nothing in the ?inst/doc? directory.


If I have in my .Rinstignore file

  inst/doc/.*[.]pdf

then I get:

<<<
* checking package vignettes in ?inst/doc? ... WARNING
Package vignettes without corresponding PDF/HTML:
. . .
>>>

What am I missing?  Can I ignore the "The following files should probably not be installed? message?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From axel.urbiz at gmail.com  Sun Jan 25 19:58:57 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sun, 25 Jan 2015 13:58:57 -0500
Subject: [Rd] Error in help files connection
Message-ID: <CAAyVsXJiiyN+yPjykb=g9_yZSViofjy4uKgxyH6hkjg868NWeg@mail.gmail.com>

Hello,

I'm building a package on Mac OS. The build/check/install goes all ok.
Also, the package gets loaded properly with library(my_package).

However, when I call the help file for a given function in the package --
i.e., "?my_function", I get the following error:

Error in gzfile(file, "rb") : cannot open the connection

I've search for this issue, but did not find anything that could help in my
case.

Thanks,

Axel.

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Jan 26 09:52:12 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Jan 2015 08:52:12 +0000
Subject: [Rd] R CMD check message: "The following files should probably
 not be installed"
In-Reply-To: <986A5055-890F-4E56-91C9-1006ADEB9599@anu.edu.au>
References: <986A5055-890F-4E56-91C9-1006ADEB9599@anu.edu.au>
Message-ID: <54C6003C.4000600@stats.ox.ac.uk>

On 25/01/2015 23:25, John Maindonald wrote:
> I am doing [R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?; Platform: x86_64-apple-darwin10.8.0 (64-bit)]
>
>> R CMD build DAAGviz
>> R CMD check DAAGviz_1.0.3.tar.gz
>
> Without a .Rinstignore file, I get:
>
> <<<
> The following files should probably not be installed:
>    ?figs10.pdf?, ?figs11.pdf?, ?figs12.pdf?, ?figs13.pdf?, ?figs14.pdf?,
>    ?figs5.pdf?, ?figs6.pdf?, ?figs9.pdf?
>
> Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
> or move the vignette sources from ?inst/doc? to ?vignettes?.
>>>>
>
> The vignette sources were in ?vignettes? when DAAGviz_1.0.3.tar.gz was created.  There was nothing in the ?inst/doc? directory.
>
> If I have in my .Rinstignore file
>
>    inst/doc/.*[.]pdf

That filters out more than the files warned about.  I guess you meant

inst/doc/figs.*[.]pdf

But the question has to be: how did the files get copied into inst/doc? 
  Maybe

'When R CMD build builds the vignettes, it copies these and the vignette 
sources from directory vignettes to inst/doc. To install any other files 
from the vignettes directory, include a file vignettes/.install_extras 
which specifies these as Perl-like regular expressions on one or more 
lines. (See the description of the .Rinstignore file for full details.)'

suggests how?

> then I get:
>
> <<<
> * checking package vignettes in ?inst/doc? ... WARNING
> Package vignettes without corresponding PDF/HTML:
> . . .
>>>>
>
> What am I missing?  Can I ignore the "The following files should probably not be installed? message?

Not if you want to submit the package to CRAN.


>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From maechler at lynne.stat.math.ethz.ch  Mon Jan 26 12:36:27 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Jan 2015 12:36:27 +0100
Subject: [Rd] speedbump in library
In-Reply-To: <CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
Message-ID: <21702.9915.512807.709742@stat.math.ethz.ch>

>>>>> Winston Chang <winstonchang1 at gmail.com>
>>>>>     on Fri, 23 Jan 2015 10:15:53 -0600 writes:

    > I think you can simplify a little by replacing this:

    > 	pkg %in% loadedNamespaces()
    > with this:
    >   .getNamespace(pkg)

almost:  It would be 

      !is.null(.getNamespace(pkg))

    > Whereas getNamespace(pkg) will load the package if it's not already
    > loaded, calling .getNamespace(pkg) (note the leading dot) won't load
    > the package.

indeed.  
And you, Winston, are right that this new code snippet would be
an order of magnitude faster :

##-----------------------------------------------------------------------------

f1 <- function(pkg) pkg %in% loadedNamespaces()
f2 <- function(pkg) !is.null(.getNamespace(pkg))

require(microbenchmark)

pkg <- "foo"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
## Unit: microseconds
##           expr    min      lq     mean  median      uq    max neval cld
##  r1 <- f1(pkg) 38.516 40.9790 42.35037 41.7245 42.4060 82.922   100   b
##  r2 <- f2(pkg)  1.331  1.8285  2.13874  2.0855  2.3365  7.252   100  a
## [1] FALSE

pkg <- "stats"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
## Unit: microseconds
##           expr    min      lq     mean  median      uq    max neval cld
##  r1 <- f1(pkg) 29.955 31.2575 32.27748 31.6035 32.1215 62.428   100   b
##  r2 <- f2(pkg)  1.067  1.4315  1.71437  1.6335  1.8460  9.169   100  a
## [1] TRUE
loadNamespace("Matrix")
## <environment: namespace:Matrix>
pkg <- "Matrix"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
## Unit: microseconds
##           expr    min      lq     mean  median      uq    max neval cld
##  r1 <- f1(pkg) 32.721 33.5205 35.17450 33.9505 34.6050 65.373   100   b
##  r2 <- f2(pkg)  1.010  1.3750  1.93671  1.5615  1.7795 12.128   100  a
## [1] TRUE

##-----------------------------------------------------------------------------

Hence, indeed,
       		!is.null(.getNamespace(pkg))

seems equivalent to
      		 pkg %in% loadedNamespaces()

--- when 'pkg' is of length 1  (!!!)

but is 20 times faster....  and we have
11  occurrences  of   ' <...> %in%  loadedNamespaces() '
in the "base packages" in the R (devel) sources,
 3 in base,  2 in methods,  3 in stats, 2 in tools, 1 in utils..
 
On the other hand,     
       	     	 pkg %in% loadedNamespaces()

is extremely nicely readable code, whereas
		!is.null(.getNamespace(pkg))
is pretty much the contrary.
.. and well readable code is so much easier to maintain etc,
such that in many cases, code optimization with the cost of
code obfuscation is *not* desirable.

Of course we could yet again use a few lines of C and R code to
provide a new R lowlevel function, say

	      is.loadedNamespace()

which would be even faster than   !is.null(.getNamespace(pkg)) 

...
...

but do we have *any* evidence that this would noticably speedup
any higher level function such as library() ?


Thank you, again, Winston; you've opened an interesting topic!

--
Martin Maechler, ETH Zurich


From maechler at lynne.stat.math.ethz.ch  Mon Jan 26 12:55:18 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Jan 2015 12:55:18 +0100
Subject: [Rd] Proper way to define cbind, rbind for s4 classes in package
In-Reply-To: <CAOQ5NyeRprfmr+RyUxnoz3JCy9jsz+hasWZN0A=KBrRbdkykRw@mail.gmail.com>
References: <54C35EB5.3060402@gmail.com>
	<CAOQ5NyeRprfmr+RyUxnoz3JCy9jsz+hasWZN0A=KBrRbdkykRw@mail.gmail.com>
Message-ID: <21702.11046.319866.816795@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Sat, 24 Jan 2015 06:39:37 -0800 writes:

    > On Sat, Jan 24, 2015 at 12:58 AM, Mario Annau
    > <mario.annau at gmail.com> wrote:
    >> Hi all, this question has already been posted on
    >> stackoverflow, however without success, see also
    >> http://stackoverflow.com/questions/27886535/proper-way-to-use-cbind-rbind-with-s4-classes-in-package.
    >> 
    >> I have written a package using S4 classes and would like
    >> to use the functions rbind, cbind with these defined
    >> classes.
    >> 
    >> Since it does not seem to be possible to define rbind and
    >> cbind directly as S4 methods (see ?cBind) I defined
    >> rbind2 and cbind2 instead:
    >> 

    > This needs some clarification. It certainly is possible to
    > define cbind and rbind methods. The BiocGenerics package
    > defines generics for those and many methods are defined by
    > e.g. S4Vectors, IRanges, etc.  The issue is that dispatch
    > on "..." is singular, i.e., you can only specify one class
    > that all args in "..." must share (potentially through
    > inheritance).

    > Thus, trying to combine objects from a
    > different hierarchy (or non-S4 objects) will not
    > work. 

Yes, indeed, that's the drawback

I've been there almost surely before everyone else, with the
Matrix package...
and I have been the author of  
    cbind2(), rbind2(), and of course, of  cBind(), and rBind().

At the time when I introduced these, the above possibility of
writing S4 methods for  '...'  where not yet part of R.

    > This has not been a huge problem for us in
    > practice. For example, we have a DataFrame object that
    > mimics data.frame. To cbind a data.frame with a DataFrame,
    > the user can just call the DataFrame()
    > constructor. rbind() between different data structures is
    > much less common.

well... yes and no.  Think of using the Matrix package, maybe
with another package that defines another generalized matrix class...
It would be nice if things worked automatically / perfectly there.

    > The cBind and rBind functions in Matrix (and the r/cbind
    > that get installed by bind_activation, the code is shared)
    > work by recursing, dropping the first argument until two
    > are left, and then combining with r/cbind2(). The Biobase
    > package uses a similar strategy to mimic c() via its
    > non-standard combine() generic. The nice thing about the
    > combine() approach is the user entry point and the generic
    > are the same, instead of having methods on rbind2() and
    > the user calling rBind().

    > I would argue that bind_activation(TRUE) should be
    > discouraged, 

Yes, you are right Michael; it should be discouraged at least to
be run in a *package*.
One could think of its use by an explicit user call.

    > because it replaces the native rbind and
    > cbind with recursive variants that are going to cause
    > problems, performance and otherwise. This is why it is
    > hidden. Perhaps a reasonable compromise would be for the
    > native cbind and rbind to check whether any arguments are
    > S4 and if so, resort to recursion. Recursion does seem to
    > be a clean way to implement "type promotion", i.e., to
    > answer the question "which type should the result be when
    > faced with mixed-type args?".

Exactly.  That has been my idea at the time ..
((yes, I'm also the author of the  bind_activation() 
  "(mis)functionality".))

    > Hopefully others have better ideas.

that would be great.

And even if not, it would be great if we could implement your
idea
    > Perhaps a reasonable compromise would be for the
    > native cbind and rbind to check whether any arguments are
    > S4 and if so, resort to recursion.

without a noticable performance penalty in the case of no S4
arguments.

Martin


    > Michael

    >> setMethod("rbind2", signature(x="ClassA", y = "ANY"),
    >> function(x, y) { # Do stuff ...  })
    >> 
    >> setMethod("cbind2", signature(x="ClassA", y = "ANY"),
    >> function(x, y) { # Do stuff ...  })
    >> 
    >> >From ?cbind2 I learned that these functions need to be
    >> activated using methods:::bind_activation to replace
    >> rbind and cbind from base.
    >> 
    >> I included the call in the package file R/zzz.R using the
    >> .onLoad function:
    >> 
    >> .onLoad <- function(...) { # Bind activation of cbind(2)
    >> and rbind(2) for S4 classes
    >> methods:::bind_activation(TRUE) } This works as
    >> expected. However, running R CMD check I am now getting
    >> the following NOTE since I am using an unexported
    >> function in methods:
    >> 
    >> * checking dependencies in R code ... NOTE Unexported
    >> object imported by a ':::' call:
    >> 'methods:::bind_activation' See the note in ?`:::` about
    >> the use of this operator.  How can I get rid of the NOTE
    >> and what is the proper way to define the methods cbind
    >> and rbind for S4 classes in a package?
    >> 
    >> Best, mario
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Mon Jan 26 14:12:55 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Mon, 26 Jan 2015 05:12:55 -0800
Subject: [Rd] speedbump in library
In-Reply-To: <21702.9915.512807.709742@stat.math.ethz.ch>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
	<21702.9915.512807.709742@stat.math.ethz.ch>
Message-ID: <CAOQ5Nyf9fjO0czbDc1U-AtBqkp1N2CtU-AaeMKxA0eqf2N2YKA@mail.gmail.com>

A isNamespaceLoaded() function would be a useful thing to have in
general if we are interested in readable code. An efficient
implementation would be just a bonus.



On Mon, Jan 26, 2015 at 3:36 AM, Martin Maechler
<maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>> Winston Chang <winstonchang1 at gmail.com>
>>>>>>     on Fri, 23 Jan 2015 10:15:53 -0600 writes:
>
>     > I think you can simplify a little by replacing this:
>
>     >   pkg %in% loadedNamespaces()
>     > with this:
>     >   .getNamespace(pkg)
>
> almost:  It would be
>
>       !is.null(.getNamespace(pkg))
>
>     > Whereas getNamespace(pkg) will load the package if it's not already
>     > loaded, calling .getNamespace(pkg) (note the leading dot) won't load
>     > the package.
>
> indeed.
> And you, Winston, are right that this new code snippet would be
> an order of magnitude faster :
>
> ##-----------------------------------------------------------------------------
>
> f1 <- function(pkg) pkg %in% loadedNamespaces()
> f2 <- function(pkg) !is.null(.getNamespace(pkg))
>
> require(microbenchmark)
>
> pkg <- "foo"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
> ## Unit: microseconds
> ##           expr    min      lq     mean  median      uq    max neval cld
> ##  r1 <- f1(pkg) 38.516 40.9790 42.35037 41.7245 42.4060 82.922   100   b
> ##  r2 <- f2(pkg)  1.331  1.8285  2.13874  2.0855  2.3365  7.252   100  a
> ## [1] FALSE
>
> pkg <- "stats"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
> ## Unit: microseconds
> ##           expr    min      lq     mean  median      uq    max neval cld
> ##  r1 <- f1(pkg) 29.955 31.2575 32.27748 31.6035 32.1215 62.428   100   b
> ##  r2 <- f2(pkg)  1.067  1.4315  1.71437  1.6335  1.8460  9.169   100  a
> ## [1] TRUE
> loadNamespace("Matrix")
> ## <environment: namespace:Matrix>
> pkg <- "Matrix"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg))); stopifnot(identical(r1,r2)); r1
> ## Unit: microseconds
> ##           expr    min      lq     mean  median      uq    max neval cld
> ##  r1 <- f1(pkg) 32.721 33.5205 35.17450 33.9505 34.6050 65.373   100   b
> ##  r2 <- f2(pkg)  1.010  1.3750  1.93671  1.5615  1.7795 12.128   100  a
> ## [1] TRUE
>
> ##-----------------------------------------------------------------------------
>
> Hence, indeed,
>                 !is.null(.getNamespace(pkg))
>
> seems equivalent to
>                  pkg %in% loadedNamespaces()
>
> --- when 'pkg' is of length 1  (!!!)
>
> but is 20 times faster....  and we have
> 11  occurrences  of   ' <...> %in%  loadedNamespaces() '
> in the "base packages" in the R (devel) sources,
>  3 in base,  2 in methods,  3 in stats, 2 in tools, 1 in utils..
>
> On the other hand,
>                  pkg %in% loadedNamespaces()
>
> is extremely nicely readable code, whereas
>                 !is.null(.getNamespace(pkg))
> is pretty much the contrary.
> .. and well readable code is so much easier to maintain etc,
> such that in many cases, code optimization with the cost of
> code obfuscation is *not* desirable.
>
> Of course we could yet again use a few lines of C and R code to
> provide a new R lowlevel function, say
>
>               is.loadedNamespace()
>
> which would be even faster than   !is.null(.getNamespace(pkg))
>
> ...
> ...
>
> but do we have *any* evidence that this would noticably speedup
> any higher level function such as library() ?
>
>
> Thank you, again, Winston; you've opened an interesting topic!
>
> --
> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Mon Jan 26 14:51:39 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Jan 2015 14:51:39 +0100
Subject: [Rd] speedbump in library
In-Reply-To: <CAOQ5Nyf9fjO0czbDc1U-AtBqkp1N2CtU-AaeMKxA0eqf2N2YKA@mail.gmail.com>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
	<21702.9915.512807.709742@stat.math.ethz.ch>
	<CAOQ5Nyf9fjO0czbDc1U-AtBqkp1N2CtU-AaeMKxA0eqf2N2YKA@mail.gmail.com>
Message-ID: <21702.18027.398197.522793@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Mon, 26 Jan 2015 05:12:55 -0800 writes:

    > A isNamespaceLoaded() function would be a useful thing to
    > have in general if we are interested in readable code. An
    > efficient implementation would be just a bonus.

Good point (readability), and thank you for the support!

Note one slight drawback with your name (which is clearly
better than mine first proposal):
We'd have the three functions named

     isBaseNamespace(ns)
     isNamespace(ns)
     isNamespaceLoaded(name)

where  'name' is really different from 'ns', namely :

  > isNamespace("stats")
  [1] FALSE
  > isNamespace(asNamespace("stats"))
  [1] TRUE

but

  > isNamespaceLoaded("stats")
  [1] TRUE

  > isNamespaceLoaded(asNamespace("stats"))
  Error in as.vector(x, "symbol") : 
    cannot coerce type 'environment' to vector of type 'symbol'
  > 

So, from my (non native English view) a slightly more suggestive
function name may be 

   isLoadedNamespace(name)

or using Luke's original language, still present in the C code,

   isRegisteredNamespace(name)

but I would prefer the former,  isLoadedN..S..()

Martin

    > On Mon, Jan 26, 2015 at 3:36 AM, Martin Maechler
    > <maechler at lynne.stat.math.ethz.ch> wrote:
    >>>>>>> Winston Chang <winstonchang1 at gmail.com> on Fri, 23
    >>>>>>> Jan 2015 10:15:53 -0600 writes:
    >> 
    >> > I think you can simplify a little by replacing this:
    >> 
    >> > pkg %in% loadedNamespaces() > with this: >
    >> .getNamespace(pkg)
    >> 
    >> almost: It would be
    >> 
    >> !is.null(.getNamespace(pkg))
    >> 
    >> > Whereas getNamespace(pkg) will load the package if it's
    >> not already > loaded, calling .getNamespace(pkg) (note
    >> the leading dot) won't load > the package.
    >> 
    >> indeed.  And you, Winston, are right that this new code
    >> snippet would be an order of magnitude faster :
    >> 
    >> ##-----------------------------------------------------------------------------
    >> 
    >> f1 <- function(pkg) pkg %in% loadedNamespaces() f2 <-
    >> function(pkg) !is.null(.getNamespace(pkg))
    >> 
    >> require(microbenchmark)
    >> 
    >> pkg <- "foo"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <-
    >> f2(pkg))); stopifnot(identical(r1,r2)); r1 ## Unit:
    >> microseconds ## expr min lq mean median uq max neval cld
    >> ## r1 <- f1(pkg) 38.516 40.9790 42.35037 41.7245 42.4060
    >> 82.922 100 b ## r2 <- f2(pkg) 1.331 1.8285 2.13874 2.0855
    >> 2.3365 7.252 100 a ## [1] FALSE
    >> 
    >> pkg <- "stats"; (mbM <- microbenchmark(r1 <- f1(pkg), r2
    >> <- f2(pkg))); stopifnot(identical(r1,r2)); r1 ## Unit:
    >> microseconds ## expr min lq mean median uq max neval cld
    >> ## r1 <- f1(pkg) 29.955 31.2575 32.27748 31.6035 32.1215
    >> 62.428 100 b ## r2 <- f2(pkg) 1.067 1.4315 1.71437 1.6335
    >> 1.8460 9.169 100 a ## [1] TRUE loadNamespace("Matrix") ##
    >> <environment: namespace:Matrix> pkg <- "Matrix"; (mbM <-
    >> microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg)));
    >> stopifnot(identical(r1,r2)); r1 ## Unit: microseconds ##
    >> expr min lq mean median uq max neval cld ## r1 <- f1(pkg)
    >> 32.721 33.5205 35.17450 33.9505 34.6050 65.373 100 b ##
    >> r2 <- f2(pkg) 1.010 1.3750 1.93671 1.5615 1.7795 12.128
    >> 100 a ## [1] TRUE
    >> 
    >> ##-----------------------------------------------------------------------------
    >> 
    >> Hence, indeed, !is.null(.getNamespace(pkg))
    >> 
    >> seems equivalent to pkg %in% loadedNamespaces()
    >> 
    >> --- when 'pkg' is of length 1 (!!!)
    >> 
    >> but is 20 times faster....  and we have 11 occurrences of
    >> ' <...> %in% loadedNamespaces() ' in the "base packages"
    >> in the R (devel) sources, 3 in base, 2 in methods, 3 in
    >> stats, 2 in tools, 1 in utils..
    >> 
    >> On the other hand, pkg %in% loadedNamespaces()
    >> 
    >> is extremely nicely readable code, whereas
    >> !is.null(.getNamespace(pkg)) is pretty much the contrary.
    >> .. and well readable code is so much easier to maintain
    >> etc, such that in many cases, code optimization with the
    >> cost of code obfuscation is *not* desirable.
    >> 
    >> Of course we could yet again use a few lines of C and R
    >> code to provide a new R lowlevel function, say
    >> 
    >> is.loadedNamespace()
    >> 
    >> which would be even faster than
    >> !is.null(.getNamespace(pkg))
    >> 
    >> ...  ...
    >> 
    >> but do we have *any* evidence that this would noticably
    >> speedup any higher level function such as library() ?
    >> 
    >> 
    >> Thank you, again, Winston; you've opened an interesting
    >> topic!
    >> 
    >> --
    >> Martin Maechler, ETH Zurich
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Mon Jan 26 15:11:50 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Mon, 26 Jan 2015 06:11:50 -0800
Subject: [Rd] speedbump in library
In-Reply-To: <21702.18027.398197.522793@stat.math.ethz.ch>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
	<21702.9915.512807.709742@stat.math.ethz.ch>
	<CAOQ5Nyf9fjO0czbDc1U-AtBqkp1N2CtU-AaeMKxA0eqf2N2YKA@mail.gmail.com>
	<21702.18027.398197.522793@stat.math.ethz.ch>
Message-ID: <CAOQ5NycdLvwfbrfMj2kaZp_ir33M9sGUecpYgZe-aoALdnbe9g@mail.gmail.com>

isLoadedNamespace() sounds fine to me..

Thanks for addressing this,
Michael

On Mon, Jan 26, 2015 at 5:51 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:

> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Mon, 26 Jan 2015 05:12:55 -0800 writes:
>
>     > A isNamespaceLoaded() function would be a useful thing to
>     > have in general if we are interested in readable code. An
>     > efficient implementation would be just a bonus.
>
> Good point (readability), and thank you for the support!
>
> Note one slight drawback with your name (which is clearly
> better than mine first proposal):
> We'd have the three functions named
>
>      isBaseNamespace(ns)
>      isNamespace(ns)
>      isNamespaceLoaded(name)
>
> where  'name' is really different from 'ns', namely :
>
>   > isNamespace("stats")
>   [1] FALSE
>   > isNamespace(asNamespace("stats"))
>   [1] TRUE
>
> but
>
>   > isNamespaceLoaded("stats")
>   [1] TRUE
>
>   > isNamespaceLoaded(asNamespace("stats"))
>   Error in as.vector(x, "symbol") :
>     cannot coerce type 'environment' to vector of type 'symbol'
>   >
>
> So, from my (non native English view) a slightly more suggestive
> function name may be
>
>    isLoadedNamespace(name)
>
> or using Luke's original language, still present in the C code,
>
>    isRegisteredNamespace(name)
>
> but I would prefer the former,  isLoadedN..S..()
>
> Martin
>
>     > On Mon, Jan 26, 2015 at 3:36 AM, Martin Maechler
>     > <maechler at lynne.stat.math.ethz.ch> wrote:
>     >>>>>>> Winston Chang <winstonchang1 at gmail.com> on Fri, 23
>     >>>>>>> Jan 2015 10:15:53 -0600 writes:
>     >>
>     >> > I think you can simplify a little by replacing this:
>     >>
>     >> > pkg %in% loadedNamespaces() > with this: >
>     >> .getNamespace(pkg)
>     >>
>     >> almost: It would be
>     >>
>     >> !is.null(.getNamespace(pkg))
>     >>
>     >> > Whereas getNamespace(pkg) will load the package if it's
>     >> not already > loaded, calling .getNamespace(pkg) (note
>     >> the leading dot) won't load > the package.
>     >>
>     >> indeed.  And you, Winston, are right that this new code
>     >> snippet would be an order of magnitude faster :
>     >>
>     >>
> ##-----------------------------------------------------------------------------
>     >>
>     >> f1 <- function(pkg) pkg %in% loadedNamespaces() f2 <-
>     >> function(pkg) !is.null(.getNamespace(pkg))
>     >>
>     >> require(microbenchmark)
>     >>
>     >> pkg <- "foo"; (mbM <- microbenchmark(r1 <- f1(pkg), r2 <-
>     >> f2(pkg))); stopifnot(identical(r1,r2)); r1 ## Unit:
>     >> microseconds ## expr min lq mean median uq max neval cld
>     >> ## r1 <- f1(pkg) 38.516 40.9790 42.35037 41.7245 42.4060
>     >> 82.922 100 b ## r2 <- f2(pkg) 1.331 1.8285 2.13874 2.0855
>     >> 2.3365 7.252 100 a ## [1] FALSE
>     >>
>     >> pkg <- "stats"; (mbM <- microbenchmark(r1 <- f1(pkg), r2
>     >> <- f2(pkg))); stopifnot(identical(r1,r2)); r1 ## Unit:
>     >> microseconds ## expr min lq mean median uq max neval cld
>     >> ## r1 <- f1(pkg) 29.955 31.2575 32.27748 31.6035 32.1215
>     >> 62.428 100 b ## r2 <- f2(pkg) 1.067 1.4315 1.71437 1.6335
>     >> 1.8460 9.169 100 a ## [1] TRUE loadNamespace("Matrix") ##
>     >> <environment: namespace:Matrix> pkg <- "Matrix"; (mbM <-
>     >> microbenchmark(r1 <- f1(pkg), r2 <- f2(pkg)));
>     >> stopifnot(identical(r1,r2)); r1 ## Unit: microseconds ##
>     >> expr min lq mean median uq max neval cld ## r1 <- f1(pkg)
>     >> 32.721 33.5205 35.17450 33.9505 34.6050 65.373 100 b ##
>     >> r2 <- f2(pkg) 1.010 1.3750 1.93671 1.5615 1.7795 12.128
>     >> 100 a ## [1] TRUE
>     >>
>     >>
> ##-----------------------------------------------------------------------------
>     >>
>     >> Hence, indeed, !is.null(.getNamespace(pkg))
>     >>
>     >> seems equivalent to pkg %in% loadedNamespaces()
>     >>
>     >> --- when 'pkg' is of length 1 (!!!)
>     >>
>     >> but is 20 times faster....  and we have 11 occurrences of
>     >> ' <...> %in% loadedNamespaces() ' in the "base packages"
>     >> in the R (devel) sources, 3 in base, 2 in methods, 3 in
>     >> stats, 2 in tools, 1 in utils..
>     >>
>     >> On the other hand, pkg %in% loadedNamespaces()
>     >>
>     >> is extremely nicely readable code, whereas
>     >> !is.null(.getNamespace(pkg)) is pretty much the contrary.
>     >> .. and well readable code is so much easier to maintain
>     >> etc, such that in many cases, code optimization with the
>     >> cost of code obfuscation is *not* desirable.
>     >>
>     >> Of course we could yet again use a few lines of C and R
>     >> code to provide a new R lowlevel function, say
>     >>
>     >> is.loadedNamespace()
>     >>
>     >> which would be even faster than
>     >> !is.null(.getNamespace(pkg))
>     >>
>     >> ...  ...
>     >>
>     >> but do we have *any* evidence that this would noticably
>     >> speedup any higher level function such as library() ?
>     >>
>     >>
>     >> Thank you, again, Winston; you've opened an interesting
>     >> topic!
>     >>
>     >> --
>     >> Martin Maechler, ETH Zurich
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From konrad.rudolph+r-devel at gmail.com  Mon Jan 26 15:41:54 2015
From: konrad.rudolph+r-devel at gmail.com (Konrad Rudolph)
Date: Mon, 26 Jan 2015 14:41:54 +0000
Subject: [Rd] Is the tcltk failure in affylmGUI related to R bug 15957
In-Reply-To: <718649604.114432406.1421554635376.JavaMail.root@wehi.edu.au>
References: <54B603B0.9090607@wehi.edu.au>
	<9A2846D1-D6AF-4FC7-ABCC-D12270693C0F@gmail.com>
	<718649604.114432406.1421554635376.JavaMail.root@wehi.edu.au>
Message-ID: <CAM2gKPazO7T0Svz4efpYJ=E01iNZMW5K79YLh9ZnTAd3XNv=rw@mail.gmail.com>

Just as an FYI, I suspect the sudden break is connected to a bug
report I filed some time ago [1], and a subsequent fix by Duncan. Long
story short, the previous behaviour of tcltk was actually buggy. The
fix changed this behaviour to what Peter has explained, with the
unintended consequence of breaking some code.

I believe that Duncan?s fix actually does ?the right thing?. But I
apologise for the inconvenience this caused.

[1] https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15970

(PS: apologies for sending this again, Keith; I just realised I hadn?t
sent it to the list.)


From maechler at lynne.stat.math.ethz.ch  Mon Jan 26 18:29:24 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Jan 2015 18:29:24 +0100
Subject: [Rd] speedbump in library
In-Reply-To: <CAOQ5NycdLvwfbrfMj2kaZp_ir33M9sGUecpYgZe-aoALdnbe9g@mail.gmail.com>
References: <CAGh0NYoAgB-ydT2j0eynAcRMefmL6C3m81dD-a6ZfDmN3kO+tw@mail.gmail.com>
	<CAFOpNVFT3hXcfbDk2fPV2ZyH=NonfZ-Nys05O4E1qWH_kJ8XAA@mail.gmail.com>
	<21702.9915.512807.709742@stat.math.ethz.ch>
	<CAOQ5Nyf9fjO0czbDc1U-AtBqkp1N2CtU-AaeMKxA0eqf2N2YKA@mail.gmail.com>
	<21702.18027.398197.522793@stat.math.ethz.ch>
	<CAOQ5NycdLvwfbrfMj2kaZp_ir33M9sGUecpYgZe-aoALdnbe9g@mail.gmail.com>
Message-ID: <21702.31092.629322.132317@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Mon, 26 Jan 2015 06:11:50 -0800 writes:

    > isLoadedNamespace() sounds fine to me..
    > Thanks for addressing this,
    > Michael

Ok, this is now in R-devel :

------------------------------------------------------------------------
r67624 | maechler | 2015-01-26 18:26:00 +0100 (Mon, 26 Jan 2015) | 1 line
Changed paths:
   M doc/NEWS.Rd
   M src/library/base/R/attach.R
   M src/library/base/R/library.R
   M src/library/base/R/namespace.R
   M src/library/base/man/ns-load.Rd
   M src/library/methods/R/RMethodUtils.R
   M src/library/methods/R/refClass.R
   M src/library/tools/R/QC.R
   M src/library/tools/R/install.R
   M src/library/utils/R/indices.R
   M src/main/envir.c
   M src/main/names.c

new function isLoadedNamespace(name) and use wherever "obvious" in our code
------------------------------------------------------------------------


    > On Mon, Jan 26, 2015 at 5:51 AM, Martin Maechler <
    > maechler at lynne.stat.math.ethz.ch> wrote:

    >> >>>>> Michael Lawrence <lawrence.michael at gene.com>
    >> >>>>>     on Mon, 26 Jan 2015 05:12:55 -0800 writes:
    >> 
    >> > A isNamespaceLoaded() function would be a useful thing to
    >> > have in general if we are interested in readable code. An
    >> > efficient implementation would be just a bonus.
    >> 
    >> Good point (readability), and thank you for the support!
    >> 
    >> Note one slight drawback with your name (which is clearly
    >> better than mine first proposal):
    >> We'd have the three functions named
    >> 
    >> isBaseNamespace(ns)
    >> isNamespace(ns)
    >> isNamespaceLoaded(name)
    >> 
    >> where  'name' is really different from 'ns', namely :
    >> 
    >> > isNamespace("stats")
    >> [1] FALSE
    >> > isNamespace(asNamespace("stats"))
    >> [1] TRUE
    >> 
    >> but
    >> 
    >> > isNamespaceLoaded("stats")
    >> [1] TRUE
    >> 
    >> > isNamespaceLoaded(asNamespace("stats"))
    >> Error in as.vector(x, "symbol") :
    >> cannot coerce type 'environment' to vector of type 'symbol'
    >> >
    >> 
    >> So, from my (non native English view) a slightly more suggestive
    >> function name may be
    >> 
    >> isLoadedNamespace(name)
    >> 
    >> or using Luke's original language, still present in the C code,
    >> 
    >> isRegisteredNamespace(name)
    >> 
    >> but I would prefer the former,  isLoadedN..S..()
    >> 
    >> Martin
    >> 
    >> > On Mon, Jan 26, 2015 at 3:36 AM, Martin Maechler
    >> > <maechler at lynne.stat.math.ethz.ch> wrote:
    >> >>>>>>> Winston Chang <winstonchang1 at gmail.com> on Fri, 23
    >> >>>>>>> Jan 2015 10:15:53 -0600 writes:

    .............................
    .............................

    >> >> Hence, indeed, !is.null(.getNamespace(pkg))
    >> >>
    >> >> seems equivalent to pkg %in% loadedNamespaces()
    >> >>
    >> >> --- when 'pkg' is of length 1 (!!!)
    >> >>
    >> >> but is 20 times faster....  and we have 11 occurrences of
    >> >> ' <...> %in% loadedNamespaces() ' in the "base packages"
    >> >> in the R (devel) sources, 3 in base, 2 in methods, 3 in
    >> >> stats, 2 in tools, 1 in utils..
    >> >>
    >> >> On the other hand, pkg %in% loadedNamespaces()
    >> >>
    >> >> is extremely nicely readable code, whereas
    >> >> !is.null(.getNamespace(pkg)) is pretty much the contrary.
    >> >> .. and well readable code is so much easier to maintain
    >> >> etc, such that in many cases, code optimization with the
    >> >> cost of code obfuscation is *not* desirable.
    >> >>
    >> >> Of course we could yet again use a few lines of C and R
    >> >> code to provide a new R lowlevel function, say
    >> >>
    >> >> is.loadedNamespace()
    >> >>
    >> >> which would be even faster than
    >> >> !is.null(.getNamespace(pkg))
    >> >>
    >> >> ...  ...
    >> >>
    >> >> but do we have *any* evidence that this would noticably
    >> >> speedup any higher level function such as library() ?
    >> >>
    >> >>
    >> >> Thank you, again, Winston; you've opened an interesting
    >> >> topic!
    >> >>
    >> >> --
    >> >> Martin Maechler, ETH Zurich


From jfox at mcmaster.ca  Mon Jan 26 18:54:34 2015
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 26 Jan 2015 12:54:34 -0500
Subject: [Rd] problem with update.packages() in R-Devel (3.2.0) on Windows
Message-ID: <002401d03991$25a38920$70ea9b60$@mcmaster.ca>

Dear all,

I've noticed the following problem for the past several days:

---------------- snip ----------------
> update.packages(ask=FALSE)

. . .

trying URL 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL
'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package 'zoo' failed

---------------- snip ----------------

Apparently, the subdirectory for the version number (/3.2) is missing from
the URL. OTOH, install.packages() works fine:

---------------- snip ----------------

> install.packages("zoo")
trying URL
'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
Content type 'application/zip' length 878614 bytes (858 KB)
opened URL
downloaded 858 KB

package 'zoo' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\John Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages

---------------- snip ----------------

Session info:

---------------- snip ----------------

> sessionInfo()
R Under development (unstable) (2015-01-25 r67615)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
[5] LC_TIME=English_Canada.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.2.0

---------------- snip ----------------

Best,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/




---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From balbi at kernel.org  Mon Jan 26 19:41:08 2015
From: balbi at kernel.org (Felipe Balbi)
Date: Mon, 26 Jan 2015 12:41:08 -0600
Subject: [Rd] [PATCH v2] Makefile: add support for git svn clones
Message-ID: <1422297668-6552-1-git-send-email-balbi@kernel.org>

git has an interface for cloning SVN repositories into git which
some users might decide to use. For those users' surprise, the
repository will always fail to build on svnonly target and it will
exit early.

The problem is simple enough to fix by just checking if a .git
directory exists in top_builddir and, if so, call git svn info insstead
of svn info.

Note, however, that this only supports Linux (and possibly Mac) users,
as I have no means of writing/testing an equivalent patch for the
Windows Makefiles.

Signed-off-by: Felipe Balbi <balbi at kernel.org>
---

Due to lack of a Windows system, this has only been tested on my linux
box, if someone could give this a whirl on windows and Mac OS X, I'd be
really glad.

cheers

 Makefile.in              | 5 ++++-
 src/include/Makefile.win | 7 +++++--
 2 files changed, 9 insertions(+), 3 deletions(-)

diff --git a/Makefile.in b/Makefile.in
index 44b0a3b4b99f..10415abd442b 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -9,6 +9,9 @@ top_builddir = .
 
 include $(top_builddir)/Makeconf
 
+GIT := `if [ -d "$(top_builddir)/.git" ]; then \
+	echo "git"; fi`
+
 distdir = $(PACKAGE)-$(VERSION)
 INSTFILES = COPYING
 NON_SVN_INSTFILES = SVN-REVISION
@@ -104,7 +107,7 @@ svnonly:
 	@if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
 	  (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
 	  touch non-tarball ; \
-	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
+	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \
 	    | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
 	    | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
 	  if test "`cat SVN-REVISION-tmp`" = "Revision: -99"; then \
diff --git a/src/include/Makefile.win b/src/include/Makefile.win
index 28361ef9cfa3..d81941f80f4f 100644
--- a/src/include/Makefile.win
+++ b/src/include/Makefile.win
@@ -2,6 +2,9 @@
 include ../gnuwin32/MkRules
 R_HOME = ../..
 
+GIT := `if [ -d "$(top_builddir)/.git" ]; then \
+	echo "git"; fi`
+
 VER = $(shell sed -e 's/\([^ ]*\).*/\1/' ../../VERSION)
 
 ## keep these in step with ./Makefile.in
@@ -67,14 +70,14 @@ ifdef USE_SVNVERSION
 	@LC_ALL=C svnversion ../.. | sed -n 's/^/Revision: /p' > svn-tmp || rm -f svn-tmp
 	@grep -v exported svn-tmp > /dev/null || rm -f svn-tmp
 else
-	@(cd ../..; LC_ALL=C svn info || echo "Revision: unknown") 2> /dev/null \
+	@(cd ../..; LC_ALL=C $(GIT) svn info || echo "Revision: unknown") 2> /dev/null \
 	  | sed -n '/^Revision/p' > svn-tmp
 	@if grep unknown svn-tmp > /dev/null ; then \
 	  rm svn-tmp; \
 	fi
 endif
 	@if test -f svn-tmp ; then \
-	  (cd ../..; LC_ALL=C TZ=GMT svn info || echo "Last Changed Date: unknown") 2> /dev/null \
+	  (cd ../..; LC_ALL=C TZ=GMT $(GIT) svn info || echo "Last Changed Date: unknown") 2> /dev/null \
 	    | sed -n '/^Last Changed Date:/p' | sed 's/[0-9][0-9]:.*//' \
 	    >> svn-tmp ; \
 	else \
-- 
2.3.0-rc1


From hb at biostat.ucsf.edu  Mon Jan 26 19:53:37 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 26 Jan 2015 10:53:37 -0800
Subject: [Rd] Inspect a "delayed" assigned whose value throws an error?
Message-ID: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>

Hi, I got an interesting programming challenge:

How do you inspect an object which is assigned via delayedAssign() and
that throws an error as soon as it is "touched" (=the value is
evaluated)?  Is it possible?


MINIMAL EXAMPLE:

$ R --vanilla
> delayedAssign("foo", stop("Hey!"))

(If you find this minimal example silly/obvious, please skip down to
the real example at the end)

> foo
Error: Hey!

> str(foo)
Error in str(foo) : Hey!
In addition: Warning message:
In str(foo) : restarting interrupted promise evaluation

> mode(foo)
Error in mode(foo) : Hey!
In addition: Warning message:
In mode(foo) : restarting interrupted promise evaluation

> .Internal(inspect(foo))
Error: Hey!
In addition: Warning message:
restarting interrupted promise evaluation

> traceback()
1: stop("Hey!")

Is there anyway I can inspect this object using the R API without
evaluating the value in the delayed assignment?  Is it possible to
test if this is a delayed assigned or not?


BACKGROUND:
The background to this is where I have a function in the R.oo package
that scans namespaces for functions with a certain class attribute.
For this I use is.function() and inherits() to inspect each object.
An aroma.affymetrix user reported on a problem that boiled down to the
following:

# source("http://bioconductor.org/biocLite.R"); biocLite("hgu133a.db")
> library("hgu133a.db")
> is.function(hgu133aPFAM)
Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
  or PROSITE accessions.
> .Internal(inspect(hgu133aPFAM))

> traceback()
3: stop(paste(msg, collapse = ""), call. = FALSE, domain = NA)
2: .Defunct(msg = msg)
1: (function ()
   {
       if (grepl("PFAM", x)) {
           bimapName <- paste0(prefix, "PFAM")
       }
       else {
           bimapName <- paste0(prefix, "PROSITE")
       }
       x <- dc[[bimapName]]
       msg = wmsg(paste0(bimapName, " is defunct. ", "Please use select() if you
 need access to PFAM or PROSITE accessions. \n"))
       if (interactive()) {
           .Defunct(msg = msg)
       }
   })()

My immediate solution is to perform those tests using tryCatch(), but
this is interesting, because this function is such that the error is
only thrown in interactive() sessions, i.e. the following works:

$ Rscript -e "hgu133a.db::hgu133aPFAM"
[...]
NULL

This is probably also why none of my aroma.affymetrix system tests
caught this.  Without tracing the source code behind, which seems
quite nested, the above is why I believe the assignment is "delayed";
traceback() shows a body source code, the object evaluates to
different things depending on interactive().

/Henrik


From hb at biostat.ucsf.edu  Mon Jan 26 20:12:39 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 26 Jan 2015 11:12:39 -0800
Subject: [Rd] problem with update.packages() in R-Devel (3.2.0) on
	Windows
In-Reply-To: <002401d03991$25a38920$70ea9b60$@mcmaster.ca>
References: <002401d03991$25a38920$70ea9b60$@mcmaster.ca>
Message-ID: <CAFDcVCRoYqWXqAL9Oqo0f8Aow0z9_0wNTo7LsTE=Cx6ZvFL5iA@mail.gmail.com>

We are several seeing this one. It's a known bug, cf.
https://stat.ethz.ch/pipermail/r-devel/2015-January/070513.html

Henrik

On Mon, Jan 26, 2015 at 9:54 AM, John Fox <jfox at mcmaster.ca> wrote:
> Dear all,
>
> I've noticed the following problem for the past several days:
>
> ---------------- snip ----------------
>> update.packages(ask=FALSE)
>
> . . .
>
> trying URL 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> In addition: Warning message:
> In download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open: HTTP status was '404 Not Found'
> Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
>   download of package 'zoo' failed
>
> ---------------- snip ----------------
>
> Apparently, the subdirectory for the version number (/3.2) is missing from
> the URL. OTOH, install.packages() works fine:
>
> ---------------- snip ----------------
>
>> install.packages("zoo")
> trying URL
> 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
> Content type 'application/zip' length 878614 bytes (858 KB)
> opened URL
> downloaded 858 KB
>
> package 'zoo' successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>         C:\Users\John Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages
>
> ---------------- snip ----------------
>
> Session info:
>
> ---------------- snip ----------------
>
>> sessionInfo()
> R Under development (unstable) (2015-01-25 r67615)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.0
>
> ---------------- snip ----------------
>
> Best,
>  John
>
> -------------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
>
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> http://www.avast.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fredhutch.org  Mon Jan 26 20:17:37 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 26 Jan 2015 11:17:37 -0800 (PST)
Subject: [Rd] problem with update.packages() in R-Devel (3.2.0)
	on	Windows
In-Reply-To: <CAFDcVCRoYqWXqAL9Oqo0f8Aow0z9_0wNTo7LsTE=Cx6ZvFL5iA@mail.gmail.com>
Message-ID: <4943441.3229570.1422299857541.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> To: "John Fox" <jfox at mcmaster.ca>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Monday, January 26, 2015 11:12:39 AM
> Subject: Re: [Rd] problem with update.packages() in R-Devel (3.2.0) on	Windows
> 
> We are several seeing this one. It's a known bug, cf.
> https://stat.ethz.ch/pipermail/r-devel/2015-January/070513.html
> 

See also 
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16172

> Henrik
> 
> On Mon, Jan 26, 2015 at 9:54 AM, John Fox <jfox at mcmaster.ca> wrote:
> > Dear all,
> >
> > I've noticed the following problem for the past several days:
> >
> > ---------------- snip ----------------
> >> update.packages(ask=FALSE)
> >
> > . . .
> >
> > trying URL
> > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > Error in download.file(url, destfile, method, mode = "wb", ...) :
> >   cannot open URL
> > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > In addition: Warning message:
> > In download.file(url, destfile, method, mode = "wb", ...) :
> >   cannot open: HTTP status was '404 Not Found'
> > Warning in download.packages(pkgs, destdir = tmpd, available =
> > available,  :
> >   download of package 'zoo' failed
> >
> > ---------------- snip ----------------
> >
> > Apparently, the subdirectory for the version number (/3.2) is
> > missing from
> > the URL. 

It's not that the version number is missing, it's that it's looking in the src/contrib section
of the repository (which doesn't have a version number). 

Dan


> > OTOH, install.packages() works fine:
> >
> > ---------------- snip ----------------
> >
> >> install.packages("zoo")
> > trying URL
> > 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
> > Content type 'application/zip' length 878614 bytes (858 KB)
> > opened URL
> > downloaded 858 KB
> >
> > package 'zoo' successfully unpacked and MD5 sums checked
> >
> > The downloaded binary packages are in
> >         C:\Users\John
> >         Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages
> >
> > ---------------- snip ----------------
> >
> > Session info:
> >
> > ---------------- snip ----------------
> >
> >> sessionInfo()
> > R Under development (unstable) (2015-01-25 r67615)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> > [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> > [5] LC_TIME=English_Canada.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> >   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.0
> >
> > ---------------- snip ----------------
> >
> > Best,
> >  John
> >
> > -------------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> >
> >
> >
> > ---
> > This email has been checked for viruses by Avast antivirus
> > software.
> > http://www.avast.com
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Mon Jan 26 21:24:34 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 26 Jan 2015 14:24:34 -0600
Subject: [Rd] Inspect a "delayed" assigned whose value throws an error?
In-Reply-To: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>
References: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>
Message-ID: <CABdHhvFHgnb9mHKQO7L_DQybVHcA7vQqwCuuj7=3cra3_ZXfzg@mail.gmail.com>

If it was any other environment than the global, you could use substitute:

e <- new.env()
delayedAssign("foo", stop("Hey!"), assign.env = e)
substitute(foo, e)

delayedAssign("foo", stop("Hey!"))
substitute(foo)

Hadley

On Mon, Jan 26, 2015 at 12:53 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi, I got an interesting programming challenge:
>
> How do you inspect an object which is assigned via delayedAssign() and
> that throws an error as soon as it is "touched" (=the value is
> evaluated)?  Is it possible?
>
>
> MINIMAL EXAMPLE:
>
> $ R --vanilla
>> delayedAssign("foo", stop("Hey!"))
>
> (If you find this minimal example silly/obvious, please skip down to
> the real example at the end)
>
>> foo
> Error: Hey!
>
>> str(foo)
> Error in str(foo) : Hey!
> In addition: Warning message:
> In str(foo) : restarting interrupted promise evaluation
>
>> mode(foo)
> Error in mode(foo) : Hey!
> In addition: Warning message:
> In mode(foo) : restarting interrupted promise evaluation
>
>> .Internal(inspect(foo))
> Error: Hey!
> In addition: Warning message:
> restarting interrupted promise evaluation
>
>> traceback()
> 1: stop("Hey!")
>
> Is there anyway I can inspect this object using the R API without
> evaluating the value in the delayed assignment?  Is it possible to
> test if this is a delayed assigned or not?
>
>
> BACKGROUND:
> The background to this is where I have a function in the R.oo package
> that scans namespaces for functions with a certain class attribute.
> For this I use is.function() and inherits() to inspect each object.
> An aroma.affymetrix user reported on a problem that boiled down to the
> following:
>
> # source("http://bioconductor.org/biocLite.R"); biocLite("hgu133a.db")
>> library("hgu133a.db")
>> is.function(hgu133aPFAM)
> Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
>   or PROSITE accessions.
>> .Internal(inspect(hgu133aPFAM))
>
>> traceback()
> 3: stop(paste(msg, collapse = ""), call. = FALSE, domain = NA)
> 2: .Defunct(msg = msg)
> 1: (function ()
>    {
>        if (grepl("PFAM", x)) {
>            bimapName <- paste0(prefix, "PFAM")
>        }
>        else {
>            bimapName <- paste0(prefix, "PROSITE")
>        }
>        x <- dc[[bimapName]]
>        msg = wmsg(paste0(bimapName, " is defunct. ", "Please use select() if you
>  need access to PFAM or PROSITE accessions. \n"))
>        if (interactive()) {
>            .Defunct(msg = msg)
>        }
>    })()
>
> My immediate solution is to perform those tests using tryCatch(), but
> this is interesting, because this function is such that the error is
> only thrown in interactive() sessions, i.e. the following works:
>
> $ Rscript -e "hgu133a.db::hgu133aPFAM"
> [...]
> NULL
>
> This is probably also why none of my aroma.affymetrix system tests
> caught this.  Without tracing the source code behind, which seems
> quite nested, the above is why I believe the assignment is "delayed";
> traceback() shows a body source code, the object evaluates to
> different things depending on interactive().
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From hb at biostat.ucsf.edu  Mon Jan 26 21:41:48 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 26 Jan 2015 12:41:48 -0800
Subject: [Rd] Inspect a "delayed" assigned whose value throws an error?
In-Reply-To: <CABdHhvFHgnb9mHKQO7L_DQybVHcA7vQqwCuuj7=3cra3_ZXfzg@mail.gmail.com>
References: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>
	<CABdHhvFHgnb9mHKQO7L_DQybVHcA7vQqwCuuj7=3cra3_ZXfzg@mail.gmail.com>
Message-ID: <CAFDcVCSNWk9Yh_DMe=nBUgNrPdon7QEy_6md_5rw0=+-KOV90Q@mail.gmail.com>

On Mon, Jan 26, 2015 at 12:24 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> If it was any other environment than the global, you could use substitute:
>
> e <- new.env()
> delayedAssign("foo", stop("Hey!"), assign.env = e)
> substitute(foo, e)
>
> delayedAssign("foo", stop("Hey!"))
> substitute(foo)

Hmm... interesting and odd.

Unfortunately, this doesn't seem to help for reaching into the
namespace of hgu133a.db and inspecting 'hgu133aPFAM', e.g.

> library("hgu133a.db")

> substitute(hgu133aPFAM, env=ns)
Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
  or PROSITE accessions.

> evalq(substitute(hgu133aPFAM), envir=ns)
Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
  or PROSITE accessions.

> evalq(substitute(hgu133aPFAM, env=ns), envir=ns)
Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
  or PROSITE accessions.

Thanks,

Henrik


>
> Hadley
>
> On Mon, Jan 26, 2015 at 12:53 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi, I got an interesting programming challenge:
>>
>> How do you inspect an object which is assigned via delayedAssign() and
>> that throws an error as soon as it is "touched" (=the value is
>> evaluated)?  Is it possible?
>>
>>
>> MINIMAL EXAMPLE:
>>
>> $ R --vanilla
>>> delayedAssign("foo", stop("Hey!"))
>>
>> (If you find this minimal example silly/obvious, please skip down to
>> the real example at the end)
>>
>>> foo
>> Error: Hey!
>>
>>> str(foo)
>> Error in str(foo) : Hey!
>> In addition: Warning message:
>> In str(foo) : restarting interrupted promise evaluation
>>
>>> mode(foo)
>> Error in mode(foo) : Hey!
>> In addition: Warning message:
>> In mode(foo) : restarting interrupted promise evaluation
>>
>>> .Internal(inspect(foo))
>> Error: Hey!
>> In addition: Warning message:
>> restarting interrupted promise evaluation
>>
>>> traceback()
>> 1: stop("Hey!")
>>
>> Is there anyway I can inspect this object using the R API without
>> evaluating the value in the delayed assignment?  Is it possible to
>> test if this is a delayed assigned or not?
>>
>>
>> BACKGROUND:
>> The background to this is where I have a function in the R.oo package
>> that scans namespaces for functions with a certain class attribute.
>> For this I use is.function() and inherits() to inspect each object.
>> An aroma.affymetrix user reported on a problem that boiled down to the
>> following:
>>
>> # source("http://bioconductor.org/biocLite.R"); biocLite("hgu133a.db")
>>> library("hgu133a.db")
>>> is.function(hgu133aPFAM)
>> Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
>>   or PROSITE accessions.
>>> .Internal(inspect(hgu133aPFAM))
>>
>>> traceback()
>> 3: stop(paste(msg, collapse = ""), call. = FALSE, domain = NA)
>> 2: .Defunct(msg = msg)
>> 1: (function ()
>>    {
>>        if (grepl("PFAM", x)) {
>>            bimapName <- paste0(prefix, "PFAM")
>>        }
>>        else {
>>            bimapName <- paste0(prefix, "PROSITE")
>>        }
>>        x <- dc[[bimapName]]
>>        msg = wmsg(paste0(bimapName, " is defunct. ", "Please use select() if you
>>  need access to PFAM or PROSITE accessions. \n"))
>>        if (interactive()) {
>>            .Defunct(msg = msg)
>>        }
>>    })()
>>
>> My immediate solution is to perform those tests using tryCatch(), but
>> this is interesting, because this function is such that the error is
>> only thrown in interactive() sessions, i.e. the following works:
>>
>> $ Rscript -e "hgu133a.db::hgu133aPFAM"
>> [...]
>> NULL
>>
>> This is probably also why none of my aroma.affymetrix system tests
>> caught this.  Without tracing the source code behind, which seems
>> quite nested, the above is why I believe the assignment is "delayed";
>> traceback() shows a body source code, the object evaluates to
>> different things depending on interactive().
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> http://had.co.nz/


From avraham.adler at gmail.com  Mon Jan 26 23:12:54 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 26 Jan 2015 17:12:54 -0500
Subject: [Rd] Building rinstaller using R-devel (3.2.0-to-be) halts when
 trying to copy html files
Message-ID: <CAL6gwnKn8Y9wJJYKQ+RJNb8KkKF=pokr3ggu7-YhAxXM+f_4MQ@mail.gmail.com>

As the build process, especially for Windows, is changing
significantly for R 3.2.0, I am trying to build R-devel in
preparation. When running `make rinstaller`, I get the following
error:

    cp -p ../../../etc/x64/Makeconf R-devel/etc/x64
    mkdir -p R-devel/doc
    cp -p ../../../doc/CRAN_mirrors.csv R-devel/doc
    mkdir -p R-devel/doc/manual/images
    cp -pR ../../../doc/html R-devel/doc
    cp -p ../../../doc/manual/*.html ../../../doc/manual/*.pdf \
      R-devel/doc/manual
    cp: cannot stat '../../../doc/manual/*.html': No such file or directory
    make[1]: *** [imagedir] Error 1
    make[1]: Leaving directory `/cygdrive/f/R/R-devel/src/gnuwin32/installer'
    make: *** [rinstaller] Error 2

Looking at the directories, I have "\doc\manual" and
"F:\R\R-devel\doc\html" and there are no .html files in the \manual
directory, only pdfs.

I am building on Windows 7 64 bit, so the MkRules.local is being used,
and the pertinent settings therein include:

    BUILD_HTML = YES
    MIKTEX = TRUE
    TEXI2ANY = missing

Is it as simple as changing line 74 in the Makefile under
src/gnuwin32/installer from:

    $(CP) -p $(R_HOME)/doc/manual/*.html $(R_HOME)/doc/manual/*.pdf \

to

    $(CP) -p $(R_HOME)/doc/html/*.html $(R_HOME)/doc/manual/*.pdf \

Or is the problem that MIKTEX alone can no longer be used and texinfo
/must/ be installed (as is implied in
<http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Building-the-manuals>?

Thank you,

Avi


From murdoch.duncan at gmail.com  Tue Jan 27 02:36:50 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Jan 2015 20:36:50 -0500
Subject: [Rd] Building rinstaller using R-devel (3.2.0-to-be) halts when
 trying to copy html files
In-Reply-To: <CAL6gwnKn8Y9wJJYKQ+RJNb8KkKF=pokr3ggu7-YhAxXM+f_4MQ@mail.gmail.com>
References: <CAL6gwnKn8Y9wJJYKQ+RJNb8KkKF=pokr3ggu7-YhAxXM+f_4MQ@mail.gmail.com>
Message-ID: <54C6EBB2.7050901@gmail.com>

On 26/01/2015 5:12 PM, Avraham Adler wrote:
> As the build process, especially for Windows, is changing
> significantly for R 3.2.0, I am trying to build R-devel in
> preparation. When running `make rinstaller`, I get the following
> error:
> 
>     cp -p ../../../etc/x64/Makeconf R-devel/etc/x64
>     mkdir -p R-devel/doc
>     cp -p ../../../doc/CRAN_mirrors.csv R-devel/doc
>     mkdir -p R-devel/doc/manual/images
>     cp -pR ../../../doc/html R-devel/doc
>     cp -p ../../../doc/manual/*.html ../../../doc/manual/*.pdf \
>       R-devel/doc/manual
>     cp: cannot stat '../../../doc/manual/*.html': No such file or directory
>     make[1]: *** [imagedir] Error 1
>     make[1]: Leaving directory `/cygdrive/f/R/R-devel/src/gnuwin32/installer'
>     make: *** [rinstaller] Error 2
> 
> Looking at the directories, I have "\doc\manual" and
> "F:\R\R-devel\doc\html" and there are no .html files in the \manual
> directory, only pdfs.
> 
> I am building on Windows 7 64 bit, so the MkRules.local is being used,
> and the pertinent settings therein include:
> 
>     BUILD_HTML = YES
>     MIKTEX = TRUE
>     TEXI2ANY = missing
> 
> Is it as simple as changing line 74 in the Makefile under
> src/gnuwin32/installer from:
> 
>     $(CP) -p $(R_HOME)/doc/manual/*.html $(R_HOME)/doc/manual/*.pdf \
> 
> to
> 
>     $(CP) -p $(R_HOME)/doc/html/*.html $(R_HOME)/doc/manual/*.pdf \
> 
> Or is the problem that MIKTEX alone can no longer be used and texinfo
> /must/ be installed (as is implied in
> <http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Building-the-manuals>?

Yes, for a complete build you need the texi2any program (and Perl).  R
will still build well enough to run, but the help system is incomplete,
and will require an Internet connection to access the manuals.

Were you interested in distributing the version without the manuals, or
is it just that you haven't updated your Rtools to include texi2any?

Duncan Murdoch

> 
> Thank you,
> 
> Avi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From avraham.adler at gmail.com  Tue Jan 27 03:57:01 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 26 Jan 2015 21:57:01 -0500
Subject: [Rd] Building rinstaller using R-devel (3.2.0-to-be) halts when
 trying to copy html files
In-Reply-To: <54C6EBB2.7050901@gmail.com>
References: <CAL6gwnKn8Y9wJJYKQ+RJNb8KkKF=pokr3ggu7-YhAxXM+f_4MQ@mail.gmail.com>
	<54C6EBB2.7050901@gmail.com>
Message-ID: <CAL6gwnKGeKevLFMGbYeYM4NuGi4oGrEt3HQN19dZ8Q26CHi-sw@mail.gmail.com>

On Mon, Jan 26, 2015 at 8:36 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 26/01/2015 5:12 PM, Avraham Adler wrote:
>> As the build process, especially for Windows, is changing
>> significantly for R 3.2.0, I am trying to build R-devel in
>> preparation. When running `make rinstaller`, I get the following
>> error:
>>
>>     cp -p ../../../etc/x64/Makeconf R-devel/etc/x64
>>     mkdir -p R-devel/doc
>>     cp -p ../../../doc/CRAN_mirrors.csv R-devel/doc
>>     mkdir -p R-devel/doc/manual/images
>>     cp -pR ../../../doc/html R-devel/doc
>>     cp -p ../../../doc/manual/*.html ../../../doc/manual/*.pdf \
>>       R-devel/doc/manual
>>     cp: cannot stat '../../../doc/manual/*.html': No such file or directory
>>     make[1]: *** [imagedir] Error 1
>>     make[1]: Leaving directory `/cygdrive/f/R/R-devel/src/gnuwin32/installer'
>>     make: *** [rinstaller] Error 2
>>
>> Looking at the directories, I have "\doc\manual" and
>> "F:\R\R-devel\doc\html" and there are no .html files in the \manual
>> directory, only pdfs.
>>
>> I am building on Windows 7 64 bit, so the MkRules.local is being used,
>> and the pertinent settings therein include:
>>
>>     BUILD_HTML = YES
>>     MIKTEX = TRUE
>>     TEXI2ANY = missing
>>
>> Is it as simple as changing line 74 in the Makefile under
>> src/gnuwin32/installer from:
>>
>>     $(CP) -p $(R_HOME)/doc/manual/*.html $(R_HOME)/doc/manual/*.pdf \
>>
>> to
>>
>>     $(CP) -p $(R_HOME)/doc/html/*.html $(R_HOME)/doc/manual/*.pdf \
>>
>> Or is the problem that MIKTEX alone can no longer be used and texinfo
>> /must/ be installed (as is implied in
>> <http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Building-the-manuals>?
>
> Yes, for a complete build you need the texi2any program (and Perl).  R
> will still build well enough to run, but the help system is incomplete,
> and will require an Internet connection to access the manuals.
>
> Were you interested in distributing the version without the manuals, or
> is it just that you haven't updated your Rtools to include texi2any?
>
> Duncan Murdoch
>

I was afraid of that. I had updated Rtools with everything (Perl, ICU,
etc.) but was afraid texinfo would interfere with MikTex; my mistake.
Fixing that worked, thank you very much. In general, even though I
don't distribute binaries to others, I prefer to run through the build
all the way to risntaller and then run check-all to make sure
everything is working properly. Also, it allows me to use the
installer to install a production version of R to one subdirectory and
keep mu

Two points if I may:

1) The MkRules has the flag TEX2ANY and the texinfo zip has a flag
MAKEINFO which seems to require the same statement. I put both in the
MkRules.local, but which one should be used?
2) For windows users "/path/to/perl" may be a bit misleading. Most of
the other entries require the subdirectory name. This one seems to
require the full name of the executable (e.g.
"F:/Strawberry/perl/bin/perl.exe").

Once again, thank you,

Avi


From john.maindonald at anu.edu.au  Tue Jan 27 10:34:01 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 27 Jan 2015 09:34:01 +0000
Subject: [Rd] R CMD check message: "The following files should probably not
 be installed"
In-Reply-To: <mailman.20.1422270004.8306.r-devel@r-project.org>
References: <mailman.20.1422270004.8306.r-devel@r-project.org>
Message-ID: <41523A30-35B5-40CD-81A3-8624BFD35201@anu.edu.au>

Sorry.  This, and the description in the ?Writing R Extensions? manual,
leaves me completely mystified.  Is it that I have to remove the PDFs
that are created when I run ?R CMD build?, and somehow ensure that
they are rebuilt when the package is installed?  Do I need a Makefile?


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

phone : +61 2 (6125)3473    fax  : +61 2(6125)5549

Centre for Mathematics & Its Applications, Room 1194,

John Dedman Mathematical Sciences Building (Building 27)

Australian National University, Canberra ACT 0200.


On 26 Jan 2015, at 22:00, <r-devel-request at r-project.org<mailto:r-devel-request at r-project.org>> <r-devel-request at r-project.org<mailto:r-devel-request at r-project.org>> wrote:

From: Prof Brian Ripley <ripley at stats.ox.ac.uk<mailto:ripley at stats.ox.ac.uk>>
Subject: Re: [Rd] R CMD check message: "The following files should probably not be installed"
Date: 26 January 2015 19:52:12 AEDT
To: <r-devel at r-project.org<mailto:r-devel at r-project.org>>


On 25/01/2015 23:25, John Maindonald wrote:
I am doing [R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?; Platform: x86_64-apple-darwin10.8.0 (64-bit)]

R CMD build DAAGviz
R CMD check DAAGviz_1.0.3.tar.gz

Without a .Rinstignore file, I get:

<<<
The following files should probably not be installed:
  ?figs10.pdf?, ?figs11.pdf?, ?figs12.pdf?, ?figs13.pdf?, ?figs14.pdf?,
  ?figs5.pdf?, ?figs6.pdf?, ?figs9.pdf?

Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
or move the vignette sources from ?inst/doc? to ?vignettes?.


The vignette sources were in ?vignettes? when DAAGviz_1.0.3.tar.gz was created.  There was nothing in the ?inst/doc? directory.

If I have in my .Rinstignore file

  inst/doc/.*[.]pdf

That filters out more than the files warned about.  I guess you meant

inst/doc/figs.*[.]pdf

But the question has to be: how did the files get copied into inst/doc?  Maybe

'When R CMD build builds the vignettes, it copies these and the vignette sources from directory vignettes to inst/doc. To install any other files from the vignettes directory, include a file vignettes/.install_extras which specifies these as Perl-like regular expressions on one or more lines. (See the description of the .Rinstignore file for full details.)'

suggests how?

then I get:

<<<
* checking package vignettes in ?inst/doc? ... WARNING
Package vignettes without corresponding PDF/HTML:
. . .


What am I missing?  Can I ignore the "The following files should probably not be installed? message?

Not if you want to submit the package to CRAN.



John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Tue Jan 27 12:25:29 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 27 Jan 2015 11:25:29 +0000
Subject: [Rd] R-devel Digest, Vol 143, Issue 25
In-Reply-To: <mailman.20.1422270004.8306.r-devel@r-project.org>
References: <mailman.20.1422270004.8306.r-devel@r-project.org>
Message-ID: <E8BC67D0-EF5D-4F8C-A60D-1169F5D14AEC@anu.edu.au>

OK, I see now that I was supposed to twig that the reference was to putting the ?.Rnw'
files back into the vignettes directory from the inst/doc directory where they?d been
placed in the course of creating the tar.gz file.  I am still trying to work out what I need 
to put into ?.Rinstignore? so that ?.install_extras? is not installed.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 26 Jan 2015, at 22:00, <r-devel-request at r-project.org> <r-devel-request at r-project.org> wrote:

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [Rd] R CMD check message: "The following files should probably not be installed"
> Date: 26 January 2015 19:52:12 AEDT
> To: <r-devel at r-project.org>
> 
> 
> On 25/01/2015 23:25, John Maindonald wrote:
>> I am doing [R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?; Platform: x86_64-apple-darwin10.8.0 (64-bit)]
>> 
>>> R CMD build DAAGviz
>>> R CMD check DAAGviz_1.0.3.tar.gz
>> 
>> Without a .Rinstignore file, I get:
>> 
>> <<<
>> The following files should probably not be installed:
>>   ?figs10.pdf?, ?figs11.pdf?, ?figs12.pdf?, ?figs13.pdf?, ?figs14.pdf?,
>>   ?figs5.pdf?, ?figs6.pdf?, ?figs9.pdf?
>> 
>> Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
>> or move the vignette sources from ?inst/doc? to ?vignettes?.
>>>>> 
>> 
>> The vignette sources were in ?vignettes? when DAAGviz_1.0.3.tar.gz was created.  There was nothing in the ?inst/doc? directory.
>> 
>> If I have in my .Rinstignore file
>> 
>>   inst/doc/.*[.]pdf
> 
> That filters out more than the files warned about.  I guess you meant
> 
> inst/doc/figs.*[.]pdf
> 
> But the question has to be: how did the files get copied into inst/doc?  Maybe
> 
> 'When R CMD build builds the vignettes, it copies these and the vignette sources from directory vignettes to inst/doc. To install any other files from the vignettes directory, include a file vignettes/.install_extras which specifies these as Perl-like regular expressions on one or more lines. (See the description of the .Rinstignore file for full details.)'
> 
> suggests how?
> 
>> then I get:
>> 
>> <<<
>> * checking package vignettes in ?inst/doc? ... WARNING
>> Package vignettes without corresponding PDF/HTML:
>> . . .
>>>>> 
>> 
>> What am I missing?  Can I ignore the "The following files should probably not be installed? message?
> 
> Not if you want to submit the package to CRAN.
> 
> 
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK


From maechler at lynne.stat.math.ethz.ch  Tue Jan 27 15:56:19 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 27 Jan 2015 15:56:19 +0100
Subject: [Rd] Inspect a "delayed" assigned whose value throws an error?
In-Reply-To: <CAFDcVCSNWk9Yh_DMe=nBUgNrPdon7QEy_6md_5rw0=+-KOV90Q@mail.gmail.com>
References: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>
	<CABdHhvFHgnb9mHKQO7L_DQybVHcA7vQqwCuuj7=3cra3_ZXfzg@mail.gmail.com>
	<CAFDcVCSNWk9Yh_DMe=nBUgNrPdon7QEy_6md_5rw0=+-KOV90Q@mail.gmail.com>
Message-ID: <21703.42771.678057.885871@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>     on Mon, 26 Jan 2015 12:41:48 -0800 writes:

    > On Mon, Jan 26, 2015 at 12:24 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
    >> If it was any other environment than the global, you could use substitute:
    >> 
    >> e <- new.env()
    >> delayedAssign("foo", stop("Hey!"), assign.env = e)
    >> substitute(foo, e)
    >> 
    >> delayedAssign("foo", stop("Hey!"))
    >> substitute(foo)

    > Hmm... interesting and odd.

    > Unfortunately, this doesn't seem to help for reaching into the
    > namespace of hgu133a.db and inspecting 'hgu133aPFAM', e.g.

    >> library("hgu133a.db")

    >> substitute(hgu133aPFAM, env=ns)
    > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
    > or PROSITE accessions.

    >> evalq(substitute(hgu133aPFAM), envir=ns)
    > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
    > or PROSITE accessions.

    >> evalq(substitute(hgu133aPFAM, env=ns), envir=ns)
    > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
    > or PROSITE accessions.

this *is* interesting..

Note that shortly after delayedAssign() was introduced into R,
we had

  R : Copyright 2005, The R Foundation for Statistical Computing
  Version 2.2.1  (2005-12-20 r36812)
  ISBN 3-900051-07-0

  ............

  > delayedAssign("x", pi^2) ; substitute(x)
  pi^2
  > 

so it also worked with the globalenv;  but that feature already
disappeared with 

  R : Copyright 2006, The R Foundation for Statistical Computing
  Version 2.3.0 (2006-04-24)

Almost surely as an inadvertent side effect of something else.

-----------------------------------

--> Quiz (even though it's not Friday) :

The help page for delayedAssign() contains a somewhat more
sophisticated example of 'promise's, and BTW an example that
worked also in *much* earlier version of R, probably in all
versions of R {I checked  R 1.0.1, probably the oldest still
running on my current Linux desktop} :

e <- (function(x, y = 1, z) environment())(1+2, "y", {cat(" HO! "); pi+2})

which gives an environment full of promises

Now, the following also works alread in R 1.0.1 :

> gete <- function(e)
   lapply(lapply(ls(env=e), as.name), 
         function(n) eval(substitute(substitute(X, e), list(X=n))))

> gete(e)
[[1]]
1 + 2

[[2]]
[1] "y"

[[3]]
{
    cat(" HO! ")
    pi + 2
}

> 

In newer versions of R, you can use  'ls(e)' instead of
'ls(env=e)', and we have bquote() to make it a tad shorter:

gete2 <- function(e)
   lapply(lapply(ls(e), as.name), function(n) eval(bquote(substitute(.(n), e))))

Apart from that (and from not using spaces and from silly things
such as 'L = lapply', and using L),
can anyone find a shorter (or "nicer") way to achieve the same
as gete(), or  gete2(), i.e., return a list with the promise expressions and
not evaluating e ?

You are not allowed to use 'x', 'y', and 'z' explicitly of
course, because here,
  gete0 <- function(e) list(substitute(x,e), substitute(y,e), substitute(z,e))
would be slightly shorter.

Martin


From h.wickham at gmail.com  Tue Jan 27 16:03:09 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 27 Jan 2015 09:03:09 -0600
Subject: [Rd] Inspect a "delayed" assigned whose value throws an error?
In-Reply-To: <21703.42771.678057.885871@stat.math.ethz.ch>
References: <CAFDcVCQiE=DEJuNMAd2xZfQF-Cz3fyx4ajTwmeBvncwmcsS8oA@mail.gmail.com>
	<CABdHhvFHgnb9mHKQO7L_DQybVHcA7vQqwCuuj7=3cra3_ZXfzg@mail.gmail.com>
	<CAFDcVCSNWk9Yh_DMe=nBUgNrPdon7QEy_6md_5rw0=+-KOV90Q@mail.gmail.com>
	<21703.42771.678057.885871@stat.math.ethz.ch>
Message-ID: <CABdHhvE7bZnNq7R6C-dZS43hhwKMvWAiV5p7eHgrb612NUxPJg@mail.gmail.com>

On Tue, Jan 27, 2015 at 8:56 AM, Martin Maechler
<maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>>     on Mon, 26 Jan 2015 12:41:48 -0800 writes:
>
>     > On Mon, Jan 26, 2015 at 12:24 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>     >> If it was any other environment than the global, you could use substitute:
>     >>
>     >> e <- new.env()
>     >> delayedAssign("foo", stop("Hey!"), assign.env = e)
>     >> substitute(foo, e)
>     >>
>     >> delayedAssign("foo", stop("Hey!"))
>     >> substitute(foo)
>
>     > Hmm... interesting and odd.
>
>     > Unfortunately, this doesn't seem to help for reaching into the
>     > namespace of hgu133a.db and inspecting 'hgu133aPFAM', e.g.
>
>     >> library("hgu133a.db")
>
>     >> substitute(hgu133aPFAM, env=ns)
>     > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
>     > or PROSITE accessions.
>
>     >> evalq(substitute(hgu133aPFAM), envir=ns)
>     > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
>     > or PROSITE accessions.
>
>     >> evalq(substitute(hgu133aPFAM, env=ns), envir=ns)
>     > Error: hgu133aPFAM is defunct. Please use select() if you need access to PFAM
>     > or PROSITE accessions.
>
> this *is* interesting..
>
> Note that shortly after delayedAssign() was introduced into R,
> we had
>
>   R : Copyright 2005, The R Foundation for Statistical Computing
>   Version 2.2.1  (2005-12-20 r36812)
>   ISBN 3-900051-07-0
>
>   ............
>
>   > delayedAssign("x", pi^2) ; substitute(x)
>   pi^2
>   >
>
> so it also worked with the globalenv;  but that feature already
> disappeared with
>
>   R : Copyright 2006, The R Foundation for Statistical Computing
>   Version 2.3.0 (2006-04-24)
>
> Almost surely as an inadvertent side effect of something else.

The substitute docs have: "If it is an ordinary variable, its value is
substituted, unless env is .GlobalEnv in which case the symbol is left
unchanged."

So it's definitely a deliberate change. This commit looks related:
https://github.com/wch/r-source/commit/182d197094f8fcecf6ec8f14bfc7c69a02ac251d.
There Duncan commented "For historical reasons, don't substitute in
R_GlobalEnv", which suggests that the behaviour you see in 2.2.1 might
have been a bug.

Hadley


-- 
http://had.co.nz/


From maechler at lynne.stat.math.ethz.ch  Tue Jan 27 16:11:25 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 27 Jan 2015 16:11:25 +0100
Subject: [Rd] names function for environments?
In-Reply-To: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
Message-ID: <21703.43677.632521.343906@stat.math.ethz.ch>

>>>>> Peter Haverty <haverty.peter at gene.com>
>>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:

    > Hi all,
    > The "ls" function wears two hats. It allows users to inspect an
    > environment interactively and also serves deeper in code as the
    > accessor for an environment's names/keys. I propose that we separate
    > these two conflicting goals, keeping ls for interactive use and adding
    > names for a quick listing of the hash keys. This involves adding two
    > lines to do_names in attrib.c.

    > The 'ls' function and its 'objects' synonym appear very frequently in
    > performance-critical code like base/R/namespace.R and throughout the
    > methods package. These functions are currently among the major
    > contributors to execution time in package loading.

    > This two-line addition to attrib.c gives a significant speedup for
    > listing an environment's names/keys (2-60X depending on the 'sorted'
    > argument). It also simplifies the environment API by making it more
    > like the other basic types. We already have $ and [[ after all.

    > Rather than sprinkling sorted=FALSE throughout the methods and base
    > code, let's use names.

as for list()s and other (generalized) vectors.

This sounds appealing at first, and I have heard/seen others propose
it.  I see one good reason *not* to allow it (and you mention the
reason by mentioning 'sorted') :

The contents of an environment are inherently unordered, and
even if the order stays fixed for a while, no code should rely
on the ordering of the objects, and for that reason,
 <env>[1]  etc do not make sense and are not allowed.

    > Would you be open to this change?

I'm undecided currently:
 "-": reason above; 
 "+": convenience, compacter R code using it;
      very simple and natural change to src/main/attrib.c

and waiting for other comments, not the least from other members of R core ..

Martin Maechler, ETH Zurich


    > I have submitted a patch and some timings to the bug tracker as
    > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170

    > Regards,
    > Pete

    > ____________________
    > Peter M. Haverty, Ph.D.
    > Genentech, Inc.
    > phaverty at gene.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Tue Jan 27 16:26:30 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 27 Jan 2015 07:26:30 -0800
Subject: [Rd] names function for environments?
In-Reply-To: <21703.43677.632521.343906@stat.math.ethz.ch>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
Message-ID: <CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>

I think ls(, sort=FALSE) would be more explicit and thus clearer. There is
much precedent for having arguments that request less work to be done e.g.
unlist(use.names=FALSE).  Yes, the extra typing is a bit painful, but there
is no intuitive reason why names() would be unsorted, while ls() would be
sorted. While it is tempting to use an existing function for this, the word
"names" is somewhat loaded. For example, one might expect
identical(names(env), names(as.list(env))) to be TRUE. I see no problem
with making names() a simple alias of ls(), as long as the behavior is the
same. Maybe a different name would be less "loaded" and imply lack of
order, something like keySet(). But do we really need this?






On Tue, Jan 27, 2015 at 7:11 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:

> >>>>> Peter Haverty <haverty.peter at gene.com>
> >>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:
>
>     > Hi all,
>     > The "ls" function wears two hats. It allows users to inspect an
>     > environment interactively and also serves deeper in code as the
>     > accessor for an environment's names/keys. I propose that we separate
>     > these two conflicting goals, keeping ls for interactive use and
> adding
>     > names for a quick listing of the hash keys. This involves adding two
>     > lines to do_names in attrib.c.
>
>     > The 'ls' function and its 'objects' synonym appear very frequently in
>     > performance-critical code like base/R/namespace.R and throughout the
>     > methods package. These functions are currently among the major
>     > contributors to execution time in package loading.
>
>     > This two-line addition to attrib.c gives a significant speedup for
>     > listing an environment's names/keys (2-60X depending on the 'sorted'
>     > argument). It also simplifies the environment API by making it more
>     > like the other basic types. We already have $ and [[ after all.
>
>     > Rather than sprinkling sorted=FALSE throughout the methods and base
>     > code, let's use names.
>
> as for list()s and other (generalized) vectors.
>
> This sounds appealing at first, and I have heard/seen others propose
> it.  I see one good reason *not* to allow it (and you mention the
> reason by mentioning 'sorted') :
>
> The contents of an environment are inherently unordered, and
> even if the order stays fixed for a while, no code should rely
> on the ordering of the objects, and for that reason,
>  <env>[1]  etc do not make sense and are not allowed.
>
>     > Would you be open to this change?
>
> I'm undecided currently:
>  "-": reason above;
>  "+": convenience, compacter R code using it;
>       very simple and natural change to src/main/attrib.c
>
> and waiting for other comments, not the least from other members of R core
> ..
>
> Martin Maechler, ETH Zurich
>
>
>     > I have submitted a patch and some timings to the bug tracker as
>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170
>
>     > Regards,
>     > Pete
>
>     > ____________________
>     > Peter M. Haverty, Ph.D.
>     > Genentech, Inc.
>     > phaverty at gene.com
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From haverty.peter at gene.com  Tue Jan 27 16:44:57 2015
From: haverty.peter at gene.com (Peter Haverty)
Date: Tue, 27 Jan 2015 07:44:57 -0800
Subject: [Rd] names function for environments?
In-Reply-To: <CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
	<CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
Message-ID: <CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>

I think that the "sorted" and "all.names" arguments are really only
appropriate for pretty printing to the screen. I think it is a bit
unfortunate that environments have a names accessor that is 60X slower
than all the other types. This is likely due to the history of
environments, which were originally just for behind-the-scenes tasks.

Now that users can use environments as hashes, we really need
something like a "keys" function. We don't want programmers depending
on the sorted-ness, as Martin mentioned.  Also, I think it helps users
when objects share as many of the key API functions as possible.
"names" is natural. "ls" was certainly confusing for me when I
started. Having to supply two additional arguments to get the desired
output doesn't help there.  Think of all the perl programmers
struggling to switch to R.  Let's help them out.
Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com


On Tue, Jan 27, 2015 at 7:26 AM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> I think ls(, sort=FALSE) would be more explicit and thus clearer. There is
> much precedent for having arguments that request less work to be done e.g.
> unlist(use.names=FALSE).  Yes, the extra typing is a bit painful, but there
> is no intuitive reason why names() would be unsorted, while ls() would be
> sorted. While it is tempting to use an existing function for this, the word
> "names" is somewhat loaded. For example, one might expect
> identical(names(env), names(as.list(env))) to be TRUE. I see no problem with
> making names() a simple alias of ls(), as long as the behavior is the same.
> Maybe a different name would be less "loaded" and imply lack of order,
> something like keySet(). But do we really need this?
>
>
>
>
>
>
> On Tue, Jan 27, 2015 at 7:11 AM, Martin Maechler
> <maechler at lynne.stat.math.ethz.ch> wrote:
>>
>> >>>>> Peter Haverty <haverty.peter at gene.com>
>> >>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:
>>
>>     > Hi all,
>>     > The "ls" function wears two hats. It allows users to inspect an
>>     > environment interactively and also serves deeper in code as the
>>     > accessor for an environment's names/keys. I propose that we separate
>>     > these two conflicting goals, keeping ls for interactive use and
>> adding
>>     > names for a quick listing of the hash keys. This involves adding two
>>     > lines to do_names in attrib.c.
>>
>>     > The 'ls' function and its 'objects' synonym appear very frequently
>> in
>>     > performance-critical code like base/R/namespace.R and throughout the
>>     > methods package. These functions are currently among the major
>>     > contributors to execution time in package loading.
>>
>>     > This two-line addition to attrib.c gives a significant speedup for
>>     > listing an environment's names/keys (2-60X depending on the 'sorted'
>>     > argument). It also simplifies the environment API by making it more
>>     > like the other basic types. We already have $ and [[ after all.
>>
>>     > Rather than sprinkling sorted=FALSE throughout the methods and base
>>     > code, let's use names.
>>
>> as for list()s and other (generalized) vectors.
>>
>> This sounds appealing at first, and I have heard/seen others propose
>> it.  I see one good reason *not* to allow it (and you mention the
>> reason by mentioning 'sorted') :
>>
>> The contents of an environment are inherently unordered, and
>> even if the order stays fixed for a while, no code should rely
>> on the ordering of the objects, and for that reason,
>>  <env>[1]  etc do not make sense and are not allowed.
>>
>>     > Would you be open to this change?
>>
>> I'm undecided currently:
>>  "-": reason above;
>>  "+": convenience, compacter R code using it;
>>       very simple and natural change to src/main/attrib.c
>>
>> and waiting for other comments, not the least from other members of R core
>> ..
>>
>> Martin Maechler, ETH Zurich
>>
>>
>>     > I have submitted a patch and some timings to the bug tracker as
>>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170
>>
>>     > Regards,
>>     > Pete
>>
>>     > ____________________
>>     > Peter M. Haverty, Ph.D.
>>     > Genentech, Inc.
>>     > phaverty at gene.com
>>
>>     > ______________________________________________
>>     > R-devel at r-project.org mailing list
>>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From john.maindonald at anu.edu.au  Tue Jan 27 16:52:58 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 27 Jan 2015 15:52:58 +0000
Subject: [Rd] How do I prevent '.install_extras' from being installed?
Message-ID: <1D189BBD-3F36-449D-ADFB-58C57A9567D7@anu.edu.au>

So now I have:
 
vignettes/.install_extras:

inst/doc/figs.*[.]Rnw$


.Rinstignore:

[.]DS_Store
inst/doc/.*[.]pdf$
inst/doc/Sweavel.sty$
inst/doc/[.]install_extras$


Everything is fine except that 'R CMD check ?? generates the note:

"Found the following hidden files and directories:
  inst/doc/.install_extras
These were most likely included in error. See section ?Package
structure? in the ?Writing R Extensions? manual."

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From lawrence.michael at gene.com  Tue Jan 27 16:59:59 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 27 Jan 2015 07:59:59 -0800
Subject: [Rd] names function for environments?
In-Reply-To: <CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
	<CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
	<CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>
Message-ID: <CAOQ5NyeH3tedOsd4LdxmoNXQaH0nT324huGn0FKPQ5PzZ2rBHw@mail.gmail.com>

Since the contract of ls() is to sort, there is nothing wrong with
programmers depending on it. And there are many functions that could be
made 60X faster, but is it worth it? But I did notice that
as.list.environment has a sorted=FALSE argument already, so I guess
identical(names(x), names(as.list(x))) could be made to be TRUE, assuming
the order is at least persistent, if undefined, so that is a nice property.
I guess I'm OK it with.



On Tue, Jan 27, 2015 at 7:44 AM, Peter Haverty <haverty.peter at gene.com>
wrote:

> I think that the "sorted" and "all.names" arguments are really only
> appropriate for pretty printing to the screen. I think it is a bit
> unfortunate that environments have a names accessor that is 60X slower
> than all the other types. This is likely due to the history of
> environments, which were originally just for behind-the-scenes tasks.
>
> Now that users can use environments as hashes, we really need
> something like a "keys" function. We don't want programmers depending
> on the sorted-ness, as Martin mentioned.  Also, I think it helps users
> when objects share as many of the key API functions as possible.
> "names" is natural. "ls" was certainly confusing for me when I
> started. Having to supply two additional arguments to get the desired
> output doesn't help there.  Think of all the perl programmers
> struggling to switch to R.  Let's help them out.
> Pete
>
> ____________________
> Peter M. Haverty, Ph.D.
> Genentech, Inc.
> phaverty at gene.com
>
>
> On Tue, Jan 27, 2015 at 7:26 AM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
> > I think ls(, sort=FALSE) would be more explicit and thus clearer. There
> is
> > much precedent for having arguments that request less work to be done
> e.g.
> > unlist(use.names=FALSE).  Yes, the extra typing is a bit painful, but
> there
> > is no intuitive reason why names() would be unsorted, while ls() would be
> > sorted. While it is tempting to use an existing function for this, the
> word
> > "names" is somewhat loaded. For example, one might expect
> > identical(names(env), names(as.list(env))) to be TRUE. I see no problem
> with
> > making names() a simple alias of ls(), as long as the behavior is the
> same.
> > Maybe a different name would be less "loaded" and imply lack of order,
> > something like keySet(). But do we really need this?
> >
> >
> >
> >
> >
> >
> > On Tue, Jan 27, 2015 at 7:11 AM, Martin Maechler
> > <maechler at lynne.stat.math.ethz.ch> wrote:
> >>
> >> >>>>> Peter Haverty <haverty.peter at gene.com>
> >> >>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:
> >>
> >>     > Hi all,
> >>     > The "ls" function wears two hats. It allows users to inspect an
> >>     > environment interactively and also serves deeper in code as the
> >>     > accessor for an environment's names/keys. I propose that we
> separate
> >>     > these two conflicting goals, keeping ls for interactive use and
> >> adding
> >>     > names for a quick listing of the hash keys. This involves adding
> two
> >>     > lines to do_names in attrib.c.
> >>
> >>     > The 'ls' function and its 'objects' synonym appear very frequently
> >> in
> >>     > performance-critical code like base/R/namespace.R and throughout
> the
> >>     > methods package. These functions are currently among the major
> >>     > contributors to execution time in package loading.
> >>
> >>     > This two-line addition to attrib.c gives a significant speedup for
> >>     > listing an environment's names/keys (2-60X depending on the
> 'sorted'
> >>     > argument). It also simplifies the environment API by making it
> more
> >>     > like the other basic types. We already have $ and [[ after all.
> >>
> >>     > Rather than sprinkling sorted=FALSE throughout the methods and
> base
> >>     > code, let's use names.
> >>
> >> as for list()s and other (generalized) vectors.
> >>
> >> This sounds appealing at first, and I have heard/seen others propose
> >> it.  I see one good reason *not* to allow it (and you mention the
> >> reason by mentioning 'sorted') :
> >>
> >> The contents of an environment are inherently unordered, and
> >> even if the order stays fixed for a while, no code should rely
> >> on the ordering of the objects, and for that reason,
> >>  <env>[1]  etc do not make sense and are not allowed.
> >>
> >>     > Would you be open to this change?
> >>
> >> I'm undecided currently:
> >>  "-": reason above;
> >>  "+": convenience, compacter R code using it;
> >>       very simple and natural change to src/main/attrib.c
> >>
> >> and waiting for other comments, not the least from other members of R
> core
> >> ..
> >>
> >> Martin Maechler, ETH Zurich
> >>
> >>
> >>     > I have submitted a patch and some timings to the bug tracker as
> >>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170
> >>
> >>     > Regards,
> >>     > Pete
> >>
> >>     > ____________________
> >>     > Peter M. Haverty, Ph.D.
> >>     > Genentech, Inc.
> >>     > phaverty at gene.com
> >>
> >>     > ______________________________________________
> >>     > R-devel at r-project.org mailing list
> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Tue Jan 27 19:15:36 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 27 Jan 2015 10:15:36 -0800
Subject: [Rd] problem with update.packages() in R-Devel (3.2.0) on
	Windows
In-Reply-To: <002401d03991$25a38920$70ea9b60$@mcmaster.ca>
References: <002401d03991$25a38920$70ea9b60$@mcmaster.ca>
Message-ID: <CAFDcVCQ11MSrRgqDShSZrTfDayharqx0L90Fxws8HkUSfJwxfw@mail.gmail.com>

It works again using:

% R --version
R Under development (unstable) (2015-01-26 r67627) -- "Unsuffered
Consequences"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

/Henrik

On Mon, Jan 26, 2015 at 9:54 AM, John Fox <jfox at mcmaster.ca> wrote:

> Dear all,
>
> I've noticed the following problem for the past several days:
>
> ---------------- snip ----------------
> > update.packages(ask=FALSE)
>
> . . .
>
> trying URL 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> In addition: Warning message:
> In download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open: HTTP status was '404 Not Found'
> Warning in download.packages(pkgs, destdir = tmpd, available = available,
> :
>   download of package 'zoo' failed
>
> ---------------- snip ----------------
>
> Apparently, the subdirectory for the version number (/3.2) is missing from
> the URL. OTOH, install.packages() works fine:
>
> ---------------- snip ----------------
>
> > install.packages("zoo")
> trying URL
> 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
> Content type 'application/zip' length 878614 bytes (858 KB)
> opened URL
> downloaded 858 KB
>
> package 'zoo' successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>         C:\Users\John Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages
>
> ---------------- snip ----------------
>
> Session info:
>
> ---------------- snip ----------------
>
> > sessionInfo()
> R Under development (unstable) (2015-01-25 r67615)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.0
>
> ---------------- snip ----------------
>
> Best,
>  John
>
> -------------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
>
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> http://www.avast.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Tue Jan 27 19:24:41 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Tue, 27 Jan 2015 10:24:41 -0800 (PST)
Subject: [Rd] problem with update.packages() in R-Devel (3.2.0)
	on	Windows
In-Reply-To: <CAFDcVCQ11MSrRgqDShSZrTfDayharqx0L90Fxws8HkUSfJwxfw@mail.gmail.com>
Message-ID: <1648547658.3261326.1422383081207.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> To: "John Fox" <jfox at mcmaster.ca>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Tuesday, January 27, 2015 10:15:36 AM
> Subject: Re: [Rd] problem with update.packages() in R-Devel (3.2.0) on	Windows
> 
> It works again using:
> 
> % R --version
> R Under development (unstable) (2015-01-26 r67627) -- "Unsuffered
> Consequences"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 

Indeed. I've closed PR#16172.

Dan


> /Henrik
> 
> On Mon, Jan 26, 2015 at 9:54 AM, John Fox <jfox at mcmaster.ca> wrote:
> 
> > Dear all,
> >
> > I've noticed the following problem for the past several days:
> >
> > ---------------- snip ----------------
> > > update.packages(ask=FALSE)
> >
> > . . .
> >
> > trying URL
> > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > Error in download.file(url, destfile, method, mode = "wb", ...) :
> >   cannot open URL
> > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > In addition: Warning message:
> > In download.file(url, destfile, method, mode = "wb", ...) :
> >   cannot open: HTTP status was '404 Not Found'
> > Warning in download.packages(pkgs, destdir = tmpd, available =
> > available,
> > :
> >   download of package 'zoo' failed
> >
> > ---------------- snip ----------------
> >
> > Apparently, the subdirectory for the version number (/3.2) is
> > missing from
> > the URL. OTOH, install.packages() works fine:
> >
> > ---------------- snip ----------------
> >
> > > install.packages("zoo")
> > trying URL
> > 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
> > Content type 'application/zip' length 878614 bytes (858 KB)
> > opened URL
> > downloaded 858 KB
> >
> > package 'zoo' successfully unpacked and MD5 sums checked
> >
> > The downloaded binary packages are in
> >         C:\Users\John
> >         Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages
> >
> > ---------------- snip ----------------
> >
> > Session info:
> >
> > ---------------- snip ----------------
> >
> > > sessionInfo()
> > R Under development (unstable) (2015-01-25 r67615)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> > [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> > [5] LC_TIME=English_Canada.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> >   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.0
> >
> > ---------------- snip ----------------
> >
> > Best,
> >  John
> >
> > -------------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> >
> >
> >
> > ---
> > This email has been checked for viruses by Avast antivirus
> > software.
> > http://www.avast.com
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jfox at mcmaster.ca  Tue Jan 27 20:32:21 2015
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 27 Jan 2015 14:32:21 -0500
Subject: [Rd] problem with update.packages() in R-Devel
	(3.2.0)	on	Windows
In-Reply-To: <1648547658.3261326.1422383081207.JavaMail.root@fredhutch.org>
References: <CAFDcVCQ11MSrRgqDShSZrTfDayharqx0L90Fxws8HkUSfJwxfw@mail.gmail.com>
	<1648547658.3261326.1422383081207.JavaMail.root@fredhutch.org>
Message-ID: <003501d03a67$f8cb4d20$ea61e760$@mcmaster.ca>

Dear Dan and Henrik,

Yes -- thanks. I discovered that earlier today.

Best,
 John

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan
> Tenenbaum
> Sent: January-27-15 1:25 PM
> To: Henrik Bengtsson
> Cc: John Fox; R-devel
> Subject: Re: [Rd] problem with update.packages() in R-Devel (3.2.0) on
> Windows
> 
> 
> 
> ----- Original Message -----
> > From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> > To: "John Fox" <jfox at mcmaster.ca>
> > Cc: "R-devel" <r-devel at r-project.org>
> > Sent: Tuesday, January 27, 2015 10:15:36 AM
> > Subject: Re: [Rd] problem with update.packages() in R-Devel (3.2.0) on
> 	Windows
> >
> > It works again using:
> >
> > % R --version
> > R Under development (unstable) (2015-01-26 r67627) -- "Unsuffered
> > Consequences"
> > Copyright (C) 2015 The R Foundation for Statistical Computing
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> 
> Indeed. I've closed PR#16172.
> 
> Dan
> 
> 
> > /Henrik
> >
> > On Mon, Jan 26, 2015 at 9:54 AM, John Fox <jfox at mcmaster.ca> wrote:
> >
> > > Dear all,
> > >
> > > I've noticed the following problem for the past several days:
> > >
> > > ---------------- snip ----------------
> > > > update.packages(ask=FALSE)
> > >
> > > . . .
> > >
> > > trying URL
> > > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > > Error in download.file(url, destfile, method, mode = "wb", ...) :
> > >   cannot open URL
> > > 'http://cran.utstat.utoronto.ca/src/contrib/zoo_1.7-11.zip'
> > > In addition: Warning message:
> > > In download.file(url, destfile, method, mode = "wb", ...) :
> > >   cannot open: HTTP status was '404 Not Found'
> > > Warning in download.packages(pkgs, destdir = tmpd, available =
> > > available,
> > > :
> > >   download of package 'zoo' failed
> > >
> > > ---------------- snip ----------------
> > >
> > > Apparently, the subdirectory for the version number (/3.2) is
> > > missing from the URL. OTOH, install.packages() works fine:
> > >
> > > ---------------- snip ----------------
> > >
> > > > install.packages("zoo")
> > > trying URL
> > >
'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2/zoo_1.7-11.zip'
> > > Content type 'application/zip' length 878614 bytes (858 KB) opened
> > > URL downloaded 858 KB
> > >
> > > package 'zoo' successfully unpacked and MD5 sums checked
> > >
> > > The downloaded binary packages are in
> > >         C:\Users\John
> > >         Fox\AppData\Local\Temp\RtmpuKqvB0\downloaded_packages
> > >
> > > ---------------- snip ----------------
> > >
> > > Session info:
> > >
> > > ---------------- snip ----------------
> > >
> > > > sessionInfo()
> > > R Under development (unstable) (2015-01-25 r67615)
> > > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
> > > x64 (build 7601) Service Pack 1
> > >
> > > locale:
> > > [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3]
> > > LC_MONETARY=English_Canada.1252 LC_NUMERIC=C [5]
> > > LC_TIME=English_Canada.1252
> > >
> > > attached base packages:
> > > [1] stats     graphics  grDevices utils     datasets  methods
> > >   base
> > >
> > > loaded via a namespace (and not attached):
> > > [1] tools_3.2.0
> > >
> > > ---------------- snip ----------------
> > >
> > > Best,
> > >  John
> > >
> > > -------------------------------------------------------
> > > John Fox, Professor
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > http://socserv.mcmaster.ca/jfox/
> > >
> > >
> > >
> > >
> > > ---
> > > This email has been checked for viruses by Avast antivirus software.
> > > http://www.avast.com
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


---
This email has been checked for viruses by Avast antivirus software.


From skyebend at skyeome.net  Tue Jan 27 22:09:31 2015
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Tue, 27 Jan 2015 13:09:31 -0800
Subject: [Rd] libcurl support and curlGetHeaders warning message in R CMD
	check
Message-ID: <54C7FE8B.3020709@skyeome.net>

Dear R devel,

Is libcurl support required to run R.devel, or is it optional?

I'm compiling R.devel on an older Debian machine  that only has libcurl 
version 7.21.0

The R news file says

"
Sun, 25 Jan 2015
CHANGES IN R-devel NEW FEATURES

     Optional use of ?libcurl? (version 7.28.0 from Oct 2012 or later) 
for Internet access (including on Windows):

...

CHANGES IN R-devel UTILITIES

     ?R CMD check --as-cran? checks existence and accessibility of URLs 
in the ?DESCRIPTION? file and in the help files.
"

Which seems to suggest libcurl support is optional.   The build process 
seems to correctly detect that I have an old version of libcurl

checking if libcurl version >= 7.28.0... no

 > capabilities('libcurl')
libcurl
   FALSE

But when I try to build any packages with R.devel (for pre-release 
testing) I get lots and lots of Notes/errors like:


Found the following (possibly) invalid URLs:
   URL: http://statnet.org/
     From: DESCRIPTION
     Status: Error
     Message: curlGetHeaders is not supported on this platform

Maybe this url check should first verify that libcurl is available?


If it is the case that libcurl is required for R CMD check --as-cran, 
I'll try to follow up with R debian for how to get appropriate version. 
(seems like libcurl 7.28 is not yet included in a stable Debian release?)

Thanks for your help,

best,
  -skye


From maechler at lynne.stat.math.ethz.ch  Wed Jan 28 09:24:32 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 28 Jan 2015 09:24:32 +0100
Subject: [Rd] [PATCH v2] Makefile: add support for git svn clones
In-Reply-To: <1422297668-6552-1-git-send-email-balbi@kernel.org>
References: <1422297668-6552-1-git-send-email-balbi@kernel.org>
Message-ID: <21704.40128.132212.472548@stat.math.ethz.ch>

>>>>> Felipe Balbi <balbi at kernel.org>
>>>>>     on Mon, 26 Jan 2015 12:41:08 -0600 writes:

    > git has an interface for cloning SVN repositories into git
    > which some users might decide to use. For those users'
    > surprise, the repository will always fail to build on
    > svnonly target and it will exit early.

    > The problem is simple enough to fix by just checking if a
    > .git directory exists in top_builddir and, if so, call git
    > svn info insstead of svn info.

    > Note, however, that this only supports Linux (and possibly
    > Mac) users, as I have no means of writing/testing an
    > equivalent patch for the Windows Makefiles.

and your patch still contains changes to Makefile.win .. so we
can hope to have gone "there" at least part of the way.

Thank you, Felipe!

[ The patch was not quite ok, probably because being simply
  copy-pasted into the e-mail, e.g., it had
 '@@ -104,7 +107,7 @@ svnonly:'
 in one line instead of two ]

As promised, I've applied the patch and tested that it does
*not* break usual building from svn.

All other tests: Please, git lovers among us who have
decided to track the R development via 'git svn' instead of via 'svn':
 
Follow Felipe's quest (below) and test this... and if it does
not work, try to fix it for your platform and send patches and/or
further contact Felipe so he can do so.

Martin Maechler, ETH Zurich

    > Signed-off-by: Felipe Balbi <balbi at kernel.org>
    > ---

    > Due to lack of a Windows system, this has only been tested
    > on my linux box, if someone could give this a whirl on
    > windows and Mac OS X, I'd be really glad.

    > cheers


>  Makefile.in              | 5 ++++-
>  src/include/Makefile.win | 7 +++++--
>  2 files changed, 9 insertions(+), 3 deletions(-)

> diff --git a/Makefile.in b/Makefile.in
> index 44b0a3b4b99f..10415abd442b 100644
> --- a/Makefile.in
> +++ b/Makefile.in
> @@ -9,6 +9,9 @@ top_builddir = .
 
>  include $(top_builddir)/Makeconf
 
> +GIT := `if [ -d "$(top_builddir)/.git" ]; then \
> +	echo "git"; fi`
> +
>  distdir = $(PACKAGE)-$(VERSION)
>  INSTFILES = COPYING
>  NON_SVN_INSTFILES = SVN-REVISION
> @@ -104,7 +107,7 @@ svnonly:
>  	@if test ! -f "$(srcdir)/doc/FAQ" || test -f non-tarball ; then \
>  	  (cd doc/manual && $(MAKE) front-matter html-non-svn) ; \
>  	  touch non-tarball ; \
> -	  (cd $(srcdir); LC_ALL=C TZ=GMT svn info || $(ECHO) "Revision: -99") 2> /dev/null \
> +	  (cd $(srcdir); LC_ALL=C TZ=GMT $(GIT) svn info || $(ECHO) "Revision: -99") 2> /dev/null \
>  	    | sed -n -e '/^Revision/p' -e '/^Last Changed Date/'p \
>  	    | cut -d' ' -f1,2,3,4 > SVN-REVISION-tmp ; \
>  	  if test "`cat SVN-REVISION-tmp`" = "Revision: -99"; then \
> diff --git a/src/include/Makefile.win b/src/include/Makefile.win
> index 28361ef9cfa3..d81941f80f4f 100644
> --- a/src/include/Makefile.win
> +++ b/src/include/Makefile.win
> @@ -2,6 +2,9 @@
>  include ../gnuwin32/MkRules
>  R_HOME = ../..
 
> +GIT := `if [ -d "$(top_builddir)/.git" ]; then \
> +	echo "git"; fi`
> +
>  VER = $(shell sed -e 's/\([^ ]*\).*/\1/' ../../VERSION)
 
>  ## keep these in step with ./Makefile.in
> @@ -67,14 +70,14 @@ ifdef USE_SVNVERSION
>  	@LC_ALL=C svnversion ../.. | sed -n 's/^/Revision: /p' > svn-tmp || rm -f svn-tmp
>  	@grep -v exported svn-tmp > /dev/null || rm -f svn-tmp
>  else
> -	@(cd ../..; LC_ALL=C svn info || echo "Revision: unknown") 2> /dev/null \
> +	@(cd ../..; LC_ALL=C $(GIT) svn info || echo "Revision: unknown") 2> /dev/null \
>  	  | sed -n '/^Revision/p' > svn-tmp
>  	@if grep unknown svn-tmp > /dev/null ; then \
>  	  rm svn-tmp; \
>  	fi
>  endif
>  	@if test -f svn-tmp ; then \
> -	  (cd ../..; LC_ALL=C TZ=GMT svn info || echo "Last Changed Date: unknown") 2> /dev/null \
> +	  (cd ../..; LC_ALL=C TZ=GMT $(GIT) svn info || echo "Last Changed Date: unknown") 2> /dev/null \
>  	    | sed -n '/^Last Changed Date:/p' | sed 's/[0-9][0-9]:.*//' \
>  	    >> svn-tmp ; \
>  	else \
> -- 
> 2.3.0-rc1


From Krustev at hotmail.com  Wed Jan 28 13:14:52 2015
From: Krustev at hotmail.com (Teodor Krastev)
Date: Wed, 28 Jan 2015 04:14:52 -0800 (PST)
Subject: [Rd] capturing user windows message
Message-ID: <1422447292107-4702411.post@n4.nabble.com>

Hello,

I need to call R function after external to R application broadcasts a
registered message in Windows messaging system.
Any clues would be appreciated...

Theo



--
View this message in context: http://r.789695.n4.nabble.com/capturing-user-windows-message-tp4702411.html
Sent from the R devel mailing list archive at Nabble.com.


From PLRoebuck at mdanderson.org  Wed Jan 28 18:02:29 2015
From: PLRoebuck at mdanderson.org (Roebuck,Paul L)
Date: Wed, 28 Jan 2015 17:02:29 +0000
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
Message-ID: <D0EE7317.B896E%proebuck@mdanderson.org>

Interrogating some (of my own) code in another package.

>norm.meth <- getMethod("normalize", "MatrixLike")
>message("str(norm.meth)")
>str(norm.meth)

>message("show(norm.meth at .Data)")
>show(norm.meth at .Data)


Last show() displays this:

function (object, ...)
{
    .local <- function (object, method = c("median", "vs", "tukey"),
        calc.medians = TRUE, sweep.cols = calc.medians,
        recalc.after.sweep = sweep.cols, ...)
    {
        .do_normalize(object,
            method = match.arg(method),
            calc.medians = calc.medians,
            sweep.cols = sweep.cols,
            recalc.after.sweep = recalc.after.sweep,
            ...)
    }
    .local(object, ...)
}


Desire to be able to access formals() for the .local() function definition,
not the generic one. Have seen information desired available via "defined"
slot of returned 'MethodDefinition' object, but not using the code below.



====================

library(methods)

if (!isGeneric("normalize")) {
    ## Other packages also define this generic...
    setGeneric("normalize",
               function(object, ...) standardGeneric("normalize"))
}

setClassUnion("MatrixLike", c("matrix", "data.frame"))

.do_normalize <- function(concs,
                          method,
                          calc.medians,
                          sweep.cols,
                          recalc.after.sweep,
                          ...) {
    message("internal routine called!")
    NULL
}

setMethod("normalize", signature(object="MatrixLike"),
          function(object,
                   method=c("median", "vs", "tukey"),
                   calc.medians=TRUE,
                   sweep.cols=calc.medians,
                   recalc.after.sweep=sweep.cols,
                   ...) {

    .do_normalize <- function(object,
                            method=match.arg(method),
                            calc.medians=calc.medians,
                            sweep.cols=sweep.cols,
                            recalc.after.sweep=recalc.after.sweep,
                            ...)
}


From lawrence.michael at gene.com  Wed Jan 28 18:28:22 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 28 Jan 2015 09:28:22 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <D0EE7317.B896E%proebuck@mdanderson.org>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
Message-ID: <CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>

Would you please clarify your exact use case?

Thanks,
Michael

On Wed, Jan 28, 2015 at 9:02 AM, Roebuck,Paul L <PLRoebuck at mdanderson.org>
wrote:

> Interrogating some (of my own) code in another package.
>
> >norm.meth <- getMethod("normalize", "MatrixLike")
> >message("str(norm.meth)")
> >str(norm.meth)
>
> >message("show(norm.meth at .Data)")
> >show(norm.meth at .Data)
>
>
> Last show() displays this:
>
> function (object, ...)
> {
>     .local <- function (object, method = c("median", "vs", "tukey"),
>         calc.medians = TRUE, sweep.cols = calc.medians,
>         recalc.after.sweep = sweep.cols, ...)
>     {
>         .do_normalize(object,
>             method = match.arg(method),
>             calc.medians = calc.medians,
>             sweep.cols = sweep.cols,
>             recalc.after.sweep = recalc.after.sweep,
>             ...)
>     }
>     .local(object, ...)
> }
>
>
> Desire to be able to access formals() for the .local() function definition,
> not the generic one. Have seen information desired available via "defined"
> slot of returned 'MethodDefinition' object, but not using the code below.
>
>
>
> ====================
>
> library(methods)
>
> if (!isGeneric("normalize")) {
>     ## Other packages also define this generic...
>     setGeneric("normalize",
>                function(object, ...) standardGeneric("normalize"))
> }
>
> setClassUnion("MatrixLike", c("matrix", "data.frame"))
>
> .do_normalize <- function(concs,
>                           method,
>                           calc.medians,
>                           sweep.cols,
>                           recalc.after.sweep,
>                           ...) {
>     message("internal routine called!")
>     NULL
> }
>
> setMethod("normalize", signature(object="MatrixLike"),
>           function(object,
>                    method=c("median", "vs", "tukey"),
>                    calc.medians=TRUE,
>                    sweep.cols=calc.medians,
>                    recalc.after.sweep=sweep.cols,
>                    ...) {
>
>     .do_normalize <- function(object,
>                             method=match.arg(method),
>                             calc.medians=calc.medians,
>                             sweep.cols=sweep.cols,
>                             recalc.after.sweep=recalc.after.sweep,
>                             ...)
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From PLRoebuck at mdanderson.org  Wed Jan 28 19:07:02 2015
From: PLRoebuck at mdanderson.org (Roebuck,Paul L)
Date: Wed, 28 Jan 2015 18:07:02 +0000
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
Message-ID: <D0EE7C23.B8A11%proebuck@mdanderson.org>

I'm attempting to reflect the information for use with corresponding
fields in GUI (in a different package), to provide default values,
argname as key for UI label lookups, etc.

So I want something much more like the formals of the implementation:

{
    "object",
    "method":             c("median", "vs", "tukey"),
    "calc.medians":       TRUE,
    "sweep.cols":         calc.medians,
    "recalc.after.sweep": sweep.cols,
    "?"
}

not those of the generic:

{
    "object",
    "?"
}


From:  Michael Lawrence <lawrence.michael at gene.com>
Date:  Wednesday, January 28, 2015 11:28 AM
To:  "Roebuck,Paul L" <PLRoebuck at mdanderson.org>
Cc:  R-devel <r-devel at r-project.org>
Subject:  Re: [Rd] [Q] Get formal arguments of my implemented S4 method


Would you please clarify your exact use case?


Thanks,
Michael


On Wed, Jan 28, 2015 at 9:02 AM, Roebuck,Paul L
<PLRoebuck at mdanderson.org> wrote:

Interrogating some (of my own) code in another package.

>norm.meth <- getMethod("normalize", "MatrixLike")
>message("str(norm.meth)")
>str(norm.meth)

>message("show(norm.meth at .Data)")
>show(norm.meth at .Data)


Last show() displays this:

function (object, ...)
{
    .local <- function (object, method = c("median", "vs", "tukey"),
        calc.medians = TRUE, sweep.cols = calc.medians,
        recalc.after.sweep = sweep.cols, ...)
    {
        .do_normalize(object,
            method = match.arg(method),
            calc.medians = calc.medians,
            sweep.cols = sweep.cols,
            recalc.after.sweep = recalc.after.sweep,
            ...)
    }
    .local(object, ...)
}


Desire to be able to access formals() for the .local() function definition,
not the generic one. Have seen information desired available via "defined"
slot of returned 'MethodDefinition' object, but not using the code below.



====================

library(methods)

if (!isGeneric("normalize")) {
    ## Other packages also define this generic...
    setGeneric("normalize",
               function(object, ...) standardGeneric("normalize"))
}

setClassUnion("MatrixLike", c("matrix", "data.frame"))

.do_normalize <- function(concs,
                          method,
                          calc.medians,
                          sweep.cols,
                          recalc.after.sweep,
                          ...) {
    message("internal routine called!")
    NULL
}

setMethod("normalize", signature(object="MatrixLike"),
          function(object,
                   method=c("median", "vs", "tukey"),
                   calc.medians=TRUE,
                   sweep.cols=calc.medians,
                   recalc.after.sweep=sweep.cols,
                   ...) {

    .do_normalize <- function(object,
                            method=match.arg(method),
                            calc.medians=calc.medians,
                            sweep.cols=sweep.cols,
                            recalc.after.sweep=recalc.after.sweep,
                            ...)
}

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Thu Jan 29 03:37:06 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 28 Jan 2015 18:37:06 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <D0EE7C23.B8A11%proebuck@mdanderson.org>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
Message-ID: <CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>

At this point I would just due:

formals(body(method)[[2L]])

At some point we need to figure out what to do with this .local() confusion.




On Wed, Jan 28, 2015 at 10:07 AM, Roebuck,Paul L <PLRoebuck at mdanderson.org>
wrote:

> I'm attempting to reflect the information for use with corresponding
> fields in GUI (in a different package), to provide default values,
> argname as key for UI label lookups, etc.
>
> So I want something much more like the formals of the implementation:
>
> {
>     "object",
>     "method":             c("median", "vs", "tukey"),
>     "calc.medians":       TRUE,
>     "sweep.cols":         calc.medians,
>     "recalc.after.sweep": sweep.cols,
>     "?"
> }
>
> not those of the generic:
>
> {
>     "object",
>     "?"
> }
>
>
> From:  Michael Lawrence <lawrence.michael at gene.com>
> Date:  Wednesday, January 28, 2015 11:28 AM
> To:  "Roebuck,Paul L" <PLRoebuck at mdanderson.org>
> Cc:  R-devel <r-devel at r-project.org>
> Subject:  Re: [Rd] [Q] Get formal arguments of my implemented S4 method
>
>
> Would you please clarify your exact use case?
>
>
> Thanks,
> Michael
>
>
> On Wed, Jan 28, 2015 at 9:02 AM, Roebuck,Paul L
> <PLRoebuck at mdanderson.org> wrote:
>
> Interrogating some (of my own) code in another package.
>
> >norm.meth <- getMethod("normalize", "MatrixLike")
> >message("str(norm.meth)")
> >str(norm.meth)
>
> >message("show(norm.meth at .Data)")
> >show(norm.meth at .Data)
>
>
> Last show() displays this:
>
> function (object, ...)
> {
>     .local <- function (object, method = c("median", "vs", "tukey"),
>         calc.medians = TRUE, sweep.cols = calc.medians,
>         recalc.after.sweep = sweep.cols, ...)
>     {
>         .do_normalize(object,
>             method = match.arg(method),
>             calc.medians = calc.medians,
>             sweep.cols = sweep.cols,
>             recalc.after.sweep = recalc.after.sweep,
>             ...)
>     }
>     .local(object, ...)
> }
>
>
> Desire to be able to access formals() for the .local() function definition,
> not the generic one. Have seen information desired available via "defined"
> slot of returned 'MethodDefinition' object, but not using the code below.
>
>
>
> ====================
>
> library(methods)
>
> if (!isGeneric("normalize")) {
>     ## Other packages also define this generic...
>     setGeneric("normalize",
>                function(object, ...) standardGeneric("normalize"))
> }
>
> setClassUnion("MatrixLike", c("matrix", "data.frame"))
>
> .do_normalize <- function(concs,
>                           method,
>                           calc.medians,
>                           sweep.cols,
>                           recalc.after.sweep,
>                           ...) {
>     message("internal routine called!")
>     NULL
> }
>
> setMethod("normalize", signature(object="MatrixLike"),
>           function(object,
>                    method=c("median", "vs", "tukey"),
>                    calc.medians=TRUE,
>                    sweep.cols=calc.medians,
>                    recalc.after.sweep=sweep.cols,
>                    ...) {
>
>     .do_normalize <- function(object,
>                             method=match.arg(method),
>                             calc.medians=calc.medians,
>                             sweep.cols=sweep.cols,
>                             recalc.after.sweep=recalc.after.sweep,
>                             ...)
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Jan 29 13:33:35 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Jan 2015 07:33:35 -0500
Subject: [Rd] Error in help files connection
In-Reply-To: <CAAyVsXJiiyN+yPjykb=g9_yZSViofjy4uKgxyH6hkjg868NWeg@mail.gmail.com>
References: <CAAyVsXJiiyN+yPjykb=g9_yZSViofjy4uKgxyH6hkjg868NWeg@mail.gmail.com>
Message-ID: <54CA289F.2000901@gmail.com>

On 25/01/2015 1:58 PM, Axel Urbiz wrote:
> Hello,
> 
> I'm building a package on Mac OS. The build/check/install goes all ok.
> Also, the package gets loaded properly with library(my_package).
> 
> However, when I call the help file for a given function in the package --
> i.e., "?my_function", I get the following error:
> 
> Error in gzfile(file, "rb") : cannot open the connection
> 
> I've search for this issue, but did not find anything that could help in my
> case.
> 

You'll need to make your package available if you want someone else to
help.  If you want to do it yourself, use options(error=recover) to find
out what file R was trying to open, likely something like

/Library/Frameworks/R.framework/Resources/library/*/Meta/package.rds

and then work out why R was unable to open it.

Duncan Murdoch


From maechler at lynne.stat.math.ethz.ch  Thu Jan 29 14:51:44 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Jan 2015 14:51:44 +0100
Subject: [Rd] names function for environments?
In-Reply-To: <CAOQ5NyeH3tedOsd4LdxmoNXQaH0nT324huGn0FKPQ5PzZ2rBHw@mail.gmail.com>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
	<CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
	<CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>
	<CAOQ5NyeH3tedOsd4LdxmoNXQaH0nT324huGn0FKPQ5PzZ2rBHw@mail.gmail.com>
Message-ID: <21706.15088.949298.673951@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Tue, 27 Jan 2015 07:59:59 -0800 writes:

    > Since the contract of ls() is to sort, there is nothing wrong with
    > programmers depending on it. And there are many functions that could be
    > made 60X faster, but is it worth it? But I did notice that
    > as.list.environment has a sorted=FALSE argument already, so I guess
    > identical(names(x), names(as.list(x))) could be made to be TRUE, assuming
    > the order is at least persistent, if undefined, so that is a nice property.
    > I guess I'm OK it with.

As we ended only hearing "pro"s and no real "con"s,
I've committed (a corrected version of) the code now.

The above identity is not true in generality though,  but

	identical(names(x), names(as.list(x, all.names=TRUE)))

is now for an environment 'x'.

One could think to change the default of 'all.names' in 
as.list.environment(.) from FALSE to TRUE,
but that may break code in subtle places and I don't think we
should go there.

Martin


    > On Tue, Jan 27, 2015 at 7:44 AM, Peter Haverty <haverty.peter at gene.com>
    > wrote:

    >> I think that the "sorted" and "all.names" arguments are really only
    >> appropriate for pretty printing to the screen. I think it is a bit
    >> unfortunate that environments have a names accessor that is 60X slower
    >> than all the other types. This is likely due to the history of
    >> environments, which were originally just for behind-the-scenes tasks.
    >> 
    >> Now that users can use environments as hashes, we really need
    >> something like a "keys" function. We don't want programmers depending
    >> on the sorted-ness, as Martin mentioned.  Also, I think it helps users
    >> when objects share as many of the key API functions as possible.
    >> "names" is natural. "ls" was certainly confusing for me when I
    >> started. Having to supply two additional arguments to get the desired
    >> output doesn't help there.  Think of all the perl programmers
    >> struggling to switch to R.  Let's help them out.
    >> Pete
    >> 
    >> ____________________
    >> Peter M. Haverty, Ph.D.
    >> Genentech, Inc.
    >> phaverty at gene.com
    >> 
    >> 
    >> On Tue, Jan 27, 2015 at 7:26 AM, Michael Lawrence
    >> <lawrence.michael at gene.com> wrote:
    >> > I think ls(, sort=FALSE) would be more explicit and thus clearer. There
    >> is
    >> > much precedent for having arguments that request less work to be done
    >> e.g.
    >> > unlist(use.names=FALSE).  Yes, the extra typing is a bit painful, but
    >> there
    >> > is no intuitive reason why names() would be unsorted, while ls() would be
    >> > sorted. While it is tempting to use an existing function for this, the
    >> word
    >> > "names" is somewhat loaded. For example, one might expect
    >> > identical(names(env), names(as.list(env))) to be TRUE. I see no problem
    >> with
    >> > making names() a simple alias of ls(), as long as the behavior is the
    >> same.
    >> > Maybe a different name would be less "loaded" and imply lack of order,
    >> > something like keySet(). But do we really need this?
    >> >
    >> >
    >> >
    >> >
    >> >
    >> >
    >> > On Tue, Jan 27, 2015 at 7:11 AM, Martin Maechler
    >> > <maechler at lynne.stat.math.ethz.ch> wrote:
    >> >>
    >> >> >>>>> Peter Haverty <haverty.peter at gene.com>
    >> >> >>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:
    >> >>
    >> >>     > Hi all,
    >> >>     > The "ls" function wears two hats. It allows users to inspect an
    >> >>     > environment interactively and also serves deeper in code as the
    >> >>     > accessor for an environment's names/keys. I propose that we
    >> separate
    >> >>     > these two conflicting goals, keeping ls for interactive use and
    >> >> adding
    >> >>     > names for a quick listing of the hash keys. This involves adding
    >> two
    >> >>     > lines to do_names in attrib.c.
    >> >>
    >> >>     > The 'ls' function and its 'objects' synonym appear very frequently
    >> >> in
    >> >>     > performance-critical code like base/R/namespace.R and throughout
    >> the
    >> >>     > methods package. These functions are currently among the major
    >> >>     > contributors to execution time in package loading.
    >> >>
    >> >>     > This two-line addition to attrib.c gives a significant speedup for
    >> >>     > listing an environment's names/keys (2-60X depending on the
    >> 'sorted'
    >> >>     > argument). It also simplifies the environment API by making it
    >> more
    >> >>     > like the other basic types. We already have $ and [[ after all.
    >> >>
    >> >>     > Rather than sprinkling sorted=FALSE throughout the methods and
    >> base
    >> >>     > code, let's use names.
    >> >>
    >> >> as for list()s and other (generalized) vectors.
    >> >>
    >> >> This sounds appealing at first, and I have heard/seen others propose
    >> >> it.  I see one good reason *not* to allow it (and you mention the
    >> >> reason by mentioning 'sorted') :
    >> >>
    >> >> The contents of an environment are inherently unordered, and
    >> >> even if the order stays fixed for a while, no code should rely
    >> >> on the ordering of the objects, and for that reason,
    >> >>  <env>[1]  etc do not make sense and are not allowed.
    >> >>
    >> >>     > Would you be open to this change?
    >> >>
    >> >> I'm undecided currently:
    >> >>  "-": reason above;
    >> >>  "+": convenience, compacter R code using it;
    >> >>       very simple and natural change to src/main/attrib.c
    >> >>
    >> >> and waiting for other comments, not the least from other members of R
    >> core
    >> >> ..
    >> >>
    >> >> Martin Maechler, ETH Zurich
    >> >>
    >> >>
    >> >>     > I have submitted a patch and some timings to the bug tracker as
    >> >>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170
    >> >>
    >> >>     > Regards,
    >> >>     > Pete
    >> >>
    >> >>     > ____________________
    >> >>     > Peter M. Haverty, Ph.D.
    >> >>     > Genentech, Inc.
    >> >>     > phaverty at gene.com
    >> >>
    >> >>     > ______________________________________________
    >> >>     > R-devel at r-project.org mailing list
    >> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >>
    >> >> ______________________________________________
    >> >> R-devel at r-project.org mailing list
    >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >
    >> >
    >>


From jmc at r-project.org  Thu Jan 29 14:57:15 2015
From: jmc at r-project.org (John Chambers)
Date: Thu, 29 Jan 2015 05:57:15 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
Message-ID: <4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>


On Jan 28, 2015, at 6:37 PM, Michael Lawrence <lawrence.michael at gene.com> wrote:

> At this point I would just due:
> 
> formals(body(method)[[2L]])
> 
> At some point we need to figure out what to do with this .local() confusion.

Agreed, definitely.  The current hack is to avoid re-matching arguments on method dispatch, so a fix would need to be fairly deep in the implementation.

But I don't think the expression above is quite right. body(method)[[2L]] is the assignment.  You need to evaluate the rhs.

Here is a function that does the same sort of thing, and returns the standard formals for the generic if this method does not have nonstandard arguments.  We should probably add a version of this function for 3.3.0, so user code doesn't have hacks around the current hack.

methodFormals <- function(f, signature = character()) {
    fdef <- getGeneric(f)
    method <- selectMethod(fdef, signature)
    genFormals <- base::formals(fdef)
    b <- body(method)
    if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]], as.name(".local"))) {
        local <- eval(b[[2]][[3]])
        if(is.function(local))
            return(formals(local))
        warning("Expected a .local assignment to be a function. Corrupted method?")
    }
    genFormals
}

> 
> 
> 
> 
> On Wed, Jan 28, 2015 at 10:07 AM, Roebuck,Paul L <PLRoebuck at mdanderson.org>
> wrote:
> 
>> I'm attempting to reflect the information for use with corresponding
>> fields in GUI (in a different package), to provide default values,
>> argname as key for UI label lookups, etc.
>> 
>> So I want something much more like the formals of the implementation:
>> 
>> {
>>    "object",
>>    "method":             c("median", "vs", "tukey"),
>>    "calc.medians":       TRUE,
>>    "sweep.cols":         calc.medians,
>>    "recalc.after.sweep": sweep.cols,
>>    "?"
>> }
>> 
>> not those of the generic:
>> 
>> {
>>    "object",
>>    "?"
>> }
>> 
>> 
>> From:  Michael Lawrence <lawrence.michael at gene.com>
>> Date:  Wednesday, January 28, 2015 11:28 AM
>> To:  "Roebuck,Paul L" <PLRoebuck at mdanderson.org>
>> Cc:  R-devel <r-devel at r-project.org>
>> Subject:  Re: [Rd] [Q] Get formal arguments of my implemented S4 method
>> 
>> 
>> Would you please clarify your exact use case?
>> 
>> 
>> Thanks,
>> Michael
>> 
>> 
>> On Wed, Jan 28, 2015 at 9:02 AM, Roebuck,Paul L
>> <PLRoebuck at mdanderson.org> wrote:
>> 
>> Interrogating some (of my own) code in another package.
>> 
>>> norm.meth <- getMethod("normalize", "MatrixLike")
>>> message("str(norm.meth)")
>>> str(norm.meth)
>> 
>>> message("show(norm.meth at .Data)")
>>> show(norm.meth at .Data)
>> 
>> 
>> Last show() displays this:
>> 
>> function (object, ...)
>> {
>>    .local <- function (object, method = c("median", "vs", "tukey"),
>>        calc.medians = TRUE, sweep.cols = calc.medians,
>>        recalc.after.sweep = sweep.cols, ...)
>>    {
>>        .do_normalize(object,
>>            method = match.arg(method),
>>            calc.medians = calc.medians,
>>            sweep.cols = sweep.cols,
>>            recalc.after.sweep = recalc.after.sweep,
>>            ...)
>>    }
>>    .local(object, ...)
>> }
>> 
>> 
>> Desire to be able to access formals() for the .local() function definition,
>> not the generic one. Have seen information desired available via "defined"
>> slot of returned 'MethodDefinition' object, but not using the code below.
>> 
>> 
>> 
>> ====================
>> 
>> library(methods)
>> 
>> if (!isGeneric("normalize")) {
>>    ## Other packages also define this generic...
>>    setGeneric("normalize",
>>               function(object, ...) standardGeneric("normalize"))
>> }
>> 
>> setClassUnion("MatrixLike", c("matrix", "data.frame"))
>> 
>> .do_normalize <- function(concs,
>>                          method,
>>                          calc.medians,
>>                          sweep.cols,
>>                          recalc.after.sweep,
>>                          ...) {
>>    message("internal routine called!")
>>    NULL
>> }
>> 
>> setMethod("normalize", signature(object="MatrixLike"),
>>          function(object,
>>                   method=c("median", "vs", "tukey"),
>>                   calc.medians=TRUE,
>>                   sweep.cols=calc.medians,
>>                   recalc.after.sweep=sweep.cols,
>>                   ...) {
>> 
>>    .do_normalize <- function(object,
>>                            method=match.arg(method),
>>                            calc.medians=calc.medians,
>>                            sweep.cols=sweep.cols,
>>                            recalc.after.sweep=recalc.after.sweep,
>>                            ...)
>> }
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>> 
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan 29 15:07:14 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 29 Jan 2015 06:07:14 -0800
Subject: [Rd] names function for environments?
In-Reply-To: <21706.15088.949298.673951@stat.math.ethz.ch>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
	<CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
	<CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>
	<CAOQ5NyeH3tedOsd4LdxmoNXQaH0nT324huGn0FKPQ5PzZ2rBHw@mail.gmail.com>
	<21706.15088.949298.673951@stat.math.ethz.ch>
Message-ID: <CAOQ5Nyft+uRSCho4ksX9MSp9P8QJt=nup+iBQ7hkQSxTY0J=Kg@mail.gmail.com>

On Thu, Jan 29, 2015 at 5:51 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:

> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Tue, 27 Jan 2015 07:59:59 -0800 writes:
>
>     > Since the contract of ls() is to sort, there is nothing wrong with
>     > programmers depending on it. And there are many functions that could
> be
>     > made 60X faster, but is it worth it? But I did notice that
>     > as.list.environment has a sorted=FALSE argument already, so I guess
>     > identical(names(x), names(as.list(x))) could be made to be TRUE,
> assuming
>     > the order is at least persistent, if undefined, so that is a nice
> property.
>     > I guess I'm OK it with.
>
> As we ended only hearing "pro"s and no real "con"s,
> I've committed (a corrected version of) the code now.
>
> The above identity is not true in generality though,  but
>
>         identical(names(x), names(as.list(x, all.names=TRUE)))
>
> is now for an environment 'x'.
>
> One could think to change the default of 'all.names' in
> as.list.environment(.) from FALSE to TRUE,
> but that may break code in subtle places and I don't think we
> should go there.
>
>
Yea, but it is super weird that as.list() filters elements out of the
environment during coercion.

I think I'm going to look through the uses of ls() inside of the core
packages, because I suspect that is usually not necessary to extract the
keys, and there is a cleaner (and probably faster) way to achieve the same
result.


> Martin
>
>
>     > On Tue, Jan 27, 2015 at 7:44 AM, Peter Haverty <
> haverty.peter at gene.com>
>     > wrote:
>
>     >> I think that the "sorted" and "all.names" arguments are really only
>     >> appropriate for pretty printing to the screen. I think it is a bit
>     >> unfortunate that environments have a names accessor that is 60X
> slower
>     >> than all the other types. This is likely due to the history of
>     >> environments, which were originally just for behind-the-scenes
> tasks.
>     >>
>     >> Now that users can use environments as hashes, we really need
>     >> something like a "keys" function. We don't want programmers
> depending
>     >> on the sorted-ness, as Martin mentioned.  Also, I think it helps
> users
>     >> when objects share as many of the key API functions as possible.
>     >> "names" is natural. "ls" was certainly confusing for me when I
>     >> started. Having to supply two additional arguments to get the
> desired
>     >> output doesn't help there.  Think of all the perl programmers
>     >> struggling to switch to R.  Let's help them out.
>     >> Pete
>     >>
>     >> ____________________
>     >> Peter M. Haverty, Ph.D.
>     >> Genentech, Inc.
>     >> phaverty at gene.com
>     >>
>     >>
>     >> On Tue, Jan 27, 2015 at 7:26 AM, Michael Lawrence
>     >> <lawrence.michael at gene.com> wrote:
>     >> > I think ls(, sort=FALSE) would be more explicit and thus clearer.
> There
>     >> is
>     >> > much precedent for having arguments that request less work to be
> done
>     >> e.g.
>     >> > unlist(use.names=FALSE).  Yes, the extra typing is a bit painful,
> but
>     >> there
>     >> > is no intuitive reason why names() would be unsorted, while ls()
> would be
>     >> > sorted. While it is tempting to use an existing function for
> this, the
>     >> word
>     >> > "names" is somewhat loaded. For example, one might expect
>     >> > identical(names(env), names(as.list(env))) to be TRUE. I see no
> problem
>     >> with
>     >> > making names() a simple alias of ls(), as long as the behavior is
> the
>     >> same.
>     >> > Maybe a different name would be less "loaded" and imply lack of
> order,
>     >> > something like keySet(). But do we really need this?
>     >> >
>     >> >
>     >> >
>     >> >
>     >> >
>     >> >
>     >> > On Tue, Jan 27, 2015 at 7:11 AM, Martin Maechler
>     >> > <maechler at lynne.stat.math.ethz.ch> wrote:
>     >> >>
>     >> >> >>>>> Peter Haverty <haverty.peter at gene.com>
>     >> >> >>>>>     on Sun, 25 Jan 2015 12:21:04 -0800 writes:
>     >> >>
>     >> >>     > Hi all,
>     >> >>     > The "ls" function wears two hats. It allows users to
> inspect an
>     >> >>     > environment interactively and also serves deeper in code
> as the
>     >> >>     > accessor for an environment's names/keys. I propose that we
>     >> separate
>     >> >>     > these two conflicting goals, keeping ls for interactive
> use and
>     >> >> adding
>     >> >>     > names for a quick listing of the hash keys. This involves
> adding
>     >> two
>     >> >>     > lines to do_names in attrib.c.
>     >> >>
>     >> >>     > The 'ls' function and its 'objects' synonym appear very
> frequently
>     >> >> in
>     >> >>     > performance-critical code like base/R/namespace.R and
> throughout
>     >> the
>     >> >>     > methods package. These functions are currently among the
> major
>     >> >>     > contributors to execution time in package loading.
>     >> >>
>     >> >>     > This two-line addition to attrib.c gives a significant
> speedup for
>     >> >>     > listing an environment's names/keys (2-60X depending on the
>     >> 'sorted'
>     >> >>     > argument). It also simplifies the environment API by
> making it
>     >> more
>     >> >>     > like the other basic types. We already have $ and [[ after
> all.
>     >> >>
>     >> >>     > Rather than sprinkling sorted=FALSE throughout the methods
> and
>     >> base
>     >> >>     > code, let's use names.
>     >> >>
>     >> >> as for list()s and other (generalized) vectors.
>     >> >>
>     >> >> This sounds appealing at first, and I have heard/seen others
> propose
>     >> >> it.  I see one good reason *not* to allow it (and you mention the
>     >> >> reason by mentioning 'sorted') :
>     >> >>
>     >> >> The contents of an environment are inherently unordered, and
>     >> >> even if the order stays fixed for a while, no code should rely
>     >> >> on the ordering of the objects, and for that reason,
>     >> >>  <env>[1]  etc do not make sense and are not allowed.
>     >> >>
>     >> >>     > Would you be open to this change?
>     >> >>
>     >> >> I'm undecided currently:
>     >> >>  "-": reason above;
>     >> >>  "+": convenience, compacter R code using it;
>     >> >>       very simple and natural change to src/main/attrib.c
>     >> >>
>     >> >> and waiting for other comments, not the least from other members
> of R
>     >> core
>     >> >> ..
>     >> >>
>     >> >> Martin Maechler, ETH Zurich
>     >> >>
>     >> >>
>     >> >>     > I have submitted a patch and some timings to the bug
> tracker as
>     >> >>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16170
>     >> >>
>     >> >>     > Regards,
>     >> >>     > Pete
>     >> >>
>     >> >>     > ____________________
>     >> >>     > Peter M. Haverty, Ph.D.
>     >> >>     > Genentech, Inc.
>     >> >>     > phaverty at gene.com
>     >> >>
>     >> >>     > ______________________________________________
>     >> >>     > R-devel at r-project.org mailing list
>     >> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> >>
>     >> >> ______________________________________________
>     >> >> R-devel at r-project.org mailing list
>     >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> >
>     >> >
>     >>
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan 29 15:17:23 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 29 Jan 2015 06:17:23 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
Message-ID: <CAOQ5NycBgy2BFU4eTw=bDHauTJgoXx4reXXy9KTjheUaid+Euw@mail.gmail.com>

On Thu, Jan 29, 2015 at 5:57 AM, John Chambers <jmc at r-project.org> wrote:

>
> On Jan 28, 2015, at 6:37 PM, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>
> At this point I would just due:
>
> formals(body(method)[[2L]])
>
> At some point we need to figure out what to do with this .local()
> confusion.
>
>
> Agreed, definitely.  The current hack is to avoid re-matching arguments on
> method dispatch, so a fix would need to be fairly deep in the
> implementation.
>
> But I don't think the expression above is quite right. body(method)[[2L]]
> is the assignment.  You need to evaluate the rhs.
>
>
Sorry, thanks for the catch.


> Here is a function that does the same sort of thing, and returns the
> standard formals for the generic if this method does not have nonstandard
> arguments.  We should probably add a version of this function for 3.3.0, so
> user code doesn't have hacks around the current hack.
>
> methodFormals <- function(f, signature = character()) {
>     fdef <- getGeneric(f)
>     method <- selectMethod(fdef, signature)
>     genFormals <- base::formals(fdef)
>     b <- body(method)
>     if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]], as.name(".local")))
> {
>         local <- eval(b[[2]][[3]])
>         if(is.function(local))
>             return(formals(local))
>         warning("Expected a .local assignment to be a function. Corrupted
> method?")
>     }
>     genFormals
> }
>
>
Yea, I had thought about having that, or a more general getMethodFunction()
on which formals() could be called. I held back though, because I thought
it might be best to address the .local issue, instead of introducing
additional API components that would otherwise be unnecessary.


>
>
>
> On Wed, Jan 28, 2015 at 10:07 AM, Roebuck,Paul L <PLRoebuck at mdanderson.org
> >
> wrote:
>
> I'm attempting to reflect the information for use with corresponding
> fields in GUI (in a different package), to provide default values,
> argname as key for UI label lookups, etc.
>
> So I want something much more like the formals of the implementation:
>
> {
>    "object",
>    "method":             c("median", "vs", "tukey"),
>    "calc.medians":       TRUE,
>    "sweep.cols":         calc.medians,
>    "recalc.after.sweep": sweep.cols,
>    "?"
> }
>
> not those of the generic:
>
> {
>    "object",
>    "?"
> }
>
>
> From:  Michael Lawrence <lawrence.michael at gene.com>
> Date:  Wednesday, January 28, 2015 11:28 AM
> To:  "Roebuck,Paul L" <PLRoebuck at mdanderson.org>
> Cc:  R-devel <r-devel at r-project.org>
> Subject:  Re: [Rd] [Q] Get formal arguments of my implemented S4 method
>
>
> Would you please clarify your exact use case?
>
>
> Thanks,
> Michael
>
>
> On Wed, Jan 28, 2015 at 9:02 AM, Roebuck,Paul L
> <PLRoebuck at mdanderson.org> wrote:
>
> Interrogating some (of my own) code in another package.
>
> norm.meth <- getMethod("normalize", "MatrixLike")
> message("str(norm.meth)")
> str(norm.meth)
>
>
> message("show(norm.meth at .Data)")
> show(norm.meth at .Data)
>
>
>
> Last show() displays this:
>
> function (object, ...)
> {
>    .local <- function (object, method = c("median", "vs", "tukey"),
>        calc.medians = TRUE, sweep.cols = calc.medians,
>        recalc.after.sweep = sweep.cols, ...)
>    {
>        .do_normalize(object,
>            method = match.arg(method),
>            calc.medians = calc.medians,
>            sweep.cols = sweep.cols,
>            recalc.after.sweep = recalc.after.sweep,
>            ...)
>    }
>    .local(object, ...)
> }
>
>
> Desire to be able to access formals() for the .local() function definition,
> not the generic one. Have seen information desired available via "defined"
> slot of returned 'MethodDefinition' object, but not using the code below.
>
>
>
> ====================
>
> library(methods)
>
> if (!isGeneric("normalize")) {
>    ## Other packages also define this generic...
>    setGeneric("normalize",
>               function(object, ...) standardGeneric("normalize"))
> }
>
> setClassUnion("MatrixLike", c("matrix", "data.frame"))
>
> .do_normalize <- function(concs,
>                          method,
>                          calc.medians,
>                          sweep.cols,
>                          recalc.after.sweep,
>                          ...) {
>    message("internal routine called!")
>    NULL
> }
>
> setMethod("normalize", signature(object="MatrixLike"),
>          function(object,
>                   method=c("median", "vs", "tukey"),
>                   calc.medians=TRUE,
>                   sweep.cols=calc.medians,
>                   recalc.after.sweep=sweep.cols,
>                   ...) {
>
>    .do_normalize <- function(object,
>                            method=match.arg(method),
>                            calc.medians=calc.medians,
>                            sweep.cols=sweep.cols,
>                            recalc.after.sweep=recalc.after.sweep,
>                            ...)
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Jan 29 15:34:34 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Jan 2015 08:34:34 -0600
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
Message-ID: <CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>

On Thu, Jan 29, 2015 at 7:57 AM, John Chambers <jmc at r-project.org> wrote:
>
> On Jan 28, 2015, at 6:37 PM, Michael Lawrence <lawrence.michael at gene.com> wrote:
>
>> At this point I would just due:
>>
>> formals(body(method)[[2L]])
>>
>> At some point we need to figure out what to do with this .local() confusion.
>
> Agreed, definitely.  The current hack is to avoid re-matching arguments on method dispatch, so a fix would need to be fairly deep in the implementation.
>
> But I don't think the expression above is quite right. body(method)[[2L]] is the assignment.  You need to evaluate the rhs.
>
> Here is a function that does the same sort of thing, and returns the standard formals for the generic if this method does not have nonstandard arguments.  We should probably add a version of this function for 3.3.0, so user code doesn't have hacks around the current hack.
>
> methodFormals <- function(f, signature = character()) {
>     fdef <- getGeneric(f)
>     method <- selectMethod(fdef, signature)
>     genFormals <- base::formals(fdef)
>     b <- body(method)
>     if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]], as.name(".local"))) {
>         local <- eval(b[[2]][[3]])
>         if(is.function(local))
>             return(formals(local))
>         warning("Expected a .local assignment to be a function. Corrupted method?")
>     }
>     genFormals
> }

I have similar code in roxygen2:

# When a generic has ... and a method adds new arguments, the S4 method
# wraps the definition inside another function which has the same arguments
# as the generic. This function figures out if that's the case, and extracts
# the original function if so.
#
# It's based on expression processing based on the structure of the
# constructed method which looks like:
#
# function (x, ...) {
#   .local <- function (x, ..., y = 7) {}
#   .local(x, ...)
# }
extract_method_fun <- function(x) {
  fun <- x at .Data

  method_body <- body(fun)
  if (!is.call(method_body)) return(fun)
  if (!identical(method_body[[1]], quote(`{`))) return(fun)

  first_line <- method_body[[2]]
  if (!is.call(first_line)) return(fun)
  if (!identical(first_line[[1]], quote(`<-`))) return(fun)
  if (!identical(first_line[[2]], quote(`.local`))) return(fun)

  first_line[[3]]
}


-- 
http://had.co.nz/


From wdunlap at tibco.com  Thu Jan 29 17:08:40 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 29 Jan 2015 08:08:40 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
	<CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>
Message-ID: <CAF8bMcZGVWdtGgLwbOkKmMy_2xXB9-oMOHLQaAjojmnAViDyzQ@mail.gmail.com>

I wish it didn't have to depend on the name '.local'.

Back when I wrote a lot of S4 methods I avoided the auto-generated .local
and named the local function something that made sense so that is was easier
for a user to track down the source of an error.

E.g., define the generic QQQ with numeric and integer methods:
setGeneric("QQQ",
           function(x, ...)NULL)
setMethod("QQQ",
          signature=signature(x="numeric"),
          function(x, lower, ...) {
              if (x<lower) stop("x<lower")
          })
setMethod("QQQ",
          signature=signature(x="integer"),
          function(x, ...) {
              .QQQ.integer <- function(x, lower, ...) if (x<lower)
stop("x<lower")
              .QQQ.integer(x, ...)
          })
and try using them:
  > QQQ(3.4, 10)
  Error in .local(x, ...) : x<lower
  > traceback()
  4: stop("x<lower") at #4
  3: .local(x, ...)
  2: QQQ(3.4, 10)
  1: QQQ(3.4, 10)
  > QQQ(3L, 10)
  Error in .QQQ.integer(x, ...) : x<lower
  > traceback()
  4: stop("x<lower") at #4
  3: .QQQ.integer(x, ...) at #5
  2: QQQ(3L, 10)
  1: QQQ(3L, 10)
I think the latter gives the user more guidance on how to fix the problem.

Perhaps instead of searching for an assignment to '.local' you could
search for an assignment to the name of the function used in the last
function call of the method.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jan 29, 2015 at 6:34 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> On Thu, Jan 29, 2015 at 7:57 AM, John Chambers <jmc at r-project.org> wrote:
> >
> > On Jan 28, 2015, at 6:37 PM, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
> >
> >> At this point I would just due:
> >>
> >> formals(body(method)[[2L]])
> >>
> >> At some point we need to figure out what to do with this .local()
> confusion.
> >
> > Agreed, definitely.  The current hack is to avoid re-matching arguments
> on method dispatch, so a fix would need to be fairly deep in the
> implementation.
> >
> > But I don't think the expression above is quite right.
> body(method)[[2L]] is the assignment.  You need to evaluate the rhs.
> >
> > Here is a function that does the same sort of thing, and returns the
> standard formals for the generic if this method does not have nonstandard
> arguments.  We should probably add a version of this function for 3.3.0, so
> user code doesn't have hacks around the current hack.
> >
> > methodFormals <- function(f, signature = character()) {
> >     fdef <- getGeneric(f)
> >     method <- selectMethod(fdef, signature)
> >     genFormals <- base::formals(fdef)
> >     b <- body(method)
> >     if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]], as.name(".local")))
> {
> >         local <- eval(b[[2]][[3]])
> >         if(is.function(local))
> >             return(formals(local))
> >         warning("Expected a .local assignment to be a function.
> Corrupted method?")
> >     }
> >     genFormals
> > }
>
> I have similar code in roxygen2:
>
> # When a generic has ... and a method adds new arguments, the S4 method
> # wraps the definition inside another function which has the same arguments
> # as the generic. This function figures out if that's the case, and
> extracts
> # the original function if so.
> #
> # It's based on expression processing based on the structure of the
> # constructed method which looks like:
> #
> # function (x, ...) {
> #   .local <- function (x, ..., y = 7) {}
> #   .local(x, ...)
> # }
> extract_method_fun <- function(x) {
>   fun <- x at .Data
>
>   method_body <- body(fun)
>   if (!is.call(method_body)) return(fun)
>   if (!identical(method_body[[1]], quote(`{`))) return(fun)
>
>   first_line <- method_body[[2]]
>   if (!is.call(first_line)) return(fun)
>   if (!identical(first_line[[1]], quote(`<-`))) return(fun)
>   if (!identical(first_line[[2]], quote(`.local`))) return(fun)
>
>   first_line[[3]]
> }
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jmc at r-project.org  Thu Jan 29 18:41:15 2015
From: jmc at r-project.org (John Chambers)
Date: Thu, 29 Jan 2015 09:41:15 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <CAF8bMcZGVWdtGgLwbOkKmMy_2xXB9-oMOHLQaAjojmnAViDyzQ@mail.gmail.com>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
	<CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>
	<CAF8bMcZGVWdtGgLwbOkKmMy_2xXB9-oMOHLQaAjojmnAViDyzQ@mail.gmail.com>
Message-ID: <B7ED848B-E850-4E92-AE72-489BE6D1162E@r-project.org>

I wouldn't want to add more to the current approach; if someone would like to devote some time, the much preferable idea IMO would be to replace the whole mechanism.

Here's one suggestion:

1.  have a class, say "nonConformingMethod" for method definitions that diverge in the argument list.

2. the internal dispatch code checks the class of the selected definition (this can likely be done with little cost in the standard case).   In the case of non-conforming, the arguments are rematched to define the method's other arguments.

The possibilities need examining, but my feeling is that the re-matching should happen in the current frame, as opposed to doing a new call.

There is a fair amount of code, for example in callNextMethod, that requires some computations using knowledge of the current mechanism.  If at some point we required re-installing all packages using non-conforming methods, that code could be made simpler and faster.

John




On Jan 29, 2015, at 8:08 AM, William Dunlap <wdunlap at tibco.com> wrote:

> I wish it didn't have to depend on the name '.local'.
> 
> Back when I wrote a lot of S4 methods I avoided the auto-generated .local
> and named the local function something that made sense so that is was easier
> for a user to track down the source of an error.
> 
> E.g., define the generic QQQ with numeric and integer methods:
> setGeneric("QQQ",
>            function(x, ...)NULL)
> setMethod("QQQ",
>           signature=signature(x="numeric"),
>           function(x, lower, ...) {
>               if (x<lower) stop("x<lower")
>           })
> setMethod("QQQ",
>           signature=signature(x="integer"),
>           function(x, ...) {
>               .QQQ.integer <- function(x, lower, ...) if (x<lower) stop("x<lower")
>               .QQQ.integer(x, ...)
>           })
> and try using them:
>   > QQQ(3.4, 10)
>   Error in .local(x, ...) : x<lower
>   > traceback()
>   4: stop("x<lower") at #4
>   3: .local(x, ...)
>   2: QQQ(3.4, 10)
>   1: QQQ(3.4, 10)
>   > QQQ(3L, 10)
>   Error in .QQQ.integer(x, ...) : x<lower
>   > traceback()
>   4: stop("x<lower") at #4
>   3: .QQQ.integer(x, ...) at #5
>   2: QQQ(3L, 10)
>   1: QQQ(3L, 10)
> I think the latter gives the user more guidance on how to fix the problem.
> 
> Perhaps instead of searching for an assignment to '.local' you could
> search for an assignment to the name of the function used in the last
> function call of the method.
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Jan 29, 2015 at 6:34 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> On Thu, Jan 29, 2015 at 7:57 AM, John Chambers <jmc at r-project.org> wrote:
> >
> > On Jan 28, 2015, at 6:37 PM, Michael Lawrence <lawrence.michael at gene.com> wrote:
> >
> >> At this point I would just due:
> >>
> >> formals(body(method)[[2L]])
> >>
> >> At some point we need to figure out what to do with this .local() confusion.
> >
> > Agreed, definitely.  The current hack is to avoid re-matching arguments on method dispatch, so a fix would need to be fairly deep in the implementation.
> >
> > But I don't think the expression above is quite right. body(method)[[2L]] is the assignment.  You need to evaluate the rhs.
> >
> > Here is a function that does the same sort of thing, and returns the standard formals for the generic if this method does not have nonstandard arguments.  We should probably add a version of this function for 3.3.0, so user code doesn't have hacks around the current hack.
> >
> > methodFormals <- function(f, signature = character()) {
> >     fdef <- getGeneric(f)
> >     method <- selectMethod(fdef, signature)
> >     genFormals <- base::formals(fdef)
> >     b <- body(method)
> >     if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]], as.name(".local"))) {
> >         local <- eval(b[[2]][[3]])
> >         if(is.function(local))
> >             return(formals(local))
> >         warning("Expected a .local assignment to be a function. Corrupted method?")
> >     }
> >     genFormals
> > }
> 
> I have similar code in roxygen2:
> 
> # When a generic has ... and a method adds new arguments, the S4 method
> # wraps the definition inside another function which has the same arguments
> # as the generic. This function figures out if that's the case, and extracts
> # the original function if so.
> #
> # It's based on expression processing based on the structure of the
> # constructed method which looks like:
> #
> # function (x, ...) {
> #   .local <- function (x, ..., y = 7) {}
> #   .local(x, ...)
> # }
> extract_method_fun <- function(x) {
>   fun <- x at .Data
> 
>   method_body <- body(fun)
>   if (!is.call(method_body)) return(fun)
>   if (!identical(method_body[[1]], quote(`{`))) return(fun)
> 
>   first_line <- method_body[[2]]
>   if (!is.call(first_line)) return(fun)
>   if (!identical(first_line[[1]], quote(`<-`))) return(fun)
>   if (!identical(first_line[[2]], quote(`.local`))) return(fun)
> 
>   first_line[[3]]
> }
> 
> 
> --
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu Jan 29 18:57:14 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 29 Jan 2015 09:57:14 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <B7ED848B-E850-4E92-AE72-489BE6D1162E@r-project.org>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
	<CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>
	<CAF8bMcZGVWdtGgLwbOkKmMy_2xXB9-oMOHLQaAjojmnAViDyzQ@mail.gmail.com>
	<B7ED848B-E850-4E92-AE72-489BE6D1162E@r-project.org>
Message-ID: <CAOQ5NyeHO4YxgmWFrk+Ov_mEFc-r_eo3M4mKeAnQdBo=n53=WQ@mail.gmail.com>

Would we really need the special class or would simply checking the formals
of the method against those of the generic be simple and fast enough?

On Thu, Jan 29, 2015 at 9:41 AM, John Chambers <jmc at r-project.org> wrote:

> I wouldn't want to add more to the current approach; if someone would like
> to devote some time, the much preferable idea IMO would be to replace the
> whole mechanism.
>
> Here's one suggestion:
>
> 1.  have a class, say "nonConformingMethod" for method definitions that
> diverge in the argument list.
>
> 2. the internal dispatch code checks the class of the selected definition
> (this can likely be done with little cost in the standard case).   In the
> case of non-conforming, the arguments are rematched to define the method's
> other arguments.
>
> The possibilities need examining, but my feeling is that the re-matching
> should happen in the current frame, as opposed to doing a new call.
>
> There is a fair amount of code, for example in callNextMethod, that
> requires some computations using knowledge of the current mechanism.  If at
> some point we required re-installing all packages using non-conforming
> methods, that code could be made simpler and faster.
>
> John
>
>
>
>
> On Jan 29, 2015, at 8:08 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
> > I wish it didn't have to depend on the name '.local'.
> >
> > Back when I wrote a lot of S4 methods I avoided the auto-generated .local
> > and named the local function something that made sense so that is was
> easier
> > for a user to track down the source of an error.
> >
> > E.g., define the generic QQQ with numeric and integer methods:
> > setGeneric("QQQ",
> >            function(x, ...)NULL)
> > setMethod("QQQ",
> >           signature=signature(x="numeric"),
> >           function(x, lower, ...) {
> >               if (x<lower) stop("x<lower")
> >           })
> > setMethod("QQQ",
> >           signature=signature(x="integer"),
> >           function(x, ...) {
> >               .QQQ.integer <- function(x, lower, ...) if (x<lower)
> stop("x<lower")
> >               .QQQ.integer(x, ...)
> >           })
> > and try using them:
> >   > QQQ(3.4, 10)
> >   Error in .local(x, ...) : x<lower
> >   > traceback()
> >   4: stop("x<lower") at #4
> >   3: .local(x, ...)
> >   2: QQQ(3.4, 10)
> >   1: QQQ(3.4, 10)
> >   > QQQ(3L, 10)
> >   Error in .QQQ.integer(x, ...) : x<lower
> >   > traceback()
> >   4: stop("x<lower") at #4
> >   3: .QQQ.integer(x, ...) at #5
> >   2: QQQ(3L, 10)
> >   1: QQQ(3L, 10)
> > I think the latter gives the user more guidance on how to fix the
> problem.
> >
> > Perhaps instead of searching for an assignment to '.local' you could
> > search for an assignment to the name of the function used in the last
> > function call of the method.
> >
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, Jan 29, 2015 at 6:34 AM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
> > On Thu, Jan 29, 2015 at 7:57 AM, John Chambers <jmc at r-project.org>
> wrote:
> > >
> > > On Jan 28, 2015, at 6:37 PM, Michael Lawrence <
> lawrence.michael at gene.com> wrote:
> > >
> > >> At this point I would just due:
> > >>
> > >> formals(body(method)[[2L]])
> > >>
> > >> At some point we need to figure out what to do with this .local()
> confusion.
> > >
> > > Agreed, definitely.  The current hack is to avoid re-matching
> arguments on method dispatch, so a fix would need to be fairly deep in the
> implementation.
> > >
> > > But I don't think the expression above is quite right.
> body(method)[[2L]] is the assignment.  You need to evaluate the rhs.
> > >
> > > Here is a function that does the same sort of thing, and returns the
> standard formals for the generic if this method does not have nonstandard
> arguments.  We should probably add a version of this function for 3.3.0, so
> user code doesn't have hacks around the current hack.
> > >
> > > methodFormals <- function(f, signature = character()) {
> > >     fdef <- getGeneric(f)
> > >     method <- selectMethod(fdef, signature)
> > >     genFormals <- base::formals(fdef)
> > >     b <- body(method)
> > >     if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]],
> as.name(".local"))) {
> > >         local <- eval(b[[2]][[3]])
> > >         if(is.function(local))
> > >             return(formals(local))
> > >         warning("Expected a .local assignment to be a function.
> Corrupted method?")
> > >     }
> > >     genFormals
> > > }
> >
> > I have similar code in roxygen2:
> >
> > # When a generic has ... and a method adds new arguments, the S4 method
> > # wraps the definition inside another function which has the same
> arguments
> > # as the generic. This function figures out if that's the case, and
> extracts
> > # the original function if so.
> > #
> > # It's based on expression processing based on the structure of the
> > # constructed method which looks like:
> > #
> > # function (x, ...) {
> > #   .local <- function (x, ..., y = 7) {}
> > #   .local(x, ...)
> > # }
> > extract_method_fun <- function(x) {
> >   fun <- x at .Data
> >
> >   method_body <- body(fun)
> >   if (!is.call(method_body)) return(fun)
> >   if (!identical(method_body[[1]], quote(`{`))) return(fun)
> >
> >   first_line <- method_body[[2]]
> >   if (!is.call(first_line)) return(fun)
> >   if (!identical(first_line[[1]], quote(`<-`))) return(fun)
> >   if (!identical(first_line[[2]], quote(`.local`))) return(fun)
> >
> >   first_line[[3]]
> > }
> >
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jmc at r-project.org  Thu Jan 29 19:06:43 2015
From: jmc at r-project.org (John Chambers)
Date: Thu, 29 Jan 2015 10:06:43 -0800
Subject: [Rd] [Q] Get formal arguments of my implemented S4 method
In-Reply-To: <CAOQ5NyeHO4YxgmWFrk+Ov_mEFc-r_eo3M4mKeAnQdBo=n53=WQ@mail.gmail.com>
References: <D0EE7317.B896E%proebuck@mdanderson.org>
	<CAOQ5NycvSXb4OQcO_rdWYpFz-5gLWepJHa+jT6MqDBM6xt=FkQ@mail.gmail.com>
	<D0EE7C23.B8A11%proebuck@mdanderson.org>
	<CAOQ5NyenjOHjGt+hnFGa2mMnhUN34weFN1kxrLKaG=LrbWpuJg@mail.gmail.com>
	<4D044AA9-AD74-4A6A-9D43-69C7961BE2D2@r-project.org>
	<CABdHhvHRO2+tP+hybZx9csEts0kEiu-3k2e9AYv6NZwHWJpt=w@mail.gmail.com>
	<CAF8bMcZGVWdtGgLwbOkKmMy_2xXB9-oMOHLQaAjojmnAViDyzQ@mail.gmail.com>
	<B7ED848B-E850-4E92-AE72-489BE6D1162E@r-project.org>
	<CAOQ5NyeHO4YxgmWFrk+Ov_mEFc-r_eo3M4mKeAnQdBo=n53=WQ@mail.gmail.com>
Message-ID: <681FA277-C657-4F31-970F-1B2EF7882B1C@r-project.org>

Some experimenting is needed.  But I think a subclass is likely to be cleaner.  The official model is that methods and generic differ only in the body, so having an object-based way to say that some methods are non-conforming feels more natural to me.

On Jan 29, 2015, at 9:57 AM, Michael Lawrence <lawrence.michael at gene.com> wrote:

> Would we really need the special class or would simply checking the formals
> of the method against those of the generic be simple and fast enough?
> 
> On Thu, Jan 29, 2015 at 9:41 AM, John Chambers <jmc at r-project.org> wrote:
> 
>> I wouldn't want to add more to the current approach; if someone would like
>> to devote some time, the much preferable idea IMO would be to replace the
>> whole mechanism.
>> 
>> Here's one suggestion:
>> 
>> 1.  have a class, say "nonConformingMethod" for method definitions that
>> diverge in the argument list.
>> 
>> 2. the internal dispatch code checks the class of the selected definition
>> (this can likely be done with little cost in the standard case).   In the
>> case of non-conforming, the arguments are rematched to define the method's
>> other arguments.
>> 
>> The possibilities need examining, but my feeling is that the re-matching
>> should happen in the current frame, as opposed to doing a new call.
>> 
>> There is a fair amount of code, for example in callNextMethod, that
>> requires some computations using knowledge of the current mechanism.  If at
>> some point we required re-installing all packages using non-conforming
>> methods, that code could be made simpler and faster.
>> 
>> John
>> 
>> 
>> 
>> 
>> On Jan 29, 2015, at 8:08 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> 
>>> I wish it didn't have to depend on the name '.local'.
>>> 
>>> Back when I wrote a lot of S4 methods I avoided the auto-generated .local
>>> and named the local function something that made sense so that is was
>> easier
>>> for a user to track down the source of an error.
>>> 
>>> E.g., define the generic QQQ with numeric and integer methods:
>>> setGeneric("QQQ",
>>>           function(x, ...)NULL)
>>> setMethod("QQQ",
>>>          signature=signature(x="numeric"),
>>>          function(x, lower, ...) {
>>>              if (x<lower) stop("x<lower")
>>>          })
>>> setMethod("QQQ",
>>>          signature=signature(x="integer"),
>>>          function(x, ...) {
>>>              .QQQ.integer <- function(x, lower, ...) if (x<lower)
>> stop("x<lower")
>>>              .QQQ.integer(x, ...)
>>>          })
>>> and try using them:
>>>> QQQ(3.4, 10)
>>>  Error in .local(x, ...) : x<lower
>>>> traceback()
>>>  4: stop("x<lower") at #4
>>>  3: .local(x, ...)
>>>  2: QQQ(3.4, 10)
>>>  1: QQQ(3.4, 10)
>>>> QQQ(3L, 10)
>>>  Error in .QQQ.integer(x, ...) : x<lower
>>>> traceback()
>>>  4: stop("x<lower") at #4
>>>  3: .QQQ.integer(x, ...) at #5
>>>  2: QQQ(3L, 10)
>>>  1: QQQ(3L, 10)
>>> I think the latter gives the user more guidance on how to fix the
>> problem.
>>> 
>>> Perhaps instead of searching for an assignment to '.local' you could
>>> search for an assignment to the name of the function used in the last
>>> function call of the method.
>>> 
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> On Thu, Jan 29, 2015 at 6:34 AM, Hadley Wickham <h.wickham at gmail.com>
>> wrote:
>>> On Thu, Jan 29, 2015 at 7:57 AM, John Chambers <jmc at r-project.org>
>> wrote:
>>>> 
>>>> On Jan 28, 2015, at 6:37 PM, Michael Lawrence <
>> lawrence.michael at gene.com> wrote:
>>>> 
>>>>> At this point I would just due:
>>>>> 
>>>>> formals(body(method)[[2L]])
>>>>> 
>>>>> At some point we need to figure out what to do with this .local()
>> confusion.
>>>> 
>>>> Agreed, definitely.  The current hack is to avoid re-matching
>> arguments on method dispatch, so a fix would need to be fairly deep in the
>> implementation.
>>>> 
>>>> But I don't think the expression above is quite right.
>> body(method)[[2L]] is the assignment.  You need to evaluate the rhs.
>>>> 
>>>> Here is a function that does the same sort of thing, and returns the
>> standard formals for the generic if this method does not have nonstandard
>> arguments.  We should probably add a version of this function for 3.3.0, so
>> user code doesn't have hacks around the current hack.
>>>> 
>>>> methodFormals <- function(f, signature = character()) {
>>>>    fdef <- getGeneric(f)
>>>>    method <- selectMethod(fdef, signature)
>>>>    genFormals <- base::formals(fdef)
>>>>    b <- body(method)
>>>>    if(is(b, "{") && is(b[[2]], "<-") && identical(b[[2]][[2]],
>> as.name(".local"))) {
>>>>        local <- eval(b[[2]][[3]])
>>>>        if(is.function(local))
>>>>            return(formals(local))
>>>>        warning("Expected a .local assignment to be a function.
>> Corrupted method?")
>>>>    }
>>>>    genFormals
>>>> }
>>> 
>>> I have similar code in roxygen2:
>>> 
>>> # When a generic has ... and a method adds new arguments, the S4 method
>>> # wraps the definition inside another function which has the same
>> arguments
>>> # as the generic. This function figures out if that's the case, and
>> extracts
>>> # the original function if so.
>>> #
>>> # It's based on expression processing based on the structure of the
>>> # constructed method which looks like:
>>> #
>>> # function (x, ...) {
>>> #   .local <- function (x, ..., y = 7) {}
>>> #   .local(x, ...)
>>> # }
>>> extract_method_fun <- function(x) {
>>>  fun <- x at .Data
>>> 
>>>  method_body <- body(fun)
>>>  if (!is.call(method_body)) return(fun)
>>>  if (!identical(method_body[[1]], quote(`{`))) return(fun)
>>> 
>>>  first_line <- method_body[[2]]
>>>  if (!is.call(first_line)) return(fun)
>>>  if (!identical(first_line[[1]], quote(`<-`))) return(fun)
>>>  if (!identical(first_line[[2]], quote(`.local`))) return(fun)
>>> 
>>>  first_line[[3]]
>>> }
>>> 
>>> 
>>> --
>>> http://had.co.nz/
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu Jan 29 19:33:15 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Jan 2015 12:33:15 -0600
Subject: [Rd] names function for environments?
In-Reply-To: <CAOQ5Nyft+uRSCho4ksX9MSp9P8QJt=nup+iBQ7hkQSxTY0J=Kg@mail.gmail.com>
References: <CAGh0NYo++Gn8dPoGXXgygoGXWpZ-XjaARW9jTHAsF4cvncB+mw@mail.gmail.com>
	<21703.43677.632521.343906@stat.math.ethz.ch>
	<CAOQ5NycNg+iU31bgkD+ZXNu2NiZ2NqSEiwyar-5iqtF+8JkK1A@mail.gmail.com>
	<CAGh0NYq=Py+MkEHEwM8fkttEDEjmxTcno9xvFuzRVRjL3nNH0w@mail.gmail.com>
	<CAOQ5NyeH3tedOsd4LdxmoNXQaH0nT324huGn0FKPQ5PzZ2rBHw@mail.gmail.com>
	<21706.15088.949298.673951@stat.math.ethz.ch>
	<CAOQ5Nyft+uRSCho4ksX9MSp9P8QJt=nup+iBQ7hkQSxTY0J=Kg@mail.gmail.com>
Message-ID: <CABdHhvEGSDjRGPujBMHuQCCjAiNyThp7s6KOLDL_0vNdbAwOCA@mail.gmail.com>

> Yea, but it is super weird that as.list() filters elements out of the
> environment during coercion.
>
> I think I'm going to look through the uses of ls() inside of the core
> packages, because I suspect that is usually not necessary to extract the
> keys, and there is a cleaner (and probably faster) way to achieve the same
> result.

It would be nice to have a function that generalised over exists("x",
env = y) and "x" %in% names(y).

Hadley


-- 
http://had.co.nz/


From liguowei1991 at gmail.com  Sat Jan 31 15:15:46 2015
From: liguowei1991 at gmail.com (eigen)
Date: Sat, 31 Jan 2015 06:15:46 -0800 (PST)
Subject: [Rd] error code 1 from Lapack routine 'dsyevr'
Message-ID: <1422713746884-4702571.post@n4.nabble.com>

Hi, 

I got an error message in my program saying 

"Error in eigen(gene_intersection.kernel) : 
  error code 1 from Lapack routine 'dsyevr' 
Execution halted". 

As you see, I was trying to compute the eigenvalues of a matrix but got this
error. Is there anyone who knows what this error means and how I can fix it?
Theoretically the eigenvalues should be nonnegative, if it helps. 

Thank you! 



--
View this message in context: http://r.789695.n4.nabble.com/error-code-1-from-Lapack-routine-dsyevr-tp4702571.html
Sent from the R devel mailing list archive at Nabble.com.


