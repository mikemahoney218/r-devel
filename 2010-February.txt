From ripley at stats.ox.ac.uk  Mon Feb  1 11:35:00 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Feb 2010 10:35:00 +0000 (GMT)
Subject: [Rd] Mksetup() limited to hashing with 32 bits
In-Reply-To: <4B4E7D2F.5060904@gmail.com>
References: <4B4E7D2F.5060904@gmail.com>
Message-ID: <alpine.LFD.2.00.1001151357440.8929@gannet.stats.ox.ac.uk>

On Wed, 13 Jan 2010, Benjamin Tyner wrote:

> The MKsetup() in unique.c throws an error if the vector to be hashed is 
> longer than (2^32)/8:
>
>   if(n < 0 || n > 536870912) /* protect against overflow to -ve */
>       error(_("length %d is too large for hashing"), n);
>
> I occasionally work with vectors longer than this on 64-bit builds. Would it 
> be too much to ask that R can take advantage of all 64 bits for hashing when 
> compiled as such?

'All 64 bits' of what?  All systems we use have 64 bit integer types, 
but there are good reasons not to use them where not needed, and 'int' 
is not 64-bit on any R platform.  I don't see the connection to 64-bit 
pointers, which is what is most often meant by a '64-bit build'.

Efficiency would be a major consideration with such long vectors. 
What type(s) are you contemplating, and are they full of duplicates? 
If the latter, we could simply allow K=29.  Otherwise likely a new 
approach would be needed.

I think the way forward is for you to do some experiments and submit 
proposed code changes with supporting evidence.  (It seems only you is 
interested.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peter.ruckdeschel at web.de  Mon Feb  1 12:08:43 2010
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 01 Feb 2010 12:08:43 +0100
Subject: [Rd] questions as to building R from source under Windows
Message-ID: <4B66B63B.1030506@web.de>

Hi R-devels,

yesterday, on a new computer, in order to check my installation
of "The Windows Toolset", I tried building R from source under
Windows (in fact under Windows 7) --- and in the end succeeded.

Some minor issues though (which I think should not be Windows 7
 issues) which might be of more general interest:

(1) TMPDIR on a different drive:
--- not sure whether this was my fault or you could do anything
about it: On my system, I have a separate drive for temp (i.e. E:),
and had this set in a corresponding TMPDIR environment variable.
During the build process of R, I had difficulties with this,
which were only resolved when I created a tmp folder on the same
drive (i.e. C:) and set environment variable TMPDIR to this new
folder. Is this a known issue /can you reproduce this?
If this is a more general issue, you might want to mention this
in R-admin / or the documentation to Rtools.

(2) TCL:
Although I set the path to TCL in MkRules, line 26 to
   C:\Program Files\R\Tcl   , in step    make rinstaller
I ran into problems, because the build process was assuming
(hard-coded, it seems) the Tcl files to reside in
../../../Tcl (from gnuwin32 folder, which is not the above
set path). Did I miss something? Everything worked fine
after I had copied the /Tcl folder to ../../../Tcl ...

(3) JPEG
Meanwhile the most recent version of jpeg sources is v8,
which is what I downloaded; I succeeded in building R with
this version after a little manual change in bitmap/Makefile .
-> Could you change line 10 in bitmap/Makefile so that it
would branch not only according to whether version was v7 or
not but rather according to whether version was larger or equal
to v7 or not / or set up a v8 alternative?

(4) Did not work for me: build R on D:
            --- a Vista / Windows 7 issue?
In the end I succeeded with my build on drive C: (NTFS formatted)
giving the current user full access privileges to the installation
folders; before, in order to circumvent these privilege issues,
I tried building R on a different drive (D:) which in my case is
formatted as FAT32; somehow I got stuck with this, though;
(my Rtools are on C:). Is this a known issue /can you reproduce this?

Best, Peter


From ligges at statistik.tu-dortmund.de  Mon Feb  1 13:37:38 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 01 Feb 2010 13:37:38 +0100
Subject: [Rd] questions as to building R from source under Windows
In-Reply-To: <4B66B63B.1030506@web.de>
References: <4B66B63B.1030506@web.de>
Message-ID: <4B66CB12.6@statistik.tu-dortmund.de>



On 01.02.2010 12:08, Peter Ruckdeschel wrote:
> Hi R-devels,
>
> yesterday, on a new computer, in order to check my installation
> of "The Windows Toolset", I tried building R from source under
> Windows (in fact under Windows 7) --- and in the end succeeded.
>
> Some minor issues though (which I think should not be Windows 7
>   issues) which might be of more general interest:
>
> (1) TMPDIR on a different drive:
> --- not sure whether this was my fault or you could do anything
> about it: On my system, I have a separate drive for temp (i.e. E:),
> and had this set in a corresponding TMPDIR environment variable.
> During the build process of R, I had difficulties with this,
> which were only resolved when I created a tmp folder on the same
> drive (i.e. C:) and set environment variable TMPDIR to this new
> folder. Is this a known issue /can you reproduce this?
> If this is a more general issue, you might want to mention this
> in R-admin / or the documentation to Rtools.


If your setup is correct according to the manuals, it may be a problem 
in one of the cygwin tools. A more detailed description to analyse it 
would be appreciated.



> (2) TCL:
> Although I set the path to TCL in MkRules, line 26 to
>     C:\Program Files\R\Tcl   , in step    make rinstaller
> I ran into problems, because the build process was assuming
> (hard-coded, it seems) the Tcl files to reside in
> ../../../Tcl (from gnuwin32 folder, which is not the above
> set path). Did I miss something? Everything worked fine
> after I had copied the /Tcl folder to ../../../Tcl ...


Citing the "R Installation and Administration" manual:
The Tcl/Tk support files are in a zip file at 
http://www.stats.ox.ac.uk/pub/Rtools/: unzip this in R HOME, and it will 
add directory tree ?R_HOME/Tcl?.


> (3) JPEG
> Meanwhile the most recent version of jpeg sources is v8,
> which is what I downloaded; I succeeded in building R with
> this version after a little manual change in bitmap/Makefile .
> ->  Could you change line 10 in bitmap/Makefile so that it
> would branch not only according to whether version was v7 or
> not but rather according to whether version was larger or equal
> to v7 or not / or set up a v8 alternative?


Well tested patches for the Makefile, MkRules and documentation 
(including manuals) are welcome.



> (4) Did not work for me: build R on D:
>              --- a Vista / Windows 7 issue?
> In the end I succeeded with my build on drive C: (NTFS formatted)
> giving the current user full access privileges to the installation
> folders; before, in order to circumvent these privilege issues,
> I tried building R on a different drive (D:) which in my case is
> formatted as FAT32; somehow I got stuck with this, though;
> (my Rtools are on C:). Is this a known issue /can you reproduce this?

I build R and packages on d:/ without any problems. I do not think that 
the drive letter is the issues here. It may be some new MS security 
policy on FAT drives - or whatever. I have not used FAT formatted drives 
for serious work for at least a decade now.

Best wishes,
Uwe



> Best, Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thomas.Petzoldt at tu-dresden.de  Mon Feb  1 15:50:06 2010
From: Thomas.Petzoldt at tu-dresden.de (Thomas Petzoldt)
Date: Mon, 01 Feb 2010 15:50:06 +0100
Subject: [Rd] Sort order of vignettes in help index and CRAN
Message-ID: <4B66EA1E.40307@tu-dresden.de>

Dear developers,

there seems to be an inconsistency in the sort order of package 
vignettes between (1) the "Overview of user guides and package 
vignettes" in the help index of package itself:

FME.pdf
FMEdyna.pdf
FMEmcmc.pdf
FMEother.pdf
FMEsteady.pdf

and (2) the sort order of CRAN:

FMEdyna.pdf
FMEmcmc.pdf
FMEother.pdf
FME.pdf            <--------------
FMEsteady.pdf


It looks like CRAN ignores the dot so that the "p" from pdf appears 
between the "o" and "s" of the other two.

It would be nice if this can be made consistent. I would prefer if CRAN 
would use the \VignetteIndexEntry , but file name ordering (without the 
extension) is also ok.

Thomas Petzoldt




-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From ken.knoblauch at inserm.fr  Mon Feb  1 17:18:56 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 01 Feb 2010 17:18:56 +0100
Subject: [Rd] update method for nls
Message-ID: <20100201171856.by70lhz74s8k0ok8@imp.inserm.fr>

Would it be useful to have an update method for nls?
I learned recently that the default method can generate an error unless
the rhs of a formula is protected by being wrapped in
a function, such as log or I(), when terms.formula is called.

https://stat.ethz.ch/pipermail/r-help/2010-January/225822.html

https://stat.ethz.ch/pipermail/r-help/2010-January/225837.html

Would the following be a useful way to ensure this?

update.nls <- function(object, formula, ...){
	formula <- if(!missing(formula)){
	  tmp <- formula[[3]]
	  formula[[3]] <- as.call(list(as.name("I"), as.call(tmp)))
	  formula
	}
	NextMethod("update", ...)
}

Ken



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From peter.ruckdeschel at web.de  Mon Feb  1 17:28:28 2010
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 01 Feb 2010 17:28:28 +0100
Subject: [Rd] questions as to building R from source under Windows
In-Reply-To: <4B66CB12.6@statistik.tu-dortmund.de>
References: <4B66B63B.1030506@web.de> <4B66CB12.6@statistik.tu-dortmund.de>
Message-ID: <hk6vfb$r8q$1@ger.gmane.org>

Hi Uwe,

thanks for your quick reply.

[... and sorry for not setting you to the CC explicitely,
but I am mailing to this list through gmane ...]

>> yesterday, on a new computer, in order to check my installation
>> of "The Windows Toolset", I tried building R from source under
>> Windows (in fact under Windows 7) --- and in the end succeeded.
>>
>> Some minor issues though (which I think should not be Windows 7
>>   issues) which might be of more general interest:
>>
>> (1) TMPDIR on a different drive:
>> --- not sure whether this was my fault or you could do anything
>> about it: On my system, I have a separate drive for temp (i.e. E:),
>> and had this set in a corresponding TMPDIR environment variable.
>> During the build process of R, I had difficulties with this,
>> which were only resolved when I created a tmp folder on the same
>> drive (i.e. C:) and set environment variable TMPDIR to this new
>> folder. Is this a known issue /can you reproduce this?
>> If this is a more general issue, you might want to mention this
>> in R-admin / or the documentation to Rtools.
>
> If your setup is correct according to the manuals, it may be a
> problem in one of the cygwin tools. A more detailed description
> to analyse it would be appreciated.
>
Yes, I guess, it was a cygwin problem; it claimed it could not access
/tmp at
one instance; so I concluded that environment variable TMPDIR was not
set and hence set it to E:\ in the console and re-ran   make all
but got the same error message; when I changed this environment variable
to C:\<somedir>\tmp however it ran through well.

Unfortunately I did not write the output / messages to files, so cannot
be much more precise at this point (I may also have missed something...);
I will try and do so in the next days.
>> (2) TCL:
>> Although I set the path to TCL in MkRules, line 26 to
>>     C:\Program Files\R\Tcl   , in step    make rinstaller
>> I ran into problems, because the build process was assuming
>> (hard-coded, it seems) the Tcl files to reside in
>> ../../../Tcl (from gnuwin32 folder, which is not the above
>> set path). Did I miss something? Everything worked fine
>> after I had copied the /Tcl folder to ../../../Tcl ...
>
>
> Citing the "R Installation and Administration" manual:
> The Tcl/Tk support files are in a zip file at
http://www.stats.ox.ac.uk/pub/Rtools/:
> unzip this in R HOME, and it will add directory tree ?R_HOME/Tcl?.
>
Yes, but I thought, as there was an entry in MkRules, that you
could have a common Tcl folder for several, possibly different R builds
/R HOME's...

--- Would it be too hard to change the corresponding
step in     make  rinstaller        to use the reference given
in MkRules instead of ../../../Tcl?
>
>> (3) JPEG
>> Meanwhile the most recent version of jpeg sources is v8,
>> which is what I downloaded; I succeeded in building R with
>> this version after a little manual change in bitmap/Makefile .
>> ->  Could you change line 10 in bitmap/Makefile so that it
>> would branch not only according to whether version was v7 or
>> not but rather according to whether version was larger or equal
>> to v7 or not / or set up a v8 alternative?

> Well tested patches for the Makefile, MkRules and documentation
(including manuals) are welcome.


For documentation for the new jpeg version, see  http://www.ijg.org/

The modification I used in bitmap/Makefile.jpeg was in fact an
alternative where I simply replaced jpeg-7 by jpeg-8, but
certainly a more sophisticated one (with something like ">=7")
would be preferrable:

ifeq ($(strip $(JPEGDIR)),jpeg-8)
LIBSOURCES= jaricom.c jcapimin.c jcapistd.c jcarith.c jccoefct.c jccolor.c \
        jcdctmgr.c jchuff.c jcinit.c jcmainct.c jcmarker.c jcmaster.c \
        jcomapi.c jcparam.c jcprepct.c jcsample.c jctrans.c jdapimin.c \
        jdapistd.c jdarith.c jdatadst.c jdatasrc.c jdcoefct.c jdcolor.c \
        jddctmgr.c jdhuff.c jdinput.c jdmainct.c jdmarker.c jdmaster.c \
        jdmerge.c jdpostct.c jdsample.c jdtrans.c jerror.c jfdctflt.c \
        jfdctfst.c jfdctint.c jidctflt.c jidctfst.c jidctint.c jquant1.c \
        jquant2.c jutils.c jmemmgr.c

>> (4) Did not work for me: build R on D:
>>              --- a Vista / Windows 7 issue?
>> In the end I succeeded with my build on drive C: (NTFS formatted)
>> giving the current user full access privileges to the installation
>> folders; before, in order to circumvent these privilege issues,
>> I tried building R on a different drive (D:) which in my case is
>> formatted as FAT32; somehow I got stuck with this, though;
>> (my Rtools are on C:). Is this a known issue /can you reproduce this?
>
> I build R and packages on d:/ without any problems. I do not think
> that the drive letter is the issues here. It may be some new MS
> security policy on FAT drives - or whatever. I have not used FAT
> formatted drives for serious work for at least a decade now.
>
Then I guess it is a FAT32 issue --- so let us drop this...

Best, Peter


From maechler at stat.math.ethz.ch  Mon Feb  1 17:30:25 2010
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon,  1 Feb 2010 17:30:25 +0100 (CET)
Subject: [Rd] qpois Help problems (PR#14200)
Message-ID: <20100201163025.6359E282EF54@mail.pubhealth.ku.dk>

>>>>> "JL" == Jerry Lewis <Jerry.Lewis at biogenidec.com>
>>>>>     on Fri, 29 Jan 2010 22:50:12 +0100 (CET) writes:

    JL> Full_Name: Jerry W. Lewis
    JL> Version: 2.10.1
    JL> OS: Windows XP Professional
    JL> Submission from: (NULL) (198.180.131.21)


    JL> In the line 

    JL> "The quantile is right continuous: qpois(q, lambda) is the smallest integer x
    JL> such that P(X <= x) >= q."

    JL> "q" is used as a probability when the Arguments section defines it to be a
    JL> quantile.

Yes.  I agree this can be slightly confusing.
Thank you for the note.

Note however that *mathematically* the above is entirely
correct.  It just uses  'q' instead of 'p', but as you know, in
math you are allowed to use whatever letters you want.....
as long as they are used consistently within one context.
As the 'Usage:' and 'Arguments:' parts are "R-codish", using R
object names, rather than mathematical notation, they are 
"out of context" from the math formula point of view  ;-)
..
I have changed that part to use 'p' now, ...
but for R-devel only, as indeed, it's *not* a bug fix.

    JL> Also there are some representation problems where the escape character is
    JL> printed instead of interpreted, such as "\ldots" and "\lambda" in the preceding
    JL> lines.

"printed" meaning what?
How exactly are you looking at that help page?
Is it the HTML version or the text version?

In any case, I'd guess that this is problem specific to your
platform, but maybe reproducible by others,
if you'd give the details...

Regards,
Martin Maechler,
ETH Zurich


From ripley at stats.ox.ac.uk  Mon Feb  1 17:45:32 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Feb 2010 16:45:32 +0000 (GMT)
Subject: [Rd] qpois Help problems (PR#14200)
In-Reply-To: <20100201163025.6359E282EF54@mail.pubhealth.ku.dk>
References: <20100201163025.6359E282EF54@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.1002011639530.18067@gannet.stats.ox.ac.uk>

On Mon, 1 Feb 2010, maechler at stat.math.ethz.ch wrote:

>>>>>> "JL" == Jerry Lewis <Jerry.Lewis at biogenidec.com>
>>>>>>     on Fri, 29 Jan 2010 22:50:12 +0100 (CET) writes:
>
>    JL> Full_Name: Jerry W. Lewis
>    JL> Version: 2.10.1
>    JL> OS: Windows XP Professional
>    JL> Submission from: (NULL) (198.180.131.21)
>
>
>    JL> In the line
>
>    JL> "The quantile is right continuous: qpois(q, lambda) is the smallest integer x
>    JL> such that P(X <= x) >= q."
>
>    JL> "q" is used as a probability when the Arguments section defines it to be a
>    JL> quantile.
>
> Yes.  I agree this can be slightly confusing.
> Thank you for the note.
>
> Note however that *mathematically* the above is entirely
> correct.  It just uses  'q' instead of 'p', but as you know, in
> math you are allowed to use whatever letters you want.....
> as long as they are used consistently within one context.
> As the 'Usage:' and 'Arguments:' parts are "R-codish", using R
> object names, rather than mathematical notation, they are
> "out of context" from the math formula point of view  ;-)
> ..
> I have changed that part to use 'p' now, ...
> but for R-devel only, as indeed, it's *not* a bug fix.
>
>    JL> Also there are some representation problems where the escape character is
>    JL> printed instead of interpreted, such as "\ldots" and "\lambda" in the preceding
>    JL> lines.
>
> "printed" meaning what?
> How exactly are you looking at that help page?
> Is it the HTML version or the text version?
>
> In any case, I'd guess that this is problem specific to your
> platform, but maybe reproducible by others,
> if you'd give the details...

HTML in R 2.10.1, I believe, see the NEWS item for 2.10.1 patched:

     o	Although \eqn{} in Rd files is defined as a 'verbatim' macro,
 	many packages expected \dots and \ldots to be interpreted
 	there (as was the case in R < 2.10.0), so this is now done
 	(using an ellipsis in HTML rendering).

(and another change fixes up misuse of \lambda).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peter.ruckdeschel at web.de  Mon Feb  1 20:26:25 2010
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 01 Feb 2010 20:26:25 +0100
Subject: [Rd] questions as to building R from source under Windows
In-Reply-To: <hk6vfb$r8q$1@ger.gmane.org>
References: <4B66B63B.1030506@web.de> <4B66CB12.6@statistik.tu-dortmund.de>
	<hk6vfb$r8q$1@ger.gmane.org>
Message-ID: <4B672AE1.3000409@web.de>

once again me --- just some more precise information...
[snip]

>>> (1) TMPDIR on a different drive:
>>> --- not sure whether this was my fault or you could do anything
>>> about it: On my system, I have a separate drive for temp (i.e. E:),
>>> and had this set in a corresponding TMPDIR environment variable.
>>> During the build process of R, I had difficulties with this,
>>> which were only resolved when I created a tmp folder on the same
>>> drive (i.e. C:) and set environment variable TMPDIR to this new
>>> folder. Is this a known issue /can you reproduce this?
>>> If this is a more general issue, you might want to mention this
>>> in R-admin / or the documentation to Rtools.
>>
>> If your setup is correct according to the manuals, it may be a
>> problem in one of the cygwin tools. A more detailed description
>> to analyse it would be appreciated.
>>
> Yes, I guess, it was a cygwin problem; it claimed it could not access
> /tmp at one instance; so I concluded that environment variable TMPDIR 
> was not set and hence set it to E:\ in the console and re-ran "make all"
> but got the same error message; when I changed this environment variable
> to C:\<somedir>\tmp however it ran through well.

Argh: A closer look gave that the reason for this must have been that I
had not set it to E:\ but rather to E:\tmp which in return did not
exist, so no wonder for the error --- blame on me! With E:\ it now
worked fine.

It is noteworthy, though, to repeat Win-FAQ 2.24:

For a successful build under Windows 7 (probably just as under Vista),
you have to a) be logged in as a user contained in the local
Administrators group and b) explicitely give full control to this user
for the installation folder and all its subfolders; having these
privileges for group "Administrator" does not suffice....


Best, Peter


From peter.ruckdeschel at web.de  Mon Feb  1 20:59:31 2010
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 01 Feb 2010 20:59:31 +0100
Subject: [Rd] questions as to building R from source under Windows
In-Reply-To: <4B66CB12.6@statistik.tu-dortmund.de>
References: <4B66B63B.1030506@web.de> <4B66CB12.6@statistik.tu-dortmund.de>
Message-ID: <hk7br2$c48$1@ger.gmane.org>

Yet another clarification:

[snip]

>> (4) Did not work for me: build R on D:
>>              --- a Vista / Windows 7 issue?
>> In the end I succeeded with my build on drive C: (NTFS formatted)
>> giving the current user full access privileges to the installation
>> folders; before, in order to circumvent these privilege issues,
>> I tried building R on a different drive (D:) which in my case is
>> formatted as FAT32; somehow I got stuck with this, though;
>> (my Rtools are on C:). Is this a known issue /can you reproduce this?
> 
> I build R and packages on d:/ without any problems. I do not think that
> the drive letter is the issues here. It may be some new MS security
> policy on FAT drives - or whatever. I have not used FAT formatted drives
> for serious work for at least a decade now.

At the end of the day, after having set the "right" TMPDIR environment
variable and copied the Tcl folder as indicated in R-admin.html,
it was /not/ a FAT32 issue: I managed to build it now on D:\
(although I agree with Uwe that this is probably not what you want to
do if NTFS works...)

best, Peter


From peter.ruckdeschel at web.de  Mon Feb  1 21:32:35 2010
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 01 Feb 2010 21:32:35 +0100
Subject: [Rd] questions as to building R from source under Windows /
 small corrections for R-admin sec. 3.1.7
In-Reply-To: <hk7br2$c48$1@ger.gmane.org>
References: <4B66B63B.1030506@web.de> <4B66CB12.6@statistik.tu-dortmund.de>
	<hk7br2$c48$1@ger.gmane.org>
Message-ID: <hk7dp1$k9d$1@ger.gmane.org>


> Yet another clarification:
> 
> [snip]
> 
>>> (4) Did not work for me: build R on D:
>>>              --- a Vista / Windows 7 issue?
>>> In the end I succeeded with my build on drive C: (NTFS formatted)
>>> giving the current user full access privileges to the installation
>>> folders; before, in order to circumvent these privilege issues,
>>> I tried building R on a different drive (D:) which in my case is
>>> formatted as FAT32; somehow I got stuck with this, though;
>>> (my Rtools are on C:). Is this a known issue /can you reproduce this?
>>
>> I build R and packages on d:/ without any problems. I do not think that
>> the drive letter is the issues here. It may be some new MS security
>> policy on FAT drives - or whatever. I have not used FAT formatted drives
>> for serious work for at least a decade now.
> 
> At the end of the day, after having set the "right" TMPDIR environment
> variable and copied the Tcl folder as indicated in R-admin.html,
> it was /not/ a FAT32 issue: I managed to build it now on D:\
> (although I agree with Uwe that this is probably not what you want to
> do if NTFS works...)
> 

together with this --- in the end --- still a little correction for
R-admin, section 3.1.7:

If you really pursue stepwise as indicated after "This works by building
all the parts in the sequence",

it must be     make rpackages   (not rpackage)

and you will need to insert a

    make -C ../../po -f Makefile.win

before   make rinstaller

Best, Peter


From diggsb at ohsu.edu  Tue Feb  2 00:57:30 2010
From: diggsb at ohsu.edu (Brian Diggs)
Date: Mon, 1 Feb 2010 15:57:30 -0800
Subject: [Rd] Error with cut.POSIXt and daylight savings time switchover
	dates
Message-ID: <E5BA65CAFB491A4DBB1370F6C972165502AE890131@EX-MB05.ohsu.edu>

The following code:

cut(as.POSIXct("2009-11-01 04:00:00", tz="America/Los_Angeles"), "1 day")

gives the error:

Error in seq.int(0, to - from, by) : 'to' must be finite

This is related to November 1st, 2009 being the switchover date from daylight savings time to standard time in the America/Los_Angeles time zone.  In particular, in cut.POSIXt, the starting time (start) is converted to a POSIXlt, and the individual members are manipulated.  Because a spacing of "1 day" is requested, the hour, minute, and second are manually set to 0.  In doing so, the represented time is now before the 2:00am PDT->PST change.  This value is passed to seq.int (as the argument from), which dispatches to seq.POSIXt.  seq.POSIXt eventually does from <- unclass(as.POSIXct(from)) which evaluates to NA because as.POSIXct(from) is NA.  The seq.int call in the next line then passes NA as the "to" argument, causing the output error (which comes from the C-code of seq.int).

Bringing it all together, the sequence of commands that causes the problems is:

tm <- as.POSIXlt("2009-11-01 04:00:00", tz="America/Los_Angeles")
tm$hour <- 0
as.POSIXct(tm)
# [1] NA

Is there a timezone/daylight savings time safe way to get to the beginning of the day in cut.POSIXt so that invalid dates are not sent to the other functions?  Alternatively, can as.POSIXct.POSIXlt be made to handle these manually manipulated dates correctly?

--
Brian Diggs, Ph.D.
Senior Research Associate, Department of Surgery, Oregon Health & Science University



From eriki at ccbr.umn.edu  Tue Feb  2 01:11:44 2010
From: eriki at ccbr.umn.edu (Erik Iverson)
Date: Mon, 1 Feb 2010 18:11:44 -0600 (CST)
Subject: [Rd] R's X11 Device Properties
Message-ID: <Pine.GSO.4.64.1002011757140.9670@tadpole.ccbr.umn.edu>

Hello,

This is an issue that is at the interface of R, X, and my window manager 
(either icewm or openbox, both latest versions).  I am running R 2.10.1 on 
Ubuntu 9.10.

My goal: When an X11 device is started in R (e.g., by simply calling 
plot), I would like for the resulting window to be in the "always on top" 
state, and for focus not to switch to it.

Configuring this behavior is handled through the window manager, but both 
of the above referenced window managers require that the first element of 
window's WM_CLASS property, second element of window's WM_CLASS property, 
or the window's WM_WINDOW_ROLE property be set so that the right window 
can be matched.

If I start R, type

> plot(1,1)

and then run "xprop" (command line program to inspect X window properties) 
on the resulting X11 window, none of these properties show up in the 
resulting output.

Is there any hope for this to change?  I did notice in ?X11 that "The 
standard X11 resource geometry can be used to specify the window position 
and/or size, but will be overridden by values specified as arguments or 
non-NA defaults set in X11.options. The class looked for is R_x11."

This "R_x11" class works fine for setting the geometry in .Xresources, but 
it does not seem to be the same "class" as WM_CLASS referenced above. 
Unfortunately, this is about as far as my knowledge of X goes, so 
hopefully this makes sense. If anyone has any pointers, they would be 
welcome. Thank you!

Best Regards,
Erik Iverson


From ripley at stats.ox.ac.uk  Tue Feb  2 07:11:52 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Feb 2010 06:11:52 +0000 (GMT)
Subject: [Rd] R's X11 Device Properties
In-Reply-To: <Pine.GSO.4.64.1002011757140.9670@tadpole.ccbr.umn.edu>
References: <Pine.GSO.4.64.1002011757140.9670@tadpole.ccbr.umn.edu>
Message-ID: <alpine.LFD.2.00.1002020558480.10850@gannet.stats.ox.ac.uk>

On Mon, 1 Feb 2010, Erik Iverson wrote:

> Hello,
>
> This is an issue that is at the interface of R, X, and my window manager 
> (either icewm or openbox, both latest versions).  I am running R 2.10.1 on 
> Ubuntu 9.10.
>
> My goal: When an X11 device is started in R (e.g., by simply calling plot), I 
> would like for the resulting window to be in the "always on top" state, and 
> for focus not to switch to it.
>
> Configuring this behavior is handled through the window manager, but both of 
> the above referenced window managers require that the first element of 
> window's WM_CLASS property, second element of window's WM_CLASS property, or 
> the window's WM_WINDOW_ROLE property be set so that the right window can be 
> matched.
>
> If I start R, type
>
>> plot(1,1)
>
> and then run "xprop" (command line program to inspect X window properties) on 
> the resulting X11 window, none of these properties show up in the resulting 
> output.
>
> Is there any hope for this to change?  I did notice in ?X11 that "The 
> standard X11 resource geometry can be used to specify the window position 
> and/or size, but will be overridden by values specified as arguments or 
> non-NA defaults set in X11.options. The class looked for is R_x11."

But the WM_CLASS is not set.

http://tronche.com/gui/x/xlib/ICC/client-to-window-manager/wm-class.html

shows how you could prepare a patch.  As so often with window manager 
issues, we need someone who uses that WM and wants the feature to try 
it out.

> This "R_x11" class works fine for setting the geometry in .Xresources, but it 
> does not seem to be the same "class" as WM_CLASS referenced above.

It is not.

> Unfortunately, this is about as far as my knowledge of X goes, so hopefully 
> this makes sense. If anyone has any pointers, they would be welcome. Thank 
> you!
>
> Best Regards,
> Erik Iverson
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From c-w.hoffmann at sunrise.ch  Mon Feb  1 20:40:09 2010
From: c-w.hoffmann at sunrise.ch (c-w.hoffmann at sunrise.ch)
Date: Mon,  1 Feb 2010 20:40:09 +0100 (CET)
Subject: [Rd] str() and signs in imaginary parts (PR#14201)
Message-ID: <20100201194009.F0ED0282EF52@mail.pubhealth.ku.dk>

My unix mailer might not work, so I send the report here:

The function "str" perpetuates the sign of the imaginary part of the 
first array element which it should not:


 > str(c(1+2i,1-3i)); str(c(2-4i,11+3i));
 cplx [1:2] 1+2i 1+3i    # note the faulty 1 + 3i
 cplx [1:2] 2-4i  1-3i    # note the faulty 1 - 3i
 > bug.report()
Have a look at

 >  (xx <- complex(real=rnorm(5,0,1),imag=rnorm(5,0,1)))
[1] -0.686846-0.010655i  1.017494-0.644474i  0.212905-0.720527i
[4] -0.843110+1.538344i -1.341294-0.741398i
 > str(xx,vec.len  = 6)
 cplx [1:5] -0.687-0.011i 1.017-0.644i 0.213-0.721i -0.843-1.538i ...
 >

--please do not edit the information below--

Version:
 platform = x86_64-apple-darwin9.8.0
 arch = x86_64
 os = darwin9.8.0
 system = x86_64, darwin9.8.0
 status =
 major = 2
 minor = 10.1
 year = 2009
 month = 12
 day = 14
 svn rev = 50720
 language = R
 version.string = R version 2.10.1 (2009-12-14)

Locale:
C

Search Path:
 .GlobalEnv, package:tools, package:tcltk, package:survival, 
package:stats4, package:splines, package:spatial, package:rpart, 
package:nnet, package:nlme, package:mgcv, package:grid, package:foreign, 
package:datasets, package:codetools, package:cluster, package:class, 
package:boot, package:Matrix, package:MASS, package:graphics, 
package:grDevices, package:KernSmooth, package:stats, package:cwhmisc, 
package:lattice, package:utils, package:methods, Autoloads, package:base

-- 
Christian W. Hoffmann,
Rigiblickstrasse 15 b, CH-8915Hausen am Albis, Switzerland,
Tel +41-44-7640853, c-w.hoffmann at sunrise.ch
www.wsl.ch/personal_homepages/hoffmann/


From murdoch at stats.uwo.ca  Tue Feb  2 13:25:09 2010
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Tue,  2 Feb 2010 13:25:09 +0100 (CET)
Subject: [Rd] [R] Suppressing scientific notation on plot axis tick
	labels (PR#14202)
Message-ID: <20100202122509.BD5EB282EFFB@mail.pubhealth.ku.dk>

On 02/02/2010 6:20 AM, Dimitri Shvorob wrote:
> Ruben Roa has kindly suggested using 'scipen' option - cf.
> 
>> fixed notation will be preferred unless it is more than ???scipen??? digits
>> wider.
> 
> However, 
> 
> options(scipen = 50)
> x  = c(1e7, 2e7)
> barplot(x) 
> 
> still does not produce the desired result.

This is strange.  I see what you describe the first time through, but
if I print the option I get the non-scientific labels on the second plot:

options(scipen = 50)
x  = c(1e7, 2e7)
barplot(x)
options("scipen")
barplot(x)

Looks like some sort of caching bug to me.  I don't think I'll have time 
to track this down; this is a crazy week.  I see the same thing in 
R-devel as in 2.10.1.

Duncan Murdoch

Version:
  platform = i386-pc-mingw32
  arch = i386
  os = mingw32
  system = i386, mingw32
  status =
  major = 2
  minor = 10.1
  year = 2009
  month = 12
  day = 14
  svn rev = 50720
  language = R
  version.string = R version 2.10.1 (2009-12-14)

Windows XP (build 2600) Service Pack 3

Locale:
LC_COLLATE=English_Canada.1252;LC_CTYPE=English_Canada.1252;LC_MONETARY=English_Canada.1252;LC_NUMERIC=C;LC_TIME=English_Canada.1252

Search Path:
  .GlobalEnv, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:methods, Autoloads, package:base


From savicky at cs.cas.cz  Tue Feb  2 13:37:46 2010
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 2 Feb 2010 13:37:46 +0100
Subject: [Rd] choose(n,k) when n is almost integer
In-Reply-To: <20091223224223.GA3057@cs.cas.cz>
References: <19239.19864.396771.484772@lynne.math.ethz.ch>
	<20091215095243.GA14388@cs.cas.cz>
	<19239.38154.219034.206322@lynne.math.ethz.ch>
	<19242.15337.267242.128687@lynne.math.ethz.ch>
	<20091217231449.GA23480@cs.cas.cz>
	<19245.16249.290239.986122@cmath-6.math.ethz.ch>
	<20091222215843.GA9120@cs.cas.cz> <20091223224223.GA3057@cs.cas.cz>
Message-ID: <20100202123746.GA27184@cs.cas.cz>

I would like to add some more information concerning the patch C
to the function choose() proposed in the email
  https://stat.ethz.ch/pipermail/r-devel/2009-December/056177.html

The patch uses transformations of choose(n, k), which are described in
  http://www.cs.cas.cz/~savicky/R-devel/formulas_choose.pdf

The accuracy of the modified function choose(n, k) may be verified
on randomly generated examples using Rmpfr package
  http://cran.at.r-project.org/web/packages/Rmpfr/index.html
and the script
  http://www.cs.cas.cz/~savicky/R-devel/test_choose_2.R

The output, which i obtained, is 

  > source("test_choose_2.R")
  k <= 9  max rel err = 9.41734e-16 
  k <= 19  max rel err = 2.084412e-15 
  k <= 29  max rel err = 3.170754e-15 
  k <= 39  max rel err = 4.99284e-14 
  k <= 49  max rel err = 5.927749e-14 
  k <= 59  max rel err = 6.526895e-14 
  k <= 69  max rel err = 6.526895e-14 
  k <= 79  max rel err = 8.783232e-14 
  k <= 89  max rel err = 1.051950e-13 
  k <= 99  max rel err = 1.051950e-13 
  k <= 109  max rel err = 1.072878e-13 
  k <= 119  max rel err = 1.072878e-13 
  k <= 129  max rel err = 1.179829e-13 
  k <= 139  max rel err = 1.247080e-13 
  k <= 149  max rel err = 1.247080e-13 
  k <= 159  max rel err = 1.255064e-13 
  k <= 169  max rel err = 1.255064e-13 
  k <= 179  max rel err = 1.267402e-13 
  k <= 189  max rel err = 1.311689e-13 
  k <= 199  max rel err = 1.573155e-13 
  k <= 209  max rel err = 1.844756e-13 

Patch C also passes make check-all in the current development
version 2.11.0 (2010-02-01).

I appreciate comments.

Petr Savicky.


From P.Dalgaard at biostat.ku.dk  Tue Feb  2 14:07:38 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 02 Feb 2010 14:07:38 +0100
Subject: [Rd] [R] Suppressing scientific notation on plot axis
 tick	labels (PR#14202)
In-Reply-To: <20100202122509.BD5EB282EFFB@mail.pubhealth.ku.dk>
References: <20100202122509.BD5EB282EFFB@mail.pubhealth.ku.dk>
Message-ID: <4B68239A.60704@biostat.ku.dk>

murdoch at stats.uwo.ca wrote:
> On 02/02/2010 6:20 AM, Dimitri Shvorob wrote:
>> Ruben Roa has kindly suggested using 'scipen' option - cf.
>>
>>> fixed notation will be preferred unless it is more than ???scipen??? digits
>>> wider.
>> However, 
>>
>> options(scipen = 50)
>> x  = c(1e7, 2e7)
>> barplot(x) 
>>
>> still does not produce the desired result.
> 
> This is strange.  I see what you describe the first time through, but
> if I print the option I get the non-scientific labels on the second plot:
> 
> options(scipen = 50)
> x  = c(1e7, 2e7)
> barplot(x)
> options("scipen")
> barplot(x)
> 
> Looks like some sort of caching bug to me.  I don't think I'll have time 
> to track this down; this is a crazy week.  I see the same thing in 
> R-devel as in 2.10.1.

Same thing with, e.g.

x <- c(1e7, 2e7)
options(scipen =3)
barplot(x)
x
barplot(x)
options(scipen=0)
barplot(x)
x
barplot(x)


> Duncan Murdoch
> 
> Version:
>   platform = i386-pc-mingw32
>   arch = i386
>   os = mingw32
>   system = i386, mingw32
>   status =
>   major = 2
>   minor = 10.1
>   year = 2009
>   month = 12
>   day = 14
>   svn rev = 50720
>   language = R
>   version.string = R version 2.10.1 (2009-12-14)
> 
> Windows XP (build 2600) Service Pack 3
> 
> Locale:
> LC_COLLATE=English_Canada.1252;LC_CTYPE=English_Canada.1252;LC_MONETARY=English_Canada.1252;LC_NUMERIC=C;LC_TIME=English_Canada.1252
> 
> Search Path:
>   .GlobalEnv, package:stats, package:graphics, package:grDevices, 
> package:utils, package:datasets, package:methods, Autoloads, package:base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Tue Feb  2 14:10:10 2010
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Tue,  2 Feb 2010 14:10:10 +0100 (CET)
Subject: [Rd] [R] Suppressing scientific notation on plot axis
	tick	labels (PR#14203)
Message-ID: <20100202131010.1CFFA2830315@mail.pubhealth.ku.dk>

murdoch at stats.uwo.ca wrote:
> On 02/02/2010 6:20 AM, Dimitri Shvorob wrote:
>> Ruben Roa has kindly suggested using 'scipen' option - cf.
>>
>>> fixed notation will be preferred unless it is more than =C3=A2=E2=82=AC=
=CB=9Cscipen=C3=A2=E2=82=AC=E2=84=A2 digits
>>> wider.
>> However,=20
>>
>> options(scipen =3D 50)
>> x  =3D c(1e7, 2e7)
>> barplot(x)=20
>>
>> still does not produce the desired result.
>=20
> This is strange.  I see what you describe the first time through, but
> if I print the option I get the non-scientific labels on the second plo=
t:
>=20
> options(scipen =3D 50)
> x  =3D c(1e7, 2e7)
> barplot(x)
> options("scipen")
> barplot(x)
>=20
> Looks like some sort of caching bug to me.  I don't think I'll have tim=
e=20
> to track this down; this is a crazy week.  I see the same thing in=20
> R-devel as in 2.10.1.

Same thing with, e.g.

x <- c(1e7, 2e7)
options(scipen =3D3)
barplot(x)
x
barplot(x)
options(scipen=3D0)
barplot(x)
x
barplot(x)


> Duncan Murdoch
>=20
> Version:
>   platform =3D i386-pc-mingw32
>   arch =3D i386
>   os =3D mingw32
>   system =3D i386, mingw32
>   status =3D
>   major =3D 2
>   minor =3D 10.1
>   year =3D 2009
>   month =3D 12
>   day =3D 14
>   svn rev =3D 50720
>   language =3D R
>   version.string =3D R version 2.10.1 (2009-12-14)
>=20
> Windows XP (build 2600) Service Pack 3
>=20
> Locale:
> LC_COLLATE=3DEnglish_Canada.1252;LC_CTYPE=3DEnglish_Canada.1252;LC_MONE=
TARY=3DEnglish_Canada.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_Canada.1252
>=20
> Search Path:
>   .GlobalEnv, package:stats, package:graphics, package:grDevices,=20
> package:utils, package:datasets, package:methods, Autoloads, package:ba=
se
>=20
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From lbraglia at gmail.com  Tue Feb  2 16:58:24 2010
From: lbraglia at gmail.com (Luca Braglia)
Date: Tue, 2 Feb 2010 16:58:24 +0100
Subject: [Rd] [lbraglia@gmail.com: [wishlist] \href in Rd]
Message-ID: <20100202155824.GA11541@A6K>

mmm maybe lost somewhere

cheers

----- Forwarded message from Luca Braglia <lbraglia at gmail.com> -----

Subject: [wishlist] \href in Rd
Date: Wed, 27 Jan 2010 16:40:54 +0100
From: Luca Braglia <lbraglia at gmail.com>
To: R Bug <r-bugs at r-project.org>
User-Agent: Mutt/1.5.20 (2009-06-14)

Following this thread

https://stat.ethz.ch/pipermail/r-help/2010-January/225856.html

it would be nice having an implementation of the LaTeX \href for Rd
too.

Thanks in advance
   Luca
  



----- End forwarded message -----


From lbraglia at gmail.com  Tue Feb  2 17:05:10 2010
From: lbraglia at gmail.com (lbraglia at gmail.com)
Date: Tue,  2 Feb 2010 17:05:10 +0100 (CET)
Subject: [Rd] [lbraglia@gmail.com: [wishlist] \href in Rd] (PR#14204)
Message-ID: <20100202160510.868D12830318@mail.pubhealth.ku.dk>

mmm maybe lost somewhere

cheers

----- Forwarded message from Luca Braglia <lbraglia at gmail.com> -----

Subject: [wishlist] \href in Rd
Date: Wed, 27 Jan 2010 16:40:54 +0100
From: Luca Braglia <lbraglia at gmail.com>
To: R Bug <r-bugs at r-project.org>
User-Agent: Mutt/1.5.20 (2009-06-14)

Following this thread

https://stat.ethz.ch/pipermail/r-help/2010-January/225856.html

it would be nice having an implementation of the LaTeX \href for Rd
too.

Thanks in advance
   Luca
  



----- End forwarded message -----


From hpages at fhcrc.org  Tue Feb  2 20:30:32 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 02 Feb 2010 11:30:32 -0800
Subject: [Rd] Missing arg default values in Docs are not triggering an 'R
 CMD check' warning
Message-ID: <4B687D58.2020301@fhcrc.org>

Hi,

Having

   foo <- function(x, y, z) {TRUE}

in my code and

   foo(x, y=NULL, z=0)

in the \usage section of my man page will trigger the
following warning during R CMD check:

* checking for code/documentation mismatches ... WARNING
Codoc mismatches from documentation object 'foo':
foo
   Code: function(x, y, z)
   Docs: function(x, y = NULL, z = 0)
   Mismatches in argument default values:
     Name: 'y' Code:  Docs: NULL
     Name: 'z' Code:  Docs: 0

which is good.

But if the mismatch is the other way around i.e if the argument
default values are specified in Code and not in Docs, then
R CMD check won't say anything. Is that intended or is it a bug?

Thanks,
H.


From spluque at gmail.com  Tue Feb  2 22:46:52 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 02 Feb 2010 15:46:52 -0600
Subject: [Rd] codoc mismatches warning
Message-ID: <871vh3tinn.fsf@kolob.sebmags.homelinux.org>

Hi,

Doing 'R CMD check diveMove' is now throwing this message:

Data codoc mismatches from documentation object 'sealLocs':
Variables in data frame 'sealLocs'
  Code: id.time.class.lon.lat
  Docs: class id lat lon time

with:

R> sessionInfo()
R version 2.10.1 (2009-12-14) 
x86_64-pc-linux-gnu 

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] slmisc_0.7.3   lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1

I've never had this problem in previous versions.  'sealLocs' is a *.csv
file with this head:

,-----[ head -n5 data/sealLocs.csv ]
| "id","time","class","lon","lat"
| "ringy",2006-06-14 20:31:46,"2",-72.655,40.915
| "ringy",2006-06-15 05:58:14,"3",-72.656,40.918
| "ringy",2006-06-15 07:56:32,"3",-72.657,40.919
| "ringy",2006-06-15 19:07:49,"2",-72.474,40.834
`-----

and this is the relevant section of man/sealLocs.Rd:

\format{A data frame with the following information:

  \describe{
    \item{id}{String naming the seal the data come from.}

    \item{time}{The date and time of the location.}

    \item{class}{The ARGOS location quality classification.}

    \item{lon, lat}{x and y geographic coordinates of each location.}
  }
}

Any pointers to avoid the warning?  Thanks.


Cheers,

-- 
Seb


From Kurt.Hornik at wu.ac.at  Tue Feb  2 23:05:35 2010
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Tue, 2 Feb 2010 23:05:35 +0100
Subject: [Rd] codoc mismatches warning
In-Reply-To: <871vh3tinn.fsf@kolob.sebmags.homelinux.org>
References: <871vh3tinn.fsf@kolob.sebmags.homelinux.org>
Message-ID: <19304.41391.523856.588234@hornik.net>

>>>>> Sebastian P Luque writes:

> Hi,
> Doing 'R CMD check diveMove' is now throwing this message:

Which version of diveMove is this?

-k

> Data codoc mismatches from documentation object 'sealLocs':
> Variables in data frame 'sealLocs'
>   Code: id.time.class.lon.lat
>   Docs: class id lat lon time

> with:

R> sessionInfo()
> R version 2.10.1 (2009-12-14) 
> x86_64-pc-linux-gnu 

> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     

> other attached packages:
> [1] slmisc_0.7.3   lattice_0.18-3

> loaded via a namespace (and not attached):
> [1] grid_2.10.1

> I've never had this problem in previous versions.  'sealLocs' is a *.csv
> file with this head:

> ,-----[ head -n5 data/sealLocs.csv ]
> | "id","time","class","lon","lat"
> | "ringy",2006-06-14 20:31:46,"2",-72.655,40.915
> | "ringy",2006-06-15 05:58:14,"3",-72.656,40.918
> | "ringy",2006-06-15 07:56:32,"3",-72.657,40.919
> | "ringy",2006-06-15 19:07:49,"2",-72.474,40.834
> `-----

> and this is the relevant section of man/sealLocs.Rd:

> \format{A data frame with the following information:

>   \describe{
>     \item{id}{String naming the seal the data come from.}

>     \item{time}{The date and time of the location.}

>     \item{class}{The ARGOS location quality classification.}

>     \item{lon, lat}{x and y geographic coordinates of each location.}
>   }
> }

> Any pointers to avoid the warning?  Thanks.


> Cheers,

> -- 
> Seb

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bullard at stat.Berkeley.EDU  Tue Feb  2 23:12:16 2010
From: bullard at stat.Berkeley.EDU (bullard at stat.Berkeley.EDU)
Date: Tue, 2 Feb 2010 14:12:16 -0800 (PST)
Subject: [Rd] S4 setClass / initialize misunderstanding
Message-ID: <6386.66.201.56.150.1265148736.squirrel@www.stat.berkeley.edu>


Hi, I recently ran into this problem. I couldn't find any mention of it in
the setClass documentation.

setClass("Foo", representation(file = "character"))
setMethod("initialize", "Foo", function(.Object, file) {
  print(file)
})
setClass("Bar", contains = "Foo")

And the error:

Error in print(file) : argument "file" is missing, with no default

The workaround is to interchange the setMethod and the second setClass
call, however, it begs the question why is setClass calling an initialize
method? As always, if I have missed documentation concerning this please
point me there.

Thanks, jim


From spluque at gmail.com  Tue Feb  2 23:23:12 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 02 Feb 2010 16:23:12 -0600
Subject: [Rd] codoc mismatches warning
In-Reply-To: <19304.41391.523856.588234@hornik.net> (Kurt Hornik's message of
	"Tue, 2 Feb 2010 23:05:35 +0100")
References: <871vh3tinn.fsf@kolob.sebmags.homelinux.org>
	<19304.41391.523856.588234@hornik.net>
Message-ID: <87sk9js2en.fsf@kolob.sebmags.homelinux.org>

On Tue, 2 Feb 2010 23:05:35 +0100,
Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:

>>>>>> Sebastian P Luque writes:
>> Hi, Doing 'R CMD check diveMove' is now throwing this message:

> Which version of diveMove is this?

It's a development version (0.9.7) at R-Forge.  The one showing this
warning hasn't been built yet by the automated system at R-Forge, but
can be downloaded from there.

-- 
Seb


From mtmorgan at fhcrc.org  Wed Feb  3 04:02:34 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 02 Feb 2010 19:02:34 -0800
Subject: [Rd] S4 setClass / initialize misunderstanding
In-Reply-To: <6386.66.201.56.150.1265148736.squirrel@www.stat.berkeley.edu>
References: <6386.66.201.56.150.1265148736.squirrel@www.stat.berkeley.edu>
Message-ID: <4B68E74A.3010700@fhcrc.org>

On 02/02/2010 02:12 PM, bullard at stat.berkeley.edu wrote:
> 
> Hi, I recently ran into this problem. I couldn't find any mention of it in
> the setClass documentation.
> 
> setClass("Foo", representation(file = "character"))
> setMethod("initialize", "Foo", function(.Object, file) {
>   print(file)
> })
> setClass("Bar", contains = "Foo")
> 
> And the error:
> 
> Error in print(file) : argument "file" is missing, with no default
>
> The workaround is to interchange the setMethod and the second setClass
> call, however, it begs the question why is setClass calling an initialize
> method? As always, if I have missed documentation concerning this please
> point me there.

Hi Jim -- The hint is in traceback()

> setClass("Bar", contains="Foo")
Error in print(file) : argument "file" is missing, with no default
> traceback()
[snip]
5: new(toDef)
4: .simpleCoerceExpr(Class, to, names(slots), classDef2)
3: makeExtends(name, what, slots = slots, classDef2 = whatClassDef,
       package = package)
2: makeClassRepresentation(Class, properties, superClasses, prototype,
       package, validity, access, version, sealed, where = where)
1: setClass("Bar", contains = "Foo")

the source

 if(!isVirtualClass(toDef))
    toClass <- class(new(toDef)) # get it with the package slot correct

subversion

% svn annotate src/library/methods/R/RClassUtils.R

 48221        jmc     if(!isVirtualClass(toDef))
 48221        jmc         toClass <- class(new(toDef)) # get it with

% svn log -r 48221
------------------------------------------------------------------------
r48221 | jmc | 2009-03-26 14:28:03 -0700 (Thu, 26 Mar 2009) | 1 line

fix bug in defining as() methods--got wrong package for simple contains
class with no added slots
------------------------------------------------------------------------

and the mailing list

https://stat.ethz.ch/pipermail/r-devel/2009-March/052829.html

but the bottom line is that you want

  validObject(new("Foo"))

to return TRUE. I'd write (if an initialize method is really required --
what happens if there's a constructor Foo() that constructs the
arguments to new("Foo", <...>) correctlyl?)

  setMethod(initialize, function(.Object, ..., file=character(0)) {
      ## process file, then
      callNextMethod(.Object, ..., file=file)
  })

'file' gets a default argument. '...' allows derived classes to
callNextMethod (explicitly, or implicitly by a call to new("Bar",
<...>)) and get the expected 'initialize' behavior. Placing 'file' after
'...' means that 'file' doesn't capture unnamed arguments, which are
supposed to be prototypes for classes that .Object extends.

Martin


> 
> Thanks, jim
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From savicky at cs.cas.cz  Wed Feb  3 10:47:31 2010
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 3 Feb 2010 10:47:31 +0100
Subject: [Rd] choose(n,k) when n is almost integer
In-Reply-To: <20100202123746.GA27184@cs.cas.cz>
References: <19239.19864.396771.484772@lynne.math.ethz.ch>
	<20091215095243.GA14388@cs.cas.cz>
	<19239.38154.219034.206322@lynne.math.ethz.ch>
	<19242.15337.267242.128687@lynne.math.ethz.ch>
	<20091217231449.GA23480@cs.cas.cz>
	<19245.16249.290239.986122@cmath-6.math.ethz.ch>
	<20091222215843.GA9120@cs.cas.cz> <20091223224223.GA3057@cs.cas.cz>
	<20100202123746.GA27184@cs.cas.cz>
Message-ID: <20100203094731.GA14583@cs.cas.cz>

On Tue, Feb 02, 2010 at 01:37:46PM +0100, Petr Savicky wrote:
> I would like to add some more information concerning the patch C
> to the function choose() proposed in the email
>   https://stat.ethz.ch/pipermail/r-devel/2009-December/056177.html
> 
> The patch uses transformations of choose(n, k), which are described in
>   http://www.cs.cas.cz/~savicky/R-devel/formulas_choose.pdf
> 
> The accuracy of the modified function choose(n, k) may be verified
> on randomly generated examples using Rmpfr package
>   http://cran.at.r-project.org/web/packages/Rmpfr/index.html
> and the script
>   http://www.cs.cas.cz/~savicky/R-devel/test_choose_2.R

Let me add an explanation of the script test_choose_2.R.

The script generates a vector of random real numbers n, which are from
a continuous distribution, but concentrate near integer values. The
original implementation of choose(m, k) considers m as an integer, if
abs(m - round(m)) <= 1e-7. The vector n is generated so that the
probability of abs(n[i] - round(n[i])) <= 1e-7 is approximately 0.1.
The distribution of n[i] - round(n[i]) is symmetric around 0, so we
get both n[i], which are close to an integer from below and from above.
On the other hand, the probability of abs(n[i] - round(n[i])) >= 0.3 is
approximately 0.1083404, so there are also numbers n[i], which are not
close to an integer.

The script calculates choose(n, k) for k in 0:209 (an ad hoc upper bound)
1. using the modified choose(n, k) from patch C
2. using the expression n(n-1)...(n-k+1)/(1 2 ... k) with Rmpfr numbers
   of precision 100 bits.
The relative difference of these two results is computed and its maximum
over all n[i] and k from 0 to a given bound is reported. The bounds on k are
chosen to be the numbers, whose last digit is 9, since the algorithm in choose(n,k)
is different for k <= 29 and k >= 30.

An upper bound of the relative rounding error of a single operation with
Rmpfr numbers of precision 100 bits is (1 + 2^-100). Hence, an upper bound
on the total relative error of n(n-1)...(n-k+1)/(1 2 ... k) is
(1 + 2^-100)^(2*209) \approx (1 + 2 * 209 * 2^-100) \approx 1 + 3.297e-28.
This is a negligible error compared to the errors reported by test_choose_2.R,
so the reported errors are the errors of the patched choose(n, k).

The errors reported by test_choose_2.R with patched choose(n,k) are in
a previous email.

Running test_choose_2.R with unpatched R version 2.11.0 (2010-02-01 r51089)
produces larger errors.

  > source("test_choose_2.R")
  k <= 9  max rel err = Inf 
  k <= 19  max rel err = Inf 

  > source("test_choose_2.R")
  k <= 9  max rel err = 0.1111111 
  k <= 19  max rel err = Inf 

  > source("test_choose_2.R")
  k <= 9  max rel err = Inf 
  k <= 19  max rel err = Inf 

  > source("test_choose_2.R")
  k <= 9  max rel err = 8.383718e-08 
  k <= 19  max rel err = 1.226306e-07 
  k <= 29  max rel err = 1.469050e-07 
  Error: segfault from C stack overflow

The Inf relative errors occur in cases, where choose(n, k) calculates 0,
but the correct result is not 0.

The stack overflow error is sometimes generated due to an infinite sequence
of transformations 
  choose(n, k) -> choose(n, n-k) -> choose(n, round(n-k))
which occur if k = 30 and n = 60 - eps. The reason for the transformation
  choose(n, k) -> choose(n, n-k)
is that
  k >= k_small_max = 30
  n is treated as an integer in R_IS_INT(n)
  n-k < k_small_max
So, choose(n, n-k) is called. There, we determine that n-k is almost an integer and
since n-k is the second argument of choose(n,k), it is explicitly rounded to an integer.
Since n = 2*k - eps, we have round(n-k) = round(k - eps) = k. The result is that
we again call choose(n, k) and this repeats until the stack overflow.

For example
  > choose(60 - 1e-9, 30)
  Error: segfault from C stack overflow

Besides patch C, which corrects this stack overflow, also the previous
patches A, B from 
  https://stat.ethz.ch/pipermail/r-devel/2009-December/056154.html
correct this, but have lower accuracy.

Petr Savicky.


From johannes_graumann at web.de  Wed Feb  3 11:40:35 2010
From: johannes_graumann at web.de (Johannes Graumann)
Date: Wed, 03 Feb 2010 11:40:35 +0100
Subject: [Rd] Package Directory Hierarchy: Recursive inclusion of *.R
	possible?
Message-ID: <hkbk2v$97e$1@ger.gmane.org>

Hello,

I would like to organize the "R" directory in my home-grown package into 
sub-directories, but "R CMD --build" doesn't seem to find *.R files below 
the actual source directory. Is there any way around that?

Thanks, Joh


From Chris.Brien at unisa.edu.au  Wed Feb  3 14:07:16 2010
From: Chris.Brien at unisa.edu.au (Chris Brien)
Date: Wed, 3 Feb 2010 23:37:16 +1030
Subject: [Rd] Package options
Message-ID: <EC96E350A5D6444B82CBD8DA338F017508A107AF@ITUPC-EX1MBOX.UniNet.unisa.edu.au>

Dear all,

I am developing a package foo that has a namespace. I would like to be able to provide an option, say opt, that 

1) is set to a default value when the package is loaded
2) can be set to a different value by the package user
3) is used by functions within the package

How can I achieve this?

Cheers,
 
Chris Brien
Adjunct Senior Lecturer in Statistics
-----
School of Mathematics & Statistics - Mawson Lakes
Phenomics and Bioinformatics Research Centre
University of South Australia
GPO Box 2471
ADELAIDE? 5001? South Australia
Phone:? +61 8 8302 5873 ? Fax:? +61 8 8302 5785
Email:?? Chris.Brien at unisa.edu.au 
WEB page:? <http://people.unisa.edu.au/Chris.Brien> 
CRICOS No 00121B 


From murdoch at stats.uwo.ca  Wed Feb  3 14:34:42 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 03 Feb 2010 08:34:42 -0500
Subject: [Rd] Package options
In-Reply-To: <EC96E350A5D6444B82CBD8DA338F017508A107AF@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
References: <EC96E350A5D6444B82CBD8DA338F017508A107AF@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
Message-ID: <4B697B72.4020208@stats.uwo.ca>

On 03/02/2010 8:07 AM, Chris Brien wrote:
> Dear all,
> 
> I am developing a package foo that has a namespace. I would like to be able to provide an option, say opt, that 
> 
> 1) is set to a default value when the package is loaded
> 2) can be set to a different value by the package user
> 3) is used by functions within the package
> 
> How can I achieve this?
> 

Do you want this option to persist to the next session if a user saves 
the workspace?  If so, then it should be stored in a variable in the 
global environment.  You can use assign(".FooOptions", value, 
envir=globalenv()) to set it, and get(".FooOptions", envir=globalenv())
to read it.

The obvious problem with this is that the user might already have a 
.FooOptions variable defined, and your code would stomp on it.  An 
alternative is to store the variable into the namespace.  You need to 
unlock it to change it.  See tools:::startDynamicHelp for code that does 
this for the variable httpdPort.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Wed Feb  3 14:43:22 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Feb 2010 13:43:22 +0000 (GMT)
Subject: [Rd] Package options
In-Reply-To: <4B697B72.4020208@stats.uwo.ca>
References: <EC96E350A5D6444B82CBD8DA338F017508A107AF@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<4B697B72.4020208@stats.uwo.ca>
Message-ID: <alpine.LFD.2.00.1002031341060.4209@gannet.stats.ox.ac.uk>

A number of packages do this.  See e.g. 'sm' and its function 
sm.options() for one implementation.

On Wed, 3 Feb 2010, Duncan Murdoch wrote:

> On 03/02/2010 8:07 AM, Chris Brien wrote:
>> Dear all,
>> 
>> I am developing a package foo that has a namespace. I would like to be able 
>> to provide an option, say opt, that 
>> 1) is set to a default value when the package is loaded
>> 2) can be set to a different value by the package user
>> 3) is used by functions within the package
>> 
>> How can I achieve this?
>> 
>
> Do you want this option to persist to the next session if a user saves the 
> workspace?  If so, then it should be stored in a variable in the global 
> environment.  You can use assign(".FooOptions", value, envir=globalenv()) to 
> set it, and get(".FooOptions", envir=globalenv())
> to read it.
>
> The obvious problem with this is that the user might already have a 
> .FooOptions variable defined, and your code would stomp on it.  An 
> alternative is to store the variable into the namespace.  You need to unlock 
> it to change it.  See tools:::startDynamicHelp for code that does this for 
> the variable httpdPort.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From diggsb at ohsu.edu  Wed Feb  3 16:48:57 2010
From: diggsb at ohsu.edu (Brian Diggs)
Date: Wed, 3 Feb 2010 07:48:57 -0800
Subject: [Rd] Error with cut.POSIXt and daylight savings time switchover
 dates
In-Reply-To: <E5BA65CAFB491A4DBB1370F6C972165502AE890131@EX-MB05.ohsu.edu>
References: <E5BA65CAFB491A4DBB1370F6C972165502AE890131@EX-MB05.ohsu.edu>
Message-ID: <E5BA65CAFB491A4DBB1370F6C972165502AEAD7498@EX-MB05.ohsu.edu>

On 2/1/2010 3:57 PM, Brian Diggs wrote:
> The following code:
> 
> cut(as.POSIXct("2009-11-01 04:00:00", tz="America/Los_Angeles"), "1 day")
> 
> gives the error:
> 
> Error in seq.int(0, to - from, by) : 'to' must be finite
> 
> This is related to November 1st, 2009 being the switchover date from
> daylight savings time to standard time in the America/Los_Angeles
> time zone.  In particular, in cut.POSIXt, the starting time (start)
> is converted to a POSIXlt, and the individual members are
> manipulated.  Because a spacing of "1 day" is requested, the hour,
> minute, and second are manually set to 0.  In doing so, the
> represented time is now before the 2:00am PDT->PST change.  This
> value is passed to seq.int (as the argument from), which dispatches
> to seq.POSIXt.  seq.POSIXt eventually does from <-
> unclass(as.POSIXct(from)) which evaluates to NA because
> as.POSIXct(from) is NA.  The seq.int call in the next line then
> passes NA as the "to" argument, causing the output error (which comes
> from the C-code of seq.int).
> 
> Bringing it all together, the sequence of commands that causes the
> problems is:
> 
> tm <- as.POSIXlt("2009-11-01 04:00:00", tz="America/Los_Angeles") 
> tm$hour <- 0 
> as.POSIXct(tm)
> # [1] NA
> 
> Is there a timezone/daylight savings time safe way to get to the
> beginning of the day in cut.POSIXt so that invalid dates are not sent
> to the other functions?  Alternatively, can as.POSIXct.POSIXlt be
> made to handle these manually manipulated dates correctly?

I realized I forgot my session info:

> sessionInfo()
R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     


> -- Brian Diggs, Ph.D. Senior Research Associate, Department of
> Surgery, Oregon Health & Science University


From o.heil at dkfz.de  Wed Feb  3 13:55:10 2010
From: o.heil at dkfz.de (o.heil at dkfz.de)
Date: Wed,  3 Feb 2010 13:55:10 +0100 (CET)
Subject: [Rd] mclapply on a set not divisible by number of cores (PR#14205)
Message-ID: <20100203125510.67099282EF59@mail.pubhealth.ku.dk>

Full_Name: Oliver Heil
Version: 2.10.0
OS: debian squeeze
Submission from: (NULL) (193.174.58.251)


When running mclapply on a list of strings with a length of 618 on 10 cores the
resulting data is wrong every 10 entries starting with the 6th. Our machine has
16 cores.

You may reproduce the error using data provided here:
<http://www.dkfz.de/gpcf/tmp_535434fsfd/>

Together with the following code (R --vanilla): 

# foreach probeid(618 Probeids) get the data points from the 
#    dataframes control and group
# calculate mean, standard deviation and detection p value for group and
control
# calculate the p value, that mean of control and mean of group are different
# 
# The result is a list (length 618) of 7 tuples
# 
# Have a look at x_sd_p.test[[6]], x_sd_p.test[[16]], ...
# It works fine using lapply or doing the function "by 
#    hand" for example with factor=probeids[6]
#

load("df.control.R")
load("df.group.R")
load("negative_bead.R")
load("probeids.R")

library("multicore")

x_sd_p.test=mclapply(probeids,function(factor){
	idxg=which(df.group$Factor %in% factor);
	mg=NA;sdg=NA;pg=1.0;
	if(length(idxg)>0){
		lg=df.group$x[idxg];
		mg=mean(lg,,TRUE);
		sdg=sd(lg,TRUE);
		t=wilcox.test(lg,negative_bead,alternative="g",exact=TRUE);
		pg=t$p.value;
	}
	idxc=which(df.control$Factor %in% factor);
	mc=NA;sdc=NA;pc=1.0
	if(length(idxc)>0){
		lc=df.control$x[idxc];
		mc=mean(lc,,TRUE);
		sdc=sd(lc,TRUE);
		t=wilcox.test(lc,negative_bead,alternative="g",exact=TRUE);
		pc=t$p.value;
	}
	p=1.0;
	if(length(idxg)>0&&length(idxc)>0){
		t=wilcox.test(lg,lc,alternative="t",exact=TRUE);
		p=t$p.value;
	}
	c(mg,sdg,pg,mc,sdc,pc,p);
},mc.cores=10)

l=lapply(x_sd_p.test,function(x){length(x)})




> sessionInfo()
R version 2.10.0 (2009-10-26)
x86_64-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] multicore_0.1-3

loaded via a namespace (and not attached):
[1] tools_2.10.0

> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          10.0
year           2009
month          10
day            26
svn rev        50208
language       R
version.string R version 2.10.0 (2009-10-26)


From ernest.turro at ic.ac.uk  Wed Feb  3 21:49:42 2010
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Wed, 3 Feb 2010 20:49:42 +0000
Subject: [Rd] ctrl-C aborts R when compiling package code with ICC+openMP
Message-ID: <3A083ED8-8635-48BD-879B-5D6E2BC05AD5@ic.ac.uk>

Hi all,

I have some C++ code that I call from my package. In my main C++ loop, I check for user interrupts and return to the R shell after ensuring I've deallocated memory appropriately. This works fine when the code is compiled with gcc+openmp and with icc without openmp, but when I compile with icc and use openmp, the entire R session is immediately terminated when I hit ctrl-C. This happens even if I only have one thread and even if I set an openmp barrier just before checking for user interrupts.

When the R session terminates unexpectedly, I usually just get "Aborted" before return to the bash prompt. Occasionally, though, I get this error:

OMP: Error #15: Initializing libguide.so, but found libguide.so already initialized.
OMP: Hint: This may cause performance degradation and correctness issues. Set environment variable KMP_DUPLICATE_LIB_OK=TRUE to ignore this problem and force the program to continue anyway. Please note that the use of KMP_DUPLICATE_LIB_OK is unsupported and using it may cause undefined behavior. For more information, please contact Intel(R) Premier Support.

But KMP_DUPLICATE_LIB_OK=TRUE changes nothing.

I had a look at:
http://software.intel.com/en-us/articles/opm-abort-initializing-libguide40dll/

which suggests there may be a conflict between libguide40 and libiomp5md, but I can't find any loaded R packages that link against libiomp5md...

Does anyone have any ideas?

Many thanks,

Ernest

From ernest.turro at ic.ac.uk  Wed Feb  3 22:17:55 2010
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Wed, 3 Feb 2010 21:17:55 +0000
Subject: [Rd] Fwd: ctrl-C aborts R when compiling package code with
	ICC+openMP
References: <3A083ED8-8635-48BD-879B-5D6E2BC05AD5@ic.ac.uk>
Message-ID: <1CC16EB0-3006-41B7-84C1-9DD765554045@ic.ac.uk>

I omitted to mention that when I set KMP_DUPLICATE_LIB_OK=TRUE and OMP_NUM_THREADS=1, I consistently get this error instead:

OMP: Error #13: Assertion failure at kmp_csupport.c(465).
OMP: Hint: Please submit a bug report with this message, compile and run commands used, and machine configuration info including native compiler and operating system versions. Faster response will be obtained by including all program sources. For information on submitting this issue, please see http://www.intel.com/software/products/support/.

Thanks,
Ernest


Begin forwarded message:

> From: Ernest Turro <ernest.turro at imperial.ac.uk>
> Date: 3 February 2010 20:49:42 GMT
> To: r-devel List <r-devel at r-project.org>
> Subject: [Rd] ctrl-C aborts R when compiling package code with ICC+openMP
> x-mailer: Apple Mail (2.1077)
> 
> Hi all,
> 
> I have some C++ code that I call from my package. In my main C++ loop, I check for user interrupts and return to the R shell after ensuring I've deallocated memory appropriately. This works fine when the code is compiled with gcc+openmp and with icc without openmp, but when I compile with icc and use openmp, the entire R session is immediately terminated when I hit ctrl-C. This happens even if I only have one thread and even if I set an openmp barrier just before checking for user interrupts.
> 
> When the R session terminates unexpectedly, I usually just get "Aborted" before return to the bash prompt. Occasionally, though, I get this error:
> 
> OMP: Error #15: Initializing libguide.so, but found libguide.so already initialized.
> OMP: Hint: This may cause performance degradation and correctness issues. Set environment variable KMP_DUPLICATE_LIB_OK=TRUE to ignore this problem and force the program to continue anyway. Please note that the use of KMP_DUPLICATE_LIB_OK is unsupported and using it may cause undefined behavior. For more information, please contact Intel(R) Premier Support.
> 
> But KMP_DUPLICATE_LIB_OK=TRUE changes nothing.
> 
> I had a look at:
> http://software.intel.com/en-us/articles/opm-abort-initializing-libguide40dll/
> 
> which suggests there may be a conflict between libguide40 and libiomp5md, but I can't find any loaded R packages that link against libiomp5md...
> 
> Does anyone have any ideas?
> 
> Many thanks,
> 
> Ernest
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Thu Feb  4 00:10:27 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 3 Feb 2010 17:10:27 -0600
Subject: [Rd] Proposal unary - operator for factors
Message-ID: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>

Hi all,

Why not make the unary minus operator return the factor with levels
reversed?  This would make it much easier to sort factors in
descending order in part of an order statement.

Hadley

-- 
http://had.co.nz/


From wdunlap at tibco.com  Thu Feb  4 00:28:04 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 3 Feb 2010 15:28:04 -0800
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Hadley Wickham
> Sent: Wednesday, February 03, 2010 3:10 PM
> To: r-devel at r-project.org
> Subject: [Rd] Proposal unary - operator for factors
> 
> Hi all,
> 
> Why not make the unary minus operator return the factor with levels
> reversed?  This would make it much easier to sort factors in
> descending order in part of an order statement.

It wouldn't make sense in the context of
   vector[-factor]

Wouldn't it be better to allow order's decreasing argument
to be a vector with one element per ... argument?  That
would work for numbers, factors, dates, and anything
else.  Currently order silently ignores decreasing[2] and
beyond.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> 
> Hadley
> 
> -- 
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From hadley at rice.edu  Thu Feb  4 00:38:11 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 3 Feb 2010 17:38:11 -0600
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com> 
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>
Message-ID: <f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>

> It wouldn't make sense in the context of
> ? vector[-factor]

True, but that doesn't work currently so you wouldn't lose anything.
However, it would make a certain class of problem that used to throw
errors become silent.

> Wouldn't it be better to allow order's decreasing argument
> to be a vector with one element per ... argument? ?That
> would work for numbers, factors, dates, and anything
> else. ?Currently order silently ignores decreasing[2] and
> beyond.

The problem is you might want to do something like order(a, -b, c, -d)

Hadley

-- 
http://had.co.nz/


From wdunlap at tibco.com  Thu Feb  4 00:49:29 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 3 Feb 2010 15:49:29 -0800
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>
	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: h.wickham at gmail.com [mailto:h.wickham at gmail.com] On 
> Behalf Of Hadley Wickham
> Sent: Wednesday, February 03, 2010 3:38 PM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Proposal unary - operator for factors
> 
> > It wouldn't make sense in the context of
> > ? vector[-factor]
> 
> True, but that doesn't work currently so you wouldn't lose anything.
> However, it would make a certain class of problem that used to throw
> errors become silent.
> 
> > Wouldn't it be better to allow order's decreasing argument
> > to be a vector with one element per ... argument? ?That
> > would work for numbers, factors, dates, and anything
> > else. ?Currently order silently ignores decreasing[2] and
> > beyond.
> 
> The problem is you might want to do something like order(a, -b, c, -d)

Currently, for numeric a you can do either
   order(-a)
or
   order(a, decreasing=FALSE)
For nonnumeric types like POSIXct and factors only
the latter works.

Under my proposal your
   order(a, -b, c, d)
would be
   order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
and it would work for any ordably class without modifications
to any classes.

Bill
 
> Hadley
> 
> -- 
> http://had.co.nz/
> 


From murdoch at stats.uwo.ca  Thu Feb  4 01:16:44 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 03 Feb 2010 19:16:44 -0500
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>
Message-ID: <4B6A11EC.7040606@stats.uwo.ca>

On 03/02/2010 6:49 PM, William Dunlap wrote:
>> -----Original Message-----
>> From: h.wickham at gmail.com [mailto:h.wickham at gmail.com] On 
>> Behalf Of Hadley Wickham
>> Sent: Wednesday, February 03, 2010 3:38 PM
>> To: William Dunlap
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Proposal unary - operator for factors
>>
>>> It wouldn't make sense in the context of
>>>   vector[-factor]
>> True, but that doesn't work currently so you wouldn't lose anything.
>> However, it would make a certain class of problem that used to throw
>> errors become silent.
>>
>>> Wouldn't it be better to allow order's decreasing argument
>>> to be a vector with one element per ... argument?  That
>>> would work for numbers, factors, dates, and anything
>>> else.  Currently order silently ignores decreasing[2] and
>>> beyond.
>> The problem is you might want to do something like order(a, -b, c, -d)
> 
> Currently, for numeric a you can do either
>    order(-a)
> or
>    order(a, decreasing=FALSE)
> For nonnumeric types like POSIXct and factors only
> the latter works.
> 
> Under my proposal your
>    order(a, -b, c, d)
> would be
>    order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
> and it would work for any ordably class without modifications
> to any classes.

Why not use

  order(a, -xtfrm(b), c, -xtfrm(d))

??

Duncan Murdoch


From hadley at rice.edu  Thu Feb  4 01:20:47 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 3 Feb 2010 18:20:47 -0600
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <4B6A11EC.7040606@stats.uwo.ca>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com> 
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com> 
	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com> 
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com> 
	<4B6A11EC.7040606@stats.uwo.ca>
Message-ID: <f8e6ff051002031620t84ad1d6tb859ccd5825052fe@mail.gmail.com>

>> Currently, for numeric a you can do either
>> ? order(-a)
>> or
>> ? order(a, decreasing=FALSE)
>> For nonnumeric types like POSIXct and factors only
>> the latter works.
>>
>> Under my proposal your
>> ? order(a, -b, c, d)
>> would be
>> ? order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
>> and it would work for any ordably class without modifications
>> to any classes.
>
> Why not use
>
> ?order(a, -xtfrm(b), c, -xtfrm(d))

That's a good suggestion.  You could make it even easier to read with
desc <- function(x) -xtfrm(x)

order(a, desc(b), c, desc(d))

Could you remind me what xtfrm stands for?

Thanks!

Hadley

-- 
http://had.co.nz/


From wdunlap at tibco.com  Thu Feb  4 01:43:26 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 3 Feb 2010 16:43:26 -0800
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <4B6A11EC.7040606@stats.uwo.ca>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>
	<4B6A11EC.7040606@stats.uwo.ca>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275B18E@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
> Sent: Wednesday, February 03, 2010 4:17 PM
> To: William Dunlap
> Cc: Hadley Wickham; r-devel at r-project.org
> Subject: Re: [Rd] Proposal unary - operator for factors
> 
> On 03/02/2010 6:49 PM, William Dunlap wrote:
> >> -----Original Message-----
> >> From: h.wickham at gmail.com [mailto:h.wickham at gmail.com] On 
> >> Behalf Of Hadley Wickham
> >> Sent: Wednesday, February 03, 2010 3:38 PM
> >> To: William Dunlap
> >> Cc: r-devel at r-project.org
> >> Subject: Re: [Rd] Proposal unary - operator for factors
> >>
> >>> It wouldn't make sense in the context of
> >>>   vector[-factor]
> >> True, but that doesn't work currently so you wouldn't lose 
> anything.
> >> However, it would make a certain class of problem that 
> used to throw
> >> errors become silent.
> >>
> >>> Wouldn't it be better to allow order's decreasing argument
> >>> to be a vector with one element per ... argument?  That
> >>> would work for numbers, factors, dates, and anything
> >>> else.  Currently order silently ignores decreasing[2] and
> >>> beyond.
> >> The problem is you might want to do something like 
> order(a, -b, c, -d)
> > 
> > Currently, for numeric a you can do either
> >    order(-a)
> > or
> >    order(a, decreasing=FALSE)
> > For nonnumeric types like POSIXct and factors only
> > the latter works.
> > 
> > Under my proposal your
> >    order(a, -b, c, d)
> > would be
> >    order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
> > and it would work for any ordably class without modifications
> > to any classes.
> 
> Why not use
> 
>   order(a, -xtfrm(b), c, -xtfrm(d))
> 
> ??

You could, if you can remember it.  I have been annoyed
that decreasing= was in order() but not as useful as it
could be since it is not vectorized.  The same goes for
na.last, although that seems less useful to me.

Here is a version of order (based on the
algorithm using in S+'s order) that
vectorizes the na.last and decreasing
arguments.  It calls the existing order
function to implement decreasing=TRUE/FALSE
and na.last=TRUE/FALSE for a single argument
but order itself could be mofified in this
way.

new.order <- function (..., na.last = TRUE, decreasing = FALSE) 
{
    vectors <- list(...)
    nVectors <- length(vectors)
    stopifnot(nVectors > 0)
    na.last <- rep(na.last, length = nVectors)
    decreasing <- rep(decreasing, length = nVectors)
    keys <- seq_len(length(vectors[[1]]))
    for (i in nVectors:1) {
        v <- vectors[[i]]
        if (length(v) < length(keys)) 
            v <- rep(v, length = length(keys))
        keys <- keys[order(v[keys], na.last = na.last[i], decreasing =
decreasing[i])]
    }
    keys
}

With the following dataset

data <- data.frame(
  ct = as.POSIXct(c("2009-01-01", "2010-02-03",
"2010-02-28"))[c(2,2,2,3,3,1)],
  dt =    as.Date(c("2009-01-01", "2010-02-03",
"2010-02-28"))[c(3,2,2,2,3,1)],
  fac =  factor(c("Small","Medium","Large"),
levels=c("Small","Medium","Large"))[c(1,3,2,3,3,1)],
  n  =    c(11,12,12,11,12,12))

> data
          ct         dt    fac  n
1 2010-02-03 2010-02-28  Small 11
2 2010-02-03 2010-02-03  Large 12
3 2010-02-03 2010-02-03 Medium 12
4 2010-02-28 2010-02-03  Large 11
5 2010-02-28 2010-02-28  Large 12
6 2009-01-01 2009-01-01  Small 12
> data.frame(lapply(data,rank))
   ct  dt fac   n
1 3.0 5.5 1.5 1.5
2 3.0 3.0 5.0 4.5
3 3.0 3.0 3.0 4.5
4 5.5 3.0 5.0 1.5
5 5.5 5.5 5.0 4.5
6 1.0 1.0 1.5 4.5

we get (where my demos use rank because I could remember
the name xtfrm):

> with(data, identical(order(ct,dt), new.order(ct,dt)))
[1] TRUE
> with(data, identical(order(fac,-n),
new.order(fac,n,decreasing=c(FALSE,TRUE))))
[1] TRUE
> with(data, identical(order(ct,-rank(dt)),
new.order(ct,dt,decreasing=c(FALSE,TRUE))))
[1] TRUE
> with(data, identical(order(ct,-rank(fac)),
new.order(ct,fac,decreasing=c(FALSE,TRUE))))
[1] TRUE
> with(data, identical(order(n,-rank(fac)),
new.order(n,fac,decreasing=c(FALSE,TRUE))))
[1] TRUE

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  
> 
> Duncan Murdoch
> 


From murdoch at stats.uwo.ca  Thu Feb  4 01:49:12 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 03 Feb 2010 19:49:12 -0500
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <f8e6ff051002031620t84ad1d6tb859ccd5825052fe@mail.gmail.com>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>
	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>
	<4B6A11EC.7040606@stats.uwo.ca>
	<f8e6ff051002031620t84ad1d6tb859ccd5825052fe@mail.gmail.com>
Message-ID: <4B6A1988.4000600@stats.uwo.ca>

On 03/02/2010 7:20 PM, Hadley Wickham wrote:
>>> Currently, for numeric a you can do either
>>>   order(-a)
>>> or
>>>   order(a, decreasing=FALSE)
>>> For nonnumeric types like POSIXct and factors only
>>> the latter works.
>>>
>>> Under my proposal your
>>>   order(a, -b, c, d)
>>> would be
>>>   order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
>>> and it would work for any ordably class without modifications
>>> to any classes.
>> Why not use
>>
>>  order(a, -xtfrm(b), c, -xtfrm(d))
> 
> That's a good suggestion.  You could make it even easier to read with
> desc <- function(x) -xtfrm(x)
> 
> order(a, desc(b), c, desc(d))
> 
> Could you remind me what xtfrm stands for?

No, I don't think I ever worked it out. :-)

Duncan Murdoch


From felix at nfrac.org  Thu Feb  4 05:20:37 2010
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 4 Feb 2010 15:20:37 +1100
Subject: [Rd] proposal for new axis.Date/axis.POSIXct
In-Reply-To: <94730b8a0912210444l1313c1d2vb780f9ea4e1fb3ad@mail.gmail.com>
References: <94730b8a0912210444l1313c1d2vb780f9ea4e1fb3ad@mail.gmail.com>
Message-ID: <94730b8a1002032020l38cfa76dye4e0916ca8f61804@mail.gmail.com>

[reposting after holiday period]

---------- Forwarded message ----------
From: Felix Andrews <felix at nfrac.org>
Date: 21 December 2009 23:44
Subject: proposal for new axis.Date/axis.POSIXct
To: r-devel at r-project.org


Hi R-devel.

I've noticed a couple of quirks in the current time/date axis
functions (axis.Date, axis.POSIXct, and the equivalents in lattice).
Looking at the code, it seems like a fairly ad-hoc approach, often
using pretty() on components of the time. This is not always ideal -
for example a one-hour interval gets cut into 10-minute chunks rather
than the more natural 15-minute chunks (since pretty() doesn't know
about the minutes in an hour, etc). Generally the number of tick marks
produced varies a lot, and there are a couple of strange cases: try
plot(0:1 ~ as.POSIXct(paste(2002:2003,"-02-01",sep="")))

So, I've written a function prettyDate() that attempts to act like
pretty(), but with dates and times. Like pretty, it takes arguments
'n' and 'min.n' which specify the desired and minimum number of ticks,
respectively.

http://pastie.org/751640

By the way, also listed there is an extension of trunc.POSIXt with
extra units "weeks", "months", "years", "decades", "centuries".

Following is a test of prettyDate() for axis labelling, drawn for a
sequence of different time intervals.

source("http://pastie.org/751640.txt")

steps <-
? ?list("10 secs",
? ? ? ? "1 min", "5 mins", "10 mins", "15 mins", "30 mins",
? ? ? ? "1 hour", "3 hours", "6 hours", "12 hours",
? ? ? ? "1 DSTday", "1 week", "2 weeks",
? ? ? ? "1 month", "3 months", "6 months",
? ? ? ? "1 year", "2 years", "5 years", "10 years",
? ? ? ? "20 years", "50 years", "100 years")
names(steps) <- paste("span =", unlist(steps))

from <- as.POSIXct("2002-02-02 02:02")
devAskNewPage(TRUE)

lapply(steps, function(s) {
? ?times <- seq(from, by = s, length = 2)
? ?plot(0:1 ~ times, yaxt = "n", ylab = "")
? ?x <- mean(par("usr")[1:2])
? ?text(x, 0.5, paste("span:", s), cex = 2)
? ?text(x, 0.33, paste(format(times), collapse="\n"))
? ?text(x, 0.05, "current axis.POSIXct")
? ?text(x, 0.95, "proposed new prettyDate axis, n = 5")
? ?## draw new proposed axis function at top of plot
? ?timelim <- par("usr")[1:2]
? ?mostattributes(timelim) <- attributes(from)
? ?axis(side = 3, at = prettyDate(timelim),
? ? ? ?labels = prettyDate(timelim, do.format=TRUE))
})

devAskNewPage(FALSE)


Is it appropriate / desirable for this to be incorporated into R?


-- 
Felix Andrews / ???
Postdoctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 4670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From ripley at stats.ox.ac.uk  Thu Feb  4 05:34:18 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Feb 2010 04:34:18 +0000 (GMT)
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <4B6A1988.4000600@stats.uwo.ca>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com>
	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com>
	<4B6A11EC.7040606@stats.uwo.ca>
	<f8e6ff051002031620t84ad1d6tb859ccd5825052fe@mail.gmail.com>
	<4B6A1988.4000600@stats.uwo.ca>
Message-ID: <alpine.LFD.2.00.1002040433090.24305@gannet.stats.ox.ac.uk>

On Wed, 3 Feb 2010, Duncan Murdoch wrote:

> On 03/02/2010 7:20 PM, Hadley Wickham wrote:
>>>> Currently, for numeric a you can do either
>>>>   order(-a)
>>>> or
>>>>   order(a, decreasing=FALSE)
>>>> For nonnumeric types like POSIXct and factors only
>>>> the latter works.
>>>> 
>>>> Under my proposal your
>>>>   order(a, -b, c, d)
>>>> would be
>>>>   order(a, b, c, d, decreasing=c(FALSE,TRUE,FALSE,TRUE))
>>>> and it would work for any ordably class without modifications
>>>> to any classes.
>>> Why not use
>>>
>>>  order(a, -xtfrm(b), c, -xtfrm(d))
>> 
>> That's a good suggestion.  You could make it even easier to read with
>> desc <- function(x) -xtfrm(x)
>> 
>> order(a, desc(b), c, desc(d))
>> 
>> Could you remind me what xtfrm stands for?
>
> No, I don't think I ever worked it out. :-)

The same logic as strxfrm.

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hadley at rice.edu  Thu Feb  4 06:19:21 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 3 Feb 2010 23:19:21 -0600
Subject: [Rd] Proposal unary - operator for factors
In-Reply-To: <alpine.LFD.2.00.1002040433090.24305@gannet.stats.ox.ac.uk>
References: <f8e6ff051002031510m4dca3c8co8d69c3117e1deab4@mail.gmail.com> 
	<77EB52C6DD32BA4D87471DCD70C8D7000275B14F@NA-PA-VBE03.na.tibco.com> 
	<f8e6ff051002031538ub5c2892ya83806ad3fe025a0@mail.gmail.com> 
	<77EB52C6DD32BA4D87471DCD70C8D7000275B165@NA-PA-VBE03.na.tibco.com> 
	<4B6A11EC.7040606@stats.uwo.ca>
	<f8e6ff051002031620t84ad1d6tb859ccd5825052fe@mail.gmail.com> 
	<4B6A1988.4000600@stats.uwo.ca>
	<alpine.LFD.2.00.1002040433090.24305@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff051002032119u7f5703dah438ab72f62a3e9a0@mail.gmail.com>

>>> Could you remind me what xtfrm stands for?
>>
>> No, I don't think I ever worked it out. :-)
>
> The same logic as strxfrm.

strxfrm is short for string transform.
=> stxfrm is short for string tansform
=> txfrm is short for tansform
=> xtfrm is short of snatform?

Hadley

-- 
http://had.co.nz/


From b.rowlingson at lancaster.ac.uk  Thu Feb  4 14:43:19 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 4 Feb 2010 13:43:19 +0000
Subject: [Rd] Package Directory Hierarchy: Recursive inclusion of *.R
	possible?
In-Reply-To: <hkbk2v$97e$1@ger.gmane.org>
References: <hkbk2v$97e$1@ger.gmane.org>
Message-ID: <d8ad40b51002040543x189e7c79y862e036957497ae3@mail.gmail.com>

On Wed, Feb 3, 2010 at 10:40 AM, Johannes Graumann
<johannes_graumann at web.de> wrote:
> Hello,
>
> I would like to organize the "R" directory in my home-grown package into
> sub-directories, but "R CMD --build" doesn't seem to find *.R files below
> the actual source directory. Is there any way around that?

This was discussed in December:

http://finzi.psych.upenn.edu/R/R-devel/2009-December/056022.html

The conclusion was that if Hadley Wickham can manage 145 files in his
R directory for ggplot2, then so can you. Like we're all superhuman.

It would be nice, but probably need way too many patches to the
various build tools.

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From hadley at rice.edu  Thu Feb  4 16:53:51 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 4 Feb 2010 09:53:51 -0600
Subject: [Rd] Why is there no c.factor?
Message-ID: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>

Hi all,

Is there are reason that there is no c.factor method?  Analogous to
c.Date, I'd expect something like the following to be useful:

c.factor <- function(...) {
  factors <- list(...)
  levels <- unique(unlist(lapply(factors, levels)))
  char <- unlist(lapply(factors, as.character))

  factor(char, levels = levels)
}

c(factor("a"), factor("b"), factor(c("c", "b","a")), factor("d"))
# [1] a b c b a d
# Levels: a b c d

Hadley

-- 
http://had.co.nz/


From tlumley at u.washington.edu  Thu Feb  4 17:13:04 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Feb 2010 08:13:04 -0800 (PST)
Subject: [Rd] Package Directory Hierarchy: Recursive inclusion of *.R
 possible?
In-Reply-To: <d8ad40b51002040543x189e7c79y862e036957497ae3@mail.gmail.com>
Message-ID: <alpine.LRH.2.01.1002040813040.14023@hymn34.u.washington.edu>

On Thu, 4 Feb 2010, Barry Rowlingson wrote:

> On Wed, Feb 3, 2010 at 10:40 AM, Johannes Graumann
> <johannes_graumann at web.de> wrote:
>> Hello,
>>
>> I would like to organize the "R" directory in my home-grown package into
>> sub-directories, but "R CMD --build" doesn't seem to find *.R files below
>> the actual source directory. Is there any way around that?
>

Not really.  You could always manage your files in a separate directory tree and then use a Makefile to put them into the package format.

     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Thu Feb  4 18:06:47 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Feb 2010 09:06:47 -0800 (PST)
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
Message-ID: <alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu>

On Thu, 4 Feb 2010, Hadley Wickham wrote:

> Hi all,
>
> Is there are reason that there is no c.factor method?  Analogous to
> c.Date, I'd expect something like the following to be useful:
>
> c.factor <- function(...) {
>  factors <- list(...)
>  levels <- unique(unlist(lapply(factors, levels)))
>  char <- unlist(lapply(factors, as.character))
>
>  factor(char, levels = levels)
> }
>
> c(factor("a"), factor("b"), factor(c("c", "b","a")), factor("d"))
> # [1] a b c b a d
> # Levels: a b c d
>

It's well established that different people have different views on what factors should do, but this doesn't match mine.   I think of factors as enumerated data types where the factor levels already specify all the valid values for the factor, so I wouldn't want to be able to combine two factors with different sets of levels.

For example:
   A <- factor("orange",levels=c("orange","yellow","red","purple"))
   B <- factor("orange", levels=c("orange","apple","mango", "banananana"))

On the other hand, I think the current behaviour, which reduces them to numbers, is just wrong.


       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From jfox at mcmaster.ca  Thu Feb  4 18:29:15 2010
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 4 Feb 2010 12:29:15 -0500
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
	<alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu>
Message-ID: <007201caa5bf$93018f50$b904adf0$@ca>

Dear Thomas and Hadley,

I'd propose the following: If the sets of levels of all arguments are the
same, then c.factor() would return a factor with the common set of levels;
if the sets of levels differ, then, as Hadley suggests, the level-set of the
result would be the union of sets of levels of the arguments, but a warning
would be issued.

Best,
 John


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of Thomas Lumley
> Sent: February-04-10 12:07 PM
> To: Hadley Wickham
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Why is there no c.factor?
> 
> On Thu, 4 Feb 2010, Hadley Wickham wrote:
> 
> > Hi all,
> >
> > Is there are reason that there is no c.factor method?  Analogous to
> > c.Date, I'd expect something like the following to be useful:
> >
> > c.factor <- function(...) {
> >  factors <- list(...)
> >  levels <- unique(unlist(lapply(factors, levels)))
> >  char <- unlist(lapply(factors, as.character))
> >
> >  factor(char, levels = levels)
> > }
> >
> > c(factor("a"), factor("b"), factor(c("c", "b","a")), factor("d"))
> > # [1] a b c b a d
> > # Levels: a b c d
> >
> 
> It's well established that different people have different views on what
> factors should do, but this doesn't match mine.   I think of factors as
> enumerated data types where the factor levels already specify all the
valid
> values for the factor, so I wouldn't want to be able to combine two
factors
> with different sets of levels.
> 
> For example:
>    A <- factor("orange",levels=c("orange","yellow","red","purple"))
>    B <- factor("orange", levels=c("orange","apple","mango", "banananana"))
> 
> On the other hand, I think the current behaviour, which reduces them to
> numbers, is just wrong.
> 
> 
>        -thomas
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pburns at pburns.seanet.com  Thu Feb  4 17:45:21 2010
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 04 Feb 2010 16:45:21 +0000
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
Message-ID: <4B6AF9A1.4080605@pburns.seanet.com>

The argument I have in 'The R Inferno'
is that how you want to combine factors
may differ from someone else's desires.

There are lots of tricky questions:
What about ordered factors?
What if the ordered levels are different in
different objects?
...

Pat


On 04/02/2010 15:53, Hadley Wickham wrote:
> Hi all,
>
> Is there are reason that there is no c.factor method?  Analogous to
> c.Date, I'd expect something like the following to be useful:
>
> c.factor<- function(...) {
>    factors<- list(...)
>    levels<- unique(unlist(lapply(factors, levels)))
>    char<- unlist(lapply(factors, as.character))
>
>    factor(char, levels = levels)
> }
>
> c(factor("a"), factor("b"), factor(c("c", "b","a")), factor("d"))
> # [1] a b c b a d
> # Levels: a b c d
>
> Hadley
>

-- 
Patrick Burns
pburns at pburns.seanet.com
http://www.burns-stat.com
(home of 'The R Inferno' and 'A Guide for the Unwilling S User')


From hadley at rice.edu  Thu Feb  4 19:03:38 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 4 Feb 2010 12:03:38 -0600
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <007201caa5bf$93018f50$b904adf0$@ca>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com> 
	<alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu> 
	<007201caa5bf$93018f50$b904adf0$@ca>
Message-ID: <f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com>

> I'd propose the following: If the sets of levels of all arguments are the
> same, then c.factor() would return a factor with the common set of levels;
> if the sets of levels differ, then, as Hadley suggests, the level-set of the
> result would be the union of sets of levels of the arguments, but a warning
> would be issued.

I like this compromise (as long as there was an argument to suppress
the warning)

Hadley


-- 
http://had.co.nz/


From h.wickham at gmail.com  Thu Feb  4 19:04:17 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 4 Feb 2010 12:04:17 -0600
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <4B6AF9A1.4080605@pburns.seanet.com>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com> 
	<4B6AF9A1.4080605@pburns.seanet.com>
Message-ID: <f8e6ff051002041004r421a2b85t67514a29b898f814@mail.gmail.com>

On Thu, Feb 4, 2010 at 10:45 AM, Patrick Burns <pburns at pburns.seanet.com> wrote:
> The argument I have in 'The R Inferno'
> is that how you want to combine factors
> may differ from someone else's desires.
>
> There are lots of tricky questions:
> What about ordered factors?
> What if the ordered levels are different in
> different objects?

Ordered factors are trickier.  I'd suggest the following compromise:

 * if all orders are the same, return an ordered factor
 * if not, return a factor with a warning

Hadley

-- 
http://had.co.nz/


From mdowle at mdowle.plus.com  Thu Feb  4 19:42:33 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 4 Feb 2010 18:42:33 -0000
Subject: [Rd] Why is there no c.factor?
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
Message-ID: <hkf4er$qmq$1@ger.gmane.org>

A search for "c.factor" returns tons of hits on this topic.

Heres just one of the hits from 2006, when I asked the same question : 
http://tolstoy.newcastle.edu.au/R/e2/devel/06/11/1137.html

So it appears to be complicated and there are good reasons.
Since I needed it, I created c.factor in data.table package, below. It does 
it more efficiently since it doesn't convert each factor to character (hence 
losing some of the benefit). I've been told I'm not unique in this approach 
and that other packages also have their own c.factor.  It deliberately isn't 
exported.  Its worked well for me over the years anyway.

c.factor = function(...)
{
    args <- list(...)
    for (i in seq(along=args)) if (!is.factor(args[[i]])) args[[i]] = 
as.factor(args[[i]])
    # The first must be factor otherwise we wouldn't be inside c.factor, its 
checked anyway in the line above.
    newlevels = sort(unique(unlist(lapply(args,levels))))
    ans = unlist(lapply(args, function(x) {
        m = match(levels(x), newlevels)
        m[as.integer(x)]
    }))
    levels(ans) = newlevels
    class(ans) = "factor"
    ans
}

"Hadley Wickham" <hadley at rice.edu> wrote in message 
news:f8e6ff051002040753x33282f33l78fce9f98dc29ae8 at mail.gmail.com...
> Hi all,
>
> Is there are reason that there is no c.factor method?  Analogous to
> c.Date, I'd expect something like the following to be useful:
>
> c.factor <- function(...) {
>  factors <- list(...)
>  levels <- unique(unlist(lapply(factors, levels)))
>  char <- unlist(lapply(factors, as.character))
>
>  factor(char, levels = levels)
> }
>
> c(factor("a"), factor("b"), factor(c("c", "b","a")), factor("d"))
> # [1] a b c b a d
> # Levels: a b c d
>
> Hadley
>
> -- 
> http://had.co.nz/
>


From diggsb at ohsu.edu  Thu Feb  4 22:39:43 2010
From: diggsb at ohsu.edu (Brian Diggs)
Date: Thu, 4 Feb 2010 13:39:43 -0800
Subject: [Rd] Error with cut.POSIXt and daylight savings time switchover
 dates (patch included)
In-Reply-To: <E5BA65CAFB491A4DBB1370F6C972165502AEAD7498@EX-MB05.ohsu.edu>
References: <E5BA65CAFB491A4DBB1370F6C972165502AE890131@EX-MB05.ohsu.edu>
	<E5BA65CAFB491A4DBB1370F6C972165502AEAD7498@EX-MB05.ohsu.edu>
Message-ID: <E5BA65CAFB491A4DBB1370F6C972165502AEAD76F3@EX-MB05.ohsu.edu>

On 2/3/2010 7:48 AM, Brian Diggs wrote:
> On 2/1/2010 3:57 PM, Brian Diggs wrote:
>> The following code:
>>
>> cut(as.POSIXct("2009-11-01 04:00:00", tz="America/Los_Angeles"), "1 day")
>>
>> gives the error:
>>
>> Error in seq.int(0, to - from, by) : 'to' must be finite

[details deleted...]

>> Is there a timezone/daylight savings time safe way to get to the
>> beginning of the day in cut.POSIXt so that invalid dates are not sent
>> to the other functions?  Alternatively, can as.POSIXct.POSIXlt be
>> made to handle these manually manipulated dates correctly?
> 
> I realized I forgot my session info:
> 
>> sessionInfo()
> R version 2.10.1 (2009-12-14) 
> i386-pc-mingw32 
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 
> [2] LC_CTYPE=English_United States.1252   
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                          
> [5] LC_TIME=English_United States.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> 
>> -- Brian Diggs, Ph.D. Senior Research Associate, Department of
>> Surgery, Oregon Health & Science University
> 

A post by Felix Andrews in a different thread pointed out the trunc.POSIXt function.  I checked, and it properly handles the daylight savings time issue:

tm <- as.POSIXlt("2009-11-01 04:00:00", tz="America/Los_Angeles")
tm <- trunc(tm, "days")
as.POSIXct(tm)
# [1] "2009-11-01 PDT"

Looking at how trunc.POSIXt does this, I created a patch (included below) for cut.POSIXt  so that it won't break either.  I've not extensively tested this patch (I don't have the R build environment for Windows installed on my machine), but being analogous to existing base code, it should work generally.


Index: datetime.R
===================================================================
--- datetime.R	(revision 51101)
+++ datetime.R	(working copy)
@@ -729,7 +729,7 @@
 	incr <- 1
 	if(valid > 1L) { start$sec <- 0L; incr <- 59.99 }
 	if(valid > 2L) { start$min <- 0L; incr <- 3600 - 1 }
-	if(valid > 3L) { start$hour <- 0L; incr <- 86400 - 1 }
+	if(valid > 3L) { start$hour <- 0L; start$isdst <- -1L; incr <- 86400 - 1 }
 	if(valid == 5L) { # weeks
 	    start$mday <- start$mday - start$wday
 	    if(start.on.monday)


From Havard.Rue at math.ntnu.no  Thu Feb  4 18:20:13 2010
From: Havard.Rue at math.ntnu.no (Havard.Rue at math.ntnu.no)
Date: Thu,  4 Feb 2010 18:20:13 +0100 (CET)
Subject: [Rd] Bug in as.character? (PR#14206)
Message-ID: <20100204172013.C3638282EFC0@mail.pubhealth.ku.dk>


A long formula which is converted using as.character, looses its last
part: ``diagonal = 1e-12)'' 

Shorter formula is ok though.

Best,
H??vard

************

Browse[2]> formula.str
y ~ -1 + b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 + b9 + b10 + b11 + 
    b12 + b13 + b14 + b15 + b16 + b17 + b18 + b19 + b20 + b21 + 
    b22 + b23 + b24 + b25 + b26 + b27 + b28 + b29 + b30 + b31 + 
    b32 + b33 + b34 + b35 + b36 + b37 + b38 + b39 + b40 + b41 + 
    b42 + b43 + b44 + b45 + b46 + b47 + b48 + b49 + elevation + 
    f(idx, model = "sphere", sphere.dir = "global_temperature_80s", 
        T.order = 2, K.order = 2, T.model = "rotsym", K.model =
"rotsym", 
        initial = c(-4, 1, 0), param = c(-4, 0.01, 3, 0.01, 0, 
            1), replicate = replicate, diagonal = 1e-12)

Browse[2]> formula.str[3]
-1 + b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 + b9 + b10 + b11 + 
    b12 + b13 + b14 + b15 + b16 + b17 + b18 + b19 + b20 + b21 + 
    b22 + b23 + b24 + b25 + b26 + b27 + b28 + b29 + b30 + b31 + 
    b32 + b33 + b34 + b35 + b36 + b37 + b38 + b39 + b40 + b41 + 
    b42 + b43 + b44 + b45 + b46 + b47 + b48 + b49 + elevation + 
    f(idx, model = "sphere", sphere.dir = "global_temperature_80s", 
        T.order = 2, K.order = 2, T.model = "rotsym", K.model =
"rotsym", 
        initial = c(-4, 1, 0), param = c(-4, 0.01, 3, 0.01, 0, 
            1), replicate = replicate, diagonal = 1e-12)()

Browse[2]> as.character(formula.str[3])
[1] "-1 + b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 + b9 + b10 + b11 + b12 +
b13 + b14 + b15 + b16 + b17 + b18 + b19 + b20 + b21 + b22 + b23 + b24 +
b25 + b26 + b27 + b28 + b29 + b30 + b31 + b32 + b33 + b34 + b35 + b36 +
b37 + b38 + b39 + b40 + b41 + b42 + b43 + b44 + b45 + b46 + b47 + b48 +
b49 + elevation + f(idx, model = \"sphere\", sphere.dir =
\"global_temperature_80s\", T.order = 2, K.order = 2, T.model = \"rotsym
\", K.model = \"rotsym\", initial = c(-4, 1, 0), param = c(-4, 0.01, 3,
0.01, 0, 1), replicate = replicate, "



--please do not edit the information below--

Version:
 platform = x86_64-redhat-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 10.1
 year = 2009
 month = 12
 day = 14
 svn rev = 50720
 language = R
 version.string = R version 2.10.1 (2009-12-14)

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_DK.utf8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:datasets, package:INLA, package:R.utils, package:R.oo,
package:utils, package:R.methodsS3, package:methods, Autoloads,
package:base

-- 
 H??vard Rue
 Department of Mathematical Sciences
 Norwegian University of Science and Technology
 N-7491 Trondheim, Norway
 Voice: +47-7359-3533    URL  : http://www.math.ntnu.no/~hrue  
 Fax  : +47-7359-3524    Email: havard.rue at math.ntnu.no

 This message was created in a Microsoft-free computing environment.


From P.Dalgaard at biostat.ku.dk  Fri Feb  5 10:34:27 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 05 Feb 2010 10:34:27 +0100
Subject: [Rd] Bug in as.character? (PR#14206)
In-Reply-To: <20100204172013.C3638282EFC0@mail.pubhealth.ku.dk>
References: <20100204172013.C3638282EFC0@mail.pubhealth.ku.dk>
Message-ID: <4B6BE623.30701@biostat.ku.dk>

Havard.Rue at math.ntnu.no wrote:
> A long formula which is converted using as.character, looses its last
> part: ``diagonal = 1e-12)'' 
> 
> Shorter formula is ok though.

(If you have to put a ? in a bug report, ask instead!)

This is entirely consistent with  help(as.character):

Note:

     ?as.character? truncates components of language objects to 500
     characters (was about 70 before 1.3.1).


If you insist on working with very long formulas in their character
representation, you need to use deparse() and deal with the resulting
multi-line character vectors. (I can't tell what you're trying to do,
but update.formula() may provide a cleaner way of modifying formulas.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From hadley at rice.edu  Fri Feb  5 15:43:44 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 5 Feb 2010 08:43:44 -0600
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com> 
	<alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu> 
	<007201caa5bf$93018f50$b904adf0$@ca>
	<f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com>
Message-ID: <f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com>

On Thu, Feb 4, 2010 at 12:03 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> I'd propose the following: If the sets of levels of all arguments are the
>> same, then c.factor() would return a factor with the common set of levels;
>> if the sets of levels differ, then, as Hadley suggests, the level-set of the
>> result would be the union of sets of levels of the arguments, but a warning
>> would be issued.
>
> I like this compromise (as long as there was an argument to suppress
> the warning)

If I provided code to do this, along with the warnings for ordered
factors and using the optimisation suggested by Matthew, is there any
member of R core would be interested in sponsoring it?

Hadley

-- 
http://had.co.nz/


From P.Dalgaard at biostat.ku.dk  Fri Feb  5 16:41:08 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 05 Feb 2010 16:41:08 +0100
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com>
	<alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu>
	<007201caa5bf$93018f50$b904adf0$@ca>	<f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com>
	<f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com>
Message-ID: <4B6C3C14.5060700@biostat.ku.dk>

Hadley Wickham wrote:
> On Thu, Feb 4, 2010 at 12:03 PM, Hadley Wickham <hadley at rice.edu> wrote:
>>> I'd propose the following: If the sets of levels of all arguments are the
>>> same, then c.factor() would return a factor with the common set of levels;
>>> if the sets of levels differ, then, as Hadley suggests, the level-set of the
>>> result would be the union of sets of levels of the arguments, but a warning
>>> would be issued.
>> I like this compromise (as long as there was an argument to suppress
>> the warning)
> 
> If I provided code to do this, along with the warnings for ordered
> factors and using the optimisation suggested by Matthew, is there any
> member of R core would be interested in sponsoring it?
> 
> Hadley
> 

Messing with c() is a bit unattractive (I'm not too happy with the other
c methods either; normally c() strips attributes and reduces to the base
class, and those obviously do not), but a more general concat() function
has been suggested a number of times. With a suitable range of methods,
this could also be used to reimplement rbind.data.frame (which,
incidentally, already contains a method for concatenating factors, with
several ugly warts!)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From wdunlap at tibco.com  Fri Feb  5 17:17:54 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Feb 2010 08:17:54 -0800
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <4B6C3C14.5060700@biostat.ku.dk>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com><alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu><007201caa5bf$93018f50$b904adf0$@ca>	<f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com><f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com>
	<4B6C3C14.5060700@biostat.ku.dk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275B4CA@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Friday, February 05, 2010 7:41 AM
> To: Hadley Wickham
> Cc: John Fox; r-devel at r-project.org; Thomas Lumley
> Subject: Re: [Rd] Why is there no c.factor?
> 
> Hadley Wickham wrote:
> > On Thu, Feb 4, 2010 at 12:03 PM, Hadley Wickham 
> <hadley at rice.edu> wrote:
> >>> I'd propose the following: If the sets of levels of all 
> arguments are the
> >>> same, then c.factor() would return a factor with the 
> common set of levels;
> >>> if the sets of levels differ, then, as Hadley suggests, 
> the level-set of the
> >>> result would be the union of sets of levels of the 
> arguments, but a warning
> >>> would be issued.
> >> I like this compromise (as long as there was an argument 
> to suppress
> >> the warning)
> > 
> > If I provided code to do this, along with the warnings for ordered
> > factors and using the optimisation suggested by Matthew, is 
> there any
> > member of R core would be interested in sponsoring it?
> > 
> > Hadley
> > 
> 
> Messing with c() is a bit unattractive (I'm not too happy 
> with the other
> c methods either; normally c() strips attributes and reduces 
> to the base
> class, and those obviously do not), but a more general 
> concat() function
> has been suggested a number of times. With a suitable range 
> of methods,
> this could also be used to reimplement rbind.data.frame (which,
> incidentally, already contains a method for concatenating 
> factors, with
> several ugly warts!)

Yes, c() should have been put on the deprecated list a couple
of decades ago, since people expect it to do too many
incompatible things.  And factor should have been a virtual
class, with subclasses "FixedLevels" (e.g., Sex) or "AdHocLevels"
(e.g., FamilyName), so c() and [()<- could do the appropriate
thing in either case.

Back to reality, S+ has a concat(...) function, whose comments say
	# This function works like c() except that names of arguments are
	# ignored.  That is, it concatenates its arguments into a single
	# S vector object, without considering the names of the arguments, 
	# in the order that the arguments are given.
	#
	# To make this function work for new classes, it is only necessary
	# to make methods for the concat.two function, which concatenates
	# two vectors; recursion will take care of the rest.
concat() is not generic but it repeatedly calls concat.two(x,y), an
SV4-generic that dispatches on the classes of x and y.  Thus you
can easily predict the class of concat(x,y,z), although it may not
be the same as the class of concat(z,y,x), given suitably bizarre
methods for concat.two().

concat() doesn't get a lot of use but I think the idea is sound.
Perhaps that model would work well for a concatenation function in R.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark      Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From S.Ellison at lgc.co.uk  Fri Feb  5 18:01:21 2010
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 05 Feb 2010 17:01:21 +0000
Subject: [Rd] Why is there no c.factor?
Message-ID: <sb6c4ef3.087@tedmail.lgc.co.uk>



>c() should have been put on the deprecated list a couple
>of decades ago

Don't you dare!

>Back to reality
phew! had me worried there.

c() is no problem at all for lists, Dates and most simple vector types;
why deprecate something solely because it doesn't behave for something
it doesn't claim to work on?


Steve E

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mdowle at mdowle.plus.com  Fri Feb  5 20:17:27 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Fri, 5 Feb 2010 19:17:27 -0000
Subject: [Rd] Why is there no c.factor?
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com><alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu><007201caa5bf$93018f50$b904adf0$@ca>	<f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com><f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com><4B6C3C14.5060700@biostat.ku.dk>
	<77EB52C6DD32BA4D87471DCD70C8D7000275B4CA@NA-PA-VBE03.na.tibco.com>
Message-ID: <hkhqs9$cn5$1@ger.gmane.org>


> concat() doesn't get a lot of use
How do you know?  Maybe its used a lot but the users had no need to tell you 
what they were using. The exact opposite might in fact be the case i.e. 
because concat is so good in splus,  you just never hear of problems with it 
from the users. That might be a very good sign.

> perhaps that model would work well for a concatenation function in R
I'd be happy to test it. I'm a bit concerned about performance though given 
what you said about repeated recursive calls, and dispatch. Could you run 
the following test in s-plus please and post back the timing?  If this small 
100MB example was fine, then we could proceed to a 64bit 10GB test. This is 
quite nippy at the moment in R (1.1sec). I'd be happy with a better way as 
long as speed wasn't compromised.

set.seed(1)
L = as.vector(outer(LETTERS,LETTERS,paste,sep=""))       # union set of 676 
levels
F = lapply(1:100, function(i) 
{                                                # create 100 factors
   f = sample(1:100, 1*1024^2 / 4, replace=TRUE)               # each factor 
1MB large (262144 integers), plus small amount for the levels
   levels(f) = sample(L,100) 
# pick 100 levels from the union set
   class(f) = "factor"
   f
})

> head(F[[1]])
[1] RT DM CO JV BG KU
100 Levels: YC FO PN IL CB CY HQ ...
> head(F[[2]])
[1] RK PD FE SG SJ CQ
100 Levels: JV FV DX NL XB ND CY QQ ...
>

With c.factor from data.table, as posted, placed in .GlobalEnv

> system.time(G <- do.call("c",F))
   user  system elapsed
   0.81    0.32    1.12
> head(G)
[1] RT DM CO JV BG KU        # looks right, comparing to F[[1]] above
676 Levels: AA AB AC AD AE AF AG AH AI AJ AK AL AM AN AO AP AQ AR AS AT AU 
AV AW AX AY AZ BA BB BC BD BE BF ... ZZ
> G[262145:262150]
[1] RK PD FE SG SJ CQ          # looks right, comparing to F[[2]] above
676 Levels: AA AB AC AD AE AF AG AH AI AJ AK AL AM AN AO AP AQ AR AS AT AU 
AV AW AX AY AZ BA BB BC BD BE BF ... ZZ
> identical(as.character(G),as.character(unlist(F)))
[1] TRUE

So I guess this would be compared to following in splus ?

system.time(G <- do.call("concat", F))

or maybe its just the following :

system.time(G <- concat(F))

I don't have splus so I can't test that myself.


"William Dunlap" <wdunlap at tibco.com> wrote in message 
news:77EB52C6DD32BA4D87471DCD70C8D7000275B4CA at NA-PA-VBE03.na.tibco.com...
> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Friday, February 05, 2010 7:41 AM
> To: Hadley Wickham
> Cc: John Fox; r-devel at r-project.org; Thomas Lumley
> Subject: Re: [Rd] Why is there no c.factor?
>
> Hadley Wickham wrote:
> > On Thu, Feb 4, 2010 at 12:03 PM, Hadley Wickham
> <hadley at rice.edu> wrote:
> >>> I'd propose the following: If the sets of levels of all
> arguments are the
> >>> same, then c.factor() would return a factor with the
> common set of levels;
> >>> if the sets of levels differ, then, as Hadley suggests,
> the level-set of the
> >>> result would be the union of sets of levels of the
> arguments, but a warning
> >>> would be issued.
> >> I like this compromise (as long as there was an argument
> to suppress
> >> the warning)
> >
> > If I provided code to do this, along with the warnings for ordered
> > factors and using the optimisation suggested by Matthew, is
> there any
> > member of R core would be interested in sponsoring it?
> >
> > Hadley
> >
>
> Messing with c() is a bit unattractive (I'm not too happy
> with the other
> c methods either; normally c() strips attributes and reduces
> to the base
> class, and those obviously do not), but a more general
> concat() function
> has been suggested a number of times. With a suitable range
> of methods,
> this could also be used to reimplement rbind.data.frame (which,
> incidentally, already contains a method for concatenating
> factors, with
> several ugly warts!)

Yes, c() should have been put on the deprecated list a couple
of decades ago, since people expect it to do too many
incompatible things.  And factor should have been a virtual
class, with subclasses "FixedLevels" (e.g., Sex) or "AdHocLevels"
(e.g., FamilyName), so c() and [()<- could do the appropriate
thing in either case.

Back to reality, S+ has a concat(...) function, whose comments say
# This function works like c() except that names of arguments are
# ignored.  That is, it concatenates its arguments into a single
# S vector object, without considering the names of the arguments,
# in the order that the arguments are given.
#
# To make this function work for new classes, it is only necessary
# to make methods for the concat.two function, which concatenates
# two vectors; recursion will take care of the rest.
concat() is not generic but it repeatedly calls concat.two(x,y), an
SV4-generic that dispatches on the classes of x and y.  Thus you
can easily predict the class of concat(x,y,z), although it may not
be the same as the class of concat(z,y,x), given suitably bizarre
methods for concat.two().

concat() doesn't get a lot of use but I think the idea is sound.
Perhaps that model would work well for a concatenation function in R.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

>
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark      Ph:
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:
> (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Fri Feb  5 20:43:38 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Feb 2010 11:43:38 -0800
Subject: [Rd] Why is there no c.factor?
In-Reply-To: <hkhqs9$cn5$1@ger.gmane.org>
References: <f8e6ff051002040753x33282f33l78fce9f98dc29ae8@mail.gmail.com><alpine.LRH.2.01.1002040906470.14023@hymn34.u.washington.edu><007201caa5bf$93018f50$b904adf0$@ca>	<f8e6ff051002041003v41927bd4s56b8a8d42cc63953@mail.gmail.com><f8e6ff051002050643gf9335cfia7d39f9c0c7f3583@mail.gmail.com><4B6C3C14.5060700@biostat.ku.dk><77EB52C6DD32BA4D87471DCD70C8D7000275B4CA@NA-PA-VBE03.na.tibco.com>
	<hkhqs9$cn5$1@ger.gmane.org>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275B598@NA-PA-VBE03.na.tibco.com>

> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Matthew Dowle
> Sent: Friday, February 05, 2010 11:17 AM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] Why is there no c.factor?
> 
> 
> > concat() doesn't get a lot of use
> How do you know?  Maybe its used a lot but the users had no 
> need to tell you 
> what they were using. The exact opposite might in fact be the 
> case i.e. 
> because concat is so good in splus,  you just never hear of 
> problems with it 
> from the users. That might be a very good sign.

We don't use concat in many of our functions.
It tends to be used only where c fails.  It
is slower than c(), in part because it is an SV4
generic while c is a .Internal (the fastest S+
interface to C code).  concat() is also written
entirely in S code, with calls to heavyweights like
sapply.  Writing it in C would speed it up a lot.

  > sys.time(for(i in 1:10000)c(1,2))
  [1] 0.27 0.27
  > sys.time(for(i in 1:10000)concat(1,2))
  [1] 20.29 20.29
  > sys.time(for(i in 1:10000)concat.two(1,2))
  [1] 0.52 0.52

The last just calls the default method of concat.two,
which is a call to c().

> 
> > perhaps that model would work well for a concatenation function in R
> I'd be happy to test it. I'm a bit concerned about 
> performance though given 
> what you said about repeated recursive calls, and dispatch. 
> Could you run 
> the following test in s-plus please and post back the timing? 
>  If this small 
> 100MB example was fine, then we could proceed to a 64bit 10GB 
> test. This is 
> quite nippy at the moment in R (1.1sec). I'd be happy with a 
> better way as 
> long as speed wasn't compromised.
> 
> set.seed(1)
> L = as.vector(outer(LETTERS,LETTERS,paste,sep=""))       # 
> union set of 676 
> levels
> F = lapply(1:100, function(i) 
> {                                                # create 100 factors
>    f = sample(1:100, 1*1024^2 / 4, replace=TRUE)              
>  # each factor 
> 1MB large (262144 integers), plus small amount for the levels
>    levels(f) = sample(L,100) 
> # pick 100 levels from the union set
>    class(f) = "factor"
>    f
> })
> 
> > head(F[[1]])
> [1] RT DM CO JV BG KU
> 100 Levels: YC FO PN IL CB CY HQ ...
> > head(F[[2]])
> [1] RK PD FE SG SJ CQ
> 100 Levels: JV FV DX NL XB ND CY QQ ...
> >
> 
> With c.factor from data.table, as posted, placed in .GlobalEnv
> 
> > system.time(G <- do.call("c",F))
>    user  system elapsed
>    0.81    0.32    1.12
> > head(G)
> [1] RT DM CO JV BG KU        # looks right, comparing to F[[1]] above
> 676 Levels: AA AB AC AD AE AF AG AH AI AJ AK AL AM AN AO AP 
> AQ AR AS AT AU 
> AV AW AX AY AZ BA BB BC BD BE BF ... ZZ
> > G[262145:262150]
> [1] RK PD FE SG SJ CQ          # looks right, comparing to 
> F[[2]] above
> 676 Levels: AA AB AC AD AE AF AG AH AI AJ AK AL AM AN AO AP 
> AQ AR AS AT AU 
> AV AW AX AY AZ BA BB BC BD BE BF ... ZZ
> > identical(as.character(G),as.character(unlist(F)))
> [1] TRUE
> 
> So I guess this would be compared to following in splus ?
> 
> system.time(G <- do.call("concat", F))
> 
> or maybe its just the following :
> 
> system.time(G <- concat(F))
> 
> I don't have splus so I can't test that myself.
> 
> 
> "William Dunlap" <wdunlap at tibco.com> wrote in message 
> news:77EB52C6DD32BA4D87471DCD70C8D7000275B4CA at NA-PA-VBE03.na.t
ibco.com...
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> > Sent: Friday, February 05, 2010 7:41 AM
> > To: Hadley Wickham
> > Cc: John Fox; r-devel at r-project.org; Thomas Lumley
> > Subject: Re: [Rd] Why is there no c.factor?
> >
> > Hadley Wickham wrote:
> > > On Thu, Feb 4, 2010 at 12:03 PM, Hadley Wickham
> > <hadley at rice.edu> wrote:
> > >>> I'd propose the following: If the sets of levels of all
> > arguments are the
> > >>> same, then c.factor() would return a factor with the
> > common set of levels;
> > >>> if the sets of levels differ, then, as Hadley suggests,
> > the level-set of the
> > >>> result would be the union of sets of levels of the
> > arguments, but a warning
> > >>> would be issued.
> > >> I like this compromise (as long as there was an argument
> > to suppress
> > >> the warning)
> > >
> > > If I provided code to do this, along with the warnings for ordered
> > > factors and using the optimisation suggested by Matthew, is
> > there any
> > > member of R core would be interested in sponsoring it?
> > >
> > > Hadley
> > >
> >
> > Messing with c() is a bit unattractive (I'm not too happy
> > with the other
> > c methods either; normally c() strips attributes and reduces
> > to the base
> > class, and those obviously do not), but a more general
> > concat() function
> > has been suggested a number of times. With a suitable range
> > of methods,
> > this could also be used to reimplement rbind.data.frame (which,
> > incidentally, already contains a method for concatenating
> > factors, with
> > several ugly warts!)
> 
> Yes, c() should have been put on the deprecated list a couple
> of decades ago, since people expect it to do too many
> incompatible things.  And factor should have been a virtual
> class, with subclasses "FixedLevels" (e.g., Sex) or "AdHocLevels"
> (e.g., FamilyName), so c() and [()<- could do the appropriate
> thing in either case.
> 
> Back to reality, S+ has a concat(...) function, whose comments say
> # This function works like c() except that names of arguments are
> # ignored.  That is, it concatenates its arguments into a single
> # S vector object, without considering the names of the arguments,
> # in the order that the arguments are given.
> #
> # To make this function work for new classes, it is only necessary
> # to make methods for the concat.two function, which concatenates
> # two vectors; recursion will take care of the rest.
> concat() is not generic but it repeatedly calls concat.two(x,y), an
> SV4-generic that dispatches on the classes of x and y.  Thus you
> can easily predict the class of concat(x,y,z), although it may not
> be the same as the class of concat(z,y,x), given suitably bizarre
> methods for concat.two().
> 
> concat() doesn't get a lot of use but I think the idea is sound.
> Perhaps that model would work well for a concatenation function in R.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> >
> > -- 
> >    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph:
> > (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:
> > (+45) 35327907
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From cgenolin at u-paris10.fr  Sat Feb  6 16:39:31 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sat, 06 Feb 2010 16:39:31 +0100
Subject: [Rd] Canberra distance
Message-ID: <4B6D8D33.2070108@u-paris10.fr>

Hi the list,

According to what I know, the Canberra distance between X et Y is : sum[ 
(|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function 
'absolute value')
In the source code of the canberra distance in the file distance.c, we 
find :

    sum = fabs(x[i1] + x[i2]);
    diff = fabs(x[i1] - x[i2]);
    dev = diff/sum;

which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
(note that this does not define a distance... This is correct when x_i 
and y_i are positive, but not when a value is negative.)

Is it on purpose or is it a bug?

Christophe


From murdoch at stats.uwo.ca  Sat Feb  6 17:10:07 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 06 Feb 2010 11:10:07 -0500
Subject: [Rd] Canberra distance
In-Reply-To: <4B6D8D33.2070108@u-paris10.fr>
References: <4B6D8D33.2070108@u-paris10.fr>
Message-ID: <4B6D945F.2030709@stats.uwo.ca>

On 06/02/2010 10:39 AM, Christophe Genolini wrote:
> Hi the list,
> 
> According to what I know, the Canberra distance between X et Y is : sum[ 
> (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function 
> 'absolute value')
> In the source code of the canberra distance in the file distance.c, we 
> find :
> 
>     sum = fabs(x[i1] + x[i2]);
>     diff = fabs(x[i1] - x[i2]);
>     dev = diff/sum;
> 
> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
> (note that this does not define a distance... This is correct when x_i 
> and y_i are positive, but not when a value is negative.)
> 
> Is it on purpose or is it a bug?

It matches the documentation in ?dist, so it's not just a coding error. 
  It will give the same value as your definition if the two items have 
the same sign (not only both positive), but different values if the 
signs differ.

The first three links I found searching Google Scholar for "Canberra 
distance" all define it only for non-negative data.  One of them gave 
exactly the R formula (even though the absolute value in the denominator 
is redundant), the others just put x_i + y_i in the denominator.

None of the 3 papers cited the origin of the definition, so I can't tell 
you who is wrong.

Duncan Murdoch


From cgenolin at u-paris10.fr  Sat Feb  6 17:31:18 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sat, 06 Feb 2010 17:31:18 +0100
Subject: [Rd] Canberra distance
In-Reply-To: <4B6D945F.2030709@stats.uwo.ca>
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
Message-ID: <4B6D9956.3030708@u-paris10.fr>

The definition I use is the on find in the book "Cluster analysis" by 
Brian Everitt, Sabine Landau and Morven Leese.
They cite, as definition paper for Canberra distance, an article of 
Lance and Williams "Computer programs for hierarchical polythetic 
classification" Computer Journal 1966.
I do not have access, but here is the link : 
http://comjnl.oxfordjournals.org/cgi/content/abstract/9/1/60
Hope this helps.

Christophe
> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>> Hi the list,
>>
>> According to what I know, the Canberra distance between X et Y is : 
>> sum[ (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function 
>> 'absolute value')
>> In the source code of the canberra distance in the file distance.c, 
>> we find :
>>
>>     sum = fabs(x[i1] + x[i2]);
>>     diff = fabs(x[i1] - x[i2]);
>>     dev = diff/sum;
>>
>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>> (note that this does not define a distance... This is correct when 
>> x_i and y_i are positive, but not when a value is negative.)
>>
>> Is it on purpose or is it a bug?
>
> It matches the documentation in ?dist, so it's not just a coding 
> error.  It will give the same value as your definition if the two 
> items have the same sign (not only both positive), but different 
> values if the signs differ.
>
> The first three links I found searching Google Scholar for "Canberra 
> distance" all define it only for non-negative data.  One of them gave 
> exactly the R formula (even though the absolute value in the 
> denominator is redundant), the others just put x_i + y_i in the 
> denominator.
>
> None of the 3 papers cited the origin of the definition, so I can't 
> tell you who is wrong.
>
> Duncan Murdoch
>
>


From cgenolin at u-paris10.fr  Sat Feb  6 17:49:14 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sat, 06 Feb 2010 17:49:14 +0100
Subject: [Rd] Canberra distance and binary distance
In-Reply-To: <4B6D9956.3030708@u-paris10.fr>
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>
Message-ID: <4B6D9D8A.5000109@u-paris10.fr>

I guess there is also a problem in the binary distance since

x <- y <- rep(0,10)
dist(rbind(x,y),method="binary")

gives 0 whereas it suppose to be undefine. (the aka asymmetric binary is 
not suppose to take in account the (off,off) couples in its calculation)

Christophe

> The definition I use is the on find in the book "Cluster analysis" by 
> Brian Everitt, Sabine Landau and Morven Leese.
> They cite, as definition paper for Canberra distance, an article of 
> Lance and Williams "Computer programs for hierarchical polythetic 
> classification" Computer Journal 1966.
> I do not have access, but here is the link : 
> http://comjnl.oxfordjournals.org/cgi/content/abstract/9/1/60
> Hope this helps.
>
> Christophe
>> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>>> Hi the list,
>>>
>>> According to what I know, the Canberra distance between X et Y is : 
>>> sum[ (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function 
>>> 'absolute value')
>>> In the source code of the canberra distance in the file distance.c, 
>>> we find :
>>>
>>>     sum = fabs(x[i1] + x[i2]);
>>>     diff = fabs(x[i1] - x[i2]);
>>>     dev = diff/sum;
>>>
>>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>>> (note that this does not define a distance... This is correct when 
>>> x_i and y_i are positive, but not when a value is negative.)
>>>
>>> Is it on purpose or is it a bug?
>>
>> It matches the documentation in ?dist, so it's not just a coding 
>> error.  It will give the same value as your definition if the two 
>> items have the same sign (not only both positive), but different 
>> values if the signs differ.
>>
>> The first three links I found searching Google Scholar for "Canberra 
>> distance" all define it only for non-negative data.  One of them gave 
>> exactly the R formula (even though the absolute value in the 
>> denominator is redundant), the others just put x_i + y_i in the 
>> denominator.
>>
>> None of the 3 papers cited the origin of the definition, so I can't 
>> tell you who is wrong.
>>
>> Duncan Murdoch
>>
>>
>
>


From murdoch at stats.uwo.ca  Sat Feb  6 18:00:24 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 06 Feb 2010 12:00:24 -0500
Subject: [Rd] Canberra distance
In-Reply-To: <4B6D9956.3030708@u-paris10.fr>
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>
Message-ID: <4B6DA028.8080902@stats.uwo.ca>

On 06/02/2010 11:31 AM, Christophe Genolini wrote:
> The definition I use is the on find in the book "Cluster analysis" by 
> Brian Everitt, Sabine Landau and Morven Leese.
> They cite, as definition paper for Canberra distance, an article of 
> Lance and Williams "Computer programs for hierarchical polythetic 
> classification" Computer Journal 1966.
> I do not have access, but here is the link : 
> http://comjnl.oxfordjournals.org/cgi/content/abstract/9/1/60
> Hope this helps.
> 

I do have access to that journal, and that paper gives the definition

sum(|x_i - y_i|) / sum(x_i + y_i)

and suggests the variation

sum( [|x_i - y_i|) / (x_i + y_i) ] )

It doesn't call either one the Canberra distance; it calls the first one 
the "non-metric coefficient" and doesn't name the second.  (I imagine 
the Canberra name came from the fact that the authors were at CSIRO in 
Canberra.)

So I'd agree your definition is better, but I don't know if it can 
really be called the "Canberra distance".

Duncan Murdoch

> Christophe
>> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>>> Hi the list,
>>>
>>> According to what I know, the Canberra distance between X et Y is : 
>>> sum[ (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function 
>>> 'absolute value')
>>> In the source code of the canberra distance in the file distance.c, 
>>> we find :
>>>
>>>     sum = fabs(x[i1] + x[i2]);
>>>     diff = fabs(x[i1] - x[i2]);
>>>     dev = diff/sum;
>>>
>>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>>> (note that this does not define a distance... This is correct when 
>>> x_i and y_i are positive, but not when a value is negative.)
>>>
>>> Is it on purpose or is it a bug?
>> It matches the documentation in ?dist, so it's not just a coding 
>> error.  It will give the same value as your definition if the two 
>> items have the same sign (not only both positive), but different 
>> values if the signs differ.
>>
>> The first three links I found searching Google Scholar for "Canberra 
>> distance" all define it only for non-negative data.  One of them gave 
>> exactly the R formula (even though the absolute value in the 
>> denominator is redundant), the others just put x_i + y_i in the 
>> denominator.
>>
>> None of the 3 papers cited the origin of the definition, so I can't 
>> tell you who is wrong.
>>
>> Duncan Murdoch
>>
>>


From ligges at statistik.tu-dortmund.de  Sat Feb  6 17:40:08 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 06 Feb 2010 17:40:08 +0100
Subject: [Rd] win-builder offline
Message-ID: <4B6D9B68.2060608@statistik.tu-dortmund.de>

Dear package developers,

the win-builder service provided at http://win-builder.r-project.org/ 
will be offline from roughly 7pm (CET) today until 5pm (CET) tomorrow.

Best wishes,
Uwe Ligges


From jari.oksanen at oulu.fi  Sat Feb  6 19:13:46 2010
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Sat, 06 Feb 2010 20:13:46 +0200
Subject: [Rd] Canberra distance
In-Reply-To: <4B6D945F.2030709@stats.uwo.ca>
Message-ID: <C7937DFA.B1DE%jari.oksanen@oulu.fi>




On 06/02/2010 18:10, "Duncan Murdoch" <murdoch at stats.uwo.ca> wrote:

> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>> Hi the list,
>> 
>> According to what I know, the Canberra distance between X et Y is : sum[
>> (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function
>> 'absolute value')
>> In the source code of the canberra distance in the file distance.c, we
>> find :
>> 
>>     sum = fabs(x[i1] + x[i2]);
>>     diff = fabs(x[i1] - x[i2]);
>>     dev = diff/sum;
>> 
>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>> (note that this does not define a distance... This is correct when x_i
>> and y_i are positive, but not when a value is negative.)
>> 
>> Is it on purpose or is it a bug?
> 
> It matches the documentation in ?dist, so it's not just a coding error.
>   It will give the same value as your definition if the two items have
> the same sign (not only both positive), but different values if the
> signs differ.
> 
> The first three links I found searching Google Scholar for "Canberra
> distance" all define it only for non-negative data.  One of them gave
> exactly the R formula (even though the absolute value in the denominator
> is redundant), the others just put x_i + y_i in the denominator.

G'day cobbers, 

Without checking the original sources (that I can't do before Monday), I'd
say that the "Canberra distance" was originally suggested only for
non-negative data (abundances of organisms which are non-negative if
observed directly). The fabs(x-y) notation was used just as a convenient
tool to get rid off the original pmin(x,y) for non-negative data -- which is
nice in R, but not so natural in C. Extension of the "Canberra distance" to
negative data probably makes a new distance perhaps deserving a new name
(Eureka distance?).

If you ever go to Canberra and drive around you'll see that it's all going
through a roundabout after a roundabout, and going straight somewhere means
goin' 'round 'n' 'round. That may make you skeptical about the "Canberra
distance". 

Cheers, Jazza Oksanen


From Bill.Venables at csiro.au  Sun Feb  7 02:03:55 2010
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Sun, 7 Feb 2010 12:03:55 +1100
Subject: [Rd] Canberra distance
In-Reply-To: <4B6DA028.8080902@stats.uwo.ca>
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>,<4B6DA028.8080902@stats.uwo.ca>
Message-ID: <1BDAE2969943D540934EE8B4EF68F95FB262394F37@EXNSW-MBX03.nexus.csiro.au>

That is interesting.  The first of these, namely

sum(|x_i - y_i|) / sum(x_i + y_i)

is now better known in ecology as the Bray-Curtis distance.  Even more interesting is the typo in Henry & Stevens "A Primer of Ecology in R" where the Bray Curtis distance formula is actually the Canberra distance  (Eq. 10.2 p. 289).  There seems to be a certain slipperiness of definition in this field.

What surprises me most is why ecologists still cling to this way of doing things,  It is one of the few places I know of where the analysis is justified purely heuristically and not from any kind of explicit model for the ecological processes under study.

Bill Venables.



________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch [murdoch at stats.uwo.ca]
Sent: 07 February 2010 03:00
To: genolini at u-paris10.fr
Cc: r-devel at r-project.org
Subject: Re: [Rd] Canberra distance

On 06/02/2010 11:31 AM, Christophe Genolini wrote:
> The definition I use is the on find in the book "Cluster analysis" by
> Brian Everitt, Sabine Landau and Morven Leese.
> They cite, as definition paper for Canberra distance, an article of
> Lance and Williams "Computer programs for hierarchical polythetic
> classification" Computer Journal 1966.
> I do not have access, but here is the link :
> http://comjnl.oxfordjournals.org/cgi/content/abstract/9/1/60
> Hope this helps.
>

I do have access to that journal, and that paper gives the definition

sum(|x_i - y_i|) / sum(x_i + y_i)

and suggests the variation

sum( [|x_i - y_i|) / (x_i + y_i) ] )

It doesn't call either one the Canberra distance; it calls the first one
the "non-metric coefficient" and doesn't name the second.  (I imagine
the Canberra name came from the fact that the authors were at CSIRO in
Canberra.)

So I'd agree your definition is better, but I don't know if it can
really be called the "Canberra distance".

Duncan Murdoch

> Christophe
>> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>>> Hi the list,
>>>
>>> According to what I know, the Canberra distance between X et Y is :
>>> sum[ (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function
>>> 'absolute value')
>>> In the source code of the canberra distance in the file distance.c,
>>> we find :
>>>
>>>     sum = fabs(x[i1] + x[i2]);
>>>     diff = fabs(x[i1] - x[i2]);
>>>     dev = diff/sum;
>>>
>>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>>> (note that this does not define a distance... This is correct when
>>> x_i and y_i are positive, but not when a value is negative.)
>>>
>>> Is it on purpose or is it a bug?
>> It matches the documentation in ?dist, so it's not just a coding
>> error.  It will give the same value as your definition if the two
>> items have the same sign (not only both positive), but different
>> values if the signs differ.
>>
>> The first three links I found searching Google Scholar for "Canberra
>> distance" all define it only for non-negative data.  One of them gave
>> exactly the R formula (even though the absolute value in the
>> denominator is redundant), the others just put x_i + y_i in the
>> denominator.
>>
>> None of the 3 papers cited the origin of the definition, so I can't
>> tell you who is wrong.
>>
>> Duncan Murdoch
>>
>>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sun Feb  7 07:52:54 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 7 Feb 2010 06:52:54 +0000 (GMT)
Subject: [Rd] Canberra distance
In-Reply-To: <1BDAE2969943D540934EE8B4EF68F95FB262394F37@EXNSW-MBX03.nexus.csiro.au>
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>, <4B6DA028.8080902@stats.uwo.ca>
	<1BDAE2969943D540934EE8B4EF68F95FB262394F37@EXNSW-MBX03.nexus.csiro.au>
Message-ID: <alpine.LFD.2.00.1002070635220.22211@gannet.stats.ox.ac.uk>

This is cetainly ancient R history.  The essence of the formula was 
last changed
-	    dist += fabs(x[i1] - x[i2])/(x[i1] + x[i2]);
+	    dist += fabs(x[i1] - x[i2])/fabs(x[i1] + x[i2]);

in October 1998.  The help page description came later.

The
            dist += fabs(x[i1] - x[i2])/(x[i1] + x[i2]);
form was there as 'canberra' in the first CVS archive in September 
1997 (as src/library/mva/src/dist.c) so it looks like one of R&R was 
the original author and this could be called pre-history.

On Sun, 7 Feb 2010, Bill.Venables at csiro.au wrote:

> That is interesting.  The first of these, namely
>
> sum(|x_i - y_i|) / sum(x_i + y_i)
>
> is now better known in ecology as the Bray-Curtis distance.  Even more interesting is the typo in Henry & Stevens "A Primer of Ecology in R" where the Bray Curtis distance formula is actually the Canberra distance  (Eq. 10.2 p. 289).  There seems to be a certain slipperiness of definition in this field.
>
> What surprises me most is why ecologists still cling to this way of doing things,  It is one of the few places I know of where the analysis is justified purely heuristically and not from any kind of explicit model for the ecological processes under study.
>
> Bill Venables.
>
>
>
> ________________________________________
> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch [murdoch at stats.uwo.ca]
> Sent: 07 February 2010 03:00
> To: genolini at u-paris10.fr
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Canberra distance
>
> On 06/02/2010 11:31 AM, Christophe Genolini wrote:
>> The definition I use is the on find in the book "Cluster analysis" by
>> Brian Everitt, Sabine Landau and Morven Leese.
>> They cite, as definition paper for Canberra distance, an article of
>> Lance and Williams "Computer programs for hierarchical polythetic
>> classification" Computer Journal 1966.
>> I do not have access, but here is the link :
>> http://comjnl.oxfordjournals.org/cgi/content/abstract/9/1/60
>> Hope this helps.
>>
>
> I do have access to that journal, and that paper gives the definition
>
> sum(|x_i - y_i|) / sum(x_i + y_i)
>
> and suggests the variation
>
> sum( [|x_i - y_i|) / (x_i + y_i) ] )
>
> It doesn't call either one the Canberra distance; it calls the first one
> the "non-metric coefficient" and doesn't name the second.  (I imagine
> the Canberra name came from the fact that the authors were at CSIRO in
> Canberra.)
>
> So I'd agree your definition is better, but I don't know if it can
> really be called the "Canberra distance".
>
> Duncan Murdoch
>
>> Christophe
>>> On 06/02/2010 10:39 AM, Christophe Genolini wrote:
>>>> Hi the list,
>>>>
>>>> According to what I know, the Canberra distance between X et Y is :
>>>> sum[ (|x_i - y_i|) / (|x_i|+|y_i|) ] (with | | denoting the function
>>>> 'absolute value')
>>>> In the source code of the canberra distance in the file distance.c,
>>>> we find :
>>>>
>>>>     sum = fabs(x[i1] + x[i2]);
>>>>     diff = fabs(x[i1] - x[i2]);
>>>>     dev = diff/sum;
>>>>
>>>> which correspond to the formula : sum[ (|x_i - y_i|) / (|x_i+y_i|) ]
>>>> (note that this does not define a distance... This is correct when
>>>> x_i and y_i are positive, but not when a value is negative.)
>>>>
>>>> Is it on purpose or is it a bug?
>>> It matches the documentation in ?dist, so it's not just a coding
>>> error.  It will give the same value as your definition if the two
>>> items have the same sign (not only both positive), but different
>>> values if the signs differ.
>>>
>>> The first three links I found searching Google Scholar for "Canberra
>>> distance" all define it only for non-negative data.  One of them gave
>>> exactly the R formula (even though the absolute value in the
>>> denominator is redundant), the others just put x_i + y_i in the
>>> denominator.
>>>
>>> None of the 3 papers cited the origin of the definition, so I can't
>>> tell you who is wrong.
>>>
>>> Duncan Murdoch
>>>
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From getoxxx at gmail.com  Sun Feb  7 15:47:18 2010
From: getoxxx at gmail.com (Renaud Gaujoux)
Date: Sun, 07 Feb 2010 16:47:18 +0200
Subject: [Rd] Estimate actual memory usage, not cumulative allocated
Message-ID: <4B6ED276.9050004@cbio.uct.ac.za>

Hi,

I'd like to know how estimate the memory actually used by some function
call.
The function essentially contains a for loop, which stops after a
variable number of iterations, depending on the input data.
I used Rprof with memory.profiling=TRUE, but the memory results seem to
increase with the number of iterations. What I understand is that the
reported memory is cumulative and based on allocation (am I  right?).
After each loop the same object is updated so the I'm not expecting
memory usage from this part.
however, the update computation itself needs to allocate memory for
temporary objects, which would be the reason why the reported memory
increases with the number of iterations.
I just want to know the minimum amount of memory I need to run the
computation, which would not be the sum of memory allocated during the
computation (as some is temporary and should be released by R if necessary)
How could I estimate this value?

#Sample code:

x <- my.object
for( i in 1:500 ){
    # compute next value
    x <- update(x)

    # stop depending on the current value
    if( stop(x) ) break;
}


Thanks,
Renaud


From getoxxx at gmail.com  Sun Feb  7 17:54:48 2010
From: getoxxx at gmail.com (Renaud Gaujoux)
Date: Sun, 07 Feb 2010 18:54:48 +0200
Subject: [Rd] Estimate actual memory usage, not cumulative allocated
In-Reply-To: <8ed68eed1002070840w78d25466o11f1c369cd91c39d@mail.gmail.com>
References: <4B6ED276.9050004@cbio.uct.ac.za>
	<8ed68eed1002070840w78d25466o11f1c369cd91c39d@mail.gmail.com>
Message-ID: <4B6EF058.40408@cbio.uct.ac.za>

Hi Sean,

I know I'll have to optimize the memory management (maybe using the
proto or R.oo packages), but for the moment I'd like to estimate the
amount of memory actually used by the call.

I got some estimate doing:

g1 <- gc(reset=TRUE)
my.function(input.data)
g2 <- gc();
sum(g1[,6] - g2[,2]);
# -> sum differences between max used memory and last current used
memory (merging Ncells and Vcells)

Does it make sense?

I was happy with it, but the thing is that it does not seem to depend on
the size of the input.data, which is a matrix that is involved
internally in matrix products. Even reducing the input.data from 5000
rows to 50 rows did not change the result: ~ 20 Mb for each.
Something to do with the garbage collector trigger I imagine?

Thanks,
Renaud

Sean O'Riordain wrote:
> Renaud,
>
> I could be wrong... but generally in R you create a new object each
> time you do an assignment which is why looping is slow; i.e. you're
> not actually updating you're creating a new version of the original.
>
> cheers,
> Sean
>
>
> On Sun, Feb 7, 2010 at 2:47 PM, Renaud Gaujoux <getoxxx at gmail.com
> <mailto:getoxxx at gmail.com>> wrote:
>
>     Hi,
>
>     I'd like to know how estimate the memory actually used by some
>     function
>     call.
>     The function essentially contains a for loop, which stops after a
>     variable number of iterations, depending on the input data.
>     I used Rprof with memory.profiling=TRUE, but the memory results
>     seem to
>     increase with the number of iterations. What I understand is that the
>     reported memory is cumulative and based on allocation (am I  right?).
>     After each loop the same object is updated so the I'm not expecting
>     memory usage from this part.
>     however, the update computation itself needs to allocate memory for
>     temporary objects, which would be the reason why the reported memory
>     increases with the number of iterations.
>     I just want to know the minimum amount of memory I need to run the
>     computation, which would not be the sum of memory allocated during the
>     computation (as some is temporary and should be released by R if
>     necessary)
>     How could I estimate this value?
>
>     #Sample code:
>
>     x <- my.object
>     for( i in 1:500 ){
>        # compute next value
>        x <- update(x)
>
>        # stop depending on the current value
>        if( stop(x) ) break;
>     }
>
>
>     Thanks,
>     Renaud
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From guillaume.yziquel at citycable.ch  Sun Feb  7 20:31:27 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sun, 07 Feb 2010 20:31:27 +0100
Subject: [Rd] Autoconf macros for R?
Message-ID: <4B6F150F.2010204@citycable.ch>

Hi.

I'm quite near a release for OCaml-R. Before that, however, I want to 
make the build system rely on autoconf / automake. So I'm asking myself 
and this mailing list whether or not there exists a set of "blessed by 
the community" autoconf macros.

For OCaml, there are these ones:

http://rwmj.wordpress.com/2009/03/31/using-autoconf-for-ocaml-projects/
http://forge.ocamlcore.org/projects/Focaml-autoconf/

Anything similar hanging out there for R?

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From tobias.verbeke at openanalytics.eu  Sun Feb  7 21:35:52 2010
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sun, 07 Feb 2010 21:35:52 +0100
Subject: [Rd] p.adjust.Rd sugggestion
Message-ID: <4B6F2428.4070904@openanalytics.eu>

L.S.

In the current version of ?p.adjust.Rd, one needs
to scroll down to the examples section to find
confirmation of one's guess that "fdr" is an
alias of "BH".

Please find a patch in attachment which mentions
this explicitly.

Best,
Tobias

-------------- next part --------------
A non-text attachment was scrubbed...
Name: p.adjust.Rd.patch
Type: text/x-patch
Size: 633 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100207/8d07bb68/attachment.bin>

From bolker at ufl.edu  Mon Feb  8 01:44:52 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 8 Feb 2010 00:44:52 +0000 (UTC)
Subject: [Rd] Canberra distance
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>, <4B6DA028.8080902@stats.uwo.ca>
	<1BDAE2969943D540934EE8B4EF68F95FB262394F37@EXNSW-MBX03.nexus.csiro.au>
Message-ID: <loom.20100208T014230-189@post.gmane.org>

 <Bill.Venables <at> csiro.au> writes:

> 
> That is interesting.  The first of these, namely
> 
> sum(|x_i - y_i|) / sum(x_i + y_i)
> 
> is now better known in ecology as the Bray-Curtis distance.  Even more
interesting is the typo in Henry &
> Stevens "A Primer of Ecology in R" where the Bray Curtis distance formula is
actually the Canberra
> distance  (Eq. 10.2 p. 289).  There seems to be a certain slipperiness of
definition in this field.

  Actually, the author is M. H. Henry (Hank) Stevens, not "Henry & Stevens" ...

  Ben Bolker


From maechler at stat.math.ethz.ch  Mon Feb  8 10:10:52 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Feb 2010 10:10:52 +0100
Subject: [Rd] p.adjust.Rd sugggestion
In-Reply-To: <4B6F2428.4070904@openanalytics.eu>
References: <4B6F2428.4070904@openanalytics.eu>
Message-ID: <19311.54556.79392.627379@lynne.math.ethz.ch>

Thank you, Tobias,

That's indeed a valuable small improvement,
now done for R-devel.

Martin

>>>>> Tobias Verbeke <tobias.verbeke at openanalytics.eu>
>>>>>     on Sun, 07 Feb 2010 21:35:52 +0100 writes:

    > L.S.
    > In the current version of ?p.adjust.Rd, one needs
    > to scroll down to the examples section to find
    > confirmation of one's guess that "fdr" is an
    > alias of "BH".

    > Please find a patch in attachment which mentions
    > this explicitly.

    > Best,
    > Tobias

    > 32c32
    > <   Hochberg (1995) (\code{"BH"}), and Benjamini & Yekutieli (2001)
    > ---
    >> Hochberg (1995) (\code{"BH"} or its alias \code{"fdr"}), and Benjamini & Yekutieli (2001)
    > 50,52c50,52
    > <   The \code{"BH"} and \code{"BY"} method of Benjamini, Hochberg, and
    > <   Yekutieli control the false discovery rate, the expected proportion of
    > <   false discoveries amongst the rejected hypotheses.  The false
    > ---
    >> The \code{"BH"} (aka \code{"fdr"}) and \code{"BY"} method of Benjamini, 
    >> Hochberg, and Yekutieli control the false discovery rate, the expected 
    >> proportion of false discoveries amongst the rejected hypotheses.  The false


From martin.becker at mx.uni-saarland.de  Mon Feb  8 11:58:24 2010
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Mon, 08 Feb 2010 11:58:24 +0100
Subject: [Rd] tiny typo in translation (src/library/tools/po/R-de.po)
Message-ID: <4B6FEE50.7070407@mx.uni-saarland.de>

Dear developers,

nearly not worth mentioning, but anyway:
there is a tiny typo in a german translation file (in 
src/library/tools/po/R-de.po: 'erzuege' instead off 'erzeuge').
The attached (if it passes the filters...) patch (for revision 51109) 
should correct this.

Thanks,
  Martin


-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 206
66123 Saarbruecken
Germany

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-de.po.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100208/8a193c07/attachment.pl>

From P.Dalgaard at biostat.ku.dk  Mon Feb  8 12:20:25 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 08 Feb 2010 12:20:25 +0100
Subject: [Rd] tiny typo in translation (src/library/tools/po/R-de.po)
In-Reply-To: <4B6FEE50.7070407@mx.uni-saarland.de>
References: <4B6FEE50.7070407@mx.uni-saarland.de>
Message-ID: <4B6FF379.7030207@biostat.ku.dk>

Martin Becker wrote:
> Dear developers,
> 
> nearly not worth mentioning, but anyway:
> there is a tiny typo in a german translation file (in
> src/library/tools/po/R-de.po: 'erzuege' instead off 'erzeuge').
> The attached (if it passes the filters...) patch (for revision 51109)
> should correct this.

Thanks. Probably best to do this via the translation team c/o Detlef
Steuer as per http://developer.r-project.org/TranslationTeams.html (Cc'ed)

-Peter D.


> 
> Thanks,
>  Martin
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Mon Feb  8 12:29:08 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 08 Feb 2010 06:29:08 -0500
Subject: [Rd] tiny typo in translation (src/library/tools/po/R-de.po)
In-Reply-To: <4B6FEE50.7070407@mx.uni-saarland.de>
References: <4B6FEE50.7070407@mx.uni-saarland.de>
Message-ID: <4B6FF584.60903@stats.uwo.ca>

Martin Becker wrote:
> Dear developers,
>
> nearly not worth mentioning, but anyway:
> there is a tiny typo in a german translation file (in 
> src/library/tools/po/R-de.po: 'erzuege' instead off 'erzeuge').
> The attached (if it passes the filters...) patch (for revision 51109) 
> should correct this.
>   

The translation sources are maintained by the translation teams, so 
corrections should go directly to them.  I've cc'd this message to 
Detlef Steuer, but for future
reference the list is on

http://developer.r-project.org/TranslationTeams.html

Thanks!

Duncan Murdoch


From msa at biostat.mgh.harvard.edu  Mon Feb  8 05:45:08 2010
From: msa at biostat.mgh.harvard.edu (msa at biostat.mgh.harvard.edu)
Date: Mon,  8 Feb 2010 05:45:08 +0100 (CET)
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
Message-ID: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>

Full_Name: Marek Ancukiewicz
Version: 2.10.1
OS: Linux
Submission from: (NULL) (74.0.49.2)


Both cor() and cor.test() incorrectly handle ordered variables with 
method="kendall", cor() incorrectly handles ordered variables for 
method="spearman" (method="person" always works correctly, while 
method="spearman" works for cor.test, but not for cor()).

In erroneous calculations these functions ignore the inherent ordering
of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume 
an alphabetic ordering ('10'<'11'<'9'). 

> cor(9:11,1:3,method="k")
[1] 1
> cor(as.ordered(9:11),1:3,method="k")
[1] -0.3333333
> cor.test(as.ordered(9:11),1:3,method="k")

	Kendall's rank correlation tau

data:  as.ordered(9:11) and 1:3 
T = 1, p-value = 1
alternative hypothesis: true tau is not equal to 0 
sample estimates:
       tau 
-0.3333333 

> cor(9:11,1:3,method="s")
[1] 1
> cor(as.ordered(9:11),1:3,method="s")
[1] -0.5
> cor.test(as.ordered(9:11),1:3,method="s")

	Spearman's rank correlation rho

data:  as.ordered(9:11) and 1:3 
S = 0, p-value = 0.3333
alternative hypothesis: true rho is not equal to 0 
sample estimates:
rho 
  1


From P.Dalgaard at biostat.ku.dk  Mon Feb  8 14:23:08 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 08 Feb 2010 14:23:08 +0100
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
In-Reply-To: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>
References: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>
Message-ID: <4B70103C.7030504@biostat.ku.dk>

msa at biostat.mgh.harvard.edu wrote:
> Full_Name: Marek Ancukiewicz
> Version: 2.10.1
> OS: Linux
> Submission from: (NULL) (74.0.49.2)
> 
> 
> Both cor() and cor.test() incorrectly handle ordered variables with 
> method="kendall", cor() incorrectly handles ordered variables for 
> method="spearman" (method="person" always works correctly, while 
> method="spearman" works for cor.test, but not for cor()).
> 
> In erroneous calculations these functions ignore the inherent ordering
> of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume 
> an alphabetic ordering ('10'<'11'<'9'). 

Strictly speaking, not a bug, since the documentation has

       x: a numeric vector, matrix or data frame.

respectively

    x, y: numeric vectors of data values.  ?x? and ?y? must have the
          same length.

so noone ever claimed that class "ordered" variables should work.

However, the root cause is that as.vector on a factor variable (ordered
or not) converts it to a character vector, hence

> rank(as.vector(as.ordered(9:11)))
[1] 3 1 2

Looks like a simple fix would be to use as.vector(x, "numeric") inside
the definition of cor().


>> cor(9:11,1:3,method="k")
> [1] 1
>> cor(as.ordered(9:11),1:3,method="k")
> [1] -0.3333333
>> cor.test(as.ordered(9:11),1:3,method="k")
> 
> 	Kendall's rank correlation tau
> 
> data:  as.ordered(9:11) and 1:3 
> T = 1, p-value = 1
> alternative hypothesis: true tau is not equal to 0 
> sample estimates:
>        tau 
> -0.3333333 
> 
>> cor(9:11,1:3,method="s")
> [1] 1
>> cor(as.ordered(9:11),1:3,method="s")
> [1] -0.5
>> cor.test(as.ordered(9:11),1:3,method="s")
> 
> 	Spearman's rank correlation rho
> 
> data:  as.ordered(9:11) and 1:3 
> S = 0, p-value = 0.3333
> alternative hypothesis: true rho is not equal to 0 
> sample estimates:
> rho 
>   1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Mon Feb  8 18:09:10 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 8 Feb 2010 17:09:10 +0000 (GMT)
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
In-Reply-To: <4B70103C.7030504@biostat.ku.dk>
References: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>
	<4B70103C.7030504@biostat.ku.dk>
Message-ID: <alpine.LFD.2.00.1002081659410.12668@gannet.stats.ox.ac.uk>

On Mon, 8 Feb 2010, Peter Dalgaard wrote:

> msa at biostat.mgh.harvard.edu wrote:
>> Full_Name: Marek Ancukiewicz
>> Version: 2.10.1
>> OS: Linux
>> Submission from: (NULL) (74.0.49.2)
>>
>>
>> Both cor() and cor.test() incorrectly handle ordered variables with
>> method="kendall", cor() incorrectly handles ordered variables for
>> method="spearman" (method="person" always works correctly, while
>> method="spearman" works for cor.test, but not for cor()).
>>
>> In erroneous calculations these functions ignore the inherent ordering
>> of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume
>> an alphabetic ordering ('10'<'11'<'9').
>
> Strictly speaking, not a bug, since the documentation has
>
>       x: a numeric vector, matrix or data frame.
>
> respectively
>
>    x, y: numeric vectors of data values.  ?x? and ?y? must have the
>          same length.
>
> so noone ever claimed that class "ordered" variables should work.
>
> However, the root cause is that as.vector on a factor variable (ordered
> or not) converts it to a character vector, hence
>
>> rank(as.vector(as.ordered(9:11)))
> [1] 3 1 2
>
> Looks like a simple fix would be to use as.vector(x, "numeric") inside
> the definition of cor().

A fix for that particular case: the problem is that relies on the 
underlying representation.  I think a better fix would be to do either 
of

- test for numeric and throw an error otherwise, or
- use xtfrm, which has the advantage of being more general and
   allowing methods to be written (S3 or S4 methods in R-devel).

>
>
>>> cor(9:11,1:3,method="k")
>> [1] 1
>>> cor(as.ordered(9:11),1:3,method="k")
>> [1] -0.3333333
>>> cor.test(as.ordered(9:11),1:3,method="k")
>>
>> 	Kendall's rank correlation tau
>>
>> data:  as.ordered(9:11) and 1:3
>> T = 1, p-value = 1
>> alternative hypothesis: true tau is not equal to 0
>> sample estimates:
>>        tau
>> -0.3333333
>>
>>> cor(9:11,1:3,method="s")
>> [1] 1
>>> cor(as.ordered(9:11),1:3,method="s")
>> [1] -0.5
>>> cor.test(as.ordered(9:11),1:3,method="s")
>>
>> 	Spearman's rank correlation rho
>>
>> data:  as.ordered(9:11) and 1:3
>> S = 0, p-value = 0.3333
>> alternative hypothesis: true rho is not equal to 0
>> sample estimates:
>> rho
>>   1
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Mon Feb  8 18:11:30 2010
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon,  8 Feb 2010 18:11:30 +0100 (CET)
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
Message-ID: <20100208171130.ADC35282EF51@mail.pubhealth.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-2083486994-1265648951=:12668
Content-Type: TEXT/PLAIN; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8BIT

On Mon, 8 Feb 2010, Peter Dalgaard wrote:

> msa at biostat.mgh.harvard.edu wrote:
>> Full_Name: Marek Ancukiewicz
>> Version: 2.10.1
>> OS: Linux
>> Submission from: (NULL) (74.0.49.2)
>>
>>
>> Both cor() and cor.test() incorrectly handle ordered variables with
>> method="kendall", cor() incorrectly handles ordered variables for
>> method="spearman" (method="person" always works correctly, while
>> method="spearman" works for cor.test, but not for cor()).
>>
>> In erroneous calculations these functions ignore the inherent ordering
>> of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume
>> an alphabetic ordering ('10'<'11'<'9').
>
> Strictly speaking, not a bug, since the documentation has
>
>       x: a numeric vector, matrix or data frame.
>
> respectively
>
>    x, y: numeric vectors of data values.  ???x??? and ???y??? must have the
>          same length.
>
> so noone ever claimed that class "ordered" variables should work.
>
> However, the root cause is that as.vector on a factor variable (ordered
> or not) converts it to a character vector, hence
>
>> rank(as.vector(as.ordered(9:11)))
> [1] 3 1 2
>
> Looks like a simple fix would be to use as.vector(x, "numeric") inside
> the definition of cor().

A fix for that particular case: the problem is that relies on the 
underlying representation.  I think a better fix would be to do either 
of

- test for numeric and throw an error otherwise, or
- use xtfrm, which has the advantage of being more general and
   allowing methods to be written (S3 or S4 methods in R-devel).

>
>
>>> cor(9:11,1:3,method="k")
>> [1] 1
>>> cor(as.ordered(9:11),1:3,method="k")
>> [1] -0.3333333
>>> cor.test(as.ordered(9:11),1:3,method="k")
>>
>> 	Kendall's rank correlation tau
>>
>> data:  as.ordered(9:11) and 1:3
>> T = 1, p-value = 1
>> alternative hypothesis: true tau is not equal to 0
>> sample estimates:
>>        tau
>> -0.3333333
>>
>>> cor(9:11,1:3,method="s")
>> [1] 1
>>> cor(as.ordered(9:11),1:3,method="s")
>> [1] -0.5
>>> cor.test(as.ordered(9:11),1:3,method="s")
>>
>> 	Spearman's rank correlation rho
>>
>> data:  as.ordered(9:11) and 1:3
>> S = 0, p-value = 0.3333
>> alternative hypothesis: true rho is not equal to 0
>> sample estimates:
>> rho
>>   1
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
>   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-2083486994-1265648951=:12668--


From diggsb at ohsu.edu  Mon Feb  8 20:30:16 2010
From: diggsb at ohsu.edu (diggsb at ohsu.edu)
Date: Mon,  8 Feb 2010 20:30:16 +0100 (CET)
Subject: [Rd] bug in cut.POSIXt (with patch) (PR#14208)
Message-ID: <20100208193016.B94F0282EF3D@mail.pubhealth.ku.dk>
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From diggsb at ohsu.edu  Mon Feb  8 21:45:24 2010
From: diggsb at ohsu.edu (diggsb at ohsu.edu)
Date: Mon,  8 Feb 2010 21:45:24 +0100 (CET)
Subject: [Rd] bug in cut.POSIXt (with patch) (PR#14208)
Message-ID: <20100208204524.66F90282EF3D@mail.pubhealth.ku.dk>
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From p.dalgaard at biostat.ku.dk  Mon Feb  8 22:20:33 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 08 Feb 2010 22:20:33 +0100
Subject: [Rd] bug in cut.POSIXt (with patch) (PR#14208)
In-Reply-To: <20100208204524.66F90282EF3D@mail.pubhealth.ku.dk>
References: <20100208204524.66F90282EF3D@mail.pubhealth.ku.dk>
Message-ID: <4B708021.6020706@biostat.ku.dk>



> I do not know why my bug report got so oddly encoded, I've reproduced
> it; hopefully it won't get mangled again.

It did, unfortunately. Not your fault, it's just that Jitterbug is 
incapable of undoing Content-Transfer-Encoding on incoming mail, so if 
your mail transfer agent sends in base64, it goes straight through to 
R-devel.

Never mind, the old bug repository will have to die rather soon now, 
hopefully to be replaced by something much better.

Un-base64'ed version follows below, possibly modulo linebreaks.

- Peter D.

------
Summary:

For certain well formed inputs, cut.POSIXt will give an error.

Example:

cut(as.POSIXct("2009-11-01 04:00:00", tz="America/Los_Angeles"), "1 day")

Example output:

Error in seq.int(0, to - from, by) : 'to' must be finite

Patch to fix error:

This patch is for src/library/base/R/datetime.R

Index: datetime.R
===================================================================
--- datetime.R	(revision 51110)
+++ datetime.R	(working copy)
@@ -729,7 +729,7 @@
  	incr <- 1
  	if(valid > 1L) { start$sec <- 0L; incr <- 59.99 }
  	if(valid > 2L) { start$min <- 0L; incr <- 3600 - 1 }
-	if(valid > 3L) { start$hour <- 0L; incr <- 86400 - 1 }
+	if(valid > 3L) { start$hour <- 0L; start$isdst <- -1L; incr <- 86400 - 1 }
  	if(valid == 5L) { # weeks
  	    start$mday <- start$mday - start$wday
  	    if(start.on.monday)

Discussion:

The bug is triggered when the (earliest) date/time given to cut.POSIXt
falls on the day transitioning from daylight savings time to standard
time, but at a time after the switchover.  In the US, November 1, 2009 was
such a day.

In cut.POSIXt(), the elements of a POSIXlt representation of the date/time
are directly manipulated to set it to the start of the day (since a day
sized spacing was requested).  This puts it before the daylight savings
time to standard time switchover.  When as.POSIXct is later called on this
object, it returns NA which causes the returned error when the NA is passed
as an argument to seq.int().

The motivation for the patch is the trunc.POSIXt function in the same
file.  It correctly handles this case:

trunc(as.POSIXct("2009-11-01 04:00:00", tz="America/Los_Angeles"), "day")
# [1] "2009-11-01 America/Los_Angeles"
as.POSIXct(trunc(as.POSIXct("2009-11-01 04:00:00", 
tz="America/Los_Angeles"), "day"))
# [1] "2009-11-01 PDT"

In that function, when truncating to days, the isdst element of the POSIXlt
is set to -1L.  That is the modification to cut.POSIXt() that I made.

--please do not edit the information below--

Version:
  platform = i386-pc-mingw32
  arch = i386
  os = mingw32
  system = i386, mingw32
  status =
  major = 2
  minor = 10.1
  year = 2009
  month = 12
  day = 14
  svn rev = 50720
  language = R
  version.string = R version 2.10.1 (2009-12-14)

Windows XP (build 2600) Service Pack 3

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
  .GlobalEnv, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:methods, Autoloads, package:base

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From msa at biostat.mgh.harvard.edu  Mon Feb  8 15:07:01 2010
From: msa at biostat.mgh.harvard.edu (Marek Ancukiewicz)
Date: Mon,  8 Feb 2010 09:07:01 -0500 (EST)
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
In-Reply-To: <4B70103C.7030504@biostat.ku.dk> (message from Peter Dalgaard on
	Mon, 08 Feb 2010 14:23:08 +0100)
References: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>
	<4B70103C.7030504@biostat.ku.dk>
Message-ID: <20100208140701.0B5EE5E1B0@biostat.mgh.harvard.edu>


Dear Peter,

Thank you. Although the documentation does mention numeric variables,
one would intuitively expect cor() and cor.test() to work for ordered
factors with methods "kendall" and "spearman". After all, these are
nonparametric procedures, defined for ordinal scales, and the only
information they need are ranks (the same should be true for
wilcox.test()).

So even if this is, strictly speaking, not a bug I would strongly
suggest extending cor() and cor.test() to work with ordered factors for
Kendall's and Spearman's correlations (although this would not make much
sense for Pearson's correlation). It looks like the change should be
very easy.

Marek Ancukiewicz

> Date: Mon, 08 Feb 2010 14:23:08 +0100
> From: Peter Dalgaard <P.Dalgaard at biostat.ku.dk>
> Cc: r-devel at stat.math.ethz.ch, R-bugs at r-project.org
> 
> msa at biostat.mgh.harvard.edu wrote:
> > Full_Name: Marek Ancukiewicz
> > Version: 2.10.1
> > OS: Linux
> > Submission from: (NULL) (74.0.49.2)
> > 
> > 
> > Both cor() and cor.test() incorrectly handle ordered variables with 
> > method="kendall", cor() incorrectly handles ordered variables for 
> > method="spearman" (method="person" always works correctly, while 
> > method="spearman" works for cor.test, but not for cor()).
> > 
> > In erroneous calculations these functions ignore the inherent ordering
> > of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume 
> > an alphabetic ordering ('10'<'11'<'9'). 
> 
> Strictly speaking, not a bug, since the documentation has
> 
>        x: a numeric vector, matrix or data frame.
> 
> respectively
> 
>     x, y: numeric vectors of data values.  ???x??? and ???y??? must have the
>           same length.
> 
> so noone ever claimed that class "ordered" variables should work.
> 
> However, the root cause is that as.vector on a factor variable (ordered
> or not) converts it to a character vector, hence
> 
> > rank(as.vector(as.ordered(9:11)))
> [1] 3 1 2
> 
> Looks like a simple fix would be to use as.vector(x, "numeric") inside
> the definition of cor().
> 
> 
> >> cor(9:11,1:3,method="k")
> > [1] 1
> >> cor(as.ordered(9:11),1:3,method="k")
> > [1] -0.3333333
> >> cor.test(as.ordered(9:11),1:3,method="k")
> > 
> > 	Kendall's rank correlation tau
> > 
> > data:  as.ordered(9:11) and 1:3 
> > T = 1, p-value = 1
> > alternative hypothesis: true tau is not equal to 0 
> > sample estimates:
> >        tau 
> > -0.3333333 
> > 
> >> cor(9:11,1:3,method="s")
> > [1] 1
> >> cor(as.ordered(9:11),1:3,method="s")
> > [1] -0.5
> >> cor.test(as.ordered(9:11),1:3,method="s")
> > 
> > 	Spearman's rank correlation rho
> > 
> > data:  as.ordered(9:11) and 1:3 
> > S = 0, p-value = 0.3333
> > alternative hypothesis: true rho is not equal to 0 
> > sample estimates:
> > rho 
> >   1
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
> 
-------------- next part --------------


The information in this e-mail is intended only for the ...{{dropped:13}}

From hstevens at muohio.edu  Mon Feb  8 19:30:05 2010
From: hstevens at muohio.edu (Hank Stevens)
Date: Mon, 8 Feb 2010 18:30:05 +0000 (UTC)
Subject: [Rd] Canberra distance
References: <4B6D8D33.2070108@u-paris10.fr> <4B6D945F.2030709@stats.uwo.ca>
	<4B6D9956.3030708@u-paris10.fr>, <4B6DA028.8080902@stats.uwo.ca>
	<1BDAE2969943D540934EE8B4EF68F95FB262394F37@EXNSW-MBX03.nexus.csiro.au>
Message-ID: <loom.20100208T192330-917@post.gmane.org>

 <Bill.Venables <at> csiro.au> writes:

> 
> That is interesting.  The first of these, namely
> 
> sum(|x_i - y_i|) / sum(x_i + y_i)
> 
> is now better known in ecology as the Bray-Curtis distance.  Even more
interesting is the typo in Henry &
> Stevens "A Primer of Ecology in R" where the Bray Curtis distance formula is
actually the Canberra
> distance  (Eq. 10.2 p. 289).  There seems to be a certain slipperiness of
definition in this field.

Thank you for bringing to my attention the similarity of the Canberra and
Bray-Curtis quantitative indices. Bray-Curtis dissimilarity can also, of course,
be defined as 

1 - 2w/(a+b) 

where w is sum of the minimum of each relevant pair of values, and a and b are
the totals for sites a and b, respectively. These definitions appear to yield
similar results, and to better reflect the original work by Bray and Curtis, I
should probably define their distance as they did!

Cheers,

Martin Henry Hoffman Stevens (a.k.a. Hank)

> 
> What surprises me most is why ecologists still cling to this way of doing
things,  It is one of the few places I
> know of where the analysis is justified purely heuristically and not from any
kind of explicit model for
> the ecological processes under study.
> 
> Bill Venables.
> 
> 
> ______________________________________________
> R-devel <at> r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From Alex.Randriamiharisoa at chuv.ch  Tue Feb  9 09:56:18 2010
From: Alex.Randriamiharisoa at chuv.ch (Randriamiharisoa Alex)
Date: Tue, 9 Feb 2010 09:56:18 +0100
Subject: [Rd] lm combined with splines
Message-ID: <4A1BF5B503CF294C88F65AE7ECF5754621F3367F07@exmbx02.intranet.chuv>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100209/35442ddf/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Feb  9 11:05:34 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Feb 2010 10:05:34 +0000 (GMT)
Subject: [Rd] lm combined with splines
In-Reply-To: <4A1BF5B503CF294C88F65AE7ECF5754621F3367F07@exmbx02.intranet.chuv>
References: <4A1BF5B503CF294C88F65AE7ECF5754621F3367F07@exmbx02.intranet.chuv>
Message-ID: <alpine.LFD.2.00.1002090951350.7535@localhost>

This is really a question for R-help: it is not about R development 
nor software development in R.

The answer to the only question I see is simple: your model depends on 
'fb3' and you supplied 'height'.

On Tue, 9 Feb 2010, Randriamiharisoa Alex wrote:

> Hello,

> In the following I tried 3 versions of an example in R help. Only 
> the two first predict command work.

Which 'example in R help'?  If you mean that from ?bs, then the 
comment about 'safe prediction' is why your third approach (even if 
done something like

ph3 <- predict(fm3, data.frame(fb3 = I(bs(ht3, df = 5))))

) would not be correct.  You need to predict using the spline with the 
knots computed by the original set of data, and predict() is smart 
enough to figure that out when it sees a formula involving bs() (look 
at str(fm1) to see where the information is stored, and hence how you 
could mimic this).


> After :
>
> library(splines)
> require(stats)
>
> 1)
> fm1 <- lm(weight ~ bs(height, df = 5), data = women)
> ht1  <- seq(57, 73, len = 200)
> ph1  <- predict(fm1, data.frame(height=ht1))  # OK
> plot(women, xlab = "Height (in)", ylab = "Weight (lb)")
> lines(ht1, ph1)
>
> 2)
> height <- women$height        # 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
> weight <- women$weight        # 115 117 120 123 126 129 132 135 139 142 146 150 154 159 164
>
> fm2 <- lm(weight ~ bs(height, df = 5))
> ht2 <- seq(57, 73, len = 200)
> ph2 <- predict(fm2, data.frame(height=ht2)) # OK
> plot(women, xlab = "Height (in)", ylab = "Weight (lb)")
> lines(ht2,ph2)
>
> 3)
> height <- women$height        # 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
> weight <- women$weight        # 115 117 120 123 126 129 132 135 139 142 146 150 154 159 164
>
> fb3 <- bs(height, df = 5)
> fm3 <- lm(weight ~ fb3)
> ht3 <- seq(57, 73, len = 200)
> ph3 <- predict(fm3, data.frame(height=ht3))  # Error message about newdata. Why ?
> plot(women, xlab = "Height (in)", ylab = "Weight (lb)")
> lines(ht3,ph3) # no line
>
> Thanks for the reason of this message.
> Alex Randria
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From g.russell at eos-solutions.com  Tue Feb  9 10:50:09 2010
From: g.russell at eos-solutions.com (g.russell at eos-solutions.com)
Date: Tue,  9 Feb 2010 10:50:09 +0100 (CET)
Subject: [Rd] Confusing error message for [[.factor (PR#14209)
Message-ID: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>

Full_Name: George Russell
Version: 2.10.0 and 2.11.0 Under development (unstable) (2010-02-08 r51108)
OS: Windows
Submission from: (NULL) (217.111.3.131)


> c("a","b")[[c(TRUE,FALSE)]]
Error in `[[.default`(factor(c("a", "b")), c(TRUE, FALSE)) : 
  recursive indexing failed at level 1

I find this error message confusing, though after reading the HELP carefully I
think I know what is going on. Would not something like "[[ does not work with
logical index vectors" be more appropriate?

sessionInfo is (for 2.11) :
R version 2.11.0 Under development (unstable) (2010-02-08 r51108) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base


From ehlers at ucalgary.ca  Tue Feb  9 18:17:45 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Tue, 09 Feb 2010 10:17:45 -0700
Subject: [Rd] Confusing error message for [[.factor (PR#14209)
In-Reply-To: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
References: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
Message-ID: <4B7198B9.5080209@ucalgary.ca>

g.russell at eos-solutions.com wrote:
> Full_Name: George Russell
> Version: 2.10.0 and 2.11.0 Under development (unstable) (2010-02-08 r51108)
> OS: Windows
> Submission from: (NULL) (217.111.3.131)
> 
> 
>> c("a","b")[[c(TRUE,FALSE)]]
> Error in `[[.default`(factor(c("a", "b")), c(TRUE, FALSE)) : 
>   recursive indexing failed at level 1
> 
> I find this error message confusing, though after reading the HELP carefully I
> think I know what is going on. Would not something like "[[ does not work with
> logical index vectors" be more appropriate?

It didn't take particularly careful reading to find this:

  "The most important distinction between [, [[ and $ is that
   the [ can select more than one element whereas the other two
   select a single element."

Try this:

  c("a","b")[[c(1,2)]]
  c("a","b")[[TRUE]]

  -Peter Ehlers

> 
> sessionInfo is (for 2.11) :
> R version 2.11.0 Under development (unstable) (2010-02-08 r51108) 
> i386-pc-mingw32 
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Peter Ehlers
University of Calgary


From murdoch at stats.uwo.ca  Tue Feb  9 18:19:22 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 09 Feb 2010 12:19:22 -0500
Subject: [Rd] Confusing error message for [[.factor (PR#14209)
In-Reply-To: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
References: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
Message-ID: <4B71991A.7030104@stats.uwo.ca>

On 09/02/2010 4:50 AM, g.russell at eos-solutions.com wrote:
> Full_Name: George Russell
> Version: 2.10.0 and 2.11.0 Under development (unstable) (2010-02-08 r51108)
> OS: Windows
> Submission from: (NULL) (217.111.3.131)
>
>
> > c("a","b")[[c(TRUE,FALSE)]]
> Error in `[[.default`(factor(c("a", "b")), c(TRUE, FALSE)) : 
>   recursive indexing failed at level 1
>   

I don't see that.  I get this:

 >  c("a","b")[[c(TRUE,FALSE)]]
Error in c("a", "b")[[c(TRUE, FALSE)]] :
  recursive indexing failed at level 1

which differs because c("a", "b") is not a factor.

> I find this error message confusing, though after reading the HELP carefully I
> think I know what is going on. Would not something like "[[ does not work with
> logical index vectors" be more appropriate?
>   

No, because it sometimes does work with logical index vectors:

 > x <- 1:2
 > x[[TRUE]]
[1] 1

(Here the TRUE is treated as 1.  I think it only works when the logical 
vector contains TRUE values, FALSE will fail, just as x[[0]] fails.)

The problem is that you were asking for the FALSE entry of the TRUE 
entry of the object, and since you had a simple vector, recursive 
indexing fails, and that's what the message says.  I imagine you had 
meant to type c("a", "b")[c(TRUE, FALSE)], but how can R know you meant 
that?

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Tue Feb  9 18:00:31 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 09 Feb 2010 18:00:31 +0100
Subject: [Rd] Confusing error message for [[.factor (PR#14209)
In-Reply-To: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
References: <20100209095009.A817C282EFC8@mail.pubhealth.ku.dk>
Message-ID: <4B7194AF.1030801@statistik.tu-dortmund.de>



On 09.02.2010 10:50, g.russell at eos-solutions.com wrote:
> Full_Name: George Russell
> Version: 2.10.0 and 2.11.0 Under development (unstable) (2010-02-08 r51108)
> OS: Windows
> Submission from: (NULL) (217.111.3.131)
>
>
>> c("a","b")[[c(TRUE,FALSE)]]
> Error in `[[.default`(factor(c("a", "b")), c(TRUE, FALSE)) :
>    recursive indexing failed at level 1
>
> I find this error message confusing, though after reading the HELP carefully I
> think I know what is going on. Would not something like "[[ does not work with
> logical index vectors" be more appropriate?


Well, it is nonsense to use it, but works since TRUE is coerced to 1 as in:

list(list(11, 12), 13)[[c(TRUE, TRUE)]]


In your example will also fail with integers without a chance to do the 
recursion.

Uwe Ligges




> sessionInfo is (for 2.11) :
> R version 2.11.0 Under development (unstable) (2010-02-08 r51108)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Tue Feb  9 18:56:03 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 9 Feb 2010 09:56:03 -0800
Subject: [Rd] cbind(deparse.level=2,...) problems
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275BADD@NA-PA-VBE03.na.tibco.com>

Should the deparse.level=2 argument to cbind
and rbind be abandoned?  It is minimally documented,
not used in any CRAN package, and causes some problems.
E.g.,

(a) If a matrix input has row names but not column names
    cbind(deparse.level=2,...) stops.
>
m<-matrix(11:14,nrow=2,ncol=2,dimnames=list(Row=c("R1","R2"),Col=charact
er()))
> cbind(m, 101:102, deparse.level=2)
Error in cbind(m, 101:102, deparse.level = 2) :
  SET_STRING_ELT() can only be applied to a 'character vector', not a
'NULL'

(b) If no argument is tagged then deparse.level=2
    makes no column names, while deparse.level=1 makes
    names for for the simple cases (where the argument
    is a name):
> x<-1:3
> cbind(x, 11:13, deparse.level=1)
     x
[1,] 1 11
[2,] 2 12
[3,] 3 13
> cbind(x, 11:13, deparse.level=2)
     [,1] [,2]
[1,]    1   11
[2,]    2   12
[3,]    3   13

     (If one argument is tagged, teens=11:13, then
     deparse.level=2 will name columns that
     deparse.level=1 will not, like x+1, which I
     think is the intended behavior.)


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From p.dalgaard at biostat.ku.dk  Tue Feb  9 19:55:49 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 09 Feb 2010 19:55:49 +0100
Subject: [Rd] cbind(deparse.level=2,...) problems
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000275BADD@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D7000275BADD@NA-PA-VBE03.na.tibco.com>
Message-ID: <4B71AFB5.2060500@biostat.ku.dk>

William Dunlap wrote:
> Should the deparse.level=2 argument to cbind
> and rbind be abandoned?  It is minimally documented,
> not used in any CRAN package, and causes some problems.

Bill,

This code has been touched by Brian quite recently. Try again with a 
current r-devel checkout. (Specifically, later than r51007).

-p

> E.g.,
> 
> (a) If a matrix input has row names but not column names
>     cbind(deparse.level=2,...) stops.
> m<-matrix(11:14,nrow=2,ncol=2,dimnames=list(Row=c("R1","R2"),Col=charact
> er()))
>> cbind(m, 101:102, deparse.level=2)
> Error in cbind(m, 101:102, deparse.level = 2) :
>   SET_STRING_ELT() can only be applied to a 'character vector', not a
> 'NULL'
> 
> (b) If no argument is tagged then deparse.level=2
>     makes no column names, while deparse.level=1 makes
>     names for for the simple cases (where the argument
>     is a name):
>> x<-1:3
>> cbind(x, 11:13, deparse.level=1)
>      x
> [1,] 1 11
> [2,] 2 12
> [3,] 3 13
>> cbind(x, 11:13, deparse.level=2)
>      [,1] [,2]
> [1,]    1   11
> [2,]    2   12
> [3,]    3   13
> 
>      (If one argument is tagged, teens=11:13, then
>      deparse.level=2 will name columns that
>      deparse.level=1 will not, like x+1, which I
>      think is the intended behavior.)

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From wdunlap at tibco.com  Tue Feb  9 22:04:12 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 9 Feb 2010 13:04:12 -0800
Subject: [Rd] cbind(deparse.level=2,...) problems
In-Reply-To: <4B71AFB5.2060500@biostat.ku.dk>
References: <77EB52C6DD32BA4D87471DCD70C8D7000275BADD@NA-PA-VBE03.na.tibco.com>
	<4B71AFB5.2060500@biostat.ku.dk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000275BBC6@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> Sent: Tuesday, February 09, 2010 10:56 AM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] cbind(deparse.level=2,...) problems
> 
> William Dunlap wrote:
> > Should the deparse.level=2 argument to cbind
> > and rbind be abandoned?  It is minimally documented,
> > not used in any CRAN package, and causes some problems.
> 
> Bill,
> 
> This code has been touched by Brian quite recently. Try again with a 
> current r-devel checkout. (Specifically, later than r51007).
> 
> -p

Yes, those problems have been fixed in the most
recent r-devel.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> 
> > E.g.,
> > 
> > (a) If a matrix input has row names but not column names
> >     cbind(deparse.level=2,...) stops.
> > 
> m<-matrix(11:14,nrow=2,ncol=2,dimnames=list(Row=c("R1","R2"),C
ol=charact
> > er()))
> >> cbind(m, 101:102, deparse.level=2)
> > Error in cbind(m, 101:102, deparse.level = 2) :
> >   SET_STRING_ELT() can only be applied to a 'character 
> vector', not a
> > 'NULL'
> > 
> > (b) If no argument is tagged then deparse.level=2
> >     makes no column names, while deparse.level=1 makes
> >     names for for the simple cases (where the argument
> >     is a name):
> >> x<-1:3
> >> cbind(x, 11:13, deparse.level=1)
> >      x
> > [1,] 1 11
> > [2,] 2 12
> > [3,] 3 13
> >> cbind(x, 11:13, deparse.level=2)
> >      [,1] [,2]
> > [1,]    1   11
> > [2,]    2   12
> > [3,]    3   13
> > 
> >      (If one argument is tagged, teens=11:13, then
> >      deparse.level=2 will name columns that
> >      deparse.level=1 will not, like x+1, which I
> >      think is the intended behavior.)
> 
> -- 
>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
> (+45) 35327907
> 


From violetlock at gmail.com  Tue Feb  9 23:00:48 2010
From: violetlock at gmail.com (violet lock)
Date: Tue, 9 Feb 2010 17:00:48 -0500
Subject: [Rd] Aggregate dataframe variables, return more than 2 vars
Message-ID: <bb3f839b1002091400i11f85210nb93fefe01e71842c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100209/a0cbe438/attachment.pl>

From maechler at stat.math.ethz.ch  Wed Feb 10 08:59:26 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Feb 2010 08:59:26 +0100
Subject: [Rd] Aggregate dataframe .. *inappropriate* for R-devel
In-Reply-To: <bb3f839b1002091400i11f85210nb93fefe01e71842c@mail.gmail.com>
References: <bb3f839b1002091400i11f85210nb93fefe01e71842c@mail.gmail.com>
Message-ID: <19314.26462.636614.717972@lynne.math.ethz.ch>

Not at all appropriate to be posted to R-devel :

>>>>> "vl" == violet lock <violetlock at gmail.com>
>>>>>     on Tue, 9 Feb 2010 17:00:48 -0500 writes:

    > Hello r-devel,
    > I have data.frame with 3 columns and I would like to group by 1 column(id),
    > find the max of the third column (date) and return the data for that max
    > date value along with the id and the value in the second column.

    > Example:
    >> dat <- data.frame(id = rep(1:3, 3), date = as.Date(rep(c("2005-08-25",
    > "2005-08-26", "2005-08-29"), each = 3)), decod = c("SCREEN", "SCREEN",
    > "SCREEN", "RAND", "RAND", "RAND", "COMPLETE", "COMPLETE", "WITHDRAWAL")  )


    > What I need is it to return is:


[...............]
[...............]


    > Any ideas would be appreciated,

E-mails that look like the above *CLEARLY* belong to  R-help
and *NEVER* to  R-devel.

Please read the posting guide
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

and *then* repost to R-help!

Martin Maechler, ETH Zurich


From b.rowlingson at lancaster.ac.uk  Wed Feb 10 10:23:33 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 10 Feb 2010 09:23:33 +0000
Subject: [Rd] R Startup configuration file
Message-ID: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>

Currently when R starts up it can be configured by a file of
environment variable specifications and a file of R code. This makes
programmatic modification of startup configuration tricky.

Case in point: I start R, do install.packages("foo"), and up pops the
'choose a CRAN mirror' dialog. I'd like to put a 'Save my choice'
button on that dialog. Currently it would have to put
'options(repos="http://example.com/cran")' into my .Rprofile file. Of
course my .Rprofile file could be full of all sorts of other code, so
there's no easy way to do this and guarantee it will work.

Could we have a ".Rconfig" file, consisting of key-value pairs in a
standard config file form (or XML?), that is read at startup and
applies the key-value pairs to options(key=value)? Obviously more
detail is needed, such as whether to just have one .Rconfig file in
the users' $HOME or in individual folders, where to put a system
Rconfig file, whether it is applied before or after .Rprofile etc.

Or is it a dumb idea? I can see other ways of doing this, such as
saving the options() as an object and re-loading it at startup, but a
config file has the advantage of being simply read-writable by humans
and computers.

I notice several other package using options-style things that might
benefit from a simple persistence framework. For example the sm
package says in ?sm.options:

     This offers the possibility of customizing the functioning of the
     'sm' library, for instance by insertions of appropriate calls to
     'sm.options' in a load hook for package 'sm'.

To which the average user goes 'huh what?'. With a config file there
could be a save.sm.options() function that wrote a new section to the
user's .RConfig:

[sm]
 whatever = 99
 doSomething = TRUE

which the sm package would read in when it is first attached.

My usual R-devel caveats - yes, I know everyone has day jobs; yes, I'm
sure there are problems with it; no, I don't expect it to get done
unless someone thinks it's a Good Thing because I probably don't have
time for it; yes, R is wonderful and fantastic and you devs do a
fantastic job.

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From murdoch at stats.uwo.ca  Wed Feb 10 12:44:15 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 10 Feb 2010 06:44:15 -0500
Subject: [Rd] R Startup configuration file
In-Reply-To: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
Message-ID: <4B729C0F.3030301@stats.uwo.ca>

Barry Rowlingson wrote:
> Currently when R starts up it can be configured by a file of
> environment variable specifications and a file of R code. This makes
> programmatic modification of startup configuration tricky.
>
> Case in point: I start R, do install.packages("foo"), and up pops the
> 'choose a CRAN mirror' dialog. I'd like to put a 'Save my choice'
> button on that dialog. Currently it would have to put
> 'options(repos="http://example.com/cran")' into my .Rprofile file. Of
> course my .Rprofile file could be full of all sorts of other code, so
> there's no easy way to do this and guarantee it will work.
>
> Could we have a ".Rconfig" file, consisting of key-value pairs in a
> standard config file form (or XML?), that is read at startup and
> applies the key-value pairs to options(key=value)? Obviously more
> detail is needed, such as whether to just have one .Rconfig file in
> the users' $HOME or in individual folders, where to put a system
> Rconfig file, whether it is applied before or after .Rprofile etc.
>   

When I read the ?Startup man page, I find it is too complicated already; 
I don't want to add another kind of file to read.  (Would we have  
separate user and site versions of this new file?  When would it be 
handled?)

However, we could achieve what you are asking for with no changes to 
base R.  One way would be to write a small package to handle options.  
When you want to save a setting, you call a function there that writes 
it to a private file.  Then you manually add a line to your .Rprofile, 
saying something like "myOptionPackage::loadMyOptions()".  This can do 
whatever you want, it only needs to know how to parse the file that your 
package wrote.

Duncan Murdoch

> Or is it a dumb idea? I can see other ways of doing this, such as
> saving the options() as an object and re-loading it at startup, but a
> config file has the advantage of being simply read-writable by humans
> and computers.
>
> I notice several other package using options-style things that might
> benefit from a simple persistence framework. For example the sm
> package says in ?sm.options:
>
>      This offers the possibility of customizing the functioning of the
>      'sm' library, for instance by insertions of appropriate calls to
>      'sm.options' in a load hook for package 'sm'.
>
> To which the average user goes 'huh what?'. With a config file there
> could be a save.sm.options() function that wrote a new section to the
> user's .RConfig:
>
> [sm]
>  whatever = 99
>  doSomething = TRUE
>
> which the sm package would read in when it is first attached.
>
> My usual R-devel caveats - yes, I know everyone has day jobs; yes, I'm
> sure there are problems with it; no, I don't expect it to get done
> unless someone thinks it's a Good Thing because I probably don't have
> time for it; yes, R is wonderful and fantastic and you devs do a
> fantastic job.
>
> Barry
>
>


From manuel.lopez-ibanez at ulb.ac.be  Wed Feb 10 14:45:11 2010
From: manuel.lopez-ibanez at ulb.ac.be (manuel.lopez-ibanez at ulb.ac.be)
Date: Wed, 10 Feb 2010 14:45:11 +0100 (CET)
Subject: [Rd] system.time provides inaccurate sys.child (PR#14210)
Message-ID: <20100210134511.4BDA32830315@mail.pubhealth.ku.dk>

Full_Name: Manuel L?pez-Ib??ez
Version: R version 2.6.2 (2008-02-08)
OS: linux-gnu 
Submission from: (NULL) (164.15.10.156)


This is only relevant for CPU intensive child processes. Otherwise, the problem
is not obvious.

Therefore, we need a CPU intensive program like this one:

/************************************/
/*** Compile with: gcc -o timer-test -O0 timer-test.c -lm */
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

double alpha, beta;
int size = 1000;

#define WORK_create_matrix(TYPEOFMATRIX)                \
                                                        \
TYPEOFMATRIX ** m_create_##TYPEOFMATRIX##_matrix (      \
int dim1, int dim2, int line, const char*file)          \
{                                                       \
    TYPEOFMATRIX **p;                                   \
    int i;                                              \
                                                        \
    p = malloc (sizeof(TYPEOFMATRIX) * dim1 * dim2      \
                + sizeof(TYPEOFMATRIX *) * dim1 );      \
    if (p == NULL) {                                    \
        fprintf(stderr, "cannot create " #TYPEOFMATRIX  \
                " matrix of size (%d x %d): "           \
                "see line %d of file %s\n",             \
                dim1, dim2, line, file);                \
        exit(1);                                        \
    }                                                   \
    for (i = 0; i < dim1; i++)                          \
        p[i] = (TYPEOFMATRIX *) (p + dim1) + i * dim2;  \
    return p;                                           \
}                                                       

WORK_create_matrix(int)
WORK_create_matrix(double)
#undef WORK_create_matrix
#define create_double_matrix(dim1,dim2)\
    m_create_double_matrix(dim1,dim2,__LINE__,__FILE__)


int main(int argc, char *argv[])
{
    double **matrix1 = create_double_matrix(size, size);
    double **matrix2 = create_double_matrix(size, size);
    int iterations = 0;
    int i,j;
    double iter_limit = 100;
    alpha = rand();
    beta = rand();

    while (iterations < iter_limit) {
        for (i = 0; i < size; i++) {
            for (j = 0; j < size; j++) {
                if (i == j) continue;
                matrix2[i][j] = pow(matrix1[i][j], alpha)
                    * pow(matrix2[j][i], beta);
                matrix1[j][i] = matrix2[i][j];
            }
        }
        iterations++;
    }

    printf("Iterations = %d\n", iterations);
    return 0;
}
/************************************/

Then in R evaluate:

> print.default (system.time (system(paste ("time", "bash -c './timer-test 100 >
/dev/null'"))))
10.77user 0.02system 0:10.81elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
0inputs+0outputs (0major+4574minor)pagefaults 0swaps
 user.self   sys.self    elapsed user.child  sys.child 
     0.000      0.000     10.818     10.777     10.777 
attr(,"class")
[1] "proc_time"

Expected: the sys.child time should be 0.02.

> version
               _                           
platform       i486-pc-linux-gnu           
arch           i486                        
os             linux-gnu                   
system         i486, linux-gnu             
status                                     
major          2                           
minor          6.2                         
year           2008                        
month          02                          
day            08                          
svn rev        44383                       
language       R                           
version.string R version 2.6.2 (2008-02-08)


From manuel.lopez-ibanez at ulb.ac.be  Wed Feb 10 15:26:48 2010
From: manuel.lopez-ibanez at ulb.ac.be (=?ISO-8859-1?Q?Manuel_L=F3pez-Ib=E1=F1ez?=)
Date: Wed, 10 Feb 2010 15:26:48 +0100
Subject: [Rd] incoming/14210 system.time provides inaccurate sys.child
Message-ID: <4B72C228.6070508@ulb.ac.be>

Patch against current trunk attached. It is a one-liner, so I do not
believe anyone can claim copyright over it.

Cheers,

	Manuel.

BTW, bugs.r-project.org is painfully slow. I cannot login, I cannot post
messages, I cannot attach files. And it doesn't handle accents in my name.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: patch.diff
Type: text/x-diff
Size: 602 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100210/c5e44b1d/attachment.bin>

From b.rowlingson at lancaster.ac.uk  Wed Feb 10 16:06:26 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 10 Feb 2010 15:06:26 +0000
Subject: [Rd] R Startup configuration file
In-Reply-To: <4B729C0F.3030301@stats.uwo.ca>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
Message-ID: <d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>

On Wed, Feb 10, 2010 at 11:44 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> When I read the ?Startup man page, I find it is too complicated already; I
> don't want to add another kind of file to read. ?(Would we have ?separate
> user and site versions of this new file? ?When would it be handled?)
>
> However, we could achieve what you are asking for with no changes to base R.
> ?One way would be to write a small package to handle options. ?When you want
> to save a setting, you call a function there that writes it to a private
> file. ?Then you manually add a line to your .Rprofile, saying something like
> "myOptionPackage::loadMyOptions()". ?This can do whatever you want, it only
> needs to know how to parse the file that your package wrote.
>

 Yup, I'd already thought about this. However it does mean that any
other packages or applications that use this feature are going to have
to say "make sure you have saveableOptions::loadMyOptions() in your R
profile startup somewhere". Resulting in "huh what?" from users.

 Actually that's not true if the options are only used in add-on
packages - they can require(saveableIOptions) and load them in their
package .First.lib or .onLoad code. It's only options in the R base
(set by options()) that you need to hack code in order to run at
startup...

 In most modern programs, options and setup state are stored when the
user hits the 'apply' button. Even emacs can handle customisation in a
set of config files these days. Can't remember the last time I hacked
lisp in my .emacs file.

 But I agree that writing a saveable options package is the first step
- then making that a default in R is the second so people don't have
to edit profiles and R packages and applications can expect an API for
savable state.

 As for Startup Overload Syndrome - yes, ?Startup is a bit complicated
already. Maybe a sign it needs simplifying!

Barry


From P.Dalgaard at biostat.ku.dk  Wed Feb 10 16:40:24 2010
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Wed, 10 Feb 2010 16:40:24 +0100 (CET)
Subject: [Rd] (PR#14210) incoming/14210 system.time provides inaccurate
Message-ID: <20100210154024.C62012830315@mail.pubhealth.ku.dk>

Manuel L=C3=B3pez-Ib=C3=A1=C3=B1ez wrote:
> Patch against current trunk attached. It is a one-liner, so I do not
> believe anyone can claim copyright over it.

Fixed for r-devel (r51115).


> Cheers,
>=20
>     Manuel.
>=20
> BTW, bugs.r-project.org is painfully slow. I cannot login, I cannot pos=
t
> messages, I cannot attach files. And it doesn't handle accents in my na=
me.

Well, it will die from other causes at the latest on March 1, anyway...
Hopefully Simon Urbanek can pick up the pieces and put a more modern bug
tracker in its place.

(Part of the reason is that Jitterbug is horribly old and unmaintained;
another part is that U.Cph. appears to be intent on committing IT
suicide in the name of rampant corporativism. It is by design that only
a select group of people can login, though. It is expecting followups by
mail, for some reason.)


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Greg.Snow at imail.org  Wed Feb 10 20:59:47 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 10 Feb 2010 12:59:47 -0700
Subject: [Rd] R crashes when setWinProgressBar is give a numeric value for
 label argument
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F9A05A77@LP-EXMBVS10.CO.IHC.COM>

This problem can be seen by the following commands:

> pb <- winProgressBar(max=1000, label='0')
> b <- 1
> setWinProgressBar(pb, b, label=b)

This set of commands (on windows of course, XP in this case) causes R to crash.

This is not strictly a bug since the documentation states that the label argument should be a character string and using as.character(b) does work properly.  But when I (and possibly others) forget this and use something like the above, having the whole R process crash seems a bit extreme.

Possible responses:

1. ignore this and hope that after being punished for not remembering the correct syntax enough times I will eventually learn to do the correct thing.

2. add a check and generate an error if title or lab is not a character string (less severe punishment, I may learn eventually, but maybe not as quick).

3. add label <- as.character(label) and same idea for title, so that the above code works without the user needing to remember the as.character.  This may need a check for NULL values as well.

4.  Something else that I have not thought of.

Number 1 would be easiest for R core, hardest on me.  Numbers 2 and 3 have the potential drawback of slowing things down slightly.

My sessionInfo()

> sessionInfo()
R version 2.10.1 Patched (2010-02-08 r51108) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.10.1
>

Same thing happens in non-patched 2.10.1

Thanks,



-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


From cstrato at aon.at  Wed Feb 10 22:02:02 2010
From: cstrato at aon.at (cstrato)
Date: Wed, 10 Feb 2010 22:02:02 +0100
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
Message-ID: <4B731ECA.304@aon.at>

Dear Debian/Ubuntu experts,

For the second time users of my BioC package reported problems when 
trying to compile it on Debian/Ubuntu.

The error is always the same: "'wcstombs' was not declared in this 
scope", see:
https://www.stat.math.ethz.ch/pipermail/bioconductor/2010-February/031739.html
https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html

Since I have no problems compiling my package on OpenSUSE11.1, MacOS X 
and WinXP, I assume that maybe some development package may not be 
installed?

Do you know what might be the reason for the compilation error on 
Debian/Ubuntu?
Which development headers/packages (glibc-headers, glibc-kernheaders??) 
need to be installed on Debian/Ubuntu?

Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From edd at debian.org  Wed Feb 10 22:17:59 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 10 Feb 2010 15:17:59 -0600
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <4B731ECA.304@aon.at>
References: <4B731ECA.304@aon.at>
Message-ID: <19315.8839.209171.339462@ron.nulle.part>


Christian,

On 10 February 2010 at 22:02, cstrato wrote:
| Dear Debian/Ubuntu experts,
| 
| For the second time users of my BioC package reported problems when 
| trying to compile it on Debian/Ubuntu.
| 
| The error is always the same: "'wcstombs' was not declared in this 
| scope", see:
| https://www.stat.math.ethz.ch/pipermail/bioconductor/2010-February/031739.html
| https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
| 
| Since I have no problems compiling my package on OpenSUSE11.1, MacOS X 
| and WinXP, I assume that maybe some development package may not be 
| installed?
| 
| Do you know what might be the reason for the compilation error on 
| Debian/Ubuntu?
| Which development headers/packages (glibc-headers, glibc-kernheaders??) 
| need to be installed on Debian/Ubuntu?

There is a dedicated list for Debian / Ubuntu called r-sig-debian which is a
better target for such questions.

I have never encountered or knowingly used wcstombs, though I do have a
manual page for it.  Could you provide a small self-contained example that
works for you to see if I can build it?

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From gb at stat.umu.se  Wed Feb 10 22:35:11 2010
From: gb at stat.umu.se (gb at stat.umu.se)
Date: Wed, 10 Feb 2010 22:35:11 +0100 (CET)
Subject: [Rd] Wrong documentation of  'isTRUE' (PR#14212)
Message-ID: <20100210213511.F049B283031C@mail.pubhealth.ku.dk>

Full_Name: G?ran Brostr?m
Version: 2.10.1
OS: Ubuntu 9.10
Submission from: (NULL) (85.11.40.53)


The documentation  for 'isTRUE' states that

 'isTRUE(x)' is an abbreviation of 'identical(TRUE, x)', and so is
  true if and only if 'x' is a length-one logical vector with no
  attributes (not even names).

But,

> x <- FALSE
> isTRUE(x)
[1] FALSE

is not true. Add, somewhere after 'logical vector, 'equal to TRUE', or 'taking
the value TRUE'. Maybe 'true' should be changed to 'TRUE' as well.


From cstrato at aon.at  Wed Feb 10 22:40:17 2010
From: cstrato at aon.at (cstrato)
Date: Wed, 10 Feb 2010 22:40:17 +0100
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <19315.8839.209171.339462@ron.nulle.part>
References: <4B731ECA.304@aon.at> <19315.8839.209171.339462@ron.nulle.part>
Message-ID: <4B7327C1.6050803@aon.at>

Dear Dirk,

Thank you for your fast reply.

I am afraid that a small self-contained example will not solve the 
problem, since in this example I would need to add "#include 
<stdlib.h>", and as you can see from:
https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
adding "#include <stdlib.h>" to some C++ *.cxx files did solve the problem.

The question is, why did this user need to add "#include <stdlib.h>" on 
Debian, while this is not necessary on OpenSUSE11.1 and MacOS X?

Best regards
Christian


Dirk Eddelbuettel wrote:
> Christian,
>
> On 10 February 2010 at 22:02, cstrato wrote:
> | Dear Debian/Ubuntu experts,
> | 
> | For the second time users of my BioC package reported problems when 
> | trying to compile it on Debian/Ubuntu.
> | 
> | The error is always the same: "'wcstombs' was not declared in this 
> | scope", see:
> | https://www.stat.math.ethz.ch/pipermail/bioconductor/2010-February/031739.html
> | https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
> | 
> | Since I have no problems compiling my package on OpenSUSE11.1, MacOS X 
> | and WinXP, I assume that maybe some development package may not be 
> | installed?
> | 
> | Do you know what might be the reason for the compilation error on 
> | Debian/Ubuntu?
> | Which development headers/packages (glibc-headers, glibc-kernheaders??) 
> | need to be installed on Debian/Ubuntu?
>
> There is a dedicated list for Debian / Ubuntu called r-sig-debian which is a
> better target for such questions.
>
> I have never encountered or knowingly used wcstombs, though I do have a
> manual page for it.  Could you provide a small self-contained example that
> works for you to see if I can build it?
>
> Dirk
>
>


From ripley at stats.ox.ac.uk  Wed Feb 10 23:03:35 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Feb 2010 22:03:35 +0000 (GMT)
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <4B731ECA.304@aon.at>
References: <4B731ECA.304@aon.at>
Message-ID: <alpine.LFD.2.00.1002102141080.27750@gannet.stats.ox.ac.uk>

Such errors are common when people use older versions of g++ to write 
their C++ code.  Later versions of g++ have somewhat stricter 
conformance to the C++ standards and catch some lax usage: we've seen 
it quite a lot for g++ 4.4.x and even more for pre-4.5.0.  In all the 
cases I have seen this message indicates a missing header.

wcstombs is a C99 function declared in <stdlib.h>: given that this 
looks like a C++ error message, did you include its C++ version, 
<cstdlib>?

Note that Mac OS X and (32-bit) WinXP are using g++ 4.2.x.  Also, what 
other headers a particular header includes is OS-dependent (and maybe 
even compiler-dependent): we have had a lot of trouble recently with 
<stdint.h> that some OSes (especially MinGW32) include from more 
common headers and some do not.

So this may be an OS issue but a compiler-version issue is more 
likely.


On Wed, 10 Feb 2010, cstrato wrote:

> Dear Debian/Ubuntu experts,
>
> For the second time users of my BioC package reported problems when trying to 
> compile it on Debian/Ubuntu.
>
> The error is always the same: "'wcstombs' was not declared in this scope", 
> see:
> https://www.stat.math.ethz.ch/pipermail/bioconductor/2010-February/031739.html
> https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
>
> Since I have no problems compiling my package on OpenSUSE11.1, MacOS X and 
> WinXP, I assume that maybe some development package may not be installed?
>
> Do you know what might be the reason for the compilation error on 
> Debian/Ubuntu?
> Which development headers/packages (glibc-headers, glibc-kernheaders??) need 
> to be installed on Debian/Ubuntu?
>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
> V.i.e.n.n.a           A.u.s.t.r.i.a
> e.m.a.i.l:        cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Wed Feb 10 23:06:24 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 10 Feb 2010 16:06:24 -0600
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <4B7327C1.6050803@aon.at>
References: <4B731ECA.304@aon.at> <19315.8839.209171.339462@ron.nulle.part>
	<4B7327C1.6050803@aon.at>
Message-ID: <19315.11744.149268.583099@ron.nulle.part>


Christian,

On 10 February 2010 at 22:40, cstrato wrote:
| Dear Dirk,
| 
| Thank you for your fast reply.
| 
| I am afraid that a small self-contained example will not solve the 
| problem, since in this example I would need to add "#include 
| <stdlib.h>", and as you can see from:
| https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
| adding "#include <stdlib.h>" to some C++ *.cxx files did solve the problem.
| 
| The question is, why did this user need to add "#include <stdlib.h>" on 
| Debian, while this is not necessary on OpenSUSE11.1 and MacOS X?

That is difficult to say given the limited information you provided [ hint:
next time please list compiler, libc, and libstdc++ versions ] but one common
pattern is more recent-vs-older g++ versions as newer ones became more picky
about missing header includes.

This is now off-topic for r-devel so let's move it off-list.

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From cstrato at aon.at  Thu Feb 11 00:08:11 2010
From: cstrato at aon.at (cstrato)
Date: Thu, 11 Feb 2010 00:08:11 +0100
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <alpine.LFD.2.00.1002102141080.27750@gannet.stats.ox.ac.uk>
References: <4B731ECA.304@aon.at>
	<alpine.LFD.2.00.1002102141080.27750@gannet.stats.ox.ac.uk>
Message-ID: <4B733C5B.9030903@aon.at>

Dear Prof. Ripley,

Thank you for this extensive explanation.

The compiler version of OpenSUSE11.1 is "gcc version 4.3.2" whereas 
Ubuntu uses "gcc 4.4.1". Interestingly, the first complaint was a Debian 
testing (squeeze) user with "gcc-4.3".

Since my package depends on ROOT I have assumed that <stdlib.h> was 
declared in their headers, which is only the case for Sun. Thus it seems 
that I need to add <cstdlib> to my respective implementation files.

Best regards
Christian


Prof Brian Ripley wrote:
> Such errors are common when people use older versions of g++ to write 
> their C++ code.  Later versions of g++ have somewhat stricter 
> conformance to the C++ standards and catch some lax usage: we've seen 
> it quite a lot for g++ 4.4.x and even more for pre-4.5.0.  In all the 
> cases I have seen this message indicates a missing header.
>
> wcstombs is a C99 function declared in <stdlib.h>: given that this 
> looks like a C++ error message, did you include its C++ version, 
> <cstdlib>?
>
> Note that Mac OS X and (32-bit) WinXP are using g++ 4.2.x.  Also, what 
> other headers a particular header includes is OS-dependent (and maybe 
> even compiler-dependent): we have had a lot of trouble recently with 
> <stdint.h> that some OSes (especially MinGW32) include from more 
> common headers and some do not.
>
> So this may be an OS issue but a compiler-version issue is more likely.
>
>
> On Wed, 10 Feb 2010, cstrato wrote:
>
>> Dear Debian/Ubuntu experts,
>>
>> For the second time users of my BioC package reported problems when 
>> trying to compile it on Debian/Ubuntu.
>>
>> The error is always the same: "'wcstombs' was not declared in this 
>> scope", see:
>> https://www.stat.math.ethz.ch/pipermail/bioconductor/2010-February/031739.html 
>>
>> https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
>>
>> Since I have no problems compiling my package on OpenSUSE11.1, MacOS 
>> X and WinXP, I assume that maybe some development package may not be 
>> installed?
>>
>> Do you know what might be the reason for the compilation error on 
>> Debian/Ubuntu?
>> Which development headers/packages (glibc-headers, 
>> glibc-kernheaders??) need to be installed on Debian/Ubuntu?
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>> V.i.e.n.n.a           A.u.s.t.r.i.a
>> e.m.a.i.l:        cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From cstrato at aon.at  Thu Feb 11 00:08:58 2010
From: cstrato at aon.at (cstrato)
Date: Thu, 11 Feb 2010 00:08:58 +0100
Subject: [Rd] wcstombs error when compiling package with Debian/Ubuntu
In-Reply-To: <19315.11744.149268.583099@ron.nulle.part>
References: <4B731ECA.304@aon.at>	<19315.8839.209171.339462@ron.nulle.part>	<4B7327C1.6050803@aon.at>
	<19315.11744.149268.583099@ron.nulle.part>
Message-ID: <4B733C8A.3040400@aon.at>

Dear Dirk,

The compiler version of OpenSUSE11.1 is "gcc version 4.3.2" whereas 
Ubuntu uses "gcc 4.4.1". Interestingly, the first complaint was a Debian 
testing (squeeze) user with "gcc-4.3".

Since it seems to be a problem of "recent-vs-older g++ versions" I will 
include the header file.

I did not realize that there is a dedicated r-sig-debian mailing list, 
which I will use next time.

Best regards
Christian


Dirk Eddelbuettel wrote:
> Christian,
>
> On 10 February 2010 at 22:40, cstrato wrote:
> | Dear Dirk,
> | 
> | Thank you for your fast reply.
> | 
> | I am afraid that a small self-contained example will not solve the 
> | problem, since in this example I would need to add "#include 
> | <stdlib.h>", and as you can see from:
> | https://stat.ethz.ch/pipermail/bioconductor/2009-August/029192.html
> | adding "#include <stdlib.h>" to some C++ *.cxx files did solve the problem.
> | 
> | The question is, why did this user need to add "#include <stdlib.h>" on 
> | Debian, while this is not necessary on OpenSUSE11.1 and MacOS X?
>
> That is difficult to say given the limited information you provided [ hint:
> next time please list compiler, libc, and libstdc++ versions ] but one common
> pattern is more recent-vs-older g++ versions as newer ones became more picky
> about missing header includes.
>
> This is now off-topic for r-devel so let's move it off-list.
>
> Dirk
>
>


From david at heffs.org.uk  Wed Feb 10 23:12:10 2010
From: david at heffs.org.uk (David Heffernan)
Date: Wed, 10 Feb 2010 22:12:10 +0000 (UTC)
Subject: [Rd] Copyright on src/nmath/qnorm.c
Message-ID: <loom.20100210T221159-74@post.gmane.org>

At the top of src/nmath/qnorm.c it is stated:

 *  Copyright (C) 1998       Ross Ihaka
 *  Copyright (C) 2000--2005 The R Development Core Team
 *  based on AS 111 (C) 1977 Royal Statistical Society
 *  and   on AS 241 (C) 1988 Royal Statistical Society

The routine is in fact an f2c'd version of AS241 from StatLib:
http://lib.stat.cmu.edu/apstat/241 and http://lib.stat.cmu.edu/apstat/

It seems odd to me that this is re-licensed under GPL and copyright asserted to
be held by R Development Core Team.  I expect that if I looked further I could
find plenty of other routines with a similar heritage.  

The StatLib page states, "The Royal Statistical Society holds the copyright to
these routines, but has given its permission for their distribution provided
that no fee is charged."

Why does R Development Core Team claim copyright for what appears to be work
copyright RSS?  You really ought to ascribe the copyright to RSS.

I don't think that the GPL is compatible with the StatLib license since the GPL
does not forbid charging a fee for distribution.

I guess you could come to some agreement with the RSS and I'm sure they would be
happy to help.

I think that it is important to be very precise on matters of licensing which is
why I raise the point.

David Heffernan.


From romain at r-enthusiasts.com  Thu Feb 11 10:08:38 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Thu, 11 Feb 2010 10:08:38 +0100
Subject: [Rd] LinkingTo and C++
Message-ID: <4B73C916.4090705@r-enthusiasts.com>

Hello,

I've been trying to make LinkingTo work when the package linked to has 
c++ code.

I've put dumb packages to illustrate this emails here ; 
http://addictedtor.free.fr/misc/linkingto

Package A defines this C++ class:

class A {
public:
	A() ;
	~A() ;
	SEXP hello() ;
} ;

Package B has this function :

SEXP say_hello(){
	A a ;
	return a.hello() ;
}

headers of package A are copied into inst/include so that package B can 
have.

LinkingTo: A

in its DESCRIPTION file.

Also, package B has the R function ;

g <- function(){
	.Call("say_hello", PACKAGE = "B")
}

With this I can compile A and B, but then I get :

$ Rscript -e "B::g()"
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared library '/usr/local/lib/R/library/B/libs/B.so':
   /usr/local/lib/R/library/B/libs/B.so: undefined symbol: _ZN1AD1Ev
Calls: :: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>

If I then add a Makevars in B with this :


# find the root directory where A is installed
ADIR=$(shell $(R_HOME)/bin/Rscript -e "cat(system.file(package='A'))" )

PKG_LIBS= $(ADIR)/libs/A$(DYLIB_EXT)


Then it works:

$ Rscript -e "B::g()"
[1] "hello"

So it appears that adding the -I flag, which is what LinkingTo does is 
not enough when the package "linking from" (B) actually has to link to 
the "linked to" package (A).

I've been looking at 
http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines 
but it seems only applicable to c(++) functions and not classes ...

What am I missing ? Should/can linkingto be extended in a way that 
accomodates c++

Romain


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/NrTG : Rcpp 0.7.5
|- http://tr.im/MPYc : RProtoBuf: protocol buffers for R
`- http://tr.im/KfKn : Rcpp 0.7.2


From arnima at hafro.is  Thu Feb 11 10:09:14 2010
From: arnima at hafro.is (Arni Magnusson)
Date: Thu, 11 Feb 2010 09:09:14 +0000 (UTC)
Subject: [Rd] Rounding multinomial proportions
Message-ID: <alpine.LFD.2.00.1002110838170.8275@hafstormur.hafro.is>

I present you with a function that solves a problem that has bugged me for 
many years. I think the problem may be general enough to at least consider 
adding this function, or a revamped version of it, to the 'stats' package, 
with the other multinomial functions reside.

I'm using R to export data to text files, which are input data for an 
external model written in C++. Parts of the data are age distributions, in 
the form of relative frequency in each year:

   Year  Age1   Age2   ...  Age10
   1980  0.123  0.234  ...  0.001
   ...   ...    ...    ...  ...

Each row should sum to exactly 1. The problem is that when I preprocess 
each line in R as p<-a/sum(a), occasionally a line will sum to 0.999, 
1.002, or the like. This could either crash the external model or lead to 
wrong conclusions.

I believe similar partitioning is commonly used in a wide variety of 
models, making this a general problem for many modellers.

In the past, I have checked every line manually, and then arbitrarily 
tweaked one or two values up or down to make the row sum to exactly one, 
but two people would tweak differently. Another semi-solution is to write 
the values to the text file in a very long format, but this would (1) make 
it harder to visually check the numbers and (2) the numbers in the article 
or report would no longer match the data files exactly, so other 
scientists could not repeat the analysis and get the same results.

Once I implemented a quick and dirty solution, simply setting the last 
proportion (Age10 above) as 1 minus the sum of ages 1-9. I quickly stopped 
using that approach when I started seeing negative values.

After this introduction, the attached round_multinom.html should make 
sense. The algorithm I ended up choosing comes from allocating seats in 
elections, so I was tempted to provide that application as well, although 
it makes the interface and documentation slightly more confusing.

The working title of this function was a short and catchy vote(), but I 
changed it to round_multinom(), even though it's not matrix-oriented like 
the other *multinom functions. That would probably be straightforward to 
do, but I'll keep it as a vector function during the initial discussion.

I'm curious to hear your impressions and ideas. In the worst case, this is 
a not-so-great solution to a marginal problem. In the best case, this 
might be worth a short note in the Journal of Statistical Software.

Thanks for your time,

Arni

P.S. In case the mailing list doesn't handle attachments, I've placed the 
same files on http://www.hafro.is/~arnima/ for your convenience.
-------------- next part --------------
\name{round_multinom}
\alias{round_multinom}
\encoding{UTF-8}
\title{
  Round Multinomial Proportions (or Allocate Seats from Election
  Results)
}
\description{
  This function can round multinomial proportions to a given number of
  decimal places, while making sure the rounded proportions sum to
  exactly one. This is achieved using one of three algorithms that were
  originally invented to allocate seats from election results.

  It is often necessary to round proportions, e.g. to produce legible
  percentages for an article or a presentation. Rounding also takes
  place when data are written to a text file, to be analyzed by an
  external model. The rounded proportions often fail to add to exactly
  one,
  \preformatted{
    a <- c(67630, 116558, 207536, 251555, 356721)
    p <- round(a/sum(a), 3)  # 0.068  0.117  0.208  0.252  0.357
    sum(p)                   # 1.002}
  which would make the rounded proportions illegal input data for many
  models. Instead of manually checking and arbitrarily tweaking
  proportions so they add to exactly one, this function can guarantee
  that condition, using an unbiased algorithm.
}
\usage{
round_multinom(x, digits = NULL, seats = NULL, method="SL", labels = names(x))
}
\arguments{
  \item{x}{vector containing multinomial proportions or counts.}
  \item{digits}{
    number of decimal places to use when rounding multinomial
    proportions.
  }
  \item{seats}{number of seats to allocate from election results.}
  \item{method}{
    string specifying the algorithm to use: \code{"DH"}, \code{"MSL"},
    or \code{"SL"}.
  }
  \item{labels}{optional vector of names for the output vector.}
}
\details{
  This function should be called \emph{either} with a \code{digits}
  argument to round multinomial proportions, \emph{or} with a
  \code{seats} argument to allocate seats from election results, not
  both.

  The algorithms are variations of the \dQuote{highest averages} method
  for allocating seats proportionally from multiparty election results:
  \describe{
    \item{\code{"DH"}}{
      d'Hondt method, involves the series 1, 2, 3, \ldots, \eqn{n}.
      Favors big parties.
    }
    \item{\code{"MSL"}}{
      Modified Sainte-Lagu??, involves the series 1, 2.4, 3.8, \ldots,
      1.4\eqn{n}--0.4. Favors big parties slightly.
    }
    \item{\code{"SL"}}{
      Sainte-Lagu??. Involves the series 1, 3, 5, \ldots, 2\eqn{n}--1.
      Does not favor big or small parties. A reasonable default method
      for rounding multinomial proportions.
    }
  }
}
\value{
  Vector of same length as \code{x}, with rounded numbers whose sum is
  one (or integers whose sum is \code{seats}).
}
\note{
  d'Hondt is used to allocate parliamentary seats in most of Europe and
  South America, East Timor, Israel, Japan, and Turkey.

  Modified Sainte-Lagu?? is used in Norway and Sweden.

  Sainte-Lagu?? is used in Bosnia and Herzegovina, Kosovo, Latvia, and
  New Zealand.
}
\author{Arni Magnusson.}
\references{
  Balinski, M. and V. Ram??rez. 1999. Parametric methods of
  apportionment, rounding and production. \emph{Mathematical Social
    Sciences} \bold{37}:107--122.

  Diaconis, P. and D. Freedman. 1979. On rounding percentages.
  \emph{Journal of the American Statistical Association}
  \bold{74}:359--364.

  Mosteller, F., C. Youtz, and D. Zahn. 1967. The distribution of sums
  of rounded percentages. \emph{Demography} \bold{4}:850--858.

  \url{http://en.wikipedia.org/wiki/Highest_averages_method} (accessed
  10 Feb 2010).
}
\seealso{
  \code{\link{round}} is the standard rounding function in \R.

  \code{\link{rmultinom}} generates random multinomial vectors.
}
\examples{
## Guarantee that rounded multinomial proportions sum to 1:

a <- c(67630, 116558, 207536, 251555, 356721)
p <- a / sum(a)
p1 <- round(p, 3)           # 0.068  0.117  0.208  0.252  0.357
sum(p1)                     # 1.002, no good
p2 <- round_multinom(p, 3)  # 0.068  0.117  0.207  0.251  0.357
sum(p2)                     # 1


## The multinomial "proportions" can also be raw counts (a, not p):

p3 <- round_multinom(a, 3)  # 0.068  0.117  0.207  0.251  0.357
sum(p3)                     # 1


## Allocate 9 seats from 178 votes using different methods:

votes <- c(red=66, green=80, blue=32)
round_multinom(votes, seats=9, method="DH")   # 4 4 1
round_multinom(votes, seats=9, method="MSL")  # 3 4 2
round_multinom(votes, seats=9, method="SL")   # 3 4 2
}
\keyword{arith}
\keyword{distribution}
-------------- next part --------------
round_multinom <- function(x, digits=NULL, seats=NULL, method="SL", labels=names(x))
{
  method <- match.arg(toupper(method), c("DH","MSL","SL"))

  if(is.null(digits) && is.null(seats) || !is.null(digits) && !is.null(seats))
    stop("Please pass a value as 'digits' or 'seats', not both")
  if(!is.null(digits))
  {
    if(digits<0 || digits>6)
      stop("Please pass a positive value (0-6) as 'digits'")
    n <- as.integer(10^digits)
  }
  else
    n <- seats

  party <- seq_along(x)
  series <- switch(method,
                   DH  = 1 + 1  *(seq_len(n)-1),  # 1, 2,   3,   ..., n
                   MSL = 1 + 1.4*(seq_len(n)-1),  # 1, 2.4, 3.8, ..., 1.4n-0.4
                   SL  = 1 + 2  *(seq_len(n)-1))  # 1, 3,   5,   ..., 2n-1

  output <- data.frame(party=rep(party,each=n), score=as.numeric(sapply(x, function(votes) votes/series)))
  output <- factor(output$party)[order(-output$score)][seq_len(n)]
  output <- as.integer(table(output))

  if(!is.null(digits))
    output <- output / n
  names(output) <- labels

  return(output)
}

From romain.francois at dbmail.com  Thu Feb 11 10:58:42 2010
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 11 Feb 2010 10:58:42 +0100
Subject: [Rd] LinkingTo and C++
In-Reply-To: <4B73C916.4090705@r-enthusiasts.com>
References: <4B73C916.4090705@r-enthusiasts.com>
Message-ID: <4B73D4D2.3030808@dbmail.com>

On 02/11/2010 10:08 AM, Romain Francois wrote:
>
> Hello,
>
> I've been trying to make LinkingTo work when the package linked to has
> c++ code.
>
> I've put dumb packages to illustrate this emails here ;
> http://addictedtor.free.fr/misc/linkingto
>
> Package A defines this C++ class:
>
> class A {
> public:
> A() ;
> ~A() ;
> SEXP hello() ;
> } ;
>
> Package B has this function :
>
> SEXP say_hello(){
> A a ;
> return a.hello() ;
> }
>
> headers of package A are copied into inst/include so that package B can
> have.
>
> LinkingTo: A
>
> in its DESCRIPTION file.
>
> Also, package B has the R function ;
>
> g <- function(){
> .Call("say_hello", PACKAGE = "B")
> }
>
> With this I can compile A and B, but then I get :
>
> $ Rscript -e "B::g()"
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared library '/usr/local/lib/R/library/B/libs/B.so':
> /usr/local/lib/R/library/B/libs/B.so: undefined symbol: _ZN1AD1Ev
> Calls: :: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
>
> If I then add a Makevars in B with this :
>
>
> # find the root directory where A is installed
> ADIR=$(shell $(R_HOME)/bin/Rscript -e "cat(system.file(package='A'))" )
>
> PKG_LIBS= $(ADIR)/libs/A$(DYLIB_EXT)
>
>
> Then it works:
>
> $ Rscript -e "B::g()"
> [1] "hello"
>
> So it appears that adding the -I flag, which is what LinkingTo does is
> not enough when the package "linking from" (B) actually has to link to
> the "linked to" package (A).
>
> I've been looking at
> http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines
> but it seems only applicable to c(++) functions and not classes ...
>
> What am I missing ? Should/can linkingto be extended in a way that
> accomodates c++
>
> Romain

One other way of course would be to have some lib support, so that for 
example an R library holds not only R packages but shared libraries.

So for example, if as part of package A's Makevars, I copy its A.so into 
R.home( component = "lib" ) and rename it libA.so :

RLIBDIR=$(shell $(R_HOME)/bin/Rscript -e "cat(R.home(component='lib'))" )

all: $(SHLIB) install

install:
	cp $(SHLIB) $(RLIBDIR)/lib$(SHLIB)
	cp -f A.h ../inst/include

Then B can just have this Makevars :

PKG_LIBS=-lA

as well as the "LinkingTo: A" in the description.

Now I realize that R.home(component='lib') is not the right place where 
to host libA.so, as one might not have rights, etc ... but should there 
be a right place, as a per-R-library lib folder ?

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/NrTG : Rcpp 0.7.5
|- http://tr.im/MPYc : RProtoBuf: protocol buffers for R
`- http://tr.im/KfKn : Rcpp 0.7.2


From arnima at hafro.is  Thu Feb 11 11:26:40 2010
From: arnima at hafro.is (Arni Magnusson)
Date: Thu, 11 Feb 2010 10:26:40 +0000 (GMT)
Subject: [Rd] Rounding multinomial proportions
In-Reply-To: <alpine.LFD.2.00.1002110838170.8275@hafstormur.hafro.is>
References: <alpine.LFD.2.00.1002110838170.8275@hafstormur.hafro.is>
Message-ID: <alpine.LFD.2.00.1002111021330.8933@hafstormur.hafro.is>

Ugh, I made a typo at the very heart of my message:

"when I preprocess each line in R as p<-a/sum(a), occasionally a line will 
sum to 0.999, 1.002, or the like"

should be

"when I preprocess each line in R as p<-round(a/sum(a),3) occasionally a 
line will sum to 0.999, 1.002, or the like"

Also, the first paragraph should end with "where the other multinomial 
functions reside."

Revision 2,

Arni



On Thu, 11 Feb 2010, Arni Magnusson wrote:

> I present you with a function that solves a problem that has bugged me 
> for many years. I think the problem may be general enough to at least 
> consider adding this function, or a revamped version of it, to the 
> 'stats' package, with the other multinomial functions reside.
>
> I'm using R to export data to text files, which are input data for an 
> external model written in C++. Parts of the data are age distributions, 
> in the form of relative frequency in each year:
>
>  Year  Age1   Age2   ...  Age10
>  1980  0.123  0.234  ...  0.001
>  ...   ...    ...    ...  ...
>
> Each row should sum to exactly 1. The problem is that when I preprocess 
> each line in R as p<-a/sum(a), occasionally a line will sum to 0.999, 
> 1.002, or the like. This could either crash the external model or lead 
> to wrong conclusions.
>
> I believe similar partitioning is commonly used in a wide variety of 
> models, making this a general problem for many modellers.
>
> In the past, I have checked every line manually, and then arbitrarily 
> tweaked one or two values up or down to make the row sum to exactly one, 
> but two people would tweak differently. Another semi-solution is to 
> write the values to the text file in a very long format, but this would 
> (1) make it harder to visually check the numbers and (2) the numbers in 
> the article or report would no longer match the data files exactly, so 
> other scientists could not repeat the analysis and get the same results.
>
> Once I implemented a quick and dirty solution, simply setting the last 
> proportion (Age10 above) as 1 minus the sum of ages 1-9. I quickly 
> stopped using that approach when I started seeing negative values.
>
> After this introduction, the attached round_multinom.html should make 
> sense. The algorithm I ended up choosing comes from allocating seats in 
> elections, so I was tempted to provide that application as well, 
> although it makes the interface and documentation slightly more 
> confusing.
>
> The working title of this function was a short and catchy vote(), but I 
> changed it to round_multinom(), even though it's not matrix-oriented 
> like the other *multinom functions. That would probably be 
> straightforward to do, but I'll keep it as a vector function during the 
> initial discussion.
>
> I'm curious to hear your impressions and ideas. In the worst case, this 
> is a not-so-great solution to a marginal problem. In the best case, this 
> might be worth a short note in the Journal of Statistical Software.
>
> Thanks for your time,
>
> Arni
>
> P.S. In case the mailing list doesn't handle attachments, I've placed 
> the same files on http://www.hafro.is/~arnima/ for your convenience.
>


From P.Dalgaard at biostat.ku.dk  Thu Feb 11 14:49:13 2010
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 11 Feb 2010 14:49:13 +0100
Subject: [Rd] Copyright on src/nmath/qnorm.c
In-Reply-To: <loom.20100210T221159-74@post.gmane.org>
References: <loom.20100210T221159-74@post.gmane.org>
Message-ID: <4B740AD9.2040905@biostat.ku.dk>

David Heffernan wrote:
> At the top of src/nmath/qnorm.c it is stated:
> 
>  *  Copyright (C) 1998       Ross Ihaka
>  *  Copyright (C) 2000--2005 The R Development Core Team
>  *  based on AS 111 (C) 1977 Royal Statistical Society
>  *  and   on AS 241 (C) 1988 Royal Statistical Society
> 
> The routine is in fact an f2c'd version of AS241 from StatLib:
> http://lib.stat.cmu.edu/apstat/241 and http://lib.stat.cmu.edu/apstat/
> 
> It seems odd to me that this is re-licensed under GPL and copyright asserted to
> be held by R Development Core Team.  I expect that if I looked further I could
> find plenty of other routines with a similar heritage.  

(a) We sought permission from the RSS to use the Applied Statistics
algorithms in R, and GPL was mentioned in the discussions. There is a
list of such algorithms in doc/COPYRIGHTS.

(b) Multiple copyright statements refer to _changes_ to code (RSS does
not automatically obtain copyright for our modifications, including the
f2c translation), and as such, the headers are accurate.

Peter D.



> 
> The StatLib page states, "The Royal Statistical Society holds the copyright to
> these routines, but has given its permission for their distribution provided
> that no fee is charged."
> 
> Why does R Development Core Team claim copyright for what appears to be work
> copyright RSS?  You really ought to ascribe the copyright to RSS.
> 
> I don't think that the GPL is compatible with the StatLib license since the GPL
> does not forbid charging a fee for distribution.
> 
> I guess you could come to some agreement with the RSS and I'm sure they would be
> happy to help.
> 
> I think that it is important to be very precise on matters of licensing which is
> why I raise the point.
> 
> David Heffernan.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From simon.urbanek at r-project.org  Thu Feb 11 17:55:03 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 11 Feb 2010 11:55:03 -0500
Subject: [Rd] LinkingTo and C++
In-Reply-To: <4B73C916.4090705@r-enthusiasts.com>
References: <4B73C916.4090705@r-enthusiasts.com>
Message-ID: <01F75CF2-FA06-420B-A4DD-6776197B1E2B@r-project.org>

Romain,

I think your'e confusing two entirely different concepts here:

1) LinkingTo: allows a package to provide C-level functions to other packages (see R-ext 5.4). Let's say package A provides a function foo by calling R_RegisterCCallable for that function. If a package B wants to use that function, it uses LinkingTo: and calls R_GetCCallable to obtain the function pointer. It does not actually link to package A because that is in general not possible - it simply obtains the pointers through R. In addition, LinkingTo: makes sure that you have access to the header files of package A which help you to cast the functions and define any data structures you may need. Since C++ is a superset of C you can use this facility with C++ as long as you don't depend on anything outside of the header files.

2) linking directly to another package's shared object is in general not possible, because packages are not guaranteed to be dynamic libraries. They are usually shared objects which may or may not be compatible with a dynamic library on a given platform. Therefore the R-ext describes other way in which you may provide some library independently of the package shared object to other packages (see R-ext 5.8). The issue is that you have to create a separate library (PKG/libs[/arch]/PKG.so won't work in general!) and provide this to other packages. As 5.8 says, this is in general not trivial because it is very platform dependent and the most portable way is to offer a static library.
 
To come back to your example, LinkingTo: A and B will work if you remove Makevars from B (you don't want to link) and put your hello method into the A.h header:

> library (B)
Loading required package: A
> .Call("say_hello", PACKAGE = "B")
[1] "hello"

However, your'e not really using the LinkingTo: facilities for the functions so it's essentially just helping you to find the header file.

Cheers,
Simon



On Feb 11, 2010, at 4:08 AM, Romain Francois wrote:

> Hello,
> 
> I've been trying to make LinkingTo work when the package linked to has c++ code.
> 
> I've put dumb packages to illustrate this emails here ; http://addictedtor.free.fr/misc/linkingto
> 
> Package A defines this C++ class:
> 
> class A {
> public:
> 	A() ;
> 	~A() ;
> 	SEXP hello() ;
> } ;
> 
> Package B has this function :
> 
> SEXP say_hello(){
> 	A a ;
> 	return a.hello() ;
> }
> 
> headers of package A are copied into inst/include so that package B can have.
> 
> LinkingTo: A
> 
> in its DESCRIPTION file.
> 
> Also, package B has the R function ;
> 
> g <- function(){
> 	.Call("say_hello", PACKAGE = "B")
> }
> 
> With this I can compile A and B, but then I get :
> 
> $ Rscript -e "B::g()"
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared library '/usr/local/lib/R/library/B/libs/B.so':
>  /usr/local/lib/R/library/B/libs/B.so: undefined symbol: _ZN1AD1Ev
> Calls: :: ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
> 
> If I then add a Makevars in B with this :
> 
> 
> # find the root directory where A is installed
> ADIR=$(shell $(R_HOME)/bin/Rscript -e "cat(system.file(package='A'))" )
> 
> PKG_LIBS= $(ADIR)/libs/A$(DYLIB_EXT)
> 
> 
> Then it works:
> 
> $ Rscript -e "B::g()"
> [1] "hello"
> 
> So it appears that adding the -I flag, which is what LinkingTo does is not enough when the package "linking from" (B) actually has to link to the "linked to" package (A).
> 
> I've been looking at http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines but it seems only applicable to c(++) functions and not classes ...
> 
> What am I missing ? Should/can linkingto be extended in a way that accomodates c++
> 
> Romain
> 
> 
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://tr.im/NrTG : Rcpp 0.7.5
> |- http://tr.im/MPYc : RProtoBuf: protocol buffers for R
> `- http://tr.im/KfKn : Rcpp 0.7.2
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From romain at r-enthusiasts.com  Thu Feb 11 18:24:31 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Thu, 11 Feb 2010 18:24:31 +0100
Subject: [Rd] LinkingTo and C++
In-Reply-To: <01F75CF2-FA06-420B-A4DD-6776197B1E2B@r-project.org>
References: <4B73C916.4090705@r-enthusiasts.com>
	<01F75CF2-FA06-420B-A4DD-6776197B1E2B@r-project.org>
Message-ID: <4B743D4F.3090102@r-enthusiasts.com>

Thanks.

On 02/11/2010 05:55 PM, Simon Urbanek wrote:
> Romain,
>
> I think your'e confusing two entirely different concepts here:

Yes. The name "LinkingTo" probably helped my confusion.

> 1) LinkingTo: allows a package to provide C-level functions to other packages (see R-ext 5.4). Let's say package A provides a function foo by calling R_RegisterCCallable for that function. If a package B wants to use that function, it uses LinkingTo: and calls R_GetCCallable to obtain the function pointer. It does not actually link to package A because that is in general not possible - it simply obtains the pointers through R. In addition, LinkingTo: makes sure that you have access to the header files of package A which help you to cast the functions and define any data structures you may need. Since C++ is a superset of C you can use this facility with C++ as long as you don't depend on anything outside of the header files.
>
> 2) linking directly to another package's shared object is in general not possible, because packages are not guaranteed to be dynamic libraries. They are usually shared objects which may or may not be compatible with a dynamic library on a given platform. Therefore the R-ext describes other way in which you may provide some library independently of the package shared object to other packages (see R-ext 5.8). The issue is that you have to create a separate library (PKG/libs[/arch]/PKG.so won't work in general!) and provide this to other packages. As 5.8 says, this is in general not trivial because it is very platform dependent and the most portable way is to offer a static library.
>
> To come back to your example, LinkingTo: A and B will work if you remove Makevars from B (you don't want to link)and put your hello method into the A.h header:

Sure. but in real life I can't realistically put everything in the 
header files.

Thanks again.

Romain

>> library (B)
> Loading required package: A
>> .Call("say_hello", PACKAGE = "B")
> [1] "hello"
>
> However, your'e not really using the LinkingTo: facilities for the functions so it's essentially just helping you to find the header file.
>
> Cheers,
> Simon
>
>
>
> On Feb 11, 2010, at 4:08 AM, Romain Francois wrote:
>
>> Hello,
>>
>> I've been trying to make LinkingTo work when the package linked to has c++ code.
>>
>> I've put dumb packages to illustrate this emails here ; http://addictedtor.free.fr/misc/linkingto
>>
>> Package A defines this C++ class:
>>
>> class A {
>> public:
>> 	A() ;
>> 	~A() ;
>> 	SEXP hello() ;
>> } ;
>>
>> Package B has this function :
>>
>> SEXP say_hello(){
>> 	A a ;
>> 	return a.hello() ;
>> }
>>
>> headers of package A are copied into inst/include so that package B can have.
>>
>> LinkingTo: A
>>
>> in its DESCRIPTION file.
>>
>> Also, package B has the R function ;
>>
>> g<- function(){
>> 	.Call("say_hello", PACKAGE = "B")
>> }
>>
>> With this I can compile A and B, but then I get :
>>
>> $ Rscript -e "B::g()"
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>   unable to load shared library '/usr/local/lib/R/library/B/libs/B.so':
>>   /usr/local/lib/R/library/B/libs/B.so: undefined symbol: _ZN1AD1Ev
>> Calls: :: ... tryCatch ->  tryCatchList ->  tryCatchOne ->  <Anonymous>
>>
>> If I then add a Makevars in B with this :
>>
>>
>> # find the root directory where A is installed
>> ADIR=$(shell $(R_HOME)/bin/Rscript -e "cat(system.file(package='A'))" )
>>
>> PKG_LIBS= $(ADIR)/libs/A$(DYLIB_EXT)
>>
>>
>> Then it works:
>>
>> $ Rscript -e "B::g()"
>> [1] "hello"
>>
>> So it appears that adding the -I flag, which is what LinkingTo does is not enough when the package "linking from" (B) actually has to link to the "linked to" package (A).
>>
>> I've been looking at http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines but it seems only applicable to c(++) functions and not classes ...
>>
>> What am I missing ? Should/can linkingto be extended in a way that accomodates c++
>>
>> Romain



-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/NrTG : Rcpp 0.7.5
|- http://tr.im/MPYc : RProtoBuf: protocol buffers for R
`- http://tr.im/KfKn : Rcpp 0.7.2


From taylor.russ at gmail.com  Thu Feb 11 18:43:27 2010
From: taylor.russ at gmail.com (rt)
Date: Thu, 11 Feb 2010 11:43:27 -0600
Subject: [Rd] Compiling R projects with multiple external libraries
Message-ID: <d6243f3f1002110943i15cdc165y6214b4ecf28a09@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100211/f379c45f/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Feb 11 19:05:10 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Feb 2010 18:05:10 +0000 (GMT)
Subject: [Rd] R crashes when setWinProgressBar is give a numeric value
 for label argument
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F9A05A77@LP-EXMBVS10.CO.IHC.COM>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F9A05A77@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.00.1002111755080.8747@gannet.stats.ox.ac.uk>

Greg,

winProgressBar() has internal checks for the argument types, and for 
some unaccounted-for reason I omitted them in setWinProgressBar().  So 
2) is easy (cut-and-paste).

I am less sure that we should add coercion, and sure that if we add it 
to setWinProgressBar() we should also add it to winProgressBar().  But 
as you suggested it, I've done so.

Thanks for the report.

Brian Ripely

On Wed, 10 Feb 2010, Greg Snow wrote:

> This problem can be seen by the following commands:
>
>> pb <- winProgressBar(max=1000, label='0')
>> b <- 1
>> setWinProgressBar(pb, b, label=b)
>
> This set of commands (on windows of course, XP in this case) causes R to crash.
>
> This is not strictly a bug since the documentation states that the label argument should be a character string and using as.character(b) does work properly.  But when I (and possibly others) forget this and use something like the above, having the whole R process crash seems a bit extreme.
>
> Possible responses:
>
> 1. ignore this and hope that after being punished for not remembering the correct syntax enough times I will eventually learn to do the correct thing.
>
> 2. add a check and generate an error if title or lab is not a character string (less severe punishment, I may learn eventually, but maybe not as quick).
>
> 3. add label <- as.character(label) and same idea for title, so that the above code works without the user needing to remember the as.character.  This may need a check for NULL values as well.
>
> 4.  Something else that I have not thought of.
>
> Number 1 would be easiest for R core, hardest on me.  Numbers 2 and 3 have the potential drawback of slowing things down slightly.
>
> My sessionInfo()
>
>> sessionInfo()
> R version 2.10.1 Patched (2010-02-08 r51108)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.10.1
>>
>
> Same thing happens in non-patched 2.10.1
>
> Thanks,
>
>
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Greg.Snow at imail.org  Thu Feb 11 19:30:54 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 11 Feb 2010 11:30:54 -0700
Subject: [Rd] R crashes when setWinProgressBar is give a numeric value
 for label argument
In-Reply-To: <alpine.LFD.2.00.1002111755080.8747@gannet.stats.ox.ac.uk>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F9A05A77@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.00.1002111755080.8747@gannet.stats.ox.ac.uk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F9A05EA3@LP-EXMBVS10.CO.IHC.COM>

Thanks,

I would be happy with an error that did not crash R, coercion just makes life a little easier, but I can live without that if you are not sure or there are reasons not to (speed being on possibility).

It looks like you just underestimated how stupid I could be.

Thanks,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, February 11, 2010 11:05 AM
> To: Greg Snow
> Cc: r-devel
> Subject: Re: [Rd] R crashes when setWinProgressBar is give a numeric
> value for label argument
> 
> Greg,
> 
> winProgressBar() has internal checks for the argument types, and for
> some unaccounted-for reason I omitted them in setWinProgressBar().  So
> 2) is easy (cut-and-paste).
> 
> I am less sure that we should add coercion, and sure that if we add it
> to setWinProgressBar() we should also add it to winProgressBar().  But
> as you suggested it, I've done so.
> 
> Thanks for the report.
> 
> Brian Ripely
> 
> On Wed, 10 Feb 2010, Greg Snow wrote:
> 
> > This problem can be seen by the following commands:
> >
> >> pb <- winProgressBar(max=1000, label='0')
> >> b <- 1
> >> setWinProgressBar(pb, b, label=b)
> >
> > This set of commands (on windows of course, XP in this case) causes R
> to crash.
> >
> > This is not strictly a bug since the documentation states that the
> label argument should be a character string and using as.character(b)
> does work properly.  But when I (and possibly others) forget this and
> use something like the above, having the whole R process crash seems a
> bit extreme.
> >
> > Possible responses:
> >
> > 1. ignore this and hope that after being punished for not remembering
> the correct syntax enough times I will eventually learn to do the
> correct thing.
> >
> > 2. add a check and generate an error if title or lab is not a
> character string (less severe punishment, I may learn eventually, but
> maybe not as quick).
> >
> > 3. add label <- as.character(label) and same idea for title, so that
> the above code works without the user needing to remember the
> as.character.  This may need a check for NULL values as well.
> >
> > 4.  Something else that I have not thought of.
> >
> > Number 1 would be easiest for R core, hardest on me.  Numbers 2 and 3
> have the potential drawback of slowing things down slightly.
> >
> > My sessionInfo()
> >
> >> sessionInfo()
> > R version 2.10.1 Patched (2010-02-08 r51108)
> > i386-pc-mingw32
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_2.10.1
> >>
> >
> > Same thing happens in non-patched 2.10.1
> >
> > Thanks,
> >
> >
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at imail.org
> > 801.408.8111
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Thu Feb 11 19:40:41 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 11 Feb 2010 13:40:41 -0500
Subject: [Rd] LinkingTo and C++
In-Reply-To: <4B743D4F.3090102@r-enthusiasts.com>
References: <4B73C916.4090705@r-enthusiasts.com>
	<01F75CF2-FA06-420B-A4DD-6776197B1E2B@r-project.org>
	<4B743D4F.3090102@r-enthusiasts.com>
Message-ID: <8FD42196-4CD7-4114-BF13-473C8FE06062@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100211/4d5bd4c1/attachment.pl>

From romain at r-enthusiasts.com  Thu Feb 11 20:55:02 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Thu, 11 Feb 2010 20:55:02 +0100
Subject: [Rd] LinkingTo and C++
In-Reply-To: <8FD42196-4CD7-4114-BF13-473C8FE06062@r-project.org>
References: <4B73C916.4090705@r-enthusiasts.com>	<01F75CF2-FA06-420B-A4DD-6776197B1E2B@r-project.org>	<4B743D4F.3090102@r-enthusiasts.com>
	<8FD42196-4CD7-4114-BF13-473C8FE06062@r-project.org>
Message-ID: <4B746096.1030604@r-enthusiasts.com>

On 02/11/2010 07:40 PM, Simon Urbanek wrote:
>
>
> On Feb 11, 2010, at 12:24 PM, Romain Francois wrote:
>
>> Thanks.
>>
>> On 02/11/2010 05:55 PM, Simon Urbanek wrote:
>>> Romain,
>>>
>>> I think your'e confusing two entirely different concepts here:
>>
>> Yes. The name "LinkingTo" probably helped my confusion.
>>
>
> Admittedly, it's probably not the best name ;).
>
>
>>> 1) LinkingTo: allows a package to provide C-level functions to other packages (see R-ext 5.4). Let's say package A provides a function foo by calling R_RegisterCCallable for that function. If a package B wants to use that function, it uses LinkingTo: and calls R_GetCCallable to obtain the function pointer. It does not actually link to package A because that is in general not possible - it simply obtains the pointers through R. In addition, LinkingTo: makes sure that you have access to the header files of package A which help you to cast the functions and define any data structures you may need. Since C++ is a superset of C you can use this facility with C++ as long as you don't depend on anything outside of the header files.
>>>
>>> 2) linking directly to another package's shared object is in general not possible, because packages are not guaranteed to be dynamic libraries. They are usually shared objects which may or may not be compatible with a dynamic library on a given platform. Therefore the R-ext describes other way in which you may provide some library independently of the package shared object to other packages (see R-ext 5.8). The issue is that you have to create a separate library (PKG/libs[/arch]/PKG.so won't work in general!) and provide this to other packages. As 5.8 says, this is in general not trivial because it is very platform dependent and the most portable way is to offer a static library.
>>>
>>> To come back to your example, LinkingTo: A and B will work if you remove Makevars from B (you don't want to link)and put your hello method into the A.h header:
>>
>> Sure. but in real life I can't realistically put everything in the header files.
>>
>
> It was just an example based on your example ;) - which was not very realistic, either. It practice it is reasonable, because it is sufficient to declare in the headers whatever you're providing so the only homework is to cast function pointers you have obtained via R_GetCCallable to the declarations from the header file.
>
> I suspect what you meant is not as much related to LinkingTo: (since the mess C++ creates at the binary level is rather hard to pass through dl pointers - but if someone has a working solution it may be worth to create a package), but rather to provide a library. That is not covered by R at this point so you're in realm of R-ext 5.8. Given how non-trivial task this is (to get it right) it may be worthwhile thinking about a portable solution and add it to R, but I don't think anyone has done that yet (mainly due to the low benefit/cost ratio I suspect). For all cases so far it was sufficient to create C or R level API for other package to use.
>
> Cheers,
> Simon

Yes. The goal is to provide a library that other packages can just use. 
I thought LinkingTo would help, but now I guess not. or maybe just so 
that B can find headers of A.

The R_RegisterCCallable/R_GetCCallable business seems to be only 
applicable when you are developping both A and B and you deal with plain 
functions, otherwise the name mangling, overloading of methods, etc 
would make the task hard and not fun at all.

So I guess, yes the question is how to reliably and portably provide a 
library for package A so that package B can just use it. This would be 
very valuable.

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/NrTG : Rcpp 0.7.5
|- http://tr.im/MPYc : RProtoBuf: protocol buffers for R
`- http://tr.im/KfKn : Rcpp 0.7.2


From seth at userprimary.net  Thu Feb 11 23:52:39 2010
From: seth at userprimary.net (Seth Falcon)
Date: Thu, 11 Feb 2010 14:52:39 -0800
Subject: [Rd] Compiling R projects with multiple external libraries
In-Reply-To: <d6243f3f1002110943i15cdc165y6214b4ecf28a09@mail.gmail.com>
References: <d6243f3f1002110943i15cdc165y6214b4ecf28a09@mail.gmail.com>
Message-ID: <4B748A37.8080104@userprimary.net>

On 2/11/10 9:43 AM, rt wrote:
> Hi,
>
> I have just learned how to use compile and link libraries using
> "make" and how to create R projects using R CMD build or INSTALL.  My
> understanding of both is somewhat limited and hence the question.
>
> I have a main library written in c which depends on other external
> libraries. Main library is to be called from R using .Call. The goal
> is to create a single R project that will compile all the external
> libraries, the main library, R-C wrappers and install it. I am unsure
> about the proper structure of R project directories and the general
> workflow such that: (a) external libraries and the main libraries are
> built first using "make" that I already have (b) R-C Wrapper is
> compiled and installed using R CMD install.
>
> I understand that there are issues using Makefiles and that there
> are preferred ways of doing these things. I am not sure how to use
> Makevars instead of Makefile for this purpose. Any help and in
> particular pointers to examples of R packages with multiple external
> libraries would be appreciated.

"1.2.1 Using Makevars" in WRE (R-ext manual)  has some detail on this 
and suggests looking at fastICA for an example.

Quote from manual:

> If you want to create and then link to a library, say using code in a
> subdirectory, use something like
>
> .PHONY: all mylibs
>
> all: $(SHLIB) $(SHLIB): mylibs
>
> mylibs: (cd subdir; make)



+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/user


From maiagx at gmail.com  Fri Feb 12 04:59:58 2010
From: maiagx at gmail.com (Charlotte Maia)
Date: Fri, 12 Feb 2010 16:59:58 +1300
Subject: [Rd] Darwinian software development and the library function
Message-ID: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>

Hi all,

Legend has it, that polite R programmers don't overwrite, say, the
print function.
However, this seems quite un-Darwinian to me (especially given that I
don't want to call all my arguments x and y).
I might want a function print.foo (myfoo, ...).

So I decided to be very impolite (in one of my packages) and overwrite
a few standard generics.
Plus, to the best of my knowledge it doesn't interfere with normal use (yay...).

This brings us to the library function.
Which by default gives a whole lot of warnings loading my package (and
any other package that does something similar), scaring off polite R
programmers and perhaps some mainstream R users.

I'm starting to think that the default for library, should be
warn.conflicts=FALSE.
However, just reading the documentation, I noticed a reference to
something called .conflicts.OK.
Not sure what that does, however if it does what it sounds like, then
it largely fixes the problem.

The biggest issue though, is whether or not one should be impolite
(i.e. Darwinian) and overwrite print etc in the first place...?

I'm inclined to go in favour of overwriting the functions.
However, it has the potential to introduce some technical problems.

Other's opinions appreciated.


kind regards
-- 
Charlotte Maia
http://sites.google.com/site/maiagx


From bluesky315 at gmail.com  Fri Feb 12 06:35:03 2010
From: bluesky315 at gmail.com (blue sky)
Date: Thu, 11 Feb 2010 23:35:03 -0600
Subject: [Rd] filenames with special characters in the R/ directory of a
	package?
Message-ID: <48413fa11002112135mca8d75dq856ed81545463094@mail.gmail.com>

According to R-exts.pdf (page 3):
For maximal portability filenames should only
contain only ASCII characters not excluded already (that is
A-Za-z0-9._!#$%&+,;=@^(){}?[]

I have some files with special characters like '[' and '%' e.g.
'[.set.R'. I also have some functions that also have those special
characters defined in those files exported in NAMESPACE.

I use the following command to install. And I get no warning or errors.

R CMD INSTALL -d -l my_custom_dir my.pkg

I then load the package. I get the following errors and warnings. I
changed a file to one without these special characters. Then the
corresponding warning/error disappears. Is it the case that there
should never be files with special characters as names?

> library(my.pkg)
Error in namespaceExport(ns, exports) :
 undefined exports: %is%
In addition: Warning message:
S3 methods ?[.set? were declared in NAMESPACE but not found
Error: package/namespace load failed for 'my.pkg'


From b.rowlingson at lancaster.ac.uk  Fri Feb 12 09:36:39 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Feb 2010 08:36:39 +0000
Subject: [Rd] filenames with special characters in the R/ directory of a
	package?
In-Reply-To: <48413fa11002112135mca8d75dq856ed81545463094@mail.gmail.com>
References: <48413fa11002112135mca8d75dq856ed81545463094@mail.gmail.com>
Message-ID: <d8ad40b51002120036h6e86fdf3x881090848b92f6f4@mail.gmail.com>

On Fri, Feb 12, 2010 at 5:35 AM, blue sky <bluesky315 at gmail.com> wrote:
> According to R-exts.pdf (page 3):
> For maximal portability filenames should only
> contain only ASCII characters not excluded already (that is
> A-Za-z0-9._!#$%&+,;=@^(){}?[]
>
> I have some files with special characters like '[' and '%' e.g.
> '[.set.R'.

That character list in your extract from R-exts.pdf is a list of
non-special characters. And [ and % are in there.

 It's clarification of three sentences previous, which says:

"the characters ?"?, ?*?, ?:?, ?/?, ?<?, ?>?, ???, ?\?, and ?|? are
not allowed in file names"

> I also have some functions that also have those special
> characters defined in those files exported in NAMESPACE.
>
> I use the following command to install. And I get no warning or errors.
>
> R CMD INSTALL -d -l my_custom_dir my.pkg
>
> I then load the package. I get the following errors and warnings. I
> changed a file to one without these special characters. Then the
> corresponding warning/error disappears. Is it the case that there
> should never be files with special characters as names?
>
>> library(my.pkg)
> Error in namespaceExport(ns, exports) :
> ?undefined exports: %is%
> In addition: Warning message:
> S3 methods ?[.set? were declared in NAMESPACE but not found
> Error: package/namespace load failed for 'my.pkg'

 Have you done an R CMD check on your package? I suspect a problem in
your NAMESPACE file, but it's not related to "special characters".

Barry


From b.rowlingson at lancaster.ac.uk  Fri Feb 12 09:50:26 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Feb 2010 08:50:26 +0000
Subject: [Rd] R Startup configuration file
In-Reply-To: <d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
Message-ID: <d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>

On Wed, Feb 10, 2010 at 3:06 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:

> ?But I agree that writing a saveable options package is the first step
> - then making that a default in R is the second so people don't have
> to edit profiles and R packages and applications can expect an API for
> savable state.

 More thinking about this has turned it into a problem of being able
to serialize R objects to XML. The most reliable way I can find of
doing that is to use serialize, then rawToChar, and put a big old hex
string in the XML. Hardly the most user-friendly format, but then
users aren't supposed to edit XML anyway. I have also considered
having encoding types for objects, something like:

<object encoding="raw" name="foo">66f6e.....a7726</object>
<object encoding="numeric" name="bar">3.141</object>
<object encoding="numeric" size="2"
name="baz"><item>3.14</item><item>6.28</item></object>

at which point I remembered that R objects can also have attributes
which can be any other R objects too. At which point I realized life's
too short for this...

..and had a rethink. Lots of software these days has a configuration
directory, and runs all the scripts or configs within - think
/etc/cron.daily/ or /etc/init.d on a unix system. This has the
advantage that components of the system can manage their own startup
files there, and not worry about stomping on others. So you'd have a
.Rprofile.d/ folder with, say, a cran.R file that could be sourced by
anything that used CRAN, for example to set the default mirror. I'd
insist that each file in .Rprofile.d/ started with a "# do not edit
this file" warning...

 I'll think some more over coffee until I realise why this is another
of my dumb ideas...

Barry


From murdoch at stats.uwo.ca  Fri Feb 12 12:01:59 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 12 Feb 2010 06:01:59 -0500
Subject: [Rd] R Startup configuration file
In-Reply-To: <d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>	
	<4B729C0F.3030301@stats.uwo.ca>	
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
Message-ID: <4B753527.7060709@stats.uwo.ca>

On 12/02/2010 3:50 AM, Barry Rowlingson wrote:
> On Wed, Feb 10, 2010 at 3:06 PM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
> 
>>  But I agree that writing a saveable options package is the first step
>> - then making that a default in R is the second so people don't have
>> to edit profiles and R packages and applications can expect an API for
>> savable state.
> 
>  More thinking about this has turned it into a problem of being able
> to serialize R objects to XML. The most reliable way I can find of
> doing that is to use serialize, then rawToChar, and put a big old hex
> string in the XML. Hardly the most user-friendly format, but then
> users aren't supposed to edit XML anyway. I have also considered
> having encoding types for objects, something like:
> 
> <object encoding="raw" name="foo">66f6e.....a7726</object>
> <object encoding="numeric" name="bar">3.141</object>
> <object encoding="numeric" size="2"
> name="baz"><item>3.14</item><item>6.28</item></object>

If you're storing hex, why not just use the binary save() format? (Or 
the save(ascii=TRUE) format.)  What is the advantage of XML?

> at which point I remembered that R objects can also have attributes
> which can be any other R objects too. At which point I realized life's
> too short for this...
> 
> ..and had a rethink. Lots of software these days has a configuration
> directory, and runs all the scripts or configs within - think
> /etc/cron.daily/ or /etc/init.d on a unix system. This has the
> advantage that components of the system can manage their own startup
> files there, and not worry about stomping on others. So you'd have a
> .Rprofile.d/ folder with, say, a cran.R file that could be sourced by
> anything that used CRAN, for example to set the default mirror. I'd
> insist that each file in .Rprofile.d/ started with a "# do not edit
> this file" warning...
> 
>  I'll think some more over coffee until I realise why this is another
> of my dumb ideas...

I see two ways such a thing might be used: everything run at startup, or 
just running things as needed.  Running everything at startup has the 
disadvantage that it requires all sorts of diverse packages to be 
loaded, so running things as needed makes more sense.  But do you really 
want to make it so granular that it depends on the kind of task 
(accessing CRAN, ...)?  Wouldn't it be good enough to have one user init 
file per package, and have it executed when the package is loaded?

Duncan


From ripley at stats.ox.ac.uk  Fri Feb 12 12:10:54 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Feb 2010 11:10:54 +0000 (GMT)
Subject: [Rd] filenames with special characters in the R/ directory of a
 package?
In-Reply-To: <d8ad40b51002120036h6e86fdf3x881090848b92f6f4@mail.gmail.com>
References: <48413fa11002112135mca8d75dq856ed81545463094@mail.gmail.com>
	<d8ad40b51002120036h6e86fdf3x881090848b92f6f4@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1002121101380.18946@localhost>

'Writing R Extensions' does say what names are allowed in the R 
directory (at the start of section 1.1.3 in section-numbered formats). 
To wit

   The R subdirectory contains R code files, only. The code files to be
   installed must start with an ASCII (lower or upper case) letter or
   digit and have one of the extensions .R, .S, .q, .r, or .s.

'[.set.R' does not meet that rule, and so is skipped.  This is not 
something R CMD check reports, since the wording implies that other 
names can be used for files to be not installed.


On Fri, 12 Feb 2010, Barry Rowlingson wrote:

> On Fri, Feb 12, 2010 at 5:35 AM, blue sky <bluesky315 at gmail.com> wrote:
>> According to R-exts.pdf (page 3):
>> For maximal portability filenames should only
>> contain only ASCII characters not excluded already (that is
>> A-Za-z0-9._!#$%&+,;=@^(){}?[]
>>
>> I have some files with special characters like '[' and '%' e.g.
>> '[.set.R'.
>
> That character list in your extract from R-exts.pdf is a list of
> non-special characters. And [ and % are in there.
>
> It's clarification of three sentences previous, which says:
>
> "the characters ?"?, ?*?, ?:?, ?/?, ?<?, ?>?, ???, ?\?, and ?|? are
> not allowed in file names"
>
>> I also have some functions that also have those special
>> characters defined in those files exported in NAMESPACE.
>>
>> I use the following command to install. And I get no warning or errors.
>>
>> R CMD INSTALL -d -l my_custom_dir my.pkg
>>
>> I then load the package. I get the following errors and warnings. I
>> changed a file to one without these special characters. Then the
>> corresponding warning/error disappears. Is it the case that there
>> should never be files with special characters as names?
>>
>>> library(my.pkg)
>> Error in namespaceExport(ns, exports) :
>> ?undefined exports: %is%
>> In addition: Warning message:
>> S3 methods ?[.set? were declared in NAMESPACE but not found
>> Error: package/namespace load failed for 'my.pkg'
>
> Have you done an R CMD check on your package? I suspect a problem in
> your NAMESPACE file, but it's not related to "special characters".
>
> Barry
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From simon.urbanek at r-project.org  Fri Feb 12 15:22:53 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 12 Feb 2010 09:22:53 -0500
Subject: [Rd] R Startup configuration file
In-Reply-To: <d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
Message-ID: <0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>


On Feb 12, 2010, at 3:50 , Barry Rowlingson wrote:

> On Wed, Feb 10, 2010 at 3:06 PM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
>
>>  But I agree that writing a saveable options package is the first  
>> step
>> - then making that a default in R is the second so people don't have
>> to edit profiles and R packages and applications can expect an API  
>> for
>> savable state.
>
> More thinking about this has turned it into a problem of being able
> to serialize R objects to XML.


This is getting OT, but, please, no XML. It's entirely useless in this  
context IMHO (as it is in others, but that's another story) and we  
already have reliable support for storing R objects (more than one in  
fact). Despite the fact that some used to claim human readability of  
XML in practice it turns out to be false, so I don't see any real  
benefits of XML in this context.

Cheers,
Simon



> The most reliable way I can find of
> doing that is to use serialize, then rawToChar, and put a big old hex
> string in the XML. Hardly the most user-friendly format, but then
> users aren't supposed to edit XML anyway. I have also considered
> having encoding types for objects, something like:
>
> <object encoding="raw" name="foo">66f6e.....a7726</object>
> <object encoding="numeric" name="bar">3.141</object>
> <object encoding="numeric" size="2"
> name="baz"><item>3.14</item><item>6.28</item></object>
>
> at which point I remembered that R objects can also have attributes
> which can be any other R objects too. At which point I realized life's
> too short for this...
>
> ..and had a rethink. Lots of software these days has a configuration
> directory, and runs all the scripts or configs within - think
> /etc/cron.daily/ or /etc/init.d on a unix system. This has the
> advantage that components of the system can manage their own startup
> files there, and not worry about stomping on others. So you'd have a
> .Rprofile.d/ folder with, say, a cran.R file that could be sourced by
> anything that used CRAN, for example to set the default mirror. I'd
> insist that each file in .Rprofile.d/ started with a "# do not edit
> this file" warning...
>
> I'll think some more over coffee until I realise why this is another
> of my dumb ideas...
>
> Barry
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From bluesky315 at gmail.com  Fri Feb 12 16:23:05 2010
From: bluesky315 at gmail.com (blue sky)
Date: Fri, 12 Feb 2010 09:23:05 -0600
Subject: [Rd] filenames with special characters in the R/ directory of a
	package?
In-Reply-To: <alpine.LFD.2.00.1002121101380.18946@localhost>
References: <48413fa11002112135mca8d75dq856ed81545463094@mail.gmail.com>
	<d8ad40b51002120036h6e86fdf3x881090848b92f6f4@mail.gmail.com>
	<alpine.LFD.2.00.1002121101380.18946@localhost>
Message-ID: <48413fa11002120723s4a92276cy85409308122bc41e@mail.gmail.com>

It is strange to me why the filename must start with a letter or
digit, while the following characters can be something like '['. Is
there a reason why it is designed in this way? So that I can
understand the design principle rather than memorizing the facts
derived from the principle.

On Fri, Feb 12, 2010 at 5:10 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> 'Writing R Extensions' does say what names are allowed in the R directory
> (at the start of section 1.1.3 in section-numbered formats). To wit
>
> ?The R subdirectory contains R code files, only. The code files to be
> ?installed must start with an ASCII (lower or upper case) letter or
> ?digit and have one of the extensions .R, .S, .q, .r, or .s.
>
> '[.set.R' does not meet that rule, and so is skipped. ?This is not something
> R CMD check reports, since the wording implies that other names can be used
> for files to be not installed.
>
>
> On Fri, 12 Feb 2010, Barry Rowlingson wrote:
>
>> On Fri, Feb 12, 2010 at 5:35 AM, blue sky <bluesky315 at gmail.com> wrote:
>>>
>>> According to R-exts.pdf (page 3):
>>> For maximal portability filenames should only
>>> contain only ASCII characters not excluded already (that is
>>> A-Za-z0-9._!#$%&+,;=@^(){}?[]
>>>
>>> I have some files with special characters like '[' and '%' e.g.
>>> '[.set.R'.
>>
>> That character list in your extract from R-exts.pdf is a list of
>> non-special characters. And [ and % are in there.
>>
>> It's clarification of three sentences previous, which says:
>>
>> "the characters ?"?, ?*?, ?:?, ?/?, ?<?, ?>?, ???, ?\?, and ?|? are
>> not allowed in file names"
>>
>>> I also have some functions that also have those special
>>> characters defined in those files exported in NAMESPACE.
>>>
>>> I use the following command to install. And I get no warning or errors.
>>>
>>> R CMD INSTALL -d -l my_custom_dir my.pkg
>>>
>>> I then load the package. I get the following errors and warnings. I
>>> changed a file to one without these special characters. Then the
>>> corresponding warning/error disappears. Is it the case that there
>>> should never be files with special characters as names?
>>>
>>>> library(my.pkg)
>>>
>>> Error in namespaceExport(ns, exports) :
>>> ?undefined exports: %is%
>>> In addition: Warning message:
>>> S3 methods ?[.set? were declared in NAMESPACE but not found
>>> Error: package/namespace load failed for 'my.pkg'
>>
>> Have you done an R CMD check on your package? I suspect a problem in
>> your NAMESPACE file, but it's not related to "special characters".
>>
>> Barry
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From hb at stat.berkeley.edu  Fri Feb 12 16:27:35 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 12 Feb 2010 16:27:35 +0100
Subject: [Rd] R Startup configuration file
In-Reply-To: <0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
	<0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
Message-ID: <59d7961d1002120727w281c1038jcfd69711f89b18e1@mail.gmail.com>

FYI,

a while ago I was looking into the "problem" with generic settings
files.  I didn't find an omnibus/perfect solution, but have a look at
the Settings class in the R.utils package (R/Settings.R in the source
code).  It tries to deal with automatic loading and saving of settings
(robust detection of the quiting of an R session etc), finding the
settings file and so.  You can use this to load package specific
settings as well.  (We make use of this in the aroma.* framework
(aroma.core, aroma.affymetrix etc), but I'll leave there for now).

My $.02

/Henrik

On Fri, Feb 12, 2010 at 3:22 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Feb 12, 2010, at 3:50 , Barry Rowlingson wrote:
>
>> On Wed, Feb 10, 2010 at 3:06 PM, Barry Rowlingson
>> <b.rowlingson at lancaster.ac.uk> wrote:
>>
>>> ?But I agree that writing a saveable options package is the first step
>>> - then making that a default in R is the second so people don't have
>>> to edit profiles and R packages and applications can expect an API for
>>> savable state.
>>
>> More thinking about this has turned it into a problem of being able
>> to serialize R objects to XML.
>
>
> This is getting OT, but, please, no XML. It's entirely useless in this
> context IMHO (as it is in others, but that's another story) and we already
> have reliable support for storing R objects (more than one in fact). Despite
> the fact that some used to claim human readability of XML in practice it
> turns out to be false, so I don't see any real benefits of XML in this
> context.
>
> Cheers,
> Simon
>
>
>
>> The most reliable way I can find of
>> doing that is to use serialize, then rawToChar, and put a big old hex
>> string in the XML. Hardly the most user-friendly format, but then
>> users aren't supposed to edit XML anyway. I have also considered
>> having encoding types for objects, something like:
>>
>> <object encoding="raw" name="foo">66f6e.....a7726</object>
>> <object encoding="numeric" name="bar">3.141</object>
>> <object encoding="numeric" size="2"
>> name="baz"><item>3.14</item><item>6.28</item></object>
>>
>> at which point I remembered that R objects can also have attributes
>> which can be any other R objects too. At which point I realized life's
>> too short for this...
>>
>> ..and had a rethink. Lots of software these days has a configuration
>> directory, and runs all the scripts or configs within - think
>> /etc/cron.daily/ or /etc/init.d on a unix system. This has the
>> advantage that components of the system can manage their own startup
>> files there, and not worry about stomping on others. So you'd have a
>> .Rprofile.d/ folder with, say, a cran.R file that could be sourced by
>> anything that used CRAN, for example to set the default mirror. I'd
>> insist that each file in .Rprofile.d/ started with a "# do not edit
>> this file" warning...
>>
>> I'll think some more over coffee until I realise why this is another
>> of my dumb ideas...
>>
>> Barry
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Fri Feb 12 16:29:18 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 12 Feb 2010 09:29:18 -0600
Subject: [Rd] R Startup configuration file
In-Reply-To: <0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
	<0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
Message-ID: <19317.29646.287419.953996@ron.nulle.part>


On 12 February 2010 at 09:22, Simon Urbanek wrote:
| On Feb 12, 2010, at 3:50 , Barry Rowlingson wrote:
| 
| > On Wed, Feb 10, 2010 at 3:06 PM, Barry Rowlingson
| > <b.rowlingson at lancaster.ac.uk> wrote:
| >
| >>  But I agree that writing a saveable options package is the first  
| >> step
| >> - then making that a default in R is the second so people don't have
| >> to edit profiles and R packages and applications can expect an API  
| >> for
| >> savable state.
| >
| > More thinking about this has turned it into a problem of being able
| > to serialize R objects to XML.
| 
| 
| This is getting OT, but, please, no XML. It's entirely useless in this  
| context IMHO (as it is in others, but that's another story) and we  
| already have reliable support for storing R objects (more than one in  
| fact). Despite the fact that some used to claim human readability of  
| XML in practice it turns out to be false, so I don't see any real  
| benefits of XML in this context.

Fully agreed.

OTOH I had the same idea as Barry the other day about maybe making files like
$R_HOME/profile.site 'walk' over a directory, say, $R_HOME/profile.site.d/ so
that users could drop files there and upon installation and re-installation
those user-contributed snippets would just survive.  This foo.d/ directory
scheme is getting more and more common in Unix/Linux land as Barry noted.

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From b.rowlingson at lancaster.ac.uk  Fri Feb 12 16:33:18 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Feb 2010 15:33:18 +0000
Subject: [Rd] R Startup configuration file
In-Reply-To: <0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>
	<4B729C0F.3030301@stats.uwo.ca>
	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>
	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>
	<0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
Message-ID: <d8ad40b51002120733n623f55abo310d04b7eec6d500@mail.gmail.com>

On Fri, Feb 12, 2010 at 2:22 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:

> This is getting OT, but, please, no XML. It's entirely useless in this
> context IMHO (as it is in others, but that's another story) and we already
> have reliable support for storing R objects (more than one in fact). Despite
> the fact that some used to claim human readability of XML in practice it
> turns out to be false, so I don't see any real benefits of XML in this
> context.

 Yes, I agree. Originally I was hoping to have a nice
human-and-computer readable config.ini file:

[options]
contrasts = structure(list(contrasts = structure(c("contr.treatment",
"contr.poly"
), .Names = c("unordered", "ordered"))), .Names = "contrasts")

but the lack of an ini parser in R made me think "heck, let's do it in
something we do have a parser for...".

maybe I should use JSON? Yeah, we have a parser and that's what all
the hipster web 3.0 kids are using these days....

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From spencer.graves at prodsyse.com  Fri Feb 12 16:41:03 2010
From: spencer.graves at prodsyse.com (spencerg)
Date: Fri, 12 Feb 2010 07:41:03 -0800
Subject: [Rd] Darwinian software development and the library function
In-Reply-To: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>
References: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>
Message-ID: <4B75768F.8020904@prodsyse.com>

Hi, Charlotte: 


      I'm not sure what you mean.  If you mean writing something like 
"print.foo (myfoo, ...)", this is relatively benign I suppose, but I 
avoid it where feasible.  On multiple occasions, I've pushed 
collaborators and even maintainers of other packages to change this or 
allow me to change it to conform to the standard;  if my memory is 
correct, there have been several violations of this standard in the 
"fda" package, which are no longer there because I changed them.  If a 
user with an object "x" of class "foo" writes print(x=x) or 
print(foo=x), I'm not sure what it would do, but it might not be what 
you want. 


      My "sos" package masks "?".  However, I don't like it.  I 
generally consider such to be potentially user hostile, and whenever 
feasible, I prefer to avoid such code.  I did it in this case for a 
couple of reasons.  First, using "?" (actually "???") seems so much 
easier to remember than "findFn" that it justifies this transgression of 
standard protocol.  Second, one of the leading figures in the R 
community (Duncan Murdoch) contributed suggested we do this and 
contributed the code. 


      If you change the definition of "print" itself, that seems to me 
to be a much bigger issue, with consequences much more difficult to 
predict.  If someone else also overwrites "print" making it different 
and incompatible with yours, then your code may not work or theirs may 
not, depending on which gets loaded first in the search path.  Worse, 
your code cannot possibly have been tested as thoroughly as the standard 
code.  If your code includes a subtle bug that only occurs under special 
circumstances, it may be hard for the person experiencing the problem to 
find, because they don't expect it. 


      Hope this helps.
      Spencer


Charlotte Maia wrote:
> Hi all,
>
> Legend has it, that polite R programmers don't overwrite, say, the
> print function.
> However, this seems quite un-Darwinian to me (especially given that I
> don't want to call all my arguments x and y).
> I might want a function print.foo (myfoo, ...).
>
> So I decided to be very impolite (in one of my packages) and overwrite
> a few standard generics.
> Plus, to the best of my knowledge it doesn't interfere with normal use (yay...).
>
> This brings us to the library function.
> Which by default gives a whole lot of warnings loading my package (and
> any other package that does something similar), scaring off polite R
> programmers and perhaps some mainstream R users.
>
> I'm starting to think that the default for library, should be
> warn.conflicts=FALSE.
> However, just reading the documentation, I noticed a reference to
> something called .conflicts.OK.
> Not sure what that does, however if it does what it sounds like, then
> it largely fixes the problem.
>
> The biggest issue though, is whether or not one should be impolite
> (i.e. Darwinian) and overwrite print etc in the first place...?
>
> I'm inclined to go in favour of overwriting the functions.
> However, it has the potential to introduce some technical problems.
>
> Other's opinions appreciated.
>
>
> kind regards
>   


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From murdoch at stats.uwo.ca  Fri Feb 12 16:46:11 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 12 Feb 2010 10:46:11 -0500
Subject: [Rd] R Startup configuration file
In-Reply-To: <d8ad40b51002120733n623f55abo310d04b7eec6d500@mail.gmail.com>
References: <d8ad40b51002100123s4b1d77bmc27ece9686106ef@mail.gmail.com>	<4B729C0F.3030301@stats.uwo.ca>	<d8ad40b51002100706t5869535av162a43a6362d6c6b@mail.gmail.com>	<d8ad40b51002120050o74e12ad2pb0423c8017f90350@mail.gmail.com>	<0D56D7F5-1509-4296-A8FA-637DB08E221D@r-project.org>
	<d8ad40b51002120733n623f55abo310d04b7eec6d500@mail.gmail.com>
Message-ID: <4B7577C3.901@stats.uwo.ca>

On 12/02/2010 10:33 AM, Barry Rowlingson wrote:
> On Fri, Feb 12, 2010 at 2:22 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>
> > This is getting OT, but, please, no XML. It's entirely useless in this
> > context IMHO (as it is in others, but that's another story) and we already
> > have reliable support for storing R objects (more than one in fact). Despite
> > the fact that some used to claim human readability of XML in practice it
> > turns out to be false, so I don't see any real benefits of XML in this
> > context.
>
>  Yes, I agree. Originally I was hoping to have a nice
> human-and-computer readable config.ini file:
>
> [options]
> contrasts = structure(list(contrasts = structure(c("contr.treatment",
> "contr.poly"
> ), .Names = c("unordered", "ordered"))), .Names = "contrasts")
>
> but the lack of an ini parser in R made me think "heck, let's do it in
> something we do have a parser for...".
>
> maybe I should use JSON? Yeah, we have a parser and that's what all
> the hipster web 3.0 kids are using these days....
We have read.dcf() if you want human and machine readable.

Duncan Murdoch


From franz.quehenberger at medunigraz.at  Fri Feb 12 13:50:11 2010
From: franz.quehenberger at medunigraz.at (franz.quehenberger at medunigraz.at)
Date: Fri, 12 Feb 2010 13:50:11 +0100 (CET)
Subject: [Rd] aggregate: with 2 by variables in the result the 2nd
	by-variable is wrong (PR#14213)
Message-ID: <20100212125011.1D834283031F@mail.pubhealth.ku.dk>

Full_Name: Franz Quehenberger
Version: 2.10.1
OS: Windows XP
Submission from: (NULL) (145.244.10.3)


aggregate is supposed to produce a data.frame that contains a line for each
combination  of levels of the variables in the by list. The first columns of the
result contain these combinations of levels. With two by variables the second
by-variable takes always only one value. However, it works fine with one or
three by-variables.

The problems seems to be caused by this line of code in aggregate():

    w <- as.data.frame(w, stringsAsFactors = FALSE)[which(!unlist(lapply(z,
is.null))), , drop = FALSE]

or more specifically by: 

    [which(!unlist(lapply(z, is.null))), , drop = FALSE]

Kind regards
FQ



# demonstration of the aggregate bug ind R 2.10.1
factor.a=rep(letters[1:3],4)
factor.b=rep(letters[4:5],each=3,times=2)
factor.c=rep(letters[4:5+2],each=6)
data=data.frame(factor.a,factor.b,factor.c,x)
x=1:12
#one by-variable works:
aggregate(x,list(a=factor.a),FUN=mean)
#thre by-variable work fine:
aggregate(x,list(a=factor.a,b=factor.b,c=factor.b),FUN=mean)
#two by-variables do not produce the levels of the second by-variable
correctly:
aggregate(x,list(a=factor.a,b=factor.b),FUN=mean)
# data
print(data)
++++++++++++++++++++++++++++++++++++++++++++++++++++
Result of the R code:
++++++++++++++++++++++++++++++++++++++++++++++++++++

> # demonstration of the aggregate bug ind R 2.10.1
> factor.a=rep(letters[1:3],4)
> factor.b=rep(letters[4:5],each=3,times=2)
> factor.c=rep(letters[4:5+2],each=6)
> data=data.frame(factor.a,factor.b,factor.c,x)
> x=1:12
> #one by-variable works:
> aggregate(x,list(a=factor.a),FUN=mean)
  a   x
1 a 5.5
2 b 6.5
3 c 7.5
> #thre by-variable work fine:
> aggregate(x,list(a=factor.a,b=factor.b,c=factor.b),FUN=mean)
  a b c x
1 a d d 4
2 b d d 5
3 c d d 6
4 a e e 7
5 b e e 8
6 c e e 9
> #two by-variables do not produce the levels of the second by-variable
correctly:
> aggregate(x,list(a=factor.a,b=factor.b),FUN=mean)
  a b x
1 a d 4
2 b d 5
3 c d 6
4 a d 7
5 b d 8
6 c d 9
Warnmeldung:
In data.frame(w, lapply(y, unlist, use.names = FALSE), stringsAsFactors = FALSE)
:
  row names were found from a short variable and have been discarded
> # data
> print(data)
   factor.a factor.b factor.c  x
1         a        d        f  1
2         b        d        f  2
3         c        d        f  3
4         a        e        f  4
5         b        e        f  5
6         c        e        f  6
7         a        d        g  7
8         b        d        g  8
9         c        d        g  9
10        a        e        g 10
11        b        e        g 11
12        c        e        g 12
>


From bluesky315 at gmail.com  Fri Feb 12 18:33:44 2010
From: bluesky315 at gmail.com (blue sky)
Date: Fri, 12 Feb 2010 11:33:44 -0600
Subject: [Rd] long integer in R?
Message-ID: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>

R-exts.pdf dosen't list many types that are supported in C++, for
example, long. Are there storage.mode corresponds to those extra
types?


From whuber at embl.de  Fri Feb 12 18:50:48 2010
From: whuber at embl.de (Wolfgang Huber)
Date: Fri, 12 Feb 2010 18:50:48 +0100
Subject: [Rd] Unexpected behaviour of x[i] when i is a matrix, on Windows
Message-ID: <4B7594F8.1070507@embl.de>

Hi,

when running the following on different instances of R (Linux and 
Windows), I get different results. The one for Linux seems to be the 
intended / documented one. When using numeric indices rather than 
characters, Windows seemed to behave as expected.

-----------On Windows--------------

x = matrix(FALSE, nrow=3, ncol=3)
colnames(x) = LETTERS[1:3]
rownames(x) = letters[1:3]
x

#       A     B     C
# a FALSE FALSE FALSE
# b FALSE FALSE FALSE
# c FALSE FALSE FALSE

x [ cbind("b", "B") ] = TRUE
x
                                                           b     B
# FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE

sessionInfo()

R version 2.10.0 (2009-10-26)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-----------On Linux--------------
x = matrix(FALSE, nrow=3, ncol=3)
colnames(x) = LETTERS[1:3]
rownames(x) = letters[1:3]
x
#       A     B     C
# a FALSE FALSE FALSE
# b FALSE FALSE FALSE
# c FALSE FALSE FALSE
x [ cbind("b", "B") ] = TRUE
x
#       A     B     C
# a FALSE FALSE FALSE
# b FALSE  TRUE FALSE
# c FALSE FALSE FALSE

 > sessionInfo()
R version 2.11.0 Under development (unstable) (2010-02-12 r51125)
x86_64-unknown-linux-gnu

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] fortunes_1.3-7




-- 

Best wishes
      Wolfgang


--
Wolfgang Huber
EMBL
http://www.embl.de/research/units/genome_biology/huber/contact


From simon.urbanek at r-project.org  Fri Feb 12 19:06:26 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 12 Feb 2010 13:06:26 -0500
Subject: [Rd] long integer in R?
In-Reply-To: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>
References: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>
Message-ID: <95D578C9-8A7F-41A0-9313-7F58DD7A60AD@r-project.org>


On Feb 12, 2010, at 12:33 , blue sky wrote:

> R-exts.pdf dosen't list many types that are supported in C++, for  
> example, long. Are there storage.mode corresponds to those extra  
> types?
>

There are none - that's why they are not listed. As for long: on 32- 
bit platforms (and Win64) int and long are equivalent so you can  
simply use INTSXP. On 64-bit unix platforms (LP64) there is no way to  
losslessly use it (other than raw) but in most applications you can  
simply use REALSXP as it gives you at least 52-bits of precision which  
its sufficient for most applications.

Cheers,
Simon


From ehlers at ucalgary.ca  Fri Feb 12 19:12:00 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 12 Feb 2010 11:12:00 -0700
Subject: [Rd] Unexpected behaviour of x[i] when i is a matrix, on Windows
In-Reply-To: <4B7594F8.1070507@embl.de>
References: <4B7594F8.1070507@embl.de>
Message-ID: <4B7599F0.6070100@ucalgary.ca>

You're comparing 2.10.0 on Windows with 2.11.0 on Linux.
Have you tried 2.11.0 on Windows? => same result as on Linux.

  -Peter Ehlers

Wolfgang Huber wrote:
> Hi,
> 
> when running the following on different instances of R (Linux and 
> Windows), I get different results. The one for Linux seems to be the 
> intended / documented one. When using numeric indices rather than 
> characters, Windows seemed to behave as expected.
> 
> -----------On Windows--------------
> 
> x = matrix(FALSE, nrow=3, ncol=3)
> colnames(x) = LETTERS[1:3]
> rownames(x) = letters[1:3]
> x
> 
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE FALSE FALSE
> # c FALSE FALSE FALSE
> 
> x [ cbind("b", "B") ] = TRUE
> x
>                                                           b     B
> # FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE
> 
> sessionInfo()
> 
> R version 2.10.0 (2009-10-26)
> i386-pc-mingw32
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> -----------On Linux--------------
> x = matrix(FALSE, nrow=3, ncol=3)
> colnames(x) = LETTERS[1:3]
> rownames(x) = letters[1:3]
> x
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE FALSE FALSE
> # c FALSE FALSE FALSE
> x [ cbind("b", "B") ] = TRUE
> x
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE  TRUE FALSE
> # c FALSE FALSE FALSE
> 
>  > sessionInfo()
> R version 2.11.0 Under development (unstable) (2010-02-12 r51125)
> x86_64-unknown-linux-gnu
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
> 
> other attached packages:
> [1] fortunes_1.3-7
> 
> 
> 
> 

-- 
Peter Ehlers
University of Calgary


From simon.urbanek at r-project.org  Fri Feb 12 19:15:35 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 12 Feb 2010 13:15:35 -0500
Subject: [Rd] Unexpected behaviour of x[i] when i is a matrix, on Windows
In-Reply-To: <4B7594F8.1070507@embl.de>
References: <4B7594F8.1070507@embl.de>
Message-ID: <E7A669B1-3070-4094-B887-095C7EECCCF1@r-project.org>


On Feb 12, 2010, at 12:50 , Wolfgang Huber wrote:

> Hi,
>
> when running the following on different instances of R (Linux and  
> Windows), I get different results. The one for Linux seems to be the  
> intended / documented one. When using numeric indices rather than  
> characters, Windows seemed to behave as expected.
>

AFAICT this has nothing to do with the platform but with using an  
older R version in Windows that doesn't support it  ...

 From NEWS:

                 CHANGES IN R VERSION 2.11.0
[...]
NEW FEATURES
[...]
     o   n-dimensional arrays with dimension names can now be indexed
         by an n-column character matrix. The indices are matched
         against the dimension names.  NA indices are propagated to the
         result.  Unmatched values and "" are not allowed and result in
         an error.


Cheers,
Simon



> -----------On Windows--------------
>
> x = matrix(FALSE, nrow=3, ncol=3)
> colnames(x) = LETTERS[1:3]
> rownames(x) = letters[1:3]
> x
>
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE FALSE FALSE
> # c FALSE FALSE FALSE
>
> x [ cbind("b", "B") ] = TRUE
> x
>                                                          b     B
> # FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE
>
> sessionInfo()
>
> R version 2.10.0 (2009-10-26)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> -----------On Linux--------------
> x = matrix(FALSE, nrow=3, ncol=3)
> colnames(x) = LETTERS[1:3]
> rownames(x) = letters[1:3]
> x
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE FALSE FALSE
> # c FALSE FALSE FALSE
> x [ cbind("b", "B") ] = TRUE
> x
> #       A     B     C
> # a FALSE FALSE FALSE
> # b FALSE  TRUE FALSE
> # c FALSE FALSE FALSE
>
> > sessionInfo()
> R version 2.11.0 Under development (unstable) (2010-02-12 r51125)
> x86_64-unknown-linux-gnu
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>
> other attached packages:
> [1] fortunes_1.3-7
>
>
>
>
> -- 
>
> Best wishes
>     Wolfgang
>
>
> --
> Wolfgang Huber
> EMBL
> http://www.embl.de/research/units/genome_biology/huber/contact
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From seth at userprimary.net  Fri Feb 12 19:21:09 2010
From: seth at userprimary.net (Seth Falcon)
Date: Fri, 12 Feb 2010 10:21:09 -0800
Subject: [Rd] Unexpected behaviour of x[i] when i is a matrix, on Windows
In-Reply-To: <4B7599F0.6070100@ucalgary.ca>
References: <4B7594F8.1070507@embl.de> <4B7599F0.6070100@ucalgary.ca>
Message-ID: <4B759C15.30304@userprimary.net>

On 2/12/10 10:12 AM, Peter Ehlers wrote:
> You're comparing 2.10.0 on Windows with 2.11.0 on Linux.
> Have you tried 2.11.0 on Windows? => same result as on Linux.

Indeed, this is new functionality added to R-devel (5 Jan).  Indexing an 
n-dim array with an n-column matrix used to only be supported when the 
matrix contained integers.  Character matrices are now supported to map 
to dimnames of the array.  Here's the NEWS entry:

     o   n-dimensional arrays with dimension names can now be indexed
         by an n-column character matrix. The indices are matched
         against the dimension names.  NA indices are propagated to the
         result.  Unmatched values and "" are not allowed and result in
         an error.

Cheers,

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/user


From whuber at embl.de  Fri Feb 12 19:21:55 2010
From: whuber at embl.de (Wolfgang Huber)
Date: Fri, 12 Feb 2010 19:21:55 +0100
Subject: [Rd] Unexpected behaviour of x[i] when i is a matrix, on Windows
In-Reply-To: <E7A669B1-3070-4094-B887-095C7EECCCF1@r-project.org>
References: <4B7594F8.1070507@embl.de>
	<E7A669B1-3070-4094-B887-095C7EECCCF1@r-project.org>
Message-ID: <4B759C43.4050402@embl.de>


Hi Simon and Peter

Ouch, I am sorry for raising this.

I hadn't even considered that this basic functionality might only have 
entered R between 2.10 and 2.11 - and that trying to use it would not 
raise an error pre-2.11.

The Windows PC was that of a student, which is a lame non-excuse for not 
trying with 2.11 there.

	Sorry again for wasting your time, and best wishes
	Wolfgang




Simon Urbanek scripsit 02/12/2010 07:15 PM:
> 
> On Feb 12, 2010, at 12:50 , Wolfgang Huber wrote:
> 
>> Hi,
>>
>> when running the following on different instances of R (Linux and 
>> Windows), I get different results. The one for Linux seems to be the 
>> intended / documented one. When using numeric indices rather than 
>> characters, Windows seemed to behave as expected.
>>
> 
> AFAICT this has nothing to do with the platform but with using an older 
> R version in Windows that doesn't support it  ...
> 
>  From NEWS:
> 
>                 CHANGES IN R VERSION 2.11.0
> [...]
> NEW FEATURES
> [...]
>     o   n-dimensional arrays with dimension names can now be indexed
>         by an n-column character matrix. The indices are matched
>         against the dimension names.  NA indices are propagated to the
>         result.  Unmatched values and "" are not allowed and result in
>         an error.
> 
> 
> Cheers,
> Simon
> 
> 
> 
>> -----------On Windows--------------
>>
>> x = matrix(FALSE, nrow=3, ncol=3)
>> colnames(x) = LETTERS[1:3]
>> rownames(x) = letters[1:3]
>> x
>>
>> #       A     B     C
>> # a FALSE FALSE FALSE
>> # b FALSE FALSE FALSE
>> # c FALSE FALSE FALSE
>>
>> x [ cbind("b", "B") ] = TRUE
>> x
>>                                                          b     B
>> # FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE
>>
>> sessionInfo()
>>
>> R version 2.10.0 (2009-10-26)
>> i386-pc-mingw32
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> -----------On Linux--------------
>> x = matrix(FALSE, nrow=3, ncol=3)
>> colnames(x) = LETTERS[1:3]
>> rownames(x) = letters[1:3]
>> x
>> #       A     B     C
>> # a FALSE FALSE FALSE
>> # b FALSE FALSE FALSE
>> # c FALSE FALSE FALSE
>> x [ cbind("b", "B") ] = TRUE
>> x
>> #       A     B     C
>> # a FALSE FALSE FALSE
>> # b FALSE  TRUE FALSE
>> # c FALSE FALSE FALSE
>>
>> > sessionInfo()
>> R version 2.11.0 Under development (unstable) (2010-02-12 r51125)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices datasets  utils     methods   base
>>
>> other attached packages:
>> [1] fortunes_1.3-7
>>
>>
>>
>>
>> -- 
>>
>> Best wishes
>>     Wolfgang
>>
>>
>> -- 
>> Wolfgang Huber
>> EMBL
>> http://www.embl.de/research/units/genome_biology/huber/contact
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 


-- 

Best wishes
      Wolfgang


--
Wolfgang Huber
EMBL
http://www.embl.de/research/units/genome_biology/huber/contact


From ehlers at ucalgary.ca  Fri Feb 12 22:01:52 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 12 Feb 2010 14:01:52 -0700
Subject: [Rd] aggregate: with 2 by variables in the result the
 2nd	by-variable is wrong (PR#14213)
In-Reply-To: <20100212125011.1D834283031F@mail.pubhealth.ku.dk>
References: <20100212125011.1D834283031F@mail.pubhealth.ku.dk>
Message-ID: <4B75C1C0.7080806@ucalgary.ca>

franz.quehenberger at medunigraz.at wrote:
> Full_Name: Franz Quehenberger
> Version: 2.10.1
> OS: Windows XP
> Submission from: (NULL) (145.244.10.3)
> 
> 
> aggregate is supposed to produce a data.frame that contains a line for each
> combination  of levels of the variables in the by list. The first columns of the
> result contain these combinations of levels. With two by variables the second
> by-variable takes always only one value. However, it works fine with one or
> three by-variables.
> 
> The problems seems to be caused by this line of code in aggregate():
> 
>     w <- as.data.frame(w, stringsAsFactors = FALSE)[which(!unlist(lapply(z,
> is.null))), , drop = FALSE]
> 
> or more specifically by: 
> 
>     [which(!unlist(lapply(z, is.null))), , drop = FALSE]
> 
> Kind regards
> FQ
> 
> 
> 
> # demonstration of the aggregate bug ind R 2.10.1
> factor.a=rep(letters[1:3],4)
> factor.b=rep(letters[4:5],each=3,times=2)
> factor.c=rep(letters[4:5+2],each=6)
> data=data.frame(factor.a,factor.b,factor.c,x)
> x=1:12
> #one by-variable works:
> aggregate(x,list(a=factor.a),FUN=mean)
> #thre by-variable work fine:
> aggregate(x,list(a=factor.a,b=factor.b,c=factor.b),FUN=mean)
> #two by-variables do not produce the levels of the second by-variable
> correctly:
> aggregate(x,list(a=factor.a,b=factor.b),FUN=mean)
> # data
> print(data)
> ++++++++++++++++++++++++++++++++++++++++++++++++++++
> Result of the R code:
> ++++++++++++++++++++++++++++++++++++++++++++++++++++
> 
>> # demonstration of the aggregate bug ind R 2.10.1
>> factor.a=rep(letters[1:3],4)
>> factor.b=rep(letters[4:5],each=3,times=2)
>> factor.c=rep(letters[4:5+2],each=6)
>> data=data.frame(factor.a,factor.b,factor.c,x)
>> x=1:12
>> #one by-variable works:
>> aggregate(x,list(a=factor.a),FUN=mean)
>   a   x
> 1 a 5.5
> 2 b 6.5
> 3 c 7.5
>> #thre by-variable work fine:
>> aggregate(x,list(a=factor.a,b=factor.b,c=factor.b),FUN=mean)
>   a b c x
> 1 a d d 4
> 2 b d d 5
> 3 c d d 6
> 4 a e e 7
> 5 b e e 8
> 6 c e e 9
>> #two by-variables do not produce the levels of the second by-variable
> correctly:
>> aggregate(x,list(a=factor.a,b=factor.b),FUN=mean)
>   a b x
> 1 a d 4
> 2 b d 5
> 3 c d 6
> 4 a d 7
> 5 b d 8
> 6 c d 9
> Warnmeldung:
> In data.frame(w, lapply(y, unlist, use.names = FALSE), stringsAsFactors = FALSE)
> :
>   row names were found from a short variable and have been discarded
>> # data
>> print(data)
>    factor.a factor.b factor.c  x
> 1         a        d        f  1
> 2         b        d        f  2
> 3         c        d        f  3
> 4         a        e        f  4
> 5         b        e        f  5
> 6         c        e        f  6
> 7         a        d        g  7
> 8         b        d        g  8
> 9         c        d        g  9
> 10        a        e        g 10
> 11        b        e        g 11
> 12        c        e        g 12
> 

I don't see this is 2.10.1 nor in 2.11.0 (Windows Vista).
I can't think of how you might have got your result.
Is there something you haven't mentioned?
What's your sessionInfo()?

-- 
Peter Ehlers
University of Calgary


From guillaume.yziquel at citycable.ch  Fri Feb 12 23:02:41 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Fri, 12 Feb 2010 23:02:41 +0100
Subject: [Rd] [ANN] OCaml-R binding for the R language.
Message-ID: <4B75D001.5080502@citycable.ch>

This post is to announce the 0.2 release of OCaml-R.

OCaml-R is a binding embedding the R interpreter into Objective Caml code.

Home page: http://home.gna.org/ocaml-r/
Download page: http://download.gna.org/ocaml-r/
Deb packages: http://yziquel.homelinux.org/debian/pool/main/o/ocaml-r/
Tutorial: http://home.gna.org/ocaml-r/gettingstarted.en.html
OCamlDoc API: http://yziquel.homelinux.org/topos/api/ocaml-r/index.html
               http://home.gna.org/ocaml-r/refdoc/index.html

The goal of OCaml-R is to provide adequate integration of the R 
interpreter into Objective Caml, and a framework suitable to bind R 
library into OCaml code.

Version 0.2 is a near-complete rewrite of the 0.1 version by Maxence 
Guesdon, with an incompatible API. Main features are:

- Safe handling of R default environment variables at compile time, 
following what is done in littler.
- R Signal handlers do not conflict with OCaml code.
- Integration with findlib, enabling the #require "R.interpreter" to 
initialise statically the R interpreter. Compiling with 'ocamlfind 
ocamlopt -package R.interpreter' also initialises the R interpreter at 
compile-time, so to speak.
- Some (most?) functionalities of the R standalone library are wrapped.
- Low-level binding, in the sense that you construct low-level R calls 
to execute them. You can also parse R code to execute it, if you wish.
- R exceptions are chained back to Objective Caml.
- R's garbage collector is chained with OCaml's garbage collector. This 
is done rather inefficiently for the moment (freeing n R values in 
O(n^2) time complexity), and we expect to bring this down to O(n) with a 
thin garbage collecting layer in the future.
- We provide a double typing scheme, with some subtyping features. A 
first typing mimics the dynamic typing of the R language, while a second 
typing, for the end-user, aims at providing a static typing of R values 
and functions. (This can be bettered).
- S3 classes are supported (static typing is however still 
unsatisfying). S4 classes are not yet supported. Help welcome.
- Some basic R datatypes, such as dataframes, are wrapped, and a 
framework to wrap the standard library has been put in place.
- Basic data structures can be converted back and forth between OCaml 
and the R interpreter.
- Ability to inspect (read-only) the inner structure of R values, which 
is quite convenient: you get to know rather quickly what a given piece 
of R code returns, which you need to know to type R code statically in 
order to bind it to OCaml.
- Not thread-safe at all. At least, not more than R is... Lwt-style 
multithreading of R code could be possible, modulo some simple and deep 
(i.e. below R API) changes in the R evaluation functions. POSIX 
threading a single R thread with multiple OCaml threads is not yet 
possible, but is within reach.
- Doesn't interact well the R "Defaults" package.

While most of the code sticks or could stick to the R API, or at least 
to the public part of the R headers, there are some functionalities 
which are outright out of the scope of the R API. Some of these 
functionalities are for convenience only (i.e. inspecting internals of R 
values), while others are crucial to the binding (chaining R exceptions 
to OCaml).

Hopefully, this lays down a foundation on which one could import R 
functionalities, libraries and packages to OCaml.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From djsamperi at gmail.com  Sat Feb 13 01:14:26 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 12 Feb 2010 19:14:26 -0500
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>
	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
Message-ID: <d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100212/1d2cd305/attachment.pl>

From guillaume.yziquel at citycable.ch  Sat Feb 13 02:01:11 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sat, 13 Feb 2010 02:01:11 +0100
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
Message-ID: <4B75F9D7.4010100@citycable.ch>

Dominick Samperi a ?crit :
> 
> Interesting, but what about the situation where a new author adds his name
> as copyright holder without the
> consent of the original copyright holder, and with only one person making
> the decision whether or not this
> change is warranted: the new copyright holder? Doesn't this amount to giving
> the copyright away, or
> giving it away to everybody?

If someone writes some code in a file, he is entitled to be the 
copyright owner of what he wrote. Kicking him away means not using his 
changes.

> GPL is often called copyleft for a reason: it basically cancels most of the
> rights that you would have with
> an ordinary copyright so that others can freely copy your work with no
> requirements other than that your

Nope. You cannot "cancel" your rights. You have them. Full stop.

You just give enough rights to other fellows. And restrictions when it 
comes to distributing GPL stuff. Essentially.

You are not taking your rights away from and giving them to others. That 
doesn't make sense.

> The only "infringement" cases that I am aware of is where a company is sued
> because it tried to turn
> GPL software into a commercial product. This is what GPL was designed to do.

Nope. GPL allows you to make commercial GPL products. So you cannot say 
that it forbids turning GPL work into a commercial product.

And there are cases where ISP have been 'distributing' GPL code in the 
routers, ADSL boxes. They've been sued for not disclosing the source 
code. They haven't been sued for shipping GPL code in these ADSL boxes 
in the scope of a commercial contract. Quite the opposite.

> It is not designed
> to protect authors (because that would be an attack on software freedom and
> apple pie, according to
> true believers).

It is designed to protect people receiving software from vendors who may 
want to conceal the source code of what they're distributing. Among 
other things.

But, for instance, if your code may be hijacked by a big corporation, 
putting it under the GPL is a guarantee that it doesn't make huge sense 
to hijack it. So here you protect the author.

But how is this R related?

All the best,

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From djsamperi at gmail.com  Sat Feb 13 04:42:20 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 12 Feb 2010 22:42:20 -0500
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <4B75F9D7.4010100@citycable.ch>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>
	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
	<4B75F9D7.4010100@citycable.ch>
Message-ID: <d4cf43b61002121942r737dda7eq33e0b11a89c14325@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100212/c9fe9122/attachment.pl>

From maiagx at gmail.com  Sat Feb 13 07:40:09 2010
From: maiagx at gmail.com (Charlotte Maia)
Date: Sat, 13 Feb 2010 19:40:09 +1300
Subject: [Rd] Darwinian software development and the library function
In-Reply-To: <4B75768F.8020904@prodsyse.com>
References: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>
	<4B75768F.8020904@prodsyse.com>
Message-ID: <b7bfe54e1002122240m4e633e03m3f3089096ef70d54@mail.gmail.com>

Hi Spencer,

Sorry, I wasn't very clear in my initial post.
The function print.foo (myfoo, ...) won't pass R check (unless one
overwrites print first).
One has to write print.foo (x, ...), which in my personal opinion, can
be problematic.

In my oosp package, I have overwritten print (along with a few others).
Initially, I overwrote both print and print.default.
However now, I merely use print = function (...) base::print (...).

Not really a generic, however it acts exactly the same (I think...).
Plus Rd documentation still documents print.mymethod in the usual way.


kind regards
Charlotte


On Sat, Feb 13, 2010 at 4:41 AM, spencerg <spencer.graves at prodsyse.com> wrote:
> Hi, Charlotte:
>
> ? ? I'm not sure what you mean. ?If you mean writing something like
> "print.foo (myfoo, ...)", this is relatively benign I suppose, but I avoid
> it where feasible. ?On multiple occasions, I've pushed collaborators and
> even maintainers of other packages to change this or allow me to change it
> to conform to the standard; ?if my memory is correct, there have been
> several violations of this standard in the "fda" package, which are no
> longer there because I changed them. ?If a user with an object "x" of class
> "foo" writes print(x=x) or print(foo=x), I'm not sure what it would do, but
> it might not be what you want.
>
> ? ? My "sos" package masks "?". ?However, I don't like it. ?I generally
> consider such to be potentially user hostile, and whenever feasible, I
> prefer to avoid such code. ?I did it in this case for a couple of reasons.
> ?First, using "?" (actually "???") seems so much easier to remember than
> "findFn" that it justifies this transgression of standard protocol. ?Second,
> one of the leading figures in the R community (Duncan Murdoch) contributed
> suggested we do this and contributed the code.
>
> ? ? If you change the definition of "print" itself, that seems to me to be a
> much bigger issue, with consequences much more difficult to predict. ?If
> someone else also overwrites "print" making it different and incompatible
> with yours, then your code may not work or theirs may not, depending on
> which gets loaded first in the search path. ?Worse, your code cannot
> possibly have been tested as thoroughly as the standard code. ?If your code
> includes a subtle bug that only occurs under special circumstances, it may
> be hard for the person experiencing the problem to find, because they don't
> expect it.
>
> ? ? Hope this helps.
> ? ? Spencer
>
>
> Charlotte Maia wrote:
>>
>> Hi all,
>>
>> Legend has it, that polite R programmers don't overwrite, say, the
>> print function.
>> However, this seems quite un-Darwinian to me (especially given that I
>> don't want to call all my arguments x and y).
>> I might want a function print.foo (myfoo, ...).
>>
>> So I decided to be very impolite (in one of my packages) and overwrite
>> a few standard generics.
>> Plus, to the best of my knowledge it doesn't interfere with normal use
>> (yay...).
>>
>> This brings us to the library function.
>> Which by default gives a whole lot of warnings loading my package (and
>> any other package that does something similar), scaring off polite R
>> programmers and perhaps some mainstream R users.
>>
>> I'm starting to think that the default for library, should be
>> warn.conflicts=FALSE.
>> However, just reading the documentation, I noticed a reference to
>> something called .conflicts.OK.
>> Not sure what that does, however if it does what it sounds like, then
>> it largely fixes the problem.
>>
>> The biggest issue though, is whether or not one should be impolite
>> (i.e. Darwinian) and overwrite print etc in the first place...?
>>
>> I'm inclined to go in favour of overwriting the functions.
>> However, it has the potential to introduce some technical problems.
>>
>> Other's opinions appreciated.
>>
>>
>> kind regards
>>
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Operating Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph: ?408-655-4567
>
>


-- 
Charlotte Maia
http://sites.google.com/site/maiagx


From simon.urbanek at r-project.org  Sat Feb 13 16:00:23 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 13 Feb 2010 10:00:23 -0500
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>
	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
Message-ID: <A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>


On Feb 12, 2010, at 7:14 PM, Dominick Samperi wrote:

> On Tue, Jan 19, 2010 at 11:54 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Copyright is the right that the author of an original work holds automatically (unless someone else can claim to own his work - e.g. his employer etc.) under the Berne Convention. The copyright gives only the author all rights - including but not limited to the right to copy, modify, distribute the work etc.  Licenses are used to give some of those rights to other people under certain conditions. Hence you cannot "assign yourself copyright" because you already have it (and if you don't then your cannot assign it). Also you don't need to give the "copyright" to anyone else - you can give certain rights to others using licenses -- such as GPL, LGPL, EUPL etc. -- but you don't give copyright by those since you have far more rights as the author (e.g., you can do whatever your want with the original work beyond the restrictions of the license). There are cases where you may want to give your copyright to someone, e.g., an organization that represents all authors of a project which makes it easier to change licenses etc., but that is a different story.
>  
> Interesting, but what about the situation where a new author adds his name as copyright holder without them consent of the original copyright holder,

If the software is released under GPL then no one needs anyone's consent. By licensing the software under GPL you give everyone the right to modify and redistribute the software so anyone can modify it, add their copyright notices and release it.


> and with only one person making the decision whether or not this change is warranted: the new copyright holder?

The decision can be made by anyone because you granted everyone the right to modify and redistribute it by using the GPL license. This is equally true of any derivative works because GPL makes sure that even those must be licensed under the same terms.


> Doesn't this amount to giving the copyright away, or giving it away to everybody?

No, you give rights (to modify and redistribute) via the license to everybody, but not the copyright. As a copyright holder you can do anything with your original code (re-license it, use commercially etc.) but anyone else can only do what you specified in the license (so e.g. they cannot release it under a different, incompatible license - let's say BSD).


> GPL is often called copyleft for a reason: it basically cancels most of the rights that you would have with an ordinary copyright

No - it doesn't cancel anything - you still have all the rights. To the contrary - it gives some of those rights to others (everyone) under strict conditions (as opposed to let's say BSD which gives them with almost no conditions).


> so that others can freely copy your work with no requirements other than that your copyright notice be retained, along with a potentially unlimited number of other "copyright" notices attached to the same work. (For completeness, there is a clause about not leaving misleading impressions about previous authors, but in my opinion the only way this could be enforced is if the contributions of the previous author are not altered. But this is inconsistent with the broad freedoms granted by the main text of the license.)
> 

Note that GPL license does not grant broad freedom - it is in fact one of the more restrictive open source licenses -- those restrictions are meant to force modifications to be contributed back to the community.


> The only "infringement" cases that I am aware of is where a company is sued because it tried to turn GPL software into a commercial product. This is what GPL was designed to do. It is not designed to protect authors (because that would be an attack on software freedom and apple pie, according to true believers).
> 

Well, the authors need no protection in that sense since they have full rights. It's entirely with the authors to specify which rights they will give to others. You could, for example, grant everyone the license to use your software without any restrictions but prohibit re-distribution in modified form -- although that would not constitute open source software.


In practice this issue seldom arises as the whole idea of open source is collaborative development, i.e., it explicitly allows others to modify and redistribute the code. There is often at least a semi-centralized entity that represents a given product (be it just the software version control repository) and if someone likes the idea but wants to use it in a different direction s/he creates a fork and thus creates a kind of sibling. The idea in open source world is that this enriches the choices since users can use whichever of the two they like better, so there will be natural selection. Unmaintained or less useful branches will just die and the maintained ones will live on -- this happens very frequently and you can often find multiple branches of projects -- some work together with their siblings (e.g if the fork is to port it to another platform they usually merge back or contribute back once in a while) some don't. Clearly, the idea is that this is good for the community, not necessarily for the ego of the authors ;). Although your copyright notice will survive, your ideals won't necessarily.


Again, those are my personal views, they do not constitute a legal advice, I'm not a lawyer and don't represent anyone else ...

Cheers,
Simon


From hb at stat.berkeley.edu  Sat Feb 13 16:10:30 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 13 Feb 2010 16:10:30 +0100
Subject: [Rd] Darwinian software development and the library function
In-Reply-To: <b7bfe54e1002122240m4e633e03m3f3089096ef70d54@mail.gmail.com>
References: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>
	<4B75768F.8020904@prodsyse.com>
	<b7bfe54e1002122240m4e633e03m3f3089096ef70d54@mail.gmail.com>
Message-ID: <59d7961d1002130710t6c2507a5i177c26d173d94c97@mail.gmail.com>

Hi.

Here are some guidelines that I find useful:

- Avoid changing the arguments of generic functions provided by the
default R packages, especially the ones in base.  Just, accept those
arguments.  If there are extra arguments you don't like, you can
always add '...' to your method and they will be accepted/pass the R
CMD check.

- Using an S3 generic function that only has '...' arguments seems to
work well and makes all methods for it pass R CMD check, regardless of
what arguments you use in your methods.

- Use R.methodS3 to define your methods, i.e. use setMethodS3("print",
"foo", function(x, ...) { ... }).  This will check if there is a
generic function or not, and if missing, it will be created.
R.methodsS3 was created to make your S3 life easier.

My $.02

Henrik

On Sat, Feb 13, 2010 at 7:40 AM, Charlotte Maia <maiagx at gmail.com> wrote:
> Hi Spencer,
>
> Sorry, I wasn't very clear in my initial post.
> The function print.foo (myfoo, ...) won't pass R check (unless one
> overwrites print first).
> One has to write print.foo (x, ...), which in my personal opinion, can
> be problematic.
>
> In my oosp package, I have overwritten print (along with a few others).
> Initially, I overwrote both print and print.default.
> However now, I merely use print = function (...) base::print (...).
>
> Not really a generic, however it acts exactly the same (I think...).
> Plus Rd documentation still documents print.mymethod in the usual way.
>
>
> kind regards
> Charlotte
>
>
> On Sat, Feb 13, 2010 at 4:41 AM, spencerg <spencer.graves at prodsyse.com> wrote:
>> Hi, Charlotte:
>>
>> ? ? I'm not sure what you mean. ?If you mean writing something like
>> "print.foo (myfoo, ...)", this is relatively benign I suppose, but I avoid
>> it where feasible. ?On multiple occasions, I've pushed collaborators and
>> even maintainers of other packages to change this or allow me to change it
>> to conform to the standard; ?if my memory is correct, there have been
>> several violations of this standard in the "fda" package, which are no
>> longer there because I changed them. ?If a user with an object "x" of class
>> "foo" writes print(x=x) or print(foo=x), I'm not sure what it would do, but
>> it might not be what you want.
>>
>> ? ? My "sos" package masks "?". ?However, I don't like it. ?I generally
>> consider such to be potentially user hostile, and whenever feasible, I
>> prefer to avoid such code. ?I did it in this case for a couple of reasons.
>> ?First, using "?" (actually "???") seems so much easier to remember than
>> "findFn" that it justifies this transgression of standard protocol. ?Second,
>> one of the leading figures in the R community (Duncan Murdoch) contributed
>> suggested we do this and contributed the code.
>>
>> ? ? If you change the definition of "print" itself, that seems to me to be a
>> much bigger issue, with consequences much more difficult to predict. ?If
>> someone else also overwrites "print" making it different and incompatible
>> with yours, then your code may not work or theirs may not, depending on
>> which gets loaded first in the search path. ?Worse, your code cannot
>> possibly have been tested as thoroughly as the standard code. ?If your code
>> includes a subtle bug that only occurs under special circumstances, it may
>> be hard for the person experiencing the problem to find, because they don't
>> expect it.
>>
>> ? ? Hope this helps.
>> ? ? Spencer
>>
>>
>> Charlotte Maia wrote:
>>>
>>> Hi all,
>>>
>>> Legend has it, that polite R programmers don't overwrite, say, the
>>> print function.
>>> However, this seems quite un-Darwinian to me (especially given that I
>>> don't want to call all my arguments x and y).
>>> I might want a function print.foo (myfoo, ...).
>>>
>>> So I decided to be very impolite (in one of my packages) and overwrite
>>> a few standard generics.
>>> Plus, to the best of my knowledge it doesn't interfere with normal use
>>> (yay...).
>>>
>>> This brings us to the library function.
>>> Which by default gives a whole lot of warnings loading my package (and
>>> any other package that does something similar), scaring off polite R
>>> programmers and perhaps some mainstream R users.
>>>
>>> I'm starting to think that the default for library, should be
>>> warn.conflicts=FALSE.
>>> However, just reading the documentation, I noticed a reference to
>>> something called .conflicts.OK.
>>> Not sure what that does, however if it does what it sounds like, then
>>> it largely fixes the problem.
>>>
>>> The biggest issue though, is whether or not one should be impolite
>>> (i.e. Darwinian) and overwrite print etc in the first place...?
>>>
>>> I'm inclined to go in favour of overwriting the functions.
>>> However, it has the potential to introduce some technical problems.
>>>
>>> Other's opinions appreciated.
>>>
>>>
>>> kind regards
>>>
>>
>>
>> --
>> Spencer Graves, PE, PhD
>> President and Chief Operating Officer
>> Structure Inspection and Monitoring, Inc.
>> 751 Emerson Ct.
>> San Jos?, CA 95126
>> ph: ?408-655-4567
>>
>>
>
>
> --
> Charlotte Maia
> http://sites.google.com/site/maiagx
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From guillaume.yziquel at citycable.ch  Sat Feb 13 16:58:58 2010
From: guillaume.yziquel at citycable.ch (Guillaume Yziquel)
Date: Sat, 13 Feb 2010 16:58:58 +0100
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
	<A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
Message-ID: <4B76CC42.2030006@citycable.ch>

Simon Urbanek a ?crit :
> On Feb 12, 2010, at 7:14 PM, Dominick Samperi wrote:
> 
>> On Tue, Jan 19, 2010 at 11:54 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>
>> Copyright is the right that the author of an original work holds automatically (unless someone else can claim to own his work - e.g. his employer etc.) under the Berne Convention.
>>  
>> Interesting, but what about the situation where a new author adds his name as copyright holder without them consent of the original copyright holder,
> 
> If the software is released under GPL then no one needs anyone's consent. By licensing the software under GPL you give everyone the right to modify and redistribute the software so anyone can modify it, add their copyright notices and release it.

Looking at the backlog of events that led Dominick to try legal stunts 
around the GPL, I guess that the only free software licence that would 
satisfy his needs concerning Rcpp is the QPL. This way he retains 
control over the evolution of the source code.

By far not one of my favourite licences, but that's the licence he's 
been looking for all along.

-- 
      Guillaume Yziquel
http://yziquel.homelinux.org/


From djsamperi at gmail.com  Sat Feb 13 18:45:03 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 13 Feb 2010 12:45:03 -0500
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>
	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
	<A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
Message-ID: <d4cf43b61002130945u355d4053s62234d93f1eb462b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100213/13b9cef0/attachment.pl>

From bluesky315 at gmail.com  Sat Feb 13 23:04:16 2010
From: bluesky315 at gmail.com (blue sky)
Date: Sat, 13 Feb 2010 16:04:16 -0600
Subject: [Rd] long integer in R?
In-Reply-To: <95D578C9-8A7F-41A0-9313-7F58DD7A60AD@r-project.org>
References: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>
	<95D578C9-8A7F-41A0-9313-7F58DD7A60AD@r-project.org>
Message-ID: <48413fa11002131404v294445dft7b10a062837e19f8@mail.gmail.com>

On Fri, Feb 12, 2010 at 12:06 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Feb 12, 2010, at 12:33 , blue sky wrote:
>
>> R-exts.pdf dosen't list many types that are supported in C++, for example,
>> long. Are there storage.mode corresponds to those extra types?
>>
>
> There are none - that's why they are not listed. As for long: on 32-bit
> platforms (and Win64) int and long are equivalent so you can simply use
> INTSXP. On 64-bit unix platforms (LP64) there is no way to losslessly use it
> (other than raw) but in most applications you can simply use REALSXP as it
> gives you at least 52-bits of precision which its sufficient for most
> applications.

According to ?integer,

"Note that on *almost* all implementations of R the range of
representable integers is restricted to about +/-2*10^9: ?double?s
can hold much larger integers exactly."

It uses 'almost'. I'm wondering on what platform integer is not
restricted to about +/-2*10^9 so that double's can not hold large
integers exactly?


From simon.urbanek at r-project.org  Sun Feb 14 00:24:19 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 13 Feb 2010 18:24:19 -0500
Subject: [Rd] long integer in R?
In-Reply-To: <48413fa11002131404v294445dft7b10a062837e19f8@mail.gmail.com>
References: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>
	<95D578C9-8A7F-41A0-9313-7F58DD7A60AD@r-project.org>
	<48413fa11002131404v294445dft7b10a062837e19f8@mail.gmail.com>
Message-ID: <994C31DF-39BA-457E-A49B-0DECE194A851@r-project.org>


On Feb 13, 2010, at 5:04 PM, blue sky wrote:

> On Fri, Feb 12, 2010 at 12:06 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Feb 12, 2010, at 12:33 , blue sky wrote:
>> 
>>> R-exts.pdf dosen't list many types that are supported in C++, for example,
>>> long. Are there storage.mode corresponds to those extra types?
>>> 
>> 
>> There are none - that's why they are not listed. As for long: on 32-bit
>> platforms (and Win64) int and long are equivalent so you can simply use
>> INTSXP. On 64-bit unix platforms (LP64) there is no way to losslessly use it
>> (other than raw) but in most applications you can simply use REALSXP as it
>> gives you at least 52-bits of precision which its sufficient for most
>> applications.
> 
> According to ?integer,
> 
> "Note that on *almost* all implementations of R the range of representable integers is restricted to about +/-2*10^9: ?double?s can hold much larger integers exactly."
> 
> It uses 'almost'. I'm wondering on what platform integer is not restricted to about +/-2*10^9 so that double's can not hold large integers exactly?
> 

I'm not sure I can parse your statement including a question, so I'll rather address the two disjoint parts of the quote:

a) restriction of representable integers. Today's platforms use 32-bit integers, but on 16-bit platforms is used to be 16-bit hence the "almost".

b) doubles can hold much larger integers exactly (note that there is no "almost" in this part) -- that is what I was saying above since doubles can store 52-bit integers without loss of precision.

I hope it helps.

Cheers,
Simon


From djsamperi at gmail.com  Sun Feb 14 02:00:20 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 13 Feb 2010 20:00:20 -0500
Subject: [Rd] Copyright versus Licenses
In-Reply-To: <A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
References: <893823751001182006l36ef05e4gf6f44d2b93e1a606@mail.gmail.com>
	<12CEDA39-5D4A-4354-BC04-ADC373760053@r-project.org>
	<d4cf43b61002121614p65525432g50027a59a5805eec@mail.gmail.com>
	<A65FA42F-71F5-4CF0-856F-BD05839B6CC9@r-project.org>
Message-ID: <d4cf43b61002131700u217d375and53fa04fea1c356@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100213/4cb56196/attachment.pl>

From bluesky315 at gmail.com  Sun Feb 14 05:21:12 2010
From: bluesky315 at gmail.com (blue sky)
Date: Sat, 13 Feb 2010 22:21:12 -0600
Subject: [Rd] long integer in R?
In-Reply-To: <994C31DF-39BA-457E-A49B-0DECE194A851@r-project.org>
References: <48413fa11002120933r727063bble99768b6812eb561@mail.gmail.com>
	<95D578C9-8A7F-41A0-9313-7F58DD7A60AD@r-project.org>
	<48413fa11002131404v294445dft7b10a062837e19f8@mail.gmail.com>
	<994C31DF-39BA-457E-A49B-0DECE194A851@r-project.org>
Message-ID: <48413fa11002132021k14ab9888q11a2460216a6a605@mail.gmail.com>

> a) restriction of representable integers. Today's platforms use 32-bit integers, but on 16-bit platforms is used to be 16-bit hence the "almost".

Just to make sure if I understand you correctly. So there are no
64-bit intergers on any platform?


From cgenolin at u-paris10.fr  Sun Feb 14 12:58:31 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sun, 14 Feb 2010 12:58:31 +0100
Subject: [Rd] Portability of a C function
Message-ID: <4B77E567.4060603@u-paris10.fr>

Hi the list,

In a package P1, I write a function f1 in C, potentially an internal 
function (not to be called from R).
In a package P2, I write a function f2 in C. The f2 function needs to 
use f1 from P1. Is it possible ?

--- 8< ---- In file P1.c ---------
double f1(x,y){
   ....
}

--- 8< ---- In file P2.c ---------
void f2(x,y,z){
   double result;
   ....
   result = f1(x,y);
   ....
}

Thanks
Christophe


From romain.francois at dbmail.com  Sun Feb 14 13:14:42 2010
From: romain.francois at dbmail.com (Romain Francois)
Date: Sun, 14 Feb 2010 13:14:42 +0100
Subject: [Rd] Portability of a C function
In-Reply-To: <4B77E567.4060603@u-paris10.fr>
References: <4B77E567.4060603@u-paris10.fr>
Message-ID: <4B77E932.2090401@dbmail.com>

Hello,

This was discussed this week in the thread "LinkingTo and C++".

It is possible, and documented in WRE section 5.4 : 
http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines

Romain

On 02/14/2010 12:58 PM, Christophe Genolini wrote:
>
> Hi the list,
>
> In a package P1, I write a function f1 in C, potentially an internal
> function (not to be called from R).
> In a package P2, I write a function f2 in C. The f2 function needs to
> use f1 from P1. Is it possible ?
>
> --- 8< ---- In file P1.c ---------
> double f1(x,y){
> ....
> }
>
> --- 8< ---- In file P2.c ---------
> void f2(x,y,z){
> double result;
> ....
> result = f1(x,y);
> ....
> }
>
> Thanks
> Christophe

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/O1wO : highlight 0.1-5
|- http://tr.im/O1qJ : Rcpp 0.7.6
`- http://tr.im/NrTG : Rcpp 0.7.5


From edd at debian.org  Sun Feb 14 13:22:07 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 14 Feb 2010 06:22:07 -0600
Subject: [Rd] Portability of a C function
In-Reply-To: <4B77E567.4060603@u-paris10.fr>
References: <4B77E567.4060603@u-paris10.fr>
Message-ID: <19319.60143.344943.662687@ron.nulle.part>


On 14 February 2010 at 12:58, Christophe Genolini wrote:
| Hi the list,
| 
| In a package P1, I write a function f1 in C, potentially an internal 
| function (not to be called from R).
| In a package P2, I write a function f2 in C. The f2 function needs to 
| use f1 from P1. Is it possible ?

Yes. See 'Writing R Extension' on LinkingTo. You can register f1 for use by
the others, if P2 has a LinkingTo: on P1 then you're good.  The 'classic'
example is for lme4 using (large) parts of Matrix.

Dirk
 
| --- 8< ---- In file P1.c ---------
| double f1(x,y){
|    ....
| }
| 
| --- 8< ---- In file P2.c ---------
| void f2(x,y,z){
|    double result;
|    ....
|    result = f1(x,y);
|    ....
| }
| 
| Thanks
| Christophe
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From saptarshi.guha at gmail.com  Sun Feb 14 17:11:57 2010
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 14 Feb 2010 11:11:57 -0500
Subject: [Rd] Feature Request: Multiline Comments
Message-ID: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com>

Hello,
Is it possible to extend the R lexer/parser to include multiline comments like
/*
acomment

*/
?
This way I can integrate emacs org-mode with my R code, so that I can
have a table of contents,
section folding, html-output of source etc.

e.g
/*
* Display Code
*/
#+BEGIN_SRC R

foo <- function(...){
stuff
}

#+end_src

and so on .

Thanks
Saptarshi


From bluesky315 at gmail.com  Sun Feb 14 19:32:22 2010
From: bluesky315 at gmail.com (blue sky)
Date: Sun, 14 Feb 2010 12:32:22 -0600
Subject: [Rd] How S3method() is implemented and called? And when to use it?
Message-ID: <48413fa11002141032g1a21d93eg9ce33be7bfb534e9@mail.gmail.com>

R-exts.pdf discribes S3method a little bit. But I want to understand
more on how it is called, implemented and when to use it.

I don't find it in an R session. But I see S3method() in some NAMESPACE files.

> S3method
Error: object 'S3method' not found
> ?S3method
No documentation for 'S3method' in specified packages and libraries:
you could try '??S3method'



I don't understand why S3method is necessary.

My understanding is that we can always use
print.foo(<something) {<function body>} # and appropriate exporting
to replace
S3method(print, foo)
, right?

Or I misunderstand something?


From romain at r-enthusiasts.com  Sun Feb 14 19:41:08 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Sun, 14 Feb 2010 19:41:08 +0100
Subject: [Rd] How S3method() is implemented and called? And when to use
 it?
In-Reply-To: <48413fa11002141032g1a21d93eg9ce33be7bfb534e9@mail.gmail.com>
References: <48413fa11002141032g1a21d93eg9ce33be7bfb534e9@mail.gmail.com>
Message-ID: <4B7843C4.8060703@r-enthusiasts.com>

Hello `Blue Sky` ,

Will you please start posting under your real name.

As documented in WRE, S3method is meant for use in namespaces:
http://cran.r-project.org/doc/manuals/R-exts.html#Registering-S3-methods

It is not an R function.

Romain

On 02/14/2010 07:32 PM, blue sky wrote:
>
> R-exts.pdf discribes S3method a little bit. But I want to understand
> more on how it is called, implemented and when to use it.
>
> I don't find it in an R session. But I see S3method() in some NAMESPACE files.
>
>> S3method
> Error: object 'S3method' not found
>> ?S3method
> No documentation for 'S3method' in specified packages and libraries:
> you could try '??S3method'
>
>
>
> I don't understand why S3method is necessary.
>
> My understanding is that we can always use
> print.foo(<something) {<function body>} # and appropriate exporting
> to replace
> S3method(print, foo)
> , right?
>
> Or I misunderstand something?


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/O1wO : highlight 0.1-5
|- http://tr.im/O1qJ : Rcpp 0.7.6
`- http://tr.im/NrTG : Rcpp 0.7.5


From pauljohn32 at gmail.com  Sun Feb 14 21:23:27 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 14 Feb 2010 14:23:27 -0600
Subject: [Rd] R CMD INSTALL customization; followup on Dirk's question
Message-ID: <13e802631002141223s12fc0c42ta2ba95fa10d0351a@mail.gmail.com>

Last year, Dirk E was asking about customizing options to for packages
when using R CMD INSTALL

http://tolstoy.newcastle.edu.au/R/e4/devel/08/06/1980.html

Has there been more on that question lately?

I also wonder what this means in the "Building Packages" section of
the R-Extensions manual:

"R CMD build can also build pre-compiled version of packages for
binary distributions, but R CMD INSTALL --build is preferred (and is
considerably more flexible). "

For an RPM-based Linux system, what are the possibilities for "binary
packages" in that sentence?

Here's why I ask.

I have to install R packages on each system in a cluster.  I would
like to build RPM packages for R packages and drop them into the
automatic updating system.  For some R packages, there are existing
RPM packages in the Fedora repos, but the list is not exhaustive.  I
do not want to spend my life fiddling R spec files package-by-package,
I just want to try to run the R CMD INSTALL lots of times, and if a
package builds then package them up.  Most packages do work without
customization, after all.  If a package fails, I can always look into
it later and customize the build for it, but I don't want to take the
"boutique" approach implicit in existing packaging efforts for RPMs
(such as R2spec).  I admire what Dirk did with cran2deb and if I had a
research assistant, I'd imitate that approach to make automatic RPMS
for all R packages and customize steps for packages that fail.

Did you ever use "checkinstall"?  It is a way to 'cheat' while making
RPM packages.  If you ordinarily do "configure" "make" "make install",
checkinstall It is used in place of "make install".  It can just
create the binary package from the installed files, without requiring
a lot of fiddling about.  Sure, its cheating, but even Captain Kirk
cheated when he needed to pass the Starfleet exam :).  Checkinstall
can take command line options for all the usual details that would go
into a spec file.

So, could I figure a way to embed "checkinstall" into the middle of
the process that goes on in R CMD INSTALL ??

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From cgenolin at u-paris10.fr  Sun Feb 14 22:18:08 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sun, 14 Feb 2010 22:18:08 +0100
Subject: [Rd] Portability of a C function
In-Reply-To: <4B77E932.2090401@dbmail.com>
References: <4B77E567.4060603@u-paris10.fr> <4B77E932.2090401@dbmail.com>
Message-ID: <4B786890.5080101@u-paris10.fr>

Thanks, this helps a lot.

So if I understand correctly:
in package P1, I want to export printMatrix and printMatrixInt. In my 
file P1.c, I have to add

void R_init_P1(DllInfo *info){
    R_registerCCallable("longitudinalData","printMatrix",printMatrix);
    R_registerCCallable("longitudinalData","printMatrixInt",printMatrixInt);
};


In P2.c, I have to add :

void R_init_P2(DllInfo *info){
    printMatrix = R_GetCCallable("longitudinalData","printMatrix");
    printMatrixInt = R_GetCCallable("longitudinalData","printMatrixInt");
};


I still have a problem here: "Writing R ext" say that 'printMatrix' and 
'printMatrixInt' should have "an appropriate declaration". What is the 
appropriate declaration?

Christophe


> Hello,
>
> This was discussed this week in the thread "LinkingTo and C++".
>
> It is possible, and documented in WRE section 5.4 : 
> http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines 
>
>
> Romain
>
> On 02/14/2010 12:58 PM, Christophe Genolini wrote:
>>
>> Hi the list,
>>
>> In a package P1, I write a function f1 in C, potentially an internal
>> function (not to be called from R).
>> In a package P2, I write a function f2 in C. The f2 function needs to
>> use f1 from P1. Is it possible ?
>>
>> --- 8< ---- In file P1.c ---------
>> double f1(x,y){
>> ....
>> }
>>
>> --- 8< ---- In file P2.c ---------
>> void f2(x,y,z){
>> double result;
>> ....
>> result = f1(x,y);
>> ....
>> }
>>
>> Thanks
>> Christophe
>


From jeff.a.ryan at gmail.com  Sun Feb 14 23:47:13 2010
From: jeff.a.ryan at gmail.com (J Ryan)
Date: Sun, 14 Feb 2010 16:47:13 -0600
Subject: [Rd] Portability of a C function
In-Reply-To: <4B786890.5080101@u-paris10.fr>
References: <4B77E567.4060603@u-paris10.fr> <4B77E932.2090401@dbmail.com>
	<4B786890.5080101@u-paris10.fr>
Message-ID: <AB84EAAD-E0DB-48C2-B60B-024DDB7E2F23@gmail.com>

Take a look here, as this may help clear up the unanswered questions:

https://stat.ethz.ch/pipermail/r-devel/2008-November/051262.html

HTH
Jeff

Jeffrey A. Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com

On Feb 14, 2010, at 3:18 PM, Christophe Genolini <cgenolin at u- 
paris10.fr> wrote:

> Thanks, this helps a lot.
>
> So if I understand correctly:
> in package P1, I want to export printMatrix and printMatrixInt. In  
> my file P1.c, I have to add
>
> void R_init_P1(DllInfo *info){
>   R_registerCCallable("longitudinalData","printMatrix",printMatrix);
>   R_registerCCallable 
> ("longitudinalData","printMatrixInt",printMatrixInt);
> };
>
>
> In P2.c, I have to add :
>
> void R_init_P2(DllInfo *info){
>   printMatrix = R_GetCCallable("longitudinalData","printMatrix");
>   printMatrixInt = R_GetCCallable 
> ("longitudinalData","printMatrixInt");
> };
>
>
> I still have a problem here: "Writing R ext" say that 'printMatrix'  
> and 'printMatrixInt' should have "an appropriate declaration". What  
> is the appropriate declaration?
>
> Christophe
>
>
>> Hello,
>>
>> This was discussed this week in the thread "LinkingTo and C++".
>>
>> It is possible, and documented in WRE section 5.4 : http://cran.r-project.org/doc/manuals/R-exts.html#Registering-native-routines
>>
>> Romain
>>
>> On 02/14/2010 12:58 PM, Christophe Genolini wrote:
>>>
>>> Hi the list,
>>>
>>> In a package P1, I write a function f1 in C, potentially an internal
>>> function (not to be called from R).
>>> In a package P2, I write a function f2 in C. The f2 function needs  
>>> to
>>> use f1 from P1. Is it possible ?
>>>
>>> --- 8< ---- In file P1.c ---------
>>> double f1(x,y){
>>> ....
>>> }
>>>
>>> --- 8< ---- In file P2.c ---------
>>> void f2(x,y,z){
>>> double result;
>>> ....
>>> result = f1(x,y);
>>> ....
>>> }
>>>
>>> Thanks
>>> Christophe
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bolker at ufl.edu  Mon Feb 15 04:56:41 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 15 Feb 2010 03:56:41 +0000 (UTC)
Subject: [Rd] Feature Request: Multiline Comments
References: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com>
Message-ID: <loom.20100215T045430-180@post.gmane.org>

Saptarshi Guha <saptarshi.guha <at> gmail.com> writes:

> 
> Hello,
> Is it possible to extend the R lexer/parser to include multiline comments like
> /*
> acomment
> 
> */
> ?
> This way I can integrate emacs org-mode with my R code, so that I can
> have a table of contents,
> section folding, html-output of source etc.
> 

  This comes up from time to time, and the typical answer is "no,
it's not that easy, block-commenting and -uncommenting is easy in
any code editor (including Emacs). However, there are a number of
R/Emacs/ESS gurus on this list, and maybe someone will answer your
more general "is there a way to integrate org-mode with my R code"
question ...

http://finzi.psych.upenn.edu/R/Rhelp02/archive/91555.html
> e.g
> /*
> * Display Code
> */
> #+BEGIN_SRC R
> 
> foo <- function(...){
> stuff
> }
> 
> #+end_src
> 
> and so on .
> 
> Thanks
> Saptarshi
> 
>


From mtmorgan at fhcrc.org  Mon Feb 15 06:39:16 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 14 Feb 2010 21:39:16 -0800
Subject: [Rd] org-mode (was Re:  Feature Request: Multiline Comments)
In-Reply-To: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com>
References: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com>
Message-ID: <4B78DE04.4000604@fhcrc.org>

On 02/14/2010 08:11 AM, Saptarshi Guha wrote:
> Hello,
> Is it possible to extend the R lexer/parser to include multiline comments like
> /*
> acomment
> 
> */
> ?
> This way I can integrate emacs org-mode with my R code, so that I can
> have a table of contents,
> section folding, html-output of source etc.

Hi Saptarshi --

Do you know about

  http://orgmode.org/worg/org-tutorials/org-R/org-R.php

?

Martin

> 
> e.g
> /*
> * Display Code
> */
> #+BEGIN_SRC R
> 
> foo <- function(...){
> stuff
> }
> 
> #+end_src
> 
> and so on .
> 
> Thanks
> Saptarshi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From eriki at ccbr.umn.edu  Mon Feb 15 07:01:40 2010
From: eriki at ccbr.umn.edu (Erik Iverson)
Date: Mon, 15 Feb 2010 00:01:40 -0600
Subject: [Rd] org-mode (was Re:  Feature Request: Multiline Comments)
In-Reply-To: <4B78DE04.4000604@fhcrc.org>
References: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com>
	<4B78DE04.4000604@fhcrc.org>
Message-ID: <4B78E344.9000301@ccbr.umn.edu>

Martin Morgan wrote:
> On 02/14/2010 08:11 AM, Saptarshi Guha wrote:
>   
>> Hello,
>> Is it possible to extend the R lexer/parser to include multiline comments like
>> /*
>> acomment
>>
>> */
>> ?
>> This way I can integrate emacs org-mode with my R code, so that I can
>> have a table of contents,
>> section folding, html-output of source etc.
>>     
>
> Hi Saptarshi --
>
> Do you know about
>
>   http://orgmode.org/worg/org-tutorials/org-R/org-R.php
>
> ?
>   

And also the very excellent org-babel, which can be used with R!

http://orgmode.org/worg/org-contrib/babel/index.php


From ripley at stats.ox.ac.uk  Mon Feb 15 08:41:10 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Feb 2010 07:41:10 +0000 (GMT)
Subject: [Rd] Incorrect Kendall's tau for ordered variables (PR#14207)
In-Reply-To: <alpine.LFD.2.00.1002081659410.12668@gannet.stats.ox.ac.uk>
References: <20100208044508.A22B7282EF3D@mail.pubhealth.ku.dk>
	<4B70103C.7030504@biostat.ku.dk>
	<alpine.LFD.2.00.1002081659410.12668@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.00.1002141956190.11769@gannet.stats.ox.ac.uk>

What seems a more serious error is that the current code (and Peter's 
modification) returns correlations computed from unordered factors, 
and there are examples in packages 'agsemisc', 'ggm' and 'mi'.
And in all cases these are Pearson correlations, as is the use of 
ordered factors in 'sfsmisc'.

The as.vector() seems to have been introduced to combat PR#7116, but 
it is not the right fix as swapping the 'x' and 'y' arguments in the 
regression example for that still crashed.  (It seems to me that the 
correct C-level fix is to check the length of the dimnames before 
trying to access the second element.)

It would be tricky to do the coercion right for ordered factors (or 
more general rankable classes): cor() accepts a data frame and does 
as.matrix() on it: if the data frame includes such columns the 
coercion has to be done column-by-column.  So I decided to pass the 
responsibility back to the caller, and only accept numeric arguments 
(as the help page says).  However, package 'mice' passes a logical 
matrix, and as we do usually silently promote logical to numeric I 
have continued to allow that.

Experience suggests that we have been too generous in doing autmatic 
coercion in the past.  It seems every time we tighten something up we 
find a handful of packages that got dubious results from inappropriate 
conversions.


On Mon, 8 Feb 2010, Prof Brian Ripley wrote:

> On Mon, 8 Feb 2010, Peter Dalgaard wrote:
>
>> msa at biostat.mgh.harvard.edu wrote:
>>> Full_Name: Marek Ancukiewicz
>>> Version: 2.10.1
>>> OS: Linux
>>> Submission from: (NULL) (74.0.49.2)
>>> 
>>> 
>>> Both cor() and cor.test() incorrectly handle ordered variables with
>>> method="kendall", cor() incorrectly handles ordered variables for
>>> method="spearman" (method="person" always works correctly, while
>>> method="spearman" works for cor.test, but not for cor()).
>>> 
>>> In erroneous calculations these functions ignore the inherent ordering
>>> of the ordered variable (e.g., '9'<'10'<'11') and instead seem to assume
>>> an alphabetic ordering ('10'<'11'<'9').
>> 
>> Strictly speaking, not a bug, since the documentation has
>>
>>       x: a numeric vector, matrix or data frame.
>> 
>> respectively
>>
>>    x, y: numeric vectors of data values.  ?x? and ?y? must have the
>>          same length.
>> 
>> so noone ever claimed that class "ordered" variables should work.
>> 
>> However, the root cause is that as.vector on a factor variable (ordered
>> or not) converts it to a character vector, hence
>> 
>>> rank(as.vector(as.ordered(9:11)))
>> [1] 3 1 2
>> 
>> Looks like a simple fix would be to use as.vector(x, "numeric") inside
>> the definition of cor().
>
> A fix for that particular case: the problem is that relies on the underlying 
> representation.  I think a better fix would be to do either of
>
> - test for numeric and throw an error otherwise, or
> - use xtfrm, which has the advantage of being more general and
>  allowing methods to be written (S3 or S4 methods in R-devel).
>
>> 
>> 
>>>> cor(9:11,1:3,method="k")
>>> [1] 1
>>>> cor(as.ordered(9:11),1:3,method="k")
>>> [1] -0.3333333
>>>> cor.test(as.ordered(9:11),1:3,method="k")
>>>
>>> 	Kendall's rank correlation tau
>>> 
>>> data:  as.ordered(9:11) and 1:3
>>> T = 1, p-value = 1
>>> alternative hypothesis: true tau is not equal to 0
>>> sample estimates:
>>>        tau
>>> -0.3333333
>>> 
>>>> cor(9:11,1:3,method="s")
>>> [1] 1
>>>> cor(as.ordered(9:11),1:3,method="s")
>>> [1] -0.5
>>>> cor.test(as.ordered(9:11),1:3,method="s")
>>>
>>> 	Spearman's rank correlation rho
>>> 
>>> data:  as.ordered(9:11) and 1:3
>>> S = 0, p-value = 0.3333
>>> alternative hypothesis: true rho is not equal to 0
>>> sample estimates:
>>> rho
>>>   1
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>> --
>>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From spencer.graves at structuremonitoring.com  Sat Feb 13 20:34:29 2010
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 13 Feb 2010 11:34:29 -0800
Subject: [Rd] Darwinian software development and the library function
In-Reply-To: <59d7961d1002130710t6c2507a5i177c26d173d94c97@mail.gmail.com>
References: <b7bfe54e1002111959l710b621fmc3b2a90d77a3771a@mail.gmail.com>	
	<4B75768F.8020904@prodsyse.com>	
	<b7bfe54e1002122240m4e633e03m3f3089096ef70d54@mail.gmail.com>
	<59d7961d1002130710t6c2507a5i177c26d173d94c97@mail.gmail.com>
Message-ID: <4B76FEC5.50307@structuremonitoring.com>

Hi, Charlotte:


       I'm with Henrik:  I don't know the global consequences of "print 
= function (...) base::print (...)", but I wouldn't do it.


       Writing "print.foo (x, ...)" may violate your sense of 
aesthetics, but I avoid it.  I've done things like that in the past, 
then changed them to match the standard.  I've also gotten others to 
change their code or agree to let me change it to match the standard.  
As I previously mentioned, some of the code in my "sos" package violates 
a standard.  However, there were more substantive reasons than just 
aesthetics.


       I hope you'll entertain other analogies:  If red lipstick is 
required for something I want to support, I'll wear red lipstick, even 
if I think blue would go better with my outfit.  Shaving is a pain in 
the face, and I wore a flaming red beard for a quarter century until it 
finally came in white.  Then I started shaving to avoid projecting the 
image of a broken down old man;  people said I looked 25 years younger.  
(Younger than what?)  You can post a question to r-devel in Urdu or 
Farsi, but I doubt of many people will reply.


       Hope this helps.
       Spencer


On 2/13/2010 7:10 AM, Henrik Bengtsson wrote:
> Hi.
>
> Here are some guidelines that I find useful:
>
> - Avoid changing the arguments of generic functions provided by the
> default R packages, especially the ones in base.  Just, accept those
> arguments.  If there are extra arguments you don't like, you can
> always add '...' to your method and they will be accepted/pass the R
> CMD check.
>
> - Using an S3 generic function that only has '...' arguments seems to
> work well and makes all methods for it pass R CMD check, regardless of
> what arguments you use in your methods.
>
> - Use R.methodS3 to define your methods, i.e. use setMethodS3("print",
> "foo", function(x, ...) { ... }).  This will check if there is a
> generic function or not, and if missing, it will be created.
> R.methodsS3 was created to make your S3 life easier.
>
> My $.02
>
> Henrik
>
> On Sat, Feb 13, 2010 at 7:40 AM, Charlotte Maia<maiagx at gmail.com>  wrote:
>    
>> Hi Spencer,
>>
>> Sorry, I wasn't very clear in my initial post.
>> The function print.foo (myfoo, ...) won't pass R check (unless one
>> overwrites print first).
>> One has to write print.foo (x, ...), which in my personal opinion, can
>> be problematic.
>>
>> In my oosp package, I have overwritten print (along with a few others).
>> Initially, I overwrote both print and print.default.
>> However now, I merely use print = function (...) base::print (...).
>>
>> Not really a generic, however it acts exactly the same (I think...).
>> Plus Rd documentation still documents print.mymethod in the usual way.
>>
>>
>> kind regards
>> Charlotte
>>
>>
>> On Sat, Feb 13, 2010 at 4:41 AM, spencerg<spencer.graves at prodsyse.com>  wrote:
>>      
>>> Hi, Charlotte:
>>>
>>>      I'm not sure what you mean.  If you mean writing something like
>>> "print.foo (myfoo, ...)", this is relatively benign I suppose, but I avoid
>>> it where feasible.  On multiple occasions, I've pushed collaborators and
>>> even maintainers of other packages to change this or allow me to change it
>>> to conform to the standard;  if my memory is correct, there have been
>>> several violations of this standard in the "fda" package, which are no
>>> longer there because I changed them.  If a user with an object "x" of class
>>> "foo" writes print(x=x) or print(foo=x), I'm not sure what it would do, but
>>> it might not be what you want.
>>>
>>>      My "sos" package masks "?".  However, I don't like it.  I generally
>>> consider such to be potentially user hostile, and whenever feasible, I
>>> prefer to avoid such code.  I did it in this case for a couple of reasons.
>>>   First, using "?" (actually "???") seems so much easier to remember than
>>> "findFn" that it justifies this transgression of standard protocol.  Second,
>>> one of the leading figures in the R community (Duncan Murdoch) contributed
>>> suggested we do this and contributed the code.
>>>
>>>      If you change the definition of "print" itself, that seems to me to be a
>>> much bigger issue, with consequences much more difficult to predict.  If
>>> someone else also overwrites "print" making it different and incompatible
>>> with yours, then your code may not work or theirs may not, depending on
>>> which gets loaded first in the search path.  Worse, your code cannot
>>> possibly have been tested as thoroughly as the standard code.  If your code
>>> includes a subtle bug that only occurs under special circumstances, it may
>>> be hard for the person experiencing the problem to find, because they don't
>>> expect it.
>>>
>>>      Hope this helps.
>>>      Spencer
>>>
>>>
>>> Charlotte Maia wrote:
>>>        
>>>> Hi all,
>>>>
>>>> Legend has it, that polite R programmers don't overwrite, say, the
>>>> print function.
>>>> However, this seems quite un-Darwinian to me (especially given that I
>>>> don't want to call all my arguments x and y).
>>>> I might want a function print.foo (myfoo, ...).
>>>>
>>>> So I decided to be very impolite (in one of my packages) and overwrite
>>>> a few standard generics.
>>>> Plus, to the best of my knowledge it doesn't interfere with normal use
>>>> (yay...).
>>>>
>>>> This brings us to the library function.
>>>> Which by default gives a whole lot of warnings loading my package (and
>>>> any other package that does something similar), scaring off polite R
>>>> programmers and perhaps some mainstream R users.
>>>>
>>>> I'm starting to think that the default for library, should be
>>>> warn.conflicts=FALSE.
>>>> However, just reading the documentation, I noticed a reference to
>>>> something called .conflicts.OK.
>>>> Not sure what that does, however if it does what it sounds like, then
>>>> it largely fixes the problem.
>>>>
>>>> The biggest issue though, is whether or not one should be impolite
>>>> (i.e. Darwinian) and overwrite print etc in the first place...?
>>>>
>>>> I'm inclined to go in favour of overwriting the functions.
>>>> However, it has the potential to introduce some technical problems.
>>>>
>>>> Other's opinions appreciated.
>>>>
>>>>
>>>> kind regards
>>>>
>>>>          
>>> --
>>> Spencer Graves, PE, PhD
>>> President and Chief Operating Officer
>>> Structure Inspection and Monitoring, Inc.
>>> 751 Emerson Ct.
>>> San Jos?, CA 95126
>>> ph:  408-655-4567
>>>
>>>
>>>        
>> --
>> Charlotte Maia
>> http://sites.google.com/site/maiagx
>>
>> ______________________________________________
>> R-devel at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>      
>


From A.R.Runnalls at kent.ac.uk  Mon Feb 15 18:00:08 2010
From: A.R.Runnalls at kent.ac.uk (A.R.Runnalls at kent.ac.uk)
Date: Mon, 15 Feb 2010 18:00:08 +0100 (CET)
Subject: [Rd] src/main/par.c (PR#14214)
Message-ID: <20100215170008.DAF33282EFC7@mail.pubhealth.ku.dk>

At lines 1154-5 in par.c (at the latest svn revision 47460), in function
do_par():

    if (new_spec && GRecording(call, dd))
	GErecordGraphicOperation(op, originalArgs, dd);

if the call GErecordGraphicOperation gives rise to a garbage collection
(as it may), the return value of do_par will be trashed.

(Discovered during CXXR development.)

Andrew


From saptarshi.guha at gmail.com  Mon Feb 15 19:26:04 2010
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 15 Feb 2010 13:26:04 -0500
Subject: [Rd] org-mode (was Re: Feature Request: Multiline Comments)
In-Reply-To: <4B78E344.9000301@ccbr.umn.edu>
References: <1e7471d51002140811w6cf02fd4x591a58aa13101ce9@mail.gmail.com> 
	<4B78DE04.4000604@fhcrc.org> <4B78E344.9000301@ccbr.umn.edu>
Message-ID: <1e7471d51002151026h60c8bef2t68e887fc0fd16833@mail.gmail.com>

Aah, yes I have read these. But my use is a bit different. I do not want R
output to be collected.  I wanted a nice IDE for R in emacs. So using
multiline comments and org-mode, i can have collapsible sections and
bookmarks in the source
.  I already use narrow-region to restrict views, but
its nice to open an R source file with a TOC, click on an entry and start
editing the function.

Thanks
saptarshi

On Mon, Feb 15, 2010 at 1:01 AM, Erik Iverson <eriki at ccbr.umn.edu> wrote:
> Martin Morgan wrote:
>>
>> On 02/14/2010 08:11 AM, Saptarshi Guha wrote:
>>
>>>
>>> Hello,
>>> Is it possible to extend the R lexer/parser to include multiline comments
>>> like
>>> /*
>>> acomment
>>>
>>> */
>>> ?
>>> This way I can integrate emacs org-mode with my R code, so that I can
>>> have a table of contents,
>>> section folding, html-output of source etc.
>>>
>>
>> Hi Saptarshi --
>>
>> Do you know about
>>
>> ?http://orgmode.org/worg/org-tutorials/org-R/org-R.php
>>
>> ?
>>
>
> And also the very excellent org-babel, which can be used with R!
>
> http://orgmode.org/worg/org-contrib/babel/index.php
>


From p.dalgaard at biostat.ku.dk  Mon Feb 15 20:02:21 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 15 Feb 2010 20:02:21 +0100
Subject: [Rd] src/main/par.c (PR#14214)
In-Reply-To: <20100215170008.DAF33282EFC7@mail.pubhealth.ku.dk>
References: <20100215170008.DAF33282EFC7@mail.pubhealth.ku.dk>
Message-ID: <4B799A3D.2040609@biostat.ku.dk>

A.R.Runnalls at kent.ac.uk wrote:
> At lines 1154-5 in par.c (at the latest svn revision 47460), in function
> do_par():
> 
>     if (new_spec && GRecording(call, dd))
> 	GErecordGraphicOperation(op, originalArgs, dd);
> 
> if the call GErecordGraphicOperation gives rise to a garbage collection
> (as it may), the return value of do_par will be trashed.
> 
> (Discovered during CXXR development.)

Thanks. Committed to r-devel r51142.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From hb at stat.berkeley.edu  Tue Feb 16 13:30:13 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 16 Feb 2010 13:30:13 +0100
Subject: [Rd] FYI: A case that the code validation of R CMD check misses
Message-ID: <59d7961d1002160430n4774bc65l8b1ba90b74c4b296@mail.gmail.com>

Hi,

I discovered a case where the code validation of R CMD check fails to
detect this issue.   If a non-existing is defined/assigned in the same
function as a non-existing object is used, it passes unnoticed.  For
example,

foo <- function(...) {
  nonExistingDummy1 <- nonExistingDummy1(...);
  nonExistingDummy2 <- nonExistingDummy2;
  res <- nonExistingDummy3(...);
  nonExistingDummy3 <- function(...) {};
}

gives

...
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK

Tested on Windows Vista with:

R version 2.10.1 Patched (2010-01-12 r50990)
R version 2.11.0 Under development (unstable) (2010-02-14 r51138)

Just a note

Henrik


From jel+r at cs.uni-magdeburg.de  Tue Feb 16 19:31:56 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Tue, 16 Feb 2010 19:31:56 +0100
Subject: [Rd] R_LIBS_USER bugs
Message-ID: <20100216183156.GA8582@trex.cs.uni-magdeburg.de>

Hi,


Having currently a big problem with R 2.10.1 vanilla (Solaris):

As soon as the R_LIBS_USER env var gets bigger than 1023 chars R
completely ignores it and uses the default:

> Sys.getenv('R_LIBS_USER');
                                          R_LIBS_USER 
"${R_LIBS_USER-~/R/i386-pc-solaris2.11-library/2.10}" 


The strange thing is, if I set another envar to the same value, there
seems to be no problem at all.  E.g.:

BLA=/develop/lnf/i386/R/LNFr-car/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-Formula/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-lmtest/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-sandwich/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-strucchange/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-zoo/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-dynlm/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-ineq/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-KernSmooth/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-np/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-plm/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-pscl/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-ROCR/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-sampleSelection/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-systemfit/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-tseries/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-urca/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-quantreg/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-mvtnorm/reloc/R-2.10/library:/develop/lnf/i386/R/LNFr-leaps/reloc/R-2.10/library
elkner.idev2 ~ > echo $BLA | wc
1       1    1065
elkner.idev2 ~ > R                   
...
> Sys.getenv('BLA') 
...
                       BLA 
"/develop/lnf/i386/R/LNFr-car/reloc/R-2.10/library:...:/develop/lnf/i386/R/LNFr-leaps/reloc/R-2.10/library"
>

Any hints, what magic is going on here?

Regards,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From martin.becker at mx.uni-saarland.de  Wed Feb 17 16:24:17 2010
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Wed, 17 Feb 2010 16:24:17 +0100
Subject: [Rd] suggestion: tiny documentation improvement for R-admin
Message-ID: <4B7C0A21.90300@mx.uni-saarland.de>

Dear developers,

I want to suggest a tiny documentation improvement for R-admin in 
subsection 3.1 ('Building from source') of 'Installing R under Windows'.
Although it is mentioned in subsection 3.1.3 that one has to enter 
?R_HOME/src/gnuwin32? before running 'make all recommended', I think it 
would be favourable to note this already in subsection 3.1.2, where the 
first 'make' commands pop up.
Please find attached a corresponding patch for rev. 51148.

Thanks,

Martin

-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 206
66123 Saarbruecken
Germany

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-admin.texi.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100217/2bfb8ee8/attachment.pl>

From seth at userprimary.net  Wed Feb 17 16:49:20 2010
From: seth at userprimary.net (Seth Falcon)
Date: Wed, 17 Feb 2010 07:49:20 -0800
Subject: [Rd] R_LIBS_USER bugs
In-Reply-To: <20100216183156.GA8582@trex.cs.uni-magdeburg.de>
References: <20100216183156.GA8582@trex.cs.uni-magdeburg.de>
Message-ID: <4B7C1000.2050901@userprimary.net>

Hi,

On 2/16/10 10:31 AM, Jens Elkner wrote:
> Having currently a big problem with R 2.10.1 vanilla (Solaris):
> 
> As soon as the R_LIBS_USER env var gets bigger than 1023 chars R
> completely ignores it and uses the default:

I guess the first question is, why do need such a long list of library
directories?

>> Sys.getenv('R_LIBS_USER');
>                                           R_LIBS_USER 
> "${R_LIBS_USER-~/R/i386-pc-solaris2.11-library/2.10}" 

I see the same thing with R-devel on OS X.  I can set R_LIBS_USER from
within R using Sys.setenv to a value longer than 1024 and retrieve it
again.  But if I have such a value in my shell, it gets overwritten.

I'm not yet sure what is going on.

+ seth


From georgi.boshnakov at manchester.ac.uk  Thu Feb 18 11:43:11 2010
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 18 Feb 2010 10:43:11 +0000
Subject: [Rd] install.packages, normalizePath, file permissions
Message-ID: <20100218104311.3130687nyivhp03j@webmail.manchester.ac.uk>

Dear developers,

I have a small but more or less well defined inquiry. Another, more  
general one for which I was not able to find information is towards  
the end of this messages. The question seems to be too technical for  
R-help, that is why I post it here.

When installing packages (Windows XP), occasionally the installation  
does not complete because, it seems, Windows locks some files. I  
normally ignore this as a minor annoyance but now I wish to ask  
students to install a number of often used packages by sourcing an R  
file and this becomes a problem.

Here is an example:

> install.packages( file.path(fp,"fgui_1.0-0.zip"     ), repos=NULL)
Warning in install.packages(file.path(fp, "fgui_1.0-0.zip"), repos = NULL) :
   argument 'lib' is missing: using 'p:/Rpack'
package 'fgui' successfully unpacked and MD5 sums checked
Error in normalizePath(path) :
   path[1]="p:\Rpack/fgui": The system cannot find the file specified


The circumstances are difficult to reproduce. For some reason, the  
system does not like "fgui" and maybe other packages. The p: drive  
above is network attached and and I have read/write access. Here is  
the result of traceback.

> traceback()
7: normalizePath(instPath)
6: sprintf(gettext(fmt, domain = domain), ...)
5: gettextf("unable to move temporary installation '%s' to '%s'",
        normalizePath(file.path(tmpDir, curPkg)), normalizePath(instPath))
4: warning(gettextf("unable to move temporary installation '%s' to '%s'",
        normalizePath(file.path(tmpDir, curPkg)), normalizePath(instPath)),
        domain = NA, call. = FALSE, immediate. = TRUE)
3: unpackPkg(pkgs[i], pkgnames[i], lib)
2: .install.winbinary(pkgs = pkgs, lib = lib, contriburl = contriburl,
        method = method, available = available, destdir = destdir,
        dependencies = dependencies, ...)
1: install.packages(file.path(fp, "fgui_1.0-0.zip"), repos = NULL)

The error seems to be thrown by the folloing chunk towards the end of  
.install.winbinary():

   ret <- file.rename(file.path(tmpDir, curPkg), instPath)
   if(!ret)
     warning(gettextf("unable to move temporary installation '%s' to '%s'",
                      normalizePath(file.path(tmpDir, curPkg)),
                      normalizePath(instPath)),
              domain = NA, call. = FALSE, immediate. = TRUE)
   ...

Apparently, renaming failed and a message is displayed.
The failure of rename.file may have left the directory specified by  
'instPath' non-existent which may cause normalizePath to fail. When  
this happens
the message printed is not that of warninig() but the one from  
normalizePath() which is uninformative for the user. Maybe an  
additional check here would be appropriate and, given that the  
installation has been basically successful at this point, even an  
attempt to copy the directory after the refusal by Windows to rename  
it? I understand of course that the developers have better things to  
do than to wrestle with the caprice of Windows.


====
Here is a more general enquiry.

I am using R in a statistics course (about 100) students in a computer  
cluster where R is installed on a server, students run WindowsXP and  
to my understanding the program is run by something called "Zen". It  
seems that if a number of students try loading packages, things become  
extremely slow and loading fails for some.

The IT services claim that R is the culprit, I am not sure and  
certainly part of the problem is related to the slow speed of the  
network, but a few problems seem to be related to permissions. I tried  
using options(timeout=N) even trying ridiculous values for N but this  
did not improve things.

I was not able to trace discussions of such issues and wonder if  
somebody has encountered similar problems.

I am about to try ask the students to install some packages in their  
area (called p: drive at this Uni) which prompted the first question  
above.

Thank you for any suggestions,
Georgi


-- 
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


From yvesalexandre at hotmail.com  Thu Feb 18 15:08:23 2010
From: yvesalexandre at hotmail.com (Yva)
Date: Thu, 18 Feb 2010 06:08:23 -0800 (PST)
Subject: [Rd] tm installation (PR#14193)
In-Reply-To: <20100125162009.377CD282EF42@mail.pubhealth.ku.dk>
References: <20100125162009.377CD282EF42@mail.pubhealth.ku.dk>
Message-ID: <1266502103314-1560172.post@n4.nabble.com>


Go the exact same problem. I'm on the same configuration:

Karmic (9.10) & R version 2.9.2 (2009-08-24)
-- 
View this message in context: http://n4.nabble.com/tm-installation-PR-14193-tp1290248p1560172.html
Sent from the R devel mailing list archive at Nabble.com.


From taylor.russ at gmail.com  Thu Feb 18 18:12:56 2010
From: taylor.russ at gmail.com (rt)
Date: Thu, 18 Feb 2010 11:12:56 -0600
Subject: [Rd] R CMD check: OK in LINUX. Crashes in Windows!
Message-ID: <d6243f3f1002180912n5b75b387s207f1763cf22b671@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100218/f9f6a6de/attachment.pl>

From pauljohn32 at gmail.com  Thu Feb 18 18:33:14 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 18 Feb 2010 11:33:14 -0600
Subject: [Rd] Where does install.R go when R gets compiled? Or,
	how to experiment 	with changes to install.R?
Message-ID: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>

Hello, everybody.

I apologize if this is obvious.  I've not tried to make changes in R
code within the R source itself before.

I'm pursuing an experiment to make RPM files for R packages
on-the-fly. Any time I install an R package successfully, I want to
wrap up those files in an RPM.   Basically, the idea is to "hack" an
option similar to --build for R CMD INSTALL.

I observe in the R source code this is the file that handles installs

src/library/tools/R/install.R

The R DESCRIPTION file has the information required and the code in
install.R is quite clear and easy to understand. I *think* I see what
I need to do.

But I don't understand how to test the effect of my changes without
re-compiling R and re-installing it.

In the installed R, there is no file "install.R", so there's no
obvious place to hack on it.

Is it actually necessary to recompile & re-install R every time I want
to test changes to that file?

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From jel+r at cs.uni-magdeburg.de  Thu Feb 18 21:20:31 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Thu, 18 Feb 2010 21:20:31 +0100
Subject: [Rd] Where does install.R go when R gets compiled? Or,
	how to experiment 	with changes to install.R?
In-Reply-To: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>
References: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>
Message-ID: <20100218202031.GA11744@trex.cs.uni-magdeburg.de>

On Thu, Feb 18, 2010 at 11:33:14AM -0600, Paul Johnson wrote:
Hello, everybody.
  
> I apologize if this is obvious.  I've not tried to make changes in R
> code within the R source itself before.
> 
> I'm pursuing an experiment to make RPM files for R packages
> on-the-fly. Any time I install an R package successfully, I want to
> wrap up those files in an RPM.   Basically, the idea is to "hack" an
> option similar to --build for R CMD INSTALL.

Hmm, why not take the easy way:

    clean_dst $PROTO
    cd $TMPBUILD
    mkdir -p $PROTO/R/library
    $R_HOME/bin/R CMD INSTALL -l $PROTO/R/library $TMPBUILD

$PROTO is the directory, where the R module gets installed (e.g. /tmp/R),
$TMPBUILD is the directory with the R module sources (e.g. /tmp/build/quantreg)
and the rest is obvious.

Than you need to care about/package $PROTO/R/library, only. 

Built about 150 R packages this way 4 Solaris without any pkg problems ...

Regards,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From kmmatoba at stanford.edu  Thu Feb 18 22:54:19 2010
From: kmmatoba at stanford.edu (Kyle Matoba)
Date: Thu, 18 Feb 2010 13:54:19 -0800
Subject: [Rd] pictex
Message-ID: <b72a69661002181354i7f6776cem27cb8ef3839f7286@mail.gmail.com>

The example at ?pictex does not work (the driver apparently uses
'rotatebox') for me as stated.  It did compile after including the
graphicsx package.  A MWE is at the help page for pictex.  I tried to
get in touch with Valerio but his email bounced.  Probably we want to
add a \usepackage{graphicsx} to the help page and try to track down
Valerio.

Cheers,

Kyle


This is pdfTeX, Version 3.1415926-1.40.10 (TeX Live 2009)

> sessionInfo()
R version 2.10.1 (2009-12-14)
x86_64-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.10.1


From ripley at stats.ox.ac.uk  Fri Feb 19 09:55:29 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Feb 2010 08:55:29 +0000 (GMT)
Subject: [Rd] pictex
In-Reply-To: <b72a69661002181354i7f6776cem27cb8ef3839f7286@mail.gmail.com>
References: <b72a69661002181354i7f6776cem27cb8ef3839f7286@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1002190845020.9732@gannet.stats.ox.ac.uk>

Thank you for the comments.  That driver dates from 1997 or so, and I 
believe we failed to contact the author several years ago, but a later 
email address is in the THANKS file.

It is really present for historical reasons, and other things change 
-- so I have added LaTeX package graphics (although graphicx will do, 
graphics suffices) and removed the Plain TeX example.

The tikzDevice in the package of that name might be a suitable 
replacement.

On Thu, 18 Feb 2010, Kyle Matoba wrote:

> The example at ?pictex does not work (the driver apparently uses
> 'rotatebox') for me as stated.  It did compile after including the
> graphicsx package.  A MWE is at the help page for pictex.  I tried to
> get in touch with Valerio but his email bounced.  Probably we want to
> add a \usepackage{graphicsx} to the help page and try to track down
> Valerio.
>
> Cheers,
>
> Kyle
>
>
> This is pdfTeX, Version 3.1415926-1.40.10 (TeX Live 2009)
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.10.1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gb at stat.umu.se  Fri Feb 19 12:25:52 2010
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 19 Feb 2010 12:25:52 +0100
Subject: [Rd] Building  R  fails
Message-ID: <4B7E7540.1050408@stat.umu.se>

I'm trying to build R-patched_2010-02-17.tar.gz, 'make' ends with

make[2]: Entering directory 
`/usr/local/src/R/R-patched/src/library/Recommended'
begin installing recommended package boot
Loading required package: survival
Error: package 'survival' could not be loaded
In addition: Warning message:
In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc) :
   there is no package called 'survival'
Execution halted
make[2]: *** [boot.ts] Error 1
make[2]: Leaving directory 
`/usr/local/src/R/R-patched/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory 
`/usr/local/src/R/R-patched/src/library/Recommended'
make: *** [stamp-recommended] Error 2

# uname -a
Linux tal 2.6.31-19-generic #56-Ubuntu SMP Thu Jan 28 02:39:34 UTC 2010 
x86_64 GNU/Linux

G?ran


From t.jombart at imperial.ac.uk  Thu Feb 18 12:30:38 2010
From: t.jombart at imperial.ac.uk (Jombart, Thibaut)
Date: Thu, 18 Feb 2010 11:30:38 +0000
Subject: [Rd] Sweave in PNG: driver online
Message-ID: <0B75A6276180B546A1CA8D2B46E7580503290BBE49@ICEXM3.ic.ac.uk>

Dear R addicts, 

Back in 2006, I posted the proposition for a tweak of the Sweave driver so that PNG figures can be produced instead of eps/pdf :
https://stat.ethz.ch/pipermail/r-help/2006-March/102122.html

The amount of code modified is tiny (it was designed to induce minimal changes to the official code), but so far the driver seems to have been useful to a number of users. From 2006 on, successive versions of the code were supposed to incorporate the official driver. My current understanding is that this tweak won't incorporate the official release, although an alternative approach is still supposed to take place eventually. 

Meanwhile, a fairly recent update of the alternative driver can be found online from my website:
http://sites.google.com/site/thibautjombart/r-packages

A vignette describes briefly the new features and how the driver can be used.

Best regards,

Thibaut.

-- 
######################################
Dr Thibaut JOMBART
MRC Centre for Outbreak Analysis and Modelling
Department of Infectious Disease Epidemiology
Imperial College - Faculty of Medicine
St Mary?s Campus
Norfolk Place
London W2 1PG
United Kingdom
Tel. : 0044 (0)20 7594 3658
t.jombart at imperial.ac.uk
http://sites.google.com/site/thibautjombart/
http://adegenet.r-forge.r-project.org/


From t.heaton at shef.ac.uk  Thu Feb 18 16:10:09 2010
From: t.heaton at shef.ac.uk (t.heaton at shef.ac.uk)
Date: Thu, 18 Feb 2010 16:10:09 +0100 (CET)
Subject: [Rd] Error in coding for splinefun(method = "monoH.FC") (PR#14215)
Message-ID: <20100218151009.D88C72830314@mail.pubhealth.ku.dk>

Full_Name: Tim Heaton
Version: 2.8.1
OS: linux-gnu
Submission from: (NULL) (143.167.4.162)


Hi,

 In my version of R, the stats package splinefun code for fitting a
Fritsch and Carlson monotonic spline does not guarantee a
monotonic result. If two adjoining sections both have over/undershoot
the way the resulting adjustment of alpha and beta is performed can give
modified values which still do not satisfy the required constraints. I posed the
question as to whether this was a known error on the R help but got no reply,
have also had a look through the bug database but couldn't find anything.

Below is an example created to demonstrate this,

###############################################
# Create the following data
# This is created so that their are two adjoining sections which have to
be adjusted
x <- 1:8
y <- c(-12, -10, 3.5, 4.45, 4.5, 140, 142, 142)

# Now run the splinefun() function

FailMonSpline <- splinefun(x, y, method = "mono")

# In theory this should be monotonic increasing but the required
conditions are not satisfied

# Check values of alpha and beta for this curve
m <- FailMonSpline(x, deriv = 1)
nx <- length(x)
n1 <- nx - 1L
dy <- y[-1] - y[-nx]
dx <- x[-1] - x[-nx]
Sx <- dy/dx

alpha <- m[-nx]/Sx
beta <- m[-1]/Sx
a2b3 <- 2 * alpha + beta - 3
ab23 <- alpha + 2 * beta - 3
ok <- (a2b3 > 0 & ab23 > 0)
ok <- ok & (alpha * (a2b3 + ab23) < a2b3^2)
# If the curve is monotonic then all ok should be FALSE however this is
not the case
ok


# Alternatively can easily seen to be non-monotonic by plotting the
region between 4 and 5

t <- seq(4,5, length = 200)
plot(t, FailMonSpline(t), type = "l")

########################################################
The version of R I am running is

platform       x86_64-suse-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          8.1
year           2008
month          12
day            22
svn rev        47281
language       R
version.string R version 2.8.1 (2008-12-22)


From Jerry.Lewis at biogenidec.com  Thu Feb 18 23:00:12 2010
From: Jerry.Lewis at biogenidec.com (Jerry.Lewis at biogenidec.com)
Date: Thu, 18 Feb 2010 23:00:12 +0100 (CET)
Subject: [Rd] pchisq accuracy (PR#14216)
Message-ID: <20100218220012.4207C282EFCB@mail.pubhealth.ku.dk>

Full_Name: Jerry W. Lewis
Version: 2.10.1
OS: Windows XP Professional
Submission from: (NULL) (166.186.168.21)


Since
  pchisq(x,df,ncp,lower.tail,TRUE)
is calculated as
  log(pchisq(x,df,ncp,lower.tail))
it looses accuracy when pchisq(x,df,ncp,lower.tail) is near 1.  Accuracy can be
maintained in that case by replacing the existing calculation with
  log1p(-pchisq(x,df,ncp,!lower.tail))


From gb at stat.umu.se  Fri Feb 19 17:17:12 2010
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 19 Feb 2010 17:17:12 +0100
Subject: [Rd] Building  R  fails
In-Reply-To: <4B7E7540.1050408@stat.umu.se>
References: <4B7E7540.1050408@stat.umu.se>
Message-ID: <4B7EB988.3050402@stat.umu.se>

I found a hack to avoid this bug(?): My personal .Rprofile file loads 
'survival'. The hack is to remove/rename the file.

Another hack is to log in (su -) as root (sudo -s doesn't help).
This behaviour is also present when I run 'update.packages', even if I 
start  R  by 'sudo R --vanilla'! I have reported this to R-help.

Should I report this to R-bugs?

G?ran



G?ran Brostr?m wrote:
> I'm trying to build R-patched_2010-02-17.tar.gz, 'make' ends with
> 
> make[2]: Entering directory 
> `/usr/local/src/R/R-patched/src/library/Recommended'
> begin installing recommended package boot
> Loading required package: survival
> Error: package 'survival' could not be loaded
> In addition: Warning message:
> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
> lib.loc) :
>   there is no package called 'survival'
> Execution halted
> make[2]: *** [boot.ts] Error 1
> make[2]: Leaving directory 
> `/usr/local/src/R/R-patched/src/library/Recommended'
> make[1]: *** [recommended-packages] Error 2
> make[1]: Leaving directory 
> `/usr/local/src/R/R-patched/src/library/Recommended'
> make: *** [stamp-recommended] Error 2
> 
> # uname -a
> Linux tal 2.6.31-19-generic #56-Ubuntu SMP Thu Jan 28 02:39:34 UTC 2010 
> x86_64 GNU/Linux
> 
> G?ran
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
G?ran Brostr?m               phone: +46 90 786 5223
Department of Statistics,    fax: +46 90 786 6614
Ume? University              email: gb at stat.umu.se
SE-90187 Ume?, Sweden        http://tal.stat.umu.se/~gb


From pdevalpine at berkeley.edu  Fri Feb 19 17:54:25 2010
From: pdevalpine at berkeley.edu (Perry de Valpine)
Date: Fri, 19 Feb 2010 08:54:25 -0800
Subject: [Rd] expression(pi) produces not-equal symbol in X11 plot
Message-ID: <AA562743-E819-4987-A6E6-025A9C300595@berkeley.edu>

On R 2.10.1 on OS X (10.6.2) using an X11() device,
plot(1:10, 1:10, main = expression(pi))
makes a not-equal symbol instead of a pi symbol.

Other Greek letters (including capital Pi) seem to work.  On a quartz device the pi symbol is displayed correctly.

I don't know if the issue is on the R side, but I post it here in case anyone knows where to go with it.

Perry


From ligges at statistik.tu-dortmund.de  Fri Feb 19 18:27:52 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 19 Feb 2010 18:27:52 +0100
Subject: [Rd] R CMD check: OK in LINUX. Crashes in Windows!
In-Reply-To: <d6243f3f1002180912n5b75b387s207f1763cf22b671@mail.gmail.com>
References: <d6243f3f1002180912n5b75b387s207f1763cf22b671@mail.gmail.com>
Message-ID: <4B7ECA18.1070607@statistik.tu-dortmund.de>

Hard to say anything if we do not see any details from your package, but 
very likely you just had some luck under Ubuntu not to see any crashes...

Uwe Ligges



On 18.02.2010 18:12, rt wrote:
> Hi,
>
> I have followed the recommended steps for creating a package (rctest). As of
> now, my goal is simply to understand how various pieces fit together. The
> package includes:
> (1) C code with source in sub-directories, compiled to create a static
> library.
> (a) There is a single C-struct (dns) a simple 'matrix': {int m; int n;
> double *d;}
> (b) C code to create random matrix of a certain size.
> (c) C code to free a dns object.
>
> (2) R-C wrappers.
>   (a) There is an S4 class (RDns) with a single slot, an external pointer to
> a C-struct (dns).
>   (b) C code to create an RDns object from an R matrix. Data from the R
> matrix is copied to the C dns object.
>   (c) C code to copy data from an RDns object to an R matrix.
>   (d)  init.c with registration routines and also a finalizer for the
> external pointer.
> (3) Makevars, NAMESPACE, Registration etc.
> (4) Documentation for all exported functions.
>
> The package passes all tests in R CMD check under Ubuntu. Everything seems
> to work fine.
>
> In Windows (using Rtools), R CMD check crashes at the end of the check.  At
> various times, the log indicates that all checks were OK and the pdf manual
> was created. Yet the console crashes.
> At other times "examples" fail to run and console crashes. However, the
> actual package loads fine and all of the functions work just fine from
> within R. Finalizer also works as expected when invoked by gc().
>
> At this point, I do not have any idea as to where or how I should look for
> the source of the problem. I am afraid, there may be something wrong with my
> code, but am not sure how to search for the bug.
> What other tests should I create to perform extensive tests that all parts
> of the code work as expected??
>
> Any help will be appreciated.
>
> Thanks,
> bug.
>
> Russ
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Fri Feb 19 22:05:16 2010
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 19 Feb 2010 16:05:16 -0500
Subject: [Rd] sample on data.frame
Message-ID: <8b356f881002191305p4830fc46w69de1f90b7880ae8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100219/6de14f7f/attachment.pl>

From olafm at statistik.tu-dortmund.de  Fri Feb 19 23:02:06 2010
From: olafm at statistik.tu-dortmund.de (Olaf Mersmann)
Date: Fri, 19 Feb 2010 23:02:06 +0100
Subject: [Rd] Small documentation fix for [.data.frame
Message-ID: <1266616819-sup-5685@bloxx.local>

Hello,

in the manual page for [.data.frame it reads:

  ... There is a method for replacement which checks \code{value} for
  the corrupt number of row, and replicates it if necessary. ...

This should probably read

  ... There is a method for replacement which checks \code{value} for
  the correct number of rows, and replicates it if necessary. ...

A trivial patch changing this is can be found here:

  http://www.statistik.tu-dortmund.de/~olafm/temp/edf_doc.patch
 
Cheers,
Olaf Mersmann


From olafm at statistik.tu-dortmund.de  Sat Feb 20 00:00:35 2010
From: olafm at statistik.tu-dortmund.de (Olaf Mersmann)
Date: Sat, 20 Feb 2010 00:00:35 +0100
Subject: [Rd] Fix for incorrect use of restrict in xz third party code
Message-ID: <1266619960-sup-1764@bloxx.local>

Hello,

the included XZ Utils source code contains an incorrect use of the
restrict keyword. This leads to data corruption under certain
circumstances. For a short discussion of the problem see

  http://sourceforge.net/projects/lzmautils/forums/forum/708858/topic/3306733

This was fixed in the XZ Utils git repository in commit 

  commit 49cfc8d392cf535f8dd10233225b1fc726fec9ef
  Author: Lasse Collin <lasse.collin at tukaani.org>
  Date:   Tue Sep 15 21:07:23 2009 +0300

    Fix incorrect use of "restrict".

Since then, there has not been a proper release of the XZ Utils so I
have applied said patch to the sources included in R and added a note
to the R_changes file in the src/extra/xz/ directory detailing the
changes.

This 'bug' is only triggered if the Intel C or gcc 4.4 is used to
compile R and the included liblzma is used instead of a system wide
one, so it might not be worth the trouble of patching the sources
instead of waiting for a new release. If anyone wants to apply a fix,
I have prepared a patch with all the changes which can be found here

  http://www.statistik.tu-dortmund.de/~olafm/temp/xz_restrict.patch

Cheers,
Olaf Mersmann


From pauljohn32 at gmail.com  Sat Feb 20 00:04:25 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 19 Feb 2010 17:04:25 -0600
Subject: [Rd] Where does install.R go when R gets compiled? Or,
	how to 	experiment with changes to install.R?
In-Reply-To: <20100218202031.GA11744@trex.cs.uni-magdeburg.de>
References: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>
	<20100218202031.GA11744@trex.cs.uni-magdeburg.de>
Message-ID: <13e802631002191504n349f30b1g43e5bec088a94998@mail.gmail.com>

On Thu, Feb 18, 2010 at 2:20 PM, Jens Elkner <jel+r at cs.uni-magdeburg.de> wrote:
> On Thu, Feb 18, 2010 at 11:33:14AM -0600, Paul Johnson wrote:
>> I'm pursuing an experiment to make RPM files for R packages
>> on-the-fly. Any time I install an R package successfully, I want to
>> wrap up those files in an RPM. ? Basically, the idea is to "hack" an
>> option similar to --build for R CMD INSTALL.
>
> Hmm, why not take the easy way:
>
> ? ?clean_dst $PROTO
> ? ?cd $TMPBUILD
> ? ?mkdir -p $PROTO/R/library
> ? ?$R_HOME/bin/R CMD INSTALL -l $PROTO/R/library $TMPBUILD
>
Yes, I've been there, done that.

I have to administer this on 60 servers in a cluster.  I don't want to
rebuild all packages on all systems. If I can figure a way to create
RPM for them, I can script the RPM installs and then I'm sure all the
systems are identical.

In the worst case scenario, I just have to copy the library tree from
one machine to another.  But the RPM approach has a bit more built-in
error checking.

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From yeahzx at yeah.net  Sat Feb 20 05:58:07 2010
From: yeahzx at yeah.net (yeahzx)
Date: Sat, 20 Feb 2010 12:58:07 +0800 (CST)
Subject: [Rd] how to create a SEXP which could be accessed in embedded R
Message-ID: <15308325.48ac.126e9bd5f7d.Coremail.yeahzx@yeah.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100220/f7863536/attachment.pl>

From jel+r at cs.uni-magdeburg.de  Sat Feb 20 07:02:27 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Sat, 20 Feb 2010 07:02:27 +0100
Subject: [Rd] R_LIBS_USER bugs
In-Reply-To: <4B7C1000.2050901@userprimary.net>
References: <20100216183156.GA8582@trex.cs.uni-magdeburg.de>
	<4B7C1000.2050901@userprimary.net>
Message-ID: <20100220060227.GA16852@trex.cs.uni-magdeburg.de>

On Wed, Feb 17, 2010 at 07:49:20AM -0800, Seth Falcon wrote:
Hi,
> 
> On 2/16/10 10:31 AM, Jens Elkner wrote:
> > Having currently a big problem with R 2.10.1 vanilla (Solaris):
> > 
> > As soon as the R_LIBS_USER env var gets bigger than 1023 chars R
> > completely ignores it and uses the default:

BTW: Sometimes even more than 1000 chars cause an 'overflow' ...

> I guess the first question is, why do need such a long list of library
> directories?

E.g. for a clean/uncluttered build system. Distributed filesystem for
several hundred students is another use case ...
  
> >> Sys.getenv('R_LIBS_USER');
> >                                           R_LIBS_USER 
> > "${R_LIBS_USER-~/R/i386-pc-solaris2.11-library/2.10}" 
> 
> I see the same thing with R-devel on OS X.  I can set R_LIBS_USER from
> within R using Sys.setenv to a value longer than 1024 and retrieve it
> again.  But if I have such a value in my shell, it gets overwritten.

Strange and buggy IMHO ...

Regards,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From ripley at stats.ox.ac.uk  Sat Feb 20 08:17:14 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Feb 2010 07:17:14 +0000 (GMT)
Subject: [Rd] Fix for incorrect use of restrict in xz third party code
In-Reply-To: <1266619960-sup-1764@bloxx.local>
References: <1266619960-sup-1764@bloxx.local>
Message-ID: <alpine.LFD.2.00.1002200711230.25269@gannet.stats.ox.ac.uk>

On Sat, 20 Feb 2010, Olaf Mersmann wrote:

> Hello,
>
> the included XZ Utils source code contains an incorrect use of the
> restrict keyword. This leads to data corruption under certain
> circumstances. For a short discussion of the problem see
>
>  http://sourceforge.net/projects/lzmautils/forums/forum/708858/topic/3306733
>
> This was fixed in the XZ Utils git repository in commit
>
>  commit 49cfc8d392cf535f8dd10233225b1fc726fec9ef
>  Author: Lasse Collin <lasse.collin at tukaani.org>
>  Date:   Tue Sep 15 21:07:23 2009 +0300
>
>    Fix incorrect use of "restrict".
>
> Since then, there has not been a proper release of the XZ Utils so I
> have applied said patch to the sources included in R and added a note
> to the R_changes file in the src/extra/xz/ directory detailing the
> changes.
>
> This 'bug' is only triggered if the Intel C or gcc 4.4 is used to
> compile R and the included liblzma is used instead of a system wide
> one, so it might not be worth the trouble of patching the sources
> instead of waiting for a new release. If anyone wants to apply a fix,
> I have prepared a patch with all the changes which can be found here
>
>  http://www.statistik.tu-dortmund.de/~olafm/temp/xz_restrict.patch

We had been waiting for xz 5.000, but decided to go with 4.999 
for R 2.10.0 as it was so long a-coming -- and are still waiting.

We do use the included sources on several platforms, and with gcc 
4.4.4 on 64-bit Windows, so I will patch this, thank you.

>
> Cheers,
> Olaf Mersmann

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sean.oriordain at gmail.com  Sat Feb 20 09:44:07 2010
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sat, 20 Feb 2010 08:44:07 +0000
Subject: [Rd] sample on data.frame
In-Reply-To: <8b356f881002191305p4830fc46w69de1f90b7880ae8@mail.gmail.com>
References: <8b356f881002191305p4830fc46w69de1f90b7880ae8@mail.gmail.com>
Message-ID: <8ed68eed1002200044r7e7af682lbd45df5a8eb95e39@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100220/3504e5dd/attachment.pl>

From romain at r-enthusiasts.com  Sat Feb 20 10:39:23 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Sat, 20 Feb 2010 10:39:23 +0100
Subject: [Rd] how to create a SEXP which could be accessed in embedded R
In-Reply-To: <15308325.48ac.126e9bd5f7d.Coremail.yeahzx@yeah.net>
References: <15308325.48ac.126e9bd5f7d.Coremail.yeahzx@yeah.net>
Message-ID: <4B7FADCB.5020604@r-enthusiasts.com>

On 02/20/2010 05:58 AM, yeahzx wrote:
>
> Hi all,
>
> I am not familiar with writing R extensions. In a C program, I want to create a SEXP and access it in embedded R. How to let the embedded engine know there's a new vector? For example, after creating a SEXP, parsing 'ls()' in embedded R and then evaluating, STRSXP returned will contain the name of the SEXP. Any help would be appreciated.
>
> Regards,
> Spiral

Hi ,

I'm not sure I understand what you mean. If you want the variable to be 
in the global environment, you have to assign it there. You can use e.g. 
defineVar :

SEXP x = PROTECT( allocVector( STRSXP, 2 ) );
SET_STRING_ELT( x, 0, Rf_mkChar( "foo" ) ) ;
SET_STRING_ELT( x, 1, Rf_mkChar( "bar" ) ) ;
defineVar( Rf_install("x"), x, R_GlobalEnv  ) ;
UNPROTECT(1) ; /* x */

Romain


PS: with Rcpp, you can do the same as :

using namespace Rcpp;
Environment global = Environment::global_env() ;
CharacterVector x(2) ; x[0] = "foo" ; x[1] = "bar" ;
global["x"] = x ;

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7
`- http://tr.im/O1wO : highlight 0.1-5


From ggrothendieck at gmail.com  Sat Feb 20 10:52:56 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 20 Feb 2010 04:52:56 -0500
Subject: [Rd] Problem with ?Syntax
Message-ID: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com>

In ?Syntax [ is given as higher priority than $ but BOD$demand[3]
seems to be the same as (BOD$demand)[3] contrary to [ being higher
priority.

> BOD$demand[3]
[1] 19
> (BOD$demand)[3]
[1] 19

What is the rule being used here?


From b.rowlingson at lancaster.ac.uk  Sat Feb 20 12:57:42 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 20 Feb 2010 11:57:42 +0000
Subject: [Rd] Problem with ?Syntax
In-Reply-To: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com>
References: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com>
Message-ID: <d8ad40b51002200357x667008fan5bb069864af3b102@mail.gmail.com>

On Sat, Feb 20, 2010 at 9:52 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> In ?Syntax [ is given as higher priority than $ but BOD$demand[3]
> seems to be the same as (BOD$demand)[3] contrary to [ being higher
> priority.
>
>> BOD$demand[3]
> [1] 19
>> (BOD$demand)[3]
> [1] 19
>
> What is the rule being used here?

 I think its the parser rule that defines the syntax of $ on a list. Does:

 BOD$(demand[3]) even work?

> BOD$(demand[3])
Error: unexpected '(' in "BOD$("

 - no. The parser sees a $ and then gets the next token (gram.y shows
this to be a symbol or a string constant) as the thing to deal with.
Symbols  I can't think of an example where $ and [ could have
ambiguous precedence that is syntactically correct, so maybe the order
is irrelevant...

 Just for fun:

> x=list(a=1,b=2)
> x$"a[1]"=2
> x$"a[1]"
[1] 2
> x$a[1]
[1] 1


Barry


From ggrothendieck at gmail.com  Sat Feb 20 13:07:44 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 20 Feb 2010 07:07:44 -0500
Subject: [Rd] Problem with ?Syntax
In-Reply-To: <d8ad40b51002200357x667008fan5bb069864af3b102@mail.gmail.com>
References: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com> 
	<d8ad40b51002200357x667008fan5bb069864af3b102@mail.gmail.com>
Message-ID: <971536df1002200407w2d5bedc6q5e74ff92e9787570@mail.gmail.com>

I wasn't claiming there was an ambiguity but it does not perform
according to the operator precedence documented in ?Syntax .  If it
performed as documented it would give an error.

On Sat, Feb 20, 2010 at 6:57 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Sat, Feb 20, 2010 at 9:52 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> In ?Syntax [ is given as higher priority than $ but BOD$demand[3]
>> seems to be the same as (BOD$demand)[3] contrary to [ being higher
>> priority.
>>
>>> BOD$demand[3]
>> [1] 19
>>> (BOD$demand)[3]
>> [1] 19
>>
>> What is the rule being used here?
>
> ?I think its the parser rule that defines the syntax of $ on a list. Does:
>
> ?BOD$(demand[3]) even work?
>
>> BOD$(demand[3])
> Error: unexpected '(' in "BOD$("
>
> ?- no. The parser sees a $ and then gets the next token (gram.y shows
> this to be a symbol or a string constant) as the thing to deal with.
> Symbols ?I can't think of an example where $ and [ could have
> ambiguous precedence that is syntactically correct, so maybe the order
> is irrelevant...
>
> ?Just for fun:
>
>> x=list(a=1,b=2)
>> x$"a[1]"=2
>> x$"a[1]"
> [1] 2
>> x$a[1]
> [1] 1
>
>
> Barry
>


From g.russell at eos-solutions.com  Fri Feb 19 13:45:14 2010
From: g.russell at eos-solutions.com (g.russell at eos-solutions.com)
Date: Fri, 19 Feb 2010 13:45:14 +0100 (CET)
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
Message-ID: <20100219124514.555E62830318@mail.pubhealth.ku.dk>

Full_Name: George Russell
Version: 2.10.0, 2.11.0 (2009-12-13 r50716)
OS: Windows
Submission from: (NULL) (217.111.3.131)


R trace:
-- cut here --
> v <- integer(0)
> v[[1]] <- v
> v
[1] 20522144
> v <- numeric(0)
> v[[1]] <- v
> v
[1] 4.254131e-314
> sessionInfo()
R version 2.10.0 (2009-10-26) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     
-- cut here --
Clearly the assignments v[[1]] <- v do not do anything useful, the problem is I
don't understand where the strange values left in v come from.

The same problem occurs with the 2.11.0 release r50716 and --vanilla. For
vanilla in Windows CMD mode I get different values in v, but ones which are to
me equally strange.

Many thanks for your help!

George Russell


From egoldlust at gmail.com  Fri Feb 19 17:40:10 2010
From: egoldlust at gmail.com (egoldlust at gmail.com)
Date: Fri, 19 Feb 2010 17:40:10 +0100 (CET)
Subject: [Rd] read.csv('/dev/stdin') fails (PR#14218)
Message-ID: <20100219164010.B708B282EF51@mail.pubhealth.ku.dk>

Full_Name: Eric Goldlust
Version: 2.10.1 (2009-12-14) x86_64-unknown-linux-gnu 
OS: Linux 2.6.9-67.0.1.ELsmp x86_64
Submission from: (NULL) (64.22.160.1)


After upgrading to from 2.9.1 to 2.10.1, I get unexpected results when calling
read.csv('/dev/stdin').  These problems go away when I call read.csv(pipe('cat
/dev/stdin')).

Shell session follows (bash):

~$ echo -e "a,b,c\n1,2,3" | Rscript <(echo "read.csv('/dev/stdin')")
Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  no lines available in input
Calls: read.csv -> read.table
Execution halted
~$ echo -e "a,b,c\n1,2,3" | Rscript <(echo "read.csv(pipe('cat /dev/stdin'))")
  a b c
1 1 2 3

Note that this code worked fine for me in 2.9.1.


From hb at stat.berkeley.edu  Sat Feb 20 16:37:12 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 20 Feb 2010 16:37:12 +0100
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
In-Reply-To: <20100219124514.555E62830318@mail.pubhealth.ku.dk>
References: <20100219124514.555E62830318@mail.pubhealth.ku.dk>
Message-ID: <59d7961d1002200737v2404e1b4q705c52b12ee1520f@mail.gmail.com>

Confirmed behavior on R version 2.10.1 Patched (2010-01-12 r50990) and
R version 2.11.0 Under development (unstable) (2010-02-14 r51138)
[Windows Vista]:

INTEGERS:
> v <- integer(5)
> v
[1] 0 0 0 0 0
> v[[2]] <- integer(0)
> v
[1]       0 2892960       0       0       0
> v[[4]] <- 1L[c()]
> v
[1]       0 2892960       0 2892960       0
> str(v)
 int [1:5] 0 2892960 0 2892960 0

DOUBLES:
> u <- integer(5)
> u
[1] 0 0 0 0 0
> u[[2]] <- integer(0)
> u
[1]       0 2892960       0       0       0
> u[[4]] <- 1L[c()]
> u
[1]       0 2892960       0 2892960       0
> str(u)
 str [1:5] 0 2892960 0 2892960 0

> u[[5]] <- double(0)
> u
[1]  0.000000e+00  3.487453e+07  0.000000e+00  3.487453e+07 4.261222e-314
> str(u)
 num [1:5] 0.00 3.49e+07 0.00 3.49e+07 4.26e-314

The actual "rubbish" values are the same within each R session, but
differ between R sessions.

Certain looks like stray memory cells are assigned.

Wanted behavior should probably be:

> u[[5]] <- double(0)
Error in u[[5]] <- double(0) : replacement has length zero

cf. u[5] <- double(0) and

> u[[5]] <- double(5)
Error in u[[5]] <- double(5) :
  more elements supplied than there are to replace

/Henrik

On Fri, Feb 19, 2010 at 1:45 PM,  <g.russell at eos-solutions.com> wrote:
> Full_Name: George Russell
> Version: 2.10.0, 2.11.0 (2009-12-13 r50716)
> OS: Windows
> Submission from: (NULL) (217.111.3.131)
>
>
> R trace:
> -- cut here --
>> v <- integer(0)
>> v[[1]] <- v
>> v
> [1] 20522144
>> v <- numeric(0)
>> v[[1]] <- v
>> v
> [1] 4.254131e-314
>> sessionInfo()
> R version 2.10.0 (2009-10-26)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=German_Germany.1252 ?LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices datasets ?utils ? ? methods ? base
> -- cut here --
> Clearly the assignments v[[1]] <- v do not do anything useful, the problem is I
> don't understand where the strange values left in v come from.
>
> The same problem occurs with the 2.11.0 release r50716 and --vanilla. For
> vanilla in Windows CMD mode I get different values in v, but ones which are to
> me equally strange.
>
> Many thanks for your help!
>
> George Russell
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Sat Feb 20 16:50:24 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 20 Feb 2010 16:50:24 +0100
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
In-Reply-To: <20100219124514.555E62830318@mail.pubhealth.ku.dk>
References: <20100219124514.555E62830318@mail.pubhealth.ku.dk>
Message-ID: <4B8004C0.5020900@biostat.ku.dk>

g.russell at eos-solutions.com wrote:
> Full_Name: George Russell
> Version: 2.10.0, 2.11.0 (2009-12-13 r50716)
> OS: Windows
> Submission from: (NULL) (217.111.3.131)
> 
> 
> R trace:
> -- cut here --
>> v <- integer(0)
>> v[[1]] <- v
>> v
> [1] 20522144
>> v <- numeric(0)
>> v[[1]] <- v
>> v
> [1] 4.254131e-314
>> sessionInfo()
> R version 2.10.0 (2009-10-26) 
> i386-pc-mingw32 
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
> [5] LC_TIME=German_Germany.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base     
> -- cut here --
> Clearly the assignments v[[1]] <- v do not do anything useful, the problem is I
> don't understand where the strange values left in v come from.

You don't want to understand, believe me! ;-)

It's a bug, probably not the very worst kind, but accessing memory that 
isn't yours is potentially harmful (but writing to it is considerably 
worse).

Looks like the issue only concerns the right hand side; nothing to do 
with the auto-expansion of v. I also get

 > v <- integer(0)
 > u <- integer(1)
 > u[[2]] <-v
 > u
[1]         0 142000760
 > u[[1]] <-v
 > u
[1] 142000760 142000760
 > a <- 1
 > a[[1]] <-v
 > a
[1] 142000760


> 
> The same problem occurs with the 2.11.0 release r50716 and --vanilla. For
> vanilla in Windows CMD mode I get different values in v, but ones which are to
> me equally strange.
> 
> Many thanks for your help!
> 
> George Russell
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From hb at stat.berkeley.edu  Sat Feb 20 17:24:05 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 20 Feb 2010 17:24:05 +0100
Subject: [Rd] R-forge down
Message-ID: <59d7961d1002200824x1eb86947mc55e761c7dc10902@mail.gmail.com>

FYI/to the maintainers of r-forge:

R-forge seems to be down:

1. http://r-forge.r-project.org/ gives minimal page "R-Forge Could Not
Connect to Database:".
2. svn+ssh://<user name>@svn.r-forge.r-project.org/ - svn requests
does not work.
3. ping svn.r-forge.r-project.org does indeed respond.

/Henrik


From jel+r at cs.uni-magdeburg.de  Sat Feb 20 18:16:08 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Sat, 20 Feb 2010 18:16:08 +0100
Subject: [Rd] R logo as SVG ?
Message-ID: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>

Hi,

does anybody have the R logo in a vector format preferable SVG?
Need it for Freedesktop (GNOME desktop) integration of Rcmdr ...

Thanx,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From p.dalgaard at biostat.ku.dk  Sat Feb 20 19:18:04 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 20 Feb 2010 19:18:04 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
Message-ID: <4B80275C.8080806@biostat.ku.dk>

Jens Elkner wrote:
> Hi,
> 
> does anybody have the R logo in a vector format preferable SVG?
> Need it for Freedesktop (GNOME desktop) integration of Rcmdr ...
> 
> Thanx,
> jel.

Not really. I played around with the tracer in inkscape at some point, 
but it didn't come out quite satisfactory. It's a bit of a time sink 
unless you happen to know inkscape (or similar) rather well, but if 
someone is willing to put in the effort, I'm sure the results would be 
more than welcome on CRAN.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From gkerns at ysu.edu  Sat Feb 20 19:33:50 2010
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Sat, 20 Feb 2010 13:33:50 -0500
Subject: [Rd] R logo as SVG ?
In-Reply-To: <4B80275C.8080806@biostat.ku.dk>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de> 
	<4B80275C.8080806@biostat.ku.dk>
Message-ID: <a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>

On Sat, Feb 20, 2010 at 1:18 PM, Peter Dalgaard
<p.dalgaard at biostat.ku.dk> wrote:
> Jens Elkner wrote:
>>
>> Hi,
>>
>> does anybody have the R logo in a vector format preferable SVG?
>> Need it for Freedesktop (GNOME desktop) integration of Rcmdr ...
>>
>> Thanx,
>> jel.
>
> Not really. I played around with the tracer in inkscape at some point, but
> it didn't come out quite satisfactory. It's a bit of a time sink unless you
> happen to know inkscape (or similar) rather well, but if someone is willing
> to put in the effort, I'm sure the results would be more than welcome on
> CRAN.
>
>

As it happens, I made one with Inkscape a couple of months ago.  If
memory serves, I did 50 scans of the .png.

http://people.ysu.edu/~gkerns/R-logo.svg

Hope it is useful to you.
Jay






***************************************************
G. Jay Kerns, Ph.D.
Associate Professor
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
VoIP: gjkerns at ekiga.net
E-mail: gkerns at ysu.edu
http://people.ysu.edu/~gkerns/


From p.dalgaard at biostat.ku.dk  Sat Feb 20 20:00:13 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 20 Feb 2010 20:00:13 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
Message-ID: <4B80313D.1000909@biostat.ku.dk>

G. Jay Kerns wrote:
> On Sat, Feb 20, 2010 at 1:18 PM, Peter Dalgaard
> <p.dalgaard at biostat.ku.dk> wrote:
>> Jens Elkner wrote:
>>> Hi,
>>>
>>> does anybody have the R logo in a vector format preferable SVG?
>>> Need it for Freedesktop (GNOME desktop) integration of Rcmdr ...
>>>
>>> Thanx,
>>> jel.
>> Not really. I played around with the tracer in inkscape at some point, but
>> it didn't come out quite satisfactory. It's a bit of a time sink unless you
>> happen to know inkscape (or similar) rather well, but if someone is willing
>> to put in the effort, I'm sure the results would be more than welcome on
>> CRAN.
>>
>>
> 
> As it happens, I made one with Inkscape a couple of months ago.  If
> memory serves, I did 50 scans of the .png.
> 
> http://people.ysu.edu/~gkerns/R-logo.svg
> 
> Hope it is useful to you.
> Jay
> 
> 

Thanks. Certainly looks better than what I had left around. A full 
megabyte might be a bit much for a desktop icon, though.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From jel+r at cs.uni-magdeburg.de  Sat Feb 20 20:56:20 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Sat, 20 Feb 2010 20:56:20 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <4B80313D.1000909@biostat.ku.dk>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
Message-ID: <20100220195620.GA17109@trex.cs.uni-magdeburg.de>

On Sat, Feb 20, 2010 at 08:00:13PM +0100, Peter Dalgaard wrote:
> G. Jay Kerns wrote:
> >On Sat, Feb 20, 2010 at 1:18 PM, Peter Dalgaard
> ><p.dalgaard at biostat.ku.dk> wrote:
> >>Jens Elkner wrote:
> >>>Hi,
> >>>
> >>>does anybody have the R logo in a vector format preferable SVG?
> >>>Need it for Freedesktop (GNOME desktop) integration of Rcmdr ...
> >>>
> >>>Thanx,
> >>>jel.
> >>Not really. I played around with the tracer in inkscape at some point, but
> >>it didn't come out quite satisfactory. It's a bit of a time sink unless 
> >>you
> >>happen to know inkscape (or similar) rather well, but if someone is 
> >>willing
> >>to put in the effort, I'm sure the results would be more than welcome on
> >>CRAN.
> >>
> >>
> >
> >As it happens, I made one with Inkscape a couple of months ago.  If
> >memory serves, I did 50 scans of the .png.
> >
> >http://people.ysu.edu/~gkerns/R-logo.svg
  
OK - thanx. Good source for studying its structure.

> Thanks. Certainly looks better than what I had left around. A full 
> megabyte might be a bit much for a desktop icon, though.

Yes and scaling would be too resource consuming as well (very bad for
menus, etc.). I think, the most challenging part here is all the 
[different type of] shadows. So does anybody know, who made  the
original pixel based image? If not raytraced and steps for reproduction
are available (e.g. gimp/psp layers), it should be possible to produce a
less resource consuming but pretty close svg (at least at the given size
;-)).

Regards,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From seth at userprimary.net  Sat Feb 20 23:21:21 2010
From: seth at userprimary.net (Seth Falcon)
Date: Sat, 20 Feb 2010 14:21:21 -0800
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
In-Reply-To: <4B8004C0.5020900@biostat.ku.dk>
References: <20100219124514.555E62830318@mail.pubhealth.ku.dk>
	<4B8004C0.5020900@biostat.ku.dk>
Message-ID: <4B806061.1060204@userprimary.net>

On 2/20/10 7:50 AM, Peter Dalgaard wrote:
> You don't want to understand, believe me! ;-)
> 
> It's a bug, probably not the very worst kind, but accessing memory that
> isn't yours is potentially harmful (but writing to it is considerably
> worse).
> 
> Looks like the issue only concerns the right hand side; nothing to do
> with the auto-expansion of v. I also get
> 
>> v <- integer(0)
>> u <- integer(1)
>> u[[2]] <-v
>> u
> [1]         0 142000760
>> u[[1]] <-v
>> u
> [1] 142000760 142000760
>> a <- 1
>> a[[1]] <-v
>> a
> [1] 142000760

I'm thinking this should be an error.  Similar to:

> v = 1
> v[[1]] = integer(3)
Error in v[[1]] = integer(3) :
  more elements supplied than there are to replace

But instead not enough elements supplied.  Perhaps:

> v[[1]] = integer()
Error in v[[1]] = integer() : [[ ]] replacement has zero length

The code in do_subassign2_dflt currently does not check that the
replacement has length > 0 for the nsubs == 1 case.  I think we want:


@@ -1529,6 +1532,8 @@ do_subassign2_dflt(SEXP call, SEXP op, SEXP args,
SEXP rho)
        if (nsubs == 0 || CAR(subs) == R_MissingArg)
            error(_("[[ ]] with missing subscript"));
        if (nsubs == 1) {
+            if (length(y) == 0)
+                error(_("[[ ]] replacement has zero length"));
            offset = OneIndex(x, thesub, length(x), 0, &newname,
recursed ? len-1 : -1, R_NilValue);
            if (isVectorList(x) && isNull(y)) {
                x = DeleteOneVectorListItem(x, offset);


+ seth


From seth at userprimary.net  Sat Feb 20 23:25:23 2010
From: seth at userprimary.net (seth at userprimary.net)
Date: Sat, 20 Feb 2010 23:25:23 +0100 (CET)
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
Message-ID: <20100220222523.C9068282EF58@mail.pubhealth.ku.dk>

On 2/20/10 7:50 AM, Peter Dalgaard wrote:
> You don't want to understand, believe me! ;-)
> 
> It's a bug, probably not the very worst kind, but accessing memory that
> isn't yours is potentially harmful (but writing to it is considerably
> worse).
> 
> Looks like the issue only concerns the right hand side; nothing to do
> with the auto-expansion of v. I also get
> 
>> v <- integer(0)
>> u <- integer(1)
>> u[[2]] <-v
>> u
> [1]         0 142000760
>> u[[1]] <-v
>> u
> [1] 142000760 142000760
>> a <- 1
>> a[[1]] <-v
>> a
> [1] 142000760

I'm thinking this should be an error.  Similar to:

> v = 1
> v[[1]] = integer(3)
Error in v[[1]] = integer(3) :
  more elements supplied than there are to replace

But instead not enough elements supplied.  Perhaps:

> v[[1]] = integer()
Error in v[[1]] = integer() : [[ ]] replacement has zero length

The code in do_subassign2_dflt currently does not check that the
replacement has length > 0 for the nsubs == 1 case.  I think we want:


@@ -1529,6 +1532,8 @@ do_subassign2_dflt(SEXP call, SEXP op, SEXP args,
SEXP rho)
        if (nsubs == 0 || CAR(subs) == R_MissingArg)
            error(_("[[ ]] with missing subscript"));
        if (nsubs == 1) {
+            if (length(y) == 0)
+                error(_("[[ ]] replacement has zero length"));
            offset = OneIndex(x, thesub, length(x), 0, &newname,
recursed ? len-1 : -1, R_NilValue);
            if (isVectorList(x) && isNull(y)) {
                x = DeleteOneVectorListItem(x, offset);


+ seth


From p.dalgaard at biostat.ku.dk  Sun Feb 21 09:36:22 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 21 Feb 2010 09:36:22 +0100
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
In-Reply-To: <20100220222523.C9068282EF58@mail.pubhealth.ku.dk>
References: <20100220222523.C9068282EF58@mail.pubhealth.ku.dk>
Message-ID: <4B80F086.9090103@biostat.ku.dk>

seth at userprimary.net wrote:

Thanks, Seth. Martin Morgan sent a patch for a few lines above yours, 
which I didn't have a chance to review until now:

-   if (!isVectorList(x) && LENGTH(y) > 1)
-       error(_("more elements supplied than there are to replace"));
+   if (!isVectorList(x) && LENGTH(y) != 1)
+       if (LENGTH(y) == 0)
+           error(_("fewer elements supplied than there are to replace"));
+       else
+           error(_("more elements supplied than there are to replace"));

I _think_ that you are both right that there is no way for a zero-length 
RHS not to be an error. E.g.,

 > x[[0]] <- real(0)
Error in x[[0]] <- real(0) : attempt to select less than one element

The difference between Seth's solution and Martin's is whether to 
pre-check for nsubs==1, and I don't think we want that because of

 > x <- matrix(1:4,2,2)
 > x[[2,2]]
[1] 4
 > x[[2,2]] <- integer(0)
 > x
      [,1]      [,2]
[1,]    1         3
[2,]    2 142000760


> On 2/20/10 7:50 AM, Peter Dalgaard wrote:
>> You don't want to understand, believe me! ;-)
>>
>> It's a bug, probably not the very worst kind, but accessing memory that
>> isn't yours is potentially harmful (but writing to it is considerably
>> worse).
>>
>> Looks like the issue only concerns the right hand side; nothing to do
>> with the auto-expansion of v. I also get
>>
>>> v <- integer(0)
>>> u <- integer(1)
>>> u[[2]] <-v
>>> u
>> [1]         0 142000760
>>> u[[1]] <-v
>>> u
>> [1] 142000760 142000760
>>> a <- 1
>>> a[[1]] <-v
>>> a
>> [1] 142000760
> 
> I'm thinking this should be an error.  Similar to:
> 
>> v = 1
>> v[[1]] = integer(3)
> Error in v[[1]] = integer(3) :
>   more elements supplied than there are to replace
> 
> But instead not enough elements supplied.  Perhaps:
> 
>> v[[1]] = integer()
> Error in v[[1]] = integer() : [[ ]] replacement has zero length
> 
> The code in do_subassign2_dflt currently does not check that the
> replacement has length > 0 for the nsubs == 1 case.  I think we want:
> 
> 
> @@ -1529,6 +1532,8 @@ do_subassign2_dflt(SEXP call, SEXP op, SEXP args,
> SEXP rho)
>         if (nsubs == 0 || CAR(subs) == R_MissingArg)
>             error(_("[[ ]] with missing subscript"));
>         if (nsubs == 1) {
> +            if (length(y) == 0)
> +                error(_("[[ ]] replacement has zero length"));
>             offset = OneIndex(x, thesub, length(x), 0, &newname,
> recursed ? len-1 : -1, R_NilValue);
>             if (isVectorList(x) && isNull(y)) {
>                 x = DeleteOneVectorListItem(x, offset);
> 
> 
> + seth
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Sun Feb 21 10:07:26 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 21 Feb 2010 10:07:26 +0100
Subject: [Rd] Rubbish values written with zero-length vectors (PR#14217)
In-Reply-To: <4B80F086.9090103@biostat.ku.dk>
References: <20100220222523.C9068282EF58@mail.pubhealth.ku.dk>
	<4B80F086.9090103@biostat.ku.dk>
Message-ID: <4B80F7CE.9080303@biostat.ku.dk>

OK. I now have a version which seems to do the trick and reuses an 
existing error message. Will commit to r-devel if and when make 
check-devel succeeds.

-p

Peter Dalgaard wrote:
> seth at userprimary.net wrote:
> 
> Thanks, Seth. Martin Morgan sent a patch for a few lines above yours, 
> which I didn't have a chance to review until now:
> 
> -   if (!isVectorList(x) && LENGTH(y) > 1)
> -       error(_("more elements supplied than there are to replace"));
> +   if (!isVectorList(x) && LENGTH(y) != 1)
> +       if (LENGTH(y) == 0)
> +           error(_("fewer elements supplied than there are to replace"));
> +       else
> +           error(_("more elements supplied than there are to replace"));
> 
> I _think_ that you are both right that there is no way for a zero-length 
> RHS not to be an error. E.g.,
> 
>  > x[[0]] <- real(0)
> Error in x[[0]] <- real(0) : attempt to select less than one element
> 
> The difference between Seth's solution and Martin's is whether to 
> pre-check for nsubs==1, and I don't think we want that because of
> 
>  > x <- matrix(1:4,2,2)
>  > x[[2,2]]
> [1] 4
>  > x[[2,2]] <- integer(0)
>  > x
>      [,1]      [,2]
> [1,]    1         3
> [2,]    2 142000760
> 
> 
>> On 2/20/10 7:50 AM, Peter Dalgaard wrote:
>>> You don't want to understand, believe me! ;-)
>>>
>>> It's a bug, probably not the very worst kind, but accessing memory that
>>> isn't yours is potentially harmful (but writing to it is considerably
>>> worse).
>>>
>>> Looks like the issue only concerns the right hand side; nothing to do
>>> with the auto-expansion of v. I also get
>>>
>>>> v <- integer(0)
>>>> u <- integer(1)
>>>> u[[2]] <-v
>>>> u
>>> [1]         0 142000760
>>>> u[[1]] <-v
>>>> u
>>> [1] 142000760 142000760
>>>> a <- 1
>>>> a[[1]] <-v
>>>> a
>>> [1] 142000760
>>
>> I'm thinking this should be an error.  Similar to:
>>
>>> v = 1
>>> v[[1]] = integer(3)
>> Error in v[[1]] = integer(3) :
>>   more elements supplied than there are to replace
>>
>> But instead not enough elements supplied.  Perhaps:
>>
>>> v[[1]] = integer()
>> Error in v[[1]] = integer() : [[ ]] replacement has zero length
>>
>> The code in do_subassign2_dflt currently does not check that the
>> replacement has length > 0 for the nsubs == 1 case.  I think we want:
>>
>>
>> @@ -1529,6 +1532,8 @@ do_subassign2_dflt(SEXP call, SEXP op, SEXP args,
>> SEXP rho)
>>         if (nsubs == 0 || CAR(subs) == R_MissingArg)
>>             error(_("[[ ]] with missing subscript"));
>>         if (nsubs == 1) {
>> +            if (length(y) == 0)
>> +                error(_("[[ ]] replacement has zero length"));
>>             offset = OneIndex(x, thesub, length(x), 0, &newname,
>> recursed ? len-1 : -1, R_NilValue);
>>             if (isVectorList(x) && isNull(y)) {
>>                 x = DeleteOneVectorListItem(x, offset);
>>
>>
>> + seth
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From hb at stat.berkeley.edu  Sun Feb 21 10:40:08 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sun, 21 Feb 2010 10:40:08 +0100
Subject: [Rd] system.time provides inaccurate sys.child (PR#14210)
In-Reply-To: <20100210134511.4BDA32830315@mail.pubhealth.ku.dk>
References: <20100210134511.4BDA32830315@mail.pubhealth.ku.dk>
Message-ID: <59d7961d1002210140m10d0d88ei18f0ea7e5aa76219@mail.gmail.com>

FYI,

you're much more likely to get a response/see actions on this if you
report issues using the most recent stable version (R v2.10.1) and/or
even the developers version (R v2.11.0).  You're current version is,
as you see, more than 2 years old.  It is likely that the threshold to
compare the code of your version with the latest one etc is to large
for someone to be bothered.

/Henrik

On Wed, Feb 10, 2010 at 2:45 PM,  <manuel.lopez-ibanez at ulb.ac.be> wrote:
> Full_Name: Manuel L?pez-Ib??ez
> Version: R version 2.6.2 (2008-02-08)
> OS: linux-gnu
> Submission from: (NULL) (164.15.10.156)
>
>
> This is only relevant for CPU intensive child processes. Otherwise, the problem
> is not obvious.
>
> Therefore, we need a CPU intensive program like this one:
>
> /************************************/
> /*** Compile with: gcc -o timer-test -O0 timer-test.c -lm */
> #include <stdio.h>
> #include <stdlib.h>
> #include <math.h>
>
> double alpha, beta;
> int size = 1000;
>
> #define WORK_create_matrix(TYPEOFMATRIX) ? ? ? ? ? ? ? ?\
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\
> TYPEOFMATRIX ** m_create_##TYPEOFMATRIX##_matrix ( ? ? ?\
> int dim1, int dim2, int line, const char*file) ? ? ? ? ?\
> { ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
> ? ?TYPEOFMATRIX **p; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
> ? ?int i; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\
> ? ?p = malloc (sizeof(TYPEOFMATRIX) * dim1 * dim2 ? ? ?\
> ? ? ? ? ? ? ? ?+ sizeof(TYPEOFMATRIX *) * dim1 ); ? ? ?\
> ? ?if (p == NULL) { ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\
> ? ? ? ?fprintf(stderr, "cannot create " #TYPEOFMATRIX ?\
> ? ? ? ? ? ? ? ?" matrix of size (%d x %d): " ? ? ? ? ? \
> ? ? ? ? ? ? ? ?"see line %d of file %s\n", ? ? ? ? ? ? \
> ? ? ? ? ? ? ? ?dim1, dim2, line, file); ? ? ? ? ? ? ? ?\
> ? ? ? ?exit(1); ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\
> ? ?} ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
> ? ?for (i = 0; i < dim1; i++) ? ? ? ? ? ? ? ? ? ? ? ? ?\
> ? ? ? ?p[i] = (TYPEOFMATRIX *) (p + dim1) + i * dim2; ?\
> ? ?return p; ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? \
> }
>
> WORK_create_matrix(int)
> WORK_create_matrix(double)
> #undef WORK_create_matrix
> #define create_double_matrix(dim1,dim2)\
> ? ?m_create_double_matrix(dim1,dim2,__LINE__,__FILE__)
>
>
> int main(int argc, char *argv[])
> {
> ? ?double **matrix1 = create_double_matrix(size, size);
> ? ?double **matrix2 = create_double_matrix(size, size);
> ? ?int iterations = 0;
> ? ?int i,j;
> ? ?double iter_limit = 100;
> ? ?alpha = rand();
> ? ?beta = rand();
>
> ? ?while (iterations < iter_limit) {
> ? ? ? ?for (i = 0; i < size; i++) {
> ? ? ? ? ? ?for (j = 0; j < size; j++) {
> ? ? ? ? ? ? ? ?if (i == j) continue;
> ? ? ? ? ? ? ? ?matrix2[i][j] = pow(matrix1[i][j], alpha)
> ? ? ? ? ? ? ? ? ? ?* pow(matrix2[j][i], beta);
> ? ? ? ? ? ? ? ?matrix1[j][i] = matrix2[i][j];
> ? ? ? ? ? ?}
> ? ? ? ?}
> ? ? ? ?iterations++;
> ? ?}
>
> ? ?printf("Iterations = %d\n", iterations);
> ? ?return 0;
> }
> /************************************/
>
> Then in R evaluate:
>
>> print.default (system.time (system(paste ("time", "bash -c './timer-test 100 >
> /dev/null'"))))
> 10.77user 0.02system 0:10.81elapsed 99%CPU (0avgtext+0avgdata 0maxresident)k
> 0inputs+0outputs (0major+4574minor)pagefaults 0swaps
> ?user.self ? sys.self ? ?elapsed user.child ?sys.child
> ? ? 0.000 ? ? ?0.000 ? ? 10.818 ? ? 10.777 ? ? 10.777
> attr(,"class")
> [1] "proc_time"
>
> Expected: the sys.child time should be 0.02.
>
>> version
> ? ? ? ? ? ? ? _
> platform ? ? ? i486-pc-linux-gnu
> arch ? ? ? ? ? i486
> os ? ? ? ? ? ? linux-gnu
> system ? ? ? ? i486, linux-gnu
> status
> major ? ? ? ? ?2
> minor ? ? ? ? ?6.2
> year ? ? ? ? ? 2008
> month ? ? ? ? ?02
> day ? ? ? ? ? ?08
> svn rev ? ? ? ?44383
> language ? ? ? R
> version.string R version 2.6.2 (2008-02-08)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Sun Feb 21 11:22:24 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 21 Feb 2010 11:22:24 +0100
Subject: [Rd] system.time provides inaccurate sys.child (PR#14210)
In-Reply-To: <59d7961d1002210140m10d0d88ei18f0ea7e5aa76219@mail.gmail.com>
References: <20100210134511.4BDA32830315@mail.pubhealth.ku.dk>
	<59d7961d1002210140m10d0d88ei18f0ea7e5aa76219@mail.gmail.com>
Message-ID: <4B810960.70900@biostat.ku.dk>

Henrik Bengtsson wrote:
> FYI,
> 
> you're much more likely to get a response/see actions on this if you
> report issues using the most recent stable version (R v2.10.1) and/or
> even the developers version (R v2.11.0).  You're current version is,
> as you see, more than 2 years old.  It is likely that the threshold to
> compare the code of your version with the latest one etc is to large
> for someone to be bothered.
> 
> /Henrik

It was fixed in r-devel same day, though. The message threading is just 
a bit messed up.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Sun Feb 21 11:25:18 2010
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Sun, 21 Feb 2010 11:25:18 +0100 (CET)
Subject: [Rd] system.time provides inaccurate sys.child (PR#14210)
Message-ID: <20100221102518.A83B9282EFC2@mail.pubhealth.ku.dk>

Henrik Bengtsson wrote:
> FYI,
> 
> you're much more likely to get a response/see actions on this if you
> report issues using the most recent stable version (R v2.10.1) and/or
> even the developers version (R v2.11.0).  You're current version is,
> as you see, more than 2 years old.  It is likely that the threshold to
> compare the code of your version with the latest one etc is to large
> for someone to be bothered.
> 
> /Henrik

It was fixed in r-devel same day, though. The message threading is just 
a bit messed up.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From b.rowlingson at lancaster.ac.uk  Sun Feb 21 14:48:24 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 21 Feb 2010 13:48:24 +0000
Subject: [Rd] R logo as SVG ?
In-Reply-To: <20100220195620.GA17109@trex.cs.uni-magdeburg.de>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>
Message-ID: <d8ad40b51002210548q2991f00breafc231f76662c97@mail.gmail.com>

On Sat, Feb 20, 2010 at 7:56 PM, Jens Elkner <jel+r at cs.uni-magdeburg.de> wrote:

> Yes and scaling would be too resource consuming as well (very bad for
> menus, etc.). I think, the most challenging part here is all the
> [different type of] shadows. So does anybody know, who made ?the
> original pixel based image? If not raytraced and steps for reproduction
> are available (e.g. gimp/psp layers), it should be possible to produce a
> less resource consuming but pretty close svg (at least at the given size

A while ago I played around with creating a new R logo using vector
graphics. I took the current logo as a starting point. Here's some
samples on different coloured backgrounds:

http://www.maths.lancs.ac.uk/~rowlings/Graphics/Logo/R/logos.svg

I figured maybe for R 3.0 it would be cool to have an R made from a 1
and a 2....

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From baptiste.auguie at googlemail.com  Sun Feb 21 15:12:46 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sun, 21 Feb 2010 15:12:46 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <d8ad40b51002210548q2991f00breafc231f76662c97@mail.gmail.com>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>
	<d8ad40b51002210548q2991f00breafc231f76662c97@mail.gmail.com>
Message-ID: <de4e29f51002210612l5f36cc1vc587552c33efbef4@mail.gmail.com>

On 21 February 2010 14:48, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:

> A while ago I played around with creating a new R logo using vector
> graphics. I took the current logo as a starting point. Here's some
> samples on different coloured backgrounds:
>
> http://www.maths.lancs.ac.uk/~rowlings/Graphics/Logo/R/logos.svg
>
> I figured maybe for R 3.0 it would be cool to have an R made from a 1
> and a 2....
>

That's funny, when I saw your logo yesterday in google images I didn't
see the 1 and 2 but rather thought it was showing a lambda for some
reason.

Personally, I've always been curious to unravel the elliptical
construction hidden in that grey area surrounding R.  That'd be a nice
side-effect of having a 3D model in povray (*); we could rotate it and
see the other side. Sadly I don't have the skill. I wonder if RGL or
Blender could make this easier yet still reproducible.

Best,

baptiste

(*) a neat example is at: http://www.imagico.de/pov/icons.html


From taylor.russ at gmail.com  Sun Feb 21 17:03:55 2010
From: taylor.russ at gmail.com (rt)
Date: Sun, 21 Feb 2010 10:03:55 -0600
Subject: [Rd] R CMD check: OK in LINUX. Crashes in Windows!
Message-ID: <d6243f3f1002210803n32f2fdafy8f37debe576ef8c9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100221/c332d251/attachment.pl>

From taylor.russ at gmail.com  Sun Feb 21 17:27:57 2010
From: taylor.russ at gmail.com (rt)
Date: Sun, 21 Feb 2010 10:27:57 -0600
Subject: [Rd] R CMD check: OK in LINUX. Crashes in Windows!
Message-ID: <d6243f3f1002210827y4c1e670cl35354cdf667cb8f9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100221/a1cd0a0a/attachment.pl>

From murdoch at stats.uwo.ca  Sun Feb 21 18:36:55 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 21 Feb 2010 12:36:55 -0500
Subject: [Rd] Where does install.R go when R gets compiled? Or,
 how to experiment 	with changes to install.R?
In-Reply-To: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>
References: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>
Message-ID: <4B816F37.3020905@stats.uwo.ca>

Paul Johnson wrote:
> Hello, everybody.
>
> I apologize if this is obvious.  I've not tried to make changes in R
> code within the R source itself before.
>
> I'm pursuing an experiment to make RPM files for R packages
> on-the-fly. Any time I install an R package successfully, I want to
> wrap up those files in an RPM.   Basically, the idea is to "hack" an
> option similar to --build for R CMD INSTALL.
>
> I observe in the R source code this is the file that handles installs
>
> src/library/tools/R/install.R
>
> The R DESCRIPTION file has the information required and the code in
> install.R is quite clear and easy to understand. I *think* I see what
> I need to do.
>
> But I don't understand how to test the effect of my changes without
> re-compiling R and re-installing it.
>
> In the installed R, there is no file "install.R", so there's no
> obvious place to hack on it.
>
> Is it actually necessary to recompile & re-install R every time I want
> to test changes to that file?
>   

The source to most packages is parsed and saved in binary images which 
are loaded as necessary by R.  So install.R has been parsed and included 
in library/tools/R/tools.rdb.

Debugging system functions can be a little tedious.  In some cases you 
can create new copies of the functions in your workspace; set their 
environment to the environment of the original function, and they'll 
work properly.  The main difficulty is that other functions in the 
package won't see your version, they'll see the original (as will your 
own, if it calls itself recursively.)

You can replace the original function in the package namespace using 
assign(), but you need to handle unlocking and locking of bindings.

Normally I'd recommend just editing the source and running make to 
incorporate the changes; it's too easy to miss a step if you try to take 
shortcuts, and then you need to debug your edits, not just your code.

Duncan Murdoch
> pj
>


From murdoch at stats.uwo.ca  Sun Feb 21 18:44:18 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 21 Feb 2010 12:44:18 -0500
Subject: [Rd] Problem with ?Syntax
In-Reply-To: <971536df1002200407w2d5bedc6q5e74ff92e9787570@mail.gmail.com>
References: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com>
	<d8ad40b51002200357x667008fan5bb069864af3b102@mail.gmail.com>
	<971536df1002200407w2d5bedc6q5e74ff92e9787570@mail.gmail.com>
Message-ID: <4B8170F2.5050707@stats.uwo.ca>

Gabor Grothendieck wrote:
> I wasn't claiming there was an ambiguity but it does not perform
> according to the operator precedence documented in ?Syntax .  If it
> performed as documented it would give an error.
>   

There are a few other errors in that page, e.g. saying that [ has 
greater priority than ::, but

version <- 1:10
base::version[1]

shows :: has higher priority.   I'll take a look.

Duncan Murdoch
> On Sat, Feb 20, 2010 at 6:57 AM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
>   
>> On Sat, Feb 20, 2010 at 9:52 AM, Gabor Grothendieck
>> <ggrothendieck at gmail.com> wrote:
>>     
>>> In ?Syntax [ is given as higher priority than $ but BOD$demand[3]
>>> seems to be the same as (BOD$demand)[3] contrary to [ being higher
>>> priority.
>>>
>>>       
>>>> BOD$demand[3]
>>>>         
>>> [1] 19
>>>       
>>>> (BOD$demand)[3]
>>>>         
>>> [1] 19
>>>
>>> What is the rule being used here?
>>>       
>>  I think its the parser rule that defines the syntax of $ on a list. Does:
>>
>>  BOD$(demand[3]) even work?
>>
>>     
>>> BOD$(demand[3])
>>>       
>> Error: unexpected '(' in "BOD$("
>>
>>  - no. The parser sees a $ and then gets the next token (gram.y shows
>> this to be a symbol or a string constant) as the thing to deal with.
>> Symbols  I can't think of an example where $ and [ could have
>> ambiguous precedence that is syntactically correct, so maybe the order
>> is irrelevant...
>>
>>  Just for fun:
>>
>>     
>>> x=list(a=1,b=2)
>>> x$"a[1]"=2
>>> x$"a[1]"
>>>       
>> [1] 2
>>     
>>> x$a[1]
>>>       
>> [1] 1
>>
>>
>> Barry
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sun Feb 21 20:54:38 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 21 Feb 2010 14:54:38 -0500
Subject: [Rd] Problem with ?Syntax
In-Reply-To: <4B8170F2.5050707@stats.uwo.ca>
References: <971536df1002200152p7d583e1cv416cd06afe865d55@mail.gmail.com>	<d8ad40b51002200357x667008fan5bb069864af3b102@mail.gmail.com>	<971536df1002200407w2d5bedc6q5e74ff92e9787570@mail.gmail.com>
	<4B8170F2.5050707@stats.uwo.ca>
Message-ID: <4B818F7E.3020202@stats.uwo.ca>

On 21/02/2010 12:44 PM, Duncan Murdoch wrote:
> Gabor Grothendieck wrote:
>> I wasn't claiming there was an ambiguity but it does not perform
>> according to the operator precedence documented in ?Syntax .  If it
>> performed as documented it would give an error.
>>   
> 
> There are a few other errors in that page, e.g. saying that [ has 
> greater priority than ::, but
> 
> version <- 1:10
> base::version[1]
> 
> shows :: has higher priority.   I'll take a look.

Actually, just one error.  The indexing operators were shown with higher 
priority than they should have.  Because ::, :::, $ and @ can only take 
a name or a string constant on the right, they effectively have higher 
priority than [ or [[.  I've clarified the man page.

Duncan Murdoch

> 
> Duncan Murdoch
>> On Sat, Feb 20, 2010 at 6:57 AM, Barry Rowlingson
>> <b.rowlingson at lancaster.ac.uk> wrote:
>>   
>>> On Sat, Feb 20, 2010 at 9:52 AM, Gabor Grothendieck
>>> <ggrothendieck at gmail.com> wrote:
>>>     
>>>> In ?Syntax [ is given as higher priority than $ but BOD$demand[3]
>>>> seems to be the same as (BOD$demand)[3] contrary to [ being higher
>>>> priority.
>>>>
>>>>       
>>>>> BOD$demand[3]
>>>>>         
>>>> [1] 19
>>>>       
>>>>> (BOD$demand)[3]
>>>>>         
>>>> [1] 19
>>>>
>>>> What is the rule being used here?
>>>>       
>>>  I think its the parser rule that defines the syntax of $ on a list. Does:
>>>
>>>  BOD$(demand[3]) even work?
>>>
>>>     
>>>> BOD$(demand[3])
>>>>       
>>> Error: unexpected '(' in "BOD$("
>>>
>>>  - no. The parser sees a $ and then gets the next token (gram.y shows
>>> this to be a symbol or a string constant) as the thing to deal with.
>>> Symbols  I can't think of an example where $ and [ could have
>>> ambiguous precedence that is syntactically correct, so maybe the order
>>> is irrelevant...
>>>
>>>  Just for fun:
>>>
>>>     
>>>> x=list(a=1,b=2)
>>>> x$"a[1]"=2
>>>> x$"a[1]"
>>>>       
>>> [1] 2
>>>     
>>>> x$a[1]
>>>>       
>>> [1] 1
>>>
>>>
>>> Barry
>>>
>>>     
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mrizzo at bgsu.edu  Mon Feb 22 04:30:11 2010
From: mrizzo at bgsu.edu (mrizzo at bgsu.edu)
Date: Mon, 22 Feb 2010 04:30:11 +0100 (CET)
Subject: [Rd] scale(x, center=FALSE) (PR#14219)
Message-ID: <20100222033011.F1D06282EF2D@mail.pubhealth.ku.dk>

Full_Name: Maria Rizzo
Version: 2.10.1 (2009-12-14) 
OS: Windows XP SP3
Submission from: (NULL) (72.241.75.222)


platform       i386-pc-mingw32              
arch           i386                         
os             mingw32                      
system         i386, mingw32                
status                                      
major          2                            
minor          10.1                         
year           2009                         
month          12                           
day            14                           
svn rev        50720                        
language       R                            
version.string R version 2.10.1 (2009-12-14)

scale returns incorrect values when center=FALSE and scale=TRUE.

When center=FALSE, scale=TRUE, the "scale" used is not the square root of sample
variance, the "scale" attribute is equal to sqrt(sum(x^2)/(n-1)).

Example:

x <- runif(10)
n <- length(x)

scaled <- scale(x, center=FALSE, scale=TRUE)
scaled
s.bad <- attr(scaled, "scale")
s.bad  #wrong
sd(x)  #correct

#compute the sd as if data has already been centered
#that is, compute the variance as sum(x^2)/(n-1)

sqrt(sum(x^2)/(n-1))


From mdowle at mdowle.plus.com  Mon Feb 22 15:37:04 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 22 Feb 2010 14:37:04 -0000
Subject: [Rd] shash in unique.c
Message-ID: <hlu4qh$l7s$1@dough.gmane.org>


Looking at shash in unique.c, from R-2.10.1  I'm wondering if it makes sense 
to hash the pointer itself rather than the string it points to?
In other words could the SEXP pointer be cast to unsigned int and the usual 
scatter be called on that as if it were integer?

shash would look like a slightly modified version of ihash like this :

static int shash(SEXP x, int indx, HashData *d)
{
    if (STRING_ELT(x,indx) == NA_STRING) return 0;
    return scatter((unsigned int) (STRING_ELT(x,indx), d);
}

rather than its current form which appears to hash the string it points to :

static int shash(SEXP x, int indx, HashData *d)
{
    unsigned int k;
    const char *p;
    if(d->useUTF8)
 p = translateCharUTF8(STRING_ELT(x, indx));
    else
 p = translateChar(STRING_ELT(x, indx));
    k = 0;
    while (*p++)
     k = 11 * k + *p; /* was 8 but 11 isn't a power of 2 */
    return scatter(k, d);
}

Looking at sequal, below, and reading its comments, if the pointers are 
equal it doesn't look at the strings they point to, which lead to the 
question above.

static int sequal(SEXP x, int i, SEXP y, int j)
{
    if (i < 0 || j < 0) return 0;
    /* Two strings which have the same address must be the same,
       so avoid looking at the contents */
    if (STRING_ELT(x, i) == STRING_ELT(y, j)) return 1;
    /* Then if either is NA the other cannot be */
    /* Once all CHARSXPs are cached, Seql will handle this */
    if (STRING_ELT(x, i) == NA_STRING || STRING_ELT(y, j) == NA_STRING)
 return 0;
    return Seql(STRING_ELT(x, i), STRING_ELT(y, j));
}

Matthew


From ligges at statistik.tu-dortmund.de  Mon Feb 22 17:10:50 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 22 Feb 2010 17:10:50 +0100
Subject: [Rd] Where does install.R go when R gets compiled? Or,
 how to 	experiment with changes to install.R?
In-Reply-To: <13e802631002191504n349f30b1g43e5bec088a94998@mail.gmail.com>
References: <13e802631002180933g5dcccbc9ie404e45999059282@mail.gmail.com>	<20100218202031.GA11744@trex.cs.uni-magdeburg.de>
	<13e802631002191504n349f30b1g43e5bec088a94998@mail.gmail.com>
Message-ID: <4B82AC8A.8040909@statistik.tu-dortmund.de>



On 20.02.2010 00:04, Paul Johnson wrote:
> On Thu, Feb 18, 2010 at 2:20 PM, Jens Elkner<jel+r at cs.uni-magdeburg.de>  wrote:
>> On Thu, Feb 18, 2010 at 11:33:14AM -0600, Paul Johnson wrote:
>>> I'm pursuing an experiment to make RPM files for R packages
>>> on-the-fly. Any time I install an R package successfully, I want to
>>> wrap up those files in an RPM.   Basically, the idea is to "hack" an
>>> option similar to --build for R CMD INSTALL.
>>
>> Hmm, why not take the easy way:
>>
>>     clean_dst $PROTO
>>     cd $TMPBUILD
>>     mkdir -p $PROTO/R/library
>>     $R_HOME/bin/R CMD INSTALL -l $PROTO/R/library $TMPBUILD
>>
> Yes, I've been there, done that.
>
> I have to administer this on 60 servers in a cluster.  I don't want to
> rebuild all packages on all systems. If I can figure a way to create
> RPM for them, I can script the RPM installs and then I'm sure all the
> systems are identical.
>
> In the worst case scenario, I just have to copy the library tree from
> one machine to another.  But the RPM approach has a bit more built-in
> error checking.
>
> pj


Paul,

beside the already answered parts: in general I'd try to read from some 
network space so that I'd had to make only 1 installation which is also 
useful for easier upgrades and parallel execution where you need 
identical doftware on all nodes.

Best,
Uwe


From taylor.russ at gmail.com  Mon Feb 22 20:11:35 2010
From: taylor.russ at gmail.com (rt)
Date: Mon, 22 Feb 2010 13:11:35 -0600
Subject: [Rd] Compiling R on Linux with SunStudio 12.1: "wide-character
	type" problems
Message-ID: <d6243f3f1002221111l2dae5dc8u3e4947de84961adb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100222/8376de67/attachment.pl>

From gunter.berton at gene.com  Mon Feb 22 20:30:13 2010
From: gunter.berton at gene.com (gunter.berton at gene.com)
Date: Mon, 22 Feb 2010 20:30:13 +0100 (CET)
Subject: [Rd] grid unit bug? (PR#14220)
Message-ID: <20100222193014.2157A282EF4F@mail.pubhealth.ku.dk>

The following seems to me to be at least a perverse trap, if not an =
outright
bug:

> is.numeric(unit(1,"npc"))
[1] TRUE
> is.numeric(1*unit(1,"npc"))
[1] FALSE
> is.numeric(unit(0,"npc") +unit(1,"npc"))
[1] FALSE

...etc.
i.e. is.numeric() appears to be TRUE for class "unit" but false for =
class
("unit.arithmetic" "unit" ). Seems to me it ought to b the same for =
both.


Bert Gunter
Genentech Nonclinical Biostatistics

(FWIW, I think grid graphics is brilliant!)

This was R version 2.11.0dev for Windows btw (not that it makes a
difference):

sessionInfo()

R version 2.11.0 Under development (unstable) (2010-02-15 r51142)=20
i386-pc-mingw32=20

locale:
[1] LC_COLLATE=3DEnglish_United States.1252=20
[2] LC_CTYPE=3DEnglish_United States.1252  =20
[3] LC_MONETARY=3DEnglish_United States.1252
[4] LC_NUMERIC=3DC                         =20
[5] LC_TIME=3DEnglish_United States.1252   =20

attached base packages:
 [1] datasets  splines   grid      tcltk     stats     graphics  =
grDevices
 [8] utils     methods   base    =20

other attached packages:
[1] TinnR_1.0.3     R2HTML_1.59-1   Hmisc_3.7-0     survival_2.35-8
[5] svSocket_0.9-48 lattice_0.18-3  MASS_7.3-5    =20

loaded via a namespace (and not attached):
[1] cluster_1.12.1 svMisc_0.9-56



=A0
=A0


From armgong at yahoo.com  Tue Feb 23 01:56:27 2010
From: armgong at yahoo.com (Gong Yu)
Date: Mon, 22 Feb 2010 16:56:27 -0800 (PST)
Subject: [Rd] patch about compile R with clang
Message-ID: <739921.71704.qm@web45909.mail.sp1.yahoo.com>

clang is compiler http://clang.llvm.org, it is fast and better c compiler then gcc, yesterday i use clang and gfortran compile R.
The only two change in source code is :

1. the configure file (in confiure when test include wctype.h,gcc can compile but clang need include both wchar.h wctype.h),so this is patch
--- /r/configure
+++ /myr/configure
@@ -39172,6 +39172,7 @@
 cat >>conftest.$ac_ext <<_ACEOF
 /* end confdefs.h.  */
 $ac_includes_default
+#include <wchar.h>
 #include <$ac_header>
 _ACEOF
 rm -f conftest.$ac_objext
@@ -39480,6 +39481,7 @@
 cat confdefs.h >>conftest.$ac_ext
 cat >>conftest.$ac_ext <<_ACEOF
 /* end confdefs.h.  */
+#include <wchar.h>
 #include <wctype.h>
 
 #ifdef F77_DUMMY_MAIN


2. edit tre-match-approx.c
change the following line 
#define __USE_STRING_INLINES
#undef __NO_INLINE__
to 
//#define __USE_STRING_INLINES
//#undef __NO_INLINE__
becasue clang will report errors(fields must have a constant size:'variable length array in structure' extension will never be supported' in string.h)


From misc7 at emerose.org  Tue Feb 23 03:49:47 2010
From: misc7 at emerose.org (Ben)
Date: Mon, 22 Feb 2010 20:49:47 -0600
Subject: [Rd] Best style to organize code, namespaces
Message-ID: <20100222204947.09b458ce.misc7@emerose.org>

Hi all,

I'm hoping someone could tell me what best practices are as far as
keeping programs organized in R.  In most languages, I like to keep
things organized by writing small functions.  So, suppose I want to
write a function that would require helper functions or would just be
too big to write in one piece.  Below are three ways to do this:


################### Style 1 (C-style) ###############
Foo <- function(x) {
  ....
}
Foo.subf <- function(x, blah) {
  ....
}
Foo.subg <- function(x, bar) {
  ....
}

################### Style 2 (Lispish?) ##############
Foo <- function(x) {
  Subf <- function(blah) {
    ....
  }
  Subg <- function(bar) {
    ....
  }
  ....
}

################### Object-Oriented #################
Foo <- function(x) {
  Subf <- function(blah) {
    ....
  }
  Subg <- function(bar) {
    ....
  }
  Main <- function() {
    ....
  }
  return(list(subf=subf, subg=subg, foo=foo))
}
################### End examples ####################

Which of these ways is best?  Style 2 seems at first to be the most
natural in R, but I found there are some major drawbacks.  First, it
is hard to debug.  For instance, if I want to debug Subf, I need to
first "debug(Foo)" and then while Foo is debugging, type
"debug(Subf)".  Another big limitation is that I can't write
test-cases (e.g. using RUnit) for Subf and Subg because they aren't
visible in any way at the global level.

For these reasons, style 1 seems to be better than style 2, if less
elegant.  However, style 1 can get awkward because any parameters
passed to the main function are not visible to the others.  In the
above case, the value of "x" must be passed to Foo.subf and Foo.subg
explicitly.  Also there is no enforcement of code isolation
(i.e. anyone can call Foo.subf).

Style 3 is more explicitly object oriented.  It has the advantage of
style 2 in that you don't need to pass x around, and the advantage of
style 1 in that you can still write tests and easily debug the
subfunctions.  However to actually call the main function you have to
type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
function for this.  Either way there is more typing.

So anyway, what is the best way to handle this?  R does not seem to
have a good way of managing namespaces or avoiding collisions, like a
module system or explicit object-orientation.  How should we get
around this limitation?  I've looked at sample R code in the
distribution and elsewhere, but so far it's been pretty
disappointing---most people seem to write very long, hard to
understand functions.

Thanks for any advice!

-- 
Ben


From murdoch at stats.uwo.ca  Tue Feb 23 04:05:10 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 22 Feb 2010 22:05:10 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <20100222204947.09b458ce.misc7@emerose.org>
References: <20100222204947.09b458ce.misc7@emerose.org>
Message-ID: <4B8345E6.7020302@stats.uwo.ca>

On 22/02/2010 9:49 PM, Ben wrote:
> Hi all,
> 
> I'm hoping someone could tell me what best practices are as far as
> keeping programs organized in R.  In most languages, I like to keep
> things organized by writing small functions.  So, suppose I want to
> write a function that would require helper functions or would just be
> too big to write in one piece.  Below are three ways to do this:
> 
> 
> ################### Style 1 (C-style) ###############
> Foo <- function(x) {
>   ....
> }
> Foo.subf <- function(x, blah) {
>   ....
> }
> Foo.subg <- function(x, bar) {
>   ....
> }
> 
> ################### Style 2 (Lispish?) ##############
> Foo <- function(x) {
>   Subf <- function(blah) {
>     ....
>   }
>   Subg <- function(bar) {
>     ....
>   }
>   ....
> }
> 
> ################### Object-Oriented #################
> Foo <- function(x) {
>   Subf <- function(blah) {
>     ....
>   }
>   Subg <- function(bar) {
>     ....
>   }
>   Main <- function() {
>     ....
>   }
>   return(list(subf=subf, subg=subg, foo=foo))
> }
> ################### End examples ####################
> 
> Which of these ways is best?  Style 2 seems at first to be the most
> natural in R, but I found there are some major drawbacks.  First, it
> is hard to debug.  For instance, if I want to debug Subf, I need to
> first "debug(Foo)" and then while Foo is debugging, type
> "debug(Subf)".  

You can use setBreakpoint to set a breakpoint in the nested functions, 
and it will exist in all invocations of Foo (which each create new 
instances of the nested functions).  debug() is not the only debugging tool.

Another big limitation is that I can't write
> test-cases (e.g. using RUnit) for Subf and Subg because they aren't
> visible in any way at the global level.
> 
> For these reasons, style 1 seems to be better than style 2, if less
> elegant.  However, style 1 can get awkward because any parameters
> passed to the main function are not visible to the others.  In the
> above case, the value of "x" must be passed to Foo.subf and Foo.subg
> explicitly.  Also there is no enforcement of code isolation
> (i.e. anyone can call Foo.subf).
> 
> Style 3 is more explicitly object oriented.  It has the advantage of
> style 2 in that you don't need to pass x around, and the advantage of
> style 1 in that you can still write tests and easily debug the
> subfunctions.  However to actually call the main function you have to
> type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
> function for this.  Either way there is more typing.
> 
> So anyway, what is the best way to handle this?  R does not seem to
> have a good way of managing namespaces or avoiding collisions, like a
> module system or explicit object-orientation. 

Packages are self-contained modules.  You don't get collisions between 
names of locals between packages, and if they export the same name, 
other packages can explicitly select which export to use.

  How should we get
> around this limitation?  I've looked at sample R code in the
> distribution and elsewhere, but so far it's been pretty
> disappointing---most people seem to write very long, hard to
> understand functions.

I would normally use a mixture of styles 1 and 2.  Use style 2 for 
functions that really do need access to Foo locals, and use style 1 for 
self-contained functions.

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Feb 23 04:15:03 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 22 Feb 2010 22:15:03 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <20100222204947.09b458ce.misc7@emerose.org>
References: <20100222204947.09b458ce.misc7@emerose.org>
Message-ID: <971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>

As you mention ease of debugging basically precludes subfunctions so
style 1 is left.

Functions can be nested in environments rather than in other functions
and this will allow debugging to still occur.

The proto package which makes it particularly convenient to nest
functions in environments giving an analog to #3 while still allowing
debugging.  See http//:r-proto.googlecode.com

> library(proto)
> # p is proto object with variable a and method f
> p <- proto(a = 1, f = function(., x = 1) .$a <- .$a + 1)
> with(p, debug(f))
> p$f()
debugging in: get("f", env = p, inherits = TRUE)(p, ...)
debug: .$a <- .$a + 1
Browse[2]>
exiting from: get("f", env = p, inherits = TRUE)(p, ...)
[1] 2
> p$a
[1] 2


On Mon, Feb 22, 2010 at 9:49 PM, Ben <misc7 at emerose.org> wrote:
> Hi all,
>
> I'm hoping someone could tell me what best practices are as far as
> keeping programs organized in R. ?In most languages, I like to keep
> things organized by writing small functions. ?So, suppose I want to
> write a function that would require helper functions or would just be
> too big to write in one piece. ?Below are three ways to do this:
>
>
> ################### Style 1 (C-style) ###############
> Foo <- function(x) {
> ?....
> }
> Foo.subf <- function(x, blah) {
> ?....
> }
> Foo.subg <- function(x, bar) {
> ?....
> }
>
> ################### Style 2 (Lispish?) ##############
> Foo <- function(x) {
> ?Subf <- function(blah) {
> ? ?....
> ?}
> ?Subg <- function(bar) {
> ? ?....
> ?}
> ?....
> }
>
> ################### Object-Oriented #################
> Foo <- function(x) {
> ?Subf <- function(blah) {
> ? ?....
> ?}
> ?Subg <- function(bar) {
> ? ?....
> ?}
> ?Main <- function() {
> ? ?....
> ?}
> ?return(list(subf=subf, subg=subg, foo=foo))
> }
> ################### End examples ####################
>
> Which of these ways is best? ?Style 2 seems at first to be the most
> natural in R, but I found there are some major drawbacks. ?First, it
> is hard to debug. ?For instance, if I want to debug Subf, I need to
> first "debug(Foo)" and then while Foo is debugging, type
> "debug(Subf)". ?Another big limitation is that I can't write
> test-cases (e.g. using RUnit) for Subf and Subg because they aren't
> visible in any way at the global level.
>
> For these reasons, style 1 seems to be better than style 2, if less
> elegant. ?However, style 1 can get awkward because any parameters
> passed to the main function are not visible to the others. ?In the
> above case, the value of "x" must be passed to Foo.subf and Foo.subg
> explicitly. ?Also there is no enforcement of code isolation
> (i.e. anyone can call Foo.subf).
>
> Style 3 is more explicitly object oriented. ?It has the advantage of
> style 2 in that you don't need to pass x around, and the advantage of
> style 1 in that you can still write tests and easily debug the
> subfunctions. ?However to actually call the main function you have to
> type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
> function for this. ?Either way there is more typing.
>
> So anyway, what is the best way to handle this? ?R does not seem to
> have a good way of managing namespaces or avoiding collisions, like a
> module system or explicit object-orientation. ?How should we get
> around this limitation? ?I've looked at sample R code in the
> distribution and elsewhere, but so far it's been pretty
> disappointing---most people seem to write very long, hard to
> understand functions.
>
> Thanks for any advice!
>
> --
> Ben
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Mark.Bravington at csiro.au  Tue Feb 23 05:27:42 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Tue, 23 Feb 2010 15:27:42 +1100
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <20100222204947.09b458ce.misc7@emerose.org>
References: <20100222204947.09b458ce.misc7@emerose.org>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F870563192A1C@exvic-mbx03.nexus.csiro.au>

Ben--

FWIW my general take on this is:

 - Namespaces solve the collision issue.

 - Style 2 tends to make for unreadably long code inside Foo, unless the subfunctions are really short.

 - Style 3 is too hard to work with

 - So I usually use a variant on style 1:

################### Style 4 (mlocal-style) ############### 
Foo <-  function(x) { ....
   initialize.Foo()
}

initialize.Foo <- function( nlocal=sys.parent()) mlocal({
  ....
})

The 'mlocal' call means that code in the body of 'initialize.Foo' executes directly in the environment of 'Foo', or wherever it's called from-- it doesn't get its own private environment, and automatically reads/writes/creates variables in 'Foo'. However, you can still pass parameters that are private to 'initialize.Foo', though you may not need any. The 'debug' package will handle 'mlocal' functions without any trouble. One downside might be that you can't (or shouldn't) call 'initialize.Foo' directly. Another is if your sub-function creates a lot of junk variables that you really don't want in 'Foo'-- obviously that's exactly what you want from an initialization function, but not necessarily in general.

 - Sometimes (style 5) I define the subfunctions externally to 'Foo' but not as 'mlocal's, and then inside 'Foo' I do

subf <- subf
environment( subf) <- environment()

just as if I'd inserted the definition of 'subf' into 'Foo'. This is like style 2, but keeps the 'Foo' code short, and lets me set up debugging externally.

 - If you use style 2, you can still automatically set up the 'debug' package's debugging on 'Subf' by:

mtrace( Foo)
bp( fname='Foo', 1, FALSE) # don't stop at line 1
bp( fname='Foo', 2, { mtrace( Subf); FALSE}) #  set the breakpoint in 'Subf,' and then carry on in 'Foo' without stopping

You won't have to intervene manually when 'Foo' runs. However, this may slow down 'Foo' itself, and does require you to know a line number after the definition of 'Subf'.

No doubt there are many other approaches...

Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

Ben wrote:
> Hi all,
> 
> I'm hoping someone could tell me what best practices are as far as
> keeping programs organized in R.  In most languages, I like to keep
> things organized by writing small functions.  So, suppose I want to
> write a function that would require helper functions or would just be
> too big to write in one piece.  Below are three ways to do this:    
> 
> 
> ################### Style 1 (C-style) ############### Foo <-
>   function(x) { ....
> }
> Foo.subf <- function(x, blah) {
>   ....
> }
> Foo.subg <- function(x, bar) {
>   ....
> }
> 
> ################### Style 2 (Lispish?) ############## Foo <-
>   function(x) { Subf <- function(blah) {
>     ....
>   }
>   Subg <- function(bar) {
>     ....
>   }
>   ....
> }
> 
> ################### Object-Oriented ################# Foo <-
>   function(x) { Subf <- function(blah) {
>     ....
>   }
>   Subg <- function(bar) {
>     ....
>   }
>   Main <- function() {
>     ....
>   }
>   return(list(subf=subf, subg=subg, foo=foo)) } ###################
> End examples #################### 
> 
> Which of these ways is best?  Style 2 seems at first to be the most
> natural in R, but I found there are some major drawbacks.  First, it
> is hard to debug.  For instance, if I want to debug Subf, I need to
> first "debug(Foo)" and then while Foo is debugging, type
> "debug(Subf)".  Another big limitation is that I can't write
> test-cases (e.g. using RUnit) for Subf and Subg because they aren't
> visible in any way at the global level.      
> 
> For these reasons, style 1 seems to be better than style 2, if less
> elegant.  However, style 1 can get awkward because any parameters
> passed to the main function are not visible to the others.  In the
> above case, the value of "x" must be passed to Foo.subf and Foo.subg
> explicitly.  Also there is no enforcement of code isolation (i.e.
> anyone can call Foo.subf).     
> 
> Style 3 is more explicitly object oriented.  It has the advantage of
> style 2 in that you don't need to pass x around, and the advantage of
> style 1 in that you can still write tests and easily debug the
> subfunctions.  However to actually call the main function you have to
> type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
> function for this.  Either way there is more typing.     
> 
> So anyway, what is the best way to handle this?  R does not seem to
> have a good way of managing namespaces or avoiding collisions, like a
> module system or explicit object-orientation.  How should we get
> around this limitation?  I've looked at sample R code in the
> distribution and elsewhere, but so far it's been pretty
> disappointing---most people seem to write very long, hard to
> understand functions.      
> 
> Thanks for any advice!

From ripley at stats.ox.ac.uk  Tue Feb 23 08:33:48 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 Feb 2010 07:33:48 +0000 (GMT)
Subject: [Rd] patch about compile R with clang
In-Reply-To: <739921.71704.qm@web45909.mail.sp1.yahoo.com>
References: <739921.71704.qm@web45909.mail.sp1.yahoo.com>
Message-ID: <alpine.LFD.2.00.1002230710020.29357@gannet.stats.ox.ac.uk>

configure is a generated file, and so should not be edited directly. 
You have not told us what version of R these patches were against, but 
it looks to me as if wchar.h is included already in current R 
(R-patched/R-devel) -- certainly in the second case before wctype.h.
(It really should not be needed according to POSIX, but it was on 
MinGW-w64.   Also, headers are an issue not just for a compiler but an 
OS, and you have not told use that either.)

So can you please clarify what version of R, what OS, and what changes 
you think might be needed to m4/R.m4 in the R-devel version of R?

On Mon, 22 Feb 2010, Gong Yu wrote:

> clang is compiler http://clang.llvm.org, it is fast and better c 
> compiler then gcc, yesterday i use clang and gfortran compile R.

Hmm, it claims to be 'faster and better', but past reports on Mac OS X 
(it ships with Snow Leopard) suggested those claims to be exaggerated.
(It did not create as fast an R, although it compiled faster, and its 
error messages were markedly worse than other compilers despite claims 
to the contrary.)

> The only two change in source code is :
>
> 1. the configure file (in confiure when test include wctype.h,gcc can compile but clang need include both wchar.h wctype.h),so this is patch
> --- /r/configure
> +++ /myr/configure
> @@ -39172,6 +39172,7 @@
> cat >>conftest.$ac_ext <<_ACEOF
> /* end confdefs.h.  */
> $ac_includes_default
> +#include <wchar.h>
> #include <$ac_header>
> _ACEOF
> rm -f conftest.$ac_objext
> @@ -39480,6 +39481,7 @@
> cat confdefs.h >>conftest.$ac_ext
> cat >>conftest.$ac_ext <<_ACEOF
> /* end confdefs.h.  */
> +#include <wchar.h>
> #include <wctype.h>
>
> #ifdef F77_DUMMY_MAIN
>
>
> 2. edit tre-match-approx.c
> change the following line
> #define __USE_STRING_INLINES
> #undef __NO_INLINE__
> to
> //#define __USE_STRING_INLINES
> //#undef __NO_INLINE__
> becasue clang will report errors(fields must have a constant size:'variable length array in structure' extension will never be supported' in string.h)

Please use C comments not C++ ones: we prefer but do not require C99.

At least on my version of Linux (Fedora 12), these optimizations are 
only supposed to be used with 'GNU CC', and are inside a test for 
__GNUC__ >= 2.  So if clang is using them, this is a bug in clang (we 
have seem similar things with the Intel CC masquerading as GCC). 
Your OS may differ, of course.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From plummer at iarc.fr  Tue Feb 23 11:18:44 2010
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 23 Feb 2010 11:18:44 +0100
Subject: [Rd] Compiling R on Linux with SunStudio 12.1: "wide-character
 type" problems
In-Reply-To: <d6243f3f1002221111l2dae5dc8u3e4947de84961adb@mail.gmail.com>
References: <d6243f3f1002221111l2dae5dc8u3e4947de84961adb@mail.gmail.com>
Message-ID: <1266920324.2402.6.camel@localhost>

Russ,

This is a known issue with Sun Studio on Linux and was fixed by Brian
Ripley in January. If you download R-patched.tar.gz from here:

ftp://ftp.stat.math.ethz.ch/Software/R/

then it should work for you.

Martyn

On Mon, 2010-02-22 at 13:11 -0600, rt wrote:
> I am trying to compile R on Linux using SunStudio. Configure flags are
> mostly as suggested in the R install guide.
> 
> CC=/opt/sun/sunstudio12.1/bin/suncc
> CFLAGS="-g -xc99 -xlibmil -xlibmieee"
> MAIN_CFLAGS=-g
> SHLIB_CFLAGS=-g
> CPPFLAGS="-I. -I/opt/sun/sunstudio12.1/prod/include
> -I/opt/sun/sunstudio12.1/prod/include/cc"
> CPPFLAGS+="-I/opt/sun/sunstudio12.1/prod/include/cc/sys
> -I/usr/local/include"
> F77=/opt/sun/sunstudio12.1/bin/sunf95
> FFLAGS="-g -O -libmil "
> SAFE_FFLAGS="-g -libmil"
> CPICFLAGS=-Kpic
> FPICFLAGS=-Kpic
> SHLIB_LDFLAGS=-shared
> LDFLAGS=-L/opt/sun/sunstudio12.1/lib/386
> CXX=/opt/sun/sunstudio12.1/bin/sunCC
> CXXFLAGS="-g -xlibmil -xlibmieee"
> CXXPICFLAGS=-Kpic
> SHLIB_CXXLDFLAGS="-G -lCstd"
> FC=/opt/sun/sunstudio12.1/bin/sunf95
> FCFLAGS=$FFLAGS
> FCPICFLAGS=-Kpic
> MAKE=dmake
> 
> R install guide also indicates that: "The OS needs to have enough support
> for wide-character types: this is checked at configuration. Specifically,
> the C99 functionality of headers wchar.h and wctype.h, types wctans_t and
> mbstate_t and functions mbrtowc, mbstowcs, wcrtomb, wcscoll, wcstombs,
> wctrans, wctype, and iswctype."
> Configure stops with the following error message:
> 
> checking iconv.h usability... yes
> checking iconv.h presence... yes
> checking for iconv.h... yes
> checking for iconv... in libiconv
> checking whether iconv accepts "UTF-8", "latin1" and "UCS-"... yes
> checking for iconvlist... yes
> checking wchar.h usability... yes
> checking wchar.h presence... yes
> checking for wchar.h... yes
> checking wctype.h usability... yes
> checking wctype.h presence... yes
> checking for wctype.h... yes
> checking whether mbrtowc exists and is declared... yes
> checking whether wcrtomb exists and is declared... yes
> checking whether wcscoll exists and is declared... yes
> checking whether wcsftime exists and is declared... yes
> checking whether wcstod exists and is declared... yes
> checking whether mbstowcs exists and is declared... yes
> checking whether wcstombs exists and is declared... yes
> **checking whether wctrans exists and is declared... no
> checking whether iswblank exists and is declared... no
> checking whether wctype exists and is declared... no
> checking whether iswctype exists and is declared... no
> configure: error: Support for MBCS locales is required.*
> 
> Relevant parts of config.log are as follows:
> 
> configure:39472: checking whether iswctype exists and is declared
> configure:39510: /opt/sun/sunstudio12.1/bin/suncc -o conftest -g -xc99
> -xlibmil -xlibmieee -m32  -I. -I/opt/sun/sunstudio12.1/prod/include
> -I/opt/sun/sunstudio12.1/prod/include/cc-I/opt/sun/sunstudio12.1/prod/include/cc/sys
> -I/usr/local/include  -L/opt/sun/sunstudio12.1/lib/386 -L/usr/local/lib
> conftest.c -ldl -lm  -liconv >&5
> *"/usr/include/wctype.h", line 112: syntax error before or at: __wc
> "/usr/include/wctype.h", line 195: syntax error before or at: towlower
> "/usr/include/wctype.h", line 302: syntax error before or at: towupper_l
> "/usr/include/wctype.h", line 302: syntax error before or at: __wc
> "/usr/include/wctype.h", line 310: syntax error before or at: towctrans_l
> "/usr/include/wctype.h", line 310: syntax error before or at: __wc
> cc: acomp failed for conftest.c
> configure:39516: $? = 1
> configure: failed program was:
> | /* confdefs.h.  */
> *| #define PACKAGE_NAME "R"
> ........
> ........
> *| #include <wctype.h>
> *|
> | #ifdef F77_DUMMY_MAIN
> |
> | #  ifdef __cplusplus
> |      extern "C"
> | #  endif
> |    int F77_DUMMY_MAIN() { return 1; }
> |
> | #endif
> *| int
> | main ()
> | {
> | #ifndef iswctype
> |   char *p = (char *) iswctype;
> | #endif
> |
> |   ;
> |   return 0;
> | }
> configure:39534: result: no
> configure:39710: error: Support for MBCS locales is required.*
> 
> I am not sure if this is a Linux issue or if it is a SunStudio issue.  Has
> anybody tried to compile R on Linux using SunStudio?
> 
> Thanks in advance,
> 
> Russ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From murdoch at stats.uwo.ca  Tue Feb 23 23:42:25 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 23 Feb 2010 17:42:25 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
References: <20100222204947.09b458ce.misc7@emerose.org>
	<971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
Message-ID: <4B8459D1.5030901@stats.uwo.ca>

On 22/02/2010 10:15 PM, Gabor Grothendieck wrote:
> As you mention ease of debugging basically precludes subfunctions so
> style 1 is left.

I think you are also unaware of setBreakpoint() (and trace(), which 
underlies it).  So more detail:

If you put this into file test.R, starting on line 1:

outer <- function(x) {
    inner <- function() {
        if (x > 3) {
           x <- 0
        }
    }

    inner()
    print(x)
}

you might want to debug why outer(10) prints 10, not 0.  So set a 
breakpoint on line 4 to see if you get there:

 > setBreakpoint("test.R#4")
c:\temp\test.R#4:
  outer step 2,3,3,2,3,2 in <environment: R_GlobalEnv>
 > outer(10)
test.R#4
Called from: eval(expr, envir, enclos)
Browse[1]>

Yes, we got there.  Take a step:

Browse[1]> n
debug: x <- 0

Now recognize we should have used x <<- 0.

Now, it would be nice if we had more flexible debugging (e.g. single 
stepping that would stay as single stepping when we exited from 
inner()), but debug() is certainly not the only possibility for 
debugging.  It's not even the best choice in a lot of situations where 
it does work.

Duncan Murdoch

> 
> Functions can be nested in environments rather than in other functions
> and this will allow debugging to still occur.
> 
> The proto package which makes it particularly convenient to nest
> functions in environments giving an analog to #3 while still allowing
> debugging.  See http//:r-proto.googlecode.com
> 
>> library(proto)
>> # p is proto object with variable a and method f
>> p <- proto(a = 1, f = function(., x = 1) .$a <- .$a + 1)
>> with(p, debug(f))
>> p$f()
> debugging in: get("f", env = p, inherits = TRUE)(p, ...)
> debug: .$a <- .$a + 1
> Browse[2]>
> exiting from: get("f", env = p, inherits = TRUE)(p, ...)
> [1] 2
>> p$a
> [1] 2
> 
> 
> On Mon, Feb 22, 2010 at 9:49 PM, Ben <misc7 at emerose.org> wrote:
>> Hi all,
>>
>> I'm hoping someone could tell me what best practices are as far as
>> keeping programs organized in R.  In most languages, I like to keep
>> things organized by writing small functions.  So, suppose I want to
>> write a function that would require helper functions or would just be
>> too big to write in one piece.  Below are three ways to do this:
>>
>>
>> ################### Style 1 (C-style) ###############
>> Foo <- function(x) {
>>  ....
>> }
>> Foo.subf <- function(x, blah) {
>>  ....
>> }
>> Foo.subg <- function(x, bar) {
>>  ....
>> }
>>
>> ################### Style 2 (Lispish?) ##############
>> Foo <- function(x) {
>>  Subf <- function(blah) {
>>    ....
>>  }
>>  Subg <- function(bar) {
>>    ....
>>  }
>>  ....
>> }
>>
>> ################### Object-Oriented #################
>> Foo <- function(x) {
>>  Subf <- function(blah) {
>>    ....
>>  }
>>  Subg <- function(bar) {
>>    ....
>>  }
>>  Main <- function() {
>>    ....
>>  }
>>  return(list(subf=subf, subg=subg, foo=foo))
>> }
>> ################### End examples ####################
>>
>> Which of these ways is best?  Style 2 seems at first to be the most
>> natural in R, but I found there are some major drawbacks.  First, it
>> is hard to debug.  For instance, if I want to debug Subf, I need to
>> first "debug(Foo)" and then while Foo is debugging, type
>> "debug(Subf)".  Another big limitation is that I can't write
>> test-cases (e.g. using RUnit) for Subf and Subg because they aren't
>> visible in any way at the global level.
>>
>> For these reasons, style 1 seems to be better than style 2, if less
>> elegant.  However, style 1 can get awkward because any parameters
>> passed to the main function are not visible to the others.  In the
>> above case, the value of "x" must be passed to Foo.subf and Foo.subg
>> explicitly.  Also there is no enforcement of code isolation
>> (i.e. anyone can call Foo.subf).
>>
>> Style 3 is more explicitly object oriented.  It has the advantage of
>> style 2 in that you don't need to pass x around, and the advantage of
>> style 1 in that you can still write tests and easily debug the
>> subfunctions.  However to actually call the main function you have to
>> type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
>> function for this.  Either way there is more typing.
>>
>> So anyway, what is the best way to handle this?  R does not seem to
>> have a good way of managing namespaces or avoiding collisions, like a
>> module system or explicit object-orientation.  How should we get
>> around this limitation?  I've looked at sample R code in the
>> distribution and elsewhere, but so far it's been pretty
>> disappointing---most people seem to write very long, hard to
>> understand functions.
>>
>> Thanks for any advice!
>>
>> --
>> Ben
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From taylor.russ at gmail.com  Tue Feb 23 23:55:58 2010
From: taylor.russ at gmail.com (rt)
Date: Tue, 23 Feb 2010 16:55:58 -0600
Subject: [Rd] Compiling R on Linux with SunStudio 12.1: "wide-character
	type" problems (rt)
Message-ID: <d6243f3f1002231455n24503c8p4d6994865b693d1d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100223/872f0764/attachment.pl>

From mwkimpel at gmail.com  Wed Feb 24 02:05:14 2010
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Tue, 23 Feb 2010 20:05:14 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <4B8459D1.5030901@stats.uwo.ca>
References: <20100222204947.09b458ce.misc7@emerose.org>
	<971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
	<4B8459D1.5030901@stats.uwo.ca>
Message-ID: <6b93d1831002231705j7cfd39c2w94224f36fba80c16@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100223/3aab8dff/attachment.pl>

From misc7 at emerose.org  Wed Feb 24 03:35:25 2010
From: misc7 at emerose.org (Ben)
Date: Tue, 23 Feb 2010 20:35:25 -0600
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
References: <20100222204947.09b458ce.misc7@emerose.org>
	<971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
Message-ID: <20100223203525.23b7ec42.misc7@emerose.org>

Thanks to everyone for the responses so far.  I didn't know about
setBreakpoint, mlocal, or proto before.

I think I'll try using proto a lot more and see if that fixes most of
my problems.  It appeals to me for two bad reasons: I had run across
proto when reading the code to ggplot2 earlier but didn't know the
purpose before (and I like ggplot2 and plyr, so Hadley's endorsement
carries some weight with me).  Also it uses an explicit passing of the
object to instances of that object---it's similar to Python's self,
and I'm a big fan of Python.  Anyway, so much for rationality.

I find it interesting that everyone seems to run into this issue, and
everyone solves it in their own way.  I hadn't known that Mark's
mvbutils and Duncan's setBreakpoint (how do I get this function?)
existed before.  I also like Mark Kimpel's trick, which appeals to a
simple-minded person like me.

Either R needs to expand it's standard library, or there should be a
standard guide on what you really need to work productively.  I'd have
a hard time in R without ggplot2, plyr, RUnit, perhaps proto now, and
a few other functions and modules, but it's taken a while to figure
out what I needed.  It could be in 6 months I'll discover something
else and realize that I've been wasting my time all along.

Anyway, thanks again for all the responses!


-- 
Ben


From murdoch at stats.uwo.ca  Wed Feb 24 03:43:36 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 23 Feb 2010 21:43:36 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <20100223203525.23b7ec42.misc7@emerose.org>
References: <20100222204947.09b458ce.misc7@emerose.org>	<971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com>
	<20100223203525.23b7ec42.misc7@emerose.org>
Message-ID: <4B849258.7070606@stats.uwo.ca>

On 23/02/2010 9:35 PM, Ben wrote:
> Thanks to everyone for the responses so far.  I didn't know about
> setBreakpoint, mlocal, or proto before.
> 
> I think I'll try using proto a lot more and see if that fixes most of
> my problems.  It appeals to me for two bad reasons: I had run across
> proto when reading the code to ggplot2 earlier but didn't know the
> purpose before (and I like ggplot2 and plyr, so Hadley's endorsement
> carries some weight with me).  Also it uses an explicit passing of the
> object to instances of that object---it's similar to Python's self,
> and I'm a big fan of Python.  Anyway, so much for rationality.
> 
> I find it interesting that everyone seems to run into this issue, and
> everyone solves it in their own way.  I hadn't known that Mark's
> mvbutils and Duncan's setBreakpoint (how do I get this function?)

setBreakpoint is in the utils package, as of R 2.10.0.  It is just a 
front end to trace, which has been in the base package for quite a long 
time.

Duncan Murdoch

> existed before.  I also like Mark Kimpel's trick, which appeals to a
> simple-minded person like me.
> 
> Either R needs to expand it's standard library, or there should be a
> standard guide on what you really need to work productively.  I'd have
> a hard time in R without ggplot2, plyr, RUnit, perhaps proto now, and
> a few other functions and modules, but it's taken a while to figure
> out what I needed.  It could be in 6 months I'll discover something
> else and realize that I've been wasting my time all along.
> 
> Anyway, thanks again for all the responses!
> 
>


From ggrothendieck at gmail.com  Wed Feb 24 04:07:16 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 23 Feb 2010 22:07:16 -0500
Subject: [Rd] Best style to organize code, namespaces
In-Reply-To: <4B8459D1.5030901@stats.uwo.ca>
References: <20100222204947.09b458ce.misc7@emerose.org>
	<971536df1002221915m7968513le6153e6180152cd8@mail.gmail.com> 
	<4B8459D1.5030901@stats.uwo.ca>
Message-ID: <971536df1002231907k17dd6460kf499ac828d21af14@mail.gmail.com>

That's quite nice.  I see you did post about it last September when it
was added to the devel version of R:
http://www.mail-archive.com/r-devel at r-project.org/msg17708.html

Relative to this discussion what would be useful would be a facility
that debugs not only a function but also all embedded functions in it
so that, say

debug(outer, recursive = TRUE)

would turn on debug for both outer and inner.  In fact, recursive
might be the default in which case one would specify recursive = FALSE
to only debug the outer function.

Also it would be useful to extend that to environments so that
debug(e) would debug all functions directly in environment e.


On Tue, Feb 23, 2010 at 5:42 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 22/02/2010 10:15 PM, Gabor Grothendieck wrote:
>>
>> As you mention ease of debugging basically precludes subfunctions so
>> style 1 is left.
>
> I think you are also unaware of setBreakpoint() (and trace(), which
> underlies it). ?So more detail:
>
> If you put this into file test.R, starting on line 1:
>
> outer <- function(x) {
> ? inner <- function() {
> ? ? ? if (x > 3) {
> ? ? ? ? ?x <- 0
> ? ? ? }
> ? }
>
> ? inner()
> ? print(x)
> }
>
> you might want to debug why outer(10) prints 10, not 0. ?So set a breakpoint
> on line 4 to see if you get there:
>
>> setBreakpoint("test.R#4")
> c:\temp\test.R#4:
> ?outer step 2,3,3,2,3,2 in <environment: R_GlobalEnv>
>> outer(10)
> test.R#4
> Called from: eval(expr, envir, enclos)
> Browse[1]>
>
> Yes, we got there. ?Take a step:
>
> Browse[1]> n
> debug: x <- 0
>
> Now recognize we should have used x <<- 0.
>
> Now, it would be nice if we had more flexible debugging (e.g. single
> stepping that would stay as single stepping when we exited from inner()),
> but debug() is certainly not the only possibility for debugging. ?It's not
> even the best choice in a lot of situations where it does work.
>
> Duncan Murdoch
>
>>
>> Functions can be nested in environments rather than in other functions
>> and this will allow debugging to still occur.
>>
>> The proto package which makes it particularly convenient to nest
>> functions in environments giving an analog to #3 while still allowing
>> debugging. ?See http//:r-proto.googlecode.com
>>
>>> library(proto)
>>> # p is proto object with variable a and method f
>>> p <- proto(a = 1, f = function(., x = 1) .$a <- .$a + 1)
>>> with(p, debug(f))
>>> p$f()
>>
>> debugging in: get("f", env = p, inherits = TRUE)(p, ...)
>> debug: .$a <- .$a + 1
>> Browse[2]>
>> exiting from: get("f", env = p, inherits = TRUE)(p, ...)
>> [1] 2
>>>
>>> p$a
>>
>> [1] 2
>>
>>
>> On Mon, Feb 22, 2010 at 9:49 PM, Ben <misc7 at emerose.org> wrote:
>>>
>>> Hi all,
>>>
>>> I'm hoping someone could tell me what best practices are as far as
>>> keeping programs organized in R. ?In most languages, I like to keep
>>> things organized by writing small functions. ?So, suppose I want to
>>> write a function that would require helper functions or would just be
>>> too big to write in one piece. ?Below are three ways to do this:
>>>
>>>
>>> ################### Style 1 (C-style) ###############
>>> Foo <- function(x) {
>>> ?....
>>> }
>>> Foo.subf <- function(x, blah) {
>>> ?....
>>> }
>>> Foo.subg <- function(x, bar) {
>>> ?....
>>> }
>>>
>>> ################### Style 2 (Lispish?) ##############
>>> Foo <- function(x) {
>>> ?Subf <- function(blah) {
>>> ? ....
>>> ?}
>>> ?Subg <- function(bar) {
>>> ? ....
>>> ?}
>>> ?....
>>> }
>>>
>>> ################### Object-Oriented #################
>>> Foo <- function(x) {
>>> ?Subf <- function(blah) {
>>> ? ....
>>> ?}
>>> ?Subg <- function(bar) {
>>> ? ....
>>> ?}
>>> ?Main <- function() {
>>> ? ....
>>> ?}
>>> ?return(list(subf=subf, subg=subg, foo=foo))
>>> }
>>> ################### End examples ####################
>>>
>>> Which of these ways is best? ?Style 2 seems at first to be the most
>>> natural in R, but I found there are some major drawbacks. ?First, it
>>> is hard to debug. ?For instance, if I want to debug Subf, I need to
>>> first "debug(Foo)" and then while Foo is debugging, type
>>> "debug(Subf)". ?Another big limitation is that I can't write
>>> test-cases (e.g. using RUnit) for Subf and Subg because they aren't
>>> visible in any way at the global level.
>>>
>>> For these reasons, style 1 seems to be better than style 2, if less
>>> elegant. ?However, style 1 can get awkward because any parameters
>>> passed to the main function are not visible to the others. ?In the
>>> above case, the value of "x" must be passed to Foo.subf and Foo.subg
>>> explicitly. ?Also there is no enforcement of code isolation
>>> (i.e. anyone can call Foo.subf).
>>>
>>> Style 3 is more explicitly object oriented. ?It has the advantage of
>>> style 2 in that you don't need to pass x around, and the advantage of
>>> style 1 in that you can still write tests and easily debug the
>>> subfunctions. ?However to actually call the main function you have to
>>> type "Foo(x)$Main()" instead of "Foo(x)", or else write a wrapper
>>> function for this. ?Either way there is more typing.
>>>
>>> So anyway, what is the best way to handle this? ?R does not seem to
>>> have a good way of managing namespaces or avoiding collisions, like a
>>> module system or explicit object-orientation. ?How should we get
>>> around this limitation? ?I've looked at sample R code in the
>>> distribution and elsewhere, but so far it's been pretty
>>> disappointing---most people seem to write very long, hard to
>>> understand functions.
>>>
>>> Thanks for any advice!
>>>
>>> --
>>> Ben
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From edd at debian.org  Wed Feb 24 04:34:39 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 23 Feb 2010 21:34:39 -0600
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
Message-ID: <19332.40527.796777.558666@ron.nulle.part>


Google Summer of Code 2010 ("GSoC 2010") is starting in a few weeks and now
is the time to collect ideas.  At this point this is all we need: a list of
possible projects which will help the sponsor (ie Google) assess how serious
and prepared the R Project is, and how many slots we should get allocated.
For the record, we had four in both 2008 and 2009.

More details (incl timelines) about Summer of Code are at
http://socghop.appspot.com/document/show/gsoc_program/google/gsoc2010/faqs

So let us all start now by proposing some ideas for 2010.  It may make sense
to centralize and standardize this on wiki.r-project.org but until we have
that process sorted out lets just post ideas here on r-devel with a [SoC] tag
in the Subject: line.

Now: we need more than just an idea for a topic. To make this meaningful and
concrete, please send 

 - a brief project summary in a just a few words ("headline summary")

 - a more detailed description, with references or links to related work 

 - a list of skill requirements (programming languages, experience,
   methodologies, ...) for the prospective student

 - a test an applicant will have to pass in order to qualify for the topic
   (as topics will often attract multiple applicants this helps to find the
   truly qualified and motivated student ready to take this on over the three
   months period)

 - a mentor for the topic (which may well be you!)

For reference, previous R projects are summarized at 
	http://www.r-project.org/soc09/
	http://www.r-project.org/soc08/
and both pages have links to the respective ideas list.  Ideas were posted
here before; see the mailing list archives.

Thanks,  Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From h.wickham at gmail.com  Wed Feb 24 05:06:02 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 23 Feb 2010 22:06:02 -0600
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
In-Reply-To: <19332.40527.796777.558666@ron.nulle.part>
References: <19332.40527.796777.558666@ron.nulle.part>
Message-ID: <f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>

> So let us all start now by proposing some ideas for 2010. ?It may make sense
> to centralize and standardize this on wiki.r-project.org but until we have
> that process sorted out lets just post ideas here on r-devel with a [SoC] tag
> in the Subject: line.

One idea per email?

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From edd at debian.org  Wed Feb 24 05:27:46 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 23 Feb 2010 22:27:46 -0600
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
In-Reply-To: <f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>
References: <19332.40527.796777.558666@ron.nulle.part>
	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>
Message-ID: <19332.43714.30266.880554@ron.nulle.part>


On 23 February 2010 at 22:06, hadley wickham wrote:
| > So let us all start now by proposing some ideas for 2010. ?It may make sense
| > to centralize and standardize this on wiki.r-project.org but until we have
| > that process sorted out lets just post ideas here on r-devel with a [SoC] tag
| > in the Subject: line.
| 
| One idea per email?

Sure, works as a start. Or mayb better as one wiki.r-project.org entry per
idea because then we can all edit these rather having to noodle through
emails.  But I am unsure where to 'hang this' in the wiki namespace.  We
could also create a one-off at wikispaces.com or wikidot.comIf you have
another scratch wiki somewhere....

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From buhr at biostat.wisc.edu  Tue Feb 23 22:25:09 2010
From: buhr at biostat.wisc.edu (buhr at biostat.wisc.edu)
Date: Tue, 23 Feb 2010 22:25:09 +0100 (CET)
Subject: [Rd] survival package: Surv handles invalid intervals (start time >
	stop (PR#14221)
Message-ID: <20100223212509.738F2282EEFA@mail.pubhealth.ku.dk>

This is a multi-part message in MIME format.
--------------080605010703060205070700
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

In the latest version of the survival package (2.35-8), the Surv 
function handles invalid intervals (where start time is greater than 
stop time) by issuing a warning that NAs have been created and then 
setting the left endpoint of the offending intervals to NA. However, the 
code that sets the endpoint to NA subsets incorrectly, and in some 
circumstances an arbitrary selection of intervals will have an endpoint 
set to NA.

For example, for the interval/event data:

     interval    event
     (NA, 10]    1
     (1,   5]    1
     (6,   4]    1

the appropriate Surv call **should** result in a warning and the left 
endpoint of the third, invalid interval being set to NA, as here:

>  Surv(c(NA,1,6),c(10,5,4),c(1,1,1))
[1] (NA,10 ] ( 1, 5 ] (NA, 4 ]
Warning message:
In Surv(c(NA, 1, 6), c(10, 5, 4), c(1, 1, 1)) :
   Stop time must be>  start time, NA created
>

However, the Surv call **actually** results in:

>  Surv(c(NA,1,6), c(10,5,4), c(1,1,1))
[1] (NA,10 ] (NA, 5 ] ( 6, 4 ]
Warning message:
In Surv(c(NA, 1, 6), c(10, 5, 4), c(1, 1, 1)) :
   Stop time must be>  start time, NA created
>

Note that the endpoint of the valid, second interval has been set to NA 
in place of the invalid, third interval.

A similar problem exists for type="interval2" type data. The 
**expected** behavior is:

>  Surv(c(NA,1,6), c(10,5,4), type="interval2")
[1] 10-     [ 1, 5] [NA, 4]
Warning message:
In Surv(c(NA, 1, 6), c(10, 5, 4), type = "interval2") :
   Invalid interval: start>  stop, NA created
>

but the **actual** behavior is:

>  Surv(c(NA,1,6), c(10,5,4), type="interval2")
[1] 10-     [NA, 5] [ 6, 4]
Warning message:
In Surv(c(NA, 1, 6), c(10, 5, 4), type = "interval2") :
   Invalid interval: start>  stop, NA created
>

The attached patch fixes the problem.

-- 
Kevin Buhr<buhr at biostat.wisc.edu>                Phone: +1 608 265 4587
Assistant Scientist                                Fax: +1 608 263 0415
Statistical Data Analysis Center
Room 211, WARF Office Building, 610 Walnut St., Madison, WI  53726-2397


--------------080605010703060205070700
Content-Type: text/x-patch;
 name="Surv-subset-bug.patch"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename="Surv-subset-bug.patch"

diff --git a/survival/R/Surv.S b/survival/R/Surv.S
index 9257ea0..50b3b85 100644
--- a/survival/R/Surv.S
+++ b/survival/R/Surv.S
@@ -56,7 +56,7 @@ Surv <- function(time, time2, event,
 	if (!is.numeric(time2)) stop("Stop time is not numeric")
 	who3 <- !(is.na(time) | is.na(time2))
 	if (any (time[who3]>= time2[who3])) {
-	    time[time[who3]>= time2[who3]] <- NA
+	    time[who3][time[who3]>= time2[who3]] <- NA
 	    warning("Stop time must be > start time, NA created")
 	    }
 	if (is.logical(event)) status <- as.numeric(event)
@@ -105,7 +105,7 @@ Surv <- function(time, time2, event,
 
 	temp <- (time[status==3] > time2[status==3])
 	if (any(temp & !is.na(temp))) {
-	    time[temp] <- NA
+	    time[status==3][temp] <- NA
 	    warning("Invalid interval: start > stop, NA created")
 	    }
 

--------------080605010703060205070700--


From dsimcha at gmail.com  Wed Feb 24 04:43:57 2010
From: dsimcha at gmail.com (David Simcha)
Date: Tue, 23 Feb 2010 22:43:57 -0500
Subject: [Rd] O(N log N) impl of Kendall's Tau
Message-ID: <4B84A07D.2040003@gmail.com>

I've attached an O(N log N) implementation of Kendall's Tau, which I 
hope will eventually replace the O(N^2) version currently implemented in 
R.  For N = 30,000 it's several hundred times faster than the old 
version.  The core algorithm comes with a lot of tests, which are 
included in the kendall.c file.  However, I've not yet integrated this 
code into the rest of R because, honestly, the code in cor.c is 
inscrutable and intermingles computing Kendall's Tau with dealing with 
missing values and computing other kinds of correlation.  I'd like one 
of the core devs' help with the integration.  The details of the 
algorithm and how to use it are explained in the comments inside kendall.c.

Please let me know what else I can do to help get this improvement 
folded into R.

--David Simcha
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: kendall.c
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100223/077b46e0/attachment.c>

From friedrich.leisch at stat.uni-muenchen.de  Wed Feb 24 10:50:22 2010
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 24 Feb 2010 10:50:22 +0100
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
In-Reply-To: <19332.43714.30266.880554@ron.nulle.part>
References: <19332.40527.796777.558666@ron.nulle.part>
	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>
	<19332.43714.30266.880554@ron.nulle.part>
Message-ID: <19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>

>>>>> On Tue, 23 Feb 2010 22:27:46 -0600,
>>>>> Dirk Eddelbuettel (DE) wrote:

  > On 23 February 2010 at 22:06, hadley wickham wrote:
  > | > So let us all start now by proposing some ideas for 2010. ?It may make sense
  > | > to centralize and standardize this on wiki.r-project.org but until we have
  > | > that process sorted out lets just post ideas here on r-devel with a [SoC] tag
  > | > in the Subject: line.
  > | 
  > | One idea per email?

  > Sure, works as a start. Or mayb better as one wiki.r-project.org entry per
  > idea because then we can all edit these rather having to noodle through
  > emails.  But I am unsure where to 'hang this' in the wiki namespace.  We
  > could also create a one-off at wikispaces.com or wikidot.comIf you have
  > another scratch wiki somewhere....

I think wiki.r-project.org would be a great place, I'd "hang it" into
the developers section. Then we could have a look at GSoC 2010 ideas
when GSoC 2011 arrives ...

Best,
Fritz


From phgrosjean at sciviews.org  Wed Feb 24 11:09:05 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 24 Feb 2010 11:09:05 +0100
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
In-Reply-To: <19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>
References: <19332.40527.796777.558666@ron.nulle.part>	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>	<19332.43714.30266.880554@ron.nulle.part>
	<19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>
Message-ID: <4B84FAC1.80409@sciviews.org>

Hello,

I have created the "projects" subsection in "developers". The Google 
Summer of Code 2010 is at 
http://rwiki.sciviews.org/doku.php?id=developers:projects:googlesummer2010

Best,

Philippe
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 24/02/10 10:50, Friedrich Leisch wrote:
>>>>>> On Tue, 23 Feb 2010 22:27:46 -0600,
>>>>>> Dirk Eddelbuettel (DE) wrote:
>
>    >  On 23 February 2010 at 22:06, hadley wickham wrote:
>    >  |>  So let us all start now by proposing some ideas for 2010.  It may make sense
>    >  |>  to centralize and standardize this on wiki.r-project.org but until we have
>    >  |>  that process sorted out lets just post ideas here on r-devel with a [SoC] tag
>    >  |>  in the Subject: line.
>    >  |
>    >  | One idea per email?
>
>    >  Sure, works as a start. Or mayb better as one wiki.r-project.org entry per
>    >  idea because then we can all edit these rather having to noodle through
>    >  emails.  But I am unsure where to 'hang this' in the wiki namespace.  We
>    >  could also create a one-off at wikispaces.com or wikidot.comIf you have
>    >  another scratch wiki somewhere....
>
> I think wiki.r-project.org would be a great place, I'd "hang it" into
> the developers section. Then we could have a look at GSoC 2010 ideas
> when GSoC 2011 arrives ...
>
> Best,
> Fritz
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From phgrosjean at sciviews.org  Wed Feb 24 17:25:09 2010
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Wed, 24 Feb 2010 17:25:09 +0100 (CET)
Subject: [Rd] Typo in the man page of ?cutree (PR#14223)
Message-ID: <20100224162510.013D62830317@mail.pubhealth.ku.dk>

In the examples section of ?cutree (stats package):

hc <- hclust(dist(USArrests))

cutree(hc, k=1:5)#k = 1 is trivial
cutree(hc, h=250)

## Compare the 2 and 3 grouping: <<= SHOULD READ AS: "2 and 4 grouping"
g24 <- cutree(hc, k = c(2,4))
table(g24[,"2"], g24[,"4"])


From therneau at mayo.edu  Wed Feb 24 17:42:06 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 24 Feb 2010 10:42:06 -0600
Subject: [Rd] Suppressing a warning from library()
Message-ID: <1267029726.27561.18.camel@punchbuggy>

I get a warning about "1 warning message" using R CMD check on the
survival library.  It comes from the code snippet:

   if (library(cmprsk, logical.return=TRUE)) {
	# further test of competing risks from survfit
	.
	.
	}
This is a very useful additional test when I'm checking any changes to
the affected code, so I like having this in my test suite even though it
doesn't run automatically.  

This argues for a change in library -- when the user sets logical.return
=T they don't need a warning message too.  I submit this to the R core
and their collective wisdom.

I admit that mine is an unusual case, and for now I'll turn if off with
options(warn=-1) 

Terry T.


From edd at debian.org  Wed Feb 24 18:08:15 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 24 Feb 2010 11:08:15 -0600
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
In-Reply-To: <4B84FAC1.80409@sciviews.org>
References: <19332.40527.796777.558666@ron.nulle.part>
	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>
	<19332.43714.30266.880554@ron.nulle.part>
	<19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>
	<4B84FAC1.80409@sciviews.org>
Message-ID: <19333.23807.803943.487024@ron.nulle.part>


On 24 February 2010 at 11:09, Philippe Grosjean wrote:
| I have created the "projects" subsection in "developers". The Google 
| Summer of Code 2010 is at 
| http://rwiki.sciviews.org/doku.php?id=developers:projects:googlesummer2010

We dediced to make this 

   http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010

to stick with the common 'GSoC' acronym.  So go ahead and submit ideas!

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From p.dalgaard at biostat.ku.dk  Wed Feb 24 18:13:14 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 24 Feb 2010 18:13:14 +0100
Subject: [Rd] Suppressing a warning from library()
In-Reply-To: <1267029726.27561.18.camel@punchbuggy>
References: <1267029726.27561.18.camel@punchbuggy>
Message-ID: <4B855E2A.2020809@biostat.ku.dk>

Terry Therneau wrote:
> I get a warning about "1 warning message" using R CMD check on the
> survival library.  It comes from the code snippet:
> 
>    if (library(cmprsk, logical.return=TRUE)) {
> 	# further test of competing risks from survfit
> 	.
> 	.
> 	}
> This is a very useful additional test when I'm checking any changes to
> the affected code, so I like having this in my test suite even though it
> doesn't run automatically.  
> 
> This argues for a change in library -- when the user sets logical.return
> =T they don't need a warning message too.  I submit this to the R core
> and their collective wisdom.
> 
> I admit that mine is an unusual case, and for now I'll turn if off with
> options(warn=-1) 

Probably, wrapping in suppressWarnings() is better.

-p


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From somorcik at fmph.uniba.sk  Wed Feb 24 15:10:08 2010
From: somorcik at fmph.uniba.sk (somorcik at fmph.uniba.sk)
Date: Wed, 24 Feb 2010 15:10:08 +0100 (CET)
Subject: [Rd] bug in "R Help on 'rmultinom()'" (PR#14222)
Message-ID: <20100224141008.E5D8E282EFFB@mail.pubhealth.ku.dk>

Full_Name: Jan Somorcik
Version: 
OS: 
Submission from: (NULL) (158.195.31.33)


The explanation of "rmultinom()" in R Help contains an obvious bug. The original
statement

"The 'rmultinom()' algorithm draws binomials from Bin(n[j], P[j]) sequentially,
where n[1] = N (N := 'size'), P[1] = p[1] (p is 'prob' scaled to sum 1), and for
j >= 2, recursively n[j]= N - sum(k=1, .., j-1) n[k] and P[j]= p[j] / (1 -
sum(p[1:(j-1)]))."

should be corrected, e.g. as follows:

"...draws binomials X[j] from.............., recursively n[j]= N - sum(k=1, ..,
j-1) X[k]"


From ripley at stats.ox.ac.uk  Wed Feb 24 18:39:29 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Feb 2010 17:39:29 +0000 (GMT)
Subject: [Rd] Suppressing a warning from library()
In-Reply-To: <1267029726.27561.18.camel@punchbuggy>
References: <1267029726.27561.18.camel@punchbuggy>
Message-ID: <alpine.OSX.1.00.1002241648540.8228@tystie.local>

On Wed, 24 Feb 2010, Terry Therneau wrote:

> I get a warning about "1 warning message" using R CMD check on the
> survival library.  It comes from the code snippet:
>
>   if (library(cmprsk, logical.return=TRUE)) {
> 	# further test of competing risks from survfit
> 	.
> 	.
> 	}
> This is a very useful additional test when I'm checking any changes to
> the affected code, so I like having this in my test suite even though it
> doesn't run automatically.
>
> This argues for a change in library -- when the user sets logical.return
> =T they don't need a warning message too.

It was the considered opinion that in general they do.  You can always 
use suppressWarnings() in your code if you don't, or you can pre-check 
that the package is available via lower-level functions such as 
.packages and .find.package.

> I submit this to the R core and their collective wisdom.
>
> I admit that mine is an unusual case, and for now I'll turn if off with
> options(warn=-1)
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Wed Feb 24 19:11:07 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 24 Feb 2010 12:11:07 -0600
Subject: [Rd] Suppressing a warning from library()
In-Reply-To: <alpine.OSX.1.00.1002241648540.8228@tystie.local>
References: <1267029726.27561.18.camel@punchbuggy>
	<alpine.OSX.1.00.1002241648540.8228@tystie.local>
Message-ID: <1267035067.27561.21.camel@punchbuggy>

The suppressWarnings construct looks like a good idea; I was not aware
of it's existence.

Thanks for the feedback.

	Terry T.


From gunter.berton at gene.com  Thu Feb 25 02:05:13 2010
From: gunter.berton at gene.com (gunter.berton at gene.com)
Date: Thu, 25 Feb 2010 02:05:13 +0100 (CET)
Subject: [Rd] grid unit bug? (PR#14220)
Message-ID: <20100225010513.E9C40283031C@mail.pubhealth.ku.dk>

Paul:

I figured that would be the problem.

I encountered the issue when I tries to check arguments in a validDetails
method for a grob.

Could one substitute the following function in the grid namespace?

is.numeric <- function(x)if(is.unit(x))TRUE else is.numeric(x)

(or make the first clause FALSE)

Obviously, messing around like this might be dangerous -- or at least would
compromise execution speed.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
 
 

-----Original Message-----
From: paul murrell [mailto:R-bugs at r-project.org] 
Sent: Wednesday, February 24, 2010 4:22 PM
To: gunter.berton at gene.com
Subject: Re: grid unit bug? (PR#14220)

> The following seems to me to be at least a perverse trap, if not an =
> outright
> bug:
> 
>> is.numeric(unit(1,"npc"))
> [1] TRUE
>> is.numeric(1*unit(1,"npc"))
> [1] FALSE
>> is.numeric(unit(0,"npc") +unit(1,"npc"))
> [1] FALSE
> 
> ...etc.
> i.e. is.numeric() appears to be TRUE for class "unit" but false for =
> class
> ("unit.arithmetic" "unit" ). Seems to me it ought to b the same for =
> both.


These results simply reflect the underlying data structures (simple "unit"s
are
just numeric vectors, but more complex "unit.arithmetic"s are lists).  I
don't
see how I can "hide" the numeric-ness of simple units (just like there's no
way
to stop a "ts" object like 'Nile' from satisfying is.numeric()).  I could
re-implement simple units as lists, but (apart from the work involved) that
would be (even) less efficient.

1. Is there a situation where this causes a problem?

2. Do you have a possible "fix" in mind?

Paul


> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (FWIW, I think grid graphics is brilliant!)
> 
> This was R version 2.11.0dev for Windows btw (not that it makes a
> difference):
> 
> sessionInfo()
> 
> R version 2.11.0 Under development (unstable) (2010-02-15 r51142)=20
> i386-pc-mingw32=20
> 
> locale:
> [1] LC_COLLATE=3DEnglish_United States.1252=20
> [2] LC_CTYPE=3DEnglish_United States.1252  =20
> [3] LC_MONETARY=3DEnglish_United States.1252
> [4] LC_NUMERIC=3DC                         =20
> [5] LC_TIME=3DEnglish_United States.1252   =20
> 
> attached base packages:
>  [1] datasets  splines   grid      tcltk     stats     graphics  =
> grDevices
>  [8] utils     methods   base    =20
> 
> other attached packages:
> [1] TinnR_1.0.3     R2HTML_1.59-1   Hmisc_3.7-0     survival_2.35-8
> [5] svSocket_0.9-48 lattice_0.18-3  MASS_7.3-5    =20
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.12.1 svMisc_0.9-56
> 
> 
> 
> =A0
> =A0
> 
>


From pcd at roxygen.org  Thu Feb 25 05:38:54 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Wed, 24 Feb 2010 22:38:54 -0600
Subject: [Rd] proto and baseenv()
Message-ID: <20100225043854.GA26106@klutometis.wikitex.org>

I understand why the following happens ($.proto delegates to get,
which ascends the parent hierarchy up to globalenv()), but I still
find it anti-intuitive:

  > z <- 1
  > y <- proto(a=2)
  > y$z
  [1] 1

Although this is well-documented behavior; wouldn't it uphold the
principle of least surprise to inherit instead from baseenv() or
emptyenv()? (See attached patch.)

Spurious parent definitions have already been the source of bizarre
bugs, prompting me to use proto like this:

  > z <- 1
  > y <- proto(baseenv(), a=2)
  > y$z
  Error in get(x, env = this, inherits = inh) : object 'z' not found

It's cumbersome, but it ensures that parent definitions don't pollute
my object space; I would rather that be the default behaviour, though.


From misc7 at emerose.org  Thu Feb 25 06:33:50 2010
From: misc7 at emerose.org (Ben)
Date: Wed, 24 Feb 2010 23:33:50 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225043854.GA26106@klutometis.wikitex.org>
References: <20100225043854.GA26106@klutometis.wikitex.org>
Message-ID: <20100224233350.4e3da5db.misc7@emerose.org>

Wow, thanks for the heads-up.  That is horrible behavior.  But using
baseenv() doesn't seem like the solution either.  I'm new to proto,
but it seems like this is also a big drawback:

> z <- 1
> proto(baseenv(), expr={a=z})$a
Error in eval(expr, envir, enclos) : object "z" not found


-- 
Ben


----------------- Original message -----------------
From: Peter Danenberg <pcd at roxygen.org>
To: r-devel at r-project.org
Date: Wed, 24 Feb 2010 22:38:54 -0600
I understand why the following happens ($.proto delegates to get,
which ascends the parent hierarchy up to globalenv()), but I still
find it anti-intuitive:

  > z <- 1
  > y <- proto(a=2)
  > y$z
  [1] 1

Although this is well-documented behavior; wouldn't it uphold the
principle of least surprise to inherit instead from baseenv() or
emptyenv()? (See attached patch.)

Spurious parent definitions have already been the source of bizarre
bugs, prompting me to use proto like this:

  > z <- 1
  > y <- proto(baseenv(), a=2)
  > y$z
  Error in get(x, env = this, inherits = inh) : object 'z' not found

It's cumbersome, but it ensures that parent definitions don't pollute
my object space; I would rather that be the default behaviour, though.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu Feb 25 08:12:54 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Feb 2010 07:12:54 +0000 (GMT)
Subject: [Rd] grid unit bug? (PR#14220)
In-Reply-To: <20100225010513.E9C40283031C@mail.pubhealth.ku.dk>
References: <20100225010513.E9C40283031C@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.1002250708460.29162@gannet.stats.ox.ac.uk>

is.numeric() is generic.  So grid could include

is.numeric.unit <- function(x) FALSE

and register it in its namespace.   Or Bert could define it in his 
application.


On Thu, 25 Feb 2010, gunter.berton at gene.com wrote:

> Paul:
>
> I figured that would be the problem.
>
> I encountered the issue when I tries to check arguments in a validDetails
> method for a grob.
>
> Could one substitute the following function in the grid namespace?
>
> is.numeric <- function(x)if(is.unit(x))TRUE else is.numeric(x)
>
> (or make the first clause FALSE)
>
> Obviously, messing around like this might be dangerous -- or at least would
> compromise execution speed.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
>
>
> -----Original Message-----
> From: paul murrell [mailto:R-bugs at r-project.org]
> Sent: Wednesday, February 24, 2010 4:22 PM
> To: gunter.berton at gene.com
> Subject: Re: grid unit bug? (PR#14220)
>
>> The following seems to me to be at least a perverse trap, if not an =
>> outright
>> bug:
>>
>>> is.numeric(unit(1,"npc"))
>> [1] TRUE
>>> is.numeric(1*unit(1,"npc"))
>> [1] FALSE
>>> is.numeric(unit(0,"npc") +unit(1,"npc"))
>> [1] FALSE
>>
>> ...etc.
>> i.e. is.numeric() appears to be TRUE for class "unit" but false for =
>> class
>> ("unit.arithmetic" "unit" ). Seems to me it ought to b the same for =
>> both.
>
>
> These results simply reflect the underlying data structures (simple "unit"s
> are
> just numeric vectors, but more complex "unit.arithmetic"s are lists).  I
> don't
> see how I can "hide" the numeric-ness of simple units (just like there's no
> way
> to stop a "ts" object like 'Nile' from satisfying is.numeric()).  I could
> re-implement simple units as lists, but (apart from the work involved) that
> would be (even) less efficient.
>
> 1. Is there a situation where this causes a problem?
>
> 2. Do you have a possible "fix" in mind?
>
> Paul
>
>
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (FWIW, I think grid graphics is brilliant!)
>>
>> This was R version 2.11.0dev for Windows btw (not that it makes a
>> difference):
>>
>> sessionInfo()
>>
>> R version 2.11.0 Under development (unstable) (2010-02-15 r51142)=20
>> i386-pc-mingw32=20
>>
>> locale:
>> [1] LC_COLLATE=3DEnglish_United States.1252=20
>> [2] LC_CTYPE=3DEnglish_United States.1252  =20
>> [3] LC_MONETARY=3DEnglish_United States.1252
>> [4] LC_NUMERIC=3DC                         =20
>> [5] LC_TIME=3DEnglish_United States.1252   =20
>>
>> attached base packages:
>>  [1] datasets  splines   grid      tcltk     stats     graphics  =
>> grDevices
>>  [8] utils     methods   base    =20
>>
>> other attached packages:
>> [1] TinnR_1.0.3     R2HTML_1.59-1   Hmisc_3.7-0     survival_2.35-8
>> [5] svSocket_0.9-48 lattice_0.18-3  MASS_7.3-5    =20
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.12.1 svMisc_0.9-56
>>
>>
>>
>> =A0
>> =A0
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pcd at roxygen.org  Thu Feb 25 10:58:15 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 03:58:15 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100224233153.a254588f.ben@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233153.a254588f.ben@emerose.org>
Message-ID: <20100225095815.GA31673@klutometis.wikitex.org>

Quoth Ben Escoto on Sweetmorn, the 56th of Chaos:
> I'm new to proto, but it seems like this is also a big drawback:
> 
> > z <- 1
> > proto(baseenv(), expr={a=z})$a
> Error in eval(expr, envir, enclos) : object "z" not found

Ouch, good point; it may be that parent pollution is the lesser of two
evils, then.

It's a little bit of a catch 22, it seems; because even if you ascend
up the parent hierarchy until you hit a non-prototype, the first
environment that has `a' also has `z':

  > library(proto)
  > get.proto <- function(x, env) {
  +   print(list(env=env,
  +              ls=ls(env, all.names=TRUE)))
  +   if (is.proto(env))
  +     tryCatch(get(x, env=env, inherits=FALSE),
  +              error=function(e) get.proto(x, env$.super))
  +   else
  +     stop(sprintf('object \'%s\' not found', x))
  +
  + }
  >
  > (function() { z <- 1; get.proto('a', proto(eval={a=z})) })()
  $env
  <environment: 0x1d12180>
  attr(,"class")
  [1] "proto"       "environment"

  $ls
  [1] ".super" ".that"  "eval"

  $env
  <environment: 0x1d12918>

  $ls
  [1] "a" "z"

  Error in get.proto(x, env$.super) : object 'a' not found
  > 

So, even if the $ environment diverged, say, from the eval
environment; the first relevant environment is already polluted.

It almost seems like you have to choose between eval and parent
pollution (unless I'm missing something).


From ggrothendieck at gmail.com  Thu Feb 25 12:49:09 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Feb 2010 06:49:09 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100224233350.4e3da5db.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
Message-ID: <971536df1002250349v3340e65fi3b4252ea4f53dc39@mail.gmail.com>

That is how R works with free variables, e.g.

z <- 1
f <- function() z
f() # 1

so the current behavior seems consistent with the rest of R.

Note that the example below could be done like this to avoid the error:

> z <- 1
> proto(baseenv(), a = z)$a
[1] 1

On Thu, Feb 25, 2010 at 12:33 AM, Ben <misc7 at emerose.org> wrote:
> Wow, thanks for the heads-up. ?That is horrible behavior. ?But using
> baseenv() doesn't seem like the solution either. ?I'm new to proto,
> but it seems like this is also a big drawback:
>
>> z <- 1
>> proto(baseenv(), expr={a=z})$a
> Error in eval(expr, envir, enclos) : object "z" not found
>
>
> --
> Ben
>
>
> ----------------- Original message -----------------
> From: Peter Danenberg <pcd at roxygen.org>
> To: r-devel at r-project.org
> Date: Wed, 24 Feb 2010 22:38:54 -0600
> I understand why the following happens ($.proto delegates to get,
> which ascends the parent hierarchy up to globalenv()), but I still
> find it anti-intuitive:
>
> ?> z <- 1
> ?> y <- proto(a=2)
> ?> y$z
> ?[1] 1
>
> Although this is well-documented behavior; wouldn't it uphold the
> principle of least surprise to inherit instead from baseenv() or
> emptyenv()? (See attached patch.)
>
> Spurious parent definitions have already been the source of bizarre
> bugs, prompting me to use proto like this:
>
> ?> z <- 1
> ?> y <- proto(baseenv(), a=2)
> ?> y$z
> ?Error in get(x, env = this, inherits = inh) : object 'z' not found
>
> It's cumbersome, but it ensures that parent definitions don't pollute
> my object space; I would rather that be the default behaviour, though.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Thomas.Petzoldt at TU-Dresden.de  Thu Feb 25 13:02:40 2010
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Thu, 25 Feb 2010 13:02:40 +0100
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100224233350.4e3da5db.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
Message-ID: <4B8666E0.4070808@TU-Dresden.de>

Am 25.02.2010 06:33, wrote Ben:
> Wow, thanks for the heads-up.  That is horrible behavior.  But using
> baseenv() doesn't seem like the solution either.  I'm new to proto,
> but it seems like this is also a big drawback:
>
>> z<- 1
>> proto(baseenv(), expr={a=z})$a
> Error in eval(expr, envir, enclos) : object "z" not found
>
>

I would say that this behaviour is intentional and not "horrible". proto 
objects do simply the same as ordinary functions in R that have also 
full access to variables and functions at a higher level:

Try the following:

 > y <- proto(a=2)
 > y$ls()
[1] "a"


ls() is defined in package base and so would even work if you inherit 
from baseenv() so why it is surprising that proto objects (by default) 
inherit objects from other packages and from the user workspace?


Thomas P.


From jgibson at hhcorp.org  Wed Feb 24 19:30:15 2010
From: jgibson at hhcorp.org (jgibson at hhcorp.org)
Date: Wed, 24 Feb 2010 19:30:15 +0100 (CET)
Subject: [Rd] wishlist: Clarify how to auto-load libraries at R start-up
	(PR#14224)
Message-ID: <20100224183015.96B9B282EF51@mail.pubhealth.ku.dk>

Full_Name: Joe Gibson
Version: 2.9.2
OS: Windows
Submission from: (NULL) (12.229.76.26)


I am new to R.  Setting up R for my epidemiology department, I want users to
have access to ggplot2 functions without having to remember to load that library
before using the functions.  It was very challenging to find how to do that. 
This will help others who wish to make R easy to use for less tech-y
colleagues:

1) In the "Note" section of library() function help
[R_home\library\base\html\library.html], add something like this:
To have libraries loaded by default when R is launched, add this code to the
?R_HOME/etc/Rprofile.site? file 
local({
       old <- getOption("defaultPackages")
       options(defaultPackages = c(old, "ggplot2"))
     })
To find the R_HOME folder, use
Sys.getenv("R_home")
(I only know that this works in Windows.  I adapted that code from
http://socserv.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html )

2) Just before 6.3.1 in
http://cran.r-project.org/doc/manuals/R-admin.html#Managing-libraries , add a
paragraph saying: "NOTE: The functions in an installed add-on package are not
available until the package is loaded.  See the library() function help for more
information."


From misc7 at emerose.org  Thu Feb 25 14:50:38 2010
From: misc7 at emerose.org (Ben)
Date: Thu, 25 Feb 2010 07:50:38 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <4B8666E0.4070808@TU-Dresden.de>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
Message-ID: <20100225075038.79ca9b63.misc7@emerose.org>

I was disappointed in this behavior because it seems error-prone.
Suppose I declare an environment

> b <- 1
> p <- proto(expr={
    a <- 2
+   ...
+ })
> p$a
[1] 2
> p$b
[1] 1

Presumably if I ask for p$a or p$b later, it's because I'm interesting
in the value of "p$a" or "p$b" that I specifically put inside that
environment.  Otherwise I would just ask for "a" or "b".  If I'm
asking for "p$b" it the above case, that means I forgot to declare b
inside p.  In this case there should be an error telling me that, not
a silent substitution of the wrong quantity.

If someone wanted to do the y$ls() thing, they could always

> y <- proto(a=1)
> with(y, ls())
[1] "a"

Another reason is that there are plenty of other programming languages
that have similar structures and this behavior is very odd.  In
standard languages asking for "b" inside the "p" object gives you an
error, and no one complains.  Even in R, we have this behavior:

> z <- 1
> list(a=3)$z
NULL

(Actually I think the above should be an error, but at least it isn't
1.)  So anyway, I'm not saying that p$b being 1 is an outright 2+2=5
bug, but it does seem to be surprising behavior that leads to bugs.
But I'm sure you're right that there are historical/structural reasons
for this to be the case, so perhaps there's no solution.


-- 
Ben Escoto

----------------- Original message -----------------
From: Thomas Petzoldt <Thomas.Petzoldt at TU-Dresden.de>
To: Ben <misc7 at emerose.org>
Date: Thu, 25 Feb 2010 13:02:40 +0100
Am 25.02.2010 06:33, wrote Ben:
> Wow, thanks for the heads-up.  That is horrible behavior.  But using
> baseenv() doesn't seem like the solution either.  I'm new to proto,
> but it seems like this is also a big drawback:
>
>> z<- 1
>> proto(baseenv(), expr={a=z})$a
> Error in eval(expr, envir, enclos) : object "z" not found
>
>

I would say that this behaviour is intentional and not "horrible". proto 
objects do simply the same as ordinary functions in R that have also 
full access to variables and functions at a higher level:

Try the following:

 > y <- proto(a=2)
 > y$ls()
[1] "a"


ls() is defined in package base and so would even work if you inherit 
from baseenv() so why it is surprising that proto objects (by default) 
inherit objects from other packages and from the user workspace?


Thomas P.


From bolker at ufl.edu  Thu Feb 25 15:30:54 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 25 Feb 2010 14:30:54 +0000 (UTC)
Subject: [Rd] scale(x, center=FALSE) (PR#14219)
References: <20100222033011.F1D06282EF2D@mail.pubhealth.ku.dk>
Message-ID: <loom.20100225T152029-86@post.gmane.org>

 <mrizzo <at> bgsu.edu> writes:

> scale returns incorrect values when center=FALSE and scale=TRUE.
> 
> When center=FALSE, scale=TRUE, the "scale" used is not 
> the square root of sample
> variance, the "scale" attribute is equal to sqrt(sum(x^2)/(n-1)).
> 
> Example:
> 
> x <- runif(10)
> n <- length(x)
> 
> scaled <- scale(x, center=FALSE, scale=TRUE)
> scaled
> s.bad <- attr(scaled, "scale")
> s.bad  #wrong
> sd(x)  #correct
> 
> #compute the sd as if data has already been centered
> #that is, compute the variance as sum(x^2)/(n-1)
> 
> sqrt(sum(x^2)/(n-1))
> 
> 

  Are you sure this is a bug? I agree that the way the function
behaves is (to me) mildly confusing, but the documentation says:

* The value of ?scale? determines how column scaling is performed
* (after centering).  If ?scale? is a numeric vector with length
* equal to the number of columns of ?x?, then each column of ?x? is
* divided by the corresponding value from ?scale?.  If ?scale? is
* ?TRUE? then scaling is done by dividing the (centered) columns of
* ?x? by their standard deviations, and if ?scale? is ?FALSE?, no
* scaling is done.

* The standard deviation for a column is obtained by computing the
* square-root of the sum-of-squares of the non-missing values in the
* column divided by the number of non-missing values minus one
* (whether or not centering was done).

  If you read the first clause of the last sentence of the first
paragraph in isolation, you would have the expectation that the
columns would be scaled by sd(x).  However, the second paragraph
clearly states that the 'standard deviation' is defined here
as the root-mean-square over (n-1), that is, sqrt(sum(x^2)/(n-1)) ...

  This does seem like a funny choice, but it is probably stuck
that way without an extremely compelling argument to the contrary.
If you want to scale columns by sd() instead you can say

scale(x,center=FALSE,scale=apply(x,2,sd))

  Would you like to submit a patch for the documentation that
would preserve the sense, clarify the behavior, and not be
much longer than the current version ... ?

  cheers
    Ben Bolker


From murdoch at stats.uwo.ca  Thu Feb 25 15:37:14 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 25 Feb 2010 09:37:14 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225075038.79ca9b63.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org>	<20100224233350.4e3da5db.misc7@emerose.org>	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
Message-ID: <4B868B1A.5050409@stats.uwo.ca>

On 25/02/2010 8:50 AM, Ben wrote:
> I was disappointed in this behavior because it seems error-prone.
> Suppose I declare an environment
>
> > b <- 1
> > p <- proto(expr={
>     a <- 2
> +   ...
> + })
> > p$a
> [1] 2
> > p$b
> [1] 1
>
> Presumably if I ask for p$a or p$b later, it's because I'm interesting
> in the value of "p$a" or "p$b" that I specifically put inside that
> environment.  Otherwise I would just ask for "a" or "b".  If I'm
> asking for "p$b" it the above case, that means I forgot to declare b
> inside p.  In this case there should be an error telling me that, not
> a silent substitution of the wrong quantity.
>   

I think you are looking for a different object model than proto offers.  
There aren't many languages that offer the prototype object model.
> If someone wanted to do the y$ls() thing, they could always
>
> > y <- proto(a=1)
> > with(y, ls())
> [1] "a"
>
> Another reason is that there are plenty of other programming languages
> that have similar structures and this behavior is very odd. 

Which languages are you thinking of?  The paper about proto only 
mentions Self, LispStat, and Javascript. The Wikipedia page 
http://en.wikipedia.org/wiki/Prototype-based_programming has a long list 
of obscure ones, but the only additional ones I've used are R, Perl and 
Tcl, all with add-on packages.

Duncan Murdoch


>  In
> standard languages asking for "b" inside the "p" object gives you an
> error, and no one complains.  Even in R, we have this behavior:
>
> > z <- 1
> > list(a=3)$z
> NULL
>
> (Actually I think the above should be an error, but at least it isn't
> 1.)  So anyway, I'm not saying that p$b being 1 is an outright 2+2=5
> bug, but it does seem to be surprising behavior that leads to bugs.
> But I'm sure you're right that there are historical/structural reasons
> for this to be the case, so perhaps there's no solution.
>
>
>


From h.wickham at gmail.com  Thu Feb 25 15:57:54 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 25 Feb 2010 08:57:54 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225075038.79ca9b63.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
Message-ID: <f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>

> Presumably if I ask for p$a or p$b later, it's because I'm interesting
> in the value of "p$a" or "p$b" that I specifically put inside that
> environment. ?Otherwise I would just ask for "a" or "b". ?If I'm
> asking for "p$b" it the above case, that means I forgot to declare b
> inside p. ?In this case there should be an error telling me that, not
> a silent substitution of the wrong quantity.
>
> If someone wanted to do the y$ls() thing, they could always
>
>> y <- proto(a=1)
>> with(y, ls())
> [1] "a"
>
> Another reason is that there are plenty of other programming languages
> that have similar structures and this behavior is very odd. ?In
> standard languages asking for "b" inside the "p" object gives you an
> error, and no one complains.

You might want to have a look at the mutatr package which implements
prototype OO with the behaviour you're looking for (I think).  I also
have a paper available if you email me off list.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gunter.berton at gene.com  Thu Feb 25 17:48:08 2010
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 25 Feb 2010 08:48:08 -0800
Subject: [Rd] grid unit bug? (PR#14220)
In-Reply-To: <alpine.LFD.2.00.1002250708460.29162@gannet.stats.ox.ac.uk>
References: <20100225010513.E9C40283031C@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.1002250708460.29162@gannet.stats.ox.ac.uk>
Message-ID: <86BA3F8E7596408F991F249CB1D7E069@gne.windows.gene.com>

Thank you Brian:

Maybe I should follow my own advice! I DID check methods(is.numeric) to see
if that were the case, but concluded it was not as that yielded an error.
But all I needed to do was read the docs! Registering the method indeed
seems the right way to do it.

Best regards,

Bert Gunter
Genentech Nonclinical Biostatistics
 
 -----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, February 24, 2010 11:13 PM
To: gunter.berton at gene.com; paul at stat.auckland.ac.nz
Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
Subject: Re: [Rd] grid unit bug? (PR#14220)

is.numeric() is generic.  So grid could include

is.numeric.unit <- function(x) FALSE

and register it in its namespace.   Or Bert could define it in his 
application.


On Thu, 25 Feb 2010, gunter.berton at gene.com wrote:

> Paul:
>
> I figured that would be the problem.
>
> I encountered the issue when I tries to check arguments in a validDetails
> method for a grob.
>
> Could one substitute the following function in the grid namespace?
>
> is.numeric <- function(x)if(is.unit(x))TRUE else is.numeric(x)
>
> (or make the first clause FALSE)
>
> Obviously, messing around like this might be dangerous -- or at least
would
> compromise execution speed.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
>
>
> -----Original Message-----
> From: paul murrell [mailto:R-bugs at r-project.org]
> Sent: Wednesday, February 24, 2010 4:22 PM
> To: gunter.berton at gene.com
> Subject: Re: grid unit bug? (PR#14220)
>
>> The following seems to me to be at least a perverse trap, if not an =
>> outright
>> bug:
>>
>>> is.numeric(unit(1,"npc"))
>> [1] TRUE
>>> is.numeric(1*unit(1,"npc"))
>> [1] FALSE
>>> is.numeric(unit(0,"npc") +unit(1,"npc"))
>> [1] FALSE
>>
>> ...etc.
>> i.e. is.numeric() appears to be TRUE for class "unit" but false for =
>> class
>> ("unit.arithmetic" "unit" ). Seems to me it ought to b the same for =
>> both.
>
>
> These results simply reflect the underlying data structures (simple
"unit"s
> are
> just numeric vectors, but more complex "unit.arithmetic"s are lists).  I
> don't
> see how I can "hide" the numeric-ness of simple units (just like there's
no
> way
> to stop a "ts" object like 'Nile' from satisfying is.numeric()).  I could
> re-implement simple units as lists, but (apart from the work involved)
that
> would be (even) less efficient.
>
> 1. Is there a situation where this causes a problem?
>
> 2. Do you have a possible "fix" in mind?
>
> Paul
>
>
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (FWIW, I think grid graphics is brilliant!)
>>
>> This was R version 2.11.0dev for Windows btw (not that it makes a
>> difference):
>>
>> sessionInfo()
>>
>> R version 2.11.0 Under development (unstable) (2010-02-15 r51142)=20
>> i386-pc-mingw32=20
>>
>> locale:
>> [1] LC_COLLATE=3DEnglish_United States.1252=20
>> [2] LC_CTYPE=3DEnglish_United States.1252  =20
>> [3] LC_MONETARY=3DEnglish_United States.1252
>> [4] LC_NUMERIC=3DC                         =20
>> [5] LC_TIME=3DEnglish_United States.1252   =20
>>
>> attached base packages:
>>  [1] datasets  splines   grid      tcltk     stats     graphics  =
>> grDevices
>>  [8] utils     methods   base    =20
>>
>> other attached packages:
>> [1] TinnR_1.0.3     R2HTML_1.59-1   Hmisc_3.7-0     survival_2.35-8
>> [5] svSocket_0.9-48 lattice_0.18-3  MASS_7.3-5    =20
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.12.1 svMisc_0.9-56
>>
>>
>>
>> =A0
>> =A0
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Thu Feb 25 18:36:24 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Feb 2010 12:36:24 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
	<f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>
Message-ID: <971536df1002250936p7987ea51hdc60cf79cad555e2@mail.gmail.com>

On Thu, Feb 25, 2010 at 9:57 AM, hadley wickham <h.wickham at gmail.com> wrote:
>> Presumably if I ask for p$a or p$b later, it's because I'm interesting
>> in the value of "p$a" or "p$b" that I specifically put inside that
>> environment. ?Otherwise I would just ask for "a" or "b". ?If I'm
>> asking for "p$b" it the above case, that means I forgot to declare b
>> inside p. ?In this case there should be an error telling me that, not
>> a silent substitution of the wrong quantity.
>>
>> If someone wanted to do the y$ls() thing, they could always
>>
>>> y <- proto(a=1)
>>> with(y, ls())
>> [1] "a"
>>
>> Another reason is that there are plenty of other programming languages
>> that have similar structures and this behavior is very odd. ?In
>> standard languages asking for "b" inside the "p" object gives you an
>> error, and no one complains.
>
> You might want to have a look at the mutatr package which implements
> prototype OO with the behaviour you're looking for (I think). ?I also
> have a paper available if you email me off list.

I think his objection is really only that he must specify baseenv() to
get the behavior he prefers but from what I understand (I am basing
this on my understanding that mutatr works like io language) in mutatr
one must use Object which seems really no different.


From pcd at roxygen.org  Thu Feb 25 19:13:16 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 12:13:16 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>
Message-ID: <20100225181316.GA10184@klutometis.wikitex.org>

Quoth hadley wickham on Sweetmorn, the 56th of Chaos:
> You might want to have a look at the mutatr package which implements
> prototype OO with the behaviour you're looking for (I think).

Hey, Hadley; I remember your prototype stuff from DSC 2009. I saw some
slides of yours that discussed proto, and was wondering whether mutatr
was still maintained.

Would you mind sending me that paper off-list, if necessary?


From pcd at roxygen.org  Thu Feb 25 19:14:44 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 12:14:44 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002250936p7987ea51hdc60cf79cad555e2@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com>
	<971536df1002250936p7987ea51hdc60cf79cad555e2@mail.gmail.com>
Message-ID: <20100225181444.GB10184@klutometis.wikitex.org>

Quoth Gabor Grothendieck on Sweetmorn, the 56th of Chaos:
> I think his objection is really only that he must specify baseenv()
> to get the behavior he prefers but from what I understand (I am
> basing this on my understanding that mutatr works like io language)
> in mutatr one must use Object which seems really no different.

Which is exactly what I started doing in proto: declaring a base
prototype (`object') that inherits from baseenv(); whence my
subprototypes spring.


From h.wickham at gmail.com  Thu Feb 25 19:37:59 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 25 Feb 2010 12:37:59 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225181316.GA10184@klutometis.wikitex.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
	<f8e6ff051002250657o7be15ab9ia24b5be410e80e9c@mail.gmail.com> 
	<20100225181316.GA10184@klutometis.wikitex.org>
Message-ID: <f8e6ff051002251037l5a3424cdic9d58020783b34e@mail.gmail.com>

> Hey, Hadley; I remember your prototype stuff from DSC 2009. I saw some
> slides of yours that discussed proto, and was wondering whether mutatr
> was still maintained.

Yes, it's maintained, and I've even written a package that uses it
(testthat - both it and mutatr are available on cran).  It's still
mainly an experiment, and I don't currently have any plans to give up
using proto.  However, my entirely personal perspective is that my
code seems to be cleaner when I use mutatr instead of proto (this
probably reflects that I wrote the package though!).

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From kasperdanielhansen at gmail.com  Wed Feb 24 21:05:24 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 24 Feb 2010 15:05:24 -0500
Subject: [Rd] build, data and vignettes
Message-ID: <e780c0971002241205t2f5c8e5gb0c3eb3110406a0d@mail.gmail.com>

Based on some testing it seems to me that if I have a package with
  a dataset in /data
  a Sweave vignette in inst/doc (but no associated pdf file)
  the vignette loads the data in /data through
     data(dataset)
and I do a
  R CMD build
R will try to build the pdf version of the vignette, but will be
unable to find the dataset in data because the package is not yet
installed.  However, if I do
  R CMD build --no-vignettes PKGNAME
  R CMD check PKGNAME_VERSION.tar.gz
the package passes R CMD check! Presumably because R CMD check
installs the package first.

This took me a long time to track down (inspired by a recent addition
of dataset to the Bioconductor package Genominator and a subsequent
failed build - specifically the dataset yeastAnno.sources and the
vignette withShortRead.Rnw).  I am using lazy loading (in case it
matters, which I don't think it does).

It seems like the relevant fix is to include pdf versions of the
vignette(s) in inst/doc.

On one hand I can see why the build fails.  And the fix is easy.  But
just thought I would mention it.

Kasper


From misc7 at emerose.org  Fri Feb 26 02:49:19 2010
From: misc7 at emerose.org (Ben)
Date: Thu, 25 Feb 2010 19:49:19 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <4B868B1A.5050409@stats.uwo.ca>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
Message-ID: <20100225194919.00b10700.misc7@emerose.org>

> I think you are looking for a different object model than proto
> offers.  There aren't many languages that offer the prototype object
> model.

Yes, your probably right---I don't have much experience using the
prototype model.  This is the way I expected it to work:

> z <- 1
> p <- proto(expr={a <- z})
> p$a
[1] 1
> p$z
Error in get(x, env = this, inherits = inh) : variable "z" was not found

Also it seems it would lead to fewer bugs if it worked that way.
(Peter Danenberg mentions he's run into bugs because of this, and I
can see why.)  But as I mentioned I'm new to prototype programming.
If it worked like in my snippet, would this lead to less effective
prototype programming?


Thanks,

-- 
Ben


From h.wickham at gmail.com  Fri Feb 26 03:07:50 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 25 Feb 2010 20:07:50 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225194919.00b10700.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca> 
	<20100225194919.00b10700.misc7@emerose.org>
Message-ID: <f8e6ff051002251807p1047d470s3b439a1d90503eeb@mail.gmail.com>

On Thu, Feb 25, 2010 at 7:49 PM, Ben <misc7 at emerose.org> wrote:
>> I think you are looking for a different object model than proto
>> offers. ?There aren't many languages that offer the prototype object
>> model.
>
> Yes, your probably right---I don't have much experience using the
> prototype model. ?This is the way I expected it to work:
>
>> z <- 1
>> p <- proto(expr={a <- z})
>> p$a
> [1] 1
>> p$z
> Error in get(x, env = this, inherits = inh) : variable "z" was not found

> library(mutatr)
>
> z <- 1
> p <- Object$clone()$do({
+   self$a <- z
+ })
> p$a
[1] 1
> p$z
Error: Field z not found in Object <0x1022b66d8>

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From pcd at roxygen.org  Fri Feb 26 03:23:22 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 20:23:22 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100225194919.00b10700.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
Message-ID: <20100226022322.GB19263@klutometis.wikitex.org>

> > I think you are looking for a different object model than proto
> > offers.  There aren't many languages that offer the prototype object
> > model.
> 
> Yes, your probably right---I don't have much experience using the
> prototype model.  This is the way I expected it to work:
> 
> > z <- 1
> > p <- proto(expr={a <- z})
> > p$a
> [1] 1
> > p$z
> Error in get(x, env = this, inherits = inh) : variable "z" was not found

Which is exactly how it should work! Namespace pollution is orthogonal
to the specific object model, and Duncan's assertion about the
prevalence of prototypes is a red herring.

Here's how it works in Scheme, for instance, using Neil van Dyke's
Prototype-Delegation package:[1]

  #;1> (use protobj)
  #;2> (define z 1)
  #;3> (define a (%))
  #;4> (! a a z)
  #;5> (? a a)
  1
  #;6> (? a z)

  Error: Object has no such slot:
  #<object>
  z

Just like one would expect! And since protobj is based on self,
Ungar-Smith's original prototype system,[2] I suspect that self
behaves similarly.

Footnotes: 
[1]  http://www.neilvandyke.org/protobj/

[2]  http://research.sun.com/self/papers/self-power.html


From ggrothendieck at gmail.com  Fri Feb 26 04:31:37 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Feb 2010 22:31:37 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100226022322.GB19263@klutometis.wikitex.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca> 
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
Message-ID: <971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>

On Thu, Feb 25, 2010 at 9:23 PM, Peter Danenberg <pcd at roxygen.org> wrote:
>> > I think you are looking for a different object model than proto
>> > offers. ?There aren't many languages that offer the prototype object
>> > model.
>>
>> Yes, your probably right---I don't have much experience using the
>> prototype model. ?This is the way I expected it to work:
>>
>> > z <- 1
>> > p <- proto(expr={a <- z})
>> > p$a
>> [1] 1
>> > p$z
>> Error in get(x, env = this, inherits = inh) : variable "z" was not found
>
> Which is exactly how it should work! Namespace pollution is orthogonal
> to the specific object model, and Duncan's assertion about the
> prevalence of prototypes is a red herring.
>
> Here's how it works in Scheme, for instance, using Neil van Dyke's
> Prototype-Delegation package:[1]
>
> ?#;1> (use protobj)
> ?#;2> (define z 1)
> ?#;3> (define a (%))
> ?#;4> (! a a z)
> ?#;5> (? a a)
> ?1
> ?#;6> (? a z)
>
> ?Error: Object has no such slot:
> ?#<object>
> ?z
>
> Just like one would expect! And since protobj is based on self,
> Ungar-Smith's original prototype system,[2] I suspect that self
> behaves similarly.
>
> Footnotes:
> [1] ?http://www.neilvandyke.org/protobj/
>
> [2] ?http://research.sun.com/self/papers/self-power.html

One would not expect the behavior you cite if you were working in R,
only if you were more familiar with something else.  One can just as
easily argue that consistency and flexibility are more important
principles.   Your preference is inconsistent with how the rest of R
works and is inflexible since everything inherits from Object.  In
contrast proto uses R-like behavior as its default but is flexible
enough that your preference can be accommodated and done so compactly.

Also I think your argument is based partly on repeating the original
erroneous (relative to the writer's intention) proto code without
repeating my correction confusing the discussion with simple user
error.


From pcd at roxygen.org  Fri Feb 26 05:16:17 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 22:16:17 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
Message-ID: <20100226041617.GB21674@klutometis.wikitex.org>

> Your preference is inconsistent with how the rest of R works and is
> inflexible since everything inherits from Object.

Really? Here are a couple of counterexamples in S3 and S4 objects:

  > z <- 1
  >
  > ## S4
  > setClass('A', representation(a='numeric'))
  [1] "A"
  > a <- new('A', a=z)
  > a at z
  Error: no slot of name "z" for this object of class "A"
  >
  > ## S3
  > a <- structure(list(a=z), class='A')
  > a$z
  NULL

As far as flexibility is concerned: keep the ability of people to
inherit from the parent environment if they don't mind
namespace-pollution and unpredictability.

I'm merely asking that the default behavior resemble the twenty-three
years of precedent since Ungar's original Self paper.

> Also I think your argument is based partly on repeating the original
> erroneous (relative to the writer's intention) proto code without
> repeating my correction confusing the discussion with simple user
> error.

I acknowledged your correction in an earlier email when I stated that,
"[one has] to choose between eval and parent pollution."


From ggrothendieck at gmail.com  Fri Feb 26 05:42:31 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Feb 2010 23:42:31 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100226041617.GB21674@klutometis.wikitex.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de> 
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca> 
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org> 
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com> 
	<20100226041617.GB21674@klutometis.wikitex.org>
Message-ID: <971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>

On Thu, Feb 25, 2010 at 11:16 PM, Peter Danenberg <pcd at roxygen.org> wrote:
>> Your preference is inconsistent with how the rest of R works and is
>> inflexible since everything inherits from Object.
>
> Really? Here are a couple of counterexamples in S3 and S4 objects:
>
> ?> z <- 1
> ?>
> ?> ## S4
> ?> setClass('A', representation(a='numeric'))
> ?[1] "A"
> ?> a <- new('A', a=z)
> ?> a at z
> ?Error: no slot of name "z" for this object of class "A"
> ?>
> ?> ## S3
> ?> a <- structure(list(a=z), class='A')
> ?> a$z
> ?NULL
>

lists don't have inheritance at all so the last example seems not
relevant.  Also other object systems which are alternatives to proto
seem less relevant than basic scoping and free variable lookup in
functions.  Those are the relevant principles.

> As far as flexibility is concerned: keep the ability of people to
> inherit from the parent environment if they don't mind
> namespace-pollution and unpredictability.

proto does that but uses the consistent default rather than the
inconsistent default that you prefer.

The namespace advantage is an advantage but its lesser than
consistency with R and the flexibility to have it either way.

> I'm merely asking that the default behavior resemble the twenty-three
> years of precedent since Ungar's original Self paper.

That is just what I (and possibly Duncan) have argued.  That your
expectation is based on different systems.

>
>> Also I think your argument is based partly on repeating the original
>> erroneous (relative to the writer's intention) proto code without
>> repeating my correction confusing the discussion with simple user
>> error.
>
> I acknowledged your correction in an earlier email when I stated that,
> "[one has] to choose between eval and parent pollution."

But the last email repeated the wrong code anyways and used that as
the springboard for the discussion.


From pcd at roxygen.org  Fri Feb 26 06:41:54 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Thu, 25 Feb 2010 23:41:54 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<20100224233350.4e3da5db.misc7@emerose.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
Message-ID: <20100226054154.GA23715@klutometis.wikitex.org>

> Also other object systems which are alternatives to proto seem less
> relevant than basic scoping and free variable lookup in functions.

Sorry, but that seems absurd; object systems are less relevant to each
other than the totally orthogonal question of scope?

> proto does that but uses the consistent default rather than the
> inconsistent default that you prefer.

$.proto falls back upon get(), I presume, because the authors didn't
feel like recursing up the parent hierarchy themselves; I'll continue
to believe that the scope pollution was an oversight until they
contradict me. At which point I'll probably switch object systems.

Vague appeals to consistency, when you're really only talking about
naive get() semantics, don't mean much; especially after you've spent
hours debugging mysterious bugs resulting from scope pollution.


From ggrothendieck at gmail.com  Fri Feb 26 13:09:47 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Feb 2010 07:09:47 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100226054154.GA23715@klutometis.wikitex.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org> 
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org> 
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com> 
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com> 
	<20100226054154.GA23715@klutometis.wikitex.org>
Message-ID: <971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>

On Fri, Feb 26, 2010 at 12:41 AM, Peter Danenberg <pcd at roxygen.org> wrote:
>> Also other object systems which are alternatives to proto seem less
>> relevant than basic scoping and free variable lookup in functions.
>
> Sorry, but that seems absurd; object systems are less relevant to each
> other than the totally orthogonal question of scope?

Yes, if you are using one then obviously you have decided to use it in
place of the other.  Also your example of S3 was misleading since it
used lists which do not have inheritance and did not truly illustrate
S3.  Free variables in S3 methods follow the same lookup procedure as
ordinary functions and using S3 together with proto works well.  In
fact, proto uses two S3 classes.

>
>> proto does that but uses the consistent default rather than the
>> inconsistent default that you prefer.
>
> $.proto falls back upon get(), I presume, because the authors didn't
> feel like recursing up the parent hierarchy themselves; I'll continue
> to believe that the scope pollution was an oversight until they
> contradict me. At which point I'll probably switch object systems.

Here I think you are admitting that the basic facilities of R do work
in the way proto does.

Also, your alternative likely would be unusable due to performance
whereas proto is fast enough to be usable (see list of applications
that use it at http://r-proto.googlecode.com/#Applications).  Its not
as fast as S3 (though sometimes you can get it that fast by optimizing
your code).  The development version of proto is even faster than the
current version of proto due to the addition of lazy evaluation.

> Vague appeals to consistency, when you're really only talking about
> naive get() semantics, don't mean much; especially after you've spent
> hours debugging mysterious bugs resulting from scope pollution.

In end it seems that your real beef is with R so perhaps you should be
using a different language.

With respect to proto its really just discussing whether to use

proto(baseenv(), ...) vs proto(...)

since the former gives you everything you want and the distinction
seems pretty trivial given how easy it is to use one or the other.  If
you used iolanguage or similar you would have to specify Object so
there is not even a penalty in terms of compactness.

There have also been threads on how to "fix" scoping in R for
individual functions and various manipulations of environments have
been suggested but in the end no one does this in practice.  In proto
at least you can do the part you want and its trivial to do so.


From murdoch at stats.uwo.ca  Fri Feb 26 13:55:32 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 26 Feb 2010 07:55:32 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<4B8666E0.4070808@TU-Dresden.de>	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
	<20100226041617.GB21674@klutometis.wikitex.org>	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
Message-ID: <4B87C4C4.6020201@stats.uwo.ca>

On 26/02/2010 7:09 AM, Gabor Grothendieck wrote:
> On Fri, Feb 26, 2010 at 12:41 AM, Peter Danenberg <pcd at roxygen.org> wrote:
>>> Also other object systems which are alternatives to proto seem less
>>> relevant than basic scoping and free variable lookup in functions.
>> Sorry, but that seems absurd; object systems are less relevant to each
>> other than the totally orthogonal question of scope?
> 
> Yes, if you are using one then obviously you have decided to use it in
> place of the other.  Also your example of S3 was misleading since it
> used lists which do not have inheritance and did not truly illustrate
> S3.  Free variables in S3 methods follow the same lookup procedure as
> ordinary functions and using S3 together with proto works well.  In
> fact, proto uses two S3 classes.
> 
>>> proto does that but uses the consistent default rather than the
>>> inconsistent default that you prefer.
>> $.proto falls back upon get(), I presume, because the authors didn't
>> feel like recursing up the parent hierarchy themselves; I'll continue
>> to believe that the scope pollution was an oversight until they
>> contradict me. At which point I'll probably switch object systems.
> 
> Here I think you are admitting that the basic facilities of R do work
> in the way proto does.
> 
> Also, your alternative likely would be unusable due to performance
> whereas proto is fast enough to be usable (see list of applications
> that use it at http://r-proto.googlecode.com/#Applications).  Its not
> as fast as S3 (though sometimes you can get it that fast by optimizing
> your code).  The development version of proto is even faster than the
> current version of proto due to the addition of lazy evaluation.
> 
>> Vague appeals to consistency, when you're really only talking about
>> naive get() semantics, don't mean much; especially after you've spent
>> hours debugging mysterious bugs resulting from scope pollution.
> 
> In end it seems that your real beef is with R so perhaps you should be
> using a different language.
> 
> With respect to proto its really just discussing whether to use
> 
> proto(baseenv(), ...) vs proto(...)

I would say the default behaviour makes more sense.  There are very few 
circumstances in R where scoping makes locals and base variables 
visible, *but nothing else*.  I think users would be surprised that

a$ls()

works, but

a$str()

fails (because str() is in utils, ls() is in base).  Effectively what 
the current default says is that objects inherit from the current 
environment.  That's how environments work in R.

One thing that I dislike about scoping in R is the fact that even in a 
namespace, searches eventually get to the global environment.  I'd 
prefer if namespace searches went through the imported namespaces and 
nothing else.  If that were the case, then the a$z example would never 
find a z in the global environment, and that example would only be a 
problem for people fiddling around in the console, not programming 
carefully in a package.  But again, this is a criticism of R, not of 
proto.  (I believe the reason for the current behaviour is to support 
finding S3 methods:  a user should be able to define a new class and an 
S3 method for it, and R should find it even if the writer of the 
original generic knew nothing about the new class or method.  This 
outside-the-namespace search is needed for that, but I'd prefer it if it 
were more limited.)

Duncan Murdoch

> 
> since the former gives you everything you want and the distinction
> seems pretty trivial given how easy it is to use one or the other.  If
> you used iolanguage or similar you would have to specify Object so
> there is not even a penalty in terms of compactness.
> 
> There have also been threads on how to "fix" scoping in R for
> individual functions and various manipulations of environments have
> been suggested but in the end no one does this in practice.  In proto
> at least you can do the part you want and its trivial to do so.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nicebread at gmx.net  Fri Feb 26 14:52:32 2010
From: nicebread at gmx.net (=?iso-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Fri, 26 Feb 2010 14:52:32 +0100
Subject: [Rd] Error on Windows build: "unable to re-encode"
Message-ID: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100226/8660aedd/attachment.pl>

From i.thurlbeck at strath.ac.uk  Fri Feb 26 12:03:35 2010
From: i.thurlbeck at strath.ac.uk (Ian Thurlbeck)
Date: Fri, 26 Feb 2010 11:03:35 +0000
Subject: [Rd] Problem with cut and paste corruption
Message-ID: <4B87AA87.2090504@strath.ac.uk>


Dear All

We have noticed a problem when cut-and-pasting a largish section
(> 4096 bytes ?) of R code from an editor to an R session.

System is Fedora 12 i386 with updates, R-2.9.0 and R-2.10.1 at least.

Problem disappears if you start R with --no-readline !

If happens independently of the editor (tried vim/kate) and the
terminal (tried konsole/gnome-terminal)

Could you please try and reproduce the problem and see if it is
limited to Fedora (Windows XP seems to work fine) ?

I've attached a 5K data file aids.R from the gss package which seems to
trigger the problem.  Just load aids.R into an editor and cut-paste
into a fresh R session and you should see something like:

...
+ "224", "2
+ "233", "234", "235", "236", "237", "238", "239", "240", "241",
Error: unexpected numeric constant in:
""224", "2
...

Many thanks

Ian
-- 
Ian Thurlbeck                http://www.mathstat.strath.ac.uk/
Mathematics and Statistics, University of Strathclyde
Livingstone Tower, 26 Richmond Street, Glasgow, UK,  G1 1XH
Tel: +44 (0)141 548 3667           Fax: +44 (0)141 552 2079

The University of Strathclyde is a charitable body, registered in Scotland, 
number SC015263.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: aids.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100226/dd5abbfa/attachment.pl>

From misc7 at emerose.org  Fri Feb 26 15:01:12 2010
From: misc7 at emerose.org (Ben)
Date: Fri, 26 Feb 2010 08:01:12 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<4B8666E0.4070808@TU-Dresden.de>
	<20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
Message-ID: <20100226080112.72341a14.misc7@emerose.org>


> In end it seems that your real beef is with R so perhaps you should
> be using a different language.

In my case you may be right.  I do think there are a million things
wrong with R.  For instance, I was looking for a package that
overcomes two of the problems R IMHO has: namespace pollution and the
lack of an easy-to-use standard object system.

Should I be using R?  I do keep asking myself that same question...

> With respect to proto its really just discussing whether to use
> proto(baseenv(), ...) vs proto(...)

Unfortunately this doesn't fix the problem as was noted earlier:

> z <- 1
> proto(baseenv(), expr={a <- z})$a
Error in eval(expr, envir, enclos) : object "z" not found

> Also, your alternative likely would be unusable due to performance
> whereas proto is fast enough to be usable (see list of applications
> that use it at http://r-proto.googlecode.com/#Applications).  Its
> not as fast as S3 (though sometimes you can get it that fast by
> optimizing your code).  The development version of proto is even
> faster than the current version of proto due to the addition of lazy
> evaluation.

This make sense to me.


-- 
Ben Escoto


From murdoch at stats.uwo.ca  Fri Feb 26 15:02:28 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 26 Feb 2010 09:02:28 -0500
Subject: [Rd] Error on Windows build: "unable to re-encode"
In-Reply-To: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>
References: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>
Message-ID: <4B87D474.5060207@stats.uwo.ca>

On 26/02/2010 8:52 AM, Felix Sch?nbrodt wrote:
> Dear developers,
>
> while our package TripleR (hosted on R-Forge) builds well on Mac and Linux, the Windows build shows following error (http://r-forge.r-project.org/R/?group_id=418&log=build_win32&pkg=TripleR&flavor=patched):
>
> Fri Feb 26 00:53:38 2010: Building binary for package TripleR (SVN revision NA)
> using R version 2.10.1 Patched (2010-02-24 r51172) ...
>
> * installing to library 'R:/R/lib/CRAN/2.10'
> * installing *source* package 'TripleR' ...
>
>   Using auto-selected zip option '--use-zip-data'
>
> ** R
> Error : unable to re-encode 'RR.r'
>
>
>
> I found the piece of code producing the error in the function .install_package_code_files in the file src/library/tools/R/admin.R:
>     ## assume that if locale is 'C' we can used 8-bit encodings unchanged.
>     if(need_enc && !(Sys.getlocale("LC_CTYPE") %in% c("C", "POSIX"))) {
>         con <- file(outFile, "a")
>         on.exit(close(con))  # Windows does not like files left open
>         for(f in codeFiles) {
>             tmp <- iconv(readLines(f, warn = FALSE), from = enc, to = "")
>             if(any(is.na(tmp)))
>                stop(gettextf("unable to re-encode '%s'", basename(f)),
>                     domain = NA, call. = FALSE)
>
>
> However, I don't really know what that means.
> I already tried to encode the source file both in UTF-8 and in latin-1, but neither worked.
>
>
> Did anyone encounter the same problem / any suggestion?


I believe you shouldn't have a problem if you declare the default 
encoding for the whole package in the DESCRIPTION file.  You'll need to 
be consistent about using that encoding in all of your .R files.  (.Rd 
files can each have their own encoding, declared within them.)  However, 
it's possible there are bugs here: since most R code is pure ASCII, the 
encoding issues are not tested a lot.

If declaring the encoding in DESCRIPTION doesn't solve the problem, I'd 
be happy to take a look at the package.

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Feb 26 15:28:46 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Feb 2010 09:28:46 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100226080112.72341a14.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org> 
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com> 
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com> 
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com> 
	<20100226080112.72341a14.misc7@emerose.org>
Message-ID: <971536df1002260628g663800c8pbb531a7565586b03@mail.gmail.com>

On Fri, Feb 26, 2010 at 9:01 AM, Ben <misc7 at emerose.org> wrote:
>
>> In end it seems that your real beef is with R so perhaps you should
>> be using a different language.
>
> In my case you may be right. ?I do think there are a million things
> wrong with R. ?For instance, I was looking for a package that
> overcomes two of the problems R IMHO has: namespace pollution and the
> lack of an easy-to-use standard object system.
>
> Should I be using R? ?I do keep asking myself that same question...
>
>> With respect to proto its really just discussing whether to use
>> proto(baseenv(), ...) vs proto(...)
>
> Unfortunately this doesn't fix the problem as was noted earlier:
>
>> z <- 1
>> proto(baseenv(), expr={a <- z})$a
> Error in eval(expr, envir, enclos) : object "z" not found
>

As already mentioned lets not confuse user error with actual problems
pertaining to proto and R.  It should have been written like this if
that is what was wanted:

> z <- 1
> proto(baseenv(), a = z)$a
[1] 1


From kasperdanielhansen at gmail.com  Fri Feb 26 16:45:43 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 26 Feb 2010 10:45:43 -0500
Subject: [Rd]  build, data and vignettes
In-Reply-To: <e780c0971002260744x311159f2x7bd7264a9e97a8ff@mail.gmail.com>
References: <e780c0971002241205t2f5c8e5gb0c3eb3110406a0d@mail.gmail.com>
	<alpine.LFD.2.00.1002260650300.24621@gannet.stats.ox.ac.uk>
	<e780c0971002260744x311159f2x7bd7264a9e97a8ff@mail.gmail.com>
Message-ID: <e780c0971002260745q44c2ed28ta1a7805e58cdab14@mail.gmail.com>

(forwarding to R-devel)

Prof. Ripley

Thanks a lot for the help.

I greatly appreciate the clarification that R does indeed install the
package during the build process. ?I must have been confused. ?The
error is now fixed and was not related to my (false) claim that R
could not locate a dataset in /data.

You were not able to replicate the error because you were using the
_build_ tarballs available from (I guess)
?http://bioconductor.org/packages/2.6/bioc/src/contrib/Genominator_1.1.3.tar.gz
These tarballs are only put up, when the package passes R CMD build
(naturally enough). ?The version of Genominator I had problems with
was 1.1.4 which is only available from subversion (since it did not
build when I wrote the email). ?1.1.4 ought to be available in a few
days when the build system picks up on the changes I just committed.

I did mention that I saw that the package did not complete R CMD
build, but (semi-passed)
?R CMD build --no-vignettes Genominator
?R CMD check Genominator_XXX.tar.gz

I have no double checked this, see output below. ?I am using an
R-devel that is a week old or so. ?What I do below is
1) check out the package from svn
2) R CMD build --no-vignettes
3) R CMD check on the tarball. ?Looks like it "passes" R CMD check
with a warning about missing PDFs
4) verify that the source directory is empty by running svn status
5) R CMD build ?which fails (as it should)
(Note the package - in this svn version - has errors in the vignette)

I would have expected that R CMD check failed or at least told me that
the vignettes do not build.

Of course, given my earlier mistakes with this, I could be messing
something up.

Output below.

Thanks as always,
Kasper

compute-0-19:~/Work/packages/temp/> echo $BIOCSVN
https://hedgehog.fhcrc.org/gentleman/bioconductor/trunk/madman/Rpacks
compute-0-19:~/Work/packages/temp/> svn co -r 44843 $BIOCSVN/Genominator
?<OUTOUR REMOVED>
Checked out revision 44843.
compute-0-19:~/Work/packages/temp/> R-devel CMD build --no-vignettes
Genominator
* checking for file 'Genominator/DESCRIPTION' ... OK
* preparing 'Genominator':
* checking DESCRIPTION meta-information ... OK
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'Genominator_1.1.4.tar.gz'

compute-0-19:~/Work/packages/temp/> R-devel CMD check Genominator_1.1.4.tar.gz
* checking for working pdflatex ... OK
* using log directory
'/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck'
* using R version 2.11.0 Under development (unstable) (2010-02-15 r51142)
* using session charset: ISO8859-15
* checking for file 'Genominator/DESCRIPTION' ... OK
* this is package 'Genominator' version '1.1.4'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'Genominator' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the name space can be loaded with stated dependencies ... OK
* checking whether the name space can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking data for non-ASCII characters ... OK
* checking examples ... OK
* checking tests ...
?OK
* checking package vignettes in 'inst/doc' ... WARNING
Package vignettes without corresponding PDF:
?/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/Genominator.Rnw
?/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/plotting.Rnw
?/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/withShortRead.Rnw
* checking PDF version of manual ... OK

WARNING: There was 1 warning, see
?/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00check.log
for details

compute-0-19:~/Work/packages/temp/> svn status Genominator
compute-0-19:~/Work/packages/temp/> R-devel CMD build Genominator
* checking for file 'Genominator/DESCRIPTION' ... OK
* preparing 'Genominator':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* installing *source* package 'Genominator' ...
** R
** data
** inst
** preparing package for lazy loading
Loading required package: DBI

Attaching package: 'IRanges'

The following object(s) are masked from 'package:base':

? ?Map, cbind, mapply, order, pmax, pmax.int, pmin, pmin.int, rbind,
? ?rep.int, table

** help
*** installing help indices
** building package indices ...
* DONE (Genominator)
* creating vignettes ... ERROR
Loading required package: RSQLite
Loading required package: DBI
Loading required package: IRanges

Attaching package: 'IRanges'

The following object(s) are masked from 'package:base':

? ?cbind, Map, mapply, order, pmax, pmax.int, pmin, pmin.int,
? ?rbind, rep.int, table

writing regions table: 0.026 sec
SQL query: SELECT counts,feature FROM counts_tbl INNER JOIN
__regions__ ON __regions__.chr = counts_tbl.chr AND
counts_tbl.location BETWEEN __regions__.start AND __regions__.end AND
(counts_tbl.strand = __regions__.strand OR __regions__.strand = 0 OR
counts_tbl.strand = 0)

fetching merge table: 0.027 sec
splitting by: feature: 0.002 sec
matplot: doing 1 plots with ?col= ("1") pch= ("1" "2" "3" "4" "5" "6"
"7" "8" "9" "0" "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
"n" "o" "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z" "A" "B" "C" "D"
"E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S" "T" "U"
"V" "W" "X" "Y" "Z") ...

writing regions table: 0.025 sec
SQL query: SELECT __regions__.id, TOTAL(counts) FROM __regions__ LEFT
OUTER JOIN counts_tbl ON __regions__.chr = counts_tbl.chr AND
counts_tbl.location BETWEEN __regions__.start AND __regions__.end AND
(counts_tbl.strand = __regions__.strand OR __regions__.strand = 0 OR
counts_tbl.strand = 0) GROUP BY __regions__.id ORDER BY __regions__.id

fetching summary table: 0.044 sec
fetching summary: 0.016 sec
matplot: doing 1 plots with ?col= ("1") pch= ("1" "2" "3" "4" "5" "6"
"7" "8" "9" "0" "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
"n" "o" "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z" "A" "B" "C" "D"
"E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S" "T" "U"
"V" "W" "X" "Y" "Z") ...

writing regions table: 0.026 sec
SQL query: SELECT __regions__.id, TOTAL(counts_1), TOTAL(counts_2)
FROM __regions__ LEFT OUTER JOIN allcounts ON __regions__.chr =
allcounts.chr AND allcounts.location BETWEEN __regions__.start AND
__regions__.end AND (allcounts.strand = __regions__.strand OR
__regions__.strand = 0 OR allcounts.strand = 0) GROUP BY
__regions__.id ORDER BY __regions__.id

fetching summary table: 0.048 sec
Loading required package: GenomeGraphs
Loading required package: biomaRt
Loading required package: grid
Loading required package: ShortRead
Loading required package: Biostrings
Loading required package: BSgenome
Loading required package: lattice
Loading required package: yeastRNASeq
Error: no function to return from, jumping to top level
Execution halted


Thanks again,
Kasper

2010/2/26 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Wed, 24 Feb 2010, Kasper Daniel Hansen wrote:
>
>> Based on some testing it seems to me that if I have a package with
>> ?a dataset in /data
>> ?a Sweave vignette in inst/doc (but no associated pdf file)
>> ?the vignette loads the data in /data through
>> ? ?data(dataset)
>> and I do a
>> ?R CMD build
>> R will try to build the pdf version of the vignette, but will be
>> unable to find the dataset in data because the package is not yet
>> installed. ?However, if I do
>
> But R CMD build *does* install the package to build vignettes. ?If I take
> the current BioC-2.6 version of Genominator (1.1.3), remove the
> inst/doc/*.pdf and any installed versions I see
>
> gannet% Rdev CMD build Genominator
> * checking for file 'Genominator/DESCRIPTION' ... OK
> * preparing 'Genominator':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * installing *source* package ?Genominator? ...
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> Loading required package: DBI
> Creating a new generic function for "head" in "Genominator"
> ** help
> *** installing help indices
> ** building package indices ...
> * DONE (Genominator)
> * creating vignettes ... OK
> * removing junk files
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'Genominator_1.1.3.tar.gz'
>
> (Well, once I had installed the 307Mb dependency yeastRNASeq.)
>
> Now, you may be using an unreleased version of Genominator, but your
> hypothesis (that the package needs to be installed beforehand) is not
> correct.
>
>> ?R CMD build --no-vignettes PKGNAME
>> ?R CMD check PKGNAME_VERSION.tar.gz
>> the package passes R CMD check! Presumably because R CMD check
>> installs the package first.
>
> Yes, to a temporary library, just as R CMD build does if there are
> vignettes.
>
>> This took me a long time to track down (inspired by a recent addition
>> of dataset to the Bioconductor package Genominator and a subsequent
>> failed build - specifically the dataset yeastAnno.sources and the
>> vignette withShortRead.Rnw). ?I am using lazy loading (in case it
>> matters, which I don't think it does).
>>
>> It seems like the relevant fix is to include pdf versions of the
>> vignette(s) in inst/doc.
>>
>> On one hand I can see why the build fails.
>
> So given the evidence that R CMD build does install the package, please
> explain.
>
>> And the fix is easy. ?But
>> just thought I would mention it.
>>
>> Kasper
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From ligges at statistik.tu-dortmund.de  Fri Feb 26 16:57:17 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 26 Feb 2010 16:57:17 +0100
Subject: [Rd] Problem with cut and paste corruption
In-Reply-To: <4B87AA87.2090504@strath.ac.uk>
References: <4B87AA87.2090504@strath.ac.uk>
Message-ID: <4B87EF5D.4080102@statistik.tu-dortmund.de>



On 26.02.2010 12:03, Ian Thurlbeck wrote:
>
> Dear All
>
> We have noticed a problem when cut-and-pasting a largish section
> (> 4096 bytes ?) of R code from an editor to an R session.

It is a bad idea to do that in any case.
If you have such huge data or code, save the data / code to a file and 
read that one. If it is R code, use source() to do so.



> System is Fedora 12 i386 with updates, R-2.9.0 and R-2.10.1 at least.
>
> Problem disappears if you start R with --no-readline !


So you hit the readline buffer limit.


> If happens independently of the editor (tried vim/kate) and the
> terminal (tried konsole/gnome-terminal)
>
> Could you please try and reproduce the problem and see if it is
> limited to Fedora (Windows XP seems to work fine) ?

There are buffer sizes and you probably hit one of them. So no need to 
try. You cannot expect Copy & Paste to work for an arbitrarily sized string.

Uwe Ligges



> I've attached a 5K data file aids.R from the gss package which seems to
> trigger the problem. Just load aids.R into an editor and cut-paste
> into a fresh R session and you should see something like:
>
> ...
> + "224", "2
> + "233", "234", "235", "236", "237", "238", "239", "240", "241",
> Error: unexpected numeric constant in:
> ""224", "2
> ...
>
> Many thanks
>
> Ian
>
>
> aids.R
>
>
> "aids"<-
> structure(list(incu = c(28, 14, 10, 10, 23, 13, 12, 37, 6, 4,
> 13, 11, 21, 8, 33, 13, 8, 20, 37, 20, 18, 8, 27, 43, 17, 8, 11,
> 15, 10, 4, 32, 23, 32, 10, 15, 28, 34, 34, 17, 29, 17, 29, 38,
> 61, 12, 38, 32, 46, 30, 34, 53, 13, 22, 4, 37, 60, 53, 20, 38,
> 62, 24, 37, 41, 18, 10, 24, 25, 39, 25, 5, 29, 19, 14, 35, 18,
> 68, 48, 16, 48, 47, 10, 69, 55, 22, 16, 23, 4, 11, 30, 13, 10,
> 36, 38, 48, 26, 29, 31, 12, 70, 67, 63, 33, 32, 32, 50, 21, 33,
> 17, 53, 10, 65, 29, 53, 36, 12, 11, 36, 31, 49, 15, 9, 11, 24,
> 4, 43, 43, 80, 36, 68, 58, 23, 55, 12, 41, 46, 51, 39, 63, 51,
> 44, 39, 29, 51, 63, 40, 22, 48, 64, 79, 89, 54, 16, 17, 29, 18,
> 15, 29, 21, 25, 24, 0, 48, 21, 37, 26, 13, 20, 17, 8, 29, 41,
> 19, 28, 18, 19, 18, 33, 40, 58, 63, 18, 59, 33, 56, 72, 32, 37,
> 62, 41, 38, 32, 11, 10, 19, 37, 37, 20, 13, 6, 35, 23, 27, 12,
> 49, 26, 42, 12, 16, 14, 38, 18, 62, 35, 42, 10, 20, 30, 34, 40,
> 59, 16, 37, 15, 40, 40, 21, 20, 43, 46, 19, 48, 5, 23, 32, 31,
> 42, 20, 24, 38, 29, 43, 11, 63, 27, 13, 62, 15, 14, 83, 34, 29,
> 55, 34, 54, 19, 20, 52, 57, 63, 38, 24, 31, 14, 64, 76, 25, 29,
> 19, 20, 52, 33, 10, 49, 36, 17, 60, 29, 67, 24, 19, 29, 32, 49,
> 40, 68, 61, 53, 22, 32, 23, 27, 47, 38, 27, 41), infe = c(80,
> 64, 57, 54, 63, 52, 49, 71, 38, 35, 40, 38, 48, 31, 54, 34, 26,
> 37, 53, 35, 33, 22, 40, 52, 26, 16, 19, 22, 17, 11, 38, 29, 33,
> 13, 64, 75, 79, 77, 60, 69, 57, 68, 76, 99, 49, 74, 68, 81, 75,
> 69, 85, 44, 53, 35, 67, 84, 83, 49, 66, 90, 52, 75, 68, 45, 36,
> 49, 48, 62, 48, 28, 50, 40, 35, 55, 38, 87, 67, 35, 67, 66, 28,
> 87, 73, 40, 33, 40, 20, 27, 46, 29, 26, 52, 53, 74, 41, 43, 45,
> 26, 83, 80, 76, 45, 44, 43, 61, 32, 44, 27, 63, 19, 73, 37, 61,
> 44, 19, 18, 43, 37, 55, 21, 15, 17, 30, 5, 49, 48, 85, 41, 72,
> 62, 27, 59, 16, 45, 49, 54, 42, 66, 54, 47, 42, 31, 53, 65, 42,
> 24, 50, 65, 80, 90, 55, 17, 18, 75, 66, 54, 67, 59, 62, 60, 36,
> 83, 54, 70, 59, 42, 49, 46, 37, 57, 69, 47, 56, 45, 46, 45, 60,
> 66, 83, 65, 20, 61, 34, 57, 73, 34, 39, 63, 42, 39, 57, 35, 34,
> 42, 60, 59, 41, 34, 27, 56, 44, 47, 32, 69, 46, 61, 31, 35, 33,
> 57, 36, 80, 53, 60, 27, 37, 46, 50, 56, 75, 32, 46, 17, 42, 41,
> 22, 36, 59, 61, 34, 63, 20, 37, 46, 45, 56, 34, 38, 52, 43, 56,
> 24, 76, 40, 26, 75, 27, 26, 94, 45, 39, 75, 44, 64, 29, 30, 61,
> 61, 66, 39, 25, 32, 23, 73, 85, 33, 37, 27, 28, 60, 41, 18, 57,
> 43, 23, 66, 35, 73, 30, 25, 35, 37, 54, 45, 73, 66, 57, 26, 36,
> 27, 31, 51, 42, 30, 44), age = c(4, 2, 1, 1, 2, 2, 2, 4, 2, 1,
> 2, 1, 3, 1, 3, 2, 1, 2, 4, 2, 2, 1, 4, 4, 2, 1, 4, 2, 1, 1, 3,
> 3, 3, 1, 56, 57, 20, 46, 46, 53, 39, 34, 56, 29, 46, 46, 26,
> 30, 25, 51, 33, 39, 57, 29, 57, 21, 52, 56, 56, 58, 52, 34, 32,
> 23, 32, 44, 58, 50, 50, 39, 24, 58, 45, 23, 35, 6, 26, 59, 51,
> 22, 42, 30, 54, 38, 34, 54, 46, 59, 26, 54, 50, 46, 59, 42, 42,
> 52, 41, 29, 17, 59, 48, 51, 56, 32, 46, 53, 33, 52, 37, 38, 53,
> 58, 58, 21, 55, 55, 53, 51, 51, 36, 57, 59, 44, 36, 46, 47, 54,
> 28, 29, 28, 41, 59, 36, 11, 37, 54, 55, 57, 27, 51, 35, 44, 5,
> 59, 49, 41, 56, 49, 33, 38, 53, 38, 49, 54, 65, 63, 62, 67, 61,
> 68, 63, 61, 70, 62, 61, 69, 78, 66, 73, 62, 67, 68, 69, 61, 70,
> 64, 62, 66, 69, 67, 60, 65, 71, 64, 73, 71, 63, 69, 74, 69, 60,
> 68, 67, 70, 82, 76, 68, 63, 68, 65, 64, 68, 63, 71, 71, 62, 71,
> 72, 61, 78, 67, 70, 62, 73, 81, 67, 73, 73, 64, 60, 62, 66, 73,
> 73, 72, 62, 67, 62, 68, 74, 64, 84, 66, 66, 69, 67, 60, 62, 69,
> 67, 66, 61, 62, 80, 66, 65, 68, 70, 66, 78, 78, 80, 65, 68, 81,
> 77, 72, 61, 67, 85, 70, 71, 71, 67, 78, 65, 72, 61, 63, 64, 66,
> 61, 77, 65, 67, 66, 72, 69, 76, 77, 65, 68, 60, 66, 60, 63, 71,
> 68, 65, 65, 68, 65, 68, 70, 70)), .Names = c("incu", "infe",
> "age"), row.names = c("1", "2", "3", "4", "5", "6", "7", "8",
> "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
> "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30",
> "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41",
> "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52",
> "53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63",
> "64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74",
> "75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85",
> "86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
> "97", "98", "99", "100", "101", "102", "103", "104", "105", "106",
> "107", "108", "109", "110", "111", "112", "113", "114", "115",
> "116", "117", "118", "119", "120", "121", "122", "123", "124",
> "125", "126", "127", "128", "129", "130", "131", "132", "133",
> "134", "135", "136", "137", "138", "139", "140", "141", "142",
> "143", "144", "145", "146", "147", "148", "149", "150", "151",
> "152", "153", "154", "155", "156", "157", "158", "159", "160",
> "161", "162", "163", "164", "165", "166", "167", "168", "169",
> "170", "171", "172", "173", "174", "175", "176", "177", "178",
> "179", "180", "181", "182", "183", "184", "185", "186", "187",
> "188", "189", "190", "191", "192", "193", "194", "195", "196",
> "197", "198", "199", "200", "201", "202", "203", "204", "205",
> "206", "207", "208", "209", "210", "211", "212", "213", "214",
> "215", "216", "217", "218", "219", "220", "221", "222", "223",
> "224", "225", "226", "227", "228", "229", "230", "231", "232",
> "233", "234", "235", "236", "237", "238", "239", "240", "241",
> "242", "243", "244", "245", "246", "247", "248", "249", "250",
> "251", "252", "253", "254", "255", "256", "257", "258", "259",
> "260", "261", "262", "263", "264", "265", "266", "267", "268",
> "269", "270", "271", "272", "273", "274", "275", "276", "277",
> "278", "279", "280", "281", "282", "283", "284", "285", "286",
> "287", "288", "289", "290", "291", "292", "293", "294", "295"
> ), class = "data.frame")
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Fri Feb 26 17:03:10 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 26 Feb 2010 17:03:10 +0100
Subject: [Rd] build, data and vignettes
In-Reply-To: <e780c0971002260745q44c2ed28ta1a7805e58cdab14@mail.gmail.com>
References: <e780c0971002241205t2f5c8e5gb0c3eb3110406a0d@mail.gmail.com>	<alpine.LFD.2.00.1002260650300.24621@gannet.stats.ox.ac.uk>	<e780c0971002260744x311159f2x7bd7264a9e97a8ff@mail.gmail.com>
	<e780c0971002260745q44c2ed28ta1a7805e58cdab14@mail.gmail.com>
Message-ID: <4B87F0BE.8040804@statistik.tu-dortmund.de>


R CMD check executes the R code in the vignettes and checks if that 
works, and it checks if the PDFs are available. It does not check if it 
can build the vignettes, because that is only necessary on the 
maintainer's machine since the PDFs are shipped with the (built) source 
package.

Best,
Uwe Ligges




On 26.02.2010 16:45, Kasper Daniel Hansen wrote:
> (forwarding to R-devel)
>
> Prof. Ripley
>
> Thanks a lot for the help.
>
> I greatly appreciate the clarification that R does indeed install the
> package during the build process.  I must have been confused.  The
> error is now fixed and was not related to my (false) claim that R
> could not locate a dataset in /data.
>
> You were not able to replicate the error because you were using the
> _build_ tarballs available from (I guess)
>   http://bioconductor.org/packages/2.6/bioc/src/contrib/Genominator_1.1.3.tar.gz
> These tarballs are only put up, when the package passes R CMD build
> (naturally enough).  The version of Genominator I had problems with
> was 1.1.4 which is only available from subversion (since it did not
> build when I wrote the email).  1.1.4 ought to be available in a few
> days when the build system picks up on the changes I just committed.
>
> I did mention that I saw that the package did not complete R CMD
> build, but (semi-passed)
>   R CMD build --no-vignettes Genominator
>   R CMD check Genominator_XXX.tar.gz
>
> I have no double checked this, see output below.  I am using an
> R-devel that is a week old or so.  What I do below is
> 1) check out the package from svn
> 2) R CMD build --no-vignettes
> 3) R CMD check on the tarball.  Looks like it "passes" R CMD check
> with a warning about missing PDFs
> 4) verify that the source directory is empty by running svn status
> 5) R CMD build  which fails (as it should)
> (Note the package - in this svn version - has errors in the vignette)
>
> I would have expected that R CMD check failed or at least told me that
> the vignettes do not build.
>
> Of course, given my earlier mistakes with this, I could be messing
> something up.
>
> Output below.
>
> Thanks as always,
> Kasper
>
> compute-0-19:~/Work/packages/temp/>  echo $BIOCSVN
> https://hedgehog.fhcrc.org/gentleman/bioconductor/trunk/madman/Rpacks
> compute-0-19:~/Work/packages/temp/>  svn co -r 44843 $BIOCSVN/Genominator
>   <OUTOUR REMOVED>
> Checked out revision 44843.
> compute-0-19:~/Work/packages/temp/>  R-devel CMD build --no-vignettes
> Genominator
> * checking for file 'Genominator/DESCRIPTION' ... OK
> * preparing 'Genominator':
> * checking DESCRIPTION meta-information ... OK
> * removing junk files
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'Genominator_1.1.4.tar.gz'
>
> compute-0-19:~/Work/packages/temp/>  R-devel CMD check Genominator_1.1.4.tar.gz
> * checking for working pdflatex ... OK
> * using log directory
> '/home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck'
> * using R version 2.11.0 Under development (unstable) (2010-02-15 r51142)
> * using session charset: ISO8859-15
> * checking for file 'Genominator/DESCRIPTION' ... OK
> * this is package 'Genominator' version '1.1.4'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'Genominator' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the name space can be loaded with stated dependencies ... OK
> * checking whether the name space can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking data for non-ASCII characters ... OK
> * checking examples ... OK
> * checking tests ...
>   OK
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignettes without corresponding PDF:
>   /home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/Genominator.Rnw
>   /home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/plotting.Rnw
>   /home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00_pkg_src/Genominator/inst/doc/withShortRead.Rnw
> * checking PDF version of manual ... OK
>
> WARNING: There was 1 warning, see
>   /home/bst/student/khansen/Work/packages/temp/Genominator.Rcheck/00check.log
> for details
>
> compute-0-19:~/Work/packages/temp/>  svn status Genominator
> compute-0-19:~/Work/packages/temp/>  R-devel CMD build Genominator
> * checking for file 'Genominator/DESCRIPTION' ... OK
> * preparing 'Genominator':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * installing *source* package 'Genominator' ...
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> Loading required package: DBI
>
> Attaching package: 'IRanges'
>
> The following object(s) are masked from 'package:base':
>
>     Map, cbind, mapply, order, pmax, pmax.int, pmin, pmin.int, rbind,
>     rep.int, table
>
> ** help
> *** installing help indices
> ** building package indices ...
> * DONE (Genominator)
> * creating vignettes ... ERROR
> Loading required package: RSQLite
> Loading required package: DBI
> Loading required package: IRanges
>
> Attaching package: 'IRanges'
>
> The following object(s) are masked from 'package:base':
>
>     cbind, Map, mapply, order, pmax, pmax.int, pmin, pmin.int,
>     rbind, rep.int, table
>
> writing regions table: 0.026 sec
> SQL query: SELECT counts,feature FROM counts_tbl INNER JOIN
> __regions__ ON __regions__.chr = counts_tbl.chr AND
> counts_tbl.location BETWEEN __regions__.start AND __regions__.end AND
> (counts_tbl.strand = __regions__.strand OR __regions__.strand = 0 OR
> counts_tbl.strand = 0)
>
> fetching merge table: 0.027 sec
> splitting by: feature: 0.002 sec
> matplot: doing 1 plots with  col= ("1") pch= ("1" "2" "3" "4" "5" "6"
> "7" "8" "9" "0" "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
> "n" "o" "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z" "A" "B" "C" "D"
> "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S" "T" "U"
> "V" "W" "X" "Y" "Z") ...
>
> writing regions table: 0.025 sec
> SQL query: SELECT __regions__.id, TOTAL(counts) FROM __regions__ LEFT
> OUTER JOIN counts_tbl ON __regions__.chr = counts_tbl.chr AND
> counts_tbl.location BETWEEN __regions__.start AND __regions__.end AND
> (counts_tbl.strand = __regions__.strand OR __regions__.strand = 0 OR
> counts_tbl.strand = 0) GROUP BY __regions__.id ORDER BY __regions__.id
>
> fetching summary table: 0.044 sec
> fetching summary: 0.016 sec
> matplot: doing 1 plots with  col= ("1") pch= ("1" "2" "3" "4" "5" "6"
> "7" "8" "9" "0" "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m"
> "n" "o" "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z" "A" "B" "C" "D"
> "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S" "T" "U"
> "V" "W" "X" "Y" "Z") ...
>
> writing regions table: 0.026 sec
> SQL query: SELECT __regions__.id, TOTAL(counts_1), TOTAL(counts_2)
> FROM __regions__ LEFT OUTER JOIN allcounts ON __regions__.chr =
> allcounts.chr AND allcounts.location BETWEEN __regions__.start AND
> __regions__.end AND (allcounts.strand = __regions__.strand OR
> __regions__.strand = 0 OR allcounts.strand = 0) GROUP BY
> __regions__.id ORDER BY __regions__.id
>
> fetching summary table: 0.048 sec
> Loading required package: GenomeGraphs
> Loading required package: biomaRt
> Loading required package: grid
> Loading required package: ShortRead
> Loading required package: Biostrings
> Loading required package: BSgenome
> Loading required package: lattice
> Loading required package: yeastRNASeq
> Error: no function to return from, jumping to top level
> Execution halted
>
>
> Thanks again,
> Kasper
>
> 2010/2/26 Prof Brian Ripley<ripley at stats.ox.ac.uk>:
>> On Wed, 24 Feb 2010, Kasper Daniel Hansen wrote:
>>
>>> Based on some testing it seems to me that if I have a package with
>>>   a dataset in /data
>>>   a Sweave vignette in inst/doc (but no associated pdf file)
>>>   the vignette loads the data in /data through
>>>     data(dataset)
>>> and I do a
>>>   R CMD build
>>> R will try to build the pdf version of the vignette, but will be
>>> unable to find the dataset in data because the package is not yet
>>> installed.  However, if I do
>>
>> But R CMD build *does* install the package to build vignettes.  If I take
>> the current BioC-2.6 version of Genominator (1.1.3), remove the
>> inst/doc/*.pdf and any installed versions I see
>>
>> gannet% Rdev CMD build Genominator
>> * checking for file 'Genominator/DESCRIPTION' ... OK
>> * preparing 'Genominator':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to re-build vignettes
>> * installing *source* package ?Genominator? ...
>> ** R
>> ** data
>> ** inst
>> ** preparing package for lazy loading
>> Loading required package: DBI
>> Creating a new generic function for "head" in "Genominator"
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> * DONE (Genominator)
>> * creating vignettes ... OK
>> * removing junk files
>> * checking for LF line-endings in source and make files
>> * checking for empty or unneeded directories
>> * building 'Genominator_1.1.3.tar.gz'
>>
>> (Well, once I had installed the 307Mb dependency yeastRNASeq.)
>>
>> Now, you may be using an unreleased version of Genominator, but your
>> hypothesis (that the package needs to be installed beforehand) is not
>> correct.
>>
>>>   R CMD build --no-vignettes PKGNAME
>>>   R CMD check PKGNAME_VERSION.tar.gz
>>> the package passes R CMD check! Presumably because R CMD check
>>> installs the package first.
>>
>> Yes, to a temporary library, just as R CMD build does if there are
>> vignettes.
>>
>>> This took me a long time to track down (inspired by a recent addition
>>> of dataset to the Bioconductor package Genominator and a subsequent
>>> failed build - specifically the dataset yeastAnno.sources and the
>>> vignette withShortRead.Rnw).  I am using lazy loading (in case it
>>> matters, which I don't think it does).
>>>
>>> It seems like the relevant fix is to include pdf versions of the
>>> vignette(s) in inst/doc.
>>>
>>> On one hand I can see why the build fails.
>>
>> So given the evidence that R CMD build does install the package, please
>> explain.
>>
>>> And the fix is easy.  But
>>> just thought I would mention it.
>>>
>>> Kasper
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From plummer at iarc.fr  Fri Feb 26 18:25:12 2010
From: plummer at iarc.fr (Martyn Plummer)
Date: Fri, 26 Feb 2010 18:25:12 +0100
Subject: [Rd] Compiling R on Linux with SunStudio 12.1: "wide-character
 type" problems (rt)
In-Reply-To: <d6243f3f1002231455n24503c8p4d6994865b693d1d@mail.gmail.com>
References: <d6243f3f1002231455n24503c8p4d6994865b693d1d@mail.gmail.com>
Message-ID: <1267205112.23203.21.camel@localhost>

You can work around this by disabling large file support (configure
--disable-largefile).

This seems to be another glibc bug. In the header glob.h, there are two
lines where the pre-processor fails to check that __GNUC__ is defined,
and it isn't defined when using Sun Studio.

Evidently, glibc was designed to work with gcc and has not been
extensively tested with other compilers, or other vendors have learned
to work around the bugs.

Martyn
 

On Tue, 2010-02-23 at 16:55 -0600, rt wrote:
> Thank you Martyn,
> 
> I am one step closer.  Using R-patched, configure was successful. However,
> make exited with an error.
> 
> Configure summary:
> Installation directory:    /usr/local
>   C compiler:                /opt/sun/sunstudio12.1/bin/suncc  -g -O -xc99
> -xlibmil -m32  -xlibmieee -nofstore
>   Fortran 77 compiler:       /opt/sun/sunstudio12.1/bin/sunf95  -g -O
> -libmil  -m32 -nofstore
>   C++ compiler:              /opt/sun/sunstudio12.1/bin/sunCC  -g -O
> -xlibmil -m32 -xlibmieee -nofstore
>   Fortran 90/95 compiler:    /opt/sun/sunstudio12.1/bin/sunf95 -g -O
> -libmil  -m32 -nofstore
>   Obj-C compiler:
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline, ICU, lzma
>   Additional capabilities:   PNG, JPEG, NLS, cairo
>   Options enabled:           shared BLAS, R profiling, Java
>   Recommended packages:      yes
> 
> MAKE error:
> make returned an error related to platform.c and glob.h.
> It seems that glob.h has a poiter to struct dirent {..}, platorm.c has
> struct dirent64 {..}.
> Error message:
>   /opt/sun/sunstudio12.1/bin/suncc
>   -I../../src/extra   -I. -I../../src/include -I../../src/include -I.
>   -I/opt/sun/sunstudio12.1/prod/include
> 
> -I/opt/sun/sunstudio12.1/prod/include/cc-I/opt/sun/sunstudio12.1/prod/include/cc/sys
> 
>   -DHAVE_CONFIG_H   -g -g -O -xc99 -xlibmil -m32  -xlibmieee -nofstore
>   -c platform.c -o platform.o
> "/usr/include/glob.h", line 175: identifier redeclared: glob64
>  current : function(pointer to const char, int, pointer to function(..)
> returning int, pointer to struct  {unsigned int gl_pathc, pointer to pointer
> to char gl_pathv, unsigned int gl_offs, int gl_flags, pointer to
> function(..) returning void gl_closedir, pointer to function(..) returning
> pointer to struct dirent64 {..} gl_readdir, pointer to function(..)
> returning pointer to void gl_opendir, pointer to function(..) returning int
> gl_lstat, pointer to function(..) returning int gl_stat}) returning int
>  previous: function(pointer to const char, int, pointer to function(..)
> returning int, pointer to struct  {unsigned int gl_pathc, pointer to pointer
> to char gl_pathv, unsigned int gl_offs, int gl_flags, pointer to
> function(..) returning void gl_closedir, pointer to function(..) returning
> pointer to struct dirent {..} gl_readdir, pointer to function(..) returning
> pointer to void gl_opendir, pointer to function(..) returning int gl_lstat,
> pointer to function(..) returning int gl_stat}) returning int :
> "/usr/include/glob.h", line 159
> 
> My cpu is correctly identified as i386 and I included the flag -m32. Do I
> need to specify architecture separately?
> 
> thanks,
> 
> Russ
> 
> > Russ,
> >
> > This is a known issue with Sun Studio on Linux and was fixed by Brian
> > Ripley in January. If you download R-patched.tar.gz from here:
> >
> > ftp://ftp.stat.math.ethz.ch/Software/R/
> >
> > then it should work for you.
> >
> > Martyn
> >
> > On Mon, 2010-02-22 at 13:11 -0600, rt wrote:
> > > I am trying to compile R on Linux using SunStudio. Configure flags are
> > > mostly as suggested in the R install guide.
> > >> R install guide also indicates that: "The OS needs to have enough
> > support
> > > for wide-character types: this is checked at configuration. Specifically,
> > > the C99 functionality of headers wchar.h and wctype.h, types wctans_t and
> > > mbstate_t and functions mbrtowc, mbstowcs, wcrtomb, wcscoll, wcstombs,
> > > wctrans, wctype, and iswctype."
> > > Configure stops with the following error message:
> > >
> > > configure:39534: result: no
> > > configure:39710: error: Support for MBCS locales is required.*
> > >
> > > I am not sure if this is a Linux issue or if it is a SunStudio issue.
> >  Has
> > > anybody tried to compile R on Linux using SunStudio?
> > >
> > > Thanks in advance,
> > >
> > > Russ
> > >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From murdoch at stats.uwo.ca  Fri Feb 26 18:37:55 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 26 Feb 2010 12:37:55 -0500
Subject: [Rd] Error on Windows build: "unable to re-encode"
In-Reply-To: <9DD49155-D72B-4CBA-919D-824365BF4707@gmx.net>
References: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>
	<4B87D474.5060207@stats.uwo.ca>
	<9DD49155-D72B-4CBA-919D-824365BF4707@gmx.net>
Message-ID: <4B8806F3.9060409@stats.uwo.ca>

On 26/02/2010 11:05 AM, Felix Sch?nbrodt wrote:
> Hi Duncan,
>
> I now declared the endcoding in the DESCRIPTION to UTF-8 (and all files are encoded in that way, too). As my last name is "Sch?nbrodt", I'd be happy to see it that way in the package ;-)
> However, it still doesn't build on Windows (but works on Mac and Linux). 
>
> Unfortunately I cannot build the Windows packages myself (I work on a Mac), but the win-builder by Uwe Ligges still shows the same error ...
>
> > If declaring the encoding in DESCRIPTION doesn't solve the problem, I'd be happy to take a look at the package.
>
> That's a great offer! I'd be very happy if you could take a look.
> You can find the source at http://r-forge.r-project.org/projects/tripler/, a tar.gz is attached as well.


I got the same error as you.  It looks as though iconv has trouble with 
the way some characters are encoded in your file.  For example, on line 
893, you have a u-umlaut encoded as EF BF BD.  According the the UTF-8 
tables at 
http://www.utf8-chartable.de/unicode-utf8-table.pl?start=65280, that 
encodes a question mark in a diamond, "REPLACEMENT CHARACTER".  There's 
no corresponding character in the standard Windows latin1 encoding, so 
conversion fails.  Firefox can display the funny question mark, but it 
doesn't display the u-umlaut as you intended, so I think this is an 
error in your file.

A way to find all such errors is as follows:  read the file as utf-8, 
then use the iconv() function in R to convert it to latin1.  When I do 
that, I get NA on lines 893 and 953, which are displayed to me as

[1] "\t# im latenten Fall: die Error variance erst am Ende berechnen 
(d.h., alle error componenten ???ber alle Gruppen mitteln, die unter 
NUll auf Null setzen, dann addieren)"
[2] "\t\t# TODO: ???berpr???fen!"    

We might be able to make the error message in the package installer more 
informative (e.g. giving the line number that failed).  I'll look into that.

Duncan Murdoch


From bolker at ufl.edu  Fri Feb 26 18:44:45 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 26 Feb 2010 12:44:45 -0500
Subject: [Rd] scale(x, center=FALSE) (PR#14219)
In-Reply-To: <4B87E790.6000302@bgsu.edu>
References: <4B87E790.6000302@bgsu.edu>
Message-ID: <4B88088D.2040505@ufl.edu>

 [cc'ing back to r-devel]

Maria Rizzo wrote:
> Ben,
> 
> I receive the digest version of r-devel - so I do not have the 
> individual messages to reply to. In reply to yours:
> 
> I think this is a bug for the following reasons. While it is true 
> that one can define a scale factor differently for different 
> purposes, one would hope that within a given function the definition 
> does not vary. If we agree that we want to divide by standard 
> deviation, which scales data to sd=1, then why would we choose to 
> divide by square root of 1/(n-1) times sum of squares of the data 
> when data is not centered? This does not scale the data to sd=1.

  This is really a disagreement with the way the function is implemented
(and I happen to agree with you), but I would argue that it is *not* a
bug in the strict sense -- I would call it a "misfeature".

  From the R FAQ:

> Finally, a command's intended definition may not be best for 
> statistical analysis. This is a very important sort of problem, but
> it is also a matter of judgment. 


 [snip]

>> Are you sure this is a bug? I agree that the way the function 
>> behaves is (to me) mildly confusing, but the documentation says:
>> 
>> * The value of ?scale? determines how column scaling is performed *
>>  (after centering).  If ?scale? is a numeric vector with length * 
>> equal to the number of columns of ?x?, then each column of ?x? is *
>>  divided by the corresponding value from ?scale?.  If ?scale? is * 
>> ?TRUE? then scaling is done by dividing the (centered) columns of *
>>  ?x? by their standard deviations, and if ?scale? is ?FALSE?, no * 
>> scaling is done.
>> 
>> * The standard deviation for a column is obtained by computing the
>>  * square-root of the sum-of-squares of the non-missing values in 
>> the * column divided by the number of non-missing values minus one
>>  * (whether or not centering was done).
>> 
>> If you read the first clause of the last sentence of the first 
>> paragraph in isolation, you would have the expectation that the 
>> columns would be scaled by sd(x).  However, the second paragraph 
>> clearly states that the 'standard deviation' is defined here as the
>>  root-mean-square over (n-1), that is, sqrt(sum(x^2)/(n-1)) ...
> 
> This conflicts with the paragraph above it. What I see is that the 
> (centered) columns are divided by their standard deviations, where 
> (centered) is inserted or not before "columns" depending on whether 
> center=TRUE or center=FALSE. Why modify the definition of "standard 
> deviation"? Why compute the standard deviation of the centered data 
> when data is not centered? This measures standard deviation with 
> respect to the origin rather than measuring dispersion about the 
> mean.

>> This does seem like a funny choice, but it is probably stuck that 
>> way without an extremely compelling argument to the contrary. If 
>> you want to scale columns by sd() instead you can say
>> 
>> scale(x,center=FALSE,scale=apply(x,2,sd))
> 
> Of course, I know how to achieve the result of scaling my data to 
> sd=1. The problem is that a function called scale with options of 
> center=TRUE or center=FALSE, should apply the same definition of 
> scale if scale=TRUE in both cases.

  "should" according to you ...
> 
>> Would you like to submit a patch for the documentation that would 
>> preserve the sense, clarify the behavior, and not be much longer 
>> than the current version ... ?
> 
> For me the problem is deeper than an issue with the documentation. In
>  any case, I think that it is a potential source of confusion and 
> errors on the part of users.
> 
> regards, Maria
> 

  Again, I agree with you that the behavior is not optimal, but it is
very hard to make changes in R when the behavior is sub-optimal rather
than actually wrong (by some definition).  R-core is very conservative
about changes that break backward compatibility; I would like it if they
chose to change the function to use standard deviation rather than
root-mean-square, but I doubt it will happen (and it would break things
for any users who are relying on the current definition).

  It turns out that the documentation for this function was changed on
25 Nov 2009 to clarify this issue, but I think the change (which among
other minor changes modified the previous use of "root mean square" to
"standard deviation") didn't help that much ...  I have attached a patch
file (and append the information below as well) that changes "standard
deviation" back to "root mean square" and is much more explicit about
this issue ... I hope R-core will jump in, critique it, and possibly use
it in some form to improve (?) the documentation ...

  [PS: I have written that the scaling is equivalent to sd() "if and
only if" centering was done.  Technically it would also be equivalent if
the column already had zero mean ...]

===================================================================
--- scale.Rd	(revision 51180)
+++ scale.Rd	(working copy)
@@ -41,13 +41,18 @@
   equal to the number of columns of \code{x}, then each column of
   \code{x} is divided by the corresponding value from \code{scale}.  If
   \code{scale} is \code{TRUE} then scaling is done by dividing the
-  (centered) columns of \code{x} by their standard deviations, and if
+  (centered) columns of \code{x} by their root-mean-squares, and if
   \code{scale} is \code{FALSE}, no scaling is done.
-
-  The standard deviation for a column is obtained by computing the
-  square-root of the sum-of-squares of the non-missing values in the
-  column divided by the number of non-missing values minus one (whether
-  or not centering was done).
+
+  The root-mean-square for a (possibly centered)
+  column is defined as
+  \eqn{\sqrt{\sum(x^2)/(n-1)}}{sqrt(sum(x^2)/(n-1))},
+  where \eqn{x} is a vector of the non-missing values
+  and \eqn{n} is the number of non-missing values.
+  If (and only if) centering was done,
+  this is equivalent to \code{sd(x,na.rm=TRUE)}.
+  (To scale by the standard deviations without centering,
+  use \code{scale(x,center=FALSE,scale=apply(x,2,sd,na.rm=TRUE))}.)
 }
 \references{
   Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: scale.Rd.patch
Type: text/x-patch
Size: 1340 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100226/b83e9d8b/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 261 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100226/b83e9d8b/attachment-0001.bin>

From valerop at uv.es  Fri Feb 26 22:59:04 2010
From: valerop at uv.es (Pedro Valero-Mora)
Date: Fri, 26 Feb 2010 22:59:04 +0100
Subject: [Rd] Announce: Speicial issue of the JSS on Graphical User
 Interfaces for R
Message-ID: <4B884428.9020901@uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100226/8f91bee7/attachment.pl>

From misc7 at emerose.org  Sat Feb 27 02:46:35 2010
From: misc7 at emerose.org (Ben)
Date: Fri, 26 Feb 2010 19:46:35 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002260628g663800c8pbb531a7565586b03@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
	<20100226080112.72341a14.misc7@emerose.org>
	<971536df1002260628g663800c8pbb531a7565586b03@mail.gmail.com>
Message-ID: <20100226194635.1bfa3e50.misc7@emerose.org>

Maybe I'm still not getting something fundamental, but I didn't intend
my "proto(baseenv(), expr={a <- z})$a" example to be realistic.  In
practice "a <- z" would be replaced with hundreds of lines of code,
where many functions are called.  In theory you could track down every
function that's global or from another package and track them down,
but then you would have to put dozens of extra lines of boilerplate.
It's actually worse than that, as this example shows:

> proto(baseenv(), f = function(.) sd(1:3))$f()
Error in get("f", env = proto(baseenv(), f = function(.) sd(1:3)), inherits = TRUE)(proto(baseenv(),  : 
  could not find function "sd"
> proto(baseenv(), sd = sd, f = function(.) sd(1:3))$f()
Error in sd(1:3) : could not find function "var"

Not only would every external function have to be specifically
declared with a separate argument, even unused functions may need to
be declared.  That means any change in the implementation of an
external function could break this code.

Again, I may be missing something since I'm new to proto, but I don't
see why you're dismissing this example as "user error".


-- 
Ben Escoto

----------------- Original message -----------------
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: Ben <misc7 at emerose.org>
Date: Fri, 26 Feb 2010 09:28:46 -0500
On Fri, Feb 26, 2010 at 9:01 AM, Ben <misc7 at emerose.org> wrote:
>
>> In end it seems that your real beef is with R so perhaps you should
>> be using a different language.
>
> In my case you may be right. ?I do think there are a million things
> wrong with R. ?For instance, I was looking for a package that
> overcomes two of the problems R IMHO has: namespace pollution and the
> lack of an easy-to-use standard object system.
>
> Should I be using R? ?I do keep asking myself that same question...
>
>> With respect to proto its really just discussing whether to use
>> proto(baseenv(), ...) vs proto(...)
>
> Unfortunately this doesn't fix the problem as was noted earlier:
>
>> z <- 1
>> proto(baseenv(), expr={a <- z})$a
> Error in eval(expr, envir, enclos) : object "z" not found
>

As already mentioned lets not confuse user error with actual problems
pertaining to proto and R.  It should have been written like this if
that is what was wanted:

> z <- 1
> proto(baseenv(), a = z)$a
[1] 1


From berwin at maths.uwa.edu.au  Sat Feb 27 03:27:10 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 27 Feb 2010 10:27:10 +0800
Subject: [Rd] build, data and vignettes
In-Reply-To: <4B87F0BE.8040804@statistik.tu-dortmund.de>
References: <e780c0971002241205t2f5c8e5gb0c3eb3110406a0d@mail.gmail.com>
	<alpine.LFD.2.00.1002260650300.24621@gannet.stats.ox.ac.uk>
	<e780c0971002260744x311159f2x7bd7264a9e97a8ff@mail.gmail.com>
	<e780c0971002260745q44c2ed28ta1a7805e58cdab14@mail.gmail.com>
	<4B87F0BE.8040804@statistik.tu-dortmund.de>
Message-ID: <20100227102710.6ed6e4d0@absentia>

G'day Uwe,

On Fri, 26 Feb 2010 17:03:10 +0100
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> R CMD check executes the R code in the vignettes and checks if that 
> works, and it checks if the PDFs are available. It does not check if
> it can build the vignettes, because that is only necessary on the 
> maintainer's machine since the PDFs are shipped with the (built)
> source package.

Are you implying that "R CMD check" has reverted to its pre-2.6.0
behaviour?  If I remember correctly, for R versions before 2.6.0  "R
CMD check" did not attempt to build the vignette, with version 2.6.0 it
started to do so.  The relvant NEWS entry is:

    o	R CMD check now (by default) attempts to latex the
    vignettes rather than just weave and tangle them: this will give a
    NOTE if there are latex errors.

Cheers,

	Berwin


From jel+r at cs.uni-magdeburg.de  Sat Feb 27 03:38:44 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Sat, 27 Feb 2010 03:38:44 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <4B82753B.2090006@biostat.ku.dk>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>
	<4B82753B.2090006@biostat.ku.dk>
Message-ID: <20100227023844.GA1272@trex.cs.uni-magdeburg.de>

On Mon, Feb 22, 2010 at 01:14:51PM +0100, Peter Dalgaard wrote:
Hi Peter,
  
sorry for the later answer - had to finish other tasks first :(

> I played around with inkscape again (& it IS a time sink...) The 
> attached version is around 200K and not too bad looking to my eyes. How 
> does it work for your purposes?

Yes - still a little bit big (most are usually not bigger than 50K, but
some exceptions hav 80..100K), but much better than 2M and sufficient
IMHO, too.

Installed the package (see
http://dev.cs.uni-magdeburg.de/lnf/i386/R/LNFr-desktop/ ) -> looks
ok in the GNOME menu and nautilus. If you want to test it yourself
on Linux or Solaris (procedure is the same for freedesktops aka Solaris
and Linux ;-)), copy the 3 files to the same location and call
update-desktop-database ; update-mime-database $instdir/share/mime

Than the menu entries appear immediately in the GNOME application menu
(nautilus needs to be restarted to get the "news" aka icon displayed
for *.R).

Currently the last thing I'm thinking about is: "with '-g Tk' start
Rcmdr if available, otherwise tkStartGUI()". Would you mind to integrate
that into the official R tree? I know, its more or less easy to modify
library/tcltk/exec/Tk-frontend.R, however admins as well as package
creators/maintainers don't like, when one package modifies the content
of another one and have to keep track of changes, i.e. need to do more
or less "sophisticated" things, when they get removed ...

Regards and thanx,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From ggrothendieck at gmail.com  Sat Feb 27 03:41:33 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Feb 2010 21:41:33 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <20100226194635.1bfa3e50.misc7@emerose.org>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com> 
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com> 
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com> 
	<20100226080112.72341a14.misc7@emerose.org>
	<971536df1002260628g663800c8pbb531a7565586b03@mail.gmail.com> 
	<20100226194635.1bfa3e50.misc7@emerose.org>
Message-ID: <971536df1002261841q6bfc95a5q167799d9cdb954c@mail.gmail.com>

On Fri, Feb 26, 2010 at 8:46 PM, Ben <misc7 at emerose.org> wrote:
> Maybe I'm still not getting something fundamental, but I didn't intend

I think you are missing the R search path.  Try this:

search()

That shows you the search path.  Normally it starts searching at the
beginning and moves forward.

> my "proto(baseenv(), expr={a <- z})$a" example to be realistic. ?In
> practice "a <- z" would be replaced with hundreds of lines of code,
> where many functions are called. ?In theory you could track down every
> function that's global or from another package and track them down,
> but then you would have to put dozens of extra lines of boilerplate.
> It's actually worse than that, as this example shows:
>
>> proto(baseenv(), f = function(.) sd(1:3))$f()
> Error in get("f", env = proto(baseenv(), f = function(.) sd(1:3)), inherits = TRUE)(proto(baseenv(), ?:
> ?could not find function "sd"
>> proto(baseenv(), sd = sd, f = function(.) sd(1:3))$f()
> Error in sd(1:3) : could not find function "var"

That's because sd is in stats, not in base and you told it to start
searching at the end of the search path rather than the beginning.
Try this:

> Object <- as.environment("package:stats")
> proto(Object, f = function(.) sd(1:3))$f()
[1] 1

>
> Not only would every external function have to be specifically
> declared with a separate argument, even unused functions may need to
> be declared. ?That means any change in the implementation of an
> external function could break this code.
>
> Again, I may be missing something since I'm new to proto, but I don't
> see why you're dismissing this example as "user error".
>
>
> --
> Ben Escoto
>
> ----------------- Original message -----------------
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: Ben <misc7 at emerose.org>
> Date: Fri, 26 Feb 2010 09:28:46 -0500
> On Fri, Feb 26, 2010 at 9:01 AM, Ben <misc7 at emerose.org> wrote:
>>
>>> In end it seems that your real beef is with R so perhaps you should
>>> be using a different language.
>>
>> In my case you may be right. ?I do think there are a million things
>> wrong with R. ?For instance, I was looking for a package that
>> overcomes two of the problems R IMHO has: namespace pollution and the
>> lack of an easy-to-use standard object system.
>>
>> Should I be using R? ?I do keep asking myself that same question...
>>
>>> With respect to proto its really just discussing whether to use
>>> proto(baseenv(), ...) vs proto(...)
>>
>> Unfortunately this doesn't fix the problem as was noted earlier:
>>
>>> z <- 1
>>> proto(baseenv(), expr={a <- z})$a
>> Error in eval(expr, envir, enclos) : object "z" not found
>>
>
> As already mentioned lets not confuse user error with actual problems
> pertaining to proto and R. ?It should have been written like this if
> that is what was wanted:
>
>> z <- 1
>> proto(baseenv(), a = z)$a
> [1] 1
>
>


From ggrothendieck at gmail.com  Sat Feb 27 04:35:01 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Feb 2010 22:35:01 -0500
Subject: [Rd] proto and baseenv()
In-Reply-To: <971536df1002261841q6bfc95a5q167799d9cdb954c@mail.gmail.com>
References: <20100225043854.GA26106@klutometis.wikitex.org> 
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com> 
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com> 
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com> 
	<20100226080112.72341a14.misc7@emerose.org>
	<971536df1002260628g663800c8pbb531a7565586b03@mail.gmail.com> 
	<20100226194635.1bfa3e50.misc7@emerose.org>
	<971536df1002261841q6bfc95a5q167799d9cdb954c@mail.gmail.com>
Message-ID: <971536df1002261935uf8a6a20l229fddbb2511f4dd@mail.gmail.com>

Added one other comment below.

On Fri, Feb 26, 2010 at 9:41 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Fri, Feb 26, 2010 at 8:46 PM, Ben <misc7 at emerose.org> wrote:
>> Maybe I'm still not getting something fundamental, but I didn't intend
>
> I think you are missing the R search path. ?Try this:
>
> search()
>
> That shows you the search path. ?Normally it starts searching at the
> beginning and moves forward.
>
>> my "proto(baseenv(), expr={a <- z})$a" example to be realistic. ?In
>> practice "a <- z" would be replaced with hundreds of lines of code,
>> where many functions are called. ?In theory you could track down every
>> function that's global or from another package and track them down,
>> but then you would have to put dozens of extra lines of boilerplate.
>> It's actually worse than that, as this example shows:
>>
>>> proto(baseenv(), f = function(.) sd(1:3))$f()
>> Error in get("f", env = proto(baseenv(), f = function(.) sd(1:3)), inherits = TRUE)(proto(baseenv(), ?:
>> ?could not find function "sd"
>>> proto(baseenv(), sd = sd, f = function(.) sd(1:3))$f()
>> Error in sd(1:3) : could not find function "var"
>
> That's because sd is in stats, not in base and you told it to start
> searching at the end of the search path rather than the beginning.
> Try this:
>
>> Object <- as.environment("package:stats")

or if you just want to exlude the global environment but still include
any loaded packages:

Object <- as.environment(2)

(If you have not loaded any packages then the two Object<- statements
have the same effect but if there are loaded packages the second
includes them while the first excludes them.)

>> proto(Object, f = function(.) sd(1:3))$f()
> [1] 1
>
>>
>> Not only would every external function have to be specifically
>> declared with a separate argument, even unused functions may need to
>> be declared. ?That means any change in the implementation of an
>> external function could break this code.
>>
>> Again, I may be missing something since I'm new to proto, but I don't
>> see why you're dismissing this example as "user error".
>>
>>
>> --
>> Ben Escoto
>>
>> ----------------- Original message -----------------
>> From: Gabor Grothendieck <ggrothendieck at gmail.com>
>> To: Ben <misc7 at emerose.org>
>> Date: Fri, 26 Feb 2010 09:28:46 -0500
>> On Fri, Feb 26, 2010 at 9:01 AM, Ben <misc7 at emerose.org> wrote:
>>>
>>>> In end it seems that your real beef is with R so perhaps you should
>>>> be using a different language.
>>>
>>> In my case you may be right. ?I do think there are a million things
>>> wrong with R. ?For instance, I was looking for a package that
>>> overcomes two of the problems R IMHO has: namespace pollution and the
>>> lack of an easy-to-use standard object system.
>>>
>>> Should I be using R? ?I do keep asking myself that same question...
>>>
>>>> With respect to proto its really just discussing whether to use
>>>> proto(baseenv(), ...) vs proto(...)
>>>
>>> Unfortunately this doesn't fix the problem as was noted earlier:
>>>
>>>> z <- 1
>>>> proto(baseenv(), expr={a <- z})$a
>>> Error in eval(expr, envir, enclos) : object "z" not found
>>>
>>
>> As already mentioned lets not confuse user error with actual problems
>> pertaining to proto and R. ?It should have been written like this if
>> that is what was wanted:
>>
>>> z <- 1
>>> proto(baseenv(), a = z)$a
>> [1] 1
>>
>>
>


From nicebread at gmx.net  Sat Feb 27 08:38:10 2010
From: nicebread at gmx.net (=?iso-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Sat, 27 Feb 2010 08:38:10 +0100
Subject: [Rd] Error on Windows build: "unable to re-encode"
In-Reply-To: <4B8806F3.9060409@stats.uwo.ca>
References: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>
	<4B87D474.5060207@stats.uwo.ca>
	<9DD49155-D72B-4CBA-919D-824365BF4707@gmx.net>
	<4B8806F3.9060409@stats.uwo.ca>
Message-ID: <D6927217-9163-4FAD-A16B-F3441F4FA8B3@gmx.net>

Thanks for your help - that was the solution (easy enough to remove these two characters - they've been in only comments anyway).
Fortunately, the DECRIPTION file accepts umlauts, as in my second name. The problem was only in the source file.

Felix


Am 26.02.2010 um 18:37 schrieb Duncan Murdoch:

> On 26/02/2010 11:05 AM, Felix Sch?nbrodt wrote:
>> Hi Duncan,
>> 
>> I now declared the endcoding in the DESCRIPTION to UTF-8 (and all files are encoded in that way, too). As my last name is "Sch?nbrodt", I'd be happy to see it that way in the package ;-)
>> However, it still doesn't build on Windows (but works on Mac and Linux). 
>> Unfortunately I cannot build the Windows packages myself (I work on a Mac), but the win-builder by Uwe Ligges still shows the same error ...
>> 
>> > If declaring the encoding in DESCRIPTION doesn't solve the problem, I'd be happy to take a look at the package.
>> 
>> That's a great offer! I'd be very happy if you could take a look.
>> You can find the source at http://r-forge.r-project.org/projects/tripler/, a tar.gz is attached as well.
> 
> 
> I got the same error as you.  It looks as though iconv has trouble with the way some characters are encoded in your file.  For example, on line 893, you have a u-umlaut encoded as EF BF BD.  According the the UTF-8 tables at http://www.utf8-chartable.de/unicode-utf8-table.pl?start=65280, that encodes a question mark in a diamond, "REPLACEMENT CHARACTER".  There's no corresponding character in the standard Windows latin1 encoding, so conversion fails.  Firefox can display the funny question mark, but it doesn't display the u-umlaut as you intended, so I think this is an error in your file.
> 
> A way to find all such errors is as follows:  read the file as utf-8, then use the iconv() function in R to convert it to latin1.  When I do that, I get NA on lines 893 and 953, which are displayed to me as
> 
> [1] "\t# im latenten Fall: die Error variance erst am Ende berechnen (d.h., alle error componenten ???ber alle Gruppen mitteln, die unter NUll auf Null setzen, dann addieren)"
> [2] "\t\t# TODO: ???berpr???fen!"    
> We might be able to make the error message in the package installer more informative (e.g. giving the line number that failed).  I'll look into that.
> 
> Duncan Murdoch
> 
> 


From pcd at roxygen.org  Sat Feb 27 09:36:20 2010
From: pcd at roxygen.org (Peter Danenberg)
Date: Sat, 27 Feb 2010 02:36:20 -0600
Subject: [Rd] proto and baseenv()
In-Reply-To: <4B87C4C4.6020201@stats.uwo.ca>
References: <20100225075038.79ca9b63.misc7@emerose.org>
	<4B868B1A.5050409@stats.uwo.ca>
	<20100225194919.00b10700.misc7@emerose.org>
	<20100226022322.GB19263@klutometis.wikitex.org>
	<971536df1002251931r4972bcdes9c6910423fc52af6@mail.gmail.com>
	<20100226041617.GB21674@klutometis.wikitex.org>
	<971536df1002252042q40b9b00do23b24370ea919482@mail.gmail.com>
	<20100226054154.GA23715@klutometis.wikitex.org>
	<971536df1002260409ud3ca15od596bf7af753d8be@mail.gmail.com>
	<4B87C4C4.6020201@stats.uwo.ca>
Message-ID: <20100227083620.GA27958@klutometis.wikitex.org>

> One thing that I dislike about scoping in R is the fact that even in a 
> namespace, searches eventually get to the global environment.  I'd prefer 
> if namespace searches went through the imported namespaces and nothing 
> else.  If that were the case, then the a$z example would never find a z in 
> the global environment, and that example would only be a problem for people 
> fiddling around in the console, not programming carefully in a
> package.

Amazing, Duncan; I think you hit upon the perfect compromise. Though
the issues you're bringing up are bigger than proto; at least in the
case of proto, deriving from as.environment(2) is an interesting
stop-gap solution.

Thanks to Gabor for suggesting it.


From p.dalgaard at biostat.ku.dk  Sat Feb 27 10:18:23 2010
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 27 Feb 2010 10:18:23 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <20100227023844.GA1272@trex.cs.uni-magdeburg.de>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>	<4B80275C.8080806@biostat.ku.dk>	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>	<4B80313D.1000909@biostat.ku.dk>	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>	<4B82753B.2090006@biostat.ku.dk>
	<20100227023844.GA1272@trex.cs.uni-magdeburg.de>
Message-ID: <4B88E35F.3010805@biostat.ku.dk>

Jens Elkner wrote:
> On Mon, Feb 22, 2010 at 01:14:51PM +0100, Peter Dalgaard wrote:
> Hi Peter,
>   
> sorry for the later answer - had to finish other tasks first :(
> 
>> I played around with inkscape again (& it IS a time sink...) The 
>> attached version is around 200K and not too bad looking to my eyes. How 
>> does it work for your purposes?
> 
> Yes - still a little bit big (most are usually not bigger than 50K, but
> some exceptions hav 80..100K), but much better than 2M and sufficient
> IMHO, too.

[AFAIR, this didn't go via r-devel, so people here won't have seen it 
before]

I suppose I should put it somewhere for others to play with. It should 
be possible to reduce the number of colour layers and get down to  the 
50 K or so, but it is quite fiddly. I found that if you put inkscape in 
"outline mode", then you can manipulate the Bezier curves directly and 
get rid of the artifacts from the bitmap tracing. Currently, it has 
about 64 paths of about 60 control points each, so it might be a better 
strategy to start over with a coarser trace.

> 
> Installed the package (see
> http://dev.cs.uni-magdeburg.de/lnf/i386/R/LNFr-desktop/ ) -> looks
> ok in the GNOME menu and nautilus. If you want to test it yourself
> on Linux or Solaris (procedure is the same for freedesktops aka Solaris
> and Linux ;-)), copy the 3 files to the same location and call
> update-desktop-database ; update-mime-database $instdir/share/mime
> 
> Than the menu entries appear immediately in the GNOME application menu
> (nautilus needs to be restarted to get the "news" aka icon displayed
> for *.R).

Mmm, I'm changing jobs on Monday and I expect to be out cold for a 
while, switching computer platform and getting up to speed in general. 
Any chance of a couple of screenshots?

> Currently the last thing I'm thinking about is: "with '-g Tk' start
> Rcmdr if available, otherwise tkStartGUI()". Would you mind to integrate
> that into the official R tree? I know, its more or less easy to modify
> library/tcltk/exec/Tk-frontend.R, however admins as well as package
> creators/maintainers don't like, when one package modifies the content
> of another one and have to keep track of changes, i.e. need to do more
> or less "sophisticated" things, when they get removed ...

This sounds a bit far-reaching. The "-g Tk" route is a bit of a kludge 
already, so everything is in for a review and I'd rather not build 
things on top of a crumbling foundation.

You might be able to do something with environment variables and 
.Rprofile files instead. (I was about to suggest 'R -e something' but 
Rcmdr refuses to start in a non-interactive session).

> 
> Regards and thanx,
> jel.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Sat Feb 27 17:08:08 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 27 Feb 2010 11:08:08 -0500
Subject: [Rd] Error on Windows build: "unable to re-encode"
In-Reply-To: <D6927217-9163-4FAD-A16B-F3441F4FA8B3@gmx.net>
References: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>	<4B87D474.5060207@stats.uwo.ca>	<9DD49155-D72B-4CBA-919D-824365BF4707@gmx.net>	<4B8806F3.9060409@stats.uwo.ca>
	<D6927217-9163-4FAD-A16B-F3441F4FA8B3@gmx.net>
Message-ID: <4B894368.1080408@stats.uwo.ca>

Felix Sch?nbrodt wrote:
> Thanks for your help - that was the solution (easy enough to remove these two characters - they've been in only comments anyway).
> Fortunately, the DECRIPTION file accepts umlauts, as in my second name. The problem was only in the source file.
>   

I think comments in R code could also include umlauts, but they need to 
be encoded in a way that can be converted to Latin1 on Windows.  I don't 
know why yours weren't.  Did those characters look like u-umlaut on your 
system?  What editor did you use to produce that file?

I'm not sure what the consequences would be of allowing unrepresentable 
characters to be mapped to question marks or hex codes (with a 
warning).  I think it would slow down the processing a bit (because 
those lines would need to be processed twice: once to detect that they 
have some bad characters, a second time to replace them).  I'm not sure 
if it would slow down processing of files that include no bad chars.  
I'll take a look.

Duncan Murdoch


> Felix
>
>
> Am 26.02.2010 um 18:37 schrieb Duncan Murdoch:
>
>   
>> On 26/02/2010 11:05 AM, Felix Sch?nbrodt wrote:
>>     
>>> Hi Duncan,
>>>
>>> I now declared the endcoding in the DESCRIPTION to UTF-8 (and all files are encoded in that way, too). As my last name is "Sch?nbrodt", I'd be happy to see it that way in the package ;-)
>>> However, it still doesn't build on Windows (but works on Mac and Linux). 
>>> Unfortunately I cannot build the Windows packages myself (I work on a Mac), but the win-builder by Uwe Ligges still shows the same error ...
>>>
>>>       
>>>> If declaring the encoding in DESCRIPTION doesn't solve the problem, I'd be happy to take a look at the package.
>>>>         
>>> That's a great offer! I'd be very happy if you could take a look.
>>> You can find the source at http://r-forge.r-project.org/projects/tripler/, a tar.gz is attached as well.
>>>       
>> I got the same error as you.  It looks as though iconv has trouble with the way some characters are encoded in your file.  For example, on line 893, you have a u-umlaut encoded as EF BF BD.  According the the UTF-8 tables at http://www.utf8-chartable.de/unicode-utf8-table.pl?start=65280, that encodes a question mark in a diamond, "REPLACEMENT CHARACTER".  There's no corresponding character in the standard Windows latin1 encoding, so conversion fails.  Firefox can display the funny question mark, but it doesn't display the u-umlaut as you intended, so I think this is an error in your file.
>>
>> A way to find all such errors is as follows:  read the file as utf-8, then use the iconv() function in R to convert it to latin1.  When I do that, I get NA on lines 893 and 953, which are displayed to me as
>>
>> [1] "\t# im latenten Fall: die Error variance erst am Ende berechnen (d.h., alle error componenten ???ber alle Gruppen mitteln, die unter NUll auf Null setzen, dann addieren)"
>> [2] "\t\t# TODO: ???berpr???fen!"    
>> We might be able to make the error message in the package installer more informative (e.g. giving the line number that failed).  I'll look into that.
>>
>> Duncan Murdoch
>>
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cbeleites at units.it  Sat Feb 27 18:20:58 2010
From: cbeleites at units.it (Claudia Beleites)
Date: Sat, 27 Feb 2010 18:20:58 +0100
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for Proposals
	-
In-Reply-To: <19333.23807.803943.487024@ron.nulle.part>
References: <19332.40527.796777.558666@ron.nulle.part>	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>	<19332.43714.30266.880554@ron.nulle.part>	<19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>	<4B84FAC1.80409@sciviews.org>
	<19333.23807.803943.487024@ron.nulle.part>
Message-ID: <hmbkac$bs3$1@dough.gmane.org>

May I ask for a bit of help?

I'd like to participate with my hyperSpec project. I set up a proposal page in 
the wiki 
[http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010:hyperspec].

hyperSpec is about handling spectroscopic (hyperspectral) data in R. It is thus 
a project that is aimed at a rather specific group of R users - far less broad 
audience than the other projects listed there.

Is it OK if I have that project in that GSoC 2010 list?

I'd really appreciate comments!

Thanks,

Claudia






Dirk Eddelbuettel wrote:
> On 24 February 2010 at 11:09, Philippe Grosjean wrote:
> | I have created the "projects" subsection in "developers". The Google 
> | Summer of Code 2010 is at 
> | http://rwiki.sciviews.org/doku.php?id=developers:projects:googlesummer2010
> 
> We dediced to make this 
> 
>    http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010
> 
> to stick with the common 'GSoC' acronym.  So go ahead and submit ideas!
> 
> Dirk
> 


-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From edd at debian.org  Sat Feb 27 18:35:41 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 27 Feb 2010 11:35:41 -0600
Subject: [Rd] [SoC] R and Google Summer of Code 2010: Call for
	Proposals	-
In-Reply-To: <hmbkac$bs3$1@dough.gmane.org>
References: <19332.40527.796777.558666@ron.nulle.part>
	<f8e6ff051002232006n5bf49d38wce7703010b15c0b1@mail.gmail.com>
	<19332.43714.30266.880554@ron.nulle.part>
	<19332.63070.481291.275065@ridcully.stat.uni-muenchen.de>
	<4B84FAC1.80409@sciviews.org>
	<19333.23807.803943.487024@ron.nulle.part>
	<hmbkac$bs3$1@dough.gmane.org>
Message-ID: <19337.22509.221848.649210@ron.nulle.part>


On 27 February 2010 at 18:20, Claudia Beleites wrote:
| May I ask for a bit of help?
| 
| I'd like to participate with my hyperSpec project. I set up a proposal page in 
| the wiki 
| [http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010:hyperspec].
| 
| hyperSpec is about handling spectroscopic (hyperspectral) data in R. It is thus 
| a project that is aimed at a rather specific group of R users - far less broad 
| audience than the other projects listed there.
| 
| Is it OK if I have that project in that GSoC 2010 list?

Of course! You had not linked to it from the overview page at

   http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010

which I just corrected. The proposal looks great -- if R gets once again
accepted there will be a discussion and voting period for all of us to find
the proposals with the most merit given our allocation.  
 
| I'd really appreciate comments!

Well as Rcpp (co-)maintainer, I would of course suggest that you use Rcpp to
interface the C++ libraries :)

Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From jel+r at cs.uni-magdeburg.de  Sat Feb 27 19:55:33 2010
From: jel+r at cs.uni-magdeburg.de (Jens Elkner)
Date: Sat, 27 Feb 2010 19:55:33 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <4B88E35F.3010805@biostat.ku.dk>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>
	<4B82753B.2090006@biostat.ku.dk>
	<20100227023844.GA1272@trex.cs.uni-magdeburg.de>
	<4B88E35F.3010805@biostat.ku.dk>
Message-ID: <20100227185533.GA3602@trex.cs.uni-magdeburg.de>

On Sat, Feb 27, 2010 at 10:18:23AM +0100, Peter Dalgaard wrote:
> Jens Elkner wrote:
...
> >Yes - still a little bit big (most are usually not bigger than 50K, but
> >some exceptions hav 80..100K), but much better than 2M and sufficient
> >IMHO, too.
...
> I suppose I should put it somewhere for others to play with. It should 

Yes, good idea!

> be possible to reduce the number of colour layers and get down to  the 
> 50 K or so, but it is quite fiddly. I found that if you put inkscape in 
> "outline mode", then you can manipulate the Bezier curves directly and 
> get rid of the artifacts from the bitmap tracing. Currently, it has 
> about 64 paths of about 60 control points each, so it might be a better 
> strategy to start over with a coarser trace.

Well, as said, for my taste it is good enough. However, to get a real
small good one, I think it should be made from scratch and not based
on a scanned pixmap. BTW: What do you think about Baptiste's work (
http://www.maths.lancs.ac.uk/~rowlings/Graphics/Logo/R/logos.svg )?
IMHO looks cool, sharp, modern and simple enough to be used in any 
vector drawing program efficiently.
  
> >http://dev.cs.uni-magdeburg.de/lnf/i386/R/LNFr-desktop/ ) -> looks
> >update-desktop-database ; update-mime-database $instdir/share/mime
...
> Any chance of a couple of screenshots?
  
Yes, can make them on monday at work. @home I have to use a macbook
right now :( (my Linux WS died few month ago and 've had not yet the time
to look for a new motherboard and stuff ...)

> >Currently the last thing I'm thinking about is: "with '-g Tk' start
> >Rcmdr if available, otherwise tkStartGUI()". Would you mind to integrate
> >that into the official R tree? I know, its more or less easy to modify
> >library/tcltk/exec/Tk-frontend.R, however admins as well as package
> >creators/maintainers don't like, when one package modifies the content
> >of another one and have to keep track of changes, i.e. need to do more
> >or less "sophisticated" things, when they get removed ...
> 
> This sounds a bit far-reaching. The "-g Tk" route is a bit of a kludge 
> already, so everything is in for a review and I'd rather not build 
> things on top of a crumbling foundation.

Yes, actually I though about something generic as well: e.g. an etc/gui
directory where everybody may put the startup files for the GUI like
  etc/gui/
          Tk.R
          Rcmdr.R
          ...

So "R -g {Tk|Rcmdr}" would be valid ... However, AFAIK these are the
only GUIs, which can be lunched from R. All others are embedding R, so
the add. work might not be worth it.
  
> You might be able to do something with environment variables and 
> .Rprofile files instead.

That's not an option for desktop integration - having to manipulate each
user's profile is certainly a really bad thing. 

> (I was about to suggest 'R -e something' but 
> Rcmdr refuses to start in a non-interactive session).

Yes,   echo "library('Rcmdr')" | R --interactive...   doesn't work
either, because it than goes crazy (looks like a kind of BATCH mode).

BTW OT: wondering why one just can't pipe its script into R. IMHO it
should be possible and after having the code processed it should stay in
interactive mode (giving an R prompt) so that one may continue to work.
Only if CMD BATCH or something like that is given, it should auto exit.
The "Fatal error: you must specify '--save', '--no-save' or '--vanilla'"
is IMHO completely non-sense, since everybody is able to start simply
'R' (i.e. no option at all) and enter stuff. Actually normal progs
don't really care, where the input comes from ...

Anyway, will be back on monday with some screenshots ...

Regards,
jel.
-- 
Otto-von-Guericke University     http://www.cs.uni-magdeburg.de/
Department of Computer Science   Geb. 29 R 027, Universitaetsplatz 2
39106 Magdeburg, Germany         Tel: +49 391 67 12768


From baptiste.auguie at googlemail.com  Sat Feb 27 20:23:17 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sat, 27 Feb 2010 20:23:17 +0100
Subject: [Rd] R logo as SVG ?
In-Reply-To: <20100227185533.GA3602@trex.cs.uni-magdeburg.de>
References: <20100220171608.GA17050@trex.cs.uni-magdeburg.de>
	<4B80275C.8080806@biostat.ku.dk>
	<a695148b1002201033q31bdc708o17b1c8bd8e2760ae@mail.gmail.com>
	<4B80313D.1000909@biostat.ku.dk>
	<20100220195620.GA17109@trex.cs.uni-magdeburg.de>
	<4B82753B.2090006@biostat.ku.dk>
	<20100227023844.GA1272@trex.cs.uni-magdeburg.de>
	<4B88E35F.3010805@biostat.ku.dk>
	<20100227185533.GA3602@trex.cs.uni-magdeburg.de>
Message-ID: <de4e29f51002271123s2ae805cex8b6d71d98ba62d8f@mail.gmail.com>

You got the first two letters right, but it's actually *Barry*'s work!

As a matter of personal taste, I like the 3D rendering of the current
logo; my only wish would be for an open source to reproduce it.

baptiste

On 27 February 2010 19:55, Jens Elkner <jel+r at cs.uni-magdeburg.de> wrote:

> BTW: What do you think about Baptiste's work (
> http://www.maths.lancs.ac.uk/~rowlings/Graphics/Logo/R/logos.svg )?
> IMHO looks cool, sharp, modern and simple enough to be used in any
> vector drawing program efficiently.


From valerop at uv.es  Sat Feb 27 20:53:09 2010
From: valerop at uv.es (Pedro Valero-Mora)
Date: Sat, 27 Feb 2010 20:53:09 +0100
Subject: [Rd] Deadline for Special issue of the JSS on Graphical User
 Interfaces for R
Message-ID: <4B897825.8050509@uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100227/9635dba4/attachment.pl>

From murdoch at stats.uwo.ca  Sat Feb 27 23:59:44 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 27 Feb 2010 17:59:44 -0500
Subject: [Rd] Error on Windows build: "unable to re-encode"
In-Reply-To: <D6927217-9163-4FAD-A16B-F3441F4FA8B3@gmx.net>
References: <FA1618C2-22BD-437F-BE7E-196725C8AD6C@gmx.net>	<4B87D474.5060207@stats.uwo.ca>	<9DD49155-D72B-4CBA-919D-824365BF4707@gmx.net>	<4B8806F3.9060409@stats.uwo.ca>
	<D6927217-9163-4FAD-A16B-F3441F4FA8B3@gmx.net>
Message-ID: <4B89A3E0.3090901@stats.uwo.ca>

On 27/02/2010 2:38 AM, Felix Sch?nbrodt wrote:
> Thanks for your help - that was the solution (easy enough to remove these two characters - they've been in only comments anyway).
> Fortunately, the DECRIPTION file accepts umlauts, as in my second name. The problem was only in the source file.

I've changed R-devel so that it now gives a warning instead of an error 
in such cases.  The warning reports the line numbers of the bad 
characters, and the installer converts them to <xx>-style hex codes.  If 
you've used them in variable names this will likely lead to a syntax 
error; in string literals it will look ugly but should be accepted.  In 
comments it will look ugly, but comments aren't normally saved, so they 
won't really matter there.

Duncan Murdoch

> 
> Felix
> 
> 
> Am 26.02.2010 um 18:37 schrieb Duncan Murdoch:
> 
>> On 26/02/2010 11:05 AM, Felix Sch?nbrodt wrote:
>>> Hi Duncan,
>>>
>>> I now declared the endcoding in the DESCRIPTION to UTF-8 (and all files are encoded in that way, too). As my last name is "Sch?nbrodt", I'd be happy to see it that way in the package ;-)
>>> However, it still doesn't build on Windows (but works on Mac and Linux). 
>>> Unfortunately I cannot build the Windows packages myself (I work on a Mac), but the win-builder by Uwe Ligges still shows the same error ...
>>>
>>>> If declaring the encoding in DESCRIPTION doesn't solve the problem, I'd be happy to take a look at the package.
>>> That's a great offer! I'd be very happy if you could take a look.
>>> You can find the source at http://r-forge.r-project.org/projects/tripler/, a tar.gz is attached as well.
>>
>> I got the same error as you.  It looks as though iconv has trouble with the way some characters are encoded in your file.  For example, on line 893, you have a u-umlaut encoded as EF BF BD.  According the the UTF-8 tables at http://www.utf8-chartable.de/unicode-utf8-table.pl?start=65280, that encodes a question mark in a diamond, "REPLACEMENT CHARACTER".  There's no corresponding character in the standard Windows latin1 encoding, so conversion fails.  Firefox can display the funny question mark, but it doesn't display the u-umlaut as you intended, so I think this is an error in your file.
>>
>> A way to find all such errors is as follows:  read the file as utf-8, then use the iconv() function in R to convert it to latin1.  When I do that, I get NA on lines 893 and 953, which are displayed to me as
>>
>> [1] "\t# im latenten Fall: die Error variance erst am Ende berechnen (d.h., alle error componenten ???ber alle Gruppen mitteln, die unter NUll auf Null setzen, dann addieren)"
>> [2] "\t\t# TODO: ???berpr???fen!"    
>> We might be able to make the error message in the package installer more informative (e.g. giving the line number that failed).  I'll look into that.
>>
>> Duncan Murdoch
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From taylor.russ at gmail.com  Sun Feb 28 16:53:52 2010
From: taylor.russ at gmail.com (rt)
Date: Sun, 28 Feb 2010 09:53:52 -0600
Subject: [Rd] Compiling R on Linux with SunStudio 12.1: "wide-character
	type" problems
Message-ID: <d6243f3f1002280753k193b5c58s5ab66b00f8078fc1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100228/83b6b851/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sun Feb 28 18:45:33 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 28 Feb 2010 18:45:33 +0100
Subject: [Rd] build, data and vignettes
In-Reply-To: <20100227102710.6ed6e4d0@absentia>
References: <e780c0971002241205t2f5c8e5gb0c3eb3110406a0d@mail.gmail.com>	<alpine.LFD.2.00.1002260650300.24621@gannet.stats.ox.ac.uk>	<e780c0971002260744x311159f2x7bd7264a9e97a8ff@mail.gmail.com>	<e780c0971002260745q44c2ed28ta1a7805e58cdab14@mail.gmail.com>	<4B87F0BE.8040804@statistik.tu-dortmund.de>
	<20100227102710.6ed6e4d0@absentia>
Message-ID: <4B8AABBD.7020807@statistik.tu-dortmund.de>



On 27.02.2010 03:27, Berwin A Turlach wrote:
> G'day Uwe,
>
> On Fri, 26 Feb 2010 17:03:10 +0100
> Uwe Ligges<ligges at statistik.tu-dortmund.de>  wrote:
>
>> R CMD check executes the R code in the vignettes and checks if that
>> works, and it checks if the PDFs are available. It does not check if
>> it can build the vignettes, because that is only necessary on the
>> maintainer's machine since the PDFs are shipped with the (built)
>> source package.
>
> Are you implying that "R CMD check" has reverted to its pre-2.6.0
> behaviour?  If I remember correctly, for R versions before 2.6.0  "R
> CMD check" did not attempt to build the vignette, with version 2.6.0 it
> started to do so.  The relvant NEWS entry is:
>
>      o	R CMD check now (by default) attempts to latex the
>      vignettes rather than just weave and tangle them: this will give a
>      NOTE if there are latex errors.


Ah, thanks for the correction, Berwin. I am living in the past, obviously.

Uwe




> Cheers,
>
> 	Berwin


From cbeleites at units.it  Sun Feb 28 19:31:42 2010
From: cbeleites at units.it (Claudia Beleites)
Date: Sun, 28 Feb 2010 19:31:42 +0100
Subject: [Rd] dots for sample
Message-ID: <4B8AB68E.2090404@units.it>

Dear R-Developers,

could 'sample' gain a ... argument?

As a convenience function, I added a sample Method to my hyperSpec 
class. This function however has a flag indicating whether the results 
should be returned directly as a hyperSpec object or rather as indices 
that give a random sample.

For the moment, I use SetGeneric to add the dots argument, but this of 
course gives a warning that the base function sample is overwritten (and 
my colleagues are almost as scared of warnings as of errors...)

Thanks,

Claudia



-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Valerio 2
I-34127 Trieste
ITALY

email: cbeleites at units.it
phone: +39 (0 40) 5 58-34 68


From Hoptman at NKI.RFMH.ORG  Sun Feb 28 23:58:39 2010
From: Hoptman at NKI.RFMH.ORG (Hoptman, Matthew)
Date: Sun, 28 Feb 2010 17:58:39 -0500
Subject: [Rd] Problem with gsl package
Message-ID: <2586A1048152BE4D861E64A98700AD4204E76425@nki-mail.nki.rfmh.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100228/11a53aad/attachment.pl>

