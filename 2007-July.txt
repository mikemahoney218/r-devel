From Bill.Venables at csiro.au  Mon Jul  2 09:23:27 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Mon, 2 Jul 2007 17:23:27 +1000
Subject: [Rd] termplot with uniform y-limits
Message-ID: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>

Does anyone have, or has anyone ever considered making, a version of
'termplot' that allows the user to specify that all plots should have
the same y-limits?

This seems a natural thing to ask for, as the plots share a y-scale.  If
you don't have the same y-axes you can easily misread the comparative
contributions of the different components. 

Notes: the current version of termplot does not allow the user to
specify ylim.  I checked.

	  the plot tools that come with mgcv do this by default.  Thanks
Simon.


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                         +61 4 8819 4402
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/


From ripley at stats.ox.ac.uk  Mon Jul  2 11:55:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Mon, 2 Jul 2007 10:55:07 +0100 (GMT Daylight Time)
Subject: [Rd] termplot with uniform y-limits
In-Reply-To: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>
Message-ID: <Pine.WNT.4.64.0707021050260.3632@Petrel>

Is the attached the sort of thing you are looking for?
It allows ylim to be specified, including as "common".

On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Does anyone have, or has anyone ever considered making, a version of
> 'termplot' that allows the user to specify that all plots should have
> the same y-limits?
>
> This seems a natural thing to ask for, as the plots share a y-scale.  If
> you don't have the same y-axes you can easily misread the comparative
> contributions of the different components.
>
> Notes: the current version of termplot does not allow the user to
> specify ylim.  I checked.
>
> 	  the plot tools that come with mgcv do this by default.  Thanks
> Simon.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Bill.Venables at csiro.au  Mon Jul  2 12:35:32 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Mon, 2 Jul 2007 20:35:32 +1000
Subject: [Rd] termplot with uniform y-limits
References: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>
	<Pine.WNT.4.64.0707021050260.3632@Petrel>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67FB2@exqld2-bne.nexus.csiro.au>

Precisely.  Thanks Brian.

I did do something like this but not nearly so elegantly.

I suggest this become the standard version in the next release.  I can't
see that it can break any existing code.  It's a pity now we can't make
ylim = "common" the default.

Regards,
Bill V. 


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                         +61 4 8819 4402
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk] 
Sent: Monday, 2 July 2007 7:55 PM
To: Venables, Bill (CMIS, Cleveland)
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] termplot with uniform y-limits

Is the attached the sort of thing you are looking for?
It allows ylim to be specified, including as "common".

On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Does anyone have, or has anyone ever considered making, a version of
> 'termplot' that allows the user to specify that all plots should have
> the same y-limits?
>
> This seems a natural thing to ask for, as the plots share a y-scale.
If
> you don't have the same y-axes you can easily misread the comparative
> contributions of the different components.
>
> Notes: the current version of termplot does not allow the user to
> specify ylim.  I checked.
>
> 	  the plot tools that come with mgcv do this by default.  Thanks
> Simon.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jul  2 13:11:19 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Jul 2007 12:11:19 +0100 (BST)
Subject: [Rd] termplot with uniform y-limits
In-Reply-To: <B998A44C8986644EA8029CFE6396A924B67FB2@exqld2-bne.nexus.csiro.au>
References: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>
	<Pine.WNT.4.64.0707021050260.3632@Petrel>
	<B998A44C8986644EA8029CFE6396A924B67FB2@exqld2-bne.nexus.csiro.au>
Message-ID: <Pine.LNX.4.64.0707021208280.4748@gannet.stats.ox.ac.uk>

On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Precisely.  Thanks Brian.
>
> I did do something like this but not nearly so elegantly.
>
> I suggest this become the standard version in the next release.  I can't

Yes, that was the intention (to go into R-devel).
(It was also my intention to attach as plain text, but my Windows mailer 
seems to have defeated that.)

> see that it can break any existing code.  It's a pity now we can't make
> ylim = "common" the default.

I suspect we could if I allow a way to get the previous behaviour 
(ylim="free", I think).

Brian

> Regards,
> Bill V.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, 2 July 2007 7:55 PM
> To: Venables, Bill (CMIS, Cleveland)
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] termplot with uniform y-limits
>
> Is the attached the sort of thing you are looking for?
> It allows ylim to be specified, including as "common".
>
> On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:
>
>> Does anyone have, or has anyone ever considered making, a version of
>> 'termplot' that allows the user to specify that all plots should have
>> the same y-limits?
>>
>> This seems a natural thing to ask for, as the plots share a y-scale.
> If
>> you don't have the same y-axes you can easily misread the comparative
>> contributions of the different components.
>>
>> Notes: the current version of termplot does not allow the user to
>> specify ylim.  I checked.
>>
>> 	  the plot tools that come with mgcv do this by default.  Thanks
>> Simon.
>>
>>
>> Bill Venables
>> CSIRO Laboratories
>> PO Box 120, Cleveland, 4163
>> AUSTRALIA
>> Office Phone (email preferred): +61 7 3826 7251
>> Fax (if absolutely necessary):  +61 7 3826 7304
>> Mobile:                         +61 4 8819 4402
>> Home Phone:                     +61 7 3286 7700
>> mailto:Bill.Venables at csiro.au
>> http://www.cmis.csiro.au/bill.venables/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Bill.Venables at csiro.au  Mon Jul  2 13:39:50 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Mon, 2 Jul 2007 21:39:50 +1000
Subject: [Rd] termplot with uniform y-limits
References: <B998A44C8986644EA8029CFE6396A924B67FB1@exqld2-bne.nexus.csiro.au>
	<Pine.WNT.4.64.0707021050260.3632@Petrel>
	<B998A44C8986644EA8029CFE6396A924B67FB2@exqld2-bne.nexus.csiro.au>
	<Pine.LNX.4.64.0707021208280.4748@gannet.stats.ox.ac.uk>
Message-ID: <B998A44C8986644EA8029CFE6396A924B67FB5@exqld2-bne.nexus.csiro.au>

If anyone in R-devel is having trouble seeing the point of this, try
this little example with the new code of Brian's:

dat <- data.frame(x1=1:20, x2 = sample(1:20), y = rnorm(20)+1:20)
fm <- lm(y ~ x1+x2, dat)
par(mfrow = c(2,2))
termplot(fm, se = T, partial.resid = T)
termplot(fm, se = T, partial.resid = T, ylim = "common") 


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                         +61 4 8819 4402
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Monday, 2 July 2007 9:11 PM
To: Venables, Bill (CMIS, Cleveland)
Cc: r-devel at stat.math.ethz.ch
Subject: RE: [Rd] termplot with uniform y-limits

On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Precisely.  Thanks Brian.
>
> I did do something like this but not nearly so elegantly.
>
> I suggest this become the standard version in the next release.  I
can't

Yes, that was the intention (to go into R-devel).
(It was also my intention to attach as plain text, but my Windows mailer

seems to have defeated that.)

> see that it can break any existing code.  It's a pity now we can't
make
> ylim = "common" the default.

I suspect we could if I allow a way to get the previous behaviour 
(ylim="free", I think).

Brian

> Regards,
> Bill V.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, 2 July 2007 7:55 PM
> To: Venables, Bill (CMIS, Cleveland)
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] termplot with uniform y-limits
>
> Is the attached the sort of thing you are looking for?
> It allows ylim to be specified, including as "common".
>
> On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:
>
>> Does anyone have, or has anyone ever considered making, a version of
>> 'termplot' that allows the user to specify that all plots should have
>> the same y-limits?
>>
>> This seems a natural thing to ask for, as the plots share a y-scale.
> If
>> you don't have the same y-axes you can easily misread the comparative
>> contributions of the different components.
>>
>> Notes: the current version of termplot does not allow the user to
>> specify ylim.  I checked.
>>
>> 	  the plot tools that come with mgcv do this by default.  Thanks
>> Simon.
>>
>>
>> Bill Venables
>> CSIRO Laboratories
>> PO Box 120, Cleveland, 4163
>> AUSTRALIA
>> Office Phone (email preferred): +61 7 3826 7251
>> Fax (if absolutely necessary):  +61 7 3826 7304
>> Mobile:                         +61 4 8819 4402
>> Home Phone:                     +61 7 3286 7700
>> mailto:Bill.Venables at csiro.au
>> http://www.cmis.csiro.au/bill.venables/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jul  2 14:22:52 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon,  2 Jul 2007 14:22:52 +0200 (CEST)
Subject: [Rd] boxplot and bxp do not respect xlim by default (PR#9754)
Message-ID: <20070702122252.516B348A89@slim.kubism.ku.dk>

Note that ?bxp quite carefully says which graphical pars it does and does 
not accept, and 'xlim' is one it does not accept.  So this is a wish, not 
a bug.

The easy part is to allow it to accept 'xlim' is specified.  The harder 
part is to find a good default of xlim in general.  Steve's suggestion is 
not good if the boxes differ in size or if at = c(0, 10:15), for example.
It seems to me that 'at' would normally be used with add=T, so I don't 
think we need to do this well (and the user will always be able to set 
'xlim').


I am about to commit an improved version for R-devel.

On Tue, 26 Jun 2007, murdoch at stats.uwo.ca wrote:

> On 6/26/2007 8:16 AM, s.ellison at lgc.co.uk wrote:
>> Full_Name: Steve Ellison
>> Version: 2.4.1
>> OS: Windows, Linux
>> Submission from: (NULL) (194.73.101.157)
>>
>>
>> bxp() allows specifcation of box locations with at=, but neither adjusts xlim=
>> to fit at nor does it respect xlim provided explicitly.
>>
>> This is because bxp() now includes explicit xlim as c(0.5, n+0.5), without
>> checking for explicitly supplied xlim (or ylim if horizontal).
>>
>> This also prevents simple added plots (eg if add=T, with at=(1:n)+0.5, the last
>> box is partly off the plot.
>>
>> The 'offending' code is in bxp:
>>     if (!add) {
>>         plot.new()
>>         if (horizontal)
>>             plot.window(ylim = c(0.5, n + 0.5), xlim = ylim,
>>                 log = log, xaxs = pars$yaxs)
>>         else plot.window(xlim = c(0.5, n + 0.5), ylim = ylim,
>>             log = log, yaxs = pars$yaxs)
>>     }
>>
>> Suggested fix:
>>    if (!add) {
>>         plot.new()
>> 	bxp.limits <- if(!is.null(at)) {
>>               c(at[1]-(at[2]-at[1])/2, at[n]+(at[n]-at[n-1])/2 )
>>            } else {
>>               c(0.5, n + 0.5)
>>            }
>>         if (horizontal)
>>             plot.window(ylim = if(is.null(pars$xlim)) bxp.limits else
>> pars$xlim,
>>                       xlim = ylim, log = log, xaxs = pars$yaxs)
>>         else plot.window(xlim = if(is.null(pars$xlim)) bxp.limits else
>> pars$xlim,
>>                       ylim = ylim, log = log, yaxs = pars$yaxs)
>>     }
>>
>>
>> This retains the current defaults for xlim with at unspecified but allows
>> explicit specification of xlim. (which is the grouping level axis whether
>> horizontal or vertical).
>
> But it fails in a few other cases:  if the user sets the widths, this
> doesn't respect that setting; if the user specifies the location of one
> boxplot (so length(at) == 1) it fails when it tries to access at[2].
>
> This is a somewhat tricky problem, that needs more careful thought than
> I have time for right now, so I'll leave it for someone else (or for
> myself in a less busy future, which may exist in some alternate universe).
>
> What I'd suggest you do in the short term is simply to set up the plot
> axes the way you want before calling bxp, then call it with add=TRUE.
>
> Duncan Murdoch
>
>>
>> I've tested the above as far as producing a modified bxp and plotting a boxplot
>> object, but have not tried calling direct from boxplot. boxplot() should,
>> however, not need modification as xlim and ylim are, I believe, passed via the
>> namedargs list in the bxp call.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Robert.McGehee at geodecapital.com  Mon Jul  2 15:27:22 2007
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon, 2 Jul 2007 09:27:22 -0400
Subject: [Rd] saving objects with embedded environments
References: <EEBC169715EB8C438D3C9283AF0F201C17C830@MSGBOSCLM2WIN.DMN1.FMR.COM>
	<66f3bd910706291644s6db3b3a9ncd1bd075ceec3553@mail.gmail.com>
Message-ID: <EEBC169715EB8C438D3C9283AF0F201C17C834@MSGBOSCLM2WIN.DMN1.FMR.COM>

Thanks for this. So at the risk of treading out too deep into unfamiliar
water, one concern is that if I run 'lm' within a function and then the
function exits, am I still (perhaps unnecessarily) keeping a copy of the
function environment and the associated data? It does not seem that
'update' even works after I exit the function, so it's not clear to me
what help saving the environment and a copy of all of its data is (see
example below).

> B <- data.frame(y=1:100, x=rnorm(100))
> FUN <- function(B) lm(y ~ x, data=B)
> m <- FUN(B)
> rm(B)
## update doesn't find object 'B' in function environment (so why store
the environment?)
> update(m, y ~ 1)  
Error in inherits(x, "data.frame") : object "B" not found

## However, there is a copy of object 'B' saved anyway, even
## after removing it from the global environment and exiting the
function
> dim(get("B", envir=attr(m$terms, ".Environment")))
[1] 100   2

For my purposes all works well now. I brought this up only as one can
quickly run out of memory if data is unnecessarily kept around after
with large models. Anecdotally, before isolating this issue I would
crash my snow/MPI session (followed by R) when trying to transfer these
'lm' and 'lm'-like objects with embedded environments. If I did not
distribute the processing, then I found that I would rather quickly use
up all 24GB of my computer's memory and swap space after repeated calls.

Thanks,
Robert

-----Original Message-----
From: Roger Peng [mailto:rdpeng at gmail.com] 
Sent: Friday, June 29, 2007 7:44 PM
To: McGehee, Robert
Cc: R-devel
Subject: Re: [Rd] saving objects with embedded environments

I believe this is intentional.  See ?serialize.  When lm() is called
in a function, the environment is saved in case the resulting fitted
model object needs to be updated, for example, with update().

if you don't want the linear model object, you might try just saving
the relevant objects to a separate list rather than try to delete
everything that is irrelevant from the 'lm' object.

-roger

On 6/28/07, McGehee, Robert <Robert.McGehee at geodecapital.com> wrote:
> Hello,
> I have been running linear regressions on large data sets. As 'lm'
saves
> a great deal of extraneous (for me) data including the residuals,
> fitted.values, model frame, etc., I generally set these to NULL within
> the object before saving off the model to a file.
>
> In the below example, however, I have found that depending on whether
or
> not I run 'lm' within another function or not, the entire function
> environment is saved off with the file. So, even while object.size and
> all.equal report that both 'lm's are equal and of small size, one
saves
> as a 24MB file and the other as 646 bytes. These seems to be because
in
> the first example the function environment is saved in attr(x1$terms,
> ".Environment") and takes up all 24MB of space.
>
> Anyway, I think this is a bug, or if nothing else very undesirable
(that
> an object reported to be 0.5kb takes up 24MB). There also seems to be
> some inconsistency on how environments are saved depending on if it is
> the global environment or not, though I'm not familiar enough with
> environments to know if this was intentional. Comments are
appreciated.
>
> Thanks,
> Robert
>
> ##################################################################
> testEq <- function(B) {
>     x <- lm(y ~ x1+x2+x3, data=B, model=FALSE)
>     x$residuals <- x$effects <- x$fitted.values <- x$qr$qr <- NULL
>     x
> }
>
> N <- 900000
> B <- data.frame(y=rnorm(N)+1:N, x1=rnorm(N)+1:N, x2=rnorm(N)+1:N,
> x3=rnorm(N)+1:N)
> x1 <- testEq(B)
> x2 <- lm(y ~ x1+x2+x3, data=B, model=FALSE)
> x2$residuals <- x2$effects <- x2$fitted.values <- x2$qr$qr <- NULL
>
> all.equal(x1, x2) ## TRUE
> object.size(x1)  ## 5112
> object.size(x2)  ## 5112
> save(x1, file="x1.RData")
> save(x2, file="x2.RData")
> file.info("x1.RData")$size ## 24063852 bytes
> file.info("x2.RData")$size ## 646 bytes
>
> > R.version
>                _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>
>
> Robert McGehee, CFA
> Quantitative Analyst
> Geode Capital Management, LLC
> One Post Office Square, 28th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee at geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for
us...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Mon Jul  2 16:15:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Jul 2007 15:15:16 +0100 (BST)
Subject: [Rd] boxplot and bxp do not respect xlim by default (PR#9754)
In-Reply-To: <20070702122252.516B348A89@slim.kubism.ku.dk>
References: <20070702122252.516B348A89@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0707021512320.11004@gannet.stats.ox.ac.uk>

On Mon, 2 Jul 2007, ripley at stats.ox.ac.uk wrote:

> Note that ?bxp quite carefully says which graphical pars it does and does
> not accept, and 'xlim' is one it does not accept.  So this is a wish, not
> a bug.
>
> The easy part is to allow it to accept 'xlim' is specified.  The harder
> part is to find a good default of xlim in general.  Steve's suggestion is
> not good if the boxes differ in size or if at = c(0, 10:15), for example.
> It seems to me that 'at' would normally be used with add=T, so I don't
> think we need to do this well (and the user will always be able to set
> 'xlim').

I should have added that some code assumes the current default for xlim 
even when 'at' is specified, including the last example in boxplot.

Other cases where Steve's suggestion was wrong are when 'at' is not 
sorted, and when there is a log x axis (and there the previous default is 
also inadequate).


>
>
> I am about to commit an improved version for R-devel.
>
> On Tue, 26 Jun 2007, murdoch at stats.uwo.ca wrote:
>
>> On 6/26/2007 8:16 AM, s.ellison at lgc.co.uk wrote:
>>> Full_Name: Steve Ellison
>>> Version: 2.4.1
>>> OS: Windows, Linux
>>> Submission from: (NULL) (194.73.101.157)
>>>
>>>
>>> bxp() allows specifcation of box locations with at=, but neither adjusts xlim=
>>> to fit at nor does it respect xlim provided explicitly.
>>>
>>> This is because bxp() now includes explicit xlim as c(0.5, n+0.5), without
>>> checking for explicitly supplied xlim (or ylim if horizontal).
>>>
>>> This also prevents simple added plots (eg if add=T, with at=(1:n)+0.5, the last
>>> box is partly off the plot.
>>>
>>> The 'offending' code is in bxp:
>>>     if (!add) {
>>>         plot.new()
>>>         if (horizontal)
>>>             plot.window(ylim = c(0.5, n + 0.5), xlim = ylim,
>>>                 log = log, xaxs = pars$yaxs)
>>>         else plot.window(xlim = c(0.5, n + 0.5), ylim = ylim,
>>>             log = log, yaxs = pars$yaxs)
>>>     }
>>>
>>> Suggested fix:
>>>    if (!add) {
>>>         plot.new()
>>> 	bxp.limits <- if(!is.null(at)) {
>>>               c(at[1]-(at[2]-at[1])/2, at[n]+(at[n]-at[n-1])/2 )
>>>            } else {
>>>               c(0.5, n + 0.5)
>>>            }
>>>         if (horizontal)
>>>             plot.window(ylim = if(is.null(pars$xlim)) bxp.limits else
>>> pars$xlim,
>>>                       xlim = ylim, log = log, xaxs = pars$yaxs)
>>>         else plot.window(xlim = if(is.null(pars$xlim)) bxp.limits else
>>> pars$xlim,
>>>                       ylim = ylim, log = log, yaxs = pars$yaxs)
>>>     }
>>>
>>>
>>> This retains the current defaults for xlim with at unspecified but allows
>>> explicit specification of xlim. (which is the grouping level axis whether
>>> horizontal or vertical).
>>
>> But it fails in a few other cases:  if the user sets the widths, this
>> doesn't respect that setting; if the user specifies the location of one
>> boxplot (so length(at) == 1) it fails when it tries to access at[2].
>>
>> This is a somewhat tricky problem, that needs more careful thought than
>> I have time for right now, so I'll leave it for someone else (or for
>> myself in a less busy future, which may exist in some alternate universe).
>>
>> What I'd suggest you do in the short term is simply to set up the plot
>> axes the way you want before calling bxp, then call it with add=TRUE.
>>
>> Duncan Murdoch
>>
>>>
>>> I've tested the above as far as producing a modified bxp and plotting a boxplot
>>> object, but have not tried calling direct from boxplot. boxplot() should,
>>> however, not need modification as xlim and ylim are, I believe, passed via the
>>> namedargs list in the bxp call.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From S.Ellison at lgc.co.uk  Mon Jul  2 18:49:17 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 02 Jul 2007 17:49:17 +0100
Subject: [Rd] boxplot and bxp do not respect xlim by default	(PR#9754)
Message-ID: <s6893ac1.004@tedmail2.lgc.co.uk>

Brian,

> Note that ?bxp quite carefully says which graphical pars it does and does
> not accept, and 'xlim' is one it does not accept.  
In my version at the time, bxp did not list which plot parameters it does not accept. xlim was simply not mentioned at all. I can't easily see lack of a mention as _good_ documentation of lack of acceptance when other unmentioned parameters ARE accepted and when plot.default is very clear on xlim being an allowed parameter by default. But that's pretty much academic if one adds xlim support in bxp.

> Steve's suggestion is
> not good if the boxes differ in size or if at = c(0, 10:15) [or if unordered at]
Certainly true (and I was kicking myself only shortly after posting it for exactly the same reason!). 
But the default for xlim stays much simpler if brian's next point is accepted:

>I should have added that some code assumes the current default for xlim 
>even when 'at' is specified, including the last example in boxplot.
An important point. That says one should not change the default xlim to adjust for arbitrary at. Fortunately, that makes life easier: keep the present xlim defaults while allowing allow user-specified xlim is near-trivial compared to implementing a general at-specific xlim default. 

>...and when there is a log x axis (and there the previous default is 
>also inadequate).
The log issue, ironically, perhaps IS a bug, as log is an allowed parameter on the x-axis (via log="x") and width is chosen without paying it any attention. I haven't looked closely at a required code mod, but it's adjustable with user-specified boxwex. Perhaps documenting the fact of a poor default and suggesting manual boxwex might be sufficient remedy? 

If I understand the discussion so far, though, the "requirement" for this bugfix/wishfix would go something like this:

i) if at is unspecified, at=1:n; if specified, it is respected. (true now)

ii) if xlim is unspecified, xlim=c(0.5,  n+0.5); if it is specified, it is respected for add=F. (only adds respect for specified xlim)

iii) For add=T, xlim should be ignored if specified (silently? with warning?). (Currently silently ignored)

iv) behaviour on log="x" should be noted in the help.

The above are fairly trivial to implement and document, as such things go... I'd be happy to give it a shot.


Steve Ellison
 


>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 02/07/2007 15:15:16 >>>
On Mon, 2 Jul 2007, ripley at stats.ox.ac.uk wrote:

So this is a wish, not
> a bug.
>
> The easy part is to allow it to accept 'xlim' is specified.  The harder
> part is to find a good default of xlim in general. , for example.
> It seems to me that 'at' would normally be used with add=T, so I don't
> think we need to do this well (and the user will always be able to set
> 'xlim').

I should have added that some code assumes the current default for xlim 
even when 'at' is specified, including the last example in boxplot.

Other cases where Steve's suggestion was wrong are when 'at' is not 
sorted, and when there is a log x axis (and there the previous default is 
also inadequate).


>
>
> I am about to commit an improved version for R-devel.
>
> On Tue, 26 Jun 2007, murdoch at stats.uwo.ca wrote:
>
>> On 6/26/2007 8:16 AM, s.ellison at lgc.co.uk wrote:
>>> Full_Name: Steve Ellison
>>> Version: 2.4.1
>>> OS: Windows, Linux
>>> Submission from: (NULL) (194.73.101.157)
>>>
>>>
>>> bxp() allows specifcation of box locations with at=, but neither adjusts xlim=
>>> to fit at nor does it respect xlim provided explicitly.
>>>
>>> This is because bxp() now includes explicit xlim as c(0.5, n+0.5), without
>>> checking for explicitly supplied xlim (or ylim if horizontal).
>>>
>>> This also prevents simple added plots (eg if add=T, with at=(1:n)+0.5, the last
>>> box is partly off the plot.
>>>
>>> The 'offending' code is in bxp:
>>>     if (!add) {
>>>         plot.new()
>>>         if (horizontal)
>>>             plot.window(ylim = c(0.5, n + 0.5), xlim = ylim,
>>>                 log = log, xaxs = pars$yaxs)
>>>         else plot.window(xlim = c(0.5, n + 0.5), ylim = ylim,
>>>             log = log, yaxs = pars$yaxs)
>>>     }
>>>
>>> Suggested fix:
>>>    if (!add) {
>>>         plot.new()
>>> 	bxp.limits <- if(!is.null(at)) {
>>>               c(at[1]-(at[2]-at[1])/2, at[n]+(at[n]-at[n-1])/2 )
>>>            } else {
>>>               c(0.5, n + 0.5)
>>>            }
>>>         if (horizontal)
>>>             plot.window(ylim = if(is.null(pars$xlim)) bxp.limits else
>>> pars$xlim,
>>>                       xlim = ylim, log = log, xaxs = pars$yaxs)
>>>         else plot.window(xlim = if(is.null(pars$xlim)) bxp.limits else
>>> pars$xlim,
>>>                       ylim = ylim, log = log, yaxs = pars$yaxs)
>>>     }
>>>
>>>
>>> This retains the current defaults for xlim with at unspecified but allows
>>> explicit specification of xlim. (which is the grouping level axis whether
>>> horizontal or vertical).
>>
>> But it fails in a few other cases:  if the user sets the widths, this
>> doesn't respect that setting; if the user specifies the location of one
>> boxplot (so length(at) == 1) it fails when it tries to access at[2].
>>
>> This is a somewhat tricky problem, that needs more careful thought than
>> I have time for right now, so I'll leave it for someone else (or for
>> myself in a less busy future, which may exist in some alternate universe).
>>
>> What I'd suggest you do in the short term is simply to set up the plot
>> axes the way you want before calling bxp, then call it with add=TRUE.
>>
>> Duncan Murdoch
>>
>>>
>>> I've tested the above as far as producing a modified bxp and plotting a boxplot
>>> object, but have not tried calling direct from boxplot. boxplot() should,
>>> however, not need modification as xlim and ylim are, I believe, passed via the
>>> namedargs list in the bxp call.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk 
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/ 
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From murdoch at stats.uwo.ca  Mon Jul  2 23:14:53 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 02 Jul 2007 17:14:53 -0400
Subject: [Rd] R CMD build with mingw and msys (PR#9766)
In-Reply-To: <20070629115333.7407D2478B@slim.kubism.ku.dk>
References: <20070629115333.7407D2478B@slim.kubism.ku.dk>
Message-ID: <46896ACD.6010209@stats.uwo.ca>

On 29/06/2007 7:53 AM, sneumann at pubhealth.ku.dk wrote:
> Full_Name: Steffen
> Version: 2-5-0
> OS: Windows
> Submission from: (NULL) (192.124.243.162)
> 
> 
> Hi,
> 
> the R CMD build script is using 
> 
>     if($WINDOWS) {
>         ## workaround for paths in Cygwin tar
>         $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
>     }
> 
> which does not work if the build environment is a MINGW.
> I have added the patch below, 

It sounds as though you're not using the tar.exe that comes with the R 
toolset, you're using the MSYS one.  Or am I misunderstanding what 
you're doing? What does "which tar" give you? (I'm assuming MSYS 
provides "which", it's not part of the R toolset.).

I'd like the R toolset to work if someone is running in an MSYS shell, 
but I don't want to support arbitrary toolsets, it's just too much work 
to try to keep up with changes to them all.

Duncan Murdoch

> 
> Yours,
> Steffen
> 
> $ diff -u build build.orig 
> --- build       Fri Jun 29 13:50:16 2007
> +++ build.orig  Fri Jun 29 08:51:48 2007
> @@ -47,7 +47,6 @@
>  R::Vars::error("R_HOME", "R_EXE");
>  
>  my $WINDOWS = ($R::Vars::OSTYPE eq "windows");
> -my $MSYS = ( $ENV{OSTYPE} eq "msys" ); 
>  
>  my @exclude_patterns = R::Utils::get_exclude_patterns();
>  
> @@ -222,14 +221,10 @@
>      my $filepath = &file_path($startdir, $filename);
>      ## under Windows, need separate Cygwin and Windows versions of path.
>      my $origfilepath = $filepath;
> -    if ($MSYS) {
> -               ## different workwaround for MSYS
> -               $filepath =~ s+^([A-Za-z]):+/\1/+;
> -    } elsif ($WINDOWS) {
> -               ## workaround for paths in Cygwin tar
> -               $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
> +    if($WINDOWS) {
> +       ## workaround for paths in Cygwin tar
> +       $filepath =~ s+^([A-Za-z]):+/cygdrive/\1+;
>      }
> -       
>      R_system(join(" ",
>                   ("$tar chf",
>                    &shell_quote_file_path($filepath),
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at stat.berkeley.edu  Tue Jul  3 00:02:05 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 2 Jul 2007 15:02:05 -0700
Subject: [Rd] File lock mechanisms in R
Message-ID: <59d7961d0707021502i6d3d6216o791ea4467e013cfd@mail.gmail.com>

Hi,

is there a (cross-platform) file-locking mechanism available in R (or
via some package)?

I am looking for a way to have one R session lock a file for
read/write access, while being updated/modified by another R session.
This will provide me with a-poor-mans parallelization method.  It is
ok to have so called advisory looking (as in Unix), which are
non-mandatory to follow.  If not available, I'll use lock files, but
there are some potential problems in creating such in an atomic way.
Ideally I wish to have this working on all platforms.

Cheers

Henrik


From pinard at iro.umontreal.ca  Tue Jul  3 00:58:15 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Mon, 2 Jul 2007 18:58:15 -0400
Subject: [Rd] File lock mechanisms in R
In-Reply-To: <59d7961d0707021502i6d3d6216o791ea4467e013cfd@mail.gmail.com>
References: <59d7961d0707021502i6d3d6216o791ea4467e013cfd@mail.gmail.com>
Message-ID: <20070702225815.GA27775@alcyon.progiciels-bpi.ca>

[Henrik Bengtsson]

>I am looking for a way to have one R session lock a file for
>read/write access, while being updated/modified by another R session.
>This will provide me with a-poor-mans parallelization method.  It is
>ok to have so called advisory looking (as in Unix), which are
>non-mandatory to follow.  If not available, I'll use lock files, but
>there are some potential problems in creating such in an atomic way.
>Ideally I wish to have this working on all platforms.

Something which worked for me, so far, is to create a directory, and see 
if the creation succeeded or failed.  If the creation succeeded, you 
have the lock.  If it failed, something else created it and has the 
lock.  You then keep retrying after some delay.  Of course, the 
directory should not be used outside your locking protocol.

On the few platforms I used, but likely on most of them, creating 
a directory "atomically" ought to be safe.  Yet, this might be a bit 
heavy-weighted when locks are meant to be light and quick.

If you want some more sophistication, leave a file within the lock 
directory (once you successfully created it and so, acquired the lock),
telling who you are.  Destroy the file before destroying the directory 
(of course).  More typically on Unix, put in this file the id of the 
running process, so when creating the directory fails, the attempter may
look in the file, and if there is no such process running, consider the 
lock stale, and preempt it (to do this safely requires some thinking).

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From murdoch at stats.uwo.ca  Tue Jul  3 03:56:23 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 02 Jul 2007 21:56:23 -0400
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <46842286.8080402@uni-bayreuth.de>
References: <46842286.8080402@uni-bayreuth.de>
Message-ID: <4689ACC7.6010005@stats.uwo.ca>

On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
> Hi,
> 
> I noticed a minor flaw in integrate() from package stats:
> 
> Taking up arguments lower and upper from integrate(),
> 
>    if (lower ==  Inf) && (upper ==  Inf)
> 
>        or
> 
>    if (lower == -Inf) && (upper == -Inf)
> 
> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
> 
> Rather, it should return 0.

Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf 
doesn't return 1?

Duncan Murdoch

> 
> Quick fix:
> 
> ### old code ###
> ### [snip]
>     else {
>             if (is.na(lower) || is.na(upper))
>                 stop("a limit is missing")
>             if (is.finite(lower)) {
>                 inf <- 1
>                 bound <- lower
>             }
>             else if (is.finite(upper)) {
>                 inf <- -1
>                 bound <- upper
>             }
>             else {
>                 inf <- 2
>                 bound <- 0
>             }
>             wk <- .External("call_dqagi", ff, rho = environment(),
>                 as.double(bound), as.integer(inf), as.double(abs.tol),
>                 as.double(rel.tol), limit = limit, PACKAGE = "base")
>     }
> ### [snip]
> 
> ### new code  to replace the old one ###
> 
> ### [snip]
>     else {
>             if (is.na(lower) || is.na(upper))
>                 stop("a limit is missing")
> 
>             if (lower == upper){
> 
>                 wk <- list("value" = 0, "abs.error" = 0,
>                         "subdivisions" = subdivisions,
>                         "ierr" = 0 )
> 
>             } else {
>                     if (is.finite(lower)) {
>                         inf <- 1
>                         bound <- lower
>                     }
>                     else if (is.finite(upper)) {
>                             inf <- -1
>                         bound <- upper
>                     }
>                     else {
>                         inf <- 2
>                         bound <- 0
>                     }
>                     wk <- .External("call_dqagi", ff, rho = environment(),
>                             as.double(bound), as.integer(inf),
>                             as.double(abs.tol), as.double(rel.tol),
>                             limit = limit, PACKAGE = "base")
> 
>             }
>     }
> ### [snip]
> 
> Best, Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pinard at iro.umontreal.ca  Tue Jul  3 04:18:06 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Mon, 2 Jul 2007 22:18:06 -0400
Subject: [Rd] R 2.5.1 - ?factor examples, details
Message-ID: <20070703021806.GA28951@alcyon.progiciels-bpi.ca>

Hi, R people.

In ?factor, in the "Examples:" section, we see:

  ## suppose you want "NA" as a level, and to allowing missing values.
  (x <- factor(c(1, 2, "NA"), exclude = ""))
  is.na(x)[2] <- TRUE
  x  # [1] 1    <NA> NA, <NA> used because NA is a level.
  is.na(x)
  # [1] FALSE  TRUE FALSE

I'm a bit confused by this example, as I do not understand the point 
being made.  Using 'exclude = ""' or not does not change the outcome.
What is being demonstrated by this clause, here?  Isn't "NA" a mere 
string, not really related to a missing value?

It might also be some kind of linguistic problem, and I'm not a native 
English speaker.  The "and to allowing" construct sounds strange to me.  
I would expect either "and to allow" or "and allowing", but maybe I'm 
plainly missing the meaning of the statement.

Could this be clarified somehow?

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From p.dalgaard at biostat.ku.dk  Tue Jul  3 09:08:46 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 03 Jul 2007 09:08:46 +0200
Subject: [Rd] R 2.5.1 - ?factor examples, details
In-Reply-To: <20070703021806.GA28951@alcyon.progiciels-bpi.ca>
References: <20070703021806.GA28951@alcyon.progiciels-bpi.ca>
Message-ID: <4689F5FE.6020100@biostat.ku.dk>

Fran?ois Pinard wrote:
> Hi, R people.
>
> In ?factor, in the "Examples:" section, we see:
>
>   ## suppose you want "NA" as a level, and to allowing missing values.
>   (x <- factor(c(1, 2, "NA"), exclude = ""))
>   is.na(x)[2] <- TRUE
>   x  # [1] 1    <NA> NA, <NA> used because NA is a level.
>   is.na(x)
>   # [1] FALSE  TRUE FALSE
>
> I'm a bit confused by this example, as I do not understand the point 
> being made.  Using 'exclude = ""' or not does not change the outcome.
> What is being demonstrated by this clause, here?  Isn't "NA" a mere 
> string, not really related to a missing value?
>
> It might also be some kind of linguistic problem, and I'm not a native 
> English speaker.  The "and to allowing" construct sounds strange to me.  
> I would expect either "and to allow" or "and allowing", but maybe I'm 
> plainly missing the meaning of the statement.
>
> Could this be clarified somehow?
>
>   
I think this is a relic. In the olden days, there was no such thing as a 
missing character values, and factor() would behave like

 >  (x <- factor(c(1, 2, "NA"), exclude = "NA"))
[1] 1    2    <NA>
Levels: 1 2

...which was a pain when dealing with abbreviations for "noradrenalin", 
"North America", "New Alliance", "Neil Armstrong", etc. So character NA 
was added to R, and the example became irrelevant without anyone noticing.


From ripley at stats.ox.ac.uk  Tue Jul  3 10:29:03 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Jul 2007 09:29:03 +0100 (BST)
Subject: [Rd] File lock mechanisms in R
In-Reply-To: <59d7961d0707021502i6d3d6216o791ea4467e013cfd@mail.gmail.com>
References: <59d7961d0707021502i6d3d6216o791ea4467e013cfd@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0707030916230.19678@gannet.stats.ox.ac.uk>

On Mon, 2 Jul 2007, Henrik Bengtsson wrote:

> Hi,
>
> is there a (cross-platform) file-locking mechanism available in R (or
> via some package)?

I don't believe there really is a cross-platform file-locking mechanism 
available to any language.  File-locking is an OS feature, and the 
semantics differ.  For those unfamiliar with this, the Wikipedia article 
is a good start (but ignores the POSIX lockf interface).

> I am looking for a way to have one R session lock a file for
> read/write access, while being updated/modified by another R session.
> This will provide me with a-poor-mans parallelization method.  It is
> ok to have so called advisory looking (as in Unix), which are
> non-mandatory to follow.  If not available, I'll use lock files, but
> there are some potential problems in creating such in an atomic way.

Depends what you mean by 'atomic'.  In R, the only way to have 
non-interruptible operations is via .Call or similar: the evaluator is 
interruptible at all times so it seems that this issue applies equally to 
all file locking from R.

> Ideally I wish to have this working on all platforms.
>
> Cheers
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Jul  3 10:45:33 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Jul 2007 10:45:33 +0200
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <4689ACC7.6010005@stats.uwo.ca>
References: <46842286.8080402@uni-bayreuth.de> <4689ACC7.6010005@stats.uwo.ca>
Message-ID: <18058.3245.990602.638911@stat.math.ethz.ch>

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 02 Jul 2007 21:56:23 -0400 writes:

    DM> On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
    >> Hi,
    >> 
    >> I noticed a minor flaw in integrate() from package stats:
    >> 
    >> Taking up arguments lower and upper from integrate(),
    >> 
    >> if (lower ==  Inf) && (upper ==  Inf)
    >> 
    >> or
    >> 
    >> if (lower == -Inf) && (upper == -Inf)
    >> 
    >> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
    >> 
    >> Rather, it should return 0.

    DM> Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf 
    DM> doesn't return 1?

    DM> Duncan Murdoch

Yes indeed, I think it should return NaN.
Martin

    >> 
    >> Quick fix:
    >> 
    >> ### old code ###
    >> ### [snip]
    >> else {
    >> if (is.na(lower) || is.na(upper))
    >> stop("a limit is missing")
    >> if (is.finite(lower)) {
    >> inf <- 1
    >> bound <- lower
    >> }
    >> else if (is.finite(upper)) {
    >> inf <- -1
    >> bound <- upper
    >> }
    >> else {
    >> inf <- 2
    >> bound <- 0
    >> }
    >> wk <- .External("call_dqagi", ff, rho = environment(),
    >> as.double(bound), as.integer(inf), as.double(abs.tol),
    >> as.double(rel.tol), limit = limit, PACKAGE = "base")
    >> }
    >> ### [snip]
    >> 
    >> ### new code  to replace the old one ###
    >> 
    >> ### [snip]
    >> else {
    >> if (is.na(lower) || is.na(upper))
    >> stop("a limit is missing")
    >> 
    >> if (lower == upper){
    >> 
    >> wk <- list("value" = 0, "abs.error" = 0,
    >> "subdivisions" = subdivisions,
    >> "ierr" = 0 )
    >> 
    >> } else {
    >> if (is.finite(lower)) {
    >> inf <- 1
    >> bound <- lower
    >> }
    >> else if (is.finite(upper)) {
    >> inf <- -1
    >> bound <- upper
    >> }
    >> else {
    >> inf <- 2
    >> bound <- 0
    >> }
    >> wk <- .External("call_dqagi", ff, rho = environment(),
    >> as.double(bound), as.integer(inf),
    >> as.double(abs.tol), as.double(rel.tol),
    >> limit = limit, PACKAGE = "base")
    >> 
    >> }
    >> }
    >> ### [snip]
    >> 
    >> Best, Peter
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    DM> ______________________________________________
    DM> R-devel at r-project.org mailing list
    DM> https://stat.ethz.ch/mailman/listinfo/r-devel


From ernesto at ipimar.pt  Tue Jul  3 12:40:02 2007
From: ernesto at ipimar.pt (ernesto)
Date: Tue, 03 Jul 2007 11:40:02 +0100
Subject: [Rd] How to get the names of the classes exported by a specific
	package.
Message-ID: <468A2782.9010606@ipimar.pt>

Hi,

I'm writing some functions to generate Rd files for a S4 package. I want 
to have 2 character vectors with the names of the S4 classes and the 
methods exported by a package. To get the info about methods I'm using 
"getGenerics(where="package:FLCore")" however I can not find a similar 
process to get the S4 classes. Are there functions to access this 
information ?

Best and thanks

EJ


From mtmorgan at fhcrc.org  Tue Jul  3 13:15:18 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 03 Jul 2007 04:15:18 -0700
Subject: [Rd] How to get the names of the classes exported by a specific
 package.
In-Reply-To: <468A2782.9010606@ipimar.pt> (ernesto@ipimar.pt's message of
	"Tue, 03 Jul 2007 11:40:02 +0100")
References: <468A2782.9010606@ipimar.pt>
Message-ID: <6phsl8568mx.fsf@gopher4.fhcrc.org>

Hi Ernesto,

As a hack,

> library(FLCore)
Loading required package: lattice
FLCore 1.4-4 - "Golden Jackal" 
> these <- ls("package:FLCore", all.names=TRUE)
> res <- metaNameUndo(these, prefix="C")
> as.character(res)
 [1] "FLBiol"    "FLBiols"   "FLCatch"   "FLFleet"   "FLFleets"  "FLIndex"  
 [7] "FLIndices" "FLQuant"   "FLQuants"  "FLSR"      "FLStock"   "FLStocks" 

Martin

ernesto <ernesto at ipimar.pt> writes:

> Hi,
>
> I'm writing some functions to generate Rd files for a S4 package. I want 
> to have 2 character vectors with the names of the S4 classes and the 
> methods exported by a package. To get the info about methods I'm using 
> "getGenerics(where="package:FLCore")" however I can not find a similar 
> process to get the S4 classes. Are there functions to access this 
> information ?
>
> Best and thanks
>
> EJ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From bates at stat.wisc.edu  Tue Jul  3 16:02:30 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Jul 2007 09:02:30 -0500
Subject: [Rd] Forthcoming change in the API of the Matrix package
Message-ID: <40e66e0b0707030702u5cec2eco96e3942770f585a6@mail.gmail.com>

Martin and I will soon release a new version of the Matrix package
with a modified API.  This will affect the authors of any packages
that use calls to the C function R_GetCCallable to directly access C
functions in the DLL or shared object object in the libs directory of
the Matrix package.  (If you didn't understand that last sentence,
relax - it means that you can ignore this message.)

We strongly suspect that I am the only such author (this mechanism is
used in the lme4 package) and, because I was the one who made the API
change, I do indeed know about it.  However, if others do use this
mechanism for, say, accessing functions in the CHOLMOD sparse matrix C
library, you should be aware of this.

The current version of the Matrix package is 0.99875-3.  This version
exports the C functions according to the old API.  The next version
will be 0.999375-0 using the new API.  I will soon upload version
0.99875-3 of the lme4 package that depends on

Matrix(<= 0.99875-3)

Version 0.999375-0 of the lme4 package will depend on

Matrix(>= 0.999375-0)

The changes in the API are in the functions as_cholmod_sparse,
as_cholmod_dense and as_cholmod_factor.  After the change the first
argument will be a pointer to a struct of the appropriate return type
(i.e. the first argument in as_cholmod_sparse is a cholmod_sparse *
and the second argument is an SEXP).  This allows the calling function
to handle both the allocation and the freeing of the storage for the
struct.

Also the new API provides several macros and typedefs for such
pointers to structs.

The development version of the Matrix package is available at

https://svn.R-project.org/R-packages/branches/Matrix-APIchange/

The corresponding  version of the lme4 package is at

https://svn.R-project.org/R-packages/branches/gappy-lmer/


From John.Maindonald at anu.edu.au  Tue Jul  3 16:20:10 2007
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Wed, 4 Jul 2007 00:20:10 +1000 (EST)
Subject: [Rd] termplot - changes in defaults
Message-ID: <33232.91.84.18.241.1183472410.squirrel@sqmail.anu.edu.au>

While termplot is under discussion, here's another proposal. I'd like to
change the default for partial.resid to TRUE, and for smooth to
panel.smooth.  I'd be surprised if those changes were to break existing
code.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Precisely.  Thanks Brian.
>
> I did do something like this but not nearly so elegantly.
>
> I suggest this become the standard version in the next release.  I can't

Yes, that was the intention (to go into R-devel).
(It was also my intention to attach as plain text, but my Windows mailer
seems to have defeated that.)

> see that it can break any existing code.  It's a pity now we can't make
> ylim = "common" the default.

I suspect we could if I allow a way to get the previous behaviour
(ylim="free", I think).

Brian

> Regards,
> Bill V.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, 2 July 2007 7:55 PM
> To: Venables, Bill (CMIS, Cleveland)
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] termplot with uniform y-limits
>
> Is the attached the sort of thing you are looking for?
> It allows ylim to be specified, including as "common".
>
> On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:
>
>> Does anyone have, or has anyone ever considered making, a version of
>> 'termplot' that allows the user to specify that all plots should have
>> the same y-limits?
>>
>> This seems a natural thing to ask for, as the plots share a y-scale.
> If
>> you don't have the same y-axes you can easily misread the comparative
>> contributions of the different components.
>>
>> Notes: the current version of termplot does not allow the user to
>> specify ylim.  I checked.
>>
>>           the plot tools that come with mgcv do this by default.  Thanks
>> Simon.
>>
>>
>> Bill Venables
>> CSIRO Laboratories
>> PO Box 120, Cleveland, 4163
>> AUSTRALIA
>> Office Phone (email preferred): +61 7 3826 7251
>> Fax (if absolutely necessary):  +61 7 3826 7304
>> Mobile:                         +61 4 8819 4402
>> Home Phone:                     +61 7 3286 7700
>> mailto:Bill.Venables at csiro.au
>> http://www.cmis.csiro.au/bill.venables/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From John.Maindonald at anu.edu.au  Tue Jul  3 16:23:26 2007
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Wed, 4 Jul 2007 00:23:26 +1000 (EST)
Subject: [Rd] termplot - changes in defaults
Message-ID: <33272.91.84.18.241.1183472606.squirrel@sqmail.anu.edu.au>

While termplot is under discussion, here's another proposal. I'd like to
change the default for partial.resid to TRUE, and for smooth to
panel.smooth.  I'd be surprised if those changes were to break existing code.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:

> Precisely.  Thanks Brian.
>
> I did do something like this but not nearly so elegantly.
>
> I suggest this become the standard version in the next release.  I can't

Yes, that was the intention (to go into R-devel).
(It was also my intention to attach as plain text, but my Windows mailer
seems to have defeated that.)

> see that it can break any existing code.  It's a pity now we can't make
ylim = "common" the default.

I suspect we could if I allow a way to get the previous behaviour
(ylim="free", I think).

Brian

> Regards,
> Bill V.
>
>
> Bill Venables
> CSIRO Laboratories
> PO Box 120, Cleveland, 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):  +61 7 3826 7304
> Mobile:                         +61 4 8819 4402
> Home Phone:                     +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> -----Original Message-----
> From: ripley at stats.ox.ac.uk [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, 2 July 2007 7:55 PM
> To: Venables, Bill (CMIS, Cleveland)
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] termplot with uniform y-limits
>
> Is the attached the sort of thing you are looking for?
> It allows ylim to be specified, including as "common".
>
> On Mon, 2 Jul 2007, Bill.Venables at csiro.au wrote:
>
>> Does anyone have, or has anyone ever considered making, a version of
'termplot' that allows the user to specify that all plots should have
the same y-limits?
>>
>> This seems a natural thing to ask for, as the plots share a y-scale.
> If
>> you don't have the same y-axes you can easily misread the comparative
contributions of the different components.
>>
>> Notes: the current version of termplot does not allow the user to
specify ylim.  I checked.
>>
>>           the plot tools that come with mgcv do this by default.  Thanks
>> Simon.
>>
>>
>> Bill Venables
>> CSIRO Laboratories
>> PO Box 120, Cleveland, 4163
>> AUSTRALIA
>> Office Phone (email preferred): +61 7 3826 7251
>> Fax (if absolutely necessary):  +61 7 3826 7304
>> Mobile:                         +61 4 8819 4402
>> Home Phone:                     +61 7 3286 7700
>> mailto:Bill.Venables at csiro.au
>> http://www.cmis.csiro.au/bill.venables/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Tue Jul  3 16:57:49 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Jul 2007 09:57:49 -0500
Subject: [Rd] [OT] help in setting up a doxygen configuration file
Message-ID: <40e66e0b0707030757g3e800316v5a65ad61b65e3621@mail.gmail.com>

I would appreciate some pointers on how to set up a doxygen
configuration file for C source code.  In particular I would like to
be able to generate a call graph.  I tend to write a lot of short
utility functions and, by the time the final design reveals itself, it
is quite possible that some of these utilities are called in only one
place.  That's not a bad thing to have happen but I would like to know
about it when it does occur.

Doxygen seems to emphasize C++ classes and I can't manage to get it to
do much with my C functions.  The package sources are available at

https://svn.R-project.org/R-packages/branches/gappy-lmer/

The doxygen configuration file is gappy-lmer/inst/doc/Doxyfile

I have written all the Javadoc-style comments in the source files such
as gappy-lmer/src/lmer.c but I can't seem to get doxygen to notice
them.


From osklyar at ebi.ac.uk  Tue Jul  3 17:26:09 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Tue, 03 Jul 2007 16:26:09 +0100
Subject: [Rd] 'inline' package update
Message-ID: <468A6A91.4060401@ebi.ac.uk>

Dear all,

the 'inline' package was updated to version 0.2.2 with the following
changes:

  - functions declared using 'cfunction' can now be saved, the code
    is recompiled when the object is loaded (not yet implemented
    for setCMethod)
  - full path to the R binary is used for compilation allowing for
    the use of the correct R version when several are installed

The update has been submitted to CRAN and should appear shortly.
Meanwhile, the package is available from

http://www.ebi.ac.uk/~osklyar/inline

Best,
Oleg

-- 
Dr Oleg Sklyar * EBI/EMBL, Cambridge CB10 1SD, England * +44-1223-494466


From Peter.Ruckdeschel at uni-bayreuth.de  Tue Jul  3 17:26:43 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Tue, 03 Jul 2007 17:26:43 +0200
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <18058.3245.990602.638911@stat.math.ethz.ch>
References: <46842286.8080402@uni-bayreuth.de>	<4689ACC7.6010005@stats.uwo.ca>
	<18058.3245.990602.638911@stat.math.ethz.ch>
Message-ID: <468A6AB3.60509@uni-bayreuth.de>

Thanks Martin and Duncan for your
comments,

Martin Maechler wrote:
>>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Mon, 02 Jul 2007 21:56:23 -0400 writes:
> 
>     DM> On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
>     >> Hi,
>     >> 
>     >> I noticed a minor flaw in integrate() from package stats:
>     >> 
>     >> Taking up arguments lower and upper from integrate(),
>     >> 
>     >> if (lower ==  Inf) && (upper ==  Inf)
>     >> 
>     >> or
>     >> 
>     >> if (lower == -Inf) && (upper == -Inf)
>     >> 
>     >> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
>     >> 
>     >> Rather, it should return 0.
> 
>     DM> Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf 
>     DM> doesn't return 1?
> 
>     DM> Duncan Murdoch
> 
> Yes indeed, I think it should return NaN.

not quite convinced --- or more precisely:

[ Let's assume lower = upper = Inf here,
  case lower = upper = -Inf is analogue ]

I'd say it depends on whether the (Lebesgue-) integral

   integral(f, lower = <some finite value>, upper = Inf)

is well defined. Then, by dominated convergence, the integral should
default to 0.

But I admit that then a test

     is.finite(integrate(f, lower = <some finite value>, upper = Inf)$value)

would be adequate, too, which makes evaluation a little more expensive :-(

If, otoh

   integrate(f, lower = <some finite value>, upper = Inf)

throws an error, I agree, there should be a NaN ...
Best, Peter


From murdoch at stats.uwo.ca  Tue Jul  3 17:39:16 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 03 Jul 2007 11:39:16 -0400
Subject: [Rd] update() problem (was: saving objects with embedded
	environments)
In-Reply-To: <EEBC169715EB8C438D3C9283AF0F201C17C834@MSGBOSCLM2WIN.DMN1.FMR.COM>
References: <EEBC169715EB8C438D3C9283AF0F201C17C830@MSGBOSCLM2WIN.DMN1.FMR.COM>	<66f3bd910706291644s6db3b3a9ncd1bd075ceec3553@mail.gmail.com>
	<EEBC169715EB8C438D3C9283AF0F201C17C834@MSGBOSCLM2WIN.DMN1.FMR.COM>
Message-ID: <468A6DA4.6070503@stats.uwo.ca>

I don't want this thread to be lost, so I've changed the subject heading.

I think there's a problem here, but the problem is that update() is 
failing, not that the environment is being unnecessarily saved.  The 
problem here is that update() has no method specific to lm objects, so 
it doesn't know about the saved environment.  I don't know what other 
kinds of objects update.default can handle properly, but if they don't 
all have terms, there should probably be a specific update.lm method 
that knows to look there.

Now it's not completely obvious what update() should do in general, e.g. 
when adding terms.  If a user asks to add a term Foo to a model, they 
may mean the Foo that is in their workspace, not the Foo that happens to 
be in the data frame but not previously included in the model.  However, 
I think in the case of an lm object produced in a function, the updating 
should be done in the environment of the function.

Duncan Murdoch

On 7/2/2007 9:27 AM, McGehee, Robert wrote:
> Thanks for this. So at the risk of treading out too deep into unfamiliar
> water, one concern is that if I run 'lm' within a function and then the
> function exits, am I still (perhaps unnecessarily) keeping a copy of the
> function environment and the associated data? It does not seem that
> 'update' even works after I exit the function, so it's not clear to me
> what help saving the environment and a copy of all of its data is (see
> example below).
> 
>> B <- data.frame(y=1:100, x=rnorm(100))
>> FUN <- function(B) lm(y ~ x, data=B)
>> m <- FUN(B)
>> rm(B)
> ## update doesn't find object 'B' in function environment (so why store
> the environment?)
>> update(m, y ~ 1)  
> Error in inherits(x, "data.frame") : object "B" not found
> 
> ## However, there is a copy of object 'B' saved anyway, even
> ## after removing it from the global environment and exiting the
> function
>> dim(get("B", envir=attr(m$terms, ".Environment")))
> [1] 100   2
> 
> For my purposes all works well now. I brought this up only as one can
> quickly run out of memory if data is unnecessarily kept around after
> with large models. Anecdotally, before isolating this issue I would
> crash my snow/MPI session (followed by R) when trying to transfer these
> 'lm' and 'lm'-like objects with embedded environments. If I did not
> distribute the processing, then I found that I would rather quickly use
> up all 24GB of my computer's memory and swap space after repeated calls.
> 
> Thanks,
> Robert
> 
> -----Original Message-----
> From: Roger Peng [mailto:rdpeng at gmail.com] 
> Sent: Friday, June 29, 2007 7:44 PM
> To: McGehee, Robert
> Cc: R-devel
> Subject: Re: [Rd] saving objects with embedded environments
> 
> I believe this is intentional.  See ?serialize.  When lm() is called
> in a function, the environment is saved in case the resulting fitted
> model object needs to be updated, for example, with update().
> 
> if you don't want the linear model object, you might try just saving
> the relevant objects to a separate list rather than try to delete
> everything that is irrelevant from the 'lm' object.
> 
> -roger
> 
> On 6/28/07, McGehee, Robert <Robert.McGehee at geodecapital.com> wrote:
>> Hello,
>> I have been running linear regressions on large data sets. As 'lm'
> saves
>> a great deal of extraneous (for me) data including the residuals,
>> fitted.values, model frame, etc., I generally set these to NULL within
>> the object before saving off the model to a file.
>>
>> In the below example, however, I have found that depending on whether
> or
>> not I run 'lm' within another function or not, the entire function
>> environment is saved off with the file. So, even while object.size and
>> all.equal report that both 'lm's are equal and of small size, one
> saves
>> as a 24MB file and the other as 646 bytes. These seems to be because
> in
>> the first example the function environment is saved in attr(x1$terms,
>> ".Environment") and takes up all 24MB of space.
>>
>> Anyway, I think this is a bug, or if nothing else very undesirable
> (that
>> an object reported to be 0.5kb takes up 24MB). There also seems to be
>> some inconsistency on how environments are saved depending on if it is
>> the global environment or not, though I'm not familiar enough with
>> environments to know if this was intentional. Comments are
> appreciated.
>>
>> Thanks,
>> Robert
>>
>> ##################################################################
>> testEq <- function(B) {
>>     x <- lm(y ~ x1+x2+x3, data=B, model=FALSE)
>>     x$residuals <- x$effects <- x$fitted.values <- x$qr$qr <- NULL
>>     x
>> }
>>
>> N <- 900000
>> B <- data.frame(y=rnorm(N)+1:N, x1=rnorm(N)+1:N, x2=rnorm(N)+1:N,
>> x3=rnorm(N)+1:N)
>> x1 <- testEq(B)
>> x2 <- lm(y ~ x1+x2+x3, data=B, model=FALSE)
>> x2$residuals <- x2$effects <- x2$fitted.values <- x2$qr$qr <- NULL
>>
>> all.equal(x1, x2) ## TRUE
>> object.size(x1)  ## 5112
>> object.size(x2)  ## 5112
>> save(x1, file="x1.RData")
>> save(x2, file="x2.RData")
>> file.info("x1.RData")$size ## 24063852 bytes
>> file.info("x2.RData")$size ## 646 bytes
>>
>> > R.version
>>                _
>> platform       i686-pc-linux-gnu
>> arch           i686
>> os             linux-gnu
>> system         i686, linux-gnu
>> status
>> major          2
>> minor          5.0
>> year           2007
>> month          04
>> day            23
>> svn rev        41293
>> language       R
>> version.string R version 2.5.0 (2007-04-23)
>>
>>
>> Robert McGehee, CFA
>> Quantitative Analyst
>> Geode Capital Management, LLC
>> One Post Office Square, 28th Floor | Boston, MA | 02109
>> Tel: 617/392-8396    Fax:617/476-6389
>> mailto:robert.mcgehee at geodecapital.com
>>
>>
>>
>> This e-mail, and any attachments hereto, are intended for
> us...{{dropped}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From maechler at stat.math.ethz.ch  Tue Jul  3 17:55:08 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Jul 2007 17:55:08 +0200
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <468A6AB3.60509@uni-bayreuth.de>
References: <46842286.8080402@uni-bayreuth.de> <4689ACC7.6010005@stats.uwo.ca>
	<18058.3245.990602.638911@stat.math.ethz.ch>
	<468A6AB3.60509@uni-bayreuth.de>
Message-ID: <18058.29020.369190.734208@stat.math.ethz.ch>

>>>>> "PetRd" == Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de>
>>>>>     on Tue, 03 Jul 2007 17:26:43 +0200 writes:

    PetRd> Thanks Martin and Duncan for your
    PetRd> comments,

    PetRd> Martin Maechler wrote:
    >>>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
    >>>>>>> on Mon, 02 Jul 2007 21:56:23 -0400 writes:
    >> 
    DM> On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
    >> >> Hi,
    >> >> 
    >> >> I noticed a minor flaw in integrate() from package stats:
    >> >> 
    >> >> Taking up arguments lower and upper from integrate(),
    >> >> 
    >> >> if (lower ==  Inf) && (upper ==  Inf)
    >> >> 
    >> >> or
    >> >> 
    >> >> if (lower == -Inf) && (upper == -Inf)
    >> >> 
    >> >> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
    >> >> 
    >> >> Rather, it should return 0.
    >> 
    DM> Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf 
    DM> doesn't return 1?
    >> 
    DM> Duncan Murdoch
    >> 
    >> Yes indeed, I think it should return NaN.

    PetRd> not quite convinced --- or more precisely:

    PetRd> [ Let's assume lower = upper = Inf here,
    PetRd> case lower = upper = -Inf is analogue ]

    PetRd> I'd say it depends on whether the (Lebesgue-) integral

    PetRd> integral(f, lower = <some finite value>, upper = Inf)

    PetRd> is well defined. Then, by dominated convergence, the integral should
    PetRd> default to 0.

    PetRd> But I admit that then a test

    PetRd> is.finite(integrate(f, lower = <some finite value>, upper = Inf)$value)

    PetRd> would be adequate, too, which makes evaluation a little more expensive :-(

No, that's not the Duncan's point I agreed on.
The argument is different:

consider       Int(f, x, x^2)
	       Int(f, x, 2*x)
	       Int(f, x, exp(x))
etc, 
These could conceivably give very different values,
with different limits for  x --> Inf

Hence, 	       Int(f, Inf, Inf)

is mathematically undefined, hence NaN
Martin

    PetRd> If, otoh

    PetRd> integrate(f, lower = <some finite value>, upper = Inf)

    PetRd> throws an error, I agree, there should be a NaN ...
    PetRd> Best, Peter


From murdoch at stats.uwo.ca  Tue Jul  3 19:21:19 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 03 Jul 2007 13:21:19 -0400
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <18058.29020.369190.734208@stat.math.ethz.ch>
References: <46842286.8080402@uni-bayreuth.de>
	<4689ACC7.6010005@stats.uwo.ca>	<18058.3245.990602.638911@stat.math.ethz.ch>	<468A6AB3.60509@uni-bayreuth.de>
	<18058.29020.369190.734208@stat.math.ethz.ch>
Message-ID: <468A858F.2090508@stats.uwo.ca>

On 7/3/2007 11:55 AM, Martin Maechler wrote:
>>>>>> "PetRd" == Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de>
>>>>>>     on Tue, 03 Jul 2007 17:26:43 +0200 writes:
> 
>     PetRd> Thanks Martin and Duncan for your
>     PetRd> comments,
> 
>     PetRd> Martin Maechler wrote:
>     >>>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>     >>>>>>> on Mon, 02 Jul 2007 21:56:23 -0400 writes:
>     >> 
>     DM> On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
>     >> >> Hi,
>     >> >> 
>     >> >> I noticed a minor flaw in integrate() from package stats:
>     >> >> 
>     >> >> Taking up arguments lower and upper from integrate(),
>     >> >> 
>     >> >> if (lower ==  Inf) && (upper ==  Inf)
>     >> >> 
>     >> >> or
>     >> >> 
>     >> >> if (lower == -Inf) && (upper == -Inf)
>     >> >> 
>     >> >> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
>     >> >> 
>     >> >> Rather, it should return 0.
>     >> 
>     DM> Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf 
>     DM> doesn't return 1?
>     >> 
>     DM> Duncan Murdoch
>     >> 
>     >> Yes indeed, I think it should return NaN.
> 
>     PetRd> not quite convinced --- or more precisely:
> 
>     PetRd> [ Let's assume lower = upper = Inf here,
>     PetRd> case lower = upper = -Inf is analogue ]
> 
>     PetRd> I'd say it depends on whether the (Lebesgue-) integral
> 
>     PetRd> integral(f, lower = <some finite value>, upper = Inf)
> 
>     PetRd> is well defined. Then, by dominated convergence, the integral should
>     PetRd> default to 0.
> 
>     PetRd> But I admit that then a test
> 
>     PetRd> is.finite(integrate(f, lower = <some finite value>, upper = Inf)$value)
> 
>     PetRd> would be adequate, too, which makes evaluation a little more expensive :-(
> 
> No, that's not the Duncan's point I agreed on.
> The argument is different:
> 
> consider       Int(f, x, x^2)
> 	       Int(f, x, 2*x)
> 	       Int(f, x, exp(x))
> etc, 
> These could conceivably give very different values,
> with different limits for  x --> Inf
> 
> Hence, 	       Int(f, Inf, Inf)
> 
> is mathematically undefined, hence NaN

In the case Peter was talking about, those limits would all be zero. 
But I don't think we could hope for the integrate() function in R to 
recognize integrability.  For example,

 > integrate(function(x) 1/x, 1e8, Inf)
1.396208e-05 with absolute error < 2.6e-05

where the correct answer is Inf, since the integral is divergent.

So I'd be fairly strongly opposed to returning 0.  Whether we return NaN 
or NA is harder:  I suspect the reason Inf-Inf or Inf/Inf is NaN is 
because this is handled on most platforms by the floating point hardware 
or the C run-time, rather than because we've made a deliberate decision 
for that.  Do we have other cases where NaN is used to mean "unable to 
determine the answer"?

Duncan Murdoch

> Martin
> 
>     PetRd> If, otoh
> 
>     PetRd> integrate(f, lower = <some finite value>, upper = Inf)
> 
>     PetRd> throws an error, I agree, there should be a NaN ...
>     PetRd> Best, Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Jul  3 19:27:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Jul 2007 18:27:39 +0100 (BST)
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <468A858F.2090508@stats.uwo.ca>
References: <46842286.8080402@uni-bayreuth.de> <4689ACC7.6010005@stats.uwo.ca>
	<18058.3245.990602.638911@stat.math.ethz.ch>
	<468A6AB3.60509@uni-bayreuth.de>
	<18058.29020.369190.734208@stat.math.ethz.ch>
	<468A858F.2090508@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0707031826370.3374@gannet.stats.ox.ac.uk>

I think throwing an error is a better solution: this is rather unlikely to 
be deliberate and returning NaN might postpone the detection too long.


On Tue, 3 Jul 2007, Duncan Murdoch wrote:

> On 7/3/2007 11:55 AM, Martin Maechler wrote:
>>>>>>> "PetRd" == Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de>
>>>>>>>     on Tue, 03 Jul 2007 17:26:43 +0200 writes:
>>
>>     PetRd> Thanks Martin and Duncan for your
>>     PetRd> comments,
>>
>>     PetRd> Martin Maechler wrote:
>>    >>>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>    >>>>>>> on Mon, 02 Jul 2007 21:56:23 -0400 writes:
>>    >>
>>     DM> On 28/06/2007 5:05 PM, Peter Ruckdeschel wrote:
>>    >>>> Hi,
>>    >>>>
>>    >>>> I noticed a minor flaw in integrate() from package stats:
>>    >>>>
>>    >>>> Taking up arguments lower and upper from integrate(),
>>    >>>>
>>    >>>> if (lower ==  Inf) && (upper ==  Inf)
>>    >>>>
>>    >>>> or
>>    >>>>
>>    >>>> if (lower == -Inf) && (upper == -Inf)
>>    >>>>
>>    >>>> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
>>    >>>>
>>    >>>> Rather, it should return 0.
>>    >>
>>     DM> Wouldn't it be better to return NA or NaN, for the same reason Inf/Inf
>>     DM> doesn't return 1?
>>    >>
>>     DM> Duncan Murdoch
>>    >>
>>    >> Yes indeed, I think it should return NaN.
>>
>>     PetRd> not quite convinced --- or more precisely:
>>
>>     PetRd> [ Let's assume lower = upper = Inf here,
>>     PetRd> case lower = upper = -Inf is analogue ]
>>
>>     PetRd> I'd say it depends on whether the (Lebesgue-) integral
>>
>>     PetRd> integral(f, lower = <some finite value>, upper = Inf)
>>
>>     PetRd> is well defined. Then, by dominated convergence, the integral should
>>     PetRd> default to 0.
>>
>>     PetRd> But I admit that then a test
>>
>>     PetRd> is.finite(integrate(f, lower = <some finite value>, upper = Inf)$value)
>>
>>     PetRd> would be adequate, too, which makes evaluation a little more expensive :-(
>>
>> No, that's not the Duncan's point I agreed on.
>> The argument is different:
>>
>> consider       Int(f, x, x^2)
>> 	       Int(f, x, 2*x)
>> 	       Int(f, x, exp(x))
>> etc,
>> These could conceivably give very different values,
>> with different limits for  x --> Inf
>>
>> Hence, 	       Int(f, Inf, Inf)
>>
>> is mathematically undefined, hence NaN
>
> In the case Peter was talking about, those limits would all be zero.
> But I don't think we could hope for the integrate() function in R to
> recognize integrability.  For example,
>
> > integrate(function(x) 1/x, 1e8, Inf)
> 1.396208e-05 with absolute error < 2.6e-05
>
> where the correct answer is Inf, since the integral is divergent.
>
> So I'd be fairly strongly opposed to returning 0.  Whether we return NaN
> or NA is harder:  I suspect the reason Inf-Inf or Inf/Inf is NaN is
> because this is handled on most platforms by the floating point hardware
> or the C run-time, rather than because we've made a deliberate decision
> for that.  Do we have other cases where NaN is used to mean "unable to
> determine the answer"?
>
> Duncan Murdoch
>
>> Martin
>>
>>     PetRd> If, otoh
>>
>>     PetRd> integrate(f, lower = <some finite value>, upper = Inf)
>>
>>     PetRd> throws an error, I agree, there should be a NaN ...
>>     PetRd> Best, Peter
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Tue Jul  3 19:42:54 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 3 Jul 2007 13:42:54 -0400
Subject: [Rd] minor flaw in integrate()
In-Reply-To: <46842286.8080402@uni-bayreuth.de>
References: <46842286.8080402@uni-bayreuth.de>
Message-ID: <971536df0707031042n8b3e0a4re00e6d286dbeba7@mail.gmail.com>

If integrate is changed it would be nice at the same time to make it
into an S3 generic.  deriv already is an S3 generic but strangely integrate
is not.  Ryacas provides a deriv method but for integrate Ryacas inconsistently
provides Integrate since integrate is not generic.

On 6/28/07, Peter Ruckdeschel <Peter.Ruckdeschel at uni-bayreuth.de> wrote:
> Hi,
>
> I noticed a minor flaw in integrate() from package stats:
>
> Taking up arguments lower and upper from integrate(),
>
>   if (lower ==  Inf) && (upper ==  Inf)
>
>       or
>
>   if (lower == -Inf) && (upper == -Inf)
>
> integrate() calculates the value for (lower==-Inf) && (upper==Inf).
>
> Rather, it should return 0.
>
> Quick fix:
>
> ### old code ###
> ### [snip]
>    else {
>            if (is.na(lower) || is.na(upper))
>                stop("a limit is missing")
>            if (is.finite(lower)) {
>                inf <- 1
>                bound <- lower
>            }
>            else if (is.finite(upper)) {
>                inf <- -1
>                bound <- upper
>            }
>            else {
>                inf <- 2
>                bound <- 0
>            }
>            wk <- .External("call_dqagi", ff, rho = environment(),
>                as.double(bound), as.integer(inf), as.double(abs.tol),
>                as.double(rel.tol), limit = limit, PACKAGE = "base")
>    }
> ### [snip]
>
> ### new code  to replace the old one ###
>
> ### [snip]
>    else {
>            if (is.na(lower) || is.na(upper))
>                stop("a limit is missing")
>
>            if (lower == upper){
>
>                wk <- list("value" = 0, "abs.error" = 0,
>                        "subdivisions" = subdivisions,
>                        "ierr" = 0 )
>
>            } else {
>                    if (is.finite(lower)) {
>                        inf <- 1
>                        bound <- lower
>                    }
>                    else if (is.finite(upper)) {
>                            inf <- -1
>                        bound <- upper
>                    }
>                    else {
>                        inf <- 2
>                        bound <- 0
>                    }
>                    wk <- .External("call_dqagi", ff, rho = environment(),
>                            as.double(bound), as.integer(inf),
>                            as.double(abs.tol), as.double(rel.tol),
>                            limit = limit, PACKAGE = "base")
>
>            }
>    }
> ### [snip]
>
> Best, Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From helprhelp at gmail.com  Tue Jul  3 21:27:00 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Tue, 3 Jul 2007 15:27:00 -0400
Subject: [Rd] reinforce library to re-load
Message-ID: <cdf817830707031227y7e076470nd8597967935c5e6@mail.gmail.com>

Hi,

I am wondering if there is a parameter in library() so that it can
reinforce package to be reloaded. It helps when you test your modified
package by yourself. Otherwise, my way is to re-start Rgui.

(by reading ?library, I understand this option is not implemented)
"...Both functions check and update the list of currently loaded
packages and do not reload a package which is already loaded.
(Furthermore, if the package has a name space and a name space of that
name is already loaded, they work from the existing names space rather
than reloading from the file system.)"

Thanks.

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From ripley at stats.ox.ac.uk  Wed Jul  4 07:36:53 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 4 Jul 2007 06:36:53 +0100 (BST)
Subject: [Rd] reinforce library to re-load
In-Reply-To: <cdf817830707031227y7e076470nd8597967935c5e6@mail.gmail.com>
References: <cdf817830707031227y7e076470nd8597967935c5e6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0707040616190.12086@gannet.stats.ox.ac.uk>

Please don't post to multiple lists: I am replying only to R-devel.

You should detach your package, and if it has a namespace unload it, 
before attempting to reload it.  Something like

detach("package:foo")
library(foo)

or

unloadNamespace("foo")  # this also detaches the package
library(foo)

If the package has a DLL, this will in general not reload that.  Now in 
quite a few cases you cannot successfully unload a DLL, but 
library.dynam.unload is provided if you want to do this (including in your 
package's .Last.lib or .onUnload hooks).

On Tue, 3 Jul 2007, Weiwei Shi wrote:

> Hi,
>
> I am wondering if there is a parameter in library() so that it can
> reinforce package to be reloaded. It helps when you test your modified
> package by yourself. Otherwise, my way is to re-start Rgui.
>
> (by reading ?library, I understand this option is not implemented)
> "...Both functions check and update the list of currently loaded
> packages and do not reload a package which is already loaded.
> (Furthermore, if the package has a name space and a name space of that
> name is already loaded, they work from the existing names space rather
> than reloading from the file system.)"
>
> Thanks.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mwtoews at sfu.ca  Wed Jul  4 08:52:40 2007
From: mwtoews at sfu.ca (mwtoews at sfu.ca)
Date: Wed,  4 Jul 2007 08:52:40 +0200 (CEST)
Subject: [Rd] editing pasted text from parameter list through rcompletion
	crashes R in Windows (PR#9775)
Message-ID: <20070704065240.4DE6348B6E@slim.kubism.ku.dk>

Full_Name: Michael Toews
Version: R 2.5.1
OS: WinXP; SP2
Submission from: (NULL) (142.58.206.114)


To reproduce this crash:
1. Start a new R session normally in Windows
2. Type (an example command): "boxplot(" without pressing enter
3. Copy this text: "c(1,2,6,4,7,3)"
4. Bring Rgui.exe back in focus, and hit "Tab" twice to activate the parameter
list (you should see "x=          ...=        range=      width=" etc.)
4. Paste the text, then press the backspace key, *crash*

There several other variations to crash R similarly, such as pressing the
left-key to edit the pasted text while rcompletion is showing the parameter
list. Present behaviour for rcompletion is to remove the parameter list from the
console after typing has started; however, this list is not removed if text is
pasted, which appears to crash R if the cursor moves backwards (buffer
problems?).

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 5.1
 year = 2007
 month = 06
 day = 27
 svn rev = 42083
 language = R
 version.string = R version 2.5.1 (2007-06-27)

Windows XP (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_Canada.1252;LC_CTYPE=English_Canada.1252;LC_MONETARY=English_Canada.1252;LC_NUMERIC=C;LC_TIME=English_Canada.1252

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices, package:utils,
package:datasets, package:methods, Autoloads, package:base


From HDoran at air.org  Tue Jul  3 21:35:11 2007
From: HDoran at air.org (Doran, Harold)
Date: Tue, 3 Jul 2007 15:35:11 -0400
Subject: [Rd] [R] reinforce library to re-load
In-Reply-To: <cdf817830707031227y7e076470nd8597967935c5e6@mail.gmail.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EE57A07@dc1ex01.air.org>

I think you want to use detach() 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Weiwei Shi
> Sent: Tuesday, July 03, 2007 3:27 PM
> To: r-help at stat.math.ethz.ch
> Cc: R-devel at stat.math.ethz.ch
> Subject: [R] reinforce library to re-load
> 
> Hi,
> 
> I am wondering if there is a parameter in library() so that 
> it can reinforce package to be reloaded. It helps when you 
> test your modified package by yourself. Otherwise, my way is 
> to re-start Rgui.
> 
> (by reading ?library, I understand this option is not 
> implemented) "...Both functions check and update the list of 
> currently loaded packages and do not reload a package which 
> is already loaded.
> (Furthermore, if the package has a name space and a name 
> space of that name is already loaded, they work from the 
> existing names space rather than reloading from the file system.)"
> 
> Thanks.
> 
> --
> Weiwei Shi, Ph.D
> Research Scientist
> GeneGO, Inc.
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mail at joeconway.com  Wed Jul  4 22:56:01 2007
From: mail at joeconway.com (Joe Conway)
Date: Wed, 04 Jul 2007 13:56:01 -0700
Subject: [Rd] problem with findFun call from embedded R
Message-ID: <468C0961.9020804@joeconway.com>

I was debugging a problem reported to me regarding PL/R, and found that 
I can duplicate it using only R sources. It might be characterized as 
possibly a misuse of the findFun() function, but I leave that for the R 
devel experts to decide.

The below results are all with R-2.5.1 (I can't seem to download 
r-patched at the moment, but didn't see anything in the 2.5.1-patched 
release notes indicating this issue had been noticed) on Fedora Core 6 
x86_64 (also duplicated with R-2.5.0 on FC7 i386).

Steps to reproduce:
8<------------------------
  configure, make, make install from source tree
  cd tests/Embedding/
  make RNamedCall
  ./RNamedCall  #works as expected
  mv foo.R foo.R.orig
  ./RNamedCall  #segfaults
8<------------------------

output:
8<------------------------
Error in file(file, "r", encoding = encoding) :
         unable to open connection
In addition: Warning message:
cannot open file 'foo.R', reason 'No such file or directory' in: 
file(file, "r", encoding = encoding)
Error: could not find function "foo"

  *** caught segfault ***
address (nil), cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 1
aborting ...
Segmentation fault
8<------------------------

The problem comes from RNamedCall starting at line 54:
8<------------------------
   fun = findFun(install("foo"), R_GlobalEnv);
   if(fun == R_NilValue) {
	fprintf(stderr, "No definition for function foo.
                          Source foo.R and save the session.\n");
   UNPROTECT(1);
   exit(1);
   }
8<------------------------

If foo.R was not found and never sourced, meaning that the object "foo" 
does not exist, findFun never returns. Instead the segfault occurs at 
line 719 in errors.c at the LONGJMP statement. Setting a breakpoint at 
erros.c:719, the backtrace looks like this (will wrap poorly):

8<------------------------
Breakpoint 2, jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE, 
processWarnings=TRUE, resetConsole=TRUE,
     ignoreRestartContexts=FALSE) at errors.c:719
719         LONGJMP(R_ToplevelContext->cjmpbuf, 0);
(gdb) bt
#0  jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE, 
processWarnings=TRUE, resetConsole=TRUE,
     ignoreRestartContexts=FALSE) at errors.c:719
#1  0x00002aaaaab77e5d in verrorcall_dflt (call=0x609d78, 
format=0x2aaaaace4a4d "%s", ap=0x7fffa13a94c0)
     at errors.c:516
#2  0x00002aaaaab7814a in Rf_errorcall (call=0x609d78, 
format=0x2aaaaace4a4d "%s") at errors.c:551
#3  0x00002aaaaab78347 in Rf_error (format=0x2aaaaace42da "could not 
find function \"%s\"") at errors.c:578
#4  0x00002aaaaab708e5 in Rf_findFun (symbol=0xc64f20, rho=0x649fa0) at 
envir.c:1244
#5  0x0000000000400e0c in bar1 () at RNamedCall.c:54
#6  0x0000000000400d59 in main (argc=1, argv=0x7fffa13ab838) at 
RNamedCall.c:16
8<------------------------

And then stepping into line 719 generates the segfault:
8<------------------------
(gdb) s

Program received signal SIGSEGV, Segmentation fault.
0x00002aaaaab701ce in Rf_findVar (symbol=0x6c12b8, rho=0x0) at envir.c:998
998         if (TYPEOF(rho) == NILSXP)
8<------------------------

I believe this is happening because findFun() was not executed inside a 
valid context, and therefore R_ToplevelContext->cjmpbuf is invalid.

My question is -- is the above an abuse of findFun() by RNamedCall.c 
(meaning I should avoid the same pattern)? Or maybe it should be wrapped 
in something similar to R_ToplevelExec?

==========================

On a related note, I found during my PL/R debugging that the segfault 
was causing the same console based, interactive, "*** caught segfault 
***" logic to execute. I was able to confirm that R_Interactive was set 
to TRUE in my PL/R session.

It seems that Rf_initEmbeddedR() sets R_Interactive to TRUE and depends 
on the output of isatty() to change it to FALSE in Rf_initialize_R() if 
there is no tty. Unfortunately, the most common methods for starting 
Postgres leave the tty attached (stdout and stderr are directed to the 
log file). I ended up explicitly writing "R_Interactive = FALSE" just 
after running Rf_initEmbeddedR() -- is this a safe and reasonable thing 
to do?

Thanks,

Joe


From byron.ellis at gmail.com  Thu Jul  5 02:34:23 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Wed, 4 Jul 2007 17:34:23 -0700
Subject: [Rd] problem with findFun call from embedded R
In-Reply-To: <468C0961.9020804@joeconway.com>
References: <468C0961.9020804@joeconway.com>
Message-ID: <7098abec0707041734m7d22ca6dq462af2c1c5d47acc@mail.gmail.com>

Yeah, setting R_Interactive is probably fine. I do it (not that I
should be considered a "safe" user of R). As to the findFun issue,
there is a much more useful function (findVar1 maybe?) that wouldn't
die if the object didn't exist.

Sadly, like many functions useful for the development of user
interfaces and embedding R have been marked "hidden" making them
unavailable for use without building a custom version of R.

On 7/4/07, Joe Conway <mail at joeconway.com> wrote:
> I was debugging a problem reported to me regarding PL/R, and found that
> I can duplicate it using only R sources. It might be characterized as
> possibly a misuse of the findFun() function, but I leave that for the R
> devel experts to decide.
>
> The below results are all with R-2.5.1 (I can't seem to download
> r-patched at the moment, but didn't see anything in the 2.5.1-patched
> release notes indicating this issue had been noticed) on Fedora Core 6
> x86_64 (also duplicated with R-2.5.0 on FC7 i386).
>
> Steps to reproduce:
> 8<------------------------
>   configure, make, make install from source tree
>   cd tests/Embedding/
>   make RNamedCall
>   ./RNamedCall  #works as expected
>   mv foo.R foo.R.orig
>   ./RNamedCall  #segfaults
> 8<------------------------
>
> output:
> 8<------------------------
> Error in file(file, "r", encoding = encoding) :
>          unable to open connection
> In addition: Warning message:
> cannot open file 'foo.R', reason 'No such file or directory' in:
> file(file, "r", encoding = encoding)
> Error: could not find function "foo"
>
>   *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 1
> aborting ...
> Segmentation fault
> 8<------------------------
>
> The problem comes from RNamedCall starting at line 54:
> 8<------------------------
>    fun = findFun(install("foo"), R_GlobalEnv);
>    if(fun == R_NilValue) {
>         fprintf(stderr, "No definition for function foo.
>                           Source foo.R and save the session.\n");
>    UNPROTECT(1);
>    exit(1);
>    }
> 8<------------------------
>
> If foo.R was not found and never sourced, meaning that the object "foo"
> does not exist, findFun never returns. Instead the segfault occurs at
> line 719 in errors.c at the LONGJMP statement. Setting a breakpoint at
> erros.c:719, the backtrace looks like this (will wrap poorly):
>
> 8<------------------------
> Breakpoint 2, jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE,
> processWarnings=TRUE, resetConsole=TRUE,
>      ignoreRestartContexts=FALSE) at errors.c:719
> 719         LONGJMP(R_ToplevelContext->cjmpbuf, 0);
> (gdb) bt
> #0  jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE,
> processWarnings=TRUE, resetConsole=TRUE,
>      ignoreRestartContexts=FALSE) at errors.c:719
> #1  0x00002aaaaab77e5d in verrorcall_dflt (call=0x609d78,
> format=0x2aaaaace4a4d "%s", ap=0x7fffa13a94c0)
>      at errors.c:516
> #2  0x00002aaaaab7814a in Rf_errorcall (call=0x609d78,
> format=0x2aaaaace4a4d "%s") at errors.c:551
> #3  0x00002aaaaab78347 in Rf_error (format=0x2aaaaace42da "could not
> find function \"%s\"") at errors.c:578
> #4  0x00002aaaaab708e5 in Rf_findFun (symbol=0xc64f20, rho=0x649fa0) at
> envir.c:1244
> #5  0x0000000000400e0c in bar1 () at RNamedCall.c:54
> #6  0x0000000000400d59 in main (argc=1, argv=0x7fffa13ab838) at
> RNamedCall.c:16
> 8<------------------------
>
> And then stepping into line 719 generates the segfault:
> 8<------------------------
> (gdb) s
>
> Program received signal SIGSEGV, Segmentation fault.
> 0x00002aaaaab701ce in Rf_findVar (symbol=0x6c12b8, rho=0x0) at envir.c:998
> 998         if (TYPEOF(rho) == NILSXP)
> 8<------------------------
>
> I believe this is happening because findFun() was not executed inside a
> valid context, and therefore R_ToplevelContext->cjmpbuf is invalid.
>
> My question is -- is the above an abuse of findFun() by RNamedCall.c
> (meaning I should avoid the same pattern)? Or maybe it should be wrapped
> in something similar to R_ToplevelExec?
>
> ==========================
>
> On a related note, I found during my PL/R debugging that the segfault
> was causing the same console based, interactive, "*** caught segfault
> ***" logic to execute. I was able to confirm that R_Interactive was set
> to TRUE in my PL/R session.
>
> It seems that Rf_initEmbeddedR() sets R_Interactive to TRUE and depends
> on the output of isatty() to change it to FALSE in Rf_initialize_R() if
> there is no tty. Unfortunately, the most common methods for starting
> Postgres leave the tty attached (stdout and stderr are directed to the
> log file). I ended up explicitly writing "R_Interactive = FALSE" just
> after running Rf_initEmbeddedR() -- is this a safe and reasonable thing
> to do?
>
> Thanks,
>
> Joe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From jeff.horner at vanderbilt.edu  Thu Jul  5 18:12:38 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu, 05 Jul 2007 11:12:38 -0500
Subject: [Rd] problem with findFun call from embedded R
In-Reply-To: <468C0961.9020804@joeconway.com>
References: <468C0961.9020804@joeconway.com>
Message-ID: <468D1876.2030605@vanderbilt.edu>

Joe Conway wrote:
> I was debugging a problem reported to me regarding PL/R, and found that 
> I can duplicate it using only R sources. It might be characterized as 
> possibly a misuse of the findFun() function, but I leave that for the R 
> devel experts to decide.
> 
> The below results are all with R-2.5.1 (I can't seem to download 
> r-patched at the moment, but didn't see anything in the 2.5.1-patched 
> release notes indicating this issue had been noticed) on Fedora Core 6 
> x86_64 (also duplicated with R-2.5.0 on FC7 i386).
> 
> Steps to reproduce:
> 8<------------------------
>   configure, make, make install from source tree
>   cd tests/Embedding/
>   make RNamedCall
>   ./RNamedCall  #works as expected
>   mv foo.R foo.R.orig
>   ./RNamedCall  #segfaults
> 8<------------------------
> 
> output:
> 8<------------------------
> Error in file(file, "r", encoding = encoding) :
>          unable to open connection
> In addition: Warning message:
> cannot open file 'foo.R', reason 'No such file or directory' in: 
> file(file, "r", encoding = encoding)
> Error: could not find function "foo"
> 
>   *** caught segfault ***
> address (nil), cause 'memory not mapped'
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 1
> aborting ...
> Segmentation fault
> 8<------------------------
> 
> The problem comes from RNamedCall starting at line 54:
> 8<------------------------
>    fun = findFun(install("foo"), R_GlobalEnv);
>    if(fun == R_NilValue) {
> 	fprintf(stderr, "No definition for function foo.
>                           Source foo.R and save the session.\n");
>    UNPROTECT(1);
>    exit(1);
>    }
> 8<------------------------
> 
> If foo.R was not found and never sourced, meaning that the object "foo" 
> does not exist, findFun never returns. Instead the segfault occurs at 
> line 719 in errors.c at the LONGJMP statement. Setting a breakpoint at 
> erros.c:719, the backtrace looks like this (will wrap poorly):
> 
> 8<------------------------
> Breakpoint 2, jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE, 
> processWarnings=TRUE, resetConsole=TRUE,
>      ignoreRestartContexts=FALSE) at errors.c:719
> 719         LONGJMP(R_ToplevelContext->cjmpbuf, 0);
> (gdb) bt
> #0  jump_to_top_ex (traceback=TRUE, tryUserHandler=TRUE, 
> processWarnings=TRUE, resetConsole=TRUE,
>      ignoreRestartContexts=FALSE) at errors.c:719
> #1  0x00002aaaaab77e5d in verrorcall_dflt (call=0x609d78, 
> format=0x2aaaaace4a4d "%s", ap=0x7fffa13a94c0)
>      at errors.c:516
> #2  0x00002aaaaab7814a in Rf_errorcall (call=0x609d78, 
> format=0x2aaaaace4a4d "%s") at errors.c:551
> #3  0x00002aaaaab78347 in Rf_error (format=0x2aaaaace42da "could not 
> find function \"%s\"") at errors.c:578
> #4  0x00002aaaaab708e5 in Rf_findFun (symbol=0xc64f20, rho=0x649fa0) at 
> envir.c:1244
> #5  0x0000000000400e0c in bar1 () at RNamedCall.c:54
> #6  0x0000000000400d59 in main (argc=1, argv=0x7fffa13ab838) at 
> RNamedCall.c:16
> 8<------------------------
> 
> And then stepping into line 719 generates the segfault:
> 8<------------------------
> (gdb) s
> 
> Program received signal SIGSEGV, Segmentation fault.
> 0x00002aaaaab701ce in Rf_findVar (symbol=0x6c12b8, rho=0x0) at envir.c:998
> 998         if (TYPEOF(rho) == NILSXP)
> 8<------------------------
> 
> I believe this is happening because findFun() was not executed inside a 
> valid context, and therefore R_ToplevelContext->cjmpbuf is invalid.
> 
> My question is -- is the above an abuse of findFun() by RNamedCall.c 
> (meaning I should avoid the same pattern)? Or maybe it should be wrapped 
> in something similar to R_ToplevelExec?

Yes, when one embeds R, findFun() will call error() which causes the 
longjmp() to the top level, so the embedding application shouldn't use 
findFun().

  Here's what I've written for the next version of RApache. Note that 
it's behavior is slightly different than the original findFun(), in that 
it doesn't search the enclosing environments. (Also, comments welcome as 
the implementation is based on the original, and I'm unsure if promise 
evaluation is needed.)


/* This one doesn't longjmp when function not found */
static SEXP MyfindFun(SEXP symb, SEXP envir){
     SEXP fun;
     SEXPTYPE t;
     fun = findVar(symb,envir);
     t = TYPEOF(fun);

     /* eval promise if need be */
     if (t == PROMSXP){
         int error=1;
         fun = R_tryEval(fun,envir,&error);
         if (error) return R_UnboundValue;
         t = TYPEOF(fun);
     }

     if (t == CLOSXP || t == BUILTINSXP || t == BUILTINSXP || t == 
SPECIALSXP)
         return fun;
     return R_UnboundValue;
}

> 
> ==========================
> 
> On a related note, I found during my PL/R debugging that the segfault 
> was causing the same console based, interactive, "*** caught segfault 
> ***" logic to execute. I was able to confirm that R_Interactive was set 
> to TRUE in my PL/R session.
> 
> It seems that Rf_initEmbeddedR() sets R_Interactive to TRUE and depends 
> on the output of isatty() to change it to FALSE in Rf_initialize_R() if 
> there is no tty. Unfortunately, the most common methods for starting 
> Postgres leave the tty attached (stdout and stderr are directed to the 
> log file). I ended up explicitly writing "R_Interactive = FALSE" just 
> after running Rf_initEmbeddedR() -- is this a safe and reasonable thing 
> to do?
> 
> Thanks,
> 
> Joe
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From 100700.3013 at compuserve.com  Thu Jul  5 13:00:46 2007
From: 100700.3013 at compuserve.com (100700.3013 at compuserve.com)
Date: Thu,  5 Jul 2007 13:00:46 +0200 (CEST)
Subject: [Rd] data messed up by read.table ? (PR#9779)
Message-ID: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>

Full_Name: Joerg Rauh
Version: 2.5.0
OS: Windows 2000
Submission from: (NULL) (84.168.226.163)


Following Michael J. Crawley "Statistical Computing" on page 9 the worms.txt is
required. After downloading it from the book's supporting website, which is 
http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/ I visually check the data
against the book and they look identical. Then I do a read.table as suggested:
worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T).

Typing "worms" to see the data, it's no longer the same: Four lines have been
added to the beginning of the file. One is the header line and three lines are
from further down in the file, i.e. lines 10,11 and 12 in reverse order.
Please look at a copy at the end of this mail. If the first four lines weren't
there, the data would be o.k. I tried different parameter settings in read.table
but couldn't obtain any improvement.

Please let me know, how I can correct this.

Best regards

Joerg

>  worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T)
> worms
          Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
1           Oak.Mead  3.1     2  Grassland     3.9    F            2
2       Church.Field  3.5     3  Grassland     4.2    F            3
3            Ashurst  2.1     0     Arable     4.8    F            4
4         Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
5       Nash's.Field  3.6    11  Grassland     4.1    F            4
6     Silwood.Bottom  5.1     2     Arable     5.2    F            7
7      Nursery.Field  2.8     3  Grassland     4.3    F            2
8        Rush.Meadow  2.4     5     Meadow     4.9    T            5
9   Gunness'.Thicket  3.8     0      Scrub     4.2    F            6
10          Oak.Mead  3.1     2  Grassland     3.9    F            2
11      Church.Field  3.5     3  Grassland     4.2    F            3
12           Ashurst  2.1     0     Arable     4.8    F            4
13       The.Orchard  1.9     0    Orchard     5.7    F            9
14     Rookery.Slope  1.5     4  Grassland       5    T            7
15       Garden.Wood  2.9    10      Scrub     5.2    F            8
16      North.Gravel  3.3     1  Grassland     4.1    F            1
17      South.Gravel  3.7     2  Grassland       4    F            2
18 Observatory.Ridge  1.8     6  Grassland     3.8    F            0
19        Pond.Field  4.1     0     Meadow       5    T            6
20      Water.Meadow  3.9     0     Meadow     4.9    T            8
21         Cheapside  2.2     8      Scrub     4.7    T            4
22        Pound.Hill  4.4     2     Arable     4.5    F            5
23        Gravel.Pit  2.9     1  Grassland     3.5    F            1
24         Farm.Wood  0.8    10      Scrub     5.1    T            3
>


From bill at insightful.com  Thu Jul  5 20:12:39 2007
From: bill at insightful.com (Bill Dunlap)
Date: Thu, 5 Jul 2007 11:12:39 -0700 (PDT)
Subject: [Rd] data messed up by read.table ? (PR#9779)
In-Reply-To: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
References: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
Message-ID: <Pine.GSO.4.56.0707051110120.26524@durian.statsci.com>

On Thu, 5 Jul 2007 100700.3013 at compuserve.com wrote:

> Following Michael J. Crawley "Statistical Computing" on page 9 the worms.txt is
> required. After downloading it from the book's supporting website, which is
> http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/ I visually check the data
> against the book and they look identical. Then I do a read.table as suggested:
> worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T).

Add the argument quote="" or quote="\"" to the call to read.table()
so the apostrophes in the file are not taken to be quotes.

> Typing "worms" to see the data, it's no longer the same: Four lines have been
> added to the beginning of the file. One is the header line and three lines are
> from further down in the file, i.e. lines 10,11 and 12 in reverse order.
> Please look at a copy at the end of this mail. If the first four lines weren't
> there, the data would be o.k. I tried different parameter settings in read.table
> but couldn't obtain any improvement.
>
> Please let me know, how I can correct this.
>
> Best regards
>
> Joerg
>
> >  worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T)
> > worms
>           Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
> 1           Oak.Mead  3.1     2  Grassland     3.9    F            2
> 2       Church.Field  3.5     3  Grassland     4.2    F            3
> 3            Ashurst  2.1     0     Arable     4.8    F            4
> 4         Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
> 5       Nash's.Field  3.6    11  Grassland     4.1    F            4
> 6     Silwood.Bottom  5.1     2     Arable     5.2    F            7
> 7      Nursery.Field  2.8     3  Grassland     4.3    F            2
> 8        Rush.Meadow  2.4     5     Meadow     4.9    T            5
> 9   Gunness'.Thicket  3.8     0      Scrub     4.2    F            6
> 10          Oak.Mead  3.1     2  Grassland     3.9    F            2
> 11      Church.Field  3.5     3  Grassland     4.2    F            3
> 12           Ashurst  2.1     0     Arable     4.8    F            4
> 13       The.Orchard  1.9     0    Orchard     5.7    F            9
> 14     Rookery.Slope  1.5     4  Grassland       5    T            7
> 15       Garden.Wood  2.9    10      Scrub     5.2    F            8
> 16      North.Gravel  3.3     1  Grassland     4.1    F            1
> 17      South.Gravel  3.7     2  Grassland       4    F            2
> 18 Observatory.Ridge  1.8     6  Grassland     3.8    F            0
> 19        Pond.Field  4.1     0     Meadow       5    T            6
> 20      Water.Meadow  3.9     0     Meadow     4.9    T            8
> 21         Cheapside  2.2     8      Scrub     4.7    T            4
> 22        Pound.Hill  4.4     2     Arable     4.5    F            5
> 23        Gravel.Pit  2.9     1  Grassland     3.5    F            1
> 24         Farm.Wood  0.8    10      Scrub     5.1    T            3

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From vdergachev at rcgardis.com  Thu Jul  5 20:16:09 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Thu, 5 Jul 2007 14:16:09 -0400
Subject: [Rd] data messed up by read.table ? (PR#9779)
In-Reply-To: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
References: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
Message-ID: <200707051416.09470.vdergachev@rcgardis.com>

On Thursday 05 July 2007 7:00:46 am 100700.3013 at compuserve.com wrote:
> Full_Name: Joerg Rauh
> Version: 2.5.0
> OS: Windows 2000
> Submission from: (NULL) (84.168.226.163)
>
>
> Following Michael J. Crawley "Statistical Computing" on page 9 the
> worms.txt is required. After downloading it from the book's supporting
> website, which is http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/ I
> visually check the data against the book and they look identical. Then I do
> a read.table as suggested:
> worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T).
>

I see the same effect on 2.5.0 and 2.5.1 running on Linux.

However, the following line reads the data correctly:

read.table('worms.txt', header=TRUE, quote="\"")

Thus the problem is likely because of single quotes in the Field.Name column, 
perhaps a single quote character was added to the list of defaults since the 
book was released.

                     best

                         Vladimir Dergachev


From p.dalgaard at biostat.ku.dk  Thu Jul  5 21:36:15 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 05 Jul 2007 21:36:15 +0200
Subject: [Rd] data messed up by read.table ? (PR#9779)
In-Reply-To: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
References: <20070705110046.EB8E348B6E@slim.kubism.ku.dk>
Message-ID: <468D482F.6000002@biostat.ku.dk>

100700.3013 at compuserve.com wrote:
> Full_Name: Joerg Rauh
> Version: 2.5.0
> OS: Windows 2000
> Submission from: (NULL) (84.168.226.163)
>
>
> Following Michael J. Crawley "Statistical Computing" on page 9 the worms.txt is
> required. After downloading it from the book's supporting website, which is 
> http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/ I visually check the data
> against the book and they look identical. Then I do a read.table as suggested:
> worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T).
>
> Typing "worms" to see the data, it's no longer the same: Four lines have been
> added to the beginning of the file. One is the header line and three lines are
> from further down in the file, i.e. lines 10,11 and 12 in reverse order.
> Please look at a copy at the end of this mail. If the first four lines weren't
> there, the data would be o.k. I tried different parameter settings in read.table
> but couldn't obtain any improvement.
>
> Please let me know, how I can correct this.
>
> Best regards
>
> Joerg
>
>   
>>  worms<-read.table("C:/Programme/R/R-2.5.0/Data/Worms.txt", header = T)
>> worms
>>     
>           Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
> 1           Oak.Mead  3.1     2  Grassland     3.9    F            2
> 2       Church.Field  3.5     3  Grassland     4.2    F            3
> 3            Ashurst  2.1     0     Arable     4.8    F            4
> 4         Field.Name Area Slope Vegetation Soil.pH Damp Worm.density
> 5       Nash's.Field  3.6    11  Grassland     4.1    F            4
> 6     Silwood.Bottom  5.1     2     Arable     5.2    F            7
> 7      Nursery.Field  2.8     3  Grassland     4.3    F            2
> 8        Rush.Meadow  2.4     5     Meadow     4.9    T            5
> 9   Gunness'.Thicket  3.8     0      Scrub     4.2    F            6
> 10          Oak.Mead  3.1     2  Grassland     3.9    F            2
> 11      Church.Field  3.5     3  Grassland     4.2    F            3
> 12           Ashurst  2.1     0     Arable     4.8    F            4
> 13       The.Orchard  1.9     0    Orchard     5.7    F            9
> 14     Rookery.Slope  1.5     4  Grassland       5    T            7
> 15       Garden.Wood  2.9    10      Scrub     5.2    F            8
> 16      North.Gravel  3.3     1  Grassland     4.1    F            1
> 17      South.Gravel  3.7     2  Grassland       4    F            2
> 18 Observatory.Ridge  1.8     6  Grassland     3.8    F            0
> 19        Pond.Field  4.1     0     Meadow       5    T            6
> 20      Water.Meadow  3.9     0     Meadow     4.9    T            8
> 21         Cheapside  2.2     8      Scrub     4.7    T            4
> 22        Pound.Hill  4.4     2     Arable     4.5    F            5
> 23        Gravel.Pit  2.9     1  Grassland     3.5    F            1
> 24         Farm.Wood  0.8    10      Scrub     5.1    T            3
>   
Same thing happens on Linux. It appears to be the single quotes that 
mess things up. Using read.delim(), which is designed to read 
tab-delimitedfiles like this one, works as does setting quote="".


From kristle.krichbaum at gmail.com  Thu Jul  5 21:48:47 2007
From: kristle.krichbaum at gmail.com (kristle.krichbaum at gmail.com)
Date: Thu,  5 Jul 2007 21:48:47 +0200 (CEST)
Subject: [Rd] cor() and cor.test() (PR#9781)
Message-ID: <20070705194847.E007A1C957@slim.kubism.ku.dk>

Hello,

I am trying to make a correlation matrix in R using cor() and also to get
the p-value for each correlation using cor.test().  I can't get these
commands to work. I'm getting errors like the following:

cor(Pollution, Wet.days)
Error in inherits(x, "data.frame") : Object "Wet.days" not found
cor("Pollution", "Wet.days")
Error in cor("Pollution", "Wet.days") : missing observations in cov/cor
In addition: Warning messages:
1: NAs introduced by coercion
2: NAs introduced by coercion

I know that "Wet.days" is there because when I type the name of the data set
(Pollution) it appears. There are no missing values in the data set for
there to be any NAs coerced. This is the example given in Mick Crawley's
book on R with Pollution data so it should definitely work.

Can you help me to get it working, please?
Kristle

-- 
Kristle Krichbaum
Graduate Assistant
Hudson Lab
208 Mueller Lab
University Park, PA 16801
www.cidd.psu.edu

	[[alternative HTML version deleted]]


From Greg.Snow at intermountainmail.org  Thu Jul  5 22:40:09 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 5 Jul 2007 14:40:09 -0600
Subject: [Rd] cor() and cor.test() (PR#9781)
In-Reply-To: <20070705194847.E007A1C957@slim.kubism.ku.dk>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBAAD0F0@LP-EXCHVS07.CO.IHC.COM>

The cor function does not know how to look inside of data frames (unless
you give it the entire data frame as the only argument).  If Pollution
and Wet.days are columns of the data frame named Pollution (which I
infer from your problem statement below) then you can do things like:

> cor(Pollution$Pollution, Pollution$Wed.days)

Or

> cor( Pollution[ ,c('Pollution','Wet.days')] )

Or 

> with( Pollution, cor(Pollution, Wet.days) )

Or 

> attach(Pollution)
> cor(Pollution, Wet.days)
> detach()

The last one may have problems since the data frame has the same name as
the column.  The with option is prefered to the last one anyways.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> kristle.krichbaum at gmail.com
> Sent: Thursday, July 05, 2007 1:49 PM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] cor() and cor.test() (PR#9781)
> 
> Hello,
> 
> I am trying to make a correlation matrix in R using cor() and 
> also to get the p-value for each correlation using 
> cor.test().  I can't get these commands to work. I'm getting 
> errors like the following:
> 
> cor(Pollution, Wet.days)
> Error in inherits(x, "data.frame") : Object "Wet.days" not 
> found cor("Pollution", "Wet.days") Error in cor("Pollution", 
> "Wet.days") : missing observations in cov/cor In addition: 
> Warning messages:
> 1: NAs introduced by coercion
> 2: NAs introduced by coercion
> 
> I know that "Wet.days" is there because when I type the name 
> of the data set
> (Pollution) it appears. There are no missing values in the 
> data set for there to be any NAs coerced. This is the example 
> given in Mick Crawley's book on R with Pollution data so it 
> should definitely work.
> 
> Can you help me to get it working, please?
> Kristle
> 
> --
> Kristle Krichbaum
> Graduate Assistant
> Hudson Lab
> 208 Mueller Lab
> University Park, PA 16801
> www.cidd.psu.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at stat.berkeley.edu  Fri Jul  6 02:40:17 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 5 Jul 2007 17:40:17 -0700
Subject: [Rd] Type on ?heatmap
Message-ID: <59d7961d0707051740v6389f5d9q62b894ede5a38fde@mail.gmail.com>

In ?heatmap (of stats) of R v2.5.1 under the Note section is reads:

"Unless Rowv = NA (or Colw = NA), the original rows and columns are
reordered..."

Typo: 'Colw' should be 'Colv'.

/Henrik


From savicky at cs.cas.cz  Fri Jul  6 12:31:51 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 6 Jul 2007 12:31:51 +0200
Subject: [Rd] Shapiro Test P Value Incorrect? (PR#9768)
In-Reply-To: <20070629205510.2D14529D52@slim.kubism.ku.dk>
References: <20070629205510.2D14529D52@slim.kubism.ku.dk>
Message-ID: <20070706103151.GC29274@cs.cas.cz>

This is not a bug. The algorithm uses different approximation of the
p-value for n=3 (exact value), 4<=n<=11 and n>=12 as seen in 
  src/library/stats/src/swilk.c
below the line 202
 /*  Calculate significance level for W */

The W statistic monotonically decreases in the presented example.

Petr.

> Full_Name: Jason Polak
> Version: R version 2.5.0 (2007-04-23)
> OS: Xubuntu 7.04
> Submission from: (NULL) (137.122.144.35)
> 
> 
> Dear R group,
> 
> I have noticed a strange anomaly with the shapiro.test() function. Unfortunately
> I do not know how to calculate the shapiro test P values manually so I don't
> know if this is an actual bug.
> 
> So, to produce the results, run the following code:
> 
> pvalues = 0;
> for (i in 1:17)
> {
> 	j = 1:(i+3);
> 	pvalues[i]=shapiro.test(j)$p;
> }
> 
> plot(pvalues);
> print(pvalues);
> 
> Now I just made the graph to illustrate that the p-values are strictly
> decreasing. To me this makes intuitive sense: we are using the Shapiro test to
> test normality of (1,2,3,4),(1,2,3,4,5), and so on. So the p-value should
> decrease.
> 
> These are the p-values:
>  [1] 0.9718776 0.9671740 0.9605557 0.9492892 0.9331653 0.9135602 0.8923668
>  [8] 0.8698419 0.8757315 0.8371814 0.7964400 0.7545289 0.7123167 0.6704457
> [15] 0.6294307 0.5896464 0.5513749
> 
> However, there is an increase in p-value when you go from (1,..,11) to
> (1,..,12). Is this just a quirk of the Shapiro test, or is there an error in the
> calculation algorithm?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From whinev at gmail.com  Fri Jul  6 12:57:20 2007
From: whinev at gmail.com (Ev Whin)
Date: Fri, 6 Jul 2007 18:57:20 +0800
Subject: [Rd] How to disable R's C stack checking
Message-ID: <dfed1c180707060357y334a8397kd58e0e40b6b1ffed@mail.gmail.com>

Hi all,

I'm developing an application on Mac OS X Darwin which embeds R.
However, the application always crashes due to the C stack checking.
I know that R_CStackLimit can be set to -1 to disable the stack
checking, but I don't know where to put the code "R_CStackLimit=-1".

Please give some instructions.
Thank you very much!

Here is my compiler infomation:

$g++ -v
Using built-in specs.
Target: i686-apple-darwin8
Configured with: /private/var/tmp/gcc/gcc-5367.obj~1/src/configure
--disable-checking -enable-werror --prefix=/usr --mandir=/share/man
--enable-languages=c,objc,c++,obj-c++
--program-transform-name=/^[cg][^.-]*$/s/$/-4.0/
--with-gxx-include-dir=/include/c++/4.0.0 --with-slibdir=/usr/lib
--build=powerpc-apple-darwin8 --with-arch=nocona --with-tune=generic
--program-prefix= --host=i686-apple-darwin8
--target=i686-apple-darwin8
Thread model: posix
gcc version 4.0.1 (Apple Computer, Inc. build 5367)

My machine infomation:

$uname -a
Darwin xi-imac 8.9.1 Darwin Kernel Version 8.9.1

Whin.


From phgrosjean at sciviews.org  Fri Jul  6 15:15:20 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 06 Jul 2007 15:15:20 +0200
Subject: [Rd] Hook for running a function before evaluation
Message-ID: <468E4068.8020203@sciviews.org>

Hello,
I like much addTaskCallback() and friends. However, there are situations 
were we would like to have a function run BEFORE, not after every 
top-level tasks. I think specifically to reset options(width = ) to 
accommodate to the current width of the console, using something like:

options(width = system("tput cols"))

I am sure there are many other situations where this could be useful. 
Combining tasks run before and after evaluation, one could design a 
system to (remotely) indicate when a given R kernel is 
starting/evaluating/ending evaluation of some code (with Rpad in mind, 
for instance).

How difficult would it be to implement such Tasks run before top-level ones?

Best,

Philippe
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................


From ripley at stats.ox.ac.uk  Fri Jul  6 16:46:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Jul 2007 15:46:07 +0100 (BST)
Subject: [Rd] Shapiro Test P Value Incorrect? (PR#9768)
In-Reply-To: <20070706103151.GC29274@cs.cas.cz>
References: <20070629205510.2D14529D52@slim.kubism.ku.dk>
	<20070706103151.GC29274@cs.cas.cz>
Message-ID: <Pine.LNX.4.64.0707061358550.28289@gannet.stats.ox.ac.uk>

On Fri, 6 Jul 2007, Petr Savicky wrote:

> This is not a bug. The algorithm uses different approximation of the
> p-value for n=3 (exact value), 4<=n<=11 and n>=12 as seen in
>  src/library/stats/src/swilk.c
> below the line 202
> /*  Calculate significance level for W */
>
> The W statistic monotonically decreases in the presented example.

The crucial piece missing from the help page (but in the references) is 
that (at least some of) the approximations used are only claimed to be 
adequate for p < 0.1.  I've added a line to that effect.

> Petr.
>
>> Full_Name: Jason Polak
>> Version: R version 2.5.0 (2007-04-23)
>> OS: Xubuntu 7.04
>> Submission from: (NULL) (137.122.144.35)
>>
>>
>> Dear R group,
>>
>> I have noticed a strange anomaly with the shapiro.test() function. Unfortunately
>> I do not know how to calculate the shapiro test P values manually so I don't
>> know if this is an actual bug.
>>
>> So, to produce the results, run the following code:
>>
>> pvalues = 0;
>> for (i in 1:17)
>> {
>> 	j = 1:(i+3);
>> 	pvalues[i]=shapiro.test(j)$p;
>> }
>>
>> plot(pvalues);
>> print(pvalues);
>>
>> Now I just made the graph to illustrate that the p-values are strictly
>> decreasing. To me this makes intuitive sense: we are using the Shapiro test to
>> test normality of (1,2,3,4),(1,2,3,4,5), and so on. So the p-value should
>> decrease.
>>
>> These are the p-values:
>>  [1] 0.9718776 0.9671740 0.9605557 0.9492892 0.9331653 0.9135602 0.8923668
>>  [8] 0.8698419 0.8757315 0.8371814 0.7964400 0.7545289 0.7123167 0.6704457
>> [15] 0.6294307 0.5896464 0.5513749
>>
>> However, there is an increase in p-value when you go from (1,..,11) to
>> (1,..,12). Is this just a quirk of the Shapiro test, or is there an error in the
>> calculation algorithm?
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mail at joeconway.com  Fri Jul  6 19:35:41 2007
From: mail at joeconway.com (Joe Conway)
Date: Fri, 06 Jul 2007 10:35:41 -0700
Subject: [Rd] problem with findFun call from embedded R
In-Reply-To: <468D1876.2030605@vanderbilt.edu>
References: <468C0961.9020804@joeconway.com> <468D1876.2030605@vanderbilt.edu>
Message-ID: <468E7D6D.1040604@joeconway.com>

Jeffrey Horner wrote:
> Joe Conway wrote:
>> I was debugging a problem reported to me regarding PL/R, and found 
>> that I can duplicate it using only R sources. It might be 
>> characterized as possibly a misuse of the findFun() function, but I 
>> leave that for the R devel experts to decide.

>> My question is -- is the above an abuse of findFun() by RNamedCall.c 
>> (meaning I should avoid the same pattern)? Or maybe it should be 
>> wrapped in something similar to R_ToplevelExec?

> Yes, when one embeds R, findFun() will call error() which causes the 
> longjmp() to the top level, so the embedding application shouldn't use 
> findFun().

OK, thanks for the confirmation. I just wonder if RNamedCall.c ought to 
be changed then...

>  Here's what I've written for the next version of RApache. Note that 
> it's behavior is slightly different than the original findFun(), in that 
> it doesn't search the enclosing environments. (Also, comments welcome as 
> the implementation is based on the original, and I'm unsure if promise 
> evaluation is needed.)
> 
> 
> /* This one doesn't longjmp when function not found */
> static SEXP MyfindFun(SEXP symb, SEXP envir){

Yes, if I patch RNamedCall.c with the attached (based on your function), 
everything seems to work.

Thanks,

Joe


-------------- next part --------------
A non-text attachment was scrubbed...
Name: myfindfun.diff
Type: text/x-patch
Size: 667 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070706/caba9bd9/attachment.bin 

From mail at joeconway.com  Fri Jul  6 19:40:05 2007
From: mail at joeconway.com (Joe Conway)
Date: Fri, 06 Jul 2007 10:40:05 -0700
Subject: [Rd] problem with findFun call from embedded R
In-Reply-To: <7098abec0707041734m7d22ca6dq462af2c1c5d47acc@mail.gmail.com>
References: <468C0961.9020804@joeconway.com>
	<7098abec0707041734m7d22ca6dq462af2c1c5d47acc@mail.gmail.com>
Message-ID: <468E7E75.30003@joeconway.com>

Byron Ellis wrote:
> Yeah, setting R_Interactive is probably fine.

Great -- thanks for the confirmation.

> As to the findFun issue,
> there is a much more useful function (findVar1 maybe?) that wouldn't
> die if the object didn't exist.

OK, I'll poke around R sources some more. The function provided by 
Jeffrey Horner on a nearby post seems to work well too.

Thanks,

Joe


From mail at joeconway.com  Fri Jul  6 20:07:36 2007
From: mail at joeconway.com (Joe Conway)
Date: Fri, 06 Jul 2007 11:07:36 -0700
Subject: [Rd] problem with findFun call from embedded R
In-Reply-To: <468E7D6D.1040604@joeconway.com>
References: <468C0961.9020804@joeconway.com> <468D1876.2030605@vanderbilt.edu>
	<468E7D6D.1040604@joeconway.com>
Message-ID: <468E84E8.3090703@joeconway.com>

Joe Conway wrote:
> 
> Yes, if I patch RNamedCall.c with the attached (based on your function), 
> everything seems to work.

Sorry -- I managed to mess up that patch. This one should be better.

Joe
-------------- next part --------------
A non-text attachment was scrubbed...
Name: myfindfun.diff
Type: text/x-patch
Size: 1484 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070706/d1e5ef91/attachment.bin 

From byron.ellis at gmail.com  Fri Jul  6 21:05:01 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Fri, 6 Jul 2007 12:05:01 -0700
Subject: [Rd] Hook for running a function before evaluation
In-Reply-To: <468E4068.8020203@sciviews.org>
References: <468E4068.8020203@sciviews.org>
Message-ID: <7098abec0707061205p579157b3w64b55dd7c84e14a2@mail.gmail.com>

Hi Philippe,

This is exactly the approach being taken in RExecServer (which is in
turn possibly connected to front ends via distributed objects). It's
an OS X app so the model is

my_ReadConsole(...) {
 didFinishEvaluationForInterpreter(...);
 internalReadConsole(...); (usually start the run loop and wait for an
appropriate event)
 willBeginEvaluationForInterpreter(...);
}

technically there should also be shouldBeginEvaluationforInterpreter()
to let us bail out of evaluation and head back to the reader loop.

http://repo.or.cz/w/RExecServer.git

On 7/6/07, Philippe Grosjean <phgrosjean at sciviews.org> wrote:
> Hello,
> I like much addTaskCallback() and friends. However, there are situations
> were we would like to have a function run BEFORE, not after every
> top-level tasks. I think specifically to reset options(width = ) to
> accommodate to the current width of the console, using something like:
>
> options(width = system("tput cols"))
>
> I am sure there are many other situations where this could be useful.
> Combining tasks run before and after evaluation, one could design a
> system to (remotely) indicate when a given R kernel is
> starting/evaluating/ending evaluation of some code (with Rpad in mind,
> for instance).
>
> How difficult would it be to implement such Tasks run before top-level ones?
>
> Best,
>
> Philippe
> --
> ..............................................<?}))><........
>   ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>   ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>   ) ) ) ) )   Mons-Hainaut University, Belgium
> ( ( ( ( (
> ..............................................................
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From phgrosjean at sciviews.org  Fri Jul  6 23:31:54 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 06 Jul 2007 23:31:54 +0200
Subject: [Rd] Hook for running a function before evaluation
In-Reply-To: <7098abec0707061205p579157b3w64b55dd7c84e14a2@mail.gmail.com>
References: <468E4068.8020203@sciviews.org>
	<7098abec0707061205p579157b3w64b55dd7c84e14a2@mail.gmail.com>
Message-ID: <468EB4CA.6030804@sciviews.org>

Hi Byron,

Excellent! I am also on OS X (together with Win XP and Quantian using 
Parallels desktop ;-)

So far, so good, I have the latest RExecServer running in a terminal. 
So, what can I do with it?
Best,

Philippe

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

Byron Ellis wrote:
> Hi Philippe,
> 
> This is exactly the approach being taken in RExecServer (which is in
> turn possibly connected to front ends via distributed objects). It's
> an OS X app so the model is
> 
> my_ReadConsole(...) {
> didFinishEvaluationForInterpreter(...);
> internalReadConsole(...); (usually start the run loop and wait for an
> appropriate event)
> willBeginEvaluationForInterpreter(...);
> }
> 
> technically there should also be shouldBeginEvaluationforInterpreter()
> to let us bail out of evaluation and head back to the reader loop.
> 
> http://repo.or.cz/w/RExecServer.git
> 
> On 7/6/07, Philippe Grosjean <phgrosjean at sciviews.org> wrote:
>> Hello,
>> I like much addTaskCallback() and friends. However, there are situations
>> were we would like to have a function run BEFORE, not after every
>> top-level tasks. I think specifically to reset options(width = ) to
>> accommodate to the current width of the console, using something like:
>>
>> options(width = system("tput cols"))
>>
>> I am sure there are many other situations where this could be useful.
>> Combining tasks run before and after evaluation, one could design a
>> system to (remotely) indicate when a given R kernel is
>> starting/evaluating/ending evaluation of some code (with Rpad in mind,
>> for instance).
>>
>> How difficult would it be to implement such Tasks run before top-level 
>> ones?
>>
>> Best,
>>
>> Philippe
>> -- 
>> ..............................................<?}))><........
>>   ) ) ) ) )
>> ( ( ( ( (    Prof. Philippe Grosjean
>>   ) ) ) ) )
>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>>   ) ) ) ) )   Mons-Hainaut University, Belgium
>> ( ( ( ( (
>> ..............................................................
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From byron.ellis at gmail.com  Sat Jul  7 02:16:17 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Fri, 6 Jul 2007 17:16:17 -0700
Subject: [Rd] Hook for running a function before evaluation
In-Reply-To: <468EB4CA.6030804@sciviews.org>
References: <468E4068.8020203@sciviews.org>
	<7098abec0707061205p579157b3w64b55dd7c84e14a2@mail.gmail.com>
	<468EB4CA.6030804@sciviews.org>
Message-ID: <7098abec0707061716w5822cdd5r1da3fc303e6a5843@mail.gmail.com>

Running from the Terminal, it acts as a simple shim for people who
would prefer to use the Terminal or a terminal-like interface such as
ESS. It provides a pretty basic graphics device implementation with a
full event loop (without requiring CarbonEL or other workarounds) in
that mode. That graphics device is also technically capable (though it
doesn't actually write the file at the moment) of writing to a variety
of bitmap formats as well as Quicktime movies without having to
involve X11. You can also route PDF, though the built-in PDF device
will likely give you smaller files.

It's under heavy development (see http://statcomp.blogspot.com) at the
moment so some things don't work often because there is an
aqua-specific thing that needs to happen (viewing help for example)
that we don't actually want to reroute away from the terminal (suspect
functions usually contain if(Platform$GUI...) at the top). I'll get
those all sorted out sooner rather than later.

However, the real power and, I hope, primary use, isn't from the
Terminal---although you can do some cute things like copy objects
between any instance (they call themselves "R Execution Server 1," "R
Execution Server 2" and so on or take a name you provide via
environment variables). Each of the instances, unless told otherwise,
is actually vending itself as a Distributed Object that can be
attached from another process.

The first client is obviously a standard R GUI (again, see the site
above for a screenshot) that can run more than one instance of R at a
time much the same way you'd just run from multiple xterms or what
have you. It'll feel like a single GUI and have all of the current
GUI's features w.r.t. script editing and so on. You'll just have more
than one Console (this was actually Stefano's idea. I just wanted to
see if it would work. :-) ).

It's a pretty similar model to Simon's JGR stuff in spirit at least,
though IIRC that is all still be running in the same process whereas
Distributed Objects do not necessarily even need to be on the same
machine. So, maybe a cross between Rserve and JGR then. :-)

So far I'm actually quite surprised how quickly its come together.

On 7/6/07, Philippe Grosjean <phgrosjean at sciviews.org> wrote:
> Hi Byron,
>
> Excellent! I am also on OS X (together with Win XP and Quantian using
> Parallels desktop ;-)
>
> So far, so good, I have the latest RExecServer running in a terminal.
> So, what can I do with it?
> Best,
>
> Philippe
>
> ..............................................<?}))><........
>   ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>   ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>   ) ) ) ) )   Mons-Hainaut University, Belgium
> ( ( ( ( (
> ..............................................................
>
> Byron Ellis wrote:
> > Hi Philippe,
> >
> > This is exactly the approach being taken in RExecServer (which is in
> > turn possibly connected to front ends via distributed objects). It's
> > an OS X app so the model is
> >
> > my_ReadConsole(...) {
> > didFinishEvaluationForInterpreter(...);
> > internalReadConsole(...); (usually start the run loop and wait for an
> > appropriate event)
> > willBeginEvaluationForInterpreter(...);
> > }
> >
> > technically there should also be shouldBeginEvaluationforInterpreter()
> > to let us bail out of evaluation and head back to the reader loop.
> >
> > http://repo.or.cz/w/RExecServer.git
> >
> > On 7/6/07, Philippe Grosjean <phgrosjean at sciviews.org> wrote:
> >> Hello,
> >> I like much addTaskCallback() and friends. However, there are situations
> >> were we would like to have a function run BEFORE, not after every
> >> top-level tasks. I think specifically to reset options(width = ) to
> >> accommodate to the current width of the console, using something like:
> >>
> >> options(width = system("tput cols"))
> >>
> >> I am sure there are many other situations where this could be useful.
> >> Combining tasks run before and after evaluation, one could design a
> >> system to (remotely) indicate when a given R kernel is
> >> starting/evaluating/ending evaluation of some code (with Rpad in mind,
> >> for instance).
> >>
> >> How difficult would it be to implement such Tasks run before top-level
> >> ones?
> >>
> >> Best,
> >>
> >> Philippe
> >> --
> >> ..............................................<?}))><........
> >>   ) ) ) ) )
> >> ( ( ( ( (    Prof. Philippe Grosjean
> >>   ) ) ) ) )
> >> ( ( ( ( (    Numerical Ecology of Aquatic Systems
> >>   ) ) ) ) )   Mons-Hainaut University, Belgium
> >> ( ( ( ( (
> >> ..............................................................
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From Mark.Bravington at csiro.au  Sat Jul  7 03:10:39 2007
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Sat, 7 Jul 2007 11:10:39 +1000
Subject: [Rd] rbind.data.frame: bug?
Message-ID: <D79013E40FEF254AAF0D72DFC94F2748545BAF@extas4-hba.tas.csiro.au>

Consider the following, which is new behaviour under R 2.5+:

> df1 <- data.frame( x=2, y='cat')
> df2 <- data.frame( x=3, y='dog')
> rbind( df1[-1,], df2)$y == rbind( df1, df2)[-1,]$y
Error in Ops.factor(rbind(df1[-1, ], df2)$y, rbind(df1,  : 
        Level sets of factors are different
        
To me this seems illogical; it shouldn't matter whether you remove the first row of the data.frame before or after augmenting the rows (and didn't, in R prior to v2.5). And there's more!

> levels( rbind( df1[-1,], df2)$y)
[1] "dog"

> levels( rbind( df1[-1,], df2[-1,])$y)
[1] "cat"

but why should rbind suddenly acknowledge the levels of its first argument in the second case and not the first?

If the data.frames have more than one row, these issue don't arise; they occur because (as the documentation says) "The 'rbind' data frame method first drops all zero-column and zero-row arguments.  (If that leaves none, it returns the first argument with columns otherwise a zero-column zero-row data
     frame.)...". So this behaviour is documented-- but isn't it nevertheless a bug?

>From the release notes, I gather that the new zero-row-stripping behaviour was introduced to get round a specific problem with 0*0 data.frames. Given the above, though, wouldn't it be preferable to just include special code to deal with the 0*0 case, leaving 0*N cases unaffected?

Mark Bravington


From jeff.horner at vanderbilt.edu  Sat Jul  7 05:48:54 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 06 Jul 2007 22:48:54 -0500
Subject: [Rd] R graphics device for flash apps
Message-ID: <468F0D26.9040603@vanderbilt.edu>

Byron,

I just read your blog (statcomp.blogspot.com, linked from your other 
post) and rand across your idea of an R/Flash graphics device. I've also 
been giving this some thought because of this amazing interactive flash app:

http://tools.google.com/gapminder

and others from http://www.gapminder.org/.

I would love more than anything to work on this. The only hitch is that 
I'm so booked up with work (not to mention a new RApache release soon) 
that I don't have the time. And believe me, getting even minimal 
functionality to work, like 2D images with pop-ups labels and such... 
would be a tremendous development effort. Not to mention trying to keep 
up with an implementation for different OS's and flash player versions.

So I have questions for the R development community:

1. Are there others interested in this? Is anyone working on an 
implementation? If not, is it too niche to even consider doing?

2. Could a project like this obtain funding, any kind, not just academic?

3. How does the community feel about a closed-source version?
There are other closed-source packages available for R (the only one I 
know of is xlsReadWrite), so it seems to be a reasonable question.

Comments, criticisms, flames... are all welcome. Email me off-list if 
you'd like.

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From byron.ellis at gmail.com  Sat Jul  7 06:17:02 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Fri, 6 Jul 2007 21:17:02 -0700
Subject: [Rd] R graphics device for flash apps
In-Reply-To: <468F0D26.9040603@vanderbilt.edu>
References: <468F0D26.9040603@vanderbilt.edu>
Message-ID: <7098abec0707062117p6c02a033w611ca20f22a3a592@mail.gmail.com>

Hi Jeffrey,

On 7/6/07, Jeffrey Horner <jeff.horner at vanderbilt.edu> wrote:
> Byron,
>
> I just read your blog (statcomp.blogspot.com, linked from your other
> post) and rand across your idea of an R/Flash graphics device. I've also
> been giving this some thought because of this amazing interactive flash app:
>
> http://tools.google.com/gapminder
>
> and others from http://www.gapminder.org/.

Ah, yes. Gotta love Hans Rosling (the guy can swallow swords too!).
:-) When I proposed the idea I was thinking more of the Adobe Flex
sort of applications where you're pushing more static graphics as SWF
through to the Flash side of things. If you poke around Google Video
for the Developer's Day stuff, one of the Flex guys had some nice
graphs in a Flex application. He was showing off Gears and it was a
pretty trivial CRM application, but you can imagine R coming into play
pretty easily.

>
> I would love more than anything to work on this. The only hitch is that
> I'm so booked up with work (not to mention a new RApache release soon)
> that I don't have the time. And believe me, getting even minimal

Yeah, I know the feeling. The RExecServer stuff I've been doing has
been an extra-curricular activity just to do some different
programming for a bit. Probably when I finally make the commits I've
been threatening for a month now into the Bioconductor repository. :-)

> functionality to work, like 2D images with pop-ups labels and such...
> would be a tremendous development effort. Not to mention trying to keep
> up with an implementation for different OS's and flash player versions.

I think the best way to start would be implementing the traditional
graphics device to push SWF. My thought that a lot of the gadgetry
would be done by the UI designer folks and that the R generated stuff
would be piped in by a surrounding Flash application. After that would
come adding non-traditional elements to the plots, likely via another
interface. I think Ming would probably be able to handle it, but
compilation is non-trivial making portability difficult.

>
> So I have questions for the R development community:
>
> 1. Are there others interested in this? Is anyone working on an
> implementation? If not, is it too niche to even consider doing?
>
> 2. Could a project like this obtain funding, any kind, not just academic?

Good question. My guess is that it would be fundamentally tied to #3.
(I wouldn't have high hopes for academic funding though...) But, hey,
who knows? Only one way to find out I suppose.

>
> 3. How does the community feel about a closed-source version?
> There are other closed-source packages available for R (the only one I
> know of is xlsReadWrite), so it seems to be a reasonable question.
>
> Comments, criticisms, flames... are all welcome. Email me off-list if
> you'd like.
>
> Jeff
> --
> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From dsterling at abac.com  Sat Jul  7 23:44:36 2007
From: dsterling at abac.com (dsterling at abac.com)
Date: Sat,  7 Jul 2007 23:44:36 +0200 (CEST)
Subject: [Rd] Minor bug in lillie.test from nortest package (PR#9784)
Message-ID: <20070707214436.1583E48CF8@slim.kubism.ku.dk>

Full_Name: David Sterling
Version: 2.4.0
OS: OS X
Submission from: (NULL) (64.81.102.199)


lillie.test() dies without grace producing the error message: 'Error in if
(pvalue > 0.1) { : missing value where TRUE/FALSE needed' when passed a vector
of identical values.

Examples:
> lillie.test(c(0,0,0,0,0,0,0,0,0,0))
Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
> lillie.test(c(1,1,1,1,1,1,1,1,1,1))
Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
> lillie.test(c(1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1))
Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
> 

I see that the package maintainer is Juergen Gross, but I am new to R and I
haven't figured out how to contact him directly.  

Thanks,
David


From ligges at statistik.uni-dortmund.de  Mon Jul  9 10:40:56 2007
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Mon,  9 Jul 2007 10:40:56 +0200 (CEST)
Subject: [Rd] Minor bug in lillie.test from nortest package (PR#9784)
Message-ID: <20070709084056.4C85A485BF@slim.kubism.ku.dk>

dsterling at abac.com wrote:
> Full_Name: David Sterling
> Version: 2.4.0

For bug reports please try the most recent version of R (which currently 
is either R-2.5.1 or R-devel if you are really enthusiastic).
But please never send a bug report for a contributed (non-base) package 
to R-bugs, but always to the package maintainer.
Since you already found out that Juergen Gross is maintaining the 
package, there are several ways to find his e-mail address, the most 
easiest one is to type
   library(help=nortest)
which tells you the maintainer's address.
CCing to Juergen ...

Uwe Ligges




> OS: OS X
> Submission from: (NULL) (64.81.102.199)
> 
> 
> lillie.test() dies without grace producing the error message: 'Error in if
> (pvalue > 0.1) { : missing value where TRUE/FALSE needed' when passed a vector
> of identical values.
> 
> Examples:
>> lillie.test(c(0,0,0,0,0,0,0,0,0,0))
> Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
>> lillie.test(c(1,1,1,1,1,1,1,1,1,1))
> Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
>> lillie.test(c(1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1.1))
> Error in if (pvalue > 0.1) { : missing value where TRUE/FALSE needed
> 
> I see that the package maintainer is Juergen Gross, but I am new to R and I
> haven't figured out how to contact him directly.  
> 
> Thanks,
> David
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From osklyar at ebi.ac.uk  Mon Jul  9 10:54:02 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 09 Jul 2007 09:54:02 +0100
Subject: [Rd] 'inline' package supports Fortran, .C calls etc
Message-ID: <4691F7AA.7030300@ebi.ac.uk>

Dear developers,

Duncan and me have just finished the update of the 'inline' package,
which latest version (0.3.2) is now on CRAN. In addition to the previous
update that featured saving and loading cfunction objects with
recompiling the code, the current release supports recompiling the code
 in setCMethod on load, different calling conventions (.C, .Call,
.Fortan) and allows to inline not only C, but also Fortran and
ObjectiveC (needs testing) code, it performs clean up of all temp files
created during compilation etc.

Best,
Oleg
-- 
Dr Oleg Sklyar * EBI/EMBL, Cambridge CB10 1SD, England * +44-1223-494466


From ggrothendieck at gmail.com  Mon Jul  9 14:41:54 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 9 Jul 2007 08:41:54 -0400
Subject: [Rd] Problem with {
Message-ID: <971536df0707090541k1e638ed3vd41089af9dd3f83e@mail.gmail.com>

Why does the error get generated here?  Is it a bug?  It seems that
f and "{" are the same but when used in sapply f works but { does not.
Is its use in lapply really "an incorrect context"?

> f <- function(x, y) y
> f(1, 2)
[1] 2
> "{"(1, 2)
[1] 2
> lapply("y", function(x, y) y, 1:4) # ok
[[1]]
[1] 1 2 3 4
> lapply("y", "{", 1:4) # error
Error in lapply("y", "{", 1:4) : '...' used in an incorrect context
> R.version.string # XP
[1] "R version 2.5.1 (2007-06-27)"

See:

https://www.stat.math.ethz.ch/pipermail/r-help/2007-July/135999.html

for a variation of the lapply using sapply (which also has the same
problem if one uses { instead of f).


From Peter.Ruckdeschel at uni-bayreuth.de  Mon Jul  9 14:58:41 2007
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Mon, 09 Jul 2007 14:58:41 +0200
Subject: [Rd] BLAS / LAPACK version information from within R-session?
Message-ID: <46923101.4020608@uni-bayreuth.de>

Hi,

for diagnostic purposes, I would like to get information about
the BLAS / LAPACK linked against R from within an R-session.

An obvious application could be safety-checks for packages like
Matrix and quantreg at load / attach - time.

Also you could be more precise on the "framework" in which R
is running for comparable benchmark timings on different systems.

Perhaps this information may even be included into the output
of R.Version() :-) ?

So my question:

    Is this possible/reasonable at all?

My impression is that it is not trivial, as you may ---at least
on Win32--- even replace the standard Rblas.dll by some of the
"better" Rblas.dll 's available on

  http://cran.at.r-project.org/bin/windows/contrib/ATLAS/

without telling R in any way before launching R.


In the (Win32) case I imagine you could read out the

      StringFileInfo

of the Rblas.dll being used --- which, for the time
being, however, does not yet contain information on
the BLAS version. But a (mid term) solution could be:

(1) For building Rblas.dll from source, extend

    src/gnuwin/dllversion.rc

from the standard R tar-ball to a new ressource file, say,

 src/gnuwin/blasdllversion.rc

including version information on BLAS/LAPACK which is then
used for building Rblas.dll.

(2) Successively replace files from

  http://cran.at.r-project.org/bin/windows/contrib/ATLAS/

by ones built against blasdllversion.rc



Unfortunately, I have no idea whether/how you could use information
similar to StringFileInfo in other OS's ...

Any suggestions appreciated.

Best,
Peter Ruckdeschel


From spluque at gmail.com  Mon Jul  9 14:59:15 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 09 Jul 2007 07:59:15 -0500
Subject: [Rd] packages using UTF-8 encoding
Message-ID: <874pkdn36k.fsf@patagonia.sebmags.homelinux.org>

Hi,

During a recent CRAN upload procedure, I was reminded of the following
regarding R-devel:


    o   R CMD check now warns on non-ASCII .Rd files without an
        \encoding field, rather than just on ones that are definitely
        not from an ISO-8859 encoding.  This agrees with the
        long-standing stipulation in 'Writing R Extensions', and
        catches some packages with UTF-8 man pages.

    o   R CMD check now warns on DESCRIPTION files with a non-portable
        Encoding field, or with non-ASCII data and no Encoding field.


So if we need UTF-8 encoding for the DESCRIPTION and *.Rd files, would it
be sufficient to have an "Encoding: UTF-8" line in the former and a
"\encoding{UTF-*}" in the latter?  Thanks.


Cheers,

-- 
Seb


From ripley at stats.ox.ac.uk  Mon Jul  9 15:23:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jul 2007 14:23:17 +0100 (BST)
Subject: [Rd] packages using UTF-8 encoding
In-Reply-To: <874pkdn36k.fsf@patagonia.sebmags.homelinux.org>
References: <874pkdn36k.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <Pine.LNX.4.64.0707091408270.19965@gannet.stats.ox.ac.uk>

On Mon, 9 Jul 2007, Sebastian P. Luque wrote:

> Hi,
>
> During a recent CRAN upload procedure, I was reminded of the following
> regarding R-devel:
>
>
>    o   R CMD check now warns on non-ASCII .Rd files without an
>        \encoding field, rather than just on ones that are definitely
>        not from an ISO-8859 encoding.  This agrees with the
>        long-standing stipulation in 'Writing R Extensions', and
>        catches some packages with UTF-8 man pages.
>
>    o   R CMD check now warns on DESCRIPTION files with a non-portable
>        Encoding field, or with non-ASCII data and no Encoding field.
>
>
> So if we need UTF-8 encoding for the DESCRIPTION and *.Rd files, would it
> be sufficient to have an "Encoding: UTF-8" line in the former and a
> "\encoding{UTF-*}" in the latter?  Thanks.

\encoding(UTF-8}, yes.

However, I would be worried about anything which 'needs' UTF-8 encoding, 
since it is going to be far from portable.  If all you need are characters 
from ISO-8859-1, it is more portable to use that.

My current understanding is that the internationalization/charset support
works well on Windows, MacOS X, systems using glibc (e.g. Linux), FreeBSD 
and some commercial Unixen.  The thing that does not work well is fonts to 
display the non-ASCII characters, where glyphs are often silently omitted.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Mon Jul  9 15:44:58 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 09 Jul 2007 15:44:58 +0200
Subject: [Rd] Problem with {
In-Reply-To: <971536df0707090541k1e638ed3vd41089af9dd3f83e@mail.gmail.com>
References: <971536df0707090541k1e638ed3vd41089af9dd3f83e@mail.gmail.com>
Message-ID: <46923BDA.3070303@biostat.ku.dk>

Gabor Grothendieck wrote:
> Why does the error get generated here?  Is it a bug?  It seems that
> f and "{" are the same but when used in sapply f works but { does not.
> Is its use in lapply really "an incorrect context"?
>
>   
>> f <- function(x, y) y
>> f(1, 2)
>>     
> [1] 2
>   
>> "{"(1, 2)
>>     
> [1] 2
>   
>> lapply("y", function(x, y) y, 1:4) # ok
>>     
> [[1]]
> [1] 1 2 3 4
>   
>> lapply("y", "{", 1:4) # error
>>     
> Error in lapply("y", "{", 1:4) : '...' used in an incorrect context
>   
lapply() is not really  part of the problem:

> (function(x,...) "{"(x,...))(1,2)
Error in (function(x, ...) { : '...' used in an incorrect context

Not sure exactly why this is so, but "{" has somewhat nonstandard
evaluation semantics and you cannot do
"{x, ...}" either, nor for that matter  x <- function(...)...; x(2),
which gives off a similar error.


>> R.version.string # XP
>>     
> [1] "R version 2.5.1 (2007-06-27)"
>
> See:
>
> https://www.stat.math.ethz.ch/pipermail/r-help/2007-July/135999.html
>
> for a variation of the lapply using sapply (which also has the same
> problem if one uses { instead of f).
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From spluque at gmail.com  Mon Jul  9 15:57:45 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 09 Jul 2007 08:57:45 -0500
Subject: [Rd] packages using UTF-8 encoding
References: <874pkdn36k.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0707091408270.19965@gannet.stats.ox.ac.uk>
Message-ID: <87zm25llwm.fsf@patagonia.sebmags.homelinux.org>

On Mon, 9 Jul 2007 14:23:17 +0100 (BST),
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

[...]

> \encoding(UTF-8}, yes.

Oops, yes (shift key pressed longer than needed).


> However, I would be worried about anything which 'needs' UTF-8 encoding,
> since it is going to be far from portable.  If all you need are
> characters from ISO-8859-1, it is more portable to use that.

Right, this is for accents in some spanish/french words.  I was thinking
of UTF-8 since that's my current locale, but that's probably irrelevant
for setting these directives here (accents).  So if ISO-8859-1 is more
portable, I think latin1 should be fine in this case.  Thanks.


-- 
Seb


From elw at stderr.org  Mon Jul  9 16:56:45 2007
From: elw at stderr.org (elw at stderr.org)
Date: Mon, 9 Jul 2007 09:56:45 -0500 (CDT)
Subject: [Rd] Planet R - a weblog aggregator for statistical computing
Message-ID: <Pine.LNX.4.64.0707051542220.9568@illuminati.stderr.org>


Announcing...

Planet R - a weblog aggregator for statistical computing

Q: What is it?

A: An aggregator for weblog posts about statistical computing topics,
    focused primarily around the R community.

Q2: Where is it?

A2: For now, at http://planetr.stderr.org

Q3: What's it good for?

A3: Hopefully, collecting resources and weblog posts from people who might
     otherwise not know about each other.  Community-building, you see?

Q4: How do I get my stuff on there?

A4: Send mail to elw at stderr.org, with a representative subject line (e.g.
     'please add to planet r' will be fine..); I'll need the link to the
     RSS feed of your blog or other resource.  If you'd like a personal
     icon in the style of Planet Debian or Planet Gnome (or one of those
     other planetplanet-based sites..) feel free to send along a smallish
     picture or icon as well. (Think 80-by-80 pixels...)

Q5: What sort of things are there?

A5: A selection of weblogs about statistical computing, a feed from
     omegahat, some bioconductor-related content, feeds from a couple of
     journals (including JoSS content, as a subset of the J Computational
     and Graphical Statistics, as well as Royal Statistical Society
     content sourced from IngentaConnect...), the changes feed from the R
     Wiki, and a few other things of great utility to the R community.


Please feel free to contact me directly with further content, media, 
suggestions, et cetera, that you think would enhance the utility of this 
site as a resource to the community.


thanks,

--elijah wright
indiana university bloomington
school of library and information science


From bolker at ufl.edu  Mon Jul  9 18:30:23 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 9 Jul 2007 16:30:23 +0000 (UTC)
Subject: [Rd] sweep sanity checking?
References: <468579C0.7090809@zoo.ufl.edu>
Message-ID: <loom.20070709T175233-590@post.gmane.org>

Ben Bolker <bolker <at> zoo.ufl.edu> writes:

>   What would R-core think of the following 'enhanced'
> sweep?  

 (now posted at
http://wiki.r-project.org/rwiki/doku.php?id=rdoc:base:sweep
)

It always warns if dim(x)[MARGIN] is
> not a multiple of length(STATS) {it's very hard indeed
> for me to think of a situation where you'd actually
> want this}; if check.margin=TRUE it is a bit stricter,
> complaining whenever dim(x)[MARGIN] doesn't
> match length(STATS).
> 
>   This change seems fairly harmless since it never does anything
> more than warn; the default for check.margin could
> be FALSE if you wanted to allow people a bit more rope
> to hang themselves with ...  (of course this won't prevent
> you from sweeping the wrong margin of a square matrix,
> but nothing will).
> 
>   cheers
>     Ben Bolker
> 

  Enough time has now passed that I feel justified following up
on this.  Does anyone have any opinions on it, one way or the other?

  Ben


From ggrothendieck at gmail.com  Mon Jul  9 20:58:11 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 9 Jul 2007 14:58:11 -0400
Subject: [Rd] Problem with {
In-Reply-To: <46923BDA.3070303@biostat.ku.dk>
References: <971536df0707090541k1e638ed3vd41089af9dd3f83e@mail.gmail.com>
	<46923BDA.3070303@biostat.ku.dk>
Message-ID: <971536df0707091158jecf74f9k62aae889fa430a0e@mail.gmail.com>

Just one additional observation.  { does work with mapply:

> f <- function(x, y) y
> mapply(f, letters, 1:26)
 a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y  z
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
> mapply("{", letters, 1:26) # same
 a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y  z
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26


On 7/9/07, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
> Gabor Grothendieck wrote:
> > Why does the error get generated here?  Is it a bug?  It seems that
> > f and "{" are the same but when used in sapply f works but { does not.
> > Is its use in lapply really "an incorrect context"?
> >
> >
> >> f <- function(x, y) y
> >> f(1, 2)
> >>
> > [1] 2
> >
> >> "{"(1, 2)
> >>
> > [1] 2
> >
> >> lapply("y", function(x, y) y, 1:4) # ok
> >>
> > [[1]]
> > [1] 1 2 3 4
> >
> >> lapply("y", "{", 1:4) # error
> >>
> > Error in lapply("y", "{", 1:4) : '...' used in an incorrect context
> >
> lapply() is not really  part of the problem:
>
> > (function(x,...) "{"(x,...))(1,2)
> Error in (function(x, ...) { : '...' used in an incorrect context
>
> Not sure exactly why this is so, but "{" has somewhat nonstandard
> evaluation semantics and you cannot do
> "{x, ...}" either, nor for that matter  x <- function(...)...; x(2),
> which gives off a similar error.
>
>
> >> R.version.string # XP
> >>
> > [1] "R version 2.5.1 (2007-06-27)"
> >
> > See:
> >
> > https://www.stat.math.ethz.ch/pipermail/r-help/2007-July/135999.html
> >
> > for a variation of the lapply using sapply (which also has the same
> > problem if one uses { instead of f).
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>


From khansen at stat.Berkeley.EDU  Tue Jul 10 05:26:56 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 9 Jul 2007 20:26:56 -0700
Subject: [Rd] cleanup and Makevars
Message-ID: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>

Hi

This is a question prompted by the mac version of R, but as I see it,  
it should have broader interest.

These days the CRAN Mac binary per default compiles every package for  
two architectures. First i386 and then ppc. In between the two  
compilation runs, any object files in pkgname/src is removed. This  
cleanup is necessary since otherwise Make would not recompile the  
object files under the next architecture.

I have a package which includes a large SDK which I have put in
   src/fusion_sdk
(and subdirectories). I take care of that by using a Makevars file  
with essentially (the whole Makevars file is reproduced below)

PKG_SOURCES = \
         fusion_sdk/calvin_files/data/src/CDFData.cpp

OBJS=$(PKG_SOURCES:.cpp=.o)

all: $(SHLIB)

However, this setup does not remove the object files in the  
fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek  
I learned that I need to clean up these directories myself.

I have - per R extensions - attempted to do so using a pkgname/ 
cleanup script. While this works for cleaning up the sub directories  
when I do R CMD build, it seems as if this script is not being run  
between compilation runs (is this intentional btw.?).

So my question is now: how do I in a simple way clean up my  
subdirectories? I would prefer it to be as simple as possible because  
so far I have not really needed anything besides a Makevars file. In  
fact the impression I have right now from looking at the SHLIB and  
INSTALL scripts is that I might need a Makefile that removes the  
object files _before_ starting the compilation, as I don't really see  
any cleanup process (eg. making a target clean) - but this may very  
well be due to my limited understanding of these scripts.

Any help/hints on how to proceed? Especially if I want it to be  
portable?

Kasper

The full Makevars file:

MYCXXFLAGS=-O0

%.o: %.cpp
	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@

PKG_CPPFLAGS=\
-imacros R_affx_constants.h\
-Ifusion_sdk/calvin_files/array/src\
-Ifusion_sdk/calvin_files/data/src\
-Ifusion_sdk/calvin_files/exception/src\
-Ifusion_sdk/calvin_files/fusion/src\
-Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
-Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
-Ifusion_sdk/calvin_files/parameter/src\
-Ifusion_sdk/calvin_files/parsers/src\
-Ifusion_sdk/calvin_files/portability/src\
-Ifusion_sdk/calvin_files/template/src\
-Ifusion_sdk/calvin_files/utils/src\
-Ifusion_sdk/calvin_files/writers/src\
-Ifusion_sdk/file\
-Ifusion_sdk/portability\
-D_USE_MEM_MAPPING_

PKG_SOURCES = \
	fusion_sdk/calvin_files/data/src/CDFData.cpp\
	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
	fusion_sdk/calvin_files/data/src/CELData.cpp\
	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
	fusion_sdk/calvin_files/data/src/DataSet.cpp\
	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
	fusion_sdk/calvin_files/data/src/GenericData.cpp\
	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/ 
CalvinCELDataAdapter.cpp\
	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.cpp\
	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
	fusion_sdk/calvin_files/utils/src/checksum.cpp\
	fusion_sdk/file/BPMAPFileData.cpp\
	fusion_sdk/file/BPMAPFileWriter.cpp\
	fusion_sdk/file/CDFFileData.cpp\
	fusion_sdk/file/CELFileData.cpp\
	fusion_sdk/file/FileIO.cpp\
	fusion_sdk/file/FileWriter.cpp\
	R_affx_cel_parser.cpp\
	R_affx_cdf_parser.cpp\
	R_affx_cdf_extras.cpp\
	R_affx_bpmap_parser.cpp

OBJS=$(PKG_SOURCES:.cpp=.o)

all: $(SHLIB)


From ripley at stats.ox.ac.uk  Tue Jul 10 08:02:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jul 2007 07:02:50 +0100 (BST)
Subject: [Rd] BLAS / LAPACK version information from within R-session?
In-Reply-To: <46923101.4020608@uni-bayreuth.de>
References: <46923101.4020608@uni-bayreuth.de>
Message-ID: <Pine.LNX.4.64.0707091405370.19965@gannet.stats.ox.ac.uk>

AFAIK all platforms by default work the same: they use dynamic libraries 
for BLAS and LAPACK, and these may well be symbolic links.  I know of no 
way to ask a BLAS dynamic library what version it is.

On Mon, 9 Jul 2007, Peter Ruckdeschel wrote:

> Hi,
>
> for diagnostic purposes, I would like to get information about
> the BLAS / LAPACK linked against R from within an R-session.
>
> An obvious application could be safety-checks for packages like
> Matrix and quantreg at load / attach - time.

Why should that be needed?  Those packages assume they are talking to 
working dynamic libraries, and there is no way to check that a particular 
library works (it might work when compiled under gcc 4.1.2 and not under 
4.2.0, to take a non-random example).

> Also you could be more precise on the "framework" in which R
> is running for comparable benchmark timings on different systems.
>
> Perhaps this information may even be included into the output
> of R.Version() :-) ?

I can think of more worthy candidates, e.g. the compilers used to build R, 
and for Linux something more precise about the distro used.  Remember that 
for most R users the BLAS/LAPACK speed is not very important: it 
only matters where linear algebra dominates the computations.  If I run R 
CMD check over CRAN with an optimized BLAS the speedup is barely 
noticeable (but I do get more failures).

> So my question:
>
>    Is this possible/reasonable at all?
>
> My impression is that it is not trivial, as you may ---at least
> on Win32--- even replace the standard Rblas.dll by some of the
> "better" Rblas.dll 's available on
>
>  http://cran.at.r-project.org/bin/windows/contrib/ATLAS/
>
> without telling R in any way before launching R.
>
>
> In the (Win32) case I imagine you could read out the
>
>      StringFileInfo
>
> of the Rblas.dll being used --- which, for the time
> being, however, does not yet contain information on
> the BLAS version. But a (mid term) solution could be:
>
> (1) For building Rblas.dll from source, extend
>
>    src/gnuwin/dllversion.rc
>
> from the standard R tar-ball to a new ressource file, say,
>
> src/gnuwin/blasdllversion.rc
>
> including version information on BLAS/LAPACK which is then
> used for building Rblas.dll.
>
> (2) Successively replace files from
>
>  http://cran.at.r-project.org/bin/windows/contrib/ATLAS/
>
> by ones built against blasdllversion.rc
>
>
>
> Unfortunately, I have no idea whether/how you could use information
> similar to StringFileInfo in other OS's ...
>
> Any suggestions appreciated.
>
> Best,
> Peter Ruckdeschel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cbaenzig at mines.edu  Tue Jul 10 03:38:12 2007
From: cbaenzig at mines.edu (cbaenzig at mines.edu)
Date: Tue, 10 Jul 2007 03:38:12 +0200 (CEST)
Subject: [Rd] Plot dies with memory not mapped (segfault) (PR#9785)
Message-ID: <20070710013812.B866155A4E@slim.kubism.ku.dk>

Full_Name: Clay B
Version: 2.5.0 (2007-04-23)
OS: Solaris Nevada Build 55b
Submission from: (NULL) (65.101.229.198)


I find that running this script causes R to segfault reliably. However, running
just for one system at a time (modifying the for loop updating iter to run just
for a system at a time works). The system is a Sun W2100z with 12 GB of ram, and
R segfaults using only around 360 MB of ram. I can include MySQL output fed to
the script on request, but it's usually for failure data around a max of 1,000
data points in the "failureQuery", and less than 30,000 for "usageQuery". I can
generate a core if desired too.

------------------------ begin traceback
------------------------------------------
s> source("SysVUserTime.R")
Loading required package: DBI

 *** caught segfault ***
address f9, cause 'memory not mapped'

Traceback:
 1: axis(side = side, at = at, labels = labels, ...)
 2: Axis.default(...)
 3: Axis(...)
 4: localAxis(x, side = 1, ...)
 5: plot.default(g$fit, g$res, xlab = "Fitted", ylab = "Residuals")
 6: plot(g$fit, g$res, xlab = "Fitted", ylab = "Residuals")
 7: eval.with.vis(expr, envir, enclos)
 8: eval.with.vis(ei, envir)
 9: source("SysVUserTime.R")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 3
------------------------- end traceback
-------------------------------------------

------------------------ begin script
---------------------------------------------
#Connects to database
library(RMySQL)
library(chron)

CLAY_CLASS<-TRUE
PIE_CHARTS<-FALSE
BOXPLOTS<-TRUE
PLOTTING<-TRUE
OUTPUT_TEXT<-FALSE
ACF_PLOT<-TRUE
query_dates<-c("Year","Quarter","Month","Week")

oldpar <- par(no.readonly = TRUE)
drv <- dbDriver("MySQL")
con <- dbConnect(drv, user="macs370",dbname="lanl",password="macs370")
systems<-c("s8_usage_clean","s15_usage_clean","s16_usage_clean","s23_usage_clean","s20_usage_node_num_cpu")
systemNum<-c("8","15","16","23","20")

# Query for each system
for (iter in 1:length(systems)) {
#for (iter in 5:5) {
        rm(dat,res,IQR_Stats,userStatTimes,cors,data)
        if(OUTPUT_TEXT!=TRUE)
        { sink(paste("/export/MACS370_project/Image/SysVUserTime/CorrelationsSys",systemNum[iter],".TXT",sep=""))
}
        if(PIE_CHARTS==TRUE) {
                for (iter in 1:length(systems)) {
                        X11()
                        res<- dbSendQuery(con, paste("SELECT
SUM(cpu_seconds_user)/SUM(total_time), SUM(cpu_seconds_system)/SUM(total_time)
FROM ",systems[iter],";",sep=""))
                        dat<- fetch(res,n=-1)
                        data<-rbind(dat[,1],dat[,2])
                        pie(data,labels=c("User","System"),main=paste("System
vs. User Time for System ",systemNum[iter],"by",QUERY_DATE,sep=""))
                }
        }

# Query for each date segmentation
for(k in 1:length(query_dates)) {
#for(k in 4:4) {
#for(k in 2:2) {
QUERY_DATE<-query_dates[k]
        
        userTime<-NULL
        failures<-NULL

# Date Clamp Limits Us To The Middle 80% Of All Data
usageDateClamp<-paste(" WHERE FROM_UNIXTIME(submit_time) >= (SELECT ",
                "FROM_UNIXTIME(MIN(submit_time)) + INTERVAL 0.10*",
                "DATEDIFF(MAX(FROM_UNIXTIME(submit_time)),MIN(FROM_UNIXTIME(",
                "submit_time))) DAY FROM ",systems[iter],") AND
FROM_UNIXTIME(",
                "submit_time) <= (SELECT FROM_UNIXTIME(MAX(submit_time)) - ",
                "INTERVAL 0.10*DATEDIFF(MAX(FROM_UNIXTIME(submit_time)),MIN(",
                "FROM_UNIXTIME(submit_time))) DAY FROM ",systems[iter],") ",
                sep="")
failureDateClamp<-paste(" AND prob_start_date >= (SELECT ",
                "FROM_UNIXTIME(MIN(submit_time)) + INTERVAL 0.10*",
                "DATEDIFF(MAX(FROM_UNIXTIME(submit_time)),MIN(FROM_UNIXTIME(",
                "submit_time))) DAY FROM ",systems[iter],") ",
                "AND prob_start_date <= (SELECT ",
                "FROM_UNIXTIME(MAX(submit_time)) - INTERVAL 0.10*",
                "DATEDIFF(MAX(FROM_UNIXTIME(submit_time)),MIN(FROM_UNIXTIME(",
                "submit_time))) DAY FROM ",systems[iter],") ",sep="")

        if(QUERY_DATE=="Year") {
                usageAVGQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d') AS
date, AVG(cpu_seconds_user/total_time) AS time, AVG(num_cpus) AS AVG_CPUs,
AVG(dispatch_time-end_time) AS AVG_job_length FROM
",systems[iter],usageDateClamp,"GROUP BY date;",sep="")
                usageQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d') AS
date, cpu_seconds_user/total_time AS time FROM ",systems[iter],"
",usageDateClamp,";",sep="")
                if(CLAY_CLASS=="TRUE") {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(clay_class='Interconnect' OR clay_class='Disk' OR
clay_class='Memory' OR clay_class='Networking, Machine Access' OR
clay_class='Shared Storage',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-01-01'),'%Y-%m-%d') as date FROM
failure_data WHERE system=",systemNum[iter],failureDateClamp," GROUP BY date) as
tbl ON tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d');",sep="")
                } else {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(hw_desc!='',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-01-01'),'%Y-%m-%d') as date FROM
failure_data WHERE system=",systemNum[iter],failureDateClamp," GROUP BY date) as
tbl ON tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-01-01'),'%Y-%m-%d');",sep="")
                }
        } else if(QUERY_DATE=="Quarter") {
                usageAVGQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d')
AS date, AVG(cpu_seconds_user/total_time) AS time, AVG(num_cpus) AS AVG_CPUs,
AVG(dispatch_time-end_time) AS AVG_job_length FROM
",systems[iter],usageDateClamp,"GROUP BY date;",sep="")
                usageQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d')
AS date, cpu_seconds_user/total_time AS time FROM
",systems[iter],usageDateClamp,";",sep="")
#               failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(clay_class='Interconnect' OR clay_class='Disk' OR
clay_class='Memory' OR clay_class='Networking, Machine Access' OR
clay_class='Shared Storage',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-',QUARTER(prob_start_date)*3,'-01'),'%Y-%m-%d')
as date FROM failure_data WHERE system=",systemNum[iter],failureDateClamp,"
GROUP BY date) as tbl ON
tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d');",sep="")
                failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(hw_desc!='',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-',QUARTER(prob_start_date)*3,'-01'),'%Y-%m-%d')
as date FROM failure_data WHERE system=",systemNum[iter],failureDateClamp,"
GROUP BY date) as tbl ON
tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',QUARTER(FROM_UNIXTIME(dispatch_time))*3,'-01'),'%Y-%m-%d');",sep="")

        } else if(QUERY_DATE=="Month") {
                usageAVGQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d')
AS date, AVG(cpu_seconds_user/total_time) AS time, AVG(num_cpus) AS AVG_CPUs,
AVG(dispatch_time-end_time) AS AVG_job_length FROM
",systems[iter],usageDateClamp," GROUP BY date;",sep="")
                usageQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d')
AS date, cpu_seconds_user/total_time AS time FROM
",systems[iter],usageDateClamp,";",sep="")
                if(CLAY_CLASS=="TRUE") {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(clay_class='Interconnect' OR clay_class='Disk' OR
clay_class='Memory' OR clay_class='Networking, Machine Access' OR
clay_class='Shared Storage',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-',MONTH(prob_start_date),'-01'),'%Y-%m-%d')
as date FROM failure_data WHERE system=",systemNum[iter],failureDateClamp,"
GROUP BY date) as tbl ON
tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d');",sep="")
                } else {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d'))
AS date, if(tbl.probs is NULL,0,tbl.probs) FROM ",systems[iter]," LEFT JOIN
(SELECT SUM(if(hw_desc!='',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEAR(prob_start_date),'-',MONTH(prob_start_date),'-01'),'%Y-%m-%d')
as date FROM failure_data WHERE system=",systemNum[iter],failureDateClamp,"
GROUP BY date) as tbl ON
tbl.date=STR_TO_DATE(CONCAT(YEAR(FROM_UNIXTIME(dispatch_time)),'-',MONTH(FROM_UNIXTIME(dispatch_time)),'-01'),'%Y-%m-%d');",sep="")
                }

        } else if(QUERY_DATE=="Week") {
                usageAVGQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),' Monday'), '%X%V %W')
AS date, AVG(cpu_seconds_user/total_time) AS time, AVG(num_cpus) AS AVG_CPUs,
AVG(dispatch_time-end_time) AS AVG_job_length FROM
",systems[iter],usageDateClamp," GROUP BY date;",sep="")
                usageQuery<-paste("SELECT
STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),' Monday'), '%X%V %W')
AS date, cpu_seconds_user/total_time AS time FROM
",systems[iter],usageDateClamp,";",sep="")
#               failureQuery<- paste("SELECT
STR_TO_DATE(CONCAT(YEARWEEK(prob_start_date), ' Monday'),'%X%V %W') as date,
count(*)/(SELECT count(*) FROM failure_data WHERE
system=",systemNum[iter],failureDateClamp,") AS probs FROM failure_data WHERE
system=",systemNum[iter]," AND hw_desc!='' GROUP BY date;",sep="")
                if(CLAY_CLASS=="TRUE") {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),'
Monday'),'%X%V %W')) AS date, if(tbl.probs is NULL,0,tbl.probs) FROM
",systems[iter]," LEFT JOIN (SELECT SUM(if(clay_class='Interconnect' OR
clay_class='Disk' OR clay_class='Memory' OR clay_class='Networking, Machine
Access' OR clay_class='Shared Storage',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEARWEEK(prob_start_date),' Monday'),'%X%V %W') as date FROM
failure_data WHERE system=",systemNum[iter],failureDateClamp," AND
end_time>=(SELECT MIN(dispatch_time) FROM ",systems[iter],") AND
start_time<=(SELECT MAX(dispatch_time) FROM ",systems[iter],") GROUP BY date) as
tbl ON tbl.date=STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),'
Monday'),'%X%V %W');",sep="")
                } else {
                        failureQuery<-paste("SELECT
DISTINCT(STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),'
Monday'),'%X%V %W')) AS date, if(tbl.probs is NULL,0,tbl.probs) FROM
",systems[iter]," LEFT JOIN (SELECT SUM(if(hw_desc!='',1,0)) AS probs,
STR_TO_DATE(CONCAT(YEARWEEK(prob_start_date),' Monday'),'%X%V %W') as date FROM
failure_data WHERE system=",systemNum[iter],failureDateClamp," AND
end_time>=(SELECT MIN(dispatch_time) FROM ",systems[iter],") AND
start_time<=(SELECT MAX(dispatch_time) FROM ",systems[iter],") GROUP BY date) as
tbl ON tbl.date=STR_TO_DATE(CONCAT(YEARWEEK(FROM_UNIXTIME(dispatch_time)),'
Monday'),'%X%V %W');",sep="")
                }
        }
        print(paste("Querying for system",systems[iter]))
        print(paste("Usage Query:",usageQuery,sep=""))
        res<- dbSendQuery(con, usageQuery)
        dat<- fetch(res,n=-1)
        userTime<-cbind(as.Date(dat[,1]),dat[,2])

        print(paste("Usage AVG Query:",usageAVGQuery,sep=""))
        res<- dbSendQuery(con, usageAVGQuery)
        userAVGs<- fetch(res,n=-1)

        print(paste("Failure Query:",failureQuery,sep=""))
        res<- dbSendQuery(con, failureQuery)
        dat<- fetch(res,n=-1)
        failures<-cbind(as.Date(dat[,1]),dat[,2])
        #Scale Failures To Have a Range Of 0-1
        failures[,2]<-failures[,2]/range(failures[,2][!is.na(failures[,2])])[2]

        IQR_stats<-boxplot(split(userTime[,2],userTime[,1]),plot=FALSE)
        userStatTimes<-rbind(IQR_stats$names,IQR_stats$stats)

        png(paste("/export/MACS370_project/Image/SysVUserTime/user_time_box",systems[iter],"by",QUERY_DATE,".png",sep=""),height=1000,width=1000)
        if(BOXPLOTS==TRUE && PLOTTING==TRUE)
        {
                par(bg="cornsilk",new=T)
                print("Boxplot...")
                boxplot(split(userTime[,2],as.Date(dates(userTime[,1]))),style="tukey",main=paste("Plot
of userTime as a percentage of
totalTime\nSystem",systemNum[iter],sep=""),xlim=as.Date(dates(range(userTime[,1]))),ylim=c(0,1),lwd=.5,plot=TRUE)
                points(failures[,2],type="p",col=4,cex=10,pch=4,ylim=c(0,1))
                dev.off()
                par(oldpar)
        # No Boxplots
        } else if (PLOTTING==TRUE) {
                par(bg="cornsilk",new=T)
                print("Plotting...")
                plot(as.Date(dates(failures[,1])),failures[,2],main=paste("Plot
of userTime as a percentage of
totalTime\nSystem",systemNum[iter],sep=""),xlim=as.Date(dates(range(userTime[,1]))),ylim=c(0,1),lwd=.5,type="p",col=4,cex=3,pch=4)
                points(failures,col=4,cex=3,pch=4,ylim=c(0,1))
                print("Getting IQR...")
                lines(userStatTimes[1,],userStatTimes[2,],xlim=as.Date(dates(range(userTime[,1]))),lwd=1)
                lines(userStatTimes[1,],userStatTimes[3,],xlim=as.Date(dates(range(userTime[,1]))),lwd=1)
                lines(userStatTimes[1,],userStatTimes[4,],xlim=as.Date(dates(range(userTime[,1]))),lwd=1)
                lines(userStatTimes[1,],userStatTimes[5,],xlim=as.Date(dates(range(userTime[,1]))),lwd=1)
                lines(userStatTimes[1,],userStatTimes[6,],xlim=as.Date(dates(range(userTime[,1]))),lwd=1)
                abline(h=mean(as.numeric(userStatTimes[2,])),lwd=1,lty=4)
                abline(h=mean(as.numeric(userStatTimes[3,])),lwd=1,lty=4)
                abline(h=mean(as.numeric(userStatTimes[4,])),lwd=1,lty=4)
                abline(h=mean(as.numeric(userStatTimes[5,])),lwd=1,lty=4)
                abline(h=mean(as.numeric(userStatTimes[6,])),lwd=1,lty=4)
                dev.off()
                par(oldpar)
        }
        print(paste("----- Correlation by:",QUERY_DATE,"For
system",systems[iter],"-----"))

        png(paste("/export/MACS370_project/Image/SysVUserTime/user_time_diff_",systems[iter],"by",QUERY_DATE,".png",sep=""),height=1000,width=1000)
        # Small Regression V. Diff(UserTime)
        cors<-cbind(c(diff(userAVGs[,2]),NA),dat[,2])
        cors<-cbind(cors[,1][!is.na(cors[,1])],cors[,2][!is.na(cors[,1])])
        cors<-cbind(cors[,1][!is.na(cors[,2])],cors[,2][!is.na(cors[,2])])
        colnames(cors)<-c("UserTime AVG Diffs","Failures")
        
        print(cor(cors))
        print(paste("Num. Obs.:",length(cors[,1])))
        
        # Test to cut out s15 yearly avg diffs. (only one data point)
        if(dim(cors)[1]>2) {
        
        # From the R Graph Gallery:
        # http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=137
        panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
        {
            usr <- par("usr"); on.exit(par(usr))
            par(usr = c(0, 1, 0, 1))
            r <- abs(cor(x, y))
            txt <- format(c(r, 0.123456789), digits=digits)[1]
            txt <- paste(prefix, txt, sep="")
            if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
    
            test <- cor.test(x,y)
            # borrowed from printCoefmat
            Signif <- symnum(test$p.value, corr = FALSE, na = FALSE,
                          cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                          symbols = c("***", "**", "*", ".", " "))
            
            text(0.5, 0.5, txt, cex = cex * r)
            text(.8, .8, Signif, cex=cex, col=2)
        }
        pairs(cors, lower.panel=panel.smooth,
upper.panel=panel.cor,main=paste("System",systems[iter],"by",QUERY_DATE))
        dev.off()

        png(paste("/export/MACS370_project/Image/SysVUserTime/user_time_",systems[iter],"by",QUERY_DATE,".png",sep=""),height=1000,width=1000)
        # Big Correlation V. UserTime, NumCPU, Job Len.
        cors<-cbind(userAVGs[,2],userAVGs[,3],userAVGs[,4],dat[,2])
        cors<-cbind(cors[,1][!is.na(cors[,1])],cors[,2][!is.na(cors[,1])],cors[,3][!is.na(cors[,1])],cors[,4][!is.na(cors[,1])])
        cors<-cbind(cors[,1][!is.na(cors[,4])],cors[,2][!is.na(cors[,4])],cors[,3][!is.na(cors[,4])],cors[,4][!is.na(cors[,4])])
        colnames(cors)<-c("UserTime AVGs","Num CPU AVGs","Job Len.
AVGs","Failures")
        print(cor(cors))
        print(paste("Num. Obs.:",length(cors[,1])))
        # From the R Graph Gallery:
        # http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=137
        panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
        {
            usr <- par("usr"); on.exit(par(usr))
            par(usr = c(0, 1, 0, 1))
            r <- abs(cor(x, y))
            txt <- format(c(r, 0.123456789), digits=digits)[1]
            txt <- paste(prefix, txt, sep="")
            if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
    
            test <- cor.test(x,y)
            # borrowed from printCoefmat
            Signif <- symnum(test$p.value, corr = FALSE, na = FALSE,
                          cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                          symbols = c("***", "**", "*", ".", " "))
            
            text(0.5, 0.5, txt, cex = cex * r)
            text(.8, .8, Signif, cex=cex, col=2)
        }
        pairs(cors, lower.panel=panel.smooth,
upper.panel=panel.cor,main=paste("System",systems[iter],"by",QUERY_DATE))
        }
        dev.off()
        if(ACF_PLOT==TRUE) {
                print("ACF plots")
                x11()
                cors<-cbind(userAVGs[,3],dat[,2])
                cors<-cbind(cors[,1][!is.na(cors[,1])],cors[,2][!is.na(cors[,1])])
                cors<-cbind(cors[,1][!is.na(cors[,2])],cors[,2][!is.na(cors[,2])])
                colnames(cors)<-c("UserTime AVG","Failures")
                acf(cors,main=paste("ACF for
system",systemNum[iter]),ci.type="ma",ci=.05)
                dev.copy(png,file=(paste("/export/MACS370_project/Image/SysVUserTime/ACF_",systems[iter],".png")))
                dev.off()
        }
        g <- lm(cors[,2] ~ cors[,1])
        plot(g$fit,g$res,xlab="Fitted",ylab="Residuals")
        abline(h=0)
        plot(g$fit,abs(g$res),xlab="Fitted",ylab="|Residuals|")
        summary(lm(abs(g$res)~g$fit))
}
if(OUTPUT_TEXT!=TRUE)
{ sink() }
}
dbDisconnect(con)
------------------------- end script


From sapsi at pobox.com  Tue Jul 10 17:41:13 2007
From: sapsi at pobox.com (Saptarshi Guha)
Date: Tue, 10 Jul 2007 11:41:13 -0400
Subject: [Rd] How to preserve data across function calls in a library package
Message-ID: <6F70270F-4DF1-4D34-8444-FCBF8F035030@pobox.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070710/11bf0ee4/attachment.pl 

From sapsi at pobox.com  Tue Jul 10 18:33:26 2007
From: sapsi at pobox.com (Saptarshi Guha)
Date: Tue, 10 Jul 2007 12:33:26 -0400
Subject: [Rd] [R] How to preserve data across function calls in a
	library package
In-Reply-To: <6F70270F-4DF1-4D34-8444-FCBF8F035030@pobox.com>
References: <6F70270F-4DF1-4D34-8444-FCBF8F035030@pobox.com>
Message-ID: <A00673FA-F462-4CD4-8D3C-03DE3B9CC2C6@pobox.com>

Hi,
	Some progress: I am using
	SEXP retty;
	book=Calloc(1,int);
	*book=10;
	PROTECT(retty=R_MakeExternalPtr(book,R_NilValue,R_NilValue));
	
	then UNPROTECTING and returning retty.

	In a another function,
	foo(SEXP s){
	 int* f=(int *)R_ExternalPtrAddr(p);
	 Rprintf("many times %d\n",*f);	
}

	When called do_foo(p) where do_foo calls foo and p is the pointer  
returned by the former code snippet, the Rprintf successfully prints  
the correct value but subsequently crashes
*** caught bus error ***
address 0x0, cause 'invalid alignment'.

	I can't figure out why... I would appreciate any advice provided.
	Rgds
	Saptarshi




On Jul 10, 2007, at 11:41 AM, Saptarshi Guha wrote:

> Hi,
> 	I am writing an R package with two functions in C++. So far
> everything works.
> 	Now, i would like to write a third function which would use a pointer
> (it is a pointer to a class object) created by first function.
> 	I tried placing this pointer outside of the function definitions
> (i.e to make it global) but when called in the 3rd function i get
>> 	 *** caught bus error ***
> address 0x0, cause 'invalid alignment'"
>
> 	I tried Callocing it in the 1st function but to no avail. Here is a
> quick summary. When foo is called (through do_foo, **after** having
> called do_kNN_e) i get the aforementioned error.
> 	Can anyone provide some pointers (no pun intended) on this?
>
> 	Thanks
> 	Saptarshi
>
> ANN* book;
> int* foot;
>
> void foo(void){
>    Rprintf("many times\n");
>    Rprintf("%p\n",book);
>    Rprintf("%p\n",foot);
> }
>
> SEXP
> kNN_e(SEXP data, SEXP Nrow, SEXP Ncol,SEXP K,SEXP Eps)
> {
>    int nrow=asInteger(Nrow);
>    int ncol=asInteger(Ncol);
>    int k=asInteger(K);
>    double eps=asReal(Eps);
>
>    SEXP ans,distance;
>    SEXP retlist;
>    PROTECT(ans=allocMatrix(INTSXP,nrow,k)); //The 2nd argument gives
> the number of rows, and the last the number of cols see http://cran.r-
> project.org/doc/manuals/R-exts.html
>    PROTECT(distance=allocMatrix(REALSXP,nrow,k));
>    ANNpointArray datapoints;
>    ANNpoint qpoint;
>    ANNkd_tree* kdTree;
>    book=Calloc(1,ANN*);
>    foot=Calloc(1,int);
>    book=kdTree;
>   *foot=10;
>
>   .......
> }
>
> extern "C" {
>    void do_foo(void){
>      foo();
>    }
>
> SEXP
> do_kNN_e(SEXP data, SEXP Nrow, SEXP Ncol,SEXP k,SEXP eps)
> {
>    return kNN_e(data,Nrow, Ncol,
> 	     k,eps);
>
> }
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
Would you people stop playing these stupid games?!?!?!!!!


From jason at acm.org  Tue Jul 10 19:58:45 2007
From: jason at acm.org (Jason Riedy)
Date: Tue, 10 Jul 2007 10:58:45 -0700
Subject: [Rd] BLAS / LAPACK version information from within R-session?
References: <46923101.4020608@uni-bayreuth.de>
	<Pine.LNX.4.64.0707091405370.19965@gannet.stats.ox.ac.uk>
Message-ID: <87myy45eei.fsf@nan.sparse.dyndns.org>

And Brian Ripley writes:
> I know of no way to ask a BLAS dynamic library what version it
> is.

Tinkering with the BLAS interface hasn't fared so well, but
LAPACK 3.1 added an ILAVER subroutine that returns the major,
minor, and patch level versions for LAPACK itself.

>> An obvious application could be safety-checks for packages
>> like Matrix and quantreg at load / attach - time.
>
> Why should that be needed?

To warn of bugs in specific LAPACK versions, perhaps.  I know I
let a couple of embarassing typos merge into 3.1.0 with the
eigenvalue drivers.  The ones I know of so far only affect
performance, but there may be another that leads to an unreported
error.  Looks like R makes DSYEVR available through eigen.R, so
it's affected.  Sorry.

And I know prior LAPACK versions have some painful error cases.
They seem to impact few people, so having the LAPACK version in
related bug reports may help remove those causes.

>> Perhaps this information may even be included into the output
>> of R.Version() :-) ?
>
> I can think of more worthy candidates, e.g. the compilers used
> to build R, and for Linux something more precise about the
> distro used.

Alas, yes, those could be very useful with the resurgence of
funny arithmetics.

Jason


From jjonphl at gmail.com  Wed Jul 11 06:41:39 2007
From: jjonphl at gmail.com (miguel manese)
Date: Wed, 11 Jul 2007 12:41:39 +0800
Subject: [Rd] Getting param names of primitives
Message-ID: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>

Hi,

In the latest R this does not work anymore

args <- formals(log)

because log is primitive. Is there any other way to get the argument
list? I just need the name of the parameter to display some error
message about it. I have looked at args() but I can't find anything to
extract the argument names from it.

Thanks,
M. Manese


From ripley at stats.ox.ac.uk  Wed Jul 11 06:48:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jul 2007 05:48:56 +0100 (BST)
Subject: [Rd] Getting param names of primitives
In-Reply-To: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>

> formals(args(log))
$x


$base
exp(1)

gives what formals(log) used to.

On Wed, 11 Jul 2007, miguel manese wrote:

> Hi,
>
> In the latest R this does not work anymore
>
> args <- formals(log)
>
> because log is primitive. Is there any other way to get the argument
> list? I just need the name of the parameter to display some error
> message about it. I have looked at args() but I can't find anything to
> extract the argument names from it.
>
> Thanks,
> M. Manese

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jjonphl at gmail.com  Wed Jul 11 08:19:25 2007
From: jjonphl at gmail.com (miguel manese)
Date: Wed, 11 Jul 2007 14:19:25 +0800
Subject: [Rd] Getting param names of primitives
In-Reply-To: <Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
Message-ID: <d35b9da60707102319t162165abl5fdc7bd1e94d4bfe@mail.gmail.com>

Thanks! Worked like a charm.

Regards,
M. Manese

On 7/11/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > formals(args(log))
> $x
>
>
> $base
> exp(1)
>
> gives what formals(log) used to.
>
> On Wed, 11 Jul 2007, miguel manese wrote:
>
> > Hi,
> >
> > In the latest R this does not work anymore
> >
> > args <- formals(log)
> >
> > because log is primitive. Is there any other way to get the argument
> > list? I just need the name of the parameter to display some error
> > message about it. I have looked at args() but I can't find anything to
> > extract the argument names from it.
> >
> > Thanks,
> > M. Manese
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From sapsi at pobox.com  Tue Jul 10 20:01:18 2007
From: sapsi at pobox.com (Saptarshi Guha)
Date: Tue, 10 Jul 2007 14:01:18 -0400
Subject: [Rd] [R] How to preserve data across function calls in a
	library package
In-Reply-To: <A00673FA-F462-4CD4-8D3C-03DE3B9CC2C6@pobox.com>
References: <6F70270F-4DF1-4D34-8444-FCBF8F035030@pobox.com>
	<A00673FA-F462-4CD4-8D3C-03DE3B9CC2C6@pobox.com>
Message-ID: <CC14F374-4A9E-42D3-B9E0-2DA277D61032@pobox.com>


On Jul 10, 2007, at 12:33 PM, Saptarshi Guha wrote:

> Hi,
> 	Some progress: I am using
> 	SEXP retty;
> 	book=Calloc(1,int);
> 	*book=10;
> 	PROTECT(retty=R_MakeExternalPtr(book,R_NilValue,R_NilValue));
> 	
> 	then UNPROTECTING and returning retty.
>
> 	In a another function,
> 	foo(SEXP s){
> 	 int* f=(int *)R_ExternalPtrAddr(p);
> 	 Rprintf("many times %d\n",*f);	
> }
>
> 	When called do_foo(p) where do_foo calls foo and p is the pointer
> returned by the former code snippet, the Rprintf successfully prints
> the correct value but subsequently crashes
> *** caught bus error ***
> address 0x0, cause 'invalid alignment'.
>
> 	I can't figure out why... I would appreciate any advice provided.
> 	Rgds
> 	Saptarshi
>

One quick solution, change the function foo, to
SEXP foo(SEXP s){
...
return(s)
}
and make corresponding changes elsewhere. This should work.
Regards
Saptarshi










>
>
>
> On Jul 10, 2007, at 11:41 AM, Saptarshi Guha wrote:
>
>> Hi,
>> 	I am writing an R package with two functions in C++. So far
>> everything works.
>> 	Now, i would like to write a third function which would use a  
>> pointer
>> (it is a pointer to a class object) created by first function.
>> 	I tried placing this pointer outside of the function definitions
>> (i.e to make it global) but when called in the 3rd function i get
>>> 	 *** caught bus error ***
>> address 0x0, cause 'invalid alignment'"
>>
>> 	I tried Callocing it in the 1st function but to no avail. Here is a
>> quick summary. When foo is called (through do_foo, **after** having
>> called do_kNN_e) i get the aforementioned error.
>> 	Can anyone provide some pointers (no pun intended) on this?
>>
>> 	Thanks
>> 	Saptarshi
>>
>> ANN* book;
>> int* foot;
>>
>> void foo(void){
>>    Rprintf("many times\n");
>>    Rprintf("%p\n",book);
>>    Rprintf("%p\n",foot);
>> }
>>
>> SEXP
>> kNN_e(SEXP data, SEXP Nrow, SEXP Ncol,SEXP K,SEXP Eps)
>> {
>>    int nrow=asInteger(Nrow);
>>    int ncol=asInteger(Ncol);
>>    int k=asInteger(K);
>>    double eps=asReal(Eps);
>>
>>    SEXP ans,distance;
>>    SEXP retlist;
>>    PROTECT(ans=allocMatrix(INTSXP,nrow,k)); //The 2nd argument gives
>> the number of rows, and the last the number of cols see http:// 
>> cran.r-
>> project.org/doc/manuals/R-exts.html
>>    PROTECT(distance=allocMatrix(REALSXP,nrow,k));
>>    ANNpointArray datapoints;
>>    ANNpoint qpoint;
>>    ANNkd_tree* kdTree;
>>    book=Calloc(1,ANN*);
>>    foot=Calloc(1,int);
>>    book=kdTree;
>>   *foot=10;
>>
>>   .......
>> }
>>
>> extern "C" {
>>    void do_foo(void){
>>      foo();
>>    }
>>
>> SEXP
>> do_kNN_e(SEXP data, SEXP Nrow, SEXP Ncol,SEXP k,SEXP eps)
>> {
>>    return kNN_e(data,Nrow, Ncol,
>> 	     k,eps);
>>
>> }
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
> Would you people stop playing these stupid games?!?!?!!!!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

Saptarshi Guha | sapsi at pobox.com | http://www.stat.purdue.edu/~sguha
What ever happened to happily ever after?


From maechler at stat.math.ethz.ch  Wed Jul 11 12:28:57 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 11 Jul 2007 12:28:57 +0200
Subject: [Rd] Getting param names of primitives
In-Reply-To: <Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
Message-ID: <18068.45289.14125.872148@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Wed, 11 Jul 2007 05:48:56 +0100 (BST) writes:

    >> formals(args(log))
    BDR> $x


    BDR> $base
    BDR> exp(1)

    BDR> gives what formals(log) used to.

(I knew). I've been asking myself several times now,
if we should not make
formals() do this automatically.
I know that the change might break some code
which has used things like

if(is.null(formals(fun))) {
 
  ## treat  fun  as a primitive function

}

but I think R has provided  is.primitive(.)
long enough now so that
we could consider the change.

Martin


    BDR> On Wed, 11 Jul 2007, miguel manese wrote:

    >> Hi,
    >> 
    >> In the latest R this does not work anymore
    >> 
    >> args <- formals(log)
    >> 
    >> because log is primitive. Is there any other way to get the argument
    >> list? I just need the name of the parameter to display some error
    >> message about it. I have looked at args() but I can't find anything to
    >> extract the argument names from it.
    >> 
    >> Thanks,
    >> M. Manese

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    BDR> ______________________________________________
    BDR> R-devel at r-project.org mailing list
    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Jul 11 14:17:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jul 2007 13:17:16 +0100 (BST)
Subject: [Rd] Getting param names of primitives
In-Reply-To: <18068.45289.14125.872148@stat.math.ethz.ch>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
	<18068.45289.14125.872148@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk>

My problem is that if we make formals() work on primitives, people will 
expect

formals(log) <- value

to work, and it cannot.

On Wed, 11 Jul 2007, Martin Maechler wrote:

>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Wed, 11 Jul 2007 05:48:56 +0100 (BST) writes:
>
>    >> formals(args(log))
>    BDR> $x
>
>
>    BDR> $base
>    BDR> exp(1)
>
>    BDR> gives what formals(log) used to.
>
> (I knew). I've been asking myself several times now,
> if we should not make
> formals() do this automatically.
> I know that the change might break some code
> which has used things like
>
> if(is.null(formals(fun))) {
>
>  ## treat  fun  as a primitive function
>
> }
>
> but I think R has provided  is.primitive(.)
> long enough now so that
> we could consider the change.
>
> Martin
>
>
>    BDR> On Wed, 11 Jul 2007, miguel manese wrote:
>
>    >> Hi,
>    >>
>    >> In the latest R this does not work anymore
>    >>
>    >> args <- formals(log)
>    >>
>    >> because log is primitive. Is there any other way to get the argument
>    >> list? I just need the name of the parameter to display some error
>    >> message about it. I have looked at args() but I can't find anything to
>    >> extract the argument names from it.
>    >>
>    >> Thanks,
>    >> M. Manese
>
>    BDR> --
>    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
>    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
>    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>    BDR> ______________________________________________
>    BDR> R-devel at r-project.org mailing list
>    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Jul 11 15:40:23 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 11 Jul 2007 06:40:23 -0700
Subject: [Rd] Getting param names of primitives
In-Reply-To: <Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Wed, 11 Jul 2007 13:17:16 +0100 (BST)")
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
	<18068.45289.14125.872148@stat.math.ethz.ch>
	<Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk>
Message-ID: <m2fy3v6ou0.fsf@ziti.fhcrc.org>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> My problem is that if we make formals() work on primitives, people will 
> expect
>
> formals(log) <- value
>
> to work, and it cannot.

But it could give an informative error message.  Asking for formals()
seems to make sense so making it work seems like a good idea.  I'll
agree that it working might encourage someone to try formals<-(), but
the fact that it cannot do anything but error seems like a strange
reason not to make formals() work.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From ggrothendieck at gmail.com  Wed Jul 11 15:50:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 11 Jul 2007 09:50:29 -0400
Subject: [Rd] Getting param names of primitives
In-Reply-To: <Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
Message-ID: <971536df0707110650j128bb2a0h352636aaf2f7f621@mail.gmail.com>

Even that does not appear to work everywhere.
Either of these returns NULL:

formals(args("{"))
formals(args(match.fun("{")))

> R.version.string # XP
[1] "R version 2.5.1 (2007-06-27)"


On 7/11/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > formals(args(log))
> $x
>
>
> $base
> exp(1)
>
> gives what formals(log) used to.
>
> On Wed, 11 Jul 2007, miguel manese wrote:
>
> > Hi,
> >
> > In the latest R this does not work anymore
> >
> > args <- formals(log)
> >
> > because log is primitive. Is there any other way to get the argument
> > list? I just need the name of the parameter to display some error
> > message about it. I have looked at args() but I can't find anything to
> > extract the argument names from it.
> >
> > Thanks,
> > M. Manese
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Wed Jul 11 16:11:04 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 11 Jul 2007 10:11:04 -0400
Subject: [Rd] Getting param names of primitives
In-Reply-To: <m2fy3v6ou0.fsf@ziti.fhcrc.org>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>	<18068.45289.14125.872148@stat.math.ethz.ch>	<Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk>
	<m2fy3v6ou0.fsf@ziti.fhcrc.org>
Message-ID: <4694E4F8.3090000@stats.uwo.ca>

On 7/11/2007 9:40 AM, Seth Falcon wrote:
> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> 
>> My problem is that if we make formals() work on primitives, people will 
>> expect
>>
>> formals(log) <- value
>>
>> to work, and it cannot.
> 
> But it could give an informative error message.  Asking for formals()
> seems to make sense so making it work seems like a good idea.  I'll
> agree that it working might encourage someone to try formals<-(), but
> the fact that it cannot do anything but error seems like a strange
> reason not to make formals() work.

But primitives don't have formals, and that's why you can't set them. 
Having formals(primitive) work just makes it harder to talk about the 
language.  Closures have formals, primitives don't.  Both have args.  If 
you want to work with the args of a function, use the args.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Wed Jul 11 16:19:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jul 2007 15:19:26 +0100 (BST)
Subject: [Rd] Getting param names of primitives
In-Reply-To: <4694E4F8.3090000@stats.uwo.ca>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
	<18068.45289.14125.872148@stat.math.ethz.ch>
	<Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk>
	<m2fy3v6ou0.fsf@ziti.fhcrc.org> <4694E4F8.3090000@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0707111513540.7025@gannet.stats.ox.ac.uk>

On Wed, 11 Jul 2007, Duncan Murdoch wrote:

> On 7/11/2007 9:40 AM, Seth Falcon wrote:
>> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>> 
>>> My problem is that if we make formals() work on primitives, people will 
>>> expect
>>> 
>>> formals(log) <- value
>>> 
>>> to work, and it cannot.
>> 
>> But it could give an informative error message.  Asking for formals()
>> seems to make sense so making it work seems like a good idea.  I'll
>> agree that it working might encourage someone to try formals<-(), but
>> the fact that it cannot do anything but error seems like a strange
>> reason not to make formals() work.
>
> But primitives don't have formals, and that's why you can't set them. Having 
> formals(primitive) work just makes it harder to talk about the language. 
> Closures have formals, primitives don't.  Both have args.  If you want to 
> work with the args of a function, use the args.

I agree: I was going to reply to Seth that the main reason was that 
'formals() ought to refer to formals which primitives lack'.

And note too that args(<primitive>) does not work for all primitives, as 
some are really part of the language (e.g. for(), return()).  Exactly 
which are is perhaps debatable, and the person who implemented the 
mechanism got to decide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Wed Jul 11 16:37:47 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 11 Jul 2007 10:37:47 -0400
Subject: [Rd] Getting param names of primitives
In-Reply-To: <Pine.LNX.4.64.0707111513540.7025@gannet.stats.ox.ac.uk>
References: <d35b9da60707102141q60586e66w88a4b991595edcd0@mail.gmail.com>
	<Pine.LNX.4.64.0707110546480.27029@gannet.stats.ox.ac.uk>
	<18068.45289.14125.872148@stat.math.ethz.ch>
	<Pine.LNX.4.64.0707111314380.5891@gannet.stats.ox.ac.uk>
	<m2fy3v6ou0.fsf@ziti.fhcrc.org> <4694E4F8.3090000@stats.uwo.ca>
	<Pine.LNX.4.64.0707111513540.7025@gannet.stats.ox.ac.uk>
Message-ID: <971536df0707110737o6d5347b1i83366fb030c57fc2@mail.gmail.com>

These don't work either:

args(match.fun("{"))
args("{")



On 7/11/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Wed, 11 Jul 2007, Duncan Murdoch wrote:
>
> > On 7/11/2007 9:40 AM, Seth Falcon wrote:
> >> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> >>
> >>> My problem is that if we make formals() work on primitives, people will
> >>> expect
> >>>
> >>> formals(log) <- value
> >>>
> >>> to work, and it cannot.
> >>
> >> But it could give an informative error message.  Asking for formals()
> >> seems to make sense so making it work seems like a good idea.  I'll
> >> agree that it working might encourage someone to try formals<-(), but
> >> the fact that it cannot do anything but error seems like a strange
> >> reason not to make formals() work.
> >
> > But primitives don't have formals, and that's why you can't set them. Having
> > formals(primitive) work just makes it harder to talk about the language.
> > Closures have formals, primitives don't.  Both have args.  If you want to
> > work with the args of a function, use the args.
>
> I agree: I was going to reply to Seth that the main reason was that
> 'formals() ought to refer to formals which primitives lack'.
>
> And note too that args(<primitive>) does not work for all primitives, as
> some are really part of the language (e.g. for(), return()).  Exactly
> which are is perhaps debatable, and the person who implemented the
> mechanism got to decide.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Wed Jul 11 18:30:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jul 2007 17:30:56 +0100 (BST)
Subject: [Rd] cleanup and Makevars
In-Reply-To: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
Message-ID: <Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>

On Mon, 9 Jul 2007, Kasper Daniel Hansen wrote:

> Hi
>
> This is a question prompted by the mac version of R, but as I see it,
> it should have broader interest.
>
> These days the CRAN Mac binary per default compiles every package for
> two architectures. First i386 and then ppc. In between the two
> compilation runs, any object files in pkgname/src is removed. This
> cleanup is necessary since otherwise Make would not recompile the
> object files under the next architecture.
>
> I have a package which includes a large SDK which I have put in
>   src/fusion_sdk
> (and subdirectories). I take care of that by using a Makevars file
> with essentially (the whole Makevars file is reproduced below)
>
> PKG_SOURCES = \
>         fusion_sdk/calvin_files/data/src/CDFData.cpp
>
> OBJS=$(PKG_SOURCES:.cpp=.o)
>
> all: $(SHLIB)
>
> However, this setup does not remove the object files in the
> fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek
> I learned that I need to clean up these directories myself.
>
> I have - per R extensions - attempted to do so using a pkgname/
> cleanup script. While this works for cleaning up the sub directories
> when I do R CMD build, it seems as if this script is not being run
> between compilation runs (is this intentional btw.?).

What do you mean by 'compilation runs'?  The 'cleanup' script will be run 
by R CMD INSTALL --cleanup (and without --cleanup it is intentionally not 
run).

> So my question is now: how do I in a simple way clean up my
> subdirectories? I would prefer it to be as simple as possible because
> so far I have not really needed anything besides a Makevars file. In
> fact the impression I have right now from looking at the SHLIB and
> INSTALL scripts is that I might need a Makefile that removes the
> object files _before_ starting the compilation, as I don't really see
> any cleanup process (eg. making a target clean) - but this may very
> well be due to my limited understanding of these scripts.

I see R CMD INSTALL --clean that runs a clean up afterwards, and 2.6.0 
will also have R CMD INSTALL --preclean in case you forgot --clean on the 
last run.

> Any help/hints on how to proceed? Especially if I want it to be
> portable?

What does R CMD INSTALL --clean not do that you want?

If you are talking about R CMD SHLIB, that currently does not clean up but 
this has been raised and it will most likely have a --clean option in 
2.6.0 that removes $(OBJECTS).

>
> Kasper
>
> The full Makevars file:
>
> MYCXXFLAGS=-O0

You do realize that is highly non-portable?

> %.o: %.cpp
> 	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>
> PKG_CPPFLAGS=\
> -imacros R_affx_constants.h\
> -Ifusion_sdk/calvin_files/array/src\
> -Ifusion_sdk/calvin_files/data/src\
> -Ifusion_sdk/calvin_files/exception/src\
> -Ifusion_sdk/calvin_files/fusion/src\
> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
> -Ifusion_sdk/calvin_files/parameter/src\
> -Ifusion_sdk/calvin_files/parsers/src\
> -Ifusion_sdk/calvin_files/portability/src\
> -Ifusion_sdk/calvin_files/template/src\
> -Ifusion_sdk/calvin_files/utils/src\
> -Ifusion_sdk/calvin_files/writers/src\
> -Ifusion_sdk/file\
> -Ifusion_sdk/portability\
> -D_USE_MEM_MAPPING_
>
> PKG_SOURCES = \
> 	fusion_sdk/calvin_files/data/src/CDFData.cpp\
> 	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
> 	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
> 	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
> 	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
> 	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
> 	fusion_sdk/calvin_files/data/src/CELData.cpp\
> 	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
> 	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
> 	fusion_sdk/calvin_files/data/src/DataSet.cpp\
> 	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
> 	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
> 	fusion_sdk/calvin_files/data/src/GenericData.cpp\
> 	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
> 	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
> 	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/
> CalvinCELDataAdapter.cpp\
> 	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
> 	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
> 	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
> 	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
> 	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.cpp\
> 	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
> 	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
> 	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
> 	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
> 	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
> 	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
> 	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
> 	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
> 	fusion_sdk/calvin_files/utils/src/checksum.cpp\
> 	fusion_sdk/file/BPMAPFileData.cpp\
> 	fusion_sdk/file/BPMAPFileWriter.cpp\
> 	fusion_sdk/file/CDFFileData.cpp\
> 	fusion_sdk/file/CELFileData.cpp\
> 	fusion_sdk/file/FileIO.cpp\
> 	fusion_sdk/file/FileWriter.cpp\
> 	R_affx_cel_parser.cpp\
> 	R_affx_cdf_parser.cpp\
> 	R_affx_cdf_extras.cpp\
> 	R_affx_bpmap_parser.cpp
>
> OBJS=$(PKG_SOURCES:.cpp=.o)
>
> all: $(SHLIB)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.Berkeley.EDU  Wed Jul 11 20:32:48 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 11 Jul 2007 11:32:48 -0700
Subject: [Rd] cleanup and Makevars
In-Reply-To: <Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
Message-ID: <637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>


On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:

> On Mon, 9 Jul 2007, Kasper Daniel Hansen wrote:
>
>> Hi
>>
>> This is a question prompted by the mac version of R, but as I see it,
>> it should have broader interest.
>>
>> These days the CRAN Mac binary per default compiles every package for
>> two architectures. First i386 and then ppc. In between the two
>> compilation runs, any object files in pkgname/src is removed. This
>> cleanup is necessary since otherwise Make would not recompile the
>> object files under the next architecture.
>>
>> I have a package which includes a large SDK which I have put in
>>   src/fusion_sdk
>> (and subdirectories). I take care of that by using a Makevars file
>> with essentially (the whole Makevars file is reproduced below)
>>
>> PKG_SOURCES = \
>>         fusion_sdk/calvin_files/data/src/CDFData.cpp
>>
>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>
>> all: $(SHLIB)
>>
>> However, this setup does not remove the object files in the
>> fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek
>> I learned that I need to clean up these directories myself.
>>
>> I have - per R extensions - attempted to do so using a pkgname/
>> cleanup script. While this works for cleaning up the sub directories
>> when I do R CMD build, it seems as if this script is not being run
>> between compilation runs (is this intentional btw.?).
>
> What do you mean by 'compilation runs'?  The 'cleanup' script will  
> be run by R CMD INSTALL --cleanup (and without --cleanup it is  
> intentionally not run).
>
>> So my question is now: how do I in a simple way clean up my
>> subdirectories? I would prefer it to be as simple as possible because
>> so far I have not really needed anything besides a Makevars file. In
>> fact the impression I have right now from looking at the SHLIB and
>> INSTALL scripts is that I might need a Makefile that removes the
>> object files _before_ starting the compilation, as I don't really see
>> any cleanup process (eg. making a target clean) - but this may very
>> well be due to my limited understanding of these scripts.
>
> I see R CMD INSTALL --clean that runs a clean up afterwards, and  
> 2.6.0 will also have R CMD INSTALL --preclean in case you forgot -- 
> clean on the last run.
>
>> Any help/hints on how to proceed? Especially if I want it to be
>> portable?
>
> What does R CMD INSTALL --clean not do that you want?
>
> If you are talking about R CMD SHLIB, that currently does not clean  
> up but this has been raised and it will most likely have a --clean  
> option in 2.6.0 that removes $(OBJECTS).

Perhaps I was not clear enough: The CRAN binary of R for Mac has two  
architectures inside $R_HOME/bin/exec, namely "ppc" and "i386". This  
means that whenever anyone installs a source package I see two  
compilation runs - the following is a shortened output:

* Installing to library '/Library/Frameworks/R.framework/Resources/ 
library'
* Installing *source* package 'affxparser' ...
** libs
** arch - i386
g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
Library/Frameworks/R.framework/Resources/include/i386 -imacros  
R_affx_constants.h -Ifusion_sdk/calvin_files/array/src -Ifusion_sdk/ 
calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src - 
Ifusion_sdk/calvin_files/fusion/src -Ifusion_sdk/calvin_files/fusion/ 
src/GCOSAdapter -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter - 
Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/ 
parsers/src -Ifusion_sdk/calvin_files/portability/src -Ifusion_sdk/ 
calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src - 
Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file -Ifusion_sdk/ 
portability -D_USE_MEM_MAPPING_ -msse3    -fPIC  -g -O2 -Wall -O0 -c  
fusion_sdk/calvin_files/data/src/CDFData.cpp -o fusion_sdk/ 
calvin_files/data/src/CDFData.o

(Now a lot of other files gets compiled)

g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk - 
dynamiclib -Wl,-macosx_version_min -Wl,10.3 -undefined dynamic_lookup  
-single_module -multiply_defined suppress -L/usr/local/lib -o  
affxparser.so fusion_sdk/calvin_files/data/src/CDFData.o fusion_sdk/ 
calvin_files/data/src/CDFProbeGroupInformation.o fusion_sdk/ 
calvin_files/data/src/CDFProbeInformation.o fusion_sdk/calvin_files/ 
data/src/CDFProbeSetInformation.o fusion_sdk/calvin_files/data/src/ 
CDFQCProbeInformation.o fusion_sdk/calvin_files/data/src/ 
CDFQCProbeSetInformation.o fusion_sdk/calvin_files/data/src/CELData.o  
fusion_sdk/calvin_files/data/src/DataGroup.o fusion_sdk/calvin_files/ 
data/src/DataGroupHeader.o fusion_sdk/calvin_files/data/src/DataSet.o  
fusion_sdk/calvin_files/data/src/DataSetHeader.o fusion_sdk/ 
calvin_files/data/src/FileHeader.o fusion_sdk/calvin_files/data/src/ 
GenericData.o fusion_sdk/calvin_files/data/src/GenericDataHeader.o  
fusion_sdk/calvin_files/exception/src/ExceptionBase.o fusion_sdk/ 
calvin_files/fusion/src/CalvinAdapter/CalvinCELDataAdapter.o  
fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.o fusion_sdk/ 
calvin_files/fusion/src/FusionCDFData.o fusion_sdk/calvin_files/ 
fusion/src/FusionCDFQCProbeSetNames.o fusion_sdk/calvin_files/fusion/ 
src/FusionCELData.o fusion_sdk/calvin_files/fusion/src/GCOSAdapter/ 
GCOSCELDataAdapter.o fusion_sdk/calvin_files/parameter/src/ 
ParameterNameValueType.o fusion_sdk/calvin_files/parsers/src/ 
CDFFileReader.o fusion_sdk/calvin_files/parsers/src/CelFileReader.o  
fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.o  
fusion_sdk/calvin_files/parsers/src/DataGroupReader.o fusion_sdk/ 
calvin_files/parsers/src/DataSetHeaderReader.o fusion_sdk/ 
calvin_files/parsers/src/DataSetReader.o fusion_sdk/calvin_files/ 
parsers/src/FileHeaderReader.o fusion_sdk/calvin_files/parsers/src/ 
FileInput.o fusion_sdk/calvin_files/parsers/src/ 
GenericDataHeaderReader.o fusion_sdk/calvin_files/parsers/src/ 
GenericFileReader.o fusion_sdk/calvin_files/utils/src/ 
AffymetrixGuid.o fusion_sdk/calvin_files/utils/src/DateTime.o  
fusion_sdk/calvin_files/utils/src/FileUtils.o fusion_sdk/calvin_files/ 
utils/src/StringUtils.o fusion_sdk/calvin_files/utils/src/checksum.o  
fusion_sdk/file/BPMAPFileData.o fusion_sdk/file/BPMAPFileWriter.o  
fusion_sdk/file/CDFFileData.o fusion_sdk/file/CELFileData.o  
fusion_sdk/file/FileIO.o fusion_sdk/file/FileWriter.o  
R_affx_cel_parser.o R_affx_cdf_parser.o R_affx_cdf_extras.o  
R_affx_bpmap_parser.o   -F/Library/Frameworks/R.framework/.. - 
framework R
** arch - ppc
g++-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
Library/Frameworks/R.framework/Resources/include/ppc -imacros  
R_affx_constants.h -Ifusion_sdk/calvin_files/array/src -Ifusion_sdk/ 
calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src - 
Ifusion_sdk/calvin_files/fusion/src -Ifusion_sdk/calvin_files/fusion/ 
src/GCOSAdapter -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter - 
Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/ 
parsers/src -Ifusion_sdk/calvin_files/portability/src -Ifusion_sdk/ 
calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src - 
Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file -Ifusion_sdk/ 
portability -D_USE_MEM_MAPPING_ -I/usr/local/include    -fPIC  -g -O2  
-Wall -O0 -c R_affx_cel_parser.cpp -o R_affx_cel_parser.o

As you see from this (and sorry for all the include statements), when  
R starts compiling for arch = "ppc", it starts with a with in /src  
whereas the first compilation run (or more precise the first  
architecture) starts from /src/fusion_sdk/calvin_files/data/src. This  
is of course because the object files in the subdirectories do not  
get removed between the two architectures.

This has - probably - something to do with R CMD SHLIB not cleaning  
up after itself. A method of removing $(OBJECTS) would be exactly  
what I need, and may I suggest that this is done per default instead  
of being set by an option. Anyone using the CRAN binary for the Mac  
will have the same problem as I.

I am happy to see that this may be fixed for R-2.6.0. Is there  
anything I can do in the meantime for getting my package to work  
under R-2.5.1? (I can always move my source files from the /src/ 
fusion_sdk subdirectories directly into /src, but I would prefer to  
avoid that).

>>
>> Kasper
>>
>> The full Makevars file:
>>
>> MYCXXFLAGS=-O0
>
> You do realize that is highly non-portable?

Yes, but I do not know of any other way to downgrade the optimization  
level. The SDK I am using breaks (due to memory alignment issues if a  
specific optimization flag for GCC is include - the flag is certainly  
implied by -O2 and as far as I recall also -O1). I guess the solution  
is to switch to an autoconfigure script. The main reason for not  
doing this is 1) time and actually more 2) the fact that the SDK does  
not come with an ac script.

Thanks for the feedback, Kasper


>> %.o: %.cpp
>> 	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>>
>> PKG_CPPFLAGS=\
>> -imacros R_affx_constants.h\
>> -Ifusion_sdk/calvin_files/array/src\
>> -Ifusion_sdk/calvin_files/data/src\
>> -Ifusion_sdk/calvin_files/exception/src\
>> -Ifusion_sdk/calvin_files/fusion/src\
>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
>> -Ifusion_sdk/calvin_files/parameter/src\
>> -Ifusion_sdk/calvin_files/parsers/src\
>> -Ifusion_sdk/calvin_files/portability/src\
>> -Ifusion_sdk/calvin_files/template/src\
>> -Ifusion_sdk/calvin_files/utils/src\
>> -Ifusion_sdk/calvin_files/writers/src\
>> -Ifusion_sdk/file\
>> -Ifusion_sdk/portability\
>> -D_USE_MEM_MAPPING_
>>
>> PKG_SOURCES = \
>> 	fusion_sdk/calvin_files/data/src/CDFData.cpp\
>> 	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
>> 	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
>> 	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
>> 	fusion_sdk/calvin_files/data/src/CELData.cpp\
>> 	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
>> 	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
>> 	fusion_sdk/calvin_files/data/src/DataSet.cpp\
>> 	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
>> 	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
>> 	fusion_sdk/calvin_files/data/src/GenericData.cpp\
>> 	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
>> 	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/
>> CalvinCELDataAdapter.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
>> 	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/ 
>> GCOSCELDataAdapter.cpp\
>> 	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
>> 	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
>> 	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
>> 	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
>> 	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
>> 	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
>> 	fusion_sdk/calvin_files/utils/src/checksum.cpp\
>> 	fusion_sdk/file/BPMAPFileData.cpp\
>> 	fusion_sdk/file/BPMAPFileWriter.cpp\
>> 	fusion_sdk/file/CDFFileData.cpp\
>> 	fusion_sdk/file/CELFileData.cpp\
>> 	fusion_sdk/file/FileIO.cpp\
>> 	fusion_sdk/file/FileWriter.cpp\
>> 	R_affx_cel_parser.cpp\
>> 	R_affx_cdf_parser.cpp\
>> 	R_affx_cdf_extras.cpp\
>> 	R_affx_bpmap_parser.cpp
>>
>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>
>> all: $(SHLIB)
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From duncan at wald.ucdavis.edu  Wed Jul 11 21:10:09 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 11 Jul 2007 12:10:09 -0700
Subject: [Rd] cleanup and Makevars
In-Reply-To: <637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
	<637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
Message-ID: <46952B11.4040307@wald.ucdavis.edu>


Hi Kasper

 This is not an immediate solution for your problem,
but a suggestion that the "ideal" solution
might be different from what you are asking for.

In many projects, when we need to compile
the same source file for two or more different
purposes (e.g. architectures, compilation flags, etc.)
we put the .o's from each build into their own sub-directory
or use a different extension for the file.
This way, we don't have to recompile all of the source
files again when we start over.

So rather than removing the .o's just after creating
the .dylib, I think it would make sense for the
mac builds that support multiple architectures
to have slightly different make rules that
use different directories for the .o files.

The more we throw into the installation mechanism,
the more complex it becomes and harder to get
something out later on.

Also, adding facilities to perform
"customized" clean up or arbitrary package
installation customizations would be a lot
easier if the package mechanism were written in R.
It would make a nice project for somebody to do this,
perhaps building one some of the facilities in the inline package
or similar for invoking, e.g. R CMD SHLIB, and so on.


D

Kasper Daniel Hansen wrote:
> On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:
> 
>> On Mon, 9 Jul 2007, Kasper Daniel Hansen wrote:
>>
>>> Hi
>>>
>>> This is a question prompted by the mac version of R, but as I see it,
>>> it should have broader interest.
>>>
>>> These days the CRAN Mac binary per default compiles every package for
>>> two architectures. First i386 and then ppc. In between the two
>>> compilation runs, any object files in pkgname/src is removed. This
>>> cleanup is necessary since otherwise Make would not recompile the
>>> object files under the next architecture.
>>>
>>> I have a package which includes a large SDK which I have put in
>>>   src/fusion_sdk
>>> (and subdirectories). I take care of that by using a Makevars file
>>> with essentially (the whole Makevars file is reproduced below)
>>>
>>> PKG_SOURCES = \
>>>         fusion_sdk/calvin_files/data/src/CDFData.cpp
>>>
>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>>
>>> all: $(SHLIB)
>>>
>>> However, this setup does not remove the object files in the
>>> fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek
>>> I learned that I need to clean up these directories myself.
>>>
>>> I have - per R extensions - attempted to do so using a pkgname/
>>> cleanup script. While this works for cleaning up the sub directories
>>> when I do R CMD build, it seems as if this script is not being run
>>> between compilation runs (is this intentional btw.?).
>> What do you mean by 'compilation runs'?  The 'cleanup' script will  
>> be run by R CMD INSTALL --cleanup (and without --cleanup it is  
>> intentionally not run).
>>
>>> So my question is now: how do I in a simple way clean up my
>>> subdirectories? I would prefer it to be as simple as possible because
>>> so far I have not really needed anything besides a Makevars file. In
>>> fact the impression I have right now from looking at the SHLIB and
>>> INSTALL scripts is that I might need a Makefile that removes the
>>> object files _before_ starting the compilation, as I don't really see
>>> any cleanup process (eg. making a target clean) - but this may very
>>> well be due to my limited understanding of these scripts.
>> I see R CMD INSTALL --clean that runs a clean up afterwards, and  
>> 2.6.0 will also have R CMD INSTALL --preclean in case you forgot -- 
>> clean on the last run.
>>
>>> Any help/hints on how to proceed? Especially if I want it to be
>>> portable?
>> What does R CMD INSTALL --clean not do that you want?
>>
>> If you are talking about R CMD SHLIB, that currently does not clean  
>> up but this has been raised and it will most likely have a --clean  
>> option in 2.6.0 that removes $(OBJECTS).
> 
> Perhaps I was not clear enough: The CRAN binary of R for Mac has two  
> architectures inside $R_HOME/bin/exec, namely "ppc" and "i386". This  
> means that whenever anyone installs a source package I see two  
> compilation runs - the following is a shortened output:
> 
> * Installing to library '/Library/Frameworks/R.framework/Resources/ 
> library'
> * Installing *source* package 'affxparser' ...
> ** libs
> ** arch - i386
> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
> precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
> Library/Frameworks/R.framework/Resources/include/i386 -imacros  
> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src -Ifusion_sdk/ 
> calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src - 
> Ifusion_sdk/calvin_files/fusion/src -Ifusion_sdk/calvin_files/fusion/ 
> src/GCOSAdapter -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter - 
> Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/ 
> parsers/src -Ifusion_sdk/calvin_files/portability/src -Ifusion_sdk/ 
> calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src - 
> Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file -Ifusion_sdk/ 
> portability -D_USE_MEM_MAPPING_ -msse3    -fPIC  -g -O2 -Wall -O0 -c  
> fusion_sdk/calvin_files/data/src/CDFData.cpp -o fusion_sdk/ 
> calvin_files/data/src/CDFData.o
> 
> (Now a lot of other files gets compiled)
> 
> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk - 
> dynamiclib -Wl,-macosx_version_min -Wl,10.3 -undefined dynamic_lookup  
> -single_module -multiply_defined suppress -L/usr/local/lib -o  
> affxparser.so fusion_sdk/calvin_files/data/src/CDFData.o fusion_sdk/ 
> calvin_files/data/src/CDFProbeGroupInformation.o fusion_sdk/ 
> calvin_files/data/src/CDFProbeInformation.o fusion_sdk/calvin_files/ 
> data/src/CDFProbeSetInformation.o fusion_sdk/calvin_files/data/src/ 
> CDFQCProbeInformation.o fusion_sdk/calvin_files/data/src/ 
> CDFQCProbeSetInformation.o fusion_sdk/calvin_files/data/src/CELData.o  
> fusion_sdk/calvin_files/data/src/DataGroup.o fusion_sdk/calvin_files/ 
> data/src/DataGroupHeader.o fusion_sdk/calvin_files/data/src/DataSet.o  
> fusion_sdk/calvin_files/data/src/DataSetHeader.o fusion_sdk/ 
> calvin_files/data/src/FileHeader.o fusion_sdk/calvin_files/data/src/ 
> GenericData.o fusion_sdk/calvin_files/data/src/GenericDataHeader.o  
> fusion_sdk/calvin_files/exception/src/ExceptionBase.o fusion_sdk/ 
> calvin_files/fusion/src/CalvinAdapter/CalvinCELDataAdapter.o  
> fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.o fusion_sdk/ 
> calvin_files/fusion/src/FusionCDFData.o fusion_sdk/calvin_files/ 
> fusion/src/FusionCDFQCProbeSetNames.o fusion_sdk/calvin_files/fusion/ 
> src/FusionCELData.o fusion_sdk/calvin_files/fusion/src/GCOSAdapter/ 
> GCOSCELDataAdapter.o fusion_sdk/calvin_files/parameter/src/ 
> ParameterNameValueType.o fusion_sdk/calvin_files/parsers/src/ 
> CDFFileReader.o fusion_sdk/calvin_files/parsers/src/CelFileReader.o  
> fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.o  
> fusion_sdk/calvin_files/parsers/src/DataGroupReader.o fusion_sdk/ 
> calvin_files/parsers/src/DataSetHeaderReader.o fusion_sdk/ 
> calvin_files/parsers/src/DataSetReader.o fusion_sdk/calvin_files/ 
> parsers/src/FileHeaderReader.o fusion_sdk/calvin_files/parsers/src/ 
> FileInput.o fusion_sdk/calvin_files/parsers/src/ 
> GenericDataHeaderReader.o fusion_sdk/calvin_files/parsers/src/ 
> GenericFileReader.o fusion_sdk/calvin_files/utils/src/ 
> AffymetrixGuid.o fusion_sdk/calvin_files/utils/src/DateTime.o  
> fusion_sdk/calvin_files/utils/src/FileUtils.o fusion_sdk/calvin_files/ 
> utils/src/StringUtils.o fusion_sdk/calvin_files/utils/src/checksum.o  
> fusion_sdk/file/BPMAPFileData.o fusion_sdk/file/BPMAPFileWriter.o  
> fusion_sdk/file/CDFFileData.o fusion_sdk/file/CELFileData.o  
> fusion_sdk/file/FileIO.o fusion_sdk/file/FileWriter.o  
> R_affx_cel_parser.o R_affx_cdf_parser.o R_affx_cdf_extras.o  
> R_affx_bpmap_parser.o   -F/Library/Frameworks/R.framework/.. - 
> framework R
> ** arch - ppc
> g++-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
> precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
> Library/Frameworks/R.framework/Resources/include/ppc -imacros  
> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src -Ifusion_sdk/ 
> calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src - 
> Ifusion_sdk/calvin_files/fusion/src -Ifusion_sdk/calvin_files/fusion/ 
> src/GCOSAdapter -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter - 
> Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/ 
> parsers/src -Ifusion_sdk/calvin_files/portability/src -Ifusion_sdk/ 
> calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src - 
> Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file -Ifusion_sdk/ 
> portability -D_USE_MEM_MAPPING_ -I/usr/local/include    -fPIC  -g -O2  
> -Wall -O0 -c R_affx_cel_parser.cpp -o R_affx_cel_parser.o
> 
> As you see from this (and sorry for all the include statements), when  
> R starts compiling for arch = "ppc", it starts with a with in /src  
> whereas the first compilation run (or more precise the first  
> architecture) starts from /src/fusion_sdk/calvin_files/data/src. This  
> is of course because the object files in the subdirectories do not  
> get removed between the two architectures.
> 
> This has - probably - something to do with R CMD SHLIB not cleaning  
> up after itself. A method of removing $(OBJECTS) would be exactly  
> what I need, and may I suggest that this is done per default instead  
> of being set by an option. Anyone using the CRAN binary for the Mac  
> will have the same problem as I.
> 
> I am happy to see that this may be fixed for R-2.6.0. Is there  
> anything I can do in the meantime for getting my package to work  
> under R-2.5.1? (I can always move my source files from the /src/ 
> fusion_sdk subdirectories directly into /src, but I would prefer to  
> avoid that).
> 
>>> Kasper
>>>
>>> The full Makevars file:
>>>
>>> MYCXXFLAGS=-O0
>> You do realize that is highly non-portable?
> 
> Yes, but I do not know of any other way to downgrade the optimization  
> level. The SDK I am using breaks (due to memory alignment issues if a  
> specific optimization flag for GCC is include - the flag is certainly  
> implied by -O2 and as far as I recall also -O1). I guess the solution  
> is to switch to an autoconfigure script. The main reason for not  
> doing this is 1) time and actually more 2) the fact that the SDK does  
> not come with an ac script.
> 
> Thanks for the feedback, Kasper
> 
> 
>>> %.o: %.cpp
>>> 	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>>>
>>> PKG_CPPFLAGS=\
>>> -imacros R_affx_constants.h\
>>> -Ifusion_sdk/calvin_files/array/src\
>>> -Ifusion_sdk/calvin_files/data/src\
>>> -Ifusion_sdk/calvin_files/exception/src\
>>> -Ifusion_sdk/calvin_files/fusion/src\
>>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
>>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
>>> -Ifusion_sdk/calvin_files/parameter/src\
>>> -Ifusion_sdk/calvin_files/parsers/src\
>>> -Ifusion_sdk/calvin_files/portability/src\
>>> -Ifusion_sdk/calvin_files/template/src\
>>> -Ifusion_sdk/calvin_files/utils/src\
>>> -Ifusion_sdk/calvin_files/writers/src\
>>> -Ifusion_sdk/file\
>>> -Ifusion_sdk/portability\
>>> -D_USE_MEM_MAPPING_
>>>
>>> PKG_SOURCES = \
>>> 	fusion_sdk/calvin_files/data/src/CDFData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CELData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataSet.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/GenericData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
>>> 	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/
>>> CalvinCELDataAdapter.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/ 
>>> GCOSCELDataAdapter.cpp\
>>> 	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/checksum.cpp\
>>> 	fusion_sdk/file/BPMAPFileData.cpp\
>>> 	fusion_sdk/file/BPMAPFileWriter.cpp\
>>> 	fusion_sdk/file/CDFFileData.cpp\
>>> 	fusion_sdk/file/CELFileData.cpp\
>>> 	fusion_sdk/file/FileIO.cpp\
>>> 	fusion_sdk/file/FileWriter.cpp\
>>> 	R_affx_cel_parser.cpp\
>>> 	R_affx_cdf_parser.cpp\
>>> 	R_affx_cdf_extras.cpp\
>>> 	R_affx_bpmap_parser.cpp
>>>
>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>>
>>> all: $(SHLIB)
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tplate at acm.org  Thu Jul 12 00:20:28 2007
From: tplate at acm.org (Tony Plate)
Date: Wed, 11 Jul 2007 16:20:28 -0600
Subject: [Rd] sweep sanity checking?
In-Reply-To: <loom.20070709T175233-590@post.gmane.org>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
Message-ID: <469557AC.2010607@acm.org>

Just an opinion from an R user: I think it's a sound idea.  I use my own 
version of sweep with a stricter check: it stops if the vector is not 
exactly the right length.

-- Tony Plate

Ben Bolker wrote:
> Ben Bolker <bolker <at> zoo.ufl.edu> writes:
>
>   
>>   What would R-core think of the following 'enhanced'
>> sweep?  
>>     
>
>  (now posted at
> http://wiki.r-project.org/rwiki/doku.php?id=rdoc:base:sweep
> )
>
> It always warns if dim(x)[MARGIN] is
>   
>> not a multiple of length(STATS) {it's very hard indeed
>> for me to think of a situation where you'd actually
>> want this}; if check.margin=TRUE it is a bit stricter,
>> complaining whenever dim(x)[MARGIN] doesn't
>> match length(STATS).
>>
>>   This change seems fairly harmless since it never does anything
>> more than warn; the default for check.margin could
>> be FALSE if you wanted to allow people a bit more rope
>> to hang themselves with ...  (of course this won't prevent
>> you from sweeping the wrong margin of a square matrix,
>> but nothing will).
>>
>>   cheers
>>     Ben Bolker
>>
>>     
>
>   Enough time has now passed that I feel justified following up
> on this.  Does anyone have any opinions on it, one way or the other?
>
>   Ben
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hpages at fhcrc.org  Thu Jul 12 04:30:19 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 11 Jul 2007 19:30:19 -0700
Subject: [Rd] [[.data frame and row names
Message-ID: <4695923B.8010405@fhcrc.org>

Hi,

I'm wondering why indexing a data frame by row name doesn't work
with [[. It works with [:

  > sw <- swiss[1:5,1:2]
  > sw["Moutier", "Agriculture"]
  [1] 36.5

but not with [[:

  > sw[["Moutier", "Agriculture"]]
  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds

The problem is really with the row name (and not the col name) since
this works:

  > sw[[4, "Agriculture"]]
  [1] 36.5

but not this:

  > sw[["Moutier", 2]]
  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds

No such problems with a matrix where everything works as expected:

  > msw <- as.matrix(sw)
  > msw[["Moutier", "Agriculture"]]
  [1] 36.5

Thanks!

H.


From ripley at stats.ox.ac.uk  Thu Jul 12 06:24:12 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jul 2007 05:24:12 +0100 (BST)
Subject: [Rd] [[.data frame and row names
In-Reply-To: <4695923B.8010405@fhcrc.org>
References: <4695923B.8010405@fhcrc.org>
Message-ID: <Pine.LNX.4.64.0707120518480.15630@gannet.stats.ox.ac.uk>

On Wed, 11 Jul 2007, Herve Pages wrote:

> Hi,
>
> I'm wondering why indexing a data frame by row name doesn't work
> with [[. It works with [:
>
>  > sw <- swiss[1:5,1:2]
>  > sw["Moutier", "Agriculture"]
>  [1] 36.5
>
> but not with [[:
>
>  > sw[["Moutier", "Agriculture"]]
>  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds
>
> The problem is really with the row name (and not the col name) since
> this works:
>
>  > sw[[4, "Agriculture"]]
>  [1] 36.5
>
> but not this:
>
>  > sw[["Moutier", 2]]
>  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds

.subset2 drops all attributes, including names.

> .subset2(sw, "Agriculture")
[1] 17.0 45.1 39.7 36.5 43.5

This is nothing new: R 2.0.0 did the same, for example.

> No such problems with a matrix where everything works as expected:
>
>  > msw <- as.matrix(sw)
>  > msw[["Moutier", "Agriculture"]]
>  [1] 36.5
>
> Thanks!
>
> H.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From savicky at cs.cas.cz  Thu Jul 12 10:16:17 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 12 Jul 2007 10:16:17 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <469557AC.2010607@acm.org>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org>
Message-ID: <20070712081616.GA7100@cs.cas.cz>

The suggestion sounds reasonable to me. Let me add that sweep is written
to work even if MARGIN includes more than one dimension. To handle these
cases correctly, the test may be replaced e.g. by
     if (check.margin && prod(dims[MARGIN])!=length(STATS)) {
       warning("length(STATS) != prod(dim(x)[MARGIN])")
     } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
       warning("prod(dim(x)[MARGIN]) is not a multiple of length(STATS)")
or even by
     dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
     if (check.margin && any(dims[MARGIN]!=dimstat)) {
       warning("length(STATS) or dim(STAT) do not match dim(x)[MARGIN]")
     } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
       warning("prod(dim(x)[MARGIN]) is not a multiple of length(STATS)")

Petr.

> Just an opinion from an R user: I think it's a sound idea.  I use my own 
> version of sweep with a stricter check: it stops if the vector is not 
> exactly the right length.
> 
> -- Tony Plate
> 
> Ben Bolker wrote:
> > Ben Bolker <bolker <at> zoo.ufl.edu> writes:
> >
> >   
> >>   What would R-core think of the following 'enhanced'
> >> sweep?  
> >>     
> >
> >  (now posted at
> > http://wiki.r-project.org/rwiki/doku.php?id=rdoc:base:sweep
> > )
> >
> > It always warns if dim(x)[MARGIN] is
> >


From software at iangregory.com  Thu Jul 12 09:28:20 2007
From: software at iangregory.com (software at iangregory.com)
Date: Thu, 12 Jul 2007 09:28:20 +0200 (CEST)
Subject: [Rd] Fextremes - Error in if (xi > 0.5) (PR#9789)
Message-ID: <20070712072820.C29A45A80D@slim.kubism.ku.dk>

Full_Name: Ian Gregory
Version: 2.41
OS: Widnows XP 64
Submission from: (NULL) (58.110.160.141)


Fextremes version: 240.10068

gpdFit(c(98,99,100),threshold=100,type="pwm")

Gives this error:
Error in if (xi > 0.5) { : missing value where TRUE/FALSE needed

This error will occur whenever a threshold value will choose a cut-off which
will have identical raw values above the cut-off.  
In the example above; the raw values would all be the same and not exist.
A larger example would identify say a cut-off at 96% and produce the error.

Line 62-66 of the function GPD:

if (xi > 0.5) {
	denom <- NA
        warning("Asymptotic standard errors not available for", 
        "PWM Method when xi > 0.5")
}


Two fixes:

(1)
Change this line:
if (xi > 0.5) {
to
if (xi > 0.5 || xi==NA) {

(2)
Change this line:
warning("Asymptotic standard errors not available for",
to:
warning("Asymptotic standard errors not available for ",

ie.  add a space after for.

Thank you,

Ian Gregory
Sydney University


From savicky at cs.cas.cz  Thu Jul 12 10:40:05 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 12 Jul 2007 10:40:05 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070712081616.GA7100@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
Message-ID: <20070712084005.GB7100@cs.cas.cz>

I am sorry for an incomplete proposal. The stricter check
     if (check.margin && any(dims[MARGIN]!=dimstat)) {
was meant to be
     if (check.margin && (length(dimstat)!=length(MARGIN) || any(dims[MARGIN]!=dimstat))) {

Petr.


From r.hankin at noc.soton.ac.uk  Thu Jul 12 10:47:44 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 12 Jul 2007 09:47:44 +0100
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070712081616.GA7100@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
Message-ID: <316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>

Hi

Brian Ripley, Heather Turner, and myself discussed this
issue at some length in a thread starting 20 June 2005 (how
do folk give a URL that points to a thread?).

The consensus was that adding a warning level option to sweep
was a good idea; Heather posted a version of sweep that implemented
this, which she posted on 21 June 2005.


rksh




On 12 Jul 2007, at 09:16, Petr Savicky wrote:

> The suggestion sounds reasonable to me. Let me add that sweep is  
> written
> to work even if MARGIN includes more than one dimension. To handle  
> these
> cases correctly, the test may be replaced e.g. by
>      if (check.margin && prod(dims[MARGIN])!=length(STATS)) {
>        warning("length(STATS) != prod(dim(x)[MARGIN])")
>      } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
>        warning("prod(dim(x)[MARGIN]) is not a multiple of length 
> (STATS)")
> or even by
>      dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
>      if (check.margin && any(dims[MARGIN]!=dimstat)) {
>        warning("length(STATS) or dim(STAT) do not match dim(x) 
> [MARGIN]")
>      } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
>        warning("prod(dim(x)[MARGIN]) is not a multiple of length 
> (STATS)")
>
> Petr.
>
>> Just an opinion from an R user: I think it's a sound idea.  I use  
>> my own
>> version of sweep with a stricter check: it stops if the vector is not
>> exactly the right length.
>>
>> -- Tony Plate
>>
>> Ben Bolker wrote:
>>> Ben Bolker <bolker <at> zoo.ufl.edu> writes:
>>>
>>>
>>>>   What would R-core think of the following 'enhanced'
>>>> sweep?
>>>>
>>>
>>>  (now posted at
>>> http://wiki.r-project.org/rwiki/doku.php?id=rdoc:base:sweep
>>> )
>>>
>>> It always warns if dim(x)[MARGIN] is
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From p.dalgaard at biostat.ku.dk  Thu Jul 12 10:55:45 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 12 Jul 2007 10:55:45 +0200
Subject: [Rd] [[.data frame and row names
In-Reply-To: <Pine.LNX.4.64.0707120518480.15630@gannet.stats.ox.ac.uk>
References: <4695923B.8010405@fhcrc.org>
	<Pine.LNX.4.64.0707120518480.15630@gannet.stats.ox.ac.uk>
Message-ID: <4695EC91.9080208@biostat.ku.dk>

Prof Brian Ripley wrote:
> On Wed, 11 Jul 2007, Herve Pages wrote:
>
>   
>> Hi,
>>
>> I'm wondering why indexing a data frame by row name doesn't work
>> with [[. It works with [:
>>
>>  > sw <- swiss[1:5,1:2]
>>  > sw["Moutier", "Agriculture"]
>>  [1] 36.5
>>
>> but not with [[:
>>
>>  > sw[["Moutier", "Agriculture"]]
>>  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds
>>
>> The problem is really with the row name (and not the col name) since
>> this works:
>>
>>  > sw[[4, "Agriculture"]]
>>  [1] 36.5
>>
>> but not this:
>>
>>  > sw[["Moutier", 2]]
>>  Error in .subset2(.subset2(x, ..2), ..1) : subscript out of bounds
>>     
>
> .subset2 drops all attributes, including names.
>
>   
>> .subset2(sw, "Agriculture")
>>     
> [1] 17.0 45.1 39.7 36.5 43.5
>
> This is nothing new: R 2.0.0 did the same, for example.
>   
>
That is not quite the issue. The names aren't there to begin with. So 
more precisely, .subset2 does not *add* row.names(sw) as the names of 
its result. That, and the fact that sw[[r,c]] is defined to be sw[[c]][[r]].

It is the data frame constructors that drop names on the individual 
components. Notice that names are getting lost in constructions like this:

 > a <- data.frame(b=c(d=1,e=2),f=c(g=3,h=4))
 > dput(a)
structure(list(b = c(1, 2), f = c(3, 4)), .Names = c("b", "f"), 
row.names = c("d", "e"), class = "data.frame")

Whereas
 > a <- list(b=c(d=1,e=2))
 > .subset2(a,1)
d e
1 2


From ripley at stats.ox.ac.uk  Thu Jul 12 11:05:02 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jul 2007 10:05:02 +0100 (BST)
Subject: [Rd] cleanup and Makevars
In-Reply-To: <637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
	<637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
Message-ID: <Pine.LNX.4.64.0707120954100.8241@gannet.stats.ox.ac.uk>

You seem extraordinarily reluctant to tell us what you are actually doing: 
no command appears here.  I presume this is a call to R CMD INSTALL, but 
why do I have to keep guessing?

Since you have taken over the make action via the all: target in your 
Makevars, you need also to take over responsibility for cleaning.  I 
should think

all: myclean $(SHLIB)

myclean:
 	rm -f $(OBJS)

should do it.  And BTW, the use of $(OBJS) to set the objects is 
undocumented, at least in 'Writing R Extensions'.

On Wed, 11 Jul 2007, Kasper Daniel Hansen wrote:

>
> On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:
>
>> On Mon, 9 Jul 2007, Kasper Daniel Hansen wrote:
>> 
>>> Hi
>>> 
>>> This is a question prompted by the mac version of R, but as I see it,
>>> it should have broader interest.
>>> 
>>> These days the CRAN Mac binary per default compiles every package for
>>> two architectures. First i386 and then ppc. In between the two
>>> compilation runs, any object files in pkgname/src is removed. This
>>> cleanup is necessary since otherwise Make would not recompile the
>>> object files under the next architecture.
>>> 
>>> I have a package which includes a large SDK which I have put in
>>>  src/fusion_sdk
>>> (and subdirectories). I take care of that by using a Makevars file
>>> with essentially (the whole Makevars file is reproduced below)
>>> 
>>> PKG_SOURCES = \
>>>        fusion_sdk/calvin_files/data/src/CDFData.cpp
>>> 
>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>> 
>>> all: $(SHLIB)
>>> 
>>> However, this setup does not remove the object files in the
>>> fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek
>>> I learned that I need to clean up these directories myself.
>>> 
>>> I have - per R extensions - attempted to do so using a pkgname/
>>> cleanup script. While this works for cleaning up the sub directories
>>> when I do R CMD build, it seems as if this script is not being run
>>> between compilation runs (is this intentional btw.?).
>> 
>> What do you mean by 'compilation runs'?  The 'cleanup' script will be run 
>> by R CMD INSTALL --cleanup (and without --cleanup it is intentionally not 
>> run).
>> 
>>> So my question is now: how do I in a simple way clean up my
>>> subdirectories? I would prefer it to be as simple as possible because
>>> so far I have not really needed anything besides a Makevars file. In
>>> fact the impression I have right now from looking at the SHLIB and
>>> INSTALL scripts is that I might need a Makefile that removes the
>>> object files _before_ starting the compilation, as I don't really see
>>> any cleanup process (eg. making a target clean) - but this may very
>>> well be due to my limited understanding of these scripts.
>> 
>> I see R CMD INSTALL --clean that runs a clean up afterwards, and 2.6.0 will 
>> also have R CMD INSTALL --preclean in case you forgot --clean on the last 
>> run.
>> 
>>> Any help/hints on how to proceed? Especially if I want it to be
>>> portable?
>> 
>> What does R CMD INSTALL --clean not do that you want?
>> 
>> If you are talking about R CMD SHLIB, that currently does not clean up but 
>> this has been raised and it will most likely have a --clean option in 2.6.0 
>> that removes $(OBJECTS).
>
> Perhaps I was not clear enough: The CRAN binary of R for Mac has two 
> architectures inside $R_HOME/bin/exec, namely "ppc" and "i386". This means 
> that whenever anyone installs a source package I see two compilation runs - 
> the following is a shortened output:
>
> * Installing to library '/Library/Frameworks/R.framework/Resources/library'
> * Installing *source* package 'affxparser' ...
> ** libs
> ** arch - i386
> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp-precomp 
> -I/Library/Frameworks/R.framework/Resources/include 
> -I/Library/Frameworks/R.framework/Resources/include/i386 -imacros 
> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src 
> -Ifusion_sdk/calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src 
> -Ifusion_sdk/calvin_files/fusion/src 
> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter 
> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter 
> -Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/parsers/src 
> -Ifusion_sdk/calvin_files/portability/src 
> -Ifusion_sdk/calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src 
> -Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file 
> -Ifusion_sdk/portability -D_USE_MEM_MAPPING_ -msse3    -fPIC  -g -O2 -Wall 
> -O0 -c fusion_sdk/calvin_files/data/src/CDFData.cpp -o 
> fusion_sdk/calvin_files/data/src/CDFData.o
>
> (Now a lot of other files gets compiled)
>
> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -dynamiclib 
> -Wl,-macosx_version_min -Wl,10.3 -undefined dynamic_lookup -single_module 
> -multiply_defined suppress -L/usr/local/lib -o affxparser.so 
> fusion_sdk/calvin_files/data/src/CDFData.o 
> fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.o 
> fusion_sdk/calvin_files/data/src/CDFProbeInformation.o 
> fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.o 
> fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.o 
> fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.o 
> fusion_sdk/calvin_files/data/src/CELData.o 
> fusion_sdk/calvin_files/data/src/DataGroup.o 
> fusion_sdk/calvin_files/data/src/DataGroupHeader.o 
> fusion_sdk/calvin_files/data/src/DataSet.o 
> fusion_sdk/calvin_files/data/src/DataSetHeader.o 
> fusion_sdk/calvin_files/data/src/FileHeader.o 
> fusion_sdk/calvin_files/data/src/GenericData.o 
> fusion_sdk/calvin_files/data/src/GenericDataHeader.o 
> fusion_sdk/calvin_files/exception/src/ExceptionBase.o 
> fusion_sdk/calvin_files/fusion/src/CalvinAdapter/CalvinCELDataAdapter.o 
> fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.o 
> fusion_sdk/calvin_files/fusion/src/FusionCDFData.o 
> fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.o 
> fusion_sdk/calvin_files/fusion/src/FusionCELData.o 
> fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.o 
> fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.o 
> fusion_sdk/calvin_files/parsers/src/CDFFileReader.o 
> fusion_sdk/calvin_files/parsers/src/CelFileReader.o 
> fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.o 
> fusion_sdk/calvin_files/parsers/src/DataGroupReader.o 
> fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.o 
> fusion_sdk/calvin_files/parsers/src/DataSetReader.o 
> fusion_sdk/calvin_files/parsers/src/FileHeaderReader.o 
> fusion_sdk/calvin_files/parsers/src/FileInput.o 
> fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.o 
> fusion_sdk/calvin_files/parsers/src/GenericFileReader.o 
> fusion_sdk/calvin_files/utils/src/AffymetrixGuid.o 
> fusion_sdk/calvin_files/utils/src/DateTime.o 
> fusion_sdk/calvin_files/utils/src/FileUtils.o 
> fusion_sdk/calvin_files/utils/src/StringUtils.o 
> fusion_sdk/calvin_files/utils/src/checksum.o fusion_sdk/file/BPMAPFileData.o 
> fusion_sdk/file/BPMAPFileWriter.o fusion_sdk/file/CDFFileData.o 
> fusion_sdk/file/CELFileData.o fusion_sdk/file/FileIO.o 
> fusion_sdk/file/FileWriter.o R_affx_cel_parser.o R_affx_cdf_parser.o 
> R_affx_cdf_extras.o R_affx_bpmap_parser.o 
> -F/Library/Frameworks/R.framework/.. -framework R
> ** arch - ppc
> g++-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp-precomp 
> -I/Library/Frameworks/R.framework/Resources/include 
> -I/Library/Frameworks/R.framework/Resources/include/ppc -imacros 
> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src 
> -Ifusion_sdk/calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src 
> -Ifusion_sdk/calvin_files/fusion/src 
> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter 
> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter 
> -Ifusion_sdk/calvin_files/parameter/src -Ifusion_sdk/calvin_files/parsers/src 
> -Ifusion_sdk/calvin_files/portability/src 
> -Ifusion_sdk/calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src 
> -Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file 
> -Ifusion_sdk/portability -D_USE_MEM_MAPPING_ -I/usr/local/include    -fPIC 
> -g -O2 -Wall -O0 -c R_affx_cel_parser.cpp -o R_affx_cel_parser.o
>
> As you see from this (and sorry for all the include statements), when R 
> starts compiling for arch = "ppc", it starts with a with in /src whereas the 
> first compilation run (or more precise the first architecture) starts from 
> /src/fusion_sdk/calvin_files/data/src. This is of course because the object 
> files in the subdirectories do not get removed between the two architectures.
>
> This has - probably - something to do with R CMD SHLIB not cleaning up after 
> itself. A method of removing $(OBJECTS) would be exactly what I need, and may 
> I suggest that this is done per default instead of being set by an option. 
> Anyone using the CRAN binary for the Mac will have the same problem as I.
>
> I am happy to see that this may be fixed for R-2.6.0. Is there anything I can 
> do in the meantime for getting my package to work under R-2.5.1? (I can 
> always move my source files from the /src/fusion_sdk subdirectories directly 
> into /src, but I would prefer to avoid that).
>
>>> 
>>> Kasper
>>> 
>>> The full Makevars file:
>>> 
>>> MYCXXFLAGS=-O0
>> 
>> You do realize that is highly non-portable?
>
> Yes, but I do not know of any other way to downgrade the optimization level. 
> The SDK I am using breaks (due to memory alignment issues if a specific 
> optimization flag for GCC is include - the flag is certainly implied by -O2 
> and as far as I recall also -O1). I guess the solution is to switch to an 
> autoconfigure script. The main reason for not doing this is 1) time and 
> actually more 2) the fact that the SDK does not come with an ac script.
>
> Thanks for the feedback, Kasper
>
>
>>> %.o: %.cpp
>>> 	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>>> 
>>> PKG_CPPFLAGS=\
>>> -imacros R_affx_constants.h\
>>> -Ifusion_sdk/calvin_files/array/src\
>>> -Ifusion_sdk/calvin_files/data/src\
>>> -Ifusion_sdk/calvin_files/exception/src\
>>> -Ifusion_sdk/calvin_files/fusion/src\
>>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
>>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
>>> -Ifusion_sdk/calvin_files/parameter/src\
>>> -Ifusion_sdk/calvin_files/parsers/src\
>>> -Ifusion_sdk/calvin_files/portability/src\
>>> -Ifusion_sdk/calvin_files/template/src\
>>> -Ifusion_sdk/calvin_files/utils/src\
>>> -Ifusion_sdk/calvin_files/writers/src\
>>> -Ifusion_sdk/file\
>>> -Ifusion_sdk/portability\
>>> -D_USE_MEM_MAPPING_
>>> 
>>> PKG_SOURCES = \
>>> 	fusion_sdk/calvin_files/data/src/CDFData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
>>> 	fusion_sdk/calvin_files/data/src/CELData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataSet.cpp\
>>> 	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
>>> 	fusion_sdk/calvin_files/data/src/GenericData.cpp\
>>> 	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
>>> 	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/
>>> CalvinCELDataAdapter.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
>>> 	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.cpp\
>>> 	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
>>> 	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
>>> 	fusion_sdk/calvin_files/utils/src/checksum.cpp\
>>> 	fusion_sdk/file/BPMAPFileData.cpp\
>>> 	fusion_sdk/file/BPMAPFileWriter.cpp\
>>> 	fusion_sdk/file/CDFFileData.cpp\
>>> 	fusion_sdk/file/CELFileData.cpp\
>>> 	fusion_sdk/file/FileIO.cpp\
>>> 	fusion_sdk/file/FileWriter.cpp\
>>> 	R_affx_cel_parser.cpp\
>>> 	R_affx_cdf_parser.cpp\
>>> 	R_affx_cdf_extras.cpp\
>>> 	R_affx_bpmap_parser.cpp
>>> 
>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>> 
>>> all: $(SHLIB)
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jul 12 14:17:48 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jul 2007 13:17:48 +0100 (BST)
Subject: [Rd] cleanup and Makevars
In-Reply-To: <Pine.LNX.4.64.0707120954100.8241@gannet.stats.ox.ac.uk>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
	<637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
	<Pine.LNX.4.64.0707120954100.8241@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0707121313210.16834@gannet.stats.ox.ac.uk>

It seems this is the BioC package affxparser.
So my suggestion does work with

R CMD INSTALL affxparser

and using the preferred form of OBJECTS instead of OBJS also works.

BDR

On Thu, 12 Jul 2007, Prof Brian Ripley wrote:

> You seem extraordinarily reluctant to tell us what you are actually doing: no 
> command appears here.  I presume this is a call to R CMD INSTALL, but why do 
> I have to keep guessing?
>
> Since you have taken over the make action via the all: target in your 
> Makevars, you need also to take over responsibility for cleaning.  I should 
> think
>
> all: myclean $(SHLIB)
>
> myclean:
> 	rm -f $(OBJS)
>
> should do it.  And BTW, the use of $(OBJS) to set the objects is 
> undocumented, at least in 'Writing R Extensions'.
>
> On Wed, 11 Jul 2007, Kasper Daniel Hansen wrote:
>
>> 
>> On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:
>> 
>>> On Mon, 9 Jul 2007, Kasper Daniel Hansen wrote:
>>> 
>>>> Hi
>>>> 
>>>> This is a question prompted by the mac version of R, but as I see it,
>>>> it should have broader interest.
>>>> 
>>>> These days the CRAN Mac binary per default compiles every package for
>>>> two architectures. First i386 and then ppc. In between the two
>>>> compilation runs, any object files in pkgname/src is removed. This
>>>> cleanup is necessary since otherwise Make would not recompile the
>>>> object files under the next architecture.
>>>> 
>>>> I have a package which includes a large SDK which I have put in
>>>>  src/fusion_sdk
>>>> (and subdirectories). I take care of that by using a Makevars file
>>>> with essentially (the whole Makevars file is reproduced below)
>>>> 
>>>> PKG_SOURCES = \
>>>>        fusion_sdk/calvin_files/data/src/CDFData.cpp
>>>> 
>>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>>> 
>>>> all: $(SHLIB)
>>>> 
>>>> However, this setup does not remove the object files in the
>>>> fusion_sdk subdirectory. From a posting on R-sig-mac by Simon Urbanek
>>>> I learned that I need to clean up these directories myself.
>>>> 
>>>> I have - per R extensions - attempted to do so using a pkgname/
>>>> cleanup script. While this works for cleaning up the sub directories
>>>> when I do R CMD build, it seems as if this script is not being run
>>>> between compilation runs (is this intentional btw.?).
>>> 
>>> What do you mean by 'compilation runs'?  The 'cleanup' script will be run 
>>> by R CMD INSTALL --cleanup (and without --cleanup it is intentionally not 
>>> run).
>>> 
>>>> So my question is now: how do I in a simple way clean up my
>>>> subdirectories? I would prefer it to be as simple as possible because
>>>> so far I have not really needed anything besides a Makevars file. In
>>>> fact the impression I have right now from looking at the SHLIB and
>>>> INSTALL scripts is that I might need a Makefile that removes the
>>>> object files _before_ starting the compilation, as I don't really see
>>>> any cleanup process (eg. making a target clean) - but this may very
>>>> well be due to my limited understanding of these scripts.
>>> 
>>> I see R CMD INSTALL --clean that runs a clean up afterwards, and 2.6.0 
>>> will also have R CMD INSTALL --preclean in case you forgot --clean on the 
>>> last run.
>>> 
>>>> Any help/hints on how to proceed? Especially if I want it to be
>>>> portable?
>>> 
>>> What does R CMD INSTALL --clean not do that you want?
>>> 
>>> If you are talking about R CMD SHLIB, that currently does not clean up but 
>>> this has been raised and it will most likely have a --clean option in 
>>> 2.6.0 that removes $(OBJECTS).
>> 
>> Perhaps I was not clear enough: The CRAN binary of R for Mac has two 
>> architectures inside $R_HOME/bin/exec, namely "ppc" and "i386". This means 
>> that whenever anyone installs a source package I see two compilation runs - 
>> the following is a shortened output:
>> 
>> * Installing to library '/Library/Frameworks/R.framework/Resources/library'
>> * Installing *source* package 'affxparser' ...
>> ** libs
>> ** arch - i386
>> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk 
>> -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include 
>> -I/Library/Frameworks/R.framework/Resources/include/i386 -imacros 
>> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src 
>> -Ifusion_sdk/calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src 
>> -Ifusion_sdk/calvin_files/fusion/src 
>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter 
>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter 
>> -Ifusion_sdk/calvin_files/parameter/src 
>> -Ifusion_sdk/calvin_files/parsers/src 
>> -Ifusion_sdk/calvin_files/portability/src 
>> -Ifusion_sdk/calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src 
>> -Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file 
>> -Ifusion_sdk/portability -D_USE_MEM_MAPPING_ -msse3    -fPIC  -g -O2 -Wall 
>> -O0 -c fusion_sdk/calvin_files/data/src/CDFData.cpp -o 
>> fusion_sdk/calvin_files/data/src/CDFData.o
>> 
>> (Now a lot of other files gets compiled)
>> 
>> g++-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -dynamiclib 
>> -Wl,-macosx_version_min -Wl,10.3 -undefined dynamic_lookup -single_module 
>> -multiply_defined suppress -L/usr/local/lib -o affxparser.so 
>> fusion_sdk/calvin_files/data/src/CDFData.o 
>> fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.o 
>> fusion_sdk/calvin_files/data/src/CDFProbeInformation.o 
>> fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.o 
>> fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.o 
>> fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.o 
>> fusion_sdk/calvin_files/data/src/CELData.o 
>> fusion_sdk/calvin_files/data/src/DataGroup.o 
>> fusion_sdk/calvin_files/data/src/DataGroupHeader.o 
>> fusion_sdk/calvin_files/data/src/DataSet.o 
>> fusion_sdk/calvin_files/data/src/DataSetHeader.o 
>> fusion_sdk/calvin_files/data/src/FileHeader.o 
>> fusion_sdk/calvin_files/data/src/GenericData.o 
>> fusion_sdk/calvin_files/data/src/GenericDataHeader.o 
>> fusion_sdk/calvin_files/exception/src/ExceptionBase.o 
>> fusion_sdk/calvin_files/fusion/src/CalvinAdapter/CalvinCELDataAdapter.o 
>> fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.o 
>> fusion_sdk/calvin_files/fusion/src/FusionCDFData.o 
>> fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.o 
>> fusion_sdk/calvin_files/fusion/src/FusionCELData.o 
>> fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.o 
>> fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.o 
>> fusion_sdk/calvin_files/parsers/src/CDFFileReader.o 
>> fusion_sdk/calvin_files/parsers/src/CelFileReader.o 
>> fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.o 
>> fusion_sdk/calvin_files/parsers/src/DataGroupReader.o 
>> fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.o 
>> fusion_sdk/calvin_files/parsers/src/DataSetReader.o 
>> fusion_sdk/calvin_files/parsers/src/FileHeaderReader.o 
>> fusion_sdk/calvin_files/parsers/src/FileInput.o 
>> fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.o 
>> fusion_sdk/calvin_files/parsers/src/GenericFileReader.o 
>> fusion_sdk/calvin_files/utils/src/AffymetrixGuid.o 
>> fusion_sdk/calvin_files/utils/src/DateTime.o 
>> fusion_sdk/calvin_files/utils/src/FileUtils.o 
>> fusion_sdk/calvin_files/utils/src/StringUtils.o 
>> fusion_sdk/calvin_files/utils/src/checksum.o 
>> fusion_sdk/file/BPMAPFileData.o fusion_sdk/file/BPMAPFileWriter.o 
>> fusion_sdk/file/CDFFileData.o fusion_sdk/file/CELFileData.o 
>> fusion_sdk/file/FileIO.o fusion_sdk/file/FileWriter.o R_affx_cel_parser.o 
>> R_affx_cdf_parser.o R_affx_cdf_extras.o R_affx_bpmap_parser.o 
>> -F/Library/Frameworks/R.framework/.. -framework R
>> ** arch - ppc
>> g++-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp-precomp 
>> -I/Library/Frameworks/R.framework/Resources/include 
>> -I/Library/Frameworks/R.framework/Resources/include/ppc -imacros 
>> R_affx_constants.h -Ifusion_sdk/calvin_files/array/src 
>> -Ifusion_sdk/calvin_files/data/src -Ifusion_sdk/calvin_files/exception/src 
>> -Ifusion_sdk/calvin_files/fusion/src 
>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter 
>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter 
>> -Ifusion_sdk/calvin_files/parameter/src 
>> -Ifusion_sdk/calvin_files/parsers/src 
>> -Ifusion_sdk/calvin_files/portability/src 
>> -Ifusion_sdk/calvin_files/template/src -Ifusion_sdk/calvin_files/utils/src 
>> -Ifusion_sdk/calvin_files/writers/src -Ifusion_sdk/file 
>> -Ifusion_sdk/portability -D_USE_MEM_MAPPING_ -I/usr/local/include    -fPIC 
>> -g -O2 -Wall -O0 -c R_affx_cel_parser.cpp -o R_affx_cel_parser.o
>> 
>> As you see from this (and sorry for all the include statements), when R 
>> starts compiling for arch = "ppc", it starts with a with in /src whereas 
>> the first compilation run (or more precise the first architecture) starts 
>> from /src/fusion_sdk/calvin_files/data/src. This is of course because the 
>> object files in the subdirectories do not get removed between the two 
>> architectures.
>> 
>> This has - probably - something to do with R CMD SHLIB not cleaning up 
>> after itself. A method of removing $(OBJECTS) would be exactly what I need, 
>> and may I suggest that this is done per default instead of being set by an 
>> option. Anyone using the CRAN binary for the Mac will have the same problem 
>> as I.
>> 
>> I am happy to see that this may be fixed for R-2.6.0. Is there anything I 
>> can do in the meantime for getting my package to work under R-2.5.1? (I can 
>> always move my source files from the /src/fusion_sdk subdirectories 
>> directly into /src, but I would prefer to avoid that).
>> 
>>>> 
>>>> Kasper
>>>> 
>>>> The full Makevars file:
>>>> 
>>>> MYCXXFLAGS=-O0
>>> 
>>> You do realize that is highly non-portable?
>> 
>> Yes, but I do not know of any other way to downgrade the optimization 
>> level. The SDK I am using breaks (due to memory alignment issues if a 
>> specific optimization flag for GCC is include - the flag is certainly 
>> implied by -O2 and as far as I recall also -O1). I guess the solution is to 
>> switch to an autoconfigure script. The main reason for not doing this is 1) 
>> time and actually more 2) the fact that the SDK does not come with an ac 
>> script.
>> 
>> Thanks for the feedback, Kasper
>> 
>> 
>>>> %.o: %.cpp
>>>> 	$(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>>>> 
>>>> PKG_CPPFLAGS=\
>>>> -imacros R_affx_constants.h\
>>>> -Ifusion_sdk/calvin_files/array/src\
>>>> -Ifusion_sdk/calvin_files/data/src\
>>>> -Ifusion_sdk/calvin_files/exception/src\
>>>> -Ifusion_sdk/calvin_files/fusion/src\
>>>> -Ifusion_sdk/calvin_files/fusion/src/GCOSAdapter\
>>>> -Ifusion_sdk/calvin_files/fusion/src/CalvinAdapter\
>>>> -Ifusion_sdk/calvin_files/parameter/src\
>>>> -Ifusion_sdk/calvin_files/parsers/src\
>>>> -Ifusion_sdk/calvin_files/portability/src\
>>>> -Ifusion_sdk/calvin_files/template/src\
>>>> -Ifusion_sdk/calvin_files/utils/src\
>>>> -Ifusion_sdk/calvin_files/writers/src\
>>>> -Ifusion_sdk/file\
>>>> -Ifusion_sdk/portability\
>>>> -D_USE_MEM_MAPPING_
>>>> 
>>>> PKG_SOURCES = \
>>>> 	fusion_sdk/calvin_files/data/src/CDFData.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CDFProbeGroupInformation.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CDFProbeInformation.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CDFProbeSetInformation.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeInformation.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CDFQCProbeSetInformation.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/CELData.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/DataGroup.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/DataGroupHeader.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/DataSet.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/DataSetHeader.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/FileHeader.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/GenericData.cpp\
>>>> 	fusion_sdk/calvin_files/data/src/GenericDataHeader.cpp\
>>>> 	fusion_sdk/calvin_files/exception/src/ExceptionBase.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/CalvinAdapter/
>>>> CalvinCELDataAdapter.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/FusionBPMAPData.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFData.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/FusionCDFQCProbeSetNames.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/FusionCELData.cpp\
>>>> 	fusion_sdk/calvin_files/fusion/src/GCOSAdapter/GCOSCELDataAdapter.cpp\
>>>> 	fusion_sdk/calvin_files/parameter/src/ParameterNameValueType.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/CDFFileReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/CelFileReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupHeaderReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/DataGroupReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/DataSetHeaderReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/DataSetReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/FileHeaderReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/FileInput.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/GenericDataHeaderReader.cpp\
>>>> 	fusion_sdk/calvin_files/parsers/src/GenericFileReader.cpp\
>>>> 	fusion_sdk/calvin_files/utils/src/AffymetrixGuid.cpp\
>>>> 	fusion_sdk/calvin_files/utils/src/DateTime.cpp\
>>>> 	fusion_sdk/calvin_files/utils/src/FileUtils.cpp\
>>>> 	fusion_sdk/calvin_files/utils/src/StringUtils.cpp\
>>>> 	fusion_sdk/calvin_files/utils/src/checksum.cpp\
>>>> 	fusion_sdk/file/BPMAPFileData.cpp\
>>>> 	fusion_sdk/file/BPMAPFileWriter.cpp\
>>>> 	fusion_sdk/file/CDFFileData.cpp\
>>>> 	fusion_sdk/file/CELFileData.cpp\
>>>> 	fusion_sdk/file/FileIO.cpp\
>>>> 	fusion_sdk/file/FileWriter.cpp\
>>>> 	R_affx_cel_parser.cpp\
>>>> 	R_affx_cdf_parser.cpp\
>>>> 	R_affx_cdf_extras.cpp\
>>>> 	R_affx_bpmap_parser.cpp
>>>> 
>>>> OBJS=$(PKG_SOURCES:.cpp=.o)
>>>> 
>>>> all: $(SHLIB)
>>> 
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rick.jones at sungard.com  Thu Jul 12 19:00:11 2007
From: rick.jones at sungard.com (rick.jones at sungard.com)
Date: Thu, 12 Jul 2007 13:00:11 -0400
Subject: [Rd] In creating a Windows binary package (zip),
	how do I make the installation configurable
Message-ID: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>


I would like to create a binary package for Windows which when
installed will give the user an option of whether to install
one version or another.

Here is the problem, I have a package 'FAME' that can run
in two different modes on Windows. An old mode that uses
R to connect to a remote linux machine and a new way that
uses a locally installed database.

I would allow this decision to be made at run time, but
the DLL in the later case depends upon the database's DLL
being on the Windows machine. A runtime solution would 
require at least one extra level of dynamic loading.

So I would like something like this to happen:
 the zip file contains fame-local.dll and fame-remote.dll
 when the user selects 'install packages from a zip file'
 the user should be given the option of which DLL 
 should be renamed to 'fame.dll'.

Is this possible??

If so, how would I do it?

If not, then are there an recommendations for a solution?
  An alternative I can try is to have 2 separate packages,
  'fame' and 'fame-remote'.

Thanks,
Rick Jones


From pgilbert at bank-banque-canada.ca  Thu Jul 12 19:22:36 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 12 Jul 2007 13:22:36 -0400
Subject: [Rd] In creating a Windows binary package (zip),
 how do I make the installation configurable
In-Reply-To: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
References: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <4696635C.1090905@bank-banque-canada.ca>

rick.jones at sungard.com wrote:

>I would like to create a binary package for Windows which when
>installed will give the user an option of whether to install
>one version or another.
>
>Here is the problem, I have a package 'FAME' that can run
>in two different modes on Windows. 
>
I hope this is a Windows version of the package called fame already on 
CRAN. Otherwise, you need to think of a different name, and it would be 
nice to have versions that work on Sun and Linux, not just Windows.

>An old mode that uses
>R to connect to a remote linux machine 
>
Just remote linux machines, or does it handle remote Sun machines too? 
Does it handle the endian problem?

>and a new way that
>uses a locally installed database.
>
>I would allow this decision to be made at run time, but
>the DLL in the later case depends upon the database's DLL
>being on the Windows machine. A runtime solution would 
>require at least one extra level of dynamic loading.
>
>So I would like something like this to happen:
> the zip file contains fame-local.dll and fame-remote.dll
> when the user selects 'install packages from a zip file'
> the user should be given the option of which DLL 
> should be renamed to 'fame.dll'.
>  
>
I'm confused.  If you want the user to be able to make a run time 
decision then you can't make this choice at install time can you?  
Should you not be installing both  fame-local.dll and fame-remote.dll 
and then deciding at run time which one to call?  (If this package is 
doing what I think it is doing,  then users would want to make a run 
time choice. Actually, often I would want to use both at run time.)

Paul

>Is this possible??
>
>If so, how would I do it?
>
>If not, then are there an recommendations for a solution?
>  An alternative I can try is to have 2 separate packages,
>  'fame' and 'fame-remote'.
>
>Thanks,
>Rick Jones
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From osklyar at ebi.ac.uk  Thu Jul 12 19:23:35 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 12 Jul 2007 18:23:35 +0100
Subject: [Rd] In creating a Windows binary package (zip),
 how do I make the installation configurable
In-Reply-To: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
References: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <46966397.5090606@ebi.ac.uk>

A configure.win file if found in the root of the package is executed 
during install before files from /inst are copied. What you can do is 
not to put your dlls in /libs but elsewhere in /inst and write a simple 
DOS script that will copy the required dll into /libs and rename it 
correspondingly.

I have something similar for my package as I include a windows dll in 
the source package because compiling my package requires a lot of 
dependencies on Windows. So I have this dll in /inst/winlibs and the 
configure.win file deletes the /src directory (thus preventing it from 
compiling if inst/winlibs is not empty) and copies the dll to /libs

Have a look at the source of 
http://www.ebi.ac.uk/~osklyar/EBImage/src/EBImage_2.1.10.tar.gz

Best,
Oleg

rick.jones at sungard.com wrote:
> I would like to create a binary package for Windows which when
> installed will give the user an option of whether to install
> one version or another.
> 
> Here is the problem, I have a package 'FAME' that can run
> in two different modes on Windows. An old mode that uses
> R to connect to a remote linux machine and a new way that
> uses a locally installed database.
> 
> I would allow this decision to be made at run time, but
> the DLL in the later case depends upon the database's DLL
> being on the Windows machine. A runtime solution would 
> require at least one extra level of dynamic loading.
> 
> So I would like something like this to happen:
>  the zip file contains fame-local.dll and fame-remote.dll
>  when the user selects 'install packages from a zip file'
>  the user should be given the option of which DLL 
>  should be renamed to 'fame.dll'.
> 
> Is this possible??
> 
> If so, how would I do it?
> 
> If not, then are there an recommendations for a solution?
>   An alternative I can try is to have 2 separate packages,
>   'fame' and 'fame-remote'.
> 
> Thanks,
> Rick Jones
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Oleg Sklyar * EBI/EMBL, Cambridge CB10 1SD, England * +44-1223-494466


From ripley at stats.ox.ac.uk  Thu Jul 12 19:26:11 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jul 2007 18:26:11 +0100 (BST)
Subject: [Rd] In creating a Windows binary package (zip),
 how do I make the installation configurable
In-Reply-To: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
References: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <Pine.LNX.4.64.0707121823180.25331@gannet.stats.ox.ac.uk>

On Thu, 12 Jul 2007, rick.jones at sungard.com wrote:

> I would like to create a binary package for Windows which when
> installed will give the user an option of whether to install
> one version or another.
>
> Here is the problem, I have a package 'FAME' that can run
> in two different modes on Windows. An old mode that uses
> R to connect to a remote linux machine and a new way that
> uses a locally installed database.
>
> I would allow this decision to be made at run time, but
> the DLL in the later case depends upon the database's DLL
> being on the Windows machine. A runtime solution would
> require at least one extra level of dynamic loading.
>
> So I would like something like this to happen:
> the zip file contains fame-local.dll and fame-remote.dll
> when the user selects 'install packages from a zip file'
> the user should be given the option of which DLL
> should be renamed to 'fame.dll'.
>
> Is this possible??

No.  You can use your own installer, though, just as we do for R itself.

> If not, then are there an recommendations for a solution?

Why not look for the in-FAME DLL in your .onLoad function, and load the 
appropriate DLL at that time?  Or even put up a dialog box to ask the user 
(if there is: think about non-interactive use) at that point.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Thu Jul 12 19:32:18 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 12 Jul 2007 13:32:18 -0400
Subject: [Rd] In creating a Windows binary package (zip),
	how do I make the installation configurable
In-Reply-To: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
References: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <971536df0707121032v3b9026d2r660f0840edea63b1@mail.gmail.com>

You could look at the Ryacas package for some ideas.   zzz.R in

   http://ryacas.googlecode.com/svn/trunk/R/zzz.R

is invoked at library(Ryacas) checking whether certain binaries are present
and if not present then issues a message telling the user to run yacasInstall()
without arguments.  yacasInstall() in:

   http://ryacas.googlecode.com/svn/trunk/R/yacasInstall.R

downloads the required binaries into the appropriate place.  (Although
Ryacas runs on UNIX, Mac and Windows the yacasInstall functionality
and associated binaries are only available for Windows currently.  Manual
installation is required on UNIX and Mac.)

It would have been possible to have zzz.R call yacasInstall()
directly but we felt that downloading files to the user's computer
transparently was not a good idea and we should make the user
issue a specific command to do it to ensure that they really want
to allow that.  Also it gives the user the possibility of doing it manually
instead of using the automatic procedure.

On 7/12/07, rick.jones at sungard.com <rick.jones at sungard.com> wrote:
>
> I would like to create a binary package for Windows which when
> installed will give the user an option of whether to install
> one version or another.
>
> Here is the problem, I have a package 'FAME' that can run
> in two different modes on Windows. An old mode that uses
> R to connect to a remote linux machine and a new way that
> uses a locally installed database.
>
> I would allow this decision to be made at run time, but
> the DLL in the later case depends upon the database's DLL
> being on the Windows machine. A runtime solution would
> require at least one extra level of dynamic loading.
>
> So I would like something like this to happen:
>  the zip file contains fame-local.dll and fame-remote.dll
>  when the user selects 'install packages from a zip file'
>  the user should be given the option of which DLL
>  should be renamed to 'fame.dll'.
>
> Is this possible??
>
> If so, how would I do it?
>
> If not, then are there an recommendations for a solution?
>  An alternative I can try is to have 2 separate packages,
>  'fame' and 'fame-remote'.
>
> Thanks,
> Rick Jones
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Thu Jul 12 19:39:41 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 12 Jul 2007 13:39:41 -0400
Subject: [Rd] In creating a Windows binary package (zip),
 how do I make the installation configurable
In-Reply-To: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
References: <B9A3DF402FE5A44CB903DB0F130225F907D024@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <4696675D.3050306@stats.uwo.ca>

On 7/12/2007 1:00 PM, rick.jones at sungard.com wrote:
> I would like to create a binary package for Windows which when
> installed will give the user an option of whether to install
> one version or another.
> 
> Here is the problem, I have a package 'FAME' that can run
> in two different modes on Windows. An old mode that uses
> R to connect to a remote linux machine and a new way that
> uses a locally installed database.
> 
> I would allow this decision to be made at run time, but
> the DLL in the later case depends upon the database's DLL
> being on the Windows machine. A runtime solution would 
> require at least one extra level of dynamic loading.
> 
> So I would like something like this to happen:
>  the zip file contains fame-local.dll and fame-remote.dll
>  when the user selects 'install packages from a zip file'
>  the user should be given the option of which DLL 
>  should be renamed to 'fame.dll'.
> 
> Is this possible??
> 
> If so, how would I do it?

I don't think it's possible:  installing from a .zip file basically just 
copies the files to the system, it doesn't execute the code.

It would be possible to do this if installing from a source package 
(just build one DLL), or you could install both and delay the decision 
until you attach the package:  there are hooks to execute code when a 
package is loaded.

> If not, then are there an recommendations for a solution?
>   An alternative I can try is to have 2 separate packages,
>   'fame' and 'fame-remote'.

I'd do it through a load hook.  The rgl package does this when running 
on a Mac, because it's not until load time that it knows if the user is 
using X11 or Aqua.  See the .onLoad function in zzz.R for details.

Duncan Murdoch


From hin-tak.leung at cimr.cam.ac.uk  Thu Jul 12 21:10:03 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 12 Jul 2007 20:10:03 +0100
Subject: [Rd] cleanup and Makevars
In-Reply-To: <637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
	<637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
Message-ID: <46967C8B.5000300@cimr.cam.ac.uk>

Kasper Daniel Hansen wrote:
> On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:
<snipped>
>>> The full Makevars file:
>>>
>>> MYCXXFLAGS=-O0
>> You do realize that is highly non-portable?
> 
> Yes, but I do not know of any other way to downgrade the optimization  
> level. The SDK I am using breaks (due to memory alignment issues if a  
> specific optimization flag for GCC is include - the flag is certainly  
> implied by -O2 and as far as I recall also -O1). I guess the solution  
> is to switch to an autoconfigure script. The main reason for not  
> doing this is 1) time and actually more 2) the fact that the SDK does  
> not come with an ac script.
> 
> Thanks for the feedback, Kasper
<snipped>

I think I probably know about the breakage - gcc 4.x mis-compiles
the Affymetrix toolkit at the default optimization (-02) shipped with 
the toolkit. (Prof Ripley's comment was spot-on - why the reluctance
to just call it the Affymetrix toolkit bundled with the bioconductor
package affyparser?). I narrowed it down to the strict-aliasing
option... try '-O2 -fno-strict-aliasing' - it is not portable, but it
works around the funny way some part of the affy toolkit (actually one
particular file) is written.

I did report it in the Affy forum and also directly to my Affymetrix
dev contacts about a year ago; gcc 4 is the default on the mac these
days, I think?

On a related issue, I have some annoyance with cross-compiling leaving 
behind *.o files (and *.d, etc) which get in the way of native
compile and vice versa, and I have been wondering if there is a
recommended solution? What I am currently doing is to have a
"Makefile.utils" (I don't want or need a proper Makefile), and do
'make -f Makefile.utils clean' when I need to clean up - it is better
than typing
   rm -f  *.o *.so *~ *.rc *.d *.dll Makedeps *.def

(particularly with bash's file completion, all I am typing is
'make -f M<tab>f<tab> clean' to clean up). I am sure somebody will laugh
at this...

Hin-Tak


From ripley at stats.ox.ac.uk  Thu Jul 12 21:17:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jul 2007 20:17:44 +0100 (BST)
Subject: [Rd] cleanup and Makevars
In-Reply-To: <46967C8B.5000300@cimr.cam.ac.uk>
References: <A153F980-E93F-4623-B097-E7635151386B@stat.berkeley.edu>
	<Pine.LNX.4.64.0707100553350.16628@gannet.stats.ox.ac.uk>
	<637BDDED-F9CD-48D1-A0C1-D982AAA9DA29@stat.Berkeley.EDU>
	<46967C8B.5000300@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0707122016210.26523@gannet.stats.ox.ac.uk>

On Thu, 12 Jul 2007, Hin-Tak Leung wrote:

> Kasper Daniel Hansen wrote:
>> On Jul 11, 2007, at 9:30 AM, Prof Brian Ripley wrote:
> <snipped>
>>>> The full Makevars file:
>>>> 
>>>> MYCXXFLAGS=-O0
>>> You do realize that is highly non-portable?
>> 
>> Yes, but I do not know of any other way to downgrade the optimization 
>> level. The SDK I am using breaks (due to memory alignment issues if a 
>> specific optimization flag for GCC is include - the flag is certainly 
>> implied by -O2 and as far as I recall also -O1). I guess the solution  is 
>> to switch to an autoconfigure script. The main reason for not  doing this 
>> is 1) time and actually more 2) the fact that the SDK does  not come with 
>> an ac script.
>> 
>> Thanks for the feedback, Kasper
> <snipped>
>
> I think I probably know about the breakage - gcc 4.x mis-compiles
> the Affymetrix toolkit at the default optimization (-02) shipped with the 
> toolkit. (Prof Ripley's comment was spot-on - why the reluctance
> to just call it the Affymetrix toolkit bundled with the bioconductor
> package affyparser?). I narrowed it down to the strict-aliasing
> option... try '-O2 -fno-strict-aliasing' - it is not portable, but it
> works around the funny way some part of the affy toolkit (actually one
> particular file) is written.
>
> I did report it in the Affy forum and also directly to my Affymetrix
> dev contacts about a year ago; gcc 4 is the default on the mac these
> days, I think?
>
> On a related issue, I have some annoyance with cross-compiling leaving behind 
> *.o files (and *.d, etc) which get in the way of native
> compile and vice versa, and I have been wondering if there is a
> recommended solution? What I am currently doing is to have a

Hopefully the --clean options to INSTALL and SHLIB in R-devel will help.
If they don't examples of what is needed will help improve.

> "Makefile.utils" (I don't want or need a proper Makefile), and do
> 'make -f Makefile.utils clean' when I need to clean up - it is better
> than typing
>  rm -f  *.o *.so *~ *.rc *.d *.dll Makedeps *.def
>
> (particularly with bash's file completion, all I am typing is
> 'make -f M<tab>f<tab> clean' to clean up). I am sure somebody will laugh
> at this...
>
> Hin-Tak
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Gregor.Gorjanc at bfro.uni-lj.si  Thu Jul 12 22:26:47 2007
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Thu, 12 Jul 2007 22:26:47 +0200
Subject: [Rd] (no subject)
Message-ID: <7FFEE688B57D7346BC6241C55900E730F31DCB@pollux.bfro.uni-lj.si>

I have just found Sun Grid R-Project resource project site at

https://r-project.dev.java.net/

Gregor


From pingoufc4 at yahoo.fr  Fri Jul 13 00:02:28 2007
From: pingoufc4 at yahoo.fr (pingou)
Date: Fri, 13 Jul 2007 00:02:28 +0200
Subject: [Rd] Presentation and packaging policy
Message-ID: <4696A4F4.5040908@yahoo.fr>

Dear all,

I have recently subscribed to this mailing list.
To briefly introduce myself, my name is Pierre-Yves, I am French,
student and actually doing a master in bioinformatics.
I am involved in a project on which I will have to use R and some of its
libraries.
To use these libraries as I am running Fedora, I have made the RPM of
these libraries for Fedora.

I have already made some libraries and the first one has just
successfully gone through the bugzilla. However I would like to ask for
your opinion about (re)packaging the libraries for the different
distribution.

I see it with two advantages:
*Updating system such as yum can manage the dependences between the
different packages
*It is a way to control the quality of the package and make sure that it
set up the file at their correct place.

What do you think of it in general ?
Do you encourage it ?

Any way thank for the work done,
Best regards,
Pierre-Yves  ~pingou


From hpages at fhcrc.org  Fri Jul 13 00:17:29 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 12 Jul 2007 15:17:29 -0700
Subject: [Rd] Generics in base with no ...
Message-ID: <4696A879.4090905@fhcrc.org>

Hi,

Some generics in base that don't have the ... extra argument:
rev(), t(), scale() and unlist(). Is there any plan to make these
more reusable? I used to be interested in having a rev() method for
my objects, but since I needed an extra argument for it, then I was
forced to create my own generic instead. And because I didn't want
to mask base::rev(), I chose another name too. The only advantage
of doing this is that the man page for myrev() was more accessible
than if I had made a rev() method. But it would be nice to make the
rev() generic more reusable anyway, just because the name "rev"
itself is good and easy to remember.

Thanks!

H.


From murdoch at stats.uwo.ca  Fri Jul 13 01:58:30 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 12 Jul 2007 19:58:30 -0400
Subject: [Rd] Generics in base with no ...
In-Reply-To: <4696A879.4090905@fhcrc.org>
References: <4696A879.4090905@fhcrc.org>
Message-ID: <4696C026.7080308@stats.uwo.ca>

On 12/07/2007 6:17 PM, Herve Pages wrote:
> Hi,
> 
> Some generics in base that don't have the ... extra argument:
> rev(), t(), scale() and unlist(). Is there any plan to make these
> more reusable? I used to be interested in having a rev() method for
> my objects, but since I needed an extra argument for it, then I was
> forced to create my own generic instead. And because I didn't want
> to mask base::rev(), I chose another name too. The only advantage
> of doing this is that the man page for myrev() was more accessible
> than if I had made a rev() method. But it would be nice to make the
> rev() generic more reusable anyway, just because the name "rev"
> itself is good and easy to remember.

It would be helpful to give specific examples of use cases.  As far as I 
know, adding the ... makes every call slower; this is acceptable if 
there's a good reason to do it, but I think we should think about it.

rev() in particular seems as though it should always take an ordered 
thing and return the same kind of thing but in the reversed order:  why 
would you want to add optional args, and still call it rev?  If you're 
using some user-specified ordering, wouldn't it be better to use sort(), 
instead?

Duncan Murdoch


From hpages at fhcrc.org  Fri Jul 13 03:10:30 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 12 Jul 2007 18:10:30 -0700
Subject: [Rd] Generics in base with no ...
In-Reply-To: <4696C026.7080308@stats.uwo.ca>
References: <4696A879.4090905@fhcrc.org> <4696C026.7080308@stats.uwo.ca>
Message-ID: <4696D106.3000404@fhcrc.org>

Duncan Murdoch wrote:
> On 12/07/2007 6:17 PM, Herve Pages wrote:
>> Hi,
>>
>> Some generics in base that don't have the ... extra argument:
>> rev(), t(), scale() and unlist(). Is there any plan to make these
>> more reusable? I used to be interested in having a rev() method for
>> my objects, but since I needed an extra argument for it, then I was
>> forced to create my own generic instead. And because I didn't want
>> to mask base::rev(), I chose another name too. The only advantage
>> of doing this is that the man page for myrev() was more accessible
>> than if I had made a rev() method. But it would be nice to make the
>> rev() generic more reusable anyway, just because the name "rev"
>> itself is good and easy to remember.
> 
> It would be helpful to give specific examples of use cases.  As far as I
> know, adding the ... makes every call slower; this is acceptable if
> there's a good reason to do it, but I think we should think about it.
> 
> rev() in particular seems as though it should always take an ordered
> thing and return the same kind of thing but in the reversed order:  why
> would you want to add optional args, and still call it rev?  If you're
> using some user-specified ordering, wouldn't it be better to use sort(),
> instead?

My objects have a name which is stored in a slot. When I revert it, I need
to rename it too because I don't want to end up with 2 different objects
having the same name. I could do y <- rev(x); y at objName <- "new name" but
this is not conceptually very good: the action of reversing _and_ renaming
should be atomic. So I wanted to add an 'objName' arg to my rev() method.

You could also imagine that the individual elements of the ordered thing
you want to revert are themselves ordered things. So maybe you just want
to reverse the top level elements or you want this to be recursive ("deep"
reversing). Then you need an extra argument like the 'recursive' arg of
the unlist() generic to control this.

Anyway, I was not aware of the performance penalty introduced by adding ...
so I understand now why these generics have not been modified so far.

Thanks!
H.


> 
> Duncan Murdoch
>


From hpages at fhcrc.org  Fri Jul 13 03:25:59 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 12 Jul 2007 18:25:59 -0700
Subject: [Rd] seq_along() doesn't use _my_ length
Message-ID: <4696D4A7.404@fhcrc.org>

Hi,

According to seq_along man page, 'seq_along(x)' is equivalent to
'seq_len(length(x))' but apparently not if 'x' is an S4 object with
a defined "length" method:

  > seq_along(letters[11:15])
  [1] 1 2 3 4 5

  > setClass("A", representation(titi="character"))
  [1] "A"

  > setMethod("length", "A", function(x) length(x at titi))
  [1] "length"

  > a <- new("A", titi=letters[11:15])

  > length(a)
  [1] 5

  > seq_along(a)
  [1] 1

Thanks!
H.


From deepayan.sarkar at gmail.com  Fri Jul 13 03:52:50 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 12 Jul 2007 18:52:50 -0700
Subject: [Rd] parse(text=...) and the srcfile attribute
Message-ID: <eb555e660707121852x13817360t5def7f645632e86@mail.gmail.com>

Hi,

I'm trying to understand whether the new source file references can
help me with something I want to do. Let's say I have

foo <- parse(text = "
a <- 1; b <- 2**2
a + b
")

I now wish to recover the sources for the parsed expressions. I can
get them one at a time:

> foo[[2]]
b <- 2^2
> as.character(attr(foo, "srcref")[[2]])
[1] "b <- 2**2"

Is there a better way? Perhaps like the print method

> as.character(foo, useSource = TRUE)

could give all the sources at once?

-Deepayan


From ggrothendieck at gmail.com  Fri Jul 13 04:02:15 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 12 Jul 2007 22:02:15 -0400
Subject: [Rd] parse(text=...) and the srcfile attribute
In-Reply-To: <eb555e660707121852x13817360t5def7f645632e86@mail.gmail.com>
References: <eb555e660707121852x13817360t5def7f645632e86@mail.gmail.com>
Message-ID: <971536df0707121902t44b214e5r212da62fba7688a@mail.gmail.com>

You can do this:

> foo at srcfile$lines
[1] "\na <- 1; b <- 2**2\na + b\n"

> # or this
> as.character(foo)
[1] "a <- 1"   "b <- 2^2" "a + b"

On 7/12/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> Hi,
>
> I'm trying to understand whether the new source file references can
> help me with something I want to do. Let's say I have
>
> foo <- parse(text = "
> a <- 1; b <- 2**2
> a + b
> ")
>
> I now wish to recover the sources for the parsed expressions. I can
> get them one at a time:
>
> > foo[[2]]
> b <- 2^2
> > as.character(attr(foo, "srcref")[[2]])
> [1] "b <- 2**2"
>
> Is there a better way? Perhaps like the print method
>
> > as.character(foo, useSource = TRUE)
>
> could give all the sources at once?
>
> -Deepayan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From deepayan.sarkar at gmail.com  Fri Jul 13 04:10:59 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 12 Jul 2007 19:10:59 -0700
Subject: [Rd] parse(text=...) and the srcfile attribute
In-Reply-To: <971536df0707121902t44b214e5r212da62fba7688a@mail.gmail.com>
References: <eb555e660707121852x13817360t5def7f645632e86@mail.gmail.com>
	<971536df0707121902t44b214e5r212da62fba7688a@mail.gmail.com>
Message-ID: <eb555e660707121910i216ea27cvd71a1bf32b36f288@mail.gmail.com>

On 7/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> You can do this:
>
> > foo at srcfile$lines
> [1] "\na <- 1; b <- 2**2\na + b\n"
>
> > # or this
> > as.character(foo)
> [1] "a <- 1"   "b <- 2^2" "a + b"

Neither of which is what I want. I want

> sapply(attr(foo, "srcref"), as.character)
[1] "a <- 1"    "b <- 2**2" "a + b"

but was hoping for a better way than this.

-Deepayan

>
> On 7/12/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> > Hi,
> >
> > I'm trying to understand whether the new source file references can
> > help me with something I want to do. Let's say I have
> >
> > foo <- parse(text = "
> > a <- 1; b <- 2**2
> > a + b
> > ")
> >
> > I now wish to recover the sources for the parsed expressions. I can
> > get them one at a time:
> >
> > > foo[[2]]
> > b <- 2^2
> > > as.character(attr(foo, "srcref")[[2]])
> > [1] "b <- 2**2"
> >
> > Is there a better way? Perhaps like the print method
> >
> > > as.character(foo, useSource = TRUE)
> >
> > could give all the sources at once?
> >
> > -Deepayan
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From murdoch at stats.uwo.ca  Fri Jul 13 12:52:26 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 13 Jul 2007 06:52:26 -0400
Subject: [Rd] parse(text=...) and the srcfile attribute
In-Reply-To: <eb555e660707121910i216ea27cvd71a1bf32b36f288@mail.gmail.com>
References: <eb555e660707121852x13817360t5def7f645632e86@mail.gmail.com>	<971536df0707121902t44b214e5r212da62fba7688a@mail.gmail.com>
	<eb555e660707121910i216ea27cvd71a1bf32b36f288@mail.gmail.com>
Message-ID: <4697596A.5030205@stats.uwo.ca>

On 12/07/2007 10:10 PM, Deepayan Sarkar wrote:
> On 7/12/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>> You can do this:
>>
>>> foo at srcfile$lines
>> [1] "\na <- 1; b <- 2**2\na + b\n"
>>
>>> # or this
>>> as.character(foo)
>> [1] "a <- 1"   "b <- 2^2" "a + b"
> 
> Neither of which is what I want. I want
> 
>> sapply(attr(foo, "srcref"), as.character)
> [1] "a <- 1"    "b <- 2**2" "a + b"
> 
> but was hoping for a better way than this.

I don't think there is one.  The code for print(foo) is deep within the 
deparser, and it never generates the things you want individually, 
they're just part of what gets generated when it deparses foo. (One 
reason for this design is that foo has a srcref attribute, its elements 
don't, because the elements of an expression are not necessarily things 
that can sensibly have attributes.)

So your one-liner is probably the best way to get what you want.

Duncan Murdoch


> -Deepayan
> 
>> On 7/12/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
>>> Hi,
>>>
>>> I'm trying to understand whether the new source file references can
>>> help me with something I want to do. Let's say I have
>>>
>>> foo <- parse(text = "
>>> a <- 1; b <- 2**2
>>> a + b
>>> ")
>>>
>>> I now wish to recover the sources for the parsed expressions. I can
>>> get them one at a time:
>>>
>>>> foo[[2]]
>>> b <- 2^2
>>>> as.character(attr(foo, "srcref")[[2]])
>>> [1] "b <- 2**2"
>>>
>>> Is there a better way? Perhaps like the print method
>>>
>>>> as.character(foo, useSource = TRUE)
>>> could give all the sources at once?
>>>
>>> -Deepayan
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Mike.Lawrence at DAL.CA  Fri Jul 13 18:29:37 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Fri, 13 Jul 2007 13:29:37 -0300
Subject: [Rd] Suggestion to extend aggregate() to return multiple and/or
	named values
Message-ID: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>

Hi all,

This is my first post to the developers list. As I understand it,  
aggregate() currently repeats a function across cells in a dataframe  
but is only able to handle functions with single value returns.  
Aggregate() also lacks the ability to retain the names given to the  
returned value. I've created an agg() function (pasted below) that is  
apparently backwards compatible (i.e. returns identical results as  
aggregate() if the function returns a single unnamed value), but is  
able to handle named and/or multiple return values. The code may be a  
little inefficient (there must be an easier way to set up the 'temp'  
data frame than to call aggregate and remove the final column), but  
I'm suggesting that something similar to this may be profitably used  
to replace aggregate entirely.

#modified aggregate command, allowing for multiple/named output values
agg=function(z,Ind,FUN,...){
	FUN.out=by(z,Ind,FUN,...)
	num.cells=length(FUN.out)
	num.dv=length(FUN.out[[1]])
	
	temp=aggregate(z,Ind,length) #dummy data frame
	temp=temp[,c(1:(length(temp)-1))] #remove last column from dummy frame
		
	for(i in 1:num.dv){
		temp=cbind(temp,NA)
		n=names(FUN.out[[1]])[i]
		names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse(i==1,'x',paste 
('x',i,sep='')))
		for(j in 1:num.cells){
			temp[j,length(temp)]=FUN.out[[j]][i]
		}
	}
	return(temp)
}

#create some factored data
z=rnorm(100) # the DV
A=rep(1:2,each=25,2) #one factor
B=rep(1:2,each=50) #another factor
Ind=list(A=A,B=B) #the factor list

aggregate(z,Ind,mean) #show the means of each cell
agg(z,Ind,mean) #should be identical to aggregate

aggregate(z,Ind,summary) #returns an error
agg(z,Ind,summary) #returns named columns

#Make a function that returns multiple unnamed values
summary2=function(x){
	s=summary(x)
	names(s)=NULL
	return(s)
}
agg(z,Ind,summary2) #returns multiple columns, default names


--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From ggrothendieck at gmail.com  Fri Jul 13 19:04:03 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 13 Jul 2007 13:04:03 -0400
Subject: [Rd] Suggestion to extend aggregate() to return multiple and/or
	named values
In-Reply-To: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>
References: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>
Message-ID: <971536df0707131004t8e02436w38918a1f6f14617@mail.gmail.com>

Note that summaryBy in the doBy package can also do that.

library(doBy)
DF <- data.frame(z, A = Ind$A, B = Ind$B)
summaryBy(z ~ A + B, DF, FUN = summary)
summaryBy(z ~ A + B, DF, FUN = summary2)

On 7/13/07, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi all,
>
> This is my first post to the developers list. As I understand it,
> aggregate() currently repeats a function across cells in a dataframe
> but is only able to handle functions with single value returns.
> Aggregate() also lacks the ability to retain the names given to the
> returned value. I've created an agg() function (pasted below) that is
> apparently backwards compatible (i.e. returns identical results as
> aggregate() if the function returns a single unnamed value), but is
> able to handle named and/or multiple return values. The code may be a
> little inefficient (there must be an easier way to set up the 'temp'
> data frame than to call aggregate and remove the final column), but
> I'm suggesting that something similar to this may be profitably used
> to replace aggregate entirely.
>
> #modified aggregate command, allowing for multiple/named output values
> agg=function(z,Ind,FUN,...){
>        FUN.out=by(z,Ind,FUN,...)
>        num.cells=length(FUN.out)
>        num.dv=length(FUN.out[[1]])
>
>        temp=aggregate(z,Ind,length) #dummy data frame
>        temp=temp[,c(1:(length(temp)-1))] #remove last column from dummy frame
>
>        for(i in 1:num.dv){
>                temp=cbind(temp,NA)
>                n=names(FUN.out[[1]])[i]
>                names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse(i==1,'x',paste
> ('x',i,sep='')))
>                for(j in 1:num.cells){
>                        temp[j,length(temp)]=FUN.out[[j]][i]
>                }
>        }
>        return(temp)
> }
>
> #create some factored data
> z=rnorm(100) # the DV
> A=rep(1:2,each=25,2) #one factor
> B=rep(1:2,each=50) #another factor
> Ind=list(A=A,B=B) #the factor list
>
> aggregate(z,Ind,mean) #show the means of each cell
> agg(z,Ind,mean) #should be identical to aggregate
>
> aggregate(z,Ind,summary) #returns an error
> agg(z,Ind,summary) #returns named columns
>
> #Make a function that returns multiple unnamed values
> summary2=function(x){
>        s=summary(x)
>        names(s)=NULL
>        return(s)
> }
> agg(z,Ind,summary2) #returns multiple columns, default names
>
>
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://memetic.ca
>
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
>        - Piet Hein
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Mike.Lawrence at DAL.CA  Fri Jul 13 19:46:01 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Fri, 13 Jul 2007 14:46:01 -0300
Subject: [Rd] Suggestion to extend aggregate() to return multiple and/or
 named values
In-Reply-To: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>
References: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>
Message-ID: <A2BC81D2-9210-4DA5-9C33-E26318B9196D@DAL.CA>

bugfix already :P prior version fails when there is only one factor  
in Ind. This version also might be faster as I avoid using aggregate  
to create the dummy frame.

agg=function(z,Ind,FUN,...){
	FUN.out=by(z,Ind,FUN,...)
	num.cells=length(FUN.out)
	num.values=length(FUN.out[[1]])
	
	for(i in 1:length(Ind)){
		Ind[[i]]=unique(Ind[[i]])
	}
	temp=expand.grid(Ind)

	for(i in 1:num.values){
		temp$new=NA
		n=names(FUN.out[[1]])[i]
		names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse(i==1,'x',paste 
('x',i,sep='')))
		for(j in 1:num.cells){
			temp[j,length(temp)]=FUN.out[[j]][i]
		}
	}
	return(temp)
}


On 13-Jul-07, at 1:29 PM, Mike Lawrence wrote:

> Hi all,
>
> This is my first post to the developers list. As I understand it,  
> aggregate() currently repeats a function across cells in a  
> dataframe but is only able to handle functions with single value  
> returns. Aggregate() also lacks the ability to retain the names  
> given to the returned value. I've created an agg() function (pasted  
> below) that is apparently backwards compatible (i.e. returns  
> identical results as aggregate() if the function returns a single  
> unnamed value), but is able to handle named and/or multiple return  
> values. The code may be a little inefficient (there must be an  
> easier way to set up the 'temp' data frame than to call aggregate  
> and remove the final column), but I'm suggesting that something  
> similar to this may be profitably used to replace aggregate entirely.
>
> #modified aggregate command, allowing for multiple/named output values
> agg=function(z,Ind,FUN,...){
> 	FUN.out=by(z,Ind,FUN,...)
> 	num.cells=length(FUN.out)
> 	num.dv=length(FUN.out[[1]])
> 	
> 	temp=aggregate(z,Ind,length) #dummy data frame
> 	temp=temp[,c(1:(length(temp)-1))] #remove last column from dummy  
> frame
> 		
> 	for(i in 1:num.dv){
> 		temp=cbind(temp,NA)
> 		n=names(FUN.out[[1]])[i]
> 		names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse 
> (i==1,'x',paste('x',i,sep='')))
> 		for(j in 1:num.cells){
> 			temp[j,length(temp)]=FUN.out[[j]][i]
> 		}
> 	}
> 	return(temp)
> }
>
> #create some factored data
> z=rnorm(100) # the DV
> A=rep(1:2,each=25,2) #one factor
> B=rep(1:2,each=50) #another factor
> Ind=list(A=A,B=B) #the factor list
>
> aggregate(z,Ind,mean) #show the means of each cell
> agg(z,Ind,mean) #should be identical to aggregate
>
> aggregate(z,Ind,summary) #returns an error
> agg(z,Ind,summary) #returns named columns
>
> #Make a function that returns multiple unnamed values
> summary2=function(x){
> 	s=summary(x)
> 	names(s)=NULL
> 	return(s)
> }
> agg(z,Ind,summary2) #returns multiple columns, default names
>
>
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://memetic.ca
>
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
> 	- Piet Hein
>
>

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From ggrothendieck at gmail.com  Fri Jul 13 19:56:35 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 13 Jul 2007 13:56:35 -0400
Subject: [Rd] Suggestion to extend aggregate() to return multiple and/or
	named values
In-Reply-To: <A2BC81D2-9210-4DA5-9C33-E26318B9196D@DAL.CA>
References: <5A3CBD8A-FB97-43E2-BA0E-EB6DAC1FDB28@DAL.CA>
	<A2BC81D2-9210-4DA5-9C33-E26318B9196D@DAL.CA>
Message-ID: <971536df0707131056v12d51bbeo4e6602375c539863@mail.gmail.com>

Note that it does not work in this case:

> aggregate(CO2[4:5], CO2[1:2], mean)
   Plant        Type conc   uptake
1    Qn1      Quebec  435 33.22857
2    Qn2      Quebec  435 35.15714
3    Qn3      Quebec  435 37.61429
4    Qc1      Quebec  435 29.97143
5    Qc3      Quebec  435 32.58571
6    Qc2      Quebec  435 32.70000
7    Mn3 Mississippi  435 24.11429
8    Mn2 Mississippi  435 27.34286
9    Mn1 Mississippi  435 26.40000
10   Mc2 Mississippi  435 12.14286
11   Mc3 Mississippi  435 17.30000
12   Mc1 Mississippi  435 18.00000
> > agg(CO2[4:5], CO2[1:2], mean)
Error: syntax error, unexpected GT in ">"
> Error in `[[<-.data.frame`(`*tmp*`, i, value = c(1L, 2L, 3L, 4L, 6L, 5L,  :
Error: syntax error, unexpected IN, expecting '\n' or ';' in "Error in"
>         replacement has 7056 rows, data has 84
Error: syntax error, unexpected SYMBOL, expecting '\n' or ';' in "
   replacement has"
>


On 7/13/07, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> bugfix already :P prior version fails when there is only one factor
> in Ind. This version also might be faster as I avoid using aggregate
> to create the dummy frame.
>
> agg=function(z,Ind,FUN,...){
>        FUN.out=by(z,Ind,FUN,...)
>        num.cells=length(FUN.out)
>        num.values=length(FUN.out[[1]])
>
>        for(i in 1:length(Ind)){
>                Ind[[i]]=unique(Ind[[i]])
>        }
>        temp=expand.grid(Ind)
>
>        for(i in 1:num.values){
>                temp$new=NA
>                n=names(FUN.out[[1]])[i]
>                names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse(i==1,'x',paste
> ('x',i,sep='')))
>                for(j in 1:num.cells){
>                        temp[j,length(temp)]=FUN.out[[j]][i]
>                }
>        }
>        return(temp)
> }
>
>
> On 13-Jul-07, at 1:29 PM, Mike Lawrence wrote:
>
> > Hi all,
> >
> > This is my first post to the developers list. As I understand it,
> > aggregate() currently repeats a function across cells in a
> > dataframe but is only able to handle functions with single value
> > returns. Aggregate() also lacks the ability to retain the names
> > given to the returned value. I've created an agg() function (pasted
> > below) that is apparently backwards compatible (i.e. returns
> > identical results as aggregate() if the function returns a single
> > unnamed value), but is able to handle named and/or multiple return
> > values. The code may be a little inefficient (there must be an
> > easier way to set up the 'temp' data frame than to call aggregate
> > and remove the final column), but I'm suggesting that something
> > similar to this may be profitably used to replace aggregate entirely.
> >
> > #modified aggregate command, allowing for multiple/named output values
> > agg=function(z,Ind,FUN,...){
> >       FUN.out=by(z,Ind,FUN,...)
> >       num.cells=length(FUN.out)
> >       num.dv=length(FUN.out[[1]])
> >
> >       temp=aggregate(z,Ind,length) #dummy data frame
> >       temp=temp[,c(1:(length(temp)-1))] #remove last column from dummy
> > frame
> >
> >       for(i in 1:num.dv){
> >               temp=cbind(temp,NA)
> >               n=names(FUN.out[[1]])[i]
> >               names(temp)[length(temp)]=ifelse(!is.null(n),n,ifelse
> > (i==1,'x',paste('x',i,sep='')))
> >               for(j in 1:num.cells){
> >                       temp[j,length(temp)]=FUN.out[[j]][i]
> >               }
> >       }
> >       return(temp)
> > }
> >
> > #create some factored data
> > z=rnorm(100) # the DV
> > A=rep(1:2,each=25,2) #one factor
> > B=rep(1:2,each=50) #another factor
> > Ind=list(A=A,B=B) #the factor list
> >
> > aggregate(z,Ind,mean) #show the means of each cell
> > agg(z,Ind,mean) #should be identical to aggregate
> >
> > aggregate(z,Ind,summary) #returns an error
> > agg(z,Ind,summary) #returns named columns
> >
> > #Make a function that returns multiple unnamed values
> > summary2=function(x){
> >       s=summary(x)
> >       names(s)=NULL
> >       return(s)
> > }
> > agg(z,Ind,summary2) #returns multiple columns, default names
> >
> >
> > --
> > Mike Lawrence
> > Graduate Student, Department of Psychology, Dalhousie University
> >
> > Website: http://memetic.ca
> >
> > Public calendar: http://icalx.com/public/informavore/Public
> >
> > "The road to wisdom? Well, it's plain and simple to express:
> > Err and err and err again, but less and less and less."
> >       - Piet Hein
> >
> >
>
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
>
> Website: http://memetic.ca
>
> Public calendar: http://icalx.com/public/informavore/Public
>
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
>        - Piet Hein
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From savicky at cs.cas.cz  Fri Jul 13 22:37:36 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 13 Jul 2007 22:37:36 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
	<316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>
Message-ID: <20070713203735.GA18016@cs.cas.cz>

I would like to suggest a replacement for the curent function
sweep based on the two previous suggestions posted at
  https://stat.ethz.ch/pipermail/r-help/2005-June/073989.html
and
  http://wiki.r-project.org/rwiki/doku.php?id=rdoc:base:sweep
with some extensions.

My suggestion is to use one of the following two variants. They
differ in whether length(STATS) == 1 is allowed without a warning
in the stricter (default) check or not. I don't know, what is better.

  sweep1 <- function (x, MARGIN, STATS, FUN = "-", check.margin=TRUE, ...)
  {
      FUN <- match.fun(FUN)
      dims <- dim(x)
      dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
      if (length(MARGIN) < length(dimstat)) {
          STATS <- drop(STATS)
          dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
      }
      if (check.margin && length(STATS) > 1 &&
          (length(dimstat)!=length(MARGIN) || any(dims[MARGIN]!=dimstat))) {
          warning("length(STATS) or dim(STAT) do not match dim(x)[MARGIN]")
      } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
          warning("prod(dim(x)[MARGIN]) is not a multiple of length(STATS)")
      perm <- c(MARGIN, (1:length(dims))[-MARGIN])
      FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
  }

  sweep2 <- function (x, MARGIN, STATS, FUN = "-", check.margin=TRUE, ...)
  {
      FUN <- match.fun(FUN)
      dims <- dim(x)
      dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
      if (length(MARGIN) < length(dimstat)) {
          STATS <- drop(STATS)
          dimstat <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
      }
      if (check.margin &&
          (length(dimstat)!=length(MARGIN) || any(dims[MARGIN]!=dimstat))) {
          warning("length(STATS) or dim(STAT) do not match dim(x)[MARGIN]")
      } else if (prod(dims[MARGIN]) %% length(STATS)!=0)
          warning("prod(dim(x)[MARGIN]) is not a multiple of length(STATS)")
      perm <- c(MARGIN, (1:length(dims))[-MARGIN])
      FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
  }

The functions are tested on the following examples.

  a <- array(1:64,dim=c(4,4,4))
  M <- c(1,3);

  b          sweep1(a,M,b) sweep2(a,M,b) sweep1(a,M,b,c=F) sweep2(a,M,b,c=F)

  a[,2,]     -             -             -                 - 
  a[1:2,2,]  warning       warning       -                 - 
  1          -             warning       -                 -
  1:3        warning       warning       warning           warning
  1:16       warning       warning       -                 -

  a <- matrix(1:8,nrow=4,ncol=2);
  M <- 1;

  b          sweep1(a,M,b) sweep2(a,M,b) sweep1(a,M,b,c=F) sweep2(a,M,b,c=F)

  1          -             warning       -                 -
  1:2        warning       warning       -                 -
  1:3        warning       warning       warning           warning
  1:4        -             -             -                 -
  matrix(1:4,nrow=1) # (A)
             -             -             -                 -
  matrix(1:4,ncol=1) # (B)
             -             -             -                 -

  a <- matrix(1:8,nrow=4,ncol=2);
  M <- 2;

  b          sweep1(a,M,b) sweep2(a,M,b) sweep1(a,M,b,c=F) sweep2(a,M,b,c=F)

  1          -             warning       -                 -
  1:2        -             -             -                 -
  1:3        warning       warning       warning           warning
  1:4        warning       warning       warning           warning
  matrix(1:2,ncol=1) # (A)
             -             -             -                 -
  matrix(1:2,nrow=1) # (B)
             -             -             -                 -

Note that cases marked (A) do not generate a warning, although they
should. This is the cost of using drop(STATS), which allows cases
marked (B) without a warning. In my opinion, cases (B) make sense.

Reproducing the tests is possible using the script
  http://www.cs.cas.cz/~savicky/R-devel/verify_sweep.R

Petr.


From ggrothendieck at gmail.com  Sat Jul 14 22:11:10 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 14 Jul 2007 16:11:10 -0400
Subject: [Rd] row names and identical
Message-ID: <971536df0707141311s2f8958eh838bfc7387991037@mail.gmail.com>

Below x1, x2 and x3 all have the same data and all have the same value
for row.names(x); however, the internal values of their row.names differ.
The internal value of row.names is c(NA, -4L) for x1, c(NA, 4L) for x2 and
c("1", "2", "3", "4") for x3; nevertheless, identical regards x1 and x2 as
identical while x3 is not identical to either of x1 or x2.

Is this intended?
Desirable?
Why do we need different internal representations for row.names
for x1 and x2?


> x1 <- x2 <- x3 <- data.frame(x = 11:14)
> row.names(x2) <- 1:4
> row.names(x3) <- as.character(1:4)
>
> # they all have the same value for row.names()
> row.names(x1)
[1] "1" "2" "3" "4"
> row.names(x2)
[1] "1" "2" "3" "4"
> row.names(x3)
[1] "1" "2" "3" "4"
>
> # but internally they are all different
> dput(x1)
structure(list(x = 11:14), .Names = "x", row.names = c(NA, -4L
), class = "data.frame")
> dput(x2)
structure(list(x = 11:14), .Names = "x", row.names = c(NA, 4L
), class = "data.frame")
> dput(x3)
structure(list(x = 11:14), .Names = "x", row.names = c("1", "2",
"3", "4"), class = "data.frame")
>
> # identical regards x1 and x2 as the same while x3 differs
> identical(x1, x2)
[1] TRUE
> identical(x1, x3)
[1] FALSE
> identical(x2, x3)
[1] FALSE
>
> R.version.string # XP
[1] "R version 2.5.1 (2007-06-27)"


From jjonphl at gmail.com  Mon Jul 16 04:23:09 2007
From: jjonphl at gmail.com (miguel manese)
Date: Mon, 16 Jul 2007 10:23:09 +0800
Subject: [Rd] row names and identical
In-Reply-To: <971536df0707141311s2f8958eh838bfc7387991037@mail.gmail.com>
References: <971536df0707141311s2f8958eh838bfc7387991037@mail.gmail.com>
Message-ID: <d35b9da60707151923m3a49d006p223924ca9b4735ed@mail.gmail.com>

I was bit by this before. row.names are supposed to be characters, and
they are until around 2.3 iirc. Then at 2.4, they started storing it
as integers presumably to save space (and probably because ints are
more low-maintenance data types than strings). So to the user (e.g.
through row.names() ) they are still characters, but internally they
are not. I don't know what c(NA, 4L) stands for though (I see that it
has 4 elems...), or why the other is c(NA, -4L). However, in my code I
access them as a vector of integers,

rownames = getAttrib(df, R_RowNamesSymbol);
if (IS_INTEGER(rownames)) {
    for (int i = 0; i < LENGTH(rownames); i++) foo(INTEGER(rownames)[i] ...);
}

Cheers,
M. Manese

On 7/15/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Below x1, x2 and x3 all have the same data and all have the same value
> for row.names(x); however, the internal values of their row.names differ.
> The internal value of row.names is c(NA, -4L) for x1, c(NA, 4L) for x2 and
> c("1", "2", "3", "4") for x3; nevertheless, identical regards x1 and x2 as
> identical while x3 is not identical to either of x1 or x2.
>
> Is this intended?
> Desirable?
> Why do we need different internal representations for row.names
> for x1 and x2?
>
>
> > x1 <- x2 <- x3 <- data.frame(x = 11:14)
> > row.names(x2) <- 1:4
> > row.names(x3) <- as.character(1:4)
> >
> > # they all have the same value for row.names()
> > row.names(x1)
> [1] "1" "2" "3" "4"
> > row.names(x2)
> [1] "1" "2" "3" "4"
> > row.names(x3)
> [1] "1" "2" "3" "4"
> >
> > # but internally they are all different
> > dput(x1)
> structure(list(x = 11:14), .Names = "x", row.names = c(NA, -4L
> ), class = "data.frame")
> > dput(x2)
> structure(list(x = 11:14), .Names = "x", row.names = c(NA, 4L
> ), class = "data.frame")
> > dput(x3)
> structure(list(x = 11:14), .Names = "x", row.names = c("1", "2",
> "3", "4"), class = "data.frame")
> >
> > # identical regards x1 and x2 as the same while x3 differs
> > identical(x1, x2)
> [1] TRUE
> > identical(x1, x3)
> [1] FALSE
> > identical(x2, x3)
> [1] FALSE
> >
> > R.version.string # XP
> [1] "R version 2.5.1 (2007-06-27)"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jjonphl at gmail.com  Mon Jul 16 04:25:09 2007
From: jjonphl at gmail.com (miguel manese)
Date: Mon, 16 Jul 2007 10:25:09 +0800
Subject: [Rd] row names and identical
In-Reply-To: <d35b9da60707151923m3a49d006p223924ca9b4735ed@mail.gmail.com>
References: <971536df0707141311s2f8958eh838bfc7387991037@mail.gmail.com>
	<d35b9da60707151923m3a49d006p223924ca9b4735ed@mail.gmail.com>
Message-ID: <d35b9da60707151925i5ee0763eh3ce520802b69ec72@mail.gmail.com>

I mean, starting 2.4 not all row names are stored as characters, some
are stored as integers.

On 7/16/07, miguel manese <jjonphl at gmail.com> wrote:
> I was bit by this before. row.names are supposed to be characters, and
> they are until around 2.3 iirc. Then at 2.4, they started storing it
> as integers presumably to save space (and probably because ints are
> more low-maintenance data types than strings). So to the user (e.g.
> through row.names() ) they are still characters, but internally they
> are not. I don't know what c(NA, 4L) stands for though (I see that it
> has 4 elems...), or why the other is c(NA, -4L). However, in my code I
> access them as a vector of integers,
>
> rownames = getAttrib(df, R_RowNamesSymbol);
> if (IS_INTEGER(rownames)) {
>     for (int i = 0; i < LENGTH(rownames); i++) foo(INTEGER(rownames)[i] ...);
> }
>
> Cheers,
> M. Manese
>
> On 7/15/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Below x1, x2 and x3 all have the same data and all have the same value
> > for row.names(x); however, the internal values of their row.names differ.
> > The internal value of row.names is c(NA, -4L) for x1, c(NA, 4L) for x2 and
> > c("1", "2", "3", "4") for x3; nevertheless, identical regards x1 and x2 as
> > identical while x3 is not identical to either of x1 or x2.
> >
> > Is this intended?
> > Desirable?
> > Why do we need different internal representations for row.names
> > for x1 and x2?
> >
> >
> > > x1 <- x2 <- x3 <- data.frame(x = 11:14)
> > > row.names(x2) <- 1:4
> > > row.names(x3) <- as.character(1:4)
> > >
> > > # they all have the same value for row.names()
> > > row.names(x1)
> > [1] "1" "2" "3" "4"
> > > row.names(x2)
> > [1] "1" "2" "3" "4"
> > > row.names(x3)
> > [1] "1" "2" "3" "4"
> > >
> > > # but internally they are all different
> > > dput(x1)
> > structure(list(x = 11:14), .Names = "x", row.names = c(NA, -4L
> > ), class = "data.frame")
> > > dput(x2)
> > structure(list(x = 11:14), .Names = "x", row.names = c(NA, 4L
> > ), class = "data.frame")
> > > dput(x3)
> > structure(list(x = 11:14), .Names = "x", row.names = c("1", "2",
> > "3", "4"), class = "data.frame")
> > >
> > > # identical regards x1 and x2 as the same while x3 differs
> > > identical(x1, x2)
> > [1] TRUE
> > > identical(x1, x3)
> > [1] FALSE
> > > identical(x2, x3)
> > [1] FALSE
> > >
> > > R.version.string # XP
> > [1] "R version 2.5.1 (2007-06-27)"
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From ggrothendieck at gmail.com  Mon Jul 16 05:30:24 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 15 Jul 2007 23:30:24 -0400
Subject: [Rd] row names and identical
In-Reply-To: <d35b9da60707151925i5ee0763eh3ce520802b69ec72@mail.gmail.com>
References: <971536df0707141311s2f8958eh838bfc7387991037@mail.gmail.com>
	<d35b9da60707151923m3a49d006p223924ca9b4735ed@mail.gmail.com>
	<d35b9da60707151925i5ee0763eh3ce520802b69ec72@mail.gmail.com>
Message-ID: <971536df0707152030x12d2d8f6m891b4d46b6d8c865@mail.gmail.com>

The question which is whether the way identical works is desirable
or intended.

On 7/15/07, miguel manese <jjonphl at gmail.com> wrote:
> I mean, starting 2.4 not all row names are stored as characters, some
> are stored as integers.
>
> On 7/16/07, miguel manese <jjonphl at gmail.com> wrote:
> > I was bit by this before. row.names are supposed to be characters, and
> > they are until around 2.3 iirc. Then at 2.4, they started storing it
> > as integers presumably to save space (and probably because ints are
> > more low-maintenance data types than strings). So to the user (e.g.
> > through row.names() ) they are still characters, but internally they
> > are not. I don't know what c(NA, 4L) stands for though (I see that it
> > has 4 elems...), or why the other is c(NA, -4L). However, in my code I
> > access them as a vector of integers,
> >
> > rownames = getAttrib(df, R_RowNamesSymbol);
> > if (IS_INTEGER(rownames)) {
> >     for (int i = 0; i < LENGTH(rownames); i++) foo(INTEGER(rownames)[i] ...);
> > }
> >
> > Cheers,
> > M. Manese
> >
> > On 7/15/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > Below x1, x2 and x3 all have the same data and all have the same value
> > > for row.names(x); however, the internal values of their row.names differ.
> > > The internal value of row.names is c(NA, -4L) for x1, c(NA, 4L) for x2 and
> > > c("1", "2", "3", "4") for x3; nevertheless, identical regards x1 and x2 as
> > > identical while x3 is not identical to either of x1 or x2.
> > >
> > > Is this intended?
> > > Desirable?
> > > Why do we need different internal representations for row.names
> > > for x1 and x2?
> > >
> > >
> > > > x1 <- x2 <- x3 <- data.frame(x = 11:14)
> > > > row.names(x2) <- 1:4
> > > > row.names(x3) <- as.character(1:4)
> > > >
> > > > # they all have the same value for row.names()
> > > > row.names(x1)
> > > [1] "1" "2" "3" "4"
> > > > row.names(x2)
> > > [1] "1" "2" "3" "4"
> > > > row.names(x3)
> > > [1] "1" "2" "3" "4"
> > > >
> > > > # but internally they are all different
> > > > dput(x1)
> > > structure(list(x = 11:14), .Names = "x", row.names = c(NA, -4L
> > > ), class = "data.frame")
> > > > dput(x2)
> > > structure(list(x = 11:14), .Names = "x", row.names = c(NA, 4L
> > > ), class = "data.frame")
> > > > dput(x3)
> > > structure(list(x = 11:14), .Names = "x", row.names = c("1", "2",
> > > "3", "4"), class = "data.frame")
> > > >
> > > > # identical regards x1 and x2 as the same while x3 differs
> > > > identical(x1, x2)
> > > [1] TRUE
> > > > identical(x1, x3)
> > > [1] FALSE
> > > > identical(x2, x3)
> > > [1] FALSE
> > > >
> > > > R.version.string # XP
> > > [1] "R version 2.5.1 (2007-06-27)"
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>


From ripley at stats.ox.ac.uk  Mon Jul 16 10:48:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Jul 2007 09:48:16 +0100 (BST)
Subject: [Rd] Progress report on 64-bit builds under Windows
Message-ID: <Pine.LNX.4.64.0707160738340.12992@gannet.stats.ox.ac.uk>

We have been asked for a couple of years about builds of R for 
64-bit Windows, e.g. at UserR 2006.  Users of 64-bit Windows still 
seem very thin on the ground, but apparently

   'Microsoft scraps 32-bit operating systems

   Microsoft has announced that Windows Server 2008 will be the last 32-bit
   system it releases, for servers or clients, as it makes its way fully
   into the world of 64-bit computing.'

(http://www.pcpro.co.uk/news/113114/microsoft-scraps-32bit-operating-systems.html)

I've not heard recently of any programmeR working on such a build.

I have Vista 64 on my current Windows desktop, intending it to be my main 
Windows platform (the machine also has Windows XP).  With the current 
Rtools.exe I am successfully doing R development on it (e.g. the only 
CRAN package that I can install under XP but not Vista 64 is RSQLite, an 
internal problem in dlltool).

A 64-bit version of R could be just a sub-architecture: only the binaries 
in R_HOME/bin and DLLs in R_HOME/modules and library/*/libs need to be 
different.  So in an ideal world we would be able to distribute binary 
packages that supported both 32- and 64-bit builds, and to build those on 
a single OS via 32/64-bit cross-compilers.  Quite a number of packages 
need support software of course: one of those is Tcl/Tk. (That is built 
using VC++, so presumably could be built using a 64-bit edition of VC++: 
see below.  Similarly iconv.dll.)


1) The good news is that under Vista 64 you get a 4GB address space for 
the current builds of R, rather than 2GB for most 32-bit versions of 
Windows, or 3GB if the /3GB switch was used.  So there is a worthwhile 
gain in using a 64-bit OS even with a 32-bit build of R.


2) To make a 64-bit build of R we need a 64-bit toolchain.  Kai Tietz has 
been working on versions of gcc and binutils, see

http://www.nabble.com/64-bit-MinGW-on-64-bit-Windows-XP-tf4012895.html

This is essentially a cross-compiler running under Cygwin.  I didn't 
succeed in getting that to build, but did build a cross-compiler chain 
under x86_64 Linux and built simple C programs that run correctly.  This 
enabled me to try building R.  There were several problems:

- most Fortran programs give an ICE (internal compiler error).
- importing a variable from a DLL gives an ICE.
- a couple of modules gave ICEs if optimization was used.
- the headers have many problems, with broken attempts at inlining and
   missing declarations.
- R itself will need some changes, as on Win64 'long' is 32-bit and cannot
   store a pointer.

Given that the toolchain is a one-man effort, I do not see these getting 
resolved soon.


3) An alternative is to use a non-GNU toolchain, e.g. from Microsoft, 
Intel or PGI (formerly Portland).  There seems no longer to be a Fortran 
compiler compatible with Microsoft Visual Studio (formerly from 
DEC/Compaq/HP), but Intel and PGI have Fortran compilers, at a price.
Someone from Microsoft reported that he had built a 64-bit version of R, 
but gave an invalid return address and we have not been able to find out 
how he did it.

There is a free (but not Free) version of Visual Studio 2005 that is said 
to be 32-bit only, but I have discovered that the free Vista Platform SDK 
contains a 64-bit toolchain.  (I have full Visual Studio 2005, which has 
64-bit and 64-bit on 32-bit and v.v. cross-compilers.)  So I believe it 
should be possible to build a 64-bit version of R using Microsoft 
compilers and f2c, and may try to do so over the summer.


Is there anyone working on (or interested in working on) these issue?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From focus17 at libero.it  Fri Jul  6 15:04:59 2007
From: focus17 at libero.it (focus17 at libero.it)
Date: Fri,  6 Jul 2007 15:04:59 +0200 (CEST)
Subject: [Rd] error in trunc function (PR#9782)
Message-ID: <20070706130459.35278486CF@slim.kubism.ku.dk>

Full_Name: Claudio
Version: 2.5.1
OS: windows
Submission from: (NULL) (157.138.120.198)


the command get a wrong result

> trunc(2.3*100)
229


From murdoch at stats.uwo.ca  Mon Jul 16 12:36:34 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 16 Jul 2007 06:36:34 -0400
Subject: [Rd] error in trunc function (PR#9782)
In-Reply-To: <20070706130459.35278486CF@slim.kubism.ku.dk>
References: <20070706130459.35278486CF@slim.kubism.ku.dk>
Message-ID: <469B4A32.3050108@stats.uwo.ca>

focus17 at libero.it wrote:
> Full_Name: Claudio
> Version: 2.5.1
> OS: windows
> Submission from: (NULL) (157.138.120.198)
>
>
> the command get a wrong result
>
>   
>> trunc(2.3*100)
>>     
> 229
That is the correct answer.  2.3 is not representable exactly; the 
actual value used is slightly less.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Jul 16 12:43:01 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 16 Jul 2007 12:43:01 +0200 (CEST)
Subject: [Rd] error in trunc function (PR#9782)
Message-ID: <20070716104301.BC5135D609@slim.kubism.ku.dk>

The result is correct.  The representation of 2.3 is slightly less than 
2.3: non-binary fractions cannot be represented exactly.

> 2.3*100 - 230
[1] -2.842171e-14

On Fri, 6 Jul 2007, focus17 at libero.it wrote:

> Full_Name: Claudio
> Version: 2.5.1
> OS: windows
> Submission from: (NULL) (157.138.120.198)
>
>
> the command get a wrong result
>
>> trunc(2.3*100)
> 229
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Mon Jul 16 13:34:24 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 16 Jul 2007 13:34:24 +0200
Subject: [Rd] error in trunc function (PR#9782)
In-Reply-To: <20070706130459.35278486CF@slim.kubism.ku.dk>
References: <20070706130459.35278486CF@slim.kubism.ku.dk>
Message-ID: <469B57C0.7040901@biostat.ku.dk>

focus17 at libero.it wrote:
> Full_Name: Claudio
> Version: 2.5.1
> OS: windows
> Submission from: (NULL) (157.138.120.198)
>
>
> the command get a wrong result
>
>   
>> trunc(2.3*100)
>>     
> 229
>
> __
Not a bug, read FAQ 7.31 and the reference therein.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ggrothendieck at gmail.com  Mon Jul 16 15:28:50 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 09:28:50 -0400
Subject: [Rd] formula(CO2)
Message-ID: <971536df0707160628g37e301e1wf81eaee0b7feb841@mail.gmail.com>

The formula attribute of the builtin CO2 dataset seems a bit strange:

> formula(CO2)
Plant ~ Type + Treatment + conc + uptake

What is one supposed to do with that?  Certainly its not suitable for
input to lm and none of the examples in ?CO2 use the above.


From ted.harding at nessie.mcc.ac.uk  Mon Jul 16 15:57:56 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Jul 2007 14:57:56 +0100 (BST)
Subject: [Rd] formula(CO2)
In-Reply-To: <971536df0707160628g37e301e1wf81eaee0b7feb841@mail.gmail.com>
Message-ID: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>

On 16-Jul-07 13:28:50, Gabor Grothendieck wrote:
> The formula attribute of the builtin CO2 dataset seems a bit strange:
> 
>> formula(CO2)
> Plant ~ Type + Treatment + conc + uptake
> 
> What is one supposed to do with that?  Certainly its not suitable
> for input to lm and none of the examples in ?CO2 use the above.

I think one is supposed to ignore it! (Or maybe be inspired to
write a mail to the list ... ).

I couldn't find anything that looked like the above formula from
str(CO2). But I did spot that the order of terms in the formula:
Plant, Type, treatment, conc, uptake, is the same as the order
of the "columns" in the dataframe.

So I tried:

  D<-data.frame(x=(1:10),y=(1:10))

  formula(D)
  x ~ y

So, lo and behold, D has a formula!

Or does it? Maybe if you give formula() a dataframe, it simply
constructs one from the "columns".

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jul-07                                       Time: 14:57:28
------------------------------ XFMail ------------------------------


From ted.harding at nessie.mcc.ac.uk  Mon Jul 16 16:14:40 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Jul 2007 15:14:40 +0100 (BST)
Subject: [Rd] formula(CO2)
In-Reply-To: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.070716151440.ted.harding@nessie.mcc.ac.uk>

On 16-Jul-07 13:57:56, Ted Harding wrote:
> On 16-Jul-07 13:28:50, Gabor Grothendieck wrote:
>> The formula attribute of the builtin CO2 dataset seems a bit strange:
>> 
>>> formula(CO2)
>> Plant ~ Type + Treatment + conc + uptake
>> 
>> What is one supposed to do with that?  Certainly its not suitable
>> for input to lm and none of the examples in ?CO2 use the above.
> 
> I think one is supposed to ignore it! (Or maybe be inspired to
> write a mail to the list ... ).
> 
> I couldn't find anything that looked like the above formula from
> str(CO2). But I did spot that the order of terms in the formula:
> Plant, Type, treatment, conc, uptake, is the same as the order
> of the "columns" in the dataframe.
> 
> So I tried:
> 
>   D<-data.frame(x=(1:10),y=(1:10))
> 
>   formula(D)
>   x ~ y
> 
> So, lo and behold, D has a formula!
> 
> Or does it? Maybe if you give formula() a dataframe, it simply
> constructs one from the "columns".

Now that I think about it, I can see a use for this phenomenon:

  > formula(CO2)
  Plant ~ Type + Treatment + conc + uptake
  > formula(CO2[,2:5])
  Type ~ Treatment + conc + uptake
  > formula(CO2[,3:5])
  Treatment ~ conc + uptake
  > formula(CO2[,4:5])
  conc ~ uptake
  > formula(CO2[,c(5,1,2,3,4)])
  uptake ~ Plant + Type + Treatment + conc


Could save a lot of typing!

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jul-07                                       Time: 15:14:38
------------------------------ XFMail ------------------------------


From ggrothendieck at gmail.com  Mon Jul 16 16:16:10 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 10:16:10 -0400
Subject: [Rd] formula(CO2)
In-Reply-To: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
References: <971536df0707160628g37e301e1wf81eaee0b7feb841@mail.gmail.com>
	<XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
Message-ID: <971536df0707160716i7084039cp48560beb367fa141@mail.gmail.com>

Following up on your comments it seems formula.data.frame just creates
a formula whose lhs is the first column name and whose rhs is made up
of the remaining column names.  It ignores the "formula" attribute.

In fact, CO2 does have a formula attribute but its not extracted by
formula.data.frame:

> CO2 at formula
uptake ~ conc | Plant
> formula(CO2)
Plant ~ Type + Treatment + conc + uptake

Is this really how its supposed to work???

On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> On 16-Jul-07 13:28:50, Gabor Grothendieck wrote:
> > The formula attribute of the builtin CO2 dataset seems a bit strange:
> >
> >> formula(CO2)
> > Plant ~ Type + Treatment + conc + uptake
> >
> > What is one supposed to do with that?  Certainly its not suitable
> > for input to lm and none of the examples in ?CO2 use the above.
>
> I think one is supposed to ignore it! (Or maybe be inspired to
> write a mail to the list ... ).
>
> I couldn't find anything that looked like the above formula from
> str(CO2). But I did spot that the order of terms in the formula:
> Plant, Type, treatment, conc, uptake, is the same as the order
> of the "columns" in the dataframe.
>
> So I tried:
>
>  D<-data.frame(x=(1:10),y=(1:10))
>
>  formula(D)
>  x ~ y
>
> So, lo and behold, D has a formula!
>
> Or does it? Maybe if you give formula() a dataframe, it simply
> constructs one from the "columns".
>
> Best wishes,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 16-Jul-07                                       Time: 14:57:28
> ------------------------------ XFMail ------------------------------
>


From gavin.simpson at ucl.ac.uk  Mon Jul 16 16:21:44 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 16 Jul 2007 15:21:44 +0100
Subject: [Rd] formula(CO2)
In-Reply-To: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
References: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
Message-ID: <1184595704.32447.66.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2007-07-16 at 14:57 +0100, ted.harding at nessie.mcc.ac.uk wrote:
> On 16-Jul-07 13:28:50, Gabor Grothendieck wrote:
> > The formula attribute of the builtin CO2 dataset seems a bit strange:
> > 
> >> formula(CO2)
> > Plant ~ Type + Treatment + conc + uptake
> > 
> > What is one supposed to do with that?  Certainly its not suitable
> > for input to lm and none of the examples in ?CO2 use the above.
> 
> I think one is supposed to ignore it! (Or maybe be inspired to
> write a mail to the list ... ).
> 
> I couldn't find anything that looked like the above formula from
> str(CO2). But I did spot that the order of terms in the formula:
> Plant, Type, treatment, conc, uptake, is the same as the order
> of the "columns" in the dataframe.

CO2 is a groupedData object not a data.frame per se.

> class(CO2)
[1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"

What Gabor saw was the result of formula.data.frame being applied to
CO2, which, as you surmise Ted, is being produced from the columns of
CO2.

> formula(CO2)
Plant ~ Type + Treatment + conc + uptake
> stats:::formula.data.frame(CO2)
Plant ~ Type + Treatment + conc + uptake

But if we load nlme, we see that now (via a groupedData method for
formula) a more useful formula is displayed.

> require(nlme)
Loading required package: nlme
[1] TRUE
> formula(CO2)
uptake ~ conc | Plant

as this can then be directly used in lme

> lme(CO2)
Linear mixed-effects model fit by REML
  Data: CO2
  Log-restricted-likelihood: -283.1447
  Fixed: uptake ~ conc
(Intercept)        conc
19.50028981  0.01773059
<snip />

But like Gabor, I'm struggling to see where this [formula(data.frame)]
might be used (useful)?

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ggrothendieck at gmail.com  Mon Jul 16 16:30:48 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 10:30:48 -0400
Subject: [Rd] formula(CO2)
In-Reply-To: <1184595704.32447.66.camel@gsimpson.geog.ucl.ac.uk>
References: <XFMail.070716145756.ted.harding@nessie.mcc.ac.uk>
	<1184595704.32447.66.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <971536df0707160730i5d5b96cal2ea39c6738012398@mail.gmail.com>

Good point.

It seems that the "groupedData" methods are all in the nlme package yet
CO2 is in datasets.  CO2 should probably be moved to nlme.

Of course one still wonders whether the way formula currently works on
data frames is really intended and desirable.  Ted's point is well taken
but I think formula.data.frame could still have the current default
yet be user overridable via the formula attribute.

On 7/16/07, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Mon, 2007-07-16 at 14:57 +0100, ted.harding at nessie.mcc.ac.uk wrote:
> > On 16-Jul-07 13:28:50, Gabor Grothendieck wrote:
> > > The formula attribute of the builtin CO2 dataset seems a bit strange:
> > >
> > >> formula(CO2)
> > > Plant ~ Type + Treatment + conc + uptake
> > >
> > > What is one supposed to do with that?  Certainly its not suitable
> > > for input to lm and none of the examples in ?CO2 use the above.
> >
> > I think one is supposed to ignore it! (Or maybe be inspired to
> > write a mail to the list ... ).
> >
> > I couldn't find anything that looked like the above formula from
> > str(CO2). But I did spot that the order of terms in the formula:
> > Plant, Type, treatment, conc, uptake, is the same as the order
> > of the "columns" in the dataframe.
>
> CO2 is a groupedData object not a data.frame per se.
>
> > class(CO2)
> [1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"
>
> What Gabor saw was the result of formula.data.frame being applied to
> CO2, which, as you surmise Ted, is being produced from the columns of
> CO2.
>
> > formula(CO2)
> Plant ~ Type + Treatment + conc + uptake
> > stats:::formula.data.frame(CO2)
> Plant ~ Type + Treatment + conc + uptake
>
> But if we load nlme, we see that now (via a groupedData method for
> formula) a more useful formula is displayed.
>
> > require(nlme)
> Loading required package: nlme
> [1] TRUE
> > formula(CO2)
> uptake ~ conc | Plant
>
> as this can then be directly used in lme
>
> > lme(CO2)
> Linear mixed-effects model fit by REML
>  Data: CO2
>  Log-restricted-likelihood: -283.1447
>  Fixed: uptake ~ conc
> (Intercept)        conc
> 19.50028981  0.01773059
> <snip />
>
> But like Gabor, I'm struggling to see where this [formula(data.frame)]
> might be used (useful)?
>
> G
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From ted.harding at nessie.mcc.ac.uk  Mon Jul 16 16:40:40 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Jul 2007 15:40:40 +0100 (BST)
Subject: [Rd] formula(CO2)
In-Reply-To: <971536df0707160716i7084039cp48560beb367fa141@mail.gmail.com>
Message-ID: <XFMail.070716154040.ted.harding@nessie.mcc.ac.uk>

On 16-Jul-07 14:16:10, Gabor Grothendieck wrote:
> Following up on your comments it seems formula.data.frame just creates
> a formula whose lhs is the first column name and whose rhs is made up
> of the remaining column names.  It ignores the "formula" attribute.
> 
> In fact, CO2 does have a formula attribute but its not extracted by
> formula.data.frame:
> 
>> CO2 at formula
> uptake ~ conc | Plant
>> formula(CO2)
> Plant ~ Type + Treatment + conc + uptake

Indeed! And, following up yet again on my own follow-up comment:

library(combinat)

for(j in (1:4)){
  for(i in combn((1:4),j,simplify=FALSE)){
    print(formula(CO2[,c(5,i)]))
  }
}
uptake ~ Plant
uptake ~ Type
uptake ~ Treatment
uptake ~ conc
uptake ~ Plant + Type
uptake ~ Plant + Treatment
uptake ~ Plant + conc
uptake ~ Type + Treatment
uptake ~ Type + conc
uptake ~ Treatment + conc
uptake ~ Plant + Type + Treatment
uptake ~ Plant + Type + conc
uptake ~ Plant + Treatment + conc
uptake ~ Type + Treatment + conc
uptake ~ Plant + Type + Treatment + conc

opening the door to automated fitting of all possible models
(without interactions)!

Now if only I could find out how to do the interactions as well,
I would never need to think again!

best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jul-07                                       Time: 15:40:36
------------------------------ XFMail ------------------------------


From ggrothendieck at gmail.com  Mon Jul 16 16:42:19 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 10:42:19 -0400
Subject: [Rd] formula(CO2)
In-Reply-To: <XFMail.070716154040.ted.harding@nessie.mcc.ac.uk>
References: <971536df0707160716i7084039cp48560beb367fa141@mail.gmail.com>
	<XFMail.070716154040.ted.harding@nessie.mcc.ac.uk>
Message-ID: <971536df0707160742n1507968dwbaa1ef315c0f57e@mail.gmail.com>

Note that the formula uptake ~. will do the same thing so its not clear
how useful this facility really is.

On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> On 16-Jul-07 14:16:10, Gabor Grothendieck wrote:
> > Following up on your comments it seems formula.data.frame just creates
> > a formula whose lhs is the first column name and whose rhs is made up
> > of the remaining column names.  It ignores the "formula" attribute.
> >
> > In fact, CO2 does have a formula attribute but its not extracted by
> > formula.data.frame:
> >
> >> CO2 at formula
> > uptake ~ conc | Plant
> >> formula(CO2)
> > Plant ~ Type + Treatment + conc + uptake
>
> Indeed! And, following up yet again on my own follow-up comment:
>
> library(combinat)
>
> for(j in (1:4)){
>  for(i in combn((1:4),j,simplify=FALSE)){
>    print(formula(CO2[,c(5,i)]))
>  }
> }
> uptake ~ Plant
> uptake ~ Type
> uptake ~ Treatment
> uptake ~ conc
> uptake ~ Plant + Type
> uptake ~ Plant + Treatment
> uptake ~ Plant + conc
> uptake ~ Type + Treatment
> uptake ~ Type + conc
> uptake ~ Treatment + conc
> uptake ~ Plant + Type + Treatment
> uptake ~ Plant + Type + conc
> uptake ~ Plant + Treatment + conc
> uptake ~ Type + Treatment + conc
> uptake ~ Plant + Type + Treatment + conc
>
> opening the door to automated fitting of all possible models
> (without interactions)!
>
> Now if only I could find out how to do the interactions as well,
> I would never need to think again!
>
> best wishes,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 16-Jul-07                                       Time: 15:40:36
> ------------------------------ XFMail ------------------------------
>


From pgilbert at bank-banque-canada.ca  Mon Jul 16 16:57:53 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 16 Jul 2007 10:57:53 -0400
Subject: [Rd] S4 coerce
Message-ID: <469B8771.5060601@bank-banque-canada.ca>

(I am not sure if this is a bug or a request for a more understandable 
warning, or possible something obvious I should be posting on r-help.)

I am trying to coerce an new class object to be a DBIConnection and it 
does not work the way I think it should:

R version 2.5.1 (2007-06-27) ...
 > require("RMySQL") # or require("RSQLite")
Loading required package: RMySQL
Loading required package: DBI
[1] TRUE
 > m <- dbDriver("MySQL")  # or  m <- dbDriver("SQLite")
 > con <- dbConnect(m, dbname="test")
 > dbGetQuery(con, "create table zzz (
+    vintage     VARCHAR(20) NOT NULL,
+    alias       VARCHAR(20) default NULL,
+    Documentation     TEXT,
+    PRIMARY KEY (vintage)
+    );")
NULL
 > dbListTables(con)
  [1] "zzz"
 > setClass("TSconnection", representation(con="DBIConnection",
+    vintage = "logical",
+    panel   = "logical")
+    )
[1] "TSconnection"
 > setAs("TSconnection", "DBIConnection", def = function(from) from at con)
 > setIs("TSconnection", "DBIConnection", coerce = function(x) x at con)
Warning messages:
1: there is no automatic definition for as(object, "DBIConnection") <- 
value when object has class "TSconnection" and no 'replace' argument was 
supplied; replacement will be an error in: makeExtends(class1, class2, 
coerce, test, replace, by, classDef1 = classDef,
2: methods currently exist for coercing from "TSconnection" to 
"DBIConnection"; they will be replaced. in: 
..removePreviousCoerce(class1, class2, where, prevIs)

# (warning may be important, but I don't understand it)

 > setAs("TSconnection", "MySQLConnection", def = function(from) from at con)
 > setIs("TSconnection", "MySQLConnection", coerce = function(x) x at con)
Warning messages:
1: there is no automatic definition for as(object, "MySQLConnection") <- 
value when object has class "TSconnection" and no 'replace' argument was 
supplied; replacement will be an error in: makeExtends(class1, class2, 
coerce, test, replace, by, classDef1 = classDef,
2: methods currently exist for coercing from "TSconnection" to 
"MySQLConnection"; they will be replaced. in: 
..removePreviousCoerce(class1, class2, where, prevIs)

 > # or
 > # setAs("TSconnection", "SQLiteConnection", def = function(from) 
from at con)
 > # setIs("TSconnection", "SQLiteConnection", coerce = function(x) x at con)

 > Tcon <- new("TSconnection", con=dbConnect(m, dbname="test"), 
vintage=FALSE, panel=FALSE)
 > is(Tcon, "DBIConnection")
[1] TRUE
 > is(Tcon, "MySQLConnection")
[1] TRUE
 > # or is(Tcon, "SQLiteConnection")

 > # This fails but I think it should work
 > dbListTables(Tcon)
Error in slot(from, "Id") : no slot of name "Id" for this object of 
class "TSconnection"

#these all work
 > dbListTables(Tcon at con)
  [1] "zzz"
 > dbListTables(as(Tcon, "MySQLConnection") )
  [1] "zzz"
 > dbListTables(as(Tcon, "DBIConnection") )
  [1] "zzz"
 >

Is this a bug or am I doing something wrong?

Thanks,
Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From ted.harding at nessie.mcc.ac.uk  Mon Jul 16 17:13:18 2007
From: ted.harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 16 Jul 2007 16:13:18 +0100 (BST)
Subject: [Rd] formula(CO2)
In-Reply-To: <971536df0707160742n1507968dwbaa1ef315c0f57e@mail.gmail.com>
Message-ID: <XFMail.070716161318.ted.harding@nessie.mcc.ac.uk>

On 16-Jul-07 14:42:19, Gabor Grothendieck wrote:
> Note that the formula uptake ~. will do the same thing so its
> not clear how useful this facility really is.

Hmmm... Do you mean somthing like

  lm(uptake ~ . , data=CO2[,i])

where i is a subset of (1:4) as in my code below? In which case
I agree!

Ted.


> 
> On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
>> On 16-Jul-07 14:16:10, Gabor Grothendieck wrote:
>> > Following up on your comments it seems formula.data.frame just
>> > creates
>> > a formula whose lhs is the first column name and whose rhs is made
>> > up
>> > of the remaining column names.  It ignores the "formula" attribute.
>> >
>> > In fact, CO2 does have a formula attribute but its not extracted by
>> > formula.data.frame:
>> >
>> >> CO2 at formula
>> > uptake ~ conc | Plant
>> >> formula(CO2)
>> > Plant ~ Type + Treatment + conc + uptake
>>
>> Indeed! And, following up yet again on my own follow-up comment:
>>
>> library(combinat)
>>
>> for(j in (1:4)){
>>  for(i in combn((1:4),j,simplify=FALSE)){
>>    print(formula(CO2[,c(5,i)]))
>>  }
>> }
>> uptake ~ Plant
>> uptake ~ Type
>> uptake ~ Treatment
>> uptake ~ conc
>> uptake ~ Plant + Type
>> uptake ~ Plant + Treatment
>> uptake ~ Plant + conc
>> uptake ~ Type + Treatment
>> uptake ~ Type + conc
>> uptake ~ Treatment + conc
>> uptake ~ Plant + Type + Treatment
>> uptake ~ Plant + Type + conc
>> uptake ~ Plant + Treatment + conc
>> uptake ~ Type + Treatment + conc
>> uptake ~ Plant + Type + Treatment + conc
>>
>> opening the door to automated fitting of all possible models
>> (without interactions)!
>>
>> Now if only I could find out how to do the interactions as well,
>> I would never need to think again!
>>
>> best wishes,
>> Ted.
>>
>> --------------------------------------------------------------------
>> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
>> Fax-to-email: +44 (0)870 094 0861
>> Date: 16-Jul-07                                       Time: 15:40:36
>> ------------------------------ XFMail ------------------------------
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Jul-07                                       Time: 16:13:15
------------------------------ XFMail ------------------------------


From ggrothendieck at gmail.com  Mon Jul 16 17:18:37 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 11:18:37 -0400
Subject: [Rd] formula(CO2)
In-Reply-To: <XFMail.070716161318.ted.harding@nessie.mcc.ac.uk>
References: <971536df0707160742n1507968dwbaa1ef315c0f57e@mail.gmail.com>
	<XFMail.070716161318.ted.harding@nessie.mcc.ac.uk>
Message-ID: <971536df0707160818o4f243500h5c9d39ad7eec70c6@mail.gmail.com>

Yes. That's what I was referring to.

On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> On 16-Jul-07 14:42:19, Gabor Grothendieck wrote:
> > Note that the formula uptake ~. will do the same thing so its
> > not clear how useful this facility really is.
>
> Hmmm... Do you mean somthing like
>
>  lm(uptake ~ . , data=CO2[,i])
>
> where i is a subset of (1:4) as in my code below? In which case
> I agree!
>
> Ted.
>
>
> >
> > On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> >> On 16-Jul-07 14:16:10, Gabor Grothendieck wrote:
> >> > Following up on your comments it seems formula.data.frame just
> >> > creates
> >> > a formula whose lhs is the first column name and whose rhs is made
> >> > up
> >> > of the remaining column names.  It ignores the "formula" attribute.
> >> >
> >> > In fact, CO2 does have a formula attribute but its not extracted by
> >> > formula.data.frame:
> >> >
> >> >> CO2 at formula
> >> > uptake ~ conc | Plant
> >> >> formula(CO2)
> >> > Plant ~ Type + Treatment + conc + uptake
> >>
> >> Indeed! And, following up yet again on my own follow-up comment:
> >>
> >> library(combinat)
> >>
> >> for(j in (1:4)){
> >>  for(i in combn((1:4),j,simplify=FALSE)){
> >>    print(formula(CO2[,c(5,i)]))
> >>  }
> >> }
> >> uptake ~ Plant
> >> uptake ~ Type
> >> uptake ~ Treatment
> >> uptake ~ conc
> >> uptake ~ Plant + Type
> >> uptake ~ Plant + Treatment
> >> uptake ~ Plant + conc
> >> uptake ~ Type + Treatment
> >> uptake ~ Type + conc
> >> uptake ~ Treatment + conc
> >> uptake ~ Plant + Type + Treatment
> >> uptake ~ Plant + Type + conc
> >> uptake ~ Plant + Treatment + conc
> >> uptake ~ Type + Treatment + conc
> >> uptake ~ Plant + Type + Treatment + conc
> >>
> >> opening the door to automated fitting of all possible models
> >> (without interactions)!
> >>
> >> Now if only I could find out how to do the interactions as well,
> >> I would never need to think again!
> >>
> >> best wishes,
> >> Ted.
> >>
> >> --------------------------------------------------------------------
> >> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> >> Fax-to-email: +44 (0)870 094 0861
> >> Date: 16-Jul-07                                       Time: 15:40:36
> >> ------------------------------ XFMail ------------------------------
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 16-Jul-07                                       Time: 16:13:15
> ------------------------------ XFMail ------------------------------
>


From S.Ellison at lgc.co.uk  Mon Jul 16 17:52:13 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 16 Jul 2007 16:52:13 +0100
Subject: [Rd] formula(CO2)
Message-ID: <s69ba259.093@tedmail2.lgc.co.uk>

CO2 is apparently a groupedData object; the formula attribute is described by Pinheiro and Bates as a 'display formula'.

Perhaps reference to the nlme package's groupedData help would be informative?

 

>>> "Gabor Grothendieck" <ggrothendieck at gmail.com> 16/07/2007 16:18:37 >>>
Yes. That's what I was referring to.

On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> On 16-Jul-07 14:42:19, Gabor Grothendieck wrote:
> > Note that the formula uptake ~. will do the same thing so its
> > not clear how useful this facility really is.
>
> Hmmm... Do you mean somthing like
>
>  lm(uptake ~ . , data=CO2[,i])
>
> where i is a subset of (1:4) as in my code below? In which case
> I agree!
>
> Ted.
>
>
> >
> > On 7/16/07, Ted Harding <ted.harding at nessie.mcc.ac.uk> wrote:
> >> On 16-Jul-07 14:16:10, Gabor Grothendieck wrote:
> >> > Following up on your comments it seems formula.data.frame just
> >> > creates
> >> > a formula whose lhs is the first column name and whose rhs is made
> >> > up
> >> > of the remaining column names.  It ignores the "formula" attribute.
> >> >
> >> > In fact, CO2 does have a formula attribute but its not extracted by
> >> > formula.data.frame:
> >> >
> >> >> CO2 at formula
> >> > uptake ~ conc | Plant
> >> >> formula(CO2)
> >> > Plant ~ Type + Treatment + conc + uptake
> >>
> >> Indeed! And, following up yet again on my own follow-up comment:
> >>
> >> library(combinat)
> >>
> >> for(j in (1:4)){
> >>  for(i in combn((1:4),j,simplify=FALSE)){
> >>    print(formula(CO2[,c(5,i)]))
> >>  }
> >> }
> >> uptake ~ Plant
> >> uptake ~ Type
> >> uptake ~ Treatment
> >> uptake ~ conc
> >> uptake ~ Plant + Type
> >> uptake ~ Plant + Treatment
> >> uptake ~ Plant + conc
> >> uptake ~ Type + Treatment
> >> uptake ~ Type + conc
> >> uptake ~ Treatment + conc
> >> uptake ~ Plant + Type + Treatment
> >> uptake ~ Plant + Type + conc
> >> uptake ~ Plant + Treatment + conc
> >> uptake ~ Type + Treatment + conc
> >> uptake ~ Plant + Type + Treatment + conc
> >>
> >> opening the door to automated fitting of all possible models
> >> (without interactions)!
> >>
> >> Now if only I could find out how to do the interactions as well,
> >> I would never need to think again!
> >>
> >> best wishes,
> >> Ted.
> >>
> >> --------------------------------------------------------------------
> >> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> >> Fax-to-email: +44 (0)870 094 0861
> >> Date: 16-Jul-07                                       Time: 15:40:36
> >> ------------------------------ XFMail ------------------------------
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel 
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <ted.harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 16-Jul-07                                       Time: 16:13:15
> ------------------------------ XFMail ------------------------------
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From leonardz at sickkids.ca  Mon Jul 16 18:17:06 2007
From: leonardz at sickkids.ca (Len Zaifman)
Date: Mon, 16 Jul 2007 12:17:06 -0400 (EDT)
Subject: [Rd] Problem building R with Sun Studio Compiler
Message-ID: <13011.142.20.196.170.1184602626.squirrel@webmail.sickkids.ca>

I would like to Build R-2.5.1 on OpenSUSE 10.2 using the SunStudio 12
compilers(http://developers.sun.com/sunstudio/index.jsp)

R builds and passes make check fine without optimising. However, when I try to compile with optimisation turned on
(-fast) the build gets stuck in an infinite loop  at the following point:

Sun_Studio/sunstudio12/bin/cc -m64 -shared -Kpic   -m64 -fPIC  -o grDevices.so chull.o devNull.o devPicTeX.o devPS.o
devQuartz.o init.o
mkdir -p -- ../../../../library/grDevices/libs
make[5]: Leaving directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
make[4]: Leaving directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'

R is running at this point and will run for as long as I do not kill it. If I compile without    -fast the next line
in the make is:



make[3]: Entering directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/graphics'

and the entire package builds and make check verifies correctly. Any ideas on why this is happening?

The build works fine for gcc as well.

-- 
Len Zaifman
Systems Manager, Supercomputing Systems
Centre for Computational Biology
Hospital for Sick Children
Toronto, Ont. M5G 1X8
leonardz at sickkids.ca
(416)813-5513


From simon.urbanek at r-project.org  Mon Jul 16 18:35:08 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 16 Jul 2007 12:35:08 -0400
Subject: [Rd] How to disable R's C stack checking
In-Reply-To: <dfed1c180707060357y334a8397kd58e0e40b6b1ffed@mail.gmail.com>
References: <dfed1c180707060357y334a8397kd58e0e40b6b1ffed@mail.gmail.com>
Message-ID: <5324F61A-D316-4181-A348-44F1423825E3@r-project.org>


On Jul 6, 2007, at 6:57 AM, Ev Whin wrote:

> Hi all,
>
> I'm developing an application on Mac OS X Darwin which embeds R.
> However, the application always crashes due to the C stack checking.
> I know that R_CStackLimit can be set to -1 to disable the stack
> checking, but I don't know where to put the code "R_CStackLimit=-1".
>

After the call to Rf_initialize_R (and don't forget to define  
CSTACK_DEFNS and include Rinterface.h).

Cheers,
Simon


From ripley at stats.ox.ac.uk  Mon Jul 16 18:55:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Jul 2007 17:55:04 +0100 (BST)
Subject: [Rd] Problem building R with Sun Studio Compiler
In-Reply-To: <13011.142.20.196.170.1184602626.squirrel@webmail.sickkids.ca>
References: <13011.142.20.196.170.1184602626.squirrel@webmail.sickkids.ca>
Message-ID: <Pine.LNX.4.64.0707161746130.8695@gannet.stats.ox.ac.uk>

The R-admin manual did tell you not to do that!

   When using the Sun compilers do @emph{not} specify @option{-fast}, as
   this disables @acronym{IEEE} arithmetic and @command{make check} will
   fail.

That was for Solaris and SunStudio 11, but I presume these are basically 
the same compilers.  (--fast has been a no-no for as long as I have been 
using R on Solaris, ca 10 years.)

On Mon, 16 Jul 2007, Len Zaifman wrote:

> I would like to Build R-2.5.1 on OpenSUSE 10.2 using the SunStudio 12
> compilers(http://developers.sun.com/sunstudio/index.jsp)
>
> R builds and passes make check fine without optimising. However, when I try to compile with optimisation turned on
> (-fast) the build gets stuck in an infinite loop  at the following point:
>
> Sun_Studio/sunstudio12/bin/cc -m64 -shared -Kpic   -m64 -fPIC  -o grDevices.so chull.o devNull.o devPicTeX.o devPS.o
> devQuartz.o init.o
> mkdir -p -- ../../../../library/grDevices/libs
> make[5]: Leaving directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
> make[4]: Leaving directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
>
> R is running at this point and will run for as long as I do not kill it. 
> If I compile without -fast the next line in the make is:
>
> make[3]: Entering directory `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/graphics'
>
> and the entire package builds and make check verifies correctly. Any 
> ideas on why this is happening?
>
> The build works fine for gcc as well.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deepayan.sarkar at gmail.com  Mon Jul 16 23:46:31 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 16 Jul 2007 14:46:31 -0700
Subject: [Rd] substitute and expression
Message-ID: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>

Hi,

I'm trying to understand whether the use of substitute() is
appropriate/documented for plotmath annotation. The following two
calls give the same results:

> plot(1:10, main = expression(alpha == 1))
> do.call(plot, list(1:10, main = expression(alpha == 1)))

But not these two:

> plot(1:10, main = substitute(alpha == a, list(a = 2)))
> do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))))
Error in as.graphicsAnnot(main) : object "alpha" not found

(as a consequence, xyplot(..., main = substitute(alpha)) doesn't
currently work.)

On the other hand, this works:

> foo <- function(x) plot(1, main = x)
> foo(substitute(alpha))

I'm not sure how to interpret ?plotmath; it says

     If the 'text' argument to one of the text-drawing functions
     ('text', 'mtext', 'axis', 'legend') in R is an expression, the
     argument is interpreted as a mathematical expression...

and uses substitute() in its examples, but

> is.expression(substitute(alpha == a, list(a = 1)))
[1] FALSE

-Deepayan


From p.dalgaard at biostat.ku.dk  Tue Jul 17 00:24:05 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 17 Jul 2007 00:24:05 +0200
Subject: [Rd] substitute and expression
In-Reply-To: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>
References: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>
Message-ID: <469BF005.3060704@biostat.ku.dk>

Deepayan Sarkar wrote:
> Hi,
>
> I'm trying to understand whether the use of substitute() is
> appropriate/documented for plotmath annotation. The following two
> calls give the same results:
>
>   
>> plot(1:10, main = expression(alpha == 1))
>> do.call(plot, list(1:10, main = expression(alpha == 1)))
>>     
>
> But not these two:
>
>   
>> plot(1:10, main = substitute(alpha == a, list(a = 2)))
>> do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))))
>>     
> Error in as.graphicsAnnot(main) : object "alpha" not found
>
> (as a consequence, xyplot(..., main = substitute(alpha)) doesn't
> currently work.)
>
> On the other hand, this works:
>
>   
>> foo <- function(x) plot(1, main = x)
>> foo(substitute(alpha))
>>     
>
> I'm not sure how to interpret ?plotmath; it says
>
>      If the 'text' argument to one of the text-drawing functions
>      ('text', 'mtext', 'axis', 'legend') in R is an expression, the
>      argument is interpreted as a mathematical expression...
>
> and uses substitute() in its examples, but
>
>   
>> is.expression(substitute(alpha == a, list(a = 1)))
>>     
> [1] FALSE
>   
I think you need to take plotmath out of the equation and study the 
difference between objects of mode "call" and those of mode 
"expression". Consider this:

 > f <- function(...)match.call()
 > do.call(f, list(1:10, main = substitute(alpha == a, list(a = 2))))
function(...)match.call()
(1:10, main = alpha == 2)
 > do.call(list, list(1:10, main = substitute(alpha == a, list(a = 2))))
Error in do.call(list, list(1:10, main = substitute(alpha == a, list(a = 
2)))) :
        object "alpha" not found

The issue is that function ends up with an argument  alpha == 2 which it 
proceeds to evaluate (lazily), where a direct call sees 
substitute(.....). It is a general problem with the do.call mechanism 
that it effectively pre-evaluates the argument list, which can confuse 
functions that rely on accessing the original argument expression. Try, 
e.g., do.call(plot, list(airquality$Wind, airquality$Ozone)) and watch 
the axis labels.

Does it work if you use something like

 main = substitute(quote(alpha == a), list(a = 2))?


From ggrothendieck at gmail.com  Tue Jul 17 02:12:08 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Jul 2007 20:12:08 -0400
Subject: [Rd] substitute and expression
In-Reply-To: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>
References: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>
Message-ID: <971536df0707161712n7f390c30j7ec84aa07e771a02@mail.gmail.com>

On 7/16/07, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> Hi,
>
> I'm trying to understand whether the use of substitute() is
> appropriate/documented for plotmath annotation. The following two
> calls give the same results:
>
> > plot(1:10, main = expression(alpha == 1))
> > do.call(plot, list(1:10, main = expression(alpha == 1)))
>
> But not these two:
>
> > plot(1:10, main = substitute(alpha == a, list(a = 2)))
> > do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))))
> Error in as.graphicsAnnot(main) : object "alpha" not found
>
> (as a consequence, xyplot(..., main = substitute(alpha)) doesn't
> currently work.)

If your question is really about do.call then use the quote = TRUE argument.
Then both of the above work:

plot(1:10, main = substitute(alpha == a, list(a = 2)))
do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))),
quote = TRUE)

plot(1:10, main = expression(alpha == 1))
do.call(plot, list(1:10, main = expression(alpha == 1)), quote = TRUE)

Another possibility is just to make sure you are passing an expression so
that the first one would become:

plot(1:10, main = substitute(alpha == a, list(a = 2)))
do.call(plot, list(1:10, main = as.expression(substitute(alpha == a,
list(a = 2)))))


>
> On the other hand, this works:
>
> > foo <- function(x) plot(1, main = x)
> > foo(substitute(alpha))
>
> I'm not sure how to interpret ?plotmath; it says
>
>     If the 'text' argument to one of the text-drawing functions
>     ('text', 'mtext', 'axis', 'legend') in R is an expression, the
>     argument is interpreted as a mathematical expression...
>
> and uses substitute() in its examples, but
>
> > is.expression(substitute(alpha == a, list(a = 1)))
> [1] FALSE
>

I am not sure what examples you are referring to but if you read the
Value section in ?substitute it does say that substitute typically
returns call objects but may return a name object and in principle
can return others too so they need not be expressions.


From deepayan.sarkar at gmail.com  Tue Jul 17 02:14:48 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 16 Jul 2007 17:14:48 -0700
Subject: [Rd] substitute and expression
In-Reply-To: <469BF005.3060704@biostat.ku.dk>
References: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>
	<469BF005.3060704@biostat.ku.dk>
Message-ID: <eb555e660707161714n57b08e62t5ed53c6405762970@mail.gmail.com>

On 7/16/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Deepayan Sarkar wrote:
> > Hi,
> >
> > I'm trying to understand whether the use of substitute() is
> > appropriate/documented for plotmath annotation. The following two
> > calls give the same results:
> >
> >
> >> plot(1:10, main = expression(alpha == 1))
> >> do.call(plot, list(1:10, main = expression(alpha == 1)))
> >>
> >
> > But not these two:
> >
> >
> >> plot(1:10, main = substitute(alpha == a, list(a = 2)))
> >> do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))))
> >>
> > Error in as.graphicsAnnot(main) : object "alpha" not found
> >
> > (as a consequence, xyplot(..., main = substitute(alpha)) doesn't
> > currently work.)
> >
> > On the other hand, this works:
> >
> >
> >> foo <- function(x) plot(1, main = x)
> >> foo(substitute(alpha))
> >>
> >
> > I'm not sure how to interpret ?plotmath; it says
> >
> >      If the 'text' argument to one of the text-drawing functions
> >      ('text', 'mtext', 'axis', 'legend') in R is an expression, the
> >      argument is interpreted as a mathematical expression...
> >
> > and uses substitute() in its examples, but
> >
> >
> >> is.expression(substitute(alpha == a, list(a = 1)))
> >>
> > [1] FALSE
> >
> I think you need to take plotmath out of the equation and study the
> difference between objects of mode "call" and those of mode
> "expression". Consider this:
>
>  > f <- function(...)match.call()
>  > do.call(f, list(1:10, main = substitute(alpha == a, list(a = 2))))
> function(...)match.call()
> (1:10, main = alpha == 2)
>  > do.call(list, list(1:10, main = substitute(alpha == a, list(a = 2))))
> Error in do.call(list, list(1:10, main = substitute(alpha == a, list(a =
> 2)))) :
>         object "alpha" not found
>
> The issue is that function ends up with an argument  alpha == 2 which it
> proceeds to evaluate (lazily), where a direct call sees
> substitute(.....). It is a general problem with the do.call mechanism
> that it effectively pre-evaluates the argument list, which can confuse
> functions that rely on accessing the original argument expression. Try,
> e.g., do.call(plot, list(airquality$Wind, airquality$Ozone)) and watch
> the axis labels.

Right. Lazy evaluation was the piece I was missing.

> Does it work if you use something like
>
>  main = substitute(quote(alpha == a), list(a = 2))?

Not for xyplot, though I haven't figured out why. Turns out this also
doesn't work:

> plot(y ~ x, data = list(x = 1:10, y = 1:10), main = substitute(alpha))
Error in as.graphicsAnnot(main) : object "alpha" not found

I'll take this to mean that the fact that substitute() works sometimes
(for plotmath) is an undocumented side effect of the implementation
that should not be relied upon.

-Deepayan


From lucasjb at csse.unimelb.edu.au  Tue Jul 17 06:22:01 2007
From: lucasjb at csse.unimelb.edu.au (Lucas Barbuto)
Date: Tue, 17 Jul 2007 14:22:01 +1000
Subject: [Rd] Unable to build with working iconv support on Solaris9/x86
Message-ID: <D55025A1-6722-424E-ABD8-73FF758BBBCE@csse.unimelb.edu.au>

Hi all,

Have had a frustrating time trying to get R 2.5.1 running happily on  
Solaris9/x86, the problems seem to stem mainly from libiconv  
support.  After a couple of hours of experimenting, I came across the  
following combination, note that iconv (the program, but not the  
library) exists in the Solaris base system, I've manually installed  
the full GNU distribution in /usr/local/apps/libiconv-1.11 but not  
in /usr/local yet.

CFLAGS="-I/usr/local/apps/libiconv-1.11/include -I/usr/local/include"  
LDFLAGS="-L/usr/local/apps/libiconv-1.11/lib -R/usr/local/apps/ 
libiconv-1.11/lib -L/usr/local/lib -R/usr/local/lib" ./configure -- 
prefix=/usr/local/apps/r-2.5.1 --with-libiconv-prefix=/usr/local/apps/ 
libiconv-1.11

Note that the option --with-libiconv-prefix=/usr/local/apps/ 
libiconv-1.11 won't get me past the configure phase by itself (fails  
the iconv test), in fact as far as I can tell --with-libiconv-prefix  
has no effect at all but I've been leaving it in just in case.

Anyway, with the environment variables CFLAGS and LDFLAGS set as  
above, the process gets through configure and make successfully, but  
fails 'make check' trying to do a conversion to "latin1"

 > ## x is intended to be in latin1
 > x <- "fa\xE7ile"
 > Encoding(x)
[1] "unknown"
 > Encoding(x) <- "latin1"
 > x
[1]Error: unsupported conversion
Execution halted

ldd -s bin/exec/R confirms that R gets it's iconv from /usr/local/ 
apps/libiconv-1.11/lib/libiconv.so.2 as expected

ldd -s bin/exec/R
[snip]
    find object=libiconv.so.2; required by bin/exec/R
     search path=/usr/local/apps/libiconv-1.11/lib:/usr/local/lib:/ 
usr/local/apps/gcc-3.4.5/lib/gcc/i386-pc-solaris2.9/3.4.5  (RPATH  
from file bin/exec/R)
     trying path=/usr/local/apps/libiconv-1.11/lib/libiconv.so.2
         libiconv.so.2 =>         /usr/local/apps/libiconv-1.11/lib/ 
libiconv.so.2
[snip]

I don't know what else to try.  Anyone?

Regards,

--
Lucas Barbuto                          E: lucasjb at csse.unimelb.edu.au
System Administrator                                T: +613 8344 1270
Department of CSSE
The University of Melbourne           http://www.csse.unimelb.edu.au/


From sfalcon at fhcrc.org  Tue Jul 17 07:06:44 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 16 Jul 2007 22:06:44 -0700
Subject: [Rd] S4 coerce
In-Reply-To: <469B8771.5060601@bank-banque-canada.ca> (Paul Gilbert's message
	of "Mon, 16 Jul 2007 10:57:53 -0400")
References: <469B8771.5060601@bank-banque-canada.ca>
Message-ID: <m2fy3nipp7.fsf@ziti.fhcrc.org>

Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:

> (I am not sure if this is a bug or a request for a more understandable 
> warning, or possible something obvious I should be posting on r-help.)
>
> I am trying to coerce an new class object to be a DBIConnection and it 
> does not work the way I think it should:
>
> R version 2.5.1 (2007-06-27) ...
>  > require("RMySQL") # or require("RSQLite")
> Loading required package: RMySQL
> Loading required package: DBI
> [1] TRUE
>  > m <- dbDriver("MySQL")  # or  m <- dbDriver("SQLite")
>  > con <- dbConnect(m, dbname="test")
>  > dbGetQuery(con, "create table zzz (
> +    vintage     VARCHAR(20) NOT NULL,
> +    alias       VARCHAR(20) default NULL,
> +    Documentation     TEXT,
> +    PRIMARY KEY (vintage)
> +    );")
> NULL
>  > dbListTables(con)
>   [1] "zzz"
>  > setClass("TSconnection", representation(con="DBIConnection",
> +    vintage = "logical",
> +    panel   = "logical")
> +    )
> [1] "TSconnection"
>  > setAs("TSconnection", "DBIConnection", def = function(from) from at con)

I think things work as you expect up until this pint.

>  > setIs("TSconnection", "DBIConnection", coerce = function(x)
>  > x at con)

I'm confused about what you want to do here.  If you want TSconnection
to be a DBIConnection, why wouldn't you use inheritance?

   setClass("TSconnection", contains="DBIConnection", ...)

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From ripley at stats.ox.ac.uk  Tue Jul 17 08:04:17 2007
From: ripley at stats.ox.ac.uk (Professor Brian Ripley)
Date: Tue, 17 Jul 2007 07:04:17 +0100
Subject: [Rd] Unable to build with working iconv support on Solaris9/x86
In-Reply-To: <D55025A1-6722-424E-ABD8-73FF758BBBCE@csse.unimelb.edu.au>
References: <D55025A1-6722-424E-ABD8-73FF758BBBCE@csse.unimelb.edu.au>
Message-ID: <469C5BE1.9070106@stats.ox.ac.uk>

Note that as the R-admin says, you need to use a better iconv than
that supplied with most commercial Unices, including Solaris.

You can use GNU libiconv in either of two ways:

- as a preload plugin
- by installing it with the libiconv prefix, and ensuring its iconv.h
is first in your path.

If you have two libraries with the same entry point (iconv here)
which one gets resolved to is pretty arcane.  Hence the need for
a prefix.

I have used both routes on Solaris 10 and 8: the CSW libs use the
second, for example.  The preload route is pretty and can be applied
to an existing executable.

Lucas Barbuto wrote:
> Hi all,
> 
> Have had a frustrating time trying to get R 2.5.1 running happily on  
> Solaris9/x86, the problems seem to stem mainly from libiconv  
> support.  After a couple of hours of experimenting, I came across the  
> following combination, note that iconv (the program, but not the  
> library) exists in the Solaris base system, I've manually installed  
> the full GNU distribution in /usr/local/apps/libiconv-1.11 but not  
> in /usr/local yet.
> 
> CFLAGS="-I/usr/local/apps/libiconv-1.11/include -I/usr/local/include"  
> LDFLAGS="-L/usr/local/apps/libiconv-1.11/lib -R/usr/local/apps/ 
> libiconv-1.11/lib -L/usr/local/lib -R/usr/local/lib" ./configure -- 
> prefix=/usr/local/apps/r-2.5.1 --with-libiconv-prefix=/usr/local/apps/ 
> libiconv-1.11
> 
> Note that the option --with-libiconv-prefix=/usr/local/apps/ 
> libiconv-1.11 won't get me past the configure phase by itself (fails  
> the iconv test), in fact as far as I can tell --with-libiconv-prefix  
> has no effect at all but I've been leaving it in just in case.

Right, and you fail the same test below.

> Anyway, with the environment variables CFLAGS and LDFLAGS set as  
> above, the process gets through configure and make successfully, but  
> fails 'make check' trying to do a conversion to "latin1"
> 
>  > ## x is intended to be in latin1
>  > x <- "fa\xE7ile"
>  > Encoding(x)
> [1] "unknown"
>  > Encoding(x) <- "latin1"
>  > x
> [1]Error: unsupported conversion
> Execution halted
> 
> ldd -s bin/exec/R confirms that R gets it's iconv from /usr/local/ 
> apps/libiconv-1.11/lib/libiconv.so.2 as expected

All that confirms is that you are linking to that DSO.

> ldd -s bin/exec/R
> [snip]
>     find object=libiconv.so.2; required by bin/exec/R
>      search path=/usr/local/apps/libiconv-1.11/lib:/usr/local/lib:/ 
> usr/local/apps/gcc-3.4.5/lib/gcc/i386-pc-solaris2.9/3.4.5  (RPATH  
> from file bin/exec/R)
>      trying path=/usr/local/apps/libiconv-1.11/lib/libiconv.so.2
>          libiconv.so.2 =>         /usr/local/apps/libiconv-1.11/lib/ 
> libiconv.so.2
> [snip]
> 
> I don't know what else to try.  Anyone?
> 
> Regards,
> 
> --
> Lucas Barbuto                          E: lucasjb at csse.unimelb.edu.au
> System Administrator                                T: +613 8344 1270
> Department of CSSE
> The University of Melbourne           http://www.csse.unimelb.edu.au/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwilhelm at lanl.gov  Tue Jul 17 00:06:06 2007
From: dwilhelm at lanl.gov (Daniel Wilhelm)
Date: Mon, 16 Jul 2007 16:06:06 -0600
Subject: [Rd] Field initialization order bug?
Message-ID: <p0624081dc2c19b42aa26@[128.165.72.98]>

I believe that I may have found a bug in R. The top code sample gives 
an error as shown. However, by simply switching which field is 
initialized first as in the bottom code sample, it works as expected.


This gives an error:


a <- NULL
a[["field1"]] <- 1
a[["field2"]] <- matrix(c(2,1), 1)

Error in a[["field2"]] <- matrix(c(2, 1), 1) :
	more elements supplied than there are to replace



Yet, this works as expected:

a <- NULL
a[["field2"]] <- matrix(c(2,1), 1)
a[["field1"]] <- 1



Daniel Wilhelm


From rizwanyounis at hotmail.com  Mon Jul 16 23:27:28 2007
From: rizwanyounis at hotmail.com (Rizwan Younis)
Date: Mon, 16 Jul 2007 17:27:28 -0400
Subject: [Rd] Error while fitting Partial Proportional Odds model using vglm
Message-ID: <BAY116-DAV96CD70E1FFE7D7B8EAB9DC1F80@phx.gbl>

Dear R developers:

I am trying to fit a PPO model using vglm from the library VGAM, and get an
error while executing the code. Here is the data, code, and error:

Data: first row is the column names. a = age, and 1,2,3, 4 and 5 are
condition grades.

  a  1 2 3  4 5
  1  1 0 0  0 0
  2 84 2 7 10 2
  3 16 0 6  6 2
  4 13 0 3  4 0
  5  0 0 0  1 0

Library(VGAM)

rc13<-read.table("icg_rcPivot_group2.txt",header=F)
names(rc13)<-c("a","1","2","3","4","5")

ppo<-vglm(cbind(rc13[,2],rc13[,3],rc13[,4],rc13[,5],rc13[,6])~a,family =
cumulative(link = logit, parallel = F , reverse = F),na.action=na.pass,
data=rc13)
summary(ppo)

I get the following error:

Error in "[<-"(`*tmp*`, , index, value = c(1.13512932539841,
0.533057528200189,  : 
	number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: NaNs produced in: log(x)
2: fitted values close to 0 or 1 in: tfun(mu = mu, y = y, w = w, res =
FALSE, eta = eta, extra)
3: 19 elements replaced by 1.819e-12 in: checkwz(wz, M = M, trace = trace,
wzeps = control$wzepsilon)


Ironically, it works ok with Proportional Odds (change parallel = T above),
but fails with PPO (parallel = F). 

I will appreciate any help to fix this problem.
Thanks

Rizwan Younis
Grad Student
University of Waterloo
Waterloo, ON Canada


From lucasjb at csse.unimelb.edu.au  Tue Jul 17 09:28:49 2007
From: lucasjb at csse.unimelb.edu.au (Lucas Barbuto)
Date: Tue, 17 Jul 2007 17:28:49 +1000
Subject: [Rd] Unable to build with working iconv support on Solaris9/x86
In-Reply-To: <469C5BE1.9070106@stats.ox.ac.uk>
References: <D55025A1-6722-424E-ABD8-73FF758BBBCE@csse.unimelb.edu.au>
	<469C5BE1.9070106@stats.ox.ac.uk>
Message-ID: <79FCB777-9D82-4966-B6BF-33A46C88C86F@csse.unimelb.edu.au>

Hi Brian,

Thanks for the advice, but I'm still confused!

On 17/07/2007, at 4:04 PM, Professor Brian Ripley wrote:
> Note that as the R-admin says, you need to use a better iconv than
> that supplied with most commercial Unices, including Solaris.

Yes, I read that and installed libiconv-1.11 locally before trying to  
build R.

> - as a preload plugin
> - by installing it with the libiconv prefix, and ensuring its iconv.h
> is first in your path.

I've read a number of articles explaining why LD_PRELOAD is  
considered harmful and should be avoided.  I'm trying to be a good  
systems administrator and do things the "right" way.  As I understand  
it RPATH (-R/somelocation argument to the linker) should take care of  
this problem (but clearly it doesn't in this case).

When you say libiconv prefix, you're referring to '--with-libiconv- 
prefix=/somelocation' correct?  And what do you mean by "ensuring  
iconv.h is first in your path"?  If I provide CFLAGS="-I/ 
somelocation" that should be searched first for headers before the  
default system locations as I understand?  But surely once the binary  
is built, the headers order doesn't matter?

> If you have two libraries with the same entry point (iconv here)
> which one gets resolved to is pretty arcane.  Hence the need for
> a prefix.

Doesn't the output of 'ldd -s bin/exec/R' show the order in which  
locations are searched for DSOs and confirm that /usr/local/apps/ 
libiconv-1.11/lib/libiconv.so.2 is found first and used?

You are correct though, 'LD_PRELOAD=/usr/local/apps/libiconv-1.11/lib/ 
libiconv.so make check' passes all tests up to d-p-q-r, whereas it  
would usually fail on the first.

Regards,

--
Lucas Barbuto                          E: lucasjb at csse.unimelb.edu.au
System Administrator                                T: +613 8344 1270
Department of CSSE
The University of Melbourne           http://www.csse.unimelb.edu.au/


From ripley at stats.ox.ac.uk  Tue Jul 17 09:30:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Jul 2007 08:30:18 +0100 (BST)
Subject: [Rd] Error while fitting Partial Proportional Odds model using
 vglm
In-Reply-To: <BAY116-DAV96CD70E1FFE7D7B8EAB9DC1F80@phx.gbl>
References: <BAY116-DAV96CD70E1FFE7D7B8EAB9DC1F80@phx.gbl>
Message-ID: <Pine.LNX.4.64.0707170825500.30535@auk.stats>

Instead of repeatedly posting this message to the R lists, please contact 
the maintainer as the R posting guide asked you to do in the first 
instance.

E.g. you have already sent

https://stat.ethz.ch/pipermail/r-help/2007-July/136488.html
https://stat.ethz.ch/pipermail/r-help/2007-July/136510.html

On Mon, 16 Jul 2007, Rizwan Younis wrote:

> Dear R developers:
>
> I am trying to fit a PPO model using vglm from the library VGAM, and get an
> error while executing the code. Here is the data, code, and error:
>
> Data: first row is the column names. a = age, and 1,2,3, 4 and 5 are
> condition grades.
>
>  a  1 2 3  4 5
>  1  1 0 0  0 0
>  2 84 2 7 10 2
>  3 16 0 6  6 2
>  4 13 0 3  4 0
>  5  0 0 0  1 0
>
> Library(VGAM)
>
> rc13<-read.table("icg_rcPivot_group2.txt",header=F)
> names(rc13)<-c("a","1","2","3","4","5")
>
> ppo<-vglm(cbind(rc13[,2],rc13[,3],rc13[,4],rc13[,5],rc13[,6])~a,family =
> cumulative(link = logit, parallel = F , reverse = F),na.action=na.pass,
> data=rc13)
> summary(ppo)
>
> I get the following error:
>
> Error in "[<-"(`*tmp*`, , index, value = c(1.13512932539841,
> 0.533057528200189,  :
> 	number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: NaNs produced in: log(x)
> 2: fitted values close to 0 or 1 in: tfun(mu = mu, y = y, w = w, res =
> FALSE, eta = eta, extra)
> 3: 19 elements replaced by 1.819e-12 in: checkwz(wz, M = M, trace = trace,
> wzeps = control$wzepsilon)
>
>
> Ironically, it works ok with Proportional Odds (change parallel = T above),
> but fails with PPO (parallel = F).
>
> I will appreciate any help to fix this problem.
> Thanks
>
> Rizwan Younis
> Grad Student
> University of Waterloo
> Waterloo, ON Canada
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gavin.simpson at ucl.ac.uk  Tue Jul 17 09:34:14 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 17 Jul 2007 08:34:14 +0100
Subject: [Rd] Error while fitting Partial Proportional Odds model
	using	vglm
In-Reply-To: <000101c7c7f0$1c7d7150$800101df@aarizwan>
References: <000101c7c7f0$1c7d7150$800101df@aarizwan>
Message-ID: <1184657654.3010.9.camel@dhcppc2.my.nat.localnet>

On Mon, 2007-07-16 at 17:27 -0400, Rizwan Younis wrote:
> Dear R developers:

This is *not* the correct list for help with R or contributed packages
on CRAN, and please do not send your messages repeatedly to any of the
lists - this is at least the 3rd time I've received this request for
help.

If you'd read the posting guide, it would have told you that you should
email the package maintainer (in this case Thomas Yee) for help with a
contributed package. If you must email the R-help list, do so only once.
If you don't get a reply, take the hint that perhaps no-one has an
answer - repeatedly bugging them isn't going to help!

By the looks of things, there is either a problem within VGAM itself
that only Thomas will be able to fix, or you are providing an
argument/data that VGAM was not expecting - there appear to be some
fitting problems also. Check that the data you are providing are what
VGAM expects, and if the problem still persists, email Thomas with a
reproducible example.

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch at stats.uwo.ca  Tue Jul 17 12:15:29 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 17 Jul 2007 06:15:29 -0400
Subject: [Rd] Field initialization order bug?
In-Reply-To: <p0624081dc2c19b42aa26@[128.165.72.98]>
References: <p0624081dc2c19b42aa26@[128.165.72.98]>
Message-ID: <469C96C1.30607@stats.uwo.ca>

Daniel Wilhelm wrote:
> I believe that I may have found a bug in R. The top code sample gives 
> an error as shown. However, by simply switching which field is 
> initialized first as in the bottom code sample, it works as expected.
>
>
> This gives an error:
>
>
> a <- NULL
> a[["field1"]] <- 1
> a[["field2"]] <- matrix(c(2,1), 1)
>
> Error in a[["field2"]] <- matrix(c(2, 1), 1) :
> 	more elements supplied than there are to replace
>
>
>
> Yet, this works as expected:
>
> a <- NULL
> a[["field2"]] <- matrix(c(2,1), 1)
> a[["field1"]] <- 1
>   
I'm surprised any of these work.  I didn't expect to be able to index 
NULL, but the clue is there in the man page for "[[":  "the 
left-hand-side is coerced as needed to accept the values."

What's happening is that in the first case, a becomes a numeric vector, 
and you can't assign a matrix to an element of a numeric vector.  It 
won't fit.

In the second case, a  becomes a list, and the assignments both succeed.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Tue Jul 17 12:29:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Jul 2007 11:29:58 +0100 (BST)
Subject: [Rd] Field initialization order bug?
In-Reply-To: <p0624081dc2c19b42aa26@[128.165.72.98]>
References: <p0624081dc2c19b42aa26@[128.165.72.98]>
Message-ID: <Pine.LNX.4.64.0707170821220.30535@auk.stats>

On Mon, 16 Jul 2007, Daniel Wilhelm wrote:

> I believe that I may have found a bug in R. The top code sample gives

You have 'merely' found a bug in your understanding.  What type did you 
expect 'a' to be?  If you expected a list, that is not what happens in the 
first example, and you need

a <- list()

or, better,

a <- vector("list", 2)

> an error as shown. However, by simply switching which field is
> initialized first as in the bottom code sample, it works as expected.
>
>
> This gives an error:
>
>
> a <- NULL
> a[["field1"]] <- 1

Now a is numeric

> a[["field2"]] <- matrix(c(2,1), 1)
>
> Error in a[["field2"]] <- matrix(c(2, 1), 1) :
> 	more elements supplied than there are to replace
>
>
>
> Yet, this works as expected:
>
> a <- NULL
> a[["field2"]] <- matrix(c(2,1), 1)

Now a is a list

> a[["field1"]] <- 1
>
>
>
> Daniel Wilhelm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Jul 17 12:32:15 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Jul 2007 11:32:15 +0100 (BST)
Subject: [Rd] Problem building R with Sun Studio Compiler
In-Reply-To: <Pine.LNX.4.64.0707161746130.8695@gannet.stats.ox.ac.uk>
References: <13011.142.20.196.170.1184602626.squirrel@webmail.sickkids.ca>
	<Pine.LNX.4.64.0707161746130.8695@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0707171021530.27991@auk.stats>

On Mon, 16 Jul 2007, Prof Brian Ripley wrote:

> The R-admin manual did tell you not to do that!
>
>  When using the Sun compilers do @emph{not} specify @option{-fast}, as
>  this disables @acronym{IEEE} arithmetic and @command{make check} will
>  fail.
>
> That was for Solaris and SunStudio 11, but I presume these are basically the 
> same compilers.  (--fast has been a no-no for as long as I have been using R 
> on Solaris, ca 10 years.)

There is another problem with -fast on x86 that is probably the cause of 
your problem.  It implies -nofstore, and we needed to force storage on 
some Fortran routines under g77/gfortran to avoid an infinite loop.

However, even if you set SAFE_FFLAGS, the likely problems with IEC60559 
compliance remain.

>
> On Mon, 16 Jul 2007, Len Zaifman wrote:
>
>> I would like to Build R-2.5.1 on OpenSUSE 10.2 using the SunStudio 12
>> compilers(http://developers.sun.com/sunstudio/index.jsp)
>> 
>> R builds and passes make check fine without optimising. However, when I try 
>> to compile with optimisation turned on
>> (-fast) the build gets stuck in an infinite loop  at the following point:
>> 
>> Sun_Studio/sunstudio12/bin/cc -m64 -shared -Kpic   -m64 -fPIC  -o 
>> grDevices.so chull.o devNull.o devPicTeX.o devPS.o
>> devQuartz.o init.o
>> mkdir -p -- ../../../../library/grDevices/libs
>> make[5]: Leaving directory 
>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
>> make[4]: Leaving directory 
>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
>> 
>> R is running at this point and will run for as long as I do not kill it. If 
>> I compile without -fast the next line in the make is:
>> 
>> make[3]: Entering directory 
>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/graphics'
>> 
>> and the entire package builds and make check verifies correctly. Any ideas 
>> on why this is happening?
>> 
>> The build works fine for gcc as well.
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Tue Jul 17 14:34:02 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 17 Jul 2007 14:34:02 +0200
Subject: [Rd] Field initialization order bug?
In-Reply-To: <Pine.LNX.4.64.0707170821220.30535@auk.stats>
References: <p0624081dc2c19b42aa26@[128.165.72.98]>
	<Pine.LNX.4.64.0707170821220.30535@auk.stats>
Message-ID: <469CB73A.7030006@biostat.ku.dk>

Prof Brian Ripley wrote:
> On Mon, 16 Jul 2007, Daniel Wilhelm wrote:
>
>   
>> I believe that I may have found a bug in R. The top code sample gives
>>     
>
> You have 'merely' found a bug in your understanding.  What type did you 
> expect 'a' to be?  If you expected a list, that is not what happens in the 
> first example, and you need
>
> a <- list()
>
> or, better,
>
> a <- vector("list", 2)
>
>   
To be precise, you need

a <- vector("list", 2) ; names(a) <- c("field1", "field2")

or you end up with a 4-element list.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pgilbert at bank-banque-canada.ca  Tue Jul 17 16:22:48 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 17 Jul 2007 10:22:48 -0400
Subject: [Rd] S4 coerce
In-Reply-To: <m2fy3nipp7.fsf@ziti.fhcrc.org>
References: <469B8771.5060601@bank-banque-canada.ca>
	<m2fy3nipp7.fsf@ziti.fhcrc.org>
Message-ID: <469CD0B8.5030301@bank-banque-canada.ca>



Seth Falcon wrote:

>Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
>
>  
>
>>(I am not sure if this is a bug or a request for a more understandable 
>>warning, or possible something obvious I should be posting on r-help.)
>>
>>I am trying to coerce an new class object to be a DBIConnection and it 
>>does not work the way I think it should:
>>
>>R version 2.5.1 (2007-06-27) ...
>> > require("RMySQL") # or require("RSQLite")
>>Loading required package: RMySQL
>>Loading required package: DBI
>>[1] TRUE
>> > m <- dbDriver("MySQL")  # or  m <- dbDriver("SQLite")
>> > con <- dbConnect(m, dbname="test")
>> > dbGetQuery(con, "create table zzz (
>>+    vintage     VARCHAR(20) NOT NULL,
>>+    alias       VARCHAR(20) default NULL,
>>+    Documentation     TEXT,
>>+    PRIMARY KEY (vintage)
>>+    );")
>>NULL
>> > dbListTables(con)
>>  [1] "zzz"
>> > setClass("TSconnection", representation(con="DBIConnection",
>>+    vintage = "logical",
>>+    panel   = "logical")
>>+    )
>>[1] "TSconnection"
>> > setAs("TSconnection", "DBIConnection", def = function(from) from at con)
>>    
>>
>
>I think things work as you expect up until this pint.
>  
>
Yes.

>  
>
>> > setIs("TSconnection", "DBIConnection", coerce = function(x)
>> > x at con)
>>    
>>
>
>I'm confused about what you want to do here.  If you want TSconnection
>to be a DBIConnection, why wouldn't you use inheritance?
>
>   setClass("TSconnection", contains="DBIConnection", ...)
>  
>
Perhaps my logic is confused, it wouldn't be the first time,  but I am 
thinking of this as going the "other direction" from inheritance.   A 
MySQLConnection or SQLiteConnection inherits from DBIConnection. To 
actually use a DBIConnection or my TSconnection it will be necessary to 
have one of these, so I would need something like

setClass("TSconnection", contains="MySQLConnection", ...)

to make this work. (Actually, I have not been able to make it work, but 
that may just be the novice level of my experimenting.)   I am hoping I 
can define the TSconnection using only DBIConnection classes and have it 
automatically work when one of the database driver packages is added. 
Otherwise  I have to define the TSconnection for each of the driver 
packages, which is not as clean.

Paul

>+ seth
>
>  
>
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From kw.statr at gmail.com  Tue Jul 17 17:14:47 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Tue, 17 Jul 2007 10:14:47 -0500
Subject: [Rd] formula(CO2)
In-Reply-To: <971536df0707160628g37e301e1wf81eaee0b7feb841@mail.gmail.com>
References: <971536df0707160628g37e301e1wf81eaee0b7feb841@mail.gmail.com>
Message-ID: <c968588d0707170814k1351a429qa23b858b7e4abd2f@mail.gmail.com>

About a month ago I had a similar issue related to 'formula':
http://tolstoy.newcastle.edu.au/R/e2/devel/07/05/3329.html

In summary:

In S-Plus, the help for formula.data.frame says:
This is a method for the function formula() for objects inheriting
from class data.frame. If object is a model frame, the formula for the
model frame is returned, otherwise a formula is deduced from the names
of object. The first name is taken to be the response, and all the
remaining names are pasted together additively.

In R, the help for formula.data.frame is aliased to the help for
formula, but does not clearly document the usage with data.frames.

Kevin

On 7/16/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> The formula attribute of the builtin CO2 dataset seems a bit strange:
>
> > formula(CO2)
> Plant ~ Type + Treatment + conc + uptake
>
> What is one supposed to do with that?  Certainly its not suitable for
> input to lm and none of the examples in ?CO2 use the above.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From P.Dalgaard at biostat.ku.dk  Tue Jul 17 17:39:50 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 17 Jul 2007 17:39:50 +0200
Subject: [Rd] substitute and expression
In-Reply-To: <eb555e660707161714n57b08e62t5ed53c6405762970@mail.gmail.com>
References: <eb555e660707161446s9e18352h7fbe19d76948c1a7@mail.gmail.com>	<469BF005.3060704@biostat.ku.dk>
	<eb555e660707161714n57b08e62t5ed53c6405762970@mail.gmail.com>
Message-ID: <469CE2C6.6010500@biostat.ku.dk>

Deepayan Sarkar wrote:
> On 7/16/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>   
>> Deepayan Sarkar wrote:
>>     
>>> Hi,
>>>
>>> I'm trying to understand whether the use of substitute() is
>>> appropriate/documented for plotmath annotation. The following two
>>> calls give the same results:
>>>
>>>
>>>       
>>>> plot(1:10, main = expression(alpha == 1))
>>>> do.call(plot, list(1:10, main = expression(alpha == 1)))
>>>>
>>>>         
>>> But not these two:
>>>
>>>
>>>       
>>>> plot(1:10, main = substitute(alpha == a, list(a = 2)))
>>>> do.call(plot, list(1:10, main = substitute(alpha == a, list(a = 2))))
>>>>
>>>>         
>>> Error in as.graphicsAnnot(main) : object "alpha" not found
>>>
>>> (as a consequence, xyplot(..., main = substitute(alpha)) doesn't
>>> currently work.)
>>>
>>> On the other hand, this works:
>>>
>>>
>>>       
>>>> foo <- function(x) plot(1, main = x)
>>>> foo(substitute(alpha))
>>>>
>>>>         
>>> I'm not sure how to interpret ?plotmath; it says
>>>
>>>      If the 'text' argument to one of the text-drawing functions
>>>      ('text', 'mtext', 'axis', 'legend') in R is an expression, the
>>>      argument is interpreted as a mathematical expression...
>>>
>>> and uses substitute() in its examples, but
>>>
>>>
>>>       
>>>> is.expression(substitute(alpha == a, list(a = 1)))
>>>>
>>>>         
>>> [1] FALSE
>>>
>>>       
>> I think you need to take plotmath out of the equation and study the
>> difference between objects of mode "call" and those of mode
>> "expression". Consider this:
>>
>>  > f <- function(...)match.call()
>>  > do.call(f, list(1:10, main = substitute(alpha == a, list(a = 2))))
>> function(...)match.call()
>> (1:10, main = alpha == 2)
>>  > do.call(list, list(1:10, main = substitute(alpha == a, list(a = 2))))
>> Error in do.call(list, list(1:10, main = substitute(alpha == a, list(a =
>> 2)))) :
>>         object "alpha" not found
>>
>> The issue is that function ends up with an argument  alpha == 2 which it
>> proceeds to evaluate (lazily), where a direct call sees
>> substitute(.....). It is a general problem with the do.call mechanism
>> that it effectively pre-evaluates the argument list, which can confuse
>> functions that rely on accessing the original argument expression. Try,
>> e.g., do.call(plot, list(airquality$Wind, airquality$Ozone)) and watch
>> the axis labels.
>>     
>
> Right. Lazy evaluation was the piece I was missing.
>
>   
>> Does it work if you use something like
>>
>>  main = substitute(quote(alpha == a), list(a = 2))?
>>     
>
> Not for xyplot, though I haven't figured out why. Turns out this also
> doesn't work:
>
>   
>> plot(y ~ x, data = list(x = 1:10, y = 1:10), main = substitute(alpha))
>>     
> Error in as.graphicsAnnot(main) : object "alpha" not found
>
> I'll take this to mean that the fact that substitute() works sometimes
> (for plotmath) is an undocumented side effect of the implementation
> that should not be relied upon.
>   
Probably the correct solution is to use expression objects. More or less
the entire reason for their existence is this sort of surprises.

plot(y ~ x, data = list(x = 1:10, y = 1:10), main =
as.expression(substitute(alpha==a, list(a=2))))

I'm not going to investigate why this is necessary in connection with
plot(), but the core issue is probably

> e <- quote(f(x)) ; e[[2]] <- quote(2+2)
> e
f(2 + 2)
> f <- quote(f(2+2))
> identical(e,f)
[1] TRUE

notice that since the two calls are identical, there is no way for e to
detect that it was called with x replaced by an object of mode "call".
Or put differently, objects of mode call tend to lose their
"personality" in connection with computing on the language. 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From bill at insightful.com  Tue Jul 17 18:58:10 2007
From: bill at insightful.com (bill at insightful.com)
Date: Tue, 17 Jul 2007 18:58:10 +0200 (CEST)
Subject: [Rd] write.dcf/read.dcf cycle converts missing entry to "NA"
	(PR#9796)
Message-ID: <20070717165810.276EB65989@slim.kubism.ku.dk>

Full_Name: Bill Dunlap
Version: 2.5.0
OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 6)
Submission from: (NULL) (24.17.60.30)


If you read a dcf file with read.dcf(file,fields=c("Field",...))
and the file does not contain the desired field "Field",
read.dcf puts a character NA for that entry in its output
matrix.  If you then call write.dcf, passing it the output
of read.dcf(), it will write the entry "Field: NA".  A subsequent
read.dcf() on write.dcf's output file will then have a "NA",
not a character NA, in the entry for "Field".  I think that
write.dcf() should not write lines in the output file where
the input matrix contains a character NA.

Here is a test function to demonstrate the problem.  It returns
TRUE when a write.dcf/read.dcf cycle does not change the data.

  test.write.dcf <- function () {
     origFile <- tempfile()
     copyFile <- tempfile()
     on.exit(unlink(c(origFile, copyFile)))
     writeLines(c("Package: testA", "Version: 0.1-1", "Depends:", "",
                  "Package: testB", "Version: 2.1"  , "Suggests: testA", "",
                  "Package: testC", "Version: 1.3.1", ""),
                origFile)
     orig <- read.dcf(origFile,
                      fields=c("Package","Version","Depends","Suggests"))
     write.dcf(orig, copyFile, width = 72)
     copy <- read.dcf(copyFile,
                      fields=c("Package","Version","Depends","Suggests"))
     value <- all.equal(orig, copy)
     if (!identical(value, TRUE)) {
        attr(value, "orig") <- orig
        attr(value, "copy") <- copy
     }
     value
  }
Currently we get
  > test.write.dcf()
  [1] "'is.NA' value mismatch: 0 in current 4 in target"
  attr(,"orig")
       Package Version Depends Suggests
  [1,] "testA" "0.1-1" ""      NA
  [2,] "testB" "2.1"   NA      "testA"
  [3,] "testC" "1.3.1" NA      NA
  attr(,"copy")
       Package Version Depends Suggests
  [1,] "testA" "0.1-1" ""      "NA"
  [2,] "testB" "2.1"   "NA"    "testA"
  [3,] "testC" "1.3.1" "NA"    "NA"
With the attached write.dcf() it returns TRUE.

The diff would be
19,22c19,24
<     eor <- character(nr * nc)
<     eor[seq.int(1, nr - 1) * nc] <- "\n"
<     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(t(x)),
<         style = "list", width = width, indent = indent), eor,
---
>     tx <- t(x)
>     not.na <- c(!is.na(tx))
>     eor <- character(sum(not.na))
>     eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
>     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
>         style = "list", width = width, indent = indent)[not.na], eor,

and the entire function would be

`write.dcf` <-
function (x, file = "", append = FALSE, indent = 0.1 * getOption("width"),
    width = 0.9 * getOption("width"))
{
    if (!is.data.frame(x))
        x <- data.frame(x)
    x <- as.matrix(x)
    mode(x) <- "character"
    if (file == "")
        file <- stdout()
    else if (is.character(file)) {
        file <- file(file, ifelse(append, "a", "w"))
        on.exit(close(file))
    }
    if (!inherits(file, "connection"))
        stop("'file' must be a character string or connection")
    nr <- nrow(x)
    nc <- ncol(x)
    tx <- t(x)
    not.na <- c(!is.na(tx))
    eor <- character(sum(not.na))
    eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
    writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
        style = "list", width = width, indent = indent)[not.na], eor,
        sep = ""), file)
}


From maechler at stat.math.ethz.ch  Tue Jul 17 19:08:03 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 17 Jul 2007 19:08:03 +0200
Subject: [Rd] Field initialization order bug?
In-Reply-To: <469CB73A.7030006@biostat.ku.dk>
References: <p0624081dc2c19b42aa26@[128.165.72.98]>
	<Pine.LNX.4.64.0707170821220.30535@auk.stats>
	<469CB73A.7030006@biostat.ku.dk>
Message-ID: <18076.63347.601933.898626@stat.math.ethz.ch>


    PD> Prof Brian Ripley wrote:

       PBR> On Mon, 16 Jul 2007, Daniel Wilhelm wrote:

	 >>> I believe that I may have found a bug in R. The top code sample gives
      PBR> You have 'merely' found a bug in your understanding.
      PBR> What type did you expect 'a' to be?  If you expected
      PBR> a list, that is not what happens in the first
      PBR> example, and you need

      PBR> a <- list()
      PBR> 
      PBR> or, better,
      PBR> 
      PBR> a <- vector("list", 2)

    PD> To be precise, you need

    PD> a <- vector("list", 2) ; names(a) <- c("field1", "field2")

    PD> or you end up with a 4-element list.

yes;  and consequently, a more readable solution would start saying

   a <- list(field1 = NULL, field2 = NULL)

or equivalently (and maybe nicer looking):

   a <- list(field1 = {}, field2 = {})


Martin Maechler, ETH Zurich


From leonardz at sickkids.ca  Tue Jul 17 21:28:47 2007
From: leonardz at sickkids.ca (Len Zaifman)
Date: Tue, 17 Jul 2007 15:28:47 -0400 (EDT)
Subject: [Rd] Problem building R with Sun Studio Compiler
In-Reply-To: <Pine.LNX.4.64.0707171021530.27991@auk.stats>
References: <13011.142.20.196.170.1184602626.squirrel@webmail.sickkids.ca>
	<Pine.LNX.4.64.0707161746130.8695@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0707171021530.27991@auk.stats>
Message-ID: <22588.142.20.196.170.1184700527.squirrel@webmail.sickkids.ca>

Thanks for all the replies:

Dr. Ripley gets it right:

I want -fast which turns on nofstore which caused the infinite loop and also pointed out non-IEEE arithmetic.

On SUSE 10.2  I used -fast -fstore -fsimple=1 which fixed both problems and still optimised:

make check passed and I get for gcc4.1 vs SunStudio 12:
186 vs 149 seconds, with all tests passed in both cases.

Prof Brian Ripley said:
> On Mon, 16 Jul 2007, Prof Brian Ripley wrote:
>
>> The R-admin manual did tell you not to do that!
>>
>>  When using the Sun compilers do @emph{not} specify @option{-fast}, as
>>  this disables @acronym{IEEE} arithmetic and @command{make check} will
>>  fail.
>>
>> That was for Solaris and SunStudio 11, but I presume these are basically the
>> same compilers.  (--fast has been a no-no for as long as I have been using R
>> on Solaris, ca 10 years.)
>
> There is another problem with -fast on x86 that is probably the cause of
> your problem.  It implies -nofstore, and we needed to force storage on
> some Fortran routines under g77/gfortran to avoid an infinite loop.
>
> However, even if you set SAFE_FFLAGS, the likely problems with IEC60559
> compliance remain.
>
>>
>> On Mon, 16 Jul 2007, Len Zaifman wrote:
>>
>>> I would like to Build R-2.5.1 on OpenSUSE 10.2 using the SunStudio 12
>>> compilers(http://developers.sun.com/sunstudio/index.jsp)
>>>
>>> R builds and passes make check fine without optimising. However, when I try
>>> to compile with optimisation turned on
>>> (-fast) the build gets stuck in an infinite loop  at the following point:
>>>
>>> Sun_Studio/sunstudio12/bin/cc -m64 -shared -Kpic   -m64 -fPIC  -o
>>> grDevices.so chull.o devNull.o devPicTeX.o devPS.o
>>> devQuartz.o init.o
>>> mkdir -p -- ../../../../library/grDevices/libs
>>> make[5]: Leaving directory
>>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
>>> make[4]: Leaving directory
>>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/grDevices/src'
>>>
>>> R is running at this point and will run for as long as I do not kill it. If
>>> I compile without -fast the next line in the make is:
>>>
>>> make[3]: Entering directory
>>> `/export/home/leonardz/ccb/HPF/support/R-2.5.1/ss12/R-2.5.1/src/library/graphics'
>>>
>>> and the entire package builds and make check verifies correctly. Any ideas
>>> on why this is happening?
>>>
>>> The build works fine for gcc as well.
>>>
>>>
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
Len Zaifman
Systems Manager, Supercomputing Systems
Centre for Computational Biology
Hospital for Sick Children
Toronto, Ont. M5G 1X8
leonardz at sickkids.ca
(416)813-5513


From leonardz at sickkids.ca  Tue Jul 17 21:44:34 2007
From: leonardz at sickkids.ca (Len Zaifman)
Date: Tue, 17 Jul 2007 15:44:34 -0400 (EDT)
Subject: [Rd] Problem building R with Sun Studio Compiler on SLES 9 SP3
Message-ID: <12003.142.20.196.170.1184701474.squirrel@webmail.sickkids.ca>

In a previous thread I had problems on openSuse 10.2 building R with optimisation and discovered that if I wanted
optimisation I need to turn on

-fstore -fsimple1 (the first is to force storage on some Fortran routines , the second is to ensure IEEE arithmetic,
with some optimisation).

That worked for my desktop. The real problem is to work on our servers (Opterons running SLES9SP3)

Make works fine but make check fails in

base-Ex.R  on IO, specifically from base-Ex.Rout.fail:

>
> if(capabilities("fifo")) {
+   zz <- fifo("foo", "w+")
+   writeLines("abc", zz)
+   print(readLines(zz))
+   close(zz)
+   unlink("foo")
+ }
Warning in fifo("foo", "w+") : cannot create fifo 'foo', reason 'Input/output error'
Error in fifo("foo", "w+") : unable to open connection
Execution halted


Does anybody know what I need to do to get this fifo capability turned on?



-- 
Len Zaifman
Systems Manager, Supercomputing Systems
Centre for Computational Biology
Hospital for Sick Children
Toronto, Ont. M5G 1X8
leonardz at sickkids.ca
(416)813-5513


From dwilhelm at lanl.gov  Tue Jul 17 17:56:38 2007
From: dwilhelm at lanl.gov (Daniel Wilhelm)
Date: Tue, 17 Jul 2007 09:56:38 -0600
Subject: [Rd] Field initialization order bug?
In-Reply-To: <Pine.LNX.4.64.0707170821220.30535@auk.stats>
References: <p0624081dc2c19b42aa26@[128.165.72.98]>
	<Pine.LNX.4.64.0707170821220.30535@auk.stats>
Message-ID: <p0624081ec2c295ae3fcb@[128.165.72.98]>

Thank you all for clarifying that bug in my understanding! I suppose 
that I expected 'a' to be promoted to a list when indexed from NULL. 
I will be more judicious in the future when I post.

Daniel Wilhelm



>On Mon, 16 Jul 2007, Daniel Wilhelm wrote:
>
>>I believe that I may have found a bug in R. The top code sample gives
>
>You have 'merely' found a bug in your understanding.  What type did 
>you expect 'a' to be?  If you expected a list, that is not what 
>happens in the first example, and you need
>
>a <- list()
>
>or, better,
>
>a <- vector("list", 2)
>
>>an error as shown. However, by simply switching which field is
>>initialized first as in the bottom code sample, it works as expected.
>>
>>
>>This gives an error:
>>
>>
>>a <- NULL
>>a[["field1"]] <- 1
>
>Now a is numeric
>
>>a[["field2"]] <- matrix(c(2,1), 1)
>>
>>Error in a[["field2"]] <- matrix(c(2, 1), 1) :
>>	more elements supplied than there are to replace
>>
>>
>>
>>Yet, this works as expected:
>>
>>a <- NULL
>>a[["field2"]] <- matrix(c(2,1), 1)
>
>Now a is a list
>
>>a[["field1"]] <- 1
>>
>>
>>
>>Daniel Wilhelm
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Jul 18 09:43:25 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 18 Jul 2007 09:43:25 +0200 (CEST)
Subject: [Rd] (PR#9796) write.dcf/read.dcf cycle converts missing entry
Message-ID: <20070718074325.17CE565969@slim.kubism.ku.dk>

BIll,

Thanks.

I am seeing some problems here, for example when all the fields are 
missing, or all the fields in a row are missing.  I've fixes for those, 
and will commit to R-devel shortly.

On Tue, 17 Jul 2007, bill at insightful.com wrote:

> Full_Name: Bill Dunlap
> Version: 2.5.0
> OS: Red Hat Enterprise Linux WS release 3 (Taroon Update 6)
> Submission from: (NULL) (24.17.60.30)
>
>
> If you read a dcf file with read.dcf(file,fields=c("Field",...))
> and the file does not contain the desired field "Field",
> read.dcf puts a character NA for that entry in its output
> matrix.  If you then call write.dcf, passing it the output
> of read.dcf(), it will write the entry "Field: NA".  A subsequent
> read.dcf() on write.dcf's output file will then have a "NA",
> not a character NA, in the entry for "Field".  I think that
> write.dcf() should not write lines in the output file where
> the input matrix contains a character NA.
>
> Here is a test function to demonstrate the problem.  It returns
> TRUE when a write.dcf/read.dcf cycle does not change the data.
>
>  test.write.dcf <- function () {
>     origFile <- tempfile()
>     copyFile <- tempfile()
>     on.exit(unlink(c(origFile, copyFile)))
>     writeLines(c("Package: testA", "Version: 0.1-1", "Depends:", "",
>                  "Package: testB", "Version: 2.1"  , "Suggests: testA", "",
>                  "Package: testC", "Version: 1.3.1", ""),
>                origFile)
>     orig <- read.dcf(origFile,
>                      fields=c("Package","Version","Depends","Suggests"))
>     write.dcf(orig, copyFile, width = 72)
>     copy <- read.dcf(copyFile,
>                      fields=c("Package","Version","Depends","Suggests"))
>     value <- all.equal(orig, copy)
>     if (!identical(value, TRUE)) {
>        attr(value, "orig") <- orig
>        attr(value, "copy") <- copy
>     }
>     value
>  }
> Currently we get
>  > test.write.dcf()
>  [1] "'is.NA' value mismatch: 0 in current 4 in target"
>  attr(,"orig")
>       Package Version Depends Suggests
>  [1,] "testA" "0.1-1" ""      NA
>  [2,] "testB" "2.1"   NA      "testA"
>  [3,] "testC" "1.3.1" NA      NA
>  attr(,"copy")
>       Package Version Depends Suggests
>  [1,] "testA" "0.1-1" ""      "NA"
>  [2,] "testB" "2.1"   "NA"    "testA"
>  [3,] "testC" "1.3.1" "NA"    "NA"
> With the attached write.dcf() it returns TRUE.
>
> The diff would be
> 19,22c19,24
> <     eor <- character(nr * nc)
> <     eor[seq.int(1, nr - 1) * nc] <- "\n"
> <     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(t(x)),
> <         style = "list", width = width, indent = indent), eor,
> ---
>>     tx <- t(x)
>>     not.na <- c(!is.na(tx))
>>     eor <- character(sum(not.na))
>>     eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
>>     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
>>         style = "list", width = width, indent = indent)[not.na], eor,
>
> and the entire function would be
>
> `write.dcf` <-
> function (x, file = "", append = FALSE, indent = 0.1 * getOption("width"),
>    width = 0.9 * getOption("width"))
> {
>    if (!is.data.frame(x))
>        x <- data.frame(x)
>    x <- as.matrix(x)
>    mode(x) <- "character"
>    if (file == "")
>        file <- stdout()
>    else if (is.character(file)) {
>        file <- file(file, ifelse(append, "a", "w"))
>        on.exit(close(file))
>    }
>    if (!inherits(file, "connection"))
>        stop("'file' must be a character string or connection")
>    nr <- nrow(x)
>    nc <- ncol(x)
>    tx <- t(x)
>    not.na <- c(!is.na(tx))
>    eor <- character(sum(not.na))
>    eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
>    writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
>        style = "list", width = width, indent = indent)[not.na], eor,
>        sep = ""), file)
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Wed Jul 18 17:39:27 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 18 Jul 2007 11:39:27 -0400
Subject: [Rd] S4 coerce
In-Reply-To: <469CD0B8.5030301@bank-banque-canada.ca>
References: <469B8771.5060601@bank-banque-canada.ca>
	<m2fy3nipp7.fsf@ziti.fhcrc.org>
	<469CD0B8.5030301@bank-banque-canada.ca>
Message-ID: <469E342F.5030103@bank-banque-canada.ca>

This may be a better example of what I am now thinking is probably a bug 
in S4 dispatch:

 > require("RMySQL") # or require("RSQLite")
Loading required package: RMySQL
Loading required package: DBI
[1] TRUE

 > m <- dbDriver("MySQL")  # or  m <- dbDriver("SQLite")
 > con <- dbConnect(m, dbname="test")
 >dbGetQuery(con, "create table zzz (
   vintage     VARCHAR(20) NOT NULL,
   alias       VARCHAR(20) default NULL,
   Documentation     TEXT,
   PRIMARY KEY (vintage)
   );")

 >dbListTables(con)
 [1] "zzz"                 

 > setClass("TSconnection", contains="DBIConnection",
    representation(con="DBIConnection",
    vintage = "logical",
    panel   = "logical"))
[1] "TSconnection"

 > setAs("TSconnection", "DBIConnection", def = function(from) from at con)
[1] "coerce<-"

 > setIs("TSconnection", "DBIConnection", coerce = function(x) x at con)
Warning message:
there is no automatic definition for as(object, "DBIConnection") <- 
value when object has class "TSconnection" and no 'replace' argument was 
supplied; replacement will be an error in: makeExtends(class1, class2, 
coerce, test, replace, by, classDef1 = classDef, 

 > Tcon <- new("TSconnection", con=dbConnect(m, dbname="test"), 
vintage=FALSE, panel=FALSE)

 > is(Tcon, "DBIConnection")
[1] TRUE

I think this should work:

 > dbListTables(Tcon)
Error in function (classes, fdef, mtable)  :
    unable to find an inherited method for function "dbListTables", for 
signature "TSconnection"

but instead I have to do this:

 > dbListTables(as(Tcon, "DBIConnection"))
 [1]  "zzz"                 
 
Paul

Paul Gilbert wrote:

>
>
> Seth Falcon wrote:
>
>> Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
>>
>>  
>>
>>> (I am not sure if this is a bug or a request for a more 
>>> understandable warning, or possible something obvious I should be 
>>> posting on r-help.)
>>>
>>> I am trying to coerce an new class object to be a DBIConnection and 
>>> it does not work the way I think it should:
>>>
>>> R version 2.5.1 (2007-06-27) ...
>>> > require("RMySQL") # or require("RSQLite")
>>> Loading required package: RMySQL
>>> Loading required package: DBI
>>> [1] TRUE
>>> > m <- dbDriver("MySQL")  # or  m <- dbDriver("SQLite")
>>> > con <- dbConnect(m, dbname="test")
>>> > dbGetQuery(con, "create table zzz (
>>> +    vintage     VARCHAR(20) NOT NULL,
>>> +    alias       VARCHAR(20) default NULL,
>>> +    Documentation     TEXT,
>>> +    PRIMARY KEY (vintage)
>>> +    );")
>>> NULL
>>> > dbListTables(con)
>>>  [1] "zzz"
>>> > setClass("TSconnection", representation(con="DBIConnection",
>>> +    vintage = "logical",
>>> +    panel   = "logical")
>>> +    )
>>> [1] "TSconnection"
>>> > setAs("TSconnection", "DBIConnection", def = function(from) from at con)
>>>   
>>
>>
>> I think things work as you expect up until this pint.
>>  
>>
> Yes.
>
>>  
>>
>>> > setIs("TSconnection", "DBIConnection", coerce = function(x)
>>> > x at con)
>>>   
>>
>>
>> I'm confused about what you want to do here.  If you want TSconnection
>> to be a DBIConnection, why wouldn't you use inheritance?
>>
>>   setClass("TSconnection", contains="DBIConnection", ...)
>>  
>>
> Perhaps my logic is confused, it wouldn't be the first time,  but I am 
> thinking of this as going the "other direction" from inheritance.   A 
> MySQLConnection or SQLiteConnection inherits from DBIConnection. To 
> actually use a DBIConnection or my TSconnection it will be necessary 
> to have one of these, so I would need something like
>
> setClass("TSconnection", contains="MySQLConnection", ...)
>
> to make this work. (Actually, I have not been able to make it work, 
> but that may just be the novice level of my experimenting.)   I am 
> hoping I can define the TSconnection using only DBIConnection classes 
> and have it automatically work when one of the database driver 
> packages is added. Otherwise  I have to define the TSconnection for 
> each of the driver packages, which is not as clean.
>
> Paul
>
>> + seth
>>
>>  
>>
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From maechler at stat.math.ethz.ch  Wed Jul 18 17:46:06 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Jul 2007 17:46:06 +0200
Subject: [Rd] S4 and Namespaces problems {was "error message from lmer"}
In-Reply-To: <Pine.LNX.4.64.0706280557300.23081@gannet.stats.ox.ac.uk>
References: <87abult2ey.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0706280557300.23081@gannet.stats.ox.ac.uk>
Message-ID: <18078.13758.396732.297757@stat.math.ethz.ch>

Here is a reproducible example for the Bug that both Sebastian
and Dale Barr found.

As Brian mentioned in an another thread,
the problem is in the interaction of Namespaces and S4 generics
and which S4 generic should keep which methods.

We know there are workarounds, but till now they seem either
ugly or very much against the idea that conceptually there
should be only one generic which may have methods defined in
many different packages / namespaces.

I would like us (R-core, mostly) to resolve this as quickly as
possible.

-------------------------------------------------------------------------

### Do this in a fresh  R session:

summary # S3 generic
find("summary") # base

library(stats4)
summary # S4 generic
find("summary") # stats4 , base

library(lme4)
## -> loads Matrix (and lattice)
find("summary") # lme4, Matrix, stats4 , base   --- 4 times ! ---

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
## -->
## Error in lmer(Reaction ~ Days + (Days | Subject), sleepstudy) :
## 	cannot get a slot ("Dim") from an object of type "NULL"

-------------------------------------------------------------------------
Martin Maechler


>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Thu, 28 Jun 2007 06:08:45 +0100 (BST) writes:

    BDR> See the thread starting
    BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046157.html
    BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046160.html

    BDR> I can't reproduce this without knowing what is in your
    BDR> startup files: it should work with --vanilla, so please
    BDR> try that and try to eliminate whatever is in your
    BDR> .Rprofile etc that is causing the problem.

    BDR> Incidentally, using rcompletion is counterproductive in
    BDR> R 2.5.1 RC: the base functionality using rcompgen is a
    BDR> more sophisticated version.

    BDR> On Wed, 27 Jun 2007, Sebastian P. Luque wrote:

    >> Hi,
    >> 
    >> I've begun to use the lme4 package, rather than nlme, for more flexibility
    >> during modelling, and running the examples in lmer I receive this error
    >> message:
    >> 
    >> ---<---------------cut here---------------start-------------->---
    R> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >> Error in printMer(object) : no slot of name "status" for this object of class "table"
    >> 
    R> sessionInfo()
    >> R version 2.5.1 RC (2007-06-25 r42057)
    >> x86_64-pc-linux-gnu
    >> 
    >> locale:
    >> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
    >> 
    >> attached base packages:
    >> [1] "stats4"    "stats"     "graphics"  "grDevices" "utils"     "datasets"
    >> [7] "methods"   "base"
    >> 
    >> other attached packages:
    >> lme4      Matrix rcompletion    rcompgen     lattice    diveMove
    >> "0.99875-2" "0.99875-2"     "0.1-2"    "0.1-13"   "0.15-11"     "0.7-9"
    >> reshape
    >> "0.7.4"
    >> ---<---------------cut here---------------end---------------->---
    >> 
    >> Since this is happening in a fresh session, and with code from examples
    >> help file, this looks like a potential bug.  Any thoughts?
    >> 
    >> 
    >> Cheers,


From rgentlem at fhcrc.org  Wed Jul 18 18:15:50 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Wed, 18 Jul 2007 09:15:50 -0700
Subject: [Rd] S4 and Namespaces problems {was "error message from lmer"}
In-Reply-To: <18078.13758.396732.297757@stat.math.ethz.ch>
References: <87abult2ey.fsf@patagonia.sebmags.homelinux.org>	<Pine.LNX.4.64.0706280557300.23081@gannet.stats.ox.ac.uk>
	<18078.13758.396732.297757@stat.math.ethz.ch>
Message-ID: <469E3CB6.30505@fhcrc.org>

Hi,

Martin Maechler wrote:
> Here is a reproducible example for the Bug that both Sebastian
> and Dale Barr found.
> 
> As Brian mentioned in an another thread,
> the problem is in the interaction of Namespaces and S4 generics
> and which S4 generic should keep which methods.
> 
> We know there are workarounds, but till now they seem either
> ugly or very much against the idea that conceptually there
> should be only one generic which may have methods defined in
> many different packages / namespaces.

   There should *not* be one generic. Generics are no different than any 
other function. Package A can have a generic named foo, and so can 
package B.  Other packages that want to add methods to a generic named 
foo need to know which one they would like to add to.  These generics 
can be masked. If Package A is first on the search path then that is the 
foo that is found first (and if Package B is first then that is the foo, 
users that specifically want foo from B should use B::foo).


> 
> I would like us (R-core, mostly) to resolve this as quickly as
> possible.
> 
> -------------------------------------------------------------------------
> 
> ### Do this in a fresh  R session:
> 
> summary # S3 generic
> find("summary") # base
> 
> library(stats4)
> summary # S4 generic
> find("summary") # stats4 , base
> 
> library(lme4)
> ## -> loads Matrix (and lattice)
> find("summary") # lme4, Matrix, stats4 , base   --- 4 times ! ---

   Have they all defined generics? If that is the case then there are 4.

   We did discuss, and I hope to make progress on the following 
proposal. For functions in base that have an S4 method defined for them 
(and hence we need a generic function), that we create a new package 
that lives slightly above base (and potentially other recommended 
packages) where these generics will live.  Developers can then rely on 
finding the generic there, and using it - if their intention is to 
extend the base generic.  Note that they may want to have their own 
generic with the same name as the one from base, and that is fine, it 
will mask the one in base.

   best wishes
    Robert
> 
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> ## -->
> ## Error in lmer(Reaction ~ Days + (Days | Subject), sleepstudy) :
> ## 	cannot get a slot ("Dim") from an object of type "NULL"
> 
> -------------------------------------------------------------------------
> Martin Maechler
> 
> 
>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Thu, 28 Jun 2007 06:08:45 +0100 (BST) writes:
> 
>     BDR> See the thread starting
>     BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046157.html
>     BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046160.html
> 
>     BDR> I can't reproduce this without knowing what is in your
>     BDR> startup files: it should work with --vanilla, so please
>     BDR> try that and try to eliminate whatever is in your
>     BDR> .Rprofile etc that is causing the problem.
> 
>     BDR> Incidentally, using rcompletion is counterproductive in
>     BDR> R 2.5.1 RC: the base functionality using rcompgen is a
>     BDR> more sophisticated version.
> 
>     BDR> On Wed, 27 Jun 2007, Sebastian P. Luque wrote:
> 
>     >> Hi,
>     >> 
>     >> I've begun to use the lme4 package, rather than nlme, for more flexibility
>     >> during modelling, and running the examples in lmer I receive this error
>     >> message:
>     >> 
>     >> ---<---------------cut here---------------start-------------->---
>     R> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>     >> Error in printMer(object) : no slot of name "status" for this object of class "table"
>     >> 
>     R> sessionInfo()
>     >> R version 2.5.1 RC (2007-06-25 r42057)
>     >> x86_64-pc-linux-gnu
>     >> 
>     >> locale:
>     >> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>     >> 
>     >> attached base packages:
>     >> [1] "stats4"    "stats"     "graphics"  "grDevices" "utils"     "datasets"
>     >> [7] "methods"   "base"
>     >> 
>     >> other attached packages:
>     >> lme4      Matrix rcompletion    rcompgen     lattice    diveMove
>     >> "0.99875-2" "0.99875-2"     "0.1-2"    "0.1-13"   "0.15-11"     "0.7-9"
>     >> reshape
>     >> "0.7.4"
>     >> ---<---------------cut here---------------end---------------->---
>     >> 
>     >> Since this is happening in a fresh session, and with code from examples
>     >> help file, this looks like a potential bug.  Any thoughts?
>     >> 
>     >> 
>     >> Cheers,
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From b.rowlingson at lancaster.ac.uk  Wed Jul 18 19:29:58 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 18 Jul 2007 18:29:58 +0100
Subject: [Rd] Saving R graphics as various file types.
Message-ID: <469E4E16.3020402@lancaster.ac.uk>

  I'm using R called via Rpy from Python running from Quantum GIS.  Put 
simply, I'm developing a GUI wrapper round some R plotting functions.

  What I want to do is offer the user a 'Save Plot As...' option.

  The problem is divining what sort of output files R can copy a 
graphics device into.  The 'capabilities()' function gives a few clues, 
and there should always be postscript and pdf functions, but then if R 
has the Cairo package then there may be even more options - Tiff, SVG 
and so on.

  What I'd like is a way of collecting up all the possible graphics 
output formats so that my Save dialog can list them, and then working 
out how to do the conversions when the user requests it.

  Perhaps someone has already done this? I think the simplest way may be 
to hard-code as much as possible initially.  For each possible output 
format have a number of possible ways of producing that output and a 
test to see if that method is available.  Then run the tests and use the 
best ones found.  For example, it's probably better to make a TIFF file 
using CairoTIFF than using jpeg() and a shell call to ImageMagick's 
convert routine. But if there's no Cairo, fall back. If there's no 
jpeg(), or no ImageMagick, then you're stuck, and jpeg output is no 
longer an option.

  How would this work in practice? Let's think:

  > library(graphicsFormats)
  > graphicsFormats()
  [1] "png" "pdf" "eps" "tiff" "svg"

  > graphicsFormatInfo("png")
  [1] "png ; portable network graphics" "raster"

  > graphicsFormatSupport("jpeg")
  Warning message:
  No jpeg support in capabilities() and no Cairo package present
  [1] FALSE

And then the all important:

  > convertTo("png",filePrefix="/foo/bar")

  I'm still pondering the above functions.  The basic idea would be to 
make graphics file format conversions device driver independent.  I'm 
not sure if this is too lofty a goal, since different device drivers 
will require very different further arguments...

  Anyway, all thoughts welcome.

Barry


From falimadhi at gmail.com  Thu Jul 19 00:11:31 2007
From: falimadhi at gmail.com (Ferdinand Alimadhi)
Date: Wed, 18 Jul 2007 18:11:31 -0400
Subject: [Rd] possible bug R CMD check: No space(s) allowed after
	\VignetteDepends{}
Message-ID: <e77aa48a0707181511l138ff5bapd82a197bdd105f2a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070718/b9dd2faf/attachment.pl 

From bill at insightful.com  Thu Jul 19 01:32:04 2007
From: bill at insightful.com (Bill Dunlap)
Date: Wed, 18 Jul 2007 16:32:04 -0700 (PDT)
Subject: [Rd] (PR#9796) write.dcf/read.dcf cycle converts missing entry
In-Reply-To: <20070718074325.17CE565969@slim.kubism.ku.dk>
References: <20070718074325.17CE565969@slim.kubism.ku.dk>
Message-ID: <Pine.GSO.4.56.0707181619420.20033@durian.statsci.com>

On Wed, 18 Jul 2007 ripley at stats.ox.ac.uk wrote:

> I am seeing some problems here, for example when all the fields are
> missing, or all the fields in a row are missing.  I've fixes for those,
> and will commit to R-devel shortly.

write.dcf() is also used by print.packageDesription() so
this change affects how missing fields are printed there.
In 2.5 we got
   > packageDescription("base", fields=c("Version","NoSuchField"))
   Version: 2.5.0
   NoSuchField: NA

   -- File: /dept/devel/sw/R/R.linux.2.5.0/lib/R/library/base/DESCRIPTION
   -- Fields read: Version, NoSuchField
and now it doesn't print anything about the non-existant field
   > packageDescription("base", fields=c("Version","NoSuchField"))
   Version: 2.6.0
   -- File: /homes/bill/R-svn/r-devel/R/library/base/DESCRIPTION
   -- Fields read: Version, NoSuchField
If this isn't acceptable then write.dcf will need a new argument
to control the printing of missing lines.

The missing trailing blank line is an inadvertant change (although
it makes appending fields to a single record dcf file possible).

> > If you read a dcf file with read.dcf(file,fields=c("Field",...))
> > and the file does not contain the desired field "Field",
> > read.dcf puts a character NA for that entry in its output
> > matrix.  If you then call write.dcf, passing it the output
> > of read.dcf(), it will write the entry "Field: NA".  A subsequent
> > read.dcf() on write.dcf's output file will then have a "NA",
> > not a character NA, in the entry for "Field".  I think that
> > write.dcf() should not write lines in the output file where
> > the input matrix contains a character NA.
> > ...
> > The diff would be
> > 19,22c19,24
> > <     eor <- character(nr * nc)
> > <     eor[seq.int(1, nr - 1) * nc] <- "\n"
> > <     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(t(x)),
> > <         style = "list", width = width, indent = indent), eor,
> > ---
> >>     tx <- t(x)
> >>     not.na <- c(!is.na(tx))
> >>     eor <- character(sum(not.na))
> >>     eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
> >>     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
> >>         style = "list", width = width, indent = indent)[not.na], eor,

   [ The ==1 should be >=1 ]


From ripley at stats.ox.ac.uk  Thu Jul 19 06:30:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Jul 2007 05:30:26 +0100 (BST)
Subject: [Rd] S4 and Namespaces problems {was "error message from lmer"}
In-Reply-To: <469E3CB6.30505@fhcrc.org>
References: <87abult2ey.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0706280557300.23081@gannet.stats.ox.ac.uk>
	<18078.13758.396732.297757@stat.math.ethz.ch>
	<469E3CB6.30505@fhcrc.org>
Message-ID: <Pine.LNX.4.64.0707181752001.24016@gannet.stats.ox.ac.uk>

On Wed, 18 Jul 2007, Robert Gentleman wrote:

> Hi,
>
> Martin Maechler wrote:
>> Here is a reproducible example for the Bug that both Sebastian
>> and Dale Barr found.
>>
>> As Brian mentioned in an another thread,
>> the problem is in the interaction of Namespaces and S4 generics
>> and which S4 generic should keep which methods.
>>
>> We know there are workarounds, but till now they seem either
>> ugly or very much against the idea that conceptually there
>> should be only one generic which may have methods defined in
>> many different packages / namespaces.
>
>   There should *not* be one generic. Generics are no different than any
> other function. Package A can have a generic named foo, and so can
> package B.  Other packages that want to add methods to a generic named
> foo need to know which one they would like to add to.  These generics
> can be masked. If Package A is first on the search path then that is the
> foo that is found first (and if Package B is first then that is the foo,
> users that specifically want foo from B should use B::foo).

I do think base is a special case here, given its privileged position in 
the namespace hierarchy.  I'd take Martin's position as rather that there 
should be only one generic derived by take-over from a function, at least 
for those in base.

I believe that if you are allowed to make a function in base S4-generic 
(and it is not obvious that you should be in many cases), then the derived 
generic should conceptually be in base and thus always be found in place 
of that in base.  Since base is not a normal environment or namespace, 
that is not straightforward to implement but it should be possible by 
(e.g.) C-level hacking and a environment to store such derived generics. 
Primitives are rather different, and we now have a fairly efficient way to 
allow designated primitives to have S4 methods.

I believe the registration model for S3 methods is pretty much the right 
one: methods are set on the first 'foo' on the relevant search path, and 
that does not cause another 'foo' to be created elsewhere that may or may 
not precede the original in the relevant search path (since there are 
multiple search paths once namespaces enter the mix).

The new implied generics model helps here: taking over a function in base 
unaltered (the same as the implied generic) could be a derived generic, 
and any alteration would create a new generic in your package.  That 
protects code in other namespaces from your alterations.

>> I would like us (R-core, mostly) to resolve this as quickly as
>> possible.

It seems tricky enough to need debate what we want for a while and aim for 
2.6.0.  But we have been discussing it on and off for at least two years.

Brian

>>
>> -------------------------------------------------------------------------
>>
>> ### Do this in a fresh  R session:
>>
>> summary # S3 generic
>> find("summary") # base
>>
>> library(stats4)
>> summary # S4 generic
>> find("summary") # stats4 , base
>>
>> library(lme4)
>> ## -> loads Matrix (and lattice)
>> find("summary") # lme4, Matrix, stats4 , base   --- 4 times ! ---
>
>   Have they all defined generics? If that is the case then there are 4.
>
>   We did discuss, and I hope to make progress on the following
> proposal. For functions in base that have an S4 method defined for them
> (and hence we need a generic function), that we create a new package
> that lives slightly above base (and potentially other recommended
> packages) where these generics will live.  Developers can then rely on
> finding the generic there, and using it - if their intention is to
> extend the base generic.  Note that they may want to have their own
> generic with the same name as the one from base, and that is fine, it
> will mask the one in base.
>
>   best wishes
>    Robert
>>
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> ## -->
>> ## Error in lmer(Reaction ~ Days + (Days | Subject), sleepstudy) :
>> ## 	cannot get a slot ("Dim") from an object of type "NULL"
>>
>> -------------------------------------------------------------------------
>> Martin Maechler
>>
>>
>>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>>     on Thu, 28 Jun 2007 06:08:45 +0100 (BST) writes:
>>
>>     BDR> See the thread starting
>>     BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046157.html
>>     BDR> https://stat.ethz.ch/pipermail/r-devel/2007-June/046160.html
>>
>>     BDR> I can't reproduce this without knowing what is in your
>>     BDR> startup files: it should work with --vanilla, so please
>>     BDR> try that and try to eliminate whatever is in your
>>     BDR> .Rprofile etc that is causing the problem.
>>
>>     BDR> Incidentally, using rcompletion is counterproductive in
>>     BDR> R 2.5.1 RC: the base functionality using rcompgen is a
>>     BDR> more sophisticated version.
>>
>>     BDR> On Wed, 27 Jun 2007, Sebastian P. Luque wrote:
>>
>>    >> Hi,
>>    >>
>>    >> I've begun to use the lme4 package, rather than nlme, for more flexibility
>>    >> during modelling, and running the examples in lmer I receive this error
>>    >> message:
>>    >>
>>    >> ---<---------------cut here---------------start-------------->---
>>     R> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>>    >> Error in printMer(object) : no slot of name "status" for this object of class "table"
>>    >>
>>     R> sessionInfo()
>>    >> R version 2.5.1 RC (2007-06-25 r42057)
>>    >> x86_64-pc-linux-gnu
>>    >>
>>    >> locale:
>>    >> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>>    >>
>>    >> attached base packages:
>>    >> [1] "stats4"    "stats"     "graphics"  "grDevices" "utils"     "datasets"
>>    >> [7] "methods"   "base"
>>    >>
>>    >> other attached packages:
>>    >> lme4      Matrix rcompletion    rcompgen     lattice    diveMove
>>    >> "0.99875-2" "0.99875-2"     "0.1-2"    "0.1-13"   "0.15-11"     "0.7-9"
>>    >> reshape
>>    >> "0.7.4"
>>    >> ---<---------------cut here---------------end---------------->---
>>    >>
>>    >> Since this is happening in a fresh session, and with code from examples
>>    >> help file, this looks like a potential bug.  Any thoughts?
>>    >>
>>    >>
>>    >> Cheers,
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From john.maindonald at anu.edu.au  Thu Jul 19 12:15:59 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 19 Jul 2007 20:15:59 +1000
Subject: [Rd] substitute and expression (Peter Dalgaard)
In-Reply-To: <mailman.8.1184752806.18649.r-devel@r-project.org>
References: <mailman.8.1184752806.18649.r-devel@r-project.org>
Message-ID: <BC3864C7-8742-4E1D-B3C1-12161A6E3A27@anu.edu.au>

In this connection, note the following

 > a4 <- 4
 > plotThis <- bquote(alpha==.(a), list(a=a4))
 > do.call(plot, list(1:10, main=do.call(expression, c(plotThis))))
 > do.call(plot, list(1:10, main=do.call(expression, plotThis)))
Error in do.call(expression, plotThis) : second argument must be a list

 > ## Whereas plotThis has class "call", c(plotThis) has class "list"
 > class(plotThis)
[1] "call"
 > class(c(plotThis))
[1] "list"

 > ## Thus, the following is possible:
 > do.call(plot, list(1:10, main=do.call(expression, list(plotThis))))


Marc Schwartz pointed out to me., some considerable time ago,
that one could use bquote() and .() to create the elements of a
list object whose elements can be plotted in parallel as required,
e.g., for axis labels, thus:

 > plot(1:2, 1:2, xaxt="n")
 > arg1 <- bquote(""< .(x), list(x=1.5))
 > arg2 <- bquote("">= .(x), list(x=1.5))
 > axis(1, at=1:2, labels=do.call(expression, list(arg1, arg2)))

For a unified approach to use of do.call(expression, ...), maybe
one should use bquote() and .()?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 18 Jul 2007, at 8:00 PM, r-devel-request at r-project.org wrote:

> From: Peter Dalgaard <P.Dalgaard at biostat.ku.dk>
> Date: 18 July 2007 1:39:50 AM
> To: Deepayan Sarkar <deepayan.sarkar at gmail.com>
> Cc: R Development Mailing List <r-devel at stat.math.ethz.ch>
> Subject: Re: [Rd] substitute and expression
>
>
> Deepayan Sarkar wrote:
>> On 7/16/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>
>>> Deepayan Sarkar wrote:
>>>
>>>> Hi,
>>>>
>>>> I'm trying to understand whether the use of substitute() is
>>>> appropriate/documented for plotmath annotation. The following two
>>>> calls give the same results:
>>>>
>>>>
>>>>
>>>>> plot(1:10, main = expression(alpha == 1))
>>>>> do.call(plot, list(1:10, main = expression(alpha == 1)))
>>>>>
>>>>>
>>>> But not these two:
>>>>
>>>>
>>>>
>>>>> plot(1:10, main = substitute(alpha == a, list(a = 2)))
>>>>> do.call(plot, list(1:10, main = substitute(alpha == a, list(a =  
>>>>> 2))))
>>>>>
>>>>>
>>>> Error in as.graphicsAnnot(main) : object "alpha" not found
>>>>
>>>> (as a consequence, xyplot(..., main = substitute(alpha)) doesn't
>>>> currently work.)
>>>>
>>>> On the other hand, this works:
>>>>
>>>>
>>>>
>>>>> foo <- function(x) plot(1, main = x)
>>>>> foo(substitute(alpha))
>>>>>
>>>>>
>>>> I'm not sure how to interpret ?plotmath; it says
>>>>
>>>>      If the 'text' argument to one of the text-drawing functions
>>>>      ('text', 'mtext', 'axis', 'legend') in R is an expression, the
>>>>      argument is interpreted as a mathematical expression...
>>>>
>>>> and uses substitute() in its examples, but
>>>>
>>>>
>>>>
>>>>> is.expression(substitute(alpha == a, list(a = 1)))
>>>>>
>>>>>
>>>> [1] FALSE
>>>>
>>>>
>>> I think you need to take plotmath out of the equation and study the
>>> difference between objects of mode "call" and those of mode
>>> "expression". Consider this:
>>>
>>>> f <- function(...)match.call()
>>>> do.call(f, list(1:10, main = substitute(alpha == a, list(a = 2))))
>>> function(...)match.call()
>>> (1:10, main = alpha == 2)
>>>> do.call(list, list(1:10, main = substitute(alpha == a, list(a =  
>>>> 2))))
>>> Error in do.call(list, list(1:10, main = substitute(alpha == a,  
>>> list(a =
>>> 2)))) :
>>>         object "alpha" not found
>>>
>>> The issue is that function ends up with an argument  alpha == 2  
>>> which it
>>> proceeds to evaluate (lazily), where a direct call sees
>>> substitute(.....). It is a general problem with the do.call  
>>> mechanism
>>> that it effectively pre-evaluates the argument list, which can  
>>> confuse
>>> functions that rely on accessing the original argument  
>>> expression. Try,
>>> e.g., do.call(plot, list(airquality$Wind, airquality$Ozone)) and  
>>> watch
>>> the axis labels.
>>>
>>
>> Right. Lazy evaluation was the piece I was missing.
>>
>>
>>> Does it work if you use something like
>>>
>>>  main = substitute(quote(alpha == a), list(a = 2))?
>>>
>>
>> Not for xyplot, though I haven't figured out why. Turns out this also
>> doesn't work:
>>
>>
>>> plot(y ~ x, data = list(x = 1:10, y = 1:10), main = substitute 
>>> (alpha))
>>>
>> Error in as.graphicsAnnot(main) : object "alpha" not found
>>
>> I'll take this to mean that the fact that substitute() works  
>> sometimes
>> (for plotmath) is an undocumented side effect of the implementation
>> that should not be relied upon.
>>
> Probably the correct solution is to use expression objects. More or  
> less
> the entire reason for their existence is this sort of surprises.
>
> plot(y ~ x, data = list(x = 1:10, y = 1:10), main =
> as.expression(substitute(alpha==a, list(a=2))))
>
> I'm not going to investigate why this is necessary in connection with
> plot(), but the core issue is probably
>
>> e <- quote(f(x)) ; e[[2]] <- quote(2+2)
>> e
> f(2 + 2)
>> f <- quote(f(2+2))
>> identical(e,f)
> [1] TRUE
>
> notice that since the two calls are identical, there is no way for  
> e to
> detect that it was called with x replaced by an object of mode "call".
> Or put differently, objects of mode call tend to lose their
> "personality" in connection with computing on the language.
>
>
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
> 35327907


From ripley at stats.ox.ac.uk  Thu Jul 19 12:37:59 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Jul 2007 11:37:59 +0100 (BST)
Subject: [Rd] (PR#9796) write.dcf/read.dcf cycle converts missing entry
In-Reply-To: <Pine.GSO.4.56.0707181619420.20033@durian.statsci.com>
References: <20070718074325.17CE565969@slim.kubism.ku.dk>
	<Pine.GSO.4.56.0707181619420.20033@durian.statsci.com>
Message-ID: <Pine.LNX.4.64.0707191136350.17359@gannet.stats.ox.ac.uk>

On Wed, 18 Jul 2007, Bill Dunlap wrote:

> On Wed, 18 Jul 2007 ripley at stats.ox.ac.uk wrote:
>
>> I am seeing some problems here, for example when all the fields are
>> missing, or all the fields in a row are missing.  I've fixes for those,
>> and will commit to R-devel shortly.
>
> write.dcf() is also used by print.packageDesription() so
> this change affects how missing fields are printed there.
> In 2.5 we got
>   > packageDescription("base", fields=c("Version","NoSuchField"))
>   Version: 2.5.0
>   NoSuchField: NA
>
>   -- File: /dept/devel/sw/R/R.linux.2.5.0/lib/R/library/base/DESCRIPTION
>   -- Fields read: Version, NoSuchField
> and now it doesn't print anything about the non-existant field
>   > packageDescription("base", fields=c("Version","NoSuchField"))
>   Version: 2.6.0
>   -- File: /homes/bill/R-svn/r-devel/R/library/base/DESCRIPTION
>   -- Fields read: Version, NoSuchField
> If this isn't acceptable then write.dcf will need a new argument
> to control the printing of missing lines.
>
> The missing trailing blank line is an inadvertant change (although
> it makes appending fields to a single record dcf file possible).

I've put in patches to address both of those issues.

Brian

>>> If you read a dcf file with read.dcf(file,fields=c("Field",...))
>>> and the file does not contain the desired field "Field",
>>> read.dcf puts a character NA for that entry in its output
>>> matrix.  If you then call write.dcf, passing it the output
>>> of read.dcf(), it will write the entry "Field: NA".  A subsequent
>>> read.dcf() on write.dcf's output file will then have a "NA",
>>> not a character NA, in the entry for "Field".  I think that
>>> write.dcf() should not write lines in the output file where
>>> the input matrix contains a character NA.
>>> ...
>>> The diff would be
>>> 19,22c19,24
>>> <     eor <- character(nr * nc)
>>> <     eor[seq.int(1, nr - 1) * nc] <- "\n"
>>> <     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(t(x)),
>>> <         style = "list", width = width, indent = indent), eor,
>>> ---
>>>>     tx <- t(x)
>>>>     not.na <- c(!is.na(tx))
>>>>     eor <- character(sum(not.na))
>>>>     eor[ c(diff(c(col(tx))[not.na]),0)==1 ] <- "\n"
>>>>     writeLines(paste(formatDL(rep.int(colnames(x), nr), c(tx),
>>>>         style = "list", width = width, indent = indent)[not.na], eor,
>
>   [ The ==1 should be >=1 ]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Thu Jul 19 13:31:56 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 19 Jul 2007 13:31:56 +0200
Subject: [Rd] substitute and expression (Peter Dalgaard)
In-Reply-To: <BC3864C7-8742-4E1D-B3C1-12161A6E3A27@anu.edu.au>
References: <mailman.8.1184752806.18649.r-devel@r-project.org>
	<BC3864C7-8742-4E1D-B3C1-12161A6E3A27@anu.edu.au>
Message-ID: <469F4BAC.7050202@biostat.ku.dk>

John Maindonald wrote:
> In this connection, note the following
>
>  > a4 <- 4
>  > plotThis <- bquote(alpha==.(a), list(a=a4))
>  > do.call(plot, list(1:10, main=do.call(expression, c(plotThis))))
>  > do.call(plot, list(1:10, main=do.call(expression, plotThis)))
> Error in do.call(expression, plotThis) : second argument must be a list
>
>  > ## Whereas plotThis has class "call", c(plotThis) has class "list"
>  > class(plotThis)
> [1] "call"
>  > class(c(plotThis))
> [1] "list"
>
>  > ## Thus, the following is possible:
>  > do.call(plot, list(1:10, main=do.call(expression, list(plotThis))))
>
>
> Marc Schwartz pointed out to me., some considerable time ago,
> that one could use bquote() and .() to create the elements of a
> list object whose elements can be plotted in parallel as required,
> e.g., for axis labels, thus:
>
>  > plot(1:2, 1:2, xaxt="n")
>  > arg1 <- bquote(""< .(x), list(x=1.5))
>  > arg2 <- bquote("">= .(x), list(x=1.5))
>  > axis(1, at=1:2, labels=do.call(expression, list(arg1, arg2)))
>
> For a unified approach to use of do.call(expression, ...), maybe
> one should use bquote() and .()?
>
>   
I think I'd prefer as.expression() in both cases:

do.call(plot, list(1:10, main=as.expression(plotThis)))

axis(1, at=1:2, labels=as.expression(list(arg1, arg2)))



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jmc at r-project.org  Thu Jul 19 15:19:36 2007
From: jmc at r-project.org (John Chambers)
Date: Thu, 19 Jul 2007 09:19:36 -0400
Subject: [Rd] S4 and Namespaces problems {was "error message from lmer"}
In-Reply-To: <Pine.LNX.4.64.0707181752001.24016@gannet.stats.ox.ac.uk>
References: <87abult2ey.fsf@patagonia.sebmags.homelinux.org>	<Pine.LNX.4.64.0706280557300.23081@gannet.stats.ox.ac.uk>	<18078.13758.396732.297757@stat.math.ethz.ch>	<469E3CB6.30505@fhcrc.org>
	<Pine.LNX.4.64.0707181752001.24016@gannet.stats.ox.ac.uk>
Message-ID: <469F64E8.9060109@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070719/f55c1e46/attachment.pl 

From ggrothendieck at gmail.com  Thu Jul 19 19:08:47 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 19 Jul 2007 13:08:47 -0400
Subject: [Rd] package NULL not found
Message-ID: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>

In performing Rcmd check I am getting this output regarding using
Argument '' and a NULL package not found and it stops with an error:

* using log directory 'C:/Rpkgs/sqldf.Rcheck'
* using ARGUMENT '
' __ignored__  R version 2.5.1 (2007-06-27)
* checking for file 'sqldf/DESCRIPTION' ... OK
* this is package 'sqldf' version '0.1-0'
* checking package dependencies ... ERROR
During startup - Warning messages:
1: there is no package called 'NULL
' in: library(package, lib.loc = lib.loc, character.only = TRUE,
logical = TRUE,
2: package NULL
 in options("defaultPackages") was not found
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

My DESCRIPTION file looks like this:

Package: sqldf
Version: 0.1-0
Date: 2007-07-19
Title: SQL on data frames.
Author: G. Grothendieck
Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
Description:  Thin layer over RSQLite and RMySQL facilitating use of
SQL selects on data frames.
Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
License: GPL (Version 3 or later)
URL: http://code.google.com/p/sqldf/

and the entire package is at (click on Source tab):

   http://code.google.com/p/sqldf/

I am using
> R.version.string # Windows XP
[1] "R version 2.5.1 (2007-06-27)"

Does anyone know what this means and how to fix it?

The package itself seems to work.  Its just getting it past Rcmd check
that is the problem.

Thanks.


From bolker at zoo.ufl.edu  Thu Jul 19 23:10:56 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu, 19 Jul 2007 17:10:56 -0400
Subject: [Rd] trivial typo in ?crimtab
Message-ID: <469FD360.4080208@zoo.ufl.edu>


 "New Scottland Yard" should be "New Scotland Yard"

  cheers
   Ben Bolker


From ggrothendieck at gmail.com  Thu Jul 19 23:55:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 19 Jul 2007 17:55:26 -0400
Subject: [Rd] package NULL not found
In-Reply-To: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>
Message-ID: <971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>

I noticed I am getting the same messages when trying to check other
packages too such as gsubfn which previously checked ok.

I had recently reinstalled cygwin so its likely something to do with
that but have not tracked it down.

On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> In performing Rcmd check I am getting this output regarding using
> Argument '' and a NULL package not found and it stops with an error:
>
> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
> * using ARGUMENT '
> ' __ignored__  R version 2.5.1 (2007-06-27)
> * checking for file 'sqldf/DESCRIPTION' ... OK
> * this is package 'sqldf' version '0.1-0'
> * checking package dependencies ... ERROR
> During startup - Warning messages:
> 1: there is no package called 'NULL
> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
> logical = TRUE,
> 2: package NULL
>  in options("defaultPackages") was not found
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
>
> My DESCRIPTION file looks like this:
>
> Package: sqldf
> Version: 0.1-0
> Date: 2007-07-19
> Title: SQL on data frames.
> Author: G. Grothendieck
> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
> Description:  Thin layer over RSQLite and RMySQL facilitating use of
> SQL selects on data frames.
> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
> License: GPL (Version 3 or later)
> URL: http://code.google.com/p/sqldf/
>
> and the entire package is at (click on Source tab):
>
>   http://code.google.com/p/sqldf/
>
> I am using
> > R.version.string # Windows XP
> [1] "R version 2.5.1 (2007-06-27)"
>
> Does anyone know what this means and how to fix it?
>
> The package itself seems to work.  Its just getting it past Rcmd check
> that is the problem.
>
> Thanks.
>


From murdoch at stats.uwo.ca  Fri Jul 20 00:36:08 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 19 Jul 2007 18:36:08 -0400
Subject: [Rd] package NULL not found
In-Reply-To: <971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>
	<971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>
Message-ID: <469FE758.10603@stats.uwo.ca>

On 19/07/2007 5:55 PM, Gabor Grothendieck wrote:
> I noticed I am getting the same messages when trying to check other
> packages too such as gsubfn which previously checked ok.
> 
> I had recently reinstalled cygwin so its likely something to do with
> that but have not tracked it down.

Another possibility may be that you have a .RData file in the check 
directory, and it is masking some important function.  This was a 
problem for me a few days ago with INSTALL; I don't know if it affects 
check.

Duncan Murdoch

> 
> On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>> In performing Rcmd check I am getting this output regarding using
>> Argument '' and a NULL package not found and it stops with an error:
>>
>> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
>> * using ARGUMENT '
>> ' __ignored__  R version 2.5.1 (2007-06-27)
>> * checking for file 'sqldf/DESCRIPTION' ... OK
>> * this is package 'sqldf' version '0.1-0'
>> * checking package dependencies ... ERROR
>> During startup - Warning messages:
>> 1: there is no package called 'NULL
>> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
>> logical = TRUE,
>> 2: package NULL
>>  in options("defaultPackages") was not found
>> See the information on DESCRIPTION files in the chapter 'Creating R
>> packages' of the 'Writing R Extensions' manual.
>>
>> My DESCRIPTION file looks like this:
>>
>> Package: sqldf
>> Version: 0.1-0
>> Date: 2007-07-19
>> Title: SQL on data frames.
>> Author: G. Grothendieck
>> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
>> Description:  Thin layer over RSQLite and RMySQL facilitating use of
>> SQL selects on data frames.
>> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
>> License: GPL (Version 3 or later)
>> URL: http://code.google.com/p/sqldf/
>>
>> and the entire package is at (click on Source tab):
>>
>>   http://code.google.com/p/sqldf/
>>
>> I am using
>>> R.version.string # Windows XP
>> [1] "R version 2.5.1 (2007-06-27)"
>>
>> Does anyone know what this means and how to fix it?
>>
>> The package itself seems to work.  Its just getting it past Rcmd check
>> that is the problem.
>>
>> Thanks.
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri Jul 20 00:50:33 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 19 Jul 2007 18:50:33 -0400
Subject: [Rd] trivial typo in ?crimtab
In-Reply-To: <469FD360.4080208@zoo.ufl.edu>
References: <469FD360.4080208@zoo.ufl.edu>
Message-ID: <469FEAB9.9030401@stats.uwo.ca>

On 19/07/2007 5:10 PM, Ben Bolker wrote:
>  "New Scottland Yard" should be "New Scotland Yard"
> 

Yes, I'll fix it. (The error is ours, it isn't in the original article.)

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Jul 20 01:16:47 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 19 Jul 2007 19:16:47 -0400
Subject: [Rd] package NULL not found
In-Reply-To: <469FE758.10603@stats.uwo.ca>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>
	<971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>
	<469FE758.10603@stats.uwo.ca>
Message-ID: <971536df0707191616s18123a76neee3eaf7b7279900@mail.gmail.com>

Thanks.  I tried performing the check from an empty directory but
it still gave the same response.  Where can I find the source code
for the check process?

* using log directory 'C:/Rpkgs/check/sqldf.Rcheck'
* using ARGUMENT '
' __ignored__  R version 2.5.1 (2007-06-27)
* checking for file 'sqldf/DESCRIPTION' ... OK
* this is package 'sqldf' version '0-1.0'
* checking package dependencies ... ERROR
During startup - Warning messages:
1: there is no package called 'NULL
' in: library(package, lib.loc = lib.loc, character.only = TRUE,
logical = TRUE,
2: package NULL
 in options("defaultPackages") was not found
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.


On 7/19/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 19/07/2007 5:55 PM, Gabor Grothendieck wrote:
> > I noticed I am getting the same messages when trying to check other
> > packages too such as gsubfn which previously checked ok.
> >
> > I had recently reinstalled cygwin so its likely something to do with
> > that but have not tracked it down.
>
> Another possibility may be that you have a .RData file in the check
> directory, and it is masking some important function.  This was a
> problem for me a few days ago with INSTALL; I don't know if it affects
> check.
>
> Duncan Murdoch
>
> >
> > On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >> In performing Rcmd check I am getting this output regarding using
> >> Argument '' and a NULL package not found and it stops with an error:
> >>
> >> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
> >> * using ARGUMENT '
> >> ' __ignored__  R version 2.5.1 (2007-06-27)
> >> * checking for file 'sqldf/DESCRIPTION' ... OK
> >> * this is package 'sqldf' version '0.1-0'
> >> * checking package dependencies ... ERROR
> >> During startup - Warning messages:
> >> 1: there is no package called 'NULL
> >> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
> >> logical = TRUE,
> >> 2: package NULL
> >>  in options("defaultPackages") was not found
> >> See the information on DESCRIPTION files in the chapter 'Creating R
> >> packages' of the 'Writing R Extensions' manual.
> >>
> >> My DESCRIPTION file looks like this:
> >>
> >> Package: sqldf
> >> Version: 0.1-0
> >> Date: 2007-07-19
> >> Title: SQL on data frames.
> >> Author: G. Grothendieck
> >> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
> >> Description:  Thin layer over RSQLite and RMySQL facilitating use of
> >> SQL selects on data frames.
> >> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
> >> License: GPL (Version 3 or later)
> >> URL: http://code.google.com/p/sqldf/
> >>
> >> and the entire package is at (click on Source tab):
> >>
> >>   http://code.google.com/p/sqldf/
> >>
> >> I am using
> >>> R.version.string # Windows XP
> >> [1] "R version 2.5.1 (2007-06-27)"
> >>
> >> Does anyone know what this means and how to fix it?
> >>
> >> The package itself seems to work.  Its just getting it past Rcmd check
> >> that is the problem.
> >>
> >> Thanks.
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Fri Jul 20 01:39:17 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 19 Jul 2007 19:39:17 -0400
Subject: [Rd] package NULL not found
In-Reply-To: <971536df0707191616s18123a76neee3eaf7b7279900@mail.gmail.com>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>	
	<971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>	
	<469FE758.10603@stats.uwo.ca>
	<971536df0707191616s18123a76neee3eaf7b7279900@mail.gmail.com>
Message-ID: <469FF625.9070602@stats.uwo.ca>

On 19/07/2007 7:16 PM, Gabor Grothendieck wrote:
> Thanks.  I tried performing the check from an empty directory but
> it still gave the same response.  Where can I find the source code
> for the check process?

On Windows the main wrapper is a Perl script in RHOME/bin/check, but 
most of the work is done by routines in the tools package.  The one that 
seems to be dying for you is tools:::.check_package_depends.

Duncan Murdoch

> 
> * using log directory 'C:/Rpkgs/check/sqldf.Rcheck'
> * using ARGUMENT '
> ' __ignored__  R version 2.5.1 (2007-06-27)
> * checking for file 'sqldf/DESCRIPTION' ... OK
> * this is package 'sqldf' version '0-1.0'
> * checking package dependencies ... ERROR
> During startup - Warning messages:
> 1: there is no package called 'NULL
> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
> logical = TRUE,
> 2: package NULL
>  in options("defaultPackages") was not found
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
> 
> 
> On 7/19/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 19/07/2007 5:55 PM, Gabor Grothendieck wrote:
>>> I noticed I am getting the same messages when trying to check other
>>> packages too such as gsubfn which previously checked ok.
>>>
>>> I had recently reinstalled cygwin so its likely something to do with
>>> that but have not tracked it down.
>> Another possibility may be that you have a .RData file in the check
>> directory, and it is masking some important function.  This was a
>> problem for me a few days ago with INSTALL; I don't know if it affects
>> check.
>>
>> Duncan Murdoch
>>
>>> On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>>> In performing Rcmd check I am getting this output regarding using
>>>> Argument '' and a NULL package not found and it stops with an error:
>>>>
>>>> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
>>>> * using ARGUMENT '
>>>> ' __ignored__  R version 2.5.1 (2007-06-27)
>>>> * checking for file 'sqldf/DESCRIPTION' ... OK
>>>> * this is package 'sqldf' version '0.1-0'
>>>> * checking package dependencies ... ERROR
>>>> During startup - Warning messages:
>>>> 1: there is no package called 'NULL
>>>> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
>>>> logical = TRUE,
>>>> 2: package NULL
>>>>  in options("defaultPackages") was not found
>>>> See the information on DESCRIPTION files in the chapter 'Creating R
>>>> packages' of the 'Writing R Extensions' manual.
>>>>
>>>> My DESCRIPTION file looks like this:
>>>>
>>>> Package: sqldf
>>>> Version: 0.1-0
>>>> Date: 2007-07-19
>>>> Title: SQL on data frames.
>>>> Author: G. Grothendieck
>>>> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
>>>> Description:  Thin layer over RSQLite and RMySQL facilitating use of
>>>> SQL selects on data frames.
>>>> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
>>>> License: GPL (Version 3 or later)
>>>> URL: http://code.google.com/p/sqldf/
>>>>
>>>> and the entire package is at (click on Source tab):
>>>>
>>>>   http://code.google.com/p/sqldf/
>>>>
>>>> I am using
>>>>> R.version.string # Windows XP
>>>> [1] "R version 2.5.1 (2007-06-27)"
>>>>
>>>> Does anyone know what this means and how to fix it?
>>>>
>>>> The package itself seems to work.  Its just getting it past Rcmd check
>>>> that is the problem.
>>>>
>>>> Thanks.
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ggrothendieck at gmail.com  Fri Jul 20 07:42:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 20 Jul 2007 01:42:31 -0400
Subject: [Rd] package NULL not found
In-Reply-To: <469FF625.9070602@stats.uwo.ca>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com>
	<971536df0707191455oe52768fm302f43e923557642@mail.gmail.com>
	<469FE758.10603@stats.uwo.ca>
	<971536df0707191616s18123a76neee3eaf7b7279900@mail.gmail.com>
	<469FF625.9070602@stats.uwo.ca>
Message-ID: <971536df0707192242x3e91a8f2t2a84d6b4f169b27b@mail.gmail.com>

It turned out that when I reinstalled cygwin I put it first on the path
and its not supposed to be.

I wonder if R build tools could check for this by running a cygwin
program that is also in Rtools and if one gets the cygwin output
rather than the Rtools output it could warn the user to change his
path.  I found it quite difficult to solve this problem.

On 7/19/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 19/07/2007 7:16 PM, Gabor Grothendieck wrote:
> > Thanks.  I tried performing the check from an empty directory but
> > it still gave the same response.  Where can I find the source code
> > for the check process?
>
> On Windows the main wrapper is a Perl script in RHOME/bin/check, but
> most of the work is done by routines in the tools package.  The one that
> seems to be dying for you is tools:::.check_package_depends.
>
> Duncan Murdoch
>
> >
> > * using log directory 'C:/Rpkgs/check/sqldf.Rcheck'
> > * using ARGUMENT '
> > ' __ignored__  R version 2.5.1 (2007-06-27)
> > * checking for file 'sqldf/DESCRIPTION' ... OK
> > * this is package 'sqldf' version '0-1.0'
> > * checking package dependencies ... ERROR
> > During startup - Warning messages:
> > 1: there is no package called 'NULL
> > ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
> > logical = TRUE,
> > 2: package NULL
> >  in options("defaultPackages") was not found
> > See the information on DESCRIPTION files in the chapter 'Creating R
> > packages' of the 'Writing R Extensions' manual.
> >
> >
> > On 7/19/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 19/07/2007 5:55 PM, Gabor Grothendieck wrote:
> >>> I noticed I am getting the same messages when trying to check other
> >>> packages too such as gsubfn which previously checked ok.
> >>>
> >>> I had recently reinstalled cygwin so its likely something to do with
> >>> that but have not tracked it down.
> >> Another possibility may be that you have a .RData file in the check
> >> directory, and it is masking some important function.  This was a
> >> problem for me a few days ago with INSTALL; I don't know if it affects
> >> check.
> >>
> >> Duncan Murdoch
> >>
> >>> On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >>>> In performing Rcmd check I am getting this output regarding using
> >>>> Argument '' and a NULL package not found and it stops with an error:
> >>>>
> >>>> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
> >>>> * using ARGUMENT '
> >>>> ' __ignored__  R version 2.5.1 (2007-06-27)
> >>>> * checking for file 'sqldf/DESCRIPTION' ... OK
> >>>> * this is package 'sqldf' version '0.1-0'
> >>>> * checking package dependencies ... ERROR
> >>>> During startup - Warning messages:
> >>>> 1: there is no package called 'NULL
> >>>> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
> >>>> logical = TRUE,
> >>>> 2: package NULL
> >>>>  in options("defaultPackages") was not found
> >>>> See the information on DESCRIPTION files in the chapter 'Creating R
> >>>> packages' of the 'Writing R Extensions' manual.
> >>>>
> >>>> My DESCRIPTION file looks like this:
> >>>>
> >>>> Package: sqldf
> >>>> Version: 0.1-0
> >>>> Date: 2007-07-19
> >>>> Title: SQL on data frames.
> >>>> Author: G. Grothendieck
> >>>> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
> >>>> Description:  Thin layer over RSQLite and RMySQL facilitating use of
> >>>> SQL selects on data frames.
> >>>> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
> >>>> License: GPL (Version 3 or later)
> >>>> URL: http://code.google.com/p/sqldf/
> >>>>
> >>>> and the entire package is at (click on Source tab):
> >>>>
> >>>>   http://code.google.com/p/sqldf/
> >>>>
> >>>> I am using
> >>>>> R.version.string # Windows XP
> >>>> [1] "R version 2.5.1 (2007-06-27)"
> >>>>
> >>>> Does anyone know what this means and how to fix it?
> >>>>
> >>>> The package itself seems to work.  Its just getting it past Rcmd check
> >>>> that is the problem.
> >>>>
> >>>> Thanks.
> >>>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>
>


From ripley at stats.ox.ac.uk  Fri Jul 20 13:17:19 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jul 2007 12:17:19 +0100 (BST)
Subject: [Rd] package NULL not found
In-Reply-To: <469FF625.9070602@stats.uwo.ca>
References: <971536df0707191008x6262867p18b615ac7960388b@mail.gmail.com> 
	<971536df0707191455oe52768fm302f43e923557642@mail.gmail.com> 
	<469FE758.10603@stats.uwo.ca>
	<971536df0707191616s18123a76neee3eaf7b7279900@mail.gmail.com>
	<469FF625.9070602@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0707201148450.25309@gannet.stats.ox.ac.uk>

Note that the message is not about '' and NULL but about '<nl>' 
and NULL<nl>.

I suspect the line endings are screwed up in the environment in use, which 
seems not to be our toolset from the comments about Cygwin.  It is most 
likely the shell used by make that is doing this, but it could be Perl.

I can reproduce this on Linux by

gannet% setenv R_DEFAULT_PACKAGES 'NULL\ 
'
gannet% Rdev --slave
During startup - Warning messages:
1: In library(package, lib.loc = lib.loc, character.only = TRUE, 
logical.return = TRUE,  :
   there is no package called 'NULL
'
2: package NULL
  in options("defaultPackages") was not found



On Thu, 19 Jul 2007, Duncan Murdoch wrote:

> On 19/07/2007 7:16 PM, Gabor Grothendieck wrote:
>> Thanks.  I tried performing the check from an empty directory but
>> it still gave the same response.  Where can I find the source code
>> for the check process?
>
> On Windows the main wrapper is a Perl script in RHOME/bin/check, but
> most of the work is done by routines in the tools package.  The one that
> seems to be dying for you is tools:::.check_package_depends.

It is what is getting passed to Rterm that seems to be the problem.

>
> Duncan Murdoch
>
>>
>> * using log directory 'C:/Rpkgs/check/sqldf.Rcheck'
>> * using ARGUMENT '
>> ' __ignored__  R version 2.5.1 (2007-06-27)
>> * checking for file 'sqldf/DESCRIPTION' ... OK
>> * this is package 'sqldf' version '0-1.0'
>> * checking package dependencies ... ERROR
>> During startup - Warning messages:
>> 1: there is no package called 'NULL
>> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
>> logical = TRUE,
>> 2: package NULL
>>  in options("defaultPackages") was not found
>> See the information on DESCRIPTION files in the chapter 'Creating R
>> packages' of the 'Writing R Extensions' manual.
>>
>>
>> On 7/19/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>> On 19/07/2007 5:55 PM, Gabor Grothendieck wrote:
>>>> I noticed I am getting the same messages when trying to check other
>>>> packages too such as gsubfn which previously checked ok.
>>>>
>>>> I had recently reinstalled cygwin so its likely something to do with
>>>> that but have not tracked it down.
>>> Another possibility may be that you have a .RData file in the check
>>> directory, and it is masking some important function.  This was a
>>> problem for me a few days ago with INSTALL; I don't know if it affects
>>> check.
>>>
>>> Duncan Murdoch
>>>
>>>> On 7/19/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>>>> In performing Rcmd check I am getting this output regarding using
>>>>> Argument '' and a NULL package not found and it stops with an error:
>>>>>
>>>>> * using log directory 'C:/Rpkgs/sqldf.Rcheck'
>>>>> * using ARGUMENT '
>>>>> ' __ignored__  R version 2.5.1 (2007-06-27)
>>>>> * checking for file 'sqldf/DESCRIPTION' ... OK
>>>>> * this is package 'sqldf' version '0.1-0'
>>>>> * checking package dependencies ... ERROR
>>>>> During startup - Warning messages:
>>>>> 1: there is no package called 'NULL
>>>>> ' in: library(package, lib.loc = lib.loc, character.only = TRUE,
>>>>> logical = TRUE,
>>>>> 2: package NULL
>>>>>  in options("defaultPackages") was not found
>>>>> See the information on DESCRIPTION files in the chapter 'Creating R
>>>>> packages' of the 'Writing R Extensions' manual.
>>>>>
>>>>> My DESCRIPTION file looks like this:
>>>>>
>>>>> Package: sqldf
>>>>> Version: 0.1-0
>>>>> Date: 2007-07-19
>>>>> Title: SQL on data frames.
>>>>> Author: G. Grothendieck
>>>>> Maintainer: G. Grothendieck <ggrothendieck at gmail.com>
>>>>> Description:  Thin layer over RSQLite and RMySQL facilitating use of
>>>>> SQL selects on data frames.
>>>>> Depends: R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn
>>>>> License: GPL (Version 3 or later)
>>>>> URL: http://code.google.com/p/sqldf/
>>>>>
>>>>> and the entire package is at (click on Source tab):
>>>>>
>>>>>   http://code.google.com/p/sqldf/
>>>>>
>>>>> I am using
>>>>>> R.version.string # Windows XP
>>>>> [1] "R version 2.5.1 (2007-06-27)"
>>>>>
>>>>> Does anyone know what this means and how to fix it?
>>>>>
>>>>> The package itself seems to work.  Its just getting it past Rcmd check
>>>>> that is the problem.
>>>>>
>>>>> Thanks.
>>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Kurt.Hornik at wu-wien.ac.at  Fri Jul 20 20:14:16 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 20 Jul 2007 20:14:16 +0200
Subject: [Rd] possible bug R CMD check: No space(s) allowed
	after	\VignetteDepends{}
In-Reply-To: <e77aa48a0707181511l138ff5bapd82a197bdd105f2a@mail.gmail.com>
References: <e77aa48a0707181511l138ff5bapd82a197bdd105f2a@mail.gmail.com>
Message-ID: <18080.64376.524791.482336@mithrandir.hornik.net>

>>>>> Ferdinand Alimadhi writes:

> R CMD check gives an error when a vignette entry %\VignetteDepends{} has any
> extra space at the end.
> Maybe this is by design, but I found it confusing.

Actually, this is by design, but I'll look into changing it.

Best
-k

> Changing the function "vignetteMetaRE" in tools package could solve the
> problem. I.e.

> vignetteMetaRE <- function(tag)
>     paste("[[:space:]]*%+[[:space:]]*\\\\Vignette", tag,"\\{([^}]*)\\}", sep
> = "")

> becomes:

> vignetteMetaRE <- function(tag)
>     paste("[[:space:]]*%+[[:space:]]*\\\\Vignette",
> tag,"\\{([^}]*)\\}[[:space:]]*", sep = "")



> Details:

> The test package I'm using has only one vignette:

> \documentclass[oneside,letterpaper,12pt]{book}
> %\VignetteIndexEntry{some entry}
> %\VignetteDepends{stats}
> %\VignetteKeyWords{mymodel}
> %\VignettePackage{testpkg}
> \begin{document}
> <<test>>=
> print("test")
> @
> \end{document}

> R CMD build, R CMD check and R CMD INSTALL run successfully.

> If I add an extra space after %\VignetteDepends{stats} then "R CMD check"
> fails

> w5:falimadh [~/work/mypkg]> R CMD check testpkg
> * checking for working latex ... OK
> * using log directory '/nfs/fs1/home/F/falimadh/work/mypkg/testpkg.Rcheck'
> * using R version 2.5.1 (2007-06-27)
> * checking for file 'testpkg/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'testpkg' version '1.0'
> * checking package dependencies ... ERROR
> Vignette dependencies not required:
>   stats
> Vignette dependencies (\VignetteDepends{} entries) must be contained in
> the DESCRIPTION Depends/Suggests/Imports entries.

> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
> ----------------------------------------------------------------------

> The error message is from tools:::.check_package_depends() function
> which is used by R CMD check.
> check_package_depends() calls .build_vignette_index() to get the vignettes
> dependency list
> For my test package, the result is:

>> reqs <-
> unique(unlist(tools:::.build_vignette_index("testpkg/inst/doc/")$Depends))
>> reqs
> [1] "stats "
>> 

> "stats " (with a space at the end) is not in the depend field of my package
> description ("stat" is). And that's where the error comes from.


> Does this make sense ?

> Thanks,
> Ferdi


>> R.Version()
> $platform
> [1] "x86_64-redhat-linux-gnu"

> $arch
> [1] "x86_64"

> $os
> [1] "linux-gnu"

> $system
> [1] "x86_64, linux-gnu"

> $status
> [1] ""

> $major
> [1] "2"

> $minor
> [1] "5.1"

> $year
> [1] "2007"

> $month
> [1] "06"

> $day
> [1] "27"

> $`svn rev`
> [1] "42083"

> $language
> [1] "R"

> $version.string
> [1] "R version 2.5.1 (2007-06-27)"

>> 

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jonathan.zhou at utoronto.ca  Fri Jul 20 22:48:43 2007
From: jonathan.zhou at utoronto.ca (Ctagz)
Date: Fri, 20 Jul 2007 13:48:43 -0700 (PDT)
Subject: [Rd] unable to load shared library: undefined symbol
Message-ID: <11713874.post@talk.nabble.com>


Hi all, 

I'm a summer University research student and I've been wroking on writing a
package, Rsoam, to integrate R with Platform's symphony software to allow
for distributed computing.  When I "R CMD check" the package, I get the
following error when trying to load the Rsoam.so after building Rsoam.cpp: 

* checking whether the package can be loaded ... ERROR
Loading required package: snow
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library '/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so':
  /root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so: undefined symbol:
_ZTIN4soam13SoamExceptionE
Error in library(Rsoam) : .First.lib failed for 'Rsoam'
Error in dyn.unload(x) : dynamic/shared library
'/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so' was not loaded

            My Makevars file consists of: 

PKG_CPPFLAGS = -I/opt/symphonyDE/3.1/src -I/opt/symphonyDE/3.1/include
-DGCC34 -Wall -DLINUX -Wno-deprecated
PKG_LIBS = -L/opt/symphonyDE/3.1/src -L/opt/symphonyDE/3.1/include
-L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
-Lsoamapi

            and 00install.out has the following g++ build: 

g++ -I/usr/lib/R/include -I/usr/lib/R/include -I/opt/symphonyDE/3.1/src
-I/opt/symphonyDE/3.1/include -DGCC34 -Wall -DLINUX -Wno-deprecated
-I/usr/local/include    -fpic  -O2 -g -c Rsoam9.cpp -o Rsoam9.o
g++ -shared -Wl,-O1 -o Rsoam.so Rsoam9.o -L/opt/symphonyDE/3.1/src
-L/opt/symphonyDE/3.1/include
-L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
-Lsoamapi  -L/usr/lib/R/lib -lR

I thought I'd written the Makevars to a sufficient degree, but I guess that
may not actually be the case.  I understand that you guys are probably not
familiar with symphony, but I was hoping if someone could tell me what slips
through when I'm building this shared library?

-Jon
-- 
View this message in context: http://www.nabble.com/unable-to-load-shared-library%3A-undefined-symbol-tf4118911.html#a11713874
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Sat Jul 21 10:04:03 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Jul 2007 09:04:03 +0100 (BST)
Subject: [Rd] unable to load shared library: undefined symbol
In-Reply-To: <11713874.post@talk.nabble.com>
References: <11713874.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0707210855110.25332@gannet.stats.ox.ac.uk>

This is nothing to do with R: you need to seek help from whoever you are 
'wroking' for.

You don't have any libraries on your link command, but you do have include 
directories: please get your supervisor to explain how linking works and 
what to do to link against 'symphony'.  (Are you confusing -L and -l?)

On Fri, 20 Jul 2007, Ctagz wrote:

>
> Hi all,
>
> I'm a summer University research student and I've been wroking on writing a
> package, Rsoam, to integrate R with Platform's symphony software to allow
> for distributed computing.  When I "R CMD check" the package, I get the
> following error when trying to load the Rsoam.so after building Rsoam.cpp:
>
> * checking whether the package can be loaded ... ERROR
> Loading required package: snow
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
> 	unable to load shared library '/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so':
>  /root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so: undefined symbol:
> _ZTIN4soam13SoamExceptionE
> Error in library(Rsoam) : .First.lib failed for 'Rsoam'
> Error in dyn.unload(x) : dynamic/shared library
> '/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so' was not loaded
>
>            My Makevars file consists of:
>
> PKG_CPPFLAGS = -I/opt/symphonyDE/3.1/src -I/opt/symphonyDE/3.1/include
> -DGCC34 -Wall -DLINUX -Wno-deprecated
> PKG_LIBS = -L/opt/symphonyDE/3.1/src -L/opt/symphonyDE/3.1/include
> -L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
> -Lsoamapi
>
>            and 00install.out has the following g++ build:
>
> g++ -I/usr/lib/R/include -I/usr/lib/R/include -I/opt/symphonyDE/3.1/src
> -I/opt/symphonyDE/3.1/include -DGCC34 -Wall -DLINUX -Wno-deprecated
> -I/usr/local/include    -fpic  -O2 -g -c Rsoam9.cpp -o Rsoam9.o
> g++ -shared -Wl,-O1 -o Rsoam.so Rsoam9.o -L/opt/symphonyDE/3.1/src
> -L/opt/symphonyDE/3.1/include
> -L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
> -Lsoamapi  -L/usr/lib/R/lib -lR
>
> I thought I'd written the Makevars to a sufficient degree, but I guess that
> may not actually be the case.  I understand that you guys are probably not
> familiar with symphony, but I was hoping if someone could tell me what slips
> through when I'm building this shared library?
>
> -Jon
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andreas.plank at web.de  Thu Jul 19 16:07:50 2007
From: andreas.plank at web.de (Andreas Plank)
Date: Thu, 19 Jul 2007 16:07:50 +0200
Subject: [Rd] triax.points() from package plotrix
Message-ID: <1184854071.4975.10.camel@chironomus.local>

Dear developers from package plotrix,

the function triax.points() from package plotrix does not draw any
points, because of internal setting in triax.points() {points(...,
type="l")}. 
I add a new option in triax.points() 
	point.type = "l", 
So the user can choose which type of points should be drawn.
May be other users already found this defect.

best whishes
Andreas Plank

####--- 8< ----#######
triax.points <- function (x,
  show.legend = FALSE,
  label.points = FALSE,
  point.labels = NULL,
  col.symbols = par("fg"),
  pch = par("pch"),
  bg.symbols = par("bg"),
  cc.axes = FALSE,
  point.type = "l", # new add
   ...
  )
{
    if (dev.cur() == 1)
        stop("Cannot add points unless the triax.frame has been drawn")
    if (missing(x))
        stop("Usage: triax.points(x,...)\n\twhere x is a 3 column array
of proportions or percentages")
    if (!is.matrix(x) && !is.data.frame(x))
        stop("x must be a matrix or data frame with at least 3 columns
and one row.")
    if (any(x > 1) || any(x < 0)) {
        if (any(x < 0))
            stop("All proportions must be between zero and one.")
        if (any(x > 100))
            stop("All percentages must be between zero and 100.")
        x <- x/100
    }
    if (any(abs(rowSums(x) - 1) > 0.01))
        warning("At least one set of proportions does not equal one.")
    sin60 <- sin(pi/3)
    if (cc.axes) {
        ypos <- x[, 3] * sin60
        xpos <- x[, 1] + x[, 3] * 0.5
    }
    else {
        ypos <- x[, 3] * sin60
        xpos <- 1 - (x[, 1] + x[, 3] * 0.5)
    }
    nobs <- dim(x)[1]
    if (is.null(point.labels))
        point.labels <- rownames(x)
    if (label.points)
        thigmophobe.labels(xpos, ypos, point.labels)
    if (show.legend) {
        legend(0.16 - 0.02 * max(nchar(point.labels)), 0.75 +
            0.04 * length(point.labels), legend = point.labels,
            pch = pch, col = col.symbols)
    }
    points(x = xpos, y = ypos, pch = pch, col = col.symbols,
        bg = bg.symbols, type = point.type, ...)
    invisible(list(x = xpos, y = ypos))
}


From jonathan.zhou at utoronto.ca  Fri Jul 20 20:50:28 2007
From: jonathan.zhou at utoronto.ca (Ctagz)
Date: Fri, 20 Jul 2007 11:50:28 -0700 (PDT)
Subject: [Rd] unable to load shared library: undefined symbol
Message-ID: <11713874.post@talk.nabble.com>


Hi all, 

I'm a summer University research student and I've been wroking on writing a
package, Rsoam, to integrate R with Platform's symphony software to allow
for distributed computing.  When I "R CMD check" the package, I get the
following error when trying to load the Rsoam.so after building Rsoam.cpp: 

* checking whether the package can be loaded ... ERROR
Loading required package: snow
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library '/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so':
  /root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so: undefined symbol:
_ZTIN4soam13SoamExceptionE
Error in library(Rsoam) : .First.lib failed for 'Rsoam'
Error in dyn.unload(x) : dynamic/shared library
'/root/Rsoam.Rcheck/Rsoam/libs/Rsoam.so' was not loaded

            My Makevars file consists of: 

PKG_CPPFLAGS = -I/opt/symphonyDE/3.1/src -I/opt/symphonyDE/3.1/include
-DGCC34 -Wall -DLINUX -Wno-deprecated
PKG_LIBS = -L/opt/symphonyDE/3.1/src -L/opt/symphonyDE/3.1/include
-L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
-Lsoamapi

            and 00install.out has the following g++ build: 

g++ -I/usr/lib/R/include -I/usr/lib/R/include -I/opt/symphonyDE/3.1/src
-I/opt/symphonyDE/3.1/include -DGCC34 -Wall -DLINUX -Wno-deprecated
-I/usr/local/include    -fpic  -O2 -g -c Rsoam9.cpp -o Rsoam9.o
g++ -shared -Wl,-O1 -o Rsoam.so Rsoam9.o -L/opt/symphonyDE/3.1/src
-L/opt/symphonyDE/3.1/include
-L/opt/symphonyDE/3.1/linux2.6-glibc2.3-x86/lib -LsampleCommon -Lsoambase
-Lsoamapi  -L/usr/lib/R/lib -lR

I thought I'd written the Makevars to a sufficient degree, but I guess that
may not actually be the case.  I understand that you guys are probably not
familiar with symphony, but I was hoping if someone could tell me what slips
through when I'm building this shared library?

-Jon
-- 
View this message in context: http://www.nabble.com/unable-to-load-shared-library%3A-undefined-symbol-tf4118911.html#a11713874
Sent from the R devel mailing list archive at Nabble.com.


From Dietrich.Trenkler at uni-osnabrueck.de  Fri Jul 20 12:57:34 2007
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich.Trenkler at uni-osnabrueck.de)
Date: Fri, 20 Jul 2007 12:57:34 +0200 (CEST)
Subject: [Rd] Bug in dev.print ? (PR#9801)
Message-ID: <20070720105734.8B43C667DE@slim.kubism.ku.dk>

Ladies and Gentlemen,

the following piece of code causes an annoying error:


 > aa <- structure(list(BG = c(24, 16, 61, 30, 37, 33, 13, 4, -34,
+     10, 33, 41, 6, 32, 39, 37, 36, -17, 60, 35, 22, 21, 29, 52,
+     41, 62, -26, 30, -33, 27, 34, 28, 36, 29, -12, 38, 34, 32,
+     40, 36, 39, 31, 19, 55, 28, 40, 38, 39, -31, 64, -22, 41,
+     37, -33, 18, 31, 1, -33, 28, 36, -22), Kont = c(4, 7, 3,
+     4, 6, 3, 4, 7, 7, 7, 2, 3, 4, 3, 3, 6, 3, 2, 6, 6, 4, 3,
+     3, 4, 6, 4, 2, 1, 2, 4, 6, 6, 3, 4, 7, 6, 3, 6, 6, 6, 6,
+     2, 7, 6, 4, 3, 6, 4, 5, 6, 7, 6, 3, 7, 7, 4, 4, 5, 6, 2,
+     2), Jan = c(25, 31, -4, 15, 13, 12, 32, 20, 30, 30, 18, 1,
+     30, 15, 8, 16, 7, 27, -3, 15, 20, 26, 18, -15, 8, -36, 25,
+     19, 27, 18, 17, 21, 15, 9, 25, 14, 19, 19, 11, 17, 15, 18,
+     21, -3, 19, 4, 14, 2, 32, 2, 29, 12, 13, 29, 30, 8, 30, 26,
+     21, 15, 31), Feb = c(28, 31, -1, 16, 14, 14, 33, 19, 28,
+     29, 18, 2, 32, 16, 7, 17, 8, 26, -3, 15, 21, 26, 20, -9,
+     9, -29, 25, 21, 28, 21, 18, 21, 16, 10, 27, 16, 18, 18, 13,
+     18, 15, 21, 23, -4, 24, 5, 15, 6, 30, 2, 30, 13, 15, 26,
+     30, 11, 31, 28, 21, 17, 30), Mrz = c(30, 31, -1, 19, 17,
+     19, 35, 19, 26, 30, 20, 9, 32, 21, 14, 19, 12, 27, 2, 18,
+     23, 26, 23, 1, 12, -10, 24, 23, 27, 25, 20, 23, 23, 13, 26,
+     18, 19, 20, 16, 19, 18, 24, 25, 3, 30, 9, 17, 12, 32, 4,
+     30, 15, 17, 26, 30, 14, 32, 25, 23, 20, 29), Apr = c(35,
+     31, 5, 21, 20, 23, 36, 19, 22, 30, 20, 16, 32, 25, 15, 21,
+     14, 26, 9, 20, 26, 28, 26, 7, 16, 3, 22, 27, 24, 28, 22,
+     23, 25, 16, 24, 20, 19, 20, 18, 22, 20, 24, 27, 12, 37, 14,
+     20, 21, 25, 6, 29, 18, 17, 23, 30, 18, 32, 23, 23, 22, 26),
+     Mai = c(40, 32, 12, 27, 26, 26, 34, 19, 18, 31, 22, 21, 32,
+         29, 22, 23, 22, 24, 16, 24, 30, 28, 30, 16, 22, 13, 19,
+         32, 20, 27, 27, 24, 33, 20, 21, 22, 21, 21, 23, 25, 25,
+         29, 26, 19, 40, 21, 24, 27, 23, 9, 26, 24, 20, 19, 31,
+         24, 32, 20, 24, 28, 24), Jun = c(41, 32, 17, 33, 30,
+         29, 34, 18, 16, 31, 25, 26, 31, 32, 27, 26, 28, 20, 20,
+         27, 32, 29, 32, 23, 27, 21, 17, 35, 18, 29, 31, 26, 38,
+         23, 18, 27, 22, 23, 31, 29, 29, 34, 25, 23, 39, 28, 28,
+         30, 19, 12, 26, 28, 22, 15, 31, 27, 31, 17, 25, 32, 22),
+     Jul = c(42, 33, 19, 35, 33, 30, 34, 18, 14, 32, 26, 29, 31,
+         36, 32, 29, 28, 21, 24, 30, 33, 30, 34, 23, 30, 26, 17,
+         35, 18, 28, 33, 27, 39, 22, 19, 29, 25, 25, 34, 32, 32,
+         37, 24, 25, 36, 29, 30, 32, 18, 14, 25, 29, 22, 15, 32,
+         32, 31, 17, 28, 34, 21), Aug = c(43, 33, 17, 35, 33,
+         31, 34, 18, 16, 32, 27, 28, 30, 35, 30, 29, 26, 23, 21,
+         30, 32, 31, 34, 20, 29, 21, 20, 35, 18, 28, 33, 28, 39,
+         21, 18, 30, 25, 26, 33, 31, 32, 37, 24, 22, 34, 29, 29,
+         31, 19, 14, 26, 29, 22, 17, 32, 31, 31, 19, 28, 34, 24),
+     Sep = c(43, 33, 13, 32, 29, 28, 33, 18, 19, 33, 26, 25, 31,
+         32, 26, 26, 24, 28, 17, 27, 31, 30, 32, 16, 25, 11, 23,
+         34, 19, 28, 31, 28, 34, 20, 19, 28, 25, 26, 28, 28, 29,
+         33, 23, 17, 35, 24, 27, 27, 20, 11, 26, 26, 24, 18, 32,
+         29, 31, 22, 28, 29, 28), Okt = c(37, 32, 5, 27, 24, 23,
+         32, 18, 21, 32, 24, 17, 31, 25, 17, 23, 17, 29, 9, 24,
+         29, 29, 27, 5, 20, -5, 25, 29, 21, 26, 27, 26, 27, 17,
+         20, 22, 22, 24, 21, 24, 25, 28, 23, 9, 33, 18, 25, 19,
+         22, 6, 27, 22, 21, 22, 32, 23, 32, 21, 27, 27, 31), Nov = c(31,
+         32, -2, 21, 18, 18, 32, 19, 25, 32, 21, 10, 31, 19, 11,
+         19, 11, 27, 2, 20, 26, 28, 21, -5, 15, -24, 25, 25, 25,
+         23, 23, 25, 19, 12, 22, 17, 21, 21, 13, 20, 18, 23, 22,
+         0, 28, 13, 19, 10, 28, 4, 27, 17, 17, 26, 31, 17, 31,
+         23, 25, 20, 31), Dez = c(27, 32, -4, 16, 14, 11, 31,
+         19, 29, 30, 19, 2, 31, 14, 7, 17, 7, 27, 0, 16, 22, 27,
+         16, -13, 10, -35, 25, 20, 26, 21, 18, 22, 14, 9, 23,
+         14, 19, 20, 11, 17, 16, 20, 22, -3, 23, 6, 17, 3, 30,
+         3, 29, 14, 15, 29, 31, 10, 30, 26, 23, 18, 33)), .Names = c("BG",
+     "Kont", "Jan", "Feb", "Mrz", "Apr", "Mai", "Jun", "Jul",
+     "Aug", "Sep", "Okt", "Nov", "Dez"), row.names = c("Abu 
Dhabi             ",
+     "Acapulco              ", "Anchorage             ", 
"Antalya               ",
+     "Athen                 ", "Atlanta               ", 
"Bangkok               ",
+     "Bogota                ", "BuenosAires           ", 
"Caracas               ",
+     "Casablanca            ", "Chicago               ", 
"ColomboSriLanka       ",
+     "Dallas                ", "Denver                ", 
"FaroAlgarve           ",
+     "GrandCanyonArizona    ", "Harare                ", 
"Helsinki              ",
+     "HeraklionKreta        ", "Hongkong              ", 
"Honolulu              ",
+     "Houston               ", "Irkutsk               ", 
"Istanbul              ",
+     "JakutskNordostsibirien", "Johannesburg          ", 
"Kairo                 ",
+     "Kapstadt              ", "Kathmandu             ", 
"LarnakaZypern         ",
+     "Las Palmas            ", "Las Vegas             ", 
"Lhasa                 ",
+     "Lima                  ", "Lissabon              ", "Los 
Angeles           ",
+     "Madeira               ", "Madrid                ", 
"Malaga                ",
+     "Mallorca              ", "Marrakesch            ", "Mexico 
City           ",
+     "Moskau                ", "Neu Delhi             ", "New 
York              ",
+     "Palermo               ", "PekingBeijing         ", 
"PerthAustralien       ",
+     "Reykjavik             ", "RioDeJaneiro          ", 
"Rom                   ",
+     "SanFrancisco          ", "SantiagoDeChile       ", 
"SantoDomingoKaribik   ",
+     "Shanghai              ", "Singapur              ", 
"SydneyAustralien      ",
+     "Teneriffa             ", "Tunis                 ", 
"Windhoek              "),
+     class = "data.frame")
 >
 > attach(aa)
 > par(mfrow=c(4,3))
 > m 
<-c("Januar","Februar","M?rz","April","Mai","Juni","Juli","August","September","Oktober","November","Dezember")
 > for(i in 1:12)
+ 
plot(BG,aa[,i+2],main=m[i],xlab="Breitengrad",ylab="Temperatur",ylim=c(-35,35))
 > dev.print(device = postscript, 
width=4,height=5,horizontal=TRUE,file="c://test.ps")
windows
      2
 > # That's fine
 > # Here comes the error
 > dev.print(device = postscript, width=5 
,height=4,horizontal=TRUE,file="c://test.ps")
Error in dev.copy(device = function (file = ifelse(onefile, "Rplots.ps",  :
        invalid graphics state
 > # From now on plotting is impossible:
 > plot(1:2)
Error in plot.new() : figure margins too large
 > # As a "remedy" I restart R



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 5.0
 year = 2007
 month = 04
 day = 23
 svn rev = 41293
 language = R
 version.string = R version 2.5.0 (2007-04-23)

Windows XP (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, aa, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:methods, Autoloads, package:base


-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de


From p.dalgaard at biostat.ku.dk  Sat Jul 21 11:47:03 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 21 Jul 2007 11:47:03 +0200
Subject: [Rd] Bug in dev.print ? (PR#9801)
In-Reply-To: <20070720105734.8B43C667DE@slim.kubism.ku.dk>
References: <20070720105734.8B43C667DE@slim.kubism.ku.dk>
Message-ID: <46A1D617.80901@biostat.ku.dk>

Dietrich.Trenkler at uni-osnabrueck.de wrote:
> Ladies and Gentlemen,
>
> the following piece of code causes an annoying error:
>
>
>  > aa <- structure(list(BG = c(24, 16, 61, 30, 37, 33, 13, 4, -34,
> +     10, 33, 41, 6, 32, 39, 37, 36, -17, 60, 35, 22, 21, 29, 52,
> +     41, 62, -26, 30, -33, 27, 34, 28, 36, 29, -12, 38, 34, 32,
> +     40, 36, 39, 31, 19, 55, 28, 40, 38, 39, -31, 64, -22, 41,
> +     37, -33, 18, 31, 1, -33, 28, 36, -22), Kont = c(4, 7, 3,
> +     4, 6, 3, 4, 7, 7, 7, 2, 3, 4, 3, 3, 6, 3, 2, 6, 6, 4, 3,
> +     3, 4, 6, 4, 2, 1, 2, 4, 6, 6, 3, 4, 7, 6, 3, 6, 6, 6, 6,
> +     2, 7, 6, 4, 3, 6, 4, 5, 6, 7, 6, 3, 7, 7, 4, 4, 5, 6, 2,
> +     2), Jan = c(25, 31, -4, 15, 13, 12, 32, 20, 30, 30, 18, 1,
> +     30, 15, 8, 16, 7, 27, -3, 15, 20, 26, 18, -15, 8, -36, 25,
> +     19, 27, 18, 17, 21, 15, 9, 25, 14, 19, 19, 11, 17, 15, 18,
> +     21, -3, 19, 4, 14, 2, 32, 2, 29, 12, 13, 29, 30, 8, 30, 26,
> +     21, 15, 31), Feb = c(28, 31, -1, 16, 14, 14, 33, 19, 28,
> +     29, 18, 2, 32, 16, 7, 17, 8, 26, -3, 15, 21, 26, 20, -9,
> +     9, -29, 25, 21, 28, 21, 18, 21, 16, 10, 27, 16, 18, 18, 13,
> +     18, 15, 21, 23, -4, 24, 5, 15, 6, 30, 2, 30, 13, 15, 26,
> +     30, 11, 31, 28, 21, 17, 30), Mrz = c(30, 31, -1, 19, 17,
> +     19, 35, 19, 26, 30, 20, 9, 32, 21, 14, 19, 12, 27, 2, 18,
> +     23, 26, 23, 1, 12, -10, 24, 23, 27, 25, 20, 23, 23, 13, 26,
> +     18, 19, 20, 16, 19, 18, 24, 25, 3, 30, 9, 17, 12, 32, 4,
> +     30, 15, 17, 26, 30, 14, 32, 25, 23, 20, 29), Apr = c(35,
> +     31, 5, 21, 20, 23, 36, 19, 22, 30, 20, 16, 32, 25, 15, 21,
> +     14, 26, 9, 20, 26, 28, 26, 7, 16, 3, 22, 27, 24, 28, 22,
> +     23, 25, 16, 24, 20, 19, 20, 18, 22, 20, 24, 27, 12, 37, 14,
> +     20, 21, 25, 6, 29, 18, 17, 23, 30, 18, 32, 23, 23, 22, 26),
> +     Mai = c(40, 32, 12, 27, 26, 26, 34, 19, 18, 31, 22, 21, 32,
> +         29, 22, 23, 22, 24, 16, 24, 30, 28, 30, 16, 22, 13, 19,
> +         32, 20, 27, 27, 24, 33, 20, 21, 22, 21, 21, 23, 25, 25,
> +         29, 26, 19, 40, 21, 24, 27, 23, 9, 26, 24, 20, 19, 31,
> +         24, 32, 20, 24, 28, 24), Jun = c(41, 32, 17, 33, 30,
> +         29, 34, 18, 16, 31, 25, 26, 31, 32, 27, 26, 28, 20, 20,
> +         27, 32, 29, 32, 23, 27, 21, 17, 35, 18, 29, 31, 26, 38,
> +         23, 18, 27, 22, 23, 31, 29, 29, 34, 25, 23, 39, 28, 28,
> +         30, 19, 12, 26, 28, 22, 15, 31, 27, 31, 17, 25, 32, 22),
> +     Jul = c(42, 33, 19, 35, 33, 30, 34, 18, 14, 32, 26, 29, 31,
> +         36, 32, 29, 28, 21, 24, 30, 33, 30, 34, 23, 30, 26, 17,
> +         35, 18, 28, 33, 27, 39, 22, 19, 29, 25, 25, 34, 32, 32,
> +         37, 24, 25, 36, 29, 30, 32, 18, 14, 25, 29, 22, 15, 32,
> +         32, 31, 17, 28, 34, 21), Aug = c(43, 33, 17, 35, 33,
> +         31, 34, 18, 16, 32, 27, 28, 30, 35, 30, 29, 26, 23, 21,
> +         30, 32, 31, 34, 20, 29, 21, 20, 35, 18, 28, 33, 28, 39,
> +         21, 18, 30, 25, 26, 33, 31, 32, 37, 24, 22, 34, 29, 29,
> +         31, 19, 14, 26, 29, 22, 17, 32, 31, 31, 19, 28, 34, 24),
> +     Sep = c(43, 33, 13, 32, 29, 28, 33, 18, 19, 33, 26, 25, 31,
> +         32, 26, 26, 24, 28, 17, 27, 31, 30, 32, 16, 25, 11, 23,
> +         34, 19, 28, 31, 28, 34, 20, 19, 28, 25, 26, 28, 28, 29,
> +         33, 23, 17, 35, 24, 27, 27, 20, 11, 26, 26, 24, 18, 32,
> +         29, 31, 22, 28, 29, 28), Okt = c(37, 32, 5, 27, 24, 23,
> +         32, 18, 21, 32, 24, 17, 31, 25, 17, 23, 17, 29, 9, 24,
> +         29, 29, 27, 5, 20, -5, 25, 29, 21, 26, 27, 26, 27, 17,
> +         20, 22, 22, 24, 21, 24, 25, 28, 23, 9, 33, 18, 25, 19,
> +         22, 6, 27, 22, 21, 22, 32, 23, 32, 21, 27, 27, 31), Nov = c(31,
> +         32, -2, 21, 18, 18, 32, 19, 25, 32, 21, 10, 31, 19, 11,
> +         19, 11, 27, 2, 20, 26, 28, 21, -5, 15, -24, 25, 25, 25,
> +         23, 23, 25, 19, 12, 22, 17, 21, 21, 13, 20, 18, 23, 22,
> +         0, 28, 13, 19, 10, 28, 4, 27, 17, 17, 26, 31, 17, 31,
> +         23, 25, 20, 31), Dez = c(27, 32, -4, 16, 14, 11, 31,
> +         19, 29, 30, 19, 2, 31, 14, 7, 17, 7, 27, 0, 16, 22, 27,
> +         16, -13, 10, -35, 25, 20, 26, 21, 18, 22, 14, 9, 23,
> +         14, 19, 20, 11, 17, 16, 20, 22, -3, 23, 6, 17, 3, 30,
> +         3, 29, 14, 15, 29, 31, 10, 30, 26, 23, 18, 33)), .Names = c("BG",
> +     "Kont", "Jan", "Feb", "Mrz", "Apr", "Mai", "Jun", "Jul",
> +     "Aug", "Sep", "Okt", "Nov", "Dez"), row.names = c("Abu 
> Dhabi             ",
> +     "Acapulco              ", "Anchorage             ", 
> "Antalya               ",
> +     "Athen                 ", "Atlanta               ", 
> "Bangkok               ",
> +     "Bogota                ", "BuenosAires           ", 
> "Caracas               ",
> +     "Casablanca            ", "Chicago               ", 
> "ColomboSriLanka       ",
> +     "Dallas                ", "Denver                ", 
> "FaroAlgarve           ",
> +     "GrandCanyonArizona    ", "Harare                ", 
> "Helsinki              ",
> +     "HeraklionKreta        ", "Hongkong              ", 
> "Honolulu              ",
> +     "Houston               ", "Irkutsk               ", 
> "Istanbul              ",
> +     "JakutskNordostsibirien", "Johannesburg          ", 
> "Kairo                 ",
> +     "Kapstadt              ", "Kathmandu             ", 
> "LarnakaZypern         ",
> +     "Las Palmas            ", "Las Vegas             ", 
> "Lhasa                 ",
> +     "Lima                  ", "Lissabon              ", "Los 
> Angeles           ",
> +     "Madeira               ", "Madrid                ", 
> "Malaga                ",
> +     "Mallorca              ", "Marrakesch            ", "Mexico 
> City           ",
> +     "Moskau                ", "Neu Delhi             ", "New 
> York              ",
> +     "Palermo               ", "PekingBeijing         ", 
> "PerthAustralien       ",
> +     "Reykjavik             ", "RioDeJaneiro          ", 
> "Rom                   ",
> +     "SanFrancisco          ", "SantiagoDeChile       ", 
> "SantoDomingoKaribik   ",
> +     "Shanghai              ", "Singapur              ", 
> "SydneyAustralien      ",
> +     "Teneriffa             ", "Tunis                 ", 
> "Windhoek              "),
> +     class = "data.frame")
>  >
>  > attach(aa)
>  > par(mfrow=c(4,3))
>  > m 
> <-c("Januar","Februar","M?rz","April","Mai","Juni","Juli","August","September","Oktober","November","Dezember")
>  > for(i in 1:12)
> + 
> plot(BG,aa[,i+2],main=m[i],xlab="Breitengrad",ylab="Temperatur",ylim=c(-35,35))
>  > dev.print(device = postscript, 
> width=4,height=5,horizontal=TRUE,file="c://test.ps")
> windows
>       2
>  > # That's fine
>  > # Here comes the error
>  > dev.print(device = postscript, width=5 
> ,height=4,horizontal=TRUE,file="c://test.ps")
> Error in dev.copy(device = function (file = ifelse(onefile, "Rplots.ps",  :
>         invalid graphics state
>  > # From now on plotting is impossible:
>  > plot(1:2)
> Error in plot.new() : figure margins too large
>  > # As a "remedy" I restart R
>
>   
There's a generic issue when dev.print() goes wrong in that it leaves 
the target device open. Have a look at dev.list() and possibly use 
dev.off() for a less drastic remedy.

I'm not at a Windows machine so I'm unsure whether the "invalid graphics 
state" is an issue in itself or it is just that you set the figure 
region so that there is no room for both the figure region and the margins.

>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 5.0
>  year = 2007
>  month = 04
>  day = 23
>  svn rev = 41293
>  language = R
>  version.string = R version 2.5.0 (2007-04-23)
>
> Windows XP (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=English_United 
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> Search Path:
>  .GlobalEnv, aa, package:stats, package:graphics, package:grDevices, 
> package:utils, package:datasets, package:methods, Autoloads, package:base
>
>
>


From stvjc at channing.harvard.edu  Sat Jul 21 13:24:25 2007
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Sat, 21 Jul 2007 07:24:25 -0400 (EDT)
Subject: [Rd] X11() dies in remote background
Message-ID: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>


this is not a problem with R but a request for related advice.

i am trying to run a lengthy batch job from my home.

the OS is ...
Linux jedi.bwh.harvard.edu 2.4.22-openmosix1smp #1 SMP Fri Sep 5 01:05:37 CEST
2003 i686 athlon i386 GNU/Linux

i start the job and put it in the background.  while i am connected, all is
well.  eventually my ISP shuts down the connection if i do not do any
input.  then:


Boxplots of G intensitiesError in X11(paste("png::", filename, sep = ""), width, height, pointsize,  :
  unable to start device PNG
Calls: doPlot -> qcBeadLevel -> png
In addition: Warning message:
In png(filename, width = 640, height = 480) :
  unable to open connection to X11 display ''
Execution halted

is it possible to have X11() succeed when there is no real display to connect
to?

R version 2.6.0 Under development (unstable) (2007-06-29 r42093)
i686-pc-linux-gnu

locale:
LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C

attached base packages:
[1] grid      tools     stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
 [1] beadarray_1.5.3    beadarraySNP_1.3.7 quantsmooth_1.3.0  lodplot_1.1
 [5] quantreg_4.06      SparseM_0.73       affy_1.13.9        affyio_1.3.1
 [9] geneplotter_1.13.4 lattice_0.15-11    annotate_1.13.3    Biobase_1.13.19
[13] limma_2.9.5

loaded via a namespace (and not attached):
[1] KernSmooth_2.22-20 RColorBrewer_0.2-3 rcompgen_0.1-13


---
Vince Carey, PhD
Assoc. Prof Med (Biostatistics)
Harvard Medical School
Channing Laboratory - ph 6175252265 fa 6177311541
181 Longwood Ave Boston MA 02115 USA
stvjc at channing.harvard.edu


From ligges at statistik.uni-dortmund.de  Sat Jul 21 15:08:14 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 21 Jul 2007 15:08:14 +0200
Subject: [Rd] triax.points() from package plotrix
In-Reply-To: <1184854071.4975.10.camel@chironomus.local>
References: <1184854071.4975.10.camel@chironomus.local>
Message-ID: <46A2053E.8040801@statistik.uni-dortmund.de>

Remarks, bug reports and feature requests on contributed packages should 
go to the corresponding package maintainer (CCing). Note that several 
developers of the > 1000 CRAN R packages do not read this mailing list.

Thank you,
Uwe Ligges



Andreas Plank wrote:
> Dear developers from package plotrix,
> 
> the function triax.points() from package plotrix does not draw any
> points, because of internal setting in triax.points() {points(...,
> type="l")}. 
> I add a new option in triax.points() 
> 	point.type = "l", 
> So the user can choose which type of points should be drawn.
> May be other users already found this defect.
> 
> best whishes
> Andreas Plank
> 
> ####--- 8< ----#######
> triax.points <- function (x,
>   show.legend = FALSE,
>   label.points = FALSE,
>   point.labels = NULL,
>   col.symbols = par("fg"),
>   pch = par("pch"),
>   bg.symbols = par("bg"),
>   cc.axes = FALSE,
>   point.type = "l", # new add
>    ...
>   )
> {
>     if (dev.cur() == 1)
>         stop("Cannot add points unless the triax.frame has been drawn")
>     if (missing(x))
>         stop("Usage: triax.points(x,...)\n\twhere x is a 3 column array
> of proportions or percentages")
>     if (!is.matrix(x) && !is.data.frame(x))
>         stop("x must be a matrix or data frame with at least 3 columns
> and one row.")
>     if (any(x > 1) || any(x < 0)) {
>         if (any(x < 0))
>             stop("All proportions must be between zero and one.")
>         if (any(x > 100))
>             stop("All percentages must be between zero and 100.")
>         x <- x/100
>     }
>     if (any(abs(rowSums(x) - 1) > 0.01))
>         warning("At least one set of proportions does not equal one.")
>     sin60 <- sin(pi/3)
>     if (cc.axes) {
>         ypos <- x[, 3] * sin60
>         xpos <- x[, 1] + x[, 3] * 0.5
>     }
>     else {
>         ypos <- x[, 3] * sin60
>         xpos <- 1 - (x[, 1] + x[, 3] * 0.5)
>     }
>     nobs <- dim(x)[1]
>     if (is.null(point.labels))
>         point.labels <- rownames(x)
>     if (label.points)
>         thigmophobe.labels(xpos, ypos, point.labels)
>     if (show.legend) {
>         legend(0.16 - 0.02 * max(nchar(point.labels)), 0.75 +
>             0.04 * length(point.labels), legend = point.labels,
>             pch = pch, col = col.symbols)
>     }
>     points(x = xpos, y = ypos, pch = pch, col = col.symbols,
>         bg = bg.symbols, type = point.type, ...)
>     invisible(list(x = xpos, y = ypos))
> }
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Jul 21 15:41:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Jul 2007 14:41:54 +0100 (BST)
Subject: [Rd] X11() dies in remote background
In-Reply-To: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
References: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
Message-ID: <Pine.LNX.4.64.0707211438070.28787@gannet.stats.ox.ac.uk>

I use a display on an Xvfb server:

Xvfb :5 -screen 0 1280x1024x24 &
setenv DISPLAY :5

You do most likely need a non-default depth (on my machine the default is 
12 bits), and it is possible you may need to deal with authentication 
issues.

On Sat, 21 Jul 2007, Vincent Carey 525-2265 wrote:

>
> this is not a problem with R but a request for related advice.
>
> i am trying to run a lengthy batch job from my home.
>
> the OS is ...
> Linux jedi.bwh.harvard.edu 2.4.22-openmosix1smp #1 SMP Fri Sep 5 01:05:37 CEST
> 2003 i686 athlon i386 GNU/Linux
>
> i start the job and put it in the background.  while i am connected, all is
> well.  eventually my ISP shuts down the connection if i do not do any
> input.  then:
>
>
> Boxplots of G intensitiesError in X11(paste("png::", filename, sep = ""), width, height, pointsize,  :
>  unable to start device PNG
> Calls: doPlot -> qcBeadLevel -> png
> In addition: Warning message:
> In png(filename, width = 640, height = 480) :
>  unable to open connection to X11 display ''
> Execution halted
>
> is it possible to have X11() succeed when there is no real display to connect
> to?
>
> R version 2.6.0 Under development (unstable) (2007-06-29 r42093)
> i686-pc-linux-gnu
>
> locale:
> LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      tools     stats     graphics  grDevices utils     datasets
> [8] methods   base
>
> other attached packages:
> [1] beadarray_1.5.3    beadarraySNP_1.3.7 quantsmooth_1.3.0  lodplot_1.1
> [5] quantreg_4.06      SparseM_0.73       affy_1.13.9        affyio_1.3.1
> [9] geneplotter_1.13.4 lattice_0.15-11    annotate_1.13.3    Biobase_1.13.19
> [13] limma_2.9.5
>
> loaded via a namespace (and not attached):
> [1] KernSmooth_2.22-20 RColorBrewer_0.2-3 rcompgen_0.1-13
>
>
> ---
> Vince Carey, PhD
> Assoc. Prof Med (Biostatistics)
> Harvard Medical School
> Channing Laboratory - ph 6175252265 fa 6177311541
> 181 Longwood Ave Boston MA 02115 USA
> stvjc at channing.harvard.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Sat Jul 21 18:13:35 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 21 Jul 2007 09:13:35 -0700
Subject: [Rd] X11() dies in remote background
In-Reply-To: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
	(Vincent Carey's message of "Sat,
	21 Jul 2007 07:24:25 -0400 (EDT)")
References: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
Message-ID: <m2ir8dlopc.fsf@ziti.fhcrc.org>

Vincent Carey 525-2265 <stvjc at channing.harvard.edu> writes:

> this is not a problem with R but a request for related advice.
>
> i am trying to run a lengthy batch job from my home.
>
> the OS is ...
> Linux jedi.bwh.harvard.edu 2.4.22-openmosix1smp #1 SMP Fri Sep 5 01:05:37 CEST
> 2003 i686 athlon i386 GNU/Linux
>
> i start the job and put it in the background.  while i am connected, all is
> well.  eventually my ISP shuts down the connection if i do not do any
> input.  

One thing you might try is using screen.  The screen program lets you
multiplex terminals in a single window, but the feature you want here
is that it allows you to detach and reattach to a session.  So you
could start a screen session at work or home, start something running,
detach, and then come back later and attach to see how things are going.

However, screen may further complicate your desire to use X11(), but
perhaps with Xvfb run from the screen session things will work.  Do
all of the graphics devices require access to X11()?  I thought you
could use pdf() for example, without X11() but I'm not certain.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From stvjc at channing.harvard.edu  Sat Jul 21 18:23:26 2007
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Sat, 21 Jul 2007 12:23:26 -0400 (EDT)
Subject: [Rd] X11() dies in remote background
In-Reply-To: <m2ir8dlopc.fsf@ziti.fhcrc.org>
References: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
	<m2ir8dlopc.fsf@ziti.fhcrc.org>
Message-ID: <Pine.GSO.4.58.0707211218080.5476@capecod.bwh.harvard.edu>


> Vincent Carey 525-2265 <stvjc at channing.harvard.edu> writes:
>
> > this is not a problem with R but a request for related advice.
> >
> > i am trying to run a lengthy batch job from my home.
> >
> > the OS is ...
> > Linux jedi.bwh.harvard.edu 2.4.22-openmosix1smp #1 SMP Fri Sep 5 01:05:37 CEST
> > 2003 i686 athlon i386 GNU/Linux
> >
> > i start the job and put it in the background.  while i am connected, all is
> > well.  eventually my ISP shuts down the connection if i do not do any
> > input.
>
> One thing you might try is using screen.  The screen program lets you
> multiplex terminals in a single window, but the feature you want here
> is that it allows you to detach and reattach to a session.  So you
> could start a screen session at work or home, start something running,
> detach, and then come back later and attach to see how things are going.
>
> However, screen may further complicate your desire to use X11(), but
> perhaps with Xvfb run from the screen session things will work.  Do
> all of the graphics devices require access to X11()?  I thought you
> could use pdf() for example, without X11() but I'm not certain.

it looks like pdf() would work.  but ... qcBeadLevel runs png() ...
and the ultimate desire seems to be to have images that will load
nicely in a browser in html.  admittedly i could hack qcBeadLevel
to run pdf and then imagemagick the results into png.

so far it looks like Xvfb will do the trick if i can authenticate
properly.  and so far, that is out of my hands.

it seems i can get the ISP to refrain from timing me out if i
print to screen from the process with some frequency.  but i don't know if
that will work indefinitely


From bcarvalh at jhsph.edu  Sat Jul 21 18:33:07 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Sat, 21 Jul 2007 12:33:07 -0400
Subject: [Rd] X11() dies in remote background
In-Reply-To: <Pine.GSO.4.58.0707211218080.5476@capecod.bwh.harvard.edu>
References: <Pine.GSO.4.58.0707210723400.23420@capecod.bwh.harvard.edu>
	<m2ir8dlopc.fsf@ziti.fhcrc.org>
	<Pine.GSO.4.58.0707211218080.5476@capecod.bwh.harvard.edu>
Message-ID: <F78C353C-758F-45CC-B09A-CBC1EAA522D9@jhsph.edu>

Won't

ServerAliveInterval 60

in /etc/ssh_config do the job of keeping your connection alive?

And wouldn't it be more appropriate if bitmap() was used instead?

b

On Jul 21, 2007, at 12:23 PM, Vincent Carey 525-2265 wrote:

>
>> Vincent Carey 525-2265 <stvjc at channing.harvard.edu> writes:
>>
>>> this is not a problem with R but a request for related advice.
>>>
>>> i am trying to run a lengthy batch job from my home.
>>>
>>> the OS is ...
>>> Linux jedi.bwh.harvard.edu 2.4.22-openmosix1smp #1 SMP Fri Sep 5  
>>> 01:05:37 CEST
>>> 2003 i686 athlon i386 GNU/Linux
>>>
>>> i start the job and put it in the background.  while i am  
>>> connected, all is
>>> well.  eventually my ISP shuts down the connection if i do not do  
>>> any
>>> input.
>>
>> One thing you might try is using screen.  The screen program lets you
>> multiplex terminals in a single window, but the feature you want here
>> is that it allows you to detach and reattach to a session.  So you
>> could start a screen session at work or home, start something  
>> running,
>> detach, and then come back later and attach to see how things are  
>> going.
>>
>> However, screen may further complicate your desire to use X11(), but
>> perhaps with Xvfb run from the screen session things will work.  Do
>> all of the graphics devices require access to X11()?  I thought you
>> could use pdf() for example, without X11() but I'm not certain.
>
> it looks like pdf() would work.  but ... qcBeadLevel runs png() ...
> and the ultimate desire seems to be to have images that will load
> nicely in a browser in html.  admittedly i could hack qcBeadLevel
> to run pdf and then imagemagick the results into png.
>
> so far it looks like Xvfb will do the trick if i can authenticate
> properly.  and so far, that is out of my hands.
>
> it seems i can get the ISP to refrain from timing me out if i
> print to screen from the process with some frequency.  but i don't  
> know if
> that will work indefinitely
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Sat Jul 21 23:01:47 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 21 Jul 2007 14:01:47 -0700
Subject: [Rd] dict package: dictionary data structure for R
Message-ID: <m28x99lbd0.fsf@ziti.fhcrc.org>

Hi all,

The dict package provides a dictionary (hashtable) data
structure much like R's built-in environment objects, but with the
following differences:

  - The Dict class can be subclassed.

  - Four different hashing functions are implemented and the user can
    specify which to use when creating an instance.

I'm sending this here as opposed to R-packages because this package
will only be of interest to developers and because I'd like to get
feedback from a slightly smaller community before either putting it on
CRAN or retiring it to /dev/null.

The design makes it fairly easy to add additional hashing functions,
although currently this must be done in C.  If nothing else, this
package should be useful for evaluating hashing functions (see the
vignette for some examples).

Source:
  R-2.6.x: http://userprimary.net/software/dict_0.1.0.tar.gz
  R-2.5.x: http://userprimary.net/software/dict_0.0.4.tar.gz

Windows binary:
  R-2.5.x: http://userprimary.net/software/dict_0.0.4.zip


+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From ggrothendieck at gmail.com  Sun Jul 22 02:43:37 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 21 Jul 2007 20:43:37 -0400
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <m28x99lbd0.fsf@ziti.fhcrc.org>
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
Message-ID: <971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>

Although the proto package is not particularly aimed at hashing note
that it covers some of the same ground and also is based on a well
thought out object model (known as object-based programming
or prototype programming).

Here is an example where we create two proto objects (which could
be regarded as hash tables) in which q is a child of p and so inherits a:

   library(proto)
   p <- proto(a = 1, b = 2)
   q <- p$proto(c = 3)
   q$a # 1



On 7/21/07, Seth Falcon <sfalcon at fhcrc.org> wrote:
> Hi all,
>
> The dict package provides a dictionary (hashtable) data
> structure much like R's built-in environment objects, but with the
> following differences:
>
>  - The Dict class can be subclassed.
>
>  - Four different hashing functions are implemented and the user can
>    specify which to use when creating an instance.
>
> I'm sending this here as opposed to R-packages because this package
> will only be of interest to developers and because I'd like to get
> feedback from a slightly smaller community before either putting it on
> CRAN or retiring it to /dev/null.
>
> The design makes it fairly easy to add additional hashing functions,
> although currently this must be done in C.  If nothing else, this
> package should be useful for evaluating hashing functions (see the
> vignette for some examples).
>
> Source:
>  R-2.6.x: http://userprimary.net/software/dict_0.1.0.tar.gz
>  R-2.5.x: http://userprimary.net/software/dict_0.0.4.tar.gz
>
> Windows binary:
>  R-2.5.x: http://userprimary.net/software/dict_0.0.4.zip
>
>
> + seth
>
> --
> Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
> http://bioconductor.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sfalcon at fhcrc.org  Sun Jul 22 04:40:44 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 21 Jul 2007 19:40:44 -0700
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
	(Gabor Grothendieck's message of "Sat,
	21 Jul 2007 20:43:37 -0400")
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
	<971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
Message-ID: <m24pjxcg9f.fsf@ziti.local>

"Gabor Grothendieck" <ggrothendieck at gmail.com> writes:

> Although the proto package is not particularly aimed at hashing note
> that it covers some of the same ground and also is based on a well
> thought out object model (known as object-based programming
> or prototype programming).

Interesting.  The dict package differs from proto in that it _is_
aimed at hashing and:

  - It is S4 based

  - It does not use R's environment objects to implement its
    hashtables (proto uses environments).

In Bioconductor, we have many hashtables where the key is an
Affymetrix probeset ID.  These look sort of like "1000_at".  It turns
out that the algorithm used by R's environments is not very good at
hashing these values.  The dict package lets you investigate this:

   library("dict")
   keys2 = paste(seq(1000, length=13000), "at", sep="_")

   # here, hash.alg=0L corresponds to the hashing function used by R's
   # environments.  I know, a name would be better.
   > summary(as.integer(table(hashCodes(keys=keys2, hash.alg=0L, size=2^14))))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    800    1100    1500    1625    2025    2700 
   # hash.alg=1L is djb2 from here: http://www.cse.yorku.ca/~oz/hash.html 
   > summary(as.integer(table(hashCodes(keys=keys2, hash.alg=1L, size=2^14))))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   1.000   2.000   1.648   2.000   4.000 

  # and this is what we see with an environment:
    > e = new.env(hash=T, size=2^14)
    > for (k in keys2) e[[k]] = k
    > summary(env.profile(e)$counts)
         Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
       0.0000    0.0000    0.0000    0.7935    0.0000 2700.0000 



-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From bill at insightful.com  Sun Jul 22 20:41:51 2007
From: bill at insightful.com (Bill Dunlap)
Date: Sun, 22 Jul 2007 11:41:51 -0700 (PDT)
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <m24pjxcg9f.fsf@ziti.local>
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
	<971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
	<m24pjxcg9f.fsf@ziti.local>
Message-ID: <Pine.GSO.4.56.0707221129070.22444@durian.statsci.com>

On Sat, 21 Jul 2007, Seth Falcon wrote:

> In Bioconductor, we have many hashtables where the key is an
> Affymetrix probeset ID.  These look sort of like "1000_at".  It turns
> out that the algorithm used by R's environments is not very good at
> hashing these values.  The dict package lets you investigate this:
>
>    library("dict")
>    keys2 = paste(seq(1000, length=13000), "at", sep="_")
>
>    # here, hash.alg=0L corresponds to the hashing function used by R's
>    # environments.  I know, a name would be better.
>    > summary(as.integer(table(hashCodes(keys=keys2, hash.alg=0L, size=2^14))))
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>     800    1100    1500    1625    2025    2700
>    # hash.alg=1L is djb2 from here: http://www.cse.yorku.ca/~oz/hash.html
>    > summary(as.integer(table(hashCodes(keys=keys2, hash.alg=1L, size=2^14))))
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   1.000   1.000   2.000   1.648   2.000   4.000
>
>   # and this is what we see with an environment:
>     > e = new.env(hash=T, size=2^14)
>     > for (k in keys2) e[[k]] = k
>     > summary(env.profile(e)$counts)
>          Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
>        0.0000    0.0000    0.0000    0.7935    0.0000 2700.0000

With environments, if you use a prime number for the size
you get considerably better results.  E.g.,

> f <- function(size, keys2 = paste(seq(1000, length=13000), "at", sep="_")){
      if (!missing(size))
         e <- new.env(hash=T, size = size)
      else
         e <- new.env(hash=T)
      for(k in keys2) e[[k]] <- k
      table(env.profile(e)$counts)
}
> f(size=2^14)

    0   800  1200  1800  2700
16376     2     2     2     2
> f(16411) # next prime above 2^14

   0    1    2    3
7644 5110 3081  576
> f() # let new.env pick a size

   0    1    2    3    4    5
6514 1486 2717 1608  289   20

Perhaps new.env() should push the requested size up
to the next prime by default.

(This is not to say your other changes are not improvements.)

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From ligges at statistik.uni-dortmund.de  Mon Jul 23 09:25:35 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 23 Jul 2007 09:25:35 +0200
Subject: [Rd] Windows builder: Package X did not pass R CMD check
Message-ID: <46A457EF.20100@statistik.uni-dortmund.de>

Dear package maintainers,

due to some hicc up in my autobuilder, many CRAN package maintainers got 
a message about an error in their packages for R-2.5.1. Please ignore 
that one.

My sincere apologies for spamming around,
Uwe Ligges


From osklyar at ebi.ac.uk  Mon Jul 23 11:02:16 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 23 Jul 2007 10:02:16 +0100
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited from 'array',
	or	intended behavior?
Message-ID: <1185181337.6294.29.camel@dirac>

Hi,

I have an S4 class directly derived from 'array' as shown in the code
below (EBImage package of Bioconductor 2.1, devel), it simply contains
array adding a couple of slots:

setClass ("Image",
  representation (colormode="integer", filename="character", 
    compression="character", resolution="numeric", features="list"
  ),
  prototype (colormode= Grayscale, filename="no-name",
compression="JPEG",
    resolution=c(2.5e+6, 2.5e+6), features=list()
  ),
  contains = "array"
)

No mathematical/arithmetical routines have been redefined for the class
and this is what I was getting since R2.0, sum of two objects of class
Image is Image again:

version.string R version 2.5.1 (2007-06-27):
> library(EBImage)
> a <- Image(0, c(2,2))
> class(a+a)
[1] "Image"
attr(,"package")
[1] "EBImage"

The same stands for 

version.string R version 2.6.0 Under development (unstable) (2007-07-11
r42199)
> library(EBImage)
> a <- Image(0, c(2,2))
> class(a+a)
[1] "Image"
attr(,"package")
[1] "EBImage"

Now, in the yesterday's revision of R2.6 I get the following:

version.string R version 2.6.0 Under development (unstable) (2007-07-21
r42284)

> library(EBImage)
> a <- Image(0, c(2,2))
> class(a+a)
[1] "array"

Is this the intended behavior to fall back to the base class (same for
*,/,-)? If yes, could someone point me to the following two things: what
are the reasons behind and WHAT operators and functions have been
affected -- I will need to redefine all those then. Moreover, it is not
consistent:

> class(a*2)
[1] "Image"
attr(,"package")
[1] "EBImage"
> class(2*a)
[1] "Image"
attr(,"package")
[1] "EBImage"


Unfortunately, I do not have R versions installed between revisions
42199 and 42284, so I cannot narrow down to the particular revision. 

Thanks in advance,
Oleg

-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +441223493366


From ripley at stats.ox.ac.uk  Mon Jul 23 11:33:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Jul 2007 10:33:39 +0100 (BST)
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited from
 'array', or intended behavior?
In-Reply-To: <1185181337.6294.29.camel@dirac>
References: <1185181337.6294.29.camel@dirac>
Message-ID: <Pine.LNX.4.64.0707231017100.23845@gannet.stats.ox.ac.uk>

I believe this occurred with the change to make use of implicit generics, 
r42246.  Please check that for yourself (see the comment at the end).

If so it will need John Chambers' attention (he is currently offline).

On Mon, 23 Jul 2007, Oleg Sklyar wrote:

> Hi,
>
> I have an S4 class directly derived from 'array' as shown in the code
> below (EBImage package of Bioconductor 2.1, devel), it simply contains
> array adding a couple of slots:
>
> setClass ("Image",
>  representation (colormode="integer", filename="character",
>    compression="character", resolution="numeric", features="list"
>  ),
>  prototype (colormode= Grayscale, filename="no-name",
> compression="JPEG",
>    resolution=c(2.5e+6, 2.5e+6), features=list()
>  ),
>  contains = "array"
> )

Which is unfortunately not self-contained.

> No mathematical/arithmetical routines have been redefined for the class
> and this is what I was getting since R2.0, sum of two objects of class
> Image is Image again:
>
> version.string R version 2.5.1 (2007-06-27):
>> library(EBImage)
>> a <- Image(0, c(2,2))
>> class(a+a)
> [1] "Image"
> attr(,"package")
> [1] "EBImage"
>
> The same stands for
>
> version.string R version 2.6.0 Under development (unstable) (2007-07-11
> r42199)
>> library(EBImage)
>> a <- Image(0, c(2,2))
>> class(a+a)
> [1] "Image"
> attr(,"package")
> [1] "EBImage"
>
> Now, in the yesterday's revision of R2.6 I get the following:
>
> version.string R version 2.6.0 Under development (unstable) (2007-07-21
> r42284)
>
>> library(EBImage)
>> a <- Image(0, c(2,2))
>> class(a+a)
> [1] "array"
>
> Is this the intended behavior to fall back to the base class (same for
> *,/,-)? If yes, could someone point me to the following two things: what
> are the reasons behind and WHAT operators and functions have been
> affected -- I will need to redefine all those then. Moreover, it is not
> consistent:
>
>> class(a*2)
> [1] "Image"
> attr(,"package")
> [1] "EBImage"
>> class(2*a)
> [1] "Image"
> attr(,"package")
> [1] "EBImage"
>
>
> Unfortunately, I do not have R versions installed between revisions
> 42199 and 42284, so I cannot narrow down to the particular revision.

But you can of course get any version out of SVN and thereby narrow this 
down.  Please don't expect others to do this for you.

svn up -r42245
make
...
svn up -r42246
make
...

confirms it for me.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From s.blomberg1 at uq.edu.au  Mon Jul 23 12:10:39 2007
From: s.blomberg1 at uq.edu.au (s.blomberg1 at uq.edu.au)
Date: Mon, 23 Jul 2007 12:10:39 +0200 (CEST)
Subject: [Rd] postscript bug? (PR#9803)
Message-ID: <20070723101039.8371165982@slim.kubism.ku.dk>

postscript() produces files that are not encoded as eps, according to
the standard. Hence, word processors such as OpenOffice and AbiWord do
not recognise the files as eps. See
http://www.postscript.org/FAQs/language/node80.html

The problem is in the first line of the postscript file: The header is
wrong. It should be:

%!PS-Adobe-3.0 EPSF-3.0

whereas postscript() produces:

%!PS-Adobe-3.0

The following code replicates the problem:

x <- rnorm(10)
y <- rnorm(10)
postscript("test.eps")
plot(x,y)
dev.off()

# Now try importing test.eps into your favorite word processor.

# Now edit test.eps and change the header to the correct header above, 
and try importing the file again. Works! (This took me a couple of hours
of hair-pulling to figure out. I sure hope it is a genuine bug. :-) )

Cheers,

Simon.

Version:
 platform = x86_64-pc-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 5.1
 year = 2007
 month = 06
 day = 27
 svn rev = 42083
 language = R
 version.string = R version 2.5.1 (2007-06-27)

Locale:
LC_CTYPE=en_AU.UTF-8;LC_NUMERIC=C;LC_TIME=en_AU.UTF-8;LC_COLLATE=en_AU.UTF-8;LC_MONETARY=en_AU.UTF-8;
LC_MESSAGES=en_AU.UTF-8;LC_PAPER=en_AU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;
LC_MEASUREMENT=en_AU.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:utils, package:datasets, package:methods, Autoloads,
package:base

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From P.Dalgaard at biostat.ku.dk  Mon Jul 23 12:36:22 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 23 Jul 2007 12:36:22 +0200
Subject: [Rd] postscript bug? (PR#9803)
In-Reply-To: <20070723101039.8371165982@slim.kubism.ku.dk>
References: <20070723101039.8371165982@slim.kubism.ku.dk>
Message-ID: <46A484A6.40606@biostat.ku.dk>

s.blomberg1 at uq.edu.au wrote:
> postscript() produces files that are not encoded as eps, according to
> the standard. Hence, word processors such as OpenOffice and AbiWord do
> not recognise the files as eps. See
> http://www.postscript.org/FAQs/language/node80.html
>
> The problem is in the first line of the postscript file: The header is
> wrong. It should be:
>
> %!PS-Adobe-3.0 EPSF-3.0
>
> whereas postscript() produces:
>
> %!PS-Adobe-3.0
>
> The following code replicates the problem:
>
> x <- rnorm(10)
> y <- rnorm(10)
> postscript("test.eps")
> plot(x,y)
> dev.off()
>
> # Now try importing test.eps into your favorite word processor.
>
> # Now edit test.eps and change the header to the correct header above, 
> and try importing the file again. Works! (This took me a couple of hours
> of hair-pulling to figure out. I sure hope it is a genuine bug. :-) )
>   
It isn't a bug. It is as it should be, because a plot file with multiple
pages cannot be EPS.

Try reading the help page for postscript again, this time ( ;-) ) paying
attention to the 'onefile' argument.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From osklyar at ebi.ac.uk  Mon Jul 23 12:43:59 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 23 Jul 2007 11:43:59 +0100
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited
	from	'array', or	intended behavior?
In-Reply-To: <1185181337.6294.29.camel@dirac>
References: <1185181337.6294.29.camel@dirac>
Message-ID: <1185187439.6294.58.camel@dirac>

Narrowed down to Rev. 42246:

* ~/R/Rsvn: svn up -r42245
* ~/R/Rsvn: make
* ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
* ~/R/Rsvn: Rsvn
> version$version.string
[1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42245)"
> library(EBImage)
> a <- Image(0,c(2,2))
> class(a+a)
[1] "Image"
attr(,"package")
[1] "EBImage"

* ~/R/Rsvn: svn up -r42246
* ~/R/Rsvn: make
* ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
* ~/R/Rsvn: Rsvn
> version$version.string
[1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42246)"
> library(EBImage)
> a <- Image(0,c(2,2))
> class(a+a)
[1] "array"

* ~/R/Rsvn: svn log -r42246
------------------------------------------------------------------------
r42246 | jmc | 2007-07-16 14:32:16 +0100 (Mon, 16 Jul 2007) | 1 line

implicitGeneric() and structure class
------------------------------------------------------------------------

-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +441223494466


From duncan at wald.ucdavis.edu  Mon Jul 23 13:11:44 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Mon, 23 Jul 2007 04:11:44 -0700
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <m28x99lbd0.fsf@ziti.fhcrc.org>
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
Message-ID: <46A48CF0.6070407@wald.ucdavis.edu>

Hi Seth.

Glad you did this. As you know, I think we need more specialized
data structures and the ability to be able to introduce them easily
into R computations, both internally and at the R language-level.

A few things that come to mind after a quick initial look.

The HashFunc typedef in hashfuncs.h would be more flexible  if it
took an additional argument of type void * to allow for user
defined data.  Alternatively, it might take the hash table
object itself.  The function might want to do some
updating of the table itself, or look at some table (e.g. for perfect 
hashing).  And if we had a place to provide additional information, it
is easy to allow the hash function object to be an R function.

Also, you are using a "global" table of hash functions (i.e. 
Dict_HashFunctions) and looking up the C routine using GET_HASHFUN
which is tied to the integer indexing for this global table.
Why not use the C routines directly from R, i.e. using
getNativeSymbolInfo and pass this from R to the newly created
dict.  This avoids the lookup, the global table and makes things
extensible with routines in packages and simply extends to allowing
R functions to be passed instead of C routines.
It also removes the need to synchronize the labeling system in
R and in C, i.e. that 0L corresponds to PJW. The reliance on
synchronized names rather than direct handles is unnecessary
although widely used in S/R code.

I'm more than happy to give some code to illustrate what I mean
more precisely if you'd like it.

  D.


Seth Falcon wrote:
> Hi all,
> 
> The dict package provides a dictionary (hashtable) data
> structure much like R's built-in environment objects, but with the
> following differences:
> 
>   - The Dict class can be subclassed.
> 
>   - Four different hashing functions are implemented and the user can
>     specify which to use when creating an instance.
> 
> I'm sending this here as opposed to R-packages because this package
> will only be of interest to developers and because I'd like to get
> feedback from a slightly smaller community before either putting it on
> CRAN or retiring it to /dev/null.
> 
> The design makes it fairly easy to add additional hashing functions,
> although currently this must be done in C.  If nothing else, this
> package should be useful for evaluating hashing functions (see the
> vignette for some examples).
> 
> Source:
>   R-2.6.x: http://userprimary.net/software/dict_0.1.0.tar.gz
>   R-2.5.x: http://userprimary.net/software/dict_0.0.4.tar.gz
> 
> Windows binary:
>   R-2.5.x: http://userprimary.net/software/dict_0.0.4.zip
> 
> 
> + seth
>


From osklyar at ebi.ac.uk  Mon Jul 23 13:14:30 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 23 Jul 2007 12:14:30 +0100
Subject: [Rd] CHAR(STRING_ELT( - OK but CHAR(asChar(STRING_ELT( - not, why?
Message-ID: <1185189270.6294.69.camel@dirac>

Any idea why CHAR(asChar(STRING_ELT( produces NA whereas
CHAR(STRING_ELT( gets a pointer to a string? It's generally expected
that STRING_ELT should already be a character, but why the coercion does
not work? Here is a simple example (consistent over R2.5.1-R2.6 rev
42284, I didn't check earlier versions, but it used to be different in
2.4):

install.packages("inline")

library(inline)

sig <- signature(x="character")
code1 <- "
  for (int i = 0; i < LENGTH(x); i++ )
    Rprintf(\"%s\\n\", CHAR(STRING_ELT(x, i)));
  return R_NilValue;
"

code2 <- "
  for (int i = 0; i < LENGTH(x); i++ )
    Rprintf(\"%s\\n\", CHAR(asChar(STRING_ELT(x, i))));
  return R_NilValue;
"

setCMethod(c("p1","p2"), list(sig,sig), list(code1,code2))


#----------------------------------------------------------
p1(c("str1", "str2"))
# str1
# str2
# NULL

p2(c("str1", "str2"))
# NA
# NA
# NULL


-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +441223494466


From ripley at stats.ox.ac.uk  Mon Jul 23 14:22:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Jul 2007 13:22:16 +0100 (BST)
Subject: [Rd] CHAR(STRING_ELT( - OK but CHAR(asChar(STRING_ELT( - not,
 why?
In-Reply-To: <1185189270.6294.69.camel@dirac>
References: <1185189270.6294.69.camel@dirac>
Message-ID: <Pine.LNX.4.64.0707231254420.30373@gannet.stats.ox.ac.uk>

I think you are asking why calling asChar on a CHARSXP gives NA_STRING. 
In particular, the calls you mention *are* perfectly OK and work as 
intended.

As barely documented in R-exts, asChar is designed for vector arguments: a 
CHARSXP is not a vector.  It gives NA_STRING for invalid inputs.
The asXXXX family of functions are designed to coerce as necessary user 
inputs, and CHARSXPs are not visible at R level.

In general, with internal functions you are expected to read the code to 
find out what they do before using them.

On Mon, 23 Jul 2007, Oleg Sklyar wrote:

> Any idea why CHAR(asChar(STRING_ELT( produces NA whereas
> CHAR(STRING_ELT( gets a pointer to a string? It's generally expected
> that STRING_ELT should already be a character,

It is required to be a CHARSXP, but 'character' usually refers to STRSXP.

> but why the coercion does not work? Here is a simple example (consistent 
> over R2.5.1-R2.6 rev 42284, I didn't check earlier versions, but it used 
> to be different in 2.4):

There is no R '2.4', but the behaviour of asChar was the same in R 2.4.0
except for the adding of SYMSXP at

-------------
r40358 | maechler | 2007-01-04 11:07:04 +0000 (Thu, 04 Jan 2007) | 1 line

eliminate CHAR_STAR in methods/src/ as per old "todo"
-------------

which message does not help me at all.  Perhaps Martin can explain?


> install.packages("inline")
>
> library(inline)
>
> sig <- signature(x="character")
> code1 <- "
>  for (int i = 0; i < LENGTH(x); i++ )
>    Rprintf(\"%s\\n\", CHAR(STRING_ELT(x, i)));
>  return R_NilValue;
> "
>
> code2 <- "
>  for (int i = 0; i < LENGTH(x); i++ )
>    Rprintf(\"%s\\n\", CHAR(asChar(STRING_ELT(x, i))));
>  return R_NilValue;
> "
>
> setCMethod(c("p1","p2"), list(sig,sig), list(code1,code2))
>
>
> #----------------------------------------------------------
> p1(c("str1", "str2"))
> # str1
> # str2
> # NULL
>
> p2(c("str1", "str2"))
> # NA
> # NA
> # NULL
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From osklyar at ebi.ac.uk  Mon Jul 23 14:31:09 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 23 Jul 2007 13:31:09 +0100
Subject: [Rd] CHAR(STRING_ELT( - OK but CHAR(asChar(STRING_ELT( - not,
	why?
In-Reply-To: <Pine.LNX.4.64.0707231254420.30373@gannet.stats.ox.ac.uk>
References: <1185189270.6294.69.camel@dirac>
	<Pine.LNX.4.64.0707231254420.30373@gannet.stats.ox.ac.uk>
Message-ID: <1185193869.6294.77.camel@dirac>

Thank you Prof. Ripley. Funny enough after digging in the R sources I
was just writing a reply to my own question (in case someone else would
find it interesting) and it was approximately the same as what you
write. It just slipped from my attention initially.

O.


On Mon, 2007-07-23 at 13:22 +0100, Prof Brian Ripley wrote:
> I think you are asking why calling asChar on a CHARSXP gives NA_STRING. 
> In particular, the calls you mention *are* perfectly OK and work as 
> intended.
> 
> As barely documented in R-exts, asChar is designed for vector arguments: a 
> CHARSXP is not a vector.  It gives NA_STRING for invalid inputs.
> The asXXXX family of functions are designed to coerce as necessary user 
> inputs, and CHARSXPs are not visible at R level.
> 
> In general, with internal functions you are expected to read the code to 
> find out what they do before using them.
> 
> On Mon, 23 Jul 2007, Oleg Sklyar wrote:
> 
> > Any idea why CHAR(asChar(STRING_ELT( produces NA whereas
> > CHAR(STRING_ELT( gets a pointer to a string? It's generally expected
> > that STRING_ELT should already be a character,
> 
> It is required to be a CHARSXP, but 'character' usually refers to STRSXP.
> 
> > but why the coercion does not work? Here is a simple example (consistent 
> > over R2.5.1-R2.6 rev 42284, I didn't check earlier versions, but it used 
> > to be different in 2.4):
> 
> There is no R '2.4', but the behaviour of asChar was the same in R 2.4.0
> except for the adding of SYMSXP at
> 
> -------------
> r40358 | maechler | 2007-01-04 11:07:04 +0000 (Thu, 04 Jan 2007) | 1 line
> 
> eliminate CHAR_STAR in methods/src/ as per old "todo"
> -------------
> 
> which message does not help me at all.  Perhaps Martin can explain?
> 
> 
> > install.packages("inline")
> >
> > library(inline)
> >
> > sig <- signature(x="character")
> > code1 <- "
> >  for (int i = 0; i < LENGTH(x); i++ )
> >    Rprintf(\"%s\\n\", CHAR(STRING_ELT(x, i)));
> >  return R_NilValue;
> > "
> >
> > code2 <- "
> >  for (int i = 0; i < LENGTH(x); i++ )
> >    Rprintf(\"%s\\n\", CHAR(asChar(STRING_ELT(x, i))));
> >  return R_NilValue;
> > "
> >
> > setCMethod(c("p1","p2"), list(sig,sig), list(code1,code2))
> >
> >
> > #----------------------------------------------------------
> > p1(c("str1", "str2"))
> > # str1
> > # str2
> > # NULL
> >
> > p2(c("str1", "str2"))
> > # NA
> > # NA
> > # NULL
> >
> >
> >
> 
-- 
Dr. Oleg Sklyar * EBI-EMBL, Cambridge CB10 1SD, UK * +441223494466


From sfalcon at fhcrc.org  Mon Jul 23 19:26:13 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 23 Jul 2007 10:26:13 -0700
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <Pine.GSO.4.56.0707221129070.22444@durian.statsci.com> (Bill
	Dunlap's message of "Sun, 22 Jul 2007 11:41:51 -0700 (PDT)")
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
	<971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
	<m24pjxcg9f.fsf@ziti.local>
	<Pine.GSO.4.56.0707221129070.22444@durian.statsci.com>
Message-ID: <m2zm1n9glm.fsf@ziti.local>

Bill Dunlap <bill at insightful.com> writes:
> With environments, if you use a prime number for the size
> you get considerably better results.  E.g.,

> Perhaps new.env() should push the requested size up
> to the next prime by default.

Perhaps.  I think we should also investigate other hashing functions
since computing the next prime and doing so for resizes will take
longer than not having to do it and it will add complexity to the
code.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From sfalcon at fhcrc.org  Mon Jul 23 19:29:43 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 23 Jul 2007 10:29:43 -0700
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <46A48CF0.6070407@wald.ucdavis.edu> (Duncan Temple Lang's message
	of "Mon, 23 Jul 2007 04:11:44 -0700")
References: <m28x99lbd0.fsf@ziti.fhcrc.org> <46A48CF0.6070407@wald.ucdavis.edu>
Message-ID: <m2vecb9gfs.fsf@ziti.local>

Duncan Temple Lang <duncan at wald.ucdavis.edu> writes:
> The HashFunc typedef in hashfuncs.h would be more flexible  if it
> took an additional argument of type void * to allow for user
> defined data.  Alternatively, it might take the hash table
> object itself.  The function might want to do some
> updating of the table itself, or look at some table (e.g. for perfect
> hashing).  And if we had a place to provide additional information, it
> is easy to allow the hash function object to be an R function.

Worth considering.  I don't think perfect hashing is in scope here,
but would need to give it more thought -- seems to me that perfect
hashing would be better served by something separate.

> Also, you are using a "global" table of hash functions
> (i.e. Dict_HashFunctions) and looking up the C routine using
> GET_HASHFUN
> which is tied to the integer indexing for this global table.
> Why not use the C routines directly from R, i.e. using
> getNativeSymbolInfo and pass this from R to the newly created
> dict.  This avoids the lookup, the global table and makes things
> extensible with routines in packages and simply extends to allowing
> R functions to be passed instead of C routines.
> It also removes the need to synchronize the labeling system in
> R and in C, i.e. that 0L corresponds to PJW. The reliance on
> synchronized names rather than direct handles is unnecessary
> although widely used in S/R code.

Why not?  Only because I didn't think of it ;-)

> I'm more than happy to give some code to illustrate what I mean
> more precisely if you'd like it.

Sure.  At the same time, I'm a bit hesitant to invest further in dict
until I get a sense of whether or not it might actually be useful to
people.  It's main use may turn out to be for investigating hash
functions behavior and for a test tool it may be sufficient as-is.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From pinard at iro.umontreal.ca  Mon Jul 23 23:58:36 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Mon, 23 Jul 2007 17:58:36 -0400
Subject: [Rd] R 2.5.1 - typo in ?'::'
Message-ID: <20070723215836.GA5473@phenix.progiciels-bpi.ca>

Within ?'::' output, just before "See Also:", "environent" might be 
a misspelling of "environment".

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From s.blomberg1 at uq.edu.au  Tue Jul 24 01:05:29 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 24 Jul 2007 09:05:29 +1000
Subject: [Rd] postscript bug? (PR#9803)
In-Reply-To: <46A484A6.40606@biostat.ku.dk>
References: <20070723101039.8371165982@slim.kubism.ku.dk>
	<46A484A6.40606@biostat.ku.dk>
Message-ID: <1185231929.14498.0.camel@sib-sblomber01d.sib.uq.edu.au>

D'oh!

Simon.

On Mon, 2007-07-23 at 12:36 +0200, Peter Dalgaard wrote:
> s.blomberg1 at uq.edu.au wrote:
> > postscript() produces files that are not encoded as eps, according to
> > the standard. Hence, word processors such as OpenOffice and AbiWord do
> > not recognise the files as eps. See
> > http://www.postscript.org/FAQs/language/node80.html
> >
> > The problem is in the first line of the postscript file: The header is
> > wrong. It should be:
> >
> > %!PS-Adobe-3.0 EPSF-3.0
> >
> > whereas postscript() produces:
> >
> > %!PS-Adobe-3.0
> >
> > The following code replicates the problem:
> >
> > x <- rnorm(10)
> > y <- rnorm(10)
> > postscript("test.eps")
> > plot(x,y)
> > dev.off()
> >
> > # Now try importing test.eps into your favorite word processor.
> >
> > # Now edit test.eps and change the header to the correct header above, 
> > and try importing the file again. Works! (This took me a couple of hours
> > of hair-pulling to figure out. I sure hope it is a genuine bug. :-) )
> >   
> It isn't a bug. It is as it should be, because a plot file with multiple
> pages cannot be EPS.
> 
> Try reading the help page for postscript again, this time ( ;-) ) paying
> attention to the 'onefile' argument.
> 
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From maechler at stat.math.ethz.ch  Tue Jul 24 09:34:50 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Jul 2007 09:34:50 +0200
Subject: [Rd] CHAR(STRING_ELT( - OK but CHAR(asChar(STRING_ELT( - not,
	why?
In-Reply-To: <Pine.LNX.4.64.0707231254420.30373@gannet.stats.ox.ac.uk>
References: <1185189270.6294.69.camel@dirac>
	<Pine.LNX.4.64.0707231254420.30373@gannet.stats.ox.ac.uk>
Message-ID: <18085.43930.736077.332525@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 23 Jul 2007 13:22:16 +0100 (BST) writes:


    BDR> I think you are asking why calling asChar on a CHARSXP gives NA_STRING. 
    BDR> In particular, the calls you mention *are* perfectly OK and work as 
    BDR> intended.

    BDR> As barely documented in R-exts, asChar is designed for vector arguments: a 
    BDR> CHARSXP is not a vector.  It gives NA_STRING for invalid inputs.
    BDR> The asXXXX family of functions are designed to coerce as necessary user 
    BDR> inputs, and CHARSXPs are not visible at R level.

    BDR> In general, with internal functions you are expected to
    BDR> read the code to find out what they do before using
    BDR> them.

[..............]


    BDR> There is no R '2.4', but the behaviour of asChar was the same in R 2.4.0
    BDR> except for the adding of SYMSXP at

    BDR> -------------
    BDR> r40358 | maechler | 2007-01-04 11:07:04 +0000 (Thu, 04 Jan 2007) | 1 line

    BDR> eliminate CHAR_STAR in methods/src/ as per old "todo"
    BDR> -------------

    BDR> which message does not help me at all.  Perhaps Martin can explain?

I had to " svn diff -r40357:40358 " to see :

What I did was to basically add

 	else if(TYPEOF(x) == SYMSXP)
 	    return PRINTNAME(x);

to asChar()  which allowed to eliminate a macro and a similar if() 
in C code from methods where there's been a long standing "TODO"
about this.

The only change this could have was to *not* return an NA
in the 'symbol/name' cases it gave NA before.

Martin


From bates at stat.wisc.edu  Tue Jul 24 15:44:49 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 24 Jul 2007 08:44:49 -0500
Subject: [Rd] Changes in the MEMSS package (data sets from Pinheiro and
	Bates, 2000, without the groupedData classes)
Message-ID: <40e66e0b0707240644y3f6b05e3ib19a18d1ae74feee@mail.gmail.com>

Some time ago Deepayan and I created a package called MEMSS for the
data sets from the nlme package  as data frames but not groupedData
objects.  Because of advances that Deepayan has made in lattice
graphics many of the specialized plotting methods for the groupedData
objects are no longer needed.  It is easier and less confusing to
store these data sets as data frames rather than as groupedData
objects.

I propose making two further changes in these objects.  Those objects
typically had factors converted to ordered factors in an artificial
way and I plan to revert them to factors.  Also, I will relabel any
factors with (26 or fewer) numeric levels with letters and to remove
the "ginfo" attribute.

Please tell me if this will cause you hardship because you have used
these data sets in your work and depend on the current formulation.


From ggrothendieck at gmail.com  Tue Jul 24 16:57:48 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 24 Jul 2007 10:57:48 -0400
Subject: [Rd] Changes in the MEMSS package (data sets from Pinheiro and
	Bates, 2000, without the groupedData classes)
In-Reply-To: <40e66e0b0707240644y3f6b05e3ib19a18d1ae74feee@mail.gmail.com>
References: <40e66e0b0707240644y3f6b05e3ib19a18d1ae74feee@mail.gmail.com>
Message-ID: <971536df0707240757m2192b58cg1d9c0069dc5b8dea@mail.gmail.com>

Does this include datasets such as CO2 and ChickWeight
which are in the datasets package?

Could you post a list of the specific datasets you are referring to
so there is no confusion what this is about.

On 7/24/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> Some time ago Deepayan and I created a package called MEMSS for the
> data sets from the nlme package  as data frames but not groupedData
> objects.  Because of advances that Deepayan has made in lattice
> graphics many of the specialized plotting methods for the groupedData
> objects are no longer needed.  It is easier and less confusing to
> store these data sets as data frames rather than as groupedData
> objects.
>
> I propose making two further changes in these objects.  Those objects
> typically had factors converted to ordered factors in an artificial
> way and I plan to revert them to factors.  Also, I will relabel any
> factors with (26 or fewer) numeric levels with letters and to remove
> the "ginfo" attribute.
>
> Please tell me if this will cause you hardship because you have used
> these data sets in your work and depend on the current formulation.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bates at stat.wisc.edu  Tue Jul 24 17:31:15 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 24 Jul 2007 10:31:15 -0500
Subject: [Rd] Changes in the MEMSS package (data sets from Pinheiro and
	Bates, 2000, without the groupedData classes)
In-Reply-To: <971536df0707240757m2192b58cg1d9c0069dc5b8dea@mail.gmail.com>
References: <40e66e0b0707240644y3f6b05e3ib19a18d1ae74feee@mail.gmail.com>
	<971536df0707240757m2192b58cg1d9c0069dc5b8dea@mail.gmail.com>
Message-ID: <40e66e0b0707240831x4e55d448yf2869a62b96765c7@mail.gmail.com>

On 7/24/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Does this include datasets such as CO2 and ChickWeight
> which are in the datasets package?

> Could you post a list of the specific datasets you are referring to
> so there is no confusion what this is about.

I am only referring to the datasets in the MEMSS package.  There will
be CO2, ChickWeight, Theoph, etc. datasets in the MEMSS package
without the groupedData classes.  However, the versions in the
datasets package will stay as they are unless and until R-core decides
to change them.

Having datasets in the datasets package and in the MEMSS package with
the same name will produce a warning when you attach the MEMSS
package.  However, I generally use datasets with a call like

data(Rail, package = "MEMSS")

which doesn't cause a warning (it is assumed that if you are this
explicit about the data set then you probably want exactly that
version and haven't accidently overridden the other).

The bottom line is that unless you have been in the habit of attaching
the MEMSS package or getting data sets from it as above then you won't
notice any difference.

> On 7/24/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> > Some time ago Deepayan and I created a package called MEMSS for the
> > data sets from the nlme package  as data frames but not groupedData
> > objects.  Because of advances that Deepayan has made in lattice
> > graphics many of the specialized plotting methods for the groupedData
> > objects are no longer needed.  It is easier and less confusing to
> > store these data sets as data frames rather than as groupedData
> > objects.
> >
> > I propose making two further changes in these objects.  Those objects
> > typically had factors converted to ordered factors in an artificial
> > way and I plan to revert them to factors.  Also, I will relabel any
> > factors with (26 or fewer) numeric levels with letters and to remove
> > the "ginfo" attribute.
> >
> > Please tell me if this will cause you hardship because you have used
> > these data sets in your work and depend on the current formulation.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From ggrothendieck at gmail.com  Tue Jul 24 18:22:55 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 24 Jul 2007 12:22:55 -0400
Subject: [Rd] Changes in the MEMSS package (data sets from Pinheiro and
	Bates, 2000, without the groupedData classes)
In-Reply-To: <40e66e0b0707240831x4e55d448yf2869a62b96765c7@mail.gmail.com>
References: <40e66e0b0707240644y3f6b05e3ib19a18d1ae74feee@mail.gmail.com>
	<971536df0707240757m2192b58cg1d9c0069dc5b8dea@mail.gmail.com>
	<40e66e0b0707240831x4e55d448yf2869a62b96765c7@mail.gmail.com>
Message-ID: <971536df0707240922u29ac8c72h38401a294e19bb5c@mail.gmail.com>

On a related note CO2 and ChickWeight in datasets have nlme
specific attributes so either those datasets themselves should be
moved to nlme or the nlme specific attributes removed in datasets
as well.

On 7/24/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 7/24/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Does this include datasets such as CO2 and ChickWeight
> > which are in the datasets package?
>
> > Could you post a list of the specific datasets you are referring to
> > so there is no confusion what this is about.
>
> I am only referring to the datasets in the MEMSS package.  There will
> be CO2, ChickWeight, Theoph, etc. datasets in the MEMSS package
> without the groupedData classes.  However, the versions in the
> datasets package will stay as they are unless and until R-core decides
> to change them.
>
> Having datasets in the datasets package and in the MEMSS package with
> the same name will produce a warning when you attach the MEMSS
> package.  However, I generally use datasets with a call like
>
> data(Rail, package = "MEMSS")
>
> which doesn't cause a warning (it is assumed that if you are this
> explicit about the data set then you probably want exactly that
> version and haven't accidently overridden the other).
>
> The bottom line is that unless you have been in the habit of attaching
> the MEMSS package or getting data sets from it as above then you won't
> notice any difference.
>
> > On 7/24/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> > > Some time ago Deepayan and I created a package called MEMSS for the
> > > data sets from the nlme package  as data frames but not groupedData
> > > objects.  Because of advances that Deepayan has made in lattice
> > > graphics many of the specialized plotting methods for the groupedData
> > > objects are no longer needed.  It is easier and less confusing to
> > > store these data sets as data frames rather than as groupedData
> > > objects.
> > >
> > > I propose making two further changes in these objects.  Those objects
> > > typically had factors converted to ordered factors in an artificial
> > > way and I plan to revert them to factors.  Also, I will relabel any
> > > factors with (26 or fewer) numeric levels with letters and to remove
> > > the "ginfo" attribute.
> > >
> > > Please tell me if this will cause you hardship because you have used
> > > these data sets in your work and depend on the current formulation.
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>


From hb at stat.berkeley.edu  Tue Jul 24 18:58:04 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 24 Jul 2007 18:58:04 +0200
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <m2zm1n9glm.fsf@ziti.local>
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
	<971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
	<m24pjxcg9f.fsf@ziti.local>
	<Pine.GSO.4.56.0707221129070.22444@durian.statsci.com>
	<m2zm1n9glm.fsf@ziti.local>
Message-ID: <59d7961d0707240958x65707eafkad22ac3056f6ea21@mail.gmail.com>

On 7/23/07, Seth Falcon <sfalcon at fhcrc.org> wrote:
> Bill Dunlap <bill at insightful.com> writes:
> > With environments, if you use a prime number for the size
> > you get considerably better results.  E.g.,
>
> > Perhaps new.env() should push the requested size up
> > to the next prime by default.
>
> Perhaps.  I think we should also investigate other hashing functions
> since computing the next prime and doing so for resizes will take
> longer than not having to do it and it will add complexity to the
> code.

An alternative is to hard-wiring primes within a reasonable range:

  http://primes.utm.edu/lists/small/millions/
  http://www.math.utah.edu/~pa/math/p10000.html

Maybe primes close to 2^n are good enough for this problem:

  http://primes.utm.edu/lists/2small/

Just my $.02

/Henrik



>
> + seth
>
> --
> Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
> http://bioconductor.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue Jul 24 19:32:47 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Jul 2007 19:32:47 +0200
Subject: [Rd] dict package: dictionary data structure for R
In-Reply-To: <59d7961d0707240958x65707eafkad22ac3056f6ea21@mail.gmail.com>
References: <m28x99lbd0.fsf@ziti.fhcrc.org>
	<971536df0707211743t117cf29cx9b745f3f9d6a0dfd@mail.gmail.com>
	<m24pjxcg9f.fsf@ziti.local>
	<Pine.GSO.4.56.0707221129070.22444@durian.statsci.com>
	<m2zm1n9glm.fsf@ziti.local>
	<59d7961d0707240958x65707eafkad22ac3056f6ea21@mail.gmail.com>
Message-ID: <18086.14271.939886.93494@stat.math.ethz.ch>

>>>>> "HenrikB" == Henrik Bengtsson <hb at stat.berkeley.edu>
>>>>>     on Tue, 24 Jul 2007 18:58:04 +0200 writes:

    HenrikB> On 7/23/07, Seth Falcon <sfalcon at fhcrc.org> wrote:
    >> Bill Dunlap <bill at insightful.com> writes:
    >> > With environments, if you use a prime number for the size
    >> > you get considerably better results.  E.g.,
    >> 
    >> > Perhaps new.env() should push the requested size up
    >> > to the next prime by default.
    >> 
    >> Perhaps.  I think we should also investigate other hashing functions
    >> since computing the next prime and doing so for resizes will take
    >> longer than not having to do it and it will add complexity to the
    >> code.

    HenrikB> An alternative is to hard-wiring primes within a reasonable range:

    HenrikB> http://primes.utm.edu/lists/small/millions/
    HenrikB> http://www.math.utah.edu/~pa/math/p10000.html

    HenrikB> Maybe primes close to 2^n are good enough for this problem:

    HenrikB> http://primes.utm.edu/lists/2small/

Yes, I had a similar thought....

Note that you don't need web sites for prime numbers:

my R   factorization  utilities I had mentioned a few times,
e.g., here
      http://tolstoy.newcastle.edu.au/R/help/05/01/10007.html

can give the first few hundred thousand primes quickly enough:

  > source("ftp://stat.ethz.ch/U/maechler/R/prime-numbers-fn.R")

  > system.time(PS3 <- prime.sieve(prime.sieve(prime.sieve())))
     user  system elapsed 
    0.446   0.006   0.452 

  > head(PS3, 20)
   [1]  2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71
  > tail(PS3, 20)
   [1] 273233 273253 273269 273271 273281 273283 273289 273311 273313 273323
  [11] 273349 273359 273367 273433 273457 273473 273503 273517 273521 273527
  > 

There are more prime / factorization utilities in that simple R
source file, but
as I say there, one should really use C code to do this;
but then R has become so fast ...

Martin Maechler, ETH Zurich

    HenrikB> Just my $.02

    HenrikB> /Henrik


From mwelinder at gmail.com  Tue Jul 24 17:18:09 2007
From: mwelinder at gmail.com (mwelinder at gmail.com)
Date: Tue, 24 Jul 2007 17:18:09 +0200 (CEST)
Subject: [Rd] Accuracy of qt for df=1 (PR#9804)
Message-ID: <20070724151809.85C7665981@slim.kubism.ku.dk>

Full_Name: Morten Welinder
Version: 2.2.0
OS: Linux
Submission from: (NULL) (216.223.241.229)


The qt function for df=1 is implemented as...

    q = - tan((P+1) * M_PI_2);

Adding 1 kills accuracy for P near 0.  A better way is to use

   q = cot(P * M_PI_2);
or
   q = 1/tan(P * M_PI_2);


From savicky at cs.cas.cz  Wed Jul 25 09:03:21 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 25 Jul 2007 09:03:21 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070713203735.GA18016@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
	<316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>
	<20070713203735.GA18016@cs.cas.cz>
Message-ID: <20070725070320.GA20948@cs.cas.cz>

I would like to suggest a patch against R-devel-2007-07-24, which
modifies function sweep by including a warning, if dim(STATS) is not
consistent with dim(x)[MARGIN]. If check.margin=FALSE, the simple test whether
prod(dim(x)[MARGIN]) is a multiple of length(STATS) is performed.
If check.margin=TRUE, then a more restrictive test is used, but a limited
recycling is still allowed without warning. Besides generating a warning
in some situations, there is no other change in the behavior of sweep.
The patch is:

--- R-devel_2007-07-24/src/library/base/R/sweep.R	2007-01-04 17:51:53.000000000 +0100
+++ R-devel_2007-07-24-sweep/src/library/base/R/sweep.R	2007-07-24 10:56:18.000000000 +0200
@@ -1,7 +1,21 @@
-sweep <- function(x, MARGIN, STATS, FUN = "-", ...)
+sweep <- function(x, MARGIN, STATS, FUN = "-", check.margin=FALSE, ...)
 {
     FUN <- match.fun(FUN)
     dims <- dim(x)
+    if (check.margin) {
+        dimmargin <- dims[MARGIN]
+        dimmargin <- dimmargin[dimmargin > 1]
+        dimstats <- if (is.null(dim(STATS))) length(STATS) else dim(STATS)
+        dimstats <- dimstats[dimstats > 1]
+        if (length(dimstats) > length(dimmargin) ||
+            any(dimstats != dimmargin[seq(along.with=dimstats)]))
+            warning("length(STATS) or dim(STATS) do not match dim(x)[MARGIN]")
+    } else if (prod(dims[MARGIN]) %% length(STATS) != 0) {
+        if (length(MARGIN) == 1)
+            warning("dim(x)[MARGIN] is not a multiple of length(STATS)")
+        else
+            warning("prod(dim(x)[MARGIN]) is not a multiple of length(STATS)")
+    }
     perm <- c(MARGIN, (1:length(dims))[ - MARGIN])
     FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
 }

The patch uses the default check.margin=FALSE, since this is more backward
compatible. Changing the default to check.margin=TRUE would also be fine
with me and also with Ben Bolker, who told me this in a separate email.

Let me include more comments on the stricter test. If check.margin=TRUE,
then the patch tests whether (after deleting possible dimensions with
only one level) dim(STATS) is a prefix of dim(x)[MARGIN]. Hence, for example,
if dim(x)[MARGIN] = c(k1,k2), the cases
  length(STATS) = 1,
  dim(STATS) = k1,
  dim(STATS) = NULL and length(STATS) = k1,
  dim(STATS) = c(k1,k2)
are accepted without warning. On the other hand, if k1 != k2, then,
for example, dim(STATS)= k2, dim(STATS) = c(k2,k1) generate
a warning, although the simple divisibility condition
   length(STATS) divides prod(dim(x)[MARGIN])
is satisfied. The warning is generated, since in the last two cases,
recycling produces incorrect or at least suspicious result.

In the simplest case, when length(MARGIN)=1 and STATS is a vector,
the cases accepted by the stricter test without warning are exactly the
following two: length(STATS) = 1, length(STATS) = dim(x)[MARGIN].

I tested the patch using the script
  http://www.cs.cas.cz/~savicky/R-devel/verify_sweep1.R
Ben Bolker also tested the patch in his environment.

I appreciate to know the opinion of R core developers on this patch.
Thank you in advance.

Petr.


From maechler at stat.math.ethz.ch  Wed Jul 25 09:57:26 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 25 Jul 2007 09:57:26 +0200 (CEST)
Subject: [Rd] Accuracy of qt for df=1 (PR#9804)
Message-ID: <20070725075726.1FE12667E6@slim.kubism.ku.dk>

>>>>> "MW" == Morten Welinder <mwelinder at gmail.com>
>>>>>     on Tue, 24 Jul 2007 17:18:09 +0200 (CEST) writes:

    MW> Full_Name: Morten Welinder
    MW> Version: 2.2.0
    MW> OS: Linux
    MW> Submission from: (NULL) (216.223.241.229)


    MW> The qt function for df=1 is implemented as...

    MW> q = - tan((P+1) * M_PI_2);

    MW> Adding 1 kills accuracy for P near 0.  A better way is to use

    MW> q = cot(P * M_PI_2);
    MW> or
    MW> q = 1/tan(P * M_PI_2);


Yes, indeed, thanks a lot, Morten!!

     ((BTW: you should really upgrade your version of R))

Best regards,
Martin


From a.manners at sib.uq.edu.au  Wed Jul 25 08:42:52 2007
From: a.manners at sib.uq.edu.au (a.manners at sib.uq.edu.au)
Date: Wed, 25 Jul 2007 08:42:52 +0200 (CEST)
Subject: [Rd] anova tables in survreg (PR#9806)
Message-ID: <20070725064252.012696598A@slim.kubism.ku.dk>

Full_Name: Andrew Manners
Version: 2.5.1
OS: windows xp prof 2003
Submission from: (NULL) (130.102.0.177)



To whom it may concern,

I'm trying to get an ANOVA table within survreg but it always produces NA's in
the p-value, regardless of the data set. The data set below comes from Tableman
and Kim 2004. I had the same problem on a number of my own data sets. I searched
the R site for others that have had this problem and it appears that at least
one has: Ronaldo Reis Junior <chrysopa> wrote a couple of messages but there
were never replies (search using "survreg" and "anova" brings up the two
relevant threads).

If this problem is unlikely to be fixed soon can you please let me know how to
install R 2.3.1? I've downloaded the zip but can't seem to get it
installed...I'm sure it's a matter of knowing which button to press,
nevertheless I can't find that button.

Thanks for your help,

Andrew

> motor<-read.table("motorette.csv",header=TRUE,
sep=",",na.strings="NA",dec=".",strip.white=TRUE)
> 
> motor
    X time status temp    x
1  11 1764      1  170 2.26
2  12 2772      1  170 2.26
3  13 3444      1  170 2.26
4  14 3542      1  170 2.26
5  15 3780      1  170 2.26
6  16 4860      1  170 2.26
7  17 5196      1  170 2.26
8  18 5448      0  170 2.26
9  19 5448      0  170 2.26
10 20 5448      0  170 2.26
11 21  408      1  190 2.16
12 22  408      1  190 2.16
13 23 1344      1  190 2.16
14 24 1344      1  190 2.16
15 25 1440      1  190 2.16
16 26 1680      0  190 2.16
17 27 1680      0  190 2.16
18 28 1680      0  190 2.16
19 29 1680      0  190 2.16
20 30 1680      0  190 2.16
21 31  408      1  220 2.03
22 32  408      1  220 2.03
23 33  504      1  220 2.03
24 34  504      1  220 2.03
25 35  504      1  220 2.03
26 36  528      0  220 2.03
27 37  528      0  220 2.03
28 38  528      0  220 2.03
29 39  528      0  220 2.03
30 40  528      0  220 2.03
> 
> mot.sreg<-survreg(Surv(time,status)~x,dist="weibull",data=motor)
> anova(mot.sreg)
     Df Deviance Resid. Df    -2*LL P(>|Chi|)
NULL NA       NA        28 311.3634        NA 
x    -1 22.77348        27 288.5900        NA #this is the problem...
> summary(mot.sreg)

Call:
survreg(formula = Surv(time, status) ~ x, data = motor, dist = "weibull")
             Value Std. Error     z        p
(Intercept) -11.83      1.957 -6.04 1.50e-09
x             9.00      0.901  9.99 1.73e-23  #works fine
Log(scale)   -1.02      0.221 -4.64 3.49e-06

Scale= 0.359 

Weibull distribution
Loglik(model)= -144.3   Loglik(intercept only)= -155.7
        Chisq= 22.77 on 1 degrees of freedom, p= 1.8e-06 
Number of Newton-Raphson Iterations: 7 
n= 30


From pgilbert at bank-banque-canada.ca  Wed Jul 25 16:31:06 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 25 Jul 2007 10:31:06 -0400
Subject: [Rd] [R] aggregate.ts
In-Reply-To: <Pine.LNX.4.44.0707250237430.16266-100000@disco.wu-wien.ac.at>
References: <Pine.LNX.4.44.0707250237430.16266-100000@disco.wu-wien.ac.at>
Message-ID: <46A75EAA.6020405@bank-banque-canada.ca>

(moved from r-help)

Achim Zeileis wrote:

>On Wed, 25 Jul 2007, laimonis wrote:
>
>  
>
>>Consider the following scrap of code:
>>    
>>
>
>...slightly modified to
>  x1 <- ts(1:24, start = c(2000, 10), freq = 12)
>  x2 <- ts(1:24, start = c(2000, 11), freq = 12)
>
>and then
>  y1 <- aggregate(x1, nfreq = 4)
>gives the desired result while
>  y2 <- aggregate(x2, nfreq = 4)
>probably does not what you would like it to do. 
>

I've been caught by this before, and complained before.  It does not do 
what most people that work with economic time series would expect.  (One 
might argue that not all time series are economic, but other time series 
don't usually fit with ts very well.)  At the very least aggregate 
should issue a warning.  Quarterly observations are for quarters of the 
year, so just arbitrarily grouping in 3 beginning with the first 
observation is *extremely* misleading, even if it is documented.

[ BTW, there is a bug in the print method here (R-2.5.1 on Linux) :
 >   y2 <- aggregate(x2, nfreq = 4) 
 >
 > y2
Error in rep.int("", start.pad) : invalid number of copies in rep.int()
 > traceback()
5: rep.int("", start.pad)
4: as.vector(data)
3: matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",
       end.pad)), nc = fr.x, byrow = TRUE, dimnames = list(dn1,
       dn2))
2: print.ts(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
1: print(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
]

....

>Currently, the "zoo" implementation allows this: Coercing back and forth
>gives:
>  library("zoo")
>  z1 <- as.ts(aggregate(as.zoo(x1), as.yearqtr, sum))
>  z2 <- as.ts(aggregate(as.zoo(x2), as.yearqtr, sum))
>  
>
This is better, but still potentially misleading. I would prefer a 
default  NA when only some of the observations are available for a 
quarter  (and the syntax is a bit cumbersome for something one needs to 
do fairly often).

Paul

>where z1 is identical to y1, and z2 is what you probably want.
>
>hth,
>Z
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>  
>
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From Achim.Zeileis at wu-wien.ac.at  Wed Jul 25 17:02:13 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Wed, 25 Jul 2007 17:02:13 +0200 (CEST)
Subject: [Rd] [R] aggregate.ts
In-Reply-To: <46A75EAA.6020405@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.44.0707251640420.16266-100000@disco.wu-wien.ac.at>

Paul,

thanks for the feedback. Concerning the zoo side:

> >Currently, the "zoo" implementation allows this: Coercing back and forth
> >gives:
> >  library("zoo")
> >  z1 <- as.ts(aggregate(as.zoo(x1), as.yearqtr, sum))
> >  z2 <- as.ts(aggregate(as.zoo(x2), as.yearqtr, sum))
> >
> >
> This is better, but still potentially misleading. I would prefer a
> default  NA when only some of the observations are available for a
> quarter

In such situations, I either extend the series first to a completely
regular time grid, or modify the function that I use for aggregation to do
exactly what I want it to do.

> (and the syntax is a bit cumbersome for something one needs to
> do fairly often).

I don't think
  aggregate(z, as.yearqtr, sum)
is really cumbersome. And the rest is just coercion back and forth between
"ts" and "zoo"/"zooreg" (which can't be much easier, I guess).
Z


From ggrothendieck at gmail.com  Wed Jul 25 17:01:34 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 25 Jul 2007 11:01:34 -0400
Subject: [Rd] [R] aggregate.ts
In-Reply-To: <46A75EAA.6020405@bank-banque-canada.ca>
References: <Pine.LNX.4.44.0707250237430.16266-100000@disco.wu-wien.ac.at>
	<46A75EAA.6020405@bank-banque-canada.ca>
Message-ID: <971536df0707250801u333d29j1819370d2551a982@mail.gmail.com>

On 7/25/07, Paul Gilbert <pgilbert at bank-banque-canada.ca> wrote:
> (moved from r-help)
>
> Achim Zeileis wrote:
>
> >On Wed, 25 Jul 2007, laimonis wrote:
> >
> >
> >
> >>Consider the following scrap of code:
> >>
> >>
> >
> >...slightly modified to
> >  x1 <- ts(1:24, start = c(2000, 10), freq = 12)
> >  x2 <- ts(1:24, start = c(2000, 11), freq = 12)
> >
> >and then
> >  y1 <- aggregate(x1, nfreq = 4)
> >gives the desired result while
> >  y2 <- aggregate(x2, nfreq = 4)
> >probably does not what you would like it to do.
> >
>
> I've been caught by this before, and complained before.  It does not do
> what most people that work with economic time series would expect.  (One
> might argue that not all time series are economic, but other time series
> don't usually fit with ts very well.)  At the very least aggregate
> should issue a warning.  Quarterly observations are for quarters of the
> year, so just arbitrarily grouping in 3 beginning with the first
> observation is *extremely* misleading, even if it is documented.
>
> [ BTW, there is a bug in the print method here (R-2.5.1 on Linux) :
>  >   y2 <- aggregate(x2, nfreq = 4)
>  >
>  > y2
> Error in rep.int("", start.pad) : invalid number of copies in rep.int()
>  > traceback()
> 5: rep.int("", start.pad)
> 4: as.vector(data)
> 3: matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",
>       end.pad)), nc = fr.x, byrow = TRUE, dimnames = list(dn1,
>       dn2))
> 2: print.ts(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
> 1: print(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
> ]
>
> ....
>
> >Currently, the "zoo" implementation allows this: Coercing back and forth
> >gives:
> >  library("zoo")
> >  z1 <- as.ts(aggregate(as.zoo(x1), as.yearqtr, sum))
> >  z2 <- as.ts(aggregate(as.zoo(x2), as.yearqtr, sum))
> >
> >
> This is better, but still potentially misleading. I would prefer a
> default  NA when only some of the observations are available for a
> quarter  (and the syntax is a bit cumbersome for something one needs to
> do fairly often).
>

That can be readily handled with a custom sum function:

sum.na <- function(x, width, ...) {
	if (!missing(width) && length(x) != width) x <- NA * x
	sum(x, ...)
}

> as.ts(aggregate(as.zoo(x2), as.yearqtr, sum.na, width = 3))
     Qtr1 Qtr2 Qtr3 Qtr4
2000                  NA
2001   12   21   30   39
2002   48   57   66   NA


From jonathan.zhou at utoronto.ca  Wed Jul 25 17:35:57 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Wed, 25 Jul 2007 08:35:57 -0700 (PDT)
Subject: [Rd] Using R_MakeExternalPtr
Message-ID: <11785023.post@talk.nabble.com>


Hi all, 

I've been writing a package and I've run into a problem that I'm unsure how
to solve.  I am looking to pass a C++ class object to R so that it may be
passed back to another C++ function later on to be used.  I'm quite new to R
and this is my first time writing a package, so I hope you can bear with me.  

The following is how I create the class and use R_MakeExternalPtr().  This
occurs in a function called "soamInit": 
    Session* sesPtr = conPtr->createSession(attributes);
    void* temp = session;

    SEXP out = R_MakeExternalPtr(temp, R_NilValue, R_NilValue);
    return out;

The following is how I try to retrieve the class object in a different C++
function called "soamSubmit", where sesCon is the externalPtr : 
	void* temp = R_ExternalPtrAddr(sesCon);
        Session* sesPtr = reinterpret_cast<Session*>(temp);

The error I get when trying to run the R function is : 
 *** caught segfault ***
address 0x3, cause 'memory not mapped'

Traceback:
 1: .Call("soamSubmit", counter, sesCon, final.script, packages)
 2: soam.Rapply(x, tester, join.method = c, njobs = 2)

So it seems like a scoping problem to me, though I'm unsure how to solve it.  

-Jon
-- 
View this message in context: http://www.nabble.com/Using-R_MakeExternalPtr-tf4142904.html#a11785023
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Jul 25 17:54:14 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 25 Jul 2007 11:54:14 -0400
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11785023.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com>
Message-ID: <5947C8C0-9BD0-4DE0-9D2E-8E67BD4918C0@r-project.org>

Jon,

I suspect that you're leaving out some important details - please  
include your R code for inspection as the C++ code below seems ok  
(although you may want to show us the declarations as well). Also you  
may want to look into this with a debugger in case the segfault is  
actually in your C++ code due to some memory management issue.

Cheers,
Simon

On Jul 25, 2007, at 11:35 AM, Jonathan Zhou wrote:

>
> Hi all,
>
> I've been writing a package and I've run into a problem that I'm  
> unsure how
> to solve.  I am looking to pass a C++ class object to R so that it  
> may be
> passed back to another C++ function later on to be used.  I'm quite  
> new to R
> and this is my first time writing a package, so I hope you can bear  
> with me.
>
> The following is how I create the class and use R_MakeExternalPtr 
> ().  This
> occurs in a function called "soamInit":
>     Session* sesPtr = conPtr->createSession(attributes);
>     void* temp = session;
>
>     SEXP out = R_MakeExternalPtr(temp, R_NilValue, R_NilValue);
>     return out;
>
> The following is how I try to retrieve the class object in a  
> different C++
> function called "soamSubmit", where sesCon is the externalPtr :
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
>
> The error I get when trying to run the R function is :
>  *** caught segfault ***
> address 0x3, cause 'memory not mapped'
>
> Traceback:
>  1: .Call("soamSubmit", counter, sesCon, final.script, packages)
>  2: soam.Rapply(x, tester, join.method = c, njobs = 2)
>
> So it seems like a scoping problem to me, though I'm unsure how to  
> solve it.
>
> -Jon
> -- 
> View this message in context: http://www.nabble.com/Using- 
> R_MakeExternalPtr-tf4142904.html#a11785023
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From sfalcon at fhcrc.org  Wed Jul 25 18:01:18 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 25 Jul 2007 09:01:18 -0700
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11785023.post@talk.nabble.com> (Jonathan Zhou's message of "Wed,
	25 Jul 2007 08:35:57 -0700 (PDT)")
References: <11785023.post@talk.nabble.com>
Message-ID: <m2ps2gv5f5.fsf@ziti.local>

Jonathan Zhou <jonathan.zhou at utoronto.ca> writes:

> Hi all, 
>
> I've been writing a package and I've run into a problem that I'm unsure how
> to solve.  I am looking to pass a C++ class object to R so that it may be
> passed back to another C++ function later on to be used.  I'm quite new to R
> and this is my first time writing a package, so I hope you can bear with me.  
>
> The following is how I create the class and use R_MakeExternalPtr().  This
> occurs in a function called "soamInit": 
>     Session* sesPtr = conPtr->createSession(attributes);
>     void* temp = session;

It isn't clear from your example, are you sure that temp is valid at
this point?

>     SEXP out = R_MakeExternalPtr(temp, R_NilValue, R_NilValue);

I was expecting to see:

      SEXP out = R_MakeExternalPtr((void *)sesPtr, R_NilValue, R_NilValue);

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From hin-tak.leung at cimr.cam.ac.uk  Wed Jul 25 18:40:35 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 25 Jul 2007 17:40:35 +0100
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11785023.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com>
Message-ID: <46A77D03.5090607@cimr.cam.ac.uk>

As other has commented, without the rest/full of your code it is 
difficult to tell... I have a few suggestions though:

- it is obviously a memory-related issue. An external pointer is partly
allocated by R and partly allocated by you - you need to check both 
parts, and their individual usages.

- I think the part allocated by R is correct; you might need a few 
PROTECT() somewhere unrelated in "soamSubmit" as well, when you are 
playing R objects in C/C++... what I mean is, the external pointer
may be unrelated to your problem.

Jonathan Zhou wrote:
> Hi all, 
> 
> I've been writing a package and I've run into a problem that I'm unsure how
> to solve.  I am looking to pass a C++ class object to R so that it may be
> passed back to another C++ function later on to be used.  I'm quite new to R
> and this is my first time writing a package, so I hope you can bear with me.  
> 
> The following is how I create the class and use R_MakeExternalPtr().  This
> occurs in a function called "soamInit": 
>     Session* sesPtr = conPtr->createSession(attributes);
>     void* temp = session;
> 
>     SEXP out = R_MakeExternalPtr(temp, R_NilValue, R_NilValue);
>     return out;
> 
> The following is how I try to retrieve the class object in a different C++
> function called "soamSubmit", where sesCon is the externalPtr : 
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
> 
> The error I get when trying to run the R function is : 
>  *** caught segfault ***
> address 0x3, cause 'memory not mapped'
> 
> Traceback:
>  1: .Call("soamSubmit", counter, sesCon, final.script, packages)
>  2: soam.Rapply(x, tester, join.method = c, njobs = 2)
> 
> So it seems like a scoping problem to me, though I'm unsure how to solve it.  
> 
> -Jon


From jonathan.zhou at utoronto.ca  Wed Jul 25 18:53:36 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Wed, 25 Jul 2007 09:53:36 -0700 (PDT)
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11785023.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com>
Message-ID: <11786494.post@talk.nabble.com>


Hi all, 

Here is the R code function in where I called the two C++ and further below
are the 2 C++ functions I used to create the externalptr and use it : 

soam.Rapply <- function (x, func, ...,
                           join.method=cbind,
                           njobs,
                           batch.size=100,
                           packages=NULL,
                           savelist=NULL)
{
    if(missing(njobs))
        njobs <- max(1,ceiling(nrow(x)/batch.size))

    if(!is.matrix(x) && !is.data.frame(x))
        stop("x must be a matrix or data frame")

    if(njobs>1)
        {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
drop = FALSE])} else {rowSet <- list(x)}

    sesCon <- .Call("soamInit")

    script <- " "

    fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
    file(fname, open="w+")
    if(!is.null(savelist)) {
        dump(savelist, fname)
        script<-readLines(fname)
    }

    if(!is.null(packages))
    for(counter in 1:length(packages))
    {
        temp<-call("library", packages[counter], character.only=TRUE)
        dput(temp, fname)
        pack.call<-readLines(fname)
        script<-append(script, pack.call)
    }

    for(counter in 1:njobs)
    {
        caller <- paste("caller", counter, sep = "")
        soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
FUN=func), caller)
        dput(soam.call, fname)
        soam.call<-readLines(fname)

        temp<-append(script, soam.call)
        final.script = temp[1]
        for(count in 2:length(temp)){
            final.script<-paste(final.script, temp[count], "\n")}

        .Call("soamSubmit", counter, sesCon, final.script, packages)
    }

    .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())

    for(job in 1:njobs)
    {
        caller <- paste("result", job, sep = "")
        temp = dget(caller)
        if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
    }

    .Call("soamUninit")

    retval
}

*** Here are the 2 C++ functions: 

extern "C"
{
SEXP soamInit ()
{
    // Initialize the API
    SoamFactory::initialize();

    // Set up application specific information to be supplied to Symphony
    char appName[] = "SampleAppCPP";

    // Set up application authentication information using the default
security provider
    DefaultSecurityCallback securityCB("Guest", "Guest");

    // Connect to the specified application
    ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);

    // Set up session creation attributes
    SessionCreationAttributes attributes;
    attributes.setSessionName("mySession");
    attributes.setSessionType("ShortRunningTasks");
    attributes.setSessionFlags(SF_RECEIVE_SYNC);

    // Create a synchronous session
    Session* sesPtr = conPtr->createSession(attributes);

    SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);

    return out;
}
}

extern "C"
{
  void soamSubmit	(SEXP jobID,		//job ID
			 SEXP sesCon,		//session pointer
			 SEXP caller,			//objects
			 SEXP pack)			//packages
{
	char* savelist = CHAR(STRING_ELT(caller, 0));
	string strTemp = "";
	int job = INTEGER(jobID)[0];

	void* temp = R_ExternalPtrAddr(sesCon);
        Session* sesPtr = reinterpret_cast<Session*>(temp);

    // Create a message
	MyMessage inMsg(job, /*pack,*/ savelist);

    // Send it
    TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
}
}
-- 
View this message in context: http://www.nabble.com/Using-R_MakeExternalPtr-tf4142904.html#a11786494
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Jul 25 20:12:57 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 25 Jul 2007 14:12:57 -0400
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11786494.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com> <11786494.post@talk.nabble.com>
Message-ID: <BC5B0418-63BC-4027-BF19-B271520017AA@r-project.org>


On Jul 25, 2007, at 12:53 PM, Jonathan Zhou wrote:

> [snip]
> extern "C"
> {
>   void soamSubmit	(SEXP jobID,		//job ID

^^^ - this will definitely crash. All .Call functions must return  
SEXP, even if it is just R_NilValue;

Cheers,
Simon





> 			 SEXP sesCon,		//session pointer
> 			 SEXP caller,			//objects
> 			 SEXP pack)			//packages
> {
> 	char* savelist = CHAR(STRING_ELT(caller, 0));
> 	string strTemp = "";
> 	int job = INTEGER(jobID)[0];
>
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
>
>     // Create a message
> 	MyMessage inMsg(job, /*pack,*/ savelist);
>
>     // Send it
>     TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
> }
> }
> -- 
> View this message in context: http://www.nabble.com/Using- 
> R_MakeExternalPtr-tf4142904.html#a11786494
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jonathan.zhou at utoronto.ca  Wed Jul 25 20:26:42 2007
From: jonathan.zhou at utoronto.ca (Jonathan Zhou)
Date: Wed, 25 Jul 2007 11:26:42 -0700 (PDT)
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <46A77D03.5090607@cimr.cam.ac.uk>
References: <11785023.post@talk.nabble.com> <46A77D03.5090607@cimr.cam.ac.uk>
Message-ID: <11790985.post@talk.nabble.com>


Hi Hin-Tak,

Here is the R code function in where I called the two C++ and further below
are the 2 C++ functions I used to create the externalptr and use it :

soam.Rapply <- function (x, func, ...,
                          join.method=cbind,
                          njobs,
                          batch.size=100,
                          packages=NULL,
                          savelist=NULL)
{
   if(missing(njobs))
       njobs <- max(1,ceiling(nrow(x)/batch.size))

   if(!is.matrix(x) && !is.data.frame(x))
       stop("x must be a matrix or data frame")

   if(njobs>1)
       {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
drop = FALSE])} else {rowSet <- list(x)}

   sesCon <- .Call("soamInit")

   script <- " "

   fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
   file(fname, open="w+")
   if(!is.null(savelist)) {
       dump(savelist, fname)
       script<-readLines(fname)
   }

   if(!is.null(packages))
   for(counter in 1:length(packages))
   {
       temp<-call("library", packages[counter], character.only=TRUE)
       dput(temp, fname)
       pack.call<-readLines(fname)
       script<-append(script, pack.call)
   }

   for(counter in 1:njobs)
   {
       caller <- paste("caller", counter, sep = "")
       soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
FUN=func), caller)
       dput(soam.call, fname)
       soam.call<-readLines(fname)

       temp<-append(script, soam.call)
       final.script = temp[1]
       for(count in 2:length(temp)){
           final.script<-paste(final.script, temp[count], "\n")}

       .Call("soamSubmit", counter, sesCon, final.script, packages)
   }

   .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())

   for(job in 1:njobs)
   {
       caller <- paste("result", job, sep = "")
       temp = dget(caller)
       if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
   }

   .Call("soamUninit")

   retval
}

*** Here are the 2 C++ functions:

extern "C"
{
SEXP soamInit ()
{
   // Initialize the API
   SoamFactory::initialize();

   // Set up application specific information to be supplied to Symphony
   char appName[] = "SampleAppCPP";

   // Set up application authentication information using the default
security provider
   DefaultSecurityCallback securityCB("Guest", "Guest");

   // Connect to the specified application
   ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);

   // Set up session creation attributes
   SessionCreationAttributes attributes;
   attributes.setSessionName("mySession");
   attributes.setSessionType("ShortRunningTasks");
   attributes.setSessionFlags(SF_RECEIVE_SYNC);

   // Create a synchronous session
   Session* sesPtr = conPtr->createSession(attributes);

   SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);

   return out;
}
}

extern "C"
{
 void soamSubmit       (SEXP jobID,            //job ID
                        SEXP sesCon,           //session pointer
                        SEXP caller,                   //objects
                        SEXP pack)                     //packages
{
       char* savelist = CHAR(STRING_ELT(caller, 0));
       string strTemp = "";
       int job = INTEGER(jobID)[0];

       void* temp = R_ExternalPtrAddr(sesCon);
       Session* sesPtr = reinterpret_cast<Session*>(temp);

   // Create a message
       MyMessage inMsg(job, /*pack,*/ savelist);

   // Send it
   TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
}
}
-- 
View this message in context: http://www.nabble.com/Using-R_MakeExternalPtr-tf4142904.html#a11790985
Sent from the R devel mailing list archive at Nabble.com.


From bolker at ufl.edu  Wed Jul 25 21:36:13 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 25 Jul 2007 19:36:13 +0000 (UTC)
Subject: [Rd] anova tables in survreg (PR#9806)
References: <20070725064252.012696598A@slim.kubism.ku.dk>
Message-ID: <loom.20070725T212021-482@post.gmane.org>

 <a.manners <at> sib.uq.edu.au> writes:

> To whom it may concern,
> 
> I'm trying to get an ANOVA table within survreg but it always 
> produces NA's in
> the p-value, regardless of the data set. 

  [snip]

   The problem is fairly clear, but not knowing the larger context
I don't know the best way to fix it.

  survival:::anova.survreg passes the following table to stat.anova():

     Df Deviance Resid. Df   -2*LL
NULL                    28 311.363
x    -1   22.773        27 288.590

stat.anova figures out where to look for the deviance
(dev.col is 2 here) and pulls out the difference
in degrees of freedom (dfs = c(NA,-1))
It then uses

vals <- table[, dev.col]/scale * sign(dfs)

  which comes out negative because sign(dfs)
is negative but the deviance is calculated as positive

  therefore

pchisq(vals, abs(dfs), lower.tail = FALSE))

  comes out as NA since vals is < 0.

  In the short term you could do:

a1 = anova(mot.sreg)
pchisq(abs(diff(a1$"-2*LL")),df=abs(a1$Df[2]),lower.tail=FALSE)

[1] 1.822632e-06

  In the longer term it looks like someone (??) should
figure out why anova.survreg and stat.anova are disagreeing
about the appropriate signs of df and deviance, and how to fix it ...

  Ben Bolker


From RossBoylan at stanfordalumni.org  Wed Jul 25 22:29:24 2007
From: RossBoylan at stanfordalumni.org (Ross Boylan)
Date: Wed, 25 Jul 2007 13:29:24 -0700
Subject: [Rd] codetools really optional for R CMD check?
Message-ID: <1185395364.7928.90.camel@corn.betterworld.us>

After upgrading to R 2.5.1 on Debian, R CMD check gives
* checking Rd cross-references ... WARNING
Error in .find.package(package, lib.loc) : 
	there is no package called 'codetools'
Execution halted
* checking for missing documentation entries ... WARNING
etc

The NEWS file says (for 2.5.0; I was on 2.4 before the recent upgrade)
    o	New recommended package 'codetools' by Luke Tierney provides
	code-analysis tools.  This can optionally be used by 'R CMD
	check' to detect problems, especially symbols which are not
	visible.

This sounds as if R CMD check should run OK without the package, and it
doesn't seem to.

Have I misunderstood something, or is their a problem with R CMD check's
handling of the case with missing codetools.

I don't have codetools installed because the Debian r-recommended
package was missing a dependency; I see that's already been fixed
(wow!).

Ross


From sw283 at maths.bath.ac.uk  Wed Jul 25 21:10:18 2007
From: sw283 at maths.bath.ac.uk (Simon Wood)
Date: Wed, 25 Jul 2007 20:10:18 +0100 (BST)
Subject: [Rd] glm(...,quasi(link="logit")) problem?
In-Reply-To: <mailman.9.1185357603.25185.r-devel@r-project.org>
References: <mailman.9.1185357603.25185.r-devel@r-project.org>
Message-ID: <Pine.LNX.4.64.0707251937370.9819@archer.maths.bath.ac.uk>

There may be a good reason for this, but under R 2.5.1 (Windows XP, Suse 
Linux)

> glm(c(0,.5)~1,quasi(link=logit))
Error: NA/NaN/Inf in foreign function call (arg 4)

whereas the same code works under R 2.1.1.

The problem (in 2.5.1) is a -Inf in the pseudodata `z' in glm.fit, as a 
result of a `-Inf' in eta, which is in turn generated by `mustart <- y' and 
`logit(mustart)'. In 2.1.1 the line `mustart <- y + 0.1 * (y == 0)' is 
what avoids the problem.

A possible fix might be to set elements of `good' to FALSE for non-finite 
`eta', for the first fit iteration only, of course. Is it worth fixing? I 
found this after  someone reported a problem with mgcv::gamm (which 
calls MASS:glmmPQL which calls glm), which is why I'm not just supplying 
my own mustart and getting on with it...

best,
Simon


>- Simon Wood, Mathematical Sciences, University of Bath, Bath BA2 7AY
>-             +44 (0)1225 386603         www.maths.bath.ac.uk/~sw283/


From edd at debian.org  Thu Jul 26 00:20:42 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 25 Jul 2007 22:20:42 +0000
Subject: [Rd] codetools really optional for R CMD check?
In-Reply-To: <1185395364.7928.90.camel@corn.betterworld.us>
References: <1185395364.7928.90.camel@corn.betterworld.us>
Message-ID: <20070725222041.GA5854@master.debian.org>

On Wed, Jul 25, 2007 at 01:29:24PM -0700, Ross Boylan wrote:
> After upgrading to R 2.5.1 on Debian, R CMD check gives
> * checking Rd cross-references ... WARNING
> Error in .find.package(package, lib.loc) : 
> 	there is no package called 'codetools'
> Execution halted
> * checking for missing documentation entries ... WARNING
> etc
> 
> The NEWS file says (for 2.5.0; I was on 2.4 before the recent upgrade)
>     o	New recommended package 'codetools' by Luke Tierney provides
> 	code-analysis tools.  This can optionally be used by 'R CMD
> 	check' to detect problems, especially symbols which are not
> 	visible.
> 
> This sounds as if R CMD check should run OK without the package, and it
> doesn't seem to.
> 
> Have I misunderstood something, or is their a problem with R CMD check's
> handling of the case with missing codetools.
> 
> I don't have codetools installed because the Debian r-recommended
> package was missing a dependency; I see that's already been fixed
> (wow!).

Yes, there was a transition problem.  When R 2.5.0 was released, I was
unaware of the need to prepare packages for codetools and rcompgen
__early enough so that they would migrate through the NEW queue in
Debian__ and hence be available upon the day of the R release.
Otherwise a Depends is no good if it can't be fulfilled.

So yes, for a while we had an implied Depends, but nothing formal. All
this has now been rectified and installing or upgrading r-recommended
will get you the new packages as it should.

Prior to another R releases with new recommended packages, I should
either pay closer attention to the relevant subdirectory in the
sources, and hope for a friendly heads-up from R Core (hint, ...)

Dirk

-- 
Three out of two people have difficulties with fractions.


From apjaworski at mmm.com  Thu Jul 26 00:56:54 2007
From: apjaworski at mmm.com (apjaworski at mmm.com)
Date: Wed, 25 Jul 2007 17:56:54 -0500
Subject: [Rd] loess prediction algorithm
Message-ID: <OF006E640B.BB7D35D0-ON8625731E.00582D8F-86257323.007E0F18@mmm.com>


Hello,

I need help with the details of loess prediction algorithm.  I would like
to get it implemented as a part of a measurement system programmed in
LabView.  My job is provide a detailed description of the algorithm.  This
is a simple one-dimensional problem - smoothing an (x, y) data set.

I found quite a detailed description of the fitting procedure in the "white
book".  It is also described in great detail at the NIST site in the
Engineering Statistics Handbook.  It provides an example of Loess
computations.  I managed to reproduce their example exactly in R.  At each
data point I compute a weighted local linear fit using the number of points
based of span.  Then I predict the values from these local fits.  This
matches R "loess" predictions exactly.

The problem starts when I try to predict at x values not in the data set.
The "white book" does not talk about predictions at all.  In the NIST
handbook in the "Final note on Loess Computations" they mention this type
of predictions but just say that the same steps are used for predictions as
for fitting.

When I try to use "the same steps" I get predictions that are quite
different that the predictions obtained by fitting R loess model to a data
set and running predict(<model object>, newdata=<grid of x values>).  They
match quite well at the lowest and highest ends of the x grid but in the
middle are different and much less smooth.  I can provide details but
basically what I do to create the predictions at x0 is this:
1.  I append c(x0, NA) to the data frame of (x, y) data.
2.  I calculate abs(xi-x0), i.e., absolute deviations of the x values in
the data set and a given x0 value.
3.  I sort the data set according to these deviations.  This way the first
row has the (x0, NA) value.
4.  I drop the first row.
5.  I divide all the deviations by the m-th one, where m is the number of
points used in local fitting -  m = floor(n*span) where n is the number of
points.
6.  I calculate the "tricube" weights and assign 0's to the negative ones.
This eliminates all the points except the m points of interest.
7.  I fit a linear weighted regression using lm.
8.  I predict y(x0) from this linear model.
This is basically the same procedure I use to predict at the x values from
the data set, except for point 4.

I got the R sources for loess but it looks to me like most of the work is
done in a bunch of Fortran modules.  They are very difficult to read and
understand, especially since they handle multiple x values.  A couple of
things that worry me are parameters in loess.control such as surface and
cell.  They seem to have something to do with predictions but I do not
account for them in my simple procedure above.

Could anyone shed a light on this problem?  Any comment will be
appreciated.

I apologize in advance if this should have been posted in r-help.  I
figured that I have a better chance asking people who read the r-devel
group, since they are likely to know more details about inner workings of
R.

Thanks in advance,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


From ross at biostat.ucsf.edu  Thu Jul 26 05:55:30 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 25 Jul 2007 20:55:30 -0700
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11790985.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com>
	<46A77D03.5090607@cimr.cam.ac.uk>  <11790985.post@talk.nabble.com>
Message-ID: <1185422130.7928.98.camel@corn.betterworld.us>

See at bottom for an example.
On Wed, 2007-07-25 at 11:26 -0700, Jonathan Zhou wrote:
> Hi Hin-Tak,
> 
> Here is the R code function in where I called the two C++ and further below
> are the 2 C++ functions I used to create the externalptr and use it :
> 
> soam.Rapply <- function (x, func, ...,
>                           join.method=cbind,
>                           njobs,
>                           batch.size=100,
>                           packages=NULL,
>                           savelist=NULL)
> {
>    if(missing(njobs))
>        njobs <- max(1,ceiling(nrow(x)/batch.size))
> 
>    if(!is.matrix(x) && !is.data.frame(x))
>        stop("x must be a matrix or data frame")
> 
>    if(njobs>1)
>        {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
> drop = FALSE])} else {rowSet <- list(x)}
> 
>    sesCon <- .Call("soamInit")
> 
>    script <- " "
> 
>    fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
>    file(fname, open="w+")
>    if(!is.null(savelist)) {
>        dump(savelist, fname)
>        script<-readLines(fname)
>    }
> 
>    if(!is.null(packages))
>    for(counter in 1:length(packages))
>    {
>        temp<-call("library", packages[counter], character.only=TRUE)
>        dput(temp, fname)
>        pack.call<-readLines(fname)
>        script<-append(script, pack.call)
>    }
> 
>    for(counter in 1:njobs)
>    {
>        caller <- paste("caller", counter, sep = "")
>        soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
> FUN=func), caller)
>        dput(soam.call, fname)
>        soam.call<-readLines(fname)
> 
>        temp<-append(script, soam.call)
>        final.script = temp[1]
>        for(count in 2:length(temp)){
>            final.script<-paste(final.script, temp[count], "\n")}
> 
>        .Call("soamSubmit", counter, sesCon, final.script, packages)
>    }
> 
>    .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())
> 
>    for(job in 1:njobs)
>    {
>        caller <- paste("result", job, sep = "")
>        temp = dget(caller)
>        if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
>    }
> 
>    .Call("soamUninit")
> 
>    retval
> }
> 
> *** Here are the 2 C++ functions:
> 
> extern "C"
> {
> SEXP soamInit ()
> {
>    // Initialize the API
>    SoamFactory::initialize();
> 
>    // Set up application specific information to be supplied to Symphony
>    char appName[] = "SampleAppCPP";
> 
>    // Set up application authentication information using the default
> security provider
>    DefaultSecurityCallback securityCB("Guest", "Guest");
> 
>    // Connect to the specified application
>    ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);
> 
>    // Set up session creation attributes
>    SessionCreationAttributes attributes;
>    attributes.setSessionName("mySession");
>    attributes.setSessionType("ShortRunningTasks");
>    attributes.setSessionFlags(SF_RECEIVE_SYNC);
> 
>    // Create a synchronous session
>    Session* sesPtr = conPtr->createSession(attributes);
// I use Rf_protect, though I'd be surprised if that matters given your
use
> 
>    SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);
> 
// temp?  don't you mean sesPtr?
>    return out;
> }
> }
> 
> extern "C"
> {
>  void soamSubmit       (SEXP jobID,            //job ID
>                         SEXP sesCon,           //session pointer
>                         SEXP caller,                   //objects
>                         SEXP pack)                     //packages
> {
>        char* savelist = CHAR(STRING_ELT(caller, 0));
>        string strTemp = "";
>        int job = INTEGER(jobID)[0];
> 
>        void* temp = R_ExternalPtrAddr(sesCon);
>        Session* sesPtr = reinterpret_cast<Session*>(temp);
> 
>    // Create a message
>        MyMessage inMsg(job, /*pack,*/ savelist);
> 
>    // Send it
>    TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
> }
> }

I've been able to get things working with this pattern (which also is
about assuring memory is freed)
Here's the pattern:
// I needed R_NO_REMAP to avoid name collisions.  You may not.
#define R_NO_REMAP 1
#include <R.h>
#include <Rinternals.h>

extern "C" {
// returns an |ExternalPtr|
SEXP makeManager(
        @<makeManager args@>);


// user should not need to call
// cleanup
void finalizeManager(SEXP ptr);

}

SEXP makeManager(
        @<makeManager args@>){
    // .... stuff

    Manager* pmanager = new Manager(pd, pm.release(), 
        *INTEGER(stepNumerator), *INTEGER(stepDenominator),
        (*INTEGER(isexact)) != 0);
    
    // one example didn't use |PROTECT()|
    SEXP ptr;
    Rf_protect(ptr = R_MakeExternalPtr(pmanager, R_NilValue,
R_NilValue));
    R_RegisterCFinalizer(ptr, (R_CFinalizer_t) finalizeManager);
    Rf_unprotect(1);
    return ptr;

}

void finalizeManager(SEXP ptr){
  Manager *pmanager = static_cast<Manager *>(R_ExternalPtrAddr(ptr));
  delete pmanager;
  R_ClearExternalPtr(ptr);
}

I'd love to hear from those more knowledgeable about whether I did
that right, and whether the FinalizerEx call can assure cleanup on
exit.

Make manager needes to be called from R like this
      mgr <- .Call("makeManager", args)


The to use it I have things like this:
// ptr is the value returned by |makeManager()|
// |do_what| is an integer requesting the kind of operation
SEXP compute(SEXP ptr, SEXP do_what){
  using namespace mspath;
  Manager *pmanager = static_cast<Manager *>(R_ExternalPtrAddr(ptr));
// you can probably stop reading there
  SEXP newvec;
  Rf_protect(newvec = Rf_allocVector(REALSXP, 6u));
  double *returned = REAL(newvec);
  std::stringstream serror;
  try { 
      pmanager->go(returned, *INTEGER(do_what));
      *returned *= -2;
    } catch(std::exception& exc) {
      serror << "Caught exception: " << exc.what();
    } catch(...) {
      serror << "Some non-standard exception was thrown" <<
std::endl;
    }
    if (! serror.str().empty()) {
      finalizeManager(ptr);  // kill manager
      Rf_error("%s", serror.str().c_str());
    }
   Rf_unprotect(1);
   return newvec;
}


From ripley at stats.ox.ac.uk  Thu Jul 26 10:11:28 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Jul 2007 09:11:28 +0100 (BST)
Subject: [Rd] loess prediction algorithm
In-Reply-To: <OF006E640B.BB7D35D0-ON8625731E.00582D8F-86257323.007E0F18@mmm.com>
References: <OF006E640B.BB7D35D0-ON8625731E.00582D8F-86257323.007E0F18@mmm.com>
Message-ID: <Pine.LNX.4.64.0707260904340.31015@gannet.stats.ox.ac.uk>

The R interface is just a wrapper for those Netlib C/Fortran functions.
I don't think anyone is going to be able (or willing) to read and explain 
those for you.

You do need to understand the loess.control parameters, and I believe they 
are explained in the White Book.  But perhaps you should use the simplest 
options in R as a baseline.

I don't believe your sketchy description of tricube weights is correct: 
the White Book has the details.

The default degree is 2, not linear fits.

On Wed, 25 Jul 2007, apjaworski at mmm.com wrote:

>
> Hello,
>
> I need help with the details of loess prediction algorithm.  I would like
> to get it implemented as a part of a measurement system programmed in
> LabView.  My job is provide a detailed description of the algorithm.  This
> is a simple one-dimensional problem - smoothing an (x, y) data set.
>
> I found quite a detailed description of the fitting procedure in the "white
> book".  It is also described in great detail at the NIST site in the
> Engineering Statistics Handbook.  It provides an example of Loess
> computations.  I managed to reproduce their example exactly in R.  At each
> data point I compute a weighted local linear fit using the number of points
> based of span.  Then I predict the values from these local fits.  This
> matches R "loess" predictions exactly.
>
> The problem starts when I try to predict at x values not in the data set.
> The "white book" does not talk about predictions at all.  In the NIST
> handbook in the "Final note on Loess Computations" they mention this type
> of predictions but just say that the same steps are used for predictions as
> for fitting.
>
> When I try to use "the same steps" I get predictions that are quite
> different that the predictions obtained by fitting R loess model to a data
> set and running predict(<model object>, newdata=<grid of x values>).  They
> match quite well at the lowest and highest ends of the x grid but in the
> middle are different and much less smooth.  I can provide details but
> basically what I do to create the predictions at x0 is this:
> 1.  I append c(x0, NA) to the data frame of (x, y) data.
> 2.  I calculate abs(xi-x0), i.e., absolute deviations of the x values in
> the data set and a given x0 value.
> 3.  I sort the data set according to these deviations.  This way the first
> row has the (x0, NA) value.
> 4.  I drop the first row.
> 5.  I divide all the deviations by the m-th one, where m is the number of
> points used in local fitting -  m = floor(n*span) where n is the number of
> points.
> 6.  I calculate the "tricube" weights and assign 0's to the negative ones.
> This eliminates all the points except the m points of interest.
> 7.  I fit a linear weighted regression using lm.
> 8.  I predict y(x0) from this linear model.
> This is basically the same procedure I use to predict at the x values from
> the data set, except for point 4.
>
> I got the R sources for loess but it looks to me like most of the work is
> done in a bunch of Fortran modules.  They are very difficult to read and
> understand, especially since they handle multiple x values.  A couple of
> things that worry me are parameters in loess.control such as surface and
> cell.  They seem to have something to do with predictions but I do not
> account for them in my simple procedure above.
>
> Could anyone shed a light on this problem?  Any comment will be
> appreciated.
>
> I apologize in advance if this should have been posted in r-help.  I
> figured that I have a better chance asking people who read the r-devel
> group, since they are likely to know more details about inner workings of
> R.
>
> Thanks in advance,
>
> Andy
>
> __________________________________
> Andy Jaworski
> 518-1-01
> Process Laboratory
> 3M Corporate Research Laboratory
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From btyner at gmail.com  Thu Jul 26 13:26:09 2007
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 26 Jul 2007 07:26:09 -0400
Subject: [Rd]  loess prediction algorithm
Message-ID: <5f88b2c50707260426i1a6289a0i7bc43878ba767ca9@mail.gmail.com>

Andy,

If you could provide an example of the R code with which you call
loess(), I can post R code which will duplicate what predict.loess
does without having to call the C/Fortran. There are a lot of
implementation details that are easy to overlook, but without knowing
the arguments to your call it is difficult to guess the source of your
problem.

Ben


From jhallman at frb.gov  Thu Jul 26 16:14:24 2007
From: jhallman at frb.gov (Jeffrey J. Hallman)
Date: 26 Jul 2007 10:14:24 -0400
Subject: [Rd] [R] aggregate.ts
References: <Pine.LNX.4.44.0707250237430.16266-100000@disco.wu-wien.ac.at>
	<46A75EAA.6020405@bank-banque-canada.ca>
Message-ID: <xmrwswn9rr3.fsf@mralx1.rsma.frb.gov>

aggregate.tis() in the fame package does what I think is the right thing: 

> x2 <- tis(1:24, start = c(2000, 11), freq = 12)
> y2 <- aggregate(x2, nfreq = 4)
> x2
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
2000                                           1   2
2001   3   4   5   6   7   8   9  10  11  12  13  14
2002  15  16  17  18  19  20  21  22  23  24        
class: tis
> y2
     Qtr1 Qtr2 Qtr3 Qtr4
2001   12   21   30   39
2002   48   57   66     
class: tis

If you really want y2 to have an observation for 2000Q4, you can use

> convert(x2, tif = "quarterly", observed = "summed", ignore = T)
          Qtr1      Qtr2      Qtr3      Qtr4
2000                                4.033333
2001 12.000000 21.000000 30.000000 39.000000
2002 48.000000 57.000000 66.000000 71.225806
class: tis



Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:

> I've been caught by this before, and complained before.  It does not do 
> what most people that work with economic time series would expect.  (One 
> might argue that not all time series are economic, but other time series 
> don't usually fit with ts very well.)  At the very least aggregate 
> should issue a warning.  Quarterly observations are for quarters of the 
> year, so just arbitrarily grouping in 3 beginning with the first 
> observation is *extremely* misleading, even if it is documented.
> 
> [ BTW, there is a bug in the print method here (R-2.5.1 on Linux) :
>  >   y2 <- aggregate(x2, nfreq = 4) 
>  >
>  > y2
> Error in rep.int("", start.pad) : invalid number of copies in rep.int()
>  > traceback()
> 5: rep.int("", start.pad)
> 4: as.vector(data)
> 3: matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",
>        end.pad)), nc = fr.x, byrow = TRUE, dimnames = list(dn1,
>        dn2))
> 2: print.ts(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
> 1: print(c(6L, 15L, 24L, 33L, 42L, 51L, 60L, 69L))
> ]
> 
> ....
> 
> >Currently, the "zoo" implementation allows this: Coercing back and forth
> >gives:
> >  library("zoo")
> >  z1 <- as.ts(aggregate(as.zoo(x1), as.yearqtr, sum))
> >  z2 <- as.ts(aggregate(as.zoo(x2), as.yearqtr, sum))
> >  
> >
> This is better, but still potentially misleading. I would prefer a 
> default  NA when only some of the observations are available for a 
> quarter  (and the syntax is a bit cumbersome for something one needs to 
> do fairly often).
> 
> Paul
> 
> >where z1 is identical to y1, and z2 is what you probably want.
> >
> >hth,
> >Z
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >  
> >
> ====================================================================================
> 
> La version fran?aise suit le texte anglais.
> 
> ------------------------------------------------------------------------------------
> 
> This email may contain privileged and/or confidential inform...{{dropped}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Jeff


From Greg.Snow at intermountainmail.org  Thu Jul 26 16:49:50 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 26 Jul 2007 08:49:50 -0600
Subject: [Rd] loess prediction algorithm
In-Reply-To: <OF006E640B.BB7D35D0-ON8625731E.00582D8F-86257323.007E0F18@mmm.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBAF2925@LP-EXCHVS07.CO.IHC.COM>

The loess.demo function in the TeachingDemos package may help you to
understand better what is happening (both running the demo and looking
at the code).  One common reason why predictions from the loess function
and hand computed predictions don't match is because the loess function
does an additional smoothing step by default, the above  demo shows both
curves (with the additional smoothing and without) so you can see how
close they are and how the smoothness differs.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of apjaworski at mmm.com
> Sent: Wednesday, July 25, 2007 4:57 PM
> To: r-devel at r-project.org
> Subject: [Rd] loess prediction algorithm
> 
> 
> Hello,
> 
> I need help with the details of loess prediction algorithm.  
> I would like to get it implemented as a part of a measurement 
> system programmed in LabView.  My job is provide a detailed 
> description of the algorithm.  This is a simple 
> one-dimensional problem - smoothing an (x, y) data set.
> 
> I found quite a detailed description of the fitting procedure 
> in the "white book".  It is also described in great detail at 
> the NIST site in the Engineering Statistics Handbook.  It 
> provides an example of Loess computations.  I managed to 
> reproduce their example exactly in R.  At each data point I 
> compute a weighted local linear fit using the number of 
> points based of span.  Then I predict the values from these 
> local fits.  This matches R "loess" predictions exactly.
> 
> The problem starts when I try to predict at x values not in 
> the data set.
> The "white book" does not talk about predictions at all.  In 
> the NIST handbook in the "Final note on Loess Computations" 
> they mention this type of predictions but just say that the 
> same steps are used for predictions as for fitting.
> 
> When I try to use "the same steps" I get predictions that are 
> quite different that the predictions obtained by fitting R 
> loess model to a data set and running predict(<model object>, 
> newdata=<grid of x values>).  They match quite well at the 
> lowest and highest ends of the x grid but in the middle are 
> different and much less smooth.  I can provide details but 
> basically what I do to create the predictions at x0 is this:
> 1.  I append c(x0, NA) to the data frame of (x, y) data.
> 2.  I calculate abs(xi-x0), i.e., absolute deviations of the 
> x values in the data set and a given x0 value.
> 3.  I sort the data set according to these deviations.  This 
> way the first row has the (x0, NA) value.
> 4.  I drop the first row.
> 5.  I divide all the deviations by the m-th one, where m is 
> the number of points used in local fitting -  m = 
> floor(n*span) where n is the number of points.
> 6.  I calculate the "tricube" weights and assign 0's to the 
> negative ones.
> This eliminates all the points except the m points of interest.
> 7.  I fit a linear weighted regression using lm.
> 8.  I predict y(x0) from this linear model.
> This is basically the same procedure I use to predict at the 
> x values from the data set, except for point 4.
> 
> I got the R sources for loess but it looks to me like most of 
> the work is done in a bunch of Fortran modules.  They are 
> very difficult to read and understand, especially since they 
> handle multiple x values.  A couple of things that worry me 
> are parameters in loess.control such as surface and cell.  
> They seem to have something to do with predictions but I do 
> not account for them in my simple procedure above.
> 
> Could anyone shed a light on this problem?  Any comment will 
> be appreciated.
> 
> I apologize in advance if this should have been posted in 
> r-help.  I figured that I have a better chance asking people 
> who read the r-devel group, since they are likely to know 
> more details about inner workings of R.
> 
> Thanks in advance,
> 
> Andy
> 
> __________________________________
> Andy Jaworski
> 518-1-01
> Process Laboratory
> 3M Corporate Research Laboratory
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeff.lindon at thelearninginstitute.net  Thu Jul 26 15:39:42 2007
From: jeff.lindon at thelearninginstitute.net (jeff.lindon at thelearninginstitute.net)
Date: Thu, 26 Jul 2007 15:39:42 +0200 (CEST)
Subject: [Rd] SQL server service pack 2 prob? (PR#9810)
Message-ID: <20070726133942.9E750667E2@slim.kubism.ku.dk>

Full_Name: Jeff Lindon
Version: 2.5.0
OS: mingw32
Submission from: (NULL) (63.147.8.67)


R 2.5.0 seems to be unable to read valid tables from SQL Server 2005 with
Service Pack 2 installed:

> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.0                         
year           2007                        
month          04                          
day            23                          
svn rev        41293                       
language       R                           
version.string R version 2.5.0 (2007-04-23)
> library(RODBC)
> channel <- odbcConnect("TLIAS01", uid="jeff.lindon")
> channel
RODB Connection 1
Details:
  case=nochange
  DSN=TLIAS01
  UID=jeff.lindon
  Trusted_Connection=Yes
  WSID=TLIJLINDON
  DATABASE=tliresearch
> d <- sqlFetch(channel, District)
Error in odbcTableExists(channel, sqtable) : 
        object "District" not found

I have checked this problem with our CIO and he confirmed my Data Source
configuration is correct (the connection test confirmed that R is able to
connect to the database), and that the table really does exist and I have
correct permissions (I work with it daily). Moreover, I was working between R
and SQL Server 2005 with no problems before yesterday using the same exact set
of instructions. The only change our CIO and I could think of is the recent
installation of Service Pack 2. 

Unfortunately, reverting to Service Pack 1 is not currently an option, so I
cannot be sure this is the problem. I am able to work around the issue by
cutting and pasting the tables I need from SQL to Excel, then saving them as
csv's. Saving directly from SQL to csv (highlighting the desired output and
right-clicking) also causes problems for read.csv. I never tried that before
Service Pack 2, though.

I hope this information helps. I absolutely love R and thank you all so much for
your work on it!


From simon.urbanek at r-project.org  Thu Jul 26 18:07:40 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 26 Jul 2007 12:07:40 -0400
Subject: [Rd] SQL server service pack 2 prob? (PR#9810)
In-Reply-To: <20070726133942.9E750667E2@slim.kubism.ku.dk>
References: <20070726133942.9E750667E2@slim.kubism.ku.dk>
Message-ID: <C468FBEE-1F5B-4737-97AA-EEABD3CE1086@r-project.org>


On Jul 26, 2007, at 9:39 AM, jeff.lindon at thelearninginstitute.net wrote:

> Full_Name: Jeff Lindon
> Version: 2.5.0
> OS: mingw32
> Submission from: (NULL) (63.147.8.67)
>
>
> R 2.5.0 seems to be unable to read valid tables from SQL Server  
> 2005 with
> Service Pack 2 installed:
>
>> version
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>> library(RODBC)
>> channel <- odbcConnect("TLIAS01", uid="jeff.lindon")
>> channel
> RODB Connection 1
> Details:
>   case=nochange
>   DSN=TLIAS01
>   UID=jeff.lindon
>   Trusted_Connection=Yes
>   WSID=TLIJLINDON
>   DATABASE=tliresearch
>> d <- sqlFetch(channel, District)
> Error in odbcTableExists(channel, sqtable) :
>         object "District" not found
>

Didn't you mean

d <- sqlFetch(channel, "District")

instead?

Cheers,
Simon

PS: This is not an R bug, so please don't abuse the R bug tracking  
system for this. If at all, the question should go to R-help or the  
RODBC maintainer (please read the posting guide).


> I have checked this problem with our CIO and he confirmed my Data  
> Source
> configuration is correct (the connection test confirmed that R is  
> able to
> connect to the database), and that the table really does exist and  
> I have
> correct permissions (I work with it daily). Moreover, I was working  
> between R
> and SQL Server 2005 with no problems before yesterday using the  
> same exact set
> of instructions. The only change our CIO and I could think of is  
> the recent
> installation of Service Pack 2.
>
> Unfortunately, reverting to Service Pack 1 is not currently an  
> option, so I
> cannot be sure this is the problem. I am able to work around the  
> issue by
> cutting and pasting the tables I need from SQL to Excel, then  
> saving them as
> csv's. Saving directly from SQL to csv (highlighting the desired  
> output and
> right-clicking) also causes problems for read.csv. I never tried  
> that before
> Service Pack 2, though.
>
> I hope this information helps. I absolutely love R and thank you  
> all so much for
> your work on it!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Thu Jul 26 18:29:44 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 26 Jul 2007 18:29:44 +0200 (CEST)
Subject: [Rd] (PR#9810) Problem with careless user of RODBC (was  SQL
Message-ID: <20070726162944.DA5F6667EC@slim.kubism.ku.dk>

Your error message was

>> d <- sqlFetch(channel, District)
> Error in odbcTableExists(channel, sqtable) :
>        object "District" not found

and as you had not defined an object 'District' in that session, it seems 
perfectly plain.  If you want to refer to table "District" you have to 
give a character string (with quotes), not the name of an R object.

If all else fails, READ the documentation!  ?sqlFetch says

  sqtable: a database table name accessible from the connected dsn. This
           should be either a character string or a character vector of
           length 1.


I am glad you love R, but it _would_ be nice to get some credit for the 
package that you are using without apparently being aware that it is 
contributed work, instead of being inconvenienced clearing up after a 
non-bug report.


On Thu, 26 Jul 2007, jeff.lindon at thelearninginstitute.net wrote:

> Full_Name: Jeff Lindon
> Version: 2.5.0
> OS: mingw32
> Submission from: (NULL) (63.147.8.67)
>
>
> R 2.5.0 seems to be unable to read valid tables from SQL Server 2005 with
> Service Pack 2 installed:
>
>> version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.0
> year           2007
> month          04
> day            23
> svn rev        41293
> language       R
> version.string R version 2.5.0 (2007-04-23)
>> library(RODBC)
>> channel <- odbcConnect("TLIAS01", uid="jeff.lindon")
>> channel
> RODB Connection 1
> Details:
>  case=nochange
>  DSN=TLIAS01
>  UID=jeff.lindon
>  Trusted_Connection=Yes
>  WSID=TLIJLINDON
>  DATABASE=tliresearch
>> d <- sqlFetch(channel, District)
> Error in odbcTableExists(channel, sqtable) :
>        object "District" not found
>
> I have checked this problem with our CIO and he confirmed my Data Source
> configuration is correct (the connection test confirmed that R is able to
> connect to the database), and that the table really does exist and I have
> correct permissions (I work with it daily). Moreover, I was working between R
> and SQL Server 2005 with no problems before yesterday using the same exact set
> of instructions. The only change our CIO and I could think of is the recent
> installation of Service Pack 2.
>
> Unfortunately, reverting to Service Pack 1 is not currently an option, so I
> cannot be sure this is the problem. I am able to work around the issue by
> cutting and pasting the tables I need from SQL to Excel, then saving them as
> csv's. Saving directly from SQL to csv (highlighting the desired output and
> right-clicking) also causes problems for read.csv. I never tried that before
> Service Pack 2, though.
>
> I hope this information helps. I absolutely love R and thank you all so much for
> your work on it!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bill at insightful.com  Thu Jul 26 19:45:28 2007
From: bill at insightful.com (bill at insightful.com)
Date: Thu, 26 Jul 2007 19:45:28 +0200 (CEST)
Subject: [Rd] sequence(c(2, 0, 3)) produces surprising results,
	would like output length to be sum(input) (PR#9811)
Message-ID: <20070726174528.0B771667EA@slim.kubism.ku.dk>

Full_Name: Bill Dunlap
Version: 2.5.0
OS: Linux
Submission from: (NULL) (70.98.76.47)


sequence(nvec) is documented to return
the concatenation of seq(nvec[i]), for
i in seq(along=nvec).  This produces inconvenient
(for me) results for 0 inputs.
    > sequence(c(2,0,3)) # would like 1 2 1 2 3, ignore 0
    [1] 1 2 1 0 1 2 3
Would changing sequence(nvec) to use seq_len(nvec[i])
instead of the current 1:nvec[i] break much existing code?

On the other hand, almost no one seems to use sequence()
and it might make more sense to allow seq_len() and seq()
to accept a vector for length.out and they would return a
vector of length sum(length.out),
    c(seq_len(length.out[1]), seq_len(length.out[2]), ...)


From bill at insightful.com  Thu Jul 26 20:37:53 2007
From: bill at insightful.com (Bill Dunlap)
Date: Thu, 26 Jul 2007 11:37:53 -0700 (PDT)
Subject: [Rd] sequence(c(2, 0, 3)) produces surprising results,
 would like output length to be sum(input) (PR#9811)
In-Reply-To: <20070726174528.0B771667EA@slim.kubism.ku.dk>
References: <20070726174528.0B771667EA@slim.kubism.ku.dk>
Message-ID: <Pine.GSO.4.56.0707261130410.25023@durian.statsci.com>

On Thu, 26 Jul 2007 bill at insightful.com wrote:

> Full_Name: Bill Dunlap
> Version: 2.5.0
> OS: Linux
> Submission from: (NULL) (70.98.76.47)
>
> sequence(nvec) is documented to return
> the concatenation of seq(nvec[i]), for
> i in seq(along=nvec).  This produces inconvenient
> (for me) results for 0 inputs.
>     > sequence(c(2,0,3)) # would like 1 2 1 2 3, ignore 0
>     [1] 1 2 1 0 1 2 3
> Would changing sequence(nvec) to use seq_len(nvec[i])
> instead of the current 1:nvec[i] break much existing code?
>
> On the other hand, almost no one seems to use sequence()
> and it might make more sense to allow seq_len() and seq()
> to accept a vector for length.out and they would return a
> vector of length sum(length.out),
>     c(seq_len(length.out[1]), seq_len(length.out[2]), ...)

seq_len() could be changed to do that with the following
code change.  It does slow down seq_len in the scalar case
                             old time    new time
for(i in 1:1e6)seq_len(2)    1.251       1.516
for(i in 1:1e6)seq_len(20)   1.690       1.990
for(i in 1:1e6)seq_len(200)  5.480       5.860

It becomes much faster than sequence in the vectorized case.
   > unix.time(for(i in 1:1e4)sequence(20:1))
      user  system elapsed
     1.550   0.000   1.557
   > unix.time(for(i in 1:1e4)seq_len(20:1))
      user  system elapsed
     0.070   0.000   0.066
   > identical(sequence(20:1), seq_len(20:1))
   [1] TRUE
My problem cases are where the length.out vector is long
and contains small integers (e.g., the output of table
on a vector of mostly unique values).

Index: src/main/seq.c
===================================================================
--- src/main/seq.c	(revision 42329)
+++ src/main/seq.c	(working copy)
@@ -594,16 +594,31 @@

 SEXP attribute_hidden do_seq_len(SEXP call, SEXP op, SEXP args, SEXP rho)
 {
-    SEXP ans;
-    int i, len, *p;
+    SEXP ans, slengths;
+    int i, *p, anslen, *lens, nlens, ilen, nprotected=0 ;

     checkArity(op, args);
-    len = asInteger(CAR(args));
-    if(len == NA_INTEGER || len < 0)
-	errorcall(call, _("argument must be non-negative"));
-    ans = allocVector(INTSXP, len);
+    slengths = CAR(args);
+    if (TYPEOF(slengths) != INTSXP) {
+    	PROTECT(slengths = coerceVector(CAR(args), INTSXP));
+        nprotected++;
+    }
+    lens = INTEGER(slengths);
+    nlens = LENGTH(slengths);
+    anslen = 0 ;
+    for(ilen=0;ilen<nlens;ilen++) {
+        int len = lens[ilen] ;
+        if(len == NA_INTEGER || len < 0)
+	    errorcall(call, _("argument must be non-negative"));
+        anslen += len ;
+    }
+    ans = allocVector(INTSXP, anslen);
     p = INTEGER(ans);
-    for(i = 0; i < len; i++) p[i] = i+1;
-
+    for(ilen=0;ilen<nlens;ilen++) {
+        int len = lens[ilen] ;
+        for(i = 0; i < len; i++) *p++ = i+1;
+    }
+    if(nprotected>0)
+        UNPROTECT(nprotected);
     return ans;
 }


From bill at insightful.com  Thu Jul 26 20:38:41 2007
From: bill at insightful.com (bill at insightful.com)
Date: Thu, 26 Jul 2007 20:38:41 +0200 (CEST)
Subject: [Rd] sequence(c(2, 0, 3)) produces surprising results,
	would (PR#9813)
Message-ID: <20070726183841.3532B667E8@slim.kubism.ku.dk>

On Thu, 26 Jul 2007 bill at insightful.com wrote:

> Full_Name: Bill Dunlap
> Version: 2.5.0
> OS: Linux
> Submission from: (NULL) (70.98.76.47)
>
> sequence(nvec) is documented to return
> the concatenation of seq(nvec[i]), for
> i in seq(along=nvec).  This produces inconvenient
> (for me) results for 0 inputs.
>     > sequence(c(2,0,3)) # would like 1 2 1 2 3, ignore 0
>     [1] 1 2 1 0 1 2 3
> Would changing sequence(nvec) to use seq_len(nvec[i])
> instead of the current 1:nvec[i] break much existing code?
>
> On the other hand, almost no one seems to use sequence()
> and it might make more sense to allow seq_len() and seq()
> to accept a vector for length.out and they would return a
> vector of length sum(length.out),
>     c(seq_len(length.out[1]), seq_len(length.out[2]), ...)

seq_len() could be changed to do that with the following
code change.  It does slow down seq_len in the scalar case
                             old time    new time
for(i in 1:1e6)seq_len(2)    1.251       1.516
for(i in 1:1e6)seq_len(20)   1.690       1.990
for(i in 1:1e6)seq_len(200)  5.480       5.860

It becomes much faster than sequence in the vectorized case.
   > unix.time(for(i in 1:1e4)sequence(20:1))
      user  system elapsed
     1.550   0.000   1.557
   > unix.time(for(i in 1:1e4)seq_len(20:1))
      user  system elapsed
     0.070   0.000   0.066
   > identical(sequence(20:1), seq_len(20:1))
   [1] TRUE
My problem cases are where the length.out vector is long
and contains small integers (e.g., the output of table
on a vector of mostly unique values).

Index: src/main/seq.c
===================================================================
--- src/main/seq.c	(revision 42329)
+++ src/main/seq.c	(working copy)
@@ -594,16 +594,31 @@

 SEXP attribute_hidden do_seq_len(SEXP call, SEXP op, SEXP args, SEXP rho)
 {
-    SEXP ans;
-    int i, len, *p;
+    SEXP ans, slengths;
+    int i, *p, anslen, *lens, nlens, ilen, nprotected=0 ;

     checkArity(op, args);
-    len = asInteger(CAR(args));
-    if(len == NA_INTEGER || len < 0)
-	errorcall(call, _("argument must be non-negative"));
-    ans = allocVector(INTSXP, len);
+    slengths = CAR(args);
+    if (TYPEOF(slengths) != INTSXP) {
+    	PROTECT(slengths = coerceVector(CAR(args), INTSXP));
+        nprotected++;
+    }
+    lens = INTEGER(slengths);
+    nlens = LENGTH(slengths);
+    anslen = 0 ;
+    for(ilen=0;ilen<nlens;ilen++) {
+        int len = lens[ilen] ;
+        if(len == NA_INTEGER || len < 0)
+	    errorcall(call, _("argument must be non-negative"));
+        anslen += len ;
+    }
+    ans = allocVector(INTSXP, anslen);
     p = INTEGER(ans);
-    for(i = 0; i < len; i++) p[i] = i+1;
-
+    for(ilen=0;ilen<nlens;ilen++) {
+        int len = lens[ilen] ;
+        for(i = 0; i < len; i++) *p++ = i+1;
+    }
+    if(nprotected>0)
+        UNPROTECT(nprotected);
     return ans;
 }


From larryh at zebra.us.udel.edu  Thu Jul 26 20:00:53 2007
From: larryh at zebra.us.udel.edu (larryh at zebra.us.udel.edu)
Date: Thu, 26 Jul 2007 20:00:53 +0200 (CEST)
Subject: [Rd] Rd2dvi (PR#9812)
Message-ID: <20070726180053.DF806667EA@slim.kubism.ku.dk>

Is this a bug--

-------------------------------------------------------------------------------
<234>% R CMD Rd2dvi base.Rd
Converting Rd files to LaTeX ...
base.Rd
Can't use an undefined value as filehandle reference at 
/opt/R-2.5.1/lib/R/share/perl/R/Rdconv.pm line 78.
ENCS is 
Creating dvi output from LaTeX ...
Saving output to 'base.dvi' ...
cp: cannot access .Rd2dvi26632/Rd2.dvi
Done
xdvi-xaw.bin: Fatal error: base.dvi: No such file.
<235>% ls base.Rd
base.Rd
<236>% uname -a
SunOS strauss.udel.edu 5.9 Generic_112233-12 sun4u sparc SUNW,Sun-Fire
<237>% R --version
R version 2.5.1 (2007-06-27)
-------------------------------------------------------------------------------

R was installed yesterday (7/25/2007). (I'm not the installer.)

Thanks,

Larry Hotchkiss



Larry Hotchkiss
University of Delaware
IT User Services -- Smith Hall
Newark, DE 19716 
302-831-1989  larryh at zebra.us.udel.edu


From bill at insightful.com  Thu Jul 26 21:09:24 2007
From: bill at insightful.com (Bill Dunlap)
Date: Thu, 26 Jul 2007 12:09:24 -0700 (PDT)
Subject: [Rd] Rd2dvi (PR#9812)
In-Reply-To: <20070726180053.DF806667EA@slim.kubism.ku.dk>
References: <20070726180053.DF806667EA@slim.kubism.ku.dk>
Message-ID: <Pine.GSO.4.56.0707261202440.25023@durian.statsci.com>

On Thu, 26 Jul 2007 larryh at zebra.us.udel.edu wrote:

> Is this a bug--
>
> -------------------------------------------------------------------------------
> <234>% R CMD Rd2dvi base.Rd
> Converting Rd files to LaTeX ...
> base.Rd
> Can't use an undefined value as filehandle reference at
> /opt/R-2.5.1/lib/R/share/perl/R/Rdconv.pm line 78.

This may be due to a change I suggested a while back which
required perl 5.6 (or so) to work.  The change was to ensure
that the file handle rdfile was closed when Rdconv was done
with it.  If this is the problem, upgrading perl to 5.8 will
make it go away.  Rdconv.pm should have a 'use v5.6' (or 5.8?)
line at the top if it wants to continue to use this syntax.

<     open(rdfile, "<$Rdname") or die "Rdconv(): Couldn't open '$Rdfile': $!\n";
<
---
>     open(my $rdfile, "<$Rdname") or die "Rdconv(): Couldn't open '$Rdfile': $!\n";
>     # Before we added the 'my $' in front of rdfile,
>     # rdfile was not getting closed.   Now it will close
>     # when $rdfile goes out of scope.  (We could have added
>     # a close rdfile at the end of the while(<rdfile>), but
>     # scoping method is more reliable.
123c127
<     while(<rdfile>){
---
>     while(<$rdfile>){

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From ripley at stats.ox.ac.uk  Fri Jul 27 09:07:00 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri, 27 Jul 2007 09:07:00 +0200 (CEST)
Subject: [Rd] (PR#9811) sequence(c(2, 0, 3)) produces surprising results,
Message-ID: <20070727070700.5FF50667EE@slim.kubism.ku.dk>

This is as doumented, and I think you could say the same thing of seq().
BTW, sequence() allows negative inputs, and I don't think you want
sum(input) in that case.

I've never seen the point of sequence(), but it has been around in R for a 
long time.  It is used in packages eRm, extRemes, hydrosanity, klaR, seas.
Who knows what people have in private code, so I don't see any compelling 
case to change it.  If people want a different version, it would only take 
a minute to write (see below).

We could make seq_len take a vector argument, but as you point out in a 
followup that makes it slower in the common case.  It also changes its 
meaning if a length > 1 vector is supplied, and would speed matter in the 
long-vector case?  What does

sequence0 <- function (nvec)
{
     s <- integer(0)
     for (i in nvec) s <- c(s, seq_len(i))
     s
}

not do that is more than a very rare need?


On Thu, 26 Jul 2007, bill at insightful.com wrote:

> Full_Name: Bill Dunlap
> Version: 2.5.0
> OS: Linux
> Submission from: (NULL) (70.98.76.47)
>
>
> sequence(nvec) is documented to return
> the concatenation of seq(nvec[i]), for
> i in seq(along=nvec).  This produces inconvenient
> (for me) results for 0 inputs.
>    > sequence(c(2,0,3)) # would like 1 2 1 2 3, ignore 0
>    [1] 1 2 1 0 1 2 3
> Would changing sequence(nvec) to use seq_len(nvec[i])
> instead of the current 1:nvec[i] break much existing code?
>
> On the other hand, almost no one seems to use sequence()
> and it might make more sense to allow seq_len() and seq()
> to accept a vector for length.out and they would return a
> vector of length sum(length.out),
>    c(seq_len(length.out[1]), seq_len(length.out[2]), ...)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From savicky at cs.cas.cz  Fri Jul 27 09:10:06 2007
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 27 Jul 2007 09:10:06 +0200
Subject: [Rd] sweep sanity checking?
In-Reply-To: <20070725070320.GA20948@cs.cas.cz>
References: <468579C0.7090809@zoo.ufl.edu>
	<loom.20070709T175233-590@post.gmane.org>
	<469557AC.2010607@acm.org> <20070712081616.GA7100@cs.cas.cz>
	<316C7A29-DB9F-4645-A4DF-275BA30E1855@noc.soton.ac.uk>
	<20070713203735.GA18016@cs.cas.cz>
	<20070725070320.GA20948@cs.cas.cz>
Message-ID: <20070727071006.GA31738@cs.cas.cz>

When I was preparing the patch of sweep submitted on July 25, I was
unaware of the code by Heather Turner. She suggested a very elegant
solution, if STATS is a vector and we want to use meaningful recycling
in full generality. I would like to suggest a combined solution, which
uses Heather Turner's algorithm if check.margin=FALSE (default) and STATS
is a vector and my previous algorithm, if check.margin=TRUE or STATS is
an array. The suggestion is

  # combined from the original code of sweep without warnings and from
  # https://stat.ethz.ch/pipermail/r-help/2005-June/073989.html by Robin Hankin
  # https://stat.ethz.ch/pipermail/r-help/2005-June/074001.html by Heather Turner
  # https://stat.ethz.ch/pipermail/r-devel/2007-June/046217.html by Ben Bolker
  # with some further modifications by Petr Savicky
  sweep <- function(x, MARGIN, STATS, FUN = "-", check.margin=FALSE, ...)
  {
      FUN <- match.fun(FUN)
      dims <- dim(x)
      dimmargin <- dims[MARGIN]
      if (is.null(dim(STATS))) {
          dimstats <- length(STATS)
      } else {
          dimstats <- dim(STATS)
          check.margin <- TRUE
      }
      s <- length(STATS)
      if (s > prod(dimmargin)) {
          warning("length of STATS greater than the extent of dim(x)[MARGIN]")
      } else if (check.margin) {
          dimmargin <- dimmargin[dimmargin > 1]
          dimstats <- dimstats[dimstats > 1]
          if (length(dimstats) > length(dimmargin) ||
              any(dimstats != dimmargin[seq(along.with=dimstats)]))
              warning("length(STATS) or dim(STATS) do not match dim(x)[MARGIN]")
      } else {
          cumDim <- c(1, cumprod(dimmargin))
          upper <- min(cumDim[cumDim >= s])
          lower <- max(cumDim[cumDim <= s])
          if (upper %% s != 0 || s %% lower != 0)
              warning("STATS does not recycle exactly across MARGIN")
      }
      perm <- c(MARGIN, (1:length(dims))[ - MARGIN])
      FUN(x, aperm(array(STATS, dims[perm]), order(perm)), ...)
  }

Heather presented four examples testing her code:
  sweep(array(1:24, dim = c(4,3,2)), 1, 1:2)    # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1, 1:12)   # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1, 1:24)   # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1:2, 1:3)  # warning
The second and third example are not really correct, since STATS extends
also to dimensions not included in MARGIN. The problem is better visible
for example in
  sweep(array(1:24, dim = c(4,4,3,3,2,2)), c(1,3), 1:12)
where MARGIN clearly has to contain two dimensions explicitly.
So, I use the examples with a larger margin corresponding to STATS
as follows
  sweep(array(1:24, dim = c(4,3,2)), 1, 1:2)    # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1:2, 1:12) # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1:3, 1:24) # no warning
  sweep(array(1:24, dim = c(4,3,2)), 1:2, 1:3)  # warning
The current proposal for sweep indeed gives no warning in the first
three examples and gives a warning in the last one.

I did not use the suggestion to call the option warn with default
warn = getOption("warn"). The reason is that there are two
different decisions:
 (1) whether to generate a warning
 (2) what to do with the warning, if it is generated.
The warn option influences (2): the warning may be suppressed,
printed after the return to the top level, printed immediately or
it may be converted to an error. I think that the option
controling (2) should not be mixed with an option which
controls (1). If R has an option controling to which extent
recycling is allowed, then this could be used, but warn
has a different purpose.

I appreciate feedback.

Petr.


From r.hankin at noc.soton.ac.uk  Fri Jul 27 09:33:18 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 27 Jul 2007 08:33:18 +0100
Subject: [Rd] (PR#9811) sequence(c(2, 0, 3)) produces surprising results,
In-Reply-To: <20070727070700.5FF50667EE@slim.kubism.ku.dk>
References: <20070727070700.5FF50667EE@slim.kubism.ku.dk>
Message-ID: <7907062F-BD1F-447C-B45F-81F62504A5EB@noc.soton.ac.uk>


On 27 Jul 2007, at 08:07, ripley at stats.ox.ac.uk wrote:

> This is as doumented, and I think you could say the same thing of  
> seq().
> BTW, sequence() allows negative inputs, and I don't think you want
> sum(input) in that case.
>
> I've never seen the point of sequence(), but it has been around in  
> R for a
> long time.  It is used in packages eRm, extRemes, hydrosanity,  
> klaR, seas.
> Who knows what people have in private code, so I don't see any  
> compelling
> case to change it.  If people want a different version, it would  
> only take
> a minute to write (see below).
>
> We could make seq_len take a vector argument, but as you point out  
> in a
> followup that makes it slower in the common case.  It also changes its
> meaning if a length > 1 vector is supplied, and would speed matter  
> in the
> long-vector case?  What does
>
> sequence0 <- function (nvec)
> {
>      s <- integer(0)
>      for (i in nvec) s <- c(s, seq_len(i))
>      s
> }
>
> not do that is more than a very rare need?
>


My 2 cents:

  Defining

        mySequence <- function(x){unlist(sapply(x,function(i){seq_len 
(i)}))}

is much faster.

Neither sequence0()  nor  mySequence() accepts vectors with any  
element <0
although as Brian Ripley points out, sequence() itself does (which I  
think is
undesirable).






Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ripley at stats.ox.ac.uk  Fri Jul 27 13:30:59 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri, 27 Jul 2007 13:30:59 +0200 (CEST)
Subject: [Rd] Rd2dvi (PR#9812)
Message-ID: <20070727113059.E0CD3667F5@slim.kubism.ku.dk>

It seems this feature was introduced in Perl 5.6.1, but that is older than 
Solaris 9 (which was first released 9/02 according to www.sun.com).

We need to know what version of Perl this was.


On Thu, 26 Jul 2007, Bill Dunlap wrote:

> On Thu, 26 Jul 2007 larryh at zebra.us.udel.edu wrote:
>
>> Is this a bug--
>>
>> -------------------------------------------------------------------------------
>> <234>% R CMD Rd2dvi base.Rd
>> Converting Rd files to LaTeX ...
>> base.Rd
>> Can't use an undefined value as filehandle reference at
>> /opt/R-2.5.1/lib/R/share/perl/R/Rdconv.pm line 78.
>
> This may be due to a change I suggested a while back which
> required perl 5.6 (or so) to work.  The change was to ensure
> that the file handle rdfile was closed when Rdconv was done
> with it.  If this is the problem, upgrading perl to 5.8 will
> make it go away.  Rdconv.pm should have a 'use v5.6' (or 5.8?)
> line at the top if it wants to continue to use this syntax.
>
> <     open(rdfile, "<$Rdname") or die "Rdconv(): Couldn't open '$Rdfile': $!\n";
> <
> ---
>>     open(my $rdfile, "<$Rdname") or die "Rdconv(): Couldn't open '$Rdfile': $!\n";
>>     # Before we added the 'my $' in front of rdfile,
>>     # rdfile was not getting closed.   Now it will close
>>     # when $rdfile goes out of scope.  (We could have added
>>     # a close rdfile at the end of the while(<rdfile>), but
>>     # scoping method is more reliable.
> 123c127
> <     while(<rdfile>){
> ---
>>     while(<$rdfile>){
>
> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>
> "All statements in this message represent the opinions of the author and do
> not necessarily reflect Insightful Corporation policy or position."
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Jul 27 18:37:47 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri, 27 Jul 2007 18:37:47 +0200 (CEST)
Subject: [Rd] (PR#9811) sequence(c(2, 0, 3)) produces surprising results,
Message-ID: <20070727163747.38DFD667EE@slim.kubism.ku.dk>

>>>>> "Robin" == Robin Hankin <r.hankin at noc.soton.ac.uk>
>>>>>     on Fri, 27 Jul 2007 08:33:18 +0100 writes:

    Robin> On 27 Jul 2007, at 08:07, ripley at stats.ox.ac.uk
    Robin> wrote:

    >> This is as doumented, and I think you could say the same
    >> thing of seq().  BTW, sequence() allows negative inputs,
    >> and I don't think you want sum(input) in that case.
    >> 
    >> I've never seen the point of sequence(), but it has been
    >> around in R for a long time.  It is used in packages eRm,
    >> extRemes, hydrosanity, klaR, seas.  Who knows what people
    >> have in private code, so I don't see any compelling case
    >> to change it.  If people want a different version, it
    >> would only take a minute to write (see below).
    >> 
    >> We could make seq_len take a vector argument, but as you
    >> point out in a followup that makes it slower in the
    >> common case.  It also changes its meaning if a length > 1
    >> vector is supplied, and would speed matter in the
    >> long-vector case?  What does
    >> 
    >> sequence0 <- function (nvec) { s <- integer(0) for (i in
    >> nvec) s <- c(s, seq_len(i)) s }
    >> 
    >> not do that is more than a very rare need?
    >> 


 Robin> My 2 cents:

    Robin>   Defining

    Robin>         mySequence <-
    Robin> function(x){unlist(sapply(x,function(i){seq_len(i)}))}

    Robin> is much faster.

    Robin> Neither sequence0() nor mySequence() accepts vectors
    Robin> with any element <0 although as Brian Ripley points
    Robin> out, sequence() itself does (which I think is
    Robin> undesirable).

Yes, I agree.

Some more historical perspective (Brian alluded to) :

As the third R core member (first after Robert & Ross),
I still have access to the following R version 
{on one very old fortunately still running Solaris machine; I'm
 pretty sure it would not compile anymore on any recent
 OS/compiler suite} :

--------------------------------------------------------------------------
..$ R-0.00alpha

R Alpha-Test Version, Copyright (C) 1995 Robert Gentleman and Ross Ihaka

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' for details.

> sequence
function (nvec)
{
        sequence <- NULL
        for (i in (1:length(nvec))) sequence <- c(sequence, seq(nvec[i]))
        sequence
}
>                  
--------------------------------------------------------------------------

which interestingly also "works" for negative nvec[i],
but the way it is written even more clearly suggests that
negative nvec  entries were not the intent.

I'm voting that R should adopt a new (fast, but R code
only) version of sequence() which gives an error for negative
'nvec' entries --- though I do agree with Brian that it's not
really an important function at all.

Martin Maechler, ETH Zurich

PS: 
  Note that this was before R became GPL'ed "Free software", and
  that the R version stems from the following place -- back in 1995 :

  /anonymous at stat.auckland.ac.nz:/pub/R/unix/
  -rw-r--r--  1 51           1371 Jun 20  1995 INSTALL
  -rw-r--r--  1 51         466232 Jun 20  1995 R-unix-src.tar.gz
  -rw-r--r--  1 51           1079 Jun 20  1995 README



From hin-tak.leung at cimr.cam.ac.uk  Fri Jul 27 22:19:31 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 27 Jul 2007 21:19:31 +0100
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11786494.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com> <11786494.post@talk.nabble.com>
Message-ID: <46AA5353.3030806@cimr.cam.ac.uk>

As others as commented, everything going in/out of the .Call() interface
needs to be SEXP (even if it does nothing and you are returning
R_NilValue).

Secondly, your attached code is both (1) too long, and (2) incomplete.

You should write some *simple* R code that
uses only soamInit() and soamUnInit() (the latter is missing and you had 
not included it), Then fill the middle with soamSubmit(). Nobody really
want to read your 60+ line of R code (too long) and incomplete C code
(too short) to work out what's broken. Use complete and short examples
to illustrate your problem!

Also, you seem to take for granted that the typo/length of Argument
in soamSubmit() are those you think they are... e.g. I would put in say, 
for example:

if ((JobID == R_NilValue) || ( TYPEOF(JobID) != INTSXP)) {
     Rprintf("JobID unexpected!\n");
     return R_NilValue;
}

Just to be on the safe side. You may find some surprises there -
trying to do INTEGER() on a REALSXP, or vice versa can be dangerous.

I am still not convinced that your segfault is to do with externalptr -
e.g. the '.Call() must return SEXP' is a basic R extension usage and you
didn't understand that one.

Jonathan Zhou wrote:
> Hi all, 
> 
> Here is the R code function in where I called the two C++ and further below
> are the 2 C++ functions I used to create the externalptr and use it : 
> 
> soam.Rapply <- function (x, func, ...,
>                            join.method=cbind,
>                            njobs,
>                            batch.size=100,
>                            packages=NULL,
>                            savelist=NULL)
> {
>     if(missing(njobs))
>         njobs <- max(1,ceiling(nrow(x)/batch.size))
> 
>     if(!is.matrix(x) && !is.data.frame(x))
>         stop("x must be a matrix or data frame")
> 
>     if(njobs>1)
>         {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
> drop = FALSE])} else {rowSet <- list(x)}
> 
>     sesCon <- .Call("soamInit")
> 
>     script <- " "
> 
>     fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
>     file(fname, open="w+")
>     if(!is.null(savelist)) {
>         dump(savelist, fname)
>         script<-readLines(fname)
>     }
> 
>     if(!is.null(packages))
>     for(counter in 1:length(packages))
>     {
>         temp<-call("library", packages[counter], character.only=TRUE)
>         dput(temp, fname)
>         pack.call<-readLines(fname)
>         script<-append(script, pack.call)
>     }
> 
>     for(counter in 1:njobs)
>     {
>         caller <- paste("caller", counter, sep = "")
>         soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
> FUN=func), caller)
>         dput(soam.call, fname)
>         soam.call<-readLines(fname)
> 
>         temp<-append(script, soam.call)
>         final.script = temp[1]
>         for(count in 2:length(temp)){
>             final.script<-paste(final.script, temp[count], "\n")}
> 
>         .Call("soamSubmit", counter, sesCon, final.script, packages)
>     }
> 
>     .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())
> 
>     for(job in 1:njobs)
>     {
>         caller <- paste("result", job, sep = "")
>         temp = dget(caller)
>         if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
>     }
> 
>     .Call("soamUninit")
> 
>     retval
> }
> 
> *** Here are the 2 C++ functions: 
> 
> extern "C"
> {
> SEXP soamInit ()
> {
>     // Initialize the API
>     SoamFactory::initialize();
> 
>     // Set up application specific information to be supplied to Symphony
>     char appName[] = "SampleAppCPP";
> 
>     // Set up application authentication information using the default
> security provider
>     DefaultSecurityCallback securityCB("Guest", "Guest");
> 
>     // Connect to the specified application
>     ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);
> 
>     // Set up session creation attributes
>     SessionCreationAttributes attributes;
>     attributes.setSessionName("mySession");
>     attributes.setSessionType("ShortRunningTasks");
>     attributes.setSessionFlags(SF_RECEIVE_SYNC);
> 
>     // Create a synchronous session
>     Session* sesPtr = conPtr->createSession(attributes);
> 
>     SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);
> 
>     return out;
> }
> }
> 
> extern "C"
> {
>   void soamSubmit	(SEXP jobID,		//job ID
> 			 SEXP sesCon,		//session pointer
> 			 SEXP caller,			//objects
> 			 SEXP pack)			//packages
> {
> 	char* savelist = CHAR(STRING_ELT(caller, 0));
> 	string strTemp = "";
> 	int job = INTEGER(jobID)[0];
> 
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
> 
>     // Create a message
> 	MyMessage inMsg(job, /*pack,*/ savelist);
> 
>     // Send it
>     TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
> }
> }


From jmc at r-project.org  Sat Jul 28 15:38:45 2007
From: jmc at r-project.org (John Chambers)
Date: Sat, 28 Jul 2007 09:38:45 -0400
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited from
 'array', or intended behavior?
In-Reply-To: <1185187439.6294.58.camel@dirac>
References: <1185181337.6294.29.camel@dirac> <1185187439.6294.58.camel@dirac>
Message-ID: <46AB46E5.2080301@r-project.org>

Yes, this is the intended behavior.  Nothing to do with implicit 
generics, but with some ongoing changes to make class "structure" and 
related classes such as "array" give trustworthy results consistent with 
the S language idea of vector structures.  There's a short note in NEWS 
about the changes, added for the revision where the change was introduced.

As for programming your class, using showMethods("+") as below will tell 
you that the method is inherited from the group generic function "Ops", 
so a method for that function is needed, if you _really_ know what the 
results should be.

The behavior of the base package code for operations is unacceptable for 
trustworthy computations with classes.  Roughly, it takes the attributes 
of the left-hand operand and inserts those into the result of operating 
on the vector or array part.  So in the example below we have two  
unrelated classes that both extend "array".  A mixed operation gives a 
result from class "A1" if done in one order and from "A2" if done in the 
other order.  Both are likely wrong and quite possibly seriously misleading.

Even if the two objects came from the same class, copying one set of 
attributes makes sense only if the two sets are identical (an expensive 
test) and not necessarily even then, if any of the attributes would be 
invalidated by the operation.

Two acceptable results are either to reduce to the common inheritance 
(array, here) or to call the result undefined and throw an error.  The 
current implementation in 2.6.0  is the first, as the example shows:

 > setClass("A1", contains="array", representation(flag = "character"))
[1] "A1"
 > setClass("A2", contains="array", representation(positive = "logical"))
[1] "A2"
 > a1 = new("A1", array(1:8, rep(2,3)), flag = "test")
 > a2 = new("A2", array(8:1, rep(2,3)), positive = rep(TRUE,8))
 > a1+a2
, , 1

     [,1] [,2]
[1,]    9    9
[2,]    9    9

, , 2

     [,1] [,2]
[1,]    9    9
[2,]    9    9

 > showMethods("+")
Function: + (package base)
e1="A1", e2="A2"
    (inherited from: e1="array", e2="array")
    (definition from function "Ops")


Oleg Sklyar wrote:
> Narrowed down to Rev. 42246:
>
> * ~/R/Rsvn: svn up -r42245
> * ~/R/Rsvn: make
> * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> * ~/R/Rsvn: Rsvn
>   
>> version$version.string
>>     
> [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42245)"
>   
>> library(EBImage)
>> a <- Image(0,c(2,2))
>> class(a+a)
>>     
> [1] "Image"
> attr(,"package")
> [1] "EBImage"
>
> * ~/R/Rsvn: svn up -r42246
> * ~/R/Rsvn: make
> * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> * ~/R/Rsvn: Rsvn
>   
>> version$version.string
>>     
> [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42246)"
>   
>> library(EBImage)
>> a <- Image(0,c(2,2))
>> class(a+a)
>>     
> [1] "array"
>
> * ~/R/Rsvn: svn log -r42246
> ------------------------------------------------------------------------
> r42246 | jmc | 2007-07-16 14:32:16 +0100 (Mon, 16 Jul 2007) | 1 line
>
> implicitGeneric() and structure class
> ------------------------------------------------------------------------
>
>   

From osklyar at ebi.ac.uk  Sat Jul 28 18:03:52 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Sat, 28 Jul 2007 17:03:52 +0100
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited
	from	'array', or intended behavior?
In-Reply-To: <46AB46E5.2080301@r-project.org>
References: <1185181337.6294.29.camel@dirac>
	<1185187439.6294.58.camel@dirac>  <46AB46E5.2080301@r-project.org>
Message-ID: <1185638632.32611.2.camel@carbon>

John, thank you for clarification. I just wonder that some packages
could also see that their behaviour has changed. Anyway, I redefined
Arith as the rest seems to work fine and also it is pretty straight
forward in my case what the result of Arith should be. Thanks again.
Oleg

On Sat, 2007-07-28 at 09:38 -0400, John Chambers wrote:
> Yes, this is the intended behavior.  Nothing to do with implicit
> generics, but with some ongoing changes to make class "structure" and
> related classes such as "array" give trustworthy results consistent
> with the S language idea of vector structures.  There's a short note
> in NEWS about the changes, added for the revision where the change was
> introduced.
> 
> As for programming your class, using showMethods("+") as below will
> tell you that the method is inherited from the group generic function
> "Ops", so a method for that function is needed, if you _really_ know
> what the results should be.
> 
> The behavior of the base package code for operations is unacceptable
> for trustworthy computations with classes.  Roughly, it takes the
> attributes of the left-hand operand and inserts those into the result
> of operating on the vector or array part.  So in the example below we
> have two  unrelated classes that both extend "array".  A mixed
> operation gives a result from class "A1" if done in one order and from
> "A2" if done in the other order.  Both are likely wrong and quite
> possibly seriously misleading.
> 
> Even if the two objects came from the same class, copying one set of
> attributes makes sense only if the two sets are identical (an
> expensive test) and not necessarily even then, if any of the
> attributes would be invalidated by the operation.
> 
> Two acceptable results are either to reduce to the common inheritance
> (array, here) or to call the result undefined and throw an error.  The
> current implementation in 2.6.0  is the first, as the example shows:
> 
> > setClass("A1", contains="array", representation(flag = "character"))
> [1] "A1"
> > setClass("A2", contains="array", representation(positive =
> "logical"))
> [1] "A2"
> > a1 = new("A1", array(1:8, rep(2,3)), flag = "test")
> > a2 = new("A2", array(8:1, rep(2,3)), positive = rep(TRUE,8))
> > a1+a2
> , , 1
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> , , 2
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> > showMethods("+")
> Function: + (package base)
> e1="A1", e2="A2"
>     (inherited from: e1="array", e2="array")
>     (definition from function "Ops")
> 
> 
> Oleg Sklyar wrote: 
> > Narrowed down to Rev. 42246:
> > 
> > * ~/R/Rsvn: svn up -r42245
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42245)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "Image"
> > attr(,"package")
> > [1] "EBImage"
> > 
> > * ~/R/Rsvn: svn up -r42246
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42246)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "array"
> > 
> > * ~/R/Rsvn: svn log -r42246
> > ------------------------------------------------------------------------
> > r42246 | jmc | 2007-07-16 14:32:16 +0100 (Mon, 16 Jul 2007) | 1 line
> > 
> > implicitGeneric() and structure class
> > ------------------------------------------------------------------------
> > 
> >   


From Albart.Coster at wur.nl  Mon Jul 30 09:05:54 2007
From: Albart.Coster at wur.nl (Coster, Albart)
Date: Mon, 30 Jul 2007 09:05:54 +0200
Subject: [Rd] developing a package: increase the number of functions
References: <mailman.5.1185703204.3948.r-devel@r-project.org>
Message-ID: <7A2D90F7A83A7547AE23FFC56E88D4F23F7750@scomp0039.wurnet.nl>

Dear list,
 
I am trying to develop a package. I used the function package.skeleton to make the directory tree of the package and then build and compiled the package as described (I hope). Now, I would like to increase the number of functions in the package without overwriting the existing package directory tree, so I put these new functions in the directory R of the tree. When I then build and install the package, I can not find the new functions, so apparently they are omitted from the installation. 
 
My question is: why does this occur? What should I do to get these new functions also installed? 
 
(I am using R 2.4.1)
 
Thanks in advance,
 
Albart Coster

From ripley at stats.ox.ac.uk  Mon Jul 30 09:31:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 30 Jul 2007 08:31:26 +0100 (BST)
Subject: [Rd] developing a package: increase the number of functions
In-Reply-To: <7A2D90F7A83A7547AE23FFC56E88D4F23F7750@scomp0039.wurnet.nl>
References: <mailman.5.1185703204.3948.r-devel@r-project.org>
	<7A2D90F7A83A7547AE23FFC56E88D4F23F7750@scomp0039.wurnet.nl>
Message-ID: <Pine.LNX.4.64.0707300829220.9472@gannet.stats.ox.ac.uk>

On Mon, 30 Jul 2007, Coster, Albart wrote:

> Dear list,
>
> I am trying to develop a package. I used the function package.skeleton 
> to make the directory tree of the package and then build and compiled 
> the package as described (I hope). Now, I would like to increase the 
> number of functions in the package without overwriting the existing 
> package directory tree, so I put these new functions in the directory R 
> of the tree. When I then build and install the package, I can not find 
> the new functions, so apparently they are omitted from the installation.

What file name(s) did you use?  See 'Writing R Extensions' for allowed 
names, and also remember you need to add documentation for those 
functions.

Do you have a NAMESPACE?

> My question is: why does this occur? What should I do to get these new 
> functions also installed?
>
> (I am using R 2.4.1)

Why?  R 2.5.1 is current.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Jul 27 22:19:31 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 27 Jul 2007 21:19:31 +0100
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11786494.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com> <11786494.post@talk.nabble.com>
Message-ID: <46AA5353.3030806@cimr.cam.ac.uk>

As others as commented, everything going in/out of the .Call() interface
needs to be SEXP (even if it does nothing and you are returning
R_NilValue).

Secondly, your attached code is both (1) too long, and (2) incomplete.

You should write some *simple* R code that
uses only soamInit() and soamUnInit() (the latter is missing and you had 
not included it), Then fill the middle with soamSubmit(). Nobody really
want to read your 60+ line of R code (too long) and incomplete C code
(too short) to work out what's broken. Use complete and short examples
to illustrate your problem!

Also, you seem to take for granted that the typo/length of Argument
in soamSubmit() are those you think they are... e.g. I would put in say, 
for example:

if ((JobID == R_NilValue) || ( TYPEOF(JobID) != INTSXP)) {
     Rprintf("JobID unexpected!\n");
     return R_NilValue;
}

Just to be on the safe side. You may find some surprises there -
trying to do INTEGER() on a REALSXP, or vice versa can be dangerous.

I am still not convinced that your segfault is to do with externalptr -
e.g. the '.Call() must return SEXP' is a basic R extension usage and you
didn't understand that one.

Jonathan Zhou wrote:
> Hi all, 
> 
> Here is the R code function in where I called the two C++ and further below
> are the 2 C++ functions I used to create the externalptr and use it : 
> 
> soam.Rapply <- function (x, func, ...,
>                            join.method=cbind,
>                            njobs,
>                            batch.size=100,
>                            packages=NULL,
>                            savelist=NULL)
> {
>     if(missing(njobs))
>         njobs <- max(1,ceiling(nrow(x)/batch.size))
> 
>     if(!is.matrix(x) && !is.data.frame(x))
>         stop("x must be a matrix or data frame")
> 
>     if(njobs>1)
>         {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
> drop = FALSE])} else {rowSet <- list(x)}
> 
>     sesCon <- .Call("soamInit")
> 
>     script <- " "
> 
>     fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
>     file(fname, open="w+")
>     if(!is.null(savelist)) {
>         dump(savelist, fname)
>         script<-readLines(fname)
>     }
> 
>     if(!is.null(packages))
>     for(counter in 1:length(packages))
>     {
>         temp<-call("library", packages[counter], character.only=TRUE)
>         dput(temp, fname)
>         pack.call<-readLines(fname)
>         script<-append(script, pack.call)
>     }
> 
>     for(counter in 1:njobs)
>     {
>         caller <- paste("caller", counter, sep = "")
>         soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
> FUN=func), caller)
>         dput(soam.call, fname)
>         soam.call<-readLines(fname)
> 
>         temp<-append(script, soam.call)
>         final.script = temp[1]
>         for(count in 2:length(temp)){
>             final.script<-paste(final.script, temp[count], "\n")}
> 
>         .Call("soamSubmit", counter, sesCon, final.script, packages)
>     }
> 
>     .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())
> 
>     for(job in 1:njobs)
>     {
>         caller <- paste("result", job, sep = "")
>         temp = dget(caller)
>         if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
>     }
> 
>     .Call("soamUninit")
> 
>     retval
> }
> 
> *** Here are the 2 C++ functions: 
> 
> extern "C"
> {
> SEXP soamInit ()
> {
>     // Initialize the API
>     SoamFactory::initialize();
> 
>     // Set up application specific information to be supplied to Symphony
>     char appName[] = "SampleAppCPP";
> 
>     // Set up application authentication information using the default
> security provider
>     DefaultSecurityCallback securityCB("Guest", "Guest");
> 
>     // Connect to the specified application
>     ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);
> 
>     // Set up session creation attributes
>     SessionCreationAttributes attributes;
>     attributes.setSessionName("mySession");
>     attributes.setSessionType("ShortRunningTasks");
>     attributes.setSessionFlags(SF_RECEIVE_SYNC);
> 
>     // Create a synchronous session
>     Session* sesPtr = conPtr->createSession(attributes);
> 
>     SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);
> 
>     return out;
> }
> }
> 
> extern "C"
> {
>   void soamSubmit	(SEXP jobID,		//job ID
> 			 SEXP sesCon,		//session pointer
> 			 SEXP caller,			//objects
> 			 SEXP pack)			//packages
> {
> 	char* savelist = CHAR(STRING_ELT(caller, 0));
> 	string strTemp = "";
> 	int job = INTEGER(jobID)[0];
> 
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
> 
>     // Create a message
> 	MyMessage inMsg(job, /*pack,*/ savelist);
> 
>     // Send it
>     TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
> }
> }


From bill at insightful.com  Fri Jul 27 21:54:24 2007
From: bill at insightful.com (bill at insightful.com)
Date: Fri, 27 Jul 2007 21:54:24 +0200 (CEST)
Subject: [Rd] (PR#9811) sequence(c(2, 0, 3)) produces surprising results,
Message-ID: <20070727195424.BF65E667EE@slim.kubism.ku.dk>

On Fri, 27 Jul 2007, Prof Brian Ripley wrote:

> This is as doumented, and I think you could say the same thing of seq().
> BTW, sequence() allows negative inputs, and I don't think you want
> sum(input) in that case.

help(sequence) says contradictory things about
the nvec[i]==0 case:
   For each element of 'nvec' the
   sequence 'seq(nvec[i])' is created.  ...
and
   nvec: an integer vector each element
   of which specifies the upper bound ...

0 is not the upper bound of seq(0).

In any case, a suitably general multisequence function
would probably want vectors of both to's and from's.

merge.data.frame() requires a combination of a vectorized
sequence function and rep.  It uses a .Internal to do
the job well.  (This is a case where the individual sequences
typically have length one or zero.)

  > .Internal(merge(rep(1:3, c(3,0,5)), rep(1:4, c(2,2,3,2)), T, T))
  $xi
   [1] 1 1 2 2 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8

  $yi
   [1] 1 2 1 2 1 2 5 6 7 5 6 7 5 6 7 5 6 7 5 6 7

  $x.alone
  integer(0)

  $y.alone
  integer(0)

sequence and rep produce complementary outputs, except in the nvec[i]==0 case.
  > rep(1:3, c(5,2,7)) # identifies group
   [1] 1 1 1 1 1 2 2 3 3 3 3 3 3 3
  > sequence(c(5,2,7)) # which in group
   [1] 1 2 3 4 5 1 2 1 2 3 4 5 6 7

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From jmc at r-project.org  Sat Jul 28 15:38:45 2007
From: jmc at r-project.org (John Chambers)
Date: Sat, 28 Jul 2007 09:38:45 -0400
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited from
 'array', or intended behavior?
In-Reply-To: <1185187439.6294.58.camel@dirac>
References: <1185181337.6294.29.camel@dirac> <1185187439.6294.58.camel@dirac>
Message-ID: <46AB46E5.2080301@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070728/eddf5bea/attachment.pl 

From osklyar at ebi.ac.uk  Sat Jul 28 18:03:52 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Sat, 28 Jul 2007 17:03:52 +0100
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited
	from	'array', or intended behavior?
In-Reply-To: <46AB46E5.2080301@r-project.org>
References: <1185181337.6294.29.camel@dirac>
	<1185187439.6294.58.camel@dirac>  <46AB46E5.2080301@r-project.org>
Message-ID: <1185638632.32611.2.camel@carbon>

John, thank you for clarification. I just wonder that some packages
could also see that their behaviour has changed. Anyway, I redefined
Arith as the rest seems to work fine and also it is pretty straight
forward in my case what the result of Arith should be. Thanks again.
Oleg

On Sat, 2007-07-28 at 09:38 -0400, John Chambers wrote:
> Yes, this is the intended behavior.  Nothing to do with implicit
> generics, but with some ongoing changes to make class "structure" and
> related classes such as "array" give trustworthy results consistent
> with the S language idea of vector structures.  There's a short note
> in NEWS about the changes, added for the revision where the change was
> introduced.
> 
> As for programming your class, using showMethods("+") as below will
> tell you that the method is inherited from the group generic function
> "Ops", so a method for that function is needed, if you _really_ know
> what the results should be.
> 
> The behavior of the base package code for operations is unacceptable
> for trustworthy computations with classes.  Roughly, it takes the
> attributes of the left-hand operand and inserts those into the result
> of operating on the vector or array part.  So in the example below we
> have two  unrelated classes that both extend "array".  A mixed
> operation gives a result from class "A1" if done in one order and from
> "A2" if done in the other order.  Both are likely wrong and quite
> possibly seriously misleading.
> 
> Even if the two objects came from the same class, copying one set of
> attributes makes sense only if the two sets are identical (an
> expensive test) and not necessarily even then, if any of the
> attributes would be invalidated by the operation.
> 
> Two acceptable results are either to reduce to the common inheritance
> (array, here) or to call the result undefined and throw an error.  The
> current implementation in 2.6.0  is the first, as the example shows:
> 
> > setClass("A1", contains="array", representation(flag = "character"))
> [1] "A1"
> > setClass("A2", contains="array", representation(positive =
> "logical"))
> [1] "A2"
> > a1 = new("A1", array(1:8, rep(2,3)), flag = "test")
> > a2 = new("A2", array(8:1, rep(2,3)), positive = rep(TRUE,8))
> > a1+a2
> , , 1
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> , , 2
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> > showMethods("+")
> Function: + (package base)
> e1="A1", e2="A2"
>     (inherited from: e1="array", e2="array")
>     (definition from function "Ops")
> 
> 
> Oleg Sklyar wrote: 
> > Narrowed down to Rev. 42246:
> > 
> > * ~/R/Rsvn: svn up -r42245
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42245)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "Image"
> > attr(,"package")
> > [1] "EBImage"
> > 
> > * ~/R/Rsvn: svn up -r42246
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42246)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "array"
> > 
> > * ~/R/Rsvn: svn log -r42246
> > ------------------------------------------------------------------------
> > r42246 | jmc | 2007-07-16 14:32:16 +0100 (Mon, 16 Jul 2007) | 1 line
> > 
> > implicitGeneric() and structure class
> > ------------------------------------------------------------------------
> > 
> >


From bolker at zoo.ufl.edu  Mon Jul 30 14:05:30 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 30 Jul 2007 08:05:30 -0400
Subject: [Rd] behavior of L-BFGS-B with trivial function triggers bug in
	stats4::mle
Message-ID: <46ADD40A.2010203@zoo.ufl.edu>


  [sent this last night, may have bounced, resending]

  With R 2.5.1 ...

  "L-BFGS-B" behaves differently from all of the
other optim() methods, which return the value of the function
when they are given a trivial function (i.e., one with no
variable arguments) to optimize.  I don't think this
is a "bug" in L-BFGS-B (more like a response to
an undefined condition), but it leads to a bug in stats4::mle --
a spurious error saying that a better fit
has been found during profiling if one tries to profile
a 1-parameter model that was originally fitted with "L-BFGS-B".

 I haven't dug quite all the way to the bottom of this
yet, but the attached code will clearly show the problem.

 In the version of mle that I've built (which has
gotten some ugly bells and whistles added) I added
a check which would be more or less equivalent
to check if length(start)==0 and then setting

   oout <- list(par=start, value=f(start),
                hessian = matrix(numeric(0),0,0)

or something along those lines.

 Or one could change L-BFGS-B to behave the same
as the other methods.

cheers
  Ben Bolker

---------------------
library(stats4)

## using example from ?mle
x <- 0:10
y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
ll <- function(ymax=15, xhalf=6)
 -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))

## fix one parameter to get 1D profile
fit2 <- mle(ll, fixed=list(xhalf=6))
profile(fit2)

## same again with method="L-BFGS-B"
fit3 <- mle(ll, fixed=list(xhalf=6),method="L-BFGS-B")
profile(fit3)   ## BUG

ll0 <- function(zzz) {
 ymax <- 15
 xhalf <- 6
 -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}

## try mle() with all-fixed parameters with various methods ...
methods = eval(formals(optim)$method)
sapply(methods,
      function(m) {
        -logLik(mle(ll, start=list(ymax=15,xhalf=6),
                    fixed=list(ymax=15,xhalf=6),method=m))
      })
##   Nelder-Mead          BFGS            CG      L-BFGS-B          SANN
##  3.389441e+01  3.389441e+01  3.389441e+01 5.048277e-270  3.389441e+01


From hin-tak.leung at cimr.cam.ac.uk  Fri Jul 27 22:19:31 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 27 Jul 2007 21:19:31 +0100
Subject: [Rd] Using R_MakeExternalPtr
In-Reply-To: <11786494.post@talk.nabble.com>
References: <11785023.post@talk.nabble.com> <11786494.post@talk.nabble.com>
Message-ID: <46AA5353.3030806@cimr.cam.ac.uk>

As others as commented, everything going in/out of the .Call() interface
needs to be SEXP (even if it does nothing and you are returning
R_NilValue).

Secondly, your attached code is both (1) too long, and (2) incomplete.

You should write some *simple* R code that
uses only soamInit() and soamUnInit() (the latter is missing and you had 
not included it), Then fill the middle with soamSubmit(). Nobody really
want to read your 60+ line of R code (too long) and incomplete C code
(too short) to work out what's broken. Use complete and short examples
to illustrate your problem!

Also, you seem to take for granted that the typo/length of Argument
in soamSubmit() are those you think they are... e.g. I would put in say, 
for example:

if ((JobID == R_NilValue) || ( TYPEOF(JobID) != INTSXP)) {
     Rprintf("JobID unexpected!\n");
     return R_NilValue;
}

Just to be on the safe side. You may find some surprises there -
trying to do INTEGER() on a REALSXP, or vice versa can be dangerous.

I am still not convinced that your segfault is to do with externalptr -
e.g. the '.Call() must return SEXP' is a basic R extension usage and you
didn't understand that one.

Jonathan Zhou wrote:
> Hi all, 
> 
> Here is the R code function in where I called the two C++ and further below
> are the 2 C++ functions I used to create the externalptr and use it : 
> 
> soam.Rapply <- function (x, func, ...,
>                            join.method=cbind,
>                            njobs,
>                            batch.size=100,
>                            packages=NULL,
>                            savelist=NULL)
> {
>     if(missing(njobs))
>         njobs <- max(1,ceiling(nrow(x)/batch.size))
> 
>     if(!is.matrix(x) && !is.data.frame(x))
>         stop("x must be a matrix or data frame")
> 
>     if(njobs>1)
>         {rowSet <- lapply(splitIndices(nrow(x), njobs), function(i) x[i, ,
> drop = FALSE])} else {rowSet <- list(x)}
> 
>     sesCon <- .Call("soamInit")
> 
>     script <- " "
> 
>     fname <- tempfile(pattern = "Rsoam_data", tmpdir = getwd())
>     file(fname, open="w+")
>     if(!is.null(savelist)) {
>         dump(savelist, fname)
>         script<-readLines(fname)
>     }
> 
>     if(!is.null(packages))
>     for(counter in 1:length(packages))
>     {
>         temp<-call("library", packages[counter], character.only=TRUE)
>         dput(temp, fname)
>         pack.call<-readLines(fname)
>         script<-append(script, pack.call)
>     }
> 
>     for(counter in 1:njobs)
>     {
>         caller <- paste("caller", counter, sep = "")
>         soam.call<-call("dput", call("apply", X=rowSet[[counter]], MARGIN=1,
> FUN=func), caller)
>         dput(soam.call, fname)
>         soam.call<-readLines(fname)
> 
>         temp<-append(script, soam.call)
>         final.script = temp[1]
>         for(count in 2:length(temp)){
>             final.script<-paste(final.script, temp[count], "\n")}
> 
>         .Call("soamSubmit", counter, sesCon, final.script, packages)
>     }
> 
>     .Call("soamGetResults", sesCon, njobs, join.method, parent.frame())
> 
>     for(job in 1:njobs)
>     {
>         caller <- paste("result", job, sep = "")
>         temp = dget(caller)
>         if(job==1) {retval=temp} else {retval=join.method(retval,temp)}
>     }
> 
>     .Call("soamUninit")
> 
>     retval
> }
> 
> *** Here are the 2 C++ functions: 
> 
> extern "C"
> {
> SEXP soamInit ()
> {
>     // Initialize the API
>     SoamFactory::initialize();
> 
>     // Set up application specific information to be supplied to Symphony
>     char appName[] = "SampleAppCPP";
> 
>     // Set up application authentication information using the default
> security provider
>     DefaultSecurityCallback securityCB("Guest", "Guest");
> 
>     // Connect to the specified application
>     ConnectionPtr conPtr = SoamFactory::connect(appName, &securityCB);
> 
>     // Set up session creation attributes
>     SessionCreationAttributes attributes;
>     attributes.setSessionName("mySession");
>     attributes.setSessionType("ShortRunningTasks");
>     attributes.setSessionFlags(SF_RECEIVE_SYNC);
> 
>     // Create a synchronous session
>     Session* sesPtr = conPtr->createSession(attributes);
> 
>     SEXP out = R_MakeExternalPtr((void*)temp, R_NilValue, R_NilValue);
> 
>     return out;
> }
> }
> 
> extern "C"
> {
>   void soamSubmit	(SEXP jobID,		//job ID
> 			 SEXP sesCon,		//session pointer
> 			 SEXP caller,			//objects
> 			 SEXP pack)			//packages
> {
> 	char* savelist = CHAR(STRING_ELT(caller, 0));
> 	string strTemp = "";
> 	int job = INTEGER(jobID)[0];
> 
> 	void* temp = R_ExternalPtrAddr(sesCon);
>         Session* sesPtr = reinterpret_cast<Session*>(temp);
> 
>     // Create a message
> 	MyMessage inMsg(job, /*pack,*/ savelist);
> 
>     // Send it
>     TaskInputHandlePtr input = sesPtr->sendTaskInput(&inMsg);
> }
> }


From bill at insightful.com  Fri Jul 27 21:54:24 2007
From: bill at insightful.com (bill at insightful.com)
Date: Fri, 27 Jul 2007 21:54:24 +0200 (CEST)
Subject: [Rd] (PR#9811) sequence(c(2, 0, 3)) produces surprising results,
Message-ID: <20070727195424.BF65E667EE@slim.kubism.ku.dk>

On Fri, 27 Jul 2007, Prof Brian Ripley wrote:

> This is as doumented, and I think you could say the same thing of seq().
> BTW, sequence() allows negative inputs, and I don't think you want
> sum(input) in that case.

help(sequence) says contradictory things about
the nvec[i]==0 case:
   For each element of 'nvec' the
   sequence 'seq(nvec[i])' is created.  ...
and
   nvec: an integer vector each element
   of which specifies the upper bound ...

0 is not the upper bound of seq(0).

In any case, a suitably general multisequence function
would probably want vectors of both to's and from's.

merge.data.frame() requires a combination of a vectorized
sequence function and rep.  It uses a .Internal to do
the job well.  (This is a case where the individual sequences
typically have length one or zero.)

  > .Internal(merge(rep(1:3, c(3,0,5)), rep(1:4, c(2,2,3,2)), T, T))
  $xi
   [1] 1 1 2 2 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8

  $yi
   [1] 1 2 1 2 1 2 5 6 7 5 6 7 5 6 7 5 6 7 5 6 7

  $x.alone
  integer(0)

  $y.alone
  integer(0)

sequence and rep produce complementary outputs, except in the nvec[i]==0 case.
  > rep(1:3, c(5,2,7)) # identifies group
   [1] 1 1 1 1 1 2 2 3 3 3 3 3 3 3
  > sequence(c(5,2,7)) # which in group
   [1] 1 2 3 4 5 1 2 1 2 3 4 5 6 7

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From osklyar at ebi.ac.uk  Sat Jul 28 18:03:52 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Sat, 28 Jul 2007 17:03:52 +0100
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited
	from	'array', or intended behavior?
In-Reply-To: <46AB46E5.2080301@r-project.org>
References: <1185181337.6294.29.camel@dirac>
	<1185187439.6294.58.camel@dirac>  <46AB46E5.2080301@r-project.org>
Message-ID: <1185638632.32611.2.camel@carbon>

John, thank you for clarification. I just wonder that some packages
could also see that their behaviour has changed. Anyway, I redefined
Arith as the rest seems to work fine and also it is pretty straight
forward in my case what the result of Arith should be. Thanks again.
Oleg

On Sat, 2007-07-28 at 09:38 -0400, John Chambers wrote:
> Yes, this is the intended behavior.  Nothing to do with implicit
> generics, but with some ongoing changes to make class "structure" and
> related classes such as "array" give trustworthy results consistent
> with the S language idea of vector structures.  There's a short note
> in NEWS about the changes, added for the revision where the change was
> introduced.
> 
> As for programming your class, using showMethods("+") as below will
> tell you that the method is inherited from the group generic function
> "Ops", so a method for that function is needed, if you _really_ know
> what the results should be.
> 
> The behavior of the base package code for operations is unacceptable
> for trustworthy computations with classes.  Roughly, it takes the
> attributes of the left-hand operand and inserts those into the result
> of operating on the vector or array part.  So in the example below we
> have two  unrelated classes that both extend "array".  A mixed
> operation gives a result from class "A1" if done in one order and from
> "A2" if done in the other order.  Both are likely wrong and quite
> possibly seriously misleading.
> 
> Even if the two objects came from the same class, copying one set of
> attributes makes sense only if the two sets are identical (an
> expensive test) and not necessarily even then, if any of the
> attributes would be invalidated by the operation.
> 
> Two acceptable results are either to reduce to the common inheritance
> (array, here) or to call the result undefined and throw an error.  The
> current implementation in 2.6.0  is the first, as the example shows:
> 
> > setClass("A1", contains="array", representation(flag = "character"))
> [1] "A1"
> > setClass("A2", contains="array", representation(positive =
> "logical"))
> [1] "A2"
> > a1 = new("A1", array(1:8, rep(2,3)), flag = "test")
> > a2 = new("A2", array(8:1, rep(2,3)), positive = rep(TRUE,8))
> > a1+a2
> , , 1
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> , , 2
> 
>      [,1] [,2]
> [1,]    9    9
> [2,]    9    9
> 
> > showMethods("+")
> Function: + (package base)
> e1="A1", e2="A2"
>     (inherited from: e1="array", e2="array")
>     (definition from function "Ops")
> 
> 
> Oleg Sklyar wrote: 
> > Narrowed down to Rev. 42246:
> > 
> > * ~/R/Rsvn: svn up -r42245
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42245)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "Image"
> > attr(,"package")
> > [1] "EBImage"
> > 
> > * ~/R/Rsvn: svn up -r42246
> > * ~/R/Rsvn: make
> > * ~/R/Rsvn: Rsvn CMD INSTALL ~/tmp/EBImage_2.1.13.tar.gz
> > * ~/R/Rsvn: Rsvn
> >   
> > > version$version.string
> > >     
> > [1] "R version 2.6.0 Under development (unstable) (2007-07-16 r42246)"
> >   
> > > library(EBImage)
> > > a <- Image(0,c(2,2))
> > > class(a+a)
> > >     
> > [1] "array"
> > 
> > * ~/R/Rsvn: svn log -r42246
> > ------------------------------------------------------------------------
> > r42246 | jmc | 2007-07-16 14:32:16 +0100 (Mon, 16 Jul 2007) | 1 line
> > 
> > implicitGeneric() and structure class
> > ------------------------------------------------------------------------
> > 
> >


From jmc at r-project.org  Sat Jul 28 15:38:45 2007
From: jmc at r-project.org (John Chambers)
Date: Sat, 28 Jul 2007 09:38:45 -0400
Subject: [Rd] R2.6 bug in arithmetics of S4 classes inherited from
 'array', or intended behavior?
In-Reply-To: <1185187439.6294.58.camel@dirac>
References: <1185181337.6294.29.camel@dirac> <1185187439.6294.58.camel@dirac>
Message-ID: <46AB46E5.2080301@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070728/eddf5bea/attachment-0001.pl 

From bolker at zoo.ufl.edu  Mon Jul 30 00:04:23 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 29 Jul 2007 18:04:23 -0400
Subject: [Rd] behavior of L-BFGS-B with trivial function triggers bug in
	stats4::mle
Message-ID: <46AD0EE7.4050700@zoo.ufl.edu>


   With the exception of "L-BFGS-B", all of the
other optim() methods return the value of the function
when they are given a trivial function (i.e., one with no
variable arguments) to optimize.  I don't think this
is a "bug" in L-BFGS-B (more like a response to
an undefined condition), but it leads to a bug in stats4::mle --
 a spurious error saying that a better fit
has been found during profiling if one tries to profile
a 1-parameter model.

  I haven't dug quite all the way to the bottom of this
yet, but the attached code will clearly show the problem.

  In the version of mle that I've built (which has
gotten some ugly bells and whistles added) I added
a check which would be more or less equivalent
to check if length(start)==0 and then setting

    oout <- list(par=start, value=f(start),
                 hessian = matrix(numeric(0),0,0)
 
 or something along those lines.

  Or one could change L-BFGS-B to behave the same
as the other methods.

 cheers
   Ben Bolker

---------------------
library(stats4)

## using example from ?mle
x <- 0:10
y <- c(26, 17, 13, 12, 20, 5, 9, 8, 5, 4, 8)
ll <- function(ymax=15, xhalf=6)
  -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))

## fix one parameter to get 1D profile
fit2 <- mle(ll, fixed=list(xhalf=6))
profile(fit2)

## same again with method="L-BFGS-B"
fit3 <- mle(ll, fixed=list(xhalf=6),method="L-BFGS-B")
profile(fit3)

ll0 <- function(zzz) {
  ymax <- 15
  xhalf <- 6
  -sum(stats::dpois(y, lambda=ymax/(1+x/xhalf), log=TRUE))
}

## try mle() with all-fixed parameters with various methods ...
methods = eval(formals(optim)$method)
sapply(methods,
       function(m) {
         -logLik(mle(ll, start=list(ymax=15,xhalf=6),
                     fixed=list(ymax=15,xhalf=6),method=m))
       })
##   Nelder-Mead          BFGS            CG      L-BFGS-B          SANN
##  3.389441e+01  3.389441e+01  3.389441e+01 5.048277e-270  3.389441e+01


From josh.quigley at tibra.com.au  Tue Jul 31 10:09:41 2007
From: josh.quigley at tibra.com.au (josh.quigley at tibra.com.au)
Date: Tue, 31 Jul 2007 10:09:41 +0200 (CEST)
Subject: [Rd] POSIXct Formating Error (PR#9819)
Message-ID: <20070731080941.553F0667EA@slim.kubism.ku.dk>

To Whom It May Concern:

 

The following appears to be a bug in the way POSIXct dates are formated.

The example is forced, but occurs naturally when importing Excel type dates

(where fractional part is fraction of a day) and small rounding errors
result.

 

As shown, looking at the POSIXct class, it looks as if both times are
16:11:03 (truncation)

Looking at as.numeric.POSIXct, it looks as if the times should be 1 second
different (rounding)

 

Looking at more digits shows the problem, the character format is truncating
the fractional part while

the numeric format is rounding it.

 

The workaround of rounding the POSIXct is non-trivial, as it is not possible
(or at least I can't)

manipulate the POSIXct number directly. Rather, you need to go to POSIXlt,
round and then go back.

 

------------------------------------------------------------------ Example
----------

 

> a <- as.POSIXct(c("2007-07-27 16:11:03.000002", "2007-07-27
16:11:03.999995"))

> a

 

[1] "2007-07-27 16:11:03 AUS Eastern Standard Time"

[2] "2007-07-27 16:11:03 AUS Eastern Standard Time"

 

> as.numeric(a)

 

[1] 1185516663 1185516664

 

> format(as.numeric(a), digits=20)

 

[1] "1185516663.000002" "1185516663.999995"

 

 

Yours truly,

 

Josh Quigley.

 

-- please do not edit the information below
---------------------------------------------

 

Version:

 platform = i386-pc-mingw32

 arch = i386

 os = mingw32

 system = i386, mingw32

 status = 

 major = 2

 minor = 5.0

 year = 2007

 month = 04

 day = 23

 svn rev = 41293

 language = R

 version.string = R version 2.5.0 (2007-04-23)

 

Windows XP (build 2600) Service Pack 2.0

 

Locale:

LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETAR
Y=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

 

Search Path:

 .GlobalEnv, package:zoo, package:chron, package:RDCOMClient, package:stats,
package:graphics, package:grDevices, package:utils, package:datasets,
package:methods, Autoloads, package:base

 

 


	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Tue Jul 31 10:35:52 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 31 Jul 2007 10:35:52 +0200 (CEST)
Subject: [Rd] POSIXct Formating Error (PR#9819)
Message-ID: <20070731083552.71653667E6@slim.kubism.ku.dk>

No bug, as intended.  If you want to see fractional seconds then you need 
to use a non-default format.  They are not (just) numbers, and fractional 
seconds are intended only for use intentionally.

There is a round() method for POSIXct objects:

> a
[1] "2007-07-27 16:11:03 GMT Daylight Time"
[2] "2007-07-27 16:11:03 GMT Daylight Time"
> format(a, "%Y-%m-%d %H:%M:%OS5")
[1] "2007-07-27 16:11:03.00000" "2007-07-27 16:11:03.99999"
> round(a)
[1] "2007-07-27 16:11:03 GMT Daylight Time"
[2] "2007-07-27 16:11:04 GMT Daylight Time"

which may do what you want.


On Tue, 31 Jul 2007, josh.quigley at tibra.com.au wrote:

> To Whom It May Concern:
>
>
>
> The following appears to be a bug in the way POSIXct dates are formated.
>
> The example is forced, but occurs naturally when importing Excel type dates
>
> (where fractional part is fraction of a day) and small rounding errors
> result.
>
>
>
> As shown, looking at the POSIXct class, it looks as if both times are
> 16:11:03 (truncation)
>
> Looking at as.numeric.POSIXct, it looks as if the times should be 1 second
> different (rounding)
>
>
>
> Looking at more digits shows the problem, the character format is truncating
> the fractional part while
>
> the numeric format is rounding it.
>
>
>
> The workaround of rounding the POSIXct is non-trivial, as it is not possible
> (or at least I can't)
>
> manipulate the POSIXct number directly. Rather, you need to go to POSIXlt,
> round and then go back.
>
>
>
> ------------------------------------------------------------------ Example
> ----------
>
>
>
>> a <- as.POSIXct(c("2007-07-27 16:11:03.000002", "2007-07-27
> 16:11:03.999995"))
>
>> a
>
>
>
> [1] "2007-07-27 16:11:03 AUS Eastern Standard Time"
>
> [2] "2007-07-27 16:11:03 AUS Eastern Standard Time"
>
>
>
>> as.numeric(a)
>
>
>
> [1] 1185516663 1185516664
>
>
>
>> format(as.numeric(a), digits=20)
>
>
>
> [1] "1185516663.000002" "1185516663.999995"
>
>
>
>
>
> Yours truly,
>
>
>
> Josh Quigley.
>
>
>
> -- please do not edit the information below
> ---------------------------------------------
>
>
>
> Version:
>
> platform = i386-pc-mingw32
>
> arch = i386
>
> os = mingw32
>
> system = i386, mingw32
>
> status =
>
> major = 2
>
> minor = 5.0
>
> year = 2007
>
> month = 04
>
> day = 23
>
> svn rev = 41293
>
> language = R
>
> version.string = R version 2.5.0 (2007-04-23)
>
>
>
> Windows XP (build 2600) Service Pack 2.0
>
>
>
> Locale:
>
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETAR
> Y=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>
>
>
> Search Path:
>
> .GlobalEnv, package:zoo, package:chron, package:RDCOMClient, package:stats,
> package:graphics, package:grDevices, package:utils, package:datasets,
> package:methods, Autoloads, package:base
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gregor.gorjanc at bfro.uni-lj.si  Tue Jul 31 15:48:22 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 31 Jul 2007 13:48:22 +0000 (UTC)
Subject: [Rd] developing a package: increase the number of functions
References: <mailman.5.1185703204.3948.r-devel@r-project.org>
	<7A2D90F7A83A7547AE23FFC56E88D4F23F7750@scomp0039.wurnet.nl>
	<Pine.LNX.4.64.0707300829220.9472@gannet.stats.ox.ac.uk>
Message-ID: <loom.20070731T154635-301@post.gmane.org>

Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:
...
> 
> Do you have a NAMESPACE?

Hi Albart!

About the NAMESACE issue. Functions that are specified in NAMESPACE
are available when you install a package, while internal ones can
only be accessed with

myInternalFun:::myPackage

Gregor


From vincent.goulet at act.ulaval.ca  Tue Jul 31 16:18:50 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Tue, 31 Jul 2007 10:18:50 -0400
Subject: [Rd] developing a package: increase the number of functions
In-Reply-To: <loom.20070731T154635-301@post.gmane.org>
References: <mailman.5.1185703204.3948.r-devel@r-project.org>
	<7A2D90F7A83A7547AE23FFC56E88D4F23F7750@scomp0039.wurnet.nl>
	<Pine.LNX.4.64.0707300829220.9472@gannet.stats.ox.ac.uk>
	<loom.20070731T154635-301@post.gmane.org>
Message-ID: <EE48C7FD-5691-4162-883B-B9267832B240@act.ulaval.ca>

Le 07-07-31 ? 09:48, Gregor Gorjanc a ?crit :

> Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:
> ...
>>
>> Do you have a NAMESPACE?
>
> Hi Albart!
>
> About the NAMESACE issue. Functions that are specified in NAMESPACE
> are available when you install a package, while internal ones can
> only be accessed with
>
> myInternalFun:::myPackage

Or rather

myPackage:::myInternalFun

>
> Gregor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
   Vincent Goulet, Associate Professor
   ?cole d'actuariat
   Universit? Laval, Qu?bec
   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From weigand.stephen at gmail.com  Tue Jul 31 18:47:47 2007
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Tue, 31 Jul 2007 11:47:47 -0500
Subject: [Rd] Typo in barplot.Rd
Message-ID: <bc47d3330707310947j75bb07c2qea25b0314abed7c3@mail.gmail.com>

?barplot seems to be missing the word "have" below (so that it reads
"Specifying a single value will have no visible effect..."):

\item{width}{optional vector of bar widths. Re-cycled to length the
    number of bars drawn.  Specifying a single value will no visible
    effect unless \code{xlim} is specified.}

Thanks,

Stephen


From murdoch at stats.uwo.ca  Tue Jul 31 20:48:25 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 31 Jul 2007 14:48:25 -0400
Subject: [Rd] Typo in barplot.Rd
In-Reply-To: <bc47d3330707310947j75bb07c2qea25b0314abed7c3@mail.gmail.com>
References: <bc47d3330707310947j75bb07c2qea25b0314abed7c3@mail.gmail.com>
Message-ID: <46AF83F9.3000602@stats.uwo.ca>

Stephen Weigand wrote:
> ?barplot seems to be missing the word "have" below (so that it reads
> "Specifying a single value will have no visible effect..."):
>
> \item{width}{optional vector of bar widths. Re-cycled to length the
>     number of bars drawn.  Specifying a single value will no visible
>     effect unless \code{xlim} is specified.}

Fixed, thanks.

Duncan Murdoch


