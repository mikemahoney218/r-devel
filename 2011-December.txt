From ggrothendieck at gmail.com  Thu Dec  1 01:56:24 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 30 Nov 2011 19:56:24 -0500
Subject: [Rd] Standardizing included packages
Message-ID: <CAP01uR=AiU-yyndd8wyFN=tr-pogFBA9-cOMTO3an8YhesUEFA@mail.gmail.com>

It seems that R is mostly distributed with the tcltk package but not always.

Is there some reason for this inconsistency?

It would be nice if one could count on those packages that are
distributed on the Windows version of R being distributed on all other
platforms too.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pdalgd at gmail.com  Thu Dec  1 08:42:29 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 1 Dec 2011 08:42:29 +0100
Subject: [Rd] Standardizing included packages
In-Reply-To: <CAP01uR=AiU-yyndd8wyFN=tr-pogFBA9-cOMTO3an8YhesUEFA@mail.gmail.com>
References: <CAP01uR=AiU-yyndd8wyFN=tr-pogFBA9-cOMTO3an8YhesUEFA@mail.gmail.com>
Message-ID: <B0EC50EC-AD99-4555-9752-FFE826C29E50@gmail.com>


On Dec 1, 2011, at 01:56 , Gabor Grothendieck wrote:

> It seems that R is mostly distributed with the tcltk package but not always.
> 
> Is there some reason for this inconsistency?

Well, the tcltk package as such is part of the _source_ distribution of R.

We have no centralized control over what binary distributors might build it against (except OSX and Windows because that is handled by members of the Core Team).

AFAIK, Linux binary distributors usually build against the Tcl/Tk for binary packages. Otherwise, you need to talk to the maintainers. However, there's also the issue of whether Tcl/Tk should be dependencies of R, and whether all R packages appear in one "R" binary package; some distributions like to allow a more modular approach.

It is only on Windows that we ship with our own builds of various libraries. In principle, they are 3rd party products, and especially on Linux, they should really be considered parts of the OS. "Good citizen" software should use what is there and not override system libraries without very good cause. On OSX, the situation is somewhere in between, and the strategy has been to make Tcl/Tk available for download along with the R binaries.


> 
> It would be nice if one could count on those packages that are
> distributed on the Windows version of R being distributed on all other
> platforms too.
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jeremy.reeve1 at gmail.com  Thu Dec  1 07:22:01 2011
From: jeremy.reeve1 at gmail.com (Jeremy Reeve)
Date: Thu, 1 Dec 2011 19:22:01 +1300
Subject: [Rd] HDF5 compound data types and h5r/hdf5 R packages
Message-ID: <CAGAqp0QDJ-pOHRNjf7cD_b9pekrUOTiqsud_bDdwH5imL0BNMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111201/13f70e8f/attachment.pl>

From brian at braverock.com  Thu Dec  1 11:41:39 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 01 Dec 2011 04:41:39 -0600
Subject: [Rd] HDF5 compound data types and h5r/hdf5 R packages
In-Reply-To: <CAGAqp0QDJ-pOHRNjf7cD_b9pekrUOTiqsud_bDdwH5imL0BNMA@mail.gmail.com>
References: <CAGAqp0QDJ-pOHRNjf7cD_b9pekrUOTiqsud_bDdwH5imL0BNMA@mail.gmail.com>
Message-ID: <1322736099.7734.24.camel@brian-desktop>

On Thu, 2011-12-01 at 19:22 +1300, Jeremy Reeve wrote:
> Hi there,
> 
> 
> I have a Java process that writes HDF5 files with the following
> approximate structure:
> 
> group "xxx" {
> 
>     group "yyy" {
> 
>         dataset {}
>         dataset {}
> 
>     }
> 
>     group "zzz" {
> 
>         dataset {}
>         dataset {}
> 
>     }
> 
> }
> 
> where dataset is a rank one dataspace having a compound datatype defined as:
> 
> H5T_UNIX_TIME, float, float, float, float
> 
> I have tried R packages h5r and hdf5 in an attempt to read the file
> but examining the source of h5r and reading documentation for hdf5
> here:  http://xweb.geos.ed.ac.uk/~hcp/Rhdf5.html  leads me to believe
> that compound datatypes are not supported by these packages.  My guess
> is that mapping arbitrary type definitions in HDF5 to available types
> in R might be somewhat tricky.  Incidentally, h5dump has trouble
> displaying the data in the dataset but I think this is to do with the
> time 'field':
> 
>       DATASPACE  SIMPLE { ( 33 ) / ( H5S_UNLIMITED ) }
>       DATA {
>          h5dump error: unable to print data
>       }
> 
> Since I am new to both HDF5 and R I wonder if there are better
> approaches to storing the information I have that will allow me to use
> either h5r or hdf5 packages unmodified.  I expect I can contribute
> changes to either of the packages that will allow me to do what I
> describe but fall short of general compound datatype support.
> 
> Any comments or advice gratefully received.
> 
> Regards...Jeremy

You should contact the maintainers of the two hdf5 packages you
reference.  Hopefully one of them will be open to assisting you,
advising of your immediate problem, and collaborating on extension of
the package. 

If that doesn't work, perhaps the R Bioconductor list would be a better
place for the discussion, since I believe that HDF5 files are mostly
used in the geological and biological sciences.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From hpages at fhcrc.org  Fri Dec  2 02:40:34 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 01 Dec 2011 17:40:34 -0800
Subject: [Rd] 1.6x speedup for requal() function (in R/src/main/unique.c)
Message-ID: <4ED82C92.3010207@fhcrc.org>

Hi,

FWIW:

/* Taken from R/src/main/unique.c */
static int requal(SEXP x, int i, SEXP y, int j)
{
     if (i < 0 || j < 0) return 0;
     if (!ISNAN(REAL(x)[i]) && !ISNAN(REAL(y)[j]))
         return (REAL(x)[i] == REAL(y)[j]);
     else if (R_IsNA(REAL(x)[i]) && R_IsNA(REAL(y)[j])) return 1;
     else if (R_IsNaN(REAL(x)[i]) && R_IsNaN(REAL(y)[j])) return 1;
     else return 0;
}

/* Between 1.34x and 1.37x faster on my 64-bit Ubuntu laptop */
static int requal2(SEXP x, int i, SEXP y, int j)
{
     double xi, yj;

     if (i < 0 || j < 0) return 0;
     xi = REAL(x)[i];
     yj = REAL(y)[j];
     if (!ISNAN(xi) && !ISNAN(yj)) return xi == yj;
     if (R_IsNA(xi) && R_IsNA(yj)) return 1;
     if (R_IsNaN(xi) && R_IsNaN(yj)) return 1;
     return 0;
}

/* Another extra 1.18x speedup. So overall requal3() is about 1.6x
    faster than requal() for me. requal3() uses a simpler logic than
    requal() but this logic should be equivalent to the logic used
    by requal(), based on the following facts:
      (a) If *one* of xi or yi is a number (i.e. not NA or NaN),
          then xi and yi can be compared with xi == yi. They don't
          need to *both* be numbers for this comparison to be valid.
      (b) Otherwise (i.e. if each of them is not a number) then each
          of them is either NA or NaN (only 2 possible values for
          each), so comparing them with R_IsNA(xi) == R_IsNA(yj)
          should do the trick. */
static int requal3(SEXP x, int i, SEXP y, int j)
{
     double xi, yj;

     if (i < 0 || j < 0) return 0;
     xi = REAL(x)[i];
     yj = REAL(y)[j];
     if (!ISNAN(xi) || !ISNAN(yj)) return xi == yj;
     return R_IsNA(xi) == R_IsNA(yj);
}

The logic of the cequal() function (in the same file) could also be
cleaned up in a similar way, probably for an even greater speedup.

This will benefit duplicated(), anyDuplicated() and unique() on numeric
and complex vectors.

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Fri Dec  2 04:13:40 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 01 Dec 2011 22:13:40 -0500
Subject: [Rd] 1.6x speedup for requal() function (in R/src/main/unique.c)
In-Reply-To: <4ED82C92.3010207@fhcrc.org>
References: <4ED82C92.3010207@fhcrc.org>
Message-ID: <4ED84264.4020609@gmail.com>

On 11-12-01 8:40 PM, Herv? Pag?s wrote:
> Hi,
>
> FWIW:
>
> /* Taken from R/src/main/unique.c */
> static int requal(SEXP x, int i, SEXP y, int j)
> {
>       if (i<  0 || j<  0) return 0;
>       if (!ISNAN(REAL(x)[i])&&  !ISNAN(REAL(y)[j]))
>           return (REAL(x)[i] == REAL(y)[j]);
>       else if (R_IsNA(REAL(x)[i])&&  R_IsNA(REAL(y)[j])) return 1;
>       else if (R_IsNaN(REAL(x)[i])&&  R_IsNaN(REAL(y)[j])) return 1;
>       else return 0;
> }
>
> /* Between 1.34x and 1.37x faster on my 64-bit Ubuntu laptop */
> static int requal2(SEXP x, int i, SEXP y, int j)
> {
>       double xi, yj;
>
>       if (i<  0 || j<  0) return 0;
>       xi = REAL(x)[i];
>       yj = REAL(y)[j];
>       if (!ISNAN(xi)&&  !ISNAN(yj)) return xi == yj;
>       if (R_IsNA(xi)&&  R_IsNA(yj)) return 1;
>       if (R_IsNaN(xi)&&  R_IsNaN(yj)) return 1;
>       return 0;
> }

That looks like a valid improvement.

>
> /* Another extra 1.18x speedup. So overall requal3() is about 1.6x
>      faster than requal() for me. requal3() uses a simpler logic than
>      requal() but this logic should be equivalent to the logic used
>      by requal(), based on the following facts:
>        (a) If *one* of xi or yi is a number (i.e. not NA or NaN),
>            then xi and yi can be compared with xi == yi. They don't
>            need to *both* be numbers for this comparison to be valid.
>        (b) Otherwise (i.e. if each of them is not a number) then each
>            of them is either NA or NaN (only 2 possible values for
>            each), so comparing them with R_IsNA(xi) == R_IsNA(yj)
>            should do the trick. */

I think this one is probably correct, but it's too tricky for my taste.

> static int requal3(SEXP x, int i, SEXP y, int j)
> {
>       double xi, yj;
>
>       if (i<  0 || j<  0) return 0;
>       xi = REAL(x)[i];
>       yj = REAL(y)[j];
>       if (!ISNAN(xi) || !ISNAN(yj)) return xi == yj;
>       return R_IsNA(xi) == R_IsNA(yj);
> }

Duncan Murdoch

>
> The logic of the cequal() function (in the same file) could also be
> cleaned up in a similar way, probably for an even greater speedup.
>
> This will benefit duplicated(), anyDuplicated() and unique() on numeric
> and complex vectors.
>
> Cheers,
> H.
>


From bernd.fischer at embl.de  Fri Dec  2 08:48:25 2011
From: bernd.fischer at embl.de (Bernd Fischer)
Date: Fri, 2 Dec 2011 08:48:25 +0100
Subject: [Rd] HDF5 compound data types and h5r/hdf5 R packages
In-Reply-To: <4ED7CC31.2080000@embl.de>
References: <CAGYbZUDVE-SOE=O27JtxK6Koj039UHJFfQA1s=8b-MqN=b-pcQ@mail.gmail.com>
	<4ED7CC31.2080000@embl.de>
Message-ID: <D7561595-9AEA-4098-B8C7-F5F65C790BA5@embl.de>

Dear Jeremy!

I have written a package rhdf5 that can handle compound data types as well. The 
H5T_UNIX_TIME type is not yet supported, but it should be possible to read the floats
into a data.frame.

I put the H5T_UNIX_TIME type on my list and will add it in the next weeks.

Currently, you can download the package from
http://www-huber.embl.de/users/befische/rhdf5/
It will appear on bioconductor in the next couple of days.

Best,

Bernd



> From: Jeremy Reeve <jeremy.reeve1 at gmail.com>
> Date: Wed, Nov 30, 2011 at 10:22 PM
> Subject: [Rd] HDF5 compound data types and h5r/hdf5 R packages
> To: r-devel at r-project.org
> 
> 
> Hi there,
> 
> 
> I have a Java process that writes HDF5 files with the following
> approximate structure:
> 
> group "xxx" {
> 
>   group "yyy" {
> 
>       dataset {}
>       dataset {}
> 
>   }
> 
>   group "zzz" {
> 
>       dataset {}
>       dataset {}
> 
>   }
> 
> }
> 
> where dataset is a rank one dataspace having a compound datatype defined as:
> 
> H5T_UNIX_TIME, float, float, float, float
> 
> I have tried R packages h5r and hdf5 in an attempt to read the file
> but examining the source of h5r and reading documentation for hdf5
> here:  http://xweb.geos.ed.ac.uk/~hcp/Rhdf5.html  leads me to believe
> that compound datatypes are not supported by these packages.  My guess
> is that mapping arbitrary type definitions in HDF5 to available types
> in R might be somewhat tricky.  Incidentally, h5dump has trouble
> displaying the data in the dataset but I think this is to do with the
> time 'field':
> 
>     DATASPACE  SIMPLE { ( 33 ) / ( H5S_UNLIMITED ) }
>     DATA {
>        h5dump error: unable to print data
>     }
> 
> Since I am new to both HDF5 and R I wonder if there are better
> approaches to storing the information I have that will allow me to use
> either h5r or hdf5 packages unmodified.  I expect I can contribute
> changes to either of the packages that will allow me to do what I
> describe but fall short of general compound datatype support.
> 
> Any comments or advice gratefully received.
> 
> Regards...Jeremy
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Bernd Fischer
EMBL Heidelberg
Meyerhofstra?e 1
69117 Heidelberg
Tel: +49 [0] 6221 387-8131
E-Mail: bernd.fischer at embl.de
Homepage: http://www.ebi.ac.uk/~bfischer


From manuel.lopez-ibanez at ulb.ac.be  Sun Dec  4 17:57:32 2011
From: manuel.lopez-ibanez at ulb.ac.be (=?ISO-8859-1?Q?Manuel_L=F3pez-Ib=E1=F1ez?=)
Date: Sun, 04 Dec 2011 17:57:32 +0100
Subject: [Rd] fix type explanation in plot.default
Message-ID: <4EDBA67C.8050105@ulb.ac.be>

The explanation of the 'type' parameter of plot.default is a bit confusing, 
plus the stray closing parenthesis. I suggest the following small change to 
match the one given in plot. Feel free to adjust at your convenience.

Apply to http://svn.r-project.org/R/trunk/src/library/graphics/man/plot.default.Rd

Cheers,
	Manuel.



-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.default.Rd.patch
Type: text/x-diff
Size: 720 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111204/104d8ca9/attachment.bin>

From michael.m.spiegel at gmail.com  Mon Dec  5 17:19:30 2011
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Mon, 5 Dec 2011 11:19:30 -0500
Subject: [Rd] serialize/unserialize vector improvement
In-Reply-To: <alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
References: <CANwu5-oZXZjThFof++sf9bE2xYt-1g60+HjhA3vogD7Qnm_m6Q@mail.gmail.com>
	<CANwu5-qjBe_3-KOH2QvufgBVnt8URRvnYz4Z9Be7m+g0KdeFVA@mail.gmail.com>
	<alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
Message-ID: <CANwu5-rkvsXFCaynUH39hdkytCkMxhKXEQD=jSiuaQPLZwzNqA@mail.gmail.com>

Has there been any movement on this patch? It will improve the
serialize/unserialize performance.

Thanks,
--Michael

On Mon, Oct 3, 2011 at 9:28 AM,  <luke-tierney at uiowa.edu> wrote:
> It's on my list to look at but I may not get to it for a couple of
> weeks. Someone else may get there earlier.
>
> Best,
>
> luke
>
>
> On Mon, 3 Oct 2011, Michael Spiegel wrote:
>
>> Any thoughts? I haven't heard any feedback on this patch.
>>
>> Thanks!
>> --Michael
>>
>> On Wed, Sep 28, 2011 at 3:10 PM, Michael Spiegel
>> <michael.m.spiegel at gmail.com> wrote:
>>>
>>> Hi folks,
>>>
>>> I've attached a patch to the svn trunk that improves the performance
>>> of the serialize/unserialize interface for vector types. The current
>>> implementation: a) invokes the R_XDREncode operation for each element
>>> of the vector type, and b) uses a switch statement to determine the
>>> stream type for each element of the vector type. I've added
>>> R_XDREncodeVector/R_XDRDecodeVector functions that accept N elements
>>> at a time, and I've reorganized the implementation so that the stream
>>> type is not queried once per element.
>>>
>>> In the following microbenchmark (below), I've observed performance
>>> improvements of about x2.4. ?In a real benchmark that is using the
>>> serialization interface to make MPI calls, I see about a 10%
>>> improvement in performance.
>>>
>>> Cheers,
>>> --Michael
>>>
>>> microbenchmark:
>>>
>>> input <- matrix(1:100000000, 10000, 10000)
>>> output <- serialize(input, NULL)
>>> for(i in 1:10) { print(system.time(serialize(input, NULL))) }
>>> for(i in 1:10) { print(system.time(unserialize(output))) }
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
> ? Actuarial Science
> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? ? ?luke at stat.uiowa.edu
> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu


From therneau at mayo.edu  Mon Dec  5 18:11:42 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 05 Dec 2011 11:11:42 -0600
Subject: [Rd] class extension and documentation
Message-ID: <1323105102.1719.37.camel@nemo>

I've added a "backsolve" method to the bdsmatrix library.
Per the Extending manual section 7.1 I've also added the following 3
lines along with my setMethod definitions for 2 classes.

backsolve <- function(r, ...) UseMethod("backsolve")
backsolve.default <- base:::backsolve
formals(backsolve.default) <- c(formals(backsolve.default), alist(...
= )) 

I've also added a backsolve-methods.Rd page, though since my arguments
are identical to the default it doesn't say much.  And, after a test
failed, added the new backsolve.default routine to my export list.

Now R CMD check claims that I need Rd pages for backsolve and
backsolve.default.  I don't think I should rewrite those.  
   How do I sidestep this  and/or
   what other manuals should I read?

Perhaps do setMethod("backsolve", signature(r="ALL"),
                           base:::backsolve(r, ...))
instead?

Terry Therneau


From therneau at mayo.edu  Mon Dec  5 18:26:47 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 05 Dec 2011 11:26:47 -0600
Subject: [Rd] PS to prior note
Message-ID: <1323106007.1719.42.camel@nemo>

Sorry to forget this
> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
base     

---
 
 Further note.  I started out by just having a new setMethod, and let R
do all the behind the scenes bookkeeping as it usually does.  But then
backsolve(cmat, x) fails, where cmat is an ordinary cholesky.  It
doesn't find the default value for ncol.

Terry T.


From murdoch.duncan at gmail.com  Mon Dec  5 19:48:19 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 05 Dec 2011 13:48:19 -0500
Subject: [Rd] class extension and documentation
In-Reply-To: <1323105102.1719.37.camel@nemo>
References: <1323105102.1719.37.camel@nemo>
Message-ID: <4EDD11F3.4090908@gmail.com>

On 05/12/2011 12:11 PM, Terry Therneau wrote:
> I've added a "backsolve" method to the bdsmatrix library.
> Per the Extending manual section 7.1 I've also added the following 3
> lines along with my setMethod definitions for 2 classes.
>
> backsolve<- function(r, ...) UseMethod("backsolve")
> backsolve.default<- base:::backsolve
> formals(backsolve.default)<- c(formals(backsolve.default), alist(...
> = ))
>
> I've also added a backsolve-methods.Rd page, though since my arguments
> are identical to the default it doesn't say much.  And, after a test
> failed, added the new backsolve.default routine to my export list.
>
> Now R CMD check claims that I need Rd pages for backsolve and
> backsolve.default.  I don't think I should rewrite those.
>     How do I sidestep this  and/or
>     what other manuals should I read?

Even though your change is subtle, I'd say it's still a change 
(backsolve is now a generic, not a simple closure; it now has a 
different argument list), so I'd like to see a new man page added.    It 
would be quite reasonable to list the new interface and then refer to 
base::backsolve for the details of what the default method does.

Duncan Murdoch


> Perhaps do setMethod("backsolve", signature(r="ALL"),
>                             base:::backsolve(r, ...))
> instead?
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Mon Dec  5 20:13:16 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 5 Dec 2011 13:13:16 -0600
Subject: [Rd] serialize/unserialize vector improvement
In-Reply-To: <CANwu5-rkvsXFCaynUH39hdkytCkMxhKXEQD=jSiuaQPLZwzNqA@mail.gmail.com>
References: <CANwu5-oZXZjThFof++sf9bE2xYt-1g60+HjhA3vogD7Qnm_m6Q@mail.gmail.com>
	<CANwu5-qjBe_3-KOH2QvufgBVnt8URRvnYz4Z9Be7m+g0KdeFVA@mail.gmail.com>
	<alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
	<CANwu5-rkvsXFCaynUH39hdkytCkMxhKXEQD=jSiuaQPLZwzNqA@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1112051313060.29068@nokomis.stat.uiowa.edu>

Not yet . It overlaps with some other work and will be done in due course.

luke

On Mon, 5 Dec 2011, Michael Spiegel wrote:

> Has there been any movement on this patch? It will improve the
> serialize/unserialize performance.
>
> Thanks,
> --Michael
>
> On Mon, Oct 3, 2011 at 9:28 AM,  <luke-tierney at uiowa.edu> wrote:
>> It's on my list to look at but I may not get to it for a couple of
>> weeks. Someone else may get there earlier.
>>
>> Best,
>>
>> luke
>>
>>
>> On Mon, 3 Oct 2011, Michael Spiegel wrote:
>>
>>> Any thoughts? I haven't heard any feedback on this patch.
>>>
>>> Thanks!
>>> --Michael
>>>
>>> On Wed, Sep 28, 2011 at 3:10 PM, Michael Spiegel
>>> <michael.m.spiegel at gmail.com> wrote:
>>>>
>>>> Hi folks,
>>>>
>>>> I've attached a patch to the svn trunk that improves the performance
>>>> of the serialize/unserialize interface for vector types. The current
>>>> implementation: a) invokes the R_XDREncode operation for each element
>>>> of the vector type, and b) uses a switch statement to determine the
>>>> stream type for each element of the vector type. I've added
>>>> R_XDREncodeVector/R_XDRDecodeVector functions that accept N elements
>>>> at a time, and I've reorganized the implementation so that the stream
>>>> type is not queried once per element.
>>>>
>>>> In the following microbenchmark (below), I've observed performance
>>>> improvements of about x2.4. ?In a real benchmark that is using the
>>>> serialization interface to make MPI calls, I see about a 10%
>>>> improvement in performance.
>>>>
>>>> Cheers,
>>>> --Michael
>>>>
>>>> microbenchmark:
>>>>
>>>> input <- matrix(1:100000000, 10000, 10000)
>>>> output <- serialize(input, NULL)
>>>> for(i in 1:10) { print(system.time(serialize(input, NULL))) }
>>>> for(i in 1:10) { print(system.time(unserialize(output))) }
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
>> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
>> ? Actuarial Science
>> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? ? ?luke at stat.uiowa.edu
>> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From therneau at mayo.edu  Mon Dec  5 21:34:30 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 5 Dec 2011 14:34:30 -0600
Subject: [Rd] class extension and documentation
Message-ID: <201112052034.pB5KYU3w027763@nemo.mayo.edu>

Duncan's reply to my query

> Now R CMD check claims that I need Rd pages for backsolve and
> backsolve.default.  I don't think I should rewrite those.
>     How do I sidestep this  and/or
>     what other manuals should I read?

Even though your change is subtle, I'd say it's still a change 
(backsolve is now a generic, not a simple closure; it now has a 
different argument list), so I'd like to see a new man page added.  It 
would be quite reasonable to list the new interface and then refer to 
base::backsolve for the details of what the default method does.

----

Fair enough.  Let's push this a little harder.

 1. Additions to the manual, section 7.1
 
  a. Warn that foo.default must now be exported.  (I don't seem to
need to export foo, exportMethods("foo") seems to be enough?)
  b. Warn that package creation will demand a manual page for foo and
foo.default.
  c. Give hints on how to do b.


 2. More information in the setMethod page on the fragility of "just add 
one to make a generic".  I can't make this work if any of the arguments
have defaults.

-----------------------

Trying to impliment this idea is turning into a quagmire.  Here is my current
code:
 
backsolve <- function(r, x, k=ncol(r), upper.tri=TRUE, ...) 
    UseMethod("backsolve")
backsolve.default <- base:::backsolve
formals(backsolve.default) <- c(formals(backsolve.default), alist(... = )) 

setMethod("backsolve", signature(r="gchol", x="ANY", k="ANY", upper.tri="ANY"),
      function(r, x, k=ncol(r), upper.tri=TRUE, ...) {
          if (any(diag(r) < 0))
              stop("Argument has a negative diagonal, cannot backsolve")

          if (!is.numeric(x)) stop("Invalid data type for x")
          x <- as.matrix(x)
...


 First, if I was going to have a new backsolve manual page, it should
mention the arguments.  This meant adding x, k, and upper.tri to the
generic above.  And they needed defaults to make the Rd page be both
correct and pass muster.

 Now, however the default method doesn't work.  backsolve of an
ordinary matrix leads to
    Error in k != floor(k) : 'k' is missing
    Calls: backsolve -> backsolve -> .local
What's the trick?

 The gchol method for backsove was documented via promptMethod. 
How do I refer to this object in a \link from backsolve?  

  Accessing that documentation is certainly a challenge.  I doublt I'll ever
find a user to guess or remember
   methods?backsolve("gchol", "ANY", "ANY", "ANY")


Terry T.


From richcalaway at revolutionanalytics.com  Tue Dec  6 01:19:36 2011
From: richcalaway at revolutionanalytics.com (Rich Calaway)
Date: Mon, 5 Dec 2011 16:19:36 -0800
Subject: [Rd] Vignette using parallel's makeCluster function has trouble
 building on Windows 7
Message-ID: <CA+_ZbMYoT0nxPJ7XnnGKjkWKvyEuaKXyjdKuMEmMJTEf+q6Ljg@mail.gmail.com>

Hi, all--

I've been working on a doParallel package to provide a foreach
parallel backend for the new parallel package, but I am having trouble
building the vignette. On my system, if I use the following minimal
vignette (call it buggyVignette.Rnw):
   \documentclass[a4paper]{article}

   \title{Sweave Example 1}
   \author{Rich Calaway}

   \begin{document}

   \maketitle

   In this example I try to run code using library parallel in a vignette:

   <<>>=
   library(parallel)
   cl <- makeCluster(3)
   @

   and find that I get an error.

   \end{document}

I get the following error when I try to build the package:

   C:\Users\richcalaway\RforgeDev\doparallel>C:\R\R-2.14.0\bin\R CMD build pkg
   * checking for file 'pkg/DESCRIPTION' ... OK
   * preparing 'doParallel':
   * checking DESCRIPTION meta-information ... OK
   * installing the package to re-build vignettes
   * creating vignettes ...Warning in file(con, "r") :
?    cannot open file
'C:\Users\RICHCA~1\AppData\Local\Temp\RtmpQlF1YN\xshell63892b
   c4': Permission denied
   Error in file(con, "r") : cannot open the connection
   Execution halted

If I simply comment out the line with the call to makeCluster, the
package (complete with vignette) builds. Also, I can use R CMD
Sweave/pdflatex together to produce a PDF without error. Has anyone
else encountered this problem, and if so, how did you fix it? I can
work around the problem if need be by converting the code chunk to a
LaTeX verbatim, but that doesn't seem very vignette-friendly.

Any help would be greatly appreciated. Below is my sessionInfo and my
current path
> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

PATH=c:\Rtools214\bin;c:\Rtools214\MinGW\bin;c:\Rtools214\MinGW64\bin;C:\Ruby\bin;C:\Program
Files (x86)\MiKTeX 2.9\miktex\bin;C;\Windows\system32;

Regards,

Rich Calaway

--
Rich Calaway
Documentation Manager
Revolution Analytics, Inc.
1505 Westlake Ave North Suite 300
Seattle, WA 98109
richcalaway at revolutionanalytics.com
206-456-6086 (Direct Phone)
855-GET-REVO x6086 (Toll-free)


From dtenenba at fhcrc.org  Tue Dec  6 01:50:27 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 5 Dec 2011 16:50:27 -0800
Subject: [Rd] Vignette using parallel's makeCluster function has trouble
 building on Windows 7
In-Reply-To: <CA+_ZbMYoT0nxPJ7XnnGKjkWKvyEuaKXyjdKuMEmMJTEf+q6Ljg@mail.gmail.com>
References: <CA+_ZbMYoT0nxPJ7XnnGKjkWKvyEuaKXyjdKuMEmMJTEf+q6Ljg@mail.gmail.com>
Message-ID: <CAF42j22XfcTTtDn4e_7E7eT-o7nHH0CgpdLVA8a=Hqeo52+bDg@mail.gmail.com>

Hi Rich,

On Mon, Dec 5, 2011 at 4:19 PM, Rich Calaway
<richcalaway at revolutionanalytics.com> wrote:
> Hi, all--
>
> I've been working on a doParallel package to provide a foreach
> parallel backend for the new parallel package, but I am having trouble
> building the vignette. On my system, if I use the following minimal
> vignette (call it buggyVignette.Rnw):
> ? \documentclass[a4paper]{article}
>
> ? \title{Sweave Example 1}
> ? \author{Rich Calaway}
>
> ? \begin{document}
>
> ? \maketitle
>
> ? In this example I try to run code using library parallel in a vignette:
>
> ? <<>>=
> ? library(parallel)
> ? cl <- makeCluster(3)
> ? @
>
> ? and find that I get an error.
>
> ? \end{document}
>
> I get the following error when I try to build the package:
>
> ? C:\Users\richcalaway\RforgeDev\doparallel>C:\R\R-2.14.0\bin\R CMD build pkg
> ? * checking for file 'pkg/DESCRIPTION' ... OK
> ? * preparing 'doParallel':
> ? * checking DESCRIPTION meta-information ... OK
> ? * installing the package to re-build vignettes
> ? * creating vignettes ...Warning in file(con, "r") :
> ? ? ?cannot open file
> 'C:\Users\RICHCA~1\AppData\Local\Temp\RtmpQlF1YN\xshell63892b
> ? c4': Permission denied
> ? Error in file(con, "r") : cannot open the connection
> ? Execution halted
>
> If I simply comment out the line with the call to makeCluster, the
> package (complete with vignette) builds. Also, I can use R CMD
> Sweave/pdflatex together to produce a PDF without error. Has anyone
> else encountered this problem, and if so, how did you fix it? I can
> work around the problem if need be by converting the code chunk to a
> LaTeX verbatim, but that doesn't seem very vignette-friendly.
>

I was able to reproduce your problem.
When I added
stopCluster(cl)
to the vignette, it built just fine with R CMD build.

Dan

> Any help would be greatly appreciated. Below is my sessionInfo and my
> current path
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> PATH=c:\Rtools214\bin;c:\Rtools214\MinGW\bin;c:\Rtools214\MinGW64\bin;C:\Ruby\bin;C:\Program
> Files (x86)\MiKTeX 2.9\miktex\bin;C;\Windows\system32;
>
> Regards,
>
> Rich Calaway
>
> --
> Rich Calaway
> Documentation Manager
> Revolution Analytics, Inc.
> 1505 Westlake Ave North Suite 300
> Seattle, WA 98109
> richcalaway at revolutionanalytics.com
> 206-456-6086?(Direct Phone)
> 855-GET-REVO x6086 (Toll-free)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From richcalaway at revolutionanalytics.com  Tue Dec  6 02:10:40 2011
From: richcalaway at revolutionanalytics.com (Rich Calaway)
Date: Mon, 5 Dec 2011 17:10:40 -0800
Subject: [Rd] Vignette using parallel's makeCluster function has trouble
 building on Windows 7
In-Reply-To: <CAF42j22XfcTTtDn4e_7E7eT-o7nHH0CgpdLVA8a=Hqeo52+bDg@mail.gmail.com>
References: <CA+_ZbMYoT0nxPJ7XnnGKjkWKvyEuaKXyjdKuMEmMJTEf+q6Ljg@mail.gmail.com>
	<CAF42j22XfcTTtDn4e_7E7eT-o7nHH0CgpdLVA8a=Hqeo52+bDg@mail.gmail.com>
Message-ID: <CA+_ZbMbYiYrdr_11N_Hxdypuoihz3p+0yXKvKrgJp20MQ8O+iA@mail.gmail.com>

Thanks, Dan! I think that's just what I needed.

--Rich

On Mon, Dec 5, 2011 at 4:50 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> Hi Rich,
>
> On Mon, Dec 5, 2011 at 4:19 PM, Rich Calaway
> <richcalaway at revolutionanalytics.com> wrote:
>> Hi, all--
>>
>> I've been working on a doParallel package to provide a foreach
>> parallel backend for the new parallel package, but I am having trouble
>> building the vignette. On my system, if I use the following minimal
>> vignette (call it buggyVignette.Rnw):
>> ? \documentclass[a4paper]{article}
>>
>> ? \title{Sweave Example 1}
>> ? \author{Rich Calaway}
>>
>> ? \begin{document}
>>
>> ? \maketitle
>>
>> ? In this example I try to run code using library parallel in a vignette:
>>
>> ? <<>>=
>> ? library(parallel)
>> ? cl <- makeCluster(3)
>> ? @
>>
>> ? and find that I get an error.
>>
>> ? \end{document}
>>
>> I get the following error when I try to build the package:
>>
>> ? C:\Users\richcalaway\RforgeDev\doparallel>C:\R\R-2.14.0\bin\R CMD build pkg
>> ? * checking for file 'pkg/DESCRIPTION' ... OK
>> ? * preparing 'doParallel':
>> ? * checking DESCRIPTION meta-information ... OK
>> ? * installing the package to re-build vignettes
>> ? * creating vignettes ...Warning in file(con, "r") :
>> ? ? ?cannot open file
>> 'C:\Users\RICHCA~1\AppData\Local\Temp\RtmpQlF1YN\xshell63892b
>> ? c4': Permission denied
>> ? Error in file(con, "r") : cannot open the connection
>> ? Execution halted
>>
>> If I simply comment out the line with the call to makeCluster, the
>> package (complete with vignette) builds. Also, I can use R CMD
>> Sweave/pdflatex together to produce a PDF without error. Has anyone
>> else encountered this problem, and if so, how did you fix it? I can
>> work around the problem if need be by converting the code chunk to a
>> LaTeX verbatim, but that doesn't seem very vignette-friendly.
>>
>
> I was able to reproduce your problem.
> When I added
> stopCluster(cl)
> to the vignette, it built just fine with R CMD build.
>
> Dan
>
>> Any help would be greatly appreciated. Below is my sessionInfo and my
>> current path
>>> sessionInfo()
>> R version 2.14.0 (2011-10-31)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> PATH=c:\Rtools214\bin;c:\Rtools214\MinGW\bin;c:\Rtools214\MinGW64\bin;C:\Ruby\bin;C:\Program
>> Files (x86)\MiKTeX 2.9\miktex\bin;C;\Windows\system32;
>>
>> Regards,
>>
>> Rich Calaway
>>
>> --
>> Rich Calaway
>> Documentation Manager
>> Revolution Analytics, Inc.
>> 1505 Westlake Ave North Suite 300
>> Seattle, WA 98109
>> richcalaway at revolutionanalytics.com
>> 206-456-6086?(Direct Phone)
>> 855-GET-REVO x6086 (Toll-free)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Rich Calaway
Documentation Manager
Revolution Analytics, Inc.
1505 Westlake Ave North Suite 300
Seattle, WA 98109
richcalaway at revolutionanalytics.com
206-456-6086 (Direct Phone)
855-GET-REVO x6086 (Toll-free)


From rtp at google.com  Tue Dec  6 06:29:54 2011
From: rtp at google.com (Tyler Pirtle)
Date: Mon, 5 Dec 2011 21:29:54 -0800
Subject: [Rd] unserialize and eager execution
Message-ID: <CAH9pPRpT1e5uwWnL453vY0ryCfkMTsp0Xk2z2yOq0vacY_i5xA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111205/5a537368/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Dec  6 07:41:14 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 06 Dec 2011 06:41:14 +0000
Subject: [Rd] unserialize and eager execution
In-Reply-To: <CAH9pPRpT1e5uwWnL453vY0ryCfkMTsp0Xk2z2yOq0vacY_i5xA@mail.gmail.com>
References: <CAH9pPRpT1e5uwWnL453vY0ryCfkMTsp0Xk2z2yOq0vacY_i5xA@mail.gmail.com>
Message-ID: <4EDDB90A.5000205@stats.ox.ac.uk>

Take a look at the information on serialization in 'R Internals'. 
AFAICS this is no different from what can happen when loading a saved 
workspace.

On 06/12/2011 05:29, Tyler Pirtle wrote:
> Hi,
>
> While debugging a network server I'm developing I noticed something unusual
> - call to unserialize() resulted in
> an error about loading a namespace.
>
> I was a bit taken back by this - why should unserializing an object cause a
> namespace lookup?
> Are there any other side-effects of unserialize() that I should be cautious
> about? I've been
> digging through the R_Unserialize() call, I haven't found the loadNamespace
> bit yet but I
> assume its in there somewhere.
>
> Is there anyway to guard against R eagerly evaluating serialized data
> (serialize()) being unserialized (unserialize()) ?

Don't unserialize 'eagerly'.  Hint: that's what lazy-loading does.

>
>
> Thanks,
>
>
> Tyler
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rtp at google.com  Tue Dec  6 08:00:39 2011
From: rtp at google.com (Tyler Pirtle)
Date: Mon, 5 Dec 2011 23:00:39 -0800
Subject: [Rd] unserialize and eager execution
In-Reply-To: <4EDDB90A.5000205@stats.ox.ac.uk>
References: <CAH9pPRpT1e5uwWnL453vY0ryCfkMTsp0Xk2z2yOq0vacY_i5xA@mail.gmail.com>
	<4EDDB90A.5000205@stats.ox.ac.uk>
Message-ID: <CAH9pPRpPq+j8YG8aVgA-VK=-9urExN5E6KJXDMA5a1dBj7at+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111205/036e19c5/attachment.pl>

From PViefers at diw.de  Mon Dec  5 19:22:40 2011
From: PViefers at diw.de (Paul Viefers)
Date: Mon, 5 Dec 2011 19:22:40 +0100
Subject: [Rd] RcppArmadillo compilation error: R CMD SHLIB returns status 1
Message-ID: <OF2D585061.05B2DE60-ONC125795D.0064F3D4-C125795D.0064F3D9@diw.de>

Dear all,

running the example by D. Eddebuettel (http://dirk.eddelbuettel.com/blog/2011/04/23/) I get an error message. Specifically, the R code I was taking from the above example is

### BEGIN EXAMPLE ###

suppressMessages(require(RcppArmadillo))
suppressMessages(require(Rcpp))
suppressMessages(require(inline))
code <- '
   arma::mat coeff = Rcpp::as<arma::mat>(a);
   arma::mat errors = Rcpp::as<arma::mat>(e);
   int m = errors.n_rows; int n = errors.n_cols;
   arma::mat simdata(m,n);
   simdata.row(0) = arma::zeros<arma::mat>(1,n);
   for (int row=1; row<m; row++) {
     simdata.row(row) = simdata.row(row-1)*trans(coeff)+errors.row(row);
   }
   return Rcpp::wrap(simdata);
 '
## create the compiled function
rcppSim <- cxxfunction(signature(a="numeric",e="numeric"),
                        code,plugin="RcppArmadillo")

### END OF EXAMPLE ###

Executing this inside R, returned the following:

ERROR(s) during compilation: source code errors or compiler configuration errors!

Program source:
  1: 
  2: // includes from the plugin
  3: #include <RcppArmadillo.h>
  4: #include <Rcpp.h>
  5: 
  6: 
  7: #ifndef BEGIN_RCPP
  8: #define BEGIN_RCPP
  9: #endif
 10: 
 11: #ifndef END_RCPP
 12: #define END_RCPP
 13: #endif
 14: 
 15: using namespace Rcpp;
 16: 
 17: 
 18: // user includes
 19: 
 20: 
 21: // declarations
 22: extern "C" {
 23: SEXP file33765791( SEXP a, SEXP e) ;
 24: }
 25: 
 26: // definition
 27: 
 28: SEXP file33765791( SEXP a, SEXP e ){
 29: BEGIN_RCPP
 30: 
 31:    arma::mat coeff = Rcpp::as<arma::mat>(a);
 32:    arma::mat errors = Rcpp::as<arma::mat>(e);
 33:    int m = errors.n_rows; int n = errors.n_cols;
 34:    arma::mat simdata(m,n);
 35:    simdata.row(0) = arma::zeros<arma::mat>(1,n);
 36:    for (int row=1; row<m; row++) {
 37:      simdata.row(row) = simdata.row(row-1)*trans(coeff)+errors.row(row);
 38:    }
 39:    return Rcpp::wrap(simdata);
 40:  
 41: END_RCPP
 42: }
 43: 
 44: 
Error in compileCode(f, code, language = language, verbose = verbose) : 
  Compilation ERROR, function(s)/method(s) not created! 
Executing command 'C:/PROGRA~1/R/R-214~1.0/bin/i386/R CMD SHLIB file33765791.cpp 2> file33765791.cpp.err.txt' returned status 1

I am working under R 2.14.0 and as the pros among you might guess, I am new to using the C++ interfaces within R. I think all I have to do is to edit some settings on my Windows 7 machine here, but the error message is too cryptic to me. Alas, I could also not find any thread or help topic that deals with this online. I appreciate any direct reply or reference where I can find a solution to this.
Please let me know in case I am leaving out some essential details here.

Many thanks,
Paul

From murdoch.duncan at gmail.com  Tue Dec  6 15:27:46 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 06 Dec 2011 09:27:46 -0500
Subject: [Rd] RcppArmadillo compilation error: R CMD SHLIB returns
 status 1
In-Reply-To: <OF2D585061.05B2DE60-ONC125795D.0064F3D4-C125795D.0064F3D9@diw.de>
References: <OF2D585061.05B2DE60-ONC125795D.0064F3D4-C125795D.0064F3D9@diw.de>
Message-ID: <4EDE2662.1070606@gmail.com>

On 05/12/2011 1:22 PM, Paul Viefers wrote:
> Dear all,
>
> running the example by D. Eddebuettel (http://dirk.eddelbuettel.com/blog/2011/04/23/) I get an error message. Specifically, the R code I was taking from the above example is
>
> ### BEGIN EXAMPLE ###
>
> suppressMessages(require(RcppArmadillo))
> suppressMessages(require(Rcpp))
> suppressMessages(require(inline))
> code<- '
>     arma::mat coeff = Rcpp::as<arma::mat>(a);
>     arma::mat errors = Rcpp::as<arma::mat>(e);
>     int m = errors.n_rows; int n = errors.n_cols;
>     arma::mat simdata(m,n);
>     simdata.row(0) = arma::zeros<arma::mat>(1,n);
>     for (int row=1; row<m; row++) {
>       simdata.row(row) = simdata.row(row-1)*trans(coeff)+errors.row(row);
>     }
>     return Rcpp::wrap(simdata);
>   '
> ## create the compiled function
> rcppSim<- cxxfunction(signature(a="numeric",e="numeric"),
>                          code,plugin="RcppArmadillo")
>
> ### END OF EXAMPLE ###
>
> Executing this inside R, returned the following:
>
> ERROR(s) during compilation: source code errors or compiler configuration errors!
>
> Program source:
>    1:
>    2: // includes from the plugin
>    3: #include<RcppArmadillo.h>
>    4: #include<Rcpp.h>
>    5:
>    6:
>    7: #ifndef BEGIN_RCPP
>    8: #define BEGIN_RCPP
>    9: #endif
>   10:
>   11: #ifndef END_RCPP
>   12: #define END_RCPP
>   13: #endif
>   14:
>   15: using namespace Rcpp;
>   16:
>   17:
>   18: // user includes
>   19:
>   20:
>   21: // declarations
>   22: extern "C" {
>   23: SEXP file33765791( SEXP a, SEXP e) ;
>   24: }
>   25:
>   26: // definition
>   27:
>   28: SEXP file33765791( SEXP a, SEXP e ){
>   29: BEGIN_RCPP
>   30:
>   31:    arma::mat coeff = Rcpp::as<arma::mat>(a);
>   32:    arma::mat errors = Rcpp::as<arma::mat>(e);
>   33:    int m = errors.n_rows; int n = errors.n_cols;
>   34:    arma::mat simdata(m,n);
>   35:    simdata.row(0) = arma::zeros<arma::mat>(1,n);
>   36:    for (int row=1; row<m; row++) {
>   37:      simdata.row(row) = simdata.row(row-1)*trans(coeff)+errors.row(row);
>   38:    }
>   39:    return Rcpp::wrap(simdata);
>   40:
>   41: END_RCPP
>   42: }
>   43:
>   44:
> Error in compileCode(f, code, language = language, verbose = verbose) :
>    Compilation ERROR, function(s)/method(s) not created!
> Executing command 'C:/PROGRA~1/R/R-214~1.0/bin/i386/R CMD SHLIB file33765791.cpp 2>  file33765791.cpp.err.txt' returned status 1
>
> I am working under R 2.14.0 and as the pros among you might guess, I am new to using the C++ interfaces within R. I think all I have to do is to edit some settings on my Windows 7 machine here, but the error message is too cryptic to me. Alas, I could also not find any thread or help topic that deals with this online. I appreciate any direct reply or reference where I can find a solution to this.
> Please let me know in case I am leaving out some essential details here.

If you put the program source into a file (e.g. fn.cpp) and in a Windows 
cmd shell you run

R CMD SHLIB fn.cpp

what do you get?   I would guess you've got a problem with your setup of 
the compiler or other tools, and this would likely show it.

Duncan Murdoch


From hpages at fhcrc.org  Tue Dec  6 23:28:52 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 06 Dec 2011 14:28:52 -0800
Subject: [Rd] warning for inefficiently compressed datasets
Message-ID: <4EDE9724.3080604@fhcrc.org>

Hi,

Recently added to doc/NEWS.Rd:

   'R CMD check' now gives a warning rather than a note if it finds
   inefficiently compressed datasets.  With 'bzip2' and 'xz' compression
   having been available since R 2.10.0, there is no excuse for not
   using them.

Why isn't a note enough for this?

Generally speaking, warnings are for things that are dangerous,
or unsafe, or unportable, or for anything that could potentially
cause trouble. I don't see how using gzip instead of bzip2 or xz
could fall into that category (and BTW gzip is the default for
save() and for 'R CMD build' resave-data feature).

The problem is that bzip2 and xz compressions are slower and also
require more memory than gzip. Bioconductor has big data packages
and sometimes it makes sense to use gzip and not bzip2 or xz. For
example, when loading Human chromosome 1 from disk, bzip2 and xz
are 7 and 3.4 times slower than gzip, respectively:

   > system.time(load("chr1-gzip.rda"))
      user  system elapsed
     1.210   0.180   1.384

   > system.time(load("chr1-bzip2.rda"))
      user  system elapsed
     9.500   0.160   9.674

   > system.time(load("chr1-xz.rda"))
      user  system elapsed
      4.46    0.20    4.69

hpages at latitude:~/testing$ ls -lhtr chr1-*.rda
-rw-r--r-- 1 hpages hpages 61M 2011-12-06 12:13 chr1-gzip.rda
-rw-r--r-- 1 hpages hpages 55M 2011-12-06 12:15 chr1-bzip2.rda
-rw-r--r-- 1 hpages hpages 49M 2011-12-06 12:25 chr1-xz.rda

This is with R-2.14.0 on a 64-bit Ubuntu laptop with 8GB of RAM.

The size on disk doesn't really matter and it doesn't matter either
that the source tarball for the full Human genome ends up being 20%
bigger when using gzip instead of xz: the 20% extra time it takes to
download it (which needs to be done only once) will largely be
compensated by the fact that most analyses will run faster e.g. in
40-45 sec. instead of more than 2 minutes (for many short analyses,
loading the chromosomes into memory is the bottleneck).

Is there a way to turn this warning off? If not, could an option be
added to 'R CMD check' to turn this warning off? Something along the
lines of the --no-resave-data option for 'R CMD build'.

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ligges at statistik.tu-dortmund.de  Wed Dec  7 09:34:08 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 07 Dec 2011 09:34:08 +0100
Subject: [Rd] warning for inefficiently compressed datasets
In-Reply-To: <4EDE9724.3080604@fhcrc.org>
References: <4EDE9724.3080604@fhcrc.org>
Message-ID: <4EDF2500.3010801@statistik.tu-dortmund.de>



On 06.12.2011 23:28, Herv? Pag?s wrote:
> Hi,
>
> Recently added to doc/NEWS.Rd:
>
> 'R CMD check' now gives a warning rather than a note if it finds
> inefficiently compressed datasets. With 'bzip2' and 'xz' compression
> having been available since R 2.10.0, there is no excuse for not
> using them.
>
> Why isn't a note enough for this?
>
> Generally speaking, warnings are for things that are dangerous,
> or unsafe, or unportable, or for anything that could potentially
> cause trouble. I don't see how using gzip instead of bzip2 or xz
> could fall into that category (and BTW gzip is the default for
> save() and for 'R CMD build' resave-data feature).
>
> The problem is that bzip2 and xz compressions are slower and also
> require more memory than gzip. Bioconductor has big data packages
> and sometimes it makes sense to use gzip and not bzip2 or xz. For
> example, when loading Human chromosome 1 from disk, bzip2 and xz
> are 7 and 3.4 times slower than gzip, respectively:
>
>  > system.time(load("chr1-gzip.rda"))
> user system elapsed
> 1.210 0.180 1.384
>
>  > system.time(load("chr1-bzip2.rda"))
> user system elapsed
> 9.500 0.160 9.674
>
>  > system.time(load("chr1-xz.rda"))
> user system elapsed
> 4.46 0.20 4.69
>
> hpages at latitude:~/testing$ ls -lhtr chr1-*.rda
> -rw-r--r-- 1 hpages hpages 61M 2011-12-06 12:13 chr1-gzip.rda
> -rw-r--r-- 1 hpages hpages 55M 2011-12-06 12:15 chr1-bzip2.rda
> -rw-r--r-- 1 hpages hpages 49M 2011-12-06 12:25 chr1-xz.rda
>
> This is with R-2.14.0 on a 64-bit Ubuntu laptop with 8GB of RAM.
>
> The size on disk doesn't really matter and it doesn't matter either
> that the source tarball for the full Human genome ends up being 20%
> bigger when using gzip instead of xz: the 20% extra time it takes to
> download it (which needs to be done only once) will largely be
> compensated by the fact that most analyses will run faster e.g. in
> 40-45 sec. instead of more than 2 minutes (for many short analyses,
> loading the chromosomes into memory is the bottleneck).


Oh, from a European side this 20% extra time may be an hour when 
downloading from the BioC master rather than a mirror.
And space and traffic is an issue for CRAN.



> Is there a way to turn this warning off? If not, could an option be
> added to 'R CMD check' to turn this warning off? Something along the
> lines of the --no-resave-data option for 'R CMD build'.


The manual tells us:

"The following environment variables can be used to customize the 
operation of check: a convenient place to set these is the file 
?~/.R/check.Renviron?.

[...]

_R_CHECK_COMPACT_DATA2_

If true, check data for ascii and uncompressed saves, and also check if 
using bzip2 or xz compression would be significantly better. Implies 
_R_CHECK_COMPACT_DATA_ is true. Default: true."


Uwe



>
> Thanks,
> H.
>


From ssath002 at ucr.edu  Tue Dec  6 20:05:55 2011
From: ssath002 at ucr.edu (Sumukh Sathnur)
Date: Tue, 6 Dec 2011 11:05:55 -0800
Subject: [Rd] Unable to collate and parse R files with R CMD check
Message-ID: <CANxMqTGJuio5_Ca=P47WdSviTUn1T6W2S3u8zVpS4n=qnr2Qiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111206/a89ef075/attachment.pl>

From zack.weinberg at sv.cmu.edu  Tue Dec  6 21:34:07 2011
From: zack.weinberg at sv.cmu.edu (Zack Weinberg)
Date: Tue, 6 Dec 2011 12:34:07 -0800
Subject: [Rd] Graphics device hook to manipulate plotmath
Message-ID: <CAKCAbMgWwATvOZZW=mAJSenaDBAQaJuBuj35KDqimAgw68Qj6w@mail.gmail.com>

Is there a hook that allows a graphics device to apply transformations
to plotmath expressions *before* they are rendered?  If there isn't
one yet, would it be feasible to add one?

The motivation for this hook is graphic devices that feed into
something that already has support for math layout, such as the
tikzDevice package (which has TeX downstream). Given

    text(x, y, expression(alpha+beta+gamma+delta))

it would be ideal (in terms of output quality) if tikzDevice could
process that as if

   text(x, y, "$\\alpha+\\beta+\\gamma+\\delta$")

had been written instead.  This would also be easier to *implement*,
from the device side, than a back-conversion from Adobe-Symbol glyph
requests to TeX math symbol macros.

(Users of tikzDevice can of course write all their TeX math
expressions directly, but this may be a great deal of conversion work,
and is also inconvenient for someone tweaking their plots in one of
the interactive graphics devices before saving them permanently.)

Thanks in advance,
zw

p.s. I am not subscribed to this list, please cc: me on replies.


From ligges at statistik.tu-dortmund.de  Wed Dec  7 09:45:11 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 07 Dec 2011 09:45:11 +0100
Subject: [Rd] Unable to collate and parse R files with R CMD check
In-Reply-To: <CANxMqTGJuio5_Ca=P47WdSviTUn1T6W2S3u8zVpS4n=qnr2Qiw@mail.gmail.com>
References: <CANxMqTGJuio5_Ca=P47WdSviTUn1T6W2S3u8zVpS4n=qnr2Qiw@mail.gmail.com>
Message-ID: <4EDF2797.3080606@statistik.tu-dortmund.de>



On 06.12.2011 20:05, Sumukh Sathnur wrote:
> Hi all,
>
> I'm trying to build a package on Windows 7 (64 bit) and although R cmd
> build worked fine and I got pkg.tar.gz with no errors, but when I tried
> doing R CMD check everything turns out ok except for the warning:
>
> "checking whether package 'pkg' can be installed ... ERROR.
> Installation failed."
>
> It then refers me to the error file "00install.out" which reads as follows:
>
> * installing *source* package 'pkg' ...
> ** R
> Error in parse(outFile) : 94:0: unexpected end of input
> 92:
> 93: dat

Oh, it means R cannot even parse the code. So try to source() each file 
in your ./R directory separately. You will find that at least one won't 
work.

Uwe Ligges


>     ^
> ERROR: unable to collate and parse R files for package 'pkg'
> * removing 'C:/PROGRA~1/R/R-214~1.0/bin/x64/PKG~1.RCH/pkg'
>
>
> I have no idea what this means and I was not able to find any similar
> errors online. Any help would be appreciated.
>
> Thanks in advance,
> Sumukh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Wed Dec  7 10:41:44 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 07 Dec 2011 01:41:44 -0800
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
Message-ID: <4EDF34D8.40001@fhcrc.org>

Hi,

This looks OK:

 > x <- c("_1_", "1_9", "2_9")
 > rank(x)
[1] 1 2 3

But this does not:

 > xa <- paste(x, "a", sep="")
 > xa
[1] "_1_a" "1_9a" "2_9a"
 > rank(xa)
[1] 2 1 3

Cheers,
H.

 > sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.14.0


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From b.rowlingson at lancaster.ac.uk  Wed Dec  7 11:17:24 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 7 Dec 2011 10:17:24 +0000
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EDF34D8.40001@fhcrc.org>
References: <4EDF34D8.40001@fhcrc.org>
Message-ID: <CANVKczMHZLgGz=UHVVr1EYp_F1WG0JiRORBgTEyj5xv5s4bUKg@mail.gmail.com>

2011/12/7 Herv? Pag?s <hpages at fhcrc.org>:
> rank(xa)

See help(Comparison), specifically:

"Beware of making _any_ assumptions about the
     collation order" followed by "Collation of
     non-letters (spaces, punctuation signs, hyphens, fractions and so
     on) is even more problematic."

Barry


From jorismeys at gmail.com  Wed Dec  7 15:48:43 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 7 Dec 2011 15:48:43 +0100
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EDF34D8.40001@fhcrc.org>
References: <4EDF34D8.40001@fhcrc.org>
Message-ID: <CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>

@Barry : regardless of whether '_' comes before or after '1' , it
should be consistent. Adding an 'a' shouldn't shift '_' from before
'1' to between '1' and '2', that's clearly an error. The help files
are not stating anything about that. The only thing I can imagine, is
that '_' gets ignored (in that case 19a would rank before 1a).

This said, I can't reproduce.

> x <- c("_1_", "1_9", "2_9")
> xa <- paste(x,'a',sep='')
> rank(x)
[1] 1 2 3
> rank(xa)
[1] 1 2 3

> sessionInfo()
R version 2.14.0 Patched (2006-00-00 r00000)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils
   methods   base

other attached packages:
[1] svSocket_0.9-51 TinnR_1.0.3     R2HTML_2.2      Hmisc_3.8-3
survival_2.36-9

loaded via a namespace (and not attached):
[1] cluster_1.14.1  grid_2.14.0     lattice_0.19-33 svMisc_0.9-63
tools_2.14.0


2011/12/7 Herv? Pag?s <hpages at fhcrc.org>:
> Hi,
>
> This looks OK:
>
>> x <- c("_1_", "1_9", "2_9")
>> rank(x)
> [1] 1 2 3
>
> But this does not:
>
>> xa <- paste(x, "a", sep="")
>> xa
> [1] "_1_a" "1_9a" "2_9a"
>> rank(xa)
> [1] 2 1 3
>
> Cheers,
> H.
>
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_CA.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_CA.UTF-8 ? ? ? ?LC_COLLATE=en_CA.UTF-8
> ?[5] LC_MONETARY=en_CA.UTF-8 ? ?LC_MESSAGES=en_CA.UTF-8
> ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone: ?(206) 667-5791
> Fax: ? ?(206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From r.m.krug at gmail.com  Wed Dec  7 16:06:43 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Wed, 07 Dec 2011 16:06:43 +0100
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
References: <4EDF34D8.40001@fhcrc.org>
	<CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
Message-ID: <4EDF8103.5040305@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 07/12/11 15:48, Joris Meys wrote:
> @Barry : regardless of whether '_' comes before or after '1' , it 
> should be consistent. Adding an 'a' shouldn't shift '_' from
> before '1' to between '1' and '2', that's clearly an error. The
> help files are not stating anything about that. The only thing I
> can imagine, is that '_' gets ignored (in that case 19a would rank
> before 1a).
> 
> This said, I can't reproduce.

I can:

> x <- c("_1_", "1_9", "2_9") xa <- paste(x,'a',sep='') rank(x)
[1] 1 2 3
> rank(xa)
[1] 2 1 3
> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> version
               _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status
major          2
minor          14.0
year           2011
month          10
day            31
svn rev        57496
language       R
version.string R version 2.14.0 (2011-10-31)
> 

Interesting.

Rainer


> 
>> x <- c("_1_", "1_9", "2_9") xa <- paste(x,'a',sep='') rank(x)
> [1] 1 2 3
>> rank(xa)
> [1] 1 2 3
> 
>> sessionInfo()
> R version 2.14.0 Patched (2006-00-00 r00000) Platform:
> i386-pc-mingw32/i386 (32-bit)
> 
> locale: [1] LC_COLLATE=English_United States.1252
> LC_CTYPE=English_United States.1252    LC_MONETARY=English_United
> States.1252 [4] LC_NUMERIC=C
> LC_TIME=English_United States.1252
> 
> attached base packages: [1] grDevices datasets  splines   graphics
> stats     tcltk     utils methods   base
> 
> other attached packages: [1] svSocket_0.9-51 TinnR_1.0.3
> R2HTML_2.2      Hmisc_3.8-3 survival_2.36-9
> 
> loaded via a namespace (and not attached): [1] cluster_1.14.1
> grid_2.14.0     lattice_0.19-33 svMisc_0.9-63 tools_2.14.0
> 
> 
> 2011/12/7 Herv? Pag?s <hpages at fhcrc.org>:
>> Hi,
>> 
>> This looks OK:
>> 
>>> x <- c("_1_", "1_9", "2_9") rank(x)
>> [1] 1 2 3
>> 
>> But this does not:
>> 
>>> xa <- paste(x, "a", sep="") xa
>> [1] "_1_a" "1_9a" "2_9a"
>>> rank(xa)
>> [1] 2 1 3
>> 
>> Cheers, H.
>> 
>>> sessionInfo()
>> R version 2.14.0 (2011-10-31) Platform: x86_64-unknown-linux-gnu
>> (64-bit)
>> 
>> locale: [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C [3]
>> LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8 [5]
>> LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8 [7] LC_PAPER=C
>> LC_NAME=C [9] LC_ADDRESS=C               LC_TELEPHONE=C [11]
>> LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages: [1] stats     graphics  grDevices utils
>> datasets  methods   base
>> 
>> loaded via a namespace (and not attached): [1] tools_2.14.0
>> 
>> 
>> -- Herv? Pag?s
>> 
>> Program in Computational Biology Division of Public Health
>> Sciences Fred Hutchinson Cancer Research Center 1100 Fairview
>> Ave. N, M1-B514 P.O. Box 19024 Seattle, WA 98109-1024
>> 
>> E-mail: hpages at fhcrc.org Phone:  (206) 667-5791 Fax:    (206)
>> 667-1319
>> 
>> ______________________________________________ 
>> R-devel at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk7fgQMACgkQoYgNqgF2egrjvACffUhSUEriYGSQY8MstwVbvAj6
+w8An1FrwX0YXqDUqDoRq/zW31FW7WOj
=zQr1
-----END PGP SIGNATURE-----


From gmbecker at ucdavis.edu  Wed Dec  7 16:24:39 2011
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 7 Dec 2011 07:24:39 -0800
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EDF8103.5040305@gmail.com>
References: <4EDF34D8.40001@fhcrc.org>
	<CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
	<4EDF8103.5040305@gmail.com>
Message-ID: <CADwqtCOPgdGYZ7CozOm0uhJ-W-5HBP_+bPxkojH1Ojm2nipaow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111207/374a8bc3/attachment.pl>

From janko.thyson.rstuff at googlemail.com  Wed Dec  7 16:36:56 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 07 Dec 2011 16:36:56 +0100
Subject: [Rd] Possible bug in 'new()' for Reference Classes
Message-ID: <4EDF8818.9000201@googlemail.com>

Dear list,

I think I stumbled across a little bug with respect to the standard 
initialization routine for Reference Classes.

It seems that a field 'self' is treated as if it's name would be '.self' 
(which we know is reserved for the self reference of the instantiated 
object itself) and thus an error is thrown.
If the field value is assigned in an explicit call after the 
instantiation via 'new()', everything works just fine:

setRefClass("ClassInfo",
         fields=list(
             self="character", super="character", sub="character"
         )
     )
     new("ClassInfo", self="B", super="A", sub="C")    # Error

     x <- new("ClassInfo", super="A", sub="C")
     x
     x$self <- "B" # Works
     x

Best regards,
Janko


From proebuck at mdanderson.org  Wed Dec  7 19:29:26 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Wed, 7 Dec 2011 12:29:26 -0600
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EDF34D8.40001@fhcrc.org>
Message-ID: <CB050CA6.25561%proebuck@mdanderson.org>

Do this first and try again.

R> Sys.setlocale("LC_COLLATE", "C")


On 12/7/11 3:41 AM, "Herv? Pag?s" <hpages at fhcrc.org> wrote:

> Hi,
> 
> This looks OK:
> 
>> x <- c("_1_", "1_9", "2_9")
>> rank(x)
> [1] 1 2 3
> 
> But this does not:
> 
>> xa <- paste(x, "a", sep="")
>> xa
> [1] "_1_a" "1_9a" "2_9a"
>> rank(xa)
> [1] 2 1 3
> 
> Cheers,
> H.
> 
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
> 


From pdalgd at gmail.com  Wed Dec  7 19:30:10 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 7 Dec 2011 19:30:10 +0100
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
References: <4EDF34D8.40001@fhcrc.org>
	<CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
Message-ID: <F2765D05-70B4-40F7-B8CC-C6012E16A237@gmail.com>


On Dec 7, 2011, at 15:48 , Joris Meys wrote:

> @Barry : regardless of whether '_' comes before or after '1' , it
> should be consistent. Adding an 'a' shouldn't shift '_' from before
> '1' to between '1' and '2', that's clearly an error. The help files
> are not stating anything about that. The only thing I can imagine, is
> that '_' gets ignored (in that case 19a would rank before 1a).

As far as I remember, that is exactly the case. In some locales, and not even consistently across different OS versions of the "same" locale, there are characters that are ignored for collation. With that in mind, what we see is really not any stranger than "a" < "ab" but "ac" > "abc". 

R just uses what the OS supplies, so if you want to use words like "inconsistent" or "error", please direct them at those who define the locales. (And be prepared to realize that you may have kicked a hornet's nest...)

> 
> This said, I can't reproduce.
> 
>> x <- c("_1_", "1_9", "2_9")
>> xa <- paste(x,'a',sep='')
>> rank(x)
> [1] 1 2 3
>> rank(xa)
> [1] 1 2 3
> 
>> sessionInfo()
> R version 2.14.0 Patched (2006-00-00 r00000)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
> 
> attached base packages:
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>   methods   base
> 
> other attached packages:
> [1] svSocket_0.9-51 TinnR_1.0.3     R2HTML_2.2      Hmisc_3.8-3
> survival_2.36-9
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.14.1  grid_2.14.0     lattice_0.19-33 svMisc_0.9-63
> tools_2.14.0
> 
> 
> 2011/12/7 Herv? Pag?s <hpages at fhcrc.org>:
>> Hi,
>> 
>> This looks OK:
>> 
>>> x <- c("_1_", "1_9", "2_9")
>>> rank(x)
>> [1] 1 2 3
>> 
>> But this does not:
>> 
>>> xa <- paste(x, "a", sep="")
>>> xa
>> [1] "_1_a" "1_9a" "2_9a"
>>> rank(xa)
>> [1] 2 1 3
>> 
>> Cheers,
>> H.
>> 
>>> sessionInfo()
>> R version 2.14.0 (2011-10-31)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> 
>> locale:
>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>  [7] LC_PAPER=C                 LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.0
>> 
>> 
>> --
>> Herv? Pag?s
>> 
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>> 
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From b.rowlingson at lancaster.ac.uk  Wed Dec  7 19:34:16 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 7 Dec 2011 18:34:16 +0000
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
References: <4EDF34D8.40001@fhcrc.org>
	<CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
Message-ID: <CANVKczOqxw_iioCyDgAdVGpayhVcx=715fZGRSBg5y6sSftrzQ@mail.gmail.com>

2011/12/7 Joris Meys <jorismeys at gmail.com>:
> @Barry : regardless of whether '_' comes before or after '1' , it
> should be consistent. Adding an 'a' shouldn't shift '_' from before
> '1' to between '1' and '2', that's clearly an error. The help files
> are not stating anything about that.

 That's an assumption. The help pages are quite clear about making assumptions.

 The only way this could be a 'bug' is if you can show that the sort
order in R is different from the lexicographic sort order using the
collating sequence of the locale in use. But even my command line
'sort' agrees:

$ sort < f1.txt
_1_
1_9
2_9

 now add the trailing a:

$ sort < f1.txt
1_9a
_1_a
2_9a

[ I had a thought maybe it was because _ is sometimes used to break
thousands in numeric formats, but I can't get any obvious consistency
out of that hypothesis ]

Barry


From jorismeys at gmail.com  Wed Dec  7 19:50:47 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 7 Dec 2011 19:50:47 +0100
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CANVKczOqxw_iioCyDgAdVGpayhVcx=715fZGRSBg5y6sSftrzQ@mail.gmail.com>
References: <4EDF34D8.40001@fhcrc.org>
	<CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
	<CANVKczOqxw_iioCyDgAdVGpayhVcx=715fZGRSBg5y6sSftrzQ@mail.gmail.com>
Message-ID: <CAO1zAVbSJEjbWnL8aHr5TjB5CL6wMByLqpo1Ohd9mNfprAKWsQ@mail.gmail.com>

2011/12/7 Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:
> 2011/12/7 Joris Meys <jorismeys at gmail.com>:
>> @Barry : regardless of whether '_' comes before or after '1' , it
>> should be consistent. Adding an 'a' shouldn't shift '_' from before
>> '1' to between '1' and '2', that's clearly an error. The help files
>> are not stating anything about that.
>
> ?That's an assumption. The help pages are quite clear about making assumptions.
>
I used the word 'error' too quickly. Translate 'error' into
'unexpected behaviour'. I also see now that assuming all characters
are actually used is an assumption one shouldn't make. But that's not
what I understood from the help text and the examples therein. Thanks
for the clarification.

I sincerely hope though that I can assume the sort order, using the
same locale, is always going to be the same. Otherwise order(x)
starts to look scaringly close to sample(seq_len(x))...

Cheers
Joris



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jmc at r-project.org  Thu Dec  8 00:19:14 2011
From: jmc at r-project.org (John Chambers)
Date: Wed, 07 Dec 2011 15:19:14 -0800
Subject: [Rd] Possible bug in 'new()' for Reference Classes
In-Reply-To: <4EDF8818.9000201@googlemail.com>
References: <4EDF8818.9000201@googlemail.com>
Message-ID: <4EDFF472.1030606@r-project.org>

Right, thanks for the catch.  Actually, field names "s", "se", "sel" 
would also produce the bug.  Partial matching of argument names bites 
again.  This should be fixed in r-devel and 2.14 patched, as of SVN rev. 
57842.

Do try to follow the API in the documentation and use generator objects 
for reference classes.  It's simpler than using S4 new() and makes it 
clear that the example is of a reference class.

John

On 12/7/11 7:36 AM, Janko Thyson wrote:
> Dear list,
>
> I think I stumbled across a little bug with respect to the standard
> initialization routine for Reference Classes.
>
> It seems that a field 'self' is treated as if it's name would be
> '.self' (which we know is reserved for the self reference of the
> instantiated object itself) and thus an error is thrown.
> If the field value is assigned in an explicit call after the
> instantiation via 'new()', everything works just fine:
>
> setRefClass("ClassInfo",
>         fields=list(
>             self="character", super="character", sub="character"
>         )
>     )
>     new("ClassInfo", self="B", super="A", sub="C")    # Error
>
>     x <- new("ClassInfo", super="A", sub="C")
>     x
>     x$self <- "B" # Works
>     x
>
> Best regards,
> Janko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bates at stat.wisc.edu  Thu Dec  8 03:39:45 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Dec 2011 20:39:45 -0600
Subject: [Rd] RcppArmadillo compilation error: R CMD SHLIB returns
	status 1
In-Reply-To: <4EDE2662.1070606@gmail.com>
References: <OF2D585061.05B2DE60-ONC125795D.0064F3D4-C125795D.0064F3D9@diw.de>
	<4EDE2662.1070606@gmail.com>
Message-ID: <CAO7JsnSaw16zBC==J6KmZXuUfQOTmMPJCNnWOyrOTgEY7Z2cqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111207/7d442288/attachment.pl>

From hpages at fhcrc.org  Thu Dec  8 10:57:02 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 08 Dec 2011 01:57:02 -0800
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CB050CA6.25561%proebuck@mdanderson.org>
References: <CB050CA6.25561%proebuck@mdanderson.org>
Message-ID: <4EE089EE.2060903@fhcrc.org>

Hi Paul,

On 11-12-07 10:29 AM, Roebuck,Paul L wrote:
> Do this first and try again.
>
> R>  Sys.setlocale("LC_COLLATE", "C")

OK I see it now (in ?Sys.setlocale):

   Sys.setlocale("LC_COLLATE", "C")   # turn off locale-specific sorting,
                                      #  usually

Thanks all for the answers!

I never really realized how far some collating sequence could go in
terms of counter-intuitiveness e.g. the fact that LC_COLLATE=en_CA.UTF-8
doesn't preserve the order of the strings when a common suffix is
added to them is scary. Also it's not that LC_COLLATE=en_CA.UTF-8
just ignores the '_' (underscores) and the '.' (dots), that can only be
the first pass, then it needs to break ties in a way that defines a
total order. So it looks like the exact definition of this collating
sequence is counter-intuitive and complicated.

Maybe that's just how things are and the developers that want
portability and reproducibility of their code are already putting
a Sys.setlocale("LC_COLLATE", "C") statement somewhere in their package
to force all their users to be on the same collating sequence.
It sounds a little bit drastic though and it might introduce some
conflicts with other packages.

So maybe a better approach is to only alter LC_COLLATE temporarily
inside the functions where it matters i.e. where the returned value
actually depends on the collating sequence? If I don't do this, then
there is no way I can write a test for my function because the
test would work for me but fail for someone else.

Actually this is the situation I was facing when I did my first post:
I have a function that downloads a list of sequences from the Ensembl
FTP server, sorts them by name, and returns them to the user. I have
a test for that function and the test was working for me when I was
doing

   tools::testInstalledPackage("MyPackage", "types="tests")

but it was failing when I was doing 'R CMD check'. It seems that
the latter alters LC_COLLATE before running the tests (maybe to
LC_COLLATE=C) but not the former. I fixed this by enforcing
LC_COLLATE=C inside my function.

A naive question: wouldn't everything be simpler if LC_COLLATE=C
was the default for everybody?

Thanks,
H.

>
>
> On 12/7/11 3:41 AM, "Herv? Pag?s"<hpages at fhcrc.org>  wrote:
>
>> Hi,
>>
>> This looks OK:
>>
>>> x<- c("_1_", "1_9", "2_9")
>>> rank(x)
>> [1] 1 2 3
>>
>> But this does not:
>>
>>> xa<- paste(x, "a", sep="")
>>> xa
>> [1] "_1_a" "1_9a" "2_9a"
>>> rank(xa)
>> [1] 2 1 3
>>
>> Cheers,
>> H.
>>
>>> sessionInfo()
>> R version 2.14.0 (2011-10-31)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>>    [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>    [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>    [7] LC_PAPER=C                 LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.0
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pviefers at hotmail.de  Thu Dec  8 08:36:07 2011
From: pviefers at hotmail.de (Paul Viefers)
Date: Thu, 8 Dec 2011 08:36:07 +0100
Subject: [Rd] RcppArmadillo compilation error: R CMD SHLIB returns
	status 1
In-Reply-To: <CAO7JsnSaw16zBC==J6KmZXuUfQOTmMPJCNnWOyrOTgEY7Z2cqA@mail.gmail.com>
References: <OF2D585061.05B2DE60-ONC125795D.0064F3D4-C125795D.0064F3D9@diw.de>	<4EDE2662.1070606@gmail.com>
	<CAO7JsnSaw16zBC==J6KmZXuUfQOTmMPJCNnWOyrOTgEY7Z2cqA@mail.gmail.com>
Message-ID: <SNT142-ds19988EBDF0F985822E5B45A7B80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111208/a4707abb/attachment.pl>

From Gordon.Brown at cancer.org.uk  Wed Dec  7 16:03:15 2011
From: Gordon.Brown at cancer.org.uk (Gordon Brown)
Date: Wed, 7 Dec 2011 15:03:15 +0000
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CAO1zAVZzHE9jLTAn88x8ORYN=+Qe9DOeE731Q27SkB1s=ezOxA@mail.gmail.com>
Message-ID: <CB0530B3.6F56%Gordon.Brown@cancer.org.uk>

Hi, folks,

Underscores are, in fact, ignored in some collation orders, including (if I
recall correctly) en_CA.UTF-8.  It's caused me a bit of confusion now and
then.  No idea about "English_United States.1252", but from the fact that
Joris' example does not agree with Herv?'s, it seems most likely that it
does not ignore them.

Cheers,

 - Gord Brown


On 2011/12/07 14:48, "Joris Meys" <jorismeys at gmail.com> wrote:

> @Barry : regardless of whether '_' comes before or after '1' , it
> should be consistent. Adding an 'a' shouldn't shift '_' from before
> '1' to between '1' and '2', that's clearly an error. The help files
> are not stating anything about that. The only thing I can imagine, is
> that '_' gets ignored (in that case 19a would rank before 1a).
> 
> This said, I can't reproduce.
> 
>> x <- c("_1_", "1_9", "2_9")
>> xa <- paste(x,'a',sep='')
>> rank(x)
> [1] 1 2 3
>> rank(xa)
> [1] 1 2 3
> 
>> sessionInfo()
> R version 2.14.0 Patched (2006-00-00 r00000)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
> 
> attached base packages:
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>    methods   base
> 
> other attached packages:
> [1] svSocket_0.9-51 TinnR_1.0.3     R2HTML_2.2      Hmisc_3.8-3
> survival_2.36-9
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.14.1  grid_2.14.0     lattice_0.19-33 svMisc_0.9-63
> tools_2.14.0
> 
> 
> 2011/12/7 Herv? Pag?s <hpages at fhcrc.org>:
>> Hi,
>> 
>> This looks OK:
>> 
>>> x <- c("_1_", "1_9", "2_9")
>>> rank(x)
>> [1] 1 2 3
>> 
>> But this does not:
>> 
>>> xa <- paste(x, "a", sep="")
>>> xa
>> [1] "_1_a" "1_9a" "2_9a"
>>> rank(xa)
>> [1] 2 1 3
>> 
>> Cheers,
>> H.
>> 
>>> sessionInfo()
>> R version 2.14.0 (2011-10-31)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> 
>> locale:
>> ?[1] LC_CTYPE=en_CA.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_CA.UTF-8 ? ? ? ?LC_COLLATE=en_CA.UTF-8
>> ?[5] LC_MONETARY=en_CA.UTF-8 ? ?LC_MESSAGES=en_CA.UTF-8
>> ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.0
>> 
>> 
>> --
>> Herv? Pag?s
>> 
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>> 
>> E-mail: hpages at fhcrc.org
>> Phone: ?(206) 667-5791
>> Fax: ? ?(206) 667-1319
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hadley at rice.edu  Thu Dec  8 14:30:36 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 8 Dec 2011 13:30:36 +0000
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EE089EE.2060903@fhcrc.org>
References: <CB050CA6.25561%proebuck@mdanderson.org>
	<4EE089EE.2060903@fhcrc.org>
Message-ID: <CABdHhvHnkmZ5mSAWRfmcEAz59YToACB8K+qo_uQb9=g89UE7wQ@mail.gmail.com>

> Actually this is the situation I was facing when I did my first post:
> I have a function that downloads a list of sequences from the Ensembl
> FTP server, sorts them by name, and returns them to the user. I have
> a test for that function and the test was working for me when I was
> doing
>
> ?tools::testInstalledPackage("MyPackage", "types="tests")
>
> but it was failing when I was doing 'R CMD check'. It seems that
> the latter alters LC_COLLATE before running the tests (maybe to
> LC_COLLATE=C) but not the former. I fixed this by enforcing
> LC_COLLATE=C inside my function.
>
> A naive question: wouldn't everything be simpler if LC_COLLATE=C
> was the default for everybody?

Or if at least LC_COLLATE=C was the default for everyone when running
R CMD check.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jorismeys at gmail.com  Thu Dec  8 15:53:55 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 8 Dec 2011 15:53:55 +0100
Subject: [Rd] object type changes after being used as an argument in
	.Internal(paste(...))
Message-ID: <CAO1zAVaw-stF360hweOxzs2J84tywdn_BmpdaT3MTkQwKUCALg@mail.gmail.com>

OK, I realize I'm hacking away in R in a manner that was not intended,
but I found this interesting behaviour nonetheless, and I am not sure
whether this was intended to be so or not.

> x <- list(1:3,1:3,1:3)
> r1 <- do.call(paste,x) # the correct way
> sapply(x,typeof)
[1] "integer" "integer" "integer"

> r2 <- .Internal(paste(x,sep=" ",collapse=NULL))
> sapply(x,typeof)
[1] "character" "character" "character"

So although I don't change x explicitly, after the call to
.Internal(paste(...)) it suddenly is a list of characters instead of
integers. Is this supposed to happen? (Normally .Internal(paste(...))
takes an anonymous list(...) as argument, so it might very well be the
intended way of working.)

Cheers
Joris
-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From proebuck at mdanderson.org  Thu Dec  8 17:31:22 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Thu, 8 Dec 2011 10:31:22 -0600
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <4EE089EE.2060903@fhcrc.org>
Message-ID: <CB06427A.256B2%proebuck@mdanderson.org>

On 12/8/11 3:57 AM, "Herv? Pag?s" <hpages at fhcrc.org> wrote:

> On 11-12-07 10:29 AM, Roebuck,Paul L wrote:
>> Do this first and try again.
>> 
>> R>  Sys.setlocale("LC_COLLATE", "C")
> 
> OK I see it now (in ?Sys.setlocale):
> 
>    Sys.setlocale("LC_COLLATE", "C")   # turn off locale-specific sorting,
>                                       #  usually
> 
> Thanks all for the answers!
> 
> I never really realized how far some collating sequence could go in
> terms of counter-intuitiveness e.g. the fact that LC_COLLATE=en_CA.UTF-8
> doesn't preserve the order of the strings when a common suffix is
> added to them is scary. Also it's not that LC_COLLATE=en_CA.UTF-8
> just ignores the '_' (underscores) and the '.' (dots), that can only be
> the first pass, then it needs to break ties in a way that defines a
> total order. So it looks like the exact definition of this collating
> sequence is counter-intuitive and complicated.
> 
> Maybe that's just how things are and the developers that want
> portability and reproducibility of their code are already putting
> a Sys.setlocale("LC_COLLATE", "C") statement somewhere in their package
> to force all their users to be on the same collating sequence.
> It sounds a little bit drastic though and it might introduce some
> conflicts with other packages.
> 
> So maybe a better approach is to only alter LC_COLLATE temporarily
> inside the functions where it matters i.e. where the returned value
> actually depends on the collating sequence? If I don't do this, then
> there is no way I can write a test for my function because the
> test would work for me but fail for someone else.
> 
> Actually this is the situation I was facing when I did my first post:
> I have a function that downloads a list of sequences from the Ensembl
> FTP server, sorts them by name, and returns them to the user. I have
> a test for that function and the test was working for me when I was
> doing
> 
>    tools::testInstalledPackage("MyPackage", "types="tests")
> 
> but it was failing when I was doing 'R CMD check'. It seems that
> the latter alters LC_COLLATE before running the tests (maybe to
> LC_COLLATE=C) but not the former. I fixed this by enforcing
> LC_COLLATE=C inside my function.

Another developer here just ran into the problem two weeks ago when
data being processed on different machines (Linux,Windows) had different
results due to sorting. From my standpoint, I'm very hesitant to make
changes that affect behavior globally, so we changed it at the function
level in the package, did the sort and reset to original value using
on.exit() method.

As far as analysis reports, I believe we may need to set the LC_COLLATE
to the POSIX locale in ALL our standard Sweave templates as well to
ensure reproducibility, which is a BIG deal here.

> 
> A naive question: wouldn't everything be simpler if LC_COLLATE=C
> was the default for everybody?

Sure, but where's the fun in that? :)

>> 
>> 
>> On 12/7/11 3:41 AM, "Herv? Pag?s"<hpages at fhcrc.org>  wrote:
>> 
>>> This looks OK:
>>> 
>>>> x<- c("_1_", "1_9", "2_9")
>>>> rank(x)
>>> [1] 1 2 3
>>> 
>>> But this does not:
>>> 
>>>> xa<- paste(x, "a", sep="")
>>>> xa
>>> [1] "_1_a" "1_9a" "2_9a"
>>>> rank(xa)
>>> [1] 2 1 3
>>> 
>>> Cheers,
>>> H.
>>> 
>>>> sessionInfo()
>>> R version 2.14.0 (2011-10-31)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>> 
>>> locale:
>>>    [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>    [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>    [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>>    [7] LC_PAPER=C                 LC_NAME=C
>>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.14.0
>>> 


From hpages at fhcrc.org  Thu Dec  8 19:26:48 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 08 Dec 2011 10:26:48 -0800
Subject: [Rd] bug in rank(), order(), is.unsorted() on character vector
In-Reply-To: <CANVKczPL-VL0HBbQnbRYUGR7GCM08RR05DLGeTo--byxja-zGA@mail.gmail.com>
References: <CB050CA6.25561%proebuck@mdanderson.org>	<4EE089EE.2060903@fhcrc.org>
	<CANVKczPL-VL0HBbQnbRYUGR7GCM08RR05DLGeTo--byxja-zGA@mail.gmail.com>
Message-ID: <4EE10168.30106@fhcrc.org>

Hi Barry,

Hope you don't mind if I put this back on the list.

On 11-12-08 05:50 AM, Barry Rowlingson wrote:
> 2011/12/8 Herv? Pag?s<hpages at fhcrc.org>:
>
>> A naive question: wouldn't everything be simpler if LC_COLLATE=C
>> was the default for everybody?
>
>   Yet when we Brits suggest everything would be simpler if the whole
> world spoke the Queen's English it causes all sorts of trouble...

:-) Sure I see your point.

But it's a programming language here, used by a lot of researchers.
And having the result of an analysis depend on a crazy collate is
causing all sorts of troubles too.

Note that trying to strike back the Empire is a lost battle anyway.
When you use R (as a user or a developer), any function name you
type (sort, rank, print, summary, etc...) is in Queen's English.
And their man pages too.

Also note that I was just talking about the *default*. AFAIK other
very serious projects like Python or SQLite *by default* use a
collating sequence that behaves like LC_COLLATE=C on strings
that contain ASCII chars only. And they let you change that if you
want. Are they being imperialist? Most R users/developers are in
research or academics where I suspect consistency and reproducibility
is even a bigger deal than in the Python or SQLite community.

Cheers,
H.


>
> Barry


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ssath002 at ucr.edu  Thu Dec  8 21:33:49 2011
From: ssath002 at ucr.edu (Sumukh Sathnur)
Date: Thu, 8 Dec 2011 12:33:49 -0800
Subject: [Rd] Unable to collate and parse R files with R CMD check
In-Reply-To: <4EDF2797.3080606@statistik.tu-dortmund.de>
References: <CANxMqTGJuio5_Ca=P47WdSviTUn1T6W2S3u8zVpS4n=qnr2Qiw@mail.gmail.com>
	<4EDF2797.3080606@statistik.tu-dortmund.de>
Message-ID: <CANxMqTF_Y-YuJw4PQccoLdVCYV0xCW9Wt8q6tUi76ds14OHBcA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111208/0adfbaa6/attachment.pl>

From mtmorgan at fhcrc.org  Thu Dec  8 23:52:54 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 08 Dec 2011 14:52:54 -0800
Subject: [Rd] Reference class finalize() fails with 'attempt to apply
	non-function'
Message-ID: <4EE13FC6.5070606@fhcrc.org>

This bug appears intermittently in R CMD check when reference classes 
have finalize methods. The problem is that garbage collection can be run 
after the methods package is no longer available. It affects 
(periodically) the Bioconductor AnnotationDbi package as well as 
packages that contain Rcpp classes. To reproduce:

   library(methods)
   a = setRefClass("A", methods=list(finalize=function() cat("A\n")))
   b = setRefClass("B", contains="A")

repeat b = setRefClass("B", contains="A") until finalize does not run 
(no garbage collection triggered during setRefClass)

   b = setRefClass("B", contains="A")
   b = setRefClass("B", contains="A")

and then

 > detach("package:methods")
 > gc()
Error in function (x)  : attempt to apply non-function
Error in function (x)  : attempt to apply non-function

 > traceback()
1: function (x)
    x$.self$finalize()(<environment>)

I believe a variant of the same type of problem generates an error

Error in function (x)  : no function to return from, jumping to top level

also seen in AnnotationDbi and Rcpp packages
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From hpages at fhcrc.org  Fri Dec  9 19:40:55 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 09 Dec 2011 10:40:55 -0800
Subject: [Rd] bug in sum() on integer vector
Message-ID: <4EE25637.1020404@fhcrc.org>

Hi,

   x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))

This is correct:

   > sum(as.double(x))
   [1] 0

This is not:

   > sum(x)
   [1] 4996000

Returning NA (with a warning) would also be acceptable for the latter.
That would make it consistent with cumsum(x):

   > cumsum(x)[length(x)]
   [1] NA
   Warning message:
   Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'

Thanks!
H.

 > sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Fri Dec  9 20:39:57 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 09 Dec 2011 14:39:57 -0500
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE25637.1020404@fhcrc.org>
References: <4EE25637.1020404@fhcrc.org>
Message-ID: <4EE2640D.3030402@gmail.com>

On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
> Hi,
>
>     x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>
> This is correct:
>
>     >  sum(as.double(x))
>     [1] 0
>
> This is not:
>
>     >  sum(x)
>     [1] 4996000
>
> Returning NA (with a warning) would also be acceptable for the latter.
> That would make it consistent with cumsum(x):
>
>     >  cumsum(x)[length(x)]
>     [1] NA
>     Warning message:
>     Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'

This is a 64 bit problem; in 32 bits things work out properly.   I'd 
guess in 64 bit arithmetic we or the run-time are doing something to 
simulate 32 bit arithmetic (since integers are 32 bits), but it looks as 
though we're not quite getting it right.

Duncan Murdoch

> Thanks!
> H.
>
>   >  sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>    [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>    [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>    [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>    [7] LC_PAPER=C                 LC_NAME=C
>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>


From hpages at fhcrc.org  Fri Dec  9 22:41:59 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 09 Dec 2011 13:41:59 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE2640D.3030402@gmail.com>
References: <4EE25637.1020404@fhcrc.org> <4EE2640D.3030402@gmail.com>
Message-ID: <4EE280A7.3000204@fhcrc.org>

Hi Duncan,

On 11-12-09 11:39 AM, Duncan Murdoch wrote:
> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>> Hi,
>>
>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>
>> This is correct:
>>
>> > sum(as.double(x))
>> [1] 0
>>
>> This is not:
>>
>> > sum(x)
>> [1] 4996000
>>
>> Returning NA (with a warning) would also be acceptable for the latter.
>> That would make it consistent with cumsum(x):
>>
>> > cumsum(x)[length(x)]
>> [1] NA
>> Warning message:
>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>
> This is a 64 bit problem; in 32 bits things work out properly.
> I'd guess
> in 64 bit arithmetic we or the run-time are doing something to simulate
> 32 bit arithmetic (since integers are 32 bits), but it looks as though
> we're not quite getting it right.

It doesn't work properly for me on Leopard (32-bit mode):

   > x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
   > sum(as.double(x))
   [1] 0
   > sum(x)
   [1] 4996000
   > sessionInfo()
   R version 2.14.0 RC (2011-10-27 r57452)
   Platform: i386-apple-darwin9.8.0/i386 (32-bit)

   locale:
   [1] C

   attached base packages:
   [1] stats     graphics  grDevices utils     datasets  methods   base

It looks like the problem is that isum() (in src/main/summary.c)
uses a 'double' internally to do the sum, whereas rsum() and csum()
use a 'long double'.

Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
will always be the same (probably fine) and that TRUE values in the
input vector are always represented as a 1 (not so sure about this one).

A more fundamental question: is switching back and forth between
'int' and 'double' (or 'long double') the right thing to do for doing
"safe" arithmetic on integers?

Thanks!
H.


>
> Duncan Murdoch
>
>> Thanks!
>> H.
>>
>> > sessionInfo()
>> R version 2.14.0 (2011-10-31)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C
>> [3] LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8
>> [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8
>> [7] LC_PAPER=C LC_NAME=C
>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Sat Dec 10 14:27:42 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 10 Dec 2011 08:27:42 -0500
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE280A7.3000204@fhcrc.org>
References: <4EE25637.1020404@fhcrc.org> <4EE2640D.3030402@gmail.com>
	<4EE280A7.3000204@fhcrc.org>
Message-ID: <4EE35E4E.6050703@gmail.com>

On 11-12-09 4:41 PM, Herv? Pag?s wrote:
> Hi Duncan,
>
> On 11-12-09 11:39 AM, Duncan Murdoch wrote:
>> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>
>>> This is correct:
>>>
>>>> sum(as.double(x))
>>> [1] 0
>>>
>>> This is not:
>>>
>>>> sum(x)
>>> [1] 4996000
>>>
>>> Returning NA (with a warning) would also be acceptable for the latter.
>>> That would make it consistent with cumsum(x):
>>>
>>>> cumsum(x)[length(x)]
>>> [1] NA
>>> Warning message:
>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>
>> This is a 64 bit problem; in 32 bits things work out properly.
>> I'd guess
>> in 64 bit arithmetic we or the run-time are doing something to simulate
>> 32 bit arithmetic (since integers are 32 bits), but it looks as though
>> we're not quite getting it right.
>
> It doesn't work properly for me on Leopard (32-bit mode):
>
>     >  x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>     >  sum(as.double(x))
>     [1] 0
>     >  sum(x)
>     [1] 4996000
>     >  sessionInfo()
>     R version 2.14.0 RC (2011-10-27 r57452)
>     Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>
>     locale:
>     [1] C
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets  methods   base
>
> It looks like the problem is that isum() (in src/main/summary.c)
> uses a 'double' internally to do the sum, whereas rsum() and csum()
> use a 'long double'.

A double has 53 bits to store the mantissa, so any 32 bit integer can be 
stored exactly.

>
> Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
> will always be the same (probably fine) and that TRUE values in the
> input vector are always represented as a 1 (not so sure about this one).
>
> A more fundamental question: is switching back and forth between
> 'int' and 'double' (or 'long double') the right thing to do for doing
> "safe" arithmetic on integers?

If you have enough terms in the sum that an intermediate value exceeds 
53 bits in length, then you'll get the wrong answer, because the 
intermediate sum can't be stored exactly.  That happens in your example. 
On the 32 bit platform I tested (Windows 32 bit), intermediate values 
are stored in registers with 64 bit precision, which is probably why 
Windows 32 bit gets it right, but various other platforms don't.

On your fundamental question:  I think the answer is that R is doing the 
right thing.  R doesn't think of an integer as a particular 
representation, it thinks of it as a number.  So if you ask for the sum 
of those numbers, R should return its best approximation to that sum, 
and it does.

A different approach would be to do the sum in 32 bit registers and 
detect 32 bit overflow in intermediate results.  But that's a very 
hardware-oriented approach, rather than a mathematical approach.

Duncan Murdoch

> Thanks!
> H.
>
>
>>
>> Duncan Murdoch
>>
>>> Thanks!
>>> H.
>>>
>>>> sessionInfo()
>>> R version 2.14.0 (2011-10-31)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>
>>> locale:
>>> [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C
>>> [3] LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8
>>> [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8
>>> [7] LC_PAPER=C LC_NAME=C
>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>
>
>


From p.murrell at auckland.ac.nz  Sun Dec 11 22:17:50 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 12 Dec 2011 10:17:50 +1300
Subject: [Rd] Graphics device hook to manipulate plotmath
In-Reply-To: <CAKCAbMgWwATvOZZW=mAJSenaDBAQaJuBuj35KDqimAgw68Qj6w@mail.gmail.com>
References: <CAKCAbMgWwATvOZZW=mAJSenaDBAQaJuBuj35KDqimAgw68Qj6w@mail.gmail.com>
Message-ID: <4EE51DFE.5050103@auckland.ac.nz>

Hi

On 7/12/2011 9:34 a.m., Zack Weinberg wrote:
> Is there a hook that allows a graphics device to apply transformations
> to plotmath expressions *before* they are rendered?  If there isn't
> one yet, would it be feasible to add one?

No such hook exists.  Plotmath expression get split off before the 
graphics engine (in 'graphics' and 'grid').

One possibility might be to add a device flag that says the device wants 
to handle plotmath, plus a new device call, DEV_math() say, so that 
'graphics' and 'grid' can send plotmath unaltered to the device.  But 
there are likely to be complications.  For example, both 'graphics' and 
'grid' can ask for metric information about text, so there would be more 
work to ensure that metric information corresponded to what the device 
would draw for plotmath expressions.

Paul

> The motivation for this hook is graphic devices that feed into
> something that already has support for math layout, such as the
> tikzDevice package (which has TeX downstream). Given
>
>      text(x, y, expression(alpha+beta+gamma+delta))
>
> it would be ideal (in terms of output quality) if tikzDevice could
> process that as if
>
>     text(x, y, "$\\alpha+\\beta+\\gamma+\\delta$")
>
> had been written instead.  This would also be easier to *implement*,
> from the device side, than a back-conversion from Adobe-Symbol glyph
> requests to TeX math symbol macros.
>
> (Users of tikzDevice can of course write all their TeX math
> expressions directly, but this may be a great deal of conversion work,
> and is also inconvenient for someone tweaking their plots in one of
> the interactive graphics devices before saving them permanently.)
>
> Thanks in advance,
> zw
>
> p.s. I am not subscribed to this list, please cc: me on replies.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ruipbarradas at sapo.pt  Mon Dec 12 14:12:28 2011
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 12 Dec 2011 13:12:28 +0000
Subject: [Rd] Problems in building a DLL in 64-bit Windows
Message-ID: <20111212131228.732736q174vpaxmk@mail.sapo.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111212/abde2151/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Dec 12 14:37:28 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Dec 2011 13:37:28 +0000 (GMT)
Subject: [Rd] Problems in building a DLL in 64-bit Windows
In-Reply-To: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
References: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
Message-ID: <alpine.LFD.2.02.1112121332510.29587@gannet.stats.ox.ac.uk>

What is R.ddl? Or is that not the actual output?

In any case, it isn't going to work unless you run 64-bit 'R', and 
my guess is that you used 32-bit 'R' to do this.  Make sure you use

..../bin/x64/R CMD

and you do not need the -L....


On Mon, 12 Dec 2011, ruipbarradas at sapo.pt wrote:

>
> I am trying to build a C language DLL and it works well with i386 but when I compile with it substituted
> by x64, like the FAQ page says, the result is an error message:

which 'FAQ page' (which FAQ, which page ...)?

> C:/PROGRA~1/R/R-214~1.0/bin/x64/R.ddl: file not recognized : File format not recognized
> collect2: ld returned 1 exit status
>
> How can I solve this? The problem is with R 2-14.0 and 2-13.0
>
> The complete source code is
>
> /*
> * myfun.c
> */
> #include <stdio.h>
> #include <R.h>
> #include <Rinternals.h>
> #include <R_ext/Rdynload.h>
>
> void myfn(double *x){ *x += 1; }
>
> The DLL is build like this:
>
> R CMD SHLIB -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -lR myfun.c -o myfun64.dll
>
> and get the error message above.
>
> The R code:
>
> #
> # myfun.R: this works with i386, but not with x64
> #
> dyn.load("myfun64.dll")
> f <- function(x) {.C("myfn", x=as.double(x))$x}
> f(1)
> f(1000)
> dyn.unload("dllmain.dll")
>
> I am trying to build a package, or at least a set of functions, and performance is sometimes a problem.
> Thank you,
>
> Rui Barradas
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From myrmecocystus at gmail.com  Mon Dec 12 16:23:50 2011
From: myrmecocystus at gmail.com (Scott Chamberlain)
Date: Mon, 12 Dec 2011 09:23:50 -0600
Subject: [Rd] Proper use of suppressPackageStartupMessages in package
	building
Message-ID: <CAD-oS=-zEfUJSm=8KkeLpttp9KFhsvkF4muyx5jFZ1k3e5PHuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111212/0f6c49b5/attachment.pl>

From JRMH001 at gmail.com  Sat Dec 10 22:00:10 2011
From: JRMH001 at gmail.com (J. R. M. Hosking)
Date: Sat, 10 Dec 2011 16:00:10 -0500
Subject: [Rd] clusterSetRNGStream() question
Message-ID: <jc0h8p$jh3$1@dough.gmane.org>

In a vanilla R 2.14.0 GUI session (on Windows XP SP3):

 > library(parallel)
 > cl<-makePSOCKcluster(2)
 > RNGkind()
[1] "Mersenne-Twister" "Inversion"
 > clusterSetRNGStream(cl)
 > RNGkind()
[1] "L'Ecuyer-CMRG" "Inversion"
 > stopCluster(cl)

Is it intentional that clusterSetRNGStream() changes the RNG kind in
the master process?  The code of clusterSetRNGStream() suggests that
it is not: the old random number seed is saved in 'oldseed' and then
assigned to '.Random.seed':

   .Random.seed <- oldseed

(https://svn.r-project.org/R/trunk/src/library/parallel/R/RngStream.R,
line 45).  However, if the intent is to restore the old seed then
this assignment should be made in the global environment, e.g. via

   assign(".Random.seed", oldseed, envir = .GlobalEnv)


J. R. M. Hosking


 > sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From ligges at statistik.tu-dortmund.de  Mon Dec 12 20:37:12 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 12 Dec 2011 20:37:12 +0100
Subject: [Rd] Problems in building a DLL in 64-bit Windows
In-Reply-To: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
References: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
Message-ID: <4EE657E8.20406@statistik.tu-dortmund.de>



On 12.12.2011 14:12, ruipbarradas at sapo.pt wrote:
>
> I am trying to build a C language DLL and it works well with i386 but when I compile with it substituted
> by x64, like the FAQ page says, the result is an error message:
>
> C:/PROGRA~1/R/R-214~1.0/bin/x64/R.ddl:

What is R.ddl? Do you mean R.dll?

If this is a typo: Is your OS 64 bit? Have you used the right compiler 
collection for making 64-bit code according to the manual?

Best,
Uwe Ligges



file not recognized : File format not recognized
> collect2: ld returned 1 exit status
>
> How can I solve this? The problem is with R 2-14.0 and 2-13.0
>
> The complete source code is
>
> /*
> * myfun.c
> */
> #include<stdio.h>
> #include<R.h>
> #include<Rinternals.h>
> #include<R_ext/Rdynload.h>
>
> void myfn(double *x){ *x += 1; }
>
> The DLL is build like this:
>
> R CMD SHLIB -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -lR myfun.c -o myfun64.dll
>
> and get the error message above.
>
> The R code:
>
> #
> # myfun.R: this works with i386, but not with x64
> #
> dyn.load("myfun64.dll")
> f<- function(x) {.C("myfn", x=as.double(x))$x}
> f(1)
> f(1000)
> dyn.unload("dllmain.dll")
>
> I am trying to build a package, or at least a set of functions, and performance is sometimes a problem.
> Thank you,
>
> Rui Barradas
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ruipbarradas at sapo.pt  Mon Dec 12 21:12:52 2011
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 12 Dec 2011 20:12:52 +0000
Subject: [Rd] Problems in building a DLL in 64-bit Windows
In-Reply-To: <alpine.LFD.2.02.1112121332510.29587@gannet.stats.ox.ac.uk>
References: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
	<alpine.LFD.2.02.1112121332510.29587@gannet.stats.ox.ac.uk>
Message-ID: <20111212201252.15986b4k4rjfgj7o@mail.sapo.pt>

Prof. Ripley,

Thank you for your suggestion.
In the mean time, I had just found a solution and was going to send a  
mail saying that the problem was solved
when I read your answer, and others.

The 'ddl' is obviously not the actual output, DOS doesn't allow copy&paste.
The solution is to use the compiler directly,

gcc -c myfun.c -o myfun.o
gcc -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -shared myfun -o myfun64.dll

Note that I didn't write '-lR' and it worked. In fact, when I've tryied
to, it gave an error again, it doesn't recognize  .../bin/x64/R.dll

(-L is overriden by R CMD SHLIB, it puts i386 in the end...)

Once again, thank you for your suggestion, I'll give it a try.

Rui Barradas


Citando Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> What is R.ddl? Or is that not the actual output?
>
> In any case, it isn't going to work unless you run 64-bit 'R', and  
> my guess is that you used 32-bit 'R' to do this.  Make sure you use
>
> ..../bin/x64/R CMD
>
> and you do not need the -L....
>
>
> On Mon, 12 Dec 2011, ruipbarradas at sapo.pt wrote:
>
>>
>> I am trying to build a C language DLL and it works well with i386  
>> but when I compile with it substituted
>> by x64, like the FAQ page says, the result is an error message:
>
> which 'FAQ page' (which FAQ, which page ...)?
>
>> C:/PROGRA~1/R/R-214~1.0/bin/x64/R.ddl: file not recognized : File  
>> format not recognized
>> collect2: ld returned 1 exit status
>>
>> How can I solve this? The problem is with R 2-14.0 and 2-13.0
>>
>> The complete source code is
>>
>> /*
>> * myfun.c
>> */
>> #include <stdio.h>
>> #include <R.h>
>> #include <Rinternals.h>
>> #include <R_ext/Rdynload.h>
>>
>> void myfn(double *x){ *x += 1; }
>>
>> The DLL is build like this:
>>
>> R CMD SHLIB -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -lR myfun.c -o myfun64.dll
>>
>> and get the error message above.
>>
>> The R code:
>>
>> #
>> # myfun.R: this works with i386, but not with x64
>> #
>> dyn.load("myfun64.dll")
>> f <- function(x) {.C("myfn", x=as.double(x))$x}
>> f(1)
>> f(1000)
>> dyn.unload("dllmain.dll")
>>
>> I am trying to build a package, or at least a set of functions, and  
>> performance is sometimes a problem.
>> Thank you,
>>
>> Rui Barradas
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From ligges at statistik.tu-dortmund.de  Mon Dec 12 21:28:38 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 12 Dec 2011 21:28:38 +0100
Subject: [Rd] Problems in building a DLL in 64-bit Windows
In-Reply-To: <20111212201252.15986b4k4rjfgj7o@mail.sapo.pt>
References: <20111212131228.732736q174vpaxmk@mail.sapo.pt>
	<alpine.LFD.2.02.1112121332510.29587@gannet.stats.ox.ac.uk>
	<20111212201252.15986b4k4rjfgj7o@mail.sapo.pt>
Message-ID: <4EE663F6.4050907@statistik.tu-dortmund.de>



On 12.12.2011 21:12, ruipbarradas at sapo.pt wrote:
> Prof. Ripley,
>
> Thank you for your suggestion.
> In the mean time, I had just found a solution and was going to send a
> mail saying that the problem was solved
> when I read your answer, and others.
>
> The 'ddl' is obviously not the actual output, DOS

DOS is not supported by R. I believe you are talking about the Windows 
command shell (and that allows copy and paste!).


 > doesn't allow copy&paste.
> The solution is to use the compiler directly,
>
> gcc -c myfun.c -o myfun.o
> gcc -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -shared myfun -o myfun64.dll

If you type gcc and do not need to change the name, you pretty likely 
use a 32-bit compiler. At least not a 32-bit one from the Rtools.



> Note that I didn't write '-lR' and it worked. In fact, when I've tryied
> to, it gave an error again, it doesn't recognize .../bin/x64/R.dll

Sure, since a 32-bit compiler does not know about 64-bit binaries.

Uwe Ligges



> (-L is overriden by R CMD SHLIB, it puts i386 in the end...)
>
> Once again, thank you for your suggestion, I'll give it a try.
>
> Rui Barradas
>
>
> Citando Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>
>> What is R.ddl? Or is that not the actual output?
>>
>> In any case, it isn't going to work unless you run 64-bit 'R', and my
>> guess is that you used 32-bit 'R' to do this. Make sure you use
>>
>> ..../bin/x64/R CMD
>>
>> and you do not need the -L....
>>
>>
>> On Mon, 12 Dec 2011, ruipbarradas at sapo.pt wrote:
>>
>>>
>>> I am trying to build a C language DLL and it works well with i386 but
>>> when I compile with it substituted
>>> by x64, like the FAQ page says, the result is an error message:
>>
>> which 'FAQ page' (which FAQ, which page ...)?
>>
>>> C:/PROGRA~1/R/R-214~1.0/bin/x64/R.ddl: file not recognized : File
>>> format not recognized
>>> collect2: ld returned 1 exit status
>>>
>>> How can I solve this? The problem is with R 2-14.0 and 2-13.0
>>>
>>> The complete source code is
>>>
>>> /*
>>> * myfun.c
>>> */
>>> #include <stdio.h>
>>> #include <R.h>
>>> #include <Rinternals.h>
>>> #include <R_ext/Rdynload.h>
>>>
>>> void myfn(double *x){ *x += 1; }
>>>
>>> The DLL is build like this:
>>>
>>> R CMD SHLIB -LC:/PROGRA~1/R/R-214~1.0/bin/x64 -lR myfun.c -o myfun64.dll
>>>
>>> and get the error message above.
>>>
>>> The R code:
>>>
>>> #
>>> # myfun.R: this works with i386, but not with x64
>>> #
>>> dyn.load("myfun64.dll")
>>> f <- function(x) {.C("myfn", x=as.double(x))$x}
>>> f(1)
>>> f(1000)
>>> dyn.unload("dllmain.dll")
>>>
>>> I am trying to build a package, or at least a set of functions, and
>>> performance is sometimes a problem.
>>> Thank you,
>>>
>>> Rui Barradas
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley, ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, Tel: +44 1865 272861 (self)
>> 1 South Parks Road, +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK Fax: +44 1865 272595
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nashjc at uottawa.ca  Mon Dec 12 22:10:07 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Mon, 12 Dec 2011 16:10:07 -0500
Subject: [Rd] Detecting typo in function argument
Message-ID: <4EE66DAF.4020403@uottawa.ca>

With some chagrin after spending a couple of hours trying to debug a script, I realized I
had typed in something like

ans<-optimx(start, myfn, mygr, lower<-lo, upper=up)

that is, the "<-" rather than "=". The outcome on my machine was a non-obvious error
several layers deep in the call stack. For info, optim() seems to stop much more quickly.

The error is "obvious", but I'm wondering if there is a simple way to trap or warn of it.
For completeness, I include the commands I used to force the error. Note that it will only
work fully with the latest (R-forge) version of optimx/optfntools because of the form of
gr="gfwd" that allows a choice of different numerical gradient routines.

This is a curiosity rather than a necessity, but if there is a simple way to check, I'll
put it in my codes.

Cheers,

JN

rm(list=ls())
start<-rep(3,6)
lo<-rep(2,6)
up<-rep(4,6)
flb <- function(x)
    { p <- length(x); sum(c(1, rep(4, p-1)) * (x - c(1, x[-p])^2)^2) }
ans<-optim(start, flb, lower=lo, upper=up)
ans
ans<-optim(start, flb, lower<-lo, upper=up)
ans
ans1<-optim(start, flb, lower<-lo, upper=up)
ans1
require(optimx)
ans1x<-optimx(start, flb, lower<-lo, upper=up)
ans1x<-optimx(start, flb, gr="gfwd",lower<-lo, upper=up)
ans1<-optim(start, flb, gr=NULL,lower<-lo, upper=up)


From ligges at statistik.tu-dortmund.de  Mon Dec 12 22:24:37 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 12 Dec 2011 22:24:37 +0100
Subject: [Rd] Detecting typo in function argument
In-Reply-To: <4EE66DAF.4020403@uottawa.ca>
References: <4EE66DAF.4020403@uottawa.ca>
Message-ID: <4EE67115.1000903@statistik.tu-dortmund.de>

This is valid syntax, so what should we check for?.

Uwe


On 12.12.2011 22:10, John C Nash wrote:
> With some chagrin after spending a couple of hours trying to debug a script, I realized I
> had typed in something like
>
> ans<-optimx(start, myfn, mygr, lower<-lo, upper=up)
>
> that is, the "<-" rather than "=". The outcome on my machine was a non-obvious error
> several layers deep in the call stack. For info, optim() seems to stop much more quickly.
>
> The error is "obvious", but I'm wondering if there is a simple way to trap or warn of it.
> For completeness, I include the commands I used to force the error. Note that it will only
> work fully with the latest (R-forge) version of optimx/optfntools because of the form of
> gr="gfwd" that allows a choice of different numerical gradient routines.
>
> This is a curiosity rather than a necessity, but if there is a simple way to check, I'll
> put it in my codes.
>
> Cheers,
>
> JN
>
> rm(list=ls())
> start<-rep(3,6)
> lo<-rep(2,6)
> up<-rep(4,6)
> flb<- function(x)
>      { p<- length(x); sum(c(1, rep(4, p-1)) * (x - c(1, x[-p])^2)^2) }
> ans<-optim(start, flb, lower=lo, upper=up)
> ans
> ans<-optim(start, flb, lower<-lo, upper=up)
> ans
> ans1<-optim(start, flb, lower<-lo, upper=up)
> ans1
> require(optimx)
> ans1x<-optimx(start, flb, lower<-lo, upper=up)
> ans1x<-optimx(start, flb, gr="gfwd",lower<-lo, upper=up)
> ans1<-optim(start, flb, gr=NULL,lower<-lo, upper=up)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpickeri at mail.nih.gov  Tue Dec 13 18:12:12 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Tue, 13 Dec 2011 09:12:12 -0800 (PST)
Subject: [Rd] problems with iconv
Message-ID: <1323796332274-4191177.post@n4.nabble.com>

I'm at wit's ends here and need some help.

I've downloaded and compiled iconv versions 1.13 and 1.14  -
libiconv.so.2.5.0 and libiconv.so.2.5.1 and copied the iconv all over,
replacing the native iconv on my Solaris machine.

Still when I try to run the configure I get:

checking iconv.h usability... yes
checking iconv.h presence... yes
checking for iconv.h... yes
checking for iconv... yes
checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"...
ac_fn_c_try_run  29941
no
configure: error: a suitable iconv is essential

If I cheat and rig the configure file so that it continues even with the
error, I get a nice version of R that runs several of the demos, but should
I try to update the packages I get:

* installing *source* package 'foreign' ...
** package 'foreign' successfully unpacked and MD5 sums checked
Error in iconv(x, "latin1", "ASCII") :
  unsupported conversion from 'latin1' to 'ASCII'

So, what is wrong with iconv 1.14?  It should be latest and greatest.  What
other iconv should I have used?  Where should I have put iconv?

Thanks very much in advance and I promise to share the binaries with who
ever wants them,
roger

--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4191177.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Tue Dec 13 20:29:18 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Dec 2011 19:29:18 +0000
Subject: [Rd] problems with iconv
In-Reply-To: <1323796332274-4191177.post@n4.nabble.com>
References: <1323796332274-4191177.post@n4.nabble.com>
Message-ID: <4EE7A78E.7060401@stats.ox.ac.uk>

On 13/12/2011 17:12, RogerP wrote:
> I'm at wit's ends here and need some help.

Like reading the manual?

You need to ensure that GNU libiconv is actually used: you are obviously 
not finding it, and I suspect your error is in not setting the path to 
its header file.

There are explicit instructions for libiconv on Solaris in the manual 
which the INSTALL file asked you to read before trying to install R and 
to resolve any problems.



> I've downloaded and compiled iconv versions 1.13 and 1.14  -
> libiconv.so.2.5.0 and libiconv.so.2.5.1 and copied the iconv all over,
> replacing the native iconv on my Solaris machine.
>
> Still when I try to run the configure I get:
>
> checking iconv.h usability... yes
> checking iconv.h presence... yes
> checking for iconv.h... yes
> checking for iconv... yes
> checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"...
> ac_fn_c_try_run  29941
> no
> configure: error: a suitable iconv is essential
>
> If I cheat and rig the configure file so that it continues even with the
> error, I get a nice version of R that runs several of the demos, but should
> I try to update the packages I get:
>
> * installing *source* package 'foreign' ...
> ** package 'foreign' successfully unpacked and MD5 sums checked
> Error in iconv(x, "latin1", "ASCII") :
>    unsupported conversion from 'latin1' to 'ASCII'
>
> So, what is wrong with iconv 1.14?  It should be latest and greatest.  What
> other iconv should I have used?  Where should I have put iconv?
>
> Thanks very much in advance and I promise to share the binaries with who
> ever wants them,
> roger
>
> --
> View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4191177.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpickeri at mail.nih.gov  Tue Dec 13 21:32:25 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Tue, 13 Dec 2011 12:32:25 -0800 (PST)
Subject: [Rd] problems with iconv
In-Reply-To: <4EE7A78E.7060401@stats.ox.ac.uk>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
Message-ID: <1323808345478-4191892.post@n4.nabble.com>

As I said in my email: help I appreciate - sarcasm not so much.

I re-read the manual - just in case I'd missed something and still do not
have any idea.  The manual, BTW, needs some serious help for it to be useful
to its intended audiance - people who don't already know how to install R. 
For example, too many times example are given as to what changes to make,
but oh, there is no mention of where to make the changes.  It is assumed
that the reader knows where to make the changes.

Anyway, configure states that if found the iconv header - iconv.h, which i
put in the includes directory.  It says it finds iconv - though it does not
say where.  

Anyone with some useful help?

--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4191892.html
Sent from the R devel mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Tue Dec 13 22:39:20 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 13 Dec 2011 22:39:20 +0100
Subject: [Rd] problems with iconv
In-Reply-To: <1323808345478-4191892.post@n4.nabble.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
Message-ID: <4EE7C608.9070906@statistik.tu-dortmund.de>

Please cite the original messages!


On 13.12.2011 21:32, RogerP wrote:
> As I said in my email: help I appreciate - sarcasm not so much.
>
> I re-read the manual - just in case I'd missed something and still do not
> have any idea.  The manual, BTW, needs some serious help for it to be useful
> to its intended audiance - people who don't already know how to install R.
> For example, too many times example are given as to what changes to make,
> but oh, there is no mention of where to make the changes.  It is assumed
> that the reader knows where to make the changes.

Where are the patches to improve that?


> Anyway, configure states that if found the iconv header - iconv.h, which i
> put in the includes directory.  It says it finds iconv - though it does not
> say where.
>
> Anyone with some useful help?

You altready got useful help but you are not accepting it.

Please read the manual and follow the advice given there (for R-release 
in Section C.5), as Brian asked you already. If something is not clear 
enough, tell us what you do not understand.
Saying that it does not work if you do not follow the advice is not 
helpful at all for people who try to help!

Uwe Ligges



> --
> View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4191892.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Tue Dec 13 22:56:30 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 13 Dec 2011 16:56:30 -0500
Subject: [Rd] problems with iconv
In-Reply-To: <4EE7C608.9070906@statistik.tu-dortmund.de>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
Message-ID: <CAC2h7ut=ts1BBRAuTc=GTZJX286yw1g+7jMp-vjN4W-y4jEhYA@mail.gmail.com>

Roger,

Since Ripley is usually right, if I was you, I would focus on

"You need to ensure that GNU libiconv is actually used: you are
obviously not finding it, and I suspect your error is in not setting
the path to its header file."

Based on your description

"I've downloaded and compiled iconv versions 1.13 and 1.14  -
libiconv.so.2.5.0 and libiconv.so.2.5.1 and copied the iconv all over,
replacing the native iconv on my Solaris machine."

I would guess you have not copied over the header files.  Although
that is really hard to guess since you don't provide any details.  It
certainly sounds like you have done some hacking.

I agree that it can sometimes be bewildering to figure out which
library gets picked up from the output ... but the way configure works
on R is the same as for almost all other unix tools.  And you can see
the compiler command on the command line.

Kasper

2011/12/13 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
> Please cite the original messages!
>
>
>
> On 13.12.2011 21:32, RogerP wrote:
>>
>> As I said in my email: help I appreciate - sarcasm not so much.
>>
>> I re-read the manual - just in case I'd missed something and still do not
>> have any idea. ?The manual, BTW, needs some serious help for it to be
>> useful
>> to its intended audiance - people who don't already know how to install R.
>> For example, too many times example are given as to what changes to make,
>> but oh, there is no mention of where to make the changes. ?It is assumed
>> that the reader knows where to make the changes.
>
>
> Where are the patches to improve that?
>
>
>
>> Anyway, configure states that if found the iconv header - iconv.h, which i
>> put in the includes directory. ?It says it finds iconv - though it does
>> not
>> say where.
>>
>> Anyone with some useful help?
>
>
> You altready got useful help but you are not accepting it.
>
> Please read the manual and follow the advice given there (for R-release in
> Section C.5), as Brian asked you already. If something is not clear enough,
> tell us what you do not understand.
> Saying that it does not work if you do not follow the advice is not helpful
> at all for people who try to help!
>
> Uwe Ligges
>
>
>
>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4191892.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Tue Dec 13 22:58:20 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 13 Dec 2011 13:58:20 -0800
Subject: [Rd] paste0 bug in install.packages() - leopard installer?
Message-ID: <CAF42j22ZissJav4xpBWpNiUkU_N1YEHbBZaqgsdc5FWz4KcQ5Q@mail.gmail.com>

Hello,

I get the following:

> install.packages("abind", repos="http://cran.fhcrc.org", type="source")
trying URL 'http://cran.fhcrc.org/src/contrib/abind_1.4-0.tar.gz'
Content type 'application/x-gzip' length 19642 bytes (19 Kb)
opened URL
==================================================
downloaded 19 Kb

* installing *source* package 'abind' ...
** package 'abind' successfully unpacked and MD5 sums checked
** R
** preparing package for lazy loading
** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded
*** arch - i386
*** arch - ppc
Error in paste0("(^|[^%])(%%)*%", spec) : not a BUILTIN function
Calls: Sys.setenv -> .expand_R_libs_env_var -> expand -> gsub -> paste0
Execution halted
*** arch - x86_64
ERROR: loading failed for 'ppc'
* removing '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/abind'

The downloaded packages are in
	'/private/tmp/RtmpiZoTMy/downloaded_packages'
Warning message:
In install.packages("abind", repos = "http://cran.fhcrc.org", type = "source") :
  installation of package 'abind' had non-zero exit status

This is with a clean install of the R-devel package installer from
http://r.research.att.com (sessionInfo() below).  It only seems to be
triggered by the type="source" flag.
I think the problem may be with the installer, as this problem does
not occur with the same revision of R-devel built from source on the
same machine.
Incidentally, this problem doesn't occur with R-devel installed via
the installer on a Lion machine but does occur on two different
Leopard machines.

sessionInfo()
R Under development (unstable) (2011-12-12 r57875)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.0

Thanks,
Dan


From hpages at fhcrc.org  Wed Dec 14 00:41:12 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 13 Dec 2011 15:41:12 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE35E4E.6050703@gmail.com>
References: <4EE25637.1020404@fhcrc.org> <4EE2640D.3030402@gmail.com>
	<4EE280A7.3000204@fhcrc.org> <4EE35E4E.6050703@gmail.com>
Message-ID: <4EE7E298.1040107@fhcrc.org>

Hi Duncan,

On 11-12-10 05:27 AM, Duncan Murdoch wrote:
> On 11-12-09 4:41 PM, Herv? Pag?s wrote:
>> Hi Duncan,
>>
>> On 11-12-09 11:39 AM, Duncan Murdoch wrote:
>>> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>>>> Hi,
>>>>
>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>>
>>>> This is correct:
>>>>
>>>>> sum(as.double(x))
>>>> [1] 0
>>>>
>>>> This is not:
>>>>
>>>>> sum(x)
>>>> [1] 4996000
>>>>
>>>> Returning NA (with a warning) would also be acceptable for the latter.
>>>> That would make it consistent with cumsum(x):
>>>>
>>>>> cumsum(x)[length(x)]
>>>> [1] NA
>>>> Warning message:
>>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>
>>> This is a 64 bit problem; in 32 bits things work out properly.
>>> I'd guess
>>> in 64 bit arithmetic we or the run-time are doing something to simulate
>>> 32 bit arithmetic (since integers are 32 bits), but it looks as though
>>> we're not quite getting it right.
>>
>> It doesn't work properly for me on Leopard (32-bit mode):
>>
>> > x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>> > sum(as.double(x))
>> [1] 0
>> > sum(x)
>> [1] 4996000
>> > sessionInfo()
>> R version 2.14.0 RC (2011-10-27 r57452)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> It looks like the problem is that isum() (in src/main/summary.c)
>> uses a 'double' internally to do the sum, whereas rsum() and csum()
>> use a 'long double'.
>
> A double has 53 bits to store the mantissa, so any 32 bit integer can be
> stored exactly.
>
>>
>> Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
>> will always be the same (probably fine) and that TRUE values in the
>> input vector are always represented as a 1 (not so sure about this one).
>>
>> A more fundamental question: is switching back and forth between
>> 'int' and 'double' (or 'long double') the right thing to do for doing
>> "safe" arithmetic on integers?
>
> If you have enough terms in the sum that an intermediate value exceeds
> 53 bits in length, then you'll get the wrong answer, because the
> intermediate sum can't be stored exactly. That happens in your example.
> On the 32 bit platform I tested (Windows 32 bit), intermediate values
> are stored in registers with 64 bit precision, which is probably why
> Windows 32 bit gets it right, but various other platforms don't.
>
> On your fundamental question: I think the answer is that R is doing the
> right thing. R doesn't think of an integer as a particular
> representation, it thinks of it as a number. So if you ask for the sum
> of those numbers, R should return its best approximation to that sum,
> and it does.

It does, really? Seems like returning 0 would be a better approximation
;-) And with the argument that "R doesn't think of an integer as a
particular representation" then there is no reason why sum(x)
would get it wrong and sum(as.double(x)) would get it right. Also why
bother having an integer type in R?

Seriously, I completely disagree with your view (hopefully it's only
yours, and not an R "feature") that it's ok for integer arithmetic to
return an approximation. It should always return the correct value or
fail. This is one of the reasons why programmers use integers and not
floating point numbers (memory usage being another one). Integers are
used for indexing elements in an array or for shifting pointers at the
C-level. The idea that integer arithmetic can be approximate is scary.

Cheers,
H.

>
> A different approach would be to do the sum in 32 bit registers and
> detect 32 bit overflow in intermediate results. But that's a very
> hardware-oriented approach, rather than a mathematical approach.
>
> Duncan Murdoch
>
>> Thanks!
>> H.
>>
>>
>>>
>>> Duncan Murdoch
>>>
>>>> Thanks!
>>>> H.
>>>>
>>>>> sessionInfo()
>>>> R version 2.14.0 (2011-10-31)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C
>>>> [3] LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8
>>>> [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8
>>>> [7] LC_PAPER=C LC_NAME=C
>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>
>>
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Wed Dec 14 01:09:00 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 13 Dec 2011 16:09:00 -0800
Subject: [Rd] warning for inefficiently compressed datasets
In-Reply-To: <4EDF2500.3010801@statistik.tu-dortmund.de>
References: <4EDE9724.3080604@fhcrc.org>
	<4EDF2500.3010801@statistik.tu-dortmund.de>
Message-ID: <4EE7E91C.8000904@fhcrc.org>

Hi Uwe,

On 11-12-07 12:34 AM, Uwe Ligges wrote:
>
>
> On 06.12.2011 23:28, Herv? Pag?s wrote:
>> Hi,
>>
>> Recently added to doc/NEWS.Rd:
>>
>> 'R CMD check' now gives a warning rather than a note if it finds
>> inefficiently compressed datasets. With 'bzip2' and 'xz' compression
>> having been available since R 2.10.0, there is no excuse for not
>> using them.
>>
>> Why isn't a note enough for this?
>>
>> Generally speaking, warnings are for things that are dangerous,
>> or unsafe, or unportable, or for anything that could potentially
>> cause trouble. I don't see how using gzip instead of bzip2 or xz
>> could fall into that category (and BTW gzip is the default for
>> save() and for 'R CMD build' resave-data feature).
>>
>> The problem is that bzip2 and xz compressions are slower and also
>> require more memory than gzip. Bioconductor has big data packages
>> and sometimes it makes sense to use gzip and not bzip2 or xz. For
>> example, when loading Human chromosome 1 from disk, bzip2 and xz
>> are 7 and 3.4 times slower than gzip, respectively:
>>
>> > system.time(load("chr1-gzip.rda"))
>> user system elapsed
>> 1.210 0.180 1.384
>>
>> > system.time(load("chr1-bzip2.rda"))
>> user system elapsed
>> 9.500 0.160 9.674
>>
>> > system.time(load("chr1-xz.rda"))
>> user system elapsed
>> 4.46 0.20 4.69
>>
>> hpages at latitude:~/testing$ ls -lhtr chr1-*.rda
>> -rw-r--r-- 1 hpages hpages 61M 2011-12-06 12:13 chr1-gzip.rda
>> -rw-r--r-- 1 hpages hpages 55M 2011-12-06 12:15 chr1-bzip2.rda
>> -rw-r--r-- 1 hpages hpages 49M 2011-12-06 12:25 chr1-xz.rda
>>
>> This is with R-2.14.0 on a 64-bit Ubuntu laptop with 8GB of RAM.
>>
>> The size on disk doesn't really matter and it doesn't matter either
>> that the source tarball for the full Human genome ends up being 20%
>> bigger when using gzip instead of xz: the 20% extra time it takes to
>> download it (which needs to be done only once) will largely be
>> compensated by the fact that most analyses will run faster e.g. in
>> 40-45 sec. instead of more than 2 minutes (for many short analyses,
>> loading the chromosomes into memory is the bottleneck).
>
>
> Oh, from a European side this 20% extra time may be an hour when
> downloading from the BioC master rather than a mirror.

I guess that's why we have mirrors.

> And space and traffic is an issue for CRAN.
>
>
>
>> Is there a way to turn this warning off? If not, could an option be
>> added to 'R CMD check' to turn this warning off? Something along the
>> lines of the --no-resave-data option for 'R CMD build'.
>
>
> The manual tells us:
>
> "The following environment variables can be used to customize the
> operation of check: a convenient place to set these is the file
> ?~/.R/check.Renviron?.

Ah I see, this is in the "R Internals" manual. Good to know.

>
> [...]
>
> _R_CHECK_COMPACT_DATA2_
>
> If true, check data for ascii and uncompressed saves, and also check if
> using bzip2 or xz compression would be significantly better. Implies
> _R_CHECK_COMPACT_DATA_ is true. Default: true."

Not with current R-devel: _R_CHECK_COMPACT_DATA2_ is gone (has been 
merged with _R_CHECK_COMPACT_DATA_).
I guess we could always use _R_CHECK_COMPACT_DATA_ to turn this off
but that would mean we also turn off checking data for ascii and
uncompressed saves...

Thanks,
H.

>
>
> Uwe
>
>
>
>>
>> Thanks,
>> H.
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From rpickeri at mail.nih.gov  Tue Dec 13 23:10:12 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Tue, 13 Dec 2011 14:10:12 -0800 (PST)
Subject: [Rd] problems with iconv
In-Reply-To: <4EE7C608.9070906@statistik.tu-dortmund.de>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
Message-ID: <1323814212607-4192313.post@n4.nabble.com>

Sorry, but IMHO saying "read the manual" does not constitute actual help.

But here it is from the manual:

A suitably comprehensive iconv function is essential. The R usage requires
iconv to be able to translate between "latin1" and "UTF-8", to recognize ""
(as the current encoding) and "ASCII", and to translate to and from the
Unicode wide-character formats "UCS-[24][BL]E" ? this is true for glibc but
not of most commercial Unixes. However, you can make use of GNU libiconv
(possibly as a plug-in replacement: see
http://www.gnu.org/software/libiconv/). 

Well, that's just what I did.  I downloaded libiconv and compiled and linked
it.  Oh, so where to put it.  Hmmmm, don't see it anywhere here.  Do you?  

Also from the manual:

/You will need GNU libiconv and readline: the Solaris version of iconv is
not sufficiently powerful. 

For the Solaris Studio compilers a little juggling of paths was needed to
ensure GNU libiconv (in /usr/local) was used rather than the Solaris iconv:

     CC="cc -xc99"
     CFLAGS="-O -xlibmieee"
     F77=f95
     FFLAGS=-O4
     CXX="CC -library=stlport4"
     CXXFLAGS=-O
     FC=f95
     FCFLAGS=$FFLAGS
     FCLIBS="-lfai -lfsu"
     R_LD_LIBRARY_PATH="/usr/local/lib:/opt/csw/gcc4/lib:/opt/csw/lib"

For a 64-bit target add -m64 to the compiler macros and use something like
LDFLAGS=-L/usr/local/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 as
appropriate. /

Well, I did that. Here are some of my options from the config.site:

CC="cc"

## Debugging and optimization options for the C compiler.
## Use this to specify CFLAGS for the version of the C compiler
## specified above.
## If unspecified, defaults to '-g -O2' for gcc, 
## and '-g' in all other cases except icc (for which see R-admin.html).
#CFLAGS="-xlibmieee"
CFLAGS="-xO5 -xc99 -xlibmieee -xlibmil -nofstore -xtarget=native -m64"

FFLAGS="-xO5 -libmil -m64"

## Options for safe compilation under the FORTRAN 77 compiler.
## Use this to specify FFLAGS for the version of the compiler specified
## above, using as accurate a result as possible, e.g. no optimization
## or using -ffloat-store.
SAFE_FFLAGS="-xO5 -libmil"

CXX="CC -library=stlport4"

## Options for the C++ compiler.
CXXFLAGS="-xO5 -xlibmil -nofstore -features=tmplrefstatic"

## Any special flags which must be used when compiling C++ code to be
## turned into a shared object.  If this variable is left unspecified
## an attempt is made to automatically detect the correct value.
CXXPICFLAGS=-Kpic

LDFLAGS=-L/opt/sunstudio12.1/lib/amd64
SHLIB_LDFLAGS=-shared
SHLIB_CXXLDFLAGS=-G
SHLIB_FCLDFLAGS=-G

## The command to be used to load shared objects which contain object
## files from the C++ compiler.  This is usually the C++ compiler/linker,
## but the automatic choice can be overridden by means of this
## variable.
## SHLIB_CXXLD=

## Any special flags which are required when creating shared objects
## containing object files from a C++ compiler.  This is usually
## automatically detected by configure, and anything set here will be in
## addition unless SHLIB_CXXLD is given.
## SHLIB_CXXLDFLAGS=


## FORTRAN 95 compiler: optional for use in packages.
## Analogous to the F77 and CXX settings.
FC=f95
FCFLAGS=$FFLAGS
FCPICFLAGS=-Kpic
SHLIB_FCLD=${FC}
## Unlike SHLIB_CXXLDFLAGS, SHLIB_FCLDFLAGS is never additional
SHLIB_FCLDFLAGS=${SHLIB_LDFLAGS}
## Additional libraries needed to link a shared object, e.g. on x86 Solaris
FCLIBS="-lfai -lfai2 -lfsu"

## Tcl/Tk settings.
## Use TCLTK_LIBS for all '-L' and '-l' options needed for linking
## against the Tcl and Tk library.
## TCLTK_LIBS=
## Use TCLTK_CPPFLAGS for all '-I' options needed for finding the tcl.h
## and tk.h headers.
## TCLTK_CPPFLAGS=

## Browser default
## Default setting for the R_BROWSER env variable
## If unset configure searches in turn for (currently)
## firefox mozilla galeon opera xdg-open kfmclient gnome-moz-remote open
## and uses the full path.
## R_BROWSER=

## BLAS and LAPACK settings
## Use BLAS_LIBS for all '-L' and '-l' options needed for linking
## against an external BLAS implementation.
## BLAS_LIBS=
## Use LAPACK_LIBS for all '-L' and '-l' options needed for linking
## against an external LAPACK implementation.  
## Note that (see R-admin) that our main intention is to allow a
## LAPACK-containing BLAS to be used, so this is rarely needed, and
## it is not used if the BLAS already contains LAPACK.
LAPACK_LIBS=/opt/solstudio12.2/lib

## Make name.
## Set this if you want to use a make by another name.
## For example, if your GNU make is called 'gmake', use 'MAKE=gmake'.
## MAKE=

## Tar name
## Set this to prefer a tar which has the capability to automagically
## read compressed archives.  The default is to choose 'gtar' or
## 'gnutar'(normally GNU tar) then 'tar'.
## Note that 'bsdtar' (from the libarchive project) is known to create
## archives in a non-POSIX format that untar() cannot read,
## so should be avoided.
## TAR=

## Library path
## This is be default created from libraries added to LIBS.
## Allow user to override.
R_LD_LIBRARY_PATH="/usr/local/lib:/opt/csw/gcc4/lib:/opt/csw/lib"
READLINE_LIBS = /usr/local/lib
USE_NLS = no
AR_FLAGS=-crS
lt_AR_FLAGS=-crS
LIBICONV=/usr/local/lib

So, here it is - all the revelent documentation on iconv.  If I've missed
anything please let me know.  If you see where in the documentation I missed
some cryptic clue on how to get iconv to work or where to put it or it's
headers, also please let me know.  

One things for sure - you can't say I've not read the documentation!

Roger

--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4192313.html
Sent from the R devel mailing list archive at Nabble.com.


From jeffpollock9 at gmail.com  Wed Dec 14 00:48:17 2011
From: jeffpollock9 at gmail.com (Jeffrey Pollock)
Date: Tue, 13 Dec 2011 23:48:17 +0000
Subject: [Rd] Rcpp too good to be true?
Message-ID: <CAG992jLNc4BqmfR6C9ffep_3wrY16H1CuhXCbfm2LKroyX2JKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111213/56f24750/attachment.pl>

From murray at stokely.org  Wed Dec 14 01:24:07 2011
From: murray at stokely.org (Murray Stokely)
Date: Tue, 13 Dec 2011 16:24:07 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE25637.1020404@fhcrc.org>
References: <4EE25637.1020404@fhcrc.org>
Message-ID: <CAECWzi+1AOZMX5ZUKNLPc+MP2yiocAb8_NEm7x_1w6RMVt0+rQ@mail.gmail.com>

FYI, the new int64 package on CRAN gets this right, but is of course
somewhat slower since it is not doing hardware 64-bit arithmetic.

?x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
 library(int64)
 sum(as.int64(x))
# [1] 0

             - Murray

2011/12/9 Herv? Pag?s <hpages at fhcrc.org>:
> Hi,
>
> ?x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>
> This is correct:
>
> ?> sum(as.double(x))
> ?[1] 0
>
> This is not:
>
> ?> sum(x)
> ?[1] 4996000
>
> Returning NA (with a warning) would also be acceptable for the latter.
> That would make it consistent with cumsum(x):
>
> ?> cumsum(x)[length(x)]
> ?[1] NA
> ?Warning message:
> ?Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>
> Thanks!
> H.
>
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_CA.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_CA.UTF-8 ? ? ? ?LC_COLLATE=en_CA.UTF-8
> ?[5] LC_MONETARY=en_CA.UTF-8 ? ?LC_MESSAGES=en_CA.UTF-8
> ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone: ?(206) 667-5791
> Fax: ? ?(206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Wed Dec 14 01:52:48 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 13 Dec 2011 16:52:48 -0800
Subject: [Rd] Rcpp too good to be true?
In-Reply-To: <CAG992jLNc4BqmfR6C9ffep_3wrY16H1CuhXCbfm2LKroyX2JKw@mail.gmail.com>
References: <CAG992jLNc4BqmfR6C9ffep_3wrY16H1CuhXCbfm2LKroyX2JKw@mail.gmail.com>
Message-ID: <4EE7F360.9030901@fhcrc.org>

On 12/13/2011 03:48 PM, Jeffrey Pollock wrote:
> Hello all,
>
> I've been working on a package to do various things related to the
> Conway-Maxwell-Poisson distribution and wanted to be able to make fast
> random draws from the distribution. My R code was running quite slow so I
> decided to give Rcpp a bash. I had used it before but only for extremely
> basic stuff and always using inline. This time I decided to give making a
> proper package a go.
>
> First of all I should say that this was incredibly easy due to
> Rcpp.package.skeleton() and the countless answers to quesions online and
> documentation!
>
> Secondly, I'm worried that my speedup has been so massive (over 500x !!!)
> that I think I've made a mistake, hence my post here.
>
> Here is all my code, if someone has a minute to point out anything wrong
> (or even if its correct and there is room for improvement, im pretty new to
> this) it would be much appreciated. I've had a simple look at the results
> and they look fine, but seriously, 500x faster?!
>
> function in R;
> library(compiler)
>
> Rrcomp<- cmpfun(
>          function(n, lam, nu, max = 100L) {
>              ans<- integer(n)
>              dist<- dcomp(0:max, lam, nu, max)
>              u<- runif(n)
>              for (i in 1:n) {
>                  count<- 0L
>                  pr<- dist[1L]
>                  while (pr<  u[i]) {
>                      count<- count + 1L
>                      pr<- pr + dist[count + 1L]
>                  }
>                  ans[i]<- count
>              }
>              return(ans)
>          }
> )

Hi Jeff

Not really what you're asking about, but looks like you're sampling with 
replacement from the sequence 0:(dist-1) n times with probability dist, so

Rrcomp.1 <-
     function(n, lam, nu, max = 100L)
{
     dist <- dcomp(0:max, lam, nu, max)
     sample(seq_along(dist) - 1L, n, TRUE, prob=dist)
}

and

 > system.time(res <- table(Rrcomp(n, lam, nu))); res
    user  system elapsed
   1.493   0.000   1.495

    0    1    2    3    4    5    6    7    8    9   10   11   12   13
  355 1656 4070 6976 8745 8861 7275 5214 3357 1892  926  399  165   69
   14   15   16   17
   24   11    2    3
 > system.time(res <- table(Rrcomp.1(n, lam, nu))); res
    user  system elapsed
   0.029   0.000   0.028

    0    1    2    3    4    5    6    7    8    9   10   11   12   13
  333 1754 4096 6876 8964 8799 7399 5030 3215 1877  951  432  184   61
   14   15   16
   23    5    1

Martin

> dcomp<- function(y, lam, nu, max = 100L) {
>      Z<- function(lam, nu, max) {
>          sum<- 0L
>          for(i in 0L:max) {
>              sum<- sum + lam^i / factorial(i)^nu
>          }
>          return(sum)
>      }
>      return(lam^y / (factorial(y)^nu * Z(lam, nu, max)))
> }
>
> function in Rcpp;
> header file;
>
> #include<Rcpp.h>
>
> RcppExport SEXP rcomp(SEXP n_, SEXP dist_);
>
> source file;
>
> #include "rcomp.h"
>
> SEXP rcomp(SEXP n_, SEXP dist_) {
>      using namespace Rcpp ;
>
>      int n = as<int>(n_);
>      NumericVector dist(dist_);
>
>      NumericVector ans(n);
>      int count;
>      double pr;
>      RNGScope scope;
>      NumericVector u = runif(n);
>
>      for (int i = 0; i<  n; ++i) {
>          count = 0;
>          pr = dist[0];
>          while (pr<  u[i]) {
>              count++;
>              pr += dist[count];
>          }
>          ans[i] = count;
>      }
>      return ans;
> }
>
> R call;
>
> rcomp<- function(n, lam, nu, max = 100){
>      dist<- dcomp(0:max, lam, nu, max)
>      .Call("rcomp", n = n, dist = dist, PACKAGE = "glmcomp")
> }
>
> Here are some results;
>> n<- 50000
>> lam<- 5
>> nu<- 1
>> rbind(table(rcomp(n, lam, nu))[1:10] / n, table(Rrcomp(n, lam, nu))[1:10]
> / n, dpois(0:9, lam))
>                 0          1          2         3         4
> 5         6
> [1,] 0.006440000 0.03124000 0.08452000 0.1392200 0.1747800 0.1755200
> 0.1490000
> [2,] 0.006660000 0.03232000 0.08412000 0.1425400 0.1779600 0.1748400
> 0.1445600
> [3,] 0.006737947 0.03368973 0.08422434 0.1403739 0.1754674 0.1754674
> 0.1462228
>               7          8          9
> [1,] 0.1063000 0.06538000 0.03534000
> [2,] 0.1039800 0.06492000 0.03624000
> [3,] 0.1044449 0.06527804 0.03626558
>
> (for nu = 1 the com-poisson distribution is the same as normal poisson)
>
>> benchmark(rcomp(n, lam, nu), Rrcomp(n, lam, nu), replications = 10, order
> = "relative")
>                  test replications elapsed relative user.self sys.self
> 2 Rrcomp(n, lam, nu)           10    2.03   1.0000      1.96     0.00
> 1  rcomp(n, lam, nu)           10 1172.51 577.5911   1164.50     0.08
>
> Thanks in advance if anyone has any time to have a look at this :)
>
> Jeff
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From ted.harding at wlandres.net  Wed Dec 14 01:52:53 2011
From: ted.harding at wlandres.net ( (Ted Harding))
Date: Wed, 14 Dec 2011 00:52:53 -0000 (GMT)
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE7E298.1040107@fhcrc.org>
Message-ID: <XFMail.111214005253.ted.harding@wlandres.net>

[See at end]

On 13-Dec-11 23:41:12, Herv? Pag?s wrote:
> Hi Duncan,
> 
> On 11-12-10 05:27 AM, Duncan Murdoch wrote:
>> On 11-12-09 4:41 PM, Herv? Pag?s wrote:
>>> Hi Duncan,
>>>
>>> On 11-12-09 11:39 AM, Duncan Murdoch wrote:
>>>> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>>>>> Hi,
>>>>>
>>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>>>
>>>>> This is correct:
>>>>>
>>>>>> sum(as.double(x))
>>>>> [1] 0
>>>>>
>>>>> This is not:
>>>>>
>>>>>> sum(x)
>>>>> [1] 4996000
>>>>>
>>>>> Returning NA (with a warning) would also be acceptable for the
>>>>> latter.
>>>>> That would make it consistent with cumsum(x):
>>>>>
>>>>>> cumsum(x)[length(x)]
>>>>> [1] NA
>>>>> Warning message:
>>>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>>
>>>> This is a 64 bit problem; in 32 bits things work out properly.
>>>> I'd guess
>>>> in 64 bit arithmetic we or the run-time are doing something to
>>>> simulate
>>>> 32 bit arithmetic (since integers are 32 bits), but it looks as
>>>> though
>>>> we're not quite getting it right.
>>>
>>> It doesn't work properly for me on Leopard (32-bit mode):
>>>
>>> > x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>> > sum(as.double(x))
>>> [1] 0
>>> > sum(x)
>>> [1] 4996000
>>> > sessionInfo()
>>> R version 2.14.0 RC (2011-10-27 r57452)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> It looks like the problem is that isum() (in src/main/summary.c)
>>> uses a 'double' internally to do the sum, whereas rsum() and csum()
>>> use a 'long double'.
>>
>> A double has 53 bits to store the mantissa, so any 32 bit integer can
>> be
>> stored exactly.
>>
>>>
>>> Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
>>> will always be the same (probably fine) and that TRUE values in the
>>> input vector are always represented as a 1 (not so sure about this
>>> one).
>>>
>>> A more fundamental question: is switching back and forth between
>>> 'int' and 'double' (or 'long double') the right thing to do for doing
>>> "safe" arithmetic on integers?
>>
>> If you have enough terms in the sum that an intermediate value exceeds
>> 53 bits in length, then you'll get the wrong answer, because the
>> intermediate sum can't be stored exactly. That happens in your
>> example.
>> On the 32 bit platform I tested (Windows 32 bit), intermediate values
>> are stored in registers with 64 bit precision, which is probably why
>> Windows 32 bit gets it right, but various other platforms don't.
>>
>> On your fundamental question: I think the answer is that R is doing
>> the
>> right thing. R doesn't think of an integer as a particular
>> representation, it thinks of it as a number. So if you ask for the sum
>> of those numbers, R should return its best approximation to that sum,
>> and it does.
> 
> It does, really? Seems like returning 0 would be a better approximation
> ;-) And with the argument that "R doesn't think of an integer as a
> particular representation" then there is no reason why sum(x)
> would get it wrong and sum(as.double(x)) would get it right. Also why
> bother having an integer type in R?
> 
> Seriously, I completely disagree with your view (hopefully it's only
> yours, and not an R "feature") that it's ok for integer arithmetic to
> return an approximation. It should always return the correct value or
> fail. This is one of the reasons why programmers use integers and not
> floating point numbers (memory usage being another one). Integers are
> used for indexing elements in an array or for shifting pointers at the
> C-level. The idea that integer arithmetic can be approximate is scary.
> 
> Cheers,
> H.
> Herv? Pag?s
> [...]

The approximation is inevitable, even for integers, if the
integers are large enough.

The number of particles in the Universe is believed to be
around 10^80 (estimates vary from 10^72 to 10^87). If we
could use each particle as a binary element in storage
(e.g. using positive and negative spin as 1 or 0) then
the largest integer that could be stored in the entire
Universe would be about 2^(10^80). A huge number, of course,
but it is the limit of what is possible.

Now, to do arithmetic with integers, you need to store two
ort more integers, thus at least halving the power of 2.
Then you need a computer to do the computation, and you
won't have room for that in the Universe unless you cut
down on the largest integer.

So, in real life (whatever Mathematics may say), you can't
expect arbitrary integer arithmetic.

Now, computer programs for numerical computation can broadly
be divided into two types.

In one, "arbitrary precision" is available: you can tell
the program how many decimal digits you want it to work to.
An example of this is 'bc':

  http://en.wikipedia.org/wiki/Bc_programming_language

You can set as many decimal ditgits as you like, *provided*
they fall within the storage capacity of your computer, for
which an upper bound is the storage capacity of the Universe
(see above). For integers and results which surpass the
decimal places you have set, the result will be an approximation.
Inevitably.

In the other type, the program is written so as to embody
integers to a fixed maximum number of decimal (or binary)
digits. An example of this is R (and most other numerical
programs). This may be 32 bits or 64 bits. Any result ot
computation which involve smore than this numer of bits
is inevitably an approximation.

Provided the user is aware of this, there is no need for
your "It should always return the correct value or fail."
It will return the correct value if the integers are not
too large; otherwise it will retuirn the best approximation
that it can cope with in the fixed finite storage space
for which it has been programmed.

There is an implcit element of the arbitrary in this. You
can install 32-bit R on a 64-bit-capable machine, or a
64-bit version. You could re-program R so that it can
work to, say, 128 bits or 256 bits even on a 32-bit machine
(using techniques like those that underlie 'bc'), but
that would be an arbitrary choice. However, the essential
point is that some choice is unavoidable, since if you push
it too far the Universe will run out of particles -- and the
computer industry will run out of transistors long before
you hit the Universe limit!

So you just have to accept the limits. Provided you are aware
of the approximations which may set in at some point, you can
cope with the consequences, so long as you take account of
some concept of "adequacy" in the inevitable approximations.
Simply to "fail" is far too unsophisticated a result!

Hoping this is useful,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at wlandres.net>
Fax-to-email: +44 (0)870 094 0861
Date: 14-Dec-11                                       Time: 00:52:49
------------------------------ XFMail ------------------------------


From josh.m.ulrich at gmail.com  Wed Dec 14 02:37:59 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 13 Dec 2011 19:37:59 -0600
Subject: [Rd] problems with iconv
In-Reply-To: <1323814212607-4192313.post@n4.nabble.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
Message-ID: <CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>

As Uwe asked, please cite the original messages.

On Tue, Dec 13, 2011 at 4:10 PM, RogerP <rpickeri at mail.nih.gov> wrote:
> Sorry, but IMHO saying "read the manual" does not constitute actual help.
>
> But here it is from the manual:
>
> A suitably comprehensive iconv function is essential. The R usage requires
> iconv to be able to translate between "latin1" and "UTF-8", to recognize ""
> (as the current encoding) and "ASCII", and to translate to and from the
> Unicode wide-character formats "UCS-[24][BL]E" ? this is true for glibc but
> not of most commercial Unixes. However, you can make use of GNU libiconv
> (possibly as a plug-in replacement: see
> http://www.gnu.org/software/libiconv/).
>
> Well, that's just what I did. ?I downloaded libiconv and compiled and linked
> it. ?Oh, so where to put it. ?Hmmmm, don't see it anywhere here. ?Do you?
>
The location isn't mentioned in Appendix A, which you cite a portion
of above, but it is mentioned in Solaris section of Appendix C, which
you cite below.

> Also from the manual:
>
> /You will need GNU libiconv and readline: the Solaris version of iconv is
> not sufficiently powerful.
>
> For the Solaris Studio compilers a little juggling of paths was needed to
> ensure GNU libiconv (in /usr/local) was used rather than the Solaris iconv:
>
This seems to indicate GNU libiconv should be installed in /usr/local,
which is the location specified in the libiconv installation
instructions:

As usual for GNU packages:
$ ./configure --prefix=/usr/local
$ make
$ make install

Did you try the suggestion two paragraphs above this in Appendix C?
"Some people have reported that the Solaris libintl needs to be
avoided, for example by using --disable-nls or --with-included-gettext
or using libintl from OpenCSW."

> ? ? CC="cc -xc99"
> ? ? CFLAGS="-O -xlibmieee"
> ? ? F77=f95
> ? ? FFLAGS=-O4
> ? ? CXX="CC -library=stlport4"
> ? ? CXXFLAGS=-O
> ? ? FC=f95
> ? ? FCFLAGS=$FFLAGS
> ? ? FCLIBS="-lfai -lfsu"
> ? ? R_LD_LIBRARY_PATH="/usr/local/lib:/opt/csw/gcc4/lib:/opt/csw/lib"
>
> For a 64-bit target add -m64 to the compiler macros and use something like
> LDFLAGS=-L/usr/local/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 as
> appropriate. /
>
> Well, I did that. Here are some of my options from the config.site:
>
<snip>
>
> So, here it is - all the revelent documentation on iconv. ?If I've missed
> anything please let me know. ?If you see where in the documentation I missed
> some cryptic clue on how to get iconv to work or where to put it or it's
> headers, also please let me know.
>
Did you take the steps required to resolve the circular dependency
between libiconv and gettext?

> One things for sure - you can't say I've not read the documentation!
>
> Roger
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From hpages at fhcrc.org  Wed Dec 14 02:43:47 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 13 Dec 2011 17:43:47 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <XFMail.111214005253.ted.harding@wlandres.net>
References: <XFMail.111214005253.ted.harding@wlandres.net>
Message-ID: <4EE7FF53.3050707@fhcrc.org>

Hi Ted,

On 11-12-13 04:52 PM, (Ted Harding) wrote:
[...]
> Now, computer programs for numerical computation can broadly
> be divided into two types.
>
> In one, "arbitrary precision" is available: you can tell
> the program how many decimal digits you want it to work to.
> An example of this is 'bc':
>
>    http://en.wikipedia.org/wiki/Bc_programming_language
>
> You can set as many decimal ditgits as you like, *provided*
> they fall within the storage capacity of your computer, for
> which an upper bound is the storage capacity of the Universe
> (see above). For integers and results which surpass the
> decimal places you have set, the result will be an approximation.
> Inevitably.

AFAICT, with bc and other tools doing arithmetic on arbitrary large
integers, operations like +, -, *, ^ etc either give the exact answer
or they fail. That's the beauty of those tools. Otherwise you could
call them "pointless" or "broken".

Arbitrary-precision vs fixed-precision is slightly off topics though.
In particular I didn't suggest that doing sum() on an integer vector
should use arbitrary large integers internally to do the computation.

Cheers,
H.

>
> In the other type, the program is written so as to embody
> integers to a fixed maximum number of decimal (or binary)
> digits. An example of this is R (and most other numerical
> programs). This may be 32 bits or 64 bits. Any result ot
> computation which involve smore than this numer of bits
> is inevitably an approximation.
>
> Provided the user is aware of this, there is no need for
> your "It should always return the correct value or fail."
> It will return the correct value if the integers are not
> too large; otherwise it will retuirn the best approximation
> that it can cope with in the fixed finite storage space
> for which it has been programmed.
>
> There is an implcit element of the arbitrary in this. You
> can install 32-bit R on a 64-bit-capable machine, or a
> 64-bit version. You could re-program R so that it can
> work to, say, 128 bits or 256 bits even on a 32-bit machine
> (using techniques like those that underlie 'bc'), but
> that would be an arbitrary choice. However, the essential
> point is that some choice is unavoidable, since if you push
> it too far the Universe will run out of particles -- and the
> computer industry will run out of transistors long before
> you hit the Universe limit!
>
> So you just have to accept the limits. Provided you are aware
> of the approximations which may set in at some point, you can
> cope with the consequences, so long as you take account of
> some concept of "adequacy" in the inevitable approximations.
> Simply to "fail" is far too unsophisticated a result!
>
> Hoping this is useful,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding)<ted.harding at wlandres.net>
> Fax-to-email: +44 (0)870 094 0861
> Date: 14-Dec-11                                       Time: 00:52:49
> ------------------------------ XFMail ------------------------------


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jeffpollock9 at gmail.com  Wed Dec 14 02:07:55 2011
From: jeffpollock9 at gmail.com (Jeffrey Pollock)
Date: Wed, 14 Dec 2011 01:07:55 +0000
Subject: [Rd] Rcpp too good to be true?
In-Reply-To: <4EE7F360.9030901@fhcrc.org>
References: <CAG992jLNc4BqmfR6C9ffep_3wrY16H1CuhXCbfm2LKroyX2JKw@mail.gmail.com>
	<4EE7F360.9030901@fhcrc.org>
Message-ID: <CAG992jLnn_FgFwjFwdExUHfCy2n=ni5_St7LvFrahhSoQwqgsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111214/2b44669d/attachment.pl>

From pauljohn32 at gmail.com  Wed Dec 14 07:30:33 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 14 Dec 2011 00:30:33 -0600
Subject: [Rd] termplot & predict.lm. some details about calculating
 predicted values with "other variables set at the mean"
Message-ID: <CAErODj9jKBLgSUfk4xX7VnnM_svrcaqJ9v8NxOC6oN2WpOJjGw@mail.gmail.com>

I'm making some functions to illustrate regressions and I have been
staring at termplot and predict.lm and residuals.lm to see how this is
done. I've wondered who wrote predict.lm originally, because I think
it is very clever.

I got interested because termplot doesn't work with interactive models:

> m1 <- lm(y ~ x1*x2)
> termplot(m1)
Error in `[.data.frame`(mf, , i) : undefined columns selected

Digging into that, I realized some surprising implications of
nonlinear formulas.

This issue arises when there are math functions in the regression
formula. The question focuses on what we mean by the mean of "x" when
we are discussing predictions and deviations.

Suppose one fits:

m1 <- lm (y ~ x1 + log(x2), data=dat)

I had thought the partial residual was calculated with reference to
the log of the mean of x2. But that's not right. It is calculated with
reference to mean(log(x2)). That seems misleading, termplot shows a
graph illustrating the effect of x2 on the horizontal axis (not
"log(x2)").  I should not say misleading.  Rather, it is unexpected.
I think users who want the reference value in the plot of x2 to be the
mean of x2 have a legitimate concern here.

With a more elaborate formula, the mismatch gets more confusing.
Suppose the regression formula is

m2 <- lm (y ~ x1 + poly(x2,3), data=dat)

The model frame has these variables:

  y        x1 poly(x2, 3).1 poly(x2, 3).2 poly(x2, 3).3

and the partial residual calculation for variable x1, which I had
expected would be based on a polynomial transformation of mean(x2), is
the weighted sum of the means of the 3 polys.

Can you help me see this more clearly?  (Or less wrongly?)

Perhaps you think I don't understand partial residuals in termplot,
but I am pretty sure I do.  I made notes about it. See slides 54 and
55 in here: http://pj.freefaculty.org/guides/Rcourse/regression-tableAndPlot-1/regression-tableAndPlot.pdf

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From pauljohn32 at gmail.com  Wed Dec 14 07:39:41 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 14 Dec 2011 00:39:41 -0600
Subject: [Rd] termplot & predict.lm. some details about calculating
 predicted values with "other variables set at the mean"
Message-ID: <CAErODj8FKiUhpAH7-D1mKpfyQgegBCJpLbPg3zteUALrK3vM9Q@mail.gmail.com>

I'm making some functions to illustrate regressions and I have been
staring at termplot and predict.lm and residuals.lm to see how this is
done. I've wondered who wrote predict.lm originally, because I think
it is very clever.

I got interested because termplot doesn't work with interactive models:

> m1 <- lm(y ~ x1*x2)
> termplot(m1)
Error in `[.data.frame`(mf, , i) : undefined columns selected

Digging into that, I realized some surprising implications of
nonlinear formulas.

This issue arises when there are math functions in the regression
formula. The question focuses on what we mean by the mean of "x" when
we are discussing predictions and deviations.

Suppose one fits:

m1 <- lm (y ~ x1 + log(x2), data=dat)

I had thought the partial residual was calculated with reference to
the log of the mean of x2. But that's not right. It is calculated with
reference to mean(log(x2)). That seems misleading, termplot shows a
graph illustrating the effect of x2 on the horizontal axis (not
"log(x2)").  I should not say misleading.  Rather, it is unexpected.
I think users who want the reference value in the plot of x2 to be the
mean of x2 have a legitimate concern here.

With a more elaborate formula, the mismatch gets more confusing.
Suppose the regression formula is

m2 <- lm (y ~ x1 + poly(x2,3), data=dat)

The model frame has these variables:

  y        x1 poly(x2, 3).1 poly(x2, 3).2 poly(x2, 3).3

and the partial residual calculation for variable x1, which I had
expected would be based on a polynomial transformation of mean(x2), is
the weighted sum of the means of the 3 polys.

Can you help me see this more clearly?  (Or less wrongly?)

Perhaps you think I don't understand partial residuals in termplot,
but I am pretty sure I do.  I made notes about it. See slides 54 and
55 in here: http://pj.freefaculty.org/guides/Rcourse/regression-tableAndPlot-1/regression-tableAndPlot.pdf

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From murdoch.duncan at gmail.com  Wed Dec 14 12:57:06 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Dec 2011 06:57:06 -0500
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE7E298.1040107@fhcrc.org>
References: <4EE25637.1020404@fhcrc.org> <4EE2640D.3030402@gmail.com>
	<4EE280A7.3000204@fhcrc.org> <4EE35E4E.6050703@gmail.com>
	<4EE7E298.1040107@fhcrc.org>
Message-ID: <4EE88F12.3050509@gmail.com>

On 11-12-13 6:41 PM, Herv? Pag?s wrote:
> Hi Duncan,
>
> On 11-12-10 05:27 AM, Duncan Murdoch wrote:
>> On 11-12-09 4:41 PM, Herv? Pag?s wrote:
>>> Hi Duncan,
>>>
>>> On 11-12-09 11:39 AM, Duncan Murdoch wrote:
>>>> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>>>>> Hi,
>>>>>
>>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>>>
>>>>> This is correct:
>>>>>
>>>>>> sum(as.double(x))
>>>>> [1] 0
>>>>>
>>>>> This is not:
>>>>>
>>>>>> sum(x)
>>>>> [1] 4996000
>>>>>
>>>>> Returning NA (with a warning) would also be acceptable for the latter.
>>>>> That would make it consistent with cumsum(x):
>>>>>
>>>>>> cumsum(x)[length(x)]
>>>>> [1] NA
>>>>> Warning message:
>>>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>>
>>>> This is a 64 bit problem; in 32 bits things work out properly.
>>>> I'd guess
>>>> in 64 bit arithmetic we or the run-time are doing something to simulate
>>>> 32 bit arithmetic (since integers are 32 bits), but it looks as though
>>>> we're not quite getting it right.
>>>
>>> It doesn't work properly for me on Leopard (32-bit mode):
>>>
>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>> sum(as.double(x))
>>> [1] 0
>>>> sum(x)
>>> [1] 4996000
>>>> sessionInfo()
>>> R version 2.14.0 RC (2011-10-27 r57452)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>
>>> locale:
>>> [1] C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> It looks like the problem is that isum() (in src/main/summary.c)
>>> uses a 'double' internally to do the sum, whereas rsum() and csum()
>>> use a 'long double'.
>>
>> A double has 53 bits to store the mantissa, so any 32 bit integer can be
>> stored exactly.
>>
>>>
>>> Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
>>> will always be the same (probably fine) and that TRUE values in the
>>> input vector are always represented as a 1 (not so sure about this one).
>>>
>>> A more fundamental question: is switching back and forth between
>>> 'int' and 'double' (or 'long double') the right thing to do for doing
>>> "safe" arithmetic on integers?
>>
>> If you have enough terms in the sum that an intermediate value exceeds
>> 53 bits in length, then you'll get the wrong answer, because the
>> intermediate sum can't be stored exactly. That happens in your example.
>> On the 32 bit platform I tested (Windows 32 bit), intermediate values
>> are stored in registers with 64 bit precision, which is probably why
>> Windows 32 bit gets it right, but various other platforms don't.
>>
>> On your fundamental question: I think the answer is that R is doing the
>> right thing. R doesn't think of an integer as a particular
>> representation, it thinks of it as a number. So if you ask for the sum
>> of those numbers, R should return its best approximation to that sum,
>> and it does.
>
> It does, really? Seems like returning 0 would be a better approximation
> ;-) And with the argument that "R doesn't think of an integer as a
> particular representation" then there is no reason why sum(x)
> would get it wrong and sum(as.double(x)) would get it right. Also why
> bother having an integer type in R?
>
> Seriously, I completely disagree with your view (hopefully it's only
> yours, and not an R "feature") that it's ok for integer arithmetic to
> return an approximation. It should always return the correct value or
> fail.

I think you need to be more specific in your design, because the function

`+` <- function(x,y) stop("fail")

meets your specs.  I think the following requirements are all desirable, 
but I don't think they can all be met at the same time:

1.  Return the exactly correct answer in all (or even nearly all) of the 
cases where the current code returns the correct answer.

2.  Do it as quickly (or nearly as quickly) as the current code.

3.  Do it without requiring much more memory than the current code does.

4.  Never return an incorrect answer.

If you think I'm wrong, show me.

Duncan Murdoch

This is one of the reasons why programmers use integers and not
> floating point numbers (memory usage being another one). Integers are
> used for indexing elements in an array or for shifting pointers at the
> C-level. The idea that integer arithmetic can be approximate is scary.
>
> Cheers,
> H.
>
>>
>> A different approach would be to do the sum in 32 bit registers and
>> detect 32 bit overflow in intermediate results. But that's a very
>> hardware-oriented approach, rather than a mathematical approach.
>>
>> Duncan Murdoch
>>
>>> Thanks!
>>> H.
>>>
>>>
>>>>
>>>> Duncan Murdoch
>>>>
>>>>> Thanks!
>>>>> H.
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.14.0 (2011-10-31)
>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C
>>>>> [3] LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8
>>>>> [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8
>>>>> [7] LC_PAPER=C LC_NAME=C
>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>
>>>>
>>>
>>>
>>
>
>


From rpickeri at mail.nih.gov  Wed Dec 14 15:15:36 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Wed, 14 Dec 2011 06:15:36 -0800 (PST)
Subject: [Rd] problems with iconv
In-Reply-To: <CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
	<CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
Message-ID: <1323872136574-4195139.post@n4.nabble.com>

For some reason when I click on reply and sign-in  - the message I'm replying
to is not carried forward.  As you requested that include your message I
copied and pasted it from my email. 

> A suitably comprehensive iconv function is essential. The R usage requires 
> iconv to be able to translate between "latin1" and "UTF-8", to recognize
> "" 
> (as the current encoding) and "ASCII", and to translate to and from the 
> Unicode wide-character formats "UCS-[24][BL]E" ? this is true for glibc
> but 
> not of most commercial Unixes. However, you can make use of GNU libiconv 
> (possibly as a plug-in replacement: see 
> http://www.gnu.org/software/libiconv/). 
> 
> Well, that's just what I did.  I downloaded libiconv and compiled and
> linked 
> it.  Oh, so where to put it.  Hmmmm, don't see it anywhere here.  Do you? 
> 
The location isn't mentioned in Appendix A, which you cite a portion 
of above, but it is mentioned in Solaris section of Appendix C, which 
you cite below. 

> Also from the manual: 
> 
> /You will need GNU libiconv and readline: the Solaris version of iconv is 
> not sufficiently powerful. 
> 
> For the Solaris Studio compilers a little juggling of paths was needed to 
> ensure GNU libiconv (in /usr/local) was used rather than the Solaris
> iconv: 
> 
This seems to indicate GNU libiconv should be installed in /usr/local, 
which is the location specified in the libiconv installation 
instructions: 

As usual for GNU packages: 
$ ./configure --prefix=/usr/local 
$ make 
$ make install 

Did you try the suggestion two paragraphs above this in Appendix C? 
"Some people have reported that the Solaris libintl needs to be 
avoided, for example by using --disable-nls or --with-included-gettext 
or using libintl from OpenCSW." 

As it turns out I put iconv and libiconv.so and libiconv.so.2.5.1 in
/usr/local/bin and /usr/local/lib.  Just for grins I copied these files to
/usr/local and tried again with the same results.  

This is my configure statement:

./configure --with-blas=-library=sunperf --with-lapack --with-readline=no
--x-includes=/usr/X11/include --x-libraries=/usr/X11/lib --prefix=/usr/local
--disable-nls  --with-included-gettext 

So, yes, I did try the suggestions mentioned in Appendix C.

>     CC="cc -xc99" 
>     CFLAGS="-O -xlibmieee" 
>     F77=f95 
>     FFLAGS=-O4 
>     CXX="CC -library=stlport4" 
>     CXXFLAGS=-O 
>     FC=f95 
>     FCFLAGS=$FFLAGS 
>     FCLIBS="-lfai -lfsu" 
>     R_LD_LIBRARY_PATH="/usr/local/lib:/opt/csw/gcc4/lib:/opt/csw/lib" 
> 
> For a 64-bit target add -m64 to the compiler macros and use something like 
> LDFLAGS=-L/usr/local/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 as 
> appropriate. / 
> 
> Well, I did that. Here are some of my options from the config.site: 
> 
<snip> 
> 
> So, here it is - all the revelent documentation on iconv.  If I've missed 
> anything please let me know.  If you see where in the documentation I
> missed 
> some cryptic clue on how to get iconv to work or where to put it or it's 
> headers, also please let me know. 
> 
Did you take the steps required to resolve the circular dependency 
between libiconv and gettext? 

I used the --disable-nls  and --with-included-gettext options.  I also
downloaded the more up-to-date cairo package.  

BTW, is there a program I can run to test my iconv binary?  I think that
would rule out any problem with the compilation.

Thanks for you suggestions and for any future help.  This is frustrating
because I have compiled R, just not with a workable iconv, which prevents me
from updating and adding packages.

Roger




--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4195139.html
Sent from the R devel mailing list archive at Nabble.com.


From nashjc at uottawa.ca  Wed Dec 14 16:19:58 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 14 Dec 2011 10:19:58 -0500
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <mailman.23.1323860405.29464.r-devel@r-project.org>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
Message-ID: <4EE8BE9E.80402@uottawa.ca>


Following this thread, I wondered why nobody tried cumsum to see where the integer
overflow occurs. On the shorter xx vector in the little script below I get a message:

Warning message:
Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>

But sum() does not give such a warning, which I believe is the point of contention. Since
cumsum() does manage to give such a warning, and show where the overflow occurs, should
sum() not be able to do so? For the record, I don't class the non-zero answer as an error
in itself. I regard the failure to warn as the issue.

For info, on my Ubnuntu Lucid 10.04 system that has 4 GB of RAM but no swap, the last line
of the script to do the int64 sum chugs for about 2 minutes then gives "Killed" and
returns to the terminal prompt. It also seems to render some other applications unstable
(I had Thunderbird running to read R-devel, and this started to behave strangely after the
crash, and I had to reboot.) I'm copying Romain as package maintainer, and I'll be happy
to try to work off-list to figure out how to avoid the "Killed" result. (On a 16GB
machine, I got the 0 answer.)

Best,

John Nash

Here's the system info and small script.

>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>  [7] LC_PAPER=C                LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] int64_1.1.2
>>


## sumerr.R  20111214
library(int64)
x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
xx <- c(rep(1800000003L, 1000), -rep(1200000002L, 1500))
sum(x)
sum(as.double(x))
sum(xx)
sum(as.double(xx))
cumsum(xx)
cumsum(as.int64(xx))

tmp<-readline("Now try the VERY SLOW int64")
sum(as.int64(x))


From josh.m.ulrich at gmail.com  Wed Dec 14 16:57:06 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 14 Dec 2011 09:57:06 -0600
Subject: [Rd] problems with iconv
In-Reply-To: <1323872136574-4195139.post@n4.nabble.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
	<CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
	<1323872136574-4195139.post@n4.nabble.com>
Message-ID: <CAPPM_gQZ59AhJjSYgQb4zoFnKvnhR3txPprZiJuYV0CXbON20w@mail.gmail.com>

On Wed, Dec 14, 2011 at 8:15 AM, RogerP <rpickeri at mail.nih.gov> wrote:
> For some reason when I click on reply and sign-in ?- the message I'm replying
> to is not carried forward. ?As you requested that include your message I
> copied and pasted it from my email.
>
I guess it's some Nabble nonsense then...

>> A suitably comprehensive iconv function is essential. The R usage requires
>> iconv to be able to translate between "latin1" and "UTF-8", to recognize
>> ""
>> (as the current encoding) and "ASCII", and to translate to and from the
>> Unicode wide-character formats "UCS-[24][BL]E" ? this is true for glibc
>> but
>> not of most commercial Unixes. However, you can make use of GNU libiconv
>> (possibly as a plug-in replacement: see
>> http://www.gnu.org/software/libiconv/).
>>
>> Well, that's just what I did. ?I downloaded libiconv and compiled and
>> linked
>> it. ?Oh, so where to put it. ?Hmmmm, don't see it anywhere here. ?Do you?
>>
> The location isn't mentioned in Appendix A, which you cite a portion
> of above, but it is mentioned in Solaris section of Appendix C, which
> you cite below.
>
>> Also from the manual:
>>
>> /You will need GNU libiconv and readline: the Solaris version of iconv is
>> not sufficiently powerful.
>>
>> For the Solaris Studio compilers a little juggling of paths was needed to
>> ensure GNU libiconv (in /usr/local) was used rather than the Solaris
>> iconv:
>>
> This seems to indicate GNU libiconv should be installed in /usr/local,
> which is the location specified in the libiconv installation
> instructions:
>
> As usual for GNU packages:
> $ ./configure --prefix=/usr/local
> $ make
> $ make install
>
> Did you try the suggestion two paragraphs above this in Appendix C?
> "Some people have reported that the Solaris libintl needs to be
> avoided, for example by using --disable-nls or --with-included-gettext
> or using libintl from OpenCSW."
>
> As it turns out I put iconv and libiconv.so and libiconv.so.2.5.1 in
> /usr/local/bin and /usr/local/lib. ?Just for grins I copied these files to
> /usr/local and tried again with the same results.
>
> This is my configure statement:
>
> ./configure --with-blas=-library=sunperf --with-lapack --with-readline=no
> --x-includes=/usr/X11/include --x-libraries=/usr/X11/lib --prefix=/usr/local
> --disable-nls ?--with-included-gettext
>
> So, yes, I did try the suggestions mentioned in Appendix C.
>
>> ? ? CC="cc -xc99"
>> ? ? CFLAGS="-O -xlibmieee"
>> ? ? F77=f95
>> ? ? FFLAGS=-O4
>> ? ? CXX="CC -library=stlport4"
>> ? ? CXXFLAGS=-O
>> ? ? FC=f95
>> ? ? FCFLAGS=$FFLAGS
>> ? ? FCLIBS="-lfai -lfsu"
>> ? ? R_LD_LIBRARY_PATH="/usr/local/lib:/opt/csw/gcc4/lib:/opt/csw/lib"
>>
>> For a 64-bit target add -m64 to the compiler macros and use something like
>> LDFLAGS=-L/usr/local/lib/sparcv9 or LDFLAGS=-L/usr/local/lib/amd64 as
>> appropriate. /
>>
>> Well, I did that. Here are some of my options from the config.site:
>>
> <snip>
>>
>> So, here it is - all the revelent documentation on iconv. ?If I've missed
>> anything please let me know. ?If you see where in the documentation I
>> missed
>> some cryptic clue on how to get iconv to work or where to put it or it's
>> headers, also please let me know.
>>
> Did you take the steps required to resolve the circular dependency
> between libiconv and gettext?
>
> I used the --disable-nls ?and --with-included-gettext options. ?I also
> downloaded the more up-to-date cairo package.
>
I was referring to the instructions on the libiconv page:
http://www.gnu.org/software/libiconv/

"On systems other than GNU/Linux, the iconv program will be
internationalized only if GNU gettext has been built and installed
before GNU libiconv."

That seems to suggest that libiconv *may* require you to install GNU
gettext before installing GNU libiconv.  Have you done that?

> BTW, is there a program I can run to test my iconv binary? ?I think that
> would rule out any problem with the compilation.
>
> Thanks for you suggestions and for any future help. ?This is frustrating
> because I have compiled R, just not with a workable iconv, which prevents me
> from updating and adding packages.
>
> Roger
>

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com


From pdalgd at gmail.com  Wed Dec 14 17:19:41 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 14 Dec 2011 17:19:41 +0100
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE8BE9E.80402@uottawa.ca>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
	<4EE8BE9E.80402@uottawa.ca>
Message-ID: <89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>


On Dec 14, 2011, at 16:19 , John C Nash wrote:

> 
> Following this thread, I wondered why nobody tried cumsum to see where the integer
> overflow occurs. On the shorter xx vector in the little script below I get a message:
> 
> Warning message:
> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>> 
> 
> But sum() does not give such a warning, which I believe is the point of contention. Since
> cumsum() does manage to give such a warning, and show where the overflow occurs, should
> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
> in itself. I regard the failure to warn as the issue.

It (sum) does warn if you take the two "halves" separately. The issue is that the overflow is detected at the end of the summation, when the result is to be saved to an integer (which of course happens for all intermediate sums in cumsum)

> x <- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
> sum(x[1:10000000])
[1] NA
Warning message:
In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
> sum(x[10000001:25000000])
[1] NA
Warning message:
In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
> sum(x)
[1] 4996000

There's a pretty easy fix, essentially to move

    if(s > INT_MAX || s < R_INT_MIN){
        warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
        *value = NA_INTEGER;
    }

inside the summation loop. Obviously, there's a speed penalty from two FP comparisons per element, but I wouldn't know whether it matters in practice for anyone.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rpickeri at mail.nih.gov  Wed Dec 14 19:43:59 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Wed, 14 Dec 2011 10:43:59 -0800 (PST)
Subject: [Rd] problems with iconv
In-Reply-To: <CAPPM_gQZ59AhJjSYgQb4zoFnKvnhR3txPprZiJuYV0CXbON20w@mail.gmail.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
	<CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
	<1323872136574-4195139.post@n4.nabble.com>
	<CAPPM_gQZ59AhJjSYgQb4zoFnKvnhR3txPprZiJuYV0CXbON20w@mail.gmail.com>
Message-ID: <1323888239574-4196455.post@n4.nabble.com>

>I used the --disable-nls  and --with-included-gettext options.  I also
downloaded the more >up-to-date cairo package.   

>BTW, is there a program I can run to test my iconv binary?  I think that
would rule out any >problem with the compilation. 

>Thanks for you suggestions and for any future help.  This is frustrating
because I have >compiled R, just not with a workable iconv, which prevents
me from updating and adding >packages. 


I did some looking at iconv and tried 'iconv --list', but got an error
saying the libgcc was the wrong elf class - elf class 32.  So I changed the
/opt/csw/lib to /opt/csw/lib/amd64 on my env var LD_LIBRARY.  It ran!  So,
thought I, this is it - I've solved the problem.

But no, even though 'iconv --list' ran I still got the same error message.  

I did notice though that the list returns values for LATIN1 and not latin1
that configure and the update.packages() both seem to want.  

Here is the results of 'iconv --list':

646 ANSI_X3.4-1968 ANSI_X3.4-1986 ASCII CP367 IBM367 ISO-IR-6 ISO646-US
ISO_646.IRV:1991 US US-ASCII CSASCII
UTF-8
ISO-10646-UCS-2 UCS-2 CSUNICODE
UCS-2BE UNICODE-1-1 UNICODEBIG CSUNICODE11
UCS-2LE UNICODELITTLE
ISO-10646-UCS-4 UCS-4 CSUCS4
UCS-4BE
UCS-4LE
UTF-16
UTF-16BE
UTF-16LE
UTF-32
UTF-32BE
UTF-32LE
UNICODE-1-1-UTF-7 UTF-7 CSUNICODE11UTF7
UCS-2-INTERNAL
UCS-2-SWAPPED
UCS-4-INTERNAL
UCS-4-SWAPPED
C99
JAVA
CP819 IBM819 ISO-8859-1 ISO-IR-100 ISO8859-1 ISO_8859-1 ISO_8859-1:1987 L1
LATIN1 CSISOLATIN1
ISO-8859-2 ISO-IR-101 ISO8859-2 ISO_8859-2 ISO_8859-2:1987 L2 LATIN2
CSISOLATIN2
ISO-8859-3 ISO-IR-109 ISO8859-3 ISO_8859-3 ISO_8859-3:1988 L3 LATIN3
CSISOLATIN3
ISO-8859-4 ISO-IR-110 ISO8859-4 ISO_8859-4 ISO_8859-4:1988 L4 LATIN4
CSISOLATIN4
CYRILLIC ISO-8859-5 ISO-IR-144 ISO8859-5 ISO_8859-5 ISO_8859-5:1988
CSISOLATINCYRILLIC
ARABIC ASMO-708 ECMA-114 ISO-8859-6 ISO-IR-127 ISO8859-6 ISO_8859-6
ISO_8859-6:1987 CSISOLATINARABIC
ECMA-118 ELOT_928 GREEK GREEK8 ISO-8859-7 ISO-IR-126 ISO8859-7 ISO_8859-7
ISO_8859-7:1987 ISO_8859-7:2003 CSISOLATINGREEK
HEBREW ISO-8859-8 ISO-IR-138 ISO8859-8 ISO_8859-8 ISO_8859-8:1988
CSISOLATINHEBREW
ISO-8859-9 ISO-IR-148 ISO8859-9 ISO_8859-9 ISO_8859-9:1989 L5 LATIN5
CSISOLATIN5
ISO-8859-10 ISO-IR-157 ISO8859-10 ISO_8859-10 ISO_8859-10:1992 L6 LATIN6
CSISOLATIN6
ISO-8859-11 ISO8859-11 ISO_8859-11
ISO-8859-13 ISO-IR-179 ISO8859-13 ISO_8859-13 L7 LATIN7
ISO-8859-14 ISO-CELTIC ISO-IR-199 ISO8859-14 ISO_8859-14 ISO_8859-14:1998 L8
LATIN8
ISO-8859-15 ISO-IR-203 ISO8859-15 ISO_8859-15 ISO_8859-15:1998 LATIN-9
ISO-8859-16 ISO-IR-226 ISO8859-16 ISO_8859-16 ISO_8859-16:2001 L10 LATIN10
KOI8-R CSKOI8R
KOI8-U
KOI8-RU
CP1250 MS-EE WINDOWS-1250
ANSI-1251 CP1251 MS-CYRL WINDOWS-1251
CP1252 MS-ANSI WINDOWS-1252
CP1253 MS-GREEK WINDOWS-1253
CP1254 MS-TURK WINDOWS-1254
CP1255 MS-HEBR WINDOWS-1255
CP1256 MS-ARAB WINDOWS-1256
CP1257 WINBALTRIM WINDOWS-1257
CP1258 WINDOWS-1258
850 CP850 IBM850 CSPC850MULTILINGUAL
862 CP862 IBM862 CSPC862LATINHEBREW
866 CP866 IBM866 CSIBM866
CP1131
MAC MACINTOSH MACROMAN CSMACINTOSH
MACCENTRALEUROPE
MACICELAND
MACCROATIAN
MACROMANIA
MACCYRILLIC
MACUKRAINE
MACGREEK
MACTURKISH
MACHEBREW
MACARABIC
MACTHAI
HP-ROMAN8 R8 ROMAN8 CSHPROMAN8
NEXTSTEP
ARMSCII-8
GEORGIAN-ACADEMY
GEORGIAN-PS
KOI8-T
CP154 CYRILLIC-ASIAN PT154 PTCP154 CSPTCP154
KZ-1048 RK1048 STRK1048-2002 CSKZ1048
MULELAO-1
CP1133 IBM-CP1133
ISO-IR-166 TIS-620 TIS620 TIS620-0 TIS620.2529-1 TIS620.2533 TIS620.2533-0
TIS620.2533-1
CP874 WINDOWS-874
VISCII VISCII1.1-1 CSVISCII
TCVN TCVN-5712 TCVN5712-1 TCVN5712-1:1993
ISO-IR-14 ISO646-JP JIS_C6220-1969-RO JP CSISO14JISC6220RO
JISX0201-1976 JIS_X0201 X0201 CSHALFWIDTHKATAKANA
ISO-IR-87 JIS0208 JIS_C6226-1983 JIS_X0208 JIS_X0208-1983 JIS_X0208-1990
X0208 CSISO87JISX0208
ISO-IR-159 JIS_X0212 JIS_X0212-1990 JIS_X0212.1990-0 X0212
CSISO159JISX02121990
CN GB_1988-80 ISO-IR-57 ISO646-CN CSISO57GB1988
CHINESE GB_2312-80 ISO-IR-58 CSISO58GB231280
CN-GB-ISOIR165 ISO-IR-165
ISO-IR-149 KOREAN KSC_5601 KS_C_5601-1987 KS_C_5601-1989 CSKSC56011987
EUC-JP EUCJP EXTENDED_UNIX_CODE_PACKED_FORMAT_FOR_JAPANESE
CSEUCPKDFMTJAPANESE
MS_KANJI PCK SHIFT-JIS SHIFT_JIS SJIS CSSHIFTJIS
CP932
ISO-2022-JP CSISO2022JP
ISO-2022-JP-1
ISO-2022-JP-2 CSISO2022JP2
CN-GB EUC-CN EUCCN GB2312 CSGB2312
GBK
CP936 MS936 WINDOWS-936
GB18030
ISO-2022-CN CSISO2022CN
ISO-2022-CN-EXT
HZ HZ-GB-2312
CNS11643 EUC-TW EUCTW CSEUCTW
BIG-5 BIG-FIVE BIG5 BIGFIVE CN-BIG5 CSBIG5
CP950
BIG5-HKSCS:1999
BIG5-HKSCS:2001
BIG5-HKSCS:2004
BIG5-HKSCS BIG5-HKSCS:2008 BIG5HKSCS
5601 EUC-KR EUCKR CSEUCKR
CP949 UHC
CP1361 JOHAB KO_KR.JOHAP92
ISO-2022-KR CSISO2022KR

Is there still something wrong with iconv?

I put the header in the <R home>/include.  Was that right?

Thanks again for your attention,
Roger

--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4196455.html
Sent from the R devel mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Wed Dec 14 21:58:17 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 14 Dec 2011 21:58:17 +0100
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
Message-ID: <4EE90DE9.6070308@statistik.tu-dortmund.de>



On 14.12.2011 17:19, peter dalgaard wrote:
>
> On Dec 14, 2011, at 16:19 , John C Nash wrote:
>
>>
>> Following this thread, I wondered why nobody tried cumsum to see where the integer
>> overflow occurs. On the shorter xx vector in the little script below I get a message:
>>
>> Warning message:
>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>
>>
>> But sum() does not give such a warning, which I believe is the point of contention. Since
>> cumsum() does manage to give such a warning, and show where the overflow occurs, should
>> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
>> in itself. I regard the failure to warn as the issue.
>
> It (sum) does warn if you take the two "halves" separately. The issue is that the overflow is detected at the end of the summation, when the result is to be saved to an integer (which of course happens for all intermediate sums in cumsum)
>
>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>> sum(x[1:10000000])
> [1] NA
> Warning message:
> In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
>> sum(x[10000001:25000000])
> [1] NA
> Warning message:
> In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
>> sum(x)
> [1] 4996000
>
> There's a pretty easy fix, essentially to move
>
>      if(s>  INT_MAX || s<  R_INT_MIN){
>          warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
>          *value = NA_INTEGER;
>      }
>
> inside the summation loop. Obviously, there's a speed penalty from two FP comparisons per element, but I wouldn't know whether it matters in practice for anyone.
>


I don't think I am interested in where the overflow happens if I call 
sum()...

Uwe


From nashjc at uottawa.ca  Wed Dec 14 22:16:31 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 14 Dec 2011 16:16:31 -0500
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE90DE9.6070308@statistik.tu-dortmund.de>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
	<4EE90DE9.6070308@statistik.tu-dortmund.de>
Message-ID: <4EE9122F.3020303@uottawa.ca>

I agree that where the overflow occurs is not critical (one can go back to cumsum and find
out). I am assuming that Uwe still wants to know there has been an overflow at some point
i.e., a warning. This could become more "interesting" as parallel computation causes
different summation orderings on sums of large numbers of items.

JN


On 12/14/2011 03:58 PM, Uwe Ligges wrote:
> 
> 
> On 14.12.2011 17:19, peter dalgaard wrote:
>>
>> On Dec 14, 2011, at 16:19 , John C Nash wrote:
>>
>>>
>>> Following this thread, I wondered why nobody tried cumsum to see where the integer
>>> overflow occurs. On the shorter xx vector in the little script below I get a message:
>>>
>>> Warning message:
>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>>
>>>
>>> But sum() does not give such a warning, which I believe is the point of contention. Since
>>> cumsum() does manage to give such a warning, and show where the overflow occurs, should
>>> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
>>> in itself. I regard the failure to warn as the issue.
>>
>> It (sum) does warn if you take the two "halves" separately. The issue is that the
>> overflow is detected at the end of the summation, when the result is to be saved to an
>> integer (which of course happens for all intermediate sums in cumsum)
>>
>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>> sum(x[1:10000000])
>> [1] NA
>> Warning message:
>> In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
>>> sum(x[10000001:25000000])
>> [1] NA
>> Warning message:
>> In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
>>> sum(x)
>> [1] 4996000
>>
>> There's a pretty easy fix, essentially to move
>>
>>      if(s>  INT_MAX || s<  R_INT_MIN){
>>          warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
>>          *value = NA_INTEGER;
>>      }
>>
>> inside the summation loop. Obviously, there's a speed penalty from two FP comparisons
>> per element, but I wouldn't know whether it matters in practice for anyone.
>>
> 
> 
> I don't think I am interested in where the overflow happens if I call sum()...
> 
> Uwe


From ligges at statistik.tu-dortmund.de  Wed Dec 14 22:17:29 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 14 Dec 2011 22:17:29 +0100
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE9122F.3020303@uottawa.ca>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
	<4EE90DE9.6070308@statistik.tu-dortmund.de>
	<4EE9122F.3020303@uottawa.ca>
Message-ID: <4EE91269.8000000@statistik.tu-dortmund.de>



On 14.12.2011 22:16, John C Nash wrote:
> I agree that where the overflow occurs is not critical (one can go back to cumsum and find
> out). I am assuming that Uwe still wants to know there has been an overflow at some point
> i.e., a warning.

Yes, sure.

Uwe


> This could become more "interesting" as parallel computation causes
> different summation orderings on sums of large numbers of items.
>
> JN
>
>
> On 12/14/2011 03:58 PM, Uwe Ligges wrote:
>>
>>
>> On 14.12.2011 17:19, peter dalgaard wrote:
>>>
>>> On Dec 14, 2011, at 16:19 , John C Nash wrote:
>>>
>>>>
>>>> Following this thread, I wondered why nobody tried cumsum to see where the integer
>>>> overflow occurs. On the shorter xx vector in the little script below I get a message:
>>>>
>>>> Warning message:
>>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>>>
>>>>
>>>> But sum() does not give such a warning, which I believe is the point of contention. Since
>>>> cumsum() does manage to give such a warning, and show where the overflow occurs, should
>>>> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
>>>> in itself. I regard the failure to warn as the issue.
>>>
>>> It (sum) does warn if you take the two "halves" separately. The issue is that the
>>> overflow is detected at the end of the summation, when the result is to be saved to an
>>> integer (which of course happens for all intermediate sums in cumsum)
>>>
>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>> sum(x[1:10000000])
>>> [1] NA
>>> Warning message:
>>> In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
>>>> sum(x[10000001:25000000])
>>> [1] NA
>>> Warning message:
>>> In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
>>>> sum(x)
>>> [1] 4996000
>>>
>>> There's a pretty easy fix, essentially to move
>>>
>>>       if(s>   INT_MAX || s<   R_INT_MIN){
>>>           warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
>>>           *value = NA_INTEGER;
>>>       }
>>>
>>> inside the summation loop. Obviously, there's a speed penalty from two FP comparisons
>>> per element, but I wouldn't know whether it matters in practice for anyone.
>>>
>>
>>
>> I don't think I am interested in where the overflow happens if I call sum()...
>>
>> Uwe


From pdalgd at gmail.com  Wed Dec 14 22:51:42 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 14 Dec 2011 22:51:42 +0100
Subject: [Rd] problems with iconv
In-Reply-To: <1323888239574-4196455.post@n4.nabble.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
	<CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
	<1323872136574-4195139.post@n4.nabble.com>
	<CAPPM_gQZ59AhJjSYgQb4zoFnKvnhR3txPprZiJuYV0CXbON20w@mail.gmail.com>
	<1323888239574-4196455.post@n4.nabble.com>
Message-ID: <F860B1FC-23B6-4F4D-A7D6-20FF324B8A91@gmail.com>


On Dec 14, 2011, at 19:43 , RogerP wrote:

>> I used the --disable-nls  and --with-included-gettext options.  I also
> downloaded the more >up-to-date cairo package.   
> 
>> BTW, is there a program I can run to test my iconv binary?  I think that
> would rule out any >problem with the compilation. 
> 
>> Thanks for you suggestions and for any future help.  This is frustrating
> because I have >compiled R, just not with a workable iconv, which prevents
> me from updating and adding >packages. 
> 
> 
> I did some looking at iconv and tried 'iconv --list', but got an error
> saying the libgcc was the wrong elf class - elf class 32.  So I changed the
> /opt/csw/lib to /opt/csw/lib/amd64 on my env var LD_LIBRARY.  It ran!  So,
> thought I, this is it - I've solved the problem.
> 
> But no, even though 'iconv --list' ran I still got the same error message.  
> 
> I did notice though that the list returns values for LATIN1 and not latin1
> that configure and the update.packages() both seem to want.  
> 
> Here is the results of 'iconv --list':
> 
> 646 ANSI_X3.4-1968 ANSI_X3.4-1986 ASCII CP367 IBM367 ISO-IR-6 ISO646-US
> ISO_646.IRV:1991 US US-ASCII CSASCII
> UTF-8
> ISO-10646-UCS-2 UCS-2 CSUNICODE
> UCS-2BE UNICODE-1-1 UNICODEBIG CSUNICODE11
> UCS-2LE UNICODELITTLE
> ISO-10646-UCS-4 UCS-4 CSUCS4
> UCS-4BE
> UCS-4LE
> UTF-16
> UTF-16BE
> UTF-16LE
> UTF-32
> UTF-32BE
> UTF-32LE
> UNICODE-1-1-UTF-7 UTF-7 CSUNICODE11UTF7
> UCS-2-INTERNAL
> UCS-2-SWAPPED
> UCS-4-INTERNAL
> UCS-4-SWAPPED
> C99
> JAVA
> CP819 IBM819 ISO-8859-1 ISO-IR-100 ISO8859-1 ISO_8859-1 ISO_8859-1:1987 L1
> LATIN1 CSISOLATIN1
> ISO-8859-2 ISO-IR-101 ISO8859-2 ISO_8859-2 ISO_8859-2:1987 L2 LATIN2
> CSISOLATIN2
> ISO-8859-3 ISO-IR-109 ISO8859-3 ISO_8859-3 ISO_8859-3:1988 L3 LATIN3
> CSISOLATIN3
> ISO-8859-4 ISO-IR-110 ISO8859-4 ISO_8859-4 ISO_8859-4:1988 L4 LATIN4
> CSISOLATIN4
> CYRILLIC ISO-8859-5 ISO-IR-144 ISO8859-5 ISO_8859-5 ISO_8859-5:1988
> CSISOLATINCYRILLIC
> ARABIC ASMO-708 ECMA-114 ISO-8859-6 ISO-IR-127 ISO8859-6 ISO_8859-6
> ISO_8859-6:1987 CSISOLATINARABIC
> ECMA-118 ELOT_928 GREEK GREEK8 ISO-8859-7 ISO-IR-126 ISO8859-7 ISO_8859-7
> ISO_8859-7:1987 ISO_8859-7:2003 CSISOLATINGREEK
> HEBREW ISO-8859-8 ISO-IR-138 ISO8859-8 ISO_8859-8 ISO_8859-8:1988
> CSISOLATINHEBREW
> ISO-8859-9 ISO-IR-148 ISO8859-9 ISO_8859-9 ISO_8859-9:1989 L5 LATIN5
> CSISOLATIN5
> ISO-8859-10 ISO-IR-157 ISO8859-10 ISO_8859-10 ISO_8859-10:1992 L6 LATIN6
> CSISOLATIN6
> ISO-8859-11 ISO8859-11 ISO_8859-11
> ISO-8859-13 ISO-IR-179 ISO8859-13 ISO_8859-13 L7 LATIN7
> ISO-8859-14 ISO-CELTIC ISO-IR-199 ISO8859-14 ISO_8859-14 ISO_8859-14:1998 L8
> LATIN8
> ISO-8859-15 ISO-IR-203 ISO8859-15 ISO_8859-15 ISO_8859-15:1998 LATIN-9
> ISO-8859-16 ISO-IR-226 ISO8859-16 ISO_8859-16 ISO_8859-16:2001 L10 LATIN10
> KOI8-R CSKOI8R
> KOI8-U
> KOI8-RU
> CP1250 MS-EE WINDOWS-1250
> ANSI-1251 CP1251 MS-CYRL WINDOWS-1251
> CP1252 MS-ANSI WINDOWS-1252
> CP1253 MS-GREEK WINDOWS-1253
> CP1254 MS-TURK WINDOWS-1254
> CP1255 MS-HEBR WINDOWS-1255
> CP1256 MS-ARAB WINDOWS-1256
> CP1257 WINBALTRIM WINDOWS-1257
> CP1258 WINDOWS-1258
> 850 CP850 IBM850 CSPC850MULTILINGUAL
> 862 CP862 IBM862 CSPC862LATINHEBREW
> 866 CP866 IBM866 CSIBM866
> CP1131
> MAC MACINTOSH MACROMAN CSMACINTOSH
> MACCENTRALEUROPE
> MACICELAND
> MACCROATIAN
> MACROMANIA
> MACCYRILLIC
> MACUKRAINE
> MACGREEK
> MACTURKISH
> MACHEBREW
> MACARABIC
> MACTHAI
> HP-ROMAN8 R8 ROMAN8 CSHPROMAN8
> NEXTSTEP
> ARMSCII-8
> GEORGIAN-ACADEMY
> GEORGIAN-PS
> KOI8-T
> CP154 CYRILLIC-ASIAN PT154 PTCP154 CSPTCP154
> KZ-1048 RK1048 STRK1048-2002 CSKZ1048
> MULELAO-1
> CP1133 IBM-CP1133
> ISO-IR-166 TIS-620 TIS620 TIS620-0 TIS620.2529-1 TIS620.2533 TIS620.2533-0
> TIS620.2533-1
> CP874 WINDOWS-874
> VISCII VISCII1.1-1 CSVISCII
> TCVN TCVN-5712 TCVN5712-1 TCVN5712-1:1993
> ISO-IR-14 ISO646-JP JIS_C6220-1969-RO JP CSISO14JISC6220RO
> JISX0201-1976 JIS_X0201 X0201 CSHALFWIDTHKATAKANA
> ISO-IR-87 JIS0208 JIS_C6226-1983 JIS_X0208 JIS_X0208-1983 JIS_X0208-1990
> X0208 CSISO87JISX0208
> ISO-IR-159 JIS_X0212 JIS_X0212-1990 JIS_X0212.1990-0 X0212
> CSISO159JISX02121990
> CN GB_1988-80 ISO-IR-57 ISO646-CN CSISO57GB1988
> CHINESE GB_2312-80 ISO-IR-58 CSISO58GB231280
> CN-GB-ISOIR165 ISO-IR-165
> ISO-IR-149 KOREAN KSC_5601 KS_C_5601-1987 KS_C_5601-1989 CSKSC56011987
> EUC-JP EUCJP EXTENDED_UNIX_CODE_PACKED_FORMAT_FOR_JAPANESE
> CSEUCPKDFMTJAPANESE
> MS_KANJI PCK SHIFT-JIS SHIFT_JIS SJIS CSSHIFTJIS
> CP932
> ISO-2022-JP CSISO2022JP
> ISO-2022-JP-1
> ISO-2022-JP-2 CSISO2022JP2
> CN-GB EUC-CN EUCCN GB2312 CSGB2312
> GBK
> CP936 MS936 WINDOWS-936
> GB18030
> ISO-2022-CN CSISO2022CN
> ISO-2022-CN-EXT
> HZ HZ-GB-2312
> CNS11643 EUC-TW EUCTW CSEUCTW
> BIG-5 BIG-FIVE BIG5 BIGFIVE CN-BIG5 CSBIG5
> CP950
> BIG5-HKSCS:1999
> BIG5-HKSCS:2001
> BIG5-HKSCS:2004
> BIG5-HKSCS BIG5-HKSCS:2008 BIG5HKSCS
> 5601 EUC-KR EUCKR CSEUCKR
> CP949 UHC
> CP1361 JOHAB KO_KR.JOHAP92
> ISO-2022-KR CSISO2022KR
> 
> Is there still something wrong with iconv?


Looks quite normal. But is that the iconv that R is connecting to? You had an error that it couldn't convert latin1 to ASCII and both are on that list....

> I put the header in the <R home>/include.  Was that right?

Probably not. I would expect something like /usr/local/include, and maybe a -I option to make sure it was found before the Solaris-supplied one. Does make install (for iconv) not do that for you?

You may need to look into config.log and see exactly what is going wrong when configure fails the test about supported conversions. 


> Thanks again for your attention,
> Roger
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4196455.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From niwang at gmail.com  Wed Dec 14 22:54:18 2011
From: niwang at gmail.com (Ni Wang)
Date: Wed, 14 Dec 2011 16:54:18 -0500
Subject: [Rd] secure password token management method in R
Message-ID: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111214/ecf9be7a/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Wed Dec 14 23:31:45 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 14 Dec 2011 22:31:45 +0000
Subject: [Rd] secure password token management method in R
In-Reply-To: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
References: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
Message-ID: <CANVKczP7J9kTi5EO0WZr53EMMKMzKbanc1z-WThijWfqbbD1BA@mail.gmail.com>

On Wed, Dec 14, 2011 at 9:54 PM, Ni Wang <niwang at gmail.com> wrote:
> hi, r developers, I am now working on a R function/package to handling
> online request with username and token/password.
>
> For security reasons, it's not so safe to store the username & token in
> persistent variables, since they'll be saved to disk when
> users save their workspace. Is there a secure way in R to handle the online
> password management? I have searched it online
> but didn't find any good suggestions. So I am trying my luck on this mail
> list.

 If you save something to an environment that isnt the Global
Environment then R won't save it when you quit and save. Suggest you
save credentials in a list. Maybe something like this:

 attach(list(username="mrbluesky",password="s3cr3t"),name="credentials")

then you just get user and password from the environment when needed:

 get("username",envir=as.environment(credentials))
 get("password",envir=as.environment(credentials))

saving the R workspace in the usual way (answering 'y' to Save
Workspace Image) won't save this data.

 I have a vague memory of Splus possibly having a temporary
environment which would do what you want, but that doesn't seem to be
present in R...

Barry


From hpages at fhcrc.org  Thu Dec 15 02:51:13 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 14 Dec 2011 17:51:13 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
Message-ID: <4EE95291.1020108@fhcrc.org>

Hi Peter,

On 11-12-14 08:19 AM, peter dalgaard wrote:
>
> On Dec 14, 2011, at 16:19 , John C Nash wrote:
>
>>
>> Following this thread, I wondered why nobody tried cumsum to see where the integer
>> overflow occurs. On the shorter xx vector in the little script below I get a message:
>>
>> Warning message:
>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>
>>
>> But sum() does not give such a warning, which I believe is the point of contention. Since
>> cumsum() does manage to give such a warning, and show where the overflow occurs, should
>> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
>> in itself. I regard the failure to warn as the issue.
>
> It (sum) does warn if you take the two "halves" separately. The issue is that the overflow is detected at the end of the summation, when the result is to be saved to an integer (which of course happens for all intermediate sums in cumsum)
>
>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>> sum(x[1:10000000])
> [1] NA
> Warning message:
> In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
>> sum(x[10000001:25000000])
> [1] NA
> Warning message:
> In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
>> sum(x)
> [1] 4996000
>
> There's a pretty easy fix, essentially to move
>
>      if(s>  INT_MAX || s<  R_INT_MIN){
>          warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
>          *value = NA_INTEGER;
>      }
>
> inside the summation loop. Obviously, there's a speed penalty from two FP comparisons per element, but I wouldn't know whether it matters in practice for anyone.
>

Since you want to generate this warning once only, your test (now
inside the loop) needs to be something like:

     if (warn && (s > INT_MAX || s < R_INT_MIN)) {
         generate the warning
         warn = 0;
     }

with 'warn' initialized to 1. This makes the isum() function almost
twice slower on my machine (64-bit Ubuntu) when compiling with
gcc -O2 and when no overflow occurs (the most common use case I guess).

Why not just do the sum in a long double instead of a double?
It slows down isum() by only 8% on my machine when compiling
with gcc -O2.
But most importantly this solution also has the advantage of making
sum(x) consistent with sum(as.double(x)). The latter uses rsum() which
does the sum in a long double. So by using a long double in both isum()
and rsum(), consistency between sum(x) and sum(as.double(x)) is
guaranteed.
Maybe that still doesn't give you the guarantee that sum(x) will always
return the correct value (when it does not return NA) because that
depends now on the ability of long double to represent exactly the sum
of at most INT_MAX arbitrary ints. The nb of bits used for long double
seems to vary a lot across platforms/compilers so it's hard to tell.
Not an ideal solution, but at least it makes isum() more accurate than
the current isum() and it makes sum(x) consistent with sum(as.double(x))
on all platforms, without degrading performance too much.

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pdalgd at gmail.com  Thu Dec 15 11:40:23 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 15 Dec 2011 11:40:23 +0100
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE95291.1020108@fhcrc.org>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
	<4EE95291.1020108@fhcrc.org>
Message-ID: <888338DE-A085-49F3-943D-60B768005D46@gmail.com>


On Dec 15, 2011, at 02:51 , Herv? Pag?s wrote:

> Hi Peter,
> 
> On 11-12-14 08:19 AM, peter dalgaard wrote:
>> 
>> On Dec 14, 2011, at 16:19 , John C Nash wrote:
>> 
>>> 
>>> Following this thread, I wondered why nobody tried cumsum to see where the integer
>>> overflow occurs. On the shorter xx vector in the little script below I get a message:
>>> 
>>> Warning message:
>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>> 
>>> 
>>> But sum() does not give such a warning, which I believe is the point of contention. Since
>>> cumsum() does manage to give such a warning, and show where the overflow occurs, should
>>> sum() not be able to do so? For the record, I don't class the non-zero answer as an error
>>> in itself. I regard the failure to warn as the issue.
>> 
>> It (sum) does warn if you take the two "halves" separately. The issue is that the overflow is detected at the end of the summation, when the result is to be saved to an integer (which of course happens for all intermediate sums in cumsum)
>> 
>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>> sum(x[1:10000000])
>> [1] NA
>> Warning message:
>> In sum(x[1:1e+07]) : Integer overflow - use sum(as.numeric(.))
>>> sum(x[10000001:25000000])
>> [1] NA
>> Warning message:
>> In sum(x[10000001:1.5e+07]) : Integer overflow - use sum(as.numeric(.))
>>> sum(x)
>> [1] 4996000
>> 
>> There's a pretty easy fix, essentially to move
>> 
>>     if(s>  INT_MAX || s<  R_INT_MIN){
>>         warningcall(call, _("Integer overflow - use sum(as.numeric(.))"));
>>         *value = NA_INTEGER;
>>     }
>> 
>> inside the summation loop. Obviously, there's a speed penalty from two FP comparisons per element, but I wouldn't know whether it matters in practice for anyone.
>> 
> 
> Since you want to generate this warning once only, your test (now
> inside the loop) needs to be something like:
> 
>    if (warn && (s > INT_MAX || s < R_INT_MIN)) {
>        generate the warning
>        warn = 0;
>    }
> 
> with 'warn' initialized to 1. This makes the isum() function almost
> twice slower on my machine (64-bit Ubuntu) when compiling with
> gcc -O2 and when no overflow occurs (the most common use case I guess).
> 
> Why not just do the sum in a long double instead of a double?
> It slows down isum() by only 8% on my machine when compiling
> with gcc -O2.
> But most importantly this solution also has the advantage of making
> sum(x) consistent with sum(as.double(x)). The latter uses rsum() which
> does the sum in a long double. So by using a long double in both isum()
> and rsum(), consistency between sum(x) and sum(as.double(x)) is
> guaranteed.

Hum, yes. Also the test would be overly cautious: The real thing to test is whether we overrun the range in which integers are exactly representable in FP i.e. roughly +/-2^52, not the +/-2^31 that fits 32 bit integers. Or +/-2^63 if we have long doubles.

However, we still need to decide whether the issue is that sum(as.double(x)) can be inconsistent with sum(x), or whether it is that integer arithmetic can be inexact. Also, the timings should really be viewed in context: Does _any_ actual code use isum to an extent where halving its speed would have any noticeable impact?

We probably shouldn't touch this for 2.14.1, then.


> Maybe that still doesn't give you the guarantee that sum(x) will always
> return the correct value (when it does not return NA) because that
> depends now on the ability of long double to represent exactly the sum
> of at most INT_MAX arbitrary ints. The nb of bits used for long double
> seems to vary a lot across platforms/compilers so it's hard to tell.
> Not an ideal solution, but at least it makes isum() more accurate than
> the current isum() and it makes sum(x) consistent with sum(as.double(x))
> on all platforms, without degrading performance too much.
> 
> Cheers,
> H.
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mailinglist at nicolasturaro.com  Thu Dec 15 13:01:08 2011
From: mailinglist at nicolasturaro.com (Nicola Sturaro Sommacal)
Date: Thu, 15 Dec 2011 13:01:08 +0100
Subject: [Rd] Undocumented functions
Message-ID: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111215/d98f3f3e/attachment.pl>

From maechler at stat.math.ethz.ch  Thu Dec 15 13:59:38 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Dec 2011 13:59:38 +0100
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <888338DE-A085-49F3-943D-60B768005D46@gmail.com>
References: <mailman.23.1323860405.29464.r-devel@r-project.org>
	<4EE8BE9E.80402@uottawa.ca>
	<89A699ED-7317-4B55-B737-031965CA3E04@gmail.com>
	<4EE95291.1020108@fhcrc.org>
	<888338DE-A085-49F3-943D-60B768005D46@gmail.com>
Message-ID: <20201.61242.318403.801323@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Thu, 15 Dec 2011 11:40:23 +0100 writes:

    > On Dec 15, 2011, at 02:51 , Herv? Pag?s wrote:

    >> Hi Peter,
    >> 
    >> On 11-12-14 08:19 AM, peter dalgaard wrote:
    >>> 
    >>> On Dec 14, 2011, at 16:19 , John C Nash wrote:
    >>> 
    >>>> 
    >>>> Following this thread, I wondered why nobody tried
    >>>> cumsum to see where the integer overflow occurs. On the
    >>>> shorter xx vector in the little script below I get a
    >>>> message:
    >>>> 
    >>>> Warning message: Integer overflow in 'cumsum'; use
    >>>> 'cumsum(as.numeric(.))'
    >>>>> 
    >>>> 
    >>>> But sum() does not give such a warning, which I believe
    >>>> is the point of contention. Since cumsum() does manage
    >>>> to give such a warning, and show where the overflow
    >>>> occurs, should sum() not be able to do so? For the
    >>>> record, I don't class the non-zero answer as an error
    >>>> in itself. I regard the failure to warn as the issue.
    >>> 
    >>> It (sum) does warn if you take the two "halves"
    >>> separately. The issue is that the overflow is detected
    >>> at the end of the summation, when the result is to be
    >>> saved to an integer (which of course happens for all
    >>> intermediate sums in cumsum)
    >>> 
    >>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L,
    >>>> 15000000)) sum(x[1:10000000])
    >>> [1] NA Warning message: In sum(x[1:1e+07]) : Integer
    >>> overflow - use sum(as.numeric(.))
    >>>> sum(x[10000001:25000000])
    >>> [1] NA Warning message: In sum(x[10000001:1.5e+07]) :
    >>> Integer overflow - use sum(as.numeric(.))
    >>>> sum(x)
    >>> [1] 4996000
    >>> 
    >>> There's a pretty easy fix, essentially to move
    >>> 
    >>> if(s> INT_MAX || s< R_INT_MIN){ warningcall(call,
    >>> _("Integer overflow - use sum(as.numeric(.))")); *value
    >>> = NA_INTEGER; }
    >>> 
    >>> inside the summation loop. Obviously, there's a speed
    >>> penalty from two FP comparisons per element, but I
    >>> wouldn't know whether it matters in practice for anyone.
    >>> 
    >> 
    >> Since you want to generate this warning once only, your
    >> test (now inside the loop) needs to be something like:
    >> 
    >> if (warn && (s > INT_MAX || s < R_INT_MIN)) { generate
    >> the warning warn = 0; }
    >> 
    >> with 'warn' initialized to 1. This makes the isum()
    >> function almost twice slower on my machine (64-bit
    >> Ubuntu) when compiling with gcc -O2 and when no overflow
    >> occurs (the most common use case I guess).
    >> 
    >> Why not just do the sum in a long double instead of a
    >> double?  It slows down isum() by only 8% on my machine
    >> when compiling with gcc -O2.  But most importantly this
    >> solution also has the advantage of making sum(x)
    >> consistent with sum(as.double(x)). The latter uses rsum()
    >> which does the sum in a long double. So by using a long
    >> double in both isum() and rsum(), consistency between
    >> sum(x) and sum(as.double(x)) is guaranteed.

    > Hum, yes. Also the test would be overly cautious: The real
    > thing to test is whether we overrun the range in which
    > integers are exactly representable in FP i.e. roughly
    > +/-2^52, not the +/-2^31 that fits 32 bit integers. Or
    > +/-2^63 if we have long doubles.

    > However, we still need to decide whether the issue is that
    > sum(as.double(x)) can be inconsistent with sum(x), or
    > whether it is that integer arithmetic can be
    > inexact. Also, the timings should really be viewed in
    > context: Does _any_ actual code use isum to an extent
    > where halving its speed would have any noticeable impact?

    > We probably shouldn't touch this for 2.14.1, then.

Definitely agree on that.


Given all the (good) considerations in this thread,
I think that Herv?'s proposal of just *not* calling isum()
but rather rsum() really makes more sense:
- Not only will it give the correct (finite) answer in more cases,
- but it will be much easier to document what sum(.) does:
  sum(x)  and  sum(as.double(x)) will return the same values.
- it is faster than the isum() version which would check for
  overflow "every time".
We could think of coercing back to integer when the result is
inside the integer range and also when NA: returning
integer instead of real NA.

Martin

    >> Maybe that still doesn't give you the guarantee that
    >> sum(x) will always return the correct value (when it does
    >> not return NA) because that depends now on the ability of
    >> long double to represent exactly the sum of at most
    >> INT_MAX arbitrary ints. The nb of bits used for long
    >> double seems to vary a lot across platforms/compilers so
    >> it's hard to tell.  Not an ideal solution, but at least
    >> it makes isum() more accurate than the current isum() and
    >> it makes sum(x) consistent with sum(as.double(x)) on all
    >> platforms, without degrading performance too much.
    >> 
    >> Cheers, H.
    >> 
    >> -- 
    >> Herv? Pag?s
    >> 
    >> Program in Computational Biology Division of Public
    >> Health Sciences Fred Hutchinson Cancer Research Center
    >> 1100 Fairview Ave. N, M1-B514 P.O. Box 19024 Seattle, WA
    >> 98109-1024
    >> 
    >> E-mail: hpages at fhcrc.org Phone: (206) 667-5791 Fax: (206)
    >> 667-1319

    > -- 
    > Peter Dalgaard, Professor Center for Statistics,
    > Copenhagen Business School Solbjerg Plads 3, 2000
    > Frederiksberg, Denmark Phone: (+45)38153501 Email:
    > pd.mes at cbs.dk Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Thu Dec 15 14:05:43 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 15 Dec 2011 13:05:43 +0000
Subject: [Rd] Undocumented functions
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
Message-ID: <loom.20111215T140454-155@post.gmane.org>

Nicola Sturaro Sommacal <mailinglist <at> nicolasturaro.com> writes:

> 
> Hi!
> 
> I am building a package. This package will not submitted to CRAN.
> 
> I write the help files for the most important functions of my package, I
> cannot write it for all functions. This may sounds strange, but so there!
> 
> I know that all user-level functions should be documented, so I have to
> move my undocumented functions to a non-user-level. It's right?
> 
> To move my functions to a non-user-level I can write them as hidden
> functions, with a dot before the names. This require a very long check of
> my code to change the call to the function preceding it by a dot. So, this
> is not a real choice.
> There are other way to reach my purpose?
> 

  Read about name spaces; search for NAMESPACE or "name space" in the 
R extensions manual.
  Any function that is not exported from a package need not be documented.

  Ben Bolker


From jorismeys at gmail.com  Thu Dec 15 14:08:11 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 15 Dec 2011 14:08:11 +0100
Subject: [Rd] Undocumented functions
In-Reply-To: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
Message-ID: <CAO1zAVZC4qg_L4Qg4bNo-_T9w5PCAuEokOrpwemN5Au+LGhxrg@mail.gmail.com>

Use namespaces and only export the functions at the user level. The
rest will be hidden in the namespace and doesn't require a help page.
See 'Package Namespaces' in the manual Writing R Extensions.

Cheers


On Thu, Dec 15, 2011 at 1:01 PM, Nicola Sturaro Sommacal
<mailinglist at nicolasturaro.com> wrote:
> Hi!
>
> I am building a package. This package will not submitted to CRAN.
>
> I write the help files for the most important functions of my package, I
> cannot write it for all functions. This may sounds strange, but so there!
>
> I know that all user-level functions should be documented, so I have to
> move my undocumented functions to a non-user-level. It's right?
>
> To move my functions to a non-user-level I can write them as hidden
> functions, with a dot before the names. This require a very long check of
> my code to change the call to the function preceding it by a dot. So, this
> is not a real choice.
> There are other way to reach my purpose?
>
> Thank you very much for help.
>
> Sincerely,
> Nicola
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From sarah.goslee at gmail.com  Thu Dec 15 14:21:36 2011
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 15 Dec 2011 08:21:36 -0500
Subject: [Rd] Undocumented functions
In-Reply-To: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
Message-ID: <CAM_vjuk+785BXXXFK0+LcG53WaRL39J4FBbXXaFjLPFpn494Lw@mail.gmail.com>

Why not use package.skeleton() to construct empty help files?

But if you're determined to change the function names instead, grep and sed are
very useful tools for that sort of thing. (The OS versions, not the R grep()).

Sarah

On Thu, Dec 15, 2011 at 7:01 AM, Nicola Sturaro Sommacal
<mailinglist at nicolasturaro.com> wrote:
> Hi!
>
> I am building a package. This package will not submitted to CRAN.
>
> I write the help files for the most important functions of my package, I
> cannot write it for all functions. This may sounds strange, but so there!
>
> I know that all user-level functions should be documented, so I have to
> move my undocumented functions to a non-user-level. It's right?
>
> To move my functions to a non-user-level I can write them as hidden
> functions, with a dot before the names. This require a very long check of
> my code to change the call to the function preceding it by a dot. So, this
> is not a real choice.
> There are other way to reach my purpose?
>
> Thank you very much for help.
>
> Sincerely,
> Nicola

-- 
Sarah Goslee
http://www.functionaldiversity.org


From rpickeri at mail.nih.gov  Thu Dec 15 14:56:31 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Thu, 15 Dec 2011 05:56:31 -0800 (PST)
Subject: [Rd] problems with iconv
In-Reply-To: <F860B1FC-23B6-4F4D-A7D6-20FF324B8A91@gmail.com>
References: <1323796332274-4191177.post@n4.nabble.com>
	<4EE7A78E.7060401@stats.ox.ac.uk>
	<1323808345478-4191892.post@n4.nabble.com>
	<4EE7C608.9070906@statistik.tu-dortmund.de>
	<1323814212607-4192313.post@n4.nabble.com>
	<CAPPM_gSVHnGST-xN=ZDn2_bF_8NLcQpUEuY78+9CEzUPKSEoEA@mail.gmail.com>
	<1323872136574-4195139.post@n4.nabble.com>
	<CAPPM_gQZ59AhJjSYgQb4zoFnKvnhR3txPprZiJuYV0CXbON20w@mail.gmail.com>
	<1323888239574-4196455.post@n4.nabble.com>
	<F860B1FC-23B6-4F4D-A7D6-20FF324B8A91@gmail.com>
Message-ID: <1323957391803-4200071.post@n4.nabble.com>

> I put the header in the <R home>/include.  Was that right?

>Probably not. I would expect something like /usr/local/include, and maybe a
-I option to make sure it was >found before the Solaris-supplied one. Does
make install (for iconv) not do that for you?

Wow!  Thanks!  That was it!  I checked out /usr/local/include and the header
was there, but I'd uncommented a line in the config.site that caused it NOT
to look at /usr/local/include.  Re-commenting the line fixed that problem.

But now, Rsched will not compile from the rhome, though it does from the
rhome/src/unix directory.  So, it's like an onion.  You take a layer off and
cry - then repeat.  But, I'll make it.

Thanks again for your help!

Roger

--
View this message in context: http://r.789695.n4.nabble.com/problems-with-iconv-tp4191177p4200071.html
Sent from the R devel mailing list archive at Nabble.com.


From proebuck at mdanderson.org  Thu Dec 15 19:53:52 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Thu, 15 Dec 2011 12:53:52 -0600
Subject: [Rd] DESCRIPTION Suggests entry help
Message-ID: <CB0F9E60.25C2B%proebuck@mdanderson.org>

How should the Suggests entry be written in this case?

Have package that supports parallel processing available
for multiple R versions. Original package DESCRIPTION
Suggests entry only listed 'multicore' and life was good.

Since R-2.14+ includes 'parallel' package, thought I could
reference that on the Suggests entry too. But not so fast.
As it doesn't exist for previous versions of R, how can I
add this such that multiple R versions are supported? All
older version R CMD checks fail attempting to load 'parallel';
current R CMD checks complain if I leave it out of DESCRIPTION
but require('parallel') within source itself.


And although I'm pretty sure this isn't available, any syntax
to imply 'either this or that' package? Or 'this package with
R version'?


From ligges at statistik.tu-dortmund.de  Thu Dec 15 22:08:37 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 15 Dec 2011 22:08:37 +0100
Subject: [Rd] DESCRIPTION Suggests entry help
In-Reply-To: <CB0F9E60.25C2B%proebuck@mdanderson.org>
References: <CB0F9E60.25C2B%proebuck@mdanderson.org>
Message-ID: <4EEA61D5.1020902@statistik.tu-dortmund.de>

If it is only in the Suggests and you test for its existence before its 
usage, it should be OK.

For old R versions my CRAN checks set the nvironment variable:
_R_CHECK_FORCE_SUGGESTS_=FALSE

Best,
Uwe Ligges



On 15.12.2011 19:53, Roebuck,Paul L wrote:
> How should the Suggests entry be written in this case?
>
> Have package that supports parallel processing available
> for multiple R versions. Original package DESCRIPTION
> Suggests entry only listed 'multicore' and life was good.
>
> Since R-2.14+ includes 'parallel' package, thought I could
> reference that on the Suggests entry too. But not so fast.
> As it doesn't exist for previous versions of R, how can I
> add this such that multiple R versions are supported? All
> older version R CMD checks fail attempting to load 'parallel';
> current R CMD checks complain if I leave it out of DESCRIPTION
> but require('parallel') within source itself.
>
>
> And although I'm pretty sure this isn't available, any syntax
> to imply 'either this or that' package? Or 'this package with
> R version'?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Thu Dec 15 22:56:53 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 15 Dec 2011 13:56:53 -0800
Subject: [Rd] error starting R-devel with --arch ppc -- "an unusual
 circumstance has arisen"
Message-ID: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>

When I try and start R-devel as follows:

R --vanilla --arch ppc

I see this, over and over again, ^C does not interrupt it and I have
to close the terminal window:

> Error in paste0(prefix, conditionMessage(e), "\n") :
  not a BUILTIN function
In addition: Warning message:
An unusual circumstance has arisen in the nesting of readline input.
Please report using bug.report()
> Error in paste0(prefix, conditionMessage(e), "\n") :
  not a BUILTIN function
In addition: Warning message:
An unusual circumstance has arisen in the nesting of readline input.
Please report using bug.report()

I can't get to sessionInfo() but here is sessionInfo() of the same R
invoked with no --arch argument:

R Under development (unstable) (2011-12-14 r57899)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


This seems to be related to the issue I reported here previously:
https://stat.ethz.ch/pipermail/r-devel/2011-December/062793.html


Thanks,
Dan


From hpages at fhcrc.org  Fri Dec 16 00:32:01 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 15 Dec 2011 15:32:01 -0800
Subject: [Rd] bug in sum() on integer vector
In-Reply-To: <4EE88F12.3050509@gmail.com>
References: <4EE25637.1020404@fhcrc.org> <4EE2640D.3030402@gmail.com>
	<4EE280A7.3000204@fhcrc.org> <4EE35E4E.6050703@gmail.com>
	<4EE7E298.1040107@fhcrc.org> <4EE88F12.3050509@gmail.com>
Message-ID: <4EEA8371.2090205@fhcrc.org>

Hi Duncan,

On 11-12-14 03:57 AM, Duncan Murdoch wrote:
> On 11-12-13 6:41 PM, Herv? Pag?s wrote:
>> Hi Duncan,
>>
>> On 11-12-10 05:27 AM, Duncan Murdoch wrote:
>>> On 11-12-09 4:41 PM, Herv? Pag?s wrote:
>>>> Hi Duncan,
>>>>
>>>> On 11-12-09 11:39 AM, Duncan Murdoch wrote:
>>>>> On 09/12/2011 1:40 PM, Herv? Pag?s wrote:
>>>>>> Hi,
>>>>>>
>>>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>>>>
>>>>>> This is correct:
>>>>>>
>>>>>>> sum(as.double(x))
>>>>>> [1] 0
>>>>>>
>>>>>> This is not:
>>>>>>
>>>>>>> sum(x)
>>>>>> [1] 4996000
>>>>>>
>>>>>> Returning NA (with a warning) would also be acceptable for the
>>>>>> latter.
>>>>>> That would make it consistent with cumsum(x):
>>>>>>
>>>>>>> cumsum(x)[length(x)]
>>>>>> [1] NA
>>>>>> Warning message:
>>>>>> Integer overflow in 'cumsum'; use 'cumsum(as.numeric(.))'
>>>>>
>>>>> This is a 64 bit problem; in 32 bits things work out properly.
>>>>> I'd guess
>>>>> in 64 bit arithmetic we or the run-time are doing something to
>>>>> simulate
>>>>> 32 bit arithmetic (since integers are 32 bits), but it looks as though
>>>>> we're not quite getting it right.
>>>>
>>>> It doesn't work properly for me on Leopard (32-bit mode):
>>>>
>>>>> x<- c(rep(1800000003L, 10000000), -rep(1200000002L, 15000000))
>>>>> sum(as.double(x))
>>>> [1] 0
>>>>> sum(x)
>>>> [1] 4996000
>>>>> sessionInfo()
>>>> R version 2.14.0 RC (2011-10-27 r57452)
>>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] C
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> It looks like the problem is that isum() (in src/main/summary.c)
>>>> uses a 'double' internally to do the sum, whereas rsum() and csum()
>>>> use a 'long double'.
>>>
>>> A double has 53 bits to store the mantissa, so any 32 bit integer can be
>>> stored exactly.
>>>
>>>>
>>>> Note that isum() seems to be assuming that NA_INTEGER and NA_LOGICAL
>>>> will always be the same (probably fine) and that TRUE values in the
>>>> input vector are always represented as a 1 (not so sure about this
>>>> one).
>>>>
>>>> A more fundamental question: is switching back and forth between
>>>> 'int' and 'double' (or 'long double') the right thing to do for doing
>>>> "safe" arithmetic on integers?
>>>
>>> If you have enough terms in the sum that an intermediate value exceeds
>>> 53 bits in length, then you'll get the wrong answer, because the
>>> intermediate sum can't be stored exactly. That happens in your example.
>>> On the 32 bit platform I tested (Windows 32 bit), intermediate values
>>> are stored in registers with 64 bit precision, which is probably why
>>> Windows 32 bit gets it right, but various other platforms don't.
>>>
>>> On your fundamental question: I think the answer is that R is doing the
>>> right thing. R doesn't think of an integer as a particular
>>> representation, it thinks of it as a number. So if you ask for the sum
>>> of those numbers, R should return its best approximation to that sum,
>>> and it does.
>>
>> It does, really? Seems like returning 0 would be a better approximation
>> ;-) And with the argument that "R doesn't think of an integer as a
>> particular representation" then there is no reason why sum(x)
>> would get it wrong and sum(as.double(x)) would get it right. Also why
>> bother having an integer type in R?
>>
>> Seriously, I completely disagree with your view (hopefully it's only
>> yours, and not an R "feature") that it's ok for integer arithmetic to
>> return an approximation. It should always return the correct value or
>> fail.
>
> I think you need to be more specific in your design, because the function
>
> `+` <- function(x,y) stop("fail")

Interesting. At least this program is *correct*, strictly speaking.
Which doesn't mean that it is useful. This one too is correct:

   `+` <- function(x,y) {
            warning("cannot sum 'x' and 'y' - returning NA")
            NA
          }

But this one is *not* correct:

   `+` <- function(x,y) {set.seed(4); return(some_random_number())}

because sometimes it returns the wrong answer ;-) (which is more or
less what sum() does on an integer vector at the moment).

>
> meets your specs. I think the following requirements are all desirable,
> but I don't think they can all be met at the same time:
>
> 1. Return the exactly correct answer in all (or even nearly all) of the
> cases where the current code returns the correct answer.
>
> 2. Do it as quickly (or nearly as quickly) as the current code.
>
> 3. Do it without requiring much more memory than the current code does.
>
> 4. Never return an incorrect answer.
>
> If you think I'm wrong, show me.

I agree that you can't have it all but IMO correctness should have a
higher priority than speed or memory usage considerations. Quoting
my previous boss (someone you know): "There are many fast and memory
efficient ways to compute the wrong result". Just before people in
the meeting room were about to start passionate discussions about the
respective merits of those fast, efficient, but unfortunately incorrect
ways.

Cheers,
H.

>
> Duncan Murdoch
>
> This is one of the reasons why programmers use integers and not
>> floating point numbers (memory usage being another one). Integers are
>> used for indexing elements in an array or for shifting pointers at the
>> C-level. The idea that integer arithmetic can be approximate is scary.
>>
>> Cheers,
>> H.
>>
>>>
>>> A different approach would be to do the sum in 32 bit registers and
>>> detect 32 bit overflow in intermediate results. But that's a very
>>> hardware-oriented approach, rather than a mathematical approach.
>>>
>>> Duncan Murdoch
>>>
>>>> Thanks!
>>>> H.
>>>>
>>>>
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>> Thanks!
>>>>>> H.
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 2.14.0 (2011-10-31)
>>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C
>>>>>> [3] LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8
>>>>>> [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8
>>>>>> [7] LC_PAPER=C LC_NAME=C
>>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From mtmorgan at fhcrc.org  Fri Dec 16 00:34:52 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 15 Dec 2011 15:34:52 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
Message-ID: <4EEA841C.5060709@fhcrc.org>

In

 > R.version.string
[1] "R Under development (unstable) (2011-12-15 r57901)"

section 1.6.6 of 'Writing R Extensions' says

   Note that exporting methods on a generic in the namespace will
   also export the generic, and exporting a generic in the
   namespace will also export its methods.

and

   Note that importMethodsFrom will also import any generics defined in
   the namespace on those methods

However, if PkgA promotes 'unique' to a generic and exports that

   DESCRIPTION:
   Imports: methods

   R/f.R:
   setGeneric("unique")

   NAMESPACE:
   export(unique)

and PkgB creates and exports a method on unique

   DESCRIPTION
   Imports: methods, PkgA

   R/f.R:
   setClass("B", representation(b="numeric"))
   setMethod(unique, "B",
             function(x, incomparables=FALSE, ...) unique(x at b))

   NAMESPACE:
   importFrom(PkgA, unique)
   exportClasses(B)
   exportMethods(unique)

and PkgC wants to import PkgB's classes and methods

   DESCRIPTION
   Imports: methods, PkgB

   R/f.R
   cunique <- function(x) unique(x)

   NAMESPACE
   importMethodsFrom(PkgB, unique)
   export(cunique)

then

(a) the 'unique' generic is not available to the user of PkgB

 > library(PkgB)
 > unique(new("B", b=1:5))
Error in unique.default(new("B", b = 1:5)) :
   unique() applies only to vectors

and (b) the generic has not been imported to PkgC's namespace

 > cunique(new("B", b=1:5))
Error in unique.default(b) : unique() applies only to vectors

A workaround is for PkgB to also export(unique), and for PkgC to also 
importFrom(PkgA, unique), but is this the intention?

This is arising from Bioconductor efforts to place commonly promoted 
functions and S3 classes into a single package, to avoid conflicts when 
the same function is promoted independently by several packages.

Martin
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Fri Dec 16 00:40:16 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 15 Dec 2011 15:40:16 -0800
Subject: [Rd] R CMD check fails to warn about undocumented classes and
	methods
Message-ID: <4EEA8560.9020102@fhcrc.org>

In

 > R.version.string
[1] "R Under development (unstable) (2011-12-15 r57901)"

PkgA promotes 'unique' to a generic and exports that

   DESCRIPTION:
   Imports: methods

   R/f.R:
   setGeneric("unique")

   NAMESPACE:
   export(unique)

and PkgB creates and exports a method on unique

   DESCRIPTION
   Imports: methods, PkgA

   R/f.R:
   setClass("B", representation(b="numeric"))
   setMethod(unique, "B",
             function(x, incomparables=FALSE, ...) unique(x at b))

   NAMESPACE:
   importFrom(PkgA, unique)
   exportClasses(B)
   exportMethods(unique)

There is a man/ page for each package, but no other documentation. Yet

    R CMD check PkgA_1.0.tar.gz

says

* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK

and for Pkg B we only get

* checking for missing documentation entries ... WARNING
Undocumented code objects:
   ?bunique?
All user-level objects in a package should have documentation entries.
See the chapter 'Writing R documentation files' in the 'Writing R
Extensions' manual.
* checking for code/documentation mismatches ... OK

Martin
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Fri Dec 16 00:46:27 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 15 Dec 2011 15:46:27 -0800
Subject: [Rd] R CMD check fails to warn about undocumented classes and
 methods
In-Reply-To: <4EEA8560.9020102@fhcrc.org>
References: <4EEA8560.9020102@fhcrc.org>
Message-ID: <4EEA86D3.1000203@fhcrc.org>

On 12/15/2011 03:40 PM, Martin Morgan wrote:
> In
>
>  > R.version.string
> [1] "R Under development (unstable) (2011-12-15 r57901)"
>
> PkgA promotes 'unique' to a generic and exports that
>
> DESCRIPTION:
> Imports: methods
>
> R/f.R:
> setGeneric("unique")
>
> NAMESPACE:
> export(unique)
>
> and PkgB creates and exports a method on unique
>
> DESCRIPTION
> Imports: methods, PkgA
>
> R/f.R:
> setClass("B", representation(b="numeric"))
> setMethod(unique, "B",
> function(x, incomparables=FALSE, ...) unique(x at b))

this also has

   bunique <- function(b) unique(b)

> NAMESPACE:
> importFrom(PkgA, unique)
> exportClasses(B)
> exportMethods(unique)

and

   export(bunique)

>
> There is a man/ page for each package, but no other documentation. Yet
>
> R CMD check PkgA_1.0.tar.gz
>
> says
>
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
>
> and for Pkg B we only get
>
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
> ?bunique?
> All user-level objects in a package should have documentation entries.
> See the chapter 'Writing R documentation files' in the 'Writing R
> Extensions' manual.
> * checking for code/documentation mismatches ... OK
>
> Martin


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From simon.urbanek at r-project.org  Fri Dec 16 01:46:01 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Dec 2011 19:46:01 -0500
Subject: [Rd] error starting R-devel with --arch ppc -- "an unusual
	circumstance has arisen"
In-Reply-To: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>
References: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>
Message-ID: <CDE00E64-F91A-4508-AC59-43668557DB63@r-project.org>

Dan,

I don't know why, but something is off in the recent R-devel build for ppc. The result is that the installed binary ppc is older than the other ones, so it doesn't have paste0 while the others do.

The really strange thing is that the build logs show success, but the build directory is old and the resulting tar ball is not updated. I'll keep you posted.

Cheers,
Simon



On Dec 15, 2011, at 4:56 PM, Dan Tenenbaum wrote:

> When I try and start R-devel as follows:
> 
> R --vanilla --arch ppc
> 
> I see this, over and over again, ^C does not interrupt it and I have
> to close the terminal window:
> 
>> Error in paste0(prefix, conditionMessage(e), "\n") :
>  not a BUILTIN function
> In addition: Warning message:
> An unusual circumstance has arisen in the nesting of readline input.
> Please report using bug.report()
>> Error in paste0(prefix, conditionMessage(e), "\n") :
>  not a BUILTIN function
> In addition: Warning message:
> An unusual circumstance has arisen in the nesting of readline input.
> Please report using bug.report()
> 
> I can't get to sessionInfo() but here is sessionInfo() of the same R
> invoked with no --arch argument:
> 
> R Under development (unstable) (2011-12-14 r57899)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
> 
> locale:
> [1] C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> This seems to be related to the issue I reported here previously:
> https://stat.ethz.ch/pipermail/r-devel/2011-December/062793.html
> 
> 
> Thanks,
> Dan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From d.scott at auckland.ac.nz  Fri Dec 16 10:51:11 2011
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri, 16 Dec 2011 22:51:11 +1300
Subject: [Rd] Undocumented functions
In-Reply-To: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
Message-ID: <4EEB148F.1090802@auckland.ac.nz>

One easy way is to list the undocumented files in pkg-internal.Rd. From 
the Writing R Extensions manual:

Note that all user-level objects in a package should be documented; if a 
package pkg contains user-level objects which are for ?internal? use 
only, it should provide a file pkg-internal.Rd which documents all such 
objects, and clearly states that these are not meant to be called by the 
user. See e.g. the sources for package *grid* in the R distribution for 
an example.

Probably a perverse use of this facility, but it works, and will even 
allow the package to pass check.

David Scott


On 16/12/2011 1:01 a.m., Nicola Sturaro Sommacal wrote:
> Hi!
>
> I am building a package. This package will not submitted to CRAN.
>
> I write the help files for the most important functions of my package, I
> cannot write it for all functions. This may sounds strange, but so there!
>
> I know that all user-level functions should be documented, so I have to
> move my undocumented functions to a non-user-level. It's right?
>
> To move my functions to a non-user-level I can write them as hidden
> functions, with a dot before the names. This require a very long check of
> my code to change the call to the function preceding it by a dot. So, this
> is not a real choice.
> There are other way to reach my purpose?
>
> Thank you very much for help.
>
> Sincerely,
> Nicola
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018


From maechler at stat.math.ethz.ch  Fri Dec 16 11:02:45 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Dec 2011 11:02:45 +0100
Subject: [Rd] R CMD check fails to warn about undocumented classes and
 methods
In-Reply-To: <4EEA86D3.1000203@fhcrc.org>
References: <4EEA8560.9020102@fhcrc.org>
	<4EEA86D3.1000203@fhcrc.org>
Message-ID: <20203.5957.7651.175889@stat.math.ethz.ch>

> On 12/15/2011 03:40 PM, Martin Morgan wrote:
> > In
> >
> >  > R.version.string
> > [1] "R Under development (unstable) (2011-12-15 r57901)"
> >
> > PkgA promotes 'unique' to a generic and exports that
> >
> > DESCRIPTION:
> > Imports: methods
> >
> > R/f.R:
> > setGeneric("unique")
> >
> > NAMESPACE:
> > export(unique)
> >
> > and PkgB creates and exports a method on unique
> >
> > DESCRIPTION
> > Imports: methods, PkgA
> >
> > R/f.R:
> > setClass("B", representation(b="numeric"))
> > setMethod(unique, "B",
> > function(x, incomparables=FALSE, ...) unique(x at b))
> 
> this also has
> 
>    bunique <- function(b) unique(b)
> 
> > NAMESPACE:
> > importFrom(PkgA, unique)
> > exportClasses(B)
> > exportMethods(unique)
> 
> and
> 
>    export(bunique)
> 
> >
> > There is a man/ page for each package, but no other documentation. Yet
> >
> > R CMD check PkgA_1.0.tar.gz
> >
> > says
> >
> > * checking for missing documentation entries ... OK
> > * checking for code/documentation mismatches ... OK
> >
> > and for Pkg B we only get
> >
> > * checking for missing documentation entries ... WARNING
> > Undocumented code objects:
> > ?bunique?
> > All user-level objects in a package should have documentation entries.
> > See the chapter 'Writing R documentation files' in the 'Writing R
> > Extensions' manual.
> > * checking for code/documentation mismatches ... OK
> >
> > Martin Morgan

Thank you, Martin.
I don't have time to delve into this, before Monday, but I agree 
that things could/should be improved.

Two quick questions/requests:

1) Is this new in R-2.14.x or R-devel, but does not happen
   earlier  ?

2) As the 'R-devel' list allows attachments of MIME type
   application/x-tar
   application/x-compressed-tar
   application/x-gzip
it would be most convenient to most readers of this list, and
notably to R core members, if you included the packages maybe
as one *.tar containing the two <pkg>.tar.gz files.

Martin Maechler, ETH Zurich


From maechler at stat.math.ethz.ch  Fri Dec 16 11:50:07 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Dec 2011 11:50:07 +0100
Subject: [Rd] Undocumented functions
In-Reply-To: <4EEB148F.1090802@auckland.ac.nz>
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
	<4EEB148F.1090802@auckland.ac.nz>
Message-ID: <20203.8799.852966.833885@stat.math.ethz.ch>

>>>>> David Scott <d.scott at auckland.ac.nz>
>>>>>     on Fri, 16 Dec 2011 22:51:11 +1300 writes:

    > One easy way is to list the undocumented files in
    > pkg-internal.Rd. From the Writing R Extensions manual:

    > Note that all user-level objects in a package should be
    > documented; if a package pkg contains user-level objects
    > which are for ?internal? use only, it should provide a
    > file pkg-internal.Rd which documents all such objects, and
    > clearly states that these are not meant to be called by
    > the user. See e.g. the sources for package *grid* in the R
    > distribution for an example.

    > Probably a perverse use of this facility, but it works,
    > and will even allow the package to pass check.

    > David Scott

Excuse me David,
but I think the above actually is pre-R-2.14.x advice.

Now that every (installed) package has a NAMESPACE anyway,
package authors really should use a NAMESPACE themselves
(instead of the "auto-generated at installation-time" one)
and export the non-internal function

Martin


    > On 16/12/2011 1:01 a.m., Nicola Sturaro Sommacal wrote:
    >> Hi!
    >> 
    >> I am building a package. This package will not submitted
    >> to CRAN.
    >> 
    >> I write the help files for the most important functions
    >> of my package, I cannot write it for all functions. This
    >> may sounds strange, but so there!
    >> 
    >> I know that all user-level functions should be
    >> documented, so I have to move my undocumented functions
    >> to a non-user-level. It's right?
    >> 
    >> To move my functions to a non-user-level I can write them
    >> as hidden functions, with a dot before the names. This
    >> require a very long check of my code to change the call
    >> to the function preceding it by a dot. So, this is not a
    >> real choice.  There are other way to reach my purpose?
    >> 
    >> Thank you very much for help.
    >> 
    >> Sincerely, Nicola

    > -- 
    > _________________________________________________________________
    > David Scott Department of Statistics The University of
    > Auckland, PB 92019 Auckland 1142, NEW ZEALAND Phone: +64 9
    > 923 5055, or +64 9 373 7599 ext 85055 Email:
    > d.scott at auckland.ac.nz, Fax: +64 9 373 7018


From mailinglist at nicolasturaro.com  Fri Dec 16 12:11:53 2011
From: mailinglist at nicolasturaro.com (Nicola Sturaro Sommacal)
Date: Fri, 16 Dec 2011 12:11:53 +0100
Subject: [Rd] Undocumented functions
In-Reply-To: <20203.8799.852966.833885@stat.math.ethz.ch>
References: <CAM8ViJPmS_zJzsT54ymj7OZOFUXAKwsCz=Qs9ckk2ESLrr-mrw@mail.gmail.com>
	<4EEB148F.1090802@auckland.ac.nz>
	<20203.8799.852966.833885@stat.math.ethz.ch>
Message-ID: <CAM8ViJPtiG61w90eGZ76G1E=EWRXq2_8jmo4DKRu4AdJNgqB6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111216/d834c680/attachment.pl>

From dadler at uni-goettingen.de  Fri Dec 16 13:36:24 2011
From: dadler at uni-goettingen.de (Daniel Adler)
Date: Fri, 16 Dec 2011 13:36:24 +0100
Subject: [Rd] makeNamespace and rdyncall
Message-ID: <E176A8C3-6428-4AAA-9840-ACA09C314D26@uni-goettingen.de>

Dear R Core Team,

I have a question related to the programming interface for namespace object creation at run-time.

This is something that I need in the rdyncall package:
During the dynamic linkage binding of a shared C library, an R namespace object is created 
that gets populated with call wrappers, symbolic constants and type information objects. 

For example,

> dynport(SDL) # create namespace, populated with wrappers to SDL library 
> search()     # gives a "package:SDL" populated with all kinds of wrappers to the C functions, etc..
[1] ".GlobalEnv"        "package:SDL"  

I was trying various alternatives to get package-behaviour implemented in transparent manner for the end-user.

The current version uses real namespace environments with all sorts of advantages such as support for
search(), detach() and '::'.

Namespace object have certain conventions for fields, and there is currently no
public interface available in 'base' for setting up such objects;
The function "makeNamespace" in src/library/base/namespace.R is defined as local function to "loadNamespace".
So I go about this problem by 'copying' the code.

Recently, R-2.14 introduced a new mandatory field 'lazyData' which mades rdyncall broken.
(By re-synchronizing with 'makeNamespace' it has been fixed in 0.7.4.)

Would it be possible and feasible to make namespace-related management functions such as makeNamespace and sealNamespace
available as an public accessible interface? Or at least accessible via ':::' ?

I would also appreciate any hint/idea for alternative ways to implement the above described behaviour.

Here is the link to the code used for creation of dynamic C binding namespaces: http://dyncall.org/svn/dyncall/trunk/bindings/R/rdyncall/R/dynport.R

best wishes,
- Daniel


From hadley at rice.edu  Fri Dec 16 14:11:10 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 16 Dec 2011 08:11:10 -0500
Subject: [Rd] makeNamespace and rdyncall
In-Reply-To: <E176A8C3-6428-4AAA-9840-ACA09C314D26@uni-goettingen.de>
References: <E176A8C3-6428-4AAA-9840-ACA09C314D26@uni-goettingen.de>
Message-ID: <CABdHhvFcW0SfsNaPtFQKC_dnxWfgCDfeugsxHLuiht6fMPKuzg@mail.gmail.com>

This is also something I'd appreciate for the devtools package.
Hadley

On Fri, Dec 16, 2011 at 7:36 AM, Daniel Adler <dadler at uni-goettingen.de> wrote:
> Dear R Core Team,
>
> I have a question related to the programming interface for namespace object creation at run-time.
>
> This is something that I need in the rdyncall package:
> During the dynamic linkage binding of a shared C library, an R namespace object is created
> that gets populated with call wrappers, symbolic constants and type information objects.
>
> For example,
>
>> dynport(SDL) # create namespace, populated with wrappers to SDL library
>> search() ? ? # gives a "package:SDL" populated with all kinds of wrappers to the C functions, etc..
> [1] ".GlobalEnv" ? ? ? ?"package:SDL"
>
> I was trying various alternatives to get package-behaviour implemented in transparent manner for the end-user.
>
> The current version uses real namespace environments with all sorts of advantages such as support for
> search(), detach() and '::'.
>
> Namespace object have certain conventions for fields, and there is currently no
> public interface available in 'base' for setting up such objects;
> The function "makeNamespace" in src/library/base/namespace.R is defined as local function to "loadNamespace".
> So I go about this problem by 'copying' the code.
>
> Recently, R-2.14 introduced a new mandatory field 'lazyData' which mades rdyncall broken.
> (By re-synchronizing with 'makeNamespace' it has been fixed in 0.7.4.)
>
> Would it be possible and feasible to make namespace-related management functions such as makeNamespace and sealNamespace
> available as an public accessible interface? Or at least accessible via ':::' ?
>
> I would also appreciate any hint/idea for alternative ways to implement the above described behaviour.
>
> Here is the link to the code used for creation of dynamic C binding namespaces: http://dyncall.org/svn/dyncall/trunk/bindings/R/rdyncall/R/dynport.R
>
> best wishes,
> - Daniel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From friendly at yorku.ca  Fri Dec 16 14:46:29 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 16 Dec 2011 08:46:29 -0500
Subject: [Rd] R package BibTex entries: looking for a more general
	solution
Message-ID: <4EEB4BB5.8060905@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111216/60b1ec86/attachment.pl>

From mtmorgan at fhcrc.org  Fri Dec 16 15:05:34 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 16 Dec 2011 06:05:34 -0800
Subject: [Rd] R CMD check fails to warn about undocumented classes and
 methods
In-Reply-To: <20203.5957.7651.175889@stat.math.ethz.ch>
References: <4EEA8560.9020102@fhcrc.org>	<4EEA86D3.1000203@fhcrc.org>
	<20203.5957.7651.175889@stat.math.ethz.ch>
Message-ID: <4EEB502E.9080907@fhcrc.org>

On 12/16/2011 02:02 AM, Martin Maechler wrote:
>> On 12/15/2011 03:40 PM, Martin Morgan wrote:
>>> In
>>>
>>>   >  R.version.string
>>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>>
>>> PkgA promotes 'unique' to a generic and exports that
>>>
>>> DESCRIPTION:
>>> Imports: methods
>>>
>>> R/f.R:
>>> setGeneric("unique")
>>>
>>> NAMESPACE:
>>> export(unique)
>>>
>>> and PkgB creates and exports a method on unique
>>>
>>> DESCRIPTION
>>> Imports: methods, PkgA
>>>
>>> R/f.R:
>>> setClass("B", representation(b="numeric"))
>>> setMethod(unique, "B",
>>> function(x, incomparables=FALSE, ...) unique(x at b))
>>
>> this also has
>>
>>     bunique<- function(b) unique(b)
>>
>>> NAMESPACE:
>>> importFrom(PkgA, unique)
>>> exportClasses(B)
>>> exportMethods(unique)
>>
>> and
>>
>>     export(bunique)
>>
>>>
>>> There is a man/ page for each package, but no other documentation. Yet
>>>
>>> R CMD check PkgA_1.0.tar.gz
>>>
>>> says
>>>
>>> * checking for missing documentation entries ... OK
>>> * checking for code/documentation mismatches ... OK
>>>
>>> and for Pkg B we only get
>>>
>>> * checking for missing documentation entries ... WARNING
>>> Undocumented code objects:
>>> ?bunique?
>>> All user-level objects in a package should have documentation entries.
>>> See the chapter 'Writing R documentation files' in the 'Writing R
>>> Extensions' manual.
>>> * checking for code/documentation mismatches ... OK
>>>
>>> Martin Morgan
>
> Thank you, Martin.
> I don't have time to delve into this, before Monday, but I agree
> that things could/should be improved.
>
> Two quick questions/requests:
>
> 1) Is this new in R-2.14.x or R-devel, but does not happen
>     earlier  ?

Earlier (2-11, 2-13, 2-14 & devel checked)

>
> 2) As the 'R-devel' list allows attachments of MIME type
>     application/x-tar
>     application/x-compressed-tar
>     application/x-gzip
> it would be most convenient to most readers of this list, and
> notably to R core members, if you included the packages maybe
> as one *.tar containing the two<pkg>.tar.gz files.

Attached.

Thanks Martin, Martin

>
> Martin Maechler, ETH Zurich


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793
-------------- next part --------------
A non-text attachment was scrubbed...
Name: PkgAB.tar
Type: application/x-tar
Size: 1614 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111216/e0bb7fd0/attachment.tar>

From mtmorgan at fhcrc.org  Fri Dec 16 15:16:55 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 16 Dec 2011 06:16:55 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEA841C.5060709@fhcrc.org>
References: <4EEA841C.5060709@fhcrc.org>
Message-ID: <4EEB52D7.9010207@fhcrc.org>

tar of Pkgs A, B, C attached. Martin

On 12/15/2011 03:34 PM, Martin Morgan wrote:
> In
>
>  > R.version.string
> [1] "R Under development (unstable) (2011-12-15 r57901)"
>
> section 1.6.6 of 'Writing R Extensions' says
>
> Note that exporting methods on a generic in the namespace will
> also export the generic, and exporting a generic in the
> namespace will also export its methods.
>
> and
>
> Note that importMethodsFrom will also import any generics defined in
> the namespace on those methods
>
> However, if PkgA promotes 'unique' to a generic and exports that
>
> DESCRIPTION:
> Imports: methods
>
> R/f.R:
> setGeneric("unique")
>
> NAMESPACE:
> export(unique)
>
> and PkgB creates and exports a method on unique
>
> DESCRIPTION
> Imports: methods, PkgA
>
> R/f.R:
> setClass("B", representation(b="numeric"))
> setMethod(unique, "B",
> function(x, incomparables=FALSE, ...) unique(x at b))
>
> NAMESPACE:
> importFrom(PkgA, unique)
> exportClasses(B)
> exportMethods(unique)
>
> and PkgC wants to import PkgB's classes and methods
>
> DESCRIPTION
> Imports: methods, PkgB
>
> R/f.R
> cunique <- function(x) unique(x)
>
> NAMESPACE
> importMethodsFrom(PkgB, unique)
> export(cunique)
>
> then
>
> (a) the 'unique' generic is not available to the user of PkgB
>
>  > library(PkgB)
>  > unique(new("B", b=1:5))
> Error in unique.default(new("B", b = 1:5)) :
> unique() applies only to vectors
>
> and (b) the generic has not been imported to PkgC's namespace
>
>  > cunique(new("B", b=1:5))
> Error in unique.default(b) : unique() applies only to vectors
>
> A workaround is for PkgB to also export(unique), and for PkgC to also
> importFrom(PkgA, unique), but is this the intention?
>
> This is arising from Bioconductor efforts to place commonly promoted
> functions and S3 classes into a single package, to avoid conflicts when
> the same function is promoted independently by several packages.
>
> Martin


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793
-------------- next part --------------
A non-text attachment was scrubbed...
Name: PkgABC.tar
Type: application/x-tar
Size: 2270 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111216/4803470d/attachment.tar>

From Achim.Zeileis at uibk.ac.at  Fri Dec 16 15:51:01 2011
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 16 Dec 2011 14:51:01 +0000 (GMT)
Subject: [Rd] R package BibTex entries: looking for a more general
	solution
In-Reply-To: <4EEB4BB5.8060905@yorku.ca>
References: <4EEB4BB5.8060905@yorku.ca>
Message-ID: <alpine.DEB.2.02.1112161444360.22726@paninaro.uibk.ac.at>

Michael,

meanwhile the "bibentry" class that Kurt mentioned back in the discussion 
in 2010 is fully implemented in R. Hence the code can be simplified when 
working with the "bibentry" objects directly (instead of the "Bibtex" 
objects derived from them).

I've quickly hacked some code to illustrate how the function needs to be 
modified but I didn't have the time to integrate it into the function
(I'm currently traveling).

   ## query packages and their bibentries
? pkgs <- unique(installed.packages()[,1])
? bibs <- lapply(pkgs, function(x) try(citation(x)))

   ## exclude those with errors
? ok <- !(sapply(bibs, class) == "try-error")
? pkgs <- pkgs[ok]
? bibs <- bibs[ok]

   ## number of bibentries per package
   nref <- sapply(bibs, length)

   ## merge all bibentries
   bibs <- do.call("c", bibs)

   ## add citation keys
   bibkeys <- lapply(1:length(nref), function(i)
     if(nref[i] > 1) paste(pkgs[i], 1:nref[i], sep = ":") else pkgs[i])
   bibs$key <- as.list(unlist(bibkeys))

And then you just need to say toBibtex(bibs) or writeLines(toBibtex(bibs)) 
or something along those lines.

For more details on the new classes, see this recent working paper by Kurt 
Duncan and myself: http://epub.wu.ac.at/3269/.

So much for today.
Best wishes,
Z

On Fri, 16 Dec 2011, Michael Friendly wrote:

> Back in 2010 I raised this issue, and there was some discussion,
> 
> https://stat.ethz.ch/pipermail/r-devel/2010-November/058987.html
> 
> The goal, then, as now is to have a way to produce a bibtex-clean .bib file
> (i.e., not requiring
> manual editing except in unusual circumstances) reflecting installed
> packages
> for use in writing where one often needs/wants to cite all packages used in
> a given article.
> 
> Achim wrote the function below? which largely does this job, quite nicely
> now that most
> DESCRIPTION files now contain Authors at R fields.? However, something changed
> since
> R 2.11.1 when I tried this last, so that the function no longer generates
> keys for packages
> which contain more than one citation.
> 
> I've tried debugging with browser(), but can't figure out how to make the
> lines around FIXME
> work.? Can someone help?
> 
> You can see the result from this at
> http://euclid.psych.yorku.ca/SCS/Private/Rbibs/Rpackages-2.14.0.bib
> The function is also at:
> 
> # Original code by Achim Zeileis, 16 Dec 2009, R-help
> # Added: support header and preamble
> 
> Rpackages.bib <- function(filename = paste("Rpackages-",getRversion(),
> ".bib", sep=""),
> ??? ??? header=TRUE, preamble=NULL, suppress.warnings=TRUE, verbose = TRUE)
> {
> ? ## installed packages
> ? pkgs <- unique(installed.packages()[,1])
> ? if (suppress.warnings) warn <- options(warn=-1)
> ? bibs <- lapply(pkgs, function(x) try(toBibtex(citation(x))))
> ? if (suppress.warnings) options(warn)
> ?
> ? n.installed <- length(bibs)
> 
> ? ## omit failed citation calls
> ? ok <- !(sapply(bibs, class) == "try-error")
> ? pkgs <- pkgs[ok]
> ? bibs <- bibs[ok]
> ? n.converted <- sum(ok)
> ? ## unify to list of Bibtex
> ? bibs <- lapply(bibs, function(x) if(inherits(x, "Bibtex")) list(x) else x)
> 
> ? ## FIXME: add bibtex keys to each entry [the line below does not work!!]
> ? pkgs <- lapply(seq_along(pkgs), function(i) if(length(bibs[[i]]) > 1)
> ??? paste(pkgs[i], 1:length(bibs[[i]]), sep = "") else pkgs[i])
> ? pkgs <- do.call("c", pkgs)
> ? bibs <- do.call("c", bibs)
> ? for(i in seq_along(pkgs)) bibs[[i]][1] <-
> ??? gsub("{,", paste("{", pkgs[i], ",", sep = ""), bibs[[i]][1], fixed =
> TRUE)
> 
> ??? if(header) header <- gsub("^", "%", toLatex(sessionInfo()))
> ??? output <- file(filename, "a")
> ??? cat(header, preamble, sep='\n', file=output, append=TRUE)
> ? ## write everything to a single .bib file
> ? writeLines(do.call("c", lapply(bibs, as.character)), con=output)
> ? close(output)
> ? if(verbose) cat("Converted", n.converted, "of", n.installed,
> ??? "package citations to BibTeX",
> ??? "\nResults written to file", filename, "\n")
> 
> ? ## return Bibtex items invisibly
> ? invisible(bibs)
> }
> 
> 
> 
> 
> 
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca 
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
>

From jmc at r-project.org  Fri Dec 16 21:19:48 2011
From: jmc at r-project.org (John Chambers)
Date: Fri, 16 Dec 2011 12:19:48 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEB52D7.9010207@fhcrc.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
Message-ID: <4EEBA7E4.70802@r-project.org>

The subject heading is correct if referring to  exportMethods() and 
importMethodsFrom().  They refer to the methods tables, not the generic 
functions, whatever the extensions manual says.

Looking into the code of namespaceImportMethods() will illustrate this. 
  It just deals with lists of method tables obtained from .getGenerics() 
which in spite of its name also only looks for the method table metadata 
objects.

As I vaguely recall, there was some concern at one time about having 
extra copies of the generic version of the function.

The fundamental problem is that creating methods for unique(), say, does 
not change the way calls to base::unique() work.  Therefore, all 
packages that want to use methods have to ensure that a generic version 
of unique gets in between.   Primitive functions are an exception 
because the method dispatch is in the C code and has a rule for checking 
when given an S4 object.  There is no corresponding provision for 
evaluating a call to a regular function.

If the importing package has a setGeneric() for the relevant function 
then its own namespace has the generic version of the function.  (That 
is a workaround, but I inferred that was what you were trying to avoid.)

Fixes seem possible, but some care is needed.  If exportMethods 
automatically exported the generic function, it really is no different 
from export() for that function.

namespaceImportMethods() could try to supply the generic function if it 
is not already present.  If it does not find the generic in the 
namespace being imported, it would essentially have to call 
setGeneric(), assuming the non-generic function exists in the specified 
package (e.g., in base for unique()).

Comments?
   John



On 12/16/11 6:16 AM, Martin Morgan wrote:
> tar of Pkgs A, B, C attached. Martin
>
> On 12/15/2011 03:34 PM, Martin Morgan wrote:
>> In
>>
>> > R.version.string
>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>
>> section 1.6.6 of 'Writing R Extensions' says
>>
>> Note that exporting methods on a generic in the namespace will
>> also export the generic, and exporting a generic in the
>> namespace will also export its methods.
>>
>> and
>>
>> Note that importMethodsFrom will also import any generics defined in
>> the namespace on those methods
>>
>> However, if PkgA promotes 'unique' to a generic and exports that
>>
>> DESCRIPTION:
>> Imports: methods
>>
>> R/f.R:
>> setGeneric("unique")
>>
>> NAMESPACE:
>> export(unique)
>>
>> and PkgB creates and exports a method on unique
>>
>> DESCRIPTION
>> Imports: methods, PkgA
>>
>> R/f.R:
>> setClass("B", representation(b="numeric"))
>> setMethod(unique, "B",
>> function(x, incomparables=FALSE, ...) unique(x at b))
>>
>> NAMESPACE:
>> importFrom(PkgA, unique)
>> exportClasses(B)
>> exportMethods(unique)
>>
>> and PkgC wants to import PkgB's classes and methods
>>
>> DESCRIPTION
>> Imports: methods, PkgB
>>
>> R/f.R
>> cunique <- function(x) unique(x)
>>
>> NAMESPACE
>> importMethodsFrom(PkgB, unique)
>> export(cunique)
>>
>> then
>>
>> (a) the 'unique' generic is not available to the user of PkgB
>>
>> > library(PkgB)
>> > unique(new("B", b=1:5))
>> Error in unique.default(new("B", b = 1:5)) :
>> unique() applies only to vectors
>>
>> and (b) the generic has not been imported to PkgC's namespace
>>
>> > cunique(new("B", b=1:5))
>> Error in unique.default(b) : unique() applies only to vectors
>>
>> A workaround is for PkgB to also export(unique), and for PkgC to also
>> importFrom(PkgA, unique), but is this the intention?
>>
>> This is arising from Bioconductor efforts to place commonly promoted
>> functions and S3 classes into a single package, to avoid conflicts when
>> the same function is promoted independently by several packages.
>>
>> Martin
>
>


From therneau at mayo.edu  Fri Dec 16 23:12:47 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 16 Dec 2011 16:12:47 -0600
Subject: [Rd] Rd error message
Message-ID: <1324073567.28420.31.camel@nemo>

I get the following error from one of my Rd files in R CMD check (R
2-14.0)

* checking Rd files ... WARNING
Error in switch(attr(block, "Rd_tag"), TEXT = if (!grepl("^[[:space:]]*
$",  : 
  EXPR must be a length 1 vector

problem found in ?backsolve.Rd?

This is likely something that will be glaringly obvious once it's
pointed out, but without a line number I can't seem to find it. I've
been counting braces but don't see a mismatch.

FYI, the file is below. (It is modeled on chol.Rd from the Matrix
package.)

Terry Therneau
--------------------------------------------------

\name{backsolve}
\alias{backsolve-methods}
\title{Solve an Upper or Lower Triangular System}
\alias{backsolve}
\alias{backsolve,gchol-method}
\alias{backsolve,gchol.bdsmatrix-method}
\description{
  Solves a system of linear equations where the coefficient matrix is
  upper (or \sQuote{right}, \sQuote{R}) or lower (\sQuote{left},
  \sQuote{L}) triangular.\cr 

  \code{x <- backsolve(R, b)} solves \eqn{R x = b}.
}
\usage{
  backsolve(r, \dots)
  \S4method{backsolve}{gchol}(r, x, k=ncol(r), upper.tri=TRUE, \dots)
  \S4method{backsolve}{gchol.bdsmatrix}(r, x, k=ncol(r), upper.tri=TRUE,
\dots)
}
\arguments{
  \item{r}{a matrix or matrix-like object}
  \item{x}{a vector or a matrix whose columns give the right-hand sides
for
    the equations.}
  \item{k}{The number of columns of \code{r} and rows of \code{x} to
use.}
  \item{upper.tri}{logical; if \code{TRUE} (default), the \emph{upper}
    \emph{tri}angular part of \code{r} is used.  Otherwise, the lower
    one.}
  \item{\dots}{further arguments passed to other methods}
}
\section{Methods}{
  Use \code{\link{showMethods}(backsolve)} to see all the defined
methods;
    the two created by the bdsmatrix library are described here:
    \describe{
      \item{bdsmatrix}{\code{signature=(r= "gchol")} for a generalized
	cholesky decomposition}
      \item{bdsmatrix}{\code{signature=(r= "gchol.bdsmatrix")} for the
	generalize cholesky decomposition of a bdsmatrix object}
    }
  }
\value{
  The solution of the triangular system.  The result will be a vector if
  \code{x} is a vector and a matrix if \code{x} is a matrix.

  Note that \code{forwardsolve(L, b)} is just a wrapper for
  \code{backsolve(L, b, upper.tri=FALSE)}.
}
\description{
  The generalized Cholesky decompostion of a symmetric matrix A is
  \eqn{A = LDL'}{A= LD t(L)} where D is diagonal, L is lower triangular,
  and \eqn{L'}{t(L)} is the transpose of L.
  These functions solve either \eqn{L\sqrt{D} x =b}{L sqrt(D) x=b}
  (when \code{upper.tri=FALSE}) or \eqn{\sqrt{D}L' x=b}{sqrt(D) t(L)
    x=b}.
  }
\note{
  The \code{bdsmatrix} package promotes the base R \code{backsolve}
  function to a
  generic.
  To see the full documentation for the default method, view
\code{backsolve}
  from the \code{base} package.
}
\seealso{
\code{\link{forwardsolve}}, \code{\link{gchol}}
}
\keyword{ array }
\keyword{ algebra }


From therneau at mayo.edu  Fri Dec 16 23:29:18 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 16 Dec 2011 16:29:18 -0600
Subject: [Rd] last message -- I've answered my own question
Message-ID: <1324074558.28420.34.camel@nemo>

Yes, it was glaring and obvious:  I had the label "description" a second
time when I really meant "details".  

Still, I had to delete sections of the file 1 by 1 until it slapped me
in the face.  Sorry for any bother.

Terry T.


From mtmorgan at fhcrc.org  Fri Dec 16 23:57:25 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 16 Dec 2011 14:57:25 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEBA7E4.70802@r-project.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org>
Message-ID: <4EEBCCD5.6010405@fhcrc.org>

On 12/16/2011 12:19 PM, John Chambers wrote:
> The subject heading is correct if referring to exportMethods() and
> importMethodsFrom(). They refer to the methods tables, not the generic
> functions, whatever the extensions manual says.
>
> Looking into the code of namespaceImportMethods() will illustrate this.
> It just deals with lists of method tables obtained from .getGenerics()
> which in spite of its name also only looks for the method table metadata
> objects.
>
> As I vaguely recall, there was some concern at one time about having
> extra copies of the generic version of the function.
>
> The fundamental problem is that creating methods for unique(), say, does
> not change the way calls to base::unique() work. Therefore, all packages
> that want to use methods have to ensure that a generic version of unique
> gets in between. Primitive functions are an exception because the method
> dispatch is in the C code and has a rule for checking when given an S4
> object. There is no corresponding provision for evaluating a call to a
> regular function.
>
> If the importing package has a setGeneric() for the relevant function
> then its own namespace has the generic version of the function. (That is
> a workaround, but I inferred that was what you were trying to avoid.)
>
> Fixes seem possible, but some care is needed. If exportMethods
> automatically exported the generic function, it really is no different
> from export() for that function.

export() somehow implies ownership of the generic, e.g., responsibility 
for documentation. I can see in the scenario below that PkgB might be 
expected to Depends: PkgA if it intends for the user to access PkgB's 
methods on PkgA::unique.

> namespaceImportMethods() could try to supply the generic function if it
> is not already present. If it does not find the generic in the namespace
> being imported, it would essentially have to call setGeneric(), assuming
> the non-generic function exists in the specified package (e.g., in base
> for unique()).

In the example below for PkgC the 'unique' generic is in PkgB's 
namespace imports

 > getNamespaceImports("PkgB")
$base
[1] TRUE

$PkgA
   unique
"unique"

I guess PkgB could have Depends: PkgA, not importFrom(PkgA, unique), and 
then defined and exported a method on PkgA::unique found on the search 
path, so that the generic wasn't available to PkgC. But I'd be happy if 
the generic found in either PkgB's namespace or namespace imports were 
imported along with the method. Not sure that I like the idea of calling 
setGeneric() -- PkgA could have done something non-standard -- and would 
rather an error.

Thans for your attention.

Martin

>
> Comments?
> John
>
>
>
> On 12/16/11 6:16 AM, Martin Morgan wrote:
>> tar of Pkgs A, B, C attached. Martin
>>
>> On 12/15/2011 03:34 PM, Martin Morgan wrote:
>>> In
>>>
>>> > R.version.string
>>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>>
>>> section 1.6.6 of 'Writing R Extensions' says
>>>
>>> Note that exporting methods on a generic in the namespace will
>>> also export the generic, and exporting a generic in the
>>> namespace will also export its methods.
>>>
>>> and
>>>
>>> Note that importMethodsFrom will also import any generics defined in
>>> the namespace on those methods
>>>
>>> However, if PkgA promotes 'unique' to a generic and exports that
>>>
>>> DESCRIPTION:
>>> Imports: methods
>>>
>>> R/f.R:
>>> setGeneric("unique")
>>>
>>> NAMESPACE:
>>> export(unique)
>>>
>>> and PkgB creates and exports a method on unique
>>>
>>> DESCRIPTION
>>> Imports: methods, PkgA
>>>
>>> R/f.R:
>>> setClass("B", representation(b="numeric"))
>>> setMethod(unique, "B",
>>> function(x, incomparables=FALSE, ...) unique(x at b))
>>>
>>> NAMESPACE:
>>> importFrom(PkgA, unique)
>>> exportClasses(B)
>>> exportMethods(unique)
>>>
>>> and PkgC wants to import PkgB's classes and methods
>>>
>>> DESCRIPTION
>>> Imports: methods, PkgB
>>>
>>> R/f.R
>>> cunique <- function(x) unique(x)
>>>
>>> NAMESPACE
>>> importMethodsFrom(PkgB, unique)
>>> export(cunique)
>>>
>>> then
>>>
>>> (a) the 'unique' generic is not available to the user of PkgB
>>>
>>> > library(PkgB)
>>> > unique(new("B", b=1:5))
>>> Error in unique.default(new("B", b = 1:5)) :
>>> unique() applies only to vectors
>>>
>>> and (b) the generic has not been imported to PkgC's namespace
>>>
>>> > cunique(new("B", b=1:5))
>>> Error in unique.default(b) : unique() applies only to vectors
>>>
>>> A workaround is for PkgB to also export(unique), and for PkgC to also
>>> importFrom(PkgA, unique), but is this the intention?
>>>
>>> This is arising from Bioconductor efforts to place commonly promoted
>>> functions and S3 classes into a single package, to avoid conflicts when
>>> the same function is promoted independently by several packages.
>>>
>>> Martin
>>
>>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From murdoch.duncan at gmail.com  Sat Dec 17 01:08:22 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Dec 2011 19:08:22 -0500
Subject: [Rd] last message -- I've answered my own question
In-Reply-To: <1324074558.28420.34.camel@nemo>
References: <1324074558.28420.34.camel@nemo>
Message-ID: <4EEBDD76.2000904@gmail.com>

On 11-12-16 5:29 PM, Terry Therneau wrote:
> Yes, it was glaring and obvious:  I had the label "description" a second
> time when I really meant "details".
>
> Still, I had to delete sections of the file 1 by 1 until it slapped me
> in the face.  Sorry for any bother.

Thanks.  The error report looks buggy; I'll take a look.

Duncan Murdoch

>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Sat Dec 17 01:52:29 2011
From: jmc at r-project.org (John Chambers)
Date: Fri, 16 Dec 2011 16:52:29 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEBCCD5.6010405@fhcrc.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org> <4EEBCCD5.6010405@fhcrc.org>
Message-ID: <4EEBE7CD.5080502@r-project.org>

The key point here is that setGeneric("unique") is done that way, 
without other argument, whoever does it.  That creates the generic from 
the implicit generic corresponding to base::unique.  If package A had 
done anything else, the resulting methods tables would NOT refer to 
package "base" but to package "PkgA" and it's that version of the 
generic that would need to be imported.

So it's not particularly relevant that we're dealing with PkgA::unique() 
if the generic function was created from base::unique by the standard 
call.  That's what would make an automatic imputation of the generic 
from importMethods() possible.

On 12/16/11 2:57 PM, Martin Morgan wrote:
> On 12/16/2011 12:19 PM, John Chambers wrote:
>> The subject heading is correct if referring to exportMethods() and
>> importMethodsFrom(). They refer to the methods tables, not the generic
>> functions, whatever the extensions manual says.
>>
>> Looking into the code of namespaceImportMethods() will illustrate this.
>> It just deals with lists of method tables obtained from .getGenerics()
>> which in spite of its name also only looks for the method table metadata
>> objects.
>>
>> As I vaguely recall, there was some concern at one time about having
>> extra copies of the generic version of the function.
>>
>> The fundamental problem is that creating methods for unique(), say, does
>> not change the way calls to base::unique() work. Therefore, all packages
>> that want to use methods have to ensure that a generic version of unique
>> gets in between. Primitive functions are an exception because the method
>> dispatch is in the C code and has a rule for checking when given an S4
>> object. There is no corresponding provision for evaluating a call to a
>> regular function.
>>
>> If the importing package has a setGeneric() for the relevant function
>> then its own namespace has the generic version of the function. (That is
>> a workaround, but I inferred that was what you were trying to avoid.)
>>
>> Fixes seem possible, but some care is needed. If exportMethods
>> automatically exported the generic function, it really is no different
>> from export() for that function.
>
> export() somehow implies ownership of the generic, e.g., responsibility
> for documentation. I can see in the scenario below that PkgB might be
> expected to Depends: PkgA if it intends for the user to access PkgB's
> methods on PkgA::unique.
>
>> namespaceImportMethods() could try to supply the generic function if it
>> is not already present. If it does not find the generic in the namespace
>> being imported, it would essentially have to call setGeneric(), assuming
>> the non-generic function exists in the specified package (e.g., in base
>> for unique()).
>
> In the example below for PkgC the 'unique' generic is in PkgB's
> namespace imports
>
>  > getNamespaceImports("PkgB")
> $base
> [1] TRUE
>
> $PkgA
> unique
> "unique"
>
> I guess PkgB could have Depends: PkgA, not importFrom(PkgA, unique), and
> then defined and exported a method on PkgA::unique found on the search
> path, so that the generic wasn't available to PkgC. But I'd be happy if
> the generic found in either PkgB's namespace or namespace imports were
> imported along with the method. Not sure that I like the idea of calling
> setGeneric() -- PkgA could have done something non-standard -- and would
> rather an error.
>
> Thans for your attention.
>
> Martin
>
>>
>> Comments?
>> John
>>
>>
>>
>> On 12/16/11 6:16 AM, Martin Morgan wrote:
>>> tar of Pkgs A, B, C attached. Martin
>>>
>>> On 12/15/2011 03:34 PM, Martin Morgan wrote:
>>>> In
>>>>
>>>> > R.version.string
>>>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>>>
>>>> section 1.6.6 of 'Writing R Extensions' says
>>>>
>>>> Note that exporting methods on a generic in the namespace will
>>>> also export the generic, and exporting a generic in the
>>>> namespace will also export its methods.
>>>>
>>>> and
>>>>
>>>> Note that importMethodsFrom will also import any generics defined in
>>>> the namespace on those methods
>>>>
>>>> However, if PkgA promotes 'unique' to a generic and exports that
>>>>
>>>> DESCRIPTION:
>>>> Imports: methods
>>>>
>>>> R/f.R:
>>>> setGeneric("unique")
>>>>
>>>> NAMESPACE:
>>>> export(unique)
>>>>
>>>> and PkgB creates and exports a method on unique
>>>>
>>>> DESCRIPTION
>>>> Imports: methods, PkgA
>>>>
>>>> R/f.R:
>>>> setClass("B", representation(b="numeric"))
>>>> setMethod(unique, "B",
>>>> function(x, incomparables=FALSE, ...) unique(x at b))
>>>>
>>>> NAMESPACE:
>>>> importFrom(PkgA, unique)
>>>> exportClasses(B)
>>>> exportMethods(unique)
>>>>
>>>> and PkgC wants to import PkgB's classes and methods
>>>>
>>>> DESCRIPTION
>>>> Imports: methods, PkgB
>>>>
>>>> R/f.R
>>>> cunique <- function(x) unique(x)
>>>>
>>>> NAMESPACE
>>>> importMethodsFrom(PkgB, unique)
>>>> export(cunique)
>>>>
>>>> then
>>>>
>>>> (a) the 'unique' generic is not available to the user of PkgB
>>>>
>>>> > library(PkgB)
>>>> > unique(new("B", b=1:5))
>>>> Error in unique.default(new("B", b = 1:5)) :
>>>> unique() applies only to vectors
>>>>
>>>> and (b) the generic has not been imported to PkgC's namespace
>>>>
>>>> > cunique(new("B", b=1:5))
>>>> Error in unique.default(b) : unique() applies only to vectors
>>>>
>>>> A workaround is for PkgB to also export(unique), and for PkgC to also
>>>> importFrom(PkgA, unique), but is this the intention?
>>>>
>>>> This is arising from Bioconductor efforts to place commonly promoted
>>>> functions and S3 classes into a single package, to avoid conflicts when
>>>> the same function is promoted independently by several packages.
>>>>
>>>> Martin
>>>
>>>
>
>


From spencer.graves at prodsyse.com  Sat Dec 17 07:43:38 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 16 Dec 2011 22:43:38 -0800
Subject: [Rd] latest Rtools missing "inconsolita.sty"
Message-ID: <4EEC3A1A.5060506@prodsyse.com>

Hello:


	  What do you suggest I do to overcome "LaTeX Error:  File 
'inconsolata.sty' not found", which I got running "R CMD check" on a 
package using Rtools I downloaded yesterday?


	  I found a similar question to R-Help Nov. 3 (URL below), but I've not 
yet had success in replicating the solution outlined there.  I tried 
several different sets of instructions for installing LaTeX packages, 
none of which seemed to work for me.  I'm running Windows 7 
[sessionInfo() below].


	  Suggestions?
	  Thanks,
	  Spencer Graves		


http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html


R version 2.14.0 (2011-10-31)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From murdoch.duncan at gmail.com  Sat Dec 17 13:27:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 17 Dec 2011 07:27:30 -0500
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EEC3A1A.5060506@prodsyse.com>
References: <4EEC3A1A.5060506@prodsyse.com>
Message-ID: <4EEC8AB2.30007@gmail.com>

On 11-12-17 1:43 AM, Spencer Graves wrote:
> Hello:
>
>
> 	  What do you suggest I do to overcome "LaTeX Error:  File
> 'inconsolata.sty' not found", which I got running "R CMD check" on a
> package using Rtools I downloaded yesterday?

That file should be installable as part of your LaTeX distribution.  If 
you are using MikTeX, you can install it from the MikTeX Package Manager 
as part of package "inconsolata".

Duncan Murdoch

>
>
> 	  I found a similar question to R-Help Nov. 3 (URL below), but I've not
> yet had success in replicating the solution outlined there.  I tried
> several different sets of instructions for installing LaTeX packages,
> none of which seemed to work for me.  I'm running Windows 7
> [sessionInfo() below].
>
>
> 	  Suggestions?
> 	  Thanks,
> 	  Spencer Graves		
>
>
> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html
>
>
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Sat Dec 17 15:02:38 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 17 Dec 2011 06:02:38 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEBE7CD.5080502@r-project.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org> <4EEBCCD5.6010405@fhcrc.org>
	<4EEBE7CD.5080502@r-project.org>
Message-ID: <CAOQ5Nyd_ies9vyvRuD78-iAf41C4qPPtbLfZOmaQMLYe8YCbTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111217/00e3e55c/attachment.pl>

From valdounet at gmail.com  Sat Dec 17 14:22:26 2011
From: valdounet at gmail.com (Vladislav Navel)
Date: Sat, 17 Dec 2011 14:22:26 +0100
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EEC3A1A.5060506@prodsyse.com>
References: <4EEC3A1A.5060506@prodsyse.com>
Message-ID: <4EEC9792.20802@gmail.com>

Hi Spencer,

to solve this problem, you only need to install the TeX package
"inconsolata". You can install it from the CTAN
(http://www.ctan.org/pkg/inconsolata) but the best way depends on the
TeX distribution you have installed.
Since you're running Windows 7, I guess it is MiKTeX and so the MiKTeX
manual may help you :

http://docs.miktex.org/2.9/manual/pkgmgt.html
http://docs.miktex.org/2.9/manual/texfeatures.html#autoinstalloptions

Hope this can help,
Vladislav Navel

Le 17/12/2011 07:43, Spencer Graves a ?crit :
> Hello:
>
>
>       What do you suggest I do to overcome "LaTeX Error:  File
> 'inconsolata.sty' not found", which I got running "R CMD check" on a
> package using Rtools I downloaded yesterday?
>
>
>       I found a similar question to R-Help Nov. 3 (URL below), but
> I've not yet had success in replicating the solution outlined there. 
> I tried several different sets of instructions for installing LaTeX
> packages, none of which seemed to work for me.  I'm running Windows 7
> [sessionInfo() below].
>
>
>       Suggestions?
>       Thanks,
>       Spencer Graves       
>
>
> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html
>
>
>
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Sat Dec 17 17:26:55 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 17 Dec 2011 08:26:55 -0800
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EEC8AB2.30007@gmail.com>
References: <4EEC3A1A.5060506@prodsyse.com> <4EEC8AB2.30007@gmail.com>
Message-ID: <4EECC2CF.3040101@prodsyse.com>

On 12/17/2011 4:27 AM, Duncan Murdoch wrote:
> On 11-12-17 1:43 AM, Spencer Graves wrote:
>> Hello:
>>
>>
>>       What do you suggest I do to overcome "LaTeX Error:  File
>> 'inconsolata.sty' not found", which I got running "R CMD check" on a
>> package using Rtools I downloaded yesterday?
>
> That file should be installable as part of your LaTeX distribution.  
> If you are using MikTeX, you can install it from the MikTeX Package 
> Manager as part of package "inconsolata".


       Thanks.  I found the MiKTeX Package Manager, selected 
"inconsolata", then Task -> Install.  This produced, "MiKTeX Problem 
Report:  Failure when receiving data from the peer".  I copied the 
report to clipboard and pasted it (below).  All the directories there 
seem to exist.  What else do you suggest?  (This is on a Windows 7 
notebook.  Is this a feature of Windows 7?  I installed MiKTeX under 
"C:\Users\sgraves" hoping to minimize these kinds of problems.)


       Thanks,
       Spencer


MiKTeX Problem Report:  Failure when receiving data from the peer:


MiKTeX Problem Report
Message: Failure when receiving data from the peer
Data: mmk,
Source: Libraries\MiKTeX\PackageManager\CurlWebSession.cpp
Line: 402
MiKTeX: 2.9
OS: Microsoft Windows 7 Home Premium Edition, 64-bit (build 7600)
Invokers: explorer
SystemAdmin: yes
PowerUser: no
Root0: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
Root1: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
Root2: C:\ProgramData\MiKTeX\2.9
Root3: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
UserInstall: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
UserConfig: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
UserData: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
CommonInstall: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
CommonConfig: C:\ProgramData\MiKTeX\2.9
CommonData: C:\ProgramData\MiKTeX\2.9

>
> Duncan Murdoch
>
>>
>>
>>       I found a similar question to R-Help Nov. 3 (URL below), but 
>> I've not
>> yet had success in replicating the solution outlined there.  I tried
>> several different sets of instructions for installing LaTeX packages,
>> none of which seemed to work for me.  I'm running Windows 7
>> [sessionInfo() below].
>>
>>
>>       Suggestions?
>>       Thanks,
>>       Spencer Graves
>>
>>
>> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html 
>>
>>
>>
>> R version 2.14.0 (2011-10-31)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sat Dec 17 18:22:22 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 17 Dec 2011 18:22:22 +0100
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EECC2CF.3040101@prodsyse.com>
References: <4EEC3A1A.5060506@prodsyse.com> <4EEC8AB2.30007@gmail.com>
	<4EECC2CF.3040101@prodsyse.com>
Message-ID: <4EECCFCE.9050207@statistik.tu-dortmund.de>



On 17.12.2011 17:26, Spencer Graves wrote:
> On 12/17/2011 4:27 AM, Duncan Murdoch wrote:
>> On 11-12-17 1:43 AM, Spencer Graves wrote:
>>> Hello:
>>>
>>>
>>> What do you suggest I do to overcome "LaTeX Error: File
>>> 'inconsolata.sty' not found", which I got running "R CMD check" on a
>>> package using Rtools I downloaded yesterday?
>>
>> That file should be installable as part of your LaTeX distribution. If
>> you are using MikTeX, you can install it from the MikTeX Package
>> Manager as part of package "inconsolata".
>
>
> Thanks. I found the MiKTeX Package Manager, selected "inconsolata", then
> Task -> Install. This produced, "MiKTeX Problem Report: Failure when
> receiving data from the peer". I copied the report to clipboard and
> pasted it (below). All the directories there seem to exist. What else do
> you suggest? (This is on a Windows 7 notebook. Is this a feature of
> Windows 7? I installed MiKTeX under "C:\Users\sgraves" hoping to
> minimize these kinds of problems.)
>
>
> Thanks,
> Spencer
>
>
> MiKTeX Problem Report: Failure when receiving data from the peer:

Works for me, you may have to ask on a MikTeX mailing list why you 
cannot install MikTeX packages ....

Best,
Uwe



>
> MiKTeX Problem Report
> Message: Failure when receiving data from the peer
> Data: mmk,
> Source: Libraries\MiKTeX\PackageManager\CurlWebSession.cpp
> Line: 402
> MiKTeX: 2.9
> OS: Microsoft Windows 7 Home Premium Edition, 64-bit (build 7600)
> Invokers: explorer
> SystemAdmin: yes
> PowerUser: no
> Root0: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> Root1: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
> Root2: C:\ProgramData\MiKTeX\2.9
> Root3: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
> UserInstall: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> UserConfig: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> UserData: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
> CommonInstall: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
> CommonConfig: C:\ProgramData\MiKTeX\2.9
> CommonData: C:\ProgramData\MiKTeX\2.9
>
>>
>> Duncan Murdoch
>>
>>>
>>>
>>> I found a similar question to R-Help Nov. 3 (URL below), but I've not
>>> yet had success in replicating the solution outlined there. I tried
>>> several different sets of instructions for installing LaTeX packages,
>>> none of which seemed to work for me. I'm running Windows 7
>>> [sessionInfo() below].
>>>
>>>
>>> Suggestions?
>>> Thanks,
>>> Spencer Graves
>>>
>>>
>>> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html
>>>
>>>
>>>
>>> R version 2.14.0 (2011-10-31)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat Dec 17 23:02:02 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 17 Dec 2011 17:02:02 -0500
Subject: [Rd] last message -- I've answered my own question
In-Reply-To: <4EEBDD76.2000904@gmail.com>
References: <1324074558.28420.34.camel@nemo> <4EEBDD76.2000904@gmail.com>
Message-ID: <4EED115A.5070908@gmail.com>

On 11-12-16 7:08 PM, Duncan Murdoch wrote:
> On 11-12-16 5:29 PM, Terry Therneau wrote:
>> Yes, it was glaring and obvious:  I had the label "description" a second
>> time when I really meant "details".
>>
>> Still, I had to delete sections of the file 1 by 1 until it slapped me
>> in the face.  Sorry for any bother.
>
> Thanks.  The error report looks buggy; I'll take a look.
>

Now fixed.  You would see something like

* checking Rd files ... WARNING
checkRd: (5) backsolve.Rd:50-57: Only one \description is allowed

after revision 57914.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Dec 17 23:08:39 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 17 Dec 2011 17:08:39 -0500
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EECC2CF.3040101@prodsyse.com>
References: <4EEC3A1A.5060506@prodsyse.com> <4EEC8AB2.30007@gmail.com>
	<4EECC2CF.3040101@prodsyse.com>
Message-ID: <4EED12E7.2010709@gmail.com>

On 11-12-17 11:26 AM, Spencer Graves wrote:
> On 12/17/2011 4:27 AM, Duncan Murdoch wrote:
>> On 11-12-17 1:43 AM, Spencer Graves wrote:
>>> Hello:
>>>
>>>
>>>        What do you suggest I do to overcome "LaTeX Error:  File
>>> 'inconsolata.sty' not found", which I got running "R CMD check" on a
>>> package using Rtools I downloaded yesterday?
>>
>> That file should be installable as part of your LaTeX distribution.
>> If you are using MikTeX, you can install it from the MikTeX Package
>> Manager as part of package "inconsolata".
>
>
>         Thanks.  I found the MiKTeX Package Manager, selected
> "inconsolata", then Task ->  Install.  This produced, "MiKTeX Problem
> Report:  Failure when receiving data from the peer".  I copied the
> report to clipboard and pasted it (below).  All the directories there
> seem to exist.  What else do you suggest?  (This is on a Windows 7
> notebook.  Is this a feature of Windows 7?  I installed MiKTeX under
> "C:\Users\sgraves" hoping to minimize these kinds of problems.)

Like Uwe, it works for me, so I don't really know what's going wrong for 
you.  I would guess from the message that it is the download that is 
failing, rather than a problem on your system:  you might want to just 
try again, or specify a different repository (via menus, "Repository | 
Change package repository...").  You might also need to specify a proxy, 
if that's how your system is set up.  (You do this in "Connection 
settings" in the change repository dialog.)

Beyond that, I'd echo Uwe's suggestion to ask on a MikTeX list.

Duncan Murdoch

>
>
>         Thanks,
>         Spencer
>
>
> MiKTeX Problem Report:  Failure when receiving data from the peer:
>
>
> MiKTeX Problem Report
> Message: Failure when receiving data from the peer
> Data: mmk,
> Source: Libraries\MiKTeX\PackageManager\CurlWebSession.cpp
> Line: 402
> MiKTeX: 2.9
> OS: Microsoft Windows 7 Home Premium Edition, 64-bit (build 7600)
> Invokers: explorer
> SystemAdmin: yes
> PowerUser: no
> Root0: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> Root1: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
> Root2: C:\ProgramData\MiKTeX\2.9
> Root3: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
> UserInstall: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> UserConfig: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
> UserData: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
> CommonInstall: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
> CommonConfig: C:\ProgramData\MiKTeX\2.9
> CommonData: C:\ProgramData\MiKTeX\2.9
>
>>
>> Duncan Murdoch
>>
>>>
>>>
>>>        I found a similar question to R-Help Nov. 3 (URL below), but
>>> I've not
>>> yet had success in replicating the solution outlined there.  I tried
>>> several different sets of instructions for installing LaTeX packages,
>>> none of which seemed to work for me.  I'm running Windows 7
>>> [sessionInfo() below].
>>>
>>>
>>>        Suggestions?
>>>        Thanks,
>>>        Spencer Graves
>>>
>>>
>>> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html
>>>
>>>
>>>
>>> R version 2.14.0 (2011-10-31)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From b.rowlingson at lancaster.ac.uk  Sun Dec 18 02:32:52 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 18 Dec 2011 01:32:52 +0000
Subject: [Rd] Saving nothing with save()
Message-ID: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>

Scenario: Here I am working away in R. I've got results that prove
global warming is anthropogenic and also the solution for producing
limitless carbon-neutral energy from nuclear fusion. Its been a good
day.

So, I want to save my work. I don't want to overwrite my current
.RData, so I save it to another file:

save(file="prize.RData")  # just need to email this to the Nobel committee
q()
  Save workspace image? [y/n/c]: - "no" I don't want to save the
workspace image, I just saved everything to "prize.RData". But gee, it
did seem to do that quite quickly considering the volume of evidential
data in my work. My unix shell prompt returns.

Uh oh. See what I did there? I typed 'save' when I meant 'save.image'.
What does that give me?

 A 42 byte, empty, latest.RData, and because there was no warning or
error I quit without saving it again. Oops. Massive Data Loss.

 Is there any reason why save(file="file.RData") couldn't warn or
error if you try and save nothing? There's no obvious check in the R
code for save.

Barry

PS the above scenario is fictional. When did I last have a good day?


From pgilbert902 at gmail.com  Sun Dec 18 02:28:20 2011
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 17 Dec 2011 20:28:20 -0500
Subject: [Rd] secure password token management method in R
In-Reply-To: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
References: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
Message-ID: <4EED41B4.1000009@gmail.com>

One way this is often done is to have this information in a file that 
only the owner can read. For example, mysql uses a file .my.cnf (in 
Windows it may have a different name). The code then just reads the 
information from the file. To guard against user carelessness, I think 
mysql will not use it if anyone other than the user has read permission 
on the file. Of the various options for passing user/password 
information, I think this is general considered one of the better ways.

Paul

On 11-12-14 04:54 PM, Ni Wang wrote:
> hi, r developers, I am now working on a R function/package to handling
> online request with username and token/password.
>
> For security reasons, it's not so safe to store the username&  token in
> persistent variables, since they'll be saved to disk when
> users save their workspace. Is there a secure way in R to handle the online
> password management? I have searched it online
> but didn't find any good suggestions. So I am trying my luck on this mail
> list.
>
> Regards
>
> Ni
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From b.rowlingson at lancaster.ac.uk  Sun Dec 18 15:03:07 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 18 Dec 2011 14:03:07 +0000
Subject: [Rd] secure password token management method in R
In-Reply-To: <4EED41B4.1000009@gmail.com>
References: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
	<4EED41B4.1000009@gmail.com>
Message-ID: <CANVKczOat6RhNsgZhPdAuxPcmFp=qM=pdYrUyUH-dNkbpffj=g@mail.gmail.com>

On Sun, Dec 18, 2011 at 1:28 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> One way this is often done is to have this information in a file that only
> the owner can read. For example, mysql uses a file .my.cnf (in Windows it
> may have a different name). The code then just reads the information from
> the file. To guard against user carelessness, I think mysql will not use it
> if anyone other than the user has read permission on the file. Of the
> various options for passing user/password information, I think this is
> general considered one of the better ways.

 If anyone has a large chunk of spare time on their hands they could
implement an R interface to the Gnome Keyring and store credentials in
there.  I think under the hood it uses dbus so first implement dbus in
R. Or just call some code with system()...

 gnome keyring API: http://live.gnome.org/GnomeKeyring/StoringPasswords

 command line interface: https://launchpad.net/gkeyring

Probably getting a bit over the top now.

Barry


From jmc at r-project.org  Sun Dec 18 20:04:40 2011
From: jmc at r-project.org (John Chambers)
Date: Sun, 18 Dec 2011 11:04:40 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <CAOQ5Nyd_ies9vyvRuD78-iAf41C4qPPtbLfZOmaQMLYe8YCbTg@mail.gmail.com>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org> <4EEBCCD5.6010405@fhcrc.org>
	<4EEBE7CD.5080502@r-project.org>
	<CAOQ5Nyd_ies9vyvRuD78-iAf41C4qPPtbLfZOmaQMLYe8YCbTg@mail.gmail.com>
Message-ID: <4EEE3948.2080300@r-project.org>



On 12/17/11 6:02 AM, Michael Lawrence wrote:
> I guess what it boils down to is whether it makes sense for PkgB to have
> exportMethods(unique) when PkgB does not export(unique) or have PkgA in
> Depends.  And whether it makes sense for PkgC to have
> importMethodsFrom(PkgB, unique) without importFrom(PkgA, unique). If it
> is not feasible/sensible to support implicit passing of generics up the
> dependency stack, then R should probably emit some sort of warning/error
> when methods are exported or imported without the corresponding generic.
>
> The fact that a generic is being created for an implicit generic defined
> in 'base' is not really the issue here.

On the contrary, it's why we need to do some thinking about what we want.

Try replacing "unique" with "sum" throughout Martin's example, adjusting 
the method definition appropriately.  No problems arise, because sum() 
is a primitive.  Exporting and importing methods works as implied by the 
extensions manual, but via the implicit generic for sum().

The essential point is that the methods being imported are "for" the 
generic implied by the function in package "base".  PkgA is the 
irrelevant aspect if the methods come from PkgB and the implied generic 
comes from "base".  The problem is that there is no "flag" for 
non-primitive functions that says "Methods have been defined for this 
function (base::unique in this case), so some calls should carry out 
method dispatch."

The extensions manual stated that exportMethods() would "export the 
generic".  We could make that true or make it unnecessary, by having 
importMethods() look for a generic in the referenced package and infer 
the implicit generic (maybe with a message).  Otherwise, we're adding 
inconsistent requirements for primitives vs true functions in the base 
package.

John
>
> Thanks,
> Michael
>
> On Fri, Dec 16, 2011 at 4:52 PM, John Chambers <jmc at r-project.org
> <mailto:jmc at r-project.org>> wrote:
>
>     The key point here is that setGeneric("unique") is done that way,
>     without other argument, whoever does it.  That creates the generic
>     from the implicit generic corresponding to base::unique.  If package
>     A had done anything else, the resulting methods tables would NOT
>     refer to package "base" but to package "PkgA" and it's that version
>     of the generic that would need to be imported.
>
>     So it's not particularly relevant that we're dealing with
>     PkgA::unique() if the generic function was created from base::unique
>     by the standard call.  That's what would make an automatic
>     imputation of the generic from importMethods() possible.
>
>
>     On 12/16/11 2:57 PM, Martin Morgan wrote:
>
>         On 12/16/2011 12:19 PM, John Chambers wrote:
>
>             The subject heading is correct if referring to
>             exportMethods() and
>             importMethodsFrom(). They refer to the methods tables, not
>             the generic
>             functions, whatever the extensions manual says.
>
>             Looking into the code of namespaceImportMethods() will
>             illustrate this.
>             It just deals with lists of method tables obtained from
>             .getGenerics()
>             which in spite of its name also only looks for the method
>             table metadata
>             objects.
>
>             As I vaguely recall, there was some concern at one time
>             about having
>             extra copies of the generic version of the function.
>
>             The fundamental problem is that creating methods for
>             unique(), say, does
>             not change the way calls to base::unique() work. Therefore,
>             all packages
>             that want to use methods have to ensure that a generic
>             version of unique
>             gets in between. Primitive functions are an exception
>             because the method
>             dispatch is in the C code and has a rule for checking when
>             given an S4
>             object. There is no corresponding provision for evaluating a
>             call to a
>             regular function.
>
>             If the importing package has a setGeneric() for the relevant
>             function
>             then its own namespace has the generic version of the
>             function. (That is
>             a workaround, but I inferred that was what you were trying
>             to avoid.)
>
>             Fixes seem possible, but some care is needed. If exportMethods
>             automatically exported the generic function, it really is no
>             different
>             from export() for that function.
>
>
>         export() somehow implies ownership of the generic, e.g.,
>         responsibility
>         for documentation. I can see in the scenario below that PkgB
>         might be
>         expected to Depends: PkgA if it intends for the user to access
>         PkgB's
>         methods on PkgA::unique.
>
>             namespaceImportMethods() could try to supply the generic
>             function if it
>             is not already present. If it does not find the generic in
>             the namespace
>             being imported, it would essentially have to call
>             setGeneric(), assuming
>             the non-generic function exists in the specified package
>             (e.g., in base
>             for unique()).
>
>
>         In the example below for PkgC the 'unique' generic is in PkgB's
>         namespace imports
>
>          > getNamespaceImports("PkgB")
>         $base
>         [1] TRUE
>
>         $PkgA
>         unique
>         "unique"
>
>         I guess PkgB could have Depends: PkgA, not importFrom(PkgA,
>         unique), and
>         then defined and exported a method on PkgA::unique found on the
>         search
>         path, so that the generic wasn't available to PkgC. But I'd be
>         happy if
>         the generic found in either PkgB's namespace or namespace
>         imports were
>         imported along with the method. Not sure that I like the idea of
>         calling
>         setGeneric() -- PkgA could have done something non-standard --
>         and would
>         rather an error.
>
>         Thans for your attention.
>
>         Martin
>
>
>             Comments?
>             John
>
>
>
>             On 12/16/11 6:16 AM, Martin Morgan wrote:
>
>                 tar of Pkgs A, B, C attached. Martin
>
>                 On 12/15/2011 03:34 PM, Martin Morgan wrote:
>
>                     In
>
>                      > R.version.string
>                     [1] "R Under development (unstable) (2011-12-15 r57901)"
>
>                     section 1.6.6 of 'Writing R Extensions' says
>
>                     Note that exporting methods on a generic in the
>                     namespace will
>                     also export the generic, and exporting a generic in the
>                     namespace will also export its methods.
>
>                     and
>
>                     Note that importMethodsFrom will also import any
>                     generics defined in
>                     the namespace on those methods
>
>                     However, if PkgA promotes 'unique' to a generic and
>                     exports that
>
>                     DESCRIPTION:
>                     Imports: methods
>
>                     R/f.R:
>                     setGeneric("unique")
>
>                     NAMESPACE:
>                     export(unique)
>
>                     and PkgB creates and exports a method on unique
>
>                     DESCRIPTION
>                     Imports: methods, PkgA
>
>                     R/f.R:
>                     setClass("B", representation(b="numeric"))
>                     setMethod(unique, "B",
>                     function(x, incomparables=FALSE, ...) unique(x at b))
>
>                     NAMESPACE:
>                     importFrom(PkgA, unique)
>                     exportClasses(B)
>                     exportMethods(unique)
>
>                     and PkgC wants to import PkgB's classes and methods
>
>                     DESCRIPTION
>                     Imports: methods, PkgB
>
>                     R/f.R
>                     cunique <- function(x) unique(x)
>
>                     NAMESPACE
>                     importMethodsFrom(PkgB, unique)
>                     export(cunique)
>
>                     then
>
>                     (a) the 'unique' generic is not available to the
>                     user of PkgB
>
>                      > library(PkgB)
>                      > unique(new("B", b=1:5))
>                     Error in unique.default(new("B", b = 1:5)) :
>                     unique() applies only to vectors
>
>                     and (b) the generic has not been imported to PkgC's
>                     namespace
>
>                      > cunique(new("B", b=1:5))
>                     Error in unique.default(b) : unique() applies only
>                     to vectors
>
>                     A workaround is for PkgB to also export(unique), and
>                     for PkgC to also
>                     importFrom(PkgA, unique), but is this the intention?
>
>                     This is arising from Bioconductor efforts to place
>                     commonly promoted
>                     functions and S3 classes into a single package, to
>                     avoid conflicts when
>                     the same function is promoted independently by
>                     several packages.
>
>                     Martin
>
>
>
>
>
>
>     ________________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


From simon.urbanek at r-project.org  Sun Dec 18 22:16:27 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 18 Dec 2011 16:16:27 -0500
Subject: [Rd] secure password token management method in R
In-Reply-To: <CANVKczOat6RhNsgZhPdAuxPcmFp=qM=pdYrUyUH-dNkbpffj=g@mail.gmail.com>
References: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
	<4EED41B4.1000009@gmail.com>
	<CANVKczOat6RhNsgZhPdAuxPcmFp=qM=pdYrUyUH-dNkbpffj=g@mail.gmail.com>
Message-ID: <7A1CFD16-8BE6-4F77-B127-84F12F1CFEED@r-project.org>

Barry,

that's a great idea. I have created a package that allows you to read/write passwords to user's keychain:

http://www.rforge.net/keychain

So far it uses the Security framework so you'll need a Mac, it but I'm about to add a generic fall-back system (encrypted file on-disk) and possibly the gnome API as well.

Cheers,
Simon


On Dec 18, 2011, at 9:03 AM, Barry Rowlingson wrote:

> On Sun, Dec 18, 2011 at 1:28 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>> One way this is often done is to have this information in a file that only
>> the owner can read. For example, mysql uses a file .my.cnf (in Windows it
>> may have a different name). The code then just reads the information from
>> the file. To guard against user carelessness, I think mysql will not use it
>> if anyone other than the user has read permission on the file. Of the
>> various options for passing user/password information, I think this is
>> general considered one of the better ways.
> 
> If anyone has a large chunk of spare time on their hands they could
> implement an R interface to the Gnome Keyring and store credentials in
> there.  I think under the hood it uses dbus so first implement dbus in
> R. Or just call some code with system()...
> 
> gnome keyring API: http://live.gnome.org/GnomeKeyring/StoringPasswords
> 
> command line interface: https://launchpad.net/gkeyring
> 
> Probably getting a bit over the top now.
> 
> Barry
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Sun Dec 18 22:34:01 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 Dec 2011 15:34:01 -0600
Subject: [Rd] secure password token management method in R
In-Reply-To: <7A1CFD16-8BE6-4F77-B127-84F12F1CFEED@r-project.org>
References: <CABSPzu7phFMjkXEt1RvEs8Z64ntTbDyNqmmayz1F3uNL+kOkHA@mail.gmail.com>
	<4EED41B4.1000009@gmail.com>
	<CANVKczOat6RhNsgZhPdAuxPcmFp=qM=pdYrUyUH-dNkbpffj=g@mail.gmail.com>
	<7A1CFD16-8BE6-4F77-B127-84F12F1CFEED@r-project.org>
Message-ID: <20206.23625.810915.581657@max.nulle.part>


On 18 December 2011 at 16:16, Simon Urbanek wrote:
| Barry,
| 
| that's a great idea. I have created a package that allows you to read/write passwords to user's keychain:
| 
| http://www.rforge.net/keychain
| 
| So far it uses the Security framework so you'll need a Mac, it but I'm about to add a generic fall-back system (encrypted file on-disk) and possibly the gnome API as well.

If you do, I could try to test it against the KDE variant as well.  Are these
by chance generic "superset" definitions that work with Gnome's and KDE's keyrings?

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From tlumley at uw.edu  Sun Dec 18 23:48:02 2011
From: tlumley at uw.edu (Thomas Lumley)
Date: Mon, 19 Dec 2011 11:48:02 +1300
Subject: [Rd] rowsum
In-Reply-To: <201103291256.p2TCuZOi004855@nemo.mayo.edu>
References: <201103291256.p2TCuZOi004855@nemo.mayo.edu>
Message-ID: <CAJ55+dKo+hy36YYSO3D+EGo74R2sEecwoENfW4J3fG-pOtGE=g@mail.gmail.com>

On Wed, Mar 30, 2011 at 1:56 AM, Terry Therneau <therneau at mayo.edu> wrote:
> ? ?> with the entirely different rowSums, but it has been around
> ? ?> for a long time.)
> ? ?A lot longer than rowSums ...
> ? ?> Bill Dunlap
> ? ?> Spotfire, TIBCO Software
> ? ?---
> ? ? ?This made me smile. ?The rowsums function was originally an internal
> ? ?part of the survival package, used for fast computation of certain sums
> ? ?when there is a cluster() statement. ?It was Statistical Sciences
> ? ?(S-Plus) who moved it to global status. ?That is, they used it in enough
> ? ?other places that they decided to speed it up, took over the
> ? ?maintainance and ownership of the function (with my blessing), and
> ? ?ceased to label it as part of "survival" in the manual.
> ? ? ?This "metabug" can't be laid at R's feet.

The same process happened independently in R.  I ported the 'survival'
version of rowsum() to R, added it to base R in version 0.63.1, and
later it made it faster using hashing.

So perhaps it isn't entirely StatSci's fault, although it's likely
that R would eventually have added a rowsum() function for
compatibility.

  -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From renaud at mancala.cbio.uct.ac.za  Mon Dec 19 08:02:30 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Mon, 19 Dec 2011 09:02:30 +0200
Subject: [Rd] R package BibTex entries: looking for a more general
	solution
Message-ID: <4EEEE186.4070001@cbio.uct.ac.za>

Hi,

I actually adapted and integrated this feature into Achim's -- nice -- 
function (posted on r-help).
Romain included it a couple of weeks ago into the bibtex package as 
function write.bib, and submitted the update to CRAN, but some NOTEs in 
the check delayed its availability on CRAN.
You can still install and try out the new version with:
install.packages("bibtex", repos="http://R-Forge.R-project.org")

Keys for multiple citations are generated as "<pkgname>%i", which might 
not be ideal, but works ok though. It might be better not number the 
first (main) citation. Romain, I think I will submit a patch for this.
Hope this helps.

Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


From bibiko at eva.mpg.de  Mon Dec 19 10:48:03 2011
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Mon, 19 Dec 2011 10:48:03 +0100
Subject: [Rd] Possible bug in edit(x) for editing matrices [tested on a Mac]
Message-ID: <2749EBD6-2786-4E5C-BC58-7B8AE4177AE4@eva.mpg.de>

Hi,

it seems there's a possible bug in edit(x) if x is a matrix filled with NA only.

To reproduce please do the following:

a <- matrix()
edit(a)

change e.g. the cell value to 1 and close the GUI-based editor. edit(a) returns NA. This also happens for any dimension of the matrix as long as all cell values are NA. If at least one of the cell values is not NA it works correctly. The same behaviour I also get via "fix(x)".

I tried this by using R via the Terminal (editing via X11 and Tcl/Tk) and the Mac R-GUI app.

Here's my sessionInfo():

R version 2.14.0 (2011-10-31)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     


Any ideas? Or is this an undocumented behaviour?

Best,
--Hans


From ripley at stats.ox.ac.uk  Mon Dec 19 12:22:50 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Dec 2011 11:22:50 +0000
Subject: [Rd] Possible bug in edit(x) for editing matrices [tested on a
 Mac]
In-Reply-To: <2749EBD6-2786-4E5C-BC58-7B8AE4177AE4@eva.mpg.de>
References: <2749EBD6-2786-4E5C-BC58-7B8AE4177AE4@eva.mpg.de>
Message-ID: <4EEF1E8A.2020206@stats.ox.ac.uk>

On 19/12/2011 09:48, Hans-J?rg Bibiko wrote:
> Hi,
>
> it seems there's a possible bug in edit(x) if x is a matrix filled with NA only.

It's as documented.  Hint: look at mode(a) or str(a), and check what 
values are accepted for a logical matrix.

> To reproduce please do the following:
>
> a<- matrix()
> edit(a)
>
> change e.g. the cell value to 1 and close the GUI-based editor. edit(a) returns NA. This also happens for any dimension of the matrix as long as all cell values are NA. If at least one of the cell values is not NA it works correctly. The same behaviour I also get via "fix(x)".
>
> I tried this by using R via the Terminal (editing via X11 and Tcl/Tk) and the Mac R-GUI app.
>
> Here's my sessionInfo():
>
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> Any ideas? Or is this an undocumented behaviour?

> Best,
> --Hans
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Dec 19 12:39:39 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Dec 2011 12:39:39 +0100
Subject: [Rd] Saving nothing with save()
In-Reply-To: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>
References: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>
Message-ID: <20207.8827.526125.480848@stat.math.ethz.ch>

>>>>> Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>>>>>     on Sun, 18 Dec 2011 01:32:52 +0000 writes:

    > Scenario: Here I am working away in R. I've got results
    > that prove global warming is anthropogenic and also the
    > solution for producing limitless carbon-neutral energy
    > from nuclear fusion. Its been a good day.

    > So, I want to save my work. I don't want to overwrite my
    > current .RData, so I save it to another file:

    > save(file="prize.RData") # just need to email this to the
    > Nobel committee q() Save workspace image? [y/n/c]: - "no"
    > I don't want to save the workspace image, I just saved
    > everything to "prize.RData". But gee, it did seem to do
    > that quite quickly considering the volume of evidential
    > data in my work. My unix shell prompt returns.

    > Uh oh. See what I did there? I typed 'save' when I meant
    > 'save.image'.  What does that give me?

    >  A 42 byte, empty, latest.RData, and because there was no
    > warning or error I quit without saving it
    > again. Oops. Massive Data Loss.

    >  Is there any reason why save(file="file.RData") couldn't
    > warn or error if you try and save nothing? There's no
    > obvious check in the R code for save.

    > Barry

    > PS the above scenario is fictional.
really?  ;-)

well, after *not* save()ing all your findings, it wouldn't have
been such a good day, would it?

well, in spite of that.
I agree that  save() should warn or stop in that case.
I have now committed a version -- to R-devel only -- 
which stop()s if  'pretest=TRUE' and uses  warning() otherwise,
e.g., in the case of save.image() when there's nothing to save.

Thank you, Barry. for the suggestion!
Martin

    > When did I last have a good day?

(I wish you more of those..)


From bibiko at eva.mpg.de  Mon Dec 19 12:43:01 2011
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Mon, 19 Dec 2011 12:43:01 +0100
Subject: [Rd] Possible bug in edit(x) for editing matrices [tested on a
	Mac]
In-Reply-To: <4EEF1E8A.2020206@stats.ox.ac.uk>
References: <2749EBD6-2786-4E5C-BC58-7B8AE4177AE4@eva.mpg.de>
	<4EEF1E8A.2020206@stats.ox.ac.uk>
Message-ID: <1667C8DD-320B-437D-97DC-A5DD7EF19D35@eva.mpg.de>


On 19 Dec 2011, at 12:22, Prof Brian Ripley wrote:

>> it seems there's a possible bug in edit(x) if x is a matrix filled with NA only.
> 
> It's as documented.  Hint: look at mode(a) or str(a), and check what values are accepted for a logical matrix.

Thank you very much! I wasn't aware of the circumstance that mode(matrix()) of course returns 'logical'. Maybe one could warn the user in the function "edit(x)" that if (is.matrix(x) && is.logical(x) == TRUE) that edit(x) doesn't work since my workaround was that I created a matrix of the dimension 10x20 via matrix(NA, nrow=10, ncol=20) and used the GUI data editor to fill the matrix's cells with values.

Kind regards,
--Hans

From richierocks at gmail.com  Mon Dec 19 11:34:03 2011
From: richierocks at gmail.com (Richard Cotton)
Date: Mon, 19 Dec 2011 10:34:03 +0000
Subject: [Rd] Speed issue when writing to RGui console from tcl/tk GUI
Message-ID: <CAPp_+=fy1CeZWWAvGqmRG2a0d2v0DTupT-_WvK8OT2W2tsNc7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111219/a262b124/attachment.pl>

From friendly at yorku.ca  Mon Dec 19 14:56:34 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 19 Dec 2011 08:56:34 -0500
Subject: [Rd] R package BibTex entries: looking for a more general
	solution
In-Reply-To: <4EEEE186.4070001@cbio.uct.ac.za>
References: <4EEEE186.4070001@cbio.uct.ac.za>
Message-ID: <4EEF4292.9080905@yorku.ca>

On 12/19/2011 2:02 AM, Renaud Gaujoux wrote:
> Hi,
>
> I actually adapted and integrated this feature into Achim's -- nice -- 
> function (posted on r-help).
> Romain included it a couple of weeks ago into the bibtex package as 
> function write.bib, and submitted the update to CRAN, but some NOTEs 
> in the check delayed its availability on CRAN.
> You can still install and try out the new version with:
> install.packages("bibtex", repos="http://R-Forge.R-project.org")
>
> Keys for multiple citations are generated as "<pkgname>%i", which 
> might not be ideal, but works ok though. It might be better not number 
> the first (main) citation. Romain, I think I will submit a patch for 
> this.
> Hope this helps.
>
Thanks, Renaud

I now have a working function, Rpackages.bib() that is roughly 
equivalent to your write.bib() and other related
material at
http://euclid.psych.yorku.ca/SCS/Private/Rbibs/

Also, see the document
http://euclid.psych.yorku.ca/SCS/Private/Rbibs/Rpkg-test.pdf
which reports some problems & perl fixes for the generated bibentries.  
These might be incorporated into
the functions to make the resulting bibtex files directly usable.  Your 
bibtex package seems the most natural place for
this.

Also, write.bib() doesn't seem to work unless you pass a list of package 
names.

 > write.bib()
Error in is(entry, "bibentry") :
   argument "entry" is missing, with no default
 > write.bib(NULL)
Error in write.bib(NULL) :
   Invalid argument `entry`: expected a bibentry object or a character 
vector of package names.
 >


best,
-Michael



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From renaud at mancala.cbio.uct.ac.za  Mon Dec 19 15:09:45 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Mon, 19 Dec 2011 16:09:45 +0200
Subject: [Rd] R package BibTex entries: looking for a more general
	solution
In-Reply-To: <4EEF4292.9080905@yorku.ca>
References: <4EEEE186.4070001@cbio.uct.ac.za> <4EEF4292.9080905@yorku.ca>
Message-ID: <4EEF45A9.2060502@cbio.uct.ac.za>

Indeed I broke the function when adding support for bibentry objects...
By the way, let's give credits back to Ceasars: I am not the author of 
the bibtex package, Romain Francois is. I just contributed the write.bib 
function, mainly inspired by Achim's function.

Romain, I will send a fix for this now.

Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 19/12/2011 15:56, Michael Friendly wrote:
> On 12/19/2011 2:02 AM, Renaud Gaujoux wrote:
>> Hi,
>>
>> I actually adapted and integrated this feature into Achim's -- nice 
>> -- function (posted on r-help).
>> Romain included it a couple of weeks ago into the bibtex package as 
>> function write.bib, and submitted the update to CRAN, but some NOTEs 
>> in the check delayed its availability on CRAN.
>> You can still install and try out the new version with:
>> install.packages("bibtex", repos="http://R-Forge.R-project.org")
>>
>> Keys for multiple citations are generated as "<pkgname>%i", which 
>> might not be ideal, but works ok though. It might be better not 
>> number the first (main) citation. Romain, I think I will submit a 
>> patch for this.
>> Hope this helps.
>>
> Thanks, Renaud
>
> I now have a working function, Rpackages.bib() that is roughly 
> equivalent to your write.bib() and other related
> material at
> http://euclid.psych.yorku.ca/SCS/Private/Rbibs/
>
> Also, see the document
> http://euclid.psych.yorku.ca/SCS/Private/Rbibs/Rpkg-test.pdf
> which reports some problems & perl fixes for the generated 
> bibentries.  These might be incorporated into
> the functions to make the resulting bibtex files directly usable.  
> Your bibtex package seems the most natural place for
> this.
>
> Also, write.bib() doesn't seem to work unless you pass a list of 
> package names.
>
> > write.bib()
> Error in is(entry, "bibentry") :
>   argument "entry" is missing, with no default
> > write.bib(NULL)
> Error in write.bib(NULL) :
>   Invalid argument `entry`: expected a bibentry object or a character 
> vector of package names.
> >
>
>
> best,
> -Michael
>
>
>


From jonathan.shore at gmail.com  Mon Dec 19 16:30:11 2011
From: jonathan.shore at gmail.com (Jonathan Shore)
Date: Mon, 19 Dec 2011 10:30:11 -0500
Subject: [Rd] Issues with building package with C src on windows [R CMD
	INSTALL ignoring makefile]
Message-ID: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>

I've written a rather complex package that requires overriding the default compilation behavior for the C code component.   In the src dir I have a Makefile that is used correctly on OSX and Linux builds of the package, but completely ignored on windows.

R CMD INSTALL <package> 

on windows runs Makeconf instead of running make on my Makefile.    If run make in the src directory manually on windows, the shared library compiles.

How can I get the INSTALL command to look for the Makefile?    I am building on R 2.14.0 on a win 7 vm.

Thanks
Jonathan

From simon.urbanek at r-project.org  Mon Dec 19 16:38:34 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 19 Dec 2011 10:38:34 -0500
Subject: [Rd] Saving nothing with save()
In-Reply-To: <20207.8827.526125.480848@stat.math.ethz.ch>
References: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>
	<20207.8827.526125.480848@stat.math.ethz.ch>
Message-ID: <001C4AF4-4AE1-4888-B6F2-4695ED3EA894@r-project.org>

Martin,

On Dec 19, 2011, at 6:39 AM, Martin Maechler wrote:

>>>>>> Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>>>>>>    on Sun, 18 Dec 2011 01:32:52 +0000 writes:
> 
>> Scenario: Here I am working away in R. I've got results
>> that prove global warming is anthropogenic and also the
>> solution for producing limitless carbon-neutral energy
>> from nuclear fusion. Its been a good day.
> 
>> So, I want to save my work. I don't want to overwrite my
>> current .RData, so I save it to another file:
> 
>> save(file="prize.RData") # just need to email this to the
>> Nobel committee q() Save workspace image? [y/n/c]: - "no"
>> I don't want to save the workspace image, I just saved
>> everything to "prize.RData". But gee, it did seem to do
>> that quite quickly considering the volume of evidential
>> data in my work. My unix shell prompt returns.
> 
>> Uh oh. See what I did there? I typed 'save' when I meant
>> 'save.image'.  What does that give me?
> 
>> A 42 byte, empty, latest.RData, and because there was no
>> warning or error I quit without saving it
>> again. Oops. Massive Data Loss.
> 
>> Is there any reason why save(file="file.RData") couldn't
>> warn or error if you try and save nothing? There's no
>> obvious check in the R code for save.
> 
>> Barry
> 
>> PS the above scenario is fictional.
> really?  ;-)
> 
> well, after *not* save()ing all your findings, it wouldn't have
> been such a good day, would it?
> 
> well, in spite of that.
> I agree that  save() should warn or stop in that case.
> I have now committed a version -- to R-devel only -- 
> which stop()s if  'pretest=TRUE' and uses  warning() otherwise,

I don't think I like that - why should it warn/stop in any case even when the use is absolutely legal?

I think this is the wrong approach - the whole idea was to warn on unintended *interactive* use - breaking existing code in the process is IMHO not necessary. I don't think 
save(list=x, file=y)
should fail even if x is empty - that makes it fail for completely legal code. What Barry was worried about was the interactive case of
save(file=x)
which should IMHO warn (there is a precedent for stopping as well - see tar - so I won't object).

I really see no reason for adding the pretest flag - it makes no sense since is warns anyway so it doesn't help at all. I would propose changing *only* the behavior of save(file=x) (to warn or stop - personally I prefer former) and not anything else.


> e.g., in the case of save.image() when there's nothing to save.
> 

Why should save.image() warn? Again, it causes unnecessary trouble for automated saving... empty workspace is probably even more common that using save(file=foo) ... If save() was fixed as above, that would be a non-issue.


> Thank you, Barry. for the suggestion!

Well, you did not follow his suggestion, though ;)

Cheers,
Simon


> Martin
> 
>> When did I last have a good day?
> 
> (I wish you more of those..)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ligges at statistik.tu-dortmund.de  Mon Dec 19 16:38:48 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 19 Dec 2011 16:38:48 +0100
Subject: [Rd] Issues with building package with C src on windows [R CMD
 INSTALL ignoring makefile]
In-Reply-To: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
References: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
Message-ID: <4EEF5A88.20701@statistik.tu-dortmund.de>



On 19.12.2011 16:30, Jonathan Shore wrote:
> I've written a rather complex package that requires overriding the default compilation behavior for the C code component.   In the src dir I have a Makefile that is used correctly on OSX and Linux builds of the package, but completely ignored on windows.
>
> R CMD INSTALL<package>
>
> on windows runs Makeconf instead of running make on my Makefile.    If run make in the src directory manually on windows, the shared library compiles.
>
> How can I get the INSTALL command to look for the Makefile?    I am building on R 2.14.0 on a win 7 vm.


See Writing R Extensions that tells you to write a

Makefile.win

which is used under Windows.

Best,
Uwe Ligges


>
> Thanks
> Jonathan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Mon Dec 19 16:42:48 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 19 Dec 2011 10:42:48 -0500
Subject: [Rd] Issues with building package with C src on windows [R CMD
	INSTALL ignoring makefile]
In-Reply-To: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
References: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
Message-ID: <58A3EC80-C9A4-44E3-B84F-E8F7EA868969@r-project.org>


On Dec 19, 2011, at 10:30 AM, Jonathan Shore wrote:

> I've written a rather complex package that requires overriding the default compilation behavior for the C code component.   In the src dir I have a Makefile that is used correctly on OSX and Linux builds of the package, but completely ignored on windows.
> 
> R CMD INSTALL <package> 
> 
> on windows runs Makeconf instead of running make on my Makefile.    If run make in the src directory manually on windows, the shared library compiles.
> 

See R-ext - you probably need to create Makefile.win

Note that in most cases it is unnecessary to use Makefile -  you can add targets to Makevars which will supply you with the correct flags and give you flexibility whereas Makefile is very limited in that you need to write all rules by hand which is very error prone and likely to break with new R versions.

Cheers,
Simon


> How can I get the INSTALL command to look for the Makefile?    I am building on R 2.14.0 on a win 7 vm.
> 
> Thanks
> Jonathan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Mon Dec 19 16:43:56 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Dec 2011 15:43:56 +0000
Subject: [Rd] Issues with building package with C src on windows [R CMD
 INSTALL ignoring makefile]
In-Reply-To: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
References: <04504571-13CA-47CC-8BC9-11ED1CA6653B@gmail.com>
Message-ID: <4EEF5BBC.3050002@stats.ox.ac.uk>

If all else fails, read the manual: it is explicitly documented that you 
need a file src/Makefile.win .

And very likely you should rather study the manual to resolve what issue 
you think 'requires' a Makefile: those who want to use R on other 
platforms (e.g. Solaris and AIX) are unlikely to thank you for taking 
that route.

On 19/12/2011 15:30, Jonathan Shore wrote:
> I've written a rather complex package that requires overriding the default compilation behavior for the C code component.   In the src dir I have a Makefile that is used correctly on OSX and Linux builds of the package, but completely ignored on windows.
>
> R CMD INSTALL<package>
>
> on windows runs Makeconf instead of running make on my Makefile.    If run make in the src directory manually on windows, the shared library compiles.
>
> How can I get the INSTALL command to look for the Makefile?    I am building on R 2.14.0 on a win 7 vm.
>
> Thanks
> Jonathan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dtenenba at fhcrc.org  Mon Dec 19 20:22:26 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 19 Dec 2011 11:22:26 -0800
Subject: [Rd] error starting R-devel with --arch ppc -- "an unusual
 circumstance has arisen"
In-Reply-To: <CDE00E64-F91A-4508-AC59-43668557DB63@r-project.org>
References: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>
	<CDE00E64-F91A-4508-AC59-43668557DB63@r-project.org>
Message-ID: <CAF42j20UoFQSWiPy55xzWxLE9xfskkANXceU9YXV0Mkf4ddsAg@mail.gmail.com>

On Thu, Dec 15, 2011 at 4:46 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Dan,
>
> I don't know why, but something is off in the recent R-devel build for ppc. The result is that the installed binary ppc is older than the other ones, so it doesn't have paste0 while the others do.
>
> The really strange thing is that the build logs show success, but the build directory is old and the resulting tar ball is not updated. I'll keep you posted.


It looks like this has been fixed.
Thanks!

Dan


>
> Cheers,
> Simon
>
>
>
> On Dec 15, 2011, at 4:56 PM, Dan Tenenbaum wrote:
>
>> When I try and start R-devel as follows:
>>
>> R --vanilla --arch ppc
>>
>> I see this, over and over again, ^C does not interrupt it and I have
>> to close the terminal window:
>>
>>> Error in paste0(prefix, conditionMessage(e), "\n") :
>> ?not a BUILTIN function
>> In addition: Warning message:
>> An unusual circumstance has arisen in the nesting of readline input.
>> Please report using bug.report()
>>> Error in paste0(prefix, conditionMessage(e), "\n") :
>> ?not a BUILTIN function
>> In addition: Warning message:
>> An unusual circumstance has arisen in the nesting of readline input.
>> Please report using bug.report()
>>
>> I can't get to sessionInfo() but here is sessionInfo() of the same R
>> invoked with no --arch argument:
>>
>> R Under development (unstable) (2011-12-14 r57899)
>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>>
>> This seems to be related to the issue I reported here previously:
>> https://stat.ethz.ch/pipermail/r-devel/2011-December/062793.html
>>
>>
>> Thanks,
>> Dan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From simon.urbanek at r-project.org  Mon Dec 19 20:57:06 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 19 Dec 2011 14:57:06 -0500
Subject: [Rd] error starting R-devel with --arch ppc -- "an unusual
	circumstance has arisen"
In-Reply-To: <CAF42j20UoFQSWiPy55xzWxLE9xfskkANXceU9YXV0Mkf4ddsAg@mail.gmail.com>
References: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>
	<CDE00E64-F91A-4508-AC59-43668557DB63@r-project.org>
	<CAF42j20UoFQSWiPy55xzWxLE9xfskkANXceU9YXV0Mkf4ddsAg@mail.gmail.com>
Message-ID: <53686490-D5D0-4F62-A780-B9A448B5A9B9@r-project.org>


On Dec 19, 2011, at 2:22 PM, Dan Tenenbaum wrote:

> On Thu, Dec 15, 2011 at 4:46 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Dan,
>> 
>> I don't know why, but something is off in the recent R-devel build for ppc. The result is that the installed binary ppc is older than the other ones, so it doesn't have paste0 while the others do.
>> 
>> The really strange thing is that the build logs show success, but the build directory is old and the resulting tar ball is not updated. I'll keep you posted.
> 
> 
> It looks like this has been fixed.

Well, temporarily - I nudged the build manually (so the paste0 issues is gone), but the nightly builds behave very oddly - they create few files (like SVN-REVISION) but even Makefiles are not generated. I'll try to flush the whole tree and see how it goes ...

Thanks,
Simon


> Thanks!
> 
> Dan
> 
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> On Dec 15, 2011, at 4:56 PM, Dan Tenenbaum wrote:
>> 
>>> When I try and start R-devel as follows:
>>> 
>>> R --vanilla --arch ppc
>>> 
>>> I see this, over and over again, ^C does not interrupt it and I have
>>> to close the terminal window:
>>> 
>>>> Error in paste0(prefix, conditionMessage(e), "\n") :
>>>  not a BUILTIN function
>>> In addition: Warning message:
>>> An unusual circumstance has arisen in the nesting of readline input.
>>> Please report using bug.report()
>>>> Error in paste0(prefix, conditionMessage(e), "\n") :
>>>  not a BUILTIN function
>>> In addition: Warning message:
>>> An unusual circumstance has arisen in the nesting of readline input.
>>> Please report using bug.report()
>>> 
>>> I can't get to sessionInfo() but here is sessionInfo() of the same R
>>> invoked with no --arch argument:
>>> 
>>> R Under development (unstable) (2011-12-14 r57899)
>>> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>>> 
>>> locale:
>>> [1] C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> 
>>> This seems to be related to the issue I reported here previously:
>>> https://stat.ethz.ch/pipermail/r-devel/2011-December/062793.html
>>> 
>>> 
>>> Thanks,
>>> Dan
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
> 
> 


From taplate at gmail.com  Tue Dec 20 03:59:28 2011
From: taplate at gmail.com (Tony Plate)
Date: Mon, 19 Dec 2011 21:59:28 -0500
Subject: [Rd] Why is the 64bit Windows version of package RSVGTipsDevice not
 available on CRAN?
Message-ID: <4EEFFA10.3060405@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111219/57d674ad/attachment.pl>

From sgerber at cs.utah.edu  Tue Dec 20 05:44:27 2011
From: sgerber at cs.utah.edu (sgerber)
Date: Mon, 19 Dec 2011 21:44:27 -0700
Subject: [Rd]  graphics device event handling
In-Reply-To: <53686490-D5D0-4F62-A780-B9A448B5A9B9@r-project.org>
References: <CAF42j23bq2nm8aD7RP9oHhDYostOw=ogr1-xtxfcwLskX9O2Fw@mail.gmail.com>
	<CDE00E64-F91A-4508-AC59-43668557DB63@r-project.org>
	<CAF42j20UoFQSWiPy55xzWxLE9xfskkANXceU9YXV0Mkf4ddsAg@mail.gmail.com>
	<53686490-D5D0-4F62-A780-B9A448B5A9B9@r-project.org>
Message-ID: <08c69b703d92bb168aa16f0e600ef38e@cs.utah.edu>

Hi All

I run across the following situation quite frequently and was wondering if
there exists a simple solution that I missed.

Situation:
I develop some graphical display using the nice basic R graphical
functions (plots, lines, images, histogramm ...).
Now I would like to add a few simple user interaction capabilities.

Problem:
There seems to be no simple callback type event handling for
mouse/keyboard events for the basic graphics devices.
The setGraphicsEventHandlers only work on X11 (on MAC) which doesn't look
nearly as nice as the basic quartz device and doesn't support transparency.

Question:
Is there a way to add graphics event handling to the CairoX11 or quartz
interface in a similar simple fashion as the setGraphicsEventHandlers
framework without requiring packages such as Rgtk and deviceCairo which can
get fairly large and seem somewhat overkill for adding few simple
interactions to existing R plot compositions.


Kind Regards
Sam


From dbebber at earthwatch.org.uk  Tue Dec 20 12:49:13 2011
From: dbebber at earthwatch.org.uk (Dan Bebber)
Date: Tue, 20 Dec 2011 11:49:13 -0000
Subject: [Rd] rgeos on Linux requires GEOS 3.2.3, not 3.3.1
Message-ID: <0BDA954190B0344B82FD28336B41D1C50405608D@exchangesrv1.earthwatchewe.lan>

Some notes on installing rgeos in R 2.14.0 on a Linux Mint 11 (x86_64-pc-linux-gnu) machine
1. rgeos 0.1-15 will not run with GEOS 3.2.0-1, which is the version currently available on Synaptic package manager
2. I installed GEOS 3.3.1 (the latest version) from http://trac.osgeo.org/geos/, but rgeos will not run with this either
3. I then install GEOS 3.2.3, and now rgeos works fine!

It seems therefore that there is a mismatch between the GEOS version that is available on Synaptic, and the rgeos version on Cran (just in case anyone else comes across this issue).

Best wishes,
Dan Bebber


From ripley at stats.ox.ac.uk  Tue Dec 20 13:37:20 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Dec 2011 12:37:20 +0000
Subject: [Rd] rgeos on Linux requires GEOS 3.2.3, not 3.3.1
In-Reply-To: <0BDA954190B0344B82FD28336B41D1C50405608D@exchangesrv1.earthwatchewe.lan>
References: <0BDA954190B0344B82FD28336B41D1C50405608D@exchangesrv1.earthwatchewe.lan>
Message-ID: <4EF08180.4010703@stats.ox.ac.uk>

On 20/12/2011 11:49, Dan Bebber wrote:
> Some notes on installing rgeos in R 2.14.0 on a Linux Mint 11 (x86_64-pc-linux-gnu) machine
> 1. rgeos 0.1-15 will not run with GEOS 3.2.0-1, which is the version currently available on Synaptic package manager
> 2. I installed GEOS 3.3.1 (the latest version) from http://trac.osgeo.org/geos/, but rgeos will not run with this either
> 3. I then install GEOS 3.2.3, and now rgeos works fine!
>
> It seems therefore that there is a mismatch between the GEOS version that is available on Synaptic, and the rgeos version on Cran (just in case anyone else comes across this issue).

Yes, as the package says, GEOS 3.2.2 is required.  But GEOS 3.3.1 does 
work on many platforms (see the CRAN check summaries for proof; and I 
also have a Mac OS X build up).

This really isn't the appropriate list: talk to the maintainer or use 
r-sig-geo.

> Best wishes,
> Dan Bebber
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Tue Dec 20 13:54:56 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 20 Dec 2011 13:54:56 +0100
Subject: [Rd] Speed issue when writing to RGui console from tcl/tk GUI
In-Reply-To: <CAPp_+=fy1CeZWWAvGqmRG2a0d2v0DTupT-_WvK8OT2W2tsNc7w@mail.gmail.com>
References: <CAPp_+=fy1CeZWWAvGqmRG2a0d2v0DTupT-_WvK8OT2W2tsNc7w@mail.gmail.com>
Message-ID: <5057C72E-A522-40A2-8C70-E75CEE499D2E@gmail.com>


On Dec 19, 2011, at 11:34 , Richard Cotton wrote:

> It seems that there are speed issues when printing to the R console from a
> tcl/tk GUI.
> 
> Here are functions to write a lot of output, and to display how long it
> takes.
> 
> printsalot <- function(n)
> {
>  for(i in 1:n) cat(i, fill = TRUE)
> }
> 
> timings <- function(n = 1e3)
> {
>  print(system.time(printsalot(n)))
> }
> 
> Calling timings() from the console reveals a run time of a few hundredths
> of a second.
> 
> The following GUI has two buttons.  Clicking the "slow" buttons just calls
> timings directly, and takes several seconds to run.  However, if we request
> input from the console, via readline (the "fast" button) then the timing
> drops back down to hundredths of a second.
> 
> library(tcltk)
> win <- tktoplevel()
> btn1 <- ttkbutton(win, text = "slow", command = function() timings())
> btn2 <- ttkbutton(win, text = "fast", command = function() {readline("Press
> ENTER > "); timings()})
> tkpack(btn1, btn2)
> 
> I've only observed this slow behaviour with RGui on Windows (XP) - it
> doesn't happen with Rterminal or eclipse/StatET or RStudio.
> 
> I want a few people to run this code to see if it affects, for example,
> other OSes, to narrow down the extent of the problem before I submit it as
> a bug.
> 

Nothing of the sort is happening on OSX. The RGui console is known to be slow if unbuffered, so you may want to experiment with turning buffering on. It could also be some event handling issue, but it doesn't really seem likely to me.

-pd

> Also, if you have any insight as to what is happening or fixes, I'd be
> interested to know.
> 
> Regards,
> Richie.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Tue Dec 20 15:17:17 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 20 Dec 2011 15:17:17 +0100
Subject: [Rd] Why is the 64bit Windows version of package RSVGTipsDevice
 not available on CRAN?
In-Reply-To: <4EEFFA10.3060405@gmail.com>
References: <4EEFFA10.3060405@gmail.com>
Message-ID: <4EF098ED.3050607@statistik.tu-dortmund.de>

This is because it does not pass 64-bit checks for me in the CRAN 
checks, doing it manually, it just crashed here (further discussion 
perhaps better off list):



* checking examples ...
** running examples for arch 'i386' ... OK
** running examples for arch 'x64' ... ERROR
Running examples in 'RSVGTipsDevice-Ex.R' failed
The error most likely occurred in:

 > ### Name: RSVGTipsDevice
 > ### Title: A SVG Graphics Driver with dynamic tips
 > ### Aliases: RSVGTipsDevice
 > ### Keywords: device package
 >
 > ### ** Examples
 >
 > library("RSVGTipsDevice")
 > sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=C                 LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=C                LC_NUMERIC=C
[5] LC_TIME=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RSVGTipsDevice_1.0-4
 > devSVGTips("svgplot1.svg", toolTipMode=1,
+     title="SVG example plot 1: shapes and points, tooltips are title + 
1 line")
 > plot(c(0,10),c(0,10), type="n", xlab="x", ylab="y",
+     main="Example SVG plot with title + 1 line tips (mode=1)")
 > setSVGShapeToolTip(title="A rectangle", desc="that is yellow")
 > rect(1,1,4,6, col='yellow')
 > setSVGShapeToolTip(title="1st circle with title only")
 > points(5.5,7.5,cex=20,pch=19,col='red')
 > setSVGShapeToolTip(title="A triangle", desc="big and green")
 > polygon(c(3,6,8), c(3,6,3), col='green')
 > # no tooltips on these points
 > points(2:8, 8:2, cex=3, pch=19, col='black')
 > # tooltips on each these points
 > invisible(sapply(1:7, function(x)
+ {setSVGShapeToolTip(title=paste("point", x))
+  points(x+1, 8-x, cex=3, pch=1, col='black')}))
 > setSVGShapeToolTip(title="Text", desc="can have a tool tip too!")
 > text(x=4, y=9, lab="Poke me!", col="blue")
 > dev.off()


Best,
Uwe Ligges




On 20.12.2011 03:59, Tony Plate wrote:
> On CRAN, the package RSVGTipsDevice is only installed for 32bit Windows, and is not available as a 64bit package for Windows.
>
> The file linked to in the package check summary on CRAN says "NB: this package is only installed for sub-architecture 'i386' ".
>
> What do I need to do to make it available as both 64bit and 32bit on CRAN? (I am the maintainer of the package).
>
> It builds, checks and runs fine as a 64 bit package on my own Windows 64 bit (XP) machine.
>
> Has a flag has been set somewhere because some time in the past this package had problems running in 64 bit mode?
>
> Here's the truncated output from the link from CRAN package check page:
>
> http://www.r-project.org/nosvn/R.check/r-release-windows-ix86+x86_64/RSVGTipsDevice-00check.html
>
>    * using R version 2.14.0 (2011-10-31)
>    * using platform: i386-pc-mingw32 (32-bit)
>    * using session charset: ISO8859-1
>    * checking for file 'RSVGTipsDevice/DESCRIPTION' ... OK
>    * this is package 'RSVGTipsDevice' version '1.0-4'
>    * checking package namespace information ... OK
>    * checking package dependencies ... OK
>    * checking if this is a source package ... OK
>    * checking if there is a namespace ... OK
>    * checking whether package 'RSVGTipsDevice' can be installed ... OK
>    * checking installed package size ... OK
>      NB: this package is only installed for sub-architecture 'i386'
>    * checking package directory ... OK
>    * checking for portable file names ... OK
>    * ... [truncated]
>
>
> Here's the output of R CMD check on my own machine:
>
> $ /cygdrive/c/R/R-2.14.0/bin/x64/R.exe CMD check RSVGTipsDevice_1.0-4.tar.gz
> * using log directory 'D:/tplate/R/rforge/rsvgtipsdevice/RSVGTipsDevice.Rcheck'
> * using R version 2.14.0 (2011-10-31)
> * using platform: x86_64-pc-mingw32 (64-bit)
> * using session charset: ISO8859-1
> * checking for file 'RSVGTipsDevice/DESCRIPTION' ... OK
> * this is package 'RSVGTipsDevice' version '1.0-4'
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking whether package 'RSVGTipsDevice' can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * loading checks for arch 'i386'
> ** checking whether the package can be loaded ... OK
> ** checking whether the package can be loaded with stated dependencies ... OK
> ** checking whether the package can be unloaded cleanly ... OK
> ** checking whether the namespace can be loaded with stated dependencies ... OK
> ** checking whether the namespace can be unloaded cleanly ... OK
> * loading checks for arch 'x64'
> ** checking whether the package can be loaded ... OK
> ** checking whether the package can be loaded with stated dependencies ... OK
> ** checking whether the package can be unloaded cleanly ... OK
> ** checking whether the namespace can be loaded with stated dependencies ... OK
> ** checking whether the namespace can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking line endings in C/C++/Fortran sources/headers ... OK
> * checking line endings in Makefiles ... OK
> * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
> * checking compiled code ... OK
> * checking examples ...
> ** running examples for arch 'i386' ... OK
> ** running examples for arch 'x64' ... OK
> * checking PDF version of manual ... OK
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Dec 20 19:40:15 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Dec 2011 19:40:15 +0100
Subject: [Rd] Saving nothing with save()
In-Reply-To: <001C4AF4-4AE1-4888-B6F2-4695ED3EA894@r-project.org>
References: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>
	<20207.8827.526125.480848@stat.math.ethz.ch>
	<001C4AF4-4AE1-4888-B6F2-4695ED3EA894@r-project.org>
Message-ID: <20208.54927.535718.382583@stat.math.ethz.ch>

>>>>> Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Mon, 19 Dec 2011 10:38:34 -0500 writes:

    > Martin, On Dec 19, 2011, at 6:39 AM, Martin Maechler
    > wrote:

    >>>>>>> Barry Rowlingson <b.rowlingson at lancaster.ac.uk> on
    >>>>>>> Sun, 18 Dec 2011 01:32:52 +0000 writes:
    >> 
    >>> Scenario: Here I am working away in R. I've got results
    >>> that prove global warming is anthropogenic and also the
    >>> solution for producing limitless carbon-neutral energy
    >>> from nuclear fusion. Its been a good day.
    >> 
    >>> So, I want to save my work. I don't want to overwrite my
    >>> current .RData, so I save it to another file:
    >> 
    >>> save(file="prize.RData") # just need to email this to
    >>> the Nobel committee q() Save workspace image? [y/n/c]: -
    >>> "no" I don't want to save the workspace image, I just
    >>> saved everything to "prize.RData". But gee, it did seem
    >>> to do that quite quickly considering the volume of
    >>> evidential data in my work. My unix shell prompt
    >>> returns.
    >> 
    >>> Uh oh. See what I did there? I typed 'save' when I meant
    >>> 'save.image'.  What does that give me?
    >> 
    >>> A 42 byte, empty, latest.RData, and because there was no
    >>> warning or error I quit without saving it
    >>> again. Oops. Massive Data Loss.
    >> 
    >>> Is there any reason why save(file="file.RData") couldn't
    >>> warn or error if you try and save nothing? There's no
    >>> obvious check in the R code for save.
    >> 
    >>> Barry
    >> 
    >>> PS the above scenario is fictional.
    >> really?  ;-)
    >> 
    >> well, after *not* save()ing all your findings, it
    >> wouldn't have been such a good day, would it?
    >> 
    >> well, in spite of that.  I agree that save() should warn
    >> or stop in that case.  I have now committed a version --
    >> to R-devel only -- which stop()s if 'pretest=TRUE' and
    >> uses warning() otherwise,

    > I don't think I like that - why should it warn/stop in any
    > case even when the use is absolutely legal?

    > I think this is the wrong approach - the whole idea was to
    > warn on unintended *interactive* use - breaking existing
    > code in the process is IMHO not necessary. I don't think
    > save(list=x, file=y) should fail even if x is empty - that
    > makes it fail for completely legal code. What Barry was
    > worried about was the interactive case of save(file=x)
    > which should IMHO warn (there is a precedent for stopping
    > as well - see tar - so I won't object).

    > I really see no reason for adding the pretest flag - it
    > makes no sense since is warns anyway so it doesn't help at
    > all. I would propose changing *only* the behavior of
    > save(file=x) (to warn or stop - personally I prefer
    > former) and not anything else.

hmm


    >> e.g., in the case of save.image() when there's nothing to
    >> save.
    >> 

    > Why should save.image() warn? Again, it causes unnecessary
    > trouble for automated saving... empty workspace is
    > probably even more common that using save(file=foo) ... If
    > save() was fixed as above, that would be a non-issue.

warning in that case actually *was* a bit intentional:
I think too many people work with '.Rdata' etc ... and I always
use --no-save --no-restore.

But then, you are right.  If we'd want to change that behavior
that should be tried differently...

I've now changed the patch to only warn and only in the case
when the 'list' argument is missing(.).

Martin

    >> Thank you, Barry. for the suggestion!

    > Well, you did not follow his suggestion, though ;)

    > Cheers, Simon


    >> Martin
    >> 
    >>> When did I last have a good day?
    >> 
    >> (I wish you more of those..)
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >>


From dbebber at earthwatch.org.uk  Wed Dec 21 21:56:35 2011
From: dbebber at earthwatch.org.uk (Dan Bebber)
Date: Wed, 21 Dec 2011 20:56:35 -0000
Subject: [Rd] rgeos on Linux requires GEOS 3.2.3, not 3.3.1
References: <29936163.43956.1324466033616.JavaMail.nabble@joe.nabble.com>
Message-ID: <0BDA954190B0344B82FD28336B41D1C504056098@exchangesrv1.earthwatchewe.lan>

Firstly my apologies, apparently this list is not the correct venue for my previous message.
I removed GEOS 3.2.3 and rgeos, then installed 3.3.1 and reinstalled rgeos.
rgeos now appears to work correctly and the issue is resolved.

Dan

-----Original Message-----
From: Roger.Bivand at nhh.no [mailto:Roger.Bivand at nhh.no]
Sent: Wed 21/12/2011 11:13
To: Dan Bebber
Subject: rgeos on Linux requires GEOS 3.2.3, not 3.3.1
 
As Brian Ripley said, this is for R-sig-geo. There are lots of issues with ubuntu and similar binary builds of GEOS. rgeos definitely works with 3.3.1, but 3.2.2 is the minimum required. I would be interested in knowing why your 3.3.1 build did not permit rgeos to install successfully. It would be helpful not to leave misleading information on lists, so if you can confirm that 3.3.1 GEOS installed from source works for you (on list), I'd be grateful. 

Roger

<quote author='Dan Bebber-2'>
Some notes on installing rgeos in R 2.14.0 on a Linux Mint 11
(x86_64-pc-linux-gnu) machine
1. rgeos 0.1-15 will not run with GEOS 3.2.0-1, which is the version
currently available on Synaptic package manager
2. I installed GEOS 3.3.1 (the latest version) from
http://trac.osgeo.org/geos/, but rgeos will not run with this either
3. I then install GEOS 3.2.3, and now rgeos works fine!

It seems therefore that there is a mismatch between the GEOS version that is
available on Synaptic, and the rgeos version on Cran (just in case anyone
else comes across this issue).

Best wishes,
Dan Bebber

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/rgeos-on-Linux-requires-GEOS-3-2-3-not-3-3-1-tp4217622p4217622.html


From b.rowlingson at lancaster.ac.uk  Thu Dec 22 10:29:29 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 22 Dec 2011 09:29:29 +0000
Subject: [Rd] Saving nothing with save()
In-Reply-To: <20208.54927.535718.382583@stat.math.ethz.ch>
References: <CANVKczNM=0L+8RbN_rwfG898euRu9y-jFUdgWtQ9RRZk1h71-w@mail.gmail.com>
	<20207.8827.526125.480848@stat.math.ethz.ch>
	<001C4AF4-4AE1-4888-B6F2-4695ED3EA894@r-project.org>
	<20208.54927.535718.382583@stat.math.ethz.ch>
Message-ID: <CANVKczNDPvjKtCt5xhgFpnCAHCZGr42Rt_v7rANsd=-cbJY5EA@mail.gmail.com>

On Tue, Dec 20, 2011 at 6:40 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:

> I've now changed the patch to only warn and only in the case
> when the 'list' argument is missing(.).
>
> Martin

 Thanks Martin, that sounds great.

 This came about from a question on Stack Overflow, where a user was
loading an R Data file and seemingly there was nothing in it, and
there were no warnings. I suspected maybe there really was nothing in
it, and discovered an easy way to create empty R Data files without
really trying.

 Turns out her file was over 400k bytes long and once she reinstalled
R [yikes] it loaded... What was the real problem? Well we never found
out!


Barry


From jorismeys at gmail.com  Thu Dec 22 16:59:38 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 22 Dec 2011 16:59:38 +0100
Subject: [Rd] Small inconsistency in help page unique - duplicated doesn't
	return indices.
Message-ID: <CAO1zAVZYhG9syFxH=HBW9UrayLzG5Ra_K--umUUUri1yD9URVA@mail.gmail.com>

I read this in the help page of unique in 2.14.0, but I reckon it's
not changed yet in 2.14.1

Under the section 'see also' is mentioned :

    duplicated which gives the indices of duplicated elements.

Afaik duplicated doesn't return the indices but a logical vector. I
propose to change to

    duplicated which gives a logical vector indicating duplicated elements.

or something along that line.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From mtmorgan at fhcrc.org  Thu Dec 22 19:01:16 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 22 Dec 2011 10:01:16 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EEE3948.2080300@r-project.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org> <4EEBCCD5.6010405@fhcrc.org>
	<4EEBE7CD.5080502@r-project.org>
	<CAOQ5Nyd_ies9vyvRuD78-iAf41C4qPPtbLfZOmaQMLYe8YCbTg@mail.gmail.com>
	<4EEE3948.2080300@r-project.org>
Message-ID: <4EF3706C.5050305@fhcrc.org>

On 12/18/2011 11:04 AM, John Chambers wrote:
>
>
> On 12/17/11 6:02 AM, Michael Lawrence wrote:
>> I guess what it boils down to is whether it makes sense for PkgB to have
>> exportMethods(unique) when PkgB does not export(unique) or have PkgA in
>> Depends. And whether it makes sense for PkgC to have
>> importMethodsFrom(PkgB, unique) without importFrom(PkgA, unique). If it
>> is not feasible/sensible to support implicit passing of generics up the
>> dependency stack, then R should probably emit some sort of warning/error
>> when methods are exported or imported without the corresponding generic.
>>
>> The fact that a generic is being created for an implicit generic defined
>> in 'base' is not really the issue here.
>
> On the contrary, it's why we need to do some thinking about what we want.
>
> Try replacing "unique" with "sum" throughout Martin's example, adjusting
> the method definition appropriately. No problems arise, because sum() is
> a primitive. Exporting and importing methods works as implied by the
> extensions manual, but via the implicit generic for sum().
>
> The essential point is that the methods being imported are "for" the
> generic implied by the function in package "base". PkgA is the
> irrelevant aspect if the methods come from PkgB and the implied generic
> comes from "base". The problem is that there is no "flag" for
> non-primitive functions that says "Methods have been defined for this
> function (base::unique in this case), so some calls should carry out
> method dispatch."
>
> The extensions manual stated that exportMethods() would "export the
> generic". We could make that true or make it unnecessary, by having
> importMethods() look for a generic in the referenced package and infer
> the implicit generic (maybe with a message). Otherwise, we're adding
> inconsistent requirements for primitives vs true functions in the base
> package.

One advantage of the exportMethods solution is that a user of PkgB gets 
access to the unique generic without having all of PkgA on the search 
path; it would be unfortunate if the exported generic also carried with 
it the burden of documenting the generic (again).

Even with the insights from this thread, I find myself spending a very 
long time working out the appropriate NAMESPACE declarations for my 
current projects.

Martin

>
> John
>>
>> Thanks,
>> Michael
>>
>> On Fri, Dec 16, 2011 at 4:52 PM, John Chambers <jmc at r-project.org
>> <mailto:jmc at r-project.org>> wrote:
>>
>> The key point here is that setGeneric("unique") is done that way,
>> without other argument, whoever does it. That creates the generic
>> from the implicit generic corresponding to base::unique. If package
>> A had done anything else, the resulting methods tables would NOT
>> refer to package "base" but to package "PkgA" and it's that version
>> of the generic that would need to be imported.
>>
>> So it's not particularly relevant that we're dealing with
>> PkgA::unique() if the generic function was created from base::unique
>> by the standard call. That's what would make an automatic
>> imputation of the generic from importMethods() possible.
>>
>>
>> On 12/16/11 2:57 PM, Martin Morgan wrote:
>>
>> On 12/16/2011 12:19 PM, John Chambers wrote:
>>
>> The subject heading is correct if referring to
>> exportMethods() and
>> importMethodsFrom(). They refer to the methods tables, not
>> the generic
>> functions, whatever the extensions manual says.
>>
>> Looking into the code of namespaceImportMethods() will
>> illustrate this.
>> It just deals with lists of method tables obtained from
>> .getGenerics()
>> which in spite of its name also only looks for the method
>> table metadata
>> objects.
>>
>> As I vaguely recall, there was some concern at one time
>> about having
>> extra copies of the generic version of the function.
>>
>> The fundamental problem is that creating methods for
>> unique(), say, does
>> not change the way calls to base::unique() work. Therefore,
>> all packages
>> that want to use methods have to ensure that a generic
>> version of unique
>> gets in between. Primitive functions are an exception
>> because the method
>> dispatch is in the C code and has a rule for checking when
>> given an S4
>> object. There is no corresponding provision for evaluating a
>> call to a
>> regular function.
>>
>> If the importing package has a setGeneric() for the relevant
>> function
>> then its own namespace has the generic version of the
>> function. (That is
>> a workaround, but I inferred that was what you were trying
>> to avoid.)
>>
>> Fixes seem possible, but some care is needed. If exportMethods
>> automatically exported the generic function, it really is no
>> different
>> from export() for that function.
>>
>>
>> export() somehow implies ownership of the generic, e.g.,
>> responsibility
>> for documentation. I can see in the scenario below that PkgB
>> might be
>> expected to Depends: PkgA if it intends for the user to access
>> PkgB's
>> methods on PkgA::unique.
>>
>> namespaceImportMethods() could try to supply the generic
>> function if it
>> is not already present. If it does not find the generic in
>> the namespace
>> being imported, it would essentially have to call
>> setGeneric(), assuming
>> the non-generic function exists in the specified package
>> (e.g., in base
>> for unique()).
>>
>>
>> In the example below for PkgC the 'unique' generic is in PkgB's
>> namespace imports
>>
>> > getNamespaceImports("PkgB")
>> $base
>> [1] TRUE
>>
>> $PkgA
>> unique
>> "unique"
>>
>> I guess PkgB could have Depends: PkgA, not importFrom(PkgA,
>> unique), and
>> then defined and exported a method on PkgA::unique found on the
>> search
>> path, so that the generic wasn't available to PkgC. But I'd be
>> happy if
>> the generic found in either PkgB's namespace or namespace
>> imports were
>> imported along with the method. Not sure that I like the idea of
>> calling
>> setGeneric() -- PkgA could have done something non-standard --
>> and would
>> rather an error.
>>
>> Thans for your attention.
>>
>> Martin
>>
>>
>> Comments?
>> John
>>
>>
>>
>> On 12/16/11 6:16 AM, Martin Morgan wrote:
>>
>> tar of Pkgs A, B, C attached. Martin
>>
>> On 12/15/2011 03:34 PM, Martin Morgan wrote:
>>
>> In
>>
>> > R.version.string
>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>
>> section 1.6.6 of 'Writing R Extensions' says
>>
>> Note that exporting methods on a generic in the
>> namespace will
>> also export the generic, and exporting a generic in the
>> namespace will also export its methods.
>>
>> and
>>
>> Note that importMethodsFrom will also import any
>> generics defined in
>> the namespace on those methods
>>
>> However, if PkgA promotes 'unique' to a generic and
>> exports that
>>
>> DESCRIPTION:
>> Imports: methods
>>
>> R/f.R:
>> setGeneric("unique")
>>
>> NAMESPACE:
>> export(unique)
>>
>> and PkgB creates and exports a method on unique
>>
>> DESCRIPTION
>> Imports: methods, PkgA
>>
>> R/f.R:
>> setClass("B", representation(b="numeric"))
>> setMethod(unique, "B",
>> function(x, incomparables=FALSE, ...) unique(x at b))
>>
>> NAMESPACE:
>> importFrom(PkgA, unique)
>> exportClasses(B)
>> exportMethods(unique)
>>
>> and PkgC wants to import PkgB's classes and methods
>>
>> DESCRIPTION
>> Imports: methods, PkgB
>>
>> R/f.R
>> cunique <- function(x) unique(x)
>>
>> NAMESPACE
>> importMethodsFrom(PkgB, unique)
>> export(cunique)
>>
>> then
>>
>> (a) the 'unique' generic is not available to the
>> user of PkgB
>>
>> > library(PkgB)
>> > unique(new("B", b=1:5))
>> Error in unique.default(new("B", b = 1:5)) :
>> unique() applies only to vectors
>>
>> and (b) the generic has not been imported to PkgC's
>> namespace
>>
>> > cunique(new("B", b=1:5))
>> Error in unique.default(b) : unique() applies only
>> to vectors
>>
>> A workaround is for PkgB to also export(unique), and
>> for PkgC to also
>> importFrom(PkgA, unique), but is this the intention?
>>
>> This is arising from Bioconductor efforts to place
>> commonly promoted
>> functions and S3 classes into a single package, to
>> avoid conflicts when
>> the same function is promoted independently by
>> several packages.
>>
>> Martin
>>
>>
>>
>>
>>
>>
>> ________________________________________________
>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/__listinfo/r-devel
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From r.turner at auckland.ac.nz  Fri Dec 23 07:16:12 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 23 Dec 2011 19:16:12 +1300
Subject: [Rd] Chi-squared test p-value based on simulation.
Message-ID: <4EF41CAC.6090302@auckland.ac.nz>


Prompted by a (fairly!) recent question from Michael Fuller, I got
to thinking about the issue of goodness-of-fit testing via chisq.test()
using p-values obtained via simulation.

I believe that such p-values are really valid only if there are no ties
in the data.  Since there are only finite number of possible samples
and hence only a finite number of statistic values, ties (while perhaps
improbable) are not impossible.  So the validity of the p-values obtained
via simulation is possibly slightly suspect.

I am given to understand that the p-values remain valid if the ties are
broken *randomly*.

Might it thereby be advisable to jitter the values of (the "true" and
simulated) test statistics before calculating the p-value?

Anyone have any thoughts on this?

     cheers,

         Rolf Turner


From Xavier.Robin at unige.ch  Thu Dec 22 14:39:01 2011
From: Xavier.Robin at unige.ch (Xavier Robin)
Date: Thu, 22 Dec 2011 14:39:01 +0100
Subject: [Rd] attach 'name' argument ignored with a file?
Message-ID: <4EF332F5.60504@unige.ch>

Dear experRts,

I have the feeling that the 'name' argument to the attach function is
ignored when 'what' is a file name. Here is an example:

  save(letters, file="letters.RData")
  letters.env <- attach("letters.RData", name="letters")
  search()
  letters.env

The name on the search path is "file:letters.RData". I would expect it
to be "letters"...
Tested today with R-latest.

Is it by design? From the doc I read:

> name 	name to use for the attached database.
> ...
> The name given for the attached environment will be used by search and can be used as the argument to as.environment. 

I don't see why that would be restricted when 'what' is a file name.

What do you think about it? Is it a bug or did I mis-read the doc?

Regards,
Xavier


From rpickeri at mail.nih.gov  Thu Dec 22 19:13:03 2011
From: rpickeri at mail.nih.gov (RogerP)
Date: Thu, 22 Dec 2011 10:13:03 -0800 (PST)
Subject: [Rd] adding packages R 2.14.0
Message-ID: <1324577583594-4226155.post@n4.nabble.com>

Well, I was able to build R 2.14.0 on my Solaris x86 machine, with a lot of
work and some help. Thanks!

At first the update.packages() would not work because some of the .so files
that came with R were 32 - not 64 bit.  I was able to install them and so
now the update.packages() works. I still have a couple of issues:

1) a lot of packages are not available for R 2.14.0.

2) When compiling I occasionally get compilation errors  - for example:

"../inst/include/Rcpp/stats/random/rhyper.h", line 31: Warning
(Anachronism): Formal argument gen of type double(*)(double,double,double)
in call to Rcpp::Vector<14>::Vector<double, double, double>(const int&,
double(*)(double,double,double), const double&, const double&, const
double&) is being passed extern "C" double(*)(double,double,double).

Will the packages not now available because available over time?  

How do I report/fix the compiling errors?

Thanks in advance!
Roger

--
View this message in context: http://r.789695.n4.nabble.com/adding-packages-R-2-14-0-tp4226155p4226155.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Fri Dec 23 12:22:15 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Dec 2011 11:22:15 +0000 (GMT)
Subject: [Rd] attach 'name' argument ignored with a file?
In-Reply-To: <4EF332F5.60504@unige.ch>
References: <4EF332F5.60504@unige.ch>
Message-ID: <alpine.LFD.2.02.1112231106360.15088@gannet.stats.ox.ac.uk>

On Thu, 22 Dec 2011, Xavier Robin wrote:

> Dear experRts,
>
> I have the feeling that the 'name' argument to the attach function is
> ignored when 'what' is a file name. Here is an example:

In current R (2.14.1) it is documented to not be used in that case 
(and it is not).

>  save(letters, file="letters.RData")
>  letters.env <- attach("letters.RData", name="letters")
>  search()
>  letters.env
>
> The name on the search path is "file:letters.RData". I would expect it
> to be "letters"...
> Tested today with R-latest.

Whatever that is.  This is not the 'at a minumum' information the 
posting guide asked you for, and it expressly asked you not to use 
inaccurate R version terminology.

> Is it by design? From the doc I read:

What 'doc', precisely, is that?   This is not what ?attach in R 2.14.1 
says.

>> name 	name to use for the attached database.
>> ...
>> The name given for the attached environment will be used by search and can be used as the argument to as.environment.
>
> I don't see why that would be restricted when 'what' is a file name.
>
> What do you think about it? Is it a bug or did I mis-read the doc?

It seems clear that there is a problem with your reading ... including 
of the posting guide, which asked you to check the current version of 
R *before posting*.  And even check future versions of R (and you 
might find that illuminating).


> Regards,
> Xavier

Did I mention the posting guide?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Fri Dec 23 14:38:13 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 23 Dec 2011 14:38:13 +0100
Subject: [Rd] adding packages R 2.14.0
In-Reply-To: <1324577583594-4226155.post@n4.nabble.com>
References: <1324577583594-4226155.post@n4.nabble.com>
Message-ID: <4EF48445.9040607@statistik.tu-dortmund.de>



On 22.12.2011 19:13, RogerP wrote:
> Well, I was able to build R 2.14.0 on my Solaris x86 machine, with a lot of
> work and some help. Thanks!
>
> At first the update.packages() would not work because some of the .so files
> that came with R were 32 - not 64 bit.


You compiled R yourself from sources. None of these .so files came with 
R, so it looks like you still haven't got the installation right.




> I was able to install them and so
> now the update.packages() works. I still have a couple of issues:
>
> 1) a lot of packages are not available for R 2.14.0.

Hear, hear! I'm interested to see your list of packages that you believe 
are not available for R-2.14.0 but for other versions. Or in other 
words: That is not true.

For the specific case of x86 Solaris:
According to the CRAN check summary for that platform "a lot" means that 
just 126 out of 3210 give ERRORs and few others may be on a stoplist.


> 2) When compiling I occasionally get compilation errors  - for example:
>
> "../inst/include/Rcpp/stats/random/rhyper.h", line 31: Warning
> (Anachronism): Formal argument gen of type double(*)(double,double,double)
> in call to Rcpp::Vector<14>::Vector<double, double, double>(const int&,
> double(*)(double,double,double), const double&, const double&, const
> double&) is being passed extern "C" double(*)(double,double,double).

Indeed, Rcpp's latest release has some problem on Solaris, see:
http://cran.r-project.org/web/checks/check_results_Rcpp.html
Please talk to the package maintainer in such a case.


> Will the packages not now available because available over time?

?

> How do I report/fix the compiling errors?

Please talk to the package maintainer in such a case.

Best,
Uwe Ligges


> Thanks in advance!
> Roger
>
> --
> View this message in context: http://r.789695.n4.nabble.com/adding-packages-R-2-14-0-tp4226155p4226155.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Fri Dec 23 20:50:00 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 23 Dec 2011 13:50:00 -0600
Subject: [Rd] Debugging namespace problems
Message-ID: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>

Hi all,

I frequently find that I've failed to export something in my NAMESPACE
and hence my package doesn't work when it's imported into another
package. Does anyone have suggestion for debugging this type of
problem?  R CMD check passes without any ns related errors on both the
importee and the importer.

I've attached a reproducible example - if you install the development
version of ggplot2 (e.g. with devtools::install_github("ggplot2") the
attached package fails R CMD check with:

> ### ** Examples
>
> plot(my_plot())
Error in structure(list(data = data, layers = list(), scales = Scales$new(),  :
  attempt to apply non-function
Calls: plot ... my_plot -> ggplot -> ggplot.data.frame -> structure
Execution halted
Error: Command failed (1)

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nstest_0.1.tar.gz
Type: application/x-gzip
Size: 726 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111223/94aca19c/attachment.gz>

From hadley at rice.edu  Fri Dec 23 20:52:57 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 23 Dec 2011 13:52:57 -0600
Subject: [Rd] Debugging namespace problems
In-Reply-To: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>
Message-ID: <CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>

I should add that I'm pretty sure this is something wrong with the
ggplot2 NAMESPACE because if I explicitly attach ggplot2 the code
works:

> library(nstest)
> my_plot()
Error in UseMethod("scale_dimension") :
  no applicable method for 'scale_dimension' applied to an object of
class "NULL"
> library(ggplot2)
> my_plot()
# Plot appears.

Hadley

On Fri, Dec 23, 2011 at 1:50 PM, Hadley Wickham <hadley at rice.edu> wrote:
> Hi all,
>
> I frequently find that I've failed to export something in my NAMESPACE
> and hence my package doesn't work when it's imported into another
> package. Does anyone have suggestion for debugging this type of
> problem? ?R CMD check passes without any ns related errors on both the
> importee and the importer.
>
> I've attached a reproducible example - if you install the development
> version of ggplot2 (e.g. with devtools::install_github("ggplot2") the
> attached package fails R CMD check with:
>
>> ### ** Examples
>>
>> plot(my_plot())
> Error in structure(list(data = data, layers = list(), scales = Scales$new(), ?:
> ?attempt to apply non-function
> Calls: plot ... my_plot -> ggplot -> ggplot.data.frame -> structure
> Execution halted
> Error: Command failed (1)
>
> Hadley
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hadley at rice.edu  Fri Dec 23 20:54:36 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 23 Dec 2011 13:54:36 -0600
Subject: [Rd] Debugging namespace problems
In-Reply-To: <CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>
	<CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>
Message-ID: <CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>

And one last note: I'm reasonably certain I haven't forgotten to
export an S3 method because I wrote the following script to (crudely)
compare the function definitions in ggplot2 with its namespace:

  ns <- parseNamespaceFile("ggplot", "~/Documents/ggplot/")

  s3e <- paste(ns$S3methods[, 1], ns$S3methods[, 2], sep = ".")

  f <- ls("package:ggplot2")
  s3 <- f[str_detect(f, fixed("."))]

  missing <- setdiff(s3, s3e)
  missing[!str_detect(missing, "bolus|icon")]

(Code isn't reproducible, but should give you the basic idea)

Hadley


On Fri, Dec 23, 2011 at 1:52 PM, Hadley Wickham <hadley at rice.edu> wrote:
> I should add that I'm pretty sure this is something wrong with the
> ggplot2 NAMESPACE because if I explicitly attach ggplot2 the code
> works:
>
>> library(nstest)
>> my_plot()
> Error in UseMethod("scale_dimension") :
> ?no applicable method for 'scale_dimension' applied to an object of
> class "NULL"
>> library(ggplot2)
>> my_plot()
> # Plot appears.
>
> Hadley
>
> On Fri, Dec 23, 2011 at 1:50 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> Hi all,
>>
>> I frequently find that I've failed to export something in my NAMESPACE
>> and hence my package doesn't work when it's imported into another
>> package. Does anyone have suggestion for debugging this type of
>> problem? ?R CMD check passes without any ns related errors on both the
>> importee and the importer.
>>
>> I've attached a reproducible example - if you install the development
>> version of ggplot2 (e.g. with devtools::install_github("ggplot2") the
>> attached package fails R CMD check with:
>>
>>> ### ** Examples
>>>
>>> plot(my_plot())
>> Error in structure(list(data = data, layers = list(), scales = Scales$new(), ?:
>> ?attempt to apply non-function
>> Calls: plot ... my_plot -> ggplot -> ggplot.data.frame -> structure
>> Execution halted
>> Error: Command failed (1)
>>
>> Hadley
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>
>
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From mtmorgan at fhcrc.org  Fri Dec 23 23:11:43 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 23 Dec 2011 14:11:43 -0800
Subject: [Rd] Debugging namespace problems
In-Reply-To: <CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>	<CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>
	<CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>
Message-ID: <4EF4FC9F.2020106@fhcrc.org>

On 12/23/2011 11:54 AM, Hadley Wickham wrote:
> And one last note: I'm reasonably certain I haven't forgotten to
> export an S3 method because I wrote the following script to (crudely)
> compare the function definitions in ggplot2 with its namespace:
>
>    ns<- parseNamespaceFile("ggplot", "~/Documents/ggplot/")
>
>    s3e<- paste(ns$S3methods[, 1], ns$S3methods[, 2], sep = ".")
>
>    f<- ls("package:ggplot2")
>    s3<- f[str_detect(f, fixed("."))]
>
>    missing<- setdiff(s3, s3e)
>    missing[!str_detect(missing, "bolus|icon")]
>
> (Code isn't reproducible, but should give you the basic idea)

I think it's this line

         if (!exists(scale_name, globalenv()))
             next


in scales_add_defaults, where the symbol isn't found in the globalenv() 
when nstest is attached and ggplot2 only loaded, but is (via the search 
path) when ggplot2 is attached.

Martin


>
> Hadley
>
>
> On Fri, Dec 23, 2011 at 1:52 PM, Hadley Wickham<hadley at rice.edu>  wrote:
>> I should add that I'm pretty sure this is something wrong with the
>> ggplot2 NAMESPACE because if I explicitly attach ggplot2 the code
>> works:
>>
>>> library(nstest)
>>> my_plot()
>> Error in UseMethod("scale_dimension") :
>>   no applicable method for 'scale_dimension' applied to an object of
>> class "NULL"
>>> library(ggplot2)
>>> my_plot()
>> # Plot appears.
>>
>> Hadley
>>
>> On Fri, Dec 23, 2011 at 1:50 PM, Hadley Wickham<hadley at rice.edu>  wrote:
>>> Hi all,
>>>
>>> I frequently find that I've failed to export something in my NAMESPACE
>>> and hence my package doesn't work when it's imported into another
>>> package. Does anyone have suggestion for debugging this type of
>>> problem?  R CMD check passes without any ns related errors on both the
>>> importee and the importer.
>>>
>>> I've attached a reproducible example - if you install the development
>>> version of ggplot2 (e.g. with devtools::install_github("ggplot2") the
>>> attached package fails R CMD check with:
>>>
>>>> ### ** Examples
>>>>
>>>> plot(my_plot())
>>> Error in structure(list(data = data, layers = list(), scales = Scales$new(),  :
>>>   attempt to apply non-function
>>> Calls: plot ... my_plot ->  ggplot ->  ggplot.data.frame ->  structure
>>> Execution halted
>>> Error: Command failed (1)
>>>
>>> Hadley
>>>
>>> --
>>> Assistant Professor / Dobelman Family Junior Chair
>>> Department of Statistics / Rice University
>>> http://had.co.nz/
>>
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>
>
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Fri Dec 23 23:19:38 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 23 Dec 2011 14:19:38 -0800
Subject: [Rd] Debugging namespace problems
In-Reply-To: <4EF4FC9F.2020106@fhcrc.org>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>	<CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>	<CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>
	<4EF4FC9F.2020106@fhcrc.org>
Message-ID: <4EF4FE7A.2060405@fhcrc.org>

On 12/23/2011 02:11 PM, Martin Morgan wrote:
> On 12/23/2011 11:54 AM, Hadley Wickham wrote:
>> And one last note: I'm reasonably certain I haven't forgotten to
>> export an S3 method because I wrote the following script to (crudely)
>> compare the function definitions in ggplot2 with its namespace:
>>
>> ns<- parseNamespaceFile("ggplot", "~/Documents/ggplot/")
>>
>> s3e<- paste(ns$S3methods[, 1], ns$S3methods[, 2], sep = ".")
>>
>> f<- ls("package:ggplot2")
>> s3<- f[str_detect(f, fixed("."))]
>>
>> missing<- setdiff(s3, s3e)
>> missing[!str_detect(missing, "bolus|icon")]
>>
>> (Code isn't reproducible, but should give you the basic idea)
>
> I think it's this line
>
> if (!exists(scale_name, globalenv()))
> next
>
>
> in scales_add_defaults, where the symbol isn't found in the globalenv()
> when nstest is attached and ggplot2 only loaded, but is (via the search
> path) when ggplot2 is attached.

and topenv(parent.frame()) is a replacement that gets to .GlobalEnv for 
ggplot2, and to the name space for nstest.

Martin

>
> Martin
>
>
>>
>> Hadley
>>
>>
>> On Fri, Dec 23, 2011 at 1:52 PM, Hadley Wickham<hadley at rice.edu> wrote:
>>> I should add that I'm pretty sure this is something wrong with the
>>> ggplot2 NAMESPACE because if I explicitly attach ggplot2 the code
>>> works:
>>>
>>>> library(nstest)
>>>> my_plot()
>>> Error in UseMethod("scale_dimension") :
>>> no applicable method for 'scale_dimension' applied to an object of
>>> class "NULL"
>>>> library(ggplot2)
>>>> my_plot()
>>> # Plot appears.
>>>
>>> Hadley
>>>
>>> On Fri, Dec 23, 2011 at 1:50 PM, Hadley Wickham<hadley at rice.edu> wrote:
>>>> Hi all,
>>>>
>>>> I frequently find that I've failed to export something in my NAMESPACE
>>>> and hence my package doesn't work when it's imported into another
>>>> package. Does anyone have suggestion for debugging this type of
>>>> problem? R CMD check passes without any ns related errors on both the
>>>> importee and the importer.
>>>>
>>>> I've attached a reproducible example - if you install the development
>>>> version of ggplot2 (e.g. with devtools::install_github("ggplot2") the
>>>> attached package fails R CMD check with:
>>>>
>>>>> ### ** Examples
>>>>>
>>>>> plot(my_plot())
>>>> Error in structure(list(data = data, layers = list(), scales =
>>>> Scales$new(), :
>>>> attempt to apply non-function
>>>> Calls: plot ... my_plot -> ggplot -> ggplot.data.frame -> structure
>>>> Execution halted
>>>> Error: Command failed (1)
>>>>
>>>> Hadley
>>>>
>>>> --
>>>> Assistant Professor / Dobelman Family Junior Chair
>>>> Department of Statistics / Rice University
>>>> http://had.co.nz/
>>>
>>>
>>>
>>> --
>>> Assistant Professor / Dobelman Family Junior Chair
>>> Department of Statistics / Rice University
>>> http://had.co.nz/
>>
>>
>>
>
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From hadley at rice.edu  Fri Dec 23 23:38:37 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 23 Dec 2011 16:38:37 -0600
Subject: [Rd] Debugging namespace problems
In-Reply-To: <4EF4FE7A.2060405@fhcrc.org>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>
	<CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>
	<CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>
	<4EF4FC9F.2020106@fhcrc.org> <4EF4FE7A.2060405@fhcrc.org>
Message-ID: <CABdHhvEf23dRNkSaMcM3hLj-vnm8qibXpFZ8T8xSMRd0S8SpUA@mail.gmail.com>

>> in scales_add_defaults, where the symbol isn't found in the globalenv()
>> when nstest is attached and ggplot2 only loaded, but is (via the search
>> path) when ggplot2 is attached.
>
> and topenv(parent.frame()) is a replacement that gets to .GlobalEnv for
> ggplot2, and to the name space for nstest.

Wonderful - thanks!  Any hints on how you discovered the problem?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From mtmorgan at fhcrc.org  Fri Dec 23 23:56:28 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 23 Dec 2011 14:56:28 -0800
Subject: [Rd] Debugging namespace problems
In-Reply-To: <CABdHhvEf23dRNkSaMcM3hLj-vnm8qibXpFZ8T8xSMRd0S8SpUA@mail.gmail.com>
References: <CABdHhvFG-3g5UFps-sn_wvaK_HKgeyhY1=8WNQ84H5sYVvL1ww@mail.gmail.com>
	<CABdHhvHr90tFo15yEWpVaw-XEpc0=SJ9NOAESN99LmK36D4t8Q@mail.gmail.com>
	<CABdHhvEoBaXV9Q-J5yrA1LS=93DX40u-iMSthnyZ65G7KPKe=g@mail.gmail.com>
	<4EF4FC9F.2020106@fhcrc.org> <4EF4FE7A.2060405@fhcrc.org>
	<CABdHhvEf23dRNkSaMcM3hLj-vnm8qibXpFZ8T8xSMRd0S8SpUA@mail.gmail.com>
Message-ID: <4EF5071C.5030802@fhcrc.org>

On 12/23/2011 02:38 PM, Hadley Wickham wrote:
>>> in scales_add_defaults, where the symbol isn't found in the globalenv()
>>> when nstest is attached and ggplot2 only loaded, but is (via the search
>>> path) when ggplot2 is attached.
>>
>> and topenv(parent.frame()) is a replacement that gets to .GlobalEnv for
>> ggplot2, and to the name space for nstest.
>
> Wonderful - thanks!  Any hints on how you discovered the problem?

nothing clever to report; it reproduces at the command line so 
traceback(), options(error=recover), and then debug(ggplot2::ggplot_build).

Martin

>
> Hadley
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From spencer.graves at prodsyse.com  Sat Dec 24 04:00:24 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 23 Dec 2011 19:00:24 -0800
Subject: [Rd] latest Rtools missing "inconsolita.sty"
In-Reply-To: <4EED12E7.2010709@gmail.com>
References: <4EEC3A1A.5060506@prodsyse.com> <4EEC8AB2.30007@gmail.com>
	<4EECC2CF.3040101@prodsyse.com> <4EED12E7.2010709@gmail.com>
Message-ID: <4EF54048.7050508@prodsyse.com>

Hi, Duncan & Uwe:


       Thanks for your suggestions.  I uninstalled and reinstalled 
MiKTeX, and the problem went away.


       MiKTeX seems to malfunction when installed anyplace but the 
default location.  Because of security problems I had had with Vista, 
I've been installing things like R and MiKTeX under my user account, not 
the default "C:/Program Files (x86)".  When I reinstalled it, I put it 
in the default location and eliminated this problem.


       Best Wishes,
       Spencer


On 12/17/2011 2:08 PM, Duncan Murdoch wrote:
> On 11-12-17 11:26 AM, Spencer Graves wrote:
>> On 12/17/2011 4:27 AM, Duncan Murdoch wrote:
>>> On 11-12-17 1:43 AM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>        What do you suggest I do to overcome "LaTeX Error:  File
>>>> 'inconsolata.sty' not found", which I got running "R CMD check" on a
>>>> package using Rtools I downloaded yesterday?
>>>
>>> That file should be installable as part of your LaTeX distribution.
>>> If you are using MikTeX, you can install it from the MikTeX Package
>>> Manager as part of package "inconsolata".
>>
>>
>>         Thanks.  I found the MiKTeX Package Manager, selected
>> "inconsolata", then Task ->  Install.  This produced, "MiKTeX Problem
>> Report:  Failure when receiving data from the peer".  I copied the
>> report to clipboard and pasted it (below).  All the directories there
>> seem to exist.  What else do you suggest?  (This is on a Windows 7
>> notebook.  Is this a feature of Windows 7?  I installed MiKTeX under
>> "C:\Users\sgraves" hoping to minimize these kinds of problems.)
>
> Like Uwe, it works for me, so I don't really know what's going wrong 
> for you.  I would guess from the message that it is the download that 
> is failing, rather than a problem on your system:  you might want to 
> just try again, or specify a different repository (via menus, 
> "Repository | Change package repository...").  You might also need to 
> specify a proxy, if that's how your system is set up.  (You do this in 
> "Connection settings" in the change repository dialog.)
>
> Beyond that, I'd echo Uwe's suggestion to ask on a MikTeX list.
>
> Duncan Murdoch
>
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> MiKTeX Problem Report:  Failure when receiving data from the peer:
>>
>>
>> MiKTeX Problem Report
>> Message: Failure when receiving data from the peer
>> Data: mmk,
>> Source: Libraries\MiKTeX\PackageManager\CurlWebSession.cpp
>> Line: 402
>> MiKTeX: 2.9
>> OS: Microsoft Windows 7 Home Premium Edition, 64-bit (build 7600)
>> Invokers: explorer
>> SystemAdmin: yes
>> PowerUser: no
>> Root0: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
>> Root1: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
>> Root2: C:\ProgramData\MiKTeX\2.9
>> Root3: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
>> UserInstall: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
>> UserConfig: C:\Users\sgraves\AppData\Roaming\MiKTeX\2.9
>> UserData: C:\Users\sgraves\AppData\Local\MiKTeX\2.9
>> CommonInstall: C:\Users\sgraves\pgms\MiKTeX\MiKTeX2.9x64
>> CommonConfig: C:\ProgramData\MiKTeX\2.9
>> CommonData: C:\ProgramData\MiKTeX\2.9
>>
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>
>>>>        I found a similar question to R-Help Nov. 3 (URL below), but
>>>> I've not
>>>> yet had success in replicating the solution outlined there.  I tried
>>>> several different sets of instructions for installing LaTeX packages,
>>>> none of which seemed to work for me.  I'm running Windows 7
>>>> [sessionInfo() below].
>>>>
>>>>
>>>>        Suggestions?
>>>>        Thanks,
>>>>        Spencer Graves
>>>>
>>>>
>>>> http://r.789695.n4.nabble.com/Problem-with-R-CMD-check-and-the-inconsolata-font-business-td3984596.html 
>>>>
>>>>
>>>>
>>>>
>>>> R version 2.14.0 (2011-10-31)
>>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jmc at r-project.org  Sat Dec 24 18:29:48 2011
From: jmc at r-project.org (John Chambers)
Date: Sat, 24 Dec 2011 09:29:48 -0800
Subject: [Rd] S4 NAMESPACE method imports and exports do not include
 (promoted?) generics
In-Reply-To: <4EF3706C.5050305@fhcrc.org>
References: <4EEA841C.5060709@fhcrc.org> <4EEB52D7.9010207@fhcrc.org>
	<4EEBA7E4.70802@r-project.org> <4EEBCCD5.6010405@fhcrc.org>
	<4EEBE7CD.5080502@r-project.org>
	<CAOQ5Nyd_ies9vyvRuD78-iAf41C4qPPtbLfZOmaQMLYe8YCbTg@mail.gmail.com>
	<4EEE3948.2080300@r-project.org> <4EF3706C.5050305@fhcrc.org>
Message-ID: <4EF60C0C.2020106@r-project.org>

As I mentioned earlier in the thread, the main hangup remains the 
treatment of implicit generics--the kludge that turns on method dispatch 
for a function in another package, unique() in your original example.

For 2.15.0, my current plan is to make the export/import of implicit 
generics as automatic as is feasible:

1.  exportMethods() would export the corresponding implicit generic, if 
that's what the generic function in PkgB is.  It would not automatically 
export non-implicit generics, those that the package defines on its own. 
  These should be exported and documented explicitly, since the package 
author is responsible for their design.  (In practice, non-implicit 
means generics with "PkgB" as their package slot.)

2. importMethodsFrom() would correspondingly automatically import 
implicit generics, if they were not already in the namespace.

3. the documentation requirements for check would not require 
documenting implicit generics if there were corresponding exported 
methods (of course, the package author is still responsible for 
documenting the exported methods themselves).

John

On 12/22/11 10:01 AM, Martin Morgan wrote:
> On 12/18/2011 11:04 AM, John Chambers wrote:
>>
>>
>> On 12/17/11 6:02 AM, Michael Lawrence wrote:
>>> I guess what it boils down to is whether it makes sense for PkgB to have
>>> exportMethods(unique) when PkgB does not export(unique) or have PkgA in
>>> Depends. And whether it makes sense for PkgC to have
>>> importMethodsFrom(PkgB, unique) without importFrom(PkgA, unique). If it
>>> is not feasible/sensible to support implicit passing of generics up the
>>> dependency stack, then R should probably emit some sort of warning/error
>>> when methods are exported or imported without the corresponding generic.
>>>
>>> The fact that a generic is being created for an implicit generic defined
>>> in 'base' is not really the issue here.
>>
>> On the contrary, it's why we need to do some thinking about what we want.
>>
>> Try replacing "unique" with "sum" throughout Martin's example, adjusting
>> the method definition appropriately. No problems arise, because sum() is
>> a primitive. Exporting and importing methods works as implied by the
>> extensions manual, but via the implicit generic for sum().
>>
>> The essential point is that the methods being imported are "for" the
>> generic implied by the function in package "base". PkgA is the
>> irrelevant aspect if the methods come from PkgB and the implied generic
>> comes from "base". The problem is that there is no "flag" for
>> non-primitive functions that says "Methods have been defined for this
>> function (base::unique in this case), so some calls should carry out
>> method dispatch."
>>
>> The extensions manual stated that exportMethods() would "export the
>> generic". We could make that true or make it unnecessary, by having
>> importMethods() look for a generic in the referenced package and infer
>> the implicit generic (maybe with a message). Otherwise, we're adding
>> inconsistent requirements for primitives vs true functions in the base
>> package.
>
> One advantage of the exportMethods solution is that a user of PkgB gets
> access to the unique generic without having all of PkgA on the search
> path; it would be unfortunate if the exported generic also carried with
> it the burden of documenting the generic (again).
>
> Even with the insights from this thread, I find myself spending a very
> long time working out the appropriate NAMESPACE declarations for my
> current projects.
>
> Martin
>
>>
>> John
>>>
>>> Thanks,
>>> Michael
>>>
>>> On Fri, Dec 16, 2011 at 4:52 PM, John Chambers <jmc at r-project.org
>>> <mailto:jmc at r-project.org>> wrote:
>>>
>>> The key point here is that setGeneric("unique") is done that way,
>>> without other argument, whoever does it. That creates the generic
>>> from the implicit generic corresponding to base::unique. If package
>>> A had done anything else, the resulting methods tables would NOT
>>> refer to package "base" but to package "PkgA" and it's that version
>>> of the generic that would need to be imported.
>>>
>>> So it's not particularly relevant that we're dealing with
>>> PkgA::unique() if the generic function was created from base::unique
>>> by the standard call. That's what would make an automatic
>>> imputation of the generic from importMethods() possible.
>>>
>>>
>>> On 12/16/11 2:57 PM, Martin Morgan wrote:
>>>
>>> On 12/16/2011 12:19 PM, John Chambers wrote:
>>>
>>> The subject heading is correct if referring to
>>> exportMethods() and
>>> importMethodsFrom(). They refer to the methods tables, not
>>> the generic
>>> functions, whatever the extensions manual says.
>>>
>>> Looking into the code of namespaceImportMethods() will
>>> illustrate this.
>>> It just deals with lists of method tables obtained from
>>> .getGenerics()
>>> which in spite of its name also only looks for the method
>>> table metadata
>>> objects.
>>>
>>> As I vaguely recall, there was some concern at one time
>>> about having
>>> extra copies of the generic version of the function.
>>>
>>> The fundamental problem is that creating methods for
>>> unique(), say, does
>>> not change the way calls to base::unique() work. Therefore,
>>> all packages
>>> that want to use methods have to ensure that a generic
>>> version of unique
>>> gets in between. Primitive functions are an exception
>>> because the method
>>> dispatch is in the C code and has a rule for checking when
>>> given an S4
>>> object. There is no corresponding provision for evaluating a
>>> call to a
>>> regular function.
>>>
>>> If the importing package has a setGeneric() for the relevant
>>> function
>>> then its own namespace has the generic version of the
>>> function. (That is
>>> a workaround, but I inferred that was what you were trying
>>> to avoid.)
>>>
>>> Fixes seem possible, but some care is needed. If exportMethods
>>> automatically exported the generic function, it really is no
>>> different
>>> from export() for that function.
>>>
>>>
>>> export() somehow implies ownership of the generic, e.g.,
>>> responsibility
>>> for documentation. I can see in the scenario below that PkgB
>>> might be
>>> expected to Depends: PkgA if it intends for the user to access
>>> PkgB's
>>> methods on PkgA::unique.
>>>
>>> namespaceImportMethods() could try to supply the generic
>>> function if it
>>> is not already present. If it does not find the generic in
>>> the namespace
>>> being imported, it would essentially have to call
>>> setGeneric(), assuming
>>> the non-generic function exists in the specified package
>>> (e.g., in base
>>> for unique()).
>>>
>>>
>>> In the example below for PkgC the 'unique' generic is in PkgB's
>>> namespace imports
>>>
>>> > getNamespaceImports("PkgB")
>>> $base
>>> [1] TRUE
>>>
>>> $PkgA
>>> unique
>>> "unique"
>>>
>>> I guess PkgB could have Depends: PkgA, not importFrom(PkgA,
>>> unique), and
>>> then defined and exported a method on PkgA::unique found on the
>>> search
>>> path, so that the generic wasn't available to PkgC. But I'd be
>>> happy if
>>> the generic found in either PkgB's namespace or namespace
>>> imports were
>>> imported along with the method. Not sure that I like the idea of
>>> calling
>>> setGeneric() -- PkgA could have done something non-standard --
>>> and would
>>> rather an error.
>>>
>>> Thans for your attention.
>>>
>>> Martin
>>>
>>>
>>> Comments?
>>> John
>>>
>>>
>>>
>>> On 12/16/11 6:16 AM, Martin Morgan wrote:
>>>
>>> tar of Pkgs A, B, C attached. Martin
>>>
>>> On 12/15/2011 03:34 PM, Martin Morgan wrote:
>>>
>>> In
>>>
>>> > R.version.string
>>> [1] "R Under development (unstable) (2011-12-15 r57901)"
>>>
>>> section 1.6.6 of 'Writing R Extensions' says
>>>
>>> Note that exporting methods on a generic in the
>>> namespace will
>>> also export the generic, and exporting a generic in the
>>> namespace will also export its methods.
>>>
>>> and
>>>
>>> Note that importMethodsFrom will also import any
>>> generics defined in
>>> the namespace on those methods
>>>
>>> However, if PkgA promotes 'unique' to a generic and
>>> exports that
>>>
>>> DESCRIPTION:
>>> Imports: methods
>>>
>>> R/f.R:
>>> setGeneric("unique")
>>>
>>> NAMESPACE:
>>> export(unique)
>>>
>>> and PkgB creates and exports a method on unique
>>>
>>> DESCRIPTION
>>> Imports: methods, PkgA
>>>
>>> R/f.R:
>>> setClass("B", representation(b="numeric"))
>>> setMethod(unique, "B",
>>> function(x, incomparables=FALSE, ...) unique(x at b))
>>>
>>> NAMESPACE:
>>> importFrom(PkgA, unique)
>>> exportClasses(B)
>>> exportMethods(unique)
>>>
>>> and PkgC wants to import PkgB's classes and methods
>>>
>>> DESCRIPTION
>>> Imports: methods, PkgB
>>>
>>> R/f.R
>>> cunique <- function(x) unique(x)
>>>
>>> NAMESPACE
>>> importMethodsFrom(PkgB, unique)
>>> export(cunique)
>>>
>>> then
>>>
>>> (a) the 'unique' generic is not available to the
>>> user of PkgB
>>>
>>> > library(PkgB)
>>> > unique(new("B", b=1:5))
>>> Error in unique.default(new("B", b = 1:5)) :
>>> unique() applies only to vectors
>>>
>>> and (b) the generic has not been imported to PkgC's
>>> namespace
>>>
>>> > cunique(new("B", b=1:5))
>>> Error in unique.default(b) : unique() applies only
>>> to vectors
>>>
>>> A workaround is for PkgB to also export(unique), and
>>> for PkgC to also
>>> importFrom(PkgA, unique), but is this the intention?
>>>
>>> This is arising from Bioconductor efforts to place
>>> commonly promoted
>>> functions and S3 classes into a single package, to
>>> avoid conflicts when
>>> the same function is promoted independently by
>>> several packages.
>>>
>>> Martin
>>>
>>>
>>>
>>>
>>>
>>>
>>> ________________________________________________
>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/__listinfo/r-devel
>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>>
>
>


From james.s.muller at gmail.com  Tue Dec 27 23:58:44 2011
From: james.s.muller at gmail.com (James Muller)
Date: Tue, 27 Dec 2011 17:58:44 -0500
Subject: [Rd] Initializing a large data structure to be accessed strictly
 within a shared C library
Message-ID: <CAChCbnoC9PQUPAxLe-Fi6gHG8AN+csz8AVJhw5g6PsO60fg=gg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111227/91b56dc2/attachment.pl>

From james.s.muller at gmail.com  Wed Dec 28 00:58:46 2011
From: james.s.muller at gmail.com (James Muller)
Date: Tue, 27 Dec 2011 18:58:46 -0500
Subject: [Rd] Initializing a large data structure to be accessed strictly
 within a shared C library
Message-ID: <CAChCbnrNt03xcks9OwknkgEawwmpx=SXFW4WQsOdX2mg0NwH1Q@mail.gmail.com>

Dear R-help members,

*(My apologies for cross-posting to both R-help and R-devel -- this
question straddles both domains...)*

The question:  Is it possible to initialize and later free a large data
structure strictly within a shared C library, to be used by a function in
the C library that I'll call from R--without ever having to pass data to
and from R? This is analogous to C++ object initialization/use/destruction,
but if possible I'd like to stay in C.

The context: I'm implementing a particle swarm optimization of a
60-dimension nonlinear transform, where the transform is defined in a
half-gigabyte dataset. By carefully initializing a C struct I can trim a
large amount of work from the PSO iteration stage. This is, of course,
straight forward if I implement the whole thing in a self-contained C
program--however, I'd like R to handle the optimization routines, and my
shared library to implement the value function.

So: what do folks think?

Cheers,

James


From murdoch.duncan at gmail.com  Wed Dec 28 02:09:37 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Dec 2011 20:09:37 -0500
Subject: [Rd] Initializing a large data structure to be accessed
 strictly within a shared C library
In-Reply-To: <CAChCbnoC9PQUPAxLe-Fi6gHG8AN+csz8AVJhw5g6PsO60fg=gg@mail.gmail.com>
References: <CAChCbnoC9PQUPAxLe-Fi6gHG8AN+csz8AVJhw5g6PsO60fg=gg@mail.gmail.com>
Message-ID: <4EFA6C51.5010300@gmail.com>

On 11-12-27 5:58 PM, James Muller wrote:
> Dear R-devel members,
>
> The question:  Is it possible to initialize and later free a large data
> structure strictly within a shared C library, to be used by a function in
> the C library that I'll call from R--without ever having to pass data to
> and from R? This is analogous to C++ object initialization/use/destruction,
> but if possible I'd like to stay in C.

Yes, if you use malloc or Calloc you'll get memory that you can manage 
yourself.  See Writing R Extensions, section 6.1.2.

Duncan Murdoch

>
> The context: I'm implementing a particle swarm optimization of a
> 60-dimension nonlinear transform, where the transform is defined in a
> half-gigabyte dataset. By carefully initializing a C struct I can trim a
> large amount of work from the PSO iteration stage. This is, of course,
> straight forward if I implement the whole thing in a self-contained C
> program--however, I'd like R to handle the optimization routines, and my
> shared library to implement the value function.
>
> So: what do folks think?
>
> Cheers,
>
> James
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From james.s.muller at gmail.com  Wed Dec 28 02:36:17 2011
From: james.s.muller at gmail.com (James Muller)
Date: Tue, 27 Dec 2011 20:36:17 -0500
Subject: [Rd] Initializing a large data structure to be accessed
 strictly within a shared C library
In-Reply-To: <4EFA6C51.5010300@gmail.com>
References: <CAChCbnoC9PQUPAxLe-Fi6gHG8AN+csz8AVJhw5g6PsO60fg=gg@mail.gmail.com>
	<4EFA6C51.5010300@gmail.com>
Message-ID: <CAChCbnrKD1Bo7oHwTd4GVzzBwCe-nPwYqNFWO74uYcHOoNemKw@mail.gmail.com>

Thanks Duncan, you've unclogged my thinking. For anybody interested,
see below a sketch of the solution.

Cheers,

James


--START SKETCH OF SOLUTION--

#include <R.h>
#include <Rinternals.h>

static typedef struct {
    int nrow, ncol;
    double *data;
} _myparticle_data_struct;
static _myparticle_data_struct myparticle_data;

void myparticle_init() {
    // Before we begin, call this from .Call() to Ralloc() memory and load the
    // data into to myparticle_data.data
}

void myparticle_free() {
    // When we're done with the PSO, .Call() to Free() the data
}

void myparticle_eval(double *value, double *x) {
    // .Call() to evaluate the value *value given vector x[]
}

--END SKETCH OF SOLUTION--


From ngkbr8es at gmail.com  Wed Dec 28 06:07:00 2011
From: ngkbr8es at gmail.com (Patrick Leyshock)
Date: Tue, 27 Dec 2011 21:07:00 -0800
Subject: [Rd] external pointers
Message-ID: <CAMp6Ef4iHDdrLfsoQ0ayJ10b_3JSKA86iz0O-Cc2KFe=v8i82g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111227/249cef37/attachment.pl>

From simon.urbanek at r-project.org  Wed Dec 28 16:09:05 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 28 Dec 2011 10:09:05 -0500
Subject: [Rd] external pointers
In-Reply-To: <CAMp6Ef4iHDdrLfsoQ0ayJ10b_3JSKA86iz0O-Cc2KFe=v8i82g@mail.gmail.com>
References: <CAMp6Ef4iHDdrLfsoQ0ayJ10b_3JSKA86iz0O-Cc2KFe=v8i82g@mail.gmail.com>
Message-ID: <97385934-7B35-4B7A-9944-3A169E0558D9@r-project.org>

Patrick,

On Dec 28, 2011, at 12:07 AM, Patrick Leyshock wrote:

> I have an external pointer object that I'd like to pass from my R code to
> some C code.  Per Section 5.13 of "Writing R Extensions", I've noted that
> "external pointers should only be used as part of an object with normal
> semantics, for example an attribute or an element of a list."  So I've
> written up a workable C function as such:
> 
> SEXP my_c_function(SEXP param)    {
>     SEXP temp = getAttrib(param, install("ptr_attribute"));
>     void * ptr = R_ExternalPtrAddr(temp);
>     ...   // do useful things with ptr
> }
> 
> I can pass my_c_function() an object with "normal" semantics (such as an
> integer vector), where the external pointer object is a parameter named
> "ptr_attribute".  The function extracts the pointer object from param; i.e.
> this function does what I want it to do.
> 
> My question is:  is there a way to do this using the .C() interface, rather
> than .Call()?

No. Why would you want to do that? .C is slower and mostly for backwards-compatibility. You can't pass anything complex with .C and the docs recommend .Call for this. The whole point of .C was to bypass R API but in your case you need it to get the pointer.


>   Using call_R seems a possibility - has anyone had luck
> going this route?
> 

call_R has nothing to do with this, it is sort of the equivalent of using the restricted set of objects to evaluate R function (so you still can't pass your pointer). As the docs say there is no point in using it in modern code.

Cheers,
Simon


> Any suggestions appreciated.
> 
> Thanks, Patrick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hadley at rice.edu  Wed Dec 28 16:37:01 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 28 Dec 2011 09:37:01 -0600
Subject: [Rd] Subsetting a data frame vs. subsetting the columns
Message-ID: <CABdHhvEee-HkZcFhYFfFGM6VYC51LYqhLVn2ppBCakJYOmoLFA@mail.gmail.com>

Hi all,

There seems to be rather a large speed disparity in subsetting when
working with a whole data frame vs. working with just columns
individually:

df <- as.data.frame(replicate(10, runif(1e5)))
ord <- order(df[[1]])

system.time(df[ord, ])
#   user  system elapsed
#  0.043   0.007   0.059
system.time(lapply(df, function(x) x[ord]))
#   user  system elapsed
#  0.022   0.008   0.029

What's going on?

I realise this isn't quite a fair example because the second case
makes a list not a data frame, but I thought it would be quick
operation to turn a list into a data frame if you don't do any
checking:

list_to_df <- function(list) {
  n <- length(list[[1]])
  structure(list,
    class = "data.frame",
    row.names = c(NA, -n))
}
system.time(list_to_df(lapply(df, function(x) x[ord])))
#    user  system elapsed
#  0.031   0.017   0.048

So I guess this is slow because it has to make a copy of the whole
data frame to modify the structure.  But couldn't [.data.frame avoid
that?

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From simon.urbanek at r-project.org  Wed Dec 28 17:14:29 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 28 Dec 2011 11:14:29 -0500
Subject: [Rd] Subsetting a data frame vs. subsetting the columns
In-Reply-To: <CABdHhvEee-HkZcFhYFfFGM6VYC51LYqhLVn2ppBCakJYOmoLFA@mail.gmail.com>
References: <CABdHhvEee-HkZcFhYFfFGM6VYC51LYqhLVn2ppBCakJYOmoLFA@mail.gmail.com>
Message-ID: <A3C8CADD-570F-4769-96C8-15E7CA97CCAE@r-project.org>

Hadley,

there was a whole discussion about subsetting and subassigning data frames (and general efficiency issues) some time ago (I can't find it in a hurry but others might) -- just look at the `[.data.frame` code to see why it's so slow. It would need to be pushed into C code to allow certain optimizations, but it's a quite complex code so I don't think there were volunteers. So the advice is don't do it ;). Treating DFs as lists is always faster since you get to the fast internal code.

Cheers,
S


On Dec 28, 2011, at 10:37 AM, Hadley Wickham wrote:

> Hi all,
> 
> There seems to be rather a large speed disparity in subsetting when
> working with a whole data frame vs. working with just columns
> individually:
> 
> df <- as.data.frame(replicate(10, runif(1e5)))
> ord <- order(df[[1]])
> 
> system.time(df[ord, ])
> #   user  system elapsed
> #  0.043   0.007   0.059
> system.time(lapply(df, function(x) x[ord]))
> #   user  system elapsed
> #  0.022   0.008   0.029
> 
> What's going on?
> 
> I realise this isn't quite a fair example because the second case
> makes a list not a data frame, but I thought it would be quick
> operation to turn a list into a data frame if you don't do any
> checking:
> 
> list_to_df <- function(list) {
>  n <- length(list[[1]])
>  structure(list,
>    class = "data.frame",
>    row.names = c(NA, -n))
> }
> system.time(list_to_df(lapply(df, function(x) x[ord])))
> #    user  system elapsed
> #  0.031   0.017   0.048
> 
> So I guess this is slow because it has to make a copy of the whole
> data frame to modify the structure.  But couldn't [.data.frame avoid
> that?
> 
> Hadley
> 
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jwiley.psych at gmail.com  Wed Dec 28 18:24:23 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 28 Dec 2011 09:24:23 -0800
Subject: [Rd] Subsetting a data frame vs. subsetting the columns
In-Reply-To: <A3C8CADD-570F-4769-96C8-15E7CA97CCAE@r-project.org>
References: <CABdHhvEee-HkZcFhYFfFGM6VYC51LYqhLVn2ppBCakJYOmoLFA@mail.gmail.com>
	<A3C8CADD-570F-4769-96C8-15E7CA97CCAE@r-project.org>
Message-ID: <CANz9Z_+uzRAzvCLg7NH=k-GNDrDgDqfeU17do5rAfXaZnKOxxA@mail.gmail.com>

On Wed, Dec 28, 2011 at 8:14 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Hadley,
>
> there was a whole discussion about subsetting and subassigning data frames (and general efficiency issues) some time ago (I can't find it in a hurry but others might)

Yep, a rather lengthy discussion at that
http://r.789695.n4.nabble.com/speeding-up-perception-td3640920.html.
IIRC, there was also some off list stuff about what it would take to
push to C, which I may have in my inbox if anyone wants.

Cheers,

Josh

-- just look at the `[.data.frame` code to see why it's so slow. It
would need to be pushed into C code to allow certain optimizations,
but it's a quite complex code so I don't think there were volunteers.
So the advice is don't do it ;). Treating DFs as lists is always
faster since you get to the fast internal code.
>
> Cheers,
> S
>
>
> On Dec 28, 2011, at 10:37 AM, Hadley Wickham wrote:
>
>> Hi all,
>>
>> There seems to be rather a large speed disparity in subsetting when
>> working with a whole data frame vs. working with just columns
>> individually:
>>
>> df <- as.data.frame(replicate(10, runif(1e5)))
>> ord <- order(df[[1]])
>>
>> system.time(df[ord, ])
>> # ? user ?system elapsed
>> # ?0.043 ? 0.007 ? 0.059
>> system.time(lapply(df, function(x) x[ord]))
>> # ? user ?system elapsed
>> # ?0.022 ? 0.008 ? 0.029
>>
>> What's going on?
>>
>> I realise this isn't quite a fair example because the second case
>> makes a list not a data frame, but I thought it would be quick
>> operation to turn a list into a data frame if you don't do any
>> checking:
>>
>> list_to_df <- function(list) {
>> ?n <- length(list[[1]])
>> ?structure(list,
>> ? ?class = "data.frame",
>> ? ?row.names = c(NA, -n))
>> }
>> system.time(list_to_df(lapply(df, function(x) x[ord])))
>> # ? ?user ?system elapsed
>> # ?0.031 ? 0.017 ? 0.048
>>
>> So I guess this is slow because it has to make a copy of the whole
>> data frame to modify the structure. ?But couldn't [.data.frame avoid
>> that?
>>
>> Hadley
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From hadley at rice.edu  Wed Dec 28 20:48:56 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 28 Dec 2011 13:48:56 -0600
Subject: [Rd] Subsetting a data frame vs. subsetting the columns
In-Reply-To: <A3C8CADD-570F-4769-96C8-15E7CA97CCAE@r-project.org>
References: <CABdHhvEee-HkZcFhYFfFGM6VYC51LYqhLVn2ppBCakJYOmoLFA@mail.gmail.com>
	<A3C8CADD-570F-4769-96C8-15E7CA97CCAE@r-project.org>
Message-ID: <CABdHhvHYAGbyF4Fzhd42EJeGt7uR5opCEM+8cxwnT8V+Bjx-+w@mail.gmail.com>

Ah, thanks for the pointers!
Hadley

On Wed, Dec 28, 2011 at 10:14 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Hadley,
>
> there was a whole discussion about subsetting and subassigning data frames (and general efficiency issues) some time ago (I can't find it in a hurry but others might) -- just look at the `[.data.frame` code to see why it's so slow. It would need to be pushed into C code to allow certain optimizations, but it's a quite complex code so I don't think there were volunteers. So the advice is don't do it ;). Treating DFs as lists is always faster since you get to the fast internal code.
>
> Cheers,
> S
>
>
> On Dec 28, 2011, at 10:37 AM, Hadley Wickham wrote:
>
>> Hi all,
>>
>> There seems to be rather a large speed disparity in subsetting when
>> working with a whole data frame vs. working with just columns
>> individually:
>>
>> df <- as.data.frame(replicate(10, runif(1e5)))
>> ord <- order(df[[1]])
>>
>> system.time(df[ord, ])
>> # ? user ?system elapsed
>> # ?0.043 ? 0.007 ? 0.059
>> system.time(lapply(df, function(x) x[ord]))
>> # ? user ?system elapsed
>> # ?0.022 ? 0.008 ? 0.029
>>
>> What's going on?
>>
>> I realise this isn't quite a fair example because the second case
>> makes a list not a data frame, but I thought it would be quick
>> operation to turn a list into a data frame if you don't do any
>> checking:
>>
>> list_to_df <- function(list) {
>> ?n <- length(list[[1]])
>> ?structure(list,
>> ? ?class = "data.frame",
>> ? ?row.names = c(NA, -n))
>> }
>> system.time(list_to_df(lapply(df, function(x) x[ord])))
>> # ? ?user ?system elapsed
>> # ?0.031 ? 0.017 ? 0.048
>>
>> So I guess this is slow because it has to make a copy of the whole
>> data frame to modify the structure. ?But couldn't [.data.frame avoid
>> that?
>>
>> Hadley
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From deville.yves at alpestat.com  Thu Dec 29 15:05:28 2011
From: deville.yves at alpestat.com (Yves Deville)
Date: Thu, 29 Dec 2011 15:05:28 +0100
Subject: [Rd] Cholesky update/downdate
Message-ID: <4EFC73A8.1080901@alpestat.com>

Dear R-devel members,

I am looking for a fast Cholesky update/downdate. The matrix A being 
symmetric positive definite (n, n) and factorized as
A = L %*% t(L), the goal is to factor the new matrix  A +- C %*% t(C) 
where C is (n, r). For instance, C is 1-column when adding/removing an 
observation in a linear regression. Of special interest is the case 
where A is sparse.
 
Looking at the 'Matrix' package (help and source code), it seems that 
the CHOLMOD library shipped with 'Matrix' allows this,
but is not (yet?) interfaced in 'Matrix', where the 'update' method for 
Cholesky decomposition objects seems limited to a new matrix A + m*I 
with a scalar (diagonal) modification.

If this is true: are there plans to implement such up/downdates?
 
Best,

Yves

Yves Deville, statistical consultant, France.


From hb at biostat.ucsf.edu  Thu Dec 29 15:49:26 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 29 Dec 2011 15:49:26 +0100
Subject: [Rd] Crashing R with readline()
Message-ID: <CAFDcVCTDivB8VxE3Oq+exsyjEc6pc_iEpnVCNu0Bf0YD6X+bQQ@mail.gmail.com>

I get the following with R v2.14.1 patched on Windows 7:

% Rterm --vanilla --silent

> sessionInfo()
R version 2.14.1 Patched (2011-12-26 r58001)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> readline(sprintf("%-*s:", 180, "A prompt"))
A prompt

                                        :
[1] ""
> q("no")
Error: caught access violation - continue with care

It is a consistent behavior.

/Henrik


From dtenenba at fhcrc.org  Thu Dec 29 20:35:25 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 29 Dec 2011 11:35:25 -0800
Subject: [Rd] Reference class finalize() fails with 'attempt to apply
	non-function'
In-Reply-To: <4EE13FC6.5070606@fhcrc.org>
References: <4EE13FC6.5070606@fhcrc.org>
Message-ID: <CAF42j21JfMNa_6yhE9nM3UzK8gY2G-Q2xhehPvyTPVjLEWTPWQ@mail.gmail.com>

On Thu, Dec 8, 2011 at 2:52 PM, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> This bug appears intermittently in R CMD check when reference classes have
> finalize methods. The problem is that garbage collection can be run after
> the methods package is no longer available. It affects (periodically) the
> Bioconductor AnnotationDbi package as well as packages that contain Rcpp
> classes. To reproduce:
>
> ?library(methods)
> ?a = setRefClass("A", methods=list(finalize=function() cat("A\n")))
> ?b = setRefClass("B", contains="A")
>
> repeat b = setRefClass("B", contains="A") until finalize does not run (no
> garbage collection triggered during setRefClass)
>
> ?b = setRefClass("B", contains="A")
> ?b = setRefClass("B", contains="A")
>
> and then
>
>> detach("package:methods")
>> gc()
> Error in function (x) ?: attempt to apply non-function
> Error in function (x) ?: attempt to apply non-function
>
>> traceback()
> 1: function (x)
> ? x$.self$finalize()(<environment>)
>
> I believe a variant of the same type of problem generates an error
>
> Error in function (x) ?: no function to return from, jumping to top level
>
> also seen in AnnotationDbi and Rcpp packages

Here is a self-contained reproducible example that immediately and
consistently produces the error on R 2.14 and R-devel:

library(methods)
a = setRefClass("A",
  methods=list(finalize=function() options("finalized"=TRUE)))
b = setRefClass("B", contains="A")

while (TRUE) {
    options("finalized" = FALSE)
    b = setRefClass("B", contains="A")
    if (!getOption("finalized")) break
}

detach("package:methods")
gc()



Thanks!
Dan




> --
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
> Location: M1-B861
> Telephone: 206 667-2793
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Dec 29 22:37:00 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Dec 2011 16:37:00 -0500
Subject: [Rd] Crashing R with readline()
In-Reply-To: <CAFDcVCTDivB8VxE3Oq+exsyjEc6pc_iEpnVCNu0Bf0YD6X+bQQ@mail.gmail.com>
References: <CAFDcVCTDivB8VxE3Oq+exsyjEc6pc_iEpnVCNu0Bf0YD6X+bQQ@mail.gmail.com>
Message-ID: <4EFCDD7C.7060304@gmail.com>

On 11-12-29 9:49 AM, Henrik Bengtsson wrote:
> I get the following with R v2.14.1 patched on Windows 7:
>
> % Rterm --vanilla --silent
>
>> sessionInfo()
> R version 2.14.1 Patched (2011-12-26 r58001)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>> readline(sprintf("%-*s:", 180, "A prompt"))
> A prompt
>
>                                          :
> [1] ""
>> q("no")
> Error: caught access violation - continue with care
>
> It is a consistent behavior.

I can reproduce this, but I can't spot where the problem is.  I/O in 
Rterm is very complicated, because we use a getline library that 
implements line editing, and we run the I/O in a thread so that graphics 
windows can be updated while waiting for input.

Presumably the problem is the long prompt causing a buffer overflow 
somewhere, and a workaround is to use a more reasonable length of 
prompt, but I don't think I'm going to be able to offer a real fix.  I'd 
guess this bug is local to Rterm in Windows, but we don't really have 
good tools there to detect buffer overflows.

Duncan Murdoch


From bates at stat.wisc.edu  Thu Dec 29 23:27:52 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 29 Dec 2011 16:27:52 -0600
Subject: [Rd] Cholesky update/downdate
In-Reply-To: <4EFC73A8.1080901@alpestat.com>
References: <4EFC73A8.1080901@alpestat.com>
Message-ID: <CAO7JsnS3z_-1WYB-28DTicbR4E6ABrDtsR3KU01gsPZ6D3GDdg@mail.gmail.com>

On Thu, Dec 29, 2011 at 8:05 AM, Yves Deville <deville.yves at alpestat.com> wrote:
> Dear R-devel members,

> I am looking for a fast Cholesky update/downdate. The matrix A being
> symmetric positive definite (n, n) and factorized as
> A = L %*% t(L), the goal is to factor the new matrix ?A +- C %*% t(C) where
> C is (n, r). For instance, C is 1-column when adding/removing an observation
> in a linear regression. Of special interest is the case where A is sparse.

> Looking at the 'Matrix' package (help and source code), it seems that the
> CHOLMOD library shipped with 'Matrix' allows this,
> but is not (yet?) interfaced in 'Matrix', where the 'update' method for
> Cholesky decomposition objects seems limited to a new matrix A + m*I with a
> scalar (diagonal) modification.

The CHOLMOD library provides sparse matrix methods, especially the
Cholesky decomposition and modifications to that decomposition, which
is where the name comes from.  Do you expect to work with sparse
matrices?

I haven't seem too much code for update/downdate operations on the
Cholesky decomposition for dense matrices.  There were rank-1
update/downdate methods in Linpack but they didn't make it through to
Lapack.
> If this is true: are there plans to implement such up/downdates?
>
> Best,
>
> Yves
>
> Yves Deville, statistical consultant, France.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Dec 29 23:50:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Dec 2011 17:50:36 -0500
Subject: [Rd] Crashing R with readline()
In-Reply-To: <4EFCDD7C.7060304@gmail.com>
References: <CAFDcVCTDivB8VxE3Oq+exsyjEc6pc_iEpnVCNu0Bf0YD6X+bQQ@mail.gmail.com>
	<4EFCDD7C.7060304@gmail.com>
Message-ID: <4EFCEEBC.6080002@gmail.com>

On 11-12-29 4:37 PM, Duncan Murdoch wrote:
> On 11-12-29 9:49 AM, Henrik Bengtsson wrote:
>> I get the following with R v2.14.1 patched on Windows 7:
>>
>> % Rterm --vanilla --silent
>>
>>> sessionInfo()
>> R version 2.14.1 Patched (2011-12-26 r58001)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>> readline(sprintf("%-*s:", 180, "A prompt"))
>> A prompt
>>
>>                                           :
>> [1] ""
>>> q("no")
>> Error: caught access violation - continue with care
>>
>> It is a consistent behavior.
>
> I can reproduce this, but I can't spot where the problem is.  I/O in
> Rterm is very complicated, because we use a getline library that
> implements line editing, and we run the I/O in a thread so that graphics
> windows can be updated while waiting for input.
>
> Presumably the problem is the long prompt causing a buffer overflow
> somewhere, and a workaround is to use a more reasonable length of
> prompt, but I don't think I'm going to be able to offer a real fix.  I'd
> guess this bug is local to Rterm in Windows, but we don't really have
> good tools there to detect buffer overflows.

Just had another idea, and found the problem - a buffer overflow in 
getline.  I'll fix it.

Duncan Murdoch


From deville.yves at alpestat.com  Fri Dec 30 11:47:33 2011
From: deville.yves at alpestat.com (Yves Deville)
Date: Fri, 30 Dec 2011 11:47:33 +0100
Subject: [Rd] Cholesky update/downdate
In-Reply-To: <CAO7JsnS3z_-1WYB-28DTicbR4E6ABrDtsR3KU01gsPZ6D3GDdg@mail.gmail.com>
References: <4EFC73A8.1080901@alpestat.com>
	<CAO7JsnS3z_-1WYB-28DTicbR4E6ABrDtsR3KU01gsPZ6D3GDdg@mail.gmail.com>
Message-ID: <4EFD96C5.9070509@alpestat.com>

Hi Douglas,

thanks for your answer.

My question indeed arises from a sparse matrix context: 'A' is sparse 
symmetric, and 'C' must also be sparse since it would otherwise fill.

It comes from a Bayes regression with a very large number of parameters; 
a loop over blocks will do the job in my specific case. Yet  I wondered 
about this since similar need for "covariance updating" may arise from 
linear filtering or kriging.

Douglas Bates wrote
> The CHOLMOD library provides sparse matrix methods, especially the
> Cholesky decomposition and modifications to that decomposition, which
> is where the name comes from.  Do you expect to work with sparse
> matrices?
>
> I haven't seem too much code for update/downdate operations on the
> Cholesky decomposition for dense matrices.  There were rank-1
> update/downdate methods in Linpack but they didn't make it through to
> Lapack.


From pgilbert902 at gmail.com  Fri Dec 30 22:32:56 2011
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 30 Dec 2011 16:32:56 -0500
Subject: [Rd] CRAN link broken
Message-ID: <4EFE2E08.1070101@gmail.com>

The packages link on CRAN (http://cran.at.r-project.org/)  seems to be 
broken.

Paul

      Object not found!
     The requested URL was not found on this server. The link on the
     referring page<http://cran.at.r-project.org/navbar.html>  seems to be
     wrong or outdated. Please inform the author of that page
     <http://cran.at.r-project.org/navbar.html>  about the error.
     If you think this is a server error, please contact the webmaster
     <mailto:%5bno%20address%20given%5d>.
         Error 404
     cran.at.r-project.org<http://cran.at.r-project.org/>
     Fri Dec 30 22:20:48 2011
     Apache/2.2.21 (Debian)


From ggrothendieck at gmail.com  Fri Dec 30 22:49:29 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Dec 2011 16:49:29 -0500
Subject: [Rd] CRAN link broken
In-Reply-To: <4EFE2E08.1070101@gmail.com>
References: <4EFE2E08.1070101@gmail.com>
Message-ID: <CAP01uRnuEnHvw5Khe+xN-LZDz_SaVpCoDRiF7gMu2Q_juQHRuQ@mail.gmail.com>

On Fri, Dec 30, 2011 at 4:32 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> The packages link on CRAN (http://cran.at.r-project.org/) ?seems to be
> broken.
>
> Paul
>
> ? ? Object not found!
> ? ?The requested URL was not found on this server. The link on the
> ? ?referring page<http://cran.at.r-project.org/navbar.html> ?seems to be
> ? ?wrong or outdated. Please inform the author of that page
> ? ?<http://cran.at.r-project.org/navbar.html> ?about the error.
> ? ?If you think this is a server error, please contact the webmaster
> ? ?<mailto:%5bno%20address%20given%5d>.
> ? ? ? ?Error 404
> ? ?cran.at.r-project.org<http://cran.at.r-project.org/>
> ? ?Fri Dec 30 22:20:48 2011
> ? ?Apache/2.2.21 (Debian)

Presumably this will propagate to the mirrors shortly, as well, if it
has not happened already.




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ripley at stats.ox.ac.uk  Sat Dec 31 07:36:04 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Dec 2011 06:36:04 +0000
Subject: [Rd] CRAN link broken
In-Reply-To: <4EFE2E08.1070101@gmail.com>
References: <4EFE2E08.1070101@gmail.com>
Message-ID: <4EFEAD54.1070301@stats.ox.ac.uk>

This is not the CRAN webmaster's address[*], and the problem has been 
reported several times already to the proper places.  No one reading 
this list apart from the handful with CRAN administrator rights can do 
anything about this.

The package repository is still there, and the check information is 
still up (via http://cran.r-project.org/web/checks/check_summary.html). 
  The only thing that appears to be missing is the web-formatted summary 
information.  That is secondary information, and it looks like the 
web/packages area needs to be regenerated.

My memory is that some of the mirrors do not auto-delete, and so will 
remain populated.  I believe http://stat.ethz.ch/CRAN/web/packages/ to 
be one of those and it looks intact.

[*] I believe that to be CRANadmin at r-project.org

On 30/12/2011 21:32, Paul Gilbert wrote:
> The packages link on CRAN (http://cran.at.r-project.org/) seems to be
> broken.
>
> Paul
>
> Object not found!
> The requested URL was not found on this server. The link on the
> referring page<http://cran.at.r-project.org/navbar.html> seems to be
> wrong or outdated. Please inform the author of that page
> <http://cran.at.r-project.org/navbar.html> about the error.
> If you think this is a server error, please contact the webmaster
> <mailto:%5bno%20address%20given%5d>.
> Error 404
> cran.at.r-project.org<http://cran.at.r-project.org/>
> Fri Dec 30 22:20:48 2011
> Apache/2.2.21 (Debian)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Sat Dec 31 12:15:10 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 31 Dec 2011 12:15:10 +0100
Subject: [Rd] CRAN link broken
In-Reply-To: <4EFEAD54.1070301@stats.ox.ac.uk>
References: <4EFE2E08.1070101@gmail.com>
	<4EFEAD54.1070301@stats.ox.ac.uk>
Message-ID: <20222.61118.495992.777618@stat.math.ethz.ch>

>>>>> Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Sat, 31 Dec 2011 06:36:04 +0000 writes:

    > This is not the CRAN webmaster's address[*], and the
    > problem has been reported several times already to the
    > proper places.  No one reading this list apart from the
    > handful with CRAN administrator rights can do anything
    > about this.

    > The package repository is still there, and the check
    > information is still up (via
    > http://cran.r-project.org/web/checks/check_summary.html).
    > The only thing that appears to be missing is the
    > web-formatted summary information.  That is secondary
    > information, and it looks like the web/packages area needs
    > to be regenerated.

    > My memory is that some of the mirrors do not auto-delete,
    > and so will remain populated.  I believe
    > http://stat.ethz.ch/CRAN/web/packages/ to be one of those
    > and it looks intact.

Well, yes..
Actually, my mirroring script does auto-deletion but "slowly":
never more than a few hundred files at a time
(apart from the 'Recommended/' subdirectories: There, it is
 important to delete, i.e., important to not have more than one
 version of a recommended package .. for our  tools/rsync-recommended
 script )


    > [*] I believe that to be CRANadmin at r-project.org

Almost:   CRAN-admin at r-project.org
	  (or any other capitalization of that)

    > On 30/12/2011 21:32, Paul Gilbert wrote:
    >> The packages link on CRAN (http://cran.at.r-project.org/)
    >> seems to be broken.
    >> 
    >> Paul
    >> 
    >> Object not found!  The requested URL was not found on
    >> this server. The link on the referring
    >> page<http://cran.at.r-project.org/navbar.html> seems to
    >> be wrong or outdated. Please inform the author of that
    >> page <http://cran.at.r-project.org/navbar.html> about the
    >> error.  If you think this is a server error, please
    >> contact the webmaster
    >> <mailto:%5bno%20address%20given%5d>.  Error 404
    >> cran.at.r-project.org<http://cran.at.r-project.org/> Fri
    >> Dec 30 22:20:48 2011 Apache/2.2.21 (Debian)
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


    > -- 
    > Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
    > Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
    > University of Oxford, Tel: +44 1865 272861 (self) 1 South
    > Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG, UK Fax:
    > +44 1865 272595

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Dec 31 15:49:14 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 31 Dec 2011 15:49:14 +0100
Subject: [Rd] CRAN link broken -- Swiss "backup"
In-Reply-To: <20222.61118.495992.777618@stat.math.ethz.ch>
References: <4EFE2E08.1070101@gmail.com> <4EFEAD54.1070301@stats.ox.ac.uk>
	<20222.61118.495992.777618@stat.math.ethz.ch>
Message-ID: <20223.8426.556399.538710@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Sat, 31 Dec 2011 12:15:10 +0100 writes:

>>>>> Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Sat, 31 Dec 2011 06:36:04 +0000 writes:

    >> This is not the CRAN webmaster's address[*], and the
    >> problem has been reported several times already to the
    >> proper places.  No one reading this list apart from the
    >> handful with CRAN administrator rights can do anything
    >> about this.

    >> The package repository is still there, and the check
    >> information is still up (via
    >> http://cran.r-project.org/web/checks/check_summary.html).
    >> The only thing that appears to be missing is the
    >> web-formatted summary information.  That is secondary
    >> information, and it looks like the web/packages area
    >> needs to be regenerated.

    >> My memory is that some of the mirrors do not auto-delete,
    >> and so will remain populated.  I believe
    >> http://stat.ethz.ch/CRAN/web/packages/ to be one of those
    >> and it looks intact.

    > Well, yes..  Actually, my mirroring script does
    > auto-deletion but "slowly": never more than a few hundred
    > files at a time (apart from the 'Recommended/'
    > subdirectories: There, it is important to delete, i.e.,
    > important to not have more than one version of a
    > recommended package .. for our tools/rsync-recommended
    > script )

In the mean time, I have
 - changed my mirror script to *NOT* delete anything for now
 - rsync'ed (-u: do not overwrite newer) 
   a backup of web/packages/ from  2011-12-29 12:20:29

This has recovered 76 Mega bytes already..
Now indeed,  the CH mirror should contain a full web/packages/
again,
i.e. -->  http://cran.CH.r-project.org/web/packages/
which is  http://stat.ethz.ch/CRAN/web/packages/

should again be "fully loaded".

Martin Maechler, ETH Zurich


