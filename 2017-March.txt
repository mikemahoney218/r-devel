From ripley at stats.ox.ac.uk  Wed Mar  1 08:35:32 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Mar 2017 07:35:32 +0000
Subject: [Rd] Test suite failures in R-devel_2017-02-25_r72256
In-Reply-To: <8760jwdlq8.fsf@write-only.cryp.to>
References: <8760jwdlq8.fsf@write-only.cryp.to>
Message-ID: <6a7e0c06-3199-6d78-7277-8009c238114c@stats.ox.ac.uk>

On 27/02/2017 09:30, Peter Simons wrote:
> Hi,
>
> I tried compiling the latest pre-release for R 3.3.3 for the NixOS Linux
> distribution [1], but the build fails during the "make check" phase
> because of the following 2 issues:

Hmm, R-devel (your subject line) is not a pre-release of R 3.3.3: it is 
'R Under development' for what is planned as R 3.4.0.  Pre-release 
tarballs for 3.3.3 are things like R-rc_2017-02-26_r72260.tar.gz (and 
were previously labelled R-beta).

Your first point only occurs in R-devel, and was something already 
reported and under investigation.  Note that test does not actually 
depend on network access: it depends on having an accessible CRAN 
mirror.  The latter could be local (and is on the CRAN check farm, for 
example).  So we have been working on a more sophisticated condition to 
run that test.

There are lots of possible check environments: it is very time-consuming 
to check them all and reasonable coverage is only attempted once a 
pre-release reaches 'alpha' status -- 3.4.0 has not done so but is 
planned to be in late March.

I have just re-checked on Linux, and R 3.3.3 RC passed its checks 
without Internet access (which is checked for where needed).

I also re-checked 3.3.3 RC without recommended packages and got the 
expected messages about incomplete testing but no failures except in 
'make check-recommended' (expected!).

Our posting guide does ask you to include the output of sessionInfo(): 
that would have avoided the version confusion (and might even have 
alerted you to it).


> 1) The "tools" test in "tests/Examples" requires network access, which
>    it doesn't have in our build environment. Therefore, it fails as
>    follows according to "tools-Ex.Rout.fail":
>
>    | [...]
>    | > set.seed(11)
>    | > ## End(Don't show)
>    | > pdb <- CRAN_package_db()
>    | Warning in url(sprintf("%s/%s", cran, path), open = "rb") :
>    |   URL 'http://CRAN.R-project.org/web/packages/packages.rds': status was 'Couldn't resolve host name'
>    | Error in url(sprintf("%s/%s", cran, path), open = "rb") :
>    |   cannot open the connection to 'http://CRAN.R-project.org/web/packages/packages.rds'
>    | Calls: CRAN_package_db -> as.data.frame -> read_CRAN_object -> gzcon -> url
>    | Execution halted
>
>    I'm wondering whether it would be possible to extend the test suite
>    with a configure-time flag that disable tests which depend on network
>    access? My experience is that most modern Linux distributions run
>    their builds in a restricted environment and therefore will run into
>    trouble if the suite assumes that it can access the Internet.
>
> 2) When R is compiled with the --without-recommended-packages flag
>    (which is our preferred configuration), the "base" test in
>    "tests/Examples" fails, apparently because it depends on MASS. I'm
>    citing from "base-Ex.Rout.fail":
>
>    | >  ## The string "foo" and the symbol 'foo' can be used interchangably here:
>    | >  stopifnot( identical(isNamespaceLoaded(  "foo"   ), FALSE),
>    | +             identical(isNamespaceLoaded(quote(foo)), FALSE),
>    | +             identical(isNamespaceLoaded(quote(stats)), statL))
>    | >
>    | > hasM <- isNamespaceLoaded("MASS") # (to restore if needed)
>    | > Mns <- asNamespace("MASS") # loads it if not already
>    | Error in loadNamespace(name) : there is no package called 'MASS'
>    | Calls: asNamespace ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
>    | Execution halted
>
> I hope this helps!
>
> Best regards,
> Peter
>
>
>
> [1] http://nixos.org/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From simons at nospf.cryp.to  Wed Mar  1 10:13:13 2017
From: simons at nospf.cryp.to (Peter Simons)
Date: Wed, 1 Mar 2017 10:13:13 +0100
Subject: [Rd] Test suite failures in R-rc_2017-02-28_r72286.tar.gz
References: <8760jwdlq8.fsf@write-only.cryp.to>
	<6a7e0c06-3199-6d78-7277-8009c238114c@stats.ox.ac.uk>
Message-ID: <87bmtljr6e.fsf_-_@write-only.cryp.to>

Hi Brian,

 > R-devel (your subject line) is not a pre-release of R 3.3.3: it is 'R
 > Under development' for what is planned as R 3.4.0. Pre-release
 > tarballs for 3.3.3 are things like R-rc_2017-02-26_r72260.tar.gz (and
 > were previously labelled R-beta).

I did not realize this distinction exists. I am sorry about the
misleading report. I followed the link for "3.3.3 release candidates"
and didn't expect that directory to contain tarballs for 3.4.0, too. In
hindsight, that should have been obvious from the different file names,
I suppose. Thank you for the clarification.

I re-ran the build and test suite with the correct tarball,
R-rc_2017-02-28_r72286.tar.gz, and the result looks different indeed.
With that version, I get a test suite error in reg-tests-1c from
"tests". I'm citing the relevant bit from "reg-tests-1c.Rout.fail":

 | > [...]
 | > ## format.POSIXlt() of Jan.1 if  1941 or '42 is involved:
 | > tJan1 <- function(n1, n2)
 | +     strptime(paste0(n1:n2,"/01/01"), "%Y/%m/%d", tz="CET")
 | > wDSTJan1 <- function(n1, n2)
 | +     which("CEST" == sub(".* ", '', format(tJan1(n1,n2), usetz=TRUE)))
 | > (w8 <- wDSTJan1(1801, 2300))
 | integer(0)
 | > (w9 <- wDSTJan1(1901, 2300))
 | integer(0)
 | > stopifnot(identical(w8, 141:142),# exactly 1941:1942 had CEST on Jan.1
 | +           identical(w9,  41: 42))
 | Error: identical(w8, 141:142) is not TRUE
 | Execution halted

This happens in the --without-recommended-packages style build. Not sure
whether this is relevant.

The sessionInfo() output looks as follows:

 | R version 3.3.3 RC (2017-02-28 r72286)
 | Platform: x86_64-pc-linux-gnu (64-bit)
 | 
 | locale:
 | [1] C
 | 
 | attached base packages:
 | [1] stats     graphics  grDevices utils     datasets  base     

Best regards,
Peter


From simons at nospf.cryp.to  Wed Mar  1 10:25:39 2017
From: simons at nospf.cryp.to (Peter Simons)
Date: Wed, 1 Mar 2017 10:25:39 +0100
Subject: [Rd] Test suite failures in R-devel_2017-02-25_r72256
References: <8760jwdlq8.fsf@write-only.cryp.to>
	<22708.16632.500910.453227@stat.math.ethz.ch>
Message-ID: <8760jtjqlo.fsf@write-only.cryp.to>

Hi Martin,

 > Is it necessary to also run the 'make check' part in that restricted
 > environment? Or could that ('checking") not get more priviledges?

in NixOS, there is no way to run any kind of build process in an
environment that has network access. On one hand, that is a security
consideration, but the even more compelling reason for that choice is
that NixOS goes to great lengths to guarantee deterministic builds, and
a build process that connects to servers on the Internet and uses data
they provides is as non-deterministic as it can be, unfortunately.

What we can do for the 3.4.0 release is to extend our build environment
for R to ensure that all required resources are downloaded and made
available locally before the build starts.

 > Note that you can only run  "make check" if you don't install
 > recommended packages, whereas more thorough testing would
 > include
 >      make check-devel
 > or even
 >      make check-all
 >
 > but these do have quite a bit more requirements including recommended
 > packages being present.

Thank you for pointing that out. We do offer our users the choice of
whether they want the recommended packages included or not (the default
choice being to not include them), so we should in fact parameterize our
build to run the extended test suite if the recommended packages are
built.

Another option would be to always build the recommended packages, but to
not install them if the user doesn't want them included. I'm not sure,
though, whether the R build system supports such a type of build easily?

Best regards,
Peter


From maechler at stat.math.ethz.ch  Wed Mar  1 21:37:35 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Mar 2017 21:37:35 +0100
Subject: [Rd] stats::median
In-Reply-To: <22707.62587.111640.683473@stat.math.ethz.ch>
References: <CAF7e_thQjawXc-U84Xr2pYB-fAkd=TDv9WTYn_c4S9CUUgmqfw@mail.gmail.com>
	<22707.62587.111640.683473@stat.math.ethz.ch>
Message-ID: <22711.12559.768080.635541@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 27 Feb 2017 10:42:19 +0100 writes:

>>>>> Rob J Hyndman <Rob.Hyndman at monash.edu>
>>>>>     on Wed, 15 Feb 2017 21:48:56 +1100 writes:

    >> The generic stats::median method is defined as median <-
    >> function (x, na.rm = FALSE) {UseMethod("median")}

    >> I suggest that this should become median <- function (x,
    >> na.rm = FALSE, ...)  {UseMethod("median")}

    >> This would allow additional S3 methods to be developed
    >> with additional arguments.

    > and S4 methods, too.

    >> Currently I have to over-ride this generic definition in
    >> the demography package because median.demogdata has
    >> several other arguments.

    >> This shouldn't break any code, and will make it easier
    >> for new S3 methods to be developed. It is also consistent
    >> with almost all other S3 methods which do include an
    >> ellipsis.

    > "shouldn't break any code" is almost always quite
    > optimistic nowadays,....

For CRAN, the change leads   13 packages (out of > 10000) to
"regress" to  status: WARN.

I've checked 10 of them, and all these define  median() S3
methods, and currently of course have not had the '...' in their
formal argument list(s).

They (and all other useRs who define median() S3 methods and
want their code to work both in R <= 3.3.x _and_ R >= 3.4.0
could use code such as
(for package 'sets' in R/summary.R )

 
median.set <-
function(x, na.rm = FALSE, ...)
{
    median(as.numeric(x), na.rm = na.rm, ...)
}

## drop '...' in R versions <= 3.4.0 :
if((!any("..." == names(formals(median)))) {
    formals(median.set) <- formals(median.set)[names(formals(median.set)) != "..."]
    body(median.set)[[2]] <- body(median.set)[[2]][-4]
}

or simply
 
median.cset <-
    if("..." %in% names(formals(median))) {
        function(x, na.rm = FALSE, ...) median.gset(x, na.rm = na.rm, ...)
    } else
        function(x, na.rm = FALSE)      median.gset(x, na.rm = na.rm)


which is R code that will work fine in both current (and older)
R and in R-devel and future R versions.

For packages however, this will leave a 'R CMD check <pkg>'
warning (for now) because code and documentation mismatch
either in R-devel (and future)  R  or in current and previous R versions.

It is less clear what to do for these man i.e. *.Rd  pages [if you
have them for your median method(s): Note that they *are* optional for
registered S3 methods; package 'sets', e.g., documents 2 out of
4 median methods]. 

It may (or may not) make sense to tweak R-devel's own 'R CMD check'
to _not_ warn for the missing '...' in median methods for a
while and consequently you'd get away with continued use of no
'...' in the help page \usage{ ... } section.

One solution of course, would be to wait a bit and then release
such package only with

Depends: R (>= 3.4.0)

where you'd  use  '...' and keep the previous CRAN version of
the package for all earlier versions of R.
That is a maintenance pain however, if you want to change your
package features, because then you'd have to start releasing to
versions of the package: an "old" one with

Depends: R (< 3.4.0)

and a "new" one with   R (>= 3.4.0).

Probably easiest would be to comment the \usage{.} / \arguments \item{...}
parts for the time being {as long as you don't want R (>= 3.4.0)
in your package DESCRIPTION "unconditionally"}.

--

Tweaking  R-devel's  tools::codoc()  for this special case may
be a solution liked more by package maintainers for this case.
OTOH, we can only change R-devel's version of codoc(), so it
would be that platform which would show slightly inaccurate
"Usage:" for these (by not showing "...")  which also seems a
kludgy solution.



    > Actually it probably will break things when people start
    > using the new R version which implements the above *AND*
    > use packages installed with a previous version of R.  I
    > agree that this does not count as "breaking any code".

    > In spite of all that *and* the perennial drawback that a
    > '...' will allow argument name typos to go unnoticed

    > I agree you have a good argument nowadays, that median()
    > should be the same as many similar "basic statistics" R
    > functions and so I'll commit such a change to R-devel (to
    > become R 3.4.0 in April).

    > Thank you for the suggestion!  Martin Maechler, ETH Zurich

    >> -------------------------------------------------------------
    >> Rob J Hyndman Professor of Statistics, Monash University
    >> www.robjhyndman.com

    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From adrian.baddeley at curtin.edu.au  Thu Mar  2 02:12:39 2017
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Thu, 2 Mar 2017 01:12:39 +0000
Subject: [Rd] stats::median
In-Reply-To: <22711.12559.768080.635541@stat.math.ethz.ch>
References: <CAF7e_thQjawXc-U84Xr2pYB-fAkd=TDv9WTYn_c4S9CUUgmqfw@mail.gmail.com>
	<22707.62587.111640.683473@stat.math.ethz.ch>,
	<22711.12559.768080.635541@stat.math.ethz.ch>
Message-ID: <HK2PR0201MB2163CA991813E54123EF7119A4280@HK2PR0201MB2163.apcprd02.prod.outlook.com>

I agree it seems sensible to add an ellipsis to the formal arguments of the generic median().


The spatstat package has


                   median.im(x, na.rm=TRUE)



                   median.linim(x, ...)


These are both accepted by the package checker.


During the transition, perhaps methods for 'median' could have formals like 'median.linim'.


Of course this means that under older R versions, a call to the generic will not recognise/pass the new additional arguments. So, during the transition, other code in the package would need to explicitly call the method rather than the generic when the extra arguments are needed..


Alternatively - if we want to define the method differently according to the version number of R - isn't there a way to use Rd macros to include/exclude an \item declaration?


cheers

Adrian


Prof Adrian Baddeley DSc FAA

John Curtin Distinguished Professor

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia


________________________________
From: Martin Maechler <maechler at stat.math.ethz.ch>
Sent: Thursday, 2 March 2017 4:37 AM
To: Rob J Hyndman; r-devel at r-project.org
Cc: Martin Maechler
Subject: Re: [Rd] stats::median

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>> on Mon, 27 Feb 2017 10:42:19 +0100 writes:

>>>>> Rob J Hyndman <Rob.Hyndman at monash.edu>
>>>>> on Wed, 15 Feb 2017 21:48:56 +1100 writes:

>> The generic stats::median method is defined as median <-
>> function (x, na.rm = FALSE) {UseMethod("median")}

>> I suggest that this should become median <- function (x,
>> na.rm = FALSE, ...) {UseMethod("median")}

>> This would allow additional S3 methods to be developed
>> with additional arguments.

> and S4 methods, too.

>> Currently I have to over-ride this generic definition in
>> the demography package because median.demogdata has
>> several other arguments.

>> This shouldn't break any code, and will make it easier
>> for new S3 methods to be developed. It is also consistent
>> with almost all other S3 methods which do include an
>> ellipsis.

> "shouldn't break any code" is almost always quite
> optimistic nowadays,....

For CRAN, the change leads 13 packages (out of > 10000) to
"regress" to status: WARN.

I've checked 10 of them, and all these define median() S3
methods, and currently of course have not had the '...' in their
formal argument list(s).

They (and all other useRs who define median() S3 methods and
want their code to work both in R <= 3.3.x _and_ R >= 3.4.0
could use code such as
(for package 'sets' in R/summary.R )


median.set <-
function(x, na.rm = FALSE, ...)
{
median(as.numeric(x), na.rm = na.rm, ...)
}

## drop '...' in R versions <= 3.4.0 :
if((!any("..." == names(formals(median)))) {
formals(median.set) <- formals(median.set)[names(formals(median.set)) != "..."]
body(median.set)[[2]] <- body(median.set)[[2]][-4]
}

or simply

median.cset <-
if("..." %in% names(formals(median))) {
function(x, na.rm = FALSE, ...) median.gset(x, na.rm = na.rm, ...)
} else
function(x, na.rm = FALSE) median.gset(x, na.rm = na.rm)


which is R code that will work fine in both current (and older)
R and in R-devel and future R versions.

For packages however, this will leave a 'R CMD check <pkg>'
warning (for now) because code and documentation mismatch
either in R-devel (and future) R or in current and previous R versions.

It is less clear what to do for these man i.e. *.Rd pages [if you
have them for your median method(s): Note that they *are* optional for
registered S3 methods; package 'sets', e.g., documents 2 out of
4 median methods].

It may (or may not) make sense to tweak R-devel's own 'R CMD check'
to _not_ warn for the missing '...' in median methods for a
while and consequently you'd get away with continued use of no
'...' in the help page \usage{ ... } section.

One solution of course, would be to wait a bit and then release
such package only with

Depends: R (>= 3.4.0)

where you'd use '...' and keep the previous CRAN version of
the package for all earlier versions of R.
That is a maintenance pain however, if you want to change your
package features, because then you'd have to start releasing to
versions of the package: an "old" one with

Depends: R (< 3.4.0)

and a "new" one with R (>= 3.4.0).

Probably easiest would be to comment the \usage{.} / \arguments \item{...}
parts for the time being {as long as you don't want R (>= 3.4.0)
in your package DESCRIPTION "unconditionally"}.

--

Tweaking R-devel's tools::codoc() for this special case may
be a solution liked more by package maintainers for this case.
OTOH, we can only change R-devel's version of codoc(), so it
would be that platform which would show slightly inaccurate
"Usage:" for these (by not showing "...") which also seems a
kludgy solution.



> Actually it probably will break things when people start
> using the new R version which implements the above *AND*
> use packages installed with a previous version of R. I
> agree that this does not count as "breaking any code".

> In spite of all that *and* the perennial drawback that a
> '...' will allow argument name typos to go unnoticed

> I agree you have a good argument nowadays, that median()
> should be the same as many similar "basic statistics" R
> functions and so I'll commit such a change to R-devel (to
> become R 3.4.0 in April).

> Thank you for the suggestion! Martin Maechler, ETH Zurich

>> -------------------------------------------------------------
>> Rob J Hyndman Professor of Statistics, Monash University
>> www.robjhyndman.com<http://www.robjhyndman.com>

>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Mar  3 09:52:16 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 3 Mar 2017 00:52:16 -0800
Subject: [Rd] Control statements with condition with greater than one should
 give error (not just warning) [PATCH]
Message-ID: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>

I'd like to propose that the whenever the length of condition passed
to an if or a while statement differs from one, an error is produced
rather than just a warning as today:

> x <- 1:2
> if (x == 1) message("x == 1")
x == 1
Warning message:
In if (x == 1) message("x == 1") :
  the condition has length > 1 and only the first element will be used

There are probably legacy reasons for why this is accepted by R in the
first place, but I cannot imagine than anyone wants to use an if/while
statement this way on purpose.  The warning about this misuse, was
introduced in November 2002 (R-devel thread 'vector arguments to
if()'; https://stat.ethz.ch/pipermail/r-devel/2002-November/025537.html).

Below is patch (also attached) that introduces option
'check.condition' such that when TRUE, it will generate an error
rather than a warning (default).  This option allows for a smooth
migration as it can be added to 'R CMD check --as-cran' and developers
can give time to check and fix their packages.  Eventually,
check.condition=TRUE can become the new default.

With options(check.condition = TRUE), one gets:

> x <- 1:2
> if (x == 1) message("x == 1")
Error in if (x == 1) message("x == 1") : the condition has length > 1

and

> while (x < 2) message("x < 2")
Error in while (x < 2) message("x < 2") : the condition has length > 1


Index: src/library/base/man/options.Rd
===================================================================
--- src/library/base/man/options.Rd (revision 72298)
+++ src/library/base/man/options.Rd (working copy)
@@ -86,6 +86,11 @@
       vector (atomic or \code{\link{list}}) is extended, by something
       like \code{x <- 1:3; x[5] <- 6}.}

+    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
+      \code{TRUE}, an error is produced whenever the condition to an
+      \code{if} or a \code{while} control statement is of length greater
+      than one.  If \code{FALSE}, a \link{warning} is produced.}
+
     \item{\code{CBoundsCheck}:}{logical, controlling whether
       \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
       array over-runs on the atomic vector arguments.
@@ -445,6 +450,7 @@
   \tabular{ll}{
     \code{add.smooth} \tab \code{TRUE}\cr
     \code{check.bounds} \tab \code{FALSE}\cr
+    \code{check.condition} \tab \code{FALSE}\cr
     \code{continue} \tab \code{"+ "}\cr
     \code{digits} \tab \code{7}\cr
     \code{echo} \tab \code{TRUE}\cr
Index: src/library/utils/R/completion.R
===================================================================
--- src/library/utils/R/completion.R (revision 72298)
+++ src/library/utils/R/completion.R (working copy)
@@ -1304,8 +1304,8 @@
           "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
           "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")

-    options <- c("add.smooth", "browser", "check.bounds", "continue",
- "contrasts", "defaultPackages", "demo.ask", "device",
+    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
+        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
  "digits", "dvipscmd", "echo", "editor", "encoding",
  "example.ask", "expressions", "help.search.types",
  "help.try.all.packages", "htmlhelp", "HTTPUserAgent",
Index: src/main/eval.c
===================================================================
--- src/main/eval.c (revision 72298)
+++ src/main/eval.c (working copy)
@@ -1851,9 +1851,13 @@
     Rboolean cond = NA_LOGICAL;

     if (length(s) > 1) {
+ int check = asInteger(GetOption1(install("check.condition")));
  PROTECT(s); /* needed as per PR#15990.  call gets protected by
warningcall() */
- warningcall(call,
-    _("the condition has length > 1 and only the first element will be used"));
+ if(check != NA_INTEGER && check > 0)
+    errorcall(call, _("the condition has length > 1"));
+ else
+    warningcall(call,
+ _("the condition has length > 1 and only the first element will be used"));
  UNPROTECT(1);
     }
     if (length(s) > 0) {
Index: src/main/options.c
===================================================================
--- src/main/options.c (revision 72298)
+++ src/main/options.c (working copy)
@@ -65,6 +65,7 @@
  * "timeout" ./connections.c

  * "check.bounds"
+ * "check.condition"
  * "error"
  * "error.messages"
  * "show.error.messages"
@@ -248,9 +249,9 @@
     char *p;

 #ifdef HAVE_RL_COMPLETION_MATCHES
+    PROTECT(v = val = allocList(22));
+#else
     PROTECT(v = val = allocList(21));
-#else
-    PROTECT(v = val = allocList(20));
 #endif

     SET_TAG(v, install("prompt"));
@@ -289,6 +290,10 @@
     SETCAR(v, ScalarLogical(0)); /* no checking */
     v = CDR(v);

+    SET_TAG(v, install("check.condition"));
+    SETCAR(v, ScalarLogical(0)); /* no checking */
+    v = CDR(v);
+
     p = getenv("R_KEEP_PKG_SOURCE");
     R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;


I'm happy to file this via https://bugs.r-project.org, if preferred.

/Henrik
-------------- next part --------------
Index: src/library/base/man/options.Rd
===================================================================
--- src/library/base/man/options.Rd	(revision 72298)
+++ src/library/base/man/options.Rd	(working copy)
@@ -86,6 +86,11 @@
       vector (atomic or \code{\link{list}}) is extended, by something
       like \code{x <- 1:3; x[5] <- 6}.}
 
+    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
+      \code{TRUE}, an error is produced whenever the condition to an
+      \code{if} or a \code{while} control statement is of length greater
+      than one.  If \code{FALSE}, a \link{warning} is produced.}
+
     \item{\code{CBoundsCheck}:}{logical, controlling whether
       \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
       array over-runs on the atomic vector arguments.
@@ -445,6 +450,7 @@
   \tabular{ll}{
     \code{add.smooth} \tab \code{TRUE}\cr
     \code{check.bounds} \tab \code{FALSE}\cr
+    \code{check.condition} \tab \code{FALSE}\cr
     \code{continue} \tab \code{"+ "}\cr
     \code{digits} \tab \code{7}\cr
     \code{echo} \tab \code{TRUE}\cr
Index: src/library/utils/R/completion.R
===================================================================
--- src/library/utils/R/completion.R	(revision 72298)
+++ src/library/utils/R/completion.R	(working copy)
@@ -1304,8 +1304,8 @@
           "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
           "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")
 
-    options <- c("add.smooth", "browser", "check.bounds", "continue",
-	"contrasts", "defaultPackages", "demo.ask", "device",
+    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
+        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
 	"digits", "dvipscmd", "echo", "editor", "encoding",
 	"example.ask", "expressions", "help.search.types",
 	"help.try.all.packages", "htmlhelp", "HTTPUserAgent",
Index: src/main/eval.c
===================================================================
--- src/main/eval.c	(revision 72298)
+++ src/main/eval.c	(working copy)
@@ -1851,9 +1851,13 @@
     Rboolean cond = NA_LOGICAL;
 
     if (length(s) > 1) {
+	int check = asInteger(GetOption1(install("check.condition")));
 	PROTECT(s);	 /* needed as per PR#15990.  call gets protected by warningcall() */
-	warningcall(call,
-		    _("the condition has length > 1 and only the first element will be used"));
+	if(check != NA_INTEGER && check > 0)
+	    errorcall(call, _("the condition has length > 1"));
+	else
+	    warningcall(call,
+			_("the condition has length > 1 and only the first element will be used"));
 	UNPROTECT(1);
     }
     if (length(s) > 0) {
Index: src/main/options.c
===================================================================
--- src/main/options.c	(revision 72298)
+++ src/main/options.c	(working copy)
@@ -65,6 +65,7 @@
  *	"timeout"		./connections.c
 
  *	"check.bounds"
+ *	"check.condition"
  *	"error"
  *	"error.messages"
  *	"show.error.messages"
@@ -248,9 +249,9 @@
     char *p;
 
 #ifdef HAVE_RL_COMPLETION_MATCHES
+    PROTECT(v = val = allocList(22));
+#else
     PROTECT(v = val = allocList(21));
-#else
-    PROTECT(v = val = allocList(20));
 #endif
 
     SET_TAG(v, install("prompt"));
@@ -289,6 +290,10 @@
     SETCAR(v, ScalarLogical(0));	/* no checking */
     v = CDR(v);
 
+    SET_TAG(v, install("check.condition"));
+    SETCAR(v, ScalarLogical(0));	/* no checking */
+    v = CDR(v);
+    
     p = getenv("R_KEEP_PKG_SOURCE");
     R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;
 

From Boehnstedt at demogr.mpg.de  Fri Mar  3 11:23:12 2017
From: Boehnstedt at demogr.mpg.de (Boehnstedt, Marie)
Date: Fri, 3 Mar 2017 10:23:12 +0000
Subject: [Rd] Bug in nlm()
Message-ID: <0051D1E3C4DC574698F0EDFC7FFA6ADBEBF89E8E@HERMES01.demogr.mpg.de>

Dear all,

I have found a bug in nlm() and would like to submit a report on this.
Since nlm() is in the stats-package, which is maintained by the R Core team, bug reports should be submitted to R's Bugzilla. However, I'm not a member of Bugzilla. Could anyone be so kind to add me to R's Bugzilla members or let me know to whom I should send the bug report?
Thank you in advance.

Kind regards,
Marie B?hnstedt


Marie B?hnstedt, MSc
Research Scientist
Max Planck Institute for Demographic Research
Konrad-Zuse-Str. 1, 18057 Rostock, Germany
www.demogr.mpg.de<http://www.demogr.mpg.de/>




----------
This mail has been sent through the MPI for Demographic ...{{dropped:9}}


From maechler at stat.math.ethz.ch  Fri Mar  3 18:15:47 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Mar 2017 18:15:47 +0100
Subject: [Rd] Bug in nlm()
In-Reply-To: <0051D1E3C4DC574698F0EDFC7FFA6ADBEBF89E8E@HERMES01.demogr.mpg.de>
References: <0051D1E3C4DC574698F0EDFC7FFA6ADBEBF89E8E@HERMES01.demogr.mpg.de>
Message-ID: <22713.42179.765118.892734@stat.math.ethz.ch>

>>>>> Boehnstedt, Marie <Boehnstedt at demogr.mpg.de>
>>>>>     on Fri, 3 Mar 2017 10:23:12 +0000 writes:

    > Dear all,
    > I have found a bug in nlm() and would like to submit a report on this.
    > Since nlm() is in the stats-package, which is maintained by the R Core team, bug reports should be submitted to R's Bugzilla. However, I'm not a member of Bugzilla. Could anyone be so kind to add me to R's Bugzilla members or let me know to whom I should send the bug report?

Dear Marie,

I can do this ... but  are you really sure?  There is
     https://www.r-project.org/bugs.html
which you should spend some time reading if you haven't already.

I think you would post a MRE (Minimal Reproducible Example) here
{or on stackoverflow or ...} if you'd follow what the 'R bugs' web
page (above) recommends and only report a bug after some
feedback from "the public".

Of course, I could be wrong.. and happy if you explain / tell me why.

Best,
Martin Maechler

    > Thank you in advance.

    > Kind regards,
    > Marie B?hnstedt


    > Marie B?hnstedt, MSc
    > Research Scientist
    > Max Planck Institute for Demographic Research
    > Konrad-Zuse-Str. 1, 18057 Rostock, Germany
    > www.demogr.mpg.de<http://www.demogr.mpg.de/>




    > ----------
    > This mail has been sent through the MPI for Demographic ...{{dropped:9}}


    > ----------------------------------------------------------------------
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Mar  3 18:22:37 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Mar 2017 18:22:37 +0100
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
Message-ID: <22713.42589.85552.452293@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Fri, 3 Mar 2017 00:52:16 -0800 writes:

    > I'd like to propose that the whenever the length of condition passed
    > to an if or a while statement differs from one, an error is produced
    > rather than just a warning as today:

    >> x <- 1:2
    >> if (x == 1) message("x == 1")
    > x == 1
    > Warning message:
    > In if (x == 1) message("x == 1") :
    > the condition has length > 1 and only the first element will be used

    > There are probably legacy reasons for why this is accepted by R in the
    > first place, but I cannot imagine than anyone wants to use an if/while
    > statement this way on purpose.  The warning about this misuse, was
    > introduced in November 2002 (R-devel thread 'vector arguments to
    > if()'; https://stat.ethz.ch/pipermail/r-devel/2002-November/025537.html).

yes, before, there was *no* warning at all and so the problem existed
in several partly important R packages.

Now is a different time, I agree, and I even tend to agree we
should make this an error... probably however not for the
upcoming R 3.4.0 (in April which is somewhat soon) but rather
for the next version.


    > Below is patch (also attached) that introduces option
    > 'check.condition' such that when TRUE, 

ouch ouch ouch!   There are many sayings starting with
  "The way to hell ...."

Here:

The way to R hell starts (or "widens", your choice) by
introducing options() that influence basic language semantics

!!

For robust code you will start to test all code of R for all
different possible combinations of these options set ---- I am
sure you would not want this.

No --- don't even think of allowing an option for something such basic!

Martin Maechler
ETH Zurich (and R Core)

    > it will generate an error
    > rather than a warning (default).  This option allows for a smooth
    > migration as it can be added to 'R CMD check --as-cran' and developers
    > can give time to check and fix their packages.  Eventually,
    > check.condition=TRUE can become the new default.

    > With options(check.condition = TRUE), one gets:

    >> x <- 1:2
    >> if (x == 1) message("x == 1")
    > Error in if (x == 1) message("x == 1") : the condition has length > 1

    > and

    >> while (x < 2) message("x < 2")
    > Error in while (x < 2) message("x < 2") : the condition has length > 1


    > Index: src/library/base/man/options.Rd
    > ===================================================================
    > --- src/library/base/man/options.Rd (revision 72298)
    > +++ src/library/base/man/options.Rd (working copy)
    > @@ -86,6 +86,11 @@
    > vector (atomic or \code{\link{list}}) is extended, by something
    > like \code{x <- 1:3; x[5] <- 6}.}

    > +    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
    > +      \code{TRUE}, an error is produced whenever the condition to an
    > +      \code{if} or a \code{while} control statement is of length greater
    > +      than one.  If \code{FALSE}, a \link{warning} is produced.}
    > +
    > \item{\code{CBoundsCheck}:}{logical, controlling whether
    > \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
    > array over-runs on the atomic vector arguments.
    > @@ -445,6 +450,7 @@
    > \tabular{ll}{
    > \code{add.smooth} \tab \code{TRUE}\cr
    > \code{check.bounds} \tab \code{FALSE}\cr
    > +    \code{check.condition} \tab \code{FALSE}\cr
    > \code{continue} \tab \code{"+ "}\cr
    > \code{digits} \tab \code{7}\cr
    > \code{echo} \tab \code{TRUE}\cr
    > Index: src/library/utils/R/completion.R
    > ===================================================================
    > --- src/library/utils/R/completion.R (revision 72298)
    > +++ src/library/utils/R/completion.R (working copy)
    > @@ -1304,8 +1304,8 @@
    > "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
    > "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")

    > -    options <- c("add.smooth", "browser", "check.bounds", "continue",
    > - "contrasts", "defaultPackages", "demo.ask", "device",
    > +    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
    > +        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
    > "digits", "dvipscmd", "echo", "editor", "encoding",
    > "example.ask", "expressions", "help.search.types",
    > "help.try.all.packages", "htmlhelp", "HTTPUserAgent",
    > Index: src/main/eval.c
    > ===================================================================
    > --- src/main/eval.c (revision 72298)
    > +++ src/main/eval.c (working copy)
    > @@ -1851,9 +1851,13 @@
    > Rboolean cond = NA_LOGICAL;

    > if (length(s) > 1) {
    > + int check = asInteger(GetOption1(install("check.condition")));
    > PROTECT(s); /* needed as per PR#15990.  call gets protected by
    > warningcall() */
    > - warningcall(call,
    > -    _("the condition has length > 1 and only the first element will be used"));
    > + if(check != NA_INTEGER && check > 0)
    > +    errorcall(call, _("the condition has length > 1"));
    > + else
    > +    warningcall(call,
    > + _("the condition has length > 1 and only the first element will be used"));
    > UNPROTECT(1);
    > }
    > if (length(s) > 0) {
    > Index: src/main/options.c
    > ===================================================================
    > --- src/main/options.c (revision 72298)
    > +++ src/main/options.c (working copy)
    > @@ -65,6 +65,7 @@
    > * "timeout" ./connections.c

    > * "check.bounds"
    > + * "check.condition"
    > * "error"
    > * "error.messages"
    > * "show.error.messages"
    > @@ -248,9 +249,9 @@
    > char *p;

    > #ifdef HAVE_RL_COMPLETION_MATCHES
    > +    PROTECT(v = val = allocList(22));
    > +#else
    > PROTECT(v = val = allocList(21));
    > -#else
    > -    PROTECT(v = val = allocList(20));
    > #endif

    > SET_TAG(v, install("prompt"));
    > @@ -289,6 +290,10 @@
    > SETCAR(v, ScalarLogical(0)); /* no checking */
    > v = CDR(v);

    > +    SET_TAG(v, install("check.condition"));
    > +    SETCAR(v, ScalarLogical(0)); /* no checking */
    > +    v = CDR(v);
    > +
    > p = getenv("R_KEEP_PKG_SOURCE");
    > R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;


    > I'm happy to file this via https://bugs.r-project.org, if preferred.

    > /Henrik

    > ----------------------------------------------------------------------
    > Index: src/library/base/man/options.Rd
    > ===================================================================
    > --- src/library/base/man/options.Rd	(revision 72298)
    > +++ src/library/base/man/options.Rd	(working copy)
    > @@ -86,6 +86,11 @@
    > vector (atomic or \code{\link{list}}) is extended, by something
    > like \code{x <- 1:3; x[5] <- 6}.}
 
    > +    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
    > +      \code{TRUE}, an error is produced whenever the condition to an
    > +      \code{if} or a \code{while} control statement is of length greater
    > +      than one.  If \code{FALSE}, a \link{warning} is produced.}
    > +
    > \item{\code{CBoundsCheck}:}{logical, controlling whether
    > \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
    > array over-runs on the atomic vector arguments.
    > @@ -445,6 +450,7 @@
    > \tabular{ll}{
    > \code{add.smooth} \tab \code{TRUE}\cr
    > \code{check.bounds} \tab \code{FALSE}\cr
    > +    \code{check.condition} \tab \code{FALSE}\cr
    > \code{continue} \tab \code{"+ "}\cr
    > \code{digits} \tab \code{7}\cr
    > \code{echo} \tab \code{TRUE}\cr
    > Index: src/library/utils/R/completion.R
    > ===================================================================
    > --- src/library/utils/R/completion.R	(revision 72298)
    > +++ src/library/utils/R/completion.R	(working copy)
    > @@ -1304,8 +1304,8 @@
    > "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
    > "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")
 
    > -    options <- c("add.smooth", "browser", "check.bounds", "continue",
    > -	"contrasts", "defaultPackages", "demo.ask", "device",
    > +    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
    > +        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
    > "digits", "dvipscmd", "echo", "editor", "encoding",
    > "example.ask", "expressions", "help.search.types",
    > "help.try.all.packages", "htmlhelp", "HTTPUserAgent",
    > Index: src/main/eval.c
    > ===================================================================
    > --- src/main/eval.c	(revision 72298)
    > +++ src/main/eval.c	(working copy)
    > @@ -1851,9 +1851,13 @@
    > Rboolean cond = NA_LOGICAL;
 
    > if (length(s) > 1) {
    > +	int check = asInteger(GetOption1(install("check.condition")));
    > PROTECT(s);	 /* needed as per PR#15990.  call gets protected by warningcall() */
    > -	warningcall(call,
    > -		    _("the condition has length > 1 and only the first element will be used"));
    > +	if(check != NA_INTEGER && check > 0)
    > +	    errorcall(call, _("the condition has length > 1"));
    > +	else
    > +	    warningcall(call,
    > +			_("the condition has length > 1 and only the first element will be used"));
    > UNPROTECT(1);
    > }
    > if (length(s) > 0) {
    > Index: src/main/options.c
    > ===================================================================
    > --- src/main/options.c	(revision 72298)
    > +++ src/main/options.c	(working copy)
    > @@ -65,6 +65,7 @@
    > *	"timeout"		./connections.c
 
    > *	"check.bounds"
    > + *	"check.condition"
    > *	"error"
    > *	"error.messages"
    > *	"show.error.messages"
    > @@ -248,9 +249,9 @@
    > char *p;
 
    > #ifdef HAVE_RL_COMPLETION_MATCHES
    > +    PROTECT(v = val = allocList(22));
    > +#else
    > PROTECT(v = val = allocList(21));
    > -#else
    > -    PROTECT(v = val = allocList(20));
    > #endif
 
    > SET_TAG(v, install("prompt"));
    > @@ -289,6 +290,10 @@
    > SETCAR(v, ScalarLogical(0));	/* no checking */
    > v = CDR(v);
 
    > +    SET_TAG(v, install("check.condition"));
    > +    SETCAR(v, ScalarLogical(0));	/* no checking */
    > +    v = CDR(v);
    > +    
    > p = getenv("R_KEEP_PKG_SOURCE");
    > R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;
 

    > ----------------------------------------------------------------------
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From hugo.raguet at gmail.com  Fri Mar  3 14:51:40 2017
From: hugo.raguet at gmail.com (Hugo Raguet)
Date: Fri, 3 Mar 2017 14:51:40 +0100
Subject: [Rd] Trouble installing packages when history mechanism is modified
 by user profile
Message-ID: <CAB4ZKxPyT33+rGZ22aZBJXXRT8_p09=eOYMB0ntaQQ4BrGdjkQ@mail.gmail.com>

I tried installing the 'ks' package from my interactive R session, it
failed with the following

Erreur dans .External2(C_loadhistory, file) :
  aucun m?canisme d'historique des commandes disponible
Calls: <Anonymous>
Ex?cution arr?t?e

second line is french for "no command history mechanism available", fouth
is "execution stopped".
This does not happen when I comment out the following line from my
.Rprofile:
utils::loadhistory(file = "~/.Rhistory")

On Stack Overflow, someone else has similar trouble with another package,
which seems to be also related to command history:
http://stackoverflow.com/questions/18240863/installing-packages-on-r-fails-when-loading-rprofile#18256224

Is this a bug in R, or in the concerned packages?

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Mar  3 18:43:53 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 3 Mar 2017 09:43:53 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <22713.42589.85552.452293@stat.math.ethz.ch>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
Message-ID: <CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>

On Fri, Mar 3, 2017 at 9:22 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>>     on Fri, 3 Mar 2017 00:52:16 -0800 writes:
>
>     > I'd like to propose that the whenever the length of condition passed
>     > to an if or a while statement differs from one, an error is produced
>     > rather than just a warning as today:
>
>     >> x <- 1:2
>     >> if (x == 1) message("x == 1")
>     > x == 1
>     > Warning message:
>     > In if (x == 1) message("x == 1") :
>     > the condition has length > 1 and only the first element will be used
>
>     > There are probably legacy reasons for why this is accepted by R in the
>     > first place, but I cannot imagine than anyone wants to use an if/while
>     > statement this way on purpose.  The warning about this misuse, was
>     > introduced in November 2002 (R-devel thread 'vector arguments to
>     > if()'; https://stat.ethz.ch/pipermail/r-devel/2002-November/025537.html).
>
> yes, before, there was *no* warning at all and so the problem existed
> in several partly important R packages.
>
> Now is a different time, I agree, and I even tend to agree we
> should make this an error... probably however not for the
> upcoming R 3.4.0 (in April which is somewhat soon) but rather
> for the next version.
>
>
>     > Below is patch (also attached) that introduces option
>     > 'check.condition' such that when TRUE,
>
> ouch ouch ouch!   There are many sayings starting with
>   "The way to hell ...."
>
> Here:
>
> The way to R hell starts (or "widens", your choice) by
> introducing options() that influence basic language semantics
>
> !!
>
> For robust code you will start to test all code of R for all
> different possible combinations of these options set ---- I am
> sure you would not want this.

You only want to test with check.condition = TRUE.  No new code,
package updates etc should be allowed to only pass if they have to use
check.condition = FALSE.

>
> No --- don't even think of allowing an option for something such basic!

But, how you propose a warning-to-error transition should be made
without wreaking havoc?  Just flip the switch in R-devel and see CRAN
and Bioconductor packages break overnight?  Particularly Bioconductor
devel might become non-functional (since at times it requires
R-devel).  For my own code / packages, I would be able to handle such
a change, but I'm completely out of control if one of the package I'm
depending on does not provide a quick fix (with the only option to
remove package tests for those dependencies).

My idea is that with this option, then this can be tested at runtime
locally by users and developers (cf. warnPartialMatchArgs), but also
via R CMD check.  It would also provide CRAN with a way to check it on
incoming submissions as on the test farm - eventually all CRAN
packages pass without errors.  This option would only exist for a
number of R releases (first default to FALSE, then TRUE) and then
eventually be deprecated and removed.  Does this clarify my design?

As an alternative to an option, one could use an environment variable
R_CHECK_CONDITION that is a bit "hidden" from misuse.

/Henrik

>
> Martin Maechler
> ETH Zurich (and R Core)
>
>     > it will generate an error
>     > rather than a warning (default).  This option allows for a smooth
>     > migration as it can be added to 'R CMD check --as-cran' and developers
>     > can give time to check and fix their packages.  Eventually,
>     > check.condition=TRUE can become the new default.
>
>     > With options(check.condition = TRUE), one gets:
>
>     >> x <- 1:2
>     >> if (x == 1) message("x == 1")
>     > Error in if (x == 1) message("x == 1") : the condition has length > 1
>
>     > and
>
>     >> while (x < 2) message("x < 2")
>     > Error in while (x < 2) message("x < 2") : the condition has length > 1
>
>
>     > Index: src/library/base/man/options.Rd
>     > ===================================================================
>     > --- src/library/base/man/options.Rd (revision 72298)
>     > +++ src/library/base/man/options.Rd (working copy)
>     > @@ -86,6 +86,11 @@
>     > vector (atomic or \code{\link{list}}) is extended, by something
>     > like \code{x <- 1:3; x[5] <- 6}.}
>
>     > +    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
>     > +      \code{TRUE}, an error is produced whenever the condition to an
>     > +      \code{if} or a \code{while} control statement is of length greater
>     > +      than one.  If \code{FALSE}, a \link{warning} is produced.}
>     > +
>     > \item{\code{CBoundsCheck}:}{logical, controlling whether
>     > \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
>     > array over-runs on the atomic vector arguments.
>     > @@ -445,6 +450,7 @@
>     > \tabular{ll}{
>     > \code{add.smooth} \tab \code{TRUE}\cr
>     > \code{check.bounds} \tab \code{FALSE}\cr
>     > +    \code{check.condition} \tab \code{FALSE}\cr
>     > \code{continue} \tab \code{"+ "}\cr
>     > \code{digits} \tab \code{7}\cr
>     > \code{echo} \tab \code{TRUE}\cr
>     > Index: src/library/utils/R/completion.R
>     > ===================================================================
>     > --- src/library/utils/R/completion.R (revision 72298)
>     > +++ src/library/utils/R/completion.R (working copy)
>     > @@ -1304,8 +1304,8 @@
>     > "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
>     > "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")
>
>     > -    options <- c("add.smooth", "browser", "check.bounds", "continue",
>     > - "contrasts", "defaultPackages", "demo.ask", "device",
>     > +    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
>     > +        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
>     > "digits", "dvipscmd", "echo", "editor", "encoding",
>     > "example.ask", "expressions", "help.search.types",
>     > "help.try.all.packages", "htmlhelp", "HTTPUserAgent",
>     > Index: src/main/eval.c
>     > ===================================================================
>     > --- src/main/eval.c (revision 72298)
>     > +++ src/main/eval.c (working copy)
>     > @@ -1851,9 +1851,13 @@
>     > Rboolean cond = NA_LOGICAL;
>
>     > if (length(s) > 1) {
>     > + int check = asInteger(GetOption1(install("check.condition")));
>     > PROTECT(s); /* needed as per PR#15990.  call gets protected by
>     > warningcall() */
>     > - warningcall(call,
>     > -    _("the condition has length > 1 and only the first element will be used"));
>     > + if(check != NA_INTEGER && check > 0)
>     > +    errorcall(call, _("the condition has length > 1"));
>     > + else
>     > +    warningcall(call,
>     > + _("the condition has length > 1 and only the first element will be used"));
>     > UNPROTECT(1);
>     > }
>     > if (length(s) > 0) {
>     > Index: src/main/options.c
>     > ===================================================================
>     > --- src/main/options.c (revision 72298)
>     > +++ src/main/options.c (working copy)
>     > @@ -65,6 +65,7 @@
>     > * "timeout" ./connections.c
>
>     > * "check.bounds"
>     > + * "check.condition"
>     > * "error"
>     > * "error.messages"
>     > * "show.error.messages"
>     > @@ -248,9 +249,9 @@
>     > char *p;
>
>     > #ifdef HAVE_RL_COMPLETION_MATCHES
>     > +    PROTECT(v = val = allocList(22));
>     > +#else
>     > PROTECT(v = val = allocList(21));
>     > -#else
>     > -    PROTECT(v = val = allocList(20));
>     > #endif
>
>     > SET_TAG(v, install("prompt"));
>     > @@ -289,6 +290,10 @@
>     > SETCAR(v, ScalarLogical(0)); /* no checking */
>     > v = CDR(v);
>
>     > +    SET_TAG(v, install("check.condition"));
>     > +    SETCAR(v, ScalarLogical(0)); /* no checking */
>     > +    v = CDR(v);
>     > +
>     > p = getenv("R_KEEP_PKG_SOURCE");
>     > R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;
>
>
>     > I'm happy to file this via https://bugs.r-project.org, if preferred.
>
>     > /Henrik
>
>     > ----------------------------------------------------------------------
>     > Index: src/library/base/man/options.Rd
>     > ===================================================================
>     > --- src/library/base/man/options.Rd       (revision 72298)
>     > +++ src/library/base/man/options.Rd       (working copy)
>     > @@ -86,6 +86,11 @@
>     > vector (atomic or \code{\link{list}}) is extended, by something
>     > like \code{x <- 1:3; x[5] <- 6}.}
>
>     > +    \item{\code{check.condition}:}{logical, defaulting to \code{FALSE}.  If
>     > +      \code{TRUE}, an error is produced whenever the condition to an
>     > +      \code{if} or a \code{while} control statement is of length greater
>     > +      than one.  If \code{FALSE}, a \link{warning} is produced.}
>     > +
>     > \item{\code{CBoundsCheck}:}{logical, controlling whether
>     > \code{\link{.C}} and \code{\link{.Fortran}} make copies to check for
>     > array over-runs on the atomic vector arguments.
>     > @@ -445,6 +450,7 @@
>     > \tabular{ll}{
>     > \code{add.smooth} \tab \code{TRUE}\cr
>     > \code{check.bounds} \tab \code{FALSE}\cr
>     > +    \code{check.condition} \tab \code{FALSE}\cr
>     > \code{continue} \tab \code{"+ "}\cr
>     > \code{digits} \tab \code{7}\cr
>     > \code{echo} \tab \code{TRUE}\cr
>     > Index: src/library/utils/R/completion.R
>     > ===================================================================
>     > --- src/library/utils/R/completion.R      (revision 72298)
>     > +++ src/library/utils/R/completion.R      (working copy)
>     > @@ -1304,8 +1304,8 @@
>     > "plt", "ps", "pty", "smo", "srt", "tck", "tcl", "usr",
>     > "xaxp", "xaxs", "xaxt", "xpd", "yaxp", "yaxs", "yaxt")
>
>     > -    options <- c("add.smooth", "browser", "check.bounds", "continue",
>     > - "contrasts", "defaultPackages", "demo.ask", "device",
>     > +    options <- c("add.smooth", "browser", "check.bounds", "check.condition",
>     > +        "continue", "contrasts", "defaultPackages", "demo.ask", "device",
>     > "digits", "dvipscmd", "echo", "editor", "encoding",
>     > "example.ask", "expressions", "help.search.types",
>     > "help.try.all.packages", "htmlhelp", "HTTPUserAgent",
>     > Index: src/main/eval.c
>     > ===================================================================
>     > --- src/main/eval.c       (revision 72298)
>     > +++ src/main/eval.c       (working copy)
>     > @@ -1851,9 +1851,13 @@
>     > Rboolean cond = NA_LOGICAL;
>
>     > if (length(s) > 1) {
>     > + int check = asInteger(GetOption1(install("check.condition")));
>     > PROTECT(s);        /* needed as per PR#15990.  call gets protected by warningcall() */
>     > - warningcall(call,
>     > -             _("the condition has length > 1 and only the first element will be used"));
>     > + if(check != NA_INTEGER && check > 0)
>     > +     errorcall(call, _("the condition has length > 1"));
>     > + else
>     > +     warningcall(call,
>     > +                 _("the condition has length > 1 and only the first element will be used"));
>     > UNPROTECT(1);
>     > }
>     > if (length(s) > 0) {
>     > Index: src/main/options.c
>     > ===================================================================
>     > --- src/main/options.c    (revision 72298)
>     > +++ src/main/options.c    (working copy)
>     > @@ -65,6 +65,7 @@
>     > * "timeout"               ./connections.c
>
>     > * "check.bounds"
>     > + *       "check.condition"
>     > * "error"
>     > * "error.messages"
>     > * "show.error.messages"
>     > @@ -248,9 +249,9 @@
>     > char *p;
>
>     > #ifdef HAVE_RL_COMPLETION_MATCHES
>     > +    PROTECT(v = val = allocList(22));
>     > +#else
>     > PROTECT(v = val = allocList(21));
>     > -#else
>     > -    PROTECT(v = val = allocList(20));
>     > #endif
>
>     > SET_TAG(v, install("prompt"));
>     > @@ -289,6 +290,10 @@
>     > SETCAR(v, ScalarLogical(0));      /* no checking */
>     > v = CDR(v);
>
>     > +    SET_TAG(v, install("check.condition"));
>     > +    SETCAR(v, ScalarLogical(0)); /* no checking */
>     > +    v = CDR(v);
>     > +
>     > p = getenv("R_KEEP_PKG_SOURCE");
>     > R_KeepSource = (p && (strcmp(p, "yes") == 0)) ? 1 : 0;
>
>
>     > ----------------------------------------------------------------------
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Fri Mar  3 18:55:16 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 4 Mar 2017 06:55:16 +1300
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
Message-ID: <CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>

> But, how you propose a warning-to-error transition should be made
> without wreaking havoc?  Just flip the switch in R-devel and see CRAN
> and Bioconductor packages break overnight?  Particularly Bioconductor
> devel might become non-functional (since at times it requires
> R-devel).  For my own code / packages, I would be able to handle such
> a change, but I'm completely out of control if one of the package I'm
> depending on does not provide a quick fix (with the only option to
> remove package tests for those dependencies).

Generally, a package can not be on CRAN if it has any warnings, so I
don't think this change would have any impact on CRAN packages.  Isn't
this also true for bioconductor?

Hadley

-- 
http://hadley.nz


From henrik.bengtsson at gmail.com  Fri Mar  3 18:55:59 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 3 Mar 2017 09:55:59 -0800
Subject: [Rd] Trouble installing packages when history mechanism is
 modified by user profile
In-Reply-To: <CAB4ZKxPyT33+rGZ22aZBJXXRT8_p09=eOYMB0ntaQQ4BrGdjkQ@mail.gmail.com>
References: <CAB4ZKxPyT33+rGZ22aZBJXXRT8_p09=eOYMB0ntaQQ4BrGdjkQ@mail.gmail.com>
Message-ID: <CAFDcVCRGTCg5ybgVvB3tVs67qn+62T_R7ex2gk9KxojVcD8imA@mail.gmail.com>

Using

if (interactive()) utils::loadhistory(file = "~/.Rhistory")

should solve your problem.  The reason is that install.packages() in
turn launches a non-interactive child R process that installs the
package.  When that process loads your startup file, it fails, because
that function can only be used in interactive mode.  Here's an
example:

$ Rscript -e "utils::loadhistory()"
Error in .External2(C_loadhistory, file) : no history mechanism available

/Henrik

On Fri, Mar 3, 2017 at 5:51 AM, Hugo Raguet <hugo.raguet at gmail.com> wrote:
> I tried installing the 'ks' package from my interactive R session, it
> failed with the following
>
> Erreur dans .External2(C_loadhistory, file) :
>   aucun m?canisme d'historique des commandes disponible
> Calls: <Anonymous>
> Ex?cution arr?t?e
>
> second line is french for "no command history mechanism available", fouth
> is "execution stopped".
> This does not happen when I comment out the following line from my
> .Rprofile:
> utils::loadhistory(file = "~/.Rhistory")
>
> On Stack Overflow, someone else has similar trouble with another package,
> which seems to be also related to command history:
> http://stackoverflow.com/questions/18240863/installing-packages-on-r-fails-when-loading-rprofile#18256224
>
> Is this a bug in R, or in the concerned packages?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Fri Mar  3 19:10:53 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 3 Mar 2017 10:10:53 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
Message-ID: <CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>

On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
>> But, how you propose a warning-to-error transition should be made
>> without wreaking havoc?  Just flip the switch in R-devel and see CRAN
>> and Bioconductor packages break overnight?  Particularly Bioconductor
>> devel might become non-functional (since at times it requires
>> R-devel).  For my own code / packages, I would be able to handle such
>> a change, but I'm completely out of control if one of the package I'm
>> depending on does not provide a quick fix (with the only option to
>> remove package tests for those dependencies).
>
> Generally, a package can not be on CRAN if it has any warnings, so I
> don't think this change would have any impact on CRAN packages.  Isn't
> this also true for bioconductor?

Having a tests/warn.R file with:

warning("boom")

passes through R CMD check --as-cran unnoticed.  Same with:

if (sample(2) == 1) message("It's your lucky day today!")

/Henrik

PS. Does testthat signal that?

>
> Hadley
>
> --
> http://hadley.nz


From zhengda1936 at gmail.com  Sat Mar  4 18:36:04 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 4 Mar 2017 12:36:04 -0500
Subject: [Rd] can we override "if" in R?
Message-ID: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>

Hello,

I heard we can override almost everything in R. Is it possible to
override "if" keyword in R to evaluate my own object instead of a
logical value?

Thanks,
Da


From csardi.gabor at gmail.com  Sat Mar  4 18:41:18 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 4 Mar 2017 17:41:18 +0000
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
Message-ID: <CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>

You can. Perhaps needless to say, be careful with this.

? `if` <- function(...) FALSE
? if (TRUE) TRUE else FALSE
[1] FALSE

G.

On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> Hello,
>
> I heard we can override almost everything in R. Is it possible to
> override "if" keyword in R to evaluate my own object instead of a
> logical value?
>
> Thanks,
> Da
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From zhengda1936 at gmail.com  Sat Mar  4 18:47:44 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 4 Mar 2017 12:47:44 -0500
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
Message-ID: <CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>

Thanks.
Can I override it for a specific class?
I can do that for operators such as "!". For example, "!.fm" works for
objects of the class "fm".
It seems I can't do the same for "if".

Best,
Da

On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> You can. Perhaps needless to say, be careful with this.
>
> ? `if` <- function(...) FALSE
> ? if (TRUE) TRUE else FALSE
> [1] FALSE
>
> G.
>
> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> Hello,
>>
>> I heard we can override almost everything in R. Is it possible to
>> override "if" keyword in R to evaluate my own object instead of a
>> logical value?
>>
>> Thanks,
>> Da
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Sat Mar  4 19:22:35 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 4 Mar 2017 18:22:35 +0000
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
Message-ID: <CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>

`!` is a generic, `if` is not. You can define an `if` that is generic,
but this might be even more dangerous....

? `if` <- function(a, b, c) UseMethod("if")
? `if.default` <- function(a,b,c) base::`if`(a, b, c)
? `if.foo` <- function(a, b, c) FALSE
? a <- structure(42, class = "foo")

? if (a) TRUE else FALSE
[1] FALSE

? if (1) TRUE else FALSE
[1] TRUE

Gabor

On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> Thanks.
> Can I override it for a specific class?
> I can do that for operators such as "!". For example, "!.fm" works for
> objects of the class "fm".
> It seems I can't do the same for "if".
>
> Best,
> Da
>
> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> You can. Perhaps needless to say, be careful with this.
>>
>> ? `if` <- function(...) FALSE
>> ? if (TRUE) TRUE else FALSE
>> [1] FALSE
>>
>> G.
>>
>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>> Hello,
>>>
>>> I heard we can override almost everything in R. Is it possible to
>>> override "if" keyword in R to evaluate my own object instead of a
>>> logical value?
>>>
>>> Thanks,
>>> Da
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From zhengda1936 at gmail.com  Sat Mar  4 20:49:26 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 4 Mar 2017 14:49:26 -0500
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
Message-ID: <CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>

I'm just curious. Why making "if" generic is even more dangerous?

Best,
Da

On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> `!` is a generic, `if` is not. You can define an `if` that is generic,
> but this might be even more dangerous....
>
> ? `if` <- function(a, b, c) UseMethod("if")
> ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> ? `if.foo` <- function(a, b, c) FALSE
> ? a <- structure(42, class = "foo")
>
> ? if (a) TRUE else FALSE
> [1] FALSE
>
> ? if (1) TRUE else FALSE
> [1] TRUE
>
> Gabor
>
> On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> Thanks.
>> Can I override it for a specific class?
>> I can do that for operators such as "!". For example, "!.fm" works for
>> objects of the class "fm".
>> It seems I can't do the same for "if".
>>
>> Best,
>> Da
>>
>> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>> You can. Perhaps needless to say, be careful with this.
>>>
>>> ? `if` <- function(...) FALSE
>>> ? if (TRUE) TRUE else FALSE
>>> [1] FALSE
>>>
>>> G.
>>>
>>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I heard we can override almost everything in R. Is it possible to
>>>> override "if" keyword in R to evaluate my own object instead of a
>>>> logical value?
>>>>
>>>> Thanks,
>>>> Da
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Mar  4 21:04:25 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 4 Mar 2017 21:04:25 +0100
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
Message-ID: <22715.7625.79979.272007@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Fri, 3 Mar 2017 10:10:53 -0800 writes:

    > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham
    > <h.wickham at gmail.com> wrote:
    >>> But, how you propose a warning-to-error transition
    >>> should be made without wreaking havoc?  Just flip the
    >>> switch in R-devel and see CRAN and Bioconductor packages
    >>> break overnight?  Particularly Bioconductor devel might
    >>> become non-functional (since at times it requires
    >>> R-devel).  For my own code / packages, I would be able
    >>> to handle such a change, but I'm completely out of
    >>> control if one of the package I'm depending on does not
    >>> provide a quick fix (with the only option to remove
    >>> package tests for those dependencies).
    >> 
    >> Generally, a package can not be on CRAN if it has any
    >> warnings, so I don't think this change would have any
    >> impact on CRAN packages.  Isn't this also true for
    >> bioconductor?

    > Having a tests/warn.R file with:

    > warning("boom")

    > passes through R CMD check --as-cran unnoticed.  

Yes, indeed.. you are right Henrik  that many/most R warning()s would
not produce  R CMD check  'WARNING's ..

I think Hadley and I fell into the same mental pit of concluding
that such warning()s  from   if(<length-larger-one>)  ...
would not currently happen in CRAN / Bioc packages and hence
turning them to errors would not have a direct effect.

With your 2nd e-mail of saying that you'd propose such an option
only for a few releases of R you've indeed clarified your intent
to me.
OTOH, I would prefer using an environment variable (as you've
proposed as an alternative)  which is turned "active"  at the
beginning only manually or  for the  "CRAN incoming" checks of
the CRAN team (and bioconductor submission checks?)
and later for  '--as-cran'  etc until it eventually becomes the
unconditional behavior of R (and the env.variable is no longer used).

Martin


From lawrence.michael at gene.com  Sat Mar  4 21:20:45 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 4 Mar 2017 12:20:45 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <22715.7625.79979.272007@stat.math.ethz.ch>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
	<22715.7625.79979.272007@stat.math.ethz.ch>
Message-ID: <CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>

Is there really a need for these complications? Packages emitting this
warning are broken by definition and should be fixed. Perhaps we could
"flip the switch" in a test environment and see how much havoc is wreaked
and whether authors are sufficiently responsive?

Michael

On Sat, Mar 4, 2017 at 12:04 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
> >>>>>     on Fri, 3 Mar 2017 10:10:53 -0800 writes:
>
>     > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham
>     > <h.wickham at gmail.com> wrote:
>     >>> But, how you propose a warning-to-error transition
>     >>> should be made without wreaking havoc?  Just flip the
>     >>> switch in R-devel and see CRAN and Bioconductor packages
>     >>> break overnight?  Particularly Bioconductor devel might
>     >>> become non-functional (since at times it requires
>     >>> R-devel).  For my own code / packages, I would be able
>     >>> to handle such a change, but I'm completely out of
>     >>> control if one of the package I'm depending on does not
>     >>> provide a quick fix (with the only option to remove
>     >>> package tests for those dependencies).
>     >>
>     >> Generally, a package can not be on CRAN if it has any
>     >> warnings, so I don't think this change would have any
>     >> impact on CRAN packages.  Isn't this also true for
>     >> bioconductor?
>
>     > Having a tests/warn.R file with:
>
>     > warning("boom")
>
>     > passes through R CMD check --as-cran unnoticed.
>
> Yes, indeed.. you are right Henrik  that many/most R warning()s would
> not produce  R CMD check  'WARNING's ..
>
> I think Hadley and I fell into the same mental pit of concluding
> that such warning()s  from   if(<length-larger-one>)  ...
> would not currently happen in CRAN / Bioc packages and hence
> turning them to errors would not have a direct effect.
>
> With your 2nd e-mail of saying that you'd propose such an option
> only for a few releases of R you've indeed clarified your intent
> to me.
> OTOH, I would prefer using an environment variable (as you've
> proposed as an alternative)  which is turned "active"  at the
> beginning only manually or  for the  "CRAN incoming" checks of
> the CRAN team (and bioconductor submission checks?)
> and later for  '--as-cran'  etc until it eventually becomes the
> unconditional behavior of R (and the env.variable is no longer used).
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Sat Mar  4 21:22:16 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 4 Mar 2017 12:22:16 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
Message-ID: <CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>

I'm curious as to precisely why someone would want to do this.

On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com> wrote:

> I'm just curious. Why making "if" generic is even more dangerous?
>
> Best,
> Da
>
> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> > `!` is a generic, `if` is not. You can define an `if` that is generic,
> > but this might be even more dangerous....
> >
> > ? `if` <- function(a, b, c) UseMethod("if")
> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> > ? `if.foo` <- function(a, b, c) FALSE
> > ? a <- structure(42, class = "foo")
> >
> > ? if (a) TRUE else FALSE
> > [1] FALSE
> >
> > ? if (1) TRUE else FALSE
> > [1] TRUE
> >
> > Gabor
> >
> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> >> Thanks.
> >> Can I override it for a specific class?
> >> I can do that for operators such as "!". For example, "!.fm" works for
> >> objects of the class "fm".
> >> It seems I can't do the same for "if".
> >>
> >> Best,
> >> Da
> >>
> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> >>> You can. Perhaps needless to say, be careful with this.
> >>>
> >>> ? `if` <- function(...) FALSE
> >>> ? if (TRUE) TRUE else FALSE
> >>> [1] FALSE
> >>>
> >>> G.
> >>>
> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> >>>> Hello,
> >>>>
> >>>> I heard we can override almost everything in R. Is it possible to
> >>>> override "if" keyword in R to evaluate my own object instead of a
> >>>> logical value?
> >>>>
> >>>> Thanks,
> >>>> Da
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From zhengda1936 at gmail.com  Sat Mar  4 21:36:28 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 4 Mar 2017 15:36:28 -0500
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
Message-ID: <CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>

In my case, I create a new type of matrices and override matrix
operations in R for these matrices.
My goal is to make the system as transparent as possible, which means
my system should execute the existing R code without modification.
The problem is that when data is in my own vectors or matrices, "if"
or "while" can't access their values unless we explicitly convert them
into R objects. But this means users need to modify the existing code.
So I hope I can override "if", "while", etc to access data in my own
vectors and matrices directly.
Does this sound reasonable?

Best,
Da

On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> I'm curious as to precisely why someone would want to do this.
>
> On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>
>> I'm just curious. Why making "if" generic is even more dangerous?
>>
>> Best,
>> Da
>>
>> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> wrote:
>> > `!` is a generic, `if` is not. You can define an `if` that is generic,
>> > but this might be even more dangerous....
>> >
>> > ? `if` <- function(a, b, c) UseMethod("if")
>> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
>> > ? `if.foo` <- function(a, b, c) FALSE
>> > ? a <- structure(42, class = "foo")
>> >
>> > ? if (a) TRUE else FALSE
>> > [1] FALSE
>> >
>> > ? if (1) TRUE else FALSE
>> > [1] TRUE
>> >
>> > Gabor
>> >
>> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> >> Thanks.
>> >> Can I override it for a specific class?
>> >> I can do that for operators such as "!". For example, "!.fm" works for
>> >> objects of the class "fm".
>> >> It seems I can't do the same for "if".
>> >>
>> >> Best,
>> >> Da
>> >>
>> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> >> wrote:
>> >>> You can. Perhaps needless to say, be careful with this.
>> >>>
>> >>> ? `if` <- function(...) FALSE
>> >>> ? if (TRUE) TRUE else FALSE
>> >>> [1] FALSE
>> >>>
>> >>> G.
>> >>>
>> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
>> >>> wrote:
>> >>>> Hello,
>> >>>>
>> >>>> I heard we can override almost everything in R. Is it possible to
>> >>>> override "if" keyword in R to evaluate my own object instead of a
>> >>>> logical value?
>> >>>>
>> >>>> Thanks,
>> >>>> Da
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-devel at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From wdunlap at tibco.com  Sat Mar  4 21:43:58 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 4 Mar 2017 12:43:58 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
Message-ID: <CAF8bMcZfCD5ADzyaxuSF314AiDfCKR6d36pRoX6Ckc2t+h2MPw@mail.gmail.com>

dplyr::translate_sql() redefines lots of functions, include "if", to
translate from R syntax to SQL syntax.

> dplyr::translate_sql(if ("mpg">25) "better" else "worse")
<SQL> CASE WHEN ('mpg' > 25.0) THEN ('better') ELSE ('worse') END

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Mar 4, 2017 at 12:22 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> I'm curious as to precisely why someone would want to do this.
>
> On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com> wrote:
>
>> I'm just curious. Why making "if" generic is even more dangerous?
>>
>> Best,
>> Da
>>
>> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> wrote:
>> > `!` is a generic, `if` is not. You can define an `if` that is generic,
>> > but this might be even more dangerous....
>> >
>> > ? `if` <- function(a, b, c) UseMethod("if")
>> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
>> > ? `if.foo` <- function(a, b, c) FALSE
>> > ? a <- structure(42, class = "foo")
>> >
>> > ? if (a) TRUE else FALSE
>> > [1] FALSE
>> >
>> > ? if (1) TRUE else FALSE
>> > [1] TRUE
>> >
>> > Gabor
>> >
>> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> >> Thanks.
>> >> Can I override it for a specific class?
>> >> I can do that for operators such as "!". For example, "!.fm" works for
>> >> objects of the class "fm".
>> >> It seems I can't do the same for "if".
>> >>
>> >> Best,
>> >> Da
>> >>
>> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> wrote:
>> >>> You can. Perhaps needless to say, be careful with this.
>> >>>
>> >>> ? `if` <- function(...) FALSE
>> >>> ? if (TRUE) TRUE else FALSE
>> >>> [1] FALSE
>> >>>
>> >>> G.
>> >>>
>> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
>> wrote:
>> >>>> Hello,
>> >>>>
>> >>>> I heard we can override almost everything in R. Is it possible to
>> >>>> override "if" keyword in R to evaluate my own object instead of a
>> >>>> logical value?
>> >>>>
>> >>>> Thanks,
>> >>>> Da
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-devel at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Sun Mar  5 00:49:06 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 4 Mar 2017 15:49:06 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
	<22715.7625.79979.272007@stat.math.ethz.ch>
	<CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
Message-ID: <CAFDcVCSRiyW2YJ9Auj_k4f41OVHmqh9T9ZWX9tA_e=yTCK3T_w@mail.gmail.com>

Here's a patch that enables the error if
_R_CHECK_CONDITION_={1,true,TRUE,yes,YES}.

$ svn diff
Index: src/main/eval.c
===================================================================
--- src/main/eval.c (revision 72303)
+++ src/main/eval.c (working copy)
@@ -1851,9 +1851,19 @@
     Rboolean cond = NA_LOGICAL;

     if (length(s) > 1) {
+ int val = 0; /* warn by default */
+ char *check = getenv("_R_CHECK_CONDITION_");
+ if (check != NULL) {
+    val = (strcmp("1", check) == 0 ||
+           strcasecmp("true", check) == 0 ||
+   strcasecmp("yes", check) == 0);
+        }
  PROTECT(s); /* needed as per PR#15990.  call gets protected by
warningcall() */
- warningcall(call,
-    _("the condition has length > 1 and only the first element will be used"));
+ if (val)
+    errorcall(call, _("the condition has length > 1"));
+        else
+    warningcall(call,
+ _("the condition has length > 1 and only the first element will be used"));
  UNPROTECT(1);
     }
     if (length(s) > 0) {

An alternative is to make _R_CHECK_CONDITION_=false the default behavior.


With this env variable, I think it'll be easier for a developer to
temporarily work around broken dependencies until fixed.  It will also
help identify broken dependencies.  For instance, as soon as one is
identified it can be wrapped up in an:

  with_faulty_conditions(x <- pkg::foo(...))

and additionally faulty if/while statements can be detected.  Your
package will still "work" until downstream packages are fixed.  Here,

with_faulty_conditions <- function(expr, envir = parent.frame()) {
  oenv <- Sys.getenv("_R_CHECK_CONDITION_")
  on.exit(Sys.setenv("_R_CHECK_CONDITION_" = oenv))
  Sys.setenv("_R_CHECK_CONDITION_" = FALSE)
  eval(substitute(expr), envir = envir)
}

/Henrik

On Sat, Mar 4, 2017 at 12:20 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> Is there really a need for these complications? Packages emitting this
> warning are broken by definition and should be fixed. Perhaps we could "flip
> the switch" in a test environment and see how much havoc is wreaked and
> whether authors are sufficiently responsive?
>
> Michael
>
> On Sat, Mar 4, 2017 at 12:04 PM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>> >>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>> >>>>>     on Fri, 3 Mar 2017 10:10:53 -0800 writes:
>>
>>     > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham
>>     > <h.wickham at gmail.com> wrote:
>>     >>> But, how you propose a warning-to-error transition
>>     >>> should be made without wreaking havoc?  Just flip the
>>     >>> switch in R-devel and see CRAN and Bioconductor packages
>>     >>> break overnight?  Particularly Bioconductor devel might
>>     >>> become non-functional (since at times it requires
>>     >>> R-devel).  For my own code / packages, I would be able
>>     >>> to handle such a change, but I'm completely out of
>>     >>> control if one of the package I'm depending on does not
>>     >>> provide a quick fix (with the only option to remove
>>     >>> package tests for those dependencies).
>>     >>
>>     >> Generally, a package can not be on CRAN if it has any
>>     >> warnings, so I don't think this change would have any
>>     >> impact on CRAN packages.  Isn't this also true for
>>     >> bioconductor?
>>
>>     > Having a tests/warn.R file with:
>>
>>     > warning("boom")
>>
>>     > passes through R CMD check --as-cran unnoticed.
>>
>> Yes, indeed.. you are right Henrik  that many/most R warning()s would
>> not produce  R CMD check  'WARNING's ..
>>
>> I think Hadley and I fell into the same mental pit of concluding
>> that such warning()s  from   if(<length-larger-one>)  ...
>> would not currently happen in CRAN / Bioc packages and hence
>> turning them to errors would not have a direct effect.
>>
>> With your 2nd e-mail of saying that you'd propose such an option
>> only for a few releases of R you've indeed clarified your intent
>> to me.
>> OTOH, I would prefer using an environment variable (as you've
>> proposed as an alternative)  which is turned "active"  at the
>> beginning only manually or  for the  "CRAN incoming" checks of
>> the CRAN team (and bioconductor submission checks?)
>> and later for  '--as-cran'  etc until it eventually becomes the
>> unconditional behavior of R (and the env.variable is no longer used).
>>
>> Martin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From csardi.gabor at gmail.com  Sun Mar  5 08:13:42 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 5 Mar 2017 07:13:42 +0000
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
Message-ID: <CABtg=KmmtEm1m8t6-vngxYEgjLecsRdGHVS62YwCWT21VqXVqA@mail.gmail.com>

Because the S3 class system is very informal. E.g. if you happen to
have an `if.whatever` function, that will be automatically a method of
your generic.

Gabor

On Sat, Mar 4, 2017 at 7:49 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> I'm just curious. Why making "if" generic is even more dangerous?
>
> Best,
> Da
>
> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> `!` is a generic, `if` is not. You can define an `if` that is generic,
>> but this might be even more dangerous....
>>
>> ? `if` <- function(a, b, c) UseMethod("if")
>> ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
>> ? `if.foo` <- function(a, b, c) FALSE
>> ? a <- structure(42, class = "foo")
>>
>> ? if (a) TRUE else FALSE
>> [1] FALSE
>>
>> ? if (1) TRUE else FALSE
>> [1] TRUE
>>
>> Gabor
>>
>> On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>> Thanks.
>>> Can I override it for a specific class?
>>> I can do that for operators such as "!". For example, "!.fm" works for
>>> objects of the class "fm".
>>> It seems I can't do the same for "if".
>>>
>>> Best,
>>> Da
>>>
>>> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>>> You can. Perhaps needless to say, be careful with this.
>>>>
>>>> ? `if` <- function(...) FALSE
>>>> ? if (TRUE) TRUE else FALSE
>>>> [1] FALSE
>>>>
>>>> G.
>>>>
>>>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>>>> Hello,
>>>>>
>>>>> I heard we can override almost everything in R. Is it possible to
>>>>> override "if" keyword in R to evaluate my own object instead of a
>>>>> logical value?
>>>>>
>>>>> Thanks,
>>>>> Da
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Sun Mar  5 19:35:44 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 6 Mar 2017 07:35:44 +1300
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CABtg=KmmtEm1m8t6-vngxYEgjLecsRdGHVS62YwCWT21VqXVqA@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CABtg=KmmtEm1m8t6-vngxYEgjLecsRdGHVS62YwCWT21VqXVqA@mail.gmail.com>
Message-ID: <CABdHhvFNgF4mkt8pMx02N3cGig2dO2+O8H_R9Sfek+7Wu+yH-Q@mail.gmail.com>

On Sun, Mar 5, 2017 at 8:13 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Because the S3 class system is very informal. E.g. if you happen to
> have an `if.whatever` function, that will be automatically a method of
> your generic.

For example:

x <- structure(1:10, class = "test")
t(x)
#>
#>  One Sample t-test
#>
#> data:  x
#> t = 5.7446, df = 9, p-value = 0.0002782
#> alternative hypothesis: true mean is not equal to 0
#> 95 percent confidence interval:
#>  3.334149 7.665851
#> sample estimates:
#> mean of x
#>       5.5


-- 
http://hadley.nz


From lawrence.michael at gene.com  Sun Mar  5 20:50:06 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sun, 5 Mar 2017 11:50:06 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
Message-ID: <CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>

On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:

> In my case, I create a new type of matrices and override matrix
> operations in R for these matrices.
> My goal is to make the system as transparent as possible, which means
> my system should execute the existing R code without modification.
> The problem is that when data is in my own vectors or matrices, "if"
> or "while" can't access their values unless we explicitly convert them
> into R objects. But this means users need to modify the existing code.
> So I hope I can override "if", "while", etc to access data in my own
> vectors and matrices directly.
> Does this sound reasonable?
>
>
Would you really need the alternate representation for scalar logicals?

I can see a case in the deferred evaluation context, although it would be
problematic wrt side effects unless the deferral is complete.




> Best,
> Da
>
> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
> > I'm curious as to precisely why someone would want to do this.
> >
> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com> wrote:
> >>
> >> I'm just curious. Why making "if" generic is even more dangerous?
> >>
> >> Best,
> >> Da
> >>
> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> >> wrote:
> >> > `!` is a generic, `if` is not. You can define an `if` that is generic,
> >> > but this might be even more dangerous....
> >> >
> >> > ? `if` <- function(a, b, c) UseMethod("if")
> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> >> > ? `if.foo` <- function(a, b, c) FALSE
> >> > ? a <- structure(42, class = "foo")
> >> >
> >> > ? if (a) TRUE else FALSE
> >> > [1] FALSE
> >> >
> >> > ? if (1) TRUE else FALSE
> >> > [1] TRUE
> >> >
> >> > Gabor
> >> >
> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> >> >> Thanks.
> >> >> Can I override it for a specific class?
> >> >> I can do that for operators such as "!". For example, "!.fm" works
> for
> >> >> objects of the class "fm".
> >> >> It seems I can't do the same for "if".
> >> >>
> >> >> Best,
> >> >> Da
> >> >>
> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi <
> csardi.gabor at gmail.com>
> >> >> wrote:
> >> >>> You can. Perhaps needless to say, be careful with this.
> >> >>>
> >> >>> ? `if` <- function(...) FALSE
> >> >>> ? if (TRUE) TRUE else FALSE
> >> >>> [1] FALSE
> >> >>>
> >> >>> G.
> >> >>>
> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
> >> >>> wrote:
> >> >>>> Hello,
> >> >>>>
> >> >>>> I heard we can override almost everything in R. Is it possible to
> >> >>>> override "if" keyword in R to evaluate my own object instead of a
> >> >>>> logical value?
> >> >>>>
> >> >>>> Thanks,
> >> >>>> Da
> >> >>>>
> >> >>>> ______________________________________________
> >> >>>> R-devel at r-project.org mailing list
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

	[[alternative HTML version deleted]]


From zhengda1936 at gmail.com  Sun Mar  5 21:52:41 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sun, 5 Mar 2017 15:52:41 -0500
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
	<CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
Message-ID: <CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>

On Sun, Mar 5, 2017 at 2:50 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
>
>
> On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>>
>> In my case, I create a new type of matrices and override matrix
>> operations in R for these matrices.
>> My goal is to make the system as transparent as possible, which means
>> my system should execute the existing R code without modification.
>> The problem is that when data is in my own vectors or matrices, "if"
>> or "while" can't access their values unless we explicitly convert them
>> into R objects. But this means users need to modify the existing code.
>> So I hope I can override "if", "while", etc to access data in my own
>> vectors and matrices directly.
>> Does this sound reasonable?
>>
>
> Would you really need the alternate representation for scalar logicals?
>
> I can see a case in the deferred evaluation context, although it would be
> problematic wrt side effects unless the deferral is complete.
This is exactly why I want to use my own matrix objects and redefine
"if" for the matrices. In my framework, all matrices are read-only, so
there isn't side effect.

Best,
Da
>
>
>
>>
>> Best,
>> Da
>>
>> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
>> <lawrence.michael at gene.com> wrote:
>> > I'm curious as to precisely why someone would want to do this.
>> >
>> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> >>
>> >> I'm just curious. Why making "if" generic is even more dangerous?
>> >>
>> >> Best,
>> >> Da
>> >>
>> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> >> wrote:
>> >> > `!` is a generic, `if` is not. You can define an `if` that is
>> >> > generic,
>> >> > but this might be even more dangerous....
>> >> >
>> >> > ? `if` <- function(a, b, c) UseMethod("if")
>> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
>> >> > ? `if.foo` <- function(a, b, c) FALSE
>> >> > ? a <- structure(42, class = "foo")
>> >> >
>> >> > ? if (a) TRUE else FALSE
>> >> > [1] FALSE
>> >> >
>> >> > ? if (1) TRUE else FALSE
>> >> > [1] TRUE
>> >> >
>> >> > Gabor
>> >> >
>> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
>> >> > wrote:
>> >> >> Thanks.
>> >> >> Can I override it for a specific class?
>> >> >> I can do that for operators such as "!". For example, "!.fm" works
>> >> >> for
>> >> >> objects of the class "fm".
>> >> >> It seems I can't do the same for "if".
>> >> >>
>> >> >> Best,
>> >> >> Da
>> >> >>
>> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi
>> >> >> <csardi.gabor at gmail.com>
>> >> >> wrote:
>> >> >>> You can. Perhaps needless to say, be careful with this.
>> >> >>>
>> >> >>> ? `if` <- function(...) FALSE
>> >> >>> ? if (TRUE) TRUE else FALSE
>> >> >>> [1] FALSE
>> >> >>>
>> >> >>> G.
>> >> >>>
>> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
>> >> >>> wrote:
>> >> >>>> Hello,
>> >> >>>>
>> >> >>>> I heard we can override almost everything in R. Is it possible to
>> >> >>>> override "if" keyword in R to evaluate my own object instead of a
>> >> >>>> logical value?
>> >> >>>>
>> >> >>>> Thanks,
>> >> >>>> Da
>> >> >>>>
>> >> >>>> ______________________________________________
>> >> >>>> R-devel at r-project.org mailing list
>> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>
>


From henrik.bengtsson at gmail.com  Sun Mar  5 22:56:48 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 5 Mar 2017 13:56:48 -0800
Subject: [Rd] length(unclass(x)) without unclass(x)?
Message-ID: <CAFDcVCTHgtGbyYcqy+TvbuBz4B5bhR4CyCkzXaSs9hUo=6NP=Q@mail.gmail.com>

I'm looking for a way to get the length of an object 'x' as given by
base data type without dispatching on class.  Something analogous to
how .subset()/.subset2(), e.g. a .length() function.  I know that I
can do length(unclass(x)), but that will trigger the creation of a new
object unclass(x) which I want to avoid because 'x' might be very
large.

Here's a dummy example illustrating what I'm trying to get to:

> x <- structure(double(1e6), class = c("foo", "numeric"))
> length.foo <- function(x) 1L
> length(x)
[1] 1
> length(unclass(x))
[1] 1000000

but the latter call will cause an internal memory allocation:

> profmem::profmem(length(unclass(x)))
Rprofmem memory profiling of:
length(unclass(x))

Memory allocations:
        bytes      calls
1     8000040 <internal>
total 8000040

In my use case, I have control over neither the class of 'x' (it can
be any class from any package) nor the implementation of length() for
the class.  I'm not sure, but in the "old old days", I think I could
have called base::length.default(x) to achieve this.  Does anyone know
of a way to infer length(unclass(x)) without going via unclass(x)?  I
prefer to do this with the existing R API and not having to implement
it in native code.

Thanks,

Henrik


From bmbroom at gmail.com  Sun Mar  5 23:03:30 2017
From: bmbroom at gmail.com (Bradley Broom)
Date: Sun, 5 Mar 2017 16:03:30 -0600
Subject: [Rd] Please add me to bugzilla
Message-ID: <CACCRr6GzeBhOQMNKwNRMwkirP3BH2SXnrim=fRM6Ydryds=Ang@mail.gmail.com>

Please add me to R bugzilla.

Thanks,
Bradley

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Mon Mar  6 01:43:18 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 5 Mar 2017 16:43:18 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
	<CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
	<CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>
Message-ID: <CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>

Da,

I've been following this thread and I'm still confused as to exactly what
you want/why you want it.

I'm probably just missing some context here, but, If() doesn't operate on
matrices, generally. Can you give an example of the type of code you want
to have continue to run that requires if operation *directly* on one of
your matrix objects, as opposed, say, to a value pulled out from it, or the
dot-product of two vectors in your system, both of which would be values
(scalars) not matrices.

Now ifelse(), is of course, a different beast altogether, and would need to
be overloaded within your system, I imagine.

Best,
~G

On Sun, Mar 5, 2017 at 12:52 PM, Da Zheng <zhengda1936 at gmail.com> wrote:

> On Sun, Mar 5, 2017 at 2:50 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
> >
> >
> > On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> >>
> >> In my case, I create a new type of matrices and override matrix
> >> operations in R for these matrices.
> >> My goal is to make the system as transparent as possible, which means
> >> my system should execute the existing R code without modification.
> >> The problem is that when data is in my own vectors or matrices, "if"
> >> or "while" can't access their values unless we explicitly convert them
> >> into R objects. But this means users need to modify the existing code.
> >> So I hope I can override "if", "while", etc to access data in my own
> >> vectors and matrices directly.
> >> Does this sound reasonable?
> >>
> >
> > Would you really need the alternate representation for scalar logicals?
> >
> > I can see a case in the deferred evaluation context, although it would be
> > problematic wrt side effects unless the deferral is complete.
> This is exactly why I want to use my own matrix objects and redefine
> "if" for the matrices. In my framework, all matrices are read-only, so
> there isn't side effect.
>
> Best,
> Da
> >
> >
> >
> >>
> >> Best,
> >> Da
> >>
> >> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
> >> <lawrence.michael at gene.com> wrote:
> >> > I'm curious as to precisely why someone would want to do this.
> >> >
> >> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> >> >>
> >> >> I'm just curious. Why making "if" generic is even more dangerous?
> >> >>
> >> >> Best,
> >> >> Da
> >> >>
> >> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com
> >
> >> >> wrote:
> >> >> > `!` is a generic, `if` is not. You can define an `if` that is
> >> >> > generic,
> >> >> > but this might be even more dangerous....
> >> >> >
> >> >> > ? `if` <- function(a, b, c) UseMethod("if")
> >> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> >> >> > ? `if.foo` <- function(a, b, c) FALSE
> >> >> > ? a <- structure(42, class = "foo")
> >> >> >
> >> >> > ? if (a) TRUE else FALSE
> >> >> > [1] FALSE
> >> >> >
> >> >> > ? if (1) TRUE else FALSE
> >> >> > [1] TRUE
> >> >> >
> >> >> > Gabor
> >> >> >
> >> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
> >> >> > wrote:
> >> >> >> Thanks.
> >> >> >> Can I override it for a specific class?
> >> >> >> I can do that for operators such as "!". For example, "!.fm" works
> >> >> >> for
> >> >> >> objects of the class "fm".
> >> >> >> It seems I can't do the same for "if".
> >> >> >>
> >> >> >> Best,
> >> >> >> Da
> >> >> >>
> >> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi
> >> >> >> <csardi.gabor at gmail.com>
> >> >> >> wrote:
> >> >> >>> You can. Perhaps needless to say, be careful with this.
> >> >> >>>
> >> >> >>> ? `if` <- function(...) FALSE
> >> >> >>> ? if (TRUE) TRUE else FALSE
> >> >> >>> [1] FALSE
> >> >> >>>
> >> >> >>> G.
> >> >> >>>
> >> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
> >> >> >>> wrote:
> >> >> >>>> Hello,
> >> >> >>>>
> >> >> >>>> I heard we can override almost everything in R. Is it possible
> to
> >> >> >>>> override "if" keyword in R to evaluate my own object instead of
> a
> >> >> >>>> logical value?
> >> >> >>>>
> >> >> >>>> Thanks,
> >> >> >>>> Da
> >> >> >>>>
> >> >> >>>> ______________________________________________
> >> >> >>>> R-devel at r-project.org mailing list
> >> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >> >
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Mar  6 03:59:43 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 5 Mar 2017 18:59:43 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
	<CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
	<CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>
	<CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>
Message-ID: <CAF8bMcbBd5gA7WH9Dzd0k5Vrfr70B50Jy6DVCY2ec4rEzAV9-Q@mail.gmail.com>

Da Zheng would like to override 'if' and 'while' to accept more than
scalar logicals and Martin Maechler would like to change 'if' to
accept only scalar logicals.  No one has mentioned '||' and '&&',
which also want scalar logicals.

Perhaps a solution is to have all of these call a new generic
function, as.scalar.logical() on their relevant arguments.  (For
efficiency, the default would be internally dispatched).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Mar 5, 2017 at 4:43 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Da,
>
> I've been following this thread and I'm still confused as to exactly what
> you want/why you want it.
>
> I'm probably just missing some context here, but, If() doesn't operate on
> matrices, generally. Can you give an example of the type of code you want
> to have continue to run that requires if operation *directly* on one of
> your matrix objects, as opposed, say, to a value pulled out from it, or the
> dot-product of two vectors in your system, both of which would be values
> (scalars) not matrices.
>
> Now ifelse(), is of course, a different beast altogether, and would need to
> be overloaded within your system, I imagine.
>
> Best,
> ~G
>
> On Sun, Mar 5, 2017 at 12:52 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>
>> On Sun, Mar 5, 2017 at 2:50 PM, Michael Lawrence
>> <lawrence.michael at gene.com> wrote:
>> >
>> >
>> > On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>> >>
>> >> In my case, I create a new type of matrices and override matrix
>> >> operations in R for these matrices.
>> >> My goal is to make the system as transparent as possible, which means
>> >> my system should execute the existing R code without modification.
>> >> The problem is that when data is in my own vectors or matrices, "if"
>> >> or "while" can't access their values unless we explicitly convert them
>> >> into R objects. But this means users need to modify the existing code.
>> >> So I hope I can override "if", "while", etc to access data in my own
>> >> vectors and matrices directly.
>> >> Does this sound reasonable?
>> >>
>> >
>> > Would you really need the alternate representation for scalar logicals?
>> >
>> > I can see a case in the deferred evaluation context, although it would be
>> > problematic wrt side effects unless the deferral is complete.
>> This is exactly why I want to use my own matrix objects and redefine
>> "if" for the matrices. In my framework, all matrices are read-only, so
>> there isn't side effect.
>>
>> Best,
>> Da
>> >
>> >
>> >
>> >>
>> >> Best,
>> >> Da
>> >>
>> >> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
>> >> <lawrence.michael at gene.com> wrote:
>> >> > I'm curious as to precisely why someone would want to do this.
>> >> >
>> >> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com>
>> wrote:
>> >> >>
>> >> >> I'm just curious. Why making "if" generic is even more dangerous?
>> >> >>
>> >> >> Best,
>> >> >> Da
>> >> >>
>> >> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com
>> >
>> >> >> wrote:
>> >> >> > `!` is a generic, `if` is not. You can define an `if` that is
>> >> >> > generic,
>> >> >> > but this might be even more dangerous....
>> >> >> >
>> >> >> > ? `if` <- function(a, b, c) UseMethod("if")
>> >> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
>> >> >> > ? `if.foo` <- function(a, b, c) FALSE
>> >> >> > ? a <- structure(42, class = "foo")
>> >> >> >
>> >> >> > ? if (a) TRUE else FALSE
>> >> >> > [1] FALSE
>> >> >> >
>> >> >> > ? if (1) TRUE else FALSE
>> >> >> > [1] TRUE
>> >> >> >
>> >> >> > Gabor
>> >> >> >
>> >> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
>> >> >> > wrote:
>> >> >> >> Thanks.
>> >> >> >> Can I override it for a specific class?
>> >> >> >> I can do that for operators such as "!". For example, "!.fm" works
>> >> >> >> for
>> >> >> >> objects of the class "fm".
>> >> >> >> It seems I can't do the same for "if".
>> >> >> >>
>> >> >> >> Best,
>> >> >> >> Da
>> >> >> >>
>> >> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi
>> >> >> >> <csardi.gabor at gmail.com>
>> >> >> >> wrote:
>> >> >> >>> You can. Perhaps needless to say, be careful with this.
>> >> >> >>>
>> >> >> >>> ? `if` <- function(...) FALSE
>> >> >> >>> ? if (TRUE) TRUE else FALSE
>> >> >> >>> [1] FALSE
>> >> >> >>>
>> >> >> >>> G.
>> >> >> >>>
>> >> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
>> >> >> >>> wrote:
>> >> >> >>>> Hello,
>> >> >> >>>>
>> >> >> >>>> I heard we can override almost everything in R. Is it possible
>> to
>> >> >> >>>> override "if" keyword in R to evaluate my own object instead of
>> a
>> >> >> >>>> logical value?
>> >> >> >>>>
>> >> >> >>>> Thanks,
>> >> >> >>>> Da
>> >> >> >>>>
>> >> >> >>>> ______________________________________________
>> >> >> >>>> R-devel at r-project.org mailing list
>> >> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >
>> >> >
>> >
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Mark.Bravington at data61.csiro.au  Mon Mar  6 02:09:51 2017
From: Mark.Bravington at data61.csiro.au (Mark.Bravington at data61.csiro.au)
Date: Mon, 6 Mar 2017 01:09:51 +0000
Subject: [Rd] can we override "if" in R?
In-Reply-To: <CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
	<CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
	<CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>,
	<CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>
Message-ID: <8dc1ad2781e54293b3a64670c0063510@exch1-cdc.nexus.csiro.au>

I can't comment for Da, but one example where the ability to make 'if' generic would have been desirable:

A couple of years ago I wrote S3 classes and methods for 1-byte integers and logicals stored as raw vectors, in order to handle massive amounts of genetic data (by the standards of the day). Everything worked pretty nicely, ie I could "methodize" just about everything I needed--- except if-statements, which would fail to respect eg my definitions of NA. [ The precise details elude me, but if() was untrustworthy. ]  To use 'if()',  I had to remember to "typecast", which was prone to "user error".

Whether this kind of thing is worth the "risk", is another matter. 

cheers
Mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of Gabriel Becker [gmbecker at ucdavis.edu]
Sent: 06 March 2017 11:43
To: Da Zheng
Cc: r-devel at r-project.org
Subject: Re: [Rd] can we override "if" in R?

Da,

I've been following this thread and I'm still confused as to exactly what
you want/why you want it.

I'm probably just missing some context here, but, If() doesn't operate on
matrices, generally. Can you give an example of the type of code you want
to have continue to run that requires if operation *directly* on one of
your matrix objects, as opposed, say, to a value pulled out from it, or the
dot-product of two vectors in your system, both of which would be values
(scalars) not matrices.

Now ifelse(), is of course, a different beast altogether, and would need to
be overloaded within your system, I imagine.

Best,
~G

On Sun, Mar 5, 2017 at 12:52 PM, Da Zheng <zhengda1936 at gmail.com> wrote:

> On Sun, Mar 5, 2017 at 2:50 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
> >
> >
> > On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> >>
> >> In my case, I create a new type of matrices and override matrix
> >> operations in R for these matrices.
> >> My goal is to make the system as transparent as possible, which means
> >> my system should execute the existing R code without modification.
> >> The problem is that when data is in my own vectors or matrices, "if"
> >> or "while" can't access their values unless we explicitly convert them
> >> into R objects. But this means users need to modify the existing code.
> >> So I hope I can override "if", "while", etc to access data in my own
> >> vectors and matrices directly.
> >> Does this sound reasonable?
> >>
> >
> > Would you really need the alternate representation for scalar logicals?
> >
> > I can see a case in the deferred evaluation context, although it would be
> > problematic wrt side effects unless the deferral is complete.
> This is exactly why I want to use my own matrix objects and redefine
> "if" for the matrices. In my framework, all matrices are read-only, so
> there isn't side effect.
>
> Best,
> Da
> >
> >
> >
> >>
> >> Best,
> >> Da
> >>
> >> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
> >> <lawrence.michael at gene.com> wrote:
> >> > I'm curious as to precisely why someone would want to do this.
> >> >
> >> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> >> >>
> >> >> I'm just curious. Why making "if" generic is even more dangerous?
> >> >>
> >> >> Best,
> >> >> Da
> >> >>
> >> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <csardi.gabor at gmail.com
> >
> >> >> wrote:
> >> >> > `!` is a generic, `if` is not. You can define an `if` that is
> >> >> > generic,
> >> >> > but this might be even more dangerous....
> >> >> >
> >> >> > ? `if` <- function(a, b, c) UseMethod("if")
> >> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> >> >> > ? `if.foo` <- function(a, b, c) FALSE
> >> >> > ? a <- structure(42, class = "foo")
> >> >> >
> >> >> > ? if (a) TRUE else FALSE
> >> >> > [1] FALSE
> >> >> >
> >> >> > ? if (1) TRUE else FALSE
> >> >> > [1] TRUE
> >> >> >
> >> >> > Gabor
> >> >> >
> >> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
> >> >> > wrote:
> >> >> >> Thanks.
> >> >> >> Can I override it for a specific class?
> >> >> >> I can do that for operators such as "!". For example, "!.fm" works
> >> >> >> for
> >> >> >> objects of the class "fm".
> >> >> >> It seems I can't do the same for "if".
> >> >> >>
> >> >> >> Best,
> >> >> >> Da
> >> >> >>
> >> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi
> >> >> >> <csardi.gabor at gmail.com>
> >> >> >> wrote:
> >> >> >>> You can. Perhaps needless to say, be careful with this.
> >> >> >>>
> >> >> >>> ? `if` <- function(...) FALSE
> >> >> >>> ? if (TRUE) TRUE else FALSE
> >> >> >>> [1] FALSE
> >> >> >>>
> >> >> >>> G.
> >> >> >>>
> >> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <zhengda1936 at gmail.com>
> >> >> >>> wrote:
> >> >> >>>> Hello,
> >> >> >>>>
> >> >> >>>> I heard we can override almost everything in R. Is it possible
> to
> >> >> >>>> override "if" keyword in R to evaluate my own object instead of
> a
> >> >> >>>> logical value?
> >> >> >>>>
> >> >> >>>> Thanks,
> >> >> >>>> Da
> >> >> >>>>
> >> >> >>>> ______________________________________________
> >> >> >>>> R-devel at r-project.org mailing list
> >> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >> >
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



--
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From richard.beare at gmail.com  Mon Mar  6 06:33:15 2017
From: richard.beare at gmail.com (Richard Beare)
Date: Mon, 6 Mar 2017 16:33:15 +1100
Subject: [Rd] Seeking advice regarding compilation of large libraries using
	RTools (Windows)
Message-ID: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>

Hello,

I am working on the SimpleITK package for R. This is an enormous package
that is largely automatically generated via a set of swig/json/lua magic,
and is working well under linux and osx. However we're having a lot of
trouble with the Windows side. In fact, we are struggling to get the base
libraries to build using the RTools 3.4 toolchain, even before the worrying
about the R-specific parts.

I'm hoping someone has observed and solved this problem.

The current issue is very long time (possibly infinite) linking of dlls, or
test executables. I've tried using a FAT32 file system for the build, as
suggested by some old bug reports, but still have the issue.

The build system is CMake-based, and we have the same issues with either
unix makefiles or ninja. The current build host is windows 2012 server, but
we've had the same problems on windows 7 and 10.

We're using the -Wa -mbig-obj flags.

One of the problem commands looks like this:

cd D:/B/SimpleITK-build/Code/Explicit/src && C:/Rtools/mingw_64/bin/g++.exe
-Wno-long-long -Wno-unused-local-typedefs -Wno-strict-overflow -Wextra
-Wformat=2 -Wno-format-nonliteral -Wunused -Wpointer-arith -Winvalid-pch
-Wcast-align -Wdisabled-optimization -Woverloaded-virtual -Wshadow
-Wwrite-strings -Wstrict-null-sentinel -Wno-invalid-offsetof  -Wa,-mbig-obj
-Wa,-mbig-obj  -mthreads   -mthreads -O3 -DNDEBUG   -mthreads   -mthreads
-shared -o ../../../bin/libSimpleITKExplicit-1.0.dll
-Wl,--out-implib,../../../lib/libSimpleITKExplicit-1.0.dll.a
-Wl,--major-image-version,1,--minor-image-version,0 -Wl,--whole-archive
CMakeFiles/SimpleITKExplicit.dir/objects.a -Wl,--no-whole-archive
@CMakeFiles/SimpleITKExplicit.dir/linklibs.rsp


As a guide, the final shared library is 259M on linux. The windows build
doesn't appear to be memory limited - the ld process is using about 1.5G
and consuming 1 core, but doesn't complete given an entire day.

Any suggestions on where to turn next? Are cross compilers the next step?

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Mar  6 10:50:12 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 6 Mar 2017 10:50:12 +0100
Subject: [Rd] Please add me to bugzilla
In-Reply-To: <CACCRr6GzeBhOQMNKwNRMwkirP3BH2SXnrim=fRM6Ydryds=Ang@mail.gmail.com>
References: <CACCRr6GzeBhOQMNKwNRMwkirP3BH2SXnrim=fRM6Ydryds=Ang@mail.gmail.com>
Message-ID: <22717.12500.568807.583249@stat.math.ethz.ch>

>>>>> Bradley Broom <bmbroom at gmail.com>
>>>>>     on Sun, 5 Mar 2017 16:03:30 -0600 writes:

    > Please add me to R bugzilla.  Thanks, Bradley

Well, I will not do it just like that (mean "after such a
minimal message").

I don't see any evidence as to your credentials, knowledge of R,
etc, as part of this request.  We are all professionals,
devoting part of our (work and free) time to the R project
(rather than employees of the company you paid to serve you ...)

It may be that you have read   https://www.r-project.org/bugs.html

Notably this part

--> NOTE: due to abuse by spammers, since 2016-07-09 only users who have previously submitted bugs can submit new ones on R?s Bugzilla. We?re working on a better system? In the mean time, post (e-mail) to R-devel or ask an R Core member to add you manually to R?s Bugzilla members.

The last sentence was *meant* to say you should post (possibly
parts, ideally a minimal reproducible example of) your bug
report to R-devel so others could comment on it, agree or
disagree with your assessment etc,
__or__ ask an R-core member to add you to bugzilla (if you really read the
other parts of the 'R bugs' web page above).

Posting to all 1000 R-devel readers with no content about what
you consider a bug  is a waste of bandwidth for at least 99% of
these readers.

[Yes, I'm also using their time ... in the hope to *improve* the
 quality of future such postings].

Martin Maechler
ETH Zurich


From jeroenooms at gmail.com  Mon Mar  6 11:51:53 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 6 Mar 2017 11:51:53 +0100
Subject: [Rd] Seeking advice regarding compilation of large libraries
 using RTools (Windows)
In-Reply-To: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>
References: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>
Message-ID: <CABFfbXs2s0TfEC1kx+VyFc3yG22Vrc2pOBgMOd36WTLcPSA6AQ@mail.gmail.com>

On Mon, Mar 6, 2017 at 6:33 AM, Richard Beare <richard.beare at gmail.com> wrote:
> I am working on the SimpleITK package for R. This is an enormous package
> that is largely automatically generated via a set of swig/json/lua magic,
> and is working well under linux and osx.

Is it available somewhere so we can try it?


> However we're having a lot of trouble with the Windows side. In fact, we are struggling to get the base libraries to build using the RTools 3.4 toolchain, even before the worrying about the R-specific parts.

What build environment do you use? The version of gcc with Rtools
should be ok, but the Rtools build utilities in the "bin" folder (in
particular 'make') are old and a frequent source of problems. However
for building external libs you can use other tools, for example those
from msys2. Just make sure you use gcc/g++ from Rtools.


> The current issue is very long time (possibly infinite) linking of dlls, or
> test executables. I've tried using a FAT32 file system for the build, as
> suggested by some old bug reports, but still have the issue.

On Windows you can avoid the run-time dll mess by building static libs
of external libraries. See rwinlib for examples:
https://github.com/rwinlib


> Any suggestions on where to turn next? Are cross compilers the next step?

Try building with msys2, but make sure to use gcc/g++ from Rtools by
setting the `CC` and `CXX` variables in the configure script. Cross
compiling will make things even more complicated because binaries
might not be compatible if your cross compiler has a different version
of gcc or has been configured for another exception model (seh/drawf).


From maechler at stat.math.ethz.ch  Mon Mar  6 13:51:31 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 6 Mar 2017 13:51:31 +0100
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
	<22715.7625.79979.272007@stat.math.ethz.ch>
	<CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
Message-ID: <22717.23379.425969.881644@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Sat, 4 Mar 2017 12:20:45 -0800 writes:

    > Is there really a need for these complications? Packages
    > emitting this warning are broken by definition and should be fixed. 

I agree and probably Henrik, too.

(Others may disagree to some extent .. and find it convenient
 that R does translate 'if(x)'  to  'if(x[1])'  for them albeit
 with a warning .. )

    > Perhaps we could "flip the switch" in a test
    > environment and see how much havoc is wreaked and whether
    > authors are sufficiently responsive?

    > Michael

As we have > 10'000 packages on CRAN alonce,  and people have
started (mis)using suppressWarnings(.) in many places,  there
may be considerably more packages affected than we optimistically assume...

As R core member who would  "flip the switch"  I'd typically then
have to be the one sending an e-mail to all package maintainers
affected.... and in this case I'm very reluctant to volunteer
for that and so, I'd prefer the environment variable where R
core and others can decide how to use it .. for a while .. until
the flip is switched for all.

or have I overlooked an issue?

Martin

    > On Sat, Mar 4, 2017 at 12:04 PM, Martin Maechler
    > <maechler at stat.math.ethz.ch
    >> wrote:

    >> >>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> >>>>>
    >> on Fri, 3 Mar 2017 10:10:53 -0800 writes:
    >> 
    >> > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham >
    >> <h.wickham at gmail.com> wrote: >>> But, how you propose a
    >> warning-to-error transition >>> should be made without
    >> wreaking havoc?  Just flip the >>> switch in R-devel and
    >> see CRAN and Bioconductor packages >>> break overnight?
    >> Particularly Bioconductor devel might >>> become
    >> non-functional (since at times it requires >>> R-devel).
    >> For my own code / packages, I would be able >>> to handle
    >> such a change, but I'm completely out of >>> control if
    >> one of the package I'm depending on does not >>> provide
    >> a quick fix (with the only option to remove >>> package
    >> tests for those dependencies).
    >> >>
    >> >> Generally, a package can not be on CRAN if it has any
    >> >> warnings, so I don't think this change would have any
    >> >> impact on CRAN packages.  Isn't this also true for >>
    >> bioconductor?
    >> 
    >> > Having a tests/warn.R file with:
    >> 
    >> > warning("boom")
    >> 
    >> > passes through R CMD check --as-cran unnoticed.
    >> 
    >> Yes, indeed.. you are right Henrik that many/most R
    >> warning()s would not produce R CMD check 'WARNING's ..
    >> 
    >> I think Hadley and I fell into the same mental pit of
    >> concluding that such warning()s from
    >> if(<length-larger-one>) ...  would not currently happen
    >> in CRAN / Bioc packages and hence turning them to errors
    >> would not have a direct effect.
    >> 
    >> With your 2nd e-mail of saying that you'd propose such an
    >> option only for a few releases of R you've indeed
    >> clarified your intent to me.  OTOH, I would prefer using
    >> an environment variable (as you've proposed as an
    >> alternative) which is turned "active" at the beginning
    >> only manually or for the "CRAN incoming" checks of the
    >> CRAN team (and bioconductor submission checks?)  and
    >> later for '--as-cran' etc until it eventually becomes the
    >> unconditional behavior of R (and the env.variable is no
    >> longer used).
    >> 
    >> Martin
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > 	[[alternative HTML version deleted]]


From bmbroom at gmail.com  Mon Mar  6 13:55:35 2017
From: bmbroom at gmail.com (Bradley Broom)
Date: Mon, 6 Mar 2017 06:55:35 -0600
Subject: [Rd] Please add me to bugzilla
In-Reply-To: <22717.12500.568807.583249@stat.math.ethz.ch>
References: <CACCRr6GzeBhOQMNKwNRMwkirP3BH2SXnrim=fRM6Ydryds=Ang@mail.gmail.com>
	<22717.12500.568807.583249@stat.math.ethz.ch>
Message-ID: <CACCRr6HKe-Niv6v_DqFmGvwj5DDQY+sYXQM=BMYRMRtNwbNnzQ@mail.gmail.com>

Apologies, I thought I was following exactly that sentence and trying to
make a minimal post that would waste as little developer bandwidth as
possible given the lack of a better system.

Anyway, I have been using R for like forever (20 years).

In my current project, I have run into problems with stack overflows in R's
dendrogram code when trying to use either str() or as.hclust() on very deep
dendrograms.

To duplicate, use this function from tests/reg-tests-1c.R in the R source
code:
mkDend <- function(n, lab, method = "complete",
                   ## gives *ties* often:
                   rGen = function(n) 1+round(16*abs(rnorm(n)))) {
    stopifnot(is.numeric(n), length(n) == 1, n >= 1, is.character(lab))
    a <- matrix(rGen(n*n), n, n)
    colnames(a) <- rownames(a) <- paste0(lab, 1:n)
    .HC. <<- hclust(as.dist(a + t(a)), method=method)
    as.dendrogram(.HC.)
}

Get a nasty dendrogram:

de <- mkDend(2000, 'x', 'single')

1st bug:
sink('somefile.txt'); str(de); sink();

What happens:
Error in getOption("OutDec") : node stack overflow

Also, the last call to sink() isn't executed because of the error, so
you'll need to call sink() after the error to clear the diversion.

What should happen:
Function completes without a stack overflow.

2nd bug:
hh <- as.hclust(de)

What happens:
Error: C stack usage  7971248 is too close to the limit

What should happen:
Function completes without a stack overflow.

A knowledgeable user might be able to increase R's limits to avoid these
errors on this particular dendrogram, but a) my users aren't that
knowledgeable about R and this is expected to be a common problem, and b)
there will be bigger dendrograms (up to at least 25000 leaves).

Please see attached patch for non-recursive implementations.

Regards,
Bradley



On Mon, Mar 6, 2017 at 3:50 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Bradley Broom <bmbroom at gmail.com>
> >>>>>     on Sun, 5 Mar 2017 16:03:30 -0600 writes:
>
>     > Please add me to R bugzilla.  Thanks, Bradley
>
> Well, I will not do it just like that (mean "after such a
> minimal message").
>
> I don't see any evidence as to your credentials, knowledge of R,
> etc, as part of this request.  We are all professionals,
> devoting part of our (work and free) time to the R project
> (rather than employees of the company you paid to serve you ...)
>
> It may be that you have read   https://www.r-project.org/bugs.html
>
> Notably this part
>
> --> NOTE: due to abuse by spammers, since 2016-07-09 only users who have
> previously submitted bugs can submit new ones on R?s Bugzilla. We?re
> working on a better system? In the mean time, post (e-mail) to R-devel or
> ask an R Core member to add you manually to R?s Bugzilla members.
>
> The last sentence was *meant* to say you should post (possibly
> parts, ideally a minimal reproducible example of) your bug
> report to R-devel so others could comment on it, agree or
> disagree with your assessment etc,
> __or__ ask an R-core member to add you to bugzilla (if you really read the
> other parts of the 'R bugs' web page above).
>
> Posting to all 1000 R-devel readers with no content about what
> you consider a bug  is a waste of bandwidth for at least 99% of
> these readers.
>
> [Yes, I'm also using their time ... in the hope to *improve* the
>  quality of future such postings].
>
> Martin Maechler
> ETH Zurich
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: R-devel.patch
Type: text/x-patch
Size: 10675 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170306/1820a81c/attachment.bin>

From maechler at stat.math.ethz.ch  Mon Mar  6 14:54:57 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 6 Mar 2017 14:54:57 +0100
Subject: [Rd] Please add me to bugzilla
In-Reply-To: <CACCRr6HKe-Niv6v_DqFmGvwj5DDQY+sYXQM=BMYRMRtNwbNnzQ@mail.gmail.com>
References: <CACCRr6GzeBhOQMNKwNRMwkirP3BH2SXnrim=fRM6Ydryds=Ang@mail.gmail.com>
	<22717.12500.568807.583249@stat.math.ethz.ch>
	<CACCRr6HKe-Niv6v_DqFmGvwj5DDQY+sYXQM=BMYRMRtNwbNnzQ@mail.gmail.com>
Message-ID: <22717.27185.536798.198647@stat.math.ethz.ch>

>>>>> Bradley Broom <bmbroom at gmail.com>
>>>>>     on Mon, 6 Mar 2017 06:55:35 -0600 writes:

    > Apologies, I thought I was following exactly that sentence
    > and trying to make a minimal post that would waste as
    > little developer bandwidth as possible given the lack of a
    > better system.

I understand.   My apologies now, as I was mistrusting, clearly
wrongly in this case.

    > Anyway, I have been using R for like forever (20 years).

    > In my current project, I have run into problems with stack
    > overflows in R's dendrogram code when trying to use either
    > str() or as.hclust() on very deep dendrograms.

I understand.  Indeed, bug PR#16424 
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16424
encountered the same problem in other dendrogram functions and
solved it by re-programming the relevant parts non-recursively,
too.

   [.............]	

    > What should happen: Function completes without a stack
    > overflow.

    > 2nd bug: hh <- as.hclust(de)

    > What happens: Error: C stack usage 7971248 is too close to the limit

    > What should happen: Function completes without a stack
    > overflow.

    > A knowledgeable user might be able to increase R's limits
    > to avoid these errors on this particular dendrogram, but
    > a) my users aren't that knowledgeable about R and this is
    > expected to be a common problem, and b) there will be
    > bigger dendrograms (up to at least 25000 leaves).

Agreed.  The current help pages warns about the problem and
gives advice (related to increasing the stack), but what you propose
is better, i.e., re-implementing relevant parts non-recursively.

    > Please see attached patch for non-recursive
    > implementations.

Very well done, thank you a lot!
[and I will add you to bugzilla .. so you can use it for the
 next bug .. ;-)]

Best,
Martin

    > Regards, Bradley



    > On Mon, Mar 6, 2017 at 3:50 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:

    >> >>>>> Bradley Broom <bmbroom at gmail.com> >>>>> on Sun, 5
    >> Mar 2017 16:03:30 -0600 writes:
    >> 
    >> > Please add me to R bugzilla.  Thanks, Bradley
    >> 
    >> Well, I will not do it just like that (mean "after such a
    >> minimal message").
    >> 
    >> I don't see any evidence as to your credentials,
    >> knowledge of R, etc, as part of this request.  We are all
    >> professionals, devoting part of our (work and free) time
    >> to the R project (rather than employees of the company
    >> you paid to serve you ...)
    >> 
    >> It may be that you have read
    >> https://www.r-project.org/bugs.html
    >> 
    >> Notably this part
    >> 
    --> NOTE: due to abuse by spammers, since 2016-07-09 only
    --> users who have
    >> previously submitted bugs can submit new ones on R?s
    >> Bugzilla. We?re working on a better system? In the mean
    >> time, post (e-mail) to R-devel or ask an R Core member to
    >> add you manually to R?s Bugzilla members.
    >> 
    >> The last sentence was *meant* to say you should post
    >> (possibly parts, ideally a minimal reproducible example
    >> of) your bug report to R-devel so others could comment on
    >> it, agree or disagree with your assessment etc, __or__
    >> ask an R-core member to add you to bugzilla (if you
    >> really read the other parts of the 'R bugs' web page
    >> above).
    >> 
    >> Posting to all 1000 R-devel readers with no content about
    >> what you consider a bug is a waste of bandwidth for at
    >> least 99% of these readers.
    >> 
    >> [Yes, I'm also using their time ... in the hope to
    >> *improve* the quality of future such postings].
    >> 
    >> Martin Maechler ETH Zurich
    >> 
    > x external: dendro-non-recursive.patch text/x-patch, u
    > [Click mouse-2 to display text]


From richard.beare at gmail.com  Mon Mar  6 21:21:51 2017
From: richard.beare at gmail.com (Richard Beare)
Date: Tue, 7 Mar 2017 07:21:51 +1100
Subject: [Rd] Seeking advice regarding compilation of large libraries
 using RTools (Windows)
In-Reply-To: <CABFfbXs2s0TfEC1kx+VyFc3yG22Vrc2pOBgMOd36WTLcPSA6AQ@mail.gmail.com>
References: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>
	<CABFfbXs2s0TfEC1kx+VyFc3yG22Vrc2pOBgMOd36WTLcPSA6AQ@mail.gmail.com>
Message-ID: <CA+V7QS990wTd_odPb1+=C9ntoBQVthjX-cNpLC75UDE7rS2QXQ@mail.gmail.com>

Yep - simpleITK is available at github.com/SimpleITK/SimpleITK. There's
also github.com/SimpleITK/SimpleITKRInstaller - a devtools based installer
for mac and linux.

CMake has a range of build environments. I experimented with MSYS2 and
mingw makefiles, but had trouble with incompatibilities in the path
required by CMake and those options - from memory the sh in RTools/bin
caused problems. Although it sounds like you are saying it is necessary to
install the MSYS2 system as well.

The unix makefile option for CMake appears to work well until the linking
stage. Ninja has problems at a similar stage.

I'll steer clear of dll's, as you suggest. I'm checking those links for
compiler/links flags to see if we're missing anything

Thanks



On Mon, Mar 6, 2017 at 9:51 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> On Mon, Mar 6, 2017 at 6:33 AM, Richard Beare <richard.beare at gmail.com>
> wrote:
> > I am working on the SimpleITK package for R. This is an enormous package
> > that is largely automatically generated via a set of swig/json/lua magic,
> > and is working well under linux and osx.
>
> Is it available somewhere so we can try it?
>
>
> > However we're having a lot of trouble with the Windows side. In fact, we
> are struggling to get the base libraries to build using the RTools 3.4
> toolchain, even before the worrying about the R-specific parts.
>
> What build environment do you use? The version of gcc with Rtools
> should be ok, but the Rtools build utilities in the "bin" folder (in
> particular 'make') are old and a frequent source of problems. However
> for building external libs you can use other tools, for example those
> from msys2. Just make sure you use gcc/g++ from Rtools.
>
>
> > The current issue is very long time (possibly infinite) linking of dlls,
> or
> > test executables. I've tried using a FAT32 file system for the build, as
> > suggested by some old bug reports, but still have the issue.
>
> On Windows you can avoid the run-time dll mess by building static libs
> of external libraries. See rwinlib for examples:
> https://github.com/rwinlib
>
>
> > Any suggestions on where to turn next? Are cross compilers the next step?
>
> Try building with msys2, but make sure to use gcc/g++ from Rtools by
> setting the `CC` and `CXX` variables in the configure script. Cross
> compiling will make things even more complicated because binaries
> might not be compatible if your cross compiler has a different version
> of gcc or has been configured for another exception model (seh/drawf).
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Mon Mar  6 23:41:55 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 6 Mar 2017 14:41:55 -0800
Subject: [Rd] can we override "if" in R?
In-Reply-To: <8dc1ad2781e54293b3a64670c0063510@exch1-cdc.nexus.csiro.au>
References: <CAFLer83hbY+3QEfoukAmt4Hy77P5=NyW3a+pyigV0CJVjzjYdA@mail.gmail.com>
	<CABtg=KkmsPVZc0Y-Rru5+DkzLHabrkVDOZWcip5jhYHD-D4HZg@mail.gmail.com>
	<CAFLer83OTdZQq+=Uj5g7fqmph8-FWwa7pFSMmz_dhcKhs8DuCA@mail.gmail.com>
	<CABtg=Kn83hAzBGyJkVrWciAYadJDsT2GmLPY4OF2_o30cxG1Ww@mail.gmail.com>
	<CAFLer83n1uv_14fLBYg78CkAKiEUsMjeSXObto7gSyS+0TTfpA@mail.gmail.com>
	<CAOQ5Nyeyy60U+q0fp9M_QyrQRkb6ynNMzWzWgUWXxVXFzGUVJQ@mail.gmail.com>
	<CAFLer82zMrfL5cQH78QAkKJf+2GU=JGnU4ScsE6MCOobDoxetw@mail.gmail.com>
	<CAOQ5Nyc87Vd+khdNw4ha0QRJKUVHsXWNoQJZmS6AKYjkZvbWPw@mail.gmail.com>
	<CAFLer81k=T-ukKKDFb5f7y1Ay4WFmmf0zzeORLom58X6TkMG4w@mail.gmail.com>
	<CADwqtCPSOEjOkENpGtW6ywwXNH2gVpifv1EJEE7zYCtotWXCRg@mail.gmail.com>
	<8dc1ad2781e54293b3a64670c0063510@exch1-cdc.nexus.csiro.au>
Message-ID: <CADwqtCOt5OmmXbC131qzhe=ZXiV2h8eKoBFtMsjgjbMM_p3d1g@mail.gmail.com>

Mark,

I do understand this desire, though notably, if selecting a single element
from one of these custom vectors gave you a normal value, if would be safe,
right? e.g. if the [ method, etc checked if the index length is one, and
returned the non-compressed value if it was, as an off-the-cuff possibility.

Also, I do feel compelled to say that I'm working with R-core (Luke Tierney
primarily) on low-level support for this kind of data-storage abstraction
that would let you create custom vector/matrix storage mechanisms that
still behave themselves as atomic vectors. See
https://www.r-project.org/dsc/2016/slides/customvectors.html for my initial
pitch and https://svn.r-project.org/R/branches/ALTREP/
<https://svn.r-project.org/R/branches/ALTREP/> for the work-in-progress
branch. We hope to merge that in after the release of 3.4, but there's no
firm date as some work on our part and discussion amongst r-core remains
before it can happen.

So in the future, I hope you'll be able to do this in ways that R sees as
actual atomic vectors. They do have to be define in C-code currently,
though.

~G

On Sun, Mar 5, 2017 at 5:09 PM, <Mark.Bravington at data61.csiro.au> wrote:

> I can't comment for Da, but one example where the ability to make 'if'
> generic would have been desirable:
>
> A couple of years ago I wrote S3 classes and methods for 1-byte integers
> and logicals stored as raw vectors, in order to handle massive amounts of
> genetic data (by the standards of the day). Everything worked pretty
> nicely, ie I could "methodize" just about everything I needed--- except
> if-statements, which would fail to respect eg my definitions of NA. [ The
> precise details elude me, but if() was untrustworthy. ]  To use 'if()',  I
> had to remember to "typecast", which was prone to "user error".
>
> Whether this kind of thing is worth the "risk", is another matter.
>
> cheers
> Mark
>
> Mark Bravington
> CSIRO Marine Lab
> Hobart
> Australia
>
> ________________________________________
> From: R-devel [r-devel-bounces at r-project.org] on behalf of Gabriel Becker
> [gmbecker at ucdavis.edu]
> Sent: 06 March 2017 11:43
> To: Da Zheng
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] can we override "if" in R?
>
> Da,
>
> I've been following this thread and I'm still confused as to exactly what
> you want/why you want it.
>
> I'm probably just missing some context here, but, If() doesn't operate on
> matrices, generally. Can you give an example of the type of code you want
> to have continue to run that requires if operation *directly* on one of
> your matrix objects, as opposed, say, to a value pulled out from it, or the
> dot-product of two vectors in your system, both of which would be values
> (scalars) not matrices.
>
> Now ifelse(), is of course, a different beast altogether, and would need to
> be overloaded within your system, I imagine.
>
> Best,
> ~G
>
> On Sun, Mar 5, 2017 at 12:52 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
>
> > On Sun, Mar 5, 2017 at 2:50 PM, Michael Lawrence
> > <lawrence.michael at gene.com> wrote:
> > >
> > >
> > > On Sat, Mar 4, 2017 at 12:36 PM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> > >>
> > >> In my case, I create a new type of matrices and override matrix
> > >> operations in R for these matrices.
> > >> My goal is to make the system as transparent as possible, which means
> > >> my system should execute the existing R code without modification.
> > >> The problem is that when data is in my own vectors or matrices, "if"
> > >> or "while" can't access their values unless we explicitly convert them
> > >> into R objects. But this means users need to modify the existing code.
> > >> So I hope I can override "if", "while", etc to access data in my own
> > >> vectors and matrices directly.
> > >> Does this sound reasonable?
> > >>
> > >
> > > Would you really need the alternate representation for scalar logicals?
> > >
> > > I can see a case in the deferred evaluation context, although it would
> be
> > > problematic wrt side effects unless the deferral is complete.
> > This is exactly why I want to use my own matrix objects and redefine
> > "if" for the matrices. In my framework, all matrices are read-only, so
> > there isn't side effect.
> >
> > Best,
> > Da
> > >
> > >
> > >
> > >>
> > >> Best,
> > >> Da
> > >>
> > >> On Sat, Mar 4, 2017 at 3:22 PM, Michael Lawrence
> > >> <lawrence.michael at gene.com> wrote:
> > >> > I'm curious as to precisely why someone would want to do this.
> > >> >
> > >> > On Sat, Mar 4, 2017 at 11:49 AM, Da Zheng <zhengda1936 at gmail.com>
> > wrote:
> > >> >>
> > >> >> I'm just curious. Why making "if" generic is even more dangerous?
> > >> >>
> > >> >> Best,
> > >> >> Da
> > >> >>
> > >> >> On Sat, Mar 4, 2017 at 1:22 PM, G?bor Cs?rdi <
> csardi.gabor at gmail.com
> > >
> > >> >> wrote:
> > >> >> > `!` is a generic, `if` is not. You can define an `if` that is
> > >> >> > generic,
> > >> >> > but this might be even more dangerous....
> > >> >> >
> > >> >> > ? `if` <- function(a, b, c) UseMethod("if")
> > >> >> > ? `if.default` <- function(a,b,c) base::`if`(a, b, c)
> > >> >> > ? `if.foo` <- function(a, b, c) FALSE
> > >> >> > ? a <- structure(42, class = "foo")
> > >> >> >
> > >> >> > ? if (a) TRUE else FALSE
> > >> >> > [1] FALSE
> > >> >> >
> > >> >> > ? if (1) TRUE else FALSE
> > >> >> > [1] TRUE
> > >> >> >
> > >> >> > Gabor
> > >> >> >
> > >> >> > On Sat, Mar 4, 2017 at 5:47 PM, Da Zheng <zhengda1936 at gmail.com>
> > >> >> > wrote:
> > >> >> >> Thanks.
> > >> >> >> Can I override it for a specific class?
> > >> >> >> I can do that for operators such as "!". For example, "!.fm"
> works
> > >> >> >> for
> > >> >> >> objects of the class "fm".
> > >> >> >> It seems I can't do the same for "if".
> > >> >> >>
> > >> >> >> Best,
> > >> >> >> Da
> > >> >> >>
> > >> >> >> On Sat, Mar 4, 2017 at 12:41 PM, G?bor Cs?rdi
> > >> >> >> <csardi.gabor at gmail.com>
> > >> >> >> wrote:
> > >> >> >>> You can. Perhaps needless to say, be careful with this.
> > >> >> >>>
> > >> >> >>> ? `if` <- function(...) FALSE
> > >> >> >>> ? if (TRUE) TRUE else FALSE
> > >> >> >>> [1] FALSE
> > >> >> >>>
> > >> >> >>> G.
> > >> >> >>>
> > >> >> >>> On Sat, Mar 4, 2017 at 5:36 PM, Da Zheng <
> zhengda1936 at gmail.com>
> > >> >> >>> wrote:
> > >> >> >>>> Hello,
> > >> >> >>>>
> > >> >> >>>> I heard we can override almost everything in R. Is it possible
> > to
> > >> >> >>>> override "if" keyword in R to evaluate my own object instead
> of
> > a
> > >> >> >>>> logical value?
> > >> >> >>>>
> > >> >> >>>> Thanks,
> > >> >> >>>> Da
> > >> >> >>>>
> > >> >> >>>> ______________________________________________
> > >> >> >>>> R-devel at r-project.org mailing list
> > >> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >> >>
> > >> >> ______________________________________________
> > >> >> R-devel at r-project.org mailing list
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >> >
> > >> >
> > >
> > >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From francisco.mauro at oregonstate.edu  Tue Mar  7 03:13:02 2017
From: francisco.mauro at oregonstate.edu (Francisco Mauro)
Date: Mon, 6 Mar 2017 18:13:02 -0800
Subject: [Rd] Potential clue for Bug 16975 - lme fixed sigma - inconsistent
	REML estimation
Message-ID: <CAHqPoOk9Y4FeaKkx+5fF3spcr1VrtU-gqs=H2MYXhcxC3TNoYw@mail.gmail.com>

Dear list,

I was trying to create a VarClass for nlme to work with Fay-Herriot
(FH) models. The idea was to create a modification of VarComb that
instead of multiplying the variance functions made their sum (I called
it varSum). After some fails etc... I found that the I was not getting
the expected results because I needed to make sigma fixed. Trying to
find how to make sigma fixed I run into this bug (with uconfirmed
status but listed) report

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16975

The ideas they propose make unnecessary the use of the variance
function I was thinking of, and I left my idea aside for a couple
days. I recently tried the variance function I mentioned before and I
got estimates that were consistent with those provided by the packages
sae and metafor and with the s-plus version of nlme.

The way of fitting a FH model proposed by Maciej in the bug report is
different to the way I fitted the model using the additive variance
function varSum. Both formulations lead to a similar distribution of
the response. However, Maciej's formulation adds the unknown variance
component as a random effect and the formulation with the additive
varClass treat this variance as a variance of an error component.

Results using varSum are the same as those provided by packages sae
and metafor, while the alternative proposed by Maciej does not fit
with those two packages, which is the subject of the bug mentioned
above. Considering this and the fact that the bug is active I thought
that this example (below) could be helpful and provide some clues to
figure out what is the problem with the bug.

I'm not sure about what way would be better to fit models like the FH
model. I find Maciej's solution more flexible for several things than
the route I was taking, but the reported bug made me loose some
confidence. I believe that information about the bug 16975 can be very
interesting. I hope the example below can help or provide some clues.

Thanks

Paco Mauro

# TODO: Add comment
#
# Author: Paco
###############################################################################
sessionInfo()
#R version 3.3.2 (2016-10-31)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows 10 x64 (build 14393)
#
#locale:
#  [1] LC_COLLATE=English_United States.1252
#[2] LC_CTYPE=English_United States.1252
#[3] LC_MONETARY=English_United States.1252
#[4] LC_NUMERIC=C
#[5] LC_TIME=English_United States.1252
#
#attached base packages:
#  [1] stats     graphics  grDevices utils     datasets  methods   base
#
#other attached packages:
#  [1] sae_1.1      MASS_7.3-45  nlme_3.1-131 rj_2.0.5-2
#
#loaded via a namespace (and not attached):
#  [1] tools_3.3.2     grid_3.3.2      lattice_0.20-34

#Package: nlme
#Version: 3.1-131
library(nlme)
library(sae)
####* varSum, a modification of varComb to make the combination
additive instead of multiplicative
varSum <-
  ## constructor for the varSum class
  function(...)
{
 val <- list(...)
 if (!all(unlist(lapply(val, inherits, "varFunc")))) {
  stop("all arguments to 'varSum' must be of class \"varFunc\".")
 }
 if (is.null(names(val))) {
  names(val) <- LETTERS[seq_along(val)]
 }
 class(val) <- c("varSum","varComb", "varFunc")
 val
}
varWeights.varSum <-
  function(object)
{
 apply(as.data.frame(lapply(object, varWeights)), 1, function(x){

    1/sqrt(sum((1/x)^2))

   })
}
Initialize.varSum <-
  function(object, data, ...)
{
 val <- lapply(object, Initialize, data)
 attr(val, "plen") <- unlist(lapply(val, function(el) length(coef(el))))
 class(val) <- c("varSum","varComb", "varFunc")
 val
}
logLik.varSum <-
  function(object, ...)
{
 lls <- lapply(object, logLik)

 lls2 <- apply(as.data.frame(lapply(object, varWeights)), 1, function(x){

    1/sqrt(sum((1/x)^2))

   })

 val <- sum(log(lls2))
 attr(val, "df") <- sum(unlist(lapply(lls, attr, "df")))
 class(val) <- "logLik"
 val
}

####* The methods from here to the example are just copies of the
varComb methods with different names
coef.varSum <-
  function(object, unconstrained = TRUE, allCoef = FALSE, ...)
{
 unlist(lapply(object, coef, unconstrained, allCoef))
}

"coef<-.varSum" <-
  function(object, ..., value)
{
 plen <- attr(object, "plen")
 if ((len <- sum(plen)) > 0) {  # varying parameters
  if (length(value) != len) {
   stop("cannot change parameter length of initialized \"varSum\" object")
  }
  start <- 0
  for (i in seq_along(object)) {
   if (plen[i] > 0) {
    coef(object[[i]]) <- value[start + (1:plen[i])]
    start <- start + plen[i]
   }
  }
 }
 object
}
formula.varSum <-
  function(x, ...) lapply(x, formula)
needUpdate.varSum <-
  function(object) any(unlist(lapply(object, needUpdate)))

print.varSum <-
  function(x, ...)
{
 cat("Sum of:\n")
 lapply(x, print)
 invisible(x)
}

print.summary.varSum <-
  function(x, ...)
{
 cat(attr(x, "structName"),"\n")
 lapply(x, print, FALSE)
 invisible(x)
}

summary.varSum <-
  function(object, structName = "Sum of variance functions:", ...)
{
 object[] <- lapply(object, summary)
 attr(object, "structName") <- structName
 class(object) <- c("summary.varSum", class(object))
 object
}

update.varSum <-
  function(object, data, ...)
{
 object[] <- lapply(object, update, data)
 object
}

###############################################################################
# Example bug report 16975
###############################################################################
data(milk)
milk$var<-milk$SD^2
#Fay-Herriot model using sae library
attach(milk)
resultREML <- eblupFH(yi ~ as.factor(MajorArea), SD^2)
resultREML
detach(milk)
# $fit
# $fit$method
# [1] "REML"
#
# $fit$convergence
# [1] TRUE
#
# $fit$iterations
# [1] 4
#
# $fit$estcoef
# beta  std.error    tvalue       pvalue
# (Intercept)            0.9681890 0.06936208 13.958476 2.793443e-44
# as.factor(MajorArea)2  0.1327801 0.10300072  1.289119 1.973569e-01
# as.factor(MajorArea)3  0.2269462 0.09232981  2.457995 1.397151e-02
# as.factor(MajorArea)4 -0.2413011 0.08161707 -2.956503 3.111496e-03
#
# $fit$refvar
# [1] 0.01855022
#
# $fit$goodness
# loglike        AIC        BIC        KIC       AICc      AICb1      AICb2
# 12.677478 -15.354956  -6.548956 -10.354956         NA         NA         NA
# KICc      KICb1      KICb2 nBootstrap
# NA         NA         NA   0.000000

#Bug 16975 report fitting of FH model proposed by Maciej Beresewicz
FH<-lme(yi ~ as.factor(MajorArea),random=~1|as.factor(SmallArea),
  data=milk,weights=varFixed(~var),
  control=lmeControl(sigma = 1,tolerance = 1e-4))
FH
# Linear mixed-effects model fit by REML
# Data: milk
# Log-restricted-likelihood: 10.34588
# Fixed: yi ~ as.factor(MajorArea)
# (Intercept) as.factor(MajorArea)2 as.factor(MajorArea)3
# 0.9680768             0.1316132             0.2269008
# as.factor(MajorArea)4
# -0.2415905
#
# Random effects:
#   Formula: ~1 | as.factor(SmallArea)
# (Intercept) Residual
# StdDev:   0.1332918        1
#
# Variance function:
#   Structure: fixed weights
# Formula: ~var
# Number of Observations: 43
# Number of Groups: 43
#Fay-Herriot model fitted using the variance function varSum defined above
 #A columns of zeros is added to tweak the varConstPower component
milk$zero<-0
FH2<-gls(yi ~ as.factor(MajorArea),data=milk,
  weights=varSum(varConstPower(1,1,~zero,fixed=list(power=1)),varFixed(~var)),
  control=lmeControl(sigma = 1))
FH2
# Generalized least squares fit by REML
# Model: yi ~ as.factor(MajorArea)
# Data: milk
# Log-restricted-likelihood: 5.165619
#
# Coefficients:
#   (Intercept) as.factor(MajorArea)2 as.factor(MajorArea)3
# 0.9681890             0.1327803             0.2269462
# as.factor(MajorArea)4
# -0.2413010
#
# Sum of variance functions:
#   Structure: Constant plus power of variance covariate
# Formula: ~zero
# Parameter estimates:
#   const     power
# 0.1361995 1.0000000
# Variance function:
#   Structure: fixed weights
# Formula: ~var
# Degrees of freedom: 43 total; 39 residual
# Residual standard error: 1


From radford at cs.toronto.edu  Tue Mar  7 03:47:54 2017
From: radford at cs.toronto.edu (Radford Neal)
Date: Mon, 6 Mar 2017 21:47:54 -0500
Subject: [Rd] length(unclass(x)) without unclass(x)?
Message-ID: <20170307024754.GA22311@mail.cs.toronto.edu>

> Henrik Bengtsson:
>
> I'm looking for a way to get the length of an object 'x' as given by
> base data type without dispatching on class.


The performance improvement you're looking for is implemented in the
latest version of pqR (pqR-2016-10-24, see pqR-project.org), along
with corresponding improvements in several other circumstances where
unclass(x) does not create a copy of x.

Here are some examples (starting with yours), using pqR's Rprofmemt
function to get convenient traces of memory allocations:

  > Rprofmemt(nelem=1000)  # trace allocations of vectors with >= 1000 elements
  > 
  > x <- structure(double(1e6), class = c("foo", "numeric"))
  RPROFMEM: 8000040 (double 1000000):"double" "structure" 
  RPROFMEM: 8000040 (double 1000000):"structure" 
  > length.foo <- function(x) 1L
  > length(x)
  [1] 1
  > length(unclass(x))
  [1] 1000000
  > 
  > `+.foo` <- function (e1, e2) (unclass(e1) + unclass(e2)) %% 100
  > z <- x + x
  RPROFMEM: 8000040 (double 1000000):"+.foo" 
  > 
  > `<.foo` <- function (e1, e2) any(unclass(e1)<unclass(e2))
  > x<x
  [1] FALSE
  > 
  > y <- unclass(x)
  RPROFMEM: 8000040 (double 1000000):

There is no large allocation with length(unclass(x)), and only the
obviously necessarily single allocation in +.foo (not two additional
allocations for unclass(e1) and unclass(e1).  For <.foo, there is no
large allocation at all, because not only are allocations avoided for
unclass(e1) and unclass(e2), but 'any' also avoids an allocation for
the result of the comparison.  Unfortunately, assigning unclass(x) to
a variable does result in a copy being made (this might often be
avoided in future).

These performance improvements are implemented using pqR's "variant
result" mechanism, which also allows many other optimizations.  See

https://radfordneal.wordpress.com/2013/06/30/how-pqr-makes-programs-faster-by-not-doing-things/

for some explanation.  There is no particular reason this mechanism
couldn't be incorporated into R Core's implementation of R.

   Radford Neal


From csardi.gabor at gmail.com  Tue Mar  7 15:13:48 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 7 Mar 2017 14:13:48 +0000
Subject: [Rd] Platform dependent native routine registration
Message-ID: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>

Dear All,

I am trying to convert a package to native routine registration, and
not sure how to
best solve the problem of C functions that are only used for a single
platform, i.e.
Windows, Linux (& Unix) or macOS.

If I simply provide a different method table for each platform, then the .Call()
statements for the other platforms will generate R CMD check warnings,
both for the
"undefined" global functions and the registration "problems":

checking foreign function calls ... WARNING
Registration problems:
  symbol ?c_keyring_macos_delete? not in namespace:
   .Call(c_keyring_macos_delete, utf8(keyring), utf8(service), utf8(username))
  symbol ?c_keyring_macos_get? not in namespace:
   .Call(c_keyring_macos_get, utf8(keyring), utf8(service), utf8(username))

[...]

See chapter ?System and foreign language interfaces? in the ?Writing R
Extensions? manual.checking R code for possible problems ... NOTE
b_macos_delete: no visible binding for global variable
  ?c_keyring_macos_delete?
b_macos_get: no visible binding for global variable
  ?c_keyring_macos_get?

[...]

Undefined global functions or variables:
  c_keyring_macos_create c_keyring_macos_delete
  c_keyring_macos_delete_keyring c_keyring_macos_get
  c_keyring_macos_list c_keyring_macos_list_keyring
  c_keyring_macos_lock_keyring c_keyring_macos_set
  c_keyring_macos_unlock_keyring

If possible, I would like to avoid defining dummy functions for all functions
that are not available on a certain platform, simply because I have a lot of
them. Is it possible?

Thanks,
Gabor


From edd at debian.org  Tue Mar  7 15:45:02 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Mar 2017 08:45:02 -0600
Subject: [Rd] Platform dependent native routine registration
In-Reply-To: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
References: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
Message-ID: <22718.51054.27893.394368@max.eddelbuettel.com>


On 7 March 2017 at 14:13, G?bor Cs?rdi wrote:
| Dear All,
| 
| I am trying to convert a package to native routine registration, and
| not sure how to
| best solve the problem of C functions that are only used for a single
| platform, i.e.
| Windows, Linux (& Unix) or macOS.
| 
| If I simply provide a different method table for each platform, then the .Call()
| statements for the other platforms will generate R CMD check warnings,
| both for the
| "undefined" global functions and the registration "problems":
| 
| checking foreign function calls ... WARNING
| Registration problems:
|   symbol ?c_keyring_macos_delete? not in namespace:
|    .Call(c_keyring_macos_delete, utf8(keyring), utf8(service), utf8(username))
|   symbol ?c_keyring_macos_get? not in namespace:
|    .Call(c_keyring_macos_get, utf8(keyring), utf8(service), utf8(username))
| 
| [...]
| 
| See chapter ?System and foreign language interfaces? in the ?Writing R
| Extensions? manual.checking R code for possible problems ... NOTE
| b_macos_delete: no visible binding for global variable
|   ?c_keyring_macos_delete?
| b_macos_get: no visible binding for global variable
|   ?c_keyring_macos_get?
| 
| [...]
| 
| Undefined global functions or variables:
|   c_keyring_macos_create c_keyring_macos_delete
|   c_keyring_macos_delete_keyring c_keyring_macos_get
|   c_keyring_macos_list c_keyring_macos_list_keyring
|   c_keyring_macos_lock_keyring c_keyring_macos_set
|   c_keyring_macos_unlock_keyring
| 
| If possible, I would like to avoid defining dummy functions for all functions
| that are not available on a certain platform, simply because I have a lot of
| them. Is it possible?

Could you resort to preprocessor conditioning to only compile the code
relevant for a particular platform while hiding away the inapplicable parts?

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From csardi.gabor at gmail.com  Tue Mar  7 15:47:50 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 7 Mar 2017 14:47:50 +0000
Subject: [Rd] Platform dependent native routine registration
In-Reply-To: <22718.51054.27893.394368@max.eddelbuettel.com>
References: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
	<22718.51054.27893.394368@max.eddelbuettel.com>
Message-ID: <CABtg=K=21nKnxtEWDTqafXGxTo8Ke_ET8Kh=SDRsd67N_oUQxw@mail.gmail.com>

On Tue, Mar 7, 2017 at 2:45 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
[...]
>
> Could you resort to preprocessor conditioning to only compile the code
> relevant for a particular platform while hiding away the inapplicable parts?

Yes, I do exactly that. The problem is that the R code still has

.Call(c_non_existent_function_on_this_platform, ...)

and R CMD check picks up on that.

But I just found that using string literals in .Call() works just
fine. Hopefully
this will still be allowed in the long run:

.Call("c_non_existent_function_on_this_platform", ...)

Gabor


From edd at debian.org  Tue Mar  7 15:51:03 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Mar 2017 08:51:03 -0600
Subject: [Rd] Platform dependent native routine registration
In-Reply-To: <CABtg=K=21nKnxtEWDTqafXGxTo8Ke_ET8Kh=SDRsd67N_oUQxw@mail.gmail.com>
References: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
	<22718.51054.27893.394368@max.eddelbuettel.com>
	<CABtg=K=21nKnxtEWDTqafXGxTo8Ke_ET8Kh=SDRsd67N_oUQxw@mail.gmail.com>
Message-ID: <22718.51415.299096.672599@max.eddelbuettel.com>


On 7 March 2017 at 14:47, G?bor Cs?rdi wrote:
| On Tue, Mar 7, 2017 at 2:45 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
| [...]
| >
| > Could you resort to preprocessor conditioning to only compile the code
| > relevant for a particular platform while hiding away the inapplicable parts?
| 
| Yes, I do exactly that. The problem is that the R code still has
| 
| .Call(c_non_existent_function_on_this_platform, ...)
| 
| and R CMD check picks up on that.

Silly me. Of course -- R code does not see the preprocessor.

You could move up one level then and ... do it via configure, ie have
'hidden' files osx-init.c, lnx-init.c, win-init.c and copy in the one you
need on a given platform.
 
| But I just found that using string literals in .Call() works just
| fine. Hopefully
| this will still be allowed in the long run:
| 
| .Call("c_non_existent_function_on_this_platform", ...)

So you are adjusting the literals on the fly at compilation time?

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From csardi.gabor at gmail.com  Tue Mar  7 15:57:16 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 7 Mar 2017 14:57:16 +0000
Subject: [Rd] Platform dependent native routine registration
In-Reply-To: <22718.51415.299096.672599@max.eddelbuettel.com>
References: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
	<22718.51054.27893.394368@max.eddelbuettel.com>
	<CABtg=K=21nKnxtEWDTqafXGxTo8Ke_ET8Kh=SDRsd67N_oUQxw@mail.gmail.com>
	<22718.51415.299096.672599@max.eddelbuettel.com>
Message-ID: <CABtg=K=PG7NndoTmBsB6VjkwbR3jTKQ41CaSwtinAzzOJoCDng@mail.gmail.com>

On Tue, Mar 7, 2017 at 2:51 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
[...]
> | But I just found that using string literals in .Call() works just
> | fine. Hopefully
> | this will still be allowed in the long run:
> |
> | .Call("c_non_existent_function_on_this_platform", ...)
>
> So you are adjusting the literals on the fly at compilation time?

No, I just leave them there. They are not supposed to be called on a platform
where the C function does not exist, and even if they would be, that's just an
error, which is fine.

I could dynamically include/exclude R code at install time, but that is not so
easy, either, I would probably need to deal with the docs as well, etc.

So I'll just leave it there....

G.

> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From plummerm at iarc.fr  Tue Mar  7 16:43:06 2017
From: plummerm at iarc.fr (Martyn Plummer)
Date: Tue, 7 Mar 2017 15:43:06 +0000
Subject: [Rd] Platform dependent native routine registration
In-Reply-To: <CABtg=K=PG7NndoTmBsB6VjkwbR3jTKQ41CaSwtinAzzOJoCDng@mail.gmail.com>
References: <CABtg=KkBqR3+FGPUwaHA4UF=V7fqkhCmvGiKTZ=x3UPP4YRbiQ@mail.gmail.com>
	<22718.51054.27893.394368@max.eddelbuettel.com>
	<CABtg=K=21nKnxtEWDTqafXGxTo8Ke_ET8Kh=SDRsd67N_oUQxw@mail.gmail.com>
	<22718.51415.299096.672599@max.eddelbuettel.com>
	<CABtg=K=PG7NndoTmBsB6VjkwbR3jTKQ41CaSwtinAzzOJoCDng@mail.gmail.com>
Message-ID: <1488901386.2633.28.camel@iarc.fr>

On Tue, 2017-03-07 at 14:57 +0000, G?bor Cs?rdi wrote:
> On Tue, Mar 7, 2017 at 2:51 PM, Dirk Eddelbuettel <edd at debian.org>
> wrote:
> [...]
> > > But I just found that using string literals in .Call() works just
> > > fine. Hopefully
> > > this will still be allowed in the long run:
> > > 
> > > .Call("c_non_existent_function_on_this_platform", ...)
> > 
> > So you are adjusting the literals on the fly at compilation time?
> 
> No, I just leave them there. They are not supposed to be called on a platform
> where the C function does not exist, and even if they would be, that's just an
> error, which is fine.
> 
> I could dynamically include/exclude R code at install time, but that is not so
> easy, either, I would probably need to deal with the docs as well, etc.
> 
> So I'll just leave it there....

You can put platform-specific R code and documentation in a
subdirectory named "unix" or "windows". But there is no provision for
MacOS-specific R code as far as I know.

Martyn


> G.
> 
> > Dirk
> > 
> > --
> > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From kellieotto at berkeley.edu  Tue Mar  7 20:06:48 2017
From: kellieotto at berkeley.edu (Kellie Ottoboni)
Date: Tue, 7 Mar 2017 11:06:48 -0800
Subject: [Rd] Bug in sample()
Message-ID: <CAH2K0L7t8=POCVz1NzCRdBmtofW+q3XN=UC_kfK7gwSbLp2+Lw@mail.gmail.com>

Dear all,

Philip Stark and I think we have found a problem with how R generates
random samples, resulting from how it generates random integers between 1
and n. (If we are reading the code correctly, the method is to multiply a
pseudo-random binary fraction by n, take the floor, and add 1; this suffers
from quantization effects that can get quite large when n is just below
2^31).

A better method, used in Python, is to generate ceil(log_2(n))
pseudo-random bits, add 1, and discard values bigger than n.

Attached is a short document explaining the issue in more detail.

Best,
Kellie

-- 
Kellie Ottoboni
Ph.D. Statistics '19, University of California, Berkeley
Fellow at Berkeley Institute for Data Science

Mobile: (650) 520-5056
Website: www.stat.berkeley.edu/~kellieotto
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sample-bug.pdf
Type: application/pdf
Size: 230126 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170307/33af608a/attachment.pdf>

From kmillar at google.com  Tue Mar  7 20:45:43 2017
From: kmillar at google.com (Karl Millar)
Date: Tue, 7 Mar 2017 11:45:43 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <22717.23379.425969.881644@stat.math.ethz.ch>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
	<22715.7625.79979.272007@stat.math.ethz.ch>
	<CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
	<22717.23379.425969.881644@stat.math.ethz.ch>
Message-ID: <CABz6aZcfd5wgYjD4E4XA4Vbie5=oM7rHSoDaRdBHeWUA_D-DNA@mail.gmail.com>

Is there anything that actually requires R core members to manually do
significant amounts of work here?

IIUC, you can do a CRAN run to detect the broken packages, and a simple
script can collect the emails of the affected maintainers, so you can send
a single email to them all.  If authors don't respond by fixing their
packages, then those packages should be archived, since there's high
probability of those packages being buggy anyway.

If you expect a non-trivial amount of questions regarding this change from
the affected package maintainers, then you can create a FAQ page for it,
which you can fill in as questions arrive, so you don't get too many
duplicated questions.

Karl

On Mon, Mar 6, 2017 at 4:51 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Michael Lawrence <lawrence.michael at gene.com>
> >>>>>     on Sat, 4 Mar 2017 12:20:45 -0800 writes:
>
>     > Is there really a need for these complications? Packages
>     > emitting this warning are broken by definition and should be fixed.
>
> I agree and probably Henrik, too.
>
> (Others may disagree to some extent .. and find it convenient
>  that R does translate 'if(x)'  to  'if(x[1])'  for them albeit
>  with a warning .. )
>
>     > Perhaps we could "flip the switch" in a test
>     > environment and see how much havoc is wreaked and whether
>     > authors are sufficiently responsive?
>
>     > Michael
>
> As we have > 10'000 packages on CRAN alonce,  and people have
> started (mis)using suppressWarnings(.) in many places,  there
> may be considerably more packages affected than we optimistically assume...
>
> As R core member who would  "flip the switch"  I'd typically then
> have to be the one sending an e-mail to all package maintainers
> affected.... and in this case I'm very reluctant to volunteer
> for that and so, I'd prefer the environment variable where R
> core and others can decide how to use it .. for a while .. until
> the flip is switched for all.
>
> or have I overlooked an issue?
>
> Martin
>
>     > On Sat, Mar 4, 2017 at 12:04 PM, Martin Maechler
>     > <maechler at stat.math.ethz.ch
>     >> wrote:
>
>     >> >>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> >>>>>
>     >> on Fri, 3 Mar 2017 10:10:53 -0800 writes:
>     >>
>     >> > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham >
>     >> <h.wickham at gmail.com> wrote: >>> But, how you propose a
>     >> warning-to-error transition >>> should be made without
>     >> wreaking havoc?  Just flip the >>> switch in R-devel and
>     >> see CRAN and Bioconductor packages >>> break overnight?
>     >> Particularly Bioconductor devel might >>> become
>     >> non-functional (since at times it requires >>> R-devel).
>     >> For my own code / packages, I would be able >>> to handle
>     >> such a change, but I'm completely out of >>> control if
>     >> one of the package I'm depending on does not >>> provide
>     >> a quick fix (with the only option to remove >>> package
>     >> tests for those dependencies).
>     >> >>
>     >> >> Generally, a package can not be on CRAN if it has any
>     >> >> warnings, so I don't think this change would have any
>     >> >> impact on CRAN packages.  Isn't this also true for >>
>     >> bioconductor?
>     >>
>     >> > Having a tests/warn.R file with:
>     >>
>     >> > warning("boom")
>     >>
>     >> > passes through R CMD check --as-cran unnoticed.
>     >>
>     >> Yes, indeed.. you are right Henrik that many/most R
>     >> warning()s would not produce R CMD check 'WARNING's ..
>     >>
>     >> I think Hadley and I fell into the same mental pit of
>     >> concluding that such warning()s from
>     >> if(<length-larger-one>) ...  would not currently happen
>     >> in CRAN / Bioc packages and hence turning them to errors
>     >> would not have a direct effect.
>     >>
>     >> With your 2nd e-mail of saying that you'd propose such an
>     >> option only for a few releases of R you've indeed
>     >> clarified your intent to me.  OTOH, I would prefer using
>     >> an environment variable (as you've proposed as an
>     >> alternative) which is turned "active" at the beginning
>     >> only manually or for the "CRAN incoming" checks of the
>     >> CRAN team (and bioconductor submission checks?)  and
>     >> later for '--as-cran' etc until it eventually becomes the
>     >> unconditional behavior of R (and the env.variable is no
>     >> longer used).
>     >>
>     >> Martin
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>
>     >   [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Tue Mar  7 20:57:13 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 7 Mar 2017 11:57:13 -0800
Subject: [Rd] Control statements with condition with greater than one
 should give error (not just warning) [PATCH]
In-Reply-To: <CABz6aZcfd5wgYjD4E4XA4Vbie5=oM7rHSoDaRdBHeWUA_D-DNA@mail.gmail.com>
References: <CAFDcVCRQVjqug-9TwWDNcFYOYYAxE1-E6G3VNmfCLNgPoLrEJQ@mail.gmail.com>
	<22713.42589.85552.452293@stat.math.ethz.ch>
	<CAFDcVCRwLgO46WdJ6=5jBsGb8z-6BGuAUoFVUcn1h0dg5rXmtQ@mail.gmail.com>
	<CABdHhvEh-nxwz6jeDCeQHB91a3BpVJA-P-8s5yyv3Xi40zkezA@mail.gmail.com>
	<CAFDcVCSFXQWhfna8Vfn=jk-vV3-HWadWHW+T1Ljo8giRmS9uTw@mail.gmail.com>
	<22715.7625.79979.272007@stat.math.ethz.ch>
	<CAOQ5NycBdX7nutXv+qR_dG2xKEpx3GONw=2LuVoNYjy6yqq6Zg@mail.gmail.com>
	<22717.23379.425969.881644@stat.math.ethz.ch>
	<CABz6aZcfd5wgYjD4E4XA4Vbie5=oM7rHSoDaRdBHeWUA_D-DNA@mail.gmail.com>
Message-ID: <CADwqtCNuF0yb1U7Qw8APJ3w5NYt8iJ5XqMiaUA-cO7_L5cPJeg@mail.gmail.com>

I'm just throwing this out there, but maybe CRAN (or some other testing
machinery) should get a "strict testing" build of R in which
suppressWarnings is reassigned to identity...

Or maybe suppressWarnings could check for, eg an environment variable and
turn itself into a no-op when present, so that build systems could be used
to test for this.

~G

On Tue, Mar 7, 2017 at 11:45 AM, Karl Millar via R-devel <
r-devel at r-project.org> wrote:

> Is there anything that actually requires R core members to manually do
> significant amounts of work here?
>
> IIUC, you can do a CRAN run to detect the broken packages, and a simple
> script can collect the emails of the affected maintainers, so you can send
> a single email to them all.  If authors don't respond by fixing their
> packages, then those packages should be archived, since there's high
> probability of those packages being buggy anyway.
>
> If you expect a non-trivial amount of questions regarding this change from
> the affected package maintainers, then you can create a FAQ page for it,
> which you can fill in as questions arrive, so you don't get too many
> duplicated questions.
>
> Karl
>
> On Mon, Mar 6, 2017 at 4:51 AM, Martin Maechler <
> maechler at stat.math.ethz.ch>
> wrote:
>
> > >>>>> Michael Lawrence <lawrence.michael at gene.com>
> > >>>>>     on Sat, 4 Mar 2017 12:20:45 -0800 writes:
> >
> >     > Is there really a need for these complications? Packages
> >     > emitting this warning are broken by definition and should be fixed.
> >
> > I agree and probably Henrik, too.
> >
> > (Others may disagree to some extent .. and find it convenient
> >  that R does translate 'if(x)'  to  'if(x[1])'  for them albeit
> >  with a warning .. )
> >
> >     > Perhaps we could "flip the switch" in a test
> >     > environment and see how much havoc is wreaked and whether
> >     > authors are sufficiently responsive?
> >
> >     > Michael
> >
> > As we have > 10'000 packages on CRAN alonce,  and people have
> > started (mis)using suppressWarnings(.) in many places,  there
> > may be considerably more packages affected than we optimistically
> assume...
> >
> > As R core member who would  "flip the switch"  I'd typically then
> > have to be the one sending an e-mail to all package maintainers
> > affected.... and in this case I'm very reluctant to volunteer
> > for that and so, I'd prefer the environment variable where R
> > core and others can decide how to use it .. for a while .. until
> > the flip is switched for all.
> >
> > or have I overlooked an issue?
> >
> > Martin
> >
> >     > On Sat, Mar 4, 2017 at 12:04 PM, Martin Maechler
> >     > <maechler at stat.math.ethz.ch
> >     >> wrote:
> >
> >     >> >>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> >>>>>
> >     >> on Fri, 3 Mar 2017 10:10:53 -0800 writes:
> >     >>
> >     >> > On Fri, Mar 3, 2017 at 9:55 AM, Hadley Wickham >
> >     >> <h.wickham at gmail.com> wrote: >>> But, how you propose a
> >     >> warning-to-error transition >>> should be made without
> >     >> wreaking havoc?  Just flip the >>> switch in R-devel and
> >     >> see CRAN and Bioconductor packages >>> break overnight?
> >     >> Particularly Bioconductor devel might >>> become
> >     >> non-functional (since at times it requires >>> R-devel).
> >     >> For my own code / packages, I would be able >>> to handle
> >     >> such a change, but I'm completely out of >>> control if
> >     >> one of the package I'm depending on does not >>> provide
> >     >> a quick fix (with the only option to remove >>> package
> >     >> tests for those dependencies).
> >     >> >>
> >     >> >> Generally, a package can not be on CRAN if it has any
> >     >> >> warnings, so I don't think this change would have any
> >     >> >> impact on CRAN packages.  Isn't this also true for >>
> >     >> bioconductor?
> >     >>
> >     >> > Having a tests/warn.R file with:
> >     >>
> >     >> > warning("boom")
> >     >>
> >     >> > passes through R CMD check --as-cran unnoticed.
> >     >>
> >     >> Yes, indeed.. you are right Henrik that many/most R
> >     >> warning()s would not produce R CMD check 'WARNING's ..
> >     >>
> >     >> I think Hadley and I fell into the same mental pit of
> >     >> concluding that such warning()s from
> >     >> if(<length-larger-one>) ...  would not currently happen
> >     >> in CRAN / Bioc packages and hence turning them to errors
> >     >> would not have a direct effect.
> >     >>
> >     >> With your 2nd e-mail of saying that you'd propose such an
> >     >> option only for a few releases of R you've indeed
> >     >> clarified your intent to me.  OTOH, I would prefer using
> >     >> an environment variable (as you've proposed as an
> >     >> alternative) which is turned "active" at the beginning
> >     >> only manually or for the "CRAN incoming" checks of the
> >     >> CRAN team (and bioconductor submission checks?)  and
> >     >> later for '--as-cran' etc until it eventually becomes the
> >     >> unconditional behavior of R (and the env.variable is no
> >     >> longer used).
> >     >>
> >     >> Martin
> >     >>
> >     >> ______________________________________________
> >     >> R-devel at r-project.org mailing list
> >     >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >>
> >
> >     >   [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From rdonnelly at continuum.io  Wed Mar  8 00:35:25 2017
From: rdonnelly at continuum.io (Ray Donnelly)
Date: Tue, 7 Mar 2017 23:35:25 +0000
Subject: [Rd] Seeking advice regarding compilation of large libraries
 using RTools (Windows)
In-Reply-To: <CA+V7QS990wTd_odPb1+=C9ntoBQVthjX-cNpLC75UDE7rS2QXQ@mail.gmail.com>
References: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>
	<CABFfbXs2s0TfEC1kx+VyFc3yG22Vrc2pOBgMOd36WTLcPSA6AQ@mail.gmail.com>
	<CA+V7QS990wTd_odPb1+=C9ntoBQVthjX-cNpLC75UDE7rS2QXQ@mail.gmail.com>
Message-ID: <CAF5kcVXsXQYwRruKbQS1zwva6pmCLGu+=PxBmCgVVKS3jpqAOA@mail.gmail.com>

On Mon, Mar 6, 2017 at 8:21 PM, Richard Beare <richard.beare at gmail.com>
wrote:

> Yep - simpleITK is available at github.com/SimpleITK/SimpleITK. There's
> also github.com/SimpleITK/SimpleITKRInstaller - a devtools based installer
> for mac and linux.
>
> CMake has a range of build environments. I experimented with MSYS2 and
> mingw makefiles, but had trouble with incompatibilities in the path
> required by CMake and those options - from memory the sh in RTools/bin
> caused problems. Although it sounds like you are saying it is necessary to
> install the MSYS2 system as well.
>

MSYS2 has two variants (3 distinctly named packages) of CMake:
mingw-w64-{i686,x86_64}-cmake and cmake. Which of these (if any) did you
use? I cannot state without experimenting which should be used, but the
mingw-w64 prefixed ones are usually the ones you want to generate native
code.


>
> The unix makefile option for CMake appears to work well until the linking
> stage. Ninja has problems at a similar stage.
>
> I'll steer clear of dll's, as you suggest. I'm checking those links for
> compiler/links flags to see if we're missing anything
>

I would be happy to see if I can get it to compile in the Anaconda
Distribution too. Here we prefer DLLs. The gnu ld linker on Windows is very
slow and doesn't seem to scale too well. I do not expect cross-compiling
would make it much faster. The clang linker (ldd) is nearly viable on
Windows and apparently much faster. I'm not sure if this near-viability is
in relation to using it in msvc mode, gcc mode or both (or even whether it
implements frontends for both).


> Thanks
>
>
>
> On Mon, Mar 6, 2017 at 9:51 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>
> > On Mon, Mar 6, 2017 at 6:33 AM, Richard Beare <richard.beare at gmail.com>
> > wrote:
> > > I am working on the SimpleITK package for R. This is an enormous
> package
> > > that is largely automatically generated via a set of swig/json/lua
> magic,
> > > and is working well under linux and osx.
> >
> > Is it available somewhere so we can try it?
> >
> >
> > > However we're having a lot of trouble with the Windows side. In fact,
> we
> > are struggling to get the base libraries to build using the RTools 3.4
> > toolchain, even before the worrying about the R-specific parts.
> >
> > What build environment do you use? The version of gcc with Rtools
> > should be ok, but the Rtools build utilities in the "bin" folder (in
> > particular 'make') are old and a frequent source of problems. However
> > for building external libs you can use other tools, for example those
> > from msys2. Just make sure you use gcc/g++ from Rtools.
>
>
> >
> > > The current issue is very long time (possibly infinite) linking of
> dlls,
> > or
> > > test executables. I've tried using a FAT32 file system for the build,
> as
> > > suggested by some old bug reports, but still have the issue.
> >
> > On Windows you can avoid the run-time dll mess by building static libs
> > of external libraries. See rwinlib for examples:
> > https://github.com/rwinlib
> >
> >
> > > Any suggestions on where to turn next? Are cross compilers the next
> step?
> >
> > Try building with msys2, but make sure to use gcc/g++ from Rtools by
> > setting the `CC` and `CXX` variables in the configure script. Cross
> > compiling will make things even more complicated because binaries
> > might not be compatible if your cross compiler has a different version
> > of gcc or has been configured for another exception model (seh/drawf).
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From richard.beare at gmail.com  Wed Mar  8 01:09:56 2017
From: richard.beare at gmail.com (Richard Beare)
Date: Wed, 8 Mar 2017 11:09:56 +1100
Subject: [Rd] Seeking advice regarding compilation of large libraries
 using RTools (Windows)
In-Reply-To: <CAF5kcVXsXQYwRruKbQS1zwva6pmCLGu+=PxBmCgVVKS3jpqAOA@mail.gmail.com>
References: <CA+V7QS9fq5QVZkkfiiHL9XPzbk+72egXDjOVhNzgHxAJJxopaQ@mail.gmail.com>
	<CABFfbXs2s0TfEC1kx+VyFc3yG22Vrc2pOBgMOd36WTLcPSA6AQ@mail.gmail.com>
	<CA+V7QS990wTd_odPb1+=C9ntoBQVthjX-cNpLC75UDE7rS2QXQ@mail.gmail.com>
	<CAF5kcVXsXQYwRruKbQS1zwva6pmCLGu+=PxBmCgVVKS3jpqAOA@mail.gmail.com>
Message-ID: <CA+V7QS-gw9wYK3j+O9JMYx61LWb_0d5GfWXHgUrCRPzfXpC4wg@mail.gmail.com>

So far I've been using the separate cmake package (direct from kitware),
rather than one available via msys2 (as I started without msys2). I'll have
a play with the msys2 versions.

The problem definitely seems to be with ld - it sits at high load for days
at a time, and I haven't seen it complete successfully on the test exe
files. They also hang around when I kill the make.

I'm having a play with building libraries but not test infrastructure,
although this isn't a long term solution.

Sounds like clang is something worth checking out - any comments on whether
it is close to working with R?

On Wed, Mar 8, 2017 at 10:35 AM, Ray Donnelly <rdonnelly at continuum.io>
wrote:

> On Mon, Mar 6, 2017 at 8:21 PM, Richard Beare <richard.beare at gmail.com>
> wrote:
>
>> Yep - simpleITK is available at github.com/SimpleITK/SimpleITK. There's
>> also github.com/SimpleITK/SimpleITKRInstaller - a devtools based
>> installer
>> for mac and linux.
>>
>> CMake has a range of build environments. I experimented with MSYS2 and
>> mingw makefiles, but had trouble with incompatibilities in the path
>> required by CMake and those options - from memory the sh in RTools/bin
>> caused problems. Although it sounds like you are saying it is necessary to
>> install the MSYS2 system as well.
>>
>
> MSYS2 has two variants (3 distinctly named packages) of CMake:
> mingw-w64-{i686,x86_64}-cmake and cmake. Which of these (if any) did you
> use? I cannot state without experimenting which should be used, but the
> mingw-w64 prefixed ones are usually the ones you want to generate native
> code.
>
>
>>
>> The unix makefile option for CMake appears to work well until the linking
>> stage. Ninja has problems at a similar stage.
>>
>> I'll steer clear of dll's, as you suggest. I'm checking those links for
>> compiler/links flags to see if we're missing anything
>>
>
> I would be happy to see if I can get it to compile in the Anaconda
> Distribution too. Here we prefer DLLs. The gnu ld linker on Windows is very
> slow and doesn't seem to scale too well. I do not expect cross-compiling
> would make it much faster. The clang linker (ldd) is nearly viable on
> Windows and apparently much faster. I'm not sure if this near-viability is
> in relation to using it in msvc mode, gcc mode or both (or even whether it
> implements frontends for both).
>
>
>> Thanks
>>
>>
>>
>> On Mon, Mar 6, 2017 at 9:51 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>>
>> > On Mon, Mar 6, 2017 at 6:33 AM, Richard Beare <richard.beare at gmail.com>
>> > wrote:
>> > > I am working on the SimpleITK package for R. This is an enormous
>> package
>> > > that is largely automatically generated via a set of swig/json/lua
>> magic,
>> > > and is working well under linux and osx.
>> >
>> > Is it available somewhere so we can try it?
>> >
>> >
>> > > However we're having a lot of trouble with the Windows side. In fact,
>> we
>> > are struggling to get the base libraries to build using the RTools 3.4
>> > toolchain, even before the worrying about the R-specific parts.
>> >
>> > What build environment do you use? The version of gcc with Rtools
>> > should be ok, but the Rtools build utilities in the "bin" folder (in
>> > particular 'make') are old and a frequent source of problems. However
>> > for building external libs you can use other tools, for example those
>> > from msys2. Just make sure you use gcc/g++ from Rtools.
>>
> >
>> >
>> > > The current issue is very long time (possibly infinite) linking of
>> dlls,
>> > or
>> > > test executables. I've tried using a FAT32 file system for the build,
>> as
>> > > suggested by some old bug reports, but still have the issue.
>> >
>> > On Windows you can avoid the run-time dll mess by building static libs
>> > of external libraries. See rwinlib for examples:
>> > https://github.com/rwinlib
>> >
>> >
>> > > Any suggestions on where to turn next? Are cross compilers the next
>> step?
>> >
>> > Try building with msys2, but make sure to use gcc/g++ from Rtools by
>> > setting the `CC` and `CXX` variables in the configure script. Cross
>> > compiling will make things even more complicated because binaries
>> > might not be compatible if your cross compiler has a different version
>> > of gcc or has been configured for another exception model (seh/drawf).
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Mar  8 09:02:19 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 8 Mar 2017 09:02:19 +0100
Subject: [Rd] Bug in nlm()
In-Reply-To: <22713.42179.765118.892734@stat.math.ethz.ch>
References: <0051D1E3C4DC574698F0EDFC7FFA6ADBEBF89E8E@HERMES01.demogr.mpg.de>
	<22713.42179.765118.892734@stat.math.ethz.ch>
Message-ID: <22719.47755.541134.331752@stat.math.ethz.ch>

       {This was sent to me, MM, only, but for completeness should
        have gone back to R-devel.

	Further: I now *have* added Marie B to the members'of "R bugzilla"
	-- M.Maechler}


I had already read the R bug reporting guide and I'm sure it is a bug.
The bug occurs when the user provides not only the analytic gradient but also the analytic Hessian of the objective function. In that case, the algorithm does not converge due to an erroneous implementation of the modified Cholesky decomposition of the Hessian matrix. It is actually a bug in the C-code called by nlm(), therefore it is hard to show that the non-convergence of the algorithm is really due to this bug with only a MRE.
However, a short example (optimizing the Rosenbrock banana valley function with and without analytic Hessian) is:

fg <- function(x){  
  gr <- function(x1, x2) c(-400*x1*(x2 - x1*x1)-2*(1-x1), 200*(x2 - x1*x1)) 
  x1 <- x[1]; x2 <- x[2]
  res<- 100*(x2 - x1*x1)^2 + (1-x1)^2 
  attr(res, "gradient") <- gr(x1, x2)
  return(res)
} 
nlm.fg <- nlm(fg, c(-1.2, 1))

fgh <- function(x){ 
  gr <- function(x1, x2) c(-400*x1*(x2 - x1*x1) - 2*(1-x1), 200*(x2 - x1*x1)) 
  h <- function(x1, x2){
    a11 <- 2 - 400*x2 + 1200*x1*x1
    a21 <- -400*x1 
    matrix(c(a11, a21, a21, 200), 2, 2)
  } 
  x1 <- x[1];  x2 <- x[2];  res<- 100*(x2 - x1*x1)^2 + (1-x1)^2 
  attr(res, "gradient") <- gr(x1, x2)
  attr(res, "hessian") <- h(x1, x2) 
  return(res)
}
nlm.fgh <- nlm(fgh, c(-1.2,1))

I have almost finished a more detailed bug report, which I would like to submit.

Best,
Marie Boehnstedt

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 3 Mar 2017 18:15:47 +0100 writes:

>>>>> Boehnstedt, Marie <Boehnstedt at demogr.mpg.de>
>>>>>     on Fri, 3 Mar 2017 10:23:12 +0000 writes:

    >> Dear all, I have found a bug in nlm() and would like to
    >> submit a report on this.  Since nlm() is in the
    >> stats-package, which is maintained by the R Core team,
    >> bug reports should be submitted to R's Bugzilla. However,
    >> I'm not a member of Bugzilla. Could anyone be so kind to
    >> add me to R's Bugzilla members or let me know to whom I
    >> should send the bug report?

    > Dear Marie,

    > I can do this ... but are you really sure?  There is
    > https://www.r-project.org/bugs.html which you should spend
    > some time reading if you haven't already.

    > I think you would post a MRE (Minimal Reproducible
    > Example) here {or on stackoverflow or ...} if you'd follow
    > what the 'R bugs' web page (above) recommends and only
    > report a bug after some feedback from "the public".

    > Of course, I could be wrong.. and happy if you explain /
    > tell me why.

    > Best, Martin Maechler

    >> Thank you in advance.

    >> Kind regards, Marie B?hnstedt


    >> Marie B?hnstedt, MSc Research Scientist Max Planck
    >> Institute for Demographic Research Konrad-Zuse-Str. 1,
    >> 18057 Rostock, Germany
    >> www.demogr.mpg.de<http://www.demogr.mpg.de/>


From spencer.graves at prodsyse.com  Wed Mar  8 23:06:48 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 8 Mar 2017 16:06:48 -0600
Subject: [Rd] Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3)
Message-ID: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>

Hello:


       A call to help(..., help_type='text') fails with "package='fda":


 > install.packages('fda')
 > help(package='fda', help_type='text')
Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
   incorrect values of 'indent' and 'width'


       I have this wrapped inside "try" in PackageSum2{sos}, so it 
doesn't die, but it also doesn't give me the additional information I 
want from help(..., help_type='text')


       Is this a bug?
       Thanks,
       Spencer Graves

Using RStudio 1.0.136 with


 > sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets
[6] methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.3


From arunkumar.sriniv at gmail.com  Thu Mar  9 01:29:00 2017
From: arunkumar.sriniv at gmail.com (Arunkumar Srinivasan)
Date: Wed, 8 Mar 2017 16:29:00 -0800
Subject: [Rd] as.POSIXct behaviour
Message-ID: <CAJ=vYTFX25JxhXBzYbVo7qu=WDYc7UHWqjb+tmgqT_GUM6HUhQ@mail.gmail.com>

Dear R-devel, I have tested the code below on R v3.3.2 and v3.3.3 on
Mac and Windows.

x <- c("2017-01-01 05:00:02", "2017-01-02 03 :M:00") # note the ? :M?
in 2nd value
as.POSIXct(x)
# [1] "2017-01-01 GMT" "2017-01-02 GMT?

The time info is lost on the first index as well. And it happens *silently*.

On the other hand, if I do:

lapply(x, as.POSIXct)
#?[[1]]
#?[1] "2017-01-01 05:00:02 GMT"
#
#?[[2]]
# [1] "2017-01-02 GMT?

A list is returned, but values are as I?d expect. Would it be possible
to retain the time info with as.POSIXct(x) directly as well? If not,
what?s the rationale? In addition, I think a warning message that some
malformed timestamps were found would be very useful.

Thank you,
Arun.


From spencer.graves at prodsyse.com  Thu Mar  9 07:28:56 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 9 Mar 2017 00:28:56 -0600
Subject: [Rd] Error in formatDL(nm, txt, indent = max(nchar(nm,
	"w")) + 3)
In-Reply-To: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>
References: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>
Message-ID: <584764a2-5345-61bb-131f-c3e59083c896@prodsyse.com>

Hello:


       I tried "debug(help)" with the problem mentioned below.  It 
stopped with a call to "library", from which I generate the following 
simple replication of this error:


 > library(help = 'fda', character.only = TRUE)
Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
   incorrect values of 'indent' and 'width'


       This was using R 3.3.3 inside RStudio on a Mac, as noted below.  
This same "library(help='fda', character.only=TRUE)" ran fine using R 
Console 3.2.1 under Windows 7.


       I also tried debug(library).  It died in line 298:


     for (i in which(file.exists(docFiles))) pkgInfo[[i]] <- 
readDocFile(docFiles[i])


       with i = 1 and docFiles[i] = 
"/Library/Frameworks/R.framework/Versions/3.3/Resources/library/fda/Meta/package.rds". 



       This looks like a bug to me.  I don't know if it's new since R 
3.2.1 or it works fine under Windows 7 but not a Mac.


       Thanks,
       Spencer Graves


*** NOTES:


       1.  When I tried "Q" to exit debug mode, I got, "Error retrieving 
help:  R code execution error."  This suggests a bug in "debug", which 
could be replicated by trying debug(help) with "help(package='fda', 
help_type='text')".  It does not want to exit from "help" using "Q".  
"c" also fails.


       2.  For sessionInfo(), see below.


On 2017-03-08 4:06 PM, Spencer Graves wrote:
> Hello:
>
>
>       A call to help(..., help_type='text') fails with "package='fda":
>
>
> > install.packages('fda')
> > help(package='fda', help_type='text')
> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>   incorrect values of 'indent' and 'width'
>
>
>       I have this wrapped inside "try" in PackageSum2{sos}, so it 
> doesn't die, but it also doesn't give me the additional information I 
> want from help(..., help_type='text')
>
>
>       Is this a bug?
>       Thanks,
>       Spencer Graves
>
> Using RStudio 1.0.136 with
>
>
> > sessionInfo()
> R version 3.3.3 (2017-03-06)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: macOS Sierra 10.12.3
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets
> [6] methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.3
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From msuzen at gmail.com  Thu Mar  9 08:05:03 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 9 Mar 2017 08:05:03 +0100
Subject: [Rd] as.POSIXct behaviour
In-Reply-To: <CAJ=vYTFX25JxhXBzYbVo7qu=WDYc7UHWqjb+tmgqT_GUM6HUhQ@mail.gmail.com>
References: <CAJ=vYTFX25JxhXBzYbVo7qu=WDYc7UHWqjb+tmgqT_GUM6HUhQ@mail.gmail.com>
Message-ID: <CAPtbhHyaJZBS0xoRNur9SsTiF+vQt5W3KCorVhuSJmA_=upgkQ@mail.gmail.com>

On 9 March 2017 at 01:29, Arunkumar Srinivasan
<arunkumar.sriniv at gmail.com> wrote:
> The time info is lost on the first index as well. And it happens *silently*.

Yes, because it assumes homogeneous format on the entire vector.  You
may want to
do  two passes with different formats or run a regular expression to
catch typos.

> lapply(x, as.POSIXct)
> A list is returned, but values are as I?d expect. Would it be possible
> to retain the time info with as.POSIXct(x) directly as well? If not,

This behaves differently because you are running as.POSIXct for each element
separately.


From wdunlap at tibco.com  Thu Mar  9 16:28:03 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Mar 2017 07:28:03 -0800
Subject: [Rd] Error in formatDL(nm, txt, indent = max(nchar(nm,
	"w")) + 3)
In-Reply-To: <584764a2-5345-61bb-131f-c3e59083c896@prodsyse.com>
References: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>
	<584764a2-5345-61bb-131f-c3e59083c896@prodsyse.com>
Message-ID: <CAF8bMcYhwPKYeRX=XYM9qTPYsxiGH_2oqvmaM0BBvAyfsoNcKw@mail.gmail.com>

This error can arise when getOption("width") is too small.  80 seems to be the
limit for me with R-3.3.2 on Windows.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Mar 8, 2017 at 10:28 PM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> Hello:
>
>
>       I tried "debug(help)" with the problem mentioned below.  It stopped
> with a call to "library", from which I generate the following simple
> replication of this error:
>
>
>> library(help = 'fda', character.only = TRUE)
> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>   incorrect values of 'indent' and 'width'
>
>
>       This was using R 3.3.3 inside RStudio on a Mac, as noted below.  This
> same "library(help='fda', character.only=TRUE)" ran fine using R Console
> 3.2.1 under Windows 7.
>
>
>       I also tried debug(library).  It died in line 298:
>
>
>     for (i in which(file.exists(docFiles))) pkgInfo[[i]] <-
> readDocFile(docFiles[i])
>
>
>       with i = 1 and docFiles[i] =
> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/fda/Meta/package.rds".
>
>
>       This looks like a bug to me.  I don't know if it's new since R 3.2.1
> or it works fine under Windows 7 but not a Mac.
>
>
>       Thanks,
>       Spencer Graves
>
>
> *** NOTES:
>
>
>       1.  When I tried "Q" to exit debug mode, I got, "Error retrieving
> help:  R code execution error."  This suggests a bug in "debug", which could
> be replicated by trying debug(help) with "help(package='fda',
> help_type='text')".  It does not want to exit from "help" using "Q".  "c"
> also fails.
>
>
>       2.  For sessionInfo(), see below.
>
>
> On 2017-03-08 4:06 PM, Spencer Graves wrote:
>>
>> Hello:
>>
>>
>>       A call to help(..., help_type='text') fails with "package='fda":
>>
>>
>> > install.packages('fda')
>> > help(package='fda', help_type='text')
>> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>>   incorrect values of 'indent' and 'width'
>>
>>
>>       I have this wrapped inside "try" in PackageSum2{sos}, so it doesn't
>> die, but it also doesn't give me the additional information I want from
>> help(..., help_type='text')
>>
>>
>>       Is this a bug?
>>       Thanks,
>>       Spencer Graves
>>
>> Using RStudio 1.0.136 with
>>
>>
>> > sessionInfo()
>> R version 3.3.3 (2017-03-06)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: macOS Sierra 10.12.3
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets
>> [6] methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.3.3
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Mar  9 16:58:42 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Mar 2017 07:58:42 -0800
Subject: [Rd] Error in formatDL(nm, txt, indent = max(nchar(nm,
	"w")) + 3)
In-Reply-To: <CAF8bMcYhwPKYeRX=XYM9qTPYsxiGH_2oqvmaM0BBvAyfsoNcKw@mail.gmail.com>
References: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>
	<584764a2-5345-61bb-131f-c3e59083c896@prodsyse.com>
	<CAF8bMcYhwPKYeRX=XYM9qTPYsxiGH_2oqvmaM0BBvAyfsoNcKw@mail.gmail.com>
Message-ID: <CAF8bMcYKk_m3OY7u3yGPJsqX7awra3PDi-=O42MtAUZ7FZLqsA@mail.gmail.com>

It happens in the fda package because some of the headers are longer
than typical (e.g., "Repository/R-Forge/DateTimeStamp") and formatDL
dies if the indent argument is too large compared to the width argument.

It might be nice to change formatDL so it never gave such an error, but
did something reasonable when the 'indent' argument was too big.
Changing
   if (indent > width/2) stop("incorrect values of 'indent' and 'width'")
to
   indent <- min(indent, width/2)
seems reasonable to me.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Mar 9, 2017 at 7:28 AM, William Dunlap <wdunlap at tibco.com> wrote:
> This error can arise when getOption("width") is too small.  80 seems to be the
> limit for me with R-3.3.2 on Windows.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Mar 8, 2017 at 10:28 PM, Spencer Graves
> <spencer.graves at prodsyse.com> wrote:
>> Hello:
>>
>>
>>       I tried "debug(help)" with the problem mentioned below.  It stopped
>> with a call to "library", from which I generate the following simple
>> replication of this error:
>>
>>
>>> library(help = 'fda', character.only = TRUE)
>> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>>   incorrect values of 'indent' and 'width'
>>
>>
>>       This was using R 3.3.3 inside RStudio on a Mac, as noted below.  This
>> same "library(help='fda', character.only=TRUE)" ran fine using R Console
>> 3.2.1 under Windows 7.
>>
>>
>>       I also tried debug(library).  It died in line 298:
>>
>>
>>     for (i in which(file.exists(docFiles))) pkgInfo[[i]] <-
>> readDocFile(docFiles[i])
>>
>>
>>       with i = 1 and docFiles[i] =
>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/fda/Meta/package.rds".
>>
>>
>>       This looks like a bug to me.  I don't know if it's new since R 3.2.1
>> or it works fine under Windows 7 but not a Mac.
>>
>>
>>       Thanks,
>>       Spencer Graves
>>
>>
>> *** NOTES:
>>
>>
>>       1.  When I tried "Q" to exit debug mode, I got, "Error retrieving
>> help:  R code execution error."  This suggests a bug in "debug", which could
>> be replicated by trying debug(help) with "help(package='fda',
>> help_type='text')".  It does not want to exit from "help" using "Q".  "c"
>> also fails.
>>
>>
>>       2.  For sessionInfo(), see below.
>>
>>
>> On 2017-03-08 4:06 PM, Spencer Graves wrote:
>>>
>>> Hello:
>>>
>>>
>>>       A call to help(..., help_type='text') fails with "package='fda":
>>>
>>>
>>> > install.packages('fda')
>>> > help(package='fda', help_type='text')
>>> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>>>   incorrect values of 'indent' and 'width'
>>>
>>>
>>>       I have this wrapped inside "try" in PackageSum2{sos}, so it doesn't
>>> die, but it also doesn't give me the additional information I want from
>>> help(..., help_type='text')
>>>
>>>
>>>       Is this a bug?
>>>       Thanks,
>>>       Spencer Graves
>>>
>>> Using RStudio 1.0.136 with
>>>
>>>
>>> > sessionInfo()
>>> R version 3.3.3 (2017-03-06)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: macOS Sierra 10.12.3
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets
>>> [6] methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.3.3
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Thu Mar  9 17:32:57 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 9 Mar 2017 10:32:57 -0600
Subject: [Rd] Error in formatDL(nm, txt, indent = max(nchar(nm,
	"w")) + 3)
In-Reply-To: <CAF8bMcYKk_m3OY7u3yGPJsqX7awra3PDi-=O42MtAUZ7FZLqsA@mail.gmail.com>
References: <a99693c0-1152-a367-d0e1-bd54edfa4319@prodsyse.com>
	<584764a2-5345-61bb-131f-c3e59083c896@prodsyse.com>
	<CAF8bMcYhwPKYeRX=XYM9qTPYsxiGH_2oqvmaM0BBvAyfsoNcKw@mail.gmail.com>
	<CAF8bMcYKk_m3OY7u3yGPJsqX7awra3PDi-=O42MtAUZ7FZLqsA@mail.gmail.com>
Message-ID: <187bd418-125a-4028-f523-d5f3375c6b4b@prodsyse.com>

Hi, Bill et al.:


On 2017-03-09 9:58 AM, William Dunlap wrote:
> It happens in the fda package because some of the headers are longer
> than typical (e.g., "Repository/R-Forge/DateTimeStamp") and formatDL
> dies if the indent argument is too large compared to the width argument.
>
> It might be nice to change formatDL so it never gave such an error, but
> did something reasonable when the 'indent' argument was too big.
> Changing
>     if (indent > width/2) stop("incorrect values of 'indent' and 'width'")
> to
>     indent <- min(indent, width/2)
> seems reasonable to me.


       Thanks.  That sounds like a useful patch to me.


       Per "www.r-project.org/bugs.html", I will forward this thread 
with your suggested patch to the maintainer for formatDL{base} = "R Core 
Team <R-core at r-project.org>".


       Spencer Graves


p.s.  Per your earlier email, I changed the code in PackageSum2{sos} to 
include the following before the first call to help{utils}:


   w0 <-options(width=80)
   on.exit(options(w0))


       This eliminated the specific error I reported but may not work 
with other packages with even longer headers.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Mar 9, 2017 at 7:28 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> This error can arise when getOption("width") is too small.  80 seems to be the
>> limit for me with R-3.3.2 on Windows.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Mar 8, 2017 at 10:28 PM, Spencer Graves
>> <spencer.graves at prodsyse.com> wrote:
>>> Hello:
>>>
>>>
>>>        I tried "debug(help)" with the problem mentioned below.  It stopped
>>> with a call to "library", from which I generate the following simple
>>> replication of this error:
>>>
>>>
>>>> library(help = 'fda', character.only = TRUE)
>>> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>>>    incorrect values of 'indent' and 'width'
>>>
>>>
>>>        This was using R 3.3.3 inside RStudio on a Mac, as noted below.  This
>>> same "library(help='fda', character.only=TRUE)" ran fine using R Console
>>> 3.2.1 under Windows 7.
>>>
>>>
>>>        I also tried debug(library).  It died in line 298:
>>>
>>>
>>>      for (i in which(file.exists(docFiles))) pkgInfo[[i]] <-
>>> readDocFile(docFiles[i])
>>>
>>>
>>>        with i = 1 and docFiles[i] =
>>> "/Library/Frameworks/R.framework/Versions/3.3/Resources/library/fda/Meta/package.rds".
>>>
>>>
>>>        This looks like a bug to me.  I don't know if it's new since R 3.2.1
>>> or it works fine under Windows 7 but not a Mac.
>>>
>>>
>>>        Thanks,
>>>        Spencer Graves
>>>
>>>
>>> *** NOTES:
>>>
>>>
>>>        1.  When I tried "Q" to exit debug mode, I got, "Error retrieving
>>> help:  R code execution error."  This suggests a bug in "debug", which could
>>> be replicated by trying debug(help) with "help(package='fda',
>>> help_type='text')".  It does not want to exit from "help" using "Q".  "c"
>>> also fails.
>>>
>>>
>>>        2.  For sessionInfo(), see below.
>>>
>>>
>>> On 2017-03-08 4:06 PM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>        A call to help(..., help_type='text') fails with "package='fda":
>>>>
>>>>
>>>>> install.packages('fda')
>>>>> help(package='fda', help_type='text')
>>>> Error in formatDL(nm, txt, indent = max(nchar(nm, "w")) + 3) :
>>>>    incorrect values of 'indent' and 'width'
>>>>
>>>>
>>>>        I have this wrapped inside "try" in PackageSum2{sos}, so it doesn't
>>>> die, but it also doesn't give me the additional information I want from
>>>> help(..., help_type='text')
>>>>
>>>>
>>>>        Is this a bug?
>>>>        Thanks,
>>>>        Spencer Graves
>>>>
>>>> Using RStudio 1.0.136 with
>>>>
>>>>
>>>>> sessionInfo()
>>>> R version 3.3.3 (2017-03-06)
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>> Running under: macOS Sierra 10.12.3
>>>>
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets
>>>> [6] methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.3.3
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From georgi.boshnakov at manchester.ac.uk  Thu Mar  9 17:47:36 2017
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 9 Mar 2017 16:47:36 +0000
Subject: [Rd] problems with RdMacros in file DESCRIPTION
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F5D930A@MBXP02.ds.man.ac.uk>

Hi,

Field RdMacros was introduced in file DESCRIPTION to allow users to import LaTeX-like macros from other packages. 

Currently 'R CMD Check --as-cran'  gives a NOTE:

> Unknown, possibly mis-spelled, field in DESCRIPTION:
>  ?RdMacros?

A small package demonstrating this is  available at
http://www.maths.manchester.ac.uk/~gb/testRdMacro_0.0.2.tar.gz
(and this is the source: http://www.maths.manchester.ac.uk/~gb/testRdMacro_src.tar.gz).
I get the message on my Linux and Windows machines and on win-builder.

Same problem is on the FAQ at https://github.com/gaborcsardi/argufy#frequently-asked-questions
but with no indication if  it has been reported.


Thanks,
Georgi


--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of r-devel-request at r-project.org [r-devel-request at r-project.org]
Sent: 09 April 2016 11:00
To: r-devel at r-project.org
Subject: R-devel Digest, Vol 158, Issue 6

Send R-devel mailing list submissions to
        r-devel at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-devel
or, via email, send a message with subject or body 'help' to
        r-devel-request at r-project.org

You can reach the person managing the list at
        r-devel-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-devel digest..."


Today's Topics:

   1. Re: [PATCH] fix CHECK_this_length in sprintf.c
      (Matthew Fowles Kulukundis)
   2. Re: (no) circular dependency (Adrian Du?a)
   3. Re: (no) circular dependency (Mark van der Loo)
   4. Re: (no) circular dependency (Dmitri Popavenko)
   5. Re: (no) circular dependency (Gabriel Becker)
   6. PR# for match.arg(arg) (Suharto Anggono Suharto Anggono)
   7. Re: (no) circular dependency (Gregory Warnes)
   8. Re: Under Windows, Rgui and Rterm crash if one tries to close
      the graphic device while identify or locator are running
      (Duncan Murdoch)
   9. Re: (no) circular dependency (Adrian Du?a)
  10. Re: (no) circular dependency (Hadley Wickham)
  11. Re: (no) circular dependency (Adrian Du?a)


----------------------------------------------------------------------

Message: 1
Date: Thu, 7 Apr 2016 11:21:56 -0400
From: Matthew Fowles Kulukundis <matt.fowles at gmail.com>
To: Martin Maechler <maechler at stat.math.ethz.ch>
Cc: r-devel at r-project.org
Subject: Re: [Rd] [PATCH] fix CHECK_this_length in sprintf.c
Message-ID:
        <CAApERuYJ3zfLTc=H3LJkqV4Nx1U_s5=1iJE4hDH1iXbWRBaL3A at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Martin~

Sorry about the bad patch.  I work on C++ at Google. We built a check for
clang-tidy that identifies errors of this form and discovered the error
here as part of our search. I am just trying to be a good citizen and
upstream a fix, but I must have gotten sloppy as I was doing a bunch of
these.

Thanks for fixing it and finding the a test for it, I actually had no idea
how to trigger this codepath and have never used R.

If you are curious, the upstream check for clang-tidy is
http://reviews.llvm.org/D18766
You may consider running some of the other clang-tidy checks on your source
base, they will likely find other bugs.

Cheers,
Matt

On Thu, Apr 7, 2016 at 6:46 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Matthew Fowles Kulukundis <matt.fowles at gmail.com>
> >>>>>     on Tue, 5 Apr 2016 11:17:30 -0400 writes:
>
>     > All~
>     > CHECK_this_length macro expands to multiple statements making it
> unsafe to
>     > use in a single line `if` statement (as is happening near line
> 335).  This
>     > fixes the macro using the standard `do { } while (0)` macro trick.
>
> yes, but you forgot the closing '}' ... so you could not even
> have compiled R after applying your patch.
>
> Also, it would be nice to contrive a minimal example where the
> change makes a difference.  This  "fails" to trigger :
>
> --------------------------------
> as.double.foo <- function(x) x[FALSE]
> x <- structure(3, class="foo")
> as.numeric(x) # numeric(0)
>
> sprintf("%d !", x)# "3 !"  instead of giving an error
> --------------------------------
>
> Thank you, Matt, in any case; this (with the "{" !) has now gone
> into the source.
>
> Martin
>
>     > Matt
>     > x[DELETED ATTACHMENT external: r-sprintf.patch, text/x-patch]
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>

        [[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Fri, 8 Apr 2016 14:59:28 +0300
From: Adrian Du?a <dusa.adrian at unibuc.ro>
To: Mark van der Loo <mark.vanderloo at gmail.com>
Cc: r-devel <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CAJ=0CtB83wvrWkyVy05ZXyGfAt9hiMnU+QpD=_h7E62dUe=iPg at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hi Mark,

Uhm... sometimes this is not always possible.
For example I have a package QCA which produces truth tables (all
combinations of presence / absence of causal conditions), and it uses the
venn package to draw a Venn diagram.
It is debatable if one should assimilate the "venn" package into the QCA
package (other people might want Venn diagrams but not necessarily the
other QCA functions).

On the other hand, the package venn would like to use the QCA package to
demonstrate its abilities to plot Venn diagrams based on truth tables
produced by the QCA package. Both have very different purposes, yet both
use functions from each other.

So I'm with Bill Dunlap here that several smaller packages are preferable
to one larger one, but on the other hand I can't separate those functions
into a third package: the truth table production is very specific to the
QCA package, while plotting Venn diagrams is very specific to the venn
package. I don't see how to separate those functions from their main
packages and create a third one that each would depend on.

This is just an example, there could be others as well, reason for which I
am (still) looking for a solution to:
- preserve the current functionalities in packages A and B (to follow
Dmitri's original post)
- be able to use functions from each other
- yet avoid circular dependency

I hope this explains it,
Adrian


On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <mark.vanderloo at gmail.com>
wrote:

> At the risk of stating the over-obvious: there's also the option of
> creating just a single package containing all functions. None of the
> functions that create the interdependencies need to be exported that way.
>
> Btw, his question is probably better at home at the r-package-devel list.
>
>
> Best,
>
> M
>
>
>
>
> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <dmitri.popavenko at gmail.com>
> wrote:
>
>> Hi Thierry,
>>
>> Thanks for that, the trouble is functions are package specific so moving
>> from one package to another could be a solution, but I would rather save
>> that as a last resort.
>>
>> As mentioned, creating a package C with all the common functions could
>> also
>> be an option, but this strategy quickly inflates the number of packages on
>> CRAN. If no other option is possible, that could be the way but I was
>> still
>> thinking about a more direct solution if possible.
>>
>> Best,
>> Dmitri
>>
>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> wrote:
>>
>> > Dear Dmitri,
>> >
>> > If it's only a small number of functions then move them the relevant
>> > functions for A to B so that B works without A. Then Import these
>> functions
>> > from B in A. Hence A depends on B but B is independent of A.
>> >
>> > It is requires to move a lot of functions than you better create a
>> package
>> > C with all the common functions. Then A and B import those functions
>> from C.
>> >
>> > Best regards,
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> > Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no more
>> > than asking him to perform a post-mortem examination: he may be able to
>> say
>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does not
>> > ensure that a reasonable answer can be extracted from a given body of
>> data.
>> > ~ John Tukey
>> >
>> > 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <dmitri.popavenko at gmail.com
>> >:
>> >
>> >> Hello all,
>> >>
>> >> I would like to build two packages (say A and B), for two different
>> >> purposes.
>> >> Each of them need one or two functions from the other, which leads to
>> the
>> >> problem of circular dependency.
>> >>
>> >> Is there a way for package A to import a function from package B, and
>> >> package B to import a function from package A, without arriving to
>> >> circular
>> >> dependency?
>> >> Other suggestions in the archive mention building a third package that
>> >> both
>> >> A and B should depend on, but this seems less attractive.
>> >>
>> >> I read about importFrom() into the NAMESPACE file, but I don't know
>> how to
>> >> relate this with the information in the DESCRIPTION file (other than
>> >> adding
>> >> each package to the Depends: field).
>> >>
>> >> Thank you,
>> >> Dmitri
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

        [[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Fri, 08 Apr 2016 12:03:32 +0000
From: Mark van der Loo <mark.vanderloo at gmail.com>
To: Adrian Du?a <dusa.adrian at unibuc.ro>
Cc: r-devel <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CAOKDuOg93kDmgjMTPwanWgyqeUk1CESQ3dYK_QiC+FEOx8w0MA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Well, I'm not saying that Dmitri _should_ do it. I merely mention it as an
option that I think is worth thinking about -- it is easy to overlook the
obvious :-). Since we have no further info on the package's structure we
can't be sure..




Op vr 8 apr. 2016 om 13:59 schreef Adrian Du?a <dusa.adrian at unibuc.ro>:

> Hi Mark,
>
> Uhm... sometimes this is not always possible.
> For example I have a package QCA which produces truth tables (all
> combinations of presence / absence of causal conditions), and it uses the
> venn package to draw a Venn diagram.
> It is debatable if one should assimilate the "venn" package into the QCA
> package (other people might want Venn diagrams but not necessarily the
> other QCA functions).
>
> On the other hand, the package venn would like to use the QCA package to
> demonstrate its abilities to plot Venn diagrams based on truth tables
> produced by the QCA package. Both have very different purposes, yet both
> use functions from each other.
>
> So I'm with Bill Dunlap here that several smaller packages are preferable
> to one larger one, but on the other hand I can't separate those functions
> into a third package: the truth table production is very specific to the
> QCA package, while plotting Venn diagrams is very specific to the venn
> package. I don't see how to separate those functions from their main
> packages and create a third one that each would depend on.
>
> This is just an example, there could be others as well, reason for which I
> am (still) looking for a solution to:
> - preserve the current functionalities in packages A and B (to follow
> Dmitri's original post)
> - be able to use functions from each other
> - yet avoid circular dependency
>
> I hope this explains it,
> Adrian
>
>
> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <
> mark.vanderloo at gmail.com> wrote:
>
>> At the risk of stating the over-obvious: there's also the option of
>> creating just a single package containing all functions. None of the
>> functions that create the interdependencies need to be exported that way.
>>
>> Btw, his question is probably better at home at the r-package-devel list.
>>
>>
>> Best,
>>
>> M
>>
>>
>>
>>
>> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <dmitri.popavenko at gmail.com>
>> wrote:
>>
>>> Hi Thierry,
>>>
>>> Thanks for that, the trouble is functions are package specific so moving
>>> from one package to another could be a solution, but I would rather save
>>> that as a last resort.
>>>
>>> As mentioned, creating a package C with all the common functions could
>>> also
>>> be an option, but this strategy quickly inflates the number of packages
>>> on
>>> CRAN. If no other option is possible, that could be the way but I was
>>> still
>>> thinking about a more direct solution if possible.
>>>
>>> Best,
>>> Dmitri
>>>
>>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>> > Dear Dmitri,
>>> >
>>> > If it's only a small number of functions then move them the relevant
>>> > functions for A to B so that B works without A. Then Import these
>>> functions
>>> > from B in A. Hence A depends on B but B is independent of A.
>>> >
>>> > It is requires to move a lot of functions than you better create a
>>> package
>>> > C with all the common functions. Then A and B import those functions
>>> from C.
>>> >
>>> > Best regards,
>>> >
>>> > ir. Thierry Onkelinx
>>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and
>>> > Forest
>>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> > Kliniekstraat 25
>>> > 1070 Anderlecht
>>> > Belgium
>>> >
>>> > To call in the statistician after the experiment is done may be no more
>>> > than asking him to perform a post-mortem examination: he may be able
>>> to say
>>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> > The plural of anecdote is not data. ~ Roger Brinner
>>> > The combination of some data and an aching desire for an answer does
>>> not
>>> > ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> > ~ John Tukey
>>> >
>>> > 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <dmitri.popavenko at gmail.com
>>> >:
>>> >
>>> >> Hello all,
>>> >>
>>> >> I would like to build two packages (say A and B), for two different
>>> >> purposes.
>>> >> Each of them need one or two functions from the other, which leads to
>>> the
>>> >> problem of circular dependency.
>>> >>
>>> >> Is there a way for package A to import a function from package B, and
>>> >> package B to import a function from package A, without arriving to
>>> >> circular
>>> >> dependency?
>>> >> Other suggestions in the archive mention building a third package that
>>> >> both
>>> >> A and B should depend on, but this seems less attractive.
>>> >>
>>> >> I read about importFrom() into the NAMESPACE file, but I don't know
>>> how to
>>> >> relate this with the information in the DESCRIPTION file (other than
>>> >> adding
>>> >> each package to the Depends: field).
>>> >>
>>> >> Thank you,
>>> >> Dmitri
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-devel at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>

        [[alternative HTML version deleted]]



------------------------------

Message: 4
Date: Fri, 8 Apr 2016 17:36:10 +0300
From: Dmitri Popavenko <dmitri.popavenko at gmail.com>
To: Mark van der Loo <mark.vanderloo at gmail.com>,        William Dunlap
        <wdunlap at tibco.com>
Cc: Adrian Du?a <dusa.adrian at unibuc.ro>,        r-devel
        <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CAJL_pojJDwU9-e3faZTgQ2BpRAoB1MhzAVZ_7Tz4vYJ7bXkKqA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Thanks all, I don't know either (for the moment).
It's all in the design phase still. Generally, I would also like to keep
specific functions in specific packages, if at all possible.

On Fri, Apr 8, 2016 at 3:03 PM, Mark van der Loo <mark.vanderloo at gmail.com>
wrote:

> Well, I'm not saying that Dmitri _should_ do it. I merely mention it as an
> option that I think is worth thinking about -- it is easy to overlook the
> obvious :-). Since we have no further info on the package's structure we
> can't be sure..
>
>
>
>
> Op vr 8 apr. 2016 om 13:59 schreef Adrian Du?a <dusa.adrian at unibuc.ro>:
>
>> Hi Mark,
>>
>> Uhm... sometimes this is not always possible.
>> For example I have a package QCA which produces truth tables (all
>> combinations of presence / absence of causal conditions), and it uses the
>> venn package to draw a Venn diagram.
>> It is debatable if one should assimilate the "venn" package into the QCA
>> package (other people might want Venn diagrams but not necessarily the
>> other QCA functions).
>>
>> On the other hand, the package venn would like to use the QCA package to
>> demonstrate its abilities to plot Venn diagrams based on truth tables
>> produced by the QCA package. Both have very different purposes, yet both
>> use functions from each other.
>>
>> So I'm with Bill Dunlap here that several smaller packages are preferable
>> to one larger one, but on the other hand I can't separate those functions
>> into a third package: the truth table production is very specific to the
>> QCA package, while plotting Venn diagrams is very specific to the venn
>> package. I don't see how to separate those functions from their main
>> packages and create a third one that each would depend on.
>>
>> This is just an example, there could be others as well, reason for which
>> I am (still) looking for a solution to:
>> - preserve the current functionalities in packages A and B (to follow
>> Dmitri's original post)
>> - be able to use functions from each other
>> - yet avoid circular dependency
>>
>> I hope this explains it,
>> Adrian
>>
>>
>> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <
>> mark.vanderloo at gmail.com> wrote:
>>
>>> At the risk of stating the over-obvious: there's also the option of
>>> creating just a single package containing all functions. None of the
>>> functions that create the interdependencies need to be exported that way.
>>>
>>> Btw, his question is probably better at home at the r-package-devel list.
>>>
>>>
>>> Best,
>>>
>>> M
>>>
>>>
>>>
>>>
>>> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <dmitri.popavenko at gmail.com>
>>> wrote:
>>>
>>>> Hi Thierry,
>>>>
>>>> Thanks for that, the trouble is functions are package specific so moving
>>>> from one package to another could be a solution, but I would rather save
>>>> that as a last resort.
>>>>
>>>> As mentioned, creating a package C with all the common functions could
>>>> also
>>>> be an option, but this strategy quickly inflates the number of packages
>>>> on
>>>> CRAN. If no other option is possible, that could be the way but I was
>>>> still
>>>> thinking about a more direct solution if possible.
>>>>
>>>> Best,
>>>> Dmitri
>>>>
>>>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>>>> thierry.onkelinx at inbo.be>
>>>> wrote:
>>>>
>>>> > Dear Dmitri,
>>>> >
>>>> > If it's only a small number of functions then move them the relevant
>>>> > functions for A to B so that B works without A. Then Import these
>>>> functions
>>>> > from B in A. Hence A depends on B but B is independent of A.
>>>> >
>>>> > It is requires to move a lot of functions than you better create a
>>>> package
>>>> > C with all the common functions. Then A and B import those functions
>>>> from C.
>>>> >
>>>> > Best regards,
>>>> >
>>>> > ir. Thierry Onkelinx
>>>> > Instituut voor natuur- en bosonderzoek / Research Institute for
>>>> Nature and
>>>> > Forest
>>>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> > Kliniekstraat 25
>>>> > 1070 Anderlecht
>>>> > Belgium
>>>> >
>>>> > To call in the statistician after the experiment is done may be no
>>>> more
>>>> > than asking him to perform a post-mortem examination: he may be able
>>>> to say
>>>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> > The plural of anecdote is not data. ~ Roger Brinner
>>>> > The combination of some data and an aching desire for an answer does
>>>> not
>>>> > ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> > ~ John Tukey
>>>> >
>>>> > 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <
>>>> dmitri.popavenko at gmail.com>:
>>>> >
>>>> >> Hello all,
>>>> >>
>>>> >> I would like to build two packages (say A and B), for two different
>>>> >> purposes.
>>>> >> Each of them need one or two functions from the other, which leads
>>>> to the
>>>> >> problem of circular dependency.
>>>> >>
>>>> >> Is there a way for package A to import a function from package B, and
>>>> >> package B to import a function from package A, without arriving to
>>>> >> circular
>>>> >> dependency?
>>>> >> Other suggestions in the archive mention building a third package
>>>> that
>>>> >> both
>>>> >> A and B should depend on, but this seems less attractive.
>>>> >>
>>>> >> I read about importFrom() into the NAMESPACE file, but I don't know
>>>> how to
>>>> >> relate this with the information in the DESCRIPTION file (other than
>>>> >> adding
>>>> >> each package to the Depends: field).
>>>> >>
>>>> >> Thank you,
>>>> >> Dmitri
>>>> >>
>>>> >>         [[alternative HTML version deleted]]
>>>> >>
>>>> >> ______________________________________________
>>>> >> R-devel at r-project.org mailing list
>>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> >>
>>>> >
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>>
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>>
>

        [[alternative HTML version deleted]]



------------------------------

Message: 5
Date: Fri, 8 Apr 2016 08:37:12 -0700
From: Gabriel Becker <gmbecker at ucdavis.edu>
To: Dmitri Popavenko <dmitri.popavenko at gmail.com>
Cc: Adrian Du?a <dusa.adrian at unibuc.ro>,        r-devel
        <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CADwqtCP9Cmo6xy1zw86=k-SZckUUM5n_0qL8HbwcG5SyRTCQrw at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Another, perhaps slightly off the wall reframing of the 3-package
possibility:

Have packages B, a, and UserFacingA, as follows

*a* contains all the functionality in your A package that
*does not depend on B*
*B* *imports from* *a* and is essentially unchanged
*UserFacingA* *Depends* on *a* and *imports from* *B*, it implements all
functionality from your package A that *does depend on* *B*, and gets the
rest from package *a*

Users, then would only ever install or load B and UserFacingA. They
wouldn't need to care much,if at all, about package a.

~G

On Fri, Apr 8, 2016 at 7:36 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com
> wrote:

> Thanks all, I don't know either (for the moment).
> It's all in the design phase still. Generally, I would also like to keep
> specific functions in specific packages, if at all possible.
>
> On Fri, Apr 8, 2016 at 3:03 PM, Mark van der Loo <mark.vanderloo at gmail.com
> >
> wrote:
>
> > Well, I'm not saying that Dmitri _should_ do it. I merely mention it as
> an
> > option that I think is worth thinking about -- it is easy to overlook the
> > obvious :-). Since we have no further info on the package's structure we
> > can't be sure..
> >
> >
> >
> >
> > Op vr 8 apr. 2016 om 13:59 schreef Adrian Du?a <dusa.adrian at unibuc.ro>:
> >
> >> Hi Mark,
> >>
> >> Uhm... sometimes this is not always possible.
> >> For example I have a package QCA which produces truth tables (all
> >> combinations of presence / absence of causal conditions), and it uses
> the
> >> venn package to draw a Venn diagram.
> >> It is debatable if one should assimilate the "venn" package into the QCA
> >> package (other people might want Venn diagrams but not necessarily the
> >> other QCA functions).
> >>
> >> On the other hand, the package venn would like to use the QCA package to
> >> demonstrate its abilities to plot Venn diagrams based on truth tables
> >> produced by the QCA package. Both have very different purposes, yet both
> >> use functions from each other.
> >>
> >> So I'm with Bill Dunlap here that several smaller packages are
> preferable
> >> to one larger one, but on the other hand I can't separate those
> functions
> >> into a third package: the truth table production is very specific to the
> >> QCA package, while plotting Venn diagrams is very specific to the venn
> >> package. I don't see how to separate those functions from their main
> >> packages and create a third one that each would depend on.
> >>
> >> This is just an example, there could be others as well, reason for which
> >> I am (still) looking for a solution to:
> >> - preserve the current functionalities in packages A and B (to follow
> >> Dmitri's original post)
> >> - be able to use functions from each other
> >> - yet avoid circular dependency
> >>
> >> I hope this explains it,
> >> Adrian
> >>
> >>
> >> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <
> >> mark.vanderloo at gmail.com> wrote:
> >>
> >>> At the risk of stating the over-obvious: there's also the option of
> >>> creating just a single package containing all functions. None of the
> >>> functions that create the interdependencies need to be exported that
> way.
> >>>
> >>> Btw, his question is probably better at home at the r-package-devel
> list.
> >>>
> >>>
> >>> Best,
> >>>
> >>> M
> >>>
> >>>
> >>>
> >>>
> >>> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <
> dmitri.popavenko at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Thierry,
> >>>>
> >>>> Thanks for that, the trouble is functions are package specific so
> moving
> >>>> from one package to another could be a solution, but I would rather
> save
> >>>> that as a last resort.
> >>>>
> >>>> As mentioned, creating a package C with all the common functions could
> >>>> also
> >>>> be an option, but this strategy quickly inflates the number of
> packages
> >>>> on
> >>>> CRAN. If no other option is possible, that could be the way but I was
> >>>> still
> >>>> thinking about a more direct solution if possible.
> >>>>
> >>>> Best,
> >>>> Dmitri
> >>>>
> >>>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
> >>>> thierry.onkelinx at inbo.be>
> >>>> wrote:
> >>>>
> >>>> > Dear Dmitri,
> >>>> >
> >>>> > If it's only a small number of functions then move them the relevant
> >>>> > functions for A to B so that B works without A. Then Import these
> >>>> functions
> >>>> > from B in A. Hence A depends on B but B is independent of A.
> >>>> >
> >>>> > It is requires to move a lot of functions than you better create a
> >>>> package
> >>>> > C with all the common functions. Then A and B import those functions
> >>>> from C.
> >>>> >
> >>>> > Best regards,
> >>>> >
> >>>> > ir. Thierry Onkelinx
> >>>> > Instituut voor natuur- en bosonderzoek / Research Institute for
> >>>> Nature and
> >>>> > Forest
> >>>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance
> >>>> > Kliniekstraat 25
> >>>> > 1070 Anderlecht
> >>>> > Belgium
> >>>> >
> >>>> > To call in the statistician after the experiment is done may be no
> >>>> more
> >>>> > than asking him to perform a post-mortem examination: he may be able
> >>>> to say
> >>>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>>> > The plural of anecdote is not data. ~ Roger Brinner
> >>>> > The combination of some data and an aching desire for an answer does
> >>>> not
> >>>> > ensure that a reasonable answer can be extracted from a given body
> of
> >>>> data.
> >>>> > ~ John Tukey
> >>>> >
> >>>> > 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <
> >>>> dmitri.popavenko at gmail.com>:
> >>>> >
> >>>> >> Hello all,
> >>>> >>
> >>>> >> I would like to build two packages (say A and B), for two different
> >>>> >> purposes.
> >>>> >> Each of them need one or two functions from the other, which leads
> >>>> to the
> >>>> >> problem of circular dependency.
> >>>> >>
> >>>> >> Is there a way for package A to import a function from package B,
> and
> >>>> >> package B to import a function from package A, without arriving to
> >>>> >> circular
> >>>> >> dependency?
> >>>> >> Other suggestions in the archive mention building a third package
> >>>> that
> >>>> >> both
> >>>> >> A and B should depend on, but this seems less attractive.
> >>>> >>
> >>>> >> I read about importFrom() into the NAMESPACE file, but I don't know
> >>>> how to
> >>>> >> relate this with the information in the DESCRIPTION file (other
> than
> >>>> >> adding
> >>>> >> each package to the Depends: field).
> >>>> >>
> >>>> >> Thank you,
> >>>> >> Dmitri
> >>>> >>
> >>>> >>         [[alternative HTML version deleted]]
> >>>> >>
> >>>> >> ______________________________________________
> >>>> >> R-devel at r-project.org mailing list
> >>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> >>
> >>>> >
> >>>> >
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>
> >>
> >> --
> >> Adrian Dusa
> >> University of Bucharest
> >> Romanian Social Data Archive
> >> Soseaua Panduri nr.90
> >> 050663 Bucharest sector 5
> >> Romania
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



--
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

        [[alternative HTML version deleted]]



------------------------------

Message: 6
Date: Fri, 8 Apr 2016 16:39:47 +0000 (UTC)
From: Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com>
To: <R-devel at r-project.org>
Subject: [Rd] PR# for match.arg(arg)
Message-ID:
        <124284635.225797.1460133587830.JavaMail.yahoo at mail.yahoo.com>
Content-Type: text/plain; charset=UTF-8

In "R News", in "Changes in R 3.3.0", in "New Features", a news item is
match.arg(arg) (the one-argument case) is faster; so is sort.int(). (PR#16640)

While it was motivated by speeding up tapply, it is in a separate bug number: 16652 (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16652).



------------------------------

Message: 7
Date: Fri, 8 Apr 2016 13:04:20 -0400
From: Gregory Warnes <greg at warnes.net>
To: Gabriel Becker <gmbecker at ucdavis.edu>
Cc: Adrian Du?a <dusa.adrian at unibuc.ro>,        r-devel
        <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID: <AE89F9A5-A0C3-4046-8A7B-617987541804 at warnes.net>
Content-Type: text/plain; charset="UTF-8"

A third possibility, which I use in my gtools and gdata packages, is to use soft-links to create a copy of the relevant functions from one package in the other.  I make sure these functions are *not* exported, so no conflicts are created, and the use of soft-links mean the code never gets out of sync.

-Greg

--
Change your thoughts and you change the world.
--Dr. Norman Vincent Peale

> On Apr 8, 2016, at 11:37 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>
> Another, perhaps slightly off the wall reframing of the 3-package
> possibility:
>
> Have packages B, a, and UserFacingA, as follows
>
> *a* contains all the functionality in your A package that
> *does not depend on B*
> *B* *imports from* *a* and is essentially unchanged
> *UserFacingA* *Depends* on *a* and *imports from* *B*, it implements all
> functionality from your package A that *does depend on* *B*, and gets the
> rest from package *a*
>
> Users, then would only ever install or load B and UserFacingA. They
> wouldn't need to care much,if at all, about package a.
>
> ~G
>
> On Fri, Apr 8, 2016 at 7:36 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com
>> wrote:
>
>> Thanks all, I don't know either (for the moment).
>> It's all in the design phase still. Generally, I would also like to keep
>> specific functions in specific packages, if at all possible.
>>
>> On Fri, Apr 8, 2016 at 3:03 PM, Mark van der Loo <mark.vanderloo at gmail.com
>> wrote:
>>
>>> Well, I'm not saying that Dmitri _should_ do it. I merely mention it as
>> an
>>> option that I think is worth thinking about -- it is easy to overlook the
>>> obvious :-). Since we have no further info on the package's structure we
>>> can't be sure..
>>>
>>>
>>>
>>>
>>> Op vr 8 apr. 2016 om 13:59 schreef Adrian Du?a <dusa.adrian at unibuc.ro>:
>>>
>>>> Hi Mark,
>>>>
>>>> Uhm... sometimes this is not always possible.
>>>> For example I have a package QCA which produces truth tables (all
>>>> combinations of presence / absence of causal conditions), and it uses
>> the
>>>> venn package to draw a Venn diagram.
>>>> It is debatable if one should assimilate the "venn" package into the QCA
>>>> package (other people might want Venn diagrams but not necessarily the
>>>> other QCA functions).
>>>>
>>>> On the other hand, the package venn would like to use the QCA package to
>>>> demonstrate its abilities to plot Venn diagrams based on truth tables
>>>> produced by the QCA package. Both have very different purposes, yet both
>>>> use functions from each other.
>>>>
>>>> So I'm with Bill Dunlap here that several smaller packages are
>> preferable
>>>> to one larger one, but on the other hand I can't separate those
>> functions
>>>> into a third package: the truth table production is very specific to the
>>>> QCA package, while plotting Venn diagrams is very specific to the venn
>>>> package. I don't see how to separate those functions from their main
>>>> packages and create a third one that each would depend on.
>>>>
>>>> This is just an example, there could be others as well, reason for which
>>>> I am (still) looking for a solution to:
>>>> - preserve the current functionalities in packages A and B (to follow
>>>> Dmitri's original post)
>>>> - be able to use functions from each other
>>>> - yet avoid circular dependency
>>>>
>>>> I hope this explains it,
>>>> Adrian
>>>>
>>>>
>>>> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <
>>>> mark.vanderloo at gmail.com> wrote:
>>>>
>>>>> At the risk of stating the over-obvious: there's also the option of
>>>>> creating just a single package containing all functions. None of the
>>>>> functions that create the interdependencies need to be exported that
>> way.
>>>>>
>>>>> Btw, his question is probably better at home at the r-package-devel
>> list.
>>>>>
>>>>>
>>>>> Best,
>>>>>
>>>>> M
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <
>> dmitri.popavenko at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Thierry,
>>>>>>
>>>>>> Thanks for that, the trouble is functions are package specific so
>> moving
>>>>>> from one package to another could be a solution, but I would rather
>> save
>>>>>> that as a last resort.
>>>>>>
>>>>>> As mentioned, creating a package C with all the common functions could
>>>>>> also
>>>>>> be an option, but this strategy quickly inflates the number of
>> packages
>>>>>> on
>>>>>> CRAN. If no other option is possible, that could be the way but I was
>>>>>> still
>>>>>> thinking about a more direct solution if possible.
>>>>>>
>>>>>> Best,
>>>>>> Dmitri
>>>>>>
>>>>>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>>>>>> thierry.onkelinx at inbo.be>
>>>>>> wrote:
>>>>>>
>>>>>>> Dear Dmitri,
>>>>>>>
>>>>>>> If it's only a small number of functions then move them the relevant
>>>>>>> functions for A to B so that B works without A. Then Import these
>>>>>> functions
>>>>>>> from B in A. Hence A depends on B but B is independent of A.
>>>>>>>
>>>>>>> It is requires to move a lot of functions than you better create a
>>>>>> package
>>>>>>> C with all the common functions. Then A and B import those functions
>>>>>> from C.
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> ir. Thierry Onkelinx
>>>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for
>>>>>> Nature and
>>>>>>> Forest
>>>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>> Assurance
>>>>>>> Kliniekstraat 25
>>>>>>> 1070 Anderlecht
>>>>>>> Belgium
>>>>>>>
>>>>>>> To call in the statistician after the experiment is done may be no
>>>>>> more
>>>>>>> than asking him to perform a post-mortem examination: he may be able
>>>>>> to say
>>>>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>>>> The combination of some data and an aching desire for an answer does
>>>>>> not
>>>>>>> ensure that a reasonable answer can be extracted from a given body
>> of
>>>>>> data.
>>>>>>> ~ John Tukey
>>>>>>>
>>>>>>> 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <
>>>>>> dmitri.popavenko at gmail.com>:
>>>>>>>
>>>>>>>> Hello all,
>>>>>>>>
>>>>>>>> I would like to build two packages (say A and B), for two different
>>>>>>>> purposes.
>>>>>>>> Each of them need one or two functions from the other, which leads
>>>>>> to the
>>>>>>>> problem of circular dependency.
>>>>>>>>
>>>>>>>> Is there a way for package A to import a function from package B,
>> and
>>>>>>>> package B to import a function from package A, without arriving to
>>>>>>>> circular
>>>>>>>> dependency?
>>>>>>>> Other suggestions in the archive mention building a third package
>>>>>> that
>>>>>>>> both
>>>>>>>> A and B should depend on, but this seems less attractive.
>>>>>>>>
>>>>>>>> I read about importFrom() into the NAMESPACE file, but I don't know
>>>>>> how to
>>>>>>>> relate this with the information in the DESCRIPTION file (other
>> than
>>>>>>>> adding
>>>>>>>> each package to the Depends: field).
>>>>>>>>
>>>>>>>> Thank you,
>>>>>>>> Dmitri
>>>>>>>>
>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>> --
>>>> Adrian Dusa
>>>> University of Bucharest
>>>> Romanian Social Data Archive
>>>> Soseaua Panduri nr.90
>>>> 050663 Bucharest sector 5
>>>> Romania
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

        [[alternative HTML version deleted]]



------------------------------

Message: 8
Date: Fri, 8 Apr 2016 13:05:47 -0400
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: Henrik Bengtsson <henrik.bengtsson at gmail.com>
Cc: R-devel <r-devel at r-project.org>
Subject: Re: [Rd] Under Windows, Rgui and Rterm crash if one tries to
        close the graphic device while identify or locator are running
Message-ID: <5707E4EB.4030108 at gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed

On 05/04/2016 3:35 PM, Duncan Murdoch wrote:
> On 05/04/2016 11:56 AM, Henrik Bengtsson wrote:
> > If of any help,
> >
> > I can reproduce this (on Windows 7) back to at least R 3.0.3 but it's
> > not there in R 3.0.0.  (I have *not* checked with R 3.0.1 and 3.0.2
> > which I don't have installed).
>
> That doesn't necessarily mean that 3.0.0 was fine.  It's a segfault (I'd
> guess some memory being accessed after being freed), and it comes and
> goes as I add debugging print statements --- so it might have been there
> in 3.0.0 but we just got lucky and it never surfaced.
>
> Still, it's a start, and I'll try bisecting between 3.0.0 and 3.0.3 to
> see if some change caused it, rather than just triggered it.

I've tracked this down, and I believe I have a working fix now.  The
issue was that the bug fix for PR#14872, a similar problem on Linux,
fixed Linux and introduced a new bug in Windows.  For future reference,
the problem is that it is currently not safe to call error() in a
Windows event handler.  We may try to fix that over the summer, the
current fix just avoids doing it.

Duncan Murdoch



------------------------------

Message: 9
Date: Fri, 8 Apr 2016 22:25:09 +0300
From: Adrian Du?a <dusa.adrian at unibuc.ro>
To: Gregory Warnes <greg at warnes.net>
Cc: r-devel <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CAJ=0CtDGJMC7PhscyC4PBFp8_9ikFbvkiGpYECgo3T5LRJaw+A at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hi Greg,

That's interesting but I assume those are self-contained functions.
In my case, the truthTable() function from package QCA depends on numerous
other functions in the QCA package so I'm not sure how feasible it is to
copy everything from each package to every other package.

Best,
Adrian

On Fri, Apr 8, 2016 at 8:04 PM, Gregory Warnes <greg at warnes.net> wrote:

> A third possibility, which I use in my gtools and gdata packages, is to
> use soft-links to create a copy of the relevant functions from one package
> in the other.  I make sure these functions are *not* exported, so no
> conflicts are created, and the use of soft-links mean the code never gets
> out of sync.
>
> -Greg
>
> *--  *
> *Change your thoughts and you change the world.*
> --Dr. Norman Vincent Peale
>
> On Apr 8, 2016, at 11:37 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>
> Another, perhaps slightly off the wall reframing of the 3-package
> possibility:
>
> Have packages B, a, and UserFacingA, as follows
>
> *a* contains all the functionality in your A package that
> *does not depend on B*
> *B* *imports from* *a* and is essentially unchanged
> *UserFacingA* *Depends* on *a* and *imports from* *B*, it implements all
> functionality from your package A that *does depend on* *B*, and gets the
> rest from package *a*
>
>
> Users, then would only ever install or load B and UserFacingA. They
> wouldn't need to care much,if at all, about package a.
>
> ~G
>
> On Fri, Apr 8, 2016 at 7:36 AM, Dmitri Popavenko <
> dmitri.popavenko at gmail.com
>
> wrote:
>
>
> Thanks all, I don't know either (for the moment).
>
> It's all in the design phase still. Generally, I would also like to keep
>
> specific functions in specific packages, if at all possible.
>
>
> On Fri, Apr 8, 2016 at 3:03 PM, Mark van der Loo <mark.vanderloo at gmail.com
>
>
> wrote:
>
>
> Well, I'm not saying that Dmitri _should_ do it. I merely mention it as
>
> an
>
> option that I think is worth thinking about -- it is easy to overlook the
>
> obvious :-). Since we have no further info on the package's structure we
>
> can't be sure..
>
>
>
>
>
> Op vr 8 apr. 2016 om 13:59 schreef Adrian Du?a <dusa.adrian at unibuc.ro>:
>
>
> Hi Mark,
>
>
> Uhm... sometimes this is not always possible.
>
> For example I have a package QCA which produces truth tables (all
>
> combinations of presence / absence of causal conditions), and it uses
>
> the
>
> venn package to draw a Venn diagram.
>
> It is debatable if one should assimilate the "venn" package into the QCA
>
> package (other people might want Venn diagrams but not necessarily the
>
> other QCA functions).
>
>
> On the other hand, the package venn would like to use the QCA package to
>
> demonstrate its abilities to plot Venn diagrams based on truth tables
>
> produced by the QCA package. Both have very different purposes, yet both
>
> use functions from each other.
>
>
> So I'm with Bill Dunlap here that several smaller packages are
>
> preferable
>
> to one larger one, but on the other hand I can't separate those
>
> functions
>
> into a third package: the truth table production is very specific to the
>
> QCA package, while plotting Venn diagrams is very specific to the venn
>
> package. I don't see how to separate those functions from their main
>
> packages and create a third one that each would depend on.
>
>
> This is just an example, there could be others as well, reason for which
>
> I am (still) looking for a solution to:
>
> - preserve the current functionalities in packages A and B (to follow
>
> Dmitri's original post)
>
> - be able to use functions from each other
>
> - yet avoid circular dependency
>
>
> I hope this explains it,
>
> Adrian
>
>
>
> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <
>
> mark.vanderloo at gmail.com> wrote:
>
>
> At the risk of stating the over-obvious: there's also the option of
>
> creating just a single package containing all functions. None of the
>
> functions that create the interdependencies need to be exported that
>
> way.
>
>
> Btw, his question is probably better at home at the r-package-devel
>
> list.
>
>
>
> Best,
>
>
> M
>
>
>
>
>
> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <
>
> dmitri.popavenko at gmail.com>
>
> wrote:
>
>
> Hi Thierry,
>
>
> Thanks for that, the trouble is functions are package specific so
>
> moving
>
> from one package to another could be a solution, but I would rather
>
> save
>
> that as a last resort.
>
>
> As mentioned, creating a package C with all the common functions could
>
> also
>
> be an option, but this strategy quickly inflates the number of
>
> packages
>
> on
>
> CRAN. If no other option is possible, that could be the way but I was
>
> still
>
> thinking about a more direct solution if possible.
>
>
> Best,
>
> Dmitri
>
>
> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>
> thierry.onkelinx at inbo.be>
>
> wrote:
>
>
> Dear Dmitri,
>
>
> If it's only a small number of functions then move them the relevant
>
> functions for A to B so that B works without A. Then Import these
>
> functions
>
> from B in A. Hence A depends on B but B is independent of A.
>
>
> It is requires to move a lot of functions than you better create a
>
> package
>
> C with all the common functions. Then A and B import those functions
>
> from C.
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
>
> Instituut voor natuur- en bosonderzoek / Research Institute for
>
> Nature and
>
> Forest
>
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>
> Assurance
>
> Kliniekstraat 25
>
> 1070 Anderlecht
>
> Belgium
>
>
> To call in the statistician after the experiment is done may be no
>
> more
>
> than asking him to perform a post-mortem examination: he may be able
>
> to say
>
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data. ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does
>
> not
>
> ensure that a reasonable answer can be extracted from a given body
>
> of
>
> data.
>
> ~ John Tukey
>
>
> 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <
>
> dmitri.popavenko at gmail.com>:
>
>
> Hello all,
>
>
> I would like to build two packages (say A and B), for two different
>
> purposes.
>
> Each of them need one or two functions from the other, which leads
>
> to the
>
> problem of circular dependency.
>
>
> Is there a way for package A to import a function from package B,
>
> and
>
> package B to import a function from package A, without arriving to
>
> circular
>
> dependency?
>
> Other suggestions in the archive mention building a third package
>
> that
>
> both
>
> A and B should depend on, but this seems less attractive.
>
>
> I read about importFrom() into the NAMESPACE file, but I don't know
>
> how to
>
> relate this with the information in the DESCRIPTION file (other
>
> than
>
> adding
>
> each package to the Depends: field).
>
>
> Thank you,
>
> Dmitri
>
>
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
>
> R-devel at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
>
> R-devel at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> --
>
> Adrian Dusa
>
> University of Bucharest
>
> Romanian Social Data Archive
>
> Soseaua Panduri nr.90
>
> 050663 Bucharest sector 5
>
> Romania
>
>
>
>
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
>
> R-devel at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

        [[alternative HTML version deleted]]



------------------------------

Message: 10
Date: Fri, 8 Apr 2016 14:34:48 -0500
From: Hadley Wickham <h.wickham at gmail.com>
To: Adrian Du?a <dusa.adrian at unibuc.ro>
Cc: r-devel <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CABdHhvEtyz2f-v7=LQRHonh3h8hQS_hQ9_4E=Cve_QOT3QmmAQ at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

In that scenario, I would expect that QCA would suggest Venn and Venn
would suggest QCA. Then there's no circular dependency problem.

Hadley

On Fri, Apr 8, 2016 at 6:59 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> Hi Mark,
>
> Uhm... sometimes this is not always possible.
> For example I have a package QCA which produces truth tables (all
> combinations of presence / absence of causal conditions), and it uses the
> venn package to draw a Venn diagram.
> It is debatable if one should assimilate the "venn" package into the QCA
> package (other people might want Venn diagrams but not necessarily the
> other QCA functions).
>
> On the other hand, the package venn would like to use the QCA package to
> demonstrate its abilities to plot Venn diagrams based on truth tables
> produced by the QCA package. Both have very different purposes, yet both
> use functions from each other.
>
> So I'm with Bill Dunlap here that several smaller packages are preferable
> to one larger one, but on the other hand I can't separate those functions
> into a third package: the truth table production is very specific to the
> QCA package, while plotting Venn diagrams is very specific to the venn
> package. I don't see how to separate those functions from their main
> packages and create a third one that each would depend on.
>
> This is just an example, there could be others as well, reason for which I
> am (still) looking for a solution to:
> - preserve the current functionalities in packages A and B (to follow
> Dmitri's original post)
> - be able to use functions from each other
> - yet avoid circular dependency
>
> I hope this explains it,
> Adrian
>
>
> On Thu, Apr 7, 2016 at 11:36 PM, Mark van der Loo <mark.vanderloo at gmail.com>
> wrote:
>
>> At the risk of stating the over-obvious: there's also the option of
>> creating just a single package containing all functions. None of the
>> functions that create the interdependencies need to be exported that way.
>>
>> Btw, his question is probably better at home at the r-package-devel list.
>>
>>
>> Best,
>>
>> M
>>
>>
>>
>>
>> On Thu, Apr 7, 2016, 22:24 Dmitri Popavenko <dmitri.popavenko at gmail.com>
>> wrote:
>>
>>> Hi Thierry,
>>>
>>> Thanks for that, the trouble is functions are package specific so moving
>>> from one package to another could be a solution, but I would rather save
>>> that as a last resort.
>>>
>>> As mentioned, creating a package C with all the common functions could
>>> also
>>> be an option, but this strategy quickly inflates the number of packages on
>>> CRAN. If no other option is possible, that could be the way but I was
>>> still
>>> thinking about a more direct solution if possible.
>>>
>>> Best,
>>> Dmitri
>>>
>>> On Thu, Apr 7, 2016 at 3:47 PM, Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>> > Dear Dmitri,
>>> >
>>> > If it's only a small number of functions then move them the relevant
>>> > functions for A to B so that B works without A. Then Import these
>>> functions
>>> > from B in A. Hence A depends on B but B is independent of A.
>>> >
>>> > It is requires to move a lot of functions than you better create a
>>> package
>>> > C with all the common functions. Then A and B import those functions
>>> from C.
>>> >
>>> > Best regards,
>>> >
>>> > ir. Thierry Onkelinx
>>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and
>>> > Forest
>>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> > Kliniekstraat 25
>>> > 1070 Anderlecht
>>> > Belgium
>>> >
>>> > To call in the statistician after the experiment is done may be no more
>>> > than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> > The plural of anecdote is not data. ~ Roger Brinner
>>> > The combination of some data and an aching desire for an answer does not
>>> > ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> > ~ John Tukey
>>> >
>>> > 2016-04-06 8:42 GMT+02:00 Dmitri Popavenko <dmitri.popavenko at gmail.com
>>> >:
>>> >
>>> >> Hello all,
>>> >>
>>> >> I would like to build two packages (say A and B), for two different
>>> >> purposes.
>>> >> Each of them need one or two functions from the other, which leads to
>>> the
>>> >> problem of circular dependency.
>>> >>
>>> >> Is there a way for package A to import a function from package B, and
>>> >> package B to import a function from package A, without arriving to
>>> >> circular
>>> >> dependency?
>>> >> Other suggestions in the archive mention building a third package that
>>> >> both
>>> >> A and B should depend on, but this seems less attractive.
>>> >>
>>> >> I read about importFrom() into the NAMESPACE file, but I don't know
>>> how to
>>> >> relate this with the information in the DESCRIPTION file (other than
>>> >> adding
>>> >> each package to the Depends: field).
>>> >>
>>> >> Thank you,
>>> >> Dmitri
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-devel at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



--
http://hadley.nz



------------------------------

Message: 11
Date: Sat, 9 Apr 2016 12:36:09 +0300
From: Adrian Du?a <dusa.adrian at unibuc.ro>
To: Hadley Wickham <h.wickham at gmail.com>
Cc: r-devel <r-devel at r-project.org>
Subject: Re: [Rd] (no) circular dependency
Message-ID:
        <CAJ=0CtC-aEHqhdGej-ER_usA1vCuDvAX6R5XO4vrpj9UgH_tJA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

On Fri, Apr 8, 2016 at 10:34 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> In that scenario, I would expect that QCA would suggest Venn and Venn
> would suggest QCA. Then there's no circular dependency problem.
>

Right, this is exactly what I was pointing myself in the first email:

- make package A dependent on package B (so that the namespace of B is
automatically available when loading package A)
- make package B "Suggest" package A (not "Depend" which leads to circular
dependency), and that if I am not mistaken will lead to automatically
install package A when package B is installed
- use requireNamespace("A") inside the function(s) of package B which uses
functions of package A
- directly use A::foo() inside those functions

The only trouble with "Suggest" is the namespace of A is not automatically
loaded with package B (the reverse would work because package A depends on
package B).
So the only other option that I found was to make use of requireNamespace()
and use A::foo() inside the functions of B.

Or as Hadley advices, make both packages A and B suggest each other and use
requireNamespace() inside the functions of both. That would also work.

Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

        [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------

End of R-devel Digest, Vol 158, Issue 6
***************************************


From ecortens at mtroyal.ca  Thu Mar  9 20:04:34 2017
From: ecortens at mtroyal.ca (Evan Cortens)
Date: Thu, 9 Mar 2017 12:04:34 -0700
Subject: [Rd] Possible issue with coercion in sprintf()?
Message-ID: <CABKQe-bjYEDeUUwDnnNsKUxA1n-6TGs4AgwZ8uEC4BiDpKUhug@mail.gmail.com>

Dear R-Devel folks,

I've just run into what initially struck me as a rather strange result, as
follows:

> sprintf('%d', c(1.0, NA))
[1] "1"  "NA"

> sprintf('%d', c(NA, 1.0))
Error in sprintf("%d", c(NA, 1)) :
  invalid format '%d'; use format %f, %e, %g or %a for numeric objects

So if I pass sprintf() a vector of reals and attempt to format them as
integers, it'll work if the first element in the vector is identical to
that element coerced to an integer (and not NA). In other words, for a
vector x, as.numeric(as.integer(x[0])) == x[0]. (Which is actually written
in C as R_FINITE(r) && (double)((int) r) == r, where r is the first element
of the vector.) But it won't work if the first element is NA. (Of course it
also won't work if the first element is, say, 1.1 rather than 1.0, for
obvious reasons.)

The reason for this is clear, namely, in sprintf.c, the coercion only
checks the first item in the vector (in the latest R-devel, this is line
275, if(ns == 0)).

As far as I can see, the help file for sprintf() doesn't explicitly mention
this behaviour, though it does imply that you shouldn't rely on coercion
always working, and it's better to pass the right kind of arguments/use the
right format strings. The behaviour is specifically mentioned in a comment
in the source though: "Now let us see if some minimal coercion would be
sensible, but only do so once, for ns = 0:", so it's clear this isn't some
kind of oversight or accident.

My question is basically, I wonder if in trying to be helpful by coercing
reals to integers, sprintf() might actually be making things more
confusing? Another solution here would be to never coerce: if you pass a
vector of reals with a format of "%d", it simply gives you an error,
telling you to
"use format %f, %e, %g or %a for numeric objects". Yet another possibility
is to have some special treatment for NA's, where it would check the first
non-NA element in the vector rather than the first element.

Or perhaps I'm totally off base here and this has been thoroughly discussed
in the past.

All best,

Evan

-- 
Evan Cortens, PhD
Institutional Analyst - Office of Institutional Analysis
Mount Royal University
403-440-6529

	[[alternative HTML version deleted]]


From Achim.Zeileis at R-project.org  Fri Mar 10 15:02:38 2017
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Fri, 10 Mar 2017 15:02:38 +0100 (CET)
Subject: [Rd] named arguments in formula and terms
Message-ID: <alpine.DEB.2.20.1703101437180.29309@paninaro>

Hi, we came across the following unexpected (for us) behavior in 
terms.formula: When determining whether a term is duplicated, only the 
order of the arguments in function calls seems to be checked but not their 
names. Thus the terms f(x, a = z) and f(x, b = z) are deemed to be 
duplicated and one of the terms is thus dropped.

R> attr(terms(y ~ f(x, a = z) + f(x, b = z)), "term.labels")
[1] "f(x, a = z)"

However, changing the arguments or the order of arguments keeps both 
terms:

R> attr(terms(y ~ f(x, a = z) + f(x, b = zz)), "term.labels")
[1] "f(x, a = z)"  "f(x, b = zz)"
R> attr(terms(y ~ f(x, a = z) + f(b = z, x)), "term.labels")
[1] "f(x, a = z)" "f(b = z, x)"

Is this intended behavior or needed for certain terms?

We came across this problem when setting up certain smooth regressors with 
different kinds of patterns. As a trivial simplified example we can 
generate the same kind of problem with rep(). Consider the two dummy 
variables rep(x = 0:1, each = 4) and rep(x = 0:1, times = 4). With the 
response y = 1:8 I get:

R> lm((1:8) ~ rep(x = 0:1, each = 4) + rep(x = 0:1, times = 4))

Call:
lm(formula = (1:8) ~ rep(x = 0:1, each = 4) + rep(x = 0:1, times = 4))

Coefficients:
            (Intercept)  rep(x = 0:1, each = 4)
                    2.5                     4.0

So while the model is identified because the two regressors are not the 
same, terms.fomula does not recognize this and drops the second regressor. 
What I would have wanted can be obtained by switching the arguments:

R> lm((1:8) ~ rep(each = 4, x = 0:1) + rep(x = 0:1, times = 4))

Call:
lm(formula = (1:8) ~ rep(each = 4, x = 0:1) + rep(x = 0:1, times = 4))

Coefficients:
             (Intercept)   rep(each = 4, x = 0:1)  rep(x = 0:1, times = 4)
                       2                        4                        1

Of course, here I could avoid the problem by setting up proper factors 
etc. But to me this looks a potential bug in terms.formula...

Thanks in advance for any insights,
Z


From rbaer at atsu.edu  Sat Mar 11 18:17:15 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 11 Mar 2017 11:17:15 -0600
Subject: [Rd] Possible issue with R-tools on Windows
Message-ID: <a0736ca8-0665-4067-e337-6489f55b8fcc@atsu.edu>

This is a bit of a cross-post but I've encountered what appears to be a 
parsing error with RTools on Windows in a couple of different contexts 
on Widows when R is installed on a secondary drive to avoid using 
precious space on my c:/ solid state drive.

This type of apparent parsing error has has occurred several times 
previously when install source code from GitHub, and most recently when 
installing Bioconductor code.  It occurred that this list might have 
input directed at RTools on Windows, if this is indeed my problem

Here's the full example of my most recent encounter posted to 
bioconductor: https://support.bioconductor.org/p/93731/

In brief the parsing seems to break in the space in the path name:

The downloaded source packages are in
     ?C:\Users\Rob Baer\AppData\Local\Temp\RtmpagJM0a\downloaded_packages?
Warning messages:
1: running command '"E:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL 
-l "C:\Users\Rob Baer\R\win-library\3.3" 
C:\Users\ROBBAE~1\AppData\Local\Temp\RtmpagJM0a/downloaded_packages/GO.db_3.4.0.tar.gz' 
had status 1
2: In install.packages(update[instlib == l, "Package"], l, repos = repos,  :
   installation of package ?GO.db? had non-zero exit status

Is there something going on with my RTools installation I should 
upgrade?  My apologies if this is too off-topic for this list.


From ligges at statistik.tu-dortmund.de  Sun Mar 12 12:02:12 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 12 Mar 2017 12:02:12 +0100
Subject: [Rd] Possible issue with R-tools on Windows
In-Reply-To: <a0736ca8-0665-4067-e337-6489f55b8fcc@atsu.edu>
References: <a0736ca8-0665-4067-e337-6489f55b8fcc@atsu.edu>
Message-ID: <4bb43fa3-17ea-cb28-58af-67d6028eac92@statistik.tu-dortmund.de>

Hmmm, you may know winbuilder: It has R not installed oin drive C: and 
works well. Even with R installed on a network share I can easily 
install packages.

using R-devel binary in, e.g. for 64 bit: in d:/RCompile/recent/R/bin/x64

working directory: d:/library-devel

specified library: c:/tmp



 > install.packages("GO.db", lib="c:/tmp")
installing the source package ?GO.db?

trying URL 
'https://bioconductor.org/packages/3.5/data/annotation/src/contrib/GO.db_3.4.0.tar.gz'
Content type 'application/x-gzip' length 31897756 bytes (30.4 MB)
downloaded 30.4 MB

* installing *source* package 'GO.db' ...
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* DONE (GO.db)

The downloaded source packages are in
         ?d:\temp\RtmpKaYI2t\downloaded_packages?


So we really need the full log.

Can you please run the installation from the OS shell, i.e. something like:

R CMD INSTALL --library=c:/tmp GO.db_3.4.0.tar.gz

and send us the install.log

Best,
Uwe Ligges



On 11.03.2017 18:17, Robert Baer wrote:
> This is a bit of a cross-post but I've encountered what appears to be a
> parsing error with RTools on Windows in a couple of different contexts
> on Widows when R is installed on a secondary drive to avoid using
> precious space on my c:/ solid state drive.
>
> This type of apparent parsing error has has occurred several times
> previously when install source code from GitHub, and most recently when
> installing Bioconductor code.  It occurred that this list might have
> input directed at RTools on Windows, if this is indeed my problem
>
> Here's the full example of my most recent encounter posted to
> bioconductor: https://support.bioconductor.org/p/93731/
>
> In brief the parsing seems to break in the space in the path name:
>
> The downloaded source packages are in
>     ?C:\Users\Rob Baer\AppData\Local\Temp\RtmpagJM0a\downloaded_packages?
> Warning messages:
> 1: running command '"E:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL
> -l "C:\Users\Rob Baer\R\win-library\3.3"
> C:\Users\ROBBAE~1\AppData\Local\Temp\RtmpagJM0a/downloaded_packages/GO.db_3.4.0.tar.gz'
> had status 1
> 2: In install.packages(update[instlib == l, "Package"], l, repos =
> repos,  :
>   installation of package ?GO.db? had non-zero exit status
>
> Is there something going on with my RTools installation I should
> upgrade?  My apologies if this is too off-topic for this list.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From georgi.boshnakov at manchester.ac.uk  Sun Mar 12 16:58:09 2017
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Sun, 12 Mar 2017 15:58:09 +0000
Subject: [Rd] . Possible issue with R-tools on Windows
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F5DAE89@MBXP02.ds.man.ac.uk>

I encountered this issue a couple of months ago and resolved it by installing Rtools in the default directory
C:\Rtools, see below for details. I didn't have time to prepare a proper error report and in fact suspected that I may be messing up something.

I tracked down the error by installing from the command line, rather than with install.packages().

On Windows I keep multiple versions of Rtools  (and R) 
and start a command window with a batch file which has something like the following at its start: 

set Rroot=c:\ProgramF\R\R-3.3.2patched
set RtoolsRoot=c:\PROGRAMF\R\Rtools3p3

To change the R version I simply copy the file and change the above two lines correspondingly.
This worked for years until recently when

> R CMD INSTALL Countr_3.2.8.tar.gz

Produced an error:

....
c:/Rtools/mingw_32/bin/g++: not found
...

(notice that the installer looks in c:/Rtools for g++)

I knew and checked again that the path to Rtools was passed correctly.
I dealt with this by installing Rtools in c:\Rtools and changing the above line in the batch file to:

REM was: set RtoolsRoot=c:\PROGRAMF\R\Rtools3p3
set RtoolsRoot=c:\Rtools

and everything worked.

Hope this helps.

Best regards,
Georgi Boshnakov



-----Original Message-----

Date: Sat, 11 Mar 2017 11:17:15 -0600
From: Robert Baer <rbaer at atsu.edu>
To: "'r-devel at r-project.org'" <r-devel at r-project.org>
Subject: [Rd] Possible issue with R-tools on Windows
Message-ID: <a0736ca8-0665-4067-e337-6489f55b8fcc at atsu.edu>
Content-Type: text/plain; charset=utf-8; format=flowed

This is a bit of a cross-post but I've encountered what appears to be a parsing error with RTools on Windows in a couple of different contexts on Widows when R is installed on a secondary drive to avoid using precious space on my c:/ solid state drive.

This type of apparent parsing error has has occurred several times previously when install source code from GitHub, and most recently when installing Bioconductor code.  It occurred that this list might have input directed at RTools on Windows, if this is indeed my problem

Here's the full example of my most recent encounter posted to
bioconductor: https://support.bioconductor.org/p/93731/

In brief the parsing seems to break in the space in the path name:

The downloaded source packages are in
     ?C:\Users\Rob Baer\AppData\Local\Temp\RtmpagJM0a\downloaded_packages?
Warning messages:
1: running command '"E:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL -l "C:\Users\Rob Baer\R\win-library\3.3" 
C:\Users\ROBBAE~1\AppData\Local\Temp\RtmpagJM0a/downloaded_packages/GO.db_3.4.0.tar.gz' 
had status 1
2: In install.packages(update[instlib == l, "Package"], l, repos = repos,  :
   installation of package ?GO.db? had non-zero exit status

Is there something going on with my RTools installation I should upgrade?  My apologies if this is too off-topic for this list.



------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------

End of R-devel Digest, Vol 169, Issue 12


From ligges at statistik.tu-dortmund.de  Sun Mar 12 18:38:25 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 12 Mar 2017 18:38:25 +0100
Subject: [Rd] . Possible issue with R-tools on Windows
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E018F5DAE89@MBXP02.ds.man.ac.uk>
References: <438D2EC9EAFE5946B2D5864670EA468E018F5DAE89@MBXP02.ds.man.ac.uk>
Message-ID: <274df480-c94b-6e82-f91b-b06dca111d3a@statistik.tu-dortmund.de>



On 12.03.2017 16:58, Georgi Boshnakov wrote:
> I encountered this issue a couple of months ago and resolved it by installing Rtools in the default directory
> C:\Rtools, see below for details. I didn't have time to prepare a proper error report and in fact suspected that I may be messing up something.
>
> I tracked down the error by installing from the command line, rather than with install.packages().
>
> On Windows I keep multiple versions of Rtools  (and R)
> and start a command window with a batch file which has something like the following at its start:
>
> set Rroot=c:\ProgramF\R\R-3.3.2patched
> set RtoolsRoot=c:\PROGRAMF\R\Rtools3p3
>
> To change the R version I simply copy the file and change the above two lines correspondingly.
> This worked for years until recently when
>
>> R CMD INSTALL Countr_3.2.8.tar.gz
>
> Produced an error:
>
> ....
> c:/Rtools/mingw_32/bin/g++: not found
> ...
>
> (notice that the installer looks in c:/Rtools for g++)
>
> I knew and checked again that the path to Rtools was passed correctly.
> I dealt with this by installing Rtools in c:\Rtools and changing the above line in the batch file to:
>
> REM was: set RtoolsRoot=c:\PROGRAMF\R\Rtools3p3
> set RtoolsRoot=c:\Rtools
>
> and everything worked.


Well, The toolkchain is now split into two parts, one for 32-bit, one 
for 64-bit.
So we have 2 versions of gcc and freinds, this is set in files 
.../etc/x64/Makeconf and .../etc/i386/Makeconf respectively  in the variable
BINPREF.

Best,
Uwe Ligges


>
> Hope this helps.
>
> Best regards,
> Georgi Boshnakov
>
>
>
> -----Original Message-----
>
> Date: Sat, 11 Mar 2017 11:17:15 -0600
> From: Robert Baer <rbaer at atsu.edu>
> To: "'r-devel at r-project.org'" <r-devel at r-project.org>
> Subject: [Rd] Possible issue with R-tools on Windows
> Message-ID: <a0736ca8-0665-4067-e337-6489f55b8fcc at atsu.edu>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
> This is a bit of a cross-post but I've encountered what appears to be a parsing error with RTools on Windows in a couple of different contexts on Widows when R is installed on a secondary drive to avoid using precious space on my c:/ solid state drive.
>
> This type of apparent parsing error has has occurred several times previously when install source code from GitHub, and most recently when installing Bioconductor code.  It occurred that this list might have input directed at RTools on Windows, if this is indeed my problem
>
> Here's the full example of my most recent encounter posted to
> bioconductor: https://support.bioconductor.org/p/93731/
>
> In brief the parsing seems to break in the space in the path name:
>
> The downloaded source packages are in
>      ?C:\Users\Rob Baer\AppData\Local\Temp\RtmpagJM0a\downloaded_packages?
> Warning messages:
> 1: running command '"E:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL -l "C:\Users\Rob Baer\R\win-library\3.3"
> C:\Users\ROBBAE~1\AppData\Local\Temp\RtmpagJM0a/downloaded_packages/GO.db_3.4.0.tar.gz'
> had status 1
> 2: In install.packages(update[instlib == l, "Package"], l, repos = repos,  :
>    installation of package ?GO.db? had non-zero exit status
>
> Is there something going on with my RTools installation I should upgrade?  My apologies if this is too off-topic for this list.
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-devel at r-project.org mailing list  DIGESTED
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ------------------------------
>
> End of R-devel Digest, Vol 169, Issue 12
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rbaer at atsu.edu  Sun Mar 12 20:23:52 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 12 Mar 2017 14:23:52 -0500
Subject: [Rd] Possible issue with R-tools on Windows - Amend subject to
 RTerm issue
In-Reply-To: <4bb43fa3-17ea-cb28-58af-67d6028eac92@statistik.tu-dortmund.de>
References: <a0736ca8-0665-4067-e337-6489f55b8fcc@atsu.edu>
	<4bb43fa3-17ea-cb28-58af-67d6028eac92@statistik.tu-dortmund.de>
Message-ID: <eb0e972e-6272-410f-37c1-6f27c5c615c9@atsu.edu>

Because my response is a little long and summarizes original thread is 
at bottom.

Okay, I tried to implement your test (and the package is installed).  My 
discovery is that it was RTerm and not
RTools giving me a problem.

Summary: RTerm starts fine if installed on C: even if there is a space 
in the path.
RTerm starts fine on E: drive if there is no space in the path, but 
fails to start if there is a space in the path.
Because of the R versions I happened to have, this was checked using a 
combination of R-3.3.1, R-3.3.2, and R-3.3.3.
I know for surethat RTerm for R-3.3.2 and R-3.3.3 fails to start from 
the command prompt in E:/prgram Files/R/R-3.3.x/bin
suggesting that R-dev should be tested.

For completeness here is what happened in a couple of circumstances:

Windows 10
I tried starting RTerm for various R versions in the following install 
locations:
C:/program files/R/R-3.3.1/bin - Works
E:/Program Files/R/R-3.3.3/bin - Fails
E:/Program/R/R-3.3.3/bin/ - Works
C:/Program Files/R/R-3.3.1/bin - Works

Microsoft Windows [Version 10.0.14393]
(c) 2016 Microsoft Corporation. All rights reserved.

=====================================================================================
RTerm will start (at least an older version) in a path containing spaces ...

R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

 > q()
Save workspace image? [y/n/c]: n
====================================================================================
Current RTerm won't start if on E: dirve in a path containing spaces ...
C:\Program Files\R\R-3.3.1\bin>e:

E:\Program Files\R\R-3.3.3\bin>R
'E:\Program' is not recognized as an internal or external command,
operable program or batch file.

E:\Program Files\R\R-3.3.3\bin>dir
  Volume in drive E is Baer_HardDrive
  Volume Serial Number is F890-9E98

  Directory of E:\Program Files\R\R-3.3.3\bin

03/11/2017  10:57 AM    <DIR>          .
03/11/2017  10:57 AM    <DIR>          ..
03/06/2017  04:00 PM             9,712 config.sh
03/11/2017  10:57 AM    <DIR>          i386
03/06/2017  04:07 PM            88,576 R.exe
03/06/2017  04:07 PM            88,576 Rscript.exe
03/11/2017  10:57 AM    <DIR>          x64
                3 File(s)        186,864 bytes
                4 Dir(s)  262,685,499,392 bytes free

E:\Program Files\R\R-3.3.3\bin>

=============================================================================
And finally current RTerm works on C: in a path with spaces ...


c:\Program Files\R\R-3.3.3\bin>R

R version 3.3.3 (2017-03-06) -- "Another Canoe"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


On 3/12/2017 6:02 AM, Uwe Ligges wrote:
> Hmmm, you may know winbuilder: It has R not installed oin drive C: and 
> works well. Even with R installed on a network share I can easily 
> install packages.
>
> using R-devel binary in, e.g. for 64 bit: in d:/RCompile/recent/R/bin/x64
>
> working directory: d:/library-devel
>
> specified library: c:/tmp
>
>
>
> > install.packages("GO.db", lib="c:/tmp")
> installing the source package ?GO.db?
>
> trying URL 
> 'https://bioconductor.org/packages/3.5/data/annotation/src/contrib/GO.db_3.4.0.tar.gz'
> Content type 'application/x-gzip' length 31897756 bytes (30.4 MB)
> downloaded 30.4 MB
>
> * installing *source* package 'GO.db' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> *** arch - i386
> *** arch - x64
> * DONE (GO.db)
>
> The downloaded source packages are in
>         ?d:\temp\RtmpKaYI2t\downloaded_packages?
>
>
> So we really need the full log.
>
> Can you please run the installation from the OS shell, i.e. something 
> like:
>
> R CMD INSTALL --library=c:/tmp GO.db_3.4.0.tar.gz
>
> and send us the install.log
>
> Best,
> Uwe Ligges
>
>
>
> On 11.03.2017 18:17, Robert Baer wrote:
>> This is a bit of a cross-post but I've encountered what appears to be a
>> parsing error with RTools on Windows in a couple of different contexts
>> on Widows when R is installed on a secondary drive to avoid using
>> precious space on my c:/ solid state drive.
>>
>> This type of apparent parsing error has has occurred several times
>> previously when install source code from GitHub, and most recently when
>> installing Bioconductor code.  It occurred that this list might have
>> input directed at RTools on Windows, if this is indeed my problem
>>
>> Here's the full example of my most recent encounter posted to
>> bioconductor: https://support.bioconductor.org/p/93731/
>>
>> In brief the parsing seems to break in the space in the path name:
>>
>> The downloaded source packages are in
>>     ?C:\Users\Rob 
>> Baer\AppData\Local\Temp\RtmpagJM0a\downloaded_packages?
>> Warning messages:
>> 1: running command '"E:/Program Files/R/R-3.3.3/bin/x64/R" CMD INSTALL
>> -l "C:\Users\Rob Baer\R\win-library\3.3"
>> C:\Users\ROBBAE~1\AppData\Local\Temp\RtmpagJM0a/downloaded_packages/GO.db_3.4.0.tar.gz' 
>>
>> had status 1
>> 2: In install.packages(update[instlib == l, "Package"], l, repos =
>> repos,  :
>>   installation of package ?GO.db? had non-zero exit status
>>
>> Is there something going on with my RTools installation I should
>> upgrade?  My apologies if this is too off-topic for this list.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Mon Mar 13 10:16:25 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 13 Mar 2017 10:16:25 +0100
Subject: [Rd] named arguments in formula and terms
In-Reply-To: <alpine.DEB.2.20.1703101437180.29309@paninaro>
References: <alpine.DEB.2.20.1703101437180.29309@paninaro>
Message-ID: <22726.25449.730959.7744@stat.math.ethz.ch>

Dear Achim,

>>>>> Achim Zeileis <Achim.Zeileis at r-project.org>
>>>>>     on Fri, 10 Mar 2017 15:02:38 +0100 writes:

    > Hi, we came across the following unexpected (for us)
    > behavior in terms.formula: When determining whether a term
    > is duplicated, only the order of the arguments in function
    > calls seems to be checked but not their names. Thus the
    > terms f(x, a = z) and f(x, b = z) are deemed to be
    > duplicated and one of the terms is thus dropped.

    R> attr(terms(y ~ f(x, a = z) + f(x, b = z)), "term.labels")
    > [1] "f(x, a = z)"

    > However, changing the arguments or the order of arguments
    > keeps both terms:

    R> attr(terms(y ~ f(x, a = z) + f(x, b = zz)), "term.labels")
    > [1] "f(x, a = z)" "f(x, b = zz)"
    R> attr(terms(y ~ f(x, a = z) + f(b = z, x)), "term.labels")
    > [1] "f(x, a = z)" "f(b = z, x)"

    > Is this intended behavior or needed for certain terms?

    > We came across this problem when setting up certain smooth
    > regressors with different kinds of patterns. As a trivial
    > simplified example we can generate the same kind of
    > problem with rep(). Consider the two dummy variables rep(x
    > = 0:1, each = 4) and rep(x = 0:1, times = 4). With the
    > response y = 1:8 I get:

    R> lm((1:8) ~ rep(x = 0:1, each = 4) + rep(x = 0:1, times = 4))

    > Call: lm(formula = (1:8) ~ rep(x = 0:1, each = 4) + rep(x
    > = 0:1, times = 4))

    > Coefficients: (Intercept) rep(x = 0:1, each = 4) 2.5 4.0

    > So while the model is identified because the two
    > regressors are not the same, terms.fomula does not
    > recognize this and drops the second regressor.  What I
    > would have wanted can be obtained by switching the
    > arguments:

    R> lm((1:8) ~ rep(each = 4, x = 0:1) + rep(x = 0:1, times =4))

    > Call: lm(formula = (1:8) ~ rep(each = 4, x = 0:1) + rep(x
    > = 0:1, times = 4))

    > Coefficients: (Intercept) rep(each = 4, x = 0:1) rep(x =
    > 0:1, times = 4) 2 4 1

    > Of course, here I could avoid the problem by setting up
    > proper factors etc. But to me this looks a potential bug
    > in terms.formula...

I agree that there is a bug.
According to https://www.r-project.org/bugs.html
I have generated an R bugzilla account for you so you can report
it there (for "book keeping", posteriority, etc).

    > Thanks in advance for any insights, Z

and thank *you* (and Nikolaus ?) for the report!

Best regards,
Martin


From Achim.Zeileis at uibk.ac.at  Mon Mar 13 16:26:16 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 13 Mar 2017 16:26:16 +0100 (CET)
Subject: [Rd] named arguments in formula and terms
In-Reply-To: <22726.25449.730959.7744@stat.math.ethz.ch>
References: <alpine.DEB.2.20.1703101437180.29309@paninaro>
	<22726.25449.730959.7744@stat.math.ethz.ch>
Message-ID: <alpine.DEB.2.20.1703131621370.15747@paninaro>

Martin, thanks for the follow-up!

On Mon, 13 Mar 2017, Martin Maechler wrote:

> Dear Achim,
>
>>>>>> Achim Zeileis <Achim.Zeileis at r-project.org>
>>>>>>     on Fri, 10 Mar 2017 15:02:38 +0100 writes:
>
>    > Hi, we came across the following unexpected (for us)
>    > behavior in terms.formula: When determining whether a term
>    > is duplicated, only the order of the arguments in function
>    > calls seems to be checked but not their names. Thus the
>    > terms f(x, a = z) and f(x, b = z) are deemed to be
>    > duplicated and one of the terms is thus dropped.
>
>    R> attr(terms(y ~ f(x, a = z) + f(x, b = z)), "term.labels")
>    > [1] "f(x, a = z)"
>
>    > However, changing the arguments or the order of arguments
>    > keeps both terms:
>
>    R> attr(terms(y ~ f(x, a = z) + f(x, b = zz)), "term.labels")
>    > [1] "f(x, a = z)" "f(x, b = zz)"
>    R> attr(terms(y ~ f(x, a = z) + f(b = z, x)), "term.labels")
>    > [1] "f(x, a = z)" "f(b = z, x)"
>
>    > Is this intended behavior or needed for certain terms?
>
>    > We came across this problem when setting up certain smooth
>    > regressors with different kinds of patterns. As a trivial
>    > simplified example we can generate the same kind of
>    > problem with rep(). Consider the two dummy variables rep(x
>    > = 0:1, each = 4) and rep(x = 0:1, times = 4). With the
>    > response y = 1:8 I get:
>
>    R> lm((1:8) ~ rep(x = 0:1, each = 4) + rep(x = 0:1, times = 4))
>
>    > Call: lm(formula = (1:8) ~ rep(x = 0:1, each = 4) + rep(x
>    > = 0:1, times = 4))
>
>    > Coefficients: (Intercept) rep(x = 0:1, each = 4) 2.5 4.0
>
>    > So while the model is identified because the two
>    > regressors are not the same, terms.fomula does not
>    > recognize this and drops the second regressor.  What I
>    > would have wanted can be obtained by switching the
>    > arguments:
>
>    R> lm((1:8) ~ rep(each = 4, x = 0:1) + rep(x = 0:1, times =4))
>
>    > Call: lm(formula = (1:8) ~ rep(each = 4, x = 0:1) + rep(x
>    > = 0:1, times = 4))
>
>    > Coefficients: (Intercept) rep(each = 4, x = 0:1) rep(x =
>    > 0:1, times = 4) 2 4 1
>
>    > Of course, here I could avoid the problem by setting up
>    > proper factors etc. But to me this looks a potential bug
>    > in terms.formula...
>
> I agree that there is a bug.

OK, good. I just wasn't sure whether I had missed some documentation 
somewhere that this is intended behavior.

> According to https://www.r-project.org/bugs.html
> I have generated an R bugzilla account for you so you can report
> it there (for "book keeping", posteriority, etc).

Thanks, I had already looked at that but waited for feedback on this list 
first.

>    > Thanks in advance for any insights, Z
>
> and thank *you* (and Nikolaus ?) for the report!

No problem. Niki found the problem and I came up with the simplified 
example. In any case, I just posted a slightly modified version of my 
e-mail as #17235 on Bugzilla:

https://bugs.R-project.org/bugzilla/show_bug.cgi?id=17235

Thanks & best wishes,
Z


> Best regards,
> Martin
>
>


From frederik at ofb.net  Mon Mar 13 17:15:19 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 13 Mar 2017 16:15:19 -0000
Subject: [Rd] strptime("1","%m") returns NA
In-Reply-To: <1484660111.26811.26.camel@iarc.fr>
References: <20170111014855.GI29294@ofb.net> <20170117022058.GB29294@ofb.net>
	<1484660111.26811.26.camel@iarc.fr>
Message-ID: <20170117162635.GD29294@ofb.net>

Hi Martyn,

Thanks for finding that stuff in the documentation, and apologies for
not reading the whole thing carefully. I guess when I got to the
minutiae about printing years before '999', I started to skim.

My vote is for more sensible / standard behavior, but I guess this has
probably been this way for a long time.

Frederick

On Tue, Jan 17, 2017 at 01:35:35PM +0000, Martyn Plummer wrote:
> Hi Frederik,
> 
> On Mon, 2017-01-16 at 18:20 -0800, frederik at ofb.net wrote:
> > Hi R Devel,
> > 
> > I wrote some code which depends on 'strptime' being able to parse an
> > incomplete date, like this:
> > 
> > > 
> > > base::strptime("2016","%Y")
> > [1] "2016-01-14 PST"
> > 
> > The above works - although it's odd that it gives the month and day
> > for Sys.time(). I might expect it to set them both to zero as the GNU
> > libc strptime does on my system, or to use January 1 which would also
> > be reasonable.
> 
> From the help page for strptime:
> 
> "For ?strptime? the input string need not specify the date completely:
> it is assumed that unspecified seconds, minutes or hours are zero, and
> an unspecified year, month or day is the current one."
> ?
> > When I specify the month, however, I get NA:
> > 
> > > 
> > > base::strptime("2016-12","%Y-%m")
> > [1] NA
> > > 
> > > base::strptime("1", "%m")
> > [1] NA
> > 
> > Any reason for this to be the case?
> 
> Also from the help page:
> 
> "(However, if a month is specified, the day of that month has to be
> specified by ?%d? or ?%e? since the current day of the month need not
> be valid for the specified month.)"
> 
> If strptime("2016-2", "%Y-%m") just filled in the current day then it
> would give valid output when called on the 1st to the 28th of each
> month, but would give either invalid output or fail when called on the
> 29th to the 31st of any month. This would be a nightmare to debug. The
> current behaviour lets you know there is a logical problem with your
> input.
> 
> > I reported a bug here:
> > 
> > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17212
> > 
> > but I don't think I'm getting emails from Bugzilla so maybe best to
> > ping me if anyone replies there instead.
> 
> See the general guidance on submitting bug reports:
> 
> "Code doing something unexpected is not necessarily a bug - make sure to carefully review the documentation for the function you are calling to see if the behaviour it exhibits is what it was designed to do, even if it?s not what you want."
> 
> https://www.r-project.org/bugs.html
> 
> 
> Martyn
> 
> > I've just written a simple reimplementation of 'strptime' for my own
> > use; I hope this bug report may be useful to others.
> > 
> > Thank you,
> > 
> > Frederick
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Mon Mar 13 19:10:23 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Mar 2017 11:10:23 -0700
Subject: [Rd] simplify2array(higher=TRUE, listOfSingleRowDataframes)
Message-ID: <CAF8bMcaZCn6zObOStYUL+W8AP=OdjA8HMq6OtB52CTtT6X6Org@mail.gmail.com>

I noticed that simplify2array acted oddly when given a list of
data.frames of various sizes.  If the data.frames have one row, it
makes a new first dimension with the dimname equal to
rownames(firstDataframe).  That dimension does not appear for
data.frames with other numbers of rows.

> str(dimnames(sapply(345:346, function(i)data.frame(X=101, Y=201, row.names=paste0("Row",1)), simplify="array")))
List of 3
 $ : chr "Row1"
 $ : chr [1:2] "X" "Y"
 $ : NULL
> str(dimnames(sapply(345:346, function(i)data.frame(X=numeric(), Y=numeric(0), row.names=character()), simplify="array")))
List of 2
 $ : chr [1:2] "X" "Y"
 $ : NULL
> str(dimnames(sapply(345:346, function(i)data.frame(X=101:102, Y=201:202, row.names=paste0("Row",1:2)), simplify="array")))
List of 2
 $ : chr [1:2] "X" "Y"
 $ : NULL

The extra dimension does not appear if I convert those data.frames to lists.

It does appear if I convert those data.frames to matrices and the
number of rows is not zero (in which case there are no dims or
dimnames).

Is this pattern of behavior intended?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


From gm at presans.com  Wed Mar 15 12:01:24 2017
From: gm at presans.com (Guillaume MULLER)
Date: Wed, 15 Mar 2017 12:01:24 +0100
Subject: [Rd] Error: memory exhausted (limit reached?)
In-Reply-To: <CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>
References: <CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>
Message-ID: <9e04a67f-5afd-020c-98d6-694fda48b59a@presans.com>

Hi,

I first posted this message on r-help, but got redirected here.

I encounter a strange memory error, and I'd like some help to determine if I'm doing something wrong or if there's a bug in recent R versions...

I'm currently working on a DeepNet project @home, with an old PC with 4Gb RAM, running Ubuntu 16.04.

For efficiency reason, I preprocessed my dataset and stored it as a csv file with write.csv() so that I can reload it at will with read.csv(). I did it several time, everything was working fine.

A few days ago, I tried to pursue my work on anther machine @work, I wanted to use a more recent & powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:

$ R
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)
Error: C stack usage  7970548 is too close to the limit


I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:

$ ulimit -s
8192
$ ulimit -s $((100*$(ulimit -s)))
$ R --vanilla
16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
Error: memory exhausted (limit reached?)


This was under Ubuntu 16.10 with R version 3.3.1 (2016-06-21) "Bug in Your Hair"

Yesterday, I upgraded my Ubuntu to 17.04 (R version 3.3.2 (2016-10-31) "Sincere Pumpkin Patch") and tried again. This resulted in the exact same error.

How is it possible that a 513MB file cannot be read on a machine with 8GB RAM?
Also, how is it possible that a machine with twice the RAM as the previous one cannot load the same file?

Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug in R/csv loader, but I don't know where to look for...

If anyone has an idea I would be glad to hear it...


GM
--------

For the sake of completeness, I share my Trainset at the following link:
> https://mega.nz/#!ZMs0TSRJ!47DCZCnE6_FnICUp8MVS2R9eY_GdVIyGZ5O9TiejHfc

FYI, it loads perfectly on 2 machines with Ubuntu 16.04 and R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree". But exceededs stack mem under Ubuntu 16.10's R version 3.3.1 (2016-06-21) -- "Bug in Your Hair" and Ubuntu to 17.04's R version 3.3.2 (2016-10-31) "Sincere Pumpkin Patch".


From tomas.kalibera at gmail.com  Wed Mar 15 13:01:25 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Wed, 15 Mar 2017 13:01:25 +0100
Subject: [Rd] Error: memory exhausted (limit reached?)
In-Reply-To: <9e04a67f-5afd-020c-98d6-694fda48b59a@presans.com>
References: <CAGxFJbRkp-1RqiWr9CZ88RbCRtN8fa3Hmz9x+fAUtBeWc-LF8A@mail.gmail.com>
	<9e04a67f-5afd-020c-98d6-694fda48b59a@presans.com>
Message-ID: <932c44c7-5039-7356-c9ae-ac63b1810043@gmail.com>

Hi Guillaume,

the error "C stack usage is too close to the limit" is usually caused by 
infinite recursion.
It can also be caused by an external library that corrupts the C stack 
(such as Java on Linux, e.g. when using rJava).

I cannot repeat the problem on my machine.

To rule out the second option, you can try in a fresh R session without 
loading any packages (check with sessionInfo).
To diagnose the first option one would need to know if and where the 
infinite recursion happens, which can be found with gdb on a machine 
where the problem can be repeated.

Best
Tomas


On 03/15/2017 12:01 PM, Guillaume MULLER wrote:
> Hi,
>
> I first posted this message on r-help, but got redirected here.
>
> I encounter a strange memory error, and I'd like some help to determine if I'm doing something wrong or if there's a bug in recent R versions...
>
> I'm currently working on a DeepNet project @home, with an old PC with 4Gb RAM, running Ubuntu 16.04.
>
> For efficiency reason, I preprocessed my dataset and stored it as a csv file with write.csv() so that I can reload it at will with read.csv(). I did it several time, everything was working fine.
>
> A few days ago, I tried to pursue my work on anther machine @work, I wanted to use a more recent & powerful machine with 8Gb of RAM running under Ubuntu 16.10, but I ran into a strange error:
>
> $ R
> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
> Error: memory exhausted (limit reached?)
> Error: C stack usage  7970548 is too close to the limit
>
>
> I read a few fora on the Internet and found a potential workaround, consisting in increasing the stack size using ulimit. Unfortunately, it doesn't work for me:
>
> $ ulimit -s
> 8192
> $ ulimit -s $((100*$(ulimit -s)))
> $ R --vanilla
> 16:05:12 R > trainSet <- read.csv("trainSetWhole.csv")
> Error: memory exhausted (limit reached?)
>
>
> This was under Ubuntu 16.10 with R version 3.3.1 (2016-06-21) "Bug in Your Hair"
>
> Yesterday, I upgraded my Ubuntu to 17.04 (R version 3.3.2 (2016-10-31) "Sincere Pumpkin Patch") and tried again. This resulted in the exact same error.
>
> How is it possible that a 513MB file cannot be read on a machine with 8GB RAM?
> Also, how is it possible that a machine with twice the RAM as the previous one cannot load the same file?
>
> Since the only other difference is the Ubuntu version (thus R version), I assume there's a bug in R/csv loader, but I don't know where to look for...
>
> If anyone has an idea I would be glad to hear it...
>
>
> GM
> --------
>
> For the sake of completeness, I share my Trainset at the following link:
>> https://mega.nz/#!ZMs0TSRJ!47DCZCnE6_FnICUp8MVS2R9eY_GdVIyGZ5O9TiejHfc
> FYI, it loads perfectly on 2 machines with Ubuntu 16.04 and R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree". But exceededs stack mem under Ubuntu 16.10's R version 3.3.1 (2016-06-21) -- "Bug in Your Hair" and Ubuntu to 17.04's R version 3.3.2 (2016-10-31) "Sincere Pumpkin Patch".
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From james.f.hester at gmail.com  Thu Mar 16 15:24:14 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Thu, 16 Mar 2017 10:24:14 -0400
Subject: [Rd] Support for user defined unary functions
Message-ID: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>

R has long supported user defined binary (infix) functions, defined
with `%fun%`. A one line change [1] to R's grammar allows users to
define unary (prefix) functions in the same manner.

    `%chr%` <- function(x) as.character(x)
    `%identical%` <- function(x, y) identical(x, y)

    %chr% 100
    #> [1] "100"

    %chr% 100 %identical% "100"
    #> [1] TRUE

This seems a natural extension of the existing functionality and
requires only a minor change to the grammar. If this change seems
acceptable I am happy to provide a complete patch with suitable tests
and documentation.

[1]:
Index: src/main/gram.y
===================================================================
--- src/main/gram.y     (revision 72358)
+++ src/main/gram.y     (working copy)
@@ -357,6 +357,7 @@
        |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
 setId( $$, @$); }
        |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
 setId( $$, @$); }
        |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
 setId( $$, @$); }
+       |       SPECIAL expr                    { $$ = xxunary($1,$2);
 setId( $$, @$); }
        |       '?' expr                        { $$ = xxunary($1,$2);
 setId( $$, @$); }

        |       expr ':'  expr                  { $$ =
xxbinary($2,$1,$3);      setId( $$, @$); }


From gmbecker at ucdavis.edu  Thu Mar 16 17:01:13 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 16 Mar 2017 09:01:13 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
Message-ID: <CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>

Jim,

This seems cool. Thanks for proposing it. To be concrete, he user-defined
unary operations would be of the same precedence (or just slightly below?)
built-in unary ones? So

"100" %identical% %chr% 100

would work and return TRUE under your patch?

And  with %num% <- as.numeric, then

1 + - %num% "5"

would also be legal (though quite ugly imo) and work?

Best,
~G

On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester <james.f.hester at gmail.com>
wrote:

> R has long supported user defined binary (infix) functions, defined
> with `%fun%`. A one line change [1] to R's grammar allows users to
> define unary (prefix) functions in the same manner.
>
>     `%chr%` <- function(x) as.character(x)
>     `%identical%` <- function(x, y) identical(x, y)
>
>     %chr% 100
>     #> [1] "100"
>
>     %chr% 100 %identical% "100"
>     #> [1] TRUE
>
> This seems a natural extension of the existing functionality and
> requires only a minor change to the grammar. If this change seems
> acceptable I am happy to provide a complete patch with suitable tests
> and documentation.
>
> [1]:
> Index: src/main/gram.y
> ===================================================================
> --- src/main/gram.y     (revision 72358)
> +++ src/main/gram.y     (working copy)
> @@ -357,6 +357,7 @@
>         |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>  setId( $$, @$); }
> +       |       SPECIAL expr                    { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '?' expr                        { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>
>         |       expr ':'  expr                  { $$ =
> xxbinary($2,$1,$3);      setId( $$, @$); }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From james.f.hester at gmail.com  Thu Mar 16 17:31:56 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Thu, 16 Mar 2017 12:31:56 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
Message-ID: <CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>

Gabe,

The unary functions have the same precedence as normal SPECIALS
(although the new unary forms take precedence over binary SPECIALS).
So they are lower precedence than unary + and -. Yes, both of your
examples are valid with this patch, here are the results and quoted
forms to see the precedence.

    `%chr%` <- function(x) as.character(x)
    `%identical%` <- function(x, y) identical(x, y)
    quote("100" %identical% %chr% 100)
    #>  "100" %identical% (`%chr%`(100))

    "100" %identical% %chr% 100
    #> [1] TRUE

    `%num%` <- as.numeric
    quote(1 + - %num% "5")
    #> 1 + -(`%num%`("5"))

    1 + - %num% "5"
    #> [1] -4

Jim

On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Jim,
>
> This seems cool. Thanks for proposing it. To be concrete, he user-defined
> unary operations would be of the same precedence (or just slightly below?)
> built-in unary ones? So
>
> "100" %identical% %chr% 100
>
> would work and return TRUE under your patch?
>
> And  with %num% <- as.numeric, then
>
> 1 + - %num% "5"
>
> would also be legal (though quite ugly imo) and work?
>
> Best,
> ~G
>
> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester <james.f.hester at gmail.com>
> wrote:
>>
>> R has long supported user defined binary (infix) functions, defined
>> with `%fun%`. A one line change [1] to R's grammar allows users to
>> define unary (prefix) functions in the same manner.
>>
>>     `%chr%` <- function(x) as.character(x)
>>     `%identical%` <- function(x, y) identical(x, y)
>>
>>     %chr% 100
>>     #> [1] "100"
>>
>>     %chr% 100 %identical% "100"
>>     #> [1] TRUE
>>
>> This seems a natural extension of the existing functionality and
>> requires only a minor change to the grammar. If this change seems
>> acceptable I am happy to provide a complete patch with suitable tests
>> and documentation.
>>
>> [1]:
>> Index: src/main/gram.y
>> ===================================================================
>> --- src/main/gram.y     (revision 72358)
>> +++ src/main/gram.y     (working copy)
>> @@ -357,6 +357,7 @@
>>         |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>> +       |       SPECIAL expr                    { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '?' expr                        { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>
>>         |       expr ':'  expr                  { $$ =
>> xxbinary($2,$1,$3);      setId( $$, @$); }
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From maechler at stat.math.ethz.ch  Thu Mar 16 17:51:36 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Mar 2017 17:51:36 +0100
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
Message-ID: <22730.49816.583399.930840@stat.math.ethz.ch>

>>>>> Jim Hester <james.f.hester at gmail.com>
>>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:

    > Gabe,
    > The unary functions have the same precedence as normal SPECIALS
    > (although the new unary forms take precedence over binary SPECIALS).
    > So they are lower precedence than unary + and -. Yes, both of your
    > examples are valid with this patch, here are the results and quoted
    > forms to see the precedence.

    > `%chr%` <- function(x) as.character(x)

  [more efficient would be     `%chr%` <- as.character]

    > `%identical%` <- function(x, y) identical(x, y)
    > quote("100" %identical% %chr% 100)
    > #>  "100" %identical% (`%chr%`(100))

    > "100" %identical% %chr% 100
    > #> [1] TRUE

    > `%num%` <- as.numeric
    > quote(1 + - %num% "5")
    > #> 1 + -(`%num%`("5"))

    > 1 + - %num% "5"
    > #> [1] -4

    > Jim

I'm sorry to be a bit of a spoiler to "coolness", but
you may know that I like to  applaud Norm Matloff for his book
title "The Art of R Programming",
because for me good code should also be beautiful to some extent.

I really very much prefer

       f(x)
to    %f% x       

and hence I really really really cannot see why anybody would prefer
the ugliness of

           1 + - %num% "5"
to
	   1 + -num("5")

(after setting  num <- as.numeric )

Martin


    > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
    >> Jim,
    >> 
    >> This seems cool. Thanks for proposing it. To be concrete, he user-defined
    >> unary operations would be of the same precedence (or just slightly below?)
    >> built-in unary ones? So
    >> 
    >> "100" %identical% %chr% 100
    >> 
    >> would work and return TRUE under your patch?
    >> 
    >> And  with %num% <- as.numeric, then
    >> 
    >> 1 + - %num% "5"
    >> 
    >> would also be legal (though quite ugly imo) and work?
    >> 
    >> Best,
    >> ~G
    >> 
    >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester <james.f.hester at gmail.com>
    >> wrote:
    >>> 
    >>> R has long supported user defined binary (infix) functions, defined
    >>> with `%fun%`. A one line change [1] to R's grammar allows users to
    >>> define unary (prefix) functions in the same manner.
    >>> 
    >>> `%chr%` <- function(x) as.character(x)
    >>> `%identical%` <- function(x, y) identical(x, y)
    >>> 
    >>> %chr% 100
    >>> #> [1] "100"
    >>> 
    >>> %chr% 100 %identical% "100"
    >>> #> [1] TRUE
    >>> 
    >>> This seems a natural extension of the existing functionality and
    >>> requires only a minor change to the grammar. If this change seems
    >>> acceptable I am happy to provide a complete patch with suitable tests
    >>> and documentation.
    >>> 
    >>> [1]:
    >>> Index: src/main/gram.y
    >>> ===================================================================
    >>> --- src/main/gram.y     (revision 72358)
    >>> +++ src/main/gram.y     (working copy)
    >>> @@ -357,6 +357,7 @@
    >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
    >>> setId( $$, @$); }
    >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
    >>> setId( $$, @$); }
    >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
    >>> setId( $$, @$); }
    >>> +       |       SPECIAL expr                    { $$ = xxunary($1,$2);
    >>> setId( $$, @$); }
    >>> |       '?' expr                        { $$ = xxunary($1,$2);
    >>> setId( $$, @$); }
    >>> 
    >>> |       expr ':'  expr                  { $$ =
    >>> xxbinary($2,$1,$3);      setId( $$, @$); }
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 
    >> 
    >> 
    >> --
    >> Gabriel Becker, PhD
    >> Associate Scientist (Bioinformatics)
    >> Genentech Research

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From gmbecker at ucdavis.edu  Thu Mar 16 18:04:59 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 16 Mar 2017 10:04:59 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <22730.49816.583399.930840@stat.math.ethz.ch>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
Message-ID: <CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>

Martin,

Jim can speak directly to his motivations; I don't claim to be able to do
so. That said, I suspect this is related to a conversation on twitter about
wanting an infix "unquote" operator in the context of the non-standard
evaluation framework Hadley Wickham and Lionel Henry (and possibly others)
are working on.

They're currently using !!! and !! for things related to this, but this
effectively requires non-standard parsing, as ~!!x is interpreted as
~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it. Others and
I pointed out this was less than desirable, but if something like it was
going to happen it would hopefully happen in the language specification,
rather than in a package (and also hopefully not using !! specifically).

Like you, I actually tend to prefer the functional form myself in most
cases. There are functional forms that would work for the above case (e.g.,
something like the .() that DBI uses), but that's probably off topic here,
and not a decision I'm directly related to anyway.

Best,
~G



On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Jim Hester <james.f.hester at gmail.com>
> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>
>     > Gabe,
>     > The unary functions have the same precedence as normal SPECIALS
>     > (although the new unary forms take precedence over binary SPECIALS).
>     > So they are lower precedence than unary + and -. Yes, both of your
>     > examples are valid with this patch, here are the results and quoted
>     > forms to see the precedence.
>
>     > `%chr%` <- function(x) as.character(x)
>
>   [more efficient would be     `%chr%` <- as.character]
>
>     > `%identical%` <- function(x, y) identical(x, y)
>     > quote("100" %identical% %chr% 100)
>     > #>  "100" %identical% (`%chr%`(100))
>
>     > "100" %identical% %chr% 100
>     > #> [1] TRUE
>
>     > `%num%` <- as.numeric
>     > quote(1 + - %num% "5")
>     > #> 1 + -(`%num%`("5"))
>
>     > 1 + - %num% "5"
>     > #> [1] -4
>
>     > Jim
>
> I'm sorry to be a bit of a spoiler to "coolness", but
> you may know that I like to  applaud Norm Matloff for his book
> title "The Art of R Programming",
> because for me good code should also be beautiful to some extent.
>
> I really very much prefer
>
>        f(x)
> to    %f% x
>
> and hence I really really really cannot see why anybody would prefer
> the ugliness of
>
>            1 + - %num% "5"
> to
>            1 + -num("5")
>
> (after setting  num <- as.numeric )
>
> Martin
>
>
>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker <
> gmbecker at ucdavis.edu> wrote:
>     >> Jim,
>     >>
>     >> This seems cool. Thanks for proposing it. To be concrete, he
> user-defined
>     >> unary operations would be of the same precedence (or just slightly
> below?)
>     >> built-in unary ones? So
>     >>
>     >> "100" %identical% %chr% 100
>     >>
>     >> would work and return TRUE under your patch?
>     >>
>     >> And  with %num% <- as.numeric, then
>     >>
>     >> 1 + - %num% "5"
>     >>
>     >> would also be legal (though quite ugly imo) and work?
>     >>
>     >> Best,
>     >> ~G
>     >>
>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester <
> james.f.hester at gmail.com>
>     >> wrote:
>     >>>
>     >>> R has long supported user defined binary (infix) functions, defined
>     >>> with `%fun%`. A one line change [1] to R's grammar allows users to
>     >>> define unary (prefix) functions in the same manner.
>     >>>
>     >>> `%chr%` <- function(x) as.character(x)
>     >>> `%identical%` <- function(x, y) identical(x, y)
>     >>>
>     >>> %chr% 100
>     >>> #> [1] "100"
>     >>>
>     >>> %chr% 100 %identical% "100"
>     >>> #> [1] TRUE
>     >>>
>     >>> This seems a natural extension of the existing functionality and
>     >>> requires only a minor change to the grammar. If this change seems
>     >>> acceptable I am happy to provide a complete patch with suitable
> tests
>     >>> and documentation.
>     >>>
>     >>> [1]:
>     >>> Index: src/main/gram.y
>     >>> ============================================================
> =======
>     >>> --- src/main/gram.y     (revision 72358)
>     >>> +++ src/main/gram.y     (working copy)
>     >>> @@ -357,6 +357,7 @@
>     >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>     >>> setId( $$, @$); }
>     >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>     >>> setId( $$, @$); }
>     >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>     >>> setId( $$, @$); }
>     >>> +       |       SPECIAL expr                    { $$ =
> xxunary($1,$2);
>     >>> setId( $$, @$); }
>     >>> |       '?' expr                        { $$ = xxunary($1,$2);
>     >>> setId( $$, @$); }
>     >>>
>     >>> |       expr ':'  expr                  { $$ =
>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>     >>>
>     >>> ______________________________________________
>     >>> R-devel at r-project.org mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>     >>
>     >>
>     >>
>     >> --
>     >> Gabriel Becker, PhD
>     >> Associate Scientist (Bioinformatics)
>     >> Genentech Research
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From james.f.hester at gmail.com  Thu Mar 16 18:51:40 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Thu, 16 Mar 2017 13:51:40 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
Message-ID: <CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>

I used the `function(x)` form to explicitly show the function was
being called with only one argument, clearly performance implications
are not relevant for these examples.

I think of this mainly as a gap in the tooling we provide users and
package authors. R has native prefix `+1`, functional `f(1)` and infix
`1 + 1` operators, but we only provide a mechanism to create user
defined functional and infix operators.

One could also argue that the user defined infix operators are also
ugly and could be replaced by `f(a, b)` calls as well; beauty is in
the eye of the beholder.

The unquote example [1] shows one example where this gap in tooling
caused authors to co-opt existing unary exclamation operator, this
same gap is part of the reason the formula [2] and question mark [3]
operators have been used elsewhere in non standard contexts.

If the language provided package authors with a native way to create
unary operators like it already does for the other operator types
these machinations would be unnecessary.

[1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
[2]: https://cran.r-project.org/package=ensurer
[3]: https://cran.r-project.org/package=types

On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Martin,
>
> Jim can speak directly to his motivations; I don't claim to be able to do
> so. That said, I suspect this is related to a conversation on twitter about
> wanting an infix "unquote" operator in the context of the non-standard
> evaluation framework Hadley Wickham and Lionel Henry (and possibly others)
> are working on.
>
> They're currently using !!! and !! for things related to this, but this
> effectively requires non-standard parsing, as ~!!x is interpreted as
> ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it. Others and
> I pointed out this was less than desirable, but if something like it was
> going to happen it would hopefully happen in the language specification,
> rather than in a package (and also hopefully not using !! specifically).
>
> Like you, I actually tend to prefer the functional form myself in most
> cases. There are functional forms that would work for the above case (e.g.,
> something like the .() that DBI uses), but that's probably off topic here,
> and not a decision I'm directly related to anyway.
>
> Best,
> ~G
>
>
>
> On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>>
>>     > Gabe,
>>     > The unary functions have the same precedence as normal SPECIALS
>>     > (although the new unary forms take precedence over binary SPECIALS).
>>     > So they are lower precedence than unary + and -. Yes, both of your
>>     > examples are valid with this patch, here are the results and quoted
>>     > forms to see the precedence.
>>
>>     > `%chr%` <- function(x) as.character(x)
>>
>>   [more efficient would be     `%chr%` <- as.character]
>>
>>     > `%identical%` <- function(x, y) identical(x, y)
>>     > quote("100" %identical% %chr% 100)
>>     > #>  "100" %identical% (`%chr%`(100))
>>
>>     > "100" %identical% %chr% 100
>>     > #> [1] TRUE
>>
>>     > `%num%` <- as.numeric
>>     > quote(1 + - %num% "5")
>>     > #> 1 + -(`%num%`("5"))
>>
>>     > 1 + - %num% "5"
>>     > #> [1] -4
>>
>>     > Jim
>>
>> I'm sorry to be a bit of a spoiler to "coolness", but
>> you may know that I like to  applaud Norm Matloff for his book
>> title "The Art of R Programming",
>> because for me good code should also be beautiful to some extent.
>>
>> I really very much prefer
>>
>>        f(x)
>> to    %f% x
>>
>> and hence I really really really cannot see why anybody would prefer
>> the ugliness of
>>
>>            1 + - %num% "5"
>> to
>>            1 + -num("5")
>>
>> (after setting  num <- as.numeric )
>>
>> Martin
>>
>>
>>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> <gmbecker at ucdavis.edu> wrote:
>>     >> Jim,
>>     >>
>>     >> This seems cool. Thanks for proposing it. To be concrete, he
>> user-defined
>>     >> unary operations would be of the same precedence (or just slightly
>> below?)
>>     >> built-in unary ones? So
>>     >>
>>     >> "100" %identical% %chr% 100
>>     >>
>>     >> would work and return TRUE under your patch?
>>     >>
>>     >> And  with %num% <- as.numeric, then
>>     >>
>>     >> 1 + - %num% "5"
>>     >>
>>     >> would also be legal (though quite ugly imo) and work?
>>     >>
>>     >> Best,
>>     >> ~G
>>     >>
>>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> <james.f.hester at gmail.com>
>>     >> wrote:
>>     >>>
>>     >>> R has long supported user defined binary (infix) functions,
>> defined
>>     >>> with `%fun%`. A one line change [1] to R's grammar allows users to
>>     >>> define unary (prefix) functions in the same manner.
>>     >>>
>>     >>> `%chr%` <- function(x) as.character(x)
>>     >>> `%identical%` <- function(x, y) identical(x, y)
>>     >>>
>>     >>> %chr% 100
>>     >>> #> [1] "100"
>>     >>>
>>     >>> %chr% 100 %identical% "100"
>>     >>> #> [1] TRUE
>>     >>>
>>     >>> This seems a natural extension of the existing functionality and
>>     >>> requires only a minor change to the grammar. If this change seems
>>     >>> acceptable I am happy to provide a complete patch with suitable
>> tests
>>     >>> and documentation.
>>     >>>
>>     >>> [1]:
>>     >>> Index: src/main/gram.y
>>     >>>
>> ===================================================================
>>     >>> --- src/main/gram.y     (revision 72358)
>>     >>> +++ src/main/gram.y     (working copy)
>>     >>> @@ -357,6 +357,7 @@
>>     >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>>     >>> setId( $$, @$); }
>>     >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>>     >>> setId( $$, @$); }
>>     >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>>     >>> setId( $$, @$); }
>>     >>> +       |       SPECIAL expr                    { $$ =
>> xxunary($1,$2);
>>     >>> setId( $$, @$); }
>>     >>> |       '?' expr                        { $$ = xxunary($1,$2);
>>     >>> setId( $$, @$); }
>>     >>>
>>     >>> |       expr ':'  expr                  { $$ =
>>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>>     >>>
>>     >>> ______________________________________________
>>     >>> R-devel at r-project.org mailing list
>>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>     >>
>>     >>
>>     >>
>>     >>
>>     >> --
>>     >> Gabriel Becker, PhD
>>     >> Associate Scientist (Bioinformatics)
>>     >> Genentech Research
>>
>>     > ______________________________________________
>>     > R-devel at r-project.org mailing list
>>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From lawrence.michael at gene.com  Thu Mar 16 23:18:00 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 16 Mar 2017 15:18:00 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
Message-ID: <CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>

I guess this would establish a separate "namespace" of symbolic prefix
operators, %*% being an example in the infix case. So you could have stuff
like %?%, but for non-symbolic (spelled out stuff like %foo%), it's hard to
see the advantage vs. foo(x).

Those examples you mention should probably be addressed (eventually) in the
core language, and it looks like people are already able to experiment, so
I'm not sure there's a significant impetus for this change.

Michael


On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
wrote:

> I used the `function(x)` form to explicitly show the function was
> being called with only one argument, clearly performance implications
> are not relevant for these examples.
>
> I think of this mainly as a gap in the tooling we provide users and
> package authors. R has native prefix `+1`, functional `f(1)` and infix
> `1 + 1` operators, but we only provide a mechanism to create user
> defined functional and infix operators.
>
> One could also argue that the user defined infix operators are also
> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
> the eye of the beholder.
>
> The unquote example [1] shows one example where this gap in tooling
> caused authors to co-opt existing unary exclamation operator, this
> same gap is part of the reason the formula [2] and question mark [3]
> operators have been used elsewhere in non standard contexts.
>
> If the language provided package authors with a native way to create
> unary operators like it already does for the other operator types
> these machinations would be unnecessary.
>
> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
> [2]: https://cran.r-project.org/package=ensurer
> [3]: https://cran.r-project.org/package=types
>
> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> > Martin,
> >
> > Jim can speak directly to his motivations; I don't claim to be able to do
> > so. That said, I suspect this is related to a conversation on twitter
> about
> > wanting an infix "unquote" operator in the context of the non-standard
> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
> others)
> > are working on.
> >
> > They're currently using !!! and !! for things related to this, but this
> > effectively requires non-standard parsing, as ~!!x is interpreted as
> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it. Others
> and
> > I pointed out this was less than desirable, but if something like it was
> > going to happen it would hopefully happen in the language specification,
> > rather than in a package (and also hopefully not using !! specifically).
> >
> > Like you, I actually tend to prefer the functional form myself in most
> > cases. There are functional forms that would work for the above case
> (e.g.,
> > something like the .() that DBI uses), but that's probably off topic
> here,
> > and not a decision I'm directly related to anyway.
> >
> > Best,
> > ~G
> >
> >
> >
> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
> > <maechler at stat.math.ethz.ch> wrote:
> >>
> >> >>>>> Jim Hester <james.f.hester at gmail.com>
> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
> >>
> >>     > Gabe,
> >>     > The unary functions have the same precedence as normal SPECIALS
> >>     > (although the new unary forms take precedence over binary
> SPECIALS).
> >>     > So they are lower precedence than unary + and -. Yes, both of your
> >>     > examples are valid with this patch, here are the results and
> quoted
> >>     > forms to see the precedence.
> >>
> >>     > `%chr%` <- function(x) as.character(x)
> >>
> >>   [more efficient would be     `%chr%` <- as.character]
> >>
> >>     > `%identical%` <- function(x, y) identical(x, y)
> >>     > quote("100" %identical% %chr% 100)
> >>     > #>  "100" %identical% (`%chr%`(100))
> >>
> >>     > "100" %identical% %chr% 100
> >>     > #> [1] TRUE
> >>
> >>     > `%num%` <- as.numeric
> >>     > quote(1 + - %num% "5")
> >>     > #> 1 + -(`%num%`("5"))
> >>
> >>     > 1 + - %num% "5"
> >>     > #> [1] -4
> >>
> >>     > Jim
> >>
> >> I'm sorry to be a bit of a spoiler to "coolness", but
> >> you may know that I like to  applaud Norm Matloff for his book
> >> title "The Art of R Programming",
> >> because for me good code should also be beautiful to some extent.
> >>
> >> I really very much prefer
> >>
> >>        f(x)
> >> to    %f% x
> >>
> >> and hence I really really really cannot see why anybody would prefer
> >> the ugliness of
> >>
> >>            1 + - %num% "5"
> >> to
> >>            1 + -num("5")
> >>
> >> (after setting  num <- as.numeric )
> >>
> >> Martin
> >>
> >>
> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
> >> <gmbecker at ucdavis.edu> wrote:
> >>     >> Jim,
> >>     >>
> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
> >> user-defined
> >>     >> unary operations would be of the same precedence (or just
> slightly
> >> below?)
> >>     >> built-in unary ones? So
> >>     >>
> >>     >> "100" %identical% %chr% 100
> >>     >>
> >>     >> would work and return TRUE under your patch?
> >>     >>
> >>     >> And  with %num% <- as.numeric, then
> >>     >>
> >>     >> 1 + - %num% "5"
> >>     >>
> >>     >> would also be legal (though quite ugly imo) and work?
> >>     >>
> >>     >> Best,
> >>     >> ~G
> >>     >>
> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
> >> <james.f.hester at gmail.com>
> >>     >> wrote:
> >>     >>>
> >>     >>> R has long supported user defined binary (infix) functions,
> >> defined
> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows users
> to
> >>     >>> define unary (prefix) functions in the same manner.
> >>     >>>
> >>     >>> `%chr%` <- function(x) as.character(x)
> >>     >>> `%identical%` <- function(x, y) identical(x, y)
> >>     >>>
> >>     >>> %chr% 100
> >>     >>> #> [1] "100"
> >>     >>>
> >>     >>> %chr% 100 %identical% "100"
> >>     >>> #> [1] TRUE
> >>     >>>
> >>     >>> This seems a natural extension of the existing functionality and
> >>     >>> requires only a minor change to the grammar. If this change
> seems
> >>     >>> acceptable I am happy to provide a complete patch with suitable
> >> tests
> >>     >>> and documentation.
> >>     >>>
> >>     >>> [1]:
> >>     >>> Index: src/main/gram.y
> >>     >>>
> >> ===================================================================
> >>     >>> --- src/main/gram.y     (revision 72358)
> >>     >>> +++ src/main/gram.y     (working copy)
> >>     >>> @@ -357,6 +357,7 @@
> >>     >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
> >>     >>> setId( $$, @$); }
> >>     >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
> >>     >>> setId( $$, @$); }
> >>     >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
> >>     >>> setId( $$, @$); }
> >>     >>> +       |       SPECIAL expr                    { $$ =
> >> xxunary($1,$2);
> >>     >>> setId( $$, @$); }
> >>     >>> |       '?' expr                        { $$ = xxunary($1,$2);
> >>     >>> setId( $$, @$); }
> >>     >>>
> >>     >>> |       expr ':'  expr                  { $$ =
> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
> >>     >>>
> >>     >>> ______________________________________________
> >>     >>> R-devel at r-project.org mailing list
> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>     >>
> >>     >>
> >>     >>
> >>     >>
> >>     >> --
> >>     >> Gabriel Becker, PhD
> >>     >> Associate Scientist (Bioinformatics)
> >>     >> Genentech Research
> >>
> >>     > ______________________________________________
> >>     > R-devel at r-project.org mailing list
> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> >
> >
> > --
> > Gabriel Becker, PhD
> > Associate Scientist (Bioinformatics)
> > Genentech Research
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Mar 16 23:57:38 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Mar 2017 15:57:38 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
Message-ID: <CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>

I am biased against introducing new syntax, but if one is
experimenting with it one should make sure the precedence feels right.
I think the unary and binary minus-sign operators have different
precedences so I see no a priori reason to make the unary and binary
%xxx% operators to be the same.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> I guess this would establish a separate "namespace" of symbolic prefix
> operators, %*% being an example in the infix case. So you could have stuff
> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's hard to
> see the advantage vs. foo(x).
>
> Those examples you mention should probably be addressed (eventually) in the
> core language, and it looks like people are already able to experiment, so
> I'm not sure there's a significant impetus for this change.
>
> Michael
>
>
> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
> wrote:
>
>> I used the `function(x)` form to explicitly show the function was
>> being called with only one argument, clearly performance implications
>> are not relevant for these examples.
>>
>> I think of this mainly as a gap in the tooling we provide users and
>> package authors. R has native prefix `+1`, functional `f(1)` and infix
>> `1 + 1` operators, but we only provide a mechanism to create user
>> defined functional and infix operators.
>>
>> One could also argue that the user defined infix operators are also
>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>> the eye of the beholder.
>>
>> The unquote example [1] shows one example where this gap in tooling
>> caused authors to co-opt existing unary exclamation operator, this
>> same gap is part of the reason the formula [2] and question mark [3]
>> operators have been used elsewhere in non standard contexts.
>>
>> If the language provided package authors with a native way to create
>> unary operators like it already does for the other operator types
>> these machinations would be unnecessary.
>>
>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>> [2]: https://cran.r-project.org/package=ensurer
>> [3]: https://cran.r-project.org/package=types
>>
>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>> > Martin,
>> >
>> > Jim can speak directly to his motivations; I don't claim to be able to do
>> > so. That said, I suspect this is related to a conversation on twitter
>> about
>> > wanting an infix "unquote" operator in the context of the non-standard
>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
>> others)
>> > are working on.
>> >
>> > They're currently using !!! and !! for things related to this, but this
>> > effectively requires non-standard parsing, as ~!!x is interpreted as
>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it. Others
>> and
>> > I pointed out this was less than desirable, but if something like it was
>> > going to happen it would hopefully happen in the language specification,
>> > rather than in a package (and also hopefully not using !! specifically).
>> >
>> > Like you, I actually tend to prefer the functional form myself in most
>> > cases. There are functional forms that would work for the above case
>> (e.g.,
>> > something like the .() that DBI uses), but that's probably off topic
>> here,
>> > and not a decision I'm directly related to anyway.
>> >
>> > Best,
>> > ~G
>> >
>> >
>> >
>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>> > <maechler at stat.math.ethz.ch> wrote:
>> >>
>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>> >>
>> >>     > Gabe,
>> >>     > The unary functions have the same precedence as normal SPECIALS
>> >>     > (although the new unary forms take precedence over binary
>> SPECIALS).
>> >>     > So they are lower precedence than unary + and -. Yes, both of your
>> >>     > examples are valid with this patch, here are the results and
>> quoted
>> >>     > forms to see the precedence.
>> >>
>> >>     > `%chr%` <- function(x) as.character(x)
>> >>
>> >>   [more efficient would be     `%chr%` <- as.character]
>> >>
>> >>     > `%identical%` <- function(x, y) identical(x, y)
>> >>     > quote("100" %identical% %chr% 100)
>> >>     > #>  "100" %identical% (`%chr%`(100))
>> >>
>> >>     > "100" %identical% %chr% 100
>> >>     > #> [1] TRUE
>> >>
>> >>     > `%num%` <- as.numeric
>> >>     > quote(1 + - %num% "5")
>> >>     > #> 1 + -(`%num%`("5"))
>> >>
>> >>     > 1 + - %num% "5"
>> >>     > #> [1] -4
>> >>
>> >>     > Jim
>> >>
>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>> >> you may know that I like to  applaud Norm Matloff for his book
>> >> title "The Art of R Programming",
>> >> because for me good code should also be beautiful to some extent.
>> >>
>> >> I really very much prefer
>> >>
>> >>        f(x)
>> >> to    %f% x
>> >>
>> >> and hence I really really really cannot see why anybody would prefer
>> >> the ugliness of
>> >>
>> >>            1 + - %num% "5"
>> >> to
>> >>            1 + -num("5")
>> >>
>> >> (after setting  num <- as.numeric )
>> >>
>> >> Martin
>> >>
>> >>
>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> >> <gmbecker at ucdavis.edu> wrote:
>> >>     >> Jim,
>> >>     >>
>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
>> >> user-defined
>> >>     >> unary operations would be of the same precedence (or just
>> slightly
>> >> below?)
>> >>     >> built-in unary ones? So
>> >>     >>
>> >>     >> "100" %identical% %chr% 100
>> >>     >>
>> >>     >> would work and return TRUE under your patch?
>> >>     >>
>> >>     >> And  with %num% <- as.numeric, then
>> >>     >>
>> >>     >> 1 + - %num% "5"
>> >>     >>
>> >>     >> would also be legal (though quite ugly imo) and work?
>> >>     >>
>> >>     >> Best,
>> >>     >> ~G
>> >>     >>
>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> >> <james.f.hester at gmail.com>
>> >>     >> wrote:
>> >>     >>>
>> >>     >>> R has long supported user defined binary (infix) functions,
>> >> defined
>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows users
>> to
>> >>     >>> define unary (prefix) functions in the same manner.
>> >>     >>>
>> >>     >>> `%chr%` <- function(x) as.character(x)
>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>> >>     >>>
>> >>     >>> %chr% 100
>> >>     >>> #> [1] "100"
>> >>     >>>
>> >>     >>> %chr% 100 %identical% "100"
>> >>     >>> #> [1] TRUE
>> >>     >>>
>> >>     >>> This seems a natural extension of the existing functionality and
>> >>     >>> requires only a minor change to the grammar. If this change
>> seems
>> >>     >>> acceptable I am happy to provide a complete patch with suitable
>> >> tests
>> >>     >>> and documentation.
>> >>     >>>
>> >>     >>> [1]:
>> >>     >>> Index: src/main/gram.y
>> >>     >>>
>> >> ===================================================================
>> >>     >>> --- src/main/gram.y     (revision 72358)
>> >>     >>> +++ src/main/gram.y     (working copy)
>> >>     >>> @@ -357,6 +357,7 @@
>> >>     >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>> >>     >>> setId( $$, @$); }
>> >>     >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>> >>     >>> setId( $$, @$); }
>> >>     >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>> >>     >>> setId( $$, @$); }
>> >>     >>> +       |       SPECIAL expr                    { $$ =
>> >> xxunary($1,$2);
>> >>     >>> setId( $$, @$); }
>> >>     >>> |       '?' expr                        { $$ = xxunary($1,$2);
>> >>     >>> setId( $$, @$); }
>> >>     >>>
>> >>     >>> |       expr ':'  expr                  { $$ =
>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>> >>     >>>
>> >>     >>> ______________________________________________
>> >>     >>> R-devel at r-project.org mailing list
>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>     >>
>> >>     >>
>> >>     >>
>> >>     >>
>> >>     >> --
>> >>     >> Gabriel Becker, PhD
>> >>     >> Associate Scientist (Bioinformatics)
>> >>     >> Genentech Research
>> >>
>> >>     > ______________________________________________
>> >>     > R-devel at r-project.org mailing list
>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>> >
>> >
>> > --
>> > Gabriel Becker, PhD
>> > Associate Scientist (Bioinformatics)
>> > Genentech Research
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Mar 17 00:13:58 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 Mar 2017 19:13:58 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
Message-ID: <9e2f5889-b9b8-f4ce-322f-86bcd3d077f8@gmail.com>

I don't have a positive or negative opinion on this yet, but I do have a 
question.  If I define both unary and binary operators with the same 
name (in different frames, presumably), what would happen?

Is "a %chr% b" a syntax error if unary %chr% is found first?  If both 
might be found, does "a %chr% %chr% b" mean "%chr%(a, %chr% b)", or is 
it a syntax error (like typing "a %chr%(%chr%(b))" would be)?

Duncan Murdoch




On 16/03/2017 10:24 AM, Jim Hester wrote:
> R has long supported user defined binary (infix) functions, defined
> with `%fun%`. A one line change [1] to R's grammar allows users to
> define unary (prefix) functions in the same manner.
>
>     `%chr%` <- function(x) as.character(x)
>     `%identical%` <- function(x, y) identical(x, y)
>
>     %chr% 100
>     #> [1] "100"
>
>     %chr% 100 %identical% "100"
>     #> [1] TRUE
>
> This seems a natural extension of the existing functionality and
> requires only a minor change to the grammar. If this change seems
> acceptable I am happy to provide a complete patch with suitable tests
> and documentation.
>
> [1]:
> Index: src/main/gram.y
> ===================================================================
> --- src/main/gram.y     (revision 72358)
> +++ src/main/gram.y     (working copy)
> @@ -357,6 +357,7 @@
>         |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>  setId( $$, @$); }
> +       |       SPECIAL expr                    { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>         |       '?' expr                        { $$ = xxunary($1,$2);
>  setId( $$, @$); }
>
>         |       expr ':'  expr                  { $$ =
> xxbinary($2,$1,$3);      setId( $$, @$); }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jono at jcarroll.com.au  Fri Mar 17 01:03:19 2017
From: jono at jcarroll.com.au (Jonathan Carroll)
Date: Fri, 17 Mar 2017 10:33:19 +1030
Subject: [Rd] RFC: (in-principle) native unquoting for standard evaluation
Message-ID: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>

(please be gentle, it's my first time)

I am interested in discussions (possibly reiterating past threads --
searching didn't turn up much) on the possibility of supporting standard
evaluation unquoting at the language level. This has been brought up in a
recent similar thread here [1] and on Twitter [2] where I proposed the
following desired (in-principle) syntax

    f <- function(col1, col2, new_col_name) {
        mtcars %>% mutate(@new_col_name = @col1 + @col2)
    }

or closer to home

    x <- 1:10; y <- "x"
    data.frame(z = @y)

where @ would be defined as a unary prefix operator which substitutes the
quoted variable name in-place, to allow more flexibility of NSE functions
within a programming context. This mechanism exists within MySQL [3] (and
likely other languages) and could potentially be extremely useful. Several
alternatives have been incorporated into packages (most recently work
on tidyeval) none of which appear to fully match the simplicity of the
above, and some of which cut a forceful path through the syntax tree.

The exact syntax isn't my concern at the moment (@ vs unquote() or other,
though the first requires user-supplied native prefix support within the
language, as per [1]) and neither is the exact way in which this would be
achieved (well above my pay grade). The practicality of @ being on the LHS
of `=` is also of a lesser concern (likely greater complexity) than the RHS.

I hear there exists (justified) reluctance to add new syntax to the
language, but I think this has sufficient merit (and a growing number of
workarounds) to warrant continued discussion.

With kindest regards,

- Jonathan.

[1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
[2] https://twitter.com/carroll_jono/status/842142292253196290
[3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Fri Mar 17 11:30:07 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 17 Mar 2017 03:30:07 -0700
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
Message-ID: <CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>

Interesting idea. Lazy and non-standard evaluation is going to happen; the
language needs a way to contain it.

I'll extend the proposal so that prefixing a formal argument with @ in
function() marks the argument as auto-quoting, so it arrives as a language
object without use of substitute(). Kind of like how '*' in C declares a
pointer and dereferences one.

subset <- function(x, @subset, ...) { }

This should make it easier to implement such functions, simplify
compilation, and allow detection of potential quoting errors through static
analysis.

Michael

On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
wrote:

> (please be gentle, it's my first time)
>
> I am interested in discussions (possibly reiterating past threads --
> searching didn't turn up much) on the possibility of supporting standard
> evaluation unquoting at the language level. This has been brought up in a
> recent similar thread here [1] and on Twitter [2] where I proposed the
> following desired (in-principle) syntax
>
>     f <- function(col1, col2, new_col_name) {
>         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>     }
>
> or closer to home
>
>     x <- 1:10; y <- "x"
>     data.frame(z = @y)
>
> where @ would be defined as a unary prefix operator which substitutes the
> quoted variable name in-place, to allow more flexibility of NSE functions
> within a programming context. This mechanism exists within MySQL [3] (and
> likely other languages) and could potentially be extremely useful. Several
> alternatives have been incorporated into packages (most recently work
> on tidyeval) none of which appear to fully match the simplicity of the
> above, and some of which cut a forceful path through the syntax tree.
>
> The exact syntax isn't my concern at the moment (@ vs unquote() or other,
> though the first requires user-supplied native prefix support within the
> language, as per [1]) and neither is the exact way in which this would be
> achieved (well above my pay grade). The practicality of @ being on the LHS
> of `=` is also of a lesser concern (likely greater complexity) than the
> RHS.
>
> I hear there exists (justified) reluctance to add new syntax to the
> language, but I think this has sufficient merit (and a growing number of
> workarounds) to warrant continued discussion.
>
> With kindest regards,
>
> - Jonathan.
>
> [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
> [2] https://twitter.com/carroll_jono/status/842142292253196290
> [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From james.f.hester at gmail.com  Fri Mar 17 13:02:49 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Fri, 17 Mar 2017 08:02:49 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <9e2f5889-b9b8-f4ce-322f-86bcd3d077f8@gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<9e2f5889-b9b8-f4ce-322f-86bcd3d077f8@gmail.com>
Message-ID: <CAD6tx946Rgf4Q80CRCdyuE_Kn3fQfP87CWmH8rc1N+yL1=rZ8A@mail.gmail.com>

This works the same way as `?` is defined in R code, and `-`, `+`
(defined in C) do now, you define one function that handles calls with
both unary and binary arguments.

    quote(a %f% %f% b)
    #> a %f% (`%f%`(b))

    `%f%` <- function(a, b) if (missing(b)) { force(a); cat("unary\n")
} else { force(a);force(b);cat("binary\n") }
    a <- 1
    b <- 2

    a %f% %f% b
    #> unary
    #> binary


This also brings up the point about what happens to existing user
defined functions such as `%in%` when they are used as unary functions
(likely by mistake). Happily this provides a useful error when run
assuming no default value of the second argument.

    %in% a
    #> Error in match(x, table, nomatch = 0L) :
    #>   argument "table" is missing, with no default


On Thu, Mar 16, 2017 at 7:13 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> I don't have a positive or negative opinion on this yet, but I do have a
> question.  If I define both unary and binary operators with the same name
> (in different frames, presumably), what would happen?
>
> Is "a %chr% b" a syntax error if unary %chr% is found first?  If both might
> be found, does "a %chr% %chr% b" mean "%chr%(a, %chr% b)", or is it a syntax
> error (like typing "a %chr%(%chr%(b))" would be)?
>
> Duncan Murdoch
>
>
>
>
>
> On 16/03/2017 10:24 AM, Jim Hester wrote:
>>
>> R has long supported user defined binary (infix) functions, defined
>> with `%fun%`. A one line change [1] to R's grammar allows users to
>> define unary (prefix) functions in the same manner.
>>
>>     `%chr%` <- function(x) as.character(x)
>>     `%identical%` <- function(x, y) identical(x, y)
>>
>>     %chr% 100
>>     #> [1] "100"
>>
>>     %chr% 100 %identical% "100"
>>     #> [1] TRUE
>>
>> This seems a natural extension of the existing functionality and
>> requires only a minor change to the grammar. If this change seems
>> acceptable I am happy to provide a complete patch with suitable tests
>> and documentation.
>>
>> [1]:
>> Index: src/main/gram.y
>> ===================================================================
>> --- src/main/gram.y     (revision 72358)
>> +++ src/main/gram.y     (working copy)
>> @@ -357,6 +357,7 @@
>>         |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>> +       |       SPECIAL expr                    { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>         |       '?' expr                        { $$ = xxunary($1,$2);
>>  setId( $$, @$); }
>>
>>         |       expr ':'  expr                  { $$ =
>> xxbinary($2,$1,$3);      setId( $$, @$); }
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From james.f.hester at gmail.com  Fri Mar 17 13:10:13 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Fri, 17 Mar 2017 08:10:13 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
Message-ID: <CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>

I agree there is no reason they _need_ to be the same precedence, but
I think SPECIALS are already have the proper precedence for both unary
and binary calls. Namely higher than all the binary operators (except
for `:`), but lower than the other unary operators. Even if we gave
unary specials their own precedence I think it would end up in the
same place.

    `%l%` <- function(x) tail(x, n = 1)
    %l% 1:5
    #> [1] 5
    %l% -5:-10
    #> [1] -10

On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I am biased against introducing new syntax, but if one is
> experimenting with it one should make sure the precedence feels right.
> I think the unary and binary minus-sign operators have different
> precedences so I see no a priori reason to make the unary and binary
> %xxx% operators to be the same.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
>> I guess this would establish a separate "namespace" of symbolic prefix
>> operators, %*% being an example in the infix case. So you could have stuff
>> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's hard to
>> see the advantage vs. foo(x).
>>
>> Those examples you mention should probably be addressed (eventually) in the
>> core language, and it looks like people are already able to experiment, so
>> I'm not sure there's a significant impetus for this change.
>>
>> Michael
>>
>>
>> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
>> wrote:
>>
>>> I used the `function(x)` form to explicitly show the function was
>>> being called with only one argument, clearly performance implications
>>> are not relevant for these examples.
>>>
>>> I think of this mainly as a gap in the tooling we provide users and
>>> package authors. R has native prefix `+1`, functional `f(1)` and infix
>>> `1 + 1` operators, but we only provide a mechanism to create user
>>> defined functional and infix operators.
>>>
>>> One could also argue that the user defined infix operators are also
>>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>>> the eye of the beholder.
>>>
>>> The unquote example [1] shows one example where this gap in tooling
>>> caused authors to co-opt existing unary exclamation operator, this
>>> same gap is part of the reason the formula [2] and question mark [3]
>>> operators have been used elsewhere in non standard contexts.
>>>
>>> If the language provided package authors with a native way to create
>>> unary operators like it already does for the other operator types
>>> these machinations would be unnecessary.
>>>
>>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>>> [2]: https://cran.r-project.org/package=ensurer
>>> [3]: https://cran.r-project.org/package=types
>>>
>>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>>> wrote:
>>> > Martin,
>>> >
>>> > Jim can speak directly to his motivations; I don't claim to be able to do
>>> > so. That said, I suspect this is related to a conversation on twitter
>>> about
>>> > wanting an infix "unquote" operator in the context of the non-standard
>>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
>>> others)
>>> > are working on.
>>> >
>>> > They're currently using !!! and !! for things related to this, but this
>>> > effectively requires non-standard parsing, as ~!!x is interpreted as
>>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it. Others
>>> and
>>> > I pointed out this was less than desirable, but if something like it was
>>> > going to happen it would hopefully happen in the language specification,
>>> > rather than in a package (and also hopefully not using !! specifically).
>>> >
>>> > Like you, I actually tend to prefer the functional form myself in most
>>> > cases. There are functional forms that would work for the above case
>>> (e.g.,
>>> > something like the .() that DBI uses), but that's probably off topic
>>> here,
>>> > and not a decision I'm directly related to anyway.
>>> >
>>> > Best,
>>> > ~G
>>> >
>>> >
>>> >
>>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>>> > <maechler at stat.math.ethz.ch> wrote:
>>> >>
>>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>>> >>
>>> >>     > Gabe,
>>> >>     > The unary functions have the same precedence as normal SPECIALS
>>> >>     > (although the new unary forms take precedence over binary
>>> SPECIALS).
>>> >>     > So they are lower precedence than unary + and -. Yes, both of your
>>> >>     > examples are valid with this patch, here are the results and
>>> quoted
>>> >>     > forms to see the precedence.
>>> >>
>>> >>     > `%chr%` <- function(x) as.character(x)
>>> >>
>>> >>   [more efficient would be     `%chr%` <- as.character]
>>> >>
>>> >>     > `%identical%` <- function(x, y) identical(x, y)
>>> >>     > quote("100" %identical% %chr% 100)
>>> >>     > #>  "100" %identical% (`%chr%`(100))
>>> >>
>>> >>     > "100" %identical% %chr% 100
>>> >>     > #> [1] TRUE
>>> >>
>>> >>     > `%num%` <- as.numeric
>>> >>     > quote(1 + - %num% "5")
>>> >>     > #> 1 + -(`%num%`("5"))
>>> >>
>>> >>     > 1 + - %num% "5"
>>> >>     > #> [1] -4
>>> >>
>>> >>     > Jim
>>> >>
>>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>>> >> you may know that I like to  applaud Norm Matloff for his book
>>> >> title "The Art of R Programming",
>>> >> because for me good code should also be beautiful to some extent.
>>> >>
>>> >> I really very much prefer
>>> >>
>>> >>        f(x)
>>> >> to    %f% x
>>> >>
>>> >> and hence I really really really cannot see why anybody would prefer
>>> >> the ugliness of
>>> >>
>>> >>            1 + - %num% "5"
>>> >> to
>>> >>            1 + -num("5")
>>> >>
>>> >> (after setting  num <- as.numeric )
>>> >>
>>> >> Martin
>>> >>
>>> >>
>>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>>> >> <gmbecker at ucdavis.edu> wrote:
>>> >>     >> Jim,
>>> >>     >>
>>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
>>> >> user-defined
>>> >>     >> unary operations would be of the same precedence (or just
>>> slightly
>>> >> below?)
>>> >>     >> built-in unary ones? So
>>> >>     >>
>>> >>     >> "100" %identical% %chr% 100
>>> >>     >>
>>> >>     >> would work and return TRUE under your patch?
>>> >>     >>
>>> >>     >> And  with %num% <- as.numeric, then
>>> >>     >>
>>> >>     >> 1 + - %num% "5"
>>> >>     >>
>>> >>     >> would also be legal (though quite ugly imo) and work?
>>> >>     >>
>>> >>     >> Best,
>>> >>     >> ~G
>>> >>     >>
>>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>>> >> <james.f.hester at gmail.com>
>>> >>     >> wrote:
>>> >>     >>>
>>> >>     >>> R has long supported user defined binary (infix) functions,
>>> >> defined
>>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows users
>>> to
>>> >>     >>> define unary (prefix) functions in the same manner.
>>> >>     >>>
>>> >>     >>> `%chr%` <- function(x) as.character(x)
>>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>>> >>     >>>
>>> >>     >>> %chr% 100
>>> >>     >>> #> [1] "100"
>>> >>     >>>
>>> >>     >>> %chr% 100 %identical% "100"
>>> >>     >>> #> [1] TRUE
>>> >>     >>>
>>> >>     >>> This seems a natural extension of the existing functionality and
>>> >>     >>> requires only a minor change to the grammar. If this change
>>> seems
>>> >>     >>> acceptable I am happy to provide a complete patch with suitable
>>> >> tests
>>> >>     >>> and documentation.
>>> >>     >>>
>>> >>     >>> [1]:
>>> >>     >>> Index: src/main/gram.y
>>> >>     >>>
>>> >> ===================================================================
>>> >>     >>> --- src/main/gram.y     (revision 72358)
>>> >>     >>> +++ src/main/gram.y     (working copy)
>>> >>     >>> @@ -357,6 +357,7 @@
>>> >>     >>> |       '+' expr %prec UMINUS           { $$ = xxunary($1,$2);
>>> >>     >>> setId( $$, @$); }
>>> >>     >>> |       '!' expr %prec UNOT             { $$ = xxunary($1,$2);
>>> >>     >>> setId( $$, @$); }
>>> >>     >>> |       '~' expr %prec TILDE            { $$ = xxunary($1,$2);
>>> >>     >>> setId( $$, @$); }
>>> >>     >>> +       |       SPECIAL expr                    { $$ =
>>> >> xxunary($1,$2);
>>> >>     >>> setId( $$, @$); }
>>> >>     >>> |       '?' expr                        { $$ = xxunary($1,$2);
>>> >>     >>> setId( $$, @$); }
>>> >>     >>>
>>> >>     >>> |       expr ':'  expr                  { $$ =
>>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>>> >>     >>>
>>> >>     >>> ______________________________________________
>>> >>     >>> R-devel at r-project.org mailing list
>>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>     >>
>>> >>     >>
>>> >>     >>
>>> >>     >>
>>> >>     >> --
>>> >>     >> Gabriel Becker, PhD
>>> >>     >> Associate Scientist (Bioinformatics)
>>> >>     >> Genentech Research
>>> >>
>>> >>     > ______________________________________________
>>> >>     > R-devel at r-project.org mailing list
>>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>> >
>>> >
>>> >
>>> > --
>>> > Gabriel Becker, PhD
>>> > Associate Scientist (Bioinformatics)
>>> > Genentech Research
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From jono at jcarroll.com.au  Fri Mar 17 14:16:15 2017
From: jono at jcarroll.com.au (Jonathan Carroll)
Date: Fri, 17 Mar 2017 13:16:15 +0000
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
Message-ID: <CAAjDRihzSY3ATAm3PhP6PVL1=eb_j43CN5_PsMiaRh1CLa2fNA@mail.gmail.com>

I love the pointer analogy. Presumably the additional complication of scope
breaks this however. * itself would have been a nice operator for this were
it not prone to ambiguity (`a * *b` vs `a**b`, from which @ does not
suffer).

Would this extension require that function authors explicitly enable
auto-quoting support? I somewhat envisioned functions seeing the resolved
unquoted object (within their calling scope) so that they could retain
their standard defintions when not using @. In my mutate example, mutate
itself could simply be the NSE version, so

    mutate(mtcars, z = mpg)

would work as normal, but

    x = "mpg"
    mutate(mtcars, z = @x)

would produce the same result (x may be changing within a loop or be
defined through a formal argument). Here, @x would resolve to `mpg` and
mutate would retain the duty of resolving that to mtcars$mpg as per normal.

A seperate SE version would not be required (as arguments could be set
programatically), but an additional flexibility could be @ acting on a
string rather than an object for direct unquoting

    mutate(mtcars, z = @"mpg")

for when the name is known but NSE isn't desired (which would also assist
with the whole utils::globalVariables() vs CRAN checks concern).

Having a formal argument forcefully auto-unquote would prevent standard
usage unless there was a way to also disable it. Unless I'm missing an
angle (which I very likely am) wouldn't it be better to have the user
supply an @-prefixed argument and retain the connection to the calling
scope?

Apologies if I have any of that confused or there are better approaches. I
merely have a desire for this to work and am learning as much as possible
about "how" as I go.

Your comments are greatly appreciated.

- Jonathan.

On Fri, 17 Mar 2017 at 21:00, Michael Lawrence <lawrence.michael at gene.com>
wrote:

Interesting idea. Lazy and non-standard evaluation is going to happen; the
language needs a way to contain it.

I'll extend the proposal so that prefixing a formal argument with @ in
function() marks the argument as auto-quoting, so it arrives as a language
object without use of substitute(). Kind of like how '*' in C declares a
pointer and dereferences one.

subset <- function(x, @subset, ...) { }

This should make it easier to implement such functions, simplify
compilation, and allow detection of potential quoting errors through static
analysis.

Michael

On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
wrote:

(please be gentle, it's my first time)

I am interested in discussions (possibly reiterating past threads --
searching didn't turn up much) on the possibility of supporting standard
evaluation unquoting at the language level. This has been brought up in a
recent similar thread here [1] and on Twitter [2] where I proposed the
following desired (in-principle) syntax

    f <- function(col1, col2, new_col_name) {
        mtcars %>% mutate(@new_col_name = @col1 + @col2)
    }

or closer to home

    x <- 1:10; y <- "x"
    data.frame(z = @y)

where @ would be defined as a unary prefix operator which substitutes the
quoted variable name in-place, to allow more flexibility of NSE functions
within a programming context. This mechanism exists within MySQL [3] (and
likely other languages) and could potentially be extremely useful. Several
alternatives have been incorporated into packages (most recently work
on tidyeval) none of which appear to fully match the simplicity of the
above, and some of which cut a forceful path through the syntax tree.

The exact syntax isn't my concern at the moment (@ vs unquote() or other,
though the first requires user-supplied native prefix support within the
language, as per [1]) and neither is the exact way in which this would be
achieved (well above my pay grade). The practicality of @ being on the LHS
of `=` is also of a lesser concern (likely greater complexity) than the RHS.

I hear there exists (justified) reluctance to add new syntax to the
language, but I think this has sufficient merit (and a growing number of
workarounds) to warrant continued discussion.

With kindest regards,

- Jonathan.

[1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
[2] https://twitter.com/carroll_jono/status/842142292253196290
[3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Fri Mar 17 14:46:25 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 17 Mar 2017 06:46:25 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
Message-ID: <CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>

Jim,

One more note about precedence. It prevents a solution like the one you
proposed from solving all of the problems you cited. By my reckoning, a
"What comes next is for NSE" unary operator needs an extremely low
precedence, because it needs to greedily grab "everything" (or a large
amount) that comes after it. Normal-style unary operators, on the other
hand, explicitly don't want that.

>From what I can see, your patch provides support for the latter but not the
former.

That said I think there are two issues here. One is can users define unary
operators. FWIW my opinion on that is roughly neutral to slightly positive.
The other issue is can we have quasi quotation of the type that Hadley and
Lionel need in the language. This could be solved without allowing
user-defined unary specials, and we would probably want it to be, as I
doubt ~ %!%x + %!%y + z is  particularly aesthetically appealing to most
(it isn't to me). I'd propose coopting unary @ for that myself. After off
list discussions with Jonathan Carrol and with Michael Lawrence I think
it's doable, unambiguous, and even imo pretty intuitive for an "unquote"
operator.

Best,
~G

On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
wrote:

> I agree there is no reason they _need_ to be the same precedence, but
> I think SPECIALS are already have the proper precedence for both unary
> and binary calls. Namely higher than all the binary operators (except
> for `:`), but lower than the other unary operators. Even if we gave
> unary specials their own precedence I think it would end up in the
> same place.
>
>     `%l%` <- function(x) tail(x, n = 1)
>     %l% 1:5
>     #> [1] 5
>     %l% -5:-10
>     #> [1] -10
>
> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > I am biased against introducing new syntax, but if one is
> > experimenting with it one should make sure the precedence feels right.
> > I think the unary and binary minus-sign operators have different
> > precedences so I see no a priori reason to make the unary and binary
> > %xxx% operators to be the same.
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
> > <lawrence.michael at gene.com> wrote:
> >> I guess this would establish a separate "namespace" of symbolic prefix
> >> operators, %*% being an example in the infix case. So you could have
> stuff
> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
> hard to
> >> see the advantage vs. foo(x).
> >>
> >> Those examples you mention should probably be addressed (eventually) in
> the
> >> core language, and it looks like people are already able to experiment,
> so
> >> I'm not sure there's a significant impetus for this change.
> >>
> >> Michael
> >>
> >>
> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
> >> wrote:
> >>
> >>> I used the `function(x)` form to explicitly show the function was
> >>> being called with only one argument, clearly performance implications
> >>> are not relevant for these examples.
> >>>
> >>> I think of this mainly as a gap in the tooling we provide users and
> >>> package authors. R has native prefix `+1`, functional `f(1)` and infix
> >>> `1 + 1` operators, but we only provide a mechanism to create user
> >>> defined functional and infix operators.
> >>>
> >>> One could also argue that the user defined infix operators are also
> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
> >>> the eye of the beholder.
> >>>
> >>> The unquote example [1] shows one example where this gap in tooling
> >>> caused authors to co-opt existing unary exclamation operator, this
> >>> same gap is part of the reason the formula [2] and question mark [3]
> >>> operators have been used elsewhere in non standard contexts.
> >>>
> >>> If the language provided package authors with a native way to create
> >>> unary operators like it already does for the other operator types
> >>> these machinations would be unnecessary.
> >>>
> >>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
> >>> [2]: https://cran.r-project.org/package=ensurer
> >>> [3]: https://cran.r-project.org/package=types
> >>>
> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> >>> wrote:
> >>> > Martin,
> >>> >
> >>> > Jim can speak directly to his motivations; I don't claim to be able
> to do
> >>> > so. That said, I suspect this is related to a conversation on twitter
> >>> about
> >>> > wanting an infix "unquote" operator in the context of the
> non-standard
> >>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
> >>> others)
> >>> > are working on.
> >>> >
> >>> > They're currently using !!! and !! for things related to this, but
> this
> >>> > effectively requires non-standard parsing, as ~!!x is interpreted as
> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
> Others
> >>> and
> >>> > I pointed out this was less than desirable, but if something like it
> was
> >>> > going to happen it would hopefully happen in the language
> specification,
> >>> > rather than in a package (and also hopefully not using !!
> specifically).
> >>> >
> >>> > Like you, I actually tend to prefer the functional form myself in
> most
> >>> > cases. There are functional forms that would work for the above case
> >>> (e.g.,
> >>> > something like the .() that DBI uses), but that's probably off topic
> >>> here,
> >>> > and not a decision I'm directly related to anyway.
> >>> >
> >>> > Best,
> >>> > ~G
> >>> >
> >>> >
> >>> >
> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
> >>> > <maechler at stat.math.ethz.ch> wrote:
> >>> >>
> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
> >>> >>
> >>> >>     > Gabe,
> >>> >>     > The unary functions have the same precedence as normal
> SPECIALS
> >>> >>     > (although the new unary forms take precedence over binary
> >>> SPECIALS).
> >>> >>     > So they are lower precedence than unary + and -. Yes, both of
> your
> >>> >>     > examples are valid with this patch, here are the results and
> >>> quoted
> >>> >>     > forms to see the precedence.
> >>> >>
> >>> >>     > `%chr%` <- function(x) as.character(x)
> >>> >>
> >>> >>   [more efficient would be     `%chr%` <- as.character]
> >>> >>
> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
> >>> >>     > quote("100" %identical% %chr% 100)
> >>> >>     > #>  "100" %identical% (`%chr%`(100))
> >>> >>
> >>> >>     > "100" %identical% %chr% 100
> >>> >>     > #> [1] TRUE
> >>> >>
> >>> >>     > `%num%` <- as.numeric
> >>> >>     > quote(1 + - %num% "5")
> >>> >>     > #> 1 + -(`%num%`("5"))
> >>> >>
> >>> >>     > 1 + - %num% "5"
> >>> >>     > #> [1] -4
> >>> >>
> >>> >>     > Jim
> >>> >>
> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
> >>> >> you may know that I like to  applaud Norm Matloff for his book
> >>> >> title "The Art of R Programming",
> >>> >> because for me good code should also be beautiful to some extent.
> >>> >>
> >>> >> I really very much prefer
> >>> >>
> >>> >>        f(x)
> >>> >> to    %f% x
> >>> >>
> >>> >> and hence I really really really cannot see why anybody would prefer
> >>> >> the ugliness of
> >>> >>
> >>> >>            1 + - %num% "5"
> >>> >> to
> >>> >>            1 + -num("5")
> >>> >>
> >>> >> (after setting  num <- as.numeric )
> >>> >>
> >>> >> Martin
> >>> >>
> >>> >>
> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
> >>> >> <gmbecker at ucdavis.edu> wrote:
> >>> >>     >> Jim,
> >>> >>     >>
> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
> >>> >> user-defined
> >>> >>     >> unary operations would be of the same precedence (or just
> >>> slightly
> >>> >> below?)
> >>> >>     >> built-in unary ones? So
> >>> >>     >>
> >>> >>     >> "100" %identical% %chr% 100
> >>> >>     >>
> >>> >>     >> would work and return TRUE under your patch?
> >>> >>     >>
> >>> >>     >> And  with %num% <- as.numeric, then
> >>> >>     >>
> >>> >>     >> 1 + - %num% "5"
> >>> >>     >>
> >>> >>     >> would also be legal (though quite ugly imo) and work?
> >>> >>     >>
> >>> >>     >> Best,
> >>> >>     >> ~G
> >>> >>     >>
> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
> >>> >> <james.f.hester at gmail.com>
> >>> >>     >> wrote:
> >>> >>     >>>
> >>> >>     >>> R has long supported user defined binary (infix) functions,
> >>> >> defined
> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows
> users
> >>> to
> >>> >>     >>> define unary (prefix) functions in the same manner.
> >>> >>     >>>
> >>> >>     >>> `%chr%` <- function(x) as.character(x)
> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
> >>> >>     >>>
> >>> >>     >>> %chr% 100
> >>> >>     >>> #> [1] "100"
> >>> >>     >>>
> >>> >>     >>> %chr% 100 %identical% "100"
> >>> >>     >>> #> [1] TRUE
> >>> >>     >>>
> >>> >>     >>> This seems a natural extension of the existing
> functionality and
> >>> >>     >>> requires only a minor change to the grammar. If this change
> >>> seems
> >>> >>     >>> acceptable I am happy to provide a complete patch with
> suitable
> >>> >> tests
> >>> >>     >>> and documentation.
> >>> >>     >>>
> >>> >>     >>> [1]:
> >>> >>     >>> Index: src/main/gram.y
> >>> >>     >>>
> >>> >> ===================================================================
> >>> >>     >>> --- src/main/gram.y     (revision 72358)
> >>> >>     >>> +++ src/main/gram.y     (working copy)
> >>> >>     >>> @@ -357,6 +357,7 @@
> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
> xxunary($1,$2);
> >>> >>     >>> setId( $$, @$); }
> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
> xxunary($1,$2);
> >>> >>     >>> setId( $$, @$); }
> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
> xxunary($1,$2);
> >>> >>     >>> setId( $$, @$); }
> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
> >>> >> xxunary($1,$2);
> >>> >>     >>> setId( $$, @$); }
> >>> >>     >>> |       '?' expr                        { $$ =
> xxunary($1,$2);
> >>> >>     >>> setId( $$, @$); }
> >>> >>     >>>
> >>> >>     >>> |       expr ':'  expr                  { $$ =
> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
> >>> >>     >>>
> >>> >>     >>> ______________________________________________
> >>> >>     >>> R-devel at r-project.org mailing list
> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> >>     >>
> >>> >>     >>
> >>> >>     >>
> >>> >>     >>
> >>> >>     >> --
> >>> >>     >> Gabriel Becker, PhD
> >>> >>     >> Associate Scientist (Bioinformatics)
> >>> >>     >> Genentech Research
> >>> >>
> >>> >>     > ______________________________________________
> >>> >>     > R-devel at r-project.org mailing list
> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> >
> >>> >
> >>> >
> >>> >
> >>> > --
> >>> > Gabriel Becker, PhD
> >>> > Associate Scientist (Bioinformatics)
> >>> > Genentech Research
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Fri Mar 17 15:09:30 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 17 Mar 2017 07:09:30 -0700
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAAjDRihzSY3ATAm3PhP6PVL1=eb_j43CN5_PsMiaRh1CLa2fNA@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
	<CAAjDRihzSY3ATAm3PhP6PVL1=eb_j43CN5_PsMiaRh1CLa2fNA@mail.gmail.com>
Message-ID: <CAOQ5NydXU5_9oygXVy5DSj8RyjjBgjyY6foe+USwCTXcTm6sAA@mail.gmail.com>

Not sure I totally understand what you wrote, but my proposal is somewhat
independent of the unquoting during the call (your proposal). Authors would
be free to either use auto-quoting or continue to rely on the substitute()
mechanism. Lazy evaluation wouldn't go away.


On Fri, Mar 17, 2017 at 6:16 AM, Jonathan Carroll <jono at jcarroll.com.au>
wrote:

> I love the pointer analogy. Presumably the additional complication of scope
> breaks this however. * itself would have been a nice operator for this were
> it not prone to ambiguity (`a * *b` vs `a**b`, from which @ does not
> suffer).
>
> Would this extension require that function authors explicitly enable
> auto-quoting support? I somewhat envisioned functions seeing the resolved
> unquoted object (within their calling scope) so that they could retain
> their standard defintions when not using @. In my mutate example, mutate
> itself could simply be the NSE version, so
>
>     mutate(mtcars, z = mpg)
>
> would work as normal, but
>
>     x = "mpg"
>     mutate(mtcars, z = @x)
>
> would produce the same result (x may be changing within a loop or be
> defined through a formal argument). Here, @x would resolve to `mpg` and
> mutate would retain the duty of resolving that to mtcars$mpg as per normal.
>
> A seperate SE version would not be required (as arguments could be set
> programatically), but an additional flexibility could be @ acting on a
> string rather than an object for direct unquoting
>
>     mutate(mtcars, z = @"mpg")
>
> for when the name is known but NSE isn't desired (which would also assist
> with the whole utils::globalVariables() vs CRAN checks concern).
>
> Having a formal argument forcefully auto-unquote would prevent standard
> usage unless there was a way to also disable it. Unless I'm missing an
> angle (which I very likely am) wouldn't it be better to have the user
> supply an @-prefixed argument and retain the connection to the calling
> scope?
>
> Apologies if I have any of that confused or there are better approaches. I
> merely have a desire for this to work and am learning as much as possible
> about "how" as I go.
>
> Your comments are greatly appreciated.
>
> - Jonathan.
>
> On Fri, 17 Mar 2017 at 21:00, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>
> Interesting idea. Lazy and non-standard evaluation is going to happen; the
> language needs a way to contain it.
>
> I'll extend the proposal so that prefixing a formal argument with @ in
> function() marks the argument as auto-quoting, so it arrives as a language
> object without use of substitute(). Kind of like how '*' in C declares a
> pointer and dereferences one.
>
> subset <- function(x, @subset, ...) { }
>
> This should make it easier to implement such functions, simplify
> compilation, and allow detection of potential quoting errors through static
> analysis.
>
> Michael
>
> On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
> wrote:
>
> (please be gentle, it's my first time)
>
> I am interested in discussions (possibly reiterating past threads --
> searching didn't turn up much) on the possibility of supporting standard
> evaluation unquoting at the language level. This has been brought up in a
> recent similar thread here [1] and on Twitter [2] where I proposed the
> following desired (in-principle) syntax
>
>     f <- function(col1, col2, new_col_name) {
>         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>     }
>
> or closer to home
>
>     x <- 1:10; y <- "x"
>     data.frame(z = @y)
>
> where @ would be defined as a unary prefix operator which substitutes the
> quoted variable name in-place, to allow more flexibility of NSE functions
> within a programming context. This mechanism exists within MySQL [3] (and
> likely other languages) and could potentially be extremely useful. Several
> alternatives have been incorporated into packages (most recently work
> on tidyeval) none of which appear to fully match the simplicity of the
> above, and some of which cut a forceful path through the syntax tree.
>
> The exact syntax isn't my concern at the moment (@ vs unquote() or other,
> though the first requires user-supplied native prefix support within the
> language, as per [1]) and neither is the exact way in which this would be
> achieved (well above my pay grade). The practicality of @ being on the LHS
> of `=` is also of a lesser concern (likely greater complexity) than the
> RHS.
>
> I hear there exists (justified) reluctance to add new syntax to the
> language, but I think this has sufficient merit (and a growing number of
> workarounds) to warrant continued discussion.
>
> With kindest regards,
>
> - Jonathan.
>
> [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
> [2] https://twitter.com/carroll_jono/status/842142292253196290
> [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Fri Mar 17 15:46:31 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 17 Mar 2017 07:46:31 -0700
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAAjDRihzSY3ATAm3PhP6PVL1=eb_j43CN5_PsMiaRh1CLa2fNA@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
	<CAAjDRihzSY3ATAm3PhP6PVL1=eb_j43CN5_PsMiaRh1CLa2fNA@mail.gmail.com>
Message-ID: <CADwqtCN7P_o8sB0Z82UbphWMSHvofWrKQ3Z53ZqieevqJ-+1wA@mail.gmail.com>

Jonathan,

Nice proposal.

I think these two uses for unary @ ( your initial @ unary operator and
Michael's extension for use inside function declaration) synergize really
well. It could easily be that function owners can declare an parameter to
always quote, and function callers can their specific arguments to behave
in the way you describe. It would make @ mean two pretty different things
in these two contexts, but they aren't^ mixable, so I think that would be
ok. This also has a strong precedence with the * operator in C, where int
*a creates a pointer, and then *a +1 uses the dereferenced value.

^ I think they're only not mixable provided that the function function
itself does not support your (Jonathan's) version of the operator, i.e.,
the ability to use variables' values to declare parameter names  or default
values within the function declaration. (Actually I think it could be
supported for default values, just not parameter names, if we wanted to) I
think that's reasonable though. I don't think we would need to support that.

One big question is whether you can do function(x, y, @...). The definition
of mutate() using Michaels extension of your proposal would require this.
This would be in keeping with the principle of the proposal, I think,
though it might (or might not) make the implementation more complicated.

I wonder if it makes sense to have a formal ability to declare where the
NSE will take place in the function definition, perhaps, (completely
spitballing) a unary ^ operator, so a simplified subset could literally be
defined as

subset2 = function(^x,  @cond) x[cond,]

Perhaps that's getting too clever, but it could be cool. Note it would be
optional. And we might even want a different different operators for that,
since it changes what the @ modifier of the parameter does. (your code gets
the result of the expression being evaluated in the ^ context, rather than
the language object). This would be, I imagine, immensely useful when
attempting to compile code that is NSE, even beyond labeling it as such via
the @ in function declarations

Best,
~G


On Fri, Mar 17, 2017 at 6:16 AM, Jonathan Carroll <jono at jcarroll.com.au>
wrote:

> I love the pointer analogy. Presumably the additional complication of scope
> breaks this however. * itself would have been a nice operator for this were
> it not prone to ambiguity (`a * *b` vs `a**b`, from which @ does not
> suffer).
>
> Would this extension require that function authors explicitly enable
> auto-quoting support? I somewhat envisioned functions seeing the resolved
> unquoted object (within their calling scope) so that they could retain
> their standard defintions when not using @. In my mutate example, mutate
> itself could simply be the NSE version, so
>
>     mutate(mtcars, z = mpg)
>
> would work as normal, but
>
>     x = "mpg"
>     mutate(mtcars, z = @x)
>
> would produce the same result (x may be changing within a loop or be
> defined through a formal argument). Here, @x would resolve to `mpg` and
> mutate would retain the duty of resolving that to mtcars$mpg as per normal.
>
> A seperate SE version would not be required (as arguments could be set
> programatically), but an additional flexibility could be @ acting on a
> string rather than an object for direct unquoting
>
>     mutate(mtcars, z = @"mpg")
>
> for when the name is known but NSE isn't desired (which would also assist
> with the whole utils::globalVariables() vs CRAN checks concern).
>
> Having a formal argument forcefully auto-unquote would prevent standard
> usage unless there was a way to also disable it. Unless I'm missing an
> angle (which I very likely am) wouldn't it be better to have the user
> supply an @-prefixed argument and retain the connection to the calling
> scope?
>
> Apologies if I have any of that confused or there are better approaches. I
> merely have a desire for this to work and am learning as much as possible
> about "how" as I go.
>
> Your comments are greatly appreciated.
>
> - Jonathan.
>
> On Fri, 17 Mar 2017 at 21:00, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>
> Interesting idea. Lazy and non-standard evaluation is going to happen; the
> language needs a way to contain it.
>
> I'll extend the proposal so that prefixing a formal argument with @ in
> function() marks the argument as auto-quoting, so it arrives as a language
> object without use of substitute(). Kind of like how '*' in C declares a
> pointer and dereferences one.
>
> subset <- function(x, @subset, ...) { }
>
> This should make it easier to implement such functions, simplify
> compilation, and allow detection of potential quoting errors through static
> analysis.
>
> Michael
>
> On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
> wrote:
>
> (please be gentle, it's my first time)
>
> I am interested in discussions (possibly reiterating past threads --
> searching didn't turn up much) on the possibility of supporting standard
> evaluation unquoting at the language level. This has been brought up in a
> recent similar thread here [1] and on Twitter [2] where I proposed the
> following desired (in-principle) syntax
>
>     f <- function(col1, col2, new_col_name) {
>         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>     }
>
> or closer to home
>
>     x <- 1:10; y <- "x"
>     data.frame(z = @y)
>
> where @ would be defined as a unary prefix operator which substitutes the
> quoted variable name in-place, to allow more flexibility of NSE functions
> within a programming context. This mechanism exists within MySQL [3] (and
> likely other languages) and could potentially be extremely useful. Several
> alternatives have been incorporated into packages (most recently work
> on tidyeval) none of which appear to fully match the simplicity of the
> above, and some of which cut a forceful path through the syntax tree.
>
> The exact syntax isn't my concern at the moment (@ vs unquote() or other,
> though the first requires user-supplied native prefix support within the
> language, as per [1]) and neither is the exact way in which this would be
> achieved (well above my pay grade). The practicality of @ being on the LHS
> of `=` is also of a lesser concern (likely greater complexity) than the
> RHS.
>
> I hear there exists (justified) reluctance to add new syntax to the
> language, but I think this has sufficient merit (and a growing number of
> workarounds) to warrant continued discussion.
>
> With kindest regards,
>
> - Jonathan.
>
> [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
> [2] https://twitter.com/carroll_jono/status/842142292253196290
> [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 17 16:55:03 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Mar 2017 08:55:03 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
Message-ID: <CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>

>After off list discussions with Jonathan Carrol and with
>Michael Lawrence I think it's doable, unambiguous,
>and even imo pretty intuitive for an "unquote" operator.

For those of us who are not CS/Lisp mavens, what is an
"unquote" operator?  Can you expression quoting and unquoting
in R syntax and show a few examples where is is useful,
intuitive, and fits in to R's functional design?  In particular,
what does it give us that the current tilde function does not?


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 17, 2017 at 6:46 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Jim,
>
> One more note about precedence. It prevents a solution like the one you
> proposed from solving all of the problems you cited. By my reckoning, a
> "What comes next is for NSE" unary operator needs an extremely low
> precedence, because it needs to greedily grab "everything" (or a large
> amount) that comes after it. Normal-style unary operators, on the other
> hand, explicitly don't want that.
>
> From what I can see, your patch provides support for the latter but not the
> former.
>
> That said I think there are two issues here. One is can users define unary
> operators. FWIW my opinion on that is roughly neutral to slightly positive.
> The other issue is can we have quasi quotation of the type that Hadley and
> Lionel need in the language. This could be solved without allowing
> user-defined unary specials, and we would probably want it to be, as I doubt
> ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it isn't
> to me). I'd propose coopting unary @ for that myself. After off list
> discussions with Jonathan Carrol and with Michael Lawrence I think it's
> doable, unambiguous, and even imo pretty intuitive for an "unquote"
> operator.
>
> Best,
> ~G
>
> On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
> wrote:
>>
>> I agree there is no reason they _need_ to be the same precedence, but
>> I think SPECIALS are already have the proper precedence for both unary
>> and binary calls. Namely higher than all the binary operators (except
>> for `:`), but lower than the other unary operators. Even if we gave
>> unary specials their own precedence I think it would end up in the
>> same place.
>>
>>     `%l%` <- function(x) tail(x, n = 1)
>>     %l% 1:5
>>     #> [1] 5
>>     %l% -5:-10
>>     #> [1] -10
>>
>> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> > I am biased against introducing new syntax, but if one is
>> > experimenting with it one should make sure the precedence feels right.
>> > I think the unary and binary minus-sign operators have different
>> > precedences so I see no a priori reason to make the unary and binary
>> > %xxx% operators to be the same.
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> >
>> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
>> > <lawrence.michael at gene.com> wrote:
>> >> I guess this would establish a separate "namespace" of symbolic prefix
>> >> operators, %*% being an example in the infix case. So you could have
>> >> stuff
>> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
>> >> hard to
>> >> see the advantage vs. foo(x).
>> >>
>> >> Those examples you mention should probably be addressed (eventually) in
>> >> the
>> >> core language, and it looks like people are already able to experiment,
>> >> so
>> >> I'm not sure there's a significant impetus for this change.
>> >>
>> >> Michael
>> >>
>> >>
>> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
>> >> wrote:
>> >>
>> >>> I used the `function(x)` form to explicitly show the function was
>> >>> being called with only one argument, clearly performance implications
>> >>> are not relevant for these examples.
>> >>>
>> >>> I think of this mainly as a gap in the tooling we provide users and
>> >>> package authors. R has native prefix `+1`, functional `f(1)` and infix
>> >>> `1 + 1` operators, but we only provide a mechanism to create user
>> >>> defined functional and infix operators.
>> >>>
>> >>> One could also argue that the user defined infix operators are also
>> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>> >>> the eye of the beholder.
>> >>>
>> >>> The unquote example [1] shows one example where this gap in tooling
>> >>> caused authors to co-opt existing unary exclamation operator, this
>> >>> same gap is part of the reason the formula [2] and question mark [3]
>> >>> operators have been used elsewhere in non standard contexts.
>> >>>
>> >>> If the language provided package authors with a native way to create
>> >>> unary operators like it already does for the other operator types
>> >>> these machinations would be unnecessary.
>> >>>
>> >>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>> >>> [2]: https://cran.r-project.org/package=ensurer
>> >>> [3]: https://cran.r-project.org/package=types
>> >>>
>> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> >>> wrote:
>> >>> > Martin,
>> >>> >
>> >>> > Jim can speak directly to his motivations; I don't claim to be able
>> >>> > to do
>> >>> > so. That said, I suspect this is related to a conversation on
>> >>> > twitter
>> >>> about
>> >>> > wanting an infix "unquote" operator in the context of the
>> >>> > non-standard
>> >>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
>> >>> others)
>> >>> > are working on.
>> >>> >
>> >>> > They're currently using !!! and !! for things related to this, but
>> >>> > this
>> >>> > effectively requires non-standard parsing, as ~!!x is interpreted as
>> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
>> >>> > Others
>> >>> and
>> >>> > I pointed out this was less than desirable, but if something like it
>> >>> > was
>> >>> > going to happen it would hopefully happen in the language
>> >>> > specification,
>> >>> > rather than in a package (and also hopefully not using !!
>> >>> > specifically).
>> >>> >
>> >>> > Like you, I actually tend to prefer the functional form myself in
>> >>> > most
>> >>> > cases. There are functional forms that would work for the above case
>> >>> (e.g.,
>> >>> > something like the .() that DBI uses), but that's probably off topic
>> >>> here,
>> >>> > and not a decision I'm directly related to anyway.
>> >>> >
>> >>> > Best,
>> >>> > ~G
>> >>> >
>> >>> >
>> >>> >
>> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>> >>> > <maechler at stat.math.ethz.ch> wrote:
>> >>> >>
>> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>> >>> >>
>> >>> >>     > Gabe,
>> >>> >>     > The unary functions have the same precedence as normal
>> >>> >> SPECIALS
>> >>> >>     > (although the new unary forms take precedence over binary
>> >>> SPECIALS).
>> >>> >>     > So they are lower precedence than unary + and -. Yes, both of
>> >>> >> your
>> >>> >>     > examples are valid with this patch, here are the results and
>> >>> quoted
>> >>> >>     > forms to see the precedence.
>> >>> >>
>> >>> >>     > `%chr%` <- function(x) as.character(x)
>> >>> >>
>> >>> >>   [more efficient would be     `%chr%` <- as.character]
>> >>> >>
>> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
>> >>> >>     > quote("100" %identical% %chr% 100)
>> >>> >>     > #>  "100" %identical% (`%chr%`(100))
>> >>> >>
>> >>> >>     > "100" %identical% %chr% 100
>> >>> >>     > #> [1] TRUE
>> >>> >>
>> >>> >>     > `%num%` <- as.numeric
>> >>> >>     > quote(1 + - %num% "5")
>> >>> >>     > #> 1 + -(`%num%`("5"))
>> >>> >>
>> >>> >>     > 1 + - %num% "5"
>> >>> >>     > #> [1] -4
>> >>> >>
>> >>> >>     > Jim
>> >>> >>
>> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>> >>> >> you may know that I like to  applaud Norm Matloff for his book
>> >>> >> title "The Art of R Programming",
>> >>> >> because for me good code should also be beautiful to some extent.
>> >>> >>
>> >>> >> I really very much prefer
>> >>> >>
>> >>> >>        f(x)
>> >>> >> to    %f% x
>> >>> >>
>> >>> >> and hence I really really really cannot see why anybody would
>> >>> >> prefer
>> >>> >> the ugliness of
>> >>> >>
>> >>> >>            1 + - %num% "5"
>> >>> >> to
>> >>> >>            1 + -num("5")
>> >>> >>
>> >>> >> (after setting  num <- as.numeric )
>> >>> >>
>> >>> >> Martin
>> >>> >>
>> >>> >>
>> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> >>> >> <gmbecker at ucdavis.edu> wrote:
>> >>> >>     >> Jim,
>> >>> >>     >>
>> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
>> >>> >> user-defined
>> >>> >>     >> unary operations would be of the same precedence (or just
>> >>> slightly
>> >>> >> below?)
>> >>> >>     >> built-in unary ones? So
>> >>> >>     >>
>> >>> >>     >> "100" %identical% %chr% 100
>> >>> >>     >>
>> >>> >>     >> would work and return TRUE under your patch?
>> >>> >>     >>
>> >>> >>     >> And  with %num% <- as.numeric, then
>> >>> >>     >>
>> >>> >>     >> 1 + - %num% "5"
>> >>> >>     >>
>> >>> >>     >> would also be legal (though quite ugly imo) and work?
>> >>> >>     >>
>> >>> >>     >> Best,
>> >>> >>     >> ~G
>> >>> >>     >>
>> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> >>> >> <james.f.hester at gmail.com>
>> >>> >>     >> wrote:
>> >>> >>     >>>
>> >>> >>     >>> R has long supported user defined binary (infix) functions,
>> >>> >> defined
>> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows
>> >>> >> users
>> >>> to
>> >>> >>     >>> define unary (prefix) functions in the same manner.
>> >>> >>     >>>
>> >>> >>     >>> `%chr%` <- function(x) as.character(x)
>> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>> >>> >>     >>>
>> >>> >>     >>> %chr% 100
>> >>> >>     >>> #> [1] "100"
>> >>> >>     >>>
>> >>> >>     >>> %chr% 100 %identical% "100"
>> >>> >>     >>> #> [1] TRUE
>> >>> >>     >>>
>> >>> >>     >>> This seems a natural extension of the existing
>> >>> >> functionality and
>> >>> >>     >>> requires only a minor change to the grammar. If this change
>> >>> seems
>> >>> >>     >>> acceptable I am happy to provide a complete patch with
>> >>> >> suitable
>> >>> >> tests
>> >>> >>     >>> and documentation.
>> >>> >>     >>>
>> >>> >>     >>> [1]:
>> >>> >>     >>> Index: src/main/gram.y
>> >>> >>     >>>
>> >>> >> ===================================================================
>> >>> >>     >>> --- src/main/gram.y     (revision 72358)
>> >>> >>     >>> +++ src/main/gram.y     (working copy)
>> >>> >>     >>> @@ -357,6 +357,7 @@
>> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '?' expr                        { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>>
>> >>> >>     >>> |       expr ':'  expr                  { $$ =
>> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>> >>> >>     >>>
>> >>> >>     >>> ______________________________________________
>> >>> >>     >>> R-devel at r-project.org mailing list
>> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >> --
>> >>> >>     >> Gabriel Becker, PhD
>> >>> >>     >> Associate Scientist (Bioinformatics)
>> >>> >>     >> Genentech Research
>> >>> >>
>> >>> >>     > ______________________________________________
>> >>> >>     > R-devel at r-project.org mailing list
>> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>> >
>> >>> >
>> >>> >
>> >>> >
>> >>> > --
>> >>> > Gabriel Becker, PhD
>> >>> > Associate Scientist (Bioinformatics)
>> >>> > Genentech Research
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From pd.mes at cbs.dk  Fri Mar 17 17:13:51 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 17 Mar 2017 16:13:51 +0000
Subject: [Rd] R 3.4.0
Message-ID: <E23A740D-BD85-4D77-ACFD-5334C2BA0D88@cbs.dk>

R 3.4.0 "You Stupid Darkness" is now scheduled for April 21

The detailed schedule can be found on developer.r-project.org

For the Core Team

Peter D.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luke-tierney at uiowa.edu  Fri Mar 17 17:22:12 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 17 Mar 2017 11:22:12 -0500 (CDT)
Subject: [Rd] R 3.4.0
In-Reply-To: <E23A740D-BD85-4D77-ACFD-5334C2BA0D88@cbs.dk>
References: <E23A740D-BD85-4D77-ACFD-5334C2BA0D88@cbs.dk>
Message-ID: <alpine.DEB.2.20.1703171121020.2612@luke-Latitude>

Your dates are for 2016 :-) in your email and developer.r-project.com

Best,

luke

On Fri, 17 Mar 2017, Peter Dalgaard wrote:

> R 3.4.0 "You Stupid Darkness" is now scheduled for April 21
>
> The detailed schedule can be found on developer.r-project.org
>
> For the Core Team
>
> Peter D.
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From gmbecker at ucdavis.edu  Fri Mar 17 20:14:52 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 17 Mar 2017 12:14:52 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>
Message-ID: <CADwqtCMhJBbed_EE=9zbfCU+0FRg7P89=S0U30bQ84aM6aWNQA@mail.gmail.com>

William,

Unbeknownst to me when I sent this, Jonathon Carrol started a specific
thread about unquoting and a proposal for supporting it at the language
level, which I think is a better place to discuss unquoting specifically.
That said, the basics as I understand them in the context of non-standard
evaluation, unquoting (or perhaps interpolation) is essentially
substituting part of an unevaluated expression with its evaluated value
inlined. The unquote operator, then, is the way of marking which parts of
the expression should be substituted in that way (i.e. interpolated).

i.e. if uq() is the unquote "operator" and do_unquote interpolates, then if
we have

x = 5

exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z


Then do_unquote would give you the *expression* f(5) + y + z

In terms of what it does that the tilde does not, it would give you the
ability to partially evaluate the captured formula/expression, without
fully doing so.  See the roxygen comments in Hadley and Lionel's rlang
package here: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R

The desired precedence of such a unary operator is not clear to me. The way
rlang implements the !! now, it is quite low, so in the examples you see
there the ~list(!! x + x) is transformed to ~list(10), not ~list(5+x) as I
would have expected.  I'm confused by this given what I understand the
purpose to be, but that probably just means I'm not the right person to ask.

Hope that helps.

Best,
~G










On Fri, Mar 17, 2017 at 8:55 AM, William Dunlap <wdunlap at tibco.com> wrote:

> >After off list discussions with Jonathan Carrol and with
> >Michael Lawrence I think it's doable, unambiguous,
> >and even imo pretty intuitive for an "unquote" operator.
>
> For those of us who are not CS/Lisp mavens, what is an
> "unquote" operator?  Can you expression quoting and unquoting
> in R syntax and show a few examples where is is useful,
> intuitive, and fits in to R's functional design?  In particular,
> what does it give us that the current tilde function does not?
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Mar 17, 2017 at 6:46 AM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> > Jim,
> >
> > One more note about precedence. It prevents a solution like the one you
> > proposed from solving all of the problems you cited. By my reckoning, a
> > "What comes next is for NSE" unary operator needs an extremely low
> > precedence, because it needs to greedily grab "everything" (or a large
> > amount) that comes after it. Normal-style unary operators, on the other
> > hand, explicitly don't want that.
> >
> > From what I can see, your patch provides support for the latter but not
> the
> > former.
> >
> > That said I think there are two issues here. One is can users define
> unary
> > operators. FWIW my opinion on that is roughly neutral to slightly
> positive.
> > The other issue is can we have quasi quotation of the type that Hadley
> and
> > Lionel need in the language. This could be solved without allowing
> > user-defined unary specials, and we would probably want it to be, as I
> doubt
> > ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it
> isn't
> > to me). I'd propose coopting unary @ for that myself. After off list
> > discussions with Jonathan Carrol and with Michael Lawrence I think it's
> > doable, unambiguous, and even imo pretty intuitive for an "unquote"
> > operator.
> >
> > Best,
> > ~G
> >
> > On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
> > wrote:
> >>
> >> I agree there is no reason they _need_ to be the same precedence, but
> >> I think SPECIALS are already have the proper precedence for both unary
> >> and binary calls. Namely higher than all the binary operators (except
> >> for `:`), but lower than the other unary operators. Even if we gave
> >> unary specials their own precedence I think it would end up in the
> >> same place.
> >>
> >>     `%l%` <- function(x) tail(x, n = 1)
> >>     %l% 1:5
> >>     #> [1] 5
> >>     %l% -5:-10
> >>     #> [1] -10
> >>
> >> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >> > I am biased against introducing new syntax, but if one is
> >> > experimenting with it one should make sure the precedence feels right.
> >> > I think the unary and binary minus-sign operators have different
> >> > precedences so I see no a priori reason to make the unary and binary
> >> > %xxx% operators to be the same.
> >> > Bill Dunlap
> >> > TIBCO Software
> >> > wdunlap tibco.com
> >> >
> >> >
> >> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
> >> > <lawrence.michael at gene.com> wrote:
> >> >> I guess this would establish a separate "namespace" of symbolic
> prefix
> >> >> operators, %*% being an example in the infix case. So you could have
> >> >> stuff
> >> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
> >> >> hard to
> >> >> see the advantage vs. foo(x).
> >> >>
> >> >> Those examples you mention should probably be addressed (eventually)
> in
> >> >> the
> >> >> core language, and it looks like people are already able to
> experiment,
> >> >> so
> >> >> I'm not sure there's a significant impetus for this change.
> >> >>
> >> >> Michael
> >> >>
> >> >>
> >> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <
> james.f.hester at gmail.com>
> >> >> wrote:
> >> >>
> >> >>> I used the `function(x)` form to explicitly show the function was
> >> >>> being called with only one argument, clearly performance
> implications
> >> >>> are not relevant for these examples.
> >> >>>
> >> >>> I think of this mainly as a gap in the tooling we provide users and
> >> >>> package authors. R has native prefix `+1`, functional `f(1)` and
> infix
> >> >>> `1 + 1` operators, but we only provide a mechanism to create user
> >> >>> defined functional and infix operators.
> >> >>>
> >> >>> One could also argue that the user defined infix operators are also
> >> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
> >> >>> the eye of the beholder.
> >> >>>
> >> >>> The unquote example [1] shows one example where this gap in tooling
> >> >>> caused authors to co-opt existing unary exclamation operator, this
> >> >>> same gap is part of the reason the formula [2] and question mark [3]
> >> >>> operators have been used elsewhere in non standard contexts.
> >> >>>
> >> >>> If the language provided package authors with a native way to create
> >> >>> unary operators like it already does for the other operator types
> >> >>> these machinations would be unnecessary.
> >> >>>
> >> >>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-
> unquote.R#L17
> >> >>> [2]: https://cran.r-project.org/package=ensurer
> >> >>> [3]: https://cran.r-project.org/package=types
> >> >>>
> >> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <
> gmbecker at ucdavis.edu>
> >> >>> wrote:
> >> >>> > Martin,
> >> >>> >
> >> >>> > Jim can speak directly to his motivations; I don't claim to be
> able
> >> >>> > to do
> >> >>> > so. That said, I suspect this is related to a conversation on
> >> >>> > twitter
> >> >>> about
> >> >>> > wanting an infix "unquote" operator in the context of the
> >> >>> > non-standard
> >> >>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
> >> >>> others)
> >> >>> > are working on.
> >> >>> >
> >> >>> > They're currently using !!! and !! for things related to this, but
> >> >>> > this
> >> >>> > effectively requires non-standard parsing, as ~!!x is interpreted
> as
> >> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
> >> >>> > Others
> >> >>> and
> >> >>> > I pointed out this was less than desirable, but if something like
> it
> >> >>> > was
> >> >>> > going to happen it would hopefully happen in the language
> >> >>> > specification,
> >> >>> > rather than in a package (and also hopefully not using !!
> >> >>> > specifically).
> >> >>> >
> >> >>> > Like you, I actually tend to prefer the functional form myself in
> >> >>> > most
> >> >>> > cases. There are functional forms that would work for the above
> case
> >> >>> (e.g.,
> >> >>> > something like the .() that DBI uses), but that's probably off
> topic
> >> >>> here,
> >> >>> > and not a decision I'm directly related to anyway.
> >> >>> >
> >> >>> > Best,
> >> >>> > ~G
> >> >>> >
> >> >>> >
> >> >>> >
> >> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
> >> >>> > <maechler at stat.math.ethz.ch> wrote:
> >> >>> >>
> >> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
> >> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
> >> >>> >>
> >> >>> >>     > Gabe,
> >> >>> >>     > The unary functions have the same precedence as normal
> >> >>> >> SPECIALS
> >> >>> >>     > (although the new unary forms take precedence over binary
> >> >>> SPECIALS).
> >> >>> >>     > So they are lower precedence than unary + and -. Yes, both
> of
> >> >>> >> your
> >> >>> >>     > examples are valid with this patch, here are the results
> and
> >> >>> quoted
> >> >>> >>     > forms to see the precedence.
> >> >>> >>
> >> >>> >>     > `%chr%` <- function(x) as.character(x)
> >> >>> >>
> >> >>> >>   [more efficient would be     `%chr%` <- as.character]
> >> >>> >>
> >> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
> >> >>> >>     > quote("100" %identical% %chr% 100)
> >> >>> >>     > #>  "100" %identical% (`%chr%`(100))
> >> >>> >>
> >> >>> >>     > "100" %identical% %chr% 100
> >> >>> >>     > #> [1] TRUE
> >> >>> >>
> >> >>> >>     > `%num%` <- as.numeric
> >> >>> >>     > quote(1 + - %num% "5")
> >> >>> >>     > #> 1 + -(`%num%`("5"))
> >> >>> >>
> >> >>> >>     > 1 + - %num% "5"
> >> >>> >>     > #> [1] -4
> >> >>> >>
> >> >>> >>     > Jim
> >> >>> >>
> >> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
> >> >>> >> you may know that I like to  applaud Norm Matloff for his book
> >> >>> >> title "The Art of R Programming",
> >> >>> >> because for me good code should also be beautiful to some extent.
> >> >>> >>
> >> >>> >> I really very much prefer
> >> >>> >>
> >> >>> >>        f(x)
> >> >>> >> to    %f% x
> >> >>> >>
> >> >>> >> and hence I really really really cannot see why anybody would
> >> >>> >> prefer
> >> >>> >> the ugliness of
> >> >>> >>
> >> >>> >>            1 + - %num% "5"
> >> >>> >> to
> >> >>> >>            1 + -num("5")
> >> >>> >>
> >> >>> >> (after setting  num <- as.numeric )
> >> >>> >>
> >> >>> >> Martin
> >> >>> >>
> >> >>> >>
> >> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
> >> >>> >> <gmbecker at ucdavis.edu> wrote:
> >> >>> >>     >> Jim,
> >> >>> >>     >>
> >> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete,
> he
> >> >>> >> user-defined
> >> >>> >>     >> unary operations would be of the same precedence (or just
> >> >>> slightly
> >> >>> >> below?)
> >> >>> >>     >> built-in unary ones? So
> >> >>> >>     >>
> >> >>> >>     >> "100" %identical% %chr% 100
> >> >>> >>     >>
> >> >>> >>     >> would work and return TRUE under your patch?
> >> >>> >>     >>
> >> >>> >>     >> And  with %num% <- as.numeric, then
> >> >>> >>     >>
> >> >>> >>     >> 1 + - %num% "5"
> >> >>> >>     >>
> >> >>> >>     >> would also be legal (though quite ugly imo) and work?
> >> >>> >>     >>
> >> >>> >>     >> Best,
> >> >>> >>     >> ~G
> >> >>> >>     >>
> >> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
> >> >>> >> <james.f.hester at gmail.com>
> >> >>> >>     >> wrote:
> >> >>> >>     >>>
> >> >>> >>     >>> R has long supported user defined binary (infix)
> functions,
> >> >>> >> defined
> >> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows
> >> >>> >> users
> >> >>> to
> >> >>> >>     >>> define unary (prefix) functions in the same manner.
> >> >>> >>     >>>
> >> >>> >>     >>> `%chr%` <- function(x) as.character(x)
> >> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
> >> >>> >>     >>>
> >> >>> >>     >>> %chr% 100
> >> >>> >>     >>> #> [1] "100"
> >> >>> >>     >>>
> >> >>> >>     >>> %chr% 100 %identical% "100"
> >> >>> >>     >>> #> [1] TRUE
> >> >>> >>     >>>
> >> >>> >>     >>> This seems a natural extension of the existing
> >> >>> >> functionality and
> >> >>> >>     >>> requires only a minor change to the grammar. If this
> change
> >> >>> seems
> >> >>> >>     >>> acceptable I am happy to provide a complete patch with
> >> >>> >> suitable
> >> >>> >> tests
> >> >>> >>     >>> and documentation.
> >> >>> >>     >>>
> >> >>> >>     >>> [1]:
> >> >>> >>     >>> Index: src/main/gram.y
> >> >>> >>     >>>
> >> >>> >> ============================================================
> =======
> >> >>> >>     >>> --- src/main/gram.y     (revision 72358)
> >> >>> >>     >>> +++ src/main/gram.y     (working copy)
> >> >>> >>     >>> @@ -357,6 +357,7 @@
> >> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
> >> >>> >> xxunary($1,$2);
> >> >>> >>     >>> setId( $$, @$); }
> >> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
> >> >>> >> xxunary($1,$2);
> >> >>> >>     >>> setId( $$, @$); }
> >> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
> >> >>> >> xxunary($1,$2);
> >> >>> >>     >>> setId( $$, @$); }
> >> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
> >> >>> >> xxunary($1,$2);
> >> >>> >>     >>> setId( $$, @$); }
> >> >>> >>     >>> |       '?' expr                        { $$ =
> >> >>> >> xxunary($1,$2);
> >> >>> >>     >>> setId( $$, @$); }
> >> >>> >>     >>>
> >> >>> >>     >>> |       expr ':'  expr                  { $$ =
> >> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
> >> >>> >>     >>>
> >> >>> >>     >>> ______________________________________________
> >> >>> >>     >>> R-devel at r-project.org mailing list
> >> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>> >>     >>
> >> >>> >>     >>
> >> >>> >>     >>
> >> >>> >>     >>
> >> >>> >>     >> --
> >> >>> >>     >> Gabriel Becker, PhD
> >> >>> >>     >> Associate Scientist (Bioinformatics)
> >> >>> >>     >> Genentech Research
> >> >>> >>
> >> >>> >>     > ______________________________________________
> >> >>> >>     > R-devel at r-project.org mailing list
> >> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>> >
> >> >>> >
> >> >>> >
> >> >>> >
> >> >>> > --
> >> >>> > Gabriel Becker, PhD
> >> >>> > Associate Scientist (Bioinformatics)
> >> >>> > Genentech Research
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-devel at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>>
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> >
> >
> > --
> > Gabriel Becker, PhD
> > Associate Scientist (Bioinformatics)
> > Genentech Research
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 17 20:53:09 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Mar 2017 12:53:09 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCMhJBbed_EE=9zbfCU+0FRg7P89=S0U30bQ84aM6aWNQA@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>
	<CADwqtCMhJBbed_EE=9zbfCU+0FRg7P89=S0U30bQ84aM6aWNQA@mail.gmail.com>
Message-ID: <CAF8bMcaQMw3Ymh4JWodoHWP0_=ZJQO3jpm=AFqc7uQ2-wPs5cQ@mail.gmail.com>

Your example
   x = 5
   exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
   do_unquote(expr)
    # -> the language object f(5) + y + z
could be done with the following wrapper for bquote
   my_do_unquote <- function(language, envir = parent.frame()) {
      if (is.expression(language)) {
         # bquote does not go into expressions, only calls
         as.expression(lapply(language, my_do_unquote))
      } else {
         do.call(bquote, list(language, where=envir))
      }
   }
as in
   > x <- 5
   > exp <- parse(text="f(.(x)) + y +z") # dot is uq for bquote
   > exp
   expression(f(.(x)) + y +z)
   > my_do_unquote(exp)
   expression(f(5) + y + z)
Or do uq() and do_unquote() do more than that?  E.g., would
uq() carry information about environments?

[I think expressions should map to expressions and calls to calls.
Otherwise what would we do with multicall expressions?]

We probably need to come up with a better name than 'non-standard
evaluation' since there are lots of non-standard ways of doing things.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 17, 2017 at 12:14 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> William,
>
> Unbeknownst to me when I sent this, Jonathon Carrol started a specific
> thread about unquoting and a proposal for supporting it at the language
> level, which I think is a better place to discuss unquoting specifically.
> That said, the basics as I understand them in the context of non-standard
> evaluation, unquoting (or perhaps interpolation) is essentially substituting
> part of an unevaluated expression with its evaluated value inlined. The
> unquote operator, then, is the way of marking which parts of the expression
> should be substituted in that way (i.e. interpolated).
>
> i.e. if uq() is the unquote "operator" and do_unquote interpolates, then if
> we have
>
> x = 5
>
> exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
>
>
> Then do_unquote would give you the expression f(5) + y + z
>
> In terms of what it does that the tilde does not, it would give you the
> ability to partially evaluate the captured formula/expression, without fully
> doing so.  See the roxygen comments in Hadley and Lionel's rlang package
> here: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R
>
> The desired precedence of such a unary operator is not clear to me. The way
> rlang implements the !! now, it is quite low, so in the examples you see
> there the ~list(!! x + x) is transformed to ~list(10), not ~list(5+x) as I
> would have expected.  I'm confused by this given what I understand the
> purpose to be, but that probably just means I'm not the right person to ask.
>
> Hope that helps.
>
> Best,
> ~G
>
>
>
>
>
>
>
>
>
>
> On Fri, Mar 17, 2017 at 8:55 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> >After off list discussions with Jonathan Carrol and with
>> >Michael Lawrence I think it's doable, unambiguous,
>> >and even imo pretty intuitive for an "unquote" operator.
>>
>> For those of us who are not CS/Lisp mavens, what is an
>> "unquote" operator?  Can you expression quoting and unquoting
>> in R syntax and show a few examples where is is useful,
>> intuitive, and fits in to R's functional design?  In particular,
>> what does it give us that the current tilde function does not?
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Mar 17, 2017 at 6:46 AM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>> > Jim,
>> >
>> > One more note about precedence. It prevents a solution like the one you
>> > proposed from solving all of the problems you cited. By my reckoning, a
>> > "What comes next is for NSE" unary operator needs an extremely low
>> > precedence, because it needs to greedily grab "everything" (or a large
>> > amount) that comes after it. Normal-style unary operators, on the other
>> > hand, explicitly don't want that.
>> >
>> > From what I can see, your patch provides support for the latter but not
>> > the
>> > former.
>> >
>> > That said I think there are two issues here. One is can users define
>> > unary
>> > operators. FWIW my opinion on that is roughly neutral to slightly
>> > positive.
>> > The other issue is can we have quasi quotation of the type that Hadley
>> > and
>> > Lionel need in the language. This could be solved without allowing
>> > user-defined unary specials, and we would probably want it to be, as I
>> > doubt
>> > ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it
>> > isn't
>> > to me). I'd propose coopting unary @ for that myself. After off list
>> > discussions with Jonathan Carrol and with Michael Lawrence I think it's
>> > doable, unambiguous, and even imo pretty intuitive for an "unquote"
>> > operator.
>> >
>> > Best,
>> > ~G
>> >
>> > On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
>> > wrote:
>> >>
>> >> I agree there is no reason they _need_ to be the same precedence, but
>> >> I think SPECIALS are already have the proper precedence for both unary
>> >> and binary calls. Namely higher than all the binary operators (except
>> >> for `:`), but lower than the other unary operators. Even if we gave
>> >> unary specials their own precedence I think it would end up in the
>> >> same place.
>> >>
>> >>     `%l%` <- function(x) tail(x, n = 1)
>> >>     %l% 1:5
>> >>     #> [1] 5
>> >>     %l% -5:-10
>> >>     #> [1] -10
>> >>
>> >> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com>
>> >> wrote:
>> >> > I am biased against introducing new syntax, but if one is
>> >> > experimenting with it one should make sure the precedence feels
>> >> > right.
>> >> > I think the unary and binary minus-sign operators have different
>> >> > precedences so I see no a priori reason to make the unary and binary
>> >> > %xxx% operators to be the same.
>> >> > Bill Dunlap
>> >> > TIBCO Software
>> >> > wdunlap tibco.com
>> >> >
>> >> >
>> >> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
>> >> > <lawrence.michael at gene.com> wrote:
>> >> >> I guess this would establish a separate "namespace" of symbolic
>> >> >> prefix
>> >> >> operators, %*% being an example in the infix case. So you could have
>> >> >> stuff
>> >> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
>> >> >> hard to
>> >> >> see the advantage vs. foo(x).
>> >> >>
>> >> >> Those examples you mention should probably be addressed (eventually)
>> >> >> in
>> >> >> the
>> >> >> core language, and it looks like people are already able to
>> >> >> experiment,
>> >> >> so
>> >> >> I'm not sure there's a significant impetus for this change.
>> >> >>
>> >> >> Michael
>> >> >>
>> >> >>
>> >> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester
>> >> >> <james.f.hester at gmail.com>
>> >> >> wrote:
>> >> >>
>> >> >>> I used the `function(x)` form to explicitly show the function was
>> >> >>> being called with only one argument, clearly performance
>> >> >>> implications
>> >> >>> are not relevant for these examples.
>> >> >>>
>> >> >>> I think of this mainly as a gap in the tooling we provide users and
>> >> >>> package authors. R has native prefix `+1`, functional `f(1)` and
>> >> >>> infix
>> >> >>> `1 + 1` operators, but we only provide a mechanism to create user
>> >> >>> defined functional and infix operators.
>> >> >>>
>> >> >>> One could also argue that the user defined infix operators are also
>> >> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>> >> >>> the eye of the beholder.
>> >> >>>
>> >> >>> The unquote example [1] shows one example where this gap in tooling
>> >> >>> caused authors to co-opt existing unary exclamation operator, this
>> >> >>> same gap is part of the reason the formula [2] and question mark
>> >> >>> [3]
>> >> >>> operators have been used elsewhere in non standard contexts.
>> >> >>>
>> >> >>> If the language provided package authors with a native way to
>> >> >>> create
>> >> >>> unary operators like it already does for the other operator types
>> >> >>> these machinations would be unnecessary.
>> >> >>>
>> >> >>> [1]:
>> >> >>> https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>> >> >>> [2]: https://cran.r-project.org/package=ensurer
>> >> >>> [3]: https://cran.r-project.org/package=types
>> >> >>>
>> >> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker
>> >> >>> <gmbecker at ucdavis.edu>
>> >> >>> wrote:
>> >> >>> > Martin,
>> >> >>> >
>> >> >>> > Jim can speak directly to his motivations; I don't claim to be
>> >> >>> > able
>> >> >>> > to do
>> >> >>> > so. That said, I suspect this is related to a conversation on
>> >> >>> > twitter
>> >> >>> about
>> >> >>> > wanting an infix "unquote" operator in the context of the
>> >> >>> > non-standard
>> >> >>> > evaluation framework Hadley Wickham and Lionel Henry (and
>> >> >>> > possibly
>> >> >>> others)
>> >> >>> > are working on.
>> >> >>> >
>> >> >>> > They're currently using !!! and !! for things related to this,
>> >> >>> > but
>> >> >>> > this
>> >> >>> > effectively requires non-standard parsing, as ~!!x is interpreted
>> >> >>> > as
>> >> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
>> >> >>> > Others
>> >> >>> and
>> >> >>> > I pointed out this was less than desirable, but if something like
>> >> >>> > it
>> >> >>> > was
>> >> >>> > going to happen it would hopefully happen in the language
>> >> >>> > specification,
>> >> >>> > rather than in a package (and also hopefully not using !!
>> >> >>> > specifically).
>> >> >>> >
>> >> >>> > Like you, I actually tend to prefer the functional form myself in
>> >> >>> > most
>> >> >>> > cases. There are functional forms that would work for the above
>> >> >>> > case
>> >> >>> (e.g.,
>> >> >>> > something like the .() that DBI uses), but that's probably off
>> >> >>> > topic
>> >> >>> here,
>> >> >>> > and not a decision I'm directly related to anyway.
>> >> >>> >
>> >> >>> > Best,
>> >> >>> > ~G
>> >> >>> >
>> >> >>> >
>> >> >>> >
>> >> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>> >> >>> > <maechler at stat.math.ethz.ch> wrote:
>> >> >>> >>
>> >> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>> >> >>> >>
>> >> >>> >>     > Gabe,
>> >> >>> >>     > The unary functions have the same precedence as normal
>> >> >>> >> SPECIALS
>> >> >>> >>     > (although the new unary forms take precedence over binary
>> >> >>> SPECIALS).
>> >> >>> >>     > So they are lower precedence than unary + and -. Yes, both
>> >> >>> >> of
>> >> >>> >> your
>> >> >>> >>     > examples are valid with this patch, here are the results
>> >> >>> >> and
>> >> >>> quoted
>> >> >>> >>     > forms to see the precedence.
>> >> >>> >>
>> >> >>> >>     > `%chr%` <- function(x) as.character(x)
>> >> >>> >>
>> >> >>> >>   [more efficient would be     `%chr%` <- as.character]
>> >> >>> >>
>> >> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
>> >> >>> >>     > quote("100" %identical% %chr% 100)
>> >> >>> >>     > #>  "100" %identical% (`%chr%`(100))
>> >> >>> >>
>> >> >>> >>     > "100" %identical% %chr% 100
>> >> >>> >>     > #> [1] TRUE
>> >> >>> >>
>> >> >>> >>     > `%num%` <- as.numeric
>> >> >>> >>     > quote(1 + - %num% "5")
>> >> >>> >>     > #> 1 + -(`%num%`("5"))
>> >> >>> >>
>> >> >>> >>     > 1 + - %num% "5"
>> >> >>> >>     > #> [1] -4
>> >> >>> >>
>> >> >>> >>     > Jim
>> >> >>> >>
>> >> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>> >> >>> >> you may know that I like to  applaud Norm Matloff for his book
>> >> >>> >> title "The Art of R Programming",
>> >> >>> >> because for me good code should also be beautiful to some
>> >> >>> >> extent.
>> >> >>> >>
>> >> >>> >> I really very much prefer
>> >> >>> >>
>> >> >>> >>        f(x)
>> >> >>> >> to    %f% x
>> >> >>> >>
>> >> >>> >> and hence I really really really cannot see why anybody would
>> >> >>> >> prefer
>> >> >>> >> the ugliness of
>> >> >>> >>
>> >> >>> >>            1 + - %num% "5"
>> >> >>> >> to
>> >> >>> >>            1 + -num("5")
>> >> >>> >>
>> >> >>> >> (after setting  num <- as.numeric )
>> >> >>> >>
>> >> >>> >> Martin
>> >> >>> >>
>> >> >>> >>
>> >> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> >> >>> >> <gmbecker at ucdavis.edu> wrote:
>> >> >>> >>     >> Jim,
>> >> >>> >>     >>
>> >> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete,
>> >> >>> >> he
>> >> >>> >> user-defined
>> >> >>> >>     >> unary operations would be of the same precedence (or just
>> >> >>> slightly
>> >> >>> >> below?)
>> >> >>> >>     >> built-in unary ones? So
>> >> >>> >>     >>
>> >> >>> >>     >> "100" %identical% %chr% 100
>> >> >>> >>     >>
>> >> >>> >>     >> would work and return TRUE under your patch?
>> >> >>> >>     >>
>> >> >>> >>     >> And  with %num% <- as.numeric, then
>> >> >>> >>     >>
>> >> >>> >>     >> 1 + - %num% "5"
>> >> >>> >>     >>
>> >> >>> >>     >> would also be legal (though quite ugly imo) and work?
>> >> >>> >>     >>
>> >> >>> >>     >> Best,
>> >> >>> >>     >> ~G
>> >> >>> >>     >>
>> >> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> >> >>> >> <james.f.hester at gmail.com>
>> >> >>> >>     >> wrote:
>> >> >>> >>     >>>
>> >> >>> >>     >>> R has long supported user defined binary (infix)
>> >> >>> >> functions,
>> >> >>> >> defined
>> >> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar
>> >> >>> >> allows
>> >> >>> >> users
>> >> >>> to
>> >> >>> >>     >>> define unary (prefix) functions in the same manner.
>> >> >>> >>     >>>
>> >> >>> >>     >>> `%chr%` <- function(x) as.character(x)
>> >> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>> >> >>> >>     >>>
>> >> >>> >>     >>> %chr% 100
>> >> >>> >>     >>> #> [1] "100"
>> >> >>> >>     >>>
>> >> >>> >>     >>> %chr% 100 %identical% "100"
>> >> >>> >>     >>> #> [1] TRUE
>> >> >>> >>     >>>
>> >> >>> >>     >>> This seems a natural extension of the existing
>> >> >>> >> functionality and
>> >> >>> >>     >>> requires only a minor change to the grammar. If this
>> >> >>> >> change
>> >> >>> seems
>> >> >>> >>     >>> acceptable I am happy to provide a complete patch with
>> >> >>> >> suitable
>> >> >>> >> tests
>> >> >>> >>     >>> and documentation.
>> >> >>> >>     >>>
>> >> >>> >>     >>> [1]:
>> >> >>> >>     >>> Index: src/main/gram.y
>> >> >>> >>     >>>
>> >> >>> >>
>> >> >>> >> ===================================================================
>> >> >>> >>     >>> --- src/main/gram.y     (revision 72358)
>> >> >>> >>     >>> +++ src/main/gram.y     (working copy)
>> >> >>> >>     >>> @@ -357,6 +357,7 @@
>> >> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
>> >> >>> >> xxunary($1,$2);
>> >> >>> >>     >>> setId( $$, @$); }
>> >> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
>> >> >>> >> xxunary($1,$2);
>> >> >>> >>     >>> setId( $$, @$); }
>> >> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
>> >> >>> >> xxunary($1,$2);
>> >> >>> >>     >>> setId( $$, @$); }
>> >> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
>> >> >>> >> xxunary($1,$2);
>> >> >>> >>     >>> setId( $$, @$); }
>> >> >>> >>     >>> |       '?' expr                        { $$ =
>> >> >>> >> xxunary($1,$2);
>> >> >>> >>     >>> setId( $$, @$); }
>> >> >>> >>     >>>
>> >> >>> >>     >>> |       expr ':'  expr                  { $$ =
>> >> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>> >> >>> >>     >>>
>> >> >>> >>     >>> ______________________________________________
>> >> >>> >>     >>> R-devel at r-project.org mailing list
>> >> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>> >>     >>
>> >> >>> >>     >>
>> >> >>> >>     >>
>> >> >>> >>     >>
>> >> >>> >>     >> --
>> >> >>> >>     >> Gabriel Becker, PhD
>> >> >>> >>     >> Associate Scientist (Bioinformatics)
>> >> >>> >>     >> Genentech Research
>> >> >>> >>
>> >> >>> >>     > ______________________________________________
>> >> >>> >>     > R-devel at r-project.org mailing list
>> >> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>> >
>> >> >>> >
>> >> >>> >
>> >> >>> >
>> >> >>> > --
>> >> >>> > Gabriel Becker, PhD
>> >> >>> > Associate Scientist (Bioinformatics)
>> >> >>> > Genentech Research
>> >> >>>
>> >> >>> ______________________________________________
>> >> >>> R-devel at r-project.org mailing list
>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>>
>> >> >>
>> >> >>         [[alternative HTML version deleted]]
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>> >
>> >
>> > --
>> > Gabriel Becker, PhD
>> > Associate Scientist (Bioinformatics)
>> > Genentech Research
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From gmbecker at ucdavis.edu  Fri Mar 17 21:09:25 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 17 Mar 2017 13:09:25 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAF8bMcaQMw3Ymh4JWodoHWP0_=ZJQO3jpm=AFqc7uQ2-wPs5cQ@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>
	<CADwqtCMhJBbed_EE=9zbfCU+0FRg7P89=S0U30bQ84aM6aWNQA@mail.gmail.com>
	<CAF8bMcaQMw3Ymh4JWodoHWP0_=ZJQO3jpm=AFqc7uQ2-wPs5cQ@mail.gmail.com>
Message-ID: <CADwqtCNgakpGMTZMsebq7KeSybJcs1QXk9jvrPCoLWjaQwvVWQ@mail.gmail.com>

Bill,

Right. My example was the functional form for clarity.

There is a desire for a unary-operator form. (rlang's !! and !!! operators
described in the comments in the file I linked to).  I can't really make
that argument because I'm not one of the people who wanted that. You'd have
to talk to the authors of the rlang package to find out their reasons for
thinking that is important. All I know is that empirically, they seem to
feel that way. There may also be issues with the use of . specifically,
because this is in the "tidyverse" context where piping is common and . is
used for something else there, but again that's conjecture on my part.

Best,
~G

On Fri, Mar 17, 2017 at 12:53 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Your example
>    x = 5
>    exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
>    do_unquote(expr)
>     # -> the language object f(5) + y + z
> could be done with the following wrapper for bquote
>    my_do_unquote <- function(language, envir = parent.frame()) {
>       if (is.expression(language)) {
>          # bquote does not go into expressions, only calls
>          as.expression(lapply(language, my_do_unquote))
>       } else {
>          do.call(bquote, list(language, where=envir))
>       }
>    }
> as in
>    > x <- 5
>    > exp <- parse(text="f(.(x)) + y +z") # dot is uq for bquote
>    > exp
>    expression(f(.(x)) + y +z)
>    > my_do_unquote(exp)
>    expression(f(5) + y + z)
> Or do uq() and do_unquote() do more than that?  E.g., would
> uq() carry information about environments?
>
> [I think expressions should map to expressions and calls to calls.
> Otherwise what would we do with multicall expressions?]
>
> We probably need to come up with a better name than 'non-standard
> evaluation' since there are lots of non-standard ways of doing things.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Mar 17, 2017 at 12:14 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> > William,
> >
> > Unbeknownst to me when I sent this, Jonathon Carrol started a specific
> > thread about unquoting and a proposal for supporting it at the language
> > level, which I think is a better place to discuss unquoting specifically.
> > That said, the basics as I understand them in the context of non-standard
> > evaluation, unquoting (or perhaps interpolation) is essentially
> substituting
> > part of an unevaluated expression with its evaluated value inlined. The
> > unquote operator, then, is the way of marking which parts of the
> expression
> > should be substituted in that way (i.e. interpolated).
> >
> > i.e. if uq() is the unquote "operator" and do_unquote interpolates, then
> if
> > we have
> >
> > x = 5
> >
> > exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
> >
> >
> > Then do_unquote would give you the expression f(5) + y + z
> >
> > In terms of what it does that the tilde does not, it would give you the
> > ability to partially evaluate the captured formula/expression, without
> fully
> > doing so.  See the roxygen comments in Hadley and Lionel's rlang package
> > here: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R
> >
> > The desired precedence of such a unary operator is not clear to me. The
> way
> > rlang implements the !! now, it is quite low, so in the examples you see
> > there the ~list(!! x + x) is transformed to ~list(10), not ~list(5+x) as
> I
> > would have expected.  I'm confused by this given what I understand the
> > purpose to be, but that probably just means I'm not the right person to
> ask.
> >
> > Hope that helps.
> >
> > Best,
> > ~G
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > On Fri, Mar 17, 2017 at 8:55 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >>
> >> >After off list discussions with Jonathan Carrol and with
> >> >Michael Lawrence I think it's doable, unambiguous,
> >> >and even imo pretty intuitive for an "unquote" operator.
> >>
> >> For those of us who are not CS/Lisp mavens, what is an
> >> "unquote" operator?  Can you expression quoting and unquoting
> >> in R syntax and show a few examples where is is useful,
> >> intuitive, and fits in to R's functional design?  In particular,
> >> what does it give us that the current tilde function does not?
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Fri, Mar 17, 2017 at 6:46 AM, Gabriel Becker <gmbecker at ucdavis.edu>
> >> wrote:
> >> > Jim,
> >> >
> >> > One more note about precedence. It prevents a solution like the one
> you
> >> > proposed from solving all of the problems you cited. By my reckoning,
> a
> >> > "What comes next is for NSE" unary operator needs an extremely low
> >> > precedence, because it needs to greedily grab "everything" (or a large
> >> > amount) that comes after it. Normal-style unary operators, on the
> other
> >> > hand, explicitly don't want that.
> >> >
> >> > From what I can see, your patch provides support for the latter but
> not
> >> > the
> >> > former.
> >> >
> >> > That said I think there are two issues here. One is can users define
> >> > unary
> >> > operators. FWIW my opinion on that is roughly neutral to slightly
> >> > positive.
> >> > The other issue is can we have quasi quotation of the type that Hadley
> >> > and
> >> > Lionel need in the language. This could be solved without allowing
> >> > user-defined unary specials, and we would probably want it to be, as I
> >> > doubt
> >> > ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it
> >> > isn't
> >> > to me). I'd propose coopting unary @ for that myself. After off list
> >> > discussions with Jonathan Carrol and with Michael Lawrence I think
> it's
> >> > doable, unambiguous, and even imo pretty intuitive for an "unquote"
> >> > operator.
> >> >
> >> > Best,
> >> > ~G
> >> >
> >> > On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> I agree there is no reason they _need_ to be the same precedence, but
> >> >> I think SPECIALS are already have the proper precedence for both
> unary
> >> >> and binary calls. Namely higher than all the binary operators (except
> >> >> for `:`), but lower than the other unary operators. Even if we gave
> >> >> unary specials their own precedence I think it would end up in the
> >> >> same place.
> >> >>
> >> >>     `%l%` <- function(x) tail(x, n = 1)
> >> >>     %l% 1:5
> >> >>     #> [1] 5
> >> >>     %l% -5:-10
> >> >>     #> [1] -10
> >> >>
> >> >> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com>
> >> >> wrote:
> >> >> > I am biased against introducing new syntax, but if one is
> >> >> > experimenting with it one should make sure the precedence feels
> >> >> > right.
> >> >> > I think the unary and binary minus-sign operators have different
> >> >> > precedences so I see no a priori reason to make the unary and
> binary
> >> >> > %xxx% operators to be the same.
> >> >> > Bill Dunlap
> >> >> > TIBCO Software
> >> >> > wdunlap tibco.com
> >> >> >
> >> >> >
> >> >> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
> >> >> > <lawrence.michael at gene.com> wrote:
> >> >> >> I guess this would establish a separate "namespace" of symbolic
> >> >> >> prefix
> >> >> >> operators, %*% being an example in the infix case. So you could
> have
> >> >> >> stuff
> >> >> >> like %?%, but for non-symbolic (spelled out stuff like %foo%),
> it's
> >> >> >> hard to
> >> >> >> see the advantage vs. foo(x).
> >> >> >>
> >> >> >> Those examples you mention should probably be addressed
> (eventually)
> >> >> >> in
> >> >> >> the
> >> >> >> core language, and it looks like people are already able to
> >> >> >> experiment,
> >> >> >> so
> >> >> >> I'm not sure there's a significant impetus for this change.
> >> >> >>
> >> >> >> Michael
> >> >> >>
> >> >> >>
> >> >> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester
> >> >> >> <james.f.hester at gmail.com>
> >> >> >> wrote:
> >> >> >>
> >> >> >>> I used the `function(x)` form to explicitly show the function was
> >> >> >>> being called with only one argument, clearly performance
> >> >> >>> implications
> >> >> >>> are not relevant for these examples.
> >> >> >>>
> >> >> >>> I think of this mainly as a gap in the tooling we provide users
> and
> >> >> >>> package authors. R has native prefix `+1`, functional `f(1)` and
> >> >> >>> infix
> >> >> >>> `1 + 1` operators, but we only provide a mechanism to create user
> >> >> >>> defined functional and infix operators.
> >> >> >>>
> >> >> >>> One could also argue that the user defined infix operators are
> also
> >> >> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is
> in
> >> >> >>> the eye of the beholder.
> >> >> >>>
> >> >> >>> The unquote example [1] shows one example where this gap in
> tooling
> >> >> >>> caused authors to co-opt existing unary exclamation operator,
> this
> >> >> >>> same gap is part of the reason the formula [2] and question mark
> >> >> >>> [3]
> >> >> >>> operators have been used elsewhere in non standard contexts.
> >> >> >>>
> >> >> >>> If the language provided package authors with a native way to
> >> >> >>> create
> >> >> >>> unary operators like it already does for the other operator types
> >> >> >>> these machinations would be unnecessary.
> >> >> >>>
> >> >> >>> [1]:
> >> >> >>> https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
> >> >> >>> [2]: https://cran.r-project.org/package=ensurer
> >> >> >>> [3]: https://cran.r-project.org/package=types
> >> >> >>>
> >> >> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker
> >> >> >>> <gmbecker at ucdavis.edu>
> >> >> >>> wrote:
> >> >> >>> > Martin,
> >> >> >>> >
> >> >> >>> > Jim can speak directly to his motivations; I don't claim to be
> >> >> >>> > able
> >> >> >>> > to do
> >> >> >>> > so. That said, I suspect this is related to a conversation on
> >> >> >>> > twitter
> >> >> >>> about
> >> >> >>> > wanting an infix "unquote" operator in the context of the
> >> >> >>> > non-standard
> >> >> >>> > evaluation framework Hadley Wickham and Lionel Henry (and
> >> >> >>> > possibly
> >> >> >>> others)
> >> >> >>> > are working on.
> >> >> >>> >
> >> >> >>> > They're currently using !!! and !! for things related to this,
> >> >> >>> > but
> >> >> >>> > this
> >> >> >>> > effectively requires non-standard parsing, as ~!!x is
> interpreted
> >> >> >>> > as
> >> >> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands
> it.
> >> >> >>> > Others
> >> >> >>> and
> >> >> >>> > I pointed out this was less than desirable, but if something
> like
> >> >> >>> > it
> >> >> >>> > was
> >> >> >>> > going to happen it would hopefully happen in the language
> >> >> >>> > specification,
> >> >> >>> > rather than in a package (and also hopefully not using !!
> >> >> >>> > specifically).
> >> >> >>> >
> >> >> >>> > Like you, I actually tend to prefer the functional form myself
> in
> >> >> >>> > most
> >> >> >>> > cases. There are functional forms that would work for the above
> >> >> >>> > case
> >> >> >>> (e.g.,
> >> >> >>> > something like the .() that DBI uses), but that's probably off
> >> >> >>> > topic
> >> >> >>> here,
> >> >> >>> > and not a decision I'm directly related to anyway.
> >> >> >>> >
> >> >> >>> > Best,
> >> >> >>> > ~G
> >> >> >>> >
> >> >> >>> >
> >> >> >>> >
> >> >> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
> >> >> >>> > <maechler at stat.math.ethz.ch> wrote:
> >> >> >>> >>
> >> >> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
> >> >> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
> >> >> >>> >>
> >> >> >>> >>     > Gabe,
> >> >> >>> >>     > The unary functions have the same precedence as normal
> >> >> >>> >> SPECIALS
> >> >> >>> >>     > (although the new unary forms take precedence over
> binary
> >> >> >>> SPECIALS).
> >> >> >>> >>     > So they are lower precedence than unary + and -. Yes,
> both
> >> >> >>> >> of
> >> >> >>> >> your
> >> >> >>> >>     > examples are valid with this patch, here are the results
> >> >> >>> >> and
> >> >> >>> quoted
> >> >> >>> >>     > forms to see the precedence.
> >> >> >>> >>
> >> >> >>> >>     > `%chr%` <- function(x) as.character(x)
> >> >> >>> >>
> >> >> >>> >>   [more efficient would be     `%chr%` <- as.character]
> >> >> >>> >>
> >> >> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
> >> >> >>> >>     > quote("100" %identical% %chr% 100)
> >> >> >>> >>     > #>  "100" %identical% (`%chr%`(100))
> >> >> >>> >>
> >> >> >>> >>     > "100" %identical% %chr% 100
> >> >> >>> >>     > #> [1] TRUE
> >> >> >>> >>
> >> >> >>> >>     > `%num%` <- as.numeric
> >> >> >>> >>     > quote(1 + - %num% "5")
> >> >> >>> >>     > #> 1 + -(`%num%`("5"))
> >> >> >>> >>
> >> >> >>> >>     > 1 + - %num% "5"
> >> >> >>> >>     > #> [1] -4
> >> >> >>> >>
> >> >> >>> >>     > Jim
> >> >> >>> >>
> >> >> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
> >> >> >>> >> you may know that I like to  applaud Norm Matloff for his book
> >> >> >>> >> title "The Art of R Programming",
> >> >> >>> >> because for me good code should also be beautiful to some
> >> >> >>> >> extent.
> >> >> >>> >>
> >> >> >>> >> I really very much prefer
> >> >> >>> >>
> >> >> >>> >>        f(x)
> >> >> >>> >> to    %f% x
> >> >> >>> >>
> >> >> >>> >> and hence I really really really cannot see why anybody would
> >> >> >>> >> prefer
> >> >> >>> >> the ugliness of
> >> >> >>> >>
> >> >> >>> >>            1 + - %num% "5"
> >> >> >>> >> to
> >> >> >>> >>            1 + -num("5")
> >> >> >>> >>
> >> >> >>> >> (after setting  num <- as.numeric )
> >> >> >>> >>
> >> >> >>> >> Martin
> >> >> >>> >>
> >> >> >>> >>
> >> >> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
> >> >> >>> >> <gmbecker at ucdavis.edu> wrote:
> >> >> >>> >>     >> Jim,
> >> >> >>> >>     >>
> >> >> >>> >>     >> This seems cool. Thanks for proposing it. To be
> concrete,
> >> >> >>> >> he
> >> >> >>> >> user-defined
> >> >> >>> >>     >> unary operations would be of the same precedence (or
> just
> >> >> >>> slightly
> >> >> >>> >> below?)
> >> >> >>> >>     >> built-in unary ones? So
> >> >> >>> >>     >>
> >> >> >>> >>     >> "100" %identical% %chr% 100
> >> >> >>> >>     >>
> >> >> >>> >>     >> would work and return TRUE under your patch?
> >> >> >>> >>     >>
> >> >> >>> >>     >> And  with %num% <- as.numeric, then
> >> >> >>> >>     >>
> >> >> >>> >>     >> 1 + - %num% "5"
> >> >> >>> >>     >>
> >> >> >>> >>     >> would also be legal (though quite ugly imo) and work?
> >> >> >>> >>     >>
> >> >> >>> >>     >> Best,
> >> >> >>> >>     >> ~G
> >> >> >>> >>     >>
> >> >> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
> >> >> >>> >> <james.f.hester at gmail.com>
> >> >> >>> >>     >> wrote:
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> R has long supported user defined binary (infix)
> >> >> >>> >> functions,
> >> >> >>> >> defined
> >> >> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar
> >> >> >>> >> allows
> >> >> >>> >> users
> >> >> >>> to
> >> >> >>> >>     >>> define unary (prefix) functions in the same manner.
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> `%chr%` <- function(x) as.character(x)
> >> >> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> %chr% 100
> >> >> >>> >>     >>> #> [1] "100"
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> %chr% 100 %identical% "100"
> >> >> >>> >>     >>> #> [1] TRUE
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> This seems a natural extension of the existing
> >> >> >>> >> functionality and
> >> >> >>> >>     >>> requires only a minor change to the grammar. If this
> >> >> >>> >> change
> >> >> >>> seems
> >> >> >>> >>     >>> acceptable I am happy to provide a complete patch with
> >> >> >>> >> suitable
> >> >> >>> >> tests
> >> >> >>> >>     >>> and documentation.
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> [1]:
> >> >> >>> >>     >>> Index: src/main/gram.y
> >> >> >>> >>     >>>
> >> >> >>> >>
> >> >> >>> >> ============================================================
> =======
> >> >> >>> >>     >>> --- src/main/gram.y     (revision 72358)
> >> >> >>> >>     >>> +++ src/main/gram.y     (working copy)
> >> >> >>> >>     >>> @@ -357,6 +357,7 @@
> >> >> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
> >> >> >>> >> xxunary($1,$2);
> >> >> >>> >>     >>> setId( $$, @$); }
> >> >> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
> >> >> >>> >> xxunary($1,$2);
> >> >> >>> >>     >>> setId( $$, @$); }
> >> >> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
> >> >> >>> >> xxunary($1,$2);
> >> >> >>> >>     >>> setId( $$, @$); }
> >> >> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
> >> >> >>> >> xxunary($1,$2);
> >> >> >>> >>     >>> setId( $$, @$); }
> >> >> >>> >>     >>> |       '?' expr                        { $$ =
> >> >> >>> >> xxunary($1,$2);
> >> >> >>> >>     >>> setId( $$, @$); }
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> |       expr ':'  expr                  { $$ =
> >> >> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
> >> >> >>> >>     >>>
> >> >> >>> >>     >>> ______________________________________________
> >> >> >>> >>     >>> R-devel at r-project.org mailing list
> >> >> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >>> >>     >>
> >> >> >>> >>     >>
> >> >> >>> >>     >>
> >> >> >>> >>     >>
> >> >> >>> >>     >> --
> >> >> >>> >>     >> Gabriel Becker, PhD
> >> >> >>> >>     >> Associate Scientist (Bioinformatics)
> >> >> >>> >>     >> Genentech Research
> >> >> >>> >>
> >> >> >>> >>     > ______________________________________________
> >> >> >>> >>     > R-devel at r-project.org mailing list
> >> >> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >>> >
> >> >> >>> >
> >> >> >>> >
> >> >> >>> >
> >> >> >>> > --
> >> >> >>> > Gabriel Becker, PhD
> >> >> >>> > Associate Scientist (Bioinformatics)
> >> >> >>> > Genentech Research
> >> >> >>>
> >> >> >>> ______________________________________________
> >> >> >>> R-devel at r-project.org mailing list
> >> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >>>
> >> >> >>
> >> >> >>         [[alternative HTML version deleted]]
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-devel at r-project.org mailing list
> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Gabriel Becker, PhD
> >> > Associate Scientist (Bioinformatics)
> >> > Genentech Research
> >
> >
> >
> >
> > --
> > Gabriel Becker, PhD
> > Associate Scientist (Bioinformatics)
> > Genentech Research
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 17 21:13:25 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Mar 2017 13:13:25 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCNgakpGMTZMsebq7KeSybJcs1QXk9jvrPCoLWjaQwvVWQ@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAF8bMcZtVQHRWE8iMC2srmunn-eyj-WatbBgE5w9drb_zm2p+w@mail.gmail.com>
	<CADwqtCMhJBbed_EE=9zbfCU+0FRg7P89=S0U30bQ84aM6aWNQA@mail.gmail.com>
	<CAF8bMcaQMw3Ymh4JWodoHWP0_=ZJQO3jpm=AFqc7uQ2-wPs5cQ@mail.gmail.com>
	<CADwqtCNgakpGMTZMsebq7KeSybJcs1QXk9jvrPCoLWjaQwvVWQ@mail.gmail.com>
Message-ID: <CAF8bMcY9gTUEM-Fbbrrpzwx4NJs4EgaSHBwnoJehGJ+2rFMyrA@mail.gmail.com>

OK.  I am more concerned now with semantics than the syntax.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 17, 2017 at 1:09 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Bill,
>
> Right. My example was the functional form for clarity.
>
> There is a desire for a unary-operator form. (rlang's !! and !!! operators
> described in the comments in the file I linked to).  I can't really make
> that argument because I'm not one of the people who wanted that. You'd have
> to talk to the authors of the rlang package to find out their reasons for
> thinking that is important. All I know is that empirically, they seem to
> feel that way. There may also be issues with the use of . specifically,
> because this is in the "tidyverse" context where piping is common and . is
> used for something else there, but again that's conjecture on my part.
>
> Best,
> ~G
>
> On Fri, Mar 17, 2017 at 12:53 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> Your example
>>    x = 5
>>    exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
>>    do_unquote(expr)
>>     # -> the language object f(5) + y + z
>> could be done with the following wrapper for bquote
>>    my_do_unquote <- function(language, envir = parent.frame()) {
>>       if (is.expression(language)) {
>>          # bquote does not go into expressions, only calls
>>          as.expression(lapply(language, my_do_unquote))
>>       } else {
>>          do.call(bquote, list(language, where=envir))
>>       }
>>    }
>> as in
>>    > x <- 5
>>    > exp <- parse(text="f(.(x)) + y +z") # dot is uq for bquote
>>    > exp
>>    expression(f(.(x)) + y +z)
>>    > my_do_unquote(exp)
>>    expression(f(5) + y + z)
>> Or do uq() and do_unquote() do more than that?  E.g., would
>> uq() carry information about environments?
>>
>> [I think expressions should map to expressions and calls to calls.
>> Otherwise what would we do with multicall expressions?]
>>
>> We probably need to come up with a better name than 'non-standard
>> evaluation' since there are lots of non-standard ways of doing things.
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Mar 17, 2017 at 12:14 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>> > William,
>> >
>> > Unbeknownst to me when I sent this, Jonathon Carrol started a specific
>> > thread about unquoting and a proposal for supporting it at the language
>> > level, which I think is a better place to discuss unquoting
>> > specifically.
>> > That said, the basics as I understand them in the context of
>> > non-standard
>> > evaluation, unquoting (or perhaps interpolation) is essentially
>> > substituting
>> > part of an unevaluated expression with its evaluated value inlined. The
>> > unquote operator, then, is the way of marking which parts of the
>> > expression
>> > should be substituted in that way (i.e. interpolated).
>> >
>> > i.e. if uq() is the unquote "operator" and do_unquote interpolates, then
>> > if
>> > we have
>> >
>> > x = 5
>> >
>> > exp = parse(text="f(uq(x)) + y +z") # expression: f(uq(x)) +y + z
>> >
>> >
>> > Then do_unquote would give you the expression f(5) + y + z
>> >
>> > In terms of what it does that the tilde does not, it would give you the
>> > ability to partially evaluate the captured formula/expression, without
>> > fully
>> > doing so.  See the roxygen comments in Hadley and Lionel's rlang package
>> > here: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R
>> >
>> > The desired precedence of such a unary operator is not clear to me. The
>> > way
>> > rlang implements the !! now, it is quite low, so in the examples you see
>> > there the ~list(!! x + x) is transformed to ~list(10), not ~list(5+x) as
>> > I
>> > would have expected.  I'm confused by this given what I understand the
>> > purpose to be, but that probably just means I'm not the right person to
>> > ask.
>> >
>> > Hope that helps.
>> >
>> > Best,
>> > ~G
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > On Fri, Mar 17, 2017 at 8:55 AM, William Dunlap <wdunlap at tibco.com>
>> > wrote:
>> >>
>> >> >After off list discussions with Jonathan Carrol and with
>> >> >Michael Lawrence I think it's doable, unambiguous,
>> >> >and even imo pretty intuitive for an "unquote" operator.
>> >>
>> >> For those of us who are not CS/Lisp mavens, what is an
>> >> "unquote" operator?  Can you expression quoting and unquoting
>> >> in R syntax and show a few examples where is is useful,
>> >> intuitive, and fits in to R's functional design?  In particular,
>> >> what does it give us that the current tilde function does not?
>> >>
>> >>
>> >> Bill Dunlap
>> >> TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >>
>> >> On Fri, Mar 17, 2017 at 6:46 AM, Gabriel Becker <gmbecker at ucdavis.edu>
>> >> wrote:
>> >> > Jim,
>> >> >
>> >> > One more note about precedence. It prevents a solution like the one
>> >> > you
>> >> > proposed from solving all of the problems you cited. By my reckoning,
>> >> > a
>> >> > "What comes next is for NSE" unary operator needs an extremely low
>> >> > precedence, because it needs to greedily grab "everything" (or a
>> >> > large
>> >> > amount) that comes after it. Normal-style unary operators, on the
>> >> > other
>> >> > hand, explicitly don't want that.
>> >> >
>> >> > From what I can see, your patch provides support for the latter but
>> >> > not
>> >> > the
>> >> > former.
>> >> >
>> >> > That said I think there are two issues here. One is can users define
>> >> > unary
>> >> > operators. FWIW my opinion on that is roughly neutral to slightly
>> >> > positive.
>> >> > The other issue is can we have quasi quotation of the type that
>> >> > Hadley
>> >> > and
>> >> > Lionel need in the language. This could be solved without allowing
>> >> > user-defined unary specials, and we would probably want it to be, as
>> >> > I
>> >> > doubt
>> >> > ~ %!%x + %!%y + z is  particularly aesthetically appealing to most
>> >> > (it
>> >> > isn't
>> >> > to me). I'd propose coopting unary @ for that myself. After off list
>> >> > discussions with Jonathan Carrol and with Michael Lawrence I think
>> >> > it's
>> >> > doable, unambiguous, and even imo pretty intuitive for an "unquote"
>> >> > operator.
>> >> >
>> >> > Best,
>> >> > ~G
>> >> >
>> >> > On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester
>> >> > <james.f.hester at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> I agree there is no reason they _need_ to be the same precedence,
>> >> >> but
>> >> >> I think SPECIALS are already have the proper precedence for both
>> >> >> unary
>> >> >> and binary calls. Namely higher than all the binary operators
>> >> >> (except
>> >> >> for `:`), but lower than the other unary operators. Even if we gave
>> >> >> unary specials their own precedence I think it would end up in the
>> >> >> same place.
>> >> >>
>> >> >>     `%l%` <- function(x) tail(x, n = 1)
>> >> >>     %l% 1:5
>> >> >>     #> [1] 5
>> >> >>     %l% -5:-10
>> >> >>     #> [1] -10
>> >> >>
>> >> >> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com>
>> >> >> wrote:
>> >> >> > I am biased against introducing new syntax, but if one is
>> >> >> > experimenting with it one should make sure the precedence feels
>> >> >> > right.
>> >> >> > I think the unary and binary minus-sign operators have different
>> >> >> > precedences so I see no a priori reason to make the unary and
>> >> >> > binary
>> >> >> > %xxx% operators to be the same.
>> >> >> > Bill Dunlap
>> >> >> > TIBCO Software
>> >> >> > wdunlap tibco.com
>> >> >> >
>> >> >> >
>> >> >> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
>> >> >> > <lawrence.michael at gene.com> wrote:
>> >> >> >> I guess this would establish a separate "namespace" of symbolic
>> >> >> >> prefix
>> >> >> >> operators, %*% being an example in the infix case. So you could
>> >> >> >> have
>> >> >> >> stuff
>> >> >> >> like %?%, but for non-symbolic (spelled out stuff like %foo%),
>> >> >> >> it's
>> >> >> >> hard to
>> >> >> >> see the advantage vs. foo(x).
>> >> >> >>
>> >> >> >> Those examples you mention should probably be addressed
>> >> >> >> (eventually)
>> >> >> >> in
>> >> >> >> the
>> >> >> >> core language, and it looks like people are already able to
>> >> >> >> experiment,
>> >> >> >> so
>> >> >> >> I'm not sure there's a significant impetus for this change.
>> >> >> >>
>> >> >> >> Michael
>> >> >> >>
>> >> >> >>
>> >> >> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester
>> >> >> >> <james.f.hester at gmail.com>
>> >> >> >> wrote:
>> >> >> >>
>> >> >> >>> I used the `function(x)` form to explicitly show the function
>> >> >> >>> was
>> >> >> >>> being called with only one argument, clearly performance
>> >> >> >>> implications
>> >> >> >>> are not relevant for these examples.
>> >> >> >>>
>> >> >> >>> I think of this mainly as a gap in the tooling we provide users
>> >> >> >>> and
>> >> >> >>> package authors. R has native prefix `+1`, functional `f(1)` and
>> >> >> >>> infix
>> >> >> >>> `1 + 1` operators, but we only provide a mechanism to create
>> >> >> >>> user
>> >> >> >>> defined functional and infix operators.
>> >> >> >>>
>> >> >> >>> One could also argue that the user defined infix operators are
>> >> >> >>> also
>> >> >> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is
>> >> >> >>> in
>> >> >> >>> the eye of the beholder.
>> >> >> >>>
>> >> >> >>> The unquote example [1] shows one example where this gap in
>> >> >> >>> tooling
>> >> >> >>> caused authors to co-opt existing unary exclamation operator,
>> >> >> >>> this
>> >> >> >>> same gap is part of the reason the formula [2] and question mark
>> >> >> >>> [3]
>> >> >> >>> operators have been used elsewhere in non standard contexts.
>> >> >> >>>
>> >> >> >>> If the language provided package authors with a native way to
>> >> >> >>> create
>> >> >> >>> unary operators like it already does for the other operator
>> >> >> >>> types
>> >> >> >>> these machinations would be unnecessary.
>> >> >> >>>
>> >> >> >>> [1]:
>> >> >> >>> https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>> >> >> >>> [2]: https://cran.r-project.org/package=ensurer
>> >> >> >>> [3]: https://cran.r-project.org/package=types
>> >> >> >>>
>> >> >> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker
>> >> >> >>> <gmbecker at ucdavis.edu>
>> >> >> >>> wrote:
>> >> >> >>> > Martin,
>> >> >> >>> >
>> >> >> >>> > Jim can speak directly to his motivations; I don't claim to be
>> >> >> >>> > able
>> >> >> >>> > to do
>> >> >> >>> > so. That said, I suspect this is related to a conversation on
>> >> >> >>> > twitter
>> >> >> >>> about
>> >> >> >>> > wanting an infix "unquote" operator in the context of the
>> >> >> >>> > non-standard
>> >> >> >>> > evaluation framework Hadley Wickham and Lionel Henry (and
>> >> >> >>> > possibly
>> >> >> >>> others)
>> >> >> >>> > are working on.
>> >> >> >>> >
>> >> >> >>> > They're currently using !!! and !! for things related to this,
>> >> >> >>> > but
>> >> >> >>> > this
>> >> >> >>> > effectively requires non-standard parsing, as ~!!x is
>> >> >> >>> > interpreted
>> >> >> >>> > as
>> >> >> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands
>> >> >> >>> > it.
>> >> >> >>> > Others
>> >> >> >>> and
>> >> >> >>> > I pointed out this was less than desirable, but if something
>> >> >> >>> > like
>> >> >> >>> > it
>> >> >> >>> > was
>> >> >> >>> > going to happen it would hopefully happen in the language
>> >> >> >>> > specification,
>> >> >> >>> > rather than in a package (and also hopefully not using !!
>> >> >> >>> > specifically).
>> >> >> >>> >
>> >> >> >>> > Like you, I actually tend to prefer the functional form myself
>> >> >> >>> > in
>> >> >> >>> > most
>> >> >> >>> > cases. There are functional forms that would work for the
>> >> >> >>> > above
>> >> >> >>> > case
>> >> >> >>> (e.g.,
>> >> >> >>> > something like the .() that DBI uses), but that's probably off
>> >> >> >>> > topic
>> >> >> >>> here,
>> >> >> >>> > and not a decision I'm directly related to anyway.
>> >> >> >>> >
>> >> >> >>> > Best,
>> >> >> >>> > ~G
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>> >> >> >>> > <maechler at stat.math.ethz.ch> wrote:
>> >> >> >>> >>
>> >> >> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >> >> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>> >> >> >>> >>
>> >> >> >>> >>     > Gabe,
>> >> >> >>> >>     > The unary functions have the same precedence as normal
>> >> >> >>> >> SPECIALS
>> >> >> >>> >>     > (although the new unary forms take precedence over
>> >> >> >>> >> binary
>> >> >> >>> SPECIALS).
>> >> >> >>> >>     > So they are lower precedence than unary + and -. Yes,
>> >> >> >>> >> both
>> >> >> >>> >> of
>> >> >> >>> >> your
>> >> >> >>> >>     > examples are valid with this patch, here are the
>> >> >> >>> >> results
>> >> >> >>> >> and
>> >> >> >>> quoted
>> >> >> >>> >>     > forms to see the precedence.
>> >> >> >>> >>
>> >> >> >>> >>     > `%chr%` <- function(x) as.character(x)
>> >> >> >>> >>
>> >> >> >>> >>   [more efficient would be     `%chr%` <- as.character]
>> >> >> >>> >>
>> >> >> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
>> >> >> >>> >>     > quote("100" %identical% %chr% 100)
>> >> >> >>> >>     > #>  "100" %identical% (`%chr%`(100))
>> >> >> >>> >>
>> >> >> >>> >>     > "100" %identical% %chr% 100
>> >> >> >>> >>     > #> [1] TRUE
>> >> >> >>> >>
>> >> >> >>> >>     > `%num%` <- as.numeric
>> >> >> >>> >>     > quote(1 + - %num% "5")
>> >> >> >>> >>     > #> 1 + -(`%num%`("5"))
>> >> >> >>> >>
>> >> >> >>> >>     > 1 + - %num% "5"
>> >> >> >>> >>     > #> [1] -4
>> >> >> >>> >>
>> >> >> >>> >>     > Jim
>> >> >> >>> >>
>> >> >> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>> >> >> >>> >> you may know that I like to  applaud Norm Matloff for his
>> >> >> >>> >> book
>> >> >> >>> >> title "The Art of R Programming",
>> >> >> >>> >> because for me good code should also be beautiful to some
>> >> >> >>> >> extent.
>> >> >> >>> >>
>> >> >> >>> >> I really very much prefer
>> >> >> >>> >>
>> >> >> >>> >>        f(x)
>> >> >> >>> >> to    %f% x
>> >> >> >>> >>
>> >> >> >>> >> and hence I really really really cannot see why anybody would
>> >> >> >>> >> prefer
>> >> >> >>> >> the ugliness of
>> >> >> >>> >>
>> >> >> >>> >>            1 + - %num% "5"
>> >> >> >>> >> to
>> >> >> >>> >>            1 + -num("5")
>> >> >> >>> >>
>> >> >> >>> >> (after setting  num <- as.numeric )
>> >> >> >>> >>
>> >> >> >>> >> Martin
>> >> >> >>> >>
>> >> >> >>> >>
>> >> >> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> >> >> >>> >> <gmbecker at ucdavis.edu> wrote:
>> >> >> >>> >>     >> Jim,
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> This seems cool. Thanks for proposing it. To be
>> >> >> >>> >> concrete,
>> >> >> >>> >> he
>> >> >> >>> >> user-defined
>> >> >> >>> >>     >> unary operations would be of the same precedence (or
>> >> >> >>> >> just
>> >> >> >>> slightly
>> >> >> >>> >> below?)
>> >> >> >>> >>     >> built-in unary ones? So
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> "100" %identical% %chr% 100
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> would work and return TRUE under your patch?
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> And  with %num% <- as.numeric, then
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> 1 + - %num% "5"
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> would also be legal (though quite ugly imo) and work?
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> Best,
>> >> >> >>> >>     >> ~G
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> >> >> >>> >> <james.f.hester at gmail.com>
>> >> >> >>> >>     >> wrote:
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> R has long supported user defined binary (infix)
>> >> >> >>> >> functions,
>> >> >> >>> >> defined
>> >> >> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar
>> >> >> >>> >> allows
>> >> >> >>> >> users
>> >> >> >>> to
>> >> >> >>> >>     >>> define unary (prefix) functions in the same manner.
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> `%chr%` <- function(x) as.character(x)
>> >> >> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> %chr% 100
>> >> >> >>> >>     >>> #> [1] "100"
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> %chr% 100 %identical% "100"
>> >> >> >>> >>     >>> #> [1] TRUE
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> This seems a natural extension of the existing
>> >> >> >>> >> functionality and
>> >> >> >>> >>     >>> requires only a minor change to the grammar. If this
>> >> >> >>> >> change
>> >> >> >>> seems
>> >> >> >>> >>     >>> acceptable I am happy to provide a complete patch
>> >> >> >>> >> with
>> >> >> >>> >> suitable
>> >> >> >>> >> tests
>> >> >> >>> >>     >>> and documentation.
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> [1]:
>> >> >> >>> >>     >>> Index: src/main/gram.y
>> >> >> >>> >>     >>>
>> >> >> >>> >>
>> >> >> >>> >>
>> >> >> >>> >> ===================================================================
>> >> >> >>> >>     >>> --- src/main/gram.y     (revision 72358)
>> >> >> >>> >>     >>> +++ src/main/gram.y     (working copy)
>> >> >> >>> >>     >>> @@ -357,6 +357,7 @@
>> >> >> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
>> >> >> >>> >> xxunary($1,$2);
>> >> >> >>> >>     >>> setId( $$, @$); }
>> >> >> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
>> >> >> >>> >> xxunary($1,$2);
>> >> >> >>> >>     >>> setId( $$, @$); }
>> >> >> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
>> >> >> >>> >> xxunary($1,$2);
>> >> >> >>> >>     >>> setId( $$, @$); }
>> >> >> >>> >>     >>> +       |       SPECIAL expr                    { $$
>> >> >> >>> >> =
>> >> >> >>> >> xxunary($1,$2);
>> >> >> >>> >>     >>> setId( $$, @$); }
>> >> >> >>> >>     >>> |       '?' expr                        { $$ =
>> >> >> >>> >> xxunary($1,$2);
>> >> >> >>> >>     >>> setId( $$, @$); }
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> |       expr ':'  expr                  { $$ =
>> >> >> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>> >> >> >>> >>     >>>
>> >> >> >>> >>     >>> ______________________________________________
>> >> >> >>> >>     >>> R-devel at r-project.org mailing list
>> >> >> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >>> >>     >>
>> >> >> >>> >>     >>
>> >> >> >>> >>     >>
>> >> >> >>> >>     >>
>> >> >> >>> >>     >> --
>> >> >> >>> >>     >> Gabriel Becker, PhD
>> >> >> >>> >>     >> Associate Scientist (Bioinformatics)
>> >> >> >>> >>     >> Genentech Research
>> >> >> >>> >>
>> >> >> >>> >>     > ______________________________________________
>> >> >> >>> >>     > R-devel at r-project.org mailing list
>> >> >> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> >
>> >> >> >>> > --
>> >> >> >>> > Gabriel Becker, PhD
>> >> >> >>> > Associate Scientist (Bioinformatics)
>> >> >> >>> > Genentech Research
>> >> >> >>>
>> >> >> >>> ______________________________________________
>> >> >> >>> R-devel at r-project.org mailing list
>> >> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >> >>>
>> >> >> >>
>> >> >> >>         [[alternative HTML version deleted]]
>> >> >> >>
>> >> >> >> ______________________________________________
>> >> >> >> R-devel at r-project.org mailing list
>> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > Gabriel Becker, PhD
>> >> > Associate Scientist (Bioinformatics)
>> >> > Genentech Research
>> >
>> >
>> >
>> >
>> > --
>> > Gabriel Becker, PhD
>> > Associate Scientist (Bioinformatics)
>> > Genentech Research
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From avraham.adler at gmail.com  Fri Mar 17 21:44:57 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 17 Mar 2017 20:44:57 +0000
Subject: [Rd] R 3.4.0
In-Reply-To: <alpine.DEB.2.20.1703171121020.2612@luke-Latitude>
References: <E23A740D-BD85-4D77-ACFD-5334C2BA0D88@cbs.dk>
	<alpine.DEB.2.20.1703171121020.2612@luke-Latitude>
Message-ID: <CAL6gwnJv4qaDuq+x8MZRFfexO9jDEzDonY48Ech6L0gDDzra5A@mail.gmail.com>

Perhaps the darkness is so stupid it forgot to update the year?

Avi
On Fri, Mar 17, 2017 at 12:24 PM <luke-tierney at uiowa.edu> wrote:

> Your dates are for 2016 :-) in your email and developer.r-project.com
>
> Best,
>
> luke
>
> On Fri, 17 Mar 2017, Peter Dalgaard wrote:
>
> > R 3.4.0 "You Stupid Darkness" is now scheduled for April 21
> >
> > The detailed schedule can be found on developer.r-project.org
> >
> > For the Core Team
> >
> > Peter D.
> >
> >
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From rzepeda17 at gmail.com  Fri Mar 17 19:56:06 2017
From: rzepeda17 at gmail.com (Rodrigo Zepeda)
Date: Fri, 17 Mar 2017 12:56:06 -0600
Subject: [Rd] Hyperbolic tangent different results on Windows and Mac
Message-ID: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>

Dear all,

We seem to have found a "strange" behaviour in the hyperbolic tangent
function tanh on Windows.
When running tanh(356 + 0i) the Windows result is NaN + 0.i while on Mac
the result is 1 + 0i. It doesn't seem to be a floating point error because
on Mac it is possible to run arbitrarily large numbers (say tanh(
999999677873648767519238192348124812341234182374817239847812738481234871823+0i)
) and still get 1 + 0i as result. This seems to be related to the imaginary
part as tanh(356) returns 1 in both Windows and Mac.

We have obtained those results in:
1) Mac with El Capitan v 10.11.6 *processor: 2.7 GHz Intel Core i5*
- 2) Mac with Sierra v 10.12.3 *processor: 3.2 GHz Intel Core i5*
- 3) Windows 10 Home v 1607 *processor: Intel Core m3-SY30 CPU@ 0.90 GHz
1.51 GHz*
- 4) Windows 7 Home Premium Service Pack 1 *processor: Intel Core i5-2410M
CPU @2.30 GHz 2.30GHz.*

?In all cases we are using R version 3.3.3 (64 bits)?

- *Does anybody have a clue on why is this happening?*
-
?PS: We have previously posted this issue in Stack Overflow (
http://stackoverflow.com/questions/42847414/hyperbolic-tangent-in-r-throws-nan-in-windows-but-not-in-mac).
A comment suggests it is related to a glibc bug.

?
?Thanks,?
Rod

	[[alternative HTML version deleted]]


From james.f.hester at gmail.com  Fri Mar 17 23:02:32 2017
From: james.f.hester at gmail.com (Jim Hester)
Date: Fri, 17 Mar 2017 18:02:32 -0400
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
Message-ID: <CAD6tx961FZG0LDROP6NBhep7-bXNLYJRjPUz91mk+KZuo2K+pw@mail.gmail.com>

The unquoting discussion is IMHO separate from this proposal and as
you noted probably better served by a native operator with different
precedence.

I think the main benefit to providing user defined prefix operators is
it allows package authors to experiment with operator ideas and gauge
community interest. The current situation means any novel unary
semantics either need to co-opt existing unary operators or propose
changes to the R parser, neither of which is ideal for
experimentation.

The user defined pipe operator (%>%), now used by > 300 packages, is
an example that giving package authors the power to experiment can
produce beneficial ideas for the community.

On Fri, Mar 17, 2017 at 9:46 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Jim,
>
> One more note about precedence. It prevents a solution like the one you
> proposed from solving all of the problems you cited. By my reckoning, a
> "What comes next is for NSE" unary operator needs an extremely low
> precedence, because it needs to greedily grab "everything" (or a large
> amount) that comes after it. Normal-style unary operators, on the other
> hand, explicitly don't want that.
>
> From what I can see, your patch provides support for the latter but not the
> former.
>
> That said I think there are two issues here. One is can users define unary
> operators. FWIW my opinion on that is roughly neutral to slightly positive.
> The other issue is can we have quasi quotation of the type that Hadley and
> Lionel need in the language. This could be solved without allowing
> user-defined unary specials, and we would probably want it to be, as I doubt
> ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it isn't
> to me). I'd propose coopting unary @ for that myself. After off list
> discussions with Jonathan Carrol and with Michael Lawrence I think it's
> doable, unambiguous, and even imo pretty intuitive for an "unquote"
> operator.
>
> Best,
> ~G
>
> On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
> wrote:
>>
>> I agree there is no reason they _need_ to be the same precedence, but
>> I think SPECIALS are already have the proper precedence for both unary
>> and binary calls. Namely higher than all the binary operators (except
>> for `:`), but lower than the other unary operators. Even if we gave
>> unary specials their own precedence I think it would end up in the
>> same place.
>>
>>     `%l%` <- function(x) tail(x, n = 1)
>>     %l% 1:5
>>     #> [1] 5
>>     %l% -5:-10
>>     #> [1] -10
>>
>> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> > I am biased against introducing new syntax, but if one is
>> > experimenting with it one should make sure the precedence feels right.
>> > I think the unary and binary minus-sign operators have different
>> > precedences so I see no a priori reason to make the unary and binary
>> > %xxx% operators to be the same.
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> >
>> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
>> > <lawrence.michael at gene.com> wrote:
>> >> I guess this would establish a separate "namespace" of symbolic prefix
>> >> operators, %*% being an example in the infix case. So you could have
>> >> stuff
>> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
>> >> hard to
>> >> see the advantage vs. foo(x).
>> >>
>> >> Those examples you mention should probably be addressed (eventually) in
>> >> the
>> >> core language, and it looks like people are already able to experiment,
>> >> so
>> >> I'm not sure there's a significant impetus for this change.
>> >>
>> >> Michael
>> >>
>> >>
>> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
>> >> wrote:
>> >>
>> >>> I used the `function(x)` form to explicitly show the function was
>> >>> being called with only one argument, clearly performance implications
>> >>> are not relevant for these examples.
>> >>>
>> >>> I think of this mainly as a gap in the tooling we provide users and
>> >>> package authors. R has native prefix `+1`, functional `f(1)` and infix
>> >>> `1 + 1` operators, but we only provide a mechanism to create user
>> >>> defined functional and infix operators.
>> >>>
>> >>> One could also argue that the user defined infix operators are also
>> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>> >>> the eye of the beholder.
>> >>>
>> >>> The unquote example [1] shows one example where this gap in tooling
>> >>> caused authors to co-opt existing unary exclamation operator, this
>> >>> same gap is part of the reason the formula [2] and question mark [3]
>> >>> operators have been used elsewhere in non standard contexts.
>> >>>
>> >>> If the language provided package authors with a native way to create
>> >>> unary operators like it already does for the other operator types
>> >>> these machinations would be unnecessary.
>> >>>
>> >>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>> >>> [2]: https://cran.r-project.org/package=ensurer
>> >>> [3]: https://cran.r-project.org/package=types
>> >>>
>> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> >>> wrote:
>> >>> > Martin,
>> >>> >
>> >>> > Jim can speak directly to his motivations; I don't claim to be able
>> >>> > to do
>> >>> > so. That said, I suspect this is related to a conversation on
>> >>> > twitter
>> >>> about
>> >>> > wanting an infix "unquote" operator in the context of the
>> >>> > non-standard
>> >>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
>> >>> others)
>> >>> > are working on.
>> >>> >
>> >>> > They're currently using !!! and !! for things related to this, but
>> >>> > this
>> >>> > effectively requires non-standard parsing, as ~!!x is interpreted as
>> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
>> >>> > Others
>> >>> and
>> >>> > I pointed out this was less than desirable, but if something like it
>> >>> > was
>> >>> > going to happen it would hopefully happen in the language
>> >>> > specification,
>> >>> > rather than in a package (and also hopefully not using !!
>> >>> > specifically).
>> >>> >
>> >>> > Like you, I actually tend to prefer the functional form myself in
>> >>> > most
>> >>> > cases. There are functional forms that would work for the above case
>> >>> (e.g.,
>> >>> > something like the .() that DBI uses), but that's probably off topic
>> >>> here,
>> >>> > and not a decision I'm directly related to anyway.
>> >>> >
>> >>> > Best,
>> >>> > ~G
>> >>> >
>> >>> >
>> >>> >
>> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>> >>> > <maechler at stat.math.ethz.ch> wrote:
>> >>> >>
>> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>> >>> >>
>> >>> >>     > Gabe,
>> >>> >>     > The unary functions have the same precedence as normal
>> >>> >> SPECIALS
>> >>> >>     > (although the new unary forms take precedence over binary
>> >>> SPECIALS).
>> >>> >>     > So they are lower precedence than unary + and -. Yes, both of
>> >>> >> your
>> >>> >>     > examples are valid with this patch, here are the results and
>> >>> quoted
>> >>> >>     > forms to see the precedence.
>> >>> >>
>> >>> >>     > `%chr%` <- function(x) as.character(x)
>> >>> >>
>> >>> >>   [more efficient would be     `%chr%` <- as.character]
>> >>> >>
>> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
>> >>> >>     > quote("100" %identical% %chr% 100)
>> >>> >>     > #>  "100" %identical% (`%chr%`(100))
>> >>> >>
>> >>> >>     > "100" %identical% %chr% 100
>> >>> >>     > #> [1] TRUE
>> >>> >>
>> >>> >>     > `%num%` <- as.numeric
>> >>> >>     > quote(1 + - %num% "5")
>> >>> >>     > #> 1 + -(`%num%`("5"))
>> >>> >>
>> >>> >>     > 1 + - %num% "5"
>> >>> >>     > #> [1] -4
>> >>> >>
>> >>> >>     > Jim
>> >>> >>
>> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>> >>> >> you may know that I like to  applaud Norm Matloff for his book
>> >>> >> title "The Art of R Programming",
>> >>> >> because for me good code should also be beautiful to some extent.
>> >>> >>
>> >>> >> I really very much prefer
>> >>> >>
>> >>> >>        f(x)
>> >>> >> to    %f% x
>> >>> >>
>> >>> >> and hence I really really really cannot see why anybody would
>> >>> >> prefer
>> >>> >> the ugliness of
>> >>> >>
>> >>> >>            1 + - %num% "5"
>> >>> >> to
>> >>> >>            1 + -num("5")
>> >>> >>
>> >>> >> (after setting  num <- as.numeric )
>> >>> >>
>> >>> >> Martin
>> >>> >>
>> >>> >>
>> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>> >>> >> <gmbecker at ucdavis.edu> wrote:
>> >>> >>     >> Jim,
>> >>> >>     >>
>> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
>> >>> >> user-defined
>> >>> >>     >> unary operations would be of the same precedence (or just
>> >>> slightly
>> >>> >> below?)
>> >>> >>     >> built-in unary ones? So
>> >>> >>     >>
>> >>> >>     >> "100" %identical% %chr% 100
>> >>> >>     >>
>> >>> >>     >> would work and return TRUE under your patch?
>> >>> >>     >>
>> >>> >>     >> And  with %num% <- as.numeric, then
>> >>> >>     >>
>> >>> >>     >> 1 + - %num% "5"
>> >>> >>     >>
>> >>> >>     >> would also be legal (though quite ugly imo) and work?
>> >>> >>     >>
>> >>> >>     >> Best,
>> >>> >>     >> ~G
>> >>> >>     >>
>> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>> >>> >> <james.f.hester at gmail.com>
>> >>> >>     >> wrote:
>> >>> >>     >>>
>> >>> >>     >>> R has long supported user defined binary (infix) functions,
>> >>> >> defined
>> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows
>> >>> >> users
>> >>> to
>> >>> >>     >>> define unary (prefix) functions in the same manner.
>> >>> >>     >>>
>> >>> >>     >>> `%chr%` <- function(x) as.character(x)
>> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>> >>> >>     >>>
>> >>> >>     >>> %chr% 100
>> >>> >>     >>> #> [1] "100"
>> >>> >>     >>>
>> >>> >>     >>> %chr% 100 %identical% "100"
>> >>> >>     >>> #> [1] TRUE
>> >>> >>     >>>
>> >>> >>     >>> This seems a natural extension of the existing
>> >>> >> functionality and
>> >>> >>     >>> requires only a minor change to the grammar. If this change
>> >>> seems
>> >>> >>     >>> acceptable I am happy to provide a complete patch with
>> >>> >> suitable
>> >>> >> tests
>> >>> >>     >>> and documentation.
>> >>> >>     >>>
>> >>> >>     >>> [1]:
>> >>> >>     >>> Index: src/main/gram.y
>> >>> >>     >>>
>> >>> >> ===================================================================
>> >>> >>     >>> --- src/main/gram.y     (revision 72358)
>> >>> >>     >>> +++ src/main/gram.y     (working copy)
>> >>> >>     >>> @@ -357,6 +357,7 @@
>> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>> |       '?' expr                        { $$ =
>> >>> >> xxunary($1,$2);
>> >>> >>     >>> setId( $$, @$); }
>> >>> >>     >>>
>> >>> >>     >>> |       expr ':'  expr                  { $$ =
>> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>> >>> >>     >>>
>> >>> >>     >>> ______________________________________________
>> >>> >>     >>> R-devel at r-project.org mailing list
>> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >>
>> >>> >>     >> --
>> >>> >>     >> Gabriel Becker, PhD
>> >>> >>     >> Associate Scientist (Bioinformatics)
>> >>> >>     >> Genentech Research
>> >>> >>
>> >>> >>     > ______________________________________________
>> >>> >>     > R-devel at r-project.org mailing list
>> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>> >
>> >>> >
>> >>> >
>> >>> >
>> >>> > --
>> >>> > Gabriel Becker, PhD
>> >>> > Associate Scientist (Bioinformatics)
>> >>> > Genentech Research
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research


From wdunlap at tibco.com  Fri Mar 17 23:41:34 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Mar 2017 15:41:34 -0700
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx961FZG0LDROP6NBhep7-bXNLYJRjPUz91mk+KZuo2K+pw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAD6tx961FZG0LDROP6NBhep7-bXNLYJRjPUz91mk+KZuo2K+pw@mail.gmail.com>
Message-ID: <CAF8bMcadX4Ya9etDi=a5erc7d1qV3memrekqg3mi+YyA6UPptQ@mail.gmail.com>

I can see that allowing a user-defined unary prefix operator can be useful.
We want to make sure its precedence and associative behavior are
convenient for a variety of envisioned uses, as we won't get a chance
to change them after the language construct is introduced.

An example of precedence getting in the way is when you would like
to define a matrix-exponentiation operator, %^%.  It will have the same
precedence as %% so
   - x %^% 2
will be equivalent to
   (-x) %^% 2
and not to
   - (x %^% 2)

[A long time ago someone wanted new postfix operators (e.g., bang for
factorial).  Is that desire still around?]

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Mar 17, 2017 at 3:02 PM, Jim Hester <james.f.hester at gmail.com> wrote:
> The unquoting discussion is IMHO separate from this proposal and as
> you noted probably better served by a native operator with different
> precedence.
>
> I think the main benefit to providing user defined prefix operators is
> it allows package authors to experiment with operator ideas and gauge
> community interest. The current situation means any novel unary
> semantics either need to co-opt existing unary operators or propose
> changes to the R parser, neither of which is ideal for
> experimentation.
>
> The user defined pipe operator (%>%), now used by > 300 packages, is
> an example that giving package authors the power to experiment can
> produce beneficial ideas for the community.
>
> On Fri, Mar 17, 2017 at 9:46 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>> Jim,
>>
>> One more note about precedence. It prevents a solution like the one you
>> proposed from solving all of the problems you cited. By my reckoning, a
>> "What comes next is for NSE" unary operator needs an extremely low
>> precedence, because it needs to greedily grab "everything" (or a large
>> amount) that comes after it. Normal-style unary operators, on the other
>> hand, explicitly don't want that.
>>
>> From what I can see, your patch provides support for the latter but not the
>> former.
>>
>> That said I think there are two issues here. One is can users define unary
>> operators. FWIW my opinion on that is roughly neutral to slightly positive.
>> The other issue is can we have quasi quotation of the type that Hadley and
>> Lionel need in the language. This could be solved without allowing
>> user-defined unary specials, and we would probably want it to be, as I doubt
>> ~ %!%x + %!%y + z is  particularly aesthetically appealing to most (it isn't
>> to me). I'd propose coopting unary @ for that myself. After off list
>> discussions with Jonathan Carrol and with Michael Lawrence I think it's
>> doable, unambiguous, and even imo pretty intuitive for an "unquote"
>> operator.
>>
>> Best,
>> ~G
>>
>> On Fri, Mar 17, 2017 at 5:10 AM, Jim Hester <james.f.hester at gmail.com>
>> wrote:
>>>
>>> I agree there is no reason they _need_ to be the same precedence, but
>>> I think SPECIALS are already have the proper precedence for both unary
>>> and binary calls. Namely higher than all the binary operators (except
>>> for `:`), but lower than the other unary operators. Even if we gave
>>> unary specials their own precedence I think it would end up in the
>>> same place.
>>>
>>>     `%l%` <- function(x) tail(x, n = 1)
>>>     %l% 1:5
>>>     #> [1] 5
>>>     %l% -5:-10
>>>     #> [1] -10
>>>
>>> On Thu, Mar 16, 2017 at 6:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> > I am biased against introducing new syntax, but if one is
>>> > experimenting with it one should make sure the precedence feels right.
>>> > I think the unary and binary minus-sign operators have different
>>> > precedences so I see no a priori reason to make the unary and binary
>>> > %xxx% operators to be the same.
>>> > Bill Dunlap
>>> > TIBCO Software
>>> > wdunlap tibco.com
>>> >
>>> >
>>> > On Thu, Mar 16, 2017 at 3:18 PM, Michael Lawrence
>>> > <lawrence.michael at gene.com> wrote:
>>> >> I guess this would establish a separate "namespace" of symbolic prefix
>>> >> operators, %*% being an example in the infix case. So you could have
>>> >> stuff
>>> >> like %?%, but for non-symbolic (spelled out stuff like %foo%), it's
>>> >> hard to
>>> >> see the advantage vs. foo(x).
>>> >>
>>> >> Those examples you mention should probably be addressed (eventually) in
>>> >> the
>>> >> core language, and it looks like people are already able to experiment,
>>> >> so
>>> >> I'm not sure there's a significant impetus for this change.
>>> >>
>>> >> Michael
>>> >>
>>> >>
>>> >> On Thu, Mar 16, 2017 at 10:51 AM, Jim Hester <james.f.hester at gmail.com>
>>> >> wrote:
>>> >>
>>> >>> I used the `function(x)` form to explicitly show the function was
>>> >>> being called with only one argument, clearly performance implications
>>> >>> are not relevant for these examples.
>>> >>>
>>> >>> I think of this mainly as a gap in the tooling we provide users and
>>> >>> package authors. R has native prefix `+1`, functional `f(1)` and infix
>>> >>> `1 + 1` operators, but we only provide a mechanism to create user
>>> >>> defined functional and infix operators.
>>> >>>
>>> >>> One could also argue that the user defined infix operators are also
>>> >>> ugly and could be replaced by `f(a, b)` calls as well; beauty is in
>>> >>> the eye of the beholder.
>>> >>>
>>> >>> The unquote example [1] shows one example where this gap in tooling
>>> >>> caused authors to co-opt existing unary exclamation operator, this
>>> >>> same gap is part of the reason the formula [2] and question mark [3]
>>> >>> operators have been used elsewhere in non standard contexts.
>>> >>>
>>> >>> If the language provided package authors with a native way to create
>>> >>> unary operators like it already does for the other operator types
>>> >>> these machinations would be unnecessary.
>>> >>>
>>> >>> [1]: https://github.com/hadley/rlang/blob/master/R/tidy-unquote.R#L17
>>> >>> [2]: https://cran.r-project.org/package=ensurer
>>> >>> [3]: https://cran.r-project.org/package=types
>>> >>>
>>> >>> On Thu, Mar 16, 2017 at 1:04 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>>> >>> wrote:
>>> >>> > Martin,
>>> >>> >
>>> >>> > Jim can speak directly to his motivations; I don't claim to be able
>>> >>> > to do
>>> >>> > so. That said, I suspect this is related to a conversation on
>>> >>> > twitter
>>> >>> about
>>> >>> > wanting an infix "unquote" operator in the context of the
>>> >>> > non-standard
>>> >>> > evaluation framework Hadley Wickham and Lionel Henry (and possibly
>>> >>> others)
>>> >>> > are working on.
>>> >>> >
>>> >>> > They're currently using !!! and !! for things related to this, but
>>> >>> > this
>>> >>> > effectively requires non-standard parsing, as ~!!x is interpreted as
>>> >>> > ~(`!!`(x)) rather than ~(!(!(x)) as the R parser understands it.
>>> >>> > Others
>>> >>> and
>>> >>> > I pointed out this was less than desirable, but if something like it
>>> >>> > was
>>> >>> > going to happen it would hopefully happen in the language
>>> >>> > specification,
>>> >>> > rather than in a package (and also hopefully not using !!
>>> >>> > specifically).
>>> >>> >
>>> >>> > Like you, I actually tend to prefer the functional form myself in
>>> >>> > most
>>> >>> > cases. There are functional forms that would work for the above case
>>> >>> (e.g.,
>>> >>> > something like the .() that DBI uses), but that's probably off topic
>>> >>> here,
>>> >>> > and not a decision I'm directly related to anyway.
>>> >>> >
>>> >>> > Best,
>>> >>> > ~G
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > On Thu, Mar 16, 2017 at 9:51 AM, Martin Maechler
>>> >>> > <maechler at stat.math.ethz.ch> wrote:
>>> >>> >>
>>> >>> >> >>>>> Jim Hester <james.f.hester at gmail.com>
>>> >>> >> >>>>>     on Thu, 16 Mar 2017 12:31:56 -0400 writes:
>>> >>> >>
>>> >>> >>     > Gabe,
>>> >>> >>     > The unary functions have the same precedence as normal
>>> >>> >> SPECIALS
>>> >>> >>     > (although the new unary forms take precedence over binary
>>> >>> SPECIALS).
>>> >>> >>     > So they are lower precedence than unary + and -. Yes, both of
>>> >>> >> your
>>> >>> >>     > examples are valid with this patch, here are the results and
>>> >>> quoted
>>> >>> >>     > forms to see the precedence.
>>> >>> >>
>>> >>> >>     > `%chr%` <- function(x) as.character(x)
>>> >>> >>
>>> >>> >>   [more efficient would be     `%chr%` <- as.character]
>>> >>> >>
>>> >>> >>     > `%identical%` <- function(x, y) identical(x, y)
>>> >>> >>     > quote("100" %identical% %chr% 100)
>>> >>> >>     > #>  "100" %identical% (`%chr%`(100))
>>> >>> >>
>>> >>> >>     > "100" %identical% %chr% 100
>>> >>> >>     > #> [1] TRUE
>>> >>> >>
>>> >>> >>     > `%num%` <- as.numeric
>>> >>> >>     > quote(1 + - %num% "5")
>>> >>> >>     > #> 1 + -(`%num%`("5"))
>>> >>> >>
>>> >>> >>     > 1 + - %num% "5"
>>> >>> >>     > #> [1] -4
>>> >>> >>
>>> >>> >>     > Jim
>>> >>> >>
>>> >>> >> I'm sorry to be a bit of a spoiler to "coolness", but
>>> >>> >> you may know that I like to  applaud Norm Matloff for his book
>>> >>> >> title "The Art of R Programming",
>>> >>> >> because for me good code should also be beautiful to some extent.
>>> >>> >>
>>> >>> >> I really very much prefer
>>> >>> >>
>>> >>> >>        f(x)
>>> >>> >> to    %f% x
>>> >>> >>
>>> >>> >> and hence I really really really cannot see why anybody would
>>> >>> >> prefer
>>> >>> >> the ugliness of
>>> >>> >>
>>> >>> >>            1 + - %num% "5"
>>> >>> >> to
>>> >>> >>            1 + -num("5")
>>> >>> >>
>>> >>> >> (after setting  num <- as.numeric )
>>> >>> >>
>>> >>> >> Martin
>>> >>> >>
>>> >>> >>
>>> >>> >>     > On Thu, Mar 16, 2017 at 12:01 PM, Gabriel Becker
>>> >>> >> <gmbecker at ucdavis.edu> wrote:
>>> >>> >>     >> Jim,
>>> >>> >>     >>
>>> >>> >>     >> This seems cool. Thanks for proposing it. To be concrete, he
>>> >>> >> user-defined
>>> >>> >>     >> unary operations would be of the same precedence (or just
>>> >>> slightly
>>> >>> >> below?)
>>> >>> >>     >> built-in unary ones? So
>>> >>> >>     >>
>>> >>> >>     >> "100" %identical% %chr% 100
>>> >>> >>     >>
>>> >>> >>     >> would work and return TRUE under your patch?
>>> >>> >>     >>
>>> >>> >>     >> And  with %num% <- as.numeric, then
>>> >>> >>     >>
>>> >>> >>     >> 1 + - %num% "5"
>>> >>> >>     >>
>>> >>> >>     >> would also be legal (though quite ugly imo) and work?
>>> >>> >>     >>
>>> >>> >>     >> Best,
>>> >>> >>     >> ~G
>>> >>> >>     >>
>>> >>> >>     >> On Thu, Mar 16, 2017 at 7:24 AM, Jim Hester
>>> >>> >> <james.f.hester at gmail.com>
>>> >>> >>     >> wrote:
>>> >>> >>     >>>
>>> >>> >>     >>> R has long supported user defined binary (infix) functions,
>>> >>> >> defined
>>> >>> >>     >>> with `%fun%`. A one line change [1] to R's grammar allows
>>> >>> >> users
>>> >>> to
>>> >>> >>     >>> define unary (prefix) functions in the same manner.
>>> >>> >>     >>>
>>> >>> >>     >>> `%chr%` <- function(x) as.character(x)
>>> >>> >>     >>> `%identical%` <- function(x, y) identical(x, y)
>>> >>> >>     >>>
>>> >>> >>     >>> %chr% 100
>>> >>> >>     >>> #> [1] "100"
>>> >>> >>     >>>
>>> >>> >>     >>> %chr% 100 %identical% "100"
>>> >>> >>     >>> #> [1] TRUE
>>> >>> >>     >>>
>>> >>> >>     >>> This seems a natural extension of the existing
>>> >>> >> functionality and
>>> >>> >>     >>> requires only a minor change to the grammar. If this change
>>> >>> seems
>>> >>> >>     >>> acceptable I am happy to provide a complete patch with
>>> >>> >> suitable
>>> >>> >> tests
>>> >>> >>     >>> and documentation.
>>> >>> >>     >>>
>>> >>> >>     >>> [1]:
>>> >>> >>     >>> Index: src/main/gram.y
>>> >>> >>     >>>
>>> >>> >> ===================================================================
>>> >>> >>     >>> --- src/main/gram.y     (revision 72358)
>>> >>> >>     >>> +++ src/main/gram.y     (working copy)
>>> >>> >>     >>> @@ -357,6 +357,7 @@
>>> >>> >>     >>> |       '+' expr %prec UMINUS           { $$ =
>>> >>> >> xxunary($1,$2);
>>> >>> >>     >>> setId( $$, @$); }
>>> >>> >>     >>> |       '!' expr %prec UNOT             { $$ =
>>> >>> >> xxunary($1,$2);
>>> >>> >>     >>> setId( $$, @$); }
>>> >>> >>     >>> |       '~' expr %prec TILDE            { $$ =
>>> >>> >> xxunary($1,$2);
>>> >>> >>     >>> setId( $$, @$); }
>>> >>> >>     >>> +       |       SPECIAL expr                    { $$ =
>>> >>> >> xxunary($1,$2);
>>> >>> >>     >>> setId( $$, @$); }
>>> >>> >>     >>> |       '?' expr                        { $$ =
>>> >>> >> xxunary($1,$2);
>>> >>> >>     >>> setId( $$, @$); }
>>> >>> >>     >>>
>>> >>> >>     >>> |       expr ':'  expr                  { $$ =
>>> >>> >>     >>> xxbinary($2,$1,$3);      setId( $$, @$); }
>>> >>> >>     >>>
>>> >>> >>     >>> ______________________________________________
>>> >>> >>     >>> R-devel at r-project.org mailing list
>>> >>> >>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>> >>     >>
>>> >>> >>     >>
>>> >>> >>     >>
>>> >>> >>     >>
>>> >>> >>     >> --
>>> >>> >>     >> Gabriel Becker, PhD
>>> >>> >>     >> Associate Scientist (Bioinformatics)
>>> >>> >>     >> Genentech Research
>>> >>> >>
>>> >>> >>     > ______________________________________________
>>> >>> >>     > R-devel at r-project.org mailing list
>>> >>> >>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > --
>>> >>> > Gabriel Becker, PhD
>>> >>> > Associate Scientist (Bioinformatics)
>>> >>> > Genentech Research
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-devel at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>>
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-devel at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>> --
>> Gabriel Becker, PhD
>> Associate Scientist (Bioinformatics)
>> Genentech Research


From edd at debian.org  Sat Mar 18 01:20:06 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 17 Mar 2017 19:20:06 -0500
Subject: [Rd] Support for user defined unary functions
In-Reply-To: <CAD6tx961FZG0LDROP6NBhep7-bXNLYJRjPUz91mk+KZuo2K+pw@mail.gmail.com>
References: <CAD6tx95VZKQ00ESU9aqq_CBy7BNtX2_ANeaPryw+3W1RVL4vww@mail.gmail.com>
	<CADwqtCMSrO-tZktHESg0LcVqP8qAKVbAnktAZGATKug2WYb-dQ@mail.gmail.com>
	<CAD6tx954cHTruRT8W0kBFob9vVZem-Cjx3cTZL6nWoz8P4dv+A@mail.gmail.com>
	<22730.49816.583399.930840@stat.math.ethz.ch>
	<CADwqtCPFv6c6LccUSvhNL6XsTw4RY7Uys_9bivnpX3FAAtgP6g@mail.gmail.com>
	<CAD6tx96FQW5e4mQRGuvM7V6BkkvVkr21Y0PMmySmc_2awKXBSw@mail.gmail.com>
	<CAOQ5NychWuMiHAxHmDLW28MsWgX44qPcOJ0UxCAqfAj43oxJXw@mail.gmail.com>
	<CAF8bMcbTq9YZVzCbjttvni8izD-HHFcoMNn9F=KOd00OcPh2Mw@mail.gmail.com>
	<CAD6tx95j0qVThovPcCfxZS6iyj5xHfuUH7_NQymHbDYbCNTW+Q@mail.gmail.com>
	<CADwqtCNV57PT-vphqpV-OCcABmtK-PxZCZtk1i=sV27FJqHYkw@mail.gmail.com>
	<CAD6tx961FZG0LDROP6NBhep7-bXNLYJRjPUz91mk+KZuo2K+pw@mail.gmail.com>
Message-ID: <22732.32054.546698.878223@max.eddelbuettel.com>


On 17 March 2017 at 18:02, Jim Hester wrote:
| The user defined pipe operator (%>%), now used by > 300 packages, is
| an example that giving package authors the power to experiment can
| produce beneficial ideas for the community.

Well, you can read that two ways.

To me it seems over 9700 packages ignore the pipe operator.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jeroenooms at gmail.com  Sat Mar 18 14:21:14 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sat, 18 Mar 2017 14:21:14 +0100
Subject: [Rd] Experimental CXX_STD problem in R 3.4
Message-ID: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>

R 3.4 has 'experimental' support for setting CXX_STD to CXX98 / CXX11
/ CXX14 / CXX17.

However on most platforms, the R configuration seems to leave the
CXX1Y and CXX1Z fields blank in "${R_HOME}/etc/Makeconf" (rather than
falling back on default CXX). Therefore specifying e.g CXX_STD= CXX14
will fail build with cryptic errors (due to compiling with CXX="")

I don't think this is intended? Some examples from r-devel on Windows:

CXX11: https://win-builder.r-project.org/R8gg703OQSq5/
CXX98: https://win-builder.r-project.org/mpVfXxk79FaN/
CXX14: https://win-builder.r-project.org/L3BSMgAk4cQ7/
CXX17: https://win-builder.r-project.org/3ETZXrgkg77I/

Similar problems appear on Linux. I think the problem is that Makeconf
contains e.g:

CXX1Z =
CXX1ZFLAGS =
CXX1ZPICFLAGS =
CXX1ZSTD =

When CXX_STD contains any other unsupported value (e.g. CXX24) R
simply falls back on the default CXX configuration. The same should
probably happen for e.g. CXX17 when CXX1Z is unset in Makeconf?


From edd at debian.org  Sat Mar 18 15:55:56 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 18 Mar 2017 09:55:56 -0500
Subject: [Rd] Experimental CXX_STD problem in R 3.4
In-Reply-To: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>
References: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>
Message-ID: <22733.19068.582932.665707@max.eddelbuettel.com>


On 18 March 2017 at 14:21, Jeroen Ooms wrote:
| R 3.4 has 'experimental' support for setting CXX_STD to CXX98 / CXX11
| / CXX14 / CXX17.

R 3.1.0 introduced CXX11 support.  R 3.4.0 will have CXX14 support.  So I
would only refer to the CXX17 part as experimental.

| However on most platforms, the R configuration seems to leave the
| CXX1Y and CXX1Z fields blank in "${R_HOME}/etc/Makeconf" (rather than
| falling back on default CXX). Therefore specifying e.g CXX_STD= CXX14
| will fail build with cryptic errors (due to compiling with CXX="")

That depends of course on the compiler found on the system. On my box (with
g++ being g++-6.2 which _defaults_ to C++14) all is well up to CXX1Y.

But I also have CXX1Z empty. 
 
| I don't think this is intended? Some examples from r-devel on Windows:
| 
| CXX11: https://win-builder.r-project.org/R8gg703OQSq5/
| CXX98: https://win-builder.r-project.org/mpVfXxk79FaN/
| CXX14: https://win-builder.r-project.org/L3BSMgAk4cQ7/
| CXX17: https://win-builder.r-project.org/3ETZXrgkg77I/

You can't expect CXX14 and CXX17 to work with the only available compiler
there, g++-4.9.3.
 
| Similar problems appear on Linux. I think the problem is that Makeconf
| contains e.g:
| 
| CXX1Z =
| CXX1ZFLAGS =
| CXX1ZPICFLAGS =
| CXX1ZSTD =
| 
| When CXX_STD contains any other unsupported value (e.g. CXX24) R
| simply falls back on the default CXX configuration. The same should
| probably happen for e.g. CXX17 when CXX1Z is unset in Makeconf?

Probably.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jmount at win-vector.com  Sat Mar 18 19:47:06 2017
From: jmount at win-vector.com (John Mount)
Date: Sat, 18 Mar 2017 11:47:06 -0700
Subject: [Rd] Red: RFC: (in-principle) native unquoting for standard
 evaluation
Message-ID: <536EF950-298A-4698-8DF5-E9288ECED877@win-vector.com>

Obviously we have to be sensitive about language and parser changes.  However, I think Jonathan Carroll has identified a feature that is well understood in the Lisp world (quoting and unquoting) that is missing from the R language.  Some symbol that indirects to a value (only once!, we don?t want this chaining; and there are issues of quoting it out) in eval would be very valuable.  Obviously it is most useful where non-standard evaluation is emphasized (plotting, formulas, and dplyr being the examples that I can immediately think of).

---------------
John Mount
http://www.win-vector.com/ <http://www.win-vector.com/> 
Our book: Practical Data Science with R https://www.manning.com/books/practical-data-science-with-r <https://www.manning.com/books/practical-data-science-with-r> 




	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Sun Mar 19 03:32:05 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 19 Mar 2017 15:32:05 +1300
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
Message-ID: <CABdHhvEHtdjRBCHkUhPWjP8gN4jvKqX2PnXJaOgn6FPBS_pRiQ@mail.gmail.com>

What would you propose for the unquote-splice operator?

Hadley

On Friday, March 17, 2017, Jonathan Carroll <jono at jcarroll.com.au> wrote:

> (please be gentle, it's my first time)
>
> I am interested in discussions (possibly reiterating past threads --
> searching didn't turn up much) on the possibility of supporting standard
> evaluation unquoting at the language level. This has been brought up in a
> recent similar thread here [1] and on Twitter [2] where I proposed the
> following desired (in-principle) syntax
>
>     f <- function(col1, col2, new_col_name) {
>         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>     }
>
> or closer to home
>
>     x <- 1:10; y <- "x"
>     data.frame(z = @y)
>
> where @ would be defined as a unary prefix operator which substitutes the
> quoted variable name in-place, to allow more flexibility of NSE functions
> within a programming context. This mechanism exists within MySQL [3] (and
> likely other languages) and could potentially be extremely useful. Several
> alternatives have been incorporated into packages (most recently work
> on tidyeval) none of which appear to fully match the simplicity of the
> above, and some of which cut a forceful path through the syntax tree.
>
> The exact syntax isn't my concern at the moment (@ vs unquote() or other,
> though the first requires user-supplied native prefix support within the
> language, as per [1]) and neither is the exact way in which this would be
> achieved (well above my pay grade). The practicality of @ being on the LHS
> of `=` is also of a lesser concern (likely greater complexity) than the
> RHS.
>
> I hear there exists (justified) reluctance to add new syntax to the
> language, but I think this has sufficient merit (and a growing number of
> workarounds) to warrant continued discussion.
>
> With kindest regards,
>
> - Jonathan.
>
> [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
> [2] https://twitter.com/carroll_jono/status/842142292253196290
> [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
http://hadley.nz

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Sun Mar 19 03:39:26 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 19 Mar 2017 15:39:26 +1300
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
Message-ID: <CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>

Would this return a quosure? (i.e. a single sided formula that captures
both expression and environment). That's the data structure we've adopted
in tidyeval as it already has some built in support.

Hadley

On Friday, March 17, 2017, Michael Lawrence <lawrence.michael at gene.com>
wrote:

> Interesting idea. Lazy and non-standard evaluation is going to happen; the
> language needs a way to contain it.
>
> I'll extend the proposal so that prefixing a formal argument with @ in
> function() marks the argument as auto-quoting, so it arrives as a language
> object without use of substitute(). Kind of like how '*' in C declares a
> pointer and dereferences one.
>
> subset <- function(x, @subset, ...) { }
>
> This should make it easier to implement such functions, simplify
> compilation, and allow detection of potential quoting errors through static
> analysis.
>
> Michael
>
> On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au
> <javascript:;>>
> wrote:
>
> > (please be gentle, it's my first time)
> >
> > I am interested in discussions (possibly reiterating past threads --
> > searching didn't turn up much) on the possibility of supporting standard
> > evaluation unquoting at the language level. This has been brought up in a
> > recent similar thread here [1] and on Twitter [2] where I proposed the
> > following desired (in-principle) syntax
> >
> >     f <- function(col1, col2, new_col_name) {
> >         mtcars %>% mutate(@new_col_name = @col1 + @col2)
> >     }
> >
> > or closer to home
> >
> >     x <- 1:10; y <- "x"
> >     data.frame(z = @y)
> >
> > where @ would be defined as a unary prefix operator which substitutes the
> > quoted variable name in-place, to allow more flexibility of NSE functions
> > within a programming context. This mechanism exists within MySQL [3] (and
> > likely other languages) and could potentially be extremely useful.
> Several
> > alternatives have been incorporated into packages (most recently work
> > on tidyeval) none of which appear to fully match the simplicity of the
> > above, and some of which cut a forceful path through the syntax tree.
> >
> > The exact syntax isn't my concern at the moment (@ vs unquote() or other,
> > though the first requires user-supplied native prefix support within the
> > language, as per [1]) and neither is the exact way in which this would be
> > achieved (well above my pay grade). The practicality of @ being on the
> LHS
> > of `=` is also of a lesser concern (likely greater complexity) than the
> > RHS.
> >
> > I hear there exists (justified) reluctance to add new syntax to the
> > language, but I think this has sufficient merit (and a growing number of
> > workarounds) to warrant continued discussion.
> >
> > With kindest regards,
> >
> > - Jonathan.
> >
> > [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
> > [2] https://twitter.com/carroll_jono/status/842142292253196290
> > [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org <javascript:;> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
http://hadley.nz

	[[alternative HTML version deleted]]


From jono at jcarroll.com.au  Sun Mar 19 04:14:22 2017
From: jono at jcarroll.com.au (Jonathan Carroll)
Date: Sun, 19 Mar 2017 13:44:22 +1030
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
	<CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>
Message-ID: <CAAjDRiiB1Ad8WrWBXZE5pG6GVbbk_MuTfTNkMY6hk=WvdQ7iog@mail.gmail.com>

Firstly, credit where due: the lazyeval NSE vignette [1] covers so many of
the angles that this proposal needs to address and is extremely well
written (even if it has been superseded). The @ prefix I'm proposing is a
drop-in replacement for `uq()` (as used in that vignette) but for which the
`f_eval()` and `~` steps would not be required by the author/user.

This is proposed as an admittedly naive suggestion which fails to account
for the subtleties raised in [1] such as unquoting of multiple arguments
and scope selection. I am hoping that the discussion can cover how best to
address those matters.

The significant hurdles (apart from implementation which I cannot speak to)
that are dealt with in lazyeval (and presumably tidyeval) seem to be:

- a prefix can be attached to only a single object, so the extra_args
example from [1] would not be possible. I'm not certain why the unquoting
of the variable would not still be possible with the form

    variable = "x"
    mean(@variable, na.rm = TRUE, trim = 0.9)

since I'm proposing that the call need not be a formula (I may be way off
on this interpretation).

- I am proposing that the new syntax be able to achieve the example

    f <- function(col1, col2, new_col_name) {
        mtcars %>% mutate(@new_col_name = @col1 + @col2)
    }

but this is ambiguous if there is, say, an object "mpg" within that
function scope. [1] handles this with .env and .data pronouns but this
doesn't seem possible with just a prefix. One solution may be to have @@
and @ representing these two options.

I appreciate the significant work that has gone into the tidyverse packages
which use NSE and my intention is not to downplay any of that. I would just
like to be able to use the language more efficiently, so native access to
the unquoting seems like a step forward.

Kindest regards,

- Jonathan.

[1] https://cran.r-project.org/web/packages/lazyeval/vignettes/lazyeval.html

On Sun, Mar 19, 2017 at 1:09 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> Would this return a quosure? (i.e. a single sided formula that captures
> both expression and environment). That's the data structure we've adopted
> in tidyeval as it already has some built in support.
>
> Hadley
>
> On Friday, March 17, 2017, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>
>> Interesting idea. Lazy and non-standard evaluation is going to happen; the
>> language needs a way to contain it.
>>
>> I'll extend the proposal so that prefixing a formal argument with @ in
>> function() marks the argument as auto-quoting, so it arrives as a language
>> object without use of substitute(). Kind of like how '*' in C declares a
>> pointer and dereferences one.
>>
>> subset <- function(x, @subset, ...) { }
>>
>> This should make it easier to implement such functions, simplify
>> compilation, and allow detection of potential quoting errors through
>> static
>> analysis.
>>
>> Michael
>>
>> On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
>> wrote:
>>
>> > (please be gentle, it's my first time)
>> >
>> > I am interested in discussions (possibly reiterating past threads --
>> > searching didn't turn up much) on the possibility of supporting standard
>> > evaluation unquoting at the language level. This has been brought up in
>> a
>> > recent similar thread here [1] and on Twitter [2] where I proposed the
>> > following desired (in-principle) syntax
>> >
>> >     f <- function(col1, col2, new_col_name) {
>> >         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>> >     }
>> >
>> > or closer to home
>> >
>> >     x <- 1:10; y <- "x"
>> >     data.frame(z = @y)
>> >
>> > where @ would be defined as a unary prefix operator which substitutes
>> the
>> > quoted variable name in-place, to allow more flexibility of NSE
>> functions
>> > within a programming context. This mechanism exists within MySQL [3]
>> (and
>> > likely other languages) and could potentially be extremely useful.
>> Several
>> > alternatives have been incorporated into packages (most recently work
>> > on tidyeval) none of which appear to fully match the simplicity of the
>> > above, and some of which cut a forceful path through the syntax tree.
>> >
>> > The exact syntax isn't my concern at the moment (@ vs unquote() or
>> other,
>> > though the first requires user-supplied native prefix support within the
>> > language, as per [1]) and neither is the exact way in which this would
>> be
>> > achieved (well above my pay grade). The practicality of @ being on the
>> LHS
>> > of `=` is also of a lesser concern (likely greater complexity) than the
>> > RHS.
>> >
>> > I hear there exists (justified) reluctance to add new syntax to the
>> > language, but I think this has sufficient merit (and a growing number of
>> > workarounds) to warrant continued discussion.
>> >
>> > With kindest regards,
>> >
>> > - Jonathan.
>> >
>> > [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
>> > [2] https://twitter.com/carroll_jono/status/842142292253196290
>> > [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> http://hadley.nz
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Sun Mar 19 06:51:09 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 18 Mar 2017 22:51:09 -0700
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
	<CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>
Message-ID: <CAOQ5NyeF8fDYGwES0sy5eQfgFriK4Hos7vqX9R2YxkLgTPrhmg@mail.gmail.com>

Yes, it would bind the language object to the environment, like an
R-level promise (but "promise" of course refers specifically to just
_lazy_ evaluation).

For the uqs() thing, expanding calls like that is somewhat orthogonal
to NSE. It would be nice in general to be able to write something like
mean(x, extra_args...) without resorting to do.call(mean, c(list(x),
extra_args)). If we had that then uqs() would just be the combination
of unquote and expansion, i.e., mean(x, @extra_args...). The "..."
postfix would not work since it's still a valid symbol name, but we
could come up with something.

Michael


On Sat, Mar 18, 2017 at 7:39 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> Would this return a quosure? (i.e. a single sided formula that captures both
> expression and environment). That's the data structure we've adopted in
> tidyeval as it already has some built in support.
>
> Hadley
>
>
> On Friday, March 17, 2017, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>>
>> Interesting idea. Lazy and non-standard evaluation is going to happen; the
>> language needs a way to contain it.
>>
>> I'll extend the proposal so that prefixing a formal argument with @ in
>> function() marks the argument as auto-quoting, so it arrives as a language
>> object without use of substitute(). Kind of like how '*' in C declares a
>> pointer and dereferences one.
>>
>> subset <- function(x, @subset, ...) { }
>>
>> This should make it easier to implement such functions, simplify
>> compilation, and allow detection of potential quoting errors through
>> static
>> analysis.
>>
>> Michael
>>
>> On Thu, Mar 16, 2017 at 5:03 PM, Jonathan Carroll <jono at jcarroll.com.au>
>> wrote:
>>
>> > (please be gentle, it's my first time)
>> >
>> > I am interested in discussions (possibly reiterating past threads --
>> > searching didn't turn up much) on the possibility of supporting standard
>> > evaluation unquoting at the language level. This has been brought up in
>> > a
>> > recent similar thread here [1] and on Twitter [2] where I proposed the
>> > following desired (in-principle) syntax
>> >
>> >     f <- function(col1, col2, new_col_name) {
>> >         mtcars %>% mutate(@new_col_name = @col1 + @col2)
>> >     }
>> >
>> > or closer to home
>> >
>> >     x <- 1:10; y <- "x"
>> >     data.frame(z = @y)
>> >
>> > where @ would be defined as a unary prefix operator which substitutes
>> > the
>> > quoted variable name in-place, to allow more flexibility of NSE
>> > functions
>> > within a programming context. This mechanism exists within MySQL [3]
>> > (and
>> > likely other languages) and could potentially be extremely useful.
>> > Several
>> > alternatives have been incorporated into packages (most recently work
>> > on tidyeval) none of which appear to fully match the simplicity of the
>> > above, and some of which cut a forceful path through the syntax tree.
>> >
>> > The exact syntax isn't my concern at the moment (@ vs unquote() or
>> > other,
>> > though the first requires user-supplied native prefix support within the
>> > language, as per [1]) and neither is the exact way in which this would
>> > be
>> > achieved (well above my pay grade). The practicality of @ being on the
>> > LHS
>> > of `=` is also of a lesser concern (likely greater complexity) than the
>> > RHS.
>> >
>> > I hear there exists (justified) reluctance to add new syntax to the
>> > language, but I think this has sufficient merit (and a growing number of
>> > workarounds) to warrant continued discussion.
>> >
>> > With kindest regards,
>> >
>> > - Jonathan.
>> >
>> > [1] https://stat.ethz.ch/pipermail/r-devel/2017-March/073894.html
>> > [2] https://twitter.com/carroll_jono/status/842142292253196290
>> > [3] https://dev.mysql.com/doc/refman/5.7/en/user-variables.html
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> http://hadley.nz


From sahil.kang at asilaycomputing.com  Sun Mar 19 07:31:57 2017
From: sahil.kang at asilaycomputing.com (Sahil Kang)
Date: Sat, 18 Mar 2017 23:31:57 -0700
Subject: [Rd] [PATCH] Improve utf8clen and remove utf8_table4
Message-ID: <b8bbaed3-1fc9-d76f-7ed0-707aa769e5e0@asilaycomputing.com>

Given a char `c' which should be the start byte of a utf8 character,
the utf8clen function returns the byte length of the utf8 character.

Before this patch, the utf8clen function would return either:
     * 1 if `c' was an ascii character or a utf8 continuation byte
     * An int in the range [2, 6] indicating the byte length of the utf8 
character

With this patch, the utf8clen function will now return either:
     * -1 if `c' is not a valid utf8 start byte
     * The byte length of the utf8 character (the number of leading 1's, 
really)

I believe returning -1 for continuation bytes makes utf8clen less error 
prone.
The utf8_table4 array is no longer needed and has been removed.

Sahil
-------------- next part --------------
A non-text attachment was scrubbed...
Name: patch.diff
Type: text/x-patch
Size: 1709 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170318/e8e82a14/attachment.bin>

From Albrecht.Gebhardt at aau.at  Sun Mar 19 10:14:56 2017
From: Albrecht.Gebhardt at aau.at (Gebhardt, Albrecht)
Date: Sun, 19 Mar 2017 09:14:56 +0000
Subject: [Rd] outer not applying a constant function
Message-ID: <D4F40A9E.16FE8%albrecht.gebhardt@aau.at>

Hi,

the function outer can not apply a constant function as in the last line of the following example:

> xg <- 1:4
> yg <- 1:4
> fxyg <- outer(xg, yg, function(x,y) x*y)
> fconstg <- outer(xg, yg, function(x,y) 1.0)
Error in outer(xg, yg, function(x, y) 1) :
  dims [product 16] do not match the length of object [1]

Of course there are simpler ways to construct a constant matrix, that is not my point.

It happens for me in the context of generating matrices of partial derivatives, and if on of these partial derivatives happens to be constant it fails.

So e.g this works:

library(Deriv)
f <- function(x,y) (x-1.5)*(y-1)*(x-1.8)+(y-1.9)^2*(x-1.1)^3
fx <- Deriv(f,"x")
fy <- Deriv(f,"y")
fxy <- Deriv(Deriv(f,"y"),"x")
fxx <- Deriv(Deriv(f,"x"),"x")
fyy <- Deriv(Deriv(f,"y"),"y")

fg   <- outer(xg,yg,f)
fxg  <- outer(xg,yg,fx)
fyg  <- outer(xg,yg,fy)
fxyg <- outer(xg,yg,fxy)
fxxg <- outer(xg,yg,fxx)
fyyg <- outer(xg,yg,fyy)

And with

f <- function(x,y) x+y

it stops working. Of course I can manually fix this for that special case, but thats not my point. I simply thought "outer" should be able to handle constant functions.

Best regards

Albrecht




	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Mar 19 13:38:18 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 Mar 2017 08:38:18 -0400
Subject: [Rd] [PATCH] Improve utf8clen and remove utf8_table4
In-Reply-To: <b8bbaed3-1fc9-d76f-7ed0-707aa769e5e0@asilaycomputing.com>
References: <b8bbaed3-1fc9-d76f-7ed0-707aa769e5e0@asilaycomputing.com>
Message-ID: <9d445306-d31b-f568-6590-f914ffc9c9c0@gmail.com>

On 19/03/2017 2:31 AM, Sahil Kang wrote:
> Given a char `c' which should be the start byte of a utf8 character,
> the utf8clen function returns the byte length of the utf8 character.
>
> Before this patch, the utf8clen function would return either:
>      * 1 if `c' was an ascii character or a utf8 continuation byte
>      * An int in the range [2, 6] indicating the byte length of the utf8
> character
>
> With this patch, the utf8clen function will now return either:
>      * -1 if `c' is not a valid utf8 start byte
>      * The byte length of the utf8 character (the number of leading 1's,
> really)
>
> I believe returning -1 for continuation bytes makes utf8clen less error
> prone.
> The utf8_table4 array is no longer needed and has been removed.

utf8clen is used internally by R in more than a dozen places, and is 
likely used in packages as well.  Have you checked that this change in 
semantics won't break any of those uses?

Duncan Murdoch


From radford at cs.toronto.edu  Sun Mar 19 19:36:10 2017
From: radford at cs.toronto.edu (Radford Neal)
Date: Sun, 19 Mar 2017 14:36:10 -0400
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <mailman.9.1489921202.31343.r-devel@r-project.org>
References: <mailman.9.1489921202.31343.r-devel@r-project.org>
Message-ID: <20170319183610.GA26048@mail.cs.toronto.edu>

Michael Lawrence (as last in long series of posters)...

> Yes, it would bind the language object to the environment, like an
> R-level promise (but "promise" of course refers specifically to just
> _lazy_ evaluation).
> 
> For the uqs() thing, expanding calls like that is somewhat orthogonal
> to NSE. It would be nice in general to be able to write something like
> mean(x, extra_args...) without resorting to do.call(mean, c(list(x),
> extra_args)). If we had that then uqs() would just be the combination
> of unquote and expansion, i.e., mean(x, @extra_args...). The "..."
> postfix would not work since it's still a valid symbol name, but we
> could come up with something.


I've been trying to follow this proposal, though without tracking down
all the tweets, etc. that are referenced.  I suspect I'm not the only
reader who isn't clear exactly what is being proposed.  I think a
detailed, self-contained proposal would be useful.

One thing I'm not clear on is whether the proposal would add anything
semantically beyond what the present "eval" and "substitute" functions
can do fairly easily.  If not, is there really any need for a slightly
more concise syntax?  Is it expected that the new syntax would be used
lots by ordinary users, or is it only for the convenience of people
who are writing fairly esoteric functions (which might then be used by
many)?  If the later, it seems undesirable to me.

There is an opportunity cost to grabbing the presently-unused unary @
operator for this, in that it might otherwise be used for some other
extension.  For example, see the last five slides in my talk at
http://www.cs.utoronto.ca/~radford/ftp/R-lang-ext.pdf for a different
proposal for a new unary @ operator.  I'm not necessarily advocating
that particular use (my ideas in this respect are still undergoing
revisions), but the overall point is that there may well be several
good uses of a unary @ operator (and there aren't many other good
characters to use for a unary operator besides @).  It is unclear to
me that the current proposal is the highest-value use of @.

   Radford Neal


From h.wickham at gmail.com  Sun Mar 19 20:00:21 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Mar 2017 08:00:21 +1300
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <20170319183610.GA26048@mail.cs.toronto.edu>
References: <mailman.9.1489921202.31343.r-devel@r-project.org>
	<20170319183610.GA26048@mail.cs.toronto.edu>
Message-ID: <CABdHhvHttoH7yNTG7bj=nKdfRd1c2yukDWaovqid+PfT6+yHMA@mail.gmail.com>

On Mon, Mar 20, 2017 at 7:36 AM, Radford Neal <radford at cs.toronto.edu> wrote:
> Michael Lawrence (as last in long series of posters)...
>
>> Yes, it would bind the language object to the environment, like an
>> R-level promise (but "promise" of course refers specifically to just
>> _lazy_ evaluation).
>>
>> For the uqs() thing, expanding calls like that is somewhat orthogonal
>> to NSE. It would be nice in general to be able to write something like
>> mean(x, extra_args...) without resorting to do.call(mean, c(list(x),
>> extra_args)). If we had that then uqs() would just be the combination
>> of unquote and expansion, i.e., mean(x, @extra_args...). The "..."
>> postfix would not work since it's still a valid symbol name, but we
>> could come up with something.
>
>
> I've been trying to follow this proposal, though without tracking down
> all the tweets, etc. that are referenced.  I suspect I'm not the only
> reader who isn't clear exactly what is being proposed.  I think a
> detailed, self-contained proposal would be useful.

We have a working implementation (which I'm calling tidyeval) in
https://github.com/hadley/rlang, but we have yet to write it up. We'll
spend some time documenting since it seems to be of broader interest.

> One thing I'm not clear on is whether the proposal would add anything
> semantically beyond what the present "eval" and "substitute" functions
> can do fairly easily.  If not, is there really any need for a slightly
> more concise syntax?  Is it expected that the new syntax would be used
> lots by ordinary users, or is it only for the convenience of people
> who are writing fairly esoteric functions (which might then be used by
> many)?  If the later, it seems undesirable to me.

I accidentally responded off list to Michael, but I think there are
three legs to "tidy" style of NSE:

1) capturing a quosure from a promise

2) quasiquotation (unquote + unquote-splice)

3) pronouns, so you can be explicit about where a variable should be
looked up (.data vs .end)

These are largely orthogonal, but I don't think you can solve the most
important NSE problems without all three. Just having 1) in base R
would be a big step forward.

> There is an opportunity cost to grabbing the presently-unused unary @
> operator for this, in that it might otherwise be used for some other
> extension.  For example, see the last five slides in my talk at
> http://www.cs.utoronto.ca/~radford/ftp/R-lang-ext.pdf for a different
> proposal for a new unary @ operator.  I'm not necessarily advocating
> that particular use (my ideas in this respect are still undergoing
> revisions), but the overall point is that there may well be several
> good uses of a unary @ operator (and there aren't many other good
> characters to use for a unary operator besides @).  It is unclear to
> me that the current proposal is the highest-value use of @.

A further extension would be to allow binary @ in function argument
names; then the LHS could be an arbitrary string used as an extension
mechanism.

Hadley

-- 
http://hadley.nz


From plummerm at iarc.fr  Sun Mar 19 21:09:07 2017
From: plummerm at iarc.fr (Martyn Plummer)
Date: Sun, 19 Mar 2017 20:09:07 +0000
Subject: [Rd] Experimental CXX_STD problem in R 3.4
In-Reply-To: <22733.19068.582932.665707@max.eddelbuettel.com>
References: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>,
	<22733.19068.582932.665707@max.eddelbuettel.com>
Message-ID: <1489954147228.25309@iarc.fr>

C++ support across different platforms is now very heterogeneous. The standard is evolving rapidly but there are also platforms in current use that do not support the recent iterations of the standard. Our goal for R 3.4.0 is to give as much flexibility as possible. The default compiler is whatever you get "out of the box" without setting the "-std=" flag.  This means different things on different platforms. If you need a specific standard there are various ways to request one, as described in the R-exts manual.

On unix-alikes, the capabilities of the compiler are tested at configure time and appropriate flags chosen to support each standard. On Windows, the capabilities are hard-coded and correspond to the current version of Rtools, i.e. only C++98 and C++11 are currently supported. 

C++17 support is experimental and was added very recently. Clang 4.0.0, which was released last week, passes the configuration tests for C++17, and so does gcc 7.0.1, the pre-release version of gcc 7.1.0 which is due out later this year. The tests for C++17 features are, however, incomplete.

I have just added some code to ensure that the compilation fails with an informative error message if a specific C++ standard is requested but the corresponding compiler has not been defined. Please test this.

Martyn


________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Dirk Eddelbuettel <edd at debian.org>
Sent: 18 March 2017 15:55
To: Jeroen Ooms
Cc: r-devel
Subject: Re: [Rd] Experimental CXX_STD problem in R 3.4

On 18 March 2017 at 14:21, Jeroen Ooms wrote:
| R 3.4 has 'experimental' support for setting CXX_STD to CXX98 / CXX11
| / CXX14 / CXX17.

R 3.1.0 introduced CXX11 support.  R 3.4.0 will have CXX14 support.  So I
would only refer to the CXX17 part as experimental.

| However on most platforms, the R configuration seems to leave the
| CXX1Y and CXX1Z fields blank in "${R_HOME}/etc/Makeconf" (rather than
| falling back on default CXX). Therefore specifying e.g CXX_STD= CXX14
| will fail build with cryptic errors (due to compiling with CXX="")

That depends of course on the compiler found on the system. On my box (with
g++ being g++-6.2 which _defaults_ to C++14) all is well up to CXX1Y.

But I also have CXX1Z empty.

| I don't think this is intended? Some examples from r-devel on Windows:
|
| CXX11: https://win-builder.r-project.org/R8gg703OQSq5/
| CXX98: https://win-builder.r-project.org/mpVfXxk79FaN/
| CXX14: https://win-builder.r-project.org/L3BSMgAk4cQ7/
| CXX17: https://win-builder.r-project.org/3ETZXrgkg77I/

You can't expect CXX14 and CXX17 to work with the only available compiler
there, g++-4.9.3.

| Similar problems appear on Linux. I think the problem is that Makeconf
| contains e.g:
|
| CXX1Z =
| CXX1ZFLAGS =
| CXX1ZPICFLAGS =
| CXX1ZSTD =
|
| When CXX_STD contains any other unsupported value (e.g. CXX24) R
| simply falls back on the default CXX configuration. The same should
| probably happen for e.g. CXX17 when CXX1Z is unset in Makeconf?

Probably.

Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From sahil.kang at asilaycomputing.com  Sun Mar 19 21:24:51 2017
From: sahil.kang at asilaycomputing.com (Sahil Kang)
Date: Sun, 19 Mar 2017 13:24:51 -0700
Subject: [Rd] [PATCH] Improve utf8clen and remove utf8_table4
In-Reply-To: <9d445306-d31b-f568-6590-f914ffc9c9c0@gmail.com>
References: <b8bbaed3-1fc9-d76f-7ed0-707aa769e5e0@asilaycomputing.com>
	<9d445306-d31b-f568-6590-f914ffc9c9c0@gmail.com>
Message-ID: <fac440cb-dcdc-eca6-fbf6-670537117ac1@asilaycomputing.com>

Some of the code that uses utf8clen checks the validity of the utf8 
string before making the call.
However, there were some hairy areas where I felt that the new semantics 
may cause issues (if not now, then in future changes).

I've attached two patches:
     * new_semantics.diff keeps the new semantics and updates those 
hairy areas above.
     * old_semantics.diff maintains the old semantics (return 1 even for 
continuation bytes).

I don't think the new semantics will cause issues, especially with the 
updates, but we can err on the side of caution and keep the old 
semantics. I feel that the new semantics provide a clearer interface 
though (the function expects a start byte and should return an error if 
a start byte is not supplied).
In either case, the utf8_table4 array has been removed.

Sahil

On 03/19/2017 05:38 AM, Duncan Murdoch wrote:
> On 19/03/2017 2:31 AM, Sahil Kang wrote:
>> Given a char `c' which should be the start byte of a utf8 character,
>> the utf8clen function returns the byte length of the utf8 character.
>>
>> Before this patch, the utf8clen function would return either:
>>      * 1 if `c' was an ascii character or a utf8 continuation byte
>>      * An int in the range [2, 6] indicating the byte length of the utf8
>> character
>>
>> With this patch, the utf8clen function will now return either:
>>      * -1 if `c' is not a valid utf8 start byte
>>      * The byte length of the utf8 character (the number of leading 1's,
>> really)
>>
>> I believe returning -1 for continuation bytes makes utf8clen less error
>> prone.
>> The utf8_table4 array is no longer needed and has been removed.
>
> utf8clen is used internally by R in more than a dozen places, and is 
> likely used in packages as well.  Have you checked that this change in 
> semantics won't break any of those uses?
>
> Duncan Murdoch
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: old_semantics.diff
Type: text/x-patch
Size: 1707 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170319/477b61e9/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: new_semantics.diff
Type: text/x-patch
Size: 6332 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170319/477b61e9/attachment-0001.bin>

From cgenolin at u-paris10.fr  Sun Mar 19 23:50:42 2017
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sun, 19 Mar 2017 23:50:42 +0100
Subject: [Rd] Error "Warning in read_symbols_from_dll(so,
 rarch): this requires 'objdump.exe' to be on the PATH
Message-ID: <751f3173-6a97-77ca-40dd-633185e216ba@u-paris10.fr>

Hi all,

I try to compile my package kml and I get the message

Warning in read_symbols_from_dll(so,rarch):
this requires 'objdump.exe' to be on the PATH

I check 'Writing R Extensions' but I did not find any reference to this error. Does someone know how 
to fix that?

Thank you very much for your help.
Christophe


From hristo.inouzhe at uva.es  Mon Mar 20 13:55:53 2017
From: hristo.inouzhe at uva.es (Hristo Inouzhe Valdes)
Date: Mon, 20 Mar 2017 13:55:53 +0100
Subject: [Rd] Fwd: Possible memory problems with mallloc when called with
	.C()
In-Reply-To: <CAK1Bz9F8FVwj7CdakKRrGT_MeF9GBfKcratMsAr3nU0WjFe+pA@mail.gmail.com>
References: <CAK1Bz9F8FVwj7CdakKRrGT_MeF9GBfKcratMsAr3nU0WjFe+pA@mail.gmail.com>
Message-ID: <CAK1Bz9FwiW5hCu32vE-RaD_5iaN8s0D5u6CnDj2PzyW3t1=N8A@mail.gmail.com>

Hello,

I'm trying to calculate a certain distance estimator for my thesis. I have a
program in C that works fine when I call it with .C() in R, but since
I'm dealing with big matrices like 30000x20000 it was getting a stack
overflow. Now I have the same program but more efficeintly coded using
malloc, and it works perfectlry in C, compiles well with R CMD SHLIB
but when I call it with .C() my pc basicly stops working independantly
of the size of the matrices involved.

The C code is the following (sorry it is a bit long):

    #include <stdio.h>
    #include <stdlib.h>
    #include <string.h>
    #include <math.h>
    #ifdef NAN
    /* NAN is supported */
    #endif
    #ifdef INFINITY
    /* INFINITY is supported */
    #endif

    void dnk_c(double *sortedFsample, unsigned long int n, unsigned
long int k, double *dKol){

      double min(double a, double b) {
        return (a < b) ? a : b;
      }

      double max(double a, double b) {
        return (a > b) ? a : b;
      }

      double r_abs(double a){
        return (a < 0) ? -a : a;
      }

      int cmp(const void *a, const void *b) {
        return (*(double*)a - *(double*)b);
      }

      double superior(double x, double i, double m){
        double op1 = r_abs(x-(i)/(m));
        double op2 = r_abs(x-(i-1)/(m));
        return max(op1,op2);
      }

      double termino1, termino2, f, g, t, h1, h2, l=1.0, m=n-k;
      unsigned long int i, j, filas;

      double **matrixA, **matrixB;

      matrixA = (double **) malloc((k+1)*sizeof(double *));
      matrixB = (double **) malloc((k+1)*sizeof(double *));

      for (i=0; i <= k; i++) {
        matrixA[i] = (double *) malloc(n*sizeof(double));
        matrixB[i] = (double *) malloc(n*sizeof(double));

        for (j=0; j < n; j++) {
          matrixA[i][j] = 0;
          matrixB[i][j] = 0;
        }
      }

      for (i=0; i<n; i++) {
        j  = k;
        f  = i-m+1;
        l  = 0;
        h2 = min(i,j);
        h1 = max(l,f);

        for(; h1 <= h2; h1++) {
          t = i-h1+1;
          filas = (unsigned long int) h1;
          matrixA[filas][i] = superior(sortedFsample[i], t, m);
        }
      }

      for (i=0; i<n; i++){
        j  = n-m-1;
        f  = i-m;
        g  = 0;
        h2 = min(i,j);
        h1 = max(g,f);

        for(; h1 <= h2; h1++) {
          t = i-h1+1;
          filas = (unsigned long int) h1;
          matrixB[filas][i] = r_abs(sortedFsample[i] - (i-h1)/m);
        }
      }


      i = 1;
      j = n-m;

      for(; i< n; i++) {
        f  = i-m+1;
        g  = 1;
        h2 = min(i,j);
        h1 = max(g,f);

        matrixA[0][i] = max(matrixA[0][i], matrixA[0][i-1]);

        for(; h1 <= h2; h1++) {
          filas = (unsigned long int) h1;
          termino1 = max(matrixA[filas][i], matrixA[filas][i-1]);
          termino2 = max(matrixA[filas][i], matrixB[filas-1][i-1]);

          matrixA[filas][i] = min(termino1, termino2);
        }

        t  = n-m-1;
        f  = i-m;
        g  = 0;
        h2 = min(i,t);
        h1 = max(g,f);

        filas = (unsigned long int) h1;
        matrixB[0][i] = max(matrixB[0][i], matrixA[0][i-1]);

        for(; h1 <= h2; h1++) {
          filas = (unsigned long int) h1;
          termino1 = max(matrixB[filas][i], matrixA[filas][i-1]);

          if (filas == 0) {
            termino2 = max(matrixB[filas][i], - INFINITY);
          }
          else{
            termino2 = max(matrixB[filas][i], matrixB[filas-1][i-1]);
          }
          matrixB[filas][i] = min(termino1, termino2);
        }
      }

      filas = (unsigned long int) t;
      unsigned long int n_int = (unsigned long int) (n-1);
      double result = min(matrixA[filas+1][n_int], matrixB[filas][n_int]);

      for (i=0; i <= k; i++) {
        free(matrixA[i]);
        free(matrixB[i]);
      }

      free(matrixA);
      free(matrixB);

      dKol[0] = result;
    }

The R CMD SHLIB returns:

    gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c
/home/hristo/pCloudDrive/R/dnk_c.c -o
/home/hristo/pCloudDrive/R/dnk_c.o
    gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o /home/hristo/pCloudDrive/R/dnk_c.so
/home/hristo/pCloudDrive/R/dnk_c.o -L/usr/lib/R/lib -lR

My call in R to the function is:

    dyn.load("dnk_c.so")
    .C("dnk_c", as.double(sortedFsample), as.integer(N),
as.integer(k), as.double(dKol))

I don't see what am I doing wrong, and there is no error message. Can
somebady give me a hint of what could be happening?
Many thanks!!!

Hristo Inouzhe Valdes,
PhD candidate University of Valladolid,
Spain,
+34 983423111.


From realitix at gmail.com  Mon Mar 20 10:24:10 2017
From: realitix at gmail.com (realitix)
Date: Mon, 20 Mar 2017 10:24:10 +0100
Subject: [Rd] IO error when writing to disk
Message-ID: <CAPXDfFnF8iSSoDJHtUy0Wm=0PqwtzysLRG0KU_pqCVAO6AoqcA@mail.gmail.com>

Hello,
Here a small improvement for R.

When you use the function write.table, if the disk is full for example, the
function doesn't return an error and the file is written but truncated.

It can be a source of mistakes because you can then copy the output file
and think everything is ok.

How to reproduce
-------------------------

>> write.csv(1:10000000, 'path')

You must have a path with a small amount of disk available (on linux:
http://souptonuts.sourceforge.net/quota_tutorial.html)

I have joined the patch in this email.
Can you open a bugzilla account for me to keep track of this change.

Thanks,
Jean-S?bastien Bevilacqua
-------------- next part --------------
Index: src/library/utils/src/io.c
===================================================================
--- src/library/utils/src/io.c	(r?vision 72357)
+++ src/library/utils/src/io.c	(copie de travail)
@@ -1120,12 +1120,23 @@
 	for(int i = 0; i < nr; i++) {
 	    if(i % 1000 == 999) R_CheckUserInterrupt();
 	    if(!isNull(rnames))
-		Rconn_printf(con, "%s%s",
-			     EncodeElement2(rnames, i, quote_rn, qmethod,
-					    &strBuf, sdec), csep);
+
+		if(Rconn_printf(con, "%s%s", EncodeElement2(rnames, i, quote_rn, qmethod, &strBuf, sdec), csep) < 0) {
+            error(_("IO error, cannot write table."));
+            break;
+        }
+
 	    for(int j = 0; j < nc; j++) {
 		xj = VECTOR_ELT(x, j);
-		if(j > 0) Rconn_printf(con, "%s", csep);
+
+		if(j > 0) {
+            if(Rconn_printf(con, "%s", csep) < 0) {
+                error(_("IO error, cannot write table."));
+                i = nr;
+                break;
+            }
+        }
+
 		if(isna(xj, i)) tmp = cna;
 		else {
 		    if(!isNull(levels[j])) {
@@ -1148,9 +1159,17 @@
 					     &strBuf, sdec);
 		    }
 		}
-		Rconn_printf(con, "%s", tmp);
+
+        if(Rconn_printf(con, "%s", tmp) < 0) {
+            error(_("IO error, cannot write table."));
+            i = nr;
+            break;
+        }
 	    }
-	    Rconn_printf(con, "%s", ceol);
+	    if(Rconn_printf(con, "%s", ceol) < 0) {
+            error(_("IO error, cannot write table."));
+            break;
+        }
 	}
 
     } else { /* A matrix */
@@ -1163,20 +1182,36 @@
 
 	for(int i = 0; i < nr; i++) {
 	    if(i % 1000 == 999) R_CheckUserInterrupt();
-	    if(!isNull(rnames))
-		Rconn_printf(con, "%s%s",
-			     EncodeElement2(rnames, i, quote_rn, qmethod,
-					    &strBuf, sdec), csep);
+	    if(!isNull(rnames)) {
+            if(Rconn_printf(con, "%s%s", EncodeElement2(rnames, i, quote_rn, qmethod, &strBuf, sdec), csep) < 0) {
+                error(_("IO error, cannot write table."));
+                break;
+            }
+        }
 	    for(int j = 0; j < nc; j++) {
-		if(j > 0) Rconn_printf(con, "%s", csep);
+		if(j > 0) {
+            if(Rconn_printf(con, "%s", csep) < 0) {
+                error(_("IO error, cannot write table."));
+                i = nr;
+                break;
+            }
+        }
 		if(isna(x, i + j*nr)) tmp = cna;
 		else {
 		    tmp = EncodeElement2(x, i + j*nr, quote_col[j], qmethod,
 					&strBuf, sdec);
 		}
-		Rconn_printf(con, "%s", tmp);
+        if(Rconn_printf(con, "%s", tmp) < 0) {
+            error(_("IO error, cannot write table."));
+            i = nr;
+            break;
+        }
 	    }
-	    Rconn_printf(con, "%s", ceol);
+
+	    if(Rconn_printf(con, "%s", ceol) < 0) {
+            error(_("IO error, cannot write table."));
+            break;
+        }
 	}
 
     }

From maechler at stat.math.ethz.ch  Mon Mar 20 14:36:42 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Mar 2017 14:36:42 +0100
Subject: [Rd] outer not applying a constant function
In-Reply-To: <D4F40A9E.16FE8%albrecht.gebhardt@aau.at>
References: <D4F40A9E.16FE8%albrecht.gebhardt@aau.at>
Message-ID: <22735.56042.847992.57086@stat.math.ethz.ch>

>>>>> Gebhardt, Albrecht <Albrecht.Gebhardt at aau.at>
>>>>>     on Sun, 19 Mar 2017 09:14:56 +0000 writes:

    > Hi,
    > the function outer can not apply a constant function as in the last line of the following example:

    >> xg <- 1:4
    >> yg <- 1:4
    >> fxyg <- outer(xg, yg, function(x,y) x*y)
    >> fconstg <- outer(xg, yg, function(x,y) 1.0)
    > Error in outer(xg, yg, function(x, y) 1) :
    > dims [product 16] do not match the length of object [1]

    > Of course there are simpler ways to construct a constant matrix, that is not my point.

    > It happens for me in the context of generating matrices of partial derivatives, and if on of these partial derivatives happens to be constant it fails.

    > So e.g this works:

    > library(Deriv)
    > f <- function(x,y) (x-1.5)*(y-1)*(x-1.8)+(y-1.9)^2*(x-1.1)^3
    > fx <- Deriv(f,"x")
    > fy <- Deriv(f,"y")
    > fxy <- Deriv(Deriv(f,"y"),"x")
    > fxx <- Deriv(Deriv(f,"x"),"x")
    > fyy <- Deriv(Deriv(f,"y"),"y")

    > fg   <- outer(xg,yg,f)
    > fxg  <- outer(xg,yg,fx)
    > fyg  <- outer(xg,yg,fy)
    > fxyg <- outer(xg,yg,fxy)
    > fxxg <- outer(xg,yg,fxx)
    > fyyg <- outer(xg,yg,fyy)

    > And with

    > f <- function(x,y) x+y

    > it stops working. Of course I can manually fix this for that special case, but thats not my point. I simply thought "outer" should be able to handle constant functions.

?outer   clearly states that  FUN  needs to be vectorized

but  function(x,y) 1    is not.

It is easy to solve by wrapping the function in Vectorize(.):

> x <- 1:3; y <- 1:4

> outer(x,y, function(x,y) 1)
Error in dim(robj) <- c(dX, dY) : 
  dims [product 12] do not match the length of object [1]

> outer(x,y, Vectorize(function(x,y) 1))
     [,1] [,2] [,3] [,4]
[1,]    1    1    1    1
[2,]    1    1    1    1
[3,]    1    1    1    1

----------------

So, your "should"  above must be read in the sense

  "It really would be convenient here and
   correspond to other "recycling" behavior of R"

and I agree with that, having experienced the same inconvenience
as you several times in the past.

outer() being a nice R-level function (i.e., no C speed up)
makes it easy to improve:

Adding something like the line

if(length(robj) == 1L) robj <- rep.int(robj, dX*dY)

before    dim(robj) <- c(dX, dY)   [which gave the error]

would solve the issue and not cost much (in the cases it is unneeded).

Or is this a bad idea?


From wdunlap at tibco.com  Mon Mar 20 16:00:40 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 20 Mar 2017 08:00:40 -0700
Subject: [Rd] Fwd: Possible memory problems with mallloc when called
	with .C()
In-Reply-To: <CAK1Bz9FwiW5hCu32vE-RaD_5iaN8s0D5u6CnDj2PzyW3t1=N8A@mail.gmail.com>
References: <CAK1Bz9F8FVwj7CdakKRrGT_MeF9GBfKcratMsAr3nU0WjFe+pA@mail.gmail.com>
	<CAK1Bz9FwiW5hCu32vE-RaD_5iaN8s0D5u6CnDj2PzyW3t1=N8A@mail.gmail.com>
Message-ID: <CAF8bMcYcvC+42i5Edsjbsw-vdKN_eNSFQK3nuOKpcXL1UL7pdA@mail.gmail.com>

> void dnk_c(double *sortedFsample, unsigned long int n, unsigned
long int k, double *dKol)

All arguments to C functions called by .C() must be pointers.  Also, R
integers are C ints, not unsigned long ints.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Mar 20, 2017 at 5:55 AM, Hristo Inouzhe Valdes
<hristo.inouzhe at uva.es> wrote:
> Hello,
>
> I'm trying to calculate a certain distance estimator for my thesis. I have a
> program in C that works fine when I call it with .C() in R, but since
> I'm dealing with big matrices like 30000x20000 it was getting a stack
> overflow. Now I have the same program but more efficeintly coded using
> malloc, and it works perfectlry in C, compiles well with R CMD SHLIB
> but when I call it with .C() my pc basicly stops working independantly
> of the size of the matrices involved.
>
> The C code is the following (sorry it is a bit long):
>
>     #include <stdio.h>
>     #include <stdlib.h>
>     #include <string.h>
>     #include <math.h>
>     #ifdef NAN
>     /* NAN is supported */
>     #endif
>     #ifdef INFINITY
>     /* INFINITY is supported */
>     #endif
>
>     void dnk_c(double *sortedFsample, unsigned long int n, unsigned
> long int k, double *dKol){
>
>       double min(double a, double b) {
>         return (a < b) ? a : b;
>       }
>
>       double max(double a, double b) {
>         return (a > b) ? a : b;
>       }
>
>       double r_abs(double a){
>         return (a < 0) ? -a : a;
>       }
>
>       int cmp(const void *a, const void *b) {
>         return (*(double*)a - *(double*)b);
>       }
>
>       double superior(double x, double i, double m){
>         double op1 = r_abs(x-(i)/(m));
>         double op2 = r_abs(x-(i-1)/(m));
>         return max(op1,op2);
>       }
>
>       double termino1, termino2, f, g, t, h1, h2, l=1.0, m=n-k;
>       unsigned long int i, j, filas;
>
>       double **matrixA, **matrixB;
>
>       matrixA = (double **) malloc((k+1)*sizeof(double *));
>       matrixB = (double **) malloc((k+1)*sizeof(double *));
>
>       for (i=0; i <= k; i++) {
>         matrixA[i] = (double *) malloc(n*sizeof(double));
>         matrixB[i] = (double *) malloc(n*sizeof(double));
>
>         for (j=0; j < n; j++) {
>           matrixA[i][j] = 0;
>           matrixB[i][j] = 0;
>         }
>       }
>
>       for (i=0; i<n; i++) {
>         j  = k;
>         f  = i-m+1;
>         l  = 0;
>         h2 = min(i,j);
>         h1 = max(l,f);
>
>         for(; h1 <= h2; h1++) {
>           t = i-h1+1;
>           filas = (unsigned long int) h1;
>           matrixA[filas][i] = superior(sortedFsample[i], t, m);
>         }
>       }
>
>       for (i=0; i<n; i++){
>         j  = n-m-1;
>         f  = i-m;
>         g  = 0;
>         h2 = min(i,j);
>         h1 = max(g,f);
>
>         for(; h1 <= h2; h1++) {
>           t = i-h1+1;
>           filas = (unsigned long int) h1;
>           matrixB[filas][i] = r_abs(sortedFsample[i] - (i-h1)/m);
>         }
>       }
>
>
>       i = 1;
>       j = n-m;
>
>       for(; i< n; i++) {
>         f  = i-m+1;
>         g  = 1;
>         h2 = min(i,j);
>         h1 = max(g,f);
>
>         matrixA[0][i] = max(matrixA[0][i], matrixA[0][i-1]);
>
>         for(; h1 <= h2; h1++) {
>           filas = (unsigned long int) h1;
>           termino1 = max(matrixA[filas][i], matrixA[filas][i-1]);
>           termino2 = max(matrixA[filas][i], matrixB[filas-1][i-1]);
>
>           matrixA[filas][i] = min(termino1, termino2);
>         }
>
>         t  = n-m-1;
>         f  = i-m;
>         g  = 0;
>         h2 = min(i,t);
>         h1 = max(g,f);
>
>         filas = (unsigned long int) h1;
>         matrixB[0][i] = max(matrixB[0][i], matrixA[0][i-1]);
>
>         for(; h1 <= h2; h1++) {
>           filas = (unsigned long int) h1;
>           termino1 = max(matrixB[filas][i], matrixA[filas][i-1]);
>
>           if (filas == 0) {
>             termino2 = max(matrixB[filas][i], - INFINITY);
>           }
>           else{
>             termino2 = max(matrixB[filas][i], matrixB[filas-1][i-1]);
>           }
>           matrixB[filas][i] = min(termino1, termino2);
>         }
>       }
>
>       filas = (unsigned long int) t;
>       unsigned long int n_int = (unsigned long int) (n-1);
>       double result = min(matrixA[filas+1][n_int], matrixB[filas][n_int]);
>
>       for (i=0; i <= k; i++) {
>         free(matrixA[i]);
>         free(matrixB[i]);
>       }
>
>       free(matrixA);
>       free(matrixB);
>
>       dKol[0] = result;
>     }
>
> The R CMD SHLIB returns:
>
>     gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c
> /home/hristo/pCloudDrive/R/dnk_c.c -o
> /home/hristo/pCloudDrive/R/dnk_c.o
>     gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o /home/hristo/pCloudDrive/R/dnk_c.so
> /home/hristo/pCloudDrive/R/dnk_c.o -L/usr/lib/R/lib -lR
>
> My call in R to the function is:
>
>     dyn.load("dnk_c.so")
>     .C("dnk_c", as.double(sortedFsample), as.integer(N),
> as.integer(k), as.double(dKol))
>
> I don't see what am I doing wrong, and there is no error message. Can
> somebady give me a hint of what could be happening?
> Many thanks!!!
>
> Hristo Inouzhe Valdes,
> PhD candidate University of Valladolid,
> Spain,
> +34 983423111.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Mon Mar 20 16:38:25 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 20 Mar 2017 16:38:25 +0100
Subject: [Rd] Experimental CXX_STD problem in R 3.4
In-Reply-To: <1489954147228.25309@iarc.fr>
References: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>
	<22733.19068.582932.665707@max.eddelbuettel.com>
	<1489954147228.25309@iarc.fr>
Message-ID: <CABFfbXv93rUEbd2wzBiMDmWP0XK5FCuT4iNijr3o1dNwPn7ezQ@mail.gmail.com>

On Sun, Mar 19, 2017 at 9:09 PM, Martyn Plummer <plummerm at iarc.fr> wrote:
> I have just added some code to ensure that the compilation fails with an informative error message if a specific C++ standard is requested but the corresponding compiler has not been defined. Please test this.

Are you sure we shouldn't just fall back on a previous standard
instead of failing? For example if the package author has specified a
preference for CXX14 but the compiler only has CXX11, the package
might still build with -std=c++11 (given that C++14 is only a small
extension on the C++11 standard).

The current behavior (in R 3.3) for packages with "CXX_STD=CXX11" is
to fall back on CXX when the compiler does not have CXX1X. Will R-3.4
start failing these packages? This would affect many users on CentOS 6
(gcc 4.4.7).


From jeroenooms at gmail.com  Mon Mar 20 17:28:36 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 20 Mar 2017 17:28:36 +0100
Subject: [Rd] Experimental CXX_STD problem in R 3.4
In-Reply-To: <1489954147228.25309@iarc.fr>
References: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>
	<22733.19068.582932.665707@max.eddelbuettel.com>
	<1489954147228.25309@iarc.fr>
Message-ID: <CABFfbXtAo90FAYXxTr5hM23SdCZ6uDpHGtz=NDhkmfVOMLdmUA@mail.gmail.com>

On Sun, Mar 19, 2017 at 9:09 PM, Martyn Plummer <plummerm at iarc.fr> wrote:
> I have just added some code to ensure that the compilation fails with an informative error message if a specific C++ standard is requested but the corresponding compiler has not been defined. Please test this.

I can confirm that (at least on Windows) we get a proper error message
for CXX14 and CXX17, eg:

  * installing *source* package 'testcxx' ...
  ** libs
  Error in .shlib_internal(args) :
   C++14 standard requested but CXX1Y is not defined
  * removing 'C:/Program Files/R/R-devel/library/testcxx'

CXX98 still does not work though. It seems SHLIB_CXX98LD is undefined
on Windows?

  * installing *source* package 'testcxx' ...
  ** libs
  c:/Rtools/mingw_64/bin/g++  -std=gnu++98
-I"C:/PROGRA~1/R/R-devel/include" -DNDEBUG
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
-c test.cpp -o test.o
  -shared -s -static-libgcc -o testcxx.dll tmp.def test.o
-Ld:/Compiler/gcc-4.9.3/local330/lib/x64
-Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-devel/bin/x64
-lR
  -shared: not found
  no DLL was created
  ERROR: compilation failed for package 'testcxx'


From wdunlap at tibco.com  Mon Mar 20 18:20:11 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 20 Mar 2017 10:20:11 -0700
Subject: [Rd] outer not applying a constant function
In-Reply-To: <22735.56042.847992.57086@stat.math.ethz.ch>
References: <D4F40A9E.16FE8%albrecht.gebhardt@aau.at>
	<22735.56042.847992.57086@stat.math.ethz.ch>
Message-ID: <CAF8bMcZhQyTh0urDXvSfWEk5uqnBvkwEu7MhF2Aj9zqGx6Y2CA@mail.gmail.com>

> Or is this a bad idea?

I don't like the proposal.  I have seen code like the following (in
fact, I have written such code, where I had forgotten a function was
not vectorized) where the error would have been discovered much later
if outer() didn't catch it.

  > outer(1:3, 11:13, sum)
  Error in outer(1:3, 11:13, sum) :
    dims [product 9] do not match the length of object [1]

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Mar 20, 2017 at 6:36 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Gebhardt, Albrecht <Albrecht.Gebhardt at aau.at>
>>>>>>     on Sun, 19 Mar 2017 09:14:56 +0000 writes:
>
>     > Hi,
>     > the function outer can not apply a constant function as in the last line of the following example:
>
>     >> xg <- 1:4
>     >> yg <- 1:4
>     >> fxyg <- outer(xg, yg, function(x,y) x*y)
>     >> fconstg <- outer(xg, yg, function(x,y) 1.0)
>     > Error in outer(xg, yg, function(x, y) 1) :
>     > dims [product 16] do not match the length of object [1]
>
>     > Of course there are simpler ways to construct a constant matrix, that is not my point.
>
>     > It happens for me in the context of generating matrices of partial derivatives, and if on of these partial derivatives happens to be constant it fails.
>
>     > So e.g this works:
>
>     > library(Deriv)
>     > f <- function(x,y) (x-1.5)*(y-1)*(x-1.8)+(y-1.9)^2*(x-1.1)^3
>     > fx <- Deriv(f,"x")
>     > fy <- Deriv(f,"y")
>     > fxy <- Deriv(Deriv(f,"y"),"x")
>     > fxx <- Deriv(Deriv(f,"x"),"x")
>     > fyy <- Deriv(Deriv(f,"y"),"y")
>
>     > fg   <- outer(xg,yg,f)
>     > fxg  <- outer(xg,yg,fx)
>     > fyg  <- outer(xg,yg,fy)
>     > fxyg <- outer(xg,yg,fxy)
>     > fxxg <- outer(xg,yg,fxx)
>     > fyyg <- outer(xg,yg,fyy)
>
>     > And with
>
>     > f <- function(x,y) x+y
>
>     > it stops working. Of course I can manually fix this for that special case, but thats not my point. I simply thought "outer" should be able to handle constant functions.
>
> ?outer   clearly states that  FUN  needs to be vectorized
>
> but  function(x,y) 1    is not.
>
> It is easy to solve by wrapping the function in Vectorize(.):
>
>> x <- 1:3; y <- 1:4
>
>> outer(x,y, function(x,y) 1)
> Error in dim(robj) <- c(dX, dY) :
>   dims [product 12] do not match the length of object [1]
>
>> outer(x,y, Vectorize(function(x,y) 1))
>      [,1] [,2] [,3] [,4]
> [1,]    1    1    1    1
> [2,]    1    1    1    1
> [3,]    1    1    1    1
>
> ----------------
>
> So, your "should"  above must be read in the sense
>
>   "It really would be convenient here and
>    correspond to other "recycling" behavior of R"
>
> and I agree with that, having experienced the same inconvenience
> as you several times in the past.
>
> outer() being a nice R-level function (i.e., no C speed up)
> makes it easy to improve:
>
> Adding something like the line
>
> if(length(robj) == 1L) robj <- rep.int(robj, dX*dY)
>
> before    dim(robj) <- c(dX, dY)   [which gave the error]
>
> would solve the issue and not cost much (in the cases it is unneeded).
>
> Or is this a bad idea?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar 21 08:29:23 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Mar 2017 07:29:23 +0000
Subject: [Rd] Incompatible change in R-devel
Message-ID: <f9a7edaa-63f9-f79f-f750-39d44511c188@stats.ox.ac.uk>

As of today's commit r72375 all packages with native-routine 
registration of C or Fortran routines need to be reinstalled in R-devel 
(and that include some of the recommended packages in R itself which 
will not be reinstalled via make dependencies, so we advise a clean 
rebuild of R).

We try to avoid such things, but now is a least bad time (before binary 
packages for pre-3.4.0 are built in earnest, although CRAN Windows ones 
have been available for a while and will be rebuilt now).

Packages aster2 used undocumented/defunct fields and is overdue for 
update: AFIAWK all other CRAN/BioC packages can be reinstalled.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From maechler at stat.math.ethz.ch  Tue Mar 21 09:38:24 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Mar 2017 09:38:24 +0100
Subject: [Rd] outer not applying a constant function
In-Reply-To: <CAF8bMcZhQyTh0urDXvSfWEk5uqnBvkwEu7MhF2Aj9zqGx6Y2CA@mail.gmail.com>
References: <D4F40A9E.16FE8%albrecht.gebhardt@aau.at>
	<22735.56042.847992.57086@stat.math.ethz.ch>
	<CAF8bMcZhQyTh0urDXvSfWEk5uqnBvkwEu7MhF2Aj9zqGx6Y2CA@mail.gmail.com>
Message-ID: <22736.59008.221932.8907@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Mon, 20 Mar 2017 10:20:11 -0700 writes:

    >> Or is this a bad idea?
    > I don't like the proposal.  I have seen code like the following (in
    > fact, I have written such code, where I had forgotten a function was
    > not vectorized) where the error would have been discovered much later
    > if outer() didn't catch it.

    >> outer(1:3, 11:13, sum)
    >  Error in outer(1:3, 11:13, sum) :
    >    dims [product 9] do not match the length of object [1]

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

You are right, thank you!
Such a "convenience change" would not be a good idea.

Martin Maechler
ETH Zurich




    > On Mon, Mar 20, 2017 at 6:36 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Gebhardt, Albrecht <Albrecht.Gebhardt at aau.at>
    >>>>>>> on Sun, 19 Mar 2017 09:14:56 +0000 writes:
    >> 
    >> > Hi,
    >> > the function outer can not apply a constant function as in the last line of the following example:
    >> 
    >> >> xg <- 1:4
    >> >> yg <- 1:4
    >> >> fxyg <- outer(xg, yg, function(x,y) x*y)
    >> >> fconstg <- outer(xg, yg, function(x,y) 1.0)
    >> > Error in outer(xg, yg, function(x, y) 1) :
    >> > dims [product 16] do not match the length of object [1]
    >> 
    >> > Of course there are simpler ways to construct a constant matrix, that is not my point.
    >> 
    >> > It happens for me in the context of generating matrices of partial derivatives, and if on of these partial derivatives happens to be constant it fails.
    >> 
    >> > So e.g this works:
    >> 
    >> > library(Deriv)
    >> > f <- function(x,y) (x-1.5)*(y-1)*(x-1.8)+(y-1.9)^2*(x-1.1)^3
    >> > fx <- Deriv(f,"x")
    >> > fy <- Deriv(f,"y")
    >> > fxy <- Deriv(Deriv(f,"y"),"x")
    >> > fxx <- Deriv(Deriv(f,"x"),"x")
    >> > fyy <- Deriv(Deriv(f,"y"),"y")
    >> 
    >> > fg   <- outer(xg,yg,f)
    >> > fxg  <- outer(xg,yg,fx)
    >> > fyg  <- outer(xg,yg,fy)
    >> > fxyg <- outer(xg,yg,fxy)
    >> > fxxg <- outer(xg,yg,fxx)
    >> > fyyg <- outer(xg,yg,fyy)
    >> 
    >> > And with
    >> 
    >> > f <- function(x,y) x+y
    >> 
    >> > it stops working. Of course I can manually fix this for that special case, but thats not my point. I simply thought "outer" should be able to handle constant functions.
    >> 
    >> ?outer   clearly states that  FUN  needs to be vectorized
    >> 
    >> but  function(x,y) 1    is not.
    >> 
    >> It is easy to solve by wrapping the function in Vectorize(.):
    >> 
    >>> x <- 1:3; y <- 1:4
    >> 
    >>> outer(x,y, function(x,y) 1)
    >> Error in dim(robj) <- c(dX, dY) :
    >> dims [product 12] do not match the length of object [1]
    >> 
    >>> outer(x,y, Vectorize(function(x,y) 1))
    >> [,1] [,2] [,3] [,4]
    >> [1,]    1    1    1    1
    >> [2,]    1    1    1    1
    >> [3,]    1    1    1    1
    >> 
    >> ----------------
    >> 
    >> So, your "should"  above must be read in the sense
    >> 
    >> "It really would be convenient here and
    >> correspond to other "recycling" behavior of R"
    >> 
    >> and I agree with that, having experienced the same inconvenience
    >> as you several times in the past.
    >> 
    >> outer() being a nice R-level function (i.e., no C speed up)
    >> makes it easy to improve:
    >> 
    >> Adding something like the line
    >> 
    >> if(length(robj) == 1L) robj <- rep.int(robj, dX*dY)
    >> 
    >> before    dim(robj) <- c(dX, dY)   [which gave the error]
    >> 
    >> would solve the issue and not cost much (in the cases it is unneeded).
    >> 
    >> Or is this a bad idea?
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Mar 21 10:54:25 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Mar 2017 10:54:25 +0100
Subject: [Rd] Hyperbolic tangent different results on Windows and Mac
In-Reply-To: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
References: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
Message-ID: <22736.63569.874287.159332@stat.math.ethz.ch>

>>>>> Rodrigo Zepeda <rzepeda17 at gmail.com>
>>>>>     on Fri, 17 Mar 2017 12:56:06 -0600 writes:

    > Dear all,
    > We seem to have found a "strange" behaviour in the hyperbolic tangent
    > function tanh on Windows.
    > When running tanh(356 + 0i) the Windows result is NaN + 0.i while on Mac
    > the result is 1 + 0i. It doesn't seem to be a floating point error because
    > on Mac it is possible to run arbitrarily large numbers (say tanh(
    > 999999677873648767519238192348124812341234182374817239847812738481234871823+0i)
    > ) and still get 1 + 0i as result. This seems to be related to the imaginary
    > part as tanh(356) returns 1 in both Windows and Mac.

    > We have obtained those results in:
    > 1) Mac with El Capitan v 10.11.6 *processor: 2.7 GHz Intel Core i5*
    > - 2) Mac with Sierra v 10.12.3 *processor: 3.2 GHz Intel Core i5*
    > - 3) Windows 10 Home v 1607 *processor: Intel Core m3-SY30 CPU@ 0.90 GHz
    > 1.51 GHz*
    > - 4) Windows 7 Home Premium Service Pack 1 *processor: Intel Core i5-2410M
    > CPU @2.30 GHz 2.30GHz.*

(The hardware should not matter).

Yes, there is a bug here on Windows only, (several Linux
versions work correctly too).

    > ?In all cases we are using R version 3.3.3 (64 bits)?


    > - *Does anybody have a clue on why is this happening?*

    > ?PS: We have previously posted this issue in Stack Overflow (
    > http://stackoverflow.com/questions/42847414/hyperbolic-tangent-in-r-throws-nan-in-windows-but-not-in-mac).
    > A comment suggests it is related to a glibc bug.

Yes, that would have been my guess too... as indeed, R on
Windows which should work for quite old versions of Windows has
been using a relatively old (gcc / libc) toolchain.

The upcoming version of R 3.4.0 uses a considerably newer
toolchain *BUT* I've just checked the latest "R-devel" binary
and the bug is still present there.

Here's a slight extension of the answer I wrote to the
above SO question here:  http://stackoverflow.com/a/42923289/161921

... Windows uses somewhat old C libraries, and here it is the
"mathlib" part of glibc. 

More specifically, according to the CRAN download page for R-devel for Windows
https://cran.r-project.org/bin/windows/base/rdevel.html ,
the R 3.3.z series uses the gcc 4.6.3 (March 2012) toolchain, whereas
"R-devel", the upcoming (not yet released!) R 3.4.z series uses
the gcc 4.9.3 (June 2015) toolchain.

According to Ben Bolker's comment on SO, the bug in glibc should have
been fixed in 2012 -- and so the change from 4.6.3 to 4.9.3
should have helped,
**however* I've just checked (installed the R-devel binary from CRAN on our Windows server virtual machine) and I see that the problem is still present there: In yesterday's version of R-devel, tanh(500+0i) still returns NaN+0i.

I now think a better solution would be to use R's internal
substitute (in R's src/main/complex.c): There, we have
------------------------------------------------
#ifndef HAVE_CTANH
#define ctanh R_ctanh
static double complex ctanh(double complex z)
{
    return -I * ctan(z * I); /* A&S 4.5.9 */
}
#endif
------------------------------------------------
and we should use it (by "#undef HAVE_CTAN" (or better by a
       	      	      configure check, using  ctanh("500 + 0i"),
as I see that on Windows,
   R> -1i * tan((500+0i)*1i)
gives
   [1] 1+0i
as it should for tanh(500+0i) --- but does not on Windows.

Martin Maechler
ETH Zurich and R Core


From edd at debian.org  Tue Mar 21 17:38:11 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 21 Mar 2017 11:38:11 -0500
Subject: [Rd] Incompatible change in R-devel
In-Reply-To: <f9a7edaa-63f9-f79f-f750-39d44511c188@stats.ox.ac.uk>
References: <f9a7edaa-63f9-f79f-f750-39d44511c188@stats.ox.ac.uk>
Message-ID: <22737.22259.497157.821096@max.eddelbuettel.com>


Hi Brian,

On 21 March 2017 at 07:29, Prof Brian Ripley wrote:
| As of today's commit r72375 all packages with native-routine 
| registration of C or Fortran routines need to be reinstalled in R-devel 
| (and that include some of the recommended packages in R itself which 
| will not be reinstalled via make dependencies, so we advise a clean 
| rebuild of R).

I am confused by this.

So in order to test this, I just triggered rebuild of the smaller drd ("daily
r-devel") and r-devel Docker images for R.  

Using drd, I used R 3.3.3 to install digest and anytime (also installing Rcpp
and BH). I then launch the R-devel build freshly created, and reported as 

 root at b00daf469882:/# RD --version
 R Under development (unstable) (2017-03-21 r72380) -- "Unsuffered Consequences"

yet both digest and anytime loaded fine by R-devel. Despite the fact that
they were installed by R 3.3.3.

As I understand your email, that should not have worked.  So I must be
missing something -- can you help set me straight?

Thanks, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ligges at statistik.tu-dortmund.de  Tue Mar 21 18:09:59 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Mar 2017 18:09:59 +0100
Subject: [Rd] Hyperbolic tangent different results on Windows and Mac
In-Reply-To: <22736.63569.874287.159332@stat.math.ethz.ch>
References: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
	<22736.63569.874287.159332@stat.math.ethz.ch>
Message-ID: <095426dc-af07-912b-6632-2011add255da@statistik.tu-dortmund.de>



On 21.03.2017 10:54, Martin Maechler wrote:
>>>>>> Rodrigo Zepeda <rzepeda17 at gmail.com>
>>>>>>     on Fri, 17 Mar 2017 12:56:06 -0600 writes:
>
>     > Dear all,
>     > We seem to have found a "strange" behaviour in the hyperbolic tangent
>     > function tanh on Windows.
>     > When running tanh(356 + 0i) the Windows result is NaN + 0.i while on Mac
>     > the result is 1 + 0i. It doesn't seem to be a floating point error because
>     > on Mac it is possible to run arbitrarily large numbers (say tanh(
>     > 999999677873648767519238192348124812341234182374817239847812738481234871823+0i)
>     > ) and still get 1 + 0i as result. This seems to be related to the imaginary
>     > part as tanh(356) returns 1 in both Windows and Mac.
>
>     > We have obtained those results in:
>     > 1) Mac with El Capitan v 10.11.6 *processor: 2.7 GHz Intel Core i5*
>     > - 2) Mac with Sierra v 10.12.3 *processor: 3.2 GHz Intel Core i5*
>     > - 3) Windows 10 Home v 1607 *processor: Intel Core m3-SY30 CPU@ 0.90 GHz
>     > 1.51 GHz*
>     > - 4) Windows 7 Home Premium Service Pack 1 *processor: Intel Core i5-2410M
>     > CPU @2.30 GHz 2.30GHz.*
>
> (The hardware should not matter).
>
> Yes, there is a bug here on Windows only, (several Linux
> versions work correctly too).
>
>     > ?In all cases we are using R version 3.3.3 (64 bits)?
>
>
>     > - *Does anybody have a clue on why is this happening?*
>
>     > ?PS: We have previously posted this issue in Stack Overflow (
>     > http://stackoverflow.com/questions/42847414/hyperbolic-tangent-in-r-throws-nan-in-windows-but-not-in-mac).
>     > A comment suggests it is related to a glibc bug.
>
> Yes, that would have been my guess too... as indeed, R on
> Windows which should work for quite old versions of Windows has
> been using a relatively old (gcc / libc) toolchain.
>
> The upcoming version of R 3.4.0 uses a considerably newer
> toolchain *BUT* I've just checked the latest "R-devel" binary
> and the bug is still present there.
>
> Here's a slight extension of the answer I wrote to the
> above SO question here:  http://stackoverflow.com/a/42923289/161921
>
> ... Windows uses somewhat old C libraries, and here it is the
> "mathlib" part of glibc.
>
> More specifically, according to the CRAN download page for R-devel for Windows
> https://cran.r-project.org/bin/windows/base/rdevel.html ,
> the R 3.3.z series uses the gcc 4.6.3 (March 2012) toolchain, whereas
> "R-devel", the upcoming (not yet released!) R 3.4.z series uses
> the gcc 4.9.3 (June 2015) toolchain.


Actually the R-3.3.z series already uses gcc-4.9.3.


Best,
Uwe Ligges

>
> According to Ben Bolker's comment on SO, the bug in glibc should have
> been fixed in 2012 -- and so the change from 4.6.3 to 4.9.3
> should have helped,
> **however* I've just checked (installed the R-devel binary from CRAN on our Windows server virtual machine) and I see that the problem is still present there: In yesterday's version of R-devel, tanh(500+0i) still returns NaN+0i.
>
> I now think a better solution would be to use R's internal
> substitute (in R's src/main/complex.c): There, we have
> ------------------------------------------------
> #ifndef HAVE_CTANH
> #define ctanh R_ctanh
> static double complex ctanh(double complex z)
> {
>     return -I * ctan(z * I); /* A&S 4.5.9 */
> }
> #endif
> ------------------------------------------------
> and we should use it (by "#undef HAVE_CTAN" (or better by a
>        	      	      configure check, using  ctanh("500 + 0i"),
> as I see that on Windows,
>    R> -1i * tan((500+0i)*1i)
> gives
>    [1] 1+0i
> as it should for tanh(500+0i) --- but does not on Windows.
>
> Martin Maechler
> ETH Zurich and R Core
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Tue Mar 21 18:12:11 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Mar 2017 18:12:11 +0100
Subject: [Rd] Error "Warning in read_symbols_from_dll(so,
 rarch): this requires 'objdump.exe' to be on the PATH
In-Reply-To: <751f3173-6a97-77ca-40dd-633185e216ba@u-paris10.fr>
References: <751f3173-6a97-77ca-40dd-633185e216ba@u-paris10.fr>
Message-ID: <27dbaf44-e952-e1c5-51cc-c21100b5154c@statistik.tu-dortmund.de>



On 19.03.2017 23:50, Christophe Genolini wrote:
> Hi all,
>
> I try to compile my package kml and I get the message
>
> Warning in read_symbols_from_dll(so,rarch):
> this requires 'objdump.exe' to be on the PATH
>
> I check 'Writing R Extensions' but I did not find any reference to this
> error. Does someone know how to fix that?

Yes: Put objdump.exe on the PATH, that executable is part of gcc and in 
its bin directoy.

Best,
Uwe Ligges



> Thank you very much for your help.
> Christophe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar 21 18:18:26 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Mar 2017 17:18:26 +0000
Subject: [Rd] Incompatible change in R-devel
In-Reply-To: <22737.22259.497157.821096@max.eddelbuettel.com>
References: <f9a7edaa-63f9-f79f-f750-39d44511c188@stats.ox.ac.uk>
	<22737.22259.497157.821096@max.eddelbuettel.com>
Message-ID: <667a73f1-dbd9-4008-5ab2-3099b4b9a818@stats.ox.ac.uk>

On 21/03/2017 16:38, Dirk Eddelbuettel wrote:
>
> Hi Brian,
>
> On 21 March 2017 at 07:29, Prof Brian Ripley wrote:
> | As of today's commit r72375 all packages with native-routine
> | registration of C or Fortran routines need to be reinstalled in R-devel
> | (and that include some of the recommended packages in R itself which
> | will not be reinstalled via make dependencies, so we advise a clean
> | rebuild of R).
>
> I am confused by this.
>
> So in order to test this, I just triggered rebuild of the smaller drd ("daily
> r-devel") and r-devel Docker images for R.
>
> Using drd, I used R 3.3.3 to install digest and anytime (also installing Rcpp
> and BH). I then launch the R-devel build freshly created, and reported as
>
>  root at b00daf469882:/# RD --version
>  R Under development (unstable) (2017-03-21 r72380) -- "Unsuffered Consequences"
>
> yet both digest and anytime loaded fine by R-devel. Despite the fact that
> they were installed by R 3.3.3.

None register C/Fortran routines for .C or .Fortran.

My belief is that packages which register more than one .C or more than 
one .Fortran native routine are affected, but that may not be exhaustive 
(and might depend on the compiler).

> As I understand your email, that should not have worked.  So I must be
> missing something -- can you help set me straight?

All packages should load ... the issue is finding (all of the) 
registered symbols.  Here's an example of what can go wrong, x86_64 Linux;

 > library(mgcv, lib = "/usr/local/lib64/R/library") # R 3.3.3
Loading required package: nlme
This is mgcv 1.8-17. For overview type 'help("mgcv-package")'.
 > mgcv:::in.out
...
     um <- .C(C_in_out, bx = as.double(bnd[, 1]), by = as.double(bnd[,
...
 > mgcv:::C_in_out
Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
   object 'C_in_out' not found

(the last message being found in testing a package which called mgcv).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From ripley at stats.ox.ac.uk  Tue Mar 21 18:27:10 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Mar 2017 17:27:10 +0000
Subject: [Rd] Error "Warning in read_symbols_from_dll(so,
 rarch): this requires 'objdump.exe' to be on the PATH
In-Reply-To: <27dbaf44-e952-e1c5-51cc-c21100b5154c@statistik.tu-dortmund.de>
References: <751f3173-6a97-77ca-40dd-633185e216ba@u-paris10.fr>
	<27dbaf44-e952-e1c5-51cc-c21100b5154c@statistik.tu-dortmund.de>
Message-ID: <b83b3899-bc79-44da-bfc1-a98f79ae967b@stats.ox.ac.uk>

On 21/03/2017 17:12, Uwe Ligges wrote:
>
>
> On 19.03.2017 23:50, Christophe Genolini wrote:
>> Hi all,
>>
>> I try to compile my package kml and I get the message

[That will not be 'compiling': it may be from R CMD check, e.g. from 
wuth --as-cran in R-devel.]

>> Warning in read_symbols_from_dll(so,rarch):
>> this requires 'objdump.exe' to be on the PATH
>>
>> I check 'Writing R Extensions' but I did not find any reference to this
>> error. Does someone know how to fix that?
>
> Yes: Put objdump.exe on the PATH, that executable is part of gcc and in
> its bin directoy.

Not quite: it is part of GNU Bintools, hence bundled with gcc in Rtools. 
  So is 'nm', which may appear in a similar message (and on Windows 
means 'nm.exe').

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From edd at debian.org  Tue Mar 21 18:30:58 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 21 Mar 2017 12:30:58 -0500
Subject: [Rd] Incompatible change in R-devel
In-Reply-To: <667a73f1-dbd9-4008-5ab2-3099b4b9a818@stats.ox.ac.uk>
References: <f9a7edaa-63f9-f79f-f750-39d44511c188@stats.ox.ac.uk>
	<22737.22259.497157.821096@max.eddelbuettel.com>
	<667a73f1-dbd9-4008-5ab2-3099b4b9a818@stats.ox.ac.uk>
Message-ID: <22737.25426.686065.795521@max.eddelbuettel.com>


On 21 March 2017 at 17:18, Prof Brian Ripley wrote:
| On 21/03/2017 16:38, Dirk Eddelbuettel wrote:
| > On 21 March 2017 at 07:29, Prof Brian Ripley wrote:
| > | As of today's commit r72375 all packages with native-routine
| > | registration of C or Fortran routines need to be reinstalled in R-devel
| > | (and that include some of the recommended packages in R itself which
| > | will not be reinstalled via make dependencies, so we advise a clean
| > | rebuild of R).
| >
| > I am confused by this.
| >
| > So in order to test this, I just triggered rebuild of the smaller drd ("daily
| > r-devel") and r-devel Docker images for R.
| >
| > Using drd, I used R 3.3.3 to install digest and anytime (also installing Rcpp
| > and BH). I then launch the R-devel build freshly created, and reported as
| >
| >  root at b00daf469882:/# RD --version
| >  R Under development (unstable) (2017-03-21 r72380) -- "Unsuffered Consequences"
| >
| > yet both digest and anytime loaded fine by R-devel. Despite the fact that
| > they were installed by R 3.3.3.
| 
| None register C/Fortran routines for .C or .Fortran.

Thanks for the prompt follow-up. Between your email and corresponding entry
in NEWS tagged over at the 'daily r-devel changes' RSS feed, I was also
thinking this might be limited to .C and .Fortran, but _not_ the .Call so
much more common in my world.
 
| My belief is that packages which register more than one .C or more than 
| one .Fortran native routine are affected, but that may not be exhaustive 
| (and might depend on the compiler).

Ok, thanks for the clarification.
 
| > As I understand your email, that should not have worked.  So I must be
| > missing something -- can you help set me straight?
| 
| All packages should load ... the issue is finding (all of the) 
| registered symbols.  Here's an example of what can go wrong, x86_64 Linux;
| 
|  > library(mgcv, lib = "/usr/local/lib64/R/library") # R 3.3.3
| Loading required package: nlme
| This is mgcv 1.8-17. For overview type 'help("mgcv-package")'.
|  > mgcv:::in.out
| ...
|      um <- .C(C_in_out, bx = as.double(bnd[, 1]), by = as.double(bnd[,
| ...
|  > mgcv:::C_in_out
| Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
|    object 'C_in_out' not found
| 
| (the last message being found in testing a package which called mgcv).

Thanks also for the illustration.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From realitix at gmail.com  Wed Mar 22 10:17:54 2017
From: realitix at gmail.com (realitix)
Date: Wed, 22 Mar 2017 10:17:54 +0100
Subject: [Rd] IO error when writing to disk
In-Reply-To: <CAPXDfFnF8iSSoDJHtUy0Wm=0PqwtzysLRG0KU_pqCVAO6AoqcA@mail.gmail.com>
References: <CAPXDfFnF8iSSoDJHtUy0Wm=0PqwtzysLRG0KU_pqCVAO6AoqcA@mail.gmail.com>
Message-ID: <CAPXDfF=suW3S-Bd8sZqTaqkpGT3-OJ2T2pHhUsNKpE+U2+cbqg@mail.gmail.com>

Hello,
I have sent a mail but I got no answer.

Can you create a bugzilla account for me.

Thanks,
Jean-S?bastien Bevilacqua

2017-03-20 10:24 GMT+01:00 realitix <realitix at gmail.com>:

> Hello,
> Here a small improvement for R.
>
> When you use the function write.table, if the disk is full for example,
> the function doesn't return an error and the file is written but truncated.
>
> It can be a source of mistakes because you can then copy the output file
> and think everything is ok.
>
> How to reproduce
> -------------------------
>
> >> write.csv(1:10000000, 'path')
>
> You must have a path with a small amount of disk available (on linux:
> http://souptonuts.sourceforge.net/quota_tutorial.html)
>
> I have joined the patch in this email.
> Can you open a bugzilla account for me to keep track of this change.
>
> Thanks,
> Jean-S?bastien Bevilacqua
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Mar 22 11:10:07 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Mar 2017 11:10:07 +0100
Subject: [Rd] IO error when writing to disk
In-Reply-To: <CAPXDfF=suW3S-Bd8sZqTaqkpGT3-OJ2T2pHhUsNKpE+U2+cbqg@mail.gmail.com>
References: <CAPXDfFnF8iSSoDJHtUy0Wm=0PqwtzysLRG0KU_pqCVAO6AoqcA@mail.gmail.com>
	<CAPXDfF=suW3S-Bd8sZqTaqkpGT3-OJ2T2pHhUsNKpE+U2+cbqg@mail.gmail.com>
Message-ID: <22738.19839.477561.237@stat.math.ethz.ch>

>>>>> realitix  <realitix at gmail.com>
>>>>>     on Wed, 22 Mar 2017 10:17:54 +0100 writes:

    > Hello,
    > I have sent a mail but I got no answer.

All work here happens on a volunteer basis... and it seems
everybody was busy or not interested.

    > Can you create a bugzilla account for me.

I've done that now.

Note that your prposed patch did contain a bit too many "copy &
paste" repetitions...  which I personally would have liked to be
written differently, using a wrapper (function or macro).

Also, let's assume on Linux, would there be a way to create a
small, say 1 MB, temporary file system as a non-root user?
In that case, we could do all the testing from inside R ..

Best,
Martin Maechler

    > Thanks,
    > Jean-S?bastien Bevilacqua

    > 2017-03-20 10:24 GMT+01:00 realitix <realitix at gmail.com>:

    >> Hello,
    >> Here a small improvement for R.
    >> 
    >> When you use the function write.table, if the disk is full for example,
    >> the function doesn't return an error and the file is written but truncated.
    >> 
    >> It can be a source of mistakes because you can then copy the output file
    >> and think everything is ok.
    >> 
    >> How to reproduce
    >> -------------------------
    >> 
    >> >> write.csv(1:10000000, 'path')
    >> 
    >> You must have a path with a small amount of disk available (on linux:
    >> http://souptonuts.sourceforge.net/quota_tutorial.html)
    >> 
    >> I have joined the patch in this email.
    >> Can you open a bugzilla account for me to keep track of this change.
    >> 
    >> Thanks,
    >> Jean-S?bastien Bevilacqua
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Wed Mar 22 14:12:18 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 22 Mar 2017 14:12:18 +0100
Subject: [Rd] Hyperbolic tangent different results on Windows and Mac
In-Reply-To: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
References: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
Message-ID: <CABFfbXu4hWq7JT14u2PYG-b6LCA7btPg2o=iOD2tgUaK48F9ew@mail.gmail.com>

This looks like a bug in mingw-w64 CRT. The problem can be produced
with C++ without R:

  #include <iostream>
  #include <cmath>
  #include <complex>

  int main(){
    std::cout << std::fixed;
    std::complex<double> z(356, 0);
    std::cout << "tanh" << z << " = " << std::tanh(z)
         << " (tanh(356) = " << std::tanh(356) << ")\n";
  }

On OS-X we get:

  tanh(356.000000,0.000000) = (1.000000,-0.000000) (tanh(356) = 1.000000)

But on Windows we get:

  tanh(356.000000,0.000000) = (nan,0.000000) (tanh(356) = 1.000000)

I was also able to reproduce the problem with gcc 6.3 in msys2 so it
has not been fixed upstream. You should file a bug report for
mingw-w64.

FWIF, we have run into NaN edge-case bugs before with mingw-w64.

 - https://sourceforge.net/p/mingw-w64/mingw-w64/ci/6617ebd5fc6b790c80071d5b1d950e737fc670e1/
 - https://github.com/wch/r-source/commit/e9aaf8fdeddf27c2a9078cd214a41475c8ff6f40

I am cc'ing Ray Donnelly who is an expert on mingw-w64.


From h.wickham at gmail.com  Wed Mar 22 16:38:33 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 23 Mar 2017 04:38:33 +1300
Subject: [Rd] RFC: (in-principle) native unquoting for standard
	evaluation
In-Reply-To: <CABdHhvHttoH7yNTG7bj=nKdfRd1c2yukDWaovqid+PfT6+yHMA@mail.gmail.com>
References: <mailman.9.1489921202.31343.r-devel@r-project.org>
	<20170319183610.GA26048@mail.cs.toronto.edu>
	<CABdHhvHttoH7yNTG7bj=nKdfRd1c2yukDWaovqid+PfT6+yHMA@mail.gmail.com>
Message-ID: <CABdHhvFcwMZBw1v8q47rCCU=kLZ9mCFQXoXC45K91LLOcrRXHQ@mail.gmail.com>

On Mon, Mar 20, 2017 at 8:00 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> On Mon, Mar 20, 2017 at 7:36 AM, Radford Neal <radford at cs.toronto.edu> wrote:
>> Michael Lawrence (as last in long series of posters)...
>>
>>> Yes, it would bind the language object to the environment, like an
>>> R-level promise (but "promise" of course refers specifically to just
>>> _lazy_ evaluation).
>>>
>>> For the uqs() thing, expanding calls like that is somewhat orthogonal
>>> to NSE. It would be nice in general to be able to write something like
>>> mean(x, extra_args...) without resorting to do.call(mean, c(list(x),
>>> extra_args)). If we had that then uqs() would just be the combination
>>> of unquote and expansion, i.e., mean(x, @extra_args...). The "..."
>>> postfix would not work since it's still a valid symbol name, but we
>>> could come up with something.
>>
>>
>> I've been trying to follow this proposal, though without tracking down
>> all the tweets, etc. that are referenced.  I suspect I'm not the only
>> reader who isn't clear exactly what is being proposed.  I think a
>> detailed, self-contained proposal would be useful.
>
> We have a working implementation (which I'm calling tidyeval) in
> https://github.com/hadley/rlang, but we have yet to write it up. We'll
> spend some time documenting since it seems to be of broader interest.

First pass at programming dplyr vignette (including details about tidyeval) at
http://rpubs.com/hadley/dplyr-programming

Hadley

-- 
http://hadley.nz


From plummerm at iarc.fr  Wed Mar 22 19:18:55 2017
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 22 Mar 2017 18:18:55 +0000
Subject: [Rd] Experimental CXX_STD problem in R 3.4
In-Reply-To: <CABFfbXv93rUEbd2wzBiMDmWP0XK5FCuT4iNijr3o1dNwPn7ezQ@mail.gmail.com>
References: <CABFfbXuox21GEDFMVAwzrHYbodRo3+eWAacz7dyRqnudMkPnrQ@mail.gmail.com>
	<22733.19068.582932.665707@max.eddelbuettel.com>
	<1489954147228.25309@iarc.fr>
	<CABFfbXv93rUEbd2wzBiMDmWP0XK5FCuT4iNijr3o1dNwPn7ezQ@mail.gmail.com>
Message-ID: <1490206734.29354.65.camel@iarc.fr>

On Mon, 2017-03-20 at 16:38 +0100, Jeroen Ooms wrote:
> On Sun, Mar 19, 2017 at 9:09 PM, Martyn Plummer <plummerm at iarc.fr>
> wrote:
> > I have just added some code to ensure that the compilation fails
> > with an informative error message if a specific C++ standard is
> > requested but the corresponding compiler has not been defined.
> > Please test this.
> 
> Are you sure we shouldn't just fall back on a previous standard
> instead of failing? For example if the package author has specified a
> preference for CXX14 but the compiler only has CXX11, the package
> might still build with -std=c++11 (given that C++14 is only a small
> extension on the C++11 standard).
> 
> The current behavior (in R 3.3) for packages with "CXX_STD=CXX11" is
> to fall back on CXX when the compiler does not have CXX1X. 

I don't think that is true.

> Will R-3.4
> start failing these packages? This would affect many users on CentOS 6
> (gcc 4.4.7).

The major issue with long-term support platforms like CentOS is that
the compiler is rather old. According to the GCC web site, 4.4.7 has
partial support for C++11 via the -std=c++0x flag ( https://gcc.gnu.org
/projects/cxx-status.html#cxx11 ). The problem is that the tests for
C++11 compliance used by R's configure script have become much more
stringent. If g++ 4.4.7 passed before, it is unlikely to pass now. This
is an issue that I discussed here.

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17189

This creates a regression on older platforms. Some packages that used
only a few C++11 features used to compile correctly but now don't
because the compiler is no longer recognized as conforming to the C++11
standard (and to be fair it never did but the previous tests were
weaker).

What I suggest is that on these platforms you do a post-install patch
of etc/Makeconf and set the variables for the C++11 compiler manually
(CXX11, CXX11FLAGS, CXX11PICFLAGS, CXX11STD, SHLIB_CXX11LD,
SHLIB_CXX11LDFLAGS).

Martyn

From lionel at rstudio.com  Wed Mar 22 20:06:52 2017
From: lionel at rstudio.com (Lionel Henry)
Date: Wed, 22 Mar 2017 20:06:52 +0100
Subject: [Rd] RFC: (in-principle) native unquoting for standard evaluation
In-Reply-To: <20170319183610.GA26048@mail.cs.toronto.edu>
References: <mailman.9.1489921202.31343.r-devel@r-project.org>
	<20170319183610.GA26048@mail.cs.toronto.edu>
Message-ID: <99be949c-16b8-685d-91f0-54afc9ff1566@rstudio.com>


RN> There is an opportunity cost to grabbing the presently-unused unary @
RN> operator for this

I don't think this is the case because the parser has to interpret `@`
in formal argument lists in a different way than in function calls.
Besides, it'd make sense to set up these annotations with a binary
`@`. There are already two main ways of passing arguments in R: by
value and by expression. Providing an explicit annotation for passing
by expression would standardise the semantics of these functions and,
as Michael suggests, would help static analysis. So passing by name
could be just another argument-passing method:

    function(expr@ x, value@ y = 10L, name@ z = rnorm(1)) {
      list(x, y, z, z)
    }

The parser would record the argument metadata in the formals list.
This metadata could be consulted by static analysis tools and a
selected subset of those tags (`expr` and `name`) would have an effect
on the evaluation mechanism.


RN> One thing I'm not clear on is whether the proposal would add anything
RN> semantically beyond what the present "eval" and "substitute" functions
RN> can do fairly easily.

Quasiquotation makes it possible to program with functions that take
arguments by expression. There is no easy way to do that with
eval() and substitute() alone. R has always been an interface language
and as such, its main advantage is to provide DSLs for data analysis
tasks. Specification of statistical models with a formula, overscoping
data frame columns with subset() and transform(), etc. This is why
providing an easier means of programming with these functions seems to
have more value than call-by-name semantics. Unquoting will be used
extensively in ggplot2 and dplyr, two popular R packages.  Please see
the vignette posted by Hadley for some introductory examples.

In any case, the unquoting notation would be orthogonal to function
arguments annotations because actuals and formals are parsed
differently. While formals annotations would be recorded by the parser
in the formals list, `@` in an actual argument list would be parsed as
a function call, like the rest of R operators.

Lionel


From lionel at rstudio.com  Wed Mar 22 20:17:39 2017
From: lionel at rstudio.com (Lionel Henry)
Date: Wed, 22 Mar 2017 20:17:39 +0100
Subject: [Rd] RFC: (in-principle) native unquoting for standard evaluation
In-Reply-To: <CAOQ5NyeF8fDYGwES0sy5eQfgFriK4Hos7vqX9R2YxkLgTPrhmg@mail.gmail.com>
References: <CAAjDRii1dPxNMTn9TSgReooOry2omQg9GCmXYDDFc99qv=F+7A@mail.gmail.com>
	<CAOQ5NydWHiqHkTVc=DHiQgqVkVqnoUN35EZYyQTwMJCWkap42A@mail.gmail.com>
	<CABdHhvFsgRMN0tFZTB6q1dbS7AHDbN_+BP_SU+QXL9ap94WFfQ@mail.gmail.com>
	<CAOQ5NyeF8fDYGwES0sy5eQfgFriK4Hos7vqX9R2YxkLgTPrhmg@mail.gmail.com>
Message-ID: <90626317-e7be-d3f3-5194-99fc714b5348@rstudio.com>

ML> For the uqs() thing, expanding calls like that is somewhat orthogonal
ML> to NSE. It would be nice in general to be able to write something like
ML> mean(x, extra_args...) without resorting to do.call(mean, c(list(x),
ML> extra_args)).

This is not completely true because splicing is necessarily linked to
the principle of unquoting (evaluating). You cannot splice something
that you don't know the value of, you have to evaluate the promise of
the splicing operand. In other words, you cannot splice at the parser
level, only at the interpreter level, and the splicing operation has
to be part of the call tree. This implies the important limitation
that you cannot splice a list in a call to a function taking named
arguments, you can only splice when capturing dots. On the plus side,
it seems more R-like to implement it as a regular function call since
all syntactic operations in R are function calls.

Since splicing is conceptually linked to unquoting, I think it would
make sense to have a derivative operator, e.g. @@. In that case it
would simply take its argument by expression and could thus be defined
as:

     `@@` <- `~`.

It'd be used like this:

     # Equivalent to as.list(mtcars)
     list(@@ mtcars)

     # Returns a list of symbols
     list(@@ lapply(letters, as.symbol))

To make it work we'd have two functions for capturing dots that would
understand arguments wrapped in an `@@` quosure. dotsValues(...)
would expand spliced arguments and then evaluate them, while
dotsExprs(...)  would expand and return a list of quosures. Dotted
primitive functions like list() or c() would also need to preprocess
the dots with a C function.

Another reason not to use `...` as syntax for splicing is that it may
be better to reserve it for forwarding operations. I think one other
syntax update that would be worthwile to consider is forwarding of
named arguments. This would allow labelling of arguments to work
transparently across wrappers:

     my_plot <- function(x) plot(1:10, ...(x))

     # The y axis is correctly labelled as 11:20 in the plot
     my_plot(11:20)

And this would also allow to forward named arguments to functions
taking their arguments by expression, just like we forward dots.

Lionel


From MMa at mdanderson.org  Thu Mar 23 20:29:25 2017
From: MMa at mdanderson.org (Ma,Man Chun John)
Date: Thu, 23 Mar 2017 19:29:25 +0000
Subject: [Rd] A question on stats::as.hclust.dendrogram
Message-ID: <6B798A745F130A4DBED27B850427CFF9A474C7@D1PWPEXMBX06.mdanderson.edu>

Hi all,

This is the first time I'm writing to R-devel, and this time I'm just asking for the purpose for a certain line of code in stats::as.hclust.dendrogram, which comes up as I'm trying to fix dendextend.

The line in question is at line 128 of dendrogram.R in R-3.3.3, at stats::as.hclust.dendrogram:

stopifnot(length(s) == 2L, all( vapply(s, is.integer, NA) ))

Is there any legitimate possibility that s is a nested list? Currently I have a case where a dendrogram object is breaks at this line, because s is a nested list:

>str (s)
List of 2
$ : int -779
$ :List of 2
  ..$ : int -625
  ..$ : int 15

I'm unsure if my dendrogram was malformed in the first place, since I was trying to use dendrapply.

So, my question is: for that particular check, why use

stopifnot(length(s) == 2L, all( vapply(s, is.integer, NA) ))

instead of

stopifnot(length(s) == 2L, all( vapply(unlist(s), is.integer, NA) ))?

I appreciate your time and I'm looking forward to your response.

Cheers,

Man Chun John Ma, PhD
Postdoctoral Fellow
Unit 0903
Dept Lymphoma & Myeloma Research
1515 Holcombe Blvd.
Houston, TX 77030
MMa at mdanderson.org

The information contained in this e-mail message may be ...{{dropped:14}}


From maechler at stat.math.ethz.ch  Fri Mar 24 13:38:39 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Mar 2017 13:38:39 +0100
Subject: [Rd] A question on stats::as.hclust.dendrogram
In-Reply-To: <6B798A745F130A4DBED27B850427CFF9A474C7@D1PWPEXMBX06.mdanderson.edu>
References: <6B798A745F130A4DBED27B850427CFF9A474C7@D1PWPEXMBX06.mdanderson.edu>
Message-ID: <22741.4943.74987.560468@stat.math.ethz.ch>

>>>>> Ma,Man Chun John <MMa at mdanderson.org>
>>>>>     on Thu, 23 Mar 2017 19:29:25 +0000 writes:

    > Hi all,
    > This is the first time I'm writing to R-devel, and this time I'm just asking for the purpose for a certain line of code in stats::as.hclust.dendrogram, which comes up as I'm trying to fix dendextend.

"fix": where is it broken?
Do you mean the fact that in R <= 3.3.3, it is defined via
recursion and hence infeasible for "deep" dendrograms?

In any case, note that  NEWS  for the upcoming version of R,
R 3.4.0  contains 

    ? The str() and as.hclust() methods for "dendrogram" now also work
      for deeply nested dendrograms thanks to non-recursive
      implementations by Bradley Broom.

so the source code of  as.hclust.dendrogram  has been changed
substantially already.

Note that you **NEVER** see the "real" source code of function
by printing it to the console.
The source code is in the source of the corresponding package,
in the case of 'stats', as part of the source code of R.

I.e., here,
 https://svn.r-project.org/R/trunk/src/library/stats/R/dendrogram.R


I think the following question has become irrelevant now,
but yes, dendrograms *are* implemented as nested lists.

Martin Maechler
ETH Zurich and R core team


    > The line in question is at line 128 of dendrogram.R in R-3.3.3, at stats::as.hclust.dendrogram:

    > stopifnot(length(s) == 2L, all( vapply(s, is.integer, NA) ))

    > Is there any legitimate possibility that s is a nested list? Currently I have a case where a dendrogram object is breaks at this line, because s is a nested list:

    >> str (s)
    > List of 2
    > $ : int -779
    > $ :List of 2
    > ..$ : int -625
    > ..$ : int 15

    > I'm unsure if my dendrogram was malformed in the first place, since I was trying to use dendrapply.

    > So, my question is: for that particular check, why use

    > stopifnot(length(s) == 2L, all( vapply(s, is.integer, NA) ))

    > instead of

    > stopifnot(length(s) == 2L, all( vapply(unlist(s), is.integer, NA) ))?

    > I appreciate your time and I'm looking forward to your response.

    > Cheers,

    > Man Chun John Ma, PhD
    > Postdoctoral Fellow
    > Unit 0903
    > Dept Lymphoma & Myeloma Research
    > 1515 Holcombe Blvd.
    > Houston, TX 77030
    > MMa at mdanderson.org

    > The information contained in this e-mail message may be ...{{dropped:14}}

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From mario at emmenlauer.de  Fri Mar 24 14:52:36 2017
From: mario at emmenlauer.de (Mario Emmenlauer)
Date: Fri, 24 Mar 2017 14:52:36 +0100
Subject: [Rd] non-infectious license for R package?
Message-ID: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>


Dear All,

I've been following this mailing list for over three years now, but
its just now that I have realized that R is licensed under GPL! :-)

I'm not a lawyer and I don't want lawyer advice, but I'd like to get
your feedback on a license question. My goal is to develop commercial
software for image analysis of biomedical samples that may be used
i.e. in academic institutions. Since I've been an academic software
developer for long, a priority for me is to make the data and tools
easily accessibly for other developers. I have toyed with the idea to
make a (free) R package that can very efficiently fetch data from the
database and push back results for visualization. To clarify: I am
not using R in my software. I'd rather like the institutions of my
customers to have open (internal) access to their data.

Now for the question: To efficiently get the data into R, I assume a
package (possibly in C or C++) is the most reasonable way? If yes,
would such a package automatically be infected by the GPL? If the
package links to (proprietary closed source) libraries to efficiently
access the data, would the libraries in turn be infected?

I'm asking this very naiively because I understand statement [1] in
such a way that it is generally encouraged to make data available in
R. Obviously open source is the preferred way, but my understanding
is that also closed source extensions can add value and may be
welcome.

I was therefore hoping that somebody has prior experience in this
regard, or can shed further light on statement [1]. Is the R-C-
interface infectious per se, even when data flows only into R, not
vice versa? If its infectious, could just the very core of R be
licensed additionally under a non-infectious license?

Furthermore, can I avoid infecting my full software stack, for example
by making only the package open source under a permissive license? Are
there any guidelines how to legally bridge between the proprietary and
the R-world? I guess other people have tried this before, can someone
share his/her experience?

[1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html

All the best,

    Mario Emmenlauer


From rmcgehee at walleyetrading.net  Fri Mar 24 15:35:56 2017
From: rmcgehee at walleyetrading.net (Robert McGehee)
Date: Fri, 24 Mar 2017 14:35:56 +0000
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
Message-ID: <30D28A63376088428E8318DD67FD407F7263EC@ny-mailstore1.walleyetrading.net>

I have no direct experience in this regard, but this FAQ seems to answer your question. 
https://www.gnu.org/licenses/gpl-faq.en.html#IfInterpreterIsGPL

I read this to mean that the answer may be different depending on whether your code links against R libraries or simply uses R as an interpreter.

PS. "Infect" is an interesting choice of words in your email :)
--Robert

-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Mario Emmenlauer
Sent: Friday, March 24, 2017 9:53 AM
To: r-devel at r-project.org
Subject: [Rd] non-infectious license for R package?


Dear All,

I've been following this mailing list for over three years now, but its just now that I have realized that R is licensed under GPL! :-)

I'm not a lawyer and I don't want lawyer advice, but I'd like to get your feedback on a license question. My goal is to develop commercial software for image analysis of biomedical samples that may be used i.e. in academic institutions. Since I've been an academic software developer for long, a priority for me is to make the data and tools easily accessibly for other developers. I have toyed with the idea to make a (free) R package that can very efficiently fetch data from the database and push back results for visualization. To clarify: I am not using R in my software. I'd rather like the institutions of my customers to have open (internal) access to their data.

Now for the question: To efficiently get the data into R, I assume a package (possibly in C or C++) is the most reasonable way? If yes, would such a package automatically be infected by the GPL? If the package links to (proprietary closed source) libraries to efficiently access the data, would the libraries in turn be infected?

I'm asking this very naiively because I understand statement [1] in such a way that it is generally encouraged to make data available in R. Obviously open source is the preferred way, but my understanding is that also closed source extensions can add value and may be welcome.

I was therefore hoping that somebody has prior experience in this regard, or can shed further light on statement [1]. Is the R-C- interface infectious per se, even when data flows only into R, not vice versa? If its infectious, could just the very core of R be licensed additionally under a non-infectious license?

Furthermore, can I avoid infecting my full software stack, for example by making only the package open source under a permissive license? Are there any guidelines how to legally bridge between the proprietary and the R-world? I guess other people have tried this before, can someone share his/her experience?

[1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html

All the best,

    Mario Emmenlauer

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at me.com  Fri Mar 24 15:44:49 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 24 Mar 2017 09:44:49 -0500
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
Message-ID: <D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>

See inline...

> On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
> 
> 
> Dear All,
> 
> I've been following this mailing list for over three years now, but
> its just now that I have realized that R is licensed under GPL! :-)
> 
> I'm not a lawyer and I don't want lawyer advice, but I'd like to get
> your feedback on a license question.


Hi, 

With the usual IANAL caveat and that I am not speaking on behalf of any other parties:

The questions you are posing will require legal advice, so your desire above to not get legal advice is in direct conflict with what you actually need here.

To your comments below, you cannot change existing licenses on software, R or otherwise. That is only something that the copyright holder(s) can do and you are not one of them.

The GPL has a FAQ here:

  https://www.gnu.org/licenses/gpl-faq.en.html <https://www.gnu.org/licenses/gpl-faq.en.html>

that you may find enlightening.

A very general statement, which is that if your compiled code (in whatever language) does not "link" against R's libraries and does not directly contain GPL licensed code (e.g. copying and pasting R Foundation copyrighted source code into yours), that is one way to steer clear of the viral part of the GPL license vis-a-vis R, if you want to, but not the only way and not a guarantee either. There can be nuances, some of which are covered in the FAQ above.

On the other hand, if your compiled code is linking to R's libraries, which you seem to suggest may be the case below, then your code, at least the relevant parts of it, will need to be licensed under a GPL compatible license.

This again is part of the nuance, in terms of the scope of the impact on your code (all or parts) and where legal advice is needed, to steer clear of downstream potential issues that could result in legal and financial liabilities for you.

The issue of linking to third party proprietary libraries is something that you will have to evaluate with respect to their licenses and any limitations that they may impose on your code and it's licensing.

Since you seem to also be suggesting that you may use closed source components in your package, you should be aware, that vis-a-vis CRAN, you would not be able to submit your package for distribution via that channel, since CRAN submissions may not contain pre-compiled binaries or similar and the entire package must conform to a compatible open source license. Thus, if you go down that path, you would have to find other distribution channels for your package, such as a company web site, etc.

None of the above should be construed as legal advice and if you plan to go down the path of offering a commercial service that you would charge clients for, a lawyer is mandatory to provide legal guidance and to assess your business risks. Even if your actual R related package is offered free of charge, while generating revenue through other means, if you should run afoul of software licensing requirements, that can still leave you open to financial liabilities and put your business and even personal assets at risk.

Regards,

Marc Schwartz


> My goal is to develop commercial
> software for image analysis of biomedical samples that may be used
> i.e. in academic institutions. Since I've been an academic software
> developer for long, a priority for me is to make the data and tools
> easily accessibly for other developers. I have toyed with the idea to
> make a (free) R package that can very efficiently fetch data from the
> database and push back results for visualization. To clarify: I am
> not using R in my software. I'd rather like the institutions of my
> customers to have open (internal) access to their data.
> 
> Now for the question: To efficiently get the data into R, I assume a
> package (possibly in C or C++) is the most reasonable way? If yes,
> would such a package automatically be infected by the GPL? If the
> package links to (proprietary closed source) libraries to efficiently
> access the data, would the libraries in turn be infected?
> 
> I'm asking this very naiively because I understand statement [1] in
> such a way that it is generally encouraged to make data available in
> R. Obviously open source is the preferred way, but my understanding
> is that also closed source extensions can add value and may be
> welcome.
> 
> I was therefore hoping that somebody has prior experience in this
> regard, or can shed further light on statement [1]. Is the R-C-
> interface infectious per se, even when data flows only into R, not
> vice versa? If its infectious, could just the very core of R be
> licensed additionally under a non-infectious license?
> 
> Furthermore, can I avoid infecting my full software stack, for example
> by making only the package open source under a permissive license? Are
> there any guidelines how to legally bridge between the proprietary and
> the R-world? I guess other people have tried this before, can someone
> share his/her experience?
> 
> [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
> 
> All the best,
> 
>    Mario Emmenlauer
> 

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Fri Mar 24 16:14:17 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 24 Mar 2017 16:14:17 +0100
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
Message-ID: <CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>

My humble 2 nonlegal cents:

There are multiple packages that make the link between R and proprietary
software. One example is R2WinBUGS which connects to WinBUGS, but there are
a lot more of these.

All of these use essentially the same idea:
- create the package under a standard GPL license
- use the (command line) interface provided by the proprietary software to
connect with it, eg by calls to sytem(). That's exaclty how R2WinBUGS
operates. It doesn't contain a single closed source library to achieve
this, all those are kept within WinBUGS itself.

So taking the route others took before you seems the way forward to me.

Cheers
Joris

On Fri, Mar 24, 2017 at 3:44 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> See inline...
>
> > On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de>
> wrote:
> >
> >
> > Dear All,
> >
> > I've been following this mailing list for over three years now, but
> > its just now that I have realized that R is licensed under GPL! :-)
> >
> > I'm not a lawyer and I don't want lawyer advice, but I'd like to get
> > your feedback on a license question.
>
>
> Hi,
>
> With the usual IANAL caveat and that I am not speaking on behalf of any
> other parties:
>
> The questions you are posing will require legal advice, so your desire
> above to not get legal advice is in direct conflict with what you actually
> need here.
>
> To your comments below, you cannot change existing licenses on software, R
> or otherwise. That is only something that the copyright holder(s) can do
> and you are not one of them.
>
> The GPL has a FAQ here:
>
>   https://www.gnu.org/licenses/gpl-faq.en.html <
> https://www.gnu.org/licenses/gpl-faq.en.html>
>
> that you may find enlightening.
>
> A very general statement, which is that if your compiled code (in whatever
> language) does not "link" against R's libraries and does not directly
> contain GPL licensed code (e.g. copying and pasting R Foundation
> copyrighted source code into yours), that is one way to steer clear of the
> viral part of the GPL license vis-a-vis R, if you want to, but not the only
> way and not a guarantee either. There can be nuances, some of which are
> covered in the FAQ above.
>
> On the other hand, if your compiled code is linking to R's libraries,
> which you seem to suggest may be the case below, then your code, at least
> the relevant parts of it, will need to be licensed under a GPL compatible
> license.
>
> This again is part of the nuance, in terms of the scope of the impact on
> your code (all or parts) and where legal advice is needed, to steer clear
> of downstream potential issues that could result in legal and financial
> liabilities for you.
>
> The issue of linking to third party proprietary libraries is something
> that you will have to evaluate with respect to their licenses and any
> limitations that they may impose on your code and it's licensing.
>
> Since you seem to also be suggesting that you may use closed source
> components in your package, you should be aware, that vis-a-vis CRAN, you
> would not be able to submit your package for distribution via that channel,
> since CRAN submissions may not contain pre-compiled binaries or similar and
> the entire package must conform to a compatible open source license. Thus,
> if you go down that path, you would have to find other distribution
> channels for your package, such as a company web site, etc.
>
> None of the above should be construed as legal advice and if you plan to
> go down the path of offering a commercial service that you would charge
> clients for, a lawyer is mandatory to provide legal guidance and to assess
> your business risks. Even if your actual R related package is offered free
> of charge, while generating revenue through other means, if you should run
> afoul of software licensing requirements, that can still leave you open to
> financial liabilities and put your business and even personal assets at
> risk.
>
> Regards,
>
> Marc Schwartz
>
>
> > My goal is to develop commercial
> > software for image analysis of biomedical samples that may be used
> > i.e. in academic institutions. Since I've been an academic software
> > developer for long, a priority for me is to make the data and tools
> > easily accessibly for other developers. I have toyed with the idea to
> > make a (free) R package that can very efficiently fetch data from the
> > database and push back results for visualization. To clarify: I am
> > not using R in my software. I'd rather like the institutions of my
> > customers to have open (internal) access to their data.
> >
> > Now for the question: To efficiently get the data into R, I assume a
> > package (possibly in C or C++) is the most reasonable way? If yes,
> > would such a package automatically be infected by the GPL? If the
> > package links to (proprietary closed source) libraries to efficiently
> > access the data, would the libraries in turn be infected?
> >
> > I'm asking this very naiively because I understand statement [1] in
> > such a way that it is generally encouraged to make data available in
> > R. Obviously open source is the preferred way, but my understanding
> > is that also closed source extensions can add value and may be
> > welcome.
> >
> > I was therefore hoping that somebody has prior experience in this
> > regard, or can shed further light on statement [1]. Is the R-C-
> > interface infectious per se, even when data flows only into R, not
> > vice versa? If its infectious, could just the very core of R be
> > licensed additionally under a non-infectious license?
> >
> > Furthermore, can I avoid infecting my full software stack, for example
> > by making only the package open source under a permissive license? Are
> > there any guidelines how to legally bridge between the proprietary and
> > the R-world? I guess other people have tried this before, can someone
> > share his/her experience?
> >
> > [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
> >
> > All the best,
> >
> >    Mario Emmenlauer
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From carlganz at ucla.edu  Fri Mar 24 16:21:34 2017
From: carlganz at ucla.edu (Ganz, Carl)
Date: Fri, 24 Mar 2017 15:21:34 +0000
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>
Message-ID: <A5A30F1D451F924B902DDE8063410E6713763B@EM1A.ad.ucla.edu>

There are also packages like highcharter, which package proprietary software without a license, but it is incumbent on the user to respect the license of the underlying library. 

-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Joris Meys
Sent: Friday, March 24, 2017 8:14 AM
To: Marc Schwartz
Cc: R-Devel
Subject: Re: [Rd] non-infectious license for R package?

My humble 2 nonlegal cents:

There are multiple packages that make the link between R and proprietary software. One example is R2WinBUGS which connects to WinBUGS, but there are a lot more of these.

All of these use essentially the same idea:
- create the package under a standard GPL license
- use the (command line) interface provided by the proprietary software to connect with it, eg by calls to sytem(). That's exaclty how R2WinBUGS operates. It doesn't contain a single closed source library to achieve this, all those are kept within WinBUGS itself.

So taking the route others took before you seems the way forward to me.

Cheers
Joris

On Fri, Mar 24, 2017 at 3:44 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> See inline...
>
> > On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de>
> wrote:
> >
> >
> > Dear All,
> >
> > I've been following this mailing list for over three years now, but 
> > its just now that I have realized that R is licensed under GPL! :-)
> >
> > I'm not a lawyer and I don't want lawyer advice, but I'd like to get 
> > your feedback on a license question.
>
>
> Hi,
>
> With the usual IANAL caveat and that I am not speaking on behalf of 
> any other parties:
>
> The questions you are posing will require legal advice, so your desire 
> above to not get legal advice is in direct conflict with what you 
> actually need here.
>
> To your comments below, you cannot change existing licenses on 
> software, R or otherwise. That is only something that the copyright 
> holder(s) can do and you are not one of them.
>
> The GPL has a FAQ here:
>
>   https://www.gnu.org/licenses/gpl-faq.en.html < 
> https://www.gnu.org/licenses/gpl-faq.en.html>
>
> that you may find enlightening.
>
> A very general statement, which is that if your compiled code (in 
> whatever
> language) does not "link" against R's libraries and does not directly 
> contain GPL licensed code (e.g. copying and pasting R Foundation 
> copyrighted source code into yours), that is one way to steer clear of 
> the viral part of the GPL license vis-a-vis R, if you want to, but not 
> the only way and not a guarantee either. There can be nuances, some of 
> which are covered in the FAQ above.
>
> On the other hand, if your compiled code is linking to R's libraries, 
> which you seem to suggest may be the case below, then your code, at 
> least the relevant parts of it, will need to be licensed under a GPL 
> compatible license.
>
> This again is part of the nuance, in terms of the scope of the impact 
> on your code (all or parts) and where legal advice is needed, to steer 
> clear of downstream potential issues that could result in legal and 
> financial liabilities for you.
>
> The issue of linking to third party proprietary libraries is something 
> that you will have to evaluate with respect to their licenses and any 
> limitations that they may impose on your code and it's licensing.
>
> Since you seem to also be suggesting that you may use closed source 
> components in your package, you should be aware, that vis-a-vis CRAN, 
> you would not be able to submit your package for distribution via that 
> channel, since CRAN submissions may not contain pre-compiled binaries 
> or similar and the entire package must conform to a compatible open 
> source license. Thus, if you go down that path, you would have to find 
> other distribution channels for your package, such as a company web site, etc.
>
> None of the above should be construed as legal advice and if you plan 
> to go down the path of offering a commercial service that you would 
> charge clients for, a lawyer is mandatory to provide legal guidance 
> and to assess your business risks. Even if your actual R related 
> package is offered free of charge, while generating revenue through 
> other means, if you should run afoul of software licensing 
> requirements, that can still leave you open to financial liabilities 
> and put your business and even personal assets at risk.
>
> Regards,
>
> Marc Schwartz
>
>
> > My goal is to develop commercial
> > software for image analysis of biomedical samples that may be used 
> > i.e. in academic institutions. Since I've been an academic software 
> > developer for long, a priority for me is to make the data and tools 
> > easily accessibly for other developers. I have toyed with the idea 
> > to make a (free) R package that can very efficiently fetch data from 
> > the database and push back results for visualization. To clarify: I 
> > am not using R in my software. I'd rather like the institutions of 
> > my customers to have open (internal) access to their data.
> >
> > Now for the question: To efficiently get the data into R, I assume a 
> > package (possibly in C or C++) is the most reasonable way? If yes, 
> > would such a package automatically be infected by the GPL? If the 
> > package links to (proprietary closed source) libraries to 
> > efficiently access the data, would the libraries in turn be infected?
> >
> > I'm asking this very naiively because I understand statement [1] in 
> > such a way that it is generally encouraged to make data available in 
> > R. Obviously open source is the preferred way, but my understanding 
> > is that also closed source extensions can add value and may be 
> > welcome.
> >
> > I was therefore hoping that somebody has prior experience in this 
> > regard, or can shed further light on statement [1]. Is the R-C- 
> > interface infectious per se, even when data flows only into R, not 
> > vice versa? If its infectious, could just the very core of R be 
> > licensed additionally under a non-infectious license?
> >
> > Furthermore, can I avoid infecting my full software stack, for 
> > example by making only the package open source under a permissive 
> > license? Are there any guidelines how to legally bridge between the 
> > proprietary and the R-world? I guess other people have tried this 
> > before, can someone share his/her experience?
> >
> > [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
> >
> > All the best,
> >
> >    Mario Emmenlauer
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



--
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Fri Mar 24 17:04:45 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 24 Mar 2017 17:04:45 +0100
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <A5A30F1D451F924B902DDE8063410E6713763B@EM1A.ad.ucla.edu>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>
	<A5A30F1D451F924B902DDE8063410E6713763B@EM1A.ad.ucla.edu>
Message-ID: <CAO1zAVaQ0FSMZKSGCbOT0znuuNKin-hq9Zm_pKPZOP4RBiVm0g@mail.gmail.com>

The key difference being that while not under the GPL, highcharter is still
open source. There isn't a single compiled library in the entire package.
WinBUGS otoh is closed source (although there is an open source version of
it, OpenBUGS). As far as I understood, CRAN doesn't accept packages
containing any binary executable code without the proper source files
attached. So including the closed source libraries as Mario wanted to do,
is not accepted on CRAN.

https://cran.r-project.org/web/packages/policies.html#Source-packages

On a sidenote: I'm not a legal expert, and I might have been misusing the
term "proprietary software" where I should've written "closed source". My
apologies if I confused anybody doing so.

Cheers

On Fri, Mar 24, 2017 at 4:21 PM, Ganz, Carl <carlganz at ucla.edu> wrote:

> There are also packages like highcharter, which package proprietary
> software without a license, but it is incumbent on the user to respect the
> license of the underlying library.
>
> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Joris
> Meys
> Sent: Friday, March 24, 2017 8:14 AM
> To: Marc Schwartz
> Cc: R-Devel
> Subject: Re: [Rd] non-infectious license for R package?
>
> My humble 2 nonlegal cents:
>
> There are multiple packages that make the link between R and proprietary
> software. One example is R2WinBUGS which connects to WinBUGS, but there are
> a lot more of these.
>
> All of these use essentially the same idea:
> - create the package under a standard GPL license
> - use the (command line) interface provided by the proprietary software to
> connect with it, eg by calls to sytem(). That's exaclty how R2WinBUGS
> operates. It doesn't contain a single closed source library to achieve
> this, all those are kept within WinBUGS itself.
>
> So taking the route others took before you seems the way forward to me.
>
> Cheers
> Joris
>
> On Fri, Mar 24, 2017 at 3:44 PM, Marc Schwartz <marc_schwartz at me.com>
> wrote:
>
> > See inline...
> >
> > > On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de>
> > wrote:
> > >
> > >
> > > Dear All,
> > >
> > > I've been following this mailing list for over three years now, but
> > > its just now that I have realized that R is licensed under GPL! :-)
> > >
> > > I'm not a lawyer and I don't want lawyer advice, but I'd like to get
> > > your feedback on a license question.
> >
> >
> > Hi,
> >
> > With the usual IANAL caveat and that I am not speaking on behalf of
> > any other parties:
> >
> > The questions you are posing will require legal advice, so your desire
> > above to not get legal advice is in direct conflict with what you
> > actually need here.
> >
> > To your comments below, you cannot change existing licenses on
> > software, R or otherwise. That is only something that the copyright
> > holder(s) can do and you are not one of them.
> >
> > The GPL has a FAQ here:
> >
> >   https://www.gnu.org/licenses/gpl-faq.en.html <
> > https://www.gnu.org/licenses/gpl-faq.en.html>
> >
> > that you may find enlightening.
> >
> > A very general statement, which is that if your compiled code (in
> > whatever
> > language) does not "link" against R's libraries and does not directly
> > contain GPL licensed code (e.g. copying and pasting R Foundation
> > copyrighted source code into yours), that is one way to steer clear of
> > the viral part of the GPL license vis-a-vis R, if you want to, but not
> > the only way and not a guarantee either. There can be nuances, some of
> > which are covered in the FAQ above.
> >
> > On the other hand, if your compiled code is linking to R's libraries,
> > which you seem to suggest may be the case below, then your code, at
> > least the relevant parts of it, will need to be licensed under a GPL
> > compatible license.
> >
> > This again is part of the nuance, in terms of the scope of the impact
> > on your code (all or parts) and where legal advice is needed, to steer
> > clear of downstream potential issues that could result in legal and
> > financial liabilities for you.
> >
> > The issue of linking to third party proprietary libraries is something
> > that you will have to evaluate with respect to their licenses and any
> > limitations that they may impose on your code and it's licensing.
> >
> > Since you seem to also be suggesting that you may use closed source
> > components in your package, you should be aware, that vis-a-vis CRAN,
> > you would not be able to submit your package for distribution via that
> > channel, since CRAN submissions may not contain pre-compiled binaries
> > or similar and the entire package must conform to a compatible open
> > source license. Thus, if you go down that path, you would have to find
> > other distribution channels for your package, such as a company web
> site, etc.
> >
> > None of the above should be construed as legal advice and if you plan
> > to go down the path of offering a commercial service that you would
> > charge clients for, a lawyer is mandatory to provide legal guidance
> > and to assess your business risks. Even if your actual R related
> > package is offered free of charge, while generating revenue through
> > other means, if you should run afoul of software licensing
> > requirements, that can still leave you open to financial liabilities
> > and put your business and even personal assets at risk.
> >
> > Regards,
> >
> > Marc Schwartz
> >
> >
> > > My goal is to develop commercial
> > > software for image analysis of biomedical samples that may be used
> > > i.e. in academic institutions. Since I've been an academic software
> > > developer for long, a priority for me is to make the data and tools
> > > easily accessibly for other developers. I have toyed with the idea
> > > to make a (free) R package that can very efficiently fetch data from
> > > the database and push back results for visualization. To clarify: I
> > > am not using R in my software. I'd rather like the institutions of
> > > my customers to have open (internal) access to their data.
> > >
> > > Now for the question: To efficiently get the data into R, I assume a
> > > package (possibly in C or C++) is the most reasonable way? If yes,
> > > would such a package automatically be infected by the GPL? If the
> > > package links to (proprietary closed source) libraries to
> > > efficiently access the data, would the libraries in turn be infected?
> > >
> > > I'm asking this very naiively because I understand statement [1] in
> > > such a way that it is generally encouraged to make data available in
> > > R. Obviously open source is the preferred way, but my understanding
> > > is that also closed source extensions can add value and may be
> > > welcome.
> > >
> > > I was therefore hoping that somebody has prior experience in this
> > > regard, or can shed further light on statement [1]. Is the R-C-
> > > interface infectious per se, even when data flows only into R, not
> > > vice versa? If its infectious, could just the very core of R be
> > > licensed additionally under a non-infectious license?
> > >
> > > Furthermore, can I avoid infecting my full software stack, for
> > > example by making only the package open source under a permissive
> > > license? Are there any guidelines how to legally bridge between the
> > > proprietary and the R-world? I guess other people have tried this
> > > before, can someone share his/her experience?
> > >
> > > [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
> > >
> > > All the best,
> > >
> > >    Mario Emmenlauer
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Mar 24 17:24:07 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Mar 2017 11:24:07 -0500
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <CAO1zAVaQ0FSMZKSGCbOT0znuuNKin-hq9Zm_pKPZOP4RBiVm0g@mail.gmail.com>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>
	<A5A30F1D451F924B902DDE8063410E6713763B@EM1A.ad.ucla.edu>
	<CAO1zAVaQ0FSMZKSGCbOT0znuuNKin-hq9Zm_pKPZOP4RBiVm0g@mail.gmail.com>
Message-ID: <22741.18471.645186.736817@max.eddelbuettel.com>


On 24 March 2017 at 17:04, Joris Meys wrote:
| attached. So including the closed source libraries as Mario wanted to do,
| is not accepted on CRAN.

He never said he wanted to upload to CRAN.

He asked whether he can use the open source work in his closed source product.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jorismeys at gmail.com  Fri Mar 24 17:31:40 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 24 Mar 2017 17:31:40 +0100
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <22741.18471.645186.736817@max.eddelbuettel.com>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<CAO1zAVYLbCN_DyUnFUvUWDVUmxUgXfs4JqV5DQ1A4bu2_WLMew@mail.gmail.com>
	<A5A30F1D451F924B902DDE8063410E6713763B@EM1A.ad.ucla.edu>
	<CAO1zAVaQ0FSMZKSGCbOT0znuuNKin-hq9Zm_pKPZOP4RBiVm0g@mail.gmail.com>
	<22741.18471.645186.736817@max.eddelbuettel.com>
Message-ID: <CAO1zAVbAFmiF40Y7FsL3mLPuLjM4jCpGoQjUETdKvcsCR9A+dQ@mail.gmail.com>

On Fri, Mar 24, 2017 at 5:24 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 24 March 2017 at 17:04, Joris Meys wrote:
> | attached. So including the closed source libraries as Mario wanted to do,
> | is not accepted on CRAN.
>
> He never said he wanted to upload to CRAN.
>
> He asked whether he can use the open source work in his closed source
> product.
>

He actually asked "Are there any guidelines how to legally bridge between
the proprietary and the R-world? "

For me CRAN is a rather important part of the R world, especially when you
want your software to be used in the academic world.
So I thought it would be useful to add that information to the other
valuable information given by others.

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Mar 24 22:41:21 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 24 Mar 2017 21:41:21 +0000
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
Message-ID: <CAAcGz99O5eC=EW=ND9fGxtDAmV+60dCDr6vcWVWexCVzH_5a3g@mail.gmail.com>

Have the lawyers look at Microsoft R, it seems the license is not very
catching ultimately.

Perhaps you could use a similar ruse, or even align to that project instead.

Cheers, Mike

On Sat, Mar 25, 2017, 00:54 Mario Emmenlauer <mario at emmenlauer.de> wrote:

>
> Dear All,
>
> I've been following this mailing list for over three years now, but
> its just now that I have realized that R is licensed under GPL! :-)
>
> I'm not a lawyer and I don't want lawyer advice, but I'd like to get
> your feedback on a license question. My goal is to develop commercial
> software for image analysis of biomedical samples that may be used
> i.e. in academic institutions. Since I've been an academic software
> developer for long, a priority for me is to make the data and tools
> easily accessibly for other developers. I have toyed with the idea to
> make a (free) R package that can very efficiently fetch data from the
> database and push back results for visualization. To clarify: I am
> not using R in my software. I'd rather like the institutions of my
> customers to have open (internal) access to their data.
>
> Now for the question: To efficiently get the data into R, I assume a
> package (possibly in C or C++) is the most reasonable way? If yes,
> would such a package automatically be infected by the GPL? If the
> package links to (proprietary closed source) libraries to efficiently
> access the data, would the libraries in turn be infected?
>
> I'm asking this very naiively because I understand statement [1] in
> such a way that it is generally encouraged to make data available in
> R. Obviously open source is the preferred way, but my understanding
> is that also closed source extensions can add value and may be
> welcome.
>
> I was therefore hoping that somebody has prior experience in this
> regard, or can shed further light on statement [1]. Is the R-C-
> interface infectious per se, even when data flows only into R, not
> vice versa? If its infectious, could just the very core of R be
> licensed additionally under a non-infectious license?
>
> Furthermore, can I avoid infecting my full software stack, for example
> by making only the package open source under a permissive license? Are
> there any guidelines how to legally bridge between the proprietary and
> the R-world? I guess other people have tried this before, can someone
> share his/her experience?
>
> [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
>
> All the best,
>
>     Mario Emmenlauer
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From stephen.politzerahles at polyu.edu.hk  Sat Mar 25 00:39:46 2017
From: stephen.politzerahles at polyu.edu.hk (POLITZER-AHLES, Stephen [CBS])
Date: Fri, 24 Mar 2017 23:39:46 +0000
Subject: [Rd] Error in documentation for ?legend
Message-ID: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>

To whom it may concern:


The help page for ?legend refers to a `title.cex` parameter, which suggests that the function has such a parameter. As far as I can tell, though, it doesn't; here's an example:


> plot(1,1)
> legend("topright",pch=1, legend="something", title="my legend", title.cex=2)
Error in legend("topright", pch = 1, legend = "something", title = "my legend",  :
  unused argument (title.cex = 2)


This issue appears to have been discussed online before (e.g. here's a post from 2011 mentioning it: http://r.789695.n4.nabble.com/Change-the-text-size-of-the-title-in-a-legend-of-a-R-plot-td3482880.html) but I'm not sure if anyone ever reported it to R developers.


Is it possible for someone to update the ?legend documentation page so that it doens't refer to a parameter that isn't usable?


Best,

Steve Politzer-Ahles


---
Stephen Politzer-Ahles
The Hong Kong Polytechnic University
Department of Chinese and Bilingual Studies
http://www.mypolyuweb.hk/~sjpolit/<http://www.mypolyuweb.hk/%7Esjpolit/>


[http://mlm.polyu.edu.hk/PolyU80_Email_Signature.png]

www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary>

Disclaimer:\ \ This message (including any attachments) ...{{dropped:19}}


From pdalgd at gmail.com  Sat Mar 25 14:10:57 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 25 Mar 2017 14:10:57 +0100
Subject: [Rd] Error in documentation for ?legend
In-Reply-To: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>
References: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>
Message-ID: <F5449896-4994-4C28-8F32-FBE529D1C239@gmail.com>


> On 25 Mar 2017, at 00:39 , POLITZER-AHLES, Stephen [CBS] <stephen.politzerahles at polyu.edu.hk> wrote:
> 
> To whom it may concern:
> 
> 
> The help page for ?legend refers to a `title.cex` parameter, which suggests that the function has such a parameter.

No it does not. All arguments are listed and documented, none of them is title.cex, and there's no "...".

However, the documentation for "cex" has this oddity inside:

     cex: character expansion factor *relative* to current
          ?par("cex")?.  Used for text, and provides the default for
          ?pt.cex? and ?title.cex?.

Checking the sources suggests that this is the last anyone has seen of title.cex:

pd$ grep -r title.cex src
src/library/graphics/man/legend.Rd:    \code{pt.cex} and \code{title.cex}.}
pd$ 

The text was inserted as part of the addition of the title.col (!) argument, so it looks like the author got some wires crossed.

-pd

> As far as I can tell, though, it doesn't; here's an example:
> 
> 
>> plot(1,1)
>> legend("topright",pch=1, legend="something", title="my legend", title.cex=2)
> Error in legend("topright", pch = 1, legend = "something", title = "my legend",  :
>  unused argument (title.cex = 2)
> 
> 
> This issue appears to have been discussed online before (e.g. here's a post from 2011 mentioning it: http://r.789695.n4.nabble.com/Change-the-text-size-of-the-title-in-a-legend-of-a-R-plot-td3482880.html) but I'm not sure if anyone ever reported it to R developers.
> 
> 
> Is it possible for someone to update the ?legend documentation page so that it doens't refer to a parameter that isn't usable?
> 
> 
> Best,
> 
> Steve Politzer-Ahles
> 
> 
> ---
> Stephen Politzer-Ahles
> The Hong Kong Polytechnic University
> Department of Chinese and Bilingual Studies
> http://www.mypolyuweb.hk/~sjpolit/<http://www.mypolyuweb.hk/%7Esjpolit/>
> 
> 
> [http://mlm.polyu.edu.hk/PolyU80_Email_Signature.png]
> 
> www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary>
> 
> Disclaimer:\ \ This message (including any attachments) ...{{dropped:19}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From stephen.politzerahles at polyu.edu.hk  Sat Mar 25 14:25:32 2017
From: stephen.politzerahles at polyu.edu.hk (POLITZER-AHLES, Stephen [CBS])
Date: Sat, 25 Mar 2017 13:25:32 +0000
Subject: [Rd] Error in documentation for ?legend
In-Reply-To: <F5449896-4994-4C28-8F32-FBE529D1C239@gmail.com>
References: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>,
	<F5449896-4994-4C28-8F32-FBE529D1C239@gmail.com>
Message-ID: <KL1PR0201MB17179059B71D5E8509964F48DD310@KL1PR0201MB1717.apcprd02.prod.outlook.com>

Right, that's my point. The help page mentions a `title.cex`, like I said; saying that `cex` sets the default `title.cex` sure implies to me (and presumably to the other people whose discussion I linked) that a `title.cex` parameter exists. Since no such parameter exists, this bit in the documentation is misleading (suggesting that there is a `title.cex` parameter which can be set, when there really isn't). Regardless of whether we call it an "oddity" or what, I don't think it's controversial that this is misleading. If it's misleading, shouldn't it be removed?


---
Stephen Politzer-Ahles
The Hong Kong Polytechnic University
Department of Chinese and Bilingual Studies
http://www.mypolyuweb.hk/~sjpolit/<http://www.mypolyuweb.hk/%7Esjpolit/>


________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: Saturday, March 25, 2017 9:10:57 PM
To: POLITZER-AHLES, Stephen [CBS]
Cc: r-devel at r-project.org
Subject: Re: [Rd] Error in documentation for ?legend


> On 25 Mar 2017, at 00:39 , POLITZER-AHLES, Stephen [CBS] <stephen.politzerahles at polyu.edu.hk> wrote:
>
> To whom it may concern:
>
>
> The help page for ?legend refers to a `title.cex` parameter, which suggests that the function has such a parameter.

No it does not. All arguments are listed and documented, none of them is title.cex, and there's no "...".

However, the documentation for "cex" has this oddity inside:

     cex: character expansion factor *relative* to current
          ?par("cex")?.  Used for text, and provides the default for
          ?pt.cex? and ?title.cex?.

Checking the sources suggests that this is the last anyone has seen of title.cex:

pd$ grep -r title.cex src
src/library/graphics/man/legend.Rd:    \code{pt.cex} and \code{title.cex}.}
pd$

The text was inserted as part of the addition of the title.col (!) argument, so it looks like the author got some wires crossed.

-pd

> As far as I can tell, though, it doesn't; here's an example:
>
>
>> plot(1,1)
>> legend("topright",pch=1, legend="something", title="my legend", title.cex=2)
> Error in legend("topright", pch = 1, legend = "something", title = "my legend",  :
>  unused argument (title.cex = 2)
>
>
> This issue appears to have been discussed online before (e.g. here's a post from 2011 mentioning it: http://r.789695.n4.nabble.com/Change-the-text-size-of-the-title-in-a-legend-of-a-R-plot-td3482880.html) but I'm not sure if anyone ever reported it to R developers.
>
>
> Is it possible for someone to update the ?legend documentation page so that it doens't refer to a parameter that isn't usable?
>
>
> Best,
>
> Steve Politzer-Ahles
>
>
> ---
> Stephen Politzer-Ahles
> The Hong Kong Polytechnic University
> Department of Chinese and Bilingual Studies
> http://www.mypolyuweb.hk/~sjpolit/<http://www.mypolyuweb.hk/%7Esjpolit/>
>
>
> [http://mlm.polyu.edu.hk/PolyU80_Email_Signature.png]
>
> www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary>>
>
> Disclaimer:\ \ This message (including any attachments) ...{{dropped:19}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com









[http://mlm.polyu.edu.hk/PolyU80_Email_Signature.png]

www.polyu.edu.hk/80anniversary<http://www.polyu.edu.hk/80anniversary>

Disclaimer:\ \ This message (including any attachments) ...{{dropped:19}}


From mario at emmenlauer.de  Sat Mar 25 14:29:16 2017
From: mario at emmenlauer.de (Mario Emmenlauer)
Date: Sat, 25 Mar 2017 14:29:16 +0100
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
Message-ID: <87d4c578-6060-d212-18b3-64537dfc492a@emmenlauer.de>


Dear All,

thanks a lot for all the quick and helpful responses! I'm currently
interested in the "stance" of this community towards closed source
contributions. The way I understand it, currently my options are quite
limited: I would most likely need to use a remote procedure call API,
and build one side of the API as GPL. But this would make the coupling
much slower and more error-prone.

I was actually hoping to give modellers very efficient access to big
image analysis data (single cell results in multi-TB range). Currently
R seems not easily combined with the classical closed-source company
model. Are there considerations to release just the part that is
required to build the interface to R under a more permissive license?

All the best,

   Mario





On 24.03.2017 15:44, Marc Schwartz wrote:
> See inline...
> 
>> On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de
>> <mailto:mario at emmenlauer.de>> wrote:
>>
>>
>> Dear All,
>>
>> I've been following this mailing list for over three years now, but
>> its just now that I have realized that R is licensed under GPL! :-)
>>
>> I'm not a lawyer and I don't want lawyer advice, but I'd like to get
>> your feedback on a license question. 
> 
> 
> Hi, 
> 
> With the usual IANAL caveat and that I am not speaking on behalf of any other
> parties:
> 
> The questions you are posing will require legal advice, so your desire above to
> not get legal advice is in direct conflict with what you actually need here.
> 
> To your comments below, you cannot change existing licenses on software, R or
> otherwise. That is only something that the copyright holder(s) can do and you
> are not one of them.
> 
> The GPL has a FAQ here:
> 
>   https://www.gnu.org/licenses/gpl-faq.en.html
> 
> that you may find enlightening.
> 
> A very general statement, which is that if your compiled code (in whatever
> language) does not "link" against R's libraries and does not directly contain
> GPL licensed code (e.g. copying and pasting R Foundation copyrighted source code
> into yours), that is one way to steer clear of the viral part of the GPL license
> vis-a-vis R, if you want to, but not the only way and not a guarantee either.
> There can be nuances, some of which are covered in the FAQ above.
> 
> On the other hand, if your compiled code is linking to R's libraries, which you
> seem to suggest may be the case below, then your code, at least the relevant
> parts of it, will need to be licensed under a GPL compatible license.
> 
> This again is part of the nuance, in terms of the scope of the impact on your
> code (all or parts) and where legal advice is needed, to steer clear of
> downstream potential issues that could result in legal and financial liabilities
> for you.
> 
> The issue of linking to third party proprietary libraries is something that you
> will have to evaluate with respect to their licenses and any limitations that
> they may impose on your code and it's licensing.
> 
> Since you seem to also be suggesting that you may use closed source components
> in your package, you should be aware, that vis-a-vis CRAN, you would not be able
> to submit your package for distribution via that channel, since CRAN submissions
> may not contain pre-compiled binaries or similar and the entire package must
> conform to a compatible open source license. Thus, if you go down that path, you
> would have to find other distribution channels for your package, such as a
> company web site, etc.
> 
> None of the above should be construed as legal advice and if you plan to go down
> the path of offering a commercial service that you would charge clients for, a
> lawyer is mandatory to provide legal guidance and to assess your business risks.
> Even if your actual R related package is offered free of charge, while
> generating revenue through other means, if you should run afoul of software
> licensing requirements, that can still leave you open to financial liabilities
> and put your business and even personal assets at risk.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
>> My goal is to develop commercial
>> software for image analysis of biomedical samples that may be used
>> i.e. in academic institutions. Since I've been an academic software
>> developer for long, a priority for me is to make the data and tools
>> easily accessibly for other developers. I have toyed with the idea to
>> make a (free) R package that can very efficiently fetch data from the
>> database and push back results for visualization. To clarify: I am
>> not using R in my software. I'd rather like the institutions of my
>> customers to have open (internal) access to their data.
>>
>> Now for the question: To efficiently get the data into R, I assume a
>> package (possibly in C or C++) is the most reasonable way? If yes,
>> would such a package automatically be infected by the GPL? If the
>> package links to (proprietary closed source) libraries to efficiently
>> access the data, would the libraries in turn be infected?
>>
>> I'm asking this very naiively because I understand statement [1] in
>> such a way that it is generally encouraged to make data available in
>> R. Obviously open source is the preferred way, but my understanding
>> is that also closed source extensions can add value and may be
>> welcome.
>>
>> I was therefore hoping that somebody has prior experience in this
>> regard, or can shed further light on statement [1]. Is the R-C-
>> interface infectious per se, even when data flows only into R, not
>> vice versa? If its infectious, could just the very core of R be
>> licensed additionally under a non-infectious license?
>>
>> Furthermore, can I avoid infecting my full software stack, for example
>> by making only the package open source under a permissive license? Are
>> there any guidelines how to legally bridge between the proprietary and
>> the R-world? I guess other people have tried this before, can someone
>> share his/her experience?
>>
>> [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
>>
>> All the best,
>>
>>    Mario Emmenlauer
>>



Viele Gruesse,

    Mario Emmenlauer


--
BioDataAnalysis GmbH, Mario Emmenlauer      Tel. Buero: +49-89-74677203
Balanstr. 43                   mailto: memmenlauer * biodataanalysis.de
D-81669 M?nchen                          http://www.biodataanalysis.de/


From mario at emmenlauer.de  Sat Mar 25 14:35:55 2017
From: mario at emmenlauer.de (Mario Emmenlauer)
Date: Sat, 25 Mar 2017 14:35:55 +0100
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <87d4c578-6060-d212-18b3-64537dfc492a@emmenlauer.de>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<87d4c578-6060-d212-18b3-64537dfc492a@emmenlauer.de>
Message-ID: <c013167c-ebf7-645a-f271-9f235262d514@emmenlauer.de>


On 25.03.2017 14:29, Mario Emmenlauer wrote:
> 
> Dear All,
> 
> thanks a lot for all the quick and helpful responses! I'm currently
> interested in the "stance" of this community towards closed source
> contributions. The way I understand it, currently my options are quite
> limited: I would most likely need to use a remote procedure call API,
> and build one side of the API as GPL. But this would make the coupling
> much slower and more error-prone.
> 
> I was actually hoping to give modellers very efficient access to big
> image analysis data (single cell results in multi-TB range). Currently
> R seems not easily combined with the classical closed-source company
> model. Are there considerations to release just the part that is
> required to build the interface to R under a more permissive license?

I.e. I was thinking of something like this FAQ entry of the GPL: How
can I allow linking of proprietary modules with my GPL-covered library
under a controlled interface only? From
https://www.gnu.org/licenses/gpl-faq.en.html#LinkingOverControlledInterface




> All the best,
> 
>    Mario
> 
> 
> 
> 
> 
> On 24.03.2017 15:44, Marc Schwartz wrote:
>> See inline...
>>
>>> On Mar 24, 2017, at 8:52 AM, Mario Emmenlauer <mario at emmenlauer.de
>>> <mailto:mario at emmenlauer.de>> wrote:
>>>
>>>
>>> Dear All,
>>>
>>> I've been following this mailing list for over three years now, but
>>> its just now that I have realized that R is licensed under GPL! :-)
>>>
>>> I'm not a lawyer and I don't want lawyer advice, but I'd like to get
>>> your feedback on a license question. 
>>
>>
>> Hi, 
>>
>> With the usual IANAL caveat and that I am not speaking on behalf of any other
>> parties:
>>
>> The questions you are posing will require legal advice, so your desire above to
>> not get legal advice is in direct conflict with what you actually need here.
>>
>> To your comments below, you cannot change existing licenses on software, R or
>> otherwise. That is only something that the copyright holder(s) can do and you
>> are not one of them.
>>
>> The GPL has a FAQ here:
>>
>>   https://www.gnu.org/licenses/gpl-faq.en.html
>>
>> that you may find enlightening.
>>
>> A very general statement, which is that if your compiled code (in whatever
>> language) does not "link" against R's libraries and does not directly contain
>> GPL licensed code (e.g. copying and pasting R Foundation copyrighted source code
>> into yours), that is one way to steer clear of the viral part of the GPL license
>> vis-a-vis R, if you want to, but not the only way and not a guarantee either.
>> There can be nuances, some of which are covered in the FAQ above.
>>
>> On the other hand, if your compiled code is linking to R's libraries, which you
>> seem to suggest may be the case below, then your code, at least the relevant
>> parts of it, will need to be licensed under a GPL compatible license.
>>
>> This again is part of the nuance, in terms of the scope of the impact on your
>> code (all or parts) and where legal advice is needed, to steer clear of
>> downstream potential issues that could result in legal and financial liabilities
>> for you.
>>
>> The issue of linking to third party proprietary libraries is something that you
>> will have to evaluate with respect to their licenses and any limitations that
>> they may impose on your code and it's licensing.
>>
>> Since you seem to also be suggesting that you may use closed source components
>> in your package, you should be aware, that vis-a-vis CRAN, you would not be able
>> to submit your package for distribution via that channel, since CRAN submissions
>> may not contain pre-compiled binaries or similar and the entire package must
>> conform to a compatible open source license. Thus, if you go down that path, you
>> would have to find other distribution channels for your package, such as a
>> company web site, etc.
>>
>> None of the above should be construed as legal advice and if you plan to go down
>> the path of offering a commercial service that you would charge clients for, a
>> lawyer is mandatory to provide legal guidance and to assess your business risks.
>> Even if your actual R related package is offered free of charge, while
>> generating revenue through other means, if you should run afoul of software
>> licensing requirements, that can still leave you open to financial liabilities
>> and put your business and even personal assets at risk.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> My goal is to develop commercial
>>> software for image analysis of biomedical samples that may be used
>>> i.e. in academic institutions. Since I've been an academic software
>>> developer for long, a priority for me is to make the data and tools
>>> easily accessibly for other developers. I have toyed with the idea to
>>> make a (free) R package that can very efficiently fetch data from the
>>> database and push back results for visualization. To clarify: I am
>>> not using R in my software. I'd rather like the institutions of my
>>> customers to have open (internal) access to their data.
>>>
>>> Now for the question: To efficiently get the data into R, I assume a
>>> package (possibly in C or C++) is the most reasonable way? If yes,
>>> would such a package automatically be infected by the GPL? If the
>>> package links to (proprietary closed source) libraries to efficiently
>>> access the data, would the libraries in turn be infected?
>>>
>>> I'm asking this very naiively because I understand statement [1] in
>>> such a way that it is generally encouraged to make data available in
>>> R. Obviously open source is the preferred way, but my understanding
>>> is that also closed source extensions can add value and may be
>>> welcome.
>>>
>>> I was therefore hoping that somebody has prior experience in this
>>> regard, or can shed further light on statement [1]. Is the R-C-
>>> interface infectious per se, even when data flows only into R, not
>>> vice versa? If its infectious, could just the very core of R be
>>> licensed additionally under a non-infectious license?
>>>
>>> Furthermore, can I avoid infecting my full software stack, for example
>>> by making only the package open source under a permissive license? Are
>>> there any guidelines how to legally bridge between the proprietary and
>>> the R-world? I guess other people have tried this before, can someone
>>> share his/her experience?
>>>
>>> [1] https://stat.ethz.ch/pipermail/r-devel/2009-May/053248.html
>>>
>>> All the best,
>>>
>>>    Mario Emmenlauer
>>>


From marc_schwartz at me.com  Sat Mar 25 16:19:04 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 25 Mar 2017 10:19:04 -0500
Subject: [Rd] non-infectious license for R package?
In-Reply-To: <c013167c-ebf7-645a-f271-9f235262d514@emmenlauer.de>
References: <d23bd77a-3904-7793-b406-f7ca9567f965@emmenlauer.de>
	<D9778ABF-9916-4347-9AC0-AC3D57763079@me.com>
	<87d4c578-6060-d212-18b3-64537dfc492a@emmenlauer.de>
	<c013167c-ebf7-645a-f271-9f235262d514@emmenlauer.de>
Message-ID: <6C3CFB2C-05FF-4DD0-8291-5BB0C0065DEC@me.com>


> On Mar 25, 2017, at 8:35 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
> 
> 
> On 25.03.2017 14:29, Mario Emmenlauer wrote:
>> 
>> Dear All,
>> 
>> thanks a lot for all the quick and helpful responses! I'm currently
>> interested in the "stance" of this community towards closed source
>> contributions. The way I understand it, currently my options are quite
>> limited: I would most likely need to use a remote procedure call API,
>> and build one side of the API as GPL. But this would make the coupling
>> much slower and more error-prone.
>> 
>> I was actually hoping to give modellers very efficient access to big
>> image analysis data (single cell results in multi-TB range). Currently
>> R seems not easily combined with the classical closed-source company
>> model. Are there considerations to release just the part that is
>> required to build the interface to R under a more permissive license?
> 
> I.e. I was thinking of something like this FAQ entry of the GPL: How
> can I allow linking of proprietary modules with my GPL-covered library
> under a controlled interface only? From
> https://www.gnu.org/licenses/gpl-faq.en.html#LinkingOverControlledInterface
> 
> 
> 
> 
>> All the best,
>> 
>>   Mario
>> 
>> 

<snip>

Hi,

As per the language included in the section of the FAQ that you reference above, if you want to go down that path, you would have to engage in formally communicating with the R Foundation, as the copyright holders of R, to solicit their formal position, which would be final. Note that depending upon the specifics, there may be other parties that would also have to render a decision, since other individuals also hold copyrights to included code in the standard R distribution and may or may not have given approval to the R Foundation to act on their behalf:

  https://svn.r-project.org/R/trunk/doc/COPYRIGHTS

If you wanted to pursue that avenue, you should communicate with the current R Foundation Co-Presidents:

  Simon Urbanek (simon.urbanek at r-project.org)
  Martyn Plummer (plummerM at iarc.fr)

were they can elect to engage the Board of the R Foundation in further discussion.

To the broader issue of the "stance" of the community at large vis-a-vis closed source software, you will find, as in any community, a spectrum of positions. 

There are, as you may be aware, commercial versions of R, that have been built upon the standard open source R distribution, which offer sufficient additional value that their customers are willing to pay for them. In some cases, these may include closed source components. A parallel of sorts would be a community based, open source version of a Linux server distribution (e.g. CentOS) versus a commercial offering (e.g. RHEL), where the latter has paid support options and other value added components and services that are revenue generating. In these commercial cases, as I referenced in my prior reply, legal counsel with expertise in open source licensing and intellectual property rights, will have rendered formal legal opinions to provide guidance and comfort that these for-profit businesses remain in conformance with license requirements to stay clear of any liabilities. No ethical business, in their right mind, would move forward without that.

However, at the end of the day, the only position that is relevant to your issue is the formal position of the R Foundation itself, since it holds the copyright to R as officially distributed and would, if needed, take action in the case of license non-conformance.

Others in the community, myself included, can offer opinions, but they hold no relevance to your situation, since they are not legally binding. In other words, we are not in a position to say that you can or cannot proceed with your plan. You can gain some insights, as others have referenced, by using examples of what appear to be acceptable implementations. But each situation can have sufficient differences as to perhaps not be exactly applicable to yours. Thus, part of the potential challenge for you would be to provide sufficient detail on your exact implementation plans to allow an opinion to be rendered that narrowly covers those details, as opposed to a more generic model.

Regards,

Marc Schwartz


From thosjleeper at gmail.com  Sun Mar 26 18:48:17 2017
From: thosjleeper at gmail.com (Thomas J. Leeper)
Date: Sun, 26 Mar 2017 17:48:17 +0100
Subject: [Rd] Documentation of model.frame() and get_all_vars()
Message-ID: <CAOC91MSiQDWXgPbvQ8YoMX2ZmVZwUUur5_Txi9N4UtgG9YtgkA@mail.gmail.com>

Hi everyone,

This is about documentation for the model.frame() page. The
get_all_vars() function (added in R 2.5.0) is a great addition, but
the behavior of its '...' argument is different from that of
model.frame() with which it is documented and this creates ambiguity.
The current docs read:

\item{\dots}{further arguments such as \code{data}, \code{na.action},
\code{subset}. Any additional arguments such as \code{offset} and
\code{weights} which reach the default method are used to create
further columns in the model frame, with parenthesised names such as
\code{"(offset)"}.}

This is only true for model.frame() methods but not get_all_vars().
For get_all_vars(), arguments passed to '...' are only ever treated as
variables to add to the data frame. See for example:

> str(model.frame(mpg ~ wt, data = mtcars, subset = am == 1), give.attr = FALSE)
'data.frame':   13 obs. of  2 variables:
 $ mpg: num  21 21 22.8 32.4 30.4 33.9 27.3 26 30.4 15.8 ...
 $ wt : num  2.62 2.88 2.32 2.2 1.61 ...

> str(get_all_vars(mpg ~ wt, data = mtcars, subset = am == 1), give.attr = FALSE)
'data.frame':   32 obs. of  3 variables:
 $ mpg   : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ wt    : num  2.62 2.88 2.32 3.21 3.44 ...
 $ subset: logi  TRUE TRUE TRUE FALSE FALSE FALSE ...

The behavior of '...' thus differs in the two functions. This is (I
think) a quite problematic ambiguity and one that might best be
resolved by adding data, na.action, and subset as formal arguments to
all current model.frame() methods and the generic to resolve the
ambiguity of '...' (with docs updated accordingly), but that would
require a more thorough patch and testing.

In lieu of that, a simple documentation change could at least describe
the current behavior more accurately:

\item{\dots}{for \code{get_all_vars}, further named columns to include
in the model frame. For \code{model.frame} methods, a mix of further
arguments such as \code{data}, \code{na.action}, \code{subset} to pass
to the default method. Any additional arguments (such as \code{offset}
and \code{weights} or other named arguments) which reach the default
method are used to create further columns in the model frame, with
parenthesised names such as \code{"(offset)"}.}

That at least describes what is currently happening.

Relatedly, it may be worth noting that additional variables passed via
'...' to get_all_vars() are subject to vector recycling whereas those
passed to model.frame.default() are not:

> str(get_all_vars(mpg ~ wt, data = mtcars, new = 2), give.attr = FALSE)
'data.frame':   32 obs. of  3 variables:
 $ mpg: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ wt : num  2.62 2.88 2.32 3.21 3.44 ...
 $ new: num  2 2 2 2 2 2 2 2 2 2 ...

> str(get_all_vars(mpg ~ wt, data = mtcars, new = rep(2, nrow(mtcars))), give.attr = FALSE)
'data.frame':   32 obs. of  3 variables:
 $ mpg: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ wt : num  2.62 2.88 2.32 3.21 3.44 ...
 $ new: num  2 2 2 2 2 2 2 2 2 2 ...

> str(model.frame.default(mpg ~ wt, data = mtcars, new = rep(2, nrow(mtcars))), give.attr = FALSE)
'data.frame':   32 obs. of  3 variables:
 $ mpg  : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ wt   : num  2.62 2.88 2.32 3.21 3.44 ...
 $ (new): num  2 2 2 2 2 2 2 2 2 2 ...

> str(model.frame.default(mpg ~ wt, data = mtcars, new = 2), give.attr = FALSE)
Error in model.frame.default(mpg ~ wt, data = mtcars, new = 2) :
  variable lengths differ (found for '(new)')

But, maybe that's something for the "Details" section? (Or it's a bug
- I don't really know.)

Thanks in advance for your consideration.

Best,
-Thomas

Thomas J. Leeper
http://www.thomasleeper.com


From r.turner at auckland.ac.nz  Mon Mar 27 02:17:59 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 27 Mar 2017 13:17:59 +1300
Subject: [Rd] A trap for young players with the lapply() function.
Message-ID: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>


 From time to time I get myself into a state of bewilderment when using
apply() by calling it with FUN equal to a function which has an 
"optional" argument named "X".

E.g.

     xxx <- lapply(y,function(x,X){cos(x*X)},X=2*pi)

which produces the error message

> Error in get(as.character(FUN), mode = "function", envir = envir) :
>   object 'y' of mode 'function' was not found

This of course happens because the name of the first argument of 
lapply() is "X" and so it takes the value of this first argument to be 
the supplied X (2*pi in the foregoing example) and then expects what the 
user has denoted by "y" to be the value of FUN, and (obviously!) it isn't.

Once one realises what is going on, it's all quite obvious, and usually
pretty easy to fix.  OTOH there are lots of functions around with second
or third arguments whose formal name is "X", and these can trip one up
until the penny drops.

This keeps happening to me, over and over again (with sufficiently long
intervals between occurrences so that my ageing memory forgets the 
previous occurrence).

Is there any way to trap/detect the use of an optional argument called 
"X" and thereby issue a more perspicuous error message?

This would be helpful to those users who, like myself, are bears of very 
little brain.

Failing that (it does look impossible) might it not be a good idea to 
add a warning to the help for lapply(), to the effect that if FUN has an 
optional argument named "X" then passing this argument via "..." will 
cause this argument to be taken as the first argument to lapply() and 
thereby induce an error?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From maechler at stat.math.ethz.ch  Mon Mar 27 09:59:09 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Mar 2017 09:59:09 +0200
Subject: [Rd] Error in documentation for ?legend
In-Reply-To: <KL1PR0201MB17179059B71D5E8509964F48DD310@KL1PR0201MB1717.apcprd02.prod.outlook.com>
References: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>
	<F5449896-4994-4C28-8F32-FBE529D1C239@gmail.com>
	<KL1PR0201MB17179059B71D5E8509964F48DD310@KL1PR0201MB1717.apcprd02.prod.outlook.com>
Message-ID: <22744.50765.707153.795584@stat.math.ethz.ch>

>>>>> POLITZER-AHLES, Stephen [CBS] <stephen.politzerahles at polyu.edu.hk>
>>>>>     on Sat, 25 Mar 2017 13:25:32 +0000 writes:

    > Right, that's my point. The help page mentions a
    > `title.cex`, like I said; saying that `cex` sets the
    > default `title.cex` sure implies to me (and presumably to
    > the other people whose discussion I linked) that a
    > `title.cex` parameter exists. Since no such parameter
    > exists, this bit in the documentation is misleading
    > (suggesting that there is a `title.cex` parameter which
    > can be set, when there really isn't). Regardless of
    > whether we call it an "oddity" or what, I don't think it's
    > controversial that this is misleading. If it's misleading,
    > shouldn't it be removed?

Yes.
I've done so now,  thank you for the report!

(You did not understand Peter:  He *did* agree with you that
 there's no 'title.cex' argument  and explained why the oddity
 probably has happened in the distant past ..)

Martin Maechler
ETH Zurich
and R Core Team (as Peter Dalgaard)

    > From: peter dalgaard <pdalgd at gmail.com>
    > Sent: Saturday, March 25, 2017 9:10:57 PM
    > To: POLITZER-AHLES, Stephen [CBS]
    > Cc: r-devel at r-project.org
    > Subject: Re: [Rd] Error in documentation for ?legend


    >> On 25 Mar 2017, at 00:39 , POLITZER-AHLES, Stephen [CBS] <stephen.politzerahles at polyu.edu.hk> wrote:
    >> 
    >> To whom it may concern:
    >> 
    >> 
    >> The help page for ?legend refers to a `title.cex` parameter, which suggests that the function has such a parameter.

    > No it does not. All arguments are listed and documented, none of them is title.cex, and there's no "...".

    > However, the documentation for "cex" has this oddity inside:

    > cex: character expansion factor *relative* to current
    > ?par("cex")?.  Used for text, and provides the default for
    > ?pt.cex? and ?title.cex?.

    > Checking the sources suggests that this is the last anyone has seen of title.cex:

    > pd$ grep -r title.cex src
    > src/library/graphics/man/legend.Rd:    \code{pt.cex} and \code{title.cex}.}
    > pd$

    > The text was inserted as part of the addition of the title.col (!) argument, so it looks like the author got some wires crossed.

    > -pd

    >> As far as I can tell, though, it doesn't; here's an example:
    >> 
    >> 
    >>> plot(1,1)
    >>> legend("topright",pch=1, legend="something", title="my legend", title.cex=2)
    >> Error in legend("topright", pch = 1, legend = "something", title = "my legend",  :
    >> unused argument (title.cex = 2)
    >> 
    >> 
    >> This issue appears to have been discussed online before (e.g. here's a post from 2011 mentioning it: http://r.789695.n4.nabble.com/Change-the-text-size-of-the-title-in-a-legend-of-a-R-plot-td3482880.html) but I'm not sure if anyone ever reported it to R developers.
    >> 
    >> 
    >> Is it possible for someone to update the ?legend documentation page so that it doens't refer to a parameter that isn't usable?
    >> 
    >> Best,
    >> 
    >> Steve Politzer-Ahles
    >> 
    >> ---
    >> Stephen Politzer-Ahles
    >> The Hong Kong Polytechnic University
    >> Department of Chinese and Bilingual Studies
    >> http://www.mypolyuweb.hk/~sjpolit/<http://www.mypolyuweb.hk/%7Esjpolit/>
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > --
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Office: A 4.23
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Mon Mar 27 10:44:42 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Mar 2017 10:44:42 +0200
Subject: [Rd] Documentation of model.frame() and get_all_vars()
In-Reply-To: <CAOC91MSiQDWXgPbvQ8YoMX2ZmVZwUUur5_Txi9N4UtgG9YtgkA@mail.gmail.com>
References: <CAOC91MSiQDWXgPbvQ8YoMX2ZmVZwUUur5_Txi9N4UtgG9YtgkA@mail.gmail.com>
Message-ID: <22744.53498.81489.774548@stat.math.ethz.ch>

>>>>> Thomas J Leeper <thosjleeper at gmail.com>
>>>>>     on Sun, 26 Mar 2017 17:48:17 +0100 writes:

    > Hi everyone,
    > This is about documentation for the model.frame() page. The
    > get_all_vars() function (added in R 2.5.0) is a great addition, but
    > the behavior of its '...' argument is different from that of
    > model.frame() with which it is documented and this creates ambiguity.
    > The current docs read:

    > \item{\dots}{further arguments such as \code{data}, \code{na.action},
    > \code{subset}. Any additional arguments such as \code{offset} and
    > \code{weights} which reach the default method are used to create
    > further columns in the model frame, with parenthesised names such as
    > \code{"(offset)"}.}

    > This is only true for model.frame() methods but not get_all_vars().
    > For get_all_vars(), arguments passed to '...' are only ever treated as
    > variables to add to the data frame. 

as the documentation of get_all_vars() actually does say.

But you are right:  The description of '...' should mention its
different meaning for get_all_vars().

    > See for example:
    >> str(model.frame(mpg ~ wt, data = mtcars, subset = am == 1), give.attr = FALSE)
    > 'data.frame':   13 obs. of  2 variables:
    > $ mpg: num  21 21 22.8 32.4 30.4 33.9 27.3 26 30.4 15.8 ...
    > $ wt : num  2.62 2.88 2.32 2.2 1.61 ...

    >> str(get_all_vars(mpg ~ wt, data = mtcars, subset = am == 1), give.attr = FALSE)
    > 'data.frame':   32 obs. of  3 variables:
    > $ mpg   : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    > $ wt    : num  2.62 2.88 2.32 3.21 3.44 ...
    > $ subset: logi  TRUE TRUE TRUE FALSE FALSE FALSE ...

    > The behavior of '...' thus differs in the two functions. This is (I
    > think) a quite problematic ambiguity and one that might best be
    > resolved by adding data, na.action, and subset as formal arguments to
    > all current model.frame() methods and the generic to resolve the
    > ambiguity of '...' (with docs updated accordingly), but that would
    > require a more thorough patch and testing.

Hmm, I agree with the very last part, however I don't understand
why you claim this to be an important ambiguity to be resolved:

get_all_vars() is _not_ called by any of our model.frame()
methods, nor the reverse:  it does not call model.frame().

I did not design or implement it but I think it does make sense
to be documented on the same page as model.frame() because the
functions have very similar semantics.
Adding the extra arguments to the generic and all methods does
not seem desirable to me.

    > In lieu of that, a simple documentation change could at least describe
    > the current behavior more accurately:

    > \item{\dots}{for \code{get_all_vars}, further named columns to include
    > in the model frame. For \code{model.frame} methods, a mix of further
    > arguments such as \code{data}, \code{na.action}, \code{subset} to pass
    > to the default method. Any additional arguments (such as \code{offset}
    > and \code{weights} or other named arguments) which reach the default
    > method are used to create further columns in the model frame, with
    > parenthesised names such as \code{"(offset)"}.}

    > That at least describes what is currently happening.

I agree... and plan to commit this improved description (to
R-devel and R 3.4.0 alpha).


    > Relatedly, it may be worth noting that additional variables passed via
    > '...' to get_all_vars() are subject to vector recycling whereas those
    > passed to model.frame.default() are not:

I'll also mention the vector recycling for get_all_vars().

    >> str(get_all_vars(mpg ~ wt, data = mtcars, new = 2), give.attr = FALSE)
    > 'data.frame':   32 obs. of  3 variables:
    > $ mpg: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    > $ wt : num  2.62 2.88 2.32 3.21 3.44 ...
    > $ new: num  2 2 2 2 2 2 2 2 2 2 ...

    >> str(get_all_vars(mpg ~ wt, data = mtcars, new = rep(2, nrow(mtcars))), give.attr = FALSE)
    > 'data.frame':   32 obs. of  3 variables:
    > $ mpg: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    > $ wt : num  2.62 2.88 2.32 3.21 3.44 ...
    > $ new: num  2 2 2 2 2 2 2 2 2 2 ...

    >> str(model.frame.default(mpg ~ wt, data = mtcars, new = rep(2, nrow(mtcars))), give.attr = FALSE)
    > 'data.frame':   32 obs. of  3 variables:
    > $ mpg  : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    > $ wt   : num  2.62 2.88 2.32 3.21 3.44 ...
    > $ (new): num  2 2 2 2 2 2 2 2 2 2 ...

    >> str(model.frame.default(mpg ~ wt, data = mtcars, new = 2), give.attr = FALSE)
    > Error in model.frame.default(mpg ~ wt, data = mtcars, new = 2) :
    > variable lengths differ (found for '(new)')

    > But, maybe that's something for the "Details" section? (Or it's a bug
    > - I don't really know.)

I would not want to change model.frame.default() currently as it's
too important a building block and it may be wise to require
that its callers should have done recycling.

    > Thanks in advance for your consideration.

Thank you Thomas for the suggested help file improvements!
Martin 

--
Martin Maechler
ETH Zurich

    > Best,
    > -Thomas

    > Thomas J. Leeper
    > http://www.thomasleeper.com


From pdalgd at gmail.com  Mon Mar 27 10:57:24 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 27 Mar 2017 10:57:24 +0200
Subject: [Rd] Error in documentation for ?legend
In-Reply-To: <22744.50765.707153.795584@stat.math.ethz.ch>
References: <KL1PR0201MB1717D53AC14D190F7D424724DD3E0@KL1PR0201MB1717.apcprd02.prod.outlook.com>
	<F5449896-4994-4C28-8F32-FBE529D1C239@gmail.com>
	<KL1PR0201MB17179059B71D5E8509964F48DD310@KL1PR0201MB1717.apcprd02.prod.outlook.com>
	<22744.50765.707153.795584@stat.math.ethz.ch>
Message-ID: <2D551256-C282-4C83-871C-F38A8F51DEEA@gmail.com>


> On 27 Mar 2017, at 09:59 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> 
> (You did not understand Peter:  He *did* agree with you that
> there's no 'title.cex' argument  and explained why the oddity
> probably has happened in the distant past ..)


I was also pointing out that the help page specifically does NOT document any such argument - otherwise the self-tests would have found the inconsistency long ago. What it does have is a (false) hint that there might somewhere be something called title.cex defaulting to the value of cex. 

The main point is that when someone claims that there is inconsistency between documentation and code, the first thing I do is to check the (long) argument list, the second thing is the (even longer) list of documented arguments. Neither has title.cex. No version information was given, so I couldn't know whether it might have been fixed in one of the more recent releases, etc.

(I didn't fix it immediately on the off chance that the original author had actually planned to implement a title.cex feature. But he probably didn't.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jeroenooms at gmail.com  Mon Mar 27 13:33:10 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 27 Mar 2017 13:33:10 +0200
Subject: [Rd] Hyperbolic tangent different results on Windows and Mac
In-Reply-To: <CABFfbXu4hWq7JT14u2PYG-b6LCA7btPg2o=iOD2tgUaK48F9ew@mail.gmail.com>
References: <CACtWsWMW8VJdzC8ZSG0a+3dGP29kVESOFFwOO3hMRpAuUQxnAw@mail.gmail.com>
	<CABFfbXu4hWq7JT14u2PYG-b6LCA7btPg2o=iOD2tgUaK48F9ew@mail.gmail.com>
Message-ID: <CABFfbXvudeA1Gb8LCD+a=3QNTtTDQr=038TyTxbwN7Zzo5PRog@mail.gmail.com>

For future reference:
https://sourceforge.net/p/mingw-w64/mailman/message/35747206/

On Wed, Mar 22, 2017 at 2:12 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> This looks like a bug in mingw-w64 CRT. The problem can be produced
> with C++ without R:
>
>   #include <iostream>
>   #include <cmath>
>   #include <complex>
>
>   int main(){
>     std::cout << std::fixed;
>     std::complex<double> z(356, 0);
>     std::cout << "tanh" << z << " = " << std::tanh(z)
>          << " (tanh(356) = " << std::tanh(356) << ")\n";
>   }
>
> On OS-X we get:
>
>   tanh(356.000000,0.000000) = (1.000000,-0.000000) (tanh(356) = 1.000000)
>
> But on Windows we get:
>
>   tanh(356.000000,0.000000) = (nan,0.000000) (tanh(356) = 1.000000)
>
> I was also able to reproduce the problem with gcc 6.3 in msys2 so it
> has not been fixed upstream. You should file a bug report for
> mingw-w64.
>
> FWIF, we have run into NaN edge-case bugs before with mingw-w64.
>
>  - https://sourceforge.net/p/mingw-w64/mingw-w64/ci/6617ebd5fc6b790c80071d5b1d950e737fc670e1/
>  - https://github.com/wch/r-source/commit/e9aaf8fdeddf27c2a9078cd214a41475c8ff6f40
>
> I am cc'ing Ray Donnelly who is an expert on mingw-w64.


From b.rowlingson at lancaster.ac.uk  Mon Mar 27 17:21:29 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 27 Mar 2017 16:21:29 +0100
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <4e15ccb966c041f68ea042459324d02c@EX-0-HT0.lancs.local>
References: <4e15ccb966c041f68ea042459324d02c@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOEg6e3b7U1rYd1nQzJQOtxXGc+e=6cvHJJVFSsxcovAQ@mail.gmail.com>

On Mon, Mar 27, 2017 at 1:17 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> Is there any way to trap/detect the use of an optional argument called
> "X" and thereby issue a more perspicuous error message?
>
> This would be helpful to those users who, like myself, are bears of very
> little brain.
>
> Failing that (it does look impossible)

You can get the names of named arguments:

 > z = function(x,X){cos(x*X)}
 > names(formals(z))
 [1] "x" "X"


> might it not be a good idea to
> add a warning to the help for lapply(), to the effect that if FUN has an
> optional argument named "X" then passing this argument via "..." will
> cause this argument to be taken as the first argument to lapply() and
> thereby induce an error?

Another idea might be to use purrr:map instead, which is quite happy
with X in your function:

 >  xxx <- purrr::map(y,function(x,X){cos(x*X)},X=2*pi)
 > xxx
[[1]]
[1] 0.08419541

[[2]]
[1] 0.6346404

[[3]]
[1] 0.9800506

[[4]]
[1] 0.8686734

[[5]]
[1] -0.9220073

But don't feed `.x` to your purrrring cats, or fails silently:

 >  xxx <- purrr::map(y,function(x,.x){cos(x*.x)},.x=2*pi)
 > xxx
[[1]]
NULL

But who would have a function with `.x` as an argument?


> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From joroman at rand.org  Mon Mar 27 19:46:38 2017
From: joroman at rand.org (Roman, John)
Date: Mon, 27 Mar 2017 17:46:38 +0000
Subject: [Rd] R fails to read repo index on NGINX
Message-ID: <EDD04CD16EC1524FACF04CF343DAB49428692944@smmb1.rand.org>

im hosting a local cran repo on an NGINX server and it fails to pull the index at /src/contrib/

the layout of the index is different from apache, could this be disrupting R?

John Roman
Linux System Administrator
RAND Corporation
joroman at rand.org
X7302

__________________________________________________________________________

This email message is for the sole use of the intended r...{{dropped:9}}


From edd at debian.org  Mon Mar 27 20:11:38 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 27 Mar 2017 13:11:38 -0500
Subject: [Rd] R fails to read repo index on NGINX
In-Reply-To: <EDD04CD16EC1524FACF04CF343DAB49428692944@smmb1.rand.org>
References: <EDD04CD16EC1524FACF04CF343DAB49428692944@smmb1.rand.org>
Message-ID: <22745.21978.217320.875223@max.eddelbuettel.com>


On 27 March 2017 at 17:46, Roman, John wrote:
| im hosting a local cran repo on an NGINX server and it fails to pull the index at /src/contrib/
| 
| the layout of the index is different from apache, could this be disrupting R?

You mean when you look at the directory in a browser?

Should not matter.  Use any command-line client (wget, curl, ...) or R's
download.file() to slurp down  http://$MYSERVER/src/contrib/PACKAGES to
inspect, compare, ... -- and that is an absolute path so the index does not
matter.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From joroman at rand.org  Mon Mar 27 20:27:02 2017
From: joroman at rand.org (Roman, John)
Date: Mon, 27 Mar 2017 18:27:02 +0000
Subject: [Rd] R fails to read repo index on NGINX
In-Reply-To: <22745.21978.217320.875223@max.eddelbuettel.com>
References: <EDD04CD16EC1524FACF04CF343DAB49428692944@smmb1.rand.org>,
	<22745.21978.217320.875223@max.eddelbuettel.com>
Message-ID: <EDD04CD16EC1524FACF04CF343DAB49428692AC5@smmb1.rand.org>

Dirk,
Thank you for your elaboration.  This issue is related to curl trusting a CA cert as its called by R.  
curl called from bash recognizes the system cert bundle for CA's, curl called from R does not.

may I know how to trust the system certificate bundle from within R?


John Roman
Linux System Administrator
RAND Corporation
joroman at rand.org
X7302

________________________________________
From: Dirk Eddelbuettel [dirk.eddelbuettel at gmail.com] on behalf of Dirk Eddelbuettel [edd at debian.org]
Sent: Monday, March 27, 2017 11:11 AM
To: Roman, John
Cc: R-devel at r-project.org
Subject: Re: [Rd] R fails to read repo index on NGINX

On 27 March 2017 at 17:46, Roman, John wrote:
| im hosting a local cran repo on an NGINX server and it fails to pull the index at /src/contrib/
|
| the layout of the index is different from apache, could this be disrupting R?

You mean when you look at the directory in a browser?

Should not matter.  Use any command-line client (wget, curl, ...) or R's
download.file() to slurp down  http://$MYSERVER/src/contrib/PACKAGES to
inspect, compare, ... -- and that is an absolute path so the index does not
matter.

Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


__________________________________________________________________________

This email message is for the sole use of the intended r...{{dropped:6}}


From edd at debian.org  Mon Mar 27 20:33:39 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 27 Mar 2017 13:33:39 -0500
Subject: [Rd] R fails to read repo index on NGINX
In-Reply-To: <EDD04CD16EC1524FACF04CF343DAB49428692AC5@smmb1.rand.org>
References: <EDD04CD16EC1524FACF04CF343DAB49428692944@smmb1.rand.org>
	<22745.21978.217320.875223@max.eddelbuettel.com>
	<EDD04CD16EC1524FACF04CF343DAB49428692AC5@smmb1.rand.org>
Message-ID: <22745.23299.880135.337732@max.eddelbuettel.com>


On 27 March 2017 at 18:27, Roman, John wrote:
| Thank you for your elaboration.  This issue is related to curl trusting a CA cert as its called by R.  
| curl called from bash recognizes the system cert bundle for CA's, curl called from R does not.
| 
| may I know how to trust the system certificate bundle from within R?

See 'help(download.file)' -- it's a little hidden but you can just make the
external curl (which, as you say, works in your particular circumstances) the
default for remote file access from R too.

Next time please try to be a little more specific with your questions and
their subject line.  Methinks nothing here has anything to do with the httpd
server you employ.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From joroman at rand.org  Mon Mar 27 21:09:25 2017
From: joroman at rand.org (Roman, John)
Date: Mon, 27 Mar 2017 19:09:25 +0000
Subject: [Rd] R libcurl does not recognize server certs
Message-ID: <EDD04CD16EC1524FACF04CF343DAB49428692B6C@smmb1.rand.org>

Dirk,
ive changed the subject given the nature of the present debugging.  Im aware i can extend extras from download.file to install.packages however
im curious to know why libcurl in the R invocation does not honor the CA bundle on my system.

how would I pass a CA bundle to install.packages?  the function has numerous arguments before the extras are taken.

John Roman
Linux System Administrator
RAND Corporation
joroman at rand.org
X7302

________________________________________
From: Dirk Eddelbuettel [dirk.eddelbuettel at gmail.com] on behalf of Dirk Eddelbuettel [edd at debian.org]
Sent: Monday, March 27, 2017 11:33 AM
To: Roman, John
Cc: Dirk Eddelbuettel; R-devel at r-project.org
Subject: RE: [Rd] R fails to read repo index on NGINX

On 27 March 2017 at 18:27, Roman, John wrote:
| Thank you for your elaboration.  This issue is related to curl trusting a CA cert as its called by R.
| curl called from bash recognizes the system cert bundle for CA's, curl called from R does not.
|
| may I know how to trust the system certificate bundle from within R?

See 'help(download.file)' -- it's a little hidden but you can just make the
external curl (which, as you say, works in your particular circumstances) the
default for remote file access from R too.

Next time please try to be a little more specific with your questions and
their subject line.  Methinks nothing here has anything to do with the httpd
server you employ.

Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


__________________________________________________________________________

This email message is for the sole use of the intended r...{{dropped:6}}


From martin.morgan at roswellpark.org  Mon Mar 27 22:31:01 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Mon, 27 Mar 2017 16:31:01 -0400
Subject: [Rd] R libcurl does not recognize server certs
In-Reply-To: <EDD04CD16EC1524FACF04CF343DAB49428692B6C@smmb1.rand.org>
References: <EDD04CD16EC1524FACF04CF343DAB49428692B6C@smmb1.rand.org>
Message-ID: <c2c948a5-1d2f-7782-f856-548dedef17ce@roswellpark.org>

On 03/27/2017 03:09 PM, Roman, John wrote:
> Dirk,
> ive changed the subject given the nature of the present debugging.  Im aware i can extend extras from download.file to install.packages however
> im curious to know why libcurl in the R invocation does not honor the CA bundle on my system.
>
> how would I pass a CA bundle to install.packages?  the function has numerous arguments before the extras are taken.
>

A little shot-in-the-dark but on Linux I have

$ curl-config --ca
/etc/ssl/certs/ca-certificates.crt

and in R ?download.file I'm told (the documentation may read as 
window-specific, but I don't think that's the case)

      set environment variable 'CURL_CA_BUNDLE' to the path to a
      certificate bundle file, usually named 'ca-bundle.crt' or
      'curl-ca-bundle.crt'.  (This is normally done for a binary

So if I were having trouble I might say (or set the environment variable 
in some other way, e.g., as part of an alias to R)

 > Sys.setenv(CURL_CA_BUNDLE="/etc/ssl/certs/ca-certificates.crt")
 > download.file("https://, tempfile())

Maybe with more info about your OS and R installation a more transparent 
solution would offer itself; I'd guess that the bundle location is 
inferred when R is built from source, and somehow there has been a 
disconnect between your R installation and certificate location, e.g., 
moving the certificate location after R installation.

Martin Morgan

> John Roman
> Linux System Administrator
> RAND Corporation
> joroman at rand.org
> X7302
>
> ________________________________________
> From: Dirk Eddelbuettel [dirk.eddelbuettel at gmail.com] on behalf of Dirk Eddelbuettel [edd at debian.org]
> Sent: Monday, March 27, 2017 11:33 AM
> To: Roman, John
> Cc: Dirk Eddelbuettel; R-devel at r-project.org
> Subject: RE: [Rd] R fails to read repo index on NGINX
>
> On 27 March 2017 at 18:27, Roman, John wrote:
> | Thank you for your elaboration.  This issue is related to curl trusting a CA cert as its called by R.
> | curl called from bash recognizes the system cert bundle for CA's, curl called from R does not.
> |
> | may I know how to trust the system certificate bundle from within R?
>
> See 'help(download.file)' -- it's a little hidden but you can just make the
> external curl (which, as you say, works in your particular circumstances) the
> default for remote file access from R too.
>
> Next time please try to be a little more specific with your questions and
> their subject line.  Methinks nothing here has anything to do with the httpd
> server you employ.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
>
> __________________________________________________________________________
>
> This email message is for the sole use of the intended...{{dropped:10}}


From r.turner at auckland.ac.nz  Mon Mar 27 23:26:54 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 28 Mar 2017 10:26:54 +1300
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <CANVKczOEg6e3b7U1rYd1nQzJQOtxXGc+e=6cvHJJVFSsxcovAQ@mail.gmail.com>
References: <4e15ccb966c041f68ea042459324d02c@EX-0-HT0.lancs.local>
	<CANVKczOEg6e3b7U1rYd1nQzJQOtxXGc+e=6cvHJJVFSsxcovAQ@mail.gmail.com>
Message-ID: <5c05350f-ea20-b8c2-5f97-2af3a05f9052@auckland.ac.nz>

On 28/03/17 04:21, Barry Rowlingson wrote:
> On Mon, Mar 27, 2017 at 1:17 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> Is there any way to trap/detect the use of an optional argument called
>> "X" and thereby issue a more perspicuous error message?
>>
>> This would be helpful to those users who, like myself, are bears of very
>> little brain.
>>
>> Failing that (it does look impossible)
>
> You can get the names of named arguments:
>
>  > z = function(x,X){cos(x*X)}
>  > names(formals(z))
>  [1] "x" "X"

That doesn't seem to help.  I tried putting a browser inside lapply()
and looked at formals(FUN).  This gave NULL, because FUN has already 
been taken to be the list argument "x" to which lapply() is being applied.

>> might it not be a good idea to
>> add a warning to the help for lapply(), to the effect that if FUN has an
>> optional argument named "X" then passing this argument via "..." will
>> cause this argument to be taken as the first argument to lapply() and
>> thereby induce an error?
>
> Another idea might be to use purrr:map instead, which is quite happy
> with X in your function:
>
>  >  xxx <- purrr::map(y,function(x,X){cos(x*X)},X=2*pi)
>  > xxx
> [[1]]
> [1] 0.08419541
>
> [[2]]
> [1] 0.6346404
>
> [[3]]
> [1] 0.9800506
>
> [[4]]
> [1] 0.8686734
>
> [[5]]
> [1] -0.9220073
>
> But don't feed `.x` to your purrrring cats, or fails silently:
>
>  >  xxx <- purrr::map(y,function(x,.x){cos(x*.x)},.x=2*pi)
>  > xxx
> [[1]]
> NULL
>
> But who would have a function with `.x` as an argument?

Indeed.  It struck me that a possible workaround would be to change the 
name of the first argument of lapply() from "X" to ".X".  No-one would 
have a function with an argument names ".X" --- at least I wouldn't, so 
this would solve the problem for me.

It seems to me that this change could be made without breaking anything.
But perhaps I am engaging in my usual PollyAnna-ish optimism! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ccberry at ucsd.edu  Tue Mar 28 04:26:55 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Mon, 27 Mar 2017 19:26:55 -0700
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>
References: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>
Message-ID: <alpine.OSX.2.20.1703271912020.6811@charles-berrys-macbook.local>

On Mon, 27 Mar 2017, Rolf Turner wrote:

>
> From time to time I get myself into a state of bewilderment when using
> apply() by calling it with FUN equal to a function which has an "optional" 
> argument named "X".
>
> E.g.
>
>    xxx <- lapply(y,function(x,X){cos(x*X)},X=2*pi)
>
> which produces the error message
>
>> Error in get(as.character(FUN), mode = "function", envir = envir) :
>>   object 'y' of mode 'function' was not found
>
> This of course happens because the name of the first argument of lapply() is 
> "X" and so it takes the value of this first argument to be the supplied X 
> (2*pi in the foregoing example) and then expects what the user has denoted by 
> "y" to be the value of FUN, and (obviously!) it isn't.
>

The lapply help page addresses this issue in `Details' :

"it is good practice to name the first two arguments X and FUN if ... is 
passed through: this both avoids partial matching to FUN and ensures that 
a sensible error message is given if arguments named X or FUN are passed 
through ..."

So that advice suggests something like:

xxx <- lapply( X=y, FUN=function(X,x){cos(X*x)}, x=2*pi )

Best,

Chuck


From jorismeys at gmail.com  Tue Mar 28 12:03:57 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 28 Mar 2017 12:03:57 +0200
Subject: [Rd] `[` not recognized as a primitive in certain cases.
Message-ID: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>

Dear,

I have noticed this problem while looking at the following question on
Stackoverflow :

http://stackoverflow.com/questions/42894213/s4-class-subset-inheritance-with-additional-arguments

While going through callNextMethod, I've noticed the following odd
behaviour:

mc <- call("[",iris,2,"Species")

mc[[1]]
## `[`

is.primitive(`[`)
## [1] TRUE

is.primitive(mc[[1]])
## [1] FALSE
# Expected to be TRUE

mc2 <- as.call(list(`[`,iris,2,"Species"))

is.primitive(mc2[[1]])
## [1] TRUE

So depending on how I construct the call (using call() or as.call() ), the
function `[` is or is not recognized as a primitive by is.primitive()

The behaviour is counterintuitive and -unless I miss something obvious
here- likely to be a bug imho. I immediately admit that my C chops aren't
sufficient to come up with a patch.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Tue Mar 28 14:46:56 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 28 Mar 2017 05:46:56 -0700
Subject: [Rd] `[` not recognized as a primitive in certain cases.
In-Reply-To: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>
References: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>
Message-ID: <CAOQ5NyfDoxZ-8Ga+WfHSBqnutsvN+=FNYJxgGM1hfNWn3UkWwQ@mail.gmail.com>

There is a difference between the symbol and the function (primitive
or closure) to which it is bound.

This:
mc2 <- as.call(list(`[`,iris,2,"Species"))

Evaluates `[` to its value, in this case the primitive object, and the
primitive itself is incorporated into the returned call.

If you were to do this:
mc2 <- as.call(list(quote(`[`),iris,2,"Species"))

The `[` would _not_ be evaluated, quote() would return the symbol, and
the symbol would end up in the call.

The two forms have virtually identical behavior as long as the call
ends up getting evaluated in the same environment.

On Tue, Mar 28, 2017 at 3:03 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Dear,
>
> I have noticed this problem while looking at the following question on
> Stackoverflow :
>
> http://stackoverflow.com/questions/42894213/s4-class-subset-inheritance-with-additional-arguments
>
> While going through callNextMethod, I've noticed the following odd
> behaviour:
>
> mc <- call("[",iris,2,"Species")
>
> mc[[1]]
> ## `[`
>
> is.primitive(`[`)
> ## [1] TRUE
>
> is.primitive(mc[[1]])
> ## [1] FALSE
> # Expected to be TRUE
>
> mc2 <- as.call(list(`[`,iris,2,"Species"))
>
> is.primitive(mc2[[1]])
> ## [1] TRUE
>
> So depending on how I construct the call (using call() or as.call() ), the
> function `[` is or is not recognized as a primitive by is.primitive()
>
> The behaviour is counterintuitive and -unless I miss something obvious
> here- likely to be a bug imho. I immediately admit that my C chops aren't
> sufficient to come up with a patch.
>
> Cheers
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lukas.stadler at oracle.com  Tue Mar 28 14:49:55 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Tue, 28 Mar 2017 14:49:55 +0200
Subject: [Rd] `[` not recognized as a primitive in certain cases.
In-Reply-To: <CAOQ5NyfDoxZ-8Ga+WfHSBqnutsvN+=FNYJxgGM1hfNWn3UkWwQ@mail.gmail.com>
References: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>
	<CAOQ5NyfDoxZ-8Ga+WfHSBqnutsvN+=FNYJxgGM1hfNWn3UkWwQ@mail.gmail.com>
Message-ID: <26E86B1F-1BF0-4DDF-BAA9-CA03FCDE573D@oracle.com>

?typeof? is your friend here:

> typeof(`[`)
[1] "special"
> typeof(mc[[1]])
[1] "symbol"
> typeof(mc2[[1]])
[1] "special"

so mc[[1]] is a symbol, and thus not a primitive.

- Lukas

> On 28 Mar 2017, at 14:46, Michael Lawrence <lawrence.michael at gene.com> wrote:
> 
> There is a difference between the symbol and the function (primitive
> or closure) to which it is bound.
> 
> This:
> mc2 <- as.call(list(`[`,iris,2,"Species"))
> 
> Evaluates `[` to its value, in this case the primitive object, and the
> primitive itself is incorporated into the returned call.
> 
> If you were to do this:
> mc2 <- as.call(list(quote(`[`),iris,2,"Species"))
> 
> The `[` would _not_ be evaluated, quote() would return the symbol, and
> the symbol would end up in the call.
> 
> The two forms have virtually identical behavior as long as the call
> ends up getting evaluated in the same environment.
> 
> On Tue, Mar 28, 2017 at 3:03 AM, Joris Meys <jorismeys at gmail.com> wrote:
>> Dear,
>> 
>> I have noticed this problem while looking at the following question on
>> Stackoverflow :
>> 
>> http://stackoverflow.com/questions/42894213/s4-class-subset-inheritance-with-additional-arguments
>> 
>> While going through callNextMethod, I've noticed the following odd
>> behaviour:
>> 
>> mc <- call("[",iris,2,"Species")
>> 
>> mc[[1]]
>> ## `[`
>> 
>> is.primitive(`[`)
>> ## [1] TRUE
>> 
>> is.primitive(mc[[1]])
>> ## [1] FALSE
>> # Expected to be TRUE
>> 
>> mc2 <- as.call(list(`[`,iris,2,"Species"))
>> 
>> is.primitive(mc2[[1]])
>> ## [1] TRUE
>> 
>> So depending on how I construct the call (using call() or as.call() ), the
>> function `[` is or is not recognized as a primitive by is.primitive()
>> 
>> The behaviour is counterintuitive and -unless I miss something obvious
>> here- likely to be a bug imho. I immediately admit that my C chops aren't
>> sufficient to come up with a patch.
>> 
>> Cheers
>> Joris
>> 
>> --
>> Joris Meys
>> Statistical consultant
>> 
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Mathematical Modelling, Statistics and Bio-Informatics
>> 
>> tel :  +32 (0)9 264 61 79
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Tue Mar 28 15:19:14 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 28 Mar 2017 15:19:14 +0200
Subject: [Rd] `[` not recognized as a primitive in certain cases.
In-Reply-To: <26E86B1F-1BF0-4DDF-BAA9-CA03FCDE573D@oracle.com>
References: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>
	<CAOQ5NyfDoxZ-8Ga+WfHSBqnutsvN+=FNYJxgGM1hfNWn3UkWwQ@mail.gmail.com>
	<26E86B1F-1BF0-4DDF-BAA9-CA03FCDE573D@oracle.com>
Message-ID: <CAO1zAVYGB=TbsRcd8LAm-Y5wsgCaJ1ofFs4oStimKmRyhtzcag@mail.gmail.com>

Thank you gents, I overlooked the subtle differences.

On Tue, Mar 28, 2017 at 2:49 PM, Lukas Stadler <lukas.stadler at oracle.com>
wrote:

> ?typeof? is your friend here:
>
> > typeof(`[`)
> [1] "special"
> > typeof(mc[[1]])
> [1] "symbol"
> > typeof(mc2[[1]])
> [1] "special"
>
> so mc[[1]] is a symbol, and thus not a primitive.
>
> - Lukas
>
> > On 28 Mar 2017, at 14:46, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
> >
> > There is a difference between the symbol and the function (primitive
> > or closure) to which it is bound.
> >
> > This:
> > mc2 <- as.call(list(`[`,iris,2,"Species"))
> >
> > Evaluates `[` to its value, in this case the primitive object, and the
> > primitive itself is incorporated into the returned call.
> >
> > If you were to do this:
> > mc2 <- as.call(list(quote(`[`),iris,2,"Species"))
> >
> > The `[` would _not_ be evaluated, quote() would return the symbol, and
> > the symbol would end up in the call.
> >
> > The two forms have virtually identical behavior as long as the call
> > ends up getting evaluated in the same environment.
> >
> > On Tue, Mar 28, 2017 at 3:03 AM, Joris Meys <jorismeys at gmail.com> wrote:
> >> Dear,
> >>
> >> I have noticed this problem while looking at the following question on
> >> Stackoverflow :
> >>
> >> http://stackoverflow.com/questions/42894213/s4-class-
> subset-inheritance-with-additional-arguments
> >>
> >> While going through callNextMethod, I've noticed the following odd
> >> behaviour:
> >>
> >> mc <- call("[",iris,2,"Species")
> >>
> >> mc[[1]]
> >> ## `[`
> >>
> >> is.primitive(`[`)
> >> ## [1] TRUE
> >>
> >> is.primitive(mc[[1]])
> >> ## [1] FALSE
> >> # Expected to be TRUE
> >>
> >> mc2 <- as.call(list(`[`,iris,2,"Species"))
> >>
> >> is.primitive(mc2[[1]])
> >> ## [1] TRUE
> >>
> >> So depending on how I construct the call (using call() or as.call() ),
> the
> >> function `[` is or is not recognized as a primitive by is.primitive()
> >>
> >> The behaviour is counterintuitive and -unless I miss something obvious
> >> here- likely to be a bug imho. I immediately admit that my C chops
> aren't
> >> sufficient to come up with a patch.
> >>
> >> Cheers
> >> Joris
> >>
> >> --
> >> Joris Meys
> >> Statistical consultant
> >>
> >> Ghent University
> >> Faculty of Bioscience Engineering
> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
> >>
> >> tel :  +32 (0)9 264 61 79
> >> Joris.Meys at Ugent.be
> >> -------------------------------
> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Mar 28 23:30:17 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 29 Mar 2017 10:30:17 +1300
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <alpine.OSX.2.20.1703271912020.6811@charles-berrys-macbook.local>
References: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>
	<alpine.OSX.2.20.1703271912020.6811@charles-berrys-macbook.local>
Message-ID: <0242d8a3-8d74-2036-e9a8-d1bfbd8aaef5@auckland.ac.nz>

On 28/03/17 15:26, Charles C. Berry wrote:
> On Mon, 27 Mar 2017, Rolf Turner wrote:
>
>>
>> From time to time I get myself into a state of bewilderment when using
>> apply() by calling it with FUN equal to a function which has an
>> "optional" argument named "X".
>>
>> E.g.
>>
>>    xxx <- lapply(y,function(x,X){cos(x*X)},X=2*pi)
>>
>> which produces the error message
>>
>>> Error in get(as.character(FUN), mode = "function", envir = envir) :
>>>   object 'y' of mode 'function' was not found
>>
>> This of course happens because the name of the first argument of
>> lapply() is "X" and so it takes the value of this first argument to be
>> the supplied X (2*pi in the foregoing example) and then expects what
>> the user has denoted by "y" to be the value of FUN, and (obviously!)
>> it isn't.
>>
>
> The lapply help page addresses this issue in `Details' :
>
> "it is good practice to name the first two arguments X and FUN if ... is
> passed through: this both avoids partial matching to FUN and ensures
> that a sensible error message is given if arguments named X or FUN are
> passed through ..."
>
> So that advice suggests something like:
>
> xxx <- lapply( X=y, FUN=function(X,x){cos(X*x)}, x=2*pi )


That is of course very sound advice, but it pre-supposes that the user 
is *aware* that there is a pitfall to be avoided.  I was hoping for 
something that would protect dweebs like myself from the pitfall given 
that we are too obtuse to be cognizant of its existence.

I think that the suggestion I made, in response to a posting by Barry 
Rowlingson, that the first argument of lapply() be given the name of 
".X" rather than just-plain-X, would be (a) effective, and (b) harmless.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wdunlap at tibco.com  Wed Mar 29 00:03:07 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 28 Mar 2017 15:03:07 -0700
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <0242d8a3-8d74-2036-e9a8-d1bfbd8aaef5@auckland.ac.nz>
References: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>
	<alpine.OSX.2.20.1703271912020.6811@charles-berrys-macbook.local>
	<0242d8a3-8d74-2036-e9a8-d1bfbd8aaef5@auckland.ac.nz>
Message-ID: <CAF8bMcYBhtpRVYo37ABjzko1sfbK0ck27c03xJ-kqpniykPjww@mail.gmail.com>

>I think that the suggestion I made, in response to a posting by Barry >Rowlingson, that the first argument of lapply() be given the name of ".X" rather >than just-plain-X, would be (a) effective, and (b) harmless.

It would break any call to *apply() that used X= to name the first
argument.  There are currently 3020 such calls in the R code in CRAN.

One can avoid the problem by creating the function given as the FUN
argument when one calls lapply() and the like.  Don't give that
function arguments named "X", "FUN", "USE.NAMES", etc. and perhaps
make use of R's lexical scoping to avoid having to use many arguments
to the function.  E.g., instead of
    sapply(1:5, sin)
use
    sapply(1:5, function(theta) sin(theta))
or instead of
    myY <- 3
    sapply(1:5, atan2, y=myY)
use
    myY <- 3
    sapply(1:5, function(x) atan2(myY, x))

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Mar 28, 2017 at 2:30 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 28/03/17 15:26, Charles C. Berry wrote:
>>
>> On Mon, 27 Mar 2017, Rolf Turner wrote:
>>
>>>
>>> From time to time I get myself into a state of bewilderment when using
>>> apply() by calling it with FUN equal to a function which has an
>>> "optional" argument named "X".
>>>
>>> E.g.
>>>
>>>    xxx <- lapply(y,function(x,X){cos(x*X)},X=2*pi)
>>>
>>> which produces the error message
>>>
>>>> Error in get(as.character(FUN), mode = "function", envir = envir) :
>>>>   object 'y' of mode 'function' was not found
>>>
>>>
>>> This of course happens because the name of the first argument of
>>> lapply() is "X" and so it takes the value of this first argument to be
>>> the supplied X (2*pi in the foregoing example) and then expects what
>>> the user has denoted by "y" to be the value of FUN, and (obviously!)
>>> it isn't.
>>>
>>
>> The lapply help page addresses this issue in `Details' :
>>
>> "it is good practice to name the first two arguments X and FUN if ... is
>> passed through: this both avoids partial matching to FUN and ensures
>> that a sensible error message is given if arguments named X or FUN are
>> passed through ..."
>>
>> So that advice suggests something like:
>>
>> xxx <- lapply( X=y, FUN=function(X,x){cos(X*x)}, x=2*pi )
>
>
>
> That is of course very sound advice, but it pre-supposes that the user is
> *aware* that there is a pitfall to be avoided.  I was hoping for something
> that would protect dweebs like myself from the pitfall given that we are too
> obtuse to be cognizant of its existence.
>
> I think that the suggestion I made, in response to a posting by Barry
> Rowlingson, that the first argument of lapply() be given the name of ".X"
> rather than just-plain-X, would be (a) effective, and (b) harmless.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From r.turner at auckland.ac.nz  Wed Mar 29 06:04:36 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 29 Mar 2017 17:04:36 +1300
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <CAF8bMcYBhtpRVYo37ABjzko1sfbK0ck27c03xJ-kqpniykPjww@mail.gmail.com>
References: <b2f95986-2a82-e9d7-d5a2-32ffac793461@auckland.ac.nz>
	<alpine.OSX.2.20.1703271912020.6811@charles-berrys-macbook.local>
	<0242d8a3-8d74-2036-e9a8-d1bfbd8aaef5@auckland.ac.nz>
	<CAF8bMcYBhtpRVYo37ABjzko1sfbK0ck27c03xJ-kqpniykPjww@mail.gmail.com>
Message-ID: <a163315d-da49-4bd5-13f1-573b06da64fc@auckland.ac.nz>


On 29/03/17 11:03, William Dunlap wrote:

>> I think that the suggestion I made, in response to a posting by
>> Barry Rowlingson, that the first argument of lapply() be given the name of
>> ".X" rather than just-plain-X, would be (a) effective, and (b) harmless.
>
> It would break any call to *apply() that used X= to name the first
> argument. There are currently 3020 such calls in the R code in CRAN.

Okay.  Scratch that idea.

> One can avoid the problem by creating the function given as the FUN
> argument when one calls lapply() and the like.  Don't give that
> function arguments named "X", "FUN", "USE.NAMES", etc. and perhaps
> make use of R's lexical scoping to avoid having to use many arguments
> to the function.  E.g., instead of
>     sapply(1:5, sin)
> use
>     sapply(1:5, function(theta) sin(theta))
> or instead of
>     myY <- 3
>     sapply(1:5, atan2, y=myY)
> use
>     myY <- 3
>     sapply(1:5, function(x) atan2(myY, x))

Again, all very sound advice but it does not address the problem of 
there being a trap for young players.  The advice can only be applied by 
a user only if the user is *aware* of the trap.

At this point it would appear that the problem is fundamentally 
unsolvable. :-(

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From maechler at stat.math.ethz.ch  Wed Mar 29 09:26:35 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Mar 2017 09:26:35 +0200
Subject: [Rd] `[` not recognized as a primitive in certain cases.
In-Reply-To: <CAO1zAVYGB=TbsRcd8LAm-Y5wsgCaJ1ofFs4oStimKmRyhtzcag@mail.gmail.com>
References: <CAO1zAVYLbF9fo8VxO8NKVYvS2yr=GDa3YrO+se8y5bq4QFUr4A@mail.gmail.com>
	<CAOQ5NyfDoxZ-8Ga+WfHSBqnutsvN+=FNYJxgGM1hfNWn3UkWwQ@mail.gmail.com>
	<26E86B1F-1BF0-4DDF-BAA9-CA03FCDE573D@oracle.com>
	<CAO1zAVYGB=TbsRcd8LAm-Y5wsgCaJ1ofFs4oStimKmRyhtzcag@mail.gmail.com>
Message-ID: <22747.25003.656995.696959@stat.math.ethz.ch>

>>>>> Joris Meys <jorismeys at gmail.com>
>>>>>     on Tue, 28 Mar 2017 15:19:14 +0200 writes:

    > Thank you gents, I overlooked the subtle differences.

    > On Tue, Mar 28, 2017 at 2:49 PM, Lukas Stadler <lukas.stadler at oracle.com>
    > wrote:

    >> ?typeof? is your friend here:
    >> 
    >> > typeof(`[`)
    >> [1] "special"
    >> > typeof(mc[[1]])
    >> [1] "symbol"
    >> > typeof(mc2[[1]])
    >> [1] "special"
    >> 
    >> so mc[[1]] is a symbol, and thus not a primitive.

or  str()  which should be better known to Joe Average useR

> mc <- call("[",iris,2,"Species")
> str(mc[[1]])
 symbol [
> str(`[`)
.Primitive("[") 
> 


    >> - Lukas
    >> 
    >> > On 28 Mar 2017, at 14:46, Michael Lawrence <lawrence.michael at gene.com>
    >> wrote:
    >> >
    >> > There is a difference between the symbol and the function (primitive
    >> > or closure) to which it is bound.
    >> >
    >> > This:
    >> > mc2 <- as.call(list(`[`,iris,2,"Species"))
    >> >
    >> > Evaluates `[` to its value, in this case the primitive object, and the
    >> > primitive itself is incorporated into the returned call.
    >> >
    >> > If you were to do this:
    >> > mc2 <- as.call(list(quote(`[`),iris,2,"Species"))
    >> >
    >> > The `[` would _not_ be evaluated, quote() would return the symbol, and
    >> > the symbol would end up in the call.
    >> >
    >> > The two forms have virtually identical behavior as long as the call
    >> > ends up getting evaluated in the same environment.
    >> >
    >> > On Tue, Mar 28, 2017 at 3:03 AM, Joris Meys <jorismeys at gmail.com> wrote:
    >> >> Dear,
    >> >>
    >> >> I have noticed this problem while looking at the following question on
    >> >> Stackoverflow :
    >> >>
    >> >> http://stackoverflow.com/questions/42894213/s4-class-
    >> subset-inheritance-with-additional-arguments
    >> >>
    >> >> While going through callNextMethod, I've noticed the following odd
    >> >> behaviour:
    >> >>
    >> >> mc <- call("[",iris,2,"Species")
    >> >>
    >> >> mc[[1]]
    >> >> ## `[`
    >> >>
    >> >> is.primitive(`[`)
    >> >> ## [1] TRUE
    >> >>
    >> >> is.primitive(mc[[1]])
    >> >> ## [1] FALSE
    >> >> # Expected to be TRUE
    >> >>
    >> >> mc2 <- as.call(list(`[`,iris,2,"Species"))
    >> >>
    >> >> is.primitive(mc2[[1]])
    >> >> ## [1] TRUE
    >> >>
    >> >> So depending on how I construct the call (using call() or as.call() ),
    >> the
    >> >> function `[` is or is not recognized as a primitive by is.primitive()
    >> >>
    >> >> The behaviour is counterintuitive and -unless I miss something obvious
    >> >> here- likely to be a bug imho. I immediately admit that my C chops
    >> aren't
    >> >> sufficient to come up with a patch.
    >> >>
    >> >> Cheers
    >> >> Joris
    >> >>
    >> >> --
    >> >> Joris Meys
    >> >> Statistical consultant
    >> >>
    >> >> Ghent University
    >> >> Faculty of Bioscience Engineering
    >> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
    >> >>
    >> >> tel :  +32 (0)9 264 61 79
    >> >> Joris.Meys at Ugent.be
    >> >> -------------------------------
    >> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
    >> >>
    >> >>        [[alternative HTML version deleted]]
    >> >>
    >> >> ______________________________________________
    >> >> R-devel at r-project.org mailing list
    >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 


    > -- 
    > Joris Meys
    > Statistical consultant

    > Ghent University
    > Faculty of Bioscience Engineering
    > Department of Mathematical Modelling, Statistics and Bio-Informatics

    > tel :  +32 (0)9 264 61 79
    > Joris.Meys at Ugent.be
    > -------------------------------
    > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From es at enricoschumann.net  Wed Mar 29 09:32:54 2017
From: es at enricoschumann.net (Enrico Schumann)
Date: Wed, 29 Mar 2017 09:32:54 +0200
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <5c05350f-ea20-b8c2-5f97-2af3a05f9052@auckland.ac.nz> (Rolf
	Turner's message of "Tue, 28 Mar 2017 10:26:54 +1300")
References: <4e15ccb966c041f68ea042459324d02c@EX-0-HT0.lancs.local>
	<CANVKczOEg6e3b7U1rYd1nQzJQOtxXGc+e=6cvHJJVFSsxcovAQ@mail.gmail.com>
	<5c05350f-ea20-b8c2-5f97-2af3a05f9052@auckland.ac.nz>
Message-ID: <87d1d0a66x.fsf@enricoschumann.net>

(inline)

On Tue, 28 Mar 2017, Rolf Turner writes:

> On 28/03/17 04:21, Barry Rowlingson wrote:
>> On Mon, Mar 27, 2017 at 1:17 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>
>>> Is there any way to trap/detect the use of an optional argument called
>>> "X" and thereby issue a more perspicuous error message?
>>>
>>> This would be helpful to those users who, like myself, are bears of very
>>> little brain.
>>>
>>> Failing that (it does look impossible)
>>
>> You can get the names of named arguments:
>>
>>  > z = function(x,X){cos(x*X)}
>>  > names(formals(z))
>>  [1] "x" "X"
>
> That doesn't seem to help.  I tried putting a browser inside lapply()
> and looked at formals(FUN).  This gave NULL, because FUN has already
> been taken to be the list argument "x" to which lapply() is being
> applied.

You can get the call, without the arguments being
matched, with `sys.call`. In your call of lapply,
saying `sys.call()` before anything else would give
you


    lapply(y, function(x, X) {
        cos(x * X)
    }, X = 2 * pi)

which would allow you to get at the argument names of
your function.

    if ("X" %in% names(sys.call()[[3L]][[2L]]))
       warnings("found 'X'")

But more would be needed: you need to figure out which
argument you actually meant to be FUN. (In the above,
I simply assumed it was the second passed argument.)
That is, you would need to figure out which passed
argument is a function, which is not safe either,
since ... may also contain functions.


>>> might it not be a good idea to
>>> add a warning to the help for lapply(), to the effect that if FUN has an
>>> optional argument named "X" then passing this argument via "..." will
>>> cause this argument to be taken as the first argument to lapply() and
>>> thereby induce an error?
>>
>> Another idea might be to use purrr:map instead, which is quite happy
>> with X in your function:
>>
>>  >  xxx <- purrr::map(y,function(x,X){cos(x*X)},X=2*pi)
>>  > xxx
>> [[1]]
>> [1] 0.08419541
>>
>> [[2]]
>> [1] 0.6346404
>>
>> [[3]]
>> [1] 0.9800506
>>
>> [[4]]
>> [1] 0.8686734
>>
>> [[5]]
>> [1] -0.9220073
>>
>> But don't feed `.x` to your purrrring cats, or fails silently:
>>
>>  >  xxx <- purrr::map(y,function(x,.x){cos(x*.x)},.x=2*pi)
>>  > xxx
>> [[1]]
>> NULL
>>
>> But who would have a function with `.x` as an argument?
>
> Indeed.  It struck me that a possible workaround would be to change
> the name of the first argument of lapply() from "X" to ".X".  No-one
> would have a function with an argument names ".X" --- at least I
> wouldn't, so this would solve the problem for me.
>
> It seems to me that this change could be made without breaking anything.
> But perhaps I am engaging in my usual PollyAnna-ish optimism! :-)
>
> cheers,
>
> Rolf

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From tkeitt at utexas.edu  Wed Mar 29 17:24:18 2017
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 29 Mar 2017 10:24:18 -0500
Subject: [Rd] Transferring ownership of R-managed buffer
Message-ID: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>

I have a use case where I would like to create an SEXP around an existing
buffer that is managed by R, thus avoiding a copy operation. If I have
something like:

void *p = (void*) RAW(PROTECT(Rf_allocVector(RAWSXP, n)));
... additional maniupulation ...
SEXP x = somefunc(SXPTYPE, n, p);  // ????

Is there a "placement" constructor available? (I have arranged for the
corresponding UNPROTECT.) I've looked at and experimented with R_allocator
and allocVector3, but can't quite get it right. I know this is odd, but it
makes sense for my use case.

Thanks for any pointers.

THK

http://www.keittlab.org/

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Wed Mar 29 20:04:34 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 29 Mar 2017 11:04:34 -0700
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
Message-ID: <bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>

Hi Tim,

On 03/29/2017 08:24 AM, Tim Keitt wrote:
> I have a use case where I would like to create an SEXP around an existing
> buffer that is managed by R, thus avoiding a copy operation.

What to you mean exactly by "an existing buffer managed by R"?

> If I have
> something like:
>
> void *p = (void*) RAW(PROTECT(Rf_allocVector(RAWSXP, n)));
> ... additional maniupulation ...
> SEXP x = somefunc(SXPTYPE, n, p);  // ????
>
> Is there a "placement" constructor available?

What's a "placement" constructor?

>(I have arranged for the
> corresponding UNPROTECT.) I've looked at and experimented with R_allocator
> and allocVector3, but can't quite get it right. I know this is odd, but it
> makes sense for my use case.

Not sure I follow what you are trying to do. Note that an SEXP is a 
pointer to a C struct called SEXPREC. I think that trying to point an
SEXPREC struct to data pointed to by an existing SEXPREC struct is very
likely to lead to a disaster.

Note that if the existing buffer managed by R is an SEXP (e.g. b) and
your code has access to this SEXP then you don't need to create another
SEXP around its data. Since SEXPs are pointers doing

   SEXP x = b;

is fine and doesn't generate any copy.

And if your code only has access to a "naked" pointer to the buffer
managed by R (e.g. to RAW(b) is the buffer is actually in an SEXP)
then why would you need to wrap it inside an SEXP?

H.

>
> Thanks for any pointers.
>
> THK
>
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.keittlab.org_&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=h04DJujKDfqzbLz4FmP3_fZ5bYS3t7UEjSwpLrW5mL0&e=
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=WpLxtWWwjoZ7TjW6oW-vxE6s3LY5kZCG1H5h0xb0Bbs&e=
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Mar 29 20:12:46 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 29 Mar 2017 11:12:46 -0700
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
Message-ID: <4fab7616-b020-804f-7683-6c26985f038c@fredhutch.org>

On 03/29/2017 11:04 AM, Herv? Pag?s wrote:
> Hi Tim,
>
> On 03/29/2017 08:24 AM, Tim Keitt wrote:
>> I have a use case where I would like to create an SEXP around an existing
>> buffer that is managed by R, thus avoiding a copy operation.
>
> What to you mean exactly by "an existing buffer managed by R"?
>
>> If I have
>> something like:
>>
>> void *p = (void*) RAW(PROTECT(Rf_allocVector(RAWSXP, n)));
>> ... additional maniupulation ...
>> SEXP x = somefunc(SXPTYPE, n, p);  // ????
>>
>> Is there a "placement" constructor available?
>
> What's a "placement" constructor?
>
>> (I have arranged for the
>> corresponding UNPROTECT.) I've looked at and experimented with
>> R_allocator
>> and allocVector3, but can't quite get it right. I know this is odd,
>> but it
>> makes sense for my use case.
>
> Not sure I follow what you are trying to do. Note that an SEXP is a
> pointer to a C struct called SEXPREC. I think that trying to point an
> SEXPREC struct to data pointed to by an existing SEXPREC struct is very
> likely to lead to a disaster.
>
> Note that if the existing buffer managed by R is an SEXP (e.g. b) and
> your code has access to this SEXP then you don't need to create another
> SEXP around its data. Since SEXPs are pointers doing
>
>   SEXP x = b;
>
> is fine and doesn't generate any copy.
>
> And if your code only has access to a "naked" pointer to the buffer
> managed by R (e.g. to RAW(b) is the buffer is actually in an SEXP)
                                ^^
                                if

sorry

H.

> then why would you need to wrap it inside an SEXP?
>
> H.
>
>>
>> Thanks for any pointers.
>>
>> THK
>>
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.keittlab.org_&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=h04DJujKDfqzbLz4FmP3_fZ5bYS3t7UEjSwpLrW5mL0&e=
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=WpLxtWWwjoZ7TjW6oW-vxE6s3LY5kZCG1H5h0xb0Bbs&e=
>>
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From tkeitt at utexas.edu  Wed Mar 29 20:36:16 2017
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 29 Mar 2017 13:36:16 -0500
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
Message-ID: <CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>

http://www.keittlab.org/

On Wed, Mar 29, 2017 at 1:04 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> Hi Tim,
>
> On 03/29/2017 08:24 AM, Tim Keitt wrote:
>
>> I have a use case where I would like to create an SEXP around an existing
>> buffer that is managed by R, thus avoiding a copy operation.
>>
>
> What to you mean exactly by "an existing buffer managed by R"?
>

Not allocated from the general heap, but rather allocated using R's
allocator and therefore returnable (hypothesis!) to the R interpreter as a
vector (not external pointer) without a copy operation.


>
> If I have
>> something like:
>>
>> void *p = (void*) RAW(PROTECT(Rf_allocVector(RAWSXP, n)));
>> ... additional maniupulation ...
>> SEXP x = somefunc(SXPTYPE, n, p);  // ????
>>
>> Is there a "placement" constructor available?
>>
>
> What's a "placement" constructor?
>

Function that constructs an object using previously allocated memory (for
example provided by a 3rd party library). In some cases, responsibility for
further management of the buffer is transferred to the new object.


>
> (I have arranged for the
>> corresponding UNPROTECT.) I've looked at and experimented with R_allocator
>> and allocVector3, but can't quite get it right. I know this is odd, but it
>> makes sense for my use case.
>>
>
> Not sure I follow what you are trying to do. Note that an SEXP is a
> pointer to a C struct called SEXPREC. I think that trying to point an
> SEXPREC struct to data pointed to by an existing SEXPREC struct is very
> likely to lead to a disaster.
>

Possibly (although that is not what I am proposing). I'm still trying to
grok where the state resides (all in the SEXPREC or between that and the
allocator).


>
> Note that if the existing buffer managed by R is an SEXP (e.g. b) and
> your code has access to this SEXP then you don't need to create another
> SEXP around its data. Since SEXPs are pointers doing
>
>   SEXP x = b;
>
> is fine and doesn't generate any copy.
>

The buffer in this case might be resized and reallocated and the original
SEXP will have gone out of scope.


>
> And if your code only has access to a "naked" pointer to the buffer
> managed by R (e.g. to RAW(b) is the buffer is actually in an SEXP)
> then why would you need to wrap it inside an SEXP?
>

I'm working with 3rd party structures that can work with a pointer and
buffer length, but cannot track the original SEXP. I just need to construct
an SEXP (SEXPREC) and point it at the buffer, set the vector length and
data type. I was checking to see if there is an API for that (and that wont
interfere with Rcpp declarations as it pulls in parts of Rinternals.h, but
as far as I can tell, not the parts that I need to work with SEXPRECs at a
low-level).

THK


> H.
>
>
>> Thanks for any pointers.
>>
>> THK
>>
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.keit
>> tlab.org_&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWd
>> GbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqw
>> y8wiRy6hS_lWF9k&s=h04DJujKDfqzbLz4FmP3_fZ5bYS3t7UEjSwpLrW5mL0&e=
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.et
>> hz.ch_mailman_listinfo_r-2Ddevel&d=DwICAg&c=eRAMFD45gAfqt84V
>> tBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5d
>> LU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=WpLxtWWwjoZ7TjW6oW-
>> vxE6s3LY5kZCG1H5h0xb0Bbs&e=
>>
>>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Wed Mar 29 23:56:53 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 29 Mar 2017 14:56:53 -0700
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
	<CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>
Message-ID: <CADwqtCMqvgAweKRJ8=dDf1Lwmsng7tVZMMWndSGvgNnN8VH3=A@mail.gmail.com>

Tim,

What you're describing is a special case of the ALTREP framework/API that
Luke Tierney, Tomas Kalibera, and I are working on putting into R. See my
initial proposal to the DSC here:
https://www.r-project.org/dsc/2016/slides/customvectors.html and the
subsequent branch here: https://svn.r-project.org/R/branches/ALTREP/ where
Luke and I have merged the ideas from that proposal with work he had been
pursuing independently.  The framework is implemented and passes basic
testing (make check all minus the internet checks, from what I recall).

The concept of having a vector which is a "window" into another vector
without duplication ( which I suspect is at least related to your use-case,
though I could be wrong) is a special case of one of alt-representations I
 have implemented there.

Unfortunately we were not able to get it ready in time for this upcoming
release (it is a rather sizable change to the internals), but we hope to
merge it into R-devel not too long after (there isn't a specific timeline
currently AFAIK). I know that the release after next is quite a long wait
but unfortunately that is how it played out. So anyway, in the future this
will be easy to do, and what you are trying to do may even happen
automatically.

More comments inline.

On Wed, Mar 29, 2017 at 11:36 AM, Tim Keitt <tkeitt at utexas.edu> wrote:

> http://www.keittlab.org/
>
> On Wed, Mar 29, 2017 at 1:04 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>
> > Hi Tim,
> >
> > On 03/29/2017 08:24 AM, Tim Keitt wrote:
> >
> >> I have a use case where I would like to create an SEXP around an
> existing
> >> buffer that is managed by R, thus avoiding a copy operation.
> >>
> >
> > What to you mean exactly by "an existing buffer managed by R"?
> >
>
> Not allocated from the general heap, but rather allocated using R's
> allocator and therefore returnable (hypothesis!) to the R interpreter as a
> vector (not external pointer) without a copy operation.


>
> >
> > If I have
> >> something like:
> >>
> >> void *p = (void*) RAW(PROTECT(Rf_allocVector(RAWSXP, n)));
> >> ... additional maniupulation ...
> >> SEXP x = somefunc(SXPTYPE, n, p);  // ????
> >>
> >> Is there a "placement" constructor available?
> >>
> >
> > What's a "placement" constructor?
> >
>
> Function that constructs an object using previously allocated memory (for
> example provided by a 3rd party library). In some cases, responsibility for
> further management of the buffer is transferred to the new object.
>

I'm not sure what you mean by this last part, but the rest is one of the
primary use cases of the ALTREP stuff.  I don't think you can do what
you're describing now. See my comments below.


>
> >
> > (I have arranged for the
> >> corresponding UNPROTECT.) I've looked at and experimented with
> R_allocator
> >> and allocVector3, but can't quite get it right. I know this is odd, but
> it
> >> makes sense for my use case.
> >>
> >
> > Not sure I follow what you are trying to do. Note that an SEXP is a
> > pointer to a C struct called SEXPREC. I think that trying to point an
> > SEXPREC struct to data pointed to by an existing SEXPREC struct is very
> > likely to lead to a disaster.
> >
>
> Possibly (although that is not what I am proposing). I'm still trying to
> grok where the state resides (all in the SEXPREC or between that and the
> allocator).
>
>
> >
> > Note that if the existing buffer managed by R is an SEXP (e.g. b) and
> > your code has access to this SEXP then you don't need to create another
> > SEXP around its data. Since SEXPs are pointers doing
> >
> >   SEXP x = b;
> >
> > is fine and doesn't generate any copy.
> >
>
> The buffer in this case might be resized and reallocated and the original
> SEXP will have gone out of scope.
>

I'm a little unclear what you're trying to do here. Traditional atomic
vectors are a SEXP header plus a C array contiguous in memory, where the
SEXP header knows the length of the array. Note that resizing the array is
AFAIK not supported (it's not part of the blessed C api) and the internal
macros that code uses to do this now will have to go away when the ALTREP
branch is merged. That is in fact one of the major reasons we couldn't get
it prepared in time for this release.



>
>
> >
> > And if your code only has access to a "naked" pointer to the buffer
> > managed by R (e.g. to RAW(b) is the buffer is actually in an SEXP)
> > then why would you need to wrap it inside an SEXP?
> >
>
> I'm working with 3rd party structures that can work with a pointer and
> buffer length, but cannot track the original SEXP. I just need to construct
> an SEXP (SEXPREC) and point it at the buffer, set the vector length and
> data type. I was checking to see if there is an API for that (and that wont
> interfere with Rcpp declarations as it pulls in parts of Rinternals.h, but
> as far as I can tell, not the parts that I need to work with SEXPRECs at a
> low-level).
>

Atomic vector SEXPRECs are (and must be) contiguous in memory (header plus
payload), so I don't think what you're wanting is possible without the
ALTREP framework being in place (decoupling header and payload is a major
motivating desire for us). I may misunderstand what you want though.

Best,
~G


> THK
>
>
> > H.
> >
> >
> >> Thanks for any pointers.
> >>
> >> THK
> >>
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.keit
> >> tlab.org_&d=DwICAg&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWd
> >> GbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5dLU_mdGwmpIk_iUqE0dPNjqw
> >> y8wiRy6hS_lWF9k&s=h04DJujKDfqzbLz4FmP3_fZ5bYS3t7UEjSwpLrW5mL0&e=
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.et
> >> hz.ch_mailman_listinfo_r-2Ddevel&d=DwICAg&c=eRAMFD45gAfqt84V
> >> tBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Ceu5d
> >> LU_mdGwmpIk_iUqE0dPNjqwy8wiRy6hS_lWF9k&s=WpLxtWWwjoZ7TjW6oW-
> >> vxE6s3LY5kZCG1H5h0xb0Bbs&e=
> >>
> >>
> > --
> > Herv? Pag?s
> >
> > Program in Computational Biology
> > Division of Public Health Sciences
> > Fred Hutchinson Cancer Research Center
> > 1100 Fairview Ave. N, M1-B514
> > P.O. Box 19024
> > Seattle, WA 98109-1024
> >
> > E-mail: hpages at fredhutch.org
> > Phone:  (206) 667-5791
> > Fax:    (206) 667-1319
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel




-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Mar 30 04:53:39 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 30 Mar 2017 15:53:39 +1300
Subject: [Rd] A trap for young players with the lapply() function.
In-Reply-To: <87d1d0a66x.fsf@enricoschumann.net>
References: <4e15ccb966c041f68ea042459324d02c@EX-0-HT0.lancs.local>
	<CANVKczOEg6e3b7U1rYd1nQzJQOtxXGc+e=6cvHJJVFSsxcovAQ@mail.gmail.com>
	<5c05350f-ea20-b8c2-5f97-2af3a05f9052@auckland.ac.nz>
	<87d1d0a66x.fsf@enricoschumann.net>
Message-ID: <ee0da8f1-ae28-9bf7-0c8d-d4609adde5ac@auckland.ac.nz>

On 29/03/17 20:32, Enrico Schumann wrote:
> (inline)
>
> On Tue, 28 Mar 2017, Rolf Turner writes:
>
>> On 28/03/17 04:21, Barry Rowlingson wrote:
>>> On Mon, Mar 27, 2017 at 1:17 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>> Is there any way to trap/detect the use of an optional argument called
>>>> "X" and thereby issue a more perspicuous error message?
>>>>
>>>> This would be helpful to those users who, like myself, are bears of very
>>>> little brain.
>>>>
>>>> Failing that (it does look impossible)
>>>
>>> You can get the names of named arguments:
>>>
>>>  > z = function(x,X){cos(x*X)}
>>>  > names(formals(z))
>>>  [1] "x" "X"
>>
>> That doesn't seem to help.  I tried putting a browser inside lapply()
>> and looked at formals(FUN).  This gave NULL, because FUN has already
>> been taken to be the list argument "x" to which lapply() is being
>> applied.
>
> You can get the call, without the arguments being
> matched, with `sys.call`. In your call of lapply,
> saying `sys.call()` before anything else would give
> you
>
>
>     lapply(y, function(x, X) {
>         cos(x * X)
>     }, X = 2 * pi)
>
> which would allow you to get at the argument names of
> your function.
>
>     if ("X" %in% names(sys.call()[[3L]][[2L]]))
>        warnings("found 'X'")
>
> But more would be needed: you need to figure out which
> argument you actually meant to be FUN. (In the above,
> I simply assumed it was the second passed argument.)
> That is, you would need to figure out which passed
> argument is a function, which is not safe either,
> since ... may also contain functions.


This idea appears to work for the particular example that I used, but it 
is not clear to me how to make it work in general.  E.g. if we define

   foo <- function(x,X){X*x}

and then do

   lapply(xxx,foo,X=2*pI)

we find that sys.call[[3]] is of length 1 and consists only of the 
*name* "foo".  One can then inspect

    formals(get(as.character(sys.call[[3]])))

and find "X" therein, on the basis of which to trigger a warning.

However I don't know how to approach distinguish the two cases, or how 
to discern if there may be other cases lurking in the bushes.

So the problem still looks insoluble to me.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thosjleeper at gmail.com  Thu Mar 30 16:01:42 2017
From: thosjleeper at gmail.com (Thomas J. Leeper)
Date: Thu, 30 Mar 2017 15:01:42 +0100
Subject: [Rd] get_all_vars() does not handle rhs matrices in formulae
Message-ID: <CAOC91MRRS+p3c-X2DezL7T-zxoQMCf4=ZdT_yHsDYg1q5KQSuw@mail.gmail.com>

Hello again,

It appears that get_all_vars() incorrectly handles model formulae that
use a right-hand side (rhs) matrix. For example, consider these two
substantively identical models:

# model using named variables
mpg <- mtcars$mpg
wt <- mtcars$wt
hp <- mtcars$hp
m1 <- lm(mpg ~ wt + hp)

# model using matrix
y <- mtcars$mpg
x <- cbind(mtcars$wt, mtcars$hp)
m2 <- lm(y ~ x)

For the first, get_all_vars() returns the correct data frame:

str(get_all_vars(m1, .GlobalEnv))
## 'data.frame':   32 obs. of  3 variables:
##  $ mpg: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ wt : num  2.62 2.88 2.32 3.21 3.44 ...
##  $ hp : num  110 110 93 110 175 105 245 62 95 123 ...

which could, for example, be passed on to predict() just like the
output from model.frame():

str(predict(m1, model.frame(m1)))
## Named num [1:32] 23.6 22.6 25.3 21.3 18.3 ...
## - attr(*, "names")= chr [1:32] "1" "2" "3" "4" ...

str(predict(m1, get_all_vars(m1)))
## Named num [1:32] 23.6 22.6 25.3 21.3 18.3 ...
## - attr(*, "names")= chr [1:32] "1" "2" "3" "4" ...

For the model specified with a rhs matrix, however, get_all_vars()
returns a three-column data frame with the second matrix column added
as an unnamed third column:

str(get_all_vars(m2, .GlobalEnv))
## 'data.frame':   32 obs. of  3 variables:
##  $ y : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ x : num  2.62 2.88 2.32 3.21 3.44 ...
##  $ NA: num  110 110 93 110 175 105 245 62 95 123 ...

This means attempts to use this data structure in predict() fail:

str(predict(m2, get_all_vars(m2)))
## Error: variable 'x' was fitted with type "nmatrix.2" but type
"numeric" was supplied

The correct structure needs to resemble following in order for that to succeed:

newdat <- data.frame(y = y)
newdat$x <- x
str(newdat)
## 'data.frame':   32 obs. of  2 variables:
##  $ y: num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
##  $ x: num [1:32, 1:2] 2.62 2.88 2.32 3.21 3.44 ...
str(predict(m2, newdat))
##  Named num [1:32] 23.6 22.6 25.3 21.3 18.3 ...
##  - attr(*, "names")= chr [1:32] "1" "2" "3" "4" ...

The correct structure is basically what is returned by model.frame()
in cases involving a rhs matrix:

all.equal(newdat, model.frame(m2), check.attributes = FALSE)
## [1] TRUE

The issue seems to be in one of the very last lines of get_all_vars():

x <- setNames(as.data.frame(c(variables, extras), optional = TRUE),
        c(varnames, extranames))

This both coerces `variables` to the wrong structure (making a
three-column data frame instead of a two-column data frame) and
therefore misnames the resulting columns. I unfortunately don't know
the most sensible/general way to solve this, otherwise I would submit
a patch. Anyone know how to fix this last line?

Best,
-Thomas

Thomas J. Leeper
http://www.thomasleeper.com


From tkeitt at utexas.edu  Thu Mar 30 20:52:47 2017
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 30 Mar 2017 13:52:47 -0500
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <CADwqtCMqvgAweKRJ8=dDf1Lwmsng7tVZMMWndSGvgNnN8VH3=A@mail.gmail.com>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
	<CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>
	<CADwqtCMqvgAweKRJ8=dDf1Lwmsng7tVZMMWndSGvgNnN8VH3=A@mail.gmail.com>
Message-ID: <CANnL8grTGSPtiVPVE4Z6ELa-Od-6j3J=HHWNSEh+7qT3JranRw@mail.gmail.com>

On Wed, Mar 29, 2017 at 4:56 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> The concept of having a vector which is a "window" into another vector
> without duplication ( which I suspect is at least related to your use-case,
> though I could be wrong) is a special case of one of alt-representations I
>  have implemented there.
>

Nice. That is exactly what I need. I was trying out a little experiment,
but I think its not possible right now because the length of an R vector is
identical to the buffer length. I can do everything I need except force the
length of the returned R vector to be only a portion of the allocated
storage.

THK

http://www.keittlab.org/

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Thu Mar 30 22:15:31 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 30 Mar 2017 13:15:31 -0700
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <CANnL8grTGSPtiVPVE4Z6ELa-Od-6j3J=HHWNSEh+7qT3JranRw@mail.gmail.com>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
	<CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>
	<CADwqtCMqvgAweKRJ8=dDf1Lwmsng7tVZMMWndSGvgNnN8VH3=A@mail.gmail.com>
	<CANnL8grTGSPtiVPVE4Z6ELa-Od-6j3J=HHWNSEh+7qT3JranRw@mail.gmail.com>
Message-ID: <CADwqtCM_iTP1ciBaxkLuro34P_uHesJP+O_-7_q9vMsRyrfqGA@mail.gmail.com>

On Thu, Mar 30, 2017 at 11:52 AM, Tim Keitt <tkeitt at utexas.edu> wrote:

>
> On Wed, Mar 29, 2017 at 4:56 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
>
>> The concept of having a vector which is a "window" into another vector
>> without duplication ( which I suspect is at least related to your use-case,
>> though I could be wrong) is a special case of one of alt-representations I
>>  have implemented there.
>>
>
> Nice. That is exactly what I need. I was trying out a little experiment,
> but I think its not possible right now because the length of an R vector is
> identical to the buffer length. I can do everything I need except force the
> length of the returned R vector to be only a portion of the allocated
> storage.
>

To be entirely accurate it's "technically possible but not allowed and
likely to stop working". I.e., it can be done in the current version of R,
but the way that you would do it is a) not part of the API so is not
supported, and b) AFAIK has a good chance of going away entirely (or at
least changing significantly) in R-devel (and thus the R release after this
coming one) during the process of merging the ALTREP branch sometime after
the upcoming release.  That was the last position on the subject I heard
from Luke Tierney, anyway.


Best,
~G


>
> THK
>
> http://www.keittlab.org/
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From tkeitt at utexas.edu  Thu Mar 30 22:31:06 2017
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 30 Mar 2017 15:31:06 -0500
Subject: [Rd] Transferring ownership of R-managed buffer
In-Reply-To: <CADwqtCM_iTP1ciBaxkLuro34P_uHesJP+O_-7_q9vMsRyrfqGA@mail.gmail.com>
References: <CANnL8go0rb+01wbPzygrFO+rEznLsT1K+_buZEzAhAMecNP8RQ@mail.gmail.com>
	<bd43b699-57fb-96a0-e187-7183bf5f7274@fredhutch.org>
	<CANnL8gpW-mKyP4JHN9PEkTRJZL-5qb3x0twrQwWao1x-3W8UJQ@mail.gmail.com>
	<CADwqtCMqvgAweKRJ8=dDf1Lwmsng7tVZMMWndSGvgNnN8VH3=A@mail.gmail.com>
	<CANnL8grTGSPtiVPVE4Z6ELa-Od-6j3J=HHWNSEh+7qT3JranRw@mail.gmail.com>
	<CADwqtCM_iTP1ciBaxkLuro34P_uHesJP+O_-7_q9vMsRyrfqGA@mail.gmail.com>
Message-ID: <CANnL8gpspMbV51nQbFZBaiO6ob6HEOP5f+tAFto0r1an8KaEtQ@mail.gmail.com>

On Thu, Mar 30, 2017 at 3:15 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> technically possible


So the garbage collector knows the buffer length independently of the
SEXPREC length field? Then, yes, its doable, but as you say not advisable.

THK

http://www.keittlab.org/

	[[alternative HTML version deleted]]


From lukas.stadler at oracle.com  Fri Mar 31 14:29:17 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Fri, 31 Mar 2017 14:29:17 +0200
Subject: [Rd] RIOT 2017
Message-ID: <90274FDC-00A7-458B-8159-A76D05EAB566@oracle.com>

I hope you don?t mind us using this mailing list for a small advertisement, but we think it is most relevant for this group:

We'd like to invite you to RIOT 2017 - the 3rd workshop on R Implementation, Optimization and Tooling [1].
It will take place co-located with, and during, useR! 2017 in Brussels on July 5th.
RIOT is an excellent venue for deep technical discussions about R implementations, tools, optimizations and extension, and will be very interesting for anyone interested in what?s under the hood of R implementations.

Regards,
Lukas Stadler (Oracle), Jan Vitek (Northeastern), Alexander Bertram (BeDataDriven)

[1] http://riotworkshop.github.io/ <http://riotworkshop.github.io/>
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Mar 31 19:03:26 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 31 Mar 2017 12:03:26 -0500
Subject: [Rd] iconv documentation error
Message-ID: <47cabe$64tuom@ironport10.mayo.edu>

This caught us yesterday when a string that we assumed to be in UTF-8 was actually using 
CP1252.  (This came from an internal web based service, so the root cause is not R's 
fault.)  The help page for iconv states that the result of an invalid conversion is NA 
only when the toRaw argument is TRUE, but this appears to be true in general.

Example:

test1 <- "M?ni?re's disease"        # the offending string (it was buried in a 13000 
character result string)
test2 <- iconv(test1, to="CP1252")  # create a version of the string that is in 
Window-1252 coding
iconv(test2, from="UTF-8")          # reprise our error
[1] NA

Note that Encoding(test2) returns "latin-1", which is also not quite in alignment with the 
help page.


