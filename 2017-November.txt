From maechler at stat.math.ethz.ch  Wed Nov  1 09:22:26 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Nov 2017 09:22:26 +0100
Subject: [Rd] Debate: Shall some of Microsoft R Open Code be ported to
 mainstream R?
In-Reply-To: <CALEXWq0Lyd2WUQYxKYn=7SSS4gp3KMHL6bdfgpCwi-J3qg0zHg@mail.gmail.com>
References: <CANNd7=mF5jQqWMYymrkx0uNQ5g6B298jj0y66is2gi6wWxUVJQ@mail.gmail.com>
 <CANNd7=nDuTKJwKByrkQW4R7TmO=j0w5kqR867FNzU4UUbbyyKA@mail.gmail.com>
 <CANNd7=n9Y5UDDgA3hn+4XGT9H4Q9BwPKoht2uBnyHBme-qerLA@mail.gmail.com>
 <CANNd7=kuJJE3k=+_3LHAzRyiQcS0HkhiNeNam=N015o7uTgmUg@mail.gmail.com>
 <CANNd7=mng2CL+8XwG4Dq_r5zZT8OP5bevn=ydQFCgAM09+pDbw@mail.gmail.com>
 <CANNd7=mafvMdEChnpwDYu49tcvRpSUXt79=fHroduhLB2ss1LQ@mail.gmail.com>
 <CANNd7=ky-7aQc-OjtPHDTPxMKxwkzyuWAGYPaVSJTsKfFg1v8w@mail.gmail.com>
 <CANNd7=mNYabPvvNEKEtKmhQXFV-uO-teERxLYOz1=sD=_w6epg@mail.gmail.com>
 <CANNd7==8Sgf2ueA08wpROe6CrD_n7==Gz7tSr_ncdpK3XPwoSw@mail.gmail.com>
 <CANNd7=ngXVKsaEwyQVmzsuVuQN5Bxcgnwmtk-EJq1ucUBt9iOw@mail.gmail.com>
 <CANNd7=mF44uUA8Y6VdmHV3QnYr_mJdoP2C-MY0-2nzULCSVoCA@mail.gmail.com>
 <CANNd7=m4vdn1jUVPP3+a9g7cTRye_a=PrvSe43eSA_NdvuaStg@mail.gmail.com>
 <CANNd7==usdHMse-okiSLnJZ_Lj_bTSnVLWLsF5O_2-xCAfaCDQ@mail.gmail.com>
 <CANNd7==3TOGYzS0aYNOmeakn2woD+U+o6GfWhKy1-BuR8WfVzQ@mail.gmail.com>
 <CANNd7==P3-yKKJUuka9+Fmajb9c7+b2X516o9hQGThyKQt0d4Q@mail.gmail.com>
 <CAPekMCncKgUyuRDd86ioLkABGG-fAVQZ6FyChgNrrm4orBmq4g@mail.gmail.com>
 <CAL6gwnLxhX2ojubf0S=4M3RCbrk7tRYsAk3pYkCkCGt5cUnkmw@mail.gmail.com>
 <CANNd7=k56MBDsbTiOREvgg81EvP1FM_eKqZPCbi2fyvyicWq=g@mail.gmail.com>
 <CALEXWq0Lyd2WUQYxKYn=7SSS4gp3KMHL6bdfgpCwi-J3qg0zHg@mail.gmail.com>
Message-ID: <23033.33858.676649.311647@stat.math.ethz.ch>

>>>>> I?aki ?car <i.ucar86 at gmail.com>
>>>>>     on Tue, 31 Oct 2017 14:55:44 +0100 writes:

    > 2017-10-31 14:34 GMT+01:00 Juan Telleria
    > <jtelleriar at gmail.com>:
    >> So as long as I can read, OpenBlas, for Windows, might be
    >> a worth considering option: http://www.openblas.net
    >> 
    >> But Intel MKL also seems to be free*:
    >> https://software.intel.com/en-us/articles/free-mkl

    > install.packages("rmsfact") 
    > sub(".*because ", "", rmsfact::rmsfact(8))

"Amen"!

... and thank you I?aki  for alerting us to the rmsfact package.
Cool!  

Martin Maechler
ETH Zurich and R Core Team


From lille.stor at gmx.com  Wed Nov  1 19:37:19 2017
From: lille.stor at gmx.com (lille stor)
Date: Wed, 1 Nov 2017 19:37:19 +0100
Subject: [Rd] Memory address of character datatype
Message-ID: <trinity-3377bf0b-206d-450a-8735-ae632809ac54-1509561439669@3c-app-mailcom-bs12>

Hi,
?
To get the memory address of where the value of variable "x" (of datatype "numeric") is stored one does the following in R (in 32 bit):
?
??? ? library(pryr)
? ?? ?x <- 1024
?? ?? addr <- as.numeric(address(x)) +?24?? ?# 24 is needed to jump the variable info and point to the data itself (i.e. 1024)
?
The question now is what is the value of the jump?so that one can?obtain the memory address of where the value of variable "x" (of datatype "character"):
?

????? library(pryr)
? ??? x <- "abc"
?? ?? addr <- as.numeric(address(x)) +?????? # what should be the value of the jump so that?it points to the data of variable "x" (i.e. abc)?
?
Thank you in advance!


From arietencate at gmail.com  Thu Nov  2 07:51:13 2017
From: arietencate at gmail.com (Arie ten Cate)
Date: Thu, 2 Nov 2017 07:51:13 +0100
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
Message-ID: <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>

Hello Tyler,

Thank you for searching for, and finding, the basic description of the
behavior of R in this matter.

I think your example is in agreement with the book.

But let me first note the following. You write: "F_j refers to a
factor (variable) in a model and not a categorical factor". However:
"a factor is a vector object used to specify a discrete
classification" (start of chapter 4 of "An Introduction to R".) You
might also see the description of the R function factor().

You note that the book says about a factor F_j:
  "... F_j is coded by contrasts if T_{i(j)} has appeared in the
formula and by dummy variables if it has not"

You find:
   "However, the example I gave demonstrated that this dummy variable
encoding only occurs for the model where the missing term is the
numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."

We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in T_i
must be encoded by dummy variables, as indeed it is.

  Arie

On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
> Hi Arie,
>
> Thank you for your further research into the issue.
>
> Regarding Stata: On the other hand, JMP gives model matrices that use the
> main effects contrasts in computing the higher order interactions, without
> the dummy variable encoding. I verified this both by analyzing the linear
> model given in my first example and noting that JMP has one more degree of
> freedom than R for the same model, as well as looking at the generated model
> matrices. It's easy to find a design where JMP will allow us fit our model
> with goodness-of-fit estimates and R will not due to the extra degree(s) of
> freedom required. Let's keep the conversation limited to R.
>
> I want to refocus back onto my original bug report, which was not for a
> missing main effects term, but rather for a missing lower-order interaction
> term. The behavior of model.matrix.default() for a missing main effects term
> is a nice example to demonstrate how model.matrix encodes with dummy
> variables instead of contrasts, but doesn't demonstrate the inconsistent
> behavior my bug report highlighted.
>
> I went looking for documentation on this behavior, and the issue stems not
> from model.matrix.default(), but rather the terms() function in interpreting
> the formula. This "clever" replacement of contrasts by dummy variables to
> maintain marginality (presuming that's the reason) is not described anywhere
> in the documentation for either the model.matrix() or the terms() function.
> In order to find a description for the behavior, I had to look in the
> underlying C code, buried above the "TermCode" function of the "model.c"
> file, which says:
>
> "TermCode decides on the encoding of a model term. Returns 1 if variable
> ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if it is to
> be encoded by dummy variables.  This is decided using the heuristic
> described in Statistical Models in S, page 38."
>
> I do not have a copy of this book, and I suspect most R users do not as
> well. Thankfully, however, some of the pages describing this behavior were
> available as part of Amazon's "Look Inside" feature--but if not for that, I
> would have no idea what heuristic R was using. Since those pages could made
> unavailable by Amazon at any time, at the very least we have an problem with
> a lack of documentation.
>
> However, I still believe there is a bug when comparing R's implementation to
> the heuristic described in the book. From Statistical Models in S, page
> 38-39:
>
> "Suppose F_j is any factor included in term T_i. Let T_{i(j)} denote the
> margin of T_i for factor F_j--that is, the term obtained by dropping F_j
> from T_i. We say that T_{i(j)} has appeared in the formula if there is some
> term T_i' for i' < i such that T_i' contains all the factors appearing in
> T_{i(j)}. The usual case is that T_{i(j)} itself is one of the preceding
> terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in the
> formula and by dummy variables if it has not"
>
> Here, F_j refers to a factor (variable) in a model and not a categorical
> factor, as specified later in that section (page 40): "Numeric variables
> appear in the computations as themselves, uncoded. Therefore, the rule does
> not do anything special for them, and it remains valid, in a trivial sense,
> whenever any of the F_j is numeric rather than categorical."
>
> Going back to my original example with three variables: X1 (numeric), X2
> (numeric), X3 (categorical). This heuristic prescribes encoding X1:X2:X3
> with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the formula. When
> any of the preceding terms do not exist, this heuristic tells us to use
> dummy variables to encode the interaction (e.g. "F_j [the interaction term]
> is coded ... by dummy variables if it [any of the marginal terms obtained by
> dropping a single factor in the interaction] has not [appeared in the
> formula]"). However, the example I gave demonstrated that this dummy
> variable encoding only occurs for the model where the missing term is the
> numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
> interaction term X1:X2:X3 is encoded by contrasts, not dummy variables. This
> is inconsistent with the description of the intended behavior given in the
> book.
>
> Best regards,
> Tyler
>
>
> On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate <arietencate at gmail.com>
> wrote:
>>
>> Hello Tyler,
>>
>> I want to bring to your attention the following document: "What
>> happens if you omit the main effect in a regression model with an
>> interaction?"
>> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a-regression-model-with-an-interaction).
>> This gives a useful review of the problem. Your example is Case 2: a
>> continuous and a categorical regressor.
>>
>> The numerical examples are coded in Stata, and they give the same
>> result as in R. Hence, if this is a bug in R then it is also a bug in
>> Stata. That seems very unlikely.
>>
>> Here is a simulation in R of the above mentioned Case 2 in Stata:
>>
>> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
>> print("Full model")
>> print(model.matrix(~(socst+grp)^2 ,data=df))
>> print("Example 2.1: drop socst")
>> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
>> print("Example 2.2: drop grp")
>> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
>>
>> This gives indeed the following regressors:
>>
>> "Full model"
>> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
>> "Example 2.1: drop socst"
>> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3 socst:grp4
>> "Example 2.2: drop grp"
>> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
>>
>> There is a little bit of R documentation about this, based on the
>> concept of marginality, which typically forbids a model having an
>> interaction but not the corresponding main effects. (You might see the
>> references in https://en.wikipedia.org/wiki/Principle_of_marginality )
>>     See "An Introduction to R", by Venables and Smith and the R Core
>> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
>> details are complicated, model formulae in R will normally generate
>> the models that an expert statistician would expect, provided that
>> marginality is preserved. Fitting, for [a contrary] example, a model
>> with an interaction but not the corresponding main effects will in
>> general lead to surprising results ....".
>>     The Reference Manual states that the R functions dropterm() and
>> addterm() resp. drop or add only terms such that marginality is
>> preserved.
>>
>> Finally, about your singular matrix t(mm)%*%mm. This is in fact
>> Example 2.1 in Case 2 discussed above. As discussed there, in Stata
>> and in R the drop of the continuous variable has no effect on the
>> degrees of freedom here: it is just a reparameterisation of the full
>> model, protecting you against losing marginality... Hence the
>> model.matrix 'mm' is still square and nonsingular after the drop of
>> X1, unless of course when a row is removed from the matrix 'design'
>> when before creating 'mm'.
>>
>>     Arie
>>
>> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
>> > You could possibly try to explain away the behavior for a missing main
>> > effects term, since without the main effects term we don't have main
>> > effect
>> > columns in the model matrix used to compute the interaction columns (At
>> > best this is undocumented behavior--I still think it's a bug, as we know
>> > how we would encode the categorical factors if they were in fact
>> > present.
>> > It's either specified in contrasts.arg or using the default set in
>> > options). However, when all the main effects are present, why would the
>> > three-factor interaction column not simply be the product of the main
>> > effect columns? In my example: we know X1, we know X2, and we know X3.
>> > Why
>> > does the encoding of X1:X2:X3 depend on whether we specified a
>> > two-factor
>> > interaction, AND only changes for specific missing interactions?
>> >
>> > In addition, I can use a two-term example similar to yours to show how
>> > this
>> > behavior results in a singular covariance matrix when, given the desired
>> > factor encoding, it should not be singular.
>> >
>> > We start with a full factorial design for a two-level continuous factor
>> > and
>> > a three-level categorical factor, and remove a single row. This design
>> > matrix does not leave enough degrees of freedom to determine
>> > goodness-of-fit, but should allow us to obtain parameter estimates.
>> >
>> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
>> >> design = design[-1,]
>> >> design
>> >   X1 X2
>> > 2 -1  A
>> > 3  1  B
>> > 4 -1  B
>> > 5  1  C
>> > 6 -1  C
>> >
>> > Here, we first calculate the model matrix for the full model, and then
>> > manually remove the X1 column from the model matrix. This gives us the
>> > model matrix one would expect if X1 were removed from the model. We then
>> > successfully calculate the covariance matrix.
>> >
>> >> mm = model.matrix(~(X1+X2)^2,data=design)
>> >> mm
>> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
>> > 2           1 -1   0   0      0      0
>> > 3           1  1   1   0      1      0
>> > 4           1 -1   1   0     -1      0
>> > 5           1  1   0   1      0      1
>> > 6           1 -1   0   1      0     -1
>> >
>> >> mm = mm[,-2]
>> >> solve(t(mm) %*% mm)
>> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
>> > (Intercept)           1 -1.0 -1.0    0.0    0.0
>> > X2B                  -1  1.5  1.0    0.0    0.0
>> > X2C                  -1  1.0  1.5    0.0    0.0
>> > X1:X2B                0  0.0  0.0    0.5    0.0
>> > X1:X2C                0  0.0  0.0    0.0    0.5
>> >
>> > Here, we see the actual behavior for model.matrix. The undesired
>> > re-coding
>> > of the model matrix interaction term makes the information matrix
>> > singular.
>> >
>> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
>> >> mm
>> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
>> > 2           1   0   0     -1      0      0
>> > 3           1   1   0      0      1      0
>> > 4           1   1   0      0     -1      0
>> > 5           1   0   1      0      0      1
>> > 6           1   0   1      0      0     -1
>> >
>> >> solve(t(mm) %*% mm)
>> > Error in solve.default(t(mm) %*% mm) : system is computationally
>> > singular:
>> > reciprocal condition number = 5.55112e-18
>> >
>> > I still believe this is a bug.
>> >
>> > Best regards,
>> > Tyler Morgan-Wall
>> >
>> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate <arietencate at gmail.com>
>> > wrote:
>> >
>> >> I think it is not a bug. It is a general property of interactions.
>> >> This property is best observed if all variables are factors
>> >> (qualitative).
>> >>
>> >> For example, you have three variables (factors). You ask for as many
>> >> interactions as possible, except an interaction term between two
>> >> particular variables. When this interaction is not a constant, it is
>> >> different for different values of the remaining variable. More
>> >> precisely: for all values of that variable. In other words: you have a
>> >> three-way interaction, with all values of that variable.
>> >>
>> >> An even smaller example is the following script with only two
>> >> variables, each being a factor:
>> >>
>> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
>> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
>> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
>> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
>> >>
>> >> The result is:
>> >>
>> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
>> >> 1           1   0   0   0       0       0
>> >> 2           1   1   0   0       0       0
>> >> 3           1   0   1   0       0       0
>> >> 4           1   1   1   0       1       0
>> >> 5           1   0   0   1       0       0
>> >> 6           1   1   0   1       0       1
>> >>
>> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
>> >> 1           1   0   0       0       0       0
>> >> 2           1   0   0       1       0       0
>> >> 3           1   1   0       0       0       0
>> >> 4           1   1   0       0       1       0
>> >> 5           1   0   1       0       0       0
>> >> 6           1   0   1       0       0       1
>> >>
>> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
>> >> 1           1   0       0       0       0       0
>> >> 2           1   1       0       0       0       0
>> >> 3           1   0       1       0       0       0
>> >> 4           1   1       0       1       0       0
>> >> 5           1   0       0       0       1       0
>> >> 6           1   1       0       0       0       1
>> >>
>> >> Thus, in the second result, we have no main effect of X1. Instead, the
>> >> effect of X1 depends on the value of X2; either A or B or C. In fact,
>> >> this is a two-way interaction, including all three values of X2. In
>> >> the third result, we have no main effect of X2, The effect of X2
>> >> depends on the value of X1; either p or q.
>> >>
>> >> A complicating element with your example seems to be that your X1 and
>> >> X2 are not factors.
>> >>
>> >>    Arie
>> >>
>> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com> wrote:
>> >> > Hi,
>> >> >
>> >> > I recently ran into an inconsistency in the way model.matrix.default
>> >> > handles factor encoding for higher level interactions with
>> >> > categorical
>> >> > variables when the full hierarchy of effects is not present.
>> >> > Depending on
>> >> > which lower level interactions are specified, the factor encoding
>> >> > changes
>> >> > for a higher level interaction. Consider the following minimal
>> >> reproducible
>> >> > example:
>> >> >
>> >> > --------------
>> >> >
>> >> >> runmatrix = expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
>> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2 X3B X3C
>> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> > 1            1  1  1   0   0     1      0      0      0      0
>> >> > 0         0
>> >> > 2            1 -1  1   0   0    -1      0      0      0      0
>> >> > 0         0
>> >> > 3            1  1 -1   0   0    -1      0      0      0      0
>> >> > 0         0
>> >> > 4            1 -1 -1   0   0     1      0      0      0      0
>> >> > 0         0
>> >> > 5            1  1  1   1   0     1      1      0      1      0
>> >> > 1         0
>> >> > 6            1 -1  1   1   0    -1     -1      0      1      0
>> >> > -1         0
>> >> > 7            1  1 -1   1   0    -1      1      0     -1      0
>> >> > -1         0
>> >> > 8            1 -1 -1   1   0     1     -1      0     -1      0
>> >> > 1         0
>> >> > 9            1  1  1   0   1     1      0      1      0      1
>> >> > 0         1
>> >> > 10           1 -1  1   0   1    -1      0     -1      0      1
>> >> > 0        -1
>> >> > 11           1  1 -1   0   1    -1      0      1      0     -1
>> >> > 0        -1
>> >> > 12           1 -1 -1   0   1     1      0     -1      0     -1
>> >> > 0         1
>> >> > attr(,"assign")
>> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
>> >> > attr(,"contrasts")
>> >> > attr(,"contrasts")$X3
>> >> > [1] "contr.treatment"
>> >> >
>> >> > --------------
>> >> >
>> >> > Specifying the full hierarchy gives us what we expect: the
>> >> > interaction
>> >> > columns are simply calculated from the product of the main effect
>> >> columns.
>> >> > The interaction term X1:X2:X3 gives us two columns in the model
>> >> > matrix,
>> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main effects.
>> >> >
>> >> > If we remove either the X2:X3 interaction or the X1:X3 interaction,
>> >> > we
>> >> get
>> >> > what we would expect for the X1:X2:X3 interaction, but when we remove
>> >> > the
>> >> > X1:X2 interaction the encoding for X1:X2:X3 changes completely:
>> >> >
>> >> > --------------
>> >> >
>> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)   (Intercept) X1 X2
>> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> > 1            1  1  1   0   0     1      0      0         0         0
>> >> > 2            1 -1  1   0   0    -1      0      0         0         0
>> >> > 3            1  1 -1   0   0    -1      0      0         0         0
>> >> > 4            1 -1 -1   0   0     1      0      0         0         0
>> >> > 5            1  1  1   1   0     1      1      0         1         0
>> >> > 6            1 -1  1   1   0    -1      1      0        -1         0
>> >> > 7            1  1 -1   1   0    -1     -1      0        -1         0
>> >> > 8            1 -1 -1   1   0     1     -1      0         1         0
>> >> > 9            1  1  1   0   1     1      0      1         0         1
>> >> > 10           1 -1  1   0   1    -1      0      1         0        -1
>> >> > 11           1  1 -1   0   1    -1      0     -1         0        -1
>> >> > 12           1 -1 -1   0   1     1      0     -1         0         1
>> >> > attr(,"assign")
>> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> > attr(,"contrasts")
>> >> > attr(,"contrasts")$X3
>> >> > [1] "contr.treatment"
>> >> >
>> >> >
>> >> >
>> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)   (Intercept) X1 X2
>> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
>> >> > 1            1  1  1   0   0     1      0      0         0         0
>> >> > 2            1 -1  1   0   0    -1      0      0         0         0
>> >> > 3            1  1 -1   0   0    -1      0      0         0         0
>> >> > 4            1 -1 -1   0   0     1      0      0         0         0
>> >> > 5            1  1  1   1   0     1      1      0         1         0
>> >> > 6            1 -1  1   1   0    -1     -1      0        -1         0
>> >> > 7            1  1 -1   1   0    -1      1      0        -1         0
>> >> > 8            1 -1 -1   1   0     1     -1      0         1         0
>> >> > 9            1  1  1   0   1     1      0      1         0         1
>> >> > 10           1 -1  1   0   1    -1      0     -1         0        -1
>> >> > 11           1  1 -1   0   1    -1      0      1         0        -1
>> >> > 12           1 -1 -1   0   1     1      0     -1         0         1
>> >> > attr(,"assign")
>> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> > attr(,"contrasts")
>> >> > attr(,"contrasts")$X3
>> >> > [1] "contr.treatment"
>> >> >
>> >> >
>> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)   (Intercept) X1 X2
>> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B X1:X2:X3C
>> >> > 1            1  1  1   0   0      0      0      0      0         1
>> >> >     0         0
>> >> > 2            1 -1  1   0   0      0      0      0      0        -1
>> >> >     0         0
>> >> > 3            1  1 -1   0   0      0      0      0      0        -1
>> >> >     0         0
>> >> > 4            1 -1 -1   0   0      0      0      0      0         1
>> >> >     0         0
>> >> > 5            1  1  1   1   0      1      0      1      0         0
>> >> >     1         0
>> >> > 6            1 -1  1   1   0     -1      0      1      0         0
>> >> >    -1         0
>> >> > 7            1  1 -1   1   0      1      0     -1      0         0
>> >> >    -1         0
>> >> > 8            1 -1 -1   1   0     -1      0     -1      0         0
>> >> >     1         0
>> >> > 9            1  1  1   0   1      0      1      0      1         0
>> >> >     0         1
>> >> > 10           1 -1  1   0   1      0     -1      0      1         0
>> >> >     0        -1
>> >> > 11           1  1 -1   0   1      0      1      0     -1         0
>> >> >     0        -1
>> >> > 12           1 -1 -1   0   1      0     -1      0     -1         0
>> >> >     0         1
>> >> > attr(,"assign")
>> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
>> >> > attr(,"contrasts")
>> >> > attr(,"contrasts")$X3
>> >> > [1] "contr.treatment"
>> >> >
>> >> > --------------
>> >> >
>> >> > Here, we now see the encoding for the interaction X1:X2:X3 is now the
>> >> > interaction of X1 and X2 with a new encoding for X3 where each factor
>> >> level
>> >> > is represented by its own column. I would expect, given the two
>> >> > column
>> >> > dummy variable encoding for X3, that the X1:X2:X3 column would also
>> >> > be
>> >> two
>> >> > columns regardless of what two-factor interactions we also specified,
>> >> > but
>> >> > in this case it switches to three. If other two factor interactions
>> >> > are
>> >> > missing in addition to X1:X2, this issue still occurs. This also
>> >> > happens
>> >> > regardless of the contrast specified in contrasts.arg for X3. I don't
>> >> > see
>> >> > any reasoning for this behavior given in the documentation, so I
>> >> > suspect
>> >> it
>> >> > is a bug.
>> >> >
>> >> > Best regards,
>> >> > Tyler Morgan-Wall
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-devel at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From tomas.kalibera at gmail.com  Thu Nov  2 10:08:05 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 2 Nov 2017 10:08:05 +0100
Subject: [Rd] Memory address of character datatype
In-Reply-To: <trinity-3377bf0b-206d-450a-8735-ae632809ac54-1509561439669@3c-app-mailcom-bs12>
References: <trinity-3377bf0b-206d-450a-8735-ae632809ac54-1509561439669@3c-app-mailcom-bs12>
Message-ID: <6870f298-a88c-7ce5-553f-c770eb8930c5@gmail.com>

If you were curious about the hidden details of the memory layout in R, 
the best reference is the source code. In your example, you are not 
getting to your string because there is one more pointer in the way, "x" 
is a vector of strings, each string is represented by a pointer.

At C level, there is an API for getting an address of the value, e.g. 
INTEGER(x) or CHAR(STRING_ELT(x)).
At R level, there is no such API.

You should never bypass these APIs.? The restrictions of the APIs allow 
us to change details of the memory layout between svn versions or even 
as the program executes (altrep), in order to save memory or improve 
performance. Also, it means that the layout can be slightly different 
between platforms, e.g. 32-bit vs 64-bit.

Unfortunately address(x) from pryr bypasses the APIs - you should never 
use address(x) in your programs and I wish address(x) did not exist. If 
you had a concrete problem at hand you wanted to solve with 
"address(x)", feel free to ask for a viable solution.

Best
Tomas




On 11/01/2017 07:37 PM, lille stor wrote:
> Hi,
>   
> To get the memory address of where the value of variable "x" (of datatype "numeric") is stored one does the following in R (in 32 bit):
>   
>  ??? ? library(pryr)
>  ? ?? ?x <- 1024
>  ?? ?? addr <- as.numeric(address(x)) +?24?? ?# 24 is needed to jump the variable info and point to the data itself (i.e. 1024)
>   
> The question now is what is the value of the jump?so that one can?obtain the memory address of where the value of variable "x" (of datatype "character"):
>   
>
>  ????? library(pryr)
>  ? ??? x <- "abc"
>  ?? ?? addr <- as.numeric(address(x)) +?????? # what should be the value of the jump so that?it points to the data of variable "x" (i.e. abc)?
>   
> Thank you in advance!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Thu Nov  2 11:44:07 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Nov 2017 11:44:07 +0100
Subject: [Rd] Memory address of character datatype
In-Reply-To: <6870f298-a88c-7ce5-553f-c770eb8930c5@gmail.com>
References: <trinity-3377bf0b-206d-450a-8735-ae632809ac54-1509561439669@3c-app-mailcom-bs12>
 <6870f298-a88c-7ce5-553f-c770eb8930c5@gmail.com>
Message-ID: <EDDD0007-BEAB-4A0B-BD32-3AABEFC7F82A@gmail.com>

I'm not really disagreeing with this, but is not the point of pryr to let you investigate internals from the R level? 

Building code that relies on pryr returning things with specific properties is very likely doubleplusunrecommended by pryr's author as well.

In that spirit, I suppose that you could reasonably wish for features that would let you peek at memory locations and follow pointers around, etc. As long as you don't poke() anything into memory, you are not likely to break anything. (Hmm, unless you try printing non-objects and suchlike...) Of course users should be aware that any change to R internals may invalidate previously working code (e.g., by changing the "24" in the OP's example).  I don't see any such functionality in pryr though.

-pd

> On 2 Nov 2017, at 10:08 , Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> 
> If you were curious about the hidden details of the memory layout in R, the best reference is the source code. In your example, you are not getting to your string because there is one more pointer in the way, "x" is a vector of strings, each string is represented by a pointer.
> 
> At C level, there is an API for getting an address of the value, e.g. INTEGER(x) or CHAR(STRING_ELT(x)).
> At R level, there is no such API.
> 
> You should never bypass these APIs.  The restrictions of the APIs allow us to change details of the memory layout between svn versions or even as the program executes (altrep), in order to save memory or improve performance. Also, it means that the layout can be slightly different between platforms, e.g. 32-bit vs 64-bit.
> 
> Unfortunately address(x) from pryr bypasses the APIs - you should never use address(x) in your programs and I wish address(x) did not exist. If you had a concrete problem at hand you wanted to solve with "address(x)", feel free to ask for a viable solution.
> 
> Best
> Tomas
> 
> 
> 
> 
> On 11/01/2017 07:37 PM, lille stor wrote:
>> Hi,
>>  To get the memory address of where the value of variable "x" (of datatype "numeric") is stored one does the following in R (in 32 bit):
>>         library(pryr)
>>       x <- 1024
>>       addr <- as.numeric(address(x)) + 24    # 24 is needed to jump the variable info and point to the data itself (i.e. 1024)
>>  The question now is what is the value of the jump so that one can obtain the memory address of where the value of variable "x" (of datatype "character"):
>>  
>>       library(pryr)
>>       x <- "abc"
>>       addr <- as.numeric(address(x)) + ??    # what should be the value of the jump so that it points to the data of variable "x" (i.e. abc)?
>>  Thank you in advance!
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tylermw at gmail.com  Thu Nov  2 16:11:51 2017
From: tylermw at gmail.com (Tyler)
Date: Thu, 2 Nov 2017 11:11:51 -0400
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
Message-ID: <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>

Hi Arie,

The book out of which this behavior is based does not use factor (in this
section) to refer to categorical factor. I will again point to this
sentence, from page 40, in the same section and referring to the behavior
under question, that shows F_j is not limited to categorical factors:
"Numeric variables appear in the computations as themselves, uncoded.
Therefore, the rule does not do anything special for them, and it remains
valid, in a trivial sense, whenever any of the F_j is numeric rather than
categorical."

Note the "... whenever any of the F_j is numeric rather than categorical."
Factor here is used in the more general sense of the word, not referring to
the R type "factor." The behavior of R does not match the heuristic that
it's citing.

Best regards,
Tyler

On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com> wrote:

> Hello Tyler,
>
> Thank you for searching for, and finding, the basic description of the
> behavior of R in this matter.
>
> I think your example is in agreement with the book.
>
> But let me first note the following. You write: "F_j refers to a
> factor (variable) in a model and not a categorical factor". However:
> "a factor is a vector object used to specify a discrete
> classification" (start of chapter 4 of "An Introduction to R".) You
> might also see the description of the R function factor().
>
> You note that the book says about a factor F_j:
>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
> formula and by dummy variables if it has not"
>
> You find:
>    "However, the example I gave demonstrated that this dummy variable
> encoding only occurs for the model where the missing term is the
> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
>
> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in T_i
> must be encoded by dummy variables, as indeed it is.
>
>   Arie
>
> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
> > Hi Arie,
> >
> > Thank you for your further research into the issue.
> >
> > Regarding Stata: On the other hand, JMP gives model matrices that use the
> > main effects contrasts in computing the higher order interactions,
> without
> > the dummy variable encoding. I verified this both by analyzing the linear
> > model given in my first example and noting that JMP has one more degree
> of
> > freedom than R for the same model, as well as looking at the generated
> model
> > matrices. It's easy to find a design where JMP will allow us fit our
> model
> > with goodness-of-fit estimates and R will not due to the extra degree(s)
> of
> > freedom required. Let's keep the conversation limited to R.
> >
> > I want to refocus back onto my original bug report, which was not for a
> > missing main effects term, but rather for a missing lower-order
> interaction
> > term. The behavior of model.matrix.default() for a missing main effects
> term
> > is a nice example to demonstrate how model.matrix encodes with dummy
> > variables instead of contrasts, but doesn't demonstrate the inconsistent
> > behavior my bug report highlighted.
> >
> > I went looking for documentation on this behavior, and the issue stems
> not
> > from model.matrix.default(), but rather the terms() function in
> interpreting
> > the formula. This "clever" replacement of contrasts by dummy variables to
> > maintain marginality (presuming that's the reason) is not described
> anywhere
> > in the documentation for either the model.matrix() or the terms()
> function.
> > In order to find a description for the behavior, I had to look in the
> > underlying C code, buried above the "TermCode" function of the "model.c"
> > file, which says:
> >
> > "TermCode decides on the encoding of a model term. Returns 1 if variable
> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if it
> is to
> > be encoded by dummy variables.  This is decided using the heuristic
> > described in Statistical Models in S, page 38."
> >
> > I do not have a copy of this book, and I suspect most R users do not as
> > well. Thankfully, however, some of the pages describing this behavior
> were
> > available as part of Amazon's "Look Inside" feature--but if not for
> that, I
> > would have no idea what heuristic R was using. Since those pages could
> made
> > unavailable by Amazon at any time, at the very least we have an problem
> with
> > a lack of documentation.
> >
> > However, I still believe there is a bug when comparing R's
> implementation to
> > the heuristic described in the book. From Statistical Models in S, page
> > 38-39:
> >
> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)} denote the
> > margin of T_i for factor F_j--that is, the term obtained by dropping F_j
> > from T_i. We say that T_{i(j)} has appeared in the formula if there is
> some
> > term T_i' for i' < i such that T_i' contains all the factors appearing in
> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the preceding
> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in the
> > formula and by dummy variables if it has not"
> >
> > Here, F_j refers to a factor (variable) in a model and not a categorical
> > factor, as specified later in that section (page 40): "Numeric variables
> > appear in the computations as themselves, uncoded. Therefore, the rule
> does
> > not do anything special for them, and it remains valid, in a trivial
> sense,
> > whenever any of the F_j is numeric rather than categorical."
> >
> > Going back to my original example with three variables: X1 (numeric), X2
> > (numeric), X3 (categorical). This heuristic prescribes encoding X1:X2:X3
> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the formula.
> When
> > any of the preceding terms do not exist, this heuristic tells us to use
> > dummy variables to encode the interaction (e.g. "F_j [the interaction
> term]
> > is coded ... by dummy variables if it [any of the marginal terms
> obtained by
> > dropping a single factor in the interaction] has not [appeared in the
> > formula]"). However, the example I gave demonstrated that this dummy
> > variable encoding only occurs for the model where the missing term is the
> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
> > interaction term X1:X2:X3 is encoded by contrasts, not dummy variables.
> This
> > is inconsistent with the description of the intended behavior given in
> the
> > book.
> >
> > Best regards,
> > Tyler
> >
> >
> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate <arietencate at gmail.com>
> > wrote:
> >>
> >> Hello Tyler,
> >>
> >> I want to bring to your attention the following document: "What
> >> happens if you omit the main effect in a regression model with an
> >> interaction?"
> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-
> omit-the-main-effect-in-a-regression-model-with-an-interaction).
> >> This gives a useful review of the problem. Your example is Case 2: a
> >> continuous and a categorical regressor.
> >>
> >> The numerical examples are coded in Stata, and they give the same
> >> result as in R. Hence, if this is a bug in R then it is also a bug in
> >> Stata. That seems very unlikely.
> >>
> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
> >>
> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
> >> print("Full model")
> >> print(model.matrix(~(socst+grp)^2 ,data=df))
> >> print("Example 2.1: drop socst")
> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
> >> print("Example 2.2: drop grp")
> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
> >>
> >> This gives indeed the following regressors:
> >>
> >> "Full model"
> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
> >> "Example 2.1: drop socst"
> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3 socst:grp4
> >> "Example 2.2: drop grp"
> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
> >>
> >> There is a little bit of R documentation about this, based on the
> >> concept of marginality, which typically forbids a model having an
> >> interaction but not the corresponding main effects. (You might see the
> >> references in https://en.wikipedia.org/wiki/Principle_of_marginality )
> >>     See "An Introduction to R", by Venables and Smith and the R Core
> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
> >> details are complicated, model formulae in R will normally generate
> >> the models that an expert statistician would expect, provided that
> >> marginality is preserved. Fitting, for [a contrary] example, a model
> >> with an interaction but not the corresponding main effects will in
> >> general lead to surprising results ....".
> >>     The Reference Manual states that the R functions dropterm() and
> >> addterm() resp. drop or add only terms such that marginality is
> >> preserved.
> >>
> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
> >> Example 2.1 in Case 2 discussed above. As discussed there, in Stata
> >> and in R the drop of the continuous variable has no effect on the
> >> degrees of freedom here: it is just a reparameterisation of the full
> >> model, protecting you against losing marginality... Hence the
> >> model.matrix 'mm' is still square and nonsingular after the drop of
> >> X1, unless of course when a row is removed from the matrix 'design'
> >> when before creating 'mm'.
> >>
> >>     Arie
> >>
> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
> >> > You could possibly try to explain away the behavior for a missing main
> >> > effects term, since without the main effects term we don't have main
> >> > effect
> >> > columns in the model matrix used to compute the interaction columns
> (At
> >> > best this is undocumented behavior--I still think it's a bug, as we
> know
> >> > how we would encode the categorical factors if they were in fact
> >> > present.
> >> > It's either specified in contrasts.arg or using the default set in
> >> > options). However, when all the main effects are present, why would
> the
> >> > three-factor interaction column not simply be the product of the main
> >> > effect columns? In my example: we know X1, we know X2, and we know X3.
> >> > Why
> >> > does the encoding of X1:X2:X3 depend on whether we specified a
> >> > two-factor
> >> > interaction, AND only changes for specific missing interactions?
> >> >
> >> > In addition, I can use a two-term example similar to yours to show how
> >> > this
> >> > behavior results in a singular covariance matrix when, given the
> desired
> >> > factor encoding, it should not be singular.
> >> >
> >> > We start with a full factorial design for a two-level continuous
> factor
> >> > and
> >> > a three-level categorical factor, and remove a single row. This design
> >> > matrix does not leave enough degrees of freedom to determine
> >> > goodness-of-fit, but should allow us to obtain parameter estimates.
> >> >
> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
> >> >> design = design[-1,]
> >> >> design
> >> >   X1 X2
> >> > 2 -1  A
> >> > 3  1  B
> >> > 4 -1  B
> >> > 5  1  C
> >> > 6 -1  C
> >> >
> >> > Here, we first calculate the model matrix for the full model, and then
> >> > manually remove the X1 column from the model matrix. This gives us the
> >> > model matrix one would expect if X1 were removed from the model. We
> then
> >> > successfully calculate the covariance matrix.
> >> >
> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
> >> >> mm
> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
> >> > 2           1 -1   0   0      0      0
> >> > 3           1  1   1   0      1      0
> >> > 4           1 -1   1   0     -1      0
> >> > 5           1  1   0   1      0      1
> >> > 6           1 -1   0   1      0     -1
> >> >
> >> >> mm = mm[,-2]
> >> >> solve(t(mm) %*% mm)
> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
> >> > X2B                  -1  1.5  1.0    0.0    0.0
> >> > X2C                  -1  1.0  1.5    0.0    0.0
> >> > X1:X2B                0  0.0  0.0    0.5    0.0
> >> > X1:X2C                0  0.0  0.0    0.0    0.5
> >> >
> >> > Here, we see the actual behavior for model.matrix. The undesired
> >> > re-coding
> >> > of the model matrix interaction term makes the information matrix
> >> > singular.
> >> >
> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
> >> >> mm
> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
> >> > 2           1   0   0     -1      0      0
> >> > 3           1   1   0      0      1      0
> >> > 4           1   1   0      0     -1      0
> >> > 5           1   0   1      0      0      1
> >> > 6           1   0   1      0      0     -1
> >> >
> >> >> solve(t(mm) %*% mm)
> >> > Error in solve.default(t(mm) %*% mm) : system is computationally
> >> > singular:
> >> > reciprocal condition number = 5.55112e-18
> >> >
> >> > I still believe this is a bug.
> >> >
> >> > Best regards,
> >> > Tyler Morgan-Wall
> >> >
> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate <arietencate at gmail.com
> >
> >> > wrote:
> >> >
> >> >> I think it is not a bug. It is a general property of interactions.
> >> >> This property is best observed if all variables are factors
> >> >> (qualitative).
> >> >>
> >> >> For example, you have three variables (factors). You ask for as many
> >> >> interactions as possible, except an interaction term between two
> >> >> particular variables. When this interaction is not a constant, it is
> >> >> different for different values of the remaining variable. More
> >> >> precisely: for all values of that variable. In other words: you have
> a
> >> >> three-way interaction, with all values of that variable.
> >> >>
> >> >> An even smaller example is the following script with only two
> >> >> variables, each being a factor:
> >> >>
> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
> >> >>
> >> >> The result is:
> >> >>
> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
> >> >> 1           1   0   0   0       0       0
> >> >> 2           1   1   0   0       0       0
> >> >> 3           1   0   1   0       0       0
> >> >> 4           1   1   1   0       1       0
> >> >> 5           1   0   0   1       0       0
> >> >> 6           1   1   0   1       0       1
> >> >>
> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
> >> >> 1           1   0   0       0       0       0
> >> >> 2           1   0   0       1       0       0
> >> >> 3           1   1   0       0       0       0
> >> >> 4           1   1   0       0       1       0
> >> >> 5           1   0   1       0       0       0
> >> >> 6           1   0   1       0       0       1
> >> >>
> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
> >> >> 1           1   0       0       0       0       0
> >> >> 2           1   1       0       0       0       0
> >> >> 3           1   0       1       0       0       0
> >> >> 4           1   1       0       1       0       0
> >> >> 5           1   0       0       0       1       0
> >> >> 6           1   1       0       0       0       1
> >> >>
> >> >> Thus, in the second result, we have no main effect of X1. Instead,
> the
> >> >> effect of X1 depends on the value of X2; either A or B or C. In fact,
> >> >> this is a two-way interaction, including all three values of X2. In
> >> >> the third result, we have no main effect of X2, The effect of X2
> >> >> depends on the value of X1; either p or q.
> >> >>
> >> >> A complicating element with your example seems to be that your X1 and
> >> >> X2 are not factors.
> >> >>
> >> >>    Arie
> >> >>
> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com> wrote:
> >> >> > Hi,
> >> >> >
> >> >> > I recently ran into an inconsistency in the way
> model.matrix.default
> >> >> > handles factor encoding for higher level interactions with
> >> >> > categorical
> >> >> > variables when the full hierarchy of effects is not present.
> >> >> > Depending on
> >> >> > which lower level interactions are specified, the factor encoding
> >> >> > changes
> >> >> > for a higher level interaction. Consider the following minimal
> >> >> reproducible
> >> >> > example:
> >> >> >
> >> >> > --------------
> >> >> >
> >> >> >> runmatrix = expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2 X3B
> X3C
> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> > 1            1  1  1   0   0     1      0      0      0      0
> >> >> > 0         0
> >> >> > 2            1 -1  1   0   0    -1      0      0      0      0
> >> >> > 0         0
> >> >> > 3            1  1 -1   0   0    -1      0      0      0      0
> >> >> > 0         0
> >> >> > 4            1 -1 -1   0   0     1      0      0      0      0
> >> >> > 0         0
> >> >> > 5            1  1  1   1   0     1      1      0      1      0
> >> >> > 1         0
> >> >> > 6            1 -1  1   1   0    -1     -1      0      1      0
> >> >> > -1         0
> >> >> > 7            1  1 -1   1   0    -1      1      0     -1      0
> >> >> > -1         0
> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1      0
> >> >> > 1         0
> >> >> > 9            1  1  1   0   1     1      0      1      0      1
> >> >> > 0         1
> >> >> > 10           1 -1  1   0   1    -1      0     -1      0      1
> >> >> > 0        -1
> >> >> > 11           1  1 -1   0   1    -1      0      1      0     -1
> >> >> > 0        -1
> >> >> > 12           1 -1 -1   0   1     1      0     -1      0     -1
> >> >> > 0         1
> >> >> > attr(,"assign")
> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
> >> >> > attr(,"contrasts")
> >> >> > attr(,"contrasts")$X3
> >> >> > [1] "contr.treatment"
> >> >> >
> >> >> > --------------
> >> >> >
> >> >> > Specifying the full hierarchy gives us what we expect: the
> >> >> > interaction
> >> >> > columns are simply calculated from the product of the main effect
> >> >> columns.
> >> >> > The interaction term X1:X2:X3 gives us two columns in the model
> >> >> > matrix,
> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main effects.
> >> >> >
> >> >> > If we remove either the X2:X3 interaction or the X1:X3 interaction,
> >> >> > we
> >> >> get
> >> >> > what we would expect for the X1:X2:X3 interaction, but when we
> remove
> >> >> > the
> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes completely:
> >> >> >
> >> >> > --------------
> >> >> >
> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)   (Intercept)
> X1 X2
> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> > 1            1  1  1   0   0     1      0      0         0
>  0
> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>  0
> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>  0
> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>  0
> >> >> > 5            1  1  1   1   0     1      1      0         1
>  0
> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
>  0
> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
>  0
> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>  0
> >> >> > 9            1  1  1   0   1     1      0      1         0
>  1
> >> >> > 10           1 -1  1   0   1    -1      0      1         0
> -1
> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
> -1
> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>  1
> >> >> > attr(,"assign")
> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> > attr(,"contrasts")
> >> >> > attr(,"contrasts")$X3
> >> >> > [1] "contr.treatment"
> >> >> >
> >> >> >
> >> >> >
> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)   (Intercept)
> X1 X2
> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
> >> >> > 1            1  1  1   0   0     1      0      0         0
>  0
> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>  0
> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>  0
> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>  0
> >> >> > 5            1  1  1   1   0     1      1      0         1
>  0
> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
>  0
> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
>  0
> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>  0
> >> >> > 9            1  1  1   0   1     1      0      1         0
>  1
> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
> -1
> >> >> > 11           1  1 -1   0   1    -1      0      1         0
> -1
> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>  1
> >> >> > attr(,"assign")
> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> > attr(,"contrasts")
> >> >> > attr(,"contrasts")$X3
> >> >> > [1] "contr.treatment"
> >> >> >
> >> >> >
> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)   (Intercept)
> X1 X2
> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B X1:X2:X3C
> >> >> > 1            1  1  1   0   0      0      0      0      0         1
> >> >> >     0         0
> >> >> > 2            1 -1  1   0   0      0      0      0      0        -1
> >> >> >     0         0
> >> >> > 3            1  1 -1   0   0      0      0      0      0        -1
> >> >> >     0         0
> >> >> > 4            1 -1 -1   0   0      0      0      0      0         1
> >> >> >     0         0
> >> >> > 5            1  1  1   1   0      1      0      1      0         0
> >> >> >     1         0
> >> >> > 6            1 -1  1   1   0     -1      0      1      0         0
> >> >> >    -1         0
> >> >> > 7            1  1 -1   1   0      1      0     -1      0         0
> >> >> >    -1         0
> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0         0
> >> >> >     1         0
> >> >> > 9            1  1  1   0   1      0      1      0      1         0
> >> >> >     0         1
> >> >> > 10           1 -1  1   0   1      0     -1      0      1         0
> >> >> >     0        -1
> >> >> > 11           1  1 -1   0   1      0      1      0     -1         0
> >> >> >     0        -1
> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1         0
> >> >> >     0         1
> >> >> > attr(,"assign")
> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
> >> >> > attr(,"contrasts")
> >> >> > attr(,"contrasts")$X3
> >> >> > [1] "contr.treatment"
> >> >> >
> >> >> > --------------
> >> >> >
> >> >> > Here, we now see the encoding for the interaction X1:X2:X3 is now
> the
> >> >> > interaction of X1 and X2 with a new encoding for X3 where each
> factor
> >> >> level
> >> >> > is represented by its own column. I would expect, given the two
> >> >> > column
> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column would also
> >> >> > be
> >> >> two
> >> >> > columns regardless of what two-factor interactions we also
> specified,
> >> >> > but
> >> >> > in this case it switches to three. If other two factor interactions
> >> >> > are
> >> >> > missing in addition to X1:X2, this issue still occurs. This also
> >> >> > happens
> >> >> > regardless of the contrast specified in contrasts.arg for X3. I
> don't
> >> >> > see
> >> >> > any reasoning for this behavior given in the documentation, so I
> >> >> > suspect
> >> >> it
> >> >> > is a bug.
> >> >> >
> >> >> > Best regards,
> >> >> > Tyler Morgan-Wall
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-devel at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Nov  2 21:59:00 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Nov 2017 21:59:00 +0100
Subject: [Rd] vcov and survival
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <23035.34580.701505.839202@stat.math.ethz.ch>

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Thu, 14 Sep 2017 13:46:44 +0000 writes:

    > Dear Martin, I made three points which likely got lost
    > because of the way I presented them:

    > (1) Singularity is an unusual situation and should be made
    > more prominent. It typically reflects a problem with the
    > data or the specification of the model. That's not to say
    > that it *never* makes sense to allow singular fits (as in
    > the situations you mentions).

    > I'd favour setting singular.ok=FALSE as the default, but
    > in the absence of that a warning or at least a note. A
    > compromise would be to have a singular.ok option() that
    > would be FALSE out of the box.

    > Any changes would have to be made very carefully so as not
    > to create chaos.

I for one, am too reluctant to want to change the default there.

    >  That goes for the points below as well.

    > (2) coef() and vcov() behave inconsistently, which can be
    > problematic because one often uses them together in code.

indeed; and I had agreed on that.
As of today, in R-devel only they now behave compatibly.
NEWS entry

    ? The ?default? ("lm" etc) methods of vcov() have gained new
      optional argument complete = TRUE which makes the vcov() methods
      more consistent with the coef() methods in the case of singular
      designs.  The former behavior is now achieved by vcov(*,
      complete=FALSE).


    > (3) As you noticed in your second message, lm() has a
    > singular.ok argument and glm() doesn't.

and that has been amended even earlier (a bit more than a month
ago) in R-devel svn rev 73380 with  NEWS  entry

    ? glm() and glm.fit get the same singular.ok=TRUE argument that
      lm() has had forever.  As a consequence, in glm(*, method =
      <your_own>), user specified methods need to accept a singular.ok
      argument as well.

    > I'll take a look at the code for glm() with an eye towards
    > creating a patch, but I'm a bit reluctant to mess with the
    > code for something as important as glm().

and as a matter of fact you did send me +- the R code part of
that change.

My current plan is to also add the  'complete = TRUE' option to the
"basic" coef() methods, such that you also have consistent
coef(*, complete=FALSE)  and
vcov(*, complete=FALSE)  behaviors.

Thank you and Terry (and others?) for bringing up the issues and
discussing them thoroughly!

Best,
Martin.


    > Best, John



    >> -----Original Message----- From: Martin Maechler
    >> [mailto:maechler at stat.math.ethz.ch] Sent: Thursday,
    >> September 14, 2017 4:23 AM To: Martin Maechler
    >> <maechler at stat.math.ethz.ch> Cc: Fox, John
    >> <jfox at mcmaster.ca>; Therneau, Terry M., Ph.D.
    >> <therneau at mayo.edu>; r-devel at r-project.org Subject: Re:
    >> [Rd] vcov and survival
    >> 
    >> >>>>> Martin Maechler <maechler at stat.math.ethz.ch> >>>>>
    >> on Thu, 14 Sep 2017 10:13:02 +0200 writes:
    >> 
    >> >>>>> Fox, John <jfox at mcmaster.ca> >>>>> on Wed, 13 Sep
    >> 2017 22:45:07 +0000 writes:
    >> 
    >> >> Dear Terry, >> Even the behaviour of lm() and glm()
    >> isn't entirely consistent. In both cases, singularity
    >> results in NA coefficients by default, and these are
    >> reported in the model summary and coefficient vector, but
    >> not in the coefficient covariance matrix:
    >> 
    >> >> ----------------
    >> 
    >> >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP +
    >> Population), >> + data=longley) >>> summary(mod.lm)
    >> 
    >> >> Call: >> lm(formula = Employed ~ GNP + Population +
    >> I(GNP + Population), >> data = longley)
    >> 
    >> >> Residuals: >> Min 1Q Median 3Q Max >> -0.80899
    >> -0.33282 -0.02329 0.25895 1.08800
    >> 
    >> >> Coefficients: (1 not defined because of singularities)
    >> >> Estimate Std. Error t value Pr(>|t|) >> (Intercept)
    >> 88.93880 13.78503 6.452 2.16e-05 *** >> GNP 0.06317
    >> 0.01065 5.933 4.96e-05 *** >> Population -0.40974 0.15214
    >> -2.693 0.0184 * >> I(GNP + Population) NA NA NA NA
    >> >> ---
    >> >> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.'
    >> 0.1 ' ' 1
    >> 
    >> >> Residual standard error: 0.5459 on 13 degrees of
    >> freedom >> Multiple R-squared: 0.9791, Adjusted
    >> R-squared: 0.9758 >> F-statistic: 303.9 on 2 and 13 DF,
    >> p-value: 1.221e-11
    >> 
    >> >>> vcov(mod.lm) >> (Intercept) GNP Population >>
    >> (Intercept) 190.0269691 0.1445617813 -2.0954381 >> GNP
    >> 0.1445618 0.0001133631 -0.0016054 >> Population
    >> -2.0954381 -0.0016053999 0.0231456 >>> coef(mod.lm) >>
    >> (Intercept) GNP Population I(GNP + Population) >>
    >> 88.93879831 0.06317244 -0.40974292 NA
    >> >>>
    >> >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP +
    >> Population), >> + data=longley) >>> summary(mod.glm)
    >> 
    >> >> Call: >> glm(formula = Employed ~ GNP + Population +
    >> I(GNP + Population), >> data = longley)
    >> 
    >> >> Deviance Residuals: >> Min 1Q Median 3Q Max >>
    >> -0.80899 -0.33282 -0.02329 0.25895 1.08800
    >> 
    >> >> Coefficients: (1 not defined because of singularities)
    >> >> Estimate Std. Error t value Pr(>|t|) >> (Intercept)
    >> 88.93880 13.78503 6.452 2.16e-05 *** >> GNP 0.06317
    >> 0.01065 5.933 4.96e-05 *** >> Population -0.40974 0.15214
    >> -2.693 0.0184 * >> I(GNP + Population) NA NA NA NA
    >> >> ---
    >> >> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.'
    >> 0.1 ' ' 1
    >> 
    >> >> (Dispersion parameter for gaussian family taken to be
    >> 0.2980278)
    >> 
    >> >> Null deviance: 185.0088 on 15 degrees of freedom >>
    >> Residual deviance: 3.8744 on 13 degrees of freedom >>
    >> AIC: 30.715
    >> 
    >> >> Number of Fisher Scoring iterations: 2
    >> 
    >> >>> coef(mod.glm) >> (Intercept) GNP Population I(GNP +
    >> Population) >> 88.93879831 0.06317244 -0.40974292 NA >>>
    >> vcov(mod.glm) >> (Intercept) GNP Population >>
    >> (Intercept) 190.0269691 0.1445617813 -2.0954381 >> GNP
    >> 0.1445618 0.0001133631 -0.0016054 >> Population
    >> -2.0954381 -0.0016053999 0.0231456
    >> 
    >> >> ----------------
    >> 
    >> >> Moreoever, lm() has a singular.ok() argument that
    >> defaults to TRUE, but glm() doesn't have this argument:
    >> 
    >> >> ----------------
    >> 
    >> >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP +
    >> Population), >> + data=longley, singular.ok=FALSE) >>
    >> Error in lm.fit(x, y, offset = offset, singular.ok =
    >> singular.ok, ...) : >> singular fit encountered
    >> 
    >> >> ----------------
    >> 
    >> >> In my opinion, singularity should at least produce a
    >> warning, both in calls to lm() and glm(), and in
    >> summary() output. Even better, again in my opinion, would
    >> be to produce an error by default in this situation, but
    >> doing so would likely break too much existing code.
    >> 
    >> > Yes, I would not want to change.  Note that this is
    >> from S > already, i.e., long "ingrained".  I think there
    >> one argument was > that there are situations with factor
    >> predictors of many levels > and conceptually their 2- or
    >> even 3-way interactions (!)  > where it is neat to just
    >> fit the model, (-> get residuals and > fitted values) and
    >> also see implicitly the "necessary rank" of > prediction
    >> space, or rather even more specifically, you see for >
    >> every factor how many levels are "distinguishable"/useful
    >> for > prediction, given the data.
    >> 
    >> >> I prefer NA to 0 for the redundant coefficients
    >> because it at least suggests that the decision about what
    >> to exclude is arbitrary, and of course simply excluding
    >> coefficients isn't the only way to proceed.
    >> 
    >> > I'm less modest and would say *definitely*, NA's are
    >> highly > prefered in such a situation.
    >> 
    >> >> Finally, the differences in behaviour between coef()
    >> and vcov() and between lm() and glm() aren't really
    >> sensible.
    >> 
    >> > I really haven't seen any difference between lm() and
    >> glm() in > the example above.  Maybe you can point them
    >> out for me.
    >> 
    >> .. now I saw it: lm() has a 'singular.ok = TRUE' argument
    >> which you can set to FALSE if you prefer an error to NA
    >> coefficients.
    >> 
    >> I also agree with you John that it would be nice if glm()
    >> also got such an argument.  Patches are welcome and seem
    >> easy. Nowadays we prefer them as attachments (diff/patch
    >> file!) at R's https://bugs.r-project.org bugzilla against
    >> the svn source, here
    >> https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
    >> and
    >> https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd
    >> 
    >> > I do quite agree that vcov() should be compatible with
    >> > coef() [and summary()] for both 'lm' and 'glm' methods,
    >> i.e., > should get NA rows and columns there.  This would
    >> require > eliminating these before e.g. using it in
    >> solve(<vcov>, *) etc, > but I think it would be a good
    >> idea that the useR must deal with > these NAs actively.
    >> 
    >> > Shall "we" try and see the fallout in CRAN space?
    >> 
    >> >> Maybe there's some reason for all this that escapes
    >> me.  > (for the first one---"no error"--- I gave a
    >> reason)
    >> 
    >> >> Best, >> John
    >> 
    >> >> --------------------------------------
    >> >> John Fox, Professor Emeritus >> McMaster University >>
    >> Hamilton, Ontario, Canada >> Web:
    >> socserv.mcmaster.ca/jfox
    >> 
    >> 
    >> 
    >> 
    >> >>> -----Original Message----- >>> From: R-devel
    >> [mailto:r-devel-bounces at r-project.org] On Behalf Of >>>
    >> Therneau, Terry M., Ph.D.  >>> Sent: Wednesday, September
    >> 13, 2017 6:19 PM >>> To: r-devel at r-project.org >>>
    >> Subject: [Rd] vcov and survival
    >> >>>
    >> >>> I have just noticed a difference in behavior between
    >> coxph and lm/glm: >>> if one or more of the coefficients
    >> from the fit in NA, then lm and glm >>> omit that
    >> row/column from the variance matrix; while coxph retains
    >> it >>> but sets the values to zero.
    >> >>>
    >> >>> Is this something that should be "fixed", i.e., made
    >> to agree? I >>> suspect that doing so will break other
    >> packages, but then NA coefs are >>> rather rare so
    >> perhaps not.
    >> >>>
    >> >>> Terry Therneau


From jfox at mcmaster.ca  Thu Nov  2 22:23:17 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 2 Nov 2017 21:23:17 +0000
Subject: [Rd] vcov and survival
In-Reply-To: <23035.34580.701505.839202@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
 <23035.34580.701505.839202@stat.math.ethz.ch>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366F93FB@FHSDB4H16-2.csu.mcmaster.ca>

Dear Martin,

Thank you for taking care of this.

Best,
 John

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Thursday, November 2, 2017 4:59 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Martin Maechler <maechler at stat.math.ethz.ch>; Therneau, Terry M.,
> Ph.D. <therneau at mayo.edu>; r-devel at r-project.org
> Subject: RE: [Rd] vcov and survival
> 
> >>>>> Fox, John <jfox at mcmaster.ca>
> >>>>>     on Thu, 14 Sep 2017 13:46:44 +0000 writes:
> 
>     > Dear Martin, I made three points which likely got lost
>     > because of the way I presented them:
> 
>     > (1) Singularity is an unusual situation and should be made
>     > more prominent. It typically reflects a problem with the
>     > data or the specification of the model. That's not to say
>     > that it *never* makes sense to allow singular fits (as in
>     > the situations you mentions).
> 
>     > I'd favour setting singular.ok=FALSE as the default, but
>     > in the absence of that a warning or at least a note. A
>     > compromise would be to have a singular.ok option() that
>     > would be FALSE out of the box.
> 
>     > Any changes would have to be made very carefully so as not
>     > to create chaos.
> 
> I for one, am too reluctant to want to change the default there.
> 
>     >  That goes for the points below as well.
> 
>     > (2) coef() and vcov() behave inconsistently, which can be
>     > problematic because one often uses them together in code.
> 
> indeed; and I had agreed on that.
> As of today, in R-devel only they now behave compatibly.
> NEWS entry
> 
>     ? The ?default? ("lm" etc) methods of vcov() have gained new
>       optional argument complete = TRUE which makes the vcov() methods
>       more consistent with the coef() methods in the case of singular
>       designs.  The former behavior is now achieved by vcov(*,
>       complete=FALSE).
> 
> 
>     > (3) As you noticed in your second message, lm() has a
>     > singular.ok argument and glm() doesn't.
> 
> and that has been amended even earlier (a bit more than a month
> ago) in R-devel svn rev 73380 with  NEWS  entry
> 
>     ? glm() and glm.fit get the same singular.ok=TRUE argument that
>       lm() has had forever.  As a consequence, in glm(*, method =
>       <your_own>), user specified methods need to accept a singular.ok
>       argument as well.
> 
>     > I'll take a look at the code for glm() with an eye towards
>     > creating a patch, but I'm a bit reluctant to mess with the
>     > code for something as important as glm().
> 
> and as a matter of fact you did send me +- the R code part of that change.
> 
> My current plan is to also add the  'complete = TRUE' option to the "basic"
> coef() methods, such that you also have consistent coef(*, complete=FALSE)
> and vcov(*, complete=FALSE)  behaviors.
> 
> Thank you and Terry (and others?) for bringing up the issues and discussing
> them thoroughly!
> 
> Best,
> Martin.
> 
> 
>     > Best, John
> 
> 
> 
>     >> -----Original Message----- From: Martin Maechler
>     >> [mailto:maechler at stat.math.ethz.ch] Sent: Thursday,
>     >> September 14, 2017 4:23 AM To: Martin Maechler
>     >> <maechler at stat.math.ethz.ch> Cc: Fox, John
>     >> <jfox at mcmaster.ca>; Therneau, Terry M., Ph.D.
>     >> <therneau at mayo.edu>; r-devel at r-project.org Subject: Re:
>     >> [Rd] vcov and survival
>     >>
>     >> >>>>> Martin Maechler <maechler at stat.math.ethz.ch> >>>>>
>     >> on Thu, 14 Sep 2017 10:13:02 +0200 writes:
>     >>
>     >> >>>>> Fox, John <jfox at mcmaster.ca> >>>>> on Wed, 13 Sep
>     >> 2017 22:45:07 +0000 writes:
>     >>
>     >> >> Dear Terry, >> Even the behaviour of lm() and glm()
>     >> isn't entirely consistent. In both cases, singularity
>     >> results in NA coefficients by default, and these are
>     >> reported in the model summary and coefficient vector, but
>     >> not in the coefficient covariance matrix:
>     >>
>     >> >> ----------------
>     >>
>     >> >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP +
>     >> Population), >> + data=longley) >>> summary(mod.lm)
>     >>
>     >> >> Call: >> lm(formula = Employed ~ GNP + Population +
>     >> I(GNP + Population), >> data = longley)
>     >>
>     >> >> Residuals: >> Min 1Q Median 3Q Max >> -0.80899
>     >> -0.33282 -0.02329 0.25895 1.08800
>     >>
>     >> >> Coefficients: (1 not defined because of singularities)
>     >> >> Estimate Std. Error t value Pr(>|t|) >> (Intercept)
>     >> 88.93880 13.78503 6.452 2.16e-05 *** >> GNP 0.06317
>     >> 0.01065 5.933 4.96e-05 *** >> Population -0.40974 0.15214
>     >> -2.693 0.0184 * >> I(GNP + Population) NA NA NA NA
>     >> >> ---
>     >> >> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.'
>     >> 0.1 ' ' 1
>     >>
>     >> >> Residual standard error: 0.5459 on 13 degrees of
>     >> freedom >> Multiple R-squared: 0.9791, Adjusted
>     >> R-squared: 0.9758 >> F-statistic: 303.9 on 2 and 13 DF,
>     >> p-value: 1.221e-11
>     >>
>     >> >>> vcov(mod.lm) >> (Intercept) GNP Population >>
>     >> (Intercept) 190.0269691 0.1445617813 -2.0954381 >> GNP
>     >> 0.1445618 0.0001133631 -0.0016054 >> Population
>     >> -2.0954381 -0.0016053999 0.0231456 >>> coef(mod.lm) >>
>     >> (Intercept) GNP Population I(GNP + Population) >>
>     >> 88.93879831 0.06317244 -0.40974292 NA
>     >> >>>
>     >> >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP +
>     >> Population), >> + data=longley) >>> summary(mod.glm)
>     >>
>     >> >> Call: >> glm(formula = Employed ~ GNP + Population +
>     >> I(GNP + Population), >> data = longley)
>     >>
>     >> >> Deviance Residuals: >> Min 1Q Median 3Q Max >>
>     >> -0.80899 -0.33282 -0.02329 0.25895 1.08800
>     >>
>     >> >> Coefficients: (1 not defined because of singularities)
>     >> >> Estimate Std. Error t value Pr(>|t|) >> (Intercept)
>     >> 88.93880 13.78503 6.452 2.16e-05 *** >> GNP 0.06317
>     >> 0.01065 5.933 4.96e-05 *** >> Population -0.40974 0.15214
>     >> -2.693 0.0184 * >> I(GNP + Population) NA NA NA NA
>     >> >> ---
>     >> >> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.'
>     >> 0.1 ' ' 1
>     >>
>     >> >> (Dispersion parameter for gaussian family taken to be
>     >> 0.2980278)
>     >>
>     >> >> Null deviance: 185.0088 on 15 degrees of freedom >>
>     >> Residual deviance: 3.8744 on 13 degrees of freedom >>
>     >> AIC: 30.715
>     >>
>     >> >> Number of Fisher Scoring iterations: 2
>     >>
>     >> >>> coef(mod.glm) >> (Intercept) GNP Population I(GNP +
>     >> Population) >> 88.93879831 0.06317244 -0.40974292 NA >>>
>     >> vcov(mod.glm) >> (Intercept) GNP Population >>
>     >> (Intercept) 190.0269691 0.1445617813 -2.0954381 >> GNP
>     >> 0.1445618 0.0001133631 -0.0016054 >> Population
>     >> -2.0954381 -0.0016053999 0.0231456
>     >>
>     >> >> ----------------
>     >>
>     >> >> Moreoever, lm() has a singular.ok() argument that
>     >> defaults to TRUE, but glm() doesn't have this argument:
>     >>
>     >> >> ----------------
>     >>
>     >> >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP +
>     >> Population), >> + data=longley, singular.ok=FALSE) >>
>     >> Error in lm.fit(x, y, offset = offset, singular.ok =
>     >> singular.ok, ...) : >> singular fit encountered
>     >>
>     >> >> ----------------
>     >>
>     >> >> In my opinion, singularity should at least produce a
>     >> warning, both in calls to lm() and glm(), and in
>     >> summary() output. Even better, again in my opinion, would
>     >> be to produce an error by default in this situation, but
>     >> doing so would likely break too much existing code.
>     >>
>     >> > Yes, I would not want to change.  Note that this is
>     >> from S > already, i.e., long "ingrained".  I think there
>     >> one argument was > that there are situations with factor
>     >> predictors of many levels > and conceptually their 2- or
>     >> even 3-way interactions (!)  > where it is neat to just
>     >> fit the model, (-> get residuals and > fitted values) and
>     >> also see implicitly the "necessary rank" of > prediction
>     >> space, or rather even more specifically, you see for >
>     >> every factor how many levels are "distinguishable"/useful
>     >> for > prediction, given the data.
>     >>
>     >> >> I prefer NA to 0 for the redundant coefficients
>     >> because it at least suggests that the decision about what
>     >> to exclude is arbitrary, and of course simply excluding
>     >> coefficients isn't the only way to proceed.
>     >>
>     >> > I'm less modest and would say *definitely*, NA's are
>     >> highly > prefered in such a situation.
>     >>
>     >> >> Finally, the differences in behaviour between coef()
>     >> and vcov() and between lm() and glm() aren't really
>     >> sensible.
>     >>
>     >> > I really haven't seen any difference between lm() and
>     >> glm() in > the example above.  Maybe you can point them
>     >> out for me.
>     >>
>     >> .. now I saw it: lm() has a 'singular.ok = TRUE' argument
>     >> which you can set to FALSE if you prefer an error to NA
>     >> coefficients.
>     >>
>     >> I also agree with you John that it would be nice if glm()
>     >> also got such an argument.  Patches are welcome and seem
>     >> easy. Nowadays we prefer them as attachments (diff/patch
>     >> file!) at R's https://bugs.r-project.org bugzilla against
>     >> the svn source, here
>     >> https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
>     >> and
>     >> https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd
>     >>
>     >> > I do quite agree that vcov() should be compatible with
>     >> > coef() [and summary()] for both 'lm' and 'glm' methods,
>     >> i.e., > should get NA rows and columns there.  This would
>     >> require > eliminating these before e.g. using it in
>     >> solve(<vcov>, *) etc, > but I think it would be a good
>     >> idea that the useR must deal with > these NAs actively.
>     >>
>     >> > Shall "we" try and see the fallout in CRAN space?
>     >>
>     >> >> Maybe there's some reason for all this that escapes
>     >> me.  > (for the first one---"no error"--- I gave a
>     >> reason)
>     >>
>     >> >> Best, >> John
>     >>
>     >> >> --------------------------------------
>     >> >> John Fox, Professor Emeritus >> McMaster University >>
>     >> Hamilton, Ontario, Canada >> Web:
>     >> socserv.mcmaster.ca/jfox
>     >>
>     >>
>     >>
>     >>
>     >> >>> -----Original Message----- >>> From: R-devel
>     >> [mailto:r-devel-bounces at r-project.org] On Behalf Of >>>
>     >> Therneau, Terry M., Ph.D.  >>> Sent: Wednesday, September
>     >> 13, 2017 6:19 PM >>> To: r-devel at r-project.org >>>
>     >> Subject: [Rd] vcov and survival
>     >> >>>
>     >> >>> I have just noticed a difference in behavior between
>     >> coxph and lm/glm: >>> if one or more of the coefficients
>     >> from the fit in NA, then lm and glm >>> omit that
>     >> row/column from the variance matrix; while coxph retains
>     >> it >>> but sets the values to zero.
>     >> >>>
>     >> >>> Is this something that should be "fixed", i.e., made
>     >> to agree? I >>> suspect that doing so will break other
>     >> packages, but then NA coefs are >>> rather rare so
>     >> perhaps not.
>     >> >>>
>     >> >>> Terry Therneau

From tirthankar.lists at gmail.com  Fri Nov  3 08:49:12 2017
From: tirthankar.lists at gmail.com (Tirthankar Chakravarty)
Date: Fri, 3 Nov 2017 13:19:12 +0530
Subject: [Rd] Extreme bunching of random values from runif with
	Mersenne-Twister seed
Message-ID: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>

This is cross-posted from SO (https://stackoverflow.com/q/47079702/1414455),
but I now feel that this needs someone from R-Devel to help understand why
this is happening.

We are facing a weird situation in our code when using R's [`runif`][1] and
setting seed with `set.seed` with the `kind = NULL` option (which resolves,
unless I am mistaken, to `kind = "default"`; the default being
`"Mersenne-Twister"`).

We set the seed using (8 digit) unique IDs generated by an upstream system,
before calling `runif`:

    seeds = c(
      "86548915", "86551615", "86566163", "86577411", "86584144",
      "86584272", "86620568", "86724613", "86756002", "86768593",
"86772411",
      "86781516", "86794389", "86805854", "86814600", "86835092",
"86874179",
      "86876466", "86901193", "86987847", "86988080")

    random_values = sapply(seeds, function(x) {
      set.seed(x)
      y = runif(1, 17, 26)
      return(y)
    })

This gives values that are **extremely** bunched together.

    > summary(random_values)
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      25.13   25.36   25.66   25.58   25.83   25.94

This behaviour of `runif` goes away when we use `kind =
"Knuth-TAOCP-2002"`, and we get values that appear to be much more evenly
spread out.

    random_values = sapply(seeds, function(x) {
      set.seed(x, kind = "Knuth-TAOCP-2002")
      y = runif(1, 17, 26)
      return(y)
    })

*Output omitted.*

---

**The most interesting thing here is that this does not happen on Windows
-- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
below).

# Windows output: #

    > seeds = c(
    +   "86548915", "86551615", "86566163", "86577411", "86584144",
    +   "86584272", "86620568", "86724613", "86756002", "86768593",
"86772411",
    +   "86781516", "86794389", "86805854", "86814600", "86835092",
"86874179",
    +   "86876466", "86901193", "86987847", "86988080")
    >
    > random_values = sapply(seeds, function(x) {
    +   set.seed(x)
    +   y = runif(1, 17, 26)
    +   return(y)
    + })
    >
    > summary(random_values)
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      17.32   20.14   23.00   22.17   24.07   25.90

Can someone help understand what is going on?

Ubuntu
------

    R version 3.4.0 (2017-04-21)
    Platform: x86_64-pc-linux-gnu (64-bit)
    Running under: Ubuntu 16.04.2 LTS

    Matrix products: default
    BLAS: /usr/lib/libblas/libblas.so.3.6.0
    LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

    locale:
    [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
     [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
     [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
     [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
     [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
    [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8

    attached base packages:
    [1] parallel  stats     graphics  grDevices utils     datasets
methods   base

    other attached packages:
    [1] RMySQL_0.10.8               DBI_0.6-1
     [3] jsonlite_1.4                tidyjson_0.2.2
     [5] optiRum_0.37.3              lubridate_1.6.0
     [7] httr_1.2.1                  gdata_2.18.0
     [9] XLConnect_0.2-12            XLConnectJars_0.2-12
    [11] data.table_1.10.4           stringr_1.2.0
    [13] readxl_1.0.0                xlsx_0.5.7
    [15] xlsxjars_0.6.1              rJava_0.9-8
    [17] sqldf_0.4-10                RSQLite_1.1-2
    [19] gsubfn_0.6-6                proto_1.0.0
    [21] dplyr_0.5.0                 purrr_0.2.4
    [23] readr_1.1.1                 tidyr_0.6.3
    [25] tibble_1.3.0                tidyverse_1.1.1
    [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
    [29] MLmetrics_1.1.1             caret_6.0-76
    [31] ROCR_1.0-7                  gplots_3.0.1
    [33] effects_3.1-2               pROC_1.10.0
    [35] pscl_1.4.9                  lattice_0.20-35
    [37] MASS_7.3-47                 ggplot2_2.2.1

    loaded via a namespace (and not attached):
    [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
modelr_0.1.0
     [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
 cellranger_1.1.0
     [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
rvest_0.3.2
    [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
plyr_1.8.4
    [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
SparseM_1.77
    [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
MatrixModels_0.4-1
    [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
lazyeval_0.2.0
    [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
 memoise_1.0.0
    [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
 foreign_0.8-69
    [37] tools_3.4.0        hms_0.3            munsell_0.4.3
compiler_3.4.0
    [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
 nloptr_1.0.4
    [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
gtable_0.2.0
    [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2     R6_2.2.0

    [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
Rcpp_0.12.11



Windows
-------

    > sessionInfo()
    R version 3.3.2 (2016-10-31)
    Platform: x86_64-w64-mingw32/x64 (64-bit)
    Running under: Windows >= 8 x64 (build 9200)

    locale:
    [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
LC_MONETARY=English_India.1252
    [4] LC_NUMERIC=C                   LC_TIME=English_India.1252

    attached base packages:
    [1] graphics  grDevices utils     datasets  grid      stats
 methods   base

    other attached packages:
     [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
eulerr_1.1.0         VennDiagram_1.6.17
     [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
 xml2_1.0.0           httr_1.3.0
    [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
 htmltools_0.3.6      urltools_1.6.0
    [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
 shiny_1.0.5          RODBC_1.3-14
    [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
gsubfn_0.6-6         proto_1.0.0
    [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
 XLConnectJars_0.2-12 data.table_1.10.4
    [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
readxl_0.1.1         googlesheets_0.2.1
    [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
RPostgreSQL_0.4-1    DBI_0.5-1
    [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
tidyr_0.7.0          tibble_1.3.3
    [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0

    loaded via a namespace (and not attached):
     [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
cellranger_1.1.0     yaml_2.1.14
     [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
 chron_2.3-48         digest_0.6.12.1
    [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
 pkgconfig_2.0.1      xtable_1.8-2
    [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
tools_3.3.2          hms_0.3
    [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
RCurl_1.95-4.8       labeling_0.3
    [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
 reshape2_1.4.2       R6_2.2.0
    [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
Rcpp_0.12.12.1

  [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Uniform.html

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Nov  3 10:39:35 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Nov 2017 10:39:35 +0100
Subject: [Rd] Extreme bunching of random values from runif
	with	Mersenne-Twister seed
In-Reply-To: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
Message-ID: <23036.14679.82544.855772@stat.math.ethz.ch>

>>>>> Tirthankar Chakravarty <tirthankar.lists at gmail.com>
>>>>>     on Fri, 3 Nov 2017 13:19:12 +0530 writes:

    > This is cross-posted from SO
    > (https://stackoverflow.com/q/47079702/1414455), but I now
    > feel that this needs someone from R-Devel to help
    > understand why this is happening.

Why R-devel -- R-help would have been appropriate:

It seems you have not read the help page for
set.seed as I expect it from posters to R-devel. 
Why would you use strings instead of integers if you *had* read it ?

    > We are facing a weird situation in our code when using R's
    > [`runif`][1] and setting seed with `set.seed` with the
    > `kind = NULL` option (which resolves, unless I am
    > mistaken, to `kind = "default"`; the default being
    > `"Mersenne-Twister"`).

again this is not what the help page says; rather

 | The use of ?kind = NULL? or ?normal.kind = NULL? in ?RNGkind? or
 | ?set.seed? selects the currently-used generator (including that
 | used in the previous session if the workspace has been restored):
 | if no generator has been used it selects ?"default"?.

but as you have > 90 (!!) packages in your sessionInfo() below,
why should we (or you) know if some of the things you did
before or (implicitly) during loading all these packages did not
change the RNG kind ?

    > We set the seed using (8 digit) unique IDs generated by an
    > upstream system, before calling `runif`:

    >     seeds = c( "86548915", "86551615", "86566163",
    > "86577411", "86584144", "86584272", "86620568",
    > "86724613", "86756002", "86768593", "86772411",
    > "86781516", "86794389", "86805854", "86814600",
    > "86835092", "86874179", "86876466", "86901193",
    > "86987847", "86988080")

    >  random_values = sapply(seeds, function(x) {
    >   set.seed(x)
    >   y = runif(1, 17, 26)
    >   return(y)
    > })

Why do you do that?

1) You should set the seed *once*, not multiple times in one simulation.

2) Assuming that your strings are correctly translated to integers
   and the same on all platforms, independent of locales (!) etc,
   you are again not following the simple instruction on the help page:

     ?set.seed? uses a single integer argument to set as many seeds as
     are required.  It is intended as a simple way to get quite
     different seeds by specifying small integer arguments, and also as
     .....
     .....

Note:   ** small ** integer 
Why do you assume   86901193  to be a small integer ?

    > This gives values that are **extremely** bunched together.

    >> summary(random_values)
    >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  25.13
    > 25.36 25.66 25.58 25.83 25.94

    > This behaviour of `runif` goes away when we use `kind =
    > "Knuth-TAOCP-2002"`, and we get values that appear to be
    > much more evenly spread out.

    >     random_values = sapply(seeds, function(x) {
    > set.seed(x, kind = "Knuth-TAOCP-2002") y = runif(1, 17,
    > 26) return(y) })

    > *Output omitted.*

    > ---

    > **The most interesting thing here is that this does not
    > happen on Windows -- only happens on Ubuntu**
    > (`sessionInfo` output for Ubuntu & Windows below).

    > # Windows output: #

    >> seeds = c(
    >     + "86548915", "86551615", "86566163", "86577411",
    > "86584144", + "86584272", "86620568", "86724613",
    > "86756002", "86768593", "86772411", + "86781516",
    > "86794389", "86805854", "86814600", "86835092",
    > "86874179", + "86876466", "86901193", "86987847",
    > "86988080")
    >> 
    >> random_values = sapply(seeds, function(x) {
    >     + set.seed(x) + y = runif(1, 17, 26) + return(y) + })
    >> 
    >> summary(random_values)
    >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  17.32
    > 20.14 23.00 22.17 24.07 25.90

    > Can someone help understand what is going on?

    > Ubuntu
    > ------

    > R version 3.4.0 (2017-04-21)
    > Platform: x86_64-pc-linux-gnu (64-bit)
    > Running under: Ubuntu 16.04.2 LTS

You have not learned to get a current version of R.
===> You should not write to R-devel (sorry if this may sound harsh ..)

Hint:
   We know that  Ubuntu LTS -- by its virtue of LTS (Long Time
   Support) will not update R.
   But the Ubuntu/Debian pages on CRAN tell you how to ensure to
   automatically get current versions of R on your ubuntu-run computer
   (Namely by adding a CRAN mirror to your ubuntu sources)

And then in your sessionInfo :

    ....
       38 packages attached + 56 namespaces loaded !!
    ....

   and similar nonsense (tons of packages+namespaces)
   on Windows which uses an even more outdated version of
   R 3.3.2.

-------------

Can you please learn to work with a minimal reproducible example MRE
(well you are close in your R code, but not if you load 50
 packages and do how-knows-what before running the example,
 you RNGkind() and many other things could have been changed ...)

Since you run ubuntu, you know the shell and you could
(after installing a current version of R) put your MRE in a
small *.R script and do

   R CMD BATCH --vanilla  MRE.R

which will produce MRE.Rout  with all input/output

BTW: Even on Windoze you can do similarly, once you've found the
location of 'Rcmd.exe':

   ......\Rcmd BATCH --vanilla MRE.R

should work there as well and deliver MRE.Rout

- - - - -
After doing all this, your problem may still be just
because you are using much too large integers for the 'seed'
argument of set.seed()

I really really strongly believe you should have used R-help
instead of R-devel.

Best,
Martin Maechler


From lukas.stadler at oracle.com  Fri Nov  3 11:04:59 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Fri, 3 Nov 2017 11:04:59 +0100
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <23036.14679.82544.855772@stat.math.ethz.ch>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <23036.14679.82544.855772@stat.math.ethz.ch>
Message-ID: <C5FCA85C-AF67-4242-818B-A0ACD50E3B3F@oracle.com>

If I interpret the original message as ?I think there?s something wrong with R's random number generator?:
Your assumption is that going from the seed to the first random number is a good hash function, which it isn?t.
E.g., with Mersenne Twister it?s a couple of multiplications, bit shifts, xors and ands, and the few bits that vary in your seed end up in the less significant bits of the result.
Something like the ?digest? package might be what you want, it provides proper hash functions.

- Lukas

> On 3 Nov 2017, at 10:39, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Tirthankar Chakravarty <tirthankar.lists at gmail.com>
>>>>>>    on Fri, 3 Nov 2017 13:19:12 +0530 writes:
> 
>> This is cross-posted from SO
>> (https://urldefense.proofpoint.com/v2/url?u=https-3A__stackoverflow.com_q_47079702_1414455&d=DwIGaQ&c=RoP1YumCXCgaWHvlZYR8PZh8Bv7qIrMUB65eapI_JnE&r=sySSOv_y4gUrdhItlSw7q2z3RRR8JsPrnS8RhIHA9W4&m=mDEuT7697Im9mtm3dqOQF3Abpcn1ZsA1E_sZE-PZIGg&s=qm177vnypIq1tc3Km5gwocAEmlwieB9pD5jkClG0I-U&e=), but I now
>> feel that this needs someone from R-Devel to help
>> understand why this is happening.
> 
> Why R-devel -- R-help would have been appropriate:
> 
> It seems you have not read the help page for
> set.seed as I expect it from posters to R-devel. 
> Why would you use strings instead of integers if you *had* read it ?
> 
>> We are facing a weird situation in our code when using R's
>> [`runif`][1] and setting seed with `set.seed` with the
>> `kind = NULL` option (which resolves, unless I am
>> mistaken, to `kind = "default"`; the default being
>> `"Mersenne-Twister"`).
> 
> again this is not what the help page says; rather
> 
> | The use of ?kind = NULL? or ?normal.kind = NULL? in ?RNGkind? or
> | ?set.seed? selects the currently-used generator (including that
> | used in the previous session if the workspace has been restored):
> | if no generator has been used it selects ?"default"?.
> 
> but as you have > 90 (!!) packages in your sessionInfo() below,
> why should we (or you) know if some of the things you did
> before or (implicitly) during loading all these packages did not
> change the RNG kind ?
> 
>> We set the seed using (8 digit) unique IDs generated by an
>> upstream system, before calling `runif`:
> 
>>    seeds = c( "86548915", "86551615", "86566163",
>> "86577411", "86584144", "86584272", "86620568",
>> "86724613", "86756002", "86768593", "86772411",
>> "86781516", "86794389", "86805854", "86814600",
>> "86835092", "86874179", "86876466", "86901193",
>> "86987847", "86988080")
> 
>> random_values = sapply(seeds, function(x) {
>>  set.seed(x)
>>  y = runif(1, 17, 26)
>>  return(y)
>> })
> 
> Why do you do that?
> 
> 1) You should set the seed *once*, not multiple times in one simulation.
> 
> 2) Assuming that your strings are correctly translated to integers
>   and the same on all platforms, independent of locales (!) etc,
>   you are again not following the simple instruction on the help page:
> 
>     ?set.seed? uses a single integer argument to set as many seeds as
>     are required.  It is intended as a simple way to get quite
>     different seeds by specifying small integer arguments, and also as
>     .....
>     .....
> 
> Note:   ** small ** integer 
> Why do you assume   86901193  to be a small integer ?
> 
>> This gives values that are **extremely** bunched together.
> 
>>> summary(random_values)
>>       Min. 1st Qu.  Median Mean 3rd Qu.  Max.  25.13
>> 25.36 25.66 25.58 25.83 25.94
> 
>> This behaviour of `runif` goes away when we use `kind =
>> "Knuth-TAOCP-2002"`, and we get values that appear to be
>> much more evenly spread out.
> 
>>    random_values = sapply(seeds, function(x) {
>> set.seed(x, kind = "Knuth-TAOCP-2002") y = runif(1, 17,
>> 26) return(y) })
> 
>> *Output omitted.*
> 
>> ---
> 
>> **The most interesting thing here is that this does not
>> happen on Windows -- only happens on Ubuntu**
>> (`sessionInfo` output for Ubuntu & Windows below).
> 
>> # Windows output: #
> 
>>> seeds = c(
>>    + "86548915", "86551615", "86566163", "86577411",
>> "86584144", + "86584272", "86620568", "86724613",
>> "86756002", "86768593", "86772411", + "86781516",
>> "86794389", "86805854", "86814600", "86835092",
>> "86874179", + "86876466", "86901193", "86987847",
>> "86988080")
>>> 
>>> random_values = sapply(seeds, function(x) {
>>    + set.seed(x) + y = runif(1, 17, 26) + return(y) + })
>>> 
>>> summary(random_values)
>>       Min. 1st Qu.  Median Mean 3rd Qu.  Max.  17.32
>> 20.14 23.00 22.17 24.07 25.90
> 
>> Can someone help understand what is going on?
> 
>> Ubuntu
>> ------
> 
>> R version 3.4.0 (2017-04-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.2 LTS
> 
> You have not learned to get a current version of R.
> ===> You should not write to R-devel (sorry if this may sound harsh ..)
> 
> Hint:
>   We know that  Ubuntu LTS -- by its virtue of LTS (Long Time
>   Support) will not update R.
>   But the Ubuntu/Debian pages on CRAN tell you how to ensure to
>   automatically get current versions of R on your ubuntu-run computer
>   (Namely by adding a CRAN mirror to your ubuntu sources)
> 
> And then in your sessionInfo :
> 
>    ....
>       38 packages attached + 56 namespaces loaded !!
>    ....
> 
>   and similar nonsense (tons of packages+namespaces)
>   on Windows which uses an even more outdated version of
>   R 3.3.2.
> 
> -------------
> 
> Can you please learn to work with a minimal reproducible example MRE
> (well you are close in your R code, but not if you load 50
> packages and do how-knows-what before running the example,
> you RNGkind() and many other things could have been changed ...)
> 
> Since you run ubuntu, you know the shell and you could
> (after installing a current version of R) put your MRE in a
> small *.R script and do
> 
>   R CMD BATCH --vanilla  MRE.R
> 
> which will produce MRE.Rout  with all input/output
> 
> BTW: Even on Windoze you can do similarly, once you've found the
> location of 'Rcmd.exe':
> 
>   ......\Rcmd BATCH --vanilla MRE.R
> 
> should work there as well and deliver MRE.Rout
> 
> - - - - -
> After doing all this, your problem may still be just
> because you are using much too large integers for the 'seed'
> argument of set.seed()
> 
> I really really strongly believe you should have used R-help
> instead of R-devel.
> 
> Best,
> Martin Maechler
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIGaQ&c=RoP1YumCXCgaWHvlZYR8PZh8Bv7qIrMUB65eapI_JnE&r=sySSOv_y4gUrdhItlSw7q2z3RRR8JsPrnS8RhIHA9W4&m=mDEuT7697Im9mtm3dqOQF3Abpcn1ZsA1E_sZE-PZIGg&s=ua3fUgGQ4bG_ImAKJ-_AHRdtFz0xtqvoA--cKTvFI1Q&e=


From tirthankar.lists at gmail.com  Fri Nov  3 14:24:23 2017
From: tirthankar.lists at gmail.com (Tirthankar Chakravarty)
Date: Fri, 3 Nov 2017 18:54:23 +0530
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <23036.14679.82544.855772@stat.math.ethz.ch>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <23036.14679.82544.855772@stat.math.ethz.ch>
Message-ID: <CA+S-T795S9ab42kUXztrWSpoA1U7UYWA5mYwm8mTx0g_jNqXYQ@mail.gmail.com>

Martin,

Thanks for the helpful reply. Alas I had forgotten that (implied)
unfavorable comparisons of *nix systems with Windows systems would likely
draw irate (but always substantive) responses on the R-devel list -- poor
phrasing on my part. :)

Regardless, let me try to address some of the concerns related to the
construction of the MRE itself and try to see if we can clean away the
shrubbery & zero down on the core issue, since I continue to believe that
this is an issue with either R's implementation or a bad interaction of the
seeds supplied with the Mersenne-Twister algorithm itself. The latter would
require a deeper understanding of the algorithm than I have at the moment.
If we can rule out the former through this thread, then I will pursue the
latter solution path.

Responses inline below, but summarizing:

1. All examples now are run using "R CMD BATCH --vanilla" as you have
suggested, to ensure that no other loaded packages or namespace changes
have interfered with the behaviour of `set.seed`.
2. Converting the character vector to integer vector has no impact on the
output.
3. Upgrading to the latest version of R has no impact on the output.
4. Multiplying the seed vector by 10L causes the behaviour to vanish,
calling into question the large integer theory.


On Fri, Nov 3, 2017 at 3:09 PM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> Why R-devel -- R-help would have been appropriate:
>

> It seems you have not read the help page for
> set.seed as I expect it from posters to R-devel.
> Why would you use strings instead of integers if you *had* read it ?
>

The manual (which we did read) says:

seed a single value, interpreted as an integer,

We were confident of R coercing characters to integers correctly. We
tested, prior to making this posting that the behaviour remains intact if
we change the `seeds` variable from a character vector to the "equivalent"
integer vector by hand.

> seeds = c(86548915L, 86551615L, 86566163L, 86577411L, 86584144L,
86584272L,
+   86620568L, 86724613L, 86756002L, 86768593L, 86772411L, 86781516L,
+   86794389L, 86805854L, 86814600L, 86835092L, 86874179L, 86876466L,
+   86901193L, 86987847L, 86988080L)
>
> random_values = sapply(seeds, function(x) {
+   set.seed(x)
+   y = runif(1, 17, 26)
+   return(y)
+ })
>
> summary(random_values)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  25.13   25.36   25.66   25.58   25.83   25.94



>     > We are facing a weird situation in our code when using R's
>     > [`runif`][1] and setting seed with `set.seed` with the
>     > `kind = NULL` option (which resolves, unless I am
>     > mistaken, to `kind = "default"`; the default being
>     > `"Mersenne-Twister"`).
>
> again this is not what the help page says; rather
>
>  | The use of ?kind = NULL? or ?normal.kind = NULL? in ?RNGkind? or
>  | ?set.seed? selects the currently-used generator (including that
>  | used in the previous session if the workspace has been restored):
>  | if no generator has been used it selects ?"default"?.
>
> but as you have > 90 (!!) packages in your sessionInfo() below,
> why should we (or you) know if some of the things you did
> before or (implicitly) during loading all these packages did not
> change the RNG kind ?
>

Agreed. We are running this system in production, and we will need
`set.seed` to behave reliably with this session, however, as you say, we
are claiming that there is an issue with the PRNG, so should isolate to an
environment that does not have any of the attendant potential confounding
factors that come with having 90 packages loaded (did you count?).

As mentioned above, we have rerun all examples using "R CMD BATCH
--vanilla" and we can report that the output is unchanged.


>
>     > We set the seed using (8 digit) unique IDs generated by an
>     > upstream system, before calling `runif`:
>
>     >     seeds = c( "86548915", "86551615", "86566163",
>     > "86577411", "86584144", "86584272", "86620568",
>     > "86724613", "86756002", "86768593", "86772411",
>     > "86781516", "86794389", "86805854", "86814600",
>     > "86835092", "86874179", "86876466", "86901193",
>     > "86987847", "86988080")
>
>     >  random_values = sapply(seeds, function(x) {
>     >   set.seed(x)
>     >   y = runif(1, 17, 26)
>     >   return(y)
>     > })
>
> Why do you do that?
>
> 1) You should set the seed *once*, not multiple times in one simulation.
>

This code is written like this since this seed is set every time the
function (API) is called for call-level replicability. It doesn't make a
lot of sense in an MRE, but this is a critical component of the larger
function. We do acknowledge that for any one of the seeds in the vector
`seeds` the vector of draws appears to have the uniform distribution.


> 2) Assuming that your strings are correctly translated to integers
>    and the same on all platforms, independent of locales (!) etc,
>    you are again not following the simple instruction on the help page:
>
>      ?set.seed? uses a single integer argument to set as many seeds as
>      are required.  It is intended as a simple way to get quite
>      different seeds by specifying small integer arguments, and also as
>      .....
>      .....
>
> Note:   ** small ** integer
> Why do you assume   86901193  to be a small integer ?
>

Because 86901193/2^32 = 0.02. What is a "small integer"?


>
>     > This gives values that are **extremely** bunched together.
>
>     >> summary(random_values)
>     >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  25.13
>     > 25.36 25.66 25.58 25.83 25.94
>
>     > This behaviour of `runif` goes away when we use `kind =
>     > "Knuth-TAOCP-2002"`, and we get values that appear to be
>     > much more evenly spread out.
>
>     >     random_values = sapply(seeds, function(x) {
>     > set.seed(x, kind = "Knuth-TAOCP-2002") y = runif(1, 17,
>     > 26) return(y) })
>
>     > *Output omitted.*
>
>     > ---
>
>     > **The most interesting thing here is that this does not
>     > happen on Windows -- only happens on Ubuntu**
>     > (`sessionInfo` output for Ubuntu & Windows below).
>
>     > # Windows output: #
>
>     >> seeds = c(
>     >     + "86548915", "86551615", "86566163", "86577411",
>     > "86584144", + "86584272", "86620568", "86724613",
>     > "86756002", "86768593", "86772411", + "86781516",
>     > "86794389", "86805854", "86814600", "86835092",
>     > "86874179", + "86876466", "86901193", "86987847",
>     > "86988080")
>     >>
>     >> random_values = sapply(seeds, function(x) {
>     >     + set.seed(x) + y = runif(1, 17, 26) + return(y) + })
>     >>
>     >> summary(random_values)
>     >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  17.32
>     > 20.14 23.00 22.17 24.07 25.90
>
>     > Can someone help understand what is going on?
>
>     > Ubuntu
>     > ------
>
>     > R version 3.4.0 (2017-04-21)
>     > Platform: x86_64-pc-linux-gnu (64-bit)
>     > Running under: Ubuntu 16.04.2 LTS
>
> You have not learned to get a current version of R.
> ===> You should not write to R-devel (sorry if this may sound harsh ..)
>

We do spend a while on certain versions of R since upgrading our systems in
production is not something we are able to do frequently & this version is
only 6 months old. However, addressing your concern, upgrading to R 3.4.2
leaves the output unchanged.


> - - - - -
> After doing all this, your problem may still be just
> because you are using much too large integers for the 'seed'
> argument of set.seed()
>

Note that multiplying the reported set of seeds by 10, results in expected
output, so not clear if there is a sweet spot that bugs out the
Mersenne-Twister algorithm:

seeds = c(86548915L, 86551615L, 86566163L, 86577411L, 86584144L, 86584272L,
  86620568L, 86724613L, 86756002L, 86768593L, 86772411L, 86781516L,
  86794389L, 86805854L, 86814600L, 86835092L, 86874179L, 86876466L,
  86901193L, 86987847L, 86988080L)*10

random_values = sapply(seeds, function(x) {
  set.seed(x)
  y = runif(1, 17, 26)
  return(y)
})

summary(random_values)



> I really really strongly believe you should have used R-help
> instead of R-devel.
>
> Best,
> Martin Maechler
>

If you continue to believe with the inputs given in this reply that this
should be on R-help, we will switch over.

Your continued help would be appreciated in understanding the issue.

T

	[[alternative HTML version deleted]]


From sokol at insa-toulouse.fr  Fri Nov  3 15:56:38 2017
From: sokol at insa-toulouse.fr (Serguei Sokol)
Date: Fri, 3 Nov 2017 15:56:38 +0100
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CA+S-T795S9ab42kUXztrWSpoA1U7UYWA5mYwm8mTx0g_jNqXYQ@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <23036.14679.82544.855772@stat.math.ethz.ch>
 <CA+S-T795S9ab42kUXztrWSpoA1U7UYWA5mYwm8mTx0g_jNqXYQ@mail.gmail.com>
Message-ID: <04aae49e-397f-41dd-c1a1-fc2819cd6054@insa-toulouse.fr>

Le 03/11/2017 ? 14:24, Tirthankar Chakravarty a ?crit?:
> Martin,
>
> Thanks for the helpful reply. Alas I had forgotten that (implied)
> unfavorable comparisons of *nix systems with Windows systems would likely
> draw irate (but always substantive) responses on the R-devel list -- poor
> phrasing on my part. :)
>
> Regardless, let me try to address some of the concerns related to the
> construction of the MRE itself and try to see if we can clean away the
> shrubbery & zero down on the core issue, since I continue to believe that
> this is an issue with either R's implementation or a bad interaction of the
> seeds supplied with the Mersenne-Twister algorithm itself.
Is there an issue or not may depend on how the vector 'seeds' was obtained.
If we simply do:

r=range(seeds)
s=seq(r[1], r[2])
# pick up seeds giving the runif() in (25; 26) interval
s25=s[sapply(s, function(i) {set.seed(i); runif(1, 17, 26) > 25})]
all(seeds %in% s25) # TRUE
length(s25)/diff(r) # 0.1107351

Thus, the proportion of such seeds is about 1/9 which is coherent with
the fraction of the interval (25; 26) in (17; 26).
Now, you can pick up any 21 numbers from s25 vector (which is 48631 long) and say
"Look! It's weird, all values drawn by runif() are > 25!"
But s25 has nothing strange by itself. If we plot kind of cumulative distribution

plot(s25, type="l")

It shows a distribution very close to uniform which means that such seeds
are not grouped more densely or rarely somewhere.
So, how your set of seeds was obtained?

Best,
Serguei.

>   The latter would
> require a deeper understanding of the algorithm than I have at the moment.
> If we can rule out the former through this thread, then I will pursue the
> latter solution path.
>
> Responses inline below, but summarizing:
>
> 1. All examples now are run using "R CMD BATCH --vanilla" as you have
> suggested, to ensure that no other loaded packages or namespace changes
> have interfered with the behaviour of `set.seed`.
> 2. Converting the character vector to integer vector has no impact on the
> output.
> 3. Upgrading to the latest version of R has no impact on the output.
> 4. Multiplying the seed vector by 10L causes the behaviour to vanish,
> calling into question the large integer theory.
>
>
> On Fri, Nov 3, 2017 at 3:09 PM, Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
>> Why R-devel -- R-help would have been appropriate:
>>
>> It seems you have not read the help page for
>> set.seed as I expect it from posters to R-devel.
>> Why would you use strings instead of integers if you *had* read it ?
>>
> The manual (which we did read) says:
>
> seed a single value, interpreted as an integer,
>
> We were confident of R coercing characters to integers correctly. We
> tested, prior to making this posting that the behaviour remains intact if
> we change the `seeds` variable from a character vector to the "equivalent"
> integer vector by hand.
>
>> seeds = c(86548915L, 86551615L, 86566163L, 86577411L, 86584144L,
> 86584272L,
> +   86620568L, 86724613L, 86756002L, 86768593L, 86772411L, 86781516L,
> +   86794389L, 86805854L, 86814600L, 86835092L, 86874179L, 86876466L,
> +   86901193L, 86987847L, 86988080L)
>> random_values = sapply(seeds, function(x) {
> +   set.seed(x)
> +   y = runif(1, 17, 26)
> +   return(y)
> + })
>> summary(random_values)
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>    25.13   25.36   25.66   25.58   25.83   25.94
>
>
>
>>      > We are facing a weird situation in our code when using R's
>>      > [`runif`][1] and setting seed with `set.seed` with the
>>      > `kind = NULL` option (which resolves, unless I am
>>      > mistaken, to `kind = "default"`; the default being
>>      > `"Mersenne-Twister"`).
>>
>> again this is not what the help page says; rather
>>
>>   | The use of ?kind = NULL? or ?normal.kind = NULL? in ?RNGkind? or
>>   | ?set.seed? selects the currently-used generator (including that
>>   | used in the previous session if the workspace has been restored):
>>   | if no generator has been used it selects ?"default"?.
>>
>> but as you have > 90 (!!) packages in your sessionInfo() below,
>> why should we (or you) know if some of the things you did
>> before or (implicitly) during loading all these packages did not
>> change the RNG kind ?
>>
> Agreed. We are running this system in production, and we will need
> `set.seed` to behave reliably with this session, however, as you say, we
> are claiming that there is an issue with the PRNG, so should isolate to an
> environment that does not have any of the attendant potential confounding
> factors that come with having 90 packages loaded (did you count?).
>
> As mentioned above, we have rerun all examples using "R CMD BATCH
> --vanilla" and we can report that the output is unchanged.
>
>
>>      > We set the seed using (8 digit) unique IDs generated by an
>>      > upstream system, before calling `runif`:
>>
>>      >     seeds = c( "86548915", "86551615", "86566163",
>>      > "86577411", "86584144", "86584272", "86620568",
>>      > "86724613", "86756002", "86768593", "86772411",
>>      > "86781516", "86794389", "86805854", "86814600",
>>      > "86835092", "86874179", "86876466", "86901193",
>>      > "86987847", "86988080")
>>
>>      >  random_values = sapply(seeds, function(x) {
>>      >   set.seed(x)
>>      >   y = runif(1, 17, 26)
>>      >   return(y)
>>      > })
>>
>> Why do you do that?
>>
>> 1) You should set the seed *once*, not multiple times in one simulation.
>>
> This code is written like this since this seed is set every time the
> function (API) is called for call-level replicability. It doesn't make a
> lot of sense in an MRE, but this is a critical component of the larger
> function. We do acknowledge that for any one of the seeds in the vector
> `seeds` the vector of draws appears to have the uniform distribution.
>
>
>> 2) Assuming that your strings are correctly translated to integers
>>     and the same on all platforms, independent of locales (!) etc,
>>     you are again not following the simple instruction on the help page:
>>
>>       ?set.seed? uses a single integer argument to set as many seeds as
>>       are required.  It is intended as a simple way to get quite
>>       different seeds by specifying small integer arguments, and also as
>>       .....
>>       .....
>>
>> Note:   ** small ** integer
>> Why do you assume   86901193  to be a small integer ?
>>
> Because 86901193/2^32 = 0.02. What is a "small integer"?
>
>
>>      > This gives values that are **extremely** bunched together.
>>
>>      >> summary(random_values)
>>      >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  25.13
>>      > 25.36 25.66 25.58 25.83 25.94
>>
>>      > This behaviour of `runif` goes away when we use `kind =
>>      > "Knuth-TAOCP-2002"`, and we get values that appear to be
>>      > much more evenly spread out.
>>
>>      >     random_values = sapply(seeds, function(x) {
>>      > set.seed(x, kind = "Knuth-TAOCP-2002") y = runif(1, 17,
>>      > 26) return(y) })
>>
>>      > *Output omitted.*
>>
>>      > ---
>>
>>      > **The most interesting thing here is that this does not
>>      > happen on Windows -- only happens on Ubuntu**
>>      > (`sessionInfo` output for Ubuntu & Windows below).
>>
>>      > # Windows output: #
>>
>>      >> seeds = c(
>>      >     + "86548915", "86551615", "86566163", "86577411",
>>      > "86584144", + "86584272", "86620568", "86724613",
>>      > "86756002", "86768593", "86772411", + "86781516",
>>      > "86794389", "86805854", "86814600", "86835092",
>>      > "86874179", + "86876466", "86901193", "86987847",
>>      > "86988080")
>>      >>
>>      >> random_values = sapply(seeds, function(x) {
>>      >     + set.seed(x) + y = runif(1, 17, 26) + return(y) + })
>>      >>
>>      >> summary(random_values)
>>      >        Min. 1st Qu.  Median Mean 3rd Qu.  Max.  17.32
>>      > 20.14 23.00 22.17 24.07 25.90
>>
>>      > Can someone help understand what is going on?
>>
>>      > Ubuntu
>>      > ------
>>
>>      > R version 3.4.0 (2017-04-21)
>>      > Platform: x86_64-pc-linux-gnu (64-bit)
>>      > Running under: Ubuntu 16.04.2 LTS
>>
>> You have not learned to get a current version of R.
>> ===> You should not write to R-devel (sorry if this may sound harsh ..)
>>
> We do spend a while on certain versions of R since upgrading our systems in
> production is not something we are able to do frequently & this version is
> only 6 months old. However, addressing your concern, upgrading to R 3.4.2
> leaves the output unchanged.
>
>
>> - - - - -
>> After doing all this, your problem may still be just
>> because you are using much too large integers for the 'seed'
>> argument of set.seed()
>>
> Note that multiplying the reported set of seeds by 10, results in expected
> output, so not clear if there is a sweet spot that bugs out the
> Mersenne-Twister algorithm:
>
> seeds = c(86548915L, 86551615L, 86566163L, 86577411L, 86584144L, 86584272L,
>    86620568L, 86724613L, 86756002L, 86768593L, 86772411L, 86781516L,
>    86794389L, 86805854L, 86814600L, 86835092L, 86874179L, 86876466L,
>    86901193L, 86987847L, 86988080L)*10
>
> random_values = sapply(seeds, function(x) {
>    set.seed(x)
>    y = runif(1, 17, 26)
>    return(y)
> })
>
> summary(random_values)
>
>
>
>> I really really strongly believe you should have used R-help
>> instead of R-devel.
>>
>> Best,
>> Martin Maechler
>>
> If you continue to believe with the inputs given in this reply that this
> should be on R-help, we will switch over.
>
> Your continued help would be appreciated in understanding the issue.
>
> T
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Serguei Sokol
Ingenieur de recherche INRA

Cellule math?matique
LISBP, INSA/INRA UMR 792, INSA/CNRS UMR 5504
135 Avenue de Rangueil
31077 Toulouse Cedex 04

tel: +33 5 6155 9849
email: sokol at insa-toulouse.fr
http://www.lisbp.fr


From wdunlap at tibco.com  Fri Nov  3 17:28:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 3 Nov 2017 09:28:37 -0700
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
Message-ID: <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>

The random numbers in a stream initialized with one seed should have about
the desired distribution.  You don't win by changing the seed all the
time.  Your seeds caused the first numbers of a bunch of streams to be
about the same, but the second and subsequent entries in each stream do
look uniformly distributed.

You didn't say what your 'upstream process' was, but it is easy to come up
with seeds that give about the same first value:

> Filter(function(s){set.seed(s);runif(1,17,26)>25.99}, 1:10000)
 [1]  514  532 1951 2631 3974 4068 4229 6092 6432 7264 9090



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Nov 3, 2017 at 12:49 AM, Tirthankar Chakravarty <
tirthankar.lists at gmail.com> wrote:

> This is cross-posted from SO (https://stackoverflow.com/q/47079702/1414455
> ),
> but I now feel that this needs someone from R-Devel to help understand why
> this is happening.
>
> We are facing a weird situation in our code when using R's [`runif`][1] and
> setting seed with `set.seed` with the `kind = NULL` option (which resolves,
> unless I am mistaken, to `kind = "default"`; the default being
> `"Mersenne-Twister"`).
>
> We set the seed using (8 digit) unique IDs generated by an upstream system,
> before calling `runif`:
>
>     seeds = c(
>       "86548915", "86551615", "86566163", "86577411", "86584144",
>       "86584272", "86620568", "86724613", "86756002", "86768593",
> "86772411",
>       "86781516", "86794389", "86805854", "86814600", "86835092",
> "86874179",
>       "86876466", "86901193", "86987847", "86988080")
>
>     random_values = sapply(seeds, function(x) {
>       set.seed(x)
>       y = runif(1, 17, 26)
>       return(y)
>     })
>
> This gives values that are **extremely** bunched together.
>
>     > summary(random_values)
>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       25.13   25.36   25.66   25.58   25.83   25.94
>
> This behaviour of `runif` goes away when we use `kind =
> "Knuth-TAOCP-2002"`, and we get values that appear to be much more evenly
> spread out.
>
>     random_values = sapply(seeds, function(x) {
>       set.seed(x, kind = "Knuth-TAOCP-2002")
>       y = runif(1, 17, 26)
>       return(y)
>     })
>
> *Output omitted.*
>
> ---
>
> **The most interesting thing here is that this does not happen on Windows
> -- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
> below).
>
> # Windows output: #
>
>     > seeds = c(
>     +   "86548915", "86551615", "86566163", "86577411", "86584144",
>     +   "86584272", "86620568", "86724613", "86756002", "86768593",
> "86772411",
>     +   "86781516", "86794389", "86805854", "86814600", "86835092",
> "86874179",
>     +   "86876466", "86901193", "86987847", "86988080")
>     >
>     > random_values = sapply(seeds, function(x) {
>     +   set.seed(x)
>     +   y = runif(1, 17, 26)
>     +   return(y)
>     + })
>     >
>     > summary(random_values)
>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       17.32   20.14   23.00   22.17   24.07   25.90
>
> Can someone help understand what is going on?
>
> Ubuntu
> ------
>
>     R version 3.4.0 (2017-04-21)
>     Platform: x86_64-pc-linux-gnu (64-bit)
>     Running under: Ubuntu 16.04.2 LTS
>
>     Matrix products: default
>     BLAS: /usr/lib/libblas/libblas.so.3.6.0
>     LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>
>     locale:
>     [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
>      [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
>      [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
>      [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
>      [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
>     [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8
>
>     attached base packages:
>     [1] parallel  stats     graphics  grDevices utils     datasets
> methods   base
>
>     other attached packages:
>     [1] RMySQL_0.10.8               DBI_0.6-1
>      [3] jsonlite_1.4                tidyjson_0.2.2
>      [5] optiRum_0.37.3              lubridate_1.6.0
>      [7] httr_1.2.1                  gdata_2.18.0
>      [9] XLConnect_0.2-12            XLConnectJars_0.2-12
>     [11] data.table_1.10.4           stringr_1.2.0
>     [13] readxl_1.0.0                xlsx_0.5.7
>     [15] xlsxjars_0.6.1              rJava_0.9-8
>     [17] sqldf_0.4-10                RSQLite_1.1-2
>     [19] gsubfn_0.6-6                proto_1.0.0
>     [21] dplyr_0.5.0                 purrr_0.2.4
>     [23] readr_1.1.1                 tidyr_0.6.3
>     [25] tibble_1.3.0                tidyverse_1.1.1
>     [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
>     [29] MLmetrics_1.1.1             caret_6.0-76
>     [31] ROCR_1.0-7                  gplots_3.0.1
>     [33] effects_3.1-2               pROC_1.10.0
>     [35] pscl_1.4.9                  lattice_0.20-35
>     [37] MASS_7.3-47                 ggplot2_2.2.1
>
>     loaded via a namespace (and not attached):
>     [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
> modelr_0.1.0
>      [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
>  cellranger_1.1.0
>      [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
> rvest_0.3.2
>     [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
> plyr_1.8.4
>     [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
> SparseM_1.77
>     [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
> MatrixModels_0.4-1
>     [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
> lazyeval_0.2.0
>     [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
>  memoise_1.0.0
>     [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
>  foreign_0.8-69
>     [37] tools_3.4.0        hms_0.3            munsell_0.4.3
> compiler_3.4.0
>     [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
>  nloptr_1.0.4
>     [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
> gtable_0.2.0
>     [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2     R6_2.2.0
>
>     [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
> Rcpp_0.12.11
>
>
>
> Windows
> -------
>
>     > sessionInfo()
>     R version 3.3.2 (2016-10-31)
>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>     Running under: Windows >= 8 x64 (build 9200)
>
>     locale:
>     [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> LC_MONETARY=English_India.1252
>     [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>
>     attached base packages:
>     [1] graphics  grDevices utils     datasets  grid      stats
>  methods   base
>
>     other attached packages:
>      [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
> eulerr_1.1.0         VennDiagram_1.6.17
>      [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
>  xml2_1.0.0           httr_1.3.0
>     [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
>  htmltools_0.3.6      urltools_1.6.0
>     [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
>  shiny_1.0.5          RODBC_1.3-14
>     [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
> gsubfn_0.6-6         proto_1.0.0
>     [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
>  XLConnectJars_0.2-12 data.table_1.10.4
>     [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
> readxl_0.1.1         googlesheets_0.2.1
>     [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
> RPostgreSQL_0.4-1    DBI_0.5-1
>     [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
> tidyr_0.7.0          tibble_1.3.3
>     [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0
>
>     loaded via a namespace (and not attached):
>      [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
> cellranger_1.1.0     yaml_2.1.14
>      [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
>  chron_2.3-48         digest_0.6.12.1
>     [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
>  pkgconfig_2.0.1      xtable_1.8-2
>     [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
> tools_3.3.2          hms_0.3
>     [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
> RCurl_1.95-4.8       labeling_0.3
>     [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
>  reshape2_1.4.2       R6_2.2.0
>     [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
> Rcpp_0.12.12.1
>
>   [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/
> Uniform.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tirthankar.lists at gmail.com  Fri Nov  3 18:31:59 2017
From: tirthankar.lists at gmail.com (Tirthankar Chakravarty)
Date: Fri, 3 Nov 2017 23:01:59 +0530
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
Message-ID: <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>

Bill,

I have clarified this on SO, and I will copy that clarification in here:

"Sure, we tested them on other 8-digit numbers as well & we could not
replicate. However, these are honest-to-goodness numbers generated by a
non-adversarial system that has no conception of these numbers being used
for anything other than a unique key for an entity -- these are not a
specially constructed edge case. Would be good to know what seeds will and
will not work, and why."

These numbers are generated by an application that serves a form, and
associates form IDs in a sequence. The application calls our API depending
on the form values entered by users, which in turn calls our R code that
executes some code that needs an RNG. Since the API has to be stateless, to
be able to replicate the results for possible debugging, we need to draw
random numbers in a way that we can replicate the results of the API
response -- we use the form ID as seeds.

I repeat, there is no design or anything adversarial about the way that
these numbers were generated -- the system generating these numbers and the
users entering inputs have no conception of our use of an RNG -- this is
meant to just be a random sequence of form IDs. This issue was discovered
completely by chance when the output of the API was observed to be highly
non-random. It is possible that it is a 1/10^8 chance, but that is hard to
believe, given that the API hit depends on user input. Note also that the
issue goes away when we use a different RNG as mentioned below.

T

On Fri, Nov 3, 2017 at 9:58 PM, William Dunlap <wdunlap at tibco.com> wrote:

> The random numbers in a stream initialized with one seed should have about
> the desired distribution.  You don't win by changing the seed all the
> time.  Your seeds caused the first numbers of a bunch of streams to be
> about the same, but the second and subsequent entries in each stream do
> look uniformly distributed.
>
> You didn't say what your 'upstream process' was, but it is easy to come up
> with seeds that give about the same first value:
>
> > Filter(function(s){set.seed(s);runif(1,17,26)>25.99}, 1:10000)
>  [1]  514  532 1951 2631 3974 4068 4229 6092 6432 7264 9090
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Nov 3, 2017 at 12:49 AM, Tirthankar Chakravarty <
> tirthankar.lists at gmail.com> wrote:
>
>> This is cross-posted from SO (https://stackoverflow.com/q/4
>> 7079702/1414455),
>> but I now feel that this needs someone from R-Devel to help understand why
>> this is happening.
>>
>> We are facing a weird situation in our code when using R's [`runif`][1]
>> and
>> setting seed with `set.seed` with the `kind = NULL` option (which
>> resolves,
>> unless I am mistaken, to `kind = "default"`; the default being
>> `"Mersenne-Twister"`).
>>
>> We set the seed using (8 digit) unique IDs generated by an upstream
>> system,
>> before calling `runif`:
>>
>>     seeds = c(
>>       "86548915", "86551615", "86566163", "86577411", "86584144",
>>       "86584272", "86620568", "86724613", "86756002", "86768593",
>> "86772411",
>>       "86781516", "86794389", "86805854", "86814600", "86835092",
>> "86874179",
>>       "86876466", "86901193", "86987847", "86988080")
>>
>>     random_values = sapply(seeds, function(x) {
>>       set.seed(x)
>>       y = runif(1, 17, 26)
>>       return(y)
>>     })
>>
>> This gives values that are **extremely** bunched together.
>>
>>     > summary(random_values)
>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>       25.13   25.36   25.66   25.58   25.83   25.94
>>
>> This behaviour of `runif` goes away when we use `kind =
>> "Knuth-TAOCP-2002"`, and we get values that appear to be much more evenly
>> spread out.
>>
>>     random_values = sapply(seeds, function(x) {
>>       set.seed(x, kind = "Knuth-TAOCP-2002")
>>       y = runif(1, 17, 26)
>>       return(y)
>>     })
>>
>> *Output omitted.*
>>
>> ---
>>
>> **The most interesting thing here is that this does not happen on Windows
>> -- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
>> below).
>>
>> # Windows output: #
>>
>>     > seeds = c(
>>     +   "86548915", "86551615", "86566163", "86577411", "86584144",
>>     +   "86584272", "86620568", "86724613", "86756002", "86768593",
>> "86772411",
>>     +   "86781516", "86794389", "86805854", "86814600", "86835092",
>> "86874179",
>>     +   "86876466", "86901193", "86987847", "86988080")
>>     >
>>     > random_values = sapply(seeds, function(x) {
>>     +   set.seed(x)
>>     +   y = runif(1, 17, 26)
>>     +   return(y)
>>     + })
>>     >
>>     > summary(random_values)
>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>       17.32   20.14   23.00   22.17   24.07   25.90
>>
>> Can someone help understand what is going on?
>>
>> Ubuntu
>> ------
>>
>>     R version 3.4.0 (2017-04-21)
>>     Platform: x86_64-pc-linux-gnu (64-bit)
>>     Running under: Ubuntu 16.04.2 LTS
>>
>>     Matrix products: default
>>     BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>     LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>
>>     locale:
>>     [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
>>      [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
>>      [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
>>      [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
>>      [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
>>     [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8
>>
>>     attached base packages:
>>     [1] parallel  stats     graphics  grDevices utils     datasets
>> methods   base
>>
>>     other attached packages:
>>     [1] RMySQL_0.10.8               DBI_0.6-1
>>      [3] jsonlite_1.4                tidyjson_0.2.2
>>      [5] optiRum_0.37.3              lubridate_1.6.0
>>      [7] httr_1.2.1                  gdata_2.18.0
>>      [9] XLConnect_0.2-12            XLConnectJars_0.2-12
>>     [11] data.table_1.10.4           stringr_1.2.0
>>     [13] readxl_1.0.0                xlsx_0.5.7
>>     [15] xlsxjars_0.6.1              rJava_0.9-8
>>     [17] sqldf_0.4-10                RSQLite_1.1-2
>>     [19] gsubfn_0.6-6                proto_1.0.0
>>     [21] dplyr_0.5.0                 purrr_0.2.4
>>     [23] readr_1.1.1                 tidyr_0.6.3
>>     [25] tibble_1.3.0                tidyverse_1.1.1
>>     [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
>>     [29] MLmetrics_1.1.1             caret_6.0-76
>>     [31] ROCR_1.0-7                  gplots_3.0.1
>>     [33] effects_3.1-2               pROC_1.10.0
>>     [35] pscl_1.4.9                  lattice_0.20-35
>>     [37] MASS_7.3-47                 ggplot2_2.2.1
>>
>>     loaded via a namespace (and not attached):
>>     [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
>> modelr_0.1.0
>>      [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
>>  cellranger_1.1.0
>>      [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
>> rvest_0.3.2
>>     [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
>> plyr_1.8.4
>>     [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
>> SparseM_1.77
>>     [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
>> MatrixModels_0.4-1
>>     [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
>> lazyeval_0.2.0
>>     [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
>>  memoise_1.0.0
>>     [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
>>  foreign_0.8-69
>>     [37] tools_3.4.0        hms_0.3            munsell_0.4.3
>> compiler_3.4.0
>>     [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
>>  nloptr_1.0.4
>>     [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
>> gtable_0.2.0
>>     [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2     R6_2.2.0
>>
>>     [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
>> Rcpp_0.12.11
>>
>>
>>
>> Windows
>> -------
>>
>>     > sessionInfo()
>>     R version 3.3.2 (2016-10-31)
>>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>>     Running under: Windows >= 8 x64 (build 9200)
>>
>>     locale:
>>     [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
>> LC_MONETARY=English_India.1252
>>     [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>>
>>     attached base packages:
>>     [1] graphics  grDevices utils     datasets  grid      stats
>>  methods   base
>>
>>     other attached packages:
>>      [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
>> eulerr_1.1.0         VennDiagram_1.6.17
>>      [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
>>  xml2_1.0.0           httr_1.3.0
>>     [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
>>  htmltools_0.3.6      urltools_1.6.0
>>     [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
>>  shiny_1.0.5          RODBC_1.3-14
>>     [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
>> gsubfn_0.6-6         proto_1.0.0
>>     [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
>>  XLConnectJars_0.2-12 data.table_1.10.4
>>     [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
>> readxl_0.1.1         googlesheets_0.2.1
>>     [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
>> RPostgreSQL_0.4-1    DBI_0.5-1
>>     [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
>> tidyr_0.7.0          tibble_1.3.3
>>     [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0
>>
>>     loaded via a namespace (and not attached):
>>      [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
>> cellranger_1.1.0     yaml_2.1.14
>>      [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
>>  chron_2.3-48         digest_0.6.12.1
>>     [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
>>  pkgconfig_2.0.1      xtable_1.8-2
>>     [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
>> tools_3.3.2          hms_0.3
>>     [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
>> RCurl_1.95-4.8       labeling_0.3
>>     [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
>>  reshape2_1.4.2       R6_2.2.0
>>     [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
>> Rcpp_0.12.12.1
>>
>>   [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Unif
>> orm.html
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Nov  3 18:57:25 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 3 Nov 2017 10:57:25 -0700
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
Message-ID: <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>

Another other generator is subject to the same problem with the same
probabilitiy.

> Filter(function(s){set.seed(s,
kind="Knuth-TAOCP-2002");runif(1,17,26)>25.99}, 1:10000)
 [1]  280  415  826 1372 2224 2544 3270 3594 3809 4116 4236 5018 5692 7043
7212 7364 7747 9256 9491 9568 9886



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Nov 3, 2017 at 10:31 AM, Tirthankar Chakravarty <
tirthankar.lists at gmail.com> wrote:

>
> Bill,
>
> I have clarified this on SO, and I will copy that clarification in here:
>
> "Sure, we tested them on other 8-digit numbers as well & we could not
> replicate. However, these are honest-to-goodness numbers generated by a
> non-adversarial system that has no conception of these numbers being used
> for anything other than a unique key for an entity -- these are not a
> specially constructed edge case. Would be good to know what seeds will and
> will not work, and why."
>
> These numbers are generated by an application that serves a form, and
> associates form IDs in a sequence. The application calls our API depending
> on the form values entered by users, which in turn calls our R code that
> executes some code that needs an RNG. Since the API has to be stateless, to
> be able to replicate the results for possible debugging, we need to draw
> random numbers in a way that we can replicate the results of the API
> response -- we use the form ID as seeds.
>
> I repeat, there is no design or anything adversarial about the way that
> these numbers were generated -- the system generating these numbers and
> the users entering inputs have no conception of our use of an RNG -- this
> is meant to just be a random sequence of form IDs. This issue was
> discovered completely by chance when the output of the API was observed to
> be highly non-random. It is possible that it is a 1/10^8 chance, but that
> is hard to believe, given that the API hit depends on user input. Note also
> that the issue goes away when we use a different RNG as mentioned below.
>
> T
>
> On Fri, Nov 3, 2017 at 9:58 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> The random numbers in a stream initialized with one seed should have
>> about the desired distribution.  You don't win by changing the seed all the
>> time.  Your seeds caused the first numbers of a bunch of streams to be
>> about the same, but the second and subsequent entries in each stream do
>> look uniformly distributed.
>>
>> You didn't say what your 'upstream process' was, but it is easy to come
>> up with seeds that give about the same first value:
>>
>> > Filter(function(s){set.seed(s);runif(1,17,26)>25.99}, 1:10000)
>>  [1]  514  532 1951 2631 3974 4068 4229 6092 6432 7264 9090
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Nov 3, 2017 at 12:49 AM, Tirthankar Chakravarty <
>> tirthankar.lists at gmail.com> wrote:
>>
>>> This is cross-posted from SO (https://stackoverflow.com/q/4
>>> 7079702/1414455),
>>> but I now feel that this needs someone from R-Devel to help understand
>>> why
>>> this is happening.
>>>
>>> We are facing a weird situation in our code when using R's [`runif`][1]
>>> and
>>> setting seed with `set.seed` with the `kind = NULL` option (which
>>> resolves,
>>> unless I am mistaken, to `kind = "default"`; the default being
>>> `"Mersenne-Twister"`).
>>>
>>> We set the seed using (8 digit) unique IDs generated by an upstream
>>> system,
>>> before calling `runif`:
>>>
>>>     seeds = c(
>>>       "86548915", "86551615", "86566163", "86577411", "86584144",
>>>       "86584272", "86620568", "86724613", "86756002", "86768593",
>>> "86772411",
>>>       "86781516", "86794389", "86805854", "86814600", "86835092",
>>> "86874179",
>>>       "86876466", "86901193", "86987847", "86988080")
>>>
>>>     random_values = sapply(seeds, function(x) {
>>>       set.seed(x)
>>>       y = runif(1, 17, 26)
>>>       return(y)
>>>     })
>>>
>>> This gives values that are **extremely** bunched together.
>>>
>>>     > summary(random_values)
>>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>       25.13   25.36   25.66   25.58   25.83   25.94
>>>
>>> This behaviour of `runif` goes away when we use `kind =
>>> "Knuth-TAOCP-2002"`, and we get values that appear to be much more evenly
>>> spread out.
>>>
>>>     random_values = sapply(seeds, function(x) {
>>>       set.seed(x, kind = "Knuth-TAOCP-2002")
>>>       y = runif(1, 17, 26)
>>>       return(y)
>>>     })
>>>
>>> *Output omitted.*
>>>
>>> ---
>>>
>>> **The most interesting thing here is that this does not happen on Windows
>>> -- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
>>> below).
>>>
>>> # Windows output: #
>>>
>>>     > seeds = c(
>>>     +   "86548915", "86551615", "86566163", "86577411", "86584144",
>>>     +   "86584272", "86620568", "86724613", "86756002", "86768593",
>>> "86772411",
>>>     +   "86781516", "86794389", "86805854", "86814600", "86835092",
>>> "86874179",
>>>     +   "86876466", "86901193", "86987847", "86988080")
>>>     >
>>>     > random_values = sapply(seeds, function(x) {
>>>     +   set.seed(x)
>>>     +   y = runif(1, 17, 26)
>>>     +   return(y)
>>>     + })
>>>     >
>>>     > summary(random_values)
>>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>       17.32   20.14   23.00   22.17   24.07   25.90
>>>
>>> Can someone help understand what is going on?
>>>
>>> Ubuntu
>>> ------
>>>
>>>     R version 3.4.0 (2017-04-21)
>>>     Platform: x86_64-pc-linux-gnu (64-bit)
>>>     Running under: Ubuntu 16.04.2 LTS
>>>
>>>     Matrix products: default
>>>     BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>>     LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>>
>>>     locale:
>>>     [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
>>>      [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
>>>      [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
>>>      [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
>>>      [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
>>>     [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8
>>>
>>>     attached base packages:
>>>     [1] parallel  stats     graphics  grDevices utils     datasets
>>> methods   base
>>>
>>>     other attached packages:
>>>     [1] RMySQL_0.10.8               DBI_0.6-1
>>>      [3] jsonlite_1.4                tidyjson_0.2.2
>>>      [5] optiRum_0.37.3              lubridate_1.6.0
>>>      [7] httr_1.2.1                  gdata_2.18.0
>>>      [9] XLConnect_0.2-12            XLConnectJars_0.2-12
>>>     [11] data.table_1.10.4           stringr_1.2.0
>>>     [13] readxl_1.0.0                xlsx_0.5.7
>>>     [15] xlsxjars_0.6.1              rJava_0.9-8
>>>     [17] sqldf_0.4-10                RSQLite_1.1-2
>>>     [19] gsubfn_0.6-6                proto_1.0.0
>>>     [21] dplyr_0.5.0                 purrr_0.2.4
>>>     [23] readr_1.1.1                 tidyr_0.6.3
>>>     [25] tibble_1.3.0                tidyverse_1.1.1
>>>     [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
>>>     [29] MLmetrics_1.1.1             caret_6.0-76
>>>     [31] ROCR_1.0-7                  gplots_3.0.1
>>>     [33] effects_3.1-2               pROC_1.10.0
>>>     [35] pscl_1.4.9                  lattice_0.20-35
>>>     [37] MASS_7.3-47                 ggplot2_2.2.1
>>>
>>>     loaded via a namespace (and not attached):
>>>     [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
>>> modelr_0.1.0
>>>      [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
>>>  cellranger_1.1.0
>>>      [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
>>> rvest_0.3.2
>>>     [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
>>> plyr_1.8.4
>>>     [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
>>> SparseM_1.77
>>>     [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
>>> MatrixModels_0.4-1
>>>     [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
>>> lazyeval_0.2.0
>>>     [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
>>>  memoise_1.0.0
>>>     [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
>>>  foreign_0.8-69
>>>     [37] tools_3.4.0        hms_0.3            munsell_0.4.3
>>> compiler_3.4.0
>>>     [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
>>>  nloptr_1.0.4
>>>     [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
>>> gtable_0.2.0
>>>     [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2
>>>  R6_2.2.0
>>>
>>>     [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
>>> Rcpp_0.12.11
>>>
>>>
>>>
>>> Windows
>>> -------
>>>
>>>     > sessionInfo()
>>>     R version 3.3.2 (2016-10-31)
>>>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>     Running under: Windows >= 8 x64 (build 9200)
>>>
>>>     locale:
>>>     [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
>>> LC_MONETARY=English_India.1252
>>>     [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>>>
>>>     attached base packages:
>>>     [1] graphics  grDevices utils     datasets  grid      stats
>>>  methods   base
>>>
>>>     other attached packages:
>>>      [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
>>> eulerr_1.1.0         VennDiagram_1.6.17
>>>      [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
>>>  xml2_1.0.0           httr_1.3.0
>>>     [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
>>>  htmltools_0.3.6      urltools_1.6.0
>>>     [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
>>>  shiny_1.0.5          RODBC_1.3-14
>>>     [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
>>> gsubfn_0.6-6         proto_1.0.0
>>>     [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
>>>  XLConnectJars_0.2-12 data.table_1.10.4
>>>     [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
>>> readxl_0.1.1         googlesheets_0.2.1
>>>     [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
>>> RPostgreSQL_0.4-1    DBI_0.5-1
>>>     [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
>>> tidyr_0.7.0          tibble_1.3.3
>>>     [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0
>>>
>>>     loaded via a namespace (and not attached):
>>>      [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
>>> cellranger_1.1.0     yaml_2.1.14
>>>      [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
>>>  chron_2.3-48         digest_0.6.12.1
>>>     [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
>>>  pkgconfig_2.0.1      xtable_1.8-2
>>>     [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
>>> tools_3.3.2          hms_0.3
>>>     [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
>>> RCurl_1.95-4.8       labeling_0.3
>>>     [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
>>>  reshape2_1.4.2       R6_2.2.0
>>>     [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
>>> Rcpp_0.12.12.1
>>>
>>>   [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Unif
>>> orm.html
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From tirthankar.lists at gmail.com  Fri Nov  3 19:30:03 2017
From: tirthankar.lists at gmail.com (Tirthankar Chakravarty)
Date: Sat, 4 Nov 2017 00:00:03 +0530
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
Message-ID: <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>

Bill,

Appreciate the point that both you and Serguei are making, but the sequence
in question is not a selected or filtered set. These are values as observed
in a sequence from a  mechanism described below. The probabilities required
to generate this exact sequence in the wild seem staggering to me.

T

On Fri, Nov 3, 2017 at 11:27 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Another other generator is subject to the same problem with the same
> probabilitiy.
>
> > Filter(function(s){set.seed(s, kind="Knuth-TAOCP-2002");runif(1,17,26)>25.99},
> 1:10000)
>  [1]  280  415  826 1372 2224 2544 3270 3594 3809 4116 4236 5018 5692 7043
> 7212 7364 7747 9256 9491 9568 9886
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Nov 3, 2017 at 10:31 AM, Tirthankar Chakravarty <
> tirthankar.lists at gmail.com> wrote:
>
>>
>> Bill,
>>
>> I have clarified this on SO, and I will copy that clarification in here:
>>
>> "Sure, we tested them on other 8-digit numbers as well & we could not
>> replicate. However, these are honest-to-goodness numbers generated by a
>> non-adversarial system that has no conception of these numbers being used
>> for anything other than a unique key for an entity -- these are not a
>> specially constructed edge case. Would be good to know what seeds will and
>> will not work, and why."
>>
>> These numbers are generated by an application that serves a form, and
>> associates form IDs in a sequence. The application calls our API depending
>> on the form values entered by users, which in turn calls our R code that
>> executes some code that needs an RNG. Since the API has to be stateless, to
>> be able to replicate the results for possible debugging, we need to draw
>> random numbers in a way that we can replicate the results of the API
>> response -- we use the form ID as seeds.
>>
>> I repeat, there is no design or anything adversarial about the way that
>> these numbers were generated -- the system generating these numbers and
>> the users entering inputs have no conception of our use of an RNG -- this
>> is meant to just be a random sequence of form IDs. This issue was
>> discovered completely by chance when the output of the API was observed to
>> be highly non-random. It is possible that it is a 1/10^8 chance, but that
>> is hard to believe, given that the API hit depends on user input. Note also
>> that the issue goes away when we use a different RNG as mentioned below.
>>
>> T
>>
>> On Fri, Nov 3, 2017 at 9:58 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>>> The random numbers in a stream initialized with one seed should have
>>> about the desired distribution.  You don't win by changing the seed all the
>>> time.  Your seeds caused the first numbers of a bunch of streams to be
>>> about the same, but the second and subsequent entries in each stream do
>>> look uniformly distributed.
>>>
>>> You didn't say what your 'upstream process' was, but it is easy to come
>>> up with seeds that give about the same first value:
>>>
>>> > Filter(function(s){set.seed(s);runif(1,17,26)>25.99}, 1:10000)
>>>  [1]  514  532 1951 2631 3974 4068 4229 6092 6432 7264 9090
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Fri, Nov 3, 2017 at 12:49 AM, Tirthankar Chakravarty <
>>> tirthankar.lists at gmail.com> wrote:
>>>
>>>> This is cross-posted from SO (https://stackoverflow.com/q/4
>>>> 7079702/1414455),
>>>> but I now feel that this needs someone from R-Devel to help understand
>>>> why
>>>> this is happening.
>>>>
>>>> We are facing a weird situation in our code when using R's [`runif`][1]
>>>> and
>>>> setting seed with `set.seed` with the `kind = NULL` option (which
>>>> resolves,
>>>> unless I am mistaken, to `kind = "default"`; the default being
>>>> `"Mersenne-Twister"`).
>>>>
>>>> We set the seed using (8 digit) unique IDs generated by an upstream
>>>> system,
>>>> before calling `runif`:
>>>>
>>>>     seeds = c(
>>>>       "86548915", "86551615", "86566163", "86577411", "86584144",
>>>>       "86584272", "86620568", "86724613", "86756002", "86768593",
>>>> "86772411",
>>>>       "86781516", "86794389", "86805854", "86814600", "86835092",
>>>> "86874179",
>>>>       "86876466", "86901193", "86987847", "86988080")
>>>>
>>>>     random_values = sapply(seeds, function(x) {
>>>>       set.seed(x)
>>>>       y = runif(1, 17, 26)
>>>>       return(y)
>>>>     })
>>>>
>>>> This gives values that are **extremely** bunched together.
>>>>
>>>>     > summary(random_values)
>>>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>>       25.13   25.36   25.66   25.58   25.83   25.94
>>>>
>>>> This behaviour of `runif` goes away when we use `kind =
>>>> "Knuth-TAOCP-2002"`, and we get values that appear to be much more
>>>> evenly
>>>> spread out.
>>>>
>>>>     random_values = sapply(seeds, function(x) {
>>>>       set.seed(x, kind = "Knuth-TAOCP-2002")
>>>>       y = runif(1, 17, 26)
>>>>       return(y)
>>>>     })
>>>>
>>>> *Output omitted.*
>>>>
>>>> ---
>>>>
>>>> **The most interesting thing here is that this does not happen on
>>>> Windows
>>>> -- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
>>>> below).
>>>>
>>>> # Windows output: #
>>>>
>>>>     > seeds = c(
>>>>     +   "86548915", "86551615", "86566163", "86577411", "86584144",
>>>>     +   "86584272", "86620568", "86724613", "86756002", "86768593",
>>>> "86772411",
>>>>     +   "86781516", "86794389", "86805854", "86814600", "86835092",
>>>> "86874179",
>>>>     +   "86876466", "86901193", "86987847", "86988080")
>>>>     >
>>>>     > random_values = sapply(seeds, function(x) {
>>>>     +   set.seed(x)
>>>>     +   y = runif(1, 17, 26)
>>>>     +   return(y)
>>>>     + })
>>>>     >
>>>>     > summary(random_values)
>>>>        Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>>       17.32   20.14   23.00   22.17   24.07   25.90
>>>>
>>>> Can someone help understand what is going on?
>>>>
>>>> Ubuntu
>>>> ------
>>>>
>>>>     R version 3.4.0 (2017-04-21)
>>>>     Platform: x86_64-pc-linux-gnu (64-bit)
>>>>     Running under: Ubuntu 16.04.2 LTS
>>>>
>>>>     Matrix products: default
>>>>     BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>>>     LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>>>
>>>>     locale:
>>>>     [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
>>>>      [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
>>>>      [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
>>>>      [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
>>>>      [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
>>>>     [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8
>>>>
>>>>     attached base packages:
>>>>     [1] parallel  stats     graphics  grDevices utils     datasets
>>>> methods   base
>>>>
>>>>     other attached packages:
>>>>     [1] RMySQL_0.10.8               DBI_0.6-1
>>>>      [3] jsonlite_1.4                tidyjson_0.2.2
>>>>      [5] optiRum_0.37.3              lubridate_1.6.0
>>>>      [7] httr_1.2.1                  gdata_2.18.0
>>>>      [9] XLConnect_0.2-12            XLConnectJars_0.2-12
>>>>     [11] data.table_1.10.4           stringr_1.2.0
>>>>     [13] readxl_1.0.0                xlsx_0.5.7
>>>>     [15] xlsxjars_0.6.1              rJava_0.9-8
>>>>     [17] sqldf_0.4-10                RSQLite_1.1-2
>>>>     [19] gsubfn_0.6-6                proto_1.0.0
>>>>     [21] dplyr_0.5.0                 purrr_0.2.4
>>>>     [23] readr_1.1.1                 tidyr_0.6.3
>>>>     [25] tibble_1.3.0                tidyverse_1.1.1
>>>>     [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
>>>>     [29] MLmetrics_1.1.1             caret_6.0-76
>>>>     [31] ROCR_1.0-7                  gplots_3.0.1
>>>>     [33] effects_3.1-2               pROC_1.10.0
>>>>     [35] pscl_1.4.9                  lattice_0.20-35
>>>>     [37] MASS_7.3-47                 ggplot2_2.2.1
>>>>
>>>>     loaded via a namespace (and not attached):
>>>>     [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
>>>> modelr_0.1.0
>>>>      [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
>>>>  cellranger_1.1.0
>>>>      [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
>>>> rvest_0.3.2
>>>>     [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
>>>> plyr_1.8.4
>>>>     [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
>>>> SparseM_1.77
>>>>     [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
>>>> MatrixModels_0.4-1
>>>>     [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
>>>> lazyeval_0.2.0
>>>>     [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
>>>>  memoise_1.0.0
>>>>     [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
>>>>  foreign_0.8-69
>>>>     [37] tools_3.4.0        hms_0.3            munsell_0.4.3
>>>> compiler_3.4.0
>>>>     [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
>>>>  nloptr_1.0.4
>>>>     [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
>>>> gtable_0.2.0
>>>>     [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2
>>>>  R6_2.2.0
>>>>
>>>>     [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
>>>> Rcpp_0.12.11
>>>>
>>>>
>>>>
>>>> Windows
>>>> -------
>>>>
>>>>     > sessionInfo()
>>>>     R version 3.3.2 (2016-10-31)
>>>>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>     Running under: Windows >= 8 x64 (build 9200)
>>>>
>>>>     locale:
>>>>     [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
>>>> LC_MONETARY=English_India.1252
>>>>     [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>>>>
>>>>     attached base packages:
>>>>     [1] graphics  grDevices utils     datasets  grid      stats
>>>>  methods   base
>>>>
>>>>     other attached packages:
>>>>      [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
>>>> eulerr_1.1.0         VennDiagram_1.6.17
>>>>      [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
>>>>  xml2_1.0.0           httr_1.3.0
>>>>     [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
>>>>  htmltools_0.3.6      urltools_1.6.0
>>>>     [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
>>>>  shiny_1.0.5          RODBC_1.3-14
>>>>     [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
>>>> gsubfn_0.6-6         proto_1.0.0
>>>>     [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
>>>>  XLConnectJars_0.2-12 data.table_1.10.4
>>>>     [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
>>>> readxl_0.1.1         googlesheets_0.2.1
>>>>     [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
>>>> RPostgreSQL_0.4-1    DBI_0.5-1
>>>>     [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
>>>> tidyr_0.7.0          tibble_1.3.3
>>>>     [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0
>>>>
>>>>     loaded via a namespace (and not attached):
>>>>      [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
>>>> cellranger_1.1.0     yaml_2.1.14
>>>>      [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
>>>>  chron_2.3-48         digest_0.6.12.1
>>>>     [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
>>>>  pkgconfig_2.0.1      xtable_1.8-2
>>>>     [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
>>>> tools_3.3.2          hms_0.3
>>>>     [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
>>>> RCurl_1.95-4.8       labeling_0.3
>>>>     [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
>>>>  reshape2_1.4.2       R6_2.2.0
>>>>     [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
>>>> Rcpp_0.12.12.1
>>>>
>>>>   [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Unif
>>>> orm.html
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From arietencate at gmail.com  Sat Nov  4 11:50:17 2017
From: arietencate at gmail.com (Arie ten Cate)
Date: Sat, 4 Nov 2017 11:50:17 +0100
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
 <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
Message-ID: <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>

Hello Tyler,

I rephrase my previous mail, as follows:

In your example, T_i = X1:X2:X3. Let F_j = X3. (The numerical
variables X1 and X2 are not encoded at all.) Then T_{i(j)} = X1:X2,
which in the example is dropped from the model. Hence the X3 in T_i
must be encoded by dummy variables, as indeed it is.

  Arie


On Thu, Nov 2, 2017 at 4:11 PM, Tyler <tylermw at gmail.com> wrote:
> Hi Arie,
>
> The book out of which this behavior is based does not use factor (in this
> section) to refer to categorical factor. I will again point to this
> sentence, from page 40, in the same section and referring to the behavior
> under question, that shows F_j is not limited to categorical factors:
> "Numeric variables appear in the computations as themselves, uncoded.
> Therefore, the rule does not do anything special for them, and it remains
> valid, in a trivial sense, whenever any of the F_j is numeric rather than
> categorical."
>
> Note the "... whenever any of the F_j is numeric rather than categorical."
> Factor here is used in the more general sense of the word, not referring to
> the R type "factor." The behavior of R does not match the heuristic that
> it's citing.
>
> Best regards,
> Tyler
>
> On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com> wrote:
>>
>> Hello Tyler,
>>
>> Thank you for searching for, and finding, the basic description of the
>> behavior of R in this matter.
>>
>> I think your example is in agreement with the book.
>>
>> But let me first note the following. You write: "F_j refers to a
>> factor (variable) in a model and not a categorical factor". However:
>> "a factor is a vector object used to specify a discrete
>> classification" (start of chapter 4 of "An Introduction to R".) You
>> might also see the description of the R function factor().
>>
>> You note that the book says about a factor F_j:
>>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
>> formula and by dummy variables if it has not"
>>
>> You find:
>>    "However, the example I gave demonstrated that this dummy variable
>> encoding only occurs for the model where the missing term is the
>> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
>>
>> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
>> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in T_i
>> must be encoded by dummy variables, as indeed it is.
>>
>>   Arie
>>
>> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
>> > Hi Arie,
>> >
>> > Thank you for your further research into the issue.
>> >
>> > Regarding Stata: On the other hand, JMP gives model matrices that use
>> > the
>> > main effects contrasts in computing the higher order interactions,
>> > without
>> > the dummy variable encoding. I verified this both by analyzing the
>> > linear
>> > model given in my first example and noting that JMP has one more degree
>> > of
>> > freedom than R for the same model, as well as looking at the generated
>> > model
>> > matrices. It's easy to find a design where JMP will allow us fit our
>> > model
>> > with goodness-of-fit estimates and R will not due to the extra degree(s)
>> > of
>> > freedom required. Let's keep the conversation limited to R.
>> >
>> > I want to refocus back onto my original bug report, which was not for a
>> > missing main effects term, but rather for a missing lower-order
>> > interaction
>> > term. The behavior of model.matrix.default() for a missing main effects
>> > term
>> > is a nice example to demonstrate how model.matrix encodes with dummy
>> > variables instead of contrasts, but doesn't demonstrate the inconsistent
>> > behavior my bug report highlighted.
>> >
>> > I went looking for documentation on this behavior, and the issue stems
>> > not
>> > from model.matrix.default(), but rather the terms() function in
>> > interpreting
>> > the formula. This "clever" replacement of contrasts by dummy variables
>> > to
>> > maintain marginality (presuming that's the reason) is not described
>> > anywhere
>> > in the documentation for either the model.matrix() or the terms()
>> > function.
>> > In order to find a description for the behavior, I had to look in the
>> > underlying C code, buried above the "TermCode" function of the "model.c"
>> > file, which says:
>> >
>> > "TermCode decides on the encoding of a model term. Returns 1 if variable
>> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if it
>> > is to
>> > be encoded by dummy variables.  This is decided using the heuristic
>> > described in Statistical Models in S, page 38."
>> >
>> > I do not have a copy of this book, and I suspect most R users do not as
>> > well. Thankfully, however, some of the pages describing this behavior
>> > were
>> > available as part of Amazon's "Look Inside" feature--but if not for
>> > that, I
>> > would have no idea what heuristic R was using. Since those pages could
>> > made
>> > unavailable by Amazon at any time, at the very least we have an problem
>> > with
>> > a lack of documentation.
>> >
>> > However, I still believe there is a bug when comparing R's
>> > implementation to
>> > the heuristic described in the book. From Statistical Models in S, page
>> > 38-39:
>> >
>> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)} denote the
>> > margin of T_i for factor F_j--that is, the term obtained by dropping F_j
>> > from T_i. We say that T_{i(j)} has appeared in the formula if there is
>> > some
>> > term T_i' for i' < i such that T_i' contains all the factors appearing
>> > in
>> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the preceding
>> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in the
>> > formula and by dummy variables if it has not"
>> >
>> > Here, F_j refers to a factor (variable) in a model and not a categorical
>> > factor, as specified later in that section (page 40): "Numeric variables
>> > appear in the computations as themselves, uncoded. Therefore, the rule
>> > does
>> > not do anything special for them, and it remains valid, in a trivial
>> > sense,
>> > whenever any of the F_j is numeric rather than categorical."
>> >
>> > Going back to my original example with three variables: X1 (numeric), X2
>> > (numeric), X3 (categorical). This heuristic prescribes encoding X1:X2:X3
>> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the formula.
>> > When
>> > any of the preceding terms do not exist, this heuristic tells us to use
>> > dummy variables to encode the interaction (e.g. "F_j [the interaction
>> > term]
>> > is coded ... by dummy variables if it [any of the marginal terms
>> > obtained by
>> > dropping a single factor in the interaction] has not [appeared in the
>> > formula]"). However, the example I gave demonstrated that this dummy
>> > variable encoding only occurs for the model where the missing term is
>> > the
>> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
>> > interaction term X1:X2:X3 is encoded by contrasts, not dummy variables.
>> > This
>> > is inconsistent with the description of the intended behavior given in
>> > the
>> > book.
>> >
>> > Best regards,
>> > Tyler
>> >
>> >
>> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate <arietencate at gmail.com>
>> > wrote:
>> >>
>> >> Hello Tyler,
>> >>
>> >> I want to bring to your attention the following document: "What
>> >> happens if you omit the main effect in a regression model with an
>> >> interaction?"
>> >>
>> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a-regression-model-with-an-interaction).
>> >> This gives a useful review of the problem. Your example is Case 2: a
>> >> continuous and a categorical regressor.
>> >>
>> >> The numerical examples are coded in Stata, and they give the same
>> >> result as in R. Hence, if this is a bug in R then it is also a bug in
>> >> Stata. That seems very unlikely.
>> >>
>> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
>> >>
>> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
>> >> print("Full model")
>> >> print(model.matrix(~(socst+grp)^2 ,data=df))
>> >> print("Example 2.1: drop socst")
>> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
>> >> print("Example 2.2: drop grp")
>> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
>> >>
>> >> This gives indeed the following regressors:
>> >>
>> >> "Full model"
>> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
>> >> "Example 2.1: drop socst"
>> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3 socst:grp4
>> >> "Example 2.2: drop grp"
>> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
>> >>
>> >> There is a little bit of R documentation about this, based on the
>> >> concept of marginality, which typically forbids a model having an
>> >> interaction but not the corresponding main effects. (You might see the
>> >> references in https://en.wikipedia.org/wiki/Principle_of_marginality )
>> >>     See "An Introduction to R", by Venables and Smith and the R Core
>> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
>> >> details are complicated, model formulae in R will normally generate
>> >> the models that an expert statistician would expect, provided that
>> >> marginality is preserved. Fitting, for [a contrary] example, a model
>> >> with an interaction but not the corresponding main effects will in
>> >> general lead to surprising results ....".
>> >>     The Reference Manual states that the R functions dropterm() and
>> >> addterm() resp. drop or add only terms such that marginality is
>> >> preserved.
>> >>
>> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
>> >> Example 2.1 in Case 2 discussed above. As discussed there, in Stata
>> >> and in R the drop of the continuous variable has no effect on the
>> >> degrees of freedom here: it is just a reparameterisation of the full
>> >> model, protecting you against losing marginality... Hence the
>> >> model.matrix 'mm' is still square and nonsingular after the drop of
>> >> X1, unless of course when a row is removed from the matrix 'design'
>> >> when before creating 'mm'.
>> >>
>> >>     Arie
>> >>
>> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
>> >> > You could possibly try to explain away the behavior for a missing
>> >> > main
>> >> > effects term, since without the main effects term we don't have main
>> >> > effect
>> >> > columns in the model matrix used to compute the interaction columns
>> >> > (At
>> >> > best this is undocumented behavior--I still think it's a bug, as we
>> >> > know
>> >> > how we would encode the categorical factors if they were in fact
>> >> > present.
>> >> > It's either specified in contrasts.arg or using the default set in
>> >> > options). However, when all the main effects are present, why would
>> >> > the
>> >> > three-factor interaction column not simply be the product of the main
>> >> > effect columns? In my example: we know X1, we know X2, and we know
>> >> > X3.
>> >> > Why
>> >> > does the encoding of X1:X2:X3 depend on whether we specified a
>> >> > two-factor
>> >> > interaction, AND only changes for specific missing interactions?
>> >> >
>> >> > In addition, I can use a two-term example similar to yours to show
>> >> > how
>> >> > this
>> >> > behavior results in a singular covariance matrix when, given the
>> >> > desired
>> >> > factor encoding, it should not be singular.
>> >> >
>> >> > We start with a full factorial design for a two-level continuous
>> >> > factor
>> >> > and
>> >> > a three-level categorical factor, and remove a single row. This
>> >> > design
>> >> > matrix does not leave enough degrees of freedom to determine
>> >> > goodness-of-fit, but should allow us to obtain parameter estimates.
>> >> >
>> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
>> >> >> design = design[-1,]
>> >> >> design
>> >> >   X1 X2
>> >> > 2 -1  A
>> >> > 3  1  B
>> >> > 4 -1  B
>> >> > 5  1  C
>> >> > 6 -1  C
>> >> >
>> >> > Here, we first calculate the model matrix for the full model, and
>> >> > then
>> >> > manually remove the X1 column from the model matrix. This gives us
>> >> > the
>> >> > model matrix one would expect if X1 were removed from the model. We
>> >> > then
>> >> > successfully calculate the covariance matrix.
>> >> >
>> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
>> >> >> mm
>> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
>> >> > 2           1 -1   0   0      0      0
>> >> > 3           1  1   1   0      1      0
>> >> > 4           1 -1   1   0     -1      0
>> >> > 5           1  1   0   1      0      1
>> >> > 6           1 -1   0   1      0     -1
>> >> >
>> >> >> mm = mm[,-2]
>> >> >> solve(t(mm) %*% mm)
>> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
>> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
>> >> > X2B                  -1  1.5  1.0    0.0    0.0
>> >> > X2C                  -1  1.0  1.5    0.0    0.0
>> >> > X1:X2B                0  0.0  0.0    0.5    0.0
>> >> > X1:X2C                0  0.0  0.0    0.0    0.5
>> >> >
>> >> > Here, we see the actual behavior for model.matrix. The undesired
>> >> > re-coding
>> >> > of the model matrix interaction term makes the information matrix
>> >> > singular.
>> >> >
>> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
>> >> >> mm
>> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
>> >> > 2           1   0   0     -1      0      0
>> >> > 3           1   1   0      0      1      0
>> >> > 4           1   1   0      0     -1      0
>> >> > 5           1   0   1      0      0      1
>> >> > 6           1   0   1      0      0     -1
>> >> >
>> >> >> solve(t(mm) %*% mm)
>> >> > Error in solve.default(t(mm) %*% mm) : system is computationally
>> >> > singular:
>> >> > reciprocal condition number = 5.55112e-18
>> >> >
>> >> > I still believe this is a bug.
>> >> >
>> >> > Best regards,
>> >> > Tyler Morgan-Wall
>> >> >
>> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate
>> >> > <arietencate at gmail.com>
>> >> > wrote:
>> >> >
>> >> >> I think it is not a bug. It is a general property of interactions.
>> >> >> This property is best observed if all variables are factors
>> >> >> (qualitative).
>> >> >>
>> >> >> For example, you have three variables (factors). You ask for as many
>> >> >> interactions as possible, except an interaction term between two
>> >> >> particular variables. When this interaction is not a constant, it is
>> >> >> different for different values of the remaining variable. More
>> >> >> precisely: for all values of that variable. In other words: you have
>> >> >> a
>> >> >> three-way interaction, with all values of that variable.
>> >> >>
>> >> >> An even smaller example is the following script with only two
>> >> >> variables, each being a factor:
>> >> >>
>> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
>> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
>> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
>> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
>> >> >>
>> >> >> The result is:
>> >> >>
>> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
>> >> >> 1           1   0   0   0       0       0
>> >> >> 2           1   1   0   0       0       0
>> >> >> 3           1   0   1   0       0       0
>> >> >> 4           1   1   1   0       1       0
>> >> >> 5           1   0   0   1       0       0
>> >> >> 6           1   1   0   1       0       1
>> >> >>
>> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
>> >> >> 1           1   0   0       0       0       0
>> >> >> 2           1   0   0       1       0       0
>> >> >> 3           1   1   0       0       0       0
>> >> >> 4           1   1   0       0       1       0
>> >> >> 5           1   0   1       0       0       0
>> >> >> 6           1   0   1       0       0       1
>> >> >>
>> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
>> >> >> 1           1   0       0       0       0       0
>> >> >> 2           1   1       0       0       0       0
>> >> >> 3           1   0       1       0       0       0
>> >> >> 4           1   1       0       1       0       0
>> >> >> 5           1   0       0       0       1       0
>> >> >> 6           1   1       0       0       0       1
>> >> >>
>> >> >> Thus, in the second result, we have no main effect of X1. Instead,
>> >> >> the
>> >> >> effect of X1 depends on the value of X2; either A or B or C. In
>> >> >> fact,
>> >> >> this is a two-way interaction, including all three values of X2. In
>> >> >> the third result, we have no main effect of X2, The effect of X2
>> >> >> depends on the value of X1; either p or q.
>> >> >>
>> >> >> A complicating element with your example seems to be that your X1
>> >> >> and
>> >> >> X2 are not factors.
>> >> >>
>> >> >>    Arie
>> >> >>
>> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com> wrote:
>> >> >> > Hi,
>> >> >> >
>> >> >> > I recently ran into an inconsistency in the way
>> >> >> > model.matrix.default
>> >> >> > handles factor encoding for higher level interactions with
>> >> >> > categorical
>> >> >> > variables when the full hierarchy of effects is not present.
>> >> >> > Depending on
>> >> >> > which lower level interactions are specified, the factor encoding
>> >> >> > changes
>> >> >> > for a higher level interaction. Consider the following minimal
>> >> >> reproducible
>> >> >> > example:
>> >> >> >
>> >> >> > --------------
>> >> >> >
>> >> >> >> runmatrix = expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
>> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2 X3B
>> >> >> X3C
>> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> > 1            1  1  1   0   0     1      0      0      0      0
>> >> >> > 0         0
>> >> >> > 2            1 -1  1   0   0    -1      0      0      0      0
>> >> >> > 0         0
>> >> >> > 3            1  1 -1   0   0    -1      0      0      0      0
>> >> >> > 0         0
>> >> >> > 4            1 -1 -1   0   0     1      0      0      0      0
>> >> >> > 0         0
>> >> >> > 5            1  1  1   1   0     1      1      0      1      0
>> >> >> > 1         0
>> >> >> > 6            1 -1  1   1   0    -1     -1      0      1      0
>> >> >> > -1         0
>> >> >> > 7            1  1 -1   1   0    -1      1      0     -1      0
>> >> >> > -1         0
>> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1      0
>> >> >> > 1         0
>> >> >> > 9            1  1  1   0   1     1      0      1      0      1
>> >> >> > 0         1
>> >> >> > 10           1 -1  1   0   1    -1      0     -1      0      1
>> >> >> > 0        -1
>> >> >> > 11           1  1 -1   0   1    -1      0      1      0     -1
>> >> >> > 0        -1
>> >> >> > 12           1 -1 -1   0   1     1      0     -1      0     -1
>> >> >> > 0         1
>> >> >> > attr(,"assign")
>> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
>> >> >> > attr(,"contrasts")
>> >> >> > attr(,"contrasts")$X3
>> >> >> > [1] "contr.treatment"
>> >> >> >
>> >> >> > --------------
>> >> >> >
>> >> >> > Specifying the full hierarchy gives us what we expect: the
>> >> >> > interaction
>> >> >> > columns are simply calculated from the product of the main effect
>> >> >> columns.
>> >> >> > The interaction term X1:X2:X3 gives us two columns in the model
>> >> >> > matrix,
>> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main
>> >> >> > effects.
>> >> >> >
>> >> >> > If we remove either the X2:X3 interaction or the X1:X3
>> >> >> > interaction,
>> >> >> > we
>> >> >> get
>> >> >> > what we would expect for the X1:X2:X3 interaction, but when we
>> >> >> > remove
>> >> >> > the
>> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes completely:
>> >> >> >
>> >> >> > --------------
>> >> >> >
>> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)   (Intercept) X1
>> >> >> >> X2
>> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> > 0
>> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> > 0
>> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> > 0
>> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> > 0
>> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> > 0
>> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
>> >> >> > 0
>> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
>> >> >> > 0
>> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> > 0
>> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> > 1
>> >> >> > 10           1 -1  1   0   1    -1      0      1         0
>> >> >> > -1
>> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
>> >> >> > -1
>> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> > 1
>> >> >> > attr(,"assign")
>> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> > attr(,"contrasts")
>> >> >> > attr(,"contrasts")$X3
>> >> >> > [1] "contr.treatment"
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)   (Intercept) X1
>> >> >> >> X2
>> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
>> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> > 0
>> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> > 0
>> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> > 0
>> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> > 0
>> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> > 0
>> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
>> >> >> > 0
>> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
>> >> >> > 0
>> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> > 0
>> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> > 1
>> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
>> >> >> > -1
>> >> >> > 11           1  1 -1   0   1    -1      0      1         0
>> >> >> > -1
>> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> > 1
>> >> >> > attr(,"assign")
>> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> > attr(,"contrasts")
>> >> >> > attr(,"contrasts")$X3
>> >> >> > [1] "contr.treatment"
>> >> >> >
>> >> >> >
>> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)   (Intercept) X1
>> >> >> >> X2
>> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B X1:X2:X3C
>> >> >> > 1            1  1  1   0   0      0      0      0      0         1
>> >> >> >     0         0
>> >> >> > 2            1 -1  1   0   0      0      0      0      0        -1
>> >> >> >     0         0
>> >> >> > 3            1  1 -1   0   0      0      0      0      0        -1
>> >> >> >     0         0
>> >> >> > 4            1 -1 -1   0   0      0      0      0      0         1
>> >> >> >     0         0
>> >> >> > 5            1  1  1   1   0      1      0      1      0         0
>> >> >> >     1         0
>> >> >> > 6            1 -1  1   1   0     -1      0      1      0         0
>> >> >> >    -1         0
>> >> >> > 7            1  1 -1   1   0      1      0     -1      0         0
>> >> >> >    -1         0
>> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0         0
>> >> >> >     1         0
>> >> >> > 9            1  1  1   0   1      0      1      0      1         0
>> >> >> >     0         1
>> >> >> > 10           1 -1  1   0   1      0     -1      0      1         0
>> >> >> >     0        -1
>> >> >> > 11           1  1 -1   0   1      0      1      0     -1         0
>> >> >> >     0        -1
>> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1         0
>> >> >> >     0         1
>> >> >> > attr(,"assign")
>> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
>> >> >> > attr(,"contrasts")
>> >> >> > attr(,"contrasts")$X3
>> >> >> > [1] "contr.treatment"
>> >> >> >
>> >> >> > --------------
>> >> >> >
>> >> >> > Here, we now see the encoding for the interaction X1:X2:X3 is now
>> >> >> > the
>> >> >> > interaction of X1 and X2 with a new encoding for X3 where each
>> >> >> > factor
>> >> >> level
>> >> >> > is represented by its own column. I would expect, given the two
>> >> >> > column
>> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column would
>> >> >> > also
>> >> >> > be
>> >> >> two
>> >> >> > columns regardless of what two-factor interactions we also
>> >> >> > specified,
>> >> >> > but
>> >> >> > in this case it switches to three. If other two factor
>> >> >> > interactions
>> >> >> > are
>> >> >> > missing in addition to X1:X2, this issue still occurs. This also
>> >> >> > happens
>> >> >> > regardless of the contrast specified in contrasts.arg for X3. I
>> >> >> > don't
>> >> >> > see
>> >> >> > any reasoning for this behavior given in the documentation, so I
>> >> >> > suspect
>> >> >> it
>> >> >> > is a bug.
>> >> >> >
>> >> >> > Best regards,
>> >> >> > Tyler Morgan-Wall
>> >> >> >
>> >> >> >         [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________


From suharto_anggono at yahoo.com  Sat Nov  4 13:11:48 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 4 Nov 2017 12:11:48 +0000 (UTC)
Subject: [Rd] ans[nas] <- NA in 'ifelse' (was: ifelse() woes ... can we
 agree on a ifelse2() ?)
References: <1529825091.2728209.1509797508916.ref@mail.yahoo.com>
Message-ID: <1529825091.2728209.1509797508916@mail.yahoo.com>

Removal of
ans[nas] <- NA
from the code of function 'ifelse' in R is not committed (yet). Why?

--------------------------------------------
On Mon, 28/11/16, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

 Subject: Re: [Rd] ifelse() woes ... can we agree on a ifelse2() ?

 Cc: R-devel at r-project.org, maechler at stat.math.ethz.ch
 Date: Monday, 28 November, 2016, 10:00 PM
 
>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sat, 26 Nov 2016 17:14:01 +0000 writes:

...


    > On current 'ifelse' code in R:

    > * The part
    > ans[nas] <- NA
    > could be omitted because NA's are already in place.
    > If the part is removed, variable 'nas' is no longer used.

I agree that this seems logical.  If I apply the change, R's own
full checks do not seem affected, and I may try to commit that
change and "wait and see".


...


From etiennesanchez2 at gmail.com  Sat Nov  4 13:14:10 2017
From: etiennesanchez2 at gmail.com (Etienne Sanchez)
Date: Sat, 4 Nov 2017 13:14:10 +0100
Subject: [Rd] Possible bug with a regex pattern
Message-ID: <CANgsd5_s8ZRCeTt7g=eADyg3EW+JZyy-ewOQZAfLd2FzEUkv-w@mail.gmail.com>

Dear list,

The following behaviour looks like a bug:

grepl("ab{,2}c", "abbbc")
# [1] TRUE

I would expect either FALSE or an "invalid regex" error.

More details can be found in the question I originally asked here:
https://stackoverflow.com/q/46999964/6656269

I've also opened an issue on the TRE github:
https://github.com/laurikari/tre/issues/62


Best,

Etienne


From radford at cs.toronto.edu  Sat Nov  4 16:33:10 2017
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 4 Nov 2017 11:33:10 -0400
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <mailman.7.1509793202.65508.r-devel@r-project.org>
References: <mailman.7.1509793202.65508.r-devel@r-project.org>
Message-ID: <20171104153310.GA14553@mail.cs.toronto.edu>

In the code below, you seem to be essentially using the random number
generator to implement a hash function.  This isn't a good idea.

My impression is that pseudo-random number generation methods are
generally evaluated by whether the sequence produced from any seed
"appears" to be random.  Informally, there may be some effort to make
long sequences started with seeds 1, 2, 3, etc. appear unrelated,
since that is a common use pattern when running a simulation several
times to check on variability.  But you are relying on the FIRST
number from each sequence being apparently unrelated to the seed.  
I think few or none of the people designing pseudo-random number
generators evaluate their methods by that criterion.

There is, however, a large literature on hash functions, which is
what you should look at.

But if you want a quick fix, perhaps looking not at the first number
in the sequence, but rather (say) the 10th, might be preferable.

   Radford Neal


> > seeds = c(86548915L, 86551615L, 86566163L, 86577411L, 86584144L,
> 86584272L,
> +   86620568L, 86724613L, 86756002L, 86768593L, 86772411L, 86781516L,
> +   86794389L, 86805854L, 86814600L, 86835092L, 86874179L, 86876466L,
> +   86901193L, 86987847L, 86988080L)
> >
> > random_values = sapply(seeds, function(x) {
> +   set.seed(x)
> +   y = runif(1, 17, 26)
> +   return(y)
> + })
> >
> > summary(random_values)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   25.13   25.36   25.66   25.58   25.83   25.94


From tylermw at gmail.com  Sat Nov  4 17:33:25 2017
From: tylermw at gmail.com (Tyler)
Date: Sat, 4 Nov 2017 12:33:25 -0400
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
 <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
 <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>
Message-ID: <CAJhwqzRxyE+nf5ZWF9H2BS1oy6O3jvn6TnwOosu46aEFdBuvnw@mail.gmail.com>

Hi Arie,

I understand what you're saying. The following excerpt out of the book
shows that F_j does not refer exclusively to categorical factors: "...the
rule does not do anything special for them, and it remains valid, in a
trivial sense, whenever any of the F_j is numeric rather than categorical."
Since F_j refers to both categorical and numeric variables, the behavior of
model.matrix is not consistent with the heuristic.

Best regards,
Tyler

On Sat, Nov 4, 2017 at 6:50 AM, Arie ten Cate <arietencate at gmail.com> wrote:

> Hello Tyler,
>
> I rephrase my previous mail, as follows:
>
> In your example, T_i = X1:X2:X3. Let F_j = X3. (The numerical
> variables X1 and X2 are not encoded at all.) Then T_{i(j)} = X1:X2,
> which in the example is dropped from the model. Hence the X3 in T_i
> must be encoded by dummy variables, as indeed it is.
>
>   Arie
>
>
> On Thu, Nov 2, 2017 at 4:11 PM, Tyler <tylermw at gmail.com> wrote:
> > Hi Arie,
> >
> > The book out of which this behavior is based does not use factor (in this
> > section) to refer to categorical factor. I will again point to this
> > sentence, from page 40, in the same section and referring to the behavior
> > under question, that shows F_j is not limited to categorical factors:
> > "Numeric variables appear in the computations as themselves, uncoded.
> > Therefore, the rule does not do anything special for them, and it remains
> > valid, in a trivial sense, whenever any of the F_j is numeric rather than
> > categorical."
> >
> > Note the "... whenever any of the F_j is numeric rather than
> categorical."
> > Factor here is used in the more general sense of the word, not referring
> to
> > the R type "factor." The behavior of R does not match the heuristic that
> > it's citing.
> >
> > Best regards,
> > Tyler
> >
> > On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com>
> wrote:
> >>
> >> Hello Tyler,
> >>
> >> Thank you for searching for, and finding, the basic description of the
> >> behavior of R in this matter.
> >>
> >> I think your example is in agreement with the book.
> >>
> >> But let me first note the following. You write: "F_j refers to a
> >> factor (variable) in a model and not a categorical factor". However:
> >> "a factor is a vector object used to specify a discrete
> >> classification" (start of chapter 4 of "An Introduction to R".) You
> >> might also see the description of the R function factor().
> >>
> >> You note that the book says about a factor F_j:
> >>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
> >> formula and by dummy variables if it has not"
> >>
> >> You find:
> >>    "However, the example I gave demonstrated that this dummy variable
> >> encoding only occurs for the model where the missing term is the
> >> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
> >>
> >> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
> >> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in T_i
> >> must be encoded by dummy variables, as indeed it is.
> >>
> >>   Arie
> >>
> >> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
> >> > Hi Arie,
> >> >
> >> > Thank you for your further research into the issue.
> >> >
> >> > Regarding Stata: On the other hand, JMP gives model matrices that use
> >> > the
> >> > main effects contrasts in computing the higher order interactions,
> >> > without
> >> > the dummy variable encoding. I verified this both by analyzing the
> >> > linear
> >> > model given in my first example and noting that JMP has one more
> degree
> >> > of
> >> > freedom than R for the same model, as well as looking at the generated
> >> > model
> >> > matrices. It's easy to find a design where JMP will allow us fit our
> >> > model
> >> > with goodness-of-fit estimates and R will not due to the extra
> degree(s)
> >> > of
> >> > freedom required. Let's keep the conversation limited to R.
> >> >
> >> > I want to refocus back onto my original bug report, which was not for
> a
> >> > missing main effects term, but rather for a missing lower-order
> >> > interaction
> >> > term. The behavior of model.matrix.default() for a missing main
> effects
> >> > term
> >> > is a nice example to demonstrate how model.matrix encodes with dummy
> >> > variables instead of contrasts, but doesn't demonstrate the
> inconsistent
> >> > behavior my bug report highlighted.
> >> >
> >> > I went looking for documentation on this behavior, and the issue stems
> >> > not
> >> > from model.matrix.default(), but rather the terms() function in
> >> > interpreting
> >> > the formula. This "clever" replacement of contrasts by dummy variables
> >> > to
> >> > maintain marginality (presuming that's the reason) is not described
> >> > anywhere
> >> > in the documentation for either the model.matrix() or the terms()
> >> > function.
> >> > In order to find a description for the behavior, I had to look in the
> >> > underlying C code, buried above the "TermCode" function of the
> "model.c"
> >> > file, which says:
> >> >
> >> > "TermCode decides on the encoding of a model term. Returns 1 if
> variable
> >> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if it
> >> > is to
> >> > be encoded by dummy variables.  This is decided using the heuristic
> >> > described in Statistical Models in S, page 38."
> >> >
> >> > I do not have a copy of this book, and I suspect most R users do not
> as
> >> > well. Thankfully, however, some of the pages describing this behavior
> >> > were
> >> > available as part of Amazon's "Look Inside" feature--but if not for
> >> > that, I
> >> > would have no idea what heuristic R was using. Since those pages could
> >> > made
> >> > unavailable by Amazon at any time, at the very least we have an
> problem
> >> > with
> >> > a lack of documentation.
> >> >
> >> > However, I still believe there is a bug when comparing R's
> >> > implementation to
> >> > the heuristic described in the book. From Statistical Models in S,
> page
> >> > 38-39:
> >> >
> >> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)} denote
> the
> >> > margin of T_i for factor F_j--that is, the term obtained by dropping
> F_j
> >> > from T_i. We say that T_{i(j)} has appeared in the formula if there is
> >> > some
> >> > term T_i' for i' < i such that T_i' contains all the factors appearing
> >> > in
> >> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the
> preceding
> >> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in the
> >> > formula and by dummy variables if it has not"
> >> >
> >> > Here, F_j refers to a factor (variable) in a model and not a
> categorical
> >> > factor, as specified later in that section (page 40): "Numeric
> variables
> >> > appear in the computations as themselves, uncoded. Therefore, the rule
> >> > does
> >> > not do anything special for them, and it remains valid, in a trivial
> >> > sense,
> >> > whenever any of the F_j is numeric rather than categorical."
> >> >
> >> > Going back to my original example with three variables: X1 (numeric),
> X2
> >> > (numeric), X3 (categorical). This heuristic prescribes encoding
> X1:X2:X3
> >> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the
> formula.
> >> > When
> >> > any of the preceding terms do not exist, this heuristic tells us to
> use
> >> > dummy variables to encode the interaction (e.g. "F_j [the interaction
> >> > term]
> >> > is coded ... by dummy variables if it [any of the marginal terms
> >> > obtained by
> >> > dropping a single factor in the interaction] has not [appeared in the
> >> > formula]"). However, the example I gave demonstrated that this dummy
> >> > variable encoding only occurs for the model where the missing term is
> >> > the
> >> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
> >> > interaction term X1:X2:X3 is encoded by contrasts, not dummy
> variables.
> >> > This
> >> > is inconsistent with the description of the intended behavior given in
> >> > the
> >> > book.
> >> >
> >> > Best regards,
> >> > Tyler
> >> >
> >> >
> >> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate <arietencate at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> Hello Tyler,
> >> >>
> >> >> I want to bring to your attention the following document: "What
> >> >> happens if you omit the main effect in a regression model with an
> >> >> interaction?"
> >> >>
> >> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-o
> mit-the-main-effect-in-a-regression-model-with-an-interaction).
> >> >> This gives a useful review of the problem. Your example is Case 2: a
> >> >> continuous and a categorical regressor.
> >> >>
> >> >> The numerical examples are coded in Stata, and they give the same
> >> >> result as in R. Hence, if this is a bug in R then it is also a bug in
> >> >> Stata. That seems very unlikely.
> >> >>
> >> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
> >> >>
> >> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
> >> >> print("Full model")
> >> >> print(model.matrix(~(socst+grp)^2 ,data=df))
> >> >> print("Example 2.1: drop socst")
> >> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
> >> >> print("Example 2.2: drop grp")
> >> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
> >> >>
> >> >> This gives indeed the following regressors:
> >> >>
> >> >> "Full model"
> >> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
> >> >> "Example 2.1: drop socst"
> >> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3
> socst:grp4
> >> >> "Example 2.2: drop grp"
> >> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
> >> >>
> >> >> There is a little bit of R documentation about this, based on the
> >> >> concept of marginality, which typically forbids a model having an
> >> >> interaction but not the corresponding main effects. (You might see
> the
> >> >> references in https://en.wikipedia.org/wiki/Principle_of_marginality
> )
> >> >>     See "An Introduction to R", by Venables and Smith and the R Core
> >> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
> >> >> details are complicated, model formulae in R will normally generate
> >> >> the models that an expert statistician would expect, provided that
> >> >> marginality is preserved. Fitting, for [a contrary] example, a model
> >> >> with an interaction but not the corresponding main effects will in
> >> >> general lead to surprising results ....".
> >> >>     The Reference Manual states that the R functions dropterm() and
> >> >> addterm() resp. drop or add only terms such that marginality is
> >> >> preserved.
> >> >>
> >> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
> >> >> Example 2.1 in Case 2 discussed above. As discussed there, in Stata
> >> >> and in R the drop of the continuous variable has no effect on the
> >> >> degrees of freedom here: it is just a reparameterisation of the full
> >> >> model, protecting you against losing marginality... Hence the
> >> >> model.matrix 'mm' is still square and nonsingular after the drop of
> >> >> X1, unless of course when a row is removed from the matrix 'design'
> >> >> when before creating 'mm'.
> >> >>
> >> >>     Arie
> >> >>
> >> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
> >> >> > You could possibly try to explain away the behavior for a missing
> >> >> > main
> >> >> > effects term, since without the main effects term we don't have
> main
> >> >> > effect
> >> >> > columns in the model matrix used to compute the interaction columns
> >> >> > (At
> >> >> > best this is undocumented behavior--I still think it's a bug, as we
> >> >> > know
> >> >> > how we would encode the categorical factors if they were in fact
> >> >> > present.
> >> >> > It's either specified in contrasts.arg or using the default set in
> >> >> > options). However, when all the main effects are present, why would
> >> >> > the
> >> >> > three-factor interaction column not simply be the product of the
> main
> >> >> > effect columns? In my example: we know X1, we know X2, and we know
> >> >> > X3.
> >> >> > Why
> >> >> > does the encoding of X1:X2:X3 depend on whether we specified a
> >> >> > two-factor
> >> >> > interaction, AND only changes for specific missing interactions?
> >> >> >
> >> >> > In addition, I can use a two-term example similar to yours to show
> >> >> > how
> >> >> > this
> >> >> > behavior results in a singular covariance matrix when, given the
> >> >> > desired
> >> >> > factor encoding, it should not be singular.
> >> >> >
> >> >> > We start with a full factorial design for a two-level continuous
> >> >> > factor
> >> >> > and
> >> >> > a three-level categorical factor, and remove a single row. This
> >> >> > design
> >> >> > matrix does not leave enough degrees of freedom to determine
> >> >> > goodness-of-fit, but should allow us to obtain parameter estimates.
> >> >> >
> >> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
> >> >> >> design = design[-1,]
> >> >> >> design
> >> >> >   X1 X2
> >> >> > 2 -1  A
> >> >> > 3  1  B
> >> >> > 4 -1  B
> >> >> > 5  1  C
> >> >> > 6 -1  C
> >> >> >
> >> >> > Here, we first calculate the model matrix for the full model, and
> >> >> > then
> >> >> > manually remove the X1 column from the model matrix. This gives us
> >> >> > the
> >> >> > model matrix one would expect if X1 were removed from the model. We
> >> >> > then
> >> >> > successfully calculate the covariance matrix.
> >> >> >
> >> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
> >> >> >> mm
> >> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
> >> >> > 2           1 -1   0   0      0      0
> >> >> > 3           1  1   1   0      1      0
> >> >> > 4           1 -1   1   0     -1      0
> >> >> > 5           1  1   0   1      0      1
> >> >> > 6           1 -1   0   1      0     -1
> >> >> >
> >> >> >> mm = mm[,-2]
> >> >> >> solve(t(mm) %*% mm)
> >> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
> >> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
> >> >> > X2B                  -1  1.5  1.0    0.0    0.0
> >> >> > X2C                  -1  1.0  1.5    0.0    0.0
> >> >> > X1:X2B                0  0.0  0.0    0.5    0.0
> >> >> > X1:X2C                0  0.0  0.0    0.0    0.5
> >> >> >
> >> >> > Here, we see the actual behavior for model.matrix. The undesired
> >> >> > re-coding
> >> >> > of the model matrix interaction term makes the information matrix
> >> >> > singular.
> >> >> >
> >> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
> >> >> >> mm
> >> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
> >> >> > 2           1   0   0     -1      0      0
> >> >> > 3           1   1   0      0      1      0
> >> >> > 4           1   1   0      0     -1      0
> >> >> > 5           1   0   1      0      0      1
> >> >> > 6           1   0   1      0      0     -1
> >> >> >
> >> >> >> solve(t(mm) %*% mm)
> >> >> > Error in solve.default(t(mm) %*% mm) : system is computationally
> >> >> > singular:
> >> >> > reciprocal condition number = 5.55112e-18
> >> >> >
> >> >> > I still believe this is a bug.
> >> >> >
> >> >> > Best regards,
> >> >> > Tyler Morgan-Wall
> >> >> >
> >> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate
> >> >> > <arietencate at gmail.com>
> >> >> > wrote:
> >> >> >
> >> >> >> I think it is not a bug. It is a general property of interactions.
> >> >> >> This property is best observed if all variables are factors
> >> >> >> (qualitative).
> >> >> >>
> >> >> >> For example, you have three variables (factors). You ask for as
> many
> >> >> >> interactions as possible, except an interaction term between two
> >> >> >> particular variables. When this interaction is not a constant, it
> is
> >> >> >> different for different values of the remaining variable. More
> >> >> >> precisely: for all values of that variable. In other words: you
> have
> >> >> >> a
> >> >> >> three-way interaction, with all values of that variable.
> >> >> >>
> >> >> >> An even smaller example is the following script with only two
> >> >> >> variables, each being a factor:
> >> >> >>
> >> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
> >> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
> >> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
> >> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
> >> >> >>
> >> >> >> The result is:
> >> >> >>
> >> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
> >> >> >> 1           1   0   0   0       0       0
> >> >> >> 2           1   1   0   0       0       0
> >> >> >> 3           1   0   1   0       0       0
> >> >> >> 4           1   1   1   0       1       0
> >> >> >> 5           1   0   0   1       0       0
> >> >> >> 6           1   1   0   1       0       1
> >> >> >>
> >> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
> >> >> >> 1           1   0   0       0       0       0
> >> >> >> 2           1   0   0       1       0       0
> >> >> >> 3           1   1   0       0       0       0
> >> >> >> 4           1   1   0       0       1       0
> >> >> >> 5           1   0   1       0       0       0
> >> >> >> 6           1   0   1       0       0       1
> >> >> >>
> >> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
> >> >> >> 1           1   0       0       0       0       0
> >> >> >> 2           1   1       0       0       0       0
> >> >> >> 3           1   0       1       0       0       0
> >> >> >> 4           1   1       0       1       0       0
> >> >> >> 5           1   0       0       0       1       0
> >> >> >> 6           1   1       0       0       0       1
> >> >> >>
> >> >> >> Thus, in the second result, we have no main effect of X1. Instead,
> >> >> >> the
> >> >> >> effect of X1 depends on the value of X2; either A or B or C. In
> >> >> >> fact,
> >> >> >> this is a two-way interaction, including all three values of X2.
> In
> >> >> >> the third result, we have no main effect of X2, The effect of X2
> >> >> >> depends on the value of X1; either p or q.
> >> >> >>
> >> >> >> A complicating element with your example seems to be that your X1
> >> >> >> and
> >> >> >> X2 are not factors.
> >> >> >>
> >> >> >>    Arie
> >> >> >>
> >> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com> wrote:
> >> >> >> > Hi,
> >> >> >> >
> >> >> >> > I recently ran into an inconsistency in the way
> >> >> >> > model.matrix.default
> >> >> >> > handles factor encoding for higher level interactions with
> >> >> >> > categorical
> >> >> >> > variables when the full hierarchy of effects is not present.
> >> >> >> > Depending on
> >> >> >> > which lower level interactions are specified, the factor
> encoding
> >> >> >> > changes
> >> >> >> > for a higher level interaction. Consider the following minimal
> >> >> >> reproducible
> >> >> >> > example:
> >> >> >> >
> >> >> >> > --------------
> >> >> >> >
> >> >> >> >> runmatrix = expand.grid(X1=c(1,-1),X2=c(1,
> -1),X3=c("A","B","C"))>
> >> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2
> X3B
> >> >> >> X3C
> >> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> > 1            1  1  1   0   0     1      0      0      0      0
> >> >> >> > 0         0
> >> >> >> > 2            1 -1  1   0   0    -1      0      0      0      0
> >> >> >> > 0         0
> >> >> >> > 3            1  1 -1   0   0    -1      0      0      0      0
> >> >> >> > 0         0
> >> >> >> > 4            1 -1 -1   0   0     1      0      0      0      0
> >> >> >> > 0         0
> >> >> >> > 5            1  1  1   1   0     1      1      0      1      0
> >> >> >> > 1         0
> >> >> >> > 6            1 -1  1   1   0    -1     -1      0      1      0
> >> >> >> > -1         0
> >> >> >> > 7            1  1 -1   1   0    -1      1      0     -1      0
> >> >> >> > -1         0
> >> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1      0
> >> >> >> > 1         0
> >> >> >> > 9            1  1  1   0   1     1      0      1      0      1
> >> >> >> > 0         1
> >> >> >> > 10           1 -1  1   0   1    -1      0     -1      0      1
> >> >> >> > 0        -1
> >> >> >> > 11           1  1 -1   0   1    -1      0      1      0     -1
> >> >> >> > 0        -1
> >> >> >> > 12           1 -1 -1   0   1     1      0     -1      0     -1
> >> >> >> > 0         1
> >> >> >> > attr(,"assign")
> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
> >> >> >> > attr(,"contrasts")
> >> >> >> > attr(,"contrasts")$X3
> >> >> >> > [1] "contr.treatment"
> >> >> >> >
> >> >> >> > --------------
> >> >> >> >
> >> >> >> > Specifying the full hierarchy gives us what we expect: the
> >> >> >> > interaction
> >> >> >> > columns are simply calculated from the product of the main
> effect
> >> >> >> columns.
> >> >> >> > The interaction term X1:X2:X3 gives us two columns in the model
> >> >> >> > matrix,
> >> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main
> >> >> >> > effects.
> >> >> >> >
> >> >> >> > If we remove either the X2:X3 interaction or the X1:X3
> >> >> >> > interaction,
> >> >> >> > we
> >> >> >> get
> >> >> >> > what we would expect for the X1:X2:X3 interaction, but when we
> >> >> >> > remove
> >> >> >> > the
> >> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes completely:
> >> >> >> >
> >> >> >> > --------------
> >> >> >> >
> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)
>  (Intercept) X1
> >> >> >> >> X2
> >> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> > 1            1  1  1   0   0     1      0      0         0
> >> >> >> > 0
> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
> >> >> >> > 0
> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
> >> >> >> > 0
> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
> >> >> >> > 0
> >> >> >> > 5            1  1  1   1   0     1      1      0         1
> >> >> >> > 0
> >> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
> >> >> >> > 0
> >> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
> >> >> >> > 0
> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
> >> >> >> > 0
> >> >> >> > 9            1  1  1   0   1     1      0      1         0
> >> >> >> > 1
> >> >> >> > 10           1 -1  1   0   1    -1      0      1         0
> >> >> >> > -1
> >> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
> >> >> >> > -1
> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
> >> >> >> > 1
> >> >> >> > attr(,"assign")
> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> >> > attr(,"contrasts")
> >> >> >> > attr(,"contrasts")$X3
> >> >> >> > [1] "contr.treatment"
> >> >> >> >
> >> >> >> >
> >> >> >> >
> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)
>  (Intercept) X1
> >> >> >> >> X2
> >> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> > 1            1  1  1   0   0     1      0      0         0
> >> >> >> > 0
> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
> >> >> >> > 0
> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
> >> >> >> > 0
> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
> >> >> >> > 0
> >> >> >> > 5            1  1  1   1   0     1      1      0         1
> >> >> >> > 0
> >> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
> >> >> >> > 0
> >> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
> >> >> >> > 0
> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
> >> >> >> > 0
> >> >> >> > 9            1  1  1   0   1     1      0      1         0
> >> >> >> > 1
> >> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
> >> >> >> > -1
> >> >> >> > 11           1  1 -1   0   1    -1      0      1         0
> >> >> >> > -1
> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
> >> >> >> > 1
> >> >> >> > attr(,"assign")
> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> >> > attr(,"contrasts")
> >> >> >> > attr(,"contrasts")$X3
> >> >> >> > [1] "contr.treatment"
> >> >> >> >
> >> >> >> >
> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)
>  (Intercept) X1
> >> >> >> >> X2
> >> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B X1:X2:X3C
> >> >> >> > 1            1  1  1   0   0      0      0      0      0
>  1
> >> >> >> >     0         0
> >> >> >> > 2            1 -1  1   0   0      0      0      0      0
> -1
> >> >> >> >     0         0
> >> >> >> > 3            1  1 -1   0   0      0      0      0      0
> -1
> >> >> >> >     0         0
> >> >> >> > 4            1 -1 -1   0   0      0      0      0      0
>  1
> >> >> >> >     0         0
> >> >> >> > 5            1  1  1   1   0      1      0      1      0
>  0
> >> >> >> >     1         0
> >> >> >> > 6            1 -1  1   1   0     -1      0      1      0
>  0
> >> >> >> >    -1         0
> >> >> >> > 7            1  1 -1   1   0      1      0     -1      0
>  0
> >> >> >> >    -1         0
> >> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0
>  0
> >> >> >> >     1         0
> >> >> >> > 9            1  1  1   0   1      0      1      0      1
>  0
> >> >> >> >     0         1
> >> >> >> > 10           1 -1  1   0   1      0     -1      0      1
>  0
> >> >> >> >     0        -1
> >> >> >> > 11           1  1 -1   0   1      0      1      0     -1
>  0
> >> >> >> >     0        -1
> >> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1
>  0
> >> >> >> >     0         1
> >> >> >> > attr(,"assign")
> >> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
> >> >> >> > attr(,"contrasts")
> >> >> >> > attr(,"contrasts")$X3
> >> >> >> > [1] "contr.treatment"
> >> >> >> >
> >> >> >> > --------------
> >> >> >> >
> >> >> >> > Here, we now see the encoding for the interaction X1:X2:X3 is
> now
> >> >> >> > the
> >> >> >> > interaction of X1 and X2 with a new encoding for X3 where each
> >> >> >> > factor
> >> >> >> level
> >> >> >> > is represented by its own column. I would expect, given the two
> >> >> >> > column
> >> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column would
> >> >> >> > also
> >> >> >> > be
> >> >> >> two
> >> >> >> > columns regardless of what two-factor interactions we also
> >> >> >> > specified,
> >> >> >> > but
> >> >> >> > in this case it switches to three. If other two factor
> >> >> >> > interactions
> >> >> >> > are
> >> >> >> > missing in addition to X1:X2, this issue still occurs. This also
> >> >> >> > happens
> >> >> >> > regardless of the contrast specified in contrasts.arg for X3. I
> >> >> >> > don't
> >> >> >> > see
> >> >> >> > any reasoning for this behavior given in the documentation, so I
> >> >> >> > suspect
> >> >> >> it
> >> >> >> > is a bug.
> >> >> >> >
> >> >> >> > Best regards,
> >> >> >> > Tyler Morgan-Wall
> >> >> >> >
> >> >> >> >         [[alternative HTML version deleted]]
> >> >> >> >
> >> >> >> > ______________________________________________
>

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Sun Nov  5 03:20:20 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sat, 4 Nov 2017 19:20:20 -0700
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
Message-ID: <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>

Tirthankar,

"random number generators" do not produce random numbers.  Any given 
generator produces a fixed sequence of numbers that appear to meet 
various tests of randomness.  By picking a seed you enter that sequence 
in a particular place and subsequent numbers in the sequence appear to 
be unrelated.  There are no guarantees that if YOU pick a SET of seeds 
they won't produce a set of values that are of a similar magnitude.

You can likely solve your problem by following Radford Neal's advice of 
not using the the first number from each seed.  However, you don't need 
to use anything more than the second number.  So, you can modify your 
function as follows:

function(x) {
       set.seed(x, kind = "default")
       y = runif(2, 17, 26)
       return(y[2])
     }

Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


On 11/3/2017 11:30 AM, Tirthankar Chakravarty wrote:
> Bill,
> 
> Appreciate the point that both you and Serguei are making, but the sequence
> in question is not a selected or filtered set. These are values as observed
> in a sequence from a  mechanism described below. The probabilities required
> to generate this exact sequence in the wild seem staggering to me.
> 
> T
> 
> On Fri, Nov 3, 2017 at 11:27 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
>> Another other generator is subject to the same problem with the same
>> probabilitiy.
>>
>>> Filter(function(s){set.seed(s, kind="Knuth-TAOCP-2002");runif(1,17,26)>25.99},
>> 1:10000)
>>   [1]  280  415  826 1372 2224 2544 3270 3594 3809 4116 4236 5018 5692 7043
>> 7212 7364 7747 9256 9491 9568 9886
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Nov 3, 2017 at 10:31 AM, Tirthankar Chakravarty <
>> tirthankar.lists at gmail.com> wrote:
>>
>>>
>>> Bill,
>>>
>>> I have clarified this on SO, and I will copy that clarification in here:
>>>
>>> "Sure, we tested them on other 8-digit numbers as well & we could not
>>> replicate. However, these are honest-to-goodness numbers generated by a
>>> non-adversarial system that has no conception of these numbers being used
>>> for anything other than a unique key for an entity -- these are not a
>>> specially constructed edge case. Would be good to know what seeds will and
>>> will not work, and why."
>>>
>>> These numbers are generated by an application that serves a form, and
>>> associates form IDs in a sequence. The application calls our API depending
>>> on the form values entered by users, which in turn calls our R code that
>>> executes some code that needs an RNG. Since the API has to be stateless, to
>>> be able to replicate the results for possible debugging, we need to draw
>>> random numbers in a way that we can replicate the results of the API
>>> response -- we use the form ID as seeds.
>>>
>>> I repeat, there is no design or anything adversarial about the way that
>>> these numbers were generated -- the system generating these numbers and
>>> the users entering inputs have no conception of our use of an RNG -- this
>>> is meant to just be a random sequence of form IDs. This issue was
>>> discovered completely by chance when the output of the API was observed to
>>> be highly non-random. It is possible that it is a 1/10^8 chance, but that
>>> is hard to believe, given that the API hit depends on user input. Note also
>>> that the issue goes away when we use a different RNG as mentioned below.
>>>
>>> T
>>>
>>> On Fri, Nov 3, 2017 at 9:58 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>>> The random numbers in a stream initialized with one seed should have
>>>> about the desired distribution.  You don't win by changing the seed all the
>>>> time.  Your seeds caused the first numbers of a bunch of streams to be
>>>> about the same, but the second and subsequent entries in each stream do
>>>> look uniformly distributed.
>>>>
>>>> You didn't say what your 'upstream process' was, but it is easy to come
>>>> up with seeds that give about the same first value:
>>>>
>>>>> Filter(function(s){set.seed(s);runif(1,17,26)>25.99}, 1:10000)
>>>>   [1]  514  532 1951 2631 3974 4068 4229 6092 6432 7264 9090
>>>>
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Fri, Nov 3, 2017 at 12:49 AM, Tirthankar Chakravarty <
>>>> tirthankar.lists at gmail.com> wrote:
>>>>
>>>>> This is cross-posted from SO (https://stackoverflow.com/q/4
>>>>> 7079702/1414455),
>>>>> but I now feel that this needs someone from R-Devel to help understand
>>>>> why
>>>>> this is happening.
>>>>>
>>>>> We are facing a weird situation in our code when using R's [`runif`][1]
>>>>> and
>>>>> setting seed with `set.seed` with the `kind = NULL` option (which
>>>>> resolves,
>>>>> unless I am mistaken, to `kind = "default"`; the default being
>>>>> `"Mersenne-Twister"`).
>>>>>
>>>>> We set the seed using (8 digit) unique IDs generated by an upstream
>>>>> system,
>>>>> before calling `runif`:
>>>>>
>>>>>      seeds = c(
>>>>>        "86548915", "86551615", "86566163", "86577411", "86584144",
>>>>>        "86584272", "86620568", "86724613", "86756002", "86768593",
>>>>> "86772411",
>>>>>        "86781516", "86794389", "86805854", "86814600", "86835092",
>>>>> "86874179",
>>>>>        "86876466", "86901193", "86987847", "86988080")
>>>>>
>>>>>      random_values = sapply(seeds, function(x) {
>>>>>        set.seed(x)
>>>>>        y = runif(1, 17, 26)
>>>>>        return(y)
>>>>>      })
>>>>>
>>>>> This gives values that are **extremely** bunched together.
>>>>>
>>>>>      > summary(random_values)
>>>>>         Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>>>        25.13   25.36   25.66   25.58   25.83   25.94
>>>>>
>>>>> This behaviour of `runif` goes away when we use `kind =
>>>>> "Knuth-TAOCP-2002"`, and we get values that appear to be much more
>>>>> evenly
>>>>> spread out.
>>>>>
>>>>>      random_values = sapply(seeds, function(x) {
>>>>>        set.seed(x, kind = "Knuth-TAOCP-2002")
>>>>>        y = runif(1, 17, 26)
>>>>>        return(y)
>>>>>      })
>>>>>
>>>>> *Output omitted.*
>>>>>
>>>>> ---
>>>>>
>>>>> **The most interesting thing here is that this does not happen on
>>>>> Windows
>>>>> -- only happens on Ubuntu** (`sessionInfo` output for Ubuntu & Windows
>>>>> below).
>>>>>
>>>>> # Windows output: #
>>>>>
>>>>>      > seeds = c(
>>>>>      +   "86548915", "86551615", "86566163", "86577411", "86584144",
>>>>>      +   "86584272", "86620568", "86724613", "86756002", "86768593",
>>>>> "86772411",
>>>>>      +   "86781516", "86794389", "86805854", "86814600", "86835092",
>>>>> "86874179",
>>>>>      +   "86876466", "86901193", "86987847", "86988080")
>>>>>      >
>>>>>      > random_values = sapply(seeds, function(x) {
>>>>>      +   set.seed(x)
>>>>>      +   y = runif(1, 17, 26)
>>>>>      +   return(y)
>>>>>      + })
>>>>>      >
>>>>>      > summary(random_values)
>>>>>         Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>>>        17.32   20.14   23.00   22.17   24.07   25.90
>>>>>
>>>>> Can someone help understand what is going on?
>>>>>
>>>>> Ubuntu
>>>>> ------
>>>>>
>>>>>      R version 3.4.0 (2017-04-21)
>>>>>      Platform: x86_64-pc-linux-gnu (64-bit)
>>>>>      Running under: Ubuntu 16.04.2 LTS
>>>>>
>>>>>      Matrix products: default
>>>>>      BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>>>>      LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>>>>
>>>>>      locale:
>>>>>      [1] LC_CTYPE=en_US.UTF-8          LC_NUMERIC=C
>>>>>       [3] LC_TIME=en_US.UTF-8           LC_COLLATE=en_US.UTF-8
>>>>>       [5] LC_MONETARY=en_US.UTF-8       LC_MESSAGES=en_US.UTF-8
>>>>>       [7] LC_PAPER=en_US.UTF-8          LC_NAME=en_US.UTF-8
>>>>>       [9] LC_ADDRESS=en_US.UTF-8        LC_TELEPHONE=en_US.UTF-8
>>>>>      [11] LC_MEASUREMENT=en_US.UTF-8    LC_IDENTIFICATION=en_US.UTF-8
>>>>>
>>>>>      attached base packages:
>>>>>      [1] parallel  stats     graphics  grDevices utils     datasets
>>>>> methods   base
>>>>>
>>>>>      other attached packages:
>>>>>      [1] RMySQL_0.10.8               DBI_0.6-1
>>>>>       [3] jsonlite_1.4                tidyjson_0.2.2
>>>>>       [5] optiRum_0.37.3              lubridate_1.6.0
>>>>>       [7] httr_1.2.1                  gdata_2.18.0
>>>>>       [9] XLConnect_0.2-12            XLConnectJars_0.2-12
>>>>>      [11] data.table_1.10.4           stringr_1.2.0
>>>>>      [13] readxl_1.0.0                xlsx_0.5.7
>>>>>      [15] xlsxjars_0.6.1              rJava_0.9-8
>>>>>      [17] sqldf_0.4-10                RSQLite_1.1-2
>>>>>      [19] gsubfn_0.6-6                proto_1.0.0
>>>>>      [21] dplyr_0.5.0                 purrr_0.2.4
>>>>>      [23] readr_1.1.1                 tidyr_0.6.3
>>>>>      [25] tibble_1.3.0                tidyverse_1.1.1
>>>>>      [27] rBayesianOptimization_1.1.0 xgboost_0.6-4
>>>>>      [29] MLmetrics_1.1.1             caret_6.0-76
>>>>>      [31] ROCR_1.0-7                  gplots_3.0.1
>>>>>      [33] effects_3.1-2               pROC_1.10.0
>>>>>      [35] pscl_1.4.9                  lattice_0.20-35
>>>>>      [37] MASS_7.3-47                 ggplot2_2.2.1
>>>>>
>>>>>      loaded via a namespace (and not attached):
>>>>>      [1] splines_3.4.0      foreach_1.4.3      AUC_0.3.0
>>>>> modelr_0.1.0
>>>>>       [5] gtools_3.5.0       assertthat_0.2.0   stats4_3.4.0
>>>>>   cellranger_1.1.0
>>>>>       [9] quantreg_5.33      chron_2.3-50       digest_0.6.10
>>>>> rvest_0.3.2
>>>>>      [13] minqa_1.2.4        colorspace_1.3-2   Matrix_1.2-10
>>>>> plyr_1.8.4
>>>>>      [17] psych_1.7.3.21     XML_3.98-1.7       broom_0.4.2
>>>>> SparseM_1.77
>>>>>      [21] haven_1.0.0        scales_0.4.1       lme4_1.1-13
>>>>> MatrixModels_0.4-1
>>>>>      [25] mgcv_1.8-17        car_2.1-5          nnet_7.3-12
>>>>> lazyeval_0.2.0
>>>>>      [29] pbkrtest_0.4-7     mnormt_1.5-5       magrittr_1.5
>>>>>   memoise_1.0.0
>>>>>      [33] nlme_3.1-131       forcats_0.2.0      xml2_1.1.1
>>>>>   foreign_0.8-69
>>>>>      [37] tools_3.4.0        hms_0.3            munsell_0.4.3
>>>>> compiler_3.4.0
>>>>>      [41] caTools_1.17.1     rlang_0.1.1        grid_3.4.0
>>>>>   nloptr_1.0.4
>>>>>      [45] iterators_1.0.8    bitops_1.0-6       tcltk_3.4.0
>>>>> gtable_0.2.0
>>>>>      [49] ModelMetrics_1.1.0 codetools_0.2-15   reshape2_1.4.2
>>>>>   R6_2.2.0
>>>>>
>>>>>      [53] knitr_1.15.1       KernSmooth_2.23-15 stringi_1.1.5
>>>>> Rcpp_0.12.11
>>>>>
>>>>>
>>>>>
>>>>> Windows
>>>>> -------
>>>>>
>>>>>      > sessionInfo()
>>>>>      R version 3.3.2 (2016-10-31)
>>>>>      Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>>      Running under: Windows >= 8 x64 (build 9200)
>>>>>
>>>>>      locale:
>>>>>      [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
>>>>> LC_MONETARY=English_India.1252
>>>>>      [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>>>>>
>>>>>      attached base packages:
>>>>>      [1] graphics  grDevices utils     datasets  grid      stats
>>>>>   methods   base
>>>>>
>>>>>      other attached packages:
>>>>>       [1] bindrcpp_0.2         h2o_3.14.0.3         ggrepel_0.6.5
>>>>> eulerr_1.1.0         VennDiagram_1.6.17
>>>>>       [6] futile.logger_1.4.3  scales_0.4.1         FinCal_0.6.3
>>>>>   xml2_1.0.0           httr_1.3.0
>>>>>      [11] wesanderson_0.3.2    wordcloud_2.5        RColorBrewer_1.1-2
>>>>>   htmltools_0.3.6      urltools_1.6.0
>>>>>      [16] timevis_0.4          dtplyr_0.0.1         magrittr_1.5
>>>>>   shiny_1.0.5          RODBC_1.3-14
>>>>>      [21] zoo_1.8-0            sqldf_0.4-10         RSQLite_1.1-2
>>>>> gsubfn_0.6-6         proto_1.0.0
>>>>>      [26] gdata_2.17.0         stringr_1.2.0        XLConnect_0.2-12
>>>>>   XLConnectJars_0.2-12 data.table_1.10.4
>>>>>      [31] xlsx_0.5.7           xlsxjars_0.6.1       rJava_0.9-8
>>>>> readxl_0.1.1         googlesheets_0.2.1
>>>>>      [36] jsonlite_1.5         tidyjson_0.2.1       RMySQL_0.10.9
>>>>> RPostgreSQL_0.4-1    DBI_0.5-1
>>>>>      [41] dplyr_0.7.2          purrr_0.2.3          readr_1.1.1
>>>>> tidyr_0.7.0          tibble_1.3.3
>>>>>      [46] ggplot2_2.2.0        tidyverse_1.0.0      lubridate_1.6.0
>>>>>
>>>>>      loaded via a namespace (and not attached):
>>>>>       [1] gtools_3.5.0         assertthat_0.2.0     triebeard_0.3.0
>>>>> cellranger_1.1.0     yaml_2.1.14
>>>>>       [6] slam_0.1-40          lattice_0.20-34      glue_1.1.1
>>>>>   chron_2.3-48         digest_0.6.12.1
>>>>>      [11] colorspace_1.3-1     httpuv_1.3.5         plyr_1.8.4
>>>>>   pkgconfig_2.0.1      xtable_1.8-2
>>>>>      [16] lazyeval_0.2.0       mime_0.5             memoise_1.0.0
>>>>> tools_3.3.2          hms_0.3
>>>>>      [21] munsell_0.4.3        lambda.r_1.1.9       rlang_0.1.1
>>>>> RCurl_1.95-4.8       labeling_0.3
>>>>>      [26] bitops_1.0-6         tcltk_3.3.2          gtable_0.2.0
>>>>>   reshape2_1.4.2       R6_2.2.0
>>>>>      [31] bindr_0.1            futile.options_1.0.0 stringi_1.1.2
>>>>> Rcpp_0.12.12.1
>>>>>
>>>>>    [1]: http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Unif
>>>>> orm.html
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>>
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Sun Nov  5 15:17:48 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 5 Nov 2017 09:17:48 -0500
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
Message-ID: <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>

On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
> Tirthankar,
> 
> "random number generators" do not produce random numbers.  Any given
> generator produces a fixed sequence of numbers that appear to meet
> various tests of randomness.  By picking a seed you enter that sequence
> in a particular place and subsequent numbers in the sequence appear to
> be unrelated.  There are no guarantees that if YOU pick a SET of seeds
> they won't produce a set of values that are of a similar magnitude.
> 
> You can likely solve your problem by following Radford Neal's advice of
> not using the the first number from each seed.  However, you don't need
> to use anything more than the second number.  So, you can modify your
> function as follows:
> 
> function(x) {
>         set.seed(x, kind = "default")
>         y = runif(2, 17, 26)
>         return(y[2])
>       }
> 
> Hope this is helpful,

That's assuming that the chosen seeds are unrelated to the function 
output, which seems unlikely on the face of it.  You can certainly 
choose a set of seeds that give high values on the second draw just as 
easily as you can choose seeds that give high draws on the first draw.

The interesting thing about this problem is that Tirthankar doesn't 
believe that the seed selection process is aware of the function output. 
  I would say that it must be, and he should be investigating how that 
happens if he is worried about the output, he shouldn't be worrying 
about R's RNG.

Duncan Murdoch


From tirthankar.lists at gmail.com  Sun Nov  5 16:39:08 2017
From: tirthankar.lists at gmail.com (Tirthankar Chakravarty)
Date: Sun, 5 Nov 2017 21:09:08 +0530
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
 <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
Message-ID: <CA+S-T7-pAVZdVu5hFex1mNB+8TV+ov19jR3foMHmK-bwrUKriA@mail.gmail.com>

Duncan, Daniel,

Thanks and indeed we intend to take the advice that Radford and Lukas have
provided in this thread.

I do want to re-iterate that the generating system itself cannot have any
conception of the use of form IDs as seeds for a PRNG *and* the system
itself only generates a sequence of form IDs, which are then filtered & are
passed to our API depending on basic rules on user inputs in that form.
Either in our production system a truly remarkable probability event has
happened or that the Mersenne-Twister is very susceptible to the first draw
in the sequence to be correlated across closely related seeds. Both of
these require understanding the Mersenne-Twister better.

The solution here as has been suggested is to use a different RNG with
adequate burn-in (in which case even MT would work) or to look more
carefully at our problem and understand if we just need a hash function.

In either case, we will cease to question R's implementation of
Mersenne-Twister (for the time being). :)

T



On Sun, Nov 5, 2017 at 7:47 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
>
>> Tirthankar,
>>
>> "random number generators" do not produce random numbers.  Any given
>> generator produces a fixed sequence of numbers that appear to meet
>> various tests of randomness.  By picking a seed you enter that sequence
>> in a particular place and subsequent numbers in the sequence appear to
>> be unrelated.  There are no guarantees that if YOU pick a SET of seeds
>> they won't produce a set of values that are of a similar magnitude.
>>
>> You can likely solve your problem by following Radford Neal's advice of
>> not using the the first number from each seed.  However, you don't need
>> to use anything more than the second number.  So, you can modify your
>> function as follows:
>>
>> function(x) {
>>         set.seed(x, kind = "default")
>>         y = runif(2, 17, 26)
>>         return(y[2])
>>       }
>>
>> Hope this is helpful,
>>
>
> That's assuming that the chosen seeds are unrelated to the function
> output, which seems unlikely on the face of it.  You can certainly choose a
> set of seeds that give high values on the second draw just as easily as you
> can choose seeds that give high draws on the first draw.
>
> The interesting thing about this problem is that Tirthankar doesn't
> believe that the seed selection process is aware of the function output.  I
> would say that it must be, and he should be investigating how that happens
> if he is worried about the output, he shouldn't be worrying about R's RNG.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Nov  5 16:58:51 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 5 Nov 2017 16:58:51 +0100
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
 <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
Message-ID: <855A97DA-B2C5-4132-86AC-2553F8A24AA3@gmail.com>


> On 5 Nov 2017, at 15:17 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
>> Tirthankar,
>> "random number generators" do not produce random numbers.  Any given
>> generator produces a fixed sequence of numbers that appear to meet
>> various tests of randomness.  By picking a seed you enter that sequence
>> in a particular place and subsequent numbers in the sequence appear to
>> be unrelated.  There are no guarantees that if YOU pick a SET of seeds
>> they won't produce a set of values that are of a similar magnitude.
>> You can likely solve your problem by following Radford Neal's advice of
>> not using the the first number from each seed.  However, you don't need
>> to use anything more than the second number.  So, you can modify your
>> function as follows:
>> function(x) {
>>        set.seed(x, kind = "default")
>>        y = runif(2, 17, 26)
>>        return(y[2])
>>      }
>> Hope this is helpful,
> 
> That's assuming that the chosen seeds are unrelated to the function output, which seems unlikely on the face of it.  You can certainly choose a set of seeds that give high values on the second draw just as easily as you can choose seeds that give high draws on the first draw.
> 
> The interesting thing about this problem is that Tirthankar doesn't believe that the seed selection process is aware of the function output.  I would say that it must be, and he should be investigating how that happens if he is worried about the output, he shouldn't be worrying about R's RNG.
> 

Hmm, no. The basic issue is that RNGs are constructed so that with x_{n+1} = f(x_n),
x_1, x_2, x_3,... will look random, not so that f(s_1), f(s_2), f(s_3), ... will look random for any s_1, s_2, ... . This is true, even if seeds s_1, s_2, ... are not chosen so as to mess with the RNG. In the present case, it seems that the seeds around 86e6 tend to give similar output. On the other hand, it is not _just_ the similarity in magnitude that does it, try e.g.

s <- as.integer(runif(1000000, 86.54e6, 86.98e6))
r <- sapply(s, function(s){set.seed(s); runif(1,17,26)})
plot(s,r, pch=".")

and no obvious pattern emerges. My best guess is that the seeds are not only of similar magnitude, but also have other bit-pattern similarities.

(Isn't there a Knuth quote to the effect that "Every random number generator will fail in at least one application"?)

One remaining issue is whether it is really true that the same seeds givee different output on different platforms. That shouldn't happen, I believe.


> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pgilbert902 at gmail.com  Sun Nov  5 21:16:00 2017
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 5 Nov 2017 15:16:00 -0500
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <855A97DA-B2C5-4132-86AC-2553F8A24AA3@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
 <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
 <855A97DA-B2C5-4132-86AC-2553F8A24AA3@gmail.com>
Message-ID: <815e526a-3a93-0f5e-6585-21f81b03b3d9@gmail.com>

I'll point out that there is there is a large literature on generating 
pseudo random numbers for parallel processes, and it is not as easy as 
one (at least me) would intuitively think. By a contra-positive like 
thinking one might guess that it will not be easy to pick seeds in a way 
that will produce independent sequences.

(I'm a bit confused about the objective but) If the objective is to 
produce independent sequence from some different seeds then the RNGs for 
parallel processing might be a good place to start. (And, BTW, if you 
want to reproduce parallel generated random numbers you need to keep 
track of both the starting seed and the number of nodes.)

Paul Gilbert

On 11/05/2017 10:58 AM, peter dalgaard wrote:
> 
>> On 5 Nov 2017, at 15:17 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
>>> Tirthankar,
>>> "random number generators" do not produce random numbers.  Any given
>>> generator produces a fixed sequence of numbers that appear to meet
>>> various tests of randomness.  By picking a seed you enter that sequence
>>> in a particular place and subsequent numbers in the sequence appear to
>>> be unrelated.  There are no guarantees that if YOU pick a SET of seeds
>>> they won't produce a set of values that are of a similar magnitude.
>>> You can likely solve your problem by following Radford Neal's advice of
>>> not using the the first number from each seed.  However, you don't need
>>> to use anything more than the second number.  So, you can modify your
>>> function as follows:
>>> function(x) {
>>>         set.seed(x, kind = "default")
>>>         y = runif(2, 17, 26)
>>>         return(y[2])
>>>       }
>>> Hope this is helpful,
>>
>> That's assuming that the chosen seeds are unrelated to the function output, which seems unlikely on the face of it.  You can certainly choose a set of seeds that give high values on the second draw just as easily as you can choose seeds that give high draws on the first draw.
>>
>> The interesting thing about this problem is that Tirthankar doesn't believe that the seed selection process is aware of the function output.  I would say that it must be, and he should be investigating how that happens if he is worried about the output, he shouldn't be worrying about R's RNG.
>>
> 
> Hmm, no. The basic issue is that RNGs are constructed so that with x_{n+1} = f(x_n),
> x_1, x_2, x_3,... will look random, not so that f(s_1), f(s_2), f(s_3), ... will look random for any s_1, s_2, ... . This is true, even if seeds s_1, s_2, ... are not chosen so as to mess with the RNG. In the present case, it seems that the seeds around 86e6 tend to give similar output. On the other hand, it is not _just_ the similarity in magnitude that does it, try e.g.
> 
> s <- as.integer(runif(1000000, 86.54e6, 86.98e6))
> r <- sapply(s, function(s){set.seed(s); runif(1,17,26)})
> plot(s,r, pch=".")
> 
> and no obvious pattern emerges. My best guess is that the seeds are not only of similar magnitude, but also have other bit-pattern similarities.
> 
> (Isn't there a Knuth quote to the effect that "Every random number generator will fail in at least one application"?)
> 
> One remaining issue is whether it is really true that the same seeds givee different output on different platforms. That shouldn't happen, I believe.
> 
> 
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sokol at insa-toulouse.fr  Mon Nov  6 10:29:42 2017
From: sokol at insa-toulouse.fr (Serguei Sokol)
Date: Mon, 6 Nov 2017 10:29:42 +0100
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
 <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
Message-ID: <c45a613d-7524-b25e-6ec8-95971e55ad2b@insa-toulouse.fr>

Le 05/11/2017 ? 15:17, Duncan Murdoch a ?crit?:
> On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
>> Tirthankar,
>>
>> "random number generators" do not produce random numbers.? Any given
>> generator produces a fixed sequence of numbers that appear to meet
>> various tests of randomness.? By picking a seed you enter that sequence
>> in a particular place and subsequent numbers in the sequence appear to
>> be unrelated.? There are no guarantees that if YOU pick a SET of seeds
>> they won't produce a set of values that are of a similar magnitude.
>>
>> You can likely solve your problem by following Radford Neal's advice of
>> not using the the first number from each seed.? However, you don't need
>> to use anything more than the second number.? So, you can modify your
>> function as follows:
>>
>> function(x) {
>> ??????? set.seed(x, kind = "default")
>> ??????? y = runif(2, 17, 26)
>> ??????? return(y[2])
>> ????? }
>>
>> Hope this is helpful,
>
> That's assuming that the chosen seeds are unrelated to the function output, which seems unlikely on the face of it.? You can certainly choose a set of seeds 
> that give high values on the second draw just as easily as you can choose seeds that give high draws on the first draw.
To confirm this statement, I did

s2_25=s[sapply(s, function(i) {set.seed(i); runif(2, 17, 26)[2] > 25})]
length(s2_25) # 48990

For memory, we had
length(s25) # 48631 out of 439166

which is much similar length.
So if we take the second or even the 10-th pseudo-random value we can
fall as easily (or as hard) at a seed sequence giving some narrow set.

Serguei.

>
> The interesting thing about this problem is that Tirthankar doesn't believe that the seed selection process is aware of the function output. ?I would say that 
> it must be, and he should be investigating how that happens if he is worried about the output, he shouldn't be worrying about R's RNG.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Nov  6 11:16:26 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 6 Nov 2017 05:16:26 -0500
Subject: [Rd] Extreme bunching of random values from runif with
 Mersenne-Twister seed
In-Reply-To: <855A97DA-B2C5-4132-86AC-2553F8A24AA3@gmail.com>
References: <CA+S-T79BhosJQR7nQkO_Eg3pu7Kvz-0xmUOvsBR5Msa+7W+jow@mail.gmail.com>
 <CAF8bMca0D1ZVsFB40-Pqx3vquuMzUDdaETyRy9oWUm4OCrMyrg@mail.gmail.com>
 <CA+S-T7_DsigtAsj=LBxwoUWNn-2x+R_oDbvGnkDFFTgtnkcRcg@mail.gmail.com>
 <CAF8bMcb-=ijBuXmFpRC+r=ogE+y0rG3MwMvk1kM=mnYgdiWNmg@mail.gmail.com>
 <CA+S-T7_--bJ_xWh+th1KLLf3=JuzS+E6tpiJCMVe=fCGUUNYvg@mail.gmail.com>
 <cd5359ff-ecaf-b998-ef1c-b89d564b9769@gmail.com>
 <3d1b6158-d6a6-fdf1-6498-d3b0655b0113@gmail.com>
 <855A97DA-B2C5-4132-86AC-2553F8A24AA3@gmail.com>
Message-ID: <7710aca7-d936-8124-1fca-f422462abe22@gmail.com>

On 05/11/2017 10:58 AM, peter dalgaard wrote:
> 
>> On 5 Nov 2017, at 15:17 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 04/11/2017 10:20 PM, Daniel Nordlund wrote:
>>> Tirthankar,
>>> "random number generators" do not produce random numbers.  Any given
>>> generator produces a fixed sequence of numbers that appear to meet
>>> various tests of randomness.  By picking a seed you enter that sequence
>>> in a particular place and subsequent numbers in the sequence appear to
>>> be unrelated.  There are no guarantees that if YOU pick a SET of seeds
>>> they won't produce a set of values that are of a similar magnitude.
>>> You can likely solve your problem by following Radford Neal's advice of
>>> not using the the first number from each seed.  However, you don't need
>>> to use anything more than the second number.  So, you can modify your
>>> function as follows:
>>> function(x) {
>>>         set.seed(x, kind = "default")
>>>         y = runif(2, 17, 26)
>>>         return(y[2])
>>>       }
>>> Hope this is helpful,
>>
>> That's assuming that the chosen seeds are unrelated to the function output, which seems unlikely on the face of it.  You can certainly choose a set of seeds that give high values on the second draw just as easily as you can choose seeds that give high draws on the first draw.
>>
>> The interesting thing about this problem is that Tirthankar doesn't believe that the seed selection process is aware of the function output.  I would say that it must be, and he should be investigating how that happens if he is worried about the output, he shouldn't be worrying about R's RNG.
>>
> 
> Hmm, no. The basic issue is that RNGs are constructed so that with x_{n+1} = f(x_n),
> x_1, x_2, x_3,... will look random, not so that f(s_1), f(s_2), f(s_3), ... will look random for any s_1, s_2, ... . This is true, even if seeds s_1, s_2, ... are not chosen so as to mess with the RNG. In the present case, it seems that the seeds around 86e6 tend to give similar output. On the other hand, it is not _just_ the similarity in magnitude that does it, try e.g.
> 
> s <- as.integer(runif(1000000, 86.54e6, 86.98e6))
> r <- sapply(s, function(s){set.seed(s); runif(1,17,26)})
> plot(s,r, pch=".")
> 
> and no obvious pattern emerges. My best guess is that the seeds are not only of similar magnitude, but also have other bit-pattern similarities.
> 
> (Isn't there a Knuth quote to the effect that "Every random number generator will fail in at least one application"?)
> 
> One remaining issue is whether it is really true that the same seeds givee different output on different platforms. That shouldn't happen, I believe.

I don't think there's a platform difference if the same generator is 
used. In my tests, I get the Ubuntu results on both MacOS and Windows. 
In one of the earlier messages, Tirthankar said he was using 
RNGkind(kind = NULL), which means earlier experiments with a different 
generator would taint the results.

Duncan Murdoch


From arietencate at gmail.com  Mon Nov  6 12:45:41 2017
From: arietencate at gmail.com (Arie ten Cate)
Date: Mon, 6 Nov 2017 12:45:41 +0100
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CAJhwqzRxyE+nf5ZWF9H2BS1oy6O3jvn6TnwOosu46aEFdBuvnw@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
 <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
 <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>
 <CAJhwqzRxyE+nf5ZWF9H2BS1oy6O3jvn6TnwOosu46aEFdBuvnw@mail.gmail.com>
Message-ID: <CACg-3ubR8YP8XoJGJ+aMEJ0GyeZxMNtFG69GScGtXyFuM1yYWg@mail.gmail.com>

Hello Tyler,

You write that you understand what I am saying. However, I am now at
loss about what exactly is the problem with the behavior of R.  Here
is a script which reproduces your experiments with three variables
(excluding the full model):

m=expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))
model.matrix(~(X1+X2+X3)^3-X1:X3,data=m)
model.matrix(~(X1+X2+X3)^3-X2:X3,data=m)
model.matrix(~(X1+X2+X3)^3-X1:X2,data=m)

Below are the three results, similar to your first mail. (The first
two are basically the same, of course.) Please pick one result which
you think is not consistent with the heuristic and please give what
you think is the correct result:

model.matrix(~(X1+X2+X3)^3-X1:X3)
  (Intercept)
  X1 X2 X3B X3C
  X1:X2 X2:X3B X2:X3C
  X1:X2:X3B X1:X2:X3C

model.matrix(~(X1+X2+X3)^3-X2:X3)
  (Intercept)
  X1 X2 X3B X3C
  X1:X2 X1:X3B X1:X3C
  X1:X2:X3B X1:X2:X3C

model.matrix(~(X1+X2+X3)^3-X1:X2)
  (Intercept)
  X1 X2 X3B X3C
  X1:X3B X1:X3C X2:X3B X2:X3C
  X1:X2:X3A X1:X2:X3B X1:X2:X3C

(I take it that the combination of X3A and X3B and X3C implies dummy
encoding, and the combination of only X3B and X3C implies contrasts
encoding, with respect to X3A.)

Thanks in advance,

Arie


On Sat, Nov 4, 2017 at 5:33 PM, Tyler <tylermw at gmail.com> wrote:
> Hi Arie,
>
> I understand what you're saying. The following excerpt out of the book shows
> that F_j does not refer exclusively to categorical factors: "...the rule
> does not do anything special for them, and it remains valid, in a trivial
> sense, whenever any of the F_j is numeric rather than categorical." Since
> F_j refers to both categorical and numeric variables, the behavior of
> model.matrix is not consistent with the heuristic.
>
> Best regards,
> Tyler
>
> On Sat, Nov 4, 2017 at 6:50 AM, Arie ten Cate <arietencate at gmail.com> wrote:
>>
>> Hello Tyler,
>>
>> I rephrase my previous mail, as follows:
>>
>> In your example, T_i = X1:X2:X3. Let F_j = X3. (The numerical
>> variables X1 and X2 are not encoded at all.) Then T_{i(j)} = X1:X2,
>> which in the example is dropped from the model. Hence the X3 in T_i
>> must be encoded by dummy variables, as indeed it is.
>>
>>   Arie
>>
>>
>> On Thu, Nov 2, 2017 at 4:11 PM, Tyler <tylermw at gmail.com> wrote:
>> > Hi Arie,
>> >
>> > The book out of which this behavior is based does not use factor (in
>> > this
>> > section) to refer to categorical factor. I will again point to this
>> > sentence, from page 40, in the same section and referring to the
>> > behavior
>> > under question, that shows F_j is not limited to categorical factors:
>> > "Numeric variables appear in the computations as themselves, uncoded.
>> > Therefore, the rule does not do anything special for them, and it
>> > remains
>> > valid, in a trivial sense, whenever any of the F_j is numeric rather
>> > than
>> > categorical."
>> >
>> > Note the "... whenever any of the F_j is numeric rather than
>> > categorical."
>> > Factor here is used in the more general sense of the word, not referring
>> > to
>> > the R type "factor." The behavior of R does not match the heuristic that
>> > it's citing.
>> >
>> > Best regards,
>> > Tyler
>> >
>> > On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com>
>> > wrote:
>> >>
>> >> Hello Tyler,
>> >>
>> >> Thank you for searching for, and finding, the basic description of the
>> >> behavior of R in this matter.
>> >>
>> >> I think your example is in agreement with the book.
>> >>
>> >> But let me first note the following. You write: "F_j refers to a
>> >> factor (variable) in a model and not a categorical factor". However:
>> >> "a factor is a vector object used to specify a discrete
>> >> classification" (start of chapter 4 of "An Introduction to R".) You
>> >> might also see the description of the R function factor().
>> >>
>> >> You note that the book says about a factor F_j:
>> >>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
>> >> formula and by dummy variables if it has not"
>> >>
>> >> You find:
>> >>    "However, the example I gave demonstrated that this dummy variable
>> >> encoding only occurs for the model where the missing term is the
>> >> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
>> >>
>> >> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
>> >> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in T_i
>> >> must be encoded by dummy variables, as indeed it is.
>> >>
>> >>   Arie
>> >>
>> >> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
>> >> > Hi Arie,
>> >> >
>> >> > Thank you for your further research into the issue.
>> >> >
>> >> > Regarding Stata: On the other hand, JMP gives model matrices that use
>> >> > the
>> >> > main effects contrasts in computing the higher order interactions,
>> >> > without
>> >> > the dummy variable encoding. I verified this both by analyzing the
>> >> > linear
>> >> > model given in my first example and noting that JMP has one more
>> >> > degree
>> >> > of
>> >> > freedom than R for the same model, as well as looking at the
>> >> > generated
>> >> > model
>> >> > matrices. It's easy to find a design where JMP will allow us fit our
>> >> > model
>> >> > with goodness-of-fit estimates and R will not due to the extra
>> >> > degree(s)
>> >> > of
>> >> > freedom required. Let's keep the conversation limited to R.
>> >> >
>> >> > I want to refocus back onto my original bug report, which was not for
>> >> > a
>> >> > missing main effects term, but rather for a missing lower-order
>> >> > interaction
>> >> > term. The behavior of model.matrix.default() for a missing main
>> >> > effects
>> >> > term
>> >> > is a nice example to demonstrate how model.matrix encodes with dummy
>> >> > variables instead of contrasts, but doesn't demonstrate the
>> >> > inconsistent
>> >> > behavior my bug report highlighted.
>> >> >
>> >> > I went looking for documentation on this behavior, and the issue
>> >> > stems
>> >> > not
>> >> > from model.matrix.default(), but rather the terms() function in
>> >> > interpreting
>> >> > the formula. This "clever" replacement of contrasts by dummy
>> >> > variables
>> >> > to
>> >> > maintain marginality (presuming that's the reason) is not described
>> >> > anywhere
>> >> > in the documentation for either the model.matrix() or the terms()
>> >> > function.
>> >> > In order to find a description for the behavior, I had to look in the
>> >> > underlying C code, buried above the "TermCode" function of the
>> >> > "model.c"
>> >> > file, which says:
>> >> >
>> >> > "TermCode decides on the encoding of a model term. Returns 1 if
>> >> > variable
>> >> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if
>> >> > it
>> >> > is to
>> >> > be encoded by dummy variables.  This is decided using the heuristic
>> >> > described in Statistical Models in S, page 38."
>> >> >
>> >> > I do not have a copy of this book, and I suspect most R users do not
>> >> > as
>> >> > well. Thankfully, however, some of the pages describing this behavior
>> >> > were
>> >> > available as part of Amazon's "Look Inside" feature--but if not for
>> >> > that, I
>> >> > would have no idea what heuristic R was using. Since those pages
>> >> > could
>> >> > made
>> >> > unavailable by Amazon at any time, at the very least we have an
>> >> > problem
>> >> > with
>> >> > a lack of documentation.
>> >> >
>> >> > However, I still believe there is a bug when comparing R's
>> >> > implementation to
>> >> > the heuristic described in the book. From Statistical Models in S,
>> >> > page
>> >> > 38-39:
>> >> >
>> >> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)} denote
>> >> > the
>> >> > margin of T_i for factor F_j--that is, the term obtained by dropping
>> >> > F_j
>> >> > from T_i. We say that T_{i(j)} has appeared in the formula if there
>> >> > is
>> >> > some
>> >> > term T_i' for i' < i such that T_i' contains all the factors
>> >> > appearing
>> >> > in
>> >> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the
>> >> > preceding
>> >> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in the
>> >> > formula and by dummy variables if it has not"
>> >> >
>> >> > Here, F_j refers to a factor (variable) in a model and not a
>> >> > categorical
>> >> > factor, as specified later in that section (page 40): "Numeric
>> >> > variables
>> >> > appear in the computations as themselves, uncoded. Therefore, the
>> >> > rule
>> >> > does
>> >> > not do anything special for them, and it remains valid, in a trivial
>> >> > sense,
>> >> > whenever any of the F_j is numeric rather than categorical."
>> >> >
>> >> > Going back to my original example with three variables: X1 (numeric),
>> >> > X2
>> >> > (numeric), X3 (categorical). This heuristic prescribes encoding
>> >> > X1:X2:X3
>> >> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the
>> >> > formula.
>> >> > When
>> >> > any of the preceding terms do not exist, this heuristic tells us to
>> >> > use
>> >> > dummy variables to encode the interaction (e.g. "F_j [the interaction
>> >> > term]
>> >> > is coded ... by dummy variables if it [any of the marginal terms
>> >> > obtained by
>> >> > dropping a single factor in the interaction] has not [appeared in the
>> >> > formula]"). However, the example I gave demonstrated that this dummy
>> >> > variable encoding only occurs for the model where the missing term is
>> >> > the
>> >> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
>> >> > interaction term X1:X2:X3 is encoded by contrasts, not dummy
>> >> > variables.
>> >> > This
>> >> > is inconsistent with the description of the intended behavior given
>> >> > in
>> >> > the
>> >> > book.
>> >> >
>> >> > Best regards,
>> >> > Tyler
>> >> >
>> >> >
>> >> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate
>> >> > <arietencate at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> Hello Tyler,
>> >> >>
>> >> >> I want to bring to your attention the following document: "What
>> >> >> happens if you omit the main effect in a regression model with an
>> >> >> interaction?"
>> >> >>
>> >> >>
>> >> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a-regression-model-with-an-interaction).
>> >> >> This gives a useful review of the problem. Your example is Case 2: a
>> >> >> continuous and a categorical regressor.
>> >> >>
>> >> >> The numerical examples are coded in Stata, and they give the same
>> >> >> result as in R. Hence, if this is a bug in R then it is also a bug
>> >> >> in
>> >> >> Stata. That seems very unlikely.
>> >> >>
>> >> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
>> >> >>
>> >> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
>> >> >> print("Full model")
>> >> >> print(model.matrix(~(socst+grp)^2 ,data=df))
>> >> >> print("Example 2.1: drop socst")
>> >> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
>> >> >> print("Example 2.2: drop grp")
>> >> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
>> >> >>
>> >> >> This gives indeed the following regressors:
>> >> >>
>> >> >> "Full model"
>> >> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
>> >> >> "Example 2.1: drop socst"
>> >> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3
>> >> >> socst:grp4
>> >> >> "Example 2.2: drop grp"
>> >> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
>> >> >>
>> >> >> There is a little bit of R documentation about this, based on the
>> >> >> concept of marginality, which typically forbids a model having an
>> >> >> interaction but not the corresponding main effects. (You might see
>> >> >> the
>> >> >> references in https://en.wikipedia.org/wiki/Principle_of_marginality
>> >> >> )
>> >> >>     See "An Introduction to R", by Venables and Smith and the R Core
>> >> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
>> >> >> details are complicated, model formulae in R will normally generate
>> >> >> the models that an expert statistician would expect, provided that
>> >> >> marginality is preserved. Fitting, for [a contrary] example, a model
>> >> >> with an interaction but not the corresponding main effects will in
>> >> >> general lead to surprising results ....".
>> >> >>     The Reference Manual states that the R functions dropterm() and
>> >> >> addterm() resp. drop or add only terms such that marginality is
>> >> >> preserved.
>> >> >>
>> >> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
>> >> >> Example 2.1 in Case 2 discussed above. As discussed there, in Stata
>> >> >> and in R the drop of the continuous variable has no effect on the
>> >> >> degrees of freedom here: it is just a reparameterisation of the full
>> >> >> model, protecting you against losing marginality... Hence the
>> >> >> model.matrix 'mm' is still square and nonsingular after the drop of
>> >> >> X1, unless of course when a row is removed from the matrix 'design'
>> >> >> when before creating 'mm'.
>> >> >>
>> >> >>     Arie
>> >> >>
>> >> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
>> >> >> > You could possibly try to explain away the behavior for a missing
>> >> >> > main
>> >> >> > effects term, since without the main effects term we don't have
>> >> >> > main
>> >> >> > effect
>> >> >> > columns in the model matrix used to compute the interaction
>> >> >> > columns
>> >> >> > (At
>> >> >> > best this is undocumented behavior--I still think it's a bug, as
>> >> >> > we
>> >> >> > know
>> >> >> > how we would encode the categorical factors if they were in fact
>> >> >> > present.
>> >> >> > It's either specified in contrasts.arg or using the default set in
>> >> >> > options). However, when all the main effects are present, why
>> >> >> > would
>> >> >> > the
>> >> >> > three-factor interaction column not simply be the product of the
>> >> >> > main
>> >> >> > effect columns? In my example: we know X1, we know X2, and we know
>> >> >> > X3.
>> >> >> > Why
>> >> >> > does the encoding of X1:X2:X3 depend on whether we specified a
>> >> >> > two-factor
>> >> >> > interaction, AND only changes for specific missing interactions?
>> >> >> >
>> >> >> > In addition, I can use a two-term example similar to yours to show
>> >> >> > how
>> >> >> > this
>> >> >> > behavior results in a singular covariance matrix when, given the
>> >> >> > desired
>> >> >> > factor encoding, it should not be singular.
>> >> >> >
>> >> >> > We start with a full factorial design for a two-level continuous
>> >> >> > factor
>> >> >> > and
>> >> >> > a three-level categorical factor, and remove a single row. This
>> >> >> > design
>> >> >> > matrix does not leave enough degrees of freedom to determine
>> >> >> > goodness-of-fit, but should allow us to obtain parameter
>> >> >> > estimates.
>> >> >> >
>> >> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
>> >> >> >> design = design[-1,]
>> >> >> >> design
>> >> >> >   X1 X2
>> >> >> > 2 -1  A
>> >> >> > 3  1  B
>> >> >> > 4 -1  B
>> >> >> > 5  1  C
>> >> >> > 6 -1  C
>> >> >> >
>> >> >> > Here, we first calculate the model matrix for the full model, and
>> >> >> > then
>> >> >> > manually remove the X1 column from the model matrix. This gives us
>> >> >> > the
>> >> >> > model matrix one would expect if X1 were removed from the model.
>> >> >> > We
>> >> >> > then
>> >> >> > successfully calculate the covariance matrix.
>> >> >> >
>> >> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
>> >> >> >> mm
>> >> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
>> >> >> > 2           1 -1   0   0      0      0
>> >> >> > 3           1  1   1   0      1      0
>> >> >> > 4           1 -1   1   0     -1      0
>> >> >> > 5           1  1   0   1      0      1
>> >> >> > 6           1 -1   0   1      0     -1
>> >> >> >
>> >> >> >> mm = mm[,-2]
>> >> >> >> solve(t(mm) %*% mm)
>> >> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
>> >> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
>> >> >> > X2B                  -1  1.5  1.0    0.0    0.0
>> >> >> > X2C                  -1  1.0  1.5    0.0    0.0
>> >> >> > X1:X2B                0  0.0  0.0    0.5    0.0
>> >> >> > X1:X2C                0  0.0  0.0    0.0    0.5
>> >> >> >
>> >> >> > Here, we see the actual behavior for model.matrix. The undesired
>> >> >> > re-coding
>> >> >> > of the model matrix interaction term makes the information matrix
>> >> >> > singular.
>> >> >> >
>> >> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
>> >> >> >> mm
>> >> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
>> >> >> > 2           1   0   0     -1      0      0
>> >> >> > 3           1   1   0      0      1      0
>> >> >> > 4           1   1   0      0     -1      0
>> >> >> > 5           1   0   1      0      0      1
>> >> >> > 6           1   0   1      0      0     -1
>> >> >> >
>> >> >> >> solve(t(mm) %*% mm)
>> >> >> > Error in solve.default(t(mm) %*% mm) : system is computationally
>> >> >> > singular:
>> >> >> > reciprocal condition number = 5.55112e-18
>> >> >> >
>> >> >> > I still believe this is a bug.
>> >> >> >
>> >> >> > Best regards,
>> >> >> > Tyler Morgan-Wall
>> >> >> >
>> >> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate
>> >> >> > <arietencate at gmail.com>
>> >> >> > wrote:
>> >> >> >
>> >> >> >> I think it is not a bug. It is a general property of
>> >> >> >> interactions.
>> >> >> >> This property is best observed if all variables are factors
>> >> >> >> (qualitative).
>> >> >> >>
>> >> >> >> For example, you have three variables (factors). You ask for as
>> >> >> >> many
>> >> >> >> interactions as possible, except an interaction term between two
>> >> >> >> particular variables. When this interaction is not a constant, it
>> >> >> >> is
>> >> >> >> different for different values of the remaining variable. More
>> >> >> >> precisely: for all values of that variable. In other words: you
>> >> >> >> have
>> >> >> >> a
>> >> >> >> three-way interaction, with all values of that variable.
>> >> >> >>
>> >> >> >> An even smaller example is the following script with only two
>> >> >> >> variables, each being a factor:
>> >> >> >>
>> >> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
>> >> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
>> >> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
>> >> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
>> >> >> >>
>> >> >> >> The result is:
>> >> >> >>
>> >> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
>> >> >> >> 1           1   0   0   0       0       0
>> >> >> >> 2           1   1   0   0       0       0
>> >> >> >> 3           1   0   1   0       0       0
>> >> >> >> 4           1   1   1   0       1       0
>> >> >> >> 5           1   0   0   1       0       0
>> >> >> >> 6           1   1   0   1       0       1
>> >> >> >>
>> >> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
>> >> >> >> 1           1   0   0       0       0       0
>> >> >> >> 2           1   0   0       1       0       0
>> >> >> >> 3           1   1   0       0       0       0
>> >> >> >> 4           1   1   0       0       1       0
>> >> >> >> 5           1   0   1       0       0       0
>> >> >> >> 6           1   0   1       0       0       1
>> >> >> >>
>> >> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
>> >> >> >> 1           1   0       0       0       0       0
>> >> >> >> 2           1   1       0       0       0       0
>> >> >> >> 3           1   0       1       0       0       0
>> >> >> >> 4           1   1       0       1       0       0
>> >> >> >> 5           1   0       0       0       1       0
>> >> >> >> 6           1   1       0       0       0       1
>> >> >> >>
>> >> >> >> Thus, in the second result, we have no main effect of X1.
>> >> >> >> Instead,
>> >> >> >> the
>> >> >> >> effect of X1 depends on the value of X2; either A or B or C. In
>> >> >> >> fact,
>> >> >> >> this is a two-way interaction, including all three values of X2.
>> >> >> >> In
>> >> >> >> the third result, we have no main effect of X2, The effect of X2
>> >> >> >> depends on the value of X1; either p or q.
>> >> >> >>
>> >> >> >> A complicating element with your example seems to be that your X1
>> >> >> >> and
>> >> >> >> X2 are not factors.
>> >> >> >>
>> >> >> >>    Arie
>> >> >> >>
>> >> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com> wrote:
>> >> >> >> > Hi,
>> >> >> >> >
>> >> >> >> > I recently ran into an inconsistency in the way
>> >> >> >> > model.matrix.default
>> >> >> >> > handles factor encoding for higher level interactions with
>> >> >> >> > categorical
>> >> >> >> > variables when the full hierarchy of effects is not present.
>> >> >> >> > Depending on
>> >> >> >> > which lower level interactions are specified, the factor
>> >> >> >> > encoding
>> >> >> >> > changes
>> >> >> >> > for a higher level interaction. Consider the following minimal
>> >> >> >> reproducible
>> >> >> >> > example:
>> >> >> >> >
>> >> >> >> > --------------
>> >> >> >> >
>> >> >> >> >> runmatrix =
>> >> >> >> >> expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
>> >> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2
>> >> >> >> X3B
>> >> >> >> X3C
>> >> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> > 1            1  1  1   0   0     1      0      0      0      0
>> >> >> >> > 0         0
>> >> >> >> > 2            1 -1  1   0   0    -1      0      0      0      0
>> >> >> >> > 0         0
>> >> >> >> > 3            1  1 -1   0   0    -1      0      0      0      0
>> >> >> >> > 0         0
>> >> >> >> > 4            1 -1 -1   0   0     1      0      0      0      0
>> >> >> >> > 0         0
>> >> >> >> > 5            1  1  1   1   0     1      1      0      1      0
>> >> >> >> > 1         0
>> >> >> >> > 6            1 -1  1   1   0    -1     -1      0      1      0
>> >> >> >> > -1         0
>> >> >> >> > 7            1  1 -1   1   0    -1      1      0     -1      0
>> >> >> >> > -1         0
>> >> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1      0
>> >> >> >> > 1         0
>> >> >> >> > 9            1  1  1   0   1     1      0      1      0      1
>> >> >> >> > 0         1
>> >> >> >> > 10           1 -1  1   0   1    -1      0     -1      0      1
>> >> >> >> > 0        -1
>> >> >> >> > 11           1  1 -1   0   1    -1      0      1      0     -1
>> >> >> >> > 0        -1
>> >> >> >> > 12           1 -1 -1   0   1     1      0     -1      0     -1
>> >> >> >> > 0         1
>> >> >> >> > attr(,"assign")
>> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
>> >> >> >> > attr(,"contrasts")
>> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> > [1] "contr.treatment"
>> >> >> >> >
>> >> >> >> > --------------
>> >> >> >> >
>> >> >> >> > Specifying the full hierarchy gives us what we expect: the
>> >> >> >> > interaction
>> >> >> >> > columns are simply calculated from the product of the main
>> >> >> >> > effect
>> >> >> >> columns.
>> >> >> >> > The interaction term X1:X2:X3 gives us two columns in the model
>> >> >> >> > matrix,
>> >> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main
>> >> >> >> > effects.
>> >> >> >> >
>> >> >> >> > If we remove either the X2:X3 interaction or the X1:X3
>> >> >> >> > interaction,
>> >> >> >> > we
>> >> >> >> get
>> >> >> >> > what we would expect for the X1:X2:X3 interaction, but when we
>> >> >> >> > remove
>> >> >> >> > the
>> >> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes completely:
>> >> >> >> >
>> >> >> >> > --------------
>> >> >> >> >
>> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)   (Intercept)
>> >> >> >> >> X1
>> >> >> >> >> X2
>> >> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> >> > 0
>> >> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
>> >> >> >> > 0
>> >> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
>> >> >> >> > 0
>> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> >> > 0
>> >> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> >> > 1
>> >> >> >> > 10           1 -1  1   0   1    -1      0      1         0
>> >> >> >> > -1
>> >> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
>> >> >> >> > -1
>> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> >> > 1
>> >> >> >> > attr(,"assign")
>> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> >> > attr(,"contrasts")
>> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> > [1] "contr.treatment"
>> >> >> >> >
>> >> >> >> >
>> >> >> >> >
>> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)   (Intercept)
>> >> >> >> >> X1
>> >> >> >> >> X2
>> >> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> >> > 0
>> >> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> >> > 0
>> >> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
>> >> >> >> > 0
>> >> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
>> >> >> >> > 0
>> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> >> > 0
>> >> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> >> > 1
>> >> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
>> >> >> >> > -1
>> >> >> >> > 11           1  1 -1   0   1    -1      0      1         0
>> >> >> >> > -1
>> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> >> > 1
>> >> >> >> > attr(,"assign")
>> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> >> > attr(,"contrasts")
>> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> > [1] "contr.treatment"
>> >> >> >> >
>> >> >> >> >
>> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)   (Intercept)
>> >> >> >> >> X1
>> >> >> >> >> X2
>> >> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B X1:X2:X3C
>> >> >> >> > 1            1  1  1   0   0      0      0      0      0
>> >> >> >> > 1
>> >> >> >> >     0         0
>> >> >> >> > 2            1 -1  1   0   0      0      0      0      0
>> >> >> >> > -1
>> >> >> >> >     0         0
>> >> >> >> > 3            1  1 -1   0   0      0      0      0      0
>> >> >> >> > -1
>> >> >> >> >     0         0
>> >> >> >> > 4            1 -1 -1   0   0      0      0      0      0
>> >> >> >> > 1
>> >> >> >> >     0         0
>> >> >> >> > 5            1  1  1   1   0      1      0      1      0
>> >> >> >> > 0
>> >> >> >> >     1         0
>> >> >> >> > 6            1 -1  1   1   0     -1      0      1      0
>> >> >> >> > 0
>> >> >> >> >    -1         0
>> >> >> >> > 7            1  1 -1   1   0      1      0     -1      0
>> >> >> >> > 0
>> >> >> >> >    -1         0
>> >> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0
>> >> >> >> > 0
>> >> >> >> >     1         0
>> >> >> >> > 9            1  1  1   0   1      0      1      0      1
>> >> >> >> > 0
>> >> >> >> >     0         1
>> >> >> >> > 10           1 -1  1   0   1      0     -1      0      1
>> >> >> >> > 0
>> >> >> >> >     0        -1
>> >> >> >> > 11           1  1 -1   0   1      0      1      0     -1
>> >> >> >> > 0
>> >> >> >> >     0        -1
>> >> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1
>> >> >> >> > 0
>> >> >> >> >     0         1
>> >> >> >> > attr(,"assign")
>> >> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
>> >> >> >> > attr(,"contrasts")
>> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> > [1] "contr.treatment"
>> >> >> >> >
>> >> >> >> > --------------
>> >> >> >> >
>> >> >> >> > Here, we now see the encoding for the interaction X1:X2:X3 is
>> >> >> >> > now
>> >> >> >> > the
>> >> >> >> > interaction of X1 and X2 with a new encoding for X3 where each
>> >> >> >> > factor
>> >> >> >> level
>> >> >> >> > is represented by its own column. I would expect, given the two
>> >> >> >> > column
>> >> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column would
>> >> >> >> > also
>> >> >> >> > be
>> >> >> >> two
>> >> >> >> > columns regardless of what two-factor interactions we also
>> >> >> >> > specified,
>> >> >> >> > but
>> >> >> >> > in this case it switches to three. If other two factor
>> >> >> >> > interactions
>> >> >> >> > are
>> >> >> >> > missing in addition to X1:X2, this issue still occurs. This
>> >> >> >> > also
>> >> >> >> > happens
>> >> >> >> > regardless of the contrast specified in contrasts.arg for X3. I
>> >> >> >> > don't
>> >> >> >> > see
>> >> >> >> > any reasoning for this behavior given in the documentation, so
>> >> >> >> > I
>> >> >> >> > suspect
>> >> >> >> it
>> >> >> >> > is a bug.
>> >> >> >> >
>> >> >> >> > Best regards,
>> >> >> >> > Tyler Morgan-Wall
>> >> >> >> >
>> >> >> >> >         [[alternative HTML version deleted]]
>> >> >> >> >
>> >> >> >> > ______________________________________________
>
>


From maechler at stat.math.ethz.ch  Mon Nov  6 15:41:37 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 6 Nov 2017 15:41:37 +0100
Subject: [Rd] ans[nas] <- NA in 'ifelse' (was: ifelse() woes ... can we
 agree on a ifelse2() ?)
In-Reply-To: <1529825091.2728209.1509797508916@mail.yahoo.com>
References: <1529825091.2728209.1509797508916.ref@mail.yahoo.com>
 <1529825091.2728209.1509797508916@mail.yahoo.com>
Message-ID: <23040.29857.160838.615482@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com>
>>>>>     on Sat, 4 Nov 2017 12:11:48 +0000 writes:

    > Removal of
    > ans[nas] <- NA
    > from the code of function 'ifelse' in R is not committed (yet). Why?

because I have been using it in my version of R-devel for this whole
year, but have forgotten to commit it.

Thank you for the reminder.  I have committed it now :

------------------------------------------------------------------------
r73681 | maechler | 2017-11-06 15:39:20 +0100 (Mon, 06 Nov 2017) | 3 lines

drop extraneous line, as suggested by Suharto Anggono, and as "promised" on R-devel list, Nov 26, 2016

------------------------------------------------------------------------


    > On Mon, 28/11/16, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > Subject: Re: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
    > To: "Suharto Anggono" <suharto_anggono at yahoo.com>
    > Cc: R-devel at r-project.org, maechler at stat.math.ethz.ch
    > Date: Monday, 28 November, 2016, 10:00 PM
 
>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sat, 26 Nov 2016 17:14:01 +0000 writes:

    > ...


    >> On current 'ifelse' code in R:

    >> * The part
    >> ans[nas] <- NA
    >> could be omitted because NA's are already in place.
    >> If the part is removed, variable 'nas' is no longer used.

    > I agree that this seems logical.  If I apply the change, R's own
    > full checks do not seem affected, and I may try to commit that
    > change and "wait and see".

    > ...


From tylermw at gmail.com  Mon Nov  6 17:09:36 2017
From: tylermw at gmail.com (Tyler)
Date: Mon, 6 Nov 2017 11:09:36 -0500
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CACg-3ubR8YP8XoJGJ+aMEJ0GyeZxMNtFG69GScGtXyFuM1yYWg@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
 <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
 <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>
 <CAJhwqzRxyE+nf5ZWF9H2BS1oy6O3jvn6TnwOosu46aEFdBuvnw@mail.gmail.com>
 <CACg-3ubR8YP8XoJGJ+aMEJ0GyeZxMNtFG69GScGtXyFuM1yYWg@mail.gmail.com>
Message-ID: <CAJhwqzRHw49DDcGc7+hM=HKKe3TuhQ7dinPZ9nc8xNAWL=HB-A@mail.gmail.com>

Hi Arie,

Given the heuristic, in all of my examples with a missing two-factor
interaction the three-factor interaction should be coded with dummy
variables. In reality, it is encoded by dummy variables only when the
numeric:numeric interaction is missing, and by contrasts for the other two.
The heuristic does not specify separate behavior for numeric vs categorical
factors (When the author of Statistical Models in S refers to F_j as a
"factor", it is a more general usage than the R type "factor" and includes
numeric variables--the language used later on in the chapter on page 40
confirms this): when there is a missing marginal term in the formula, the
higher-order interaction should be coded by dummy variables, regardless of
type. Thus, the terms() function is only following the cited behavior 1/3rd
of the time.

Best regards,
Tyler

On Mon, Nov 6, 2017 at 6:45 AM, Arie ten Cate <arietencate at gmail.com> wrote:

> Hello Tyler,
>
> You write that you understand what I am saying. However, I am now at
> loss about what exactly is the problem with the behavior of R.  Here
> is a script which reproduces your experiments with three variables
> (excluding the full model):
>
> m=expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))
> model.matrix(~(X1+X2+X3)^3-X1:X3,data=m)
> model.matrix(~(X1+X2+X3)^3-X2:X3,data=m)
> model.matrix(~(X1+X2+X3)^3-X1:X2,data=m)
>
> Below are the three results, similar to your first mail. (The first
> two are basically the same, of course.) Please pick one result which
> you think is not consistent with the heuristic and please give what
> you think is the correct result:
>
> model.matrix(~(X1+X2+X3)^3-X1:X3)
>   (Intercept)
>   X1 X2 X3B X3C
>   X1:X2 X2:X3B X2:X3C
>   X1:X2:X3B X1:X2:X3C
>
> model.matrix(~(X1+X2+X3)^3-X2:X3)
>   (Intercept)
>   X1 X2 X3B X3C
>   X1:X2 X1:X3B X1:X3C
>   X1:X2:X3B X1:X2:X3C
>
> model.matrix(~(X1+X2+X3)^3-X1:X2)
>   (Intercept)
>   X1 X2 X3B X3C
>   X1:X3B X1:X3C X2:X3B X2:X3C
>   X1:X2:X3A X1:X2:X3B X1:X2:X3C
>
> (I take it that the combination of X3A and X3B and X3C implies dummy
> encoding, and the combination of only X3B and X3C implies contrasts
> encoding, with respect to X3A.)
>
> Thanks in advance,
>
> Arie
>
>
> On Sat, Nov 4, 2017 at 5:33 PM, Tyler <tylermw at gmail.com> wrote:
> > Hi Arie,
> >
> > I understand what you're saying. The following excerpt out of the book
> shows
> > that F_j does not refer exclusively to categorical factors: "...the rule
> > does not do anything special for them, and it remains valid, in a trivial
> > sense, whenever any of the F_j is numeric rather than categorical." Since
> > F_j refers to both categorical and numeric variables, the behavior of
> > model.matrix is not consistent with the heuristic.
> >
> > Best regards,
> > Tyler
> >
> > On Sat, Nov 4, 2017 at 6:50 AM, Arie ten Cate <arietencate at gmail.com>
> wrote:
> >>
> >> Hello Tyler,
> >>
> >> I rephrase my previous mail, as follows:
> >>
> >> In your example, T_i = X1:X2:X3. Let F_j = X3. (The numerical
> >> variables X1 and X2 are not encoded at all.) Then T_{i(j)} = X1:X2,
> >> which in the example is dropped from the model. Hence the X3 in T_i
> >> must be encoded by dummy variables, as indeed it is.
> >>
> >>   Arie
> >>
> >>
> >> On Thu, Nov 2, 2017 at 4:11 PM, Tyler <tylermw at gmail.com> wrote:
> >> > Hi Arie,
> >> >
> >> > The book out of which this behavior is based does not use factor (in
> >> > this
> >> > section) to refer to categorical factor. I will again point to this
> >> > sentence, from page 40, in the same section and referring to the
> >> > behavior
> >> > under question, that shows F_j is not limited to categorical factors:
> >> > "Numeric variables appear in the computations as themselves, uncoded.
> >> > Therefore, the rule does not do anything special for them, and it
> >> > remains
> >> > valid, in a trivial sense, whenever any of the F_j is numeric rather
> >> > than
> >> > categorical."
> >> >
> >> > Note the "... whenever any of the F_j is numeric rather than
> >> > categorical."
> >> > Factor here is used in the more general sense of the word, not
> referring
> >> > to
> >> > the R type "factor." The behavior of R does not match the heuristic
> that
> >> > it's citing.
> >> >
> >> > Best regards,
> >> > Tyler
> >> >
> >> > On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com>
> >> > wrote:
> >> >>
> >> >> Hello Tyler,
> >> >>
> >> >> Thank you for searching for, and finding, the basic description of
> the
> >> >> behavior of R in this matter.
> >> >>
> >> >> I think your example is in agreement with the book.
> >> >>
> >> >> But let me first note the following. You write: "F_j refers to a
> >> >> factor (variable) in a model and not a categorical factor". However:
> >> >> "a factor is a vector object used to specify a discrete
> >> >> classification" (start of chapter 4 of "An Introduction to R".) You
> >> >> might also see the description of the R function factor().
> >> >>
> >> >> You note that the book says about a factor F_j:
> >> >>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
> >> >> formula and by dummy variables if it has not"
> >> >>
> >> >> You find:
> >> >>    "However, the example I gave demonstrated that this dummy variable
> >> >> encoding only occurs for the model where the missing term is the
> >> >> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
> >> >>
> >> >> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
> >> >> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in
> T_i
> >> >> must be encoded by dummy variables, as indeed it is.
> >> >>
> >> >>   Arie
> >> >>
> >> >> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
> >> >> > Hi Arie,
> >> >> >
> >> >> > Thank you for your further research into the issue.
> >> >> >
> >> >> > Regarding Stata: On the other hand, JMP gives model matrices that
> use
> >> >> > the
> >> >> > main effects contrasts in computing the higher order interactions,
> >> >> > without
> >> >> > the dummy variable encoding. I verified this both by analyzing the
> >> >> > linear
> >> >> > model given in my first example and noting that JMP has one more
> >> >> > degree
> >> >> > of
> >> >> > freedom than R for the same model, as well as looking at the
> >> >> > generated
> >> >> > model
> >> >> > matrices. It's easy to find a design where JMP will allow us fit
> our
> >> >> > model
> >> >> > with goodness-of-fit estimates and R will not due to the extra
> >> >> > degree(s)
> >> >> > of
> >> >> > freedom required. Let's keep the conversation limited to R.
> >> >> >
> >> >> > I want to refocus back onto my original bug report, which was not
> for
> >> >> > a
> >> >> > missing main effects term, but rather for a missing lower-order
> >> >> > interaction
> >> >> > term. The behavior of model.matrix.default() for a missing main
> >> >> > effects
> >> >> > term
> >> >> > is a nice example to demonstrate how model.matrix encodes with
> dummy
> >> >> > variables instead of contrasts, but doesn't demonstrate the
> >> >> > inconsistent
> >> >> > behavior my bug report highlighted.
> >> >> >
> >> >> > I went looking for documentation on this behavior, and the issue
> >> >> > stems
> >> >> > not
> >> >> > from model.matrix.default(), but rather the terms() function in
> >> >> > interpreting
> >> >> > the formula. This "clever" replacement of contrasts by dummy
> >> >> > variables
> >> >> > to
> >> >> > maintain marginality (presuming that's the reason) is not described
> >> >> > anywhere
> >> >> > in the documentation for either the model.matrix() or the terms()
> >> >> > function.
> >> >> > In order to find a description for the behavior, I had to look in
> the
> >> >> > underlying C code, buried above the "TermCode" function of the
> >> >> > "model.c"
> >> >> > file, which says:
> >> >> >
> >> >> > "TermCode decides on the encoding of a model term. Returns 1 if
> >> >> > variable
> >> >> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2 if
> >> >> > it
> >> >> > is to
> >> >> > be encoded by dummy variables.  This is decided using the heuristic
> >> >> > described in Statistical Models in S, page 38."
> >> >> >
> >> >> > I do not have a copy of this book, and I suspect most R users do
> not
> >> >> > as
> >> >> > well. Thankfully, however, some of the pages describing this
> behavior
> >> >> > were
> >> >> > available as part of Amazon's "Look Inside" feature--but if not for
> >> >> > that, I
> >> >> > would have no idea what heuristic R was using. Since those pages
> >> >> > could
> >> >> > made
> >> >> > unavailable by Amazon at any time, at the very least we have an
> >> >> > problem
> >> >> > with
> >> >> > a lack of documentation.
> >> >> >
> >> >> > However, I still believe there is a bug when comparing R's
> >> >> > implementation to
> >> >> > the heuristic described in the book. From Statistical Models in S,
> >> >> > page
> >> >> > 38-39:
> >> >> >
> >> >> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)}
> denote
> >> >> > the
> >> >> > margin of T_i for factor F_j--that is, the term obtained by
> dropping
> >> >> > F_j
> >> >> > from T_i. We say that T_{i(j)} has appeared in the formula if there
> >> >> > is
> >> >> > some
> >> >> > term T_i' for i' < i such that T_i' contains all the factors
> >> >> > appearing
> >> >> > in
> >> >> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the
> >> >> > preceding
> >> >> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in
> the
> >> >> > formula and by dummy variables if it has not"
> >> >> >
> >> >> > Here, F_j refers to a factor (variable) in a model and not a
> >> >> > categorical
> >> >> > factor, as specified later in that section (page 40): "Numeric
> >> >> > variables
> >> >> > appear in the computations as themselves, uncoded. Therefore, the
> >> >> > rule
> >> >> > does
> >> >> > not do anything special for them, and it remains valid, in a
> trivial
> >> >> > sense,
> >> >> > whenever any of the F_j is numeric rather than categorical."
> >> >> >
> >> >> > Going back to my original example with three variables: X1
> (numeric),
> >> >> > X2
> >> >> > (numeric), X3 (categorical). This heuristic prescribes encoding
> >> >> > X1:X2:X3
> >> >> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the
> >> >> > formula.
> >> >> > When
> >> >> > any of the preceding terms do not exist, this heuristic tells us to
> >> >> > use
> >> >> > dummy variables to encode the interaction (e.g. "F_j [the
> interaction
> >> >> > term]
> >> >> > is coded ... by dummy variables if it [any of the marginal terms
> >> >> > obtained by
> >> >> > dropping a single factor in the interaction] has not [appeared in
> the
> >> >> > formula]"). However, the example I gave demonstrated that this
> dummy
> >> >> > variable encoding only occurs for the model where the missing term
> is
> >> >> > the
> >> >> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
> >> >> > interaction term X1:X2:X3 is encoded by contrasts, not dummy
> >> >> > variables.
> >> >> > This
> >> >> > is inconsistent with the description of the intended behavior given
> >> >> > in
> >> >> > the
> >> >> > book.
> >> >> >
> >> >> > Best regards,
> >> >> > Tyler
> >> >> >
> >> >> >
> >> >> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate
> >> >> > <arietencate at gmail.com>
> >> >> > wrote:
> >> >> >>
> >> >> >> Hello Tyler,
> >> >> >>
> >> >> >> I want to bring to your attention the following document: "What
> >> >> >> happens if you omit the main effect in a regression model with an
> >> >> >> interaction?"
> >> >> >>
> >> >> >>
> >> >> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-
> omit-the-main-effect-in-a-regression-model-with-an-interaction).
> >> >> >> This gives a useful review of the problem. Your example is Case
> 2: a
> >> >> >> continuous and a categorical regressor.
> >> >> >>
> >> >> >> The numerical examples are coded in Stata, and they give the same
> >> >> >> result as in R. Hence, if this is a bug in R then it is also a bug
> >> >> >> in
> >> >> >> Stata. That seems very unlikely.
> >> >> >>
> >> >> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
> >> >> >>
> >> >> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
> >> >> >> print("Full model")
> >> >> >> print(model.matrix(~(socst+grp)^2 ,data=df))
> >> >> >> print("Example 2.1: drop socst")
> >> >> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
> >> >> >> print("Example 2.2: drop grp")
> >> >> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
> >> >> >>
> >> >> >> This gives indeed the following regressors:
> >> >> >>
> >> >> >> "Full model"
> >> >> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
> >> >> >> "Example 2.1: drop socst"
> >> >> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3
> >> >> >> socst:grp4
> >> >> >> "Example 2.2: drop grp"
> >> >> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
> >> >> >>
> >> >> >> There is a little bit of R documentation about this, based on the
> >> >> >> concept of marginality, which typically forbids a model having an
> >> >> >> interaction but not the corresponding main effects. (You might see
> >> >> >> the
> >> >> >> references in https://en.wikipedia.org/wiki/
> Principle_of_marginality
> >> >> >> )
> >> >> >>     See "An Introduction to R", by Venables and Smith and the R
> Core
> >> >> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
> >> >> >> details are complicated, model formulae in R will normally
> generate
> >> >> >> the models that an expert statistician would expect, provided that
> >> >> >> marginality is preserved. Fitting, for [a contrary] example, a
> model
> >> >> >> with an interaction but not the corresponding main effects will in
> >> >> >> general lead to surprising results ....".
> >> >> >>     The Reference Manual states that the R functions dropterm()
> and
> >> >> >> addterm() resp. drop or add only terms such that marginality is
> >> >> >> preserved.
> >> >> >>
> >> >> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
> >> >> >> Example 2.1 in Case 2 discussed above. As discussed there, in
> Stata
> >> >> >> and in R the drop of the continuous variable has no effect on the
> >> >> >> degrees of freedom here: it is just a reparameterisation of the
> full
> >> >> >> model, protecting you against losing marginality... Hence the
> >> >> >> model.matrix 'mm' is still square and nonsingular after the drop
> of
> >> >> >> X1, unless of course when a row is removed from the matrix
> 'design'
> >> >> >> when before creating 'mm'.
> >> >> >>
> >> >> >>     Arie
> >> >> >>
> >> >> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
> >> >> >> > You could possibly try to explain away the behavior for a
> missing
> >> >> >> > main
> >> >> >> > effects term, since without the main effects term we don't have
> >> >> >> > main
> >> >> >> > effect
> >> >> >> > columns in the model matrix used to compute the interaction
> >> >> >> > columns
> >> >> >> > (At
> >> >> >> > best this is undocumented behavior--I still think it's a bug, as
> >> >> >> > we
> >> >> >> > know
> >> >> >> > how we would encode the categorical factors if they were in fact
> >> >> >> > present.
> >> >> >> > It's either specified in contrasts.arg or using the default set
> in
> >> >> >> > options). However, when all the main effects are present, why
> >> >> >> > would
> >> >> >> > the
> >> >> >> > three-factor interaction column not simply be the product of the
> >> >> >> > main
> >> >> >> > effect columns? In my example: we know X1, we know X2, and we
> know
> >> >> >> > X3.
> >> >> >> > Why
> >> >> >> > does the encoding of X1:X2:X3 depend on whether we specified a
> >> >> >> > two-factor
> >> >> >> > interaction, AND only changes for specific missing interactions?
> >> >> >> >
> >> >> >> > In addition, I can use a two-term example similar to yours to
> show
> >> >> >> > how
> >> >> >> > this
> >> >> >> > behavior results in a singular covariance matrix when, given the
> >> >> >> > desired
> >> >> >> > factor encoding, it should not be singular.
> >> >> >> >
> >> >> >> > We start with a full factorial design for a two-level continuous
> >> >> >> > factor
> >> >> >> > and
> >> >> >> > a three-level categorical factor, and remove a single row. This
> >> >> >> > design
> >> >> >> > matrix does not leave enough degrees of freedom to determine
> >> >> >> > goodness-of-fit, but should allow us to obtain parameter
> >> >> >> > estimates.
> >> >> >> >
> >> >> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
> >> >> >> >> design = design[-1,]
> >> >> >> >> design
> >> >> >> >   X1 X2
> >> >> >> > 2 -1  A
> >> >> >> > 3  1  B
> >> >> >> > 4 -1  B
> >> >> >> > 5  1  C
> >> >> >> > 6 -1  C
> >> >> >> >
> >> >> >> > Here, we first calculate the model matrix for the full model,
> and
> >> >> >> > then
> >> >> >> > manually remove the X1 column from the model matrix. This gives
> us
> >> >> >> > the
> >> >> >> > model matrix one would expect if X1 were removed from the model.
> >> >> >> > We
> >> >> >> > then
> >> >> >> > successfully calculate the covariance matrix.
> >> >> >> >
> >> >> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
> >> >> >> >> mm
> >> >> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
> >> >> >> > 2           1 -1   0   0      0      0
> >> >> >> > 3           1  1   1   0      1      0
> >> >> >> > 4           1 -1   1   0     -1      0
> >> >> >> > 5           1  1   0   1      0      1
> >> >> >> > 6           1 -1   0   1      0     -1
> >> >> >> >
> >> >> >> >> mm = mm[,-2]
> >> >> >> >> solve(t(mm) %*% mm)
> >> >> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
> >> >> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
> >> >> >> > X2B                  -1  1.5  1.0    0.0    0.0
> >> >> >> > X2C                  -1  1.0  1.5    0.0    0.0
> >> >> >> > X1:X2B                0  0.0  0.0    0.5    0.0
> >> >> >> > X1:X2C                0  0.0  0.0    0.0    0.5
> >> >> >> >
> >> >> >> > Here, we see the actual behavior for model.matrix. The undesired
> >> >> >> > re-coding
> >> >> >> > of the model matrix interaction term makes the information
> matrix
> >> >> >> > singular.
> >> >> >> >
> >> >> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
> >> >> >> >> mm
> >> >> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
> >> >> >> > 2           1   0   0     -1      0      0
> >> >> >> > 3           1   1   0      0      1      0
> >> >> >> > 4           1   1   0      0     -1      0
> >> >> >> > 5           1   0   1      0      0      1
> >> >> >> > 6           1   0   1      0      0     -1
> >> >> >> >
> >> >> >> >> solve(t(mm) %*% mm)
> >> >> >> > Error in solve.default(t(mm) %*% mm) : system is computationally
> >> >> >> > singular:
> >> >> >> > reciprocal condition number = 5.55112e-18
> >> >> >> >
> >> >> >> > I still believe this is a bug.
> >> >> >> >
> >> >> >> > Best regards,
> >> >> >> > Tyler Morgan-Wall
> >> >> >> >
> >> >> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate
> >> >> >> > <arietencate at gmail.com>
> >> >> >> > wrote:
> >> >> >> >
> >> >> >> >> I think it is not a bug. It is a general property of
> >> >> >> >> interactions.
> >> >> >> >> This property is best observed if all variables are factors
> >> >> >> >> (qualitative).
> >> >> >> >>
> >> >> >> >> For example, you have three variables (factors). You ask for as
> >> >> >> >> many
> >> >> >> >> interactions as possible, except an interaction term between
> two
> >> >> >> >> particular variables. When this interaction is not a constant,
> it
> >> >> >> >> is
> >> >> >> >> different for different values of the remaining variable. More
> >> >> >> >> precisely: for all values of that variable. In other words: you
> >> >> >> >> have
> >> >> >> >> a
> >> >> >> >> three-way interaction, with all values of that variable.
> >> >> >> >>
> >> >> >> >> An even smaller example is the following script with only two
> >> >> >> >> variables, each being a factor:
> >> >> >> >>
> >> >> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
> >> >> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
> >> >> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
> >> >> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
> >> >> >> >>
> >> >> >> >> The result is:
> >> >> >> >>
> >> >> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
> >> >> >> >> 1           1   0   0   0       0       0
> >> >> >> >> 2           1   1   0   0       0       0
> >> >> >> >> 3           1   0   1   0       0       0
> >> >> >> >> 4           1   1   1   0       1       0
> >> >> >> >> 5           1   0   0   1       0       0
> >> >> >> >> 6           1   1   0   1       0       1
> >> >> >> >>
> >> >> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
> >> >> >> >> 1           1   0   0       0       0       0
> >> >> >> >> 2           1   0   0       1       0       0
> >> >> >> >> 3           1   1   0       0       0       0
> >> >> >> >> 4           1   1   0       0       1       0
> >> >> >> >> 5           1   0   1       0       0       0
> >> >> >> >> 6           1   0   1       0       0       1
> >> >> >> >>
> >> >> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
> >> >> >> >> 1           1   0       0       0       0       0
> >> >> >> >> 2           1   1       0       0       0       0
> >> >> >> >> 3           1   0       1       0       0       0
> >> >> >> >> 4           1   1       0       1       0       0
> >> >> >> >> 5           1   0       0       0       1       0
> >> >> >> >> 6           1   1       0       0       0       1
> >> >> >> >>
> >> >> >> >> Thus, in the second result, we have no main effect of X1.
> >> >> >> >> Instead,
> >> >> >> >> the
> >> >> >> >> effect of X1 depends on the value of X2; either A or B or C. In
> >> >> >> >> fact,
> >> >> >> >> this is a two-way interaction, including all three values of
> X2.
> >> >> >> >> In
> >> >> >> >> the third result, we have no main effect of X2, The effect of
> X2
> >> >> >> >> depends on the value of X1; either p or q.
> >> >> >> >>
> >> >> >> >> A complicating element with your example seems to be that your
> X1
> >> >> >> >> and
> >> >> >> >> X2 are not factors.
> >> >> >> >>
> >> >> >> >>    Arie
> >> >> >> >>
> >> >> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com>
> wrote:
> >> >> >> >> > Hi,
> >> >> >> >> >
> >> >> >> >> > I recently ran into an inconsistency in the way
> >> >> >> >> > model.matrix.default
> >> >> >> >> > handles factor encoding for higher level interactions with
> >> >> >> >> > categorical
> >> >> >> >> > variables when the full hierarchy of effects is not present.
> >> >> >> >> > Depending on
> >> >> >> >> > which lower level interactions are specified, the factor
> >> >> >> >> > encoding
> >> >> >> >> > changes
> >> >> >> >> > for a higher level interaction. Consider the following
> minimal
> >> >> >> >> reproducible
> >> >> >> >> > example:
> >> >> >> >> >
> >> >> >> >> > --------------
> >> >> >> >> >
> >> >> >> >> >> runmatrix =
> >> >> >> >> >> expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
> >> >> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2
> >> >> >> >> X3B
> >> >> >> >> X3C
> >> >> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> >> > 1            1  1  1   0   0     1      0      0      0
> 0
> >> >> >> >> > 0         0
> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0      0
> 0
> >> >> >> >> > 0         0
> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0      0
> 0
> >> >> >> >> > 0         0
> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0      0
> 0
> >> >> >> >> > 0         0
> >> >> >> >> > 5            1  1  1   1   0     1      1      0      1
> 0
> >> >> >> >> > 1         0
> >> >> >> >> > 6            1 -1  1   1   0    -1     -1      0      1
> 0
> >> >> >> >> > -1         0
> >> >> >> >> > 7            1  1 -1   1   0    -1      1      0     -1
> 0
> >> >> >> >> > -1         0
> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1
> 0
> >> >> >> >> > 1         0
> >> >> >> >> > 9            1  1  1   0   1     1      0      1      0
> 1
> >> >> >> >> > 0         1
> >> >> >> >> > 10           1 -1  1   0   1    -1      0     -1      0
> 1
> >> >> >> >> > 0        -1
> >> >> >> >> > 11           1  1 -1   0   1    -1      0      1      0
>  -1
> >> >> >> >> > 0        -1
> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1      0
>  -1
> >> >> >> >> > 0         1
> >> >> >> >> > attr(,"assign")
> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
> >> >> >> >> > attr(,"contrasts")
> >> >> >> >> > attr(,"contrasts")$X3
> >> >> >> >> > [1] "contr.treatment"
> >> >> >> >> >
> >> >> >> >> > --------------
> >> >> >> >> >
> >> >> >> >> > Specifying the full hierarchy gives us what we expect: the
> >> >> >> >> > interaction
> >> >> >> >> > columns are simply calculated from the product of the main
> >> >> >> >> > effect
> >> >> >> >> columns.
> >> >> >> >> > The interaction term X1:X2:X3 gives us two columns in the
> model
> >> >> >> >> > matrix,
> >> >> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main
> >> >> >> >> > effects.
> >> >> >> >> >
> >> >> >> >> > If we remove either the X2:X3 interaction or the X1:X3
> >> >> >> >> > interaction,
> >> >> >> >> > we
> >> >> >> >> get
> >> >> >> >> > what we would expect for the X1:X2:X3 interaction, but when
> we
> >> >> >> >> > remove
> >> >> >> >> > the
> >> >> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes
> completely:
> >> >> >> >> >
> >> >> >> >> > --------------
> >> >> >> >> >
> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)
>  (Intercept)
> >> >> >> >> >> X1
> >> >> >> >> >> X2
> >> >> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> >> > 1            1  1  1   0   0     1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 5            1  1  1   1   0     1      1      0         1
> >> >> >> >> > 0
> >> >> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
> >> >> >> >> > 0
> >> >> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
> >> >> >> >> > 0
> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
> >> >> >> >> > 0
> >> >> >> >> > 9            1  1  1   0   1     1      0      1         0
> >> >> >> >> > 1
> >> >> >> >> > 10           1 -1  1   0   1    -1      0      1         0
> >> >> >> >> > -1
> >> >> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
> >> >> >> >> > -1
> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
> >> >> >> >> > 1
> >> >> >> >> > attr(,"assign")
> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> >> >> > attr(,"contrasts")
> >> >> >> >> > attr(,"contrasts")$X3
> >> >> >> >> > [1] "contr.treatment"
> >> >> >> >> >
> >> >> >> >> >
> >> >> >> >> >
> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)
>  (Intercept)
> >> >> >> >> >> X1
> >> >> >> >> >> X2
> >> >> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
> >> >> >> >> > 1            1  1  1   0   0     1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
> >> >> >> >> > 0
> >> >> >> >> > 5            1  1  1   1   0     1      1      0         1
> >> >> >> >> > 0
> >> >> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
> >> >> >> >> > 0
> >> >> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
> >> >> >> >> > 0
> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
> >> >> >> >> > 0
> >> >> >> >> > 9            1  1  1   0   1     1      0      1         0
> >> >> >> >> > 1
> >> >> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
> >> >> >> >> > -1
> >> >> >> >> > 11           1  1 -1   0   1    -1      0      1         0
> >> >> >> >> > -1
> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
> >> >> >> >> > 1
> >> >> >> >> > attr(,"assign")
> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
> >> >> >> >> > attr(,"contrasts")
> >> >> >> >> > attr(,"contrasts")$X3
> >> >> >> >> > [1] "contr.treatment"
> >> >> >> >> >
> >> >> >> >> >
> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)
>  (Intercept)
> >> >> >> >> >> X1
> >> >> >> >> >> X2
> >> >> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B
> X1:X2:X3C
> >> >> >> >> > 1            1  1  1   0   0      0      0      0      0
> >> >> >> >> > 1
> >> >> >> >> >     0         0
> >> >> >> >> > 2            1 -1  1   0   0      0      0      0      0
> >> >> >> >> > -1
> >> >> >> >> >     0         0
> >> >> >> >> > 3            1  1 -1   0   0      0      0      0      0
> >> >> >> >> > -1
> >> >> >> >> >     0         0
> >> >> >> >> > 4            1 -1 -1   0   0      0      0      0      0
> >> >> >> >> > 1
> >> >> >> >> >     0         0
> >> >> >> >> > 5            1  1  1   1   0      1      0      1      0
> >> >> >> >> > 0
> >> >> >> >> >     1         0
> >> >> >> >> > 6            1 -1  1   1   0     -1      0      1      0
> >> >> >> >> > 0
> >> >> >> >> >    -1         0
> >> >> >> >> > 7            1  1 -1   1   0      1      0     -1      0
> >> >> >> >> > 0
> >> >> >> >> >    -1         0
> >> >> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0
> >> >> >> >> > 0
> >> >> >> >> >     1         0
> >> >> >> >> > 9            1  1  1   0   1      0      1      0      1
> >> >> >> >> > 0
> >> >> >> >> >     0         1
> >> >> >> >> > 10           1 -1  1   0   1      0     -1      0      1
> >> >> >> >> > 0
> >> >> >> >> >     0        -1
> >> >> >> >> > 11           1  1 -1   0   1      0      1      0     -1
> >> >> >> >> > 0
> >> >> >> >> >     0        -1
> >> >> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1
> >> >> >> >> > 0
> >> >> >> >> >     0         1
> >> >> >> >> > attr(,"assign")
> >> >> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
> >> >> >> >> > attr(,"contrasts")
> >> >> >> >> > attr(,"contrasts")$X3
> >> >> >> >> > [1] "contr.treatment"
> >> >> >> >> >
> >> >> >> >> > --------------
> >> >> >> >> >
> >> >> >> >> > Here, we now see the encoding for the interaction X1:X2:X3 is
> >> >> >> >> > now
> >> >> >> >> > the
> >> >> >> >> > interaction of X1 and X2 with a new encoding for X3 where
> each
> >> >> >> >> > factor
> >> >> >> >> level
> >> >> >> >> > is represented by its own column. I would expect, given the
> two
> >> >> >> >> > column
> >> >> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column
> would
> >> >> >> >> > also
> >> >> >> >> > be
> >> >> >> >> two
> >> >> >> >> > columns regardless of what two-factor interactions we also
> >> >> >> >> > specified,
> >> >> >> >> > but
> >> >> >> >> > in this case it switches to three. If other two factor
> >> >> >> >> > interactions
> >> >> >> >> > are
> >> >> >> >> > missing in addition to X1:X2, this issue still occurs. This
> >> >> >> >> > also
> >> >> >> >> > happens
> >> >> >> >> > regardless of the contrast specified in contrasts.arg for
> X3. I
> >> >> >> >> > don't
> >> >> >> >> > see
> >> >> >> >> > any reasoning for this behavior given in the documentation,
> so
> >> >> >> >> > I
> >> >> >> >> > suspect
> >> >> >> >> it
> >> >> >> >> > is a bug.
> >> >> >> >> >
> >> >> >> >> > Best regards,
> >> >> >> >> > Tyler Morgan-Wall
> >> >> >> >> >
> >> >> >> >> >         [[alternative HTML version deleted]]
> >> >> >> >> >
> >> >> >> >> > ______________________________________________
> >
> >
>

	[[alternative HTML version deleted]]


From arietencate at gmail.com  Tue Nov  7 06:41:24 2017
From: arietencate at gmail.com (Arie ten Cate)
Date: Tue, 7 Nov 2017 06:41:24 +0100
Subject: [Rd] Bug in model.matrix.default for higher-order interaction
 encoding when specific model terms are missing
In-Reply-To: <CAJhwqzRHw49DDcGc7+hM=HKKe3TuhQ7dinPZ9nc8xNAWL=HB-A@mail.gmail.com>
References: <CACg-3uZiwGNQUF3ZsoE7w7fwQ8xEXWfs9L=vpJskgOuf=QiTPw@mail.gmail.com>
 <CAJhwqzSEFPOqSmKkRq9dCe2zJQ_JwQiVyNKwAdACOE3Lh+COig@mail.gmail.com>
 <CACg-3uZgYfZAgWH9+ucJhjG1yz8dXOFDr0MOe6iQhffRuznvfg@mail.gmail.com>
 <CAJhwqzRPC3cVVGbrv3QLWm-uaqJ=iAFE4iGHGP25Mn-de7h+iQ@mail.gmail.com>
 <CACg-3uZWTTZCFraX3P9nDEnQsc34zmJHRpKE=wPhwtOj9xquPw@mail.gmail.com>
 <CAJhwqzRxyE+nf5ZWF9H2BS1oy6O3jvn6TnwOosu46aEFdBuvnw@mail.gmail.com>
 <CACg-3ubR8YP8XoJGJ+aMEJ0GyeZxMNtFG69GScGtXyFuM1yYWg@mail.gmail.com>
 <CAJhwqzRHw49DDcGc7+hM=HKKe3TuhQ7dinPZ9nc8xNAWL=HB-A@mail.gmail.com>
Message-ID: <CACg-3ubXkbYkfNxW7y=L7jsAr21rb5FJS6ChhMrBpi8M19urjw@mail.gmail.com>

Hello Tyler,

model.matrix(~(X1+X2+X3)^3-X1:X3)

T_i = X1:X2:X3. Let F_j = X3. (The numerical variables X1 and X2 are
not encoded at all. Then, again, T_{i(j)} = X1:X2, which in this
example is NOT dropped from the model. Hence the X3 in T_i must be
encoded by contrast, as indeed it is.

  Arie

On Mon, Nov 6, 2017 at 5:09 PM, Tyler <tylermw at gmail.com> wrote:
> Hi Arie,
>
> Given the heuristic, in all of my examples with a missing two-factor
> interaction the three-factor interaction should be coded with dummy
> variables. In reality, it is encoded by dummy variables only when the
> numeric:numeric interaction is missing, and by contrasts for the other two.
> The heuristic does not specify separate behavior for numeric vs categorical
> factors (When the author of Statistical Models in S refers to F_j as a
> "factor", it is a more general usage than the R type "factor" and includes
> numeric variables--the language used later on in the chapter on page 40
> confirms this): when there is a missing marginal term in the formula, the
> higher-order interaction should be coded by dummy variables, regardless of
> type. Thus, the terms() function is only following the cited behavior 1/3rd
> of the time.
>
> Best regards,
> Tyler
>
> On Mon, Nov 6, 2017 at 6:45 AM, Arie ten Cate <arietencate at gmail.com> wrote:
>>
>> Hello Tyler,
>>
>> You write that you understand what I am saying. However, I am now at
>> loss about what exactly is the problem with the behavior of R.  Here
>> is a script which reproduces your experiments with three variables
>> (excluding the full model):
>>
>> m=expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))
>> model.matrix(~(X1+X2+X3)^3-X1:X3,data=m)
>> model.matrix(~(X1+X2+X3)^3-X2:X3,data=m)
>> model.matrix(~(X1+X2+X3)^3-X1:X2,data=m)
>>
>> Below are the three results, similar to your first mail. (The first
>> two are basically the same, of course.) Please pick one result which
>> you think is not consistent with the heuristic and please give what
>> you think is the correct result:
>>
>> model.matrix(~(X1+X2+X3)^3-X1:X3)
>>   (Intercept)
>>   X1 X2 X3B X3C
>>   X1:X2 X2:X3B X2:X3C
>>   X1:X2:X3B X1:X2:X3C
>>
>> model.matrix(~(X1+X2+X3)^3-X2:X3)
>>   (Intercept)
>>   X1 X2 X3B X3C
>>   X1:X2 X1:X3B X1:X3C
>>   X1:X2:X3B X1:X2:X3C
>>
>> model.matrix(~(X1+X2+X3)^3-X1:X2)
>>   (Intercept)
>>   X1 X2 X3B X3C
>>   X1:X3B X1:X3C X2:X3B X2:X3C
>>   X1:X2:X3A X1:X2:X3B X1:X2:X3C
>>
>> (I take it that the combination of X3A and X3B and X3C implies dummy
>> encoding, and the combination of only X3B and X3C implies contrasts
>> encoding, with respect to X3A.)
>>
>> Thanks in advance,
>>
>> Arie
>>
>>
>> On Sat, Nov 4, 2017 at 5:33 PM, Tyler <tylermw at gmail.com> wrote:
>> > Hi Arie,
>> >
>> > I understand what you're saying. The following excerpt out of the book
>> > shows
>> > that F_j does not refer exclusively to categorical factors: "...the rule
>> > does not do anything special for them, and it remains valid, in a
>> > trivial
>> > sense, whenever any of the F_j is numeric rather than categorical."
>> > Since
>> > F_j refers to both categorical and numeric variables, the behavior of
>> > model.matrix is not consistent with the heuristic.
>> >
>> > Best regards,
>> > Tyler
>> >
>> > On Sat, Nov 4, 2017 at 6:50 AM, Arie ten Cate <arietencate at gmail.com>
>> > wrote:
>> >>
>> >> Hello Tyler,
>> >>
>> >> I rephrase my previous mail, as follows:
>> >>
>> >> In your example, T_i = X1:X2:X3. Let F_j = X3. (The numerical
>> >> variables X1 and X2 are not encoded at all.) Then T_{i(j)} = X1:X2,
>> >> which in the example is dropped from the model. Hence the X3 in T_i
>> >> must be encoded by dummy variables, as indeed it is.
>> >>
>> >>   Arie
>> >>
>> >>
>> >> On Thu, Nov 2, 2017 at 4:11 PM, Tyler <tylermw at gmail.com> wrote:
>> >> > Hi Arie,
>> >> >
>> >> > The book out of which this behavior is based does not use factor (in
>> >> > this
>> >> > section) to refer to categorical factor. I will again point to this
>> >> > sentence, from page 40, in the same section and referring to the
>> >> > behavior
>> >> > under question, that shows F_j is not limited to categorical factors:
>> >> > "Numeric variables appear in the computations as themselves, uncoded.
>> >> > Therefore, the rule does not do anything special for them, and it
>> >> > remains
>> >> > valid, in a trivial sense, whenever any of the F_j is numeric rather
>> >> > than
>> >> > categorical."
>> >> >
>> >> > Note the "... whenever any of the F_j is numeric rather than
>> >> > categorical."
>> >> > Factor here is used in the more general sense of the word, not
>> >> > referring
>> >> > to
>> >> > the R type "factor." The behavior of R does not match the heuristic
>> >> > that
>> >> > it's citing.
>> >> >
>> >> > Best regards,
>> >> > Tyler
>> >> >
>> >> > On Thu, Nov 2, 2017 at 2:51 AM, Arie ten Cate <arietencate at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> Hello Tyler,
>> >> >>
>> >> >> Thank you for searching for, and finding, the basic description of
>> >> >> the
>> >> >> behavior of R in this matter.
>> >> >>
>> >> >> I think your example is in agreement with the book.
>> >> >>
>> >> >> But let me first note the following. You write: "F_j refers to a
>> >> >> factor (variable) in a model and not a categorical factor". However:
>> >> >> "a factor is a vector object used to specify a discrete
>> >> >> classification" (start of chapter 4 of "An Introduction to R".) You
>> >> >> might also see the description of the R function factor().
>> >> >>
>> >> >> You note that the book says about a factor F_j:
>> >> >>   "... F_j is coded by contrasts if T_{i(j)} has appeared in the
>> >> >> formula and by dummy variables if it has not"
>> >> >>
>> >> >> You find:
>> >> >>    "However, the example I gave demonstrated that this dummy
>> >> >> variable
>> >> >> encoding only occurs for the model where the missing term is the
>> >> >> numeric-numeric interaction, ~(X1+X2+X3)^3-X1:X2."
>> >> >>
>> >> >> We have here T_i = X1:X2:X3. Also: F_j = X3 (the only factor). Then
>> >> >> T_{i(j)} = X1:X2, which is dropped from the model. Hence the X3 in
>> >> >> T_i
>> >> >> must be encoded by dummy variables, as indeed it is.
>> >> >>
>> >> >>   Arie
>> >> >>
>> >> >> On Tue, Oct 31, 2017 at 4:01 PM, Tyler <tylermw at gmail.com> wrote:
>> >> >> > Hi Arie,
>> >> >> >
>> >> >> > Thank you for your further research into the issue.
>> >> >> >
>> >> >> > Regarding Stata: On the other hand, JMP gives model matrices that
>> >> >> > use
>> >> >> > the
>> >> >> > main effects contrasts in computing the higher order interactions,
>> >> >> > without
>> >> >> > the dummy variable encoding. I verified this both by analyzing the
>> >> >> > linear
>> >> >> > model given in my first example and noting that JMP has one more
>> >> >> > degree
>> >> >> > of
>> >> >> > freedom than R for the same model, as well as looking at the
>> >> >> > generated
>> >> >> > model
>> >> >> > matrices. It's easy to find a design where JMP will allow us fit
>> >> >> > our
>> >> >> > model
>> >> >> > with goodness-of-fit estimates and R will not due to the extra
>> >> >> > degree(s)
>> >> >> > of
>> >> >> > freedom required. Let's keep the conversation limited to R.
>> >> >> >
>> >> >> > I want to refocus back onto my original bug report, which was not
>> >> >> > for
>> >> >> > a
>> >> >> > missing main effects term, but rather for a missing lower-order
>> >> >> > interaction
>> >> >> > term. The behavior of model.matrix.default() for a missing main
>> >> >> > effects
>> >> >> > term
>> >> >> > is a nice example to demonstrate how model.matrix encodes with
>> >> >> > dummy
>> >> >> > variables instead of contrasts, but doesn't demonstrate the
>> >> >> > inconsistent
>> >> >> > behavior my bug report highlighted.
>> >> >> >
>> >> >> > I went looking for documentation on this behavior, and the issue
>> >> >> > stems
>> >> >> > not
>> >> >> > from model.matrix.default(), but rather the terms() function in
>> >> >> > interpreting
>> >> >> > the formula. This "clever" replacement of contrasts by dummy
>> >> >> > variables
>> >> >> > to
>> >> >> > maintain marginality (presuming that's the reason) is not
>> >> >> > described
>> >> >> > anywhere
>> >> >> > in the documentation for either the model.matrix() or the terms()
>> >> >> > function.
>> >> >> > In order to find a description for the behavior, I had to look in
>> >> >> > the
>> >> >> > underlying C code, buried above the "TermCode" function of the
>> >> >> > "model.c"
>> >> >> > file, which says:
>> >> >> >
>> >> >> > "TermCode decides on the encoding of a model term. Returns 1 if
>> >> >> > variable
>> >> >> > ``whichBit'' in ``thisTerm'' is to be encoded by contrasts and 2
>> >> >> > if
>> >> >> > it
>> >> >> > is to
>> >> >> > be encoded by dummy variables.  This is decided using the
>> >> >> > heuristic
>> >> >> > described in Statistical Models in S, page 38."
>> >> >> >
>> >> >> > I do not have a copy of this book, and I suspect most R users do
>> >> >> > not
>> >> >> > as
>> >> >> > well. Thankfully, however, some of the pages describing this
>> >> >> > behavior
>> >> >> > were
>> >> >> > available as part of Amazon's "Look Inside" feature--but if not
>> >> >> > for
>> >> >> > that, I
>> >> >> > would have no idea what heuristic R was using. Since those pages
>> >> >> > could
>> >> >> > made
>> >> >> > unavailable by Amazon at any time, at the very least we have an
>> >> >> > problem
>> >> >> > with
>> >> >> > a lack of documentation.
>> >> >> >
>> >> >> > However, I still believe there is a bug when comparing R's
>> >> >> > implementation to
>> >> >> > the heuristic described in the book. From Statistical Models in S,
>> >> >> > page
>> >> >> > 38-39:
>> >> >> >
>> >> >> > "Suppose F_j is any factor included in term T_i. Let T_{i(j)}
>> >> >> > denote
>> >> >> > the
>> >> >> > margin of T_i for factor F_j--that is, the term obtained by
>> >> >> > dropping
>> >> >> > F_j
>> >> >> > from T_i. We say that T_{i(j)} has appeared in the formula if
>> >> >> > there
>> >> >> > is
>> >> >> > some
>> >> >> > term T_i' for i' < i such that T_i' contains all the factors
>> >> >> > appearing
>> >> >> > in
>> >> >> > T_{i(j)}. The usual case is that T_{i(j)} itself is one of the
>> >> >> > preceding
>> >> >> > terms. Then F_j is coded by contrasts if T_{i(j)} has appeared in
>> >> >> > the
>> >> >> > formula and by dummy variables if it has not"
>> >> >> >
>> >> >> > Here, F_j refers to a factor (variable) in a model and not a
>> >> >> > categorical
>> >> >> > factor, as specified later in that section (page 40): "Numeric
>> >> >> > variables
>> >> >> > appear in the computations as themselves, uncoded. Therefore, the
>> >> >> > rule
>> >> >> > does
>> >> >> > not do anything special for them, and it remains valid, in a
>> >> >> > trivial
>> >> >> > sense,
>> >> >> > whenever any of the F_j is numeric rather than categorical."
>> >> >> >
>> >> >> > Going back to my original example with three variables: X1
>> >> >> > (numeric),
>> >> >> > X2
>> >> >> > (numeric), X3 (categorical). This heuristic prescribes encoding
>> >> >> > X1:X2:X3
>> >> >> > with contrasts as long as X1:X2, X1:X3, and X2:X3 exist in the
>> >> >> > formula.
>> >> >> > When
>> >> >> > any of the preceding terms do not exist, this heuristic tells us
>> >> >> > to
>> >> >> > use
>> >> >> > dummy variables to encode the interaction (e.g. "F_j [the
>> >> >> > interaction
>> >> >> > term]
>> >> >> > is coded ... by dummy variables if it [any of the marginal terms
>> >> >> > obtained by
>> >> >> > dropping a single factor in the interaction] has not [appeared in
>> >> >> > the
>> >> >> > formula]"). However, the example I gave demonstrated that this
>> >> >> > dummy
>> >> >> > variable encoding only occurs for the model where the missing term
>> >> >> > is
>> >> >> > the
>> >> >> > numeric-numeric interaction, "~(X1+X2+X3)^3-X1:X2". Otherwise, the
>> >> >> > interaction term X1:X2:X3 is encoded by contrasts, not dummy
>> >> >> > variables.
>> >> >> > This
>> >> >> > is inconsistent with the description of the intended behavior
>> >> >> > given
>> >> >> > in
>> >> >> > the
>> >> >> > book.
>> >> >> >
>> >> >> > Best regards,
>> >> >> > Tyler
>> >> >> >
>> >> >> >
>> >> >> > On Fri, Oct 27, 2017 at 2:18 PM, Arie ten Cate
>> >> >> > <arietencate at gmail.com>
>> >> >> > wrote:
>> >> >> >>
>> >> >> >> Hello Tyler,
>> >> >> >>
>> >> >> >> I want to bring to your attention the following document: "What
>> >> >> >> happens if you omit the main effect in a regression model with an
>> >> >> >> interaction?"
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >> (https://stats.idre.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a-regression-model-with-an-interaction).
>> >> >> >> This gives a useful review of the problem. Your example is Case
>> >> >> >> 2: a
>> >> >> >> continuous and a categorical regressor.
>> >> >> >>
>> >> >> >> The numerical examples are coded in Stata, and they give the same
>> >> >> >> result as in R. Hence, if this is a bug in R then it is also a
>> >> >> >> bug
>> >> >> >> in
>> >> >> >> Stata. That seems very unlikely.
>> >> >> >>
>> >> >> >> Here is a simulation in R of the above mentioned Case 2 in Stata:
>> >> >> >>
>> >> >> >> df <- expand.grid(socst=c(-1:1),grp=c("1","2","3","4"))
>> >> >> >> print("Full model")
>> >> >> >> print(model.matrix(~(socst+grp)^2 ,data=df))
>> >> >> >> print("Example 2.1: drop socst")
>> >> >> >> print(model.matrix(~(socst+grp)^2 -socst ,data=df))
>> >> >> >> print("Example 2.2: drop grp")
>> >> >> >> print(model.matrix(~(socst+grp)^2 -grp ,data=df))
>> >> >> >>
>> >> >> >> This gives indeed the following regressors:
>> >> >> >>
>> >> >> >> "Full model"
>> >> >> >> (Intercept) socst grp2 grp3 grp4 socst:grp2 socst:grp3 socst:grp4
>> >> >> >> "Example 2.1: drop socst"
>> >> >> >> (Intercept) grp2 grp3 grp4 socst:grp1 socst:grp2 socst:grp3
>> >> >> >> socst:grp4
>> >> >> >> "Example 2.2: drop grp"
>> >> >> >> (Intercept) socst socst:grp2 socst:grp3 socst:grp4
>> >> >> >>
>> >> >> >> There is a little bit of R documentation about this, based on the
>> >> >> >> concept of marginality, which typically forbids a model having an
>> >> >> >> interaction but not the corresponding main effects. (You might
>> >> >> >> see
>> >> >> >> the
>> >> >> >> references in
>> >> >> >> https://en.wikipedia.org/wiki/Principle_of_marginality
>> >> >> >> )
>> >> >> >>     See "An Introduction to R", by Venables and Smith and the R
>> >> >> >> Core
>> >> >> >> Team. At the bottom of page 52 (PDF: 57) it says: "Although the
>> >> >> >> details are complicated, model formulae in R will normally
>> >> >> >> generate
>> >> >> >> the models that an expert statistician would expect, provided
>> >> >> >> that
>> >> >> >> marginality is preserved. Fitting, for [a contrary] example, a
>> >> >> >> model
>> >> >> >> with an interaction but not the corresponding main effects will
>> >> >> >> in
>> >> >> >> general lead to surprising results ....".
>> >> >> >>     The Reference Manual states that the R functions dropterm()
>> >> >> >> and
>> >> >> >> addterm() resp. drop or add only terms such that marginality is
>> >> >> >> preserved.
>> >> >> >>
>> >> >> >> Finally, about your singular matrix t(mm)%*%mm. This is in fact
>> >> >> >> Example 2.1 in Case 2 discussed above. As discussed there, in
>> >> >> >> Stata
>> >> >> >> and in R the drop of the continuous variable has no effect on the
>> >> >> >> degrees of freedom here: it is just a reparameterisation of the
>> >> >> >> full
>> >> >> >> model, protecting you against losing marginality... Hence the
>> >> >> >> model.matrix 'mm' is still square and nonsingular after the drop
>> >> >> >> of
>> >> >> >> X1, unless of course when a row is removed from the matrix
>> >> >> >> 'design'
>> >> >> >> when before creating 'mm'.
>> >> >> >>
>> >> >> >>     Arie
>> >> >> >>
>> >> >> >> On Sun, Oct 15, 2017 at 7:05 PM, Tyler <tylermw at gmail.com> wrote:
>> >> >> >> > You could possibly try to explain away the behavior for a
>> >> >> >> > missing
>> >> >> >> > main
>> >> >> >> > effects term, since without the main effects term we don't have
>> >> >> >> > main
>> >> >> >> > effect
>> >> >> >> > columns in the model matrix used to compute the interaction
>> >> >> >> > columns
>> >> >> >> > (At
>> >> >> >> > best this is undocumented behavior--I still think it's a bug,
>> >> >> >> > as
>> >> >> >> > we
>> >> >> >> > know
>> >> >> >> > how we would encode the categorical factors if they were in
>> >> >> >> > fact
>> >> >> >> > present.
>> >> >> >> > It's either specified in contrasts.arg or using the default set
>> >> >> >> > in
>> >> >> >> > options). However, when all the main effects are present, why
>> >> >> >> > would
>> >> >> >> > the
>> >> >> >> > three-factor interaction column not simply be the product of
>> >> >> >> > the
>> >> >> >> > main
>> >> >> >> > effect columns? In my example: we know X1, we know X2, and we
>> >> >> >> > know
>> >> >> >> > X3.
>> >> >> >> > Why
>> >> >> >> > does the encoding of X1:X2:X3 depend on whether we specified a
>> >> >> >> > two-factor
>> >> >> >> > interaction, AND only changes for specific missing
>> >> >> >> > interactions?
>> >> >> >> >
>> >> >> >> > In addition, I can use a two-term example similar to yours to
>> >> >> >> > show
>> >> >> >> > how
>> >> >> >> > this
>> >> >> >> > behavior results in a singular covariance matrix when, given
>> >> >> >> > the
>> >> >> >> > desired
>> >> >> >> > factor encoding, it should not be singular.
>> >> >> >> >
>> >> >> >> > We start with a full factorial design for a two-level
>> >> >> >> > continuous
>> >> >> >> > factor
>> >> >> >> > and
>> >> >> >> > a three-level categorical factor, and remove a single row. This
>> >> >> >> > design
>> >> >> >> > matrix does not leave enough degrees of freedom to determine
>> >> >> >> > goodness-of-fit, but should allow us to obtain parameter
>> >> >> >> > estimates.
>> >> >> >> >
>> >> >> >> >> design = expand.grid(X1=c(1,-1),X2=c("A","B","C"))
>> >> >> >> >> design = design[-1,]
>> >> >> >> >> design
>> >> >> >> >   X1 X2
>> >> >> >> > 2 -1  A
>> >> >> >> > 3  1  B
>> >> >> >> > 4 -1  B
>> >> >> >> > 5  1  C
>> >> >> >> > 6 -1  C
>> >> >> >> >
>> >> >> >> > Here, we first calculate the model matrix for the full model,
>> >> >> >> > and
>> >> >> >> > then
>> >> >> >> > manually remove the X1 column from the model matrix. This gives
>> >> >> >> > us
>> >> >> >> > the
>> >> >> >> > model matrix one would expect if X1 were removed from the
>> >> >> >> > model.
>> >> >> >> > We
>> >> >> >> > then
>> >> >> >> > successfully calculate the covariance matrix.
>> >> >> >> >
>> >> >> >> >> mm = model.matrix(~(X1+X2)^2,data=design)
>> >> >> >> >> mm
>> >> >> >> >   (Intercept) X1 X2B X2C X1:X2B X1:X2C
>> >> >> >> > 2           1 -1   0   0      0      0
>> >> >> >> > 3           1  1   1   0      1      0
>> >> >> >> > 4           1 -1   1   0     -1      0
>> >> >> >> > 5           1  1   0   1      0      1
>> >> >> >> > 6           1 -1   0   1      0     -1
>> >> >> >> >
>> >> >> >> >> mm = mm[,-2]
>> >> >> >> >> solve(t(mm) %*% mm)
>> >> >> >> >             (Intercept)  X2B  X2C X1:X2B X1:X2C
>> >> >> >> > (Intercept)           1 -1.0 -1.0    0.0    0.0
>> >> >> >> > X2B                  -1  1.5  1.0    0.0    0.0
>> >> >> >> > X2C                  -1  1.0  1.5    0.0    0.0
>> >> >> >> > X1:X2B                0  0.0  0.0    0.5    0.0
>> >> >> >> > X1:X2C                0  0.0  0.0    0.0    0.5
>> >> >> >> >
>> >> >> >> > Here, we see the actual behavior for model.matrix. The
>> >> >> >> > undesired
>> >> >> >> > re-coding
>> >> >> >> > of the model matrix interaction term makes the information
>> >> >> >> > matrix
>> >> >> >> > singular.
>> >> >> >> >
>> >> >> >> >> mm = model.matrix(~(X1+X2)^2-X1,data=design)
>> >> >> >> >> mm
>> >> >> >> >   (Intercept) X2B X2C X1:X2A X1:X2B X1:X2C
>> >> >> >> > 2           1   0   0     -1      0      0
>> >> >> >> > 3           1   1   0      0      1      0
>> >> >> >> > 4           1   1   0      0     -1      0
>> >> >> >> > 5           1   0   1      0      0      1
>> >> >> >> > 6           1   0   1      0      0     -1
>> >> >> >> >
>> >> >> >> >> solve(t(mm) %*% mm)
>> >> >> >> > Error in solve.default(t(mm) %*% mm) : system is
>> >> >> >> > computationally
>> >> >> >> > singular:
>> >> >> >> > reciprocal condition number = 5.55112e-18
>> >> >> >> >
>> >> >> >> > I still believe this is a bug.
>> >> >> >> >
>> >> >> >> > Best regards,
>> >> >> >> > Tyler Morgan-Wall
>> >> >> >> >
>> >> >> >> > On Sun, Oct 15, 2017 at 1:49 AM, Arie ten Cate
>> >> >> >> > <arietencate at gmail.com>
>> >> >> >> > wrote:
>> >> >> >> >
>> >> >> >> >> I think it is not a bug. It is a general property of
>> >> >> >> >> interactions.
>> >> >> >> >> This property is best observed if all variables are factors
>> >> >> >> >> (qualitative).
>> >> >> >> >>
>> >> >> >> >> For example, you have three variables (factors). You ask for
>> >> >> >> >> as
>> >> >> >> >> many
>> >> >> >> >> interactions as possible, except an interaction term between
>> >> >> >> >> two
>> >> >> >> >> particular variables. When this interaction is not a constant,
>> >> >> >> >> it
>> >> >> >> >> is
>> >> >> >> >> different for different values of the remaining variable. More
>> >> >> >> >> precisely: for all values of that variable. In other words:
>> >> >> >> >> you
>> >> >> >> >> have
>> >> >> >> >> a
>> >> >> >> >> three-way interaction, with all values of that variable.
>> >> >> >> >>
>> >> >> >> >> An even smaller example is the following script with only two
>> >> >> >> >> variables, each being a factor:
>> >> >> >> >>
>> >> >> >> >>  df <- expand.grid(X1=c("p","q"), X2=c("A","B","C"))
>> >> >> >> >>  print(model.matrix(~(X1+X2)^2    ,data=df))
>> >> >> >> >>  print(model.matrix(~(X1+X2)^2 -X1,data=df))
>> >> >> >> >>  print(model.matrix(~(X1+X2)^2 -X2,data=df))
>> >> >> >> >>
>> >> >> >> >> The result is:
>> >> >> >> >>
>> >> >> >> >>   (Intercept) X1q X2B X2C X1q:X2B X1q:X2C
>> >> >> >> >> 1           1   0   0   0       0       0
>> >> >> >> >> 2           1   1   0   0       0       0
>> >> >> >> >> 3           1   0   1   0       0       0
>> >> >> >> >> 4           1   1   1   0       1       0
>> >> >> >> >> 5           1   0   0   1       0       0
>> >> >> >> >> 6           1   1   0   1       0       1
>> >> >> >> >>
>> >> >> >> >>   (Intercept) X2B X2C X1q:X2A X1q:X2B X1q:X2C
>> >> >> >> >> 1           1   0   0       0       0       0
>> >> >> >> >> 2           1   0   0       1       0       0
>> >> >> >> >> 3           1   1   0       0       0       0
>> >> >> >> >> 4           1   1   0       0       1       0
>> >> >> >> >> 5           1   0   1       0       0       0
>> >> >> >> >> 6           1   0   1       0       0       1
>> >> >> >> >>
>> >> >> >> >>   (Intercept) X1q X1p:X2B X1q:X2B X1p:X2C X1q:X2C
>> >> >> >> >> 1           1   0       0       0       0       0
>> >> >> >> >> 2           1   1       0       0       0       0
>> >> >> >> >> 3           1   0       1       0       0       0
>> >> >> >> >> 4           1   1       0       1       0       0
>> >> >> >> >> 5           1   0       0       0       1       0
>> >> >> >> >> 6           1   1       0       0       0       1
>> >> >> >> >>
>> >> >> >> >> Thus, in the second result, we have no main effect of X1.
>> >> >> >> >> Instead,
>> >> >> >> >> the
>> >> >> >> >> effect of X1 depends on the value of X2; either A or B or C.
>> >> >> >> >> In
>> >> >> >> >> fact,
>> >> >> >> >> this is a two-way interaction, including all three values of
>> >> >> >> >> X2.
>> >> >> >> >> In
>> >> >> >> >> the third result, we have no main effect of X2, The effect of
>> >> >> >> >> X2
>> >> >> >> >> depends on the value of X1; either p or q.
>> >> >> >> >>
>> >> >> >> >> A complicating element with your example seems to be that your
>> >> >> >> >> X1
>> >> >> >> >> and
>> >> >> >> >> X2 are not factors.
>> >> >> >> >>
>> >> >> >> >>    Arie
>> >> >> >> >>
>> >> >> >> >> On Thu, Oct 12, 2017 at 7:12 PM, Tyler <tylermw at gmail.com>
>> >> >> >> >> wrote:
>> >> >> >> >> > Hi,
>> >> >> >> >> >
>> >> >> >> >> > I recently ran into an inconsistency in the way
>> >> >> >> >> > model.matrix.default
>> >> >> >> >> > handles factor encoding for higher level interactions with
>> >> >> >> >> > categorical
>> >> >> >> >> > variables when the full hierarchy of effects is not present.
>> >> >> >> >> > Depending on
>> >> >> >> >> > which lower level interactions are specified, the factor
>> >> >> >> >> > encoding
>> >> >> >> >> > changes
>> >> >> >> >> > for a higher level interaction. Consider the following
>> >> >> >> >> > minimal
>> >> >> >> >> reproducible
>> >> >> >> >> > example:
>> >> >> >> >> >
>> >> >> >> >> > --------------
>> >> >> >> >> >
>> >> >> >> >> >> runmatrix =
>> >> >> >> >> >> expand.grid(X1=c(1,-1),X2=c(1,-1),X3=c("A","B","C"))>
>> >> >> >> >> model.matrix(~(X1+X2+X3)^3,data=runmatrix)   (Intercept) X1 X2
>> >> >> >> >> X3B
>> >> >> >> >> X3C
>> >> >> >> >> X1:X2 X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> >> > 1            1  1  1   0   0     1      0      0      0
>> >> >> >> >> > 0
>> >> >> >> >> > 0         0
>> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0      0
>> >> >> >> >> > 0
>> >> >> >> >> > 0         0
>> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0      0
>> >> >> >> >> > 0
>> >> >> >> >> > 0         0
>> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0      0
>> >> >> >> >> > 0
>> >> >> >> >> > 0         0
>> >> >> >> >> > 5            1  1  1   1   0     1      1      0      1
>> >> >> >> >> > 0
>> >> >> >> >> > 1         0
>> >> >> >> >> > 6            1 -1  1   1   0    -1     -1      0      1
>> >> >> >> >> > 0
>> >> >> >> >> > -1         0
>> >> >> >> >> > 7            1  1 -1   1   0    -1      1      0     -1
>> >> >> >> >> > 0
>> >> >> >> >> > -1         0
>> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0     -1
>> >> >> >> >> > 0
>> >> >> >> >> > 1         0
>> >> >> >> >> > 9            1  1  1   0   1     1      0      1      0
>> >> >> >> >> > 1
>> >> >> >> >> > 0         1
>> >> >> >> >> > 10           1 -1  1   0   1    -1      0     -1      0
>> >> >> >> >> > 1
>> >> >> >> >> > 0        -1
>> >> >> >> >> > 11           1  1 -1   0   1    -1      0      1      0
>> >> >> >> >> > -1
>> >> >> >> >> > 0        -1
>> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1      0
>> >> >> >> >> > -1
>> >> >> >> >> > 0         1
>> >> >> >> >> > attr(,"assign")
>> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6 7 7
>> >> >> >> >> > attr(,"contrasts")
>> >> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> >> > [1] "contr.treatment"
>> >> >> >> >> >
>> >> >> >> >> > --------------
>> >> >> >> >> >
>> >> >> >> >> > Specifying the full hierarchy gives us what we expect: the
>> >> >> >> >> > interaction
>> >> >> >> >> > columns are simply calculated from the product of the main
>> >> >> >> >> > effect
>> >> >> >> >> columns.
>> >> >> >> >> > The interaction term X1:X2:X3 gives us two columns in the
>> >> >> >> >> > model
>> >> >> >> >> > matrix,
>> >> >> >> >> > X1:X2:X3B and X1:X2:X3C, matching the products of the main
>> >> >> >> >> > effects.
>> >> >> >> >> >
>> >> >> >> >> > If we remove either the X2:X3 interaction or the X1:X3
>> >> >> >> >> > interaction,
>> >> >> >> >> > we
>> >> >> >> >> get
>> >> >> >> >> > what we would expect for the X1:X2:X3 interaction, but when
>> >> >> >> >> > we
>> >> >> >> >> > remove
>> >> >> >> >> > the
>> >> >> >> >> > X1:X2 interaction the encoding for X1:X2:X3 changes
>> >> >> >> >> > completely:
>> >> >> >> >> >
>> >> >> >> >> > --------------
>> >> >> >> >> >
>> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X3,data=runmatrix)
>> >> >> >> >> >> (Intercept)
>> >> >> >> >> >> X1
>> >> >> >> >> >> X2
>> >> >> >> >> X3B X3C X1:X2 X2:X3B X2:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> >> >> > 0
>> >> >> >> >> > 6            1 -1  1   1   0    -1      1      0        -1
>> >> >> >> >> > 0
>> >> >> >> >> > 7            1  1 -1   1   0    -1     -1      0        -1
>> >> >> >> >> > 0
>> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> >> >> > 0
>> >> >> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> >> >> > 1
>> >> >> >> >> > 10           1 -1  1   0   1    -1      0      1         0
>> >> >> >> >> > -1
>> >> >> >> >> > 11           1  1 -1   0   1    -1      0     -1         0
>> >> >> >> >> > -1
>> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> >> >> > 1
>> >> >> >> >> > attr(,"assign")
>> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> >> >> > attr(,"contrasts")
>> >> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> >> > [1] "contr.treatment"
>> >> >> >> >> >
>> >> >> >> >> >
>> >> >> >> >> >
>> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X2:X3,data=runmatrix)
>> >> >> >> >> >> (Intercept)
>> >> >> >> >> >> X1
>> >> >> >> >> >> X2
>> >> >> >> >> X3B X3C X1:X2 X1:X3B X1:X3C X1:X2:X3B X1:X2:X3C
>> >> >> >> >> > 1            1  1  1   0   0     1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 2            1 -1  1   0   0    -1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 3            1  1 -1   0   0    -1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 4            1 -1 -1   0   0     1      0      0         0
>> >> >> >> >> > 0
>> >> >> >> >> > 5            1  1  1   1   0     1      1      0         1
>> >> >> >> >> > 0
>> >> >> >> >> > 6            1 -1  1   1   0    -1     -1      0        -1
>> >> >> >> >> > 0
>> >> >> >> >> > 7            1  1 -1   1   0    -1      1      0        -1
>> >> >> >> >> > 0
>> >> >> >> >> > 8            1 -1 -1   1   0     1     -1      0         1
>> >> >> >> >> > 0
>> >> >> >> >> > 9            1  1  1   0   1     1      0      1         0
>> >> >> >> >> > 1
>> >> >> >> >> > 10           1 -1  1   0   1    -1      0     -1         0
>> >> >> >> >> > -1
>> >> >> >> >> > 11           1  1 -1   0   1    -1      0      1         0
>> >> >> >> >> > -1
>> >> >> >> >> > 12           1 -1 -1   0   1     1      0     -1         0
>> >> >> >> >> > 1
>> >> >> >> >> > attr(,"assign")
>> >> >> >> >> >  [1] 0 1 2 3 3 4 5 5 6 6
>> >> >> >> >> > attr(,"contrasts")
>> >> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> >> > [1] "contr.treatment"
>> >> >> >> >> >
>> >> >> >> >> >
>> >> >> >> >> >> model.matrix(~(X1+X2+X3)^3-X1:X2,data=runmatrix)
>> >> >> >> >> >> (Intercept)
>> >> >> >> >> >> X1
>> >> >> >> >> >> X2
>> >> >> >> >> X3B X3C X1:X3B X1:X3C X2:X3B X2:X3C X1:X2:X3A X1:X2:X3B
>> >> >> >> >> X1:X2:X3C
>> >> >> >> >> > 1            1  1  1   0   0      0      0      0      0
>> >> >> >> >> > 1
>> >> >> >> >> >     0         0
>> >> >> >> >> > 2            1 -1  1   0   0      0      0      0      0
>> >> >> >> >> > -1
>> >> >> >> >> >     0         0
>> >> >> >> >> > 3            1  1 -1   0   0      0      0      0      0
>> >> >> >> >> > -1
>> >> >> >> >> >     0         0
>> >> >> >> >> > 4            1 -1 -1   0   0      0      0      0      0
>> >> >> >> >> > 1
>> >> >> >> >> >     0         0
>> >> >> >> >> > 5            1  1  1   1   0      1      0      1      0
>> >> >> >> >> > 0
>> >> >> >> >> >     1         0
>> >> >> >> >> > 6            1 -1  1   1   0     -1      0      1      0
>> >> >> >> >> > 0
>> >> >> >> >> >    -1         0
>> >> >> >> >> > 7            1  1 -1   1   0      1      0     -1      0
>> >> >> >> >> > 0
>> >> >> >> >> >    -1         0
>> >> >> >> >> > 8            1 -1 -1   1   0     -1      0     -1      0
>> >> >> >> >> > 0
>> >> >> >> >> >     1         0
>> >> >> >> >> > 9            1  1  1   0   1      0      1      0      1
>> >> >> >> >> > 0
>> >> >> >> >> >     0         1
>> >> >> >> >> > 10           1 -1  1   0   1      0     -1      0      1
>> >> >> >> >> > 0
>> >> >> >> >> >     0        -1
>> >> >> >> >> > 11           1  1 -1   0   1      0      1      0     -1
>> >> >> >> >> > 0
>> >> >> >> >> >     0        -1
>> >> >> >> >> > 12           1 -1 -1   0   1      0     -1      0     -1
>> >> >> >> >> > 0
>> >> >> >> >> >     0         1
>> >> >> >> >> > attr(,"assign")
>> >> >> >> >> >  [1] 0 1 2 3 3 4 4 5 5 6 6 6
>> >> >> >> >> > attr(,"contrasts")
>> >> >> >> >> > attr(,"contrasts")$X3
>> >> >> >> >> > [1] "contr.treatment"
>> >> >> >> >> >
>> >> >> >> >> > --------------
>> >> >> >> >> >
>> >> >> >> >> > Here, we now see the encoding for the interaction X1:X2:X3
>> >> >> >> >> > is
>> >> >> >> >> > now
>> >> >> >> >> > the
>> >> >> >> >> > interaction of X1 and X2 with a new encoding for X3 where
>> >> >> >> >> > each
>> >> >> >> >> > factor
>> >> >> >> >> level
>> >> >> >> >> > is represented by its own column. I would expect, given the
>> >> >> >> >> > two
>> >> >> >> >> > column
>> >> >> >> >> > dummy variable encoding for X3, that the X1:X2:X3 column
>> >> >> >> >> > would
>> >> >> >> >> > also
>> >> >> >> >> > be
>> >> >> >> >> two
>> >> >> >> >> > columns regardless of what two-factor interactions we also
>> >> >> >> >> > specified,
>> >> >> >> >> > but
>> >> >> >> >> > in this case it switches to three. If other two factor
>> >> >> >> >> > interactions
>> >> >> >> >> > are
>> >> >> >> >> > missing in addition to X1:X2, this issue still occurs. This
>> >> >> >> >> > also
>> >> >> >> >> > happens
>> >> >> >> >> > regardless of the contrast specified in contrasts.arg for
>> >> >> >> >> > X3. I
>> >> >> >> >> > don't
>> >> >> >> >> > see
>> >> >> >> >> > any reasoning for this behavior given in the documentation,
>> >> >> >> >> > so
>> >> >> >> >> > I
>> >> >> >> >> > suspect
>> >> >> >> >> it
>> >> >> >> >> > is a bug.
>> >> >> >> >> >
>> >> >> >> >> > Best regards,
>> >> >> >> >> > Tyler Morgan-Wall
>> >> >> >> >> >
>> >> >> >> >> >         [[alternative HTML version deleted]]
>> >> >> >> >> >
>> >> >> >> >> > ______________________________________________
>> >
>> >
>
>


From tomas.kalibera at gmail.com  Tue Nov  7 15:55:57 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 7 Nov 2017 15:55:57 +0100
Subject: [Rd] range function with finite=T and logical parameters
In-Reply-To: <23022.6773.353931.80946@stat.math.ethz.ch>
References: <A7D1EB89-0A3C-456D-A73C-6E3B2B11DF3E@oracle.com>
 <23022.6773.353931.80946@stat.math.ethz.ch>
Message-ID: <8d573470-0df9-cf6e-e780-ef34f166da0d@gmail.com>

FYI this has been fixed in R-devel by Martin
Tomas

On 10/23/2017 06:36 PM, Martin Maechler wrote:
>>>>>> Lukas Stadler <lukas.stadler at oracle.com>
>>>>>>      on Mon, 23 Oct 2017 15:56:55 +0200 writes:
>      > Hi!
>      > I was wondering about the behavior of the range function wrt. logical NAs:
>
>      >> range(c(0L, 1L, NA), finite=T)
>      > [1] 0 1
>      >> range(c(F, T, NA), finite=T)
>      > [1] NA NA
>
>      > The documentation is quite clear that "finite = TRUE includes na.rm = TRUE?, so that I would have assumed that these two snippets would produce the same result.
>
>      > - Lukas
>
>
> I agree.  Further, another informal "rule" would require that the two calls
>
>       range(L, *)
>       range(as.numeric(L), *)
>
> are equivalent for logical vectors L without attributes.
> I'll look into fixing this by an obvious change to (R-level)
> range.default().
>
> ------
>
> Note for the more advanced ones -- i.e. typical R-devel readers :
>
> T and F are variables in R.  For that reason, using the language
> keywords TRUE and FALSE is much preferred in such cases.  For
> some tests we'd even use
>
>      T <- FALSE
>
> or even
>
>      delayedAssign("F", stop("do not use 'F'  when programming with R"))
>
> before running the tests -- just do ensure that the code to be
> tested does not use these short forms.
>
>
> Thank you, Lukas,  for the report!
>
> Best,
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Nov  7 22:48:07 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Nov 2017 22:48:07 +0100
Subject: [Rd] New vcov(*, complete=TRUE) etc -- coef(<lm>) vs coef(<aov>)
In-Reply-To: <23035.34580.701505.839202@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
 <23035.34580.701505.839202@stat.math.ethz.ch>
Message-ID: <23042.10775.842118.267916@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 2 Nov 2017 21:59:00 +0100 writes:

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Thu, 14 Sep 2017 13:46:44 +0000 writes:

    >> Dear Martin, I made three points which likely got lost
    >> because of the way I presented them:

    >> (1) Singularity is an unusual situation and should be
    >> made more prominent. It typically reflects a problem with
    >> the data or the specification of the model. That's not to
    >> say that it *never* makes sense to allow singular fits
    >> (as in the situations you mentions).

    >> I'd favour setting singular.ok=FALSE as the default, but
    >> in the absence of that a warning or at least a note. A
    >> compromise would be to have a singular.ok option() that
    >> would be FALSE out of the box.

    >> Any changes would have to be made very carefully so as
    >> not to create chaos.

    > I for one, am too reluctant to want to change the default
    > there.

    >> That goes for the points below as well.

    >> (2) coef() and vcov() behave inconsistently, which can be
    >> problematic because one often uses them together in code.

    > indeed; and I had agreed on that.  As of today, in R-devel
    > only they now behave compatibly.  NEWS entry

    >     ? The ?default? ("lm" etc) methods of vcov() have
    > gained new optional argument complete = TRUE which makes
    > the vcov() methods more consistent with the coef() methods
    > in the case of singular designs.  The former behavior is
    > now achieved by vcov(*, complete=FALSE).


    >> (3) As you noticed in your second message, lm() has a
    >> singular.ok argument and glm() doesn't.

    > and that has been amended even earlier (a bit more than a
    > month ago) in R-devel svn rev 73380 with NEWS entry

    >     ? glm() and glm.fit get the same singular.ok=TRUE
    > argument that lm() has had forever.  As a consequence, in
    > glm(*, method = <your_own>), user specified methods need
    > to accept a singular.ok argument as well.

    >> I'll take a look at the code for glm() with an eye
    >> towards creating a patch, but I'm a bit reluctant to mess
    >> with the code for something as important as glm().

    > and as a matter of fact you did send me +- the R code part
    > of that change.

    > My current plan is to also add the 'complete = TRUE'
    > option to the "basic" coef() methods, such that you also
    > have consistent coef(*, complete=FALSE) and vcov(*,
    > complete=FALSE) behaviors.

and indeed I had added the above a bit later.

However, to my surprise, I have now found that we have a
coef.aov() method -- completely undocumented which behaves *differently*:

where as the default coef() method which is called for lm(..)
results gives *all* coefficients, and gives  NA  for "aliased" ones,
the aov method *drops* the  NA  coefficients  and has done so
"forever"  (I've checked R version 1.1.1 of April 14, 2000).

vcov() on the other hand has not had a special "aov" method, but
treats aov() and lm() results the same... which means that in
R-devel the vcov() method for an aov() object  uses
'complete=TRUE' and gives NA rows and columns for the aliased coefficients,
whereas  coef.aov()  removes all the NAs  and  gives only the
"non-aliased" coefficients.   Consequently, in R-devel,
vcov(<aov>) and coef(<aov>)  are *now* incoherent, whereas these
two *were* coherent before the change.

I propose to
1. continue the strategy to keep coef() back-compatible  and
2. to *document* the "surprising" behavior of coef.aov()
3. introduce a  vcov.aov()  with complete=FALSE  default
   behavior which is compatile to the coef.aov() one [where I'd
   also introduce the no-change  'complete=FALSE' argument].

Hmm... again, this has been more work and more implications than
originally optimistically assumed..

Opinions, caveats, other feedback -- are very welcome!

Martin


From jfox at mcmaster.ca  Tue Nov  7 23:09:03 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 7 Nov 2017 22:09:03 +0000
Subject: [Rd] New vcov(*, complete=TRUE) etc -- coef(<lm>) vs coef(<aov>)
In-Reply-To: <21185_1510091295_vA7LmFIC009268_23042.10775.842118.267916@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
 <23035.34580.701505.839202@stat.math.ethz.ch>
 <21185_1510091295_vA7LmFIC009268_23042.10775.842118.267916@stat.math.ethz.ch>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836705530@FHSDB4H16-2.csu.mcmaster.ca>

Dear Martin,

I think that your plan makes sense. It's too bad that aov() behaved differently in this respect from lm(), and thus created more work, but it's not be a bad thing that the difference is now explicit and documented.

I expect that that other problems like this will surface, particularly with contributed packages (and I know that you're aware that this has already happened with the car package). That is, packages that made provision for aliased coefficients based on the old behaviour of coef() and vcov() will now have to adapt to the new, more consistent behaviour.

Best,
 John

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin
> Maechler
> Sent: Tuesday, November 7, 2017 4:48 PM
> To: r-devel at r-project.org
> Cc: Martin Maechler <maechler at stat.math.ethz.ch>
> Subject: [Rd] New vcov(*, complete=TRUE) etc -- coef(<lm>) vs coef(<aov>)
> 
> >>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>     on Thu, 2 Nov 2017 21:59:00 +0100 writes:
> 
> >>>>> Fox, John <jfox at mcmaster.ca>
> >>>>>     on Thu, 14 Sep 2017 13:46:44 +0000 writes:
> 
>     >> Dear Martin, I made three points which likely got lost
>     >> because of the way I presented them:
> 
>     >> (1) Singularity is an unusual situation and should be
>     >> made more prominent. It typically reflects a problem with
>     >> the data or the specification of the model. That's not to
>     >> say that it *never* makes sense to allow singular fits
>     >> (as in the situations you mentions).
> 
>     >> I'd favour setting singular.ok=FALSE as the default, but
>     >> in the absence of that a warning or at least a note. A
>     >> compromise would be to have a singular.ok option() that
>     >> would be FALSE out of the box.
> 
>     >> Any changes would have to be made very carefully so as
>     >> not to create chaos.
> 
>     > I for one, am too reluctant to want to change the default
>     > there.
> 
>     >> That goes for the points below as well.
> 
>     >> (2) coef() and vcov() behave inconsistently, which can be
>     >> problematic because one often uses them together in code.
> 
>     > indeed; and I had agreed on that.  As of today, in R-devel
>     > only they now behave compatibly.  NEWS entry
> 
>     >     ? The ?default? ("lm" etc) methods of vcov() have
>     > gained new optional argument complete = TRUE which makes
>     > the vcov() methods more consistent with the coef() methods
>     > in the case of singular designs.  The former behavior is
>     > now achieved by vcov(*, complete=FALSE).
> 
> 
>     >> (3) As you noticed in your second message, lm() has a
>     >> singular.ok argument and glm() doesn't.
> 
>     > and that has been amended even earlier (a bit more than a
>     > month ago) in R-devel svn rev 73380 with NEWS entry
> 
>     >     ? glm() and glm.fit get the same singular.ok=TRUE
>     > argument that lm() has had forever.  As a consequence, in
>     > glm(*, method = <your_own>), user specified methods need
>     > to accept a singular.ok argument as well.
> 
>     >> I'll take a look at the code for glm() with an eye
>     >> towards creating a patch, but I'm a bit reluctant to mess
>     >> with the code for something as important as glm().
> 
>     > and as a matter of fact you did send me +- the R code part
>     > of that change.
> 
>     > My current plan is to also add the 'complete = TRUE'
>     > option to the "basic" coef() methods, such that you also
>     > have consistent coef(*, complete=FALSE) and vcov(*,
>     > complete=FALSE) behaviors.
> 
> and indeed I had added the above a bit later.
> 
> However, to my surprise, I have now found that we have a
> coef.aov() method -- completely undocumented which behaves *differently*:
> 
> where as the default coef() method which is called for lm(..) results gives *all*
> coefficients, and gives  NA  for "aliased" ones, the aov method *drops* the  NA
> coefficients  and has done so "forever"  (I've checked R version 1.1.1 of April 14,
> 2000).
> 
> vcov() on the other hand has not had a special "aov" method, but treats aov()
> and lm() results the same... which means that in R-devel the vcov() method for
> an aov() object  uses 'complete=TRUE' and gives NA rows and columns for the
> aliased coefficients, whereas  coef.aov()  removes all the NAs  and  gives only
> the
> "non-aliased" coefficients.   Consequently, in R-devel,
> vcov(<aov>) and coef(<aov>)  are *now* incoherent, whereas these two
> *were* coherent before the change.
> 
> I propose to
> 1. continue the strategy to keep coef() back-compatible  and 2. to *document*
> the "surprising" behavior of coef.aov() 3. introduce a  vcov.aov()  with
> complete=FALSE  default
>    behavior which is compatile to the coef.aov() one [where I'd
>    also introduce the no-change  'complete=FALSE' argument].
> 
> Hmm... again, this has been more work and more implications than originally
> optimistically assumed..
> 
> Opinions, caveats, other feedback -- are very welcome!
> 
> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From tomas.kalibera at gmail.com  Wed Nov  8 13:17:56 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Wed, 8 Nov 2017 13:17:56 +0100
Subject: [Rd] Rscript Bug Report (improper parsing of [args])
In-Reply-To: <CAMigB8HscaN4sNHagnBZRF-ZMPCvEDZqM2tDX_6HywF3wr-P1w@mail.gmail.com>
References: <CAMigB8HscaN4sNHagnBZRF-ZMPCvEDZqM2tDX_6HywF3wr-P1w@mail.gmail.com>
Message-ID: <0a184a00-c318-5976-1847-85e6831e26bc@gmail.com>

Thanks for the report, fixed in R-devel.
Tomas

On 10/20/2017 08:09 PM, Trevor Davis wrote:
> Hi,
>
> A user of my `optparse` package discovered a bug in Rscript's parsing of
> [args]. (https://github.com/trevorld/optparse/issues/24)
>
> I've reproduced the bug on my machine including compiling and checking the
> development version of R.  I couldn't find a mention of it in the Bug
> Tracker or New Features.
>
> Can be minimally reproduced on the UNIX command line with following
> commands:
>
>      bash$ touch test.R
>      bash$ Rscript test.R -g 5
>
>      WARNING: unknown gui '5', using X11
>
> This is a bug because according to the documentation in ?Rscript besides
> `-e` the only [options] Rscript should attempt to parse should
>
> 1) Come before the file i.e. `Rscript -g X11 test.R` and not `Rscript
> test.R -g X11`
> 2) Begin with two dashes and not one i.e. `--` and not `-' i.e. `Rscript
> --gui=X11 test.R` and not `Rscript -g X11 test.R` (although I'm not sure if
> the command-line Rscript even needs to be supporting the gui option).
>
> Thanks,
>
> Trevor
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jose.conde1 at upr.edu  Wed Nov  8 22:37:42 2017
From: jose.conde1 at upr.edu (Jose G Conde Santiago)
Date: Wed, 8 Nov 2017 17:37:42 -0400
Subject: [Rd] Default for bin limits in hist()
Message-ID: <93254875-80C3-4AB4-A1BA-5598EEAF7676@upr.edu>

Hello all.

I noticed that the default setting for breaks in the construction of histograms in hist() is ?right = TRUE?.

I think ?right=FALSE? would be more consistent with usual definitions of lower and upper limits for bins in applied statistics, and I suggest that you consider making it the default for hist().

For example, I generated the following frequency distribution for duration of hospitalization with a script in R specifying the cuts to be ?right = FALSE? (from an exercise in Bernard Rosner?s Fundamentals of Biostatistics book).  

                number     %
[0,5)             5         0.20
[5,10)         12         0.48
[10,15)         6         0.24
[15,20)         1         0.04
[20,25)         0         0.00
[25,30]         1         0.04

The actual boundaries for each bin are: 0-4, 5-9, 10-14, ? and so on since the limits on the right are ?open?, with the exception of the last bin. This format is in agreement with usual practice and recommendations. Actually, it is compatible with the process described by Romer in his book (?from y inclusive to y exclusive?).

If I use R to generate a histogram with 6 bins, I get the following:

-------------- next part --------------
A non-text attachment was scrubbed...
Name: histogram1.pdf
Type: application/pdf
Size: 4457 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20171108/8db83513/attachment.pdf>
-------------- next part --------------

? which actually presents the histogram of the frequency distribution when the ?right? parameter is set as ?TRUE?: 


               number     %

[0,5]             9         0.36
(5,10]           9         0.36
(10,15]         5         0.20
(15,20]         1         0.04
(20,25]         0         0.00
(25,30]         1         0.04

In this case, the real limits of the bins are 0-5, 6-10, 11-15, ? and so on.

If I edit the histogram command adding ?right = FALSE?, I can get the histogram for my original frequency distribution. Compare bins 1 and 2 in both distributions and histograms.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Histogram2.pdf
Type: application/pdf
Size: 4481 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20171108/8db83513/attachment-0001.pdf>
-------------- next part --------------



The actual choice of the argument for the ?right? parameter may be a matter of choice, but I think most users of R would benefit from using bins with limits that are closed to the left and open to the right, and so having this setting as a default for hist().

I am aware I am writing from the limited perspective of my own field (epidemiology and biostatistics), but there are plenty of examples that show the need to consider changing the default. Here are just a few:

https://www.statcan.gc.ca/eng/concepts/definitions/age2

https://seer.cancer.gov/stdpopulations/stdpop.19ages.html

https://www.census.gov/data/tables/time-series/demo/income-poverty/cps-hinc/hinc-01.html


Thank you.

Jos? 

Jos? G. Conde, MD, MPH
Professor, School of Medicine
Director, CentIT2
UPR Medical Sciences Campus 

Tel  (787) 763-9401 Fax (787) 758-5206

Email: jose.conde1 at upr.edu

URL: http://rcmi.rcm.upr.edu


From wdunlap at tibco.com  Thu Nov  9 01:43:05 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Nov 2017 16:43:05 -0800
Subject: [Rd] check does not check that package examples remove tempdir()
Message-ID: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>

I was looking at the CRAN package 'bfork-0.1.2', which exposes the Unix
fork() and waitpid() calls at the R code level, and noticed that the help
file example for bfork::fork removes R's temporary directory, the value of
tempdir().   I think it happens because the forked process shares the value
of tempdir() with the parent process and removes it when it exits.

This seems like a serious problem - should 'check' make sure that running
code in a package's examples, vignettes, etc. leaves tempdir() intact?

> dir.exists(tempdir())
[1] TRUE
> library(bfork)
> example(fork)

fork>     ## create a function to be run as a separate process
fork>     fn <- function() {
fork+         Sys.sleep(4)
fork+         print("World!")
fork+     }

fork>     ## fork the process
fork>     pid <- fork(fn)

fork>     ## do work in the parent process
fork>     print("Hello")
[1] "Hello"

fork>     ## wait for the child process
fork>     waitpid(pid)
[1] "World!"
[1] 7063
> dir.exists(tempdir())
[1] FALSE


Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Thu Nov  9 01:55:38 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 8 Nov 2017 16:55:38 -0800
Subject: [Rd] check does not check that package examples remove tempdir()
In-Reply-To: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
References: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
Message-ID: <CAFDcVCQt=+gZf-=j_bv2Zt5aNoyhT8WWOjSrLPu9GF97CqFC8w@mail.gmail.com>

Related to this problem - from R-devel NEWS
(https://cran.r-project.org/doc/manuals/r-devel/NEWS.html):

* tempdir(check = TRUE) recreates the tmpdir() if it is no longer
valid (e.g. because some other process has cleaned up the ?/tmp?
directory).

Not sure if there's a plan to make check = TRUE the default though.

/Henrik

On Wed, Nov 8, 2017 at 4:43 PM, William Dunlap via R-devel
<r-devel at r-project.org> wrote:
> I was looking at the CRAN package 'bfork-0.1.2', which exposes the Unix
> fork() and waitpid() calls at the R code level, and noticed that the help
> file example for bfork::fork removes R's temporary directory, the value of
> tempdir().   I think it happens because the forked process shares the value
> of tempdir() with the parent process and removes it when it exits.
>
> This seems like a serious problem - should 'check' make sure that running
> code in a package's examples, vignettes, etc. leaves tempdir() intact?
>
>> dir.exists(tempdir())
> [1] TRUE
>> library(bfork)
>> example(fork)
>
> fork>     ## create a function to be run as a separate process
> fork>     fn <- function() {
> fork+         Sys.sleep(4)
> fork+         print("World!")
> fork+     }
>
> fork>     ## fork the process
> fork>     pid <- fork(fn)
>
> fork>     ## do work in the parent process
> fork>     print("Hello")
> [1] "Hello"
>
> fork>     ## wait for the child process
> fork>     waitpid(pid)
> [1] "World!"
> [1] 7063
>> dir.exists(tempdir())
> [1] FALSE
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Nov  9 02:01:08 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Nov 2017 17:01:08 -0800
Subject: [Rd] check does not check that package examples remove tempdir()
In-Reply-To: <CAFDcVCQt=+gZf-=j_bv2Zt5aNoyhT8WWOjSrLPu9GF97CqFC8w@mail.gmail.com>
References: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
 <CAFDcVCQt=+gZf-=j_bv2Zt5aNoyhT8WWOjSrLPu9GF97CqFC8w@mail.gmail.com>
Message-ID: <CAF8bMcYxiaLxig_gbgybficK7QcRYwu7N5A9ChrzK+Lr1Pw9cQ@mail.gmail.com>

I think recreating tempdir() is ok in an emergency situation, but package
code
should not be removing tempdir() - it may contain important information.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 8, 2017 at 4:55 PM, Henrik Bengtsson <henrik.bengtsson at gmail.com
> wrote:

> Related to this problem - from R-devel NEWS
> (https://cran.r-project.org/doc/manuals/r-devel/NEWS.html):
>
> * tempdir(check = TRUE) recreates the tmpdir() if it is no longer
> valid (e.g. because some other process has cleaned up the ?/tmp?
> directory).
>
> Not sure if there's a plan to make check = TRUE the default though.
>
> /Henrik
>
> On Wed, Nov 8, 2017 at 4:43 PM, William Dunlap via R-devel
> <r-devel at r-project.org> wrote:
> > I was looking at the CRAN package 'bfork-0.1.2', which exposes the Unix
> > fork() and waitpid() calls at the R code level, and noticed that the help
> > file example for bfork::fork removes R's temporary directory, the value
> of
> > tempdir().   I think it happens because the forked process shares the
> value
> > of tempdir() with the parent process and removes it when it exits.
> >
> > This seems like a serious problem - should 'check' make sure that running
> > code in a package's examples, vignettes, etc. leaves tempdir() intact?
> >
> >> dir.exists(tempdir())
> > [1] TRUE
> >> library(bfork)
> >> example(fork)
> >
> > fork>     ## create a function to be run as a separate process
> > fork>     fn <- function() {
> > fork+         Sys.sleep(4)
> > fork+         print("World!")
> > fork+     }
> >
> > fork>     ## fork the process
> > fork>     pid <- fork(fn)
> >
> > fork>     ## do work in the parent process
> > fork>     print("Hello")
> > [1] "Hello"
> >
> > fork>     ## wait for the child process
> > fork>     waitpid(pid)
> > [1] "World!"
> > [1] 7063
> >> dir.exists(tempdir())
> > [1] FALSE
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Nov  9 11:27:01 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Nov 2017 11:27:01 +0100
Subject: [Rd] New vcov(*, complete=TRUE) etc -- coef(<lm>) vs coef(<aov>)
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836705530@FHSDB4H16-2.csu.mcmaster.ca>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
 <23035.34580.701505.839202@stat.math.ethz.ch>
 <21185_1510091295_vA7LmFIC009268_23042.10775.842118.267916@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC836705530@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <23044.11637.88318.621129@stat.math.ethz.ch>

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Tue, 7 Nov 2017 22:09:03 +0000 writes:

    > Dear Martin, I think that your plan makes sense. It's too
    > bad that aov() behaved differently in this respect from
    > lm(), and thus created more work, but it's not be a bad
    > thing that the difference is now explicit and documented.

    > I expect that that other problems like this will surface,
    > particularly with contributed packages (and I know that
    > you're aware that this has already happened with the car
    > package). That is, packages that made provision for
    > aliased coefficients based on the old behaviour of coef()
    > and vcov() will now have to adapt to the new, more
    > consistent behaviour.

    > Best, John

Thank you John for the confirmation (and see below).

    >> -----Original Message-----
    >> >>>>> Martin Maechler <maechler at stat.math.ethz.ch>
    >> >>>>>     on Thu, 2 Nov 2017 21:59:00 +0100 writes:
    >> 
    >> >>>>> Fox, John <jfox at mcmaster.ca>
    >> >>>>>     on Thu, 14 Sep 2017 13:46:44 +0000 writes:
    >> 
    >> >> Dear Martin, I made three points which likely got lost
    >> >> because of the way I presented them:
    >> 
    >> >> (1) Singularity is an unusual situation and should be
    >> >> made more prominent. It typically reflects a problem with
    >> >> the data or the specification of the model. That's not to
    >> >> say that it *never* makes sense to allow singular fits
    >> >> (as in the situations you mentions).
    >> 
    >> >> I'd favour setting singular.ok=FALSE as the default, but
    >> >> in the absence of that a warning or at least a note. A
    >> >> compromise would be to have a singular.ok option() that
    >> >> would be FALSE out of the box.
    >> 
    >> >> Any changes would have to be made very carefully so as
    >> >> not to create chaos.
    >> 
    >> > I for one, am too reluctant to want to change the default
    >> > there.
    >> 
    >> >> That goes for the points below as well.
    >> 
    >> >> (2) coef() and vcov() behave inconsistently, which can be
    >> >> problematic because one often uses them together in code.
    >> 
    >> > indeed; and I had agreed on that.  As of today, in R-devel
    >> > only they now behave compatibly.  NEWS entry
    >> 
    >> >     ? The ?default? ("lm" etc) methods of vcov() have
    >> > gained new optional argument complete = TRUE which makes
    >> > the vcov() methods more consistent with the coef() methods
    >> > in the case of singular designs.  The former behavior is
    >> > now achieved by vcov(*, complete=FALSE).
    >> 
    >> 
    >> >> (3) As you noticed in your second message, lm() has a
    >> >> singular.ok argument and glm() doesn't.
    >> 
    >> > and that has been amended even earlier (a bit more than a
    >> > month ago) in R-devel svn rev 73380 with NEWS entry
    >> 
    >> >     ? glm() and glm.fit get the same singular.ok=TRUE
    >> > argument that lm() has had forever.  As a consequence, in
    >> > glm(*, method = <your_own>), user specified methods need
    >> > to accept a singular.ok argument as well.
    >> 
    >> >> I'll take a look at the code for glm() with an eye
    >> >> towards creating a patch, but I'm a bit reluctant to mess
    >> >> with the code for something as important as glm().
    >> 
    >> > and as a matter of fact you did send me +- the R code part
    >> > of that change.
    >> 
    >> > My current plan is to also add the 'complete = TRUE'
    >> > option to the "basic" coef() methods, such that you also
    >> > have consistent coef(*, complete=FALSE) and vcov(*,
    >> > complete=FALSE) behaviors.
    >> 
    >> and indeed I had added the above a bit later.
    >> 
    >> However, to my surprise, I have now found that we have a
    >> coef.aov() method -- completely undocumented which behaves *differently*:
    >> 
    >> where as the default coef() method which is called for lm(..) results gives *all*
    >> coefficients, and gives  NA  for "aliased" ones, the aov method *drops* the  NA
    >> coefficients  and has done so "forever"  (I've checked R version 1.1.1 of April 14,
    >> 2000).
    >> 
    >> vcov() on the other hand has not had a special "aov" method, but treats aov()
    >> and lm() results the same... which means that in R-devel the vcov() method for
    >> an aov() object  uses 'complete=TRUE' and gives NA rows and columns for the
    >> aliased coefficients, whereas  coef.aov()  removes all the NAs  and  gives only
    >> the
    >> "non-aliased" coefficients.   Consequently, in R-devel,
    >> vcov(<aov>) and coef(<aov>)  are *now* incoherent, whereas these two
    >> *were* coherent before the change.

    >> I propose to

    >> 1. continue the strategy to keep coef() back-compatible and
    >> 2. to *document* the "surprising" behavior of coef.aov() 
    >> 3. introduce a  vcov.aov()  with complete=FALSE  default
    >> behavior which is compatile to the coef.aov() one [where I'd
    >> also introduce the no-change  'complete=FALSE' argument].

I have now committed the above proposal to R-devel,
svn rev 73692.

This does revert  vcov(<aov>)  default behavior in R-devel to
the R <= 3.4.x behavior...
so  an effect in package-space should rather be beneficial.

Martin Maechler
ETH Zurich


From danlrobertson89 at gmail.com  Thu Nov  9 02:55:42 2017
From: danlrobertson89 at gmail.com (danlrobertson89 at gmail.com)
Date: Thu, 9 Nov 2017 01:55:42 +0000
Subject: [Rd] check does not check that package examples remove tempdir()
In-Reply-To: <CAF8bMcYxiaLxig_gbgybficK7QcRYwu7N5A9ChrzK+Lr1Pw9cQ@mail.gmail.com>
References: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
 <CAFDcVCQt=+gZf-=j_bv2Zt5aNoyhT8WWOjSrLPu9GF97CqFC8w@mail.gmail.com>
 <CAF8bMcYxiaLxig_gbgybficK7QcRYwu7N5A9ChrzK+Lr1Pw9cQ@mail.gmail.com>
Message-ID: <20171109015542.GA3076@tomyris>

> tempdir(). I think it happens because the forked process shares the
> value of tempdir() with the parent process and removes it when it
> exits.

This is very likely the case. Pretty much the entire library can be
summed up by bfork_fork, which is the following.

    SEXP res;
    pid_t pid;
    if((pid = fork()) == 0) {
        PROTECT(res = eval(lang1(fn), R_GlobalEnv));
        PROTECT(res = eval(lang2(install("q"), mkString("no")), R_GlobalEnv));
        UNPROTECT(2);
    }

    return ScalarInteger(pid);

I wrote this lib when I was still in school and can see several issues
with the implementation of `bfork_fork`. This issue happens because
we do not exit with _exit, but by essentially calling q("no").

Cheers,

Dan
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20171109/6a98e5e2/attachment.sig>

From lukas.stadler at oracle.com  Thu Nov  9 16:34:49 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Thu, 9 Nov 2017 16:34:49 +0100
Subject: [Rd] formatting raw vectors with names
Message-ID: <9779FEE0-79EE-493D-8599-74A103AA01B9@oracle.com>

I think there?s a bug concerning the formatting of raw vectors with names:

> structure(as.raw(1:3), .Names = c("a", "bbbb", "c"))
   a bbbb    c 
01 02 03 
> structure(1:3, .Names = c("a", "bbbb", "c"))
   a bbbb    c 
   1    2    3 

The problem is that EncodeRaw does not honor the requested width, in fact it doesn?t even get the width as a parameter.
An easy fix would be to change:

static void printNamedRawVector(Rbyte * x, int n, SEXP * names)
    PRINT_N_VECTOR(formatRaw(x, n, &w),
		   Rprintf("%s%*s", EncodeRaw(x[k], ""), R_print.gap,""))

to

static void printNamedRawVector(Rbyte * x, int n, SEXP * names)
    PRINT_N_VECTOR(formatRaw(x, n, &w),
		   Rprintf("%*s%s%*s", w - 2, "", EncodeRaw(x[k], ""), R_print.gap,""))

in printvector.c:314.

- Lukas

From pd.mes at cbs.dk  Thu Nov  9 16:49:25 2017
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 9 Nov 2017 15:49:25 +0000
Subject: [Rd] R 3.4.3 scheduled for November 30
Message-ID: <5D651A71-84E7-4183-BAE2-8AAB3282BEEC@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Thu Nov  9 18:42:42 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Nov 2017 18:42:42 +0100
Subject: [Rd] formatting raw vectors with names
In-Reply-To: <9779FEE0-79EE-493D-8599-74A103AA01B9@oracle.com>
References: <9779FEE0-79EE-493D-8599-74A103AA01B9@oracle.com>
Message-ID: <23044.37778.615463.123646@stat.math.ethz.ch>

>>>>> Lukas Stadler <lukas.stadler at oracle.com>
>>>>>     on Thu, 9 Nov 2017 16:34:49 +0100 writes:

    > I think there?s a bug concerning the formatting of raw vectors with names:
    >> structure(as.raw(1:3), .Names = c("a", "bbbb", "c"))
    > a bbbb    c 
    > 01 02 03 
    >> structure(1:3, .Names = c("a", "bbbb", "c"))
    > a bbbb    c 
    > 1    2    3 

    > The problem is that EncodeRaw does not honor the requested width, in fact it doesn?t even get the width as a parameter.
    > An easy fix would be to change:

    > static void printNamedRawVector(Rbyte * x, int n, SEXP * names)
    >    PRINT_N_VECTOR(formatRaw(x, n, &w),
    >                   Rprintf("%s%*s", EncodeRaw(x[k], ""), R_print.gap,""))

    > to

    > static void printNamedRawVector(Rbyte * x, int n, SEXP * names)
    >    PRINT_N_VECTOR(formatRaw(x, n, &w),
    >                   Rprintf("%*s%s%*s", w - 2, "", EncodeRaw(x[k], ""), R_print.gap,""))

    > in printvector.c:314.

Thank you, Lukas,

all you show and say seems very convincing to me,
notably the fix as well.

I'll deal with this, after a little testing.
If the effect is small in "package - space", it may be ported to
R-patched to become R 3.4.3  in three weeks.

Martin


From tomas.kalibera at gmail.com  Fri Nov 10 10:26:08 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 10 Nov 2017 10:26:08 +0100
Subject: [Rd] check does not check that package examples remove tempdir()
In-Reply-To: <20171109015542.GA3076@tomyris>
References: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
 <CAFDcVCQt=+gZf-=j_bv2Zt5aNoyhT8WWOjSrLPu9GF97CqFC8w@mail.gmail.com>
 <CAF8bMcYxiaLxig_gbgybficK7QcRYwu7N5A9ChrzK+Lr1Pw9cQ@mail.gmail.com>
 <20171109015542.GA3076@tomyris>
Message-ID: <a7e2d047-c983-8243-c5d4-a098422a4da1@gmail.com>


Please note there is parallel::mcparallel/mccollect in R which provides 
similar functionality, mcparallel starts a new job and mccollect allows 
to wait for it.

You are right about _exit, but there are additional issues which cannot 
be solved independently in an external package, and, such a low level 
interface cannot be used without race conditions from R anyway.

Best
Tomas

On 11/09/2017 02:55 AM, danlrobertson89 at gmail.com wrote:
>> tempdir(). I think it happens because the forked process shares the
>> value of tempdir() with the parent process and removes it when it
>> exits.
> This is very likely the case. Pretty much the entire library can be
> summed up by bfork_fork, which is the following.
>
>      SEXP res;
>      pid_t pid;
>      if((pid = fork()) == 0) {
>          PROTECT(res = eval(lang1(fn), R_GlobalEnv));
>          PROTECT(res = eval(lang2(install("q"), mkString("no")), R_GlobalEnv));
>          UNPROTECT(2);
>      }
>
>      return ScalarInteger(pid);
>
> I wrote this lib when I was still in school and can see several issues
> with the implementation of `bfork_fork`. This issue happens because
> we do not exit with _exit, but by essentially calling q("no").
>
> Cheers,
>
> Dan
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Fri Nov 10 16:19:37 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Fri, 10 Nov 2017 16:19:37 +0100
Subject: [Rd] check does not check that package examples remove tempdir()
In-Reply-To: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
References: <CAF8bMcZfc7uibFXC7Gx=qjXr4J808rKupZjf6AUhTBeV_Vu1ig@mail.gmail.com>
Message-ID: <CABFfbXsFCKnmaDgH1TiOm-8QnYei0CFS6xmTbezX7MX5R0v8Kg@mail.gmail.com>

On Thu, Nov 9, 2017 at 1:43 AM, William Dunlap via R-devel
<r-devel at r-project.org> wrote:
> I was looking at the CRAN package 'bfork-0.1.2', which exposes the Unix
> fork() and waitpid() calls at the R code level, and noticed that the help
> file example for bfork::fork removes R's temporary directory, the value of
> tempdir().   I think it happens because the forked process shares the value
> of tempdir() with the parent process and removes it when it exits.

This has come up a few times:

 - https://stat.ethz.ch/pipermail/r-devel/2017-February/073748.html
 - https://stat.ethz.ch/pipermail/r-devel/2017-April/074149.html

You may want to read up on the latter discussion.


From lille.stor at gmx.com  Sun Nov 12 17:47:37 2017
From: lille.stor at gmx.com (lille stor)
Date: Sun, 12 Nov 2017 17:47:37 +0100
Subject: [Rd] Array changing address unexpectedly
Message-ID: <trinity-72a45fb5-062c-4f24-9082-4069285db083-1510505257888@3c-app-mailcom-bs15>

Hi,

Given the following R code:

     library(pryr)

     data <- array(dim = c(5))

     for(x in 1:5)
     {
          data[x] <- as.integer(x * 2)
     }

     add = address(data) # save address of "data"

     for(x in 1:5)
     {
          data[x] <- as.integer(0)
     }

     if (add == address(data))
     {
        print("Address did not change")
     }
     else
     {
        print("Address changed")
     }

If one runs this code, message "Address changed" is printed. However, if one comments line "data[x] <- as.integer(0)" the address of "data" does not change and message "Address did not change" is printed instead. Why? The datatype of the array should not change with this line and hence no need for R to convert the array to a different type (and have the array's address changing in the process).
 
Thank you!


From dwinsemius at comcast.net  Sun Nov 12 18:02:23 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 12 Nov 2017 09:02:23 -0800
Subject: [Rd] Array changing address unexpectedly
In-Reply-To: <trinity-72a45fb5-062c-4f24-9082-4069285db083-1510505257888@3c-app-mailcom-bs15>
References: <trinity-72a45fb5-062c-4f24-9082-4069285db083-1510505257888@3c-app-mailcom-bs15>
Message-ID: <A6CB74E6-F1EF-4DA1-BACC-4C74ACCA9A7D@comcast.net>


> On Nov 12, 2017, at 8:47 AM, lille stor <lille.stor at gmx.com> wrote:
> 
> Hi,
> 
> Given the following R code:
> 
>     library(pryr)
> 
>     data <- array(dim = c(5))
> 
>     for(x in 1:5)
>     {
>          data[x] <- as.integer(x * 2)
>     }
> 
>     add = address(data) # save address of "data"
> 
>     for(x in 1:5)
>     {
>          data[x] <- as.integer(0)
>     }
> 
>     if (add == address(data))
>     {
>        print("Address did not change")
>     }
>     else
>     {
>        print("Address changed")
>     }
> 
> If one runs this code, message "Address changed" is printed. However, if one comments line "data[x] <- as.integer(0)" the address of "data" does not change and message "Address did not change" is printed instead. Why? The datatype of the array should not change with this line and hence no need for R to convert the array to a different type (and have the array's address changing in the process).

I'm guessing you didn't take note of the error message:

>     else
Error: unexpected 'else' in "    else"

It's always good practice to investigate errors. The else function needs to come immediately after the "{".

Here's a more complete test of what I take to be your question:

library(pryr)

data <- array(dim = c(5))
add = address(data)
    for(x in 1:5)
    {
         data[x] <- as.integer(x * 2)
    }
 if (add == address(data))
    {
       print("Address did not change")
    } else {
       print("Address changed")
    }


data <- array(dim = c(5))   # reset
add = address(data)
    for(x in 1:5)
    {
         data[x] <- as.integer(0)
    }

    if (add == address(data))
    {
       print("Address did not change")
    } else {
       print("Address changed")
    }

# changes in both situations.


> 
> Thank you!
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From lille.stor at gmx.com  Sun Nov 12 18:50:29 2017
From: lille.stor at gmx.com (lille stor)
Date: Sun, 12 Nov 2017 18:50:29 +0100
Subject: [Rd] Array changing address unexpectedly
In-Reply-To: <A6CB74E6-F1EF-4DA1-BACC-4C74ACCA9A7D@comcast.net>
References: <trinity-72a45fb5-062c-4f24-9082-4069285db083-1510505257888@3c-app-mailcom-bs15>
 <A6CB74E6-F1EF-4DA1-BACC-4C74ACCA9A7D@comcast.net>
Message-ID: <trinity-ef1803d5-8973-4874-b9c8-cb8e5ab8d03e-1510509029462@3c-app-mailcom-bs15>

Hi David,
?
Thanks for the correction concerning the "else" issue.
?
Taking your code and removing some lines (to increase readability):
?

library(pryr)
?
data <- array(dim = c(5))
for(x in 1:5)
{
?? data[x] <- as.integer(x * 2)
}
?
#print(data)
?
add = address(data)
for(x in 1:5)
{
?? data[x] <- as.integer(0)
}
?
if (add == address(data))
{
print("Address did not change")
} else {
print("Address changed")
}
?
?
If one runs this code everything works as expected, i.e. message "Address did not change" is printed. However, if one uncomments line "#print(data)", message "Address is changed" is printed instead. Any idea why this happens as it is a bit counter-intuitive? Is it something to do with some kind of lazy-evaluation mechanism R has that makes the array to be filled-up only when needed (in this case, when printing it) thus changing the array's address?
?
Thank you once more!
?


?

Sent:?Sunday, November 12, 2017 at 6:02 PM
From:?"David Winsemius" <dwinsemius at comcast.net>
To:?"lille stor" <lille.stor at gmx.com>
Cc:?r-devel at r-project.org
Subject:?Re: [Rd] Array changing address unexpectedly
> On Nov 12, 2017, at 8:47 AM, lille stor <lille.stor at gmx.com> wrote:
>
> Hi,
>
> Given the following R code:
>
> library(pryr)
>
> data <- array(dim = c(5))
>
> for(x in 1:5)
> {
> data[x] <- as.integer(x * 2)
> }
>
> add = address(data) # save address of "data"
>
> for(x in 1:5)
> {
> data[x] <- as.integer(0)
> }
>
> if (add == address(data))
> {
> print("Address did not change")
> }
> else
> {
> print("Address changed")
> }
>
> If one runs this code, message "Address changed" is printed. However, if one comments line "data[x] <- as.integer(0)" the address of "data" does not change and message "Address did not change" is printed instead. Why? The datatype of the array should not change with this line and hence no need for R to convert the array to a different type (and have the array's address changing in the process).

I'm guessing you didn't take note of the error message:

> else
Error: unexpected 'else' in " else"

It's always good practice to investigate errors. The else function needs to come immediately after the "{".

Here's a more complete test of what I take to be your question:

library(pryr)

data <- array(dim = c(5))
add = address(data)
for(x in 1:5)
{
data[x] <- as.integer(x * 2)
}
if (add == address(data))
{
print("Address did not change")
} else {
print("Address changed")
}


data <- array(dim = c(5)) # reset
add = address(data)
for(x in 1:5)
{
data[x] <- as.integer(0)
}

if (add == address(data))
{
print("Address did not change")
} else {
print("Address changed")
}

# changes in both situations.


>
> Thank you!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




?


From luke-tierney at uiowa.edu  Sun Nov 12 20:38:43 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 12 Nov 2017 13:38:43 -0600 (CST)
Subject: [Rd] Array changing address unexpectedly
In-Reply-To: <trinity-ef1803d5-8973-4874-b9c8-cb8e5ab8d03e-1510509029462@3c-app-mailcom-bs15>
References: <trinity-72a45fb5-062c-4f24-9082-4069285db083-1510505257888@3c-app-mailcom-bs15>
 <A6CB74E6-F1EF-4DA1-BACC-4C74ACCA9A7D@comcast.net>
 <trinity-ef1803d5-8973-4874-b9c8-cb8e5ab8d03e-1510509029462@3c-app-mailcom-bs15>
Message-ID: <alpine.OSX.2.20.1711121326510.53256@lukes-air>

A simpler version with annotation:

library(pryr)

data <- 1:5          # new allocation, referenced from one variable

add <- address(data)

data[1] <- 6L        # only one reference; don't need to duplicate

add == address(data) # TRUE

print(data)          # inside the print call the local variable also references
                      # the object, so there are two references

data[1] <- 7L        # there have been two references to the object, so need
                      # to duplicate

add == address(data) # FALSE

R objects are supposed to be immutable, so conceptually
assignments create a new object. If R is sure it is safe to do
so, it will avoid making a copy and re-use the original
object. In the first assignment there is only one reference to
the object, the variable data, and it is safe to re-use the
object, so the address of the new value of `data` is the same as
the address of the old value. It would not be safe to do this if
the assignment happened inside print(), since there are then two
references -- the original variable and the local variable for
the argument. R currently doesn't have enough information to know
that there is only one reference after the call to print()
returns, so it has to be safe and make a copy, and the new value
has a different address than the old one. R may be able to be
less conservative in the future, but for now it cannot.

[As an exercise you can try to work out why the calls to
address() don't play a role in this.]

As a rule you shouldn't need to worry about addresses, and R might
make changes in the future that would: cause the address in this
version of the example to change on the first assignments; cause the
address on the second assignment to not change; cause the information
provided by pryr to be inaccurate or misleading; result in the use of
a tool like pryr::address to change the internal structure of the
object.

Best,

luke

On Sun, 12 Nov 2017, lille stor wrote:

> Hi David,
> 
> Thanks for the correction concerning the "else" issue.
> 
> Taking your code and removing some lines (to increase readability):
> 
>
> library(pryr)
> 
> data <- array(dim = c(5))
> for(x in 1:5)
> {
> ?? data[x] <- as.integer(x * 2)
> }
> 
> #print(data)
> 
> add = address(data)
> for(x in 1:5)
> {
> ?? data[x] <- as.integer(0)
> }
> 
> if (add == address(data))
> {
> print("Address did not change")
> } else {
> print("Address changed")
> }
>
> 
> If one runs this code everything works as expected, i.e. message "Address did not change" is printed. However, if one uncomments line "#print(data)", message "Address is changed" is printed instead. Any idea why this happens as it is a bit counter-intuitive? Is it something to do with some kind of lazy-evaluation mechanism R has that makes the array to be filled-up only when needed (in this case, when printing it) thus changing the array's address?
> 
> Thank you once more!
> 
>
>
> 
>
> Sent:?Sunday, November 12, 2017 at 6:02 PM
> From:?"David Winsemius" <dwinsemius at comcast.net>
> To:?"lille stor" <lille.stor at gmx.com>
> Cc:?r-devel at r-project.org
> Subject:?Re: [Rd] Array changing address unexpectedly
>> On Nov 12, 2017, at 8:47 AM, lille stor <lille.stor at gmx.com> wrote:
>>
>> Hi,
>>
>> Given the following R code:
>>
>> library(pryr)
>>
>> data <- array(dim = c(5))
>>
>> for(x in 1:5)
>> {
>> data[x] <- as.integer(x * 2)
>> }
>>
>> add = address(data) # save address of "data"
>>
>> for(x in 1:5)
>> {
>> data[x] <- as.integer(0)
>> }
>>
>> if (add == address(data))
>> {
>> print("Address did not change")
>> }
>> else
>> {
>> print("Address changed")
>> }
>>
>> If one runs this code, message "Address changed" is printed. However, if one comments line "data[x] <- as.integer(0)" the address of "data" does not change and message "Address did not change" is printed instead. Why? The datatype of the array should not change with this line and hence no need for R to convert the array to a different type (and have the array's address changing in the process).
>
> I'm guessing you didn't take note of the error message:
>
>> else
> Error: unexpected 'else' in " else"
>
> It's always good practice to investigate errors. The else function needs to come immediately after the "{".
>
> Here's a more complete test of what I take to be your question:
>
> library(pryr)
>
> data <- array(dim = c(5))
> add = address(data)
> for(x in 1:5)
> {
> data[x] <- as.integer(x * 2)
> }
> if (add == address(data))
> {
> print("Address did not change")
> } else {
> print("Address changed")
> }
>
>
> data <- array(dim = c(5)) # reset
> add = address(data)
> for(x in 1:5)
> {
> data[x] <- as.integer(0)
> }
>
> if (add == address(data))
> {
> print("Address did not change")
> } else {
> print("Address changed")
> }
>
> # changes in both situations.
>
>
>>
>> Thank you!
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
>
>
>
>
> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From pperry at stern.nyu.edu  Sun Nov 12 21:34:21 2017
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Sun, 12 Nov 2017 15:34:21 -0500
Subject: [Rd] special latin1 do not print as glyphs in current devel on
 windows
In-Reply-To: <59BA6C55.9020405@stern.nyu.edu>
References: <CANu2KkOOSz1yRy0iszE47uTniAms=_LgBOW8ZbEJpCCfhJyUuA@mail.gmail.com>
 <59A2E7FC.9090303@stern.nyu.edu>
 <ff34748c-cac7-a079-460d-601e150e3a6d@gmail.com>
 <59BA6C55.9020405@stern.nyu.edu>
Message-ID: <5A08B04D.2030201@stern.nyu.edu>

Just following up on this since the associated bug report just got 
closed (https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17329 ) 
because my original bug report was incomplete, and did not include 
sessionInfo() or LC_CTYPE.

Admittedly, my original bug report was a little confused. I have since 
gained a better understanding of the issue. I want to confirm that this 
(a) is a real bug in base, R, not RStudio (b) provide more context. It 
looks like the real issue is that R marks native strings as "latin1" 
when the declared character locale is Windows-1252. This causes problems 
when converting to UTF-8. See Daniel Possenriede's email below for much 
more detail, including his sessionInfo() and a reproducible example .

The development version of the `stringi` package and the CRAN version of 
the `utf8` package both have workarounds for this bug. (See, e.g. 
https://github.com/gagolews/stringi/issues/287 and the links to the 
related issues).


Patrick

> Patrick Perry <mailto:pperry at stern.nyu.edu>
> September 14, 2017 at 7:47 AM
> This particular issue has a simple fix. Currently, the 
> "R_check_locale" function includes the following code starting at line 
> 244 in src/main/platform.c:
>
> #ifdef Win32
>     {
>     char *ctype = setlocale(LC_CTYPE, NULL), *p;
>     p = strrchr(ctype, '.');
>     if (p && isdigit(p[1])) localeCP = atoi(p+1); else localeCP = 0;
>     /* Not 100% correct, but CP1252 is a superset */
>     known_to_be_latin1 = latin1locale = (localeCP == 1252);
>     }
> #endif
>
> The "1252" should be "28591"; see 
> https://msdn.microsoft.com/en-us/library/windows/desktop/dd317756(v=vs.85).aspx 
> .
>
>
> Daniel Possenriede <mailto:possenriede at gmail.com>
> September 14, 2017 at 3:40 AM
> This is a follow-up on my initial posts regarding character encodings 
> on Windows 
> (https://stat.ethz.ch/pipermail/r-devel/2017-August/074728.html) and 
> Patrick Perry's reply 
> (https://stat.ethz.ch/pipermail/r-devel/2017-August/074830.html) in 
> particular (thank you for the links and the bug report!). My initial 
> posts were quite chaotic (and partly wrong), so I am trying to clear 
> things up a bit.
>
> Actually, the title of my original message "special latin1 
> [characters] do not print as glyphs in current devel on windows" is 
> already wrong, because the problem exists with characters with CP1252 
> encoding in the 80-9F (hex) range. Like Brian Ripley rightfully 
> pointed out, latin1 != CP1252. The characters in the 80-9F code point 
> range are not even part of ISO/IEC 8859-1 a.k.a. latin1, see for 
> example https://en.wikipedia.org/wiki/Windows-1252. R treats them as 
> if they were, however, and that is exactly the problem, IMHO.
>
> Let me show you what I mean. (All output from R 3.5 r73238, see 
> sessionInfo at the end)
>
> > Sys.getlocale("LC_CTYPE")
> [1] "German_Germany.1252"
> > x <- c("?", "?", "?", "?")
> > sapply(x, charToRaw)
> \u0080 \u009e \u009a  ?
> 80 9e 9a fc
>
> "?", "?", "?" serve as examples in the 80-9F range of CP1252. I also 
> show the "?" just as an example of a non-ASCII character outside that 
> range (and because Patrick Perry used it in his bug report which might 
> be a (slightly) different problem, but I will get to that later.)
>
> > print(x)
> [1] "\u0080" "\u009e" "\u009a" "?"
>
> "?", "?", and "?" are printed as (incorrect) unicode escapes. "?" for 
> example should be \u20ac not \u0080.
> (In R 3.4.1, print(x) shows the glyphs and not the unicode escapes. 
> Apparently, as of v3.5, print() calls enc2utf8() (or its equivalent in 
> C (translateCharUTF8?))?)
>
> > print("\u20ac")
> [1] "?"
>
> The characters in x are marked as "latin1".
>
> > Encoding(x)
> [1] "latin1" "latin1" "latin1" "latin1"
>
> Looking at the CP1252 table (e.g. link above), we see that this is 
> incorrect for "?", "?", and "?", which simply do not exist in latin1.
>
> As per the documentation, "enc2utf8 convert[s] elements of character 
> vectors to [...] UTF-8 [...], taking any marked encoding into 
> account." Since the marked encoding is wrong, so is the output of 
> enc2utf8().
>
> > enc2utf8(x)
> [1] "\u0080" "\u009e" "\u009a" "?"
>
> Now, when we set the encoding to "unknown" everything works fine.
>
> > x_un <- x
> > Encoding(x_un) <- "unknown"
> > print(x_un)
> [1] "?" "?" "?" "?"
> > (x_un2utf8 <- enc2utf8(x_un))
> [1] "?" "?" "?" "?"
>
> Long story short: The characters in the 80 to 9F range should not be 
> marked as "latin1" on CP1252 locales, IMHO.
>
> As a side-note: the output of localeToCharset() is also problematic, 
> since ISO8859-1 != CP1252.
>
> > localeToCharset()
> [1] "ISO8859-1"
>
> Finally on to Patrick Perry's bug report 
> (https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17329): 'On 
> Windows, enc2utf8("?") yields "|".'
>
> Unfortunately, I cannot reproduce this with the CP1252 locale, as can 
> be seen above. Probably, because the bug applies to the C locale 
> (sorry if this is somewhere apparent in the bug report and I missed it).
>
> > Sys.setlocale("LC_CTYPE", "C")
> [1] "C"
> > enc2utf8("?")
> [1] "|"
> > charToRaw("?")
> [1] fc
> > Encoding("?")
> [1] "unknown"
>
> This does not seem to be related to the marked encoding of the string, 
> so it seems to me that this is a different problem than the one above.
>
> Any advice on how to proceed further would be highly appreciated.
>
> Thanks!
> Daniel
>
> > sessionInfo()
> R Under development (unstable) (2017-09-11 r73238)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 14393)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=C
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0
>
> Patrick Perry <mailto:pperry at stern.nyu.edu>
> August 27, 2017 at 11:40 AM
> Regarding the Windows character encoding issues Daniel Possenriede 
> posted about earlier this month, where non-Latin-1 strings were 
> getting marked as such 
> (https://stat.ethz.ch/pipermail/r-devel/2017-August/074731.html ):
>
> The issue is that on Windows, when the character locale is 
> Windows-1252, R marks some (possibly all) native non-ASCII strings as 
> "latin1". I posted a related bug report: 
> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17329 . The bug 
> report also includes a link to a fix for a related issue: converting 
> strings from Windows native to UTF-8.
>
> There is a work-around for this bug in the current development version 
> of the 'corpus' package (not on CRAN yet). See 
> https://github.com/patperry/r-corpus/issues/5 . I have tested this on 
> a Windows-1252 install of R, but I have not tested it on a Windows 
> install in another locale. It'd be great if someone with such an 
> install would test the fix and report back, either here or on the 
> github issue.
>
>
> Patrick


	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Mon Nov 13 21:33:58 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 13 Nov 2017 21:33:58 +0100
Subject: [Rd] Where are dggsvd3 and dggsvp3?
Message-ID: <6DA2E87C-B79D-4930-85A6-4711BACDF2C9@xs4all.nl>


The README of the module Lapack in the R sources for R 3.4.2 notes that
the Lapack routines dggsvd3 and dggsvp3 were added in R 3.3.0.
I'm referring to <..>/R-3.4.2/src/modules/lapack/{README,dlapack.f}.

However searching for these two routines in dlapack.f gives no results.

Where are they in the R sources?

Berend Hasselman


From Chris.Brien at unisa.edu.au  Tue Nov 14 12:37:37 2017
From: Chris.Brien at unisa.edu.au (Chris Brien)
Date: Tue, 14 Nov 2017 11:37:37 +0000
Subject: [Rd] Possible bug(s) causing ggplot2 and XLConnect to crash recent
 builds of r-devel
Message-ID: <f6e4f25bcb694fe6a490088ffeaa55d4@ITUPW-EXMBOX3B.UniNet.unisa.edu.au>

The following R code causes R to crashes under recent r-devel builds of R: 

library(ggplot2)
RCBD.lay <- data.frame(Blocks = factor(rep(1:5, each = 6)), 
                       Units = factor(rep(1:6, times = 5)),
                       Treatments = factor(rep(1:6, times = 5)))
ggplot(data = RCBD.lay, aes(x = Units, y = Blocks, label = Treatments)) +
  geom_text(aes(colour = Treatments))

I have installed and am running R on a Windows 10 machine with Rtools34.exe installed. I am using RStudio version 1.1.383

This bug happens with combined Windows 32/64 bit binary builds of the 2017-11-11 r73707 and 2017-11-14 r73724 development snapshot of R. It does not occur under the build of the 2017-06-27 r72859 development snapshot of R.

I installed the latest build with an empty R library tree " D:/Analyses/R LibDevel". 

> .libPaths()
[1] "D:/Analyses/R LibDevel"                         
[2] "C:/Program Files/StatSoft/R/R-devel.724/library"

I installed package ggplot2 and its dependencies from CRAN using RStudio. As a result the following 20 packages were the only packages installed in the previously empty library tree:

"colorspace","dichromat","digest","ggplot2","gtable","labeling","lazyeval",
  "magrittr","munsell","plyr","R6","RColorBrewer","Rcpp","reshape2","rlang","scales",
  "stringi","stringr","tibble","viridisLite"

I then executed the above code in the Console window of Rstudio (running 64 bit R) and received the message "R Session aborted" with the information that "R encountered a fatal error".

I also started the RGui for the 64-bit version and entered the same code into the console. The error message displayed in a dialog box was "R Windows GUI front-end has stopped working". Closing the dialog box cause RGui to close.

I had a similar experience with the package XLConnect.

Having used remove.packages to remove the ggplot2 and associated packages from the library, I installed XLConnect and it dependencies from CRAN from RStudio. Now the packages installed in "D:/Analyses/R LibDevel" were: "rJava", "XLConnect", "XLConnectJars".

In this case executing library(XLConnect) cause the same response - "R Session aborted" with the information that "R encountered a fatal error".

These are not packages that I maintain. However, I have packages (imageData and dae) that depend on ggplot2 and it seems that this bug is preventing me from compiling the packages under the most recent builds, although I can build the packages under the build of the 2017-06-27 r72859 development snapshot of R.

Regards, 

  Chris Brien

Adjunct Senior Lecturer in Statistics
-----
Phenomics and Bioinformatics Research Centre
University of South Australia
GPO Box 2471
ADELAIDE  5001  South Australia
Phone:? +61 8 8302 5535   Fax:? +61 8 8302 5785
Email:?? Chris.Brien at unisa.edu.au 
WEB page:? <http://people.unisa.edu.au/Chris.Brien> 
CRICOS No 00121B 


From etiennesanchez2 at gmail.com  Tue Nov 14 19:33:07 2017
From: etiennesanchez2 at gmail.com (Etienne Sanchez)
Date: Tue, 14 Nov 2017 19:33:07 +0100
Subject: [Rd] str() not displaying names
Message-ID: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>

In some cases, str() does not print the "names" attribute of the object:

u <- structure(c(5, 6), names = c("a", "b"), color = "blue")
str(u)
#  atomic [1:2] 5 6
#  - attr(*, "color")= chr "blue"

Is it a bug or a design choice?

Originally asked here:
https://stackoverflow.com/q/47185756/6656269


From h.wickham at gmail.com  Mon Nov 20 19:50:24 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Nov 2017 12:50:24 -0600
Subject: [Rd] Small performance bug in [.Date
Message-ID: <CABdHhvH6iWobpPDdpOWc0oqDASNJbTwgRQp9RaS-Jk_JNDE4dg@mail.gmail.com>

Hi all,

I think there's an unnecessary line in [.Date which has a considerable
impact on performance when subsetting large dates:

x <- Sys.Date() + 1:1e6

microbenchmark::microbenchmark(x[1])
#> Unit: microseconds
#>  expr     min       lq     mean   median       uq      max neval
#>  x[1] 920.651 1039.346 3624.833 2294.404 3786.881 41176.38   100

`[.Date` <- function(x, ..., drop = TRUE) {
    cl <- oldClass(x)
    # class(x) <- NULL
    val <- NextMethod("[")
    class(val) <- cl
    val
}
microbenchmark::microbenchmark(x[1])
#> Unit: microseconds
#>  expr   min     lq     mean median    uq      max neval
#>  x[1] 2.738 3.0225 28.40893  3.269 3.513 2470.068   100

Setting the class of x to NULL is problematic because it forces a
copy, and I'm pretty sure it's unnecessary as NextMethod() does not
consult the class of x, but instead uses .Class.

Hadley

-- 
http://hadley.nz


From pauljohn32 at gmail.com  Mon Nov 20 21:59:26 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 20 Nov 2017 14:59:26 -0600
Subject: [Rd] package check fail on Windows-release only?
Message-ID: <CAErODj_g2m95Nx1WD=YsApCrzEo_Q1cHxQSOuKYhO9-DAFFOfg@mail.gmail.com>

I mistakenly left a write in "/tmp" in the rockchalk package (version
1.8.109) that I uploaded last Friday. Kurt H wrote and asked me to fix
today.

While uploading a new one, I became aware of a problem I had not seen.
The version I uploaded last Friday, 1.8.109, has OK status on all
platforms except r-release-windows-ix86+x86_64. I get OK on
oldrel-windows and also on devel-windows.

https://cran.r-project.org/web/checks/check_results_rockchalk.html

Can you please advise me on what to do? I don't understand, well,
anything about this :(

The error says:

* installing *source* package 'rockchalk' ...
** package 'rockchalk' successfully unpacked and MD5 sums checked
** R
** data
** inst
** preparing package for lazy loading
Warning: S3 methods 'print.sparseSummary', 'print.diagSummary',
'c.abIndex', 'c.sparseVector', 'as.array.Matrix',
'as.array.sparseVector', 'as.matrix.Matrix', 'as.matrix.sparseVector',
'as.vector.Matrix', 'as.vector.sparseVector' were declared in
NAMESPACE but not found
Error in namespaceExport(ns, exports) :
  undefined exports: %&%, Cholesky, .SuiteSparse_version, Diagonal,
.symDiagonal, .sparseDiagonal, .trDiagonal, Hilbert, KhatriRao,
Matrix, MatrixClass, spMatrix, sparseMatrix, rsparsematrix, Schur,
abIseq, abIseq1, rep2abI, band, bandSparse, bdiag, .bdiag,
c.sparseVector, condest, onenormest, .asmatrix, .dsy2mat, .dsy2dsp,
.dxC2mat, .T2Cmat, ..2dge, .dense2sy, .C2nC, .nC2d, .nC2l, .diag.dsC,
.solve.dgC.chol, .solve.dgC.qr, .solve.dgC.lu, diagN2U, diagU2N,
.diagU2N, .diag2tT, .diag2sT, .diag2mat, drop0, expand, expm, facmul,
fac2sparse, fac2Sparse, forceSymmetric, T2graph, graph2T,
anyDuplicatedT, uniqTsparse, isTriangular, isDiagonal, isLDL,
is.null.DN, invPerm, lu, nearPD, nnzero, formatSpMatrix,
formatSparseM, .formatSparseSimple, printSpMatrix, printSpMatrix2,
qrR, rankMatrix, readHB, readMM, sparse.model.matrix, sparseVector,
symmpart, skewpart, tril, triu, updown, pack, unpack,
.updateCHMfactor, .validateCsparse, writeMM, cBind, rBind
ERROR: lazy loading failed for package 'rockchalk'
* removing 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'
* restoring previous 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From maechler at stat.math.ethz.ch  Tue Nov 21 10:15:39 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Nov 2017 10:15:39 +0100
Subject: [Rd] package check fail on Windows-release only?
In-Reply-To: <CAErODj_g2m95Nx1WD=YsApCrzEo_Q1cHxQSOuKYhO9-DAFFOfg@mail.gmail.com>
References: <CAErODj_g2m95Nx1WD=YsApCrzEo_Q1cHxQSOuKYhO9-DAFFOfg@mail.gmail.com>
Message-ID: <23059.61115.505878.79893@stat.math.ethz.ch>

>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Mon, 20 Nov 2017 14:59:26 -0600 writes:

    > I mistakenly left a write in "/tmp" in the rockchalk package (version
    > 1.8.109) that I uploaded last Friday. Kurt H wrote and asked me to fix
    > today.

    > While uploading a new one, I became aware of a problem I had not seen.
    > The version I uploaded last Friday, 1.8.109, has OK status on all
    > platforms except r-release-windows-ix86+x86_64. I get OK on
    > oldrel-windows and also on devel-windows.

    > https://cran.r-project.org/web/checks/check_results_rockchalk.html

    > Can you please advise me on what to do? I don't understand, well,
    > anything about this :(

Dear Paul,

something like this really should have been posted to the R-package-devel
list, not to R-devel; as it is here now, I'm crossposting to there for one msg
Please remove R-devel at .. from CC  if/when replying and keep it there.

    > The error says:

    > * installing *source* package 'rockchalk' ...
    > ** package 'rockchalk' successfully unpacked and MD5 sums checked
    > ** R
    > ** data
    > ** inst
    > ** preparing package for lazy loading
    > Warning: S3 methods 'print.sparseSummary', 'print.diagSummary',
    > 'c.abIndex', 'c.sparseVector', 'as.array.Matrix',
    > 'as.array.sparseVector', 'as.matrix.Matrix', 'as.matrix.sparseVector',
    > 'as.vector.Matrix', 'as.vector.sparseVector' were declared in
    > NAMESPACE but not found
    > Error in namespaceExport(ns, exports) :
    > undefined exports: %&%, Cholesky, .SuiteSparse_version, Diagonal,
    > .symDiagonal, .sparseDiagonal, .trDiagonal, Hilbert, KhatriRao,
    > Matrix, MatrixClass, spMatrix, sparseMatrix, rsparsematrix, Schur,
    > abIseq, abIseq1, rep2abI, band, bandSparse, bdiag, .bdiag,
    > c.sparseVector, condest, onenormest, .asmatrix, .dsy2mat, .dsy2dsp,
    > .dxC2mat, .T2Cmat, ..2dge, .dense2sy, .C2nC, .nC2d, .nC2l, .diag.dsC,
    > .solve.dgC.chol, .solve.dgC.qr, .solve.dgC.lu, diagN2U, diagU2N,
    > .diagU2N, .diag2tT, .diag2sT, .diag2mat, drop0, expand, expm, facmul,
    > fac2sparse, fac2Sparse, forceSymmetric, T2graph, graph2T,
    > anyDuplicatedT, uniqTsparse, isTriangular, isDiagonal, isLDL,
    > is.null.DN, invPerm, lu, nearPD, nnzero, formatSpMatrix,
    > formatSparseM, .formatSparseSimple, printSpMatrix, printSpMatrix2,
    > qrR, rankMatrix, readHB, readMM, sparse.model.matrix, sparseVector,
    > symmpart, skewpart, tril, triu, updown, pack, unpack,
    > .updateCHMfactor, .validateCsparse, writeMM, cBind, rBind
    > ERROR: lazy loading failed for package 'rockchalk'
    > * removing 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'
    > * restoring previous 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'

all of these these are names of  Matrix-package objects..
and I know that yesterday Matrix package version changes (1.1-11
--> 1.1-12) happened on CRAN and hence in servers which update..

So it *could* be this is all just a temporary problem aka "race
situation" , where the check of your package very unhappily
happened exactly at a moment where the new Matrix package was
already there, but not quite ....
seems quite improbable, but then your problem seems "rare"..

Martin


From maechler at stat.math.ethz.ch  Tue Nov 21 11:39:00 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Nov 2017 11:39:00 +0100
Subject: [Rd] Small performance bug in [.Date
In-Reply-To: <CABdHhvH6iWobpPDdpOWc0oqDASNJbTwgRQp9RaS-Jk_JNDE4dg@mail.gmail.com>
References: <CABdHhvH6iWobpPDdpOWc0oqDASNJbTwgRQp9RaS-Jk_JNDE4dg@mail.gmail.com>
Message-ID: <23060.580.899992.677761@stat.math.ethz.ch>

>>>>> Hadley Wickham <h.wickham at gmail.com>
>>>>>     on Mon, 20 Nov 2017 12:50:24 -0600 writes:

    > Hi all,
    > I think there's an unnecessary line in [.Date which has a considerable
    > impact on performance when subsetting large dates:

    > x <- Sys.Date() + 1:1e6

    > microbenchmark::microbenchmark(x[1])
    > #> Unit: microseconds
    > #>  expr     min       lq     mean   median       uq      max neval
    > #>  x[1] 920.651 1039.346 3624.833 2294.404 3786.881 41176.38   100

    > `[.Date` <- function(x, ..., drop = TRUE) {
    > cl <- oldClass(x)
    > # class(x) <- NULL
    > val <- NextMethod("[")
    > class(val) <- cl
    > val
    > }
    > microbenchmark::microbenchmark(x[1])
    > #> Unit: microseconds
    > #>  expr   min     lq     mean median    uq      max neval
    > #>  x[1] 2.738 3.0225 28.40893  3.269 3.513 2470.068   100

    > Setting the class of x to NULL is problematic because it forces a
    > copy, and I'm pretty sure it's unnecessary as NextMethod() does not
    > consult the class of x, but instead uses .Class.

Yes, at least so it looks in  src/main/objects.c

Also, we had a very similar change a while ago :
------------------------------------------------------------------------
r65926 | luke | 2014-06-12 15:54:38 +0200 (Thu, 12. Jun 2014) | 2 Zeilen
Ge?nderte Pfade:
   M src/library/base/R/datetime.R

Commented out class(x) <- NULL in [.POSIXct and [[.POSICct.
------------------------------------------------------------------------

and we never seemed to have followed up in a systematic manner
finding other places where this happens and could be
eliminated.  I see about half a dozen examples in
base/R/dates.R  alone and am trying to find more in other places.

[maybe this used to be necessary for very early different
 versions of NextMethod() which were not yet optimized using  .Class etc]

Thank you very much,
Hadley!

Martin


From mbonsch at posteo.de  Tue Nov 21 07:36:36 2017
From: mbonsch at posteo.de (mbonsch at posteo.de)
Date: Tue, 21 Nov 2017 07:36:36 +0100
Subject: [Rd] Truncating vectors by reference in C-backend
Message-ID: <33653f9fc65218be8f063662fdd59fec@posteo.de>

Dear all,

I want to create a function shrinkVector(x) that takes x and truncates 
it to the first element without copy.
With SETLENGTH and SET_TRUELENGTH, I can achieve that.  You can find a 
reproducible example below.
But the memory that was freed is not available for other objects 
afterwards, except if x is a list (VECSXP). Any suggestions?

library(inline)
## define the shrinking function
shrinkVector <- cfunction(signature(x = "ANY"),
                           body = paste0("SETLENGTH(x, 1);",
                                                   "SET_TRUELENGTH(x, 
1);",
                                                   
"return(R_NilValue);"))
## create a large vector that only fits into memory once
x <- 1 : 2e9
## shrink it
shrinkVector(x)
## shrinking seems to have worked
print(length(x) == 1)
# [1] TRUE
print(object.size(x))
# 48 bytes
## but I can't reuse the memory for a large x2:
x2 <- 1 : 2e8
# Error: cannot allocate vector of size 762.9 Mb
## if I remove x, it works
rm(x)
gc()
x2 <- 1 : 2e8

Thank you very much for your help.

Kind regards,
Markus Bonsch


From luke-tierney at uiowa.edu  Tue Nov 21 13:40:31 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 21 Nov 2017 06:40:31 -0600 (CST)
Subject: [Rd] Truncating vectors by reference in C-backend
In-Reply-To: <33653f9fc65218be8f063662fdd59fec@posteo.de>
References: <33653f9fc65218be8f063662fdd59fec@posteo.de>
Message-ID: <alpine.DEB.2.20.1711210633190.2642@luke-Latitude>

DO NOT DO THIS!!! SETLENGTH and SET_TRUELENGTH are NOT part of the API
and are for internal use only.

Tho proper way to do this is to copy the data you want into a smaller
vector and allow the larger one to be garbage collected.

[VECSXPs are like all other vectors in that they are contigously
allocated by malloc, and there is no mprtable way to return part
a memory region allocated by malloc back to malloc].

There is experimental INTERNAL support for growable vectors that is
managed with INTERNALLY with TRUELENGTH and a bit setting, but this is
NOT, at leat not yet, intended for use by packages. The ALTREP
framework that should be available in the next release might allow
something like this to be done, but care is needed to make sure R's
copying semantics are adhered to.

Best,

luke

On Tue, 21 Nov 2017, mbonsch at posteo.de wrote:

> Dear all,
>
> I want to create a function shrinkVector(x) that takes x and truncates it 
> to the first element without copy.
> With SETLENGTH and SET_TRUELENGTH, I can achieve that.  You can find a 
> reproducible example below.
> But the memory that was freed is not available for other objects 
> afterwards, except if x is a list (VECSXP). Any suggestions?
>
> library(inline)
> ## define the shrinking function
> shrinkVector <- cfunction(signature(x = "ANY"),
>                          body = paste0("SETLENGTH(x, 1);",
>                                                  "SET_TRUELENGTH(x, 1);",
>                                                  "return(R_NilValue);"))
> ## create a large vector that only fits into memory once
> x <- 1 : 2e9
> ## shrink it
> shrinkVector(x)
> ## shrinking seems to have worked
> print(length(x) == 1)
> # [1] TRUE
> print(object.size(x))
> # 48 bytes
> ## but I can't reuse the memory for a large x2:
> x2 <- 1 : 2e8
> # Error: cannot allocate vector of size 762.9 Mb
> ## if I remove x, it works
> rm(x)
> gc()
> x2 <- 1 : 2e8
>
> Thank you very much for your help.
>
> Kind regards,
> Markus Bonsch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ligges at statistik.tu-dortmund.de  Tue Nov 21 13:49:22 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Nov 2017 13:49:22 +0100
Subject: [Rd] [R-pkg-devel] package check fail on Windows-release only?
In-Reply-To: <23059.61115.505878.79893@stat.math.ethz.ch>
References: <CAErODj_g2m95Nx1WD=YsApCrzEo_Q1cHxQSOuKYhO9-DAFFOfg@mail.gmail.com>
 <23059.61115.505878.79893@stat.math.ethz.ch>
Message-ID: <4ee45c6b-6a08-991b-01d9-056c43184ef0@statistik.tu-dortmund.de>



On 21.11.2017 10:15, Martin Maechler wrote:
>>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>>      on Mon, 20 Nov 2017 14:59:26 -0600 writes:
> 
>      > I mistakenly left a write in "/tmp" in the rockchalk package (version
>      > 1.8.109) that I uploaded last Friday. Kurt H wrote and asked me to fix
>      > today.
> 
>      > While uploading a new one, I became aware of a problem I had not seen.
>      > The version I uploaded last Friday, 1.8.109, has OK status on all
>      > platforms except r-release-windows-ix86+x86_64. I get OK on
>      > oldrel-windows and also on devel-windows.
> 
>      > https://cran.r-project.org/web/checks/check_results_rockchalk.html
> 
>      > Can you please advise me on what to do? I don't understand, well,
>      > anything about this :(
> 
> Dear Paul,
> 
> something like this really should have been posted to the R-package-devel
> list, not to R-devel; as it is here now, I'm crossposting to there for one msg
> Please remove R-devel at .. from CC  if/when replying and keep it there.
> 
>      > The error says:
> 
>      > * installing *source* package 'rockchalk' ...
>      > ** package 'rockchalk' successfully unpacked and MD5 sums checked
>      > ** R
>      > ** data
>      > ** inst
>      > ** preparing package for lazy loading
>      > Warning: S3 methods 'print.sparseSummary', 'print.diagSummary',
>      > 'c.abIndex', 'c.sparseVector', 'as.array.Matrix',
>      > 'as.array.sparseVector', 'as.matrix.Matrix', 'as.matrix.sparseVector',
>      > 'as.vector.Matrix', 'as.vector.sparseVector' were declared in
>      > NAMESPACE but not found
>      > Error in namespaceExport(ns, exports) :
>      > undefined exports: %&%, Cholesky, .SuiteSparse_version, Diagonal,
>      > .symDiagonal, .sparseDiagonal, .trDiagonal, Hilbert, KhatriRao,
>      > Matrix, MatrixClass, spMatrix, sparseMatrix, rsparsematrix, Schur,
>      > abIseq, abIseq1, rep2abI, band, bandSparse, bdiag, .bdiag,
>      > c.sparseVector, condest, onenormest, .asmatrix, .dsy2mat, .dsy2dsp,
>      > .dxC2mat, .T2Cmat, ..2dge, .dense2sy, .C2nC, .nC2d, .nC2l, .diag.dsC,
>      > .solve.dgC.chol, .solve.dgC.qr, .solve.dgC.lu, diagN2U, diagU2N,
>      > .diagU2N, .diag2tT, .diag2sT, .diag2mat, drop0, expand, expm, facmul,
>      > fac2sparse, fac2Sparse, forceSymmetric, T2graph, graph2T,
>      > anyDuplicatedT, uniqTsparse, isTriangular, isDiagonal, isLDL,
>      > is.null.DN, invPerm, lu, nearPD, nnzero, formatSpMatrix,
>      > formatSparseM, .formatSparseSimple, printSpMatrix, printSpMatrix2,
>      > qrR, rankMatrix, readHB, readMM, sparse.model.matrix, sparseVector,
>      > symmpart, skewpart, tril, triu, updown, pack, unpack,
>      > .updateCHMfactor, .validateCsparse, writeMM, cBind, rBind
>      > ERROR: lazy loading failed for package 'rockchalk'
>      > * removing 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'
>      > * restoring previous 'd:/Rcompile/CRANpkg/lib/3.4/rockchalk'
> 
> all of these these are names of  Matrix-package objects..
> and I know that yesterday Matrix package version changes (1.1-11
> --> 1.1-12) happened on CRAN and hence in servers which update..
> 
> So it *could* be this is all just a temporary problem aka "race
> situation" , where the check of your package very unhappily
> happened exactly at a moment where the new Matrix package was
> already there, but not quite ....
> seems quite improbable, but then your problem seems "rare"..

Perfect analysis: Race condition. Happens from time to time.
Can you simply resubmit it, please.

Best,
Uwe Ligges




> 
> Martin
> 
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>


From h.wickham at gmail.com  Tue Nov 21 14:23:11 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 21 Nov 2017 07:23:11 -0600
Subject: [Rd] Small performance bug in [.Date
In-Reply-To: <23060.580.899992.677761@stat.math.ethz.ch>
References: <CABdHhvH6iWobpPDdpOWc0oqDASNJbTwgRQp9RaS-Jk_JNDE4dg@mail.gmail.com>
 <23060.580.899992.677761@stat.math.ethz.ch>
Message-ID: <CABdHhvGLu7x9jAYQh_vr3i9ar8Th-5Z3mZ1o5ejwHL9GPRyHiw@mail.gmail.com>

> Yes, at least so it looks in  src/main/objects.c
>
> Also, we had a very similar change a while ago :
> ------------------------------------------------------------------------
> r65926 | luke | 2014-06-12 15:54:38 +0200 (Thu, 12. Jun 2014) | 2 Zeilen
> Ge?nderte Pfade:
>    M src/library/base/R/datetime.R
>
> Commented out class(x) <- NULL in [.POSIXct and [[.POSICct.
> ------------------------------------------------------------------------
>
> and we never seemed to have followed up in a systematic manner
> finding other places where this happens and could be
> eliminated.  I see about half a dozen examples in
> base/R/dates.R  alone and am trying to find more in other places.
>
> [maybe this used to be necessary for very early different
>  versions of NextMethod() which were not yet optimized using  .Class etc]

Thanks for making the fix!

Hadley

-- 
http://hadley.nz


From maechler at stat.math.ethz.ch  Thu Nov 16 22:00:16 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Nov 2017 22:00:16 +0100
Subject: [Rd] str() not displaying names
In-Reply-To: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>
References: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>
Message-ID: <23053.64608.131895.80128@stat.math.ethz.ch>

[This is a "re-post" -- for some reason it never appeared on R-devel]

>>>>> Etienne Sanchez <etiennesanchez2 at gmail.com>
>>>>>     on Tue, 14 Nov 2017 19:33:07 +0100 writes:

> In some cases, str() does not print the "names" attribute of the object:
> 
> u <- structure(c(5, 6), names = c("a", "b"), color = "blue")

> str(u)
> #  atomic [1:2] 5 6
> #  - attr(*, "color")= chr "blue"
> 
> Is it a bug or a design choice?


> Originally asked here:
> https://stackoverflow.com/q/47185756/6656269

It's not a bug in the sense that a long time ago -- when I wrote
the first version of str(), for S-plus, before R existed --
I had decided that when  is.vector(.) was false, for whatever
reason, the atomic vectors should be shown as above.

I don't remember if S-plus used the same somewhat surprising
definition of is.vector(.) as R does (but I think it did):
it is only TRUE for a vector that has no other attributes than
possibly "names". 

I did occasionally find that the historical choice probably was
not quite the best in hindsight, but never got convinced that it
should be changed...
Once I'll have finished the  deparse/dput/dump changes in
R-devel (hopefully within a week), and as R-devel has quite a
few small changes to R <= 3.4.x anyway, I may consider to change
utils:::str.default here  ... and have a few dozens of package
maintainers and R users live with the fact the str() outputs
will have changed in late spring next year ...

Notably if you or other give convincing reasons why it's worth
to change... but note that it's quite easy to give "Pro"
reasons, but there are "Cons" and for such cases a lot of "Cons"
are related to "there must 100's of 1000s of R code lines using
str(), and so there will be 100s of places where the output
changes, ( ... but then I'd guestimate that the change would be
to the better in most cases).


Martin

--
Martin Maechler, ETH Zurich


> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From winstonchang1 at gmail.com  Tue Nov 21 18:40:29 2017
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 21 Nov 2017 11:40:29 -0600
Subject: [Rd] Are Rprintf and REprintf thread-safe?
Message-ID: <CAFOpNVG48s4mahtM3nFkedParKJtoGkR5WPZOhg6bhaz-W43sg@mail.gmail.com>

Is it safe to call Rprintf and REprintf from a background thread? I'm
working on a package that makes calls to fprintf(stderr, ...) on a
background thread when errors happen, but when I run R CMD check, it
says:

  Compiled code should not call entry points which might terminate R nor
  write to stdout/stderr instead of to the console, nor the system RNG.

Is it safe to replace these calls with REprintf()?

-Winston


From luke-tierney at uiowa.edu  Tue Nov 21 19:42:15 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 21 Nov 2017 12:42:15 -0600 (CST)
Subject: [Rd] Are Rprintf and REprintf thread-safe?
In-Reply-To: <CAFOpNVG48s4mahtM3nFkedParKJtoGkR5WPZOhg6bhaz-W43sg@mail.gmail.com>
References: <CAFOpNVG48s4mahtM3nFkedParKJtoGkR5WPZOhg6bhaz-W43sg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1711211239350.2642@luke-Latitude>

On Tue, 21 Nov 2017, Winston Chang wrote:

> Is it safe to call Rprintf and REprintf from a background thread? I'm
> working on a package that makes calls to fprintf(stderr, ...) on a
> background thread when errors happen, but when I run R CMD check, it
> says:
>
>  Compiled code should not call entry points which might terminate R nor
>  write to stdout/stderr instead of to the console, nor the system RNG.
>
> Is it safe to replace these calls with REprintf()?

Only if you enjoy race conditions or segfaults.

Rprintf and REprintf are not thread-safe.

Best,

luke


>
> -Winston
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From winstonchang1 at gmail.com  Tue Nov 21 22:12:36 2017
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 21 Nov 2017 15:12:36 -0600
Subject: [Rd] Are Rprintf and REprintf thread-safe?
In-Reply-To: <alpine.DEB.2.20.1711211239350.2642@luke-Latitude>
References: <CAFOpNVG48s4mahtM3nFkedParKJtoGkR5WPZOhg6bhaz-W43sg@mail.gmail.com>
 <alpine.DEB.2.20.1711211239350.2642@luke-Latitude>
Message-ID: <CAFOpNVFV6YhDRFF7-29zes=H6_3T0V83jqtx4mtYgs9tLazQ=Q@mail.gmail.com>

Thanks - I'll find another way to send messages to the main thread for printing.

-Winston

On Tue, Nov 21, 2017 at 12:42 PM,  <luke-tierney at uiowa.edu> wrote:
> On Tue, 21 Nov 2017, Winston Chang wrote:
>
>> Is it safe to call Rprintf and REprintf from a background thread? I'm
>> working on a package that makes calls to fprintf(stderr, ...) on a
>> background thread when errors happen, but when I run R CMD check, it
>> says:
>>
>>  Compiled code should not call entry points which might terminate R nor
>>  write to stdout/stderr instead of to the console, nor the system RNG.
>>
>> Is it safe to replace these calls with REprintf()?
>
>
> Only if you enjoy race conditions or segfaults.
>
> Rprintf and REprintf are not thread-safe.
>
> Best,
>
> luke
>
>
>>
>> -Winston
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From martin.morgan at roswellpark.org  Tue Nov 21 22:25:28 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 21 Nov 2017 16:25:28 -0500
Subject: [Rd] Are Rprintf and REprintf thread-safe?
In-Reply-To: <CAFOpNVFV6YhDRFF7-29zes=H6_3T0V83jqtx4mtYgs9tLazQ=Q@mail.gmail.com>
References: <CAFOpNVG48s4mahtM3nFkedParKJtoGkR5WPZOhg6bhaz-W43sg@mail.gmail.com>
 <alpine.DEB.2.20.1711211239350.2642@luke-Latitude>
 <CAFOpNVFV6YhDRFF7-29zes=H6_3T0V83jqtx4mtYgs9tLazQ=Q@mail.gmail.com>
Message-ID: <d6bb0907-79b7-1aee-ab98-fbefc5944151@roswellpark.org>

On 11/21/2017 04:12 PM, Winston Chang wrote:
> Thanks - I'll find another way to send messages to the main thread for printing.

The CRAN synchronicity and Bioconductor BiocParallel packages provide 
inter-process locks that you could use to surround writes (instead of 
sending message to the main thread), also easy enough to incorporate at 
the C level using the BH package as source for relevant boost header.

Martin

> 
> -Winston
> 
> On Tue, Nov 21, 2017 at 12:42 PM,  <luke-tierney at uiowa.edu> wrote:
>> On Tue, 21 Nov 2017, Winston Chang wrote:
>>
>>> Is it safe to call Rprintf and REprintf from a background thread? I'm
>>> working on a package that makes calls to fprintf(stderr, ...) on a
>>> background thread when errors happen, but when I run R CMD check, it
>>> says:
>>>
>>>   Compiled code should not call entry points which might terminate R nor
>>>   write to stdout/stderr instead of to the console, nor the system RNG.
>>>
>>> Is it safe to replace these calls with REprintf()?
>>
>>
>> Only if you enjoy race conditions or segfaults.
>>
>> Rprintf and REprintf are not thread-safe.
>>
>> Best,
>>
>> luke
>>
>>
>>>
>>> -Winston
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From hpages at fredhutch.org  Tue Nov 21 23:42:33 2017
From: hpages at fredhutch.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 21 Nov 2017 14:42:33 -0800
Subject: [Rd] `[[<-.data.frame` leaves holes after existing columns and
 returns a corrupt data frame
Message-ID: <5A14ABD9.8070107@fredhutch.org>

Hi,

`[<-.data.frame` is cautious about not leaving holes after existing
columns:

   > `[<-`(data.frame(id=1:6), 3, value=data.frame(V3=11:16))
   Error in `[<-.data.frame`(data.frame(id = 1:6), 3, value = 
data.frame(V3 = 11:16)) :
     new columns would leave holes after existing columns

but `[[<-.data.frame` not so much:

   > `[[<-`(data.frame(id=1:6), 3, value=11:16)
     id      V3
   1  1 NULL 11
   2  2 <NA> 12
   3  3 <NA> 13
   4  4 <NA> 14
   5  5 <NA> 15
   6  6 <NA> 16
   Warning message:
   In format.data.frame(x, digits = digits, na.encode = FALSE) :
     corrupt data frame: columns will be truncated or padded with NAs

The latter should probably behave like the former in that case. Maybe
by sharing more code with it?

Thanks,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Nov 22 03:19:59 2017
From: hpages at fredhutch.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 21 Nov 2017 18:19:59 -0800
Subject: [Rd] `[<-.data.frame` sets rownames incorrectly
Message-ID: <5A14DECF.1080500@fredhutch.org>

Hi,

Here is another problem with data frame subsetting:

   > df <- data.frame(aa=1:3)
   > value <- data.frame(aa=11:12, row.names=c("A", "B"))

   > `[<-`(df, 4:5, , value=value)
     aa
   1  1
   2  2
   3  3
   A 11
   B 12

   > `[<-`(df, 5:4, , value=value)
     aa
   1  1
   2  2
   3  3
   B 12
   A 11

For this last result, the rownames of the 2 last rows should
be swapped.

H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Nov 22 03:23:40 2017
From: hpages at fredhutch.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 21 Nov 2017 18:23:40 -0800
Subject: [Rd] `[<-.data.frame` sets rownames incorrectly
In-Reply-To: <5A14DECF.1080500@fredhutch.org>
References: <5A14DECF.1080500@fredhutch.org>
Message-ID: <5A14DFAC.90201@fredhutch.org>

On 11/21/2017 06:19 PM, Herv? Pag?s wrote:
> Hi,
>
> Here is another problem with data frame subsetting:
>
>    > df <- data.frame(aa=1:3)
>    > value <- data.frame(aa=11:12, row.names=c("A", "B"))
>
>    > `[<-`(df, 4:5, , value=value)
>      aa
>    1  1
>    2  2
>    3  3
>    A 11
>    B 12
>
>    > `[<-`(df, 5:4, , value=value)
>      aa
>    1  1
>    2  2
>    3  3
>    B 12
>    A 11

This actually produces:

   > `[<-`(df, 5:4, , value=value)
     aa
   1  1
   2  2
   3  3
   A 12
   B 11

but should instead produce:

     aa
   1  1
   2  2
   3  3
   B 12
   A 11

sorry for the confusion.

H.

>
> For this last result, the rownames of the 2 last rows should
> be swapped.
>
> H.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Thu Nov 16 22:00:16 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Nov 2017 22:00:16 +0100
Subject: [Rd] str() not displaying names
In-Reply-To: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>
References: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>
Message-ID: <23053.64608.131895.80128@stat.math.ethz.ch>

>>>>> Etienne Sanchez <etiennesanchez2 at gmail.com>
>>>>>     on Tue, 14 Nov 2017 19:33:07 +0100 writes:

> In some cases, str() does not print the "names" attribute of the object:
> 
> u <- structure(c(5, 6), names = c("a", "b"), color = "blue")

> str(u)
> #  atomic [1:2] 5 6
> #  - attr(*, "color")= chr "blue"
> 
> Is it a bug or a design choice?


> Originally asked here:
> https://stackoverflow.com/q/47185756/6656269

It's not a bug in the sense that a long time ago -- when I wrote
the first version of str(), for S-plus, before R existed --
I had decided that when  is.vector(.) was false, for whatever
reason, the atomic vectors should be shown as above.

I don't remember if S-plus used the same somewhat surprising
definition of is.vector(.) as R does (but I think it did):
it is only TRUE for a vector that has no other attributes than
possibly "names". 

I did occasionally find that the historical choice probably was
not quite the best in hindsight, but never got convinced that it
should be changed...
Once I'll have finished the  deparse/dput/dump changes in
R-devel (hopefully within a week), and as R-devel has quite a
few small changes to R <= 3.4.x anyway, I may consider to change
utils:::str.default here  ... and have a few dozens of package
maintainers and R users live with the fact the str() outputs
will have changed in late spring next year ...

Notably if you or other give convincing reasons why it's worth
to change... but note that it's quite easy to give "Pro"
reasons, but there are "Cons" and for such cases a lot of "Cons"
are related to "there must 100's of 1000s of R code lines using
str(), and so there will be 100s of places where the output
changes, ( ... but then I'd guestimate that the change would be
to the better in most cases).


Martin

--
Martin Maechler, ETH Zurich


> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From aaronw at catalyst.net.nz  Fri Nov 24 00:46:48 2017
From: aaronw at catalyst.net.nz (Aaron Wells)
Date: Fri, 24 Nov 2017 12:46:48 +1300
Subject: [Rd] Bug in R CMD INSTALL when handling invalid LazyData
	DESCRIPTION field
Message-ID: <f5019bfa-ce82-1359-0353-200127556e45@catalyst.net.nz>

Hi, I think I've found a bug in R CMD INSTALL. When it tries to parse a
DESCRIPTION file with an invalid LazyData field, it errors out while
trying to print the correct error message:

> R CMD INSTALL .
* installing to library ?/home/example/R/x86_64-pc-linux-gnu-library/3.4?
* installing *source* package ?samplepackage? ...
** data
Error in errmsg("invalid value of ", field, " field in DESCRIPTION") :
  could not find function "errmsg"
* removing ?/home/example/R/x86_64-pc-linux-gnu-library/3.4/samplepackage?


It should instead be using that errmsg() function to print the more
helpful error message: "invalid value of LazyData field in DESCRIPTION".

I've traced it down to this line of code in tools:::.install_packages()
https://github.com/wch/r-source/blob/trunk/src/library/tools/R/install.R#L977
. The errmsg() function actually is defined earlier on in the function,
but there seems to be a scoping issue that makes it not available here.

I've uploaded a sample project to reproduce the bug here:
https://github.com/agwells/R-CMD-INSTALL-bug

I'm running R version 3.4.2 (2017-09-28), on Ubuntu 16.04.

Cheers,
Aaron


From maechler at stat.math.ethz.ch  Fri Nov 24 09:18:31 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Nov 2017 09:18:31 +0100
Subject: [Rd] Bug in R CMD INSTALL when handling invalid
	LazyData	DESCRIPTION field
In-Reply-To: <f5019bfa-ce82-1359-0353-200127556e45@catalyst.net.nz>
References: <f5019bfa-ce82-1359-0353-200127556e45@catalyst.net.nz>
Message-ID: <23063.54743.153721.18694@stat.math.ethz.ch>

>>>>> Aaron Wells <aaronw at catalyst.net.nz>
>>>>>     on Fri, 24 Nov 2017 12:46:48 +1300 writes:

    > Hi, I think I've found a bug in R CMD INSTALL. When it tries to parse a
    > DESCRIPTION file with an invalid LazyData field, it errors out while
    > trying to print the correct error message:

    >> R CMD INSTALL .
    > * installing to library ?/home/example/R/x86_64-pc-linux-gnu-library/3.4?
    > * installing *source* package ?samplepackage? ...
    > ** data
    > Error in errmsg("invalid value of ", field, " field in DESCRIPTION") :
    > could not find function "errmsg"
    > * removing ?/home/example/R/x86_64-pc-linux-gnu-library/3.4/samplepackage?


    > It should instead be using that errmsg() function to print the more
    > helpful error message: "invalid value of LazyData field in DESCRIPTION".

    > I've traced it down to this line of code in tools:::.install_packages()
    > https://github.com/wch/r-source/blob/trunk/src/library/tools/R/install.R#L977
    > . The errmsg() function actually is defined earlier on in the function,
    > but there seems to be a scoping issue that makes it not available here.

    > I've uploaded a sample project to reproduce the bug here:
    > https://github.com/agwells/R-CMD-INSTALL-bug

    > I'm running R version 3.4.2 (2017-09-28), on Ubuntu 16.04.

    > Cheers,
    > Aaron

Thank you very much, Aaron.
This is indeed a bug, and it looks that I had caused it when
introducing the internal str_parse() utlity.

It's too bad this is so close before release of R 3.4.3 and the
fix to the bug is not trivial (not very hard either) such that
it most probably will not make it into 3.4.3.

Martin Maechler
ETH Zurich


From apanteleymonov at starpoint.com  Fri Nov 24 18:16:12 2017
From: apanteleymonov at starpoint.com (Andriy Panteleymonov)
Date: Fri, 24 Nov 2017 12:16:12 -0500
Subject: [Rd] extractAIC.coxph warning
Message-ID: <138A8B36-6F0F-42BF-8535-FA04692D182B@exchange.starpoint.com>

Hi,
It is not critical but in case of coxph.null model (~1)
extractAIC function generates
       Warning message:
        In is.na(fit$coefficients) :
        is.na() applied to non-(list or vector) of type 'NULL'
As I understand it happens because of absent coefficients attribute.
Function stats:::extractAIC.coxph
Line edf <- sum(!is.na(fit$coefficients))

I think extra null-checking would be useful here.

Regards,
Andriy


________________________________
Since 1982, Starpoint Solutions has been a trusted source of human capital and solutions. We are committed to our clients, employees, environment, community and social concerns. We foster an inclusive culture based on trust, respect, honesty and solid performance. Learn more about Starpoint and our social responsibility at http://www.starpoint.com/social_responsibility

________________________________
This email message from Starpoint Solutions LLC is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. Opinions, conclusions and other information in this message that do not relate to the official business of Starpoint Solutions shall be understood as neither given nor endorsed by it.

	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Sat Nov 25 12:03:36 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 25 Nov 2017 11:03:36 +0000 (UTC)
Subject: [Rd] Function 'factor' issues
References: <875369431.2881005.1511607816625.ref@mail.yahoo.com>
Message-ID: <875369431.2881005.1511607816625@mail.yahoo.com>

>From commits to R devel, I saw attempts to speed up subsetting and 'match', and to cache results of conversion of small nonnegative integers to character string. That's good.

I am sorry for pushing, still.

Is the partial new behavior of function 'factor' with respect to NA really worthy?

match(xlevs, nlevs)[f]  looks nice, too.

- Using
f <- match(xlevs, nlevs)[f]
instead of
f <- match(xlevs[f], nlevs)
for remapping
- Remapping only if length(nlevs) differs from length(xlevs)
Applying changes similar to above to function 'levels<-.factor' will not change 'levels<-.factor' result at all. So, the corresponding part of functions 'factor' and 'levels<-.factor' can be kept in sync.

--------------------------------------------


 Subject: Re: [Rd] Function 'factor' issues
 To: r-devel at r-project.org
 Date: Sunday, 22 October, 2017, 6:43 AM
 
My idea (like in https://bugs.r-project.org/bugzilla/attachment.cgi?id=1540 ):
- For remapping, use
f <- match(xlevs, nlevs)[f]
instead of
f <- match(xlevs[f], nlevs)
(I have mentioned it).
- Remap only if length(nlevs) differs from length(xlevs) .


[snip]

--------------------------------------------
On Wed, 18/10/17, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

Subject: Re: [Rd] Function 'factor' issues

Cc: r-devel at r-project.org
Date: Wednesday, 18 October, 2017, 11:54 PM

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sun, 15 Oct 2017 16:03:48 +0000 writes:

 
    > In R devel, function 'factor' has been changed, allowing and merging duplicated 'labels'.

Indeed.  That had been asked for and discussed a bit on this
list from June 14 to June 23, starting at
   https://stat.ethz.ch/pipermail/r-devel/2017-June/074451.html

    > Issue 1: Handling of specified 'labels' without duplicates is slower than before.
    > Example:
    > x <- rep(1:26, 40000)
    > system.time(factor(x, levels=1:26, labels=letters))

    > Function 'factor' is already rather slow because of conversion to character. Please don't add slowdown.

Indeed, I doo see a ~ 20%  performance loss for the example
above, and I may get to look into this.
However, in R-devel there have been important internal
changes (ALTREP additions) some of which are currently giving
some performance losses in some cases (but they have the
potential to give big performance _gains_ e.g. for simple
indexing into large vectors which may apply here !).
For factor(), these C level "ALTREP" changes may not be the reason at
all for the slow down;
I may find time to investigate further.

{{ For the ALTREP-change slowdowns I've noticed in some
   indexing/subset operations, we'll definitely have time to look into
   before R-devel is going to be released next spring... and as mentioned,
   these operations may even become considerably faster *thanks*
   to ALTREP ... }}

    > Issue 2: While default 'labels' is 'levels', not specifying 'labels' may be different from specifying 'labels' to be the same as 'levels'.

    > Example 1:
    > as.integer(factor(c(NA,2,3), levels = c(2, NA), exclude = NULL))
    > is different from
    > as.integer(factor(c(NA,2,3), levels = c(2, NA), labels = c(2, NA), exclude = NULL))

You are right.  But this is not so exceptional and part of the new feature of
'labels' allowing to "fix up" things in such cases.  While it
would be nice if this was not the case the same phenomenon
happens in other functions as well because of lazy evaluation.
I think I had noticed that already and at the time found
"not easy" to work around.
(There are many aspects about changing such important base functions:
1. not breaking back compatibility ((unless in rare
    border cases, where we are sure it's worth))
2. Keeping code relatively transparent
3. Keep the semantics "simple" to document and as intuitive as possible
)

    > File reg-tests-1d.R indicates that 'factor' behavior with NA is slightly changed, for the better. NA entry (because it is unmatched to 'levels' argument or is in 'exclude') is absorbed into NA in "levels" attribute (comes from 'labels' argument), if any. The issue is that it happens only when 'labels' is specified.

I'm not sure anymore, but I think I had noticed that also in
June, considered to change it and found that such a changed
factor() would be too different from what it has "always been".
So, yes, IIRC, this current behavior is on purpose, if only for back compatibility.


    > Function 'factor' could use match(xlevs, nlevs)[f]. It doesn't match NA to NA level. When 'f' is long enough, longer than 'xlevs', it is faster than match(xlevs[f], nlevs).

    > Example 2:
    > With
    > levs <- c("A","A")  ,
    > factor(levs, levels=levs)
    > gives error, but
    > factor(levs, levels=levs, labels=levs)
    > doesn't.

yes, again that is a consequence of what you said above (before
'Example 1')

    > Note: In theory, if function 'factor' merged duplicated 'labels' in all cases, at least in
    > factor(c(sqrt(2)^2, 2))  ,
    > function 'factor' could do matching on original 'x' (without conversion to character), as in R before version 2.10.0. If function 'factor' did it,
    > factor(c(sqrt(2)^2, 2), levels = c(sqrt(2)^2, 2), labels = c("sqrt(2)^2", "2"))
    > could take sqrt(2)^2 and 2 as distinct.

Well, that may be interesting.. but I doubt if that's somewhere
we should go, easily, because  factor() has been documented to do
what it does now (with very slightly rounding such numbers via as.character(.))
and hence such a change would typically lead to much work for
too many people.

I do see that indeed the  as.character(.) inside factor() takes
most of the CPU time used in largish factor() examples [as your
first], and indeed, for the case of integer 'x', we really could
be much faster in factor construction.   

[snip]


From maechler at stat.math.ethz.ch  Sat Nov 25 22:06:08 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 25 Nov 2017 22:06:08 +0100
Subject: [Rd] str() not displaying names
In-Reply-To: <23053.64608.131895.80128@stat.math.ethz.ch>
References: <CANgsd5-ZszDpeRDKseBMu_03u7FuwEcqoDkjOR-QTEjKzaMAbg@mail.gmail.com>
 <23053.64608.131895.80128@stat.math.ethz.ch>
Message-ID: <23065.56128.333896.608967@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 16 Nov 2017 22:00:16 +0100 writes:

    > [This is a "re-post" -- for some reason it never appeared
    > on R-devel]
>>>>> Etienne Sanchez <etiennesanchez2 at gmail.com>
>>>>> on Tue, 14 Nov 2017 19:33:07 +0100 writes:

    >> In some cases, str() does not print the "names" attribute
    >> of the object:
    >> 
    >> u <- structure(c(5, 6), names = c("a", "b"), color =
    >> "blue")

    >> str(u) # atomic [1:2] 5 6 # - attr(*, "color")= chr
    >> "blue"
    >> 
    >> Is it a bug or a design choice?


    >> Originally asked here:
    >> https://stackoverflow.com/q/47185756/6656269

    > It's not a bug in the sense that a long time ago -- when I
    > wrote the first version of str(), for S-plus, before R
    > existed -- I had decided that when is.vector(.) was false,
    > for whatever reason, the atomic vectors should be shown as
    > above.

    > I don't remember if S-plus used the same somewhat
    > surprising definition of is.vector(.) as R does (but I
    > think it did): it is only TRUE for a vector that has no
    > other attributes than possibly "names".

    > I did occasionally find that the historical choice
    > probably was not quite the best in hindsight, but never
    > got convinced that it should be changed...  Once I'll have
    > finished the deparse/dput/dump changes in R-devel
    > (hopefully within a week), and as R-devel has quite a few
    > small changes to R <= 3.4.x anyway, I may consider to
    > change utils:::str.default here ... and have a few dozens
    > of package maintainers and R users live with the fact the
    > str() outputs will have changed in late spring next year
    > ...

    > Notably if you or other give convincing reasons why it's
    > worth to change... but note that it's quite easy to give
    > "Pro" reasons, but there are "Cons" and for such cases a
    > lot of "Cons" are related to "there must 100's of 1000s of
    > R code lines using str(), and so there will be 100s of
    > places where the output changes, ( ... but then I'd
    > guestimate that the change would be to the better in most
    > cases).

I have been daring (again!)  and did change  str()   so it will
typically no longer print the ominous  "atomic" in such cases.

This is for "R-devel" with svn rev >= 73780 ..

It will slightly change str() output for such cases, but in the
half a dozen cases I've looked the cases were always for the
better.

Martin

--
Martin Maechler
ETH Zurich and R Core


From aaronw at catalyst.net.nz  Sun Nov 26 21:36:29 2017
From: aaronw at catalyst.net.nz (Aaron Wells)
Date: Mon, 27 Nov 2017 09:36:29 +1300
Subject: [Rd] Bug in R CMD INSTALL when handling invalid LazyData
 DESCRIPTION field
In-Reply-To: <23063.54743.153721.18694@stat.math.ethz.ch>
References: <f5019bfa-ce82-1359-0353-200127556e45@catalyst.net.nz>
 <23063.54743.153721.18694@stat.math.ethz.ch>
Message-ID: <298db09b-4888-fb84-2b20-e0ce8a665977@catalyst.net.nz>

Well, on the positive side, it seems to be a fairly limited bug. :)

You have to actually have a syntax error in your DESCRIPTION file, and
it needs to be in one of the fields passed to parse_description_field()
as defined in tools:::.install_packages(); which is only Biarch,
LazyData, ByteCompile, and KeepSource.

Cheers,
Aaron


On 11/24/2017 09:18 PM, Martin Maechler wrote:
>>>>>> Aaron Wells <aaronw at catalyst.net.nz>
>>>>>>     on Fri, 24 Nov 2017 12:46:48 +1300 writes:
> 
>     > Hi, I think I've found a bug in R CMD INSTALL. When it tries to parse a
>     > DESCRIPTION file with an invalid LazyData field, it errors out while
>     > trying to print the correct error message:
> 
>     >> R CMD INSTALL .
>     > * installing to library ?/home/example/R/x86_64-pc-linux-gnu-library/3.4?
>     > * installing *source* package ?samplepackage? ...
>     > ** data
>     > Error in errmsg("invalid value of ", field, " field in DESCRIPTION") :
>     > could not find function "errmsg"
>     > * removing ?/home/example/R/x86_64-pc-linux-gnu-library/3.4/samplepackage?
> 
> 
>     > It should instead be using that errmsg() function to print the more
>     > helpful error message: "invalid value of LazyData field in DESCRIPTION".
> 
>     > I've traced it down to this line of code in tools:::.install_packages()
>     > https://github.com/wch/r-source/blob/trunk/src/library/tools/R/install.R#L977
>     > . The errmsg() function actually is defined earlier on in the function,
>     > but there seems to be a scoping issue that makes it not available here.
> 
>     > I've uploaded a sample project to reproduce the bug here:
>     > https://github.com/agwells/R-CMD-INSTALL-bug
> 
>     > I'm running R version 3.4.2 (2017-09-28), on Ubuntu 16.04.
> 
>     > Cheers,
>     > Aaron
> 
> Thank you very much, Aaron.
> This is indeed a bug, and it looks that I had caused it when
> introducing the internal str_parse() utlity.
> 
> It's too bad this is so close before release of R 3.4.3 and the
> fix to the bug is not trivial (not very hard either) such that
> it most probably will not make it into 3.4.3.
> 
> Martin Maechler
> ETH Zurich
>


From ramiro at precisionbioassay.com  Mon Nov 27 22:02:52 2017
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Mon, 27 Nov 2017 21:02:52 +0000
Subject: [Rd] withTimeout bug, it does not work properly with nlme anymore
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B9C4AA4D@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I was relying on withTimeout (from R.utils) to help me stop nlme when it ?hangs?.  However, recently this stopped working.  I am pasting a reproducible example below: withTimeout should stop nlme after 10 seconds but the code will generate data for which nlme does not converge (or takes too long) and withTimeout does not stop it.  I tried this both on a linux (64 bit, CentOS 7, R 3.4.1, nlme 3.1-131 R.util 2.6, and also with R 3.2.5) and mac (Sierra 10.13.1, R 3.4.2, same versions or nlme and R.utils).  It takes over R and I need to use brute-force to stop it.  As mentioned, this used to work and it is very helpful for the purposes of having a loop where nlme goes through many models.

Thank you in advance for any help,
Ramiro

library(nlme)
library(R.utils)

dat<-data.frame(x=c(3.69,3.69,3.69,3.69,3.69,3.69,3.69,3.69,3.69,3.69,3.69,3.69,3,3,3,3,3,3,3,3,3,3,3,3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,2.3,1.61,1.61,1.61,1.61,1.61,1.61,1.61,1.61,1.61,1.61,1.61,1.61,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.92,0.22,0.22,0.22,0.22,0.22,0.22,0.22,0.22,0.22,0.22,0.22,0.22,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-0.47,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86,-1.86),
y=c(0.35,0.69,0.57,1.48,6.08,-0.34,0.53,1.66,0.02,4.4,8.42,3.3,2.32,-2.3,7.52,-2.12,3.41,-4.76,7.9,5.04,10.26,-1.42,7.85,-1.88,3.81,-2.59,4.32,5.7,1.18, -1.74,1.81,6.16,4.2,-0.39,1.55,-1.4,1.76,-4.14,-2.36,-0.24,4.8,-7.07,1.34,1.98,0.86,-3.96,-0.61,2.68,-1.65,-2.06,3.67,-0.19,2.33,3.78,2.16,0.35, -5.6,1.32,2.99,4.21,-0.9,4.32,-4.01,2.03,0.9,-0.74,-5.78,5.76,0.52,1.37,-0.9,-4.06,-0.49,-2.39,-2.67,-0.71,-0.4,2.55,0.97,1.96,8.13,-5.93,4.01,0.79, -5.61,0.29,4.92,-2.89,-3.24,-3.06,-0.23,0.71,0.75,4.6,1.35, -3.35),
f.block=c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4),
id=c("a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3","a2","a2","a2","a2","a1","a1","a1","a1","a3","a3","a3","a3"))

fpl.B.range <- function(lx,logbase,A,B,C,D) {
    A/(1+logbase^(-B*(lx-C)))+D
}
myFormula<-list(formula(A~id),formula(B~id),formula(C~id),formula(D~id))
INIT <- c(A.a1=1,A.a2=0,A.a3=0,B=1,B.a2=0,B.a3=0,C=0,C.a2=0,C.a3=0,D=1,D.a2=0,D.a3=0)


for (i in 1:100) {
    print(paste("Iteration ",i,"...this will stall soon"))
    set.seed(i)
    dat$y <- dat$y+rnorm(nrow(dat), mean = 0, sd = 0.1)
    try({withTimeout(nlme(model=y~fpl.B.range(x,exp(1),A,B,C,D),
                      control=nlmeControl(maxIter=50,pnlsMaxIter=7,msMaxIter=50,niterEM=25),
                          data=dat, na.action=na.omit,
                          fixed=myFormula,random=list(f.block=pdSymm(A+B+C+D~1)),
                          start=INIT),timeout=10)})
}


	[[alternative HTML version deleted]]


From arietencate at gmail.com  Tue Nov 28 09:29:29 2017
From: arietencate at gmail.com (Arie ten Cate)
Date: Tue, 28 Nov 2017 09:29:29 +0100
Subject: [Rd] Discourage the weights= option of lm with summarized data
In-Reply-To: <CACg-3uYd66Wbua3q71Hau4w6gHhJdENrnHVzNU_yd3z4XLa5gw@mail.gmail.com>
References: <CACg-3uaGhq_RX5S7YQVz0KEx6G-MoVaFVXx_MWuP75qaWqw3mQ@mail.gmail.com>
 <3350d9cc415940f39ba36bd65e104ee0@UM-MAIL3216.unimaas.nl>
 <CACg-3uZMSoj5RBkREqzM6Dc-AiqMahHbQPMzP34KgoeQ7UmVHg@mail.gmail.com>
 <E784F4E0-01CE-4A09-8DD8-4F85FAC293AF@gmail.com>
 <CACg-3uYd66Wbua3q71Hau4w6gHhJdENrnHVzNU_yd3z4XLa5gw@mail.gmail.com>
Message-ID: <CACg-3ubeaHdkwnTnOoSVAPezqoo4soQ=_E2uj1aMzCsgfF+S_A@mail.gmail.com>

Since the three posters agree (only) that there is a bug, I propose to
file it as a bug, which is the least we can do now.

There is more to it: the only other case of a change in the Reference
Manual which I know of, is also about the weights option! This is in
coxph. The Reference Manual version 3.0.0 (2013) says about coxph:

   " ... If weights is a vector of integers, then the estimated
coefficients are equivalent to estimating the model from data with the
individual cases replicated as many times as indicated by weights."

This is not true, as can be seen from the following code, which uses
the data from the first example in the Reference Manual of coxph:

   library(survival)
   print(df1 <- as.data.frame(list(
     time=c(4,3,1,1,2,2,3),
   status=c(1,1,1,0,1,1,0),
        x=c(0,2,1,1,1,0,0),
      sex=c(0,0,0,0,1,1,1)
   )))
   print(w <- rep(2,7))
   print(coxph(Surv(time,status) ~ x + strata(sex),data=df1,weights=w))
      # manually doubling the data:
   print(df2 <- rbind(df1,df1))
   print(coxph(Surv(time,status) ~ x + strata(sex), data=df2))

This should not come as a surprise, since with coxph the computation
of the likelihood (given the parameters) for a single observation uses
also the other observations.

This bug has been repaired. The present Reference Manual of coxph says
that the weights option specifies a vector of case weights, to which
is added only: "For a thorough discussion of these see the book by
Therneau and Grambsch."

Let us repair the other bug also.

    Arie

On Thu, Oct 12, 2017 at 1:48 PM, Arie ten Cate <arietencate at gmail.com> wrote:
>  OK. We have now three suggestions to repair the text:
>  - remove the text
>  - add "not" at the beginning of the text
>  - add at the end of the text a warning; something like:
>
>   "Note that in this case the standard estimates of the parameters are
> in general not correct, and hence also the t values and the p value.
> Also the number of degrees of freedom is not correct. (The parameter
> values are correct.)"
>
> A remark about the glm example: the Reference manual says: "For a
> binomial GLM prior weights are used to give the number of trials when
> the response is the proportion of successes ....".  Hence in the
> binomial case the weights are frequencies.
> With y <- 0.51 and w <- 100 you get the same result.
>
>    Arie
>
> On Mon, Oct 9, 2017 at 5:22 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> AFAIR, it is a little more subtle than that.
>>
>> If you have replication weights, then the estimates are right, it is "just" that the SE from summary.lm() are wrong. Somehow, the text should reflect this.
>>
>> It is of some importance when you put glm() into the mix, because you can in fact get correct results from things like
>>
>> y <- c(0,1)
>> w <- c(49,51)
>> glm(y~1, weights=w, family=binomial)
>>
>> -pd
>>
>>> On 9 Oct 2017, at 07:58 , Arie ten Cate <arietencate at gmail.com> wrote:
>>>
>>> Yes.  Thank you; I should have quoted it.
>>> I suggest to remove this text or to add the word "not" at the beginning.
>>>
>>>   Arie
>>>
>>> On Sun, Oct 8, 2017 at 4:38 PM, Viechtbauer Wolfgang (SP)
>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>> Ah, I think you are referring to this part from ?lm:
>>>>
>>>> "(including the case that there are w_i observations equal to y_i and the data have been summarized)"
>>>>
>>>> I see; indeed, I don't think this is what 'weights' should be used for (the other part before that is correct). Sorry, I misunderstood the point you were trying to make.
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>> -----Original Message-----
>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>> Sent: Sunday, 08 October, 2017 14:55
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>>
>>>> Indeed: Using 'weights' is not meant to indicate that the same
>>>> observation is repeated 'n' times.  As I showed, this gives erroneous
>>>> results. Hence I suggested that it is discouraged rather than
>>>> encouraged in the Details section of lm in the Reference manual.
>>>>
>>>>   Arie
>>>>
>>>> ---Original Message-----
>>>> On Sat, 7 Oct 2017, wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
>>>>
>>>> Using 'weights' is not meant to indicate that the same observation is
>>>> repeated 'n' times. It is meant to indicate different variances (or to
>>>> be precise, that the variance of the last observation in 'x' is
>>>> sigma^2 / n, while the first three observations have variance
>>>> sigma^2).
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>> -----Original Message-----
>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>> Sent: Saturday, 07 October, 2017 9:36
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>>
>>>> In the Details section of lm (linear models) in the Reference manual,
>>>> it is suggested to use the weights= option for summarized data. This
>>>> must be discouraged rather than encouraged. The motivation for this is
>>>> as follows.
>>>>
>>>> With summarized data the standard errors get smaller with increasing
>>>> numbers of observations. However, the standard errors in lm do not get
>>>> smaller when for instance all weights are multiplied with the same
>>>> constant larger than one, since the inverse weights are merely
>>>> proportional to the error variances.
>>>>
>>>> Here is an example of the estimated standard errors being too large
>>>> with the weights= option. The p value and the number of degrees of
>>>> freedom are also wrong. The parameter estimates are correct.
>>>>
>>>>  n <- 10
>>>>  x <- c(1,2,3,4)
>>>>  y <- c(1,2,5,4)
>>>>  w <- c(1,1,1,n)
>>>>  xb <- c(x,rep(x[4],n-1))  # restore the original data
>>>>  yb <- c(y,rep(y[4],n-1))
>>>>  print(summary(lm(yb ~ xb)))
>>>>  print(summary(lm(y ~ x, weights=w)))
>>>>
>>>> Compare with PROC REG in SAS, with a WEIGHT statement (like R) and a
>>>> FREQ statement (for summarized data).
>>>>
>>>>    Arie
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>


From pdalgd at gmail.com  Tue Nov 28 11:15:14 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 28 Nov 2017 11:15:14 +0100
Subject: [Rd] Discourage the weights= option of lm with summarized data
In-Reply-To: <CACg-3ubeaHdkwnTnOoSVAPezqoo4soQ=_E2uj1aMzCsgfF+S_A@mail.gmail.com>
References: <CACg-3uaGhq_RX5S7YQVz0KEx6G-MoVaFVXx_MWuP75qaWqw3mQ@mail.gmail.com>
 <3350d9cc415940f39ba36bd65e104ee0@UM-MAIL3216.unimaas.nl>
 <CACg-3uZMSoj5RBkREqzM6Dc-AiqMahHbQPMzP34KgoeQ7UmVHg@mail.gmail.com>
 <E784F4E0-01CE-4A09-8DD8-4F85FAC293AF@gmail.com>
 <CACg-3uYd66Wbua3q71Hau4w6gHhJdENrnHVzNU_yd3z4XLa5gw@mail.gmail.com>
 <CACg-3ubeaHdkwnTnOoSVAPezqoo4soQ=_E2uj1aMzCsgfF+S_A@mail.gmail.com>
Message-ID: <EE91C515-08B9-4D0C-ACBC-2882D55EBA7F@gmail.com>

It's on my todo list (for R-devel, it is not _that_ important), other things just keep taking priority...

-pd

> On 28 Nov 2017, at 09:29 , Arie ten Cate <arietencate at gmail.com> wrote:
> 
> Since the three posters agree (only) that there is a bug, I propose to
> file it as a bug, which is the least we can do now.
> 
> There is more to it: the only other case of a change in the Reference
> Manual which I know of, is also about the weights option! This is in
> coxph. The Reference Manual version 3.0.0 (2013) says about coxph:
> 
>   " ... If weights is a vector of integers, then the estimated
> coefficients are equivalent to estimating the model from data with the
> individual cases replicated as many times as indicated by weights."
> 
> This is not true, as can be seen from the following code, which uses
> the data from the first example in the Reference Manual of coxph:
> 
>   library(survival)
>   print(df1 <- as.data.frame(list(
>     time=c(4,3,1,1,2,2,3),
>   status=c(1,1,1,0,1,1,0),
>        x=c(0,2,1,1,1,0,0),
>      sex=c(0,0,0,0,1,1,1)
>   )))
>   print(w <- rep(2,7))
>   print(coxph(Surv(time,status) ~ x + strata(sex),data=df1,weights=w))
>      # manually doubling the data:
>   print(df2 <- rbind(df1,df1))
>   print(coxph(Surv(time,status) ~ x + strata(sex), data=df2))
> 
> This should not come as a surprise, since with coxph the computation
> of the likelihood (given the parameters) for a single observation uses
> also the other observations.
> 
> This bug has been repaired. The present Reference Manual of coxph says
> that the weights option specifies a vector of case weights, to which
> is added only: "For a thorough discussion of these see the book by
> Therneau and Grambsch."
> 
> Let us repair the other bug also.
> 
>    Arie
> 
> On Thu, Oct 12, 2017 at 1:48 PM, Arie ten Cate <arietencate at gmail.com> wrote:
>> OK. We have now three suggestions to repair the text:
>> - remove the text
>> - add "not" at the beginning of the text
>> - add at the end of the text a warning; something like:
>> 
>>  "Note that in this case the standard estimates of the parameters are
>> in general not correct, and hence also the t values and the p value.
>> Also the number of degrees of freedom is not correct. (The parameter
>> values are correct.)"
>> 
>> A remark about the glm example: the Reference manual says: "For a
>> binomial GLM prior weights are used to give the number of trials when
>> the response is the proportion of successes ....".  Hence in the
>> binomial case the weights are frequencies.
>> With y <- 0.51 and w <- 100 you get the same result.
>> 
>>   Arie
>> 
>> On Mon, Oct 9, 2017 at 5:22 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>>> AFAIR, it is a little more subtle than that.
>>> 
>>> If you have replication weights, then the estimates are right, it is "just" that the SE from summary.lm() are wrong. Somehow, the text should reflect this.
>>> 
>>> It is of some importance when you put glm() into the mix, because you can in fact get correct results from things like
>>> 
>>> y <- c(0,1)
>>> w <- c(49,51)
>>> glm(y~1, weights=w, family=binomial)
>>> 
>>> -pd
>>> 
>>>> On 9 Oct 2017, at 07:58 , Arie ten Cate <arietencate at gmail.com> wrote:
>>>> 
>>>> Yes.  Thank you; I should have quoted it.
>>>> I suggest to remove this text or to add the word "not" at the beginning.
>>>> 
>>>>  Arie
>>>> 
>>>> On Sun, Oct 8, 2017 at 4:38 PM, Viechtbauer Wolfgang (SP)
>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>>> Ah, I think you are referring to this part from ?lm:
>>>>> 
>>>>> "(including the case that there are w_i observations equal to y_i and the data have been summarized)"
>>>>> 
>>>>> I see; indeed, I don't think this is what 'weights' should be used for (the other part before that is correct). Sorry, I misunderstood the point you were trying to make.
>>>>> 
>>>>> Best,
>>>>> Wolfgang
>>>>> 
>>>>> -----Original Message-----
>>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>>> Sent: Sunday, 08 October, 2017 14:55
>>>>> To: r-devel at r-project.org
>>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>>> 
>>>>> Indeed: Using 'weights' is not meant to indicate that the same
>>>>> observation is repeated 'n' times.  As I showed, this gives erroneous
>>>>> results. Hence I suggested that it is discouraged rather than
>>>>> encouraged in the Details section of lm in the Reference manual.
>>>>> 
>>>>>  Arie
>>>>> 
>>>>> ---Original Message-----
>>>>> On Sat, 7 Oct 2017, wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
>>>>> 
>>>>> Using 'weights' is not meant to indicate that the same observation is
>>>>> repeated 'n' times. It is meant to indicate different variances (or to
>>>>> be precise, that the variance of the last observation in 'x' is
>>>>> sigma^2 / n, while the first three observations have variance
>>>>> sigma^2).
>>>>> 
>>>>> Best,
>>>>> Wolfgang
>>>>> 
>>>>> -----Original Message-----
>>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>>> Sent: Saturday, 07 October, 2017 9:36
>>>>> To: r-devel at r-project.org
>>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>>> 
>>>>> In the Details section of lm (linear models) in the Reference manual,
>>>>> it is suggested to use the weights= option for summarized data. This
>>>>> must be discouraged rather than encouraged. The motivation for this is
>>>>> as follows.
>>>>> 
>>>>> With summarized data the standard errors get smaller with increasing
>>>>> numbers of observations. However, the standard errors in lm do not get
>>>>> smaller when for instance all weights are multiplied with the same
>>>>> constant larger than one, since the inverse weights are merely
>>>>> proportional to the error variances.
>>>>> 
>>>>> Here is an example of the estimated standard errors being too large
>>>>> with the weights= option. The p value and the number of degrees of
>>>>> freedom are also wrong. The parameter estimates are correct.
>>>>> 
>>>>> n <- 10
>>>>> x <- c(1,2,3,4)
>>>>> y <- c(1,2,5,4)
>>>>> w <- c(1,1,1,n)
>>>>> xb <- c(x,rep(x[4],n-1))  # restore the original data
>>>>> yb <- c(y,rep(y[4],n-1))
>>>>> print(summary(lm(yb ~ xb)))
>>>>> print(summary(lm(y ~ x, weights=w)))
>>>>> 
>>>>> Compare with PROC REG in SAS, with a WEIGHT statement (like R) and a
>>>>> FREQ statement (for summarized data).
>>>>> 
>>>>>   Arie
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marius.mather at gmail.com  Tue Nov 28 04:25:57 2017
From: marius.mather at gmail.com (Marius)
Date: Tue, 28 Nov 2017 14:25:57 +1100
Subject: [Rd] Height not set properly in grDevices::jpeg() with type =
	"cairo"
Message-ID: <CAFiqf9wkh7Vjnq7q9x7hqSCqVofegWKyv-ObUcit6gbWGMrsVQ@mail.gmail.com>

Hi,
I have been having issues producing plots in JPEG format, using type =
"cairo" to get better anti-aliasing. When trying to set the physical
size with units = "cm" or units = "mm", the width is set correctly but
the height is not - it looks like the height is simply treated as
pixels regardless of the 'units' argument.

Example:


x = 1:10
y = 2 * x
jpeg("ExamplePlot.jpg",
     type = "cairo",
     width = 200,
     height = 200,
     units = "mm",
     res = 96)
plot(x, y)
dev.off()


On my system (Windows 7, running R 3.4.2), this produces a plot that
is 755 x 200 pixels, and is vertically very squashed.

Looking at grDevices::jpeg, it looks like the culprit is these lines:

   g <- .geometry(width, height, units, res)
    if (match.arg(type) == "cairo") {
        antialias <- match(match.arg(antialias), aa.cairo)
        invisible(.External(C_devCairo, filename, 3L, g$width,
            height, pointsize, bg, res, antialias, quality, if
(nzchar(family)) family else "sans",
            300))
    }

g$width is used, but "height" is used instead of "g$height". I suspect
simply using "g$height" here would fix the issue but have not had time
to test this.

My R.version:

platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          4.2
year           2017
month          09
day            28
svn rev        73368
language       R
version.string R version 3.4.2 (2017-09-28)
nickname       Short Summer

Please let me know if any further information is needed.

Thanks,
Marius


From pdalgd at gmail.com  Tue Nov 28 13:01:24 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 28 Nov 2017 13:01:24 +0100
Subject: [Rd] Discourage the weights= option of lm with summarized data
In-Reply-To: <CACg-3uYd66Wbua3q71Hau4w6gHhJdENrnHVzNU_yd3z4XLa5gw@mail.gmail.com>
References: <CACg-3uaGhq_RX5S7YQVz0KEx6G-MoVaFVXx_MWuP75qaWqw3mQ@mail.gmail.com>
 <3350d9cc415940f39ba36bd65e104ee0@UM-MAIL3216.unimaas.nl>
 <CACg-3uZMSoj5RBkREqzM6Dc-AiqMahHbQPMzP34KgoeQ7UmVHg@mail.gmail.com>
 <E784F4E0-01CE-4A09-8DD8-4F85FAC293AF@gmail.com>
 <CACg-3uYd66Wbua3q71Hau4w6gHhJdENrnHVzNU_yd3z4XLa5gw@mail.gmail.com>
Message-ID: <1678DE0E-9691-4D20-B23C-790DAAB10EE9@gmail.com>

My local R-devel version now has (in ?lm)

     Non-?NULL? ?weights? can be used to indicate that different
     observations have different variances (with the values in
     ?weights? being inversely proportional to the variances); or
     equivalently, when the elements of ?weights? are positive integers
     w_i, that each response y_i is the mean of w_i unit-weight
     observations (including the case that there are w_i observations
     equal to y_i and the data have been summarized). However, in the
     latter case, notice that within-group variation is not used.
     Therefore, the sigma estimate and residual degrees of freedom may
     be suboptimal; in the case of replication weights, even wrong.
     Hence, standard errors and analysis of variance tables should be
     treated with care.

OK?


-pd


> On 12 Oct 2017, at 13:48 , Arie ten Cate <arietencate at gmail.com> wrote:
> 
> OK. We have now three suggestions to repair the text:
> - remove the text
> - add "not" at the beginning of the text
> - add at the end of the text a warning; something like:
> 
>  "Note that in this case the standard estimates of the parameters are
> in general not correct, and hence also the t values and the p value.
> Also the number of degrees of freedom is not correct. (The parameter
> values are correct.)"
> 
> A remark about the glm example: the Reference manual says: "For a
> binomial GLM prior weights are used to give the number of trials when
> the response is the proportion of successes ....".  Hence in the
> binomial case the weights are frequencies.
> With y <- 0.51 and w <- 100 you get the same result.
> 
>   Arie
> 
> On Mon, Oct 9, 2017 at 5:22 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> AFAIR, it is a little more subtle than that.
>> 
>> If you have replication weights, then the estimates are right, it is "just" that the SE from summary.lm() are wrong. Somehow, the text should reflect this.
>> 
>> It is of some importance when you put glm() into the mix, because you can in fact get correct results from things like
>> 
>> y <- c(0,1)
>> w <- c(49,51)
>> glm(y~1, weights=w, family=binomial)
>> 
>> -pd
>> 
>>> On 9 Oct 2017, at 07:58 , Arie ten Cate <arietencate at gmail.com> wrote:
>>> 
>>> Yes.  Thank you; I should have quoted it.
>>> I suggest to remove this text or to add the word "not" at the beginning.
>>> 
>>>  Arie
>>> 
>>> On Sun, Oct 8, 2017 at 4:38 PM, Viechtbauer Wolfgang (SP)
>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>> Ah, I think you are referring to this part from ?lm:
>>>> 
>>>> "(including the case that there are w_i observations equal to y_i and the data have been summarized)"
>>>> 
>>>> I see; indeed, I don't think this is what 'weights' should be used for (the other part before that is correct). Sorry, I misunderstood the point you were trying to make.
>>>> 
>>>> Best,
>>>> Wolfgang
>>>> 
>>>> -----Original Message-----
>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>> Sent: Sunday, 08 October, 2017 14:55
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>> 
>>>> Indeed: Using 'weights' is not meant to indicate that the same
>>>> observation is repeated 'n' times.  As I showed, this gives erroneous
>>>> results. Hence I suggested that it is discouraged rather than
>>>> encouraged in the Details section of lm in the Reference manual.
>>>> 
>>>>  Arie
>>>> 
>>>> ---Original Message-----
>>>> On Sat, 7 Oct 2017, wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
>>>> 
>>>> Using 'weights' is not meant to indicate that the same observation is
>>>> repeated 'n' times. It is meant to indicate different variances (or to
>>>> be precise, that the variance of the last observation in 'x' is
>>>> sigma^2 / n, while the first three observations have variance
>>>> sigma^2).
>>>> 
>>>> Best,
>>>> Wolfgang
>>>> 
>>>> -----Original Message-----
>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Arie ten Cate
>>>> Sent: Saturday, 07 October, 2017 9:36
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Discourage the weights= option of lm with summarized data
>>>> 
>>>> In the Details section of lm (linear models) in the Reference manual,
>>>> it is suggested to use the weights= option for summarized data. This
>>>> must be discouraged rather than encouraged. The motivation for this is
>>>> as follows.
>>>> 
>>>> With summarized data the standard errors get smaller with increasing
>>>> numbers of observations. However, the standard errors in lm do not get
>>>> smaller when for instance all weights are multiplied with the same
>>>> constant larger than one, since the inverse weights are merely
>>>> proportional to the error variances.
>>>> 
>>>> Here is an example of the estimated standard errors being too large
>>>> with the weights= option. The p value and the number of degrees of
>>>> freedom are also wrong. The parameter estimates are correct.
>>>> 
>>>> n <- 10
>>>> x <- c(1,2,3,4)
>>>> y <- c(1,2,5,4)
>>>> w <- c(1,1,1,n)
>>>> xb <- c(x,rep(x[4],n-1))  # restore the original data
>>>> yb <- c(y,rep(y[4],n-1))
>>>> print(summary(lm(yb ~ xb)))
>>>> print(summary(lm(y ~ x, weights=w)))
>>>> 
>>>> Compare with PROC REG in SAS, with a WEIGHT statement (like R) and a
>>>> FREQ statement (for summarized data).
>>>> 
>>>>   Arie
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tdhock5 at gmail.com  Wed Nov 29 16:25:33 2017
From: tdhock5 at gmail.com (Toby Hocking)
Date: Wed, 29 Nov 2017 10:25:33 -0500
Subject: [Rd] Un-informative Error in re-building vignettes
Message-ID: <CALK03d2O6EXqog74vsUsnMop6cLhFHPD=J4A3L4xKntfM+hqdQ@mail.gmail.com>

I am getting the following on CRAN windows and winbuilder
https://www.r-project.org/nosvn/R.check/r-devel-windows-ix86+x86_64/penaltyLearning-00check.html

Apparently there is an error in re-building vignettes, but I do not have
any idea what it is, because all that is listed is three dots (...). Is
this a bug in R CMD check?

If not, the only solution I can think of is removing the vignette entirely.
Any other ideas?

   - checking re-building of vignette outputs ... [11s] WARNING
   Error in re-building vignettes:
     ...
   - checking PDF version of manual ... OK

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Nov 29 16:43:34 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 29 Nov 2017 10:43:34 -0500
Subject: [Rd] Un-informative Error in re-building vignettes
In-Reply-To: <CALK03d2O6EXqog74vsUsnMop6cLhFHPD=J4A3L4xKntfM+hqdQ@mail.gmail.com>
References: <CALK03d2O6EXqog74vsUsnMop6cLhFHPD=J4A3L4xKntfM+hqdQ@mail.gmail.com>
Message-ID: <0A146974-8F86-44CC-A248-765C0FEF6B66@me.com>



> On Nov 29, 2017, at 10:25 AM, Toby Hocking <tdhock5 at gmail.com> wrote:
> 
> I am getting the following on CRAN windows and winbuilder
> https://www.r-project.org/nosvn/R.check/r-devel-windows-ix86+x86_64/penaltyLearning-00check.html
> 
> Apparently there is an error in re-building vignettes, but I do not have
> any idea what it is, because all that is listed is three dots (...). Is
> this a bug in R CMD check?
> 
> If not, the only solution I can think of is removing the vignette entirely.
> Any other ideas?
> 
>   - checking re-building of vignette outputs ... [11s] WARNING
>   Error in re-building vignettes:
>     ...
>   - checking PDF version of manual ... OK


Hi,

First, generally CRAN package building related issues should be posted to R-Package-Devel, not here:

  https://stat.ethz.ch/mailman/listinfo/r-package-devel <https://stat.ethz.ch/mailman/listinfo/r-package-devel>

Second, you might want to review the full CRAN build report for your package, which reports more information across several builds:

https://cran.r-project.org/web/checks/check_results_penaltyLearning.html <https://cran.r-project.org/web/checks/check_results_penaltyLearning.html>

Regards,

Marc Schwartz



	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Wed Nov 29 19:13:47 2017
From: hpages at fredhutch.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 29 Nov 2017 10:13:47 -0800
Subject: [Rd] binary form of is() contradicts its unary form
Message-ID: <5A1EF8DB.6080401@fredhutch.org>

Hi,

The unary forms of is() and extends() report that data.frame
extends list, oldClass, and vector:

   > is(data.frame())
   [1] "data.frame" "list"       "oldClass"   "vector"

   > extends("data.frame")
   [1] "data.frame" "list"       "oldClass"   "vector"

However, the binary form of is() disagrees:

   > is(data.frame(), "list")
   [1] FALSE
   > is(data.frame(), "oldClass")
   [1] FALSE
   > is(data.frame(), "vector")
   [1] FALSE

while the binary form of extends() agrees:

   > extends("data.frame", "list")
   [1] TRUE
   > extends("data.frame", "oldClass")
   [1] TRUE
   > extends("data.frame", "vector")
   [1] TRUE

Who is right?

Shouldn't 'is(object, class2)' be equivalent
to 'class2 %in% is(object)'? Furthermore, is there
any reason why 'is(object, class2)' is not implemented
as 'class2 %in% is(object)'?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From mehmet.suzen at gmail.com  Wed Nov 29 20:22:25 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Wed, 29 Nov 2017 20:22:25 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <5A1EF8DB.6080401@fredhutch.org>
References: <5A1EF8DB.6080401@fredhutch.org>
Message-ID: <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>

Hi Herve,

I think you are confusing subclasses and classes. There is no
contradiction. `is` documentation
is very clear:

`With one argument, returns all the super-classes of this object's class.`

Note that object class is always `data.frame` here, check:

> class(data.frame())
[1] "data.frame"
> is(data.frame(), "data.frame")
[1] TRUE

Best,
Mehmet





On 29 Nov 2017 19:13, "Herv? Pag?s" <hpages at fredhutch.org> wrote:

> Hi,
>
> The unary forms of is() and extends() report that data.frame
> extends list, oldClass, and vector:
>
>   > is(data.frame())
>   [1] "data.frame" "list"       "oldClass"   "vector"
>
>   > extends("data.frame")
>   [1] "data.frame" "list"       "oldClass"   "vector"
>
> However, the binary form of is() disagrees:
>
>   > is(data.frame(), "list")
>   [1] FALSE
>   > is(data.frame(), "oldClass")
>   [1] FALSE
>   > is(data.frame(), "vector")
>   [1] FALSE
>
> while the binary form of extends() agrees:
>
>   > extends("data.frame", "list")
>   [1] TRUE
>   > extends("data.frame", "oldClass")
>   [1] TRUE
>   > extends("data.frame", "vector")
>   [1] TRUE
>
> Who is right?
>
> Shouldn't 'is(object, class2)' be equivalent
> to 'class2 %in% is(object)'? Furthermore, is there
> any reason why 'is(object, class2)' is not implemented
> as 'class2 %in% is(object)'?
>
> Thanks,
> H.
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Canc
> <https://maps.google.com/?q=Fred+Hutchinson+Canc&entry=gmail&source=g>er
> Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Wed Nov 29 20:46:59 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 29 Nov 2017 11:46:59 -0800
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
Message-ID: <5A1F0EB3.7090508@fredhutch.org>

Hi Mehmet,

On 11/29/2017 11:22 AM, Suzen, Mehmet wrote:
> Hi Herve,
>
> I think you are confusing subclasses and classes. There is no
> contradiction. `is` documentation
> is very clear:
>
> `With one argument, returns all the super-classes of this object's class.`

Yes that's indeed very clear. So if "list" is a super-class
of "data.frame" (as reported by is(data.frame())), then
is(data.frame(), "list") should be TRUE.

With S4 classes:

   setClass("A")
   setClass("B", contains="A")

   ## Get all the super-classes of B.
   is(new("B"))
   # [1] "B" "A"

   ## Does a B object inherit from A?
   is(new("B"), "A")
   # [1] TRUE

Cheers,
H.

>
> Note that object class is always `data.frame` here, check:
>
>  > class(data.frame())
> [1] "data.frame"
>  > is(data.frame(), "data.frame")
> [1] TRUE
>
> Best,
> Mehmet
>
>
>
>
>
> On 29 Nov 2017 19:13, "Herv? Pag?s" <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     Hi,
>
>     The unary forms of is() and extends() report that data.frame
>     extends list, oldClass, and vector:
>
>        > is(data.frame())
>        [1] "data.frame" "list"       "oldClass"   "vector"
>
>        > extends("data.frame")
>        [1] "data.frame" "list"       "oldClass"   "vector"
>
>     However, the binary form of is() disagrees:
>
>        > is(data.frame(), "list")
>        [1] FALSE
>        > is(data.frame(), "oldClass")
>        [1] FALSE
>        > is(data.frame(), "vector")
>        [1] FALSE
>
>     while the binary form of extends() agrees:
>
>        > extends("data.frame", "list")
>        [1] TRUE
>        > extends("data.frame", "oldClass")
>        [1] TRUE
>        > extends("data.frame", "vector")
>        [1] TRUE
>
>     Who is right?
>
>     Shouldn't 'is(object, class2)' be equivalent
>     to 'class2 %in% is(object)'? Furthermore, is there
>     any reason why 'is(object, class2)' is not implemented
>     as 'class2 %in% is(object)'?
>
>     Thanks,
>     H.
>
>     --
>     Herv? Pag?s
>
>     Program in Computational Biology
>     Division of Public Health Sciences
>     Fred Hutchinson Canc
>     <https://urldefense.proofpoint.com/v2/url?u=https-3A__maps.google.com_-3Fq-3DFred-2BHutchinson-2BCanc-26entry-3Dgmail-26source-3Dg&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=sTr3VPPxYCZLOtlBS3DToP4-Wi44EOLs99gJcV932b0&e=>er
>     Research Center
>     1100 Fairview Ave. N, M1-B514
>     P.O. Box 19024
>     Seattle, WA 98109-1024
>
>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     Phone:  (206) 667-5791
>     Fax:    (206) 667-1319
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=OzNPwqjAWVsXOGKMCmd4Fa7Udcm21ewfJmUN78LenQY&e=>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From mehmet.suzen at gmail.com  Wed Nov 29 21:21:44 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Wed, 29 Nov 2017 21:21:44 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <5A1F0EB3.7090508@fredhutch.org>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
Message-ID: <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>

Hi Herve,

Interesting observation with `setClass` but it is for S4.  It looks
like `data.frame()` is not an S4 class.

> isS4(data.frame())
[1] FALSE

And in your case this might help:

> is(asS4(data.frame()), "list")
[1] TRUE

Looks like `is` is designed for S4 classes, I am not entirely sure.

Best,
-Mehmet

On 29 November 2017 at 20:46, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi Mehmet,
>
> On 11/29/2017 11:22 AM, Suzen, Mehmet wrote:
>>
>> Hi Herve,
>>
>> I think you are confusing subclasses and classes. There is no
>> contradiction. `is` documentation
>> is very clear:
>>
>> `With one argument, returns all the super-classes of this object's class.`
>
>
> Yes that's indeed very clear. So if "list" is a super-class
> of "data.frame" (as reported by is(data.frame())), then
> is(data.frame(), "list") should be TRUE.
>
> With S4 classes:
>
>   setClass("A")
>   setClass("B", contains="A")
>
>   ## Get all the super-classes of B.
>   is(new("B"))
>   # [1] "B" "A"
>
>   ## Does a B object inherit from A?
>   is(new("B"), "A")
>   # [1] TRUE
>
> Cheers,
> H.
>
>>
>> Note that object class is always `data.frame` here, check:
>>
>>  > class(data.frame())
>> [1] "data.frame"
>>  > is(data.frame(), "data.frame")
>> [1] TRUE
>>
>> Best,
>> Mehmet
>>
>>
>>
>>
>>
>> On 29 Nov 2017 19:13, "Herv? Pag?s" <hpages at fredhutch.org
>> <mailto:hpages at fredhutch.org>> wrote:
>>
>>     Hi,
>>
>>     The unary forms of is() and extends() report that data.frame
>>     extends list, oldClass, and vector:
>>
>>        > is(data.frame())
>>        [1] "data.frame" "list"       "oldClass"   "vector"
>>
>>        > extends("data.frame")
>>        [1] "data.frame" "list"       "oldClass"   "vector"
>>
>>     However, the binary form of is() disagrees:
>>
>>        > is(data.frame(), "list")
>>        [1] FALSE
>>        > is(data.frame(), "oldClass")
>>        [1] FALSE
>>        > is(data.frame(), "vector")
>>        [1] FALSE
>>
>>     while the binary form of extends() agrees:
>>
>>        > extends("data.frame", "list")
>>        [1] TRUE
>>        > extends("data.frame", "oldClass")
>>        [1] TRUE
>>        > extends("data.frame", "vector")
>>        [1] TRUE
>>
>>     Who is right?
>>
>>     Shouldn't 'is(object, class2)' be equivalent
>>     to 'class2 %in% is(object)'? Furthermore, is there
>>     any reason why 'is(object, class2)' is not implemented
>>     as 'class2 %in% is(object)'?
>>
>>     Thanks,
>>     H.
>>
>>     --
>>     Herv? Pag?s
>>
>>     Program in Computational Biology
>>     Division of Public Health Sciences
>>     Fred Hutchinson Canc
>>
>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__maps.google.com_-3Fq-3DFred-2BHutchinson-2BCanc-26entry-3Dgmail-26source-3Dg&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=sTr3VPPxYCZLOtlBS3DToP4-Wi44EOLs99gJcV932b0&e=>er
>>     Research Center
>>     1100 Fairview Ave. N, M1-B514
>>     P.O. Box 19024
>>     Seattle, WA 98109-1024
>>
>>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>     Phone:  (206) 667-5791
>>     Fax:    (206) 667-1319
>>
>>     ______________________________________________
>>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=OzNPwqjAWVsXOGKMCmd4Fa7Udcm21ewfJmUN78LenQY&e=>
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Nov 29 21:45:20 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 29 Nov 2017 12:45:20 -0800
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
Message-ID: <5A1F1C60.9080506@fredhutch.org>

Yes, data.frame is not an S4 class but is(data.frame())
finds its super-classes anyway and without the need to wrap
it in asS4(). And "list' is one of the super-classes. Then
is(data.frame(), "list") contradicts this.

I'm not asking for a workaround. I already have one with
'class2 %in% is(object)' as reported in my original post.
'is(asS4(object), class2)' is maybe another one but, unlike
the former, it's not obvious that it will behave consistently
with unary is(). There could be some other surprise on the
way.

You're missing the point of my original post. Which is that
there is a serious inconsistency between the unary and binary
forms of is(). Maybe the binary form is right in case of
is(data.frame(), "list"). But then the unary form should not
return "list'. This inconsistency will potentially hurt anybody
who tries to do computations on a class hierarchy, especially
if the hierarchy is complex and mixes S4 and S3 classes. So I'm
hoping this can be addressed. Hope you understand.

Cheers,
H.


On 11/29/2017 12:21 PM, Suzen, Mehmet wrote:
> Hi Herve,
>
> Interesting observation with `setClass` but it is for S4.  It looks
> like `data.frame()` is not an S4 class.
>
>> isS4(data.frame())
> [1] FALSE
>
> And in your case this might help:
>
>> is(asS4(data.frame()), "list")
> [1] TRUE
>
> Looks like `is` is designed for S4 classes, I am not entirely sure.
>
> Best,
> -Mehmet
>
> On 29 November 2017 at 20:46, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> Hi Mehmet,
>>
>> On 11/29/2017 11:22 AM, Suzen, Mehmet wrote:
>>>
>>> Hi Herve,
>>>
>>> I think you are confusing subclasses and classes. There is no
>>> contradiction. `is` documentation
>>> is very clear:
>>>
>>> `With one argument, returns all the super-classes of this object's class.`
>>
>>
>> Yes that's indeed very clear. So if "list" is a super-class
>> of "data.frame" (as reported by is(data.frame())), then
>> is(data.frame(), "list") should be TRUE.
>>
>> With S4 classes:
>>
>>    setClass("A")
>>    setClass("B", contains="A")
>>
>>    ## Get all the super-classes of B.
>>    is(new("B"))
>>    # [1] "B" "A"
>>
>>    ## Does a B object inherit from A?
>>    is(new("B"), "A")
>>    # [1] TRUE
>>
>> Cheers,
>> H.
>>
>>>
>>> Note that object class is always `data.frame` here, check:
>>>
>>>   > class(data.frame())
>>> [1] "data.frame"
>>>   > is(data.frame(), "data.frame")
>>> [1] TRUE
>>>
>>> Best,
>>> Mehmet
>>>
>>>
>>>
>>>
>>>
>>> On 29 Nov 2017 19:13, "Herv? Pag?s" <hpages at fredhutch.org
>>> <mailto:hpages at fredhutch.org>> wrote:
>>>
>>>      Hi,
>>>
>>>      The unary forms of is() and extends() report that data.frame
>>>      extends list, oldClass, and vector:
>>>
>>>         > is(data.frame())
>>>         [1] "data.frame" "list"       "oldClass"   "vector"
>>>
>>>         > extends("data.frame")
>>>         [1] "data.frame" "list"       "oldClass"   "vector"
>>>
>>>      However, the binary form of is() disagrees:
>>>
>>>         > is(data.frame(), "list")
>>>         [1] FALSE
>>>         > is(data.frame(), "oldClass")
>>>         [1] FALSE
>>>         > is(data.frame(), "vector")
>>>         [1] FALSE
>>>
>>>      while the binary form of extends() agrees:
>>>
>>>         > extends("data.frame", "list")
>>>         [1] TRUE
>>>         > extends("data.frame", "oldClass")
>>>         [1] TRUE
>>>         > extends("data.frame", "vector")
>>>         [1] TRUE
>>>
>>>      Who is right?
>>>
>>>      Shouldn't 'is(object, class2)' be equivalent
>>>      to 'class2 %in% is(object)'? Furthermore, is there
>>>      any reason why 'is(object, class2)' is not implemented
>>>      as 'class2 %in% is(object)'?
>>>
>>>      Thanks,
>>>      H.
>>>
>>>      --
>>>      Herv? Pag?s
>>>
>>>      Program in Computational Biology
>>>      Division of Public Health Sciences
>>>      Fred Hutchinson Canc
>>>
>>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__maps.google.com_-3Fq-3DFred-2BHutchinson-2BCanc-26entry-3Dgmail-26source-3Dg&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=sTr3VPPxYCZLOtlBS3DToP4-Wi44EOLs99gJcV932b0&e=>er
>>>      Research Center
>>>      1100 Fairview Ave. N, M1-B514
>>>      P.O. Box 19024
>>>      Seattle, WA 98109-1024
>>>
>>>      E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>>      Phone:  (206) 667-5791
>>>      Fax:    (206) 667-1319
>>>
>>>      ______________________________________________
>>>      R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>      https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=Edo4xQQyNSdlhiJjtVDnOcunTA8a6KT5EN7_jowitP8&s=ES11eQ8qMdiYMc5X-SbEfQyy2VoX6MUfX0skN-QWunc&e=
>>>
>>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=AptypGUf1qnpkFcOc1eU_vdGSHsush3RGVUyjk7yDu8&s=OzNPwqjAWVsXOGKMCmd4Fa7Udcm21ewfJmUN78LenQY&e=>
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From mehmet.suzen at gmail.com  Thu Nov 30 03:14:49 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Thu, 30 Nov 2017 03:14:49 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <5A1F1C60.9080506@fredhutch.org>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
Message-ID: <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>

On 29 November 2017 at 21:45, Herv? Pag?s <hpages at fredhutch.org> wrote:
> You're missing the point of my original post. Which is that
> there is a serious inconsistency between the unary and binary
> forms of is(). Maybe the binary form is right in case of

My understanding is that there is no inconsistency. `is` does what it
claims, from the documentation:

?is?: With two arguments, tests whether ?object? can be treated as
          from ?class2?.

          With one argument, returns all the super-classes of this
          object's class.

Important verb there is 'can be treated as from' with two arguments. So,
one can not treat `data.frame` as from 'list' class in a simple sense,
even though it inherits
from list. The complication is that list is a Primitive and this is
not coming from a
clean S4 hierarchy c.f, your A, B example.

Also, strictly speaking, having super-classes resolved does not
automatically qualify an
assumption that the object can be treated as a class of one of its
super-classes.

Cheers,
Mehmet


From i.ucar86 at gmail.com  Thu Nov 30 11:37:02 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 30 Nov 2017 11:37:02 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
Message-ID: <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>

2017-11-30 3:14 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
> My understanding is that there is no inconsistency. `is` does what it
> claims, from the documentation:
>
> ?is?: With two arguments, tests whether ?object? can be treated as
>           from ?class2?.
>
>           With one argument, returns all the super-classes of this
>           object's class.

Note that this is not in the documentation since a year ago.

I?aki


From mehmet.suzen at gmail.com  Thu Nov 30 13:26:14 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Thu, 30 Nov 2017 13:26:14 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
Message-ID: <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>

On 30 November 2017 at 11:37, I?aki ?car <i.ucar86 at gmail.com> wrote:
> 2017-11-30 3:14 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
>> My understanding is that there is no inconsistency. `is` does what it
>> claims, from the documentation:
>>
>> ?is?: With two arguments, tests whether ?object? can be treated as
>>           from ?class2?.
>>
>>           With one argument, returns all the super-classes of this
>>           object's class.
>
> Note that this is not in the documentation since a year ago.
>

As far as I understood and gather, starting from methods v3.3.2, the following
new reference is added:

* Chambers, John M. (2016) Extending R, Chapman & Hall. (Chapters 9 and 10.)

Pushing that details there, I assume.

Best,
Mehmet


From i.ucar86 at gmail.com  Thu Nov 30 14:04:37 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 30 Nov 2017 14:04:37 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
Message-ID: <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>

2017-11-30 13:26 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
> On 30 November 2017 at 11:37, I?aki ?car <i.ucar86 at gmail.com> wrote:
>> 2017-11-30 3:14 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
>>> My understanding is that there is no inconsistency. `is` does what it
>>> claims, from the documentation:
>>>
>>> ?is?: With two arguments, tests whether ?object? can be treated as
>>>           from ?class2?.
>>>
>>>           With one argument, returns all the super-classes of this
>>>           object's class.
>>
>> Note that this is not in the documentation since a year ago.
>>
>
> As far as I understood and gather, starting from methods v3.3.2, the following
> new reference is added:
>
> * Chambers, John M. (2016) Extending R, Chapman & Hall. (Chapters 9 and 10.)
>
> Pushing that details there, I assume.

Am I supposed to read every reference on a man page just to know what
to expect from a function?

I?aki


From mehmet.suzen at gmail.com  Thu Nov 30 14:13:15 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Thu, 30 Nov 2017 14:13:15 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
Message-ID: <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>

On 30 November 2017 at 14:04, I?aki ?car <i.ucar86 at gmail.com> wrote:
>
> Am I supposed to read every reference on a man page just to know what
> to expect from a function?
>

If the reference is from John Chamber, you are supposed to read it.
It is not always possible for maintainers to document everything on a man page.


From i.ucar86 at gmail.com  Thu Nov 30 14:32:12 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 30 Nov 2017 14:32:12 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
 <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
Message-ID: <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>

2017-11-30 14:13 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
> On 30 November 2017 at 14:04, I?aki ?car <i.ucar86 at gmail.com> wrote:
>>
>> Am I supposed to read every reference on a man page just to know what
>> to expect from a function?
>>
>
> If the reference is from John Chamber, you are supposed to read it.

As a joke, it's funny.

> It is not always possible for maintainers to document everything on a man page.

My only point is that Herv?'s concern is perfectly legitimate given
the output of "?is". Whether the inconsistency is in the behaviour of
the function or in the documentation, that I don't know. Personally, I
think that having two functions (is, extends) with exactly the same
output wouldn't be very practical. But it's a fact that the difference
is not currently addressed in the man page.

I?aki


From maechler at stat.math.ethz.ch  Thu Nov 30 15:45:03 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 Nov 2017 15:45:03 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
 <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
 <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
Message-ID: <23072.6511.695333.220629@stat.math.ethz.ch>

>>>>> I?aki ?car <i.ucar86 at gmail.com>
>>>>>     on Thu, 30 Nov 2017 14:32:12 +0100 writes:

    > 2017-11-30 14:13 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
    >> On 30 November 2017 at 14:04, I?aki ?car <i.ucar86 at gmail.com> wrote:
    >>> 
    >>> Am I supposed to read every reference on a man page just to know what
    >>> to expect from a function?
    >>> 
    >> 
    >> If the reference is from John Chamber, you are supposed to read it.
                       (note: it is  Chamber*s* )

    > As a joke, it's funny.

    >> It is not always possible for maintainers to document everything on a man page.

Correct.  But honestly, I'm not even sure if John Chambers'
change to the help page last October dropped that description of
is() on purpose.   In my eyes, the main change to the help page was to
deemphasize the use of setIs(), and document that separately
(for experts, whereas the doc for is() and extends() is for mere useRs) :

--------------------------------------------------------------------------------
r71460 | jmc | 2016-10-06 20:23:19 +0200 (Thu, 06. Oct 2016) |

   M src/library/methods/man/as.Rd
   M src/library/methods/man/is.Rd
   A src/library/methods/man/setAs.Rd
   A src/library/methods/man/setIs.Rd
   M src/library/methods/man/setMethod.Rd

Further changes to separate user-relevant doc. for is(), as().
Change examples in setMethod() to be acceptable R code 
....
--------------------------------------------------------------------------------

    > My only point is that Herv?'s concern is perfectly legitimate given
    > the output of "?is". 

I'd tend to agree -- but am *not* volunteering to fix it, currently.

    > Whether the inconsistency is in the behaviour of
    > the function or in the documentation, that I don't know. Personally, I
    > think that having two functions (is, extends) with exactly the same
    > output wouldn't be very practical. 

They have different "input", (or---better language-- 'argument's) :

	is(<object>, ..)
   extends(<class>,  ..)

I would also tend to agree with Herv? that the binary and unary
uses of is()  "should be" consistent, as they are for S4, where
indeed, is() stems from.

    > But it's a fact that the difference
    > is not currently addressed in the man page.

correct, too.

    > I?aki


From mehmet.suzen at gmail.com  Thu Nov 30 15:54:04 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Thu, 30 Nov 2017 15:54:04 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
 <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
 <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
Message-ID: <CAPtbhHwsof6RJ7ahrWfQjg7JbohfvHSh+1X1x4KC02xbirZYWg@mail.gmail.com>

On 30 Nov 2017 14:32, "I?aki ?car" <i.ucar86 at gmail.com> wrote:

>>
>> Am I supposed to read every reference on a man page just to know what
>> to expect from a function?
>>
>
> If the reference is from John Chamber, you are supposed to read it.

As a joke, it's funny.



Not a joke. John Chambers is the authority in R object systems. Please do
not mock him or resources pointing to his works.



> It is not always possible for maintainers to document everything on a man
page.

My only point is that Herv?'s concern is perfectly legitimate given
the output of "?is". Whether the inconsistency is in the behaviour of
the function or in the documentation, that I don't know. Personally, I


There is no inconsistency as far as I understood; Data.frame do not have a
pure S4 super-class hierachy.

	[[alternative HTML version deleted]]


From i.ucar86 at gmail.com  Thu Nov 30 16:30:41 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Thu, 30 Nov 2017 16:30:41 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CAPtbhHwsof6RJ7ahrWfQjg7JbohfvHSh+1X1x4KC02xbirZYWg@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
 <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
 <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
 <CAPtbhHwsof6RJ7ahrWfQjg7JbohfvHSh+1X1x4KC02xbirZYWg@mail.gmail.com>
Message-ID: <CALEXWq0UDugLt2MZawPcGcd6cDZz+L7xcxY0_nj82nOsz_oLgA@mail.gmail.com>

2017-11-30 15:54 GMT+01:00 Suzen, Mehmet <mehmet.suzen at gmail.com>:
>
>
> On 30 Nov 2017 14:32, "I?aki ?car" <i.ucar86 at gmail.com> wrote:
>
>>>
>>> Am I supposed to read every reference on a man page just to know what
>>> to expect from a function?
>>>
>>
>> If the reference is from John Chamber, you are supposed to read it.
>
> As a joke, it's funny.
>
>
>
> Not a joke. John Chambers is the authority in R object systems. Please do
> not mock him or resources pointing to his works.

I perfectly know John Chambers' work, thank you, and there was no
mockery towards him.

If you really believe that references should be needed to know what to
expect from a function call, then we work with different definitions
of "manual". But judging from the excellent R documentation, I would
say that the R maintainers don't share your view.

I?aki


From mehmet.suzen at gmail.com  Thu Nov 30 18:06:27 2017
From: mehmet.suzen at gmail.com (Suzen, Mehmet)
Date: Thu, 30 Nov 2017 18:06:27 +0100
Subject: [Rd] binary form of is() contradicts its unary form
In-Reply-To: <CALEXWq0UDugLt2MZawPcGcd6cDZz+L7xcxY0_nj82nOsz_oLgA@mail.gmail.com>
References: <5A1EF8DB.6080401@fredhutch.org>
 <CAPtbhHzXe3=EBW6wwyx1Hh158qjBrC0vfFbh4+o3bRZTC+c5Kw@mail.gmail.com>
 <5A1F0EB3.7090508@fredhutch.org>
 <CAPtbhHws5Fydk0AHeq3Urh9qEZ4XM0C-BJtoRvUpnStb33G=mg@mail.gmail.com>
 <5A1F1C60.9080506@fredhutch.org>
 <CAPtbhHy4=U8V-XRtg63=eS4PAWgqQM6=-xnSmVSgdPFbuv8dxw@mail.gmail.com>
 <CALEXWq3yQadGRyhUmcJ9p7kG=2Jf55=8v-U6tNukRWnZ6_Tpdw@mail.gmail.com>
 <CAPtbhHx+mQtMwVoTYqi4yCFf8EujMdzH+-Ped=Q02uxDhfEP-w@mail.gmail.com>
 <CALEXWq3aHdFmpFq+ehGVGddewXtq1GsS0y5R_5HpCu2eWidtDg@mail.gmail.com>
 <CAPtbhHzO_S-PYMjnXXLO3E9=jakrLtbwzuKCfaYMqigYX=Wndg@mail.gmail.com>
 <CALEXWq3_N5OZvPTC4tuCVRPsPSNV+SHYHiqk66FZczLmdWdohw@mail.gmail.com>
 <CAPtbhHwsof6RJ7ahrWfQjg7JbohfvHSh+1X1x4KC02xbirZYWg@mail.gmail.com>
 <CALEXWq0UDugLt2MZawPcGcd6cDZz+L7xcxY0_nj82nOsz_oLgA@mail.gmail.com>
Message-ID: <CAPtbhHzRdFdvFhrjT3wnHYbUd-N6t67188frM4wwRcCLyo3YbQ@mail.gmail.com>

On 30 November 2017 at 16:30, I?aki ?car <i.ucar86 at gmail.com> wrote:
> If you really believe that references should be needed to know what to
> expect from a function call, then we work with different definitions

A behaviour of a function call might be quite complex depending on
the arguments characteristics,  it may not possible always to boil
down all possible behaviours of a function to a man page as in `?`,
and sometimes giving a reference to a larger exposition makes more
sense.


