From hin-tak.leung at cimr.cam.ac.uk  Thu Feb  1 03:08:15 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 01 Feb 2007 02:08:15 +0000
Subject: [Rd] possible bug: dev.copy / could not find any X11 fonts
In-Reply-To: <45C0CE62.90700@biostat.ku.dk>
References: <20070131145039.GA12289@pu100877.student.princeton.edu>
	<45C0CE62.90700@biostat.ku.dk>
Message-ID: <45C14B8F.5020102@cimr.cam.ac.uk>

Peter Dalgaard wrote:
<snipped>
> Annoying, but your example works for me, so I suspect that the problem 
> is nevertheless a setup issue at your end....   I would guess that the 
> culprit is the tiny font used to label the axes. Things like this 
> sometimes happen when you are missing 75dpi fontset. If you fire up 
> xfontsel, can you find
> 
> -adobe-helvetica-medium-r-*-*-8-*-*-*-*-*-iso8859-1
> 
> ?
> (available pixel sizes should be 8,10,11,12,14,17,18,20,24,25,34)

The examples also works for me, and I was wondering about similiar
issues; but my thought is more along the line of the scalable PS
Type 1 fonts being missing. (The Type 1 fonts is scalable and functions
as catch-all for any size). Given the vintage of it - i486-* probably
indicates that the CPU is pre-pentium or the linux distribution is,
so the X server may not be able to or configured to use PS Type1 fonts.
On my X server I have both the -adobe-helvetica-* bitmap fonts,
and also it as PS Type 1 (The URW clone of the 13 standard
postscript fonts is carried by ghostcript and also occasionally
carried by or made available on some linux distro to Xfree/Xorg)

HTL

>> version information:
>>                _                           
>> platform       i486-pc-linux-gnu           
>> arch           i486                        
>> os             linux-gnu                   
>> system         i486, linux-gnu             
>> status                                     
>> major          2                           
>> minor          4.1                         
>> year           2006                        
>> month          12                          
>> day            18                          
>> svn rev        40228                       
>> language       R                           
>> version.string R version 2.4.1 (2006-12-18)
>>   
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Thu Feb  1 16:16:17 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 01 Feb 2007 07:16:17 -0800
Subject: [Rd] Problems with definitions of S4-generics
In-Reply-To: <C1E66E0D.2458%Beyerj@students.uni-marburg.de>
	(=?iso-8859-1?Q?J=F6rg?= Beyer's message of "Wed, 31 Jan 2007 16:02:21
	+0100")
References: <C1E66E0D.2458%Beyerj@students.uni-marburg.de>
Message-ID: <m2fy9p52ny.fsf@fhcrc.org>

J?rg Beyer <Beyerj at students.uni-marburg.de> writes:

> Hello all, 
>
> I'd like to report a problem related to S4 classes.
>
> Platform: 
> Mac G4/400 PCI (PPC-architecture)
> Mac OS 10.4.8
> R 2.4.1 for Mac OS X (CRAN binary, 2006-12-19) w/ R.app 1.18

I see the same thing using a fairly recent R-devel:


> setGeneric("foobar", function(x) standardGeneric("foobar"))
[1] "foobar"

> removeGeneric("foobar")
[1] TRUE

> getGeneric("foobar")
standardGeneric for "foobar" defined from package ".GlobalEnv"

function (x) 
standardGeneric("foobar")
<environment: 0x5fd6d6c>
Methods may be defined for arguments: x 

+ seth


From marc_schwartz at comcast.net  Thu Feb  1 17:40:31 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 01 Feb 2007 10:40:31 -0600
Subject: [Rd] prop.test.Rd References patch
Message-ID: <1170348031.9954.10.camel@localhost.localdomain>

Hi all,

Presuming that my reply on r-help this morning was correct, attached is
a patch file against the current svn trunk version of prop.test.Rd to
add the references for the methods.

Any corrections are welcome.

Regards,

Marc Schwartz


From marc_schwartz at comcast.net  Thu Feb  1 17:54:51 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 01 Feb 2007 10:54:51 -0600
Subject: [Rd] prop.test.Rd References patch
In-Reply-To: <1170348031.9954.10.camel@localhost.localdomain>
References: <1170348031.9954.10.camel@localhost.localdomain>
Message-ID: <1170348891.9954.18.camel@localhost.localdomain>

On Thu, 2007-02-01 at 10:40 -0600, Marc Schwartz wrote:
> Hi all,
> 
> Presuming that my reply on r-help this morning was correct, attached is
> a patch file against the current svn trunk version of prop.test.Rd to
> add the references for the methods.
> 
> Any corrections are welcome.
> 
> Regards,
> 
> Marc Schwartz

Hmmmm....

Looks like the attachment was stripped. Seems that the file had a
text/x-patch MIME type set.

I can't seem to get the file (even with renaming) to text/plain for some
reason.

So...here is the content pasted in here:

--- prop.test.Rd	2007-02-01 08:31:34.000000000 -0600
+++ prop.test.Rev.Rd	2007-02-01 08:38:58.000000000 -0600
@@ -91,6 +91,19 @@
     whether Yates' continuity correction was applied.}
   \item{data.name}{a character string giving the names of the data.}
 }
+\references{
+  Wilson, E.B. (1927) Probable inference, the law of succession, and
+  statistical inference.
+  \emph{J. Am. Stat. Assoc.}, \bold{22}, 209--212.
+
+  Newcombe R.G. (1998) Two-Sided Confidence Intervals for the Single
+  Proportion: Comparison of Seven Methods.
+  \emph{Statistics in Medicine}, \bold{17} 857--872.
+
+  Newcombe R.G. (1998) Interval Estimation for the Difference Between
+  Independent Proportions: Comparison of Eleven Methods.
+  \emph{Statistics in Medicine}, \bold{17} 873--890.
+}  
 \seealso{\code{\link{binom.test}} for an \emph{exact} test of a binomial
   hypothesis.}
 \examples{


I also uploaded the file to:

  http://home.comcast.net/~marc_schwartz/prop.test.Rd.diff

as a backup.

Regards,

Marc


From maechler at stat.math.ethz.ch  Thu Feb  1 18:40:13 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Feb 2007 18:40:13 +0100
Subject: [Rd] prop.test.Rd References patch
In-Reply-To: <1170348891.9954.18.camel@localhost.localdomain>
References: <1170348031.9954.10.camel@localhost.localdomain>
	<1170348891.9954.18.camel@localhost.localdomain>
Message-ID: <17858.9725.468827.671868@stat.math.ethz.ch>

>>>>> "Marc" == Marc Schwartz <marc_schwartz at comcast.net>
>>>>>     on Thu, 01 Feb 2007 10:54:51 -0600 writes:

    Marc> On Thu, 2007-02-01 at 10:40 -0600, Marc Schwartz
    Marc> wrote:
    >> Hi all,
    >> 
    >> Presuming that my reply on r-help this morning was
    >> correct, attached is a patch file against the current svn
    >> trunk version of prop.test.Rd to add the references for
    >> the methods.
    >> 
    >> Any corrections are welcome.
    >> 
    >> Regards,
    >> 
    >> Marc Schwartz

    Marc> Hmmmm....

    Marc> Looks like the attachment was stripped. Seems that the
    Marc> file had a text/x-patch MIME type set.

Okay, I add this to the list of those that are not stripped.

    Marc> I can't seem to get the file (even with renaming) to
    Marc> text/plain for some reason.

    Marc> So...here is the content pasted in here:

..........

Thank you, Marc!

Martin Maechler, ETH Zurich


From ubk2101 at columbia.edu  Thu Feb  1 19:22:41 2007
From: ubk2101 at columbia.edu (K. B. Udaya)
Date: Thu, 1 Feb 2007 13:22:41 -0500
Subject: [Rd] SEXP i/o, .Call(), and garbage collection.
Message-ID: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>

Apologies for any obtuseness in the following.  We have been working
on Version 2.0 of the randomSurvivalForest CRAN package and we're
encountering a perplexing 'memory not mapped' segfault that we believe
is "influenced" by GC.

We essentially have two R functions, rsf.default(..), and
predict.rsf(..) and two corresponding entry points, rsfGrow(...), and
rsfPredict(...), into our C library.  These entry points are
implemented via the .Call(...) interface.  Inputs to the C code are
vectors of integers and reals in the form of SEXP pointers, and the
outputs for both .Call(...)'s is a SEXP list containing vectors of
integers and reals.

rsf.default(...)  grows a forest of binary trees given survival data,
and predict.rsf(...) takes the forest output from rsf.default(...) and
uses it to predict with a new data set.

Things go fine until we put the system under stress.  We can grow
repeatedly without issues, and predict repeatedly without issues,
using a loop to stress the system.  We detect no memory leaks, and C
stack usage is stable.

However, when we grow and predict alternately within the same loop we
encounter a segfault, randomly in the R functions.  The segfault can
occur after hundreds of iterations, but when gctorture is true, the
segfault usually occurs much sooner.

In the C code, we protect all incoming SEXP objects, though we don't
believe it is necessary for function arguments.  The output objects
are of course protected, and all are balanced with unprotect
statements.

Within the C code, we manage our own memory using malloc(...) and
free(...).  We detect no memory leaks, and our experience has been
that they are relatively easy to detect under stress given the large
memory imprint our data structures typically have.  Stack usage using
Cstack_info() is stable.

For clarity, pseudo code for the trivial stress loop is as follows:

formula = as.formula(Survrsf(time,status)~.))
data(veteran, package="randomSurvivalForest")

for (i in 1:1000) {
  growObject = rsf.default(formula, veteran)
  predictObject = rsf.predict(growObject, veteran)
}

On single iterations, we have carefully examined the output of each
function for coherency.  All vectors are initialized and populated
with valid data.  We can grow repeatedly or predict repeatedly.
However, when the two functions are combined in the same loop, we
consistently segfault with 'memory not mapped' in either R function,
usually in some seemingly random and benign location.  For example:

Growing using  logrank , Iteration  253  ...

*** caught segfault ***
address 0x7dbdda88, cause 'memory not mapped'

Traceback:
1: as.vector(x[, i])
2: as.data.frame.matrix(model.matrix(as.formula(paste("~ -1 +",
paste(c(fNames[1:2], predTempNames), collapse = "+"))), data))
3: as.data.frame(model.matrix(as.formula(paste("~ -1 +",
paste(c(fNames[1:2],     predTempNames), collapse = "+"))), data))
4: rsf.default(formula = formula, data = dataSet, ntree, mtry,
nodesize,     splitrule = splitrule[j], importance = importance,
forest = forest,     do.trace = do.trace, proximity = proximity, ntime
= ntime,     seed = seed, add.noise = add.noise, predictorWt =
predictorWt)
5: rsf(formula = formula, data = dataSet, ntree, mtry, nodesize,
splitrule = splitrule[j], importance = importance, forest = forest,
 do.trace = do.trace, proximity = proximity, ntime = ntime,     seed =
seed, add.noise = add.noise, predictorWt = predictorWt)
6: eval.with.vis(expr, envir, enclos)
7: eval.with.vis(ei, envir)
8: source("stress.R")

We see that we are in the grow phase in the above segfault, that does
not depend on any output SEXP objects that may potentially be corrupt.
 However, the creation of SEXP objects (in the predict call) appears
to be a necessary condition for failure.

We are wondering if there is something fundamentally missing in our
understanding of the interaction between R and C via SEXP objects,
memory allocation, persistency, and any potential garbage collection
that may be occurring.  Any comments would be greatly appreciated.

Our environment is as follows, though we have seen the same behaviour
on an SGI Altix system, a Mac OS X (Intel) system, and with R 2.3.0:

platform       powerpc-apple-darwin8.8.0
arch           powerpc
os             darwin8.8.0
system         powerpc, darwin8.8.0
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)


-- 
ubk

ubk2101 at columbia.edu

Udaya B. Kogalur, Ph.D.
Kogalur Shear Corporation
5425 Nestleway Drive, Suite L1
Clemmons, NC 27012


From hin-tak.leung at cimr.cam.ac.uk  Thu Feb  1 20:01:06 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 01 Feb 2007 19:01:06 +0000
Subject: [Rd] SEXP i/o, .Call(), and garbage collection.
In-Reply-To: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
References: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
Message-ID: <45C238F2.8070900@cimr.cam.ac.uk>

One possible reason for such problems is if you copy the pointers
for say, attributes, classes, names, rather than duplicating them.
With very few exceptions, mostly in classes, no two R objects of
the sort you normally encounter/create/play-with should share *any*
part of their data-structure. e.g. such problem can result if you
assign the row names of the input to the output (even if both have
the same row names).

However, without the actual code, can't tell.

K. B. Udaya wrote:
> Apologies for any obtuseness in the following.  We have been working
> on Version 2.0 of the randomSurvivalForest CRAN package and we're
> encountering a perplexing 'memory not mapped' segfault that we believe
> is "influenced" by GC.
> 
> We essentially have two R functions, rsf.default(..), and
> predict.rsf(..) and two corresponding entry points, rsfGrow(...), and
> rsfPredict(...), into our C library.  These entry points are
> implemented via the .Call(...) interface.  Inputs to the C code are
> vectors of integers and reals in the form of SEXP pointers, and the
> outputs for both .Call(...)'s is a SEXP list containing vectors of
> integers and reals.
> 
> rsf.default(...)  grows a forest of binary trees given survival data,
> and predict.rsf(...) takes the forest output from rsf.default(...) and
> uses it to predict with a new data set.
> 
> Things go fine until we put the system under stress.  We can grow
> repeatedly without issues, and predict repeatedly without issues,
> using a loop to stress the system.  We detect no memory leaks, and C
> stack usage is stable.
> 
> However, when we grow and predict alternately within the same loop we
> encounter a segfault, randomly in the R functions.  The segfault can
> occur after hundreds of iterations, but when gctorture is true, the
> segfault usually occurs much sooner.
> 
> In the C code, we protect all incoming SEXP objects, though we don't
> believe it is necessary for function arguments.  The output objects
> are of course protected, and all are balanced with unprotect
> statements.
> 
> Within the C code, we manage our own memory using malloc(...) and
> free(...).  We detect no memory leaks, and our experience has been
> that they are relatively easy to detect under stress given the large
> memory imprint our data structures typically have.  Stack usage using
> Cstack_info() is stable.
> 
> For clarity, pseudo code for the trivial stress loop is as follows:
> 
> formula = as.formula(Survrsf(time,status)~.))
> data(veteran, package="randomSurvivalForest")
> 
> for (i in 1:1000) {
>   growObject = rsf.default(formula, veteran)
>   predictObject = rsf.predict(growObject, veteran)
> }
> 
> On single iterations, we have carefully examined the output of each
> function for coherency.  All vectors are initialized and populated
> with valid data.  We can grow repeatedly or predict repeatedly.
> However, when the two functions are combined in the same loop, we
> consistently segfault with 'memory not mapped' in either R function,
> usually in some seemingly random and benign location.  For example:
> 
> Growing using  logrank , Iteration  253  ...
> 
> *** caught segfault ***
> address 0x7dbdda88, cause 'memory not mapped'
> 
> Traceback:
> 1: as.vector(x[, i])
> 2: as.data.frame.matrix(model.matrix(as.formula(paste("~ -1 +",
> paste(c(fNames[1:2], predTempNames), collapse = "+"))), data))
> 3: as.data.frame(model.matrix(as.formula(paste("~ -1 +",
> paste(c(fNames[1:2],     predTempNames), collapse = "+"))), data))
> 4: rsf.default(formula = formula, data = dataSet, ntree, mtry,
> nodesize,     splitrule = splitrule[j], importance = importance,
> forest = forest,     do.trace = do.trace, proximity = proximity, ntime
> = ntime,     seed = seed, add.noise = add.noise, predictorWt =
> predictorWt)
> 5: rsf(formula = formula, data = dataSet, ntree, mtry, nodesize,
> splitrule = splitrule[j], importance = importance, forest = forest,
>  do.trace = do.trace, proximity = proximity, ntime = ntime,     seed =
> seed, add.noise = add.noise, predictorWt = predictorWt)
> 6: eval.with.vis(expr, envir, enclos)
> 7: eval.with.vis(ei, envir)
> 8: source("stress.R")
> 
> We see that we are in the grow phase in the above segfault, that does
> not depend on any output SEXP objects that may potentially be corrupt.
>  However, the creation of SEXP objects (in the predict call) appears
> to be a necessary condition for failure.
> 
> We are wondering if there is something fundamentally missing in our
> understanding of the interaction between R and C via SEXP objects,
> memory allocation, persistency, and any potential garbage collection
> that may be occurring.  Any comments would be greatly appreciated.
> 
> Our environment is as follows, though we have seen the same behaviour
> on an SGI Altix system, a Mac OS X (Intel) system, and with R 2.3.0:
> 
> platform       powerpc-apple-darwin8.8.0
> arch           powerpc
> os             darwin8.8.0
> system         powerpc, darwin8.8.0
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
> 
>


From vdergachev at rcgardis.com  Thu Feb  1 20:15:48 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Thu, 1 Feb 2007 14:15:48 -0500
Subject: [Rd] SEXP i/o, .Call(), and garbage collection.
In-Reply-To: <45C238F2.8070900@cimr.cam.ac.uk>
References: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
	<45C238F2.8070900@cimr.cam.ac.uk>
Message-ID: <200702011415.48587.vdergachev@rcgardis.com>

On Thursday 01 February 2007 2:01 pm, Hin-Tak Leung wrote:
> One possible reason for such problems is if you copy the pointers
> for say, attributes, classes, names, rather than duplicating them.
> With very few exceptions, mostly in classes, no two R objects of
> the sort you normally encounter/create/play-with should share *any*
> part of their data-structure. e.g. such problem can result if you
> assign the row names of the input to the output (even if both have
> the same row names).
>

Hmm.. I thought that using setAttrib() would automatically increase the 
reference count, right ?

In particular, I quite often use "pseudo-factor" string vectors - where the 
string objects are passed through cache and reused when forming a string 
vector. The result is true character() type but with considerable memory 
savings. The downside is that R reference count field is usually saturated.

                                best

                                    Vladimir Dergachev


From jhallman at frb.gov  Fri Feb  2 14:59:30 2007
From: jhallman at frb.gov (Jeffrey J. Hallman)
Date: 02 Feb 2007 08:59:30 -0500
Subject: [Rd] Help with OS X (BSD) ps command
Message-ID: <xmr64akoe2l.fsf@mralx1.rsma.frb.gov>

My fame package has a function that checks to see if a FAME SERVER process is
already running.  On Linux, I can do this in one of two ways:

  pid <- Sys.getpid()
  user <- Sys.info()["user"]

  cmd <- paste("pgrep -fU", user, "-P", pid, "'FAME SERVER'")
  fameRunning <- as.logical(length(system(cmd, intern = T)))

or I can use

  cmd <- paste("ps -ef | grep", user, "| grep", pid,
                 "| grep -v grep | grep -c 'FAME SERVER'")
  fameRunning <- as.logical(as.numeric(system(cmd, intern = T)))

Mac OS X does not have pgrep, and being a BSD derivative, takes different
arguments for the 'ps' command.  I don't have access to a BSD machine. Can
someone who does tell me the correct invocation of 'ps' to see if 'user' is
running a 'FAME SERVER' process with the R process as its parent process?

Please don't tell me how to get pgrep for OS X, as my objective here is to
stop the CRAN test machine from complaining about my invalid ps command.

While FAME is not officially supported on OS X, I am told that it can be made
to work there.  Had I not heard this, of course, I could just answer FALSE for
OS X and be done with it.

-- 
Jeff


From ripley at stats.ox.ac.uk  Fri Feb  2 15:36:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Feb 2007 14:36:36 +0000 (GMT)
Subject: [Rd] Help with OS X (BSD) ps command
In-Reply-To: <xmr64akoe2l.fsf@mralx1.rsma.frb.gov>
References: <xmr64akoe2l.fsf@mralx1.rsma.frb.gov>
Message-ID: <Pine.LNX.4.64.0702021424580.29423@gannet.stats.ox.ac.uk>

Most systems do not have pgrep: it is not POSIX.  From Linux:

STANDARDS
        pkill and pgrep were introduced in Sun's Solaris 7.  This implementation is fully
        compatible.


The man pages of Darwin and many other systems are online, and linked from
developer.r-project.org.  You could do what the R developers do, and look 
at them.

However, you seem not to have looked on your own system, as my Linux 'ps' 
man page tells me the BSD syntax, and I can test it on Linux's 'ps'.  I 
guess you want 'ps ux'.


On Fri, 2 Feb 2007, Jeffrey J. Hallman wrote:

> My fame package has a function that checks to see if a FAME SERVER process is
> already running.  On Linux, I can do this in one of two ways:
>
>  pid <- Sys.getpid()
>  user <- Sys.info()["user"]
>
>  cmd <- paste("pgrep -fU", user, "-P", pid, "'FAME SERVER'")
>  fameRunning <- as.logical(length(system(cmd, intern = T)))
>
> or I can use
>
>  cmd <- paste("ps -ef | grep", user, "| grep", pid,
>                 "| grep -v grep | grep -c 'FAME SERVER'")
>  fameRunning <- as.logical(as.numeric(system(cmd, intern = T)))
>
> Mac OS X does not have pgrep, and being a BSD derivative, takes different
> arguments for the 'ps' command.  I don't have access to a BSD machine. Can
> someone who does tell me the correct invocation of 'ps' to see if 'user' is
> running a 'FAME SERVER' process with the R process as its parent process?
>
> Please don't tell me how to get pgrep for OS X, as my objective here is to
> stop the CRAN test machine from complaining about my invalid ps command.
>
> While FAME is not officially supported on OS X, I am told that it can be made
> to work there.  Had I not heard this, of course, I could just answer FALSE for
> OS X and be done with it.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeff.horner at vanderbilt.edu  Fri Feb  2 16:00:29 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 02 Feb 2007 09:00:29 -0600
Subject: [Rd] SEXP i/o, .Call(), and garbage collection.
In-Reply-To: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
References: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
Message-ID: <45C3520D.1030205@vanderbilt.edu>

K. B. Udaya wrote:
> Apologies for any obtuseness in the following.  We have been working
> on Version 2.0 of the randomSurvivalForest CRAN package and we're
> encountering a perplexing 'memory not mapped' segfault that we believe
> is "influenced" by GC.
[...]
> We are wondering if there is something fundamentally missing in our
> understanding of the interaction between R and C via SEXP objects,
> memory allocation, persistency, and any potential garbage collection
> that may be occurring.  Any comments would be greatly appreciated.
> 
> Our environment is as follows, though we have seen the same behaviour
> on an SGI Altix system, a Mac OS X (Intel) system, and with R 2.3.0:

If you can run your code on linux (x86, amd64, ppc32, or ppc64), then 
consider using valgrind for catching memory access problems. You would 
need to recompile R with debugging support (-g) and it would be best to 
compile without optimizations (although -O1 seems to be tolerated).

And running R within valgrind is as simple as:

R -d valgrind --vanilla < script.R

or even interactively with:

R -d valgrind

Best,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From hpages at fhcrc.org  Fri Feb  2 20:43:59 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Fri,  2 Feb 2007 11:43:59 -0800
Subject: [Rd] Inaccuracy in ?convolve
Message-ID: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>

Hi,

Man page for 'convolve' says:

    conj: logical; if 'TRUE', take the complex _conjugate_ before
          back-transforming (default, and used for usual convolution).

The complex conjugate of 'x', of 'y', of both?

In fact it seems that it takes the complex conjugate of 'y' only which
is OK but might be worth mentioning because (1) conj=TRUE is the default
and (2) with this default then convolve(x,y) is not the same as convolve(y,x).
Note that 'convolve' is commutative with conj=FALSE and would be too
if conj=TRUE was taking the complex conjugate of x _and_ y...

Cheers,
H.


From hpages at fhcrc.org  Sat Feb  3 02:03:26 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Feb 2007 17:03:26 -0800
Subject: [Rd] convolve: request for "usual" behaviour + some improvements +
 some fixes
In-Reply-To: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>
References: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>
Message-ID: <45C3DF5E.9000307@fhcrc.org>

Hi again,

There are many problems with current 'convolve' function.
The author of the man page seems to be aware that 'convolve' does _not_ the
usual thing:

  Note that the usual definition of convolution of two sequences 'x'
  and 'y' is given by 'convolve(x, rev(y), type = "o")'.

and indeed, it does not:

  > x <- 1:3
  > y <- 3:1
  > convolve(x, y, type="o")
  [1]  1  4 10 12  9

The "usual" convolution would rather give:

  > convolve(x, rev(y), type="o")
  [1]  3  8 14  8  3

Also the "usual" convolution is commutative:

  > convolve(y, rev(x), type="o")
  [1]  3  8 14  8  3

but convolve is not:

  > convolve(y, x, type="o")
  [1]  9 12 10  4  1

Of course I could write the following wrapper:

  usual_convolve <- function(x, y, ...) convolve(x, rev(y))

to work around those issues but 'convolve' has other problems:

  (1) The input sequences shouldn't need to have the same length when
      type = "circular" (the shortest can be right-padded with 0s up
      to the length of the longest).
  (2) If the input sequences are both integer vectors, then the result
      should be an integer vector too.
  (3) The "filter" feature seems to be broken (it's not even clear
      what it should do or why we need it though):
        > x <- 1:9
        > y <- 1
        > convolve(x, y, type="f")
        Error in convolve(x, y, type = "f") : subscript out of bounds
        > convolve(y, x, type="f")
        numeric(0)
  (4) If you look at the source code, you'll see that 'x' is first left-padded
      with '0's. The "usual" convolution doesn't do that: it always padd
      sequences on the _same_ side (generally on the right).
  (5) It's not clear why we need a 'conj' arg. All what it does is
      take the conjugate of fft(y) before it does the product with fft(x).
      But this has the "non-usual" effect of reverting the expected result:
        > round(convolve(as.integer(c(0,0,0,1)), 1:7, type="o"))
        [1] 0 0 0 7 6 5 4 3 2 1

Here below is my version of 'convolve' just in case. It does the "usual"
convolution plus:
  - no need to have 'x' and 'y' of the same length when 'type' is "circular",
  - when 'x' and 'y' are integer vectors, the output is an integer vector,
  - no more 'conj' arg (not needed, only leads to confusion),
  - when type is "filter", the output sequence is the same as with
    type="open" but is truncated to the length of 'x' (the original signal)
    It can be seen has the result of 'x' filtered by 'y' (the filter).

convolve2 <- function(x, y, type = c("circular", "open", "filter"))
{
    type <- match.arg(type)
    nx <- length(x)
    ny <- length(y)
    if (type == "circular")
        nz <- max(nx, ny)
    else
        nz <- nx + ny - 1
    if (nz > nx)
        x[(nx+1):nz] <- as.integer(0)
    if (nz > ny)
        y[(ny+1):nz] <- as.integer(0)
    fx <- fft(x)
    fy <- fft(y)
    fz <- fx * fy
    z <- fft(fz, inverse=TRUE) / nz
    if (is.numeric(x) && is.numeric(y))
        z <- Re(z)
    if (is.integer(x) && is.integer(y))
        z <- as.integer(round(z))
    if (type == "filter")
        z[1:nx]
    else
        z
}

Cheers,
H.


From hpages at fhcrc.org  Sat Feb  3 06:30:04 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Feb 2007 21:30:04 -0800
Subject: [Rd] convolve: request for "usual" behaviour + some
 improvements + some fixes
In-Reply-To: <45C3DF5E.9000307@fhcrc.org>
References: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>
	<45C3DF5E.9000307@fhcrc.org>
Message-ID: <45C41DDC.2030301@fhcrc.org>

Last but not least: convolve2 can be made 100 times or 1000 times faster
than convolve by choosing a power of 2 for the length of the fft-buffer
(a length of 2^n is the best case for the fft, the worst case being when
the length is a prime number):

> x <- 1:100003
> y <- 1:1
> system.time(cc <- convolve(x, y, type="o")) # uses buffer length of 100003
   user  system elapsed
 76.428   0.016  76.445
> system.time(cc <- convolve2(x, y, type="o")) # uses buffer length of 2^17
   user  system elapsed
  0.164   0.012   0.179

Here is the modified 'convolve2':

convolve2 <- function(x, y, type = c("circular", "open", "filter"))
{
    type <- match.arg(type)
    nx <- length(x)
    ny <- length(y)
    if (type == "circular") {
        nz <- max(nx, ny)
    } else {
        nz0 <- nx + ny - 1
        nz <- 2^ceiling(log2(nz0))
    }
    if (nz > nx)
        x[(nx+1):nz] <- as.integer(0)
    if (nz > ny)
        y[(ny+1):nz] <- as.integer(0)
    fz <- fft(x) * fft(y)
    z <- fft(fz, inverse=TRUE) / nz
    if (type == "open") {
        z <- z[1:nz0]
    } else {
        if (type == "filter")
            z <- z[1:nx]
    }
    if (is.numeric(x) && is.numeric(y))
        z <- Re(z)
    if (is.integer(x) && is.integer(y))
        z <- as.integer(round(z))
    z
}

In fact, it should try to be smarter than that and not use the fft at all
when one of the 2 input sequences is very short (less than 3 or 4) or
e.g. when one is 10000 times shorter than the other one.

Cheers,
H.


Herve Pages wrote:
> Hi again,
> 
> There are many problems with current 'convolve' function.
> The author of the man page seems to be aware that 'convolve' does _not_ the
> usual thing:
> 
>   Note that the usual definition of convolution of two sequences 'x'
>   and 'y' is given by 'convolve(x, rev(y), type = "o")'.
> 
> and indeed, it does not:
> 
>   > x <- 1:3
>   > y <- 3:1
>   > convolve(x, y, type="o")
>   [1]  1  4 10 12  9
> 
> The "usual" convolution would rather give:
> 
>   > convolve(x, rev(y), type="o")
>   [1]  3  8 14  8  3
> 
> Also the "usual" convolution is commutative:
> 
>   > convolve(y, rev(x), type="o")
>   [1]  3  8 14  8  3
> 
> but convolve is not:
> 
>   > convolve(y, x, type="o")
>   [1]  9 12 10  4  1
> 
> Of course I could write the following wrapper:
> 
>   usual_convolve <- function(x, y, ...) convolve(x, rev(y))
> 
> to work around those issues but 'convolve' has other problems:
> 
>   (1) The input sequences shouldn't need to have the same length when
>       type = "circular" (the shortest can be right-padded with 0s up
>       to the length of the longest).
>   (2) If the input sequences are both integer vectors, then the result
>       should be an integer vector too.
>   (3) The "filter" feature seems to be broken (it's not even clear
>       what it should do or why we need it though):
>         > x <- 1:9
>         > y <- 1
>         > convolve(x, y, type="f")
>         Error in convolve(x, y, type = "f") : subscript out of bounds
>         > convolve(y, x, type="f")
>         numeric(0)
>   (4) If you look at the source code, you'll see that 'x' is first left-padded
>       with '0's. The "usual" convolution doesn't do that: it always padd
>       sequences on the _same_ side (generally on the right).
>   (5) It's not clear why we need a 'conj' arg. All what it does is
>       take the conjugate of fft(y) before it does the product with fft(x).
>       But this has the "non-usual" effect of reverting the expected result:
>         > round(convolve(as.integer(c(0,0,0,1)), 1:7, type="o"))
>         [1] 0 0 0 7 6 5 4 3 2 1
> 
> Here below is my version of 'convolve' just in case. It does the "usual"
> convolution plus:
>   - no need to have 'x' and 'y' of the same length when 'type' is "circular",
>   - when 'x' and 'y' are integer vectors, the output is an integer vector,
>   - no more 'conj' arg (not needed, only leads to confusion),
>   - when type is "filter", the output sequence is the same as with
>     type="open" but is truncated to the length of 'x' (the original signal)
>     It can be seen has the result of 'x' filtered by 'y' (the filter).
> 
> convolve2 <- function(x, y, type = c("circular", "open", "filter"))
> {
>     type <- match.arg(type)
>     nx <- length(x)
>     ny <- length(y)
>     if (type == "circular")
>         nz <- max(nx, ny)
>     else
>         nz <- nx + ny - 1
>     if (nz > nx)
>         x[(nx+1):nz] <- as.integer(0)
>     if (nz > ny)
>         y[(ny+1):nz] <- as.integer(0)
>     fx <- fft(x)
>     fy <- fft(y)
>     fz <- fx * fy
>     z <- fft(fz, inverse=TRUE) / nz
>     if (is.numeric(x) && is.numeric(y))
>         z <- Re(z)
>     if (is.integer(x) && is.integer(y))
>         z <- as.integer(round(z))
>     if (type == "filter")
>         z[1:nx]
>     else
>         z
> }
> 
> Cheers,
> H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Sat Feb  3 15:06:34 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 3 Feb 2007 15:06:34 +0100
Subject: [Rd] convolve: request for "usual" behaviour + some
	improvements + some fixes
In-Reply-To: <45C41DDC.2030301@fhcrc.org>
References: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>
	<45C3DF5E.9000307@fhcrc.org> <45C41DDC.2030301@fhcrc.org>
Message-ID: <17860.38634.114087.849247@stat.math.ethz.ch>

Thank you, Herve,

>>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
>>>>>     on Fri, 02 Feb 2007 21:30:04 -0800 writes:

    Herve> Last but not least: convolve2 can be made 100 times or 1000 times faster
    Herve> than convolve by choosing a power of 2 for the length of the fft-buffer
    Herve> (a length of 2^n is the best case for the fft, the worst case being when
    Herve> the length is a prime number):

    >> x <- 1:100003
    >> y <- 1:1
    >> system.time(cc <- convolve(x, y, type="o")) # uses buffer length of 100003
    Herve> user  system elapsed
    Herve> 76.428   0.016  76.445
    >> system.time(cc <- convolve2(x, y, type="o")) # uses buffer length of 2^17
    Herve> user  system elapsed
    Herve> 0.164   0.012   0.179

The typical approach here and definitely the idea of the
original author of convolve() - would be to use  nextn()  here
instead of  "next_power_of_2()".

convolve() is one of the very old R functions stemming from
Auckland already seen in the very first R tarball that's still
available: Dated from June 20, 1995, with most file dates from
Jun 16/17, i.e. really of even older date,  the file src/rrc/fft
(no 'library', noR extension yet) contains definitions for  'fft', 'nextn'
and 'convolve' where the latter was (note the ":=" for what now
would be assignment to the base package)

convolve := function (a, b, conj=F)
{
	na <- length(a)
	nb <- length(b)
	n <- max(na, nb)
	if (nb < n)
		b <- c(b, rep(0, n - nb))
	else if (na < n)
		a <- c(b, rep(0, n - na))
	da <- fft(a)
	db <- fft(b)
	if(conj) {
		a <- da$x * db$x + da$y * db$y
		b <- - da$x * db$y + db$x * da$y
	}
	else {
		a <- da$x * db$x - da$y * db$y
		b <- da$x * db$y + db$x * da$y
	}
	fft(a, b, inv=T)$x
}

and just for historical fun here's the help file in that
cute olde help file format:

TITLE(convolve @ Fast Convolution)
USAGE(
convolve(a, b, conj=false)
)
ARGUMENTS(
ARG(a,b @ the sequences to be convolved.)
ARG(conj @ logical, if true the transform of LANG(b) is conjugated
before back-transformation.)
)
DESCRIPTION(
LANG(convolve) uses the Fast Fourier Transform to compute the
convolution of the sequences given as its arguments.
PARA
Complex conjugation is useful when computing
autocovariances and autocorrelations by fast convolution.
)
REFERENCES(
Brillinger, D. R. (1981).
ITALIC(Time Series: Data Analysis and Theory), Second Edition.
San Francisco: Holden-Day.
)
SEEALSO(
LANG(LINK(fft)), LANG(LINK(nextn)).
)

Later I had added bits to the docu, convolve got the 'type'
argument, Brian also fixed code and amplified the description and provided
the alternative filter()  which had hencefor been recommended
instead of convolve for most applications.

For back-compatibility (and reverence to the very first R code
writers (!?)) we did not change its behavior but rather documented it
more precisely.

I haven't studied the details of all the possible padding
options for a long time, but I remember that 0-padding
(to length 'n' where 'n' is "highly composite") is only
approximately the same as a non-padded version -- since the
Fourier frequencies  2*pi*j/n depend on n.
As you notice, padding is often very recommendable but it's
strictly giving the solution to a different problem.
For that reason, ?convolve has mentioned  nextn() for 12 years
now, but not "urged" the padding

If we would change convolve() to behave more like your proposal
how many user-defined functions and scripts will give wrong
answers if they are not amended?  
Probably only a very small fraction of all existing code (since
convolve() is not in wide use), but that may still be 100's of
cases. So that would need a the new version with a new name
(such as "convolve2" or maybe slightly nicer "convolve.".

Is it worth introducing that and to start deprecating convolve() ?
IIRC, the last time we considered this (several years ago), we
had concluded "no", but maybe it's worth to get rid of this
infelicity rather than to document it in ever more details.

Martin



    Herve> Here is the modified 'convolve2':

    Herve> convolve2 <- function(x, y, type = c("circular", "open", "filter"))
    Herve> {
    Herve> type <- match.arg(type)
    Herve> nx <- length(x)
    Herve> ny <- length(y)
    Herve> if (type == "circular") {
    Herve> nz <- max(nx, ny)
    Herve> } else {
    Herve> nz0 <- nx + ny - 1
    Herve> nz <- 2^ceiling(log2(nz0))
    Herve> }
    Herve> if (nz > nx)
    Herve> x[(nx+1):nz] <- as.integer(0)
    Herve> if (nz > ny)
    Herve> y[(ny+1):nz] <- as.integer(0)
    Herve> fz <- fft(x) * fft(y)
    Herve> z <- fft(fz, inverse=TRUE) / nz
    Herve> if (type == "open") {
    Herve> z <- z[1:nz0]
    Herve> } else {
    Herve> if (type == "filter")
    Herve> z <- z[1:nx]
    Herve> }
    Herve> if (is.numeric(x) && is.numeric(y))
    Herve> z <- Re(z)
    Herve> if (is.integer(x) && is.integer(y))
    Herve> z <- as.integer(round(z))
    Herve> z
    Herve> }

    Herve> In fact, it should try to be smarter than that and not use the fft at all
    Herve> when one of the 2 input sequences is very short (less than 3 or 4) or
    Herve> e.g. when one is 10000 times shorter than the other one.

    Herve> Cheers,
    Herve> H.


    Herve> Herve Pages wrote:
    >> Hi again,
    >> 
    >> There are many problems with current 'convolve' function.
    >> The author of the man page seems to be aware that 'convolve' does _not_ the
    >> usual thing:
    >> 
    >> Note that the usual definition of convolution of two sequences 'x'
    >> and 'y' is given by 'convolve(x, rev(y), type = "o")'.
    >> 
    >> and indeed, it does not:
    >> 
    >> > x <- 1:3
    >> > y <- 3:1
    >> > convolve(x, y, type="o")
    >> [1]  1  4 10 12  9
    >> 
    >> The "usual" convolution would rather give:
    >> 
    >> > convolve(x, rev(y), type="o")
    >> [1]  3  8 14  8  3
    >> 
    >> Also the "usual" convolution is commutative:
    >> 
    >> > convolve(y, rev(x), type="o")
    >> [1]  3  8 14  8  3
    >> 
    >> but convolve is not:
    >> 
    >> > convolve(y, x, type="o")
    >> [1]  9 12 10  4  1
    >> 
    >> Of course I could write the following wrapper:
    >> 
    >> usual_convolve <- function(x, y, ...) convolve(x, rev(y))
    >> 
    >> to work around those issues but 'convolve' has other problems:
    >> 
    >> (1) The input sequences shouldn't need to have the same length when
    >> type = "circular" (the shortest can be right-padded with 0s up
    >> to the length of the longest).
    >> (2) If the input sequences are both integer vectors, then the result
    >> should be an integer vector too.
    >> (3) The "filter" feature seems to be broken (it's not even clear
    >> what it should do or why we need it though):
    >> > x <- 1:9
    >> > y <- 1
    >> > convolve(x, y, type="f")
    >> Error in convolve(x, y, type = "f") : subscript out of bounds
    >> > convolve(y, x, type="f")
    >> numeric(0)
    >> (4) If you look at the source code, you'll see that 'x' is first left-padded
    >> with '0's. The "usual" convolution doesn't do that: it always padd
    >> sequences on the _same_ side (generally on the right).
    >> (5) It's not clear why we need a 'conj' arg. All what it does is
    >> take the conjugate of fft(y) before it does the product with fft(x).
    >> But this has the "non-usual" effect of reverting the expected result:
    >> > round(convolve(as.integer(c(0,0,0,1)), 1:7, type="o"))
    >> [1] 0 0 0 7 6 5 4 3 2 1
    >> 
    >> Here below is my version of 'convolve' just in case. It does the "usual"
    >> convolution plus:
    >> - no need to have 'x' and 'y' of the same length when 'type' is "circular",
    >> - when 'x' and 'y' are integer vectors, the output is an integer vector,
    >> - no more 'conj' arg (not needed, only leads to confusion),
    >> - when type is "filter", the output sequence is the same as with
    >> type="open" but is truncated to the length of 'x' (the original signal)
    >> It can be seen has the result of 'x' filtered by 'y' (the filter).
    >> 
    >> convolve2 <- function(x, y, type = c("circular", "open", "filter"))
    >> {
    >> type <- match.arg(type)
    >> nx <- length(x)
    >> ny <- length(y)
    >> if (type == "circular")
    >> nz <- max(nx, ny)
    >> else
    >> nz <- nx + ny - 1
    >> if (nz > nx)
    >> x[(nx+1):nz] <- as.integer(0)
    >> if (nz > ny)
    >> y[(ny+1):nz] <- as.integer(0)
    >> fx <- fft(x)
    >> fy <- fft(y)
    >> fz <- fx * fy
    >> z <- fft(fz, inverse=TRUE) / nz
    >> if (is.numeric(x) && is.numeric(y))
    >> z <- Re(z)
    >> if (is.integer(x) && is.integer(y))
    >> z <- as.integer(round(z))
    >> if (type == "filter")
    >> z[1:nx]
    >> else
    >> z
    >> }
    >> 
    >> Cheers,
    >> H.
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    Herve> ______________________________________________
    Herve> R-devel at r-project.org mailing list
    Herve> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Sun Feb  4 20:17:51 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Feb 2007 20:17:51 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
Message-ID: <45C6315F.9020209@aon.at>

Dear all,

I am currently learning how to create R packages using C++ classes.
For this purpose I have written a small package MyClass (which I try
to attach since I do not have access to a website).

MyClass has methods WriteFileC() and WriteFileCpp() which implement
C-style and C++-style writing of a table to a file using FILE or
ofstream respectively, and the corresponding R-functions writeFileC.R
and writeFileCpp.R.

While I can compile and execute my package w/o problems on Fedora Core 4,
I can only execute writeFileC.R on my Intel-MacBook Pro, but not 
writeFileCpp.R.
Executing my functions I get the following output:

 > library(MyClass)

Welcome to MyClass
 > writeFileC("myout_fileC.txt")
[1] "outfile =  myout_fileC.txt"
Writing file myout_fileC.txt using C style.
---MyClassA::MyClassA()---------
---MyClassA::WriteFileC---------
<20> records exported.
---MyClassA::~MyClassA()---------
[1] "writeFileC finished"
NULL
 > writeFileCpp("myout_fileCpp.txt")
[1] "outfile =  myout_fileCpp.txt"
Writing file myout_fileCpp.txt using C++ style.
---MyClassA::MyClassA()---------
---MyClassA::WriteFileCpp---------

 *** caught bus error ***
address 0x6, cause 'non-existent physical address'

Traceback:
 1: .C("WriteFileCpp", as.character(outfile), PACKAGE = "MyClass")
 2: writeFileCpp("myout_fileCpp.txt")


While I understand, that C++ iostreams are best avoided, since there is
no guarantee that the output will appear in the R console (as mentioned
on page 62 of R-exts.pdf), I do not understand why I cannot use ofstream,
which is isolated in a C++ method only.

Is there a way how to use ofstream on MacOS X or is this a limit of the
current Mac implementation?

Thank you in advance.
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._

-------------- next part --------------
A non-text attachment was scrubbed...
Name: MyClass_0.1.2.tar.gz
Type: application/x-gzip
Size: 9198 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070204/2e7fb79c/attachment.gz 

From edd at debian.org  Sun Feb  4 20:43:21 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 4 Feb 2007 13:43:21 -0600
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45C6315F.9020209@aon.at>
References: <45C6315F.9020209@aon.at>
Message-ID: <17862.14169.654577.51179@basebud.nulle.part>


On 4 February 2007 at 20:17, cstrato wrote:
| I am currently learning how to create R packages using C++ classes.

Congratulations :)    

[ This reminds me to email Oleg (CC'ed). Oleg, your HOWTO is a very useful.
Would you consider adding a section on Dominick's most excellent RcppTemplate
package which makes writing code to go back and forth between R and C++ soooo
much easier?  ]

| For this purpose I have written a small package MyClass (which I try
| to attach since I do not have access to a website).
[...]
| While I can compile and execute my package w/o problems on Fedora Core 4,

Works for me too on Debian.

[...]
|  > writeFileCpp("myout_fileCpp.txt")
| [1] "outfile =  myout_fileCpp.txt"
| Writing file myout_fileCpp.txt using C++ style.
| ---MyClassA::MyClassA()---------
| ---MyClassA::WriteFileCpp---------
| 
|  *** caught bus error ***
| address 0x6, cause 'non-existent physical address'
| 
| Traceback:
|  1: .C("WriteFileCpp", as.character(outfile), PACKAGE = "MyClass")
|  2: writeFileCpp("myout_fileCpp.txt")
| 
| 
| While I understand, that C++ iostreams are best avoided, since there is
| no guarantee that the output will appear in the R console (as mentioned
| on page 62 of R-exts.pdf), I do not understand why I cannot use ofstream,
| which is isolated in a C++ method only.
| 
| Is there a way how to use ofstream on MacOS X or is this a limit of the
| current Mac implementation?

Can you get to this in a debugger on MacOS X?  Just glancing at your code I
saw nothing obviously sticking out...

Dirk
 
-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From cstrato at aon.at  Sun Feb  4 21:20:26 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Feb 2007 21:20:26 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <17862.14169.654577.51179@basebud.nulle.part>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
Message-ID: <45C6400A.3050700@aon.at>

Dirk Eddelbuettel wrote:
> On 4 February 2007 at 20:17, cstrato wrote:
> | I am currently learning how to create R packages using C++ classes.
>
> Congratulations :)    
>
> [ This reminds me to email Oleg (CC'ed). Oleg, your HOWTO is a very useful.
> Would you consider adding a section on Dominick's most excellent RcppTemplate
> package which makes writing code to go back and forth between R and C++ soooo
> much easier?  ]
>
> | For this purpose I have written a small package MyClass (which I try
> | to attach since I do not have access to a website).
> [...]
> | While I can compile and execute my package w/o problems on Fedora Core 4,
>
> Works for me too on Debian.
>
> [...]
> |  > writeFileCpp("myout_fileCpp.txt")
> | [1] "outfile =  myout_fileCpp.txt"
> | Writing file myout_fileCpp.txt using C++ style.
> | ---MyClassA::MyClassA()---------
> | ---MyClassA::WriteFileCpp---------
> | 
> |  *** caught bus error ***
> | address 0x6, cause 'non-existent physical address'
> | 
> | Traceback:
> |  1: .C("WriteFileCpp", as.character(outfile), PACKAGE = "MyClass")
> |  2: writeFileCpp("myout_fileCpp.txt")
> | 
> | 
> | While I understand, that C++ iostreams are best avoided, since there is
> | no guarantee that the output will appear in the R console (as mentioned
> | on page 62 of R-exts.pdf), I do not understand why I cannot use ofstream,
> | which is isolated in a C++ method only.
> | 
> | Is there a way how to use ofstream on MacOS X or is this a limit of the
> | current Mac implementation?
>
> Can you get to this in a debugger on MacOS X?  Just glancing at your code I
> saw nothing obviously sticking out...
>
> Dirk
>  
>   
Dear Dirk

Thank you for your fast answer.
Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
old-style print commands.
However, here is the output of the crash log from my Mac. Does it help?

**********

Host Name:      coeurebooks-computer
Date/Time:      2007-02-04 18:51:50.233 +0100
OS Version:     10.4.8 (Build 8N1051)
Report Version: 4

Command: R
Path:    /Library/Frameworks/R.framework/Resources/bin/exec/i386/R
Parent:  bash [206]

Version: ??? (???)

PID:    1836
Thread: 0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_PROTECTION_FAILURE (0x0002) at 0x00000006

Thread 0 Crashed:
0   libstdc++.6.dylib     0x020fe231 std::basic_ostream<char, 
std::char_traits<char> >::flush() + 17 (ostream.tcc:395)
1   libstdc++.6.dylib     0x020fe358 std::basic_ostream<char, 
std::char_traits<char> 
 >::sentry::sentry[in-charge](std::basic_ostream<char, 
std::char_traits<char> >&) + 120 (ostream.tcc:56)
2   libstdc++.6.dylib     0x02100b5d std::basic_ostream<char, 
std::char_traits<char> >& std::operator<< <std::char_traits<char> 
 >(std::basic_ostream<char, std::char_traits<char> >&, char const*) + 29 
(ostream.tcc:620)
3   MyClass.so            0x0004a30f MyClassA::WriteFileCpp(char const*) 
+ 335
4   MyClass.so            0x0004a6d0 WriteFileCpp + 80
5   libR.dylib            0x0106c701 do_dotCode + 7789 (dotcode.c:1732)
6   libR.dylib            0x01096a0f Rf_eval + 1530 (eval.c:445)
7   libR.dylib            0x01098b43 do_set + 561 (eval.c:1357)
8   libR.dylib            0x010968b4 Rf_eval + 1183 (eval.c:431)
9   libR.dylib            0x01098be1 do_begin + 62 (eval.c:1108)
10  libR.dylib            0x010968b4 Rf_eval + 1183 (eval.c:431)
11  libR.dylib            0x01099fd6 Rf_applyClosure + 688 (eval.c:614)
12  libR.dylib            0x01096725 Rf_eval + 784 (eval.c:455)
13  libR.dylib            0x010b458c Rf_ReplIteration + 396 (main.c:256)
14  libR.dylib            0x010b48f3 R_ReplConsole + 148 (main.c:306)
15  libR.dylib            0x010b4c30 run_Rmainloop + 91 (main.c:945)
16  libR.dylib            0x010b4c4b Rf_mainloop + 16 (main.c:952)
17  R                     0x00001f64 main + 54 (Rmain.c:35)
18  R                     0x00001f12 _start + 216
19  R                     0x00001e39 start + 41

Thread 0 crashed with X86 Thread State (32-bit):
  eax: 0x00000012    ebx: 0x0004a1cb ecx: 0x0214f178 edx: 0x00000000
  edi: 0xbfffe568    esi: 0x0214f178 ebp: 0xbfffe508 esp: 0xbfffe4f0
   ss: 0x0000001f    efl: 0x00010286 eip: 0x020fe231  cs: 0x00000017
   ds: 0x0000001f     es: 0x0000001f  fs: 0x00000000  gs: 0x00000037

Binary Images Description:
    0x1000 -     0x1fff R     
/Library/Frameworks/R.framework/Resources/bin/exec/i386/R
    0x5000 -     0x6fff libRblas.dylib     
/Library/Frameworks/R.framework/Resources/lib/i386/libRblas.dylib
    0xa000 -    0x11fff libgcc_s.1.0.dylib     
/Library/Frameworks/R.framework/Versions/2.4/Resources/lib/libgcc_s.1.0.dylib
   0x49000 -    0x4afff MyClass.so     
/Users/rabbitus/Library/R/library/MyClass/libs/i386/MyClass.so
   0x53000 -    0x70fff libreadline.5.1.dylib     
/Library/Frameworks/R.framework/Versions/2.4/Resources/lib/libreadline.5.1.dylib
  0x582000 -   0x5cffff libgfortran.0.dylib     
/Library/Frameworks/R.framework/Versions/2.4/Resources/lib/libgfortran.0.dylib
  0x712000 -   0x716fff methods.so     
/Library/Frameworks/R.framework/Resources/library/methods/libs/i386/methods.so
 0x1008000 -  0x11f5fff libR.dylib     
/Library/Frameworks/R.framework/Resources/lib/i386/libR.dylib
 0x1705000 -  0x171ffff grDevices.so     
/Library/Frameworks/R.framework/Resources/library/grDevices/libs/i386/grDevices.so
 0x17d1000 -  0x17d8fff libgcc_s.1.0.dylib     
/usr/local/gcc4.0/lib/libgcc_s.1.0.dylib
 0x2008000 -  0x204ffff stats.so     
/Library/Frameworks/R.framework/Resources/library/stats/libs/i386/stats.so
 0x20bc000 -  0x214dfff libstdc++.6.dylib     
/usr/local/gcc4.0/lib/libstdc++.6.dylib
0x8fe00000 - 0x8fe49fff dyld 46.9    /usr/lib/dyld
0x90000000 - 0x9016ffff libSystem.B.dylib     /usr/lib/libSystem.B.dylib
0x901bf000 - 0x901c1fff libmathCommon.A.dylib     
/usr/lib/system/libmathCommon.A.dylib
0x901c3000 - 0x90200fff com.apple.CoreText 1.1.1 (???)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreText.framework/Versions/A/CoreText
0x90227000 - 0x902fcfff ATS     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS
0x9031c000 - 0x90771fff com.apple.CoreGraphics 1.258.51 (???)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
0x90808000 - 0x908d0fff com.apple.CoreFoundation 6.4.6 (368.27)    
/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation
0x9090e000 - 0x9090efff com.apple.CoreServices 10.4 (???)    
/System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
0x90910000 - 0x90a03fff libicucore.A.dylib     /usr/lib/libicucore.A.dylib
0x90a53000 - 0x90ad2fff libobjc.A.dylib     /usr/lib/libobjc.A.dylib
0x90afb000 - 0x90b5ffff libstdc++.6.dylib     /usr/lib/libstdc++.6.dylib
0x90bce000 - 0x90bd5fff libgcc_s.1.dylib     /usr/lib/libgcc_s.1.dylib
0x90bda000 - 0x90c4dfff com.apple.framework.IOKit 1.4.6 (???)    
/System/Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x90c62000 - 0x90c74fff libauto.dylib     /usr/lib/libauto.dylib
0x90c7a000 - 0x90f20fff com.apple.CoreServices.CarbonCore 682.15    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore
0x90f63000 - 0x90fcbfff com.apple.CoreServices.OSServices 4.1    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices
0x91004000 - 0x91042fff com.apple.CFNetwork 129.18    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CFNetwork.framework/Versions/A/CFNetwork
0x91055000 - 0x91065fff com.apple.WebServices 1.1.3 (1.1.0)    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/WebServicesCore.framework/Versions/A/WebServicesCore
0x91070000 - 0x910effff com.apple.SearchKit 1.0.5    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit
0x91129000 - 0x91147fff com.apple.Metadata 10.4.4 (121.36)    
/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata
0x91153000 - 0x91161fff libz.1.dylib     /usr/lib/libz.1.dylib
0x91164000 - 0x91303fff com.apple.security 4.4.1 (27569)    
/System/Library/Frameworks/Security.framework/Versions/A/Security
0x91401000 - 0x91409fff com.apple.DiskArbitration 2.1.1    
/System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
0x91410000 - 0x91436fff com.apple.SystemConfiguration 1.8.6    
/System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration
0x91448000 - 0x9144ffff libbsm.dylib     /usr/lib/libbsm.dylib
0x91453000 - 0x914c9fff com.apple.audio.CoreAudio 3.0.4    
/System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
0x9151a000 - 0x9151afff com.apple.ApplicationServices 10.4 (???)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices
0x9151c000 - 0x91548fff com.apple.AE 314 (313)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE
0x9155b000 - 0x9162ffff com.apple.ColorSync 4.4.6    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSync.framework/Versions/A/ColorSync
0x9166a000 - 0x916ddfff com.apple.print.framework.PrintCore 4.6 
(177.13)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
0x9170b000 - 0x917b4fff com.apple.QD 3.10.21 (???)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD
0x917da000 - 0x91825fff com.apple.HIServices 1.5.2 (???)    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices
0x91844000 - 0x9185afff com.apple.LangAnalysis 1.6.3    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis
0x91866000 - 0x91881fff com.apple.FindByContent 1.5    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/FindByContent.framework/Versions/A/FindByContent
0x9188c000 - 0x918c9fff com.apple.LaunchServices 181    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices
0x918dd000 - 0x918e9fff com.apple.speech.synthesis.framework 3.5    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
0x918f0000 - 0x9192bfff com.apple.ImageIO.framework 1.5.0    
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/ImageIO
0x9193d000 - 0x919effff libcrypto.0.9.7.dylib     
/usr/lib/libcrypto.0.9.7.dylib
0x91a35000 - 0x91a4bfff libcups.2.dylib     /usr/lib/libcups.2.dylib
0x91a50000 - 0x91a6efff libJPEG.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib
0x91a73000 - 0x91ad1fff libJP2.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib
0x91ae3000 - 0x91ae7fff libGIF.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib
0x91ae9000 - 0x91b66fff libRaw.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libRaw.dylib
0x91b6a000 - 0x91ba7fff libTIFF.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib
0x91bad000 - 0x91bc7fff libPng.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib
0x91bcc000 - 0x91bcefff libRadiance.dylib     
/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib
0x91bd0000 - 0x91bd0fff com.apple.Accelerate 1.3.1 (Accelerate 1.3.1)    
/System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate
0x91bd2000 - 0x91c60fff com.apple.vImage 2.5    
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage
0x91c67000 - 0x91c67fff com.apple.Accelerate.vecLib 3.3.1 (vecLib 
3.3.1)    
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib
0x91c69000 - 0x91cc2fff libvMisc.dylib     
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib
0x91ccb000 - 0x91ceffff libvDSP.dylib     
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib
0x91cf7000 - 0x92100fff libBLAS.dylib     
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
0x9213a000 - 0x924eefff libLAPACK.dylib     
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib
0x9251b000 - 0x92598fff com.apple.DesktopServices 1.3.4    
/System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv
0x925d9000 - 0x92809fff com.apple.Foundation 6.4.7 (567.28)    
/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation
0x92915000 - 0x929f3fff libxml2.2.dylib     /usr/lib/libxml2.2.dylib
0x92a10000 - 0x92afdfff libiconv.2.dylib     /usr/lib/libiconv.2.dylib
0x92b0d000 - 0x92b24fff libGL.dylib     
/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib
0x92b2f000 - 0x92b87fff libGLU.dylib     
/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib
0x92bbc000 - 0x92bc4fff com.apple.speech.recognition.framework 3.6    
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition
0x92db0000 - 0x92dbefff com.apple.audio.SoundManager 3.9.1    
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CarbonSound.framework/Versions/A/CarbonSound
0x92dcf000 - 0x930c3fff com.apple.HIToolbox 1.4.8 (???)    
/System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox
0x931c9000 - 0x931d4fff com.apple.opengl 1.4.13    
/System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL
0x93266000 - 0x9391cfff com.apple.AppKit 6.4.8 (824.42)    
/System/Library/Frameworks/AppKit.framework/Versions/C/AppKit
0x93c9d000 - 0x93d16fff com.apple.CoreData 90    
/System/Library/Frameworks/CoreData.framework/Versions/A/CoreData
0x93d4f000 - 0x93e07fff com.apple.audio.toolbox.AudioToolbox 1.4.3    
/System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
0x93e49000 - 0x93e49fff com.apple.audio.units.AudioUnit 1.4.2    
/System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
0x93e4b000 - 0x9401dfff com.apple.QuartzCore 1.4.10    
/System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore
0x9406e000 - 0x940affff libsqlite3.0.dylib     /usr/lib/libsqlite3.0.dylib
0x940b7000 - 0x940f1fff libGLImage.dylib     
/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
0x95fba000 - 0x95fe8fff libncurses.5.4.dylib     
/usr/lib/libncurses.5.4.dylib
0x96a29000 - 0x96a29fff com.apple.vecLib 3.3.1 (vecLib 3.3.1)    
/System/Library/Frameworks/vecLib.framework/Versions/A/vecLib
0x9b9f1000 - 0x9b9f1fff libmx.A.dylib     /usr/lib/libmx.A.dylib

Best regards
Christian


From edd at debian.org  Sun Feb  4 21:34:30 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 4 Feb 2007 14:34:30 -0600
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45C6400A.3050700@aon.at>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at>
Message-ID: <17862.17238.953948.854563@basebud.nulle.part>


On 4 February 2007 at 21:20, cstrato wrote:
| Thank you for your fast answer.
| Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
| old-style print commands.
| However, here is the output of the crash log from my Mac. Does it help?

Not me. I barely know what Mac OS X is, and never used it myself. You may
need to talk to the r-sig-mac folks. If everything else fails, Simon tends to
come up with answers no matter how hard or esoteric the question :)

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From sfalcon at fhcrc.org  Sun Feb  4 22:40:00 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 04 Feb 2007 13:40:00 -0800
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45C6400A.3050700@aon.at> (cstrato@aon.at's message of "Sun,
	04 Feb 2007 21:20:26 +0100")
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at>
Message-ID: <m2d54pob4f.fsf@fhcrc.org>

cstrato <cstrato at aon.at> writes:
> Thank you for your fast answer.
> Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
> old-style print commands.

You should be able to use gdb on OS X (works for me, YMMV).  So you
could try:

      R -d gdb
      run
      # source a script that causes crash
      # back in gdb, use backtrace, etc.

+ seth


From cstrato at aon.at  Sun Feb  4 22:40:50 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Feb 2007 22:40:50 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <17862.17238.953948.854563@basebud.nulle.part>
References: <45C6315F.9020209@aon.at>	<17862.14169.654577.51179@basebud.nulle.part>	<45C6400A.3050700@aon.at>
	<17862.17238.953948.854563@basebud.nulle.part>
Message-ID: <45C652E2.5090705@aon.at>

Dirk Eddelbuettel wrote:
> On 4 February 2007 at 21:20, cstrato wrote:
> | Thank you for your fast answer.
> | Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
> | old-style print commands.
> | However, here is the output of the crash log from my Mac. Does it help?
>
> Not me. I barely know what Mac OS X is, and never used it myself. You may
> need to talk to the r-sig-mac folks. If everything else fails, Simon tends to
> come up with answers no matter how hard or esoteric the question :)
>
> Dirk
>
>   
Thank you. I have seen that Mac-questions get also answered on this 
mailing list, so maybe
someone has an answer?
BTW, I forgot to mention that I downloaded the R-2.4.1.dmg binary since 
I wanted to create
a package for the current version. So I don?t know if the problem 
disappears  when using the
new developer version. Is the problem 2.4.1-specific only?

Best regards
Christian


From cstrato at aon.at  Sun Feb  4 22:47:37 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Feb 2007 22:47:37 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <m2d54pob4f.fsf@fhcrc.org>
References: <45C6315F.9020209@aon.at>	<17862.14169.654577.51179@basebud.nulle.part>	<45C6400A.3050700@aon.at>
	<m2d54pob4f.fsf@fhcrc.org>
Message-ID: <45C65479.30906@aon.at>

Seth Falcon wrote:
> cstrato <cstrato at aon.at> writes:
>   
>> Thank you for your fast answer.
>> Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
>> old-style print commands.
>>     
>
> You should be able to use gdb on OS X (works for me, YMMV).  So you
> could try:
>
>       R -d gdb
>       run
>       # source a script that causes crash
>       # back in gdb, use backtrace, etc.
>
> + seth
>
>
>   
Dear Seth

Thank you for this tip, I just tried it and here is the result:

Welcome to MyClass
 > writeFileCpp("myout_fileCpp.txt")
[1] "outfile =  myout_fileCpp.txt"
Writing file myout_fileCpp.txt using C++ style.
---MyClassA::MyClassA()---------
---MyClassA::WriteFileCpp---------

Program received signal EXC_BAD_ACCESS, Could not access memory.
Reason: KERN_PROTECTION_FAILURE at address: 0x00000006
0x020fe231 in std::ostream::flush (this=0x214f178) at 
/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc:395
395     
/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc: 
No such file or directory.
        in 
/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc
(gdb)

It seems that it cannot find ostream.tcc, whatever this extension means.

Best regards
Christian


From hpages at fhcrc.org  Mon Feb  5 02:51:22 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Sun,  4 Feb 2007 17:51:22 -0800
Subject: [Rd] convolve: request for "usual" behaviour + some
	improvements + some fixes
In-Reply-To: <17860.38634.114087.849247@stat.math.ethz.ch>
References: <1170445439.45c3947fb1dc8@webmail.fhcrc.org>
	<45C3DF5E.9000307@fhcrc.org> <45C41DDC.2030301@fhcrc.org>
	<17860.38634.114087.849247@stat.math.ethz.ch>
Message-ID: <1170640282.45c68d9aa3a30@webmail.fhcrc.org>

Hi Martin,

Thanks for taking the time to read me. Here is a followup,
it's rather long but hopefully not too long (and not too boring) ;-)

Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

> Thank you, Herve,
> 
> >>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
> >>>>>     on Fri, 02 Feb 2007 21:30:04 -0800 writes:
> 
>     Herve> Last but not least: convolve2 can be made 100 times or 1000 times
faster
>     Herve> than convolve by choosing a power of 2 for the length of the
fft-buffer
>     Herve> (a length of 2^n is the best case for the fft, the worst case
being
when
>     Herve> the length is a prime number):
...
> The typical approach here and definitely the idea of the
> original author of convolve() - would be to use  nextn()  here
> instead of  "next_power_of_2()".

The current implementation of convolve uses an fft-buffer of length
nx + ny - 1 for "open" convolution, not nextn().
The fft-based convolution is by nature "circular". However it can be
used for "open" convolutions: the trick is to padd the input sequences
with enough zeros to avoid the overlap inherent to circular convolution.
Then the ouput sequence doesn't "look" circular anymore.

For example, if the input sequences are
   X =   2   5   8
   Y = 100   1   0
then the "circular" convolution of X and Y is
   Z = 205 802 508
To achieve "open" convolution, it's enough to _right_ padd X and
Y with zeros:
   X =   2   5   8   0
   Y = 100   1   0   0
then the "circular" convolution doesn't look circular anymore (it
looks "open"):
   Z = 200 802 508   5

All you need to do is to padd enough zeros to have length X (and Y)
>= nx + ny - 1. But you can add more zeros if you want: this doesn't
change the result (except that you get extra zeros in the output
sequence):
  X =   2   5   8   0   0   0
  Y = 100   1   0   0   0   0
  Z = 200 802 508   5   0   0

The current approach of adding the strict minimum number of necessary
zeros could _at first glance_ seem reasonable since it minimizes
the amount of memory used. But the problem with this approach is that the
fft algorithm is not very good in the general case and very very bad when
the length of the sequence is a prime number: in this case it has to
perform n^2 complex multiplications so it can litterally take days or
weeks when n is a big prime number (>= 10 millions).

> 
> convolve() is one of the very old R functions stemming from
> Auckland already seen in the very first R tarball that's still
> available: Dated from June 20, 1995, with most file dates from
> Jun 16/17, i.e. really of even older date,  the file src/rrc/fft
> (no 'library', noR extension yet) contains definitions for  'fft', 'nextn'
> and 'convolve' where the latter was (note the ":=" for what now
> would be assignment to the base package)
> 
> convolve := function (a, b, conj=F)
> {
> 	na <- length(a)
> 	nb <- length(b)
> 	n <- max(na, nb)
> 	if (nb < n)
> 		b <- c(b, rep(0, n - nb))
> 	else if (na < n)
> 		a <- c(b, rep(0, n - na))
> 	da <- fft(a)
> 	db <- fft(b)
> 	if(conj) {
> 		a <- da$x * db$x + da$y * db$y
> 		b <- - da$x * db$y + db$x * da$y
> 	}
> 	else {
> 		a <- da$x * db$x - da$y * db$y
> 		b <- da$x * db$y + db$x * da$y
> 	}
> 	fft(a, b, inv=T)$x
> }
> 
> and just for historical fun here's the help file in that
> cute olde help file format:
> 
> TITLE(convolve @ Fast Convolution)
> USAGE(
> convolve(a, b, conj=false)
> )
> ARGUMENTS(
> ARG(a,b @ the sequences to be convolved.)
> ARG(conj @ logical, if true the transform of LANG(b) is conjugated
> before back-transformation.)
> )
> DESCRIPTION(
> LANG(convolve) uses the Fast Fourier Transform to compute the
> convolution of the sequences given as its arguments.
> PARA
> Complex conjugation is useful when computing
> autocovariances and autocorrelations by fast convolution.
> )
> REFERENCES(
> Brillinger, D. R. (1981).
> ITALIC(Time Series: Data Analysis and Theory), Second Edition.
> San Francisco: Holden-Day.
> )
> SEEALSO(
> LANG(LINK(fft)), LANG(LINK(nextn)).
> )

If you ignore the huge bug that 'a' is replaced by 'b' during the 0-padding
operation, this one was better than the current 'convolve'. It already had
the 'conj' argument and the default for it was FALSE so, by default,
the convolve function was doing convolution, not cross-correlation
(more on this below).
But it was doing "circular" convolution only...

> 
> Later I had added bits to the docu, convolve got the 'type'
> argument, Brian also fixed code and amplified the description and provided
> the alternative filter()  which had hencefor been recommended
> instead of convolve for most applications.

filter() might be OK for users who want filtering but what about people
who want a convolution?

Just FYI, with:
   X =   2   5   8
   Y = 100   1
filter(X, Y) gives:
   Z = 502 805  NA
convolve(X, Y, type="filter") gives:
   Z = 208 805
and convolve(x, y, conj=FALSE, type="filter") gives:
   Z = 200 502
so there are some inconsistencies.

But more important: what if I want the "usual" convolution product?

convolve(X, Y, type="o") gives:
   Z = 2 208 805 500
and convolve(x, y, conj=FALSE, type="o") is closer to what I expect
   Z = 5 200 802 508
but still not there :-/

IMO, having a function that does the correct convolution product is
very usefull e.g. for polynom multiplication (if you see X and Y as
the coefficients of polynoms Px and Py, then Z contains the coefficients
of polynomial product Px * Py), or for fast high precision arithmetic
(_exact_ multiplication of numbers with thousands of decimals).
An fft-based convolve function is _the_ tool for those operations
and of course, it shoul be fast.

> 
> For back-compatibility (and reverence to the very first R code
> writers (!?)) we did not change its behavior but rather documented it
> more precisely.
> 
> I haven't studied the details of all the possible padding
> options for a long time, but I remember that 0-padding
> (to length 'n' where 'n' is "highly composite") is only
> approximately the same as a non-padded version -- since the
> Fourier frequencies  2*pi*j/n depend on n.
> As you notice, padding is often very recommendable but it's
> strictly giving the solution to a different problem.

Nope, it gives exactly the same result (modulo floating point
rounding errors).

> For that reason, ?convolve has mentioned  nextn() for 12 years
> now, but not "urged" the padding

convolve() mentions nextn() but does not use it. The user has
no control over the length of the fft-buffer that is used.
But it shouldn't need to: you can safely assume that the best
choice is almost always to take the next_power_of_2 length.
Maybe there could be a few situations where you don't want to do this.
For example, if length(X) + length(Y) - 1 is 1031, the next power
of 2 is 2048 so you need to (almost) double the size of X and Y.
Maybe you are on a machine with very limited memory and you don't
want to do this. But in this case you'd better not try to use the
fft-based convolution at all because when n is a prime number (1031),
then it's better to compute the convolution by just doing:

   Z[i] = sum(k, X[k]*Y[i-k])

You'll do much less multiplications! and they will be on
doubles (or integers) when X and Y are double (or integer) vectors
(with the fft-base convolution, all multiplications are one complexes).

All this to say that it's only worth to use an fft-based convolution
if the length of the fft buffer is a power of 2. And for open
convolution you can _always_ do this. And the cost of it is nothing
compared to the gain in speed (use twice the memory to multiply the
speed by 100, 10000 or more!)

For example, compare the speed of 'filter' (not fft-based) with the
speed of 'convolve2':

  > x <- sample(1:9, 100000, replace=TRUE)
  > y <- rep(1:1, 10000)
  > system.time(z1 <- filter(x, y))
     user  system elapsed
   31.486   0.460  32.478
  > system.time(z2 <- convolve2(x, y, type="o"))
     user  system elapsed
    0.400   0.032   0.454

Note that z1 starts and ends with 4999 NAs. All the values between
(filtered signal?) are also in z2. To be precise:

  all.equal(z1[5000:95000], z2[10000:100000])

is TRUE.


> 
> If we would change convolve() to behave more like your proposal
> how many user-defined functions and scripts will give wrong
> answers if they are not amended?

With current version of convolve, they are getting wrong answers
anyway. Nobody on this list wants this

  http://www.sciencemag.org/cgi/content/summary/314/5807/1856

to happen just because of a buggy convolve function in R right?

> Probably only a very small fraction of all existing code (since
> convolve() is not in wide use), but that may still be 100's of
> cases. So that would need a the new version with a new name
> (such as "convolve2" or maybe slightly nicer "convolve.".
> 
> Is it worth introducing that and to start deprecating convolve() ?
> IIRC, the last time we considered this (several years ago), we
> had concluded "no", but maybe it's worth to get rid of this
> infelicity rather than to document it in ever more details.
> 

Here below is another 'convolve2' function (just in case). I've
reintroduced the 'conj' argument after I did some homework
and understood what it was really doing. _What_ it
does is make 'convolve' return the cross-correlation of
X and Y instead of the correlation.
_How_ it does this is by taking the conjugate of fft(y)
before to multiply it by fft(x). Without going into too many
details, I'll just say that this "trick" doesn't play well
with the type="o" option hence the special treatment of
y when 'type' is not "circular" and 'conj' is TRUE.
Also, I've reset the default to FALSE so by default convolve2
does convolution, not cross-correlation.

As for the "filter" type, it seems that the idea of its original
author was to truncate the result of the convolution but it's
not clear to me where this truncation should occur (to the right?
to the left?). IMO, the convolution product of X by Y _is_ the
result of X filtered by Y, it's just that one terminology comes
from maths and the other from signal processing. And there is nothing
to truncate because if the filter (Y) has a length >= 2, then it's
normal to expect a filtered signal longer than X so I would tend to
say that the "filter" feature is a broken concept.

Best,
H.


convolve2 <- function(x, y, conj=FALSE, type=c("circular", "open", "filter"))
{
    type <- match.arg(type)
    nx <- length(x)
    ny <- length(y)
    if (type == "circular") {
        fft_length <- max(nx, ny)
    } else {
        if (conj) {
            y <- rev(y)
            if (is.complex(y))
                y <- Conj(y)
            conj <- FALSE
        }
        nz <- nx + ny - 1
        fft_length <- 2^ceiling(log2(nz))
    }
    if (fft_length > nx)
        x[(nx+1):fft_length] <- as.integer(0)
    if (fft_length > ny)
        y[(ny+1):fft_length] <- as.integer(0)
    fy <- fft(y)
    if (conj)
        fy <- Conj(fy)
    z <- fft(fft(x) * fy, inverse=TRUE) / length(x)
    if (type == "open") {
        z <- z[1:nz]
    } else {
        if (type == "filter")
            z <- z[1:nx]
    }
    if (is.numeric(x) && is.numeric(y))
        z <- Re(z)
    if (is.integer(x) && is.integer(y))
        z <- as.integer(round(z))
    z
}


From wl2776 at gmail.com  Mon Feb  5 10:28:24 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 5 Feb 2007 01:28:24 -0800 (PST)
Subject: [Rd] How to customize the list of exported functions in a shared
	library
Message-ID: <8803194.post@talk.nabble.com>


Dear R users,

I am writing binding from C library to R.
I use R 2.4.1, windows XP, and MinGW.

commands

set PKG_CPPFLAGS="-I../sources" "-I." 
set PKG_LIBS="-Lc:/mingw/lib" -lfl -liberty
set DEBUG=T

R CMD SHLIB -d --output=Rsnns.dll  [ list of all C sources]

produce the DLL having all defined functions in the export list.
This doesn't satisfy me, as I would like to hide most of defined functions
and export only a couple of functions from the library and interface
functions which I have written in order to call them from R.

The ../sources directory contains also two compiled libraries, created with
ar. 
If I try to link my DLL with them,  that is

R CMD SHLIB -d --output Rsnns.dll Rsnns.c
-Wl,-Lc:/mingw/lib,-lfl,-L../sources,-lkernel,-lfunc

desired functions from the library are not exported, export list gets only
interface functions in the C file.

And GCC seems to ignore the .def file, which I create.

Thank you.
-- 
View this message in context: http://www.nabble.com/How-to-customize-the-list-of-exported-functions-in-a-shared-library-tf3173289.html#a8803194
Sent from the R devel mailing list archive at Nabble.com.


From atp at piskorski.com  Mon Feb  5 15:03:54 2007
From: atp at piskorski.com (Andrew Piskorski)
Date: Mon, 5 Feb 2007 09:03:54 -0500
Subject: [Rd] How to customize the list of exported functions in a
	shared library
In-Reply-To: <8803194.post@talk.nabble.com>
References: <8803194.post@talk.nabble.com>
Message-ID: <20070205140354.GA12059@tehun.pair.com>

On Mon, Feb 05, 2007 at 01:28:24AM -0800, Vladimir Eremeev wrote:
> I am writing binding from C library to R.
> I use R 2.4.1, windows XP, and MinGW.

> R CMD SHLIB -d --output=Rsnns.dll  [ list of all C sources]

> R CMD SHLIB -d --output Rsnns.dll Rsnns.c -Wl,-Lc:/mingw/lib,-lfl,-L../sources,-lkernel,-lfunc

You should probably also show us the actual compiler/linker commands
that "R CMD SHLIB" is generating, so we can be sure of what's really
going on.

I'm not sure what you may have to do differently with MinGW on Windows
(what linker does that use anyway?), but for comparison, here's how I
do it for R 2.2.1, on Linux (Ubuntu Dapper 6.06), with gcc 4.0.3, and
Gnu ld 2.16.91:

For my own custom R package's C code, my Makefile says:

  OBJ = ../foo.o $(patsubst %.c,%.o,$(wildcard ../source/[a-z]*.c))
  $(OBJ): %.o:  %.c $(HDRS)
  R.so: $(OBJ) Makevars vis.map
          R CMD SHLIB -o my_pkg_name_R.so $(OBJ)

My Makevars includes this:

  PKG_LIBS = -Wl,--version-script=vis.map

And when I build my R package, the R.so make target above generates
this link command:

  gcc -shared -o my_pkg_name_R.so [lots of *.o filenames here] -Wl,--version-script=vis.map -L/usr/lib/R/lib -lR

My vis.map file, which uses Gnu ld syntax, looks like this:

  {
     global: my_pkg_*;
     local:*;
  };

That works, my shared library exports ONLY the symbols starting with
"my_pkg_", everything else remains private.

It's the "--version-script" linker option doing the magic.  Even with
Gnu ld, there are definitely other ways to control symbol visibility,
but that one seemed most convenient in my case.

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From wl2776 at gmail.com  Mon Feb  5 15:41:56 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 5 Feb 2007 06:41:56 -0800 (PST)
Subject: [Rd] How to customize the list of exported functions in a
 shared library
In-Reply-To: <20070205140354.GA12059@tehun.pair.com>
References: <8803194.post@talk.nabble.com>
	<20070205140354.GA12059@tehun.pair.com>
Message-ID: <8807456.post@talk.nabble.com>



Andrew Piskorski wrote:
> 
> On Mon, Feb 05, 2007 at 01:28:24AM -0800, Vladimir Eremeev wrote:
>> I am writing binding from C library to R.
>> I use R 2.4.1, windows XP, and MinGW.
> 
>> R CMD SHLIB -d --output=Rsnns.dll  [ list of all C sources]
> 
>> R CMD SHLIB -d --output Rsnns.dll Rsnns.c
>> -Wl,-Lc:/mingw/lib,-lfl,-L../sources,-lkernel,-lfunc
> 
> You should probably also show us the actual compiler/linker commands
> that "R CMD SHLIB" is generating, so we can be sure of what's really
> going on.
> 

It calls gcc:
gcc  "-I../sources" "-I."  -IC:/PROGRA~1/R/include  -gdwarf-2 -Wall -O2
-std=gnu99   -c rsnns.c -o rsnns.o
gcc  -shared   -o Rsnns.dll Rsnns.def [ lots of *.o ]  -LC:/PROGRA~1/R/bin
"-Lc:/mingw/lib" -lfl -liberty   -lR

The file Rsnns.def is generated automatically and is deleted on success.
On error, it remains, and contains export of all symbols.
Probably GCC generates it, I haven't tracked its generation in the R's
scripts.


Andrew Piskorski wrote:
> 
> I'm not sure what you may have to do differently with MinGW on Windows
> (what linker does that use anyway?), but for comparison, here's how I
> do it for R 2.2.1, on Linux (Ubuntu Dapper 6.06), with gcc 4.0.3, and
> Gnu ld 2.16.91:
> 

gcc.EXE (GCC) 3.4.2 (mingw-special)
GNU ld version 2.15.91 20040904

Thank you, I'll study this linker option.


Andrew Piskorski wrote:
> 
> For my own custom R package's C code, my Makefile says:
>   OBJ = ../foo.o $(patsubst %.c,%.o,$(wildcard ../source/[a-z]*.c))
>   $(OBJ): %.o:  %.c $(HDRS)
>   R.so: $(OBJ) Makevars vis.map
>           R CMD SHLIB -o my_pkg_name_R.so $(OBJ)
> 
> My Makevars includes this:
> 
>   PKG_LIBS = -Wl,--version-script=vis.map
> 
> And when I build my R package, the R.so make target above generates
> this link command:
> 
>   gcc -shared -o my_pkg_name_R.so [lots of *.o filenames here]
> -Wl,--version-script=vis.map -L/usr/lib/R/lib -lR
> 
> My vis.map file, which uses Gnu ld syntax, looks like this:
> 
>   {
>      global: my_pkg_*;
>      local:*;
>   };
> 
> That works, my shared library exports ONLY the symbols starting with
> "my_pkg_", everything else remains private.
> 
> It's the "--version-script" linker option doing the magic.  Even with
> Gnu ld, there are definitely other ways to control symbol visibility,
> but that one seemed most convenient in my case.
> -- 
> Andrew Piskorski <atp at piskorski.com>
> http://www.piskorski.com/
> 
> 

-- 
View this message in context: http://www.nabble.com/How-to-customize-the-list-of-exported-functions-in-a-shared-library-tf3173289.html#a8807456
Sent from the R devel mailing list archive at Nabble.com.


From wl2776 at gmail.com  Mon Feb  5 15:51:49 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 5 Feb 2007 06:51:49 -0800 (PST)
Subject: [Rd] How to customize the list of exported functions in a
 shared library (update)
In-Reply-To: <8807456.post@talk.nabble.com>
References: <8803194.post@talk.nabble.com>
	<20070205140354.GA12059@tehun.pair.com>
	<8807456.post@talk.nabble.com>
Message-ID: <8807621.post@talk.nabble.com>




Vladimir Eremeev wrote:
> 
> 
> It calls gcc:
> gcc  "-I../sources" "-I."  -IC:/PROGRA~1/R/include  -gdwarf-2 -Wall -O2
> -std=gnu99   -c rsnns.c -o rsnns.o
> gcc  -shared   -o Rsnns.dll Rsnns.def [ lots of *.o ]  -LC:/PROGRA~1/R/bin
> "-Lc:/mingw/lib" -lfl -liberty   -lR
> 
> The file Rsnns.def is generated automatically and is deleted on success.
> On error, it remains, and contains export of all symbols.
> Probably GCC generates it, I haven't tracked its generation in the R's
> scripts.
> 

This file is generated in R scripts.
MkRules contains

%.dll:
	@$(ECHO) EXPORTS > $*.def
	@$(NM) $^ | $(SED) -n 's/^........ [BCDRT] _/ /p' >> $*.def
	$(DLL) -shared $(DLLFLAGS) $($*-DLLFLAGS) -o $@ $*.def $^ $($*-DLLLIBS)
$(DLLLIBS)
	@$(RM) $*.def

-- 
View this message in context: http://www.nabble.com/How-to-customize-the-list-of-exported-functions-in-a-shared-library-tf3173289.html#a8807621
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Mon Feb  5 16:09:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Feb 2007 15:09:34 +0000 (GMT)
Subject: [Rd] How to customize the list of exported functions in a
 shared library
In-Reply-To: <20070205140354.GA12059@tehun.pair.com>
References: <8803194.post@talk.nabble.com>
	<20070205140354.GA12059@tehun.pair.com>
Message-ID: <Pine.LNX.4.64.0702051505440.26938@gannet.stats.ox.ac.uk>

It is a bit different on Windows, since it is making a DLL and GNU ld has 
lots of special-casing for those.

To see how to do it, look at the standard package 'stats'.  That has a 
.def file and it works.  The naming convention is probably what you 
missed.  (Also, things have changed since R 2.2.1.)

On Mon, 5 Feb 2007, Andrew Piskorski wrote:

> On Mon, Feb 05, 2007 at 01:28:24AM -0800, Vladimir Eremeev wrote:
>> I am writing binding from C library to R.
>> I use R 2.4.1, windows XP, and MinGW.
>
>> R CMD SHLIB -d --output=Rsnns.dll  [ list of all C sources]
>
>> R CMD SHLIB -d --output Rsnns.dll Rsnns.c -Wl,-Lc:/mingw/lib,-lfl,-L../sources,-lkernel,-lfunc
>
> You should probably also show us the actual compiler/linker commands
> that "R CMD SHLIB" is generating, so we can be sure of what's really
> going on.
>
> I'm not sure what you may have to do differently with MinGW on Windows
> (what linker does that use anyway?), but for comparison, here's how I
> do it for R 2.2.1, on Linux (Ubuntu Dapper 6.06), with gcc 4.0.3, and
> Gnu ld 2.16.91:
>
> For my own custom R package's C code, my Makefile says:
>
>  OBJ = ../foo.o $(patsubst %.c,%.o,$(wildcard ../source/[a-z]*.c))
>  $(OBJ): %.o:  %.c $(HDRS)
>  R.so: $(OBJ) Makevars vis.map
>          R CMD SHLIB -o my_pkg_name_R.so $(OBJ)
>
> My Makevars includes this:
>
>  PKG_LIBS = -Wl,--version-script=vis.map
>
> And when I build my R package, the R.so make target above generates
> this link command:
>
>  gcc -shared -o my_pkg_name_R.so [lots of *.o filenames here] -Wl,--version-script=vis.map -L/usr/lib/R/lib -lR
>
> My vis.map file, which uses Gnu ld syntax, looks like this:
>
>  {
>     global: my_pkg_*;
>     local:*;
>  };
>
> That works, my shared library exports ONLY the symbols starting with
> "my_pkg_", everything else remains private.
>
> It's the "--version-script" linker option doing the magic.  Even with
> Gnu ld, there are definitely other ways to control symbol visibility,
> but that one seemed most convenient in my case.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Feb  5 16:28:35 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 5 Feb 2007 15:28:35 +0000 (GMT)
Subject: [Rd] How to customize the list of exported functions in a
 shared library (update)
In-Reply-To: <8807621.post@talk.nabble.com>
References: <8803194.post@talk.nabble.com>
	<20070205140354.GA12059@tehun.pair.com>
	<8807456.post@talk.nabble.com> <8807621.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0702051520400.27282@gannet.stats.ox.ac.uk>

On Mon, 5 Feb 2007, Vladimir Eremeev wrote:

> Vladimir Eremeev wrote:

Something important is missing here!

>> It calls gcc:
>> gcc  "-I../sources" "-I."  -IC:/PROGRA~1/R/include  -gdwarf-2 -Wall -O2
>> -std=gnu99   -c rsnns.c -o rsnns.o
>> gcc  -shared   -o Rsnns.dll Rsnns.def [ lots of *.o ]  -LC:/PROGRA~1/R/bin
>> "-Lc:/mingw/lib" -lfl -liberty   -lR
>>
>> The file Rsnns.def is generated automatically and is deleted on success.
>> On error, it remains, and contains export of all symbols.
>> Probably GCC generates it, I haven't tracked its generation in the R's
>> scripts.

Actually, you *still* haven't tracked its generation in the R's scripts.

> This file is generated in R scripts.
> MkRules contains
>
> %.dll:
> 	@$(ECHO) EXPORTS > $*.def
> 	@$(NM) $^ | $(SED) -n 's/^........ [BCDRT] _/ /p' >> $*.def
> 	$(DLL) -shared $(DLLFLAGS) $($*-DLLFLAGS) -o $@ $*.def $^ $($*-DLLLIBS)
> $(DLLLIBS)
> 	@$(RM) $*.def

Yes, but that is not necessarily the rule used.  See MakeDll which 
contains the rules for generating DLLs to be linked into R, and CHANGES 
for the documentation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lei.wu at jax.org  Mon Feb  5 17:33:37 2007
From: lei.wu at jax.org (Lei Wu)
Date: Mon, 5 Feb 2007 11:33:37 -0500
Subject: [Rd] strange error message get from La.svd(X)
Message-ID: <20070205113337791.00000001288@phocid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070205/fb551706/attachment.pl 

From hpages at fhcrc.org  Mon Feb  5 18:07:52 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Mon,  5 Feb 2007 09:07:52 -0800
Subject: [Rd] Wrong vector size reported by error message
Message-ID: <1170695272.45c764681d287@webmail.fhcrc.org>

Hi,

On my system, I get the following error message:

  > big <- 2:(2**30)
  Error: cannot allocate vector of size 0 Kb

Note the wrong "size 0 Kb" in the message!

Cheers,
H.


> sessionInfo()
R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
i686-pc-linux-gnu

locale:
LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"


From cstrato at aon.at  Mon Feb  5 19:48:17 2007
From: cstrato at aon.at (cstrato)
Date: Mon, 05 Feb 2007 19:48:17 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <182A7E81-FAD6-42C9-8C5A-9D918E416A13@gmail.com>
References: <45C6315F.9020209@aon.at>	<17862.14169.654577.51179@basebud.nulle.part>	<45C6400A.3050700@aon.at>
	<m2d54pob4f.fsf@fhcrc.org> <45C65479.30906@aon.at>
	<182A7E81-FAD6-42C9-8C5A-9D918E416A13@gmail.com>
Message-ID: <45C77BF1.2080106@aon.at>

Dear Jochen

Thank you, there seems to be a problem with accessing memory but 
probably not in my simple program.
Here are the essential parts:

1. R-function:
"writeFileCpp" <-
function(outfile=character(0)) {
   r <- .C("WriteFileCpp",as.character(outfile), PACKAGE="MyClass");
   return();
}

2. R-wrapper:
   void WriteFileCpp(char **outfile)
   {
      MyClassA *classA = new MyClassA();
      classA->WriteFileCpp(outfile[0]);
      delete classA;
   }

3. C++ method:
void MyClassA::WriteFileCpp(const char *outfile)
{
   ofstream output(outfile, ios::out);
   output << 21 << endl;
   output.close();
}

This crashes with "non-existent physical address"

Interestingly, the following C++ method works:
void MyClassA::WriteFileCpp(const char *outfile)
{
   ofstream output(outfile, ios::out);
//   output << 21 << endl;
   output.close();
}

This means, that the operator "<<" seems to cause the problem, but why?

Best regards
Christian



Jochen Laubrock wrote:
> Hi cstrato,
>
>
> On 04.02.2007, at 22:47, cstrato wrote:
>
>> ostream.tcc
>>
>
>
> On my system (Mac OS X), ostream.tcc seems to be just a part of the 
> FSF/GNU implementation of the stl, as
>
> head -n 40 /usr/include/c++/4.0.0/bits/ostream.tcc
>
> gives
>
>> // This file is part of the GNU ISO C++ Library.  This library is free
>> // software; you can redistribute it and/or modify it under the
>> [...]
>> /** @file ostream.tcc
>> *  This is an internal header file, included by other library headers.
>> *  You should not attempt to use it directly.
>> */
>>
>> //
>> // ISO C++ 14882: 27.6.2  Output streams
>
>
> I think your error looks more like you are accessing invalid memory, 
> maybe a dangling pointer ?
>
> hth, jochen
>


From ubk2101 at columbia.edu  Mon Feb  5 20:27:54 2007
From: ubk2101 at columbia.edu (K. B. Udaya)
Date: Mon, 5 Feb 2007 14:27:54 -0500
Subject: [Rd] SEXP i/o, .Call(), and garbage collection.
In-Reply-To: <45C3520D.1030205@vanderbilt.edu>
References: <38c08c270702011022k2b15e80fl1cac5eef32eeb882@mail.gmail.com>
	<45C3520D.1030205@vanderbilt.edu>
Message-ID: <38c08c270702051127p295d153eiac362a4cf8065814@mail.gmail.com>

Thank you for the prompt and helpful replies.  We're embarrassed to
report that the problem was far more mundane:  a lonely uninitialized
integer pointer.

On the bright side, we now have a far deeper understanding of SEXP i/o.

Rest assured, the C-coding team (that would be me) has be duly spanked.

ubk


From osklyar at ebi.ac.uk  Tue Feb  6 00:01:24 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 05 Feb 2007 23:01:24 +0000
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <1170695272.45c764681d287@webmail.fhcrc.org>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
Message-ID: <45C7B744.5010701@ebi.ac.uk>

my R-SVN revision is 40458 compared to 40386 yours, could it be 
corrected already?

* ~: R
 > 2**30
[1] 1073741824
 > a<-2:1073741824
Error: cannot allocate vector of size 4194304 Kb
 > sessionInfo()
R version 2.5.0 Under development (unstable) (2007-01-22 r40548)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"
 >

--
Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466


hpages at fhcrc.org wrote:
> Hi,
> 
> On my system, I get the following error message:
> 
>   > big <- 2:(2**30)
>   Error: cannot allocate vector of size 0 Kb
> 
> Note the wrong "size 0 Kb" in the message!
> 
> Cheers,
> H.
> 
> 
>> sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
> i686-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.dalgaard at biostat.ku.dk  Tue Feb  6 00:32:54 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 06 Feb 2007 00:32:54 +0100
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <45C7B744.5010701@ebi.ac.uk>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
	<45C7B744.5010701@ebi.ac.uk>
Message-ID: <45C7BEA6.7020106@biostat.ku.dk>

Oleg Sklyar wrote:
> my R-SVN revision is 40458 compared to 40386 yours, could it be 
> corrected already?
>
> * ~: R
>  > 2**30
> [1] 1073741824
>  > a<-2:1073741824
> Error: cannot allocate vector of size 4194304 Kb
>   
There could be system dependencies. I get

> a<-2:1073741824

> a<-2:(2**30)

> gc()

            used   (Mb) gc trigger   (Mb)   max used   (Mb)

Ncells    235404   12.6     467875   25.0     350000   18.7

Vcells 536991796 4097.0 1127800953 8604.5 1073863120 8193.0

> 


;-)

(Frankly, I had forgotten about the size of that swap partition...)

-pd


>  > sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-01-22 r40548)
> x86_64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>  >
>
> --
> Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466
>
>
> hpages at fhcrc.org wrote:
>   
>> Hi,
>>
>> On my system, I get the following error message:
>>
>>   > big <- 2:(2**30)
>>   Error: cannot allocate vector of size 0 Kb
>>
>> Note the wrong "size 0 Kb" in the message!
>>
>> Cheers,
>> H.
>>
>>
>>     
>>> sessionInfo()
>>>       
>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>> i686-pc-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Tue Feb  6 00:42:57 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 05 Feb 2007 15:42:57 -0800
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <45C7B744.5010701@ebi.ac.uk>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
	<45C7B744.5010701@ebi.ac.uk>
Message-ID: <45C7C101.5050901@fhcrc.org>

Hi Oleg,

Oleg Sklyar wrote:
> my R-SVN revision is 40458 compared to 40386 yours, could it be
> corrected already?

No I don't think so. Maybe an architecture specific problem?
You are on a 64-bit system, I'm on a 32-bit system.

I was able to reproduce on 3 systems so far (with any version of R):
  - on my Pentium M laptop with Ubuntu 6.06
  - on a Linux SUSE 9.2 32-bit system
  - on a Core 1 Duo (32-bit) Mac Mini

All those systems are 32-bits.

I've tried on a couple of 64-bit systems and I don't get this problem.

Cheers,
H.

> 
> * ~: R
>> 2**30
> [1] 1073741824
>> a<-2:1073741824
> Error: cannot allocate vector of size 4194304 Kb
>> sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-01-22 r40548)
> x86_64-unknown-linux-gnu
> 
> locale:
> LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
> 
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>>
> 
> -- 
> Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466
> 
> 
> hpages at fhcrc.org wrote:
>> Hi,
>>
>> On my system, I get the following error message:
>>
>>   > big <- 2:(2**30)
>>   Error: cannot allocate vector of size 0 Kb
>>
>> Note the wrong "size 0 Kb" in the message!
>>
>> Cheers,
>> H.
>>
>>
>>> sessionInfo()
>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>> i686-pc-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>>
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Tue Feb  6 00:46:22 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Mon,  5 Feb 2007 15:46:22 -0800
Subject: [Rd] Build error with last R-devel tarball
Message-ID: <1170719182.45c7c1cee2c96@webmail.fhcrc.org>

Hi,


On Windows, with last R-devel tarball (r40647) from
  ftp://ftp.stat.math.ethz.ch/Software/R/R-devel_2007-02-04.tar.gz
I get the following build error:

E:\biocbld\bbs-2.0-bioc\R\src\gnuwin32> make
...
...
---------- Making package utils ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  installing R files
Error in namespaceExport(ns, exports) : undefined exports :?, CRAN.packages,
Rprof, Rprofmem, RShowDo
c, RSiteSearch, URLdecode, URLencode, alarm, apropos, argsAnywhere,
assignInNamespace, as.roman, as.p
erson, as.personList, available.packages, browseEnv, browseURL, bug.report,
capture.output, checkCRAN
, chooseCRANmirror, citation, citEntry, citHeader, citFooter, close.socket,
combn, compareVersion, co
ntrib.url, count.fields, data, data.entry, dataentry, de, de.ncols, de.restore,
de.setup, debugger, d
emo, download.file, download.packages, dump.frames, edit, emacs, example,
file_test, file.edit, find,
 fix, fixInNamespace, flush.console, formatOL, formatUL, getAnywhere,
getFromNamespace, getS3method,
glob2rx, head, head.matrix, help, help.search, help.start, history,
index.search, install.packages, i
nstalled.packages, limitedLabels, loadhistory, localeToCharset, ls.str, lsf.str,
make.packages.html,
make.socket, memory.limit, memory.size, menu, methods, mirror2html, modifyList,
new.packag
In addition: Warning message:
S3 methods '[.getAnywhere', '[.roman', 'as.character.person',
'as.character.personList', 'as.characte
r.roman', 'as.person.default', 'as.personList.default', 'as.personList.person',
'edit.data.frame', 'e
dit.default', 'edit.matrix', 'edit.vignette', 'format.roman', 'head.data.frame',
'head.default', 'hea
d.function', 'head.matrix', 'head.ftable', 'head.table', 'print.citation',
'print.Bibtex', 'print.cit
ationList', 'print.getAnywhere', 'print.hsearch', 'print.help_files_with_topic',
'print.Latex', 'prin
t.ls_str', 'print.MethodsFunction', 'print.packageDescription',
'print.packageIQR', 'print.packageSta
tus', 'print.roman', 'print.sessionInfo', 'print.socket', 'print.vignette',
'prompt.data.frame', 'pro
mpt.default', 'stack.data.frame', 'stack.default', 'str.POSIXt',
'str.data.frame', 'str.default', 'su
mmary.packageStatus', 'tail.data.frame', 'tail.default', 'tail.function',
'tail.matrix', 'tail.ftable
', 'tail.table', 'toBibtex.citation', 'toBibtex.citationList',
'toBibtex.person', 'toBibtex [... trun
cated]
Execution halted
make[4]: *** [E:/biocbld/bbs-2.0-bioc/R/library/utils/R/utils] Error 1
make[3]: *** [all] Error 2
make[2]: *** [pkg-utils] Error 2
make[1]: *** [rpackage] Error 1
make: *** [all] Error 2

Cheers,
H.


From osklyar at ebi.ac.uk  Tue Feb  6 00:59:05 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Mon, 05 Feb 2007 23:59:05 +0000
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <45C7C101.5050901@fhcrc.org>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
	<45C7B744.5010701@ebi.ac.uk> <45C7C101.5050901@fhcrc.org>
Message-ID: <45C7C4C9.9090801@ebi.ac.uk>

Herve, it looks like 64-bit. I just tried another 32 bit version: 
Windows build R-2.4.1 under VMWare on the same 64 bit Ubuntu as in my 
post above and Windows version shows the same bug as you report:

R2.4.1 on Windows 2000 as guest system in VMWare Ubuntu 6.10 64bit
-----------
 > big <- 2:(2**30)
Fehler: kann Vektor der Gr??e 0 Kb nicht allozieren
 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32

locale:
LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

--
Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466


Herve Pages wrote:
> Hi Oleg,
> 
> Oleg Sklyar wrote:
>> my R-SVN revision is 40458 compared to 40386 yours, could it be
>> corrected already?
> 
> No I don't think so. Maybe an architecture specific problem?
> You are on a 64-bit system, I'm on a 32-bit system.
> 
> I was able to reproduce on 3 systems so far (with any version of R):
>   - on my Pentium M laptop with Ubuntu 6.06
>   - on a Linux SUSE 9.2 32-bit system
>   - on a Core 1 Duo (32-bit) Mac Mini
> 
> All those systems are 32-bits.
> 
> I've tried on a couple of 64-bit systems and I don't get this problem.
> 
> Cheers,
> H.
> 
>> * ~: R
>>> 2**30
>> [1] 1073741824
>>> a<-2:1073741824
>> Error: cannot allocate vector of size 4194304 Kb
>>> sessionInfo()
>> R version 2.5.0 Under development (unstable) (2007-01-22 r40548)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
>>
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>> -- 
>> Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466
>>
>>
>> hpages at fhcrc.org wrote:
>>> Hi,
>>>
>>> On my system, I get the following error message:
>>>
>>>   > big <- 2:(2**30)
>>>   Error: cannot allocate vector of size 0 Kb
>>>
>>> Note the wrong "size 0 Kb" in the message!
>>>
>>> Cheers,
>>> H.
>>>
>>>
>>>> sessionInfo()
>>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>>> i686-pc-linux-gnu
>>>
>>> locale:
>>> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>>>
>>>
>>> attached base packages:
>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>>> [7] "base"
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Tue Feb  6 01:04:43 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 05 Feb 2007 16:04:43 -0800
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <45C7C101.5050901@fhcrc.org>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
	<45C7B744.5010701@ebi.ac.uk> <45C7C101.5050901@fhcrc.org>
Message-ID: <45C7C61B.6080406@fhcrc.org>

Herve Pages wrote:
> Hi Oleg,
> 
> Oleg Sklyar wrote:
>> my R-SVN revision is 40458 compared to 40386 yours, could it be
>> corrected already?
> 
> No I don't think so. Maybe an architecture specific problem?
> You are on a 64-bit system, I'm on a 32-bit system.
> 
> I was able to reproduce on 3 systems so far (with any version of R):
>   - on my Pentium M laptop with Ubuntu 6.06
>   - on a Linux SUSE 9.2 32-bit system
>   - on a Core 1 Duo (32-bit) Mac Mini

Same problem on a 64-bit Solaris 2.9 machine but with a 32-bit R executable
(compiled with a 32-bit gcc 4.1.1).

H.

> 
> All those systems are 32-bits.
> 
> I've tried on a couple of 64-bit systems and I don't get this problem.
> 
> Cheers,
> H.
>


From hpages at fhcrc.org  Tue Feb  6 01:10:25 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 05 Feb 2007 16:10:25 -0800
Subject: [Rd] Wrong vector size reported by error message
In-Reply-To: <45C7C4C9.9090801@ebi.ac.uk>
References: <1170695272.45c764681d287@webmail.fhcrc.org>
	<45C7B744.5010701@ebi.ac.uk> <45C7C101.5050901@fhcrc.org>
	<45C7C4C9.9090801@ebi.ac.uk>
Message-ID: <45C7C771.8090205@fhcrc.org>

Oleg Sklyar wrote:
> Herve, it looks like 64-bit. I just tried another 32 bit version:
> Windows build R-2.4.1 under VMWare on the same 64 bit Ubuntu as in my
> post above and Windows version shows the same bug as you report:
> 
> R2.4.1 on Windows 2000 as guest system in VMWare Ubuntu 6.10 64bit
> -----------
>> big <- 2:(2**30)
> Fehler: kann Vektor der Gr??e 0 Kb nicht allozieren

Right, I just tried on our Windows Server 2003 build machine (mingw32) and
got it too. Thanks Oleg!

H.

>> sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252
> 
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> -- 
> Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466
>


From ripley at stats.ox.ac.uk  Tue Feb  6 08:28:38 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Feb 2007 07:28:38 +0000 (GMT)
Subject: [Rd] Build error with last R-devel tarball
In-Reply-To: <1170719182.45c7c1cee2c96@webmail.fhcrc.org>
References: <1170719182.45c7c1cee2c96@webmail.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0702060726370.18593@gannet.stats.ox.ac.uk>

This was fixed in SVN within a few hours.  Tarballs are snapshots, please 
check SVN before reporting problems.

As I have said several times, please do not expect R-devel to build on all 
platforms at all times.

On Mon, 5 Feb 2007, hpages at fhcrc.org wrote:

> Hi,
>
>
> On Windows, with last R-devel tarball (r40647) from
>  ftp://ftp.stat.math.ethz.ch/Software/R/R-devel_2007-02-04.tar.gz
> I get the following build error:
>
> E:\biocbld\bbs-2.0-bioc\R\src\gnuwin32> make
> ...
> ...
> ---------- Making package utils ------------
>  adding build stamp to DESCRIPTION
>  installing NAMESPACE file and metadata
>  installing R files
> Error in namespaceExport(ns, exports) : undefined exports :?, CRAN.packages,
> Rprof, Rprofmem, RShowDo
> c, RSiteSearch, URLdecode, URLencode, alarm, apropos, argsAnywhere,
> assignInNamespace, as.roman, as.p
> erson, as.personList, available.packages, browseEnv, browseURL, bug.report,
> capture.output, checkCRAN
> , chooseCRANmirror, citation, citEntry, citHeader, citFooter, close.socket,
> combn, compareVersion, co
> ntrib.url, count.fields, data, data.entry, dataentry, de, de.ncols, de.restore,
> de.setup, debugger, d
> emo, download.file, download.packages, dump.frames, edit, emacs, example,
> file_test, file.edit, find,
> fix, fixInNamespace, flush.console, formatOL, formatUL, getAnywhere,
> getFromNamespace, getS3method,
> glob2rx, head, head.matrix, help, help.search, help.start, history,
> index.search, install.packages, i
> nstalled.packages, limitedLabels, loadhistory, localeToCharset, ls.str, lsf.str,
> make.packages.html,
> make.socket, memory.limit, memory.size, menu, methods, mirror2html, modifyList,
> new.packag
> In addition: Warning message:
> S3 methods '[.getAnywhere', '[.roman', 'as.character.person',
> 'as.character.personList', 'as.characte
> r.roman', 'as.person.default', 'as.personList.default', 'as.personList.person',
> 'edit.data.frame', 'e
> dit.default', 'edit.matrix', 'edit.vignette', 'format.roman', 'head.data.frame',
> 'head.default', 'hea
> d.function', 'head.matrix', 'head.ftable', 'head.table', 'print.citation',
> 'print.Bibtex', 'print.cit
> ationList', 'print.getAnywhere', 'print.hsearch', 'print.help_files_with_topic',
> 'print.Latex', 'prin
> t.ls_str', 'print.MethodsFunction', 'print.packageDescription',
> 'print.packageIQR', 'print.packageSta
> tus', 'print.roman', 'print.sessionInfo', 'print.socket', 'print.vignette',
> 'prompt.data.frame', 'pro
> mpt.default', 'stack.data.frame', 'stack.default', 'str.POSIXt',
> 'str.data.frame', 'str.default', 'su
> mmary.packageStatus', 'tail.data.frame', 'tail.default', 'tail.function',
> 'tail.matrix', 'tail.ftable
> ', 'tail.table', 'toBibtex.citation', 'toBibtex.citationList',
> 'toBibtex.person', 'toBibtex [... trun
> cated]
> Execution halted
> make[4]: *** [E:/biocbld/bbs-2.0-bioc/R/library/utils/R/utils] Error 1
> make[3]: *** [all] Error 2
> make[2]: *** [pkg-utils] Error 2
> make[1]: *** [rpackage] Error 1
> make: *** [all] Error 2
>
> Cheers,
> H.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From geoffrey.russell at gmail.com  Tue Feb  6 05:38:30 2007
From: geoffrey.russell at gmail.com (Geoff Russell)
Date: Tue, 6 Feb 2007 15:08:30 +1030
Subject: [Rd] Metapost device driver
In-Reply-To: <93c3eada0702051553x5375d70br8d9f8ca73199d2c6@mail.gmail.com>
References: <93c3eada0702051553x5375d70br8d9f8ca73199d2c6@mail.gmail.com>
Message-ID: <93c3eada0702052038x56da710ale94d6653fbda87f0@mail.gmail.com>

Hi All,

I've started work on a MetaPost device driver (please don't hold your
breath) and have one question about a magic number, see below.

I've copied the XFig driver and renamed everything and this works, I can
open the new metapost() and it works exactly like the xfig
driver. Now all I have to do is the actual work!

There is a magic number in ExtEntries as follows:

     static const R_ExternalMethodDef ExtEntries[] = {
           EXTDEF(PicTeX, 6),
           EXTDEF(PostScript, 16),        EXTDEF(XFig, 11),
           EXTDEF(MetaPost, 12),    /* Is 12 is OK */
           EXTDEF(PDF, 13),

I just picked 12, is this Ok, or does it have some special significance?

Cheers,
Geoff Russell


From kate at few.vu.nl  Tue Feb  6 11:51:34 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Tue, 6 Feb 2007 11:51:34 +0100 (CET)
Subject: [Rd] convolve: request for "usual" behaviour + some
 improvements + some fixes
In-Reply-To: <mailman.5.1170673202.28439.r-devel@r-project.org>
References: <mailman.5.1170673202.28439.r-devel@r-project.org>
Message-ID: <Pine.GSO.4.56.0702061140580.27859@laurel.few.vu.nl>

To add to the wish-list for "convolve":

For modeling processes that decay exponentially in time, e.g.,
fluorescence, it is desirable to have a function that convolves an
arbitrary vector with an exponential using an iterative method.

In the TIMP package (which won't be on CRAN till R 2.5.0 is official, but
is for now at www.nat.vu.nl/~kate/TIMP) we implemented this
special-purpose function as "Conv1" in C to be called via .C.  It would be
nice, at least for us, to have this function (or an improved version) as
an option in "convolve".

There is more on this in Section 4.2 of
 Laptenok S, Mullen KM, Borst JW, van Stokkum IHM, Apanasovich
 VV, Visser AJWG (2007). ``Fluorescence Lifetime Imaging Microscopy (FLIM)
 Data Analysis with TIMP.'' Journal of Statistical Software, 18(4).  URL
 http://www.jstatsoft.org/v18/i08/.

> ------------------------------
>
> Message: 8
> Date: Sun,  4 Feb 2007 17:51:22 -0800
> From: hpages at fhcrc.org
> Subject: Re: [Rd] convolve: request for "usual" behaviour + some
> 	improvements + some fixes
> To: Martin Maechler <maechler at stat.math.ethz.ch>
> Cc: r-devel at r-project.org
> Message-ID: <1170640282.45c68d9aa3a30 at webmail.fhcrc.org>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Hi Martin,
>
> Thanks for taking the time to read me. Here is a followup,
> it's rather long but hopefully not too long (and not too boring) ;-)
>
> Quoting Martin Maechler <maechler at stat.math.ethz.ch>:
>
> > Thank you, Herve,
> >
> > >>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
> > >>>>>     on Fri, 02 Feb 2007 21:30:04 -0800 writes:
> >
> >     Herve> Last but not least: convolve2 can be made 100 times or 1000 times
> faster
> >     Herve> than convolve by choosing a power of 2 for the length of the
> fft-buffer
> >     Herve> (a length of 2^n is the best case for the fft, the worst case
> being
> when
> >     Herve> the length is a prime number):
> ...
> > The typical approach here and definitely the idea of the
> > original author of convolve() - would be to use  nextn()  here
> > instead of  "next_power_of_2()".
>
> The current implementation of convolve uses an fft-buffer of length
> nx + ny - 1 for "open" convolution, not nextn().
> The fft-based convolution is by nature "circular". However it can be
> used for "open" convolutions: the trick is to padd the input sequences
> with enough zeros to avoid the overlap inherent to circular convolution.
> Then the ouput sequence doesn't "look" circular anymore.
>
> For example, if the input sequences are
>    X =   2   5   8
>    Y = 100   1   0
> then the "circular" convolution of X and Y is
>    Z = 205 802 508
> To achieve "open" convolution, it's enough to _right_ padd X and
> Y with zeros:
>    X =   2   5   8   0
>    Y = 100   1   0   0
> then the "circular" convolution doesn't look circular anymore (it
> looks "open"):
>    Z = 200 802 508   5
>
> All you need to do is to padd enough zeros to have length X (and Y)
> >= nx + ny - 1. But you can add more zeros if you want: this doesn't
> change the result (except that you get extra zeros in the output
> sequence):
>   X =   2   5   8   0   0   0
>   Y = 100   1   0   0   0   0
>   Z = 200 802 508   5   0   0
>
> The current approach of adding the strict minimum number of necessary
> zeros could _at first glance_ seem reasonable since it minimizes
> the amount of memory used. But the problem with this approach is that the
> fft algorithm is not very good in the general case and very very bad when
> the length of the sequence is a prime number: in this case it has to
> perform n^2 complex multiplications so it can litterally take days or
> weeks when n is a big prime number (>= 10 millions).
>
> >
> > convolve() is one of the very old R functions stemming from
> > Auckland already seen in the very first R tarball that's still
> > available: Dated from June 20, 1995, with most file dates from
> > Jun 16/17, i.e. really of even older date,  the file src/rrc/fft
> > (no 'library', noR extension yet) contains definitions for  'fft', 'nextn'
> > and 'convolve' where the latter was (note the ":=" for what now
> > would be assignment to the base package)
> >
> > convolve := function (a, b, conj=F)
> > {
> > 	na <- length(a)
> > 	nb <- length(b)
> > 	n <- max(na, nb)
> > 	if (nb < n)
> > 		b <- c(b, rep(0, n - nb))
> > 	else if (na < n)
> > 		a <- c(b, rep(0, n - na))
> > 	da <- fft(a)
> > 	db <- fft(b)
> > 	if(conj) {
> > 		a <- da$x * db$x + da$y * db$y
> > 		b <- - da$x * db$y + db$x * da$y
> > 	}
> > 	else {
> > 		a <- da$x * db$x - da$y * db$y
> > 		b <- da$x * db$y + db$x * da$y
> > 	}
> > 	fft(a, b, inv=T)$x
> > }
> >
> > and just for historical fun here's the help file in that
> > cute olde help file format:
> >
> > TITLE(convolve @ Fast Convolution)
> > USAGE(
> > convolve(a, b, conj=false)
> > )
> > ARGUMENTS(
> > ARG(a,b @ the sequences to be convolved.)
> > ARG(conj @ logical, if true the transform of LANG(b) is conjugated
> > before back-transformation.)
> > )
> > DESCRIPTION(
> > LANG(convolve) uses the Fast Fourier Transform to compute the
> > convolution of the sequences given as its arguments.
> > PARA
> > Complex conjugation is useful when computing
> > autocovariances and autocorrelations by fast convolution.
> > )
> > REFERENCES(
> > Brillinger, D. R. (1981).
> > ITALIC(Time Series: Data Analysis and Theory), Second Edition.
> > San Francisco: Holden-Day.
> > )
> > SEEALSO(
> > LANG(LINK(fft)), LANG(LINK(nextn)).
> > )
>
> If you ignore the huge bug that 'a' is replaced by 'b' during the 0-padding
> operation, this one was better than the current 'convolve'. It already had
> the 'conj' argument and the default for it was FALSE so, by default,
> the convolve function was doing convolution, not cross-correlation
> (more on this below).
> But it was doing "circular" convolution only...
>
> >
> > Later I had added bits to the docu, convolve got the 'type'
> > argument, Brian also fixed code and amplified the description and provided
> > the alternative filter()  which had hencefor been recommended
> > instead of convolve for most applications.
>
> filter() might be OK for users who want filtering but what about people
> who want a convolution?
>
> Just FYI, with:
>    X =   2   5   8
>    Y = 100   1
> filter(X, Y) gives:
>    Z = 502 805  NA
> convolve(X, Y, type="filter") gives:
>    Z = 208 805
> and convolve(x, y, conj=FALSE, type="filter") gives:
>    Z = 200 502
> so there are some inconsistencies.
>
> But more important: what if I want the "usual" convolution product?
>
> convolve(X, Y, type="o") gives:
>    Z = 2 208 805 500
> and convolve(x, y, conj=FALSE, type="o") is closer to what I expect
>    Z = 5 200 802 508
> but still not there :-/
>
> IMO, having a function that does the correct convolution product is
> very usefull e.g. for polynom multiplication (if you see X and Y as
> the coefficients of polynoms Px and Py, then Z contains the coefficients
> of polynomial product Px * Py), or for fast high precision arithmetic
> (_exact_ multiplication of numbers with thousands of decimals).
> An fft-based convolve function is _the_ tool for those operations
> and of course, it shoul be fast.
>
> >
> > For back-compatibility (and reverence to the very first R code
> > writers (!?)) we did not change its behavior but rather documented it
> > more precisely.
> >
> > I haven't studied the details of all the possible padding
> > options for a long time, but I remember that 0-padding
> > (to length 'n' where 'n' is "highly composite") is only
> > approximately the same as a non-padded version -- since the
> > Fourier frequencies  2*pi*j/n depend on n.
> > As you notice, padding is often very recommendable but it's
> > strictly giving the solution to a different problem.
>
> Nope, it gives exactly the same result (modulo floating point
> rounding errors).
>
> > For that reason, ?convolve has mentioned  nextn() for 12 years
> > now, but not "urged" the padding
>
> convolve() mentions nextn() but does not use it. The user has
> no control over the length of the fft-buffer that is used.
> But it shouldn't need to: you can safely assume that the best
> choice is almost always to take the next_power_of_2 length.
> Maybe there could be a few situations where you don't want to do this.
> For example, if length(X) + length(Y) - 1 is 1031, the next power
> of 2 is 2048 so you need to (almost) double the size of X and Y.
> Maybe you are on a machine with very limited memory and you don't
> want to do this. But in this case you'd better not try to use the
> fft-based convolution at all because when n is a prime number (1031),
> then it's better to compute the convolution by just doing:
>
>    Z[i] = sum(k, X[k]*Y[i-k])
>
> You'll do much less multiplications! and they will be on
> doubles (or integers) when X and Y are double (or integer) vectors
> (with the fft-base convolution, all multiplications are one complexes).
>
> All this to say that it's only worth to use an fft-based convolution
> if the length of the fft buffer is a power of 2. And for open
> convolution you can _always_ do this. And the cost of it is nothing
> compared to the gain in speed (use twice the memory to multiply the
> speed by 100, 10000 or more!)
>
> For example, compare the speed of 'filter' (not fft-based) with the
> speed of 'convolve2':
>
>   > x <- sample(1:9, 100000, replace=TRUE)
>   > y <- rep(1:1, 10000)
>   > system.time(z1 <- filter(x, y))
>      user  system elapsed
>    31.486   0.460  32.478
>   > system.time(z2 <- convolve2(x, y, type="o"))
>      user  system elapsed
>     0.400   0.032   0.454
>
> Note that z1 starts and ends with 4999 NAs. All the values between
> (filtered signal?) are also in z2. To be precise:
>
>   all.equal(z1[5000:95000], z2[10000:100000])
>
> is TRUE.
>
>
> >
> > If we would change convolve() to behave more like your proposal
> > how many user-defined functions and scripts will give wrong
> > answers if they are not amended?
>
> With current version of convolve, they are getting wrong answers
> anyway. Nobody on this list wants this
>
>   http://www.sciencemag.org/cgi/content/summary/314/5807/1856
>
> to happen just because of a buggy convolve function in R right?
>
> > Probably only a very small fraction of all existing code (since
> > convolve() is not in wide use), but that may still be 100's of
> > cases. So that would need a the new version with a new name
> > (such as "convolve2" or maybe slightly nicer "convolve.".
> >
> > Is it worth introducing that and to start deprecating convolve() ?
> > IIRC, the last time we considered this (several years ago), we
> > had concluded "no", but maybe it's worth to get rid of this
> > infelicity rather than to document it in ever more details.
> >
>
> Here below is another 'convolve2' function (just in case). I've
> reintroduced the 'conj' argument after I did some homework
> and understood what it was really doing. _What_ it
> does is make 'convolve' return the cross-correlation of
> X and Y instead of the correlation.
> _How_ it does this is by taking the conjugate of fft(y)
> before to multiply it by fft(x). Without going into too many
> details, I'll just say that this "trick" doesn't play well
> with the type="o" option hence the special treatment of
> y when 'type' is not "circular" and 'conj' is TRUE.
> Also, I've reset the default to FALSE so by default convolve2
> does convolution, not cross-correlation.
>
> As for the "filter" type, it seems that the idea of its original
> author was to truncate the result of the convolution but it's
> not clear to me where this truncation should occur (to the right?
> to the left?). IMO, the convolution product of X by Y _is_ the
> result of X filtered by Y, it's just that one terminology comes
> from maths and the other from signal processing. And there is nothing
> to truncate because if the filter (Y) has a length >= 2, then it's
> normal to expect a filtered signal longer than X so I would tend to
> say that the "filter" feature is a broken concept.
>
> Best,
> H.
>
>
> convolve2 <- function(x, y, conj=FALSE, type=c("circular", "open", "filter"))
> {
>     type <- match.arg(type)
>     nx <- length(x)
>     ny <- length(y)
>     if (type == "circular") {
>         fft_length <- max(nx, ny)
>     } else {
>         if (conj) {
>             y <- rev(y)
>             if (is.complex(y))
>                 y <- Conj(y)
>             conj <- FALSE
>         }
>         nz <- nx + ny - 1
>         fft_length <- 2^ceiling(log2(nz))
>     }
>     if (fft_length > nx)
>         x[(nx+1):fft_length] <- as.integer(0)
>     if (fft_length > ny)
>         y[(ny+1):fft_length] <- as.integer(0)
>     fy <- fft(y)
>     if (conj)
>         fy <- Conj(fy)
>     z <- fft(fft(x) * fy, inverse=TRUE) / length(x)
>     if (type == "open") {
>         z <- z[1:nz]
>     } else {
>         if (type == "filter")
>             z <- z[1:nx]
>     }
>     if (is.numeric(x) && is.numeric(y))
>         z <- Re(z)
>     if (is.integer(x) && is.integer(y))
>         z <- as.integer(round(z))
>     z
> }
>
>

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit Amsterdam
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/


From P.Dalgaard at biostat.ku.dk  Tue Feb  6 12:41:10 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 06 Feb 2007 12:41:10 +0100
Subject: [Rd] Metapost device driver
In-Reply-To: <93c3eada0702052038x56da710ale94d6653fbda87f0@mail.gmail.com>
References: <93c3eada0702051553x5375d70br8d9f8ca73199d2c6@mail.gmail.com>
	<93c3eada0702052038x56da710ale94d6653fbda87f0@mail.gmail.com>
Message-ID: <45C86956.2010006@biostat.ku.dk>

Geoff Russell wrote:
> Hi All,
>
> I've started work on a MetaPost device driver (please don't hold your
> breath) and have one question about a magic number, see below.
>
> I've copied the XFig driver and renamed everything and this works, I can
> open the new metapost() and it works exactly like the xfig
> driver. Now all I have to do is the actual work!
>
> There is a magic number in ExtEntries as follows:
>
>      static const R_ExternalMethodDef ExtEntries[] = {
>            EXTDEF(PicTeX, 6),
>            EXTDEF(PostScript, 16),        EXTDEF(XFig, 11),
>            EXTDEF(MetaPost, 12),    /* Is 12 is OK */
>            EXTDEF(PDF, 13),
>
> I just picked 12, is this Ok, or does it have some special significance?
>
>   
You seem to have missed the 2nd part of Brian's reply: Yes, it is
significant, and not magic: it's the argument count.




-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From rlweaver at stat.cmu.edu  Tue Feb  6 18:10:52 2007
From: rlweaver at stat.cmu.edu (Rhiannon L Weaver)
Date: Tue, 6 Feb 2007 12:10:52 -0500 (EST)
Subject: [Rd] RPM support for package installation?
Message-ID: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>

Hello,

Tech question, I hope this has not been addressed before.  I searched help 
archives and looked for online help but came up empty-handed.

My question is: (short version) Is there a RPM-supported version of 
update.packages() for use with updating package libraries on managed 
multi-user Linux networks?

Details:

I put in a request for updating the version of R on one of the hosts on my 
work Unix network, which is managed by our IT department.  Current version 
is 2.1.0; I asked them to update to 2.4.1. The core update installed and I 
was able to test it, but the update had trouble loading the package 
"Matrix" for use with "lme4".  I don't recall the specific error (will 
check it out when the new version gets re-installed again and I can 
document it).  Other packages (lme, wavethresh, MASS) seemed to load 
without problems.

I think the Matrix problem can be solved by running update.packages() but 
when I requested the admin to update packages for the new version, they 
said that they need to do this via an RPM.  Specifically (and I'm not a 
network guru so my advice may not be entirely accurate):

me: I think if you have admin access you should be able to update the R 
packages by using the command update.packages() from within a running, 
updated version of R, and it will automatically check packages for new 
versions and update them.

admin: But this method moves us to an unsustainable host with locally 
installed packages.  The add-on packages need to be installed via an RPM.

As I understand it, RPM is like a kind of makefile for Linux machines. 
The help mentions need of -devel or -dev files for RPM installations and 
updates of the core software; is there a similar avenue I can point my 
admin to for package updates?  I'm not afraid of a little Linux, but I 
fear I am a bit out of my element on this one.

Currently the workaround is for them to install the new version and for me 
to download and maintain packages locally.

Thanks very much for your time,
-Rhiannon


From hpages at fhcrc.org  Tue Feb  6 18:22:21 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Tue,  6 Feb 2007 09:22:21 -0800
Subject: [Rd] Build error with last R-devel tarball
In-Reply-To: <Pine.LNX.4.64.0702060726370.18593@gannet.stats.ox.ac.uk>
References: <1170719182.45c7c1cee2c96@webmail.fhcrc.org>
	<Pine.LNX.4.64.0702060726370.18593@gannet.stats.ox.ac.uk>
Message-ID: <1170782541.45c8b94db7006@webmail.fhcrc.org>

Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> This was fixed in SVN within a few hours.  Tarballs are snapshots, please 
> check SVN before reporting problems.

Thanks! I will check SVN before reporting problems with a tarball.
Just hope that nobody will get too upset if I'm reporting a problem
that just got fixed during the time I did 'svn up' and 'Send Message'
though ;-)

> 
> As I have said several times, please do not expect R-devel to build on all 
> platforms at all times.

Of course. But please, let us know if reporting problems when they occur
is still the right thing to do or not.

Thanks,
H.

> 
> On Mon, 5 Feb 2007, hpages at fhcrc.org wrote:
> 
> > Hi,
> >
> >
> > On Windows, with last R-devel tarball (r40647) from
> >  ftp://ftp.stat.math.ethz.ch/Software/R/R-devel_2007-02-04.tar.gz
> > I get the following build error:
> >
> > E:\biocbld\bbs-2.0-bioc\R\src\gnuwin32> make
> > ...
> > ...
> > ---------- Making package utils ------------
> >  adding build stamp to DESCRIPTION
> >  installing NAMESPACE file and metadata
> >  installing R files
> > Error in namespaceExport(ns, exports) : undefined exports :?,
> CRAN.packages,
> > Rprof, Rprofmem, RShowDo
> > c, RSiteSearch, URLdecode, URLencode, alarm, apropos, argsAnywhere,
> > assignInNamespace, as.roman, as.p
> > erson, as.personList, available.packages, browseEnv, browseURL,
> bug.report,
> > capture.output, checkCRAN
> > , chooseCRANmirror, citation, citEntry, citHeader, citFooter,
> close.socket,
> > combn, compareVersion, co
> > ntrib.url, count.fields, data, data.entry, dataentry, de, de.ncols,
> de.restore,
> > de.setup, debugger, d
> > emo, download.file, download.packages, dump.frames, edit, emacs, example,
> > file_test, file.edit, find,
> > fix, fixInNamespace, flush.console, formatOL, formatUL, getAnywhere,
> > getFromNamespace, getS3method,
> > glob2rx, head, head.matrix, help, help.search, help.start, history,
> > index.search, install.packages, i
> > nstalled.packages, limitedLabels, loadhistory, localeToCharset, ls.str,
> lsf.str,
> > make.packages.html,
> > make.socket, memory.limit, memory.size, menu, methods, mirror2html,
> modifyList,
> > new.packag
> > In addition: Warning message:
> > S3 methods '[.getAnywhere', '[.roman', 'as.character.person',
> > 'as.character.personList', 'as.characte
> > r.roman', 'as.person.default', 'as.personList.default',
> 'as.personList.person',
> > 'edit.data.frame', 'e
> > dit.default', 'edit.matrix', 'edit.vignette', 'format.roman',
> 'head.data.frame',
> > 'head.default', 'hea
> > d.function', 'head.matrix', 'head.ftable', 'head.table', 'print.citation',
> > 'print.Bibtex', 'print.cit
> > ationList', 'print.getAnywhere', 'print.hsearch',
> 'print.help_files_with_topic',
> > 'print.Latex', 'prin
> > t.ls_str', 'print.MethodsFunction', 'print.packageDescription',
> > 'print.packageIQR', 'print.packageSta
> > tus', 'print.roman', 'print.sessionInfo', 'print.socket',
> 'print.vignette',
> > 'prompt.data.frame', 'pro
> > mpt.default', 'stack.data.frame', 'stack.default', 'str.POSIXt',
> > 'str.data.frame', 'str.default', 'su
> > mmary.packageStatus', 'tail.data.frame', 'tail.default', 'tail.function',
> > 'tail.matrix', 'tail.ftable
> > ', 'tail.table', 'toBibtex.citation', 'toBibtex.citationList',
> > 'toBibtex.person', 'toBibtex [... trun
> > cated]
> > Execution halted
> > make[4]: *** [E:/biocbld/bbs-2.0-bioc/R/library/utils/R/utils] Error 1
> > make[3]: *** [all] Error 2
> > make[2]: *** [pkg-utils] Error 2
> > make[1]: *** [rpackage] Error 1
> > make: *** [all] Error 2
> >
> > Cheers,
> > H.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From ripley at stats.ox.ac.uk  Tue Feb  6 18:58:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Feb 2007 17:58:17 +0000 (GMT)
Subject: [Rd] Build error with last R-devel tarball
In-Reply-To: <1170782541.45c8b94db7006@webmail.fhcrc.org>
References: <1170719182.45c7c1cee2c96@webmail.fhcrc.org>
	<Pine.LNX.4.64.0702060726370.18593@gannet.stats.ox.ac.uk>
	<1170782541.45c8b94db7006@webmail.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0702061753460.1387@auk.stats>

On Tue, 6 Feb 2007, hpages at fhcrc.org wrote:

> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>
>> This was fixed in SVN within a few hours.  Tarballs are snapshots, please
>> check SVN before reporting problems.
>
> Thanks! I will check SVN before reporting problems with a tarball.
> Just hope that nobody will get too upset if I'm reporting a problem
> that just got fixed during the time I did 'svn up' and 'Send Message'
> though ;-)
>
>>
>> As I have said several times, please do not expect R-devel to build on all
>> platforms at all times.
>
> Of course. But please, let us know if reporting problems when they occur
> is still the right thing to do or not.

It's often a good idea to check 24-48 hours later and then report.
Autobuilders are running on about that frequency.

>
> Thanks,
> H.
>
>>
>> On Mon, 5 Feb 2007, hpages at fhcrc.org wrote:
>>
>>> Hi,
>>>
>>>
>>> On Windows, with last R-devel tarball (r40647) from
>>>  ftp://ftp.stat.math.ethz.ch/Software/R/R-devel_2007-02-04.tar.gz
>>> I get the following build error:
>>>
>>> E:\biocbld\bbs-2.0-bioc\R\src\gnuwin32> make
>>> ...
>>> ...
>>> ---------- Making package utils ------------
>>>  adding build stamp to DESCRIPTION
>>>  installing NAMESPACE file and metadata
>>>  installing R files
>>> Error in namespaceExport(ns, exports) : undefined exports :?,
>> CRAN.packages,
>>> Rprof, Rprofmem, RShowDo
>>> c, RSiteSearch, URLdecode, URLencode, alarm, apropos, argsAnywhere,
>>> assignInNamespace, as.roman, as.p
>>> erson, as.personList, available.packages, browseEnv, browseURL,
>> bug.report,
>>> capture.output, checkCRAN
>>> , chooseCRANmirror, citation, citEntry, citHeader, citFooter,
>> close.socket,
>>> combn, compareVersion, co
>>> ntrib.url, count.fields, data, data.entry, dataentry, de, de.ncols,
>> de.restore,
>>> de.setup, debugger, d
>>> emo, download.file, download.packages, dump.frames, edit, emacs, example,
>>> file_test, file.edit, find,
>>> fix, fixInNamespace, flush.console, formatOL, formatUL, getAnywhere,
>>> getFromNamespace, getS3method,
>>> glob2rx, head, head.matrix, help, help.search, help.start, history,
>>> index.search, install.packages, i
>>> nstalled.packages, limitedLabels, loadhistory, localeToCharset, ls.str,
>> lsf.str,
>>> make.packages.html,
>>> make.socket, memory.limit, memory.size, menu, methods, mirror2html,
>> modifyList,
>>> new.packag
>>> In addition: Warning message:
>>> S3 methods '[.getAnywhere', '[.roman', 'as.character.person',
>>> 'as.character.personList', 'as.characte
>>> r.roman', 'as.person.default', 'as.personList.default',
>> 'as.personList.person',
>>> 'edit.data.frame', 'e
>>> dit.default', 'edit.matrix', 'edit.vignette', 'format.roman',
>> 'head.data.frame',
>>> 'head.default', 'hea
>>> d.function', 'head.matrix', 'head.ftable', 'head.table', 'print.citation',
>>> 'print.Bibtex', 'print.cit
>>> ationList', 'print.getAnywhere', 'print.hsearch',
>> 'print.help_files_with_topic',
>>> 'print.Latex', 'prin
>>> t.ls_str', 'print.MethodsFunction', 'print.packageDescription',
>>> 'print.packageIQR', 'print.packageSta
>>> tus', 'print.roman', 'print.sessionInfo', 'print.socket',
>> 'print.vignette',
>>> 'prompt.data.frame', 'pro
>>> mpt.default', 'stack.data.frame', 'stack.default', 'str.POSIXt',
>>> 'str.data.frame', 'str.default', 'su
>>> mmary.packageStatus', 'tail.data.frame', 'tail.default', 'tail.function',
>>> 'tail.matrix', 'tail.ftable
>>> ', 'tail.table', 'toBibtex.citation', 'toBibtex.citationList',
>>> 'toBibtex.person', 'toBibtex [... trun
>>> cated]
>>> Execution halted
>>> make[4]: *** [E:/biocbld/bbs-2.0-bioc/R/library/utils/R/utils] Error 1
>>> make[3]: *** [all] Error 2
>>> make[2]: *** [pkg-utils] Error 2
>>> make[1]: *** [rpackage] Error 1
>>> make: *** [all] Error 2
>>>
>>> Cheers,
>>> H.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Feb  6 19:16:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Feb 2007 18:16:33 +0000 (GMT)
Subject: [Rd] RPM support for package installation?
In-Reply-To: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
References: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
Message-ID: <Pine.LNX.4.64.0702061800330.1387@auk.stats>

The problem is the speed with which R packages change.  My dept considered 
this, and decided against.  There have been something like 200 new 
versions of CRAN packages already this year.

Even if we provided automated wrappers to make source RPMs, someone would 
still have to build the binary RPMs for your (unstated) architecture and 
then install it.  Unless you use very few packages nor sysadmin is going 
to be happy with this approach.

It really is quite easy to have your own library and install packages 
there, and it will become easier in 2.5.0.  Your 'workaround' is the 
preferred solution for many sites including ours, although for our most 
popular architectures we also run a central site-library of popular 
packages (e.g. those used for teaching here).


On Tue, 6 Feb 2007, Rhiannon L Weaver wrote:

> Hello,
>
> Tech question, I hope this has not been addressed before.  I searched help
> archives and looked for online help but came up empty-handed.
>
> My question is: (short version) Is there a RPM-supported version of
> update.packages() for use with updating package libraries on managed
> multi-user Linux networks?
>
> Details:
>
> I put in a request for updating the version of R on one of the hosts on my
> work Unix network, which is managed by our IT department.  Current version
> is 2.1.0; I asked them to update to 2.4.1. The core update installed and I
> was able to test it, but the update had trouble loading the package
> "Matrix" for use with "lme4".  I don't recall the specific error (will
> check it out when the new version gets re-installed again and I can
> document it).  Other packages (lme, wavethresh, MASS) seemed to load
> without problems.
>
> I think the Matrix problem can be solved by running update.packages() but
> when I requested the admin to update packages for the new version, they
> said that they need to do this via an RPM.  Specifically (and I'm not a
> network guru so my advice may not be entirely accurate):
>
> me: I think if you have admin access you should be able to update the R
> packages by using the command update.packages() from within a running,
> updated version of R, and it will automatically check packages for new
> versions and update them.
>
> admin: But this method moves us to an unsustainable host with locally
> installed packages.  The add-on packages need to be installed via an RPM.
>
> As I understand it, RPM is like a kind of makefile for Linux machines.
> The help mentions need of -devel or -dev files for RPM installations and
> updates of the core software; is there a similar avenue I can point my
> admin to for package updates?  I'm not afraid of a little Linux, but I
> fear I am a bit out of my element on this one.
>
> Currently the workaround is for them to install the new version and for me
> to download and maintain packages locally.
>
> Thanks very much for your time,
> -Rhiannon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmacdon at med.umich.edu  Tue Feb  6 19:26:42 2007
From: jmacdon at med.umich.edu (James MacDonald)
Date: Tue, 06 Feb 2007 13:26:42 -0500
Subject: [Rd] R from SVN fails to build on win32
Message-ID: <45C881AF.47B0.00EE.0@med.umich.edu>

I get the following error when building R from the subversion server as
well as the latest tarball. I am on Windows XP, and I recently updated
my MinGW installation. It's quite possible I am doing something wrong,
but I am not sure what that might be.

making console.d from console.c
making dataentry.d from dataentry.c
making dynload.d from dynload.c
making edit.d from edit.c
making editor.d from editor.c
making embeddedR.d from embeddedR.c
making extra.d from extra.c
making opt.d from opt.c
making pager.d from pager.c
making preferences.d from preferences.c
making psignal.d from psignal.c
making rhome.d from rhome.c
making rui.d from rui.c
making run.d from run.c
making shext.d from shext.c
making sys-win32.d from sys-win32.c
making system.d from system.c
making dos_glob.d from dos_glob.c
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c console.c -o console.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c dataentry.c -o dataentry.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c dynload.c -o dynload.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c edit.c -o edit.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c editor.c -o editor.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c embeddedR.c -o embeddedR.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD -DLEA_MALLOC -c extra.c -o extra.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c opt.c -o opt.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c pager.c -o pager.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c preferences.c -o preferences.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c psignal.c -o psignal.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c rhome.c -o rhome.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c rui.c -o rui.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c run.c -o run.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c shext.c -o shext.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c sys-win32.c -o sys-win32.o
sys-win32.c: In function `do_system': sys-win32.c:183: warning: `hERR'
might be used uninitialized in this function gcc  -O3 -Wall -pedantic
-std=gnu99 -I../include -I. -DHAVE_CONFIG_H -DR_DLL_BUILD  -c system.c
-o system.o
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c dos_glob.c -o dos_glob.o
gcc     -c -o e_pow.o e_pow.S
gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
-DR_DLL_BUILD  -c malloc.c -o malloc.o
windres  -I ../include -i dllversion.rc -o dllversion.o
c:\MinGW\bin\windres.exe: unknown format type `../include'
c:\MinGW\bin\windres.exe: supported formats: rc res coff make[3]: ***
[dllversion.o] Error 1
make[2]: *** [../../bin/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2


Best,

Jim



James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


From ripley at stats.ox.ac.uk  Tue Feb  6 20:00:29 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Feb 2007 19:00:29 +0000 (GMT)
Subject: [Rd] R from SVN fails to build on win32
In-Reply-To: <45C881AF.47B0.00EE.0@med.umich.edu>
References: <45C881AF.47B0.00EE.0@med.umich.edu>
Message-ID: <Pine.LNX.4.64.0702061847470.6785@gannet.stats.ox.ac.uk>

You have not told us which version of R you are trying to build.
But this looks like a problem with your bintools, as nothing has changed 
in that line for a long time.

I am using binutils-2.17.50-20060824.  There was an update at the 
weekend, and I suspect that is broken because it says

     In addition it patches windres to allow use of spaces in filenames,

Does altering the Makefile to have -I../include work?


On Tue, 6 Feb 2007, James MacDonald wrote:

> I get the following error when building R from the subversion server as
> well as the latest tarball. I am on Windows XP, and I recently updated
> my MinGW installation. It's quite possible I am doing something wrong,
> but I am not sure what that might be.
>
> making console.d from console.c
> making dataentry.d from dataentry.c
> making dynload.d from dynload.c
> making edit.d from edit.c
> making editor.d from editor.c
> making embeddedR.d from embeddedR.c
> making extra.d from extra.c
> making opt.d from opt.c
> making pager.d from pager.c
> making preferences.d from preferences.c
> making psignal.d from psignal.c
> making rhome.d from rhome.c
> making rui.d from rui.c
> making run.d from run.c
> making shext.d from shext.c
> making sys-win32.d from sys-win32.c
> making system.d from system.c
> making dos_glob.d from dos_glob.c
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c console.c -o console.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c dataentry.c -o dataentry.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c dynload.c -o dynload.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c edit.c -o edit.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c editor.c -o editor.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c embeddedR.c -o embeddedR.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD -DLEA_MALLOC -c extra.c -o extra.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c opt.c -o opt.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c pager.c -o pager.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c preferences.c -o preferences.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c psignal.c -o psignal.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c rhome.c -o rhome.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c rui.c -o rui.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c run.c -o run.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c shext.c -o shext.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c sys-win32.c -o sys-win32.o
> sys-win32.c: In function `do_system': sys-win32.c:183: warning: `hERR'
> might be used uninitialized in this function gcc  -O3 -Wall -pedantic
> -std=gnu99 -I../include -I. -DHAVE_CONFIG_H -DR_DLL_BUILD  -c system.c
> -o system.o
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c dos_glob.c -o dos_glob.o
> gcc     -c -o e_pow.o e_pow.S
> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
> -DR_DLL_BUILD  -c malloc.c -o malloc.o
> windres  -I ../include -i dllversion.rc -o dllversion.o
> c:\MinGW\bin\windres.exe: unknown format type `../include'
> c:\MinGW\bin\windres.exe: supported formats: rc res coff make[3]: ***
> [dllversion.o] Error 1
> make[2]: *** [../../bin/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
>
>
> Best,
>
> Jim
>
>
>
> James W. MacDonald, M.S.
> Biostatistician
> Affymetrix and cDNA Microarray Core
> University of Michigan Cancer Center
> 1500 E. Medical Center Drive
> 7410 CCGC
> Ann Arbor MI 48109
> 734-647-5623
>
>
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rlweaver at stat.cmu.edu  Tue Feb  6 20:35:31 2007
From: rlweaver at stat.cmu.edu (Rhiannon L Weaver)
Date: Tue, 6 Feb 2007 14:35:31 -0500 (EST)
Subject: [Rd] RPM support for package installation?
In-Reply-To: <Pine.LNX.4.64.0702061800330.1387@auk.stats>
References: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
	<Pine.LNX.4.64.0702061800330.1387@auk.stats>
Message-ID: <Pine.LNX.4.64.0702061431080.754@hydra8.stat.cmu.edu>


Hi,

Thanks for the clarification.  As long as the admins don't mind (which I 
guess they won't because it means they won't have to build RPMs or 
binaries), I will be okay with just using local versions of the libraries. 
I just wanted to make sure I wasn't missing something obvious (which is 
probably pretty likely in situations like this).  Thanks again for your 
help.

-Rhiannon


On Tue, 6 Feb 2007, Prof Brian Ripley wrote:

> The problem is the speed with which R packages change.  My dept considered 
> this, and decided against.  There have been something like 200 new versions 
> of CRAN packages already this year.
>
> Even if we provided automated wrappers to make source RPMs, someone would 
> still have to build the binary RPMs for your (unstated) architecture and then 
> install it.  Unless you use very few packages nor sysadmin is going to be 
> happy with this approach.
>
> It really is quite easy to have your own library and install packages there, 
> and it will become easier in 2.5.0.  Your 'workaround' is the preferred 
> solution for many sites including ours, although for our most popular 
> architectures we also run a central site-library of popular packages (e.g. 
> those used for teaching here).
>
>
> On Tue, 6 Feb 2007, Rhiannon L Weaver wrote:
>
>> Hello,
>> 
>> Tech question, I hope this has not been addressed before.  I searched help
>> archives and looked for online help but came up empty-handed.
>> 
>> My question is: (short version) Is there a RPM-supported version of
>> update.packages() for use with updating package libraries on managed
>> multi-user Linux networks?
>> 
>> Details:
>> 
>> I put in a request for updating the version of R on one of the hosts on my
>> work Unix network, which is managed by our IT department.  Current version
>> is 2.1.0; I asked them to update to 2.4.1. The core update installed and I
>> was able to test it, but the update had trouble loading the package
>> "Matrix" for use with "lme4".  I don't recall the specific error (will
>> check it out when the new version gets re-installed again and I can
>> document it).  Other packages (lme, wavethresh, MASS) seemed to load
>> without problems.
>> 
>> I think the Matrix problem can be solved by running update.packages() but
>> when I requested the admin to update packages for the new version, they
>> said that they need to do this via an RPM.  Specifically (and I'm not a
>> network guru so my advice may not be entirely accurate):
>> 
>> me: I think if you have admin access you should be able to update the R
>> packages by using the command update.packages() from within a running,
>> updated version of R, and it will automatically check packages for new
>> versions and update them.
>> 
>> admin: But this method moves us to an unsustainable host with locally
>> installed packages.  The add-on packages need to be installed via an RPM.
>> 
>> As I understand it, RPM is like a kind of makefile for Linux machines.
>> The help mentions need of -devel or -dev files for RPM installations and
>> updates of the core software; is there a similar avenue I can point my
>> admin to for package updates?  I'm not afraid of a little Linux, but I
>> fear I am a bit out of my element on this one.
>> 
>> Currently the workaround is for them to install the new version and for me
>> to download and maintain packages locally.
>> 
>> Thanks very much for your time,
>> -Rhiannon
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From ripley at stats.ox.ac.uk  Tue Feb  6 20:38:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Feb 2007 19:38:20 +0000 (GMT)
Subject: [Rd] R from SVN fails to build on win32
In-Reply-To: <Pine.LNX.4.64.0702061847470.6785@gannet.stats.ox.ac.uk>
References: <45C881AF.47B0.00EE.0@med.umich.edu>
	<Pine.LNX.4.64.0702061847470.6785@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0702061935260.9092@gannet.stats.ox.ac.uk>

On Tue, 6 Feb 2007, Prof Brian Ripley wrote:

> You have not told us which version of R you are trying to build.
> But this looks like a problem with your bintools, as nothing has changed in 
> that line for a long time.
>
> I am using binutils-2.17.50-20060824.  There was an update at the weekend, 
> and I suspect that is broken because it says
>
>    In addition it patches windres to allow use of spaces in filenames,
>
> Does altering the Makefile to have -I../include work?

I am also having no problems with

[d:/R/svn/trunk/src/gnuwin32]% windres --version
GNU windres 2.17.50 20070129

>
>
> On Tue, 6 Feb 2007, James MacDonald wrote:
>
>> I get the following error when building R from the subversion server as
>> well as the latest tarball. I am on Windows XP, and I recently updated
>> my MinGW installation. It's quite possible I am doing something wrong,
>> but I am not sure what that might be.
>> 
>> making console.d from console.c
>> making dataentry.d from dataentry.c
>> making dynload.d from dynload.c
>> making edit.d from edit.c
>> making editor.d from editor.c
>> making embeddedR.d from embeddedR.c
>> making extra.d from extra.c
>> making opt.d from opt.c
>> making pager.d from pager.c
>> making preferences.d from preferences.c
>> making psignal.d from psignal.c
>> making rhome.d from rhome.c
>> making rui.d from rui.c
>> making run.d from run.c
>> making shext.d from shext.c
>> making sys-win32.d from sys-win32.c
>> making system.d from system.c
>> making dos_glob.d from dos_glob.c
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c console.c -o console.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c dataentry.c -o dataentry.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c dynload.c -o dynload.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c edit.c -o edit.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c editor.c -o editor.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c embeddedR.c -o embeddedR.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD -DLEA_MALLOC -c extra.c -o extra.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c opt.c -o opt.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c pager.c -o pager.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c preferences.c -o preferences.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c psignal.c -o psignal.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c rhome.c -o rhome.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c rui.c -o rui.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c run.c -o run.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c shext.c -o shext.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c sys-win32.c -o sys-win32.o
>> sys-win32.c: In function `do_system': sys-win32.c:183: warning: `hERR'
>> might be used uninitialized in this function gcc  -O3 -Wall -pedantic
>> -std=gnu99 -I../include -I. -DHAVE_CONFIG_H -DR_DLL_BUILD  -c system.c
>> -o system.o
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c dos_glob.c -o dos_glob.o
>> gcc     -c -o e_pow.o e_pow.S
>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>> -DR_DLL_BUILD  -c malloc.c -o malloc.o
>> windres  -I ../include -i dllversion.rc -o dllversion.o
>> c:\MinGW\bin\windres.exe: unknown format type `../include'
>> c:\MinGW\bin\windres.exe: supported formats: rc res coff make[3]: ***
>> [dllversion.o] Error 1
>> make[2]: *** [../../bin/R.dll] Error 2
>> make[1]: *** [rbuild] Error 2
>> make: *** [all] Error 2
>> 
>> 
>> Best,
>> 
>> Jim
>> 
>> 
>> 
>> James W. MacDonald, M.S.
>> Biostatistician
>> Affymetrix and cDNA Microarray Core
>> University of Michigan Cancer Center
>> 1500 E. Medical Center Drive
>> 7410 CCGC
>> Ann Arbor MI 48109
>> 734-647-5623
>> 
>> 
>> **********************************************************
>> Electronic Mail is not secure, may not be read every day, and should not be 
>> used for urgent or sensitive issues.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmacdon at med.umich.edu  Tue Feb  6 20:58:18 2007
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Tue, 06 Feb 2007 14:58:18 -0500
Subject: [Rd] R from SVN fails to build on win32
In-Reply-To: <Pine.LNX.4.64.0702061935260.9092@gannet.stats.ox.ac.uk>
References: <45C881AF.47B0.00EE.0@med.umich.edu>
	<Pine.LNX.4.64.0702061847470.6785@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0702061935260.9092@gannet.stats.ox.ac.uk>
Message-ID: <45C8DDDA.60503@med.umich.edu>

Hi Professor Ripley,

Prof Brian Ripley wrote:
> On Tue, 6 Feb 2007, Prof Brian Ripley wrote:
> 
>> You have not told us which version of R you are trying to build.
>> But this looks like a problem with your bintools, as nothing has 
>> changed in that line for a long time.
>>
>> I am using binutils-2.17.50-20060824.  There was an update at the 
>> weekend, and I suspect that is broken because it says
>>
>>    In addition it patches windres to allow use of spaces in filenames,
>>
>> Does altering the Makefile to have -I../include work?
> 
> 
> I am also having no problems with
> 
> [d:/R/svn/trunk/src/gnuwin32]% windres --version
> GNU windres 2.17.50 20070129

You were correct. I updated to binutils-2.17.50-20060824 and the 
compilation is now proceeding without error.

Thank you for the help!

Best,

Jim


> 
>>
>>
>> On Tue, 6 Feb 2007, James MacDonald wrote:
>>
>>> I get the following error when building R from the subversion server as
>>> well as the latest tarball. I am on Windows XP, and I recently updated
>>> my MinGW installation. It's quite possible I am doing something wrong,
>>> but I am not sure what that might be.
>>>
>>> making console.d from console.c
>>> making dataentry.d from dataentry.c
>>> making dynload.d from dynload.c
>>> making edit.d from edit.c
>>> making editor.d from editor.c
>>> making embeddedR.d from embeddedR.c
>>> making extra.d from extra.c
>>> making opt.d from opt.c
>>> making pager.d from pager.c
>>> making preferences.d from preferences.c
>>> making psignal.d from psignal.c
>>> making rhome.d from rhome.c
>>> making rui.d from rui.c
>>> making run.d from run.c
>>> making shext.d from shext.c
>>> making sys-win32.d from sys-win32.c
>>> making system.d from system.c
>>> making dos_glob.d from dos_glob.c
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c console.c -o console.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c dataentry.c -o dataentry.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c dynload.c -o dynload.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c edit.c -o edit.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c editor.c -o editor.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c embeddedR.c -o embeddedR.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD -DLEA_MALLOC -c extra.c -o extra.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c opt.c -o opt.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c pager.c -o pager.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c preferences.c -o preferences.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c psignal.c -o psignal.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c rhome.c -o rhome.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c rui.c -o rui.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c run.c -o run.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c shext.c -o shext.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c sys-win32.c -o sys-win32.o
>>> sys-win32.c: In function `do_system': sys-win32.c:183: warning: `hERR'
>>> might be used uninitialized in this function gcc  -O3 -Wall -pedantic
>>> -std=gnu99 -I../include -I. -DHAVE_CONFIG_H -DR_DLL_BUILD  -c system.c
>>> -o system.o
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c dos_glob.c -o dos_glob.o
>>> gcc     -c -o e_pow.o e_pow.S
>>> gcc  -O3 -Wall -pedantic -std=gnu99 -I../include -I. -DHAVE_CONFIG_H
>>> -DR_DLL_BUILD  -c malloc.c -o malloc.o
>>> windres  -I ../include -i dllversion.rc -o dllversion.o
>>> c:\MinGW\bin\windres.exe: unknown format type `../include'
>>> c:\MinGW\bin\windres.exe: supported formats: rc res coff make[3]: ***
>>> [dllversion.o] Error 1
>>> make[2]: *** [../../bin/R.dll] Error 2
>>> make[1]: *** [rbuild] Error 2
>>> make: *** [all] Error 2
>>>
>>>
>>> Best,
>>>
>>> Jim
>>>
>>>
>>>
>>> James W. MacDonald, M.S.
>>> Biostatistician
>>> Affymetrix and cDNA Microarray Core
>>> University of Michigan Cancer Center
>>> 1500 E. Medical Center Drive
>>> 7410 CCGC
>>> Ann Arbor MI 48109
>>> 734-647-5623
>>>
>>>
>>> **********************************************************
>>> Electronic Mail is not secure, may not be read every day, and should 
>>> not be used for urgent or sensitive issues.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
> 


-- 
James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


From byron.ellis at gmail.com  Tue Feb  6 22:32:29 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Tue, 6 Feb 2007 13:32:29 -0800
Subject: [Rd] Transparency convenience function
Message-ID: <7098abec0702061332y3de9756md407f550757a87fd@mail.gmail.com>

Hi all,

For making plots with transparency I've found the following function
quite useful when specifying colors that I thought might be of
interest (I suspect it's easier to implement under R-devel. IIRC rgb()
now takes matrix arguments):

alpha <- function(colors,alpha=1.0) {
	if(alpha < 0 || alpha > 1)
		stop("alpha must be in [0,1]")
	apply(col2rgb(colors)/255,2,function(x) rgb(x[1],x[2],x[3],alpha))
}

-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From roebuck at mdanderson.org  Wed Feb  7 06:56:51 2007
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Tue, 6 Feb 2007 23:56:51 -0600 (CST)
Subject: [Rd] Help with OS X (BSD) ps command
In-Reply-To: <xmr64akoe2l.fsf@mralx1.rsma.frb.gov>
References: <xmr64akoe2l.fsf@mralx1.rsma.frb.gov>
Message-ID: <Pine.OSF.4.58.0702062303530.122756@wotan.mdacc.tmc.edu>

On Fri, 2 Feb 2007, Jeffrey J. Hallman wrote:

> My fame package has a function that checks to see if
> a FAME SERVER process is already running.  On Linux,
> I can do this in one of two ways:
>
>   pid <- Sys.getpid()
>   user <- Sys.info()["user"]
>
>   cmd <- paste("pgrep -fU", user, "-P", pid, "'FAME SERVER'")
>   fameRunning <- as.logical(length(system(cmd, intern = T)))
>
> or I can use
>
>   cmd <- paste("ps -ef | grep", user, "| grep", pid,
>                  "| grep -v grep | grep -c 'FAME SERVER'")
>   fameRunning <- as.logical(as.numeric(system(cmd, intern = T)))
>
> Mac OS X does not have pgrep, and being a BSD
> derivative, takes different arguments for the 'ps'
> command.  I don't have access to a BSD machine. Can
> someone who does tell me the correct invocation of
> 'ps' to see if 'user' is running a 'FAME SERVER'
> process with the R process as its parent process?
>
> While FAME is not officially supported on OS X, I
> am told that it can be made to work there.  Had I
> not heard this, of course, I could just answer FALSE
> for OS X and be done with it.

<<untested>>
cmd <- paste("ps -o user,ppid,command", "| ",
             "grep", user, "| ",
             "grep", pid, "| "
             "grep -c '[F]AME SERVER'")

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From maechler at stat.math.ethz.ch  Wed Feb  7 14:57:37 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 Feb 2007 14:57:37 +0100
Subject: [Rd] RPM support for package installation?
In-Reply-To: <Pine.LNX.4.64.0702061431080.754@hydra8.stat.cmu.edu>
References: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
	<Pine.LNX.4.64.0702061800330.1387@auk.stats>
	<Pine.LNX.4.64.0702061431080.754@hydra8.stat.cmu.edu>
Message-ID: <17865.56017.573249.622745@stat.math.ethz.ch>

>>>>> "Rhiannon" == Rhiannon L Weaver <rlweaver at stat.cmu.edu>
>>>>>     on Tue, 6 Feb 2007 14:35:31 -0500 (EST) writes:

    Rhiannon> Hi,

    Rhiannon> Thanks for the clarification.  As long as the
    Rhiannon> admins don't mind (which I guess they won't
    Rhiannon> because it means they won't have to build RPMs or
    Rhiannon> binaries), I will be okay with just using local
    Rhiannon> versions of the libraries.  

You will be using local version of the  ** packages **
by installing them into your own library.  Try to be careful not
to confuse the two terms.

    Rhiannon> versions of the libraries.  I just wanted to make
    Rhiannon> sure I wasn't missing something obvious (which is
    Rhiannon> probably pretty likely in situations like this).
    Rhiannon> Thanks again for your help.

    Rhiannon> -Rhiannon


    Rhiannon> On Tue, 6 Feb 2007, Prof Brian Ripley wrote:

    >> The problem is the speed with which R packages change.
    >> My dept considered this, and decided against.  There have
    >> been something like 200 new versions of CRAN packages
    >> already this year.
    >> 
    >> Even if we provided automated wrappers to make source
    >> RPMs, someone would still have to build the binary RPMs
    >> for your (unstated) architecture and then install it.
    >> Unless you use very few packages nor sysadmin is going to
    >> be happy with this approach.
    >> 
    >> It really is quite easy to have your own library and
    >> install packages there, and it will become easier in
    >> 2.5.0.  Your 'workaround' is the preferred solution for
    >> many sites including ours, although for our most popular
    >> architectures we also run a central site-library of
    >> popular packages (e.g.  those used for teaching here).
    >> 
    >> 
    >> On Tue, 6 Feb 2007, Rhiannon L Weaver wrote:
    >> 
    >>> Hello,
    >>> 
    >>> Tech question, I hope this has not been addressed
    >>> before.  I searched help archives and looked for online
    >>> help but came up empty-handed.
    >>> 
    >>> My question is: (short version) Is there a RPM-supported
    >>> version of update.packages() for use with updating
    >>> package libraries on managed multi-user Linux networks?
    >>> 
    >>> Details:
    >>> 
    >>> I put in a request for updating the version of R on one
    >>> of the hosts on my work Unix network, which is managed
    >>> by our IT department.  Current version is 2.1.0; I asked
    >>> them to update to 2.4.1. The core update installed and I
    >>> was able to test it, but the update had trouble loading
    >>> the package "Matrix" for use with "lme4".  I don't
    >>> recall the specific error (will check it out when the
    >>> new version gets re-installed again and I can document
    >>> it).  Other packages (lme, wavethresh, MASS) seemed to
    >>> load without problems.
    >>> 
    >>> I think the Matrix problem can be solved by running
    >>> update.packages() but when I requested the admin to
    >>> update packages for the new version, they said that they
    >>> need to do this via an RPM.  Specifically (and I'm not a
    >>> network guru so my advice may not be entirely accurate):
    >>> 
    >>> me: I think if you have admin access you should be able
    >>> to update the R packages by using the command
    >>> update.packages() from within a running, updated version
    >>> of R, and it will automatically check packages for new
    >>> versions and update them.
    >>> 
    >>> admin: But this method moves us to an unsustainable host
    >>> with locally installed packages.  The add-on packages
    >>> need to be installed via an RPM.
    >>> 
    >>> As I understand it, RPM is like a kind of makefile for
    >>> Linux machines.  The help mentions need of -devel or
    >>> -dev files for RPM installations and updates of the core
    >>> software; is there a similar avenue I can point my admin
    >>> to for package updates?  I'm not afraid of a little
    >>> Linux, but I fear I am a bit out of my element on this
    >>> one.
    >>> 
    >>> Currently the workaround is for them to install the new
    >>> version and for me to download and maintain packages
    >>> locally.
    >>> 
    >>> Thanks very much for your time, -Rhiannon
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 
    >> -- 
    >> Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
    >> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
    >> University of Oxford, Tel: +44 1865 272861 (self) 1 South
    >> Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG, UK Fax:
    >> +44 1865 272595
    >> 

    Rhiannon> ______________________________________________
    Rhiannon> R-devel at r-project.org mailing list
    Rhiannon> https://stat.ethz.ch/mailman/listinfo/r-devel


From lei.wu at jax.org  Wed Feb  7 16:12:12 2007
From: lei.wu at jax.org (Lei Wu)
Date: Wed, 7 Feb 2007 10:12:12 -0500
Subject: [Rd] what's the C code for La.svd function?
In-Reply-To: <Pine.OSF.4.58.0702062303530.122756@wotan.mdacc.tmc.edu>
Message-ID: <20070207101212688.00000001288@phocid>

Hi R gurus,

If I want to bring back the old La.svd in R-2.3.0, which C files I need to bring back? The current La.svd() runs much faster, but not robust enough. It failed on some datasets. I would like to bring back the old one even it's slower.

Thank you very much for any hint.

Lei


From maechler at stat.math.ethz.ch  Wed Feb  7 18:46:20 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 Feb 2007 18:46:20 +0100
Subject: [Rd] RPM support for package installation?
In-Reply-To: <1170858494.27046.38.camel@biol102145.oulu.fi>
References: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
	<Pine.LNX.4.64.0702061800330.1387@auk.stats>
	<Pine.LNX.4.64.0702061431080.754@hydra8.stat.cmu.edu>
	<17865.56017.573249.622745@stat.math.ethz.ch>
	<1170858494.27046.38.camel@biol102145.oulu.fi>
Message-ID: <17866.4204.691875.320401@stat.math.ethz.ch>

>>>>> "Jari" == Jari Oksanen <jarioksa at sun3.oulu.fi>
>>>>>     on Wed, 07 Feb 2007 16:28:14 +0200 writes:

    Jari> On Wed, 2007-02-07 at 14:57 +0100, Martin Maechler wrote:
    >> >>>>> "Rhiannon" == Rhiannon L Weaver <rlweaver at stat.cmu.edu>
    >> >>>>>     on Tue, 6 Feb 2007 14:35:31 -0500 (EST) writes:
    >> 
    Rhiannon> Hi,
    >> 
    Rhiannon> Thanks for the clarification.  As long as the
    Rhiannon> admins don't mind (which I guess they won't
    Rhiannon> because it means they won't have to build RPMs or
    Rhiannon> binaries), I will be okay with just using local
    Rhiannon> versions of the libraries.  
    >> 
    >> You will be using local version of the  ** packages **
    >> by installing them into your own library.  Try to be careful not
    >> to confuse the two terms.

    Jari> This is what Wikipedia says:

    Jari> "R is also highly extensible through the use of packages, which are
    Jari> user-submitted libraries..."
    Jari> (http://en.wikipedia.org/wiki/R_%28programming_language%29)

    Jari> Time to correct Wikipedia?

Yes, please!  I don't have time currently...
Martin


From prechelt at inf.fu-berlin.de  Wed Feb  7 19:39:36 2007
From: prechelt at inf.fu-berlin.de (Lutz Prechelt)
Date: Wed, 7 Feb 2007 19:39:36 +0100
Subject: [Rd] manage R function and data dependencies like 'make'
Message-ID: <793FF35679078340BCDDA196B495E57E1F0968@spree.pcpool.mi.fu-berlin.de>

Dear R-devels,

I am looking for a package (or some other infrastructure) for the
following situation:

I am doing a larger data evaluation.
I have several dozen data files and do not want to keep the persistent
data in the R workspace (for robustness reasons).
I have several dozen R files, some for reading and preprocessing data
files, others for doing plots or analyses.
I will make frequent changes to both data files and R files while doing
the analysis.

I would like to automate mechanisms that allow 
- a data file reading function to suppress its actual work if neither
the data file nor the R file containing the function were modified since
the data file was last read
- an R file sourcing function to suppress its actual work if the R file
has not been modified
- and perhaps even: automate re-reading a data file upon access to the
corresponding dataframe iff the file has been modified since the
dataframe was created.

In short: Something like Unix's 'make', but for managing dependencies of
functions and dataframes in addition to files. In R. (And of course I am
very open for solutions that are more elegant than what I have sketched
above.)

I could not find something in the help and have rather few ideas for
good search terms.

I any such thing available?
(If no such infrastructure exists, what is the right R function for
accessing file modification dates?)

Thanks!

  Lutz


From ripley at stats.ox.ac.uk  Wed Feb  7 19:48:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 Feb 2007 18:48:30 +0000 (GMT)
Subject: [Rd] manage R function and data dependencies like 'make'
In-Reply-To: <793FF35679078340BCDDA196B495E57E1F0968@spree.pcpool.mi.fu-berlin.de>
References: <793FF35679078340BCDDA196B495E57E1F0968@spree.pcpool.mi.fu-berlin.de>
Message-ID: <Pine.LNX.4.64.0702071845180.2816@gannet.stats.ox.ac.uk>

R-devel has file_test() in utils (earlier versions had a private version 
in tools).  That has a '-nt' op to do what you need.

file.info() accesses modification dates.

Having said that, I would use 'make' as for example R's own test suites 
do.

On Wed, 7 Feb 2007, Lutz Prechelt wrote:

> Dear R-devels,
>
> I am looking for a package (or some other infrastructure) for the
> following situation:
>
> I am doing a larger data evaluation.
> I have several dozen data files and do not want to keep the persistent
> data in the R workspace (for robustness reasons).
> I have several dozen R files, some for reading and preprocessing data
> files, others for doing plots or analyses.
> I will make frequent changes to both data files and R files while doing
> the analysis.
>
> I would like to automate mechanisms that allow
> - a data file reading function to suppress its actual work if neither
> the data file nor the R file containing the function were modified since
> the data file was last read
> - an R file sourcing function to suppress its actual work if the R file
> has not been modified
> - and perhaps even: automate re-reading a data file upon access to the
> corresponding dataframe iff the file has been modified since the
> dataframe was created.
>
> In short: Something like Unix's 'make', but for managing dependencies of
> functions and dataframes in addition to files. In R. (And of course I am
> very open for solutions that are more elegant than what I have sketched
> above.)
>
> I could not find something in the help and have rather few ideas for
> good search terms.
>
> I any such thing available?
> (If no such infrastructure exists, what is the right R function for
> accessing file modification dates?)
>
> Thanks!
>
>  Lutz
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Wed Feb  7 20:41:04 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 07 Feb 2007 14:41:04 -0500
Subject: [Rd] manage R function and data dependencies like 'make'
In-Reply-To: <793FF35679078340BCDDA196B495E57E1F0968@spree.pcpool.mi.fu-berlin.de>
References: <793FF35679078340BCDDA196B495E57E1F0968@spree.pcpool.mi.fu-berlin.de>
Message-ID: <45CA2B50.30301@bank-banque-canada.ca>

I use make to do things like you describe. Here is an example target 
from one of my Makerules files:

$(T:%=compare.R$(REP).T%):compare.%: compare.R estimates.%
	@echo making $(notdir $(PWD)) $@ because $? changed ...
	@(cd  $(subst compare.,,$@) ; \
	    echo "z <- try( source('../compare.R')); \
	  if (!inherits(z, 'try-error')) q('yes', status=0) else \
	   {print(z); q('yes', status=1)} "  | \
	      R --slave >../$(FLAGS)/$@.log 2>&1)
	@mv $(FLAGS)/$@.log $(FLAGS)/$@


I realize this is out of context and possibly mangled by mail wrap, but 
if you are familiar with (GNU) make then it should give you a good idea 
what to do. In this example I am accumulating (intermediate) things in 
the .RData file and using flags as targets to indicate the status of 
different steps. Another possibility would be to rename the .RData files 
and use them as the targets. Let me know if you want a more complete 
example.

I really would encourage you to think of wrapping R (like a compiler) in 
make, rather than trying to re-implement something like make within R.

(I would be interested to see examples if anyone is using Ant to do this 
kind of thing.)

Paul


Lutz Prechelt wrote:
> Dear R-devels,
> 
> I am looking for a package (or some other infrastructure) for the
> following situation:
> 
> I am doing a larger data evaluation.
> I have several dozen data files and do not want to keep the persistent
> data in the R workspace (for robustness reasons).
> I have several dozen R files, some for reading and preprocessing data
> files, others for doing plots or analyses.
> I will make frequent changes to both data files and R files while doing
> the analysis.
> 
> I would like to automate mechanisms that allow 
> - a data file reading function to suppress its actual work if neither
> the data file nor the R file containing the function were modified since
> the data file was last read
> - an R file sourcing function to suppress its actual work if the R file
> has not been modified
> - and perhaps even: automate re-reading a data file upon access to the
> corresponding dataframe iff the file has been modified since the
> dataframe was created.
> 
> In short: Something like Unix's 'make', but for managing dependencies of
> functions and dataframes in addition to files. In R. (And of course I am
> very open for solutions that are more elegant than what I have sketched
> above.)
> 
> I could not find something in the help and have rather few ideas for
> good search terms.
> 
> I any such thing available?
> (If no such infrastructure exists, what is the right R function for
> accessing file modification dates?)
> 
> Thanks!
> 
>   Lutz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From mwkimpel at gmail.com  Thu Feb  8 08:14:26 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Thu, 08 Feb 2007 02:14:26 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
Message-ID: <45CACDD2.9060007@gmail.com>

Hans-Peter and other R developers,

How are you? Have you made any progess with embedding Url's in Excel?

Well, I have been busy thinking of more things for you to do;)

My colleagues in the lab are not R literate, and some are barely 
computer literate, so I give them everything in Excel workbooks. I have 
gradually evolved a system such that these workbooks have become 
compendia of my data, output, and methods. That, in fact, is why I 
bought the Pro version of xlsReadWritePro. I have been saving graphics 
as PDF files, then inserting them as object in Excel sheets.

What I would like to be able to do is to embed objects (files) in sheets 
of a workbook directly from within R. I would also like to be able to 
save my current R workspace as an object embedded in a sheet so that in 
the future, if packages change, I could go back and recreate the 
analysis. I do not need to be able to manuipulate files that R has not 
created, like a PDF file from another user. I would, however, like to be 
able to save my graphics as PDF files inside a worksheet, even if it 
meant creating a  temp file or something.

Before people begin talking about how MySQL or some other database could 
handle all that archiving, let me say that that is not what my 
colleagues want. They want a nice Excel file that they can take home on 
there laptops. One thing I like about worksheets is that they themselves 
can contain many embedded files, so it keeps our virtual desks neater 
and less confusing.

Hans, if you could do this, it would be of tremendous benefit to me and 
hopefully a lot of people. R developers tend to think that all 
scientists are running Linux on 64-bit computers, but most biomedical 
researches still store date in Excel files. This won't solve everybody's 
needs, but it could be a start.

Well, let me know what you think. I am cc'ing R-devel to see if any of 
those guys have ideas as well.

Thanks,
Mark



-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From villegas.ro at gmail.com  Thu Feb  8 11:24:57 2007
From: villegas.ro at gmail.com (R. Villegas)
Date: Thu, 8 Feb 2007 11:24:57 +0100
Subject: [Rd] possible bug: dev.copy / could not find any X11 fonts
In-Reply-To: <20070131145039.GA12289@pu100877.student.princeton.edu>
References: <20070131145039.GA12289@pu100877.student.princeton.edu>
Message-ID: <29cf68350702080224l292bb9abt429309c4e7e66b8e@mail.gmail.com>

2007/1/31, Tamas K Papp <tpapp at princeton.edu>:
> Hi,
>
> I am experiencing something strange, and thought I would ask before
> reporting a bug.  I trimmed it down to a self-contained example,
> attached as an R file.  The purpose of the functions is to save the
> plots into a ps file and simultaneously plot them on an x11 device,
> but don't open a new one if there is already one opened (I don't want
> the repositioning / flicker).
>
> When running the code:
>
> > source("plotf.r")
> > plotf(avc,1)
> Error in dev.copy(which = x11dev) : could not find any X11 fonts
> Check that the Font Path is correct.
>
> The error message reappears whenever I switch to the plot window.  A
> partial plot is in the x11 window.
>
> When called in other contexts, plotting functions work perfectly, so I
> don't see what the problem is.
>
> Thanks,
>
> Tamas
>
>
> version information:
>                _
> platform       i486-pc-linux-gnu
> arch           i486
> os             linux-gnu
> system         i486, linux-gnu
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>

I see this error last time in Ubuntu Edgy. Check your FontPath in
/etc/X11/xorg.conf.


From hin-tak.leung at cimr.cam.ac.uk  Thu Feb  8 12:16:55 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 08 Feb 2007 11:16:55 +0000
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <45CACDD2.9060007@gmail.com>
References: <45CACDD2.9060007@gmail.com>
Message-ID: <45CB06A7.5080007@cimr.cam.ac.uk>

I don't know of any native xls read/write facility in R, either
in core or as add-ons (I could be wrong), but if you want some source 
code to scavenge on to build some R package out of it, there are two
perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel
which are small enough to "read from front cover to back cover",
so to speak, might be useful for reference and steal code from.

The other open-source packages which can read/write excel files
are gnumeric and openoffice and probably too big to find one's way 
around the source code to steal there :-).

Good luck.

HTL

Mark W Kimpel wrote:
> Hans-Peter and other R developers,
> 
> How are you? Have you made any progess with embedding Url's in Excel?
> 
> Well, I have been busy thinking of more things for you to do;)
> 
> My colleagues in the lab are not R literate, and some are barely 
> computer literate, so I give them everything in Excel workbooks. I have 
> gradually evolved a system such that these workbooks have become 
> compendia of my data, output, and methods. That, in fact, is why I 
> bought the Pro version of xlsReadWritePro. I have been saving graphics 
> as PDF files, then inserting them as object in Excel sheets.
> 
> What I would like to be able to do is to embed objects (files) in sheets 
> of a workbook directly from within R. I would also like to be able to 
> save my current R workspace as an object embedded in a sheet so that in 
> the future, if packages change, I could go back and recreate the 
> analysis. I do not need to be able to manuipulate files that R has not 
> created, like a PDF file from another user. I would, however, like to be 
> able to save my graphics as PDF files inside a worksheet, even if it 
> meant creating a  temp file or something.
> 
> Before people begin talking about how MySQL or some other database could 
> handle all that archiving, let me say that that is not what my 
> colleagues want. They want a nice Excel file that they can take home on 
> there laptops. One thing I like about worksheets is that they themselves 
> can contain many embedded files, so it keeps our virtual desks neater 
> and less confusing.
> 
> Hans, if you could do this, it would be of tremendous benefit to me and 
> hopefully a lot of people. R developers tend to think that all 
> scientists are running Linux on 64-bit computers, but most biomedical 
> researches still store date in Excel files. This won't solve everybody's 
> needs, but it could be a start.
> 
> Well, let me know what you think. I am cc'ing R-devel to see if any of 
> those guys have ideas as well.
> 
> Thanks,
> Mark
> 
> 
>


From jmacdon at med.umich.edu  Thu Feb  8 14:15:10 2007
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Thu, 08 Feb 2007 08:15:10 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <45CB06A7.5080007@cimr.cam.ac.uk>
References: <45CACDD2.9060007@gmail.com> <45CB06A7.5080007@cimr.cam.ac.uk>
Message-ID: <45CB225E.6020702@med.umich.edu>

Have you looked at RDCOMClient? I would imagine you could do what you 
want with this package.

http://www.omegahat.org/RDCOMClient/

Best,

Jim

Hin-Tak Leung wrote:
> I don't know of any native xls read/write facility in R, either
> in core or as add-ons (I could be wrong), but if you want some source 
> code to scavenge on to build some R package out of it, there are two
> perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel
> which are small enough to "read from front cover to back cover",
> so to speak, might be useful for reference and steal code from.
> 
> The other open-source packages which can read/write excel files
> are gnumeric and openoffice and probably too big to find one's way 
> around the source code to steal there :-).
> 
> Good luck.
> 
> HTL
> 
> Mark W Kimpel wrote:
> 
>>Hans-Peter and other R developers,
>>
>>How are you? Have you made any progess with embedding Url's in Excel?
>>
>>Well, I have been busy thinking of more things for you to do;)
>>
>>My colleagues in the lab are not R literate, and some are barely 
>>computer literate, so I give them everything in Excel workbooks. I have 
>>gradually evolved a system such that these workbooks have become 
>>compendia of my data, output, and methods. That, in fact, is why I 
>>bought the Pro version of xlsReadWritePro. I have been saving graphics 
>>as PDF files, then inserting them as object in Excel sheets.
>>
>>What I would like to be able to do is to embed objects (files) in sheets 
>>of a workbook directly from within R. I would also like to be able to 
>>save my current R workspace as an object embedded in a sheet so that in 
>>the future, if packages change, I could go back and recreate the 
>>analysis. I do not need to be able to manuipulate files that R has not 
>>created, like a PDF file from another user. I would, however, like to be 
>>able to save my graphics as PDF files inside a worksheet, even if it 
>>meant creating a  temp file or something.
>>
>>Before people begin talking about how MySQL or some other database could 
>>handle all that archiving, let me say that that is not what my 
>>colleagues want. They want a nice Excel file that they can take home on 
>>there laptops. One thing I like about worksheets is that they themselves 
>>can contain many embedded files, so it keeps our virtual desks neater 
>>and less confusing.
>>
>>Hans, if you could do this, it would be of tremendous benefit to me and 
>>hopefully a lot of people. R developers tend to think that all 
>>scientists are running Linux on 64-bit computers, but most biomedical 
>>researches still store date in Excel files. This won't solve everybody's 
>>needs, but it could be a start.
>>
>>Well, let me know what you think. I am cc'ing R-devel to see if any of 
>>those guys have ideas as well.
>>
>>Thanks,
>>Mark
>>
>>
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


From hin-tak.leung at cimr.cam.ac.uk  Thu Feb  8 14:50:15 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 08 Feb 2007 13:50:15 +0000
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <45CB225E.6020702@med.umich.edu>
References: <45CACDD2.9060007@gmail.com> <45CB06A7.5080007@cimr.cam.ac.uk>
	<45CB225E.6020702@med.umich.edu>
Message-ID: <45CB2A97.4080306@cimr.cam.ac.uk>

James W. MacDonald wrote:
> Have you looked at RDCOMClient? I would imagine you could do what you 
> want with this package.
> 
> http://www.omegahat.org/RDCOMClient/

Interesting point. But the dcom client would be windows-specific?
(those I mentioned - the perl mondules, openoffice, run on windows,
as well as unix boxes - not sure about gnumeric :-).

In fact there is a very perverse way of doing it - ActiveState provides
a PerlCom product for hooking up dcom with activestate perl. i.e. you 
can go via R -> RDComClient -> PerlCom -> ActiveState Perl -> 
SpreadSheet::* . Just so that it does not require Excel installed
or an MS Office license...

In that sense, probably technology based on bridging over odbc
is also acceptable?

HTL

> Hin-Tak Leung wrote:
>> I don't know of any native xls read/write facility in R, either
>> in core or as add-ons (I could be wrong), but if you want some source 
>> code to scavenge on to build some R package out of it, there are two
>> perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel
>> which are small enough to "read from front cover to back cover",
>> so to speak, might be useful for reference and steal code from.
>>
>> The other open-source packages which can read/write excel files
>> are gnumeric and openoffice and probably too big to find one's way 
>> around the source code to steal there :-).
>>
>> Good luck.
>>
>> HTL
>>
>> Mark W Kimpel wrote:
>>
>>> Hans-Peter and other R developers,
>>>
>>> How are you? Have you made any progess with embedding Url's in Excel?
>>>
>>> Well, I have been busy thinking of more things for you to do;)
>>>
>>> My colleagues in the lab are not R literate, and some are barely 
>>> computer literate, so I give them everything in Excel workbooks. I 
>>> have gradually evolved a system such that these workbooks have become 
>>> compendia of my data, output, and methods. That, in fact, is why I 
>>> bought the Pro version of xlsReadWritePro. I have been saving 
>>> graphics as PDF files, then inserting them as object in Excel sheets.
>>>
>>> What I would like to be able to do is to embed objects (files) in 
>>> sheets of a workbook directly from within R. I would also like to be 
>>> able to save my current R workspace as an object embedded in a sheet 
>>> so that in the future, if packages change, I could go back and 
>>> recreate the analysis. I do not need to be able to manuipulate files 
>>> that R has not created, like a PDF file from another user. I would, 
>>> however, like to be able to save my graphics as PDF files inside a 
>>> worksheet, even if it meant creating a  temp file or something.
>>>
>>> Before people begin talking about how MySQL or some other database 
>>> could handle all that archiving, let me say that that is not what my 
>>> colleagues want. They want a nice Excel file that they can take home 
>>> on there laptops. One thing I like about worksheets is that they 
>>> themselves can contain many embedded files, so it keeps our virtual 
>>> desks neater and less confusing.
>>>
>>> Hans, if you could do this, it would be of tremendous benefit to me 
>>> and hopefully a lot of people. R developers tend to think that all 
>>> scientists are running Linux on 64-bit computers, but most biomedical 
>>> researches still store date in Excel files. This won't solve 
>>> everybody's needs, but it could be a start.
>>>
>>> Well, let me know what you think. I am cc'ing R-devel to see if any 
>>> of those guys have ideas as well.
>>>
>>> Thanks,
>>> Mark
>>>
>>>
>>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From whit.armstrong at hcmny.com  Thu Feb  8 15:05:25 2007
From: whit.armstrong at hcmny.com (Armstrong, Whit)
Date: Thu, 8 Feb 2007 09:05:25 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
Message-ID: <E58BE6136618CF4C964F6EC7773AE569F5700E@ex4.nyc.hcmny.com>

you can also use my package which uses Jakarta POI to write the excel
files.

It can be used on any platform that supports java.

The Perl solution may be better if you want to do anything complicated,
but this package supports writing all basic R objects.

http://code.google.com/p/rexcelpoi/




> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Hin-Tak Leung
> Sent: Thursday, February 08, 2007 8:50 AM
> To: James W. MacDonald
> Cc: mwkimpel at gmail.com; Mark W. Kimpel MD 
> (mkimpel at iupui.edu); r-devel at r-project.org
> Subject: Re: [Rd] xlsReadWrite Pro and embedding objects and 
> files in Excel worksheets
> 
> James W. MacDonald wrote:
> > Have you looked at RDCOMClient? I would imagine you could 
> do what you 
> > want with this package.
> > 
> > http://www.omegahat.org/RDCOMClient/
> 
> Interesting point. But the dcom client would be windows-specific?
> (those I mentioned - the perl mondules, openoffice, run on 
> windows, as well as unix boxes - not sure about gnumeric :-).
> 
> In fact there is a very perverse way of doing it - 
> ActiveState provides a PerlCom product for hooking up dcom 
> with activestate perl. i.e. you can go via R -> RDComClient 
> -> PerlCom -> ActiveState Perl ->
> SpreadSheet::* . Just so that it does not require Excel 
> installed or an MS Office license...
> 
> In that sense, probably technology based on bridging over 
> odbc is also acceptable?
> 
> HTL
> 
> > Hin-Tak Leung wrote:
> >> I don't know of any native xls read/write facility in R, either in 
> >> core or as add-ons (I could be wrong), but if you want some source 
> >> code to scavenge on to build some R package out of it, 
> there are two 
> >> perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel 
> >> which are small enough to "read from front cover to back 
> cover", so 
> >> to speak, might be useful for reference and steal code from.
> >>
> >> The other open-source packages which can read/write excel 
> files are 
> >> gnumeric and openoffice and probably too big to find one's 
> way around 
> >> the source code to steal there :-).
> >>
> >> Good luck.
> >>
> >> HTL
> >>
> >> Mark W Kimpel wrote:
> >>
> >>> Hans-Peter and other R developers,
> >>>
> >>> How are you? Have you made any progess with embedding 
> Url's in Excel?
> >>>
> >>> Well, I have been busy thinking of more things for you to do;)
> >>>
> >>> My colleagues in the lab are not R literate, and some are barely 
> >>> computer literate, so I give them everything in Excel 
> workbooks. I 
> >>> have gradually evolved a system such that these workbooks have 
> >>> become compendia of my data, output, and methods. That, 
> in fact, is 
> >>> why I bought the Pro version of xlsReadWritePro. I have 
> been saving 
> >>> graphics as PDF files, then inserting them as object in 
> Excel sheets.
> >>>
> >>> What I would like to be able to do is to embed objects (files) in 
> >>> sheets of a workbook directly from within R. I would also 
> like to be 
> >>> able to save my current R workspace as an object embedded 
> in a sheet 
> >>> so that in the future, if packages change, I could go back and 
> >>> recreate the analysis. I do not need to be able to 
> manuipulate files 
> >>> that R has not created, like a PDF file from another 
> user. I would, 
> >>> however, like to be able to save my graphics as PDF files 
> inside a 
> >>> worksheet, even if it meant creating a  temp file or something.
> >>>
> >>> Before people begin talking about how MySQL or some other 
> database 
> >>> could handle all that archiving, let me say that that is 
> not what my 
> >>> colleagues want. They want a nice Excel file that they 
> can take home 
> >>> on there laptops. One thing I like about worksheets is that they 
> >>> themselves can contain many embedded files, so it keeps 
> our virtual 
> >>> desks neater and less confusing.
> >>>
> >>> Hans, if you could do this, it would be of tremendous 
> benefit to me 
> >>> and hopefully a lot of people. R developers tend to think 
> that all 
> >>> scientists are running Linux on 64-bit computers, but most 
> >>> biomedical researches still store date in Excel files. This won't 
> >>> solve everybody's needs, but it could be a start.
> >>>
> >>> Well, let me know what you think. I am cc'ing R-devel to 
> see if any 
> >>> of those guys have ideas as well.
> >>>
> >>> Thanks,
> >>> Mark
> >>>
> >>>
> >>>
> >>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 




This e-mail message is intended only for the named recipient(s) above. It may contain confidential information. If you are not the intended recipient you are hereby notified that any dissemination, distribution or copying of this e-mail and any attachment(s) is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender by replying to this e-mail and delete the message and any attachment(s) from your system. Thank you.


From bolker at zoo.ufl.edu  Thu Feb  8 15:46:01 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu, 08 Feb 2007 09:46:01 -0500
Subject: [Rd] strategies for incorporating a data= argument
Message-ID: <45CB37A9.3060200@zoo.ufl.edu>


  As I've mentioned here, before, I'm working on an extended
version of mle(), a function from the stats4 package that's
a wrapper for optim().

  I'd like (against the advice of Peter Dalgaard -- sorry) to
incorporate a "data" argument, similar to the arguments in
lm, nls, nlme, etc., that would allow the log-likelihood function
to be evaluated with different sets of data.  (Peter's advice
was to use closures, writing a function-to-generate-likelihood-functions
such as

fn0 <- function(x) {
   function(mu,sd) { -sum(dnorm(x,mu,sd,log=TRUE) }
}
mle(minuslogl=fn0(x),...)

 My feeling is that this will be somewhat mysterious to
the intermediate R users who are my target audience.)

  I have three thoughts on how to allow different data
sets to be substituted in the same objective function,
and I'm not sure which is best.

 1.  passed in ... as in optim()

  advantages -- simple, not a lot of mucking around
with environments etc..
  disadvantages -- have to separate out arguments that
are not intended for the objective function, either by
messing with the argument string (e.g. matching against
formals(fn)) or by isolating optim args in
an optim.args list

e.g.
  fn <- function(mu,sd,x) {
    -sum(dnorm(x,mu,sd))
  }
  mle(minuslogl=fn,...,x=x)

 2. passed as a separate argument (data=), where
elements of data are taken as additional arguments to
the function (e.g. do.call("fn",c(args,data)))

  e.g.
  fn <- function(mu,sd,x) {
    -sum(dnorm(x,mu,sd))
  }
  mle(minuslogl=fn,...,data=list(x=x))


 3. passed as a separate argument, (data=), function
BODY is evaluated in an environment containing the
elements of data (or attach(data) before evaluating
function; or with(data,...))

  advantages: works well for a formula interface
  is there a better way to add objects from a list
to an environment than

 mapply(function(name,obj) { assign(name,obj,envir=myenv) },
       names(mylist),mylist)

?

  e.g.
  fn <- function(mu,sd) {
    -sum(dnorm(x,mu,sd))
  }
  mle(minuslogl=fn,...,data=list(x=x))

  For anyone who has read this far: right now I am calling my
extended function mle(), but that seems to be asking for trouble
[i.e. confused questions from users who don't know they're using
bbmle::mle and not stats4::mle].  Any recommendations for what to
call it?  mle2? mlex ("extended mle") ?  mlx?

  thanks for any input,
    Ben Bolker

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 254 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070208/4006ad2f/attachment.bin 

From mwkimpel at gmail.com  Thu Feb  8 16:17:16 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Thu, 08 Feb 2007 10:17:16 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <45CB2A97.4080306@cimr.cam.ac.uk>
References: <45CACDD2.9060007@gmail.com> <45CB06A7.5080007@cimr.cam.ac.uk>
	<45CB225E.6020702@med.umich.edu> <45CB2A97.4080306@cimr.cam.ac.uk>
Message-ID: <45CB3EFC.3050607@gmail.com>

Thanks for the useful suggestions. I am not as CS savvy as some of you, 
so maybe Hans-Peter could reply? I haven't checked into it, but does his 
  package write to files that are OpenOffice compliant? Would that 
satisfy more users?

Mark

Hin-Tak Leung wrote:
> James W. MacDonald wrote:
>> Have you looked at RDCOMClient? I would imagine you could do what you 
>> want with this package.
>>
>> http://www.omegahat.org/RDCOMClient/
> 
> Interesting point. But the dcom client would be windows-specific?
> (those I mentioned - the perl mondules, openoffice, run on windows,
> as well as unix boxes - not sure about gnumeric :-).
> 
> In fact there is a very perverse way of doing it - ActiveState provides
> a PerlCom product for hooking up dcom with activestate perl. i.e. you 
> can go via R -> RDComClient -> PerlCom -> ActiveState Perl -> 
> SpreadSheet::* . Just so that it does not require Excel installed
> or an MS Office license...
> 
> In that sense, probably technology based on bridging over odbc
> is also acceptable?
> 
> HTL
> 
>> Hin-Tak Leung wrote:
>>> I don't know of any native xls read/write facility in R, either
>>> in core or as add-ons (I could be wrong), but if you want some source 
>>> code to scavenge on to build some R package out of it, there are two
>>> perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel
>>> which are small enough to "read from front cover to back cover",
>>> so to speak, might be useful for reference and steal code from.
>>>
>>> The other open-source packages which can read/write excel files
>>> are gnumeric and openoffice and probably too big to find one's way 
>>> around the source code to steal there :-).
>>>
>>> Good luck.
>>>
>>> HTL
>>>
>>> Mark W Kimpel wrote:
>>>
>>>> Hans-Peter and other R developers,
>>>>
>>>> How are you? Have you made any progess with embedding Url's in Excel?
>>>>
>>>> Well, I have been busy thinking of more things for you to do;)
>>>>
>>>> My colleagues in the lab are not R literate, and some are barely 
>>>> computer literate, so I give them everything in Excel workbooks. I 
>>>> have gradually evolved a system such that these workbooks have 
>>>> become compendia of my data, output, and methods. That, in fact, is 
>>>> why I bought the Pro version of xlsReadWritePro. I have been saving 
>>>> graphics as PDF files, then inserting them as object in Excel sheets.
>>>>
>>>> What I would like to be able to do is to embed objects (files) in 
>>>> sheets of a workbook directly from within R. I would also like to be 
>>>> able to save my current R workspace as an object embedded in a sheet 
>>>> so that in the future, if packages change, I could go back and 
>>>> recreate the analysis. I do not need to be able to manuipulate files 
>>>> that R has not created, like a PDF file from another user. I would, 
>>>> however, like to be able to save my graphics as PDF files inside a 
>>>> worksheet, even if it meant creating a  temp file or something.
>>>>
>>>> Before people begin talking about how MySQL or some other database 
>>>> could handle all that archiving, let me say that that is not what my 
>>>> colleagues want. They want a nice Excel file that they can take home 
>>>> on there laptops. One thing I like about worksheets is that they 
>>>> themselves can contain many embedded files, so it keeps our virtual 
>>>> desks neater and less confusing.
>>>>
>>>> Hans, if you could do this, it would be of tremendous benefit to me 
>>>> and hopefully a lot of people. R developers tend to think that all 
>>>> scientists are running Linux on 64-bit computers, but most 
>>>> biomedical researches still store date in Excel files. This won't 
>>>> solve everybody's needs, but it could be a start.
>>>>
>>>> Well, let me know what you think. I am cc'ing R-devel to see if any 
>>>> of those guys have ideas as well.
>>>>
>>>> Thanks,
>>>> Mark
>>>>
>>>>
>>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> 

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From ggrothendieck at gmail.com  Thu Feb  8 17:58:54 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 8 Feb 2007 11:58:54 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <45CACDD2.9060007@gmail.com>
References: <45CACDD2.9060007@gmail.com>
Message-ID: <971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>

Its not entirely clear to me what it is that you are looking
for.  Maybe you want to create an Excel spreadsheet with a hyperlink
to a web page?  This R code will do that.  It requires a Windows machine that
has Excel running on it.


library(RDCOMClient)
xl <- COMCreate("Excel.Application")
xl[["Visible"]] <- TRUE
wkbk <- xl$Workbooks()$Add()

sh <- xl$ActiveSheet()

B2R <- sh$Range("B3")
B2R[["Formula"]] <- '=HYPERLINK("http://www.r-project.org")'

wkbk$SaveAs("\\test-url.xls")
xl$Quit()




On 2/8/07, Mark W Kimpel <mwkimpel at gmail.com> wrote:
> Hans-Peter and other R developers,
>
> How are you? Have you made any progess with embedding Url's in Excel?
>
> Well, I have been busy thinking of more things for you to do;)
>
> My colleagues in the lab are not R literate, and some are barely
> computer literate, so I give them everything in Excel workbooks. I have
> gradually evolved a system such that these workbooks have become
> compendia of my data, output, and methods. That, in fact, is why I
> bought the Pro version of xlsReadWritePro. I have been saving graphics
> as PDF files, then inserting them as object in Excel sheets.
>
> What I would like to be able to do is to embed objects (files) in sheets
> of a workbook directly from within R. I would also like to be able to
> save my current R workspace as an object embedded in a sheet so that in
> the future, if packages change, I could go back and recreate the
> analysis. I do not need to be able to manuipulate files that R has not
> created, like a PDF file from another user. I would, however, like to be
> able to save my graphics as PDF files inside a worksheet, even if it
> meant creating a  temp file or something.
>
> Before people begin talking about how MySQL or some other database could
> handle all that archiving, let me say that that is not what my
> colleagues want. They want a nice Excel file that they can take home on
> there laptops. One thing I like about worksheets is that they themselves
> can contain many embedded files, so it keeps our virtual desks neater
> and less confusing.
>
> Hans, if you could do this, it would be of tremendous benefit to me and
> hopefully a lot of people. R developers tend to think that all
> scientists are running Linux on 64-bit computers, but most biomedical
> researches still store date in Excel files. This won't solve everybody's
> needs, but it could be a start.
>
> Well, let me know what you think. I am cc'ing R-devel to see if any of
> those guys have ideas as well.
>
> Thanks,
> Mark
>
>
>
> --
> Mark W. Kimpel MD
> Neuroinformatics
> Department of Psychiatry
> Indiana University School of Medicine
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Thu Feb  8 18:38:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 8 Feb 2007 12:38:26 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>
Message-ID: <971536df0702080938x41ada445h7af43d82e7972bdb@mail.gmail.com>

I meant that the machine has Excel on it.  Excel does not have to be running
prior to running the R code as the R code will start up and shut
down Excel itself.

On 2/8/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Its not entirely clear to me what it is that you are looking
> for.  Maybe you want to create an Excel spreadsheet with a hyperlink
> to a web page?  This R code will do that.  It requires a Windows machine that
> has Excel running on it.
>
>
> library(RDCOMClient)
> xl <- COMCreate("Excel.Application")
> xl[["Visible"]] <- TRUE
> wkbk <- xl$Workbooks()$Add()
>
> sh <- xl$ActiveSheet()
>
> B2R <- sh$Range("B3")
> B2R[["Formula"]] <- '=HYPERLINK("http://www.r-project.org")'
>
> wkbk$SaveAs("\\test-url.xls")
> xl$Quit()
>
>
>
>
> On 2/8/07, Mark W Kimpel <mwkimpel at gmail.com> wrote:
> > Hans-Peter and other R developers,
> >
> > How are you? Have you made any progess with embedding Url's in Excel?
> >
> > Well, I have been busy thinking of more things for you to do;)
> >
> > My colleagues in the lab are not R literate, and some are barely
> > computer literate, so I give them everything in Excel workbooks. I have
> > gradually evolved a system such that these workbooks have become
> > compendia of my data, output, and methods. That, in fact, is why I
> > bought the Pro version of xlsReadWritePro. I have been saving graphics
> > as PDF files, then inserting them as object in Excel sheets.
> >
> > What I would like to be able to do is to embed objects (files) in sheets
> > of a workbook directly from within R. I would also like to be able to
> > save my current R workspace as an object embedded in a sheet so that in
> > the future, if packages change, I could go back and recreate the
> > analysis. I do not need to be able to manuipulate files that R has not
> > created, like a PDF file from another user. I would, however, like to be
> > able to save my graphics as PDF files inside a worksheet, even if it
> > meant creating a  temp file or something.
> >
> > Before people begin talking about how MySQL or some other database could
> > handle all that archiving, let me say that that is not what my
> > colleagues want. They want a nice Excel file that they can take home on
> > there laptops. One thing I like about worksheets is that they themselves
> > can contain many embedded files, so it keeps our virtual desks neater
> > and less confusing.
> >
> > Hans, if you could do this, it would be of tremendous benefit to me and
> > hopefully a lot of people. R developers tend to think that all
> > scientists are running Linux on 64-bit computers, but most biomedical
> > researches still store date in Excel files. This won't solve everybody's
> > needs, but it could be a start.
> >
> > Well, let me know what you think. I am cc'ing R-devel to see if any of
> > those guys have ideas as well.
> >
> > Thanks,
> > Mark
> >
> >
> >
> > --
> > Mark W. Kimpel MD
> > Neuroinformatics
> > Department of Psychiatry
> > Indiana University School of Medicine
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From jhallman at frb.gov  Thu Feb  8 18:41:48 2007
From: jhallman at frb.gov (Jeffrey J. Hallman)
Date: 08 Feb 2007 12:41:48 -0500
Subject: [Rd] RPM support for package installation?
References: <Pine.LNX.4.64.0702061144390.754@hydra8.stat.cmu.edu>
Message-ID: <xmr4ppwh7hf.fsf@mralx1.rsma.frb.gov>

I feel your pain.  At my workplace, the network administrators insist that
anything that is to be distributed across the network be packaged up in an
RPM.  I have my own library of packages accessible to my section members, but
when I want to make something available to everyone, I have to create an RPM.

After many trials and tribulations, here is the rpm spec file I created for
Prof. Ripley's RODBC package. A few things to note:

1. R-2.4.0 was installed in /opt/r-2.4.0 by an RPM called R-arc
2. I create /opt/r-2.4.0/lib/R/src and unpack the source package there, so
   my users can look at the original code if they want to.
3. The rpm does R CMD INSTALL pkg  twice: once when it is installing the rpm,
   and again in the post-install step. The reason for the second pass is to
   insure that the help index files get rebuilt with all of the packages that
   are installed in the production directory.

My other rpms are similar to this one.  With that, here is the spec file:

-- 
Jeff



%define rversion 2.4.0
%define rtopdir /opt/r-%{rversion}
%define rhome %{rtopdir}/lib/R
%define rbin %{rhome}/bin/R
%define rSourcePackageDir %{rhome}/src
%define rBinaryPackageDir %{rhome}/library
%define arcrel 9

Name: R-rodbc-arc
Version: %{rversion}
Release: 1.1.REV.%{arcrel}
Summary: Package ODBC Interface for R
License: free
Requires: R-arc >= %{rversion}
Provides: R-rodbc
Group: Applications/Engineering
Source0: %{name}-%{version}.tar.gz
Buildroot: /tmp/%{name}-%{version}
%description
CRAN version 1.1-7 of RODBC, an ODBC interface for R.
%prep
%build
%install
[ "%{buildroot}" != "/" ] && rm -rf %{buildroot}
mkdir -p %{buildroot}%{rBinaryPackageDir}
mkdir -p %{buildroot}%{rSourcePackageDir}
mkdir -p %{buildroot}%{rhome}/doc/html/search
cd %{buildroot}%{rSourcePackageDir}
tar -xzf $RPM_SOURCE_DIR/%{name}-%{version}.tar.gz 
%{rbin} CMD INSTALL -c -l %{buildroot}%{rBinaryPackageDir} RODBC

%files
%defattr(-, mathadm, appgrp)
%{rSourcePackageDir}/*
%{rBinaryPackageDir}/*

%clean
rm -rf %{buildroot}

%post
cd %{rSourcePackageDir}
pwd
%{rbin} CMD INSTALL -c RODBC
chown -R mathadm:appgrp %{rBinaryPackageDir}/RODBC
chown mathadm:appgrp %{rhome}/doc/html/packages.html
chown mathadm:appgrp %{rhome}/doc/html/search/index.txt

%preun


From khansen at stat.Berkeley.EDU  Thu Feb  8 18:59:22 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Thu, 8 Feb 2007 09:59:22 -0800
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <45CB06A7.5080007@cimr.cam.ac.uk>
References: <45CACDD2.9060007@gmail.com> <45CB06A7.5080007@cimr.cam.ac.uk>
Message-ID: <42818DA1-D6A9-42B1-8653-378F595286CF@stat.berkeley.edu>

The gdata etc. packages (I cannot remember which of the g* packages  
it is) contains a read.xls function which reads an excel file based  
on a PERL script. I have used it for small stuff and for that it  
worked fine. I don't think they contain a write module though.

Kasper


On Feb 8, 2007, at 3:16 AM, Hin-Tak Leung wrote:

> I don't know of any native xls read/write facility in R, either
> in core or as add-ons (I could be wrong), but if you want some source
> code to scavenge on to build some R package out of it, there are two
> perl modules, Spreadsheet::ParseExcel and Spreadsheet::WriteExcel
> which are small enough to "read from front cover to back cover",
> so to speak, might be useful for reference and steal code from.
>
> The other open-source packages which can read/write excel files
> are gnumeric and openoffice and probably too big to find one's way
> around the source code to steal there :-).
>
> Good luck.
>
> HTL
>
> Mark W Kimpel wrote:
>> Hans-Peter and other R developers,
>>
>> How are you? Have you made any progess with embedding Url's in Excel?
>>
>> Well, I have been busy thinking of more things for you to do;)
>>
>> My colleagues in the lab are not R literate, and some are barely
>> computer literate, so I give them everything in Excel workbooks. I  
>> have
>> gradually evolved a system such that these workbooks have become
>> compendia of my data, output, and methods. That, in fact, is why I
>> bought the Pro version of xlsReadWritePro. I have been saving  
>> graphics
>> as PDF files, then inserting them as object in Excel sheets.
>>
>> What I would like to be able to do is to embed objects (files) in  
>> sheets
>> of a workbook directly from within R. I would also like to be able to
>> save my current R workspace as an object embedded in a sheet so  
>> that in
>> the future, if packages change, I could go back and recreate the
>> analysis. I do not need to be able to manuipulate files that R has  
>> not
>> created, like a PDF file from another user. I would, however, like  
>> to be
>> able to save my graphics as PDF files inside a worksheet, even if it
>> meant creating a  temp file or something.
>>
>> Before people begin talking about how MySQL or some other database  
>> could
>> handle all that archiving, let me say that that is not what my
>> colleagues want. They want a nice Excel file that they can take  
>> home on
>> there laptops. One thing I like about worksheets is that they  
>> themselves
>> can contain many embedded files, so it keeps our virtual desks neater
>> and less confusing.
>>
>> Hans, if you could do this, it would be of tremendous benefit to  
>> me and
>> hopefully a lot of people. R developers tend to think that all
>> scientists are running Linux on 64-bit computers, but most biomedical
>> researches still store date in Excel files. This won't solve  
>> everybody's
>> needs, but it could be a start.
>>
>> Well, let me know what you think. I am cc'ing R-devel to see if  
>> any of
>> those guys have ideas as well.
>>
>> Thanks,
>> Mark
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tshort at eprisolutions.com  Thu Feb  8 20:09:15 2007
From: tshort at eprisolutions.com (tshort)
Date: Thu, 8 Feb 2007 11:09:15 -0800 (PST)
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <45CACDD2.9060007@gmail.com>
References: <45CACDD2.9060007@gmail.com>
Message-ID: <8871790.post@talk.nabble.com>


Another option for creating XLS files it to write out HTML instead. Excel can
read html files just fine, and a useful trick is giving the html file a .xls
extension. So, from the user's point of view, it is an excel file even
though it's just an html file. 

Using html works great for embedding links and formatted tables. You can use
the R2HTML package to generate HTML files, including formatting for a large
number of R objects.

One thing you can't do with this approach is include graphics. In theory you
could do that by extending this approach. Excel can read in *.mhtml files,
which are multipart mime-encoded bundles that include the html file plus
mime-encoded graphics files that go with it. You could generate png files in
R to include. Excel will also happily read in mhtml files with a .xls
extension. The following links could help you get started:

http://en.wikipedia.org/wiki/MHTML
http://finzi.psych.upenn.edu/R/library/caTools/html/base64.html

I don't know of an R package that has a function to encode files as a
multipart mime, but the link above is a good start.

- Tom

Tom Short
EPRI


Mark W Kimpel wrote:
> 
> Hans-Peter and other R developers,
> 
> How are you? Have you made any progess with embedding Url's in Excel?
> 
> Well, I have been busy thinking of more things for you to do;)
> 
> My colleagues in the lab are not R literate, and some are barely 
> computer literate, so I give them everything in Excel workbooks. I have 
> gradually evolved a system such that these workbooks have become 
> compendia of my data, output, and methods. That, in fact, is why I 
> bought the Pro version of xlsReadWritePro. I have been saving graphics 
> as PDF files, then inserting them as object in Excel sheets.
> 
> What I would like to be able to do is to embed objects (files) in sheets 
> of a workbook directly from within R. I would also like to be able to 
> save my current R workspace as an object embedded in a sheet so that in 
> the future, if packages change, I could go back and recreate the 
> analysis. I do not need to be able to manuipulate files that R has not 
> created, like a PDF file from another user. I would, however, like to be 
> able to save my graphics as PDF files inside a worksheet, even if it 
> meant creating a  temp file or something.
> 
> Before people begin talking about how MySQL or some other database could 
> handle all that archiving, let me say that that is not what my 
> colleagues want. They want a nice Excel file that they can take home on 
> there laptops. One thing I like about worksheets is that they themselves 
> can contain many embedded files, so it keeps our virtual desks neater 
> and less confusing.
> 
> Hans, if you could do this, it would be of tremendous benefit to me and 
> hopefully a lot of people. R developers tend to think that all 
> scientists are running Linux on 64-bit computers, but most biomedical 
> researches still store date in Excel files. This won't solve everybody's 
> needs, but it could be a start.
> 
> Well, let me know what you think. I am cc'ing R-devel to see if any of 
> those guys have ideas as well.
> 
> Thanks,
> Mark
> 
> 
> 
> -- 
> Mark W. Kimpel MD
> Neuroinformatics
> Department of Psychiatry
> Indiana University School of Medicine
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/xlsReadWrite-Pro-and-embedding-objects-and-files-in-Excel-worksheets-tf3191737.html#a8871790
Sent from the R devel mailing list archive at Nabble.com.


From bill at insightful.com  Thu Feb  8 20:48:39 2007
From: bill at insightful.com (bill at insightful.com)
Date: Thu,  8 Feb 2007 20:48:39 +0100 (CET)
Subject: [Rd] supsmu(periodic=TRUE) can crash R by reading before start of
	array (PR#9502)
Message-ID: <20070208194839.2D35D5A87C@slim.kubism.ku.dk>

supsmu(periodic=TRUE) can crash R by reading before start of array.

To reproduce:
   set.seed(1)
   xx <- runif(29000)
   yy <- rnorm(29000)
   span <- 0.49
   i <- 1
   while(i < 200){
      cat(i,"\n")
      int <- supsmu(xx,yy,periodic=T,span=span)
      i <-i+1
   }

results in:
   1
   2
   3
   4
   5
   6
   7
   8
   9

   Program received signal SIGSEGV, Segmentation fault.
   smooth_ (n=0xffffeffe, x=0xb6a7f020, y=0xb6993020, w=0xb6921020,
       span=0xffffeffe, iper=0xffffeffe, vsmlsq=0xffffeffe, smo=0xb68e8020,
       acvr=0x9c7e7c8) at ppr.f:1087
   1087             xti=x(j)
   Current language:  auto; currently fortran
   (gdb) list
   1082          if (ibw.lt.2) ibw=2
   1083          it=2*ibw+1
   1084          do 20 i=1,it
   1085             j=i
   1086             if (jper.eq.2) j=i-ibw-1
-> 1087             xti=x(j)
   1088             if (j.ge.1) go to 10
   1089             j=n+j
   1090             xti=x(j)-1d0
   1091     10      wt=w(j)
   (gdb) print jper
   $1 = 2
   (gdb) print j
   $2 = -4099

If you use 'R -d valgrind' it stops in the same spot
on the first call to supsmu:
   1
   ==8058== Invalid read of size 8
   ==8058==    at 0x56A65DA: smooth_ (ppr.f:1087)
   ==8058==    by 0x56A64D5: supsmu_ (ppr.f:1028)
   ==8058==    by 0x80B2488: do_dotCode (dotcode.c:1753)
   ==8058==    by 0x80C9405: Rf_eval (eval.c:441)
   ...
   ==8058==  Address 0x5EFDA80 is 0 bytes after a block of size 232,024 alloc'd
   ==8058==    at 0x401A6EE: malloc (vg_replace_malloc.c:149)
   ==8058==    by 0x80EFBC9: Rf_allocVector (memory.c:1952)
   ==8058==    by 0x807B6CB: do_makevector (builtin.c:558)
   ==8058==    by 0x80F9946: do_internal (names.c:1091)
   ==8058==    by 0x80C9478: Rf_eval (eval.c:424)

Note that it computes x(j) and then, if j is out of
bounds, resets j to be at the end of the x array
and recomputes x(j).  It should not compute x(j) if
j is out of bounds.

A fix that keeps this looking like Fortran IV is
to put 'if (j.ge.1)' at the start of line 1087
(in R_HOME/src/library/stats/src/ppr.f).  This stops
the crash and makes valgrind happy.

(Splus has the identical problem and fix.)

*** ppr.f~	2007-02-08 11:31:50.000000000 -0800
--- ppr.f	2007-02-08 11:32:07.000000000 -0800
***************
*** 1084,1090 ****
        do 20 i=1,it
           j=i
           if (jper.eq.2) j=i-ibw-1
!          xti=x(j)
           if (j.ge.1) go to 10
           j=n+j
           xti=x(j)-1d0
--- 1084,1090 ----
        do 20 i=1,it
           j=i
           if (jper.eq.2) j=i-ibw-1
!          if (j.ge.1) xti=x(j)
           if (j.ge.1) go to 10
           j=n+j
           xti=x(j)-1d0

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = Under development (unstable)
 major = 2
 minor = 5.0
 year = 2007
 month = 02
 day = 05
 svn rev = 40659
 language = R
 version.string = R version 2.5.0 Under development (unstable) (2007-02-05 r40659)

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From vdergachev at rcgardis.com  Thu Feb  8 20:54:21 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Thu, 8 Feb 2007 14:54:21 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <8871790.post@talk.nabble.com>
References: <45CACDD2.9060007@gmail.com> <8871790.post@talk.nabble.com>
Message-ID: <200702081454.21831.vdergachev@rcgardis.com>

On Thursday 08 February 2007 2:09 pm, tshort wrote:

> I don't know of an R package that has a function to encode files as a
> multipart mime, but the link above is a good start.

Tclib has mime encoding module one could use it from within R with 
.Tcl("package require tcllib")

                    best

                        Vladimir Dergachev

>
> - Tom


From ross at biostat.ucsf.edu  Thu Feb  8 21:32:45 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 8 Feb 2007 12:32:45 -0800
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45C65479.30906@aon.at>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
Message-ID: <20070208203245.GA6397@wheat.betterworld.us>

On Sun, Feb 04, 2007 at 10:47:37PM +0100, cstrato wrote:
> Seth Falcon wrote:
> > cstrato <cstrato at aon.at> writes:
> >   
> >> Thank you for your fast answer.
> >> Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
> >> old-style print commands.
> >>     
> >
> > You should be able to use gdb on OS X (works for me, YMMV).  So you
> > could try:
> >
> >       R -d gdb
> >       run
> >       # source a script that causes crash
> >       # back in gdb, use backtrace, etc.
> >
> > + seth
> >
> >
> >   
> Dear Seth
> 
> Thank you for this tip, I just tried it and here is the result:
> 
> Welcome to MyClass
>  > writeFileCpp("myout_fileCpp.txt")
> [1] "outfile =  myout_fileCpp.txt"
> Writing file myout_fileCpp.txt using C++ style.
> ---MyClassA::MyClassA()---------
> ---MyClassA::WriteFileCpp---------
> 
> Program received signal EXC_BAD_ACCESS, Could not access memory.
> Reason: KERN_PROTECTION_FAILURE at address: 0x00000006
> 0x020fe231 in std::ostream::flush (this=0x214f178) at 
> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc:395
> 395     
> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc: 
> No such file or directory.
>         in 
> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc
> (gdb)
> 
> It seems that it cannot find ostream.tcc, whatever this extension means.
> 
> Best regards
> Christian

I also don't see what the problem is, but have a couple of thoughts.
Under OS-X there is an environment variable you can define to get the
dynamic linker to load debug versions of libraries.  I can't remember
what it is, but maybe something like DYLD_DEBUG (but probably DEBUG is
part of the value of the variable).

For that, or the tracing above, to be fully informative you need to
have installed the appropriate debugging libraries and sources.

You may need to set an explicit source search path in gdb to pick up
the source files.

Try stepping through the code from write before the crash to determine
exactly where it runs into trouble.

Does the output file you are trying to create exist?

Unfortunately, none of this really gets at your core bug, but it might
help track it down.

Ross


From ross at biostat.ucsf.edu  Thu Feb  8 22:02:36 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 8 Feb 2007 13:02:36 -0800
Subject: [Rd] One possible use for threads in R
Message-ID: <20070208210236.GB6397@wheat.betterworld.us>

I have been using R on a cluster with some work that does not
parallelize neatly because the time individual computations take
varies widely and unpredictably.

So I've considered implementing a work-stealing arrangement, in which
idle nodes grab tasks from busy nodes.  It might also be useful for
nodes to communicate results with each other.

My first thought on handling this was to have one R thread that
managed the communication, and 2 that managed computation (each node
is dual-processor).

Previous discussion has noted that R is not multi-threaded, and also
asked what use cases multi-threading might address.  So here's a use
case.

The advantage of having R doing the communication is that it's easy to
pass R-level objects around using, e.g., Rmpi.  The advantage of
having the communicator and the calculators share the same thread is
that work and information the communicator got would be immediately
available to the calculators.

Other comments suggested IPC is fast (though one comment referred
specifically to Linux, and the cluster is OS-X), so it may be quite
workable to have each thread in a separate process.

I'm not at all sure the implementation I sketched above is the best
approach to this problem (or even that it would be if R were
multi-threaded), but it does seem to me this might be one area where
threads would be handy in R.

Ross Boylan


From cstrato at aon.at  Thu Feb  8 22:04:14 2007
From: cstrato at aon.at (cstrato)
Date: Thu, 08 Feb 2007 22:04:14 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <20070208203245.GA6397@wheat.betterworld.us>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
	<20070208203245.GA6397@wheat.betterworld.us>
Message-ID: <45CB904E.1020300@aon.at>

Ross Boylan wrote:
> On Sun, Feb 04, 2007 at 10:47:37PM +0100, cstrato wrote:
>   
>> Seth Falcon wrote:
>>     
>>> cstrato <cstrato at aon.at> writes:
>>>   
>>>       
>>>> Thank you for your fast answer.
>>>> Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
>>>> old-style print commands.
>>>>     
>>>>         
>>> You should be able to use gdb on OS X (works for me, YMMV).  So you
>>> could try:
>>>
>>>       R -d gdb
>>>       run
>>>       # source a script that causes crash
>>>       # back in gdb, use backtrace, etc.
>>>
>>> + seth
>>>
>>>
>>>   
>>>       
>> Dear Seth
>>
>> Thank you for this tip, I just tried it and here is the result:
>>
>> Welcome to MyClass
>>  > writeFileCpp("myout_fileCpp.txt")
>> [1] "outfile =  myout_fileCpp.txt"
>> Writing file myout_fileCpp.txt using C++ style.
>> ---MyClassA::MyClassA()---------
>> ---MyClassA::WriteFileCpp---------
>>
>> Program received signal EXC_BAD_ACCESS, Could not access memory.
>> Reason: KERN_PROTECTION_FAILURE at address: 0x00000006
>> 0x020fe231 in std::ostream::flush (this=0x214f178) at 
>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc:395
>> 395     
>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc: 
>> No such file or directory.
>>         in 
>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc
>> (gdb)
>>
>> It seems that it cannot find ostream.tcc, whatever this extension means.
>>
>> Best regards
>> Christian
>>     
>
> I also don't see what the problem is, but have a couple of thoughts.
> Under OS-X there is an environment variable you can define to get the
> dynamic linker to load debug versions of libraries.  I can't remember
> what it is, but maybe something like DYLD_DEBUG (but probably DEBUG is
> part of the value of the variable).
>
> For that, or the tracing above, to be fully informative you need to
> have installed the appropriate debugging libraries and sources.
>
> You may need to set an explicit source search path in gdb to pick up
> the source files.
>
> Try stepping through the code from write before the crash to determine
> exactly where it runs into trouble.
>
> Does the output file you are trying to create exist?
>
> Unfortunately, none of this really gets at your core bug, but it might
> help track it down.
>
> Ross
>
>
>   
Dear Ross

Thank you, my problem is that I know exactly where the problem is but 
not how to solve it.

I have installed R-2.4.1 on three different machines to test the package:
- Intel-Laptop running Fedora Core 4:         package is OK
- PPC-PowerBook Titanium OS X 10.4.4:         package is OK
- Intel-MacBook Pro Core 2 Duo OS X 10.4.8:   C output OK, C++ output 
crashes R

The following code in method WriteFileCpp() works, but gives no result:
{
  std::ofstream output(outfile);
  output.close();
}

The following code in method WriteFileCpp() crashes R:
{
  std::ofstream output(outfile);
  output << "21" << endl;
  output.close();
}

It seems that on the Intel-MacBook Pro the operator "<<" is not 
recognized, when called
from within my package in R.
In contrast, when compiled as a C++ library, the same code does work on 
my Intel-Mac!

Best regards
Christian


From ross at biostat.ucsf.edu  Thu Feb  8 23:14:50 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 8 Feb 2007 14:14:50 -0800
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45CB904E.1020300@aon.at>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
	<20070208203245.GA6397@wheat.betterworld.us>
	<45CB904E.1020300@aon.at>
Message-ID: <20070208221450.GI5871@wheat.betterworld.us>

On Thu, Feb 08, 2007 at 10:04:14PM +0100, cstrato wrote:
> Ross Boylan wrote:
> >On Sun, Feb 04, 2007 at 10:47:37PM +0100, cstrato wrote:
> >  
> >>Seth Falcon wrote:
> >>    
> >>>cstrato <cstrato at aon.at> writes:
> >>>  
> >>>      
> >>>>Thank you for your fast answer.
> >>>>Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
> >>>>old-style print commands.
> >>>>    
> >>>>        
> >>>You should be able to use gdb on OS X (works for me, YMMV).  So you
> >>>could try:
> >>>
> >>>      R -d gdb
> >>>      run
> >>>      # source a script that causes crash
> >>>      # back in gdb, use backtrace, etc.
> >>>
> >>>+ seth
> >>>
> >>>
> >>>  
> >>>      
> >>Dear Seth
> >>
> >>Thank you for this tip, I just tried it and here is the result:
> >>
> >>Welcome to MyClass
> >> > writeFileCpp("myout_fileCpp.txt")
> >>[1] "outfile =  myout_fileCpp.txt"
> >>Writing file myout_fileCpp.txt using C++ style.
> >>---MyClassA::MyClassA()---------
> >>---MyClassA::WriteFileCpp---------
> >>
> >>Program received signal EXC_BAD_ACCESS, Could not access memory.
> >>Reason: KERN_PROTECTION_FAILURE at address: 0x00000006
> >>0x020fe231 in std::ostream::flush (this=0x214f178) at 
> >>/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc:395
> >>395     
> >>/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc: 
> >>No such file or directory.
> >>        in 
> >>/Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc
> >>(gdb)
> >>
> >>It seems that it cannot find ostream.tcc, whatever this extension means.
> >>
> >>Best regards
> >>Christian
> >>    
> >
> >I also don't see what the problem is, but have a couple of thoughts.
> >Under OS-X there is an environment variable you can define to get the
> >dynamic linker to load debug versions of libraries.  I can't remember
> >what it is, but maybe something like DYLD_DEBUG (but probably DEBUG is
> >part of the value of the variable).
> >
> >For that, or the tracing above, to be fully informative you need to
> >have installed the appropriate debugging libraries and sources.
> >
> >You may need to set an explicit source search path in gdb to pick up
> >the source files.
> >
> >Try stepping through the code from write before the crash to determine
> >exactly where it runs into trouble.
> >
> >Does the output file you are trying to create exist?
> >
> >Unfortunately, none of this really gets at your core bug, but it might
> >help track it down.
> >
> >Ross
> >
> >
> >  
> Dear Ross
> 
> Thank you, my problem is that I know exactly where the problem is but 
> not how to solve it.
> 
> I have installed R-2.4.1 on three different machines to test the package:
> - Intel-Laptop running Fedora Core 4:         package is OK
> - PPC-PowerBook Titanium OS X 10.4.4:         package is OK
> - Intel-MacBook Pro Core 2 Duo OS X 10.4.8:   C output OK, C++ output 
> crashes R
> 
> The following code in method WriteFileCpp() works, but gives no result:
> {
>  std::ofstream output(outfile);
>  output.close();
> }
> 
> The following code in method WriteFileCpp() crashes R:
> {
>  std::ofstream output(outfile);
>  output << "21" << endl;
>  output.close();
> }
> 
> It seems that on the Intel-MacBook Pro the operator "<<" is not 
> recognized, when called from within my package in R.
> In contrast, when compiled as a C++ library, the same code does work on 
> my Intel-Mac!
> 
> Best regards
> Christian
> 
> 
Knowing the line isn't as specific as knowing exactly where it was
when it crashed.

Your stack trace was
Thread 0 Crashed:
0   libstdc++.6.dylib     0x020fe231 std::basic_ostream<char,
std::char_traits<char> >::flush() + 17 (ostream.tcc:395)
1   libstdc++.6.dylib     0x020fe358 std::basic_ostream<char,
std::char_traits<char>
 >::sentry::sentry[in-charge](std::basic_ostream<char,
std::char_traits<char> >&) + 120 (ostream.tcc:56)
2   libstdc++.6.dylib     0x02100b5d std::basic_ostream<char,
std::char_traits<char> >& std::operator<< <std::char_traits<char>
 >(std::basic_ostream<char, std::char_traits<char> >&, char const*) + 29
(ostream.tcc:620)
3   MyClass.so            0x0004a30f MyClassA::WriteFileCpp(char const*)
which doesn't look as if the problem is that << isn't recognized.
What is the thing that was at address 0x06?

The flush is probably from the endl.  If you traced it through, you
could tell if the first << completed.

Does
 output << endl;
work?
or
 output << "21";
or
 output << 21 << endl;
or
 #include <string>
 string s("21");
 output << s;
?

The different fates of the two OS-X platforms is certainly vexing.
These are all shots in the dark, but
1) Was the complete system (i.e., R as well as your code) built with
the the toolchain on both platforms?
2) Are your environments (e.g., environment variables) the same?
3) The recommended way to build stuff that will be talking to R is
with R CMD config.  Check first if that gives the same results on both
systems, and second if your build is using them.
4) Maybe some dylib (e.g., stdc++) is not getting initialized
properly.

Maybe there's some subtle linker problem, or a problem with the
representation of strings


From cstrato at aon.at  Thu Feb  8 23:53:21 2007
From: cstrato at aon.at (cstrato)
Date: Thu, 08 Feb 2007 23:53:21 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <20070208221450.GI5871@wheat.betterworld.us>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
	<20070208203245.GA6397@wheat.betterworld.us>
	<45CB904E.1020300@aon.at>
	<20070208221450.GI5871@wheat.betterworld.us>
Message-ID: <45CBA9E1.6060400@aon.at>

Ross Boylan wrote:
> On Thu, Feb 08, 2007 at 10:04:14PM +0100, cstrato wrote:
>   
>> Ross Boylan wrote:
>>     
>>> On Sun, Feb 04, 2007 at 10:47:37PM +0100, cstrato wrote:
>>>  
>>>       
>>>> Seth Falcon wrote:
>>>>    
>>>>         
>>>>> cstrato <cstrato at aon.at> writes:
>>>>>  
>>>>>      
>>>>>           
>>>>>> Thank you for your fast answer.
>>>>>> Sorrowly, I don?t know how to use a debugger on MacOS X, I am using 
>>>>>> old-style print commands.
>>>>>>    
>>>>>>        
>>>>>>             
>>>>> You should be able to use gdb on OS X (works for me, YMMV).  So you
>>>>> could try:
>>>>>
>>>>>      R -d gdb
>>>>>      run
>>>>>      # source a script that causes crash
>>>>>      # back in gdb, use backtrace, etc.
>>>>>
>>>>> + seth
>>>>>
>>>>>
>>>>>  
>>>>>      
>>>>>           
>>>> Dear Seth
>>>>
>>>> Thank you for this tip, I just tried it and here is the result:
>>>>
>>>> Welcome to MyClass
>>>>         
>>>>> writeFileCpp("myout_fileCpp.txt")
>>>>>           
>>>> [1] "outfile =  myout_fileCpp.txt"
>>>> Writing file myout_fileCpp.txt using C++ style.
>>>> ---MyClassA::MyClassA()---------
>>>> ---MyClassA::WriteFileCpp---------
>>>>
>>>> Program received signal EXC_BAD_ACCESS, Could not access memory.
>>>> Reason: KERN_PROTECTION_FAILURE at address: 0x00000006
>>>> 0x020fe231 in std::ostream::flush (this=0x214f178) at 
>>>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc:395
>>>> 395     
>>>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc: 
>>>> No such file or directory.
>>>>        in 
>>>> /Builds/unix/o403/i686-apple-darwin8/libstdc++-v3/include/bits/ostream.tcc
>>>> (gdb)
>>>>
>>>> It seems that it cannot find ostream.tcc, whatever this extension means.
>>>>
>>>> Best regards
>>>> Christian
>>>>    
>>>>         
>>> I also don't see what the problem is, but have a couple of thoughts.
>>> Under OS-X there is an environment variable you can define to get the
>>> dynamic linker to load debug versions of libraries.  I can't remember
>>> what it is, but maybe something like DYLD_DEBUG (but probably DEBUG is
>>> part of the value of the variable).
>>>
>>> For that, or the tracing above, to be fully informative you need to
>>> have installed the appropriate debugging libraries and sources.
>>>
>>> You may need to set an explicit source search path in gdb to pick up
>>> the source files.
>>>
>>> Try stepping through the code from write before the crash to determine
>>> exactly where it runs into trouble.
>>>
>>> Does the output file you are trying to create exist?
>>>
>>> Unfortunately, none of this really gets at your core bug, but it might
>>> help track it down.
>>>
>>> Ross
>>>
>>>
>>>  
>>>       
>> Dear Ross
>>
>> Thank you, my problem is that I know exactly where the problem is but 
>> not how to solve it.
>>
>> I have installed R-2.4.1 on three different machines to test the package:
>> - Intel-Laptop running Fedora Core 4:         package is OK
>> - PPC-PowerBook Titanium OS X 10.4.4:         package is OK
>> - Intel-MacBook Pro Core 2 Duo OS X 10.4.8:   C output OK, C++ output 
>> crashes R
>>
>> The following code in method WriteFileCpp() works, but gives no result:
>> {
>>  std::ofstream output(outfile);
>>  output.close();
>> }
>>
>> The following code in method WriteFileCpp() crashes R:
>> {
>>  std::ofstream output(outfile);
>>  output << "21" << endl;
>>  output.close();
>> }
>>
>> It seems that on the Intel-MacBook Pro the operator "<<" is not 
>> recognized, when called from within my package in R.
>> In contrast, when compiled as a C++ library, the same code does work on 
>> my Intel-Mac!
>>
>> Best regards
>> Christian
>>
>>
>>     
> Knowing the line isn't as specific as knowing exactly where it was
> when it crashed.
>
> Your stack trace was
> Thread 0 Crashed:
> 0   libstdc++.6.dylib     0x020fe231 std::basic_ostream<char,
> std::char_traits<char> >::flush() + 17 (ostream.tcc:395)
> 1   libstdc++.6.dylib     0x020fe358 std::basic_ostream<char,
> std::char_traits<char>
>  >::sentry::sentry[in-charge](std::basic_ostream<char,
> std::char_traits<char> >&) + 120 (ostream.tcc:56)
> 2   libstdc++.6.dylib     0x02100b5d std::basic_ostream<char,
> std::char_traits<char> >& std::operator<< <std::char_traits<char>
>  >(std::basic_ostream<char, std::char_traits<char> >&, char const*) + 29
> (ostream.tcc:620)
> 3   MyClass.so            0x0004a30f MyClassA::WriteFileCpp(char const*)
> which doesn't look as if the problem is that << isn't recognized.
> What is the thing that was at address 0x06?
>
> The flush is probably from the endl.  If you traced it through, you
> could tell if the first << completed.
>
> Does
>  output << endl;
> work?
>   
Does not work!
> or
>  output << "21";
>   
Does not work!
> or
>  output << 21 << endl;
>   
Does not work!
> or
>  #include <string>
>  string s("21");
>  output << s;
> ?
>   
Does work!  Even
"output << s << endl;"
works, but the outfile is empty!
> The different fates of the two OS-X platforms is certainly vexing.
> These are all shots in the dark, but
> 1) Was the complete system (i.e., R as well as your code) built with
> the the toolchain on both platforms?
>   
Yes
> 2) Are your environments (e.g., environment variables) the same?
>   
Yes
> 3) The recommended way to build stuff that will be talking to R is
> with R CMD config.  Check first if that gives the same results on both
> systems, and second if your build is using them.
>   
Not tested yet
> 4) Maybe some dylib (e.g., stdc++) is not getting initialized
> properly.
>
> Maybe there's some subtle linker problem, or a problem with the
> representation of strings
>
>
>   
What do you mean with linker problem?


From peter-m.schumacher at db.com  Thu Feb  8 19:08:25 2007
From: peter-m.schumacher at db.com (peter-m.schumacher at db.com)
Date: Thu,  8 Feb 2007 19:08:25 +0100 (CET)
Subject: [Rd] obscure error with subsetting as.list() of a function then
	assigning that a (PR#9500)
Message-ID: <20070208180825.7B3D75A842@slim.kubism.ku.dk>



Hello. I was writing some code that computes on the language and came across
this. I can work around it, but thought you might like to know about it.

> f <- function(x) { NULL }
> a <- as.list(f)[[1]]
> a # ie print(a)
Error: argument "a" is missing, with no default

Note it says *argument* "a", which is strange. In fact, and unsurprisingly, the bug lies
with the object itself, not with print():

> typeof(a)
Error in typeof(a) : argument "a" is missing, with no default
> deparse(a)
Error in deparse(a) : argument "a" is missing, with no default

However, this does work:
> as.list(f)[[1]]

It prints nothing, which is correct, and there is no error. So it seems the bug lies with
assigning a name to as.list(f)[[1]] as above, then trying to work with that new object.

Regards,
Peter-M.Schumacher at db.com


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 4.1
 year = 2006
 month = 12
 day = 18
 svn rev = 40228
 language = R
 version.string = R version 2.4.1 (2006-12-18)

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

Search Path:
 .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
---

This e-mail may contain confidential and/or privileged infor...{{dropped}}


From wd213355 at albany.edu  Thu Feb  8 18:09:33 2007
From: wd213355 at albany.edu (wd213355 at albany.edu)
Date: Thu,  8 Feb 2007 18:09:33 +0100 (CET)
Subject: [Rd] wheel ownership of new documents: OS X, (PR#9499)
Message-ID: <20070208170933.F30605A883@slim.kubism.ku.dk>

Full_Name: William Doane
Version: R version 2.4.1 (2006-12-18) R.app GUI 1.18 (4038)
OS: OS X 10.4.8
Submission from: (NULL) (72.228.26.7)


If one creates a new document within R.app and saves it, the group ownership is
set to wheel, rather than the users' personal group:

-rw-r--r--    1 wejdoane  wheel         3 Feb  8 12:01 abc.R

Expected behavior:
-rw-r--r--    1 wejdoane  wejdoane    3 Feb  8 12:01 abc.R


From ggrothendieck at gmail.com  Fri Feb  9 00:17:32 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 8 Feb 2007 18:17:32 -0500
Subject: [Rd] obscure error with subsetting as.list() of a function then
	assigning that a (PR#9500)
In-Reply-To: <20070208180825.7B3D75A842@slim.kubism.ku.dk>
References: <20070208180825.7B3D75A842@slim.kubism.ku.dk>
Message-ID: <971536df0702081517y3dd0e8d4l3a791499d1953d4@mail.gmail.com>

Also note:

   missing(a) # TRUE


On 2/8/07, peter-m.schumacher at db.com <peter-m.schumacher at db.com> wrote:
>
>
> Hello. I was writing some code that computes on the language and came across
> this. I can work around it, but thought you might like to know about it.
>
> > f <- function(x) { NULL }
> > a <- as.list(f)[[1]]
> > a # ie print(a)
> Error: argument "a" is missing, with no default
>
> Note it says *argument* "a", which is strange. In fact, and unsurprisingly, the bug lies
> with the object itself, not with print():
>
> > typeof(a)
> Error in typeof(a) : argument "a" is missing, with no default
> > deparse(a)
> Error in deparse(a) : argument "a" is missing, with no default
>
> However, this does work:
> > as.list(f)[[1]]
>
> It prints nothing, which is correct, and there is no error. So it seems the bug lies with
> assigning a name to as.list(f)[[1]] as above, then trying to work with that new object.
>
> Regards,
> Peter-M.Schumacher at db.com
>
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 4.1
>  year = 2006
>  month = 12
>  day = 18
>  svn rev = 40228
>  language = R
>  version.string = R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ross at biostat.ucsf.edu  Fri Feb  9 00:30:36 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 8 Feb 2007 15:30:36 -0800
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45CBA9E1.6060400@aon.at>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
	<20070208203245.GA6397@wheat.betterworld.us>
	<45CB904E.1020300@aon.at>
	<20070208221450.GI5871@wheat.betterworld.us>
	<45CBA9E1.6060400@aon.at>
Message-ID: <20070208233036.GK5871@wheat.betterworld.us>

On Thu, Feb 08, 2007 at 11:53:21PM +0100, cstrato wrote:
...
> >Maybe there's some subtle linker problem, or a problem with the
> >representation of strings
> >
> >
> >  
> What do you mean with linker problem?
> 
Nothing very specific, but generically wrong options, wrong
objects/libraries, or wrong order of the first 2.  "Wrong" includes
omitting something that should be there or including something that
shouldn't.

Linking on OS-X is unconventional relative to other systems I have
used.  In particular, one usually gets lots of errors about duplicate
symbols (which can be turned off, at some risk) and needs to specify
flat rather than 2-level namespace.  There's lots more if you look at
the linker page (man ld).

Similar issues can arise at the compiler phase too.

Another fun thing on OS-X is that they have a libtool that is
different from the GNU libtool, and your project might use both.  So
you need to be sure to get the right one.  But it's unlikely you could
even build if that were an issue.

If different parts (e.g., R vs your code) are built with different
options, that can cause trouble.

For example, my Makefile has
MAINCXXFLAGS :=  $(shell R CMD config --cppflags) -std=c++98 -Wall -I$(TRUESRCDIR)
This relies on GNU make features.


From p.dalgaard at biostat.ku.dk  Fri Feb  9 00:39:45 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 09 Feb 2007 00:39:45 +0100
Subject: [Rd] obscure error with subsetting as.list() of a function then
 assigning that a (PR#9500)
In-Reply-To: <20070208180825.7B3D75A842@slim.kubism.ku.dk> (peter-m
	schumacher's message of "Thu,  8 Feb 2007 19:08:25 +0100 (CET)")
References: <20070208180825.7B3D75A842@slim.kubism.ku.dk>
Message-ID: <x2mz3ousla.fsf@viggo.kubism.ku.dk>

peter-m.schumacher at db.com writes:

> Hello. I was writing some code that computes on the language and came across
> this. I can work around it, but thought you might like to know about it.
>
>> f <- function(x) { NULL }
>> a <- as.list(f)[[1]]
>> a # ie print(a)
> Error: argument "a" is missing, with no default
>
> Note it says *argument* "a", which is strange. In fact, and unsurprisingly, the bug lies
> with the object itself, not with print():
>
>> typeof(a)
> Error in typeof(a) : argument "a" is missing, with no default
>> deparse(a)
> Error in deparse(a) : argument "a" is missing, with no default
>
> However, this does work:
>> as.list(f)[[1]]
>
> It prints nothing, which is correct, and there is no error. So it seems the bug lies with
> assigning a name to as.list(f)[[1]] as above, then trying to work with that new object.


It's not a bug things work in ways that confuse users when they pry
into things they were not expected to pry into.... Do you have a good
reason to call this a bug?

What you're seeing is R's "missing argument object", via the default
value of the formal argument x. A slightly cleaner way to get your
result is

> formals(f)
$x


> a <-formals(f)$x
> a
Error: argument "a" is missing, with no default

Technically, the missing argument object is a zero-length variable
name: 

> mode(formals(f)$x)
[1] "name"
> as.character(formals(f)$x)
[1] ""


Except for direct meddling with the formals(f), the only way to assign
the missing argument object is via parameter passing - any other
attempt to access it gives an error. So the common case is that the
object is indeed a function argument.



> Regards,
> Peter-M.Schumacher at db.com
>
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 4.1
>  year = 2006
>  month = 12
>  day = 18
>  svn rev = 40228
>  language = R
>  version.string = R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Feb  9 00:40:05 2007
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Fri,  9 Feb 2007 00:40:05 +0100 (CET)
Subject: [Rd] obscure error with subsetting as.list() of a function then
	(PR#9504)
Message-ID: <20070208234005.63F2A5A866@slim.kubism.ku.dk>

peter-m.schumacher at db.com writes:

> Hello. I was writing some code that computes on the language and came acr=
oss
> this. I can work around it, but thought you might like to know about it.
>
>> f <- function(x) { NULL }
>> a <- as.list(f)[[1]]
>> a # ie print(a)
> Error: argument "a" is missing, with no default
>
> Note it says *argument* "a", which is strange. In fact, and unsurprisingl=
y, the bug lies
> with the object itself, not with print():
>
>> typeof(a)
> Error in typeof(a) : argument "a" is missing, with no default
>> deparse(a)
> Error in deparse(a) : argument "a" is missing, with no default
>
> However, this does work:
>> as.list(f)[[1]]
>
> It prints nothing, which is correct, and there is no error. So it seems t=
he bug lies with
> assigning a name to as.list(f)[[1]] as above, then trying to work with th=
at new object.


It's not a bug things work in ways that confuse users when they pry
into things they were not expected to pry into.... Do you have a good
reason to call this a bug?

What you're seeing is R's "missing argument object", via the default
value of the formal argument x. A slightly cleaner way to get your
result is

> formals(f)
$x


> a <-formals(f)$x
> a
Error: argument "a" is missing, with no default

Technically, the missing argument object is a zero-length variable
name:=20

> mode(formals(f)$x)
[1] "name"
> as.character(formals(f)$x)
[1] ""


Except for direct meddling with the formals(f), the only way to assign
the missing argument object is via parameter passing - any other
attempt to access it gives an error. So the common case is that the
object is indeed a function argument.



> Regards,
> Peter-M.Schumacher at db.com
>
>
> --please do not edit the information below--
>
> Version:
>  platform =3D i386-pc-mingw32
>  arch =3D i386
>  os =3D mingw32
>  system =3D i386, mingw32
>  status =3D
>  major =3D 2
>  minor =3D 4.1
>  year =3D 2006
>  month =3D 12
>  day =3D 18
>  svn rev =3D 40228
>  language =3D R
>  version.string =3D R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=3DEnglish_United Kingdom.1252;LC_CTYPE=3DEnglish_United Kingdo=
m.1252;LC_MONETARY=3DEnglish_United Kingdom.1252;LC_NUMERIC=3DC;LC_TIME=3DE=
nglish_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:graph=
ics, package:grDevices, package:utils, package:datasets, package:methods, A=
utoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--=20
   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From roebuck at mdanderson.org  Fri Feb  9 04:50:39 2007
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Thu, 8 Feb 2007 21:50:39 -0600 (CST)
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <20070208233036.GK5871@wheat.betterworld.us>
References: <45C6315F.9020209@aon.at>
	<17862.14169.654577.51179@basebud.nulle.part>
	<45C6400A.3050700@aon.at> <m2d54pob4f.fsf@fhcrc.org>
	<45C65479.30906@aon.at>
	<20070208203245.GA6397@wheat.betterworld.us> <45CB904E.1020300@aon.at>
	<20070208221450.GI5871@wheat.betterworld.us> <45CBA9E1.6060400@aon.at>
	<20070208233036.GK5871@wheat.betterworld.us>
Message-ID: <Pine.OSF.4.58.0702082146180.229264@wotan.mdacc.tmc.edu>

On Thu, 8 Feb 2007, Ross Boylan wrote:

> On Thu, Feb 08, 2007 at 11:53:21PM +0100, cstrato wrote:
> ...
> > >Maybe there's some subtle linker problem, or a problem with the
> > >representation of strings
> >
> > What do you mean with linker problem?
> >
> Nothing very specific, but generically wrong options, wrong
> objects/libraries, or wrong order of the first 2.  "Wrong" includes
> omitting something that should be there or including something that
> shouldn't.
> [SNIP]

Ross,

This is not the case as the package was converted to use
Makevars and had the same results. It's probably something
misconfigured on Christian's laptop; waiting for Simon
to take a look.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From mwkimpel at gmail.com  Fri Feb  9 08:01:12 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Fri, 09 Feb 2007 02:01:12 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
 worksheets
In-Reply-To: <971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>
Message-ID: <45CC1C38.3010202@gmail.com>

Gabor,

What I want is a bit more than hyperlinks, although I did ask the 
package developer about that to. My idea is, from within R, place things 
like pdf files and .Rdata directly into an Excel spreadsheet. As a 
practical matter, if I can create a report with some data that someone 
else can manipulate as a "regular" spreadsheet (ex. sort gene lists) and 
then have other sheets that contain pdf output files of graphs I do 
within R. I would also like to archive my R workspace at time of 
analysis so that I could, if I had to, the analysis again. As I and 
others are constantly tweaking what functions do, it is sometimes 
impossible for me to go back and figure out what versions of what 
functions I was using. sessionInfo won't do what I want.

Since Hans-Peter came up with his really nice package, I thought I would 
throw this out as an idea. I have been doing this manually for some time 
  and my boss likes it because he only has to get one file from me, not 
10. I include worksheets with the values of parameters passed to 
functions, abbreviations, etc. Then 5 months from now and he wants me to 
explain the sheet to him, everything is in one place.

In a way, I want to treat an Excel spreadsheet as a list (the workbook) 
that can contain different kinds of objects (spreadsheets, pdfs, Rdata, 
ex.). The Excel file acts as a binder for these different files. My boss 
doesn't even want to deal with zipped files because when they are 
unzipped he ends up with tons of files.

I know this might not make a lot of sense to UNIX users who mostly 
interact with other programmers, but for those of us who deal with the 
computer-barely-literate biologists who run Windows, it could be a nice 
way of keeping things together.

BTW, I only mention Excel and Windows because that is what I use. I 
think it would be great to come up with a common format that Linux, Mac, 
and UNIX users could use. Could openOffice serve that purpose?

Thanks for your input.

Mark

Gabor Grothendieck wrote:
> Its not entirely clear to me what it is that you are looking
> for.  Maybe you want to create an Excel spreadsheet with a hyperlink
> to a web page?  This R code will do that.  It requires a Windows machine 
> that
> has Excel running on it.
> 
> 
> library(RDCOMClient)
> xl <- COMCreate("Excel.Application")
> xl[["Visible"]] <- TRUE
> wkbk <- xl$Workbooks()$Add()
> 
> sh <- xl$ActiveSheet()
> 
> B2R <- sh$Range("B3")
> B2R[["Formula"]] <- '=HYPERLINK("http://www.r-project.org")'
> 
> wkbk$SaveAs("\\test-url.xls")
> xl$Quit()
> 
> 
> 
> 
> On 2/8/07, Mark W Kimpel <mwkimpel at gmail.com> wrote:
>> Hans-Peter and other R developers,
>>
>> How are you? Have you made any progess with embedding Url's in Excel?
>>
>> Well, I have been busy thinking of more things for you to do;)
>>
>> My colleagues in the lab are not R literate, and some are barely
>> computer literate, so I give them everything in Excel workbooks. I have
>> gradually evolved a system such that these workbooks have become
>> compendia of my data, output, and methods. That, in fact, is why I
>> bought the Pro version of xlsReadWritePro. I have been saving graphics
>> as PDF files, then inserting them as object in Excel sheets.
>>
>> What I would like to be able to do is to embed objects (files) in sheets
>> of a workbook directly from within R. I would also like to be able to
>> save my current R workspace as an object embedded in a sheet so that in
>> the future, if packages change, I could go back and recreate the
>> analysis. I do not need to be able to manuipulate files that R has not
>> created, like a PDF file from another user. I would, however, like to be
>> able to save my graphics as PDF files inside a worksheet, even if it
>> meant creating a  temp file or something.
>>
>> Before people begin talking about how MySQL or some other database could
>> handle all that archiving, let me say that that is not what my
>> colleagues want. They want a nice Excel file that they can take home on
>> there laptops. One thing I like about worksheets is that they themselves
>> can contain many embedded files, so it keeps our virtual desks neater
>> and less confusing.
>>
>> Hans, if you could do this, it would be of tremendous benefit to me and
>> hopefully a lot of people. R developers tend to think that all
>> scientists are running Linux on 64-bit computers, but most biomedical
>> researches still store date in Excel files. This won't solve everybody's
>> needs, but it could be a start.
>>
>> Well, let me know what you think. I am cc'ing R-devel to see if any of
>> those guys have ideas as well.
>>
>> Thanks,
>> Mark
>>
>>
>>
>> -- 
>> Mark W. Kimpel MD
>> Neuroinformatics
>> Department of Psychiatry
>> Indiana University School of Medicine
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From mwkimpel at gmail.com  Fri Feb  9 08:10:33 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Fri, 09 Feb 2007 02:10:33 -0500
Subject: [Rd] append within worksheet in write.xls
Message-ID: <45CC1E69.1070509@gmail.com>

I can currently append an entire worksheet with write.xls, but would 
also like to be able to append within the same worksheet. Is this 
possible? It doesn't seem to work if I use append = T

Thanks,
Mark


-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From mwkimpel at gmail.com  Fri Feb  9 08:17:48 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Fri, 09 Feb 2007 02:17:48 -0500
Subject: [Rd] newline with cell of Excel worksheet created with write.xls
Message-ID: <45CC201C.9060600@gmail.com>

As part of my project to put different types of results into worksheets, 
I would like to be able to put an auto-generated methods section. If I 
compose in RWinEdt, read into R, and use write.table with a .txt file 
extension, what I get out has line-breaks that correspond to those I put 
in in the first place.

If I do the same thing but write.xls with .xls extention, I get an Excel 
  worksheet with the entire paragraph on one line (row). It seems to me 
that Excel uses a special character for new-lines (new-rows). Is there a 
way that write.xls could convert \n to this special character?

I'm  writing lots of posts on this, but trying to break up the subjects 
to create better threads.

Mark

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From ripley at stats.ox.ac.uk  Fri Feb  9 09:09:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Feb 2007 08:09:37 +0000 (GMT)
Subject: [Rd] supsmu(periodic=TRUE) can crash R by reading before start
 of array (PR#9502)
In-Reply-To: <20070208194839.2D35D5A87C@slim.kubism.ku.dk>
References: <20070208194839.2D35D5A87C@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0702090807090.23029@gannet.stats.ox.ac.uk>

Thank you for the comprehensive report and fix.
Now incorporated in R-devel.

Brian

On Thu, 8 Feb 2007, bill at insightful.com wrote:

> supsmu(periodic=TRUE) can crash R by reading before start of array.
>
> To reproduce:
>   set.seed(1)
>   xx <- runif(29000)
>   yy <- rnorm(29000)
>   span <- 0.49
>   i <- 1
>   while(i < 200){
>      cat(i,"\n")
>      int <- supsmu(xx,yy,periodic=T,span=span)
>      i <-i+1
>   }
>
> results in:
>   1
>   2
>   3
>   4
>   5
>   6
>   7
>   8
>   9
>
>   Program received signal SIGSEGV, Segmentation fault.
>   smooth_ (n=0xffffeffe, x=0xb6a7f020, y=0xb6993020, w=0xb6921020,
>       span=0xffffeffe, iper=0xffffeffe, vsmlsq=0xffffeffe, smo=0xb68e8020,
>       acvr=0x9c7e7c8) at ppr.f:1087
>   1087             xti=x(j)
>   Current language:  auto; currently fortran
>   (gdb) list
>   1082          if (ibw.lt.2) ibw=2
>   1083          it=2*ibw+1
>   1084          do 20 i=1,it
>   1085             j=i
>   1086             if (jper.eq.2) j=i-ibw-1
> -> 1087             xti=x(j)
>   1088             if (j.ge.1) go to 10
>   1089             j=n+j
>   1090             xti=x(j)-1d0
>   1091     10      wt=w(j)
>   (gdb) print jper
>   $1 = 2
>   (gdb) print j
>   $2 = -4099
>
> If you use 'R -d valgrind' it stops in the same spot
> on the first call to supsmu:
>   1
>   ==8058== Invalid read of size 8
>   ==8058==    at 0x56A65DA: smooth_ (ppr.f:1087)
>   ==8058==    by 0x56A64D5: supsmu_ (ppr.f:1028)
>   ==8058==    by 0x80B2488: do_dotCode (dotcode.c:1753)
>   ==8058==    by 0x80C9405: Rf_eval (eval.c:441)
>   ...
>   ==8058==  Address 0x5EFDA80 is 0 bytes after a block of size 232,024 alloc'd
>   ==8058==    at 0x401A6EE: malloc (vg_replace_malloc.c:149)
>   ==8058==    by 0x80EFBC9: Rf_allocVector (memory.c:1952)
>   ==8058==    by 0x807B6CB: do_makevector (builtin.c:558)
>   ==8058==    by 0x80F9946: do_internal (names.c:1091)
>   ==8058==    by 0x80C9478: Rf_eval (eval.c:424)
>
> Note that it computes x(j) and then, if j is out of
> bounds, resets j to be at the end of the x array
> and recomputes x(j).  It should not compute x(j) if
> j is out of bounds.
>
> A fix that keeps this looking like Fortran IV is
> to put 'if (j.ge.1)' at the start of line 1087
> (in R_HOME/src/library/stats/src/ppr.f).  This stops
> the crash and makes valgrind happy.
>
> (Splus has the identical problem and fix.)
>
> *** ppr.f~	2007-02-08 11:31:50.000000000 -0800
> --- ppr.f	2007-02-08 11:32:07.000000000 -0800
> ***************
> *** 1084,1090 ****
>        do 20 i=1,it
>           j=i
>           if (jper.eq.2) j=i-ibw-1
> !          xti=x(j)
>           if (j.ge.1) go to 10
>           j=n+j
>           xti=x(j)-1d0
> --- 1084,1090 ----
>        do 20 i=1,it
>           j=i
>           if (jper.eq.2) j=i-ibw-1
> !          if (j.ge.1) xti=x(j)
>           if (j.ge.1) go to 10
>           j=n+j
>           xti=x(j)-1d0
>
> --please do not edit the information below--
>
> Version:
> platform = i686-pc-linux-gnu
> arch = i686
> os = linux-gnu
> system = i686, linux-gnu
> status = Under development (unstable)
> major = 2
> minor = 5.0
> year = 2007
> month = 02
> day = 05
> svn rev = 40659
> language = R
> version.string = R version 2.5.0 Under development (unstable) (2007-02-05 r40659)
>
> Locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> Search Path:
> .GlobalEnv, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
>
> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>
> "All statements in this message represent the opinions of the author and do
> not necessarily reflect Insightful Corporation policy or position."
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Fri Feb  9 10:28:04 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Feb 2007 04:28:04 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <45CC1C38.3010202@gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<971536df0702080858u7026f522ye4c0f30004aec53f@mail.gmail.com>
	<45CC1C38.3010202@gmail.com>
Message-ID: <971536df0702090128p673ee45cp28ccef147d3e5dcc@mail.gmail.com>

If Excel has the capability to do it then by controlling Excel from R
using RDCOMClient or rcom packages you can do it (in Windows).
For example, the code below creates a plot in R and then creates an Excel
spreadsheet and inserts it.

Get up to speed on VBA and then use the Macro recorder in
Excel while you do it manually and look at the macro source that it
generates to find out what VBA commands it uses for a particular task.

plot(1:10)
savePlot("c:\\myplot", "wmf")

library(RDCOMClient)
xl <- COMCreate("Excel.Application")
xl[["Visible"]] <- TRUE
wkbk <- xl$Workbooks()$Add()

sh <- xl$ActiveSheet()

sh$Pictures()$Insert("C:\\myplot.wmf")

wkbk$SaveAs("\\test-pic.xls")
xl$Quit()



On 2/9/07, Mark W Kimpel <mwkimpel at gmail.com> wrote:
> Gabor,
>
> What I want is a bit more than hyperlinks, although I did ask the
> package developer about that to. My idea is, from within R, place things
> like pdf files and .Rdata directly into an Excel spreadsheet. As a
> practical matter, if I can create a report with some data that someone
> else can manipulate as a "regular" spreadsheet (ex. sort gene lists) and
> then have other sheets that contain pdf output files of graphs I do
> within R. I would also like to archive my R workspace at time of
> analysis so that I could, if I had to, the analysis again. As I and
> others are constantly tweaking what functions do, it is sometimes
> impossible for me to go back and figure out what versions of what
> functions I was using. sessionInfo won't do what I want.
>
> Since Hans-Peter came up with his really nice package, I thought I would
> throw this out as an idea. I have been doing this manually for some time
>  and my boss likes it because he only has to get one file from me, not
> 10. I include worksheets with the values of parameters passed to
> functions, abbreviations, etc. Then 5 months from now and he wants me to
> explain the sheet to him, everything is in one place.
>
> In a way, I want to treat an Excel spreadsheet as a list (the workbook)
> that can contain different kinds of objects (spreadsheets, pdfs, Rdata,
> ex.). The Excel file acts as a binder for these different files. My boss
> doesn't even want to deal with zipped files because when they are
> unzipped he ends up with tons of files.
>
> I know this might not make a lot of sense to UNIX users who mostly
> interact with other programmers, but for those of us who deal with the
> computer-barely-literate biologists who run Windows, it could be a nice
> way of keeping things together.
>
> BTW, I only mention Excel and Windows because that is what I use. I
> think it would be great to come up with a common format that Linux, Mac,
> and UNIX users could use. Could openOffice serve that purpose?
>
> Thanks for your input.
>
> Mark
>
> Gabor Grothendieck wrote:
> > Its not entirely clear to me what it is that you are looking
> > for.  Maybe you want to create an Excel spreadsheet with a hyperlink
> > to a web page?  This R code will do that.  It requires a Windows machine
> > that
> > has Excel running on it.
> >
> >
> > library(RDCOMClient)
> > xl <- COMCreate("Excel.Application")
> > xl[["Visible"]] <- TRUE
> > wkbk <- xl$Workbooks()$Add()
> >
> > sh <- xl$ActiveSheet()
> >
> > B2R <- sh$Range("B3")
> > B2R[["Formula"]] <- '=HYPERLINK("http://www.r-project.org")'
> >
> > wkbk$SaveAs("\\test-url.xls")
> > xl$Quit()
> >
> >
> >
> >
> > On 2/8/07, Mark W Kimpel <mwkimpel at gmail.com> wrote:
> >> Hans-Peter and other R developers,
> >>
> >> How are you? Have you made any progess with embedding Url's in Excel?
> >>
> >> Well, I have been busy thinking of more things for you to do;)
> >>
> >> My colleagues in the lab are not R literate, and some are barely
> >> computer literate, so I give them everything in Excel workbooks. I have
> >> gradually evolved a system such that these workbooks have become
> >> compendia of my data, output, and methods. That, in fact, is why I
> >> bought the Pro version of xlsReadWritePro. I have been saving graphics
> >> as PDF files, then inserting them as object in Excel sheets.
> >>
> >> What I would like to be able to do is to embed objects (files) in sheets
> >> of a workbook directly from within R. I would also like to be able to
> >> save my current R workspace as an object embedded in a sheet so that in
> >> the future, if packages change, I could go back and recreate the
> >> analysis. I do not need to be able to manuipulate files that R has not
> >> created, like a PDF file from another user. I would, however, like to be
> >> able to save my graphics as PDF files inside a worksheet, even if it
> >> meant creating a  temp file or something.
> >>
> >> Before people begin talking about how MySQL or some other database could
> >> handle all that archiving, let me say that that is not what my
> >> colleagues want. They want a nice Excel file that they can take home on
> >> there laptops. One thing I like about worksheets is that they themselves
> >> can contain many embedded files, so it keeps our virtual desks neater
> >> and less confusing.
> >>
> >> Hans, if you could do this, it would be of tremendous benefit to me and
> >> hopefully a lot of people. R developers tend to think that all
> >> scientists are running Linux on 64-bit computers, but most biomedical
> >> researches still store date in Excel files. This won't solve everybody's
> >> needs, but it could be a start.
> >>
> >> Well, let me know what you think. I am cc'ing R-devel to see if any of
> >> those guys have ideas as well.
> >>
> >> Thanks,
> >> Mark
> >>
> >>
> >>
> >> --
> >> Mark W. Kimpel MD
> >> Neuroinformatics
> >> Department of Psychiatry
> >> Indiana University School of Medicine
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
>
> --
> Mark W. Kimpel MD
> Neuroinformatics
> Department of Psychiatry
> Indiana University School of Medicine
>


From peter-m.schumacher at db.com  Fri Feb  9 16:39:46 2007
From: peter-m.schumacher at db.com (Peter-M Schumacher)
Date: Fri, 9 Feb 2007 15:39:46 +0000
Subject: [Rd] obscure error with subsetting as.list() of a function then
 assigning that a (PR#9500)
In-Reply-To: <x2mz3ousla.fsf@viggo.kubism.ku.dk>
Message-ID: <OFBD0A3341.2281D77F-ON8025727D.005555F7-8025727D.005609C9@db.com>


Ok, thanks for clearing it up. But:

> It's not a bug things work in ways that confuse users when they pry
> into things they were not expected to pry into.... Do you have a good
> reason to call this a bug?

Well if it's intended to work that way then it's not a bug.
As I said, I was computing on the language, in particular writing code that
processes the parse tree of a function. But I guess I need to avoid certain
gotchas like this one.

Regards,
Peter



                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
             Peter Dalgaard <p.dalgaard at biostat.ku.dk>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
             08/02/2007 23:39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              To 
                                                                                                                                                                                                                                                                                                                                                                                                                        Peter-M Schumacher/DMGGM/DMG UK/DeuBa at DBEMEA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           cc 
                                                                                                                                                                                                                                                                                                                                                                                                                        r-devel at stat.math.ethz.ch, R-bugs at biostat.ku.dk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Subject 
                                                                                                                                                                                                                                                                                                                                                                                                                        Re: [Rd] obscure error with subsetting as.list() of a function then assigning that a (PR#9500)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              




peter-m.schumacher at db.com writes:

> Hello. I was writing some code that computes on the language and came across
> this. I can work around it, but thought you might like to know about it.
>
>> f <- function(x) { NULL }
>> a <- as.list(f)[[1]]
>> a # ie print(a)
> Error: argument "a" is missing, with no default
>
> Note it says *argument* "a", which is strange. In fact, and unsurprisingly, the bug lies
> with the object itself, not with print():
>
>> typeof(a)
> Error in typeof(a) : argument "a" is missing, with no default
>> deparse(a)
> Error in deparse(a) : argument "a" is missing, with no default
>
> However, this does work:
>> as.list(f)[[1]]
>
> It prints nothing, which is correct, and there is no error. So it seems the bug lies with
> assigning a name to as.list(f)[[1]] as above, then trying to work with that new object.


It's not a bug things work in ways that confuse users when they pry
into things they were not expected to pry into.... Do you have a good
reason to call this a bug?

What you're seeing is R's "missing argument object", via the default
value of the formal argument x. A slightly cleaner way to get your
result is

> formals(f)
$x


> a <-formals(f)$x
> a
Error: argument "a" is missing, with no default

Technically, the missing argument object is a zero-length variable
name:

> mode(formals(f)$x)
[1] "name"
> as.character(formals(f)$x)
[1] ""


Except for direct meddling with the formals(f), the only way to assign
the missing argument object is via parameter passing - any other
attempt to access it gives an error. So the common case is that the
object is indeed a function argument.



> Regards,
> Peter-M.Schumacher at db.com
>
>
> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 4.1
>  year = 2006
>  month = 12
>  day = 18
>  svn rev = 40228
>  language = R
>  version.string = R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



---

This e-mail may contain confidential and/or privileged infor...{{dropped}}


From peter-m.schumacher at db.com  Fri Feb  9 16:40:34 2007
From: peter-m.schumacher at db.com (peter-m.schumacher at db.com)
Date: Fri,  9 Feb 2007 16:40:34 +0100 (CET)
Subject: [Rd] obscure error with subsetting as.list() of a function then
	(PR#9506)
Message-ID: <20070209154034.F0D3B5A8DD@slim.kubism.ku.dk>


Ok, thanks for clearing it up. But:

> It's not a bug things work in ways that confuse users when they pry
> into things they were not expected to pry into.... Do you have a good=

> reason to call this a bug?

Well if it's intended to work that way then it's not a bug.
As I said, I was computing on the language, in particular writing code =
that
processes the parse tree of a function. But I guess I need to avoid cer=
tain
gotchas like this one.

Regards,
Peter



                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
             Peter Dalgaard <p.dalgaard at biostat.ku.dk>                 =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
             08/02/2007 23:39                                          =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                To 
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                     Peter-M Schumacher=
/DMGGM/DMG UK/DeuBa at DBEMEA                                             =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                cc 
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                     r-devel at stat.math.=
ethz.ch, R-bugs at biostat.ku.dk                                          =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                           Subject 
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                     Re: [Rd] obscure e=
rror with subsetting as.list() of a function then assigning that a (PR#=
9500)                                                                  =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                       =
                                                                   




peter-m.schumacher at db.com writes:

> Hello. I was writing some code that computes on the language and came=
 across
> this. I can work around it, but thought you might like to know about =
it.
>
>> f <- function(x) { NULL }
>> a <- as.list(f)[[1]]
>> a # ie print(a)
> Error: argument "a" is missing, with no default
>
> Note it says *argument* "a", which is strange. In fact, and unsurpris=
ingly, the bug lies
> with the object itself, not with print():
>
>> typeof(a)
> Error in typeof(a) : argument "a" is missing, with no default
>> deparse(a)
> Error in deparse(a) : argument "a" is missing, with no default
>
> However, this does work:
>> as.list(f)[[1]]
>
> It prints nothing, which is correct, and there is no error. So it see=
ms the bug lies with
> assigning a name to as.list(f)[[1]] as above, then trying to work wit=
h that new object.


It's not a bug things work in ways that confuse users when they pry
into things they were not expected to pry into.... Do you have a good
reason to call this a bug?

What you're seeing is R's "missing argument object", via the default
value of the formal argument x. A slightly cleaner way to get your
result is

> formals(f)
$x


> a <-formals(f)$x
> a
Error: argument "a" is missing, with no default

Technically, the missing argument object is a zero-length variable
name:

> mode(formals(f)$x)
[1] "name"
> as.character(formals(f)$x)
[1] ""


Except for direct meddling with the formals(f), the only way to assign
the missing argument object is via parameter passing - any other
attempt to access it gives an error. So the common case is that the
object is indeed a function argument.



> Regards,
> Peter-M.Schumacher at db.com
>
>
> --please do not edit the information below--
>
> Version:
>  platform =3D i386-pc-mingw32
>  arch =3D i386
>  os =3D mingw32
>  system =3D i386, mingw32
>  status =3D
>  major =3D 2
>  minor =3D 4.1
>  year =3D 2006
>  month =3D 12
>  day =3D 18
>  svn rev =3D 40228
>  language =3D R
>  version.string =3D R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=3DEnglish_United Kingdom.1252;LC_CTYPE=3DEnglish_United Ki=
ngdom.1252;LC_MONETARY=3DEnglish_United Kingdom.1252;LC_NUMERIC=3DC;LC_=
TIME=3DEnglish_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:c:/schupl/R/myRLib/.RData, package:stats, package:g=
raphics, package:grDevices, package:utils, package:datasets, package:me=
thods, Autoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{drop=
ped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
   O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 353=
27918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 353=
27907



---

This e-mail may contain confidential and/or privileged infor...{{dropped}}


From cstrato at aon.at  Fri Feb  9 17:11:33 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 09 Feb 2007 17:11:33 +0100
Subject: [Rd]  Problem using ofstream in C++ class in package for MacOS X
References: 20070208233036.GK5871@wheat.betterworld.us
Message-ID: <45CC9D35.8050202@aon.at>

Dear Ross

Thank you  for this clarification, maybe there is something 
misconfigured on my Intel-Mac.
BTW, I have now upgraded to XCode 2.4.1 from 2.4, but the result remains 
the same.

I don?t know if this could help clarify what might be wrong, but I am 
not able to compile
plier, a simple package containing an R-wrapper around Affymetrix C++ 
plier code.
This is the output I get when trying to compile plier:

m3450p027:/Volumes/CoreData/CRAN/Bioconductor/packages rabbitus$ 
R_ARCH=/i386 R CMD INSTALL -l ~/Library/R/library plier_1.4.0.tar.gz
* Installing *source* package 'plier' ...
** libs
** arch - i386
g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386  -msse3    
-fPIC  -g -O2 -march=nocona -c affyplier.cpp -o affyplier.o
/Volumes/CoreData/temp/cc3VRxb1.s:4750:indirect jmp without `*'
/Volumes/CoreData/temp/cc3VRxb1.s:4769:indirect jmp without `*'
/Volumes/CoreData/temp/cc3VRxb1.s:4784:indirect jmp without `*'
/Volumes/CoreData/temp/cc3VRxb1.s:4799:indirect jmp without `*'
/Volumes/CoreData/temp/cc3VRxb1.s:4818:indirect jmp without `*'
/Volumes/CoreData/temp/cc3VRxb1.s:4833:indirect jmp without `*'
g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386  -msse3    
-fPIC  -g -O2 -march=nocona -c plier_impl.cpp -o plier_impl.o
/Volumes/CoreData/temp/ccLq6FYI.s:554:indirect jmp without `*'
/Volumes/CoreData/temp/ccLq6FYI.s:569:indirect jmp without `*'
/Volumes/CoreData/temp/ccLq6FYI.s:584:indirect jmp without `*'
/Volumes/CoreData/temp/ccLq6FYI.s:599:indirect jmp without `*'
/Volumes/CoreData/temp/ccLq6FYI.s:618:indirect jmp without `*'
g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386  -msse3    
-fPIC  -g -O2 -march=nocona -c plieralg.cpp -o plieralg.o
plieralg.cpp:30:20: error: malloc.h: No such file or directory
make: *** [plieralg.o] Error 1
chmod: /Users/rabbitus/Library/R/library/plier/libs/i386/*: No such file 
or directory
** arch - ppc
g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/ppc  
-I/usr/local/include    -fPIC  -g -O2 -c affyplier.cpp -o affyplier.o
g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/ppc  
-I/usr/local/include    -fPIC  -g -O2 -c plier_impl.cpp -o plier_impl.o
g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/ppc  
-I/usr/local/include    -fPIC  -g -O2 -c plieralg.cpp -o plieralg.o
plieralg.cpp:30:20: error: malloc.h: No such file or directory
make: *** [plieralg.o] Error 1
chmod: /Users/rabbitus/Library/R/library/plier/libs/ppc/*: No such file 
or directory
ERROR: compilation failed for package 'plier'
** Removing '/Users/rabbitus/Library/R/library/plier

In any case, the problem seems to be R-specific, since the same code for 
my package MyClass
runs fine, when compiled as a shared library and called from other C++ code.

BTW, since I do not have an url, I would like to attach my package, so 
that people could try it.
In my initial mailing I have attached my package as 
MyClass_0.1.2.tar.gz, but it got scrambled
as 
https://stat.ethz.ch/pipermail/r-devel/attachments/20070204/2e7fb79c/attachment.gz 

Is there a possibility to attach it in a way so that people can use it?

Thank you
Best regards
Christian


From khansen at stat.Berkeley.EDU  Fri Feb  9 18:11:36 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Fri, 9 Feb 2007 09:11:36 -0800
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <45CC9D35.8050202@aon.at>
References: 20070208233036.GK5871@wheat.betterworld.us
	<45CC9D35.8050202@aon.at>
Message-ID: <C8002483-F16D-468A-8551-E4E705E0DE4D@stat.berkeley.edu>

I have some experience wrapping code from Affymetrix in R (see the  
affxparser package). Depending on who actually wrote the package, you  
may find that it is not trivial to get it to work on different  
platforms. They are not always carefully to think about different  
compilers etc.

You may want to look at the plier package in Bioconductor to who they  
do it.

Of course this may or may not be related to your other C++ problems.

Kasper


On Feb 9, 2007, at 8:11 AM, cstrato wrote:

> Dear Ross
>
> Thank you  for this clarification, maybe there is something
> misconfigured on my Intel-Mac.
> BTW, I have now upgraded to XCode 2.4.1 from 2.4, but the result  
> remains
> the same.
>
> I don?t know if this could help clarify what might be wrong, but I am
> not able to compile
> plier, a simple package containing an R-wrapper around Affymetrix C++
> plier code.
> This is the output I get when trying to compile plier:
>
> m3450p027:/Volumes/CoreData/CRAN/Bioconductor/packages rabbitus$
> R_ARCH=/i386 R CMD INSTALL -l ~/Library/R/library plier_1.4.0.tar.gz
> * Installing *source* package 'plier' ...
> ** libs
> ** arch - i386
> g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/i386  -msse3
> -fPIC  -g -O2 -march=nocona -c affyplier.cpp -o affyplier.o
> /Volumes/CoreData/temp/cc3VRxb1.s:4750:indirect jmp without `*'
> /Volumes/CoreData/temp/cc3VRxb1.s:4769:indirect jmp without `*'
> /Volumes/CoreData/temp/cc3VRxb1.s:4784:indirect jmp without `*'
> /Volumes/CoreData/temp/cc3VRxb1.s:4799:indirect jmp without `*'
> /Volumes/CoreData/temp/cc3VRxb1.s:4818:indirect jmp without `*'
> /Volumes/CoreData/temp/cc3VRxb1.s:4833:indirect jmp without `*'
> g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/i386  -msse3
> -fPIC  -g -O2 -march=nocona -c plier_impl.cpp -o plier_impl.o
> /Volumes/CoreData/temp/ccLq6FYI.s:554:indirect jmp without `*'
> /Volumes/CoreData/temp/ccLq6FYI.s:569:indirect jmp without `*'
> /Volumes/CoreData/temp/ccLq6FYI.s:584:indirect jmp without `*'
> /Volumes/CoreData/temp/ccLq6FYI.s:599:indirect jmp without `*'
> /Volumes/CoreData/temp/ccLq6FYI.s:618:indirect jmp without `*'
> g++-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/i386  -msse3
> -fPIC  -g -O2 -march=nocona -c plieralg.cpp -o plieralg.o
> plieralg.cpp:30:20: error: malloc.h: No such file or directory
> make: *** [plieralg.o] Error 1
> chmod: /Users/rabbitus/Library/R/library/plier/libs/i386/*: No such  
> file
> or directory
> ** arch - ppc
> g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/ppc
> -I/usr/local/include    -fPIC  -g -O2 -c affyplier.cpp -o affyplier.o
> g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/ppc
> -I/usr/local/include    -fPIC  -g -O2 -c plier_impl.cpp -o  
> plier_impl.o
> g++-4.0 -arch ppc -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/ppc
> -I/usr/local/include    -fPIC  -g -O2 -c plieralg.cpp -o plieralg.o
> plieralg.cpp:30:20: error: malloc.h: No such file or directory
> make: *** [plieralg.o] Error 1
> chmod: /Users/rabbitus/Library/R/library/plier/libs/ppc/*: No such  
> file
> or directory
> ERROR: compilation failed for package 'plier'
> ** Removing '/Users/rabbitus/Library/R/library/plier
>
> In any case, the problem seems to be R-specific, since the same  
> code for
> my package MyClass
> runs fine, when compiled as a shared library and called from other C 
> ++ code.
>
> BTW, since I do not have an url, I would like to attach my package, so
> that people could try it.
> In my initial mailing I have attached my package as
> MyClass_0.1.2.tar.gz, but it got scrambled
> as
> https://stat.ethz.ch/pipermail/r-devel/attachments/ 
> 20070204/2e7fb79c/attachment.gz
>
> Is there a possibility to attach it in a way so that people can use  
> it?
>
> Thank you
> Best regards
> Christian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Fri Feb  9 19:44:40 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 09 Feb 2007 19:44:40 +0100
Subject: [Rd] Problem using ofstream in C++ class in package for MacOS X
In-Reply-To: <C8002483-F16D-468A-8551-E4E705E0DE4D@stat.berkeley.edu>
References: 20070208233036.GK5871@wheat.betterworld.us
	<45CC9D35.8050202@aon.at>
	<C8002483-F16D-468A-8551-E4E705E0DE4D@stat.berkeley.edu>
Message-ID: <45CCC118.7000908@aon.at>

Dear Kasper

Thank you, but I want to keep the focus on my own problem (I can indeed 
compile your package).

Since I do not have an url, I would like to attach my package, so that 
people could try it.
In my initial mailing I have attached my package as 
MyClass_0.1.2.tar.gz, but it got scrambled
as 
https://stat.ethz.ch/pipermail/r-devel/attachments/20070204/2e7fb79c/attachment.gz 

Is there a possibility to attach it in a way so that people can use it?

Thank you
Best regards
Christian

Kasper Daniel Hansen wrote:
> I have some experience wrapping code from Affymetrix in R (see the 
> affxparser package). Depending on who actually wrote the package, you 
> may find that it is not trivial to get it to work on different 
> platforms. They are not always carefully to think about different 
> compilers etc.
>
> You may want to look at the plier package in Bioconductor to who they 
> do it.
>
> Of course this may or may not be related to your other C++ problems.
>
> Kasper
>


From S.J.Eglen at damtp.cam.ac.uk  Sun Feb 11 10:15:20 2007
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Sun, 11 Feb 2007 09:15:20 +0000
Subject: [Rd] dump.frames in call from debugger()
Message-ID: <t5x64a96onr.fsf@notch.damtp.cam.ac.uk>

Hi,

https://svn.r-project.org/R/trunk/src/library/utils/R/debugger.R

currently has the arg list of dump.frames as:
  dump.frames <- function(dumpto = "last.dump", to.file = FALSE)

would it be sensible to change the default for to.file to be 
  to.file = !interactive()

So that last.dump.rda would be created if a script (such as below)
is run with "R CMD BATCH" when it hits the error.

Stephen

## simple error in script.

options(error=recover)

simple <- function() {
  errorhere()
}

simple()


From geoffrey.russell at gmail.com  Sun Feb 11 22:37:03 2007
From: geoffrey.russell at gmail.com (Geoff Russell)
Date: Mon, 12 Feb 2007 08:07:03 +1030
Subject: [Rd] Graphics driver test script?
Message-ID: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>

Hi,

1. I started work on a metapost graphics driver a week or so ago and it is
gradually taking shape. I'm building up my own test cases into a
script as I go, but
figured you may have a "canonical testing script" of cases a driver must handle?

2. The clipping function looks like being a tricky problem. It seems
to me that the
callers of the driver assume that clipping affects all following calls
until the next
clipping call resets the clipping box.   With metapost, the clipping
function clips the
current graphics region and has no effect on following drawing functions.  I'm
not sure how to handle this --- the 2 models are very different.

Cheers,
Geoff Russell


From gchappi at gmail.com  Mon Feb 12 00:59:12 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Mon, 12 Feb 2007 00:59:12 +0100
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <45CACDD2.9060007@gmail.com>
References: <45CACDD2.9060007@gmail.com>
Message-ID: <47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>

Hi Mark,

Sorry to not reply earlier, I was away this week.

> Hans-Peter and other R developers,
> How are you? Have you made any progess with embedding Url's in Excel?

Yes, but I started with the update of the free version and got delayed
there (not that I didn't know that paying customers should be
prefered...) - I'll update the pro version right now and you should
have it until Wednesday, maybe tomorrow. Another person asked to write
formulas directly, it will be included also.

> I am cc'ing R-devel to see if any of
> those guys have ideas as well.

Good idea.

Regarding your post about your needs (report generation, container, ...):

I think the suggestion from Gabor with controlling Excel from within R
is an excellent way. xlsReadWritePro could be an option which has some
advantages and some disadvantages.

ActiveX/RDCOMClient:
- you can do everything that Excel supports
- this comes at a price: the interface from R is a bit technical. (the
suggestion with VBA and Macro recorder is a good one imho. Reading
about the Excel Object Model may also help)
- it's more free (what a statement for an excel-based dependency...)
- dependencies (installed Excel, RDCOMClient (probably a non-issue at
your situation))
- more Excelversions are supported

xlsReadWritePro:
- you can only do what is currently implemented
- the interface (should) let you program on a higher level and tries
to shield you from technical details. One of the goals was to give an
easy to use, well tested and well documented interface that feels
R-ish.
- no dependencies (Perl/DCOM/Excel/Java)
- it is native, i.e. works directly on the file.
- (at least potentially) it could be ported to Linux
- currently only Excel v97 - 2003. Excel 2007 is planned to follow
(~end of 07, no promises).

It depends on your situation. ActiveX was not an option for us as we
needed to work on the plain file. Otherwise we have pratically the
same requirements a you (just with other data).

I could potentially implement almost the whole Excel object model
functionality within xlsReadWritePro. But to be honest, it is costly
and I don't think many people would need that.

We basically implemented in the pro version what we needed ourself
internally. Upon request I try to add features if they fit well in the
existing interface and if I have time (or if it is payed for) but I
cannot give any promises.

Best regards,
Hans-Peter


From mwkimpel at gmail.com  Mon Feb 12 02:51:04 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Sun, 11 Feb 2007 20:51:04 -0500
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>
Message-ID: <45CFC808.5050202@gmail.com>

Hans-Peter,

Welcome back, I hope you had a good time away :)

I got what I thought were some answers that misinterpreted what my 
intent was, so let me ask again and try to be more clear.

I would like to be able to use a single Excel spreadsheet as an archive 
for any output I generate in a single R session, including pdf files of 
graphics and possibly the R history or even the R workspace itself. I 
would envision writing the files to be inserted first to a temp file and 
then inserting them into Excel using whatever commands (Visual Basic?) 
that would do that. I know it can be done from the menu, so I am pretty 
sure that it can be done with VB. I am unsure, however, exactly how you 
are generating the Excel files. For my own edification, are you using VB 
or something similar?

Also, to make this not so Windows specific, would these files be 
compatible with openOffice or some other open-source spreadsheet program 
that would be compatible with the other OS's that R users employ? That 
might make it more broadly appealing.

I know that efforts have been made to generate R-compendia that include 
code and data. I think that is great for archiving analyses for the use 
of other R users, but what I am seeking would be much more friendly to 
my end users, which are biologists and psychologists. They don't want 
zip archives that generate a bunch of files, they want just one file 
with everything neat and tidy.

For example, one file with these sheets:

1. .Rworkspace generated at time the last sheet was written. This would 
be akin to an R-compendia but mostly designed for archiving, not 
data-abstraction.
2. methods page. I am working on an auto-generating methods page that 
could be copy and pasted into a paper with minimal editing. I am even 
including references that vary depending on the p.adjust method I use.
3. parameters that are passed to major functions like filters. I list 
what filter I used and how many probesets remained after the filter was 
applied.
4. graphs
5. matrix output.

I am interested in what others think of this idea in general. I am not 
just trying to get something for myself. If someone has a better idea of 
how to package analyses with graphics for the end-user, I'd love to hear it.

I would also be interested in feedback from other developers as to what 
they think of my general idea. Is it worth pursuing? Would it be worthy 
of a simple package?

Thanks for your help and hard-work Hans-Peter and I look forward to 
hearing how things are going,

Mark

Hans-Peter wrote:
> Hi Mark,
> 
> Sorry to not reply earlier, I was away this week.
> 
>> Hans-Peter and other R developers,
>> How are you? Have you made any progess with embedding Url's in Excel?
> 
> Yes, but I started with the update of the free version and got delayed
> there (not that I didn't know that paying customers should be
> prefered...) - I'll update the pro version right now and you should
> have it until Wednesday, maybe tomorrow. Another person asked to write
> formulas directly, it will be included also.
> 
>> I am cc'ing R-devel to see if any of
>> those guys have ideas as well.
> 
> Good idea.
> 
> Regarding your post about your needs (report generation, container, ...):
> 
> I think the suggestion from Gabor with controlling Excel from within R
> is an excellent way. xlsReadWritePro could be an option which has some
> advantages and some disadvantages.
> 
> ActiveX/RDCOMClient:
> - you can do everything that Excel supports
> - this comes at a price: the interface from R is a bit technical. (the
> suggestion with VBA and Macro recorder is a good one imho. Reading
> about the Excel Object Model may also help)
> - it's more free (what a statement for an excel-based dependency...)
> - dependencies (installed Excel, RDCOMClient (probably a non-issue at
> your situation))
> - more Excelversions are supported
> 
> xlsReadWritePro:
> - you can only do what is currently implemented
> - the interface (should) let you program on a higher level and tries
> to shield you from technical details. One of the goals was to give an
> easy to use, well tested and well documented interface that feels
> R-ish.
> - no dependencies (Perl/DCOM/Excel/Java)
> - it is native, i.e. works directly on the file.
> - (at least potentially) it could be ported to Linux
> - currently only Excel v97 - 2003. Excel 2007 is planned to follow
> (~end of 07, no promises).
> 
> It depends on your situation. ActiveX was not an option for us as we
> needed to work on the plain file. Otherwise we have pratically the
> same requirements a you (just with other data).
> 
> I could potentially implement almost the whole Excel object model
> functionality within xlsReadWritePro. But to be honest, it is costly
> and I don't think many people would need that.
> 
> We basically implemented in the pro version what we needed ourself
> internally. Upon request I try to add features if they fit well in the
> existing interface and if I have time (or if it is payed for) but I
> cannot give any promises.
> 
> Best regards,
> Hans-Peter
> 

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From byron.ellis at gmail.com  Mon Feb 12 09:08:19 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Mon, 12 Feb 2007 00:08:19 -0800
Subject: [Rd] Graphics driver test script?
In-Reply-To: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>
References: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>
Message-ID: <7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>

On 2/11/07, Geoff Russell <geoffrey.russell at gmail.com> wrote:
> Hi,
>
> 1. I started work on a metapost graphics driver a week or so ago and it is
> gradually taking shape. I'm building up my own test cases into a
> script as I go, but
> figured you may have a "canonical testing script" of cases a driver must handle?
>

I typically use demo(graphics) for initial development and then things
like example(plotmath) to make sure I'm getting font encoding working
properly.

> 2. The clipping function looks like being a tricky problem. It seems
> to me that the
> callers of the driver assume that clipping affects all following calls
> until the next
> clipping call resets the clipping box.   With metapost, the clipping
> function clips the
> current graphics region and has no effect on following drawing functions.  I'm
> not sure how to handle this --- the 2 models are very different.
>

Sounds like you get to make a lot of clipping calls in metapost.

> Cheers,
> Geoff Russell
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From ripley at stats.ox.ac.uk  Mon Feb 12 09:24:35 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Feb 2007 08:24:35 +0000 (GMT)
Subject: [Rd] Graphics driver test script?
In-Reply-To: <7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>
References: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>
	<7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702120815410.391@gannet.stats.ox.ac.uk>

On Mon, 12 Feb 2007, Byron Ellis wrote:

> On 2/11/07, Geoff Russell <geoffrey.russell at gmail.com> wrote:
>> Hi,
>>
>> 1. I started work on a metapost graphics driver a week or so ago and it is
>> gradually taking shape. I'm building up my own test cases into a
>> script as I go, but
>> figured you may have a "canonical testing script" of cases a driver must handle?
>>
>
> I typically use demo(graphics) for initial development and then things
> like example(plotmath) to make sure I'm getting font encoding working
> properly.
>
>> 2. The clipping function looks like being a tricky problem. It seems
>> to me that the
>> callers of the driver assume that clipping affects all following calls
>> until the next
>> clipping call resets the clipping box.   With metapost, the clipping
>> function clips the
>> current graphics region and has no effect on following drawing functions.  I'm
>> not sure how to handle this --- the 2 models are very different.
>>
>
> Sounds like you get to make a lot of clipping calls in metapost.

Or ask R to do the clipping.  The structure for a graphics device includes

     Rboolean canClip;           /* Hardware clipping */

R's clipping is not as sophisticated as is possible in some devices (e.g. 
it does not take line widths and joins into account AFAIR), but it is used 
by the XFig device, for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gchappi at gmail.com  Mon Feb 12 10:31:27 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Mon, 12 Feb 2007 10:31:27 +0100
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <45CFC808.5050202@gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>
	<45CFC808.5050202@gmail.com>
Message-ID: <47fce0650702120131r56bca68dmbd388c4a73f0e2a9@mail.gmail.com>

Hi Mark,

> I would like to be able to use a single Excel spreadsheet as an archive
> for any output I generate in a single R session, including pdf files of
> graphics and possibly the R history or even the R workspace itself.

What we do is:
- assemble all generated files (xls/png/txt) in a specific *folder*
- the pictures currently end in zip files
- Excel currently only holds the data (no images etc.)
- we don't save any workspace or .Rdata. Each calculation starts from
scratch (sometimes with cached data, but this is transparent)
- we have some packages with the most important/stable source code
- other code we source each time before a calculation
- all code is in a subversion repository and therefore has it's full history.

This works very nice for us. It was not so easy, i.e. we needed some
time to find a lean and flexible setup. R still feels difficult for
me.

> sure that it can be done with VB. I am unsure, however, exactly how you
> are generating the Excel files. For my own edification, are you using VB
> or something similar?

I use Delphi (Object Pascal). The hardwork is done by a 3rd party
library which I bought (Flexcel/tmssoftware.com). You can download the
source of the free xlsReadWrite to see how it was done. (To compile
you would have to buy the flexcel library which - unfortunately - is
not open source and I am not allowed to distribute it.)

> Also, to make this not so Windows specific, would these files be
> compatible with openOffice or some other open-source spreadsheet program
> that would be compatible with the other OS's that R users employ? That
> might make it more broadly appealing.

No, its pure Excel format. - IIRC there is a ODF Toolkit Project which
could be used to generate the files (maybe odfSweave does this
already?). The ODF Toolkit Project is certainly appealing, not least
because of the license situation.

> I would also be interested in feedback from other developers as to what
> they think of my general idea. Is it worth pursuing? Would it be worthy
> of a simple package?

About (small) original data, methods, parameters and matrix output I
agree.   Not so sure about graphs. I prefere to keep things separated.

You can do this already today by controlling Excel from R (see tipps
from Gabor) or (in part) with xlsReadWritePro.

-- 
Regards,
Hans-Peter


From gchappi at gmail.com  Mon Feb 12 10:50:43 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Mon, 12 Feb 2007 10:50:43 +0100
Subject: [Rd] append within worksheet in write.xls
In-Reply-To: <45CC1E69.1070509@gmail.com>
References: <45CC1E69.1070509@gmail.com>
Message-ID: <47fce0650702120150n4a800e27p909adc0662456a83@mail.gmail.com>

Hi,

2007/2/9, Mark W Kimpel <mwkimpel at gmail.com>:
> I can currently append an entire worksheet with write.xls, but would
> also like to be able to append within the same worksheet. Is this
> possible?

Of course. Please see ?xls.open, ?xls.sheet and ?write.xls (note the
'keep' argument!). I give you a short example at the end of the email.

>It doesn't seem to work if I use append = T

I am not aware of an issue. Please post (better email) your code. BTW
the 'append' argument is only meant for single operations (the whole
sheet will be re-read and rewritten each time).

A last thing, such specific xlsReadWrite(Pro) questions are not very
on topic for the the r-devel list. I don't know for sure, but I
strongly suspect that this is not be appreciated here. It is probably
better you just email me.

Cheers,
Hans-Peter

--------
(the example is with read, but write is analogue)

rfile <- "TestReadDataFile.xls"

cat( "### TEST: xls.open and xls.close\n" )
exc <- xls.open( rfile )
res1 <- read.xls( exc,, 1, from = 3, cols = 1 )[[1]]
  # switch to character sheet, check and read
xls.sheet( exc, "select", "characterSheet" )
  # switch to logical sheet, check and read
xls.sheet( exc, "select", "logicalSheet" )
res1 <- read.xls( exc, type = "logical", from = 3, cols = 1 )
xls.close( exc )

cat( "### TEST: keep\n" )
  # read first column from first sheet
res1 <- read.xls( rfile,, 1, from = 3, cols = 1, keep = TRUE )[[1]]
  # switch to character sheet, check and read
xls.sheet( rfile, "select", "characterSheet", keep = TRUE )
  # switch to logical sheet, check and read
xls.sheet( , "select", "logicalSheet", keep = TRUE )
  # with the next command the file will be closed (without saving)
res1 <- read.xls( , type = "logical", from = 3, cols = 1, keep = FALSE )


From gchappi at gmail.com  Mon Feb 12 11:07:51 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Mon, 12 Feb 2007 11:07:51 +0100
Subject: [Rd] newline with cell of Excel worksheet created with write.xls
In-Reply-To: <45CC201C.9060600@gmail.com>
References: <45CC201C.9060600@gmail.com>
Message-ID: <47fce0650702120207k39e014a9wd46a48b9fb698ae3@mail.gmail.com>

Hi Mark,

You need a character vector or a data.frame for separate rows. Something like:

longtext <- 'akdf kadf? \nkad flkd?flkadfk dafk \nlakdf
kdjfkjdfkjadfk\njadfkjdflk adf'
(rowtext <- as.data.frame( strsplit( longtext, split = "\n" )) )

may do this.

Regards,
Hans-Peter


PS: Probably not so appropriate for the R-devel list either...


2007/2/9, Mark W Kimpel <mwkimpel at gmail.com>:
> As part of my project to put different types of results into worksheets,
> I would like to be able to put an auto-generated methods section. If I
> compose in RWinEdt, read into R, and use write.table with a .txt file
> extension, what I get out has line-breaks that correspond to those I put
> in in the first place.
>
> If I do the same thing but write.xls with .xls extention, I get an Excel
>   worksheet with the entire paragraph on one line (row). It seems to me
> that Excel uses a special character for new-lines (new-rows). Is there a
> way that write.xls could convert \n to this special character?
>
> I'm  writing lots of posts on this, but trying to break up the subjects
> to create better threads.
>
> Mark
>
> --
> Mark W. Kimpel MD
> Neuroinformatics
> Department of Psychiatry
> Indiana University School of Medicine
>


From mwkimpel at gmail.com  Mon Feb 12 17:37:59 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Mon, 12 Feb 2007 11:37:59 -0500
Subject: [Rd] newline with cell of Excel worksheet created with write.xls
In-Reply-To: <47fce0650702120207k39e014a9wd46a48b9fb698ae3@mail.gmail.com>
References: <45CC201C.9060600@gmail.com>
	<47fce0650702120207k39e014a9wd46a48b9fb698ae3@mail.gmail.com>
Message-ID: <45D097E7.2000004@gmail.com>

Hans-Peter,

I agree, I wasn't sure whether to put this stuff on-list or not. I have 
seen some people request that things NOT be taken of list because then 
the answers are not available to everybody. Let's solve some of these 
issues ourselves (I am willing to help) and, if appropriate, repost the 
solutions or additional functionality to the list.

Mark

Hans-Peter wrote:
> Hi Mark,
> 
> You need a character vector or a data.frame for separate rows. Something 
> like:
> 
> longtext <- 'akdf kadf? \nkad flkd?flkadfk dafk \nlakdf
> kdjfkjdfkjadfk\njadfkjdflk adf'
> (rowtext <- as.data.frame( strsplit( longtext, split = "\n" )) )
> 
> may do this.
> 
> Regards,
> Hans-Peter
> 
> 
> PS: Probably not so appropriate for the R-devel list either...
> 
> 
> 2007/2/9, Mark W Kimpel <mwkimpel at gmail.com>:
>> As part of my project to put different types of results into worksheets,
>> I would like to be able to put an auto-generated methods section. If I
>> compose in RWinEdt, read into R, and use write.table with a .txt file
>> extension, what I get out has line-breaks that correspond to those I put
>> in in the first place.
>>
>> If I do the same thing but write.xls with .xls extention, I get an Excel
>>   worksheet with the entire paragraph on one line (row). It seems to me
>> that Excel uses a special character for new-lines (new-rows). Is there a
>> way that write.xls could convert \n to this special character?
>>
>> I'm  writing lots of posts on this, but trying to break up the subjects
>> to create better threads.
>>
>> Mark
>>
>> -- 
>> Mark W. Kimpel MD
>> Neuroinformatics
>> Department of Psychiatry
>> Indiana University School of Medicine
>>
> 

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From danielsuo at gmail.com  Mon Feb 12 21:32:39 2007
From: danielsuo at gmail.com (Daniel Suo)
Date: Mon, 12 Feb 2007 15:32:39 -0500
Subject: [Rd] Package build Vignette creation errors
Message-ID: <ae34ecbf0702121232u28ec2502qc27d8d5b95beb343@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070212/1534a55e/attachment.pl 

From p.murrell at auckland.ac.nz  Mon Feb 12 21:55:17 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 13 Feb 2007 09:55:17 +1300
Subject: [Rd] Graphics driver test script?
In-Reply-To: <7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>
References: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>
	<7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>
Message-ID: <45D0D435.6030509@stat.auckland.ac.nz>

Hi


Byron Ellis wrote:
> On 2/11/07, Geoff Russell <geoffrey.russell at gmail.com> wrote:
>> Hi,
>>
>> 1. I started work on a metapost graphics driver a week or so ago and it is
>> gradually taking shape. I'm building up my own test cases into a
>> script as I go, but
>> figured you may have a "canonical testing script" of cases a driver must handle?
>>
> 
> I typically use demo(graphics) for initial development and then things
> like example(plotmath) to make sure I'm getting font encoding working
> properly.
> 
>> 2. The clipping function looks like being a tricky problem. It seems
>> to me that the
>> callers of the driver assume that clipping affects all following calls
>> until the next
>> clipping call resets the clipping box.   With metapost, the clipping
>> function clips the
>> current graphics region and has no effect on following drawing functions.  I'm
>> not sure how to handle this --- the 2 models are very different.
>>
> 
> Sounds like you get to make a lot of clipping calls in metapost.


Yes, it may not be the most efficient approach, but one method would be
to keep track of the R's latest clipping region within your device
structure (just update it whenever R asks your device to set the clip
region, i.e., in MetaPost_Clip()) and enforce the current clip region
for each drawing call.

Paul


>> Cheers,
>> Geoff Russell
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From tplate at blackmesacapital.com  Mon Feb 12 22:56:51 2007
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 12 Feb 2007 14:56:51 -0700
Subject: [Rd] bug in partial matching of attribute names
Message-ID: <45D0E2A3.4020201@blackmesacapital.com>

There looks to be a bug in do_attr() (src/main/attrib.c): incorrect 
partial matches of attribute names can be returned when there are an odd 
number of partial matches.

E.g.:

 > x <- c(a=1,b=2)
 > attr(x, "abcdef") <- 99
 > attr(x, "ab")
[1] 99
 > attr(x, "abc") <- 100
 > attr(x, "ab") # correctly returns NULL because of ambig partial match
NULL
 > attr(x, "abcd") <- 101
 > attr(x, "ab") # incorrectly returns non-NULL for ambig partial match
[1] 101
 > names(attributes(x))
[1] "names"  "abcdef" "abc"    "abcd"
 >

The problem in do_attr() looks to be that after match is set to 
PARTIAL2, it can be set back to PARTIAL again.  I think a simple fix is 
to add a "break" in this block in do_attr():

     else if (match == PARTIAL) {
	/* this match is partial and we already have a partial match,
	   so the query is ambiguous and we return R_NilValue */
	match = PARTIAL2;
	break; /* <---- ADD BREAK HERE */
     } else {

However, if this is indeed a bug, would this be a good opportunity to 
get rid of partial matching on attribute names -- it was broken anyway 
-- so toss it out? :-)  Does anyone depend on partial matching for 
attribute names?  My view is that it's one of those things like partial 
matching of list and vector element names that seemed like a good idea 
at first, but turns out to be more trouble than it's worth.

On a related topic, partial matching does not seem to work for the 
"names" attribute (which I would regard as a good thing :-).  However, 
I'm puzzled why it doesn't work, because the code in do_attr() seems to 
try hard to make it work.  Can anybody explain why?

E.g.:
 > attr(x, "names")
[1] "a" "b"
 > attr(x, "nam")
NULL

 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"
 >

-- Tony Plate


From geoffrey.russell at gmail.com  Tue Feb 13 07:17:36 2007
From: geoffrey.russell at gmail.com (Geoff Russell)
Date: Tue, 13 Feb 2007 16:47:36 +1030
Subject: [Rd] Graphics driver test script?
In-Reply-To: <45D0D435.6030509@stat.auckland.ac.nz>
References: <93c3eada0702111337i349d3fb5v8cad9777bcbb2714@mail.gmail.com>
	<7098abec0702120008k71d67fe0r717fdf2557060aaf@mail.gmail.com>
	<45D0D435.6030509@stat.auckland.ac.nz>
Message-ID: <93c3eada0702122217i19fb6fc1s1eccbd468eaefb02@mail.gmail.com>

On 2/13/07, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
>
> Byron Ellis wrote:
> > On 2/11/07, Geoff Russell <geoffrey.russell at gmail.com> wrote:
> >> Hi,
> >>
> >> 1. I started work on a metapost graphics driver a week or so ago and it is
> >> gradually taking shape. I'm building up my own test cases into a
> >> script as I go, but
> >> figured you may have a "canonical testing script" of cases a driver must handle?
> >>
> >
> > I typically use demo(graphics) for initial development and then things
> > like example(plotmath) to make sure I'm getting font encoding working
> > properly.
> >
> >> 2. The clipping function looks like being a tricky problem. It seems
> >> to me that the
> >> callers of the driver assume that clipping affects all following calls
> >> until the next
> >> clipping call resets the clipping box.   With metapost, the clipping
> >> function clips the
> >> current graphics region and has no effect on following drawing functions.  I'm
> >> not sure how to handle this --- the 2 models are very different.
> >>
> >
> > Sounds like you get to make a lot of clipping calls in metapost.
>
>
> Yes, it may not be the most efficient approach, but one method would be
> to keep track of the R's latest clipping region within your device
> structure (just update it whenever R asks your device to set the clip
> region, i.e., in MetaPost_Clip()) and enforce the current clip region
> for each drawing call.

Yes, I can draw to a temp picture, then clip to the current clip region and
then add the temp picture to the current picture. Easy to do, but ugly.

I'll also checkout R clipping - thanks.

Cheers,
Geoff



>
> Paul
>
>
> >> Cheers,
> >> Geoff Russell
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
>


From ripley at stats.ox.ac.uk  Tue Feb 13 09:38:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Feb 2007 08:38:37 +0000 (GMT)
Subject: [Rd] bug in partial matching of attribute names
In-Reply-To: <45D0E2A3.4020201@blackmesacapital.com>
References: <45D0E2A3.4020201@blackmesacapital.com>
Message-ID: <Pine.LNX.4.64.0702130835100.10412@auk.stats>

It happens that I was looking at this yesterday (in connection with 
encodings on CHARSXPs) and have a fix in testing across CRAN right now.

As for "names", as you will know from reading 'R Internals' the names can 
be stored in more than one place, which is why it has to be treated 
specially.

On Mon, 12 Feb 2007, Tony Plate wrote:

> There looks to be a bug in do_attr() (src/main/attrib.c): incorrect
> partial matches of attribute names can be returned when there are an odd
> number of partial matches.
>
> E.g.:
>
> > x <- c(a=1,b=2)
> > attr(x, "abcdef") <- 99
> > attr(x, "ab")
> [1] 99
> > attr(x, "abc") <- 100
> > attr(x, "ab") # correctly returns NULL because of ambig partial match
> NULL
> > attr(x, "abcd") <- 101
> > attr(x, "ab") # incorrectly returns non-NULL for ambig partial match
> [1] 101
> > names(attributes(x))
> [1] "names"  "abcdef" "abc"    "abcd"
> >
>
> The problem in do_attr() looks to be that after match is set to
> PARTIAL2, it can be set back to PARTIAL again.  I think a simple fix is
> to add a "break" in this block in do_attr():
>
>     else if (match == PARTIAL) {
> 	/* this match is partial and we already have a partial match,
> 	   so the query is ambiguous and we return R_NilValue */
> 	match = PARTIAL2;
> 	break; /* <---- ADD BREAK HERE */
>     } else {
>
> However, if this is indeed a bug, would this be a good opportunity to
> get rid of partial matching on attribute names -- it was broken anyway
> -- so toss it out? :-)  Does anyone depend on partial matching for
> attribute names?  My view is that it's one of those things like partial
> matching of list and vector element names that seemed like a good idea
> at first, but turns out to be more trouble than it's worth.
>
> On a related topic, partial matching does not seem to work for the
> "names" attribute (which I would regard as a good thing :-).  However,
> I'm puzzled why it doesn't work, because the code in do_attr() seems to
> try hard to make it work.  Can anybody explain why?
>
> E.g.:
> > attr(x, "names")
> [1] "a" "b"
> > attr(x, "nam")
> NULL
>
> > sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> >
>
> -- Tony Plate
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From geoffrey.russell at gmail.com  Tue Feb 13 11:34:39 2007
From: geoffrey.russell at gmail.com (Geoff Russell)
Date: Tue, 13 Feb 2007 21:04:39 +1030
Subject: [Rd] Problems with metapost colors
Message-ID: <93c3eada0702130234w7f600b79ue415b8f8a2393bca@mail.gmail.com>

Hi all,

The developing metapost driver will handle the plots in
demo(graphics) putting the lines in the right places, and so on.

But the colors are ... to put it politely ... suboptimal :)

I can mail an Rplots.mp file to anybody who might be interested in suggesting
how I can handle colors. Its about 90kb compressed.

Currently, I just split the color into rgb components between 0 and 1 because
that's traditionally what metapost uses --- 3 components between 0 and 1. The
color wheel looks like a wheel, but some of the other plots come out badly.

Cheers,
Geoff Russell


From tplate at blackmesacapital.com  Tue Feb 13 19:34:18 2007
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 13 Feb 2007 11:34:18 -0700
Subject: [Rd] question on docs for delayedAssign and substitute
Message-ID: <45D204AA.8080106@blackmesacapital.com>

The help files for delayedAssign and substitute both say that 
substitute() can be used to see the expression associated with a 
promise.  However, I can't see how to do that.  When I try the example 
in help file for delayedAssign I don't see substitute() extracting the 
promise, e.g.:

 > msg <- "old"
 > delayedAssign("x", msg)
 > msg <- "new!"
 > substitute(x) #- I would expect to see 'msg' here
x
 > x #- new!
[1] "new!"
 > substitute(x)
x
 >

Has this functionality been removed, and the docs not updated?  Or am I 
missing something?

-- Tony Plate

 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
g.data
  "1.6"
 >


From murdoch at stats.uwo.ca  Tue Feb 13 21:11:03 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 13 Feb 2007 15:11:03 -0500
Subject: [Rd] question on docs for delayedAssign and substitute
In-Reply-To: <45D204AA.8080106@blackmesacapital.com>
References: <45D204AA.8080106@blackmesacapital.com>
Message-ID: <45D21B57.2050800@stats.uwo.ca>

On 2/13/2007 1:34 PM, Tony Plate wrote:
> The help files for delayedAssign and substitute both say that 
> substitute() can be used to see the expression associated with a 
> promise.  However, I can't see how to do that.  When I try the example 
> in help file for delayedAssign I don't see substitute() extracting the 
> promise, e.g.:
> 
>  > msg <- "old"
>  > delayedAssign("x", msg)
>  > msg <- "new!"
>  > substitute(x) #- I would expect to see 'msg' here
> x
>  > x #- new!
> [1] "new!"
>  > substitute(x)
> x
>  >
> 
> Has this functionality been removed, and the docs not updated?  Or am I 
> missing something?

This is a misfeature that has been around forever.  The substitute() 
function works differently when the env argument is the global 
environment than it does in general.

 > delayedAssign("x", 1+2)
 > substitute(x)
x
 > e <- new.env()
 > delayedAssign("x", 1+2, assign.env = e)
 > substitute(x, e)
1 + 2

The documentation for substitute() indicates this, but perhaps not 
entirely unambiguously.

Duncan Murdoch

> 
> -- Tony Plate
> 
>  > sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=English_United 
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> other attached packages:
> g.data
>   "1.6"
>  >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tplate at blackmesacapital.com  Wed Feb 14 01:12:12 2007
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 13 Feb 2007 17:12:12 -0700
Subject: [Rd] bug in partial matching of attribute names
In-Reply-To: <Pine.LNX.4.64.0702130835100.10412@auk.stats>
References: <45D0E2A3.4020201@blackmesacapital.com>
	<Pine.LNX.4.64.0702130835100.10412@auk.stats>
Message-ID: <45D253DC.1080501@blackmesacapital.com>

Ok, thanks for the news of a fix in progress.

On the topic of the "names" attribute being treated specially, I wonder 
if the do_attr() function might treat it a little too specially.  As far 
as I can tell, the loop in the first large block code in do_attr() 
(attrib.c), which begins

     /* try to find a match among the attributes list */
     for (alist = ATTRIB(s); alist != R_NilValue; alist = CDR(alist)) {

will find a full or partial match for a "names" attribute (at least for 
ordinary lists and vectors).

Then the large block of code after that, beginning:

     /* unless a full match has been found, check for a "names" attribute */
     if (match != FULL && ! strncmp(CHAR(PRINTNAME(R_NamesSymbol)), str, 
n)) {

seems unnecessary because a names attribute has already been checked 
for.  In the case of a partial match on the "names" attribute this code 
will behave as though there is an ambiguous partial match, and 
(incorrectly) return Nil.  Is this second block of code specific to the 
"names" attribute possibly a hangover from an earlier day when the first 
loop didn't detect a "names" attribute?  Or am I missing something?  Are 
there some other objects for which the first loop doesn't include a 
"names" attribute?

-- Tony Plate

Prof Brian Ripley wrote:
> It happens that I was looking at this yesterday (in connection with 
> encodings on CHARSXPs) and have a fix in testing across CRAN right now.
> 
> As for "names", as you will know from reading 'R Internals' the names 
> can be stored in more than one place, which is why it has to be treated 
> specially.
> 
> On Mon, 12 Feb 2007, Tony Plate wrote:
> 
>> There looks to be a bug in do_attr() (src/main/attrib.c): incorrect
>> partial matches of attribute names can be returned when there are an odd
>> number of partial matches.
>>
>> E.g.:
>>
>> > x <- c(a=1,b=2)
>> > attr(x, "abcdef") <- 99
>> > attr(x, "ab")
>> [1] 99
>> > attr(x, "abc") <- 100
>> > attr(x, "ab") # correctly returns NULL because of ambig partial match
>> NULL
>> > attr(x, "abcd") <- 101
>> > attr(x, "ab") # incorrectly returns non-NULL for ambig partial match
>> [1] 101
>> > names(attributes(x))
>> [1] "names"  "abcdef" "abc"    "abcd"
>> >
>>
>> The problem in do_attr() looks to be that after match is set to
>> PARTIAL2, it can be set back to PARTIAL again.  I think a simple fix is
>> to add a "break" in this block in do_attr():
>>
>>     else if (match == PARTIAL) {
>>     /* this match is partial and we already have a partial match,
>>        so the query is ambiguous and we return R_NilValue */
>>     match = PARTIAL2;
>>     break; /* <---- ADD BREAK HERE */
>>     } else {
>>
>> However, if this is indeed a bug, would this be a good opportunity to
>> get rid of partial matching on attribute names -- it was broken anyway
>> -- so toss it out? :-)  Does anyone depend on partial matching for
>> attribute names?  My view is that it's one of those things like partial
>> matching of list and vector element names that seemed like a good idea
>> at first, but turns out to be more trouble than it's worth.
>>
>> On a related topic, partial matching does not seem to work for the
>> "names" attribute (which I would regard as a good thing :-).  However,
>> I'm puzzled why it doesn't work, because the code in do_attr() seems to
>> try hard to make it work.  Can anybody explain why?
>>
>> E.g.:
>> > attr(x, "names")
>> [1] "a" "b"
>> > attr(x, "nam")
>> NULL
>>
>> > sessionInfo()
>> R version 2.4.1 (2006-12-18)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> States.1252;LC_MONETARY=English_United
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>> >
>>
>> -- Tony Plate
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From geoffrey.russell at gmail.com  Wed Feb 14 06:33:19 2007
From: geoffrey.russell at gmail.com (Geoff Russell)
Date: Wed, 14 Feb 2007 16:03:19 +1030
Subject: [Rd] How to upload metapost driver ?
Message-ID: <93c3eada0702132133h4722c546y957f829968ec83a6@mail.gmail.com>

Hi all,

To develop the metapost driver, I did an svn checkout (R-2-4-branch
revision 40647)
as instructed in

http://developer.r-project.org/SVNtips.html

i.e., I did a,

       svn co $REPOS/branches/R-2-4-branch r-release-branch/R

Not being a core developer, can I just commit the changes?  Am I
on the right branch?

Most of the work is in devPS.c, but there are also some
documentation changes (e.g, Devices.Rd).

Cheers
Geoff Russell

P.S. The driver isn't quite finished but I thought I'd ask now, in case I was
working on the wrong branch!


From ripley at stats.ox.ac.uk  Wed Feb 14 07:16:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Feb 2007 06:16:10 +0000 (GMT)
Subject: [Rd] bug in partial matching of attribute names
In-Reply-To: <45D253DC.1080501@blackmesacapital.com>
References: <45D0E2A3.4020201@blackmesacapital.com>
	<Pine.LNX.4.64.0702130835100.10412@auk.stats>
	<45D253DC.1080501@blackmesacapital.com>
Message-ID: <Pine.LNX.4.64.0702140611440.6666@gannet.stats.ox.ac.uk>

On Tue, 13 Feb 2007, Tony Plate wrote:

> Ok, thanks for the news of a fix in progress.

BTW, your suggested fix is incorrect.  Consider having an exact match 
after two partial matches in the list of attributes.

> On the topic of the "names" attribute being treated specially, I wonder if 
> the do_attr() function might treat it a little too specially.  As far as I 
> can tell, the loop in the first large block code in do_attr() (attrib.c), 
> which begins
>
>    /* try to find a match among the attributes list */
>    for (alist = ATTRIB(s); alist != R_NilValue; alist = CDR(alist)) {
>
> will find a full or partial match for a "names" attribute (at least for 
> ordinary lists and vectors).
>
> Then the large block of code after that, beginning:
>
>    /* unless a full match has been found, check for a "names" attribute */
>    if (match != FULL && ! strncmp(CHAR(PRINTNAME(R_NamesSymbol)), str, n)) 
> {
>
> seems unnecessary because a names attribute has already been checked for. 
> In the case of a partial match on the "names" attribute this code will 
> behave as though there is an ambiguous partial match, and (incorrectly) 
> return Nil.  Is this second block of code specific to the "names" attribute 
> possibly a hangover from an earlier day when the first loop didn't detect a 
> "names" attribute?  Or am I missing something?  Are there some other objects 
> for which the first loop doesn't include a "names" attribute?

Yes: I pointed you at the 'R internals' manual, but this is also on the 
help page.  1D arrays and pairlists have names stored elsewhere.  It needs 
to be changed to be

-       else if (match == PARTIAL) {
+       else if (match == PARTIAL && strcmp(CHAR(PRINTNAME(tag)), "names")) {


> -- Tony Plate
>
> Prof Brian Ripley wrote:
>> It happens that I was looking at this yesterday (in connection with 
>> encodings on CHARSXPs) and have a fix in testing across CRAN right now.
>> 
>> As for "names", as you will know from reading 'R Internals' the names can 
>> be stored in more than one place, which is why it has to be treated 
>> specially.
>> 
>> On Mon, 12 Feb 2007, Tony Plate wrote:
>> 
>>> There looks to be a bug in do_attr() (src/main/attrib.c): incorrect
>>> partial matches of attribute names can be returned when there are an odd
>>> number of partial matches.
>>> 
>>> E.g.:
>>> 
>>> > x <- c(a=1,b=2)
>>> > attr(x, "abcdef") <- 99
>>> > attr(x, "ab")
>>> [1] 99
>>> > attr(x, "abc") <- 100
>>> > attr(x, "ab") # correctly returns NULL because of ambig partial match
>>> NULL
>>> > attr(x, "abcd") <- 101
>>> > attr(x, "ab") # incorrectly returns non-NULL for ambig partial match
>>> [1] 101
>>> > names(attributes(x))
>>> [1] "names"  "abcdef" "abc"    "abcd"
>>> >
>>> 
>>> The problem in do_attr() looks to be that after match is set to
>>> PARTIAL2, it can be set back to PARTIAL again.  I think a simple fix is
>>> to add a "break" in this block in do_attr():
>>>
>>>     else if (match == PARTIAL) {
>>>     /* this match is partial and we already have a partial match,
>>>        so the query is ambiguous and we return R_NilValue */
>>>     match = PARTIAL2;
>>>     break; /* <---- ADD BREAK HERE */
>>>     } else {
>>> 
>>> However, if this is indeed a bug, would this be a good opportunity to
>>> get rid of partial matching on attribute names -- it was broken anyway
>>> -- so toss it out? :-)  Does anyone depend on partial matching for
>>> attribute names?  My view is that it's one of those things like partial
>>> matching of list and vector element names that seemed like a good idea
>>> at first, but turns out to be more trouble than it's worth.
>>> 
>>> On a related topic, partial matching does not seem to work for the
>>> "names" attribute (which I would regard as a good thing :-).  However,
>>> I'm puzzled why it doesn't work, because the code in do_attr() seems to
>>> try hard to make it work.  Can anybody explain why?
>>> 
>>> E.g.:
>>> > attr(x, "names")
>>> [1] "a" "b"
>>> > attr(x, "nam")
>>> NULL
>>> 
>>> > sessionInfo()
>>> R version 2.4.1 (2006-12-18)
>>> i386-pc-mingw32
>>> 
>>> locale:
>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> States.1252;LC_MONETARY=English_United
>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>>> [7] "base"
>>> >
>>> 
>>> -- Tony Plate
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Feb 14 07:21:25 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Feb 2007 06:21:25 +0000 (GMT)
Subject: [Rd] How to upload metapost driver ?
In-Reply-To: <93c3eada0702132133h4722c546y957f829968ec83a6@mail.gmail.com>
References: <93c3eada0702132133h4722c546y957f829968ec83a6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702140616280.6666@gannet.stats.ox.ac.uk>

It is best to prepare a package with your work, as other authors of 
graphics devices have done.

Only work maintained by the core developers goes into the main source, and 
we don't have an metapost gurus to maintain it, AFAIK.

On Wed, 14 Feb 2007, Geoff Russell wrote:

> Hi all,
>
> To develop the metapost driver, I did an svn checkout (R-2-4-branch
> revision 40647)
> as instructed in
>
> http://developer.r-project.org/SVNtips.html
>
> i.e., I did a,
>
>       svn co $REPOS/branches/R-2-4-branch r-release-branch/R
>
> Not being a core developer, can I just commit the changes?  Am I
> on the right branch?

Not for developing R itself, but you are not doing that.  All new material 
goes into the trunk, and patches are then transferred to the active 
R-patched branch.

> Most of the work is in devPS.c, but there are also some
> documentation changes (e.g, Devices.Rd).
>
> Cheers
> Geoff Russell
>
> P.S. The driver isn't quite finished but I thought I'd ask now, in case I was
> working on the wrong branch!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From whit.armstrong at hcmny.com  Wed Feb 14 15:14:13 2007
From: whit.armstrong at hcmny.com (Armstrong, Whit)
Date: Wed, 14 Feb 2007 09:14:13 -0500
Subject: [Rd] make check failure: lapack.Rout.fail
Message-ID: <E58BE6136618CF4C964F6EC7773AE569F57170@ex4.nyc.hcmny.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070214/c3faeea9/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Feb 14 16:14:17 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Feb 2007 15:14:17 +0000 (GMT)
Subject: [Rd] make check failure: lapack.Rout.fail
In-Reply-To: <E58BE6136618CF4C964F6EC7773AE569F57170@ex4.nyc.hcmny.com>
References: <E58BE6136618CF4C964F6EC7773AE569F57170@ex4.nyc.hcmny.com>
Message-ID: <Pine.LNX.4.64.0702141510530.31751@gannet.stats.ox.ac.uk>

On Wed, 14 Feb 2007, Armstrong, Whit wrote:

> I see that the comment in the lapack test indicates that developers are
> aware of this issue.
>
> Are there any known fixes to this problem?  compiler flags, etc.
>
> an upgrade to a more recent gcc is not an option for me.

Well, R-devel has an updated LAPACK so you could try that.
But the real problem is the 2003 compiler, from well before x86_64 Linux 
was stable and the known fix is to use a less ancient g77.

>
> this occurred while doing make check-all on R-patched_2007-02-11.tar.gz
>
> with the following:
>
> RHEL3 on x86_64
> gcc (GCC) 3.2.3 20030502 (Red Hat Linux 3.2.3-47)
> GNU Fortran (GCC 3.2.3 20030502 (Red Hat Linux 3.2.3-47)) 3.2.3 20030502
> (Red Hat Linux 3.2.3-47)
>
> code snip:
>
>> ## failed for some 64bit-Lapack-gcc combinations:
>> sm <- cbind(1, 3:1, 1:3)
>> eigenok(sm, eigen(sm))
> Error: abs(A %*% V - V %*% diag(lam)) < Eps is not all TRUE
> Execution halted
>
>
> Thanks in advance,
> Whit
>
>
>
>
>
> This e-mail message is intended only for the named recipient(s) above. It may contain confidential information. If you are not the intended recipient you are hereby notified that any dissemination, distribution or copying of this e-mail and any attachment(s) is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender by replying to this e-mail and delete the message and any attachment(s) from your system. Thank you.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tplate at blackmesacapital.com  Wed Feb 14 16:57:01 2007
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 14 Feb 2007 08:57:01 -0700
Subject: [Rd] bug in partial matching of attribute names
In-Reply-To: <Pine.LNX.4.64.0702140611440.6666@gannet.stats.ox.ac.uk>
References: <45D0E2A3.4020201@blackmesacapital.com>
	<Pine.LNX.4.64.0702130835100.10412@auk.stats>
	<45D253DC.1080501@blackmesacapital.com>
	<Pine.LNX.4.64.0702140611440.6666@gannet.stats.ox.ac.uk>
Message-ID: <45D3314D.2000302@blackmesacapital.com>

Prof Brian Ripley wrote:
> On Tue, 13 Feb 2007, Tony Plate wrote:
> 
>> Ok, thanks for the news of a fix in progress.
> 
> 
> BTW, your suggested fix is incorrect.  Consider having an exact match 
> after two partial matches in the list of attributes.
oops.  yes.

> 
>> On the topic of the "names" attribute being treated specially, I 
>> wonder if the do_attr() function might treat it a little too 
>> specially.  As far as I can tell, the loop in the first large block 
>> code in do_attr() (attrib.c), which begins
>>
>>    /* try to find a match among the attributes list */
>>    for (alist = ATTRIB(s); alist != R_NilValue; alist = CDR(alist)) {
>>
>> will find a full or partial match for a "names" attribute (at least 
>> for ordinary lists and vectors).
>>
>> Then the large block of code after that, beginning:
>>
>>    /* unless a full match has been found, check for a "names" 
>> attribute */
>>    if (match != FULL && ! strncmp(CHAR(PRINTNAME(R_NamesSymbol)), str, 
>> n)) {
>>
>> seems unnecessary because a names attribute has already been checked 
>> for. In the case of a partial match on the "names" attribute this code 
>> will behave as though there is an ambiguous partial match, and 
>> (incorrectly) return Nil.  Is this second block of code specific to 
>> the "names" attribute possibly a hangover from an earlier day when the 
>> first loop didn't detect a "names" attribute?  Or am I missing 
>> something?  Are there some other objects for which the first loop 
>> doesn't include a "names" attribute?
> 
> 
> Yes: I pointed you at the 'R internals' manual, but this is also on the 
> help page.  1D arrays and pairlists have names stored elsewhere.  It 
> needs to be changed to be
> 
> -       else if (match == PARTIAL) {
> +       else if (match == PARTIAL && strcmp(CHAR(PRINTNAME(tag)), 
> "names")) {

Wouldn't it be equivalent (but clearer & a minute fraction more 
computationally efficient) to put that test 
'strcmp(CHAR(PRINTNAME(tag)), "names")' right at the start of that 
block, i.e., as an additional condition in

     if (match != FULL && ! strncmp(CHAR(PRINTNAME(R_NamesSymbol)), str, 
n)) {

?

-- Tony Plate

> 
> 
>> -- Tony Plate
>>
>> Prof Brian Ripley wrote:
>>
>>> It happens that I was looking at this yesterday (in connection with 
>>> encodings on CHARSXPs) and have a fix in testing across CRAN right now.
>>>
>>> As for "names", as you will know from reading 'R Internals' the names 
>>> can be stored in more than one place, which is why it has to be 
>>> treated specially.
>>>
>>> On Mon, 12 Feb 2007, Tony Plate wrote:
>>>
>>>> There looks to be a bug in do_attr() (src/main/attrib.c): incorrect
>>>> partial matches of attribute names can be returned when there are an 
>>>> odd
>>>> number of partial matches.
>>>>
>>>> E.g.:
>>>>
>>>> > x <- c(a=1,b=2)
>>>> > attr(x, "abcdef") <- 99
>>>> > attr(x, "ab")
>>>> [1] 99
>>>> > attr(x, "abc") <- 100
>>>> > attr(x, "ab") # correctly returns NULL because of ambig partial match
>>>> NULL
>>>> > attr(x, "abcd") <- 101
>>>> > attr(x, "ab") # incorrectly returns non-NULL for ambig partial match
>>>> [1] 101
>>>> > names(attributes(x))
>>>> [1] "names"  "abcdef" "abc"    "abcd"
>>>> >
>>>>
>>>> The problem in do_attr() looks to be that after match is set to
>>>> PARTIAL2, it can be set back to PARTIAL again.  I think a simple fix is
>>>> to add a "break" in this block in do_attr():
>>>>
>>>>     else if (match == PARTIAL) {
>>>>     /* this match is partial and we already have a partial match,
>>>>        so the query is ambiguous and we return R_NilValue */
>>>>     match = PARTIAL2;
>>>>     break; /* <---- ADD BREAK HERE */
>>>>     } else {
>>>>
>>>> However, if this is indeed a bug, would this be a good opportunity to
>>>> get rid of partial matching on attribute names -- it was broken anyway
>>>> -- so toss it out? :-)  Does anyone depend on partial matching for
>>>> attribute names?  My view is that it's one of those things like partial
>>>> matching of list and vector element names that seemed like a good idea
>>>> at first, but turns out to be more trouble than it's worth.
>>>>
>>>> On a related topic, partial matching does not seem to work for the
>>>> "names" attribute (which I would regard as a good thing :-).  However,
>>>> I'm puzzled why it doesn't work, because the code in do_attr() seems to
>>>> try hard to make it work.  Can anybody explain why?
>>>>
>>>> E.g.:
>>>> > attr(x, "names")
>>>> [1] "a" "b"
>>>> > attr(x, "nam")
>>>> NULL
>>>>
>>>> > sessionInfo()
>>>> R version 2.4.1 (2006-12-18)
>>>> i386-pc-mingw32
>>>>
>>>> locale:
>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>> States.1252;LC_MONETARY=English_United
>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  
>>>> "methods"
>>>> [7] "base"
>>>> >
>>>>
>>>> -- Tony Plate
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>


From bolker at zoo.ufl.edu  Wed Feb 14 23:23:18 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 14 Feb 2007 17:23:18 -0500
Subject: [Rd] environment confusion
Message-ID: <45D38BD6.2010700@zoo.ufl.edu>


  I'm in a bit beyond my depth with environments and such.

  The environment of a particular function, which I've set
so it should have the things it needs, seems to be getting
"lost" at some point during a call sequence.
   It's hard to come up with a _simple_ reproducible
example, although if anyone's sufficiently interested I
can post the package somewhere -- with the package installed,
it's only a few steps to reproduce the example.

  I end up, deep in the process of trying to compute
a likelihood profile, with the following situation:
I want to evaluate "call":

call

mle2(minuslogl = function (lmu = NULL, ltheta = NULL)
{
    if (!is.null(parameters)) {
        pars <- unlist(as.list(match.call())[-1])
        for (i in seq(along = parameters)) {
            assign(vars[i], mmats[[i]] %*% pars[vpos[[i]]])
        }
    }
    arglist1 <- lapply(arglist1, eval, envir = data, enclos =
sys.frame(sys.nframe()))
    r <- -sum(do.call(ddistn, arglist1))
    r
}, start = list(lmu = -2.16316747342067, ltheta = 2.30970721353114),
    fixed = list(lmu = -2.18543734742826))

  The function appears to have the right stuff in its
environment:

Browse[1]> ls(envir=environment(call$minuslogl))
[1] "arglist1" "ddistn"   "mmats"    "vars"     "vpos"

   But evaluating the call, even with the environment
set to the environment of the internal function, doesn't
seem to work

Browse[1]> eval(call,envir=environment(call$minuslogl))
Error during wrapup: object "arglist1" not found

  The full stack looks like this:

> profile(m0f,skiperrs=FALSE)
Error in is.vector(X) : object "arglist1" not found

Enter a frame number, or 0 to exit

 1: profile(m0f, skiperrs = FALSE)
 2: profile(m0f, skiperrs = FALSE)
 3: .local(fitted, ...)
 4: onestep(step)
 5: eval.parent(call, 2)
 6: eval(expr, p)
 7: eval(expr, envir, enclos)
 8: mle2(minuslogl = function (lmu = NULL, ltheta = NULL)
 9: optim(start, objectivefunction, method = method, hessian = TRUE, ...)
10: function (par)
11: fn(par, ...)
12: do.call("minuslogl", args, envir = environment(minuslogl))
13: minuslogl(ltheta = 2.30970721353114, lmu = -2.18543734742826)
14: lapply(arglist1, eval, envir = data, enclos = sys.frame(sys.nframe()))
15: is.vector(X)

Selection:

  Anyone have any ideas/directions/leading questions?

  cheers
    Ben Bolker



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 254 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070214/4e178bd4/attachment.bin 

From eairoldi at Princeton.EDU  Wed Feb 14 23:51:50 2007
From: eairoldi at Princeton.EDU (Edo Airoldi)
Date: Wed, 14 Feb 2007 17:51:50 -0500
Subject: [Rd] Problem with the 'hist' function
Message-ID: <7B7F2C3E-07D7-44ED-A7E7-06E97CCB702E@princeton.edu>

Hi, I am using the following R version:

 > R version 2.4.1 (2006-12-18)
 > Copyright (C) 2006 The R Foundation for Statistical Computing
 > ISBN 3-900051-07-0

  I believe I found a bug in the 'hist' function, when  
'probability=TRUE'. I looked in the archives and I came across  
problems with the 'hist' functions (e.g., bug PR# 944, posted in  
2001), however, a quick search did not find the exact problem I a  
found. A brief description of the issue follows.

 > z<-rnorm(10)
 > z
[1]  0.51649608 -0.20676010  0.65951365  0.46733006  0.02084361   
0.18323525
[7] -0.21522566  0.29597667  0.81549448  0.26252625
 > hist(z,breaks=seq(-1,1,by=.25))
 > hist(z,breaks=seq(-1,1,by=.25),probability=TRUE)

  I think the values on the Y axis are messed up, e.g., it should top  
at 0.3 (relative frequency) for the bin [0.25 0.50). How is 'Density'  
computed?

best regards,
Edo


-------------------------------------------------
  Edo Airoldi, Ph.D.

  Department of Computer Science  &
  Lewis-Sigler Institute for Integrative Genomics
  Princeton University, NJ 08544

  609-258-8326 (lab phone)  609-258-8004 (fax)


From murdoch at stats.uwo.ca  Thu Feb 15 00:14:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 14 Feb 2007 18:14:27 -0500
Subject: [Rd] Problem with the 'hist' function
In-Reply-To: <7B7F2C3E-07D7-44ED-A7E7-06E97CCB702E@princeton.edu>
References: <7B7F2C3E-07D7-44ED-A7E7-06E97CCB702E@princeton.edu>
Message-ID: <45D397D3.3020602@stats.uwo.ca>

On 2/14/2007 5:51 PM, Edo Airoldi wrote:
> Hi, I am using the following R version:
> 
>  > R version 2.4.1 (2006-12-18)
>  > Copyright (C) 2006 The R Foundation for Statistical Computing
>  > ISBN 3-900051-07-0
> 
>   I believe I found a bug in the 'hist' function, when  
> 'probability=TRUE'. I looked in the archives and I came across  
> problems with the 'hist' functions (e.g., bug PR# 944, posted in  
> 2001), however, a quick search did not find the exact problem I a  
> found. A brief description of the issue follows.
> 
>  > z<-rnorm(10)
>  > z
> [1]  0.51649608 -0.20676010  0.65951365  0.46733006  0.02084361   
> 0.18323525
> [7] -0.21522566  0.29597667  0.81549448  0.26252625
>  > hist(z,breaks=seq(-1,1,by=.25))
>  > hist(z,breaks=seq(-1,1,by=.25),probability=TRUE)
> 
>   I think the values on the Y axis are messed up, e.g., it should top  
> at 0.3 (relative frequency) for the bin [0.25 0.50). How is 'Density'  
> computed?

It's not relative frequency, it's density:  relative frequency per unit 
of x.  The upper limit would be 4 with a step size of 0.25 (if all the 
observations fell in one interval).

Duncan Murdoch


From gchappi at gmail.com  Thu Feb 15 01:39:48 2007
From: gchappi at gmail.com (Hans-Peter)
Date: Thu, 15 Feb 2007 01:39:48 +0100
Subject: [Rd] xlsReadWrite Pro and embedding objects and files in Excel
	worksheets
In-Reply-To: <47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>
References: <45CACDD2.9060007@gmail.com>
	<47fce0650702111559y4486346k553a2b4604b4ba68@mail.gmail.com>
Message-ID: <47fce0650702141639g5bee27fex6ebae3395f6b25b1@mail.gmail.com>

Hi Mark et al.

2007/2/12, Hans-Peter <gchappi at gmail.com>:
> Yes, but I started with the update of the free version and got delayed
> there (not that I didn't know that paying customers should be
> prefered...) - I'll update the pro version right now and you should
> have it until Wednesday, maybe tomorrow. Another person asked to write
> formulas directly, it will be included also.

I have now uploaded the new version 1.1.0 which runs all my tests
fine. It will be publicly linked at the website as soon as the free
version is also ready and after some more testing and beautifying of
the help text.

Downloads:
- Program: http://treetron.googlepages.com/xlsReadWritePro_1.1.0.zip
- Testscripts (e.g. formula and link):
http://treetron.googlepages.com/xlsReadWritePro_TestData_1.1.0.zip
- Update-msg pro:
http://treetron.googlepages.com/UpdateMsg_xlsReadWritePro_1.1.0.txt
- Update-msg free version:
http://treetron.googlepages.com/UpdateMsg_xlsReadWrite_1.3.0.txt
(draft, I have to finish some details)

Regards,
Hans-Peter


PS: I bcc the email to some people who made suggestions. Unfortunately
the update of the free version took longer as planned. I have to be
more prudent with giving time indications...


From sebastiendurand at videotron.ca  Thu Feb 15 16:47:17 2007
From: sebastiendurand at videotron.ca (Sebastien Durand)
Date: Thu, 15 Feb 2007 10:47:17 -0500
Subject: [Rd] Graphical device questions!
Message-ID: <p0623090ec1fa30db55f3@[192.168.2.3]>

Dear all,

I have posted these questions in r-help list but 
since I am getting no reply, I concluded that I 
must asked my question in the wrong list so here 
I am!

Here is my questions:

1- Under a WINDOWS installation of R-2.4.1,  can 
we change the naming of a new ploting device open 
by the command "windows()"?. Instead of the 
default name e.g.: "Device 2" I would like to use 
something like "Density plot" or whatever!


2- Under a MAC OS X installation of R-2.4.1, 
using quartz devices, is there a way to perform 
bringToTop operation like the one available under 
WINDOWS using bringToTop function.

Thank you very much for your time.

Cheers

S?bastien

-- 
Dans le Ssu Ma Fa on lit: "Celui qui place la vie 
au dessus de toute chose sera paralys? par 
l'irr?solution"


From murdoch at stats.uwo.ca  Thu Feb 15 17:27:11 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 15 Feb 2007 11:27:11 -0500
Subject: [Rd] Graphical device questions!
In-Reply-To: <p0623090ec1fa30db55f3@[192.168.2.3]>
References: <p0623090ec1fa30db55f3@[192.168.2.3]>
Message-ID: <45D489DF.4090008@stats.uwo.ca>

On 2/15/2007 10:47 AM, Sebastien Durand wrote:
> Dear all,
> 
> I have posted these questions in r-help list but 
> since I am getting no reply, I concluded that I 
> must asked my question in the wrong list so here 
> I am!

I think you asked in the right place last time, but nobody knew the 
answer.
> 
> Here is my questions:
> 
> 1- Under a WINDOWS installation of R-2.4.1,  can 
> we change the naming of a new ploting device open 
> by the command "windows()"?. Instead of the 
> default name e.g.: "Device 2" I would like to use 
> something like "Density plot" or whatever!

No, there's no facility to allow you to do that.
> 
> 
> 2- Under a MAC OS X installation of R-2.4.1, 
> using quartz devices, is there a way to perform 
> bringToTop operation like the one available under 
> WINDOWS using bringToTop function.

That name only is only used in Win32 builds.  There might be similar 
functionality available in OSX or X11 under a different name.

Duncan Murdoch

> 
> Thank you very much for your time.
> 
> Cheers
> 
> S?bastien
>


From ivo_welch at brown.edu  Thu Feb 15 17:56:13 2007
From: ivo_welch at brown.edu (ivo welch)
Date: Thu, 15 Feb 2007 11:56:13 -0500
Subject: [Rd] error messages with dimension mismatch?
Message-ID: <45D490AD.1060602@brown.edu>


dear R developers:

may I suggest that you add to the various error messages that relate to
"non-conformable arguments" (e.g. matrix multiplication) or "not
multiple of"(e.g., comparison) the actual two dimension numbers that do
not match up?  something like

    Error in t(a) %*% vcov(reg.model) : non-conformable arguments
to
   Error in t(a) %*% vcov(reg.model) : non-conformable arguments (0, 5)

regards,

/ivo


From sebastiendurand at videotron.ca  Thu Feb 15 17:59:32 2007
From: sebastiendurand at videotron.ca (Sebastien Durand)
Date: Thu, 15 Feb 2007 11:59:32 -0500
Subject: [Rd] Graphical device questions!
In-Reply-To: <45D489DF.4090008@stats.uwo.ca>
References: <p0623090ec1fa30db55f3@[192.168.2.3]>
	<45D489DF.4090008@stats.uwo.ca>
Message-ID: <p06230910c1fa40bf0ff4@[192.168.2.3]>

Dear all,

Does anybody know of any function such as 
bringToTop windows function but under Mac OS X...

I looked and I could not find any...

Cheers...

S?bastien

>On 2/15/2007 10:47 AM, Sebastien Durand wrote:
>>Dear all,
>>
>>I have posted these questions in r-help list 
>>but since I am getting no reply, I concluded 
>>that I must asked my question in the wrong list 
>>so here I am!
>
>I think you asked in the right place last time, but nobody knew the answer.
>>
>>Here is my questions:
>>
>>1- Under a WINDOWS installation of R-2.4.1, 
>>can we change the naming of a new ploting 
>>device open by the command "windows()"?. 
>>Instead of the default name e.g.: "Device 2" I 
>>would like to use something like "Density plot" 
>>or whatever!
>
>No, there's no facility to allow you to do that.
>>
>>
>>2- Under a MAC OS X installation of R-2.4.1, 
>>using quartz devices, is there a way to perform 
>>bringToTop operation like the one available 
>>under WINDOWS using bringToTop function.
>
>That name only is only used in Win32 builds. 
>There might be similar functionality available 
>in OSX or X11 under a different name.
>
>Duncan Murdoch
>
>>
>>Thank you very much for your time.
>>
>>Cheers
>>
>>S?bastien


-- 
Dans le Ssu Ma Fa on lit: "Celui qui place la vie 
au dessus de toute chose sera paralys? par 
l'irr?solution"


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Feb 15 21:10:41 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 15 Feb 2007 21:10:41 +0100
Subject: [Rd] Encoding API
Message-ID: <200702152110.45670.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Hi!

I've been observing the recent SVN log entries about encoding information in 
CHARSXPs with great interest. This looks like a very nice addition. While 
this is still work in progress, I'd like to suggest the following extra:

At least in RKWard, all shown strings need to be converted to UTF-8 (the 
internal storage format used in Qt QStrings). This needs to be done 
independent of the current locale, and the encoding used in the embedded R 
process. I imagine other graphical or non-graphical toolkits will similarly 
use UTF-8 to store strings, internally.

For this reason, an addition of e.g.

char* Rf_translateCharToUTF8(SEXP);

would be nice. This function would translate to UTF-8 independently of the 
current LC_CTYPE. While it is possible to achieve the same effect by first 
translating the strings to the current LC_CTYPE encoding (using 
Rf_translateChar()), and then translate to UTF-8 in a second step (using 
custom means, if needed), being able to do this conversion in a single step 
would be more elegant, and also potentially avoid expensive recoding steps.

Alternatively, having access to the IS_UTF8 and IS_LATIN1 macros from C would 
be good enough to hand-code efficient conversion to UTF-8 (but may be too 
close to the internals).

Not sure, whether this is considered important enough to warant inclusion in 
the API, but I just wanted to throw in the idea in time.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070215/9f70fc9c/attachment.bin 

From ripley at stats.ox.ac.uk  Fri Feb 16 08:26:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Feb 2007 07:26:32 +0000 (GMT)
Subject: [Rd] R-devel news: non-ASCII character strings in packages
Message-ID: <Pine.LNX.4.64.0702160659190.15614@gannet.stats.ox.ac.uk>

R-devel (pre-2.5.0) now has enough facilities to allow packages with 
non-ASCII character strings to work reasonably well in locales where the 
fonts use support the characters used.  For example, names in Western 
European languages can be used on both Latin-1 (and hence Windows 1252) 
and UTF-8 systems.  It should also be possible to make use of non-ASCII 
object names.

To enable this, two things need to be done.

1) The package encoding needs to be declared in the DESCRIPTION file.
2) Any character strings stored in .rda files need to be marked as Latin-1 
or UTF-8 (see 'Writing R Extensions' for how to do so).

R CMD check will give NOTE or WARNING messages when it detects non-ASCII 
characters.

Please do bear in mind the caveat in the first paragraph: it is very 
unlikely that using French in a Chinese locale or v.v. will work correctly 
(even on a UTF-8 system).

The changes needed are backwards compatible: if you make them to your 
package, it will work equally well (or badly) in R < 2.5.0, and better in 
2.5.0 when released.

Currently one CRAN package has non-ASCII object names and fifteen have 
non-ASCII data (as detected by R CMD check).

Note that non-ASCII data need not be from non-English languages: Windows 
1252 in particular has a variety of signs that are far from portable, most 
notably its misnamed 'smart quotes' (but also the Euro).

Finally, please do not add Encoding: to the DESCRIPTION of ASCII-only 
packages.  It just slows things down and (unless latin1 is specified) 
restricts the package to only systems supporting iconv.  (Yes, there are 
examples of this.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Fri Feb 16 15:35:35 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Feb 2007 09:35:35 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
Message-ID: <971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>

I mentioned this twice already and no one answered;however, I am mentioning
this a third time since its a serious deficiency.   The Rscript facility
that is upcoming in R is useful but on Windows one will often be relegated
to having two files: a batch file and an R file unless the -x switch
is implemented
to allow them to be combined.  This is not a problem on UNIX which supports
#! but on Windows we need -x.  Every other common scripting language including
perl, python and ruby supports -x for this purpose.

(The -x flag would start R processing at the first line that begins with #! so
that prior lines could be Windows batch commands allowing the same file
to be used as a batch file and an R file.)

Note that there is a bug in Windows which means that if you simply associate
.R to running R then the result cannot be redirected.  There is a bug
fix available
for this but I think we need to be able to run out of the box for something this
common.


On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Haven't got any feedback on this one.
>
> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
>
> It certainly would give more flexibility to users of Rscript on non-UNIX systems
> where #! notation is not available.
>
> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Good idea.  ruby seems to work the same way.  python does too but with
> > a slightly different definition:
> >
> > C:\> ruby -h | findstr strip
> >  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
> >
> > C:\> perl -h | findstr strip
> >  -x[directory]   strip off text before #!perl line and perhaps cd to directory
> >
> > C:\> python -h | findstr skip
> > -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
> >
> >
> > On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> > >
> > > ActivePerl has '-x' switch which tells it to skip all lines in the file till
> > > "#!".
> > > This allows writing perl scripts in ordinary .bat files.
> > >
> > > ?shQuote contains a link with the following perl script example:
> > > ===8<===
> > > @echo off
> > > :: hello.bat
> > > :: Windows executable Perl script
> > > :: Note:
> > > ::   assumes perl.exe is in path
> > > ::   otherwise, use absolute path
> > > perl -x -S "%0" %*
> > > goto end
> > > #!perl
> > >
> > > print "Hello, World!\n";
> > > __END__
> > > :end
> > > :: ------ end of hello.bat ------
> > >
> > > Windows Notes:
> > > " -x " (lower case x): Skip all text until shebang line.
> > > " -S " (upper case S): Look for script using PATH variable. Special meaning
> > > in Windows: appends .bat or .cmd if lookup for name fails and name does not
> > > have either suffix.
> > > " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
> > > ===8<===
> > >
> > > I think the simplest way to implement shebang on windows would be embedding
> > > one more command line switch with similar functionality to perl's '-x'.
> > >
> > > --
> > > View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
> > > Sent from the R devel mailing list archive at Nabble.com.
> > >
>


From ripley at stats.ox.ac.uk  Fri Feb 16 16:56:45 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Feb 2007 15:56:45 +0000 (GMT)
Subject: [Rd] Requiring iconv
Message-ID: <Pine.LNX.4.64.0702161318380.25336@auk.stats>

Sooner or later we are going to have to require iconv for fully functional 
R installations.

The only systems we are aware of that do not come with a suitable iconv 
(with support for Unicode charsets like UTF-8) are some older commercial 
Unixen, and GNU libiconv works on those we know of.

Does anyone have a system for which R's configure does not find a working 
iconv and on which they could not install GNU libiconv?  I am 
contemplating that 2.5.0 would need to be explicitly configured with 
--without-iconv to allow it to be built on such a system, and that 'make 
check' would not then work. (An alternative would be to bundle libiconv 
with R, but it is 4Mb and would be needed very rarely.  For Windows users 
we provide a DLL, which is compiled with VC++ as that is what works out 
of the box.)

(capabilities("iconv") will tell you the status of a build if you have 
forgotten what happened at configure time.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ross at biostat.ucsf.edu  Fri Feb 16 22:30:43 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 16 Feb 2007 13:30:43 -0800
Subject: [Rd] pinning down symbol values (Scoping/Promises) question
Message-ID: <1171661444.9347.79.camel@iron.psg.net>

I would like to define a function using symbols, but freeze the symbols
at their current values at the time of definition.  Both symbols
referring to the global scope and symbols referring to arguments are at
issue. Consider this (R 2.4.0):
> k1 <- 5
> k
[1] 100
> a <- function(z) function() z+k
> a1 <- a(k1)
> k1 <- 2
> k <- 3
> a1()
[1] 5
> k <- 10
> k1 <- 100
> a1()
[1] 12

First, I'm a little surprised that that the value for k1 seems to get
pinned by the initial evaluation of a1.  I expected the final value to
be 110 because the z in z+k is a promise.

Second, how do I pin the values to the ones that obtain when the
different functions are invoked?  In other words, how should a be
defined so that a1() gets me 5+100 in the previous example?

I have a partial solution (for k), but it's ugly.  With k = 1 and k1 =
100,
> a <- eval(substitute(function(z) function() z+x, list(x=k)))
> k <- 20
> a1 <- a(k1)
> a1()
[1] 101
(by the way, I thought a <- eval(substitute(function(z) function() z+k))
would work, but it didn't).

This seems to pin the passed in argument as well, though it's even
uglier:
> a <- eval(substitute(function(z) { z; function() z+x}, list(x=k)))
> a1 <- a(k1)
> k1 <- 5
> a1()
[1] 120

-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From ross at biostat.ucsf.edu  Fri Feb 16 22:36:57 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 16 Feb 2007 13:36:57 -0800
Subject: [Rd] R Language Manual: possible error
Message-ID: <1171661817.9347.86.camel@iron.psg.net>

The R Language manual, section 4.3.4 ("Scope"), has
     f <- function(x) {
         y <- 10
         g <- function(x) x + y
         return(g)
     }
     h <- f()
     h(3)
  
... When `h(3)' is evaluated we see that its body is that of `g'.
Within that body `x' and `y' are unbound.

Is that last sentence right?  It looks to me as if x is a bound
variable, and the definitions given in the elided material seem to say
so too.  I guess there is hidden, outer, x that is unbound.  Maybe the
example was meant to be 
	g <- function(a) a + y?

The front page of the manual says
 The current version of this document is 2.4.0 (2006-11-25) DRAFT.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From ggrothendieck at gmail.com  Sat Feb 17 02:04:05 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Feb 2007 20:04:05 -0500
Subject: [Rd] pinning down symbol values (Scoping/Promises) question
In-Reply-To: <1171661444.9347.79.camel@iron.psg.net>
References: <1171661444.9347.79.camel@iron.psg.net>
Message-ID: <971536df0702161704v274b165fp9de7b5ccda20e68d@mail.gmail.com>

See ?force

a <- function(z) {
	force(k)
	function() z+k
}


On 2/16/07, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> I would like to define a function using symbols, but freeze the symbols
> at their current values at the time of definition.  Both symbols
> referring to the global scope and symbols referring to arguments are at
> issue. Consider this (R 2.4.0):
> > k1 <- 5
> > k
> [1] 100
> > a <- function(z) function() z+k
> > a1 <- a(k1)
> > k1 <- 2
> > k <- 3
> > a1()
> [1] 5
> > k <- 10
> > k1 <- 100
> > a1()
> [1] 12
>
> First, I'm a little surprised that that the value for k1 seems to get
> pinned by the initial evaluation of a1.  I expected the final value to
> be 110 because the z in z+k is a promise.
>
> Second, how do I pin the values to the ones that obtain when the
> different functions are invoked?  In other words, how should a be
> defined so that a1() gets me 5+100 in the previous example?
>
> I have a partial solution (for k), but it's ugly.  With k = 1 and k1 =
> 100,
> > a <- eval(substitute(function(z) function() z+x, list(x=k)))
> > k <- 20
> > a1 <- a(k1)
> > a1()
> [1] 101
> (by the way, I thought a <- eval(substitute(function(z) function() z+k))
> would work, but it didn't).
>
> This seems to pin the passed in argument as well, though it's even
> uglier:
> > a <- eval(substitute(function(z) { z; function() z+x}, list(x=k)))
> > a1 <- a(k1)
> > k1 <- 5
> > a1()
> [1] 120
>
> --
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sat Feb 17 13:04:53 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 17 Feb 2007 07:04:53 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>	<8651815.post@talk.nabble.com>	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
Message-ID: <45D6EF65.1070702@stats.uwo.ca>

On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
> I mentioned this twice already and no one answered;however, I am mentioning
> this a third time since its a serious deficiency.   

I agree this would be a reasonable addition, but I wouldn't class it as 
a serious deficiency, and I don't plan to work on it myself.

If you want to put together patches to the trunk code and docs to 
implement this I'll review them and possibly commit them.  If you don't 
see this as a high enough priority to do that, then I'd suggest doing 
what I do:  don't use the CMD.EXE shell.  There are a number of 
Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can 
handle the #! syntax just fine.  Or just use two files, as you describe 
below.

Duncan Murdoch

 > The Rscript facility
> that is upcoming in R is useful but on Windows one will often be relegated
> to having two files: a batch file and an R file unless the -x switch
> is implemented
> to allow them to be combined.  This is not a problem on UNIX which supports
> #! but on Windows we need -x.  Every other common scripting language including
> perl, python and ruby supports -x for this purpose.
> 
> (The -x flag would start R processing at the first line that begins with #! so
> that prior lines could be Windows batch commands allowing the same file
> to be used as a batch file and an R file.)
> 
> Note that there is a bug in Windows which means that if you simply associate
> .R to running R then the result cannot be redirected.  There is a bug
> fix available
> for this but I think we need to be able to run out of the box for something this
> common.
> 
> 
> On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>> Haven't got any feedback on this one.
>>
>> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
>>
>> It certainly would give more flexibility to users of Rscript on non-UNIX systems
>> where #! notation is not available.
>>
>> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>> Good idea.  ruby seems to work the same way.  python does too but with
>>> a slightly different definition:
>>>
>>> C:\> ruby -h | findstr strip
>>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
>>>
>>> C:\> perl -h | findstr strip
>>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
>>>
>>> C:\> python -h | findstr skip
>>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
>>>
>>>
>>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
>>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
>>>> "#!".
>>>> This allows writing perl scripts in ordinary .bat files.
>>>>
>>>> ?shQuote contains a link with the following perl script example:
>>>> ===8<===
>>>> @echo off
>>>> :: hello.bat
>>>> :: Windows executable Perl script
>>>> :: Note:
>>>> ::   assumes perl.exe is in path
>>>> ::   otherwise, use absolute path
>>>> perl -x -S "%0" %*
>>>> goto end
>>>> #!perl
>>>>
>>>> print "Hello, World!\n";
>>>> __END__
>>>> :end
>>>> :: ------ end of hello.bat ------
>>>>
>>>> Windows Notes:
>>>> " -x " (lower case x): Skip all text until shebang line.
>>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
>>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
>>>> have either suffix.
>>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
>>>> ===8<===
>>>>
>>>> I think the simplest way to implement shebang on windows would be embedding
>>>> one more command line switch with similar functionality to perl's '-x'.
>>>>
>>>> --
>>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
>>>> Sent from the R devel mailing list archive at Nabble.com.
>>>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Feb 17 13:31:37 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 17 Feb 2007 07:31:37 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <45D6EF65.1070702@stats.uwo.ca>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
	<45D6EF65.1070702@stats.uwo.ca>
Message-ID: <971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>

I think its best if core mods are done by the core group while others
focus on work that can be done external to the core.

Thus, what I have done is to enhance the batchfiles distribution with
3 new batchfiles: Rscript.bat, #Rscript.bat and runR.bat which will be
part of the
next distribution of batchfiles but can be obtained now, if desired, from the
batchfiles svn (with the caveat that they require R 2.5.0).  The batchfiles
home page is here:

   http://code.google.com/p/batchfiles

The source tab on that page gets you to the svn and the links on the right
include links to the NEWS and README files which describe the additions,
a link to info on the Windows bug that I mentioned and two perl links that
describe how this all works in perl which may be a helpful analogous
situation.
.
On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
> > I mentioned this twice already and no one answered;however, I am mentioning
> > this a third time since its a serious deficiency.
>
> I agree this would be a reasonable addition, but I wouldn't class it as
> a serious deficiency, and I don't plan to work on it myself.
>
> If you want to put together patches to the trunk code and docs to
> implement this I'll review them and possibly commit them.  If you don't
> see this as a high enough priority to do that, then I'd suggest doing
> what I do:  don't use the CMD.EXE shell.  There are a number of
> Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can
> handle the #! syntax just fine.  Or just use two files, as you describe
> below.
>
> Duncan Murdoch
>
>  > The Rscript facility
> > that is upcoming in R is useful but on Windows one will often be relegated
> > to having two files: a batch file and an R file unless the -x switch
> > is implemented
> > to allow them to be combined.  This is not a problem on UNIX which supports
> > #! but on Windows we need -x.  Every other common scripting language including
> > perl, python and ruby supports -x for this purpose.
> >
> > (The -x flag would start R processing at the first line that begins with #! so
> > that prior lines could be Windows batch commands allowing the same file
> > to be used as a batch file and an R file.)
> >
> > Note that there is a bug in Windows which means that if you simply associate
> > .R to running R then the result cannot be redirected.  There is a bug
> > fix available
> > for this but I think we need to be able to run out of the box for something this
> > common.
> >
> >
> > On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >> Haven't got any feedback on this one.
> >>
> >> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
> >>
> >> It certainly would give more flexibility to users of Rscript on non-UNIX systems
> >> where #! notation is not available.
> >>
> >> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >>> Good idea.  ruby seems to work the same way.  python does too but with
> >>> a slightly different definition:
> >>>
> >>> C:\> ruby -h | findstr strip
> >>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
> >>>
> >>> C:\> perl -h | findstr strip
> >>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
> >>>
> >>> C:\> python -h | findstr skip
> >>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
> >>>
> >>>
> >>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> >>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
> >>>> "#!".
> >>>> This allows writing perl scripts in ordinary .bat files.
> >>>>
> >>>> ?shQuote contains a link with the following perl script example:
> >>>> ===8<===
> >>>> @echo off
> >>>> :: hello.bat
> >>>> :: Windows executable Perl script
> >>>> :: Note:
> >>>> ::   assumes perl.exe is in path
> >>>> ::   otherwise, use absolute path
> >>>> perl -x -S "%0" %*
> >>>> goto end
> >>>> #!perl
> >>>>
> >>>> print "Hello, World!\n";
> >>>> __END__
> >>>> :end
> >>>> :: ------ end of hello.bat ------
> >>>>
> >>>> Windows Notes:
> >>>> " -x " (lower case x): Skip all text until shebang line.
> >>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
> >>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
> >>>> have either suffix.
> >>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
> >>>> ===8<===
> >>>>
> >>>> I think the simplest way to implement shebang on windows would be embedding
> >>>> one more command line switch with similar functionality to perl's '-x'.
> >>>>
> >>>> --
> >>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
> >>>> Sent from the R devel mailing list archive at Nabble.com.
> >>>>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Sat Feb 17 13:46:20 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 17 Feb 2007 07:46:20 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>	
	<8651815.post@talk.nabble.com>	
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>	
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>	
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>	
	<45D6EF65.1070702@stats.uwo.ca>
	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
Message-ID: <45D6F91C.7060000@stats.uwo.ca>

On 2/17/2007 7:31 AM, Gabor Grothendieck wrote:
> I think its best if core mods are done by the core group while others
> focus on work that can be done external to the core.

Fair enough, but then you also have to accept that the core group is 
going to set the priorities.  As far as I know *nobody* in the core 
group uses the CMD.EXE shell regularly, so changes to accommodate its 
limitations are going to get low priority.

Duncan Murdoch

> 
> Thus, what I have done is to enhance the batchfiles distribution with
> 3 new batchfiles: Rscript.bat, #Rscript.bat and runR.bat which will be
> part of the
> next distribution of batchfiles but can be obtained now, if desired, from the
> batchfiles svn (with the caveat that they require R 2.5.0).  The batchfiles
> home page is here:
> 
>    http://code.google.com/p/batchfiles
> 
> The source tab on that page gets you to the svn and the links on the right
> include links to the NEWS and README files which describe the additions,
> a link to info on the Windows bug that I mentioned and two perl links that
> describe how this all works in perl which may be a helpful analogous
> situation.
> .
> On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
>>> I mentioned this twice already and no one answered;however, I am mentioning
>>> this a third time since its a serious deficiency.
>> I agree this would be a reasonable addition, but I wouldn't class it as
>> a serious deficiency, and I don't plan to work on it myself.
>>
>> If you want to put together patches to the trunk code and docs to
>> implement this I'll review them and possibly commit them.  If you don't
>> see this as a high enough priority to do that, then I'd suggest doing
>> what I do:  don't use the CMD.EXE shell.  There are a number of
>> Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can
>> handle the #! syntax just fine.  Or just use two files, as you describe
>> below.
>>
>> Duncan Murdoch
>>
>>  > The Rscript facility
>>> that is upcoming in R is useful but on Windows one will often be relegated
>>> to having two files: a batch file and an R file unless the -x switch
>>> is implemented
>>> to allow them to be combined.  This is not a problem on UNIX which supports
>>> #! but on Windows we need -x.  Every other common scripting language including
>>> perl, python and ruby supports -x for this purpose.
>>>
>>> (The -x flag would start R processing at the first line that begins with #! so
>>> that prior lines could be Windows batch commands allowing the same file
>>> to be used as a batch file and an R file.)
>>>
>>> Note that there is a bug in Windows which means that if you simply associate
>>> .R to running R then the result cannot be redirected.  There is a bug
>>> fix available
>>> for this but I think we need to be able to run out of the box for something this
>>> common.
>>>
>>>
>>> On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>>> Haven't got any feedback on this one.
>>>>
>>>> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
>>>>
>>>> It certainly would give more flexibility to users of Rscript on non-UNIX systems
>>>> where #! notation is not available.
>>>>
>>>> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>>>> Good idea.  ruby seems to work the same way.  python does too but with
>>>>> a slightly different definition:
>>>>>
>>>>> C:\> ruby -h | findstr strip
>>>>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
>>>>>
>>>>> C:\> perl -h | findstr strip
>>>>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
>>>>>
>>>>> C:\> python -h | findstr skip
>>>>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
>>>>>
>>>>>
>>>>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
>>>>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
>>>>>> "#!".
>>>>>> This allows writing perl scripts in ordinary .bat files.
>>>>>>
>>>>>> ?shQuote contains a link with the following perl script example:
>>>>>> ===8<===
>>>>>> @echo off
>>>>>> :: hello.bat
>>>>>> :: Windows executable Perl script
>>>>>> :: Note:
>>>>>> ::   assumes perl.exe is in path
>>>>>> ::   otherwise, use absolute path
>>>>>> perl -x -S "%0" %*
>>>>>> goto end
>>>>>> #!perl
>>>>>>
>>>>>> print "Hello, World!\n";
>>>>>> __END__
>>>>>> :end
>>>>>> :: ------ end of hello.bat ------
>>>>>>
>>>>>> Windows Notes:
>>>>>> " -x " (lower case x): Skip all text until shebang line.
>>>>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
>>>>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
>>>>>> have either suffix.
>>>>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
>>>>>> ===8<===
>>>>>>
>>>>>> I think the simplest way to implement shebang on windows would be embedding
>>>>>> one more command line switch with similar functionality to perl's '-x'.
>>>>>>
>>>>>> --
>>>>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
>>>>>> Sent from the R devel mailing list archive at Nabble.com.
>>>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ggrothendieck at gmail.com  Sat Feb 17 15:31:58 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 17 Feb 2007 09:31:58 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <45D6F91C.7060000@stats.uwo.ca>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
	<45D6EF65.1070702@stats.uwo.ca>
	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
	<45D6F91C.7060000@stats.uwo.ca>
Message-ID: <971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>

Surely R has higher standards than that.  How about quality and
completeness of implementation?

Every other major scripting language has implemented this for good reason
and its a glaring omission.

On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/17/2007 7:31 AM, Gabor Grothendieck wrote:
> > I think its best if core mods are done by the core group while others
> > focus on work that can be done external to the core.
>
> Fair enough, but then you also have to accept that the core group is
> going to set the priorities.  As far as I know *nobody* in the core
> group uses the CMD.EXE shell regularly, so changes to accommodate its
> limitations are going to get low priority.
>
> Duncan Murdoch
>
> >
> > Thus, what I have done is to enhance the batchfiles distribution with
> > 3 new batchfiles: Rscript.bat, #Rscript.bat and runR.bat which will be
> > part of the
> > next distribution of batchfiles but can be obtained now, if desired, from the
> > batchfiles svn (with the caveat that they require R 2.5.0).  The batchfiles
> > home page is here:
> >
> >    http://code.google.com/p/batchfiles
> >
> > The source tab on that page gets you to the svn and the links on the right
> > include links to the NEWS and README files which describe the additions,
> > a link to info on the Windows bug that I mentioned and two perl links that
> > describe how this all works in perl which may be a helpful analogous
> > situation.
> > .
> > On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
> >>> I mentioned this twice already and no one answered;however, I am mentioning
> >>> this a third time since its a serious deficiency.
> >> I agree this would be a reasonable addition, but I wouldn't class it as
> >> a serious deficiency, and I don't plan to work on it myself.
> >>
> >> If you want to put together patches to the trunk code and docs to
> >> implement this I'll review them and possibly commit them.  If you don't
> >> see this as a high enough priority to do that, then I'd suggest doing
> >> what I do:  don't use the CMD.EXE shell.  There are a number of
> >> Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can
> >> handle the #! syntax just fine.  Or just use two files, as you describe
> >> below.
> >>
> >> Duncan Murdoch
> >>
> >>  > The Rscript facility
> >>> that is upcoming in R is useful but on Windows one will often be relegated
> >>> to having two files: a batch file and an R file unless the -x switch
> >>> is implemented
> >>> to allow them to be combined.  This is not a problem on UNIX which supports
> >>> #! but on Windows we need -x.  Every other common scripting language including
> >>> perl, python and ruby supports -x for this purpose.
> >>>
> >>> (The -x flag would start R processing at the first line that begins with #! so
> >>> that prior lines could be Windows batch commands allowing the same file
> >>> to be used as a batch file and an R file.)
> >>>
> >>> Note that there is a bug in Windows which means that if you simply associate
> >>> .R to running R then the result cannot be redirected.  There is a bug
> >>> fix available
> >>> for this but I think we need to be able to run out of the box for something this
> >>> common.
> >>>
> >>>
> >>> On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >>>> Haven't got any feedback on this one.
> >>>>
> >>>> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
> >>>>
> >>>> It certainly would give more flexibility to users of Rscript on non-UNIX systems
> >>>> where #! notation is not available.
> >>>>
> >>>> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >>>>> Good idea.  ruby seems to work the same way.  python does too but with
> >>>>> a slightly different definition:
> >>>>>
> >>>>> C:\> ruby -h | findstr strip
> >>>>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
> >>>>>
> >>>>> C:\> perl -h | findstr strip
> >>>>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
> >>>>>
> >>>>> C:\> python -h | findstr skip
> >>>>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
> >>>>>
> >>>>>
> >>>>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> >>>>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
> >>>>>> "#!".
> >>>>>> This allows writing perl scripts in ordinary .bat files.
> >>>>>>
> >>>>>> ?shQuote contains a link with the following perl script example:
> >>>>>> ===8<===
> >>>>>> @echo off
> >>>>>> :: hello.bat
> >>>>>> :: Windows executable Perl script
> >>>>>> :: Note:
> >>>>>> ::   assumes perl.exe is in path
> >>>>>> ::   otherwise, use absolute path
> >>>>>> perl -x -S "%0" %*
> >>>>>> goto end
> >>>>>> #!perl
> >>>>>>
> >>>>>> print "Hello, World!\n";
> >>>>>> __END__
> >>>>>> :end
> >>>>>> :: ------ end of hello.bat ------
> >>>>>>
> >>>>>> Windows Notes:
> >>>>>> " -x " (lower case x): Skip all text until shebang line.
> >>>>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
> >>>>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
> >>>>>> have either suffix.
> >>>>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
> >>>>>> ===8<===
> >>>>>>
> >>>>>> I think the simplest way to implement shebang on windows would be embedding
> >>>>>> one more command line switch with similar functionality to perl's '-x'.
> >>>>>>
> >>>>>> --
> >>>>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
> >>>>>> Sent from the R devel mailing list archive at Nabble.com.
> >>>>>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>
>


From elw at stderr.org  Sat Feb 17 16:10:51 2007
From: elw at stderr.org (elw at stderr.org)
Date: Sat, 17 Feb 2007 09:10:51 -0600 (CST)
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
	<45D6EF65.1070702@stats.uwo.ca>
	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
	<45D6F91C.7060000@stats.uwo.ca>
	<971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702170910160.22878@illuminati.stderr.org>


> Surely R has higher standards than that.  How about quality and 
> completeness of implementation?
>
> Every other major scripting language has implemented this for good 
> reason and its a glaring omission.


Gabor, can we get a URL from you to a patch that implements this 
functionality?

Thanks!

--elijah


From gavin.simpson at ucl.ac.uk  Sat Feb 17 16:15:30 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 17 Feb 2007 15:15:30 +0000
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
	<45D6EF65.1070702@stats.uwo.ca>
	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
	<45D6F91C.7060000@stats.uwo.ca>
	<971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>
Message-ID: <1171725331.3013.21.camel@dhcppc2.my.nat.localnet>

On Sat, 2007-02-17 at 09:31 -0500, Gabor Grothendieck wrote:
> Surely R has higher standards than that.  How about quality and
> completeness of implementation?
> 
> Every other major scripting language has implemented this for good reason
> and its a glaring omission.

I think you are forgetting that R is an open source project, and is
reliant on the generous efforts of the R community, and in particular
the Core development team, for any work done on it.

I disagree with your statement about core mods being best done by the
core group - we all benefit when anyone, core or otherwise, contributes
to R. Duncan has already offered to review a submitted patch and
therefore commit some of his time to improving this feature - and this
is how it should work for those features that are of lower priority to
the core team.

However, that is your opinion and you are free to contribute directly to
R or not or contribute in some other way (as R-help subscribers know you
do to their benefit). But Core developers have that same right, and I'm
sure there are numerous other things in R that they might consider to be
incompletely implemented, in need of improvement or just plain missing
and therefore more deserving of their attention. Otherwise the SVN logs
wouldn't be quite so active...

G

> 
> On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 2/17/2007 7:31 AM, Gabor Grothendieck wrote:
> > > I think its best if core mods are done by the core group while others
> > > focus on work that can be done external to the core.
> >
> > Fair enough, but then you also have to accept that the core group is
> > going to set the priorities.  As far as I know *nobody* in the core
> > group uses the CMD.EXE shell regularly, so changes to accommodate its
> > limitations are going to get low priority.
> >
> > Duncan Murdoch
> >
> > >
> > > Thus, what I have done is to enhance the batchfiles distribution with
> > > 3 new batchfiles: Rscript.bat, #Rscript.bat and runR.bat which will be
> > > part of the
> > > next distribution of batchfiles but can be obtained now, if desired, from the
> > > batchfiles svn (with the caveat that they require R 2.5.0).  The batchfiles
> > > home page is here:
> > >
> > >    http://code.google.com/p/batchfiles
> > >
> > > The source tab on that page gets you to the svn and the links on the right
> > > include links to the NEWS and README files which describe the additions,
> > > a link to info on the Windows bug that I mentioned and two perl links that
> > > describe how this all works in perl which may be a helpful analogous
> > > situation.
> > > .
> > > On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > >> On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
> > >>> I mentioned this twice already and no one answered;however, I am mentioning
> > >>> this a third time since its a serious deficiency.
> > >> I agree this would be a reasonable addition, but I wouldn't class it as
> > >> a serious deficiency, and I don't plan to work on it myself.
> > >>
> > >> If you want to put together patches to the trunk code and docs to
> > >> implement this I'll review them and possibly commit them.  If you don't
> > >> see this as a high enough priority to do that, then I'd suggest doing
> > >> what I do:  don't use the CMD.EXE shell.  There are a number of
> > >> Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can
> > >> handle the #! syntax just fine.  Or just use two files, as you describe
> > >> below.
> > >>
> > >> Duncan Murdoch
> > >>
> > >>  > The Rscript facility
> > >>> that is upcoming in R is useful but on Windows one will often be relegated
> > >>> to having two files: a batch file and an R file unless the -x switch
> > >>> is implemented
> > >>> to allow them to be combined.  This is not a problem on UNIX which supports
> > >>> #! but on Windows we need -x.  Every other common scripting language including
> > >>> perl, python and ruby supports -x for this purpose.
> > >>>
> > >>> (The -x flag would start R processing at the first line that begins with #! so
> > >>> that prior lines could be Windows batch commands allowing the same file
> > >>> to be used as a batch file and an R file.)
> > >>>
> > >>> Note that there is a bug in Windows which means that if you simply associate
> > >>> .R to running R then the result cannot be redirected.  There is a bug
> > >>> fix available
> > >>> for this but I think we need to be able to run out of the box for something this
> > >>> common.
> > >>>
> > >>>
> > >>> On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > >>>> Haven't got any feedback on this one.
> > >>>>
> > >>>> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
> > >>>>
> > >>>> It certainly would give more flexibility to users of Rscript on non-UNIX systems
> > >>>> where #! notation is not available.
> > >>>>
> > >>>> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > >>>>> Good idea.  ruby seems to work the same way.  python does too but with
> > >>>>> a slightly different definition:
> > >>>>>
> > >>>>> C:\> ruby -h | findstr strip
> > >>>>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
> > >>>>>
> > >>>>> C:\> perl -h | findstr strip
> > >>>>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
> > >>>>>
> > >>>>> C:\> python -h | findstr skip
> > >>>>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
> > >>>>>
> > >>>>>
> > >>>>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> > >>>>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
> > >>>>>> "#!".
> > >>>>>> This allows writing perl scripts in ordinary .bat files.
> > >>>>>>
> > >>>>>> ?shQuote contains a link with the following perl script example:
> > >>>>>> ===8<===
> > >>>>>> @echo off
> > >>>>>> :: hello.bat
> > >>>>>> :: Windows executable Perl script
> > >>>>>> :: Note:
> > >>>>>> ::   assumes perl.exe is in path
> > >>>>>> ::   otherwise, use absolute path
> > >>>>>> perl -x -S "%0" %*
> > >>>>>> goto end
> > >>>>>> #!perl
> > >>>>>>
> > >>>>>> print "Hello, World!\n";
> > >>>>>> __END__
> > >>>>>> :end
> > >>>>>> :: ------ end of hello.bat ------
> > >>>>>>
> > >>>>>> Windows Notes:
> > >>>>>> " -x " (lower case x): Skip all text until shebang line.
> > >>>>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
> > >>>>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
> > >>>>>> have either suffix.
> > >>>>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
> > >>>>>> ===8<===
> > >>>>>>
> > >>>>>> I think the simplest way to implement shebang on windows would be embedding
> > >>>>>> one more command line switch with similar functionality to perl's '-x'.
> > >>>>>>
> > >>>>>> --
> > >>>>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
> > >>>>>> Sent from the R devel mailing list archive at Nabble.com.
> > >>>>>>
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> >
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ggrothendieck at gmail.com  Sat Feb 17 16:57:50 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 17 Feb 2007 10:57:50 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <1171725331.3013.21.camel@dhcppc2.my.nat.localnet>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>
	<8651815.post@talk.nabble.com>
	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>
	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>
	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>
	<45D6EF65.1070702@stats.uwo.ca>
	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>
	<45D6F91C.7060000@stats.uwo.ca>
	<971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>
	<1171725331.3013.21.camel@dhcppc2.my.nat.localnet>
Message-ID: <971536df0702170757w10e90c41p6003c926cafaeff8@mail.gmail.com>

Just because its open source does not mean everyone should do everything.
I suspect I have more expertise in Windows batch than the core developers
and also suspect they have more knowledge of the core than I so its a
good division of labor if I provide the batch files and they add -x
since it takes me
less time to produce batch files and they less time to add -x.

Furthermore its possible to develop something for the core and then have
it rejected and while hopefully this won't happen or if does it happens for
good reason, if one works on an external package then there is no chance
the work will be wasted since you have control over it.

In general the idea of having external packages has seemed to work well
and allows parallel development in a maximal way so the idea of having
the core work on the core and others work externally has been successful.

While no one has to provide Rscript or -x or anything else that applies to me
too and I didn't have to develop the external supporting Windows-specific
software in batchfiles or make it available to yet it is now available for you
and others to use with R 2.5.0 (via svn and more formally when I release it
to CRAN probably when R 2.5.0 is released).

Also I think that the success of R in the community is such that the core
developers do have some responsibility to the community at large beyond
their own needs.much as a business which when it gets to a certain size
and prominence has certain responsibilities to society beyond its own
purposes and some reasonable compromise between their own needs
and obvious requirements to complete certain work or do it to a certain
level of quality needs to be taken account of.

On 2/17/07, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Sat, 2007-02-17 at 09:31 -0500, Gabor Grothendieck wrote:
> > Surely R has higher standards than that.  How about quality and
> > completeness of implementation?
> >
> > Every other major scripting language has implemented this for good reason
> > and its a glaring omission.
>
> I think you are forgetting that R is an open source project, and is
> reliant on the generous efforts of the R community, and in particular
> the Core development team, for any work done on it.
>
> I disagree with your statement about core mods being best done by the
> core group - we all benefit when anyone, core or otherwise, contributes
> to R. Duncan has already offered to review a submitted patch and
> therefore commit some of his time to improving this feature - and this
> is how it should work for those features that are of lower priority to
> the core team.
>
> However, that is your opinion and you are free to contribute directly to
> R or not or contribute in some other way (as R-help subscribers know you
> do to their benefit). But Core developers have that same right, and I'm
> sure there are numerous other things in R that they might consider to be
> incompletely implemented, in need of improvement or just plain missing
> and therefore more deserving of their attention. Otherwise the SVN logs
> wouldn't be quite so active...
>
> G
>
> >
> > On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > > On 2/17/2007 7:31 AM, Gabor Grothendieck wrote:
> > > > I think its best if core mods are done by the core group while others
> > > > focus on work that can be done external to the core.
> > >
> > > Fair enough, but then you also have to accept that the core group is
> > > going to set the priorities.  As far as I know *nobody* in the core
> > > group uses the CMD.EXE shell regularly, so changes to accommodate its
> > > limitations are going to get low priority.
> > >
> > > Duncan Murdoch
> > >
> > > >
> > > > Thus, what I have done is to enhance the batchfiles distribution with
> > > > 3 new batchfiles: Rscript.bat, #Rscript.bat and runR.bat which will be
> > > > part of the
> > > > next distribution of batchfiles but can be obtained now, if desired, from the
> > > > batchfiles svn (with the caveat that they require R 2.5.0).  The batchfiles
> > > > home page is here:
> > > >
> > > >    http://code.google.com/p/batchfiles
> > > >
> > > > The source tab on that page gets you to the svn and the links on the right
> > > > include links to the NEWS and README files which describe the additions,
> > > > a link to info on the Windows bug that I mentioned and two perl links that
> > > > describe how this all works in perl which may be a helpful analogous
> > > > situation.
> > > > .
> > > > On 2/17/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > > >> On 2/16/2007 9:35 AM, Gabor Grothendieck wrote:
> > > >>> I mentioned this twice already and no one answered;however, I am mentioning
> > > >>> this a third time since its a serious deficiency.
> > > >> I agree this would be a reasonable addition, but I wouldn't class it as
> > > >> a serious deficiency, and I don't plan to work on it myself.
> > > >>
> > > >> If you want to put together patches to the trunk code and docs to
> > > >> implement this I'll review them and possibly commit them.  If you don't
> > > >> see this as a high enough priority to do that, then I'd suggest doing
> > > >> what I do:  don't use the CMD.EXE shell.  There are a number of
> > > >> Unix-like shells available in Windows (Cygwin, MSYS, etc.) that can
> > > >> handle the #! syntax just fine.  Or just use two files, as you describe
> > > >> below.
> > > >>
> > > >> Duncan Murdoch
> > > >>
> > > >>  > The Rscript facility
> > > >>> that is upcoming in R is useful but on Windows one will often be relegated
> > > >>> to having two files: a batch file and an R file unless the -x switch
> > > >>> is implemented
> > > >>> to allow them to be combined.  This is not a problem on UNIX which supports
> > > >>> #! but on Windows we need -x.  Every other common scripting language including
> > > >>> perl, python and ruby supports -x for this purpose.
> > > >>>
> > > >>> (The -x flag would start R processing at the first line that begins with #! so
> > > >>> that prior lines could be Windows batch commands allowing the same file
> > > >>> to be used as a batch file and an R file.)
> > > >>>
> > > >>> Note that there is a bug in Windows which means that if you simply associate
> > > >>> .R to running R then the result cannot be redirected.  There is a bug
> > > >>> fix available
> > > >>> for this but I think we need to be able to run out of the box for something this
> > > >>> common.
> > > >>>
> > > >>>
> > > >>> On 1/29/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > >>>> Haven't got any feedback on this one.
> > > >>>>
> > > >>>> Will we be getting a perl/python/ruby style -x switch for Rscript for R 2.5.0?
> > > >>>>
> > > >>>> It certainly would give more flexibility to users of Rscript on non-UNIX systems
> > > >>>> where #! notation is not available.
> > > >>>>
> > > >>>> On 1/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > >>>>> Good idea.  ruby seems to work the same way.  python does too but with
> > > >>>>> a slightly different definition:
> > > >>>>>
> > > >>>>> C:\> ruby -h | findstr strip
> > > >>>>>  -x[directory]   strip off text before #!ruby line and perhaps cd to directory
> > > >>>>>
> > > >>>>> C:\> perl -h | findstr strip
> > > >>>>>  -x[directory]   strip off text before #!perl line and perhaps cd to directory
> > > >>>>>
> > > >>>>> C:\> python -h | findstr skip
> > > >>>>> -x     : skip first line of source, allowing use of non-Unix forms of #!cmd
> > > >>>>>
> > > >>>>>
> > > >>>>> On 1/26/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> > > >>>>>> ActivePerl has '-x' switch which tells it to skip all lines in the file till
> > > >>>>>> "#!".
> > > >>>>>> This allows writing perl scripts in ordinary .bat files.
> > > >>>>>>
> > > >>>>>> ?shQuote contains a link with the following perl script example:
> > > >>>>>> ===8<===
> > > >>>>>> @echo off
> > > >>>>>> :: hello.bat
> > > >>>>>> :: Windows executable Perl script
> > > >>>>>> :: Note:
> > > >>>>>> ::   assumes perl.exe is in path
> > > >>>>>> ::   otherwise, use absolute path
> > > >>>>>> perl -x -S "%0" %*
> > > >>>>>> goto end
> > > >>>>>> #!perl
> > > >>>>>>
> > > >>>>>> print "Hello, World!\n";
> > > >>>>>> __END__
> > > >>>>>> :end
> > > >>>>>> :: ------ end of hello.bat ------
> > > >>>>>>
> > > >>>>>> Windows Notes:
> > > >>>>>> " -x " (lower case x): Skip all text until shebang line.
> > > >>>>>> " -S " (upper case S): Look for script using PATH variable. Special meaning
> > > >>>>>> in Windows: appends .bat or .cmd if lookup for name fails and name does not
> > > >>>>>> have either suffix.
> > > >>>>>> " %* " only on WinNT/2K/XP; use %1 %2 . . . %9 on Win9x/DOS
> > > >>>>>> ===8<===
> > > >>>>>>
> > > >>>>>> I think the simplest way to implement shebang on windows would be embedding
> > > >>>>>> one more command line switch with similar functionality to perl's '-x'.
> > > >>>>>>
> > > >>>>>> --
> > > >>>>>> View this message in context: http://www.nabble.com/Rscript-on-Windows-tf3120774.html#a8651815
> > > >>>>>> Sent from the R devel mailing list archive at Nabble.com.
> > > >>>>>>
> > > >>> ______________________________________________
> > > >>> R-devel at r-project.org mailing list
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>
> > >
> > >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [t] +44 (0)20 7679 0522
> ECRC                              [f] +44 (0)20 7679 0565
> UCL Department of Geography
> Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
> Gower Street
> London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
> WC1E 6BT                          [w] http://www.freshwaters.org.uk/
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From Peter.Rossi at chicagogsb.edu  Sat Feb 17 17:54:43 2007
From: Peter.Rossi at chicagogsb.edu (Rossi, Peter E.)
Date: Sat, 17 Feb 2007 10:54:43 -0600
Subject: [Rd] S3 vs S4 classes
Message-ID: <1E7B167439290641966EB161D433079801DBF29C@GSBEX.gsb.uchicago.edu>

 
I have developed a package, bayesm, which uses existing classes of
objects.  I would like
to add a new class corresponding to objects from this package.

I have been reading about classes and all sources tell me that I should
use
so-called "new" or S4 classes.

However, a major purpose of defining a class for my package would be to
add methods to the existing generic functions:  print, plot, and
summary.  My understanding
is that these functions work with the "old" or S3 classes.  

If I want to use S4 classes, do I need to write new generic functions or
is there
as way to "extend" the existing generics to work with S4 classes and
objects.  I may
be using the wrong word here "extend" but I hope that everyone
understands the point.
If I have to write new generic functions, it is a simply matter of
registering the pre-existing
methods based on S3 objects?  Or do you basicaly have to start from
scratch -- i.e.
the two types of classes, methods and generic functions are distinct?

thanks 

peter r
 
................................
 Peter E. Rossi
 Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
 Editor, Quantitative Marketing and Economics
 Rm 353, Graduate School of Business, U of Chicago
 5807 S. Woodlawn Ave, Chicago IL 60637
 Tel: (773) 702-7513   |   Fax: (773) 834-2081


From ripley at stats.ox.ac.uk  Sat Feb 17 18:34:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Feb 2007 17:34:20 +0000 (GMT)
Subject: [Rd] S3 vs S4 classes
In-Reply-To: <1E7B167439290641966EB161D433079801DBF29C@GSBEX.gsb.uchicago.edu>
References: <1E7B167439290641966EB161D433079801DBF29C@GSBEX.gsb.uchicago.edu>
Message-ID: <Pine.LNX.4.64.0702171659500.32039@gannet.stats.ox.ac.uk>

On Sat, 17 Feb 2007, Rossi, Peter E. wrote:

> I have developed a package, bayesm, which uses existing classes of 
> objects.  I would like to add a new class corresponding to objects from 
> this package.
>
> I have been reading about classes and all sources tell me that I should 
> use so-called "new" or S4 classes.

For new projects, perhaps: the issue is far less clear cut for existing 
ones.  In particular, the structure of model-fitting classes inherited 
from the White Book (lm, glm and so on) is S3 classes, and so related 
model-fitting functions (e.g. my polr) fit most naturally into the S3 
paradigm.

> However, a major purpose of defining a class for my package would be to 
> add methods to the existing generic functions:  print, plot, and 
> summary.  My understanding is that these functions work with the "old" 
> or S3 classes.

S4 classes should use show() rather than print(), according to the 
established practice (and I think the Green Book, but I do not have it to 
hand).  Certainly auto-printing uses show() for S4 objects in preference 
to print().

> If I want to use S4 classes, do I need to write new generic functions or 
> is there as way to "extend" the existing generics to work with S4 
> classes and objects.  I may be using the wrong word here "extend" but I 
> hope that everyone understands the point. If I have to write new generic 
> functions, it is a simply matter of registering the pre-existing methods 
> based on S3 objects?  Or do you basicaly have to start from scratch -- 
> i.e. the two types of classes, methods and generic functions are 
> distinct?

If you define an S4 method for any function, e.g. plot, it becomes S4 
generic and after looking for S4 methods will use the previous function 
(and if that is S3 generic, it will still look for S3 methods).

To my mind the advantage of S4 classes is that they are what JMC sometimes 
calls 'formal' classes: they are rigidly defined.  That suits them to new 
projects where you can think about the classes you want and define their 
structure and relationships in advance.  On the other hand, for 
development and experimenting that rigid definition can be a 
straightjacket.  I have moved various model-fitting functions to S4, and 
moved them back to S3 in frustration at the lack of fit to existing tools.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sat Feb 17 18:55:22 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 17 Feb 2007 12:55:22 -0500
Subject: [Rd] Rscript on Windows
In-Reply-To: <971536df0702170757w10e90c41p6003c926cafaeff8@mail.gmail.com>
References: <971536df0701252058i739700dx8f7e02f8be48bf4e@mail.gmail.com>	<8651815.post@talk.nabble.com>	<971536df0701260645p68852335n21812456a52733e8@mail.gmail.com>	<971536df0701290644w51e75315r59120822cffe2819@mail.gmail.com>	<971536df0702160635m256f5dc0q51c2b5e683a22ede@mail.gmail.com>	<45D6EF65.1070702@stats.uwo.ca>	<971536df0702170431j6234dc69n8f43eade71978b84@mail.gmail.com>	<45D6F91C.7060000@stats.uwo.ca>	<971536df0702170631t2daf5818nefe910db36fc49a@mail.gmail.com>	<1171725331.3013.21.camel@dhcppc2.my.nat.localnet>
	<971536df0702170757w10e90c41p6003c926cafaeff8@mail.gmail.com>
Message-ID: <45D7418A.5030107@stats.uwo.ca>

On 2/17/2007 10:57 AM, Gabor Grothendieck wrote:

[ deletions ]

> Also I think that the success of R in the community is such that the core
> developers do have some responsibility to the community at large beyond
> their own needs.

I'd agree with this, as long as you don't limit it to the core 
developers.  We all have some responsibility to the community at large 
beyond our own needs.  But I think we also all have the right to decide 
how to prioritize those responsibilities.

much as a business which when it gets to a certain size
> and prominence has certain responsibilities to society beyond its own
> purposes and some reasonable compromise between their own needs
> and obvious requirements to complete certain work or do it to a certain
> level of quality needs to be taken account of.

Sounds like you should contact Microsoft, and try to get them to take 
their responsibilities seriously, and support #! syntax in CMD.EXE. 
They've got a lot more resources than the R core group has.

Duncan Murdoch


From jmc at r-project.org  Sun Feb 18 04:59:32 2007
From: jmc at r-project.org (John Chambers)
Date: Sat, 17 Feb 2007 19:59:32 -0800
Subject: [Rd] S3 vs S4 classes
In-Reply-To: <1E7B167439290641966EB161D433079801DBF29C@GSBEX.gsb.uchicago.edu>
References: <1E7B167439290641966EB161D433079801DBF29C@GSBEX.gsb.uchicago.edu>
Message-ID: <45D7CF24.3050606@r-project.org>

Rossi, Peter E. wrote:
>  
> I have developed a package, bayesm, which uses existing classes of
> objects.  I would like
> to add a new class corresponding to objects from this package.
>
> I have been reading about classes and all sources tell me that I should
> use
> so-called "new" or S4 classes.
>
> However, a major purpose of defining a class for my package would be to
> add methods to the existing generic functions:  print, plot, and
> summary.  My understanding
> is that these functions work with the "old" or S3 classes.  
>
> If I want to use S4 classes, do I need to write new generic functions or
> is there
> as way to "extend" the existing generics to work with S4 classes and
> objects.  
If you define a method for any function that is currently not a generic, 
the function is automatically turned into a generic with the existing 
function becoming the default method.  So you can define methods for any 
function.

In particular, defining a method for an S3 generic makes that generic 
the default method for the S4 generic function.

Should you do this?  The main advantages are that you can then know 
something about the methods (i.e., there is some metadata that allows 
one to list the methods, ask what method would be selected for 
particular arguments, etc.),  and also,  methods can be defined for more 
than one argument.  The advantages increase if you want to define new 
classes of objects, since these also have a formal definition and some 
guarantee that the objects really do behave as the class says they do.

Basically, the S3 methods were a "quick and dirty" implementation that 
came out with the "Statistical Methods in S" project and book.  They 
have been intensively worked up for those applications, and the easy way 
out is still to use them for that purpose.

Over the (15)  years since that project got going, a more serious effort 
produced a more extensive view of classes and methods.

You should not feel pressed to choose one or another.  Some of the older 
generation are still using Fortran after all.

But the newer version was developed with the goal of having better 
software.  Some people don't like them, which is their privilege.  
People have their own goals, and their own prior investments.



> I may
> be using the wrong word here "extend" but I hope that everyone
> understands the point.
> If I have to write new generic functions, it is a simply matter of
> registering the pre-existing
> methods based on S3 objects?  Or do you basicaly have to start from
> scratch -- i.e.
> the two types of classes, methods and generic functions are distinct?
>
> thanks 
>
> peter r
>  
> ................................
>  Peter E. Rossi
>  Joseph T. and Bernice S. Lewis Professor of Marketing and Statistics
>  Editor, Quantitative Marketing and Economics
>  Rm 353, Graduate School of Business, U of Chicago
>  5807 S. Woodlawn Ave, Chicago IL 60637
>  Tel: (773) 702-7513   |   Fax: (773) 834-2081
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From tpapp at Princeton.EDU  Mon Feb 19 15:51:10 2007
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 19 Feb 2007 09:51:10 -0500
Subject: [Rd] OT: suggestions for a 64-bit server / cluster
Message-ID: <20070219145110.GB28140@pu100877.student.princeton.edu>

Hi,

Our department has finally decided to get a powerful server (or maybe
a cluster) for computationally intensive jobs.  I will mainly run R
and Matlab, on Linux.

We are currently in the process of deciding what kind of hardware to
get, so I would like to ask for suggestions from those who have
experience in this.  Our budget is $10-15k.  If you can recommend a
configuration, brand or particular US-based company, please contact me
off-list.

Thanks,

Tamas


From ross at biostat.ucsf.edu  Mon Feb 19 23:41:42 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 19 Feb 2007 14:41:42 -0800
Subject: [Rd] "try"ing to understand condition handling
Message-ID: <20070219224141.GA21040@wheat.betterworld.us>

I'm confused by the page documenting tryCatch and friends.

I think it describes 3 separate mechanisms: tryCatch (in which control
returns to the invoking tryCatch), withCallHandlers (in which control
goes up to the calling handler/s but then continues from the point at
which signalCondition() was invoked), and withRestarts (I can't tell
where control ends up).

For tryCatch the docs say the arguments ... provide handlers, and that
these are matched to the condition.  It appears that matching works by
providing entries in ... as named arguments, and the handler matches
if the name is one of the classes of the condition.  Is that right?  I
don't see the matching rule explicitly stated.  And then  the handler
itself is a single argument function, where the argument is the
condition?

My reading is that if some code executes signalCondition and it is
running inside a tryCatch, control will not return to the line after
the signalCondition.  Whereas, if the context is withCallHandlers,
the call to signalCondition does return (with a NULL) and execution
continues.  That seems odd; do I have it right?

Also, the documents don't explicitly say that the abstract subclasses
of 'error' and 'warning' are subclasses of 'condition', though that
seems to be implied and true.

It appears that for tryCatch only the first matching handler is
executed, while for withCallHandlers all matching handlers are
executed.

And, finally, with restarts there is again the issue of how the name
in the name=function form gets matched to the condition, and the more
basic question of what happens.  My guess is that control stays with
the handler, but then this mechanism seems very similar to tryCatch
(with the addition of being able to pass extra arguments to the
handler and  maybe a more flexible handler specification).

Can anyone clarify any of this?

P.S. Is there any mechanism that would allow one to trap an interrupt,
like a ctl-C,  so that if the user hit ctl-C some state would be
changed but execution would then continue where it was?  I have in
mind the ctl-C handler setting a "time to finish up" flag which the
maini code checks from time to time.

Thanks.

Ross Boylan


From edd at debian.org  Tue Feb 20 02:10:49 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 19 Feb 2007 19:10:49 -0600
Subject: [Rd] Custom per-package options passed down via library() ?
Message-ID: <17882.19097.558422.737418@basebud.nulle.part>


I want to load an in-house library 'differently' in a particular context and,
to achieve this, would like to govern the behaviour of its .onLoad()
function.

In a related context, Frank Harrell and I have been wondering on and off
about how to tell Hmisc to be less verbose in certain situations.  He
achieves this by placing information in a custom field in options(). 
I could do the same in my case -- but am wondering if there is a better way.
Is there?

Any hints welcome!

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From monty at sprintmail.com  Tue Feb 20 03:19:32 2007
From: monty at sprintmail.com (Rod Montgomery)
Date: Mon, 19 Feb 2007 21:19:32 -0500
Subject: [Rd]  Using GPUs for computation
Message-ID: <45DA5AB4.8030908@sprintmail.com>

> Douglas Bates <dmbates_at_gmail.com> wrote on Tue 24 Jan 2006 - 14:38:46 GMT:
> 
[snip]
> More seriously, the approach to speeding up model fitting that has been most successful to date is to speed up the BLAS
> (Basic Linear Algebra Subroutines), especially the Level-3 BLAS. The bulk of the computation in the Matrix package takes
> place in either Lapack (for dense matrices) or CHOLMOD (for sparse matrices) code and those are based on calls to the
> Levels 1, 2 and 3 BLAS. The Atlas package and K. Goto's BLAS are designed to obtain the highest level of performance
> possible from the CPU on these routines. I think the easiest way of incorporating the power of the GPU into the model
> fitting process would be to port the BLAS to the GPU. I also imagine that someone somewhere has already started on that.
> 
I haven't seen anything more recent about using GPUs to compute for R, but NVIDIA just recently made available a beta of its
CUDA environment for general-purpose computation on its new 8800-series GPUs, and there seems to be a BLAS library there.

I tried to include links in this message, but I got "Message rejected by filter rule match" from r-devel-owner when I did so.


From ripley at stats.ox.ac.uk  Tue Feb 20 08:35:51 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Feb 2007 07:35:51 +0000 (GMT)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <20070219224141.GA21040@wheat.betterworld.us>
References: <20070219224141.GA21040@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>

Since you have not told us what 'the documents' are (and only vaguely 
named one), do you not think your own documentation is inadequate?

There are documents about the condition system on developer.r-project.org: 
please consult them.

I quess 'ctl-C' is your private abbreviation for 'control C' (and not a 
type of cancer): that generates an interrrupt in most (but not all) R 
ports.  Where it does, you can set up interrupt handlers (as the help page 
said)


On Mon, 19 Feb 2007, Ross Boylan wrote:

> I'm confused by the page documenting tryCatch and friends.
>
> I think it describes 3 separate mechanisms: tryCatch (in which control
> returns to the invoking tryCatch), withCallHandlers (in which control
> goes up to the calling handler/s but then continues from the point at
> which signalCondition() was invoked), and withRestarts (I can't tell
> where control ends up).
>
> For tryCatch the docs say the arguments ... provide handlers, and that
> these are matched to the condition.  It appears that matching works by
> providing entries in ... as named arguments, and the handler matches
> if the name is one of the classes of the condition.  Is that right?  I
> don't see the matching rule explicitly stated.  And then  the handler
> itself is a single argument function, where the argument is the
> condition?
>
> My reading is that if some code executes signalCondition and it is
> running inside a tryCatch, control will not return to the line after
> the signalCondition.  Whereas, if the context is withCallHandlers,
> the call to signalCondition does return (with a NULL) and execution
> continues.  That seems odd; do I have it right?
>
> Also, the documents don't explicitly say that the abstract subclasses
> of 'error' and 'warning' are subclasses of 'condition', though that
> seems to be implied and true.
>
> It appears that for tryCatch only the first matching handler is
> executed, while for withCallHandlers all matching handlers are
> executed.
>
> And, finally, with restarts there is again the issue of how the name
> in the name=function form gets matched to the condition, and the more
> basic question of what happens.  My guess is that control stays with
> the handler, but then this mechanism seems very similar to tryCatch
> (with the addition of being able to pass extra arguments to the
> handler and  maybe a more flexible handler specification).
>
> Can anyone clarify any of this?
>
> P.S. Is there any mechanism that would allow one to trap an interrupt,
> like a ctl-C,  so that if the user hit ctl-C some state would be
> changed but execution would then continue where it was?  I have in
> mind the ctl-C handler setting a "time to finish up" flag which the
> maini code checks from time to time.
>
> Thanks.
>
> Ross Boylan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Feb 20 08:46:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Feb 2007 07:46:05 +0000 (GMT)
Subject: [Rd] Custom per-package options passed down via library() ?
In-Reply-To: <17882.19097.558422.737418@basebud.nulle.part>
References: <17882.19097.558422.737418@basebud.nulle.part>
Message-ID: <Pine.LNX.4.64.0702200736530.1875@gannet.stats.ox.ac.uk>

Some packages have their own option-like mechanism, e.g. sm.
Others use environment variables for this purpose.
And there are userhooks for .First.lib, .onLoad and .onAttach that could 
be exploited.

In the Hmisc case, you are talking about messages, I believe.  You can 
handle those via message classes.  The latter is not as easy as I would 
like (and is currently under discussion), but in this particular case the 
message class 'packageStartupMessage' of R >= 2.5.0 seems to be what is 
wanted.

library() does not have a ... argument, so you cannot do what your subject 
line suggests.  Since library() is scheduled to be replaced by use() 
sometime Real Soon Now, it is not being enhanced but I think this is part 
of the goals for use().

On Mon, 19 Feb 2007, Dirk Eddelbuettel wrote:

>
> I want to load an in-house library 'differently' in a particular context and,
> to achieve this, would like to govern the behaviour of its .onLoad()
> function.
>
> In a related context, Frank Harrell and I have been wondering on and off
> about how to tell Hmisc to be less verbose in certain situations.  He
> achieves this by placing information in a custom field in options().
> I could do the same in my case -- but am wondering if there is a better way.
> Is there?
>
> Any hints welcome!
>
> Regards, Dirk
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Tue Feb 20 14:13:20 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 20 Feb 2007 07:13:20 -0600
Subject: [Rd] Custom per-package options passed down via library() ?
In-Reply-To: <Pine.LNX.4.64.0702200736530.1875@gannet.stats.ox.ac.uk>
References: <17882.19097.558422.737418@basebud.nulle.part>
	<Pine.LNX.4.64.0702200736530.1875@gannet.stats.ox.ac.uk>
Message-ID: <17882.62448.646325.171009@basebud.nulle.part>


Dear Brian,

On 20 February 2007 at 07:46, Prof Brian Ripley wrote:
| Some packages have their own option-like mechanism, e.g. sm.
| Others use environment variables for this purpose.
| And there are userhooks for .First.lib, .onLoad and .onAttach that could 
| be exploited.

Ah, now I see setHook() et al. Interesting, thanks.  Won't help in my case --
I need to load a library without triggering some code branches, eg inits of
compiled code. I may just have to split my library, or do something else.
 
| In the Hmisc case, you are talking about messages, I believe.  You can 
| handle those via message classes.  The latter is not as easy as I would 
| like (and is currently under discussion), but in this particular case the 
| message class 'packageStartupMessage' of R >= 2.5.0 seems to be what is 
| wanted.
| 
| library() does not have a ... argument, so you cannot do what your subject 
| line suggests.  Since library() is scheduled to be replaced by use() 
| sometime Real Soon Now, it is not being enhanced but I think this is part 
| of the goals for use().

Interesting too -- that should be Real Useful Real Soon Now.

Thanks, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ross at biostat.ucsf.edu  Tue Feb 20 18:41:14 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 20 Feb 2007 09:41:14 -0800
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
Message-ID: <20070220174113.GB5871@wheat.betterworld.us>

On Tue, Feb 20, 2007 at 07:35:51AM +0000, Prof Brian Ripley wrote:
> Since you have not told us what 'the documents' are (and only vaguely 
> named one), do you not think your own documentation is inadequate?
I mean the command description produced by ?tryCatch.
> 
> There are documents about the condition system on developer.r-project.org: 
> please consult them.
> 
OK, though I would hope the user level documentation would suffice.
> I quess 'ctl-C' is your private abbreviation for 'control C' (and not a 
> type of cancer): that generates an interrrupt in most (but not all) R 
> ports.  Where it does, you can set up interrupt handlers (as the help page 
> said)
> 
My P.S. concerned whether the code that was interrupted could continue
from the point of interruption.  As far as I can tell from ?tryCatch
there is not,

> 
> On Mon, 19 Feb 2007, Ross Boylan wrote:
> 
> >I'm confused by the page documenting tryCatch and friends.
> >
> >I think it describes 3 separate mechanisms: tryCatch (in which control
> >returns to the invoking tryCatch), withCallHandlers (in which control
> >goes up to the calling handler/s but then continues from the point at
> >which signalCondition() was invoked), and withRestarts (I can't tell
> >where control ends up).
> >
> >For tryCatch the docs say the arguments ... provide handlers, and that
> >these are matched to the condition.  It appears that matching works by
> >providing entries in ... as named arguments, and the handler matches
> >if the name is one of the classes of the condition.  Is that right?  I
> >don't see the matching rule explicitly stated.  And then  the handler
> >itself is a single argument function, where the argument is the
> >condition?
> >
> >My reading is that if some code executes signalCondition and it is
> >running inside a tryCatch, control will not return to the line after
> >the signalCondition.  Whereas, if the context is withCallHandlers,
> >the call to signalCondition does return (with a NULL) and execution
> >continues.  That seems odd; do I have it right?
> >
> >Also, the documents don't explicitly say that the abstract subclasses
> >of 'error' and 'warning' are subclasses of 'condition', though that
> >seems to be implied and true.
> >
> >It appears that for tryCatch only the first matching handler is
> >executed, while for withCallHandlers all matching handlers are
> >executed.
> >
> >And, finally, with restarts there is again the issue of how the name
> >in the name=function form gets matched to the condition, and the more
> >basic question of what happens.  My guess is that control stays with
> >the handler, but then this mechanism seems very similar to tryCatch
> >(with the addition of being able to pass extra arguments to the
> >handler and  maybe a more flexible handler specification).
> >
> >Can anyone clarify any of this?
> >
> >P.S. Is there any mechanism that would allow one to trap an interrupt,
> >like a ctl-C,  so that if the user hit ctl-C some state would be
> >changed but execution would then continue where it was?  I have in
> >mind the ctl-C handler setting a "time to finish up" flag which the
> >maini code checks from time to time.
> >
> >Thanks.
> >
> >Ross Boylan
> >
> >______________________________________________
> >R-devel at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From spluque at gmail.com  Tue Feb 20 19:51:45 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 20 Feb 2007 12:51:45 -0600
Subject: [Rd] RODBC problems with unixodbc
Message-ID: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>

Hi,

I noticed that if a column is named "end" in a data frame (table.df
below), it leads to errors when trying to sqlSave()'it to a postgresql
connection:


---<---------------cut here---------------start-------------->---
con <- odbcConnect("PostgreSQL-DB", uid="user", pwd="password",
                   case="postgresql")
R> sqlSave(con, table.df)
Error in sqlSave(con, table.df) : 
	[RODBC] ERROR: Could not SQLExecDirect
42601 7 [unixODBC]Error while executing the query;
ERROR:  syntax error at or near "end" at character 140
---<---------------cut here---------------end---------------->---


If I rename the column to something else (e.g. "ending"), this proceeds
without problems.  What could the problem be here?  Thanks.


Cheers,

-- 
Seb


From sdavis2 at mail.nih.gov  Tue Feb 20 20:02:15 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 20 Feb 2007 14:02:15 -0500
Subject: [Rd] RODBC problems with unixodbc
In-Reply-To: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
References: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <200702201402.15985.sdavis2@mail.nih.gov>

On Tuesday 20 February 2007 13:51, Sebastian P. Luque wrote:
> Hi,
>
> I noticed that if a column is named "end" in a data frame (table.df
> below), it leads to errors when trying to sqlSave()'it to a postgresql
> connection:
>
>
> ---<---------------cut here---------------start-------------->---
> con <- odbcConnect("PostgreSQL-DB", uid="user", pwd="password",
>                    case="postgresql")
> R> sqlSave(con, table.df)
> Error in sqlSave(con, table.df) :
> 	[RODBC] ERROR: Could not SQLExecDirect
> 42601 7 [unixODBC]Error while executing the query;
> ERROR:  syntax error at or near "end" at character 140
> ---<---------------cut here---------------end---------------->---
>
>
> If I rename the column to something else (e.g. "ending"), this proceeds
> without problems.  What could the problem be here?  Thanks.

"end" is a reserved word in postgresql.  See here:

http://www.postgresql.org/docs/8.2/static/sql-keywords-appendix.html

This doesn't have anything to do with RODBC or unixODBC, I don't think.

Sean


From sdavis2 at mail.nih.gov  Tue Feb 20 20:02:15 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 20 Feb 2007 14:02:15 -0500
Subject: [Rd] RODBC problems with unixodbc
In-Reply-To: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
References: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <200702201402.15985.sdavis2@mail.nih.gov>

On Tuesday 20 February 2007 13:51, Sebastian P. Luque wrote:
> Hi,
>
> I noticed that if a column is named "end" in a data frame (table.df
> below), it leads to errors when trying to sqlSave()'it to a postgresql
> connection:
>
>
> ---<---------------cut here---------------start-------------->---
> con <- odbcConnect("PostgreSQL-DB", uid="user", pwd="password",
>                    case="postgresql")
> R> sqlSave(con, table.df)
> Error in sqlSave(con, table.df) :
> 	[RODBC] ERROR: Could not SQLExecDirect
> 42601 7 [unixODBC]Error while executing the query;
> ERROR:  syntax error at or near "end" at character 140
> ---<---------------cut here---------------end---------------->---
>
>
> If I rename the column to something else (e.g. "ending"), this proceeds
> without problems.  What could the problem be here?  Thanks.

"end" is a reserved word in postgresql.  See here:

http://www.postgresql.org/docs/8.2/static/sql-keywords-appendix.html

This doesn't have anything to do with RODBC or unixODBC, I don't think.

Sean


From vdergachev at rcgardis.com  Tue Feb 20 20:07:55 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Tue, 20 Feb 2007 14:07:55 -0500
Subject: [Rd] RODBC problems with unixodbc
In-Reply-To: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
References: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <200702201407.56078.vdergachev@rcgardis.com>

On Tuesday 20 February 2007 1:51 pm, Sebastian P. Luque wrote:
> Hi,
>
> I noticed that if a column is named "end" in a data frame (table.df
> below), it leads to errors when trying to sqlSave()'it to a postgresql
> connection:
>
>
> ---<---------------cut here---------------start-------------->---
> con <- odbcConnect("PostgreSQL-DB", uid="user", pwd="password",
>                    case="postgresql")
> R> sqlSave(con, table.df)
> Error in sqlSave(con, table.df) :
> 	[RODBC] ERROR: Could not SQLExecDirect
> 42601 7 [unixODBC]Error while executing the query;
> ERROR:  syntax error at or near "end" at character 140
> ---<---------------cut here---------------end---------------->---
>
>
> If I rename the column to something else (e.g. "ending"), this proceeds
> without problems.  What could the problem be here?  Thanks.

It is likely "end" is a reserved word

                     best

                         Vladimir Dergachev

>
>
> Cheers,


From vdergachev at rcgardis.com  Tue Feb 20 20:07:55 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Tue, 20 Feb 2007 14:07:55 -0500
Subject: [Rd] RODBC problems with unixodbc
In-Reply-To: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
References: <87mz38mzlq.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <200702201407.56078.vdergachev@rcgardis.com>

On Tuesday 20 February 2007 1:51 pm, Sebastian P. Luque wrote:
> Hi,
>
> I noticed that if a column is named "end" in a data frame (table.df
> below), it leads to errors when trying to sqlSave()'it to a postgresql
> connection:
>
>
> ---<---------------cut here---------------start-------------->---
> con <- odbcConnect("PostgreSQL-DB", uid="user", pwd="password",
>                    case="postgresql")
> R> sqlSave(con, table.df)
> Error in sqlSave(con, table.df) :
> 	[RODBC] ERROR: Could not SQLExecDirect
> 42601 7 [unixODBC]Error while executing the query;
> ERROR:  syntax error at or near "end" at character 140
> ---<---------------cut here---------------end---------------->---
>
>
> If I rename the column to something else (e.g. "ending"), this proceeds
> without problems.  What could the problem be here?  Thanks.

It is likely "end" is a reserved word

                     best

                         Vladimir Dergachev

>
>
> Cheers,


From tplate at acm.org  Tue Feb 20 20:14:11 2007
From: tplate at acm.org (Tony Plate)
Date: Tue, 20 Feb 2007 12:14:11 -0700
Subject: [Rd] proposal to allow just transcript files (output only) in the
 'tests' directory
Message-ID: <45DB4883.2040700@acm.org>

Currently, as far as I can see, both input and output fles must be 
supplied in the 'tests' directory (the input in a '.R' file, and the 
output in a corresponding '.Rout.save' file.)  Often, the '.R' file is 
redundant, as it could be reconstructed by simply stripping the commands 
out of the '.Rout.save' file.  E.g., the command
$ sed -n -e 's/^[>+] //p' ./src/library/stats/tests/nls.Rout.save
produces the same R commands as in ./src/library/stats/tests/nls.R

If I've missed something, and this is already supported, my apologies, & 
please let me know.

If indeed this facility is not present, would anyone from the R core 
group consider an addition to allow '.Rt' (or '.Rt.save') files in the 
'tests' directory?  These would by just like the '.Rout.save' files, 
except that no corresponding '.R' file would be required -- the R 
commands would be extracted from them by simple line processing.  Of 
course, '.R' and '.Rout.save' files could still be used where necessary 
or preferred.

The primary advantage of this change would be to make it easier to add 
and maintain tests -- only one file would need to be created or changed, 
and no redundant information would be required.  My view is that tests 
should be as easy as possible to create and maintain, and the current 
system adds a small amount of unnecessary difficulty.

If such an addition would be considered, I would be happy to supply 
patches to implement it (and test them in a build under Windows & 
Linux).  I have tested a prototype, and it seems pretty simple to add 
this: as far as I can see, small changes are needed in three files:

./share/make/tests.mk
./src/gnuwin32/fixed/share/tests.mk
./bin/check

Please respond with 
comments/suggestions/corrections/pointing-out-of-gotchas/etc!

thanks,

Tony Plate


From luke at stat.uiowa.edu  Tue Feb 20 20:15:25 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 13:15:25 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <20070220174113.GB5871@wheat.betterworld.us>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<20070220174113.GB5871@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0702201312050.30864@nokomis.stat.uiowa.edu>

On Tue, 20 Feb 2007, Ross Boylan wrote:

> On Tue, Feb 20, 2007 at 07:35:51AM +0000, Prof Brian Ripley wrote:
>> Since you have not told us what 'the documents' are (and only vaguely
>> named one), do you not think your own documentation is inadequate?
> I mean the command description produced by ?tryCatch.
>>
>> There are documents about the condition system on developer.r-project.org:
>> please consult them.
>>
> OK, though I would hope the user level documentation would suffice.
>> I quess 'ctl-C' is your private abbreviation for 'control C' (and not a
>> type of cancer): that generates an interrrupt in most (but not all) R
>> ports.  Where it does, you can set up interrupt handlers (as the help page
>> said)
>>
> My P.S. concerned whether the code that was interrupted could continue
> from the point of interruption.  As far as I can tell from ?tryCatch
> there is not,

Currently interrupts cannot be handled in a way that allows them to
continue at the point of interruption.  On some platforms that is not
possible in all cases, and coming close to it is very difficult.  So
for all practical purposes only tryCatch is currently useful for
interrupt handling.  At some point disabling interrupts will be
possible from the R level but currently I believe it is not.

Best,

luke

>
>>
>> On Mon, 19 Feb 2007, Ross Boylan wrote:
>>
>>> I'm confused by the page documenting tryCatch and friends.
>>>
>>> I think it describes 3 separate mechanisms: tryCatch (in which control
>>> returns to the invoking tryCatch), withCallHandlers (in which control
>>> goes up to the calling handler/s but then continues from the point at
>>> which signalCondition() was invoked), and withRestarts (I can't tell
>>> where control ends up).
>>>
>>> For tryCatch the docs say the arguments ... provide handlers, and that
>>> these are matched to the condition.  It appears that matching works by
>>> providing entries in ... as named arguments, and the handler matches
>>> if the name is one of the classes of the condition.  Is that right?  I
>>> don't see the matching rule explicitly stated.  And then  the handler
>>> itself is a single argument function, where the argument is the
>>> condition?
>>>
>>> My reading is that if some code executes signalCondition and it is
>>> running inside a tryCatch, control will not return to the line after
>>> the signalCondition.  Whereas, if the context is withCallHandlers,
>>> the call to signalCondition does return (with a NULL) and execution
>>> continues.  That seems odd; do I have it right?
>>>
>>> Also, the documents don't explicitly say that the abstract subclasses
>>> of 'error' and 'warning' are subclasses of 'condition', though that
>>> seems to be implied and true.
>>>
>>> It appears that for tryCatch only the first matching handler is
>>> executed, while for withCallHandlers all matching handlers are
>>> executed.
>>>
>>> And, finally, with restarts there is again the issue of how the name
>>> in the name=function form gets matched to the condition, and the more
>>> basic question of what happens.  My guess is that control stays with
>>> the handler, but then this mechanism seems very similar to tryCatch
>>> (with the addition of being able to pass extra arguments to the
>>> handler and  maybe a more flexible handler specification).
>>>
>>> Can anyone clarify any of this?
>>>
>>> P.S. Is there any mechanism that would allow one to trap an interrupt,
>>> like a ctl-C,  so that if the user hit ctl-C some state would be
>>> changed but execution would then continue where it was?  I have in
>>> mind the ctl-C handler setting a "time to finish up" flag which the
>>> maini code checks from time to time.
>>>
>>> Thanks.
>>>
>>> Ross Boylan
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Tue Feb 20 20:40:11 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 13:40:11 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <20070219224141.GA21040@wheat.betterworld.us>
References: <20070219224141.GA21040@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0702201316240.30864@nokomis.stat.uiowa.edu>

On Mon, 19 Feb 2007, Ross Boylan wrote:

> I'm confused by the page documenting tryCatch and friends.
>
> I think it describes 3 separate mechanisms: tryCatch (in which control
> returns to the invoking tryCatch), withCallHandlers (in which control
> goes up to the calling handler/s but then continues from the point at
> which signalCondition() was invoked),

unless a handler does a non-local exit, typically by invoking a restart

> and withRestarts (I can't tell
> where control ends up).

at the withRestarts call

> For tryCatch the docs say the arguments ... provide handlers, and that
> these are matched to the condition.  It appears that matching works by
> providing entries in ... as named arguments, and the handler matches
> if the name is one of the classes of the condition.  Is that right?  I
> don't see the matching rule explicitly stated.  And then  the handler
> itself is a single argument function, where the argument is the
> condition?
>
> My reading is that if some code executes signalCondition and it is
> running inside a tryCatch, control will not return to the line after
> the signalCondition.  Whereas, if the context is withCallHandlers,
> the call to signalCondition does return (with a NULL) and execution
> continues.  That seems odd; do I have it right?

If all the available handlers return normally then signalCondition
returns.  Not odd at all -- analogous to synchronous posix signals.
If you don't want this then write a handler that does a transfer of
control or write a signaling function that uses signalCondition and
provides a default action, i.e. what it does if signalCondition
returns, that does a transfer of control, e.g.  by invoking an "abort"
restart.  This is essentially what stop() does.

>
> Also, the documents don't explicitly say that the abstract subclasses
> of 'error' and 'warning' are subclasses of 'condition', though that
> seems to be implied and true.
>
> It appears that for tryCatch only the first matching handler is
> executed, while for withCallHandlers all matching handlers are
> executed.

All handlers are executed, most recently established first, until
there are none left or there is a transfer of control.  Conceptually,
exiting handlers established with tryCatch execute a transfer of
control and then run their code.

> And, finally, with restarts there is again the issue of how the name
> in the name=function form gets matched to the condition, and the more
> basic question of what happens.  My guess is that control stays with
> the handler, but then this mechanism seems very similar to tryCatch
> (with the addition of being able to pass extra arguments to the
> handler and  maybe a more flexible handler specification).

Restart names, in the simple forms of withRestarts, are names for
points to transfer control to. They are not conditions.  They are used
by condition handlers to find appropriate points to jump to. You can
look at the code for warning() and suppressWarnings() to see an example of
how this is used.

The tryCatch mechanism is quite simple and adequate for most purposes.
The calling handler plus restarts framweork is itended to be rich
enough to allow construction of a variety of frameworks, including
tryCatch, but this power comes at the cost of added complexity.

Hopefully a more extensive document on this will get written in the
next few months; for now the notes available off the developer page
may be useful.

best,

luke

>
> Can anyone clarify any of this?
>
> P.S. Is there any mechanism that would allow one to trap an interrupt,
> like a ctl-C,  so that if the user hit ctl-C some state would be
> changed but execution would then continue where it was?  I have in
> mind the ctl-C handler setting a "time to finish up" flag which the
> maini code checks from time to time.
>
> Thanks.
>
> Ross Boylan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From h.wickham at gmail.com  Tue Feb 20 20:48:00 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 20 Feb 2007 13:48:00 -0600
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>

> Since you have not told us what 'the documents' are (and only vaguely
> named one), do you not think your own documentation is inadequate?
>
> There are documents about the condition system on developer.r-project.org:
> please consult them.

Where exactly?

I tried:

 * reading http://developer.r-project.org/, but couldn't see anything
obvious, and there certainly isn't anything in the pointers section

 * using find on that page to search for "condition", "try"

 * using the google search with keywords: "condition system", "try catch", "try"

Perhaps you could provide a more explicit reference?

Hadley


From bill at insightful.com  Tue Feb 20 20:56:17 2007
From: bill at insightful.com (Bill Dunlap)
Date: Tue, 20 Feb 2007 11:56:17 -0800 (PST)
Subject: [Rd] proposal to allow just transcript files (output only) in
 the 'tests' directory
In-Reply-To: <45DB4883.2040700@acm.org>
References: <45DB4883.2040700@acm.org>
Message-ID: <Pine.GSO.4.56.0702201141300.27827@durian.statsci.com>

On Tue, 20 Feb 2007, Tony Plate wrote:

> Currently, as far as I can see, both input and output fles must be
> supplied in the 'tests' directory (the input in a '.R' file, and the
> output in a corresponding '.Rout.save' file.)  Often, the '.R' file is
> redundant, as it could be reconstructed by simply stripping the commands
> out of the '.Rout.save' file.  E.g., the command
> $ sed -n -e 's/^[>+] //p' ./src/library/stats/tests/nls.Rout.save
> produces the same R commands as in ./src/library/stats/tests/nls.R

Some output lines start with "+ ".  E.g., in
    gamlss/tests/manual.Rout.save
I see
    > mod3<-stepAIC(mod1, scope=list(lower=~1,upper=~(x1+x2+x3+x4+x5+x6)^2))
    Distribution parameter:  mu
    Start:  AIC= 319.16
     y ~ x1 + x2 + x3 + x4 + x5 + x6

            Df    AIC
    + x4:x5  1 307.07
    + x1:x5  1 316.94
    - x6     1 317.16
so R would try to parse "x4:x5  1 307.07".

You could use awk so the "^+ " lines had to immediately
follow "^> " (or a properly preceded "^+ "), but I suspect
there will still be problems.

I have experimented with similar things to compare Splus
and R output for the same commands.  Having the original
input lines helps there.  The hard part is parsing the output
so it can be recognized as a matrix, a vector with names,
an expression, lm() output, etc.  Then I could see that
the following outputs are equivalent:

   R    :
   R    : Call:
   R    : lm(formula = log(x) ~ x, data = list(x = 1:10))
   R    :
   R    : Coefficients:
   R    : (Intercept)            x
   R    :      0.2432       0.2304
   R    :

   Splus: Call:
   Splus: lm(formula = log(x) ~ x, data = list(x = 1:10))
   Splus:
   Splus: Coefficients:
   Splus:  (Intercept)         x
   Splus:    0.2432038 0.2304068
   Splus:
   Splus: Degrees of freedom: 10 total; 8 residual
   Splus: Residual standard error: 0.2388027

This would also be handy for comparing results in different versions of
R, where low level printing routines may be changed a bit.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From ripley at stats.ox.ac.uk  Tue Feb 20 20:59:11 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Feb 2007 19:59:11 +0000 (GMT)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>
References: <20070219224141.GA21040@wheat.betterworld.us> 
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702201955180.14637@gannet.stats.ox.ac.uk>

Look for 'exception' or 'handling':

http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html
http://www.stat.uiowa.edu/~luke/R/exceptions/simplecond.html


On Tue, 20 Feb 2007, hadley wickham wrote:

>> Since you have not told us what 'the documents' are (and only vaguely
>> named one), do you not think your own documentation is inadequate?
>> 
>> There are documents about the condition system on developer.r-project.org:
>> please consult them.
>
> Where exactly?
>
> I tried:
>
> * reading http://developer.r-project.org/, but couldn't see anything
> obvious, and there certainly isn't anything in the pointers section
>
> * using find on that page to search for "condition", "try"
>
> * using the google search with keywords: "condition system", "try catch", 
> "try"
>
> Perhaps you could provide a more explicit reference?
>
> Hadley
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at stat.uiowa.edu  Tue Feb 20 21:02:13 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 14:02:13 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702201401241.30864@nokomis.stat.uiowa.edu>

Search for 'exception'.  THe result points to

http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html

Best,

luke



On Tue, 20 Feb 2007, hadley wickham wrote:

>> Since you have not told us what 'the documents' are (and only vaguely
>> named one), do you not think your own documentation is inadequate?
>>
>> There are documents about the condition system on developer.r-project.org:
>> please consult them.
>
> Where exactly?
>
> I tried:
>
> * reading http://developer.r-project.org/, but couldn't see anything
> obvious, and there certainly isn't anything in the pointers section
>
> * using find on that page to search for "condition", "try"
>
> * using the google search with keywords: "condition system", "try catch", "try"
>
> Perhaps you could provide a more explicit reference?
>
> Hadley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From charles.dupont at vanderbilt.edu  Tue Feb 20 21:47:18 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Tue, 20 Feb 2007 14:47:18 -0600
Subject: [Rd] fix for a major format.pval limitation
Message-ID: <45DB5E56.4000802@vanderbilt.edu>

'format.pval' has a major limitation in its implementation for example 
suppose a person had a vector like 'a' and the error being ?0.001.

    > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
    > format.pval(a, eps=0.001)

The person wants to have the 'format.pval' output with 2 digits always 
showing like this

    [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.001"

How ever format.pval can only display this

    [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.001"

If this was the 'format' function this could be corrected by setting the 
'nsmall' argument to 2.  But 'format.pval' has no ability to pass 
arguments to format.


I think that the best solution would be to give 'format.pval' a '...' 
argument that would get passed to all the 'format' function calls in 
'format.pval'.

I have attached a patch that does this.  This patch is against svn 
r-release-branch and will also apply to r-devel.


Charles Dupont
-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University
-------------- next part --------------
A non-text attachment was scrubbed...
Name: format.pval.patch
Type: text/x-diff
Size: 2008 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070220/4cf183f0/attachment.bin 

From h.wickham at gmail.com  Tue Feb 20 21:49:30 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 20 Feb 2007 14:49:30 -0600
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <Pine.LNX.4.64.0702201401241.30864@nokomis.stat.uiowa.edu>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com>
	<Pine.LNX.4.64.0702201401241.30864@nokomis.stat.uiowa.edu>
Message-ID: <f8e6ff050702201249gb11b6atb01085aa3cddf141@mail.gmail.com>

> Search for 'exception'.  THe result points to
>
> http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html

Thanks Luke (and Brian).  The note is entitled "A Prototype of a
Condition System for R" - can we assume the actual implementation is
as described?

Thanks,

Hadley


From luke at stat.uiowa.edu  Tue Feb 20 22:09:08 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 15:09:08 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <f8e6ff050702201249gb11b6atb01085aa3cddf141@mail.gmail.com>
References: <20070219224141.GA21040@wheat.betterworld.us> 
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk> 
	<f8e6ff050702201148n78325d8kb33b6469ab6acab9@mail.gmail.com> 
	<Pine.LNX.4.64.0702201401241.30864@nokomis.stat.uiowa.edu>
	<f8e6ff050702201249gb11b6atb01085aa3cddf141@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702201506190.2959@nokomis.stat.uiowa.edu>

Qualitatively I believe so.  Names were changed and some details were
changed to better integrate with existing paractice and internals, and
the hook mechanisms used for experimenting are either no longer
available or will be removed before long.  Sorting these things out is
one of the tastks of writing up a pepr on this, which I hioe to get to
within a few months.

Best,

luke

On Tue, 20 Feb 2007, hadley wickham wrote:

>> Search for 'exception'.  THe result points to
>> 
>> http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html
>
> Thanks Luke (and Brian).  The note is entitled "A Prototype of a
> Condition System for R" - can we assume the actual implementation is
> as described?
>
> Thanks,
>
> Hadley
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ross at biostat.ucsf.edu  Tue Feb 20 22:44:16 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 20 Feb 2007 13:44:16 -0800
Subject: [Rd] "try"ing to understand condition handling (interrupts)
In-Reply-To: <Pine.LNX.4.64.0702201312050.30864@nokomis.stat.uiowa.edu>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<20070220174113.GB5871@wheat.betterworld.us>
	<Pine.LNX.4.64.0702201312050.30864@nokomis.stat.uiowa.edu>
Message-ID: <20070220214416.GD5871@wheat.betterworld.us>

[resequencing and deleting for clarity]
On Tue, Feb 20, 2007 at 01:15:25PM -0600, Luke Tierney wrote:
> On Tue, 20 Feb 2007, Ross Boylan wrote:
> >>>P.S. Is there any mechanism that would allow one to trap an interrupt,
> >>>like a ctl-C,  so that if the user hit ctl-C some state would be
> >>>changed but execution would then continue where it was?  I have in
> >>>mind the ctl-C handler setting a "time to finish up" flag which the
> >>>maini code checks from time to time.
> 
> >On Tue, Feb 20, 2007 at 07:35:51AM +0000, Prof Brian Ripley wrote:
...

> >>I quess 'ctl-C' is your private abbreviation for 'control C' (and
> >>not a
[yes, ctl-C = control C, RB]
> >>type of cancer): that generates an interrrupt in most (but not all) R
> >>ports.  Where it does, you can set up interrupt handlers (as the help page
> >>said)
> >>
> >My P.S. concerned whether the code that was interrupted could continue
> >from the point of interruption.  As far as I can tell from ?tryCatch
> >there is not,
> 
> Currently interrupts cannot be handled in a way that allows them to
> continue at the point of interruption.  On some platforms that is not
> possible in all cases, and coming close to it is very difficult.  So
> for all practical purposes only tryCatch is currently useful for
> interrupt handling.  At some point disabling interrupts will be
> possible from the R level but currently I believe it is not.
> 
> Best,
> 
> luke
I had suspected that, since R is not thread-safe, handling
asynchronous events might be challenging.

I tried the following experiment on Linux:

> h<-function(e) print("Got You!")
> f<-function(n, delay) for (i in seq(n)) {Sys.sleep(delay); print(i)}
> withCallingHandlers(f(7,1), interrupt=h)
[1] 1
[1] "Got You!"

So in this case the withCallingHandlers acts like a tryCatch, in that
control does not return to the point of interruption.  However,
sys.calls within h does show where things were just before the
interrupt:
> h<-function(e) {print("Got You!"); print(sys.calls());}
> withCallingHandlers(f(7,1), interrupt=h)
[1] 1
[1] 2
[1] 3
[1] "Got You!"
[[1]]
withCallingHandlers(f(7, 1), interrupt = h)

[[2]]
f(7, 1)

[[3]]
Sys.sleep(delay)

[[4]]
function (e)
{
    print("Got You!")
    print(sys.calls())
}(list())


Ross


From luke at stat.uiowa.edu  Tue Feb 20 23:21:39 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 16:21:39 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling (interrupts)
In-Reply-To: <20070220214416.GD5871@wheat.betterworld.us>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702200725490.1805@gannet.stats.ox.ac.uk>
	<20070220174113.GB5871@wheat.betterworld.us>
	<Pine.LNX.4.64.0702201312050.30864@nokomis.stat.uiowa.edu>
	<20070220214416.GD5871@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0702201615001.25308@itasca2.wildberry.org>

On Tue, 20 Feb 2007, Ross Boylan wrote:

> [resequencing and deleting for clarity]
> On Tue, Feb 20, 2007 at 01:15:25PM -0600, Luke Tierney wrote:
>> On Tue, 20 Feb 2007, Ross Boylan wrote:
>>>>> P.S. Is there any mechanism that would allow one to trap an interrupt,
>>>>> like a ctl-C,  so that if the user hit ctl-C some state would be
>>>>> changed but execution would then continue where it was?  I have in
>>>>> mind the ctl-C handler setting a "time to finish up" flag which the
>>>>> maini code checks from time to time.
>>
>>> On Tue, Feb 20, 2007 at 07:35:51AM +0000, Prof Brian Ripley wrote:
> ...
>
>>>> I quess 'ctl-C' is your private abbreviation for 'control C' (and
>>>> not a
> [yes, ctl-C = control C, RB]
>>>> type of cancer): that generates an interrrupt in most (but not all) R
>>>> ports.  Where it does, you can set up interrupt handlers (as the help page
>>>> said)
>>>>
>>> My P.S. concerned whether the code that was interrupted could continue
>>> from the point of interruption.  As far as I can tell from ?tryCatch
>>> there is not,
>>
>> Currently interrupts cannot be handled in a way that allows them to
>> continue at the point of interruption.  On some platforms that is not
>> possible in all cases, and coming close to it is very difficult.  So
>> for all practical purposes only tryCatch is currently useful for
>> interrupt handling.  At some point disabling interrupts will be
>> possible from the R level but currently I believe it is not.
>>
>> Best,
>>
>> luke
> I had suspected that, since R is not thread-safe, handling
> asynchronous events might be challenging.

This has nothing to do with thread safety.  It has everything to do
with what is safe to do within signal handlers on the one hand and OS
specific variations on what happens when signals interrupt a system
call on the other.

>
> I tried the following experiment on Linux:
>
>> h<-function(e) print("Got You!")
>> f<-function(n, delay) for (i in seq(n)) {Sys.sleep(delay); print(i)}
>> withCallingHandlers(f(7,1), interrupt=h)
> [1] 1
> [1] "Got You!"
>
> So in this case the withCallingHandlers acts like a tryCatch, in that
> control does not return to the point of interruption.  However,
> sys.calls within h does show where things were just before the
> interrupt:
>> h<-function(e) {print("Got You!"); print(sys.calls());}
>> withCallingHandlers(f(7,1), interrupt=h)
> [1] 1
> [1] 2
> [1] 3
> [1] "Got You!"
> [[1]]
> withCallingHandlers(f(7, 1), interrupt = h)
>
> [[2]]
> f(7, 1)
>
> [[3]]
> Sys.sleep(delay)
>
> [[4]]
> function (e)
> {
>    print("Got You!")
>    print(sys.calls())
> }(list())

Experiments like this are useful but don't expect results you get to
be reliable in the future.  What the call stack as shown by sys.xyz
looks like in particular at handling time may change (probably not
much for calling handlers but most likely for exiting ones).

Best,

luke

>
> Ross
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ross at biostat.ucsf.edu  Tue Feb 20 23:35:40 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 20 Feb 2007 14:35:40 -0800
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <Pine.LNX.4.64.0702201316240.30864@nokomis.stat.uiowa.edu>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702201316240.30864@nokomis.stat.uiowa.edu>
Message-ID: <20070220223539.GE5871@wheat.betterworld.us>

Thanks; your response is very helpful.  This message has some remarks
on my questions relative to the developer docs, one additional
question, and some documentation comments.

I'm really glad to hear you plan to revise the exception/condition
docs. since I  found the existing ones a bit murky.

Below, [1] means
http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html,
one of the documents Prof Ripley referred to.

That page also has a nice illustration of using the restart facility.

On Tue, Feb 20, 2007 at 01:40:11PM -0600, Luke Tierney wrote:
> On Mon, 19 Feb 2007, Ross Boylan wrote:
> 
> >I'm confused by the page documenting tryCatch and friends.
> >
> >I think it describes 3 separate mechanisms: tryCatch (in which control
> >returns to the invoking tryCatch), withCallHandlers (in which
  should have been "withCallingHandlers"
> >control
> >goes up to the calling handler/s but then continues from the point at
> >which signalCondition() was invoked),
> 
> unless a handler does a non-local exit, typically by invoking a restart
> 
> >and withRestarts (I can't tell
> >where control ends up).
> 
> at the withRestarts call
> 
> >For tryCatch the docs say the arguments ... provide handlers, and that
> >these are matched to the condition.  It appears that matching works by
> >providing entries in ... as named arguments, and the handler matches
> >if the name is one of the classes of the condition.  Is that right?  I
> >don't see the matching rule explicitly stated.  And then  the handler
> >itself is a single argument function, where the argument is the
> >condition?
>From [1], while discussing tryCatch,

Handlers are specified as

name = fun

where name specifies an exception class and fun is a function of one
argument, the condition that is to be handled.  


...
> >
> >Also, the documents don't explicitly say that the abstract subclasses
> >of 'error' and 'warning' are subclasses of 'condition', though that
> >seems to be implied and true.
The class relations are explicit in [1].

> >
> >It appears that for tryCatch only the first matching handler is
> >executed, while for withCallHandlers all matching handlers are
> >executed.
> 
> All handlers are executed, most recently established first, until
> there are none left or there is a transfer of control.  Conceptually,
> exiting handlers established with tryCatch execute a transfer of
> control and then run their code.

Here's the one point of clarification: does the preceding paragraph
about "all handlers are executed" apply only to withCallingHandlers,
or does it include tryCatch as well?  Rereading ?tryCatch, it still
looks as if the first match only will fire.
....
> 
> Hopefully a more extensive document on this will get written in the
> next few months; for now the notes available off the developer page
> may be useful.
> 
> best,
> 
> luke
Great.  FWIW, here are some suggestions about the documentation:

I would find a presentation that provided an overall orientation and
then worked down easiest to follow.  So, goiing from the top down: 
1. there are 3 forms of exception handling: try/catch, calling
handlers and restarts.
2. the characteristic behavior of each is ... (i.e., what's the flow
of control).  Maybe give a snippet of typical uses of each.
3. the details (exact calling environment of the handler(s), matching
rules, syntax...)
4. try() is basically a convenient form of tryCatch.
5. Other relations between these 3 forms: what happens if they are
nested; how restarts alter the "standard" control flow of the other
forms.  I also found the info that the restart mechanism is the most
general and complicated useful for orientation (that might go under
point 1).

It might be appropriate to document each form on a separate manual
page; I'm not sure if they are too linked (particularly by the use of
conditions and the control flow of restart) to make that a good idea.

I notice that some of the outline above is not the standard R manual
format; maybe the big picture should go in the language manual or on a
concept page (?Exceptions maybe).

Be explicit about the relations between conditions (class inheritance
relations).

Be explicit about how handlers are chosen and which forms they take.

It might be worth mentioning stuff that is a little surprising.  The
fact that the value of  the finally is not the value of the tryCatch
was a little surprising, since usually the value of a series of
statements or expression is that of the last one.  The fact that
signalCondition can participate in two different flows of control
(discussion snipped above) was also surprising to me.  In both cases
the current ?tryCatch is pretty explicit already, so that's not the
issue.

I found the current language (for ?tryCatch) about the calling context
of different handlers a bit obscure.  For example, discussing tryCatch:
   " If a handler
     is found then control is transferred to the 'tryCatch' call that
     established the handler, the handler found and all more recent
     handlers are disestablished, the handler is called with the
     condition as its argument, and the result returned by the handler
     is returned as the value of the 'tryCatch' call."
It seems to me that control is transferred to within the tryCatch
call, rather than to the call itself.  I'd expect transferring control
to the call to re-execute the whole thing, ad infinitum.  I found the
seemingly less formal description in [1] easier to grasp:
" When an exception is signaled, the most recently established handler
that matches the exception (for which the exception inherits from the
specified class) is chosen, control transfers back to the try.catch
expression, the handler function is called, and the value returned by
the handler function is returned by the try.catch call. "

?tryCatch refers to "up" and "down" the stack in a few places.
Although there is really only one plausible reading, referring to
handlers established before or after the focal handler might be
clearer (at least in my head, I have an image of call stacks sometimes
going down in physical memory as they grow).

Ross


From luke at stat.uiowa.edu  Wed Feb 21 00:28:24 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Feb 2007 17:28:24 -0600 (CST)
Subject: [Rd] "try"ing to understand condition handling
In-Reply-To: <20070220223539.GE5871@wheat.betterworld.us>
References: <20070219224141.GA21040@wheat.betterworld.us>
	<Pine.LNX.4.64.0702201316240.30864@nokomis.stat.uiowa.edu>
	<20070220223539.GE5871@wheat.betterworld.us>
Message-ID: <Pine.LNX.4.64.0702201653050.25308@itasca2.wildberry.org>

On Tue, 20 Feb 2007, Ross Boylan wrote:

> Thanks; your response is very helpful.  This message has some remarks
> on my questions relative to the developer docs, one additional
> question, and some documentation comments.
>
> I'm really glad to hear you plan to revise the exception/condition
> docs. since I  found the existing ones a bit murky.
>
> Below, [1] means
> http://www.stat.uiowa.edu/~luke/R/exceptions/simpcond.html,
> one of the documents Prof Ripley referred to.
>
> That page also has a nice illustration of using the restart facility.
>
> On Tue, Feb 20, 2007 at 01:40:11PM -0600, Luke Tierney wrote:
>> On Mon, 19 Feb 2007, Ross Boylan wrote:
>>
>>> I'm confused by the page documenting tryCatch and friends.
>>>
>>> I think it describes 3 separate mechanisms: tryCatch (in which control
>>> returns to the invoking tryCatch), withCallHandlers (in which
>  should have been "withCallingHandlers"
>>> control
>>> goes up to the calling handler/s but then continues from the point at
>>> which signalCondition() was invoked),
>>
>> unless a handler does a non-local exit, typically by invoking a restart
>>
>>> and withRestarts (I can't tell
>>> where control ends up).
>>
>> at the withRestarts call
>>
>>> For tryCatch the docs say the arguments ... provide handlers, and that
>>> these are matched to the condition.  It appears that matching works by
>>> providing entries in ... as named arguments, and the handler matches
>>> if the name is one of the classes of the condition.  Is that right?  I
>>> don't see the matching rule explicitly stated.  And then  the handler
>>> itself is a single argument function, where the argument is the
>>> condition?
> From [1], while discussing tryCatch,
>
> Handlers are specified as
>
> name = fun
>
> where name specifies an exception class and fun is a function of one
> argument, the condition that is to be handled.
>
>
> ...
>>>
>>> Also, the documents don't explicitly say that the abstract subclasses
>>> of 'error' and 'warning' are subclasses of 'condition', though that
>>> seems to be implied and true.
> The class relations are explicit in [1].
>
>>>
>>> It appears that for tryCatch only the first matching handler is
>>> executed, while for withCallHandlers all matching handlers are
>>> executed.
>>
>> All handlers are executed, most recently established first, until
>> there are none left or there is a transfer of control.  Conceptually,
>> exiting handlers established with tryCatch execute a transfer of
>> control and then run their code.
>
> Here's the one point of clarification: does the preceding paragraph
> about "all handlers are executed" apply only to withCallingHandlers,
> or does it include tryCatch as well?  Rereading ?tryCatch, it still
> looks as if the first match only will fire.
> ....

Only to calling handlers because exiting ones conceptually execute a
transfer of control out of the loop over the eligible handlers.

[In principle tryCatch can be written in terms of withCallingHandlers
using callCC to transfer control (callCC will be in R-devel shortly
and corresponds to callcc in [1]).  The expression

     tryCatch(expr, c1 = h1, c2 = h2)

is essentially equivalent to something like (untested but hopefully close)

     cond <- NULL
     h <- NULL
     v <- callCC(function(k)
         withCallingHandlers(expr,
                             c1 = function(c) { cond <<- c; h <<- h1; k(NULL)},
                             c2 = function(c) { cond <<- c; h <<- h2; k(NULL)}))
     if (is.null(h)) value
     else h(cond)

Matching calling handlers are applied one at a time, but if one of
these two matches then the call k(NULL) causes an immediate return
from callCC with value NULL.  If this doesn't help, ignore it.]

>>
>> Hopefully a more extensive document on this will get written in the
>> next few months; for now the notes available off the developer page
>> may be useful.
>>
>> best,
>>
>> luke
> Great.  FWIW, here are some suggestions about the documentation:
>
> I would find a presentation that provided an overall orientation and
> then worked down easiest to follow.  So, goiing from the top down:
> 1. there are 3 forms of exception handling: try/catch, calling
> handlers and restarts.
> 2. the characteristic behavior of each is ... (i.e., what's the flow
> of control).  Maybe give a snippet of typical uses of each.
> 3. the details (exact calling environment of the handler(s), matching
> rules, syntax...)
> 4. try() is basically a convenient form of tryCatch.
> 5. Other relations between these 3 forms: what happens if they are
> nested; how restarts alter the "standard" control flow of the other
> forms.  I also found the info that the restart mechanism is the most
> general and complicated useful for orientation (that might go under
> point 1).
>
> It might be appropriate to document each form on a separate manual
> page; I'm not sure if they are too linked (particularly by the use of
> conditions and the control flow of restart) to make that a good idea.
>
> I notice that some of the outline above is not the standard R manual
> format; maybe the big picture should go in the language manual or on a
> concept page (?Exceptions maybe).
>
> Be explicit about the relations between conditions (class inheritance
> relations).
>
> Be explicit about how handlers are chosen and which forms they take.
>
> It might be worth mentioning stuff that is a little surprising.  The
> fact that the value of  the finally is not the value of the tryCatch
> was a little surprising, since usually the value of a series of
> statements or expression is that of the last one.  The fact that
> signalCondition can participate in two different flows of control
> (discussion snipped above) was also surprising to me.  In both cases
> the current ?tryCatch is pretty explicit already, so that's not the
> issue.
>
> I found the current language (for ?tryCatch) about the calling context
> of different handlers a bit obscure.  For example, discussing tryCatch:
>   " If a handler
>     is found then control is transferred to the 'tryCatch' call that
>     established the handler, the handler found and all more recent
>     handlers are disestablished, the handler is called with the
>     condition as its argument, and the result returned by the handler
>     is returned as the value of the 'tryCatch' call."
> It seems to me that control is transferred to within the tryCatch
> call, rather than to the call itself.  I'd expect transferring control
> to the call to re-execute the whole thing, ad infinitum.  I found the
> seemingly less formal description in [1] easier to grasp:
> " When an exception is signaled, the most recently established handler
> that matches the exception (for which the exception inherits from the
> specified class) is chosen, control transfers back to the try.catch
> expression, the handler function is called, and the value returned by
> the handler function is returned by the try.catch call. "
>
> ?tryCatch refers to "up" and "down" the stack in a few places.
> Although there is really only one plausible reading, referring to
> handlers established before or after the focal handler might be
> clearer (at least in my head, I have an image of call stacks sometimes
> going down in physical memory as they grow).
>

Thanks for the suggestions.  Will keep them in mind for the revision.

Best,

luke


> Ross
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From x.sole at iconcologia.net  Wed Feb 21 13:54:07 2007
From: x.sole at iconcologia.net (Sole Acha, Xavi)
Date: Wed, 21 Feb 2007 13:54:07 +0100
Subject: [Rd] R unstable and crashes after executing .C
Message-ID: <5FF3F11444E3A9439191AA1EDCB69A17B86201@icosrvmail01.ICO.SCS.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070221/872fd9e6/attachment.pl 

From osklyar at ebi.ac.uk  Wed Feb 21 14:16:23 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Wed, 21 Feb 2007 13:16:23 +0000
Subject: [Rd] R unstable and crashes after executing .C
In-Reply-To: <5FF3F11444E3A9439191AA1EDCB69A17B86201@icosrvmail01.ICO.SCS.local>
References: <5FF3F11444E3A9439191AA1EDCB69A17B86201@icosrvmail01.ICO.SCS.local>
Message-ID: <45DC4627.1010605@ebi.ac.uk>

There are many packages around that use .C and .Call interfaces with 
really huge objects and still are pretty stable. The error is most 
likely in your own C code and it most likely to be connected to memory 
allocation/deallocation or array indexing, but without having the code 
here no one will be able to help further.

Oleg

Sole Acha, Xavi wrote:
> Dear R listers,
> 
>  
> 
> I have developed a C function to be executed from R through the ".C" interface. After doing dyn.load, the function executes properly and I get the results. However, after executing my function, R seems to get unstable and crashes (giving a segmentation fault and exiting) whenever I try to do ANYTHING with a relatively large object (creating a new one or even just writing the name of an existing one). 
> 
>  
> 
> I use R 2.4.0 under a Linux machine with 1 GB RAM. Below there is an example of execution, so you can get an idea of what is happening:
> 
>  
> 
> --------------------
> 
> dyn.load("my_C_module.so");
> 
> res <- .C("my_C_function",.....); #The function executes fine and res is ok
> 
> dyn.unload("my_C_module.so") #I know this isn't strictly necessary
> 
>  
> 
> #Here R is still running, but when I execute:
> 
>  
> 
> m <- matrix(0,1000,100); #I try to create a new object and R crashes
> 
>  
> 
> *** caught segfault ***
> 
> address 0x10, cause 'memory not mapped'
> 
>  
> 
> Traceback:
> 
>  1: matrix(0, 1000, 100)
> 
>  
> 
> Possible actions:
> 
> 1: abort (with core dump)
> 
> 2: normal R exit
> 
> 3: exit R without saving workspace
> 
> 4: exit R saving workspace
> 
> --------------------
> 
>  
> 
> Although I tell R to abort and give me the core dump, it doesn't succeed in doing so.
> 
>  
> 
> I would be grateful if anyone could tell me what could be the problem with my C function that makes R behave this way?
> 
>  
> 
> Thank you very much in advance, and apologies for this long email.
> 
>  
> 
> Xavier Sol?.
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Oleg Sklyar * EBI/EMBL, Cambridge CB10 1SD, England * +44-1223-494466


From ripley at stats.ox.ac.uk  Wed Feb 21 14:32:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Feb 2007 13:32:10 +0000 (GMT)
Subject: [Rd] R unstable and crashes after executing .C
In-Reply-To: <5FF3F11444E3A9439191AA1EDCB69A17B86201@icosrvmail01.ICO.SCS.local>
References: <5FF3F11444E3A9439191AA1EDCB69A17B86201@icosrvmail01.ICO.SCS.local>
Message-ID: <Pine.LNX.4.64.0702211331250.10793@auk.stats>

Please do as I suggested in my reply to your message to R-help!
And do read the posting guide and not send HMTL mail.

On Wed, 21 Feb 2007, Sole Acha, Xavi wrote:

> Dear R listers,
>
>
>
> I have developed a C function to be executed from R through the ".C" interface. After doing dyn.load, the function executes properly and I get the results. However, after executing my function, R seems to get unstable and crashes (giving a segmentation fault and exiting) whenever I try to do ANYTHING with a relatively large object (creating a new one or even just writing the name of an existing one).
>
>
>
> I use R 2.4.0 under a Linux machine with 1 GB RAM. Below there is an example of execution, so you can get an idea of what is happening:
>
>
>
> --------------------
>
> dyn.load("my_C_module.so");
>
> res <- .C("my_C_function",.....); #The function executes fine and res is ok
>
> dyn.unload("my_C_module.so") #I know this isn't strictly necessary
>
>
>
> #Here R is still running, but when I execute:
>
>
>
> m <- matrix(0,1000,100); #I try to create a new object and R crashes
>
>
>
> *** caught segfault ***
>
> address 0x10, cause 'memory not mapped'
>
>
>
> Traceback:
>
> 1: matrix(0, 1000, 100)
>
>
>
> Possible actions:
>
> 1: abort (with core dump)
>
> 2: normal R exit
>
> 3: exit R without saving workspace
>
> 4: exit R saving workspace
>
> --------------------
>
>
>
> Although I tell R to abort and give me the core dump, it doesn't succeed in doing so.
>
>
>
> I would be grateful if anyone could tell me what could be the problem with my C function that makes R behave this way?
>
>
>
> Thank you very much in advance, and apologies for this long email.
>
>
>
> Xavier Sol?.
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From vdergachev at rcgardis.com  Wed Feb 21 19:25:23 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Wed, 21 Feb 2007 13:25:23 -0500
Subject: [Rd] JIT compiler library
Message-ID: <200702211325.23611.vdergachev@rcgardis.com>


Since this escaped my notice before, I thought it useful to post a link here - 
in case you have not seen it either:

http://www.gnu.org/software/lightning/lightning.html

This a portable JIT compiler library with fairly easy syntax (one syntax - 
many cpus).

                      best

                          Vladimir Dergachev


From mgd at santafe.edu  Wed Feb 21 19:54:42 2007
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Wed, 21 Feb 2007 11:54:42 -0700
Subject: [Rd] JIT compiler library
In-Reply-To: <200702211325.23611.vdergachev@rcgardis.com>
References: <200702211325.23611.vdergachev@rcgardis.com>
Message-ID: <45DC9572.4090505@santafe.edu>

Vladimir Dergachev wrote:
> Since this escaped my notice before, I thought it useful to post a link here - 
> in case you have not seen it either:
>
> http://www.gnu.org/software/lightning/lightning.html
>
> This a portable JIT compiler library with fairly easy syntax (one syntax - 
> many cpus).
>   
I think it hasn't been worked on for quite a while, though.   Or has it 
development picked up again?
Another idea is LLVM  http://llvm.org


From ahmed_9473 at yahoo.com  Wed Feb 21 20:12:06 2007
From: ahmed_9473 at yahoo.com (ahmed sedky)
Date: Wed, 21 Feb 2007 11:12:06 -0800 (PST)
Subject: [Rd] "Re: Contents of R-devel digest..."
Message-ID: <211979.29084.qm@web31908.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070221/163f7ba7/attachment.pl 

From byron.ellis at gmail.com  Wed Feb 21 21:30:50 2007
From: byron.ellis at gmail.com (Byron Ellis)
Date: Wed, 21 Feb 2007 12:30:50 -0800
Subject: [Rd] JIT compiler library
In-Reply-To: <45DC9572.4090505@santafe.edu>
References: <200702211325.23611.vdergachev@rcgardis.com>
	<45DC9572.4090505@santafe.edu>
Message-ID: <7098abec0702211230y3ed4f073ra09b20126ac90c2e@mail.gmail.com>

I think work on Lightning picked up again when the work on GNU
Smalltalk started picking up again (there have been something like 4
or 5 releases in the last 6 months). IIRC it's a bit more lightweight
than LLVM.

On 2/21/07, Marcus G. Daniels <mgd at santafe.edu> wrote:
> Vladimir Dergachev wrote:
> > Since this escaped my notice before, I thought it useful to post a link here -
> > in case you have not seen it either:
> >
> > http://www.gnu.org/software/lightning/lightning.html
> >
> > This a portable JIT compiler library with fairly easy syntax (one syntax -
> > many cpus).
> >
> I think it hasn't been worked on for quite a while, though.   Or has it
> development picked up again?
> Another idea is LLVM  http://llvm.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From mtmorgan at fhcrc.org  Wed Feb 21 23:09:44 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 21 Feb 2007 14:09:44 -0800
Subject: [Rd] non-interactive R_tryEval does not return
Message-ID: <6phmz37go2f.fsf@gopher4.fhcrc.org>

...at least I think that is what happens, at least on some
configurations. Here's a repeatable example:

cd R_HOME/tests/Embedding
touch tmp.R
make tryEval

and then (correct)

> ./tryEval --slave
Error in sqrt("") : Non-numeric argument to mathematical function
Caught an error calling sqrt(). Try again with a different argument.
[1] 3

versus (non-interactive; no return)

> ./tryEval --slave < tmp.R
Error in sqrt("") : Non-numeric argument to mathematical function
Execution halted

> echo "sessionInfo()" | R --slave
R version 2.5.0 Under development (unstable) (2007-02-21 r40774) 
x86_64-unknown-linux-gnu 

locale:
LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"
-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From jeff.horner at vanderbilt.edu  Wed Feb 21 23:23:46 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 21 Feb 2007 16:23:46 -0600
Subject: [Rd] Adding difftime objects to POSIXt objects
Message-ID: <45DCC672.8070807@vanderbilt.edu>

Hello,

?DateTimeClasses states that "one can add or subtract a number of 
seconds or a 'difftime' object from a date-time object, but not add two 
date-time objects."

So, is the below expected behavior?

 > x <- Sys.time()
 > x
[1] "2007-02-21 16:19:56 CST"
 > x + as.difftime("1","%H")
[1] "2007-02-21 16:19:57 CST"
Warning message:
Incompatible methods ("+.POSIXt", "Ops.difftime") for "+"

"+.POSIXt" does behave as expected, though:

 > "+.POSIXt"(x,as.difftime("1","%H"))
[1] "2007-02-21 17:19:56 CST"

 > R.version
                _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          5.0
year           2007
month          01
day            07
svn rev        40398
language       R
version.string R version 2.5.0 Under development (unstable) (2007-01-07 
r40398)

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Feb 21 23:37:29 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Wed, 21 Feb 2007 23:37:29 +0100
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <6phmz37go2f.fsf@gopher4.fhcrc.org>
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
Message-ID: <200702212337.33350.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Wednesday 21 February 2007 23:09, Martin Morgan wrote:
> > ./tryEval --slave < tmp.R
>
> Error in sqrt("") : Non-numeric argument to mathematical function
> Execution halted

To force interactive use (when embedding), you can set R_Interactive (from 
Rinterface.h) to TRUE, after Rf_initEmbeddedR().

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070221/bc539942/attachment.bin 

From jeff.horner at vanderbilt.edu  Wed Feb 21 23:45:25 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 21 Feb 2007 16:45:25 -0600
Subject: [Rd] Adding difftime objects to POSIXt objects
In-Reply-To: <45DCC672.8070807@vanderbilt.edu>
References: <45DCC672.8070807@vanderbilt.edu>
Message-ID: <45DCCB85.50000@vanderbilt.edu>

Jeffrey Horner wrote:
> Hello,
> 
> ?DateTimeClasses states that "one can add or subtract a number of 
> seconds or a 'difftime' object from a date-time object, but not add two 
> date-time objects."
> 
> So, is the below expected behavior?
> 
>  > x <- Sys.time()
>  > x
> [1] "2007-02-21 16:19:56 CST"
>  > x + as.difftime("1","%H")
> [1] "2007-02-21 16:19:57 CST"
> Warning message:
> Incompatible methods ("+.POSIXt", "Ops.difftime") for "+"
> 
> "+.POSIXt" does behave as expected, though:
> 
>  > "+.POSIXt"(x,as.difftime("1","%H"))
> [1] "2007-02-21 17:19:56 CST"
> 
>  > R.version
>                 _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          5.0
> year           2007
> month          01
> day            07
> svn rev        40398
> language       R
> version.string R version 2.5.0 Under development (unstable) (2007-01-07 
> r40398)

Oops! I thought I ran this on the latest revision, but the same behavior 
is exhibited in r40774:

 > x <- Sys.time()
 > x
[1] "2007-02-21 16:44:16 CST"
 > x + as.difftime("1","%H")
[1] "2007-02-21 16:44:17 CST"
Warning message:
Incompatible methods ("+.POSIXt", "Ops.difftime") for "+"
 > R.version
                _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          5.0
year           2007
month          02
day            21
svn rev        40774
language       R
version.string R version 2.5.0 Under development (unstable) (2007-02-21 
r40774)


Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From mtmorgan at fhcrc.org  Wed Feb 21 23:53:32 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 21 Feb 2007 14:53:32 -0800
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <200702212337.33350.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	(Thomas
	Friedrichsmeier's message of "Wed, 21 Feb 2007 23:37:29 +0100")
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
	<200702212337.33350.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <6phejojgm1f.fsf@gopher4.fhcrc.org>

Yes, I know this, but R then acts as though it were interactive!
Thanks for the suggestion though. Martin

Thomas Friedrichsmeier <thomas.friedrichsmeier at ruhr-uni-bochum.de> writes:

> On Wednesday 21 February 2007 23:09, Martin Morgan wrote:
>> > ./tryEval --slave < tmp.R
>>
>> Error in sqrt("") : Non-numeric argument to mathematical function
>> Execution halted
>
> To force interactive use (when embedding), you can set R_Interactive (from 
> Rinterface.h) to TRUE, after Rf_initEmbeddedR().
>
> Regards
> Thomas Friedrichsmeier
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From ripley at stats.ox.ac.uk  Wed Feb 21 23:58:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Feb 2007 22:58:04 +0000 (GMT)
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <6phmz37go2f.fsf@gopher4.fhcrc.org>
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk>

Yes, this is as expected/documented (in so far as R_tryEval is 
documented: it is not part of the API, as far as I am aware).

Its point is to be the equivalent of submitting an expression from the 
toplevel and returning to the toplevel, without using R_ReadConsole. So it 
behaves in just the same ways as any other R session with respect to 
R errors.

I think in all the intended uses R would be in interactive mode, and I 
suspect it is an oversight that Rf_initEmbeddedR does not set that on 
Unix-alikes (it does on Windows).  You can set R_Interactive afterwards, 
of course.


On Wed, 21 Feb 2007, Martin Morgan wrote:

> ...at least I think that is what happens, at least on some
> configurations. Here's a repeatable example:
>
> cd R_HOME/tests/Embedding
> touch tmp.R
> make tryEval
>
> and then (correct)
>
>> ./tryEval --slave
> Error in sqrt("") : Non-numeric argument to mathematical function
> Caught an error calling sqrt(). Try again with a different argument.
> [1] 3
>
> versus (non-interactive; no return)
>
>> ./tryEval --slave < tmp.R
> Error in sqrt("") : Non-numeric argument to mathematical function
> Execution halted
>
>> echo "sessionInfo()" | R --slave
> R version 2.5.0 Under development (unstable) (2007-02-21 r40774)
> x86_64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 22 00:10:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Feb 2007 23:10:46 +0000 (GMT)
Subject: [Rd] Adding difftime objects to POSIXt objects
In-Reply-To: <45DCCB85.50000@vanderbilt.edu>
References: <45DCC672.8070807@vanderbilt.edu> <45DCCB85.50000@vanderbilt.edu>
Message-ID: <Pine.LNX.4.64.0702212307480.12540@gannet.stats.ox.ac.uk>

This is known, and not easy to solve given the way dispatch works for 
binary operators.

The documentation was broken when Ops.difftime was introduced.  You have 
found the known fix ....

On Wed, 21 Feb 2007, Jeffrey Horner wrote:

> Jeffrey Horner wrote:
>> Hello,
>>
>> ?DateTimeClasses states that "one can add or subtract a number of
>> seconds or a 'difftime' object from a date-time object, but not add two
>> date-time objects."
>>
>> So, is the below expected behavior?
>>
>> > x <- Sys.time()
>> > x
>> [1] "2007-02-21 16:19:56 CST"
>> > x + as.difftime("1","%H")
>> [1] "2007-02-21 16:19:57 CST"
>> Warning message:
>> Incompatible methods ("+.POSIXt", "Ops.difftime") for "+"
>>
>> "+.POSIXt" does behave as expected, though:
>>
>> > "+.POSIXt"(x,as.difftime("1","%H"))
>> [1] "2007-02-21 17:19:56 CST"
>>
>> > R.version
>>                 _
>> platform       i686-pc-linux-gnu
>> arch           i686
>> os             linux-gnu
>> system         i686, linux-gnu
>> status         Under development (unstable)
>> major          2
>> minor          5.0
>> year           2007
>> month          01
>> day            07
>> svn rev        40398
>> language       R
>> version.string R version 2.5.0 Under development (unstable) (2007-01-07
>> r40398)
>
> Oops! I thought I ran this on the latest revision, but the same behavior
> is exhibited in r40774:
>
> > x <- Sys.time()
> > x
> [1] "2007-02-21 16:44:16 CST"
> > x + as.difftime("1","%H")
> [1] "2007-02-21 16:44:17 CST"
> Warning message:
> Incompatible methods ("+.POSIXt", "Ops.difftime") for "+"
> > R.version
>                _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          5.0
> year           2007
> month          02
> day            21
> svn rev        40774
> language       R
> version.string R version 2.5.0 Under development (unstable) (2007-02-21
> r40774)
>
>
> Jeff
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Feb 22 00:13:19 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 22 Feb 2007 00:13:19 +0100
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <6phejojgm1f.fsf@gopher4.fhcrc.org>
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
	<200702212337.33350.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<6phejojgm1f.fsf@gopher4.fhcrc.org>
Message-ID: <200702220013.23155.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Wednesday 21 February 2007 23:53, Martin Morgan wrote:
> Yes, I know this, but R then acts as though it were interactive!
> Thanks for the suggestion though. Martin

If that is a problem, another way around it would be to set options("error") 
instead.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070222/03a806ea/attachment.bin 

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Feb 22 00:36:17 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 22 Feb 2007 00:36:17 +0100
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk>
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
	<Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk>
Message-ID: <200702220036.21500.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Wednesday 21 February 2007 23:58, Prof Brian Ripley wrote:
> Yes, this is as expected/documented (in so far as R_tryEval is
> documented: it is not part of the API, as far as I am aware).

Fortunately, it is part of the API.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070222/c34201f4/attachment.bin 

From mtmorgan at fhcrc.org  Thu Feb 22 01:28:48 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 21 Feb 2007 16:28:48 -0800
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Wed, 21 Feb 2007 22:58:04 +0000 (GMT)")
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
	<Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk>
Message-ID: <6ph8xerghmn.fsf@gopher4.fhcrc.org>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Yes, this is as expected/documented (in so far as R_tryEval is
> documented: it is not part of the API, as far as I am aware).
>
> Its point is to be the equivalent of submitting an expression from the
> toplevel and returning to the toplevel, without using
> R_ReadConsole. So it behaves in just the same ways as any other R
> session with respect to R errors.

Unpacking the above a bit, I guess the meaning of 'as expected /
documented' is that in non-interactive modes errors halt R (in
errors.c just before LONGJMP(R_ToplevelContext->cjmpbuf, 0)). This
does not seem quite consistent with the idea that R_tryEval is 'the
equivalent of submitting an expression from the toplevel and returning
to the toplevel', since in this case there is no return to the top
level.  This tension is where my problem came from.

> I think in all the intended uses R would be in interactive mode, and I
> suspect it is an oversight that Rf_initEmbeddedR does not set that on
> Unix-alikes (it does on Windows).  You can set R_Interactive
> afterwards, of course.

Alternative GUIs might want an interactive, embedded R. I would have
thought other uses (web services for me) would rather a
non-interactive embedded R. Whatever the case, I likely over-worried
the consequences of R_Interactive=TRUE; it seems only to matter with
plots, or when there is a segfault (plus whatever user packages might
choose to do differently in response to interactive()).

Thanks to both for the help,

Martin

> On Wed, 21 Feb 2007, Martin Morgan wrote:
>
>> ...at least I think that is what happens, at least on some
>> configurations. Here's a repeatable example:
>>
>> cd R_HOME/tests/Embedding
>> touch tmp.R
>> make tryEval
>>
>> and then (correct)
>>
>>> ./tryEval --slave
>> Error in sqrt("") : Non-numeric argument to mathematical function
>> Caught an error calling sqrt(). Try again with a different argument.
>> [1] 3
>>
>> versus (non-interactive; no return)
>>
>>> ./tryEval --slave < tmp.R
>> Error in sqrt("") : Non-numeric argument to mathematical function
>> Execution halted
>>
>>> echo "sessionInfo()" | R --slave
>> R version 2.5.0 Under development (unstable) (2007-02-21 r40774)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From ripley at stats.ox.ac.uk  Thu Feb 22 07:38:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 06:38:58 +0000 (GMT)
Subject: [Rd] non-interactive R_tryEval does not return
In-Reply-To: <200702220036.21500.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <6phmz37go2f.fsf@gopher4.fhcrc.org>
	<Pine.LNX.4.64.0702212231510.12540@gannet.stats.ox.ac.uk>
	<200702220036.21500.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <Pine.LNX.4.64.0702220636100.1112@gannet.stats.ox.ac.uk>

On Thu, 22 Feb 2007, Thomas Friedrichsmeier wrote:

> On Wednesday 21 February 2007 23:58, Prof Brian Ripley wrote:
>> Yes, this is as expected/documented (in so far as R_tryEval is
>> documented: it is not part of the API, as far as I am aware).
>
> Fortunately, it is part of the API.

I was unaware that you were the arbiter of what is part of the API.
R_tryEval is not mentioned in 'Writing R Extensions', which is.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ellis at stat.harvard.edu  Thu Feb 22 09:25:22 2007
From: ellis at stat.harvard.edu (ellis at stat.harvard.edu)
Date: Thu, 22 Feb 2007 09:25:22 +0100 (CET)
Subject: [Rd] R_tryEval not properly documented in 'Writing R Extensions'
	(PR#9524)
Message-ID: <20070222082522.AEB815ACA2@slim.kubism.ku.dk>

Full_Name: Byron Ellis
Version: 2.4.1
OS: N/A
Submission from: (NULL) (75.55.126.10)


R_tryEval is implied to be in the public API by 'Embedding R in Other
Applications,' but not documented in 'Writing R Extensions.' This would seem to
be an oversight given the dependence of many applications including but not
limited to the official OS X GUI on this function.


From ripley at stats.ox.ac.uk  Thu Feb 22 10:02:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 09:02:20 +0000 (GMT)
Subject: [Rd] R_tryEval not properly documented in 'Writing R
 Extensions' (PR#9524)
In-Reply-To: <20070222082522.AEB815ACA2@slim.kubism.ku.dk>
References: <20070222082522.AEB815ACA2@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0702220851500.3102@gannet.stats.ox.ac.uk>

On Thu, 22 Feb 2007, ellis at stat.harvard.edu wrote:

> Full_Name: Byron Ellis
> Version: 2.4.1
> OS: N/A
> Submission from: (NULL) (75.55.126.10)
>
>
> R_tryEval is implied to be in the public API by 'Embedding R in Other
> Applications,' but not documented in 'Writing R Extensions.' This would seem to
> be an oversight given the dependence of many applications including but not
> limited to the official OS X GUI on this function.

It is not an oversight.  R_tryEval is as far as the R sources are 
concerned just part of the test examples for embedding.

I think you may be referring to

http://developer.r-project.org/embedded.html

That does not list R_tryEval in 'Routines for the Embedded R', so makes no 
such implication (and in any case dates from 2000, before there was a 
documented interface).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 22 10:02:39 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 22 Feb 2007 10:02:39 +0100 (CET)
Subject: [Rd] R_tryEval not properly documented in 'Writing R
	Extensions' (PR#9525)
Message-ID: <20070222090239.5BD0F5D5B7@slim.kubism.ku.dk>

On Thu, 22 Feb 2007, ellis at stat.harvard.edu wrote:

> Full_Name: Byron Ellis
> Version: 2.4.1
> OS: N/A
> Submission from: (NULL) (75.55.126.10)
>
>
> R_tryEval is implied to be in the public API by 'Embedding R in Other
> Applications,' but not documented in 'Writing R Extensions.' This would seem to
> be an oversight given the dependence of many applications including but not
> limited to the official OS X GUI on this function.

It is not an oversight.  R_tryEval is as far as the R sources are 
concerned just part of the test examples for embedding.

I think you may be referring to

http://developer.r-project.org/embedded.html

That does not list R_tryEval in 'Routines for the Embedded R', so makes no 
such implication (and in any case dates from 2000, before there was a 
documented interface).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Feb 22 12:02:32 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Feb 2007 06:02:32 -0500
Subject: [Rd] rgl update:  please test!
Message-ID: <45DD7848.70602@stats.uwo.ca>

(This is bcc'd to a list of people who have had problems with rgl lately 
or who are known to be big users; not cc'd, so you don't all get cc'd 
all the responses on the R-devel list).

I've just put together a test build of rgl, and put it on my web site as

http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.tar.gz 
(source)

and

http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.zip 
(Windows binary).

This includes a number of changes:

   - changes to configure script from Laszlo Kajan and Brian Ripley: 
should now be much more portable
   - removed deprecated OSX font setting calls
   - texture properties are now returned by material3d()
   - allowed normals and texture coordinates to be specified in 
triangles and quads
   - normals may be specified in qmesh objects, but (at present) 
subdivide removes them
   - material3d() now preserves the values of unspecified parameters (as 
documented, but not previously functioning)
   - open3d() now resets all material properties to the defaults.

Could people who have been having problems with rgl (or just making use 
of it) please test this update?  Some of the changes are very recent, 
and may still be buggy:  but I'm going offline from late tomorrow until 
March 4, so I'm not going to have an opportunity to test them myself 
well enough to want to send this to CRAN.

I'm hoping to send this to CRAN soon after I return.

Duncan Murdoch


From ellis at stat.harvard.edu  Thu Feb 22 20:50:09 2007
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Thu, 22 Feb 2007 11:50:09 -0800
Subject: [Rd] R_tryEval not properly documented in 'Writing R
	Extensions' (PR#9524)
In-Reply-To: <Pine.LNX.4.64.0702220851500.3102@gannet.stats.ox.ac.uk>
References: <20070222082522.AEB815ACA2@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0702220851500.3102@gannet.stats.ox.ac.uk>
Message-ID: <7098abec0702221150i1455d126o59862ae7e7ad2040@mail.gmail.com>

Considering the lack of embedding documentation until relatively
recently, the fact that the function appeared in Rinternals and the
Embedding test cases makes it more part of the API that its appearance
in any documentation since anyone embedding would have to base their
work on those test cases.


In any case, my second claim---that the function is used heavily by
projects under the official R umbrella as well as outside of
it---still stands and should probably serve as sufficient cause to
nominate R_tryEval for the public API.


On 2/22/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Thu, 22 Feb 2007, ellis at stat.harvard.edu wrote:
>
> > Full_Name: Byron Ellis
> > Version: 2.4.1
> > OS: N/A
> > Submission from: (NULL) (75.55.126.10)
> >
> >
> > R_tryEval is implied to be in the public API by 'Embedding R in Other
> > Applications,' but not documented in 'Writing R Extensions.' This would seem to
> > be an oversight given the dependence of many applications including but not
> > limited to the official OS X GUI on this function.
>
> It is not an oversight.  R_tryEval is as far as the R sources are
> concerned just part of the test examples for embedding.
>
> I think you may be referring to
>
> http://developer.r-project.org/embedded.html
>
> That does not list R_tryEval in 'Routines for the Embedded R', so makes no
> such implication (and in any case dates from 2000, before there was a
> documented interface).
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
Byron Ellis (byron.ellis at gmail.com)
"Oook" -- The Librarian


From jeff.horner at vanderbilt.edu  Thu Feb 22 23:10:52 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu, 22 Feb 2007 16:10:52 -0600
Subject: [Rd] Patch for "units<-" in datetime.R
Message-ID: <45DE14EC.60500@vanderbilt.edu>



Index: src/library/base/R/datetime.R
===================================================================
--- src/library/base/R/datetime.R       (revision 40781)
+++ src/library/base/R/datetime.R       (working copy)
@@ -381,7 +381,7 @@
      if (from == value) return(x)
      if (!(value %in% c("secs", "mins", "hours", "days", "weeks")))
          stop("invalid units specified")
-    sc <- cumprod(c(sec=1, mins=60, hours=60, days=24, weeks=7))
+    sc <- cumprod(c(secs=1, mins=60, hours=60, days=24, weeks=7))
      newx <- as.vector(x)*sc[from]/sc[value]
      structure(newx, units=value, class="difftime")
  }

Cheers,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From Christophe.Jean at uv.es  Mon Feb 12 13:24:00 2007
From: Christophe.Jean at uv.es (Christophe.Jean at uv.es)
Date: Mon, 12 Feb 2007 13:24:00 +0100 (CET)
Subject: [Rd] dyn.load (PR#9364)
Message-ID: <20070212122400.B2F335A99F@slim.kubism.ku.dk>

Hi,

I have exactly the same problem with R 2.4.1 on an Intel MacBook with  
Mac OS X 10.4.8.

Please find below the output of the test.

Christophe
---
 > source("/Users/Christophe/Desktop/Rdynunload/run.R")
WARNING: ignoring environment value of R_HOME
gcc-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/ 
include -I/Library/Frameworks/R.framework/Resources/include/i386  - 
msse3  -D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c  
code.c -o code.o
gcc-4.0 -arch i386 -dynamiclib -Wl,-macosx_version_min -Wl,10.3 - 
undefined dynamic_lookup -single_module -multiply_defined suppress -L/ 
usr/local/lib -o foo.so code.o   -L/Library/Frameworks/R.framework/ 
Resources/lib/i386 -lR -dylib_file libRblas.dylib:/Library/Frameworks/ 
R.framework/Resources/lib/i386/libRblas.dylib
[1] "Failed"
loaded DLL/SO
WARNING: ignoring environment value of R_HOME
gcc-4.0 -arch i386 -I/Library/Frameworks/R.framework/Resources/ 
include -I/Library/Frameworks/R.framework/Resources/include/i386  - 
msse3  -D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c  
other.c -o other.o
gcc-4.0 -arch i386 -dynamiclib -Wl,-macosx_version_min -Wl,10.3 - 
undefined dynamic_lookup -single_module -multiply_defined suppress -L/ 
usr/local/lib -o foo.so other.o   -L/Library/Frameworks/R.framework/ 
Resources/lib/i386 -lR -dylib_file libRblas.dylib:/Library/Frameworks/ 
R.framework/Resources/lib/i386/libRblas.dylib
first attempt
loaded DLL/SO
first attempt
---


From jhallman at frb.gov  Mon Feb 12 19:13:35 2007
From: jhallman at frb.gov (jhallman at frb.gov)
Date: Mon, 12 Feb 2007 13:13:35 -0500
Subject: [Rd] How to override functions in namespaces?
Message-ID: <20070212181335.825821F7B2@mail.rsma.frb.gov>

In package A I have askForString(), which asks the user for a string.
Also in package A I have defined ssh(), which calls askForString().

Package B has package A as a prerequisite.

In package B I redefine askForString() to take advantage of a nicer user
interface made available by B, namely the Emacs mini-buffer prompt.

Packages B and A are both on the search path, with B ahead of A.  If I
call askForString() at the command prompt, I get the version from B.
But the version used by ssh() depends on whether or not package A has a
namespace. If so, ssh() (defined in A) always uses the A version of
askForString().  How can I get ssh() to use the B version of
askForString()? Or am I going about this all wrong?

Jeff


From sebastien.durand at umontreal.ca  Tue Feb 13 14:15:42 2007
From: sebastien.durand at umontreal.ca (Sebastien Durand)
Date: Tue, 13 Feb 2007 08:15:42 -0500
Subject: [Rd] Graphical device questions
Message-ID: <p0623090bc1f769e13ff3@[192.168.2.3]>

Dear all,

I have posted these questions in r-help list but 
since I am getting no reply, I concluded that I 
must asked my question in the wrong list so here 
I am!

Here is my questions:

1- Under a WINDOWS installation of R-2.4.1,  can 
we change the naming of a new ploting device open 
by the command "windows()"?. Instead of the 
default name e.g.: "Device 2" I would like to use 
something like "Density plot" or whatever!


2- Under a MAC OS X installation of R-2.4.1, 
using quartz devices, is there a way to perform 
bringToTop operation like the one available under 
WINDOWS using bringToTop function.

Thank you very much for your time.

Cheers

S?bastien

-- 
Dans le Ssu Ma Fa on lit: "Celui qui place la vie 
au dessus de toute chose sera paralys? par 
l'irr?solution"


From plynchnlm at gmail.com  Wed Feb 14 18:04:10 2007
From: plynchnlm at gmail.com (plynchnlm at gmail.com)
Date: Wed, 14 Feb 2007 18:04:10 +0100 (CET)
Subject: [Rd] Bug in httpget function for internet.Rout test (PR#9509)
Message-ID: <20070214170410.7576F5A8ED@slim.kubism.ku.dk>

Full_Name: Paul Lynch
Version: 2.4.1
OS: RedHat EL4
Submission from: (NULL) (130.14.254.25)


The httpget function used for the test that produces the internet.Rout file (or
in my case, the internet.Rout.fail file) checks for a "Content-Length" header
returned from a  webserver in response to the URL: 
http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat.  When I attempt to access
that URL either via the make check in R or via "curl --head
http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat" via the command line, the
header I receive is "Content-length" with a lower case "l".  Another user on
r-help reports that he gets it with an upper case "L", so the problem appears to
be only visible from certain IP addresses.  It seems likely that the web server
at www.stats.ox.ac.uk is doing some load balancing based on the incoming IP
address, so that some users with get a response from a web server that returns
"Content-length" while others will get a response from a different web server
that returns "Content-Length".  Whatever the cause  is, it seems reasonable that
the test for internet.Rout in httpget should not particular about whether the
upper or lower case "L" is used.


From jhallman at frb.gov  Fri Feb 16 04:24:56 2007
From: jhallman at frb.gov (jhallman at frb.gov)
Date: Thu, 15 Feb 2007 22:24:56 -0500
Subject: [Rd] Request: make as.POSIXlt generic
Message-ID: <20070216032456.2E9C81F7B0@mail.rsma.frb.gov>

In the base package, as.POSIXct() is an S3 generic function, but
as.POSIXlt() is not.  As shown below, the current implementation is
already crying out to be refactored into a generic function with methods
for various classes.  It calls "inherits" five times. Not only is this
bad style, it also disallows me or anyone else from making as.POSIXlt()
work with other kinds of time-ish objects, such as the 'ti' (Time Index)
class in my fame package.

I would also like to see three other functions made generic: rowSums(),
rowMeans(), and filter().  This would enable Gabor to create methods for
his 'zoo' series, and let me create methods for my 'tis' (Time Indexed
Series).  But these are not as urgent as cleaning up as.POSIXlt().

Jeff Hallman



The current as.POSIXlt() implementation:

as.POSIXlt <- function(x, tz = ""){
    fromchar <- function(x) {
	xx <- x[1]
        if(is.na(xx)) {
            j <- 1
            while(is.na(xx) && (j <- j+1) <= length(x))
                xx <- x[j]
            if(is.na(xx)) f <- "%Y-%m-%d" # all NAs
        }
	if(is.na(xx) ||
           !is.na(strptime(xx, f <- "%Y-%m-%d %H:%M:%OS")) ||
	   !is.na(strptime(xx, f <- "%Y/%m/%d %H:%M:%OS")) ||
	   !is.na(strptime(xx, f <- "%Y-%m-%d %H:%M")) ||
	   !is.na(strptime(xx, f <- "%Y/%m/%d %H:%M")) ||
	   !is.na(strptime(xx, f <- "%Y-%m-%d")) ||
	   !is.na(strptime(xx, f <- "%Y/%m/%d")))
        {
	    res <- strptime(x, f)
            if(nchar(tz)) attr(res, "tzone") <- tz
            return(res)
        }
	stop("character string is not in a standard unambiguous format")
    }

    if(inherits(x, "POSIXlt")) return(x)
    if(inherits(x, "Date")) return(.Internal(Date2POSIXlt(x)))
    tzone <- attr(x, "tzone")
    if(inherits(x, "date") || inherits(x, "dates")) x <- as.POSIXct(x)
    if(is.character(x)) return(fromchar(unclass(x))) # precaution PR7826
    if(is.factor(x))	return(fromchar(as.character(x)))
    if(is.logical(x) && all(is.na(x))) x <- as.POSIXct.default(x)
    if(!inherits(x, "POSIXct"))
        stop(gettextf("do not know how to convert '%s' to class \"POSIXlt\"",
                      deparse(substitute(x))))
    if(missing(tz) && !is.null(tzone)) tz <- tzone[1]
    .Internal(as.POSIXlt(x, tz))
}


From lloydl at cybermesa.com  Sat Feb 17 04:04:44 2007
From: lloydl at cybermesa.com (lloydl at cybermesa.com)
Date: Sat, 17 Feb 2007 04:04:44 +0100 (CET)
Subject: [Rd] MCMC Pack Crashes R-GUI session (PR#9516)
Message-ID: <20070217030444.986515ACFF@slim.kubism.ku.dk>

Full_Name: Lloyd Lubet
Version: 2.4.1rc
OS: XP
Submission from: (NULL) (65.19.17.17)


Dear Andrew,

I am trying to learn gibbs sampling and Metropolis. 
When I run your gibbs version of multiple linear regression my session crashes.
I have trimmed the dataframe and set my object.size = 1 gigB.
Despite my best efforts it still crashes while advising me to contact the MCMC
Pack developement team.

I am running windows XP with R version 2.4.1.c (the latest).

Here's the offending instruction in R:
 
mcmcReg<-MCMCSVDreg( jpMorganChase.Adj.Close ~ exxon.Oil.Volume+usSteel.Volume,
data=yy.lo.res.scaled[ 2000:2274, ], burnin = 100, mcmc = 1000,

thin=1, verbose = 1, seed = NA, tau2.start = 1,

g0 = 0, a0 = 0.01, b0 = 0.01, c0=2, d0=2, w0=1,

beta.samp=TRUE, intercept=TRUE )



Here's the error msg:

Runtime Error!

Program ... \R\R-2.4.1rc\bin\Rgui.exe

This application has requested the Tuntime to terminate it in an unusual way.
Please contact the applications support team for more information



R Console - Rgui.exe - Application Error

The instruction at "0x5ad71531" referenced memory at "0x00000014". Memory could
not be read.



Then, it crashes. 



Sincerely,



Lloyd Lubet


From mwtoews at sfu.ca  Sun Feb 18 02:26:15 2007
From: mwtoews at sfu.ca (mwtoews at sfu.ca)
Date: Sun, 18 Feb 2007 02:26:15 +0100 (CET)
Subject: [Rd] Windows EPS format error (PR#9518)
Message-ID: <20070218012615.6B7225A945@slim.kubism.ku.dk>

This bug can be reproduced using R version 2.4.1 for Windows, where 
WinAnsiEncoding is used.
To reproduce this bug, start a Windows R session, and run:

postscript("first.eps", width=6, height=6, horizontal=FALSE, 
onefile=FALSE, paper="special")
plot(1:5)
dev.off()
q("no")

Now, start a new R session, and run:

pdf("second.pdf")
plot(1:5)
dev.off()
postscript("third.eps", width=6, height=6, horizontal=FALSE, 
onefile=FALSE, paper="special")
plot(1:5)
dev.off()
q("no")

The differences between "first.eps" and "third.eps" are shown to be:

$ diff first.eps third.eps
40d39
< /WinAnsiEncoding [
73d71
< ]

The file "third.eps" is an invalid format, and Vhostview reports:
Error: /undefined in WinAnsiEncoding
Operand stack:
   .notdef   .notdef   .notdef
... etc ...

I've also tested for this peculiar behavior with R 2.4.1 for Debian, 
however it checked clean.
+mt


From giusi.moffa at bristol.ac.uk  Sun Feb 18 20:08:01 2007
From: giusi.moffa at bristol.ac.uk (Giusi Moffa)
Date: Sun, 18 Feb 2007 19:08:01 +0000
Subject: [Rd] R crashes in Mac OS
Message-ID: <1061F143-443E-4C68-B162-1DE10E2A0C01@bristol.ac.uk>

I am running R under Mac OS X (Tiger, v10.4). Unfortunately it keeps  
crashing while using the editor. One thing that seems to make things  
worse is having more than one script open at the same time. Can  
anyone help?

The last time it happened I got the following messages

error message from R:

*** caught segfault ***
address 0x89d789d8, cause 'memory not mapped'


report:

Date/Time:      2007-02-18 18:59:42.108 +0000
OS Version:     10.4.8 (Build 8N1051)
Report Version: 4

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Parent:  WindowServer [55]

Version: R 2.4.1 GUI 1.18 (4038)

PID:    235
Thread: 0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_INVALID_ADDRESS (0x0001) at 0x89d789d8

Thread 0 Crashed:


From boe at demog.berkeley.edu  Mon Feb 19 06:43:13 2007
From: boe at demog.berkeley.edu (boe at demog.berkeley.edu)
Date: Mon, 19 Feb 2007 06:43:13 +0100 (CET)
Subject: [Rd] supsmu produces segfault when handed all NAs. (PR#9519)
Message-ID: <20070219054313.8D12A5D57F@slim.kubism.ku.dk>

When handed an argument with all NAs, supsmu() causes a
sigfault causing termination of R.  The following example
reproduces the problem (on a linux gentoo system), but I have verified the 
same behavior on a solaris builds as well as several versions of R.


   x <- (1:100)/10;
   y <- sin(pi*x) + rnorm(length(x));
   tmp <- supsmu(x,y);  # works
   y[c(2,5,10)] <- NA;   # a few NAs is OK, warning generated
   tmp<-  supsmu(x,y);
   y<- NA + y;           # all NAs
   tmp <- supsmu(x,y);   # oops

  *** caught segfault ***
  address 0xfffffff8, cause 'memory not mapped'

  Traceback:
   1: .Fortran(R_supsmu, as.integer(leno), as.double(xo), 
as.double(y[ord]),     as.double(wt[o
rd]), as.integer(iper), as.double(span), as.double(bass),     smo = 
double(leno), double(n * 7
), double(1))
    2: supsmu(x, y)

    Possible actions:
    1: abort (with core dump)
    2: normal R exit
    3: exit R without saving workspace
    4: exit R saving workspace
    Selection:

--please do not edit the information below--

Version:
  platform = i686-pc-linux-gnu
  arch = i686
  os = linux-gnu
  system = i686, linux-gnu
  status =
  major = 2
  minor = 4.1
  year = 2006
  month = 12
  day = 18
  svn rev = 40228
  language = R
  version.string = R version 2.4.1 (2006-12-18)

Locale:
LC_CTYPE=en_US.utf8;LC_NUMERIC=C;LC_TIME=en_US.utf8;LC_COLLATE=en_US.utf8;LC_MONETARY=en_US.ut
f8;LC_MESSAGES=en_US.utf8;LC_PAPER=en_US.utf8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASURE
MENT=en_US.utf8;LC_IDENTIFICATION=C
Search Path:
  .GlobalEnv, package:stats, package:graphics, package:grDevices, 
package:utils, package:datase
ts, package:methods, Autoloads, package:base


From candrews at buffalo.edu  Mon Feb 19 17:47:02 2007
From: candrews at buffalo.edu (candrews at buffalo.edu)
Date: Mon, 19 Feb 2007 17:47:02 +0100 (CET)
Subject: [Rd] lower.tail for plnorm (PR#9520)
Message-ID: <20070219164702.7993E5AB7E@slim.kubism.ku.dk>

Full_Name: Chris Andrews
Version: 2.4.1
OS: Windows XP
Submission from: (NULL) (128.205.90.25)



# CDF works as expected (=0)
pnorm(-Inf) # 0
plnorm(0)  # 0

# specifying lower.tail=FALSE should give survival function (=1)
pnorm(-Inf, lower.tail=FALSE) # 1
plnorm(0, lower.tail=FALSE) # 0 != 1


From tom at levelelimited.com  Tue Feb 20 15:59:51 2007
From: tom at levelelimited.com (tom at levelelimited.com)
Date: Tue, 20 Feb 2007 14:59:51 +0000
Subject: [Rd] Problem with types on 64-bit
Message-ID: <jdrobr.ckei5y@webmail.levelelimited.com>

Hi Everyone,

I have a problem using some working 32-bit R code with 64-bit machine ( I am
using version R-2.4.1 ).  The problem occurs when I am trying to detect a NULL
STRSXP type. ( Perhaps I am doing this detection in the wrong way? )

On 32-bit the following works, and correctly identifies if I am passing NULL
or a valid string object:

if ( v_dta_start != R_NilValue && STRING_ELT( v_dta_start, 0 ) != R_NilValue )
{
    dta.start = CHAR( STRING_ELT( v_dta_start, 0 ) );
}

Yet on a 64-bit machine I get the following errors:

(1) when I pass NULL it goes into the if clause and then when it tries to set
dta.start it displays:
CHAR() can only be applied to a 'CHARSXP', not a 'NULL'
(2) if I pass a valid string such as "hello", I get the following:
CHAR() can only be applied to a 'CHARSXP', not a 'character'

I have tried converting using AS_CHARACTER but that just brings up the same
messages.  I have also seen S4 and PROMSXP types come up in these error
messages.  

What I don't understand is why this happens - any ideas?

If I can supply any more info let me know, below is the CPU information for
the 64-bit machine. 

Many thanks for your help

Tom

64-BIT CPU INFO
===============

processor	: 0
vendor_id	: AuthenticAMD
cpu family	: 15
model		: 5
model name	: AMD Opteron(tm) Processor 144
stepping	: 10
cpu MHz		: 1794.932
cache size	: 1024 KB
fpu		: yes
fpu_exception	: yes
cpuid level	: 1
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat
pse36 clflush mmx fxsr sse sse2 syscall nx mmxext lm 3dnowext 3dnow
bogomips	: 3597.08
TLB size	: 1024 4K pages
clflush size	: 64
cache_alignment	: 64
address sizes	: 40 bits physical, 48 bits virtual
power management: ts fid vid ttp


From Robert.King at newcastle.edu.au  Wed Feb 21 00:30:25 2007
From: Robert.King at newcastle.edu.au (Robert King)
Date: Wed, 21 Feb 2007 10:30:25 +1100
Subject: [Rd] text.rpart for the "class" method doesn't act on label="yprob"
Message-ID: <200702211030.26010.robert.king@newcastle.edu.au>

Hello All,

Am I misreading the documentation?

The text.rpart documentation says:
"label   a column name of x$frame; values of this will label the nodes. For
the "class" method, label="yval" results in the factor levels being
used, "yprob" results in the probability of the winning factor level being
used, and ?specific yval level? results in the probability of that factor
level."

However, yprob doesn't seem to do this:
> pred = rep(letters[1:6],5)
> resp = rep(letters[1:3],10)
> ex.rp <- rpart(resp~pred)
> plot(ex.rp)
> text(ex.rp,label="yval")

# works as advertised

> plot(ex.rp)
> text(ex.rp,label="yprob")

Error in text.rpart(ex.rp, label = "yprob") :
        Label must be a column label of the frame component of the tree

If I try to fake it, by making an element of the frame, like this:
> ex.rp$frame$yprob = (ex.rp$frame$n-ex.rp$frame$dev)/ex.rp$frame$n

The text command does add text to the plot, but adds the class labels
(i.e. "yval"), not the probabilities

> text(ex.rp,label="yprob")


From j.j.goeman at lumc.nl  Wed Feb 21 10:37:54 2007
From: j.j.goeman at lumc.nl (j.j.goeman at lumc.nl)
Date: Wed, 21 Feb 2007 10:37:54 +0100 (CET)
Subject: [Rd] avoiding a needless function evaluation in optimize() (PR#9523)
Message-ID: <20070221093754.6F1A75ACC7@slim.kubism.ku.dk>

Full_Name: Jelle Goeman
Version: 2.4.0
OS: windows XP
Submission from: (NULL) (145.88.209.33)


 Hi,

I like to use optimize() to optimize functions whose evaluation is costly in
terms of computation time. The Brent algorithm which is implemented in optimize
was designed to optimize a function with as few function evaluations as
possible. Therefore it bothers me that optimize() always evaluates the function
twice at the optimal value. This can be seen for example by saying:

square <- function(x) {
  print(x)
  x*x
}
opt <- optimize(square, c(-5,1), tol=0.1)

Looking at the code of optimize(), I see that the extra function evaluation
comes when optimize returns

list(minimum = val, objective = f(val, ...))

f(val, ...) is calculated, but f(val, ...) has already been calculated at some
point during the algorithm.

Would it be possible to let optimize() store its previous function evaluations
to avoid this unnecessary function evaluation? 

Kind regards,

Jelle


From Rainer.Hurling at nw-fva.de  Thu Feb 22 13:39:21 2007
From: Rainer.Hurling at nw-fva.de (Rainer Hurling)
Date: Thu, 22 Feb 2007 13:39:21 +0100
Subject: [Rd] rgl update:  please test!
In-Reply-To: <45DD7848.70602@stats.uwo.ca>
References: <45DD7848.70602@stats.uwo.ca>
Message-ID: <45DD8EF9.9040203@nw-fva.de>

Hallo Duncan,

your newest version works fine under R-2.5.0 (devel) on FreeBSD 
7.0-CURRENT (i386). I made some tests with different types of diagrams 
and all seems to be ok for me.

Thank you very much. I am look forward to the release of this version.

Have a nice trip,
Rainer



Duncan Murdoch wrote:
> (This is bcc'd to a list of people who have had problems with rgl lately 
> or who are known to be big users; not cc'd, so you don't all get cc'd 
> all the responses on the R-devel list).
> 
> I've just put together a test build of rgl, and put it on my web site as
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.tar.gz 
> (source)
> 
> and
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.zip 
> (Windows binary).
> 
> This includes a number of changes:
> 
>    - changes to configure script from Laszlo Kajan and Brian Ripley: 
> should now be much more portable
>    - removed deprecated OSX font setting calls
>    - texture properties are now returned by material3d()
>    - allowed normals and texture coordinates to be specified in 
> triangles and quads
>    - normals may be specified in qmesh objects, but (at present) 
> subdivide removes them
>    - material3d() now preserves the values of unspecified parameters (as 
> documented, but not previously functioning)
>    - open3d() now resets all material properties to the defaults.
> 
> Could people who have been having problems with rgl (or just making use 
> of it) please test this update?  Some of the changes are very recent, 
> and may still be buggy:  but I'm going offline from late tomorrow until 
> March 4, so I'm not going to have an opportunity to test them myself 
> well enough to want to send this to CRAN.
> 
> I'm hoping to send this to CRAN soon after I return.
> 
> Duncan Murdoch


From wlangdon at essex.ac.uk  Thu Feb 22 16:09:46 2007
From: wlangdon at essex.ac.uk (wlangdon at essex.ac.uk)
Date: Thu, 22 Feb 2007 16:09:46 +0100 (CET)
Subject: [Rd] memory problem read.table v array (PR#9526)
Message-ID: <20070222150946.15DB35D5BB@slim.kubism.ku.dk>

Full_Name: bill langdon
Version: 2.4.1
OS: ubuntu
Submission from: (NULL) (155.245.58.159)


#WBL 22 Feb 2007 ubuntu 
R.version
#platform       i486-pc-linux-gnu
#arch           i486
#os             linux-gnu
#system         i486, linux-gnu
#status
#major          2
#minor          4.1
#year           2006
#month          12
#day            18
#svn rev        40228
#language       R
#version.string R version 2.4.1 (2006-12-18)

#if matrix "a" is created by array "vals" is created ok

#if matrix "a" is created by read.table,
#peak resource use (CPU, memory) by "array()" is excessive

#a = array(0,dim=c(409600,1));                        #ok
#a = read.table("big.txt",header=FALSE);              #all memory used 
#a = read.table("639x639.txt",header=FALSE);          #all memory used 
#a = read.table("4096.txt",header=FALSE);             #all memory used 
#a = read.table("4096nocomment.txt",header=FALSE);    #all memory used 
#a = read.table("tiny.txt",header=FALSE);             #ten lines ok
#a = read.table("1000.txt",header=FALSE);             #all memory used 
a = read.table("639.txt",header=FALSE);               #uses 1.6047029GB
dim(a)
dd = 639;
vals = array(a,dim=c(dd,dd));


From Mathieu.DAcremont at pse.unige.ch  Thu Feb 22 17:59:18 2007
From: Mathieu.DAcremont at pse.unige.ch (Mathieu.DAcremont at pse.unige.ch)
Date: Thu, 22 Feb 2007 17:59:18 +0100 (CET)
Subject: [Rd] Error in ICC1.CI ? (PR#9528)
Message-ID: <20070222165918.C2C495ACE5@slim.kubism.ku.dk>


Hello,

I'm using the function ICC1.CI of the psychometric package. I wonder if 
there is an error in this function. Because in the paper of McGraw and 
Wong (Psychol Met, 1, 30) or the one of Shrout & Fleiss (Psychol Bult, 
86, 420), the Ftab is not calculate in the same manner of the lower and 
upper bound.

According to these articles Ftab for the lower bound is:

F(df.row, df.error)

and for the upper bound, it is:

F(df.error, df.row).

So the df are reversed. However, in your function ICC1.CI, the Ftab is 
calculated in the same way for the upper and lower bound:

     Ftab <- qf(noma/2, df1, df2, lower.tail = F)
     Fl <- Fobs/Ftab
     Fu <- Fobs * Ftab
     lcl <- (Fl - 1)/(Fl + n)
     ucl <- (Fu - 1)/(Fu + n)

Is that an error ?

Best regards,

-- 
Mathieu d'Acremont, PhD		Mathieu.Dacremont at pse.unige.ch
Ma?tre-Assistant               	tel/fax +4122 379 98 20/44

P?le de Recherche National en Sciences Affectives
CISA - Universit? de Gen?ve
Rue des Battoirs 7
CH-1205 Gen?ve
http://affect.unige.ch/


From h.wickham at gmail.com  Thu Feb 22 23:51:48 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 22 Feb 2007 16:51:48 -0600
Subject: [Rd] Writing a package in which files must be sourced in a specific
	order
Message-ID: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>

Dear all,

I have been using the proto package to create objects with mutable
state for my ggplot package.  This has been very successful so far,
but I have run into a problem when building/installing the package,
because the source files need to be loaded in a specific order so that
dependencies are initialised correctly.

I have named the files so that dependencies are loaded before they are
needed, so that

lapply(dir("~/documents/ggplot/ggplot/R", full.name=T), source)

runs without error, but when installing the package I get an error
than indicates that the files aren't being loaded in alphabetical
order:

Error in proto(Geom, { : object "Geom" not found
Error: unable to load R code in package 'ggplot'
Error: package/namespace load failed for 'ggplot'

Can anyone suggest how I could get around this?

Regards,

Hadley


From ripley at stats.ox.ac.uk  Thu Feb 22 23:54:27 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 22:54:27 +0000 (GMT)
Subject: [Rd] Problem with types on 64-bit
In-Reply-To: <jdrobr.ckei5y@webmail.levelelimited.com>
References: <jdrobr.ckei5y@webmail.levelelimited.com>
Message-ID: <Pine.LNX.4.64.0702222247430.27196@gannet.stats.ox.ac.uk>

Neither NULL nor "hello" are valid values for an element of a STRSXP: only 
CHARSXPs are.  So your test is not the correct one: you need to test 
both isString(v_dta_start) and  TYPEOF(STRING_ELT( v_dta_start, 0 )) == 
CHARSXP to be really safe.

Calling STRSXP on a random SEXP is likely to give different results on 
different machines: there is no fundamental 32- vs 64-but difference here.

On Tue, 20 Feb 2007, tom at levelelimited.com wrote:

> Hi Everyone,
>
> I have a problem using some working 32-bit R code with 64-bit machine ( I am
> using version R-2.4.1 ).  The problem occurs when I am trying to detect a NULL
> STRSXP type. ( Perhaps I am doing this detection in the wrong way? )
>
> On 32-bit the following works, and correctly identifies if I am passing NULL
> or a valid string object:
>
> if ( v_dta_start != R_NilValue && STRING_ELT( v_dta_start, 0 ) != R_NilValue )
> {
>    dta.start = CHAR( STRING_ELT( v_dta_start, 0 ) );
> }
>
> Yet on a 64-bit machine I get the following errors:
>
> (1) when I pass NULL it goes into the if clause and then when it tries to set
> dta.start it displays:
> CHAR() can only be applied to a 'CHARSXP', not a 'NULL'
> (2) if I pass a valid string such as "hello", I get the following:
> CHAR() can only be applied to a 'CHARSXP', not a 'character'
>
> I have tried converting using AS_CHARACTER but that just brings up the same
> messages.  I have also seen S4 and PROMSXP types come up in these error
> messages.
>
> What I don't understand is why this happens - any ideas?
>
> If I can supply any more info let me know, below is the CPU information for
> the 64-bit machine.
>
> Many thanks for your help
>
> Tom

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From osklyar at ebi.ac.uk  Fri Feb 23 00:11:28 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 22 Feb 2007 23:11:28 +0000
Subject: [Rd] Problem with types on 64-bit
In-Reply-To: <jdrobr.ckei5y@webmail.levelelimited.com>
References: <jdrobr.ckei5y@webmail.levelelimited.com>
Message-ID: <45DE2320.9070907@ebi.ac.uk>

Besides the comments from Prof. Ripley, I am not sure your if statement 
is fully correct, because suppose v_dta_start is R_NilValue -- why then 
STRING_ELT( R_NilValue, 0 ) should be a valid statement in first place? 
In my code I often use R_NilValue to check for R-NULL, but it always 
works fine on both 32 and 64 bits, moreover on Linux, Mac and Windows as 
well... Oleg

tom at levelelimited.com wrote:
> Hi Everyone,
> 
> I have a problem using some working 32-bit R code with 64-bit machine ( I am
> using version R-2.4.1 ).  The problem occurs when I am trying to detect a NULL
> STRSXP type. ( Perhaps I am doing this detection in the wrong way? )
> 
> On 32-bit the following works, and correctly identifies if I am passing NULL
> or a valid string object:
> 
> if ( v_dta_start != R_NilValue && STRING_ELT( v_dta_start, 0 ) != R_NilValue )
> {
>     dta.start = CHAR( STRING_ELT( v_dta_start, 0 ) );
> }
> 
> Yet on a 64-bit machine I get the following errors:
> 
> (1) when I pass NULL it goes into the if clause and then when it tries to set
> dta.start it displays:
> CHAR() can only be applied to a 'CHARSXP', not a 'NULL'
> (2) if I pass a valid string such as "hello", I get the following:
> CHAR() can only be applied to a 'CHARSXP', not a 'character'
> 
> I have tried converting using AS_CHARACTER but that just brings up the same
> messages.  I have also seen S4 and PROMSXP types come up in these error
> messages.  
> 
> What I don't understand is why this happens - any ideas?
> 
> If I can supply any more info let me know, below is the CPU information for
> the 64-bit machine. 
> 
> Many thanks for your help
> 
> Tom
> 
> 64-BIT CPU INFO
> ===============
> 
> processor	: 0
> vendor_id	: AuthenticAMD
> cpu family	: 15
> model		: 5
> model name	: AMD Opteron(tm) Processor 144
> stepping	: 10
> cpu MHz		: 1794.932
> cache size	: 1024 KB
> fpu		: yes
> fpu_exception	: yes
> cpuid level	: 1
> wp		: yes
> flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat
> pse36 clflush mmx fxsr sse sse2 syscall nx mmxext lm 3dnowext 3dnow
> bogomips	: 3597.08
> TLB size	: 1024 4K pages
> clflush size	: 64
> cache_alignment	: 64
> address sizes	: 40 bits physical, 48 bits virtual
> power management: ts fid vid ttp
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466


From ripley at stats.ox.ac.uk  Fri Feb 23 00:12:12 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 23:12:12 +0000 (GMT)
Subject: [Rd] (PR#9523) avoiding a needless function evaluation in
 optimize()
In-Reply-To: <20070221093754.6F1A75ACC7@slim.kubism.ku.dk>
References: <20070221093754.6F1A75ACC7@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0702222307510.27196@gannet.stats.ox.ac.uk>

This is very far from easy, as the C code used does not return the 
function value.

If you would like to rewrite it and the interface and submit a patch it 
will be considered.

It's hard to imagine an application where this would matter, and you have 
not given one to encourage us to give this more than the lowest priority 
on the wishlist.


On Wed, 21 Feb 2007, j.j.goeman at lumc.nl wrote:

> Full_Name: Jelle Goeman
> Version: 2.4.0
> OS: windows XP
> Submission from: (NULL) (145.88.209.33)
>
>
> Hi,
>
> I like to use optimize() to optimize functions whose evaluation is costly in
> terms of computation time. The Brent algorithm which is implemented in optimize
> was designed to optimize a function with as few function evaluations as
> possible. Therefore it bothers me that optimize() always evaluates the function
> twice at the optimal value. This can be seen for example by saying:
>
> square <- function(x) {
>  print(x)
>  x*x
> }
> opt <- optimize(square, c(-5,1), tol=0.1)
>
> Looking at the code of optimize(), I see that the extra function evaluation
> comes when optimize returns
>
> list(minimum = val, objective = f(val, ...))
>
> f(val, ...) is calculated, but f(val, ...) has already been calculated at some
> point during the algorithm.
>
> Would it be possible to let optimize() store its previous function evaluations
> to avoid this unnecessary function evaluation?
>
> Kind regards,
>
> Jelle
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Feb 23 00:18:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 23:18:18 +0000 (GMT)
Subject: [Rd] memory problem read.table v array (PR#9526)
In-Reply-To: <20070222150946.15DB35D5BB@slim.kubism.ku.dk>
References: <20070222150946.15DB35D5BB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0702222255030.27196@gannet.stats.ox.ac.uk>

There is nothing to reproduce here: we do not have 639.txt.

But note that read.table returns a data frame, and ?array has

     data: a vector (including a list) giving data to fill the array.

so I do wonder if this is what you intended: you seem to have tried to 
create an array list with 639*639 elements.  It is certainly not the same 
sort of object as array(0,dim=c(409600,1)).

Had 639.txt contained 639 rows of reals, your 'a' would be about
639*639*639*8 bytes, beyond the address space of your machine.

as.matrix(read.table("639.txt", header=FALSE)) might have been what you 
are looking for.


On Thu, 22 Feb 2007, wlangdon at essex.ac.uk wrote:

> Full_Name: bill langdon
> Version: 2.4.1
> OS: ubuntu
> Submission from: (NULL) (155.245.58.159)
>
>
> #WBL 22 Feb 2007 ubuntu
> R.version
> #platform       i486-pc-linux-gnu
> #arch           i486
> #os             linux-gnu
> #system         i486, linux-gnu
> #status
> #major          2
> #minor          4.1
> #year           2006
> #month          12
> #day            18
> #svn rev        40228
> #language       R
> #version.string R version 2.4.1 (2006-12-18)
>
> #if matrix "a" is created by array "vals" is created ok
>
> #if matrix "a" is created by read.table,
> #peak resource use (CPU, memory) by "array()" is excessive
>
> #a = array(0,dim=c(409600,1));                        #ok
> #a = read.table("big.txt",header=FALSE);              #all memory used
> #a = read.table("639x639.txt",header=FALSE);          #all memory used
> #a = read.table("4096.txt",header=FALSE);             #all memory used
> #a = read.table("4096nocomment.txt",header=FALSE);    #all memory used
> #a = read.table("tiny.txt",header=FALSE);             #ten lines ok
> #a = read.table("1000.txt",header=FALSE);             #all memory used
> a = read.table("639.txt",header=FALSE);               #uses 1.6047029GB
> dim(a)
> dd = 639;
> vals = array(a,dim=c(dd,dd));


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri Feb 23 00:24:48 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 22 Feb 2007 18:24:48 -0500
Subject: [Rd] How to override functions in namespaces?
In-Reply-To: <20070212181335.825821F7B2@mail.rsma.frb.gov>
References: <20070212181335.825821F7B2@mail.rsma.frb.gov>
Message-ID: <45DE2640.20004@stats.uwo.ca>

On 2/12/2007 1:13 PM, jhallman at frb.gov wrote:
> In package A I have askForString(), which asks the user for a string.
> Also in package A I have defined ssh(), which calls askForString().
> 
> Package B has package A as a prerequisite.
> 
> In package B I redefine askForString() to take advantage of a nicer user
> interface made available by B, namely the Emacs mini-buffer prompt.
> 
> Packages B and A are both on the search path, with B ahead of A.  If I
> call askForString() at the command prompt, I get the version from B.
> But the version used by ssh() depends on whether or not package A has a
> namespace. If so, ssh() (defined in A) always uses the A version of
> askForString().  How can I get ssh() to use the B version of
> askForString()? Or am I going about this all wrong?

There are several ways.  If package A "knows" that some users will want 
to replace askForString(), then it should allow the user to tell it what 
to use for that function, and fall back to its own definition as a 
default.  It could do this by explicitly looking for askForString in the 
global environment (which will fall back to the search list if not 
found), or it could get the function from an option() setting, etc.

If package A doesn't expect askForString() to be changed, then you 
shouldn't change it:  you might break something else in A.  You should 
write to the author of A (which sounds as though it's yourself), and ask 
for some improvements to the package.

There are dirty methods to modify the contents of a namespace, but you 
shouldn't use those.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Fri Feb 23 00:27:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 23:27:56 +0000 (GMT)
Subject: [Rd] How to override functions in namespaces?
In-Reply-To: <20070212181335.825821F7B2@mail.rsma.frb.gov>
References: <20070212181335.825821F7B2@mail.rsma.frb.gov>
Message-ID: <Pine.LNX.4.64.0702222318430.27682@gannet.stats.ox.ac.uk>

On Mon, 12 Feb 2007, jhallman at frb.gov wrote:

> In package A I have askForString(), which asks the user for a string.
> Also in package A I have defined ssh(), which calls askForString().
>
> Package B has package A as a prerequisite.
>
> In package B I redefine askForString() to take advantage of a nicer user
> interface made available by B, namely the Emacs mini-buffer prompt.
>
> Packages B and A are both on the search path, with B ahead of A.  If I
> call askForString() at the command prompt, I get the version from B.
> But the version used by ssh() depends on whether or not package A has a
> namespace. If so, ssh() (defined in A) always uses the A version of
> askForString().  How can I get ssh() to use the B version of
> askForString()? Or am I going about this all wrong?

That is one of the main purposes of a namespace, but you can defeat it.

In the scenario you paint, B::askForString() should work (whether or not B 
has a namespace).

If (I am guessing) you want the version that would be gotten at the top 
level (the > prompt) whether or not B is in use, use
get("askForString", pos=1)().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From osklyar at ebi.ac.uk  Fri Feb 23 00:28:50 2007
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 22 Feb 2007 23:28:50 +0000
Subject: [Rd] Writing a package in which files must be sourced in a
 specific order
In-Reply-To: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>
References: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>
Message-ID: <45DE2732.9060606@ebi.ac.uk>

Put all loadings into functions and call the functions in .onLoad or 
.FirstLib, whatever you have there. I would simply advise not to put any 
  code outside of functions or class methods. In this way the order of 
loading will not matter, it will not depend on system or alphabet and 
you will also be able to save the loaded image of the package for faster 
loading.

Best
Oleg

hadley wickham wrote:
> Dear all,
> 
> I have been using the proto package to create objects with mutable
> state for my ggplot package.  This has been very successful so far,
> but I have run into a problem when building/installing the package,
> because the source files need to be loaded in a specific order so that
> dependencies are initialised correctly.
> 
> I have named the files so that dependencies are loaded before they are
> needed, so that
> 
> lapply(dir("~/documents/ggplot/ggplot/R", full.name=T), source)
> 
> runs without error, but when installing the package I get an error
> than indicates that the files aren't being loaded in alphabetical
> order:
> 
> Error in proto(Geom, { : object "Geom" not found
> Error: unable to load R code in package 'ggplot'
> Error: package/namespace load failed for 'ggplot'
> 
> Can anyone suggest how I could get around this?
> 
> Regards,
> 
> Hadley
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Oleg Sklyar | EBI-EMBL, Cambridge CB10 1SD, UK | +44-1223-494466


From ripley at stats.ox.ac.uk  Fri Feb 23 00:46:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Feb 2007 23:46:33 +0000 (GMT)
Subject: [Rd] Writing a package in which files must be sourced in a
 specific order
In-Reply-To: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>
References: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702222332320.27682@gannet.stats.ox.ac.uk>

What 'alphabetical order' is depends on the locale.  In en_NZ g < G, in C
G < g.  So it is a rather slippery concept (and gets worse in non-English 
locales: 'aa' sorts after z in Danish).

You don't tell us quite what you are doing, but R CMD INSTALL is 
working in C when concatenating the files in the R directory to ensure 
consistency across R installations.

My guess is that you need to give a collation order in the DESCRIPTION 
file (see 'Writing R Extensions'), if I am interpolating your 
comments correctly.

On Thu, 22 Feb 2007, hadley wickham wrote:

> Dear all,
>
> I have been using the proto package to create objects with mutable
> state for my ggplot package.  This has been very successful so far,
> but I have run into a problem when building/installing the package,
> because the source files need to be loaded in a specific order so that
> dependencies are initialised correctly.

'loaded'?  Do you mean sourced during INSTALL?

> I have named the files so that dependencies are loaded before they are
> needed, so that
>
> lapply(dir("~/documents/ggplot/ggplot/R", full.name=T), source)
>
> runs without error, but when installing the package I get an error
> than indicates that the files aren't being loaded in alphabetical
> order:
>
> Error in proto(Geom, { : object "Geom" not found
> Error: unable to load R code in package 'ggplot'
> Error: package/namespace load failed for 'ggplot'
>
> Can anyone suggest how I could get around this?
>
> Regards,
>
> Hadley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Fri Feb 23 00:56:16 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 22 Feb 2007 17:56:16 -0600
Subject: [Rd] Writing a package in which files must be sourced in a
	specific order
In-Reply-To: <Pine.LNX.4.64.0702222332320.27682@gannet.stats.ox.ac.uk>
References: <f8e6ff050702221451n17d13a35oaa5e9859ccdb7834@mail.gmail.com>
	<Pine.LNX.4.64.0702222332320.27682@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050702221556k6a9f7326xda2b890ccc796648@mail.gmail.com>

> What 'alphabetical order' is depends on the locale.  In en_NZ g < G, in C
> G < g.  So it is a rather slippery concept (and gets worse in non-English
> locales: 'aa' sorts after z in Danish).

I only used characters a-z, so I didn't think that would be a problem.
 However, it turns out I had misnamed one of my files so that it
wasn't sorting correctly, and renaming it fixed the problem.
(Previously I had manully included that file first and I had forgotten
to remove it)

Thanks for the help.

Hadley


From ripley at stats.ox.ac.uk  Fri Feb 23 09:10:08 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Feb 2007 08:10:08 +0000 (GMT)
Subject: [Rd] text.rpart for the "class" method doesn't act on
	label="yprob"
In-Reply-To: <200702211030.26010.robert.king@newcastle.edu.au>
References: <200702211030.26010.robert.king@newcastle.edu.au>
Message-ID: <Pine.LNX.4.64.0702230808080.1396@gannet.stats.ox.ac.uk>

Not sure why this on R-devel!  Nobody has contacted the maintainer, as 
asked by the posting guide.

I've wondered about this in the past.  It seems the argument was dropped 
in rpart3, but the help was not changed.  It is checked but not used.


On Wed, 21 Feb 2007, Robert King wrote:

> Hello All,
>
> Am I misreading the documentation?
>
> The text.rpart documentation says:
> "label   a column name of x$frame; values of this will label the nodes. For
> the "class" method, label="yval" results in the factor levels being
> used, "yprob" results in the probability of the winning factor level being
> used, and ??specific yval level?? results in the probability of that factor
> level."
>
> However, yprob doesn't seem to do this:
>> pred = rep(letters[1:6],5)
>> resp = rep(letters[1:3],10)
>> ex.rp <- rpart(resp~pred)
>> plot(ex.rp)
>> text(ex.rp,label="yval")
>
> # works as advertised
>
>> plot(ex.rp)
>> text(ex.rp,label="yprob")
>
> Error in text.rpart(ex.rp, label = "yprob") :
>        Label must be a column label of the frame component of the tree
>
> If I try to fake it, by making an element of the frame, like this:
>> ex.rp$frame$yprob = (ex.rp$frame$n-ex.rp$frame$dev)/ex.rp$frame$n
>
> The text command does add text to the plot, but adds the class labels
> (i.e. "yval"), not the probabilities
>
>> text(ex.rp,label="yprob")
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mel at altk.com  Fri Feb 23 11:49:58 2007
From: mel at altk.com (mel)
Date: Fri, 23 Feb 2007 11:49:58 +0100
Subject: [Rd] IDE for R C++ package writing ?
Message-ID: <45DEC6D6.5090005@altk.com>

Dear all,

I have to develop a (hopefully) small package for R in C++.
I didn't code in C++ for some years, and i'm now searching
for an adequate IDE for this task.

Some of my criterions : not proprietary, not too heavy,
open to linux, not java gasworks, still maintained, etc

After looking on several places
http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
http://www.freeprogrammingresources.com/cppide.html
+ R docs
I was thinking on code::blocks, and emacs (and perhaps vim)

Emacs seems used by some R developers as an R editor.
So i did think on emacs because it could perhaps be interesting
to have the same editor for R code and C++ code.

However, when looking at the last emacs windows version,
it seems to date from january 2004 ... (dead end ?)
ftp://ftp.gnu.org/pub/gnu/emacs/windows/

I will be grateful for all advices on this tool topic.
Better choosing emacs ? or code::blocks ?
or another idea ?
Does somebody have an idea about the most used IDEs for
R C++ package writing ?

Thanks
Vincent


From sdavis2 at mail.nih.gov  Fri Feb 23 11:59:16 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 23 Feb 2007 05:59:16 -0500
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <200702230559.16509.sdavis2@mail.nih.gov>

On Friday 23 February 2007 05:49, mel wrote:
> Dear all,
>
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
>
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
>
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_devel
>opment_environments http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
>
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
>
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
>
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?

Emacs is quite nice, as it has a package for R integration called ESS (emacs 
speaks statistics).  I do not use a GUI on Mac or Linux and just use 
emacs/ESS for running R as well as coding.  

IDE's such as Kdevelop, Eclipse, etc., have a lot of enterprise-level tools 
like automatic makefile generation, etc., but emacs works fine for me and 
what I do.

Sean


From ripley at stats.ox.ac.uk  Fri Feb 23 12:17:12 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Feb 2007 11:17:12 +0000 (GMT)
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <Pine.LNX.4.64.0702231104230.3158@gannet.stats.ox.ac.uk>

You seem to mention both Linux and Windows.

Emacs and XEmacs are both stable on both platforms, and I think most R 
developers use an emacs or vi variant for all their programming.  I would 
not call emacs an IDE, but the main thing I find useful is to have a 
language-aware editor (syntax highlighting, indentation ...).

If you write a package you will also need an Rd editor, and emacs/ESS is 
probably the best supported of those.

Later versions of precompiled emacs for Windows have existed, but I am 
running 21.3.1 (2002) on Windows and 21.4.1 on Linux: emacs itself is very 
stable.  If you prefer a more graphical environment, XEmacs is a good 
alternative and despite its name has an active Windows version.

On Fri, 23 Feb 2007, mel wrote:

> Dear all,
>
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
>
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
>
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
> http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
>
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
>
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
>
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?
>
> Thanks
> Vincent
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdiaz at cnio.es  Fri Feb 23 12:23:42 2007
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 23 Feb 2007 12:23:42 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <200702231223.42112.rdiaz@cnio.es>

On Friday 23 February 2007 11:49, mel wrote:
> Dear all,
>
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
>
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
>
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_devel
>opment_environments http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
>
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
>
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
>
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?


Dear Vincent,

I wouldn't let the date of 2004 scare you away from emacs. And, if I 
understand, in windows you can also use xemacs and/or emacs. 

One extremely nice feature of using Emacs is using the very same editor for R, 
C, C++, or anything else for that matter. It certainly fits your other 
requirements

> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc

Good luck!

R.



>
> Thanks
> Vincent
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Ram?n D?az-Uriarte
Statistical Computing Team
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr?nico, y en s...{{dropped}}


From mel at altk.com  Fri Feb 23 12:30:15 2007
From: mel at altk.com (mel)
Date: Fri, 23 Feb 2007 12:30:15 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <45DED047.7030905@altk.com>

Thanks for those first answers.
Indeed i forgot to precise that i'm currently working
on windows (but would like to be able to evolve to linux).


From dimitris.rizopoulos at med.kuleuven.be  Fri Feb 23 13:20:24 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 23 Feb 2007 13:20:24 +0100
Subject: [Rd] Bootstrapping stepAIC() with glm.nb()
Message-ID: <002601c75744$fea7c930$0540210a@www.domain>

Dear all,

I would like to Boostrap the stepAIC() procedure from package MASS for 
variety of model objects, i.e.,

fn <- function(object, data, B = 2){
    n <- nrow(data)
    res <- vector(mode = "list", length = B)
    index <- sample(n, n * B, replace = TRUE)
    dim(index) <- c(n, B)
    for (i in 1:B) {
        up.obj <- update(object, data = data[index[, i], ])
        res[[i]] <- stepAIC(up.obj, trace = FALSE)
    }
    res
}

####################

library(MASS)


# 'glm' objects
x1 <- runif(100, -4, 4)
x2 <- runif(100, -4, 4)
y <- 1 + 2 * x1 + rnorm(100, sd = 3)
dat <- data.frame(y, x1, x2)
glmFit <- glm(y ~ x1 + x2, data = dat)
fn(glmFit, data = dat)

# 'aov' objects
quine.hi <- aov(log(Days + 2.5) ~ .^4, quine)
fn(quine.hi, data = quine)


However, for "negbin" objects returned by glm.nb() the following 
problem occurs:

quine.nb <- glm.nb(Days ~ .^4, data = quine)
fn(quine.nb, data = quine)


Any hints to overcome this are greatly appreciated.

Thanks in advance,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ripley at stats.ox.ac.uk  Fri Feb 23 13:40:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Feb 2007 12:40:32 +0000 (GMT)
Subject: [Rd] Bootstrapping stepAIC() with glm.nb()
In-Reply-To: <002601c75744$fea7c930$0540210a@www.domain>
References: <002601c75744$fea7c930$0540210a@www.domain>
Message-ID: <Pine.LNX.4.64.0702231227510.4298@gannet.stats.ox.ac.uk>

You did not say what the problem was!

But you are asking that an object which is not in scope (index) be found a 
few levels down.  You should be able to fix this by substituting in the 
values in fn.  Here is one way:

         up.obj <- update(object, data = data[index[, i], ])
         Call <- up.obj$call
         Call$data <- data[index[, i], ]
         up.obj$call <- Call

(there are others).

On Fri, 23 Feb 2007, Dimitris Rizopoulos wrote:

> Dear all,
>
> I would like to Boostrap the stepAIC() procedure from package MASS for
> variety of model objects, i.e.,
>
> fn <- function(object, data, B = 2){
>    n <- nrow(data)
>    res <- vector(mode = "list", length = B)
>    index <- sample(n, n * B, replace = TRUE)
>    dim(index) <- c(n, B)
>    for (i in 1:B) {
>        up.obj <- update(object, data = data[index[, i], ])
>        res[[i]] <- stepAIC(up.obj, trace = FALSE)
>    }
>    res
> }
>
> ####################
>
> library(MASS)
>
>
> # 'glm' objects
> x1 <- runif(100, -4, 4)
> x2 <- runif(100, -4, 4)
> y <- 1 + 2 * x1 + rnorm(100, sd = 3)
> dat <- data.frame(y, x1, x2)
> glmFit <- glm(y ~ x1 + x2, data = dat)
> fn(glmFit, data = dat)
>
> # 'aov' objects
> quine.hi <- aov(log(Days + 2.5) ~ .^4, quine)
> fn(quine.hi, data = quine)
>
>
> However, for "negbin" objects returned by glm.nb() the following
> problem occurs:
>
> quine.nb <- glm.nb(Days ~ .^4, data = quine)
> fn(quine.nb, data = quine)
>
>
> Any hints to overcome this are greatly appreciated.
>
> Thanks in advance,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nilsson.henric at gmail.com  Fri Feb 23 13:54:34 2007
From: nilsson.henric at gmail.com (Henric Nilsson (Public))
Date: Fri, 23 Feb 2007 13:54:34 +0100 (CET)
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <24627.212.209.13.15.1172235274.squirrel@www.sorch.se>

Den Fr, 2007-02-23, 11:49 skrev mel:
> Dear all,
>
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
>
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
>
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
> http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
>
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
>
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/

Not a dead end:
Emacs development has continued and version 22 is due RSN. For Windows
users, I'd recommend EmacsW32 and binaries of the patched Emacs available
from http://ourcomments.org/Emacs/EmacsW32.html. The binaries are current
(22.0.93.1 last time I checked) and the provided EmacsW32 extension offers
quite a few goodies.


HTH,
Henric



>
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?
>
> Thanks
> Vincent
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From dimitris.rizopoulos at med.kuleuven.be  Fri Feb 23 14:07:18 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 23 Feb 2007 14:07:18 +0100
Subject: [Rd] Bootstrapping stepAIC() with glm.nb()
References: <002601c75744$fea7c930$0540210a@www.domain>
	<Pine.LNX.4.64.0702231227510.4298@gannet.stats.ox.ac.uk>
Message-ID: <003f01c7574b$8bc33ba0$0540210a@www.domain>


----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.be>
Cc: <r-devel at r-project.org>
Sent: Friday, February 23, 2007 1:40 PM
Subject: Re: [Rd] Bootstrapping stepAIC() with glm.nb()


> You did not say what the problem was!
>
> But you are asking that an object which is not in scope (index) be 
> found a few levels down.  You should be able to fix this by 
> substituting in the values in fn.  Here is one way:
>
>         up.obj <- update(object, data = data[index[, i], ])
>         Call <- up.obj$call
>         Call$data <- data[index[, i], ]
>         up.obj$call <- Call
>
> (there are others).


thanks very much for your reply and workaround. However, could you 
please explain me (or point me to the right direction) why it *does* 
work, without the workaround, for 'lm', 'glm' and 'aov' objects.

Thanks in advance,
Dimitris




>
> On Fri, 23 Feb 2007, Dimitris Rizopoulos wrote:
>
>> Dear all,
>>
>> I would like to Boostrap the stepAIC() procedure from package MASS 
>> for
>> variety of model objects, i.e.,
>>
>> fn <- function(object, data, B = 2){
>>    n <- nrow(data)
>>    res <- vector(mode = "list", length = B)
>>    index <- sample(n, n * B, replace = TRUE)
>>    dim(index) <- c(n, B)
>>    for (i in 1:B) {
>>        up.obj <- update(object, data = data[index[, i], ])
>>        res[[i]] <- stepAIC(up.obj, trace = FALSE)
>>    }
>>    res
>> }
>>
>> ####################
>>
>> library(MASS)
>>
>>
>> # 'glm' objects
>> x1 <- runif(100, -4, 4)
>> x2 <- runif(100, -4, 4)
>> y <- 1 + 2 * x1 + rnorm(100, sd = 3)
>> dat <- data.frame(y, x1, x2)
>> glmFit <- glm(y ~ x1 + x2, data = dat)
>> fn(glmFit, data = dat)
>>
>> # 'aov' objects
>> quine.hi <- aov(log(Days + 2.5) ~ .^4, quine)
>> fn(quine.hi, data = quine)
>>
>>
>> However, for "negbin" objects returned by glm.nb() the following
>> problem occurs:
>>
>> quine.nb <- glm.nb(Days ~ .^4, data = quine)
>> fn(quine.nb, data = quine)
>>
>>
>> Any hints to overcome this are greatly appreciated.
>>
>> Thanks in advance,
>> Dimitris
>>
>> ----
>> Dimitris Rizopoulos
>> Ph.D. Student
>> Biostatistical Centre
>> School of Public Health
>> Catholic University of Leuven
>>
>> Address: Kapucijnenvoer 35, Leuven, Belgium
>> Tel: +32/(0)16/336899
>> Fax: +32/(0)16/337015
>> Web: http://med.kuleuven.be/biostat/
>>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>>
>>
>> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ripley at stats.ox.ac.uk  Fri Feb 23 14:14:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Feb 2007 13:14:58 +0000 (GMT)
Subject: [Rd] Bootstrapping stepAIC() with glm.nb()
In-Reply-To: <003f01c7574b$8bc33ba0$0540210a@www.domain>
References: <002601c75744$fea7c930$0540210a@www.domain>
	<Pine.LNX.4.64.0702231227510.4298@gannet.stats.ox.ac.uk>
	<003f01c7574b$8bc33ba0$0540210a@www.domain>
Message-ID: <Pine.LNX.4.64.0702231310590.6439@gannet.stats.ox.ac.uk>

On Fri, 23 Feb 2007, Dimitris Rizopoulos wrote:

>
> ----- Original Message ----- From: "Prof Brian Ripley" 
> <ripley at stats.ox.ac.uk>
> To: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.be>
> Cc: <r-devel at r-project.org>
> Sent: Friday, February 23, 2007 1:40 PM
> Subject: Re: [Rd] Bootstrapping stepAIC() with glm.nb()
>
>
>> You did not say what the problem was!
>> 
>> But you are asking that an object which is not in scope (index) be found a 
>> few levels down.  You should be able to fix this by substituting in the 
>> values in fn.  Here is one way:
>>
>>         up.obj <- update(object, data = data[index[, i], ])
>>         Call <- up.obj$call
>>         Call$data <- data[index[, i], ]
>>         up.obj$call <- Call
>> 
>> (there are others).
>
>
> thanks very much for your reply and workaround. However, could you please 
> explain me (or point me to the right direction) why it *does* work, without 
> the workaround, for 'lm', 'glm' and 'aov' objects.

They have dropterm methods that make use of the model frame that is stored 
with the objects (by default).

>
> Thanks in advance,
> Dimitris
>
>
>
>
>> 
>> On Fri, 23 Feb 2007, Dimitris Rizopoulos wrote:
>> 
>>> Dear all,
>>> 
>>> I would like to Boostrap the stepAIC() procedure from package MASS for
>>> variety of model objects, i.e.,
>>> 
>>> fn <- function(object, data, B = 2){
>>>    n <- nrow(data)
>>>    res <- vector(mode = "list", length = B)
>>>    index <- sample(n, n * B, replace = TRUE)
>>>    dim(index) <- c(n, B)
>>>    for (i in 1:B) {
>>>        up.obj <- update(object, data = data[index[, i], ])
>>>        res[[i]] <- stepAIC(up.obj, trace = FALSE)
>>>    }
>>>    res
>>> }
>>> 
>>> ####################
>>> 
>>> library(MASS)
>>> 
>>> 
>>> # 'glm' objects
>>> x1 <- runif(100, -4, 4)
>>> x2 <- runif(100, -4, 4)
>>> y <- 1 + 2 * x1 + rnorm(100, sd = 3)
>>> dat <- data.frame(y, x1, x2)
>>> glmFit <- glm(y ~ x1 + x2, data = dat)
>>> fn(glmFit, data = dat)
>>> 
>>> # 'aov' objects
>>> quine.hi <- aov(log(Days + 2.5) ~ .^4, quine)
>>> fn(quine.hi, data = quine)
>>> 
>>> 
>>> However, for "negbin" objects returned by glm.nb() the following
>>> problem occurs:
>>> 
>>> quine.nb <- glm.nb(Days ~ .^4, data = quine)
>>> fn(quine.nb, data = quine)
>>> 
>>> 
>>> Any hints to overcome this are greatly appreciated.
>>> 
>>> Thanks in advance,
>>> Dimitris
>>> 
>>> ----
>>> Dimitris Rizopoulos
>>> Ph.D. Student
>>> Biostatistical Centre
>>> School of Public Health
>>> Catholic University of Leuven
>>> 
>>> Address: Kapucijnenvoer 35, Leuven, Belgium
>>> Tel: +32/(0)16/336899
>>> Fax: +32/(0)16/337015
>>> Web: http://med.kuleuven.be/biostat/
>>>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>>> 
>>> 
>>> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Feb 23 14:39:43 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 23 Feb 2007 13:39:43 +0000
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <45DEEE9F.9040302@cimr.cam.ac.uk>

I don't know if ess runs under xemacs, but historically,
xemacs (a fork of the emacs code) had windows support earlier than
gnu emacs did, and obviously, it is still being worked on
as the last version is December 2006.

http://www.xemacs.org/Download/win32/

HTH

mel wrote:
> Dear all,
> 
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
> 
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
> 
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
> http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
> 
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
> 
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
> 
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?
> 
> Thanks
> Vincent
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From vincent.goulet at act.ulaval.ca  Fri Feb 23 15:34:36 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Fri, 23 Feb 2007 09:34:36 -0500
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <200702230934.36898.vincent.goulet@act.ulaval.ca>

Le Vendredi 23 F?vrier 2007 05:49, mel a ?crit?:
> Dear all,
>
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
>
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
>
> After looking on several places
> http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_devel
>opment_environments http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
>
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
>
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
>
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?

So, many other people told you that Emacs is a good choice. If you want to try 
it out, I also maintain a modified version of GNU Emacs that is simple to 
install and works with ESS and the latest version of R out of the box:

	http://vgoulet.act.ulaval.ca/emacs

Please note that the bells and whistles of EmacsW32 are not included. It is a 
plain GNU Emacs 21.3 with AUCTeX, ESS, Aspell and other minor enhancements 
thrown in.

HTH

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From marc_schwartz at comcast.net  Fri Feb 23 15:52:49 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 23 Feb 2007 08:52:49 -0600
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <Pine.LNX.4.64.0702231104230.3158@gannet.stats.ox.ac.uk>
References: <45DEC6D6.5090005@altk.com>
	<Pine.LNX.4.64.0702231104230.3158@gannet.stats.ox.ac.uk>
Message-ID: <1172242369.4882.112.camel@localhost.localdomain>

In addition to Prof. Ripley's comments, which I wholeheartedly support,
I might point you to some additional tools, that enhance the use of
Emacs for coding.

I am running Emacs (alpha version 23 from cvs source) under Linux and
while I do not do C, C++ or FORTRAN coding, these tools have
dramatically improved my coding productivity when using R and Sweave (R
+ LaTeX) along with ESS and other standard Emacs tools such as
Auctex/Preview-Latex.


1. ECB - Emacs Code Browser

  http://ecb.sourceforge.net/


2. psvn - A Subversion interface for emacs

  http://www.xsteve.at/prg/vc_svn/


Both of the above, especially if you integrate version control using
Subversion, greatly enhance the functionality of Emacs as an IDE.

HTH,

Marc Schwartz

On Fri, 2007-02-23 at 11:17 +0000, Prof Brian Ripley wrote:
> You seem to mention both Linux and Windows.
> 
> Emacs and XEmacs are both stable on both platforms, and I think most R 
> developers use an emacs or vi variant for all their programming.  I would 
> not call emacs an IDE, but the main thing I find useful is to have a 
> language-aware editor (syntax highlighting, indentation ...).
> 
> If you write a package you will also need an Rd editor, and emacs/ESS is 
> probably the best supported of those.
> 
> Later versions of precompiled emacs for Windows have existed, but I am 
> running 21.3.1 (2002) on Windows and 21.4.1 on Linux: emacs itself is very 
> stable.  If you prefer a more graphical environment, XEmacs is a good 
> alternative and despite its name has an active Windows version.
> 
> On Fri, 23 Feb 2007, mel wrote:
> 
> > Dear all,
> >
> > I have to develop a (hopefully) small package for R in C++.
> > I didn't code in C++ for some years, and i'm now searching
> > for an adequate IDE for this task.
> >
> > Some of my criterions : not proprietary, not too heavy,
> > open to linux, not java gasworks, still maintained, etc
> >
> > After looking on several places
> > http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
> > http://www.freeprogrammingresources.com/cppide.html
> > + R docs
> > I was thinking on code::blocks, and emacs (and perhaps vim)
> >
> > Emacs seems used by some R developers as an R editor.
> > So i did think on emacs because it could perhaps be interesting
> > to have the same editor for R code and C++ code.
> >
> > However, when looking at the last emacs windows version,
> > it seems to date from january 2004 ... (dead end ?)
> > ftp://ftp.gnu.org/pub/gnu/emacs/windows/
> >
> > I will be grateful for all advices on this tool topic.
> > Better choosing emacs ? or code::blocks ?
> > or another idea ?
> > Does somebody have an idea about the most used IDEs for
> > R C++ package writing ?
> >
> > Thanks
> > Vincent


From rdiaz at cnio.es  Fri Feb 23 16:57:23 2007
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 23 Feb 2007 16:57:23 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <1172242369.4882.112.camel@localhost.localdomain>
References: <45DEC6D6.5090005@altk.com>
	<Pine.LNX.4.64.0702231104230.3158@gannet.stats.ox.ac.uk>
	<1172242369.4882.112.camel@localhost.localdomain>
Message-ID: <200702231657.23526.rdiaz@cnio.es>

On Friday 23 February 2007 15:52, Marc Schwartz wrote:
> In addition to Prof. Ripley's comments, which I wholeheartedly support,
> I might point you to some additional tools, that enhance the use of
> Emacs for coding.
>
> I am running Emacs (alpha version 23 from cvs source) under Linux and
> while I do not do C, C++ or FORTRAN coding, these tools have
> dramatically improved my coding productivity when using R and Sweave (R
> + LaTeX) along with ESS and other standard Emacs tools such as
> Auctex/Preview-Latex.
>
>
> 1. ECB - Emacs Code Browser
>
>   http://ecb.sourceforge.net/
>
>
> 2. psvn - A Subversion interface for emacs
>
>   http://www.xsteve.at/prg/vc_svn/
>
>
> Both of the above, especially if you integrate version control using
> Subversion, greatly enhance the functionality of Emacs as an IDE.
>
> HTH,
>
> Marc Schwartz


Just a minor addition to Marc's comment: if you edit Python code, you might 
experience short, but frequent, freezes of Emacs that are related to a 
problem with semantic (a package on which ECB depends). I've not seen these 
with R (or C/C++ or LaTeX).

With that minor caveat, I find ECB is a great tool that works out of the box 
with R.

Best,

R.


>
> On Fri, 2007-02-23 at 11:17 +0000, Prof Brian Ripley wrote:
> > You seem to mention both Linux and Windows.
> >
> > Emacs and XEmacs are both stable on both platforms, and I think most R
> > developers use an emacs or vi variant for all their programming.  I would
> > not call emacs an IDE, but the main thing I find useful is to have a
> > language-aware editor (syntax highlighting, indentation ...).
> >
> > If you write a package you will also need an Rd editor, and emacs/ESS is
> > probably the best supported of those.
> >
> > Later versions of precompiled emacs for Windows have existed, but I am
> > running 21.3.1 (2002) on Windows and 21.4.1 on Linux: emacs itself is
> > very stable.  If you prefer a more graphical environment, XEmacs is a
> > good alternative and despite its name has an active Windows version.
> >
> > On Fri, 23 Feb 2007, mel wrote:
> > > Dear all,
> > >
> > > I have to develop a (hopefully) small package for R in C++.
> > > I didn't code in C++ for some years, and i'm now searching
> > > for an adequate IDE for this task.
> > >
> > > Some of my criterions : not proprietary, not too heavy,
> > > open to linux, not java gasworks, still maintained, etc
> > >
> > > After looking on several places
> > > http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_d
> > >evelopment_environments
> > > http://www.freeprogrammingresources.com/cppide.html
> > > + R docs
> > > I was thinking on code::blocks, and emacs (and perhaps vim)
> > >
> > > Emacs seems used by some R developers as an R editor.
> > > So i did think on emacs because it could perhaps be interesting
> > > to have the same editor for R code and C++ code.
> > >
> > > However, when looking at the last emacs windows version,
> > > it seems to date from january 2004 ... (dead end ?)
> > > ftp://ftp.gnu.org/pub/gnu/emacs/windows/
> > >
> > > I will be grateful for all advices on this tool topic.
> > > Better choosing emacs ? or code::blocks ?
> > > or another idea ?
> > > Does somebody have an idea about the most used IDEs for
> > > R C++ package writing ?
> > >
> > > Thanks
> > > Vincent
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Ram?n D?az-Uriarte
Statistical Computing Team
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr?nico, y en s...{{dropped}}


From h.wickham at gmail.com  Fri Feb 23 17:05:01 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 23 Feb 2007 10:05:01 -0600
Subject: [Rd] Functions that write functions in R packages
Message-ID: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>

Dear all,

Another question related to my ggplot package:  I have made some
substantial changes to the backend of my package so that plot objects
can now describe themselves much better.  A consequence of this is
that a number of convenience functions that previously I wrote by
hand, can now be written automatically.  What is the best practice for
creating these functions for bundling in a package?  I see three
possible solutions:

 * dump function specifications out to a .r file
 * dynamically create at package build time so they are including in
the package rdata file
 * dynamically create at package load time

Can anyone offer any advice as to which is preferable? (or if there's
a better way I haven't thought of)

My code currently looks like this (experimenting with two ways of
creating the functions)

create_accessors <- function(objects, name, short=NULL) {
	lapply(objects, function(x) {
		assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
		if (!is.null(short)) {
			eval(
				substitute(
					f <- function(plot, ...) plot + add(...),
					list(
						add = as.name(paste(name, x$objname, sep="_")),
						f = as.name(paste(short, x$objname, sep=""))
					)
				), envir = globalenv()
			)
				
		}
	})		
}

Thanks,

Hadley


From murdoch at stats.uwo.ca  Fri Feb 23 20:01:56 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 23 Feb 2007 14:01:56 -0500
Subject: [Rd] Functions that write functions in R packages
In-Reply-To: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
References: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
Message-ID: <45DF3A24.1080607@stats.uwo.ca>

On 2/23/2007 11:05 AM, hadley wickham wrote:
> Dear all,
> 
> Another question related to my ggplot package:  I have made some
> substantial changes to the backend of my package so that plot objects
> can now describe themselves much better.  A consequence of this is
> that a number of convenience functions that previously I wrote by
> hand, can now be written automatically.  What is the best practice for
> creating these functions for bundling in a package?  I see three
> possible solutions:
> 
>  * dump function specifications out to a .r file
>  * dynamically create at package build time so they are including in
> the package rdata file
>  * dynamically create at package load time
> 
> Can anyone offer any advice as to which is preferable? (or if there's
> a better way I haven't thought of)
> 
> My code currently looks like this (experimenting with two ways of
> creating the functions)
> 
> create_accessors <- function(objects, name, short=NULL) {
> 	lapply(objects, function(x) {
> 		assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
> 		if (!is.null(short)) {
> 			eval(
> 				substitute(
> 					f <- function(plot, ...) plot + add(...),
> 					list(
> 						add = as.name(paste(name, x$objname, sep="_")),
> 						f = as.name(paste(short, x$objname, sep=""))
> 					)
> 				), envir = globalenv()
> 			)
> 				
> 		}
> 	})		
> }

I'd say it's not a great idea to write to globalenv.  What if your 
function stomps on my object of the same name?  It would be better to 
set up your own environment and write these objects there.  You could 
then attach that environment, and the user would see your functions (if 
he hadn't defined his own).

If others of your functions need to call these, then you need to be 
careful with environments so that they don't accidentally call the 
user's function of the same name instead.

With the considerations above, I think it would be easiest to do the 
creation at install time or earlier, rather than at load time.

Duncan Murdoch


From h.wickham at gmail.com  Fri Feb 23 20:52:45 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 23 Feb 2007 13:52:45 -0600
Subject: [Rd] Functions that write functions in R packages
In-Reply-To: <45DF3A24.1080607@stats.uwo.ca>
References: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
	<45DF3A24.1080607@stats.uwo.ca>
Message-ID: <f8e6ff050702231152y44154de2j249143fc89a0d34e@mail.gmail.com>

On 2/23/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/23/2007 11:05 AM, hadley wickham wrote:
> > Dear all,
> >
> > Another question related to my ggplot package:  I have made some
> > substantial changes to the backend of my package so that plot objects
> > can now describe themselves much better.  A consequence of this is
> > that a number of convenience functions that previously I wrote by
> > hand, can now be written automatically.  What is the best practice for
> > creating these functions for bundling in a package?  I see three
> > possible solutions:
> >
> >  * dump function specifications out to a .r file
> >  * dynamically create at package build time so they are including in
> > the package rdata file
> >  * dynamically create at package load time
> >
> > Can anyone offer any advice as to which is preferable? (or if there's
> > a better way I haven't thought of)
> >
> > My code currently looks like this (experimenting with two ways of
> > creating the functions)
> >
> > create_accessors <- function(objects, name, short=NULL) {
> >       lapply(objects, function(x) {
> >               assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
> >               if (!is.null(short)) {
> >                       eval(
> >                               substitute(
> >                                       f <- function(plot, ...) plot + add(...),
> >                                       list(
> >                                               add = as.name(paste(name, x$objname, sep="_")),
> >                                               f = as.name(paste(short, x$objname, sep=""))
> >                                       )
> >                               ), envir = globalenv()
> >                       )
> >
> >               }
> >       })
> > }
>
> I'd say it's not a great idea to write to globalenv.  What if your
> function stomps on my object of the same name?  It would be better to
> set up your own environment and write these objects there.  You could
> then attach that environment, and the user would see your functions (if
> he hadn't defined his own).

I agree - this is just my working code.

> If others of your functions need to call these, then you need to be
> careful with environments so that they don't accidentally call the
> user's function of the same name instead.
>
> With the considerations above, I think it would be easiest to do the
> creation at install time or earlier, rather than at load time.

But how should I do that?  Is the easiest way simply to autogenerate
an R file, rather than the functions themselves?

Thanks,

Hadley


From jeff.horner at vanderbilt.edu  Fri Feb 23 21:57:12 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 23 Feb 2007 14:57:12 -0600
Subject: [Rd] Formatting difftime objects
Message-ID: <45DF5528.8000809@vanderbilt.edu>

I like the new difftime functionality. Here's a dataframe of 5k run times:
 > r5k
          race                date     totaltime          pace     mile
1     RUDOLPH 2004-12-03 19:00:00 27.76667 mins 8.937224 mins 3.106856
2     RUDOLPH 2005-12-02 18:30:00 25.28333 mins 8.137916 mins 3.106856
3   FROSTBITE 2005-12-10 07:00:00 24.75000 mins 7.966253 mins 3.106856
4    JUDICATA 2006-03-04 08:00:00 25.51667 mins 8.213019 mins 3.106856
5    TOM KING 2006-03-18 07:00:00 23.71667 mins 7.633655 mins 3.106856
6     RUDOLPH 2006-12-01 18:30:00 24.21667 mins 7.794589 mins 3.106856
7  FATHERHOOD 2006-06-24 07:00:00 23.51667 mins 7.569281 mins 3.106856
8 FIRECRACKER 2006-07-04 07:00:00 23.53333 mins 7.574646 mins 3.106856
9  FANGTASTIC 2007-02-10 10:00:00 22.86667 mins 7.360067 mins 3.106856

But I thought the formatting could use some help, so I re-wrote 
base::format.difftime and added support for the conversion 
specifications '%W', '%d', '%H', '%M', and '%S' (borrowed from 
strftime). It also honors getOption("digits") and 
getOption(digits.secs") for '%S'. I added support for a "format" 
attribute as well:

 > attr(r5k$pace,"format") <- "%M:%S"
 > attr(r5k$totaltime,"format") <- "%M:%S"
 > r5k
          race                date totaltime  pace     mile
1     RUDOLPH 2004-12-03 19:00:00     27:46 08:56 3.106856
2     RUDOLPH 2005-12-02 18:30:00     25:17 08:08 3.106856
3   FROSTBITE 2005-12-10 07:00:00     24:45 07:58 3.106856
4    JUDICATA 2006-03-04 08:00:00     25:31 08:13 3.106856
5    TOM KING 2006-03-18 07:00:00     23:43 07:38 3.106856
6     RUDOLPH 2006-12-01 18:30:00     24:13 07:48 3.106856
7  FATHERHOOD 2006-06-24 07:00:00     23:31 07:34 3.106856
8 FIRECRACKER 2006-07-04 07:00:00     23:32 07:34 3.106856
9  FANGTASTIC 2007-02-10 10:00:00     22:52 07:22 3.106856

Formats can also be passed as an argument:

 > format(sum(r5k$totaltime),"%W:%d:%H:%M:%S")
[1] "00:00:03:41:10"
 > format(sum(r5k$totaltime),"%W:%d")
[1] "00:0.1535880"
 > format(sum(r5k$totaltime),"%W")
[1] "0.0219411"

My code is a little verbose, and I'm looking for some optimizations. If 
anyone has comments, suggestions, I'd be much obliged.

Here's the code:
format.difftime <- function (x,format=NULL,...)
{
     # Look for a "format" attribute, if null then return basics
     if (is.null(format)){
         if (is.null(attr(x,"format")))
             return(paste(format(unclass(x),...), units(x)))
         else
             format <- rep(attr(x,"format"),length(x))
     } else {
         format <- rep(format,length(x))
     }

     units(x)<-'secs'

     rem <- unclass(x)

     w <- d <- h <- m <- s <- array(0,length(x))
     lunit <- ""
     if (length(grep('%W',format,fixed=TRUE)) > 0 ){
         w     <- rem %/% (7 * 86400)
         rem   <- rem - w * 7 * 86400
         lunit <- "weeks"
     }
     if (length(grep('%d',format,fixed=TRUE)) > 0){
         d     <- rem %/% 86400
         rem   <- rem - d * 86400
         lunit <- "days"
     }
     if (length(grep('%H',format,fixed=TRUE)) > 0){
         h     <- rem %/% 3600
         rem   <- rem - h * 3600
         lunit <- "hours"
     }
     if (length(grep('%M',format,fixed=TRUE)) > 0){
         m     <- rem %/% 60
         rem   <- rem  - m *  60
         lunit <- "mins"
     }
     if (length(grep('%S',format,fixed=TRUE)) > 0){
         s     <- rem
         rem   <- rem - s
         lunit <- "secs"
     }

     # Find precision formatting
     digits <-
         ifelse(is.null(getOption("digits")),
             0,
             as.integer(getOption("digits"))
         )
     digits.secs <-
         ifelse(is.null(getOption("digits.secs")),
             0,
             as.integer(getOption("digits.secs"))
         )

     # Place remainder in last unit we saw.
     # Also set formatting.
     wf <- df <- hf <- mf <- sf <- "%02.f"
     if (lunit != ""){
         if (lunit == "weeks"){
             w <- w + rem / (7 * 86400)
             wf <- paste("%02.",digits,"f",sep='')
         } else if (lunit == "days"){
             d <- d + rem / 86400
             df <- paste("%02.",digits,"f",sep='')
         } else if (lunit == "hours"){
             h <- h + rem / 3600
             hf <- paste("%02.",digits,"f",sep='')
         } else if (lunit == "mins"){
             m <- m + rem / 60
             mf <- paste("%02.",digits,"f",sep='')
         } else if (lunit == "secs"){
             sf <- paste("%02.",digits.secs,"f",sep='')
         }
     }


     # Do substitution
     for (i in 1:length(format)){
         format[i] <- gsub('%W',sprintf(wf,w[i]),format[i],fixed=TRUE)
         format[i] <- gsub('%d',sprintf(df,d[i]),format[i],fixed=TRUE)
         format[i] <- gsub('%H',sprintf(hf,h[i]),format[i],fixed=TRUE)
         format[i] <- gsub('%M',sprintf(mf,m[i]),format[i],fixed=TRUE)
         format[i] <- gsub('%S',sprintf(sf,s[i]),format[i],fixed=TRUE)
     }

     format
}


Cheers,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From m1jjh00 at frb.gov  Fri Feb 23 17:23:53 2007
From: m1jjh00 at frb.gov (Jeffrey J. Hallman)
Date: Fri, 23 Feb 2007 11:23:53 -0500
Subject: [Rd] How to override functions in namespaces?
In-Reply-To: Message from Prof Brian Ripley <ripley@stats.ox.ac.uk> of "Thu,
	22 Feb 2007 23:27:56 GMT."
	<Pine.LNX.4.64.0702222318430.27682@gannet.stats.ox.ac.uk> 
Message-ID: <20070223162353.BED301F7B0@mail.rsma.frb.gov>

Prof Ripley,

Thanks to both you and Duncan Murdoch, who replied with similar advice.
Your suggestion to use get("askForString", pos = 1)() in my ssh()
function does what I want whether package B is attached or not.

Jeff

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
  br> On Mon, 12 Feb 2007, jhallman at frb.gov wrote:
  >> In package A I have askForString(), which asks the user for a string.
  >> Also in package A I have defined ssh(), which calls askForString().
  >> 
  >> Package B has package A as a prerequisite.
  >> 
  >> In package B I redefine askForString() to take advantage of a nicer user
  >> interface made available by B, namely the Emacs mini-buffer prompt.
  >> 
  >> Packages B and A are both on the search path, with B ahead of A.  If I
  >> call askForString() at the command prompt, I get the version from B.
  >> But the version used by ssh() depends on whether or not package A has a
  >> namespace. If so, ssh() (defined in A) always uses the A version of
  >> askForString().  How can I get ssh() to use the B version of
  >> askForString()? Or am I going about this all wrong?

  br> That is one of the main purposes of a namespace, but you can defeat it.

  br> In the scenario you paint, B::askForString() should work (whether or not B has
  br> a namespace).


  br> If (I am guessing) you want the version that would be gotten at the top level
  br> (the > prompt) whether or not B is in use, use

  br> get("askForString", pos=1)().


From kw.statr at gmail.com  Fri Feb 23 23:42:23 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Fri, 23 Feb 2007 16:42:23 -0600
Subject: [Rd] Solved two problems with Cygwin
Message-ID: <c968588d0702231442s588a7ec6yad3367e79c6d7474@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070223/f50799d4/attachment.pl 

From h.wickham at gmail.com  Sat Feb 24 02:38:01 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 23 Feb 2007 19:38:01 -0600
Subject: [Rd] Depending on many packages: another best practice question
Message-ID: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>

Dear all,

ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
sm).  Some of these are absolutely necessary (eg. proto), but most are
used for one or two specific tasks (eg. boot is only used to get
plogis, used for logit scales).

Do you think I should make them all "depends" packages, or "suggests"
packages, and then manually test for package presence before using a
certain function?  What is easier for users?

Thanks,

Hadley


From ggrothendieck at gmail.com  Sat Feb 24 06:33:44 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Feb 2007 00:33:44 -0500
Subject: [Rd] Functions that write functions in R packages
In-Reply-To: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
References: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
Message-ID: <971536df0702232133w4d167f32p6fd761a18421fc1f@mail.gmail.com>

Not sure what the setup is here but if the objects are
intended to be proto objects then the accessor functions
could be placed in the object itself (or in an ancestor object)
rather than in the global environment.  For example, this inserts
a function get.v(.) into proto object p for each variable v in p.

library(proto)

make.accessors <- function(p, ...) {
   lapply(ls(p, ...), f. <- function(v) {
       	nm <- paste("get", v, sep = ".")
	p[[nm]] <- function(.) {}
	body(p[[nm]]) <- substitute(.$v, list(v = v))
	environment(p[[nm]]) <- p
   })
   invisible(p)
}
make.accessors(p)
p$get.x()
p$get.y()

# or the constructor of objects like p could build it right it
# at object construction time
make.p <- function(...) make.accessors(proto(...))
q <- make.p(x = 1, y = 2)
q$get.x()	
q$get.y()	


On 2/23/07, hadley wickham <h.wickham at gmail.com> wrote:
> Dear all,
>
> Another question related to my ggplot package:  I have made some
> substantial changes to the backend of my package so that plot objects
> can now describe themselves much better.  A consequence of this is
> that a number of convenience functions that previously I wrote by
> hand, can now be written automatically.  What is the best practice for
> creating these functions for bundling in a package?  I see three
> possible solutions:
>
>  * dump function specifications out to a .r file
>  * dynamically create at package build time so they are including in
> the package rdata file
>  * dynamically create at package load time
>
> Can anyone offer any advice as to which is preferable? (or if there's
> a better way I haven't thought of)
>
> My code currently looks like this (experimenting with two ways of
> creating the functions)
>
> create_accessors <- function(objects, name, short=NULL) {
>        lapply(objects, function(x) {
>                assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
>                if (!is.null(short)) {
>                        eval(
>                                substitute(
>                                        f <- function(plot, ...) plot + add(...),
>                                        list(
>                                                add = as.name(paste(name, x$objname, sep="_")),
>                                                f = as.name(paste(short, x$objname, sep=""))
>                                        )
>                                ), envir = globalenv()
>                        )
>
>                }
>        })
> }
>
> Thanks,
>
> Hadley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From blindglobe at gmail.com  Sat Feb 24 13:28:17 2007
From: blindglobe at gmail.com (AJ Rossini)
Date: Sat, 24 Feb 2007 13:28:17 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <24627.212.209.13.15.1172235274.squirrel@www.sorch.se>
References: <45DEC6D6.5090005@altk.com>
	<24627.212.209.13.15.1172235274.squirrel@www.sorch.se>
Message-ID: <200702241328.23342.blindglobe@gmail.com>


> Den Fr, 2007-02-23, 11:49 skrev mel:

> > I will be grateful for all advices on this tool topic.
> > Better choosing emacs ? or code::blocks ?
> > or another idea ?
> > Does somebody have an idea about the most used IDEs for
> > R C++ package writing ?

Emacs has IDE capabilities possible, as extensions.   See the CEDET library 
and ECB package extension for code browsers, UML tools, etc.  JDEE (Java 
development environment for Emacs) is an excellent IDE for Java, SLIME is 
excellent for Common Lisp, but there isn't a truly excellent tool for C++ or 
R at this time.  (ESS IMHO is as good as it gets at present, but let's 
reserve the term "excellent" for things that deserve it, having stood the 
long test of time and design standards, like Emacs and Common Lisp have).

best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can 
easily
roll-back your mistakes" (AJR, 4Jan05).
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070224/7469d4db/attachment.bin 

From res90sx5 at verizon.net  Sat Feb 24 01:03:49 2007
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Fri, 23 Feb 2007 16:03:49 -0800
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEEE9F.9040302@cimr.cam.ac.uk>
Message-ID: <015201c757a7$43396ba0$0201a8c0@Aragorn>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Hin-Tak Leung
> Sent: Friday, February 23, 2007 5:40 AM
> To: mel
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] IDE for R C++ package writing ?
> 
> I don't know if ess runs under xemacs, but historically,

I have used ess under Xemacs on Windows.  I think John Fox still has some documents and files available on the web for setting up Xemacs with ess.  You can try searching the R-help archives or probably even just google Fox and Xemacs.

Hope this is helpful,

Dan Nordlund
Bothell, WA  USA 

> xemacs (a fork of the emacs code) had windows support earlier than
> gnu emacs did, and obviously, it is still being worked on
> as the last version is December 2006.
> 
> http://www.xemacs.org/Download/win32/
> 
> HTH


From izmirlian at nih.gov  Sat Feb 24 02:45:54 2007
From: izmirlian at nih.gov (Grant Izmirlian)
Date: Fri, 23 Feb 2007 20:45:54 -0500
Subject: [Rd]  IDE for R C++ package writing ?
In-Reply-To: <mailman.10.1172228404.11456.r-devel@r-project.org>
References: <mailman.10.1172228404.11456.r-devel@r-project.org>
Message-ID: <200702232045.54315.izmirlian@nih.gov>

On windows the currently maintained version is xemacs...the projcects split 
some time ago.
-- 
Grant Izmirlian
NCI
????? ?????????

On Friday 23 February 2007 06:00, r-devel-request at r-project.org wrote:
> [Rd] IDE for R C++ package writing ?
> Dear all,
> 
> I have to develop a (hopefully) small package for R in C++.
> I didn't code in C++ for some years, and i'm now searching
> for an adequate IDE for this task.
> 
> Some of my criterions : not proprietary, not too heavy,
> open to linux, not java gasworks, still maintained, etc
> 
> After looking on several places
>http://en.wikipedia.org/wiki/List_of_C%2B%2B_compilers_and_integrated_development_environments
> http://www.freeprogrammingresources.com/cppide.html
> + R docs
> I was thinking on code::blocks, and emacs (and perhaps vim)
> 
> Emacs seems used by some R developers as an R editor.
> So i did think on emacs because it could perhaps be interesting
> to have the same editor for R code and C++ code.
> 
> However, when looking at the last emacs windows version,
> it seems to date from january 2004 ... (dead end ?)
> ftp://ftp.gnu.org/pub/gnu/emacs/windows/
> 
> I will be grateful for all advices on this tool topic.
> Better choosing emacs ? or code::blocks ?
> or another idea ?
> Does somebody have an idea about the most used IDEs for
> R C++ package writing ?
> 
> Thanks
> Vincent


From edd at debian.org  Sat Feb 24 16:00:51 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 24 Feb 2007 09:00:51 -0600
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
Message-ID: <17888.21283.92112.591730@basebud.nulle.part>


On 23 February 2007 at 19:38, hadley wickham wrote:
| ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
| proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
| sm).  Some of these are absolutely necessary (eg. proto), but most are
| used for one or two specific tasks (eg. boot is only used to get
| plogis, used for logit scales).
| 
| Do you think I should make them all "depends" packages, or "suggests"
| packages, and then manually test for package presence before using a
| certain function?  What is easier for users?

Rcmdr uses to have hard Depends. Given that I maintained Rcmdr in Debian, I
had to add a lot of additional packages to Debian only to cover Rcmdr's build
requirements.   

John later changed that to Suggests

   Depends: R (>= 2.1.0), tcltk, grDevices, utils
   Suggests: abind, car (>= 1.2-1), effects (>= 1.0-7), foreign, grid,
   lattice, lmtest, MASS, mgcv, multcomp (>= 0.991-2), nlme, nnet, relimp,
   rgl, RODBC 

which he then tests for in Startup.R.  I think Graham's rattle does something
similar.

I think you will get confused users either way as it is impossible to please
all the people all the time. Foolprof methods only attract smarter fools.

Hope this helps, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From h.wickham at gmail.com  Sat Feb 24 16:29:58 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 24 Feb 2007 09:29:58 -0600
Subject: [Rd] Functions that write functions in R packages
In-Reply-To: <971536df0702232133w4d167f32p6fd761a18421fc1f@mail.gmail.com>
References: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
	<971536df0702232133w4d167f32p6fd761a18421fc1f@mail.gmail.com>
Message-ID: <f8e6ff050702240729j1ce31159g7b509d20c9fe3bcb@mail.gmail.com>

I'm trying to make wrappers to proto functions (eg. GeomPoint$new())
so that user don't notice that they're using a proto function (ie. use
geom_point()) instead.  I'm hoping I can wrap proto up sufficiently
that only developers need to worry that ggplot uses a completely
different oo system.

Hadley

On 2/23/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Not sure what the setup is here but if the objects are
> intended to be proto objects then the accessor functions
> could be placed in the object itself (or in an ancestor object)
> rather than in the global environment.  For example, this inserts
> a function get.v(.) into proto object p for each variable v in p.
>
> library(proto)
>
> make.accessors <- function(p, ...) {
>    lapply(ls(p, ...), f. <- function(v) {
>         nm <- paste("get", v, sep = ".")
>         p[[nm]] <- function(.) {}
>         body(p[[nm]]) <- substitute(.$v, list(v = v))
>         environment(p[[nm]]) <- p
>    })
>    invisible(p)
> }
> make.accessors(p)
> p$get.x()
> p$get.y()
>
> # or the constructor of objects like p could build it right it
> # at object construction time
> make.p <- function(...) make.accessors(proto(...))
> q <- make.p(x = 1, y = 2)
> q$get.x()
> q$get.y()
>
>
> On 2/23/07, hadley wickham <h.wickham at gmail.com> wrote:
> > Dear all,
> >
> > Another question related to my ggplot package:  I have made some
> > substantial changes to the backend of my package so that plot objects
> > can now describe themselves much better.  A consequence of this is
> > that a number of convenience functions that previously I wrote by
> > hand, can now be written automatically.  What is the best practice for
> > creating these functions for bundling in a package?  I see three
> > possible solutions:
> >
> >  * dump function specifications out to a .r file
> >  * dynamically create at package build time so they are including in
> > the package rdata file
> >  * dynamically create at package load time
> >
> > Can anyone offer any advice as to which is preferable? (or if there's
> > a better way I haven't thought of)
> >
> > My code currently looks like this (experimenting with two ways of
> > creating the functions)
> >
> > create_accessors <- function(objects, name, short=NULL) {
> >        lapply(objects, function(x) {
> >                assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
> >                if (!is.null(short)) {
> >                        eval(
> >                                substitute(
> >                                        f <- function(plot, ...) plot + add(...),
> >                                        list(
> >                                                add = as.name(paste(name, x$objname, sep="_")),
> >                                                f = as.name(paste(short, x$objname, sep=""))
> >                                        )
> >                                ), envir = globalenv()
> >                        )
> >
> >                }
> >        })
> > }
> >
> > Thanks,
> >
> > Hadley
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From ggrothendieck at gmail.com  Sat Feb 24 17:35:22 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Feb 2007 11:35:22 -0500
Subject: [Rd] Functions that write functions in R packages
In-Reply-To: <f8e6ff050702240729j1ce31159g7b509d20c9fe3bcb@mail.gmail.com>
References: <f8e6ff050702230805s2c45957epe516e5b431a7cdd2@mail.gmail.com>
	<971536df0702232133w4d167f32p6fd761a18421fc1f@mail.gmail.com>
	<f8e6ff050702240729j1ce31159g7b509d20c9fe3bcb@mail.gmail.com>
Message-ID: <971536df0702240835t1dd2ba3ek756fc91574b2175e@mail.gmail.com>

How about something like this where we put the accessors in
.GlobalEnv at object construction time in this example but you
could alternately place them into package:ggplot or elsewhere on
the search path:

library(proto)

make.accessors <- function(p, e = p, ...)
  lapply(ls(p, ...), function(v) {
     if (is.function(get(v, p))) e[[v]] <- do.call("$.proto", list(p, v))
  invisible(p)
})
p <- proto(x = function(.) 1, y = function(.) 2)
make.accessors(p, .GlobalEnv)
x()
print(x)
y()
print(y)
rm(x, y)

# or the constructor of objects like p could build it right it
# at object construction time
make.p <- function(..., e = .GlobalEnv) make.accessors(proto(...), e = e)
q <- make.p(x = function(.) 1, y = function(.) 2)
x()
print(x)
y()
print(y)









On 2/24/07, hadley wickham <h.wickham at gmail.com> wrote:
> I'm trying to make wrappers to proto functions (eg. GeomPoint$new())
> so that user don't notice that they're using a proto function (ie. use
> geom_point()) instead.  I'm hoping I can wrap proto up sufficiently
> that only developers need to worry that ggplot uses a completely
> different oo system.
>
> Hadley
>
> On 2/23/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Not sure what the setup is here but if the objects are
> > intended to be proto objects then the accessor functions
> > could be placed in the object itself (or in an ancestor object)
> > rather than in the global environment.  For example, this inserts
> > a function get.v(.) into proto object p for each variable v in p.
> >
> > library(proto)
> >
> > make.accessors <- function(p, ...) {
> >    lapply(ls(p, ...), f. <- function(v) {
> >         nm <- paste("get", v, sep = ".")
> >         p[[nm]] <- function(.) {}
> >         body(p[[nm]]) <- substitute(.$v, list(v = v))
> >         environment(p[[nm]]) <- p
> >    })
> >    invisible(p)
> > }
> > make.accessors(p)
> > p$get.x()
> > p$get.y()
> >
> > # or the constructor of objects like p could build it right it
> > # at object construction time
> > make.p <- function(...) make.accessors(proto(...))
> > q <- make.p(x = 1, y = 2)
> > q$get.x()
> > q$get.y()
> >
> >
> > On 2/23/07, hadley wickham <h.wickham at gmail.com> wrote:
> > > Dear all,
> > >
> > > Another question related to my ggplot package:  I have made some
> > > substantial changes to the backend of my package so that plot objects
> > > can now describe themselves much better.  A consequence of this is
> > > that a number of convenience functions that previously I wrote by
> > > hand, can now be written automatically.  What is the best practice for
> > > creating these functions for bundling in a package?  I see three
> > > possible solutions:
> > >
> > >  * dump function specifications out to a .r file
> > >  * dynamically create at package build time so they are including in
> > > the package rdata file
> > >  * dynamically create at package load time
> > >
> > > Can anyone offer any advice as to which is preferable? (or if there's
> > > a better way I haven't thought of)
> > >
> > > My code currently looks like this (experimenting with two ways of
> > > creating the functions)
> > >
> > > create_accessors <- function(objects, name, short=NULL) {
> > >        lapply(objects, function(x) {
> > >                assign(paste(name, x$objname, sep="_"), x$new, pos=globalenv())
> > >                if (!is.null(short)) {
> > >                        eval(
> > >                                substitute(
> > >                                        f <- function(plot, ...) plot + add(...),
> > >                                        list(
> > >                                                add = as.name(paste(name, x$objname, sep="_")),
> > >                                                f = as.name(paste(short, x$objname, sep=""))
> > >                                        )
> > >                                ), envir = globalenv()
> > >                        )
> > >
> > >                }
> > >        })
> > > }
> > >
> > > Thanks,
> > >
> > > Hadley
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>


From simon.urbanek at r-project.org  Sat Feb 24 18:15:37 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 24 Feb 2007 12:15:37 -0500
Subject: [Rd] R crashes in Mac OS
In-Reply-To: <1061F143-443E-4C68-B162-1DE10E2A0C01@bristol.ac.uk>
References: <1061F143-443E-4C68-B162-1DE10E2A0C01@bristol.ac.uk>
Message-ID: <3B0A38A1-ADD7-4325-82FB-B9FAB1EFC3F8@r-project.org>


On Feb 18, 2007, at 2:08 PM, Giusi Moffa wrote:

> I am running R under Mac OS X (Tiger, v10.4). Unfortunately it keeps
> crashing while using the editor. One thing that seems to make things
> worse is having more than one script open at the same time. Can
> anyone help?
>

Please send me a full crash report. Also please try to find a  
reproducible example if you can.

Thanks,
Simon


From ripley at stats.ox.ac.uk  Sat Feb 24 19:38:51 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Feb 2007 18:38:51 +0000 (GMT)
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>

On Fri, 23 Feb 2007, hadley wickham wrote:

> Dear all,
>
> ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
> proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
> sm).  Some of these are absolutely necessary (eg. proto), but most are
> used for one or two specific tasks (eg. boot is only used to get
> plogis, used for logit scales).

Hmm, there is no plogis in boot, but there is in stats.

> Do you think I should make them all "depends" packages, or "suggests"
> packages, and then manually test for package presence before using a
> certain function?  What is easier for users?

The second, especially as from 2.5.0 the 'Depends' and 'Imports' are 
installed by default.

What you have not mentioned is that those packages also have dependencies.

Using 'Depends' on a non-CRAN package (e.g. hexbin) is definitely awkward 
for the user/sysadmin and I would try to avoid it.

I've been here with ggplot for my GGobi class, and a smaller set of
would have been helpful.  Do you really need reshape, for example?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Sat Feb 24 20:21:53 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 24 Feb 2007 13:21:53 -0600
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>

> > ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
> > proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
> > sm).  Some of these are absolutely necessary (eg. proto), but most are
> > used for one or two specific tasks (eg. boot is only used to get
> > plogis, used for logit scales).
>
> Hmm, there is no plogis in boot, but there is in stats.

Oops, I had originally included it to use logit and inv.logit, but
then realised I could use plogis etc instead.  That's one dependency
down.

>
> > Do you think I should make them all "depends" packages, or "suggests"
> > packages, and then manually test for package presence before using a
> > certain function?  What is easier for users?
>
> The second, especially as from 2.5.0 the 'Depends' and 'Imports' are
> installed by default.

Ok, that makes sense then.

> What you have not mentioned is that those packages also have dependencies.
>
> Using 'Depends' on a non-CRAN package (e.g. hexbin) is definitely awkward
> for the user/sysadmin and I would try to avoid it.

It's frustrating enough for the windows user, as suggests packages
seem to get installed by default as well.

> I've been here with ggplot for my GGobi class, and a smaller set of
> would have been helpful.  Do you really need reshape, for example?

Reshape powers the facetting, so is essential.  It also reflects my
philosophy of separating data manipulation from display, as opposed to
lattice which often combines the two (there are advantages and
disadvantages to both, of course)

I think the minimum I need is grid, reshape, and proto, none of which
have any further dependencies.

Hadley


From ripley at stats.ox.ac.uk  Sat Feb 24 21:13:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Feb 2007 20:13:50 +0000 (GMT)
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com> 
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>

On Sat, 24 Feb 2007, hadley wickham wrote:

>> > ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
>> > proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
>> > sm).  Some of these are absolutely necessary (eg. proto), but most are
>> > used for one or two specific tasks (eg. boot is only used to get
>> > plogis, used for logit scales).
>> 
>> Hmm, there is no plogis in boot, but there is in stats.
>
> Oops, I had originally included it to use logit and inv.logit, but
> then realised I could use plogis etc instead.  That's one dependency
> down.
>
>> 
>> > Do you think I should make them all "depends" packages, or "suggests"
>> > packages, and then manually test for package presence before using a
>> > certain function?  What is easier for users?
>> 
>> The second, especially as from 2.5.0 the 'Depends' and 'Imports' are
>> installed by default.
>
> Ok, that makes sense then.
>
>> What you have not mentioned is that those packages also have dependencies.
>> 
>> Using 'Depends' on a non-CRAN package (e.g. hexbin) is definitely awkward
>> for the user/sysadmin and I would try to avoid it.
>
> It's frustrating enough for the windows user, as suggests packages
> seem to get installed by default as well.

Prior to 2.5.0, yes, but not in future.

>
>> I've been here with ggplot for my GGobi class, and a smaller set of
>> would have been helpful.  Do you really need reshape, for example?
>
> Reshape powers the facetting, so is essential.  It also reflects my
> philosophy of separating data manipulation from display, as opposed to
> lattice which often combines the two (there are advantages and
> disadvantages to both, of course)
>
> I think the minimum I need is grid, reshape, and proto, none of which
> have any further dependencies.
>
> Hadley
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From S.J.Eglen at damtp.cam.ac.uk  Sun Feb 25 11:49:31 2007
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Sun, 25 Feb 2007 10:49:31 +0000
Subject: [Rd] typo in R-lang.texi
Message-ID: <17889.27067.556027.967012@notch.damtp.cam.ac.uk>

Hi, 

R-lang.texi line 2020/1 currently says:

  This allows, e.g., a 
  local variable in a function to have the same name AS a global object. 

The word "AS" is missing in that sentence.

(Line number according to
 https://svn.r-project.org/R/trunk/doc/manual/R-lang.texi)

Stephen


From felix.naef at isrec.ch  Sat Feb 24 16:58:59 2007
From: felix.naef at isrec.ch (felix.naef at isrec.ch)
Date: Sat, 24 Feb 2007 16:58:59 +0100 (CET)
Subject: [Rd] slow graphics on MAC OS X R-2.4.1 (PR#9530)
Message-ID: <20070224155859.7DD5A5D5D2@slim.kubism.ku.dk>

We use R a lot for graphics and noticed very slow graphics in Quartz  
mode where X11 is much faster.

Our hardware: intel mac pro and intel macbook pro, both are affected.

os versions: OS X Tiger 10.4.8
R version: R version 2.4.1 (2006-12-18)

We tried the following simple thing.

- Open the R program from the dock (not from the command line)
- run the following two lines:
d = matrix(runif(300*2000),300,2000)
image(d)
image(d)  #again a second time

and see how long it takes to appear on screen the first time, and  
again the second time.

Then close R and open an X11 terminal and start R from the command line.
try the same commands
d = matrix(runif(300*2000),300,2000)
image(d)
image(d)  #again a second time

We found huge differences in speed, perhaps we are doing something  
wrong?
As a result we exclusively use R in X11 mode which works fine for us.


Felix Naef



	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Sun Feb 25 15:57:53 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 25 Feb 2007 08:57:53 -0600
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
	<Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050702250657i1ff01035je267f64a5d584b85@mail.gmail.com>

On 2/24/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Sat, 24 Feb 2007, hadley wickham wrote:
>
> >> > ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
> >> > proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
> >> > sm).  Some of these are absolutely necessary (eg. proto), but most are
> >> > used for one or two specific tasks (eg. boot is only used to get
> >> > plogis, used for logit scales).
> >>
> >> Hmm, there is no plogis in boot, but there is in stats.
> >
> > Oops, I had originally included it to use logit and inv.logit, but
> > then realised I could use plogis etc instead.  That's one dependency
> > down.
> >
> >>
> >> > Do you think I should make them all "depends" packages, or "suggests"
> >> > packages, and then manually test for package presence before using a
> >> > certain function?  What is easier for users?
> >>
> >> The second, especially as from 2.5.0 the 'Depends' and 'Imports' are
> >> installed by default.
> >
> > Ok, that makes sense then.
> >
> >> What you have not mentioned is that those packages also have dependencies.
> >>
> >> Using 'Depends' on a non-CRAN package (e.g. hexbin) is definitely awkward
> >> for the user/sysadmin and I would try to avoid it.
> >
> > It's frustrating enough for the windows user, as suggests packages
> > seem to get installed by default as well.
>
> Prior to 2.5.0, yes, but not in future.

Great.  One more question:  do you have any suggstion for you I should
deal with examples?  Do I have to wrap those in conditional require
statements as well?  That seems to be the way to get R CMD check to
pass, but adds (unnecessary?) repitition.

Hadley


From ggrothendieck at gmail.com  Sun Feb 25 16:38:18 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 25 Feb 2007 10:38:18 -0500
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <f8e6ff050702250657i1ff01035je267f64a5d584b85@mail.gmail.com>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
	<Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>
	<f8e6ff050702250657i1ff01035je267f64a5d584b85@mail.gmail.com>
Message-ID: <971536df0702250738o168336e5q67fd997eb86958ae@mail.gmail.com>

You can use

if(require(myPackage)) { ... }

or

\dontrun{ ... }

or

make them demos in the myPackage/demo directory since demos
are not checked.


On 2/25/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 2/24/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > On Sat, 24 Feb 2007, hadley wickham wrote:
> >
> > >> > ggplot currently requires 13 packages (grid, reshape, RColorBrewer,
> > >> > proto, splines, MASS, Hmisc, boot, butler, hexbin, mapproj, quantreg,
> > >> > sm).  Some of these are absolutely necessary (eg. proto), but most are
> > >> > used for one or two specific tasks (eg. boot is only used to get
> > >> > plogis, used for logit scales).
> > >>
> > >> Hmm, there is no plogis in boot, but there is in stats.
> > >
> > > Oops, I had originally included it to use logit and inv.logit, but
> > > then realised I could use plogis etc instead.  That's one dependency
> > > down.
> > >
> > >>
> > >> > Do you think I should make them all "depends" packages, or "suggests"
> > >> > packages, and then manually test for package presence before using a
> > >> > certain function?  What is easier for users?
> > >>
> > >> The second, especially as from 2.5.0 the 'Depends' and 'Imports' are
> > >> installed by default.
> > >
> > > Ok, that makes sense then.
> > >
> > >> What you have not mentioned is that those packages also have dependencies.
> > >>
> > >> Using 'Depends' on a non-CRAN package (e.g. hexbin) is definitely awkward
> > >> for the user/sysadmin and I would try to avoid it.
> > >
> > > It's frustrating enough for the windows user, as suggests packages
> > > seem to get installed by default as well.
> >
> > Prior to 2.5.0, yes, but not in future.
>
> Great.  One more question:  do you have any suggstion for you I should
> deal with examples?  Do I have to wrap those in conditional require
> statements as well?  That seems to be the way to get R CMD check to
> pass, but adds (unnecessary?) repitition.
>
> Hadley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ernest.turro at ic.ac.uk  Sun Feb 25 18:37:24 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Sun, 25 Feb 2007 17:37:24 +0000
Subject: [Rd] R/C++/memory leaks
Message-ID: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>

Dear all,

I have wrapped a C++ function in an R package. I allocate/deallocate  
memory using C++ 'new' and 'delete'. In order to allow user  
interrupts without memory leaks I've moved all the delete statements  
required after an interrupt to a separate C++ function freeMemory(),  
which is called using on.exit() just before the .C() call.

I am concerned about the following. In square brackets you see R's  
total virtual memory use (VIRT in `top`):

1) Load library and data [178MB] (if I run gc(), then [122MB])
2) Just before .C [223MB]
3) Just before freeing memory [325MB]
4) Just after freeing memory [288MB]
5) After running gc() [230MB]

So although the freeMemory function works (frees 37MB), R ends up  
using 100MB more after the function call than before it. ls() only  
returns the data object so no new objects have been added to the  
workspace.

Do any of you have any idea what could be eating this memory?

Many thanks,

Ernest

PS: it is not practical to use R_alloc et al because C++ allocation/ 
deallocation involves constructors/destructors and because the C++  
code is also compiled into a standalone binary (I would rather avoid  
maintaining two separate versions).


From sfalcon at fhcrc.org  Sun Feb 25 18:46:54 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 25 Feb 2007 09:46:54 -0800
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <971536df0702250738o168336e5q67fd997eb86958ae@mail.gmail.com>
	(Gabor Grothendieck's message of "Sun,
	25 Feb 2007 10:38:18 -0500")
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
	<Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>
	<f8e6ff050702250657i1ff01035je267f64a5d584b85@mail.gmail.com>
	<971536df0702250738o168336e5q67fd997eb86958ae@mail.gmail.com>
Message-ID: <m2tzxam8oh.fsf@ziti.local>

"Gabor Grothendieck" <ggrothendieck at gmail.com> writes:

> You can use
>
> if(require(myPackage)) { ... }

Probably you will want:

  if (suppressWarnings(require("somePkg"))) { ... }

This way, you won't get a lot of noise when somePkg isn't installed.

Running the examples at least some of the time seems like a nice idea
to assure basic functionality...

+ seth


From ross at biostat.ucsf.edu  Sun Feb 25 23:21:44 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 25 Feb 2007 14:21:44 -0800
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
Message-ID: <20070225222144.GA16188@wheat.betterworld.us>

On Sun, Feb 25, 2007 at 05:37:24PM +0000, Ernest Turro wrote:
> Dear all,
> 
> I have wrapped a C++ function in an R package. I allocate/deallocate  
> memory using C++ 'new' and 'delete'. In order to allow user  
> interrupts without memory leaks I've moved all the delete statements  
> required after an interrupt to a separate C++ function freeMemory(),  
> which is called using on.exit() just before the .C() call.

Do you mean that you call on.exit() before the .C, and the call to
on.exit() sets up the handler?  Your last sentence sounds as if you
invoke freeMemory() before the .C call.

Another approach is to associate your C objects with an R object, and
have them cleaned up when the R object gets garbage collected.
However, this requires switching to a .Call interface from the more
straightforward .C interface.

The finalizer call I used doesn't assure cleanup on exit. The optional
argument to R_RegisterCFinalizerEx might provide such assurance, but I
couldn't tell what it really does.  Since all memory should
be released by the OS, when the process ends, I wasn't so worried
about that.


Here's the pattern:
// I needed R_NO_REMAP to avoid name collisions.  You may not.
#define R_NO_REMAP 1
#include <R.h>
#include <Rinternals.h>

extern "C" {
// returns an |ExternalPtr|
SEXP makeManager(
	@<makeManager args@>);


// user should not need to call
// cleanup
void finalizeManager(SEXP ptr);

}

SEXP makeManager(
	@<makeManager args@>){
    // .... stuff

    Manager* pmanager = new Manager(pd, pm.release(), 
    	*INTEGER(stepNumerator), *INTEGER(stepDenominator),
    	(*INTEGER(isexact)) != 0);
    
    // one example didn't use |PROTECT()|
    SEXP ptr;
    Rf_protect(ptr = R_MakeExternalPtr(pmanager, R_NilValue, R_NilValue));
    R_RegisterCFinalizer(ptr, (R_CFinalizer_t) finalizeManager);
    Rf_unprotect(1);
    return ptr;

}

void finalizeManager(SEXP ptr){
  Manager *pmanager = static_cast<Manager *>(R_ExternalPtrAddr(ptr));
  delete pmanager;
  R_ClearExternalPtr(ptr);
}

I'd love to hear from those more knowledgeable about whether I did
that right, and whether the FinalizerEx call can assure cleanup on
exit.

Make manager needes to be called from R like this
      mgr <- .Call("makeManager", args)

> 
> I am concerned about the following. In square brackets you see R's  
> total virtual memory use (VIRT in `top`):
> 
> 1) Load library and data [178MB] (if I run gc(), then [122MB])
> 2) Just before .C [223MB]
> 3) Just before freeing memory [325MB]
So you explicitly call your freeMemory() function?
> 4) Just after freeing memory [288MB]
There are at least 3 possibilities:
  * your C++ code is leaking
  * C++ memory is never really returned (Commonly, at least in C, the
  amount of memory allocated to the process never goes down, even if
  you do a free.  This may depend on the OS and the specific calls the
  program makes.
  * You did other stuff in R  that's still around.  After all you went
  up +45MB between 1 and 2; maybe it's not so odd you went up +65MB
  between 2 and 4.
> 5) After running gc() [230MB]
> 
> So although the freeMemory function works (frees 37MB), R ends up  
> using 100MB more after the function call than before it. ls() only  
> returns the data object so no new objects have been added to the  
> workspace.
> 
> Do any of you have any idea what could be eating this memory?
> 
> Many thanks,
> 
> Ernest
> 
> PS: it is not practical to use R_alloc et al because C++ allocation/ 
> deallocation involves constructors/destructors and because the C++  
> code is also compiled into a standalone binary (I would rather avoid  
> maintaining two separate versions).

I use regular C++ new's too (except for the external pointer that's
returned).  However, you can override the operator new in C++ so that
it uses your own allocator, e.g., R_alloc.  I'm not sure about all the
implications that might make that dangerous (e.g., can the memory be
garbage collected?  can it be moved?).  Overriding new is a bit tricky
since there are several variants.  In particular, there is one with
and one without an exception.  Also, invdividual classes can define
their own new operators; if you have any, you'd need to change those
too.

Ross Boylan


From ernest.turro at ic.ac.uk  Mon Feb 26 00:18:56 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Sun, 25 Feb 2007 23:18:56 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <20070225222144.GA16188@wheat.betterworld.us>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
Message-ID: <F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>


On 25 Feb 2007, at 22:21, Ross Boylan wrote:

> On Sun, Feb 25, 2007 at 05:37:24PM +0000, Ernest Turro wrote:
>> Dear all,
>>
>> I have wrapped a C++ function in an R package. I allocate/deallocate
>> memory using C++ 'new' and 'delete'. In order to allow user
>> interrupts without memory leaks I've moved all the delete statements
>> required after an interrupt to a separate C++ function freeMemory(),
>> which is called using on.exit() just before the .C() call.
>
> Do you mean that you call on.exit() before the .C, and the call to
> on.exit() sets up the handler?  Your last sentence sounds as if you
> invoke freeMemory() before the .C call.
>

" 'on.exit' records the expression given as its argument as needing
      to be executed when the current function exits (either naturally
      or as the result of an error)."


This means you call on.exit() somewhere at the top of the function.  
You are guaranteed the expression you pass to on.exit() will be  
executed before the function returns. So, even though you call on.exit 
() before .C(), the expression you pass it will actually be called  
after .C().

This means you can be sure that freeMemory() is called even if an  
interrupt or other error occurs.


> Another approach is to associate your C objects with an R object, and
> have them cleaned up when the R object gets garbage collected.
> However, this requires switching to a .Call interface from the more
> straightforward .C interface.
>
> The finalizer call I used doesn't assure cleanup on exit. The optional
> argument to R_RegisterCFinalizerEx might provide such assurance, but I
> couldn't tell what it really does.  Since all memory should
> be released by the OS, when the process ends, I wasn't so worried
> about that.
>
>
> Here's the pattern:
> // I needed R_NO_REMAP to avoid name collisions.  You may not.
> #define R_NO_REMAP 1
> #include <R.h>
> #include <Rinternals.h>
>
> extern "C" {
> // returns an |ExternalPtr|
> SEXP makeManager(
> 	@<makeManager args@>);
>
>
> // user should not need to call
> // cleanup
> void finalizeManager(SEXP ptr);
>
> }
>
> SEXP makeManager(
> 	@<makeManager args@>){
>     // .... stuff
>
>     Manager* pmanager = new Manager(pd, pm.release(),
>     	*INTEGER(stepNumerator), *INTEGER(stepDenominator),
>     	(*INTEGER(isexact)) != 0);
>
>     // one example didn't use |PROTECT()|
>     SEXP ptr;
>     Rf_protect(ptr = R_MakeExternalPtr(pmanager, R_NilValue,  
> R_NilValue));
>     R_RegisterCFinalizer(ptr, (R_CFinalizer_t) finalizeManager);
>     Rf_unprotect(1);
>     return ptr;
>
> }
>
> void finalizeManager(SEXP ptr){
>   Manager *pmanager = static_cast<Manager *>(R_ExternalPtrAddr(ptr));
>   delete pmanager;
>   R_ClearExternalPtr(ptr);
> }
>
> I'd love to hear from those more knowledgeable about whether I did
> that right, and whether the FinalizerEx call can assure cleanup on
> exit.
>
> Make manager needes to be called from R like this
>       mgr <- .Call("makeManager", args)
>

Since this is a standalone C++ program too, I'd rather use the R API  
as little as possible... But I will look at your solution if I find  
it is really necessary.. Thanks

>>
>> I am concerned about the following. In square brackets you see R's
>> total virtual memory use (VIRT in `top`):
>>
>> 1) Load library and data [178MB] (if I run gc(), then [122MB])
>> 2) Just before .C [223MB]
>> 3) Just before freeing memory [325MB]
> So you explicitly call your freeMemory() function?

This is called thanks to on.exit()

>> 4) Just after freeing memory [288MB]
> There are at least 3 possibilities:
>   * your C++ code is leaking

The number of news and deletes are the same, and so is their  
branching... I don't think it is this.

>   * C++ memory is never really returned (Commonly, at least in C, the
>   amount of memory allocated to the process never goes down, even if
>   you do a free.  This may depend on the OS and the specific calls the
>   program makes.

OK, but the memory should be freed after the process completes, surely?

>   * You did other stuff in R  that's still around.  After all you went
>   up +45MB between 1 and 2; maybe it's not so odd you went up +65MB
>   between 2 and 4.

Yep, I do stuff before .C and that accounts for the increase  
before .C. But all the objects created before .C go out of scope by  
4) and so, after gc(), we should be back to 122MB. As I mentioned, ls 
() after 5) returns only the data loaded in 1).

>> 5) After running gc() [230MB]
>>
>> So although the freeMemory function works (frees 37MB), R ends up
>> using 100MB more after the function call than before it. ls() only
>> returns the data object so no new objects have been added to the
>> workspace.
>>
>> Do any of you have any idea what could be eating this memory?
>>
>> Many thanks,
>>
>> Ernest
>>
>> PS: it is not practical to use R_alloc et al because C++ allocation/
>> deallocation involves constructors/destructors and because the C++
>> code is also compiled into a standalone binary (I would rather avoid
>> maintaining two separate versions).
>
> I use regular C++ new's too (except for the external pointer that's
> returned).  However, you can override the operator new in C++ so that
> it uses your own allocator, e.g., R_alloc.  I'm not sure about all the
> implications that might make that dangerous (e.g., can the memory be
> garbage collected?  can it be moved?).  Overriding new is a bit tricky
> since there are several variants.  In particular, there is one with
> and one without an exception.  Also, invdividual classes can define
> their own new operators; if you have any, you'd need to change those
> too.
>

That sounds rather dangerous!

Thanks very much for your thoughts, though.

> Ross Boylan
>


Ernest


From presnell at stat.ufl.edu  Mon Feb 26 00:52:10 2007
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Sun, 25 Feb 2007 18:52:10 -0500
Subject: [Rd] Edits of R-exts.texi
Message-ID: <87ps7xn6c5.fsf@stat.ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: R-exts-bp.diff
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070225/a20174a1/attachment.pl 

From presnell at stat.ufl.edu  Mon Feb 26 01:55:33 2007
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Sun, 25 Feb 2007 19:55:33 -0500
Subject: [Rd] Edits of R-exts.texi
In-Reply-To: <87ps7xn6c5.fsf@stat.ufl.edu> (Brett Presnell's message of "Sun\,
	25 Feb 2007 18\:52\:10 -0500")
References: <87ps7xn6c5.fsf@stat.ufl.edu>
Message-ID: <87ejodn3ei.fsf@stat.ufl.edu>


Somehow I managed to copy an older version of my edits before running
"svn diff", so please ignore my last message.  I will fix this and
resubmit.  Sorry for the bother.


From presnell at stat.ufl.edu  Mon Feb 26 04:34:20 2007
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Sun, 25 Feb 2007 22:34:20 -0500
Subject: [Rd] Edits of R-exts.texi (2nd try)
Message-ID: <87zm71lhhf.fsf@stat.ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: R-exts-bp.diff
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070225/c9f84bf5/attachment.pl 

From ross at biostat.ucsf.edu  Mon Feb 26 07:43:36 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 25 Feb 2007 22:43:36 -0800
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
Message-ID: <20070226064336.GL5871@wheat.betterworld.us>

Here are a few small follow-up comments:
On Sun, Feb 25, 2007 at 11:18:56PM +0000, Ernest Turro wrote:
> 
> On 25 Feb 2007, at 22:21, Ross Boylan wrote:
> 
> >On Sun, Feb 25, 2007 at 05:37:24PM +0000, Ernest Turro wrote:
> >>Dear all,
> >>
> >>I have wrapped a C++ function in an R package. I allocate/deallocate
> >>memory using C++ 'new' and 'delete'. In order to allow user
> >>interrupts without memory leaks I've moved all the delete statements
> >>required after an interrupt to a separate C++ function freeMemory(),
> >>which is called using on.exit() just before the .C() call.
> >
> >Do you mean that you call on.exit() before the .C, and the call to
> >on.exit() sets up the handler?  Your last sentence sounds as if you
> >invoke freeMemory() before the .C call.
> >
> 
> " 'on.exit' records the expression given as its argument as needing
>      to be executed when the current function exits (either naturally
>      or as the result of an error)."
> 
> 
> This means you call on.exit() somewhere at the top of the function.  
> You are guaranteed the expression you pass to on.exit() will be  
> executed before the function returns. So, even though you call on.exit 
> () before .C(), the expression you pass it will actually be called  
> after .C().
> 
> This means you can be sure that freeMemory() is called even if an  
> interrupt or other error occurs.
> 
> 
> >Another approach is to associate your C objects with an R object, and
> >have them cleaned up when the R object gets garbage collected.
> >However, this requires switching to a .Call interface from the more
> >straightforward .C interface.
[details snipped]
> 
> Since this is a standalone C++ program too, I'd rather use the R API  
> as little as possible... But I will look at your solution if I find  
> it is really necessary.. Thanks

The use of the R api can be confined to a wrapper function.  But I can
think of no reason that a change to the alternate approach I outlined
would solve the apparent leaking you describe.

> 
> >>
> >>I am concerned about the following. In square brackets you see R's
> >>total virtual memory use (VIRT in `top`):
> >>
> >>1) Load library and data [178MB] (if I run gc(), then [122MB])
> >>2) Just before .C [223MB]
> >>3) Just before freeing memory [325MB]
> >So you explicitly call your freeMemory() function?
> 
> This is called thanks to on.exit()
> 
> >>4) Just after freeing memory [288MB]
> >There are at least 3 possibilities:
> >  * your C++ code is leaking
> 
> The number of news and deletes are the same, and so is their  
> branching... I don't think it is this.
> 
> >  * C++ memory is never really returned (Commonly, at least in C, the
> >  amount of memory allocated to the process never goes down, even if
> >  you do a free.  This may depend on the OS and the specific calls the
> >  program makes.
> 
> OK, but the memory should be freed after the process completes,
> surely?

Most OS's I know will free memory when a process finishes, except for
shared memory.  But is that relevant?  I assume the process doesn't
complete until you exit R.  Your puzzle seems to involve different
stages within the life of a single process.

> 
> >  * You did other stuff in R  that's still around.  After all you went
> >  up +45MB between 1 and 2; maybe it's not so odd you went up +65MB
> >  between 2 and 4.
> 
> Yep, I do stuff before .C and that accounts for the increase  
> before .C. But all the objects created before .C go out of scope by  
> 4) and so, after gc(), we should be back to 122MB. As I mentioned, ls 
> () after 5) returns only the data loaded in 1).

In principle (and according to ?on.exit) the expression registered by
on.exit is evaluated when the relevant function is exited.  In
principle garbage collection reclaims all unused space (though with no
guarantee of when).

It may be that the practice is looser than the principle.  For example,
Python always nominally managed memory for you, but I think for
quite awhile it didn't really reclaim the memory (because garbage
collection didn't exist or had been turned off).


> 
> >>5) After running gc() [230MB]
> >>
> >>So although the freeMemory function works (frees 37MB), R ends up
> >>using 100MB more after the function call than before it. ls() only
> >>returns the data object so no new objects have been added to the
> >>workspace.
> >>
> >>Do any of you have any idea what could be eating this memory?
> >>
> >>Many thanks,
> >>
> >>Ernest
> >>
> >>PS: it is not practical to use R_alloc et al because C++ allocation/
> >>deallocation involves constructors/destructors and because the C++
> >>code is also compiled into a standalone binary (I would rather avoid
> >>maintaining two separate versions).
> >
> >I use regular C++ new's too (except for the external pointer that's
> >returned).  However, you can override the operator new in C++ so that
> >it uses your own allocator, e.g., R_alloc.  I'm not sure about all the
> >implications that might make that dangerous (e.g., can the memory be
> >garbage collected?  can it be moved?).  Overriding new is a bit tricky
> >since there are several variants.  In particular, there is one with
> >and one without an exception.  Also, invdividual classes can define
> >their own new operators; if you have any, you'd need to change those
> >too.
> >
> 
> That sounds rather dangerous!
At least tedious to get right.  My statements weren't intended as a
recommendation of this approach; I was just pointing out R_alloc and
C++ allocation could probably be fit together.  If your C++ program
isn't doing anything exotic with memory management there are probably
4 operators to redefine ( [singleton and array allocation] x
[exception specification present or absent]).  Oops, you'd need to get
the delete's as well...

> 
> Thanks very much for your thoughts, though.
> 
You could also try some memory leak detector on the problem to narrow
it down.

> >Ross Boylan
> >
> 
> 
> Ernest


From mel at altk.com  Mon Feb 26 10:51:15 2007
From: mel at altk.com (mel)
Date: Mon, 26 Feb 2007 10:51:15 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45DEC6D6.5090005@altk.com>
References: <45DEC6D6.5090005@altk.com>
Message-ID: <45E2AD93.3010407@altk.com>


First, great thanks to all for all the answers.
I confess i was a bit scared about (re)learning a possible
tomorrow obsolete tool.

I'm however quite astonished nobody proposes another tool.
Do 100% R package developers use emacs ?

Anyway, given the answers, it seems i'll go on emacs or xemacs.

Thanks for the guidance.
Vincent


From hin-tak.leung at cimr.cam.ac.uk  Mon Feb 26 11:51:45 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 26 Feb 2007 10:51:45 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
Message-ID: <45E2BBC1.10201@cimr.cam.ac.uk>

Read the help page of gc(). You need to run it with reset=TRUE for
the usage to drop back to original. i.e. gc(reset=TRUE). gc() on its
own doesn't quite do what you think it would do.

Ernest Turro wrote:
> Dear all,
> 
> I have wrapped a C++ function in an R package. I allocate/deallocate  
> memory using C++ 'new' and 'delete'. In order to allow user  
> interrupts without memory leaks I've moved all the delete statements  
> required after an interrupt to a separate C++ function freeMemory(),  
> which is called using on.exit() just before the .C() call.
> 
> I am concerned about the following. In square brackets you see R's  
> total virtual memory use (VIRT in `top`):
> 
> 1) Load library and data [178MB] (if I run gc(), then [122MB])
> 2) Just before .C [223MB]
> 3) Just before freeing memory [325MB]
> 4) Just after freeing memory [288MB]
> 5) After running gc() [230MB]
> 
> So although the freeMemory function works (frees 37MB), R ends up  
> using 100MB more after the function call than before it. ls() only  
> returns the data object so no new objects have been added to the  
> workspace.
> 
> Do any of you have any idea what could be eating this memory?
> 
> Many thanks,
> 
> Ernest
> 
> PS: it is not practical to use R_alloc et al because C++ allocation/ 
> deallocation involves constructors/destructors and because the C++  
> code is also compiled into a standalone binary (I would rather avoid  
> maintaining two separate versions).
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kate at few.vu.nl  Mon Feb 26 12:43:32 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Mon, 26 Feb 2007 12:43:32 +0100 (CET)
Subject: [Rd] typo in nls.Rd
Message-ID: <Pine.GSO.4.56.0702261153330.24809@laurel.few.vu.nl>


in R version 2.5.0 Under development (unstable) (2007-02-25 r40804),
the `formula' entry in the `arguments' section of nls.Rd (L25-26) reads

\item{formula}{a nonlinear model \link{formula} including variables and
    parameters.  Will be coerced to a formula is necessary.}

`is' should be `if'.

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit Amsterdam
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/


From ernest.turro at ic.ac.uk  Mon Feb 26 14:20:42 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 26 Feb 2007 13:20:42 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <45E2BBC1.10201@cimr.cam.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<45E2BBC1.10201@cimr.cam.ac.uk>
Message-ID: <9098DF16-AB71-4558-BB1A-EAC486B4B16E@ic.ac.uk>


On 26 Feb 2007, at 10:51, Hin-Tak Leung wrote:
> Ernest Turro wrote:
>> Dear all,
>> I have wrapped a C++ function in an R package. I allocate/ 
>> deallocate  memory using C++ 'new' and 'delete'. In order to allow  
>> user  interrupts without memory leaks I've moved all the delete  
>> statements  required after an interrupt to a separate C++ function  
>> freeMemory(),  which is called using on.exit() just before the .C 
>> () call.
>> I am concerned about the following. In square brackets you see  
>> R's  total virtual memory use (VIRT in `top`):
>> 1) Load library and data [178MB] (if I run gc(), then [122MB])
>> 2) Just before .C [223MB]
>> 3) Just before freeing memory [325MB]
>> 4) Just after freeing memory [288MB]
>> 5) After running gc() [230MB]
>> So although the freeMemory function works (frees 37MB), R ends up   
>> using 100MB more after the function call than before it. ls()  
>> only  returns the data object so no new objects have been added to  
>> the  workspace.
>> Do any of you have any idea what could be eating this memory?
>> Many thanks,
>> Ernest
>> PS: it is not practical to use R_alloc et al because C++  
>> allocation/ deallocation involves constructors/destructors and  
>> because the C++  code is also compiled into a standalone binary (I  
>> would rather avoid  maintaining two separate versions).
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

> Read the help page of gc(). You need to run it with reset=TRUE for
> the usage to drop back to original. i.e. gc(reset=TRUE). gc() on its
> own doesn't quite do what you think it would do.
>

Thanks, but in this case it barely makes a difference.. :(


From elw at stderr.org  Mon Feb 26 16:51:29 2007
From: elw at stderr.org (elw at stderr.org)
Date: Mon, 26 Feb 2007 09:51:29 -0600 (CST)
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <45E2AD93.3010407@altk.com>
References: <45DEC6D6.5090005@altk.com> <45E2AD93.3010407@altk.com>
Message-ID: <Pine.LNX.4.64.0702260947530.28370@illuminati.stderr.org>


> First, great thanks to all for all the answers. I confess i was a bit 
> scared about (re)learning a possible tomorrow obsolete tool.
>
> I'm however quite astonished nobody proposes another tool. Do 100% R 
> package developers use emacs ?


Plenty of folks don't use an IDE at all.  Copy/pasting working bits of 
code from your .Rhistory into a working file is a very useful tactic...

--e


From rdiaz at cnio.es  Mon Feb 26 16:19:54 2007
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Mon, 26 Feb 2007 16:19:54 +0100
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <Pine.LNX.4.64.0702260947530.28370@illuminati.stderr.org>
References: <45DEC6D6.5090005@altk.com> <45E2AD93.3010407@altk.com>
	<Pine.LNX.4.64.0702260947530.28370@illuminati.stderr.org>
Message-ID: <200702261619.54712.rdiaz@cnio.es>

On Monday 26 February 2007 16:51, elw at stderr.org wrote:
> > First, great thanks to all for all the answers. I confess i was a bit
> > scared about (re)learning a possible tomorrow obsolete tool.
> >
> > I'm however quite astonished nobody proposes another tool. Do 100% R
> > package developers use emacs ?
>
> Plenty of folks don't use an IDE at all.  Copy/pasting working bits of
> code from your .Rhistory into a working file is a very useful tactic...

You kidding, right? (I mean, maybe lots of people do that, but maybe that 
ain't such a good idea :-).

R.

P.S. Whether or not emacs + ess + ecb + a whole bunch of other things is or 
not a "real IDE" (whatever that means) I think is tangential to the original 
question. The issue, if I understand, are editing tools that will make the 
editing et al. simpler. So 

> > I'm however quite astonished nobody proposes another tool. Do 100% R
> > package developers use emacs ?
>

No. Not 100%. But you said you'll be using Windows but want to move to 
GNU/Linux. Then, you might want to use the very same tool over a range of 
OSs, or regardless of whether you are in front of your workstation, or 
accessing it over a slow modem connection, etc. In such cases, Emacs is an 
excellent choice. Or one of the very, very few. In addition, I think you are 
seeing an example of  "once you try emacs, you often realize that other 
choices do not really offer you all that much, but you loose a lot". 

HTH,

R.


>
> --e
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Ram?n D?az-Uriarte
Statistical Computing Team
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr?nico, y en s...{{dropped}}


From Gregor.Gorjanc at bfro.uni-lj.si  Mon Feb 26 16:34:31 2007
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Mon, 26 Feb 2007 16:34:31 +0100
Subject: [Rd] Is there any package on CRAN that uses Fortran-90/95
Message-ID: <7FFEE688B57D7346BC6241C55900E730F31D73@pollux.bfro.uni-lj.si>

Hi!

Is there any package on CRAN that uses Fortran-90/95? I would like
to study it.

Thanks, Gregor


From elw at stderr.org  Mon Feb 26 18:02:15 2007
From: elw at stderr.org (elw at stderr.org)
Date: Mon, 26 Feb 2007 11:02:15 -0600 (CST)
Subject: [Rd] IDE for R C++ package writing ?
In-Reply-To: <200702261619.54712.rdiaz@cnio.es>
References: <45DEC6D6.5090005@altk.com> <45E2AD93.3010407@altk.com>
	<Pine.LNX.4.64.0702260947530.28370@illuminati.stderr.org>
	<200702261619.54712.rdiaz@cnio.es>
Message-ID: <Pine.LNX.4.64.0702261059230.30064@illuminati.stderr.org>





Ya, copy/paste from .Rhistory is pretty common.  Especially among newbies 
and oldsters who dislike IDEs.  :)  [I got burned by Borland, way back 
when, and basically can't stand "wizards" and the like now...]

Looks like someone wrote a "send-to-R" plugin for vim last year:

http://www.vim.org/scripts/script.php?script_id=1048

--e



On Mon, 26 Feb 2007, Ramon Diaz-Uriarte wrote:

> Date: Mon, 26 Feb 2007 16:19:54 +0100
> From: Ramon Diaz-Uriarte <rdiaz at cnio.es>
> To: r-devel at r-project.org
> Cc: elw at stderr.org, mel <mel at altk.com>
> Subject: Re: [Rd] IDE for R C++ package writing ?
> 
> On Monday 26 February 2007 16:51, elw at stderr.org wrote:
>>> First, great thanks to all for all the answers. I confess i was a bit
>>> scared about (re)learning a possible tomorrow obsolete tool.
>>>
>>> I'm however quite astonished nobody proposes another tool. Do 100% R
>>> package developers use emacs ?
>>
>> Plenty of folks don't use an IDE at all.  Copy/pasting working bits of
>> code from your .Rhistory into a working file is a very useful tactic...
>
> You kidding, right? (I mean, maybe lots of people do that, but maybe that
> ain't such a good idea :-).
>
> R.
>
> P.S. Whether or not emacs + ess + ecb + a whole bunch of other things is or
> not a "real IDE" (whatever that means) I think is tangential to the original
> question. The issue, if I understand, are editing tools that will make the
> editing et al. simpler. So
>
>>> I'm however quite astonished nobody proposes another tool. Do 100% R
>>> package developers use emacs ?
>>
>
> No. Not 100%. But you said you'll be using Windows but want to move to
> GNU/Linux. Then, you might want to use the very same tool over a range of
> OSs, or regardless of whether you are in front of your workstation, or
> accessing it over a slow modem connection, etc. In such cases, Emacs is an
> excellent choice. Or one of the very, very few. In addition, I think you are
> seeing an example of  "once you try emacs, you often realize that other
> choices do not really offer you all that much, but you loose a lot".
>
> HTH,
>
> R.
>
>
>>
>> --e
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ernest.turro at ic.ac.uk  Mon Feb 26 17:08:55 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 26 Feb 2007 16:08:55 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <20070226064336.GL5871@wheat.betterworld.us>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
Message-ID: <A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>

Thanks for your comments Ross. A couple more comments/queries below:

On 26 Feb 2007, at 06:43, Ross Boylan wrote:

> [details snipped]
>
> The use of the R api can be confined to a wrapper function.  But I can
> think of no reason that a change to the alternate approach I outlined
> would solve the apparent leaking you describe.
>

I'm not sure I see how a wrapper function using the R API would  
suffice. Example:

During heavy computation in the C++ function I need to allow  
interrupts from R. This means that R_CheckUserInterrupt needs to be  
called during the computation. Therefore, use of the R API can't be  
confined to just the wrapper function.

In fact, I'm worried that some of the libraries I'm using are failing  
to release memory after interrupt and that that is the problem. I  
can't see what I could do about that... E.g.

#include <valarray>

valarray<double> foo; // I don't know 100% that the foo object hasn't  
allocated some memory. if the program is interrupted it wouldn't be  
released....

I find it's very unfortunate that R_CheckUserInterrupt doesn't return  
a value. If it did (e.g. if it returned true if an interrupt has  
occurred), I could just branch off somewhere, clean up properly and  
return to R.

Any ideas on how this could be achieved?

Thanks,

E


>>
>>>>
>>>> I am concerned about the following. In square brackets you see R's
>>>> total virtual memory use (VIRT in `top`):
>>>>
>>>> 1) Load library and data [178MB] (if I run gc(), then [122MB])
>>>> 2) Just before .C [223MB]
>>>> 3) Just before freeing memory [325MB]
>>> So you explicitly call your freeMemory() function?
>>
>> This is called thanks to on.exit()
>>
>>>> 4) Just after freeing memory [288MB]
>>> There are at least 3 possibilities:
>>>  * your C++ code is leaking
>>
>> The number of news and deletes are the same, and so is their
>> branching... I don't think it is this.
>>
>>>  * C++ memory is never really returned (Commonly, at least in C, the
>>>  amount of memory allocated to the process never goes down, even if
>>>  you do a free.  This may depend on the OS and the specific calls  
>>> the
>>>  program makes.
>>
>> OK, but the memory should be freed after the process completes,
>> surely?
>
> Most OS's I know will free memory when a process finishes, except for
> shared memory.  But is that relevant?  I assume the process doesn't
> complete until you exit R.  Your puzzle seems to involve different
> stages within the life of a single process.
>
>>
>>>  * You did other stuff in R  that's still around.  After all you  
>>> went
>>>  up +45MB between 1 and 2; maybe it's not so odd you went up +65MB
>>>  between 2 and 4.
>>
>> Yep, I do stuff before .C and that accounts for the increase
>> before .C. But all the objects created before .C go out of scope by
>> 4) and so, after gc(), we should be back to 122MB. As I mentioned, ls
>> () after 5) returns only the data loaded in 1).
>
> In principle (and according to ?on.exit) the expression registered by
> on.exit is evaluated when the relevant function is exited.  In
> principle garbage collection reclaims all unused space (though with no
> guarantee of when).
>
> It may be that the practice is looser than the principle.  For  
> example,
> Python always nominally managed memory for you, but I think for
> quite awhile it didn't really reclaim the memory (because garbage
> collection didn't exist or had been turned off).
>
>
>>
>>>> 5) After running gc() [230MB]
>>>>
>>>> So although the freeMemory function works (frees 37MB), R ends up
>>>> using 100MB more after the function call than before it. ls() only
>>>> returns the data object so no new objects have been added to the
>>>> workspace.
>>>>
>>>> Do any of you have any idea what could be eating this memory?
>>>>
>>>> Many thanks,
>>>>
>>>> Ernest
>>>>
>>>> PS: it is not practical to use R_alloc et al because C++  
>>>> allocation/
>>>> deallocation involves constructors/destructors and because the C++
>>>> code is also compiled into a standalone binary (I would rather  
>>>> avoid
>>>> maintaining two separate versions).
>>>
>>> I use regular C++ new's too (except for the external pointer that's
>>> returned).  However, you can override the operator new in C++ so  
>>> that
>>> it uses your own allocator, e.g., R_alloc.  I'm not sure about  
>>> all the
>>> implications that might make that dangerous (e.g., can the memory be
>>> garbage collected?  can it be moved?).  Overriding new is a bit  
>>> tricky
>>> since there are several variants.  In particular, there is one with
>>> and one without an exception.  Also, invdividual classes can define
>>> their own new operators; if you have any, you'd need to change those
>>> too.
>>>
>>
>> That sounds rather dangerous!
> At least tedious to get right.  My statements weren't intended as a
> recommendation of this approach; I was just pointing out R_alloc and
> C++ allocation could probably be fit together.  If your C++ program
> isn't doing anything exotic with memory management there are probably
> 4 operators to redefine ( [singleton and array allocation] x
> [exception specification present or absent]).  Oops, you'd need to get
> the delete's as well...
>
>>
>> Thanks very much for your thoughts, though.
>>
> You could also try some memory leak detector on the problem to narrow
> it down.
>
>>> Ross Boylan
>>>
>>
>>
>> Ernest


From h.wickham at gmail.com  Mon Feb 26 17:29:51 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 26 Feb 2007 10:29:51 -0600
Subject: [Rd] Depending on many packages: another best practice question
In-Reply-To: <971536df0702250738o168336e5q67fd997eb86958ae@mail.gmail.com>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<f8e6ff050702241121q1890ab16sff1d19bbb432eff6@mail.gmail.com>
	<Pine.LNX.4.64.0702242013310.15657@gannet.stats.ox.ac.uk>
	<f8e6ff050702250657i1ff01035je267f64a5d584b85@mail.gmail.com>
	<971536df0702250738o168336e5q67fd997eb86958ae@mail.gmail.com>
Message-ID: <f8e6ff050702260829y5b120e41o9a271f26db255c6a@mail.gmail.com>

> You can use
>
> if(require(myPackage)) { ... }

Yes, but the problem with this is that I now have the fact that this
function requires that package stated in two places - in the body of
the function, and in the examples - adding redundancy which makes
maintenance harder.

I guess what I really want, is some way to throw an error that R CMD
check won't complain about - ie. a special dependency not met error.

Hadley


From simon.urbanek at r-project.org  Mon Feb 26 17:58:15 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 26 Feb 2007 11:58:15 -0500
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
Message-ID: <B5F49FDC-5EE5-4CC1-8F53-43CBBE915A7F@r-project.org>

Ernest,

On Feb 25, 2007, at 12:37 PM, Ernest Turro wrote:

> I have wrapped a C++ function in an R package. I allocate/ 
> deallocate memory using C++ 'new' and 'delete'. In order to allow  
> user interrupts without memory leaks

How do you allow for user interrupts? R doesn't allow interrupts  
while in .C/.Call on purpose, so it's up to your code to handle  
interrupts properly. This also implies that you can use the regular  
methods for error recovery available in your language and handle the  
interrupt yourself by freeing the memory as needed, your code  
shouldn't return to R until it has cleaned everything up ...


> I've moved all the delete statements required after an interrupt to  
> a separate C++ function freeMemory(), which is called using on.exit 
> () just before the .C() call.
>

This sounds a bit dangerous - how can the separate function know  
about the previous call and the state it was in before the interrupt  
(save for hard-wiring everything into one instance)? Again, the  
crucial part is the interrupt handling in your code - it may fail to  
release some objects...

@Ross [see follow-up]: R_RegisterCFinalizerEx is called on R exit if  
desired (see arguments). However, I don't think this is relevant to  
the discussed issue as a process termination frees all its memory.  
Moreover I don't think Ernest wants to wrap all his classes to R  
objects - we're not talking about the GC here, it is supposed to be C+ 
+ internal issue.

Cheers,
Simon


> I am concerned about the following. In square brackets you see R's
> total virtual memory use (VIRT in `top`):
>
> 1) Load library and data [178MB] (if I run gc(), then [122MB])
> 2) Just before .C [223MB]
> 3) Just before freeing memory [325MB]
> 4) Just after freeing memory [288MB]
> 5) After running gc() [230MB]
>
> So although the freeMemory function works (frees 37MB), R ends up
> using 100MB more after the function call than before it. ls() only
> returns the data object so no new objects have been added to the
> workspace.
>
> Do any of you have any idea what could be eating this memory?
>
> Many thanks,
>
> Ernest
>
> PS: it is not practical to use R_alloc et al because C++ allocation/
> deallocation involves constructors/destructors and because the C++
> code is also compiled into a standalone binary (I would rather avoid
> maintaining two separate versions).
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ernest.turro at ic.ac.uk  Mon Feb 26 18:32:17 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 26 Feb 2007 17:32:17 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <B5F49FDC-5EE5-4CC1-8F53-43CBBE915A7F@r-project.org>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<B5F49FDC-5EE5-4CC1-8F53-43CBBE915A7F@r-project.org>
Message-ID: <065FE26B-74E7-4867-A214-4C555DE35762@ic.ac.uk>

Hi Simon,

On 26 Feb 2007, at 16:58, Simon Urbanek wrote:

> Ernest,
>
> On Feb 25, 2007, at 12:37 PM, Ernest Turro wrote:
>
>> I have wrapped a C++ function in an R package. I allocate/ 
>> deallocate memory using C++ 'new' and 'delete'. In order to allow  
>> user interrupts without memory leaks
>
> How do you allow for user interrupts? R doesn't allow interrupts  
> while in .C/.Call on purpose,

void R_CheckUserInterrupt(void)


> so it's up to your code to handle interrupts properly. This also  
> implies that you can use the regular methods for error recovery  
> available in your language and handle the interrupt yourself by  
> freeing the memory as needed, your code shouldn't return to R until  
> it has cleaned everything up ...

How can I detect an interrupt from R inside the C/C++ code without  
using the R API? SIGINTs don't get passed on if they come from within  
R...

>
>
>> I've moved all the delete statements required after an interrupt  
>> to a separate C++ function freeMemory(), which is called using  
>> on.exit() just before the .C() call.
>>
>
> This sounds a bit dangerous - how can the separate function know  
> about the previous call and the state it was in before the  
> interrupt (save for hard-wiring everything into one instance)?  
> Again, the crucial part is the interrupt handling in your code - it  
> may fail to release some objects...
>

I have to declare variables for any allocated memory globally:

static int foo*;

extern "C"
void func(...) {
	foo = new int[1024];

	// heavy computation
	// inside loop:
	R_CheckUserInterrupt()
	//end heavy computation
}

extern "C"
void freemem(...) {
	delete [] foo;
}

in R:

func <- function() {
on.exit(.C("freemem"))
.C("func")
}



Cheers,

Ernest

> @Ross [see follow-up]: R_RegisterCFinalizerEx is called on R exit  
> if desired (see arguments). However, I don't think this is relevant  
> to the discussed issue as a process termination frees all its  
> memory. Moreover I don't think Ernest wants to wrap all his classes  
> to R objects - we're not talking about the GC here, it is supposed  
> to be C++ internal issue.
>
> Cheers,
> Simon
>
>
>> I am concerned about the following. In square brackets you see R's
>> total virtual memory use (VIRT in `top`):
>>
>> 1) Load library and data [178MB] (if I run gc(), then [122MB])
>> 2) Just before .C [223MB]
>> 3) Just before freeing memory [325MB]
>> 4) Just after freeing memory [288MB]
>> 5) After running gc() [230MB]
>>
>> So although the freeMemory function works (frees 37MB), R ends up
>> using 100MB more after the function call than before it. ls() only
>> returns the data object so no new objects have been added to the
>> workspace.
>>
>> Do any of you have any idea what could be eating this memory?
>>
>> Many thanks,
>>
>> Ernest
>>
>> PS: it is not practical to use R_alloc et al because C++ allocation/
>> deallocation involves constructors/destructors and because the C++
>> code is also compiled into a standalone binary (I would rather avoid
>> maintaining two separate versions).
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From tlumley at u.washington.edu  Mon Feb 26 22:42:25 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 26 Feb 2007 13:42:25 -0800 (PST)
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <45E2BBC1.10201@cimr.cam.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<45E2BBC1.10201@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0702261340440.3337@homer22.u.washington.edu>

On Mon, 26 Feb 2007, Hin-Tak Leung wrote:

> Read the help page of gc(). You need to run it with reset=TRUE for
> the usage to drop back to original. i.e. gc(reset=TRUE). gc() on its
> own doesn't quite do what you think it would do.

This is almost completely incorrect (apart from the advice to read the 
help page).  The setting for reset= has absolutely no effect on R's memory 
use. It just clears the internal variable that has kept track of the 
highest memory use so far.

 	-thomas


> Ernest Turro wrote:
>> Dear all,
>>
>> I have wrapped a C++ function in an R package. I allocate/deallocate
>> memory using C++ 'new' and 'delete'. In order to allow user
>> interrupts without memory leaks I've moved all the delete statements
>> required after an interrupt to a separate C++ function freeMemory(),
>> which is called using on.exit() just before the .C() call.
>>
>> I am concerned about the following. In square brackets you see R's
>> total virtual memory use (VIRT in `top`):
>>
>> 1) Load library and data [178MB] (if I run gc(), then [122MB])
>> 2) Just before .C [223MB]
>> 3) Just before freeing memory [325MB]
>> 4) Just after freeing memory [288MB]
>> 5) After running gc() [230MB]
>>
>> So although the freeMemory function works (frees 37MB), R ends up
>> using 100MB more after the function call than before it. ls() only
>> returns the data object so no new objects have been added to the
>> workspace.
>>
>> Do any of you have any idea what could be eating this memory?
>>
>> Many thanks,
>>
>> Ernest
>>
>> PS: it is not practical to use R_alloc et al because C++ allocation/
>> deallocation involves constructors/destructors and because the C++
>> code is also compiled into a standalone binary (I would rather avoid
>> maintaining two separate versions).
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ross at biostat.ucsf.edu  Mon Feb 26 23:34:30 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 26 Feb 2007 14:34:30 -0800
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
Message-ID: <1172529270.9347.164.camel@iron.psg.net>

On Mon, 2007-02-26 at 16:08 +0000, Ernest Turro wrote:
> Thanks for your comments Ross. A couple more comments/queries below:
> 
> On 26 Feb 2007, at 06:43, Ross Boylan wrote:
> 
> > [details snipped]
> >
> > The use of the R api can be confined to a wrapper function.  But I can
> > think of no reason that a change to the alternate approach I outlined
> > would solve the apparent leaking you describe.
> >
> 
> I'm not sure I see how a wrapper function using the R API would  
> suffice. Example:
It doesn't sound as if it would suffice.  I was responding to your
original remark that

> Since this is a standalone C++ program too, I'd rather use the R API  
> as little as possible... But I will look at your solution if I find  
> it is really necessary.. Thanks

I thought that was expressing a concern about using the alternate
approach I outlined because it would use the R API.  If you need to use
that API for other reasons, you're still stuck with it :)
> 
> During heavy computation in the C++ function I need to allow  
> interrupts from R. This means that R_CheckUserInterrupt needs to be  
> called during the computation. Therefore, use of the R API can't be  
> confined to just the wrapper function.
> 
> In fact, I'm worried that some of the libraries I'm using are failing  
> to release memory after interrupt and that that is the problem. I  
> can't see what I could do about that... E.g.
> 
> #include <valarray>
> 
> valarray<double> foo; // I don't know 100% that the foo object hasn't  
> allocated some memory. if the program is interrupted it wouldn't be  
> released....
That's certainly possible, but you seem to be overlooking the
possibility that all the code is releasing memory appropriately, but the
process's memory footprint isn't going down correspondingly.  In my
experience that's fairly typical behavior.

In that case, depending on your point of view, you either don't have a
problem or you have a hard problem.  If you really want the memory
released back to the system, it's a hard problem.  If you don't care, as
long as you have no leaks, all's well.

> 
> I find it's very unfortunate that R_CheckUserInterrupt doesn't return  
> a value. If it did (e.g. if it returned true if an interrupt has  
> occurred), I could just branch off somewhere, clean up properly and  
> return to R.
> 
> Any ideas on how this could be achieved?
I can't tell from the info page what function gets called in R if there
is an interrupt, but it sounds as you could do the following hack:
The R interrupt handler gets a function that calls a C function of your
devising.  The C function sets a flag meaning "interrupt requested".
Then in your main code, you periodically call R_CheckUserInterrupt.
When it returns you check the flag; if it's set, you cleanup and exit.
Ross


From pavel at stat.washington.edu  Tue Feb 27 03:39:19 2007
From: pavel at stat.washington.edu (Pavel N. Krivitsky)
Date: Mon, 26 Feb 2007 18:39:19 -0800
Subject: [Rd] Checking for user interrupt in a .C() call without without
 triggering a non-local exit.
Message-ID: <45E399D7.4080501@stat.washington.edu>

Hi,

An R package on which I am working makes a series of very
computationally-intensive and complex .C() calls, that I would like to
make interruptible. However, calling R_CheckUserInterrupt() causes a
non-local exit, so the memory allocated by malloc() is never freed. The
way the code is structured, it might not be practical to replace all the
malloc() calls with R_alloc() calls.

The question is, can I somehow detect a user interrupt and handle it
gracefully in my own code? A similar question was posed a few months ago
( http://tolstoy.newcastle.edu.au/R/devel/06/08/6415.html ), but didn't
get any response. Has anything changed since?

              Thanks,
              Pavel Krivitsky


From ernest.turro at ic.ac.uk  Tue Feb 27 17:51:57 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 27 Feb 2007 16:51:57 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <1172529270.9347.164.camel@iron.psg.net>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
	<1172529270.9347.164.camel@iron.psg.net>
Message-ID: <B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>

Hi Ross,

On 26 Feb 2007, at 22:34, Ross Boylan wrote:

> On Mon, 2007-02-26 at 16:08 +0000, Ernest Turro wrote:
>> Thanks for your comments Ross. A couple more comments/queries below:
>>
>> On 26 Feb 2007, at 06:43, Ross Boylan wrote:
>>
>>> [details snipped]
>>>
>>> The use of the R api can be confined to a wrapper function.  But  
>>> I can
>>> think of no reason that a change to the alternate approach I  
>>> outlined
>>> would solve the apparent leaking you describe.
>>>
>>
>> I'm not sure I see how a wrapper function using the R API would
>> suffice. Example:
> It doesn't sound as if it would suffice.  I was responding to your
> original remark that
>
>> Since this is a standalone C++ program too, I'd rather use the R API
>> as little as possible... But I will look at your solution if I find
>> it is really necessary.. Thanks
>
> I thought that was expressing a concern about using the alternate
> approach I outlined because it would use the R API.  If you need to  
> use
> that API for other reasons, you're still stuck with it :)
>>
>> During heavy computation in the C++ function I need to allow
>> interrupts from R. This means that R_CheckUserInterrupt needs to be
>> called during the computation. Therefore, use of the R API can't be
>> confined to just the wrapper function.
>>
>> In fact, I'm worried that some of the libraries I'm using are failing
>> to release memory after interrupt and that that is the problem. I
>> can't see what I could do about that... E.g.
>>
>> #include <valarray>
>>
>> valarray<double> foo; // I don't know 100% that the foo object hasn't
>> allocated some memory. if the program is interrupted it wouldn't be
>> released....
> That's certainly possible, but you seem to be overlooking the
> possibility that all the code is releasing memory appropriately,  
> but the
> process's memory footprint isn't going down correspondingly.  In my
> experience that's fairly typical behavior.
>

OK, but does this still explain why the footprint keeps increasing  
indefinitely when i do run, interrupt, run, interrupt, run,  
interrupt......?


> In that case, depending on your point of view, you either don't have a
> problem or you have a hard problem.  If you really want the memory
> released back to the system, it's a hard problem.  If you don't  
> care, as
> long as you have no leaks, all's well.
>
>>
>> I find it's very unfortunate that R_CheckUserInterrupt doesn't return
>> a value. If it did (e.g. if it returned true if an interrupt has
>> occurred), I could just branch off somewhere, clean up properly and
>> return to R.
>>
>> Any ideas on how this could be achieved?
> I can't tell from the info page what function gets called in R if  
> there
> is an interrupt, but it sounds as you could do the following hack:
> The R interrupt handler gets a function that calls a C function of  
> your
> devising.  The C function sets a flag meaning "interrupt requested".
> Then in your main code, you periodically call R_CheckUserInterrupt.
> When it returns you check the flag; if it's set, you cleanup and exit.
> Ross
>

If this is feasible, it's by far the best solution.

in error.c:

void R_CheckUserInterrupt(void)
{
     R_CheckStack();
     /* This is the point where GUI systems need to do enough event
        processing to determine whether there is a user interrupt event
        pending.  Need to be careful not to do too much event
        processing though: if event handlers written in R are allowed
        to run at this point then we end up with concurrent R
        evaluations and that can cause problems until we have proper
        concurrency support. LT */
#if  ( defined(HAVE_AQUA) || defined(Win32) )
     R_ProcessEvents();
#else
     if (R_interrupts_pending)
   onintr();
#endif /* Win32 */
}

Leaving aside the HAVE_AQUA and Win32 cases, I would like to write a  
new function:

int R_CheckInterruptsPending(void)
{
     R_CheckStack();
     return R_interrupts_pending;
}

and then in my C++ code:

if(R_checkInterruptsPending) {
	// clean up
	// ...
	R_CheckInterruptsPending();
}

R_CheckStack() is declared in R_ext/Utils.h but the variable  
R_interrupts_pending isn't, so how could I access it? In other words,  
how can I extend error.c .....


Thanks,

E


From ernest.turro at ic.ac.uk  Tue Feb 27 17:55:38 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 27 Feb 2007 16:55:38 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
	<1172529270.9347.164.camel@iron.psg.net>
	<B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
Message-ID: <C5C34622-06F9-410B-B774-8141FBD57ED0@ic.ac.uk>

[snip]

Sorry. Small mistake fixed below:

>
> Leaving aside the HAVE_AQUA and Win32 cases, I would like to write  
> a new function:
>
> int R_CheckInterruptsPending(void)
> {
>     R_CheckStack();
>     return R_interrupts_pending;
> }
>
> and then in my C++ code:
>

if(R_CheckInterruptsPending) {
	// clean up
	// ...
	R_CheckUserInterrupt();
}
>
> R_CheckStack() is declared in R_ext/Utils.h but the variable  
> R_interrupts_pending isn't, so how could I access it? In other  
> words, how can I extend error.c .....
>
>
> Thanks,
>
> E
>
>
>
>
>
>


From luke at stat.uiowa.edu  Tue Feb 27 18:37:08 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 27 Feb 2007 11:37:08 -0600 (CST)
Subject: [Rd] Checking for user interrupt in a .C() call without without
 triggering a non-local exit.
In-Reply-To: <45E399D7.4080501@stat.washington.edu>
References: <45E399D7.4080501@stat.washington.edu>
Message-ID: <Pine.LNX.4.64.0702271129210.2965@nokomis.stat.uiowa.edu>

On Mon, 26 Feb 2007, Pavel N. Krivitsky wrote:

> Hi,
>
> An R package on which I am working makes a series of very
> computationally-intensive and complex .C() calls, that I would like to
> make interruptible. However, calling R_CheckUserInterrupt() causes a
> non-local exit, so the memory allocated by malloc() is never freed. The
> way the code is structured, it might not be practical to replace all the
> malloc() calls with R_alloc() calls.
>
> The question is, can I somehow detect a user interrupt and handle it
> gracefully in my own code? A similar question was posed a few months ago
> ( http://tolstoy.newcastle.edu.au/R/devel/06/08/6415.html ), but didn't
> get any response. Has anything changed since?

Not really.  There is an internal mechanism for registering C level
on.exit routines but this is not in a form that can be made public as
it would tie down implementation decisions too much.  It is principle
possible to build something around R_ToplevelExec, but that is not at
this point part of the public API and so is subject to change.  We
might consider providing something along these lines after 2.5 is
released.  A tricky issues is that while checking for interrupts is
cheap on standard Unix setups where interrupts arrive as signals, it
isn't in GUI setups where event processing is needed to detect whether
a user interrupt action has occurred (and that checking could cause
errors and non-local exits).

Best,

luke


-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Tue Feb 27 18:45:11 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 27 Feb 2007 11:45:11 -0600 (CST)
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
	<1172529270.9347.164.camel@iron.psg.net>
	<B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
Message-ID: <Pine.LNX.4.64.0702271137200.2965@nokomis.stat.uiowa.edu>

On Tue, 27 Feb 2007, Ernest Turro wrote:

> Hi Ross,
>
> On 26 Feb 2007, at 22:34, Ross Boylan wrote:
>
>> On Mon, 2007-02-26 at 16:08 +0000, Ernest Turro wrote:
>>> Thanks for your comments Ross. A couple more comments/queries below:
>>>
>>> On 26 Feb 2007, at 06:43, Ross Boylan wrote:
>>>
>>>> [details snipped]
>>>>
>>>> The use of the R api can be confined to a wrapper function.  But
>>>> I can
>>>> think of no reason that a change to the alternate approach I
>>>> outlined
>>>> would solve the apparent leaking you describe.
>>>>
>>>
>>> I'm not sure I see how a wrapper function using the R API would
>>> suffice. Example:
>> It doesn't sound as if it would suffice.  I was responding to your
>> original remark that
>>
>>> Since this is a standalone C++ program too, I'd rather use the R API
>>> as little as possible... But I will look at your solution if I find
>>> it is really necessary.. Thanks
>>
>> I thought that was expressing a concern about using the alternate
>> approach I outlined because it would use the R API.  If you need to
>> use
>> that API for other reasons, you're still stuck with it :)
>>>
>>> During heavy computation in the C++ function I need to allow
>>> interrupts from R. This means that R_CheckUserInterrupt needs to be
>>> called during the computation. Therefore, use of the R API can't be
>>> confined to just the wrapper function.
>>>
>>> In fact, I'm worried that some of the libraries I'm using are failing
>>> to release memory after interrupt and that that is the problem. I
>>> can't see what I could do about that... E.g.
>>>
>>> #include <valarray>
>>>
>>> valarray<double> foo; // I don't know 100% that the foo object hasn't
>>> allocated some memory. if the program is interrupted it wouldn't be
>>> released....
>> That's certainly possible, but you seem to be overlooking the
>> possibility that all the code is releasing memory appropriately,
>> but the
>> process's memory footprint isn't going down correspondingly.  In my
>> experience that's fairly typical behavior.
>>
>
> OK, but does this still explain why the footprint keeps increasing
> indefinitely when i do run, interrupt, run, interrupt, run,
> interrupt......?
>
>
>> In that case, depending on your point of view, you either don't have a
>> problem or you have a hard problem.  If you really want the memory
>> released back to the system, it's a hard problem.  If you don't
>> care, as
>> long as you have no leaks, all's well.
>>
>>>
>>> I find it's very unfortunate that R_CheckUserInterrupt doesn't return
>>> a value. If it did (e.g. if it returned true if an interrupt has
>>> occurred), I could just branch off somewhere, clean up properly and
>>> return to R.
>>>
>>> Any ideas on how this could be achieved?
>> I can't tell from the info page what function gets called in R if
>> there
>> is an interrupt, but it sounds as you could do the following hack:
>> The R interrupt handler gets a function that calls a C function of
>> your
>> devising.  The C function sets a flag meaning "interrupt requested".
>> Then in your main code, you periodically call R_CheckUserInterrupt.
>> When it returns you check the flag; if it's set, you cleanup and exit.
>> Ross
>>
>
> If this is feasible, it's by far the best solution.
>
> in error.c:
>
> void R_CheckUserInterrupt(void)
> {
>     R_CheckStack();
>     /* This is the point where GUI systems need to do enough event
>        processing to determine whether there is a user interrupt event
>        pending.  Need to be careful not to do too much event
>        processing though: if event handlers written in R are allowed
>        to run at this point then we end up with concurrent R
>        evaluations and that can cause problems until we have proper
>        concurrency support. LT */
> #if  ( defined(HAVE_AQUA) || defined(Win32) )
>     R_ProcessEvents();
> #else
>     if (R_interrupts_pending)
>   onintr();
> #endif /* Win32 */
> }
>
> Leaving aside the HAVE_AQUA and Win32 cases, I would like to write a
> new function:

Unfortunately we can't leave those aside.  If standard unix where
interrupts arrive as signals is all you care about then you can just
save, replace and restore the R SIGINT handler around your code with
one that sets a flag of your own.  Things are not so simple on GUI
systems where detecting a user interrupt action requires event
processing, which might result in errors and non-local exits in
response to those.

There is an internal mechanism for registering C level on.exit
routines but this is not in a form that can be made public as it would
tie down implementation decisions too much.  It is principle possible
to build something around R_ToplevelExec, but that is not at this
point part of the public API and so is subject to change.  We might
consider providing a variant of R_CheckInterrupts that either just
checks or that executes cleanup code sometime after 2.5 is released.

Best,

luke

>
> int R_CheckInterruptsPending(void)
> {
>     R_CheckStack();
>     return R_interrupts_pending;
> }
>
> and then in my C++ code:
>
> if(R_checkInterruptsPending) {
> 	// clean up
> 	// ...
> 	R_CheckInterruptsPending();
> }
>
> R_CheckStack() is declared in R_ext/Utils.h but the variable
> R_interrupts_pending isn't, so how could I access it? In other words,
> how can I extend error.c .....
>
>
> Thanks,
>
> E
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ernest.turro at ic.ac.uk  Tue Feb 27 19:01:33 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 27 Feb 2007 18:01:33 +0000
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <Pine.LNX.4.64.0702271137200.2965@nokomis.stat.uiowa.edu>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
	<1172529270.9347.164.camel@iron.psg.net>
	<B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
	<Pine.LNX.4.64.0702271137200.2965@nokomis.stat.uiowa.edu>
Message-ID: <041F0BCD-653B-4309-85FA-82334DA2B50B@ic.ac.uk>


On 27 Feb 2007, at 17:45, Luke Tierney wrote:

> On Tue, 27 Feb 2007, Ernest Turro wrote:
>
>> Hi Ross,
>>
>> On 26 Feb 2007, at 22:34, Ross Boylan wrote:
>>
>>> On Mon, 2007-02-26 at 16:08 +0000, Ernest Turro wrote:
>>>> Thanks for your comments Ross. A couple more comments/queries  
>>>> below:
>>>>
>>>> On 26 Feb 2007, at 06:43, Ross Boylan wrote:
>>>>
>>>>> [details snipped]
>>>>>
>>>>> The use of the R api can be confined to a wrapper function.  But
>>>>> I can
>>>>> think of no reason that a change to the alternate approach I
>>>>> outlined
>>>>> would solve the apparent leaking you describe.
>>>>>
>>>>
>>>> I'm not sure I see how a wrapper function using the R API would
>>>> suffice. Example:
>>> It doesn't sound as if it would suffice.  I was responding to your
>>> original remark that
>>>
>>>> Since this is a standalone C++ program too, I'd rather use the R  
>>>> API
>>>> as little as possible... But I will look at your solution if I find
>>>> it is really necessary.. Thanks
>>>
>>> I thought that was expressing a concern about using the alternate
>>> approach I outlined because it would use the R API.  If you need to
>>> use
>>> that API for other reasons, you're still stuck with it :)
>>>>
>>>> During heavy computation in the C++ function I need to allow
>>>> interrupts from R. This means that R_CheckUserInterrupt needs to be
>>>> called during the computation. Therefore, use of the R API can't be
>>>> confined to just the wrapper function.
>>>>
>>>> In fact, I'm worried that some of the libraries I'm using are  
>>>> failing
>>>> to release memory after interrupt and that that is the problem. I
>>>> can't see what I could do about that... E.g.
>>>>
>>>> #include <valarray>
>>>>
>>>> valarray<double> foo; // I don't know 100% that the foo object  
>>>> hasn't
>>>> allocated some memory. if the program is interrupted it wouldn't be
>>>> released....
>>> That's certainly possible, but you seem to be overlooking the
>>> possibility that all the code is releasing memory appropriately,
>>> but the
>>> process's memory footprint isn't going down correspondingly.  In my
>>> experience that's fairly typical behavior.
>>>
>>
>> OK, but does this still explain why the footprint keeps increasing
>> indefinitely when i do run, interrupt, run, interrupt, run,
>> interrupt......?
>>
>>
>>> In that case, depending on your point of view, you either don't  
>>> have a
>>> problem or you have a hard problem.  If you really want the memory
>>> released back to the system, it's a hard problem.  If you don't
>>> care, as
>>> long as you have no leaks, all's well.
>>>
>>>>
>>>> I find it's very unfortunate that R_CheckUserInterrupt doesn't  
>>>> return
>>>> a value. If it did (e.g. if it returned true if an interrupt has
>>>> occurred), I could just branch off somewhere, clean up properly and
>>>> return to R.
>>>>
>>>> Any ideas on how this could be achieved?
>>> I can't tell from the info page what function gets called in R if
>>> there
>>> is an interrupt, but it sounds as you could do the following hack:
>>> The R interrupt handler gets a function that calls a C function of
>>> your
>>> devising.  The C function sets a flag meaning "interrupt requested".
>>> Then in your main code, you periodically call R_CheckUserInterrupt.
>>> When it returns you check the flag; if it's set, you cleanup and  
>>> exit.
>>> Ross
>>>
>>
>> If this is feasible, it's by far the best solution.
>>
>> in error.c:
>>
>> void R_CheckUserInterrupt(void)
>> {
>>     R_CheckStack();
>>     /* This is the point where GUI systems need to do enough event
>>        processing to determine whether there is a user interrupt  
>> event
>>        pending.  Need to be careful not to do too much event
>>        processing though: if event handlers written in R are allowed
>>        to run at this point then we end up with concurrent R
>>        evaluations and that can cause problems until we have proper
>>        concurrency support. LT */
>> #if  ( defined(HAVE_AQUA) || defined(Win32) )
>>     R_ProcessEvents();
>> #else
>>     if (R_interrupts_pending)
>>   onintr();
>> #endif /* Win32 */
>> }
>>
>> Leaving aside the HAVE_AQUA and Win32 cases, I would like to write a
>> new function:
>
> Unfortunately we can't leave those aside.  If standard unix where
> interrupts arrive as signals is all you care about then you can just
> save, replace and restore the R SIGINT handler around your code with
> one that sets a flag of your own.  Things are not so simple on GUI
> systems where detecting a user interrupt action requires event
> processing, which might result in errors and non-local exits in
> response to those.
>
> There is an internal mechanism for registering C level on.exit
> routines but this is not in a form that can be made public as it would
> tie down implementation decisions too much.  It is principle possible
> to build something around R_ToplevelExec, but that is not at this
> point part of the public API and so is subject to change.  We might
> consider providing a variant of R_CheckInterrupts that either just
> checks or that executes cleanup code sometime after 2.5 is released.
>

Yes, I think it would be great if you added a variant of  
R_CheckUserInterrupt() that actually returned something (e.g. a  
boolean) to the R API.

So in your view, is the best solution to pass a memory cleanup C  
function to on.exit() before the call? What about memory allocated in  
some of the external libraries that I use? E.g. as I mentioned above:

>>>>
>>>> #include <valarray>
>>>> // ...
>>>> valarray<double> foo; // I don't know 100% that the foo object  
>>>> hasn't
>>>> allocated some memory. if the program is interrupted it wouldn't be
>>>> released....


Thanks for your help,

Ernest


> Best,
>
> luke
>
>>
>> int R_CheckInterruptsPending(void)
>> {
>>     R_CheckStack();
>>     return R_interrupts_pending;
>> }
>>
>> and then in my C++ code:
>>
>> if(R_checkInterruptsPending) {
>> 	// clean up
>> 	// ...
>> 	R_CheckInterruptsPending();
>> }
>>
>> R_CheckStack() is declared in R_ext/Utils.h but the variable
>> R_interrupts_pending isn't, so how could I access it? In other words,
>> how can I extend error.c .....
>>
>>
>> Thanks,
>>
>> E
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -- 
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke at stat.uiowa.edu  Tue Feb 27 19:32:18 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 27 Feb 2007 12:32:18 -0600 (CST)
Subject: [Rd] R/C++/memory leaks
In-Reply-To: <041F0BCD-653B-4309-85FA-82334DA2B50B@ic.ac.uk>
References: <39CFDB8F-918C-48FB-9A6D-D8055D828C13@ic.ac.uk>
	<20070225222144.GA16188@wheat.betterworld.us>
	<F3C922F3-4B4C-4DA9-84E1-F17B52302BCB@ic.ac.uk>
	<20070226064336.GL5871@wheat.betterworld.us>
	<A0FD96B2-2FCD-416E-9496-6D6192511357@ic.ac.uk>
	<1172529270.9347.164.camel@iron.psg.net>
	<B62E11C5-9122-495A-9032-37610A7288B4@ic.ac.uk>
	<Pine.LNX.4.64.0702271137200.2965@nokomis.stat.uiowa.edu>
	<041F0BCD-653B-4309-85FA-82334DA2B50B@ic.ac.uk>
Message-ID: <Pine.LNX.4.64.0702271230430.2965@nokomis.stat.uiowa.edu>

On Tue, 27 Feb 2007, Ernest Turro wrote:

>
> On 27 Feb 2007, at 17:45, Luke Tierney wrote:
>
>> On Tue, 27 Feb 2007, Ernest Turro wrote:
>> 
>>> Hi Ross,
>>> 
>>> On 26 Feb 2007, at 22:34, Ross Boylan wrote:
>>> 
>>>> On Mon, 2007-02-26 at 16:08 +0000, Ernest Turro wrote:
>>>>> Thanks for your comments Ross. A couple more comments/queries below:
>>>>> 
>>>>> On 26 Feb 2007, at 06:43, Ross Boylan wrote:
>>>>> 
>>>>>> [details snipped]
>>>>>> 
>>>>>> The use of the R api can be confined to a wrapper function.  But
>>>>>> I can
>>>>>> think of no reason that a change to the alternate approach I
>>>>>> outlined
>>>>>> would solve the apparent leaking you describe.
>>>>>> 
>>>>> 
>>>>> I'm not sure I see how a wrapper function using the R API would
>>>>> suffice. Example:
>>>> It doesn't sound as if it would suffice.  I was responding to your
>>>> original remark that
>>>> 
>>>>> Since this is a standalone C++ program too, I'd rather use the R API
>>>>> as little as possible... But I will look at your solution if I find
>>>>> it is really necessary.. Thanks
>>>> 
>>>> I thought that was expressing a concern about using the alternate
>>>> approach I outlined because it would use the R API.  If you need to
>>>> use
>>>> that API for other reasons, you're still stuck with it :)
>>>>> 
>>>>> During heavy computation in the C++ function I need to allow
>>>>> interrupts from R. This means that R_CheckUserInterrupt needs to be
>>>>> called during the computation. Therefore, use of the R API can't be
>>>>> confined to just the wrapper function.
>>>>> 
>>>>> In fact, I'm worried that some of the libraries I'm using are failing
>>>>> to release memory after interrupt and that that is the problem. I
>>>>> can't see what I could do about that... E.g.
>>>>> 
>>>>> #include <valarray>
>>>>> 
>>>>> valarray<double> foo; // I don't know 100% that the foo object hasn't
>>>>> allocated some memory. if the program is interrupted it wouldn't be
>>>>> released....
>>>> That's certainly possible, but you seem to be overlooking the
>>>> possibility that all the code is releasing memory appropriately,
>>>> but the
>>>> process's memory footprint isn't going down correspondingly.  In my
>>>> experience that's fairly typical behavior.
>>>> 
>>> 
>>> OK, but does this still explain why the footprint keeps increasing
>>> indefinitely when i do run, interrupt, run, interrupt, run,
>>> interrupt......?
>>> 
>>> 
>>>> In that case, depending on your point of view, you either don't have a
>>>> problem or you have a hard problem.  If you really want the memory
>>>> released back to the system, it's a hard problem.  If you don't
>>>> care, as
>>>> long as you have no leaks, all's well.
>>>> 
>>>>> 
>>>>> I find it's very unfortunate that R_CheckUserInterrupt doesn't return
>>>>> a value. If it did (e.g. if it returned true if an interrupt has
>>>>> occurred), I could just branch off somewhere, clean up properly and
>>>>> return to R.
>>>>> 
>>>>> Any ideas on how this could be achieved?
>>>> I can't tell from the info page what function gets called in R if
>>>> there
>>>> is an interrupt, but it sounds as you could do the following hack:
>>>> The R interrupt handler gets a function that calls a C function of
>>>> your
>>>> devising.  The C function sets a flag meaning "interrupt requested".
>>>> Then in your main code, you periodically call R_CheckUserInterrupt.
>>>> When it returns you check the flag; if it's set, you cleanup and exit.
>>>> Ross
>>>> 
>>> 
>>> If this is feasible, it's by far the best solution.
>>> 
>>> in error.c:
>>> 
>>> void R_CheckUserInterrupt(void)
>>> {
>>>    R_CheckStack();
>>>    /* This is the point where GUI systems need to do enough event
>>>       processing to determine whether there is a user interrupt event
>>>       pending.  Need to be careful not to do too much event
>>>       processing though: if event handlers written in R are allowed
>>>       to run at this point then we end up with concurrent R
>>>       evaluations and that can cause problems until we have proper
>>>       concurrency support. LT */
>>> #if  ( defined(HAVE_AQUA) || defined(Win32) )
>>>    R_ProcessEvents();
>>> #else
>>>    if (R_interrupts_pending)
>>>  onintr();
>>> #endif /* Win32 */
>>> }
>>> 
>>> Leaving aside the HAVE_AQUA and Win32 cases, I would like to write a
>>> new function:
>> 
>> Unfortunately we can't leave those aside.  If standard unix where
>> interrupts arrive as signals is all you care about then you can just
>> save, replace and restore the R SIGINT handler around your code with
>> one that sets a flag of your own.  Things are not so simple on GUI
>> systems where detecting a user interrupt action requires event
>> processing, which might result in errors and non-local exits in
>> response to those.
>> 
>> There is an internal mechanism for registering C level on.exit
>> routines but this is not in a form that can be made public as it would
>> tie down implementation decisions too much.  It is principle possible
>> to build something around R_ToplevelExec, but that is not at this
>> point part of the public API and so is subject to change.  We might
>> consider providing a variant of R_CheckInterrupts that either just
>> checks or that executes cleanup code sometime after 2.5 is released.
>> 
>
> Yes, I think it would be great if you added a variant of 
> R_CheckUserInterrupt() that actually returned something (e.g. a boolean) to 
> the R API.
>
> So in your view, is the best solution to pass a memory cleanup C function to 
> on.exit() before the call? What about memory allocated in some of the 
> external libraries that I use? E.g. as I mentioned above:

Depends on the cleanup actions you have to take.

Best,

luke

>
>>>>> 
>>>>> #include <valarray>
>>>>> // ...
>>>>> valarray<double> foo; // I don't know 100% that the foo object hasn't
>>>>> allocated some memory. if the program is interrupted it wouldn't be
>>>>> released....
>
>
> Thanks for your help,
>
> Ernest
>
>
>> Best,
>> 
>> luke
>> 
>>> 
>>> int R_CheckInterruptsPending(void)
>>> {
>>>    R_CheckStack();
>>>    return R_interrupts_pending;
>>> }
>>> 
>>> and then in my C++ code:
>>> 
>>> if(R_checkInterruptsPending) {
>>> 	// clean up
>>> 	// ...
>>> 	R_CheckInterruptsPending();
>>> }
>>> 
>>> R_CheckStack() is declared in R_ext/Utils.h but the variable
>>> R_interrupts_pending isn't, so how could I access it? In other words,
>>> how can I extend error.c .....
>>> 
>>> 
>>> Thanks,
>>> 
>>> E
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> -- 
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>   Actuarial Science
>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From tpapp at Princeton.EDU  Wed Feb 28 03:15:27 2007
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Tue, 27 Feb 2007 21:15:27 -0500
Subject: [Rd] asking for advice on how to catch nonexistent list elements
Message-ID: <20070228021527.GA4856@pu100877.student.princeton.edu>

Hi,

I am sorry if this is documented or in the archives somewhere, I tried
searching and could not find anything.

When using the $ operator to get a nonexistent element (or if you
prefer, all elements are defined as NULL by default) of a list, it
returns NULL, eg

> a <- list(maximum=12)
> a$maximum
[1] 12
> a$maxium  # typo
NULL

I know that this is the documented behavior of $, so this is
definitely not a bug.  But it leads to bugs that are quite elusive: an
error will only be generated when some function eventually chokes on
NULL.

I would like to know how people cope with that, and if there is a way
to generate an error message (at least when debugging code) for the
typo above.

Thanks,

Tamas


From giampi at kth.se  Wed Feb 28 14:08:06 2007
From: giampi at kth.se (Giampiero Salvi)
Date: Wed, 28 Feb 2007 14:08:06 +0100 (CET)
Subject: [Rd] incremental plots with pdf and dev.copy
Message-ID: <Pine.LNX.4.58.0702281351150.21779@ctt14.speech.kth.se>

Hi,
I am trying to produce incremental plots directly using the pdf
device. I mean that I want to produce a plot, save it in a pdf
file, then add details and save the new plot in a new file, and
so on. Before I used to do this with x11, by just adding graphics to
a plot and then using dev.copy2eps at the right times for each eps
figure. Now I want to do this in batch mode and the x11 device is not
available.

This is how I go about it:

pdf(file="file1.pdf")          # create the first plot
dev.control(displaylist='enable') # allow copying print devices
plot(1:10)                     # first plot
dev.copy(pdf,file="file2.pdf") # create the second plot
dev.control(displaylist='enable')
dev.off(dev.prev())            # close the first plot
points(2,3)                    # add to the second plot
dev.copy(pdf,file="file3.pdf") # create the third plot
dev.off(dev.prev())            # close the second plot
points(3,2)                    # add to the third plot
dev.off()

The problem is this works only for the first two plots. For the
third I get an error at "dev.copy(pdf,file="file3.pdf")"

Error in dev.copy(pdf, file = "file3.pdf") :
        invalid graphics state

I also tried to remove the second dev.control statement, but in
that case the same error is delayed to the "points(3,2)" line
(plotting in the third plot).

Is this behaviour expected? Is there a better way to do what I'm
trying to do?

Thank you!
Giampiero

-- 
________________________________________________________
Giampiero Salvi, Ph.D.
www.speech.kth.se/~giampi          skype: giampierosalvi
Royal Institute of Technology, Speech, Music and Hearing
Lindstedtsv.    24,    SE-100 44,    Stockholm,   Sweden
Tel: +46-8-790 62 93                Fax: +46-8-790 78 54


From a.maier at mpie.de  Wed Feb 28 09:16:03 2007
From: a.maier at mpie.de (a.maier at mpie.de)
Date: Wed, 28 Feb 2007 09:16:03 +0100 (CET)
Subject: [Rd] Tk GUI : Select Packages from CRAN Dialog does not have a
	scrollbar (PR#9534)
Message-ID: <20070228081603.458465ACA3@slim.kubism.ku.dk>

Full_Name: Alois Maier
Version: 2.4.1 
OS: OpenSUSE 10.2 x86-32
Submission from: (NULL) (192.12.81.1)


How to reproduce the bug:
start R with --gui=tk option.
R --gui=tk

select from menu: Packages - Install Packages from CRAN.
The first dialog box that appears (CRAN mirror selection) has a scrollbar.
The following dialog box (package selection) shows no scrollbar. This makes it
difficult to select packages with names after "ade4". 

The dialog box also does not show title.


From hin-tak.leung at cimr.cam.ac.uk  Wed Feb 28 16:58:24 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 28 Feb 2007 15:58:24 +0000
Subject: [Rd] incremental plots with pdf and dev.copy
In-Reply-To: <Pine.LNX.4.58.0702281351150.21779@ctt14.speech.kth.se>
References: <Pine.LNX.4.58.0702281351150.21779@ctt14.speech.kth.se>
Message-ID: <45E5A6A0.2070101@cimr.cam.ac.uk>

This is an r-help question - please post to the relevant list next time.

The problem is with your "dev.off(dev.prev())" lines - you should
have used just "dev.off()" plain, without the dev.prev() inside.
As for why, please read the help pages.

Giampiero Salvi wrote:
> Hi,
> I am trying to produce incremental plots directly using the pdf
> device. I mean that I want to produce a plot, save it in a pdf
> file, then add details and save the new plot in a new file, and
> so on. Before I used to do this with x11, by just adding graphics to
> a plot and then using dev.copy2eps at the right times for each eps
> figure. Now I want to do this in batch mode and the x11 device is not
> available.
> 
> This is how I go about it:
> 
> pdf(file="file1.pdf")          # create the first plot
> dev.control(displaylist='enable') # allow copying print devices
> plot(1:10)                     # first plot
> dev.copy(pdf,file="file2.pdf") # create the second plot
> dev.control(displaylist='enable')
> dev.off(dev.prev())            # close the first plot
> points(2,3)                    # add to the second plot
> dev.copy(pdf,file="file3.pdf") # create the third plot
> dev.off(dev.prev())            # close the second plot
> points(3,2)                    # add to the third plot
> dev.off()
> 
> The problem is this works only for the first two plots. For the
> third I get an error at "dev.copy(pdf,file="file3.pdf")"
> 
> Error in dev.copy(pdf, file = "file3.pdf") :
>         invalid graphics state
> 
> I also tried to remove the second dev.control statement, but in
> that case the same error is delayed to the "points(3,2)" line
> (plotting in the third plot).
> 
> Is this behaviour expected? Is there a better way to do what I'm
> trying to do?
> 
> Thank you!
> Giampiero
>


From mike.prager at noaa.gov  Wed Feb 28 20:01:53 2007
From: mike.prager at noaa.gov (Mike Prager)
Date: Wed, 28 Feb 2007 14:01:53 -0500
Subject: [Rd] Help with "row.names = as.integer(c(NA, 5))" in file from dput
Message-ID: <5ejbu2pim3puhifcqi1abid79q3nh3nkon@4ax.com>

I am trying to understand why syntax used by dput() to write
rownames is valid (say, when read by dget()).  I ask this
because I desire to emulate its actions *reliably* in my For2R
routines, and I won't be comfortable until I understand what R
is doing.

Given data set "fred":

> fred
    id      var1
1 1991 0.4388587
2 1992 0.8772471
3 1993 0.6230486
4 1994 0.2340929
5 1995 0.5005605

we can try this--

> dput(ats, control = "all")
structure(list(id = c(1991, 1992, 1993, 1994, 1995), var1 =
c(0.4388587, 0.8772471, 0.6230486, 0.2340929, 0.5005605)),
.Names = c("id", "var1"), row.names = as.integer(c(NA, 5)),
class = "data.frame")

In the above result, why is the following part valid?

row.names = as.integer(c(NA, 5))

given that the length of the RHS expression is 2, while the
needed length is 5.

Moreover, the following doesn't work:

> row.names(fred) <- as.integer(c(NA,5))
Error in `row.names<-.data.frame`(`*tmp*`, value = c(NA, 5)) : 
        invalid 'row.names' length

Is there any reason why the expression

c(NA,5) 

is better here than the more natural

1:5 

here?

I will appreciate help from anyone with time to reply.

MHP

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From p.dalgaard at biostat.ku.dk  Wed Feb 28 21:52:02 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 28 Feb 2007 21:52:02 +0100
Subject: [Rd] Help with "row.names = as.integer(c(NA,
 5))" in file from dput
In-Reply-To: <5ejbu2pim3puhifcqi1abid79q3nh3nkon@4ax.com>
References: <5ejbu2pim3puhifcqi1abid79q3nh3nkon@4ax.com>
Message-ID: <45E5EB72.9030108@biostat.ku.dk>

Mike Prager wrote:
> I am trying to understand why syntax used by dput() to write
> rownames is valid (say, when read by dget()).  I ask this
> because I desire to emulate its actions *reliably* in my For2R
> routines, and I won't be comfortable until I understand what R
> is doing.
>
> Given data set "fred":
>
>   
>> fred
>>     
>     id      var1
> 1 1991 0.4388587
> 2 1992 0.8772471
> 3 1993 0.6230486
> 4 1994 0.2340929
> 5 1995 0.5005605
>
> we can try this--
>
>   
>> dput(ats, control = "all")
>>     
> structure(list(id = c(1991, 1992, 1993, 1994, 1995), var1 =
> c(0.4388587, 0.8772471, 0.6230486, 0.2340929, 0.5005605)),
> .Names = c("id", "var1"), row.names = as.integer(c(NA, 5)),
> class = "data.frame")
>
> In the above result, why is the following part valid?
>
> row.names = as.integer(c(NA, 5))
>
> given that the length of the RHS expression is 2, while the
> needed length is 5.
>
> Moreover, the following doesn't work:
>
>   
>> row.names(fred) <- as.integer(c(NA,5))
>>     
> Error in `row.names<-.data.frame`(`*tmp*`, value = c(NA, 5)) : 
>         invalid 'row.names' length
>
> Is there any reason why the expression
>
> c(NA,5) 
>
> is better here than the more natural
>
> 1:5 
>
> here?
>
>   
It's mainly a space-saving device. Originally, row.names was a character 
vector, but storage of character vectors is quite inefficient, so we now 
allow integer names and also a very short form where 1:n is stored just 
using the single value n. To distinguish the latter two, we use the 
c(NA, n) form, because row names are not allowed to be missing.

Consider the following and notice how the string row names take up 
roughly 36 bytes per  record where the actual data are only 8 bytes per 
record.

 > d<-data.frame(x=rnorm(1000))
 > object.size(d)
[1] 8392
 > row.names(d)<-as.character(1:1000)
 > object.size(d)
[1] 44384
 > row.names(d)<-1000:1
 > object.size(d)
[1] 12384
 > row.names(d)<-NULL
 > object.size(d)
[1] 8392




> I will appreciate help from anyone with time to reply.
>
> MHP
>
>


From mike.prager at noaa.gov  Wed Feb 28 22:06:38 2007
From: mike.prager at noaa.gov (Mike Prager)
Date: Wed, 28 Feb 2007 16:06:38 -0500
Subject: [Rd] Help with "row.names = as.integer(c(NA,
	5))" in file from dput
References: <5ejbu2pim3puhifcqi1abid79q3nh3nkon@4ax.com>
	<45E5EB72.9030108@biostat.ku.dk>
Message-ID: <s5rbu2dtu6eo2ltssgdv8p3vr697hke2t7@4ax.com>

Peter--

Thank you.  Am I correct in understanding, then, that,

(1) The syntax I asked about is a special case, and the parser
and/or dget() somehow recognize it as such, and

(2) The syntax 1:15 (where 15 is the number of rows)  should
work just as well as c(NA, 15)?

I ask, again, because I want to ensure the widest possible
compatibility for the way For2R is writing data in emulation of
dput().

--Mike


Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> Mike Prager wrote:
> > I am trying to understand why syntax used by dput() to write
> > rownames is valid (say, when read by dget()).  I ask this
> > because I desire to emulate its actions *reliably* in my For2R
> > routines, and I won't be comfortable until I understand what R
> > is doing.
> >
> > Given data set "fred":
> >
> >   
> >> fred
> >>     
> >     id      var1
> > 1 1991 0.4388587
> > 2 1992 0.8772471
> > 3 1993 0.6230486
> > 4 1994 0.2340929
> > 5 1995 0.5005605
> >
> > we can try this--
> >
> >   
> >> dput(ats, control = "all")
> >>     
> > structure(list(id = c(1991, 1992, 1993, 1994, 1995), var1 =
> > c(0.4388587, 0.8772471, 0.6230486, 0.2340929, 0.5005605)),
> > .Names = c("id", "var1"), row.names = as.integer(c(NA, 5)),
> > class = "data.frame")
> >
> > In the above result, why is the following part valid?
> >
> > row.names = as.integer(c(NA, 5))
> >
> > given that the length of the RHS expression is 2, while the
> > needed length is 5.
> >
> > Moreover, the following doesn't work:
> >
> >   
> >> row.names(fred) <- as.integer(c(NA,5))
> >>     
> > Error in `row.names<-.data.frame`(`*tmp*`, value = c(NA, 5)) : 
> >         invalid 'row.names' length
> >
> > Is there any reason why the expression
> >
> > c(NA,5) 
> >
> > is better here than the more natural
> >
> > 1:5 
> >
> > here?
> >
> >   
> It's mainly a space-saving device. Originally, row.names was a character 
> vector, but storage of character vectors is quite inefficient, so we now 
> allow integer names and also a very short form where 1:n is stored just 
> using the single value n. To distinguish the latter two, we use the 
> c(NA, n) form, because row names are not allowed to be missing.
> 
> Consider the following and notice how the string row names take up 
> roughly 36 bytes per  record where the actual data are only 8 bytes per 
> record.
> 
>  > d<-data.frame(x=rnorm(1000))
>  > object.size(d)
> [1] 8392
>  > row.names(d)<-as.character(1:1000)
>  > object.size(d)
> [1] 44384
>  > row.names(d)<-1000:1
>  > object.size(d)
> [1] 12384
>  > row.names(d)<-NULL
>  > object.size(d)
> [1] 8392
> 
> 
> 
> 
> > I will appreciate help from anyone with time to reply.
> >
> > MHP
> >
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From p.dalgaard at biostat.ku.dk  Wed Feb 28 23:01:15 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 28 Feb 2007 23:01:15 +0100
Subject: [Rd] Help with "row.names = as.integer(c(NA,
 5))" in file from dput
In-Reply-To: <s5rbu2dtu6eo2ltssgdv8p3vr697hke2t7@4ax.com>
References: <5ejbu2pim3puhifcqi1abid79q3nh3nkon@4ax.com>	<45E5EB72.9030108@biostat.ku.dk>
	<s5rbu2dtu6eo2ltssgdv8p3vr697hke2t7@4ax.com>
Message-ID: <45E5FBAB.1020006@biostat.ku.dk>

Mike Prager wrote:
> Peter--
>
> Thank you.  Am I correct in understanding, then, that,
>
> (1) The syntax I asked about is a special case, and the parser
> and/or dget() somehow recognize it as such, and
>
> (2) The syntax 1:15 (where 15 is the number of rows)  should
> work just as well as c(NA, 15)?
>
> I ask, again, because I want to ensure the widest possible
> compatibility for the way For2R is writing data in emulation of
> dput().
>
>   
Essentially yes, but

(1) it is not as much about syntax, but about internal representation

(2) Yes, it gives the same result -- the 1:15 is recognized as a vector 
that can be optimized to c(NA, 15). Needing to have the code check for 
this case is of course somewhat wasteful.

To wit:

 > dd <- structure(list(x = c(1.19894055844457, -0.476584995973736, 
1.90525643132169,   -0.726616166810353, 0.590506316214127)), .Names = 
"x", row.names =1:5, class = "data.frame") -
 > dput(dd,control="all")
structure(list(x = c(1.19894055844457, -0.476584995973736, 
1.90525643132169,
-0.726616166810353, 0.590506316214127)), .Names = "x", row.names = 
as.integer(c(NA,
5)), class = "data.frame")


> --Mike
>
>
> Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>
>   
>> Mike Prager wrote:
>>     
>>> I am trying to understand why syntax used by dput() to write
>>> rownames is valid (say, when read by dget()).  I ask this
>>> because I desire to emulate its actions *reliably* in my For2R
>>> routines, and I won't be comfortable until I understand what R
>>> is doing.
>>>
>>> Given data set "fred":
>>>
>>>   
>>>       
>>>> fred
>>>>     
>>>>         
>>>     id      var1
>>> 1 1991 0.4388587
>>> 2 1992 0.8772471
>>> 3 1993 0.6230486
>>> 4 1994 0.2340929
>>> 5 1995 0.5005605
>>>
>>> we can try this--
>>>
>>>   
>>>       
>>>> dput(ats, control = "all")
>>>>     
>>>>         
>>> structure(list(id = c(1991, 1992, 1993, 1994, 1995), var1 =
>>> c(0.4388587, 0.8772471, 0.6230486, 0.2340929, 0.5005605)),
>>> .Names = c("id", "var1"), row.names = as.integer(c(NA, 5)),
>>> class = "data.frame")
>>>
>>> In the above result, why is the following part valid?
>>>
>>> row.names = as.integer(c(NA, 5))
>>>
>>> given that the length of the RHS expression is 2, while the
>>> needed length is 5.
>>>
>>> Moreover, the following doesn't work:
>>>
>>>   
>>>       
>>>> row.names(fred) <- as.integer(c(NA,5))
>>>>     
>>>>         
>>> Error in `row.names<-.data.frame`(`*tmp*`, value = c(NA, 5)) : 
>>>         invalid 'row.names' length
>>>
>>> Is there any reason why the expression
>>>
>>> c(NA,5) 
>>>
>>> is better here than the more natural
>>>
>>> 1:5 
>>>
>>> here?
>>>
>>>   
>>>       
>> It's mainly a space-saving device. Originally, row.names was a character 
>> vector, but storage of character vectors is quite inefficient, so we now 
>> allow integer names and also a very short form where 1:n is stored just 
>> using the single value n. To distinguish the latter two, we use the 
>> c(NA, n) form, because row names are not allowed to be missing.
>>
>> Consider the following and notice how the string row names take up 
>> roughly 36 bytes per  record where the actual data are only 8 bytes per 
>> record.
>>
>>  > d<-data.frame(x=rnorm(1000))
>>  > object.size(d)
>> [1] 8392
>>  > row.names(d)<-as.character(1:1000)
>>  > object.size(d)
>> [1] 44384
>>  > row.names(d)<-1000:1
>>  > object.size(d)
>> [1] 12384
>>  > row.names(d)<-NULL
>>  > object.size(d)
>> [1] 8392
>>
>>
>>
>>
>>     
>>> I will appreciate help from anyone with time to reply.
>>>
>>> MHP
>>>
>>>
>>>       
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>     
>
>


