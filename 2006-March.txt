From jcredberry at gmail.com  Wed Mar  1 00:02:55 2006
From: jcredberry at gmail.com (jcredberry@gmail.com)
Date: Wed,  1 Mar 2006 00:02:55 +0100 (CET)
Subject: [Rd] GUI Crashes (PR#8649)
Message-ID: <20060228230255.42051E93B@slim.kubism.ku.dk>

Full_Name: Julio Rojas
Version: 2.2.1
OS: XP Pro
Submission from: (NULL) (213.60.4.253)


I was debugging a program with browser "()", made a couple of "plot"'s within
the debugging console. Switched back from the plot window to the console window
using the mouse, without closing the plot window, and the GUI crashed and
disapeared. The program is still runing in memory, but with no way to reach it
or get it back alive. I'm running a fairly big dataset and the Task Manager
shows "Rgui.exe" is using 120 Megs of RAM and 99% of the processor.

It has happened twice tonight.


From murdoch at stats.uwo.ca  Wed Mar  1 01:59:29 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 28 Feb 2006 19:59:29 -0500
Subject: [Rd] GUI Crashes (PR#8649)
In-Reply-To: <20060228230255.42051E93B@slim.kubism.ku.dk>
References: <20060228230255.42051E93B@slim.kubism.ku.dk>
Message-ID: <4404F1F1.8030903@stats.uwo.ca>

On 2/28/2006 6:02 PM, jcredberry at gmail.com wrote:
> Full_Name: Julio Rojas
> Version: 2.2.1
> OS: XP Pro
> Submission from: (NULL) (213.60.4.253)
> 
> 
> I was debugging a program with browser "()", made a couple of "plot"'s within
> the debugging console. Switched back from the plot window to the console window
> using the mouse, without closing the plot window, and the GUI crashed and
> disapeared. The program is still runing in memory, but with no way to reach it
> or get it back alive. I'm running a fairly big dataset and the Task Manager
> shows "Rgui.exe" is using 120 Megs of RAM and 99% of the processor.
> 
> It has happened twice tonight.

Please give us a description of a procedure that we can use to reliably 
reproduce the crash.  Otherwise we have no place to start.

Duncan Murdoch


From falberto at ualg.pt  Wed Mar  1 19:06:34 2006
From: falberto at ualg.pt (Filipe)
Date: Wed, 01 Mar 2006 18:06:34 +0000
Subject: [Rd] (no subject)
Message-ID: <6.1.2.0.1.20060301174027.033ad630@pop.ualg.pt>

Hi all

I am not sure this question is better suitted for the R-devel or R-help, 
but here it goes anyway

I am not a software developer but I have produced a personal set of 
functions that I would like now to combine in a package.
I am finding this really hard to do only by following the manuals provided 
(the language is for software developers I guess which I am far to be).
Even so I could install the R-tools in my Windows machine, and start using 
the command line.
Eventually I run into problems and now I am stuck. I wonder if you could 
help me with this problem.

What I have done so far:

I started by using the package.skeleton() function to start my package, I 
placed the folder produced by this function inside the bin folder.
Then I?ve installed the R-tools by extracting the zip file into the \bin 
folder
I have also installed the Active Perl 5.8

I could then follow the instructions on the files produced by 
package.skeleton()
and use the command R CMD build and R CMD check.
Here is where I get the following problem:
after building /updating the help files I get the message " no hhc: found" 
and after that "cp: cannot stat"
there seems to be a file named mypakage.chm missing

Can you help  me solving this, ?




Best regards
Filipe Alberto
Filipe Alberto
Posdoctoral Fellowship Researcher
http://www.ualg.pt/ccmar/maree/index.php?t=falberto
------------------------------------------------------------------------

MAREE-Marine Ecology and Evolution (http://www.ualg.pt/ccmar/maree)
CCMAR - Centre of Marine Sciences, and CIMAR -Laborat?rio Associado
Faculdade de Ci?ncias do Mar e Ambiente, Universidade do Algarve

Mailing address:
F.C.M.A., Univ. Algarve, Gambelas, 8005-139 Faro, Portugal
Fax: 351-289-800069, Phone: 351-289-800900 ext:7355


From ggrothendieck at gmail.com  Wed Mar  1 19:42:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 1 Mar 2006 13:42:11 -0500
Subject: [Rd] (no subject)
In-Reply-To: <6.1.2.0.1.20060301174027.033ad630@pop.ualg.pt>
References: <6.1.2.0.1.20060301174027.033ad630@pop.ualg.pt>
Message-ID: <971536df0603011042l38b6a34fnd4c3c5a367977257@mail.gmail.com>

hhc is the Microsoft Help compiler.  Make sure its on your path.
Info on it is here:
http://www.murdoch-sutherland.com/Rtools/#ldbug

Also batchfiles:
http://cran.r-project.org/contrib/extra/batchfiles/

contains a Windows XP batch file, rfind.bat, that you can run without arguments
that will try to locate all the utilities you need on your disk which can help
you verify that you have them.

In the case of hhc.exe just copy it to somewhere on your path.


On 3/1/06, Filipe <falberto at ualg.pt> wrote:
> Hi all
>
> I am not sure this question is better suitted for the R-devel or R-help,
> but here it goes anyway
>
> I am not a software developer but I have produced a personal set of
> functions that I would like now to combine in a package.
> I am finding this really hard to do only by following the manuals provided
> (the language is for software developers I guess which I am far to be).
> Even so I could install the R-tools in my Windows machine, and start using
> the command line.
> Eventually I run into problems and now I am stuck. I wonder if you could
> help me with this problem.
>
> What I have done so far:
>
> I started by using the package.skeleton() function to start my package, I
> placed the folder produced by this function inside the bin folder.
> Then I've installed the R-tools by extracting the zip file into the \bin
> folder
> I have also installed the Active Perl 5.8
>
> I could then follow the instructions on the files produced by
> package.skeleton()
> and use the command R CMD build and R CMD check.
> Here is where I get the following problem:
> after building /updating the help files I get the message " no hhc: found"
> and after that "cp: cannot stat"
> there seems to be a file named mypakage.chm missing
>
> Can you help  me solving this, ?
>
>
>
>
> Best regards
> Filipe Alberto
> Filipe Alberto
> Posdoctoral Fellowship Researcher
> http://www.ualg.pt/ccmar/maree/index.php?t=falberto
> ------------------------------------------------------------------------
>
> MAREE-Marine Ecology and Evolution (http://www.ualg.pt/ccmar/maree)
> CCMAR - Centre of Marine Sciences, and CIMAR -Laborat?rio Associado
> Faculdade de Ci?ncias do Mar e Ambiente, Universidade do Algarve
>
> Mailing address:
> F.C.M.A., Univ. Algarve, Gambelas, 8005-139 Faro, Portugal
> Fax: 351-289-800069, Phone: 351-289-800900 ext:7355
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pburns at pburns.seanet.com  Wed Mar  1 20:58:39 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 01 Mar 2006 19:58:39 +0000
Subject: [Rd] [Fwd: Re: [R] a strange problem with integrate()]
Message-ID: <4405FCEF.4080707@pburns.seanet.com>

When I saw the subject of the original message on
R-help, I was 95% confident that I knew the answer
(before I had seen the question).

This made me think that perhaps for some functions
there should be a 'Troubleshooting' section in the help
file.

The current help file for 'integrate' does say, as Sundar
points out, what the requirements are.  However, I
think more people would solve the problem more quickly
on their own if there were a troubleshooting section.

Most functions aren't abused in predictable ways, but
a few are.  Another that springs immediately to mind
is 'read.table'.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

-------- Original Message --------
Subject: 	Re: [R] a strange problem with integrate()
Date: 	Wed, 01 Mar 2006 11:44:33 -0600
From: 	Sundar Dorai-Raj <sundar.dorai-raj at pdf.com>
Organization: 	PDF Solutions, Inc.
To: 	vito muggeo <vmuggeo at dssm.unipa.it>
CC: 	r-help at stat.math.ethz.ch <r-help at stat.math.ethz.ch>
References: 	<4405D98F.6030709 at dssm.unipa.it>



vito muggeo wrote:
> Dear all,
> I am stuck on the following problem with integrate(). I have been out of 
> luck using RSiteSearch()..
> 
> My function is
> 
> g2<-function(b,theta,xi,yi,sigma2){
>        xi<-cbind(1,xi)
>        eta<-drop(xi%*%theta)
>        num<-exp((eta + rep(b,length(eta)))*yi)
>        den<- 1 + exp(eta + rep(b,length(eta)))
>        result=(num/den)*exp((-b^2)/sigma2)/sqrt(2*pi*sigma2)
>        r=prod(result)
>        return(r)
>        }
> 
> And I am interested in evaluating the simple integral, but:
> 
>  > integrate(g2,-2,2,theta=c(-2,3),xi=c(1,2,5,6),yi=c(1,0,1,1),sigma2=1)
> Error in integrate(g2, -2, 2, theta = c(-2, 3), xi = c(1, 2, 5, 6), yi = 
> c(1,  :
>          evaluation of function gave a result of wrong length
>  >
> 
> I have checked the integrand function
> 
>  > valori<-seq(-2,2,l=30)
>  > risvalori<-NULL
>  > for(k in valori) 
> risvalori[length(risvalori)+1]<-g2(k,theta=c(-2,3),xi=c(1,2,5,6),yi=c(1,0,1,1),sigma2=1)
>  > plot(valori, risvalori)
> 
> And the integral exists..
> 
> Please, any comment is coming?
> 
> many thanks,
> vito
> 

Please (re-)read ?integrate:

  f: an R function taking a numeric first argument and returning a
           numeric vector of the same length.  Returning a non-finite
           element will generate an error.

Note the "returning a numeric vector of the *same* length." Your 
function returns "prod(r)" which is not the same length as "b".

Some style issues (and I state these as diplomatically as is possible in 
e-mail):

a. Don't mix "<-" with "=" for assignment in your scripts.
b. Use more spaces and consistent indenting.

Here's what my code looks like:

g2 <- function(b, theta, xi, yi, sigma2) {
   xi <- cbind(1, xi)
   eta <- drop(xi %*% theta)
   num <- exp((eta + rep(b, length(eta))) * yi)
   den <- 1 + exp(eta + rep(b, length(eta)))
   result <- (num/den) * exp((-b2)/sigma2)/sqrt(2 * pi * sigma2)
   r <- prod(result)
   r
}

After reformatting your code I saw your problem immediately without 
having executing a single line.

HTH,

--sundar

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


From davison at uchicago.edu  Wed Mar  1 22:44:52 2006
From: davison at uchicago.edu (Dan Davison)
Date: Wed, 1 Mar 2006 15:44:52 -0600 (CST)
Subject: [Rd] stopifnot() suggestion
Message-ID: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>

If an expression is passed to stopifnot() which contains missing values, 
then the resulting error message is somewhat baffling until you are used 
to it, e.g.

> x <- y <- rep(TRUE, 10)
> y[7] <- NA
> stopifnot(x, y)
Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
stop(paste(deparse(mc[[i +  :
 	missing value where TRUE/FALSE needed

A minor change to stopifnot() produces the following behaviour:

> stopifnot(x, y)
Error in stopifnot(x, y) : y contains missing values

My attempt at a suitable modification follows, and below that the original 
function definition. Is a change along these lines appropriate?

## Altered version

stopifnot <- function (...) {
     n <- length(ll <- list(...))
     if (n == 0)
         return(invisible())
     mc <- match.call()
     for (i in 1:n) {
         if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i + 1]])), " contains missing values")
         if (!(is.logical(r) && all(r)))
             stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. = FALSE)
     }
}


## from R-2.1.1/src/library/base/R/stop.R

stopifnot <- function(...)
{
     n <- length(ll <- list(...))
     if(n == 0)
         return(invisible())
     mc <- match.call()
     for(i in 1:n)
         if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
             stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
}


Thanks,

Dan


> version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R

----------
Dan Davison
Committee on Evolutionary Biology
University of Chicago, U.S.A.


From rpeng at jhsph.edu  Wed Mar  1 22:57:26 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 01 Mar 2006 16:57:26 -0500
Subject: [Rd] stopifnot() suggestion
In-Reply-To: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
References: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
Message-ID: <440618C6.2010106@jhsph.edu>

Wouldn't it be better to do something like

stopifnot(all(!is.na(x)), all(!is.na(y)), x, y)

rather than have stopifnot() go checking for NAs?  I agree the message is 
strange but if having non-NA values is really a condition, then why not just put 
it in the call to stopifnot()?

-roger

Dan Davison wrote:
> If an expression is passed to stopifnot() which contains missing values, 
> then the resulting error message is somewhat baffling until you are used 
> to it, e.g.
> 
>> x <- y <- rep(TRUE, 10)
>> y[7] <- NA
>> stopifnot(x, y)
> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
> stop(paste(deparse(mc[[i +  :
>  	missing value where TRUE/FALSE needed
> 
> A minor change to stopifnot() produces the following behaviour:
> 
>> stopifnot(x, y)
> Error in stopifnot(x, y) : y contains missing values
> 
> My attempt at a suitable modification follows, and below that the original 
> function definition. Is a change along these lines appropriate?
> 
> ## Altered version
> 
> stopifnot <- function (...) {
>      n <- length(ll <- list(...))
>      if (n == 0)
>          return(invisible())
>      mc <- match.call()
>      for (i in 1:n) {
>          if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i + 1]])), " contains missing values")
>          if (!(is.logical(r) && all(r)))
>              stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. = FALSE)
>      }
> }
> 
> 
> ## from R-2.1.1/src/library/base/R/stop.R
> 
> stopifnot <- function(...)
> {
>      n <- length(ll <- list(...))
>      if(n == 0)
>          return(invisible())
>      mc <- match.call()
>      for(i in 1:n)
>          if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
>              stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
> }
> 
> 
> Thanks,
> 
> Dan
> 
> 
>> version
>           _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> 
> ----------
> Dan Davison
> Committee on Evolutionary Biology
> University of Chicago, U.S.A.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From davison at uchicago.edu  Wed Mar  1 23:24:22 2006
From: davison at uchicago.edu (Dan Davison)
Date: Wed, 1 Mar 2006 16:24:22 -0600 (CST)
Subject: [Rd] stopifnot() suggestion
In-Reply-To: <440618C6.2010106@jhsph.edu>
References: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
	<440618C6.2010106@jhsph.edu>
Message-ID: <Pine.GSO.4.62.0603011601370.13700@harper.uchicago.edu>

On Wed, 1 Mar 2006, Roger D. Peng wrote:

> Wouldn't it be better to do something like
>
> stopifnot(all(!is.na(x)), all(!is.na(y)), x, y)
>
> rather than have stopifnot() go checking for NAs?  I agree the message is 
> strange but if having non-NA values is really a condition, then why not just 
> put it in the call to stopifnot()?
>
> -roger
>

I was thinking of a fallible R user accidentally testing the truth of an 
expression with NAs, rather than of a situation where you remember that 
there may be missing values. For example

> f <- function() { x <- NA ; if(x != 4) stop("x should be 4") }
> g <- function() { x <- NA ; stopifnot(x == 4) }
> f()
Error in if (x != 4) stop("x should be 4") :
 	missing value where TRUE/FALSE needed
> g()
Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
stop(paste(deparse(mc[[i +  :
 	missing value where TRUE/FALSE needed

If you write the error-checking code represented by f(), you get a message 
which is very helpful in correcting your error. But someone who uses 
stopifnot() instead gets the output of g(). Even a user who knows the 
origin of the code in the error message doesn't know which of several 
stopifnot()s is responsible.

Dan



> Dan Davison wrote:
>> If an expression is passed to stopifnot() which contains missing values, 
>> then the resulting error message is somewhat baffling until you are used to 
>> it, e.g.
>> 
>>> x <- y <- rep(TRUE, 10)
>>> y[7] <- NA
>>> stopifnot(x, y)
>> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r))) 
>> stop(paste(deparse(mc[[i +  :
>>  	missing value where TRUE/FALSE needed
>> 
>> A minor change to stopifnot() produces the following behaviour:
>> 
>>> stopifnot(x, y)
>> Error in stopifnot(x, y) : y contains missing values
>> 
>> My attempt at a suitable modification follows, and below that the original 
>> function definition. Is a change along these lines appropriate?
>> 
>> ## Altered version
>> 
>> stopifnot <- function (...) {
>>      n <- length(ll <- list(...))
>>      if (n == 0)
>>          return(invisible())
>>      mc <- match.call()
>>      for (i in 1:n) {
>>          if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i + 
>> 1]])), " contains missing values")
>>          if (!(is.logical(r) && all(r)))
>>              stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. = 
>> FALSE)
>>      }
>> }
>> 
>> 
>> ## from R-2.1.1/src/library/base/R/stop.R
>> 
>> stopifnot <- function(...)
>> {
>>      n <- length(ll <- list(...))
>>      if(n == 0)
>>          return(invisible())
>>      mc <- match.call()
>>      for(i in 1:n)
>>          if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
>>              stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
>> }
>> 
>> 
>> Thanks,
>> 
>> Dan
>> 
>> 
>>> version
>>           _
>> platform i386-pc-linux-gnu
>> arch     i386
>> os       linux-gnu
>> system   i386, linux-gnu
>> status
>> major    2
>> minor    2.0
>> year     2005
>> month    10
>> day      06
>> svn rev  35749
>> language R
>> 
>> ----------
>> Dan Davison
>> Committee on Evolutionary Biology
>> University of Chicago, U.S.A.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>


From deepayan.sarkar at gmail.com  Thu Mar  2 03:02:13 2006
From: deepayan.sarkar at gmail.com (deepayan.sarkar@gmail.com)
Date: Thu,  2 Mar 2006 03:02:13 +0100 (CET)
Subject: [Rd] Bug/Wishlist: 'partial' in 'sort' and 'quantile' (PR#8650)
Message-ID: <20060302020213.9CCC93FBD1@slim.kubism.ku.dk>

Hi,

This is essentially a reposting of

http://tolstoy.newcastle.edu.au/R/devel/05/11/3305.html

which had no responses, and the behaviour reported there persists in
r-devel as of yesterday.

(1) sort() with non-null partial

> x = rnorm(100000)
> keep = as.integer(ppoints(10000) * 100000)
> system.time(sort(x))
[1] 0.05 0.00 0.04 0.00 0.00
> system.time(sort(x, partial = keep))
[1] 52.04  0.02 52.08  0.00  0.00

This is perhaps not strictly a bug, but taking approximately 1000
times longer to do a subset of the work seems pointless at best.

(2) quantile.default() always calls sort() with a non-null partial
argument. Consequently,

> system.time(quantile(x, ppoints(10000)))
[1] 88.82  0.05 88.90  0.00  0.00

There's no way around this except by writing a custom version of
quantile. lattice currently does this, giving

> system.time(lattice:::fast.quantile(x, ppoints(10000)))
[1] 0.07 0.01 0.08 0.00 0.00

Which brings me to my wishlist request: if (1) cannot be fixed easily,
could quantile.default() at least have an optional argument that can
be used to disable partial sorting?

> sessionInfo()
Version 2.3.0 Under development (unstable) (2006-02-28 r37448)
x86_64-unknown-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

Deepayan
--
http://www.stat.wisc.edu/~deepayan/


From deepayan.sarkar at gmail.com  Thu Mar  2 04:27:47 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 1 Mar 2006 21:27:47 -0600
Subject: [Rd] wishlist: functions to manipulate functions
Message-ID: <eb555e660603011927h7b10e9f3l55f75801cdb1997@mail.gmail.com>

Hi,

Even though R is a functional language and it's common to have
functions as arguments to other functions (notably lapply and
friends), it is not possible to manipulate functions as easily as
other objects. I particularly miss

1. An operator to combine functions (analogous to %*%), e.g.

"%of%" <-
    function(f, g)
{
    function(x) f(g(x))
}

which for instance could be used to do

sapply(ls(), class %of% get)

rather than

sapply(ls(), function(x) class(get(x)))


2. Something to create a new function from an old one with different
defaults, e.g.

update.function <-
    function(object, ...)
{
    args <- list(...)
    function(...)
    {
        dots <- list(...)
        dots[names(args)] <- args
        do.call(object, dots)
    }
}

This is probably more useful in lattice than elsewhere, e.g.

library(lattice)
qqmath(rt(1000, df = 5), distribution = update(qt, df = 5))

instead of

qqmath(rt(1000, df = 5), distribution = function(p) qt(p, df = 5))

Would these be worth adding to the base system?

It would also have been cool if (sin^2 + cos^2) returned a valid
function, but defining Ops.function doesn't seem to have any effect
(probably because oldClass is NULL for functions).

Deepayan
--
http://www.stat.wisc.edu/~deepayan/


From ripley at stats.ox.ac.uk  Thu Mar  2 07:45:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Mar 2006 06:45:39 +0000 (GMT)
Subject: [Rd] stopifnot() suggestion
In-Reply-To: <Pine.GSO.4.62.0603011601370.13700@harper.uchicago.edu>
References: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
	<440618C6.2010106@jhsph.edu>
	<Pine.GSO.4.62.0603011601370.13700@harper.uchicago.edu>
Message-ID: <Pine.LNX.4.64.0603020640230.10469@gannet.stats.ox.ac.uk>

stopifnot() is not intended for use by end-users, but for tests in 
packages.  If the writers of package tests are not aware of the perils of 
using == or != with numbers, then it is good that they get reminded.

And we do have isTRUE for use with it.


On Wed, 1 Mar 2006, Dan Davison wrote:

> On Wed, 1 Mar 2006, Roger D. Peng wrote:
>
>> Wouldn't it be better to do something like
>>
>> stopifnot(all(!is.na(x)), all(!is.na(y)), x, y)
>>
>> rather than have stopifnot() go checking for NAs?  I agree the message is
>> strange but if having non-NA values is really a condition, then why not just
>> put it in the call to stopifnot()?
>>
>> -roger
>>
>
> I was thinking of a fallible R user accidentally testing the truth of an
> expression with NAs, rather than of a situation where you remember that
> there may be missing values. For example
>
>> f <- function() { x <- NA ; if(x != 4) stop("x should be 4") }
>> g <- function() { x <- NA ; stopifnot(x == 4) }
>> f()
> Error in if (x != 4) stop("x should be 4") :
> 	missing value where TRUE/FALSE needed
>> g()
> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
> stop(paste(deparse(mc[[i +  :
> 	missing value where TRUE/FALSE needed
>
> If you write the error-checking code represented by f(), you get a message
> which is very helpful in correcting your error. But someone who uses
> stopifnot() instead gets the output of g(). Even a user who knows the
> origin of the code in the error message doesn't know which of several
> stopifnot()s is responsible.
>
> Dan
>
>
>
>> Dan Davison wrote:
>>> If an expression is passed to stopifnot() which contains missing values,
>>> then the resulting error message is somewhat baffling until you are used to
>>> it, e.g.
>>>
>>>> x <- y <- rep(TRUE, 10)
>>>> y[7] <- NA
>>>> stopifnot(x, y)
>>> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
>>> stop(paste(deparse(mc[[i +  :
>>>  	missing value where TRUE/FALSE needed
>>>
>>> A minor change to stopifnot() produces the following behaviour:
>>>
>>>> stopifnot(x, y)
>>> Error in stopifnot(x, y) : y contains missing values
>>>
>>> My attempt at a suitable modification follows, and below that the original
>>> function definition. Is a change along these lines appropriate?
>>>
>>> ## Altered version
>>>
>>> stopifnot <- function (...) {
>>>      n <- length(ll <- list(...))
>>>      if (n == 0)
>>>          return(invisible())
>>>      mc <- match.call()
>>>      for (i in 1:n) {
>>>          if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i +
>>> 1]])), " contains missing values")
>>>          if (!(is.logical(r) && all(r)))
>>>              stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. =
>>> FALSE)
>>>      }
>>> }
>>>
>>>
>>> ## from R-2.1.1/src/library/base/R/stop.R
>>>
>>> stopifnot <- function(...)
>>> {
>>>      n <- length(ll <- list(...))
>>>      if(n == 0)
>>>          return(invisible())
>>>      mc <- match.call()
>>>      for(i in 1:n)
>>>          if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
>>>              stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
>>> }
>>>
>>>
>>> Thanks,
>>>
>>> Dan
>>>
>>>
>>>> version
>>>           _
>>> platform i386-pc-linux-gnu
>>> arch     i386
>>> os       linux-gnu
>>> system   i386, linux-gnu
>>> status
>>> major    2
>>> minor    2.0
>>> year     2005
>>> month    10
>>> day      06
>>> svn rev  35749
>>> language R
>>>
>>> ----------
>>> Dan Davison
>>> Committee on Evolutionary Biology
>>> University of Chicago, U.S.A.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Mar  2 08:43:56 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Mar 2006 08:43:56 +0100
Subject: [Rd] stopifnot() suggestion
In-Reply-To: <Pine.LNX.4.64.0603020640230.10469@gannet.stats.ox.ac.uk>
References: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
	<440618C6.2010106@jhsph.edu>
	<Pine.GSO.4.62.0603011601370.13700@harper.uchicago.edu>
	<Pine.LNX.4.64.0603020640230.10469@gannet.stats.ox.ac.uk>
Message-ID: <17414.41532.507637.485340@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Thu, 2 Mar 2006 06:45:39 +0000 (GMT) writes:

    BDR> stopifnot() is not intended for use by end-users, but for tests in 
    BDR> packages.  

and additionally for  "function writers"  aka 'programmeRs'.
I think we have argued that R has stopifnot() where other
programming languages use  assert().
It can be very convenient to have one compact

   stopifnot( condition_A,  condition_B,  condition_C)

statement at the beginning of your function instead of
potentially much more verbose

   if(!condition_A) 
       stop("bla A bla A bla bla")
   if(!condition_B) 
       stop("bla B bla B bla bla")
   if(!condition_C) 
       stop("bla C bla C bla bla")

where the latter *would* produce more understandable error
messages but need much more programmer's time.

    BDR> If the writers of package tests are not aware of the perils of 
    BDR> using == or != with numbers, then it is good that they get reminded.

    BDR> And we do have isTRUE for use with it.

indeed!

I still don't see why Dan's original proposition shouldn't be
considered for adaption.
One of the most valid (IMO) complaints about S and R have been the
``uncomprehensible error messages'' that people see occasionally.
[[Though, sometimes the error message is well understandable
  and it's just the user's lazyness to *read* and *think* .. ]]

An extra is.na() check in a stopifnot() in order to produce a
much better message seems to me well worth.

Martin


    BDR> On Wed, 1 Mar 2006, Dan Davison wrote:

    >> On Wed, 1 Mar 2006, Roger D. Peng wrote:
    >> 
    >>> Wouldn't it be better to do something like
    >>> 
    >>> stopifnot(all(!is.na(x)), all(!is.na(y)), x, y)
    >>> 
    >>> rather than have stopifnot() go checking for NAs?  I agree the message is
    >>> strange but if having non-NA values is really a condition, then why not just
    >>> put it in the call to stopifnot()?
    >>> 
    >>> -roger
    >>> 
    >> 
    >> I was thinking of a fallible R user accidentally testing the truth of an
    >> expression with NAs, rather than of a situation where you remember that
    >> there may be missing values. For example
    >> 
    >>> f <- function() { x <- NA ; if(x != 4) stop("x should be 4") }
    >>> g <- function() { x <- NA ; stopifnot(x == 4) }
    >>> f()
    >> Error in if (x != 4) stop("x should be 4") :
    >> missing value where TRUE/FALSE needed
    >>> g()
    >> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
    >> stop(paste(deparse(mc[[i +  :
    >> missing value where TRUE/FALSE needed
    >> 
    >> If you write the error-checking code represented by f(), you get a message
    >> which is very helpful in correcting your error. But someone who uses
    >> stopifnot() instead gets the output of g(). Even a user who knows the
    >> origin of the code in the error message doesn't know which of several
    >> stopifnot()s is responsible.
    >> 
    >> Dan
    >> 
    >> 
    >> 
    >>> Dan Davison wrote:
    >>>> If an expression is passed to stopifnot() which contains missing values,
    >>>> then the resulting error message is somewhat baffling until you are used to
    >>>> it, e.g.
    >>>> 
    >>>>> x <- y <- rep(TRUE, 10)
    >>>>> y[7] <- NA
    >>>>> stopifnot(x, y)
    >>>> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
    >>>> stop(paste(deparse(mc[[i +  :
    >>>> missing value where TRUE/FALSE needed
    >>>> 
    >>>> A minor change to stopifnot() produces the following behaviour:
    >>>> 
    >>>>> stopifnot(x, y)
    >>>> Error in stopifnot(x, y) : y contains missing values
    >>>> 
    >>>> My attempt at a suitable modification follows, and below that the original
    >>>> function definition. Is a change along these lines appropriate?
    >>>> 
    >>>> ## Altered version
    >>>> 
    >>>> stopifnot <- function (...) {
    >>>> n <- length(ll <- list(...))
    >>>> if (n == 0)
    >>>> return(invisible())
    >>>> mc <- match.call()
    >>>> for (i in 1:n) {
    >>>> if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i +
    >>>> 1]])), " contains missing values")
    >>>> if (!(is.logical(r) && all(r)))
    >>>> stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. =
    >>>> FALSE)
    >>>> }
    >>>> }
    >>>> 
    >>>> 
    >>>> ## from R-2.1.1/src/library/base/R/stop.R
    >>>> 
    >>>> stopifnot <- function(...)
    >>>> {
    >>>> n <- length(ll <- list(...))
    >>>> if(n == 0)
    >>>> return(invisible())
    >>>> mc <- match.call()
    >>>> for(i in 1:n)
    >>>> if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
    >>>> stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
    >>>> }
    >>>> 
    >>>> 
    >>>> Thanks,
    >>>> 
    >>>> Dan
    >>>> 
    >>>> 
    >>>>> version
    >>>> _
    >>>> platform i386-pc-linux-gnu
    >>>> arch     i386
    >>>> os       linux-gnu
    >>>> system   i386, linux-gnu
    >>>> status
    >>>> major    2
    >>>> minor    2.0
    >>>> year     2005
    >>>> month    10
    >>>> day      06
    >>>> svn rev  35749
    >>>> language R
    >>>> 
    >>>> ----------
    >>>> Dan Davison
    >>>> Committee on Evolutionary Biology
    >>>> University of Chicago, U.S.A.
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> 
    >>> 
    >>> --
    >>> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
    >>> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    BDR> ______________________________________________
    BDR> R-devel at r-project.org mailing list
    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu Mar  2 09:27:28 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Mar 2006 08:27:28 +0000 (GMT)
Subject: [Rd] stopifnot() suggestion
In-Reply-To: <17414.41532.507637.485340@stat.math.ethz.ch>
References: <Pine.GSO.4.62.0603011507180.13700@harper.uchicago.edu>
	<440618C6.2010106@jhsph.edu>
	<Pine.GSO.4.62.0603011601370.13700@harper.uchicago.edu>
	<Pine.LNX.4.64.0603020640230.10469@gannet.stats.ox.ac.uk>
	<17414.41532.507637.485340@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0603020808360.15967@gannet.stats.ox.ac.uk>

On Thu, 2 Mar 2006, Martin Maechler wrote:

>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Thu, 2 Mar 2006 06:45:39 +0000 (GMT) writes:
>
>    BDR> stopifnot() is not intended for use by end-users, but for tests in
>    BDR> packages.
>
> and additionally for  "function writers"  aka 'programmeRs'.
> I think we have argued that R has stopifnot() where other
> programming languages use  assert().

Languages which do not have NA, so I have never argued such.

> It can be very convenient to have one compact
>
>   stopifnot( condition_A,  condition_B,  condition_C)
>
> statement at the beginning of your function instead of
> potentially much more verbose
>
>   if(!condition_A)
>       stop("bla A bla A bla bla")
>   if(!condition_B)
>       stop("bla B bla B bla bla")
>   if(!condition_C)
>       stop("bla C bla C bla bla")
>
> where the latter *would* produce more understandable error
> messages but need much more programmer's time.
>
>    BDR> If the writers of package tests are not aware of the perils of
>    BDR> using == or != with numbers, then it is good that they get reminded.
>
>    BDR> And we do have isTRUE for use with it.
>
> indeed!
>
> I still don't see why Dan's original proposition shouldn't be
> considered for adaption.
> One of the most valid (IMO) complaints about S and R have been the
> ``uncomprehensible error messages'' that people see occasionally.
> [[Though, sometimes the error message is well understandable
>  and it's just the user's lazyness to *read* and *think* .. ]]

I find that `incomprehensible'!

> An extra is.na() check in a stopifnot() in order to produce a
> much better message seems to me well worth.

Because what should happen with NA is not well-defined.  In one version, 
it is said that stopifnot() fails if an expression is not true.  Now, if 
that said TRUE, returning NA would not be an error and stopifnot should 
give an error.  Later on we are told it is `conceptually equivalent' to 
something which behaves as it currently does.  So this hangs on exactly 
what is meant by `true'.

It seems to me that stopifnot() should probably throw an error unless the 
logical result is TRUE, but at present it is written assuming the result 
must be TRUE or FALSE (and I have just documented that).  And if you 
advocate it as the analogue of assert, then I think the behaviour needs to 
be changed.

>
> Martin
>
>
>    BDR> On Wed, 1 Mar 2006, Dan Davison wrote:
>
>    >> On Wed, 1 Mar 2006, Roger D. Peng wrote:
>    >>
>    >>> Wouldn't it be better to do something like
>    >>>
>    >>> stopifnot(all(!is.na(x)), all(!is.na(y)), x, y)
>    >>>
>    >>> rather than have stopifnot() go checking for NAs?  I agree the message is
>    >>> strange but if having non-NA values is really a condition, then why not just
>    >>> put it in the call to stopifnot()?
>    >>>
>    >>> -roger
>    >>>
>    >>
>    >> I was thinking of a fallible R user accidentally testing the truth of an
>    >> expression with NAs, rather than of a situation where you remember that
>    >> there may be missing values. For example
>    >>
>    >>> f <- function() { x <- NA ; if(x != 4) stop("x should be 4") }
>    >>> g <- function() { x <- NA ; stopifnot(x == 4) }
>    >>> f()
>    >> Error in if (x != 4) stop("x should be 4") :
>    >> missing value where TRUE/FALSE needed
>    >>> g()
>    >> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
>    >> stop(paste(deparse(mc[[i +  :
>    >> missing value where TRUE/FALSE needed
>    >>
>    >> If you write the error-checking code represented by f(), you get a message
>    >> which is very helpful in correcting your error. But someone who uses
>    >> stopifnot() instead gets the output of g(). Even a user who knows the
>    >> origin of the code in the error message doesn't know which of several
>    >> stopifnot()s is responsible.
>    >>
>    >> Dan
>    >>
>    >>
>    >>
>    >>> Dan Davison wrote:
>    >>>> If an expression is passed to stopifnot() which contains missing values,
>    >>>> then the resulting error message is somewhat baffling until you are used to
>    >>>> it, e.g.
>    >>>>
>    >>>>> x <- y <- rep(TRUE, 10)
>    >>>>> y[7] <- NA
>    >>>>> stopifnot(x, y)
>    >>>> Error in if (!(is.logical(r <- eval(ll[[i]])) && all(r)))
>    >>>> stop(paste(deparse(mc[[i +  :
>    >>>> missing value where TRUE/FALSE needed
>    >>>>
>    >>>> A minor change to stopifnot() produces the following behaviour:
>    >>>>
>    >>>>> stopifnot(x, y)
>    >>>> Error in stopifnot(x, y) : y contains missing values
>    >>>>
>    >>>> My attempt at a suitable modification follows, and below that the original
>    >>>> function definition. Is a change along these lines appropriate?
>    >>>>
>    >>>> ## Altered version
>    >>>>
>    >>>> stopifnot <- function (...) {
>    >>>> n <- length(ll <- list(...))
>    >>>> if (n == 0)
>    >>>> return(invisible())
>    >>>> mc <- match.call()
>    >>>> for (i in 1:n) {
>    >>>> if(any(is.na(r <- eval(ll[[i]])))) stop(paste(deparse(mc[[i +
>    >>>> 1]])), " contains missing values")
>    >>>> if (!(is.logical(r) && all(r)))
>    >>>> stop(paste(deparse(mc[[i + 1]]), "is not TRUE"), call. =
>    >>>> FALSE)
>    >>>> }
>    >>>> }
>    >>>>
>    >>>>
>    >>>> ## from R-2.1.1/src/library/base/R/stop.R
>    >>>>
>    >>>> stopifnot <- function(...)
>    >>>> {
>    >>>> n <- length(ll <- list(...))
>    >>>> if(n == 0)
>    >>>> return(invisible())
>    >>>> mc <- match.call()
>    >>>> for(i in 1:n)
>    >>>> if(!(is.logical(r <- eval(ll[[i]])) && all(r)))
>    >>>> stop(paste(deparse(mc[[i+1]]), "is not TRUE"), call. = FALSE)
>    >>>> }
>    >>>>
>    >>>>
>    >>>> Thanks,
>    >>>>
>    >>>> Dan
>    >>>>
>    >>>>
>    >>>>> version
>    >>>> _
>    >>>> platform i386-pc-linux-gnu
>    >>>> arch     i386
>    >>>> os       linux-gnu
>    >>>> system   i386, linux-gnu
>    >>>> status
>    >>>> major    2
>    >>>> minor    2.0
>    >>>> year     2005
>    >>>> month    10
>    >>>> day      06
>    >>>> svn rev  35749
>    >>>> language R
>    >>>>
>    >>>> ----------
>    >>>> Dan Davison
>    >>>> Committee on Evolutionary Biology
>    >>>> University of Chicago, U.S.A.
>    >>>>
>    >>>> ______________________________________________
>    >>>> R-devel at r-project.org mailing list
>    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>    >>>>
>    >>>
>    >>> --
>    >>> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>    >>>
>    >>
>    >> ______________________________________________
>    >> R-devel at r-project.org mailing list
>    >> https://stat.ethz.ch/mailman/listinfo/r-devel
>    >>
>    >>
>
>    BDR> --
>    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
>    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
>    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>    BDR> ______________________________________________
>    BDR> R-devel at r-project.org mailing list
>    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From I.J.Wilson at ncl.ac.uk  Thu Mar  2 13:20:57 2006
From: I.J.Wilson at ncl.ac.uk (I.J.Wilson@ncl.ac.uk)
Date: Thu,  2 Mar 2006 13:20:57 +0100 (CET)
Subject: [Rd] problem with as.table (PR#8652)
Message-ID: <20060302122057.F17963FA48@slim.kubism.ku.dk>

# Your mailer is set to "none" (default on Windows),
# hence we cannot send the bug report directly from R.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs at r-project.org
#
######################################################


There is a problem with as.table converting from a matrix with
more than 26 rows (or columns) .

rows past 26 are set to <NA>.  This makes operations such as
turning the data back into a data.frame difficult.

example causing problems:

b <-  as.table(matrix(1:60,ncol=2))
as.integer(as.data.frame(b)[,1])

Ian Wilson


--please do not edit the information below--

Version:
 platform = i686-redhat-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status =
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=en_GB.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_GB.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_GB.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:onelocus, package:methods, package:stats, 
package:graphics, package:grDevices, package:utils, package:datasets, 
Autoloads, package:base


From dimitris.rizopoulos at med.kuleuven.be  Thu Mar  2 13:54:09 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 2 Mar 2006 13:54:09 +0100
Subject: [Rd] '...' passed to both plot() and legend()
Message-ID: <001a01c63df8$65d6d680$0540210a@www.domain>

Dear R-devels,

I'd like to create a plot method for a class of objects that passes 
the '...' argument to both plot() and legend(), e.g.,

x <- list(data = rnorm(1000))
class(x) <- "foo"
plot.foo <- function(x, legend = FALSE, cx = "topright", cy = NULL, 
...){
    dx <- sort(x$data)
    plot(dx, dnorm(dx), type = "l", ...)
    if (legend)
        legend(cx, cy, "Gaussian density", bty = "n", ...)
    invisible()
}
#####################
plot(x)
plot(x, legend = TRUE, cex = 1.1)


However, and as expected, if I use an argument of plot() that is not 
an argument of legend() an error occurs, e.g.,

plot(x, legend = TRUE, cex.lab = 1.1)


Is there any (efficient and appropriate) way that I could use the 
'...' argument in this case?

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R


Thanks in advance for any hints,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ripley at stats.ox.ac.uk  Thu Mar  2 14:16:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Mar 2006 13:16:21 +0000 (GMT)
Subject: [Rd] '...' passed to both plot() and legend()
In-Reply-To: <001a01c63df8$65d6d680$0540210a@www.domain>
References: <001a01c63df8$65d6d680$0540210a@www.domain>
Message-ID: <Pine.LNX.4.64.0603021314150.25490@gannet.stats.ox.ac.uk>

See e.g. graphics:::plot.POSIXct, which contains

     axisInt <- function(x, type, main, sub, xlab, ylab, col,
         lty, lwd, xlim, ylim, bg, pch, log, asp, axes, frame.plot,
         ...) axis.POSIXct(1, x, ...)

You could use such as wrapper for legend, in your case probably to pick 
out just the arguments you want.


On Thu, 2 Mar 2006, Dimitris Rizopoulos wrote:

> Dear R-devels,
>
> I'd like to create a plot method for a class of objects that passes
> the '...' argument to both plot() and legend(), e.g.,
>
> x <- list(data = rnorm(1000))
> class(x) <- "foo"
> plot.foo <- function(x, legend = FALSE, cx = "topright", cy = NULL,
> ...){
>    dx <- sort(x$data)
>    plot(dx, dnorm(dx), type = "l", ...)
>    if (legend)
>        legend(cx, cy, "Gaussian density", bty = "n", ...)
>    invisible()
> }
> #####################
> plot(x)
> plot(x, legend = TRUE, cex = 1.1)
>
>
> However, and as expected, if I use an argument of plot() that is not
> an argument of legend() an error occurs, e.g.,
>
> plot(x, legend = TRUE, cex.lab = 1.1)
>
>
> Is there any (efficient and appropriate) way that I could use the
> '...' argument in this case?
>
>> version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
>
>
> Thanks in advance for any hints,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://www.med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Thu Mar  2 14:21:44 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 02 Mar 2006 08:21:44 -0500
Subject: [Rd] minor oddity in pdf() help page
Message-ID: <4406F168.9080605@jhsph.edu>

The following paragraph from ?pdf struck me as a bit odd:

      'pdf' writes uncompressed PDF.  It is primarily intended for
      producing PDF graphics for inclusion in other documents, and
      PDF-includers such as 'pdftex' are usually able to handle
      compression.

Should that be "...and PDF-includers such as 'pdftex' are usually _un_able to 
handle compression" ?

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From p.dalgaard at biostat.ku.dk  Thu Mar  2 14:24:29 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Mar 2006 14:24:29 +0100
Subject: [Rd] problem with as.table (PR#8652)
In-Reply-To: <20060302122057.F17963FA48@slim.kubism.ku.dk>
References: <20060302122057.F17963FA48@slim.kubism.ku.dk>
Message-ID: <x2psl50yk2.fsf@viggo.kubism.ku.dk>

I.J.Wilson at ncl.ac.uk writes:

> # Your mailer is set to "none" (default on Windows),
> # hence we cannot send the bug report directly from R.
> # Please copy the bug report (after finishing it) to
> # your favorite email program and send it to
> #
> #       r-bugs at r-project.org
> #
> ######################################################
> 
> 
> There is a problem with as.table converting from a matrix with
> more than 26 rows (or columns) .
> 
> rows past 26 are set to <NA>.  This makes operations such as
> turning the data back into a data.frame difficult.
> 
> example causing problems:
> 
> b <-  as.table(matrix(1:60,ncol=2))
> as.integer(as.data.frame(b)[,1])

You can add dimnames to b or the original matrix for a workaround.

Probably the easiest fix is (in as.table.default) to replace

 LETTERS[seq(length = dim(x)[i])]

with 

 make.unique(LETTERS[seq(from=0, length = dim(x)[i]) %% 26 + 1], sep="")

The effect would be like

> make.unique(LETTERS[(0:59)%%26+1], sep="")
 [1] "A"  "B"  "C"  "D"  "E"  "F"  "G"  "H"  "I"  "J"  "K"  "L"  "M"  "N"  "O"
[16] "P"  "Q"  "R"  "S"  "T"  "U"  "V"  "W"  "X"  "Y"  "Z"  "A1" "B1" "C1" "D1"
[31] "E1" "F1" "G1" "H1" "I1" "J1" "K1" "L1" "M1" "N1" "O1" "P1" "Q1" "R1" "S1"
[46] "T1" "U1" "V1" "W1" "X1" "Y1" "Z1" "A2" "B2" "C2" "D2" "E2" "F2" "G2" "H2"

Users might prefer a different scheme, but wouldn't really deserve
it... (If they want otherwise, they can just set it themselves).



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ggrothendieck at gmail.com  Thu Mar  2 14:28:07 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Mar 2006 08:28:07 -0500
Subject: [Rd] '...' passed to both plot() and legend()
In-Reply-To: <001a01c63df8$65d6d680$0540210a@www.domain>
References: <001a01c63df8$65d6d680$0540210a@www.domain>
Message-ID: <971536df0603020528g4556774di3af2caa63365af6f@mail.gmail.com>

You can remove the legend names, assuming there are none
that are also plot names, like this (untested):

args <- list(...)
legnams <- intersect(names(args), names(formals(legend))]
do.call("plot", replace(args, legnams, NULL))


On 3/2/06, Dimitris Rizopoulos <dimitris.rizopoulos at med.kuleuven.be> wrote:
> Dear R-devels,
>
> I'd like to create a plot method for a class of objects that passes
> the '...' argument to both plot() and legend(), e.g.,
>
> x <- list(data = rnorm(1000))
> class(x) <- "foo"
> plot.foo <- function(x, legend = FALSE, cx = "topright", cy = NULL,
> ...){
>    dx <- sort(x$data)
>    plot(dx, dnorm(dx), type = "l", ...)
>    if (legend)
>        legend(cx, cy, "Gaussian density", bty = "n", ...)
>    invisible()
> }
> #####################
> plot(x)
> plot(x, legend = TRUE, cex = 1.1)
>
>
> However, and as expected, if I use an argument of plot() that is not
> an argument of legend() an error occurs, e.g.,
>
> plot(x, legend = TRUE, cex.lab = 1.1)
>
>
> Is there any (efficient and appropriate) way that I could use the
> '...' argument in this case?
>
> > version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
>
>
> Thanks in advance for any hints,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://www.med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar  2 14:51:08 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 02 Mar 2006 13:51:08 +0000
Subject: [Rd] minor oddity in pdf() help page
In-Reply-To: <4406F168.9080605@jhsph.edu>
References: <4406F168.9080605@jhsph.edu>
Message-ID: <4406F84C.7020306@cimr.cam.ac.uk>

Roger D. Peng wrote:
> The following paragraph from ?pdf struck me as a bit odd:
> 
>       'pdf' writes uncompressed PDF.  It is primarily intended for
>       producing PDF graphics for inclusion in other documents, and
>       PDF-includers such as 'pdftex' are usually able to handle
>       compression.
> 
> Should that be "...and PDF-includers such as 'pdftex' are usually _un_able to 
> handle compression" ?

Hmm, I think the documentation is correct but incomplete - pdftex *can*
handle compression, but compression is not implemented in R's pdf
output device. So it should say:

"... PDF-includers such as 'pdftex' are usually able to handle
compression, but R's pdf device does not utilise that feature of pdf."

(I have checked a pdf generated by R, and it doesn't compress, and I was 
using pdflatex this morning to include a compressed pdf, so both
parts are correct).

There is a caveat: the PDF specs (and the postscript language standard)
actually defines a few stream compression schemes - LZW and deflate
are two I know of from the top of my head, I think there are more.
But LZW used to be tangled up with the Unisys patent until recently
when the patent expired, so most open-source softwares won't do
it. deflate is implemented in zlib and ghostscript-written pdf
usually have stream compression on. i.e. For some purposes such
as getting smaller pdf's, it may be better to output from R
postscript and use ghostscript to do ps2pdf rather than doing
it directly from R, and to be pedantic, pdftex can only handle
deflate encoded compression, AFAIK, for the reason I outlined above,
but it is sufficient for most purposes, since most tools cannot
generate LZW-compressed pdf's.

HTL


From ripley at stats.ox.ac.uk  Thu Mar  2 15:01:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Mar 2006 14:01:10 +0000 (GMT)
Subject: [Rd] minor oddity in pdf() help page
In-Reply-To: <4406F84C.7020306@cimr.cam.ac.uk>
References: <4406F168.9080605@jhsph.edu> <4406F84C.7020306@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0603021359190.27636@gannet.stats.ox.ac.uk>

No, it means what it actually says.

If you include R's PDF in another application, the latter will usually 
compress *if you asked the application for compressed PDF*.

On Thu, 2 Mar 2006, Hin-Tak Leung wrote:

> Roger D. Peng wrote:
>> The following paragraph from ?pdf struck me as a bit odd:
>>
>>       'pdf' writes uncompressed PDF.  It is primarily intended for
>>       producing PDF graphics for inclusion in other documents, and
>>       PDF-includers such as 'pdftex' are usually able to handle
>>       compression.
>>
>> Should that be "...and PDF-includers such as 'pdftex' are usually _un_able to
>> handle compression" ?
>
> Hmm, I think the documentation is correct but incomplete - pdftex *can*
> handle compression, but compression is not implemented in R's pdf
> output device. So it should say:
>
> "... PDF-includers such as 'pdftex' are usually able to handle
> compression, but R's pdf device does not utilise that feature of pdf."
>
> (I have checked a pdf generated by R, and it doesn't compress, and I was
> using pdflatex this morning to include a compressed pdf, so both
> parts are correct).
>
> There is a caveat: the PDF specs (and the postscript language standard)
> actually defines a few stream compression schemes - LZW and deflate
> are two I know of from the top of my head, I think there are more.
> But LZW used to be tangled up with the Unisys patent until recently
> when the patent expired, so most open-source softwares won't do
> it. deflate is implemented in zlib and ghostscript-written pdf
> usually have stream compression on. i.e. For some purposes such
> as getting smaller pdf's, it may be better to output from R
> postscript and use ghostscript to do ps2pdf rather than doing
> it directly from R, and to be pedantic, pdftex can only handle
> deflate encoded compression, AFAIK, for the reason I outlined above,
> but it is sufficient for most purposes, since most tools cannot
> generate LZW-compressed pdf's.
>
> HTL
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Thu Mar  2 15:12:00 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 02 Mar 2006 09:12:00 -0500
Subject: [Rd] minor oddity in pdf() help page
In-Reply-To: <Pine.LNX.4.64.0603021359190.27636@gannet.stats.ox.ac.uk>
References: <4406F168.9080605@jhsph.edu> <4406F84C.7020306@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0603021359190.27636@gannet.stats.ox.ac.uk>
Message-ID: <4406FD30.9050703@jhsph.edu>

Okay, it might be the early morning hour---when I read it a second time it made 
sense.

-roger

Prof Brian Ripley wrote:
> No, it means what it actually says.
> 
> If you include R's PDF in another application, the latter will usually 
> compress *if you asked the application for compressed PDF*.
> 
> On Thu, 2 Mar 2006, Hin-Tak Leung wrote:
> 
>> Roger D. Peng wrote:
>>> The following paragraph from ?pdf struck me as a bit odd:
>>>
>>>       'pdf' writes uncompressed PDF.  It is primarily intended for
>>>       producing PDF graphics for inclusion in other documents, and
>>>       PDF-includers such as 'pdftex' are usually able to handle
>>>       compression.
>>>
>>> Should that be "...and PDF-includers such as 'pdftex' are usually 
>>> _un_able to
>>> handle compression" ?
>>
>> Hmm, I think the documentation is correct but incomplete - pdftex *can*
>> handle compression, but compression is not implemented in R's pdf
>> output device. So it should say:
>>
>> "... PDF-includers such as 'pdftex' are usually able to handle
>> compression, but R's pdf device does not utilise that feature of pdf."
>>
>> (I have checked a pdf generated by R, and it doesn't compress, and I was
>> using pdflatex this morning to include a compressed pdf, so both
>> parts are correct).
>>
>> There is a caveat: the PDF specs (and the postscript language standard)
>> actually defines a few stream compression schemes - LZW and deflate
>> are two I know of from the top of my head, I think there are more.
>> But LZW used to be tangled up with the Unisys patent until recently
>> when the patent expired, so most open-source softwares won't do
>> it. deflate is implemented in zlib and ghostscript-written pdf
>> usually have stream compression on. i.e. For some purposes such
>> as getting smaller pdf's, it may be better to output from R
>> postscript and use ghostscript to do ps2pdf rather than doing
>> it directly from R, and to be pedantic, pdftex can only handle
>> deflate encoded compression, AFAIK, for the reason I outlined above,
>> but it is sufficient for most purposes, since most tools cannot
>> generate LZW-compressed pdf's.
>>
>> HTL
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar  2 16:51:40 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 02 Mar 2006 15:51:40 +0000
Subject: [Rd] minor oddity in pdf() help page
In-Reply-To: <Pine.LNX.4.64.0603021359190.27636@gannet.stats.ox.ac.uk>
References: <4406F168.9080605@jhsph.edu> <4406F84C.7020306@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0603021359190.27636@gannet.stats.ox.ac.uk>
Message-ID: <4407148C.2030904@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> No, it means what it actually says.
> 
> If you include R's PDF in another application, the latter will usually 
> compress *if you asked the application for compressed PDF*.

Hmm, no, I don't know about "another application", but pdftex
actually tries to insert the graphic/pdf/page objects in
the origin form if possible - I would have a word with the author
and consider that behavior buggy if pdftex modifies graphic
insertion unncessarily.

i.e. the default behavior of pdftex is such that anything it
generates such as the text content part will be compressed, but
any externally included pdf graphics (such as from R) is
preserved in their original form if possible.

Even if pdftex behaves as you outlined (which I doubt), the paragraph
probably can be reworded to a less ambiguous form as e.g. "PDF-includers 
such as 'pdftex' are usually able to generate compressed pdf from 
uncompressed input." .

> On Thu, 2 Mar 2006, Hin-Tak Leung wrote:
> 
>> Roger D. Peng wrote:
>>
>>> The following paragraph from ?pdf struck me as a bit odd:
>>>
>>>       'pdf' writes uncompressed PDF.  It is primarily intended for
>>>       producing PDF graphics for inclusion in other documents, and
>>>       PDF-includers such as 'pdftex' are usually able to handle
>>>       compression.
>>>
>>> Should that be "...and PDF-includers such as 'pdftex' are usually 
>>> _un_able to
>>> handle compression" ?
>>
>>
>> Hmm, I think the documentation is correct but incomplete - pdftex *can*
>> handle compression, but compression is not implemented in R's pdf
>> output device. So it should say:
>>
>> "... PDF-includers such as 'pdftex' are usually able to handle
>> compression, but R's pdf device does not utilise that feature of pdf."
>>
>> (I have checked a pdf generated by R, and it doesn't compress, and I was
>> using pdflatex this morning to include a compressed pdf, so both
>> parts are correct).
>>
>> There is a caveat: the PDF specs (and the postscript language standard)
>> actually defines a few stream compression schemes - LZW and deflate
>> are two I know of from the top of my head, I think there are more.
>> But LZW used to be tangled up with the Unisys patent until recently
>> when the patent expired, so most open-source softwares won't do
>> it. deflate is implemented in zlib and ghostscript-written pdf
>> usually have stream compression on. i.e. For some purposes such
>> as getting smaller pdf's, it may be better to output from R
>> postscript and use ghostscript to do ps2pdf rather than doing
>> it directly from R, and to be pedantic, pdftex can only handle
>> deflate encoded compression, AFAIK, for the reason I outlined above,
>> but it is sufficient for most purposes, since most tools cannot
>> generate LZW-compressed pdf's.
>>
>> HTL
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From murdoch at stats.uwo.ca  Thu Mar  2 17:19:47 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Mar 2006 11:19:47 -0500
Subject: [Rd] Named parameters in optim()
Message-ID: <44071B23.2000706@stats.uwo.ca>

If I name the elements of the vector of initial values passed to 
optim(), then it attaches the names to the final result, e.g.

 > f <- function(parms) (parms[1]-1)^2+(parms[2]-2)^2
 > optim(c(x=3,y=4), f)
$par
         x         y
0.9999635 2.0003241

$value
[1] 1.063637e-07

$counts
function gradient
       65       NA

$convergence
[1] 0

$message
NULL

However, the vector that gets passed to f doesn't have its names attached:

 > f <- function(parms) {
+  print(parms)
+  (parms["x"]-1)^2+(parms["y"]-2)^2
+ }
 > optim(c(x=3,y=4), f)
[1] 3 4
Error in optim(c(x = 3, y = 4), f) : function cannot be evaluated at 
initial parameters

Is this something that should be fixed, i.e. could it be fixed without 
making optim() substantially slower?  If not, it's at least something 
that should be documented.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Thu Mar  2 20:52:55 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Mar 2006 19:52:55 +0000 (GMT)
Subject: [Rd] Named parameters in optim()
In-Reply-To: <44071B23.2000706@stats.uwo.ca>
References: <44071B23.2000706@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0603021952390.29313@gannet.stats.ox.ac.uk>

I think the cost is small, and have just added this.

On Thu, 2 Mar 2006, Duncan Murdoch wrote:

> If I name the elements of the vector of initial values passed to
> optim(), then it attaches the names to the final result, e.g.
>
> > f <- function(parms) (parms[1]-1)^2+(parms[2]-2)^2
> > optim(c(x=3,y=4), f)
> $par
>         x         y
> 0.9999635 2.0003241
>
> $value
> [1] 1.063637e-07
>
> $counts
> function gradient
>       65       NA
>
> $convergence
> [1] 0
>
> $message
> NULL
>
> However, the vector that gets passed to f doesn't have its names attached:
>
> > f <- function(parms) {
> +  print(parms)
> +  (parms["x"]-1)^2+(parms["y"]-2)^2
> + }
> > optim(c(x=3,y=4), f)
> [1] 3 4
> Error in optim(c(x = 3, y = 4), f) : function cannot be evaluated at
> initial parameters
>
> Is this something that should be fixed, i.e. could it be fixed without
> making optim() substantially slower?  If not, it's at least something
> that should be documented.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Mar  2 21:01:06 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Mar 2006 15:01:06 -0500
Subject: [Rd] Named parameters in optim()
In-Reply-To: <Pine.LNX.4.64.0603021952390.29313@gannet.stats.ox.ac.uk>
References: <44071B23.2000706@stats.uwo.ca>
	<Pine.LNX.4.64.0603021952390.29313@gannet.stats.ox.ac.uk>
Message-ID: <44074F02.30702@stats.uwo.ca>

On 3/2/2006 2:52 PM, Prof Brian Ripley wrote:
> I think the cost is small, and have just added this.

Thank you!

Duncan Murdoch

> 
> On Thu, 2 Mar 2006, Duncan Murdoch wrote:
> 
>> If I name the elements of the vector of initial values passed to
>> optim(), then it attaches the names to the final result, e.g.
>>
>> > f <- function(parms) (parms[1]-1)^2+(parms[2]-2)^2
>> > optim(c(x=3,y=4), f)
>> $par
>>         x         y
>> 0.9999635 2.0003241
>>
>> $value
>> [1] 1.063637e-07
>>
>> $counts
>> function gradient
>>       65       NA
>>
>> $convergence
>> [1] 0
>>
>> $message
>> NULL
>>
>> However, the vector that gets passed to f doesn't have its names attached:
>>
>> > f <- function(parms) {
>> +  print(parms)
>> +  (parms["x"]-1)^2+(parms["y"]-2)^2
>> + }
>> > optim(c(x=3,y=4), f)
>> [1] 3 4
>> Error in optim(c(x = 3, y = 4), f) : function cannot be evaluated at
>> initial parameters
>>
>> Is this something that should be fixed, i.e. could it be fixed without
>> making optim() substantially slower?  If not, it's at least something
>> that should be documented.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From ales.ziberna at gmail.com  Fri Mar  3 12:28:12 2006
From: ales.ziberna at gmail.com (=?ISO-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Fri, 03 Mar 2006 12:28:12 +0100
Subject: [Rd] Problem with creating links ("see also" section) in help files.
Message-ID: <4408284C.5020908@gmail.com>

A link in one of my help files does not work. I have in this help file:
\seealso{\code{\link{crit.fun}}, \code{\link{opt.par}}, 
\code{\link{opt.random.par}}, \code{\link{opt.these.par}}, 
\code{\link{nkpartitions}}, \code{\link{nkpar}}, 
\code{\link{plot.check.these.par}} }

Everything in one row, the last link does not work. In another help 
file, I have:
\name{plot.mat}
\alias{plot.mat}
\alias{plot.crit.fun}
\alias{plot.opt.par}
\alias{plot.opt.par.mode}
\alias{plot.opt.more.par}
\alias{plot.opt.more.par.mode}
\alias{plot.check.these.par}

The last alias should corresponds to the link that does not work.

This is also produces a massage when building a binary package or 
installing a package:
  check.these.par                   text    html    latex   example chm
     missing link(s):  plot.check.these.par

Any ideas?

Best regards and thanks in advance for any suggestions,
Ales Ziberna


From murdoch at stats.uwo.ca  Fri Mar  3 13:30:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 03 Mar 2006 07:30:20 -0500
Subject: [Rd] Problem with creating links ("see also" section) in help
 files.
In-Reply-To: <4408284C.5020908@gmail.com>
References: <4408284C.5020908@gmail.com>
Message-ID: <440836DC.2070907@stats.uwo.ca>

On 3/3/2006 6:28 AM, Ale? ?iberna wrote:
> A link in one of my help files does not work. I have in this help file:
> \seealso{\code{\link{crit.fun}}, \code{\link{opt.par}}, 
> \code{\link{opt.random.par}}, \code{\link{opt.these.par}}, 
> \code{\link{nkpartitions}}, \code{\link{nkpar}}, 
> \code{\link{plot.check.these.par}} }
> 
> Everything in one row, the last link does not work. In another help 
> file, I have:
> \name{plot.mat}
> \alias{plot.mat}
> \alias{plot.crit.fun}
> \alias{plot.opt.par}
> \alias{plot.opt.par.mode}
> \alias{plot.opt.more.par}
> \alias{plot.opt.more.par.mode}
> \alias{plot.check.these.par}
> 
> The last alias should corresponds to the link that does not work.
> 
> This is also produces a massage when building a binary package or 
> installing a package:
>   check.these.par                   text    html    latex   example chm
>      missing link(s):  plot.check.these.par
> 
> Any ideas?

Based on the error message and the symptom that the link doesn't work, 
I'd assume that the alias isn't being recognized.  You could confirm 
this by seeing whether ?plot.check.these.par works in the R console.

Do any of the other aliases in that file work?  Maybe there's something 
wrong with the whole file.

Duncan Murdoch


From bates at stat.wisc.edu  Fri Mar  3 16:45:11 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Mar 2006 09:45:11 -0600
Subject: [Rd] Peculiar timing result
Message-ID: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>

I have been timing a particular model fit using lmer on several
different computers and came up with a peculiar result - the model fit
is considerably slower on a dual-core Athlon 64 using Goto's
multithreaded BLAS than on a single-core processor.

Here is the timing on a single-core Athlon 64 3000+ running under
today's R-devel with version 0.995-5 of the Matrix package.

> library(Matrix)
> data(star, package = 'mlmRev')
> system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star, control = list(nit=0,grad=0,msV=1)))
  0      241720.:  1.16440 0.335239  0.00000  1.78732 0.867209 0.382318  0.00000
  1      239722.:  1.94952 5.00000e-10 0.00933767  1.65999 0.858003
0.341520 0.00908757
  2      239580.:  1.95924 0.0884059 0.00933767  1.65308 0.857487
0.339296 0.00954718
  3      239215.:  2.60877 0.0765848 0.0177699  1.45739 0.843562
0.275100 0.0236849
  4      239204.:  2.62582 0.106670 0.0239698  1.41976 0.841086
0.261033 0.0267073
  5      239176.:  2.63149 0.0787924 0.0367185  1.37952 0.838527
0.245076 0.0301134
  6      239141.:  2.64949 0.108534 0.0594586  1.28846 0.832543
0.208404 0.0375456
  7      239049.:  2.64794 0.0789214 0.121782  1.10436 0.819711
0.126101 0.0524965
  8      239004.:  2.66044 0.117957 0.181505 0.932202 0.798982
0.0718116 0.0628958
  9      238944.:  2.66310 0.0819653 0.334477 0.631735 0.740855
0.258359 0.0806590
 10      238893.:  2.72626 0.0975205 0.653432 0.703912 0.666067
0.109922 0.201809
 11      238892.:  2.74381 0.111146 0.666155 0.693544 0.662000 0.104060 0.207591
 12      238888.:  2.75052 0.0990238 0.689199 0.694588 0.655781
0.106516 0.216460
 13      238861.:  2.80325 0.126935  1.05912 0.733914 0.556162 0.159296 0.360938
 14      238832.:  2.82656 0.117617  1.59471 0.607916 0.441371
0.0749944 0.976142
 15      238811.:  2.87350 0.136332  1.59046 0.653141 0.353763 0.226061  1.79285
 16      238810.:  2.87663 0.125135  1.58992 0.656808 0.352605 0.220488  1.79282
 17      238806.:  2.89342 0.141551  1.58607 0.676523 0.344212 0.181833  1.79268
 18      238804.:  2.90080 0.125137  1.56624 0.682921 0.261295 0.180598  1.74325
 19      238802.:  2.91950 0.128569  1.56836 0.680436 0.336051 0.159940  1.80400
 20      238801.:  2.92795 0.134762  1.56597 0.685121 0.331695 0.145547  1.80414
 21      238801.:  2.93741 0.125667  1.56139 0.687827 0.332700 0.138854  1.81495
 22      238800.:  2.94588 0.131757  1.55294 0.687909 0.330414 0.137834  1.82826
 23      238799.:  2.96867 0.129716  1.52943 0.688678 0.323171 0.139912  1.84615
 24      238799.:  2.98994 0.133378  1.52188 0.700038 0.337387 0.131403  1.77623
 25      238799.:  3.00312 0.135308  1.51475 0.697550 0.311750 0.145683  1.78037
 26      238799.:  3.00461 0.129920  1.51083 0.697666 0.306722 0.138745  1.81188
 27      238799.:  3.00504 0.134882  1.50539 0.696745 0.302949 0.135897  1.84405
 28      238799.:  3.00422 0.134013  1.47947 0.698115 0.303243 0.133806  1.86486
 29      238799.:  3.00819 0.134378  1.48185 0.701871 0.307097 0.134637  1.84996
 30      238799.:  3.01313 0.134279  1.49098 0.702883 0.304788 0.133682  1.86254
 31      238799.:  3.01291 0.134253  1.49060 0.701818 0.303155 0.133771  1.84613
 32      238799.:  3.01142 0.134314  1.48921 0.701782 0.303589 0.134439  1.84653
 33      238799.:  3.01174 0.134315  1.48926 0.701641 0.304120 0.134145  1.84635
 34      238799.:  3.01175 0.134304  1.48942 0.701740 0.303762 0.134185  1.84649
 35      238799.:  3.01173 0.134307  1.48937 0.701724 0.303809 0.134206  1.84647
[1] 43.10  3.78 48.41  0.00  0.00


(If you run the timing yourself and don't want to see the iteration
output, take the msV=1 out of the control list.  I keep it in there so
I can monitor the progress.)

If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
the same version of R, BLAS and Matrix package, the timing ends up
with something like

90 140 235 0 0

I do see that the multithreading is working on a calculation that is
essentially BLAS-bound such as

> mm <- Matrix(rnorm(1e6), nc = 1e3)
> system.time(crossprod(mm))
[1] 0.57 0.02 0.60 0.00 0.00

On the X2 processor it still takes about 0.6 seconds user time but
only 0.3 seconds elapsed time when the machine is otherwise idle and
both cores are available for the calculation.

Any suggestions why the dual-core processor is so much slower than the
single core processor?

By the way, I would be interested in accumulating timings of this
model fit on other systems.  If you do time it please send me
(off-list) a summary of the version of R, version of the accelerated
BLAS if you use them, processor speed and configuration (i.e.
multiprocessor, multicore, etc.) and, if you know it, memory speed.

This is an example of a complex multilevel model with crossed grouping
factors fit to a relatively large (30000 observations on 10000
students, 1400 teachers and 80 schools) data set.


From pgilbert at bank-banque-canada.ca  Fri Mar  3 17:36:13 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 03 Mar 2006 11:36:13 -0500
Subject: [Rd] Peculiar timing result
In-Reply-To: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
References: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
Message-ID: <4408707D.5030706@bank-banque-canada.ca>

Doug

This is probably not your reason, but I am finding my dual core Athlon 
64 is much slower running 64 bit Linux and R than it was running 32 bit 
Linux and R. All the programs are bigger.  (Some, like the clock applet, 
are a lot bigger for no obvious reason.)  The difference is enough to 
put my meager 1GB machine into swapping much more, with the result that 
it is a lot slower.

Paul

Douglas Bates wrote:

>I have been timing a particular model fit using lmer on several
>different computers and came up with a peculiar result - the model fit
>is considerably slower on a dual-core Athlon 64 using Goto's
>multithreaded BLAS than on a single-core processor.
>
>Here is the timing on a single-core Athlon 64 3000+ running under
>today's R-devel with version 0.995-5 of the Matrix package.
>
>  
>
>>library(Matrix)
>>data(star, package = 'mlmRev')
>>system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star, control = list(nit=0,grad=0,msV=1)))
>>    
>>
>  0      241720.:  1.16440 0.335239  0.00000  1.78732 0.867209 0.382318  0.00000
>  1      239722.:  1.94952 5.00000e-10 0.00933767  1.65999 0.858003
>0.341520 0.00908757
>  2      239580.:  1.95924 0.0884059 0.00933767  1.65308 0.857487
>0.339296 0.00954718
>  3      239215.:  2.60877 0.0765848 0.0177699  1.45739 0.843562
>0.275100 0.0236849
>  4      239204.:  2.62582 0.106670 0.0239698  1.41976 0.841086
>0.261033 0.0267073
>  5      239176.:  2.63149 0.0787924 0.0367185  1.37952 0.838527
>0.245076 0.0301134
>  6      239141.:  2.64949 0.108534 0.0594586  1.28846 0.832543
>0.208404 0.0375456
>  7      239049.:  2.64794 0.0789214 0.121782  1.10436 0.819711
>0.126101 0.0524965
>  8      239004.:  2.66044 0.117957 0.181505 0.932202 0.798982
>0.0718116 0.0628958
>  9      238944.:  2.66310 0.0819653 0.334477 0.631735 0.740855
>0.258359 0.0806590
> 10      238893.:  2.72626 0.0975205 0.653432 0.703912 0.666067
>0.109922 0.201809
> 11      238892.:  2.74381 0.111146 0.666155 0.693544 0.662000 0.104060 0.207591
> 12      238888.:  2.75052 0.0990238 0.689199 0.694588 0.655781
>0.106516 0.216460
> 13      238861.:  2.80325 0.126935  1.05912 0.733914 0.556162 0.159296 0.360938
> 14      238832.:  2.82656 0.117617  1.59471 0.607916 0.441371
>0.0749944 0.976142
> 15      238811.:  2.87350 0.136332  1.59046 0.653141 0.353763 0.226061  1.79285
> 16      238810.:  2.87663 0.125135  1.58992 0.656808 0.352605 0.220488  1.79282
> 17      238806.:  2.89342 0.141551  1.58607 0.676523 0.344212 0.181833  1.79268
> 18      238804.:  2.90080 0.125137  1.56624 0.682921 0.261295 0.180598  1.74325
> 19      238802.:  2.91950 0.128569  1.56836 0.680436 0.336051 0.159940  1.80400
> 20      238801.:  2.92795 0.134762  1.56597 0.685121 0.331695 0.145547  1.80414
> 21      238801.:  2.93741 0.125667  1.56139 0.687827 0.332700 0.138854  1.81495
> 22      238800.:  2.94588 0.131757  1.55294 0.687909 0.330414 0.137834  1.82826
> 23      238799.:  2.96867 0.129716  1.52943 0.688678 0.323171 0.139912  1.84615
> 24      238799.:  2.98994 0.133378  1.52188 0.700038 0.337387 0.131403  1.77623
> 25      238799.:  3.00312 0.135308  1.51475 0.697550 0.311750 0.145683  1.78037
> 26      238799.:  3.00461 0.129920  1.51083 0.697666 0.306722 0.138745  1.81188
> 27      238799.:  3.00504 0.134882  1.50539 0.696745 0.302949 0.135897  1.84405
> 28      238799.:  3.00422 0.134013  1.47947 0.698115 0.303243 0.133806  1.86486
> 29      238799.:  3.00819 0.134378  1.48185 0.701871 0.307097 0.134637  1.84996
> 30      238799.:  3.01313 0.134279  1.49098 0.702883 0.304788 0.133682  1.86254
> 31      238799.:  3.01291 0.134253  1.49060 0.701818 0.303155 0.133771  1.84613
> 32      238799.:  3.01142 0.134314  1.48921 0.701782 0.303589 0.134439  1.84653
> 33      238799.:  3.01174 0.134315  1.48926 0.701641 0.304120 0.134145  1.84635
> 34      238799.:  3.01175 0.134304  1.48942 0.701740 0.303762 0.134185  1.84649
> 35      238799.:  3.01173 0.134307  1.48937 0.701724 0.303809 0.134206  1.84647
>[1] 43.10  3.78 48.41  0.00  0.00
>
>
>(If you run the timing yourself and don't want to see the iteration
>output, take the msV=1 out of the control list.  I keep it in there so
>I can monitor the progress.)
>
>If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
>the same version of R, BLAS and Matrix package, the timing ends up
>with something like
>
>90 140 235 0 0
>
>I do see that the multithreading is working on a calculation that is
>essentially BLAS-bound such as
>
>  
>
>>mm <- Matrix(rnorm(1e6), nc = 1e3)
>>system.time(crossprod(mm))
>>    
>>
>[1] 0.57 0.02 0.60 0.00 0.00
>
>On the X2 processor it still takes about 0.6 seconds user time but
>only 0.3 seconds elapsed time when the machine is otherwise idle and
>both cores are available for the calculation.
>
>Any suggestions why the dual-core processor is so much slower than the
>single core processor?
>
>By the way, I would be interested in accumulating timings of this
>model fit on other systems.  If you do time it please send me
>(off-list) a summary of the version of R, version of the accelerated
>BLAS if you use them, processor speed and configuration (i.e.
>multiprocessor, multicore, etc.) and, if you know it, memory speed.
>
>This is an example of a complex multilevel model with crossed grouping
>factors fit to a relatively large (30000 observations on 10000
>students, 1400 teachers and 80 schools) data set.
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>


From jaomatos at gmail.com  Fri Mar  3 18:18:07 2006
From: jaomatos at gmail.com (=?ISO-8859-1?Q?Jos=E9_Matos?=)
Date: Fri, 3 Mar 2006 17:18:07 +0000
Subject: [Rd] script to create rpm spec files from CRAN packages
Message-ID: <9fd2371d0603030918g32151e5fs@mail.gmail.com>

Hi,
   I hope this is the right list to do this announcement.

  In order to facilitate my work submiting R packages to Fedora Extras
I have create a python script that takes a CRAN package (tar.gz file)
and from there it prints a first draft for a spec file.

  This script follows the Fedora conventions for rpms but I hope that
with small changes this can be helpfull for other people.

        The script (released under GPL2) can be found here:
http://www.fc.up.pt/pessoas/jamatos/R/cran2rpmspec

        All comments are welcome. :-)
--
Jos? Matos


From andy_liaw at merck.com  Fri Mar  3 19:18:02 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 3 Mar 2006 13:18:02 -0500
Subject: [Rd] Peculiar timing result
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8B8@usctmx1106.merck.com>

Paul,

I think what you're seeing is the performance gap between 64-bit binary and
32-bit binary on x86_64.  I believe Prof. Ripley had mentioned this several
times in the past.

I do remember back when I was playing with optimized BLAS with R on 32-bit
Linux that I've seen something similar to what Prof. Bates is seeing, that
the one that uses threaded BLAS took longer the than non-threaded one (on
dual Xeon boxes).  I never dug into it more, though.

Andy

From: Paul Gilbert
> 
> Doug
> 
> This is probably not your reason, but I am finding my dual 
> core Athlon 
> 64 is much slower running 64 bit Linux and R than it was 
> running 32 bit 
> Linux and R. All the programs are bigger.  (Some, like the 
> clock applet, 
> are a lot bigger for no obvious reason.)  The difference is enough to 
> put my meager 1GB machine into swapping much more, with the 
> result that 
> it is a lot slower.
> 
> Paul
> 
> Douglas Bates wrote:
> 
> >I have been timing a particular model fit using lmer on several 
> >different computers and came up with a peculiar result - the 
> model fit 
> >is considerably slower on a dual-core Athlon 64 using Goto's 
> >multithreaded BLAS than on a single-core processor.
> >
> >Here is the timing on a single-core Athlon 64 3000+ running under 
> >today's R-devel with version 0.995-5 of the Matrix package.
> >
> >  
> >
> >>library(Matrix)
> >>data(star, package = 'mlmRev')
> >>system.time(fm1 <- 
> >>lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), 
> star, control = list(nit=0,grad=0,msV=1)))
> >>    
> >>
> >  0      241720.:  1.16440 0.335239  0.00000  1.78732 
> 0.867209 0.382318  0.00000
> >  1      239722.:  1.94952 5.00000e-10 0.00933767  1.65999 0.858003
> >0.341520 0.00908757
> >  2      239580.:  1.95924 0.0884059 0.00933767  1.65308 0.857487
> >0.339296 0.00954718
> >  3      239215.:  2.60877 0.0765848 0.0177699  1.45739 0.843562
> >0.275100 0.0236849
> >  4      239204.:  2.62582 0.106670 0.0239698  1.41976 0.841086
> >0.261033 0.0267073
> >  5      239176.:  2.63149 0.0787924 0.0367185  1.37952 0.838527
> >0.245076 0.0301134
> >  6      239141.:  2.64949 0.108534 0.0594586  1.28846 0.832543
> >0.208404 0.0375456
> >  7      239049.:  2.64794 0.0789214 0.121782  1.10436 0.819711
> >0.126101 0.0524965
> >  8      239004.:  2.66044 0.117957 0.181505 0.932202 0.798982
> >0.0718116 0.0628958
> >  9      238944.:  2.66310 0.0819653 0.334477 0.631735 0.740855
> >0.258359 0.0806590
> > 10      238893.:  2.72626 0.0975205 0.653432 0.703912 0.666067
> >0.109922 0.201809
> > 11      238892.:  2.74381 0.111146 0.666155 0.693544 
> 0.662000 0.104060 0.207591
> > 12      238888.:  2.75052 0.0990238 0.689199 0.694588 0.655781
> >0.106516 0.216460
> > 13      238861.:  2.80325 0.126935  1.05912 0.733914 
> 0.556162 0.159296 0.360938
> > 14      238832.:  2.82656 0.117617  1.59471 0.607916 0.441371
> >0.0749944 0.976142
> > 15      238811.:  2.87350 0.136332  1.59046 0.653141 
> 0.353763 0.226061  1.79285
> > 16      238810.:  2.87663 0.125135  1.58992 0.656808 
> 0.352605 0.220488  1.79282
> > 17      238806.:  2.89342 0.141551  1.58607 0.676523 
> 0.344212 0.181833  1.79268
> > 18      238804.:  2.90080 0.125137  1.56624 0.682921 
> 0.261295 0.180598  1.74325
> > 19      238802.:  2.91950 0.128569  1.56836 0.680436 
> 0.336051 0.159940  1.80400
> > 20      238801.:  2.92795 0.134762  1.56597 0.685121 
> 0.331695 0.145547  1.80414
> > 21      238801.:  2.93741 0.125667  1.56139 0.687827 
> 0.332700 0.138854  1.81495
> > 22      238800.:  2.94588 0.131757  1.55294 0.687909 
> 0.330414 0.137834  1.82826
> > 23      238799.:  2.96867 0.129716  1.52943 0.688678 
> 0.323171 0.139912  1.84615
> > 24      238799.:  2.98994 0.133378  1.52188 0.700038 
> 0.337387 0.131403  1.77623
> > 25      238799.:  3.00312 0.135308  1.51475 0.697550 
> 0.311750 0.145683  1.78037
> > 26      238799.:  3.00461 0.129920  1.51083 0.697666 
> 0.306722 0.138745  1.81188
> > 27      238799.:  3.00504 0.134882  1.50539 0.696745 
> 0.302949 0.135897  1.84405
> > 28      238799.:  3.00422 0.134013  1.47947 0.698115 
> 0.303243 0.133806  1.86486
> > 29      238799.:  3.00819 0.134378  1.48185 0.701871 
> 0.307097 0.134637  1.84996
> > 30      238799.:  3.01313 0.134279  1.49098 0.702883 
> 0.304788 0.133682  1.86254
> > 31      238799.:  3.01291 0.134253  1.49060 0.701818 
> 0.303155 0.133771  1.84613
> > 32      238799.:  3.01142 0.134314  1.48921 0.701782 
> 0.303589 0.134439  1.84653
> > 33      238799.:  3.01174 0.134315  1.48926 0.701641 
> 0.304120 0.134145  1.84635
> > 34      238799.:  3.01175 0.134304  1.48942 0.701740 
> 0.303762 0.134185  1.84649
> > 35      238799.:  3.01173 0.134307  1.48937 0.701724 
> 0.303809 0.134206  1.84647
> >[1] 43.10  3.78 48.41  0.00  0.00
> >
> >
> >(If you run the timing yourself and don't want to see the iteration 
> >output, take the msV=1 out of the control list.  I keep it 
> in there so 
> >I can monitor the progress.)
> >
> >If I time the same model fit on a dual-core Athlon 64 X2 
> 3800+ with the 
> >same version of R, BLAS and Matrix package, the timing ends up with 
> >something like
> >
> >90 140 235 0 0
> >
> >I do see that the multithreading is working on a calculation that is 
> >essentially BLAS-bound such as
> >
> >  
> >
> >>mm <- Matrix(rnorm(1e6), nc = 1e3)
> >>system.time(crossprod(mm))
> >>    
> >>
> >[1] 0.57 0.02 0.60 0.00 0.00
> >
> >On the X2 processor it still takes about 0.6 seconds user 
> time but only 
> >0.3 seconds elapsed time when the machine is otherwise idle and both 
> >cores are available for the calculation.
> >
> >Any suggestions why the dual-core processor is so much 
> slower than the 
> >single core processor?
> >
> >By the way, I would be interested in accumulating timings of 
> this model 
> >fit on other systems.  If you do time it please send me
> >(off-list) a summary of the version of R, version of the accelerated 
> >BLAS if you use them, processor speed and configuration (i.e. 
> >multiprocessor, multicore, etc.) and, if you know it, memory speed.
> >
> >This is an example of a complex multilevel model with 
> crossed grouping 
> >factors fit to a relatively large (30000 observations on 10000 
> >students, 1400 teachers and 80 schools) data set.
> >
> >______________________________________________
> >R-devel at r-project.org mailing list 
> >https://stat.ethz.ch/mailman/listinfo/r-devel
> >  
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Fri Mar  3 19:18:44 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Mar 2006 18:18:44 +0000 (GMT)
Subject: [Rd] Peculiar timing result
In-Reply-To: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
References: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603031749580.21096@gannet.stats.ox.ac.uk>

On Fri, 3 Mar 2006, Douglas Bates wrote:

> I have been timing a particular model fit using lmer on several
> different computers and came up with a peculiar result - the model fit
> is considerably slower on a dual-core Athlon 64 using Goto's
> multithreaded BLAS than on a single-core processor.

Is there a Goto BLAS tuned for that chip?  I can only see one tuned for an 
(unspecified) Opteron.  L1 and L2 cache sizes do sometimes matter a lot 
for tuned BLAS, and (according to the AMD site I just looked up) the X2 
3800+ only has a 512Kb per core L2 cache.  Opterons have a 1Mb L2 cache.

Also, the very large system time seen in the dual-core run is typical of 
what I see when pthreads is not working right, and I suggest you try a 
limit of one thread (see the R-admin manual).  On our dual-processor 
Opteron 248 that ran in 44 secs instead of 328.

> Here is the timing on a single-core Athlon 64 3000+ running under
> today's R-devel with version 0.995-5 of the Matrix package.
>
>> library(Matrix)
>> data(star, package = 'mlmRev')
>> system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star,
control = list(nit=0,grad=0,msV=1)))
> [1] 43.10  3.78 48.41  0.00  0.00
>
>
> (If you run the timing yourself and don't want to see the iteration
> output, take the msV=1 out of the control list.  I keep it in there so
> I can monitor the progress.)
>
> If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
> the same version of R, BLAS and Matrix package, the timing ends up
> with something like
>
> 90 140 235 0 0
....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Fri Mar  3 19:26:32 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 Mar 2006 12:26:32 -0600
Subject: [Rd] Peculiar timing result
In-Reply-To: <4408707D.5030706@bank-banque-canada.ca>
References: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
	<4408707D.5030706@bank-banque-canada.ca>
Message-ID: <40e66e0b0603031026x52865f77w3375d23c8a417c98@mail.gmail.com>

I don't think this calculation is memory-bound at all and I would be
surprised if changing to a 32-bit environment would change things.  I
do have a 32-bit chroot environment on these machines (needed for
things like wine and acroread) so I'll try that out but I think I will
need to use Atlas as the accelerated BLAS rather than Goto's BLAS.  I
imagine the Opteron/Athlon 64 version of Goto's BLAS assumes a 64-bit
environment.

On 3/3/06, Paul Gilbert <pgilbert at bank-banque-canada.ca> wrote:
> Doug
>
> This is probably not your reason, but I am finding my dual core Athlon
> 64 is much slower running 64 bit Linux and R than it was running 32 bit
> Linux and R. All the programs are bigger.  (Some, like the clock applet,
> are a lot bigger for no obvious reason.)  The difference is enough to
> put my meager 1GB machine into swapping much more, with the result that
> it is a lot slower.
>
> Paul
>
> Douglas Bates wrote:
>
> >I have been timing a particular model fit using lmer on several
> >different computers and came up with a peculiar result - the model fit
> >is considerably slower on a dual-core Athlon 64 using Goto's
> >multithreaded BLAS than on a single-core processor.
> >
> >Here is the timing on a single-core Athlon 64 3000+ running under
> >today's R-devel with version 0.995-5 of the Matrix package.
> >
> >
> >
> >>library(Matrix)
> >>data(star, package = 'mlmRev')
> >>system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star, control = list(nit=0,grad=0,msV=1)))
> >>
> >>
> >  0      241720.:  1.16440 0.335239  0.00000  1.78732 0.867209 0.382318  0.00000
> >  1      239722.:  1.94952 5.00000e-10 0.00933767  1.65999 0.858003
> >0.341520 0.00908757
> >  2      239580.:  1.95924 0.0884059 0.00933767  1.65308 0.857487
> >0.339296 0.00954718
> >  3      239215.:  2.60877 0.0765848 0.0177699  1.45739 0.843562
> >0.275100 0.0236849
> >  4      239204.:  2.62582 0.106670 0.0239698  1.41976 0.841086
> >0.261033 0.0267073
> >  5      239176.:  2.63149 0.0787924 0.0367185  1.37952 0.838527
> >0.245076 0.0301134
> >  6      239141.:  2.64949 0.108534 0.0594586  1.28846 0.832543
> >0.208404 0.0375456
> >  7      239049.:  2.64794 0.0789214 0.121782  1.10436 0.819711
> >0.126101 0.0524965
> >  8      239004.:  2.66044 0.117957 0.181505 0.932202 0.798982
> >0.0718116 0.0628958
> >  9      238944.:  2.66310 0.0819653 0.334477 0.631735 0.740855
> >0.258359 0.0806590
> > 10      238893.:  2.72626 0.0975205 0.653432 0.703912 0.666067
> >0.109922 0.201809
> > 11      238892.:  2.74381 0.111146 0.666155 0.693544 0.662000 0.104060 0.207591
> > 12      238888.:  2.75052 0.0990238 0.689199 0.694588 0.655781
> >0.106516 0.216460
> > 13      238861.:  2.80325 0.126935  1.05912 0.733914 0.556162 0.159296 0.360938
> > 14      238832.:  2.82656 0.117617  1.59471 0.607916 0.441371
> >0.0749944 0.976142
> > 15      238811.:  2.87350 0.136332  1.59046 0.653141 0.353763 0.226061  1.79285
> > 16      238810.:  2.87663 0.125135  1.58992 0.656808 0.352605 0.220488  1.79282
> > 17      238806.:  2.89342 0.141551  1.58607 0.676523 0.344212 0.181833  1.79268
> > 18      238804.:  2.90080 0.125137  1.56624 0.682921 0.261295 0.180598  1.74325
> > 19      238802.:  2.91950 0.128569  1.56836 0.680436 0.336051 0.159940  1.80400
> > 20      238801.:  2.92795 0.134762  1.56597 0.685121 0.331695 0.145547  1.80414
> > 21      238801.:  2.93741 0.125667  1.56139 0.687827 0.332700 0.138854  1.81495
> > 22      238800.:  2.94588 0.131757  1.55294 0.687909 0.330414 0.137834  1.82826
> > 23      238799.:  2.96867 0.129716  1.52943 0.688678 0.323171 0.139912  1.84615
> > 24      238799.:  2.98994 0.133378  1.52188 0.700038 0.337387 0.131403  1.77623
> > 25      238799.:  3.00312 0.135308  1.51475 0.697550 0.311750 0.145683  1.78037
> > 26      238799.:  3.00461 0.129920  1.51083 0.697666 0.306722 0.138745  1.81188
> > 27      238799.:  3.00504 0.134882  1.50539 0.696745 0.302949 0.135897  1.84405
> > 28      238799.:  3.00422 0.134013  1.47947 0.698115 0.303243 0.133806  1.86486
> > 29      238799.:  3.00819 0.134378  1.48185 0.701871 0.307097 0.134637  1.84996
> > 30      238799.:  3.01313 0.134279  1.49098 0.702883 0.304788 0.133682  1.86254
> > 31      238799.:  3.01291 0.134253  1.49060 0.701818 0.303155 0.133771  1.84613
> > 32      238799.:  3.01142 0.134314  1.48921 0.701782 0.303589 0.134439  1.84653
> > 33      238799.:  3.01174 0.134315  1.48926 0.701641 0.304120 0.134145  1.84635
> > 34      238799.:  3.01175 0.134304  1.48942 0.701740 0.303762 0.134185  1.84649
> > 35      238799.:  3.01173 0.134307  1.48937 0.701724 0.303809 0.134206  1.84647
> >[1] 43.10  3.78 48.41  0.00  0.00
> >
> >
> >(If you run the timing yourself and don't want to see the iteration
> >output, take the msV=1 out of the control list.  I keep it in there so
> >I can monitor the progress.)
> >
> >If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
> >the same version of R, BLAS and Matrix package, the timing ends up
> >with something like
> >
> >90 140 235 0 0
> >
> >I do see that the multithreading is working on a calculation that is
> >essentially BLAS-bound such as
> >
> >
> >
> >>mm <- Matrix(rnorm(1e6), nc = 1e3)
> >>system.time(crossprod(mm))
> >>
> >>
> >[1] 0.57 0.02 0.60 0.00 0.00
> >
> >On the X2 processor it still takes about 0.6 seconds user time but
> >only 0.3 seconds elapsed time when the machine is otherwise idle and
> >both cores are available for the calculation.
> >
> >Any suggestions why the dual-core processor is so much slower than the
> >single core processor?
> >
> >By the way, I would be interested in accumulating timings of this
> >model fit on other systems.  If you do time it please send me
> >(off-list) a summary of the version of R, version of the accelerated
> >BLAS if you use them, processor speed and configuration (i.e.
> >multiprocessor, multicore, etc.) and, if you know it, memory speed.
> >
> >This is an example of a complex multilevel model with crossed grouping
> >factors fit to a relatively large (30000 observations on 10000
> >students, 1400 teachers and 80 schools) data set.
> >
> >______________________________________________
> >R-devel at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>


From aziz.chaouch at gmail.com  Fri Mar  3 19:55:00 2006
From: aziz.chaouch at gmail.com (aziz.chaouch@gmail.com)
Date: Fri,  3 Mar 2006 19:55:00 +0100 (CET)
Subject: [Rd] [as.POSIXlt]: Incorrect conversion only for some specific
	date/time (PR#8654)
Message-ID: <20060303185500.750B1103F0@slim.kubism.ku.dk>

Full_Name: Aziz Chaouch
Version: 2.2.1
OS: XP/2000
Submission from: (NULL) (132.156.89.240)


Hi,

I'm not sure this is a "bug" but here is the problem:

I'm using the function as.POSIXlt to convert character strings into time
objects. I'm using date format as "YYYY/M/D HH:MM" such as as.POSIXlt("1999/6/7
13:30"). Most of the time, this works fine. However for some reasons, some
specific dates such as "2000/4/2 02:00" are not correctly converted with respect
to hours (the converted hour is 01:00 while the input was 02:00). Look for the
result in R:

> as.POSIXlt("2000/4/2 02:00")
[1] "2000-04-02 01:00:00"

Strangely, other hours are converted correctly:

> as.POSIXlt("2000/4/2 01:00")
[1] "2000-04-02 01:00:00"
> as.POSIXlt("2000/4/2 03:00")
[1] "2000-04-02 03:00:00"

I've only experienced this problem for some specific dates when the time is set
to 02:00.

The following list shows date/time that have problems so far but obviously there
are more:
"2000/4/2 02:00"
"2001/4/1 02:00"
"2002/4/7 02:00"
"2003/4/6 02:00"
"2004/4/4 02:00"
"2005/4/3 02:00"

Does anybody knows what's the problem? Am I missing something?

Thanks


From ggrothendieck at gmail.com  Fri Mar  3 20:03:42 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 3 Mar 2006 14:03:42 -0500
Subject: [Rd] [as.POSIXlt]: Incorrect conversion only for some specific
	date/time (PR#8654)
In-Reply-To: <20060303185500.750B1103F0@slim.kubism.ku.dk>
References: <20060303185500.750B1103F0@slim.kubism.ku.dk>
Message-ID: <971536df0603031103w2b5ad68dwa636ae094d0aa934@mail.gmail.com>

Its due to daylight savings time in your time zone.  If you don't want
that then use the tz = "GMT" argument to specify GMT time zone as
GMT has no daylight savings time or set your entire session that way,
i.e. Sys.putenv(TZ = "GMT").

Also read the Help Desk article in R News 4/1 on dates and times.

On 3/3/06, aziz.chaouch at gmail.com <aziz.chaouch at gmail.com> wrote:
> Full_Name: Aziz Chaouch
> Version: 2.2.1
> OS: XP/2000
> Submission from: (NULL) (132.156.89.240)
>
>
> Hi,
>
> I'm not sure this is a "bug" but here is the problem:
>
> I'm using the function as.POSIXlt to convert character strings into time
> objects. I'm using date format as "YYYY/M/D HH:MM" such as as.POSIXlt("1999/6/7
> 13:30"). Most of the time, this works fine. However for some reasons, some
> specific dates such as "2000/4/2 02:00" are not correctly converted with respect
> to hours (the converted hour is 01:00 while the input was 02:00). Look for the
> result in R:
>
> > as.POSIXlt("2000/4/2 02:00")
> [1] "2000-04-02 01:00:00"
>
> Strangely, other hours are converted correctly:
>
> > as.POSIXlt("2000/4/2 01:00")
> [1] "2000-04-02 01:00:00"
> > as.POSIXlt("2000/4/2 03:00")
> [1] "2000-04-02 03:00:00"
>
> I've only experienced this problem for some specific dates when the time is set
> to 02:00.
>
> The following list shows date/time that have problems so far but obviously there
> are more:
> "2000/4/2 02:00"
> "2001/4/1 02:00"
> "2002/4/7 02:00"
> "2003/4/6 02:00"
> "2004/4/4 02:00"
> "2005/4/3 02:00"
>
> Does anybody knows what's the problem? Am I missing something?
>
> Thanks
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Mar  3 20:26:21 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri,  3 Mar 2006 20:26:21 +0100 (CET)
Subject: [Rd] (PR#8654) failure to read the help carefully!
Message-ID: <20060303192621.1428FE890@slim.kubism.ku.dk>

You seem unaware of Summer Time.  When a timezone moves on to Summer Time, 
there is no 2am, so you most likely specified a non-existent time.

You have not told us where you are, and we cannot tell from your junk-mail 
address (nor does the IP address resolve here, but an IP-to-geo service 
claims it is in Ottawa).  But I suspect you will find the days you mention 
are the beginning of Summer Time in your unstated timezone.

E.g. in PST8PDT

> seq(as.POSIXlt("2000/4/2 01:00"), by="hour", length=4)
[1] "2000-04-02 01:00:00 PST" "2000-04-02 03:00:00 PDT"
[3] "2000-04-02 04:00:00 PDT" "2000-04-02 05:00:00 PDT"

The help page for strptime (as used here) says

      Remember that in most timezones some times do not occur and some
      occur twice because of transitions to/from summer time.  What
      happens in those cases is OS-specific.


On Fri, 3 Mar 2006, aziz.chaouch at gmail.com wrote:

> Full_Name: Aziz Chaouch
> Version: 2.2.1
> OS: XP/2000
> Submission from: (NULL) (132.156.89.240)
>
>
> Hi,
>
> I'm not sure this is a "bug" but here is the problem:

You are specifically asked in the FAQ not to misuse R-bugs for things you 
are not *sure* are incorrect!

> I'm using the function as.POSIXlt to convert character strings into time
> objects. I'm using date format as "YYYY/M/D HH:MM" such as as.POSIXlt("1999/6/7
> 13:30"). Most of the time, this works fine. However for some reasons, some
> specific dates such as "2000/4/2 02:00" are not correctly converted with respect
> to hours (the converted hour is 01:00 while the input was 02:00). Look for the
> result in R:
>
>> as.POSIXlt("2000/4/2 02:00")
> [1] "2000-04-02 01:00:00"
>
> Strangely, other hours are converted correctly:
>
>> as.POSIXlt("2000/4/2 01:00")
> [1] "2000-04-02 01:00:00"
>> as.POSIXlt("2000/4/2 03:00")
> [1] "2000-04-02 03:00:00"
>
> I've only experienced this problem for some specific dates when the time is set
> to 02:00.
>
> The following list shows date/time that have problems so far but obviously there
> are more:
> "2000/4/2 02:00"
> "2001/4/1 02:00"
> "2002/4/7 02:00"
> "2003/4/6 02:00"
> "2004/4/4 02:00"
> "2005/4/3 02:00"
>
> Does anybody knows what's the problem? Am I missing something?

Yes, yes.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jaomatos at gmail.com  Fri Mar  3 21:32:00 2006
From: jaomatos at gmail.com (=?ISO-8859-1?Q?Jos=E9_Matos?=)
Date: Fri, 3 Mar 2006 20:32:00 +0000
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
Message-ID: <9fd2371d0603031232k5e217784y@mail.gmail.com>

Hi,
  in Fedora Extras we build R packages to a temporary directory. The
relevant section in
the spec file is this:

%build
cd ..; R CMD INSTALL %{packname} -l %{buildroot}%{_libdir}/R/library

It works. :-)

We noticed one problem though (I will assume working on ix86 here) the
temporary build path is saved in
/usr/lib/R/library/*/Meta/hsearch.rds, i.e. for each package.

To see this is enough to run strings over these file.

Is this a security concern? Does R uses this path in any way?

In case the answer is yes, it is safe to run sed over this file and do
a textual replacement?

Thanks and best regards,
--
Jos? Matos


From jaomatos at gmail.com  Sat Mar  4 00:17:14 2006
From: jaomatos at gmail.com (=?ISO-8859-1?Q?Jos=E9_Matos?=)
Date: Fri, 3 Mar 2006 23:17:14 +0000
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
In-Reply-To: <9fd2371d0603031232k5e217784y@mail.gmail.com>
References: <9fd2371d0603031232k5e217784y@mail.gmail.com>
Message-ID: <9fd2371d0603031517n985acc0y@mail.gmail.com>

On 03/03/06, Jos? Matos <jaomatos at gmail.com> wrote:
> Hi,
>   in Fedora Extras we build R packages to a temporary directory. The
> relevant section in
> the spec file is this:
>
> %build
> cd ..; R CMD INSTALL %{packname} -l %{buildroot}%{_libdir}/R/library
>
> It works. :-)
>
> We noticed one problem though (I will assume working on ix86 here) the
> temporary build path is saved in
> /usr/lib/R/library/*/Meta/hsearch.rds, i.e. for each package.

  Searching a little bit more I see that Peter Daalgard came to the
same conclusion one month ago:
https://stat.ethz.ch/pipermail/r-help/2006-February/086069.html

> To see this is enough to run strings over these file.
>
> Is this a security concern? Does R uses this path in any way?
>
> In case the answer is yes, it is safe to run sed over this file and do
> a textual replacement?
>
> Thanks and best regards,
> --
> Jos? Matos
>

--
Jos? Ab?lio


From edd at debian.org  Sat Mar  4 03:03:01 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 3 Mar 2006 20:03:01 -0600
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
In-Reply-To: <9fd2371d0603031517n985acc0y@mail.gmail.com>
References: <9fd2371d0603031232k5e217784y@mail.gmail.com>
	<9fd2371d0603031517n985acc0y@mail.gmail.com>
Message-ID: <17416.62805.935196.816151@basebud.nulle.part>


On 3 March 2006 at 23:17, Jos? Matos wrote:
| On 03/03/06, Jos? Matos <jaomatos at gmail.com> wrote:
| > Hi,
| >   in Fedora Extras we build R packages to a temporary directory. The
| > relevant section in
| > the spec file is this:
| >
| > %build
| > cd ..; R CMD INSTALL %{packname} -l %{buildroot}%{_libdir}/R/library
| >
| > It works. :-)
| >
| > We noticed one problem though (I will assume working on ix86 here) the
| > temporary build path is saved in
| > /usr/lib/R/library/*/Meta/hsearch.rds, i.e. for each package.
| 
|   Searching a little bit more I see that Peter Daalgard came to the
| same conclusion one month ago:
| https://stat.ethz.ch/pipermail/r-help/2006-February/086069.html

And I guess you also saw that he called that harmless, right?

We have building packages like this 'forever' under Debian and yet to have a
problem with it:

edd at basebud:~> strings /usr/lib/R/site-library/*/Meta/*.rds | grep -c buildd
5154

That 5154 occurrences of the string buildd showing that the package was built
in a Debian autobuilder.  

| > To see this is enough to run strings over these file.
| >
| > Is this a security concern? Does R uses this path in any way?

Why would this have security implications?  As others have said, the main
thing is $R_HOME set in the R shell script (and now to a lesser extent the
locations for the doc/, include/, and share/ directories which are allowed to
be somewhere other than directly under $R_HOME if you so desire [ and we do,
slowly, as there may be advantages to eventual convergence towards Linux FHS
standards ] ).

| > In case the answer is yes, it is safe to run sed over this file and do
| > a textual replacement?

I'd treat that as an empirical exercise :)  Maybe you can even cook up a
patch that may one day make it into being called by 'make install' ?

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ripley at stats.ox.ac.uk  Sat Mar  4 09:07:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Mar 2006 08:07:39 +0000 (GMT)
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
In-Reply-To: <9fd2371d0603031517n985acc0y@mail.gmail.com>
References: <9fd2371d0603031232k5e217784y@mail.gmail.com>
	<9fd2371d0603031517n985acc0y@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603040743540.10823@gannet.stats.ox.ac.uk>

On Fri, 3 Mar 2006, Jos? Matos wrote:

> On 03/03/06, Jos? Matos <jaomatos at gmail.com> wrote:
>> Hi,
>>   in Fedora Extras we build R packages to a temporary directory. The
>> relevant section in
>> the spec file is this:
>>
>> %build
>> cd ..; R CMD INSTALL %{packname} -l %{buildroot}%{_libdir}/R/library
>>
>> It works. :-)
>>
>> We noticed one problem though (I will assume working on ix86 here) the
>> temporary build path is saved in
>> /usr/lib/R/library/*/Meta/hsearch.rds, i.e. for each package.
>
>  Searching a little bit more I see that Peter Daalgard came to the
> same conclusion one month ago:
> https://stat.ethz.ch/pipermail/r-help/2006-February/086069.html

Yes, and his conclusion holds as well.

Please explain what the problem is.  The first element of the object saved 
in hsearch.rds is a data frame with a column LibPath.  This is not used
by help.search() after installation.

>> To see this is enough to run strings over these file.
>>
>> Is this a security concern?

Why should there be any security issues about a non-existent path?

>> Does R uses this path in any way?

Peter was referring to packages installed with R.  If they were used, no 
binary installation of R would work, so I presume they are not used.

>> In case the answer is yes, it is safe to run sed over this file and do
>> a textual replacement?

Not safe: the string lengths are encoded in the file.

>>
>> Thanks and best regards,
>> --
>> Jos? Matos
>>
>
> --
> Jos? Ab?lio
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From towsonu2003 at gmail.com  Sat Mar  4 09:18:38 2006
From: towsonu2003 at gmail.com (towsonu2003@gmail.com)
Date: Sat,  4 Mar 2006 09:18:38 +0100 (CET)
Subject: [Rd] R does not have friendly GUI (PR#8656)
Message-ID: <20060304081838.876D7E0B8@slim.kubism.ku.dk>

Full_Name: 
Version: 2.1.1
OS: Linux (Ubuntu 5.10)
Submission from: (NULL) (136.160.174.71)


R does not have a friendly gui from where all functions can be accessed by
"point-and-click". Existing one I could try (tk) is too simple. 

The friendly gui should also include a spreadsheet-like data-viewer as well as a
data-output (exportable tables) and a graphics-output modules (the latter
already exits).


From francoisromain at free.fr  Sat Mar  4 11:20:30 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sat, 04 Mar 2006 11:20:30 +0100
Subject: [Rd] R does not have friendly GUI (PR#8656)
In-Reply-To: <20060304081838.876D7E0B8@slim.kubism.ku.dk>
References: <20060304081838.876D7E0B8@slim.kubism.ku.dk>
Message-ID: <440969EE.60003@free.fr>

Le 04.03.2006 09:18, towsonu2003 at gmail.com a ?crit :
> Full_Name: 
> Version: 2.1.1
> OS: Linux (Ubuntu 5.10)
> Submission from: (NULL) (136.160.174.71)
>
> R does not have a friendly gui from where all functions can be accessed by
> "point-and-click". Existing one I could try (tk) is too simple. 
>
> The friendly gui should also include a spreadsheet-like data-viewer as well as a
> data-output (exportable tables) and a graphics-output modules (the latter
> already exits).
Hi,

Do you also want to be able to type :
PROC UNIVARIATE ....
in R ?

What you described is *so* not a bug. You have not tried hard enough.

There are gui for R : JGR, sciviews, Rcmdr, etc ....
You can export results in HTML (package R2HTML), to latex (package xtable).
If the features therein are not completely satisfying your needs, you 
can contribute something, as you know it is open source.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From antonio.fabio at gmail.com  Sat Mar  4 13:08:43 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Sat, 4 Mar 2006 13:08:43 +0100
Subject: [Rd]  R does not have friendly GUI (PR#8656)
In-Reply-To: <b0808fdc0603040407p725f2288p@mail.gmail.com>
References: <20060304081838.876D7E0B8@slim.kubism.ku.dk>
	<b0808fdc0603040407p725f2288p@mail.gmail.com>
Message-ID: <b0808fdc0603040408k5347e0faj@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060304/49a90134/attachment.pl

From ripley at stats.ox.ac.uk  Sat Mar  4 17:55:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Mar 2006 16:55:54 +0000 (GMT)
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
In-Reply-To: <Pine.LNX.4.64.0603040743540.10823@gannet.stats.ox.ac.uk>
References: <9fd2371d0603031232k5e217784y@mail.gmail.com>
	<9fd2371d0603031517n985acc0y@mail.gmail.com>
	<Pine.LNX.4.64.0603040743540.10823@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0603041649470.26249@gannet.stats.ox.ac.uk>

I've made two changes for R 2.3.0

1) as the LibPath is not actually used, it is recorded as "".  (For 
compatibility we don't want to remove the field.)  Since it was returned 
but not printed by help.search(), the actual installed path is returned
instead.  (Given that the return format of help.search is undocumented, I 
don't see how anyone could have made use of it without realizing it was 
subject to guesswork and to change.)

2) hsearch.rds could usefully be stored in compressed format, and so will 
be.

On Sat, 4 Mar 2006, Prof Brian Ripley wrote:

> On Fri, 3 Mar 2006, Jos? Matos wrote:
>
>> On 03/03/06, Jos? Matos <jaomatos at gmail.com> wrote:
>>> Hi,
>>>   in Fedora Extras we build R packages to a temporary directory. The
>>> relevant section in
>>> the spec file is this:
>>> 
>>> %build
>>> cd ..; R CMD INSTALL %{packname} -l %{buildroot}%{_libdir}/R/library
>>> 
>>> It works. :-)
>>> 
>>> We noticed one problem though (I will assume working on ix86 here) the
>>> temporary build path is saved in
>>> /usr/lib/R/library/*/Meta/hsearch.rds, i.e. for each package.
>>
>>  Searching a little bit more I see that Peter Daalgard came to the
>> same conclusion one month ago:
>> https://stat.ethz.ch/pipermail/r-help/2006-February/086069.html
>
> Yes, and his conclusion holds as well.
>
> Please explain what the problem is.  The first element of the object saved in 
> hsearch.rds is a data frame with a column LibPath.  This is not used
> by help.search() after installation.
>
>>> To see this is enough to run strings over these file.
>>> 
>>> Is this a security concern?
>
> Why should there be any security issues about a non-existent path?
>
>>> Does R uses this path in any way?
>
> Peter was referring to packages installed with R.  If they were used, no 
> binary installation of R would work, so I presume they are not used.
>
>>> In case the answer is yes, it is safe to run sed over this file and do
>>> a textual replacement?
>
> Not safe: the string lengths are encoded in the file.
>
>>> 
>>> Thanks and best regards,
>>> --
>>> Jos? Matos
>>> 
>> 
>> --
>> Jos? Ab?lio
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sat Mar  4 18:36:51 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat,  4 Mar 2006 18:36:51 +0100 (CET)
Subject: [Rd] Bug/Wishlist: 'partial' in 'sort' and 'quantile' (PR#8650)
Message-ID: <20060304173651.3E68DE0B8@slim.kubism.ku.dk>

Deepayan,

The current algorithm is really designed for partial of length 1, and is
more or less proportional to the length of partial.  So inevitably it is 
slow in your (pretty unrealistic?) example.  I have temporarily altered it 
so a barebones full sort is done if partial has more than 10 elements, the 
changeover point for a million-element vector on my system.

John Chambers wrote a paper on this in 1971 (and I know that from his 1977 
book).  It is possible to write partial sorting to be about as fast as 
sorting in all cases (at least if partial is sorted) and much faster if 
partial is small.  But I am not sure it is really worth the bother when 
full sorting is so fast even on a million elements.

Brian

On Thu, 2 Mar 2006, deepayan.sarkar at gmail.com wrote:

> Hi,
>
> This is essentially a reposting of
>
> http://tolstoy.newcastle.edu.au/R/devel/05/11/3305.html
>
> which had no responses, and the behaviour reported there persists in
> r-devel as of yesterday.
>
> (1) sort() with non-null partial
>
>> x = rnorm(100000)
>> keep = as.integer(ppoints(10000) * 100000)
>> system.time(sort(x))
> [1] 0.05 0.00 0.04 0.00 0.00
>> system.time(sort(x, partial = keep))
> [1] 52.04  0.02 52.08  0.00  0.00
>
> This is perhaps not strictly a bug, but taking approximately 1000
> times longer to do a subset of the work seems pointless at best.
>
> (2) quantile.default() always calls sort() with a non-null partial
> argument. Consequently,
>
>> system.time(quantile(x, ppoints(10000)))
> [1] 88.82  0.05 88.90  0.00  0.00
>
> There's no way around this except by writing a custom version of
> quantile. lattice currently does this, giving
>
>> system.time(lattice:::fast.quantile(x, ppoints(10000)))
> [1] 0.07 0.01 0.08 0.00 0.00
>
> Which brings me to my wishlist request: if (1) cannot be fixed easily,
> could quantile.default() at least have an optional argument that can
> be used to disable partial sorting?
>
>> sessionInfo()
> Version 2.3.0 Under development (unstable) (2006-02-28 r37448)
> x86_64-unknown-linux-gnu
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> Deepayan
> --
> http://www.stat.wisc.edu/~deepayan/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Sat Mar  4 18:51:42 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 4 Mar 2006 11:51:42 -0600
Subject: [Rd] R does not have friendly GUI (PR#8656)
In-Reply-To: <440969EE.60003@free.fr>
References: <20060304081838.876D7E0B8@slim.kubism.ku.dk>
	<440969EE.60003@free.fr>
Message-ID: <17417.54190.856059.952762@basebud.nulle.part>


On 4 March 2006 at 11:20, Romain Francois wrote:
| Le 04.03.2006 09:18, towsonu2003 at gmail.com a ?crit :
| > Full_Name: 
| > Version: 2.1.1
| > OS: Linux (Ubuntu 5.10)
| > Submission from: (NULL) (136.160.174.71)
| >
| > R does not have a friendly gui from where all functions can be accessed by
| > "point-and-click". Existing one I could try (tk) is too simple. 
| >
| > The friendly gui should also include a spreadsheet-like data-viewer as well as a
| > data-output (exportable tables) and a graphics-output modules (the latter
| > already exits).

$ apt-get install r-cran-rcmdr
$ R
$ > library(Rcmdr)

is pretty close.

| Do you also want to be able to type :
| PROC UNIVARIATE ....
| in R ?

Exactly -- and I am missing the feature where R is doing my home work for me.
The sequence

	> library(timemachine)
	> timemachineGo(highschool)
	> timemachineDo(getBetterMarks)

fails. Any idea why?

| What you described is *so* not a bug. You have not tried hard enough.

Well put, Romain!

Regards, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From towsonu2003 at gmail.com  Sat Mar  4 19:18:29 2006
From: towsonu2003 at gmail.com (t u)
Date: Sat, 4 Mar 2006 13:18:29 -0500
Subject: [Rd] R does not have friendly GUI (PR#8656)
In-Reply-To: <17417.54190.856059.952762@basebud.nulle.part>
References: <20060304081838.876D7E0B8@slim.kubism.ku.dk>
	<440969EE.60003@free.fr>
	<17417.54190.856059.952762@basebud.nulle.part>
Message-ID: <adcb43b10603041018l55252afbx87b453b42c797501@mail.gmail.com>

On 3/4/06, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 4 March 2006 at 11:20, Romain Francois wrote:
> | Le 04.03.2006 09:18, towsonu2003 at gmail.com a ?crit :
> | > Full_Name:
> | > Version: 2.1.1
> | > OS: Linux (Ubuntu 5.10)
> | > Submission from: (NULL) (136.160.174.71)
> | >
> | > R does not have a friendly gui from where all functions can be accessed by
> | > "point-and-click". Existing one I could try (tk) is too simple.
> | >
> | > The friendly gui should also include a spreadsheet-like data-viewer as well as a
> | > data-output (exportable tables) and a graphics-output modules (the latter
> | > already exits).
>
> $ apt-get install r-cran-rcmdr
> $ R
> $ > library(Rcmdr)
>
> is pretty close.
>
> | Do you also want to be able to type :
> | PROC UNIVARIATE ....
> | in R ?
>
> Exactly -- and I am missing the feature where R is doing my home work for me.
> The sequence
>
>         > library(timemachine)
>         > timemachineGo(highschool)
>         > timemachineDo(getBetterMarks)
>
> fails. Any idea why?
>
> | What you described is *so* not a bug. You have not tried hard enough.
>
> Well put, Romain!
>
> Regards, Dirk
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                   -- Thomas A. Edison
>

As per your signature, "there are no rules here - we're trying to
accomplish something". I agree with you in "You have not tried hard
enough" and specially thank Mr Eddelbuettel for Rcmdr suggestion. It
is similar to my request in the bug report.

>         > library(timemachine)
>         > timemachineGo(highschool)
>         > timemachineDo(getBetterMarks)
>
> fails. Any idea why?

as you mentioned, sudo apt-get r-cran-foreigntime.

Thanks,

Sincerely.


From groemping at tfh-berlin.de  Sun Mar  5 09:50:08 2006
From: groemping at tfh-berlin.de (groemping@tfh-berlin.de)
Date: Sun,  5 Mar 2006 09:50:08 +0100 (CET)
Subject: [Rd] Wishlist: merge and subset to keep attributes (PR#8658)
Message-ID: <20060305085008.3BE34E0B8@slim.kubism.ku.dk>

Full_Name: Ulrike Gr?mping
Version: 2.2.1
OS: Windows
Submission from: (NULL) (84.190.139.94)


When importing data from SPSS, it is a nice feature of the package foreign that
it allows (option use.value.labels=F) to work with the original SPSS codes while
keeping the value labels as information in an attribute. Unfortunately, after
merging or subsetting, these attributes disappear. 
The code below illustrates the problem: Variable time originally has value
labels that are gone after merging or subsetting.

It would be very helpful, if this could be changed.

With kind regards, Ulrike
-----------------------------------------------------------------

data1 <- data.frame(id=c("Id1","Id2","Id3","Id4","Id5","Id6"),
        time=c(3,4,3,5,9,4))
vallab <- c(3,4,5,9)
names(vallab) <- c("day","night","twilight","unknown")
attr(data1$time,"value.labels")<-vallab
str(data1)
## gives the output:
## `data.frame':   6 obs. of  2 variables:
##  $ id  : Factor w/ 6 levels "Id1","Id2","Id3",..: 1 2 3 4 5 6
##  $ time: atomic  3 4 3 5 9 4
##   ..- attr(*, "value.labels")= Named num  3 4 5 9
##   .. ..- attr(*, "names")= chr  "day" "night" "twilight" "unknown"
data2 <- data.frame(id=rep(c("Id1","Id2","Id3","Id4","Id5","Id6"),2), 
        y=rnorm(12))
merged <- merge(data1,data2)
subset <- subset(data1,id %in% c("Id2","Id4","Id6"))
str(merged)
## gives the output:
## `data.frame':   12 obs. of  3 variables:
##  $ id  : Factor w/ 6 levels "Id1","Id2","Id3",..: 1 1 2 2 3 3 4 4 5 5 ...
##  $ time: num  3 3 4 4 3 3 5 5 9 9 ...
##  $ y   : num  -0.621 -2.617 -0.980  0.486 -0.558 ...
str(subset)
## gives the output:
## `data.frame':   3 obs. of  2 variables:
## $ id  : Factor w/ 6 levels "Id1","Id2","Id3",..: 2 4 6
## $ time: num  4 5 4


From groemping at tfh-berlin.de  Sun Mar  5 10:22:56 2006
From: groemping at tfh-berlin.de (groemping@tfh-berlin.de)
Date: Sun,  5 Mar 2006 10:22:56 +0100 (CET)
Subject: [Rd] Wishlist: xtabs and table to optionally use attribute value
	labels (PR#8659)
Message-ID: <20060305092256.D71A8D178@slim.kubism.ku.dk>

Full_Name: Ulrike Gr?mping
Version: 2.2.1
OS: Windows
Submission from: (NULL) (84.190.139.94)


A wish somehow related to my wish 8658: Package foreign allows to import
categorical data from SPSS (and possibly other software) using the original
codes, which are often useful for data manipulation, since one can use already
available lists of codes from others who don't use R etc. The original value
labels are preserved as an attribute of the variables. It would be very nice if
these value labels instead of the codes could be displayed in tables. The code
at the end of this note illustrates what I mean; currently I can only achieve a
conveniently annotated table by generating a factor from each variable I want to
tabulate with a lengthy command.

My wish: being able to generate the last table in the example output by a
statement like 'table(data1$time)' or 'table(data1$time, use.value.labels=T)' or

'table(as.factor(data1$time))'.

'table(as.factor(data1$time))' would do the job, if 'as.factor()' would use
value labels (like in 
  data1$ftime <- factor(data1$time,levels=attr(data1$time, "value.labels"), 
         labels=names(attr(data1$time,"value.labels")))
), whenever they are present. This might also help in obtaining more meaningful
output e.g. from regression procedures with such data.

Hoping this wish will make it to the list of wishes fulfilled some day.

With kind regards, Ulrike
-----------------------------------------------------------------
data1 <- data.frame(id=c("Id1","Id2","Id3","Id4","Id5","Id6"),
        time=c(3,4,3,5,9,4))
vallab <- c(3,4,5,9)
names(vallab) <- c("day","night","twilight","unknown")
attr(data1$time,"value.labels")<-vallab
str(data1)
## gives the output:
## `data.frame':   6 obs. of  2 variables:
##  $ id  : Factor w/ 6 levels "Id1","Id2","Id3",..: 1 2 3 4 5 6
##  $ time: atomic  3 4 3 5 9 4
##   ..- attr(*, "value.labels")= Named num  3 4 5 9
##   .. ..- attr(*, "names")= chr  "day" "night" "twilight" "unknown"
table(data1$time)
## gives the output:
## 3 4 5 9 
## 2 2 1 1 
data1$ftime<-factor(data1$time,levels=attr(data1$time,"value.labels"),
                    labels=names(attr(data1$time,"value.labels")))
table(data1$ftime)
## gives the output:
##      day    night twilight  unknown 
##        2        2        1        1


From ales.ziberna at gmail.com  Sun Mar  5 11:48:42 2006
From: ales.ziberna at gmail.com (=?windows-1252?Q?Ale=9A_=8Eiberna?=)
Date: Sun, 05 Mar 2006 11:48:42 +0100
Subject: [Rd] Problem with creating links ("see also" section) in help
 files.
In-Reply-To: <440836DC.2070907@stats.uwo.ca>
References: <4408284C.5020908@gmail.com> <440836DC.2070907@stats.uwo.ca>
Message-ID: <440AC20A.1060500@gmail.com>

Duncan Murdoch pravi:
> On 3/3/2006 6:28 AM, Ale? ?iberna wrote:
>> A link in one of my help files does not work. I have in this help file:
>> \seealso{\code{\link{crit.fun}}, \code{\link{opt.par}}, 
>> \code{\link{opt.random.par}}, \code{\link{opt.these.par}}, 
>> \code{\link{nkpartitions}}, \code{\link{nkpar}}, 
>> \code{\link{plot.check.these.par}} }
>>
>> Everything in one row, the last link does not work. In another help 
>> file, I have:
>> \name{plot.mat}
>> \alias{plot.mat}
>> \alias{plot.crit.fun}
>> \alias{plot.opt.par}
>> \alias{plot.opt.par.mode}
>> \alias{plot.opt.more.par}
>> \alias{plot.opt.more.par.mode}
>> \alias{plot.check.these.par}
>>
>> The last alias should corresponds to the link that does not work.
>>
>> This is also produces a massage when building a binary package or 
>> installing a package:
>>   check.these.par                   text    html    latex   example chm
>>      missing link(s):  plot.check.these.par
>>
>> Any ideas?
>
> Based on the error message and the symptom that the link doesn't work, 
> I'd assume that the alias isn't being recognized.  You could confirm 
> this by seeing whether ?plot.check.these.par works in the R console.
>
> Do any of the other aliases in that file work?  Maybe there's 
> something wrong with the whole file.
>
> Duncan Murdoch
>
Thanks for the reply!

The ?plot.check.these.par also does not work, however all other links 
(alias-es) do work in that file.

Are there any limitations to the number of alias-es in a given help file?

Best regards,
Ales Ziberna


From ales.ziberna at gmail.com  Sun Mar  5 12:05:13 2006
From: ales.ziberna at gmail.com (=?windows-1252?Q?Ale=9A_=8Eiberna?=)
Date: Sun, 05 Mar 2006 12:05:13 +0100
Subject: [Rd] Problem with creating links ("see also" section) in help
 files.
In-Reply-To: <440AC20A.1060500@gmail.com>
References: <4408284C.5020908@gmail.com> <440836DC.2070907@stats.uwo.ca>
	<440AC20A.1060500@gmail.com>
Message-ID: <440AC5E9.5000309@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060305/d26dba99/attachment.pl

From f.harrell at vanderbilt.edu  Sun Mar  5 15:24:04 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 05 Mar 2006 08:24:04 -0600
Subject: [Rd]  Wishlist: merge and subset to keep attributes (PR#8658)
Message-ID: <440AF484.4040407@vanderbilt.edu>

When importing data from SPSS, it is a nice feature of the package 
foreign that
it allows (option use.value.labels=F) to work with the original SPSS 
codes while
keeping the value labels as information in an attribute. Unfortunately, 
after
merging or subsetting, these attributes disappear.
The code below illustrates the problem: Variable time originally has value
labels that are gone after merging or subsetting.

It would be very helpful, if this could be changed.

With kind regards, Ulrike
-------------------------------

Ulrike - see the spss.get, label, contents, and describe functions in 
the Hmisc package.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From roger at ysidro.econ.uiuc.edu  Sun Mar  5 19:28:31 2006
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sun, 5 Mar 2006 12:28:31 -0600
Subject: [Rd] Bug/Wishlist: 'partial' in 'sort' and 'quantile' (PR#8650)
Message-ID: <3E97C922-AB2C-4929-8542-54E9A3D8FA1B@ysidro.econ.uiuc.edu>

I used to have a version of the classical Floyd and Revest "Select"  
algorithm (ACM#489)
for computing  univariate quantiles in my quantreg package.  At some  
point
g77 decided that it shouldn't be possible to use recursion  in  
fortran and I had
to remove it.  Stimulated by my your recent inquiry,  I thought I  
would see
whether it could be revived.  At least on my macs, running gfortran,  
it seems
that recursion is now again permissible.  I've not done any serious  
testing, but
I get:

 > unix.time(kuantile(y))  #my fortran translation of the Floyd- 
Revest algol algorithm
[1] 0.56 0.41 0.96 0.00 0.00
 > unix.time(median(y))
[1] 1.80 0.27 2.07 0.00 0.00
 > length(y)
[1] 10000000

for a rnorm example.  I'd be happy to provide some new version of  
this, but
I'm afraid that there are still lots of g77 users, including on macs,  
that
wouldn't be functional due to the recursion.  Any thoughts on this  
would  be
appreciated.  Brian is doubtless right that current methods are  
perfectly
adequate for almost all purposes, but in cases of very large datasets  
where
many quantiles are needed, it may be worthwhile.

Roger

url:    www.econ.uiuc.edu/~roger                Roger Koenker
email   rkoenker at uiuc.edu                       Department of Economics
vox:    217-333-4558                            University of Illinois
fax:    217-244-6678                            Champaign, IL 61820


From timh at insightful.com  Sun Mar  5 22:36:01 2006
From: timh at insightful.com (timh@insightful.com)
Date: Sun,  5 Mar 2006 22:36:01 +0100 (CET)
Subject: [Rd] Problem with R CMD Rdconv -t Ssgm file.Rd > file.sgml;
	omits section{foo}{text} (PR#8660)
Message-ID: <20060305213601.8FBC8CC0C@slim.kubism.ku.dk>

I have a .Rd file containing a number of \section commands.
When I convert this to .sgml, the sections are missing; neither the
title nor following text is there.

In contrast, when I convert to .d, the sections are present.

R CMD Rdconv -t Ssgm temp.Rd > temp.sgml
R CMD Rdconv -t Sd temp.Rd > temp.d


Tim Hesterberg

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From timh at insightful.com  Mon Mar  6 01:37:20 2006
From: timh at insightful.com (timh@insightful.com)
Date: Mon,  6 Mar 2006 01:37:20 +0100 (CET)
Subject: [Rd] Problems with R CMD Rdconv and R CMD Sd2Rd (PR#8661)
Message-ID: <20060306003720.42F1711346@slim.kubism.ku.dk>

I'm using R 2.2.0 on Windows.
Doing some conversions of help files.  Internal comments indicate
that the Sd2Rd conversion is "Converted by Sd2Rd version 1.21."

I'm converting 
	.d -> .Rd	
	.sgml -> .Rd
using Sd2Rd, then checking by using Rdconv to
convert .Rd back to .d or .sgml.

Here are errors in some of the conversions.
The most significant errors are in .Rd to .sgml.
The largest number of errors are in .Rd to .d (however,
this conversion is not so important).

--------------------------------------------------
	.Rd to .sgml
	R CMD Rdconv -t Ssgm file.Rd > file.sgml

If the .Rd contains
\section{title}{text}
the section is missing completely from the sgml file.
(I reported this separately; it works fine when converting to .d)


Similarly, \keyword{lars}
is missing completely from the sgml file
(It works fine when converting to .d)



Rd converts \$ to \$; it should be just $.  This in .Rd

\code{.Machine\$double.eps},

is converted to

<s-expression>.Machine\$double.eps</s-expression>,

It should be

<s-expression>.Machine$double.eps</s-expression>,

or better yet

<code>.Machine$double.eps</code>,



In \examples{}, 
	<
should be converted verbatim rather than converted to 
	&lt;


In the References section (and for links more generally?), file
names are missing the .sgm
This:

\seealso{
\code{\link{lm}}
\code{\link{lsfit}}
}

is converted to:

<s-see>
<s-function name="lm">lm</s-function>
<s-function name="lsfit">lsfit</s-function>
</s-see>

It should be

<s-see>
<s-function name="lm.sgm">lm</s-function>
<s-function name="lsfit.sgm">lsfit</s-function>
</s-see>




--------------------------------------------------
	.sgml to .Rd
	R CMD Sd2Rd file.sgml > file.Rd

This

<descrip>
<tag> lar </tag>
least-angle regression
<tag> lasso </tag>
lasso method
<tag> stepwise </tag>
forward stepwise regression
</descrip>

is put verbatim into the .Rd
It should be converted into a \describe list




A references section should be converted to \references, not 
\section{References}.  This

<s-section name = "REFERENCES">
Efron, ...
</s-section>

is converted to

\section{References}{
Efron, ...
}

it should be 

\references{
Efron, ...
}




--------------------------------------------------
	.Rd to .d
	R CMD Rdconv -t Sd file.Rd > file.d

It converts
	\code{lars}
to
	'lars'
It should be
	`lars'


It converts (in argument list)
\item{...}{

to
.AG \&...

should be
.AG ...


Converts:
\section{Side Effects}{
A plot is produced
}

to:
.SH Side Effects
A plot is produced

should be
.SE
A plot is produced


Converts
\emph{Annals of Statistics}
\bold{32}, 407--451.

to:
_Annals of Statistics_
*32*, 407-451.

Should be:
.ul
Annals of Statistics
\fB32\fP, 407-451.


Sd2Rd converts
	.PP in a .d file within the arguments section 
to
	two blank lines in .Rd; 
Rdconv converts that to
	.IP "" 
whereas 
	.PP
would be better.


Rdconv loses comments.


This:
\value{
...
the same order of computational cost as a least squares fit.
}
\references{

is converted to (missing a newline):

the same order of computational cost as a least squares fit..SH REFERENCES


This
\name{lars.object}
\alias{lars.object}
\alias{class.lars}

is converted to
.FN lars.object

should be:
.FN lars.object
.FN class.lars


The document "Writing R Extensions" manual, chapter on
"Writing R documentation files" is silent about how to document S3 classes.
(It does mention S4 classes)


--------------------------------------------------
	.d to .Rd
	R CMD Sd2Rd file.d > file.Rd


A very common error when writing a .d file is to use .AG where you
should use .RC, in the .RT section, e.g.

.RT
Invisibly returns a list with components:
.AG fraction
See above
.AG cv
The CV curve at each value of fraction

Right now the converter is moving those into the "Arguments" section,
rather than leaving them in the "Value" section.  It would be nice
if they were left in the Value section.






--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From michael.hoehle at gmail.com  Mon Mar  6 13:43:00 2006
From: michael.hoehle at gmail.com (Michael Hoehle)
Date: Mon, 6 Mar 2006 13:43:00 +0100
Subject: [Rd] Bug or Feature in Rcmd build workaround workaround for paths
	in Cygwin tar
Message-ID: <84fc09fb0603060443l66f99771sf4627eb781bbf024@mail.gmail.com>

To R-devel,

I am currently writing a package with R 2.2.1 under Windows using
cygwin and the recommended Rtools. Physically my package ist hosted on
the Drive z: .

When I call Rcmd.exe build ?-binary for my package I have a problem
with the "build" script in $R_HOME/bin/. Starting on line 226 the code
is as follows:

if($WINDOWS) {
	## workaround for paths in Cygwin tar
	$filepath =~ s+^([A-Za-x]):+/cygdrive/\1+;
}

Is there a particular reason that only lower case letter from a-x are
handled? As my drive is z:  I would like the workaround to work for
lower case letters a-z.

Best regards,

Michael H?hle


From ripley at stats.ox.ac.uk  Mon Mar  6 14:12:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Mar 2006 13:12:48 +0000 (GMT)
Subject: [Rd] Bug or Feature in Rcmd build workaround workaround for
 paths in Cygwin tar
In-Reply-To: <84fc09fb0603060443l66f99771sf4627eb781bbf024@mail.gmail.com>
References: <84fc09fb0603060443l66f99771sf4627eb781bbf024@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603061310290.11970@gannet.stats.ox.ac.uk>

On Mon, 6 Mar 2006, Michael Hoehle wrote:

> To R-devel,
>
> I am currently writing a package with R 2.2.1 under Windows using
> cygwin and the recommended Rtools. Physically my package ist hosted on
> the Drive z: .
>
> When I call Rcmd.exe build ?-binary for my package I have a problem
> with the "build" script in $R_HOME/bin/. Starting on line 226 the code
> is as follows:
>
> if($WINDOWS) {
> 	## workaround for paths in Cygwin tar
> 	$filepath =~ s+^([A-Za-x]):+/cygdrive/\1+;
> }
>
> Is there a particular reason that only lower case letter from a-x are
> handled? As my drive is z:  I would like the workaround to work for
> lower case letters a-z.

So edit the file and it should work.  (Something is a little strange, as 
Windows has drive letters in upper case.)

You may need to edit check as well as build.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sgiannerini at gmail.com  Mon Mar  6 17:50:53 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 6 Mar 2006 17:50:53 +0100
Subject: [Rd] Running R on dual/quad Opteron machines
Message-ID: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>

Dear all,

I am managing a departmental purchase of an Opteron based
workstation/server for scientific computing on which we will be
running R.
The environment will probably be either Unix/Linux or Solaris and the
amount of RAM will be 8-16Gb, depending on the number of processors.
My main concerns are the following:

1. How much does R  benefit from passing from one processor to
two/four processor machines? Consider that the typical intensive use
of the server
 will be represented by simulation studies with many repeated loops.
2. How does R cope with parallelization and/or parallelized compiled code ?

I would be very grateful if someone could give suggestions and/or
point me to information on the above mentioned issues.

Regards,

Simone Giannerini

--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From mtmorgan at fhcrc.org  Mon Mar  6 17:57:41 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 06 Mar 2006 08:57:41 -0800
Subject: [Rd] validObject does not check validity of slots
Message-ID: <6phk6b7zf22.fsf@gopher3.fhcrc.org>

The documentation for validObject suggests that slots are checked for
validity, but validObject seems only to check that the slot has
something claiming to be correct; validObject(obj) does not perform
the equivalent of validObject(obj at y) for slot y.

This is also the second problem issue reported in

http://tolstoy.newcastle.edu.au/R/devel/05/03/0151.html

Relevant documentation, an example, and sessionInfo follow.

Martin

validObject             package:methods             R Documentation

Arguments:
     ...
     Note that validity methods do not have to check validity of any
     slots or superclasses:  the logic of 'validObject' ensures these
     tests are done once only.
     ...
Details:

     Validity testing takes place "bottom up":  first the validity of
     the object's slots, if any, is tested.  
     ...

setClass("foo",
         representation( x="numeric" ),
         validity = function( object ) object at x > 0 )
setClass("bar",
         representation( y="foo", z="numeric" ),
         validity = function( object ) object at z > 0 )
obj <- new( "bar", y = new( "foo", x=1 ), z = 1 )

and then...

> validObject( obj )
[1] TRUE
## invalidate obj at y
> obj at y@x <- -1
> validObject( obj at y )                  # right, this is not valid
Error in validObject(obj at y) : invalid class "foo" object: FALSE
> ## obj at y is invalid, but obj is valid?
> validObject( obj )                    # should be invalid?
[1] TRUE



> sessionInfo()
Version 2.3.0 Under development (unstable) (2006-03-03 r37471) 
x86_64-unknown-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"


From sdavis2 at mail.nih.gov  Mon Mar  6 17:58:20 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 06 Mar 2006 11:58:20 -0500
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
Message-ID: <C031D45C.7702%sdavis2@mail.nih.gov>




On 3/6/06 11:50 AM, "Simone Giannerini" <sgiannerini at gmail.com> wrote:

> Dear all,
> 
> I am managing a departmental purchase of an Opteron based
> workstation/server for scientific computing on which we will be
> running R.
> The environment will probably be either Unix/Linux or Solaris and the
> amount of RAM will be 8-16Gb, depending on the number of processors.
> My main concerns are the following:
> 
> 1. How much does R  benefit from passing from one processor to
> two/four processor machines? Consider that the typical intensive use
> of the server
>  will be represented by simulation studies with many repeated loops.

You will have to implement some parallelization code yourself in order to
take full advantage of the multiple processors.  See below.

> 2. How does R cope with parallelization and/or parallelized compiled code ?

You might look at the Rmpi and snow packages for parallelization from within
R.  We use Rmpi and snow for analyses like simulation and have found these
applications quite easy to implement in parallel from within R.


From sgiannerini at gmail.com  Mon Mar  6 18:03:34 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 6 Mar 2006 18:03:34 +0100
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <C031D45C.7702%sdavis2@mail.nih.gov>
References: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
	<C031D45C.7702%sdavis2@mail.nih.gov>
Message-ID: <3c12769c0603060903g24cc42f3r2045310a341071cc@mail.gmail.com>

Dear Sean,

many thanks for the suggestion, I will have a look at the packages.

Regards,

Simone

On 3/6/06, Sean Davis <sdavis2 at mail.nih.gov> wrote:
>
>
>
> On 3/6/06 11:50 AM, "Simone Giannerini" <sgiannerini at gmail.com> wrote:
>
> > Dear all,
> >
> > I am managing a departmental purchase of an Opteron based
> > workstation/server for scientific computing on which we will be
> > running R.
> > The environment will probably be either Unix/Linux or Solaris and the
> > amount of RAM will be 8-16Gb, depending on the number of processors.
> > My main concerns are the following:
> >
> > 1. How much does R  benefit from passing from one processor to
> > two/four processor machines? Consider that the typical intensive use
> > of the server
> >  will be represented by simulation studies with many repeated loops.
>
> You will have to implement some parallelization code yourself in order to
> take full advantage of the multiple processors.  See below.
>
> > 2. How does R cope with parallelization and/or parallelized compiled code ?
>
> You might look at the Rmpi and snow packages for parallelization from within
> R.  We use Rmpi and snow for analyses like simulation and have found these
> applications quite easy to implement in parallel from within R.
>
>


--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From tlumley at u.washington.edu  Mon Mar  6 18:13:07 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 6 Mar 2006 09:13:07 -0800 (PST)
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
References: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603060906130.24583@homer24.u.washington.edu>

On Mon, 6 Mar 2006, Simone Giannerini wrote:
> The environment will probably be either Unix/Linux or Solaris and the
> amount of RAM will be 8-16Gb, depending on the number of processors.
> My main concerns are the following:
>
> 1. How much does R  benefit from passing from one processor to
> two/four processor machines? Consider that the typical intensive use
> of the server
> will be represented by simulation studies with many repeated loops.

The typical way that R is used on multiprocessor systems is running more 
than one program, rather than parallel processing. If four people are 
using the computer or if one person splits 10,000 iterations of a 
simulation into 4 sets of 2,500 you will be using all four processors.

> 2. How does R cope with parallelization and/or parallelized compiled code ?
>

It doesn't really.  There are interfaces to MPI and PVM and there is the 
possibility of using a parallel BLAS to speed up linear algebra.  These 
won't help much unless the server is under fairly low load so that a 
single program can use more than 100% of a single processor.  Our 
multiprocessor Opteron servers are rarely that underutilized.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From sgiannerini at gmail.com  Mon Mar  6 18:29:10 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 6 Mar 2006 18:29:10 +0100
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <Pine.LNX.4.64.0603060906130.24583@homer24.u.washington.edu>
References: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
	<Pine.LNX.4.64.0603060906130.24583@homer24.u.washington.edu>
Message-ID: <3c12769c0603060929k3c974861h6badd72e47ebe4af@mail.gmail.com>

On 3/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Mon, 6 Mar 2006, Simone Giannerini wrote:
> > The environment will probably be either Unix/Linux or Solaris and the
> > amount of RAM will be 8-16Gb, depending on the number of processors.
> > My main concerns are the following:
> >
> > 1. How much does R  benefit from passing from one processor to
> > two/four processor machines? Consider that the typical intensive use
> > of the server
> > will be represented by simulation studies with many repeated loops.
>
> The typical way that R is used on multiprocessor systems is running more
> than one program, rather than parallel processing. If four people are
> using the computer or if one person splits 10,000 iterations of a
> simulation into 4 sets of 2,500 you will be using all four processors.
>

Many thanks, if I have understood correctly, in this case I would need
running four separate instances of R, since a single thread cannot
exploit more than one cpu, am I correct?

Regards,

Simone

--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From tlumley at u.washington.edu  Mon Mar  6 19:37:37 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 6 Mar 2006 10:37:37 -0800 (PST)
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <3c12769c0603060929k3c974861h6badd72e47ebe4af@mail.gmail.com>
References: <3c12769c0603060850pd3bbc73gb40a5e9f324d8050@mail.gmail.com>
	<Pine.LNX.4.64.0603060906130.24583@homer24.u.washington.edu>
	<3c12769c0603060929k3c974861h6badd72e47ebe4af@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603061035570.17097@homer23.u.washington.edu>

On Mon, 6 Mar 2006, Simone Giannerini wrote:

> On 3/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
>> On Mon, 6 Mar 2006, Simone Giannerini wrote:
>>> The environment will probably be either Unix/Linux or Solaris and the
>>> amount of RAM will be 8-16Gb, depending on the number of processors.
>>> My main concerns are the following:
>>>
>>> 1. How much does R  benefit from passing from one processor to
>>> two/four processor machines? Consider that the typical intensive use
>>> of the server
>>> will be represented by simulation studies with many repeated loops.
>>
>> The typical way that R is used on multiprocessor systems is running more
>> than one program, rather than parallel processing. If four people are
>> using the computer or if one person splits 10,000 iterations of a
>> simulation into 4 sets of 2,500 you will be using all four processors.
>>
> Many thanks, if I have understood correctly, in this case I would need
> running four separate instances of R, since a single thread cannot
> exploit more than one cpu, am I correct?
>

You *can* exploit more than one CPU using eg the "snow" package, but it's 
often easier to just run multiple instances of R, and for a shared 
computing system there are often multiple people each running one instance 
of R.

 	-thomas


From sdavis2 at mail.nih.gov  Mon Mar  6 20:28:30 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 06 Mar 2006 14:28:30 -0500
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <Pine.LNX.4.64.0603061035570.17097@homer23.u.washington.edu>
Message-ID: <C031F78E.7745%sdavis2@mail.nih.gov>




On 3/6/06 1:37 PM, "Thomas Lumley" <tlumley at u.washington.edu> wrote:

> On Mon, 6 Mar 2006, Simone Giannerini wrote:
> 
>> On 3/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
>>> On Mon, 6 Mar 2006, Simone Giannerini wrote:
>>>> The environment will probably be either Unix/Linux or Solaris and the
>>>> amount of RAM will be 8-16Gb, depending on the number of processors.
>>>> My main concerns are the following:
>>>> 
>>>> 1. How much does R  benefit from passing from one processor to
>>>> two/four processor machines? Consider that the typical intensive use
>>>> of the server
>>>> will be represented by simulation studies with many repeated loops.
>>> 
>>> The typical way that R is used on multiprocessor systems is running more
>>> than one program, rather than parallel processing. If four people are
>>> using the computer or if one person splits 10,000 iterations of a
>>> simulation into 4 sets of 2,500 you will be using all four processors.
>>> 
>> Many thanks, if I have understood correctly, in this case I would need
>> running four separate instances of R, since a single thread cannot
>> exploit more than one cpu, am I correct?
>> 
> 
> You *can* exploit more than one CPU using eg the "snow" package, but it's
> often easier to just run multiple instances of R, and for a shared
> computing system there are often multiple people each running one instance
> of R.

And let me couch my earlier statements on snow/Rmpi by saying that we use
these tools on a relatively large beowulf cluster (~200 nodes), which is
somewhat different than a single box with 2-4 processors, so it is may not
be worth the trouble outside of a cluster environment.  For example, we have
not moved to using Rmpi/snow on our dual-processor G5s because the speed
gain just isn't worth the extra installation trouble, etc.

Sean


From brown at biology.utah.edu  Mon Mar  6 22:09:44 2006
From: brown at biology.utah.edu (Tim Brown)
Date: Mon, 06 Mar 2006 14:09:44 -0700
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
Message-ID: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>

Hi everyone,

I know this is a long shot but I just wanted to throw it out 
there.  I have lately been using R a lot and have found that it is 
basically impossible to find any code help or answers via google 
searching because the name "R" is simply not explicit enough. For 
every other popular program or programming language a simple search 
with the name of the program and your problem brings up something 
pretty close to the answer, its usually just a matter of phrasing it 
so the results you are looking come up in your search (e.g. "find 
length of array, Matlab").  Try a similar web search for R and you 
will learn nothing -- Why? because the letter "R" is on almost every 
web page on the planet.

I'm not just whining here, I think this is a really serious problem. 
On the web, "findability" is perhaps the single most important 
feature of any product or program. The unique beauty of the Web 
anyone who solves any problem can post the answer almost anywhere 
want, a search engines will index it and serve it up to someone 
looking for a solution to that problem. Of course it doesn't quite 
work like that but its pretty close if you trying to find out how to 
program something in most languages and programs. You can't do this 
in R because its name is not unique enough, and that seriously 
hampers the ability of both new and expert users to accomplish things 
quickly.  I realize that there is the R-project website and so on, 
but the decentralized nature of the web assures that not not everyone 
will post their answers there and people such as me who search google 
first rather than going straight to a single site will have a hard 
time finding answers.

So seriously, has there ever been any discussion about renaming R so 
that people's hard work on making this kick-butt program can be 
shared and searched with the same facility that other programs enjoy. 
It could be something as simple as "R plus" ;) just anything that 
makes it unique enough that R program pages aren't indexed with 100 
billion pages that happen to have a single R on them for some reason.

Cheers,

Tim


From ggrothendieck at gmail.com  Mon Mar  6 22:18:28 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 6 Mar 2006 16:18:28 -0500
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
References: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
Message-ID: <971536df0603061318x433af0f8q50f4bb6e61eaa12f@mail.gmail.com>

Note that just entering R into google will get you to the R home
page and looking for R plus some other phrase actually does
work quite often.  One can also try r-project or r-project.org
plus the phrase.

On 3/6/06, Tim Brown <brown at biology.utah.edu> wrote:
> Hi everyone,
>
> I know this is a long shot but I just wanted to throw it out
> there.  I have lately been using R a lot and have found that it is
> basically impossible to find any code help or answers via google
> searching because the name "R" is simply not explicit enough. For
> every other popular program or programming language a simple search
> with the name of the program and your problem brings up something
> pretty close to the answer, its usually just a matter of phrasing it
> so the results you are looking come up in your search (e.g. "find
> length of array, Matlab").  Try a similar web search for R and you
> will learn nothing -- Why? because the letter "R" is on almost every
> web page on the planet.
>
> I'm not just whining here, I think this is a really serious problem.
> On the web, "findability" is perhaps the single most important
> feature of any product or program. The unique beauty of the Web
> anyone who solves any problem can post the answer almost anywhere
> want, a search engines will index it and serve it up to someone
> looking for a solution to that problem. Of course it doesn't quite
> work like that but its pretty close if you trying to find out how to
> program something in most languages and programs. You can't do this
> in R because its name is not unique enough, and that seriously
> hampers the ability of both new and expert users to accomplish things
> quickly.  I realize that there is the R-project website and so on,
> but the decentralized nature of the web assures that not not everyone
> will post their answers there and people such as me who search google
> first rather than going straight to a single site will have a hard
> time finding answers.
>
> So seriously, has there ever been any discussion about renaming R so
> that people's hard work on making this kick-butt program can be
> shared and searched with the same facility that other programs enjoy.
> It could be something as simple as "R plus" ;) just anything that
> makes it unique enough that R program pages aren't indexed with 100
> billion pages that happen to have a single R on them for some reason.
>
> Cheers,
>
> Tim
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jgentry at jimmy.harvard.edu  Mon Mar  6 22:26:07 2006
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 6 Mar 2006 16:26:07 -0500 (EST)
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
Message-ID: <Pine.SOL.4.20.0603061621440.15003-100000@santiam.dfci.harvard.edu>

> so the results you are looking come up in your search (e.g. "find 
> length of array, Matlab").  Try a similar web search for R and you 
> will learn nothing -- Why? because the letter "R" is on almost every 
> web page on the planet.

FWIW using Teoma (I've been (probably unwisely) boycotting Google of
late), the search 'find length of vector R' points to mostly responses
about the R language.  Also FWIW it appears the same is not true of
Google.  Although I'm too lazy to try more than this one example (as I
didn't intend it to be a search engine comparison) I wonder if something
like "R" might not just be very Google-friendly while not being bad in
various other search engines.

Regardless I realize that more esoteric searches likely won't have the
same R-centric responses as was the case here.

> quickly.  I realize that there is the R-project website and so on, 
> but the decentralized nature of the web assures that not not everyone 
> will post their answers there and people such as me who search google 
> first rather than going straight to a single site will have a hard 
> time finding answers.

I've found that putting r-project as a search string is not very limiting
as the bulk of stuff like you're looking for ends up in these mailing
lists.  Also a lot of other sites with R based info/help tend to link to
r-project anyways (and thus should get picked up).  Not perfect but not as
dire a situation as you make it sound, IMO.


From murdoch at stats.uwo.ca  Tue Mar  7 01:21:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 06 Mar 2006 19:21:50 -0500
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
References: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
Message-ID: <440CD21E.3040809@stats.uwo.ca>

On 3/6/2006 4:09 PM, Tim Brown wrote:
> Hi everyone,
> 
> I know this is a long shot but I just wanted to throw it out 
> there.  I have lately been using R a lot and have found that it is 
> basically impossible to find any code help or answers via google 
> searching because the name "R" is simply not explicit enough.

That hasn't been my experience.  Could you post some examples of your 
searches?

For example, "find length of array in R" turns up R-specific answers in 
4th and 9th positions on the first page of results.  Using "find length 
of array, R Project" turns up 6 out of 10 hits referencing R.

Duncan Murdoch


  For
> every other popular program or programming language a simple search 
> with the name of the program and your problem brings up something 
> pretty close to the answer, its usually just a matter of phrasing it 
> so the results you are looking come up in your search (e.g. "find 
> length of array, Matlab").  Try a similar web search for R and you 
> will learn nothing -- Why? because the letter "R" is on almost every 
> web page on the planet.
> 
> I'm not just whining here, I think this is a really serious problem. 
> On the web, "findability" is perhaps the single most important 
> feature of any product or program. The unique beauty of the Web 
> anyone who solves any problem can post the answer almost anywhere 
> want, a search engines will index it and serve it up to someone 
> looking for a solution to that problem. Of course it doesn't quite 
> work like that but its pretty close if you trying to find out how to 
> program something in most languages and programs. You can't do this 
> in R because its name is not unique enough, and that seriously 
> hampers the ability of both new and expert users to accomplish things 
> quickly.  I realize that there is the R-project website and so on, 
> but the decentralized nature of the web assures that not not everyone 
> will post their answers there and people such as me who search google 
> first rather than going straight to a single site will have a hard 
> time finding answers.
> 
> So seriously, has there ever been any discussion about renaming R so 
> that people's hard work on making this kick-butt program can be 
> shared and searched with the same facility that other programs enjoy. 
> It could be something as simple as "R plus" ;) just anything that 
> makes it unique enough that R program pages aren't indexed with 100 
> billion pages that happen to have a single R on them for some reason.
> 
> Cheers,
> 
> Tim
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Tue Mar  7 02:06:19 2006
From: jmc at r-project.org (John Chambers)
Date: Mon, 06 Mar 2006 20:06:19 -0500
Subject: [Rd] validObject does not check validity of slots
In-Reply-To: <6phk6b7zf22.fsf@gopher3.fhcrc.org>
References: <6phk6b7zf22.fsf@gopher3.fhcrc.org>
Message-ID: <440CDC8B.9080905@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060306/ffef8f50/attachment.pl

From maechler at stat.math.ethz.ch  Tue Mar  7 09:20:07 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Mar 2006 09:20:07 +0100
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <440CD21E.3040809@stats.uwo.ca>
References: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
	<440CD21E.3040809@stats.uwo.ca>
Message-ID: <17421.16951.246716.141836@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 06 Mar 2006 19:21:50 -0500 writes:

    Duncan> On 3/6/2006 4:09 PM, Tim Brown wrote:
    >> Hi everyone,
    >> 
    >> I know this is a long shot but I just wanted to throw it
    >> out there.  I have lately been using R a lot and have
    >> found that it is basically impossible to find any code
    >> help or answers via google searching because the name "R"
    >> is simply not explicit enough.

    Duncan> That hasn't been my experience.  Could you post some
    Duncan> examples of your searches?

    Duncan> For example, "find length of array in R" turns up
    Duncan> R-specific answers in 4th and 9th positions on the
    Duncan> first page of results.  Using "find length of array,
    Duncan> R Project" turns up 6 out of 10 hits referencing R.

in which google?  The one in the US, in Europe, in China, or ... ?

As we probably all know the censorship differs from place to
place .. and it seems one has no way to circumvent 
Big-Brother Google's decisions anymore.

Sorry, but I couldn't refrain; I had been very disappointed by these news.

Martin Maechler



    Duncan>   For
    >> every other popular program or programming language a
    >> simple search with the name of the program and your
    >> problem brings up something pretty close to the answer,
    >> its usually just a matter of phrasing it so the results
    >> you are looking come up in your search (e.g. "find length
    >> of array, Matlab").  Try a similar web search for R and
    >> you will learn nothing -- Why? because the letter "R" is
    >> on almost every web page on the planet.
    >> 
    >> I'm not just whining here, I think this is a really
    >> serious problem.  On the web, "findability" is perhaps
    >> the single most important feature of any product or
    >> program. The unique beauty of the Web anyone who solves
    >> any problem can post the answer almost anywhere want, a
    >> search engines will index it and serve it up to someone
    >> looking for a solution to that problem. Of course it
    >> doesn't quite work like that but its pretty close if you
    >> trying to find out how to program something in most
    >> languages and programs. You can't do this in R because
    >> its name is not unique enough, and that seriously hampers
    >> the ability of both new and expert users to accomplish
    >> things quickly.  I realize that there is the R-project
    >> website and so on, but the decentralized nature of the
    >> web assures that not not everyone will post their answers
    >> there and people such as me who search google first
    >> rather than going straight to a single site will have a
    >> hard time finding answers.
    >> 
    >> So seriously, has there ever been any discussion about
    >> renaming R so that people's hard work on making this
    >> kick-butt program can be shared and searched with the
    >> same facility that other programs enjoy.  It could be
    >> something as simple as "R plus" ;) just anything that
    >> makes it unique enough that R program pages aren't
    >> indexed with 100 billion pages that happen to have a
    >> single R on them for some reason.
    >> 
    >> Cheers,
    >> 
    >> Tim
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    Duncan> ______________________________________________
    Duncan> R-devel at r-project.org mailing list
    Duncan> https://stat.ethz.ch/mailman/listinfo/r-devel


From sgiannerini at gmail.com  Tue Mar  7 09:59:13 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Tue, 7 Mar 2006 09:59:13 +0100
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <C031F78E.7745%sdavis2@mail.nih.gov>
References: <Pine.LNX.4.64.0603061035570.17097@homer23.u.washington.edu>
	<C031F78E.7745%sdavis2@mail.nih.gov>
Message-ID: <3c12769c0603070059kfa51d68h8c2da372beecef29@mail.gmail.com>

Ok thanks, I am wondering whether running multiple instances of R
would be possible without problems in presence of compiled code
(shared libraries).
Intuitively, while there can be multiple instances of R, all of them
would be using the same library, but I am just guessing, I might do a
check on this.

Ciao

Simone

>
> And let me couch my earlier statements on snow/Rmpi by saying that we use
> these tools on a relatively large beowulf cluster (~200 nodes), which is
> somewhat different than a single box with 2-4 processors, so it is may not
> be worth the trouble outside of a cluster environment.  For example, we have
> not moved to using Rmpi/snow on our dual-processor G5s because the speed
> gain just isn't worth the extra installation trouble, etc.
>
> Sean
>
>



--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From ripley at stats.ox.ac.uk  Tue Mar  7 10:15:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Mar 2006 09:15:53 +0000 (GMT)
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <3c12769c0603070059kfa51d68h8c2da372beecef29@mail.gmail.com>
References: <Pine.LNX.4.64.0603061035570.17097@homer23.u.washington.edu>
	<C031F78E.7745%sdavis2@mail.nih.gov>
	<3c12769c0603070059kfa51d68h8c2da372beecef29@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603070907380.12003@gannet.stats.ox.ac.uk>

On Tue, 7 Mar 2006, Simone Giannerini wrote:

> Ok thanks, I am wondering whether running multiple instances of R
> would be possible without problems in presence of compiled code
> (shared libraries).
> Intuitively, while there can be multiple instances of R, all of them
> would be using the same library, but I am just guessing, I might do a
> check on this.

That's what the `shared library' means.  The common parts (e.g. code and 
static data) are shared, but the data areas are not.

Different processes run in different address spaces, and modern OSes are 
careful only to give a user process write access to its own address space.

Many of us have servers running multiple copies of R at almost all times.
I typically run R tests with four copies running on a dual-CPU Opteron, 
that being about the minimum number needed to get 100% CPU usage since I/O 
is also being done.

>
> Ciao
>
> Simone
>
>>
>> And let me couch my earlier statements on snow/Rmpi by saying that we use
>> these tools on a relatively large beowulf cluster (~200 nodes), which is
>> somewhat different than a single box with 2-4 processors, so it is may not
>> be worth the trouble outside of a cluster environment.  For example, we have
>> not moved to using Rmpi/snow on our dual-processor G5s because the speed
>> gain just isn't worth the extra installation trouble, etc.
>>
>> Sean

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Tue Mar  7 11:55:42 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 07 Mar 2006 10:55:42 +0000
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
References: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
Message-ID: <440D66AE.9060904@cimr.cam.ac.uk>

Hi,

I have given up on "R" with any topic on Google quite some time
ago (because bits from fragmented postscript/pdf files show up,
for example) - but using "r-devel" with topic normally gives me
enough. YMMV.

HTL

Tim Brown wrote:
> Hi everyone,
> 
> I know this is a long shot but I just wanted to throw it out 
> there.  I have lately been using R a lot and have found that it is 
> basically impossible to find any code help or answers via google 
> searching because the name "R" is simply not explicit enough. For 
> every other popular program or programming language a simple search 
> with the name of the program and your problem brings up something 
> pretty close to the answer, its usually just a matter of phrasing it 
> so the results you are looking come up in your search (e.g. "find 
> length of array, Matlab").  Try a similar web search for R and you 
> will learn nothing -- Why? because the letter "R" is on almost every 
> web page on the planet.
> 
> I'm not just whining here, I think this is a really serious problem. 
> On the web, "findability" is perhaps the single most important 
> feature of any product or program. The unique beauty of the Web 
> anyone who solves any problem can post the answer almost anywhere 
> want, a search engines will index it and serve it up to someone 
> looking for a solution to that problem. Of course it doesn't quite 
> work like that but its pretty close if you trying to find out how to 
> program something in most languages and programs. You can't do this 
> in R because its name is not unique enough, and that seriously 
> hampers the ability of both new and expert users to accomplish things 
> quickly.  I realize that there is the R-project website and so on, 
> but the decentralized nature of the web assures that not not everyone 
> will post their answers there and people such as me who search google 
> first rather than going straight to a single site will have a hard 
> time finding answers.
> 
> So seriously, has there ever been any discussion about renaming R so 
> that people's hard work on making this kick-butt program can be 
> shared and searched with the same facility that other programs enjoy. 
> It could be something as simple as "R plus" ;) just anything that 
> makes it unique enough that R program pages aren't indexed with 100 
> billion pages that happen to have a single R on them for some reason.
> 
> Cheers,
> 
> Tim
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kriegstn at yahoo.de  Tue Mar  7 13:05:14 2006
From: kriegstn at yahoo.de (Bernd Kriegstein)
Date: Tue, 7 Mar 2006 13:05:14 +0100 (CET)
Subject: [Rd] double pointer matrix
Message-ID: <20060307120514.75381.qmail@web27413.mail.ukl.yahoo.com>

Hello,

I'm having some difficulty to understand how I could
take the proper result from the following listing:

-- cut ---
#include <stdlib.h>
#include <R.h>
#include <Rmath.h>

void retMat ( double **y, int *n, int *m, double *a,
double *b) {
        int i, j;
        y = malloc( (*n) * sizeof( double ) );
        for (i=0; i<*n; i++) {
                y[i] = malloc ( (*m) * sizeof( double
) );
        }
        
        GetRNGstate();

        for (i=0; i<*n; i++) {
                for (j=0; j<*m; j++) {
                        y[i][j] = (i+1)*(j+1)*rbeta(
*a, *b );
                }
        }
        
        PutRNGstate();
}
---
I understand that I will have to make the matrix
initialized in the double for loop above to be somehow
visible as a vector, because of the way that the
matrix elements are passed in the argument when used
in the R space. Is there a way to accomplish this?

Thanks for any answers,

- b.


From hin-tak.leung at cimr.cam.ac.uk  Tue Mar  7 14:37:25 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 07 Mar 2006 13:37:25 +0000
Subject: [Rd] double pointer matrix
In-Reply-To: <20060307120514.75381.qmail@web27413.mail.ukl.yahoo.com>
References: <20060307120514.75381.qmail@web27413.mail.ukl.yahoo.com>
Message-ID: <440D8C95.5020409@cimr.cam.ac.uk>

Please don't do malloc inside C code like this - it won't interact too 
well with the garbage collector in R, and your program probably will 
either leak or crash or both... and when are you going to do your
free()?

What you want is do is to delete that malloc line and do the
allocation on the R side, something like this (the first line does
the equivalent of your malloc allocation):

y <- double(n)
y <- .C("retMat", as.double(y), as.double(n), as.double(m), 
as.double(a), as.double(b))[1]

HTL

Bernd Kriegstein wrote:
> Hello,
> 
> I'm having some difficulty to understand how I could
> take the proper result from the following listing:
> 
> -- cut ---
> #include <stdlib.h>
> #include <R.h>
> #include <Rmath.h>
> 
> void retMat ( double **y, int *n, int *m, double *a,
> double *b) {
>         int i, j;
>         y = malloc( (*n) * sizeof( double ) );
>         for (i=0; i<*n; i++) {
>                 y[i] = malloc ( (*m) * sizeof( double
> ) );
>         }
>         
>         GetRNGstate();
> 
>         for (i=0; i<*n; i++) {
>                 for (j=0; j<*m; j++) {
>                         y[i][j] = (i+1)*(j+1)*rbeta(
> *a, *b );
>                 }
>         }
>         
>         PutRNGstate();
> }
> ---
> I understand that I will have to make the matrix
> initialized in the double for loop above to be somehow
> visible as a vector, because of the way that the
> matrix elements are passed in the argument when used
> in the R space. Is there a way to accomplish this?
> 
> Thanks for any answers,
> 
> - b.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sgiannerini at gmail.com  Tue Mar  7 14:39:13 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Tue, 7 Mar 2006 14:39:13 +0100
Subject: [Rd] Running R on dual/quad Opteron machines
In-Reply-To: <Pine.LNX.4.64.0603070907380.12003@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0603061035570.17097@homer23.u.washington.edu>
	<C031F78E.7745%sdavis2@mail.nih.gov>
	<3c12769c0603070059kfa51d68h8c2da372beecef29@mail.gmail.com>
	<Pine.LNX.4.64.0603070907380.12003@gannet.stats.ox.ac.uk>
Message-ID: <3c12769c0603070539o42fdff4cucab46ba85531bca1@mail.gmail.com>

Dear prof. Ripley,

many thanks for the clarification, now I have good elements for
managing the purchase.

kind regards,

Simone Giannerini

On 3/7/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Tue, 7 Mar 2006, Simone Giannerini wrote:
>
> > Ok thanks, I am wondering whether running multiple instances of R
> > would be possible without problems in presence of compiled code
> > (shared libraries).
> > Intuitively, while there can be multiple instances of R, all of them
> > would be using the same library, but I am just guessing, I might do a
> > check on this.
>
> That's what the `shared library' means.  The common parts (e.g. code and
> static data) are shared, but the data areas are not.
>
> Different processes run in different address spaces, and modern OSes are
> careful only to give a user process write access to its own address space.
>
> Many of us have servers running multiple copies of R at almost all times.
> I typically run R tests with four copies running on a dual-CPU Opteron,
> that being about the minimum number needed to get 100% CPU usage since I/O
> is also being done.
>
> >
> > Ciao
> >
> > Simone
> >
> >>
> >> And let me couch my earlier statements on snow/Rmpi by saying that we use
> >> these tools on a relatively large beowulf cluster (~200 nodes), which is
> >> somewhat different than a single box with 2-4 processors, so it is may not
> >> be worth the trouble outside of a cluster environment.  For example, we have
> >> not moved to using Rmpi/snow on our dual-processor G5s because the speed
> >> gain just isn't worth the extra installation trouble, etc.
> >>
> >> Sean
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From murdoch at stats.uwo.ca  Tue Mar  7 15:03:01 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Mar 2006 09:03:01 -0500
Subject: [Rd] Expanding partial names
Message-ID: <440D9295.7090207@stats.uwo.ca>

I'm writing wrappers for some functions that change some of the default 
arguments.  I'd rather not list all of the arguments for the low level 
functions because there are about a dozen wrapper functions, and about 
20 arguments to lowlevel.  Instead I'm trying something like this:

lowlevel <- function(longname = 1) {
   cat("longname = ", longname, "\n")
}

wrapper <- function(...) {
   newargs <- list(longname = 2)
   newargs[names(list(...))] <- list(...)
   do.call("lowlevel", newargs)
}

This almost works:

 > wrapper()
longname =  2
 > wrapper(longname = 3)
longname =  3

But it fails if I try to use partial argument matching:

 > wrapper(long=4)
Error in lowlevel(longname = 2, long = 4) :
         unused argument(s) (long ...)

because long isn't matched to longname.  Is there a reasonable way to do 
this (e.g. using pmatch or charmatch) other than listing all the low 
level arguments in the argument list to wrapper?

Duncan Murdoch


From charles.dupont at vanderbilt.edu  Tue Mar  7 15:39:26 2006
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Tue, 07 Mar 2006 08:39:26 -0600
Subject: [Rd] possible bug: NULL equality in lists.
Message-ID: <440D9B1E.6020001@vanderbilt.edu>

I was messing around with R and I found an example R behaving oddly:

a <- alist(NULL, "bob", c(3,6,2,3))
a
a == 'NULL'
a == "NULL"
a == 'cat'


If I create a list with a NULL value
  >a <- alist(NULL, "bob", c(3,6,2,3))
  >a
[[1]]
NULL

[[2]]
[1] "bob"

[[3]]
c(3, 6, 2, 3)

and run some tests on 'a', the '== "NULL' test returns TRUE for the NULL 
entry in the list 'a'.
  >a == 'NULL'
[1]  TRUE FALSE FALSE
  >a == "NULL"
[1]  TRUE FALSE FALSE
  >a == 'cat'
[1]  FALSE FALSE FALSE

This is consistent for every example of NULL's in a list that I can 
think of.

Is this a bug or undocumented correct behavior?

Here is my version output

platform i486-pc-linux-gnu
arch     i486
os       linux-gnu
system   i486, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R


Thanks

Charles
-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University


From ggrothendieck at gmail.com  Tue Mar  7 15:42:39 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 7 Mar 2006 09:42:39 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <440D9295.7090207@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
Message-ID: <971536df0603070642y295f4c64l74fb3e5d67b1605e@mail.gmail.com>

Try this:


wrapper <- function(...) {
  args <- list(...)
  if (length(args)) {
	  nf <- names(formals(lowlevel))
	  nams <- nf[pmatch(names(args), nf)]
	  args <- replace(list(longname = 2), nams, args)
  }
  do.call("lowlevel", args)
}

Here is a test:

> wrapper()
longname =  1
> wrapper(longname = 34)
longname =  34
> wrapper(long = 34)
longname =  34


On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I'm writing wrappers for some functions that change some of the default
> arguments.  I'd rather not list all of the arguments for the low level
> functions because there are about a dozen wrapper functions, and about
> 20 arguments to lowlevel.  Instead I'm trying something like this:
>
> lowlevel <- function(longname = 1) {
>   cat("longname = ", longname, "\n")
> }
>
> wrapper <- function(...) {
>   newargs <- list(longname = 2)
>   newargs[names(list(...))] <- list(...)
>   do.call("lowlevel", newargs)
> }
>
> This almost works:
>
>  > wrapper()
> longname =  2
>  > wrapper(longname = 3)
> longname =  3
>
> But it fails if I try to use partial argument matching:
>
>  > wrapper(long=4)
> Error in lowlevel(longname = 2, long = 4) :
>         unused argument(s) (long ...)
>
> because long isn't matched to longname.  Is there a reasonable way to do
> this (e.g. using pmatch or charmatch) other than listing all the low
> level arguments in the argument list to wrapper?
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.uni-dortmund.de  Tue Mar  7 16:13:02 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Mar 2006 16:13:02 +0100
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <440D9B1E.6020001@vanderbilt.edu>
References: <440D9B1E.6020001@vanderbilt.edu>
Message-ID: <440DA2FE.8050709@statistik.uni-dortmund.de>

Charles Dupont wrote:

> I was messing around with R and I found an example R behaving oddly:
> 
> a <- alist(NULL, "bob", c(3,6,2,3))
> a
> a == 'NULL'
> a == "NULL"
> a == 'cat'
> 


Always use is.null() to test on NULL, as in:

   sapply(a, is.null)

Uwe Ligges



> If I create a list with a NULL value
>   >a <- alist(NULL, "bob", c(3,6,2,3))
>   >a
> [[1]]
> NULL
> 
> [[2]]
> [1] "bob"
> 
> [[3]]
> c(3, 6, 2, 3)
> 
> and run some tests on 'a', the '== "NULL' test returns TRUE for the NULL 
> entry in the list 'a'.
>   >a == 'NULL'
> [1]  TRUE FALSE FALSE
>   >a == "NULL"
> [1]  TRUE FALSE FALSE
>   >a == 'cat'
> [1]  FALSE FALSE FALSE
> 
> This is consistent for every example of NULL's in a list that I can 
> think of.
> 
> Is this a bug or undocumented correct behavior?
> 
> Here is my version output
> 
> platform i486-pc-linux-gnu
> arch     i486
> os       linux-gnu
> system   i486, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
> 
> 
> Thanks
> 
> Charles


From murdoch at stats.uwo.ca  Tue Mar  7 16:12:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Mar 2006 10:12:36 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <971536df0603070642y295f4c64l74fb3e5d67b1605e@mail.gmail.com>
References: <440D9295.7090207@stats.uwo.ca>
	<971536df0603070642y295f4c64l74fb3e5d67b1605e@mail.gmail.com>
Message-ID: <440DA2E4.4030508@stats.uwo.ca>

On 3/7/2006 9:42 AM, Gabor Grothendieck wrote:
> Try this:
> 
> 
> wrapper <- function(...) {
>   args <- list(...)
>   if (length(args)) {
> 	  nf <- names(formals(lowlevel))
> 	  nams <- nf[pmatch(names(args), nf)]
> 	  args <- replace(list(longname = 2), nams, args)
>   }
>   do.call("lowlevel", args)
> }
> 
> Here is a test:
> 
>> wrapper()
> longname =  1
>> wrapper(longname = 34)
> longname =  34
>> wrapper(long = 34)
> longname =  34

Thanks, that's getting close, but it doesn't quite handle errors cleanly:

 > wrapper(junk=3)
Error in lowlevel(longname = 2, "NA" = 3) :
         unused argument(s) (NA ...)

It looks like I'll need something fairly elaborate.

Duncan Murdoch

> On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> I'm writing wrappers for some functions that change some of the default
>> arguments.  I'd rather not list all of the arguments for the low level
>> functions because there are about a dozen wrapper functions, and about
>> 20 arguments to lowlevel.  Instead I'm trying something like this:
>>
>> lowlevel <- function(longname = 1) {
>>   cat("longname = ", longname, "\n")
>> }
>>
>> wrapper <- function(...) {
>>   newargs <- list(longname = 2)
>>   newargs[names(list(...))] <- list(...)
>>   do.call("lowlevel", newargs)
>> }
>>
>> This almost works:
>>
>>  > wrapper()
>> longname =  2
>>  > wrapper(longname = 3)
>> longname =  3
>>
>> But it fails if I try to use partial argument matching:
>>
>>  > wrapper(long=4)
>> Error in lowlevel(longname = 2, long = 4) :
>>         unused argument(s) (long ...)
>>
>> because long isn't matched to longname.  Is there a reasonable way to do
>> this (e.g. using pmatch or charmatch) other than listing all the low
>> level arguments in the argument list to wrapper?
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Mar  7 16:27:06 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 7 Mar 2006 10:27:06 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <440DA2E4.4030508@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
	<971536df0603070642y295f4c64l74fb3e5d67b1605e@mail.gmail.com>
	<440DA2E4.4030508@stats.uwo.ca>
Message-ID: <971536df0603070727r7538941pbdc6e7b4ffef89e0@mail.gmail.com>

The original code was not intended to be fully finished.
It was just to give the idea so I left out the error checking.
Adding such a check is just a matter of adding an if
statement to check the pmatch for NA:

wrapper <- function(...) {
  args <- list(...)
  if (length(args)) {
     nf <- names(formals(lowlevel))
     idx <- pmatch(names(args), nf)
     if (any(is.na(idx)))
        stop(paste("Invalid names used:", names(args)[is.na(idx)]))
     nams <- nf[idx]
     args <- replace(list(longname = 2), nams, args)
  }
  do.call("lowlevel", args)
}

wrapper(long = 3)
wrapper(junk = 5)

On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/7/2006 9:42 AM, Gabor Grothendieck wrote:
> > Try this:
> >
> >
> > wrapper <- function(...) {
> >   args <- list(...)
> >   if (length(args)) {
> >         nf <- names(formals(lowlevel))
> >         nams <- nf[pmatch(names(args), nf)]
> >         args <- replace(list(longname = 2), nams, args)
> >   }
> >   do.call("lowlevel", args)
> > }
> >
> > Here is a test:
> >
> >> wrapper()
> > longname =  1
> >> wrapper(longname = 34)
> > longname =  34
> >> wrapper(long = 34)
> > longname =  34
>
> Thanks, that's getting close, but it doesn't quite handle errors cleanly:
>
>  > wrapper(junk=3)
> Error in lowlevel(longname = 2, "NA" = 3) :
>         unused argument(s) (NA ...)
>
> It looks like I'll need something fairly elaborate.
>
> Duncan Murdoch
>
> > On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> I'm writing wrappers for some functions that change some of the default
> >> arguments.  I'd rather not list all of the arguments for the low level
> >> functions because there are about a dozen wrapper functions, and about
> >> 20 arguments to lowlevel.  Instead I'm trying something like this:
> >>
> >> lowlevel <- function(longname = 1) {
> >>   cat("longname = ", longname, "\n")
> >> }
> >>
> >> wrapper <- function(...) {
> >>   newargs <- list(longname = 2)
> >>   newargs[names(list(...))] <- list(...)
> >>   do.call("lowlevel", newargs)
> >> }
> >>
> >> This almost works:
> >>
> >>  > wrapper()
> >> longname =  2
> >>  > wrapper(longname = 3)
> >> longname =  3
> >>
> >> But it fails if I try to use partial argument matching:
> >>
> >>  > wrapper(long=4)
> >> Error in lowlevel(longname = 2, long = 4) :
> >>         unused argument(s) (long ...)
> >>
> >> because long isn't matched to longname.  Is there a reasonable way to do
> >> this (e.g. using pmatch or charmatch) other than listing all the low
> >> level arguments in the argument list to wrapper?
> >>
> >> Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From sfalcon at fhcrc.org  Tue Mar  7 16:37:12 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Mar 2006 07:37:12 -0800
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <440DA2FE.8050709@statistik.uni-dortmund.de> (Uwe Ligges's
	message of "Tue, 07 Mar 2006 16:13:02 +0100")
References: <440D9B1E.6020001@vanderbilt.edu>
	<440DA2FE.8050709@statistik.uni-dortmund.de>
Message-ID: <m2wtf6w9jr.fsf@ziti.local>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Charles Dupont wrote:
>
>> I was messing around with R and I found an example R behaving oddly:
>> 
>> a <- alist(NULL, "bob", c(3,6,2,3))
>> a
>> a == 'NULL'
>> a == "NULL"
>> a == 'cat'
>> 
>
>
> Always use is.null() to test on NULL, as in:

What should I do if I want to check for the string "NULL"?

> a <- list(NULL, "NULL", NA, "NA")

> a == "NULL"
[1]  TRUE  TRUE FALSE FALSE

> a == "NA"
[1] FALSE FALSE  TRUE  TRUE

These are because of as.character:

> as.character(a)
[1] "NULL" "NULL" "NA"   "NA"  

Yet,

> as.character(NULL)
character(0)
> as.character(NA)
[1] NA



+ seth


From dimitris.rizopoulos at med.kuleuven.be  Tue Mar  7 16:46:03 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 7 Mar 2006 16:46:03 +0100
Subject: [Rd] possible bug: NULL equality in lists.
References: <440D9B1E.6020001@vanderbilt.edu><440DA2FE.8050709@statistik.uni-dortmund.de>
	<m2wtf6w9jr.fsf@ziti.local>
Message-ID: <004101c641fe$3d60f1e0$0540210a@www.domain>

I think it'd be more appropriate to use:

sapply(a, "==", "NULL")

or

sapply(a, "==", "NA")

for this case.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Seth Falcon" <sfalcon at fhcrc.org>
To: <r-devel at stat.math.ethz.ch>
Sent: Tuesday, March 07, 2006 4:37 PM
Subject: Re: [Rd] possible bug: NULL equality in lists.


> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
>
>> Charles Dupont wrote:
>>
>>> I was messing around with R and I found an example R behaving 
>>> oddly:
>>>
>>> a <- alist(NULL, "bob", c(3,6,2,3))
>>> a
>>> a == 'NULL'
>>> a == "NULL"
>>> a == 'cat'
>>>
>>
>>
>> Always use is.null() to test on NULL, as in:
>
> What should I do if I want to check for the string "NULL"?
>
>> a <- list(NULL, "NULL", NA, "NA")
>
>> a == "NULL"
> [1]  TRUE  TRUE FALSE FALSE
>
>> a == "NA"
> [1] FALSE FALSE  TRUE  TRUE
>
> These are because of as.character:
>
>> as.character(a)
> [1] "NULL" "NULL" "NA"   "NA"
>
> Yet,
>
>> as.character(NULL)
> character(0)
>> as.character(NA)
> [1] NA
>
>
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ligges at statistik.uni-dortmund.de  Tue Mar  7 16:50:34 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Mar 2006 16:50:34 +0100
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <m2wtf6w9jr.fsf@ziti.local>
References: <440D9B1E.6020001@vanderbilt.edu>	<440DA2FE.8050709@statistik.uni-dortmund.de>
	<m2wtf6w9jr.fsf@ziti.local>
Message-ID: <440DABCA.6030108@statistik.uni-dortmund.de>

Seth Falcon wrote:

> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> 
> 
>>Charles Dupont wrote:
>>
>>
>>>I was messing around with R and I found an example R behaving oddly:
>>>
>>>a <- alist(NULL, "bob", c(3,6,2,3))
>>>a
>>>a == 'NULL'
>>>a == "NULL"
>>>a == 'cat'
>>>
>>
>>
>>Always use is.null() to test on NULL, as in:
> 
> 
> What should I do if I want to check for the string "NULL"?

These are all dangerous, hence use the "safe" ways:

sapply(a, is.null)
sapply(a, identical, "NULL")
sapply(a, is.na)
sapply(a, identical, "NA")

Best,
Uwe



> 
>>a <- list(NULL, "NULL", NA, "NA")
> 
> 
>>a == "NULL"
> 
> [1]  TRUE  TRUE FALSE FALSE
> 
> 
>>a == "NA"
> 
> [1] FALSE FALSE  TRUE  TRUE
> 
> These are because of as.character:
> 
> 
>>as.character(a)
> 
> [1] "NULL" "NULL" "NA"   "NA"  
> 
> Yet,
> 
> 
>>as.character(NULL)
> 
> character(0)
> 
>>as.character(NA)
> 
> [1] NA
> 
> 
> + seth
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Tue Mar  7 17:50:03 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 07 Mar 2006 08:50:03 -0800
Subject: [Rd] validObject does not check validity of slots
In-Reply-To: <440CDC8B.9080905@r-project.org> (John Chambers's message of
	"Mon, 06 Mar 2006 20:06:19 -0500")
References: <6phk6b7zf22.fsf@gopher3.fhcrc.org>
	<440CDC8B.9080905@r-project.org>
Message-ID: <6ph1wxeyzb8.fsf@gopher3.fhcrc.org>

Thanks John for the reply and explanation. I sometimes use validObject
interactively, and in those circumstances it might be nice to be able
to require recursive validity checking, e.g., with an optional
argument.

Martin

John Chambers <jmc at r-project.org> writes:

> The problem is over-ambitious documentation.? Recursively running
> the checks on slots for all validObject calls would be a fairly
> serious efficiency hit.? Objects are checked for validity when
> created, other than as the default object, so assuming the slot
> objects to be as claimed is reasonable if they haven't been
> corrupted later on.? We'll update the documentation.
>
> Validity checking is a tricky business in general.? R validates new
> objects, but users can turn valid objects into invalid objects in
> cases where slots have to match in special ways (you can't apply
> validObject each time a slot changes, since the change may be part
> of a bigger computation that _will_ produce a valid object).?
> Similarly, constraints on the elements can't be checked each time an
> element or subset of the object changes, if the changes have to be
> done in stages. ? Systems that "commit" top-level assignments can
> check then, but R does not have that distinction.
>
> Martin Morgan wrote:
>
>           The documentation for validObject suggests that slots are
> checked for validity, but validObject seems only to check that the
> slot has something claiming to be correct; validObject(obj) does not
> perform the equivalent of validObject(obj at y) for slot y.
>
> This is also the second problem issue reported in
>
> http://tolstoy.newcastle.edu.au/R/devel/05/03/0151.html
>
> Relevant documentation, an example, and sessionInfo follow.
>
> Martin
>
> validObject             package:methods             R Documentation
>
> Arguments:
>      ...
>      Note that validity methods do not have to check validity of any
>      slots or superclasses:  the logic of 'validObject' ensures these
>      tests are done once only.
>      ...
> Details:
>
>      Validity testing takes place "bottom up":  first the validity of
>      the object's slots, if any, is tested.  
>      ...
>
> setClass("foo",
>          representation( x="numeric" ),
>          validity = function( object ) object at x > 0 )
> setClass("bar",
>          representation( y="foo", z="numeric" ),
>          validity = function( object ) object at z > 0 )
> obj <- new( "bar", y = new( "foo", x=1 ), z = 1 )
>
> and then...
>
>   
>
>                     validObject( obj )
>     
>
>
>      [1] TRUE
> ## invalidate obj at y
>   
>
>                     obj at y@x <- -1
> validObject( obj at y )                  # right, this is not valid
>     
>
>
>      Error in validObject(obj at y) : invalid class "foo" object: FALSE
>   
>
>                     ## obj at y is invalid, but obj is valid?
> validObject( obj )                    # should be invalid?
>     
>
>
>      [1] TRUE
>
>
>
>   
>
>                     sessionInfo()
>     
>
>
>      Version 2.3.0 Under development (unstable) (2006-03-03 r37471) 
> x86_64-unknown-linux-gnu 
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
> [7] "base"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From sfalcon at fhcrc.org  Tue Mar  7 17:56:32 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Mar 2006 08:56:32 -0800
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <440DABCA.6030108@statistik.uni-dortmund.de> (Uwe Ligges's
	message of "Tue, 07 Mar 2006 16:50:34 +0100")
References: <440D9B1E.6020001@vanderbilt.edu>
	<440DA2FE.8050709@statistik.uni-dortmund.de>
	<m2wtf6w9jr.fsf@ziti.local>
	<440DABCA.6030108@statistik.uni-dortmund.de>
Message-ID: <m2slpuw5vj.fsf@ziti.local>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> These are all dangerous, hence use the "safe" ways:
>
> sapply(a, is.null)
> sapply(a, identical, "NULL")
> sapply(a, is.na)
> sapply(a, identical, "NA")

Point taken, but is the behavior of as.character correct?

as.character(list(NULL))

as.character(NULL)

+ seth


From charles.dupont at vanderbilt.edu  Tue Mar  7 18:08:03 2006
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Tue, 07 Mar 2006 11:08:03 -0600
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <440DABCA.6030108@statistik.uni-dortmund.de>
References: <440D9B1E.6020001@vanderbilt.edu>	<440DA2FE.8050709@statistik.uni-dortmund.de>	<m2wtf6w9jr.fsf@ziti.local>
	<440DABCA.6030108@statistik.uni-dortmund.de>
Message-ID: <440DBDF3.1010608@vanderbilt.edu>

Uwe Ligges wrote:
> Seth Falcon wrote:
> 
> 
>>Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
>>
>>
>>
>>>Charles Dupont wrote:
>>>
>>>
>>>
>>>>I was messing around with R and I found an example R behaving oddly:
>>>>
>>>>a <- alist(NULL, "bob", c(3,6,2,3))
>>>>a
>>>>a == 'NULL'
>>>>a == "NULL"
>>>>a == 'cat'
>>>>
>>>
>>>
>>>Always use is.null() to test on NULL, as in:
>>
>>
>>What should I do if I want to check for the string "NULL"?
> 
> 
> These are all dangerous, hence use the "safe" ways:
> 
> sapply(a, is.null)
> sapply(a, identical, "NULL")
> sapply(a, is.na)
> sapply(a, identical, "NA")
> 
> Best,
> Uwe

For the NA list problem.  It would be better if 'as.character' when
converting a list when it finds a NA value to set that element to the
string NA value not "NA" the string.


Charles

> 
> 
>>>a <- list(NULL, "NULL", NA, "NA")
>>
>>
>>>a == "NULL"
>>
>>[1]  TRUE  TRUE FALSE FALSE
>>
>>
>>
>>>a == "NA"
>>
>>[1] FALSE FALSE  TRUE  TRUE
>>
>>These are because of as.character:
>>
>>
>>
>>>as.character(a)
>>
>>[1] "NULL" "NULL" "NA"   "NA"  
>>
>>Yet,
>>
>>
>>
>>>as.character(NULL)
>>
>>character(0)
>>
>>
>>>as.character(NA)
>>
>>[1] NA
>>
>>
>>+ seth
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University


From charles.dupont at vanderbilt.edu  Tue Mar  7 18:08:41 2006
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Tue, 07 Mar 2006 11:08:41 -0600
Subject: [Rd] Expanding partial names
In-Reply-To: <440D9295.7090207@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
Message-ID: <440DBE19.6070308@vanderbilt.edu>

Duncan Murdoch wrote:
> I'm writing wrappers for some functions that change some of the default 
> arguments.  I'd rather not list all of the arguments for the low level 
> functions because there are about a dozen wrapper functions, and about 
> 20 arguments to lowlevel.  Instead I'm trying something like this:
> 
> lowlevel <- function(longname = 1) {
>    cat("longname = ", longname, "\n")
> }
> 
> wrapper <- function(...) {
>    newargs <- list(longname = 2)
>    newargs[names(list(...))] <- list(...)
>    do.call("lowlevel", newargs)
> }
> 
> This almost works:
> 
>  > wrapper()
> longname =  2
>  > wrapper(longname = 3)
> longname =  3
> 
> But it fails if I try to use partial argument matching:
> 
>  > wrapper(long=4)
> Error in lowlevel(longname = 2, long = 4) :
>          unused argument(s) (long ...)
> 
> because long isn't matched to longname.  Is there a reasonable way to do 
> this (e.g. using pmatch or charmatch) other than listing all the low 
> level arguments in the argument list to wrapper?
> 
> Duncan Murdoch

If all you are doing is changing the default values of some arguments
this should work.

wrapper <- lowlevel
formals(wrapper) <- replace(formals(lowlevel), c("longname"), list(2))

Charles


From ligges at statistik.uni-dortmund.de  Tue Mar  7 18:12:55 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Mar 2006 18:12:55 +0100
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <m2slpuw5vj.fsf@ziti.local>
References: <440D9B1E.6020001@vanderbilt.edu>	<440DA2FE.8050709@statistik.uni-dortmund.de>	<m2wtf6w9jr.fsf@ziti.local>	<440DABCA.6030108@statistik.uni-dortmund.de>
	<m2slpuw5vj.fsf@ziti.local>
Message-ID: <440DBF17.9080400@statistik.uni-dortmund.de>

Seth Falcon wrote:

> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> 
>>These are all dangerous, hence use the "safe" ways:
>>
>>sapply(a, is.null)
>>sapply(a, identical, "NULL")
>>sapply(a, is.na)
>>sapply(a, identical, "NA")
> 
> 
> Point taken, but is the behavior of as.character correct?
> 
> as.character(list(NULL))
> 
> as.character(NULL)


I thought about it quite a while. I think the current bahaviour is quite 
OK. What should as.character do in the follwing case:
   as.character(list("A", NA, NULL))
?

Note that it only can return a character vector...!

So, should it return a character vector of length 2? That's a bad idea, 
if the length is reduced.

Moreover, as.character() does not get a NA or a NULL object for coercion 
but an element of type list that itself conatins NA or NULL...

So if you want to convert a list to character and *keep* NA/NULL values, 
you can only say:

  lapply(a, as.character)

Uwe






> + seth
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Tue Mar  7 18:31:24 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 7 Mar 2006 11:31:24 -0600
Subject: [Rd] Expanding partial names
In-Reply-To: <440DA2E4.4030508@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
	<971536df0603070642y295f4c64l74fb3e5d67b1605e@mail.gmail.com>
	<440DA2E4.4030508@stats.uwo.ca>
Message-ID: <f8e6ff050603070931s590c916m6f8de408cb2b287d@mail.gmail.com>

Here's a slightly different approach:

lowlevel <- function(longname = 1, ...) {
  cat("longname = ", longname, "\n")
}

wrapper <- function(...) {
  newargs <- defaults(list(...), list(longname = 2))
  do.call("lowlevel", newargs)
}

defaults <- function(x, defaults)  {
	if (length(x) == 0) return(defaults)
	names(x) <- ifelse(is.na(pmatch(names(x), names(defaults))),
names(x), names(defaults))
	c(x, defaults[setdiff(names(defaults), names(x))])
}

wrapper()
wrapper(longname=20)
wrapper(long=20)
wrapper(junk=3)


Hadley


From sfalcon at fhcrc.org  Tue Mar  7 19:23:00 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Mar 2006 10:23:00 -0800
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <440DBF17.9080400@statistik.uni-dortmund.de> (Uwe Ligges's
	message of "Tue, 07 Mar 2006 18:12:55 +0100")
References: <440D9B1E.6020001@vanderbilt.edu>
	<440DA2FE.8050709@statistik.uni-dortmund.de>
	<m2wtf6w9jr.fsf@ziti.local>
	<440DABCA.6030108@statistik.uni-dortmund.de>
	<m2slpuw5vj.fsf@ziti.local>
	<440DBF17.9080400@statistik.uni-dortmund.de>
Message-ID: <m28xrmw1vf.fsf@ziti.local>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
>> Point taken, but is the behavior of as.character correct?
>> as.character(list(NULL))
>> as.character(NULL)
>
>
> I thought about it quite a while. I think the current bahaviour is
> quite OK. What should as.character do in the follwing case:
>    as.character(list("A", NA, NULL))
> ?
>
> Note that it only can return a character vector...!
>
> So, should it return a character vector of length 2? That's a bad
> idea, if the length is reduced.

But consistent with vectorizing a list using unlist:

unlist(list(NULL, NULL, "a"))
[1] "a"

> Moreover, as.character() does not get a NA or a NULL object for
> coercion but an element of type list that itself conatins NA or
> NULL...

In the case of NA, I think converting to "NA" should be a last
resort.  Since NA is a perfectly valid element of a character vector,
it would seem to be a better choice.


From ligges at statistik.uni-dortmund.de  Tue Mar  7 19:37:02 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Mar 2006 19:37:02 +0100
Subject: [Rd] possible bug: NULL equality in lists.
In-Reply-To: <m28xrmw1vf.fsf@ziti.local>
References: <440D9B1E.6020001@vanderbilt.edu>	<440DA2FE.8050709@statistik.uni-dortmund.de>	<m2wtf6w9jr.fsf@ziti.local>	<440DABCA.6030108@statistik.uni-dortmund.de>	<m2slpuw5vj.fsf@ziti.local>	<440DBF17.9080400@statistik.uni-dortmund.de>
	<m28xrmw1vf.fsf@ziti.local>
Message-ID: <440DD2CE.9040503@statistik.uni-dortmund.de>

Seth Falcon wrote:

> Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:
> 
>>>Point taken, but is the behavior of as.character correct?
>>>as.character(list(NULL))
>>>as.character(NULL)
>>
>>
>>I thought about it quite a while. I think the current bahaviour is
>>quite OK. What should as.character do in the follwing case:
>>   as.character(list("A", NA, NULL))
>>?
>>
>>Note that it only can return a character vector...!
>>
>>So, should it return a character vector of length 2? That's a bad
>>idea, if the length is reduced.
> 
> 
> But consistent with vectorizing a list using unlist:
> 
> unlist(list(NULL, NULL, "a"))
> [1] "a"


Seth, as.character() does NOT unlist anything, it converts the *list* 
objects to character, the one element case might be a to trivial 
example, instead consider:


 > as.character(list(c("a", "b"), NULL, c(NA, NULL, 2)))
[1] "c(\"a\", \"b\")" "NULL"            "c(NA, 2)"

I think you simply should not apply as.character on a list as a whole in 
order to get what you are expecting ...

Best,
Uwe




>>Moreover, as.character() does not get a NA or a NULL object for
>>coercion but an element of type list that itself conatins NA or
>>NULL...
> 
> 
> In the case of NA, I think converting to "NA" should be a last
> resort.  Since NA is a perfectly valid element of a character vector,
> it would seem to be a better choice.



> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue Mar  7 19:59:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Mar 2006 13:59:36 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <440DBE19.6070308@vanderbilt.edu>
References: <440D9295.7090207@stats.uwo.ca> <440DBE19.6070308@vanderbilt.edu>
Message-ID: <440DD818.9010100@stats.uwo.ca>

On 3/7/2006 12:08 PM, Charles Dupont wrote:
> Duncan Murdoch wrote:
>> I'm writing wrappers for some functions that change some of the default 
>> arguments.  I'd rather not list all of the arguments for the low level 
>> functions because there are about a dozen wrapper functions, and about 
>> 20 arguments to lowlevel.  Instead I'm trying something like this:
>> 
>> lowlevel <- function(longname = 1) {
>>    cat("longname = ", longname, "\n")
>> }
>> 
>> wrapper <- function(...) {
>>    newargs <- list(longname = 2)
>>    newargs[names(list(...))] <- list(...)
>>    do.call("lowlevel", newargs)
>> }
>> 
>> This almost works:
>> 
>>  > wrapper()
>> longname =  2
>>  > wrapper(longname = 3)
>> longname =  3
>> 
>> But it fails if I try to use partial argument matching:
>> 
>>  > wrapper(long=4)
>> Error in lowlevel(longname = 2, long = 4) :
>>          unused argument(s) (long ...)
>> 
>> because long isn't matched to longname.  Is there a reasonable way to do 
>> this (e.g. using pmatch or charmatch) other than listing all the low 
>> level arguments in the argument list to wrapper?
>> 
>> Duncan Murdoch
> 
> If all you are doing is changing the default values of some arguments
> this should work.
> 
> wrapper <- lowlevel
> formals(wrapper) <- replace(formals(lowlevel), c("longname"), list(2))

Thanks for the suggestion, but the calculation of the new defaults is 
more involved than my example indicated.  I really need to do some 
computation within the wrapper to come up with the new defaults.

Duncan Murdoch


From deepayan.sarkar at gmail.com  Tue Mar  7 20:00:46 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 7 Mar 2006 13:00:46 -0600
Subject: [Rd] Expanding partial names
In-Reply-To: <440D9295.7090207@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
Message-ID: <eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>



On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I'm writing wrappers for some functions that change some of the default 
> arguments.  I'd rather not list all of the arguments for the low level 
> functions because there are about a dozen wrapper functions, and about 
> 20 arguments to lowlevel.  Instead I'm trying something like this:
> 
> lowlevel <- function(longname = 1) {
>    cat("longname = ", longname, "\n")
> }
> 
> wrapper <- function(...) {
>    newargs <- list(longname = 2)
>    newargs[names(list(...))] <- list(...)
>    do.call("lowlevel", newargs)
> }
> 
> This almost works:
> 
>  > wrapper()
> longname =  2
>  > wrapper(longname = 3)
> longname =  3
> 
> But it fails if I try to use partial argument matching:
> 
>  > wrapper(long=4)
> Error in lowlevel(longname = 2, long = 4) :
>          unused argument(s) (long ...)
> 
> because long isn't matched to longname.  Is there a reasonable way to do 
> this (e.g. using pmatch or charmatch) other than listing all the low 
> level arguments in the argument list to wrapper?

One trick I often use that is different from any of the suggestions I have seen so far (and is more transparent IMO) is the following:


lowlevel <- function(longname = 1) {
   cat("longname = ", longname, "\n")
}

wrapper <- function(...) {
    newArgs <-
        function(longname = 2, ...)
            list(longname = longname,
                 ...)
    do.call("lowlevel", newArgs(...))
}

which gives:

> wrapper()
longname =  2 
> wrapper(longname = 3)
longname =  3 
> wrapper(long=20)
longname =  20 
> wrapper(junk=3)
Error in lowlevel(longname = 2, junk = 3) : 
	unused argument(s) (junk ...)

-Deepayan


From mschwartz at mn.rr.com  Tue Mar  7 21:30:09 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 07 Mar 2006 14:30:09 -0600
Subject: [Rd] R started in terminal shell script or ESS steps on
	LD_LIBRARY_PATH?
Message-ID: <1141763409.4501.85.camel@localhost.localdomain>

Hi all,

Just noted this behavior in the past couple of days, where if R is
started in a shell script such as:

  gnome-terminal [-e][-x] R

or in ESS (version 5.2.12 with Emacs or XEmacs), the LD_LIBRARY_PATH
environment variable is not properly appended to, resulting in the loss
of the pre-start value.

This is using R Version 2.2.1 Patched (2006-02-28 r37448) on FC4.

I noted this when attempting to access an Oracle 10g server using RODBC
(version 1.1-5) and to the best of my recollection, this is a new
problem.

It took me a while to figure this out and was about to send an e-mail to
r-sig-db since I was having trouble connecting using odbcConnect(), when
I noted the problem with LD_LIBRARY_PATH. I noted this quite by accident
as I was writing the e-mail to r-sig-db.

I was on the verge of mental vapor lock with this, so if I missed a
documented change in behavior, my apologies. In looking at the R startup
script, it seems appropriate in terms of appending to the existing
value. So it seems that this is being altered elsewhere presumably.



In the two cases I note above, I get:

> Sys.getenv("LD_LIBRARY_PATH")
                                     LD_LIBRARY_PATH 
"/usr/local/lib/R/lib:/usr/local/lib:/usr/X11R6/lib"


whereas the pre-start value is:

  LD_LIBRARY_PATH=/usr/lib/oracle/10.2.0.1/client/lib



Importantly, if I start a gnome-terminal session and then start R from
the command line, I get:

> Sys.getenv("LD_LIBRARY_PATH")

LD_LIBRARY_PATH
"/usr/local/lib/R/lib:/usr/local/lib:/usr/X11R6/lib:/usr/lib/oracle/10.2.0.1/client/lib"


In this case, I can use odbcConnect() to the Oracle server and it works
the first time, every time.

This suggests to me some type of problem in the inheritance of the
pre-session environment in the two former cases, but again, I may be
missing something.


Even if I try:

LD_LIBRARY_PATH <- Sys.getenv("LD_LIBRARY_PATH")

Sys.putenv(LD_LIBRARY_PATH = paste(LD_LIBRARY_PATH,
           "/usr/lib/oracle/10.2.0.1/client/lib", sep = ":"))

and then:

> Sys.getenv("LD_LIBRARY_PATH")

LD_LIBRARY_PATH 
"/usr/local/lib/R/lib:/usr/local/lib:/usr/X11R6/lib:/usr/lib/oracle/10.2.0.1/client/lib" 


I still cannot get odbcConnect() to work. I still get the error that I
was getting in the two initial R startup situations:

Warning messages:
1: [RODBC] ERROR: state 01000, code 0, message [unixODBC][Driver
Manager]Can't open lib
'/usr/lib/oracle/10.2.0.1/client/lib/libsqora.so.10.1' :
libclntsh.so.10.1: cannot open shared object file: No such file or
directory 
2: ODBC connection failed in: odbcDriverConnect(st, case = case,
believeNRows = believeNRows)


The above error is what has been driving me nuts for the past two days,
since clearly these files are present and it works in R from the
gnome-terminal command line and when using the sql*plus instant client
directly.  The LD_LIBRARY_PATH issue is the only one that I have noted
that appears to be different.


Any ideas on this?  Did I miss a change someplace?

Thanks for any insights.

Marc Schwartz


From jmc at r-project.org  Tue Mar  7 22:33:59 2006
From: jmc at r-project.org (John Chambers)
Date: Tue, 07 Mar 2006 16:33:59 -0500
Subject: [Rd] validObject does not check validity of slots
In-Reply-To: <6ph1wxeyzb8.fsf@gopher3.fhcrc.org>
References: <6phk6b7zf22.fsf@gopher3.fhcrc.org>
	<440CDC8B.9080905@r-project.org> <6ph1wxeyzb8.fsf@gopher3.fhcrc.org>
Message-ID: <440DFC47.9060501@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060307/7315b833/attachment.pl

From maechler at stat.math.ethz.ch  Tue Mar  7 22:59:10 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Mar 2006 22:59:10 +0100
Subject: [Rd] validObject does not check validity of slots
In-Reply-To: <440DFC47.9060501@r-project.org>
References: <6phk6b7zf22.fsf@gopher3.fhcrc.org>
	<440CDC8B.9080905@r-project.org>
	<6ph1wxeyzb8.fsf@gopher3.fhcrc.org>
	<440DFC47.9060501@r-project.org>
Message-ID: <17422.558.399660.933037@stat.math.ethz.ch>

>>>>> "JMC" == John Chambers <jmc at r-project.org>
>>>>>     on Tue, 07 Mar 2006 16:33:59 -0500 writes:

    JMC> Martin Morgan wrote:
    >> Thanks John for the reply and explanation. I sometimes
    >> use validObject interactively, and in those circumstances
    >> it might be nice to be able to require recursive validity
    >> checking, e.g., with an optional argument.
    >> 
    >> 

    JMC> Sounds reasonable.  After some complicated replacements
    JMC> of slots at various levels, it would make sense to do a
    JMC> more complete test, and it does have to be done
    JMC> explicitly.

    JMC> It looks straightforward to have an argument complete=
    JMC> that defaults to FALSE; if so, I'll add it to r-devel.

I agree with the other Martin that this would be "nice" to have.
Also for debugging purposes, or as "watch point" when developing
new functionality.

Martin Maechler, ETH Zurich

    >> Martin
    >> 
    >> John Chambers <jmc at r-project.org> writes:
    >> 
    >> 
    >> 
    >>> The problem is over-ambitious documentation.
    >>> Recursively running the checks on slots for all
    >>> validObject calls would be a fairly serious efficiency
    >>> hit.  Objects are checked for validity when created,
    >>> other than as the default object, so assuming the slot
    >>> objects to be as claimed is reasonable if they haven't
    >>> been corrupted later on.  We'll update the
    >>> documentation.
    >>> 
    >>> Validity checking is a tricky business in general.  R
    >>> validates new objects, but users can turn valid objects
    >>> into invalid objects in cases where slots have to match
    >>> in special ways (you can't apply validObject each time a
    >>> slot changes, since the change may be part of a bigger
    >>> computation that _will_ produce a valid object).
    >>> Similarly, constraints on the elements can't be checked
    >>> each time an element or subset of the object changes, if
    >>> the changes have to be done in stages.  Systems that
    >>> "commit" top-level assignments can check then, but R
    >>> does not have that distinction.
    >>> 
    >>> Martin Morgan wrote:
    >>> 
    >>> The documentation for validObject suggests that slots
    >>> are checked for validity, but validObject seems only to
    >>> check that the slot has something claiming to be
    >>> correct; validObject(obj) does not perform the
    >>> equivalent of validObject(obj at y) for slot y.
    >>> 
    >>> This is also the second problem issue reported in
    >>> 
    >>> http://tolstoy.newcastle.edu.au/R/devel/05/03/0151.html
    >>> 
    >>> Relevant documentation, an example, and sessionInfo
    >>> follow.
    >>> 
    >>> Martin
    >>> 
    >>> validObject package:methods R Documentation
    >>> 
    >>> Arguments: ...  Note that validity methods do not have
    >>> to check validity of any slots or superclasses: the
    >>> logic of 'validObject' ensures these tests are done once
    >>> only.  ...  Details:
    >>> 
    >>> Validity testing takes place "bottom up": first the
    >>> validity of the object's slots, if any, is tested.  ...
    >>> 
    >>> setClass("foo", representation( x="numeric" ), validity
    >>> = function( object ) object at x > 0 ) setClass("bar",
    >>> representation( y="foo", z="numeric" ), validity =
    >>> function( object ) object at z > 0 ) obj <- new( "bar", y =
    >>> new( "foo", x=1 ), z = 1 )
    >>> 
    >>> and then...
    >>> 
    >>> 
    >>> 
    >>> validObject( obj )
    >>> 
    >>> 
    >>> 
    >>> [1] TRUE ## invalidate obj at y
    >>> 
    >>> 
    >>> obj at y@x <- -1 validObject( obj at y ) # right, this is not
    >>> valid
    >>> 
    >>> 
    >>> 
    >>> Error in validObject(obj at y) : invalid class "foo"
    >>> object: FALSE
    >>> 
    >>> 
    >>> ## obj at y is invalid, but obj is valid?  validObject( obj
    >>> ) # should be invalid?
    >>> 
    >>> 
    >>> 
    >>> [1] TRUE
    >>> 
    >>> 
    >>> 
    >>> 
    >>> 
    >>> sessionInfo()
    >>> 
    >>> 
    >>> 
    >>> Version 2.3.0 Under development (unstable) (2006-03-03
    >>> r37471) x86_64-unknown-linux-gnu
    >>> 
    >>> attached base packages: [1] "methods" "stats" "graphics"
    >>> "grDevices" "utils" "datasets" [7] "base"
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>> 
    >>> 
    >>> 
    >>  ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 
    >> 

    JMC> 	[[alternative HTML version deleted]]

    JMC> ______________________________________________
    JMC> R-devel at r-project.org mailing list
    JMC> https://stat.ethz.ch/mailman/listinfo/r-devel


From ch-r-devel at bobobeach.com  Tue Mar  7 23:31:05 2006
From: ch-r-devel at bobobeach.com (Cyrus Harmon)
Date: Tue, 7 Mar 2006 14:31:05 -0800
Subject: [Rd] SVN troubles
Message-ID: <BA80E707-F63B-47DB-A7B0-5CF96DD74F64@bobobeach.com>


Dear r-devel,

Sorry to trouble the list with this, but I've been beating my head  
against the wall trying to figure out what's wrong. When I try to  
connect to the R SVN server, I get the following message:

(sly at cornas):~/src/R$ svn co https://svn.r-project.org/R/trunk r-devel
svn: PROPFIND request failed on '/R/trunk'
svn: PROPFIND of '/R/trunk': SSL negotiation failed: SSL error: bad  
signature (https://svn.r-project.org)

on other boxes, things are fine. I've tried two different versions of  
svn on this box, 1.2.3 and 1.3.0, to no avail. Any suggestions would  
be greatly appreciated. Perhaps SSL is broken here, but I can't seem  
to figure out how to get any better diagnostics for this.

Thanks,

Cyrus


From sfalcon at fhcrc.org  Wed Mar  8 00:46:50 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 07 Mar 2006 15:46:50 -0800
Subject: [Rd] SVN troubles
In-Reply-To: <BA80E707-F63B-47DB-A7B0-5CF96DD74F64@bobobeach.com> (Cyrus
	Harmon's message of "Tue, 7 Mar 2006 14:31:05 -0800")
References: <BA80E707-F63B-47DB-A7B0-5CF96DD74F64@bobobeach.com>
Message-ID: <m2bqwhes2d.fsf@ziti.local>

Cyrus Harmon <ch-r-devel at bobobeach.com> writes:

> Dear r-devel,
>
> Sorry to trouble the list with this, but I've been beating my head  
> against the wall trying to figure out what's wrong. When I try to  
> connect to the R SVN server, I get the following message:
>
> (sly at cornas):~/src/R$ svn co https://svn.r-project.org/R/trunk r-devel
> svn: PROPFIND request failed on '/R/trunk'
> svn: PROPFIND of '/R/trunk': SSL negotiation failed: SSL error: bad  
> signature (https://svn.r-project.org)

You could try going to that URL with a web browser on that system.
You could also see what is inside your ~/.subversion directory on that
system.  Perhaps a cached cert is invalid and preventing ssl auth.

+ seth


From murdoch at stats.uwo.ca  Wed Mar  8 01:15:48 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Mar 2006 19:15:48 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>
References: <440D9295.7090207@stats.uwo.ca>
	<eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>
Message-ID: <440E2234.5090406@stats.uwo.ca>

On 3/7/2006 2:00 PM, Deepayan Sarkar wrote:
> 
> On 3/7/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> I'm writing wrappers for some functions that change some of the default 
>> arguments.  I'd rather not list all of the arguments for the low level 
>> functions because there are about a dozen wrapper functions, and about 
>> 20 arguments to lowlevel.  Instead I'm trying something like this:
>>
>> lowlevel <- function(longname = 1) {
>>    cat("longname = ", longname, "\n")
>> }
>>
>> wrapper <- function(...) {
>>    newargs <- list(longname = 2)
>>    newargs[names(list(...))] <- list(...)
>>    do.call("lowlevel", newargs)
>> }
>>
>> This almost works:
>>
>>  > wrapper()
>> longname =  2
>>  > wrapper(longname = 3)
>> longname =  3
>>
>> But it fails if I try to use partial argument matching:
>>
>>  > wrapper(long=4)
>> Error in lowlevel(longname = 2, long = 4) :
>>          unused argument(s) (long ...)
>>
>> because long isn't matched to longname.  Is there a reasonable way to do 
>> this (e.g. using pmatch or charmatch) other than listing all the low 
>> level arguments in the argument list to wrapper?
> 
> One trick I often use that is different from any of the suggestions I have seen so far (and is more transparent IMO) is the following:

Thanks, this is a nice idea.  It looks as though it would combine well 
with Charles Duponts' suggestion to change the formals, i.e. I could 
have a generic version of your newArgs function, then change the formals 
and the body to match the pattern you used.

One thing I'd like is to be able to put the new defaults in a list, 
because this code is going to show up in about a dozen places, and I 
don't want to have to edit all of them when the arg list of the low 
level function changes.  So really I want something like

newArgs(..., newDefaults)

where newDefaults is a tagged list (e.g. list(longname = 2) for the 
example below), and the return value is a list containing all the names 
in newDefaults, perhaps with their values modified according to the args 
passed in ... .

In the actual use newDefaults would be the result of a function call 
(the user will have made some configuration choices and I want those to 
be used as defaults to another function) but that's not so important 
here.  I'd like the wrapper to be a bit like par(), though I notice that 
par() doesn't accept partial name matching so maybe I'm worrying about 
something I shouldn't.

Duncan Murdoch

> 
> 
> lowlevel <- function(longname = 1) {
>    cat("longname = ", longname, "\n")
> }
> 
> wrapper <- function(...) {
>     newArgs <-
>         function(longname = 2, ...)
>             list(longname = longname,
>                  ...)
>     do.call("lowlevel", newArgs(...))
> }
> 
> which gives:
> 
>> wrapper()
> longname =  2 
>> wrapper(longname = 3)
> longname =  3 
>> wrapper(long=20)
> longname =  20 
>> wrapper(junk=3)
> Error in lowlevel(longname = 2, junk = 3) : 
> 	unused argument(s) (junk ...)
> 
> -Deepayan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Wed Mar  8 03:02:48 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Mar 2006 20:02:48 -0600
Subject: [Rd] Wishlist - Give R a name that shows up in search engines...
In-Reply-To: <440D66AE.9060904@cimr.cam.ac.uk>
References: <6.2.5.6.0.20060306134952.04a69380@dandelion.org>
	<440D66AE.9060904@cimr.cam.ac.uk>
Message-ID: <17422.15176.16654.86702@basebud.nulle.part>


On 7 March 2006 at 10:55, Hin-Tak Leung wrote:
| I have given up on "R" with any topic on Google quite some time
| ago (because bits from fragmented postscript/pdf files show up,
| for example) - but using "r-devel" with topic normally gives me
| enough. YMMV.

Nobody seems to have mentioned the RSiteSearch() function which automagically
restrict the search to domains relevant to the contect of "our" use of the
letter R. I quite like that as I tend to have an R prompt open when I am
puzzled by R questions ...

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From andy_liaw at merck.com  Wed Mar  8 03:15:18 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 7 Mar 2006 21:15:18 -0500
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
 ...
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>

From: Dirk Eddelbuettel
> 
> On 7 March 2006 at 10:55, Hin-Tak Leung wrote:
> | I have given up on "R" with any topic on Google quite some time ago 
> | (because bits from fragmented postscript/pdf files show up, for 
> | example) - but using "r-devel" with topic normally gives me enough. 
> | YMMV.
> 
> Nobody seems to have mentioned the RSiteSearch() function 
> which automagically restrict the search to domains relevant 
> to the contect of "our" use of the letter R. I quite like 
> that as I tend to have an R prompt open when I am puzzled by 
> R questions ...

My guess is that people were hoping to find things outside of what Jon made
available or what's on or linked from www.r-project.org.  I believe that's
not going to be very productive (at least for now).  I don't think there's a
whole lot of things related to R that isn't found in those two places.

Andy
 
> Dirk
> 
> -- 
> Hell, there are no rules here - we're trying to accomplish something. 
>                                                   -- Thomas A. Edison
> 
> ______________________________________________
> R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch at stats.uwo.ca  Wed Mar  8 03:18:14 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Mar 2006 21:18:14 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <440E2234.5090406@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
	<eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>
	<440E2234.5090406@stats.uwo.ca>
Message-ID: <440E3EE6.4060901@stats.uwo.ca>

Okay, here's my effort based on Deepayan's and Charles' ideas.  The 
newArgs function is not what I'd call transparent, but I like the way 
the wrapper looks.

 > newArgs <- function(..., Params) {
+   f <- function(...) list(...)
+   formals(f) <- c(Params, formals(f))

+   b <- as.list(body(f))
+   body(f) <- as.call(c(b[1], names, b[-1]))
+   f(...)
+ }
 >
 > lowlevel <- function(longname = 1) {
+   cat("longname = ", longname, "\n")
+ }
 >
 > newDefaults <- list(longname=2)
 >
 > wrapper <- function (...)
+   do.call("lowlevel", newArgs(..., Params=newDefaults))

newArgs sets up f to look like

function (longname = 2, ...) list(longname = longname, ...)

and then calls it.  The thing I like about this, as opposed to using 
pmatch, is that I'm sure the partial matching is what's used by R's 
argument matching, whereas that's only pretty likely with pmatch.

I also sort of like these lines:

+   names <- as.list(names(Params))
+   names(names) <- names
+   names <- lapply(names, as.name)

but maybe I should have named Params as names, so they looked like this:

+   names <- as.list(names(names))
+   names(names) <- names
+   names <- lapply(names, as.name)

And of course I like the fact that this seems to work, but we've seen 
several versions that do that:

 > wrapper()
longname =  2
 > wrapper(longname=3)
longname =  3
 > wrapper(long=3)
longname =  3
 > wrapper(long=20)
longname =  20
 > wrapper(junk=20)
Error in lowlevel(longname = 2, junk = 20) :
         unused argument(s) (junk ...)

Duncan Murdoch


From ch-r-devel at bobobeach.com  Wed Mar  8 07:15:47 2006
From: ch-r-devel at bobobeach.com (Cyrus Harmon)
Date: Tue, 7 Mar 2006 22:15:47 -0800
Subject: [Rd] SVN troubles
In-Reply-To: <m2bqwhes2d.fsf@ziti.local>
References: <BA80E707-F63B-47DB-A7B0-5CF96DD74F64@bobobeach.com>
	<m2bqwhes2d.fsf@ziti.local>
Message-ID: <F7849AB0-E7EF-4AF6-8337-3DEBAF292E3A@bobobeach.com>


Just thought y'all might like to know that the cause of my trouble  
was that the openssl libraries currently in fink (for MacOS X on  
Intel) seem to be broken. Using the system supplied openssl libraries  
to build svn seems to fix the problem.

Thanks and sorry for the noise.

Cyrus

On Mar 7, 2006, at 3:46 PM, Seth Falcon wrote:

> Cyrus Harmon <ch-r-devel at bobobeach.com> writes:
>
>> Dear r-devel,
>>
>> Sorry to trouble the list with this, but I've been beating my head
>> against the wall trying to figure out what's wrong. When I try to
>> connect to the R SVN server, I get the following message:
>>
>> (sly at cornas):~/src/R$ svn co https://svn.r-project.org/R/trunk r- 
>> devel
>> svn: PROPFIND request failed on '/R/trunk'
>> svn: PROPFIND of '/R/trunk': SSL negotiation failed: SSL error: bad
>> signature (https://svn.r-project.org)
>
> You could try going to that URL with a web browser on that system.
> You could also see what is inside your ~/.subversion directory on that
> system.  Perhaps a cached cert is invalid and preventing ssl auth.
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jaomatos at gmail.com  Wed Mar  8 11:24:11 2006
From: jaomatos at gmail.com (=?ISO-8859-1?Q?Jos=E9_Matos?=)
Date: Wed, 8 Mar 2006 10:24:11 +0000
Subject: [Rd] Build directory path saved in Meta/hsearch.rds
In-Reply-To: <Pine.LNX.4.64.0603041649470.26249@gannet.stats.ox.ac.uk>
References: <9fd2371d0603031232k5e217784y@mail.gmail.com>
	<9fd2371d0603031517n985acc0y@mail.gmail.com>
	<Pine.LNX.4.64.0603040743540.10823@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0603041649470.26249@gannet.stats.ox.ac.uk>
Message-ID: <9fd2371d0603080224o162f7bb0t@mail.gmail.com>

On 04/03/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> I've made two changes for R 2.3.0
>
> 1) as the LibPath is not actually used, it is recorded as "".  (For
> compatibility we don't want to remove the field.)  Since it was returned
> but not printed by help.search(), the actual installed path is returned
> instead.  (Given that the return format of help.search is undocumented, I
> don't see how anyone could have made use of it without realizing it was
> subject to guesswork and to change.)
>
> 2) hsearch.rds could usefully be stored in compressed format, and so will
> be.

  I would like to thank you and Dirk for your answers (and Peter
Daalgard FWIW :-).

My concern was that R could use that path in some way.

Usually this is not a problem because as Brian clearly told that path
will be inexistent, the problem would exist if this temporary path
could be exploited maliciously to inject code into R. I hope that
these concerns don't sound too far fetched since sometimes the
temporary directories are world writable.

  Thank you for the change, I am glad to see that this will be
addressed for 2.3.

  Best regards,
--
Jos? Ab?lio


From hin-tak.leung at cimr.cam.ac.uk  Wed Mar  8 13:34:54 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 08 Mar 2006 12:34:54 +0000
Subject: [Rd] double pointer matrix
In-Reply-To: <20060307194613.26687.qmail@web27409.mail.ukl.yahoo.com>
References: <20060307194613.26687.qmail@web27409.mail.ukl.yahoo.com>
Message-ID: <440ECF6E.3040201@cimr.cam.ac.uk>

CC-ing r-devel for the direct e-mail.

Bernd Kriegstein wrote:
> Hi Hin-Tak,
> 
> Thanks for the answer, but it's a little bit
> tangential. Mind you that y is a double pointer,
> commonly used in initialization of matrices. My
> problem is that I cannot eventually access the
> elements of this matrix from within R.

If you write the R code as (sorry, I make a mistake earlier -
you really mean a n*m matrix, not a n*1 one)

y <- double(n*m)
y <- .C("retMat", as.double(y) ....)[1],

y would *appear* to your C code as a double pointer,
and also would be allocated storage on the R side.
(you don't want to know how and why that is, it
is in the R-extension manual and not very clearly
explained, so you'll just have to try it out and see).

In fact
y <- .C("retMat", double(n*m), ...) [1]

probably would do the job just fine. (note it is
double(n*n), not as.double(...)) - this is allocating on
the way in.

> 
> Put another way, do you have any idea about how to
> make a matrix in the C body and then pass it to R
> stack?

I do, but the only way of doing allocation and having it
interacting correctly with
R's garbage collector (i.e. having free() taken care of
automatically), is via the .Call/.External interfaces,
and it gets more complicated - basically you do something like

#include <R.h>
#include <Rinternals.h>

SEXP retMat(SEXP args)
{
...
PROTECT(y = allocMatrix(REALSXP,n,m)
...
}

and honestly, what I outlined earlier and again is the
simpliest way.

HTL

> 
> Thanks for any answers,
> 
> - b.
> 
> --- Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
> schrieb:
> 
> 
>>Please don't do malloc inside C code like this - it
>>won't interact too 
>>well with the garbage collector in R, and your
>>program probably will 
>>either leak or crash or both... and when are you
>>going to do your
>>free()?
>>
>>What you want is do is to delete that malloc line
>>and do the
>>allocation on the R side, something like this (the
>>first line does
>>the equivalent of your malloc allocation):
>>
>>y <- double(n)
>>y <- .C("retMat", as.double(y), as.double(n),
>>as.double(m), 
>>as.double(a), as.double(b))[1]
>>
>>HTL
>>
>>Bernd Kriegstein wrote:
>>
>>>Hello,
>>>
>>>I'm having some difficulty to understand how I
>>
>>could
>>
>>>take the proper result from the following listing:
>>>
>>>-- cut ---
>>>#include <stdlib.h>
>>>#include <R.h>
>>>#include <Rmath.h>
>>>
>>>void retMat ( double **y, int *n, int *m, double
>>
>>*a,
>>
>>>double *b) {
>>>        int i, j;
>>>        y = malloc( (*n) * sizeof( double ) );
>>>        for (i=0; i<*n; i++) {
>>>                y[i] = malloc ( (*m) * sizeof(
>>
>>double
>>
>>>) );
>>>        }
>>>        
>>>        GetRNGstate();
>>>
>>>        for (i=0; i<*n; i++) {
>>>                for (j=0; j<*m; j++) {
>>>                        y[i][j] =
>>
>>(i+1)*(j+1)*rbeta(
>>
>>>*a, *b );
>>>                }
>>>        }
>>>        
>>>        PutRNGstate();
>>>}
>>>---
>>>I understand that I will have to make the matrix
>>>initialized in the double for loop above to be
>>
>>somehow
>>
>>>visible as a vector, because of the way that the
>>>matrix elements are passed in the argument when
>>
>>used
>>
>>>in the R space. Is there a way to accomplish this?
>>>
>>>Thanks for any answers,
>>>
>>>- b.


From murdoch at stats.uwo.ca  Wed Mar  8 14:37:49 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Mar 2006 08:37:49 -0500
Subject: [Rd] Expanding partial names
In-Reply-To: <440E3EE6.4060901@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>
	<eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>
	<440E2234.5090406@stats.uwo.ca> <440E3EE6.4060901@stats.uwo.ca>
Message-ID: <440EDE2D.4060202@stats.uwo.ca>

Whoops, just noticed that I cut when I should have copied.  The newArgs 
function should look like this:

newArgs <- function(..., Params) {
   f <- function(...) list(...)
   formals(f) <- c(Params, formals(f))
   names <- as.list(names(Params))
   names(names) <- names
   names <- lapply(names, as.name)
   b <- as.list(body(f))
   body(f) <- as.call(c(b[1], names, b[-1]))
   f(...)
}

Duncan Murdoch

On 3/7/2006 9:18 PM, Duncan Murdoch wrote:
> Okay, here's my effort based on Deepayan's and Charles' ideas.  The 
> newArgs function is not what I'd call transparent, but I like the way 
> the wrapper looks.
> 
>  > newArgs <- function(..., Params) {
> +   f <- function(...) list(...)
> +   formals(f) <- c(Params, formals(f))
> 
> +   b <- as.list(body(f))
> +   body(f) <- as.call(c(b[1], names, b[-1]))
> +   f(...)
> + }
>  >
>  > lowlevel <- function(longname = 1) {
> +   cat("longname = ", longname, "\n")
> + }
>  >
>  > newDefaults <- list(longname=2)
>  >
>  > wrapper <- function (...)
> +   do.call("lowlevel", newArgs(..., Params=newDefaults))
> 
> newArgs sets up f to look like
> 
> function (longname = 2, ...) list(longname = longname, ...)
> 
> and then calls it.  The thing I like about this, as opposed to using 
> pmatch, is that I'm sure the partial matching is what's used by R's 
> argument matching, whereas that's only pretty likely with pmatch.
> 
> I also sort of like these lines:
> 
> +   names <- as.list(names(Params))
> +   names(names) <- names
> +   names <- lapply(names, as.name)
> 
> but maybe I should have named Params as names, so they looked like this:
> 
> +   names <- as.list(names(names))
> +   names(names) <- names
> +   names <- lapply(names, as.name)
> 
> And of course I like the fact that this seems to work, but we've seen 
> several versions that do that:
> 
>  > wrapper()
> longname =  2
>  > wrapper(longname=3)
> longname =  3
>  > wrapper(long=3)
> longname =  3
>  > wrapper(long=20)
> longname =  20
>  > wrapper(junk=20)
> Error in lowlevel(longname = 2, junk = 20) :
>          unused argument(s) (junk ...)
> 
> Duncan Murdoch
>


From roger.bos at gmail.com  Wed Mar  8 14:39:47 2006
From: roger.bos at gmail.com (roger bos)
Date: Wed, 8 Mar 2006 08:39:47 -0500
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
	...
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
Message-ID: <1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060308/69fd1523/attachment.pl

From hb at maths.lth.se  Wed Mar  8 15:00:24 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 8 Mar 2006 15:00:24 +0100
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
	...
In-Reply-To: <1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
	<1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>
Message-ID: <59d7961d0603080600t69fc64fcx8a03944c3eedc301@mail.gmail.com>

On 3/8/06, roger bos <roger.bos at gmail.com> wrote:
> Indeed, when I was writing code in Java or VBA and I needed code, say to
> buble sort or invert a CDF, I could find many examples on the web since the
> user base was so large.  R has something better: CRAN.  It was really smart
> to make a central repository where useRs can share code.  No other language
> that I can think of really has an equivalent.  All I have to do it search
> CRAN and I can find 99% of what out there (I'm making a guess on the actual
> number here).

Don't forget, there's also life outside CRAN ;)

/Henrik

>
> Besides, I don't need to write bubble sort routines anymore because almost
> everything I need is already built into R.
>
>
>
>
> On 3/7/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> >
> > From: Dirk Eddelbuettel
> > >
> > > On 7 March 2006 at 10:55, Hin-Tak Leung wrote:
> > > | I have given up on "R" with any topic on Google quite some time ago
> > > | (because bits from fragmented postscript/pdf files show up, for
> > > | example) - but using "r-devel" with topic normally gives me enough.
> > > | YMMV.
> > >
> > > Nobody seems to have mentioned the RSiteSearch() function
> > > which automagically restrict the search to domains relevant
> > > to the contect of "our" use of the letter R. I quite like
> > > that as I tend to have an R prompt open when I am puzzled by
> > > R questions ...
> >
> > My guess is that people were hoping to find things outside of what Jon
> > made
> > available or what's on or linked from www.r-project.org.  I believe that's
> > not going to be very productive (at least for now).  I don't think there's
> > a
> > whole lot of things related to R that isn't found in those two places.
> >
> > Andy
> >
> > > Dirk
> > >
> > > --
> > > Hell, there are no rules here - we're trying to accomplish something.
> > >                                                   -- Thomas A. Edison
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)


From jeff.horner at vanderbilt.edu  Wed Mar  8 15:44:27 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 08 Mar 2006 08:44:27 -0600
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
 ...
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
Message-ID: <440EEDCB.1080209@vanderbilt.edu>

On 7 March 2006 at 10:55, Hin-Tak Leung wrote:
| I have given up on "R" with any topic on Google quite some time ago
| (because bits from fragmented postscript/pdf files show up, for
| example) - but using "r-devel" with topic normally gives me enough.
| YMMV.

I think Google's filetype searching can be very useful. This was 
discussed on R-help last May. Someone also pointed out that searching in 
this way would bring up lots of Rebol code, but that's easily weeded out:

filetype:R -rebol apply

and of the 10 hits (of 12,300) on the first page of results, only 1 
points to an R project website.

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University


From hin-tak.leung at cimr.cam.ac.uk  Wed Mar  8 15:55:51 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 08 Mar 2006 14:55:51 +0000
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
 ...
In-Reply-To: <1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
	<1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>
Message-ID: <440EF077.2020501@cimr.cam.ac.uk>

roger bos wrote:
> Indeed, when I was writing code in Java or VBA and I needed code, say to 
> buble sort or invert a CDF, I could find many examples on the web since 
> the user base was so large.  R has something better: CRAN.  It was 
> really smart to make a central repository where useRs can share code.  
> No other language that I can think of really has an equivalent.  All I 
> have to do it search CRAN and I can find 99% of what out there (I'm 
> making a guess on the actual number here).
<snipped>

Hang on there - "No other language that I can think of really has
an equivalent." - have you heard of CPAN, and CTAN? CRAN
was modelled *after* CPAN, which in turn was modelled after CTAN...
Either of them is far bigger in size, far older in history, and far
more well-established.

In fact, I am sorry to say, the search engine of either CPAN or CTAN
are better than CRAN's. (this last sentence is subjective, of course).

Obviously not a Perl nor TeX user then.

(probably not a good idea to express this on r-devel, nevermind)

HTL


From kwright68 at gmail.com  Wed Mar  8 17:07:17 2006
From: kwright68 at gmail.com (Kevin Wright)
Date: Wed, 8 Mar 2006 10:07:17 -0600
Subject: [Rd] Wishlist: Creating horizontal PDFs
Message-ID: <adf71a630603080807u510da0dcq2dc8a3adb0276dad@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060308/0570e82d/attachment.pl

From mschwartz at mn.rr.com  Wed Mar  8 19:01:44 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 08 Mar 2006 12:01:44 -0600
Subject: [Rd] R started in terminal shell script or ESS steps
	on	LD_LIBRARY_PATH?
In-Reply-To: <1141763409.4501.85.camel@localhost.localdomain>
References: <1141763409.4501.85.camel@localhost.localdomain>
Message-ID: <1141840904.6237.12.camel@localhost.localdomain>

Hi all,

In follow up to my prior post on this issue, I have found a workaround,
but have not yet clearly identified the etiology of the problem.
Whatever it is, it is presumably unique to my system, though if anyone
can replicate this on another FC4 system...  :-)

The workaround involves booting to init 3 rather than init 5 and
starting X manually from the console. I found this after going through
some of the steps described below regarding my X configuration. In this
way, LD_LIBRARY_PATH is preserved and RODBC works without issue in both
ESS and the gnome-terminal shell start up script.

Dirk was kind enough to send me an offlist e-mail yesterday in reply,
which sparked some thoughts as I was away from the computer for a few
hours yesterday afternoon and evening.

Dirk's e-mail logically queried on any issues with gnome-terminal and/or
the bash shell itself.

Since this problem was new (this had all worked previously), I checked
to see if there had been any recent updates to either gnome-terminal or
bash in the FC repos. There were none, although there have been of
course updates to GNOME, GTK and other libs.

This got me to think about other updates since the last known time this
process worked properly. So I spent several hours last night and this
morning reviewing possibilities.

The last Xorg updates are from last September, so these are not new.

Other changes that I had made in the recent past include:

1. Modifying my xorg.conf to support nVidia TwinView hardware
acceleration functionality. TwinView is like xinerama mode, spanning
both displays to give me a virtual 3200x1200 screen, though supporting
HW acceleration on both displays. Previously I had been using two X
servers (also using the nVidia driver in non-xinerama mode) to support
my dual display configuration.  Reverting back to the old configuration
did not resolve the problem. 

2. The last nVidia driver update (8178) was in December and this process
had worked since then.

3. There was an updated Cisco VPN client for Linux (4.8) to support
recent kernels. The VPN client is installed from source. This normally
starts up on boot as a service. Disabling the service, thus removing the
kernel module, did not resolve the problem.

4. I had updated the encryption of several of my partitions on my laptop
to use dm-crypt/LUKS with 256 bit AES from regular dm-crypt to take
advantage of pending LUKS support updates in HAL and other system
functions. Disabling the encryption (so the relevant kernel modules did
not load), logging in as root and running ESS from root's home did not
resolve the problem.

5. Just in case, I also reinstalled kernel version 2.6.15-1.1830
(running 1833 now) to see if there was any change there. No joy. I
cannot locate any of the 2.6.14 FC4 kernel versions, as these have been
removed from the repos, so it leaves open the possibility of something
in the .14 to .15 rebase change.


Other than routine system updates via yum, these are the only
"self-inflicted" changes that I have made recently. If any of the above
should spark some thoughts, let me know.

My plans are to live with this for now. FC5 is targeted for release next
Wednesday, presuming that it stays on schedule. I'll do a clean install
with that and see if anything is resolved, perhaps indicating some other
issue that is as yet unidentified.

Many thanks to Dirk for your assistance.

Best regards,

Marc Schwartz


From hin-tak.leung at cimr.cam.ac.uk  Wed Mar  8 19:39:03 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 08 Mar 2006 18:39:03 +0000
Subject: [Rd] R started in terminal shell script or ESS
	steps	on	LD_LIBRARY_PATH?
In-Reply-To: <1141840904.6237.12.camel@localhost.localdomain>
References: <1141763409.4501.85.camel@localhost.localdomain>
	<1141840904.6237.12.camel@localhost.localdomain>
Message-ID: <440F24C7.3020603@cimr.cam.ac.uk>

This sounds like a shell init issue... and you probably want to hunt
down where LD_LIBRARY path is *set*, rather than how it is inherited.

When you log in in run-level three, you get a login shell rather than
a normal interactive shell, and your startx inherits your login-shell's 
environment, You get a normal interactive shell(?) inside 
gnome-terminal/xterm if you start at run-level 5, and finally, you get
a non-interactive shell if you run a script, most of the time.
The environments in the three cases are all different, and
sometimes security related environment variables are not inherited
by forked sub-shells, such as LD_LIBRARY_PATH; or more likely, 
LD_LIBRARY_PATH is set up for the login shell, and other shells
simply don't get it.

HTL

 From the INVOCATION part of bash's man page - assuming that's your 
login shell, otherwise, others.
===========
When  bash is invoked as an interactive login shell, or as a non-inter-
active shell with the --login option, it first reads and executes  com-
mands  from  the file /etc/profile, if that file exists.  After reading
that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile,
in  that order, and reads and executes commands from the first one that
exists and is readable.  The --noprofile option may be  used  when  the
shell is started to inhibit this behavior.

When  a  login  shell  exits, bash reads and executes commands from the
file ~/.bash_logout, if it exists.

When an interactive shell that is not a login shell  is  started,  bash
reads  and executes commands from ~/.bashrc, if that file exists.  This
may be inhibited by using the --norc option.  The --rcfile file  option
will  force  bash  to  read  and  execute commands from file instead of
~/.bashrc.

When bash is started non-interactively, to  run  a  shell  script,  for
example, it looks for the variable BASH_ENV in the environment, expands
its value if it appears there, and uses the expanded value as the  name
of  a  file to read and execute.  Bash behaves as if the following com-
mand were executed:
    if [ -n "$BASH_ENV" ]; then . "$BASH_ENV"; fi
but the value of the PATH variable is not used to search for  the  file
name.
=========



Marc Schwartz (via MN) wrote:
> Hi all,
> 
> In follow up to my prior post on this issue, I have found a workaround,
> but have not yet clearly identified the etiology of the problem.
> Whatever it is, it is presumably unique to my system, though if anyone
> can replicate this on another FC4 system...  :-)
> 
> The workaround involves booting to init 3 rather than init 5 and
> starting X manually from the console. I found this after going through
> some of the steps described below regarding my X configuration. In this
> way, LD_LIBRARY_PATH is preserved and RODBC works without issue in both
> ESS and the gnome-terminal shell start up script.
> 
> Dirk was kind enough to send me an offlist e-mail yesterday in reply,
> which sparked some thoughts as I was away from the computer for a few
> hours yesterday afternoon and evening.
> 
> Dirk's e-mail logically queried on any issues with gnome-terminal and/or
> the bash shell itself.
> 
> Since this problem was new (this had all worked previously), I checked
> to see if there had been any recent updates to either gnome-terminal or
> bash in the FC repos. There were none, although there have been of
> course updates to GNOME, GTK and other libs.
> 
> This got me to think about other updates since the last known time this
> process worked properly. So I spent several hours last night and this
> morning reviewing possibilities.
> 
> The last Xorg updates are from last September, so these are not new.
> 
> Other changes that I had made in the recent past include:
> 
> 1. Modifying my xorg.conf to support nVidia TwinView hardware
> acceleration functionality. TwinView is like xinerama mode, spanning
> both displays to give me a virtual 3200x1200 screen, though supporting
> HW acceleration on both displays. Previously I had been using two X
> servers (also using the nVidia driver in non-xinerama mode) to support
> my dual display configuration.  Reverting back to the old configuration
> did not resolve the problem. 
> 
> 2. The last nVidia driver update (8178) was in December and this process
> had worked since then.
> 
> 3. There was an updated Cisco VPN client for Linux (4.8) to support
> recent kernels. The VPN client is installed from source. This normally
> starts up on boot as a service. Disabling the service, thus removing the
> kernel module, did not resolve the problem.
> 
> 4. I had updated the encryption of several of my partitions on my laptop
> to use dm-crypt/LUKS with 256 bit AES from regular dm-crypt to take
> advantage of pending LUKS support updates in HAL and other system
> functions. Disabling the encryption (so the relevant kernel modules did
> not load), logging in as root and running ESS from root's home did not
> resolve the problem.
> 
> 5. Just in case, I also reinstalled kernel version 2.6.15-1.1830
> (running 1833 now) to see if there was any change there. No joy. I
> cannot locate any of the 2.6.14 FC4 kernel versions, as these have been
> removed from the repos, so it leaves open the possibility of something
> in the .14 to .15 rebase change.
> 
> 
> Other than routine system updates via yum, these are the only
> "self-inflicted" changes that I have made recently. If any of the above
> should spark some thoughts, let me know.
> 
> My plans are to live with this for now. FC5 is targeted for release next
> Wednesday, presuming that it stays on schedule. I'll do a clean install
> with that and see if anything is resolved, perhaps indicating some other
> issue that is as yet unidentified.
> 
> Many thanks to Dirk for your assistance.
> 
> Best regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From graywh at gmail.com  Wed Mar  8 21:25:18 2006
From: graywh at gmail.com (graywh@gmail.com)
Date: Wed,  8 Mar 2006 21:25:18 +0100 (CET)
Subject: [Rd] Clipboard connections (PR#8668)
Message-ID: <20060308202518.586FABAFB@slim.kubism.ku.dk>

Full_Name: Will Gray
Version: R 2.2.1
OS: WinXP SP2
Submission from: (NULL) (160.129.18.69)


I've been using R with a text editor (Tinn-R) and using a feature of the editor
that sends code to a running R session.  Sometimes it is convenient to use the
command "source(file('clipboard'))" to send whole blocks of code.  However, this
quickly fills up the limit of 50 connections, even if 47 are closed.  What does
R hold on to connections it doesn't need, and especially multiple closed
connections to the clipboard?  Should this be changed?


From mschwartz at mn.rr.com  Wed Mar  8 22:42:19 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 08 Mar 2006 15:42:19 -0600
Subject: [Rd] R started in terminal shell script or ESS
	steps	on	LD_LIBRARY_PATH?
In-Reply-To: <1141847654.28287.1.camel@localhost.localdomain>
References: <1141763409.4501.85.camel@localhost.localdomain>
	<1141840904.6237.12.camel@localhost.localdomain>
	<440F24C7.3020603@cimr.cam.ac.uk>
	<1141847654.28287.1.camel@localhost.localdomain>
Message-ID: <1141854139.19839.5.camel@localhost.localdomain>

On Wed, 2006-03-08 at 13:54 -0600, Marc Schwartz wrote:
> On Wed, 2006-03-08 at 18:39 +0000, Hin-Tak Leung wrote:  
> > This sounds like a shell init issue... and you probably want to hunt
> > down where LD_LIBRARY path is *set*, rather than how it is inherited.
> > 
> > When you log in in run-level three, you get a login shell rather than
> > a normal interactive shell, and your startx inherits your login-shell's 
> > environment, You get a normal interactive shell(?) inside 
> > gnome-terminal/xterm if you start at run-level 5, and finally, you get
> > a non-interactive shell if you run a script, most of the time.
> > The environments in the three cases are all different, and
> > sometimes security related environment variables are not inherited
> > by forked sub-shells, such as LD_LIBRARY_PATH; or more likely, 
> > LD_LIBRARY_PATH is set up for the login shell, and other shells
> > simply don't get it.
> > 
> > HTL
> > 
> >  From the INVOCATION part of bash's man page - assuming that's your 
> > login shell, otherwise, others.
> > ===========
> > When  bash is invoked as an interactive login shell, or as a non-inter-
> > active shell with the --login option, it first reads and executes  com-
> > mands  from  the file /etc/profile, if that file exists.  After reading
> > that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile,
> > in  that order, and reads and executes commands from the first one that
> > exists and is readable.  The --noprofile option may be  used  when  the
> > shell is started to inhibit this behavior.
> > 
> > When  a  login  shell  exits, bash reads and executes commands from the
> > file ~/.bash_logout, if it exists.
> > 
> > When an interactive shell that is not a login shell  is  started,  bash
> > reads  and executes commands from ~/.bashrc, if that file exists.  This
> > may be inhibited by using the --norc option.  The --rcfile file  option
> > will  force  bash  to  read  and  execute commands from file instead of
> > ~/.bashrc.
> > 
> > When bash is started non-interactively, to  run  a  shell  script,  for
> > example, it looks for the variable BASH_ENV in the environment, expands
> > its value if it appears there, and uses the expanded value as the  name
> > of  a  file to read and execute.  Bash behaves as if the following com-
> > mand were executed:
> >     if [ -n "$BASH_ENV" ]; then . "$BASH_ENV"; fi
> > but the value of the PATH variable is not used to search for  the  file
> > name.
> > =========
> 

<SNIP>


Many thanks for the reply.  Given the subject matter feel free to
respond offlist with any further replies. I can post back should I
figure this out for the sake of closure on the thread.

LD_LIBRARY_PATH is set in ~/.bashrc and this has worked fine previously,
so I am still unclear as to what has changed. Though I am readily
willing to accept that something has been screwed up somehow. Presuming
that a system wide setting has been compromised in some fashion, the
pending clean install of FC 5 may be helpful.

If not, I may need to consider something in my own user profile
configuration.

I also logged into a KDE session from init 5, to see if perhaps whatever
was going on might have been GNOME specific. Unfortunately, the same
behavior is seen in KDE using ESS.

Two more data points under init 5 in GNOME however:

1. If I open a gnome-terminal console and start R from the CLI, things
work. If I exit R and use 'gnome-terminal -x R' within that same console
to mimic my startup script, it does not work, even though the variable
is clearly set in the console prior to entering the command. However, if
from the same initial gnome-terminal console session, I use 'xterm -e
R', it works.

2. If I use the "Run Application..." dialogue from the GNOME menu, type
in 'R' and check "Run in terminal", it does not work.

There is something subtle going on here, that I am just not seeing.

Thanks again for taking the time to reply.

Best regards,

Marc


From thomas.wainwright at noaa.gov  Wed Mar  8 23:17:55 2006
From: thomas.wainwright at noaa.gov (thomas.wainwright@noaa.gov)
Date: Wed,  8 Mar 2006 23:17:55 +0100 (CET)
Subject: [Rd] Error in return value for as.Date() (PR#8669)
Message-ID: <20060308221755.1852A199FD@slim.kubism.ku.dk>

Full_Name: Tom Wainwright
Version: 2.2.1  (2005-12-20 r36812)
OS: Linux (SuSE 9.3)
Submission from: (NULL) (161.55.180.38)


The as.Date function returns erroneous result for certain values using a
day-of-year format.  First an example that works (last day of 1970):

> as.Date("1970.365", format="%Y.%j")
[1] "1970-12-31"

Next, a bad example (oops, 1970 wasn't a leap year).  Incrementing day by one
moves
date ahead by 2 years 1 month:

> as.Date("1970.366", format="%Y.%j")
[1] "1972-01-31"
> as.Date("1970.366", format="%Y.%j") - as.Date("1970.365", format="%Y.%j")
Time difference of 396 days

The second example should probably return an NA as this is an invalid date.


From khansen at stat.Berkeley.EDU  Wed Mar  8 23:48:28 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 8 Mar 2006 14:48:28 -0800
Subject: [Rd] R started in terminal shell script or ESS
	steps	on	LD_LIBRARY_PATH?
In-Reply-To: <1141854139.19839.5.camel@localhost.localdomain>
References: <1141763409.4501.85.camel@localhost.localdomain>
	<1141840904.6237.12.camel@localhost.localdomain>
	<440F24C7.3020603@cimr.cam.ac.uk>
	<1141847654.28287.1.camel@localhost.localdomain>
	<1141854139.19839.5.camel@localhost.localdomain>
Message-ID: <2C80985C-BBB5-4422-B6B4-2A24CB4132A0@stat.berkeley.edu>

I am _not_ an expert on bash. But as far as I know, .bashrc is not  
read when you have a login session, whereas .bash_profile is. I have  
never really understood the deep differences between the two - I only  
have some superficial understanding. But for my purposes I just have a
   source .bashrc
in my .bash_profile script. In that way I set the same variables no  
matter what kind of session I have (clearly, I only use .bashrc).

There are important differences when you want to run a program at  
login, but you do not want to run it every time you start up a shell.  
But simply for setting environment variables, this ought to work.

Perhaps this helps? Or perhaps this is something deeper than the  
simple issue outlined above.

/Kasper


On Mar 8, 2006, at 1:42 PM, Marc Schwartz (via MN) wrote:

> On Wed, 2006-03-08 at 13:54 -0600, Marc Schwartz wrote:
>> On Wed, 2006-03-08 at 18:39 +0000, Hin-Tak Leung wrote:
>>> This sounds like a shell init issue... and you probably want to hunt
>>> down where LD_LIBRARY path is *set*, rather than how it is  
>>> inherited.
>>>
>>> When you log in in run-level three, you get a login shell rather  
>>> than
>>> a normal interactive shell, and your startx inherits your login- 
>>> shell's
>>> environment, You get a normal interactive shell(?) inside
>>> gnome-terminal/xterm if you start at run-level 5, and finally,  
>>> you get
>>> a non-interactive shell if you run a script, most of the time.
>>> The environments in the three cases are all different, and
>>> sometimes security related environment variables are not inherited
>>> by forked sub-shells, such as LD_LIBRARY_PATH; or more likely,
>>> LD_LIBRARY_PATH is set up for the login shell, and other shells
>>> simply don't get it.
>>>
>>> HTL
>>>
>>>  From the INVOCATION part of bash's man page - assuming that's your
>>> login shell, otherwise, others.
>>> ===========
>>> When  bash is invoked as an interactive login shell, or as a non- 
>>> inter-
>>> active shell with the --login option, it first reads and  
>>> executes  com-
>>> mands  from  the file /etc/profile, if that file exists.  After  
>>> reading
>>> that file, it looks for ~/.bash_profile, ~/.bash_login, and  
>>> ~/.profile,
>>> in  that order, and reads and executes commands from the first  
>>> one that
>>> exists and is readable.  The --noprofile option may be  used   
>>> when  the
>>> shell is started to inhibit this behavior.
>>>
>>> When  a  login  shell  exits, bash reads and executes commands  
>>> from the
>>> file ~/.bash_logout, if it exists.
>>>
>>> When an interactive shell that is not a login shell  is   
>>> started,  bash
>>> reads  and executes commands from ~/.bashrc, if that file  
>>> exists.  This
>>> may be inhibited by using the --norc option.  The --rcfile file   
>>> option
>>> will  force  bash  to  read  and  execute commands from file  
>>> instead of
>>> ~/.bashrc.
>>>
>>> When bash is started non-interactively, to  run  a  shell   
>>> script,  for
>>> example, it looks for the variable BASH_ENV in the environment,  
>>> expands
>>> its value if it appears there, and uses the expanded value as  
>>> the  name
>>> of  a  file to read and execute.  Bash behaves as if the  
>>> following com-
>>> mand were executed:
>>>     if [ -n "$BASH_ENV" ]; then . "$BASH_ENV"; fi
>>> but the value of the PATH variable is not used to search for   
>>> the  file
>>> name.
>>> =========
>>
>
> <SNIP>
>
>
> Many thanks for the reply.  Given the subject matter feel free to
> respond offlist with any further replies. I can post back should I
> figure this out for the sake of closure on the thread.
>
> LD_LIBRARY_PATH is set in ~/.bashrc and this has worked fine  
> previously,
> so I am still unclear as to what has changed. Though I am readily
> willing to accept that something has been screwed up somehow.  
> Presuming
> that a system wide setting has been compromised in some fashion, the
> pending clean install of FC 5 may be helpful.
>
> If not, I may need to consider something in my own user profile
> configuration.
>
> I also logged into a KDE session from init 5, to see if perhaps  
> whatever
> was going on might have been GNOME specific. Unfortunately, the same
> behavior is seen in KDE using ESS.
>
> Two more data points under init 5 in GNOME however:
>
> 1. If I open a gnome-terminal console and start R from the CLI, things
> work. If I exit R and use 'gnome-terminal -x R' within that same  
> console
> to mimic my startup script, it does not work, even though the variable
> is clearly set in the console prior to entering the command.  
> However, if
> from the same initial gnome-terminal console session, I use 'xterm -e
> R', it works.
>
> 2. If I use the "Run Application..." dialogue from the GNOME menu,  
> type
> in 'R' and check "Run in terminal", it does not work.
>
> There is something subtle going on here, that I am just not seeing.
>
> Thanks again for taking the time to reply.
>
> Best regards,
>
> Marc
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mschwartz at mn.rr.com  Thu Mar  9 00:25:04 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 08 Mar 2006 17:25:04 -0600
Subject: [Rd] R started in terminal shell script or ESS
	steps	on	LD_LIBRARY_PATH?
In-Reply-To: <2C80985C-BBB5-4422-B6B4-2A24CB4132A0@stat.berkeley.edu>
References: <1141763409.4501.85.camel@localhost.localdomain>
	<1141840904.6237.12.camel@localhost.localdomain>
	<440F24C7.3020603@cimr.cam.ac.uk>
	<1141847654.28287.1.camel@localhost.localdomain>
	<1141854139.19839.5.camel@localhost.localdomain>
	<2C80985C-BBB5-4422-B6B4-2A24CB4132A0@stat.berkeley.edu>
Message-ID: <1141860305.609.26.camel@localhost.localdomain>

On Wed, 2006-03-08 at 14:48 -0800, Kasper Daniel Hansen wrote:
> I am _not_ an expert on bash. But as far as I know, .bashrc is not  
> read when you have a login session, whereas .bash_profile is. I have  
> never really understood the deep differences between the two - I only  
> have some superficial understanding. But for my purposes I just have a
>    source .bashrc
> in my .bash_profile script. In that way I set the same variables no  
> matter what kind of session I have (clearly, I only use .bashrc).
> 
> There are important differences when you want to run a program at  
> login, but you do not want to run it every time you start up a shell.  
> But simply for setting environment variables, this ought to work.
> 
> Perhaps this helps? Or perhaps this is something deeper than the  
> simple issue outlined above.
> 
> /Kasper

<snip>

Thanks for the reply Kasper.

Two brief notes, so as not to consume further time and bandwidth here:

1. Dirk has just suggested that I edit /etc/ld.so.conf (then run
ldconfig). Placing the requisite path into that file works and I'm back
to using init 5. RODBC works now.  Thanks Dirk!

2. As mentioned this all had worked just recently. My preference is to
set up my user profile specifically with any customizations, since this
is a single user laptop system. Thus, root's login is clean, when
required for other purposes.  The default FC4 ~/.bash_profile does call
~/.bashrc, which in turn calls /etc/bashrc. So, presuming that the chain
is intact, this should all work, which it had been.

I'm still confused as to the nature of the underlying change, but
perhaps that will be resolved with a clean install soon.

I do sincerely appreciate everyone's time and feedback on this. Sorry
for consuming bandwidth here, for what honestly appeared to be an R
specific issue.

Best regards,

Marc


From rmh at temple.edu  Thu Mar  9 02:48:44 2006
From: rmh at temple.edu (rmh@temple.edu)
Date: Thu,  9 Mar 2006 02:48:44 +0100 (CET)
Subject: [Rd] bugs in simtest (PR#8670)
Message-ID: <20060309014844.DBED61754E@slim.kubism.ku.dk>

# R for Windows will not send your bug report automatically.
# Please copy the bug report (after finishing it) to
# your favorite email program and send it to
#
#       r-bugs at r-project.org
#
######################################################

This report is joint from Richard Heiberger <rmh at temple.edu>
and Burt Holland <bholland at temple.edu>.
Burt Holland is the coauthor of the paper that the ?ptukey
documentation references.


R was used to run an example in our elementary Stat course.  It was
a one-way ANOVA, the factor `strategy' having 3 levels Price, Quality
and Convenience.   

We issued the command 

summary(simint(sales ~ strategy, type="Tukey", data=Xm15.01s))

and received the output 

Coefficients:
                                    Estimate  2.5 % 97.5 % t value Std.Err.
strategyPrice-strategyConvenience      31.10 -40.67 102.87   1.043   29.824
strategyQuality-strategyConvenience    75.45   3.68 147.22   2.530   29.824
strategyQuality-strategyPrice          44.35 -27.42 116.12   1.487   29.824
                                    p raw p Bonf p adj
strategyPrice-strategyConvenience   0.301  0.904 0.553
strategyQuality-strategyConvenience 0.014  0.043 0.037
strategyQuality-strategyPrice       0.143  0.428 0.305

This gives correct 95% confidence intervals and adjusted p-values for the
Tukey multiple comparisons procedure.



Next we issued 

summary(simtest(sales ~ strategy, type="Tukey", data=Xm15.01s))

which produced the output

Coefficients:
                                    Estimate t value Std.Err. p raw p Bonf
strategyQuality-strategyConvenience    75.45  -2.530   29.824 0.014  0.043
strategyQuality-strategyPrice          44.35  -1.487   29.824 0.143  0.285
strategyPrice-strategyConvenience      31.10  -1.043   29.824 0.301  0.301
                                    p adj
strategyQuality-strategyConvenience 0.037
strategyQuality-strategyPrice       0.243
strategyPrice-strategyConvenience   0.301

Notice that the simtest output gives negative t statistics.  This is
wrong because the point estimates are positive.

The simtest Bonferroni p-values and adjusted p-values differ from the
simint values by more than trivial amounts.

We are puzzled that the two functions use different conventions on
sequencing the contrasts.  For levels A,B,C, it looks like

simint is using
B-A
C-A
C-B

and simtest is using
C-A
C-B
B-A


We verify all the p-values from the following code


tt <- c(31.10,75.45,44.35)/29.824
tt

         2*(1-pt(tt, 57))            ## raw
3     * (2*(1-pt(tt, 57)))           ## Bonferroni
        1-ptukey(tt*sqrt(2), 3, 57)  ## tukey

## It looks like simtest is using
(3:1) * (2*(1-pt(tt[c(2,3,1)], 57))) ## simtest Bonferroni
## The subscript is there to account for the different sequencing.
## The (3:1) multiplier is strange.

## It looks like simtest is using approximately
(1-ptukey(tt[c(2,3,1)]*sqrt(2), 3, 57)) / (1+c(0,1,3)*.12)^2
## We have no idea what that divisor is doing there other than
## approximating the answer that simtest is giving.




## Here is another example, this time using one of your datasets.
## Again, the p.Bonf and p.adj differ.  Again, the t.values for the
## simtest have the wrong sign.
## This is from
## c:/Program Files/R/R-2.2.1/library/multcomp/R-ex/Rex.zip/simtest.R

> data(cholesterol)
> 
> # adjusted p-values for all-pairwise comparisons in a one-way 
> # layout (tests for restricted combinations)
> simtest(response ~ trt, data=cholesterol, type="Tukey", ttype="logical")

        Simultaneous tests: Tukey contrasts

Call: 
simtest.formula(formula = response ~ trt, data = cholesterol, 
    type = "Tukey", ttype = "logical")

Contrast matrix:
                      trt1time trt2times trt4times trtdrugD trtdrugE
trt2times-trt1time  0       -1         1         0        0        0
trt4times-trt1time  0       -1         0         1        0        0
trtdrugD-trt1time   0       -1         0         0        1        0
trtdrugE-trt1time   0       -1         0         0        0        1
trt4times-trt2times 0        0        -1         1        0        0
trtdrugD-trt2times  0        0        -1         0        1        0
trtdrugE-trt2times  0        0        -1         0        0        1
trtdrugD-trt4times  0        0         0        -1        1        0
trtdrugE-trt4times  0        0         0        -1        0        1
trtdrugE-trtdrugD   0        0         0         0       -1        1

Adjusted P-Values

                    p adj
trtdrugE-trt1time   0.000
trtdrugE-trt2times  0.000
trtdrugD-trt1time   0.000
trtdrugE-trt4times  0.000
trt4times-trt1time  0.000
trtdrugD-trt2times  0.000
trtdrugE-trtdrugD   0.001
trt2times-trt1time  0.042
trt4times-trt2times 0.042
trtdrugD-trt4times  0.044
> 
> 
> summary(simtest(response ~ trt, data=cholesterol, type="Tukey", ttype="logical"))

         Simultaneous tests: Tukey contrasts 

Call: 
simtest.formula(formula = response ~ trt, data = cholesterol, 
    type = "Tukey", ttype = "logical")

         Tukey contrasts for factor trt

Contrast matrix:
                      trt1time trt2times trt4times trtdrugD trtdrugE
trt2times-trt1time  0       -1         1         0        0        0
trt4times-trt1time  0       -1         0         1        0        0
trtdrugD-trt1time   0       -1         0         0        1        0
trtdrugE-trt1time   0       -1         0         0        0        1
trt4times-trt2times 0        0        -1         1        0        0
trtdrugD-trt2times  0        0        -1         0        1        0
trtdrugE-trt2times  0        0        -1         0        0        1
trtdrugD-trt4times  0        0         0        -1        1        0
trtdrugE-trt4times  0        0         0        -1        0        1
trtdrugE-trtdrugD   0        0         0         0       -1        1


Absolute Error Tolerance:  0.001 

Coefficients:
                    Estimate t value Std.Err. p raw p Bonf p adj
trtdrugE-trt1time     15.166 -10.507    1.443 0.000  0.000 0.000
trtdrugE-trt2times    11.723  -8.122    1.443 0.000  0.000 0.000
trtdrugD-trt1time      9.579  -6.637    1.443 0.000  0.000 0.000
trtdrugE-trt4times     8.573  -5.939    1.443 0.000  0.000 0.000
trt4times-trt1time     6.593  -4.568    1.443 0.000  0.000 0.000
trtdrugD-trt2times     6.136  -4.251    1.443 0.000  0.000 0.000
trtdrugE-trtdrugD      5.586  -3.870    1.443 0.000  0.001 0.001
trt2times-trt1time     3.443  -2.385    1.443 0.021  0.043 0.042
trt4times-trt2times    3.150  -2.182    1.443 0.034  0.043 0.042
trtdrugD-trt4times     2.986  -2.069    1.443 0.044  0.044 0.044
> summary(simint(response ~ trt, data=cholesterol, type="Tukey", ttype="logical"))

        Simultaneous 95% confidence intervals: Tukey contrasts

Call: 
simint.formula(formula = response ~ trt, data = cholesterol, 
    type = "Tukey", ttype = "logical")

         Tukey contrasts for factor trt

Contrast matrix:
                      trt1time trt2times trt4times trtdrugD trtdrugE
trt2times-trt1time  0       -1         1         0        0        0
trt4times-trt1time  0       -1         0         1        0        0
trtdrugD-trt1time   0       -1         0         0        1        0
trtdrugE-trt1time   0       -1         0         0        0        1
trt4times-trt2times 0        0        -1         1        0        0
trtdrugD-trt2times  0        0        -1         0        1        0
trtdrugE-trt2times  0        0        -1         0        0        1
trtdrugD-trt4times  0        0         0        -1        1        0
trtdrugE-trt4times  0        0         0        -1        0        1
trtdrugE-trtdrugD   0        0         0         0       -1        1

Absolute Error Tolerance:  0.001 

 95 % quantile:  2.842 

Coefficients:
                    Estimate  2.5 % 97.5 % t value Std.Err. p raw p Bonf p adj
trt2times-trt1time     3.443 -0.658  7.544   2.385    1.443 0.021  0.213 0.138
trt4times-trt1time     6.593  2.491 10.694   4.568    1.443 0.000  0.000 0.000
trtdrugD-trt1time      9.579  5.478 13.681   6.637    1.443 0.000  0.000 0.000
trtdrugE-trt1time     15.166 11.064 19.267  10.507    1.443 0.000  0.000 0.000
trt4times-trt2times    3.150 -0.952  7.251   2.182    1.443 0.034  0.344 0.205
trtdrugD-trt2times     6.136  2.035 10.238   4.251    1.443 0.000  0.001 0.001
trtdrugE-trt2times    11.723  7.621 15.824   8.122    1.443 0.000  0.000 0.000
trtdrugD-trt4times     2.986 -1.115  7.088   2.069    1.443 0.044  0.443 0.251
trtdrugE-trt4times     8.573  4.471 12.674   5.939    1.443 0.000  0.000 0.000
trtdrugE-trtdrugD      5.586  1.485  9.688   3.870    1.443 0.000  0.003 0.003
> 



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Home Edition (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:multcomp, package:mvtnorm, package:abind, package:relimp, 
file:C:/PROGRA~1/R/R-22~1.1/library/Rcmdr/etc/HH/.RData, package:leaps, package:Rcmdr, 
package:car, package:tcltk, package:methods, package:stats, package:graphics, package:grDevices, 
package:utils, package:datasets, package:rcom, RcmdrEnv, Autoloads, package:base


From ripley at stats.ox.ac.uk  Thu Mar  9 08:40:02 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu,  9 Mar 2006 08:40:02 +0100 (CET)
Subject: [Rd] Clipboard connections (PR#8668)
Message-ID: <20060309074002.A23873FC9F@slim.kubism.ku.dk>

This is not a bug, but user error.  You are failing to close the 
connection.  R has no idea you do not subsequently want to use the 
connection via getConnection.  As the help page ?file and its reference, 
and also the R-news article on connections.

The correct usage is either

source("clipboard")

or

zz <- file("clipboard")
source(zz)
close(zz)

BTW, there are no `clipboard connections': there are file connections to 
the clipboard on Windows only.


On Wed, 8 Mar 2006, graywh at gmail.com wrote:

> Full_Name: Will Gray
> Version: R 2.2.1
> OS: WinXP SP2
> Submission from: (NULL) (160.129.18.69)
>
>
> I've been using R with a text editor (Tinn-R) and using a feature of the editor
> that sends code to a running R session.  Sometimes it is convenient to use the
> command "source(file('clipboard'))" to send whole blocks of code.  However, this
> quickly fills up the limit of 50 connections, even if 47 are closed.  What does
> R hold on to connections it doesn't need, and especially multiple closed
> connections to the clipboard?  Should this be changed?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  9 08:53:45 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu,  9 Mar 2006 08:53:45 +0100 (CET)
Subject: [Rd] bugs in simtest (PR#8670)
Message-ID: <20060309075345.B087A3FCA3@slim.kubism.ku.dk>

There is no simtest in R!  It appears you are using contributed package 
multcomp.

Please do re-read the FAQ.  Bug reports in contributed packages should not 
be sent to the R-bugs repository, but to the package maintainer.

This report has been closed.


On Thu, 9 Mar 2006, rmh at temple.edu wrote:

> # R for Windows will not send your bug report automatically.
> # Please copy the bug report (after finishing it) to
> # your favorite email program and send it to
> #
> #       r-bugs at r-project.org
> #
> ######################################################
>
> This report is joint from Richard Heiberger <rmh at temple.edu>
> and Burt Holland <bholland at temple.edu>.
> Burt Holland is the coauthor of the paper that the ?ptukey
> documentation references.
>
>
> R was used to run an example in our elementary Stat course.  It was
> a one-way ANOVA, the factor `strategy' having 3 levels Price, Quality
> and Convenience.
>
> We issued the command
>
> summary(simint(sales ~ strategy, type="Tukey", data=Xm15.01s))
>
> and received the output
>
> Coefficients:
>                                    Estimate  2.5 % 97.5 % t value Std.Err.
> strategyPrice-strategyConvenience      31.10 -40.67 102.87   1.043   29.824
> strategyQuality-strategyConvenience    75.45   3.68 147.22   2.530   29.824
> strategyQuality-strategyPrice          44.35 -27.42 116.12   1.487   29.824
>                                    p raw p Bonf p adj
> strategyPrice-strategyConvenience   0.301  0.904 0.553
> strategyQuality-strategyConvenience 0.014  0.043 0.037
> strategyQuality-strategyPrice       0.143  0.428 0.305
>
> This gives correct 95% confidence intervals and adjusted p-values for the
> Tukey multiple comparisons procedure.
>
>
>
> Next we issued
>
> summary(simtest(sales ~ strategy, type="Tukey", data=Xm15.01s))
>
> which produced the output
>
> Coefficients:
>                                    Estimate t value Std.Err. p raw p Bonf
> strategyQuality-strategyConvenience    75.45  -2.530   29.824 0.014  0.043
> strategyQuality-strategyPrice          44.35  -1.487   29.824 0.143  0.285
> strategyPrice-strategyConvenience      31.10  -1.043   29.824 0.301  0.301
>                                    p adj
> strategyQuality-strategyConvenience 0.037
> strategyQuality-strategyPrice       0.243
> strategyPrice-strategyConvenience   0.301
>
> Notice that the simtest output gives negative t statistics.  This is
> wrong because the point estimates are positive.
>
> The simtest Bonferroni p-values and adjusted p-values differ from the
> simint values by more than trivial amounts.
>
> We are puzzled that the two functions use different conventions on
> sequencing the contrasts.  For levels A,B,C, it looks like
>
> simint is using
> B-A
> C-A
> C-B
>
> and simtest is using
> C-A
> C-B
> B-A
>
>
> We verify all the p-values from the following code
>
>
> tt <- c(31.10,75.45,44.35)/29.824
> tt
>
>         2*(1-pt(tt, 57))            ## raw
> 3     * (2*(1-pt(tt, 57)))           ## Bonferroni
>        1-ptukey(tt*sqrt(2), 3, 57)  ## tukey
>
> ## It looks like simtest is using
> (3:1) * (2*(1-pt(tt[c(2,3,1)], 57))) ## simtest Bonferroni
> ## The subscript is there to account for the different sequencing.
> ## The (3:1) multiplier is strange.
>
> ## It looks like simtest is using approximately
> (1-ptukey(tt[c(2,3,1)]*sqrt(2), 3, 57)) / (1+c(0,1,3)*.12)^2
> ## We have no idea what that divisor is doing there other than
> ## approximating the answer that simtest is giving.
>
>
>
>
> ## Here is another example, this time using one of your datasets.
> ## Again, the p.Bonf and p.adj differ.  Again, the t.values for the
> ## simtest have the wrong sign.
> ## This is from
> ## c:/Program Files/R/R-2.2.1/library/multcomp/R-ex/Rex.zip/simtest.R
>
>> data(cholesterol)
>>
>> # adjusted p-values for all-pairwise comparisons in a one-way
>> # layout (tests for restricted combinations)
>> simtest(response ~ trt, data=cholesterol, type="Tukey", ttype="logical")
>
>        Simultaneous tests: Tukey contrasts
>
> Call:
> simtest.formula(formula = response ~ trt, data = cholesterol,
>    type = "Tukey", ttype = "logical")
>
> Contrast matrix:
>                      trt1time trt2times trt4times trtdrugD trtdrugE
> trt2times-trt1time  0       -1         1         0        0        0
> trt4times-trt1time  0       -1         0         1        0        0
> trtdrugD-trt1time   0       -1         0         0        1        0
> trtdrugE-trt1time   0       -1         0         0        0        1
> trt4times-trt2times 0        0        -1         1        0        0
> trtdrugD-trt2times  0        0        -1         0        1        0
> trtdrugE-trt2times  0        0        -1         0        0        1
> trtdrugD-trt4times  0        0         0        -1        1        0
> trtdrugE-trt4times  0        0         0        -1        0        1
> trtdrugE-trtdrugD   0        0         0         0       -1        1
>
> Adjusted P-Values
>
>                    p adj
> trtdrugE-trt1time   0.000
> trtdrugE-trt2times  0.000
> trtdrugD-trt1time   0.000
> trtdrugE-trt4times  0.000
> trt4times-trt1time  0.000
> trtdrugD-trt2times  0.000
> trtdrugE-trtdrugD   0.001
> trt2times-trt1time  0.042
> trt4times-trt2times 0.042
> trtdrugD-trt4times  0.044
>>
>>
>> summary(simtest(response ~ trt, data=cholesterol, type="Tukey", ttype="logical"))
>
>         Simultaneous tests: Tukey contrasts
>
> Call:
> simtest.formula(formula = response ~ trt, data = cholesterol,
>    type = "Tukey", ttype = "logical")
>
>         Tukey contrasts for factor trt
>
> Contrast matrix:
>                      trt1time trt2times trt4times trtdrugD trtdrugE
> trt2times-trt1time  0       -1         1         0        0        0
> trt4times-trt1time  0       -1         0         1        0        0
> trtdrugD-trt1time   0       -1         0         0        1        0
> trtdrugE-trt1time   0       -1         0         0        0        1
> trt4times-trt2times 0        0        -1         1        0        0
> trtdrugD-trt2times  0        0        -1         0        1        0
> trtdrugE-trt2times  0        0        -1         0        0        1
> trtdrugD-trt4times  0        0         0        -1        1        0
> trtdrugE-trt4times  0        0         0        -1        0        1
> trtdrugE-trtdrugD   0        0         0         0       -1        1
>
>
> Absolute Error Tolerance:  0.001
>
> Coefficients:
>                    Estimate t value Std.Err. p raw p Bonf p adj
> trtdrugE-trt1time     15.166 -10.507    1.443 0.000  0.000 0.000
> trtdrugE-trt2times    11.723  -8.122    1.443 0.000  0.000 0.000
> trtdrugD-trt1time      9.579  -6.637    1.443 0.000  0.000 0.000
> trtdrugE-trt4times     8.573  -5.939    1.443 0.000  0.000 0.000
> trt4times-trt1time     6.593  -4.568    1.443 0.000  0.000 0.000
> trtdrugD-trt2times     6.136  -4.251    1.443 0.000  0.000 0.000
> trtdrugE-trtdrugD      5.586  -3.870    1.443 0.000  0.001 0.001
> trt2times-trt1time     3.443  -2.385    1.443 0.021  0.043 0.042
> trt4times-trt2times    3.150  -2.182    1.443 0.034  0.043 0.042
> trtdrugD-trt4times     2.986  -2.069    1.443 0.044  0.044 0.044
>> summary(simint(response ~ trt, data=cholesterol, type="Tukey", ttype="logical"))
>
>        Simultaneous 95% confidence intervals: Tukey contrasts
>
> Call:
> simint.formula(formula = response ~ trt, data = cholesterol,
>    type = "Tukey", ttype = "logical")
>
>         Tukey contrasts for factor trt
>
> Contrast matrix:
>                      trt1time trt2times trt4times trtdrugD trtdrugE
> trt2times-trt1time  0       -1         1         0        0        0
> trt4times-trt1time  0       -1         0         1        0        0
> trtdrugD-trt1time   0       -1         0         0        1        0
> trtdrugE-trt1time   0       -1         0         0        0        1
> trt4times-trt2times 0        0        -1         1        0        0
> trtdrugD-trt2times  0        0        -1         0        1        0
> trtdrugE-trt2times  0        0        -1         0        0        1
> trtdrugD-trt4times  0        0         0        -1        1        0
> trtdrugE-trt4times  0        0         0        -1        0        1
> trtdrugE-trtdrugD   0        0         0         0       -1        1
>
> Absolute Error Tolerance:  0.001
>
> 95 % quantile:  2.842
>
> Coefficients:
>                    Estimate  2.5 % 97.5 % t value Std.Err. p raw p Bonf p adj
> trt2times-trt1time     3.443 -0.658  7.544   2.385    1.443 0.021  0.213 0.138
> trt4times-trt1time     6.593  2.491 10.694   4.568    1.443 0.000  0.000 0.000
> trtdrugD-trt1time      9.579  5.478 13.681   6.637    1.443 0.000  0.000 0.000
> trtdrugE-trt1time     15.166 11.064 19.267  10.507    1.443 0.000  0.000 0.000
> trt4times-trt2times    3.150 -0.952  7.251   2.182    1.443 0.034  0.344 0.205
> trtdrugD-trt2times     6.136  2.035 10.238   4.251    1.443 0.000  0.001 0.001
> trtdrugE-trt2times    11.723  7.621 15.824   8.122    1.443 0.000  0.000 0.000
> trtdrugD-trt4times     2.986 -1.115  7.088   2.069    1.443 0.044  0.443 0.251
> trtdrugE-trt4times     8.573  4.471 12.674   5.939    1.443 0.000  0.000 0.000
> trtdrugE-trtdrugD      5.586  1.485  9.688   3.870    1.443 0.000  0.003 0.003
>>
>
>
>
> --please do not edit the information below--
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 2.1
> year = 2005
> month = 12
> day = 20
> svn rev = 36812
> language = R
>
> Windows XP Home Edition (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> Search Path:
> .GlobalEnv, package:multcomp, package:mvtnorm, package:abind, package:relimp,
> file:C:/PROGRA~1/R/R-22~1.1/library/Rcmdr/etc/HH/.RData, package:leaps, package:Rcmdr,
> package:car, package:tcltk, package:methods, package:stats, package:graphics, package:grDevices,
> package:utils, package:datasets, package:rcom, RcmdrEnv, Autoloads, package:base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar  9 09:21:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Mar 2006 08:21:45 +0000 (GMT)
Subject: [Rd] Wishlist: Creating horizontal PDFs
In-Reply-To: <adf71a630603080807u510da0dcq2dc8a3adb0276dad@mail.gmail.com>
References: <adf71a630603080807u510da0dcq2dc8a3adb0276dad@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603090814270.12692@gannet.stats.ox.ac.uk>

On Wed, 8 Mar 2006, Kevin Wright wrote:

> It would be nice to easily create horizontal PDF files for standard paper
> sizes.  For example:
> pdf(file, paper="default", horizontal=TRUE)
>
> Currently (R 2.2.1) there is no 'horizontal' argument for the PDF driver.
> It looks like the only way to create a horizontal PDF is to manually specify
> width and height.  For example:
> pdf(file, width=11, height=8.5)
>
> Does this feature look useful?  If so, I may someday try to make the changes
> (I rarely have the ability to build R).
>
> If anyone else wants to make the change, the code for the PDF driver appears
> to be in R-devel/src/library/grDevices/src/devPS.c
>
> The changes should not be hard.  FYI...there is a 'horizontal' option for
> the postscript driver.

They may be harder than you think, as PS is a more powerful language than 
PDF.

I don't see the point here.  Postscript files have an orientation (in the 
DSC comments), and PDF files do not.  For postscript just swapping width 
and height is not enough, for pdf it might be.  If you want to do just 
that, why not write your own wrapper to pdf?  However, note that viewers 
may well decide on the orientation automatically or via 
user-specification, so there is no way I know of to make PDFs that will 
print/display in particular orientations.  Again unlike postscript, PDF is 
not designed to be sent directly to a printer.

> Kevin Wright
>
> 	[[alternative HTML version deleted]]

Time to read the posting guide ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From charles.dupont at vanderbilt.edu  Thu Mar  9 17:19:53 2006
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Thu, 09 Mar 2006 10:19:53 -0600
Subject: [Rd] Expanding partial names
In-Reply-To: <440E3EE6.4060901@stats.uwo.ca>
References: <440D9295.7090207@stats.uwo.ca>	<eb555e660603071100r57d5f956v453161406fb32c65@mail.gmail.com>	<440E2234.5090406@stats.uwo.ca>
	<440E3EE6.4060901@stats.uwo.ca>
Message-ID: <441055A9.1070203@vanderbilt.edu>

Duncan Murdoch wrote:
> Okay, here's my effort based on Deepayan's and Charles' ideas.  The 
> newArgs function is not what I'd call transparent, but I like the way 
> the wrapper looks.
> 
>  > newArgs <- function(..., Params) {
> +   f <- function(...) list(...)
> +   formals(f) <- c(Params, formals(f))
> 
> +   b <- as.list(body(f))
> +   body(f) <- as.call(c(b[1], names, b[-1]))
> +   f(...)
> + }
>  >
>  > lowlevel <- function(longname = 1) {
> +   cat("longname = ", longname, "\n")
> + }
>  >
>  > newDefaults <- list(longname=2)
>  >
>  > wrapper <- function (...)
> +   do.call("lowlevel", newArgs(..., Params=newDefaults))
> 
> newArgs sets up f to look like
> 
> function (longname = 2, ...) list(longname = longname, ...)
> 
> and then calls it.  The thing I like about this, as opposed to using 
> pmatch, is that I'm sure the partial matching is what's used by R's 
> argument matching, whereas that's only pretty likely with pmatch.
> 
> I also sort of like these lines:
> 
> +   names <- as.list(names(Params))
> +   names(names) <- names
> +   names <- lapply(names, as.name)
> 
> but maybe I should have named Params as names, so they looked like this:
> 
> +   names <- as.list(names(names))
> +   names(names) <- names
> +   names <- lapply(names, as.name)
> 
> And of course I like the fact that this seems to work, but we've seen 
> several versions that do that:
> 
>  > wrapper()
> longname =  2
>  > wrapper(longname=3)
> longname =  3
>  > wrapper(long=3)
> longname =  3
>  > wrapper(long=20)
> longname =  20
>  > wrapper(junk=20)
> Error in lowlevel(longname = 2, junk = 20) :
>          unused argument(s) (junk ...)
> 

If while running the program you don't need to change either the default 
options of the wrapper or the change which lowlevel function is called 
this approach works well if you calculations are not too complicated.

createWrapper <- function(FUN, Params) {
   as.function(c(replace(formals(FUN), names(Params), Params),
                 body(FUN)))
}

const <- 10

newDefaults <- alist(cat = 2,
                      longname = if(cat == 2){
                        if(!missing(dog)) cat + dog
                        else cat + 2
                      } else cat * const, dog=)

wrapper <- createWrapper(lowlevel, newDefaults)

 > wrapper()
longname =  4
 > wrapper(longname=3)
longname =  3
 > wrapper(long=3)
longname =  3
 > wrapper(3)
longname =  3
 > wrapper(cat=4)
longname =  40
 > wrapper(dog=6)
longname =  8
 > wrapper(cat=4, dog=6)
longname =  40
 > wrapper(long=3, cat=4, dog=6)
longname =  3

Charles


From rkannan at rcn.com  Fri Mar 10 04:31:29 2006
From: rkannan at rcn.com (Kannan Ramaswamy)
Date: Thu, 9 Mar 2006 21:31:29 -0600
Subject: [Rd] Is R threadsafe?
Message-ID: <2fc9332910fb2106847b79e4371f0fa5@rcn.com>

Hi,
I am planning to embed R in a Windows application. I would like to know 
if the R.dll dynamic library is threadsafe? Is it possible to have more 
than one thread calling R functions concurrently? Note that I am using 
Windows XP SP2 with R 2.2.1 on a dual processor SMP machine.

The last information I found in the R-devel archives was a mail from 
Duncan Temple Lang on 07-Nov-2005 saying there was a plan to make it 
threadsafe before the end of the year 
(http://tolstoy.newcastle.edu.au/R/devel/05/11/3110.html).

--Kannan.


From andy_liaw at merck.com  Fri Mar 10 22:35:20 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 10 Mar 2006 16:35:20 -0500
Subject: [Rd] problem building R-patched on x86-64 with PGI 6.1
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED913@usctmx1106.merck.com>

Dear R-devel,

[I'm not sure if this is appropriate for R-devel.  If not, I'm more than
happy to move it to R-help.]

As those of you who saw my post on R-help know, I've been trying to build
R-patched on a dual Opteron box running Scyld Beowulf, using the PGI 6.1
compilers.  The build went fine, but I couldn't get it to pass make
check-all.  Jennifer Lai, who reported success with PGI 6.0 previously,
seems to have the same problem with 6.1.  Here are the particulars:

Since R requires IEEE754 conformance, the flag to use for PGI is -Kieee.
(BTW, configure still insist on sticking in -mieee-fp, which generates a
warning.)  With that flag, the build runs into trouble with the first
example in ?optim.  Running it by hand gives me:

> optim(c(-1.2,1), fr, control=list(trace=6))
  Nelder-Mead direct search function minimizer
function value for initial parameters = 24.200000
  Scaled convergence tolerance is 3.60608e-07
Stepsize computed as 0.120000
BUILD              3 24.200000 7.095296
REFLECTION         5 15.080000 4.541696
REFLECTION         7 7.095296 4.456256
[...]
HI-REDUCTION     191 0.000002 0.000000
LO-REDUCTION     193 0.000001 0.000000

and the process just hangs (until ctrl-z and kill -9).

If I build R without the -Kieee flag, make check-all fails at arith-true.R,
in particular, the following:

> pretty(pi, n = 10) - 2:5
[1] -2.220446e-16 -4.440892e-16 -8.881784e-16 -8.881784e-16

whereas the build with the -Kieee flag gives:

> pretty(pi, n = 10) - 2:5
[1] 0 0 0 0

and can pass the arith-true.R test.

The configuration is as follows:

export PG_HOME=/usr/pgi/linux86-64/6.1 
~/Rbuild/R-patched/configure \
     CC=pgcc \
     CFLAGS="-g -Kieee" \
     CPPFLAGS="-I$PG_HOME/include -I$PG_HOME/include/CC" \
     CPICFLAGS=-fpic \
     F77=pgf95 \
     FFLAGS="-g -Kieee"\
     FPICFLAGS=-fpic \
     CXX=pgCC \
     CXXFLAGS="-g -Kieee" \
     CXXPICFLAGS=-fpic \
     SHLIB_CXXLDFLAGS=-shared \
     SHLIB_LDFLAGS=-shared \
     LDFLAGS="-L$PG_HOME/libso -L/usr/lib64 -L/usr/X11R6/lib64" \
     --without-tcltk \
     --with-blas="-L/usr/pgi/linux86-64/6.1/libso -lacml"

[The pgf95 (or pgf90) is needed for linking against ACML to work.  This
should be unrelated as optim is in C.]

I'd very much appreciate any pointers.

Best,
Andy


Andy Liaw, PhD
Biometrics Research    PO Box 2000 RY33-300
Merck Research Labs        Rahway, NJ 07065
andy_liaw(a)merck.com          732-594-0820


From ripley at stats.ox.ac.uk  Sat Mar 11 09:02:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 11 Mar 2006 08:02:11 +0000 (GMT)
Subject: [Rd] problem building R-patched on x86-64 with PGI 6.1
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED913@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED913@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.64.0603110749470.6922@gannet.stats.ox.ac.uk>

On Fri, 10 Mar 2006, Liaw, Andy wrote:

> Dear R-devel,
>
> [I'm not sure if this is appropriate for R-devel.  If not, I'm more than
> happy to move it to R-help.]

It is certainly not appropriate to R-help: see the posting guide.

> As those of you who saw my post on R-help know, I've been trying to build
> R-patched on a dual Opteron box running Scyld Beowulf, using the PGI 6.1
> compilers.  The build went fine, but I couldn't get it to pass make
> check-all.  Jennifer Lai, who reported success with PGI 6.0 previously,
> seems to have the same problem with 6.1.  Here are the particulars:
>
> Since R requires IEEE754 conformance, the flag to use for PGI is -Kieee.
> (BTW, configure still insist on sticking in -mieee-fp, which generates a
> warning.)  With that flag, the build runs into trouble with the first
> example in ?optim.  Running it by hand gives me:

Well, configure insists on doing so because we were told it was correct.
(Will change.)  Is -Kieee always correct for PG?
Looking at

http://www.amd.com/us-en/assets/content_type/DownloadableAssets/dwamd_PGI_nov603.pdf

suggests you might want to try -pc64 -Kieee.

>> optim(c(-1.2,1), fr, control=list(trace=6))
>  Nelder-Mead direct search function minimizer
> function value for initial parameters = 24.200000
>  Scaled convergence tolerance is 3.60608e-07
> Stepsize computed as 0.120000
> BUILD              3 24.200000 7.095296
> REFLECTION         5 15.080000 4.541696
> REFLECTION         7 7.095296 4.456256
> [...]
> HI-REDUCTION     191 0.000002 0.000000
> LO-REDUCTION     193 0.000001 0.000000
>
> and the process just hangs (until ctrl-z and kill -9).

This could well be a problem with extended precision: I'll see if I can 
spot anything.

> If I build R without the -Kieee flag, make check-all fails at arith-true.R,
> in particular, the following:
>
>> pretty(pi, n = 10) - 2:5
> [1] -2.220446e-16 -4.440892e-16 -8.881784e-16 -8.881784e-16
>
> whereas the build with the -Kieee flag gives:
>
>> pretty(pi, n = 10) - 2:5
> [1] 0 0 0 0
>
> and can pass the arith-true.R test.
>
> The configuration is as follows:
>
> export PG_HOME=/usr/pgi/linux86-64/6.1
> ~/Rbuild/R-patched/configure \
>     CC=pgcc \
>     CFLAGS="-g -Kieee" \
>     CPPFLAGS="-I$PG_HOME/include -I$PG_HOME/include/CC" \
>     CPICFLAGS=-fpic \
>     F77=pgf95 \
>     FFLAGS="-g -Kieee"\
>     FPICFLAGS=-fpic \
>     CXX=pgCC \
>     CXXFLAGS="-g -Kieee" \
>     CXXPICFLAGS=-fpic \
>     SHLIB_CXXLDFLAGS=-shared \
>     SHLIB_LDFLAGS=-shared \
>     LDFLAGS="-L$PG_HOME/libso -L/usr/lib64 -L/usr/X11R6/lib64" \
>     --without-tcltk \
>     --with-blas="-L/usr/pgi/linux86-64/6.1/libso -lacml"
>
> [The pgf95 (or pgf90) is needed for linking against ACML to work.  This
> should be unrelated as optim is in C.]
>
> I'd very much appreciate any pointers.
>
> Best,
> Andy
>
>
> Andy Liaw, PhD
> Biometrics Research    PO Box 2000 RY33-300
> Merck Research Labs        Rahway, NJ 07065
> andy_liaw(a)merck.com          732-594-0820
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Mar 11 12:29:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 11 Mar 2006 11:29:45 +0000 (GMT)
Subject: [Rd] Peculiar timing result
In-Reply-To: <Pine.LNX.4.64.0603031749580.21096@gannet.stats.ox.ac.uk>
References: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
	<Pine.LNX.4.64.0603031749580.21096@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0603111122210.23496@gannet.stats.ox.ac.uk>

Here is a summary of some results on a dual Opteron 252 running FC3

64-bit gcc 3.4.5
R's blas		34.83  3.45 38.56
ATLAS			36.70  3.28 40.14
ATLAS multithread	76.85  5.39 82.29
Goto 1 thread		36.17  3.44 39.76
Goto multithread       178.06 345.97 467.99
ACML			49.69  3.36 53.23

64-bit gcc 4.1.0
R's blas		34.98  3.49 38.55
32-bit gcc 3.4.5
R's blas		33.72  3.27 36.99
32-bit gcc 4.1.0
R's blas		34.62  3.25 37.93

The timings are not that repeatable, but the message seems clear that
this problem does not benefit from a tuned BLAS and the overhead from 
multiple threads is harmful.  (The gcc 4.1.0 results took fewer 
iterations, which skews the results in its favour.)

And my 2GHz Pentium M laptop under Windows gave 39.96  3.68 44.06.

Clearly the Goto BLAS has a problem here: the results are slower on a dual 
252 than a dual 248 (see below).


On Fri, 3 Mar 2006, Prof Brian Ripley wrote:

> On Fri, 3 Mar 2006, Douglas Bates wrote:
>
>> I have been timing a particular model fit using lmer on several
>> different computers and came up with a peculiar result - the model fit
>> is considerably slower on a dual-core Athlon 64 using Goto's
>> multithreaded BLAS than on a single-core processor.
>
> Is there a Goto BLAS tuned for that chip?  I can only see one tuned for an
> (unspecified) Opteron.  L1 and L2 cache sizes do sometimes matter a lot
> for tuned BLAS, and (according to the AMD site I just looked up) the X2
> 3800+ only has a 512Kb per core L2 cache.  Opterons have a 1Mb L2 cache.
>
> Also, the very large system time seen in the dual-core run is typical of
> what I see when pthreads is not working right, and I suggest you try a
> limit of one thread (see the R-admin manual).  On our dual-processor
> Opteron 248 that ran in 44 secs instead of 328.
>
>> Here is the timing on a single-core Athlon 64 3000+ running under
>> today's R-devel with version 0.995-5 of the Matrix package.
>>
>>> library(Matrix)
>>> data(star, package = 'mlmRev')
>>> system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star,
> control = list(nit=0,grad=0,msV=1)))
>> [1] 43.10  3.78 48.41  0.00  0.00
>>
>>
>> (If you run the timing yourself and don't want to see the iteration
>> output, take the msV=1 out of the control list.  I keep it in there so
>> I can monitor the progress.)
>>
>> If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
>> the same version of R, BLAS and Matrix package, the timing ends up
>> with something like
>>
>> 90 140 235 0 0
> ....
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roger at ysidro.econ.uiuc.edu  Sat Mar 11 20:28:38 2006
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sat, 11 Mar 2006 13:28:38 -0600
Subject: [Rd] Quicker quantiles?
Message-ID: <4D16D625-FFFA-4EAD-99E8-C5F459A78D99@ysidro.econ.uiuc.edu>

Motivated by Deepayan's recent inquiries about the efficiency of the  
R 'quantile'
function:

         http://tolstoy.newcastle.edu.au/R/devel/05/11/3305.html
         http://tolstoy.newcastle.edu.au/R/devel/06/03/4358.html

I decided to try to revive an old project to implement a version of  
the Floyd
and Rivest (1975) algorithm for finding quantiles with O(n)  
comparisons.  I
used to have a direct translation from FR's algol68 in my quantreg  
package,
but was forced to remove it when it encountered  g77 compilers that
didn't like the way I had handled recursion.

Fortunately, in the interim, I've corresponded with Krzysztof Kiwiel  
in Warsaw
who has made a detailed study of the algorithm:

K.C. Kiwiel: On Floyd and Rivest's SELECT Algorithm, Theoretical
       Computer Sci. 347 (2005) 214-238.

He has also kindly  agreed to allow me to incorporate his  
implementation of
the FR algorithm in R under GPL.

For the moment, I have made an alpha-test package with a single  
function --
'kuantile' -- that attempts to reproduce the functionality of the  
current
base quantile function, essentially replacing the partial sorting done
there with calls to Kiwiel's 'select' function.  This package is  
available
from:

         http://www.econ.uiuc.edu/~roger/research/rq/kuantile

The good news is that the new function  _is_ somewhat quicker than
the base 'quantile' function.  The following table is based on means
of 10 replications.  The first two columns report times for computing
just the median, the next two columns for computing the five default
quantiles:  seq(0,1,.25), and the last column is the time needed for  
a call
of sort().

         mean system.time()[1] for various calls*

           median only      default 5
n      quantile kuantile quantile kuantile      sort

100        0.002    0.001    0.004    0.004       0.000
1000      0.002    0.001    0.003    0.002       0.002
10000    0.003    0.002    0.009    0.005       0.005
1e+05    0.024    0.010    0.061    0.013       0.031
1e+06    0.206    0.120    0.535    0.142       0.502
1e+07    2.132    0.790    5.575    1.035       7.484

* On a mac G5 running R 2.2.1.

The bad news is that this approach doesn't help with Deepayan's
original question which involved instances in which quantile() was
being called for rather large number of probabilities.  In such
cases it seems that it is difficult to improve upon doing a full sort.

I would welcome comments on any of this....

url:    www.econ.uiuc.edu/~roger    Roger Koenker
email:  rkoenker at uiuc.edu           Department of Economics
vox:    217-333-4558                University of Illinois
fax:    217-244-6678                Champaign, IL 61820


From ripley at stats.ox.ac.uk  Sat Mar 11 22:00:50 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 11 Mar 2006 21:00:50 +0000 (GMT)
Subject: [Rd] Quicker quantiles?
In-Reply-To: <4D16D625-FFFA-4EAD-99E8-C5F459A78D99@ysidro.econ.uiuc.edu>
References: <4D16D625-FFFA-4EAD-99E8-C5F459A78D99@ysidro.econ.uiuc.edu>
Message-ID: <Pine.LNX.4.64.0603111959360.28498@gannet.stats.ox.ac.uk>

Please do the comparison with R-devel.  That has a different policy,
including switching to quicksort when partial has more than 10 elements.

BTW you need to compare with quicksort (which suffices here and is quite a 
lot faster than shellsort for large numeric vectors).

For 1 million+1 I am getting timings on my Windows laptop

sort 		0.39
quicksort	0.24
quantile(50%)   0.13
quantile()	0.17
kuantile(50%)   0.16
kuantile()      0.17

(timings for a million are about 50% more in the last four lines as 
roughly twice as many raw quantiles are needed.)

Note that there is never more than about a factor of three gain over 
quicksort (remembering that quantile has some overhead of its own, so I 
also timed a version of quantile always using quicksort, using about 
0.34).  Given how rare this is as a task for R, it would probably be quite 
sufficient to always use quicksort.


On Sat, 11 Mar 2006, roger koenker wrote:

> Motivated by Deepayan's recent inquiries about the efficiency of the
> R 'quantile'
> function:
>
>         http://tolstoy.newcastle.edu.au/R/devel/05/11/3305.html
>         http://tolstoy.newcastle.edu.au/R/devel/06/03/4358.html
>
> I decided to try to revive an old project to implement a version of
> the Floyd
> and Rivest (1975) algorithm for finding quantiles with O(n)
> comparisons.  I
> used to have a direct translation from FR's algol68 in my quantreg
> package,
> but was forced to remove it when it encountered  g77 compilers that
> didn't like the way I had handled recursion.
>
> Fortunately, in the interim, I've corresponded with Krzysztof Kiwiel
> in Warsaw
> who has made a detailed study of the algorithm:
>
> K.C. Kiwiel: On Floyd and Rivest's SELECT Algorithm, Theoretical
>       Computer Sci. 347 (2005) 214-238.
>
> He has also kindly  agreed to allow me to incorporate his
> implementation of
> the FR algorithm in R under GPL.
>
> For the moment, I have made an alpha-test package with a single
> function --
> 'kuantile' -- that attempts to reproduce the functionality of the
> current
> base quantile function, essentially replacing the partial sorting done
> there with calls to Kiwiel's 'select' function.  This package is
> available
> from:
>
>         http://www.econ.uiuc.edu/~roger/research/rq/kuantile
>
> The good news is that the new function  _is_ somewhat quicker than
> the base 'quantile' function.  The following table is based on means
> of 10 replications.  The first two columns report times for computing
> just the median, the next two columns for computing the five default
> quantiles:  seq(0,1,.25), and the last column is the time needed for
> a call
> of sort().
>
>         mean system.time()[1] for various calls*
>
>           median only      default 5
> n      quantile kuantile quantile kuantile      sort
>
> 100        0.002    0.001    0.004    0.004       0.000
> 1000      0.002    0.001    0.003    0.002       0.002
> 10000    0.003    0.002    0.009    0.005       0.005
> 1e+05    0.024    0.010    0.061    0.013       0.031
> 1e+06    0.206    0.120    0.535    0.142       0.502
> 1e+07    2.132    0.790    5.575    1.035       7.484
>
> * On a mac G5 running R 2.2.1.
>
> The bad news is that this approach doesn't help with Deepayan's
> original question which involved instances in which quantile() was
> being called for rather large number of probabilities.  In such
> cases it seems that it is difficult to improve upon doing a full sort.
>
> I would welcome comments on any of this....
>
> url:    www.econ.uiuc.edu/~roger    Roger Koenker
> email:  rkoenker at uiuc.edu           Department of Economics
> vox:    217-333-4558                University of Illinois
> fax:    217-244-6678                Champaign, IL 61820
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From groemping at tfh-berlin.de  Sun Mar 12 17:51:13 2006
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Sun, 12 Mar 2006 17:51:13 +0100
Subject: [Rd] Wishlist: merge and subset to keep attributes (PR#8658)
In-Reply-To: <440AF484.4040407@vanderbilt.edu>
References: <440AF484.4040407@vanderbilt.edu>
Message-ID: <20060312162915.M39698@tfh-berlin.de>

> When importing data from SPSS, it is a nice feature of the package 
> foreign that 
> it allows (option use.value.labels=F) to work with the original SPSS 
> codes while 
> keeping the value labels as information in an attribute. Unfortunately, 
> after 
> merging or subsetting, these attributes disappear. 
> The code below illustrates the problem: Variable time originally has value 
> labels that are gone after merging or subsetting. 
> 
> It would be very helpful, if this could be changed. 
> 
> With kind regards, Ulrike 
> ------------------------------- 
> 
> Ulrike - see the spss.get, label, contents, and describe functions in 
> the Hmisc package. 
> 
> -- 
> Frank E Harrell Jr ? Professor and Chair ? ? ? ? ? School of Medicine 
> ? ? ? ? ? ? ? ? ? ? ? Department of Biostatistics ? Vanderbilt University 
------- End of Original Message -------

For the sake of completeness of the thread in R-devel:
After a longer offline exchange, Frank and I have agreed that Hmisc spss.get 
currently does not offer more than read.spss from package foreign in terms of 
being able to use both original codes and value labels from SPSS files (which 
is desirable when working with large datasets from well-documented studies 
that often require filtering rules based on original codes to be applied 
while at the same time one does want to preseve annotation with value 
labels). 

The solution from package foreign: The option "use.value.labels=F" prevents 
SPSS factors (with codes and value labels) to be read into R as factors. 
Instead, codes are read as numeric values, and the value labels are preserved 
by assigning an attribute "value.labels" to each such variable. My issue is 
that these attributes are lost when subsetting or merging such datasets. I 
have no idea how difficult it is to get this changed; if it is doable without 
too much hassle, it would be great. 

And by the way - not mentioned in my wish - read.spss also assigns the 
attribute "variable.labels" to the dataset itself. This attribute is 
currently also lost when merging or subsetting. 
(Here, spss.get from Hmisc works differently by assigning each variable a 
class and a label attribute which are preserved. I have the suspicion that 
this makes spss.get substantially slower than read.spss; on the other hand, 
it makes it easier to use these labels in annotation.)

With kind regards, Ulrike


From p.dalgaard at biostat.ku.dk  Sun Mar 12 19:17:31 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Mar 2006 19:17:31 +0100
Subject: [Rd] Wishlist: merge and subset to keep attributes (PR#8658)
In-Reply-To: <20060312162915.M39698@tfh-berlin.de>
References: <440AF484.4040407@vanderbilt.edu>
	<20060312162915.M39698@tfh-berlin.de>
Message-ID: <x2fylny1c4.fsf@turmalin.kubism.ku.dk>

"Ulrike Gr?mping" <groemping at tfh-berlin.de> writes:

> > When importing data from SPSS, it is a nice feature of the package 
> > foreign that 
> > it allows (option use.value.labels=F) to work with the original SPSS 
> > codes while 
> > keeping the value labels as information in an attribute. Unfortunately, 
> > after 
> > merging or subsetting, these attributes disappear. 
> > The code below illustrates the problem: Variable time originally has value 
> > labels that are gone after merging or subsetting. 
> > 
> > It would be very helpful, if this could be changed. 
> > 
> > With kind regards, Ulrike 
> > ------------------------------- 
> > 
> > Ulrike - see the spss.get, label, contents, and describe functions in 
> > the Hmisc package. 
> > 
> > -- 
> > Frank E Harrell Jr ? Professor and Chair ? ? ? ? ? School of Medicine 
> > ? ? ? ? ? ? ? ? ? ? ? Department of Biostatistics ? Vanderbilt University 
> ------- End of Original Message -------
> 
> For the sake of completeness of the thread in R-devel:
> After a longer offline exchange, Frank and I have agreed that Hmisc spss.get 
> currently does not offer more than read.spss from package foreign in terms of 
> being able to use both original codes and value labels from SPSS files (which 
> is desirable when working with large datasets from well-documented studies 
> that often require filtering rules based on original codes to be applied 
> while at the same time one does want to preseve annotation with value 
> labels). 
> 
> The solution from package foreign: The option "use.value.labels=F" prevents 
> SPSS factors (with codes and value labels) to be read into R as factors. 
> Instead, codes are read as numeric values, and the value labels are preserved 
> by assigning an attribute "value.labels" to each such variable. My issue is 
> that these attributes are lost when subsetting or merging such datasets. I 
> have no idea how difficult it is to get this changed; if it is doable without 
> too much hassle, it would be great. 

I don't think this is possible. It is happening at the level of "["
which always strips attributes. Try for instance

x <- 1:4
attr(x, "foo") <- "bar"
x
x[1]

It's a bit unclear to me why this is so, but e.g. dimension attributes
do fairly obviously need to be removed. 

It's the sort of thing where you're bound to discover just how much
code is relying on the current behaviour (quite possibly unwittingly)
if you try to change it. 

In general it is not a good idea to change language semantics for
everyone in all contexts, just because someone is unhappy with the
behaviour in one particular context...

If you want different behaviour for a limited scope, you probably need
to do it Frank's way: by defining a class and an indexing method for
it. Or copy over the attributes as needed.
 
> And by the way - not mentioned in my wish - read.spss also assigns the 
> attribute "variable.labels" to the dataset itself. This attribute is 
> currently also lost when merging or subsetting. 
> (Here, spss.get from Hmisc works differently by assigning each variable a 
> class and a label attribute which are preserved. I have the suspicion that 
> this makes spss.get substantially slower than read.spss; on the other hand, 
> it makes it easier to use these labels in annotation.)


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Friedrich.Leisch at tuwien.ac.at  Wed Mar  8 17:57:13 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Wed, 8 Mar 2006 17:57:13 +0100
Subject: [Rd] Wishlist - Give R a name that shows up in search engines
 ...
In-Reply-To: <440EF077.2020501@cimr.cam.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED8DF@usctmx1106.merck.com>
	<1db726800603080539i56d0c73cv1121fcafdc53b5b8@mail.gmail.com>
	<440EF077.2020501@cimr.cam.ac.uk>
Message-ID: <17423.3305.319732.148326@celebrian.ci.tuwien.ac.at>

>>>>> On Wed, 08 Mar 2006 14:55:51 +0000,
>>>>> Hin-Tak Leung (HL) wrote:

  > roger bos wrote:
  >> Indeed, when I was writing code in Java or VBA and I needed code, say to 
  >> buble sort or invert a CDF, I could find many examples on the web since 
  >> the user base was so large.  R has something better: CRAN.  It was 
  >> really smart to make a central repository where useRs can share code.  
  >> No other language that I can think of really has an equivalent.  All I 
  >> have to do it search CRAN and I can find 99% of what out there (I'm 
  >> making a guess on the actual number here).
  > <snipped>

  > Hang on there - "No other language that I can think of really has
  > an equivalent." - have you heard of CPAN, and CTAN? CRAN
  > was modelled *after* CPAN, which in turn was modelled after CTAN...
  > Either of them is far bigger in size, far older in history, and far
  > more well-established.

  > In fact, I am sorry to say, the search engine of either CPAN or CTAN
  > are better than CRAN's. (this last sentence is subjective, of course).

  > Obviously not a Perl nor TeX user then.

  > (probably not a good idea to express this on r-devel, nevermind)

No problem at all ... I take it you volunteer to design, setup, host,
and maintain a better system?

Best,
Fritz


From todd at baileywick.plus.com  Mon Mar 13 00:11:45 2006
From: todd at baileywick.plus.com (todd@baileywick.plus.com)
Date: Mon, 13 Mar 2006 00:11:45 +0100 (CET)
Subject: [Rd] merge.data.frame bug report (PR#8676)
Message-ID: <20060312231145.0D36029D71@slim.kubism.ku.dk>

Merging data frames with no by variables does not append suffixes to  
column names to keep them unique.  Also, shouldn't by=NULL be a  
legitimate way to get the "Cartesian product" of two data frames,  
instead of getting the error message "'by' must specify columns"?

 > df=data.frame(col=1:3)
 > merge(df,df,by=numeric(0))
   col col
1   1   1
2   2   1
3   3   1
4   1   2
5   2   2
6   3   2
7   1   3
8   2   3
9   3   3
 >

 > merge(df,df,by=NULL)
Error in fix.by(by.x, x) : 'by' must specify column(s)
 >

 > sessionInfo()
R version 2.2.1, 2005-12-20, powerpc-apple-darwin7.9.0

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
[6] "datasets"  "base"
 >

 > version
          _
platform powerpc-apple-darwin7.9.0
arch     powerpc
os       darwin7.9.0
system   powerpc, darwin7.9.0
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R
 >


Best,
Todd Bailey


From mkdavis at math.ucalgary.ca  Mon Mar 13 00:39:11 2006
From: mkdavis at math.ucalgary.ca (mkdavis@math.ucalgary.ca)
Date: Mon, 13 Mar 2006 00:39:11 +0100 (CET)
Subject: [Rd] Logic Error (PR#8677)
Message-ID: <20060312233911.22F1329D71@slim.kubism.ku.dk>

Full_Name: Matthew Davis
Version: 2.2.0
OS: OS X (10.4.5)
Submission from: (NULL) (209.107.120.195)


the mean of my sample x is 0.2, and when I check mean(x)<=0.2 I get a TRUE
value, when I check mean(x)<=(1-0.8) I get a FALSE value.  (x <- c(0, 1, 0, 0,
0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0))


From deleeuw at stat.ucla.edu  Mon Mar 13 00:43:01 2006
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Sun, 12 Mar 2006 15:43:01 -0800
Subject: [Rd] Logic Error (PR#8677)
In-Reply-To: <20060312233911.22F1329D71@slim.kubism.ku.dk>
References: <20060312233911.22F1329D71@slim.kubism.ku.dk>
Message-ID: <7B8D9612-2B7D-4E0E-811C-F89585F404D5@stat.ucla.edu>

 > 0.2==(1-0.8)
[1] FALSE

On Mar 12, 2006, at 15:39 , mkdavis at math.ucalgary.ca wrote:

> Full_Name: Matthew Davis
> Version: 2.2.0
> OS: OS X (10.4.5)
> Submission from: (NULL) (209.107.120.195)
>
>
> the mean of my sample x is 0.2, and when I check mean(x)<=0.2 I get  
> a TRUE
> value, when I check mean(x)<=(1-0.8) I get a FALSE value.  (x <- c 
> (0, 1, 0, 0,
> 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0))
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

===
Jan de Leeuw; Distinguished Professor and Chair, UCLA Department of  
Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8125 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
.mac: jdeleeuw ++++++  aim: deleeuwjan ++++++ skype: j_deleeuw
homepages: http://gifi.stat.ucla.edu ++++++ http://www.cuddyvalley.org
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au


From murdoch at stats.uwo.ca  Mon Mar 13 00:48:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 12 Mar 2006 18:48:23 -0500
Subject: [Rd] Logic Error (PR#8677)
In-Reply-To: <20060312233911.22F1329D71@slim.kubism.ku.dk>
References: <20060312233911.22F1329D71@slim.kubism.ku.dk>
Message-ID: <4414B347.4030700@stats.uwo.ca>

On 3/12/2006 6:39 PM, mkdavis at math.ucalgary.ca wrote:
> Full_Name: Matthew Davis
> Version: 2.2.0
> OS: OS X (10.4.5)
> Submission from: (NULL) (209.107.120.195)
> 
> 
> the mean of my sample x is 0.2, and when I check mean(x)<=0.2 I get a TRUE
> value, when I check mean(x)<=(1-0.8) I get a FALSE value.  (x <- c(0, 1, 0, 0,
> 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0))

Why make this so complicated?  The natural conclusion from that is that 
0.2 is not equal to (1-0.8), and indeed:

 > (1-0.8) == 0.2
[1] FALSE

The problem is that neither 0.2 nor 0.8 can be represented exactly, so 
when you do calculations using them you are doing approximations.  The 
approximation involving your mean is different than the one involving 
(1-0.8).  This is an FAQ,

7.31 Why doesn't R think these numbers are equal?

This is not a bug.

Duncan Murdoch


From jkawczak at uncc.edu  Mon Mar 13 01:08:01 2006
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Sun, 12 Mar 2006 19:08:01 -0500 (EST)
Subject: [Rd] Logic Error (PR#8677)
In-Reply-To: <4414B347.4030700@stats.uwo.ca>
References: <20060312233911.22F1329D71@slim.kubism.ku.dk>
	<4414B347.4030700@stats.uwo.ca>
Message-ID: <Pine.GSO.4.55.0603121903090.10870@is-sm1.uncc.edu>

However, mean(x)==0.2 returns TRUE
Also, mean(x)>=(1-0.8) returns TRUE ;)

So, it's not just the approximation calculus.

On Sun, 12 Mar 2006, Duncan Murdoch wrote:

> On 3/12/2006 6:39 PM, mkdavis at math.ucalgary.ca wrote:
> > Full_Name: Matthew Davis
> > Version: 2.2.0
> > OS: OS X (10.4.5)
> > Submission from: (NULL) (209.107.120.195)
> >
> >
> > the mean of my sample x is 0.2, and when I check mean(x)<=0.2 I get a TRUE
> > value, when I check mean(x)<=(1-0.8) I get a FALSE value.  (x <- c(0, 1, 0, 0,
> > 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0))
>
> Why make this so complicated?  The natural conclusion from that is that
> 0.2 is not equal to (1-0.8), and indeed:
>
>  > (1-0.8) == 0.2
> [1] FALSE
>
> The problem is that neither 0.2 nor 0.8 can be represented exactly, so
> when you do calculations using them you are doing approximations.  The
> approximation involving your mean is different than the one involving
> (1-0.8).  This is an FAQ,
>
> 7.31 Why doesn't R think these numbers are equal?
>
> This is not a bug.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Mon Mar 13 01:23:52 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 12 Mar 2006 19:23:52 -0500
Subject: [Rd] Logic Error (PR#8677)
In-Reply-To: <Pine.GSO.4.55.0603121903090.10870@is-sm1.uncc.edu>
References: <20060312233911.22F1329D71@slim.kubism.ku.dk>
	<4414B347.4030700@stats.uwo.ca>
	<Pine.GSO.4.55.0603121903090.10870@is-sm1.uncc.edu>
Message-ID: <4414BB98.5060504@stats.uwo.ca>

On 3/12/2006 7:08 PM, Janusz Kawczak wrote:
> However, mean(x)==0.2 returns TRUE
> Also, mean(x)>=(1-0.8) returns TRUE ;)
> 
> So, it's not just the approximation calculus.

I don't get your point.  On my computer,

 > 1-0.8 < 0.2
[1] TRUE

which is consistent with what I wrote below and what you write above. 
mean(x) comes out to the same approximation as the constant 0.2 uses, 
but 1-0.8 doesn't, it comes out smaller.

Duncan Murdoch

> 
> On Sun, 12 Mar 2006, Duncan Murdoch wrote:
> 
>> On 3/12/2006 6:39 PM, mkdavis at math.ucalgary.ca wrote:
>>> Full_Name: Matthew Davis
>>> Version: 2.2.0
>>> OS: OS X (10.4.5)
>>> Submission from: (NULL) (209.107.120.195)
>>>
>>>
>>> the mean of my sample x is 0.2, and when I check mean(x)<=0.2 I get a TRUE
>>> value, when I check mean(x)<=(1-0.8) I get a FALSE value.  (x <- c(0, 1, 0, 0,
>>> 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0))
>> Why make this so complicated?  The natural conclusion from that is that
>> 0.2 is not equal to (1-0.8), and indeed:
>>
>>  > (1-0.8) == 0.2
>> [1] FALSE
>>
>> The problem is that neither 0.2 nor 0.8 can be represented exactly, so
>> when you do calculations using them you are doing approximations.  The
>> approximation involving your mean is different than the one involving
>> (1-0.8).  This is an FAQ,
>>
>> 7.31 Why doesn't R think these numbers are equal?
>>
>> This is not a bug.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From westfeld at inf.tu-dresden.de  Mon Mar 13 10:52:25 2006
From: westfeld at inf.tu-dresden.de (westfeld@inf.tu-dresden.de)
Date: Mon, 13 Mar 2006 10:52:25 +0100 (CET)
Subject: [Rd] Sys.sleep waits forever + workaround (PR#8678)
Message-ID: <20060313095225.256D629C30@slim.kubism.ku.dk>

When I tried to schedule a calculation for the next day (waiting several
10000 seconds), I noticed that Sys.sleep does never return (R version
2.1.0 on Linux). From the C code I expect that the maximum number of
seconds is about 2000 (2^31/1e6), which is system-dependent.

##Sys.sleep <- function(time)
##    invisible(.Internal(Sys.sleep(time)))

Sys.sleep <- function(time) {
        nloops <- time%/%1000
        while (nloops>0) {
                nloops <- nloops-1
                .Internal(Sys.sleep(1000))
        }
        invisible(.Internal(Sys.sleep(time%%1000)))
}


-- 
Andreas Westfeld, 0432 01CC F511 9E2B 0B57 5993 0B22 98F8 4AD8 EEEA
<westfeld at inf.tu-dresden.de> http://www.inf.tu-dresden.de/~aw4
TU Dresden Fakult?t Informatik, Institut f?r Systemarchitektur
Datenschutz und Datensicherheit, Tel. +49-351-463-37918


From ripley at stats.ox.ac.uk  Mon Mar 13 11:10:38 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 13 Mar 2006 11:10:38 +0100 (CET)
Subject: [Rd] Sys.sleep waits forever + workaround (PR#8678)
Message-ID: <20060313101038.B9EC9102CB@slim.kubism.ku.dk>

On Mon, 13 Mar 2006, westfeld at inf.tu-dresden.de wrote:

> When I tried to schedule a calculation for the next day (waiting several
> 10000 seconds), I noticed that Sys.sleep does never return (R version
> 2.1.0 on Linux). From the C code I expect that the maximum number of
> seconds is about 2000 (2^31/1e6), which is system-dependent.

Actually, it is not: is always (2^31-1)/1e6.

This is easy to fix at C level, and I have done so.

>
> ##Sys.sleep <- function(time)
> ##    invisible(.Internal(Sys.sleep(time)))
>
> Sys.sleep <- function(time) {
>        nloops <- time%/%1000
>        while (nloops>0) {
>                nloops <- nloops-1
>                .Internal(Sys.sleep(1000))
>        }
>        invisible(.Internal(Sys.sleep(time%%1000)))
> }
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ales.ziberna at gmail.com  Mon Mar 13 12:30:55 2006
From: ales.ziberna at gmail.com (=?ISO-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Mon, 13 Mar 2006 12:30:55 +0100
Subject: [Rd] Building help pages
Message-ID: <441557EF.7000900@gmail.com>

Hello!

I was just wondering, why only one of my "Rd" files is converted in 
"chm" format (REGE) and the other are not when installing a package? The 
output from installing a package on WinXp is below.

I tried to find more information about what "chm" format actually is, 
however have found none.

Best regards and thaks for any replies,
Ales Ziberna


C:\Ales\Statistika>R CMD INSTALL blockmodeling


---------- Making package blockmodeling ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  making DLL ...
  ... DLL made
  installing DLL
  installing R files
  installing man source files
  installing indices
  installing help
 >>> Building/Updating help pages for package 'blockmodeling'
     Formats: text html latex example chm
  Pajek                             text    html    latex
  REGE                              text    html    latex   example chm
  check.these.par                   text    html    latex   example
  clu                               text    html    latex   example
  crit.fun                          text    html    latex   example
  find.m                            text    html    latex
  formatA                           text    html    latex   example
  fun.by.blocks                     text    html    latex   example
  gplot1                            text    html    latex
  nkpartitions                      text    html    latex   example
  opt.par                           text    html    latex   example
  opt.random.par                    text    html    latex   example
  plot.mat                          text    html    latex   example
  rand                              text    html    latex
  recode                            text    html    latex   example
  sedist                            text    html    latex   example
  ss                                text    html    latex
  two2one                           text    html    latex   example
Microsoft HTML Help Compiler 4.74.8702

Compiling c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm


Compile time: 0 minutes, 3 seconds
19      Topics
144     Local links
7       Internet links
1       Graphic


Created c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm, 59,385 bytes
Compression decreased file by 44,606 bytes.
  preparing package blockmodeling for lazy loading
  adding MD5 sums


From ligges at statistik.uni-dortmund.de  Mon Mar 13 12:54:19 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 13 Mar 2006 12:54:19 +0100
Subject: [Rd] Building help pages
In-Reply-To: <441557EF.7000900@gmail.com>
References: <441557EF.7000900@gmail.com>
Message-ID: <44155D6B.2020803@statistik.uni-dortmund.de>

Ale? ?iberna wrote:

> Hello!
> 
> I was just wondering, why only one of my "Rd" files is converted in 
> "chm" format (REGE) and the other are not when installing a package? The 
> output from installing a package on WinXp is below.

I guess your are installing from a source directory from which you 
already have installed some time ago. The chm files correpsonding to 
*unchanged* Rd files are not re-generated. So In guess only REGE.Rd has 
changed in the meantime.


> I tried to find more information about what "chm" format actually is, 
> however have found none.

Microsoft's compiled html format can be accessed by, e.g.
options(chmhelp=TRUE)
?plot

Uwe Ligges


> Best regards and thaks for any replies,
> Ales Ziberna
> 
> 
> C:\Ales\Statistika>R CMD INSTALL blockmodeling
> 
> 
> ---------- Making package blockmodeling ------------
>   adding build stamp to DESCRIPTION
>   installing NAMESPACE file and metadata
>   making DLL ...
>   ... DLL made
>   installing DLL
>   installing R files
>   installing man source files
>   installing indices
>   installing help
>  >>> Building/Updating help pages for package 'blockmodeling'
>      Formats: text html latex example chm
>   Pajek                             text    html    latex
>   REGE                              text    html    latex   example chm
>   check.these.par                   text    html    latex   example
>   clu                               text    html    latex   example
>   crit.fun                          text    html    latex   example
>   find.m                            text    html    latex
>   formatA                           text    html    latex   example
>   fun.by.blocks                     text    html    latex   example
>   gplot1                            text    html    latex
>   nkpartitions                      text    html    latex   example
>   opt.par                           text    html    latex   example
>   opt.random.par                    text    html    latex   example
>   plot.mat                          text    html    latex   example
>   rand                              text    html    latex
>   recode                            text    html    latex   example
>   sedist                            text    html    latex   example
>   ss                                text    html    latex
>   two2one                           text    html    latex   example
> Microsoft HTML Help Compiler 4.74.8702
> 
> Compiling c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm
> 
> 
> Compile time: 0 minutes, 3 seconds
> 19      Topics
> 144     Local links
> 7       Internet links
> 1       Graphic
> 
> 
> Created c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm, 59,385 bytes
> Compression decreased file by 44,606 bytes.
>   preparing package blockmodeling for lazy loading
>   adding MD5 sums
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ales.ziberna at gmail.com  Mon Mar 13 13:01:15 2006
From: ales.ziberna at gmail.com (=?windows-1252?Q?Ale=9A_=8Eiberna?=)
Date: Mon, 13 Mar 2006 13:01:15 +0100
Subject: [Rd] Building help pages
In-Reply-To: <44155D6B.2020803@statistik.uni-dortmund.de>
References: <441557EF.7000900@gmail.com>
	<44155D6B.2020803@statistik.uni-dortmund.de>
Message-ID: <44155F0B.40607@gmail.com>

Thank you for this clarification. You are off course right, this was the 
only "Rd" file that was changed.

Best regards,
Ales Ziberna

Uwe Ligges pravi:
> Ale? ?iberna wrote:
>
>> Hello!
>>
>> I was just wondering, why only one of my "Rd" files is converted in 
>> "chm" format (REGE) and the other are not when installing a package? 
>> The output from installing a package on WinXp is below.
>
> I guess your are installing from a source directory from which you 
> already have installed some time ago. The chm files correpsonding to 
> *unchanged* Rd files are not re-generated. So In guess only REGE.Rd 
> has changed in the meantime.
>
>
>> I tried to find more information about what "chm" format actually is, 
>> however have found none.
>
> Microsoft's compiled html format can be accessed by, e.g.
> options(chmhelp=TRUE)
> ?plot
>
> Uwe Ligges
>
>
>> Best regards and thaks for any replies,
>> Ales Ziberna
>>
>>
>> C:\Ales\Statistika>R CMD INSTALL blockmodeling
>>
>>
>> ---------- Making package blockmodeling ------------
>>   adding build stamp to DESCRIPTION
>>   installing NAMESPACE file and metadata
>>   making DLL ...
>>   ... DLL made
>>   installing DLL
>>   installing R files
>>   installing man source files
>>   installing indices
>>   installing help
>>  >>> Building/Updating help pages for package 'blockmodeling'
>>      Formats: text html latex example chm
>>   Pajek                             text    html    latex
>>   REGE                              text    html    latex   example chm
>>   check.these.par                   text    html    latex   example
>>   clu                               text    html    latex   example
>>   crit.fun                          text    html    latex   example
>>   find.m                            text    html    latex
>>   formatA                           text    html    latex   example
>>   fun.by.blocks                     text    html    latex   example
>>   gplot1                            text    html    latex
>>   nkpartitions                      text    html    latex   example
>>   opt.par                           text    html    latex   example
>>   opt.random.par                    text    html    latex   example
>>   plot.mat                          text    html    latex   example
>>   rand                              text    html    latex
>>   recode                            text    html    latex   example
>>   sedist                            text    html    latex   example
>>   ss                                text    html    latex
>>   two2one                           text    html    latex   example
>> Microsoft HTML Help Compiler 4.74.8702
>>
>> Compiling c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm
>>
>>
>> Compile time: 0 minutes, 3 seconds
>> 19      Topics
>> 144     Local links
>> 7       Internet links
>> 1       Graphic
>>
>>
>> Created c:\Ales\Statistika\blockmodeling\chm\blockmodeling.chm, 
>> 59,385 bytes
>> Compression decreased file by 44,606 bytes.
>>   preparing package blockmodeling for lazy loading
>>   adding MD5 sums
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From lai at lindaspaces.com  Mon Mar 13 16:19:31 2006
From: lai at lindaspaces.com (Jennifer Lai)
Date: Mon, 13 Mar 2006 10:19:31 -0500
Subject: [Rd] problem building R-patched on x86-64 with PGI 6.1
In-Reply-To: <Pine.LNX.4.64.0603110749470.6922@gannet.stats.ox.ac.uk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED913@usctmx1106.merck.com>
	<Pine.LNX.4.64.0603110749470.6922@gannet.stats.ox.ac.uk>
Message-ID: <44158D83.10607@lindaspaces.com>

Prof Brian Ripley wrote:

>
>> As those of you who saw my post on R-help know, I've been trying to 
>> build
>> R-patched on a dual Opteron box running Scyld Beowulf, using the PGI 6.1
>> compilers.  The build went fine, but I couldn't get it to pass make
>> check-all.  Jennifer Lai, who reported success with PGI 6.0 previously,
>> seems to have the same problem with 6.1.  Here are the particulars:
>>
>> Since R requires IEEE754 conformance, the flag to use for PGI is -Kieee.
>> (BTW, configure still insist on sticking in -mieee-fp, which generates a
>> warning.)  With that flag, the build runs into trouble with the first
>> example in ?optim.  Running it by hand gives me:
>
>
> Well, configure insists on doing so because we were told it was correct.
> (Will change.)  Is -Kieee always correct for PG?
> Looking at
>
> http://www.amd.com/us-en/assets/content_type/DownloadableAssets/dwamd_PGI_nov603.pdf 
>
>
> suggests you might want to try -pc64 -Kieee.
>
Thanks, Prof. Ripley! The optim example pass the sanity check with -pc64 
-Kieee flag.
"make check" now fails at reg-tests-1.R


Regards,
Jennifer


From murdoch at stats.uwo.ca  Mon Mar 13 18:33:01 2006
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon, 13 Mar 2006 18:33:01 +0100 (CET)
Subject: [Rd] [R] dotchart: Gap between text and chart (PR#8681)
Message-ID: <20060313173301.4874F102CB@slim.kubism.ku.dk>

(Moved from r-help)

On 3/13/2006 9:33 AM, Dietrich Trenkler wrote:
> I have some data which I would like to display with dotchart. The
> labels are very long, so the chart becomes too small. Setting cex=0.7
> seems to be a good compromise, but the gap between the text and the
> chart still is too large. I did not find a "gap" parameter in the
> description of dotchart...
> 
> Thanks for any help.
> 
> D. Trenkler
> 
> 
> "a" <- structure(c(103.35, 36.73, 55.09, 302.66, 68.54, 35.46,
>     138.65, 25.21, 110.85, 6.66, 46.57, 70.23), .Names = 
> c("Nahrungsmittel und alkoholfreie Getraenke",
>     "Alkoholische Getraenke, Tabakwaren", "Bekleidung und Schuhe",
>     "Wohnungsmieten, Energie", "Einrichtungsgegenstaende", 
> "Gesundheitspflege",
>     "Verkehr", "Nachrichtenuebermittlung", "Freizeit, Unterhaltung  und 
> Kultur",
>     "Bildungswesen", "Beherbergungs und Gaststaettendienstleistungen",
>     "Andere Waren und Dienstleistungen"))
> 
> dotchart(sort(a))
> dotchart(sort(a),cex=0.7)

I've determined that this is a bug in dotchart.  It miscalculates the 
height of a line of text in the right margin, using

  lheight <- strheight("M", "inch")

which doesn't give the right answer.  You get the correct answer in this 
case by putting

  lheight <- par("mai")[2]/par("mar")[2]

but that's not a general solution, as the denominator may be zero.

I'll look for a better solution.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Mar 13 18:55:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Mar 2006 17:55:48 +0000 (GMT)
Subject: [Rd] [R] dotchart: Gap between text and chart (PR#8681)
In-Reply-To: <20060313173301.4874F102CB@slim.kubism.ku.dk>
References: <20060313173301.4874F102CB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0603131752560.4969@gannet.stats.ox.ac.uk>

On Mon, 13 Mar 2006, murdoch at stats.uwo.ca wrote:

> (Moved from r-help)
>
> On 3/13/2006 9:33 AM, Dietrich Trenkler wrote:
>> I have some data which I would like to display with dotchart. The
>> labels are very long, so the chart becomes too small. Setting cex=0.7
>> seems to be a good compromise, but the gap between the text and the
>> chart still is too large. I did not find a "gap" parameter in the
>> description of dotchart...
>>
>> Thanks for any help.
>>
>> D. Trenkler
>>
>>
>> "a" <- structure(c(103.35, 36.73, 55.09, 302.66, 68.54, 35.46,
>>     138.65, 25.21, 110.85, 6.66, 46.57, 70.23), .Names =
>> c("Nahrungsmittel und alkoholfreie Getraenke",
>>     "Alkoholische Getraenke, Tabakwaren", "Bekleidung und Schuhe",
>>     "Wohnungsmieten, Energie", "Einrichtungsgegenstaende",
>> "Gesundheitspflege",
>>     "Verkehr", "Nachrichtenuebermittlung", "Freizeit, Unterhaltung  und
>> Kultur",
>>     "Bildungswesen", "Beherbergungs und Gaststaettendienstleistungen",
>>     "Andere Waren und Dienstleistungen"))
>>
>> dotchart(sort(a))
>> dotchart(sort(a),cex=0.7)
>
> I've determined that this is a bug in dotchart.  It miscalculates the
> height of a line of text in the right margin, using
>
>  lheight <- strheight("M", "inch")
>
> which doesn't give the right answer.  You get the correct answer in this
> case by putting
>
>  lheight <- par("mai")[2]/par("mar")[2]
>
> but that's not a general solution, as the denominator may be zero.
>
> I'll look for a better solution.

Like setting mai not mar?  The ratio is par("csi"), by the way.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Mon Mar 13 19:48:18 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Mar 2006 13:48:18 -0500
Subject: [Rd] [R] dotchart: Gap between text and chart (PR#8681)
In-Reply-To: <Pine.LNX.4.64.0603131752560.4969@gannet.stats.ox.ac.uk>
References: <20060313173301.4874F102CB@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0603131752560.4969@gannet.stats.ox.ac.uk>
Message-ID: <4415BE72.4080100@stats.uwo.ca>

On 3/13/2006 12:55 PM, Prof Brian Ripley wrote:
> On Mon, 13 Mar 2006, murdoch at stats.uwo.ca wrote:
> 
>> (Moved from r-help)
>>
>> On 3/13/2006 9:33 AM, Dietrich Trenkler wrote:
>>> I have some data which I would like to display with dotchart. The
>>> labels are very long, so the chart becomes too small. Setting cex=0.7
>>> seems to be a good compromise, but the gap between the text and the
>>> chart still is too large. I did not find a "gap" parameter in the
>>> description of dotchart...
>>>
>>> Thanks for any help.
>>>
>>> D. Trenkler
>>>
>>>
>>> "a" <- structure(c(103.35, 36.73, 55.09, 302.66, 68.54, 35.46,
>>>     138.65, 25.21, 110.85, 6.66, 46.57, 70.23), .Names =
>>> c("Nahrungsmittel und alkoholfreie Getraenke",
>>>     "Alkoholische Getraenke, Tabakwaren", "Bekleidung und Schuhe",
>>>     "Wohnungsmieten, Energie", "Einrichtungsgegenstaende",
>>> "Gesundheitspflege",
>>>     "Verkehr", "Nachrichtenuebermittlung", "Freizeit, Unterhaltung  und
>>> Kultur",
>>>     "Bildungswesen", "Beherbergungs und Gaststaettendienstleistungen",
>>>     "Andere Waren und Dienstleistungen"))
>>>
>>> dotchart(sort(a))
>>> dotchart(sort(a),cex=0.7)
>>
>> I've determined that this is a bug in dotchart.  It miscalculates the
>> height of a line of text in the right margin, using
>>
>>  lheight <- strheight("M", "inch")
>>
>> which doesn't give the right answer.  You get the correct answer in this
>> case by putting
>>
>>  lheight <- par("mai")[2]/par("mar")[2]
>>
>> but that's not a general solution, as the denominator may be zero.
>>
>> I'll look for a better solution.
> 
> Like setting mai not mar?  The ratio is par("csi"), by the way.

Yes, setting mai rather than mar simplifies the code a bit, but some 
parts still need to work in lines, because mtext doesn't accept 
positioning arguments in inches.  I've used par("csi") in place of the 
ratio now, and am about to commit to r-devel and r-patched.

Duncan Murdoch


From lai at lindaspaces.com  Mon Mar 13 19:56:20 2006
From: lai at lindaspaces.com (Jennifer Lai)
Date: Mon, 13 Mar 2006 13:56:20 -0500
Subject: [Rd] problem building R-patched on x86-64 with PGI 6.1
In-Reply-To: <44158D83.10607@lindaspaces.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED913@usctmx1106.merck.com>
	<Pine.LNX.4.64.0603110749470.6922@gannet.stats.ox.ac.uk>
	<44158D83.10607@lindaspaces.com>
Message-ID: <4415C054.5000608@lindaspaces.com>


Jennifer Lai wrote:

> Prof Brian Ripley wrote:
>
>>
>>> As those of you who saw my post on R-help know, I've been trying to 
>>> build
>>> R-patched on a dual Opteron box running Scyld Beowulf, using the PGI 
>>> 6.1
>>> compilers.  The build went fine, but I couldn't get it to pass make
>>> check-all.  Jennifer Lai, who reported success with PGI 6.0 previously,
>>> seems to have the same problem with 6.1.  Here are the particulars:
>>>
>>> Since R requires IEEE754 conformance, the flag to use for PGI is 
>>> -Kieee.
>>> (BTW, configure still insist on sticking in -mieee-fp, which 
>>> generates a
>>> warning.)  With that flag, the build runs into trouble with the first
>>> example in ?optim.  Running it by hand gives me:
>>
>>
>>
>> Well, configure insists on doing so because we were told it was correct.
>> (Will change.)  Is -Kieee always correct for PG?
>> Looking at
>>
>> http://www.amd.com/us-en/assets/content_type/DownloadableAssets/dwamd_PGI_nov603.pdf 
>>
>>
>> suggests you might want to try -pc64 -Kieee.
>>
> Thanks, Prof. Ripley! The optim example pass the sanity check with 
> -pc64 -Kieee flag.
> "make check" now fails at reg-tests-1.R
>
>
Actually the -pc64 didn't help. I forgot that at some point my 
environment was configured to pick up PGI 6.0 compiler instead of PGI 
6.1 (for testing purpose).
The optim example compiled with PGI 6.0, but not PGI 6.1.

Sorry for the confusion.

- Jennifer


From Sun.Bing at epamail.epa.gov  Mon Mar 13 20:41:14 2006
From: Sun.Bing at epamail.epa.gov (Sun.Bing@epamail.epa.gov)
Date: Mon, 13 Mar 2006 11:41:14 -0800
Subject: [Rd] Help on interfacing C++ with R
Message-ID: <OFF3325189.3431239E-ON88257130.00694BA6-88257130.006C2551@epamail.epa.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060313/5ec90fde/attachment.pl

From Roger.Bivand at nhh.no  Mon Mar 13 21:01:16 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 13 Mar 2006 21:01:16 +0100 (CET)
Subject: [Rd] Help on interfacing C++ with R
In-Reply-To: <OFF3325189.3431239E-ON88257130.00694BA6-88257130.006C2551@epamail.epa.gov>
Message-ID: <Pine.LNX.4.44.0603132050340.5897-100000@reclus.nhh.no>

On Mon, 13 Mar 2006 Sun.Bing at epamail.epa.gov wrote:

> Hi, I am trying to set up a C++ library for my R code. I followed the 
> R-extension manual but found out that the example of "X.cpp, X_main.cpp" 
> is somewhat too simple. Here is my code:

Simpler is easier, all this std stuff gets in the way. The problem is that 
R is passing pointers (probably) to doubles, not simple integers. As far 
as I can see, you need to change the 

.C("testIntDivision", 4, 2);

to make sure your numbers are integers (as.integer()) is OK), and the 
function itself (provided that it is visible, and I've no idea if this is 
the case, to pointer arguments:

int testIntDivision(int&, int&); // untried

then pick out the integer values at those addresses. It'll be one or both 
of these problems (I am not fluent in C++, but the same principles apply 
to C). 

I would be concerned about exporting any competing main to load 
dynamically into R too, could you compile the code in two files, one the 
code to load into R, the other with main calling your code, and *only* 
load what needs to be inside R?

> 
>  //lib4R.h testing for interfacing C++ with R -- using C++ library in R
> #include <iostream>
> using namespace std;
> 
> class lib4R {
> public:
>         lib4R();
>         ~lib4R();
> 
>         int testIntDivision(int, int);
>         double testDoubleMultiplication(double, double);
> 
>         int getID();
>         void setID(int);
> private:
>         int ID;
> };
> 
> // lib4R.cpp : Defines the entry points for the library.
> #include "lib4R.h"
> 
> lib4R::lib4R() {
>         cout << "Constructor lib4R()" << endl;
> }
> 
> lib4R::~lib4R() {
>         cout << "Destructor ~lib4R()" << endl;
> }
> 
> extern "C" {
> 
> int lib4R::testIntDivision(int a, int b) {
>       return a/b;
> }
> 
> double lib4R::testDoubleMultiplication(double a, double b) {
>         return a*b;
> }
> 
> int lib4R::getID() {
>         return this->ID;
> }
> 
> void lib4R::setID(int ID) {
>         this->ID = ID;
> }
> 
> int main(int argc, char* argv[])
> {
>         cout << "Entering main()" << endl;
>         lib4R lib1;
> 
>         cout << "testIntDivision(4,2) = " << lib1.testIntDivision(4,2) << 
> endl;
> 
>         return 0;
> }
> 
> } // extern C
> 
> I am working on Windows. I use these to compile the dll with Visual C++:
> 
> cl /MT /c lib4R.cpp
> link /dll /out:lib4R.dll /export:testIntDivision /export:main lib4R.obj
> 
> So when I start rterm.exe:
> 
> >dyn.load("../lib4R.dll");
> >.C("main");
> Entering main()
> Constructor lib4R()
> testIntDivision(4,2) = 2
> Destructor ~lib4$()
> list()
> 
> The output is correct, but if I
> >.C("testIntDivision", 4, 2);
> 
> it generated the dialog box claiming "R has encountered a problem and 
> needs to be closed.......Please tell Microsoft about this problem....", 
> sigh.
> 
> So what's wrong with my code, how do I use individual methods/functions of 
> C++ in R?
> 
> Thanks in advance for any help you can offer!
> 
> Bing
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From bates at stat.wisc.edu  Tue Mar 14 02:10:06 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Mar 2006 19:10:06 -0600
Subject: [Rd] Peculiar timing result
In-Reply-To: <Pine.LNX.4.64.0603111122210.23496@gannet.stats.ox.ac.uk>
References: <40e66e0b0603030745r54b830bdo1f6beeb4a3f310a9@mail.gmail.com>
	<Pine.LNX.4.64.0603031749580.21096@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0603111122210.23496@gannet.stats.ox.ac.uk>
Message-ID: <40e66e0b0603131710k3013edf6wb16a683851adf0f1@mail.gmail.com>

On 3/11/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> Here is a summary of some results on a dual Opteron 252 running FC3
>
> 64-bit gcc 3.4.5
> R's blas                34.83  3.45 38.56
> ATLAS                   36.70  3.28 40.14
> ATLAS multithread       76.85  5.39 82.29
> Goto 1 thread           36.17  3.44 39.76
> Goto multithread       178.06 345.97 467.99
> ACML                    49.69  3.36 53.23
>
> 64-bit gcc 4.1.0
> R's blas                34.98  3.49 38.55
> 32-bit gcc 3.4.5
> R's blas                33.72  3.27 36.99
> 32-bit gcc 4.1.0
> R's blas                34.62  3.25 37.93
>
> The timings are not that repeatable, but the message seems clear that
> this problem does not benefit from a tuned BLAS and the overhead from
> multiple threads is harmful.  (The gcc 4.1.0 results took fewer
> iterations, which skews the results in its favour.)
>
> And my 2GHz Pentium M laptop under Windows gave 39.96  3.68 44.06.
>
> Clearly the Goto BLAS has a problem here: the results are slower on a dual
> 252 than a dual 248 (see below).

Thanks for the information on the timings.  It happens that this
message ended up in my R-help folder and I only got around to reading
that folder today.

Is it ok with you if I forward this message to Simon Urbanek?  I am
having similar difficulties in the timing with R on a dual-core Intel
MacBook.
>
>
> On Fri, 3 Mar 2006, Prof Brian Ripley wrote:
>
> > On Fri, 3 Mar 2006, Douglas Bates wrote:
> >
> >> I have been timing a particular model fit using lmer on several
> >> different computers and came up with a peculiar result - the model fit
> >> is considerably slower on a dual-core Athlon 64 using Goto's
> >> multithreaded BLAS than on a single-core processor.
> >
> > Is there a Goto BLAS tuned for that chip?  I can only see one tuned for an
> > (unspecified) Opteron.  L1 and L2 cache sizes do sometimes matter a lot
> > for tuned BLAS, and (according to the AMD site I just looked up) the X2
> > 3800+ only has a 512Kb per core L2 cache.  Opterons have a 1Mb L2 cache.
> >
> > Also, the very large system time seen in the dual-core run is typical of
> > what I see when pthreads is not working right, and I suggest you try a
> > limit of one thread (see the R-admin manual).  On our dual-processor
> > Opteron 248 that ran in 44 secs instead of 328.
> >
> >> Here is the timing on a single-core Athlon 64 3000+ running under
> >> today's R-devel with version 0.995-5 of the Matrix package.
> >>
> >>> library(Matrix)
> >>> data(star, package = 'mlmRev')
> >>> system.time(fm1 <- lmer(math~gr+sx+eth+cltype+(yrs|id)+(1|tch)+(yrs|sch), star,
> > control = list(nit=0,grad=0,msV=1)))
> >> [1] 43.10  3.78 48.41  0.00  0.00
> >>
> >>
> >> (If you run the timing yourself and don't want to see the iteration
> >> output, take the msV=1 out of the control list.  I keep it in there so
> >> I can monitor the progress.)
> >>
> >> If I time the same model fit on a dual-core Athlon 64 X2 3800+ with
> >> the same version of R, BLAS and Matrix package, the timing ends up
> >> with something like
> >>
> >> 90 140 235 0 0
> > ....
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From andy_liaw at merck.com  Tue Mar 14 05:53:12 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 13 Mar 2006 23:53:12 -0500
Subject: [Rd] problem building R-patched on x86-64 with PGI 6.1
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED92D@usctmx1106.merck.com>

Thanks to Brian, I can now get PGI 6.1 to build R-devel 
(2006-03-13 r37533) and pass make check-all, using the 
config flags I showed in my original post.  I will try
to re-build with optimizing flags, and report back if I
run into problems there.

Best,
Andy


From: Jennifer Lai 
> 
> Jennifer Lai wrote:
> 
> > Prof Brian Ripley wrote:
> >
> >>
> >>> As those of you who saw my post on R-help know, I've been 
> trying to
> >>> build
> >>> R-patched on a dual Opteron box running Scyld Beowulf, 
> using the PGI 
> >>> 6.1
> >>> compilers.  The build went fine, but I couldn't get it to 
> pass make
> >>> check-all.  Jennifer Lai, who reported success with PGI 
> 6.0 previously,
> >>> seems to have the same problem with 6.1.  Here are the 
> particulars:
> >>>
> >>> Since R requires IEEE754 conformance, the flag to use for PGI is
> >>> -Kieee.
> >>> (BTW, configure still insist on sticking in -mieee-fp, which 
> >>> generates a
> >>> warning.)  With that flag, the build runs into trouble 
> with the first
> >>> example in ?optim.  Running it by hand gives me:
> >>
> >>
> >>
> >> Well, configure insists on doing so because we were told it was 
> >> correct. (Will change.)  Is -Kieee always correct for PG? 
> Looking at
> >>
> >> 
> http://www.amd.com/us-en/assets/content_type/DownloadableAssets/dwamd
> >> _PGI_nov603.pdf
> >>
> >>
> >> suggests you might want to try -pc64 -Kieee.
> >>
> > Thanks, Prof. Ripley! The optim example pass the sanity check with
> > -pc64 -Kieee flag.
> > "make check" now fails at reg-tests-1.R
> >
> >
> Actually the -pc64 didn't help. I forgot that at some point my 
> environment was configured to pick up PGI 6.0 compiler instead of PGI 
> 6.1 (for testing purpose).
> The optim example compiled with PGI 6.0, but not PGI 6.1.
> 
> Sorry for the confusion.
> 
> - Jennifer
> 
>


From gregor.gorjanc at bfro.uni-lj.si  Tue Mar 14 09:58:22 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 14 Mar 2006 09:58:22 +0100
Subject: [Rd] Undocumented argument na.last in factor()
Message-ID: <441685AE.7070607@bfro.uni-lj.si>

Hello!

I just noticed that argument na.last in factor() is not documented. Did
I miss something or ...? I just wonder how base package passes then R
CMD check. I checked also in source man page in R-devel.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From gregor.gorjanc at bfro.uni-lj.si  Tue Mar 14 11:29:59 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 14 Mar 2006 11:29:59 +0100
Subject: [Rd] Internal codes of the factor
Message-ID: <44169B27.9020908@bfro.uni-lj.si>

Hello!

I am writing some functions and I repeatedly acces internal factor
codes. I figured out that internal codes are 1:n where 1 represents 1st
level, 2 2nd level etc. This is not documented and I wonder if this is
on purpose and subject to change or would be a good idea to add this to
documentation for factor? I can prepair a pacth if this is accepted.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From maechler at stat.math.ethz.ch  Tue Mar 14 11:57:32 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Mar 2006 11:57:32 +0100
Subject: [Rd] Undocumented argument na.last in factor()
In-Reply-To: <441685AE.7070607@bfro.uni-lj.si>
References: <441685AE.7070607@bfro.uni-lj.si>
Message-ID: <17430.41372.607288.134595@stat.math.ethz.ch>

>>>>> "Gregor" == Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si>
>>>>>     on Tue, 14 Mar 2006 09:58:22 +0100 writes:

    Gregor> Hello!  I just noticed that argument na.last in
    Gregor> factor() is not documented. Did I miss something or
    Gregor> ...? I just wonder how base package passes then R
    Gregor> CMD check. I checked also in source man page in
    Gregor> R-devel.

I wondered too -- for a few moments only -- after reading your
message...

*BUT*  na.last  is *not* an argument to factor()!

Look more carefully  at   str(factor)  or args(factor)
(or the help page) !

Regards, 
Martin Maechler


From gregor.gorjanc at bfro.uni-lj.si  Tue Mar 14 12:03:35 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 14 Mar 2006 12:03:35 +0100
Subject: [Rd] Undocumented argument na.last in factor()
In-Reply-To: <17430.41372.607288.134595@stat.math.ethz.ch>
References: <441685AE.7070607@bfro.uni-lj.si>
	<17430.41372.607288.134595@stat.math.ethz.ch>
Message-ID: <4416A307.9050206@bfro.uni-lj.si>

Martin Maechler wrote:
>>>>>>"Gregor" == Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si>
>>>>>>    on Tue, 14 Mar 2006 09:58:22 +0100 writes:
> 
> 
>     Gregor> Hello!  I just noticed that argument na.last in
>     Gregor> factor() is not documented. Did I miss something or
>     Gregor> ...? I just wonder how base package passes then R
>     Gregor> CMD check. I checked also in source man page in
>     Gregor> R-devel.
> 
> I wondered too -- for a few moments only -- after reading your
> message...
> 
> *BUT*  na.last  is *not* an argument to factor()!
> 
> Look more carefully  at   str(factor)  or args(factor)
> (or the help page) !

Argh, yes you are right. Argument na.last is for sort for levels. I
apologize for this.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From hb at maths.lth.se  Tue Mar 14 13:40:45 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 14 Mar 2006 13:40:45 +0100
Subject: [Rd] Can example() code stop the example without generating an
	error?
Message-ID: <59d7961d0603140440t6a51f55j31dedad5325d9224@mail.gmail.com>

Hi,

does anyone know if it is possible to write example code (in Rd
examples) such that one can stop the example without generating an
error?  Example:

code A
if (cond)
  niceStop()
code B

I know this sounds weird, but I would like some of my Rd examples to
run if and only if another package is available or if a certain large
Affymetrix data file is available.  One can put all of the example in
a function and return from the function if the package is not
available, but then all object assigned are lost. My best/cleanest
solution right now is to use break in a dummy for loop. Examples:

for (z in 1) {

code A
if (cond)
  break
code B

}

Other suggestions?  The solution must off course pass R CMD check.

/Henrik

PS. I know example() calls source(), but I'm not sure how R CMD check
does it. DS.


From ligges at statistik.uni-dortmund.de  Tue Mar 14 14:01:59 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Mar 2006 14:01:59 +0100
Subject: [Rd] Can example() code stop the example without generating an
 error?
In-Reply-To: <59d7961d0603140440t6a51f55j31dedad5325d9224@mail.gmail.com>
References: <59d7961d0603140440t6a51f55j31dedad5325d9224@mail.gmail.com>
Message-ID: <4416BEC7.2070807@statistik.uni-dortmund.de>

Henrik Bengtsson wrote:

> Hi,
> 
> does anyone know if it is possible to write example code (in Rd
> examples) such that one can stop the example without generating an
> error?  Example:
> 
> code A
> if (cond)
>   niceStop()
> code B


What about

code A
if(cond){
   code B
}

But maybe I do not get your point.

Uwe Ligges


> I know this sounds weird, but I would like some of my Rd examples to
> run if and only if another package is available or if a certain large
> Affymetrix data file is available.  One can put all of the example in
> a function and return from the function if the package is not
> available, but then all object assigned are lost. My best/cleanest
> solution right now is to use break in a dummy for loop. Examples:
> 
> for (z in 1) {
> 
> code A
> if (cond)
>   break
> code B
> 
> }
> 
> Other suggestions?  The solution must off course pass R CMD check.
> 
> /Henrik
> 
> PS. I know example() calls source(), but I'm not sure how R CMD check
> does it. DS.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at maths.lth.se  Tue Mar 14 15:04:30 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 14 Mar 2006 15:04:30 +0100
Subject: [Rd] New simpleExit() condition (Was: Re: Can example() code stop
	the example without generating an error?)
Message-ID: <59d7961d0603140604k23255e04vdaaa0963a66653d5@mail.gmail.com>

On 3/14/06, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> Henrik Bengtsson wrote:
>
> > Hi,
> >
> > does anyone know if it is possible to write example code (in Rd
> > examples) such that one can stop the example without generating an
> > error?  Example:
> >
> > code A
> > if (cond)
> >   niceStop()
> > code B
>
>
> What about
>
> code A
> if(cond){
>    code B
> }
>
> But maybe I do not get your point.

The purpose is to keep the code clean and I want to avoid nested if
statements.  Further conditions down the stream would make the code
quite ugly.  Pretty much for the same reason you use 'return()' and
'break'.

A nicer and more general solution is to have a subclass "simpleExit"
of "simpleCondition" and make source() catch such signals via
tryCatch(..., simpleExit=function(se) {...}).  Here is a complete
example:

simpleExit <- function(...) {
  cond <- simpleCondition(...)
  class(cond) <- c("simpleExit", class(cond))
  cond
}

exit <- function(...) {
  invisible(signalCondition(simpleExit(...)))
}

evalWithExit <- function(...) {
  tryCatch(..., simpleExit=function(cond) cond)
}

sourceWithExit <- function(...) {
  evalWithExit(source(...))
}


Examples:

> evalWithExit({cat("Hi\n");exit("Bye!");cat("there\n")}); cat("bye\n")
Hi
<simpleExit: Bye!>
bye

# Compare this...
> code <- 'cat("Hi\n"); exit("Bye!"); cat("there\n")'
> source(textConnection(code))
Hi
there

# ...with this:
> sourceWithExit(textConnection(code))
Hi
<simpleExit: Bye!>

R-core, would this be a useful feature to add to source()?

/Henrik

> Uwe Ligges
>
>
> > I know this sounds weird, but I would like some of my Rd examples to
> > run if and only if another package is available or if a certain large
> > Affymetrix data file is available.  One can put all of the example in
> > a function and return from the function if the package is not
> > available, but then all object assigned are lost. My best/cleanest
> > solution right now is to use break in a dummy for loop. Examples:
> >
> > for (z in 1) {
> >
> > code A
> > if (cond)
> >   break
> > code B
> >
> > }
> >
> > Other suggestions?  The solution must off course pass R CMD check.
> >
> > /Henrik
> >
> > PS. I know example() calls source(), but I'm not sure how R CMD check
> > does it. DS.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)


From ripley at stats.ox.ac.uk  Tue Mar 14 15:16:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Mar 2006 14:16:23 +0000 (GMT)
Subject: [Rd] Can example() code stop the example without generating an
 error?
In-Reply-To: <4416BEC7.2070807@statistik.uni-dortmund.de>
References: <59d7961d0603140440t6a51f55j31dedad5325d9224@mail.gmail.com>
	<4416BEC7.2070807@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0603141415100.8761@gannet.stats.ox.ac.uk>

On Tue, 14 Mar 2006, Uwe Ligges wrote:

> Henrik Bengtsson wrote:
>
>> Hi,
>>
>> does anyone know if it is possible to write example code (in Rd
>> examples) such that one can stop the example without generating an
>> error?  Example:
>>
>> code A
>> if (cond)
>>   niceStop()
>> code B
>
>
> What about
>
> code A
> if(cond){
>   code B
> }
>
> But maybe I do not get your point.

That is how many examples in base R do it.  The only thing to remember is 
that you have to explicitly print inside any such test.

>
> Uwe Ligges
>
>
>> I know this sounds weird, but I would like some of my Rd examples to
>> run if and only if another package is available or if a certain large
>> Affymetrix data file is available.  One can put all of the example in
>> a function and return from the function if the package is not
>> available, but then all object assigned are lost. My best/cleanest
>> solution right now is to use break in a dummy for loop. Examples:
>>
>> for (z in 1) {
>>
>> code A
>> if (cond)
>>   break
>> code B
>>
>> }
>>
>> Other suggestions?  The solution must off course pass R CMD check.
>>
>> /Henrik
>>
>> PS. I know example() calls source(), but I'm not sure how R CMD check
>> does it. DS.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Tue Mar 14 15:20:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Mar 2006 09:20:41 -0500
Subject: [Rd] New simpleExit() condition (Was: Re: Can example() code
	stop the example without generating an error?)
In-Reply-To: <59d7961d0603140604k23255e04vdaaa0963a66653d5@mail.gmail.com>
References: <59d7961d0603140604k23255e04vdaaa0963a66653d5@mail.gmail.com>
Message-ID: <971536df0603140620y60769e0ep6b71faa2aa4abfc5@mail.gmail.com>

I would very much like to see such a feature too.

On 3/14/06, Henrik Bengtsson <hb at maths.lth.se> wrote:
> On 3/14/06, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> > Henrik Bengtsson wrote:
> >
> > > Hi,
> > >
> > > does anyone know if it is possible to write example code (in Rd
> > > examples) such that one can stop the example without generating an
> > > error?  Example:
> > >
> > > code A
> > > if (cond)
> > >   niceStop()
> > > code B
> >
> >
> > What about
> >
> > code A
> > if(cond){
> >    code B
> > }
> >
> > But maybe I do not get your point.
>
> The purpose is to keep the code clean and I want to avoid nested if
> statements.  Further conditions down the stream would make the code
> quite ugly.  Pretty much for the same reason you use 'return()' and
> 'break'.
>
> A nicer and more general solution is to have a subclass "simpleExit"
> of "simpleCondition" and make source() catch such signals via
> tryCatch(..., simpleExit=function(se) {...}).  Here is a complete
> example:
>
> simpleExit <- function(...) {
>  cond <- simpleCondition(...)
>  class(cond) <- c("simpleExit", class(cond))
>  cond
> }
>
> exit <- function(...) {
>  invisible(signalCondition(simpleExit(...)))
> }
>
> evalWithExit <- function(...) {
>  tryCatch(..., simpleExit=function(cond) cond)
> }
>
> sourceWithExit <- function(...) {
>  evalWithExit(source(...))
> }
>
>
> Examples:
>
> > evalWithExit({cat("Hi\n");exit("Bye!");cat("there\n")}); cat("bye\n")
> Hi
> <simpleExit: Bye!>
> bye
>
> # Compare this...
> > code <- 'cat("Hi\n"); exit("Bye!"); cat("there\n")'
> > source(textConnection(code))
> Hi
> there
>
> # ...with this:
> > sourceWithExit(textConnection(code))
> Hi
> <simpleExit: Bye!>
>
> R-core, would this be a useful feature to add to source()?
>
> /Henrik
>
> > Uwe Ligges
> >
> >
> > > I know this sounds weird, but I would like some of my Rd examples to
> > > run if and only if another package is available or if a certain large
> > > Affymetrix data file is available.  One can put all of the example in
> > > a function and return from the function if the package is not
> > > available, but then all object assigned are lost. My best/cleanest
> > > solution right now is to use break in a dummy for loop. Examples:
> > >
> > > for (z in 1) {
> > >
> > > code A
> > > if (cond)
> > >   break
> > > code B
> > >
> > > }
> > >
> > > Other suggestions?  The solution must off course pass R CMD check.
> > >
> > > /Henrik
> > >
> > > PS. I know example() calls source(), but I'm not sure how R CMD check
> > > does it. DS.
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
>
> --
> Henrik Bengtsson
> Mobile: +46 708 909208 (+1h UTC)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dsamperi at DecisionSynergy.com  Tue Mar 14 18:41:23 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Tue, 14 Mar 2006 12:41:23 -0500
Subject: [Rd] RcppTemplate 2.0 R/C++ interface library update
Message-ID: <44170043.1010403@DecisionSynergy.com>

The demo package RcppTemplate for the
R/C++ interface library Rcpp has been updated
for improved portability, with thanks to
Brian Ripley for his comments.
Please use versions >= 2.0 for maximum
portability across platforms.


From rkoenker at uiuc.edu  Tue Mar 14 18:57:06 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Tue, 14 Mar 2006 11:57:06 -0600
Subject: [Rd] Fwd: makeconf issue on R-devel 2006-03-12 r37524
References: <7A5734F6-9584-49D6-933A-2F8AF93AFFBD@uiuc.edu>
Message-ID: <738521DF-2528-4826-BB1C-04D143AF4BFF@uiuc.edu>

I sent the message below to r-sig-mac yesterday, but having no reply
I decided to explore a bit myself and found that editing:

/Library/Frameworks/R.framework/Versions/2.3/Resources/share/make/ 
shlib.mk

yzzy: diff shlib.mk shlib.mk~
3c3
< include $(R_HOME)/etc/Makeconf
---
 > include $(R_HOME)/etc${R_ARCH}/Makeconf

restored the functionality of R CMD INSTALL.

Is this a known issue?


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


Begin forwarded message:

> From: roger koenker <rkoenker at uiuc.edu>
> Date: March 13, 2006 4:46:30 PM CST
> To: r-sig-mac at stat.math.ethz.ch
> Subject: makeconf issue on R-devel 2006-03-12 r37524
>
> I've just installed R-devel   Version 2.3.0 Under development  
> (unstable) (2006-03-12 r37524)
> on a G5 and things went smoothly despite my gfortran configuration,  
> (that is ./configure, make,
> make install was fine), but now trying to install  a source package  
> I get:
>
> yzzy: R CMD check kuantile
> * checking for working latex ... OK
> * using log directory '/Users/roger/Projects/kuantile/kuantile.Rcheck'
> * using Version 2.3.0 Under development (unstable) (2006-03-12 r37524)
> * checking for file 'kuantile/DESCRIPTION' ... OK
> * this is package 'kuantile' version '1.00'
> * checking package dependencies ... OK
> * checking if this is a source package ... WARNING
> Subdirectory 'kuantile/src' contains object files.
> * checking whether package 'kuantile' can be installed ... ERROR
> Installation failed.
> See '/Users/roger/Projects/kuantile/kuantile.Rcheck/00install.out'  
> for details.
>
> yzzy: more /Users/roger/Projects/kuantile/kuantile.Rcheck/ 
> 00install.out
> * Installing *source* package 'kuantile' ...
> ** libs
> ** arch - Frameworks
> /Library/Frameworks/R.framework/Resources/share/make/shlib.mk:3: / 
> Library/Frameworks/R.fra
> mework/Resources/etc/Frameworks/Makeconf: No such file or directory
> make: *** No rule to make target `/Library/Frameworks/R.framework/ 
> Resources/etc/Frameworks
> /Makeconf'.  Stop.
> chmod: /Users/roger/Projects/kuantile/kuantile.Rcheck/kuantile/libs/ 
> Frameworks/*: No such
> file or directory
> gfortran   -fPIC -fno-common  -g -O2 -c dsel05.f -o dsel05.o
> gfortran   -fPIC -fno-common  -g -O2 -c kuantile.f -o kuantile.o
> gcc -flat_namespace -bundle -undefined suppress -L/sw/lib -L/usr/ 
> local/lib -o kuantile.so
> dsel05.o kuantile.o  -L/usr/local/lib/gcc/powerpc-apple- 
> darwin8/4.0.0 -L/usr/local/lib/gcc
> -lgfortran -lgcc_s -lSystemStubs -lmx -lSystem -F/Library/ 
> Frameworks/R.framework/.. -fram
> ework R
> ERROR: compilation failed for package 'kuantile'
> ** Removing '/Users/roger/Projects/kuantile/kuantile.Rcheck/kuantile'
>
> isn't there something fishy with the specification of the Makeconf  
> file in ..../etc/Frameworks???
>
> Roger
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
>


From ripley at stats.ox.ac.uk  Tue Mar 14 20:31:24 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Mar 2006 19:31:24 +0000 (GMT)
Subject: [Rd] Fwd: makeconf issue on R-devel 2006-03-12 r37524
In-Reply-To: <738521DF-2528-4826-BB1C-04D143AF4BFF@uiuc.edu>
References: <7A5734F6-9584-49D6-933A-2F8AF93AFFBD@uiuc.edu>
	<738521DF-2528-4826-BB1C-04D143AF4BFF@uiuc.edu>
Message-ID: <Pine.LNX.4.64.0603141922070.784@gannet.stats.ox.ac.uk>

On Tue, 14 Mar 2006, roger koenker wrote:

> I sent the message below to r-sig-mac yesterday, but having no reply
> I decided to explore a bit myself and found that editing:
>
> /Library/Frameworks/R.framework/Versions/2.3/Resources/share/make/
> shlib.mk
>
> yzzy: diff shlib.mk shlib.mk~
> 3c3
> < include $(R_HOME)/etc/Makeconf
> ---
> > include $(R_HOME)/etc${R_ARCH}/Makeconf
>
> restored the functionality of R CMD INSTALL.
>
> Is this a known issue?

No, and the change will break things which currently work correctly.

Looks like this is something specific to how Macs install under the 
bin/exec directory.  It likely stems from the following line in INSTALL.

      archs=`(cd ${R_HOME}/bin/exec; ls)`

which on other systems will only contain directories for sub-architectures 
or the R or Rgnome executables, since it says

>> ** arch - Frameworks


>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Champaign, IL 61820
>
>
> Begin forwarded message:
>
>> From: roger koenker <rkoenker at uiuc.edu>
>> Date: March 13, 2006 4:46:30 PM CST
>> To: r-sig-mac at stat.math.ethz.ch
>> Subject: makeconf issue on R-devel 2006-03-12 r37524
>>
>> I've just installed R-devel   Version 2.3.0 Under development
>> (unstable) (2006-03-12 r37524)
>> on a G5 and things went smoothly despite my gfortran configuration,
>> (that is ./configure, make,
>> make install was fine), but now trying to install  a source package
>> I get:
>>
>> yzzy: R CMD check kuantile
>> * checking for working latex ... OK
>> * using log directory '/Users/roger/Projects/kuantile/kuantile.Rcheck'
>> * using Version 2.3.0 Under development (unstable) (2006-03-12 r37524)
>> * checking for file 'kuantile/DESCRIPTION' ... OK
>> * this is package 'kuantile' version '1.00'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... WARNING
>> Subdirectory 'kuantile/src' contains object files.
>> * checking whether package 'kuantile' can be installed ... ERROR
>> Installation failed.
>> See '/Users/roger/Projects/kuantile/kuantile.Rcheck/00install.out'
>> for details.
>>
>> yzzy: more /Users/roger/Projects/kuantile/kuantile.Rcheck/
>> 00install.out
>> * Installing *source* package 'kuantile' ...
>> ** libs
>> ** arch - Frameworks
>> /Library/Frameworks/R.framework/Resources/share/make/shlib.mk:3: /
>> Library/Frameworks/R.fra
>> mework/Resources/etc/Frameworks/Makeconf: No such file or directory
>> make: *** No rule to make target `/Library/Frameworks/R.framework/
>> Resources/etc/Frameworks
>> /Makeconf'.  Stop.
>> chmod: /Users/roger/Projects/kuantile/kuantile.Rcheck/kuantile/libs/
>> Frameworks/*: No such
>> file or directory
>> gfortran   -fPIC -fno-common  -g -O2 -c dsel05.f -o dsel05.o
>> gfortran   -fPIC -fno-common  -g -O2 -c kuantile.f -o kuantile.o
>> gcc -flat_namespace -bundle -undefined suppress -L/sw/lib -L/usr/
>> local/lib -o kuantile.so
>> dsel05.o kuantile.o  -L/usr/local/lib/gcc/powerpc-apple-
>> darwin8/4.0.0 -L/usr/local/lib/gcc
>> -lgfortran -lgcc_s -lSystemStubs -lmx -lSystem -F/Library/
>> Frameworks/R.framework/.. -fram
>> ework R
>> ERROR: compilation failed for package 'kuantile'
>> ** Removing '/Users/roger/Projects/kuantile/kuantile.Rcheck/kuantile'
>>
>> isn't there something fishy with the specification of the Makeconf
>> file in ..../etc/Frameworks???
>>
>> Roger
>>
>>
>> url:    www.econ.uiuc.edu/~roger            Roger Koenker
>> email    rkoenker at uiuc.edu            Department of Economics
>> vox:     217-333-4558                University of Illinois
>> fax:       217-244-6678                Champaign, IL 61820
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Wed Mar 15 03:30:08 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Wed, 15 Mar 2006 10:30:08 +0800
Subject: [Rd] Internal codes of the factor
In-Reply-To: <44169B27.9020908@bfro.uni-lj.si>
References: <44169B27.9020908@bfro.uni-lj.si>
Message-ID: <17431.31792.677194.884181@bossiaea.maths.uwa.edu.au>

G'day Gregor,

>>>>> "GG" == Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> writes:

    GG> I am writing some functions and I repeatedly acces internal
    GG> factor codes. I figured out that internal codes are 1:n where
    GG> 1 represents 1st level, 2 2nd level etc. This is not
    GG> documented [...]
The help page for factor states in the 'Details' section:

     The encoding of the vector happens as follows. First all the
     values in 'exclude' are removed from 'levels'. If 'x[i]' equals
     'levels[j]', then the 'i'-th element of the result is 'j'.  If no
     match is found for 'x[i]' in 'levels', then the 'i'-th element of
     the result is set to 'NA'.

Note in particular the part on "then the 'i'-th element of the result
is 'j'".  This pretty much documents that the internal codes are 1:n
and 'NA', as documented in the following sentence.



Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin


From gregor.gorjanc at bfro.uni-lj.si  Wed Mar 15 06:32:01 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Wed, 15 Mar 2006 06:32:01 +0100
Subject: [Rd] Internal codes of the factor
In-Reply-To: <17431.31792.677194.884181@bossiaea.maths.uwa.edu.au>
References: <44169B27.9020908@bfro.uni-lj.si>
	<17431.31792.677194.884181@bossiaea.maths.uwa.edu.au>
Message-ID: <4417A6D1.3020200@bfro.uni-lj.si>

Berwin A Turlach wrote:
> G'day Gregor,
> 
> 
>>>>>>"GG" == Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> writes:
> 
> 
>     GG> I am writing some functions and I repeatedly acces internal
>     GG> factor codes. I figured out that internal codes are 1:n where
>     GG> 1 represents 1st level, 2 2nd level etc. This is not
>     GG> documented [...]
> The help page for factor states in the 'Details' section:
> 
>      The encoding of the vector happens as follows. First all the
>      values in 'exclude' are removed from 'levels'. If 'x[i]' equals
>      'levels[j]', then the 'i'-th element of the result is 'j'.  If no
>      match is found for 'x[i]' in 'levels', then the 'i'-th element of
>      the result is set to 'NA'.
> 
> Note in particular the part on "then the 'i'-th element of the result
> is 'j'".  This pretty much documents that the internal codes are 1:n
> and 'NA', as documented in the following sentence.

Thanks for this pointer to documentation.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From dan.kelley at dal.ca  Wed Mar 15 17:33:01 2006
From: dan.kelley at dal.ca (dan.kelley@dal.ca)
Date: Wed, 15 Mar 2006 17:33:01 +0100 (CET)
Subject: [Rd] R_alloc problem on Mac OSX (PR#8683)
Message-ID: <20060315163301.C0B1141EAB@slim.kubism.ku.dk>

Full_Name: Dan Kelley
Version: 2.2.1
OS: Mac OSX
Submission from: (NULL) (129.173.23.36)


I'm having difficulties getting R_alloc() to work on a 64-bit Mac running R
2.2.1 installed via a .dmg file obtained from the R site.  Details are given
below, in a level of detail that I hope is appropriate.  My eye was particularly
drawn to line #2 in the gdb 'where' output, but line #1 seems sensible so I may
just be displaying my ignorance by drawing attention to this.

I wonder, is there something I should be doing first, to initialize memory?

 ......

$ R --version
R 2.2.1 (2005-12-20).
Copyright (C) 2005 R Development Core Team

$ gcc -g -o test5 test5.c
-I/library/Frameworks/R.framework/Versions/2.2/Resources/include/
-L/library/Frameworks/R.framework/Versions/2.2/Resources/lib/ -lR -lm
/usr/bin/ld: warning multiple definitions of symbol _signgam
/library/Frameworks/R.framework/Versions/2.2/Resources/lib//libR.dylib(lgamma.lo)
definition of _signgam
/usr/lib/gcc/powerpc-apple-darwin8/4.0.0/../../../libm.dylib(gamma9.o)
definition of _signgam

$ gdb test5
GNU gdb 6.1-20040303 (Apple version gdb-413) (Wed May 18 10:17:02 GMT 2005)
Copyright 2004 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for details.
This GDB was configured as "powerpc-apple-darwin"...Reading symbols for shared
libraries .... done

(gdb) run
Starting program: /Users/kelley/src/R-from-fortran/test5
Reading symbols for shared libraries .........+ done
about to call R_alloc(1,4)

Program received signal EXC_BAD_ACCESS, Could not access memory.
Reason: KERN_PROTECTION_FAILURE at address: 0x0000000c
GetNewPage (node_class=1) at ../../../../R-2.2.1/src/main/memory.c:622
622     ../../../../R-2.2.1/src/main/memory.c: No such file or directory.
        in ../../../../R-2.2.1/src/main/memory.c
(gdb) where
#0  GetNewPage (node_class=1) at ../../../../R-2.2.1/src/main/memory.c:622
#1  0x00293d38 in Rf_allocVector (type=9, length=4) at
../../../../R-2.2.1/src/main/memory.c:1918
#2  0x002932e8 in R_alloc (nelem=25167368, eltsize=1996) at
../../../../R-2.2.1/src/main/memory.c:1604
#3  0x00002ad0 in main () at test5.c:8
(gdb) list
617     in ../../../../R-2.2.1/src/main/memory.c
(gdb) file test5
Load new symbol table from "/Users/kelley/src/R-from-fortran/test5"? (y or n) y
Reading symbols from /Users/kelley/src/R-from-fortran/test5...done.
(gdb) list
1       #include <stdio.h>
2       #include <R.h>
3       int main()
4       {
5               int *t;
6               long int n = 1;
7               printf("about to call R_alloc(%d,%d)\n",n,sizeof(int));
8               t = (int *) R_alloc(n, sizeof(int));
9               printf("done\n");
10              return(0);
(gdb) src/R-from-fortran/


From tlumley at u.washington.edu  Wed Mar 15 18:26:03 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 15 Mar 2006 09:26:03 -0800 (PST)
Subject: [Rd] R_alloc problem on Mac OSX (PR#8683)
In-Reply-To: <20060315163301.C0B1141EAB@slim.kubism.ku.dk>
References: <20060315163301.C0B1141EAB@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0603150924220.27160@homer23.u.washington.edu>

On Wed, 15 Mar 2006, dan.kelley at dal.ca wrote:

> Full_Name: Dan Kelley
> Version: 2.2.1
> OS: Mac OSX
> Submission from: (NULL) (129.173.23.36)
>
>
> I'm having difficulties getting R_alloc() to work on a 64-bit Mac running R
> 2.2.1 installed via a .dmg file obtained from the R site.  Details are given
> below, in a level of detail that I hope is appropriate.  My eye was particularly
> drawn to line #2 in the gdb 'where' output, but line #1 seems sensible so I may
> just be displaying my ignorance by drawing attention to this.
>
> I wonder, is there something I should be doing first, to initialize memory?

Yes. Read section 7 of "Writing R Extensions" if you want to write a 
different front-end for R.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From bullard at berkeley.edu  Thu Mar 16 00:58:04 2006
From: bullard at berkeley.edu (James Bullard)
Date: Wed, 15 Mar 2006 15:58:04 -0800
Subject: [Rd] multiple packages using the same native code.
Message-ID: <4418AA0C.1040703@berkeley.edu>

This might fall under the purview of bundles, but I could not find any 
example bundles which demonstrated what I am after.

I would like to construct two packages (A, B) which utilize a number of 
common C functions. The most straightforward way to do this is just copy 
the relevant .c and .h files from one src directory to the next, but 
this is tedious especially in the face of multiple developers and changes.

If I declare in the depends field that package A needs to be present in 
order to install package B this only enforces that package A has been 
installed correct? Is there a way to check whether the src of a package 
is available and to be able to compile against it (the source of a 
package does not seem to be installed by default so this might, in 
general, be impossible)? Linking against installed packages seems to be 
easier in the sense that I know that if a package is installed that uses 
native code the .so is available, but is there a makevars variable which 
I can use to tell R to add to its linking command upon R CMD INSTALL?

Does anyone have examples of configure scripts which are doing this by 
hand? I could see this as being a relatively painless addition for 
linking by mapping any dependency specified in the depends field (in 
DESCRIPTION) to additional dependencies in the list of directories to 
link against, but in terms of compiling I don't see an obvious solution 
besides writing it myself in the configure, but then it might make it 
much harder for the user to install.

Sorry if this is in the help manual - I have looked at places where I 
thought it might naturally be, but did not see anything.

Thanks in advance, jim


From sfalcon at fhcrc.org  Thu Mar 16 02:06:21 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 15 Mar 2006 17:06:21 -0800
Subject: [Rd] multiple packages using the same native code.
In-Reply-To: <4418AA0C.1040703@berkeley.edu> (James Bullard's message of "Wed,
	15 Mar 2006 15:58:04 -0800")
References: <4418AA0C.1040703@berkeley.edu>
Message-ID: <m2wtevp59u.fsf@ziti.local>

Hi Jim,

James Bullard <bullard at berkeley.edu> writes:
> I would like to construct two packages (A, B) which utilize a number of 
> common C functions. The most straightforward way to do this is just copy 
> the relevant .c and .h files from one src directory to the next, but 
> this is tedious especially in the face of multiple developers and
> changes.

I'm not sure I understand what you are after.  One possible solution
would be to create a third package 'C' that contains the common C
code.  This would allow you to call C function defined in 'C' from the
C code in 'A' or 'B'.

Using a .onLoad hook and getNativeSymbolInfo(), you can pass C
function pointers to the code in packages A and B.

Suppose in 'C' you have a C function foo() that is registered in the
usual manner so that it can be called by .Call or .C.

Then in 'A' you could have (all untested, sorry, but hopefully it
sketches the idea for you):

A/src/A.c

   static DL_FUNC C_foo;

   void init_funcs_from_C(SEXP foo_info) {
       C_foo = R_ExternalPtrAddr(foo_info);
   }

   void bar(int *x) {
       ...
       z = C_foo();
       ...
   }


A/R/zzz.R

   .onLoad <- function(libname, pkgname) {
       foo_info <- getNativeSymbolInfo("foo", PACKAGE="C")
       .Call("init_funcs_from_C", foo_info$address)
   }


+ seth


From hb at maths.lth.se  Thu Mar 16 09:02:53 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 16 Mar 2006 09:02:53 +0100
Subject: [Rd] New simpleExit() condition (Was: Re: Can example() code
	stop the example without generating an error?)
In-Reply-To: <971536df0603140620y60769e0ep6b71faa2aa4abfc5@mail.gmail.com>
References: <59d7961d0603140604k23255e04vdaaa0963a66653d5@mail.gmail.com>
	<971536df0603140620y60769e0ep6b71faa2aa4abfc5@mail.gmail.com>
Message-ID: <59d7961d0603160002p7f8d8110na00f66114bb9debb@mail.gmail.com>

On 3/14/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I would very much like to see such a feature too.
>
> On 3/14/06, Henrik Bengtsson <hb at maths.lth.se> wrote:

[snip]

> > A nicer and more general solution is to have a subclass "simpleExit"
> > of "simpleCondition" and make source() catch such signals via
> > tryCatch(..., simpleExit=function(se) {...}).  Here is a complete
> > example:
> >
> > simpleExit <- function(...) {
> >  cond <- simpleCondition(...)
> >  class(cond) <- c("simpleExit", class(cond))
> >  cond
> > }
> >
> > exit <- function(...) {
> >  invisible(signalCondition(simpleExit(...)))
> > }
> >
> > evalWithExit <- function(...) {
> >  tryCatch(..., simpleExit=function(cond) cond)
> > }
> >
> > sourceWithExit <- function(...) {
> >  evalWithExit(source(...))
> > }
> >
> >
> > Examples:
> >
> > > evalWithExit({cat("Hi\n");exit("Bye!");cat("there\n")}); cat("bye\n")
> > Hi
> > <simpleExit: Bye!>
> > bye
> >
> > # Compare this...
> > > code <- 'cat("Hi\n"); exit("Bye!"); cat("there\n")'
> > > source(textConnection(code))
> > Hi
> > there
> >
> > # ...with this:
> > > sourceWithExit(textConnection(code))
> > Hi
> > <simpleExit: Bye!>
> >
> > R-core, would this be a useful feature to add to source()?
> >
> > /Henrik

I just realized that I just might be looking for a way to generate a
user-interrupt signal, e.g. (try pressing Ctrl-C or Ctrl-Break)

  tryCatch(Sys.sleep(10), interrupt=function(intr) print(intr))

A caught "interrupt" object looks like:

 list()
 - attr(*, "class")= chr [1:2] "interrupt" "condition"

So, trying:

simpleInterrupt <- function(...) {
  cond <- simpleCondition(...)
  class(cond) <- c("simpleInterrupt", "interrupt", class(cond))
  cond
}

interrupt <- function(...) {
  invisible(signalCondition(simpleInterrupt(...)))
}

Unfortunately that is not enough; the interrupt seems not to be
signalled. Same holds if you try to "resignal" a caught interrupt,
e.g. (try pressing Ctrl-C or Ctrl-Break *once*):

tryCatch({
  tryCatch({
    print(1)
    Sys.sleep(10)
    print(2)
  }, interrupt=function(intr) {
    cat("User-interrupt signal caught\n")
    signalCondition(intr)
  })
  Sys.sleep(10)
  print(3)
})

gives:

[1] 1
User-interrupt signal caught
<a 10 second sleep>
[1] 3

I was hoping that the *resignaled* user-interrupt signal would break
out of the out outer tryCatch too.

So, I guess, now my question is, is it possible to generate a
low-level user-interrupt signal from source code?  That would be
useful.

Thanks

Henrik


From silvia.figini at eco.unipv.it  Thu Mar 16 09:52:42 2006
From: silvia.figini at eco.unipv.it (silvia.figini@eco.unipv.it)
Date: Thu, 16 Mar 2006 09:52:42 +0100 (CET)
Subject: [Rd] survBayes (PR#8685)
Message-ID: <20060316085242.C391941EAD@slim.kubism.ku.dk>

Full_Name: SILVIA FIGINI
Version: 2.2.0
OS: WINDOWS XP 
Submission from: (NULL) (193.204.46.204)


I would like to use survBayes function, but I have a critical error:

Error in rep.default(0, int.number - 3) : not valid number of pairs in rep()!

(Errore in rep.default(0, int.number - 3) : numero non valido di copie in
rep()

I have a data with 25 covariates and a status variable (censoring
indicator) and only a duration time. This data is right censored.

This is the code that I use:
My data set has 22 variables (only dummy - binary variables) and 3500
observations.
The censor is right.
# Import the data
multi<-read.csv("C:\\Documents and
Settings\\user\\Desktop\\cambridge\\data_multilevel_canale_noleggio.csv",
header=TRUE, sep=";")
attach(multi)
fix(multi)
names(multi)
a<-survBayes(Surv(durata,stato,type="right")~ESG_ATTIVAZIONI+ESG_INFO_DISCONNESSIONE+ESG_PROBLEMI_TECNICI+ESG_VARIAZIONI_CONTRATTUALI+PACCHETTO_CINEMA_CALCIO+OFFERTA_ONLY_DECODER+OFFERTA_PRONTO_SKY+ESG_GESTIONE_AMMINISTRATIVA+ESG_METODO_DI_PAGAMENTO+ESG_PROMOZIONI+PACCHETTO_CINEMA_SPORT+MOP_PO+AREA_NIELSEN_SUD_ISOLE+OFFERTA_ONLY_SMART_CARD+COMPANY_OLD_SKY_ITALIA,data=multi,burn.in=1000,number.sample=2000)
The strata variables are not supported.

Many thanks,
Silvia




Thanks,
Silvia Figini


From sebastien.moretti at igs.cnrs-mrs.fr  Thu Mar 16 11:49:03 2006
From: sebastien.moretti at igs.cnrs-mrs.fr (Sebastien Moretti)
Date: Thu, 16 Mar 2006 11:49:03 +0100
Subject: [Rd] R 2.2 for Suse 9.1
Message-ID: <4419429F.4010909@igs.cnrs-mrs.fr>

Hello,
Do you plan to build a rpm package of R 2.2 for Suse 9.1 ?

I tried to build it by myself but failed due to compilation problems.
Thanks

-- 
S?bastien Moretti
http://www.igs.cnrs-mrs.fr/
CNRS - IGS UPR 2589
163 Avenue de Luminy, case 934
13288 Marseille cedex 9 (France)


From detlef.steuer at hsu-hamburg.de  Thu Mar 16 15:15:58 2006
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Thu, 16 Mar 2006 15:15:58 +0100
Subject: [Rd] R 2.2 for Suse 9.1
In-Reply-To: <4419429F.4010909@igs.cnrs-mrs.fr>
References: <4419429F.4010909@igs.cnrs-mrs.fr>
Message-ID: <20060316151558.006bf5b9.detlef.steuer@hsu-hamburg.de>

Hi,

On Thu, 16 Mar 2006 11:49:03 +0100
Sebastien Moretti <sebastien.moretti at igs.cnrs-mrs.fr> wrote:

> Hello,
> Do you plan to build a rpm package of R 2.2 for Suse 9.1 ?

I don?t have a suse 9.1 box anymore. perhaps I can help, if you send 
the compiler messages.

Detlef

> 
> I tried to build it by myself but failed due to compilation problems.
> Thanks
> 
> -- 
> S?bastien Moretti
> http://www.igs.cnrs-mrs.fr/
> CNRS - IGS UPR 2589
> 163 Avenue de Luminy, case 934
> 13288 Marseille cedex 9 (France)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From trfamula at ucdavis.edu  Thu Mar 16 21:28:26 2006
From: trfamula at ucdavis.edu (trfamula@ucdavis.edu)
Date: Thu, 16 Mar 2006 21:28:26 +0100 (CET)
Subject: [Rd] Installation of gmodels package (PR#8686)
Message-ID: <20060316202826.71807103E7@slim.kubism.ku.dk>

Full_Name: Thomas R Famula
Version: 2.2.1
OS: Linux - fedora core 4
Submission from: (NULL) (169.237.28.28)


Sorry to bother - I hope this is a simple fix.
Here is the set of error messages I recieved in trying to install the "gmodels"
package. I typed in "install.packages(c("gmodels"))" as the root and recieved
the following series of replies:



install.packages(c("gmodels"))
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/gmodels_2.12.0.tar.gz'
Content type 'application/x-tar' length 21872 bytes
opened URL
==================================================
downloaded 21Kb

* Installing *source* package 'gmodels' ...
** R
** preparing package for lazy loading
Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :
        there is no package called 'gdata'
Execution halted
ERROR: lazy loading failed for package 'gmodels'
** Removing '/usr/lib64/R/library/gmodels'

The downloaded packages are in
        /tmp/Rtmpba5986/downloaded_packages
Warning message:
installation of package 'gmodels' had non-zero exit status in:
install.packages(c("gmodels"))


From todd at baileywick.plus.com  Thu Mar 16 21:54:04 2006
From: todd at baileywick.plus.com (todd@baileywick.plus.com)
Date: Thu, 16 Mar 2006 21:54:04 +0100 (CET)
Subject: [Rd] PR#8676
Message-ID: <20060316205404.095D4199FD@slim.kubism.ku.dk>

Not actually documented to work?  The documentation for merge says,  
"If the by.* vectors are of length 0, the result, r, is the  
?Cartesian product? of x and y".

todd


From kjetilbrinchmannhalvorsen at gmail.com  Thu Mar 16 22:04:44 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 16 Mar 2006 17:04:44 -0400
Subject: [Rd] Installation of gmodels package (PR#8686)
In-Reply-To: <20060316202826.71807103E7@slim.kubism.ku.dk>
References: <20060316202826.71807103E7@slim.kubism.ku.dk>
Message-ID: <4419D2EC.3040409@gmail.com>

trfamula at ucdavis.edu wrote:
> Full_Name: Thomas R Famula
> Version: 2.2.1
> OS: Linux - fedora core 4
> Submission from: (NULL) (169.237.28.28)
> 
> 
> Sorry to bother - I hope this is a simple fix.
> Here is the set of error messages I recieved in trying to install the "gmodels"
> package. I typed in "install.packages(c("gmodels"))" as the root and recieved
> the following series of replies:
> 
> 
> 
> install.packages(c("gmodels"))
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/gmodels_2.12.0.tar.gz'
> Content type 'application/x-tar' length 21872 bytes
> opened URL
> ==================================================
> downloaded 21Kb
> 
> * Installing *source* package 'gmodels' ...
> ** R
> ** preparing package for lazy loading
> Error in loadNamespace(i[[1]], c(lib.loc, .libPaths())) :
>         there is no package called 'gdata'
> Execution halted
> ERROR: lazy loading failed for package 'gmodels'
> ** Removing '/usr/lib64/R/library/gmodels'
> 
> The downloaded packages are in
>         /tmp/Rtmpba5986/downloaded_packages
> Warning message:
> installation of package 'gmodels' had non-zero exit status in:
> install.packages(c("gmodels"))
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Try with
install.packages("gmodels", dependencies=TRUE)

Kjetil


From todd at baileywick.plus.com  Thu Mar 16 22:28:02 2006
From: todd at baileywick.plus.com (todd@baileywick.plus.com)
Date: Thu, 16 Mar 2006 22:28:02 +0100 (CET)
Subject: [Rd] sub returns garbage (PR#8687)
Message-ID: <20060316212802.D4E51C976@slim.kubism.ku.dk>

Full_Name: Todd Bailey
Version: 2.1
OS: Mac OS-X 10.4.3
Submission from: (NULL) (87.112.79.124)


sub returns garbage in some strings when replacing something with nothing and
fixed=TRUE.  For example:

> a=c('hello','hello'); sub('lo','',a,fixed=TRUE)
[1] "hel"     "hel\0\0"
> a=c('hello','hello'); sub('lo','',a,fixed=FALSE)
[1] "hel" "hel"


> version
         _                        
platform powerpc-apple-darwin7.9.0
arch     powerpc                  
os       darwin7.9.0              
system   powerpc, darwin7.9.0     
status                            
major    2                        
minor    2.1                      
year     2005                     
month    12                       
day      20                       
svn rev  36812                    
language R


From p.dalgaard at biostat.ku.dk  Thu Mar 16 22:42:51 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Mar 2006 22:42:51 +0100
Subject: [Rd] sub returns garbage (PR#8687)
In-Reply-To: <20060316212802.D4E51C976@slim.kubism.ku.dk>
References: <20060316212802.D4E51C976@slim.kubism.ku.dk>
Message-ID: <x2d5gmukv8.fsf@turmalin.kubism.ku.dk>

todd at baileywick.plus.com writes:

> Full_Name: Todd Bailey
> Version: 2.1

Er, 2.2.1....

> OS: Mac OS-X 10.4.3
> Submission from: (NULL) (87.112.79.124)
> 
> 
> sub returns garbage in some strings when replacing something with nothing and
> fixed=TRUE.  For example:
> 
> > a=c('hello','hello'); sub('lo','',a,fixed=TRUE)
> [1] "hel"     "hel\0\0"
> > a=c('hello','hello'); sub('lo','',a,fixed=FALSE)
> [1] "hel" "hel"

Confirmed on Linux & Windows. We've seen this symptom a few times
before.... 

> 
> > version
>          _                        
> platform powerpc-apple-darwin7.9.0
> arch     powerpc                  
> os       darwin7.9.0              
> system   powerpc, darwin7.9.0     
> status                            
> major    2                        
> minor    2.1                      
> year     2005                     
> month    12                       
> day      20                       
> svn rev  36812                    
> language R
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mschwartz at mn.rr.com  Thu Mar 16 22:43:57 2006
From: mschwartz at mn.rr.com (mschwartz@mn.rr.com)
Date: Thu, 16 Mar 2006 22:43:57 +0100 (CET)
Subject: [Rd] sub returns garbage (PR#8687)
Message-ID: <20060316214357.EACFB103EE@slim.kubism.ku.dk>

On Thu, 2006-03-16 at 22:28 +0100, todd at baileywick.plus.com wrote:
> Full_Name: Todd Bailey
> Version: 2.1
> OS: Mac OS-X 10.4.3
> Submission from: (NULL) (87.112.79.124)
> 
> 
> sub returns garbage in some strings when replacing something with nothing and
> fixed=TRUE.  For example:
> 
> > a=c('hello','hello'); sub('lo','',a,fixed=TRUE)
> [1] "hel"     "hel\0\0"
> > a=c('hello','hello'); sub('lo','',a,fixed=FALSE)
> [1] "hel" "hel"


This has been fixed in R Patched. From NEWS:

 o	sub(fixed = TRUE) could get wrong the length of the character
	string of elements of the result after the first.


>From my installation:

> a <- c('hello', 'hello'); sub('lo', '', a, fixed=TRUE)
[1] "hel" "hel"

> a <- c('hello', 'hello'); sub('lo', '', a, fixed=FALSE)
[1] "hel" "hel"


HTH,

Marc Schwartz


From bullard at berkeley.edu  Fri Mar 17 03:53:21 2006
From: bullard at berkeley.edu (James Bullard)
Date: Thu, 16 Mar 2006 18:53:21 -0800
Subject: [Rd] multiple packages using the same native code.
In-Reply-To: <m2wtevp59u.fsf@ziti.local>
References: <4418AA0C.1040703@berkeley.edu> <m2wtevp59u.fsf@ziti.local>
Message-ID: <441A24A1.6020006@berkeley.edu>

Seth, thanks for the advice. This solution seems like it might work, but 
then all errors occur at runtime rather than at compile time. This seems 
like I am exchanging one evil for another (run time segfaults versus 
code duplication) Lets say we have these three package A, B, and C 
defined more or less like this:

A/src/bar.c
int bar()
{
    foo();
}

B/src/baz.c
int baz()
{
    foo();
}

C/src/foo.c
int foo()
{
    return 1;
}


Now, the only way I can see to do this is to copy foo.c into both src 
directories of package A and B. This is not exactly what anyone wants, 
but rather I'd rather just say that both package A and B depend on 
package C. If I put them in a bundle then can I expect that the src will 
always simultaneously be available? In this way I can easily modify the 
configure script to handle this, but if I have no way to depend on the 
presence of the code (ie. users could download and install packages 
separately even if it's a bundle) then it seems like there is no way to 
generally modify the configure file to do this.


thanks, jim





Seth Falcon wrote:

>Hi Jim,
>
>James Bullard <bullard at berkeley.edu> writes:
>  
>
>>I would like to construct two packages (A, B) which utilize a number of 
>>common C functions. The most straightforward way to do this is just copy 
>>the relevant .c and .h files from one src directory to the next, but 
>>this is tedious especially in the face of multiple developers and
>>changes.
>>    
>>
>
>I'm not sure I understand what you are after.  One possible solution
>would be to create a third package 'C' that contains the common C
>code.  This would allow you to call C function defined in 'C' from the
>C code in 'A' or 'B'.
>
>Using a .onLoad hook and getNativeSymbolInfo(), you can pass C
>function pointers to the code in packages A and B.
>
>Suppose in 'C' you have a C function foo() that is registered in the
>usual manner so that it can be called by .Call or .C.
>
>Then in 'A' you could have (all untested, sorry, but hopefully it
>sketches the idea for you):
>
>A/src/A.c
>
>   static DL_FUNC C_foo;
>
>   void init_funcs_from_C(SEXP foo_info) {
>       C_foo = R_ExternalPtrAddr(foo_info);
>   }
>
>   void bar(int *x) {
>       ...
>       z = C_foo();
>       ...
>   }
>
>
>A/R/zzz.R
>
>   .onLoad <- function(libname, pkgname) {
>       foo_info <- getNativeSymbolInfo("foo", PACKAGE="C")
>       .Call("init_funcs_from_C", foo_info$address)
>   }
>
>
>+ seth
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>


From weigand.stephen at charter.net  Fri Mar 17 04:48:46 2006
From: weigand.stephen at charter.net (Stephen D. Weigand)
Date: Thu, 16 Mar 2006 21:48:46 -0600
Subject: [Rd] Wishlist: 'append' argument for write.ftable()
Message-ID: <68eef2d11757ede9cabf59b3f47c4320@charter.net>

I would like to suggest that an 'append' argument be added to
write.ftable().  This would allow, for example, the user to
append ftable() output to a text report.

I have attached an svn patch to ftable.R that makes the proposed
change to write.ftable(). [A very trivial change since 'append'
is simply passed to cat().]

I have also attached a patch to read.ftable.Rd which documents
the proposed argument (borrowing from cat.Rd).

Thanks for considering this,

Stephen
--

Stephen Weigand
Rochester, Minnesota, USA

From weigand.stephen at charter.net  Fri Mar 17 05:08:58 2006
From: weigand.stephen at charter.net (Stephen D. Weigand)
Date: Thu, 16 Mar 2006 22:08:58 -0600
Subject: [Rd] Wishlist: 'append' argument for write.ftable()
In-Reply-To: <68eef2d11757ede9cabf59b3f47c4320@charter.net>
References: <68eef2d11757ede9cabf59b3f47c4320@charter.net>
Message-ID: <c312d0eb09f5ad68a4d2941bc1b1a25a@charter.net>


On Mar 16, 2006, at 9:48 PM, Stephen D. Weigand wrote:

> I would like to suggest that an 'append' argument be added to
> write.ftable().  This would allow, for example, the user to
> append ftable() output to a text report.
>
> I have attached an svn patch to ftable.R that makes the proposed
> change to write.ftable(). [A very trivial change since 'append'
> is simply passed to cat().]
>
> I have also attached a patch to read.ftable.Rd which documents
> the proposed argument (borrowing from cat.Rd).

The text-based patch files were attached but had extensions *.patch.
I'm resending them with *.txt extensions in case that's necessary.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ftable.R.patch.txt
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060316/ba57404f/ftable.R.patch.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: read.ftable.Rd.patch.txt
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060316/ba57404f/read.ftable.Rd.patch.txt
-------------- next part --------------

As a backup, the patches are in-line below.
Thanks again,
Stephen


Index: R/src/library/stats/R/ftable.R
===================================================================
--- R/src/library/stats/R/ftable.R      (revision 37549)
+++ R/src/library/stats/R/ftable.R      (working copy)
@@ -151,7 +151,7 @@
      x
  }

-write.ftable <- function(x, file = "", quote = TRUE,
+write.ftable <- function(x, file = "", append = FALSE, quote = TRUE,
                           digits = getOption("digits"))
  {
      if(!inherits(x, "ftable"))
@@ -191,7 +191,8 @@
                    format(unclass(x), digits = digits))
      x <- cbind(apply(LABS, 2, format, justify = "left"),
                 apply(DATA, 2, format, justify = "right"))
-    cat(t(x), file = file, sep = c(rep(" ", ncol(x) - 1), "\n"))
+    cat(t(x), file = file, append = append,
+        sep = c(rep(" ", ncol(x) - 1), "\n"))
      invisible(ox)
  }

Index: R/src/library/stats/man/read.ftable.Rd
===================================================================
--- R/src/library/stats/man/read.ftable.Rd      (revision 37549)
+++ R/src/library/stats/man/read.ftable.Rd      (working copy)
@@ -31,6 +31,10 @@
    \item{skip}{the number of lines of the data file to skip before
      beginning to read data.}
    \item{x}{an object of class \code{"ftable"}.}
+  \item{append}{logical.  If \code{TRUE} and \code{file} is the name of
+    a file (and not a connection or \code{"|cmd"}), the output from
+    \code{write.ftable} is appended to the file.  If \code{FALSE},
+    the contents of \code{file} will be overwritten.}
    \item{digits}{an integer giving the number of significant digits to
      use for (the cell entries of) \code{x}.}
    \item{\dots}{further arguments to be passed to or from methods.}

From sfalcon at fhcrc.org  Fri Mar 17 05:32:44 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 16 Mar 2006 20:32:44 -0800
Subject: [Rd] multiple packages using the same native code.
In-Reply-To: <441A24A1.6020006@berkeley.edu> (James Bullard's message of "Thu,
	16 Mar 2006 18:53:21 -0800")
References: <4418AA0C.1040703@berkeley.edu> <m2wtevp59u.fsf@ziti.local>
	<441A24A1.6020006@berkeley.edu>
Message-ID: <m2hd5xlmhf.fsf@ziti.local>

James Bullard <bullard at berkeley.edu> writes:

> Seth, thanks for the advice. This solution seems like it might work,
> but then all errors occur at runtime rather than at compile time.

I'm sure you could still create some compile time errors ;-)
Yes, doing things dynamically means you won't catch nearly as much at
compile time.  I think with some reasonable testing this really isn't
so bad.

Another option would be to develop a separate C library and have the
configure scripts for 'A' and 'B' find where it is installed.


From p.dalgaard at biostat.ku.dk  Fri Mar 17 08:51:08 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Mar 2006 08:51:08 +0100
Subject: [Rd] sub returns garbage (PR#8687)
In-Reply-To: <x2d5gmukv8.fsf@turmalin.kubism.ku.dk>
References: <20060316212802.D4E51C976@slim.kubism.ku.dk>
	<x2d5gmukv8.fsf@turmalin.kubism.ku.dk>
Message-ID: <x2fylh33wz.fsf@turmalin.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> todd at baileywick.plus.com writes:
> 
> > Full_Name: Todd Bailey
> > Version: 2.1
> 
> Er, 2.2.1....
> 
> > OS: Mac OS-X 10.4.3
> > Submission from: (NULL) (87.112.79.124)
> > 
> > 
> > sub returns garbage in some strings when replacing something with nothing and
> > fixed=TRUE.  For example:
> > 
> > > a=c('hello','hello'); sub('lo','',a,fixed=TRUE)
> > [1] "hel"     "hel\0\0"
> > > a=c('hello','hello'); sub('lo','',a,fixed=FALSE)
> > [1] "hel" "hel"
> 
> Confirmed on Linux & Windows. We've seen this symptom a few times
> before.... 

...and fixed it, apparently! (Thanks Marc.) 

I claim XP braindamage -- I'm not Linuxifying my new ThinkPad until
FC5 is out.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Mar 17 08:51:19 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri, 17 Mar 2006 08:51:19 +0100 (CET)
Subject: [Rd] sub returns garbage (PR#8687)
Message-ID: <20060317075119.9449E3FCAB@slim.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> todd at baileywick.plus.com writes:
> 
> > Full_Name: Todd Bailey
> > Version: 2.1
> 
> Er, 2.2.1....
> 
> > OS: Mac OS-X 10.4.3
> > Submission from: (NULL) (87.112.79.124)
> > 
> > 
> > sub returns garbage in some strings when replacing something with nothing and
> > fixed=TRUE.  For example:
> > 
> > > a=c('hello','hello'); sub('lo','',a,fixed=TRUE)
> > [1] "hel"     "hel\0\0"
> > > a=c('hello','hello'); sub('lo','',a,fixed=FALSE)
> > [1] "hel" "hel"
> 
> Confirmed on Linux & Windows. We've seen this symptom a few times
> before.... 

...and fixed it, apparently! (Thanks Marc.) 

I claim XP braindamage -- I'm not Linuxifying my new ThinkPad until
FC5 is out.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Fri Mar 17 08:55:21 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Mar 2006 08:55:21 +0100
Subject: [Rd] Wishlist: 'append' argument for write.ftable()
In-Reply-To: <c312d0eb09f5ad68a4d2941bc1b1a25a@charter.net>
References: <68eef2d11757ede9cabf59b3f47c4320@charter.net>
	<c312d0eb09f5ad68a4d2941bc1b1a25a@charter.net>
Message-ID: <17434.27497.921981.461990@stat.math.ethz.ch>

>>>>> "Stephen" == Stephen D Weigand <weigand.stephen at charter.net>
>>>>>     on Thu, 16 Mar 2006 22:08:58 -0600 writes:

    Stephen> On Mar 16, 2006, at 9:48 PM, Stephen D. Weigand wrote:

    >> I would like to suggest that an 'append' argument be added to
    >> write.ftable().  This would allow, for example, the user to
    >> append ftable() output to a text report.
    >> 
    >> I have attached an svn patch to ftable.R that makes the proposed
    >> change to write.ftable(). [A very trivial change since 'append'
    >> is simply passed to cat().]
    >> 
    >> I have also attached a patch to read.ftable.Rd which documents
    >> the proposed argument (borrowing from cat.Rd).

That's an obviously simple and useful proposal.
It will be in R-devel (R 2.3.0 to be) -- with a slight
modification of putting the new 'append' after the 'quote'
argument:
Will it make less likely to hurt anybody who has made use of
"positional argumenting", i.e., had used

write.ftable(tab, fil, TRUE)

Martin Maechler, ETH Zurich


From maechler at stat.math.ethz.ch  Fri Mar 17 11:36:52 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Mar 2006 11:36:52 +0100
Subject: [Rd] .Platform$eol.sep ? [Re: "\r" with RSQLite]
In-Reply-To: <20060316145131.GE17669@jessie.research.bell-labs.com>
References: <20060315184534.13623.qmail@web60212.mail.yahoo.com>
	<20060316145131.GE17669@jessie.research.bell-labs.com>
Message-ID: <17434.37188.943713.118662@stat.math.ethz.ch>

[ diverted from R-help to R-devel ]

>>>>> "DJ" == David James <dj at research.bell-labs.com>
>>>>>     on Thu, 16 Mar 2006 09:51:31 -0500 writes:

    DJ> That is a bug, namely, the default end of line on the windows version 
    DJ> should be "\r\n" instead of "\n".  The workaround is to specify 
    DJ> eol="\r\n" in dbWriteTable(), e.g.,

    DJ> dbWriteTable(con, "DF", df, eol = "\r\n")
    DJ> dbReadTable(con, "DF")

    DJ> Hope this helps,

    DJ> --
    DJ> David

    DJ> PS The object .Platform includes path.sep and file.sep but not
    DJ> end of line separator (as of 2.2.0) -- would it make sense to
    DJ> also include eol.sep?

I think it would.  AFAIK, the Macs used to have  "\r" such that

  Unix:    "\n"
  Windoze: "\r\n"
  Mac :    "\r"

but it could well be that this has only been for Mac OS x.y, x <= 9,
i.e., is no longer true for MacOS X (which would behave like `Unix' then).

Brian Ripley is currently enjoying holidays AFAIK; I think he
might want to shed more light on this as well.

Martin


From duncan at wald.ucdavis.edu  Fri Mar 17 14:38:49 2006
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 17 Mar 2006 05:38:49 -0800
Subject: [Rd] multiple packages using the same native code.
In-Reply-To: <441A24A1.6020006@berkeley.edu>
References: <4418AA0C.1040703@berkeley.edu> <m2wtevp59u.fsf@ziti.local>
	<441A24A1.6020006@berkeley.edu>
Message-ID: <441ABBE9.7090805@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



There is work underway to be able to handle this concept
of a package providing native code to other packages.
It is done in several packages already, but it is time
to make the package mechanism extensible and this feature
is one of the motivating examples.  It probably won't make it
into 2.3.0 as I am only just finishing a quarter of intense teaching,
but it will be available reasonably soon (i.e. a month or so).


Copying the code is the most natural approach, but this does not
support the important case where one wants a single instance of
a shared native symbol, i.e. a global data object.

There are several situations that we want to be able to support
and these will be possible via a package mechanism that relies
more on R code than shell & Perl scripts.

James Bullard wrote:
> Seth, thanks for the advice. This solution seems like it might work, but 
> then all errors occur at runtime rather than at compile time. This seems 
> like I am exchanging one evil for another (run time segfaults versus 
> code duplication) Lets say we have these three package A, B, and C 
> defined more or less like this:
> 
> A/src/bar.c
> int bar()
> {
>     foo();
> }
> 
> B/src/baz.c
> int baz()
> {
>     foo();
> }
> 
> C/src/foo.c
> int foo()
> {
>     return 1;
> }
> 
> 
> Now, the only way I can see to do this is to copy foo.c into both src 
> directories of package A and B. This is not exactly what anyone wants, 
> but rather I'd rather just say that both package A and B depend on 
> package C. If I put them in a bundle then can I expect that the src will 
> always simultaneously be available? In this way I can easily modify the 
> configure script to handle this, but if I have no way to depend on the 
> presence of the code (ie. users could download and install packages 
> separately even if it's a bundle) then it seems like there is no way to 
> generally modify the configure file to do this.
> 
> 
> thanks, jim
> 
> 
> 
> 
> 
> Seth Falcon wrote:
> 
> 
>>Hi Jim,
>>
>>James Bullard <bullard at berkeley.edu> writes:
>> 
>>
>>
>>>I would like to construct two packages (A, B) which utilize a number of 
>>>common C functions. The most straightforward way to do this is just copy 
>>>the relevant .c and .h files from one src directory to the next, but 
>>>this is tedious especially in the face of multiple developers and
>>>changes.
>>>   
>>>
>>
>>I'm not sure I understand what you are after.  One possible solution
>>would be to create a third package 'C' that contains the common C
>>code.  This would allow you to call C function defined in 'C' from the
>>C code in 'A' or 'B'.
>>
>>Using a .onLoad hook and getNativeSymbolInfo(), you can pass C
>>function pointers to the code in packages A and B.
>>
>>Suppose in 'C' you have a C function foo() that is registered in the
>>usual manner so that it can be called by .Call or .C.
>>
>>Then in 'A' you could have (all untested, sorry, but hopefully it
>>sketches the idea for you):
>>
>>A/src/A.c
>>
>>  static DL_FUNC C_foo;
>>
>>  void init_funcs_from_C(SEXP foo_info) {
>>      C_foo = R_ExternalPtrAddr(foo_info);
>>  }
>>
>>  void bar(int *x) {
>>      ...
>>      z = C_foo();
>>      ...
>>  }
>>
>>
>>A/R/zzz.R
>>
>>  .onLoad <- function(libname, pkgname) {
>>      foo_info <- getNativeSymbolInfo("foo", PACKAGE="C")
>>      .Call("init_funcs_from_C", foo_info$address)
>>  }
>>
>>
>>+ seth
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> 
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                    duncan at wald.ucdavis.edu
Department of Statistics              work:  (530) 752-4782
4210 Mathematical Sciences Building   fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis,
CA 95616,
USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)

iD8DBQFEGrvp9p/Jzwa2QP4RAuoFAJ4ouFY/G21sWkw8fY/MCPc5GantdACdGFjE
xWGG+UGbxs1sTKN5o1+j69A=
=Isbq
-----END PGP SIGNATURE-----


From Yves.Rosseel at UGent.be  Mon Mar 13 15:24:44 2006
From: Yves.Rosseel at UGent.be (Yves.Rosseel@UGent.be)
Date: Mon, 13 Mar 2006 15:24:44 +0100 (CET)
Subject: [Rd] anova.mlm (single-model case) does not handle factors?
	(PR#8679)
Message-ID: <20060313142444.8D92C10401@slim.kubism.ku.dk>

Full_Name: Yves Rosseel
Version: 2.2.1
OS: i686-pc-linux-gnu
Submission from: (NULL) (157.193.116.152)


Dear developers,

For the single-model case, the anova.mlm() function does not seem to handle
multi-parameter predictors (eg factors) correctly. A toy example illustrates the
problem:

Y <- cbind(rnorm(100),rnorm(100),rnorm(100))
A <- factor(rep(c(1,2,3,4), each=25))
fit <- lm(Y ~ A)
anova.mlm(fit)

gives

Error in T %*% ss[[i]] : non-conformable arguments

I think the problem lies in the computation of the 'ss' terms (line 237 in the
file mlm.R in the source code). Changing this (and the following line) by
something similar to what is done in summary.manova seems to resolve the
problem:

 comp <- as.matrix(fit$effects)[seq(along=asgn), ,drop=FALSE]
 uasgn <- unique(asgn)
 nterms <- length(uasgn)
 ss <- list(nterms)
 df <- numeric(nterms)
 for(i in seq(nterms)) {
    ai <- (asgn == uasgn[i])
    ss[[i]] <- crossprod(comp[ai, ,drop=FALSE])
    df[i] <- sum(ai)
 }


From Yves.Rosseel at UGent.be  Mon Mar 13 18:09:19 2006
From: Yves.Rosseel at UGent.be (Yves.Rosseel@UGent.be)
Date: Mon, 13 Mar 2006 18:09:19 +0100 (CET)
Subject: [Rd] wishlist: function mlh.mlm to test multivariate linear
	hypotheses of the form: LBT'=0 (PR#8680)
Message-ID: <20060313170919.449363FCA0@slim.kubism.ku.dk>

Full_Name: Yves Rosseel
Version: 2.2.1
OS: 
Submission from: (NULL) (157.193.116.152)


The code below sketches a possible implementation of a function 'mlh.mlm' which
I think would be a good complement to the 'anova.mlm' function in the stats
package. It tests a single linear hypothesis of the form H_0: LBT'= 0 where B is
the matrix of regression coefficients; L is a matrix with rows giving linear
combinations of the regressions coefficients; the transformation matrix T has
the same meaning as in the anova.mlm function. An example and some bare-bones
code is listed below (code depends on the Pillai, Wilks etc. functions defined
in src/library/stats/R/mlm.R).

Example model: 3 dependents, 1 between-subjects factor with 4 levels

set.seed(123)
Y <- cbind(rnorm(100), rnorm(100), rnorm(100)) 
A <- factor(rep(c(1,2,3,4), each=25))
fit <- lm(Y ~ A)

Example 1: simple contrast: compare level 3 versus level 4 (multivariate)
(note: first zero in l1 corresponds to the intercept, not the first level of A)
l1 <- c(0, 0, 1, -1)
L <- rbind(l1)
mlh.mlm(fit, L=L, test="Wilks")

     Wilks   approx F     num Df     den Df     Pr(>F)
 0.9874192  0.3992218  3.0000000 94.0000000  0.7538689

Example 2: suppose the three dependents are three timepoints (time); is there a
contrast*time interaction (using the contrast above: level 3 versus level 4)

t1 <- c(1,-1,0); t2 <- c(0,1,-1)
T <- rbind(t1,t2)
mlh.mlm(fit, L=L, T=T, test="Wilks")

     Wilks   approx F     num Df     den Df     Pr(>F)
 0.9889929  0.5286555  2.0000000 95.0000000  0.5911205



Code:
------------------------------------------------------------------------------------
mlh.mlm <-
    function(object, L = null, T = diag(nrow = p),
             test = c("Pillai", "Wilks", "Hotelling-Lawley", "Roy"))
{
    # test the multivariate linear hypothesis LBT'=0
    # B = matrix of regression coefficients
    # L = matrix, each row is a linear combination of the parameters
    # T = transformation matrix

    if(!inherits(object, "mlm"))
        stop("object must be of class \"mlm\"")

    if( is.null(L) )
        stop("L matrix is not specified.")

    # L must be a matrix
    if( is.null(dim(L)) )
        L <- t(L)

    if( nrow(object$coef) != ncol(L) )
        stop("nrow(object$coef) != ncol(L)")

    p <- ncol(SSD(object)$SSD)
    ssd <- SSD(object)
    df.res <- ssd$df
    rss.qr <- qr(T %*% ssd$SSD %*% t(T))

    X <- as.matrix( model.matrix(object) )
    B <- as.matrix( object$coef )

    df <- nrow(L)
    ss <- t(L %*% B) %*%
          as.matrix(solve(L %*% solve(t(X) %*% X) %*% t(L))) %*%
          (L %*% B)

    eigs <- Re(eigen(qr.coef(rss.qr,
                             T %*% ss %*% t(T)),
                             symmetric = FALSE)$values)

    test <- match.arg(test)
    stats <- switch(test,
                           "Pillai" = Pillai(eigs, df, df.res),
                           "Wilks"  =  Wilks(eigs, df, df.res),
                           "Hotelling-Lawley" = HL(eigs, df, df.res),
                           "Roy"    = Roy(eigs, df, df.res)
                    )
    stats[5] <- pf(stats[2], stats[3], stats[4], lower.tail = FALSE)
    names(stats) <- c(test, "approx F", "num Df", "den Df", "Pr(>F)")

    stats
}


From dgrove at fhcrc.org  Fri Mar 17 18:31:16 2006
From: dgrove at fhcrc.org (dgrove@fhcrc.org)
Date: Fri, 17 Mar 2006 18:31:16 +0100 (CET)
Subject: [Rd] documentation for plot.default (PR#8689)
Message-ID: <20060317173116.1C3D541EAC@slim.kubism.ku.dk>

Full_Name: Doug Grove
Version: 2.2.1
OS: SuSE 9.3 Linux
Submission from: (NULL) (140.107.156.61)


Could someone please alter the wording of the documentation of the 'xlim'
argument
in plot.default?  It currently includes "(min,max)" which led me to think that
I couldn't use a specification like xlim=c(10,1).  The basic issue is that there
is
nothing (that I see) in the help page that suggests that one can specify the
axis limits in a decreasing order and get a plot that corresponds to that.  I
had no idea
this was possible 'til I saw a posting on r-help yesterday.  Ideally it would be
nice
to somehow indicate this is possible, however at the least changing the
"(min,max)"
to "(begin,end)" or something more reflective of what the xlim/ylim arguments
represent
would be better.

Thanks!
Doug


From timh at insightful.com  Fri Mar 17 20:19:28 2006
From: timh at insightful.com (timh@insightful.com)
Date: Fri, 17 Mar 2006 20:19:28 +0100 (CET)
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
Message-ID: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>

----- Quick summary:  

In the File:Open dialog, please change
"S files (*.q)" 
to
"S files (*.q, *.ssc, *.S)" 
and show the corresponding files (including .SSC and .s files).

----- Background
This is motivated by the following query to R-help:

>Date: Thu, 16 Mar 2006 22:44:11 -0600
>From: "xpRt.wannabe" <xprt.wannabe at gmail.com>
>Subject: [R] Is there a way to view S-PLUS script files in R
>To: r-help at stat.math.ethz.ch
>
>Dear List,
>
>I have some S-PLUS script files (.ssc).  Does there exist an R
>function/command  that can read such files?  I simply want to view the
>code and practice in R to help me learn the subject matter.
>
>Any help would be greatly appreciated.
>
>platform i386-pc-mingw32
>arch     i386
>os       mingw32
>system   i386, mingw32
>status
>major    2
>minor    2.1
>year     2005
>month    12
>day      20
>svn rev  36812
>language R

I responded:
>You can open them in R.  On Windows, File:Open Script,
>change "Files of type" to "All Files", then open the .ssc file.

So there is a workaround.  But it is odd that the "S files" option
doesn't actually include what are probably the most common S files.

Thanks,
Tim Hesterberg


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:glmpath, package:survival, package:splines, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From hichem.omrani at utc.fr  Fri Mar 17 20:35:09 2006
From: hichem.omrani at utc.fr (Omrani Hichem)
Date: Fri, 17 Mar 2006 20:35:09 +0100
Subject: [Rd] About AHP (Analytic Hierachy process)
In-Reply-To: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
Message-ID: <1142624109.441b0f6dbf334@mail3c.utc.fr>

Dear Sir,

I wander if, it existes in R,a library or a routine for AHP (Analytic Hiararchy
Process). AHP is a kind of Multi criteria Analysis approach.

Thanks, for help.


From murdoch at stats.uwo.ca  Fri Mar 17 20:45:07 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Mar 2006 14:45:07 -0500
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
Message-ID: <441B11C3.1030805@stats.uwo.ca>

On 3/17/2006 2:19 PM, timh at insightful.com wrote:
> ----- Quick summary:  
> 
> In the File:Open dialog, please change
> "S files (*.q)" 
> to
> "S files (*.q, *.ssc, *.S)" 
> and show the corresponding files (including .SSC and .s files).

I'll make this change in the Windows Rgui.  Is this an issue in the Mac 
gui too?

Duncan Murdoch

> 
> ----- Background
> This is motivated by the following query to R-help:
> 
>>Date: Thu, 16 Mar 2006 22:44:11 -0600
>>From: "xpRt.wannabe" <xprt.wannabe at gmail.com>
>>Subject: [R] Is there a way to view S-PLUS script files in R
>>To: r-help at stat.math.ethz.ch
>>
>>Dear List,
>>
>>I have some S-PLUS script files (.ssc).  Does there exist an R
>>function/command  that can read such files?  I simply want to view the
>>code and practice in R to help me learn the subject matter.
>>
>>Any help would be greatly appreciated.
>>
>>platform i386-pc-mingw32
>>arch     i386
>>os       mingw32
>>system   i386, mingw32
>>status
>>major    2
>>minor    2.1
>>year     2005
>>month    12
>>day      20
>>svn rev  36812
>>language R
> 
> I responded:
>>You can open them in R.  On Windows, File:Open Script,
>>change "Files of type" to "All Files", then open the .ssc file.
> 
> So there is a workaround.  But it is odd that the "S files" option
> doesn't actually include what are probably the most common S files.
> 
> Thanks,
> Tim Hesterberg
> 
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = 
>  major = 2
>  minor = 2.1
>  year = 2005
>  month = 12
>  day = 20
>  svn rev = 36812
>  language = R
> 
> Windows XP Professional (build 2600) Service Pack 2.0
> 
> Locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> Search Path:
>  .GlobalEnv, package:glmpath, package:survival, package:splines, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From timh at insightful.com  Fri Mar 17 20:53:56 2006
From: timh at insightful.com (Tim Hesterberg)
Date: 17 Mar 2006 11:53:56 -0800
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <441B11C3.1030805@stats.uwo.ca> (message from Duncan Murdoch on
	Fri, 17 Mar 2006 14:45:07 -0500)
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
	<441B11C3.1030805@stats.uwo.ca>
Message-ID: <SE2KEXCH01wO5blwHUp00000a39@se2kexch01.insightful.com>

I think it would be good to make the change in the Mac gui too.
This would help people on the mac who work on multiple platforms,
or try scripts from other people.


I forgot to mention one other extension, ".t", an extension often
used for tests to be processed using do.test().  However, this
is less common, could easily be excluded; people can use "all files"
for this.

Thanks,
Tim

>On 3/17/2006 2:19 PM, timh at insightful.com wrote:
>> ----- Quick summary:  
>> 
>> In the File:Open dialog, please change
>> "S files (*.q)" 
>> to
>> "S files (*.q, *.ssc, *.S)" 
>> and show the corresponding files (including .SSC and .s files).
>
>I'll make this change in the Windows Rgui.  Is this an issue in the Mac 
>gui too?
>
>Duncan Murdoch
>
>> 
>> ----- Background
>> This is motivated by the following query to R-help:
>> 
>>>Date: Thu, 16 Mar 2006 22:44:11 -0600
>>>From: "xpRt.wannabe" <xprt.wannabe at gmail.com>
>>>Subject: [R] Is there a way to view S-PLUS script files in R
>>>To: r-help at stat.math.ethz.ch
>>>
>>>Dear List,
>>>
>>>I have some S-PLUS script files (.ssc).  Does there exist an R
>>>function/command  that can read such files?  I simply want to view the
>>>code and practice in R to help me learn the subject matter.
>>>
>>>Any help would be greatly appreciated.
>>>
>>>platform i386-pc-mingw32
>>>arch     i386
>>>os       mingw32
>>>system   i386, mingw32
>>>status
>>>major    2
>>>minor    2.1
>>>year     2005
>>>month    12
>>>day      20
>>>svn rev  36812
>>>language R
>> 
>> I responded:
>>>You can open them in R.  On Windows, File:Open Script,
>>>change "Files of type" to "All Files", then open the .ssc file.
>> 
>> So there is a workaround.  But it is odd that the "S files" option
>> doesn't actually include what are probably the most common S files.
>> 
>> Thanks,
>> Tim Hesterberg
>> 
>> 
>> --please do not edit the information below--
>> 
>> Version:
>>  platform = i386-pc-mingw32
>>  arch = i386
>>  os = mingw32
>>  system = i386, mingw32
>>  status = 
>>  major = 2
>>  minor = 2.1
>>  year = 2005
>>  month = 12
>>  day = 20
>>  svn rev = 36812
>>  language = R
>> 
>> Windows XP Professional (build 2600) Service Pack 2.0
>> 
>> Locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>> 
>> Search Path:
>>  .GlobalEnv, package:glmpath, package:survival, package:splines, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Fri Mar 17 21:13:53 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Mar 2006 15:13:53 -0500
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <SE2KEXCH01wO5blwHUp00000a39@se2kexch01.insightful.com>
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
	<441B11C3.1030805@stats.uwo.ca>
	<SE2KEXCH01wO5blwHUp00000a39@se2kexch01.insightful.com>
Message-ID: <441B1881.9050302@stats.uwo.ca>

On 3/17/2006 2:53 PM, Tim Hesterberg wrote:
> I think it would be good to make the change in the Mac gui too.
> This would help people on the mac who work on multiple platforms,
> or try scripts from other people.

I don't know anything about how file dialogs work there, so I won't 
touch this one.

> I forgot to mention one other extension, ".t", an extension often
> used for tests to be processed using do.test().  However, this
> is less common, could easily be excluded; people can use "all files"
> for this.

I think "all files" is best for that.

Duncan Murdoch

> 
> Thanks,
> Tim
> 
>>On 3/17/2006 2:19 PM, timh at insightful.com wrote:
>>> ----- Quick summary:  
>>> 
>>> In the File:Open dialog, please change
>>> "S files (*.q)" 
>>> to
>>> "S files (*.q, *.ssc, *.S)" 
>>> and show the corresponding files (including .SSC and .s files).
>>
>>I'll make this change in the Windows Rgui.  Is this an issue in the Mac 
>>gui too?
>>
>>Duncan Murdoch
>>
>>> 
>>> ----- Background
>>> This is motivated by the following query to R-help:
>>> 
>>>>Date: Thu, 16 Mar 2006 22:44:11 -0600
>>>>From: "xpRt.wannabe" <xprt.wannabe at gmail.com>
>>>>Subject: [R] Is there a way to view S-PLUS script files in R
>>>>To: r-help at stat.math.ethz.ch
>>>>
>>>>Dear List,
>>>>
>>>>I have some S-PLUS script files (.ssc).  Does there exist an R
>>>>function/command  that can read such files?  I simply want to view the
>>>>code and practice in R to help me learn the subject matter.
>>>>
>>>>Any help would be greatly appreciated.
>>>>
>>>>platform i386-pc-mingw32
>>>>arch     i386
>>>>os       mingw32
>>>>system   i386, mingw32
>>>>status
>>>>major    2
>>>>minor    2.1
>>>>year     2005
>>>>month    12
>>>>day      20
>>>>svn rev  36812
>>>>language R
>>> 
>>> I responded:
>>>>You can open them in R.  On Windows, File:Open Script,
>>>>change "Files of type" to "All Files", then open the .ssc file.
>>> 
>>> So there is a workaround.  But it is odd that the "S files" option
>>> doesn't actually include what are probably the most common S files.
>>> 
>>> Thanks,
>>> Tim Hesterberg
>>> 
>>> 
>>> --please do not edit the information below--
>>> 
>>> Version:
>>>  platform = i386-pc-mingw32
>>>  arch = i386
>>>  os = mingw32
>>>  system = i386, mingw32
>>>  status = 
>>>  major = 2
>>>  minor = 2.1
>>>  year = 2005
>>>  month = 12
>>>  day = 20
>>>  svn rev = 36812
>>>  language = R
>>> 
>>> Windows XP Professional (build 2600) Service Pack 2.0
>>> 
>>> Locale:
>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>> 
>>> Search Path:
>>>  .GlobalEnv, package:glmpath, package:survival, package:splines, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From simon.urbanek at r-project.org  Fri Mar 17 22:14:44 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Mar 2006 16:14:44 -0500
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <441B11C3.1030805@stats.uwo.ca>
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
	<441B11C3.1030805@stats.uwo.ca>
Message-ID: <68A9B4BE-6C88-4123-9C2E-8A39A983981D@r-project.org>


On Mar 17, 2006, at 2:45 PM, Duncan Murdoch wrote:

> On 3/17/2006 2:19 PM, timh at insightful.com wrote:
>> ----- Quick summary:
>>
>> In the File:Open dialog, please change
>> "S files (*.q)"
>> to
>> "S files (*.q, *.ssc, *.S)"
>> and show the corresponding files (including .SSC and .s files).
>
> I'll make this change in the Windows Rgui.  Is this an issue in the  
> Mac  gui too?
>

Yes, I was not aware of .ssc, either. Will fix that.

Thanks,
Simon


From simon.urbanek at r-project.org  Fri Mar 17 22:15:01 2006
From: simon.urbanek at r-project.org (simon.urbanek@r-project.org)
Date: Fri, 17 Mar 2006 22:15:01 +0100 (CET)
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
Message-ID: <20060317211501.81501283AF@slim.kubism.ku.dk>


On Mar 17, 2006, at 2:45 PM, Duncan Murdoch wrote:

> On 3/17/2006 2:19 PM, timh at insightful.com wrote:
>> ----- Quick summary:
>>
>> In the File:Open dialog, please change
>> "S files (*.q)"
>> to
>> "S files (*.q, *.ssc, *.S)"
>> and show the corresponding files (including .SSC and .s files).
>
> I'll make this change in the Windows Rgui.  Is this an issue in the  
> Mac  gui too?
>

Yes, I was not aware of .ssc, either. Will fix that.

Thanks,
Simon


From tlumley at u.washington.edu  Fri Mar 17 22:32:32 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 17 Mar 2006 13:32:32 -0800 (PST)
Subject: [Rd] collation order
Message-ID: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>


The following caused a hard-to-diagnose problem for a user of the survey 
package.  Presumably this is a strange Unicode thing, but is there a 
convenient reference for how the collation order is determined? I am 
surprised that adding the same character to the end of two strings of the 
same length can change the sorting order.

in en_US.utf8 locale
> "1//"<"10/"
[1] TRUE
> "1//2"<"10/2"
[1] FALSE

in C locale on the same system.
> "1//"<"10/"
[1] TRUE
> "1//2"<"10/2"
[1] TRUE

[This is in r-devel of March 6, but the problem that was reported to me 
involved Windows vs Linux on released versions]

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From simon.urbanek at r-project.org  Fri Mar 17 23:32:39 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Mar 2006 17:32:39 -0500
Subject: [Rd] collation order
In-Reply-To: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>
References: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>
Message-ID: <CFEFA5D5-32B9-4B02-B3EB-118062B5BDF9@r-project.org>

On Mar 17, 2006, at 4:32 PM, Thomas Lumley wrote:

> The following caused a hard-to-diagnose problem for a user of the  
> survey package.  Presumably this is a strange Unicode thing,

It is independent of the encoding:

urbanek at corrino:~$ LC_COLLATE=en_US R --vanilla -q<tr
 > "1//"<"10/"
[1] TRUE
 > "1//2"<"10/2"
[1] FALSE
 > Sys.getlocale("LC_COLLATE")
[1] "en_US"

(en_US is ISO-8859-1 on that machine)

And systems don't seem to agree on anything but C locale:

Mac OS X:
caladan:urbanek$ LC_COLLATE=en_US R --vanilla -q<tr
 > "1//"<"10/"
[1] TRUE
 > "1//2"<"10/2"
[1] TRUE
 > Sys.getlocale("LC_COLLATE")
[1] "en_US"

IRIX:
fry:urbanek$ LC_COLLATE=en_US R --vanilla -q<tr
 > "1//"<"10/"
[1] FALSE
 > "1//2"<"10/2"
[1] FALSE
 > Sys.getlocale("LC_COLLATE")
[1] "en_US"

But at least most systems are consistent in terms of adding a  
character, except for GNU/Linux.

Looking at the locale definitions, GNU/Linux uses "iso14651_t1"  
template for many languages. Maybe the problem is that "/" is defined  
in the "SPECIAL" section of the ISO-14651 template, which possibly  
causes / to be completely ignored in the "LATIN" part, which would  
explain the behavior (("1"<"10")==TRUE, ("12"<"102")==FALSE). I  
couldn't find anything on what the "offical" en_** collating should  
be so I have no idea whether this is a bug in the GNU/Linux locales  
or not...

Cheers,
Simon


From p.dalgaard at biostat.ku.dk  Fri Mar 17 23:40:52 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Mar 2006 23:40:52 +0100
Subject: [Rd] anova.mlm (single-model case) does not handle factors?
	(PR#8679)
In-Reply-To: <20060313142444.8D92C10401@slim.kubism.ku.dk>
References: <20060313142444.8D92C10401@slim.kubism.ku.dk>
Message-ID: <x2hd5witjf.fsf@turmalin.kubism.ku.dk>

Yves.Rosseel at ugent.be writes:

> Full_Name: Yves Rosseel
> Version: 2.2.1
> OS: i686-pc-linux-gnu
> Submission from: (NULL) (157.193.116.152)
> 
> 
> Dear developers,
> 
> For the single-model case, the anova.mlm() function does not seem to handle
> multi-parameter predictors (eg factors) correctly. A toy example illustrates the
> problem:
> 
> Y <- cbind(rnorm(100),rnorm(100),rnorm(100))
> A <- factor(rep(c(1,2,3,4), each=25))
> fit <- lm(Y ~ A)
> anova.mlm(fit)
> 
> gives
> 
> Error in T %*% ss[[i]] : non-conformable arguments
> 
> I think the problem lies in the computation of the 'ss' terms (line 237 in the
> file mlm.R in the source code). Changing this (and the following line) by
> something similar to what is done in summary.manova seems to resolve the
> problem:
> 
>  comp <- as.matrix(fit$effects)[seq(along=asgn), ,drop=FALSE]
>  uasgn <- unique(asgn)
>  nterms <- length(uasgn)
>  ss <- list(nterms)
>  df <- numeric(nterms)
>  for(i in seq(nterms)) {
>     ai <- (asgn == uasgn[i])
>     ss[[i]] <- crossprod(comp[ai, ,drop=FALSE])
>     df[i] <- sum(ai)
>  }

Thanks for pointing this out. Amazing that it hasn't cropped up before...

The culprit seems to be the line

ss <- lapply(split(comp, asgn), function(x) crossprod(t(x)))

in which "comp" (an effects by responses matrix) is effectively turned
into a vector by split(). And, adding insult to injury, had you
actually gotten a matrix result, you wouldn't want to transpose it
before calculating the cross products.

A simpler, but slightly dirty fix is to set 

ss <- lapply(split.data.frame(comp, asgn), crossprod)

(the dirtiness is that split.data.frame actually does the right thing
for matrices; possibly, an identically defined split.matrix() would be
cleaner, although I'm never quite happy with matrix functions that
aren't symmetric in rows/columns.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Mar 17 23:56:29 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Mar 2006 23:56:29 +0100
Subject: [Rd] collation order
In-Reply-To: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>
References: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>
Message-ID: <x2d5gkiste.fsf@turmalin.kubism.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> The following caused a hard-to-diagnose problem for a user of the survey 
> package.  Presumably this is a strange Unicode thing, but is there a 
> convenient reference for how the collation order is determined? I am 
> surprised that adding the same character to the end of two strings of the 
> same length can change the sorting order.
> 
> in en_US.utf8 locale
> > "1//"<"10/"
> [1] TRUE
> > "1//2"<"10/2"
> [1] FALSE
> 
> in C locale on the same system.
> > "1//"<"10/"
> [1] TRUE
> > "1//2"<"10/2"
> [1] TRUE
> 
> [This is in r-devel of March 6, but the problem that was reported to me 
> involved Windows vs Linux on released versions]

Unicode has nothing to do with it (same thing in ISO-8859-1. It is
(I think) about characters being skipped during collating, i.e. same
effect as this:

> Sys.setlocale(locale="C")
[1] "C"
> "Thomas  O'Malley" < "Thomas Lumley"
[1] TRUE
> Sys.setlocale(locale="en_US.UTF8")
[1] "LC_CTYPE=en_US.UTF8;LC_NUMERIC=C;LC_TIME=en_US.UTF8;LC_COLLATE=en_US.UTF8;LC_MONETARY=en_US.UTF8;LC_MESSAGES=C;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
> "Thomas  O'Malley" <" Thomas Lumley"
[1] FALSE


> 
>  	-thomas
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Sat Mar 18 00:02:29 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Mar 2006 00:02:29 +0100
Subject: [Rd] collation order
In-Reply-To: <x2d5gkiste.fsf@turmalin.kubism.ku.dk>
References: <Pine.LNX.4.64.0603171320170.12181@homer22.u.washington.edu>
	<x2d5gkiste.fsf@turmalin.kubism.ku.dk>
Message-ID: <x28xr8isje.fsf@turmalin.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> > Sys.setlocale(locale="C")
> [1] "C"
> > "Thomas  O'Malley" < "Thomas Lumley"
> [1] TRUE
> > Sys.setlocale(locale="en_US.UTF8")
> [1] "LC_CTYPE=en_US.UTF8;LC_NUMERIC=C;LC_TIME=en_US.UTF8;LC_COLLATE=en_US.UTF8;LC_MONETARY=en_US.UTF8;LC_MESSAGES=C;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C"
> > "Thomas  O'Malley" <" Thomas Lumley"

Argh. The perils of beautifying code after the fact. The last line was
of course intended to read

"Thomas  O'Malley" < "Thomas Lumley"

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mbeason at harrahs.com  Sat Mar 18 01:08:08 2006
From: mbeason at harrahs.com (Matthew Beason)
Date: Fri, 17 Mar 2006 16:08:08 -0800
Subject: [Rd] R make install and demo(graphics) issue
Message-ID: <E153C65077E0034E97A981C6CE26F1BD044B3BCB@ENTWMAIL1A.harrahs.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060317/d2ddbe3b/attachment.pl

From simon.urbanek at r-project.org  Sat Mar 18 01:52:08 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Mar 2006 19:52:08 -0500
Subject: [Rd] R make install and demo(graphics) issue
In-Reply-To: <E153C65077E0034E97A981C6CE26F1BD044B3BCB@ENTWMAIL1A.harrahs.org>
References: <E153C65077E0034E97A981C6CE26F1BD044B3BCB@ENTWMAIL1A.harrahs.org>
Message-ID: <B8612CAD-70E8-4A00-9025-B37083340277@r-project.org>


On 17.3.2006, at 19:08, Matthew Beason wrote:

> I've successfully gotten R 2.2.1 to compile on AIX 5.2.
>
> However, when I run "make install", I receive the following message:
>
> /appl/perform/workspace/R-2.2.1
> [root at diablo][/appl/perform/workspace/R-2.2.1] make install
> /appl/perform/workspace/R-2.2.1/m4
> Target "install" is up to date.
> /appl/perform/workspace/R-2.2.1/tools
> Target "install" is up to date.
> /appl/perform/workspace/R-2.2.1/doc
> installing doc ...
> ../tools/install-sh: no destination specified.
> make: The error code from the last command is 1.
>

Chances are that this is related to an issue with some shells  
mentioned here before - you can either use R-2.2.1 patched from SVN  
where it is fixed, or alternatively edit configure at line 1913:
if test -z ${rdocdir}; then
into
if test -z "${rdocdir}"; then
and make the same modification to the subsequent two if statements as  
well.

Cheers,
Simon


From pburns at pburns.seanet.com  Sat Mar 18 13:54:48 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 18 Mar 2006 12:54:48 +0000
Subject: [Rd] all.equal buglet(s)
Message-ID: <441C0318.9080506@pburns.seanet.com>

In the details section for 'all.equal' (in the paragraph
on complex values) it says 'all.numeric.numeric'.  I
presume that should be 'all.equal.numeric'.

When two integer vectors differ, it is possible to get
overflow:

 > set.seed(1)
 > r1 <- .Random.seed
 > set.seed(2)
 > r2 <- .Random.seed
 > all.equal(r1, r2)
[1] "Mean relative  difference: NA"
Warning message:
NAs produced by integer overflow in: target - current

A small change to 'all.equal.numeric' would fix that if it
is felt to be worthwhile.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


From maechler at stat.math.ethz.ch  Sat Mar 18 14:58:57 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 18 Mar 2006 14:58:57 +0100
Subject: [Rd] all.equal buglet(s)
In-Reply-To: <441C0318.9080506@pburns.seanet.com>
References: <441C0318.9080506@pburns.seanet.com>
Message-ID: <17436.4641.69503.211180@stat.math.ethz.ch>

Thanks a lot, Pat!

>>>>> "PatBurns" == Patrick Burns <pburns at pburns.seanet.com>
>>>>>     on Sat, 18 Mar 2006 12:54:48 +0000 writes:

    PatBurns> In the details section for 'all.equal' (in the paragraph
    PatBurns> on complex values) it says 'all.numeric.numeric'.  I
    PatBurns> presume that should be 'all.equal.numeric'.

yes, thanks, fixed.

    PatBurns> When two integer vectors differ, it is possible to get
    PatBurns> overflow:

    >> set.seed(1)
    >> r1 <- .Random.seed
    >> set.seed(2)
    >> r2 <- .Random.seed
    >> all.equal(r1, r2)
    PatBurns> [1] "Mean relative  difference: NA"
    PatBurns> Warning message:
    PatBurns> NAs produced by integer overflow in: target - current

    PatBurns> A small change to 'all.equal.numeric' would fix that if it
    PatBurns> is felt to be worthwhile.

it is.  Thank you.  The fix will be in tomorrow's R-devel

Martin Maechler, ETH Zurich


From sgiannerini at gmail.com  Sun Mar 19 11:29:33 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Sun, 19 Mar 2006 11:29:33 +0100
Subject: [Rd] About AHP (Analytic Hierachy process)
In-Reply-To: <1142624109.441b0f6dbf334@mail3c.utc.fr>
References: <20060317191928.A0B2641EB7@slim.kubism.ku.dk>
	<1142624109.441b0f6dbf334@mail3c.utc.fr>
Message-ID: <3c12769c0603190229h3e67d5ddqe41fa4622b718ba1@mail.gmail.com>

To my knowledge there is not such a thing in R, but at
http://www.superdecisions.com
there is a free multiplatform software implemented by Saaty that does
AHP/ANP models.

Regards,

Simone

On 3/17/06, Omrani Hichem <hichem.omrani at utc.fr> wrote:
> Dear Sir,
>
> I wander if, it existes in R,a library or a routine for AHP (Analytic Hiararchy
> Process). AHP is a kind of Multi criteria Analysis approach.
>
> Thanks, for help.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


--
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153
E-mail: giannerini at stat.unibo.it


From h.wickham at gmail.com  Mon Mar 20 03:30:12 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 19 Mar 2006 20:30:12 -0600
Subject: [Rd] Package dependencies when submitting to CRAN: policies?
Message-ID: <f8e6ff050603191830s140fe7a0k8292dd5bda8c2530@mail.gmail.com>

What is the policy for submitting packages that depend on external
non-R code?  We'd like to add Rggobi2 to CRAN, but since the CRAN
machine won't have GGobi, I wanted to check what the policy/procedures
are.

Regards,

Hadley


From gregor.gorjanc at gmail.com  Mon Mar 20 06:50:55 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Mon, 20 Mar 2006 06:50:55 +0100
Subject: [Rd] [R] Collapsing levels of a factor
Message-ID: <441E42BF.2080602@gmail.com>

>> x <- factor(1:3, labels = c("b" , "f", "minus"))
>> x
> [1] b     f     minus
> Levels: b f minus
> 
> I want to change all "minus" to "b". I know that the simplest way to do this is
> 
>> levels(x)  <- c("b", "f", "b")
> 
> and also that
> 
>>  x[x == "minus"] <- "b"
>> x <- factor(x)
> 
> works. But why not
> 
>> x <- ifelse(x == "minus", "b", x)
>> x <- factor(x)
> x
> [1] 1 2 b
> Levels: 1 2 b
> 

I find particulary usefull the list approach. Here is the example from
levels help page. I like this approach, since you can modify list and
apply it to a factor via levels.

  ## we can add levels this way:
     f <- factor(c("a","b"))
     levels(f) <- c("c", "a", "b")
     f

     f <- factor(c("a","b"))
     levels(f) <- list(C="C", A="a", B="b")
     f

I was playing around this last week and wrote a simple function[1],
which can save you some work in getting such a list from a factor. Is R
core interested in it?

[1]http://www.bfro.uni-lj.si/MR/ggorjan/software/R/ggmisc/factorMap.R

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From ligges at statistik.uni-dortmund.de  Mon Mar 20 08:42:59 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 20 Mar 2006 08:42:59 +0100
Subject: [Rd] Package dependencies when submitting to CRAN: policies?
In-Reply-To: <f8e6ff050603191830s140fe7a0k8292dd5bda8c2530@mail.gmail.com>
References: <f8e6ff050603191830s140fe7a0k8292dd5bda8c2530@mail.gmail.com>
Message-ID: <441E5D03.9080105@statistik.uni-dortmund.de>

hadley wickham wrote:

> What is the policy for submitting packages that depend on external
> non-R code?  We'd like to add Rggobi2 to CRAN, but since the CRAN
> machine won't have GGobi, I wanted to check what the policy/procedures
> are.

I think it is worth to discuss this topic with the CRAN maintainers 
(hence Kurt Hornik, in particular).

I will come back to this in a separate thread off-list.

Uwe Ligges


> Regards,
> 
> Hadley


From roebuck at mdanderson.org  Mon Mar 20 09:01:43 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 20 Mar 2006 02:01:43 -0600 (CST)
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <20060317211501.81501283AF@slim.kubism.ku.dk>
References: <20060317211501.81501283AF@slim.kubism.ku.dk>
Message-ID: <Pine.OSF.4.58.0603200142520.393656@wotan.mdacc.tmc.edu>

On Fri, 17 Mar 2006 Simon Urbanek wrote:

> On Mar 17, 2006, at 2:45 PM, Duncan Murdoch wrote:
>
> > On 3/17/2006 2:19 PM, timh at insightful.com wrote:
> >> ----- Quick summary:
> >>
> >> In the File:Open dialog, please change
> >> "S files (*.q)"
> >> to
> >> "S files (*.q, *.ssc, *.S)"
> >> and show the corresponding files (including .SSC and .s files).
> >
> > I'll make this change in the Windows Rgui.
> > Is this an issue in the Mac gui too?
>
> Yes, I was not aware of .ssc, either. Will fix that.

The Info.plist modifications I sent Simon a while back
included both dot-ssc and dot-s for S-plus files.

Might want to keep in mind that dot-s (and dot-S) is the
file extension for assembly source and on case-insensitive
file systems, like Windows and Mac OS X (HFS+ using default
settings), that could cause confusion if assembly source
files are present.

See also gcc(1).

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From murdoch at stats.uwo.ca  Mon Mar 20 15:04:16 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Mar 2006 09:04:16 -0500
Subject: [Rd] Open .ssc .S ... files in R (PR#8690)
In-Reply-To: <Pine.OSF.4.58.0603200142520.393656@wotan.mdacc.tmc.edu>
References: <20060317211501.81501283AF@slim.kubism.ku.dk>
	<Pine.OSF.4.58.0603200142520.393656@wotan.mdacc.tmc.edu>
Message-ID: <441EB660.8040502@stats.uwo.ca>

On 3/20/2006 3:01 AM, Paul Roebuck wrote:
> On Fri, 17 Mar 2006 Simon Urbanek wrote:
> 
>> On Mar 17, 2006, at 2:45 PM, Duncan Murdoch wrote:
>>
>> > On 3/17/2006 2:19 PM, timh at insightful.com wrote:
>> >> ----- Quick summary:
>> >>
>> >> In the File:Open dialog, please change
>> >> "S files (*.q)"
>> >> to
>> >> "S files (*.q, *.ssc, *.S)"
>> >> and show the corresponding files (including .SSC and .s files).
>> >
>> > I'll make this change in the Windows Rgui.
>> > Is this an issue in the Mac gui too?
>>
>> Yes, I was not aware of .ssc, either. Will fix that.
> 
> The Info.plist modifications I sent Simon a while back
> included both dot-ssc and dot-s for S-plus files.
> 
> Might want to keep in mind that dot-s (and dot-S) is the
> file extension for assembly source and on case-insensitive
> file systems, like Windows and Mac OS X (HFS+ using default
> settings), that could cause confusion if assembly source
> files are present.
> 
> See also gcc(1).

On Windows outside of gcc, assembly source is normally named *.asm.  R 
only uses one assembly source file named *.S so I think it's fairly 
unlikely that this will cause confusion.  I don't know if it's more 
common on OS X.

On the other hand, *.s or *.S are reasonably common names for S source 
files in packages, so I think this is a useful change, at least in Windows.

Duncan Murdoch


From jhallman at frb.gov  Mon Mar 20 16:52:09 2006
From: jhallman at frb.gov (jhallman at frb.gov)
Date: Mon, 20 Mar 2006 16:52:09 +0100 (CET)
Subject: [Rd] format.default loses matrix structure (PR#8695)
Message-ID: <20060320155209.7509241EC7@slim.kubism.ku.dk>

Full_Name: Jeff Hallman
Version: 2.2.0
OS: Linux
Submission from: (NULL) (132.200.32.34)


format.default() loses matrix structure if big.mark is given

> format(matrix(1:16, 4))
     [,1] [,2] [,3] [,4]
[1,] " 1" " 5" " 9" "13"
[2,] " 2" " 6" "10" "14"
[3,] " 3" " 7" "11" "15"
[4,] " 4" " 8" "12" "16"
> format(matrix(1:16, 4), big.mark = ",")
 [1] " 1" " 2" " 3" " 4" " 5" " 6" " 7" " 8" " 9" "10" "11" "12" "13" "14" "15"
[16] "16"


From gregor.gorjanc at bfro.uni-lj.si  Mon Mar 20 16:53:11 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Mon, 20 Mar 2006 16:53:11 +0100
Subject: [Rd] levels for list and data.frame
Message-ID: <441ECFE7.9080800@bfro.uni-lj.si>

Hello!

Does R core find the following pacth usefull - I created methods for
levels for list and data.frame, which can be usefull to get a list of
levels for entries in a list or columns in a data.frame. Patch is
attached and shown bellow example

# Example
> tmp <- list()
> tmp$a <- factor(letters[1:10])
> tmp$b <- factor(letters[5:14])
> tmp$c <- 1:10
> tmp1 <- as.data.frame(tmp)
> tmp2 <- list()
> tmp2$"1" <- tmp
> tmp2$"2" <- tmp1
> str(tmp2)
List of 2
 $ 1:List of 3
  ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
  ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
  ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
 $ 2:`data.frame':      10 obs. of  3 variables:
  ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
  ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
  ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10

> levels(tmp2)
$"1"
$"1"$a
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"

$"1"$b
 [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"


$"2"
$"2"$a
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"

$"2"$b
 [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"

> levels(tmp2, drop = FALSE)
$"1"
$"1"$a
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"

$"1"$b
 [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"

$"1"$c
NULL


$"2"
$"2"$a
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"

$"2"$b
 [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"

$"2"$c
NULL

----------------------------------------------------------------------

$ svn diff factor.R
Index: factor.R
===================================================================
--- factor.R    (revision 37559)
+++ factor.R    (working copy)
@@ -25,7 +25,25 @@
 ## Help old S users:
 category <- function(...) .Defunct()

-levels <- function(x) attr(x, "levels")
+levels <- function(x, ...) UseMethod("levels")
+
+levels.default <- function(x, ...) attr(x, "levels")
+
+levels.list <- function(x, drop = TRUE)
+{
+    tmp <- lapply(x, levels, drop = drop)
+    if (drop) {
+        tmp1 <- unlist(lapply(tmp, is.null))
+        tmp <- tmp[!tmp1]
+    }
+    return(tmp)
+}
+
+levels.data.frame <- function(x, ...)
+{
+    return(levels.list(x, ...))
+}
+
 nlevels <- function(x) length(levels(x))

 "levels<-" <- function(x, value) UseMethod("levels<-")

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.
----------------------------------------------------------------------
-------------- next part --------------
A non-text attachment was scrubbed...
Name: factor.R.diff.gz
Type: application/x-gzip
Size: 361 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060320/522fdf5f/attachment.gz 

From Jeffrey.J.Hallman at frb.gov  Mon Mar 20 17:08:23 2006
From: Jeffrey.J.Hallman at frb.gov (Jeffrey.J.Hallman at frb.gov)
Date: Mon, 20 Mar 2006 17:08:23 +0100 (CET)
Subject: [Rd] R-2.2.0 format.default() loses matrix structure (PR#8696)
Message-ID: <20060320160823.CCD0141EC8@slim.kubism.ku.dk>


If argument big.mark is supplied.  Like so:

> version         _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R
> mat <- matrix(1:6, 3)
> mat
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
> format(mat)
     [,1] [,2]
[1,] "1"  "4"
[2,] "2"  "5"
[3,] "3"  "6"
> format(mat, big.mark = ",")
[1] "1" "2" "3" "4" "5" "6"
>


From mbeason at harrahs.com  Mon Mar 20 18:52:53 2006
From: mbeason at harrahs.com (Matthew Beason)
Date: Mon, 20 Mar 2006 09:52:53 -0800
Subject: [Rd] R make install and demo(graphics) issue
Message-ID: <E153C65077E0034E97A981C6CE26F1BD04534403@ENTWMAIL1A.harrahs.org>

Simon,

    Thanks! That resolved the "make install" issue. However, after
installation when running "demo(graphics)" or "png()" from within R, I
get the following error:

  > demo(graphics)


        demo(graphics)
        ---- ~~~~~~~~

Type  <Return>   to start :

> require(graphics)
[1] TRUE

> require(datasets)
[1] TRUE

> if (dev.cur() <= 1) get(getOption("device"))()
Error in get(getOption("device"))() : X11 module cannot be loaded
In addition: Warning message:
unable to load shared library '/usr/local/R/lib/R/modules/R_X11.so':
  Could not load module /usr/local/R/lib/R/modules/R_X11.so.
        Dependent module /usr/java14/jre/bin/libjpeg.a(libjpeg.so.62)
could not be loaded.
        File /usr/java14/jre/bin/libjpeg.a is not an
          archive or the file could not be read properly.
System error: Exec format error
System error: Exec format error
Could not load module /usr/java14/jre/bin/libjpeg.a.
        Dependent module /usr/java14/jre/bin/libjpeg.a could not be
loaded.

> png()
Error in png() : X11 module cannot be loaded
In addition: Warning message:
unable to load shared library '/usr/local/R/lib/R/modules/R_X11.so':
  Could not load module /usr/local/R/lib/R/modules/R_X11.so.
        Dependent module /usr/java14/jre/bin/libjpeg.a(libjpeg.so.62)
could not be loaded.
        File /usr/java14/jre/bin/libjpeg.a is not an
          archive or the file could not be read properly.
System error: Exec format error
System error: Exec format error
Could not load module /usr/java14/jre/bin/libjpeg.a.
        Dependent module /usr/java14/jre/bin/libjpeg.a could not be
loaded.

I've checked and "/usr/java14/jre/bin/libjpeg.a" does exist.
ls -l /usr/java14/jre/bin/libjpeg.a
-r--r--r--   1 bin      bin          289503 Jan 19 2005
/usr/java14/jre/bin/libjpeg.a
file /usr/java14/jre/bin/libjpeg.a
/usr/java14/jre/bin/libjpeg.a: executable (RISC System/6000) or object
module not stripped

Any thoughts or suggestions would be greatly appreciated!

Matthew Beason

-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
Sent: Friday, March 17, 2006 4:52 PM
To: Matthew Beason
Cc: r-devel at r-project.org
Subject: Re: [Rd] R make install and demo(graphics) issue


On 17.3.2006, at 19:08, Matthew Beason wrote:

> I've successfully gotten R 2.2.1 to compile on AIX 5.2.
>
> However, when I run "make install", I receive the following message:
>
> /appl/perform/workspace/R-2.2.1
> [root at diablo][/appl/perform/workspace/R-2.2.1] make install
> /appl/perform/workspace/R-2.2.1/m4
> Target "install" is up to date.
> /appl/perform/workspace/R-2.2.1/tools
> Target "install" is up to date.
> /appl/perform/workspace/R-2.2.1/doc
> installing doc ...
> ../tools/install-sh: no destination specified.
> make: The error code from the last command is 1.
>

Chances are that this is related to an issue with some shells mentioned
here before - you can either use R-2.2.1 patched from SVN where it is
fixed, or alternatively edit configure at line 1913:
if test -z ${rdocdir}; then
into
if test -z "${rdocdir}"; then
and make the same modification to the subsequent two if statements as
well.

Cheers,
Simon


From gregor.gorjanc at gmail.com  Mon Mar 20 23:27:21 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Mon, 20 Mar 2006 23:27:21 +0100
Subject: [Rd] levels for list and data.frame
Message-ID: <441F2C49.8080703@gmail.com>

oops, this does not pass R CMD check. I will have to read manuals a bit
more.

...
* checking S3 generic/method consistency ... WARNING
levels:
  function(x, ...)
levels.list:
  function(x, drop)

levels:
  function(x, ...)
levels.data.frame:
  function(x, drop)
...

Anyway, I would like to ask what is the "opinion" about writing methods
for classes as list and data.frame. Methods for this might not be as
simple as for numeric, character, factor and it would be nice that there
would be some guidelines for at least:
- what should be the "general" output i.e. list or something else - I
understand that it is hard to say in advance, but a common policy might
not hurt
- what to do if a method for a list or data.frame can not be applied to
each entry/column


> Hello!
> 
> Does R core find the following pacth usefull - I created methods for
> levels for list and data.frame, which can be usefull to get a list of
> levels for entries in a list or columns in a data.frame. Patch is
> attached and shown bellow example
> 
> # Example
>> tmp <- list()
>> tmp$a <- factor(letters[1:10])
>> tmp$b <- factor(letters[5:14])
>> tmp$c <- 1:10
>> tmp1 <- as.data.frame(tmp)
>> tmp2 <- list()
>> tmp2$"1" <- tmp
>> tmp2$"2" <- tmp1
>> str(tmp2)
> List of 2
>  $ 1:List of 3
>   ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
>   ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
>   ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
>  $ 2:`data.frame':      10 obs. of  3 variables:
>   ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
>   ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
>   ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
> 
>> levels(tmp2)
> $"1"
> $"1"$a
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> 
> $"1"$b
>  [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
> 
> 
> $"2"
> $"2"$a
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> 
> $"2"$b
>  [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
> 
>> levels(tmp2, drop = FALSE)
> $"1"
> $"1"$a
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> 
> $"1"$b
>  [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
> 
> $"1"$c
> NULL
> 
> 
> $"2"
> $"2"$a
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> 
> $"2"$b
>  [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
> 
> $"2"$c
> NULL
> 
> ----------------------------------------------------------------------
> 
> $ svn diff factor.R
> Index: factor.R
> ===================================================================
> --- factor.R    (revision 37559)
> +++ factor.R    (working copy)
> @@ -25,7 +25,25 @@
>  ## Help old S users:
>  category <- function(...) .Defunct()
> 
> -levels <- function(x) attr(x, "levels")
> +levels <- function(x, ...) UseMethod("levels")
> +
> +levels.default <- function(x, ...) attr(x, "levels")
> +
> +levels.list <- function(x, drop = TRUE)
> +{
> +    tmp <- lapply(x, levels, drop = drop)
> +    if (drop) {
> +        tmp1 <- unlist(lapply(tmp, is.null))
> +        tmp <- tmp[!tmp1]
> +    }
> +    return(tmp)
> +}
> +
> +levels.data.frame <- function(x, ...)
> +{
> +    return(levels.list(x, ...))
> +}
> +
>  nlevels <- function(x) length(levels(x))
> 
>  "levels<-" <- function(x, value) UseMethod("levels<-")
> 

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From maechler at stat.math.ethz.ch  Tue Mar 21 10:17:35 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Mar 2006 10:17:35 +0100
Subject: [Rd] levels for list and data.frame
In-Reply-To: <441F2C49.8080703@gmail.com>
References: <441F2C49.8080703@gmail.com>
Message-ID: <17439.50351.172900.987055@stat.math.ethz.ch>

Hi Gregor,

before even considering methods for "list" and "data.frame",
can you explain why you think it is important for  levels() to
become a generic function at all?
For me, levels belong to factors (or then to contour plots, or
co-plots ) but exactly because level is a too generic word, it
seems to me to be problematic as a generic function.

How would describe the purpose of the levels() generic?

>>>>> "Gregor" == Gregor Gorjanc <gregor.gorjanc at gmail.com>
>>>>>     on Mon, 20 Mar 2006 23:27:21 +0100 writes:

    Gregor> oops, this does not pass R CMD check. I will have to read manuals a bit
    Gregor> more.

    Gregor> ...
    Gregor> * checking S3 generic/method consistency ... WARNING
    Gregor> levels:
    Gregor> function(x, ...)
    Gregor> levels.list:
    Gregor> function(x, drop)

    Gregor> levels:
    Gregor> function(x, ...)
    Gregor> levels.data.frame:
    Gregor> function(x, drop)
    Gregor> ...

    Gregor> Anyway, I would like to ask what is the "opinion" about writing methods
    Gregor> for classes as list and data.frame. Methods for this might not be as
    Gregor> simple as for numeric, character, factor and it would be nice that there
    Gregor> would be some guidelines for at least:
    Gregor> - what should be the "general" output i.e. list or something else - I
    Gregor> understand that it is hard to say in advance, but a common policy might
    Gregor> not hurt
    Gregor> - what to do if a method for a list or data.frame can not be applied to
    Gregor> each entry/column


    >> Hello!
    >> 
    >> Does R core find the following pacth usefull - I created methods for
    >> levels for list and data.frame, which can be usefull to get a list of
    >> levels for entries in a list or columns in a data.frame. Patch is
    >> attached and shown bellow example
    >> 
    >> # Example
    >>> tmp <- list()
    >>> tmp$a <- factor(letters[1:10])
    >>> tmp$b <- factor(letters[5:14])
    >>> tmp$c <- 1:10
    >>> tmp1 <- as.data.frame(tmp)
    >>> tmp2 <- list()
    >>> tmp2$"1" <- tmp
    >>> tmp2$"2" <- tmp1
    >>> str(tmp2)
    >> List of 2
    >> $ 1:List of 3
    >> ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
    >> ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
    >> ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
    >> $ 2:`data.frame':      10 obs. of  3 variables:
    >> ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
    >> ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
    >> ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
    >> 
    >>> levels(tmp2)
    >> $"1"
    >> $"1"$a
    >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
    >> 
    >> $"1"$b
    >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
    >> 
    >> 
    >> $"2"
    >> $"2"$a
    >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
    >> 
    >> $"2"$b
    >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
    >> 
    >>> levels(tmp2, drop = FALSE)
    >> $"1"
    >> $"1"$a
    >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
    >> 
    >> $"1"$b
    >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
    >> 
    >> $"1"$c
    >> NULL
    >> 
    >> 
    >> $"2"
    >> $"2"$a
    >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
    >> 
    >> $"2"$b
    >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
    >> 
    >> $"2"$c
    >> NULL
    >> 
    >> ----------------------------------------------------------------------
    >> 
    >> $ svn diff factor.R
    >> Index: factor.R
    >> ===================================================================
    >> --- factor.R    (revision 37559)
    >> +++ factor.R    (working copy)
    >> @@ -25,7 +25,25 @@
    >> ## Help old S users:
    >> category <- function(...) .Defunct()
    >> 
    >> -levels <- function(x) attr(x, "levels")
    >> +levels <- function(x, ...) UseMethod("levels")
    >> +
    >> +levels.default <- function(x, ...) attr(x, "levels")
    >> +
    >> +levels.list <- function(x, drop = TRUE)
    >> +{
    >> +    tmp <- lapply(x, levels, drop = drop)
    >> +    if (drop) {
    >> +        tmp1 <- unlist(lapply(tmp, is.null))
    >> +        tmp <- tmp[!tmp1]
    >> +    }
    >> +    return(tmp)
    >> +}
    >> +
    >> +levels.data.frame <- function(x, ...)
    >> +{
    >> +    return(levels.list(x, ...))
    >> +}
    >> +
    >> nlevels <- function(x) length(levels(x))
    >> 
    >> "levels<-" <- function(x, value) UseMethod("levels<-")
    >> 

    Gregor> -- 
    Gregor> Lep pozdrav / With regards,
    Gregor> Gregor Gorjanc

    Gregor> ----------------------------------------------------------------------
    Gregor> University of Ljubljana     PhD student
    Gregor> Biotechnical Faculty
    Gregor> Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
    Gregor> Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

    Gregor> SI-1230 Domzale             tel: +386 (0)1 72 17 861
    Gregor> Slovenia, Europe            fax: +386 (0)1 72 17 888

    Gregor> ----------------------------------------------------------------------
    Gregor> "One must learn by doing the thing; for though you think you know it,
    Gregor> you have no certainty until you try." Sophocles ~ 450 B.C.

    Gregor> ______________________________________________
    Gregor> R-devel at r-project.org mailing list
    Gregor> https://stat.ethz.ch/mailman/listinfo/r-devel


From marquardt.christian at gmail.com  Wed Mar 22 03:15:15 2006
From: marquardt.christian at gmail.com (marquardt.christian at gmail.com)
Date: Wed, 22 Mar 2006 03:15:15 +0100 (CET)
Subject: [Rd] Double complex with gcc and Intel v9 Fortran (PR#8699)
Message-ID: <20060322021515.3C40110DD4@slim.kubism.ku.dk>

Full_Name: Christian Marquardt
Version: 2.2.1
OS: Linux
Submission from: (NULL) (84.167.229.240)


Hello,

I believe this is a bug in the configuration / installation:

When configuring R-2.2.1 using the Intel v9 Fortran compiler as default Fortran
compiler and g++ as C++ compiler on a Suse 9.3 Linux, the configuration script
finds that the C and Fortran idea of double comples disagree.

I have tried to extract the test used for this from m4/R.m4 (a slightly modified
version of the two test files is added at the end). When compiling

   ifort -c ctest.f
   gcc -c cftest.c

and linking properly,

   ifort -nofor_main cftest.o ctest.o -o runme

running the executable gives the following output:

   ./runme
123.456000 14.710644
0.000000 -0.000006

To me, this inicates that the test should actually be passed successfully.

Unfortunately, I haven't quite understood how to rebuild the configure.ac etc
once R.m4 is changed; otherwise I would try to come up with a patch for R.m4.
But maybe someone else can fix this?

Many thanks,

  Christian.


----<ctest.f>------------------------------------
      subroutine cftest(x)
      complex*16 x(3)
      integer i

c a few tests of constructs that are sometimes missing
      if(x(1) .eq. x(1)) i = 0
      x(1) = x(1)*x(2) + x(3)
      end

----<cftest.c>------------------------------------
#include <math.h>
#define HAVE_F77_UNDERSCORE 1
#ifdef HAVE_F77_UNDERSCORE
# define F77_SYMBOL(x)   x ## _
#else
# define F77_SYMBOL(x)   x
#endif

typedef struct {
        double r;
        double i;
} Rcomplex;

extern void F77_SYMBOL(cftest)(Rcomplex *x);

int main () {
    Rcomplex z[3];

    z[0].r = 3.14159265;
    z[0].i = 2.172;
    z[1].i = 3.14159265;
    z[1].r = 2.172;
    z[2].r = 123.456;
    z[2].i = 0.123456;
    F77_SYMBOL(cftest)(z);
    printf("%f %f\n", z[0].r, z[0].i);
    printf("%f %f\n", z[0].r - 123.456, z[0].i - 14.71065);
    if(fabs(z[0].r - 123.456) < 1e-4 && fabs(z[0].i - 14.71065) < 1e-4)
        exit(0);
    else exit(1);
}


From cspark at clemson.edu  Wed Mar 22 05:52:13 2006
From: cspark at clemson.edu (cspark at clemson.edu)
Date: Wed, 22 Mar 2006 05:52:13 +0100 (CET)
Subject: [Rd] pbinom( ) function (PR#8700)
Message-ID: <20060322045213.AB440103EF@slim.kubism.ku.dk>

Full_Name: Chanseok Park
Version: R 2.2.1
OS: RedHat EL4
Submission from: (NULL) (130.127.112.89)



pbinom(any negative value, size, prob) should be zero. 
But I got the following results. 
I mean, if a negative value is close to zero, then pbinom() calculate
pbinom(0, size, prob). dbinom() also behaves similarly. 


> pbinom( -2.220446e-22, 3,.1)
[1] 0.729

> pbinom( -2.220446e-8, 3,.1)
[1] 0.729

> pbinom( -2.220446e-7, 3,.1)
[1] 0


From gregor.gorjanc at gmail.com  Wed Mar 22 08:50:02 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Wed, 22 Mar 2006 08:50:02 +0100
Subject: [Rd] [Fwd: Re:  levels for list and data.frame]
Message-ID: <442101AA.2080507@gmail.com>

I unintentionally missed to cc to r-devel.

-------- Original Message --------
Subject: Re: [Rd] levels for list and data.frame
Date: Tue, 21 Mar 2006 20:50:21 +0100
From: Gregor Gorjanc <gregor.gorjanc at gmail.com>
Reply-To: gregor.gorjanc at gmail.com
To: Martin Maechler <maechler at stat.math.ethz.ch>
References: <441F2C49.8080703 at gmail.com>
<17439.50351.172900.987055 at stat.math.ethz.ch>

Martin Maechler wrote:
> Hi Gregor,
> 
> before even considering methods for "list" and "data.frame",
> can you explain why you think it is important for  levels() to
> become a generic function at all?
> For me, levels belong to factors (or then to contour plots, or
> co-plots ) but exactly because level is a too generic word, it
> seems to me to be problematic as a generic function.
> 
> How would describe the purpose of the levels() generic?
> 

You are right. I was in situation where I wanted to get levels from all
entries (factors) of a list and considered to write a method for this
instead of always using lapply(). It went quite smoothly, if I skip R
CMD check error. After that I began to think and post a question to
R-devel. Perhaps levels is really to generic, however one can set levels
also for non-factors. Although, I agree that this is of no use. I was
also playing with levels<- and find it quite hard to do something
general and usable for lists and data.frame.

If we put levels aside, is there any opinion/policy about list,
data.frame methods? Just curiosity.

> 
>>>>>>"Gregor" == Gregor Gorjanc <gregor.gorjanc at gmail.com>
>>>>>>    on Mon, 20 Mar 2006 23:27:21 +0100 writes:
> 
> 
>     Gregor> oops, this does not pass R CMD check. I will have to read manuals a bit
>     Gregor> more.
> 
>     Gregor> ...
>     Gregor> * checking S3 generic/method consistency ... WARNING
>     Gregor> levels:
>     Gregor> function(x, ...)
>     Gregor> levels.list:
>     Gregor> function(x, drop)
> 
>     Gregor> levels:
>     Gregor> function(x, ...)
>     Gregor> levels.data.frame:
>     Gregor> function(x, drop)
>     Gregor> ...
> 
>     Gregor> Anyway, I would like to ask what is the "opinion" about writing methods
>     Gregor> for classes as list and data.frame. Methods for this might not be as
>     Gregor> simple as for numeric, character, factor and it would be nice that there
>     Gregor> would be some guidelines for at least:
>     Gregor> - what should be the "general" output i.e. list or something else - I
>     Gregor> understand that it is hard to say in advance, but a common policy might
>     Gregor> not hurt
>     Gregor> - what to do if a method for a list or data.frame can not be applied to
>     Gregor> each entry/column
> 
> 
>     >> Hello!
>     >> 
>     >> Does R core find the following pacth usefull - I created methods for
>     >> levels for list and data.frame, which can be usefull to get a list of
>     >> levels for entries in a list or columns in a data.frame. Patch is
>     >> attached and shown bellow example
>     >> 
>     >> # Example
>     >>> tmp <- list()
>     >>> tmp$a <- factor(letters[1:10])
>     >>> tmp$b <- factor(letters[5:14])
>     >>> tmp$c <- 1:10
>     >>> tmp1 <- as.data.frame(tmp)
>     >>> tmp2 <- list()
>     >>> tmp2$"1" <- tmp
>     >>> tmp2$"2" <- tmp1
>     >>> str(tmp2)
>     >> List of 2
>     >> $ 1:List of 3
>     >> ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
>     >> ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
>     >> ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
>     >> $ 2:`data.frame':      10 obs. of  3 variables:
>     >> ..$ a: Factor w/ 10 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10
>     >> ..$ b: Factor w/ 10 levels "e","f","g","h",..: 1 2 3 4 5 6 7 8 9 10
>     >> ..$ c: int [1:10] 1 2 3 4 5 6 7 8 9 10
>     >> 
>     >>> levels(tmp2)
>     >> $"1"
>     >> $"1"$a
>     >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
>     >> 
>     >> $"1"$b
>     >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
>     >> 
>     >> 
>     >> $"2"
>     >> $"2"$a
>     >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
>     >> 
>     >> $"2"$b
>     >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
>     >> 
>     >>> levels(tmp2, drop = FALSE)
>     >> $"1"
>     >> $"1"$a
>     >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
>     >> 
>     >> $"1"$b
>     >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
>     >> 
>     >> $"1"$c
>     >> NULL
>     >> 
>     >> 
>     >> $"2"
>     >> $"2"$a
>     >> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
>     >> 
>     >> $"2"$b
>     >> [1] "e" "f" "g" "h" "i" "j" "k" "l" "m" "n"
>     >> 
>     >> $"2"$c
>     >> NULL
>     >> 
>     >> ----------------------------------------------------------------------
>     >> 
>     >> $ svn diff factor.R
>     >> Index: factor.R
>     >> ===================================================================
>     >> --- factor.R    (revision 37559)
>     >> +++ factor.R    (working copy)
>     >> @@ -25,7 +25,25 @@
>     >> ## Help old S users:
>     >> category <- function(...) .Defunct()
>     >> 
>     >> -levels <- function(x) attr(x, "levels")
>     >> +levels <- function(x, ...) UseMethod("levels")
>     >> +
>     >> +levels.default <- function(x, ...) attr(x, "levels")
>     >> +
>     >> +levels.list <- function(x, drop = TRUE)
>     >> +{
>     >> +    tmp <- lapply(x, levels, drop = drop)
>     >> +    if (drop) {
>     >> +        tmp1 <- unlist(lapply(tmp, is.null))
>     >> +        tmp <- tmp[!tmp1]
>     >> +    }
>     >> +    return(tmp)
>     >> +}
>     >> +
>     >> +levels.data.frame <- function(x, ...)
>     >> +{
>     >> +    return(levels.list(x, ...))
>     >> +}
>     >> +
>     >> nlevels <- function(x) length(levels(x))
>     >> 
>     >> "levels<-" <- function(x, value) UseMethod("levels<-")
>     >> 
> 
>     Gregor> -- 
>     Gregor> Lep pozdrav / With regards,
>     Gregor> Gregor Gorjanc
> 
>     Gregor> ----------------------------------------------------------------------
>     Gregor> University of Ljubljana     PhD student
>     Gregor> Biotechnical Faculty
>     Gregor> Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
>     Gregor> Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si
> 
>     Gregor> SI-1230 Domzale             tel: +386 (0)1 72 17 861
>     Gregor> Slovenia, Europe            fax: +386 (0)1 72 17 888
> 
>     Gregor> ----------------------------------------------------------------------
>     Gregor> "One must learn by doing the thing; for though you think you know it,
>     Gregor> you have no certainty until you try." Sophocles ~ 450 B.C.
> 
>     Gregor> ______________________________________________
>     Gregor> R-devel at r-project.org mailing list
>     Gregor> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.
----------------------------------------------------------------------


-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From gregor.gorjanc at gmail.com  Wed Mar 22 08:52:13 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Wed, 22 Mar 2006 08:52:13 +0100
Subject: [Rd] levels for list and data.frame
In-Reply-To: <17440.65104.20685.13548@stat.math.ethz.ch>
References: <441F2C49.8080703@gmail.com>	<17439.50351.172900.987055@stat.math.ethz.ch>	<442058FD.4070406@gmail.com>
	<17440.65104.20685.13548@stat.math.ethz.ch>
Message-ID: <4421022D.1090106@gmail.com>

Martin Maechler wrote:
>>>>>>"Gregor" == Gregor Gorjanc <gregor.gorjanc at gmail.com>
>>>>>>    on Tue, 21 Mar 2006 20:50:21 +0100 writes:
> 
> 
>     Gregor> Martin Maechler wrote:
>     >> Hi Gregor,
>     >> 
>     >> before even considering methods for "list" and
>     >> "data.frame", can you explain why you think it is
>     >> important for levels() to become a generic function at
>     >> all?  For me, levels belong to factors (or then to
>     >> contour plots, or co-plots ) but exactly because level is
>     >> a too generic word, it seems to me to be problematic as a
>     >> generic function.
>     >> 
>     >> How would describe the purpose of the levels() generic?
>     >> 
> 
>     Gregor> You are right. I was in situation where I wanted to
>     Gregor> get levels from all entries (factors) of a list and
>     Gregor> considered to write a method for this instead of
>     Gregor> always using lapply(). It went quite smoothly, if I
>     Gregor> skip R CMD check error. After that I began to think
>     Gregor> and post a question to R-devel. Perhaps levels is
>     Gregor> really to generic, however one can set levels also
>     Gregor> for non-factors. Although, I agree that this is of
>     Gregor> no use. I was also playing with levels<- and find it
>     Gregor> quite hard to do something general and usable for
>     Gregor> lists and data.frame.
> 
>     Gregor> If we put levels aside, is there any opinion/policy
>     Gregor> about list, data.frame methods? Just curiosity.
> 
> I don't understand the question.  Do you mean the question if
> methods should be written for "list" or for "data.frame" (which
> inherit from "list")?

Yes.

> But in any case, can you please take this back to R-devel?
> It has started there, and people should be able to see the
> continuation / conclusion.
> 

Hmm, replay all to your mail does not include r-devel, weird. Done.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From maechler at stat.math.ethz.ch  Wed Mar 22 09:52:22 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 22 Mar 2006 09:52:22 +0100 (CET)
Subject: [Rd] pbinom( ) function (PR#8700)
Message-ID: <20060322085222.2E6CA41ED9@slim.kubism.ku.dk>

>>>>> "cspark" == cspark  <cspark at clemson.edu>
>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:

    cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
    cspark> EL4 Submission from: (NULL) (130.127.112.89)



    cspark> pbinom(any negative value, size, prob) should be
    cspark> zero.  But I got the following results.  I mean, if
    cspark> a negative value is close to zero, then pbinom()
    cspark> calculate pbinom(0, size, prob). 

    >> pbinom( -2.220446e-22, 3,.1)
    [1] 0.729
    >> pbinom( -2.220446e-8, 3,.1)
    [1] 0.729
    >> pbinom( -2.220446e-7, 3,.1)
    [1] 0

Yes, all the [dp]* functions which are discrete with mass on the
integers only, do *round* their 'x' to integers.

I could well argue that the current behavior is *not* a bug,
since we do treat "x close to integer" as integer, and hence 
   pbinom(eps, size, prob)  with  eps "very close to 0" should give
   pbinom(0,   size, prob)
as it now does.

However, for esthetical reasons, 
I agree that we should test for "< 0" first (and give 0 then) and only
round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
about a month).

    cspark> dbinom() also behaves similarly.

yes, similarly, but differently.
I have changed it (for R-devel) as well, to behave the same as
others d*() , e.g., dpois(), dnbinom() do.


Martin Maechler, ETH Zurich


From murdoch at stats.uwo.ca  Wed Mar 22 13:40:11 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Mar 2006 07:40:11 -0500
Subject: [Rd] pbinom( ) function (PR#8700)
In-Reply-To: <20060322085222.2E6CA41ED9@slim.kubism.ku.dk>
References: <20060322085222.2E6CA41ED9@slim.kubism.ku.dk>
Message-ID: <442145AB.8030708@stats.uwo.ca>

On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch wrote:
>>>>>> "cspark" == cspark  <cspark at clemson.edu>
>>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:
> 
>     cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
>     cspark> EL4 Submission from: (NULL) (130.127.112.89)
> 
> 
> 
>     cspark> pbinom(any negative value, size, prob) should be
>     cspark> zero.  But I got the following results.  I mean, if
>     cspark> a negative value is close to zero, then pbinom()
>     cspark> calculate pbinom(0, size, prob). 
> 
>     >> pbinom( -2.220446e-22, 3,.1)
>     [1] 0.729
>     >> pbinom( -2.220446e-8, 3,.1)
>     [1] 0.729
>     >> pbinom( -2.220446e-7, 3,.1)
>     [1] 0
> 
> Yes, all the [dp]* functions which are discrete with mass on the
> integers only, do *round* their 'x' to integers.
> 
> I could well argue that the current behavior is *not* a bug,
> since we do treat "x close to integer" as integer, and hence 
>    pbinom(eps, size, prob)  with  eps "very close to 0" should give
>    pbinom(0,   size, prob)
> as it now does.
> 
> However, for esthetical reasons, 
> I agree that we should test for "< 0" first (and give 0 then) and only
> round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
> about a month).
> 
>     cspark> dbinom() also behaves similarly.
> 
> yes, similarly, but differently.
> I have changed it (for R-devel) as well, to behave the same as
> others d*() , e.g., dpois(), dnbinom() do.

Martin, your description makes it sound as though dbinom(0.3, size, 
prob) would give the same answer as dbinom(0, size, prob), whereas it 
actually gives 0 with a warning, as documented in ?dbinom.  The d* 
functions only round near-integers to integers, where it looks as though 
near means within 1E-7.  The p* functions round near integers to 
integers, and truncate others to the integer below.

I suppose the reason for this behaviour is to protect against rounding 
error giving nonsense results; I'm not sure that's a great idea, but if 
we do it, should we really be handling 0 differently?

Duncan Murdoch


From maechler at stat.math.ethz.ch  Wed Mar 22 15:34:34 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 22 Mar 2006 15:34:34 +0100 (CET)
Subject: [Rd] pbinom( ) function (PR#8700)
Message-ID: <20060322143434.A728341ED5@slim.kubism.ku.dk>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Wed, 22 Mar 2006 07:40:11 -0500 writes:

    Duncan> On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch
    Duncan> wrote:
    >>>>>>> "cspark" == cspark <cspark at clemson.edu> on Wed, 22
    >>>>>>> Mar 2006 05:52:13 +0100 (CET) writes:
    >>
    cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
    cspark> EL4 Submission from: (NULL) (130.127.112.89)
    >>
    cspark> pbinom(any negative value, size, prob) should be
    cspark> zero.  But I got the following results.  I mean, if
    cspark> a negative value is close to zero, then pbinom()
    cspark> calculate pbinom(0, size, prob).
    >>  >> pbinom( -2.220446e-22, 3,.1) [1] 0.729 >> pbinom(
    >> -2.220446e-8, 3,.1) [1] 0.729 >> pbinom( -2.220446e-7,
    >> 3,.1) [1] 0
    >> 
    >> Yes, all the [dp]* functions which are discrete with mass
    >> on the integers only, do *round* their 'x' to integers.
    >> 
    >> I could well argue that the current behavior is *not* a
    >> bug, since we do treat "x close to integer" as integer,
    >> and hence pbinom(eps, size, prob) with eps "very close to
    >> 0" should give pbinom(0, size, prob) as it now does.
    >> 
    >> However, for esthetical reasons, I agree that we should
    >> test for "< 0" first (and give 0 then) and only round
    >> otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
    >> about a month).
    >> 
    cspark> dbinom() also behaves similarly.
    >>  yes, similarly, but differently.  I have changed it (for
    >> R-devel) as well, to behave the same as others d*() ,
    >> e.g., dpois(), dnbinom() do.

    Duncan> Martin, your description makes it sound as though
    Duncan> dbinom(0.3, size, prob) would give the same answer
    Duncan> as dbinom(0, size, prob), whereas it actually gives
    Duncan> 0 with a warning, as documented in ?dbinom.  The d*
    Duncan> functions only round near-integers to integers,
    Duncan> where it looks as though near means within 1E-7.

That's correct. Above, I did not describe what happens for the d*()
functions but said that dbinom() behaves differently than
pbinom and that I have changed dbinom() to behave similarly to
dnbinom(), dgeom(),....

    Duncan> The p* functions round near integers to integers,
    Duncan> and truncate others to the integer below.

    Duncan> I suppose the reason for this behaviour is to
    Duncan> protect against rounding error giving nonsense
    Duncan> results; I'm not sure that's a great idea, 

I agree that it may not seem such a great idea; but that has
been discussed and decided (IIRC against my preference) quite a
while ago, and I don't think it is worthwhile to rediscuss such
relatively fundamental behavior every few years..

    Duncan> but if we do it, should we really be handling 0
    Duncan> differently?

yes:
- only around 0, small absolute deviations are large relative deviations

- 0 is the left border of the function's domain, where one would expect
  strict mathematical behavior more strongly.

Martin Maechler


From p.dalgaard at biostat.ku.dk  Wed Mar 22 16:08:49 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Wed, 22 Mar 2006 16:08:49 +0100 (CET)
Subject: [Rd] pbinom( ) function (PR#8700)
Message-ID: <20060322150849.54D7541EC9@slim.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch wrote:
> >>>>>> "cspark" == cspark  <cspark at clemson.edu>
> >>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:
> > 
> >     cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
> >     cspark> EL4 Submission from: (NULL) (130.127.112.89)
> > 
> > 
> > 
> >     cspark> pbinom(any negative value, size, prob) should be
> >     cspark> zero.  But I got the following results.  I mean, if
> >     cspark> a negative value is close to zero, then pbinom()
> >     cspark> calculate pbinom(0, size, prob). 
> > 
> >     >> pbinom( -2.220446e-22, 3,.1)
> >     [1] 0.729
> >     >> pbinom( -2.220446e-8, 3,.1)
> >     [1] 0.729
> >     >> pbinom( -2.220446e-7, 3,.1)
> >     [1] 0
> > 
> > Yes, all the [dp]* functions which are discrete with mass on the
> > integers only, do *round* their 'x' to integers.
> > 
> > I could well argue that the current behavior is *not* a bug,
> > since we do treat "x close to integer" as integer, and hence 
> >    pbinom(eps, size, prob)  with  eps "very close to 0" should give
> >    pbinom(0,   size, prob)
> > as it now does.
> > 
> > However, for esthetical reasons, 
> > I agree that we should test for "< 0" first (and give 0 then) and only
> > round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
> > about a month).
> > 
> >     cspark> dbinom() also behaves similarly.
> > 
> > yes, similarly, but differently.
> > I have changed it (for R-devel) as well, to behave the same as
> > others d*() , e.g., dpois(), dnbinom() do.
> 
> Martin, your description makes it sound as though dbinom(0.3, size, 
> prob) would give the same answer as dbinom(0, size, prob), whereas it 
> actually gives 0 with a warning, as documented in ?dbinom.  The d* 
> functions only round near-integers to integers, where it looks as though 
> near means within 1E-7.  The p* functions round near integers to 
> integers, and truncate others to the integer below.

Well, the p-functions are constant on the intervals between
integers... (Or, did you refer to the lack of a warning? One point
could be that cumulative p.d.f.s extends naturally to non-integers,
whereas densities don't really extend, since they are defined with
respect to counting measure on the integers.)
 
> I suppose the reason for this behaviour is to protect against rounding 
> error giving nonsense results; I'm not sure that's a great idea, but if 
> we do it, should we really be handling 0 differently?

Most of these round-near-integer issues were spurred by real
programming problems. It is somewhat hard to come up with a problem
that leads you generate a binomial variate value with "floating point
noise", but I'm quite sure that we'll be reminded if we try to change
it... (One potential issue is back-calculation to counts from relative
frequencies).


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Wed Mar 22 16:08:41 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Mar 2006 16:08:41 +0100
Subject: [Rd] pbinom( ) function (PR#8700)
In-Reply-To: <442145AB.8030708@stats.uwo.ca>
References: <20060322085222.2E6CA41ED9@slim.kubism.ku.dk>
	<442145AB.8030708@stats.uwo.ca>
Message-ID: <x2pske7c06.fsf@viggo.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch wrote:
> >>>>>> "cspark" == cspark  <cspark at clemson.edu>
> >>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:
> > 
> >     cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
> >     cspark> EL4 Submission from: (NULL) (130.127.112.89)
> > 
> > 
> > 
> >     cspark> pbinom(any negative value, size, prob) should be
> >     cspark> zero.  But I got the following results.  I mean, if
> >     cspark> a negative value is close to zero, then pbinom()
> >     cspark> calculate pbinom(0, size, prob). 
> > 
> >     >> pbinom( -2.220446e-22, 3,.1)
> >     [1] 0.729
> >     >> pbinom( -2.220446e-8, 3,.1)
> >     [1] 0.729
> >     >> pbinom( -2.220446e-7, 3,.1)
> >     [1] 0
> > 
> > Yes, all the [dp]* functions which are discrete with mass on the
> > integers only, do *round* their 'x' to integers.
> > 
> > I could well argue that the current behavior is *not* a bug,
> > since we do treat "x close to integer" as integer, and hence 
> >    pbinom(eps, size, prob)  with  eps "very close to 0" should give
> >    pbinom(0,   size, prob)
> > as it now does.
> > 
> > However, for esthetical reasons, 
> > I agree that we should test for "< 0" first (and give 0 then) and only
> > round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
> > about a month).
> > 
> >     cspark> dbinom() also behaves similarly.
> > 
> > yes, similarly, but differently.
> > I have changed it (for R-devel) as well, to behave the same as
> > others d*() , e.g., dpois(), dnbinom() do.
> 
> Martin, your description makes it sound as though dbinom(0.3, size, 
> prob) would give the same answer as dbinom(0, size, prob), whereas it 
> actually gives 0 with a warning, as documented in ?dbinom.  The d* 
> functions only round near-integers to integers, where it looks as though 
> near means within 1E-7.  The p* functions round near integers to 
> integers, and truncate others to the integer below.

Well, the p-functions are constant on the intervals between
integers... (Or, did you refer to the lack of a warning? One point
could be that cumulative p.d.f.s extends naturally to non-integers,
whereas densities don't really extend, since they are defined with
respect to counting measure on the integers.)
 
> I suppose the reason for this behaviour is to protect against rounding 
> error giving nonsense results; I'm not sure that's a great idea, but if 
> we do it, should we really be handling 0 differently?

Most of these round-near-integer issues were spurred by real
programming problems. It is somewhat hard to come up with a problem
that leads you generate a binomial variate value with "floating point
noise", but I'm quite sure that we'll be reminded if we try to change
it... (One potential issue is back-calculation to counts from relative
frequencies).


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From anthony.brooks at csc.mrc.ac.uk  Wed Mar 22 17:06:08 2006
From: anthony.brooks at csc.mrc.ac.uk (Brooks, Anthony B)
Date: Wed, 22 Mar 2006 16:06:08 -0000
Subject: [Rd] Choose.files to give shortnames
Message-ID: <A9890059664CAD468E43D67208E576C76BDEAF@icex5.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060322/2b019324/attachment.pl 

From murdoch at stats.uwo.ca  Wed Mar 22 17:38:52 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Mar 2006 11:38:52 -0500
Subject: [Rd] pbinom( ) function (PR#8700)
In-Reply-To: <x2pske7c06.fsf@viggo.kubism.ku.dk>
References: <20060322085222.2E6CA41ED9@slim.kubism.ku.dk>	<442145AB.8030708@stats.uwo.ca>
	<x2pske7c06.fsf@viggo.kubism.ku.dk>
Message-ID: <44217D9C.7060003@stats.uwo.ca>

On 3/22/2006 10:08 AM, Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
>> On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch wrote:
>> >>>>>> "cspark" == cspark  <cspark at clemson.edu>
>> >>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:
>> > 
>> >     cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
>> >     cspark> EL4 Submission from: (NULL) (130.127.112.89)
>> > 
>> > 
>> > 
>> >     cspark> pbinom(any negative value, size, prob) should be
>> >     cspark> zero.  But I got the following results.  I mean, if
>> >     cspark> a negative value is close to zero, then pbinom()
>> >     cspark> calculate pbinom(0, size, prob). 
>> > 
>> >     >> pbinom( -2.220446e-22, 3,.1)
>> >     [1] 0.729
>> >     >> pbinom( -2.220446e-8, 3,.1)
>> >     [1] 0.729
>> >     >> pbinom( -2.220446e-7, 3,.1)
>> >     [1] 0
>> > 
>> > Yes, all the [dp]* functions which are discrete with mass on the
>> > integers only, do *round* their 'x' to integers.
>> > 
>> > I could well argue that the current behavior is *not* a bug,
>> > since we do treat "x close to integer" as integer, and hence 
>> >    pbinom(eps, size, prob)  with  eps "very close to 0" should give
>> >    pbinom(0,   size, prob)
>> > as it now does.
>> > 
>> > However, for esthetical reasons, 
>> > I agree that we should test for "< 0" first (and give 0 then) and only
>> > round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
>> > about a month).
>> > 
>> >     cspark> dbinom() also behaves similarly.
>> > 
>> > yes, similarly, but differently.
>> > I have changed it (for R-devel) as well, to behave the same as
>> > others d*() , e.g., dpois(), dnbinom() do.
>> 
>> Martin, your description makes it sound as though dbinom(0.3, size, 
>> prob) would give the same answer as dbinom(0, size, prob), whereas it 
>> actually gives 0 with a warning, as documented in ?dbinom.  The d* 
>> functions only round near-integers to integers, where it looks as though 
>> near means within 1E-7.  The p* functions round near integers to 
>> integers, and truncate others to the integer below.
> 
> Well, the p-functions are constant on the intervals between
> integers... 

Not quite:  they're constant on intervals (n - 1e-7, n+1 - 1e-7), for 
integers n.  Since Martin's change, this is not true for n=0.

(Or, did you refer to the lack of a warning? One point
> could be that cumulative p.d.f.s extends naturally to non-integers,
> whereas densities don't really extend, since they are defined with
> respect to counting measure on the integers.)

I wasn't complaining about the behaviour here, I was just clarifying 
Martin's description of it, when he said that "all the [dp]* functions 
which are discrete with mass on the integers only, do *round* their 'x' 
to integers".

>  
>> I suppose the reason for this behaviour is to protect against rounding 
>> error giving nonsense results; I'm not sure that's a great idea, but if 
>> we do it, should we really be handling 0 differently?
> 
> Most of these round-near-integer issues were spurred by real
> programming problems. It is somewhat hard to come up with a problem
> that leads you generate a binomial variate value with "floating point
> noise", but I'm quite sure that we'll be reminded if we try to change
> it... (One potential issue is back-calculation to counts from relative
> frequencies).

Again, I wasn't suggesting we change the general +/- 1E-7 behaviour 
(though it should be documented to avoid bug reports like this one), but 
I'm worried about having zero as a special case.  This will break 
relations such as

  dbinom(x, n, 0.5) == dbinom(n-x, n, 0.5)

(in the case where x is n+epsilon or -epsilon, for small enough 
epsilon).  Is it really desirable to break the symmetry like this?

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed Mar 22 17:39:03 2006
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Wed, 22 Mar 2006 17:39:03 +0100 (CET)
Subject: [Rd] pbinom( ) function (PR#8700)
Message-ID: <20060322163903.DE0B140AB9@slim.kubism.ku.dk>

On 3/22/2006 10:08 AM, Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
>> On 3/22/2006 3:52 AM, maechler at stat.math.ethz.ch wrote:
>> >>>>>> "cspark" == cspark  <cspark at clemson.edu>
>> >>>>>>     on Wed, 22 Mar 2006 05:52:13 +0100 (CET) writes:
>> > 
>> >     cspark> Full_Name: Chanseok Park Version: R 2.2.1 OS: RedHat
>> >     cspark> EL4 Submission from: (NULL) (130.127.112.89)
>> > 
>> > 
>> > 
>> >     cspark> pbinom(any negative value, size, prob) should be
>> >     cspark> zero.  But I got the following results.  I mean, if
>> >     cspark> a negative value is close to zero, then pbinom()
>> >     cspark> calculate pbinom(0, size, prob). 
>> > 
>> >     >> pbinom( -2.220446e-22, 3,.1)
>> >     [1] 0.729
>> >     >> pbinom( -2.220446e-8, 3,.1)
>> >     [1] 0.729
>> >     >> pbinom( -2.220446e-7, 3,.1)
>> >     [1] 0
>> > 
>> > Yes, all the [dp]* functions which are discrete with mass on the
>> > integers only, do *round* their 'x' to integers.
>> > 
>> > I could well argue that the current behavior is *not* a bug,
>> > since we do treat "x close to integer" as integer, and hence 
>> >    pbinom(eps, size, prob)  with  eps "very close to 0" should give
>> >    pbinom(0,   size, prob)
>> > as it now does.
>> > 
>> > However, for esthetical reasons, 
>> > I agree that we should test for "< 0" first (and give 0 then) and only
>> > round otherwise.  I'll change this for R-devel (i.e. R 2.3.0 in
>> > about a month).
>> > 
>> >     cspark> dbinom() also behaves similarly.
>> > 
>> > yes, similarly, but differently.
>> > I have changed it (for R-devel) as well, to behave the same as
>> > others d*() , e.g., dpois(), dnbinom() do.
>> 
>> Martin, your description makes it sound as though dbinom(0.3, size, 
>> prob) would give the same answer as dbinom(0, size, prob), whereas it 
>> actually gives 0 with a warning, as documented in ?dbinom.  The d* 
>> functions only round near-integers to integers, where it looks as though 
>> near means within 1E-7.  The p* functions round near integers to 
>> integers, and truncate others to the integer below.
> 
> Well, the p-functions are constant on the intervals between
> integers... 

Not quite:  they're constant on intervals (n - 1e-7, n+1 - 1e-7), for 
integers n.  Since Martin's change, this is not true for n=0.

(Or, did you refer to the lack of a warning? One point
> could be that cumulative p.d.f.s extends naturally to non-integers,
> whereas densities don't really extend, since they are defined with
> respect to counting measure on the integers.)

I wasn't complaining about the behaviour here, I was just clarifying 
Martin's description of it, when he said that "all the [dp]* functions 
which are discrete with mass on the integers only, do *round* their 'x' 
to integers".

>  
>> I suppose the reason for this behaviour is to protect against rounding 
>> error giving nonsense results; I'm not sure that's a great idea, but if 
>> we do it, should we really be handling 0 differently?
> 
> Most of these round-near-integer issues were spurred by real
> programming problems. It is somewhat hard to come up with a problem
> that leads you generate a binomial variate value with "floating point
> noise", but I'm quite sure that we'll be reminded if we try to change
> it... (One potential issue is back-calculation to counts from relative
> frequencies).

Again, I wasn't suggesting we change the general +/- 1E-7 behaviour 
(though it should be documented to avoid bug reports like this one), but 
I'm worried about having zero as a special case.  This will break 
relations such as

  dbinom(x, n, 0.5) == dbinom(n-x, n, 0.5)

(in the case where x is n+epsilon or -epsilon, for small enough 
epsilon).  Is it really desirable to break the symmetry like this?

Duncan Murdoch


From ehlers at math.ucalgary.ca  Wed Mar 22 18:48:28 2006
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Wed, 22 Mar 2006 10:48:28 -0700
Subject: [Rd] Choose.files to give shortnames
In-Reply-To: <A9890059664CAD468E43D67208E576C76BDEAF@icex5.ic.ac.uk>
References: <A9890059664CAD468E43D67208E576C76BDEAF@icex5.ic.ac.uk>
Message-ID: <44218DEC.5090408@math.ucalgary.ca>

Would

basename(choose.files())

work for your usage?
Still, a full.names argument might be useful.

Peter Ehlers

Brooks, Anthony B wrote:

> Hi
> I am writing a script to generate a QC report for some data based on a number of files. I am currently using the choose.files function to select the files as not all the files need to be QC'd. One minor issue is that choose.files returns the complete path of the filename (eg "C:/QCdata/Test1/File01", "C:/QCdata/Test1/File02"...). Is it possible to use choose.files to return just the file name eg("File01", "File02"...), in a way similar to the full.names=FALSE argument in the dir function.
> 
> Thanks
> Tony
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From phgrosjean at sciviews.org  Thu Mar 23 08:35:53 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 23 Mar 2006 08:35:53 +0100
Subject: [Rd] Choose.files to give shortnames
Message-ID: <44224FD9.6040605@sciviews.org>

Brooks, Anthony B wrote:

 > Hi
 > I am writing a script to generate a QC report for some data based on 
a number of files. I am currently using the choose.files function to 
select the files as not all the files need to be QC'd. One minor issue 
is that choose.files returns the complete path of the filename (eg 
"C:/QCdata/Test1/File01", "C:/QCdata/Test1/File02"...). Is it possible 
to use choose.files to return just the file name eg("File01", 
"File02"...), in a way similar to the full.names=FALSE argument in the 
dir function.
 >
 > Thanks
 > Tony


 > basename(choose.files())

Best,

Philippe Grosjean


From feihuacompany at netscape.net  Thu Mar 23 18:37:47 2006
From: feihuacompany at netscape.net (feihuacompany at netscape.net)
Date: Thu, 23 Mar 2006 18:37:47 +0100 (CET)
Subject: [Rd] Company Representative Needed, (PR#8704)
Message-ID: <20060323173747.1C9E5F91B@slim.kubism.ku.dk>

--qzsoft_directmail_seperator
Content-Type: text/plain;
	charset="DEFAULT"
Content-Transfer-Encoding: base64

MjdoIEJhbyBGZW5nIE1hbnNpb24sCjI5OSBKaW5namlhbmcgUm9hZCwKU2hhbmdoYWkgQ2hpbmEu
Cmh0dHA6Ly93d3cuZmgyMS5jb20uY24KCkRlYXIgU2lyL01hZGFtLAogV2UgYXJlIGNvLW9wZXJh
dGlvbiB3aG8gZGVhbCBvbiByYXcgbWF0ZXJpYWxzIGFuZCBleHBvcnQgaW50bwphbWVyaWNhL2V1
cm9wZS4gV2UgYXJlIHNlYXJjaGluZyBmb3IgcmVwcmVzZW50YXRpdmVzIHdobyBjYW4gaGVscCB1
cwplc3RhYmxpc2ggYSBtZWRpdW0gb2YgZ2V0dGluZyB0byBvdXIgY3VzdHVtZXJzIGluIEFtZXJp
Y2EgYW5kIEV1cm9wZSBhcwp3ZWxsIGFzIG1ha2luZyBwYXltZW50cyB0aHJvdWdoIHlvdSB0byB1
cy5JIHdpbGwgYWxzbyBsaWtlIHRvIG5vdGUgaGVyZQp0aGF0IGFjdGluZyBhcyBteSBwYXltZW50
IGFnZW50IGluIHlvdXIgY291bnRyeSBpbiBvdGhlciB3b3Jkcyx5b3Ugd2lsbAogYmUgY29sbGVj
dGluZyBwYXltZW50IGZyb20gY3VzdG9tZXJzIGkgc3VwcGx5IGdvb2RzIHRvLgpCeSBkb2luZyB0
aGlzIG9uIG15IGJlaGFsZiB5b3Ugd2lsbCBiZSBwYWlkIDEwJSBvZiB2ZXJ5IGFtb3VudCB0aGF0
IHlvdQpjb2xsZWN0LgogUGxlYXNlIGlmIHlvdSBhcmUgaW50ZXJlc3RlZCBpbiAgdHJhbnNhY3Rp
bmcgYnVzaW5lc3Mgd2l0aCB1cyB3ZSB3aWxsCmJlIHZlcnkgZ2xhZCxwbGVhc2UgY29udGFjdCB1
cyBmb3IgIG1vcmUgaW5mb3JtYXRpb24uIFN1YmplY3QgdG8geW91cgpzYXRpc2ZhY3Rpb24geW91
IHdpbGwgYmUgZ2l2ZW4gdGhlIG9wcG9ydHVuaXR5IHRvIG5lZ290aWF0ZSB5b3VyIG1vZGUgb2YK
d2hpY2ggd2Ugd2lsbApwYXkgZm9yIHlvdXIgc2VydmljZXMgYXMgb3VyIHJlcHJlc2VudGF0aXZl
IGluIEFtZXJpY2EvRXVyb3BlLiBQbGVhc2UgaWYgeW91CmFyZQppbnRlcmVzdGVkIGtpbmRseSBy
ZXBseSBiYWNrIHRvIHVzIGFzIHNvb24gYXMgcG9zc2libGUsd2l0aCB0aGUgZW1haWwgYmVsb3cu
ClRoYW5rIHlvdSwKTXIgS2ltIFlvdW5nLihDLkUuTykKRmVpaHVhIG9yZ2FuaXNhdGlvbi5DaGlu
YQoKZmVpaHVhY29tcGFueUBuZXRzY2FwZS5uZXQKCg==

--qzsoft_directmail_seperator--


From roebuck at mdanderson.org  Thu Mar 23 19:02:28 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Thu, 23 Mar 2006 12:02:28 -0600 (CST)
Subject: [Rd] diag manpage quibble
Message-ID: <Pine.OSF.4.58.0603231155270.48960@wotan.mdacc.tmc.edu>

R-2.2.1/src/library/base/R/man/diag.Rd
--------------------------------------

-diag(x = 1, nrow, ncol= )
+diag(x = 1, nrow, ncol = n)

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From kcarter at cyllene.uwa.edu.au  Fri Mar 24 09:27:49 2006
From: kcarter at cyllene.uwa.edu.au (Kim Carter)
Date: Fri, 24 Mar 2006 16:27:49 +0800
Subject: [Rd] R and sun gridengine
Message-ID: <200603241627.49655.kcarter@cyllene.uwa.edu.au>

Hi

I am looking for assistance with setting up R under Sun grid engine 6
(6.0-update7). I would like to set up transparent interactive access
to R using either a qlogin or qrsh solution. While it basically works
using either method, I reach the same sticking point.  There seems
to be an issue with signalling or something, as R works ok until a 
non-R command is typed in - eg "blah" - at which point the remote
session is terminated (note: i am using ssh as an rsh/rlogin replacement).

If anyone has any suggestions or can point me in the  right direction,
it would be greatly appreciated.

Kim Carter


--


From antonio.fabio at gmail.com  Fri Mar 24 11:03:56 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 24 Mar 2006 11:03:56 +0100
Subject: [Rd] bug in plot.acf
Message-ID: <b0808fdc0603240203u76062eb9y@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060324/e0b98e77/attachment.pl 

From hin-tak.leung at cimr.cam.ac.uk  Fri Mar 24 12:10:09 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 24 Mar 2006 11:10:09 +0000
Subject: [Rd] sub returns garbage (PR#8687)
In-Reply-To: <x2fylh33wz.fsf@turmalin.kubism.ku.dk>
References: <20060316212802.D4E51C976@slim.kubism.ku.dk>	<x2d5gmukv8.fsf@turmalin.kubism.ku.dk>
	<x2fylh33wz.fsf@turmalin.kubism.ku.dk>
Message-ID: <4423D391.9010601@cimr.cam.ac.uk>

Peter Dalgaard wrote:
<snipped>
> I claim XP braindamage -- I'm not Linuxifying my new ThinkPad until
> FC5 is out.
>

Rather irrelevant, I have been running FC5 since Tuesday
afternoon.

$ cat /etc/fedora-release
Fedora Core release 5 (Bordeaux)

FC5 came out on Monday. You should have linuxifying your thinkpad
by now :-) ? Just checking...

HTL


From p.dalgaard at biostat.ku.dk  Fri Mar 24 13:45:49 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Mar 2006 13:45:49 +0100
Subject: [Rd] sub returns garbage (PR#8687)
In-Reply-To: <4423D391.9010601@cimr.cam.ac.uk>
References: <20060316212802.D4E51C976@slim.kubism.ku.dk>
	<x2d5gmukv8.fsf@turmalin.kubism.ku.dk>
	<x2fylh33wz.fsf@turmalin.kubism.ku.dk>
	<4423D391.9010601@cimr.cam.ac.uk>
Message-ID: <x2odzw57uq.fsf@viggo.kubism.ku.dk>

Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk> writes:

> Peter Dalgaard wrote:
> <snipped>
> > I claim XP braindamage -- I'm not Linuxifying my new ThinkPad until
> > FC5 is out.
> >
> 
> Rather irrelevant, I have been running FC5 since Tuesday
> afternoon.
> 
> $ cat /etc/fedora-release
> Fedora Core release 5 (Bordeaux)
> 
> FC5 came out on Monday. You should have linuxifying your thinkpad
> by now :-) ? Just checking...

A few other things are on my mind these days... 

I'll get there, though. I've gotten XP the point where it allows me to
do all the usual evasions: Web browsing, login & check mail via putty,
Minesweep, WinAmp, but none of the productive work like debugging,
compiling, editing presentations, etc.

(I'm sure there are ways to get all the other stuff working too, but
overall, I was surprised at how much of the futzing you need to do
customize a Linux box, you actually *also* need to do on XP, and I
haven't even started on the hairy bits.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Fri Mar 24 13:55:03 2006
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Fri, 24 Mar 2006 13:55:03 +0100 (CET)
Subject: [Rd] bug in plot.acf (PR#8705)
Message-ID: <20060324125503.E098B183A3@slim.kubism.ku.dk>

(Moved from r-devel to r-bugs)

On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
> Hi all.
> There's a bug in plot.acf, when plotting acf for multivariate time series.
> Here a reproducible example:
> 
> X <- rnorm(1000)
> Y <- -X + rnorm(1000, sd=0.6)
> Z <- cbind(X,Y)
> 
> In
> acf(Z)
> cross-correlation plot y-axis is limited to 0-1. But:
> acf(Z, ylim=c(-1,1))
> shows that there was a negative correlation, that was cut away in the
> previous plot.
> 
> I've seen the error is trivial. There's something like:
> 
> for(each pair of univariate time series) {
> if(is.null(ylim)) {
> ...#set ylim properly
> }
> ...
> }
> 
> in plot.acf code, so that in the first iteration the ylim par is properly
> set to about c(0,1), but in
> subsequent interations, ylim is no more NULL, and the old, unproper ylim
> specification
> remains.

Thanks for noticing this.  It's easy to fix, but before I do, I'd like 
an opinion on the proper fix.  Should all the plots use the same ylim, 
or in the case where it is unspecified, should they each choose their 
own?  I can see arguments for both possibilities.

Duncan Murdoch


> 
> Antonio, Fabio Di Narzo.
> 
> P.S. Sorry for not indicating exact source lines, but from this PC I don't
> have access to
> R sources...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri Mar 24 14:04:18 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Mar 2006 08:04:18 -0500
Subject: [Rd] [R] RGui: windows-record and command history
In-Reply-To: <442348BC.3080707@stat.auckland.ac.nz>
References: <d0f55a670603230435t6a4b7a59h@mail.gmail.com>		<4422A744.50209@stats.uwo.ca>		<971536df0603230729t4828a082o26f5905b50226250@mail.gmail.com>		<4422C1A3.5050509@stats.uwo.ca>	<971536df0603230746r1ef31624qea7ffb5e8f015c67@mail.gmail.com>	<4422DCED.9040005@stats.uwo.ca>	<4422FA3F.5060001@stat.auckland.ac.nz>	<4423424F.20407@math.ucalgary.ca>
	<442348BC.3080707@stat.auckland.ac.nz>
Message-ID: <4423EE52.2020104@stats.uwo.ca>

I've moved this from r-help to r-devel.

On 3/23/2006 8:17 PM, Paul Murrell wrote:

>> 
>> Paul,
>> If I read your comments correctly, the problem with manipulating the
>> graph history is with saved histories across sessions/versions. Is
>> there any reason not to manipulate it *within* a session? I never
>> save plots for re-use in R. Re-running code is usually best for me.
>> But I would find it handy to fiddle with the display list in a
>> session.
> 
> 
> That is *one* problem with the display list.  Messing directly with the 
> display list *within a session* is *less* dangerous, but R's behaviour 
> if you do that is "undefined".
> 
> The display list is technically an internal structure for R's internal 
> use.  We can't stop you playing with it, but I do not encourage it and 
> it is not officially supported.
> 
> There are a number of simple things that you could do to the display 
> list that should work, but providing proper support for general 
> manipulations of the display list would require a significant amount of 
> (re)design of the R graphics code.
> 
> Paul
> 
> p.s.  These comments apply to the display list in R's "graphics engine". 
>   The 'grid' package also maintains a display list, and that has been 
> designed to support more general manipulations.

Are we talking about the same thing?  I think Peter is only thinking of 
manipulating the .SavedPlots variable, which is a Windows-only object 
holding plot history.  I imagine the entries in .SavedPlots[[5]] are the 
things that you are worried about, and I agree people shouldn't play 
with those, they should be using grid instead with its documented interface.

If we do warn people off manipulating .SavedPlots, then I think it 
should be a higher priority to implement some manipulations ourselves, 
e.g. "[<-.SavedPlots", to allow entries to be moved around or deleted in 
the list.

Duncan


From michael.dondrup at cebitec.uni-bielefeld.de  Fri Mar 24 14:11:02 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Fri, 24 Mar 2006 14:11:02 +0100
Subject: [Rd] R and sun gridengine
In-Reply-To: <200603241627.49655.kcarter@cyllene.uwa.edu.au>
References: <200603241627.49655.kcarter@cyllene.uwa.edu.au>
Message-ID: <4423EFE6.702@cebitec.uni-bielefeld.de>

Kim Carter wrote:
> Hi
> 
> I am looking for assistance with setting up R under Sun grid engine 6
> (6.0-update7). I would like to set up transparent interactive access
> to R using either a qlogin or qrsh solution. While it basically works
> using either method, I reach the same sticking point.  There seems
> to be an issue with signalling or something, as R works ok until a 
> non-R command is typed in - eg "blah" - at which point the remote
> session is terminated (note: i am using ssh as an rsh/rlogin replacement).
> 
> If anyone has any suggestions or can point me in the  right direction,
> it would be greatly appreciated.
> 
> Kim Carter
> 
> 
> --
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

Are you trying something like
'qrsh R' ? Then the reason might be a missing tty and R goes to 
batch-mode, like:

bagheera:~>qrsh tty
not a tty

but:

bagheera:~>qrsh
Last login: Fri Mar 24 14:02:47 from bagheera.CeBiTe
morpheus:~> tty
/dev/pts/3

If you supply a command to qrsh, you will not have a terminal.

I think there is no switch to force R into interactive mode,like for 
example for 'bash -i'. I found: 
http://www.r-project.org/nocvs/mail/r-help/2002/8927.html
but have not checked if it still works.

Maybe this helps
Michael








--


From maechler at stat.math.ethz.ch  Fri Mar 24 14:53:05 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri, 24 Mar 2006 14:53:05 +0100 (CET)
Subject: [Rd] bug in plot.acf (PR#8705)
Message-ID: <20060324135305.569EF41EB2@slim.kubism.ku.dk>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Fri, 24 Mar 2006 13:55:03 +0100 (CET) writes:

    Duncan> (Moved from r-devel to r-bugs)
    Duncan> On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
    >> Hi all.
    >> There's a bug in plot.acf, when plotting acf for multivariate time series.
    >> Here a reproducible example:
    >> 
    >> X <- rnorm(1000)
    >> Y <- -X + rnorm(1000, sd=0.6)
    >> Z <- cbind(X,Y)
    >> 
    >> In
    >> acf(Z)
    >> cross-correlation plot y-axis is limited to 0-1. But:
    >> acf(Z, ylim=c(-1,1))
    >> shows that there was a negative correlation, that was cut away in the
    >> previous plot.
    >> 
    >> I've seen the error is trivial. There's something like:
    >> 
    >> for(each pair of univariate time series) {
    >> if(is.null(ylim)) {
    >> ...#set ylim properly
    >> }
    >> ...
    >> }
    >> 
    >> in plot.acf code, so that in the first iteration the ylim par is properly
    >> set to about c(0,1), but in
    >> subsequent interations, ylim is no more NULL, and the old, unproper ylim
    >> specification
    >> remains.

    Duncan> Thanks for noticing this.  It's easy to fix, but
    Duncan> before I do, I'd like an opinion on the proper fix.
    Duncan> Should all the plots use the same ylim, or in the
    Duncan> case where it is unspecified, should they each
    Duncan> choose their own?  I can see arguments for both
    Duncan> possibilities.

    Duncan> Duncan Murdoch

I'd vote for the first one, a common y-scale.  
Only that is also consistent with the behavior of explicitly
speficied 'ylim'.

Martin

    >> 
    >> Antonio, Fabio Di Narzo.
    >> 
    >> P.S. Sorry for not indicating exact source lines, but from this PC I don't
    >> have access to
    >> R sources...


From antonio.fabio at gmail.com  Fri Mar 24 15:10:40 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 24 Mar 2006 15:10:40 +0100
Subject: [Rd] bug in plot.acf (PR#8705)
In-Reply-To: <20060324135305.569EF41EB2@slim.kubism.ku.dk>
References: <20060324135305.569EF41EB2@slim.kubism.ku.dk>
Message-ID: <b0808fdc0603240610t730e08b2o@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060324/37fab319/attachment.pl 

From jombart at biomserv.univ-lyon1.fr  Fri Mar 24 15:13:17 2006
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Fri, 24 Mar 2006 15:13:17 +0100
Subject: [Rd] Sweaving in png
Message-ID: <4423FE7D.8020907@biomserv.univ-lyon1.fr>

Hello list, 

despite I already posted a mail on this topic on R help, I guess this place may be more appropriate.
I'll make it shorter this time. Sorry for posting twice.

I found that using pixmap pictures in a Sweave document was sometimes almost impossible, due to the huge size of the pdf pictures produced.

The first solution I found was to save pictures in png, when too heavy in pdf. Here is an example:

### in a .rnw document ###

% here is an invisible chunck to create a picture
<<fig =FALSE,echo=FALSE>>=
png(filename='figs/myPic.png')
@

% next, R code to generate picture
<<fig=FALSE,echo=TRUE>>=
...[code to produce the figure]
@

% then, close the device. Hidden, again
<<fig =FALSE,echo=FALSE>>=
dev.off()
@

% and then, include it as a picture
\includegraphics{figs/myPic.png}

### end of the example ###

I
This is quite long, and I would have prefered to need simply: 

<<fig=TRUE,pdf=FALSE,png=TRUE>>
...[code to produce the figure]
@

So I tried to adapte the Sweave driver 'RweaveLatex' in order to do so. It worked.

The not-so-new driver is only a slight modification of RweaveLatex, and can 
generate ps, pdf or png figures; it was tested on Ubuntu64, Debian, 
several Windows systems and macOS X partforms with no detected problem.

Does someone find this useful, and/or were there better solutions I missed?

Regards,

Thibaut Jombart .

-- 
######################################
Thibaut JOMBART
CNRS UMR 5558 - Laboratoire de Biom?trie et Biologie Evolutive
Universite Lyon 1
43 bd du 11 novembre 1918
69622 Villeurbanne Cedex
T?l. : 04.72.43.29.35
Fax : 04.72.43.13.88
jombart at biomserv.univ-lyon1.fr <https://stat.ethz.ch/mailman/listinfo/r-help>


From murdoch at stats.uwo.ca  Fri Mar 24 15:19:37 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Mar 2006 09:19:37 -0500
Subject: [Rd] bug in plot.acf (PR#8705)
In-Reply-To: <b0808fdc0603240610t730e08b2o@mail.gmail.com>
References: <20060324135305.569EF41EB2@slim.kubism.ku.dk>
	<b0808fdc0603240610t730e08b2o@mail.gmail.com>
Message-ID: <4423FFF9.7020101@stats.uwo.ca>

On 3/24/2006 9:10 AM, Antonio, Fabio Di Narzo wrote:
> 2006/3/24, maechler at stat.math.ethz.ch <maechler at stat.math.ethz.ch>:
>>
>> >>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>> >>>>>     on Fri, 24 Mar 2006 13:55:03 +0100 (CET) writes:
>>
>>     Duncan> (Moved from r-devel to r-bugs)
>>     Duncan> On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
>>     >> Hi all.
>>     >> There's a bug in plot.acf, when plotting acf for multivariate time
>> series.
>>     >> Here a reproducible example:
>>     >>
>>     >> X <- rnorm(1000)
>>     >> Y <- -X + rnorm(1000, sd=0.6)
>>     >> Z <- cbind(X,Y)
>>     >>
>>     >> In
>>     >> acf(Z)
>>     >> cross-correlation plot y-axis is limited to 0-1. But:
>>     >> acf(Z, ylim=c(-1,1))
>>     >> shows that there was a negative correlation, that was cut away in
>> the
>>     >> previous plot.
>>     >>
>>     >> I've seen the error is trivial. There's something like:
>>     >>
>>     >> for(each pair of univariate time series) {
>>     >> if(is.null(ylim)) {
>>     >> ...#set ylim properly
>>     >> }
>>     >> ...
>>     >> }
>>     >>
>>     >> in plot.acf code, so that in the first iteration the ylim par is
>> properly
>>     >> set to about c(0,1), but in
>>     >> subsequent interations, ylim is no more NULL, and the old, unproper
>> ylim
>>     >> specification
>>     >> remains.
>>
>>     Duncan> Thanks for noticing this.  It's easy to fix, but
>>     Duncan> before I do, I'd like an opinion on the proper fix.
>>     Duncan> Should all the plots use the same ylim, or in the
>>     Duncan> case where it is unspecified, should they each
>>     Duncan> choose their own?  I can see arguments for both
>>     Duncan> possibilities.
>>
>>     Duncan> Duncan Murdoch
>>
>> I'd vote for the first one, a common y-scale.
>> Only that is also consistent with the behavior of explicitly
>> speficied 'ylim'.
>>
>> Martin
> 
> 
> This sounds to me to be the best, also for visual comparison of multiple
> plots at once (having them all on the same screen...).
> Antonio, Fabio Di Narzo.

Okay, will do it that way.

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Mar 24 15:25:57 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Mar 2006 09:25:57 -0500
Subject: [Rd] bug in plot.acf (PR#8705)
In-Reply-To: <20060324125503.E098B183A3@slim.kubism.ku.dk>
References: <20060324125503.E098B183A3@slim.kubism.ku.dk>
Message-ID: <971536df0603240625j4f8ff3d9uc05082063747d4af@mail.gmail.com>

On 3/24/06, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
> (Moved from r-devel to r-bugs)
>
> On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
> > Hi all.
> > There's a bug in plot.acf, when plotting acf for multivariate time series.
> > Here a reproducible example:
> >
> > X <- rnorm(1000)
> > Y <- -X + rnorm(1000, sd=0.6)
> > Z <- cbind(X,Y)
> >
> > In
> > acf(Z)
> > cross-correlation plot y-axis is limited to 0-1. But:
> > acf(Z, ylim=c(-1,1))
> > shows that there was a negative correlation, that was cut away in the
> > previous plot.
> >
> > I've seen the error is trivial. There's something like:
> >
> > for(each pair of univariate time series) {
> > if(is.null(ylim)) {
> > ...#set ylim properly
> > }
> > ...
> > }
> >
> > in plot.acf code, so that in the first iteration the ylim par is properly
> > set to about c(0,1), but in
> > subsequent interations, ylim is no more NULL, and the old, unproper ylim
> > specification
> > remains.
>
> Thanks for noticing this.  It's easy to fix, but before I do, I'd like
> an opinion on the proper fix.  Should all the plots use the same ylim,
> or in the case where it is unspecified, should they each choose their
> own?  I can see arguments for both possibilities.
>


Not sure if its worth considering this but plot.zoo allows ylim to be
a pair or it can be a list of pairs to specify different ylims for each
plot or it can be a labelled list to specify just those indicated with
the unspecified ones being defaulted.  Also if can be a set of data
points in which case its range it used.

z <- zoo(cbind(a = 1:10, b = 11:20, c = 21:30))
plot(z, ylim = list(c(1,20), c(1,40), c(1,60)))
plot(z, ylim = c(1,40))
plot(z, ylim = list(b = c(1,40)))  # a and c get default and b gets
indicated one
plot(z, ylim = list(c(1,40), a = c(1, 10))) # default is c(1,40) and a
is c(1,10)
plot(z, ylim = list(1:40, a = 1:10)) # same


From TimHesterberg at comcast.net  Fri Mar 24 16:53:42 2006
From: TimHesterberg at comcast.net (TimHesterberg at comcast.net)
Date: Fri, 24 Mar 2006 16:53:42 +0100 (CET)
Subject: [Rd] enhancement request for browser (PR#8706)
Message-ID: <20060324155342.8D8FF41EAB@slim.kubism.ku.dk>

I would like a way to modify the behavior of browser(), so that
entering a blank line does nothing rather than being equivalent to "c".

I'm running R using emacs ESS.
I often debug functions by inserting a browser, and stepping through
one line at a time, sending a line at a time from a buffer with
the function to the R buffer.
But every time I send a blank line, the browser interprets that as a c,
and continues on.

When I write functions, I make them more readable using blank lines
between sections.  The combination of this with the current behavior
of browser is maddening.

When the browser call is inside a loop and I happen to enter a
blank line, the loop continues without me realizing it.  All of a
sudden many variables have changed, for no apparent reason.

It also seems to happen "by itself", perhaps due to an interaction
of R and emacs ESS when I paste in a block of text.

Thank you,
Tim Hesterberg

P.S.  The use of a blank line as a synonym for "c" is not documented
in help(browser).


--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:glmpath, package:survival, package:splines, package:lars, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From simon.urbanek at r-project.org  Fri Mar 24 17:04:04 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 Mar 2006 12:04:04 -0400
Subject: [Rd] R make install and demo(graphics) issue
In-Reply-To: <E153C65077E0034E97A981C6CE26F1BD04534403@ENTWMAIL1A.harrahs.org>
References: <E153C65077E0034E97A981C6CE26F1BD04534403@ENTWMAIL1A.harrahs.org>
Message-ID: <1DE0AE96-1103-492B-A6C1-C87B4EA38209@r-project.org>

Matthew,

On Mar 20, 2006, at 1:52 PM, Matthew Beason wrote:

>     Thanks! That resolved the "make install" issue. However, after  
> installation when running "demo(graphics)" or "png()" from within  
> R, I get the following error:
> [...]
> unable to load shared library '/usr/local/R/lib/R/modules/R_X11.so':
>   Could not load module /usr/local/R/lib/R/modules/R_X11.so.
>         Dependent module /usr/java14/jre/bin/libjpeg.a(libjpeg.so.62)
> could not be loaded.
>         File /usr/java14/jre/bin/libjpeg.a is not an
>           archive or the file could not be read properly.

This seems like a problem with your libjpeg shared library - it seems  
to be bogus. Please make sure you have a properly installed libjpeg  
and that the correct one is detected. The one above comes from JRE  
which is probably not what you want. I don't know about your setup,  
so it's hard to tell which libraries are supposed to be where. Do you  
have binaries for multiple architectures on the same machine? I'm  
currently traveling so I can't check our AIX setup.

Cheers,
Simon


From murdoch at stats.uwo.ca  Fri Mar 24 18:59:05 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Mar 2006 12:59:05 -0500
Subject: [Rd] bug in plot.acf (PR#8705)
In-Reply-To: <971536df0603240625j4f8ff3d9uc05082063747d4af@mail.gmail.com>
References: <20060324125503.E098B183A3@slim.kubism.ku.dk>
	<971536df0603240625j4f8ff3d9uc05082063747d4af@mail.gmail.com>
Message-ID: <44243369.8090302@stats.uwo.ca>

On 3/24/2006 9:25 AM, Gabor Grothendieck wrote:
> On 3/24/06, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>> (Moved from r-devel to r-bugs)
>>
>> On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
>> > Hi all.
>> > There's a bug in plot.acf, when plotting acf for multivariate time series.
>> > Here a reproducible example:
>> >
>> > X <- rnorm(1000)
>> > Y <- -X + rnorm(1000, sd=0.6)
>> > Z <- cbind(X,Y)
>> >
>> > In
>> > acf(Z)
>> > cross-correlation plot y-axis is limited to 0-1. But:
>> > acf(Z, ylim=c(-1,1))
>> > shows that there was a negative correlation, that was cut away in the
>> > previous plot.
>> >
>> > I've seen the error is trivial. There's something like:
>> >
>> > for(each pair of univariate time series) {
>> > if(is.null(ylim)) {
>> > ...#set ylim properly
>> > }
>> > ...
>> > }
>> >
>> > in plot.acf code, so that in the first iteration the ylim par is properly
>> > set to about c(0,1), but in
>> > subsequent interations, ylim is no more NULL, and the old, unproper ylim
>> > specification
>> > remains.
>>
>> Thanks for noticing this.  It's easy to fix, but before I do, I'd like
>> an opinion on the proper fix.  Should all the plots use the same ylim,
>> or in the case where it is unspecified, should they each choose their
>> own?  I can see arguments for both possibilities.
>>
> 
> 
> Not sure if its worth considering this but plot.zoo allows ylim to be
> a pair or it can be a list of pairs to specify different ylims for each
> plot or it can be a labelled list to specify just those indicated with
> the unspecified ones being defaulted.  Also if can be a set of data
> points in which case its range it used.

I'd say this is probably not a great idea here, since there are n^2 
limits to specify when plotting n series:  it's not obvious what the 
input would be. (Ylim as an I x I x 2 array?  Or 2 x I x I?)  Users who 
want that level of control should write a custom version of plot.acf.

Duncan


From murdoch at stats.uwo.ca  Fri Mar 24 19:16:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Mar 2006 13:16:39 -0500
Subject: [Rd] bug in plot.acf (PR#8705)
In-Reply-To: <20060324125503.E098B183A3@slim.kubism.ku.dk>
References: <20060324125503.E098B183A3@slim.kubism.ku.dk>
Message-ID: <44243787.3050809@stats.uwo.ca>

This is fixed now in R-devel and R-patched.  Thanks again for the report.

Duncan Murdoch

On 3/24/2006 7:55 AM, murdoch at stats.uwo.ca wrote:
> (Moved from r-devel to r-bugs)
> 
> On 3/24/2006 5:03 AM, Antonio, Fabio Di Narzo wrote:
>> Hi all.
>> There's a bug in plot.acf, when plotting acf for multivariate time series.
>> Here a reproducible example:
>> 
>> X <- rnorm(1000)
>> Y <- -X + rnorm(1000, sd=0.6)
>> Z <- cbind(X,Y)
>> 
>> In
>> acf(Z)
>> cross-correlation plot y-axis is limited to 0-1. But:
>> acf(Z, ylim=c(-1,1))
>> shows that there was a negative correlation, that was cut away in the
>> previous plot.
>> 
>> I've seen the error is trivial. There's something like:
>> 
>> for(each pair of univariate time series) {
>> if(is.null(ylim)) {
>> ...#set ylim properly
>> }
>> ...
>> }
>> 
>> in plot.acf code, so that in the first iteration the ylim par is properly
>> set to about c(0,1), but in
>> subsequent interations, ylim is no more NULL, and the old, unproper ylim
>> specification
>> remains.
> 
> Thanks for noticing this.  It's easy to fix, but before I do, I'd like 
> an opinion on the proper fix.  Should all the plots use the same ylim, 
> or in the case where it is unspecified, should they each choose their 
> own?  I can see arguments for both possibilities.
> 
> Duncan Murdoch
> 
> 
>> 
>> Antonio, Fabio Di Narzo.
>> 
>> P.S. Sorry for not indicating exact source lines, but from this PC I don't
>> have access to
>> R sources...
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbernzwe at bear.com  Fri Mar 24 21:00:17 2006
From: bbernzwe at bear.com (Bernzweig, Bruce (Exchange))
Date: Fri, 24 Mar 2006 15:00:17 -0500
Subject: [Rd] How to capture t-score and p-values from t.test
Message-ID: <136753ACA3E9A5498440B172A77F4BF20A5D331B@whexchmb15.bsna.bsroot.bear.com>

When I do t.test on two distributions (see example below), it outputs
numerous data about the t.test.

What I'd like to do is individually capture some of this data and assign
it to other variables.

However, I am unable to find anything in the help section.

 

In the example below, the t value is -4.0441 and the p-value is 0.006771

How can I assign these values to two variables, let's say tVal and pVal?

 

Thanks,

 

- Bruce

 

> t.test(d[1], d[2], var.equal=TRUE)

        Two Sample t-test

data:  d[1] and d[2] 

t = -4.0441, df = 6, p-value = 0.006771

alternative hypothesis: true difference in means is not equal to 0 

95 percent confidence interval:

 -5.216430 -1.283570 

sample estimates:

mean of x mean of y 

     2.50      5.75

-------------- next part --------------


**********************************************************************
Please be aware that, notwithstanding the fact that the person sending
this communication has an address in Bear Stearns' e-mail system, this
person is not an employee, agent or representative of Bear Stearns.
Accordingly, this person has no power or authority to represent, make
any recommendation, solicitation, offer or statements or disclose
information on behalf of or in any way bind Bear Stearns or any of its
affiliates.
**********************************************************************


From p.dalgaard at biostat.ku.dk  Fri Mar 24 21:36:53 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Mar 2006 21:36:53 +0100
Subject: [Rd] How to capture t-score and p-values from t.test
In-Reply-To: <136753ACA3E9A5498440B172A77F4BF20A5D331B@whexchmb15.bsna.bsroot.bear.com>
References: <136753ACA3E9A5498440B172A77F4BF20A5D331B@whexchmb15.bsna.bsroot.bear.com>
Message-ID: <x2pskb7f6i.fsf@turmalin.kubism.ku.dk>

"Bernzweig, Bruce (Exchange)" <bbernzwe at bear.com> writes:

> When I do t.test on two distributions (see example below), it outputs
> numerous data about the t.test.
> 
> What I'd like to do is individually capture some of this data and assign
> it to other variables.
> 
> However, I am unable to find anything in the help section.
> 
>  
> 
> In the example below, the t value is -4.0441 and the p-value is 0.006771
> 
> How can I assign these values to two variables, let's say tVal and pVal?
> 

tt <- t.test(d[1], d[2], var.equal=TRUE)

tt$statistic
tt$p.value

unclass(tt)
names(tt)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From bbernzwe at bear.com  Fri Mar 24 21:42:08 2006
From: bbernzwe at bear.com (Bernzweig, Bruce (Exchange))
Date: Fri, 24 Mar 2006 15:42:08 -0500
Subject: [Rd] How to capture t-score and p-values from t.test
Message-ID: <136753ACA3E9A5498440B172A77F4BF20A5D331D@whexchmb15.bsna.bsroot.bear.com>

Thanks Peter!

-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter Dalgaard
Sent: Friday, March 24, 2006 3:37 PM
To: Bernzweig, Bruce (Exchange)
Cc: r-devel at r-project.org
Subject: Re: [Rd] How to capture t-score and p-values from t.test

"Bernzweig, Bruce (Exchange)" <bbernzwe at bear.com> writes:

> When I do t.test on two distributions (see example below), it outputs
> numerous data about the t.test.
> 
> What I'd like to do is individually capture some of this data and assign
> it to other variables.
> 
> However, I am unable to find anything in the help section.
> 
>  
> 
> In the example below, the t value is -4.0441 and the p-value is 0.006771
> 
> How can I assign these values to two variables, let's say tVal and pVal?
> 

tt <- t.test(d[1], d[2], var.equal=TRUE)

tt$statistic
tt$p.value

unclass(tt)
names(tt)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



**********************************************************************
Please be aware that, notwithstanding the fact that the person sending
this communication has an address in Bear Stearns' e-mail system, this
person is not an employee, agent or representative of Bear Stearns.
Accordingly, this person has no power or authority to represent, make
any recommendation, solicitation, offer or statements or disclose
information on behalf of or in any way bind Bear Stearns or any of its
affiliates.


From kwright68 at gmail.com  Fri Mar 24 22:32:26 2006
From: kwright68 at gmail.com (Kevin Wright)
Date: Fri, 24 Mar 2006 15:32:26 -0600
Subject: [Rd] Undocumented features of 'browser' (and possible changes)
Message-ID: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>

I often use browser() when debugging a function.  After entering
browser, I would find it very useful to be able to cut-and-paste a
chunk of R code to the browser (or use ess-eval-region in Emacs).  An
inconvenience, however, is that both blank lines and comment lines
will exit the browser.

The man page for browser says nothing about exiting the browser via
ENTER or via a line that begins with a comment, only that
"sub-interpreter can be exited by typing c" and "Typing Q quits the
current execution".

A hack that does allow code pasting into the browser is to put "NULL"
at the start of blank lines and comment lines.

Question: How would people react to a request to change the browser so
that blank lines and comment lines do not exit the browser?

Possible answers (check one or write your own)
[ ] - Who are you kidding?
[ ] - Even though it is undocumented and redundant, I use ENTER to exit browser
[ ] - You are forgetting about this scenario...
[ ] - A patch would be welcome
[ ] - Sounds great and I committed the changes already.  :-)


Kevin Wright, Windows 2000, R 2.2.1


From p.dalgaard at biostat.ku.dk  Fri Mar 24 23:11:25 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Mar 2006 23:11:25 +0100
Subject: [Rd] Undocumented features of 'browser' (and possible changes)
In-Reply-To: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
References: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
Message-ID: <x2lkuz7asy.fsf@turmalin.kubism.ku.dk>

"Kevin Wright" <kwright68 at gmail.com> writes:

> I often use browser() when debugging a function.  After entering
> browser, I would find it very useful to be able to cut-and-paste a
> chunk of R code to the browser (or use ess-eval-region in Emacs).  An
> inconvenience, however, is that both blank lines and comment lines
> will exit the browser.
> 
> The man page for browser says nothing about exiting the browser via
> ENTER or via a line that begins with a comment, only that
> "sub-interpreter can be exited by typing c" and "Typing Q quits the
> current execution".
> 
> A hack that does allow code pasting into the browser is to put "NULL"
> at the start of blank lines and comment lines.
> 
> Question: How would people react to a request to change the browser so
> that blank lines and comment lines do not exit the browser?
> 
> Possible answers (check one or write your own)
> [ ] - Who are you kidding?
> [ ] - Even though it is undocumented and redundant, I use ENTER to exit browser
> [x] - You are forgetting about this scenario...

ENTER does not actually quit the browser, it repeats the last command,
as in

> f(2)
Called from: f(2)
Browse[1]> n
debug: x <- 2
Browse[1]> 
debug: y <- x + 1
Browse[1]> 

This is useful, since it drives you nuts to type "n",ENTER if you're
debugging a lengthy piece of code (possibly more noticeable when
you're using debug() than with browser(), but the two need to be
consistent). This is also the way things work in e.g. the gdb
debugger.

Having "c" as the initial default is still open for discussion, of
course. The scenario where browser() is in a function that gets called
repeatedly does require some attention; it might be convenient to be
able to continue with a single keystroke in that case.


> [ ] - A patch would be welcome
> [ ] - Sounds great and I committed the changes already.  :-)
> 
> 
> Kevin Wright, Windows 2000, R 2.2.1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From kwright68 at gmail.com  Fri Mar 24 23:41:36 2006
From: kwright68 at gmail.com (Kevin Wright)
Date: Fri, 24 Mar 2006 16:41:36 -0600
Subject: [Rd] Undocumented features of 'browser' (and possible changes)
In-Reply-To: <x2lkuz7asy.fsf@turmalin.kubism.ku.dk>
References: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
	<x2lkuz7asy.fsf@turmalin.kubism.ku.dk>
Message-ID: <adf71a630603241441u26d7f577ta1a4b9448bf0253b@mail.gmail.com>

Thanks for the clarification about ENTER and for explaining that
browser and debug use the same parser.  I'll crawl back into my
cubicle and keep using my hack.  Maybe I'll look into  re-writing
ess-eval-region to not send blank lines and comment lines.

Kevin


On 24 Mar 2006 23:11:25 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> "Kevin Wright" <kwright68 at gmail.com> writes:
>
> > I often use browser() when debugging a function.  After entering
> > browser, I would find it very useful to be able to cut-and-paste a
> > chunk of R code to the browser (or use ess-eval-region in Emacs).  An
> > inconvenience, however, is that both blank lines and comment lines
> > will exit the browser.
> >
> > The man page for browser says nothing about exiting the browser via
> > ENTER or via a line that begins with a comment, only that
> > "sub-interpreter can be exited by typing c" and "Typing Q quits the
> > current execution".
> >
> > A hack that does allow code pasting into the browser is to put "NULL"
> > at the start of blank lines and comment lines.
> >
> > Question: How would people react to a request to change the browser so
> > that blank lines and comment lines do not exit the browser?
> >
> > Possible answers (check one or write your own)
> > [ ] - Who are you kidding?
> > [ ] - Even though it is undocumented and redundant, I use ENTER to exit browser
> > [x] - You are forgetting about this scenario...
>
> ENTER does not actually quit the browser, it repeats the last command,
> as in
>
> > f(2)
> Called from: f(2)
> Browse[1]> n
> debug: x <- 2
> Browse[1]>
> debug: y <- x + 1
> Browse[1]>
>
> This is useful, since it drives you nuts to type "n",ENTER if you're
> debugging a lengthy piece of code (possibly more noticeable when
> you're using debug() than with browser(), but the two need to be
> consistent). This is also the way things work in e.g. the gdb
> debugger.
>
> Having "c" as the initial default is still open for discussion, of
> course. The scenario where browser() is in a function that gets called
> repeatedly does require some attention; it might be convenient to be
> able to continue with a single keystroke in that case.
>
>
> > [ ] - A patch would be welcome
> > [ ] - Sounds great and I committed the changes already.  :-)
> >
> >
> > Kevin Wright, Windows 2000, R 2.2.1
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>


From sfalcon at fhcrc.org  Sat Mar 25 00:37:20 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 24 Mar 2006 15:37:20 -0800
Subject: [Rd] Undocumented features of 'browser' (and possible changes)
In-Reply-To: <adf71a630603241441u26d7f577ta1a4b9448bf0253b@mail.gmail.com>
	(Kevin Wright's message of "Fri, 24 Mar 2006 16:41:36 -0600")
References: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
	<x2lkuz7asy.fsf@turmalin.kubism.ku.dk>
	<adf71a630603241441u26d7f577ta1a4b9448bf0253b@mail.gmail.com>
Message-ID: <m2acbfmn2n.fsf@ziti.local>

"Kevin Wright" <kwright68 at gmail.com> writes:

> Thanks for the clarification about ENTER and for explaining that
> browser and debug use the same parser.  I'll crawl back into my
> cubicle and keep using my hack.  Maybe I'll look into  re-writing
> ess-eval-region to not send blank lines and comment lines.

Well, modifying ess to get what you want seems reasonable.  I have
used the ENTER as repeat feature so I wouldn't want that to go away.
But it does suggest a couple of alternative solutions:

1. Add one more command that the debug mode knows about that is a
   no-op.  Then copy/paste commands can send that first.

2. Add an option to browser that turns of the ENTER is repeat.

+ seth


From murdoch at stats.uwo.ca  Sat Mar 25 06:22:28 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 25 Mar 2006 00:22:28 -0500
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>
Message-ID: <4424D394.7050204@stats.uwo.ca>

[ Moved from R-help]

Duncan Mackay wrote:
> Hi all,
> On the subject of histories, how about changing the default value of
> "max.show" from 25 to Inf? I find that the line of code I'm looking for is
> ALWAYS on the 26th line back from the end of the default history!! Also, re
> changing the amount of history saved, Prof Ripley replied to an earlier
> query of mine on this list (04 Mar 2005) with info about the R_HISTSIZE
> environment variable that can be changed to save more or less history. And
> it wouldn't it be great if the history mechanism had the option of storing
> the session date??!!

I've written a timestamp() function to do the timestamping, but I'd like
some people on platforms other than Windows to take a look -- I can't
test it there.  I'd especially like to hear if trying it on platforms
that don't support history() causes problems.

This needs new internals, so you need to be able to build R to test.

If anyone has the time, could you try applying the attached patch to a
reasonably current R-devel source tree, and send me comments or make
improvements?  Thanks.

Duncan Murdoch

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060325/9337e93d/attachment.pl 

From berwin at maths.uwa.edu.au  Sat Mar 25 13:12:16 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 25 Mar 2006 20:12:16 +0800
Subject: [Rd] Suggest patch for princomp.formula and prcomp.formula
Message-ID: <17445.13216.869157.615441@bossiaea.maths.uwa.edu.au>

Dear all,

perhaps I am using princomp.formula and prcomp.formula in a way that
is not documented to work, but then the documentation just says:

        formula: a formula with no response variable.

Thus, to avoid a lot of typing, it would be nice if one could use '.'
and '-' in the formula, e.g.

> library(DAAG)
> res <- prcomp(~ . - case - site - Pop - sex, possum)
Error in prcomp.formula(~. - case - site - Pop - sex, possum) : 
	PCA applies only to numerical variables
> res <- princomp(~ . - case - site - Pop - sex, possum)
Error in princomp.formula(~. - case - site - Pop - sex, possum) : 
	PCA applies only to numerical variables

Unfortunately, as the examples above show, this is currently not
possible, since both functions test whether any term mentioned in the
formula is non numeric or a factor, instead of just testing those that
enter the analysis.

The attached patch should allow the use of '.' and '-', while still
producing an error when a factor or a non-numeric variable is
specified to enter the analysis:

> library(DAAG)
> res <- prcomp(~ . - case - site - Pop - sex, possum)
> res <- princomp(~ . - case - site - Pop - sex, possum)
> res <- prcomp(~ . - case - site - Pop, possum)
Error in prcomp.formula(~. - case - site - Pop, possum) : 
	PCA applies only to numerical variables
> res <- princomp(~ . - case - site - Pop, possum)
Error in princomp.formula(~. - case - site - Pop, possum) : 
	PCA applies only to numerical variables

On my machine, `make check FORCE=FORCE' succeeds with this patch and,
as far as I can tell, no modification of the help pages would be
necessary.  

Cheers,

        Berwin

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060325/5a5d4a95/attachment.pl 

From ivowel at gmail.com  Sat Mar 25 15:17:43 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 25 Mar 2006 09:17:43 -0500
Subject: [Rd] Suggestion: Slightly Clearer Error Message
Message-ID: <50d1c22d0603250617p419966e3h3a306e7f016056d1@mail.gmail.com>

dear R developers:

May I suggest that you enhance the error message:

Error in "[<-"(`*tmp*`, , curcol, value = c(0.0198881080712288,
0.00889721376726782,  :
	number of items to replace is not a multiple of replacement length

with information about why this is the case?  For example,

	number of items to replace (dimensions: x,y,z) is not a multiple of
replacement length (dimension x,y)

I just spent some time to figure out that a row-vector was not a
col-vector in context here.  in fact, this may warrant a special note
("you cannot replace a col-vector of length x with a row-vector of
length y").

just a suggestion...

regards,

/iaw


From maechler at stat.math.ethz.ch  Sat Mar 25 17:30:27 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 25 Mar 2006 17:30:27 +0100
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <4424D394.7050204@stats.uwo.ca>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>
	<4424D394.7050204@stats.uwo.ca>
Message-ID: <17445.28707.485402.183387@stat.math.ethz.ch>

Hi Duncan,

I think all ESS users don't use history() because ESS calls R  
with "--no-readline" (Unix)  
or   "--ess"  (Windows & Cygwin)

I'd wish that in that case, and probably also in BATCH mode,
timestamp() should write the time stamp prefixed by "##" to the
"R console" (to R's stdout); when people are using ESS properly, then
rather than wanting a history, they save the R's buffer ("*R*") as
"R transcript" (file typically ending with ".Rt" or ".Rout") 
and it makes much sense to have a time stampe entry in that file when
others would want an entry in the history.

BTW, after applying your patch, for me, compilation ends
prematurely with

gcc -I. -I../../src/include -I../../../R/src/include -I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O3 -pedantic -Wall -Wno-comment -DDEBUG_q -Wcast-align -c ../../../R/src/unix/stubs.c -o stubs.o
../../../R/src/unix/stubs.c: In function `do_addhistory':
../../../R/src/unix/stubs.c:46: warning: implicit declaration of function `ptr_R_addhistory'
../../../R/src/unix/stubs.c:46: error: `rho' undeclared (first use in this function)
../../../R/src/unix/stubs.c:46: error: (Each undeclared identifier is reported only once
../../../R/src/unix/stubs.c:46: error: for each function it appears in.)
../../../R/src/unix/stubs.c:46: warning: return makes pointer from integer without a cast
make[3]: *** [stubs.o] Error 1


Martin


From murdoch at stats.uwo.ca  Sat Mar 25 20:58:27 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 25 Mar 2006 14:58:27 -0500
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <17445.28707.485402.183387@stat.math.ethz.ch>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>	<4424D394.7050204@stats.uwo.ca>
	<17445.28707.485402.183387@stat.math.ethz.ch>
Message-ID: <4425A0E3.8070108@stats.uwo.ca>

On 3/25/2006 11:30 AM, Martin Maechler wrote:
> Hi Duncan,
> 
> I think all ESS users don't use history() because ESS calls R  
> with "--no-readline" (Unix)  
> or   "--ess"  (Windows & Cygwin)
> 
> I'd wish that in that case, and probably also in BATCH mode,
> timestamp() should write the time stamp prefixed by "##" to the
> "R console" (to R's stdout); when people are using ESS properly, then
> rather than wanting a history, they save the R's buffer ("*R*") as
> "R transcript" (file typically ending with ".Rt" or ".Rout") 
> and it makes much sense to have a time stampe entry in that file when
> others would want an entry in the history.
> 
> BTW, after applying your patch, for me, compilation ends
> prematurely with
> 
> gcc -I. -I../../src/include -I../../../R/src/include -I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O3 -pedantic -Wall -Wno-comment -DDEBUG_q -Wcast-align -c ../../../R/src/unix/stubs.c -o stubs.o
> ../../../R/src/unix/stubs.c: In function `do_addhistory':
> ../../../R/src/unix/stubs.c:46: warning: implicit declaration of function `ptr_R_addhistory'
> ../../../R/src/unix/stubs.c:46: error: `rho' undeclared (first use in this function)
> ../../../R/src/unix/stubs.c:46: error: (Each undeclared identifier is reported only once
> ../../../R/src/unix/stubs.c:46: error: for each function it appears in.)
> ../../../R/src/unix/stubs.c:46: warning: return makes pointer from integer without a cast
> make[3]: *** [stubs.o] Error 1

Okay, this compile error is fixed.  I've put a new version of the patch in

http://www.stats.uwo.ca/faculty/murdoch/software/timestamp.patch

I haven't addressed the ESS request above other than changing the 
message prefix to start with ##; I don't know how to detect ESS from 
within an R session.

Duncan Murdoch


From bill at insightful.com  Sat Mar 25 21:49:33 2006
From: bill at insightful.com (Bill Dunlap)
Date: Sat, 25 Mar 2006 12:49:33 -0800 (PST)
Subject: [Rd] gsub(replacement="\\X") -> "X", not "\\X"
Message-ID: <Pine.GSO.4.56.0603251237340.21795@octopus>

I would have thought that all 4 of the following
would give the same result (the first):
   > gsub("backslash-X", "\\X", "this is a backslash-X", fixed=T)
   [1] "this is a \\X"
   > gsub("backslash-X", "\\X", "this is a backslash-X", extended=F)
   [1] "this is a X"
   > gsub("backslash-X", "\\X", "this is a backslash-X", extended=T)
   [1] "this is a X"
   > gsub("backslash-X", "\\X", "this is a backslash-X", perl=T)
   [1] "this is a X"
If fixed==F the first "\\" is ignored except if it is followed by a
digit.  In particular, the replacement string must use "\\\\" to insert
a backslash and "\\" by itself is the same as "".  When fixed==T,
replacement="\\" means to insert a backslash.

I've seen code in package:gdata that depends on this behavior but I did
not see it described in help(gsub).  It describes using
replacement="\\<digit>" to put a matched subpattern into the output,
but not the fact that replacement="\\<nondigit>" is equivalent to
replacement="<nondigit>" (but only when fixed==F).

Is that intended or is the help file incomplete?  I'd like to
get Splus's gsub/substituteString in line with R's.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From kjetilbrinchmannhalvorsen at gmail.com  Sat Mar 25 21:57:50 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Sat, 25 Mar 2006 16:57:50 -0400
Subject: [Rd] How to capture t-score and p-values from t.test
In-Reply-To: <136753ACA3E9A5498440B172A77F4BF20A5D331B@whexchmb15.bsna.bsroot.bear.com>
References: <136753ACA3E9A5498440B172A77F4BF20A5D331B@whexchmb15.bsna.bsroot.bear.com>
Message-ID: <4425AECE.7000108@gmail.com>

Bernzweig, Bruce (Exchange) wrote:
> When I do t.test on two distributions (see example below), it outputs
> numerous data about the t.test.
> 
> What I'd like to do is individually capture some of this data and assign
> it to other variables.
> 
> However, I am unable to find anything in the help section.

t.test returns an object of class "htest", but ?htest :
 > ?htest
No documentation for 'htest' in specified packages and libraries:
you could try 'help.search("htest")'
but that does not do anythinh eiather.

Some time ago, I wrote a helpfile for htest, but that was rejected, 
since "S3 classes are not usually documented".

Kjetil


> 
>  
> 
> In the example below, the t value is -4.0441 and the p-value is 0.006771
> 
> How can I assign these values to two variables, let's say tVal and pVal?
> 
>  
> 
> Thanks,
> 
>  
> 
> - Bruce
> 
>  
> 
>> t.test(d[1], d[2], var.equal=TRUE)
> 
>         Two Sample t-test
> 
> data:  d[1] and d[2] 
> 
> t = -4.0441, df = 6, p-value = 0.006771
> 
> alternative hypothesis: true difference in means is not equal to 0 
> 
> 95 percent confidence interval:
> 
>  -5.216430 -1.283570 
> 
> sample estimates:
> 
> mean of x mean of y 
> 
>      2.50      5.75
> 
> 
> 
> ------------------------------------------------------------------------
> 
> 
> 
> **********************************************************************
> Please be aware that, notwithstanding the fact that the person sending
> this communication has an address in Bear Stearns' e-mail system, this
> person is not an employee, agent or representative of Bear Stearns.
> Accordingly, this person has no power or authority to represent, make
> any recommendation, solicitation, offer or statements or disclose
> information on behalf of or in any way bind Bear Stearns or any of its
> affiliates.
> **********************************************************************
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cberry at tajo.ucsd.edu  Sun Mar 26 00:06:16 2006
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 25 Mar 2006 15:06:16 -0800
Subject: [Rd] Undocumented features of 'browser' (and possible changes)
In-Reply-To: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
References: <adf71a630603241332g4e592112icc2944d969207924@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603251458030.7761@tajo.ucsd.edu>

On Fri, 24 Mar 2006, Kevin Wright wrote:

> I often use browser() when debugging a function.  After entering
> browser, I would find it very useful to be able to cut-and-paste a
> chunk of R code to the browser (or use ess-eval-region in Emacs).  An
> inconvenience, however, is that both blank lines and comment lines
> will exit the browser.

Kevin,

This trick may help:

Browse[1]> { ### blank lines will be ignored
+
+
+
+ x+1
+ }
[1] 2
Browse[1]>

Maybe you want to write 'ess-eval-region-in-braces'.

[rest deleted]

Chuck

Charles C. Berry                        (858) 534-2098
                                          Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	         UC San Diego
http://biostat.ucsd.edu/~cberry/         La Jolla, San Diego 92093-0717


From smyth at wehi.EDU.AU  Sun Mar 26 15:06:42 2006
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Sun, 26 Mar 2006 23:06:42 +1000 (EST)
Subject: [Rd]  How to capture t-score and p-values from t.test
In-Reply-To: <mailman.9.1143367202.16219.r-devel@r-project.org>
References: <mailman.9.1143367202.16219.r-devel@r-project.org>
Message-ID: <1399.58.106.251.152.1143378402.squirrel@homebase.wehi.edu.au>

> Date: Sat, 25 Mar 2006 16:57:50 -0400
> From: Kjetil Brinchmann Halvorsen
> 	<kjetilbrinchmannhalvorsen at gmail.com>
> Subject: Re: [Rd] How to capture t-score and p-values from t.test
> To: "Bernzweig, Bruce \(Exchange\)" <bbernzwe at bear.com>
> Cc: r-devel at r-project.org
>
> Bernzweig, Bruce (Exchange) wrote:
>> When I do t.test on two distributions (see example below), it outputs
>> numerous data about the t.test.
>>
>> What I'd like to do is individually capture some of this data and assign
>> it to other variables.
>>
>> However, I am unable to find anything in the help section.
>
> t.test returns an object of class "htest", but ?htest :
>  > ?htest
> No documentation for 'htest' in specified packages and libraries:
> you could try 'help.search("htest")'
> but that does not do anythinh eiather.
>
> Some time ago, I wrote a helpfile for htest, but that was rejected,
> since "S3 classes are not usually documented".
>
> Kjetil

The "htest" object created by t.test() is fully documented in the "Value" section of
help("t.test").  In effect, this defines what a "htest" object is understood to be.

help.search("htest") brings up a list of every function which produces an "htest" object.

Gordon


From ripley at stats.ox.ac.uk  Sun Mar 26 18:26:09 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sun, 26 Mar 2006 18:26:09 +0200 (CEST)
Subject: [Rd] Double complex with gcc and Intel v9 Fortran (PR#8699)
Message-ID: <20060326162609.69B88103EE@slim.kubism.ku.dk>

On Wed, 22 Mar 2006, marquardt.christian at gmail.com wrote:

> Full_Name: Christian Marquardt
> Version: 2.2.1
> OS: Linux
> Submission from: (NULL) (84.167.229.240)
>
>
> Hello,
>
> I believe this is a bug in the configuration / installation:
>
> When configuring R-2.2.1 using the Intel v9 Fortran compiler as default 
> Fortran compiler and g++ as C++ compiler on a Suse 9.3 Linux, the 
> configuration script finds that the C and Fortran idea of double comples 
> disagree.
>
> I have tried to extract the test used for this from m4/R.m4 (a slightly 
> modified version of the two test files is added at the end). When 
> compiling
>
>   ifort -c ctest.f
>   gcc -c cftest.c
>
> and linking properly,
>
>   ifort -nofor_main cftest.o ctest.o -o runme
>
> running the executable gives the following output:
>
>   ./runme
> 123.456000 14.710644
> 0.000000 -0.000006
>
> To me, this inicates that the test should actually be passed successfully.

No, because R is linked with the C compiler and not the Fortran compiler.
Did you look in config.log and see what it indicated the error was?

You have not shown us anything that indicates that this is a bug in R.

You also haven't told us what architecture this is: I tried mixing gcc 
3.4.4 and ifort 9.0 on x86_64 Fedora Core 3, and had no problems.

> Unfortunately, I haven't quite understood how to rebuild the configure.ac etc
> once R.m4 is changed;

I presume you mean to rebuild 'configure': configure.ac does not depend on 
R.m4.  Just configure in maintainer mode, and 'make'.

> otherwise I would try to come up with a patch for R.m4.
> But maybe someone else can fix this?

We cannot fix things that we cannot reproduce.

>
> Many thanks,
>
>  Christian.
>
>
> ----<ctest.f>------------------------------------
>      subroutine cftest(x)
>      complex*16 x(3)
>      integer i
>
> c a few tests of constructs that are sometimes missing
>      if(x(1) .eq. x(1)) i = 0
>      x(1) = x(1)*x(2) + x(3)
>      end
>
> ----<cftest.c>------------------------------------
> #include <math.h>
> #define HAVE_F77_UNDERSCORE 1
> #ifdef HAVE_F77_UNDERSCORE
> # define F77_SYMBOL(x)   x ## _
> #else
> # define F77_SYMBOL(x)   x
> #endif
>
> typedef struct {
>        double r;
>        double i;
> } Rcomplex;
>
> extern void F77_SYMBOL(cftest)(Rcomplex *x);
>
> int main () {
>    Rcomplex z[3];
>
>    z[0].r = 3.14159265;
>    z[0].i = 2.172;
>    z[1].i = 3.14159265;
>    z[1].r = 2.172;
>    z[2].r = 123.456;
>    z[2].i = 0.123456;
>    F77_SYMBOL(cftest)(z);
>    printf("%f %f\n", z[0].r, z[0].i);
>    printf("%f %f\n", z[0].r - 123.456, z[0].i - 14.71065);
>    if(fabs(z[0].r - 123.456) < 1e-4 && fabs(z[0].i - 14.71065) < 1e-4)
>        exit(0);
>    else exit(1);
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Mar 26 18:52:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 26 Mar 2006 17:52:07 +0100 (BST)
Subject: [Rd] Choose.files to give shortnames
In-Reply-To: <44218DEC.5090408@math.ucalgary.ca>
References: <A9890059664CAD468E43D67208E576C76BDEAF@icex5.ic.ac.uk>
	<44218DEC.5090408@math.ucalgary.ca>
Message-ID: <Pine.LNX.4.64.0603261750130.27074@gannet.stats.ox.ac.uk>

On Wed, 22 Mar 2006, P Ehlers wrote:

> Would
>
> basename(choose.files())
>
> work for your usage?
> Still, a full.names argument might be useful.

I don't think so, as you can change directory in choose.files(), unlike 
dir().

> Peter Ehlers
>
> Brooks, Anthony B wrote:
>
>> I am writing a script to generate a QC report for some data based on a 
>> number of files. I am currently using the choose.files function to 
>> select the files as not all the files need to be QC'd. One minor issue 
>> is that choose.files returns the complete path of the filename (eg 
>> "C:/QCdata/Test1/File01", "C:/QCdata/Test1/File02"...). Is it possible 
>> to use choose.files to return just the file name eg("File01", 
>> "File02"...), in a way similar to the full.names=FALSE argument in the 
>> dir function.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sun Mar 26 19:41:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 26 Mar 2006 12:41:03 -0500
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <4425A0E3.8070108@stats.uwo.ca>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>	<4424D394.7050204@stats.uwo.ca>	<17445.28707.485402.183387@stat.math.ethz.ch>
	<4425A0E3.8070108@stats.uwo.ca>
Message-ID: <4426D22F.3040709@stats.uwo.ca>

I managed to get an R build going on a Linux box, and tested the changes 
there.  Now they're committed to R-devel.

Duncan Murdoch

On 3/25/2006 2:58 PM, Duncan Murdoch wrote:
> On 3/25/2006 11:30 AM, Martin Maechler wrote:
>> Hi Duncan,
>>
>> I think all ESS users don't use history() because ESS calls R  
>> with "--no-readline" (Unix)  
>> or   "--ess"  (Windows & Cygwin)
>>
>> I'd wish that in that case, and probably also in BATCH mode,
>> timestamp() should write the time stamp prefixed by "##" to the
>> "R console" (to R's stdout); when people are using ESS properly, then
>> rather than wanting a history, they save the R's buffer ("*R*") as
>> "R transcript" (file typically ending with ".Rt" or ".Rout") 
>> and it makes much sense to have a time stampe entry in that file when
>> others would want an entry in the history.
>>
>> BTW, after applying your patch, for me, compilation ends
>> prematurely with
>>
>> gcc -I. -I../../src/include -I../../../R/src/include -I/usr/X11R6/include -I/usr/local/include -DHAVE_CONFIG_H   -g -O3 -pedantic -Wall -Wno-comment -DDEBUG_q -Wcast-align -c ../../../R/src/unix/stubs.c -o stubs.o
>> ../../../R/src/unix/stubs.c: In function `do_addhistory':
>> ../../../R/src/unix/stubs.c:46: warning: implicit declaration of function `ptr_R_addhistory'
>> ../../../R/src/unix/stubs.c:46: error: `rho' undeclared (first use in this function)
>> ../../../R/src/unix/stubs.c:46: error: (Each undeclared identifier is reported only once
>> ../../../R/src/unix/stubs.c:46: error: for each function it appears in.)
>> ../../../R/src/unix/stubs.c:46: warning: return makes pointer from integer without a cast
>> make[3]: *** [stubs.o] Error 1
> 
> Okay, this compile error is fixed.  I've put a new version of the patch in
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/timestamp.patch
> 
> I haven't addressed the ESS request above other than changing the 
> message prefix to start with ##; I don't know how to detect ESS from 
> within an R session.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.murrell at auckland.ac.nz  Sun Mar 26 22:22:21 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 27 Mar 2006 08:22:21 +1200
Subject: [Rd] [R] RGui: windows-record and command history
In-Reply-To: <4423EE52.2020104@stats.uwo.ca>
References: <d0f55a670603230435t6a4b7a59h@mail.gmail.com>		<4422A744.50209@stats.uwo.ca>		<971536df0603230729t4828a082o26f5905b50226250@mail.gmail.com>		<4422C1A3.5050509@stats.uwo.ca>	<971536df0603230746r1ef31624qea7ffb5e8f015c67@mail.gmail.com>	<4422DCED.9040005@stats.uwo.ca>	<4422FA3F.5060001@stat.auckland.ac.nz>	<4423424F.20407@math.ucalgary.ca>
	<442348BC.3080707@stat.auckland.ac.nz>
	<4423EE52.2020104@stats.uwo.ca>
Message-ID: <4426F7FD.7010305@stat.auckland.ac.nz>

Hi


Duncan Murdoch wrote:
> I've moved this from r-help to r-devel.
> 
> On 3/23/2006 8:17 PM, Paul Murrell wrote:
> 
>>>
>>> Paul,
>>> If I read your comments correctly, the problem with manipulating the
>>> graph history is with saved histories across sessions/versions. Is
>>> there any reason not to manipulate it *within* a session? I never
>>> save plots for re-use in R. Re-running code is usually best for me.
>>> But I would find it handy to fiddle with the display list in a
>>> session.
>>
>>
>>
>> That is *one* problem with the display list.  Messing directly with 
>> the display list *within a session* is *less* dangerous, but R's 
>> behaviour if you do that is "undefined".
>>
>> The display list is technically an internal structure for R's internal 
>> use.  We can't stop you playing with it, but I do not encourage it and 
>> it is not officially supported.
>>
>> There are a number of simple things that you could do to the display 
>> list that should work, but providing proper support for general 
>> manipulations of the display list would require a significant amount 
>> of (re)design of the R graphics code.
>>
>> Paul
>>
>> p.s.  These comments apply to the display list in R's "graphics 
>> engine".   The 'grid' package also maintains a display list, and that 
>> has been designed to support more general manipulations.
> 
> 
> Are we talking about the same thing?  I think Peter is only thinking of 
> manipulating the .SavedPlots variable, which is a Windows-only object 
> holding plot history.  I imagine the entries in .SavedPlots[[5]] are the 
> things that you are worried about, and I agree people shouldn't play 
> with those, they should be using grid instead with its documented 
> interface.


Sorry, I came into the discussion a bit late, so there's a good chance I 
have misunderstood.  Within a session, manipulation of .SavedPlots (via 
the appropriate interface) seems reasonable (i.e., manipulations 
involving an entire "page" of output as the basic unit).  Warnings about 
use *between* sessions still apply though.

Paul


> If we do warn people off manipulating .SavedPlots, then I think it 
> should be a higher priority to implement some manipulations ourselves, 
> e.g. "[<-.SavedPlots", to allow entries to be moved around or deleted in 
> the list.
> 
> Duncan

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ripley at stats.ox.ac.uk  Sun Mar 26 22:29:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 26 Mar 2006 21:29:35 +0100 (BST)
Subject: [Rd] Suggest patch for princomp.formula and prcomp.formula
In-Reply-To: <17445.13216.869157.615441@bossiaea.maths.uwa.edu.au>
References: <17445.13216.869157.615441@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.64.0603262108450.15505@gannet.stats.ox.ac.uk>

I would argue this is a bug in model.frame(), but it seems that it is 
S-compatible.  That is, variables excluded by - appear in the model frame 
even though they do not really appear in the simplified formula.  (I 
suppose the rationale is that - need not always interpreted as deletion.)

The proposed fix regretably will not work, since one can do things like

library(MASS)
prcomp(~ dist + dist:climb, hills)

I'll see if I can dream up a general solution.  (One way forward is to 
simplify the formula and call terms again, but simplifcation is rather 
clumsy code.)


On Sat, 25 Mar 2006, Berwin A Turlach wrote:

> Dear all,
>
> perhaps I am using princomp.formula and prcomp.formula in a way that
> is not documented to work, but then the documentation just says:
>
>        formula: a formula with no response variable.
>
> Thus, to avoid a lot of typing, it would be nice if one could use '.'
> and '-' in the formula, e.g.
>
>> library(DAAG)
>> res <- prcomp(~ . - case - site - Pop - sex, possum)
> Error in prcomp.formula(~. - case - site - Pop - sex, possum) :
> 	PCA applies only to numerical variables
>> res <- princomp(~ . - case - site - Pop - sex, possum)
> Error in princomp.formula(~. - case - site - Pop - sex, possum) :
> 	PCA applies only to numerical variables
>
> Unfortunately, as the examples above show, this is currently not
> possible, since both functions test whether any term mentioned in the
> formula is non numeric or a factor, instead of just testing those that
> enter the analysis.
>
> The attached patch should allow the use of '.' and '-', while still
> producing an error when a factor or a non-numeric variable is
> specified to enter the analysis:
>
>> library(DAAG)
>> res <- prcomp(~ . - case - site - Pop - sex, possum)
>> res <- princomp(~ . - case - site - Pop - sex, possum)
>> res <- prcomp(~ . - case - site - Pop, possum)
> Error in prcomp.formula(~. - case - site - Pop, possum) :
> 	PCA applies only to numerical variables
>> res <- princomp(~ . - case - site - Pop, possum)
> Error in princomp.formula(~. - case - site - Pop, possum) :
> 	PCA applies only to numerical variables
>
> On my machine, `make check FORCE=FORCE' succeeds with this patch and,
> as far as I can tell, no modification of the help pages would be
> necessary.
>
> Cheers,
>
>        Berwin
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Mon Mar 27 02:11:41 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 26 Mar 2006 19:11:41 -0500
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <971536df050922115057416498@mail.gmail.com>
References: <971536df05092208135b7ff57d@mail.gmail.com>	<4332DEEA.8090705@stats.uwo.ca>	<971536df050922101246bf8667@mail.gmail.com>	<4332F2D3.6000807@stats.uwo.ca>	<971536df050922115057416498@mail.gmail.com>
Message-ID: <44272DBD.1030707@stats.uwo.ca>

I've just committed some code to R-devel to allow clipboard access to 
non-text in Windows.  This was something we discussed last September. 
I'm not completely happy with the code (it works with numerical 
clipboard format numbers rather than translating them into their names), 
but I'd rather make it available than work on it any more.

Duncan Murdoch


From rpeng at jhsph.edu  Mon Mar 27 02:58:40 2006
From: rpeng at jhsph.edu (Roger Peng)
Date: Sun, 26 Mar 2006 19:58:40 -0500
Subject: [Rd] Sweaving in png
In-Reply-To: <4423FE7D.8020907@biomserv.univ-lyon1.fr>
References: <4423FE7D.8020907@biomserv.univ-lyon1.fr>
Message-ID: <442738C0.6020800@jhsph.edu>

For what it's worth, I would find such a adaptation useful.

-roger

Thibaut Jombart wrote:
> Hello list, 
> 
> despite I already posted a mail on this topic on R help, I guess this place may be more appropriate.
> I'll make it shorter this time. Sorry for posting twice.
> 
> I found that using pixmap pictures in a Sweave document was sometimes almost impossible, due to the huge size of the pdf pictures produced.
> 
> The first solution I found was to save pictures in png, when too heavy in pdf. Here is an example:
> 
> ### in a .rnw document ###
> 
> % here is an invisible chunck to create a picture
> <<fig =FALSE,echo=FALSE>>=
> png(filename='figs/myPic.png')
> @
> 
> % next, R code to generate picture
> <<fig=FALSE,echo=TRUE>>=
> ...[code to produce the figure]
> @
> 
> % then, close the device. Hidden, again
> <<fig =FALSE,echo=FALSE>>=
> dev.off()
> @
> 
> % and then, include it as a picture
> \includegraphics{figs/myPic.png}
> 
> ### end of the example ###
> 
> I
> This is quite long, and I would have prefered to need simply: 
> 
> <<fig=TRUE,pdf=FALSE,png=TRUE>>
> ...[code to produce the figure]
> @
> 
> So I tried to adapte the Sweave driver 'RweaveLatex' in order to do so. It worked.
> 
> The not-so-new driver is only a slight modification of RweaveLatex, and can 
> generate ps, pdf or png figures; it was tested on Ubuntu64, Debian, 
> several Windows systems and macOS X partforms with no detected problem.
> 
> Does someone find this useful, and/or were there better solutions I missed?
> 
> Regards,
> 
> Thibaut Jombart .
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ssu at thegeorgeinstitute.org  Mon Mar 27 06:06:37 2006
From: ssu at thegeorgeinstitute.org (Steve Su)
Date: Mon, 27 Mar 2006 15:06:37 +1100
Subject: [Rd] Creating a package bundle.
Message-ID: <3B862D6B11ECDE458F679DDA238A135A1D82D9@lisa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060327/ba7314b3/attachment.pl 

From carminechilds_jg at porterpartners.com  Mon Mar 27 06:41:43 2006
From: carminechilds_jg at porterpartners.com (carminechilds_jg at porterpartners.com)
Date: Mon, 27 Mar 2006 06:41:43 +0200 (CEST)
Subject: [Rd] Touchdown Equity Report (PR#8711)
Message-ID: <20060327044143.B0A25CC11@slim.kubism.ku.dk>

V2UnZCBsaWtlIHRvIGdpdmUgYSBoaWdoIGZpdmUgdG8gb3VyIHJlc2VhcmNo
IHRlYW0uDQpPdXIgcG9ydGZvbGlvIGlzIHVwIDcwJSBzbyBmYXIgaW4gMjAw
NiBhbmQgbG9va2luZw0Kc3Ryb25nZXIgZXZlcnkgZGF5ISBXZSBob3BlIG91
ciBtZW1iZXJzIGhhdmUgYmVlbg0Ka2VlcGluZyB1cCB3aXRoIHRoZXNlIGlu
Y3JlZGlibGUgcGlja3MuDQoNCldlIHdvdWxkIGxpa2UgdG8gaW50cm9kdWNl
IHlvdSB0byBhIGNvbXBhbnkgaW52b2x2ZWQgaW4NCnRoZSBuYW5vdGVjaG5v
bG9neSBmaWVsZC4gIEl0IGlzIHdpZGVseSBiZWxpZXZlZCBhbW9uZw0KZXhw
ZXJ0cyB0aGF0IHRoaXMgY291bGQgYmUgdGhlIG5leHQgc2VjdG9yIHRvIGxl
YWQgYW4NCmVjb25vbWljIGJvb20uICBTb21lIHJlYWxseSBCaWcgbmV3cyBl
eHBlY3RlZCBmcm9tIHRoaXMNCm5leHQgd2lubmVyOg0KDQpDTzogTmFub19T
dXBlckxhdHRpY2VfVGVjaG5vbG9neSBJbmMuIF9fIHxcfCBTIEwgVA0KQ3Vy
cmVudGx5IFRyYWRpbmcgYXQ6ICQzLjEwDQpJdHMgMSBXZWVrX1RhcmdldCBp
czogJDUuNDUNCg0KR2V0IGluIGVhcmx5IG9uIHRoaXMgb25lISBBIE1hc3Np
dmUgUFIgQ2FtcGFpZ24gaXMgdW5kZXJ3YXkNCmZvciBNb25kYXkgYW5kIGFs
bCBuZXh0IHdlZWtzIHRyYWRpbmcsIEdldCBJbiBFYXJseSEhDQpXZSB0b2xk
IHlvdSBsYXN0IHRpbWUgYWJvdXQgdGhpcyBvbmUsIGV4cGVjdCBtb3JlIHRo
aXMgdGltZSENCg0KTmFub19TdXBlckxhdHRpY2VfVGVjaG5vbG9neSBpcyBh
IG5hbm90ZWNobm9sb2d5IGNvbXBhbnkNCmVuZ2FnZWQgaW4gdGhlIGNvYXRp
bmcgb2YgcHJlY2lzaW9uIHRvb2xzIGFuZCBjb21wb25lbnRzDQp3aXRoIG5h
bm8gc3RydWN0ZWQgY29hdGluZ3MgZm9yIGhpZ2gtdGVjaCBpbmR1c3RyaWVz
Lg0KDQpGb3IgbW9yZSBpbiBkZXB0aCBpbmZvcm1hdGlvbiBhYm91dCB0aGlz
IGV4Y2l0aW5nIGNvbXBhbnkNCmp1c3QgZG8gYSBzZWFyY2ggb24gTmFubyBT
dXBlcmxhdHRpY2UuDQoNClBsZWFzZSBSZWFkIEFsbCB0aGUgUmVjZW50IFBy
ZXNzIFJlbGVhc2VzIGFuZCBFeHBlY3Qgc29tZSANClJlYWxseSBCaWcgTmV3
cyBUaGlzIFVwY29taW5nIFdlZUshIQ0KDQoqKiBBQ1QgUVVJQ0ssIEdPT0Qg
TFVDSyAmIFRSQURFIE9VVCBUSEUgVE9QISEgICoqIA==


From ssu at thegeorgeinstitute.org  Mon Mar 27 07:05:19 2006
From: ssu at thegeorgeinstitute.org (Steve Su)
Date: Mon, 27 Mar 2006 16:05:19 +1100
Subject: [Rd] "sh" is not recognised as an internal or external command,
	operable program or batch file
Message-ID: <3B862D6B11ECDE458F679DDA238A135A1D82DA@lisa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060327/1ea0bd94/attachment.pl 

From andy_liaw at merck.com  Mon Mar 27 07:15:44 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Mar 2006 00:15:44 -0500
Subject: [Rd] "sh" is not recognised as an internal or external comman d,
 operable program or batch file
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED9D3@usctmx1106.merck.com>

That looks like the symptom of not following the documentation when trying
to build packages on Windows.  (You have not stated the platform.)  In that
case please check and see if you have the tools in Rtools.zip installed and
on the PATH.

Andy

From: Steve Su
> 
> Dear All,
> 
>  
> 
> I was trying to check my package using 
> 
>  
> 
> R CMD check GLDEX 
> 
>  
> 
> And I got the following error?
> 
>  
> 
> "sh" is not recognised as an internal or external command, 
> operable program or batch file
> 
>  
> 
> Can anyone let me know what might be the cause of this error?
> 
>  
> 
> Thanks.
> 
>  
> 
> Steve.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ggrothendieck at gmail.com  Mon Mar 27 07:42:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Mar 2006 00:42:34 -0500
Subject: [Rd] "sh" is not recognised as an internal or external comman d,
	operable program or batch file
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED9D3@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED9D3@usctmx1106.merck.com>
Message-ID: <971536df0603262142j292d5138n1765e72698086879@mail.gmail.com>

Also if you are running XP then get and run Rfind.bat from

http://cran.r-project.org/contrib/extra/batchfiles

Just run it without arguments and it will try to locate on your disk
and display all the prerequisites that you need.  If it can't find
anything then you know that that is the problem.


On 3/27/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> That looks like the symptom of not following the documentation when trying
> to build packages on Windows.  (You have not stated the platform.)  In that
> case please check and see if you have the tools in Rtools.zip installed and
> on the PATH.
>
> Andy
>
> From: Steve Su
> >
> > Dear All,
> >
> >
> >
> > I was trying to check my package using
> >
> >
> >
> > R CMD check GLDEX
> >
> >
> >
> > And I got the following error?
> >
> >
> >
> > "sh" is not recognised as an internal or external command,
> > operable program or batch file
> >
> >
> >
> > Can anyone let me know what might be the cause of this error?
> >
> >
> >
> > Thanks.
> >
> >
> >
> > Steve.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Mon Mar 27 08:47:38 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Mar 2006 08:47:38 +0200
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <44257DBE.2050000@stats.uwo.ca>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>
	<4424D394.7050204@stats.uwo.ca>
	<17445.28707.485402.183387@stat.math.ethz.ch>
	<44257DBE.2050000@stats.uwo.ca>
Message-ID: <17447.35466.623764.281536@stat.math.ethz.ch>

[from a semi-private diversion of the R-devel thread ]

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Sat, 25 Mar 2006 12:28:30 -0500 writes:

    Duncan> On 3/25/2006 11:30 AM, Martin Maechler wrote:
    >> Hi Duncan,
    >> 
    >> I think all ESS users don't use history() because ESS
    >> calls R with "--no-readline" (Unix) or "--ess" (Windows &
    >> Cygwin)
    >> 
    >> I'd wish that in that case, and probably also in BATCH
    >> mode, timestamp() should write the time stamp prefixed by
    >> "##" to the "R console" (to R's stdout); when people are
    >> using ESS properly, then rather than wanting a history,
    >> they save the R's buffer ("*R*") as "R transcript" (file
    >> typically ending with ".Rt" or ".Rout") and it makes much
    >> sense to have a time stampe entry in that file when
    >> others would want an entry in the history.

    Duncan> Thanks, that's a good suggestion.  Do you know what
    Duncan> the test is for this state, in either R or C code?
    Duncan> capabilities() doesn't do it.  Does ESS make itself
    Duncan> known to R code somehow?

Yes, when ESS starts  R (or S+) , it also issues 

  options(STERM='iESS')

and we (ESS core) thought that other GUIs / IDEs ideally should
also set "STERM"  - which AFAIK hasn't been adopted widely.

hence   if ( identical("iESS", getOption("STERM")) )  { 
	   ## are running 'inside ESS'
        }

should be pretty reliable.

Martin


From Friedrich.Leisch at tuwien.ac.at  Mon Mar 27 09:58:07 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch at tuwien.ac.at)
Date: Mon, 27 Mar 2006 09:58:07 +0200
Subject: [Rd] Sweaving in png
In-Reply-To: <442738C0.6020800@jhsph.edu>
References: <4423FE7D.8020907@biomserv.univ-lyon1.fr>
	<442738C0.6020800@jhsph.edu>
Message-ID: <17447.39695.821834.393844@celebrian.ci.tuwien.ac.at>


Yes, I have that on mmy 2do list for quite some time now. Could you
send me your patches to the code?

Fritz


>>>>> On Sun, 26 Mar 2006 19:58:40 -0500,
>>>>> Roger Peng (RP) wrote:

  > For what it's worth, I would find such a adaptation useful.
  > -roger

  > Thibaut Jombart wrote:
  >> Hello list, 
  >> 
  >> despite I already posted a mail on this topic on R help, I guess this place may be more appropriate.
  >> I'll make it shorter this time. Sorry for posting twice.
  >> 
  >> I found that using pixmap pictures in a Sweave document was sometimes almost impossible, due to the huge size of the pdf pictures produced.
  >> 
  >> The first solution I found was to save pictures in png, when too heavy in pdf. Here is an example:
  >> 
  >> ### in a .rnw document ###
  >> 
  >> % here is an invisible chunck to create a picture
  >> <<fig =FALSE,echo=FALSE>>=
  >> png(filename='figs/myPic.png')
  >> @
  >> 
  >> % next, R code to generate picture
  >> <<fig=FALSE,echo=TRUE>>=
  >> ...[code to produce the figure]
  >> @
  >> 
  >> % then, close the device. Hidden, again
  >> <<fig =FALSE,echo=FALSE>>=
  >> dev.off()
  >> @
  >> 
  >> % and then, include it as a picture
  >> \includegraphics{figs/myPic.png}
  >> 
  >> ### end of the example ###
  >> 
  >> I
  >> This is quite long, and I would have prefered to need simply: 
  >> 
  >> <<fig=TRUE,pdf=FALSE,png=TRUE>>
  >> ...[code to produce the figure]
  >> @
  >> 
  >> So I tried to adapte the Sweave driver 'RweaveLatex' in order to do so. It worked.
  >> 
  >> The not-so-new driver is only a slight modification of RweaveLatex, and can 
  >> generate ps, pdf or png figures; it was tested on Ubuntu64, Debian, 
  >> several Windows systems and macOS X partforms with no detected problem.
  >> 
  >> Does someone find this useful, and/or were there better solutions I missed?
  >> 
  >> Regards,
  >> 
  >> Thibaut Jombart .
  >> 

  > -- 
  > Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/

  > ______________________________________________
  > R-devel at r-project.org mailing list
  > https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.dondrup at cebitec.uni-bielefeld.de  Mon Mar 27 10:22:33 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Mon, 27 Mar 2006 10:22:33 +0200
Subject: [Rd] Operator masks in R, restrict set of applicable functions
Message-ID: <4427A0C9.90303@cebitec.uni-bielefeld.de>

Hi,
is there a way to restrict the set of admissible functions for an eval() 
statement to a possibly 'safe' set, excluding all potentially dangerous 
functions like 'system', 'open', etc.(like, for instance, in the 'Safe' 
module for Perl)?

The background for this question is, that this would be run in a 
CGI-environment. The user should be able to input some R-code (a 
function assignment), thereafter the code is parsed, evaluated and the 
type of function parameters checked by a call to 'formals'
like in:
 > expr <- parse(text='foo <- function(x = numeric()){mean(x)}')
 > eval(expr[1])
 > formals(foo)
$x
numeric()

of course, this is highly dangerous, given this setting, as one could try
 > expr <- parse(text='system("ls");
foo <- function(x = numeric()){mean(x)}') # or more evil things
 > eval(expr)

I know I could do something like
 > system <- function(...) stop ('This is not allowed!')
but it's rather likely to miss one of the 'bad' functions.

Any ideas would be appreciated.

Regards
Michael Dondrup


From ripley at stats.ox.ac.uk  Mon Mar 27 10:48:27 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Mar 2006 09:48:27 +0100 (BST)
Subject: [Rd] Operator masks in R, restrict set of applicable functions
In-Reply-To: <4427A0C9.90303@cebitec.uni-bielefeld.de>
References: <4427A0C9.90303@cebitec.uni-bielefeld.de>
Message-ID: <Pine.LNX.4.64.0603270933370.6974@gannet.stats.ox.ac.uk>

On Mon, 27 Mar 2006, Michael Dondrup wrote:

> Hi,
> is there a way to restrict the set of admissible functions for an eval()
> statement to a possibly 'safe' set, excluding all potentially dangerous
> functions like 'system', 'open', etc.(like, for instance, in the 'Safe'
> module for Perl)?

In short, no.  (BTW, what is unsafe about 'open'?  What are you trying to 
circumvent here?  E.g. unlink() might be on your list, as might file().)

The normal approach is to run R in an environment which restricts what the 
user can do: that should be sufficient to avoid unwanted file deletions, 
for example.

One could argue that a lot of these operations should be in a package 
other than base, but much of R is itself written in R and assumes them. 
(I did look into putting system() and file.*() in utils when the current 
organization of packages was made, but at least at the time they were too 
deeply embedded in other functionality.)

One idea would be to evaluate your expression in a strictly controlled 
environment of your own choosing, but there are ways for knowledgeable 
users to circumvent that (see below).

> The background for this question is, that this would be run in a
> CGI-environment. The user should be able to input some R-code (a
> function assignment), thereafter the code is parsed, evaluated and the
> type of function parameters checked by a call to 'formals'
> like in:
> > expr <- parse(text='foo <- function(x = numeric()){mean(x)}')
> > eval(expr[1])
> > formals(foo)
> $x
> numeric()
>
> of course, this is highly dangerous, given this setting, as one could try
> > expr <- parse(text='system("ls");
> foo <- function(x = numeric()){mean(x)}') # or more evil things
> > eval(expr)
>
> I know I could do something like
> > system <- function(...) stop ('This is not allowed!')
> but it's rather likely to miss one of the 'bad' functions.

But a user can use base::system, and load packages which could contain 
arbitrarily dangerous code (even its own compiled-code version of system).

>
> Any ideas would be appreciated.
>
> Regards
> Michael Dondrup
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Mon Mar 27 11:39:50 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 27 Mar 2006 17:39:50 +0800
Subject: [Rd] Suggest patch for princomp.formula and prcomp.formula
In-Reply-To: <Pine.LNX.4.64.0603262108450.15505@gannet.stats.ox.ac.uk>
References: <17445.13216.869157.615441@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.64.0603262108450.15505@gannet.stats.ox.ac.uk>
Message-ID: <17447.45798.736375.467072@bossiaea.maths.uwa.edu.au>

G'day Brian,

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    BDR> The proposed fix regretably will not work, since one can do
    BDR> things like

    BDR> library(MASS)
    BDR> prcomp(~ dist + dist:climb, hills)
Yes, I had the impression that this would work with the current
version but dismissed it as unintentional. ;-)

I wouldn't expect anyone to specify interaction terms in a principal
components analysis, but perhaps there are valid reasons to do so.

Attached is a slightly modified patch which still allows the above
example but also the changes that I proposed.  On my machine, R-devel
with this patch passes "make check FORCE=FORCE" and produces the
following output:

      > library(DAAG)
      > res <- prcomp(~ . - case - site - Pop - sex, possum)
      > res <- princomp(~ . - case - site - Pop - sex, possum)
      > res <- prcomp(~ . - case - site - Pop, possum)
      Error in prcomp.formula(~. - case - site - Pop, possum) : 
      	PCA applies only to numerical variables
      > res <- princomp(~ . - case - site - Pop, possum)
      Error in princomp.formula(~. - case - site - Pop, possum) : 
      	PCA applies only to numerical variables
      > library(MASS)
      
      Attaching package: 'MASS'
      
      
      	The following object(s) are masked from package:DAAG :
      
      	 hills 
      
      > prcomp(~ dist + dist:climb, hills)
      Standard deviations:
      [1] 29655.128279     3.101566
      
      Rotation:
                          PC1          PC2
      dist       -0.000154139 -0.999999988
      dist:climb -0.999999988  0.000154139

Cheers,

        Berwin

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060327/07c910e4/attachment.pl 

From toby at abdn.ac.uk  Mon Mar 27 12:55:27 2006
From: toby at abdn.ac.uk (toby at abdn.ac.uk)
Date: Mon, 27 Mar 2006 12:55:27 +0200 (CEST)
Subject: [Rd] ?symbols man page (PR#8713)
Message-ID: <20060327105527.2CD693FCAB@slim.kubism.ku.dk>

Full_Name: TOBY MARTHEWS
Version: 2.2.1
OS: Windows XP
Submission from: (NULL) (139.133.7.37)


Just a small one, but it did trip me up today. On the ?symbols man page the
following paragraph:

  inches: If 'inches' is 'FALSE', the units are taken to be those of
          the x axis...

should say:

  inches: If 'inches' is 'FALSE', the units are taken to be those of
          the y axis...

Thanks,
Toby


From hb at maths.lth.se  Mon Mar 27 13:21:51 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 27 Mar 2006 13:21:51 +0200
Subject: [Rd] Safe to UNPROTECT() when object is assigned to a list?
Message-ID: <59d7961d0603270321j3d8ab3c7wdc78ad42eae7b5ca@mail.gmail.com>

Hi,

I'm troubleshooting some native code on Windows that very occationally
(and semi-randomly) crashes R.  Already looked at "everything", I just
want to double check that it is safe to UNPROTECT() allocated
variables as soon as they are assigned to, say, a PROTECTed list.

>From (R v2.3.0) Section 5.7.1 "Handling the effects of garbage
collection" in "Writing R Extensions":

"In some cases it is necessary to keep better track of whether
protection is really needed. Be particularly aware of situations where
a large number of objects are generated. The pointer protection stack
has a fixed size (default 10,000) and can become full. It is not a
good idea then to just PROTECT everything in sight and UNPROTECT
several thousand objects at the end. It will almost invariably 
possible to either assign the objects as part of another object (which
automatically protects them) or unprotect them immediately after use."

BTW, should it say "...another [protected] object..."?

Example from "5.7.4 Attributes" illustrating my question:

     SEXP out(SEXP x, SEXP y)
     {
       R_len_t i, j, nx, ny;
       double tmp;
       SEXP ans, dim, dimnames;

       nx = length(x); ny = length(y);
       PROTECT(ans = allocVector(REALSXP, nx*ny));
       for(i = 0; i < nx; i++) {
         tmp = REAL(x)[i];
         for(j = 0; j < ny; j++)
           REAL(ans)[i + nx*j] = tmp * REAL(y)[j];
       }

       PROTECT(dim = allocVector(INTSXP, 2));
       INTEGER(dim)[0] = nx; INTEGER(dim)[1] = ny;
       setAttrib(ans, R_DimSymbol, dim);

       *** It is safe to do UNPROTECT(1) for 'dim' already here, correct? ***

       PROTECT(dimnames = allocVector(VECSXP, 2));
       SET_VECTOR_ELT(dimnames, 0, getAttrib(x, R_NamesSymbol));
       SET_VECTOR_ELT(dimnames, 1, getAttrib(y, R_NamesSymbol));
       setAttrib(ans, R_DimNamesSymbol, dimnames);

       UNPROTECT(3);
       return(ans);
     }

Thanks

/Henrik


From murdoch at stats.uwo.ca  Mon Mar 27 13:54:01 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 27 Mar 2006 06:54:01 -0500
Subject: [Rd] Help please: please test timestamping of command history
In-Reply-To: <17447.35466.623764.281536@stat.math.ethz.ch>
References: <002001c64ee8$415b9ce0$c1e66081@bio.flinders.edu.au>	<4424D394.7050204@stats.uwo.ca>	<17445.28707.485402.183387@stat.math.ethz.ch>	<44257DBE.2050000@stats.uwo.ca>
	<17447.35466.623764.281536@stat.math.ethz.ch>
Message-ID: <4427D259.2000201@stats.uwo.ca>

On 3/27/2006 1:47 AM, Martin Maechler wrote:
> [from a semi-private diversion of the R-devel thread ]
> 
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Sat, 25 Mar 2006 12:28:30 -0500 writes:
> 
>     Duncan> On 3/25/2006 11:30 AM, Martin Maechler wrote:
>     >> Hi Duncan,
>     >> 
>     >> I think all ESS users don't use history() because ESS
>     >> calls R with "--no-readline" (Unix) or "--ess" (Windows &
>     >> Cygwin)
>     >> 
>     >> I'd wish that in that case, and probably also in BATCH
>     >> mode, timestamp() should write the time stamp prefixed by
>     >> "##" to the "R console" (to R's stdout); when people are
>     >> using ESS properly, then rather than wanting a history,
>     >> they save the R's buffer ("*R*") as "R transcript" (file
>     >> typically ending with ".Rt" or ".Rout") and it makes much
>     >> sense to have a time stampe entry in that file when
>     >> others would want an entry in the history.
> 
>     Duncan> Thanks, that's a good suggestion.  Do you know what
>     Duncan> the test is for this state, in either R or C code?
>     Duncan> capabilities() doesn't do it.  Does ESS make itself
>     Duncan> known to R code somehow?
> 
> Yes, when ESS starts  R (or S+) , it also issues 
> 
>   options(STERM='iESS')
> 
> and we (ESS core) thought that other GUIs / IDEs ideally should
> also set "STERM"  - which AFAIK hasn't been adopted widely.
> 
> hence   if ( identical("iESS", getOption("STERM")) )  { 
> 	   ## are running 'inside ESS'
>         }
> 
> should be pretty reliable.

Thanks.  The version that I committed yesterday defaulted to writing the 
timestamp to the console as well as the history.  Could you take a look, 
and let me know if some special ESS behaviour is still needed?

Duncan


From p.dalgaard at biostat.ku.dk  Mon Mar 27 14:34:52 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Mar 2006 14:34:52 +0200
Subject: [Rd] R 2.3.0 scheduled for April 24, Grand-Feature freeze is active
Message-ID: <x2zmjc6p77.fsf@viggo.kubism.ku.dk>


The release of version 2.3.0 has been scheduled for April 24, 2006.

The first alpha release should be available later today, once I have
reviewed the build scripts.

The detailed release schedule is as follows


March 27:

    Declare start of release process. The build process is assumed to
    be essentially in place at this time.

    There is a "grand feature" freeze (minor tweaks can be applied,
    but no wholesale restructuring or API changes). Notice that
    wrapping a package in a namespace is a grand feature, and so is
    meddling with the event loop.

    Package maintainers should start adapting to any changes in base.

    Start making R-2.3.0-alpha.tar.gz packages automatically available.

April 10:

    Feature freeze, simultaneously on base and recommended packages.
    It is assumed that all recommended packages pass their checks at
    this point. The API should not be touched.

    Start making R-2.3.0-beta.tar.gz packages automatically available.

    NEW:
    The R-2-3-patches SVN branch is created at this point.


April 17:

    Code freeze. Only critical and/or trivial bugs fixed from this
    time onwards. Configure/make should only be touched in
    emergencies. 

    NEW:
    Start making R-2.3.0-rc.tar.gz packages automatically available.

April 24:

    Release.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Mon Mar 27 14:54:37 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Mar 2006 14:54:37 +0200
Subject: [Rd] Safe to UNPROTECT() when object is assigned to a list?
In-Reply-To: <59d7961d0603270321j3d8ab3c7wdc78ad42eae7b5ca@mail.gmail.com>
References: <59d7961d0603270321j3d8ab3c7wdc78ad42eae7b5ca@mail.gmail.com>
Message-ID: <x2veu06oaa.fsf@viggo.kubism.ku.dk>

"Henrik Bengtsson" <hb at maths.lth.se> writes:

> Hi,
> 
> I'm troubleshooting some native code on Windows that very occationally
> (and semi-randomly) crashes R.  Already looked at "everything", I just
> want to double check that it is safe to UNPROTECT() allocated
> variables as soon as they are assigned to, say, a PROTECTed list.
> 
> >From (R v2.3.0) Section 5.7.1 "Handling the effects of garbage
> collection" in "Writing R Extensions":
> 
> "In some cases it is necessary to keep better track of whether
> protection is really needed. Be particularly aware of situations where
> a large number of objects are generated. The pointer protection stack
> has a fixed size (default 10,000) and can become full. It is not a
> good idea then to just PROTECT everything in sight and UNPROTECT
> several thousand objects at the end. It will almost invariably 
> possible to either assign the objects as part of another object (which
> automatically protects them) or unprotect them immediately after use."
> 
> BTW, should it say "...another [protected] object..."?

Yes. (And the text could need general rephrasing too. I'm afraid that
I'm the guilty party.)

 
> Example from "5.7.4 Attributes" illustrating my question:
> 
>      SEXP out(SEXP x, SEXP y)
>      {
>        R_len_t i, j, nx, ny;
>        double tmp;
>        SEXP ans, dim, dimnames;
> 
>        nx = length(x); ny = length(y);
>        PROTECT(ans = allocVector(REALSXP, nx*ny));
>        for(i = 0; i < nx; i++) {
>          tmp = REAL(x)[i];
>          for(j = 0; j < ny; j++)
>            REAL(ans)[i + nx*j] = tmp * REAL(y)[j];
>        }
> 
>        PROTECT(dim = allocVector(INTSXP, 2));
>        INTEGER(dim)[0] = nx; INTEGER(dim)[1] = ny;
>        setAttrib(ans, R_DimSymbol, dim);
> 
>        *** It is safe to do UNPROTECT(1) for 'dim' already here, correct? ***

Yes. The protection of "ans" will carry over to its attributes. 

>        PROTECT(dimnames = allocVector(VECSXP, 2));
>        SET_VECTOR_ELT(dimnames, 0, getAttrib(x, R_NamesSymbol));
>        SET_VECTOR_ELT(dimnames, 1, getAttrib(y, R_NamesSymbol));
>        setAttrib(ans, R_DimNamesSymbol, dimnames);
> 
>        UNPROTECT(3);
>        return(ans);
>      }
> 
> Thanks
> 
> /Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Mon Mar 27 15:59:00 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 27 Mar 2006 15:59:00 +0200
Subject: [Rd] Creating a package bundle.
In-Reply-To: <3B862D6B11ECDE458F679DDA238A135A1D82D9@lisa>
References: <3B862D6B11ECDE458F679DDA238A135A1D82D9@lisa>
Message-ID: <4427EFA4.4090200@statistik.uni-dortmund.de>

Steve Su wrote:

> Dear All,
> 
>  
> 
> What is the easiest way to create a package bundle in R? I have three
> packages I would like to group together in which one package will
> depends on three others. It looks like from
> 
> http://tolstoy.newcastle.edu.au/R/help/01a/0284.html, all that is
> required is to put require in the .First? I wonder how one can create a
> package so that when it is downloaded,
> 
> all the other packages are downloaded and installed as well? In my case,
> the three sub packages are not written by me and are already in R so I
> would like to keep the current


Perhaps you simply want to use

   install.packages("the_package", dependencies = TRUE)

rather than building a package bundle of packages you are not 
maintaining yourself.


Uwe Ligges


> versions as part of the bundle rather than allow them to get updated so
> there will not be compatibility problems?
> 
>  
> 
> I am aware there is a writing R extensions guide but it seems to be
> geared towards a more advanced user rather than beginner like me?
> 
>  
> 
> Thanks in advance.
> 
>  
> 
> Steve.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.dalgaard at biostat.ku.dk  Mon Mar 27 16:14:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Mar 2006 16:14:27 +0200
Subject: [Rd] R 2.3.0 scheduled for April 24,
	Grand-Feature freeze is active
In-Reply-To: <x2zmjc6p77.fsf@viggo.kubism.ku.dk>
References: <x2zmjc6p77.fsf@viggo.kubism.ku.dk>
Message-ID: <x2r74o6kl8.fsf@viggo.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> The release of version 2.3.0 has been scheduled for April 24, 2006.
> 
> The first alpha release should be available later today, once I have
> reviewed the build scripts.

Done. The first version is now sitting in 

  http://biostat.ku.dk/~pd/R-pre

Further preliminary source releases will be made by a cron job at 4:05
(CET) each morning until release, provided the build process completes
without error. Notice that the releases are only MINIMALLY CHECKED, we
rely on your verification to get the remaining bugs out before the
final release.

They will be mirrored fairly quickly at the CRAN master site in
Vienna, but might not percolate to the rest of CRAN before a new
version has been made.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From sfalcon at fhcrc.org  Mon Mar 27 16:28:50 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 27 Mar 2006 06:28:50 -0800
Subject: [Rd] Creating a package bundle.
In-Reply-To: <3B862D6B11ECDE458F679DDA238A135A1D82D9@lisa> (Steve Su's message
	of "Mon, 27 Mar 2006 15:06:37 +1100")
References: <3B862D6B11ECDE458F679DDA238A135A1D82D9@lisa>
Message-ID: <m21wwootb1.fsf@ziti.local>

Hi Steve,

Are you sure you want a bundle?  If you are writing your own package
Foo that depends on two pacakges already available via CRAN, then all
you need to do is list those two pacakges in the Depends field of your
package's DESCRIPTION file.

This will give you the automatic downloading of Foo's dependencies
when a user does: install.packages("foo", dependencies=TRUE)

As for the versions, you can specify required versions also in the
Depends field (see the writing R extensions guide).

+ seth


From toby at abdn.ac.uk  Mon Mar 27 18:30:42 2006
From: toby at abdn.ac.uk (toby at abdn.ac.uk)
Date: Mon, 27 Mar 2006 18:30:42 +0200 (CEST)
Subject: [Rd] not a problem: a submission (PR#8714)
Message-ID: <20060327163042.A354B3EFF4@slim.kubism.ku.dk>

Full_Name: TOBY MARTHEWS
Version: 2.1.1
OS: Windows XP
Submission from: (NULL) (139.133.7.38)


I think you should have better examples on the ?plot man page, if you don't mind
me saying. Can I suggest something like this, which would probably stop so many
emails to the R help about how to put on error bars

Cheers,
Toby M
******************************

xvalsT1=1:3
yvalsT1=c(10,20,30)
errplusT1=c(2,3,4)
errminusT1=c(9,8,7)
xvalsT2=1:3
yvalsT2=c(30,35,40)
errplusT2=c(12,13,14)
errminusT2=c(1,2,3)
treatment=c(rep("T1",times=length(xvalsT1)),rep("T2",times=length(xvalsT2)))

xvals=c(xvalsT1,xvalsT2)
yvals=c(yvalsT1,yvalsT2)
errplus=c(errplusT1,errplusT2)
errminus=c(errminusT1,errminusT2)
RGR=data.frame(treatment,xvals,yvals,errplus,errminus)

minx=min(RGR$xvals);maxx=max(RGR$xvals)
miny=min(RGR$yvals-RGR$errminus);maxy=max(RGR$yvals+RGR$errplus)
plot(x=0,y=0,type="n",xlim=c(minx,maxx),ylim=c(miny,maxy),lab=c(2,4,0),xlab="month",ylab="Relative
Growth Rate",axes=FALSE)
axis(1,at=1:3,month.abb[1:3])        #axis(1,at=1:3,labels=c("Jan","Feb","Mar"))
has the
same effect
axis(2)

trts=c("T1","T2");syms=c(21,24)
for (i in 1:2) {
 A=subset(RGR,treatment==trts[i])
 points(x=A$xvals,y=A$yvals,pch=syms[i])
 segments(A$xvals,A$yvals-A$errminus,A$xvals,A$yvals+A$errplus)        #similar
to
symbols(x=A$xvals,y=A$yvals,boxplots=cbind(0,0,A$errminus,A$errplus,0.5),inches=FALSE,add=TRUE)
 errwidth=0.015
 segments(A$xvals-errwidth,A$yvals+A$errplus,A$xvals+errwidth,A$yvals+A$errplus)
 segments(A$xvals-errwidth,A$yvals-A$errminus,A$xvals+errwidth,A$yvals-A$errminus)
 lines(x=A$xvals,y=A$yvals,lty=syms[i])
}
#PS - this is a bit of an inelegant way to put on error bars, but to do better
you
#have to use commands like plotCI {gplots} or xYplot {Hmisc} - to learn more
look at
RSiteSearch("error bars")

legend(x=2.7,y=9,trts,pch=syms)        #in same units as the axes


From michael.dondrup at cebitec.uni-bielefeld.de  Mon Mar 27 18:59:09 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Mon, 27 Mar 2006 18:59:09 +0200
Subject: [Rd] Operator masks in R, restrict set of applicable functions
In-Reply-To: <Pine.LNX.4.64.0603270933370.6974@gannet.stats.ox.ac.uk>
References: <4427A0C9.90303@cebitec.uni-bielefeld.de>
	<Pine.LNX.4.64.0603270933370.6974@gannet.stats.ox.ac.uk>
Message-ID: <442819DD.1000300@cebitec.uni-bielefeld.de>

Thank you very much,
Sorry for bothering again, but how about this:

 > assignInNamespace('system',function(...)stop('No system!'),'base')
 > system()
Error in system() : No system!
 > base::system()
Error in base::system() : No system!
 > detach(package:utils) # no way back?

I guess there is a way to circumvent that, too?
Of course, if it works, it's tideous work to do this for all unsafe 
functions (of course: file, url, unlink, dyn.load,...,  maybe I'm just 
too cautious )
I would really  like to chroot the R-process, and agree it would be the 
best option, but I'm using RSPerl, which loads R.so. Hence, I cannot 
restrict R-code more than the web-server(at least I think so). Though 
this would be necessary, as the web-server accesses some files that 
unsafe code should never even be able to read, including the cgi-scripts.

Thank you again
Michael


Prof Brian Ripley wrote:
> On Mon, 27 Mar 2006, Michael Dondrup wrote:
> 
> 
>>Hi,
>>is there a way to restrict the set of admissible functions for an eval()
>>statement to a possibly 'safe' set, excluding all potentially dangerous
>>functions like 'system', 'open', etc.(like, for instance, in the 'Safe'
>>module for Perl)?
> 
> 
> In short, no.  (BTW, what is unsafe about 'open'?  What are you trying to 
> circumvent here?  E.g. unlink() might be on your list, as might file().)
> 
> The normal approach is to run R in an environment which restricts what the 
> user can do: that should be sufficient to avoid unwanted file deletions, 
> for example.
> 
> One could argue that a lot of these operations should be in a package 
> other than base, but much of R is itself written in R and assumes them. 
> (I did look into putting system() and file.*() in utils when the current 
> organization of packages was made, but at least at the time they were too 
> deeply embedded in other functionality.)
> 
> One idea would be to evaluate your expression in a strictly controlled 
> environment of your own choosing, but there are ways for knowledgeable 
> users to circumvent that (see below).
> 
> 
>>The background for this question is, that this would be run in a
>>CGI-environment. The user should be able to input some R-code (a
>>function assignment), thereafter the code is parsed, evaluated and the
>>type of function parameters checked by a call to 'formals'
>>like in:
>>
>>>expr <- parse(text='foo <- function(x = numeric()){mean(x)}')
>>>eval(expr[1])
>>>formals(foo)
>>
>>$x
>>numeric()
>>
>>of course, this is highly dangerous, given this setting, as one could try
>>
>>>expr <- parse(text='system("ls");
>>
>>foo <- function(x = numeric()){mean(x)}') # or more evil things
>>
>>>eval(expr)
>>
>>I know I could do something like
>>
>>>system <- function(...) stop ('This is not allowed!')
>>
>>but it's rather likely to miss one of the 'bad' functions.
> 
> 
> But a user can use base::system, and load packages which could contain 
> arbitrarily dangerous code (even its own compiled-code version of system).
> 
> 
>>Any ideas would be appreciated.
>>
>>Regards
>>Michael Dondrup
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> 


-- 
Dipl. Inform. Michael Dondrup
CeBiTec - http://www.cebitec.uni-bielefeld.de/~mdondrup
Bielefeld University,  D-33594 Bielefeld, Germany


From ripley at stats.ox.ac.uk  Mon Mar 27 19:33:01 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Mar 2006 18:33:01 +0100 (BST)
Subject: [Rd] Operator masks in R, restrict set of applicable functions
In-Reply-To: <442819DD.1000300@cebitec.uni-bielefeld.de>
References: <4427A0C9.90303@cebitec.uni-bielefeld.de>
	<Pine.LNX.4.64.0603270933370.6974@gannet.stats.ox.ac.uk>
	<442819DD.1000300@cebitec.uni-bielefeld.de>
Message-ID: <Pine.LNX.4.64.0603271816380.17917@gannet.stats.ox.ac.uk>

On Mon, 27 Mar 2006, Michael Dondrup wrote:

> Thank you very much,
> Sorry for bothering again, but how about this:
>
>> assignInNamespace('system',function(...)stop('No system!'),'base')
>> system()
> Error in system() : No system!
>> base::system()
> Error in base::system() : No system!
>> detach(package:utils) # no way back?
>
> I guess there is a way to circumvent that, too?

Yes.  For base::system is just

> system
function (command, intern = FALSE, ignore.stderr = FALSE)
.Internal(system(if (ignore.stderr) paste(command, "2>/dev/null") else 
command,
     intern))
<environment: namespace:base>

so you can just call the .Internal.

If designing R from scratch it would be a good idea to separate out all 
the 'unsafe' (for a suitable definition) function and provide ways to lock 
their internal code.  Some of this would be fairly easy to do (e.g. 
disabling the internals of system), but I am not sure a partial solution 
would be much help.  And disabling dyn.load would be almost impossible in 
general use, as that would stop standard packages being loaded, and they 
are loaded after user code (e.g. .Rprofile) is run.

> Of course, if it works, it's tideous work to do this for all unsafe functions 
> (of course: file, url, unlink, dyn.load,...,  maybe I'm just too cautious )
> I would really  like to chroot the R-process, and agree it would be the best 
> option, but I'm using RSPerl, which loads R.so. Hence, I cannot restrict 
> R-code more than the web-server(at least I think so).

That is not clear to me.  I thought you mentioned CGI, not a server 
extension, so my understanding was that R was running in a separate 
process from the server.

> Though this would be 
> necessary, as the web-server accesses some files that unsafe code should 
> never even be able to read, including the cgi-scripts.
>
> Thank you again
> Michael
>
>
> Prof Brian Ripley wrote:
>> On Mon, 27 Mar 2006, Michael Dondrup wrote:
>> 
>> 
>>> Hi,
>>> is there a way to restrict the set of admissible functions for an eval()
>>> statement to a possibly 'safe' set, excluding all potentially dangerous
>>> functions like 'system', 'open', etc.(like, for instance, in the 'Safe'
>>> module for Perl)?
>> 
>> 
>> In short, no.  (BTW, what is unsafe about 'open'?  What are you trying to 
>> circumvent here?  E.g. unlink() might be on your list, as might file().)
>> 
>> The normal approach is to run R in an environment which restricts what the 
>> user can do: that should be sufficient to avoid unwanted file deletions, 
>> for example.
>> 
>> One could argue that a lot of these operations should be in a package other 
>> than base, but much of R is itself written in R and assumes them. (I did 
>> look into putting system() and file.*() in utils when the current 
>> organization of packages was made, but at least at the time they were too 
>> deeply embedded in other functionality.)
>> 
>> One idea would be to evaluate your expression in a strictly controlled 
>> environment of your own choosing, but there are ways for knowledgeable 
>> users to circumvent that (see below).
>> 
>> 
>>> The background for this question is, that this would be run in a
>>> CGI-environment. The user should be able to input some R-code (a
>>> function assignment), thereafter the code is parsed, evaluated and the
>>> type of function parameters checked by a call to 'formals'
>>> like in:
>>> 
>>>> expr <- parse(text='foo <- function(x = numeric()){mean(x)}')
>>>> eval(expr[1])
>>>> formals(foo)
>>> 
>>> $x
>>> numeric()
>>> 
>>> of course, this is highly dangerous, given this setting, as one could try
>>> 
>>>> expr <- parse(text='system("ls");
>>> 
>>> foo <- function(x = numeric()){mean(x)}') # or more evil things
>>> 
>>>> eval(expr)
>>> 
>>> I know I could do something like
>>> 
>>>> system <- function(...) stop ('This is not allowed!')
>>> 
>>> but it's rather likely to miss one of the 'bad' functions.
>> 
>> 
>> But a user can use base::system, and load packages which could contain 
>> arbitrarily dangerous code (even its own compiled-code version of system).
>> 
>> 
>>> Any ideas would be appreciated.
>>> 
>>> Regards
>>> Michael Dondrup
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jtlindgr at cs.Helsinki.FI  Mon Mar 27 20:43:16 2006
From: jtlindgr at cs.Helsinki.FI (jtlindgr at cs.Helsinki.FI)
Date: Mon, 27 Mar 2006 20:43:16 +0200 (CEST)
Subject: [Rd] Matrix inner product crashes on x86_64 (PR#8715)
Message-ID: <20060327184316.9849042658@slim.kubism.ku.dk>


Matrix inner product seems to crash R2.2.1 on a 64bit arch. 
More precisely, the crash happens atleast if the matrix is 
non-square. The bug can be reproduced (atleast here) with

bash$ bin/R
> X<-matrix(data=0,nrow=100,ncol=10);
> mat<-X%*%t(X);
Illegal instruction
bash$

The crash doesnt happen if the matrix is specified square,
e.g. 10x10. The underlying OS was

Linux version 2.6.12-xeon-csl3 (root at chuck) (gcc version 3.4.5 20050809 (prerelease) (Ubuntu 3.4.4-6ubuntu8)) #1 SMP Wed Feb 22 18:34:17 EET 2006

and its running on Intel(R) Xeon(TM) MP CPU 3.66GHz.

I configured R from the source tar.gz myself; each phase of 
"./configure --with-x=no ; make ; make install" 
passed without aborting on any errors.


Cheers,
J.

--please do not edit the information below--

Version:
 platform = x86_64-unknown-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=fi_FI at euro;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.ISO-8859-15;LC_MONETARY=fi_FI at euro;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From ripley at stats.ox.ac.uk  Mon Mar 27 21:05:20 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 27 Mar 2006 21:05:20 +0200 (CEST)
Subject: [Rd] Matrix inner product crashes on x86_64 (PR#8715)
Message-ID: <20060327190520.767B04269A@slim.kubism.ku.dk>

Not reproducible for me (and do you really think that something as simple 
as this would not have been found on x86_64 long before now?)

This is almost certainly caused by your use of an inappropriate external 
BLAS.  Something has probably been compiled for a different processor than 
the one you are using, since illegal instructions are a compiler (not R) 
issue that I have seen quite often on ix86 systems when this happened.

Use --without-blas when recompiling R and see if it then works.

On Mon, 27 Mar 2006, jtlindgr at cs.helsinki.fi wrote:

>
> Matrix inner product seems to crash R2.2.1 on a 64bit arch.
> More precisely, the crash happens atleast if the matrix is
> non-square. The bug can be reproduced (atleast here) with
>
> bash$ bin/R
>> X<-matrix(data=0,nrow=100,ncol=10);
>> mat<-X%*%t(X);
> Illegal instruction
> bash$
>
> The crash doesnt happen if the matrix is specified square,
> e.g. 10x10. The underlying OS was
>
> Linux version 2.6.12-xeon-csl3 (root at chuck) (gcc version 3.4.5 20050809 (prerelease) (Ubuntu 3.4.4-6ubuntu8)) #1 SMP Wed Feb 22 18:34:17 EET 2006
>
> and its running on Intel(R) Xeon(TM) MP CPU 3.66GHz.
>
> I configured R from the source tar.gz myself; each phase of
> "./configure --with-x=no ; make ; make install"
> passed without aborting on any errors.
>
>
> Cheers,
> J.
>
> --please do not edit the information below--
>
> Version:
> platform = x86_64-unknown-linux-gnu
> arch = x86_64
> os = linux-gnu
> system = x86_64, linux-gnu
> status =
> major = 2
> minor = 2.1
> year = 2005
> month = 12
> day = 20
> svn rev = 36812
> language = R
>
> Locale:
> LC_CTYPE=fi_FI at euro;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.ISO-8859-15;LC_MONETARY=fi_FI at euro;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jtlindgr at cs.Helsinki.FI  Mon Mar 27 21:40:43 2006
From: jtlindgr at cs.Helsinki.FI (jtlindgr at cs.Helsinki.FI)
Date: Mon, 27 Mar 2006 21:40:43 +0200 (CEST)
Subject: [Rd] Matrix inner product crashes on x86_64 (PR#8715)
Message-ID: <20060327194043.0B4FC4264E@slim.kubism.ku.dk>

On Mon, 27 Mar 2006, Prof Brian Ripley wrote:

> Not reproducible for me (and do you really think that something as simple as
> this would not have been found on x86_64 long before now?)
> This is almost certainly caused by your use of an inappropriate external BLAS.
> Something has probably been compiled for a different processor than the one
> you are using, since illegal instructions are a compiler (not R) issue that I
> have seen quite often on ix86 systems when this happened.
> Use --without-blas when recompiling R and see if it then works.

Thank you for the prompt reply. Disabling the external BLAS fixed
the problem as you suspected. 

(As a minor curiosity, the problem was not caught by any tests 
ran by make check or make check-all -- but I do not presume here 
to speculate or guess whether the tests try out any such matrix 
calculations or not.). :)


Thanks again,
J.


> 
> On Mon, 27 Mar 2006, jtlindgr at cs.helsinki.fi wrote:
> 
> > 
> > Matrix inner product seems to crash R2.2.1 on a 64bit arch.
> > More precisely, the crash happens atleast if the matrix is
> > non-square. The bug can be reproduced (atleast here) with
> > 
> > bash$ bin/R
> > > X<-matrix(data=0,nrow=100,ncol=10);
> > > mat<-X%*%t(X);
> > Illegal instruction
> > bash$
> > 
> > The crash doesnt happen if the matrix is specified square,
> > e.g. 10x10. The underlying OS was
> > 
> > Linux version 2.6.12-xeon-csl3 (root at chuck) (gcc version 3.4.5 20050809
> > (prerelease) (Ubuntu 3.4.4-6ubuntu8)) #1 SMP Wed Feb 22 18:34:17 EET 2006
> > 
> > and its running on Intel(R) Xeon(TM) MP CPU 3.66GHz.
> > 
> > I configured R from the source tar.gz myself; each phase of
> > "./configure --with-x=no ; make ; make install"
> > passed without aborting on any errors.
> > 
> > 
> > Cheers,
> > J.
> > 
> > --please do not edit the information below--
> > 
> > Version:
> > platform = x86_64-unknown-linux-gnu
> > arch = x86_64
> > os = linux-gnu
> > system = x86_64, linux-gnu
> > status =
> > major = 2
> > minor = 2.1
> > year = 2005
> > month = 12
> > day = 20
> > svn rev = 36812
> > language = R
> > 
> > Locale:
> > LC_CTYPE=fi_FI at euro;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.IS
> > O-8859-15;LC_MONETARY=fi_FI at euro;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=C;LC_N
> > AME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
> > 
> > Search Path:
> > .GlobalEnv, package:methods, package:stats, package:graphics,
> > package:grDevices, package:utils, package:datasets, Autoloads, package:base
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
> 
>


From Rbugs06 at kreil.org  Mon Mar 27 22:22:27 2006
From: Rbugs06 at kreil.org (Rbugs06 at kreil.org)
Date: Mon, 27 Mar 2006 22:22:27 +0200 (CEST)
Subject: [Rd] sink(..., split=T) gives segmentation fault (PR#8716)
Message-ID: <20060327202227.48A564264D@slim.kubism.ku.dk>

Full_Name: D Kreil
Version: R 2.2.1 (2005-12-20).
OS: Linux, Fedora FC4
Submission from: (NULL) (62.178.15.60)


sink("filename",split=T);
cat("sometext\n");
for (...) {
  cat(some terms);
}

reproducibly gives a segmentation fault. No other problems with this
installation.
Removing the split=T fixes the crash.

uname -a gives:
Linux aton.boku.ac.at 2.6.15-1.1831_FC4smp #1 SMP Tue Feb 7 13:51:52 EST 2006
x86_64 x86_64 x86_64 GNU/Linux


From pinard at progiciels-bpi.ca  Tue Mar 28 03:00:19 2006
From: pinard at progiciels-bpi.ca (pinard at progiciels-bpi.ca)
Date: Tue, 28 Mar 2006 03:00:19 +0200 (CEST)
Subject: [Rd] Error once having applied (PR#8718)
Message-ID: <20060328010019.0BD20ECD9@slim.kubism.ku.dk>

Hi, people.  Here is a transcript of a "R --vanilla" session:

======================================================================>

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.1  (2005-12-20 r36812)
ISBN 3-900051-07-0

R est un logiciel libre livr?? sans AUCUNE GARANTIE.
Vous pouvez le redistribuer sous certaines conditions.
Tapez 'license()' ou 'licence()' pour plus de d??tails.

R est un projet collaboratif avec de nombreux contributeurs.
Tapez 'contributors()' pour plus d'information et
'citation()' pour la fa??on de le citer dans les publications.

Tapez 'demo()' pour des d??monstrations, 'help()' pour l'aide
en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
Tapez 'q()' pour quitter R.

> z = data.frame(a=0:9, b=10:19)
> apply(z, 1, sum)
 1  2  3  4  5  6  7  8  9 10
10 12 14 16 18 20 22 24 26 28
> apply(z, 1, '$', 'a')
NULL
> apply(z, 1, sum)
Erreur dans sum(..., na.rm = na.rm) : 'mode' de l'argument incorrect
======================================================================<

There are three explicit calls to "apply", one would expect the first
and the third to yield similar results.  They do indeed, if the second
"apply" is not executed, or if '$' gets replaced by '[[' within it.  So
the second "apply", as written, may be hurting the R interpreter.

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From ripley at stats.ox.ac.uk  Tue Mar 28 08:11:23 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 28 Mar 2006 08:11:23 +0200 (CEST)
Subject: [Rd] Matrix inner product crashes on x86_64 (PR#8715)
Message-ID: <20060328061123.4D6BDE93A@slim.kubism.ku.dk>

On Mon, 27 Mar 2006, Jussi T Lindgren wrote:

> On Mon, 27 Mar 2006, Prof Brian Ripley wrote:
>
>> Not reproducible for me (and do you really think that something as simple as
>> this would not have been found on x86_64 long before now?)
>> This is almost certainly caused by your use of an inappropriate external BLAS.
>> Something has probably been compiled for a different processor than the one
>> you are using, since illegal instructions are a compiler (not R) issue that I
>> have seen quite often on ix86 systems when this happened.
>> Use --without-blas when recompiling R and see if it then works.
>
> Thank you for the prompt reply. Disabling the external BLAS fixed
> the problem as you suspected.
>
> (As a minor curiosity, the problem was not caught by any tests
> ran by make check or make check-all -- but I do not presume here
> to speculate or guess whether the tests try out any such matrix
> calculations or not.). :)

They do.  What the BLAS does will depend on the exact dimensions, so there 
will be very many paths through its code.

>
>
> Thanks again,
> J.
>
>
>>
>> On Mon, 27 Mar 2006, jtlindgr at cs.helsinki.fi wrote:
>>
>>>
>>> Matrix inner product seems to crash R2.2.1 on a 64bit arch.
>>> More precisely, the crash happens atleast if the matrix is
>>> non-square. The bug can be reproduced (atleast here) with
>>>
>>> bash$ bin/R
>>>> X<-matrix(data=0,nrow=100,ncol=10);
>>>> mat<-X%*%t(X);
>>> Illegal instruction
>>> bash$
>>>
>>> The crash doesnt happen if the matrix is specified square,
>>> e.g. 10x10. The underlying OS was
>>>
>>> Linux version 2.6.12-xeon-csl3 (root at chuck) (gcc version 3.4.5 20050809
>>> (prerelease) (Ubuntu 3.4.4-6ubuntu8)) #1 SMP Wed Feb 22 18:34:17 EET 2006
>>>
>>> and its running on Intel(R) Xeon(TM) MP CPU 3.66GHz.
>>>
>>> I configured R from the source tar.gz myself; each phase of
>>> "./configure --with-x=no ; make ; make install"
>>> passed without aborting on any errors.
>>>
>>>
>>> Cheers,
>>> J.
>>>
>>> --please do not edit the information below--
>>>
>>> Version:
>>> platform = x86_64-unknown-linux-gnu
>>> arch = x86_64
>>> os = linux-gnu
>>> system = x86_64, linux-gnu
>>> status =
>>> major = 2
>>> minor = 2.1
>>> year = 2005
>>> month = 12
>>> day = 20
>>> svn rev = 36812
>>> language = R
>>>
>>> Locale:
>>> LC_CTYPE=fi_FI at euro;LC_NUMERIC=C;LC_TIME=en_US.ISO-8859-15;LC_COLLATE=en_US.IS
>>> O-8859-15;LC_MONETARY=fi_FI at euro;LC_MESSAGES=en_US.ISO-8859-15;LC_PAPER=C;LC_N
>>> AME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
>>>
>>> Search Path:
>>> .GlobalEnv, package:methods, package:stats, package:graphics,
>>> package:grDevices, package:utils, package:datasets, Autoloads, package:base
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From A.Robinson at ms.unimelb.edu.au  Tue Mar 28 09:55:37 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 28 Mar 2006 17:55:37 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
Message-ID: <20060328075537.GD53476@ms.unimelb.edu.au>

Hi Developers,

The alpha, compiles successfully, but it is failing make check-all (on
two seperate machines, both FreeBSD 6.1).

Here is the version string:

platform       i386-unknown-freebsd6.1
arch           i386
os             freebsd6.1
system         i386, freebsd6.1
status         alpha
major          2
minor          3.0
year           2006
month          03
day            27
svn rev        37584
language       R
version.string Version 2.3.0 alpha (2006-03-27 r37584)



Here is the error message from make check-all

comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
...706c706
< [1] "Mean scaled  difference: 0.08333333"
---
> [1] TRUE
gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
gmake[2]: *** [test-Specific] Error 2
gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
gmake[1]: *** [test-all-basics] Error 1
gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
gmake: *** [check-all] Error 2




I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
found some warnings, viz.



> pgamma(1,Inf,scale=Inf) == 0
[1] TRUE
> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
appropriate
> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
+              pgamma(Inf,Inf,scale=Inf))))
[1] TRUE
Warning messages:
1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p) 
2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p) 




> x0 <- -2 * 10^-c(22,10,7,5)
> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
Warning messages:
1: non-integer x = -0.000000
2: non-integer x = -0.000020
> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>


I hope that this is helpful.  Thanks are due to Peter Dalgaard for
guidance.  So, thanks Peter :).

Cheers

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From ripley at stats.ox.ac.uk  Tue Mar 28 10:03:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Mar 2006 09:03:48 +0100 (BST)
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328075537.GD53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>

Thanks for checking.

Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds 
the line

[1] "Mean scaled  difference: 0.08333333"

Some experimentation suggests it is

> All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))

If so, we have

Rhyper <- scan()
16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11

Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)

and those have been checked.  So the error would appear to be in

qhyper(Phyper, m = 40, n = 30, k = 20)

and indeed a mean scaled difference of 1/12 is plausible, since the mean 
of Rhyper is 12. So I deduce that your platform has a problem in qhyper, 
but please cross-check.

If so, this is strange as the only recent change to qhyper.c (or things I 
can see it uses such as lfastchoose) is cosmetic.

Can you confirm the diagnosis is correct so far?


On Tue, 28 Mar 2006, Andrew Robinson wrote:

> Hi Developers,
>
> The alpha, compiles successfully, but it is failing make check-all (on
> two seperate machines, both FreeBSD 6.1).
>
> Here is the version string:
>
> platform       i386-unknown-freebsd6.1
> arch           i386
> os             freebsd6.1
> system         i386, freebsd6.1
> status         alpha
> major          2
> minor          3.0
> year           2006
> month          03
> day            27
> svn rev        37584
> language       R
> version.string Version 2.3.0 alpha (2006-03-27 r37584)
>
>
>
> Here is the error message from make check-all
>
> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> ...706c706
> < [1] "Mean scaled  difference: 0.08333333"
> ---
>> [1] TRUE
> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> gmake[2]: *** [test-Specific] Error 2
> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> gmake[1]: *** [test-all-basics] Error 1
> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> gmake: *** [check-all] Error 2
>
>
>
>
> I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> found some warnings, viz.
>
>
>
>> pgamma(1,Inf,scale=Inf) == 0
> [1] TRUE
>> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> appropriate
>> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> +              pgamma(Inf,Inf,scale=Inf))))
> [1] TRUE
> Warning messages:
> 1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> 2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>
>
>
>
>> x0 <- -2 * 10^-c(22,10,7,5)
>> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> +           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> Warning messages:
> 1: non-integer x = -0.000000
> 2: non-integer x = -0.000020
>> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>>
>
>
> I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> guidance.  So, thanks Peter :).
>
> Cheers
>
> Andrew
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Mar 28 10:40:26 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Mar 2006 10:40:26 +0200
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328075537.GD53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
Message-ID: <17448.63098.100658.943934@stat.math.ethz.ch>

>>>>> "Andrew" == Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
>>>>>     on Tue, 28 Mar 2006 17:55:37 +1000 writes:

    Andrew> Hi Developers,
    Andrew> The alpha, compiles successfully, but it is failing make check-all (on
    Andrew> two seperate machines, both FreeBSD 6.1).

    Andrew> Here is the version string:

    Andrew> platform       i386-unknown-freebsd6.1
    Andrew> arch           i386
    Andrew> os             freebsd6.1
    Andrew> system         i386, freebsd6.1
    Andrew> status         alpha
    Andrew> major          2
    Andrew> minor          3.0
    Andrew> year           2006
    Andrew> month          03
    Andrew> day            27
    Andrew> svn rev        37584
    Andrew> language       R
    Andrew> version.string Version 2.3.0 alpha (2006-03-27 r37584)



    Andrew> Here is the error message from make check-all

    Andrew> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
    Andrew> ...706c706
    Andrew> < [1] "Mean scaled  difference: 0.08333333"
    Andrew> ---
    >> [1] TRUE

So what we need to know is the ``neighborhood'' of the line
-----------------------------------------------
[1] "Mean scaled  difference: 0.08333333"
-----------------------------------------------

in your <builddir>/tests/d-p-q-r-tests.Rout

This will show which of the equality tests did not give TRUE.


    Andrew> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
    Andrew> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
    Andrew> gmake[2]: *** [test-Specific] Error 2
    Andrew> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
    Andrew> gmake[1]: *** [test-all-basics] Error 1
    Andrew> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
    Andrew> gmake: *** [check-all] Error 2


    ......................


From A.Robinson at ms.unimelb.edu.au  Tue Mar 28 12:19:48 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 28 Mar 2006 20:19:48 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
Message-ID: <20060328101948.GJ53476@ms.unimelb.edu.au>

You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
shows:

> All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
[1] "Mean scaled  difference: 0.08333333"



Let me know if/how I can further assist.

Andrew



On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
> Thanks for checking.
> 
> Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds 
> the line
> 
> [1] "Mean scaled  difference: 0.08333333"
> 
> Some experimentation suggests it is
> 
> >All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
> 
> If so, we have
> 
> Rhyper <- scan()
> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> 
> Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> 
> and those have been checked.  So the error would appear to be in
> 
> qhyper(Phyper, m = 40, n = 30, k = 20)
> 
> and indeed a mean scaled difference of 1/12 is plausible, since the mean 
> of Rhyper is 12. So I deduce that your platform has a problem in qhyper, 
> but please cross-check.
> 
> If so, this is strange as the only recent change to qhyper.c (or things I 
> can see it uses such as lfastchoose) is cosmetic.
> 
> Can you confirm the diagnosis is correct so far?
> 
> 
> On Tue, 28 Mar 2006, Andrew Robinson wrote:
> 
> >Hi Developers,
> >
> >The alpha, compiles successfully, but it is failing make check-all (on
> >two seperate machines, both FreeBSD 6.1).
> >
> >Here is the version string:
> >
> >platform       i386-unknown-freebsd6.1
> >arch           i386
> >os             freebsd6.1
> >system         i386, freebsd6.1
> >status         alpha
> >major          2
> >minor          3.0
> >year           2006
> >month          03
> >day            27
> >svn rev        37584
> >language       R
> >version.string Version 2.3.0 alpha (2006-03-27 r37584)
> >
> >
> >
> >Here is the error message from make check-all
> >
> >comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> >...706c706
> >< [1] "Mean scaled  difference: 0.08333333"
> >---
> >>[1] TRUE
> >gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> >gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >gmake[2]: *** [test-Specific] Error 2
> >gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >gmake[1]: *** [test-all-basics] Error 1
> >gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >gmake: *** [check-all] Error 2
> >
> >
> >
> >
> >I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> >found some warnings, viz.
> >
> >
> >
> >>pgamma(1,Inf,scale=Inf) == 0
> >[1] TRUE
> >>## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> >appropriate
> >>all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> >+              pgamma(Inf,Inf,scale=Inf))))
> >[1] TRUE
> >Warning messages:
> >1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >
> >
> >
> >
> >>x0 <- -2 * 10^-c(22,10,7,5)
> >>stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> >+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> >Warning messages:
> >1: non-integer x = -0.000000
> >2: non-integer x = -0.000020
> >>## very small negatives were rounded to 0 in R 2.2.1 and earlier
> >>
> >
> >
> >I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> >guidance.  So, thanks Peter :).
> >
> >Cheers
> >
> >Andrew
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From ripley at stats.ox.ac.uk  Tue Mar 28 11:27:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Mar 2006 10:27:08 +0100 (BST)
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328101948.GJ53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>

On Tue, 28 Mar 2006, Andrew Robinson wrote:

> You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
> shows:
>
>> All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
> [1] "Mean scaled  difference: 0.08333333"

Yes, please run the lines below, e.g.

Rhyper <- scan()
16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11

Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
qhyper(Phyper, m = 40, n = 30, k = 20)

and tell us what answer you get.


>
>
>
> Let me know if/how I can further assist.
>
> Andrew
>
>
>
> On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
>> Thanks for checking.
>>
>> Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds
>> the line
>>
>> [1] "Mean scaled  difference: 0.08333333"
>>
>> Some experimentation suggests it is
>>
>>> All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
>>
>> If so, we have
>>
>> Rhyper <- scan()
>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>
>> Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>
>> and those have been checked.  So the error would appear to be in
>>
>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>
>> and indeed a mean scaled difference of 1/12 is plausible, since the mean
>> of Rhyper is 12. So I deduce that your platform has a problem in qhyper,
>> but please cross-check.
>>
>> If so, this is strange as the only recent change to qhyper.c (or things I
>> can see it uses such as lfastchoose) is cosmetic.
>>
>> Can you confirm the diagnosis is correct so far?
>>
>>
>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>
>>> Hi Developers,
>>>
>>> The alpha, compiles successfully, but it is failing make check-all (on
>>> two seperate machines, both FreeBSD 6.1).
>>>
>>> Here is the version string:
>>>
>>> platform       i386-unknown-freebsd6.1
>>> arch           i386
>>> os             freebsd6.1
>>> system         i386, freebsd6.1
>>> status         alpha
>>> major          2
>>> minor          3.0
>>> year           2006
>>> month          03
>>> day            27
>>> svn rev        37584
>>> language       R
>>> version.string Version 2.3.0 alpha (2006-03-27 r37584)
>>>
>>>
>>>
>>> Here is the error message from make check-all
>>>
>>> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
>>> ...706c706
>>> < [1] "Mean scaled  difference: 0.08333333"
>>> ---
>>>> [1] TRUE
>>> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
>>> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>> gmake[2]: *** [test-Specific] Error 2
>>> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>> gmake[1]: *** [test-all-basics] Error 1
>>> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>> gmake: *** [check-all] Error 2
>>>
>>>
>>>
>>>
>>> I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
>>> found some warnings, viz.
>>>
>>>
>>>
>>>> pgamma(1,Inf,scale=Inf) == 0
>>> [1] TRUE
>>>> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
>>> appropriate
>>>> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
>>> +              pgamma(Inf,Inf,scale=Inf))))
>>> [1] TRUE
>>> Warning messages:
>>> 1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>> 2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>
>>>
>>>
>>>
>>>> x0 <- -2 * 10^-c(22,10,7,5)
>>>> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
>>> +           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
>>> Warning messages:
>>> 1: non-integer x = -0.000000
>>> 2: non-integer x = -0.000020
>>>> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>>>>
>>>
>>>
>>> I hope that this is helpful.  Thanks are due to Peter Dalgaard for
>>> guidance.  So, thanks Peter :).
>>>
>>> Cheers
>>>
>>> Andrew
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From A.Robinson at ms.unimelb.edu.au  Tue Mar 28 13:01:50 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 28 Mar 2006 21:01:50 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
Message-ID: <20060328110150.GL53476@ms.unimelb.edu.au>

I get:

> Rhyper <- scan()
1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11 
21:
Read 20 items
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20) 
> qhyper(Phyper, m = 40, n = 30, k = 20)                             
 [1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11


The 12th element (8) differs from the input (7). 


> Phyper <- phyper (7, m = 40, n = 30, k = 20)
> qhyper(Phyper, m = 40, n = 30, k = 20)
[1] 8


If I do this using 2.2.1 then the input and the output are identical.




On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
> On Tue, 28 Mar 2006, Andrew Robinson wrote:
> 
> >You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
> >shows:
> >
> >>All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
> >[1] "Mean scaled  difference: 0.08333333"
> 
> Yes, please run the lines below, e.g.
> 
> Rhyper <- scan()
> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> 
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> qhyper(Phyper, m = 40, n = 30, k = 20)
> 
> and tell us what answer you get.
> 
> 
> >
> >
> >
> >Let me know if/how I can further assist.
> >
> >Andrew
> >
> >
> >
> >On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
> >>Thanks for checking.
> >>
> >>Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds
> >>the line
> >>
> >>[1] "Mean scaled  difference: 0.08333333"
> >>
> >>Some experimentation suggests it is
> >>
> >>>All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>
> >>If so, we have
> >>
> >>Rhyper <- scan()
> >>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>
> >>Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>
> >>and those have been checked.  So the error would appear to be in
> >>
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>
> >>and indeed a mean scaled difference of 1/12 is plausible, since the mean
> >>of Rhyper is 12. So I deduce that your platform has a problem in qhyper,
> >>but please cross-check.
> >>
> >>If so, this is strange as the only recent change to qhyper.c (or things I
> >>can see it uses such as lfastchoose) is cosmetic.
> >>
> >>Can you confirm the diagnosis is correct so far?
> >>
> >>
> >>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>
> >>>Hi Developers,
> >>>
> >>>The alpha, compiles successfully, but it is failing make check-all (on
> >>>two seperate machines, both FreeBSD 6.1).
> >>>
> >>>Here is the version string:
> >>>
> >>>platform       i386-unknown-freebsd6.1
> >>>arch           i386
> >>>os             freebsd6.1
> >>>system         i386, freebsd6.1
> >>>status         alpha
> >>>major          2
> >>>minor          3.0
> >>>year           2006
> >>>month          03
> >>>day            27
> >>>svn rev        37584
> >>>language       R
> >>>version.string Version 2.3.0 alpha (2006-03-27 r37584)
> >>>
> >>>
> >>>
> >>>Here is the error message from make check-all
> >>>
> >>>comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> >>>...706c706
> >>>< [1] "Mean scaled  difference: 0.08333333"
> >>>---
> >>>>[1] TRUE
> >>>gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> >>>gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>gmake[2]: *** [test-Specific] Error 2
> >>>gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>gmake[1]: *** [test-all-basics] Error 1
> >>>gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>gmake: *** [check-all] Error 2
> >>>
> >>>
> >>>
> >>>
> >>>I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> >>>found some warnings, viz.
> >>>
> >>>
> >>>
> >>>>pgamma(1,Inf,scale=Inf) == 0
> >>>[1] TRUE
> >>>>## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> >>>appropriate
> >>>>all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> >>>+              pgamma(Inf,Inf,scale=Inf))))
> >>>[1] TRUE
> >>>Warning messages:
> >>>1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>
> >>>
> >>>
> >>>
> >>>>x0 <- -2 * 10^-c(22,10,7,5)
> >>>>stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> >>>+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> >>>Warning messages:
> >>>1: non-integer x = -0.000000
> >>>2: non-integer x = -0.000020
> >>>>## very small negatives were rounded to 0 in R 2.2.1 and earlier
> >>>>
> >>>
> >>>
> >>>I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> >>>guidance.  So, thanks Peter :).
> >>>
> >>>Cheers
> >>>
> >>>Andrew
> >>>
> >>
> >>--
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From maechler at stat.math.ethz.ch  Tue Mar 28 12:05:17 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Tue, 28 Mar 2006 12:05:17 +0200 (CEST)
Subject: [Rd] Error once having applied (PR#8718)
Message-ID: <20060328100517.BCD54426B3@slim.kubism.ku.dk>

Merci, Fran?ois!

>>>>> "FrPi" == Fran?ois Pinard <pinard at progiciels-bpi.ca>
>>>>>     on Tue, 28 Mar 2006 03:00:19 +0200 (CEST) writes:

    FrPi> Hi, people.  Here is a transcript of a "R --vanilla" session:
    FrPi> ======================================================================>

    FrPi> R : Copyright 2005, The R Foundation for Statistical Computing
    FrPi> Version 2.2.1  (2005-12-20 r36812)

    ....................

    >> z = data.frame(a=0:9, b=10:19)
    >> apply(z, 1, sum)
    FrPi> 1  2  3  4  5  6  7  8  9 10
    FrPi> 10 12 14 16 18 20 22 24 26 28
    >> apply(z, 1, '$', 'a')
    FrPi> NULL
    >> apply(z, 1, sum)
    FrPi> Erreur dans sum(..., na.rm = na.rm) : 'mode' de l'argument incorrect
    FrPi> ======================================================================<

    FrPi> There are three explicit calls to "apply", one would expect the first
    FrPi> and the third to yield similar results.  They do indeed, if the second
    FrPi> "apply" is not executed, or if '$' gets replaced by '[[' within it.  So
    FrPi> the second "apply", as written, may be hurting the R interpreter.

Indeed! 'z' itself is not changed; it's something else that's corrupted,
since one can reproduce the bug by

apply(data.frame(a=0:9, b=10:19), 1, sum)
apply(data.frame(a=0:9, b=10:19), 1, "$", "a")
apply(data.frame(a=0:9, b=10:19), 1, sum)
##-> error ... invalid 'mode'

This also happens in "R-devel", since yesterday aka 
"2.3.0 alpha".

Martin


From info at chatta.it  Tue Mar 28 12:19:41 2006
From: info at chatta.it (info at chatta.it)
Date: Tue, 28 Mar 2006 12:19:41 +0200 (CEST)
Subject: [Rd] Secure SMTP Message (PR#8719)
Message-ID: <20060328101941.A2DEF426B6@slim.kubism.ku.dk>

RISPOSTA AUTOMATICA

L'indirizzo info at chatta.it non ?? pi?? attivo.

Se desideri contattarci ti invitiamo a farlo attraverso questo indirizzo:

http://www.chatta.it/contattaci.asp


Cordiali Saluti

Lo Staff di www.Chatta.it


From ripley at stats.ox.ac.uk  Tue Mar 28 13:02:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Mar 2006 12:02:11 +0100 (BST)
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328110150.GL53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>

Then we need you to dig in to find out why.  I'd start by seeing if Phyper 
had changed (either by printing it to 16dp or by saving it from 2.2.1 and 
reloading into 2.3.0).

On Tue, 28 Mar 2006, Andrew Robinson wrote:

> I get:
>
>> Rhyper <- scan()
> 1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> 21:
> Read 20 items
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
>
>
> The 12th element (8) differs from the input (7).
>
>
>> Phyper <- phyper (7, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1] 8
>
>
> If I do this using 2.2.1 then the input and the output are identical.
>
>
>
>
> On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>
>>> You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
>>> shows:
>>>
>>>> All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
>>> [1] "Mean scaled  difference: 0.08333333"
>>
>> Yes, please run the lines below, e.g.
>>
>> Rhyper <- scan()
>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>
>> and tell us what answer you get.
>>
>>
>>>
>>>
>>>
>>> Let me know if/how I can further assist.
>>>
>>> Andrew
>>>
>>>
>>>
>>> On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
>>>> Thanks for checking.
>>>>
>>>> Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds
>>>> the line
>>>>
>>>> [1] "Mean scaled  difference: 0.08333333"
>>>>
>>>> Some experimentation suggests it is
>>>>
>>>>> All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
>>>>
>>>> If so, we have
>>>>
>>>> Rhyper <- scan()
>>>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>
>>>> Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>>
>>>> and those have been checked.  So the error would appear to be in
>>>>
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>
>>>> and indeed a mean scaled difference of 1/12 is plausible, since the mean
>>>> of Rhyper is 12. So I deduce that your platform has a problem in qhyper,
>>>> but please cross-check.
>>>>
>>>> If so, this is strange as the only recent change to qhyper.c (or things I
>>>> can see it uses such as lfastchoose) is cosmetic.
>>>>
>>>> Can you confirm the diagnosis is correct so far?
>>>>
>>>>
>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>
>>>>> Hi Developers,
>>>>>
>>>>> The alpha, compiles successfully, but it is failing make check-all (on
>>>>> two seperate machines, both FreeBSD 6.1).
>>>>>
>>>>> Here is the version string:
>>>>>
>>>>> platform       i386-unknown-freebsd6.1
>>>>> arch           i386
>>>>> os             freebsd6.1
>>>>> system         i386, freebsd6.1
>>>>> status         alpha
>>>>> major          2
>>>>> minor          3.0
>>>>> year           2006
>>>>> month          03
>>>>> day            27
>>>>> svn rev        37584
>>>>> language       R
>>>>> version.string Version 2.3.0 alpha (2006-03-27 r37584)
>>>>>
>>>>>
>>>>>
>>>>> Here is the error message from make check-all
>>>>>
>>>>> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
>>>>> ...706c706
>>>>> < [1] "Mean scaled  difference: 0.08333333"
>>>>> ---
>>>>>> [1] TRUE
>>>>> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
>>>>> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>> gmake[2]: *** [test-Specific] Error 2
>>>>> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>> gmake[1]: *** [test-all-basics] Error 1
>>>>> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>> gmake: *** [check-all] Error 2
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
>>>>> found some warnings, viz.
>>>>>
>>>>>
>>>>>
>>>>>> pgamma(1,Inf,scale=Inf) == 0
>>>>> [1] TRUE
>>>>>> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
>>>>> appropriate
>>>>>> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
>>>>> +              pgamma(Inf,Inf,scale=Inf))))
>>>>> [1] TRUE
>>>>> Warning messages:
>>>>> 1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>> 2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> x0 <- -2 * 10^-c(22,10,7,5)
>>>>>> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
>>>>> +           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
>>>>> Warning messages:
>>>>> 1: non-integer x = -0.000000
>>>>> 2: non-integer x = -0.000020
>>>>>> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>>>>>>
>>>>>
>>>>>
>>>>> I hope that this is helpful.  Thanks are due to Peter Dalgaard for
>>>>> guidance.  So, thanks Peter :).
>>>>>
>>>>> Cheers
>>>>>
>>>>> Andrew
>>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From A.Robinson at ms.unimelb.edu.au  Tue Mar 28 15:17:34 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 28 Mar 2006 23:17:34 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
Message-ID: <20060328131734.GP53476@ms.unimelb.edu.au>

This is from 2.2.1:

> Phyper <- phyper(7, m = 40, n = 30, k = 20)
> print(Phyper, digits=16)
[1] 0.01796062766370490

This is from 2.3.0:

> Phyper <- phyper(7, m = 40, n = 30, k = 20)
> print(Phyper, digits=16)
[1] 0.01796062766370491

> qhyper(Phyper, m = 40, n = 30, k = 20)
[1] 8

Then if I save Phyper from 2.2.1, and load it in 2.3.0,

> qhyper(Phyper, m = 40, n = 30, k = 20)
[1] 7

so it appears that the difference between 0.01796062766370490 and
0.01796062766370491 is important here.

(2.3.0)

> qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
[1] 7
> qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
[1] 8



Comparing the full sample:

This is from 2.2.1:

> Rhyper <- scan()
1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
21: 
Read 20 items
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> print(Phyper, digits=16)
 [1] 0.99744478362220412 0.51295659016196715 0.51295659016196715
 [4] 0.98680472393309626 0.51295659016196715 0.86627412777488222
 [7] 0.86627412777488222 0.71494883441868140 0.86627412777488222
[10] 0.30864259597126753 0.30864259597126753 0.01796062766370490
[13] 0.51295659016196715 0.95139460528774533 0.86627412777488222
[16] 0.15132082044442866 0.95139460528774533 0.86627412777488222
[19] 0.86627412777488222 0.51295659016196715



This is from 2.3.0:

> print(Phyper, digits=16)
 [1] 0.99744478362220401 0.51295659016196726 0.51295659016196726
 [4] 0.98680472393309615 0.51295659016196726 0.86627412777488211
 [7] 0.86627412777488211 0.71494883441868129 0.86627412777488211
[10] 0.30864259597126747 0.30864259597126747 0.01796062766370491
[13] 0.51295659016196726 0.95139460528774533 0.86627412777488211
[16] 0.15132082044442868 0.95139460528774533 0.86627412777488211
[19] 0.86627412777488211 0.51295659016196726


The 14's (elements 14 and 17) are identical, everything else is
slightly different.


I also got this interesting result from 2.2.1:


> Rhyper <- 1:20
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> qhyper(Phyper, m = 40, n = 30, k = 20)
 [1]  1  2  3  4  6  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20


Repeating the operation for 2.3.0:


> Rhyper <- 1:20
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> qhyper(Phyper, m = 40, n = 30, k = 20)
 [1]  1  2  3  4  6  6  8  8  9 10 11 12 13 14 15 16 17 18 19 20


(I also tried on WinXP R 2.2.1, and got the expected 1:20 back.)


On Tue, Mar 28, 2006 at 12:02:11PM +0100, Prof Brian Ripley wrote:
> Then we need you to dig in to find out why.  I'd start by seeing if Phyper 
> had changed (either by printing it to 16dp or by saving it from 2.2.1 and 
> reloading into 2.3.0).
> 
> On Tue, 28 Mar 2006, Andrew Robinson wrote:
> 
> >I get:
> >
> >>Rhyper <- scan()
> >1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >21:
> >Read 20 items
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
> >
> >
> >The 12th element (8) differs from the input (7).
> >
> >
> >>Phyper <- phyper (7, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 8
> >
> >
> >If I do this using 2.2.1 then the input and the output are identical.
> >
> >
> >
> >
> >On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
> >>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>
> >>>You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
> >>>shows:
> >>>
> >>>>All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>[1] "Mean scaled  difference: 0.08333333"
> >>
> >>Yes, please run the lines below, e.g.
> >>
> >>Rhyper <- scan()
> >>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>
> >>and tell us what answer you get.
> >>
> >>
> >>>
> >>>
> >>>
> >>>Let me know if/how I can further assist.
> >>>
> >>>Andrew
> >>>
> >>>
> >>>
> >>>On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
> >>>>Thanks for checking.
> >>>>
> >>>>Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds
> >>>>the line
> >>>>
> >>>>[1] "Mean scaled  difference: 0.08333333"
> >>>>
> >>>>Some experimentation suggests it is
> >>>>
> >>>>>All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>>
> >>>>If so, we have
> >>>>
> >>>>Rhyper <- scan()
> >>>>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>>
> >>>>Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>
> >>>>and those have been checked.  So the error would appear to be in
> >>>>
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>>
> >>>>and indeed a mean scaled difference of 1/12 is plausible, since the mean
> >>>>of Rhyper is 12. So I deduce that your platform has a problem in qhyper,
> >>>>but please cross-check.
> >>>>
> >>>>If so, this is strange as the only recent change to qhyper.c (or things 
> >>>>I
> >>>>can see it uses such as lfastchoose) is cosmetic.
> >>>>
> >>>>Can you confirm the diagnosis is correct so far?
> >>>>
> >>>>
> >>>>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>>>
> >>>>>Hi Developers,
> >>>>>
> >>>>>The alpha, compiles successfully, but it is failing make check-all (on
> >>>>>two seperate machines, both FreeBSD 6.1).
> >>>>>
> >>>>>Here is the version string:
> >>>>>
> >>>>>platform       i386-unknown-freebsd6.1
> >>>>>arch           i386
> >>>>>os             freebsd6.1
> >>>>>system         i386, freebsd6.1
> >>>>>status         alpha
> >>>>>major          2
> >>>>>minor          3.0
> >>>>>year           2006
> >>>>>month          03
> >>>>>day            27
> >>>>>svn rev        37584
> >>>>>language       R
> >>>>>version.string Version 2.3.0 alpha (2006-03-27 r37584)
> >>>>>
> >>>>>
> >>>>>
> >>>>>Here is the error message from make check-all
> >>>>>
> >>>>>comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> >>>>>...706c706
> >>>>>< [1] "Mean scaled  difference: 0.08333333"
> >>>>>---
> >>>>>>[1] TRUE
> >>>>>gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> >>>>>gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>gmake[2]: *** [test-Specific] Error 2
> >>>>>gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>gmake[1]: *** [test-all-basics] Error 1
> >>>>>gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>gmake: *** [check-all] Error 2
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> >>>>>found some warnings, viz.
> >>>>>
> >>>>>
> >>>>>
> >>>>>>pgamma(1,Inf,scale=Inf) == 0
> >>>>>[1] TRUE
> >>>>>>## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> >>>>>appropriate
> >>>>>>all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> >>>>>+              pgamma(Inf,Inf,scale=Inf))))
> >>>>>[1] TRUE
> >>>>>Warning messages:
> >>>>>1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>>x0 <- -2 * 10^-c(22,10,7,5)
> >>>>>>stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> >>>>>+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> >>>>>Warning messages:
> >>>>>1: non-integer x = -0.000000
> >>>>>2: non-integer x = -0.000020
> >>>>>>## very small negatives were rounded to 0 in R 2.2.1 and earlier
> >>>>>>
> >>>>>
> >>>>>
> >>>>>I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> >>>>>guidance.  So, thanks Peter :).
> >>>>>
> >>>>>Cheers
> >>>>>
> >>>>>Andrew
> >>>>>
> >>>>
> >>>>--
> >>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>>
> >>
> >>--
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From A.Robinson at ms.unimelb.edu.au  Tue Mar 28 15:23:55 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 28 Mar 2006 23:23:55 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328131734.GP53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
	<20060328131734.GP53476@ms.unimelb.edu.au>
Message-ID: <20060328132355.GQ53476@ms.unimelb.edu.au>

Addendum: the following is true for both 2.2.1 and 2.3.0

> 
> > qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
> [1] 7
> > qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
> [1] 8
> 



-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From ripley at stats.ox.ac.uk  Tue Mar 28 14:53:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Mar 2006 13:53:09 +0100 (BST)
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060328131734.GP53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
	<20060328131734.GP53476@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>

qgamma.c comtains the line

     p *= 1 - 64*DBL_EPSILON;

which seems to be too small nowadays.  I find for example

> p <-  phyper(7, m = 40, n = 30, k = 20)
>
> qhyper(p*(1+5e-16), m = 40, n = 30, k = 20)
[1] 7
> qhyper(p*(1+6e-16), m = 40, n = 30, k = 20)
[1] 8

so it seems far more sensitive than the tolerance indicates is intended.
Now, phyper has been changed since that tolerance was added, and that 
may be part of the explanation.

Can you try a larger tolerance, e.g 1000?

A better fix is probably not to use a tolerance but rather to do a 
downwards search using phyper.


On Tue, 28 Mar 2006, Andrew Robinson wrote:

> This is from 2.2.1:
>
>> Phyper <- phyper(7, m = 40, n = 30, k = 20)
>> print(Phyper, digits=16)
> [1] 0.01796062766370490
>
> This is from 2.3.0:
>
>> Phyper <- phyper(7, m = 40, n = 30, k = 20)
>> print(Phyper, digits=16)
> [1] 0.01796062766370491
>
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1] 8
>
> Then if I save Phyper from 2.2.1, and load it in 2.3.0,
>
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1] 7
>
> so it appears that the difference between 0.01796062766370490 and
> 0.01796062766370491 is important here.
>
> (2.3.0)
>
>> qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
> [1] 7
>> qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
> [1] 8
>
>
>
> Comparing the full sample:
>
> This is from 2.2.1:
>
>> Rhyper <- scan()
> 1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> 21:
> Read 20 items
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> print(Phyper, digits=16)
> [1] 0.99744478362220412 0.51295659016196715 0.51295659016196715
> [4] 0.98680472393309626 0.51295659016196715 0.86627412777488222
> [7] 0.86627412777488222 0.71494883441868140 0.86627412777488222
> [10] 0.30864259597126753 0.30864259597126753 0.01796062766370490
> [13] 0.51295659016196715 0.95139460528774533 0.86627412777488222
> [16] 0.15132082044442866 0.95139460528774533 0.86627412777488222
> [19] 0.86627412777488222 0.51295659016196715
>
>
>
> This is from 2.3.0:
>
>> print(Phyper, digits=16)
> [1] 0.99744478362220401 0.51295659016196726 0.51295659016196726
> [4] 0.98680472393309615 0.51295659016196726 0.86627412777488211
> [7] 0.86627412777488211 0.71494883441868129 0.86627412777488211
> [10] 0.30864259597126747 0.30864259597126747 0.01796062766370491
> [13] 0.51295659016196726 0.95139460528774533 0.86627412777488211
> [16] 0.15132082044442868 0.95139460528774533 0.86627412777488211
> [19] 0.86627412777488211 0.51295659016196726
>
>
> The 14's (elements 14 and 17) are identical, everything else is
> slightly different.
>
>
> I also got this interesting result from 2.2.1:
>
>
>> Rhyper <- 1:20
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1]  1  2  3  4  6  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>
>
> Repeating the operation for 2.3.0:
>
>
>> Rhyper <- 1:20
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1]  1  2  3  4  6  6  8  8  9 10 11 12 13 14 15 16 17 18 19 20
>
>
> (I also tried on WinXP R 2.2.1, and got the expected 1:20 back.)
>
>
> On Tue, Mar 28, 2006 at 12:02:11PM +0100, Prof Brian Ripley wrote:
>> Then we need you to dig in to find out why.  I'd start by seeing if Phyper
>> had changed (either by printing it to 16dp or by saving it from 2.2.1 and
>> reloading into 2.3.0).
>>
>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>
>>> I get:
>>>
>>>> Rhyper <- scan()
>>> 1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>> 21:
>>> Read 20 items
>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
>>>
>>>
>>> The 12th element (8) differs from the input (7).
>>>
>>>
>>>> Phyper <- phyper (7, m = 40, n = 30, k = 20)
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1] 8
>>>
>>>
>>> If I do this using 2.2.1 then the input and the output are identical.
>>>
>>>
>>>
>>>
>>> On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>
>>>>> You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
>>>>> shows:
>>>>>
>>>>>> All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
>>>>> [1] "Mean scaled  difference: 0.08333333"
>>>>
>>>> Yes, please run the lines below, e.g.
>>>>
>>>> Rhyper <- scan()
>>>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>
>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>
>>>> and tell us what answer you get.
>>>>
>>>>
>>>>>
>>>>>
>>>>>
>>>>> Let me know if/how I can further assist.
>>>>>
>>>>> Andrew
>>>>>
>>>>>
>>>>>
>>>>> On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
>>>>>> Thanks for checking.
>>>>>>
>>>>>> Please look in d-p-q-r-tests.Rout.fail and see what immediately preceeds
>>>>>> the line
>>>>>>
>>>>>> [1] "Mean scaled  difference: 0.08333333"
>>>>>>
>>>>>> Some experimentation suggests it is
>>>>>>
>>>>>>> All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
>>>>>>
>>>>>> If so, we have
>>>>>>
>>>>>> Rhyper <- scan()
>>>>>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>>>
>>>>>> Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>>>>
>>>>>> and those have been checked.  So the error would appear to be in
>>>>>>
>>>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>>>
>>>>>> and indeed a mean scaled difference of 1/12 is plausible, since the mean
>>>>>> of Rhyper is 12. So I deduce that your platform has a problem in qhyper,
>>>>>> but please cross-check.
>>>>>>
>>>>>> If so, this is strange as the only recent change to qhyper.c (or things
>>>>>> I
>>>>>> can see it uses such as lfastchoose) is cosmetic.
>>>>>>
>>>>>> Can you confirm the diagnosis is correct so far?
>>>>>>
>>>>>>
>>>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>>>
>>>>>>> Hi Developers,
>>>>>>>
>>>>>>> The alpha, compiles successfully, but it is failing make check-all (on
>>>>>>> two seperate machines, both FreeBSD 6.1).
>>>>>>>
>>>>>>> Here is the version string:
>>>>>>>
>>>>>>> platform       i386-unknown-freebsd6.1
>>>>>>> arch           i386
>>>>>>> os             freebsd6.1
>>>>>>> system         i386, freebsd6.1
>>>>>>> status         alpha
>>>>>>> major          2
>>>>>>> minor          3.0
>>>>>>> year           2006
>>>>>>> month          03
>>>>>>> day            27
>>>>>>> svn rev        37584
>>>>>>> language       R
>>>>>>> version.string Version 2.3.0 alpha (2006-03-27 r37584)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Here is the error message from make check-all
>>>>>>>
>>>>>>> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
>>>>>>> ...706c706
>>>>>>> < [1] "Mean scaled  difference: 0.08333333"
>>>>>>> ---
>>>>>>>> [1] TRUE
>>>>>>> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
>>>>>>> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>> gmake[2]: *** [test-Specific] Error 2
>>>>>>> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>> gmake[1]: *** [test-all-basics] Error 1
>>>>>>> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>> gmake: *** [check-all] Error 2
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
>>>>>>> found some warnings, viz.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> pgamma(1,Inf,scale=Inf) == 0
>>>>>>> [1] TRUE
>>>>>>>> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
>>>>>>> appropriate
>>>>>>>> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
>>>>>>> +              pgamma(Inf,Inf,scale=Inf))))
>>>>>>> [1] TRUE
>>>>>>> Warning messages:
>>>>>>> 1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>>>> 2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> x0 <- -2 * 10^-c(22,10,7,5)
>>>>>>>> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
>>>>>>> +           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
>>>>>>> Warning messages:
>>>>>>> 1: non-integer x = -0.000000
>>>>>>> 2: non-integer x = -0.000020
>>>>>>>> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I hope that this is helpful.  Thanks are due to Peter Dalgaard for
>>>>>>> guidance.  So, thanks Peter :).
>>>>>>>
>>>>>>> Cheers
>>>>>>>
>>>>>>> Andrew
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>>
>>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From robert.pusz at wp.pl  Tue Mar 28 17:01:54 2006
From: robert.pusz at wp.pl (robert.pusz at wp.pl)
Date: Tue, 28 Mar 2006 17:01:54 +0200 (CEST)
Subject: [Rd] weights in glm (PR#8720)
Message-ID: <20060328150154.C5BB1426A5@slim.kubism.ku.dk>

Full_Name: Robert Pusz
Version: 2.2.1
OS: Windows
Submission from: (NULL) (157.25.9.126)


Hello,
In my opinion something is wrong with 'weights' option in glm.
My code is following:
###begin of the code####
cl <- c(5012, 106, 3410, 5655, 1092, 1513, 557, 1351, 3133, 2063, 3257, 
4179, 5582, 5900, 8473, 4932, 3463, 5596, 2262, 0, 2638, 1111, 
4881, 4211, 6271, 5257, 6926, 6165, 0, 0, 898, 5270, 2268, 5500, 
6333, 1233, 1368, 0, 0, 0, 1734, 3116, 2594, 2159, 3786, 2917, 
0, 0, 0, 0, 2642, 1817, 3479, 2658, 225, 0, 0, 0, 0, 0, 1828, 
0, 649, 984, 0, 0, 0, 0, 0, 0, 599, 673, 603, 0, 0, 0, 0, 0, 
0, 0, 54, 535, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0, 0, 0, 0, 0, 
0, 0, 0)

w <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 
1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 
1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 
1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)

row <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

col <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 
5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 
9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10)
Row <- ordered(as.factor(row))
Col <- ordered(as.factor(col))
fit <- glm(cl ~ Row + Col, family = quasipoisson, weights = w)
###end of the code####

When I have written summary(fit) I have got:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  7.64459         NA      NA       NA
Row2        -0.05467         NA      NA       NA
Row3         0.24541         NA      NA       NA
Row4         0.42035         NA      NA       NA
Row5         0.43961         NA      NA       NA
Row6         0.04532         NA      NA       NA
Row7        -0.04881         NA      NA       NA
Row8         0.25370         NA      NA       NA
Row9        -0.14976         NA      NA       NA
Row10       -0.01267         NA      NA       NA
Col2         0.69283         NA      NA       NA
Col3         0.62603         NA      NA       NA
Col4         0.27695         NA      NA       NA
Col5         0.06056         NA      NA       NA
Col6        -0.19582         NA      NA       NA
Col7        -0.83044         NA      NA       NA
Col8        -1.27914         NA      NA       NA
Col9        -1.93235         NA      NA       NA
Col10       -2.49709         NA      NA       NA

When I omited 'weights=w' above table was filled in with numbers, but the
results were wrong (because of taking zeros in regression).

Could you tell me what's wrong?
Kind regards,
Robert


From hb at maths.lth.se  Tue Mar 28 17:18:34 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 28 Mar 2006 17:18:34 +0200
Subject: [Rd] How to set options() when a package without a name space is
	loaded?
Message-ID: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>

Hi,

how do I set options() when loading a package *without* a name space? 
Is it possible?

I though this one was a common question, but I could not find it in
the FAQ, in the help nor in the r-help/r-devel archives.  Section
1.6.3 on "Load hooks" in "Writing R Extensions" says that this should
be done using the .onLoad hook, but that does only apply to packages
name spaces, cf. ?.onLoad

Thanks

Henrik


From hb at maths.lth.se  Tue Mar 28 17:39:52 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 28 Mar 2006 17:39:52 +0200
Subject: [Rd] How to set options() when a package without a name space
	is loaded?
In-Reply-To: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
References: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
Message-ID: <59d7961d0603280739y477ed387p348fda1e27aa2464@mail.gmail.com>

Don't worry.  Sorry for that, I should of course know that it is in
.First.lib() as documented Section 1.1.4 on "Package subdirectories"
in "Writing R Extensions"; "A common use is to call library.dynam()
inside .First.lib() to load compiled code: another use is to call
those functions with side effects".

The reason why it "didn't work" was that I mispelled the option in
.First.lib().  It's time for me to go home now ;)

Henrik


On 3/28/06, Henrik Bengtsson <hb at maths.lth.se> wrote:
> Hi,
>
> how do I set options() when loading a package *without* a name space?
> Is it possible?
>
> I though this one was a common question, but I could not find it in
> the FAQ, in the help nor in the r-help/r-devel archives.  Section
> 1.6.3 on "Load hooks" in "Writing R Extensions" says that this should
> be done using the .onLoad hook, but that does only apply to packages
> name spaces, cf. ?.onLoad
>
> Thanks
>
> Henrik
>


From murdoch at stats.uwo.ca  Tue Mar 28 17:59:31 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 28 Mar 2006 10:59:31 -0500
Subject: [Rd] How to set options() when a package without a name space
 is	loaded?
In-Reply-To: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
References: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
Message-ID: <44295D63.2030709@stats.uwo.ca>

On 3/28/2006 10:18 AM, Henrik Bengtsson wrote:
> Hi,
> 
> how do I set options() when loading a package *without* a name space? 
> Is it possible?

Use .First.lib().  It is mentioned in the R-exts section you looked in 
below, but its purpose is not.

Duncan Murdoch

> 
> I though this one was a common question, but I could not find it in
> the FAQ, in the help nor in the r-help/r-devel archives.  Section
> 1.6.3 on "Load hooks" in "Writing R Extensions" says that this should
> be done using the .onLoad hook, but that does only apply to packages
> name spaces, cf. ?.onLoad
> 
> Thanks
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar 28 18:04:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Mar 2006 17:04:07 +0100 (BST)
Subject: [Rd] How to set options() when a package without a name space
 is loaded?
In-Reply-To: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
References: <59d7961d0603280718k624b2336w1433400a7cd3cb3@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0603281702480.1639@gannet.stats.ox.ac.uk>

BTW, sections in .texi manuals do not have numbers, so please use the 
node name.

You can use .First.lib.


On Tue, 28 Mar 2006, Henrik Bengtsson wrote:

> Hi,
>
> how do I set options() when loading a package *without* a name space?
> Is it possible?
>
> I though this one was a common question, but I could not find it in
> the FAQ, in the help nor in the r-help/r-devel archives.  Section
> 1.6.3 on "Load hooks" in "Writing R Extensions" says that this should
> be done using the .onLoad hook, but that does only apply to packages
> name spaces, cf. ?.onLoad
>
> Thanks
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Mar 28 19:39:32 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 28 Mar 2006 19:39:32 +0200 (CEST)
Subject: [Rd] weights in glm (PR#8720)
Message-ID: <20060328173932.D6B581953A@slim.kubism.ku.dk>

First, R-bugs is not for asking questions, only for reporting things you 
are *certain* are bugs: see the R FAQ.

Why are you using weights to omit cases?  If you had used subset, this 
would have worked.  The problem is the use of zero weights, which are not 
intended to be used in this way.  We can fix this up, but it is not the 
correct way to use glm.


On Tue, 28 Mar 2006, robert.pusz at wp.pl wrote:

> Full_Name: Robert Pusz
> Version: 2.2.1
> OS: Windows
> Submission from: (NULL) (157.25.9.126)
>
>
> Hello,
> In my opinion something is wrong with 'weights' option in glm.
> My code is following:
> ###begin of the code####
> cl <- c(5012, 106, 3410, 5655, 1092, 1513, 557, 1351, 3133, 2063, 3257,
> 4179, 5582, 5900, 8473, 4932, 3463, 5596, 2262, 0, 2638, 1111,
> 4881, 4211, 6271, 5257, 6926, 6165, 0, 0, 898, 5270, 2268, 5500,
> 6333, 1233, 1368, 0, 0, 0, 1734, 3116, 2594, 2159, 3786, 2917,
> 0, 0, 0, 0, 2642, 1817, 3479, 2658, 225, 0, 0, 0, 0, 0, 1828,
> 0, 649, 984, 0, 0, 0, 0, 0, 0, 599, 673, 603, 0, 0, 0, 0, 0,
> 0, 0, 54, 535, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0, 0, 0, 0, 0,
> 0, 0, 0)
>
> w <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,
> 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,
> 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,
> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
>
> row <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
>
> col <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9,
> 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10)
> Row <- ordered(as.factor(row))
> Col <- ordered(as.factor(col))
> fit <- glm(cl ~ Row + Col, family = quasipoisson, weights = w)
> ###end of the code####
>
> When I have written summary(fit) I have got:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)  7.64459         NA      NA       NA
> Row2        -0.05467         NA      NA       NA
> Row3         0.24541         NA      NA       NA
> Row4         0.42035         NA      NA       NA
> Row5         0.43961         NA      NA       NA
> Row6         0.04532         NA      NA       NA
> Row7        -0.04881         NA      NA       NA
> Row8         0.25370         NA      NA       NA
> Row9        -0.14976         NA      NA       NA
> Row10       -0.01267         NA      NA       NA
> Col2         0.69283         NA      NA       NA
> Col3         0.62603         NA      NA       NA
> Col4         0.27695         NA      NA       NA
> Col5         0.06056         NA      NA       NA
> Col6        -0.19582         NA      NA       NA
> Col7        -0.83044         NA      NA       NA
> Col8        -1.27914         NA      NA       NA
> Col9        -1.93235         NA      NA       NA
> Col10       -2.49709         NA      NA       NA
>
> When I omited 'weights=w' above table was filled in with numbers, but the
> results were wrong (because of taking zeros in regression).
>
> Could you tell me what's wrong?
> Kind regards,
> Robert
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Mar 28 20:57:47 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Mar 2006 20:57:47 +0200
Subject: [Rd] weights in glm (PR#8720)
In-Reply-To: <20060328173932.D6B581953A@slim.kubism.ku.dk>
References: <20060328173932.D6B581953A@slim.kubism.ku.dk>
Message-ID: <x2hd5ixuqc.fsf@turmalin.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> First, R-bugs is not for asking questions, only for reporting things you 
> are *certain* are bugs: see the R FAQ.
> 
> Why are you using weights to omit cases?  If you had used subset, this 
> would have worked.  The problem is the use of zero weights, which are not 
> intended to be used in this way.  We can fix this up, but it is not the 
> correct way to use glm.

I'm not even sure we want to fix this up. I recall some nasty issues
with DF that have no proper solution that way - an observation with a
tiny weight represents an observation with a large variance and
contributes 1DF to the residual, with weight zero it is not supposed
to contribute at all, so there's a discontinuity for weights
approaching zero.
 
> 
> On Tue, 28 Mar 2006, robert.pusz at wp.pl wrote:
> 
> > Full_Name: Robert Pusz
> > Version: 2.2.1
> > OS: Windows
> > Submission from: (NULL) (157.25.9.126)
> >
> >
> > Hello,
> > In my opinion something is wrong with 'weights' option in glm.
> > My code is following:
> > ###begin of the code####
> > cl <- c(5012, 106, 3410, 5655, 1092, 1513, 557, 1351, 3133, 2063, 3257,
> > 4179, 5582, 5900, 8473, 4932, 3463, 5596, 2262, 0, 2638, 1111,
> > 4881, 4211, 6271, 5257, 6926, 6165, 0, 0, 898, 5270, 2268, 5500,
> > 6333, 1233, 1368, 0, 0, 0, 1734, 3116, 2594, 2159, 3786, 2917,
> > 0, 0, 0, 0, 2642, 1817, 3479, 2658, 225, 0, 0, 0, 0, 0, 1828,
> > 0, 649, 984, 0, 0, 0, 0, 0, 0, 599, 673, 603, 0, 0, 0, 0, 0,
> > 0, 0, 54, 535, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0)
> >
> > w <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> > 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,
> > 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,
> > 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,
> > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
> >
> > row <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> > 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> > 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> > 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
> > 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
> >
> > col <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> > 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,
> > 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
> > 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9,
> > 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10)
> > Row <- ordered(as.factor(row))
> > Col <- ordered(as.factor(col))
> > fit <- glm(cl ~ Row + Col, family = quasipoisson, weights = w)
> > ###end of the code####
> >
> > When I have written summary(fit) I have got:
> >            Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  7.64459         NA      NA       NA
> > Row2        -0.05467         NA      NA       NA
> > Row3         0.24541         NA      NA       NA
> > Row4         0.42035         NA      NA       NA
> > Row5         0.43961         NA      NA       NA
> > Row6         0.04532         NA      NA       NA
> > Row7        -0.04881         NA      NA       NA
> > Row8         0.25370         NA      NA       NA
> > Row9        -0.14976         NA      NA       NA
> > Row10       -0.01267         NA      NA       NA
> > Col2         0.69283         NA      NA       NA
> > Col3         0.62603         NA      NA       NA
> > Col4         0.27695         NA      NA       NA
> > Col5         0.06056         NA      NA       NA
> > Col6        -0.19582         NA      NA       NA
> > Col7        -0.83044         NA      NA       NA
> > Col8        -1.27914         NA      NA       NA
> > Col9        -1.93235         NA      NA       NA
> > Col10       -2.49709         NA      NA       NA
> >
> > When I omited 'weights=w' above table was filled in with numbers, but the
> > results were wrong (because of taking zeros in regression).
> >
> > Could you tell me what's wrong?
> > Kind regards,
> > Robert
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jtrimble at bodymedia.com  Tue Mar 28 23:40:04 2006
From: jtrimble at bodymedia.com (jtrimble at bodymedia.com)
Date: Tue, 28 Mar 2006 23:40:04 +0200 (CEST)
Subject: [Rd] RS-DBI does not recognized MySQL decimals (PR#8723)
Message-ID: <20060328214004.14DF21953A@slim.kubism.ku.dk>

Full_Name: Jason Trimble
Version: 2.2.1
OS: Windows XP and RedHat EL4
Submission from: (NULL) (209.166.128.18)


Whenever a MySQL query returns a Decimal result to R I get the following warning
in R: 

Warning message:RS-DBI driver warning: (unrecognized MySQL field type 246 in
column 1)

I get this for a simple query like ?SELECT 2, 2.5? 
anything that returns a
decimal!

Application version are:
R ver 2.1.1
RMySQL ver. 0.5-7
DBI ver. 0.1-10
MySQL  Ver 14.12 Distrib 5.0.18.


From A.Robinson at ms.unimelb.edu.au  Wed Mar 29 00:43:32 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 29 Mar 2006 08:43:32 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
	<20060328131734.GP53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>
Message-ID: <20060328224332.GS53476@ms.unimelb.edu.au>

Certainly.  I assume that you mean qhyper.c rather than qgamma.c.  Can
you please be more explicit as to how I can try your suggestion.  Do
you mean that I should try:

p *= 1 - 1000*DBL_EPSILON;

?

Thanks.

On Tue, Mar 28, 2006 at 01:53:09PM +0100, Prof Brian Ripley wrote:
> qgamma.c comtains the line
> 
>     p *= 1 - 64*DBL_EPSILON;
> 
> which seems to be too small nowadays.  I find for example
> 
> >p <-  phyper(7, m = 40, n = 30, k = 20)
> >
> >qhyper(p*(1+5e-16), m = 40, n = 30, k = 20)
> [1] 7
> >qhyper(p*(1+6e-16), m = 40, n = 30, k = 20)
> [1] 8
> 
> so it seems far more sensitive than the tolerance indicates is intended.
> Now, phyper has been changed since that tolerance was added, and that 
> may be part of the explanation.
> 
> Can you try a larger tolerance, e.g 1000?
> 
> A better fix is probably not to use a tolerance but rather to do a 
> downwards search using phyper.
> 
> 
> On Tue, 28 Mar 2006, Andrew Robinson wrote:
> 
> >This is from 2.2.1:
> >
> >>Phyper <- phyper(7, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.01796062766370490
> >
> >This is from 2.3.0:
> >
> >>Phyper <- phyper(7, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.01796062766370491
> >
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 8
> >
> >Then if I save Phyper from 2.2.1, and load it in 2.3.0,
> >
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 7
> >
> >so it appears that the difference between 0.01796062766370490 and
> >0.01796062766370491 is important here.
> >
> >(2.3.0)
> >
> >>qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
> >[1] 7
> >>qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
> >[1] 8
> >
> >
> >
> >Comparing the full sample:
> >
> >This is from 2.2.1:
> >
> >>Rhyper <- scan()
> >1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >21:
> >Read 20 items
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.99744478362220412 0.51295659016196715 0.51295659016196715
> >[4] 0.98680472393309626 0.51295659016196715 0.86627412777488222
> >[7] 0.86627412777488222 0.71494883441868140 0.86627412777488222
> >[10] 0.30864259597126753 0.30864259597126753 0.01796062766370490
> >[13] 0.51295659016196715 0.95139460528774533 0.86627412777488222
> >[16] 0.15132082044442866 0.95139460528774533 0.86627412777488222
> >[19] 0.86627412777488222 0.51295659016196715
> >
> >
> >
> >This is from 2.3.0:
> >
> >>print(Phyper, digits=16)
> >[1] 0.99744478362220401 0.51295659016196726 0.51295659016196726
> >[4] 0.98680472393309615 0.51295659016196726 0.86627412777488211
> >[7] 0.86627412777488211 0.71494883441868129 0.86627412777488211
> >[10] 0.30864259597126747 0.30864259597126747 0.01796062766370491
> >[13] 0.51295659016196726 0.95139460528774533 0.86627412777488211
> >[16] 0.15132082044442868 0.95139460528774533 0.86627412777488211
> >[19] 0.86627412777488211 0.51295659016196726
> >
> >
> >The 14's (elements 14 and 17) are identical, everything else is
> >slightly different.
> >
> >
> >I also got this interesting result from 2.2.1:
> >
> >
> >>Rhyper <- 1:20
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1]  1  2  3  4  6  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
> >
> >
> >Repeating the operation for 2.3.0:
> >
> >
> >>Rhyper <- 1:20
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1]  1  2  3  4  6  6  8  8  9 10 11 12 13 14 15 16 17 18 19 20
> >
> >
> >(I also tried on WinXP R 2.2.1, and got the expected 1:20 back.)
> >
> >
> >On Tue, Mar 28, 2006 at 12:02:11PM +0100, Prof Brian Ripley wrote:
> >>Then we need you to dig in to find out why.  I'd start by seeing if Phyper
> >>had changed (either by printing it to 16dp or by saving it from 2.2.1 and
> >>reloading into 2.3.0).
> >>
> >>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>
> >>>I get:
> >>>
> >>>>Rhyper <- scan()
> >>>1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>21:
> >>>Read 20 items
> >>>>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>[1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
> >>>
> >>>
> >>>The 12th element (8) differs from the input (7).
> >>>
> >>>
> >>>>Phyper <- phyper (7, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>[1] 8
> >>>
> >>>
> >>>If I do this using 2.2.1 then the input and the output are identical.
> >>>
> >>>
> >>>
> >>>
> >>>On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
> >>>>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>>>
> >>>>>You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
> >>>>>shows:
> >>>>>
> >>>>>>All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>>>[1] "Mean scaled  difference: 0.08333333"
> >>>>
> >>>>Yes, please run the lines below, e.g.
> >>>>
> >>>>Rhyper <- scan()
> >>>>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>>
> >>>>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>>
> >>>>and tell us what answer you get.
> >>>>
> >>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>Let me know if/how I can further assist.
> >>>>>
> >>>>>Andrew
> >>>>>
> >>>>>
> >>>>>
> >>>>>On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
> >>>>>>Thanks for checking.
> >>>>>>
> >>>>>>Please look in d-p-q-r-tests.Rout.fail and see what immediately 
> >>>>>>preceeds
> >>>>>>the line
> >>>>>>
> >>>>>>[1] "Mean scaled  difference: 0.08333333"
> >>>>>>
> >>>>>>Some experimentation suggests it is
> >>>>>>
> >>>>>>>All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>>>>
> >>>>>>If so, we have
> >>>>>>
> >>>>>>Rhyper <- scan()
> >>>>>>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>>>>
> >>>>>>Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>>>
> >>>>>>and those have been checked.  So the error would appear to be in
> >>>>>>
> >>>>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>>>>
> >>>>>>and indeed a mean scaled difference of 1/12 is plausible, since the 
> >>>>>>mean
> >>>>>>of Rhyper is 12. So I deduce that your platform has a problem in 
> >>>>>>qhyper,
> >>>>>>but please cross-check.
> >>>>>>
> >>>>>>If so, this is strange as the only recent change to qhyper.c (or 
> >>>>>>things
> >>>>>>I
> >>>>>>can see it uses such as lfastchoose) is cosmetic.
> >>>>>>
> >>>>>>Can you confirm the diagnosis is correct so far?
> >>>>>>
> >>>>>>
> >>>>>>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>>>>>
> >>>>>>>Hi Developers,
> >>>>>>>
> >>>>>>>The alpha, compiles successfully, but it is failing make check-all 
> >>>>>>>(on
> >>>>>>>two seperate machines, both FreeBSD 6.1).
> >>>>>>>
> >>>>>>>Here is the version string:
> >>>>>>>
> >>>>>>>platform       i386-unknown-freebsd6.1
> >>>>>>>arch           i386
> >>>>>>>os             freebsd6.1
> >>>>>>>system         i386, freebsd6.1
> >>>>>>>status         alpha
> >>>>>>>major          2
> >>>>>>>minor          3.0
> >>>>>>>year           2006
> >>>>>>>month          03
> >>>>>>>day            27
> >>>>>>>svn rev        37584
> >>>>>>>language       R
> >>>>>>>version.string Version 2.3.0 alpha (2006-03-27 r37584)
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>Here is the error message from make check-all
> >>>>>>>
> >>>>>>>comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> >>>>>>>...706c706
> >>>>>>>< [1] "Mean scaled  difference: 0.08333333"
> >>>>>>>---
> >>>>>>>>[1] TRUE
> >>>>>>>gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> >>>>>>>gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake[2]: *** [test-Specific] Error 2
> >>>>>>>gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake[1]: *** [test-all-basics] Error 1
> >>>>>>>gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake: *** [check-all] Error 2
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> >>>>>>>found some warnings, viz.
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>>pgamma(1,Inf,scale=Inf) == 0
> >>>>>>>[1] TRUE
> >>>>>>>>## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> >>>>>>>appropriate
> >>>>>>>>all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> >>>>>>>+              pgamma(Inf,Inf,scale=Inf))))
> >>>>>>>[1] TRUE
> >>>>>>>Warning messages:
> >>>>>>>1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>>>2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>>x0 <- -2 * 10^-c(22,10,7,5)
> >>>>>>>>stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> >>>>>>>+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> >>>>>>>Warning messages:
> >>>>>>>1: non-integer x = -0.000000
> >>>>>>>2: non-integer x = -0.000020
> >>>>>>>>## very small negatives were rounded to 0 in R 2.2.1 and earlier
> >>>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> >>>>>>>guidance.  So, thanks Peter :).
> >>>>>>>
> >>>>>>>Cheers
> >>>>>>>
> >>>>>>>Andrew
> >>>>>>>
> >>>>>>
> >>>>>>--
> >>>>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>>>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>>>1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>>>
> >>>>>
> >>>>
> >>>>--
> >>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>>
> >>
> >>--
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From A.Robinson at ms.unimelb.edu.au  Wed Mar 29 02:05:59 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 29 Mar 2006 10:05:59 +1000
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
	<20060328131734.GP53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>
Message-ID: <20060329000559.GU53476@ms.unimelb.edu.au>

I tried it.  That is, in qhyper.c I replaced

p *= 1 - 64*DBL_EPSILON;

with

p *= 1 - 1000*DBL_EPSILON;

and recompiled.  2.3.0 alpha now passses make check-all and returns
sensible results on both of my FreeBSD 6.1 machines.

> Rhyper <- 1:20
> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> qhyper(Phyper, m = 40, n = 30, k = 20)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20

Thanks very much for your guidance, this has been educational.  Is
there anything else that I should check?




On Tue, Mar 28, 2006 at 01:53:09PM +0100, Prof Brian Ripley wrote:
> qgamma.c comtains the line
> 
>     p *= 1 - 64*DBL_EPSILON;
> 
> which seems to be too small nowadays.  I find for example
> 
> >p <-  phyper(7, m = 40, n = 30, k = 20)
> >
> >qhyper(p*(1+5e-16), m = 40, n = 30, k = 20)
> [1] 7
> >qhyper(p*(1+6e-16), m = 40, n = 30, k = 20)
> [1] 8
> 
> so it seems far more sensitive than the tolerance indicates is intended.
> Now, phyper has been changed since that tolerance was added, and that 
> may be part of the explanation.
> 
> Can you try a larger tolerance, e.g 1000?
> 
> A better fix is probably not to use a tolerance but rather to do a 
> downwards search using phyper.
> 
> 
> On Tue, 28 Mar 2006, Andrew Robinson wrote:
> 
> >This is from 2.2.1:
> >
> >>Phyper <- phyper(7, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.01796062766370490
> >
> >This is from 2.3.0:
> >
> >>Phyper <- phyper(7, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.01796062766370491
> >
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 8
> >
> >Then if I save Phyper from 2.2.1, and load it in 2.3.0,
> >
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1] 7
> >
> >so it appears that the difference between 0.01796062766370490 and
> >0.01796062766370491 is important here.
> >
> >(2.3.0)
> >
> >>qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
> >[1] 7
> >>qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
> >[1] 8
> >
> >
> >
> >Comparing the full sample:
> >
> >This is from 2.2.1:
> >
> >>Rhyper <- scan()
> >1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >21:
> >Read 20 items
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>print(Phyper, digits=16)
> >[1] 0.99744478362220412 0.51295659016196715 0.51295659016196715
> >[4] 0.98680472393309626 0.51295659016196715 0.86627412777488222
> >[7] 0.86627412777488222 0.71494883441868140 0.86627412777488222
> >[10] 0.30864259597126753 0.30864259597126753 0.01796062766370490
> >[13] 0.51295659016196715 0.95139460528774533 0.86627412777488222
> >[16] 0.15132082044442866 0.95139460528774533 0.86627412777488222
> >[19] 0.86627412777488222 0.51295659016196715
> >
> >
> >
> >This is from 2.3.0:
> >
> >>print(Phyper, digits=16)
> >[1] 0.99744478362220401 0.51295659016196726 0.51295659016196726
> >[4] 0.98680472393309615 0.51295659016196726 0.86627412777488211
> >[7] 0.86627412777488211 0.71494883441868129 0.86627412777488211
> >[10] 0.30864259597126747 0.30864259597126747 0.01796062766370491
> >[13] 0.51295659016196726 0.95139460528774533 0.86627412777488211
> >[16] 0.15132082044442868 0.95139460528774533 0.86627412777488211
> >[19] 0.86627412777488211 0.51295659016196726
> >
> >
> >The 14's (elements 14 and 17) are identical, everything else is
> >slightly different.
> >
> >
> >I also got this interesting result from 2.2.1:
> >
> >
> >>Rhyper <- 1:20
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1]  1  2  3  4  6  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
> >
> >
> >Repeating the operation for 2.3.0:
> >
> >
> >>Rhyper <- 1:20
> >>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>qhyper(Phyper, m = 40, n = 30, k = 20)
> >[1]  1  2  3  4  6  6  8  8  9 10 11 12 13 14 15 16 17 18 19 20
> >
> >
> >(I also tried on WinXP R 2.2.1, and got the expected 1:20 back.)
> >
> >
> >On Tue, Mar 28, 2006 at 12:02:11PM +0100, Prof Brian Ripley wrote:
> >>Then we need you to dig in to find out why.  I'd start by seeing if Phyper
> >>had changed (either by printing it to 16dp or by saving it from 2.2.1 and
> >>reloading into 2.3.0).
> >>
> >>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>
> >>>I get:
> >>>
> >>>>Rhyper <- scan()
> >>>1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>21:
> >>>Read 20 items
> >>>>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>[1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
> >>>
> >>>
> >>>The 12th element (8) differs from the input (7).
> >>>
> >>>
> >>>>Phyper <- phyper (7, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>[1] 8
> >>>
> >>>
> >>>If I do this using 2.2.1 then the input and the output are identical.
> >>>
> >>>
> >>>
> >>>
> >>>On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
> >>>>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>>>
> >>>>>You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
> >>>>>shows:
> >>>>>
> >>>>>>All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>>>[1] "Mean scaled  difference: 0.08333333"
> >>>>
> >>>>Yes, please run the lines below, e.g.
> >>>>
> >>>>Rhyper <- scan()
> >>>>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>>
> >>>>Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>>
> >>>>and tell us what answer you get.
> >>>>
> >>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>Let me know if/how I can further assist.
> >>>>>
> >>>>>Andrew
> >>>>>
> >>>>>
> >>>>>
> >>>>>On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
> >>>>>>Thanks for checking.
> >>>>>>
> >>>>>>Please look in d-p-q-r-tests.Rout.fail and see what immediately 
> >>>>>>preceeds
> >>>>>>the line
> >>>>>>
> >>>>>>[1] "Mean scaled  difference: 0.08333333"
> >>>>>>
> >>>>>>Some experimentation suggests it is
> >>>>>>
> >>>>>>>All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
> >>>>>>
> >>>>>>If so, we have
> >>>>>>
> >>>>>>Rhyper <- scan()
> >>>>>>16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
> >>>>>>
> >>>>>>Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
> >>>>>>
> >>>>>>and those have been checked.  So the error would appear to be in
> >>>>>>
> >>>>>>qhyper(Phyper, m = 40, n = 30, k = 20)
> >>>>>>
> >>>>>>and indeed a mean scaled difference of 1/12 is plausible, since the 
> >>>>>>mean
> >>>>>>of Rhyper is 12. So I deduce that your platform has a problem in 
> >>>>>>qhyper,
> >>>>>>but please cross-check.
> >>>>>>
> >>>>>>If so, this is strange as the only recent change to qhyper.c (or 
> >>>>>>things
> >>>>>>I
> >>>>>>can see it uses such as lfastchoose) is cosmetic.
> >>>>>>
> >>>>>>Can you confirm the diagnosis is correct so far?
> >>>>>>
> >>>>>>
> >>>>>>On Tue, 28 Mar 2006, Andrew Robinson wrote:
> >>>>>>
> >>>>>>>Hi Developers,
> >>>>>>>
> >>>>>>>The alpha, compiles successfully, but it is failing make check-all 
> >>>>>>>(on
> >>>>>>>two seperate machines, both FreeBSD 6.1).
> >>>>>>>
> >>>>>>>Here is the version string:
> >>>>>>>
> >>>>>>>platform       i386-unknown-freebsd6.1
> >>>>>>>arch           i386
> >>>>>>>os             freebsd6.1
> >>>>>>>system         i386, freebsd6.1
> >>>>>>>status         alpha
> >>>>>>>major          2
> >>>>>>>minor          3.0
> >>>>>>>year           2006
> >>>>>>>month          03
> >>>>>>>day            27
> >>>>>>>svn rev        37584
> >>>>>>>language       R
> >>>>>>>version.string Version 2.3.0 alpha (2006-03-27 r37584)
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>Here is the error message from make check-all
> >>>>>>>
> >>>>>>>comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
> >>>>>>>...706c706
> >>>>>>>< [1] "Mean scaled  difference: 0.08333333"
> >>>>>>>---
> >>>>>>>>[1] TRUE
> >>>>>>>gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
> >>>>>>>gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake[2]: *** [test-Specific] Error 2
> >>>>>>>gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake[1]: *** [test-all-basics] Error 1
> >>>>>>>gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
> >>>>>>>gmake: *** [check-all] Error 2
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
> >>>>>>>found some warnings, viz.
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>>pgamma(1,Inf,scale=Inf) == 0
> >>>>>>>[1] TRUE
> >>>>>>>>## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
> >>>>>>>appropriate
> >>>>>>>>all(is.nan(c(pgamma(Inf,  1,scale=Inf),
> >>>>>>>+              pgamma(Inf,Inf,scale=Inf))))
> >>>>>>>[1] TRUE
> >>>>>>>Warning messages:
> >>>>>>>1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>>>2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>>x0 <- -2 * 10^-c(22,10,7,5)
> >>>>>>>>stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
> >>>>>>>+           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
> >>>>>>>Warning messages:
> >>>>>>>1: non-integer x = -0.000000
> >>>>>>>2: non-integer x = -0.000020
> >>>>>>>>## very small negatives were rounded to 0 in R 2.2.1 and earlier
> >>>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>I hope that this is helpful.  Thanks are due to Peter Dalgaard for
> >>>>>>>guidance.  So, thanks Peter :).
> >>>>>>>
> >>>>>>>Cheers
> >>>>>>>
> >>>>>>>Andrew
> >>>>>>>
> >>>>>>
> >>>>>>--
> >>>>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>>>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>>>1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>>>
> >>>>>
> >>>>
> >>>>--
> >>>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>>
> >>
> >>--
> >>Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865 272861 (self)
> >>1 South Parks Road,                     +44 1865 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From mbeason at harrahs.com  Wed Mar 29 01:37:48 2006
From: mbeason at harrahs.com (Matthew Beason)
Date: Tue, 28 Mar 2006 15:37:48 -0800
Subject: [Rd] R make install and demo(graphics) issue
Message-ID: <E153C65077E0034E97A981C6CE26F1BD04807419@ENTWMAIL1A.harrahs.org>


> -----Original Message-----
> From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
> Sent: Friday, March 24, 2006 8:04 AM
> To: Matthew Beason
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] R make install and demo(graphics) issue
> 
> Matthew,
> 
> On Mar 20, 2006, at 1:52 PM, Matthew Beason wrote:
> 
> >     Thanks! That resolved the "make install" issue. However, after 
> > installation when running "demo(graphics)" or "png()" from 
> within R, I 
> > get the following error:
> > [...]
> > unable to load shared library '/usr/local/R/lib/R/modules/R_X11.so':
> >   Could not load module /usr/local/R/lib/R/modules/R_X11.so.
> >         Dependent module 
> /usr/java14/jre/bin/libjpeg.a(libjpeg.so.62)
> > could not be loaded.
> >         File /usr/java14/jre/bin/libjpeg.a is not an
> >           archive or the file could not be read properly.
> 
> This seems like a problem with your libjpeg shared library - 
> it seems to be bogus. Please make sure you have a properly 
> installed libjpeg and that the correct one is detected. The 
> one above comes from JRE which is probably not what you want. 
> I don't know about your setup, so it's hard to tell which 
> libraries are supposed to be where. Do you have binaries for 
> multiple architectures on the same machine? I'm currently 
> traveling so I can't check our AIX setup.

That could very well be the case. However, I'm not sure where else to
obtain the libjpeg shared library. I've installed the version from the
Linux toolbox for AIX as well downloading it from the AIX public domain
site hosted by UCLA. Neither of these appeared to satisfy the libjpeg
shared library requirement. Is there somewhere else I can obtain it or
am I left to compiling from scratch?
As far as multiple binaries go, I don't believe so. We're running AIX
5.2 ML6 with the standard set of filesets installed. I have installed a
number of RPMS for tasks unrelated to R. 
I know I'm very close to getting this working properly. I truly
appreciate the effort everyone is putting into this to give me a hand.

Thanks in advance!

Matt




> 
> Cheers,
> Simon
> 
> 
> 
>


From bolker at ufl.edu  Wed Mar 29 01:51:58 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 28 Mar 2006 23:51:58 +0000 (UTC)
Subject: [Rd] weights in glm (PR#8720)
References: <20060328173932.D6B581953A@slim.kubism.ku.dk>
	<x2hd5ixuqc.fsf@turmalin.kubism.ku.dk>
Message-ID: <loom.20060329T014422-58@post.gmane.org>

Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:

> 
> I'm not even sure we want to fix this up. I recall some nasty issues
> with DF that have no proper solution that way - an observation with a
> tiny weight represents an observation with a large variance and
> contributes 1DF to the residual, with weight zero it is not supposed
> to contribute at all, so there's a discontinuity for weights
> approaching zero.
> 

  with respect: is it worth adding a note to the documentation
and/or a warning to the code?  I understand that it
becomes unwieldy to warn/protect against all
"stupid"/unforeseen/suboptimal uses of the software, but I also 
understand how the original poster could have decided that setting
a weight to zero was a plausible way to ignore cases ... there is 
already a warning that "observations with zero weight not used for
calculating dispersion" -- could one modify this
slightly to warn people against using zero weights?  (Are zero
weights always a bad idea?)

   Ben Bolker


From ggrothendieck at gmail.com  Wed Mar 29 05:08:40 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Mar 2006 22:08:40 -0500
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <44272DBD.1030707@stats.uwo.ca>
References: <971536df05092208135b7ff57d@mail.gmail.com>
	<4332DEEA.8090705@stats.uwo.ca>
	<971536df050922101246bf8667@mail.gmail.com>
	<4332F2D3.6000807@stats.uwo.ca>
	<971536df050922115057416498@mail.gmail.com>
	<44272DBD.1030707@stats.uwo.ca>
Message-ID: <971536df0603281908j47836d85t3e5ca257b3e5e15e@mail.gmail.com>

Hi, I am just trying it now.  Suppose I copy the first few lines of
the table at:

http://www.pricelesswarehome.org/2006/CumulativePL.php

into the clipboard by selecting them with the mouse in IE and
pressing ctrl-C.  Now I can just go to Excel, click on a cell
and press ctrl-V and they get pasted as cells.  In fact,
that is usually what I would do: paste it into Excel and then
transfer it to R.

Is this correct?

readClipboard(49340)  # got number from getClipboardFormats()

and then parse the HTML that I get from that.

I guess what would be nice would be if one could somehow use
read.table to read it in and directly get a data frame out.

Regards.


On 3/26/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I've just committed some code to R-devel to allow clipboard access to
> non-text in Windows.  This was something we discussed last September.
> I'm not completely happy with the code (it works with numerical
> clipboard format numbers rather than translating them into their names),
> but I'd rather make it available than work on it any more.
>
> Duncan Murdoch
>


From ripley at stats.ox.ac.uk  Wed Mar 29 08:07:59 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 29 Mar 2006 08:07:59 +0200 (CEST)
Subject: [Rd] RS-DBI does not recognized MySQL decimals (PR#8723)
Message-ID: <20060329060759.B53F041EC3@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1125417764-1143612462=:26272
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 8BIT

Please read the FAQ, and report problems in contributed packages to the 
maintainer and not R-bugs, as we ask.

I suspect the problem is in RMySQL, but the maintainer is the same as for 
DBI.

On Tue, 28 Mar 2006, jtrimble at bodymedia.com wrote:

> Full_Name: Jason Trimble
> Version: 2.2.1
> OS: Windows XP and RedHat EL4
> Submission from: (NULL) (209.166.128.18)
>
>
> Whenever a MySQL query returns a Decimal result to R I get the following warning
> in R:
>
> Warning message:RS-DBI driver warning: (unrecognized MySQL field type 246 in
> column 1)
>
> I get this for a simple query like ?SELECT 2, 2.5? 
anything that returns a
> decimal!
>
> Application version are:
> R ver 2.1.1
> RMySQL ver. 0.5-7
> DBI ver. 0.1-10
> MySQL  Ver 14.12 Distrib 5.0.18.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1125417764-1143612462=:26272--


From ripley at stats.ox.ac.uk  Wed Mar 29 08:04:50 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Mar 2006 07:04:50 +0100 (BST)
Subject: [Rd] R 2.3.0 (alpha) on FreeBSD 6.1 fails make check-all
In-Reply-To: <20060329000559.GU53476@ms.unimelb.edu.au>
References: <20060328075537.GD53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603280846340.25281@gannet.stats.ox.ac.uk>
	<20060328101948.GJ53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281025470.26448@gannet.stats.ox.ac.uk>
	<20060328110150.GL53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281159400.27543@gannet.stats.ox.ac.uk>
	<20060328131734.GP53476@ms.unimelb.edu.au>
	<Pine.LNX.4.64.0603281337200.32120@gannet.stats.ox.ac.uk>
	<20060329000559.GU53476@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0603290704150.26272@gannet.stats.ox.ac.uk>

Yes, that is what I meant.  I will commit that.

On Wed, 29 Mar 2006, Andrew Robinson wrote:

> I tried it.  That is, in qhyper.c I replaced
>
> p *= 1 - 64*DBL_EPSILON;
>
> with
>
> p *= 1 - 1000*DBL_EPSILON;
>
> and recompiled.  2.3.0 alpha now passses make check-all and returns
> sensible results on both of my FreeBSD 6.1 machines.
>
>> Rhyper <- 1:20
>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>> qhyper(Phyper, m = 40, n = 30, k = 20)
> [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>
> Thanks very much for your guidance, this has been educational.  Is
> there anything else that I should check?
>
>
>
>
> On Tue, Mar 28, 2006 at 01:53:09PM +0100, Prof Brian Ripley wrote:
>> qgamma.c comtains the line
>>
>>     p *= 1 - 64*DBL_EPSILON;
>>
>> which seems to be too small nowadays.  I find for example
>>
>>> p <-  phyper(7, m = 40, n = 30, k = 20)
>>>
>>> qhyper(p*(1+5e-16), m = 40, n = 30, k = 20)
>> [1] 7
>>> qhyper(p*(1+6e-16), m = 40, n = 30, k = 20)
>> [1] 8
>>
>> so it seems far more sensitive than the tolerance indicates is intended.
>> Now, phyper has been changed since that tolerance was added, and that
>> may be part of the explanation.
>>
>> Can you try a larger tolerance, e.g 1000?
>>
>> A better fix is probably not to use a tolerance but rather to do a
>> downwards search using phyper.
>>
>>
>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>
>>> This is from 2.2.1:
>>>
>>>> Phyper <- phyper(7, m = 40, n = 30, k = 20)
>>>> print(Phyper, digits=16)
>>> [1] 0.01796062766370490
>>>
>>> This is from 2.3.0:
>>>
>>>> Phyper <- phyper(7, m = 40, n = 30, k = 20)
>>>> print(Phyper, digits=16)
>>> [1] 0.01796062766370491
>>>
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1] 8
>>>
>>> Then if I save Phyper from 2.2.1, and load it in 2.3.0,
>>>
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1] 7
>>>
>>> so it appears that the difference between 0.01796062766370490 and
>>> 0.01796062766370491 is important here.
>>>
>>> (2.3.0)
>>>
>>>> qhyper(0.01796062766370490, m = 40, n = 30, k = 20)
>>> [1] 7
>>>> qhyper(0.01796062766370491, m = 40, n = 30, k = 20)
>>> [1] 8
>>>
>>>
>>>
>>> Comparing the full sample:
>>>
>>> This is from 2.2.1:
>>>
>>>> Rhyper <- scan()
>>> 1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>> 21:
>>> Read 20 items
>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>> print(Phyper, digits=16)
>>> [1] 0.99744478362220412 0.51295659016196715 0.51295659016196715
>>> [4] 0.98680472393309626 0.51295659016196715 0.86627412777488222
>>> [7] 0.86627412777488222 0.71494883441868140 0.86627412777488222
>>> [10] 0.30864259597126753 0.30864259597126753 0.01796062766370490
>>> [13] 0.51295659016196715 0.95139460528774533 0.86627412777488222
>>> [16] 0.15132082044442866 0.95139460528774533 0.86627412777488222
>>> [19] 0.86627412777488222 0.51295659016196715
>>>
>>>
>>>
>>> This is from 2.3.0:
>>>
>>>> print(Phyper, digits=16)
>>> [1] 0.99744478362220401 0.51295659016196726 0.51295659016196726
>>> [4] 0.98680472393309615 0.51295659016196726 0.86627412777488211
>>> [7] 0.86627412777488211 0.71494883441868129 0.86627412777488211
>>> [10] 0.30864259597126747 0.30864259597126747 0.01796062766370491
>>> [13] 0.51295659016196726 0.95139460528774533 0.86627412777488211
>>> [16] 0.15132082044442868 0.95139460528774533 0.86627412777488211
>>> [19] 0.86627412777488211 0.51295659016196726
>>>
>>>
>>> The 14's (elements 14 and 17) are identical, everything else is
>>> slightly different.
>>>
>>>
>>> I also got this interesting result from 2.2.1:
>>>
>>>
>>>> Rhyper <- 1:20
>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1]  1  2  3  4  6  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>>>
>>>
>>> Repeating the operation for 2.3.0:
>>>
>>>
>>>> Rhyper <- 1:20
>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>> [1]  1  2  3  4  6  6  8  8  9 10 11 12 13 14 15 16 17 18 19 20
>>>
>>>
>>> (I also tried on WinXP R 2.2.1, and got the expected 1:20 back.)
>>>
>>>
>>> On Tue, Mar 28, 2006 at 12:02:11PM +0100, Prof Brian Ripley wrote:
>>>> Then we need you to dig in to find out why.  I'd start by seeing if Phyper
>>>> had changed (either by printing it to 16dp or by saving it from 2.2.1 and
>>>> reloading into 2.3.0).
>>>>
>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>
>>>>> I get:
>>>>>
>>>>>> Rhyper <- scan()
>>>>> 1: 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>> 21:
>>>>> Read 20 items
>>>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>> [1] 16 11 11 15 11 13 13 12 13 10 10  8 11 14 13  9 14 13 13 11
>>>>>
>>>>>
>>>>> The 12th element (8) differs from the input (7).
>>>>>
>>>>>
>>>>>> Phyper <- phyper (7, m = 40, n = 30, k = 20)
>>>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>> [1] 8
>>>>>
>>>>>
>>>>> If I do this using 2.2.1 then the input and the output are identical.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Tue, Mar 28, 2006 at 10:27:08AM +0100, Prof Brian Ripley wrote:
>>>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>>>
>>>>>>> You're welcome.  You are correct.  d-p-q-r-tests.Rout.fail
>>>>>>> shows:
>>>>>>>
>>>>>>>> All.eq(Rhyper,          qhyper   (Phyper, m = 40, n = 30, k = 20))
>>>>>>> [1] "Mean scaled  difference: 0.08333333"
>>>>>>
>>>>>> Yes, please run the lines below, e.g.
>>>>>>
>>>>>> Rhyper <- scan()
>>>>>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>>>
>>>>>> Phyper         <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>>>
>>>>>> and tell us what answer you get.
>>>>>>
>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Let me know if/how I can further assist.
>>>>>>>
>>>>>>> Andrew
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Tue, Mar 28, 2006 at 09:03:48AM +0100, Prof Brian Ripley wrote:
>>>>>>>> Thanks for checking.
>>>>>>>>
>>>>>>>> Please look in d-p-q-r-tests.Rout.fail and see what immediately
>>>>>>>> preceeds
>>>>>>>> the line
>>>>>>>>
>>>>>>>> [1] "Mean scaled  difference: 0.08333333"
>>>>>>>>
>>>>>>>> Some experimentation suggests it is
>>>>>>>>
>>>>>>>>> All.eq(Rhyper,	  qhyper   (Phyper, m = 40, n = 30, k = 20))
>>>>>>>>
>>>>>>>> If so, we have
>>>>>>>>
>>>>>>>> Rhyper <- scan()
>>>>>>>> 16 11 11 15 11 13 13 12 13 10 10  7 11 14 13  9 14 13 13 11
>>>>>>>>
>>>>>>>> Phyper	  <- phyper   (Rhyper, m = 40, n = 30, k = 20)
>>>>>>>>
>>>>>>>> and those have been checked.  So the error would appear to be in
>>>>>>>>
>>>>>>>> qhyper(Phyper, m = 40, n = 30, k = 20)
>>>>>>>>
>>>>>>>> and indeed a mean scaled difference of 1/12 is plausible, since the
>>>>>>>> mean
>>>>>>>> of Rhyper is 12. So I deduce that your platform has a problem in
>>>>>>>> qhyper,
>>>>>>>> but please cross-check.
>>>>>>>>
>>>>>>>> If so, this is strange as the only recent change to qhyper.c (or
>>>>>>>> things
>>>>>>>> I
>>>>>>>> can see it uses such as lfastchoose) is cosmetic.
>>>>>>>>
>>>>>>>> Can you confirm the diagnosis is correct so far?
>>>>>>>>
>>>>>>>>
>>>>>>>> On Tue, 28 Mar 2006, Andrew Robinson wrote:
>>>>>>>>
>>>>>>>>> Hi Developers,
>>>>>>>>>
>>>>>>>>> The alpha, compiles successfully, but it is failing make check-all
>>>>>>>>> (on
>>>>>>>>> two seperate machines, both FreeBSD 6.1).
>>>>>>>>>
>>>>>>>>> Here is the version string:
>>>>>>>>>
>>>>>>>>> platform       i386-unknown-freebsd6.1
>>>>>>>>> arch           i386
>>>>>>>>> os             freebsd6.1
>>>>>>>>> system         i386, freebsd6.1
>>>>>>>>> status         alpha
>>>>>>>>> major          2
>>>>>>>>> minor          3.0
>>>>>>>>> year           2006
>>>>>>>>> month          03
>>>>>>>>> day            27
>>>>>>>>> svn rev        37584
>>>>>>>>> language       R
>>>>>>>>> version.string Version 2.3.0 alpha (2006-03-27 r37584)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Here is the error message from make check-all
>>>>>>>>>
>>>>>>>>> comparing 'd-p-q-r-tests.Rout' to './d-p-q-r-tests.Rout.save'
>>>>>>>>> ...706c706
>>>>>>>>> < [1] "Mean scaled  difference: 0.08333333"
>>>>>>>>> ---
>>>>>>>>>> [1] TRUE
>>>>>>>>> gmake[3]: *** [d-p-q-r-tests.Rout] Error 1
>>>>>>>>> gmake[3]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>>>> gmake[2]: *** [test-Specific] Error 2
>>>>>>>>> gmake[2]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>>>> gmake[1]: *** [test-all-basics] Error 1
>>>>>>>>> gmake[1]: Leaving directory `/usr/local/beta/R-alpha/tests'
>>>>>>>>> gmake: *** [check-all] Error 2
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> I have checked d-p-q-r-tests.Rout.fail for any obvious problems - I
>>>>>>>>> found some warnings, viz.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> pgamma(1,Inf,scale=Inf) == 0
>>>>>>>>> [1] TRUE
>>>>>>>>>> ## Also pgamma(Inf,Inf) == 1 for which NaN was slightly more
>>>>>>>>> appropriate
>>>>>>>>>> all(is.nan(c(pgamma(Inf,  1,scale=Inf),
>>>>>>>>> +              pgamma(Inf,Inf,scale=Inf))))
>>>>>>>>> [1] TRUE
>>>>>>>>> Warning messages:
>>>>>>>>> 1: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>>>>>> 2: NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> x0 <- -2 * 10^-c(22,10,7,5)
>>>>>>>>>> stopifnot(pbinom(x0, size = 3, prob = 0.1) == 0,
>>>>>>>>> +           dbinom(x0, 3, 0.1) == 0) # d*() warns about non-integer
>>>>>>>>> Warning messages:
>>>>>>>>> 1: non-integer x = -0.000000
>>>>>>>>> 2: non-integer x = -0.000020
>>>>>>>>>> ## very small negatives were rounded to 0 in R 2.2.1 and earlier
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> I hope that this is helpful.  Thanks are due to Peter Dalgaard for
>>>>>>>>> guidance.  So, thanks Peter :).
>>>>>>>>>
>>>>>>>>> Cheers
>>>>>>>>>
>>>>>>>>> Andrew
>>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>>
>>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at maths.lth.se  Wed Mar 29 11:40:08 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 29 Mar 2006 11:40:08 +0200
Subject: [Rd] Substitute() changed since R2.3.0 (2006-02-02 r37243)?
Message-ID: <59d7961d0603290140y29d0b959w6fd6cc5a5a8dd24b@mail.gmail.com>

Hi,

I've got the following two versions of R on WinXP:

A) R Version 2.3.0 Under development (unstable) (2006-02-02 r37243)
B) R Version 2.3.0 Under development (unstable) (2006-03-27 r37579)

and a the following "test.R" script:

foo <- function(path, ...) { print(path) }
bar <- function(x, ...) foo(...)
wow <- function(x, ...) capture.output(foo(...))
bar(1, path=2)
print(wow(1, path=2))

With A, I get:

> source("test.R")
[1] 2
[1] "[1] 2"

But with B, I get
> source("test.R")
[1] 2
Error in print(path) : argument "path" is missing, with no default

Further debugging led me to the following test2.R script:

foo <- function(path, ...) { print(path) }
bar <- function(x, ...) foo(...)
wow <- function(x, ...) yaa(foo(...))
yaa <- function(...) substitute(list(...))
bar(1, path=2)
print(wow(1, path=2))

With A, I get

> source("test2.R")
[1] 2
list(foo(...))

But with B, I get

> source("test.R")
[1] 2
list(foo())

Note that '...' is missing in the latest version.  I don't think this is wanted.

/Henrik


From p.dalgaard at biostat.ku.dk  Wed Mar 29 11:58:34 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Mar 2006 11:58:34 +0200
Subject: [Rd] Substitute() changed since R2.3.0 (2006-02-02 r37243)?
In-Reply-To: <59d7961d0603290140y29d0b959w6fd6cc5a5a8dd24b@mail.gmail.com>
References: <59d7961d0603290140y29d0b959w6fd6cc5a5a8dd24b@mail.gmail.com>
Message-ID: <x27j6dbmid.fsf@viggo.kubism.ku.dk>

"Henrik Bengtsson" <hb at maths.lth.se> writes:

> Hi,
> 
> I've got the following two versions of R on WinXP:
> 
> A) R Version 2.3.0 Under development (unstable) (2006-02-02 r37243)
> B) R Version 2.3.0 Under development (unstable) (2006-03-27 r37579)
> 
> and a the following "test.R" script:
> 
> foo <- function(path, ...) { print(path) }
> bar <- function(x, ...) foo(...)
> wow <- function(x, ...) capture.output(foo(...))
> bar(1, path=2)
> print(wow(1, path=2))
> 
> With A, I get:
> 
> > source("test.R")
> [1] 2
> [1] "[1] 2"
> 
> But with B, I get
> > source("test.R")
> [1] 2
> Error in print(path) : argument "path" is missing, with no default
> 
> Further debugging led me to the following test2.R script:
> 
> foo <- function(path, ...) { print(path) }
> bar <- function(x, ...) foo(...)
> wow <- function(x, ...) yaa(foo(...))
> yaa <- function(...) substitute(list(...))
> bar(1, path=2)
> print(wow(1, path=2))
> 
> With A, I get
> 
> > source("test2.R")
> [1] 2
> list(foo(...))
> 
> But with B, I get
> 
> > source("test.R")
> [1] 2
> list(foo())
> 
> Note that '...' is missing in the latest version.  I don't think this is wanted.

I suspect that you're right. Just for reproduction purposes: The
script is not needed, and the whole thing simplifies to the two lines:

yaa <- function(...) substitute(list(...))
yaa(foo(...))

which gives list(foo()) in 2.3.0 alpha and used to give list(foo(...)).

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From imosqueira at suk.azti.es  Wed Mar 29 12:17:12 2006
From: imosqueira at suk.azti.es (Iago Mosqueira)
Date: Wed, 29 Mar 2006 12:17:12 +0200
Subject: [Rd] Bundle internal dependencies
In-Reply-To: <mailman.9.1143626403.30297.r-devel@r-project.org>
References: <mailman.9.1143626403.30297.r-devel@r-project.org>
Message-ID: <1143627432.26910.8.camel@localhost.localdomain>

Dear all,

When creating a bundle with some internal dependencies (package B in
bundle depends on package A), would having the same version installed
suffice? Can I ignore the dependencie in package B's description? The
test of package B fails when calling data() for an object in pacakge A,
so I am not sure right now whether the whole dependencie is not being
met or simple relates to data(). What is the best way of dealing with
this structure?

Many thanks,


Iago Mosqueira


From hb at maths.lth.se  Wed Mar 29 12:25:13 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 29 Mar 2006 12:25:13 +0200
Subject: [Rd] Substitute() changed since R2.3.0 (2006-02-02 r37243)?
In-Reply-To: <x27j6dbmid.fsf@viggo.kubism.ku.dk>
References: <59d7961d0603290140y29d0b959w6fd6cc5a5a8dd24b@mail.gmail.com>
	<x27j6dbmid.fsf@viggo.kubism.ku.dk>
Message-ID: <59d7961d0603290225rddfd4a1s5798db4ac91d086c@mail.gmail.com>

On 29 Mar 2006 11:58:34 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> "Henrik Bengtsson" <hb at maths.lth.se> writes:
>
> > Hi,
> >
> > I've got the following two versions of R on WinXP:
> >
> > A) R Version 2.3.0 Under development (unstable) (2006-02-02 r37243)
> > B) R Version 2.3.0 Under development (unstable) (2006-03-27 r37579)
> >
> > and a the following "test.R" script:
> >
> > foo <- function(path, ...) { print(path) }
> > bar <- function(x, ...) foo(...)
> > wow <- function(x, ...) capture.output(foo(...))
> > bar(1, path=2)
> > print(wow(1, path=2))
> >
> > With A, I get:
> >
> > > source("test.R")
> > [1] 2
> > [1] "[1] 2"
> >
> > But with B, I get
> > > source("test.R")
> > [1] 2
> > Error in print(path) : argument "path" is missing, with no default
> >
> > Further debugging led me to the following test2.R script:
> >
> > foo <- function(path, ...) { print(path) }
> > bar <- function(x, ...) foo(...)
> > wow <- function(x, ...) yaa(foo(...))
> > yaa <- function(...) substitute(list(...))
> > bar(1, path=2)
> > print(wow(1, path=2))
> >
> > With A, I get
> >
> > > source("test2.R")
> > [1] 2
> > list(foo(...))
> >
> > But with B, I get
> >
> > > source("test.R")
> > [1] 2
> > list(foo())
> >
> > Note that '...' is missing in the latest version.  I don't think this is wanted.
>
> I suspect that you're right. Just for reproduction purposes: The
> script is not needed, and the whole thing simplifies to the two lines:
>
> yaa <- function(...) substitute(list(...))
> yaa(foo(...))
>
> which gives list(foo()) in 2.3.0 alpha and used to give list(foo(...)).

And, yaa(foo(x,y,...,z)) gives list(foo(x, y, z)) but used to give
list(foo(x, y, ..., z)).

/Henrik

>
> --
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+2h UTC)


From murdoch at stats.uwo.ca  Wed Mar 29 14:02:24 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 29 Mar 2006 07:02:24 -0500
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <971536df0603281908j47836d85t3e5ca257b3e5e15e@mail.gmail.com>
References: <971536df05092208135b7ff57d@mail.gmail.com>	
	<4332DEEA.8090705@stats.uwo.ca>	
	<971536df050922101246bf8667@mail.gmail.com>	
	<4332F2D3.6000807@stats.uwo.ca>	
	<971536df050922115057416498@mail.gmail.com>	
	<44272DBD.1030707@stats.uwo.ca>
	<971536df0603281908j47836d85t3e5ca257b3e5e15e@mail.gmail.com>
Message-ID: <442A7750.1000300@stats.uwo.ca>

On 3/28/2006 10:08 PM, Gabor Grothendieck wrote:
> Hi, I am just trying it now.  Suppose I copy the first few lines of
> the table at:
> 
> http://www.pricelesswarehome.org/2006/CumulativePL.php
> 
> into the clipboard by selecting them with the mouse in IE and
> pressing ctrl-C.  Now I can just go to Excel, click on a cell
> and press ctrl-V and they get pasted as cells.  In fact,
> that is usually what I would do: paste it into Excel and then
> transfer it to R.
> 
> Is this correct?

I don't use either IE or Excel, but that sounds plausible.
> 
> readClipboard(49340)  # got number from getClipboardFormats()
> 
> and then parse the HTML that I get from that.
> 
> I guess what would be nice would be if one could somehow use
> read.table to read it in and directly get a data frame out.

You'll have to write the code for that.  As far as I know, 49340 is not 
a standard clipboard format, so you'll need to look through the IE 
documentation to find out what's in it.

Duncan Murdoch

> 
> Regards.
> 
> 
> On 3/26/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> I've just committed some code to R-devel to allow clipboard access to
>> non-text in Windows.  This was something we discussed last September.
>> I'm not completely happy with the code (it works with numerical
>> clipboard format numbers rather than translating them into their names),
>> but I'd rather make it available than work on it any more.
>>
>> Duncan Murdoch
>>


From ggrothendieck at gmail.com  Wed Mar 29 14:20:39 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 29 Mar 2006 07:20:39 -0500
Subject: [Rd] Wishlist - access non-text from clipboard in Windows
In-Reply-To: <442A7750.1000300@stats.uwo.ca>
References: <971536df05092208135b7ff57d@mail.gmail.com>
	<4332DEEA.8090705@stats.uwo.ca>
	<971536df050922101246bf8667@mail.gmail.com>
	<4332F2D3.6000807@stats.uwo.ca>
	<971536df050922115057416498@mail.gmail.com>
	<44272DBD.1030707@stats.uwo.ca>
	<971536df0603281908j47836d85t3e5ca257b3e5e15e@mail.gmail.com>
	<442A7750.1000300@stats.uwo.ca>
Message-ID: <971536df0603290420n120fcc8ambcc3d6bca250a9d8@mail.gmail.com>

On 3/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/28/2006 10:08 PM, Gabor Grothendieck wrote:
> > Hi, I am just trying it now.  Suppose I copy the first few lines of
> > the table at:
> >
> > http://www.pricelesswarehome.org/2006/CumulativePL.php
> >
> > into the clipboard by selecting them with the mouse in IE and
> > pressing ctrl-C.  Now I can just go to Excel, click on a cell
> > and press ctrl-V and they get pasted as cells.  In fact,
> > that is usually what I would do: paste it into Excel and then
> > transfer it to R.
> >
> > Is this correct?
>
> I don't use either IE or Excel, but that sounds plausible.
> >
> > readClipboard(49340)  # got number from getClipboardFormats()
> >
> > and then parse the HTML that I get from that.
> >
> > I guess what would be nice would be if one could somehow use
> > read.table to read it in and directly get a data frame out.
>
> You'll have to write the code for that.  As far as I know, 49340 is not
> a standard clipboard format, so you'll need to look through the IE
> documentation to find out what's in it.
>
> Duncan Murdoch
>
> >
> > Regards.
> >
> >
> > On 3/26/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> I've just committed some code to R-devel to allow clipboard access to
> >> non-text in Windows.  This was something we discussed last September.
> >> I'm not completely happy with the code (it works with numerical
> >> clipboard format numbers rather than translating them into their names),
> >> but I'd rather make it available than work on it any more.
> >>
> >> Duncan Murdoch
> >>
>
>


This seems to work.  The next step would be to add functionality
so that one can do:

read.table("clipboard")

and have it automatically figure out what formats are available on the
clipboard and use the appropriate one, which in this case would be
to recognize the HTML table and extract the cells, to get a data.frame
so that the process is as or almost as easy as in Excel.


From murdoch at stats.uwo.ca  Wed Mar 29 15:09:18 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 29 Mar 2006 08:09:18 -0500
Subject: [Rd] substitute() bug by you ? [forwarded]
In-Reply-To: <17450.33316.556960.657525@stat.math.ethz.ch>
References: <17450.33316.556960.657525@stat.math.ethz.ch>
Message-ID: <442A86FE.2010900@stats.uwo.ca>

On 3/29/2006 7:48 AM, Martin Maechler wrote:
> Hi Duncan,
> 
> Just in case you haven't been alerted yet;
> I think the bug mentioned is caused by this change in coerce.c :

Thanks, I was just coming to the same conclusion.  I'll look into it.

Duncan
> 
> ----------------------------------------------------------------------------
> r37269 | murdoch | 2006-02-05 18:00:54 +0100 (Sun, 05 Feb 2006) | 7 lines
> 
> Changes to substitute and findVar:
> In C, substitute( , R_NilValue) does no substs, just
> getting PREXPRs, while substitute( , R_GlobalEnv) does
> substitutions.
> 
> In R:  substitute( , .GlobalEnv) is just like
> R_NilValue above, as is substitute( , NULL).
> ----------------------------------------------------------------------------
> 
> Regards,
> Martin
> 
> 
> ------- start of forwarded message -------
> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> To: "Henrik Bengtsson" <hb at maths.lth.se>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Substitute() changed since R2.3.0 (2006-02-02 r37243)?
> Date: 29 Mar 2006 11:58:34 +0200
> 
> "Henrik Bengtsson" <hb at maths.lth.se> writes:
> 
>> Hi,
>>
>> I've got the following two versions of R on WinXP:
>>
>> A) R Version 2.3.0 Under development (unstable) (2006-02-02 r37243)
>> B) R Version 2.3.0 Under development (unstable) (2006-03-27 r37579)
>>
>> and a the following "test.R" script:
>>
>> foo <- function(path, ...) { print(path) }
>> bar <- function(x, ...) foo(...)
>> wow <- function(x, ...) capture.output(foo(...))
>> bar(1, path=2)
>> print(wow(1, path=2))
>>
>> With A, I get:
>>
>>> source("test.R")
>> [1] 2
>> [1] "[1] 2"
>>
>> But with B, I get
>>> source("test.R")
>> [1] 2
>> Error in print(path) : argument "path" is missing, with no default
>>
>> Further debugging led me to the following test2.R script:
>>
>> foo <- function(path, ...) { print(path) }
>> bar <- function(x, ...) foo(...)
>> wow <- function(x, ...) yaa(foo(...))
>> yaa <- function(...) substitute(list(...))
>> bar(1, path=2)
>> print(wow(1, path=2))
>>
>> With A, I get
>>
>>> source("test2.R")
>> [1] 2
>> list(foo(...))
>>
>> But with B, I get
>>
>>> source("test.R")
>> [1] 2
>> list(foo())
>>
>> Note that '...' is missing in the latest version.  I don't think this is wanted.
> 
> I suspect that you're right. Just for reproduction purposes: The
> script is not needed, and the whole thing simplifies to the two lines:
> 
> yaa <- function(...) substitute(list(...))
> yaa(foo(...))
> 
> which gives list(foo()) in 2.3.0 alpha and used to give list(foo(...)).
>


From ripley at stats.ox.ac.uk  Wed Mar 29 15:56:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Mar 2006 14:56:40 +0100 (BST)
Subject: [Rd] [R] rownames, colnames, and date and time
In-Reply-To: <441FE3E5.5030707@univie.ac.at>
References: <441FE3E5.5030707@univie.ac.at>
Message-ID: <Pine.LNX.4.64.0603291445320.9177@gannet.stats.ox.ac.uk>

Yet again, this is the wrong list for suggesting changes to R.  Please do 
use R-devel for that purpose (and I have moved this).

If this bothers you (it all works as documented, so why not use it as 
documented?), please supply a suitable patch to the current R-devel 
sources and it will be considered.

And BTW, row.names is the canonical accessor function for data frames,
and its 'value' argument is documented differently from that for rownames 
for an array.  Cf:

Details:

      The extractor functions try to do something sensible for any
      matrix-like object 'x'.  If the object has 'dimnames' the first
      component is used as the row names, and the second component (if
      any) is used for the col names.  For a data frame, 'rownames' and
      'colnames' are equivalent to 'row.names' and 'names' respectively.

Note:

      'row.names' is similar to 'rownames' for arrays, and it has a
      method that calls 'rownames' for an array argument.

I am not sure why R decided to add rownames for the same purpose as 
row.names: eventually they were made equivalent.


On Tue, 21 Mar 2006, Erich Neuwirth wrote:

> I noticed something surprising (in R 2.2.1 on WinXP)
> According to the documentation, rownames and colnames are character vectors.
> Assigning a vector of class POSIXct or POSIXlt as rownames or colnames
> therefore is not strictly according to the rules.
> In some cases, R performs a reasonable typecast, but in some other cases
> where the same typecast also would be possible, it does not.
>
> Assigning a vector of class POSIXct to the rownames or names of a
> dataframe creates a reasonable string representation of the dates (and
> possibly times).
> Assigning such a vector to the rownames or colnames of a matrix produces
> rownames or colnames consisting of the integer representation of the
> date-time value.
> Trying to assign a vector of class POSIXlt in all cases
> (dataframes and matrices, rownames, colnames, names)
> produces an error.
>
> Demonstration code is given below.
>
> This is somewhat inconsistent.
> Perhaps a reasonable solution could be that the typecast
> used for POSIXct and dataframes is used in all the other cases also.
>
> Code:
>
> mymat<-matrix(1:4,nrow=2,ncol=2)
> mydf<-data.frame(mymat)
> mydates<-as.POSIXct(c("2001-1-24","2005-12-25"))
>
> rownames(mydf)<-mydates
> names(mydf)<-mydates
> rownames(mymat)<-mydates
> colnames(mymat)<-mydates
>
> print(deparse(mydates))
> print(deparse(rownames(mydf)))
> print(deparse(names(mydf)))
> print(deparse(rownames(mymat)))
> print(deparse(colnames(mymat)))
>
> mydates1<-as.POSIXlt(mydates)
>
> # the following lines will not work and
> # produce errors
>
> rownames(mydf)<-mydates1
> names(mydf)<-mydates1
> rownames(mymat)<-mydates1
> colnames(mymat)<-mydates1
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sds at gnu.org  Wed Mar 29 16:57:44 2006
From: sds at gnu.org (sds at gnu.org)
Date: Wed, 29 Mar 2006 16:57:44 +0200 (CEST)
Subject: [Rd] pictex should quote underscores (PR#8725)
Message-ID: <20060329145744.DB5AF426CD@slim.kubism.ku.dk>

Full_Name: Sam
Version: 2.2.1, 2005-12-20
OS: i686-redhat-linux-gnu
Submission from: (NULL) (209.213.205.130)


running
     pictex()
     plot(1:11,(-5:5)^2, type='b', main="Simple_Example_Plot")
     dev.off()
(as in the pictex example, but with underscores instead of spaces).
the TeX file contains

\put {Simple_Example_Plot}  [lB] <0.00pt,0.00pt> at 124.00 275.33

the underscores have a special meaning in TeX, so they should be quoted
or converted to dashes.


From sds at podval.org  Wed Mar 29 17:01:30 2006
From: sds at podval.org (sds at podval.org)
Date: Wed, 29 Mar 2006 17:01:30 +0200 (CEST)
Subject: [Rd] bug in pictex() (package:grDevices) (PR#8727)
Message-ID: <20060329150130.78EBF426C3@slim.kubism.ku.dk>

> * Prof Brian Ripley <evcyrl at fgngf.bk.np.hx> [2006-03-29 15:39:17 +0100]:
>
> Have you reported this to pictex()'s author?

no, I have no idea who that is.

> Remember that it is a contributed graphics device, and not one r-core
> is maintaining.  You could also submit a patch yourself.
>
> There is quite a lot wrong with it, as it has not been more than
> minimally updated for years.

I see.
I now submitted this bug via the web interface.
(for some reason it is duplicated, sorry about that)

> On Wed, 29 Mar 2006, Sam Steingold wrote:
>
>> The following message is a courtesy copy of an article
>> that has been posted to gmane.comp.lang.r.general as well.
>>
>> running
>>     pictex()
>>     plot(1:11,(-5:5)^2, type='b', main="Simple_Example_Plot")
>>     dev.off()
>> (as in the pictex example, but with underscores instead of spaces).
>> the TeX file contains
>>
>> \put {Simple_Example_Plot}  [lB] <0.00pt,0.00pt> at 124.00 275.33
>>
>> the underscores have a special meaning in TeX, so they should be quoted
>> or converted to dashes.

-- 
Sam Steingold (http://www.podval.org/~sds) on Fedora Core release 4 (Stentz)
http://www.honestreporting.com http://www.memri.org http://www.camera.org
http://www.dhimmi.com http://www.savegushkatif.org http://www.iris.org.il
What's the difference between Apathy & Ignorance? -I don't know and don't care!


From pgilbert at bank-banque-canada.ca  Wed Mar 29 17:22:32 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 29 Mar 2006 10:22:32 -0500
Subject: [Rd] Bundle internal dependencies
In-Reply-To: <1143627432.26910.8.camel@localhost.localdomain>
References: <mailman.9.1143626403.30297.r-devel@r-project.org>
	<1143627432.26910.8.camel@localhost.localdomain>
Message-ID: <442AA638.5000605@bank-banque-canada.ca>

Iago

What you are trying to do should work, but there are a couple of things 
to watch out for. In the bundle DESCRIPTION "Contains" line be sure to 
put the packages in the order that they should be checked.  In the R 
code for package B be sure to put an .onload function with 
requires("A"), or else require("A") explicitly for anything that needs 
it.  As I recall, this is not necessary for packages, if the package 
DESCRIPTION has Depends: A, but with bundles R CMD check does not work 
unless you explicitly do requires("A") in the code. It may also be 
necessary to specify the package in the data() function - I always do.

I think that is all, but is has been awhile since I worked this out, so 
I may have forgotten something.

Paul

Iago Mosqueira wrote:
> Dear all,
> 
> When creating a bundle with some internal dependencies (package B in
> bundle depends on package A), would having the same version installed
> suffice? Can I ignore the dependencie in package B's description? The
> test of package B fails when calling data() for an object in pacakge A,
> so I am not sure right now whether the whole dependencie is not being
> met or simple relates to data(). What is the best way of dealing with
> this structure?
> 
> Many thanks,
> 
> 
> Iago Mosqueira
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From ripley at stats.ox.ac.uk  Wed Mar 29 22:26:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 29 Mar 2006 21:26:10 +0100 (BST)
Subject: [Rd] [R] rownames, colnames, and date and time
In-Reply-To: <Pine.LNX.4.64.0603291445320.9177@gannet.stats.ox.ac.uk>
References: <441FE3E5.5030707@univie.ac.at>
	<Pine.LNX.4.64.0603291445320.9177@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0603292107580.28145@gannet.stats.ox.ac.uk>

Looking at the code it occurs to me that there is another case you have 
not considered, namely dimnames().

rownames<- and colnames<- are just wrappers for dimnames<-, so consistency 
does mean that all three should behave the same.

For arrays (including matrices), dimnames<- is primitive.  It coerces 
factors to character, and says in the C code

     /* if (isObject(val1)) dispatch on as.character.foo, but we don't
        have the context at this point to do so */

so someone considered this before now.

For data frames, dimnames<-.data.frame is used.  That calls row.names<- 
and names<-, and the first has a data.frame method.  Only the row.names<- 
method is documented to coerce its value to character, and I think it _is_ 
all quite consistent.  The basic rule is that all these functions coerce 
for data frames, and none do for arrays.

However, there was a problematic assumption in the row.names<-.data.frame 
and dimnames<-.data.frame methods, which tested the length of 'value' 
before coercion.  That sounds reasonable, but in unusual cases such as 
POSIXlt, coercion changes the length, and I have swapped the lines around.

What you expected was that dimnames<-() would coerce to character, 
although I can find no support for that expectation in the documentation. 
If it were not a primitive function that would be easy to achieve, but as 
it is, it would need an expert in the internal code to change.  There is 
also the risk of inconsistency, since as the comment says, the C code is 
used in places where the context is not known.  I think this is probably 
best left alone.


On Wed, 29 Mar 2006, Prof Brian Ripley wrote:

> Yet again, this is the wrong list for suggesting changes to R.  Please do use 
> R-devel for that purpose (and I have moved this).
>
> If this bothers you (it all works as documented, so why not use it as 
> documented?), please supply a suitable patch to the current R-devel sources 
> and it will be considered.
>
> And BTW, row.names is the canonical accessor function for data frames,
> and its 'value' argument is documented differently from that for rownames for 
> an array.  Cf:
>
> Details:
>
>     The extractor functions try to do something sensible for any
>     matrix-like object 'x'.  If the object has 'dimnames' the first
>     component is used as the row names, and the second component (if
>     any) is used for the col names.  For a data frame, 'rownames' and
>     'colnames' are equivalent to 'row.names' and 'names' respectively.
>
> Note:
>
>     'row.names' is similar to 'rownames' for arrays, and it has a
>     method that calls 'rownames' for an array argument.
>
> I am not sure why R decided to add rownames for the same purpose as 
> row.names: eventually they were made equivalent.
>
>
> On Tue, 21 Mar 2006, Erich Neuwirth wrote:
>
>> I noticed something surprising (in R 2.2.1 on WinXP)
>> According to the documentation, rownames and colnames are character 
>> vectors.
>> Assigning a vector of class POSIXct or POSIXlt as rownames or colnames
>> therefore is not strictly according to the rules.
>> In some cases, R performs a reasonable typecast, but in some other cases
>> where the same typecast also would be possible, it does not.
>> 
>> Assigning a vector of class POSIXct to the rownames or names of a
>> dataframe creates a reasonable string representation of the dates (and
>> possibly times).
>> Assigning such a vector to the rownames or colnames of a matrix produces
>> rownames or colnames consisting of the integer representation of the
>> date-time value.
>> Trying to assign a vector of class POSIXlt in all cases
>> (dataframes and matrices, rownames, colnames, names)
>> produces an error.
>> 
>> Demonstration code is given below.
>> 
>> This is somewhat inconsistent.
>> Perhaps a reasonable solution could be that the typecast
>> used for POSIXct and dataframes is used in all the other cases also.
>> 
>> Code:
>> 
>> mymat<-matrix(1:4,nrow=2,ncol=2)
>> mydf<-data.frame(mymat)
>> mydates<-as.POSIXct(c("2001-1-24","2005-12-25"))
>> 
>> rownames(mydf)<-mydates
>> names(mydf)<-mydates
>> rownames(mymat)<-mydates
>> colnames(mymat)<-mydates
>> 
>> print(deparse(mydates))
>> print(deparse(rownames(mydf)))
>> print(deparse(names(mydf)))
>> print(deparse(rownames(mymat)))
>> print(deparse(colnames(mymat)))
>> 
>> mydates1<-as.POSIXlt(mydates)
>> 
>> # the following lines will not work and
>> # produce errors
>> 
>> rownames(mydf)<-mydates1
>> names(mydf)<-mydates1
>> rownames(mymat)<-mydates1
>> colnames(mymat)<-mydates1
>> 
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dj at research.bell-labs.com  Thu Mar 30 00:31:34 2006
From: dj at research.bell-labs.com (David James)
Date: Wed, 29 Mar 2006 17:31:34 -0500
Subject: [Rd] write.table and segment fault?
Message-ID: <20060329223134.GA23019@jessie.research.bell-labs.com>

Hi,

I'm experiencing R segmentation faults on multiple versions of R
when writing out a particular data.frame:

   ## dd is a 44 by 3 data.frame

   load(url("http://stat.bell-labs.com/RS-DBI/download/dd.rda"))
   write.table(dd, file = "dd.csv", sep = ",", row.names = FALSE)

this occurs on

> sessionInfo()
  R version 2.2.0, 2005-10-06, i686-pc-linux-gnu

  attached base packages:
  [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
  [7] "base"

> sessionInfo()
  R version 2.2.1, 2005-12-20, i686-pc-linux-gnu
 
  attached base packages:
  [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
  [7] "base"

> sessionInfo()
  Version 2.3.0 alpha (2006-03-27 r37590)
  i686-pc-linux-gnu
 
  attached base packages:
  [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
  [7] "base"
  > load("dd.rda")
  > write.table(dd, file = "dd.csv", sep=",", row.names = TRUE)
 
   *** caught segfault ***
  address 0x18, cause 'memory not mapped'
 
  Traceback:
   1: write.table(dd, file = "dd.csv", sep = ",", row.names = TRUE)
   
  Possible actions:
  1: abort (with core dump)
  2: normal R exit
  3: exit R without saving workspace
  4: exit R saving workspace
  Selection: 3

--
David


From jmc at r-project.org  Thu Mar 30 00:47:59 2006
From: jmc at r-project.org (John Chambers)
Date: Wed, 29 Mar 2006 17:47:59 -0500
Subject: [Rd] write.table and segment fault?
In-Reply-To: <20060329223134.GA23019@jessie.research.bell-labs.com>
References: <20060329223134.GA23019@jessie.research.bell-labs.com>
Message-ID: <442B0E9F.30702@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060329/60a051d3/attachment.pl 

From ssu at thegeorgeinstitute.org  Thu Mar 30 01:26:20 2006
From: ssu at thegeorgeinstitute.org (Steve Su)
Date: Thu, 30 Mar 2006 10:26:20 +1100
Subject: [Rd] Compiling codes from existing packages.
Message-ID: <3B862D6B11ECDE458F679DDA238A135A1D82EE@lisa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060330/9d9dfb16/attachment.pl 

From pinard at iro.umontreal.ca  Thu Mar 30 05:21:46 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 29 Mar 2006 22:21:46 -0500
Subject: [Rd] [R] atan2(1,1i)
In-Reply-To: <Pine.LNX.4.64.0603290850150.27660@gannet.stats.ox.ac.uk>
Message-ID: <20060330032146.GA23133@phenix.sram.qc.ca>

[Brian Ripley]

>BTW, this *really* is an R-devel topic, so please try to use the
>appropriate list.

OK, I'm moving this matter to R-devel.

>[Robin Hankin]

>> My point was that the documentation is inconsistent with the
>> function.

>I think it is _your reading_ of the documentation that is inconsistent.
>An equally plausible reading is that both x and y must be numeric or 
>complex.

If a documentation may be read with many plausible but different 
meanings, then it is ambiguous and needs to be improved.  There is no 
point in asserting, as you did above, that the problem lies in the 
reading of the original poster.

The R documentation is quite good and very useful, there is a tremendous 
job in there, which I acknowlege.  Much thanks to all.  This being said, 
however, the documentation is not perfect, and you should stop reacting 
to R criticism as if it was personal offense, because it is not.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From j.van_den_hoff at fz-rossendorf.de  Thu Mar 30 09:28:14 2006
From: j.van_den_hoff at fz-rossendorf.de (j.van_den_hoff at fz-rossendorf.de)
Date: Thu, 30 Mar 2006 09:28:14 +0200 (CEST)
Subject: [Rd] header containing 8713 (PR#8729)
Message-ID: <20060330072814.BFE81426B3@slim.kubism.ku.dk>

concerning the symbols manpage:


it probably should actually say

"If 'inches' is 'FALSE', the units for the width and height of the 
symbols are taken to be those of the x axis and y axis, respectively..." 
at least for 'boxplots' symbols this is empirically the actual 
behaviour. if other symbols (e.g. circles) actually _are_ using x axis 
units, the difference between 'isotropic' and 'anisotropic' symobls 
should be made clear.

the current text gave me the false impression that I needed to set asp=1 
in order to get correct heights for the boxplots symbols.

joerg


From ripley at stats.ox.ac.uk  Thu Mar 30 10:40:10 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 30 Mar 2006 10:40:10 +0200 (CEST)
Subject: [Rd] header containing 8713 (PR#8713)
Message-ID: <20060330084010.0E2921953A@slim.kubism.ku.dk>

I believe this was intended to be a followup to PR#8713 but has opened a 
new report, so I am replying to re-file it in the correct place.

You can read the source code to find out what happens (as anyone else 
looking into this would need to).

I currently have

   Argument \code{inches} controls the sizes of the symbols.  If
   \code{TRUE} (the default), the the symbols are scaled so that the
   largest dimension of any symbol is one inch.  If a positive number is
   given the symbols are scaled to make largest symbol this height in
   inches (so \code{TRUE} and \code{1} are equivalent). If \code{inches}
   is \code{FALSE}, the units are taken to be those of the appropriate
   axes.  (For circles, squares and stars the units of the x axis are
   used.)

Note that it is not just width and height: the units for the whiskers are 
also relevant.  Indeed, the scaling for boxplots is chosen so that the 
largest width, height or whisker length is one inch.

On Thu, 30 Mar 2006, j.van_den_hoff at fz-rossendorf.de wrote:

> concerning the symbols manpage:
>
>
> it probably should actually say
>
> "If 'inches' is 'FALSE', the units for the width and height of the
> symbols are taken to be those of the x axis and y axis, respectively..."
> at least for 'boxplots' symbols this is empirically the actual
> behaviour. if other symbols (e.g. circles) actually _are_ using x axis
> units, the difference between 'isotropic' and 'anisotropic' symobls
> should be made clear.
>
> the current text gave me the false impression that I needed to set asp=1
> in order to get correct heights for the boxplots symbols.
>
> joerg
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pburns at pburns.seanet.com  Thu Mar 30 11:28:40 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 30 Mar 2006 10:28:40 +0100
Subject: [Rd] [R] rownames, colnames, and date and time
In-Reply-To: <Pine.LNX.4.64.0603292107580.28145@gannet.stats.ox.ac.uk>
References: <441FE3E5.5030707@univie.ac.at>	<Pine.LNX.4.64.0603291445320.9177@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0603292107580.28145@gannet.stats.ox.ac.uk>
Message-ID: <442BA4C8.8080200@pburns.seanet.com>

I haven't been following all of this thread, but
it reminds me of a bug that was in S-PLUS not
too long ago where dimnames could sometimes
be numeric.  This caused some problems that
were very hard to track down because there were
no visual clues of what was really wrong.

I've been pleased not to encounter that in R and
hope it continues.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Prof Brian Ripley wrote:

>Looking at the code it occurs to me that there is another case you have 
>not considered, namely dimnames().
>
>rownames<- and colnames<- are just wrappers for dimnames<-, so consistency 
>does mean that all three should behave the same.
>
>For arrays (including matrices), dimnames<- is primitive.  It coerces 
>factors to character, and says in the C code
>
>     /* if (isObject(val1)) dispatch on as.character.foo, but we don't
>        have the context at this point to do so */
>
>so someone considered this before now.
>
>For data frames, dimnames<-.data.frame is used.  That calls row.names<- 
>and names<-, and the first has a data.frame method.  Only the row.names<- 
>method is documented to coerce its value to character, and I think it _is_ 
>all quite consistent.  The basic rule is that all these functions coerce 
>for data frames, and none do for arrays.
>
>However, there was a problematic assumption in the row.names<-.data.frame 
>and dimnames<-.data.frame methods, which tested the length of 'value' 
>before coercion.  That sounds reasonable, but in unusual cases such as 
>POSIXlt, coercion changes the length, and I have swapped the lines around.
>
>What you expected was that dimnames<-() would coerce to character, 
>although I can find no support for that expectation in the documentation. 
>If it were not a primitive function that would be easy to achieve, but as 
>it is, it would need an expert in the internal code to change.  There is 
>also the risk of inconsistency, since as the comment says, the C code is 
>used in places where the context is not known.  I think this is probably 
>best left alone.
>
>
>On Wed, 29 Mar 2006, Prof Brian Ripley wrote:
>
>  
>
>>Yet again, this is the wrong list for suggesting changes to R.  Please do use 
>>R-devel for that purpose (and I have moved this).
>>
>>If this bothers you (it all works as documented, so why not use it as 
>>documented?), please supply a suitable patch to the current R-devel sources 
>>and it will be considered.
>>
>>And BTW, row.names is the canonical accessor function for data frames,
>>and its 'value' argument is documented differently from that for rownames for 
>>an array.  Cf:
>>
>>Details:
>>
>>    The extractor functions try to do something sensible for any
>>    matrix-like object 'x'.  If the object has 'dimnames' the first
>>    component is used as the row names, and the second component (if
>>    any) is used for the col names.  For a data frame, 'rownames' and
>>    'colnames' are equivalent to 'row.names' and 'names' respectively.
>>
>>Note:
>>
>>    'row.names' is similar to 'rownames' for arrays, and it has a
>>    method that calls 'rownames' for an array argument.
>>
>>I am not sure why R decided to add rownames for the same purpose as 
>>row.names: eventually they were made equivalent.
>>
>>
>>On Tue, 21 Mar 2006, Erich Neuwirth wrote:
>>
>>    
>>
>>>I noticed something surprising (in R 2.2.1 on WinXP)
>>>According to the documentation, rownames and colnames are character 
>>>vectors.
>>>Assigning a vector of class POSIXct or POSIXlt as rownames or colnames
>>>therefore is not strictly according to the rules.
>>>In some cases, R performs a reasonable typecast, but in some other cases
>>>where the same typecast also would be possible, it does not.
>>>
>>>Assigning a vector of class POSIXct to the rownames or names of a
>>>dataframe creates a reasonable string representation of the dates (and
>>>possibly times).
>>>Assigning such a vector to the rownames or colnames of a matrix produces
>>>rownames or colnames consisting of the integer representation of the
>>>date-time value.
>>>Trying to assign a vector of class POSIXlt in all cases
>>>(dataframes and matrices, rownames, colnames, names)
>>>produces an error.
>>>
>>>Demonstration code is given below.
>>>
>>>This is somewhat inconsistent.
>>>Perhaps a reasonable solution could be that the typecast
>>>used for POSIXct and dataframes is used in all the other cases also.
>>>
>>>Code:
>>>
>>>mymat<-matrix(1:4,nrow=2,ncol=2)
>>>mydf<-data.frame(mymat)
>>>mydates<-as.POSIXct(c("2001-1-24","2005-12-25"))
>>>
>>>rownames(mydf)<-mydates
>>>names(mydf)<-mydates
>>>rownames(mymat)<-mydates
>>>colnames(mymat)<-mydates
>>>
>>>print(deparse(mydates))
>>>print(deparse(rownames(mydf)))
>>>print(deparse(names(mydf)))
>>>print(deparse(rownames(mymat)))
>>>print(deparse(colnames(mymat)))
>>>
>>>mydates1<-as.POSIXlt(mydates)
>>>
>>># the following lines will not work and
>>># produce errors
>>>
>>>rownames(mydf)<-mydates1
>>>names(mydf)<-mydates1
>>>rownames(mymat)<-mydates1
>>>colnames(mymat)<-mydates1
>>>
>>>
>>>
>>>      
>>>
>>    
>>
>
>  
>


From gael.millot at curie.fr  Thu Mar 30 11:29:32 2006
From: gael.millot at curie.fr (gael.millot at curie.fr)
Date: Thu, 30 Mar 2006 11:29:32 +0200 (CEST)
Subject: [Rd] ansari.test one-tailed (PR#8730)
Message-ID: <20060330092932.2D15D426CD@slim.kubism.ku.dk>

Full_Name: Gael Millot
Version: 2.2.0.
OS: XP
Submission from: (NULL) (195.220.102.20)


Hello.

I sent an Email in r-help without answer for the moment.

I am wondering if it could have a mistake
in the code of the ansari.test function. For me, it seems that the function
do not recover the p value at the correct side of the normal law N(0, 1) when it
use
the normal approximation (presence of ties) in a one tailed test.

Here is what is written in ansari.test :
p <- pnorm(normalize(STATISTIC, r, TIES))
        PVAL <- switch(alternative,
                       two.sided = 2 * min(p, 1 - p),
                       less = 1 - p,
                       greater = p)

pnorm() is written without "lowertail = FALSE". So it should be :
less = p
greater = 1-p

Am I wrong ???

Thanks very much for your help.

Gael.

Gael Millot
UMR 7147 et Universite Paris 6
Equipe Recombinaison et instabilite genetique
Pav Trouillet Rossignol 5eme etage
Institut Curie
26 rue d'Ulm
75248 Paris Cedex 05
tel : 01 42 34 66 34
fax : 01 42 34 66 44
Email : gael.millot at curie.fr


From j.van_den_hoff at fz-rossendorf.de  Thu Mar 30 11:44:17 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Thu, 30 Mar 2006 11:44:17 +0200
Subject: [Rd] symbols plot
Message-ID: <442BA871.5090206@fz-rossendorf.de>

before getting scolded for submitting a (non-)bug report:

when using the 'symbols' function for plotting boxplot data (i.e. using
'boxplots' symbols), I noted that the x/y-position of the symbols is
associated with the center of the box.

while this is obviously natural for a usual plotting symbol (say a
circle or a rectangle), it is probably never desired if one uses the
'boxplots' symbols: looking at such a plot, probably everyone will
assume that y-position is that of the median within the box (in other
words: that one can read off the values of the medians from the y-axis). 
the center of the box in a 'boxplots' symbol is not a very special 
point, generally. in short: I think 'symbols' with 'boxplots' should 
behave as 'boxplot' does with respect to the y-position. (this of course 
does make sense only, if you presume, that the user actually _did_ 
specify the median as the y-coordinate in the 'symbols' call -- but that 
seems the only natural choice in this case, right?)

the current behaviour is counter-intuitive, I believe, if the
distributions are asymmetrical (and the median is not centered in it's
box). (I even think, that such plots are misinterpreted easily: think
what happens if the median lies very near one of the hinges in one box
and is centered in another one within the same plot and the medians are
actually the same)

in short: I think the 'boxplots' should not be centered at the specified
y-coordinates but rather drawn with a y-coordinate of

y + bxh * (0.5 - bxm)

where bxh and bxm are the second (box height) and fifths (median as 
fraction of box height) column of the 'boxplots'
matrix. in this way, the median position is identical to the specified
y-coordinate.

if such a change 'breaks' current usage, I would propose a further 
argument to 'symbols' to control the positioning behaviour (box center 
vs. median drawn at specified y-coordinate).

at the very least, I think, the manpage should explicitely state that
all symbols (including boxplots) are positioned with their geometrical
center at the specified coordinates and that this might not be what the 
user wants for 'boxplots' (OK: I was looking at my data for quite some 
time until I noticed the source of my trouble. I would have appreciated 
such a remark :-)).

regards,

joerg


From schlather at hsu-hh.de  Thu Mar 30 12:34:17 2006
From: schlather at hsu-hh.de (schlather at hsu-hh.de)
Date: Thu, 30 Mar 2006 12:34:17 +0200 (CEST)
Subject: [Rd] function min does not return correct result if
	.Machine$integer.max is involved (PR#8731)
Message-ID: <20060330103417.A3A2E19066@slim.kubism.ku.dk>

Full_Name: Martin Schlather
Version: 2.2.0 and alpha 2.3.0 (06/3/29)
OS: Linux (x86_64 and Intel)
Submission from: (NULL) (139.11.183.106)


> min(.Machine$integer.max, 10^20)
[1] 1e+20

> min(as.integer(.Machine$integer.max), 10^20)
[1] 1e+20


but
> min(.Machine$integer.max + 0, 10^20)
[1] 2147483647

> min(as.integer(.Machine$integer.max - 1), 10^20)
[1] 2147483646

> min(as.double(.Machine$integer.max), 10^20)
[1] 2147483647

Cheers, Martin


From p.dalgaard at biostat.ku.dk  Thu Mar 30 13:38:38 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Mar 2006 13:38:38 +0200
Subject: [Rd] function min does not return correct result if
	.Machine$integer.max is involved (PR#8731)
In-Reply-To: <20060330103417.A3A2E19066@slim.kubism.ku.dk>
References: <20060330103417.A3A2E19066@slim.kubism.ku.dk>
Message-ID: <x2odzow4ap.fsf@viggo.kubism.ku.dk>

schlather at hsu-hh.de writes:

> Full_Name: Martin Schlather
> Version: 2.2.0 and alpha 2.3.0 (06/3/29)
> OS: Linux (x86_64 and Intel)
> Submission from: (NULL) (139.11.183.106)
> 
> 
> > min(.Machine$integer.max, 10^20)
> [1] 1e+20
> 
> > min(as.integer(.Machine$integer.max), 10^20)
> [1] 1e+20
> 
> 
> but
> > min(.Machine$integer.max + 0, 10^20)
> [1] 2147483647
> 
> > min(as.integer(.Machine$integer.max - 1), 10^20)
> [1] 2147483646
> 
> > min(as.double(.Machine$integer.max), 10^20)
> [1] 2147483647

I have a vague recollection that we might have used
.Machine$integer.max to represent "integer infinity" at some point. If
so, then the results make some sense, but we don't seem to have
similar conventions in any other places that I can think of (i.e.
as.integer(Inf) is NA, etc.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Mar 30 14:55:22 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 30 Mar 2006 14:55:22 +0200 (CEST)
Subject: [Rd] function min does not return correct result if
	.Machine$integer.max (PR#8732)
Message-ID: <20060330125522.622D842702@slim.kubism.ku.dk>

The code has

     s = INT_MAX;
     for (i = 0; i < n; i++) {
 	if (x[i] != NA_INTEGER) {
 	    if (s > x[i]) {
 		s = x[i];
 		if(!updated) updated = 1;
 	    }
 	}
 	else if (!narm) {
 	    if(!updated) updated = 1;
 	    *value = NA_INTEGER;
 	    return(updated);
 	}
     }
     *value = s;

so it ignores the initial value INT_MAX (updated is not set).  Fairly easy 
to fix ... done for 2.3.0.

There's a parallel problem with -.Machine$integer.max, also fixed.

On Thu, 30 Mar 2006, schlather at hsu-hh.de wrote:

> Full_Name: Martin Schlather
> Version: 2.2.0 and alpha 2.3.0 (06/3/29)
> OS: Linux (x86_64 and Intel)
> Submission from: (NULL) (139.11.183.106)
>
>
>> min(.Machine$integer.max, 10^20)
> [1] 1e+20
>
>> min(as.integer(.Machine$integer.max), 10^20)
> [1] 1e+20
>
>
> but
>> min(.Machine$integer.max + 0, 10^20)
> [1] 2147483647
>
>> min(as.integer(.Machine$integer.max - 1), 10^20)
> [1] 2147483646
>
>> min(as.double(.Machine$integer.max), 10^20)
> [1] 2147483647
>
> Cheers, Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 30 14:41:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Mar 2006 13:41:40 +0100 (BST)
Subject: [Rd] [R] rownames, colnames, and date and time
In-Reply-To: <442BA4C8.8080200@pburns.seanet.com>
References: <441FE3E5.5030707@univie.ac.at>
	<Pine.LNX.4.64.0603291445320.9177@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0603292107580.28145@gannet.stats.ox.ac.uk>
	<442BA4C8.8080200@pburns.seanet.com>
Message-ID: <Pine.LNX.4.64.0603301101410.12719@gannet.stats.ox.ac.uk>

On Thu, 30 Mar 2006, Patrick Burns wrote:

> I haven't been following all of this thread, but
> it reminds me of a bug that was in S-PLUS not
> too long ago where dimnames could sometimes
> be numeric.  This caused some problems that
> were very hard to track down because there were
> no visual clues of what was really wrong.
>
> I've been pleased not to encounter that in R and
> hope it continues.

Yes, the C-level assignment code ensures that what is assigned is 
character or NULL (even if you set the attribute rather than use 
dimnames<-).

>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Prof Brian Ripley wrote:
>
>> Looking at the code it occurs to me that there is another case you have
>> not considered, namely dimnames().
>>
>> rownames<- and colnames<- are just wrappers for dimnames<-, so consistency
>> does mean that all three should behave the same.
>>
>> For arrays (including matrices), dimnames<- is primitive.  It coerces
>> factors to character, and says in the C code
>>
>>     /* if (isObject(val1)) dispatch on as.character.foo, but we don't
>>        have the context at this point to do so */
>>
>> so someone considered this before now.
>>
>> For data frames, dimnames<-.data.frame is used.  That calls row.names<-
>> and names<-, and the first has a data.frame method.  Only the row.names<-
>> method is documented to coerce its value to character, and I think it _is_
>> all quite consistent.  The basic rule is that all these functions coerce
>> for data frames, and none do for arrays.
>>
>> However, there was a problematic assumption in the row.names<-.data.frame
>> and dimnames<-.data.frame methods, which tested the length of 'value'
>> before coercion.  That sounds reasonable, but in unusual cases such as
>> POSIXlt, coercion changes the length, and I have swapped the lines around.
>>
>> What you expected was that dimnames<-() would coerce to character,
>> although I can find no support for that expectation in the documentation.
>> If it were not a primitive function that would be easy to achieve, but as
>> it is, it would need an expert in the internal code to change.  There is
>> also the risk of inconsistency, since as the comment says, the C code is
>> used in places where the context is not known.  I think this is probably
>> best left alone.
>>
>>
>> On Wed, 29 Mar 2006, Prof Brian Ripley wrote:
>>
>>
>>
>>> Yet again, this is the wrong list for suggesting changes to R.  Please do use
>>> R-devel for that purpose (and I have moved this).
>>>
>>> If this bothers you (it all works as documented, so why not use it as
>>> documented?), please supply a suitable patch to the current R-devel sources
>>> and it will be considered.
>>>
>>> And BTW, row.names is the canonical accessor function for data frames,
>>> and its 'value' argument is documented differently from that for rownames for
>>> an array.  Cf:
>>>
>>> Details:
>>>
>>>    The extractor functions try to do something sensible for any
>>>    matrix-like object 'x'.  If the object has 'dimnames' the first
>>>    component is used as the row names, and the second component (if
>>>    any) is used for the col names.  For a data frame, 'rownames' and
>>>    'colnames' are equivalent to 'row.names' and 'names' respectively.
>>>
>>> Note:
>>>
>>>    'row.names' is similar to 'rownames' for arrays, and it has a
>>>    method that calls 'rownames' for an array argument.
>>>
>>> I am not sure why R decided to add rownames for the same purpose as
>>> row.names: eventually they were made equivalent.
>>>
>>>
>>> On Tue, 21 Mar 2006, Erich Neuwirth wrote:
>>>
>>>
>>>
>>>> I noticed something surprising (in R 2.2.1 on WinXP)
>>>> According to the documentation, rownames and colnames are character
>>>> vectors.
>>>> Assigning a vector of class POSIXct or POSIXlt as rownames or colnames
>>>> therefore is not strictly according to the rules.
>>>> In some cases, R performs a reasonable typecast, but in some other cases
>>>> where the same typecast also would be possible, it does not.
>>>>
>>>> Assigning a vector of class POSIXct to the rownames or names of a
>>>> dataframe creates a reasonable string representation of the dates (and
>>>> possibly times).
>>>> Assigning such a vector to the rownames or colnames of a matrix produces
>>>> rownames or colnames consisting of the integer representation of the
>>>> date-time value.
>>>> Trying to assign a vector of class POSIXlt in all cases
>>>> (dataframes and matrices, rownames, colnames, names)
>>>> produces an error.
>>>>
>>>> Demonstration code is given below.
>>>>
>>>> This is somewhat inconsistent.
>>>> Perhaps a reasonable solution could be that the typecast
>>>> used for POSIXct and dataframes is used in all the other cases also.
>>>>
>>>> Code:
>>>>
>>>> mymat<-matrix(1:4,nrow=2,ncol=2)
>>>> mydf<-data.frame(mymat)
>>>> mydates<-as.POSIXct(c("2001-1-24","2005-12-25"))
>>>>
>>>> rownames(mydf)<-mydates
>>>> names(mydf)<-mydates
>>>> rownames(mymat)<-mydates
>>>> colnames(mymat)<-mydates
>>>>
>>>> print(deparse(mydates))
>>>> print(deparse(rownames(mydf)))
>>>> print(deparse(names(mydf)))
>>>> print(deparse(rownames(mymat)))
>>>> print(deparse(colnames(mymat)))
>>>>
>>>> mydates1<-as.POSIXlt(mydates)
>>>>
>>>> # the following lines will not work and
>>>> # produce errors
>>>>
>>>> rownames(mydf)<-mydates1
>>>> names(mydf)<-mydates1
>>>> rownames(mymat)<-mydates1
>>>> colnames(mymat)<-mydates1
>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From meier at stat.math.ethz.ch  Thu Mar 30 15:49:28 2006
From: meier at stat.math.ethz.ch (Lukas Meier)
Date: Thu, 30 Mar 2006 15:49:28 +0200
Subject: [Rd] Documentation of aic function in family objects
Message-ID: <17451.57832.218041.313346@stat.math.ethz.ch>

Dear R-developers,

Wouldn't it make sense to document the aic function in family
objects? 

I'm currently writing an R-program which makes use of the
log-likelihood function of e.g. a logistic regression model or a
poisson regression model. As I have observed, the aic function
in a family object calculates the part of the AIC which does not
depend on the predictor dimension. 

As this is not documented I should probably not use it. Or is
there another solution without rewriting the already implemented
functions?

Best wishes,

Lukas Meier


From michael.dondrup at cebitec.uni-bielefeld.de  Thu Mar 30 16:34:14 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Thu, 30 Mar 2006 16:34:14 +0200
Subject: [Rd] R and sun gridengine
In-Reply-To: <4423EFE6.702@cebitec.uni-bielefeld.de>
References: <200603241627.49655.kcarter@cyllene.uwa.edu.au>
	<4423EFE6.702@cebitec.uni-bielefeld.de>
Message-ID: <442BEC66.7090004@cebitec.uni-bielefeld.de>

Michael Dondrup wrote:
> Kim Carter wrote:
> 
>>Hi
>>
>>I am looking for assistance with setting up R under Sun grid engine 6
>>(6.0-update7). I would like to set up transparent interactive access
>>to R using either a qlogin or qrsh solution. While it basically works
>>using either method, I reach the same sticking point.  There seems
>>to be an issue with signalling or something, as R works ok until a 
>>non-R command is typed in - eg "blah" - at which point the remote
>>session is terminated (note: i am using ssh as an rsh/rlogin replacement).
>>
>>If anyone has any suggestions or can point me in the  right direction,
>>it would be greatly appreciated.
>>
>>Kim Carter
>>
>>
>>--
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
> Are you trying something like
> 'qrsh R' ? Then the reason might be a missing tty and R goes to 
> batch-mode, like:
> 
> bagheera:~>qrsh tty
> not a tty
> 
> but:
> 
> bagheera:~>qrsh
> Last login: Fri Mar 24 14:02:47 from bagheera.CeBiTe
> morpheus:~> tty
> /dev/pts/3
> 
> If you supply a command to qrsh, you will not have a terminal.
> 
> I think there is no switch to force R into interactive mode,like for 
> example for 'bash -i'. I found: 
> http://www.r-project.org/nocvs/mail/r-help/2002/8927.html
> but have not checked if it still works.
> 
> Maybe this helps
> Michael
> 
> 
> 
> 
> 
> 
> 
> 
> --
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Hi,
I forgot to add a much simpler solution, so try (something like):

 >qrsh xterm -e R

you might have to adjust your $DISPLAY,
in particular, if you are using Sun ray-terminals or better: use the 
qxterm script (I think it comes wit sge 6, but not sure)


-- 
Dipl. Inform. Michael Dondrup
CeBiTec - http://www.cebitec.uni-bielefeld.de/~mdondrup


From ripley at stats.ox.ac.uk  Thu Mar 30 19:23:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Mar 2006 18:23:11 +0100 (BST)
Subject: [Rd] compress defaults for save() and save.image()
Message-ID: <Pine.LNX.4.64.0603301815180.23911@gannet.stats.ox.ac.uk>

I have changed the default in save() to compress = !ascii.  This seems 
quite safe, as almost always save() is called explicitly and people will
appreciate that it might take a little time to save large objects (and 
depending on your system, compression could even be faster).

Should we also change the default in save.image()?  That is almost always 
used implicitly, via q(), a menu ....  There are arguments that it is a 
more serious change so should not be done at the end of the release cycle, 
and also that large .RData files are something people would want to avoid.

BTW, the defaults can be changed via options() (see ?save): has anyone 
ever found that useful?

And whilst I am feeling curious, has anyone used save(ascii = TRUE) in 
recent years?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From leif at reflectivity.com  Thu Mar 30 19:59:54 2006
From: leif at reflectivity.com (Leif Kirschenbaum)
Date: Thu, 30 Mar 2006 09:59:54 -0800
Subject: [Rd] request to add "..." to cat(ngettext in "warnings" function
Message-ID: <200603301759.k2UHxviY009706@hypatia.math.ethz.ch>

Madams & Sirs,
  I am working on porting some R code to one of our servers to run under web or crontab direction.  With that in mind I have been working on directing informative, warning, and error messages to outputs as I require.  I would like to suggest a change to the "warnings" function; that the passed arguments be enabled to all instances of "cat" in the function, specifically that the "cat(ngettext" have the ellipsis added to the call so that users may be able to call warnings as "warnings(file=stderr())" and the function will write all text to the stderr stream.  As it is written today, the text "Warning message:" is written to the console output no matter what.  Since I am writing only output to the console output which is to be passed to the calling script (PHP, shell script, etc.) I need to divert all other messages to the stderr which I log using sink, so I need all of warnings' output to go to stderr.

Thank you.


warnings<-function (...) 
{
    if (!exists("last.warning", envir = .GlobalEnv)) 
        return()
    last.warning <- get("last.warning", envir = .GlobalEnv)
    if (!(n <- length(last.warning))) 
        return()
    names <- names(last.warning)
    cat(ngettext(n, "Warning message:\n", "Warning messages:\n"),...)
    for (i in 1:n) {
        out <- if (n == 1) 
            names[i]
        else paste(i, ": ", names[i], sep = "")
        if (length(last.warning[[i]])) {
            temp <- deparse(last.warning[[i]])
            out <- paste(out, "in:", temp[1], if (length(temp) > 
                1) 
                " ...")
        }
        cat(out, ..., fill = TRUE)
    }
}




Leif Kirschenbaum
Senior Yield Engineer
Reflectivity, Inc.
(408) 737-8100 x307
leif at reflectivity.com


From rpeng at jhsph.edu  Thu Mar 30 20:03:11 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 30 Mar 2006 13:03:11 -0500
Subject: [Rd] compress defaults for save() and save.image()
In-Reply-To: <Pine.LNX.4.64.0603301815180.23911@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0603301815180.23911@gannet.stats.ox.ac.uk>
Message-ID: <442C1D5F.2000704@jhsph.edu>



Prof Brian Ripley wrote:
> I have changed the default in save() to compress = !ascii.  This seems 
> quite safe, as almost always save() is called explicitly and people will
> appreciate that it might take a little time to save large objects (and 
> depending on your system, compression could even be faster).

I'm in favor of such a change.  I almost always explicitly set `compress = 
TRUE'.  When I don't use it, it's because I want to be able to load large 
objects quickly and I've noticed that loading uncompressed workspaces can be 
quite a bit faster.  Usually though, the savings in disk space is worth the 
small penalty in loading time.

> 
> Should we also change the default in save.image()?  That is almost always 
> used implicitly, via q(), a menu ....  There are arguments that it is a 
> more serious change so should not be done at the end of the release cycle, 
> and also that large .RData files are something people would want to avoid.

I rarely use `save.image()' except to occasionally dump data during a long run 
for crash recovery purposes.  I don't think changing the defaults would make a 
difference to me.

> 
> BTW, the defaults can be changed via options() (see ?save): has anyone 
> ever found that useful?

I was not even aware of this!

> 
> And whilst I am feeling curious, has anyone used save(ascii = TRUE) in 
> recent years?
> 

I don't think I've ever used this feature.

-roger

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From andy_liaw at merck.com  Thu Mar 30 21:32:16 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 30 Mar 2006 14:32:16 -0500
Subject: [Rd] compress defaults for save() and save.image()
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED9F1@usctmx1106.merck.com>

Ditto for me, with the following exceptions:

- I always use save(..., compress=TRUE), without exception.
- The only time I'd use save.image() is when I need to break a remote
connection on short notice.
- I have not used options() to set the default simply because I have not
figured out how exactly to do it.  From what I remember, the doc simply says
it can be done, but does not explicitly say how.

Andy

From: Roger D. Peng
> 
> Prof Brian Ripley wrote:
> > I have changed the default in save() to compress = !ascii.  
> This seems
> > quite safe, as almost always save() is called explicitly 
> and people will
> > appreciate that it might take a little time to save large 
> objects (and 
> > depending on your system, compression could even be faster).
> 
> I'm in favor of such a change.  I almost always explicitly 
> set `compress = 
> TRUE'.  When I don't use it, it's because I want to be able 
> to load large 
> objects quickly and I've noticed that loading uncompressed 
> workspaces can be 
> quite a bit faster.  Usually though, the savings in disk 
> space is worth the 
> small penalty in loading time.
> 
> > 
> > Should we also change the default in save.image()?  That is almost 
> > always
> > used implicitly, via q(), a menu ....  There are arguments 
> that it is a 
> > more serious change so should not be done at the end of the 
> release cycle, 
> > and also that large .RData files are something people would 
> want to avoid.
> 
> I rarely use `save.image()' except to occasionally dump data 
> during a long run 
> for crash recovery purposes.  I don't think changing the 
> defaults would make a 
> difference to me.
> 
> > 
> > BTW, the defaults can be changed via options() (see ?save): 
> has anyone
> > ever found that useful?
> 
> I was not even aware of this!
> 
> > 
> > And whilst I am feeling curious, has anyone used save(ascii 
> = TRUE) in
> > recent years?
> > 
> 
> I don't think I've ever used this feature.
> 
> -roger
> 
> -- 
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From btyner at stat.purdue.edu  Thu Mar 30 21:41:31 2006
From: btyner at stat.purdue.edu (btyner at stat.purdue.edu)
Date: Thu, 30 Mar 2006 21:41:31 +0200 (CEST)
Subject: [Rd] custom strip in lattice ignoring plotmath expressions for all
	but style = 1 (PR#8733)
Message-ID: <20060330194131.1785EAB7A@slim.kubism.ku.dk>

Full_Name: Ben Tyner
Version: 2.2.0
OS: i686-pc-linux-gnu
Submission from: (NULL) (128.210.141.240)


My appologies if this has already been fixed, but I didn't see it in the
tracking system yet so I thought I'd report it. Demonstration:

xyplot(Petal.Length ~ Petal.Width | Species, iris,
       strip = strip.custom(style = 1,
                            var.name = expression(beta),
                            strip.names = c(T, T)
               )
       ) # correct behavior w.r.t. var.name

xyplot(Petal.Length ~ Petal.Width | Species, iris,
       strip = strip.custom(style = 3,
                            var.name = expression(beta),
                            strip.names = c(T, T)
                            )
       ) # the var.name shows up as "beta"


From deepayan.sarkar at gmail.com  Thu Mar 30 22:06:22 2006
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Thu, 30 Mar 2006 22:06:22 +0200 (CEST)
Subject: [Rd] custom strip in lattice ignoring plotmath expressions for
	all but style = 1 (PR#8733)
Message-ID: <20060330200622.C06D4AB79@slim.kubism.ku.dk>

T24gMy8zMC8wNiwgYnR5bmVyQHN0YXQucHVyZHVlLmVkdSA8YnR5bmVyQHN0YXQucHVyZHVlLmVk
dT4gd3JvdGU6Cj4gRnVsbF9OYW1lOiBCZW4gVHluZXIKPiBWZXJzaW9uOiAyLjIuMAo+IE9TOiBp
Njg2LXBjLWxpbnV4LWdudQo+IFN1Ym1pc3Npb24gZnJvbTogKE5VTEwpICgxMjguMjEwLjE0MS4y
NDApCj4KPgo+IE15IGFwcG9sb2dpZXMgaWYgdGhpcyBoYXMgYWxyZWFkeSBiZWVuIGZpeGVkLCBi
dXQgSSBkaWRuJ3Qgc2VlIGl0IGluIHRoZQo+IHRyYWNraW5nIHN5c3RlbSB5ZXQgc28gSSB0aG91
Z2h0IEknZCByZXBvcnQgaXQuIERlbW9uc3RyYXRpb246Cj4KPiB4eXBsb3QoUGV0YWwuTGVuZ3Ro
IH4gUGV0YWwuV2lkdGggfCBTcGVjaWVzLCBpcmlzLAo+ICAgICAgICBzdHJpcCA9IHN0cmlwLmN1
c3RvbShzdHlsZSA9IDEsCj4gICAgICAgICAgICAgICAgICAgICAgICAgICAgIHZhci5uYW1lID0g
ZXhwcmVzc2lvbihiZXRhKSwKPiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgc3RyaXAubmFt
ZXMgPSBjKFQsIFQpCj4gICAgICAgICAgICAgICAgKQo+ICAgICAgICApICMgY29ycmVjdCBiZWhh
dmlvciB3LnIudC4gdmFyLm5hbWUKPgo+IHh5cGxvdChQZXRhbC5MZW5ndGggfiBQZXRhbC5XaWR0
aCB8IFNwZWNpZXMsIGlyaXMsCj4gICAgICAgIHN0cmlwID0gc3RyaXAuY3VzdG9tKHN0eWxlID0g
MywKPiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgdmFyLm5hbWUgPSBleHByZXNzaW9uKGJl
dGEpLAo+ICAgICAgICAgICAgICAgICAgICAgICAgICAgICBzdHJpcC5uYW1lcyA9IGMoVCwgVCkK
PiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgKQo+ICAgICAgICApICMgdGhlIHZhci5uYW1l
IHNob3dzIHVwIGFzICJiZXRhIgoKMS4gQnVncyBpbiBwYWNrYWdlcyBzaG91bGQgYmUgcmVwb3J0
ZWQgdG8gdGhlIG1haW50YWluZXIsIG5vdCBSLWJ1Z3MuCgoyLiBUaGlzIGFscmVhZHkgd29ya3Mg
YXMgaXQgc2hvdWxkIGluIFIgMi4zLjAgYWxwaGEKCkRlZXBheWFuCg==


From deepayan at stat.wisc.edu  Thu Mar 30 23:24:41 2006
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 30 Mar 2006 15:24:41 -0600
Subject: [Rd] custom strip in lattice ignoring plotmath expressions for
	all but style = 1 (PR#8733)
In-Reply-To: <eb555e660603301319s37a35852p4fcd2296555f8ed2@mail.gmail.com>
References: <20060330194131.1785EAB7A@slim.kubism.ku.dk>
	<eb555e660603301319s37a35852p4fcd2296555f8ed2@mail.gmail.com>
Message-ID: <200603301524.42095.deepayan@stat.wisc.edu>


Trying again...

On Thursday 30 March 2006 15:19, btyner at stat.purdue.edu wrote:

> Full_Name: Ben Tyner
> Version: 2.2.0
> OS: i686-pc-linux-gnu
> Submission from: (NULL) (128.210.141.240)
>
>
> My appologies if this has already been fixed, but I didn't see it in the
> tracking system yet so I thought I'd report it. Demonstration:
>
> xyplot(Petal.Length ~ Petal.Width | Species, iris,
>        strip = strip.custom(style = 1,
>                             var.name = expression(beta),
>                             strip.names = c(T, T)
>                )
>        ) # correct behavior w.r.t. var.name
>
> xyplot(Petal.Length ~ Petal.Width | Species, iris,
>        strip = strip.custom(style = 3,
>                             var.name = expression(beta),
>                             strip.names = c(T, T)
>                             )
>        ) # the var.name shows up as "beta"

1. Bugs in packages should be reported to the maintainer, not R-bugs.

2. This already works as it should in R 2.3.0 alpha

-Deepayan


From jeff.horner at vanderbilt.edu  Fri Mar 31 00:34:46 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Thu, 30 Mar 2006 16:34:46 -0600
Subject: [Rd] Writing character vectors with embedded nulls to a connection
Message-ID: <442C5D06.20309@vanderbilt.edu>

Is this possible? I've tried both writeChar() and writeBin() to no avail.

My goal is to serialize(ascii=FALSE) an object to a connection but 
determine the size of the serialized object before hand:

sobject <- serialize(object,NULL,ascii=FALSE)
len <- nchar(sobject)
#
# run some code here to notify listener on other end of connection
# how many bytes I'm getting ready to send
#
writeChar(sobject,con)

The other option is to serialize twice:

len <- nchar(serialize(object,NULL,ascii=FALSE))
#
# run some code here to notify listener on other end of connection
# how many bytes I'm getting ready to send
#
serialize(object,con,ascii=FALSE)

Object stores, like memcache (http://danga.com/memcached/), need to know 
object sizes before storing. RDBMS's which support large objects (CLOBS 
or BLOBS) don't nececarilly need to know object sizes before-hand, but 
they do have max column size limits which must be honored.

BTW, readchar() can read strings with embedded nulls; I figured 
writeChar() should be able to write them.

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University


From btyner at gmail.com  Fri Mar 31 00:42:24 2006
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 30 Mar 2006 17:42:24 -0500
Subject: [Rd] custom strip in lattice ignoring plotmath expressions for
 all but style = 1 (PR#8733)
In-Reply-To: <200603301524.42095.deepayan@stat.wisc.edu>
References: <20060330194131.1785EAB7A@slim.kubism.ku.dk>
	<eb555e660603301319s37a35852p4fcd2296555f8ed2@mail.gmail.com>
	<200603301524.42095.deepayan@stat.wisc.edu>
Message-ID: <442C5ED0.5000205@stat.purdue.edu>

Sorry, so used to it being bundled that I didn't realize lattice was a 
"contributed package".

Ben

Deepayan Sarkar wrote:

>
>
>1. Bugs in packages should be reported to the maintainer, not R-bugs.
>
>2. This already works as it should in R 2.3.0 alpha
>
>-Deepayan
>  
>


From btyner at gmail.com  Fri Mar 31 00:42:43 2006
From: btyner at gmail.com (btyner at gmail.com)
Date: Fri, 31 Mar 2006 00:42:43 +0200 (CEST)
Subject: [Rd] custom strip in lattice ignoring plotmath expressions for
	all (PR#8734)
Message-ID: <20060330224243.3EACDAC04@slim.kubism.ku.dk>

Sorry, so used to it being bundled that I didn't realize lattice was a 
"contributed package".

Ben

Deepayan Sarkar wrote:

>
>
>1. Bugs in packages should be reported to the maintainer, not R-bugs.
>
>2. This already works as it should in R 2.3.0 alpha
>
>-Deepayan
>  
>


From ssu at thegeorgeinstitute.org  Fri Mar 31 05:56:07 2006
From: ssu at thegeorgeinstitute.org (Steve Su)
Date: Fri, 31 Mar 2006 14:56:07 +1100
Subject: [Rd] Fortran and C entry point problem.
Message-ID: <3B862D6B11ECDE458F679DDA238A135A1D82FE@lisa>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060331/03688b47/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Mar 31 09:08:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 31 Mar 2006 08:08:09 +0100 (BST)
Subject: [Rd] [R] R garbage collection
In-Reply-To: <442C9786.4050708@yahoo.com>
References: <442C9786.4050708@yahoo.com>
Message-ID: <Pine.LNX.4.64.0603310748320.32430@gannet.stats.ox.ac.uk>

On Thu, 30 Mar 2006, Jeff Henrikson wrote:

> r-help,

[Moved to R-devel.]

> The R manual lists two types of memory: transient and user-controlled.
> If I have transient blocks reachable from the globals only by traversal
> through user-controlled blocks, will they be correctly preserved?

I don't understand your terminology, especially 'traversal'.  It is not 
normal to have either type of block reachable through R objects, and if 
you are using something like external pointers, the answer would be no.

> Secondly, what are the ways to mark user controlled blocks as "roots"
> for the garbage collector, so that transient blocks they reference stay
> uncollected?  So far I can only deduce that as long as the answer to my
> first question is yes, I can bind an arbitrary symbol to them in the
> global environment.  Is this the best way?

I think you are referring to blocks allocated by R_alloc.  The manual says

   This memory is taken from the heap, and released at the end of the .C,
   .Call or .External call. Users can also manage it, by noting the current
   position with a call to vmaxget and clearing memory allocated
   subsequently by a call to vmaxset. This is only recommended for experts.

If you want to allocate storage as part of an R object, this is not the 
best way to do it (allocVector etc are).  It is a side-effect of the 
current implementation that memory allocated by R_alloc which is made part 
of an object will be protected for the lifetime of that object, but this 
is not documented and should not be relied on.  (I am thinking if for 
example a block is made into a CHARSXP 'by hand', but the documented route 
is mkChar which makes a copy.)

> Jeff Henrikson
>
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please do, including the question `which list': this clearly belongs on 
R-devel.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar 31 09:38:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 31 Mar 2006 08:38:26 +0100 (BST)
Subject: [Rd] Writing character vectors with embedded nulls to a
	connection
In-Reply-To: <442C5D06.20309@vanderbilt.edu>
References: <442C5D06.20309@vanderbilt.edu>
Message-ID: <Pine.LNX.4.64.0603310831490.707@gannet.stats.ox.ac.uk>

I think you should be using a raw type to hold such data in R.  It is not 
intentional that readChar handles embedded nuls (and in fact it might not 
in an MBCS).

As ?serialize says

      For 'serialize', 'NULL' unless 'connection=NULL', when the result
      is stored in the first element of a character vector (but is not a
      normal character string unless 'ascii = TRUE' and should not be
      processed except by 'unserialize').

so you have been told this is not intended to work as you tried.

serialize predates the raw type, or it would have made use of it.  In 
these days of MBCS character strings it is increasingly unsafe to use them 
to hold anything other than valid character data.


On Thu, 30 Mar 2006, Jeffrey Horner wrote:

> Is this possible? I've tried both writeChar() and writeBin() to no avail.
>
> My goal is to serialize(ascii=FALSE) an object to a connection but
> determine the size of the serialized object before hand:
>
> sobject <- serialize(object,NULL,ascii=FALSE)
> len <- nchar(sobject)
> #
> # run some code here to notify listener on other end of connection
> # how many bytes I'm getting ready to send
> #
> writeChar(sobject,con)
>
> The other option is to serialize twice:
>
> len <- nchar(serialize(object,NULL,ascii=FALSE))
> #
> # run some code here to notify listener on other end of connection
> # how many bytes I'm getting ready to send
> #
> serialize(object,con,ascii=FALSE)
>
> Object stores, like memcache (http://danga.com/memcached/), need to know
> object sizes before storing. RDBMS's which support large objects (CLOBS
> or BLOBS) don't nececarilly need to know object sizes before-hand, but
> they do have max column size limits which must be honored.
>
> BTW, readchar() can read strings with embedded nulls; I figured
> writeChar() should be able to write them.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Friedrich.Leisch at tuwien.ac.at  Fri Mar 31 11:38:26 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch at tuwien.ac.at)
Date: Fri, 31 Mar 2006 11:38:26 +0200
Subject: [Rd] compress defaults for save() and save.image()
In-Reply-To: <Pine.LNX.4.64.0603301815180.23911@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0603301815180.23911@gannet.stats.ox.ac.uk>
Message-ID: <17452.63634.926399.101915@celebrian.ci.tuwien.ac.at>

>>>>> On Thu, 30 Mar 2006 18:23:11 +0100 (BST),
>>>>> Prof Brian Ripley (PBR) wrote:

  > I have changed the default in save() to compress = !ascii.  This seems 
  > quite safe, as almost always save() is called explicitly and people will
  > appreciate that it might take a little time to save large objects (and 
  > depending on your system, compression could even be faster).

Very good idea.

  > Should we also change the default in save.image()?  That is almost always 
  > used implicitly, via q(), a menu ....  There are arguments that it is a 
  > more serious change so should not be done at the end of the release cycle, 
  > and also that large .RData files are something people would want to avoid.

  > BTW, the defaults can be changed via options() (see ?save): has anyone 
  > ever found that useful?

Yes, I and many people I know have

options(save.defaults=list(compress=TRUE))

in our settings, and I'd like to keep the option version such that I
am independent from whatever the function defaults are. 


>>>>> Liaw, Andy wrote:

  > - I always use save(..., compress=TRUE), without exception.
  > - The only time I'd use save.image() is when I need to break a remote
  > connection on short notice.
  > - I have not used options() to set the default simply because I have not
  > figured out how exactly to do it.  From what I remember, the doc simply says
  > it can be done, but does not explicitly say how.

Umm, there is an explicit example in help(save), I have added a pointer from
the main text of the help page.


Best,
Fritz


From michael.watson at bbsrc.ac.uk  Fri Mar 31 12:39:19 2006
From: michael.watson at bbsrc.ac.uk (michael.watson at bbsrc.ac.uk)
Date: Fri, 31 Mar 2006 12:39:19 +0200 (CEST)
Subject: [Rd] Bug in barplot (PR#8738)
Message-ID: <20060331103919.EB41BB6A9@slim.kubism.ku.dk>

Hi

There seems to be a bug in barplot().  It occurs when specifying the
ylim argument.  It's best shown by example:

dat <- matrix(c(1,1,1,2,2,2,3,3,3),ncol=3)
barplot(dat, beside=TRUE)
X11()
barplot(dat, beside=TRUE, ylim=c(1,3))

As can be seem, drawing of the graph seems to discount the margins of
the plot.

I'm using R 2.2.1 on Windows

Thanks
Mick


From ripley at stats.ox.ac.uk  Fri Mar 31 13:02:30 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Fri, 31 Mar 2006 13:02:30 +0200 (CEST)
Subject: [Rd] Bug in barplot (PR#8738)
Message-ID: <20060331110230.5E2C4CCD4@slim.kubism.ku.dk>

It is not a bug: please read the help file

      xpd: logical. Should bars be allowed to go outside region?

and note that the default is TRUE.

On Fri, 31 Mar 2006, michael.watson at bbsrc.ac.uk wrote:

> There seems to be a bug in barplot().  It occurs when specifying the
> ylim argument.  It's best shown by example:
>
> dat <- matrix(c(1,1,1,2,2,2,3,3,3),ncol=3)
> barplot(dat, beside=TRUE)
> X11()
> barplot(dat, beside=TRUE, ylim=c(1,3))
>
> As can be seem, drawing of the graph seems to discount the margins of
> the plot.

As documented.

> I'm using R 2.2.1 on Windows

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri Mar 31 14:49:43 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 31 Mar 2006 07:49:43 -0500
Subject: [Rd] Fortran and C entry point problem.
In-Reply-To: <3B862D6B11ECDE458F679DDA238A135A1D82FE@lisa>
References: <3B862D6B11ECDE458F679DDA238A135A1D82FE@lisa>
Message-ID: <442D2567.8060108@stats.uwo.ca>

You need to tell us what platform you're on, what compilers you're 
using, etc.  The details vary.

Duncan Murdoch

On 3/30/2006 10:56 PM, Steve Su wrote:
> Dear All,
> 
>  
> 
> I have seen a number of e mails on this topic but I have not seen a
> general solution to date. I have Fortran and C source codes and they
> have been compiled successfully using:
> 
>  
> 
> R CMD build mypackage
> 
>  
> 
> And
> 
>  
> 
> R CMD install mypackage
> 
>  
> 
> Without error messages. 
> 
>  
> 
> I then open R and tests out two functions and get:
> 
>  
> 
>> pgl(0.2,1,2,3,4)
> 
> Error in .C("gl_fmkl_distfunc", lambdas[1], lambdas[2], lambdas[3],
> lambdas[4],  : 
> 
>         C entry point "gl_fmkl_distfunc" not in DLL for package
> "mypackage"
> 
>> runif.sobol(10,5)
> 
> Error in .Fortran("sobol", as.double(qn), as.integer(n),
> as.integer(dimension),  : 
> 
>         Fortran entry point "sobol_" not in DLL for package "mypackage"
> 
>  
> 
>  
> 
> Alternatively running C CMD check mypackage will also pick up these
> errors when they try to run the examples.
> 
>  
> 
> I have used Fortran and C codes already available on CRAN so I am unsure
> what is the missing link to make these work?
> 
>  
> 
> Can anyone provide an explanation and procedure to over come this
> problem?
> 
>  
> 
> Thanks.
> 
>  
> 
> Steve.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke at stat.uiowa.edu  Fri Mar 31 17:29:24 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 31 Mar 2006 09:29:24 -0600 (CST)
Subject: [Rd] [R] R garbage collection
In-Reply-To: <Pine.LNX.4.64.0603310748320.32430@gannet.stats.ox.ac.uk>
References: <442C9786.4050708@yahoo.com>
	<Pine.LNX.4.64.0603310748320.32430@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.63.0603310921450.11743@nokomis.stat.uiowa.edu>

The allocations described as User-Controlled are not part of the
GC-managed heap.  The ones described as Transient happen to be but
that is not user visible; alternate implementations might insure that
they are freed as soon as the appropriate context is left.

If you are interested in managing the lifetime of heap-allocated
objects then you register roots for the GC with R_PreserveObject.

luke

On Fri, 31 Mar 2006, Prof Brian Ripley wrote:

> On Thu, 30 Mar 2006, Jeff Henrikson wrote:
>
>> r-help,
>
> [Moved to R-devel.]
>
>> The R manual lists two types of memory: transient and user-controlled.
>> If I have transient blocks reachable from the globals only by traversal
>> through user-controlled blocks, will they be correctly preserved?
>
> I don't understand your terminology, especially 'traversal'.  It is not
> normal to have either type of block reachable through R objects, and if
> you are using something like external pointers, the answer would be no.
>
>> Secondly, what are the ways to mark user controlled blocks as "roots"
>> for the garbage collector, so that transient blocks they reference stay
>> uncollected?  So far I can only deduce that as long as the answer to my
>> first question is yes, I can bind an arbitrary symbol to them in the
>> global environment.  Is this the best way?
>
> I think you are referring to blocks allocated by R_alloc.  The manual says
>
>   This memory is taken from the heap, and released at the end of the .C,
>   .Call or .External call. Users can also manage it, by noting the current
>   position with a call to vmaxget and clearing memory allocated
>   subsequently by a call to vmaxset. This is only recommended for experts.
>
> If you want to allocate storage as part of an R object, this is not the
> best way to do it (allocVector etc are).  It is a side-effect of the
> current implementation that memory allocated by R_alloc which is made part
> of an object will be protected for the lifetime of that object, but this
> is not documented and should not be relied on.  (I am thinking if for
> example a block is made into a CHARSXP 'by hand', but the documented route
> is mkChar which makes a copy.)
>
>> Jeff Henrikson
>>
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> Please do, including the question `which list': this clearly belongs on
> R-devel.
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From bbernzwe at bear.com  Fri Mar 31 18:23:52 2006
From: bbernzwe at bear.com (Bernzweig, Bruce (Exchange))
Date: Fri, 31 Mar 2006 11:23:52 -0500
Subject: [Rd] Run t-test on multiple time series
Message-ID: <136753ACA3E9A5498440B172A77F4BF20A5D3375@whexchmb15.bsna.bsroot.bear.com>

I have two sets of time-series that I imported from Excel using RODBC
and placed in

"securities" and "factors".

 

What I need to do is generate t-scores for each security-factor pair.

 

I tried the following:

 

    t1 <- t.test(securities[,3:42], factors[,2:41], var.equal=TRUE)

 

However, this gives me just a single t-score.  Note: the numeric values
that I need are in indices 3 to 42 for securities and 2 to 41 for
factors.

 

I'm pretty new with R so I was wondering if I could use something
similar to the following where I can run some function that would
calculate against all values (all meaning each security or each factor):

 

> x <- c(1, 2, 3, 4, 5)

> y <- x+1

> y

  [1] 2 3 4 5 6

 

Or do I need to iterate through the list of securities and factors and
generate a t-score for each pair one at a time?

 

Thanks,

 

- Bruce

 

 

-------------- next part --------------


**********************************************************************
Please be aware that, notwithstanding the fact that the pers...{{dropped}}


From ripley at stats.ox.ac.uk  Fri Mar 31 18:48:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 31 Mar 2006 17:48:35 +0100 (BST)
Subject: [Rd] Writing character vectors with embedded nulls to a
	connection
In-Reply-To: <Pine.LNX.4.64.0603310831490.707@gannet.stats.ox.ac.uk>
References: <442C5D06.20309@vanderbilt.edu>
	<Pine.LNX.4.64.0603310831490.707@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0603311721420.11998@gannet.stats.ox.ac.uk>

The following approach

sobject <- charToRaw(serialize(object,NULL))
len <- length(sobject)
writeBin(sobject, outcon)

would appear to work.  As from 2.3.0 you will then be able to do

unserialize(readBin(incon, "raw", n=len))


On Fri, 31 Mar 2006, Prof Brian Ripley wrote:

> I think you should be using a raw type to hold such data in R.  It is not 
> intentional that readChar handles embedded nuls (and in fact it might not in 
> an MBCS).
>
> As ?serialize says
>
>     For 'serialize', 'NULL' unless 'connection=NULL', when the result
>     is stored in the first element of a character vector (but is not a
>     normal character string unless 'ascii = TRUE' and should not be
>     processed except by 'unserialize').
>
> so you have been told this is not intended to work as you tried.
>
> serialize predates the raw type, or it would have made use of it.  In these 
> days of MBCS character strings it is increasingly unsafe to use them to hold 
> anything other than valid character data.
>
>
> On Thu, 30 Mar 2006, Jeffrey Horner wrote:
>
>> Is this possible? I've tried both writeChar() and writeBin() to no avail.
>> 
>> My goal is to serialize(ascii=FALSE) an object to a connection but
>> determine the size of the serialized object before hand:
>> 
>> sobject <- serialize(object,NULL,ascii=FALSE)
>> len <- nchar(sobject)
>> #
>> # run some code here to notify listener on other end of connection
>> # how many bytes I'm getting ready to send
>> #
>> writeChar(sobject,con)
>> 
>> The other option is to serialize twice:
>> 
>> len <- nchar(serialize(object,NULL,ascii=FALSE))
>> #
>> # run some code here to notify listener on other end of connection
>> # how many bytes I'm getting ready to send
>> #
>> serialize(object,con,ascii=FALSE)
>> 
>> Object stores, like memcache (http://danga.com/memcached/), need to know
>> object sizes before storing. RDBMS's which support large objects (CLOBS
>> or BLOBS) don't nececarilly need to know object sizes before-hand, but
>> they do have max column size limits which must be honored.
>> 
>> BTW, readchar() can read strings with embedded nulls; I figured
>> writeChar() should be able to write them.
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Fri Mar 31 21:13:14 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 31 Mar 2006 14:13:14 -0500
Subject: [Rd] package?<pac>
Message-ID: <442D7F4A.3080002@bank-banque-canada.ca>

When I use

   package?<pac>

the author field gets reproduced twice, once with the  \author{ } string 
and a secod time formatted.

Also,  would it be possible to make   package?<pac>  find the overview 
without the package being attached,  or at least give a more informative 
error message.

Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From jmacdon at med.umich.edu  Fri Mar 31 22:23:00 2006
From: jmacdon at med.umich.edu (James MacDonald)
Date: Fri, 31 Mar 2006 15:23:00 -0500
Subject: [Rd] Segfault with too many menu items on Rgui
Message-ID: <s42d495f.003@med-gwia-02a.med.umich.edu>

Hi all,

In the CHANGES file for R-2.3.0alpha, there is the following
statement:

winMenuAdd() now has no limits on the number of menus or items, and
names are now limited to 500 (not 50) bytes.

However, I can reproducibly get a segfault using this (admittedly
silly) example:

for( i in 1:5) winMenuAdd(paste("Test", letters[i], sep=""))
for(i in 1:5) for(j in 1:24) winMenuAddItem(paste("Test", letters[i],
sep=""), as.character(j), paste(rep(letters[j], 4), collapse=""))

This is probably almost never a problem, but many Bioconductor packages
have vignettes that are added to a 'Vignettes' menu item. If you load
enough of these packages you will get a segfault.

> version
               _                                      
platform       i386-pc-mingw32                        
arch           i386                                   
os             mingw32                                
system         i386, mingw32                          
status         alpha                                  
major          2                                      
minor          3.0                                    
year           2006                                   
month          03                                     
day            29                                     
svn rev        37607                                  
language       R                                      
version.string Version 2.3.0 alpha (2006-03-29 r37607)

Best,

Jim



James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues.


