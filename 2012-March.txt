From prana at Vertica.com  Thu Mar  1 17:05:40 2012
From: prana at Vertica.com (Pratibha Rana)
Date: Thu, 1 Mar 2012 11:05:40 -0500
Subject: [Rd] mb_m buffer not cleared if parseEval fails
Message-ID: <4F4F9E54.8030005@vertica.com>

Hi,

I am using RInside for one of the applications that I'm using. The error 
that occured is as follows.

When I use  R.parseEval("xyz") if the parse fails then the mb_m is not 
cleared and hence all subsequent
calls to R.parseEval fail.

example:

when R.parseEval("stringConcatfactoryrandom") is executed the R instance 
looks like this
  (gdb) p R
$7 = (RInside &) @0x7fff13d42d10: {mb_m = {buffer = 
"stringConcatfactoryrandom"}, global_env = <incomplete type>, verbose_m 
= false, static instance_ = 0x7fff13d42d10}

since there's no function called stringConcatfactoryrandom in my R code, 
the above call fails. The I use the same R instance to call

R.parseEval("exists")    and I  get this

(gdb) p R
$8 = (RInside &) @0x7fff13d42d10: {mb_m = {buffer = 
"stringConcatfactoryrandomexists"}, global_env = <incomplete type>, 
verbose_m = false, static instance_ = 0x7fff13d42d10}

I think the buffer should be cleared after each call to parseEval


Thanks
Pratibha


From edd at debian.org  Thu Mar  1 17:39:02 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 1 Mar 2012 10:39:02 -0600
Subject: [Rd] mb_m buffer not cleared if parseEval fails
In-Reply-To: <4F4F9E54.8030005@vertica.com>
References: <4F4F9E54.8030005@vertica.com>
Message-ID: <20303.42534.652923.559562@max.nulle.part>


Hi Pratibha,

May I suggest to move this over to the rcpp-devel list (where you need to be
subscribed to post)?   I am setting an appropriate Reply-To: now, we should
then also remove the CC for r-devel.

On 1 March 2012 at 11:05, Pratibha Rana wrote:
| Hi,
| 
| I am using RInside for one of the applications that I'm using. The error 
| that occured is as follows.
| 
| When I use  R.parseEval("xyz") if the parse fails then the mb_m is not 
| cleared and hence all subsequent
| calls to R.parseEval fail.
| 
| example:
| 
| when R.parseEval("stringConcatfactoryrandom") is executed the R instance 
| looks like this
|   (gdb) p R
| $7 = (RInside &) @0x7fff13d42d10: {mb_m = {buffer = 
| "stringConcatfactoryrandom"}, global_env = <incomplete type>, verbose_m 
| = false, static instance_ = 0x7fff13d42d10}
| 
| since there's no function called stringConcatfactoryrandom in my R code, 
| the above call fails. The I use the same R instance to call
| 
We could do with a try/catch logic here.  You can either (easiest) wrap your
actual expression in a try() [ or tryCatch() ] and then submit the new
compound expression.

Or we tackle this at the C++ and add a try/catch layer in the member function
RInside::parseEval() --- which never had one as I started with the code from
littler which, being C, never had this type of exception handling.

I do not have to implement this, or try it, but if you get a chance I'd love
to hear how it goes.

| R.parseEval("exists")    and I  get this
| 
| (gdb) p R
| $8 = (RInside &) @0x7fff13d42d10: {mb_m = {buffer = 
| "stringConcatfactoryrandomexists"}, global_env = <incomplete type>, 
| verbose_m = false, static instance_ = 0x7fff13d42d10}
| 
| I think the buffer should be cleared after each call to parseEval

Other approaches may work too. What you suggest would just ignore the error
and carry on.  That may work too, but there is something about this I don't
quite like...


Cheers, Dirk

 
| Thanks
| Pratibha
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From bates at stat.wisc.edu  Thu Mar  1 18:06:51 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Mar 2012 11:06:51 -0600
Subject: [Rd] Julia
Message-ID: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>

My purpose in mentioning the Julia language (julialang.org) here is
not to start a flame war.  I find it to be a very interesting
development and others who read this list may want to read about it
too.

It is still very much early days for this language - about the same
stage as R was in 1995 or 1996 when only a few people knew about it -
but Julia holds much potential.  There is a thread about "R and
statistical programming" on groups.google.com/group/julia-dev.  As
always happens, there is a certain amount of grumbling of the "R IS
SOOOO SLOOOOW" flavor but there is also some good discussion regarding
features of R (well, S actually) that are central to the language.
(Disclaimer: I am one of the participants discussing the importance of
data frames and formulas in R.)

If you want to know why Julia has attracted a lot of interest very
recently (like in the last 10 days), as a language it uses multiple
dispatch (like S4 methods) with methods being compiled on the fly
using the LLVM (http://llvm.org) infrastructure.  In some ways it
achieves the Holy Grail of languages like R, Matlab, NumPy, ... in
that it combines the speed of compiled languages with the flexibility
of the high-level interpreted language.

One of the developers, Jeff Bezanson, gave a seminar about the design
of the language at Stanford yesterday, and the video is archived at
http://www.stanford.edu/class/ee380/.  You don't see John Chambers on
camera but I am reasonably certain that a couple of the questions and
comments came from him.


From jeffrey.ryan at lemnica.com  Thu Mar  1 18:20:41 2012
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Thu, 1 Mar 2012 11:20:41 -0600
Subject: [Rd] Julia
In-Reply-To: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
Message-ID: <CABDUZc_oOs1Oh0xR7_0g5_yBs2Q0SgUfhA-xyc9hMNq1n+bMvg@mail.gmail.com>

Doug,

Agreed on the interesting point - looks like it has some real promise.
 I think the spike in interest could be attributable to Mike
Loukides's tweet on Feb 20. (editor at O'Reilly)

https://twitter.com/#!/mikeloukides/status/171773229407551488

That is exactly the moment I stumbled upon it.

Jeff

On Thu, Mar 1, 2012 at 11:06 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> My purpose in mentioning the Julia language (julialang.org) here is
> not to start a flame war. ?I find it to be a very interesting
> development and others who read this list may want to read about it
> too.
>
> It is still very much early days for this language - about the same
> stage as R was in 1995 or 1996 when only a few people knew about it -
> but Julia holds much potential. ?There is a thread about "R and
> statistical programming" on groups.google.com/group/julia-dev. ?As
> always happens, there is a certain amount of grumbling of the "R IS
> SOOOO SLOOOOW" flavor but there is also some good discussion regarding
> features of R (well, S actually) that are central to the language.
> (Disclaimer: I am one of the participants discussing the importance of
> data frames and formulas in R.)
>
> If you want to know why Julia has attracted a lot of interest very
> recently (like in the last 10 days), as a language it uses multiple
> dispatch (like S4 methods) with methods being compiled on the fly
> using the LLVM (http://llvm.org) infrastructure. ?In some ways it
> achieves the Holy Grail of languages like R, Matlab, NumPy, ... in
> that it combines the speed of compiled languages with the flexibility
> of the high-level interpreted language.
>
> One of the developers, Jeff Bezanson, gave a seminar about the design
> of the language at Stanford yesterday, and the video is archived at
> http://www.stanford.edu/class/ee380/. ?You don't see John Chambers on
> camera but I am reasonably certain that a couple of the questions and
> comments came from him.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com

R/Finance 2012: Applied Finance with R
www.RinFinance.com

See you in Chicago!!!!


From bates at stat.wisc.edu  Thu Mar  1 18:37:27 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Mar 2012 11:37:27 -0600
Subject: [Rd] Julia
In-Reply-To: <CABDUZc_oOs1Oh0xR7_0g5_yBs2Q0SgUfhA-xyc9hMNq1n+bMvg@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<CABDUZc_oOs1Oh0xR7_0g5_yBs2Q0SgUfhA-xyc9hMNq1n+bMvg@mail.gmail.com>
Message-ID: <CAO7JsnRaTCAHrgu-j-GpiSERvULk3R+34o+EZtxusfAxPRLQMw@mail.gmail.com>

On Thu, Mar 1, 2012 at 11:20 AM, Jeffrey Ryan <jeffrey.ryan at lemnica.com> wrote:
> Doug,
>
> Agreed on the interesting point - looks like it has some real promise.
> ?I think the spike in interest could be attributable to Mike
> Loukides's tweet on Feb 20. (editor at O'Reilly)
>
> https://twitter.com/#!/mikeloukides/status/171773229407551488
>
> That is exactly the moment I stumbled upon it.

I think Jeff Bezanson attributes the interest to a blog posting by
Viral Shah, another member of the development team, that hit Reddit.
He said that, with Viral now in India, it all happened overnight for
those in North America and he awoke the next day to find a firestorm
of interest.  I ran across Julia in the Release Notes of LLVM and
mentioned it to Dirk Eddelbuettel who posted about it on Google+ in
January.  (Dirk, being much younger than I, knows about these
new-fangled social media things and I don't.)


From ligges at statistik.tu-dortmund.de  Thu Mar  1 19:52:09 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 01 Mar 2012 19:52:09 +0100
Subject: [Rd] missing value break my if clause and crash my program
In-Reply-To: <1330519010.98298.YahooMailClassic@web88609.mail.bf1.yahoo.com>
References: <1330519010.98298.YahooMailClassic@web88609.mail.bf1.yahoo.com>
Message-ID: <4F4FC559.6010407@statistik.tu-dortmund.de>



On 29.02.2012 13:36, zisheng xing wrote:
> I have a program which is designed to read through a dbf file and carry out certain amount of further calculation if one condition obtained from the newly read line. The condition to determine if the calculation can be done is a if-clasue (i.e. if(m>0). Unfortunately, when m is missing, the program crashed. Just wonder who can help me out.

1. Please ask questions on R-help after reading its posting guide. 
R-devel is for development purposes.

2. Your code results in an ERROR rather than a crash.

3. Check if m exists before you compare it to some value.

Uwe Ligges





>
> Thanks
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Thu Mar  1 21:28:24 2012
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 01 Mar 2012 12:28:24 -0800
Subject: [Rd] improved error message when existing implicit S4 generic
 is not imported?
In-Reply-To: <4F4B3D31.50400@stats.ox.ac.uk>
References: <4F49D3B5.5010507@fhcrc.org> <4F4B3D31.50400@stats.ox.ac.uk>
Message-ID: <4F4FDBE8.1010801@fhcrc.org>

Hi,

On 02/27/2012 12:22 AM, Prof Brian Ripley wrote:
...
>(Re another message: stats4 *is* "methodsGenerics" for base packages.)

Why isn't it called base4 if it's for "base" packages?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kjetilbrinchmannhalvorsen at gmail.com  Thu Mar  1 21:32:40 2012
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Thu, 1 Mar 2012 14:32:40 -0600
Subject: [Rd] Julia
In-Reply-To: <CAO7JsnRaTCAHrgu-j-GpiSERvULk3R+34o+EZtxusfAxPRLQMw@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<CABDUZc_oOs1Oh0xR7_0g5_yBs2Q0SgUfhA-xyc9hMNq1n+bMvg@mail.gmail.com>
	<CAO7JsnRaTCAHrgu-j-GpiSERvULk3R+34o+EZtxusfAxPRLQMw@mail.gmail.com>
Message-ID: <CACU_Y098SmKrmW0cXWRvsUi8wR4Cvg9xB8413wrq15GzndiLYg@mail.gmail.com>

Can somebody postb a link to the video? I cant find it, searching
"Julia" on youtube stanford channel gives nothing.

Kjetil

On Thu, Mar 1, 2012 at 11:37 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Thu, Mar 1, 2012 at 11:20 AM, Jeffrey Ryan <jeffrey.ryan at lemnica.com> wrote:
>> Doug,
>>
>> Agreed on the interesting point - looks like it has some real promise.
>> ?I think the spike in interest could be attributable to Mike
>> Loukides's tweet on Feb 20. (editor at O'Reilly)
>>
>> https://twitter.com/#!/mikeloukides/status/171773229407551488
>>
>> That is exactly the moment I stumbled upon it.
>
> I think Jeff Bezanson attributes the interest to a blog posting by
> Viral Shah, another member of the development team, that hit Reddit.
> He said that, with Viral now in India, it all happened overnight for
> those in North America and he awoke the next day to find a firestorm
> of interest. ?I ran across Julia in the Release Notes of LLVM and
> mentioned it to Dirk Eddelbuettel who posted about it on Google+ in
> January. ?(Dirk, being much younger than I, knows about these
> new-fangled social media things and I don't.)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Ted.Harding at wlandres.net  Thu Mar  1 21:47:47 2012
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 01 Mar 2012 20:47:47 -0000 (GMT)
Subject: [Rd] Julia
In-Reply-To: <CACU_Y098SmKrmW0cXWRvsUi8wR4Cvg9xB8413wrq15GzndiLYg@mail.gmail.com>
Message-ID: <XFMail.20120301204747.Ted.Harding@wlandres.net>

http://julialang.org/blog

Then click on "Stanford Talk Video".
Then click on "available here".

Ted.

On 01-Mar-2012 Kjetil Halvorsen wrote:
> Can somebody postb a link to the video? I cant find it, searching
> "Julia" on youtube stanford channel gives nothing.
> 
> Kjetil
> 
> On Thu, Mar 1, 2012 at 11:37 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Thu, Mar 1, 2012 at 11:20 AM, Jeffrey Ryan <jeffrey.ryan at lemnica.com>
>> wrote:
>>> Doug,
>>>
>>> Agreed on the interesting point - looks like it has some real promise.
>>> ?_I think the spike in interest could be attributable to Mike
>>> Loukides's tweet on Feb 20. (editor at O'Reilly)
>>>
>>> https://twitter.com/#!/mikeloukides/status/171773229407551488
>>>
>>> That is exactly the moment I stumbled upon it.
>>
>> I think Jeff Bezanson attributes the interest to a blog posting by
>> Viral Shah, another member of the development team, that hit Reddit.
>> He said that, with Viral now in India, it all happened overnight for
>> those in North America and he awoke the next day to find a firestorm
>> of interest. ?_I ran across Julia in the Release Notes of LLVM and
>> mentioned it to Dirk Eddelbuettel who posted about it on Google+ in
>> January. ?_(Dirk, being much younger than I, knows about these
>> new-fangled social media things and I don't.)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 01-Mar-2012  Time: 20:47:42
This message was sent by XFMail


From karl.forner at gmail.com  Fri Mar  2 10:36:14 2012
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 2 Mar 2012 10:36:14 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <20120217230633.GA19243@cs.cas.cz>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
Message-ID: <CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120302/2a54e4ce/attachment.pl>

From karl.forner at gmail.com  Fri Mar  2 10:38:54 2012
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 2 Mar 2012 10:38:54 +0100
Subject: [Rd] c/c++ Random Number Generators Benchmarks using OpenMP
Message-ID: <CAMd4_AeSiWaJQ94HxwwXiURFsqa=ygP4LX9x57wVvebYptiY8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120302/541bdd43/attachment.pl>

From savicky at cs.cas.cz  Fri Mar  2 12:24:41 2012
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 2 Mar 2012 12:24:41 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
	<CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
Message-ID: <20120302112441.GA28122@cs.cas.cz>

On Fri, Mar 02, 2012 at 10:36:14AM +0100, Karl Forner wrote:
[...]
> Hello,
> I would be also in favor for using multiple seeds based on (seed,
> task_number) for convenience (i.e. avoiding storing the seeds)
> and with the possibility of having a dynamic number of tasks, but I am mot
> sure it is theoretically correct.
> But I can refer you to this article:
> http://www.agner.org/random/ran-instructions.pdf , section 6.1
> where the author states:
> 
> For example, if we make 100 streams of 10^10 random numbers each from an
> > SFMT
> > generator with cycle length ? = 2^11213, we have a probability of overlap
> > p ? 10^3362.
> >
> 
> What do you think ? I am very concerned by the correctness of this approach
> so would appreciate any advice on that matter.

Hi.

If correctness is crucial, then the literature on cryptography provides
the best answers. At the current state of knowledge, it is not possible
to prove that a generator is undistinguishable from truly random numbers
in a mathematical sense. The problem is that if we can prove this for
any generator, then the proof also implies P \not= NP. This is an open
problem, so proving that any generator is correct in the sense of
undistinguishability is also open.

The best, what we can have, is a generator, which cannot be distinguished
from truly random numbers using the known methods, although experts on
cryptography tried to find such a method intensively. An example of such a
generator is Fortuna generator using AES, which is available at CRAN as "randaes".

  http://en.wikipedia.org/wiki/Fortuna_PRNG

The same can be said about initializations. Initialization is a random
number generator, whose output is used as the initial state of some
other generator. There is no proof that a particular initialization cannot
be distinguished from truly random numbers in a mathematical sense for
the same reason as above.

A possible strategy is to use a cryptographically strong hash function
for the initialization. This means to transform the seed to the initial
state of the generator using a function, for which we have a good
guarantee that it produces output, which is computationally hard to
distinguish from truly random numbers. For this purpose, i suggest
to use the package rngSetSeed provided currently at

  http://www.cs.cas.cz/~savicky/randomNumbers/

It is based on AES and Fortuna similarly as "randaes", but these
components are used only for the initialization of Mersenne-Twister.
When the generator is initialized, then it runs on its usual speed.

In the notation of

  http://www.agner.org/random/ran-instructions.pdf

using rngSetSeed for initialization of Mersenne-Twister is Method 4
in Section 6.1.

I appreciate comments.

Petr Savicky.

P.S. I included some more comments on the relationship of provably good
random number generators and P ?= NP question to the end of the page

  http://www.cs.cas.cz/~savicky/randomNumbers/


From savicky at cs.cas.cz  Fri Mar  2 13:36:08 2012
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 2 Mar 2012 13:36:08 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
	<CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
Message-ID: <20120302123608.GB28122@cs.cas.cz>

On Fri, Mar 02, 2012 at 10:36:14AM +0100, Karl Forner wrote:
[...]
> Hello,
> I would be also in favor for using multiple seeds based on (seed,
> task_number) for convenience (i.e. avoiding storing the seeds)
> and with the possibility of having a dynamic number of tasks, but I am mot
> sure it is theoretically correct.
> But I can refer you to this article:
> http://www.agner.org/random/ran-instructions.pdf , section 6.1
> where the author states:
> 
> For example, if we make 100 streams of 10^10 random numbers each from an
> > SFMT
> > generator with cycle length ? = 2^11213, we have a probability of overlap
> > p ? 10^3362.
> >
> 
> What do you think ? I am very concerned by the correctness of this approach
> so would appreciate any advice on that matter.

Hi.

First, let us consider a theoretical scenario, where the starting
points are chosen independently and from the uniform distribution.
Then the above should be OK.

SFMT supports several different periods, one of them is 2^11213-1.
If we choose 100 random starting points in the cycle of this
length and consider intervals of length 10^10 each, then two
of them overlap with probability

  (2 * 10^10 - 1) / (2^11213 - 1)

which is approx 10^-3365. An upper bound on the probability that
any of the 100 overlap is

  choose(100, 2) * (2 * 10^10 - 1) / (2^11213 - 1)

which is still negligible and approx 10^-3362 as you say except
of a typo in the sign.

The crucial assumption is that we choose the starting points
from the uniform distribution over the period. Every point
on the period cycle is represented by a different internal
state of the generator. So, uniform distribution on the period
is equivalent to the uniform distribution on admissible states. 
An admissible state is represented by 11213 bits, which are
not all 0. The probability of all 0 is extremely small. So, 
in order to generate one such state, it is sufficient to fill
the state array with uniform i.i.d. bits. This is suitable
only as a theoretical model, since this can guarantee
reproducibility only if we store the whole state.

In order to guarantee reproducibility with simpler means, we
cannot fill the initial state with uniform i.i.d. random bits.
So, we do not have a uniform distribution over the period, but we
can have different approximations to it. A cryptographically
strong hash function is such an approximation in the sense
of computational indistinguishability. It does not and also
cannot approximate the uniform distribution in the statistical
sense, since the set of possible outputs is much smaller than
the period. However, if someone gives us two initial states,
one from the hash function and the other created from uniform
i.i.d. bits, then there is no known computational method to
distinguish these two in moderate CPU time. So, you can safely
use the output of the hash function for simulations.

In fact, the requirements of simulations are weaker. For example,
MD5 cannot be used for cryptography any more, since there are known
algorithms to break it. However, if you use it for a simulation,
then the simulation will be biased only if it contains an algorithm,
which breaks MD5. The probability that this happens just by chance
is small.

Petr Savicky.


From karl.forner at gmail.com  Fri Mar  2 13:36:34 2012
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 2 Mar 2012 13:36:34 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <20120302112441.GA28122@cs.cas.cz>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
	<CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
	<20120302112441.GA28122@cs.cas.cz>
Message-ID: <CAMd4_Ae_Lpr_S_oQH-voUSaymoqBpWBAw71M6ufRgLHV2BEBtQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120302/0e40e822/attachment.pl>

From maechler at stat.math.ethz.ch  Fri Mar  2 14:32:58 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Mar 2012 14:32:58 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
	<CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
Message-ID: <20304.52234.90441.676731@stat.math.ethz.ch>

>>>>> Karl Forner <karl.forner at gmail.com>
>>>>>     on Fri, 2 Mar 2012 10:36:14 +0100 writes:

    >> Some of the random number generators allow as a seed a
    >> vector, not only a single number. This can simplify
    >> generating the seeds.  There can be one seed for each of
    >> the 1000 runs and then, the rows of the seed matrix can
    >> be
    >> 
    >> c(seed1, 1), c(seed1, 2), ...  c(seed2, 1), c(seed2, 2),
    >> ...  c(seed3, 1), c(seed3, 2), ...  ...
    >> 
    >> There could be even only one seed and the matrix can be
    >> generated as
    >> 
    >> c(seed, 1, 1), c(seed, 1, 2), ...  c(seed, 2, 1), c(seed,
    >> 2, 2), ...  c(seed, 3, 1), c(seed, 3, 2), ...
    >> 
    >> If the initialization using the vector c(seed, i, j) is
    >> done with a good quality hash function, the runs will be
    >> independent.
    >> 
    >> What is your opinion on this?
    >> 
    >> An advantage of seeding with a vector is also that there
    >> can be significantly more initial states of the generator
    >> among which we select by the seed than 2^32, which is the
    >> maximum for a single integer seed.
    >> 
    >> 

    > Hello, I would be also in favor for using multiple seeds
    > based on (seed, task_number) for convenience
    > (i.e. avoiding storing the seeds) and with the possibility
    > of having a dynamic number of tasks, but I am mot sure it
    > is theoretically correct.  But I can refer you to this
    > article: http://www.agner.org/random/ran-instructions.pdf
    > , section 6.1 where the author states:

    > For example, if we make 100 streams of 10^10 random
    > numbers each from an
    >> SFMT generator with cycle length ? = 2^11213, we have a
    >> probability of overlap p ? 10^3362.
    >> 

    > What do you think ? 

well, if that article really gets a probability of 10^3362
(= Inf in R's double precision) 
I'd doubt the validity of every thing else there,
but maybe you've got a transcription error there?

;-)

Martin

    > I am very concerned by the correctness
    > of this approach so would appreciate any advice on that
    > matter.

    > Thanks Karl

    > 	[[alternative HTML version deleted]]


    > ----------------------------------------------------------------------
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From Denis.Croize.Fillon at ifremer.fr  Fri Mar  2 14:10:56 2012
From: Denis.Croize.Fillon at ifremer.fr (=?ISO-8859-1?Q?Denis_Croiz=E9-Fillon?=)
Date: Fri, 02 Mar 2012 14:10:56 +0100
Subject: [Rd] make check fails for R.2.14.1 / SUSE Linux Enterprise Server
 11 (x86_64) / intel compiler 11.1
Message-ID: <4F50C6E0.9020709@ifremer.fr>

             Hi,

On a linux (suse 11p1 64 bits) and intel compiler (11.1 20100806), for R 
2.14.1 I ran :
./configure
make
The config.log file is available at 
ftp://ftp.ifremer.fr/ifremer/divers_permanents/config.log

Binary file R is created, all seems Ok. However :
make check
fails with the message :
make[1]: Entering directory `/tmp/R/R-2.14.1/tests'
make[2]: Entering directory `/tmp/R/R-2.14.1/tests'
make[3]: Entering directory `/tmp/R/R-2.14.1/tests/Examples'
Testing examples for package 'base'
Error: testing 'base' failed
Execution halted
make[3]: *** [test-Examples-Base] Error 1
make[3]: Leaving directory `/tmp/R/R-2.14.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/tmp/R/R-2.14.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/tmp/R/R-2.14.1/tests'
make: *** [check] Error 2

 From base-Ex.Rout.fail (available at base-Ex.Rout.fail), the following 
tests return FALSE and stop the execution
!identical(0, -0, num.eq=FALSE)
!identical(NaN, -NaN, single.NA=FALSE)
!identical(m, m0, attrib.as.set=FALSE)

As I'm not familiar with R, I looked for similar problems in R-devel 
archives without success.
I also tried with a previous version (2.11.1) used until now, with the 
same environment, parameters and compiler, the make check works fine

Thanks a lot for your help

Best regards,
Denis


From ligges at statistik.tu-dortmund.de  Fri Mar  2 14:44:41 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 02 Mar 2012 14:44:41 +0100
Subject: [Rd] make check fails for R.2.14.1 / SUSE Linux Enterprise
 Server 11 (x86_64) / intel compiler 11.1
In-Reply-To: <4F50C6E0.9020709@ifremer.fr>
References: <4F50C6E0.9020709@ifremer.fr>
Message-ID: <4F50CEC9.6010109@statistik.tu-dortmund.de>

1. Have you followed the hints about configuration with Intel compilers 
in the R Installation and Administration manual?
2. Havbe you tried R-2.14.2 which is the current reelase version (since 
two days)?

Uwe Ligges


On 02.03.2012 14:10, Denis Croiz?-Fillon wrote:
> Hi,
>
> On a linux (suse 11p1 64 bits) and intel compiler (11.1 20100806), for R
> 2.14.1 I ran :
> ./configure
> make
> The config.log file is available at
> ftp://ftp.ifremer.fr/ifremer/divers_permanents/config.log
>
> Binary file R is created, all seems Ok. However :
> make check
> fails with the message :
> make[1]: Entering directory `/tmp/R/R-2.14.1/tests'
> make[2]: Entering directory `/tmp/R/R-2.14.1/tests'
> make[3]: Entering directory `/tmp/R/R-2.14.1/tests/Examples'
> Testing examples for package 'base'
> Error: testing 'base' failed
> Execution halted
> make[3]: *** [test-Examples-Base] Error 1
> make[3]: Leaving directory `/tmp/R/R-2.14.1/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/tmp/R/R-2.14.1/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/tmp/R/R-2.14.1/tests'
> make: *** [check] Error 2
>
>  From base-Ex.Rout.fail (available at base-Ex.Rout.fail), the following
> tests return FALSE and stop the execution
> !identical(0, -0, num.eq=FALSE)
> !identical(NaN, -NaN, single.NA=FALSE)
> !identical(m, m0, attrib.as.set=FALSE)
>
> As I'm not familiar with R, I looked for similar problems in R-devel
> archives without success.
> I also tried with a previous version (2.11.1) used until now, with the
> same environment, parameters and compiler, the make check works fine
>
> Thanks a lot for your help
>
> Best regards,
> Denis
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From savicky at cs.cas.cz  Fri Mar  2 14:51:30 2012
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 2 Mar 2012 14:51:30 +0100
Subject: [Rd] portable parallel seeds project: request for critiques
In-Reply-To: <CAMd4_Ae_Lpr_S_oQH-voUSaymoqBpWBAw71M6ufRgLHV2BEBtQ@mail.gmail.com>
References: <CAErODj-KZo+Am6a30pnVrPC-STw++500=QOi-rZaMsXYWzeX+Q@mail.gmail.com>
	<20120217230633.GA19243@cs.cas.cz>
	<CAMd4_AdVia=Ur530VEyqUxH9vf52E6-SyzgakGZm9K1ncD2GYg@mail.gmail.com>
	<20120302112441.GA28122@cs.cas.cz>
	<CAMd4_Ae_Lpr_S_oQH-voUSaymoqBpWBAw71M6ufRgLHV2BEBtQ@mail.gmail.com>
Message-ID: <20120302135129.GA11697@cs.cas.cz>

On Fri, Mar 02, 2012 at 01:36:34PM +0100, Karl Forner wrote:
> Thanks for your quick reply.
> 
> About the rngSetSeed package: is it usable at c/c++ level ?

Not directly. The rngSetSeed package is meant to provide an R-level
alternative to set.seed() for Mersenne-Twister with a better guarantee
that different seeds provide unrelated streams. In particular, with
rngSetSeed, it should be safe to reseed quite often, for example
in each iteration of a loop like

  for (i in 1:n) {
      setVectorSeed(c(base.seed, i))
      # some code
  }

Otherwise everything remains the same as with set.seed(). In order
to maintain several streams, one has to maintain copies of .Random.seed
and use them, when required.

> Hmm I had not paid attention to the last paragraph:
> 
> > The seeding procedure used in the
> > present software use*s a separate random number* generator of a different
> > design in order to
> > avoid any interference. An extra feature is the RandomInitByArray function
> > which makes
> > it possible to initialize the random number generator with multiple seeds.
> > We can make sure
> > that the streams have different starting points by using the thread id as
> > one of the seeds.
> >
> 
> So it means that I am already using this solution ! (in the RcppRandomSFTM,
> see other post).
> and that I should be reasonably safe.

If RcppRandomSFTM uses the initialization for SFMT provided by the
authors of SFMT, then you should be reasonably safe. I do not know
exactly the SFMT initializations, but for the original Mersenne-Twister,
the initializations from 2002, both the single number seed and a vector
seed avoid known problems with the previous initializations. It should
be pointed out, however, that the initialization by array from 2002 is
more careful than the single number initialization, So, it is better to
use the array initialization even for a single number seed.

Petr Savicky.


From OleF.Christensen at agrsci.dk  Fri Mar  2 14:57:08 2012
From: OleF.Christensen at agrsci.dk (Ole Fredslund Christensen)
Date: Fri, 2 Mar 2012 14:57:08 +0100
Subject: [Rd] print method for summary adds trailing zero
Message-ID: <5D46A8E0D922A14E98DA61151D68DF870140247139E6@DJFEXMBX01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120302/83fd6072/attachment.pl>

From Denis.Croize.Fillon at ifremer.fr  Fri Mar  2 16:09:57 2012
From: Denis.Croize.Fillon at ifremer.fr (=?ISO-8859-1?Q?Denis_Croiz=E9-Fillon?=)
Date: Fri, 02 Mar 2012 16:09:57 +0100
Subject: [Rd] make check fails for R.2.14.1 / SUSE Linux Enterprise
 Server 11 (x86_64) / intel compiler 11.1
In-Reply-To: <4F50CEC9.6010109@statistik.tu-dortmund.de>
References: <4F50C6E0.9020709@ifremer.fr>
	<4F50CEC9.6010109@statistik.tu-dortmund.de>
Message-ID: <4F50E2C5.3020809@ifremer.fr>


	Dear Uwe,

looking again my environment with configuration given, I missed some, sorry.
I downloaded the last version and compiled it with my updated 
environment : make check is Ok.

Thank you very much for your quick help

Best regards,
Denis

On 02/03/12 14:44, Uwe Ligges wrote:
> 1. Have you followed the hints about configuration with Intel compilers
> in the R Installation and Administration manual?
> 2. Havbe you tried R-2.14.2 which is the current reelase version (since
> two days)?
>
> Uwe Ligges
>
>
> On 02.03.2012 14:10, Denis Croiz?-Fillon wrote:
>> Hi,
>>
>> On a linux (suse 11p1 64 bits) and intel compiler (11.1 20100806), for R
>> 2.14.1 I ran :
>> ./configure
>> make
>> The config.log file is available at
>> ftp://ftp.ifremer.fr/ifremer/divers_permanents/config.log
>>
>> Binary file R is created, all seems Ok. However :
>> make check
>> fails with the message :
>> make[1]: Entering directory `/tmp/R/R-2.14.1/tests'
>> make[2]: Entering directory `/tmp/R/R-2.14.1/tests'
>> make[3]: Entering directory `/tmp/R/R-2.14.1/tests/Examples'
>> Testing examples for package 'base'
>> Error: testing 'base' failed
>> Execution halted
>> make[3]: *** [test-Examples-Base] Error 1
>> make[3]: Leaving directory `/tmp/R/R-2.14.1/tests/Examples'
>> make[2]: *** [test-Examples] Error 2
>> make[2]: Leaving directory `/tmp/R/R-2.14.1/tests'
>> make[1]: *** [test-all-basics] Error 1
>> make[1]: Leaving directory `/tmp/R/R-2.14.1/tests'
>> make: *** [check] Error 2
>>
>> From base-Ex.Rout.fail (available at base-Ex.Rout.fail), the following
>> tests return FALSE and stop the execution
>> !identical(0, -0, num.eq=FALSE)
>> !identical(NaN, -NaN, single.NA=FALSE)
>> !identical(m, m0, attrib.as.set=FALSE)
>>
>> As I'm not familiar with R, I looked for similar problems in R-devel
>> archives without success.
>> I also tried with a previous version (2.11.1) used until now, with the
>> same environment, parameters and compiler, the make check works fine
>>
>> Thanks a lot for your help
>>
>> Best regards,
>> Denis
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Mar  2 16:25:10 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 2 Mar 2012 10:25:10 -0500
Subject: [Rd] print method for summary adds trailing zero
In-Reply-To: <5D46A8E0D922A14E98DA61151D68DF870140247139E6@DJFEXMBX01.djf.agrsci.dk>
References: <5D46A8E0D922A14E98DA61151D68DF870140247139E6@DJFEXMBX01.djf.agrsci.dk>
Message-ID: <2A8316E9-079D-4E42-9A57-E17D733F96A7@r-project.org>


On Mar 2, 2012, at 8:57 AM, Ole Fredslund Christensen wrote:

> Dear R-devel
> 
> Thought I better report this. An example is shown below.
> 
>> vec <- rnorm(100)+10.5
>> ss <- summary(vec)
>> print(ss)
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  8.433   9.886  10.450  10.560  11.300  12.720
>> for(kk in 1:length(ss)) print(ss[[kk]])
> [1] 8.433
> [1] 9.886
> [1] 10.45
> [1] 10.56
> [1] 11.3
> [1] 12.72
>> print(mean(vec))
> [1] 10.56399
> 
> Note the difference between 10.56399 and 10.560.
> It may confuse users that the number of significant digits is smaller than the number of digits shown by the print of a summary object (at least it confused me).
> 

Well, that's not even the really confusing one -- thy this:

> vec <- round((rnorm(100)+10.5)*100000)
> summary(vec)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 768000  966000 1053000 1048000 1107000 1316000 
> max(vec)
[1] 1315985

That's the point at which you decide never to use summary() again ;).

Cheers,
Simon


From mario.frasca at nelen-schuurmans.nl  Fri Mar  2 16:49:45 2012
From: mario.frasca at nelen-schuurmans.nl (Mario Frasca)
Date: Fri, 02 Mar 2012 16:49:45 +0100
Subject: [Rd] seeing feedback when R CMD check pkg runs unit tests.
Message-ID: <1330703385.2502.98.camel@nens-lt-92>

good day here,

I'm maintaining a couple of R modules, both on r-forge.

tests for these modules are written making use of unit testing, and I
make use of the svUnit module, part of SciViews-R.

I also make use of examples in the .Rd files.

my question regards 'R CMD check pkg'.

if an _example_ is not run correctly, I get clear feedback on the
command line where I run 'R CMD check pkg'.  _unit tests_ on the other
hand may give failure or error, or may be marked as skipped.  all these
conditions are caught by the unit testing module that allows the unit
testing script to produce a complete report.

if the unit testing module manages to run the tests, the report is
generated and 'R CMD check pkg' will say "OK".

maybe you find here a more verbose description of the issue:
http://stackoverflow.com/questions/2737680/
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14702

very briefly: I'd like the check to include the possibility to issue a
NOTE or a WARNING message, respectively for skipped and failing tests.

as I understood it, I can write my own check-my.R routine and use 'R CMD
check-my pkg'.

but this way my modules would check-my (on my system) differently than
they would check, say, on r-forge.  r-forge would tell me my module is
all right for releasing even if it has failing unit tests.

let me exaggerate: doesn't this sound to you as if unit testing was
discouraged by R?

many thanks for all replies,
MF


From pgilbert902 at gmail.com  Fri Mar  2 18:15:48 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 02 Mar 2012 12:15:48 -0500
Subject: [Rd] seeing feedback when R CMD check pkg runs unit tests.
In-Reply-To: <1330703385.2502.98.camel@nens-lt-92>
References: <1330703385.2502.98.camel@nens-lt-92>
Message-ID: <4F510044.80600@gmail.com>

Mario

I think of the RUnit and svUnit testing to be in addition to the 
standard  R package testing framework. You can get unit and more 
integrated testing results, with the behaviour I think you are looking 
for, simply by putting small test files in the tests/ directory of the 
package. These files should stop("error message") or warning("message") 
when your code does not get expected results. I'm not sure about "note" 
but you might consider avoiding those, since the R CMD check "notes" 
tend to become warnings or errors in a later version. R CMD check gives 
the same sorts of messages for these as it does for examples. Examples 
only need to run, but in tests/ you can do things like

if( 2*2 != 4 ) stop("arithmatic is messed up.")

and R CMD check will flag this problem.

CRAN disables some of this testing for time consideration, but your own 
R CMD check will run the tests, and I think R-forge does not 
automatically disable anything (yet). So, it may be necessary to arrange 
  skipping tests that you expect to fail on some platforms.

You may be able to get similar results from RUnit or svUnit, it would 
just be a question of passing the stop() and warnings() back to the top 
level in the script file in tests/. If you don't do that, as you 
observed, R CMD check thinks the unit testing worked fine, it did its 
job and found the errors.

(Happy to hear additional points of view on this, my understanding of 
RUnit and svUnit is limited.)

Paul

On 12-03-02 10:49 AM, Mario Frasca wrote:
> good day here,
>
> I'm maintaining a couple of R modules, both on r-forge.
>
> tests for these modules are written making use of unit testing, and I
> make use of the svUnit module, part of SciViews-R.
>
> I also make use of examples in the .Rd files.
>
> my question regards 'R CMD check pkg'.
>
> if an _example_ is not run correctly, I get clear feedback on the
> command line where I run 'R CMD check pkg'.  _unit tests_ on the other
> hand may give failure or error, or may be marked as skipped.  all these
> conditions are caught by the unit testing module that allows the unit
> testing script to produce a complete report.
>
> if the unit testing module manages to run the tests, the report is
> generated and 'R CMD check pkg' will say "OK".
>
> maybe you find here a more verbose description of the issue:
> http://stackoverflow.com/questions/2737680/
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14702
>
> very briefly: I'd like the check to include the possibility to issue a
> NOTE or a WARNING message, respectively for skipped and failing tests.
>
> as I understood it, I can write my own check-my.R routine and use 'R CMD
> check-my pkg'.
>
> but this way my modules would check-my (on my system) differently than
> they would check, say, on r-forge.  r-forge would tell me my module is
> all right for releasing even if it has failing unit tests.
>
> let me exaggerate: doesn't this sound to you as if unit testing was
> discouraged by R?
>
> many thanks for all replies,
> MF
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From oliver at first.in-berlin.de  Sat Mar  3 02:14:13 2012
From: oliver at first.in-berlin.de (oliver)
Date: Sat, 3 Mar 2012 02:14:13 +0100
Subject: [Rd] Julia
In-Reply-To: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
Message-ID: <20120303011413.GA18995@siouxsie>

On Thu, Mar 01, 2012 at 11:06:51AM -0600, Douglas Bates wrote:
> My purpose in mentioning the Julia language (julialang.org) here is
> not to start a flame war.  I find it to be a very interesting
> development and others who read this list may want to read about it
> too.
[...]


Very interesting language.
Thank you for mentioning it here.

Compiling from the github-sources was easy.

Will explore it during the next days.

Seems not to be very specific to statistics,
but good for math in general.

Not sure, if it might make sense to combine
R and Julia in the long run (I mean: combining via
providing interfaces between them, calling the one via the
other, merging code or using libs from the one or the other
from each side).

Ciao,
   Oliver


From akin1876 at gmail.com  Sat Mar  3 14:35:02 2012
From: akin1876 at gmail.com (Serdar)
Date: Sat, 03 Mar 2012 14:35:02 +0100
Subject: [Rd] Roxygen
Message-ID: <4F521E06.8010602@gmail.com>

Hi,

I'm writing documentation using Roxygen and writing in Swedish. But I 
can't use ??? for instance and I haven't found any encoding option in 
the R-manual. Is there any one that can help me?

Regards Serdar


From therneau at mayo.edu  Sat Mar  3 14:42:43 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Sat, 03 Mar 2012 07:42:43 -0600
Subject: [Rd] .C clarification
Message-ID: <1330782163.27537.24.camel@nemo>

Does .C duplicate unnecessary arguments?  For instance
  fit <- .C("xxx", as.integer(n), x, y, z=double(15))

The first and fourth arguments would have NAMED = 0. Is my guess that .C
won't make yet one more (unnecessary) copy correct?

(Just trying to understand).

Terry T


From mariotomo at gmail.com  Sat Mar  3 09:56:04 2012
From: mariotomo at gmail.com (Mario Frasca)
Date: Sat, 3 Mar 2012 09:56:04 +0100
Subject: [Rd] seeing feedback when R CMD check pkg runs unit tests.
In-Reply-To: <4F510044.80600@gmail.com>
References: <1330703385.2502.98.camel@nens-lt-92>
	<4F510044.80600@gmail.com>
Message-ID: <20120303095604.74bdbb05@zorapide>

On Fri, 02 Mar 2012 12:15:48 -0500
pgilbert902 at gmail.com (Paul Gilbert) wrote:

> Mario
> 
> [...] Examples only need to run, but in tests/ you can
> do things like
> 
> if( 2*2 != 4 ) stop("arithmatic is messed up.")
> 

problem is: when you do a stop, you stop, meaning you do not run
subsequent tests.  the nice part of unit testing is that you have a
complete report of all failing parts, not just the first one.

but what you write, I would translate it into:

one script -the current one- to execute all tests (and it has to
succeed, in the sense it has to perform all tests and say it managed to
produce a report).

one script -which I did not yet write- to examine the complete
test report of the former one and inform `R CMD check` (the user)
whether anything went wrong in the unit tests.

WARNING would be bad enough if there are failing tests.

do you know how I can emit a NOTE from a test script?
I sometimes use disabled tests as a reminder of things that still have
to be done, but if I associate them to a WARNING or ERROR, r-forge will
not allow me to release the module.

> You may be able to get similar results from RUnit or svUnit, it would 
> just be a question of passing the stop() and warnings() back to the
> top level in the script file in tests/. If you don't do that, as you 
> observed, R CMD check thinks the unit testing worked fine, it did its 
> job and found the errors.

exactly.  this made me thing of splitting the task in two parts.
thanks, I will try that and come back here next week. (and document it
on the svUnit and stack overflow sites)

> (Happy to hear additional points of view on this, my understanding of 
> RUnit and svUnit is limited.)

extensive unit testing lets me experiment broad internal changes.
the xml report of svUnit, combined with jenkins, automates the boring
part of the task. pity we still miss a coverage report.

Mario


From pgilbert902 at gmail.com  Sat Mar  3 18:24:53 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 03 Mar 2012 12:24:53 -0500
Subject: [Rd] seeing feedback when R CMD check pkg runs unit tests.
In-Reply-To: <20120303095604.74bdbb05@zorapide>
References: <1330703385.2502.98.camel@nens-lt-92> <4F510044.80600@gmail.com>
	<20120303095604.74bdbb05@zorapide>
Message-ID: <4F5253E5.8080907@gmail.com>



On 12-03-03 03:56 AM, Mario Frasca wrote:
> On Fri, 02 Mar 2012 12:15:48 -0500
> pgilbert902 at gmail.com (Paul Gilbert) wrote:
>
>> Mario
>>
>> [...] Examples only need to run, but in tests/ you can
>> do things like
>>
>> if( 2*2 != 4 ) stop("arithmatic is messed up.")
>>
>
> problem is: when you do a stop, you stop, meaning you do not run
> subsequent tests.  the nice part of unit testing is that you have a
> complete report of all failing parts, not just the first one.

When debugging myself I use make to run the tests, then make -k runs 
them all (and make -j -k  runs them in parallel). Generally, I don't 
expect to have many errors by the time I look at R-forge results. Of 
course, not running all the tests is a pain if you have multiple 
failures and you are trying to debug for other platforms using R-forge.
>
> but what you write, I would translate it into:
>
> one script -the current one- to execute all tests (and it has to
> succeed, in the sense it has to perform all tests and say it managed to
> produce a report).
>
> one script -which I did not yet write- to examine the complete
> test report of the former one and inform `R CMD check` (the user)
> whether anything went wrong in the unit tests.
>
> WARNING would be bad enough if there are failing tests.
>
> do you know how I can emit a NOTE from a test script?
> I sometimes use disabled tests as a reminder of things that still have
> to be done, but if I associate them to a WARNING or ERROR, r-forge will
> not allow me to release the module.

You can use message() or cat() to put it in the R output, but I don't 
know how you would pass this back to R CMD check. If you use a make 
target to do this then you can grep the output for these messages.

>> You may be able to get similar results from RUnit or svUnit, it would
>> just be a question of passing the stop() and warnings() back to the
>> top level in the script file in tests/. If you don't do that, as you
>> observed, R CMD check thinks the unit testing worked fine, it did its
>> job and found the errors.
>
> exactly.  this made me thing of splitting the task in two parts.
> thanks, I will try that and come back here next week. (and document it
> on the svUnit and stack overflow sites)
>
>> (Happy to hear additional points of view on this, my understanding of
>> RUnit and svUnit is limited.)
>
> extensive unit testing lets me experiment broad internal changes.
> the xml report of svUnit, combined with jenkins, automates the boring
> part of the task. pity we still miss a coverage report.

I get most of this from the tests/ and make based system I've been using 
for many years, but the hard part is developing a comprehensive set of 
tests. Do the unit testing frameworks help with that?

Paul
>
> Mario


From ripley at stats.ox.ac.uk  Sat Mar  3 18:29:21 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 03 Mar 2012 17:29:21 +0000
Subject: [Rd] .C clarification
In-Reply-To: <1330782163.27537.24.camel@nemo>
References: <1330782163.27537.24.camel@nemo>
Message-ID: <4F5254F1.7010400@stats.ox.ac.uk>

On 03/03/2012 13:42, Terry Therneau wrote:
> Does .C duplicate unnecessary arguments?  For instance
>    fit<- .C("xxx", as.integer(n), x, y, z=double(15))
>
> The first and fourth arguments would have NAMED = 0. Is my guess that .C
> won't make yet one more (unnecessary) copy correct?

.C's internals (do_dotcode) does not know about NAMED.  It duplicates 
(unless DUP=FALSE).

Use .Call if you want to control duplication.

> (Just trying to understand).
>
> Terry T
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From branch.lizard at gmail.com  Sun Mar  4 06:18:26 2012
From: branch.lizard at gmail.com (branch.lizard)
Date: Sat, 3 Mar 2012 21:18:26 -0800 (PST)
Subject: [Rd] R tcltk Gui and Rpy2
Message-ID: <1330838306717-4442989.post@n4.nabble.com>

I have a tcltk gui I created in R. I can open R and use the source command to
open the gui and then click buttons to perform functions. I would like to
make this a standalone program where the user does not have to open R and
type the source command to run the tcltk gui. I have a very nasty workaround
working for me which I use the R_PROFILE command to run the gui however I
would like to make the gui into a python executable program. I am very new
to python, but quite familiar with R. How does one go about doing this? I
have dabbled in Rpy2 a little and used the source command within python to
get the gui to load however it does not allow me to "click" the buttons b/c
it seems that the python script sessions closes at ""). Forgive me for my
terrible explanation of this. If you do not understand what I am asking,
please say so and I will try to provide some incite. 

--
View this message in context: http://r.789695.n4.nabble.com/R-tcltk-Gui-and-Rpy2-tp4442989p4442989.html
Sent from the R devel mailing list archive at Nabble.com.


From rvaradhan at jhmi.edu  Sun Mar  4 16:32:53 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Sun, 4 Mar 2012 15:32:53 +0000
Subject: [Rd] Conditional means and variances of a multivariate normal
 distribution
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3196A25@DOM-EB-MAIL2.win.ad.jhu.edu>

Hi,



Let X = (x_1, x_2, ... ,  x_p) be multivariate normal with mean, mu = (mu_1, ... , mu_p) and covariance = Sigma.  I was looking for an R function to compute conditional mean and conditional variance of a given subset of X given another subset of X.  While this is trivially easy to do, there is nothing in "base" for doing this, at least nothing that I am aware of.  I am also not aware of anything in the contributed packages (although my search was not comprehensive).  I feel that this would be a useful addition, if it is not already there.  I have written this following function, which I am sure can be improved a lot (including better argument names!). I would like to hear your thought on this.



condNormal <- function(x.given, mu, sigma, req.ind, given.ind){

# Returns conditional mean and variance of x[req.ind]

# Given x[given.ind] = x.given

# where X is multivariate Normal with

# mean = mu and covariance = sigma

#

B <- sigma[req.ind, req.ind]

C <- sigma[req.ind, given.ind]

D <- sigma[given.ind, given.ind]

cMu <- drop(mu[req.ind] + C %*% solve(D) %*% (x.given - mu[given.ind]))

cVar <- B - C %*% solve(D) %*% t(C)

list(condMean=cMu, condVar=cVar)

}



n <- 10

A <- matrix(rnorm(n^2), n, n)

A <- A %*% t(A)

condNormal(x=c(1,1,0,0,-1), mu=rep(1,n), sigma=A, req=c(2,3,5), given=c(1,4,7,9,10))



Best regards,

Ravi


From flodel at gmail.com  Sun Mar  4 19:00:03 2012
From: flodel at gmail.com (Florent D.)
Date: Sun, 4 Mar 2012 13:00:03 -0500
Subject: [Rd] hash table clean-up
Message-ID: <CAJPTfn=spLTDrZF5tajzneWGGjuKNUOLBVF7yPvoRTMw64-_cw@mail.gmail.com>

Hello,

I have noticed that the memory usage inside an R session increases as
more and more objects with unique names are created, even after they
are removed. Here is a small reproducible example:

> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 531720 14.2     899071 24.1   818163 21.9
Vcells 247949  1.9     786432  6.0   641735  4.9
>
> for (i in 1:100000) {
+ name <- paste("x", runif(1), sep="")
+ assign(name, NULL)
+ rm(list=name)
+ rm(name)
}
>
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 831714 22.3    1368491 36.6  1265230 33.8
Vcells 680551  5.2    1300721 10.0   969572  7.4

It appears the increase in memory usage is due to the way R's
environment hash table operates
(http://cran.r-project.org/doc/manuals/R-ints.html#Hash-table): as
objects with new names are created, new entries are made in the hash
table; but when the objects are removed from the environment, the
corresponding entries are not deleted.

I hope you will agree the growth in memory size is an undesirable
feature and can address the issue in a future release. If not, please
let me know why you think it should remain this way.

I believe a fix could be made around the time the hash table is
resized, where only non-removed items would be kept. I can try to make
those changes to src/main/envir.c myself, but C is not my area of
expertise. So if you beat me to it, please let me know.

Thank you,
Florent.


From luke-tierney at uiowa.edu  Sun Mar  4 22:19:56 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 4 Mar 2012 15:19:56 -0600
Subject: [Rd] hash table clean-up
In-Reply-To: <CAJPTfn=spLTDrZF5tajzneWGGjuKNUOLBVF7yPvoRTMw64-_cw@mail.gmail.com>
References: <CAJPTfn=spLTDrZF5tajzneWGGjuKNUOLBVF7yPvoRTMw64-_cw@mail.gmail.com>
Message-ID: <alpine.OSX.2.02.1203041506050.44564@lukes-macbook-air.local>

On Sun, 4 Mar 2012, Florent D. wrote:

> Hello,
>
> I have noticed that the memory usage inside an R session increases as
> more and more objects with unique names are created, even after they
> are removed. Here is a small reproducible example:
>
>> gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 531720 14.2     899071 24.1   818163 21.9
> Vcells 247949  1.9     786432  6.0   641735  4.9
>>
>> for (i in 1:100000) {
> + name <- paste("x", runif(1), sep="")
> + assign(name, NULL)
> + rm(list=name)
> + rm(name)
> }
>>
>> gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 831714 22.3    1368491 36.6  1265230 33.8
> Vcells 680551  5.2    1300721 10.0   969572  7.4
>
> It appears the increase in memory usage is due to the way R's
> environment hash table operates
> (http://cran.r-project.org/doc/manuals/R-ints.html#Hash-table): as
> objects with new names are created, new entries are made in the hash
> table; but when the objects are removed from the environment, the
> corresponding entries are not deleted.

Your analysis is incorrect. What you are seeing is the fact that thea
symbol or name objects used as keys are being added to the global
symbol table and that is not garbage collected. I believe that too
many internals rely on this for it to be changed any time soon.  It
may be possible to have some symbols GC protected and others not, but
again that would require very careful throught and implementation and
isn't likely to be a priority anty time soon as far as I can see.

There may be some value in having hash tables that use some form of
uninterned symbols as keys at some point but that is a larger project
that might be better provided by a contributed package, at least
initially.

Best,

luke

>
> I hope you will agree the growth in memory size is an undesirable
> feature and can address the issue in a future release. If not, please
> let me know why you think it should remain this way.
>
> I believe a fix could be made around the time the hash table is
> resized, where only non-removed items would be kept. I can try to make
> those changes to src/main/envir.c myself, but C is not my area of
> expertise. So if you beat me to it, please let me know.
>
> Thank you,
> Florent.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ggrothendieck at gmail.com  Sun Mar  4 22:40:19 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 4 Mar 2012 16:40:19 -0500
Subject: [Rd] hash table clean-up
In-Reply-To: <alpine.OSX.2.02.1203041506050.44564@lukes-macbook-air.local>
References: <CAJPTfn=spLTDrZF5tajzneWGGjuKNUOLBVF7yPvoRTMw64-_cw@mail.gmail.com>
	<alpine.OSX.2.02.1203041506050.44564@lukes-macbook-air.local>
Message-ID: <CAP01uRnO8zJuZaw4B=tZEuEzGoHmiZ4Q=Y8-2a8yyhXPFEzV2A@mail.gmail.com>

On Sun, Mar 4, 2012 at 4:19 PM,  <luke-tierney at uiowa.edu> wrote:
> On Sun, 4 Mar 2012, Florent D. wrote:
>
>> Hello,
>>
>> I have noticed that the memory usage inside an R session increases as
>> more and more objects with unique names are created, even after they
>> are removed. Here is a small reproducible example:
>>
>>> gc()
>>
>> ? ? ? ?used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 531720 14.2 ? ? 899071 24.1 ? 818163 21.9
>> Vcells 247949 ?1.9 ? ? 786432 ?6.0 641735 4.9
>>>
>>>
>>> for (i in 1:100000) {
>>
>> + name <- paste("x", runif(1), sep="")
>> + assign(name, NULL)
>> + rm(list=name)
>> + rm(name)
>> }
>>>
>>>
>>> gc()
>>
>> ? ? ? ?used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 831714 22.3 ? ?1368491 36.6 ?1265230 33.8
>> Vcells 680551 ?5.2 ? ?1300721 10.0 ? 969572 ?7.4
>>
>> It appears the increase in memory usage is due to the way R's
>> environment hash table operates
>> (http://cran.r-project.org/doc/manuals/R-ints.html#Hash-table): as
>> objects with new names are created, new entries are made in the hash
>> table; but when the objects are removed from the environment, the
>> corresponding entries are not deleted.
>
>
> Your analysis is incorrect. What you are seeing is the fact that thea
> symbol or name objects used as keys are being added to the global
> symbol table and that is not garbage collected. I believe that too
> many internals rely on this for it to be changed any time soon. ?It
> may be possible to have some symbols GC protected and others not, but
> again that would require very careful throught and implementation and
> isn't likely to be a priority anty time soon as far as I can see.
>
> There may be some value in having hash tables that use some form of
> uninterned symbols as keys at some point but that is a larger project
> that might be better provided by a contributed package, at least
> initially.
>

Does this apply to lists too or just environments?


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Sun Mar  4 23:29:19 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 4 Mar 2012 17:29:19 -0500
Subject: [Rd] hash table clean-up
In-Reply-To: <CAP01uRnO8zJuZaw4B=tZEuEzGoHmiZ4Q=Y8-2a8yyhXPFEzV2A@mail.gmail.com>
References: <CAJPTfn=spLTDrZF5tajzneWGGjuKNUOLBVF7yPvoRTMw64-_cw@mail.gmail.com>
	<alpine.OSX.2.02.1203041506050.44564@lukes-macbook-air.local>
	<CAP01uRnO8zJuZaw4B=tZEuEzGoHmiZ4Q=Y8-2a8yyhXPFEzV2A@mail.gmail.com>
Message-ID: <19E4EA4D-959C-4DDB-B61A-8C3506DF7C51@r-project.org>


On Mar 4, 2012, at 4:40 PM, Gabor Grothendieck wrote:

> On Sun, Mar 4, 2012 at 4:19 PM,  <luke-tierney at uiowa.edu> wrote:
>> On Sun, 4 Mar 2012, Florent D. wrote:
>> 
>>> Hello,
>>> 
>>> I have noticed that the memory usage inside an R session increases as
>>> more and more objects with unique names are created, even after they
>>> are removed. Here is a small reproducible example:
>>> 
>>>> gc()
>>> 
>>>        used (Mb) gc trigger (Mb) max used (Mb)
>>> Ncells 531720 14.2     899071 24.1   818163 21.9
>>> Vcells 247949  1.9     786432  6.0 641735 4.9
>>>> 
>>>> 
>>>> for (i in 1:100000) {
>>> 
>>> + name <- paste("x", runif(1), sep="")
>>> + assign(name, NULL)
>>> + rm(list=name)
>>> + rm(name)
>>> }
>>>> 
>>>> 
>>>> gc()
>>> 
>>>        used (Mb) gc trigger (Mb) max used (Mb)
>>> Ncells 831714 22.3    1368491 36.6  1265230 33.8
>>> Vcells 680551  5.2    1300721 10.0   969572  7.4
>>> 
>>> It appears the increase in memory usage is due to the way R's
>>> environment hash table operates
>>> (http://cran.r-project.org/doc/manuals/R-ints.html#Hash-table): as
>>> objects with new names are created, new entries are made in the hash
>>> table; but when the objects are removed from the environment, the
>>> corresponding entries are not deleted.
>> 
>> 
>> Your analysis is incorrect. What you are seeing is the fact that thea
>> symbol or name objects used as keys are being added to the global
>> symbol table and that is not garbage collected. I believe that too
>> many internals rely on this for it to be changed any time soon.  It
>> may be possible to have some symbols GC protected and others not, but
>> again that would require very careful throught and implementation and
>> isn't likely to be a priority anty time soon as far as I can see.
>> 
>> There may be some value in having hash tables that use some form of
>> uninterned symbols as keys at some point but that is a larger project
>> that might be better provided by a contributed package, at least
>> initially.
>> 
> 
> Does this apply to lists too or just environments?
> 

Just environments and pairlists (the latter don't use hashing, though). Lists (i.e. generic vectors) are not keyed by symbols (but are not hashed, either).

Cheers,
S


From yinnerspace at gmail.com  Mon Mar  5 00:04:08 2012
From: yinnerspace at gmail.com (yindalon)
Date: Sun, 4 Mar 2012 15:04:08 -0800 (PST)
Subject: [Rd] rpart package, text function, and round of class counts
Message-ID: <1330902248616-4444576.post@n4.nabble.com>

I run the following code:

library(rpart)
data(kyphosis)
fit <- rpart(Kyphosis ~ ., data=kyphosis)
plot(fit)
text(fit, use.n=TRUE)

The text labels represent the count of each class at the leaf node.
Unfortunately, the numbers are rounded and in scientific notation rather
than the exact number of examples sorted by that node in each class. 

The plot is supposed to look like
http://www.statmethods.net/advstats/images/ctree.png as per
http://www.statmethods.net/advstats/cart.html.

I'm running 2.14.1 on a mac.

Can anyone verify or point out if I am doing something obviously wrong for
displaying the counts rounded and in scientific notation rather than the
true counts in each class at each node?
Thanks.

--
View this message in context: http://r.789695.n4.nabble.com/rpart-package-text-function-and-round-of-class-counts-tp4444576p4444576.html
Sent from the R devel mailing list archive at Nabble.com.


From rvaradhan at jhmi.edu  Mon Mar  5 06:07:14 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Mon, 5 Mar 2012 05:07:14 +0000
Subject: [Rd] Conditional means and variances of a multivariate normal
 distribution
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3196A25@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3196A25@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3196B88@DOM-EB-MAIL2.win.ad.jhu.edu>

Hi,

My previous version of the conditional MVN function had a bug in that it would not work when conditional distribution was required for a single variable. I fixed this and also made a few minor changes. Here is the new version. 

condNormal <- function(x.given, mu, sigma, given.ind, req.ind){
# Returns conditional mean and variance of x[req.ind] 
# Given x[given.ind] = x.given
# where X is multivariate Normal with
# mean = mu and covariance = sigma
# 
B <- sigma[req.ind, req.ind]
C <- sigma[req.ind, given.ind, drop=FALSE]
D <- sigma[given.ind, given.ind]
CDinv <- C %*% solve(D)
cMu <- c(mu[req.ind] + CDinv %*% (x.given - mu[given.ind]))
cVar <- B - CDinv %*% t(C)
list(condMean=cMu, condVar=cVar)
}

n <- 10
A <- matrix(rnorm(n^2), n, n)
A <- A %*% t(A)
condNormal(x=c(1,1,0,0,-1), mu=rep(1,n), sigma=A, req=c(2,3,5), given=c(1,4,7,9,10))
condNormal(x=c(1,1,0,0,-1), mu=rep(1,n), sigma=A, req=2, given=c(1,4,7,9,10))

As far as I know, there is nothing related to multivariate normal distributions in "stats".  Hence, it seems like this function might be more useful in a contributed package such as "fMultivar" or "mvtnorm".

Best,
Ravi.
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Ravi Varadhan [rvaradhan at jhmi.edu]
Sent: Sunday, March 04, 2012 10:32 AM
To: r-devel at r-project.org
Subject: [Rd] Conditional means and variances of a multivariate normal distribution

Hi,



Let X = (x_1, x_2, ... ,  x_p) be multivariate normal with mean, mu = (mu_1, ... , mu_p) and covariance = Sigma.  I was looking for an R function to compute conditional mean and conditional variance of a given subset of X given another subset of X.  While this is trivially easy to do, there is nothing in "base" for doing this, at least nothing that I am aware of.  I am also not aware of anything in the contributed packages (although my search was not comprehensive).  I feel that this would be a useful addition, if it is not already there.  I have written this following function, which I am sure can be improved a lot (including better argument names!). I would like to hear your thought on this.



condNormal <- function(x.given, mu, sigma, req.ind, given.ind){

# Returns conditional mean and variance of x[req.ind]

# Given x[given.ind] = x.given

# where X is multivariate Normal with

# mean = mu and covariance = sigma

#

B <- sigma[req.ind, req.ind]

C <- sigma[req.ind, given.ind]

D <- sigma[given.ind, given.ind]

cMu <- drop(mu[req.ind] + C %*% solve(D) %*% (x.given - mu[given.ind]))

cVar <- B - C %*% solve(D) %*% t(C)

list(condMean=cMu, condVar=cVar)

}



n <- 10

A <- matrix(rnorm(n^2), n, n)

A <- A %*% t(A)

condNormal(x=c(1,1,0,0,-1), mu=rep(1,n), sigma=A, req=c(2,3,5), given=c(1,4,7,9,10))



Best regards,

Ravi

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From Achim.Zeileis at uibk.ac.at  Mon Mar  5 07:35:15 2012
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 5 Mar 2012 07:35:15 +0100 (CET)
Subject: [Rd] rpart package, text function, and round of class counts
In-Reply-To: <1330902248616-4444576.post@n4.nabble.com>
References: <1330902248616-4444576.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.02.1203050726150.1037@paninaro.uibk.ac.at>

On Sun, 4 Mar 2012, yindalon wrote:

> I run the following code:
>
> library(rpart)
> data(kyphosis)
> fit <- rpart(Kyphosis ~ ., data=kyphosis)
> plot(fit)
> text(fit, use.n=TRUE)
>
> The text labels represent the count of each class at the leaf node.
> Unfortunately, the numbers are rounded and in scientific notation rather
> than the exact number of examples sorted by that node in each class.

You probably have a getOption("digits") of 4 or lower. text.rpart uses 
getOption("digits") - 3 as the default which then means only 1 significant 
digit and hence it rounds and uses scientific notation. Using

text(fit, use.n = TRUE, digits = 3)

should do the trick. Maybe adding setting xpd = TRUE in addition helps in 
avoiding clipping of some labels.

Also, I would recommend to use

library("partykit")
plot(as.party(fit))

for visualization which uses a display like for the ctree() function (also 
mentioned on the web page you quote below).

> The plot is supposed to look like
> http://www.statmethods.net/advstats/images/ctree.png as per
> http://www.statmethods.net/advstats/cart.html.
>
> I'm running 2.14.1 on a mac.
>
> Can anyone verify or point out if I am doing something obviously wrong for
> displaying the counts rounded and in scientific notation rather than the
> true counts in each class at each node?
> Thanks.
>
> --
> View this message in context: http://r.789695.n4.nabble.com/rpart-package-text-function-and-round-of-class-counts-tp4444576p4444576.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jorismeys at gmail.com  Mon Mar  5 09:17:44 2012
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 5 Mar 2012 09:17:44 +0100
Subject: [Rd] plot.TukeyHSD prints funny main titles
Message-ID: <CAO1zAVao8O_bGdXruVUs-ckxUe45mUh0STtkhiVc5eeX9tVOcg@mail.gmail.com>

Hi,

if you use the plot.TukeyHSD() function with a main argument, that one
is printed over the default title 'X% family-wise confidence level'.
Try for example:

Model <- aov(count~spray,data=InsectSprays)
plot(TukeyHSD(Model),main='HHHHH',las=2)

This doesn't happen with an xlab or ylab argument, as they give errors
due to the fact they're specified inside the function already:

function (x, ...)
{
    for (i in seq_along(x)) {
        ...
        plot(c(xi[, "lwr"], xi[, "upr"]), rep.int(yvals, 2),
            type = "n", axes = FALSE, xlab = "", ylab = "", ...)
        ...
    }
}

The main title and the xlab are created with the title() function
lower in the code. So to avoid a main title being specified twice, I
propose to add main="" to the plot statement quoted above.

Cheers
Joris


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From wdunlap at tibco.com  Mon Mar  5 16:53:28 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 5 Mar 2012 15:53:28 +0000
Subject: [Rd] Julia
In-Reply-To: <20120303011413.GA18995@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
Message-ID: <E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>

I haven't used Julia yet, but from my quick reading
of the docs it looks like arguments to functions are
passed by reference and not by value, so functions
can change their arguments.  My recollection from when
I first started using S (in the course of a job helping
profs and grad students do statistical programming, c. 1983)
is that not having to worry about in-place algorithms changing
your data gave S a big advantage over Fortran or C.
While this feature could slow things down and increase
memory code, I felt that it made it easier to write correct
code and to use functions that others had written.
Does Julia have a const declaration or other
means of controlling or documenting that a given function
will or will not change the data passed into it?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of oliver
> Sent: Friday, March 02, 2012 5:14 PM
> To: Douglas Bates
> Cc: R-devel
> Subject: Re: [Rd] Julia
> 
> On Thu, Mar 01, 2012 at 11:06:51AM -0600, Douglas Bates wrote:
> > My purpose in mentioning the Julia language (julialang.org) here is
> > not to start a flame war.  I find it to be a very interesting
> > development and others who read this list may want to read about it
> > too.
> [...]
> 
> 
> Very interesting language.
> Thank you for mentioning it here.
> 
> Compiling from the github-sources was easy.
> 
> Will explore it during the next days.
> 
> Seems not to be very specific to statistics,
> but good for math in general.
> 
> Not sure, if it might make sense to combine
> R and Julia in the long run (I mean: combining via
> providing interfaces between them, calling the one via the
> other, merging code or using libs from the one or the other
> from each side).
> 
> Ciao,
>    Oliver
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From oliver at first.in-berlin.de  Mon Mar  5 18:08:35 2012
From: oliver at first.in-berlin.de (oliver)
Date: Mon, 5 Mar 2012 18:08:35 +0100
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
Message-ID: <20120305170835.GA4134@siouxsie>

On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
> I haven't used Julia yet, but from my quick reading
> of the docs it looks like arguments to functions are
> passed by reference and not by value, so functions
> can change their arguments.  My recollection from when
> I first started using S (in the course of a job helping
> profs and grad students do statistical programming, c. 1983)
> is that not having to worry about in-place algorithms changing
> your data gave S a big advantage over Fortran or C.
[...]


C also uses Call-by-Value.
Fortran I don't know in detail.


> While this feature could slow things down and increase
> memory code, I felt that it made it easier to write correct
> code and to use functions that others had written.

Yes, I also think, that call-by-value decreases
errors in Code.

What I read about Julia it's like MATLAB plus more features for programming.
Does matlab also only use call-by-reference?


> Does Julia have a const declaration or other
> means of controlling or documenting that a given function
> will or will not change the data passed into it?

I did not explored it in detail so far.
Maybe the orig-poster already did this in more depth?


Ciao,
   Oliver


From hpages at fhcrc.org  Tue Mar  6 00:58:59 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 05 Mar 2012 15:58:59 -0800
Subject: [Rd] Julia
In-Reply-To: <20120305170835.GA4134@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie>
Message-ID: <4F555343.8020007@fhcrc.org>

Hi Oliver,

On 03/05/2012 09:08 AM, oliver wrote:
> On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
>> I haven't used Julia yet, but from my quick reading
>> of the docs it looks like arguments to functions are
>> passed by reference and not by value, so functions
>> can change their arguments.  My recollection from when
>> I first started using S (in the course of a job helping
>> profs and grad students do statistical programming, c. 1983)
>> is that not having to worry about in-place algorithms changing
>> your data gave S a big advantage over Fortran or C.
> [...]
>
>
> C also uses Call-by-Value.

C *only* uses Call-by-Value.

Cheers,
H.

> Fortran I don't know in detail.
>
>
>> While this feature could slow things down and increase
>> memory code, I felt that it made it easier to write correct
>> code and to use functions that others had written.
>
> Yes, I also think, that call-by-value decreases
> errors in Code.
>
> What I read about Julia it's like MATLAB plus more features for programming.
> Does matlab also only use call-by-reference?
>
>
>> Does Julia have a const declaration or other
>> means of controlling or documenting that a given function
>> will or will not change the data passed into it?
>
> I did not explored it in detail so far.
> Maybe the orig-poster already did this in more depth?
>
>
> Ciao,
>     Oliver
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From djsamperi at gmail.com  Tue Mar  6 01:21:01 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 5 Mar 2012 19:21:01 -0500
Subject: [Rd] Calling FORTRAN function from R issue?
Message-ID: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>

Hello,

I am trying to call the BLAS Level1 function zdotc from R via
a .C call like this:

#include "R.h"
#include "R_ext/BLAS.h"

void testzdotc() {
    Rcomplex zx[3], zy[3], ret_val;

    zx[0].r = 1.0; zx[0].i = 0.0;
    zx[1].r = 2.0; zx[0].i = 0.0;
    zx[2].r = 3.0; zx[0].i = 0.0;

    zy[0].r = 1.0; zy[0].i = 0.0;
    zy[1].r = 2.0; zy[0].i = 0.0;
    zy[2].r = 3.0; zy[0].i = 0.0;

    int n=3, incx=1, incy=1;
    F77_CALL(zdotc)(&ret_val, &n, zx, &incx, zy, &incy);
    Rprintf("ret_val = %f, %f\n", ret_val.r, ret_val.i);
}

This does not work. When I run '.C('testzdotc')' there is
typically a delay for a second or so, then I get: 0.0, 0.0
instead of the correct ans: 14.0, 0.0.

Section 5.2 of the R manual (on Extending R) says that only
FORTRAN subroutines can be called (not functions), probably
because of the non-standard way the compilers map FORTRAN
function names to symbols in the DLL.

This is consistent with the interface prototype for the BLAS
routine zdotc contained in <R>/include/R_ext/BLAS.h, namely,

BLAS_extern Rcomplex
    F77_NAME(zdotc)(Rcomplex * ret_val, int *n,
		    Rcomplex *zx, int *incx, Rcomplex *zy, int *incy);

But this seems to BOTH return a result, and pass the result
as the first argument?

On the other hand, this is not consistent with the standard
FORTRAN definition for zdotc that is contained in
<R>/src/extra/blas/cmplxblas.f, where the first argument is
n, not ret_val. Consequently, it is not clear where the wrapper
is defined that is called via the prototype.

My search is complicated by the fact that the libraries
libR.so, libRblas.so, libRlapack.so are stripped.

When I install the standard (FORTRAN-based) BLAS on my
system (Fedora 16), I find that zdotc is defined in the traditional
way (without adjustment to the first argument). This is probably
irrelevant because R does not use it in my configuration.

I found some documentation on Intel FORTRAN that seems to
suggest that the first argument on the C side is always the
same as (a pointer to) the FORTRAN function return value, but
this is not so if I use the standard definition of zdotc.f with
gfortran.

Any ideas?

Thanks,
Dominick


From oliver at first.in-berlin.de  Tue Mar  6 01:19:28 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 6 Mar 2012 01:19:28 +0100
Subject: [Rd] Julia
In-Reply-To: <4F555343.8020007@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
Message-ID: <20120306001928.GF5702@siouxsie>

On Mon, Mar 05, 2012 at 03:58:59PM -0800, Herv? Pag?s wrote:
> Hi Oliver,
> 
> On 03/05/2012 09:08 AM, oliver wrote:
> >On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
> >>I haven't used Julia yet, but from my quick reading
> >>of the docs it looks like arguments to functions are
> >>passed by reference and not by value, so functions
> >>can change their arguments.  My recollection from when
> >>I first started using S (in the course of a job helping
> >>profs and grad students do statistical programming, c. 1983)
> >>is that not having to worry about in-place algorithms changing
> >>your data gave S a big advantage over Fortran or C.
> >[...]
> >
> >
> >C also uses Call-by-Value.
> 
> C *only* uses Call-by-Value.
[...]


Yes, that's what I meant.

With "also" I meant, that it uses call-by-value, as some
other languages also do.


Ciao,
   Oliver


From murdoch.duncan at gmail.com  Tue Mar  6 01:33:10 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 05 Mar 2012 19:33:10 -0500
Subject: [Rd] Julia
In-Reply-To: <4F555343.8020007@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
Message-ID: <4F555B46.3080007@gmail.com>

On 12-03-05 6:58 PM, Herv? Pag?s wrote:
> Hi Oliver,
>
> On 03/05/2012 09:08 AM, oliver wrote:
>> On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
>>> I haven't used Julia yet, but from my quick reading
>>> of the docs it looks like arguments to functions are
>>> passed by reference and not by value, so functions
>>> can change their arguments.  My recollection from when
>>> I first started using S (in the course of a job helping
>>> profs and grad students do statistical programming, c. 1983)
>>> is that not having to worry about in-place algorithms changing
>>> your data gave S a big advantage over Fortran or C.
>> [...]
>>
>>
>> C also uses Call-by-Value.
>
> C *only* uses Call-by-Value.

While literally true, the fact that you can't send an array by value, 
and must send the value of a pointer to it, kind of supports Bill's 
point:  in C, you mostly end up sending arrays by reference.

Duncan Murdoch


From wdunlap at tibco.com  Tue Mar  6 01:35:32 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Mar 2012 00:35:32 +0000
Subject: [Rd] Julia
In-Reply-To: <4F555343.8020007@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
Message-ID: <E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>

Yes, C does use call by value, always.  However, data arrays
are almost always passed via pointers to malloc'ed space,
so, effectively, data arrays are passed by reference.
(One can put a 'const type*' in the prototype of a function to declare
that the data pointed to will not not be changed, but it is
up to documentation or coding standards to let someone know that
data pointed to will likely be changed.)

I find R's (& S+'s & S's) copy-on-write-if-not-copying-would-be-discoverable-
by-the-uer machanism for giving the allusion of pass-by-value a good way
to structure the contract between the function writer and the function user.
Does Julia have the tools to let a function writer or user decide whether
he really needs to copy its arguments or not?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Herv? Pag?s
> Sent: Monday, March 05, 2012 3:59 PM
> To: oliver
> Cc: R-devel
> Subject: Re: [Rd] Julia
> 
> Hi Oliver,
> 
> On 03/05/2012 09:08 AM, oliver wrote:
> > On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
> >> I haven't used Julia yet, but from my quick reading
> >> of the docs it looks like arguments to functions are
> >> passed by reference and not by value, so functions
> >> can change their arguments.  My recollection from when
> >> I first started using S (in the course of a job helping
> >> profs and grad students do statistical programming, c. 1983)
> >> is that not having to worry about in-place algorithms changing
> >> your data gave S a big advantage over Fortran or C.
> > [...]
> >
> >
> > C also uses Call-by-Value.
> 
> C *only* uses Call-by-Value.
> 
> Cheers,
> H.
> 
> > Fortran I don't know in detail.
> >
> >
> >> While this feature could slow things down and increase
> >> memory code, I felt that it made it easier to write correct
> >> code and to use functions that others had written.
> >
> > Yes, I also think, that call-by-value decreases
> > errors in Code.
> >
> > What I read about Julia it's like MATLAB plus more features for programming.
> > Does matlab also only use call-by-reference?
> >
> >
> >> Does Julia have a const declaration or other
> >> means of controlling or documenting that a given function
> >> will or will not change the data passed into it?
> >
> > I did not explored it in detail so far.
> > Maybe the orig-poster already did this in more depth?
> >
> >
> > Ciao,
> >     Oliver
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> --
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Tue Mar  6 03:33:16 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 5 Mar 2012 18:33:16 -0800
Subject: [Rd] R 2.15.0 alpha: R CMD check --as-cran /
 tools:::..check_package_CRAN_incoming() crash
Message-ID: <CAFDcVCSdVwgkB4hiiG8gQyfGgZxz73J1k6F9bjVeKuKcmc93MQ@mail.gmail.com>

For what it's worth, with

  R --no-init-file CMD check --as-cran ${pkg}_${version}.tar.gz

on R version 2.15.0 alpha (2012-03-03 r58572) on Windows I just
managed to generate a crash:

Checking package affxparser...
* using log directory 'X:/affxparser,BioC-devel/R2.15.0/affxparser.Rcheck'
* using R version 2.15.0 alpha (2012-03-03 r58572)
* using platform: x86_64-pc-mingw32 (64-bit)
* using session charset: ISO8859-1
* checking for file 'affxparser/DESCRIPTION' ... OK
* this is package 'affxparser' version '1.27.4'
* checking CRAN incoming feasibility ...Warning in
url(sprintf("%s/src/contrib/Meta/archive.rds", CRAN), "rb") :
  unable to connect to 'CRAN.R-project.org' on port 80.
Error in url(sprintf("%s/src/contrib/Meta/archive.rds", CRAN), "rb") :
  cannot open the connection
Execution halted

I can *not* reproduce it.  Also, if I disable internet access, it
continues with a warning:

* this is package 'affxparser' version '1.27.4'
* checking CRAN incoming feasibility ...Warning in
url(sprintf("%s/src/contrib/PACKAGES.gz", u), "rb") :
  unable to resolve 'CRAN.R-project.org'
NB: need Internet access to use CRAN incoming checks
 OK
* checking package namespace information ... OK
...

Looking at tools:::..check_package_CRAN_incoming() [in
src/library/tools/R/QC.R], there are few places where different online
URLs:

URL 1: %s/src/contrib/PACKAGES.gz,
URL 2: %s/src/contrib/Meta/archive.rds,
URL 3: %s/src/contrib/Meta/current.rds,
URL 4: %s/web/packages/packages.rds

are downloaded, but it is only the first one that is downloaded with
exception handling.  Thus, if URL 2, 3 or 4 is broken/being updated,
or internet access goes down, the above crash would occur.

Also, in tools:::.check_Rd_xrefs() another URL is downloaded assuming
working internet access.

Just feedback. I can live the above, but it could be that others
report on this in the future.

/Henrik


From Berwin.Turlach at gmail.com  Tue Mar  6 07:28:05 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Tue, 6 Mar 2012 14:28:05 +0800
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
Message-ID: <20120306142805.581283ab@bossiaea>

G'day Dominick,

On Mon, 5 Mar 2012 19:21:01 -0500
Dominick Samperi <djsamperi at gmail.com> wrote:

> Section 5.2 of the R manual (on Extending R) says that only
> FORTRAN subroutines can be called (not functions), probably
> because of the non-standard way the compilers map FORTRAN
> function names to symbols in the DLL.

Section 5.2 deals with calling C/FORTRAN code from R via .C()
or .Fortran(), and is not directly relevant to the question on how to
call FORTRAN code from C code. :)
 
> This is consistent with the interface prototype for the BLAS
> routine zdotc contained in <R>/include/R_ext/BLAS.h, namely,
> 
> BLAS_extern Rcomplex
>     F77_NAME(zdotc)(Rcomplex * ret_val, int *n,
> 		    Rcomplex *zx, int *incx, Rcomplex *zy, int *incy);
> 
>[...]
>
> On the other hand, this is not consistent with the standard
> FORTRAN definition for zdotc that is contained in
> <R>/src/extra/blas/cmplxblas.f, where the first argument is
> n, not ret_val. 

This seems to be indeed inconsistent and, presumably, a bug.  Applying
the attach patch to R's development version (compiles, installs and
passes all checks with this patch), and changing in your code the line

	F77_CALL(zdotc)(&ret_val, &n, zx, &incx, zy, &incy);

to

	ret_val = F77_CALL(zdotc)(&n, zx, &incx, zy, &incy);

produces the expected output.

> Consequently, it is not clear where the wrapper
> is defined that is called via the prototype.

The F77_xxxx macros seem to be defined in <R>/include/R_ext/RS.h, and
their sole purpose seems to be to append a _ to the argument if
needed.  

Cheers,

	Berwin
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-Patch
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120306/848a76d6/attachment.pl>

From oliver at first.in-berlin.de  Tue Mar  6 09:56:58 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 6 Mar 2012 09:56:58 +0100
Subject: [Rd] Julia
In-Reply-To: <CAAk+MXxjF-z-Kf4a4MkhsVeoZHEnzVWvh7r0QVYnAQ+pk59XOw@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<20120306001928.GF5702@siouxsie>
	<CAAk+MXxjF-z-Kf4a4MkhsVeoZHEnzVWvh7r0QVYnAQ+pk59XOw@mail.gmail.com>
Message-ID: <20120306085658.GA1849@siouxsie>

On Mon, Mar 05, 2012 at 04:54:05PM -0800, Nicholas Crookston wrote:
> There are many experts on this topic.  I'll keep this short.
> 
> Newer Fortran Languages allow for call by value, but call by reference
> is the typical and historically, the only approach (there was a time
> when you could change the value of 1 to 2!).

Oh, strange.


> 
> C "only" calls by value except that the value can be a pointer! So,
> havoc is just a * away.
[...]

For me there was no "havoc" at this point, but for others maybe.

There are also other languages that only use call-by-value...
...functional languages are that way in principal.

  Nevertheless internally they may heavily use pointers and
  even if you have values that are large arrays for example,
  they internally just give a pointer to that data structure.
  (That's, why functional languages are not necessarily slow
  just because you act on large data and have no references
  in that language. (A common misunderstanding about functional
  languages must be slow because they have nor references.)
  The pointer-stuff is just hidden.

Even they ((non-purely) functional languages) may have references,
their concept of references is different. (See OCaml for example.)
There you can use references to change values in place, but the
reference itself is a functional value, and you will never have
access to the pointer stuff directly. Hence no problems with
mem-arithmetics and dangling pointer's or Null-pointers.



[...]
> I like R and will continue to use it. However, I also think that
> strict "call by value" can get you into trouble, just trouble of a
> different kind.

Can you elaborate more on this?
What problems do you have in mind?
And what kind of references do you have in mind?
The C-like pointers or something like OCaml's ref's?


> I'm not sure we will ever yearn for "Julia ouR-Julia",
> but it is sure fun to think about what might be possible with this
> language. And having fun is one key objective.

I have fun if things work.
And if the tools do, what I want to achieve...
...and the fun is better, if they do it elegantly.

Do you ask for references in R?
And what kind of references do you have in mind,
and why does it hurt you not to have them?

Can you give examples, so that it's easier to see,
whwere you miss something?


Ciao,
   Oliver

P.S.: The speed issue of R was coming up more than once;
      in some blog posts it was mentioned. would it make
      sense to start a seperated thread of it?
      In one  of the blog-articles I read, it was mourned about
      how NA / missing values were handled, and that NA should
      maybe become thrown out, just to get higher speed.
      I would not like to have that. Handling NA as special
      case IMHO is a very good way. Don't remember if the
      article I have in mind just argued about HOW this was
      handled, or if it should be thrown out completely.
      Making the handling of it better and more performant I
      think is a good idea, ignoring NA IMHO is a bad idea.

      But maybe that really would be worth a seperate thread?


From oliver at first.in-berlin.de  Tue Mar  6 10:06:21 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 6 Mar 2012 10:06:21 +0100
Subject: [Rd] Julia
In-Reply-To: <4F555B46.3080007@gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<4F555B46.3080007@gmail.com>
Message-ID: <20120306090621.GB1849@siouxsie>

On Mon, Mar 05, 2012 at 07:33:10PM -0500, Duncan Murdoch wrote:
> On 12-03-05 6:58 PM, Herv? Pag?s wrote:
> >Hi Oliver,
> >
> >On 03/05/2012 09:08 AM, oliver wrote:
> >>On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
> >>>I haven't used Julia yet, but from my quick reading
> >>>of the docs it looks like arguments to functions are
> >>>passed by reference and not by value, so functions
> >>>can change their arguments.  My recollection from when
> >>>I first started using S (in the course of a job helping
> >>>profs and grad students do statistical programming, c. 1983)
> >>>is that not having to worry about in-place algorithms changing
> >>>your data gave S a big advantage over Fortran or C.
> >>[...]
> >>
> >>
> >>C also uses Call-by-Value.
> >
> >C *only* uses Call-by-Value.
> 
> While literally true, the fact that you can't send an array by
> value, and must send the value of a pointer to it, kind of supports
> Bill's point:  in C, you mostly end up sending arrays by reference.
[...]

It's a problem of how the term "reference" is used.
If you want to limit the possible confsion, better say:
giving the pointer-by-value.

Or: giving the address-value of the array/struct/...
by value.

To say, you give the array reference is a shorthand,
which maybe creates confusion.

Just avoiding the word "reference" here would make it more clear.
AFAIK in C++ references are different to pointers. (Some others
who know C++ in detail might explain this in detail.)

So, using the same terms for many different concepts can create
a mess in understanding.


Ciao,
   Oliver


From oliver at first.in-berlin.de  Tue Mar  6 10:11:43 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 6 Mar 2012 10:11:43 +0100
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
Message-ID: <20120306091143.GC1849@siouxsie>

On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
[...]
> I find R's (& S+'s & S's) copy-on-write-if-not-copying-would-be-discoverable-
> by-the-uer machanism for giving the allusion of pass-by-value a good way
> to structure the contract between the function writer and the function user.
[...]


Can you elaborate more on this,
especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
stuff?

What do you mean with discoverability of not-copying?

Ciao,
   Oliver


From bhh at xs4all.nl  Tue Mar  6 11:19:07 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Mar 2012 11:19:07 +0100
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
Message-ID: <B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>


On 06-03-2012, at 01:21, Dominick Samperi wrote:

> Hello,
> 
> I am trying to call the BLAS Level1 function zdotc from R via
> a .C call like this:
> 
> #include "R.h"
> #include "R_ext/BLAS.h"
> 
> void testzdotc() {
>    Rcomplex zx[3], zy[3], ret_val;
> 
>    zx[0].r = 1.0; zx[0].i = 0.0;
>    zx[1].r = 2.0; zx[0].i = 0.0;
>    zx[2].r = 3.0; zx[0].i = 0.0;
> 
>    zy[0].r = 1.0; zy[0].i = 0.0;
>    zy[1].r = 2.0; zy[0].i = 0.0;
>    zy[2].r = 3.0; zy[0].i = 0.0;
> 
>    int n=3, incx=1, incy=1;
>    F77_CALL(zdotc)(&ret_val, &n, zx, &incx, zy, &incy);
>    Rprintf("ret_val = %f, %f\n", ret_val.r, ret_val.i);
> }
> 
> This does not work. When I run '.C('testzdotc')' there is
> typically a delay for a second or so, then I get: 0.0, 0.0
> instead of the correct ans: 14.0, 0.0.

I tried calling zdotc  through an intermediate Fortran routine hoping it would solve your problem.

Above C routine changed to

<code>
#include "R.h"

void F77_NAME(callzdotc)(Rcomplex *, int *, Rcomplex *, int *, Rcomplex *, int *);

void testzdotc() {
   Rcomplex zx[3], zy[3], ret_val;

   zx[0].r = 1.0; zx[0].i = 0.0;
   zx[1].r = 2.0; zx[0].i = 0.0;
   zx[2].r = 3.0; zx[0].i = 0.0;

   zy[0].r = 1.0; zy[0].i = 0.0;
   zy[1].r = 2.0; zy[0].i = 0.0;
   zy[2].r = 3.0; zy[0].i = 0.0;

   int n=3, incx=1, incy=1;
   F77_CALL(callzdotc)(&ret_val, &n, zx, &incx, zy, &incy);
   Rprintf("ret_val = %f, %f\n", ret_val.r, ret_val.i);
}
</code>

The fortran subroutine is

<code>
      subroutine callzdotc(retval,n, zx, incx, zy, incy)
      integer n, incx, incy
      double complex retval, zx(*), zy(*)
      external double complex zdotc

      retval = zdotc(n, zx, incx, zy, incy)

      return
      end
</code>

Made a shared object with

R CMD SHLIB --output=dozdot.so callzdotc.f czdot.c 

and ran

dyn.load("dozdot.so")
.C("testzdotc")

with the result 0.0, 0.0

I would've expected this to give the correct result.

Berend

Mac OS X 10.6.8
R2.14.2
Using reference Rblas.


From Berwin.Turlach at gmail.com  Tue Mar  6 12:56:08 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Tue, 6 Mar 2012 19:56:08 +0800
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
Message-ID: <20120306195608.7ec858c0@bossiaea>

G'day Berend,

On Tue, 6 Mar 2012 11:19:07 +0100
Berend Hasselman <bhh at xs4all.nl> wrote:

> On 06-03-2012, at 01:21, Dominick Samperi wrote:
[...]
> >    zx[0].r = 1.0; zx[0].i = 0.0;
> >    zx[1].r = 2.0; zx[0].i = 0.0;
> >    zx[2].r = 3.0; zx[0].i = 0.0;

Just noticing that it is always zx[0].i, same with the imaginary part
of zy.  But this is probably not of importance. :)

> I tried calling zdotc  through an intermediate Fortran routine hoping
> it would solve your problem.
[...] 
> Above C routine changed to
[...]
> The fortran subroutine is
> 
> <code>
>       subroutine callzdotc(retval,n, zx, incx, zy, incy)
>       integer n, incx, incy
>       double complex retval, zx(*), zy(*)
>       external double complex zdotc
> 
>       retval = zdotc(n, zx, incx, zy, incy)
> 
>       return
>       end
> </code>
> 
> Made a shared object with
> 
> R CMD SHLIB --output=dozdot.so callzdotc.f czdot.c 
> 
> and ran
> 
> dyn.load("dozdot.so")
> .C("testzdotc")
> 
> with the result 0.0, 0.0

Same here.

Once I change the line

	external double complex zdotc

in your fortran subroutine to

	double complex zdotc

everything works fine and I get as result 14.0, 0.0.

It is long time ago that I was taught (and studied) the FORTRAN 77
standard.  But flipping through some books from that time I thing I
have some inkling on what is going on.  The "external" statement is not
needed here (seems to be used in the sense that C is using the
"external" statement).

Cheers,

	Berwin


From bhh at xs4all.nl  Tue Mar  6 13:06:34 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Mar 2012 13:06:34 +0100
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <20120306195608.7ec858c0@bossiaea>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
Message-ID: <879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>


On 06-03-2012, at 12:56, Berwin A Turlach wrote:

> G'day Berend,
> 
> [..]
>> I tried calling zdotc  through an intermediate Fortran routine hoping
>> it would solve your problem.
> [...] 
>> Above C routine changed to
> [...]
>> The fortran subroutine is
>> 
>> <code>
>>      subroutine callzdotc(retval,n, zx, incx, zy, incy)
>>      integer n, incx, incy
>>      double complex retval, zx(*), zy(*)
>>      external double complex zdotc
>> 
>>      retval = zdotc(n, zx, incx, zy, incy)
>> 
>>      return
>>      end
>> </code>
>> 
>> Made a shared object with
>> 
>> R CMD SHLIB --output=dozdot.so callzdotc.f czdot.c 
>> 
>> and ran
>> 
>> dyn.load("dozdot.so")
>> .C("testzdotc")
>> 
>> with the result 0.0, 0.0
> 
> Same here.
> 
> Once I change the line
> 
> 	external double complex zdotc
> 
> in your fortran subroutine to
> 
> 	double complex zdotc
> 
> everything works fine and I get as result 14.0, 0.0.
> 
> It is long time ago that I was taught (and studied) the FORTRAN 77
> standard.  But flipping through some books from that time I thing I
> have some inkling on what is going on.  The "external" statement is not
> needed here (seems to be used in the sense that C is using the
> "external" statement).


Thanks.
I should have tried that too.

This implies that Dominick's original issue can be avoided by using an intermediate Fortran routine.

But I would really like to hear from an Rexpert why you shouldn't/can't use external here in the Fortran.

Berend


From Berwin.Turlach at gmail.com  Tue Mar  6 14:37:03 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Tue, 6 Mar 2012 21:37:03 +0800
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
Message-ID: <20120306213703.6a5a091f@absentia>

G'day Berend,

On Tue, 6 Mar 2012 13:06:34 +0100
Berend Hasselman <bhh at xs4all.nl> wrote:

[... big snip ...]

> But I would really like to hear from an Rexpert why you
> shouldn't/can't use external here in the Fortran.

Probably less a question for an Rexpert but for a Fortran expert....

If you insert "implicit none" (one of my favourite extensions that I
always use) as the first statement after 
	subroutine callzdotc(retval,n, zx, incx, zy, incy)
you will see what is going on.  The compiler should refuse compilation
and complain that the type of zdotc was not declared (at least my
compiler does).  For FORTRAN to know that zdotc returns a double
complex you need the 
	double complex zdotc
declaration in callzdotc.

An
	external double complex zdotc
would be necessary if you were to call another subroutine/function, say
foo, that accepts functions as formal arguments and you want to pass
zdotc via such an argument.  Something like

	subroutine callzdotc(....)
        ....
        external double complex zdotc
	....
        call foo(a, b, zdotc)
        ....
	return
	end

	subroutine(a, b, h)
	double complex h, t
	....
	t = h(..,..,..,..)
	....
	return
	end

In C, the qualifier (or whatever the technical term is) "external" is
used to indicate that the function/variable/symbol is defined in
another compilation unit.  In FORTRAN77, "external" is used to tell the
compiler that you are passing a function to another
function/subroutine.  At least that is my understanding from what I
re-read in my FORTRAN documentation.
 
Thus, perhaps strangely, if there is only a 
	external double complex zdotc
declaration in your subroutine, the compiler doesn't know that a call
to zdotc will return a double complex but will assume that the result
has the implicitly defined type, a real*8 IIRC.  So zdotc is called, and
puts a double complex as result on the stack (heap?), but within
callzdotc a real as return is expected and that is taken from the
stack (heap?), that real is than coerced to a double complex when
assigned to retval.  Note that while I am pretty sure about the above,
this last paragraph is more speculative. :)  But it would explain why
the erroneous code returns 0 on little-endian machines.

HTH.

Cheers,
	
	Berwin




Cheers,

	Berwin


From bhh at xs4all.nl  Tue Mar  6 15:07:39 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Mar 2012 15:07:39 +0100
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <20120306213703.6a5a091f@absentia>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
	<20120306213703.6a5a091f@absentia>
Message-ID: <7415EC02-58F3-47D3-9D4D-1A3B52EEA97F@xs4all.nl>


On 06-03-2012, at 14:37, Berwin A Turlach wrote:

> G'day Berend,
> 
> On Tue, 6 Mar 2012 13:06:34 +0100
> Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> [... big snip ...]
> 
>> But I would really like to hear from an Rexpert why you
>> shouldn't/can't use external here in the Fortran.
> 
> Probably less a question for an Rexpert but for a Fortran expert....
> 
> If you insert "implicit none" (one of my favourite extensions that I
> always use) as the first statement after 
> 	subroutine callzdotc(retval,n, zx, incx, zy, incy)
> you will see what is going on.  The compiler should refuse compilation
> and complain that the type of zdotc was not declared (at least my
> compiler does).  For FORTRAN to know that zdotc returns a double
> complex you need the 
> 	double complex zdotc
> declaration in callzdotc.
> 

I usually use -fimplicit-none or a similar option as argument for a fortran compiler.
I didn't use it in a syntax checking pre compiling run.

> An
> 	external double complex zdotc
> would be necessary if you were to call another subroutine/function, say
> foo, that accepts functions as formal arguments and you want to pass
> zdotc via such an argument.  Something like
> 
> 	subroutine callzdotc(....)
>        ....
>        external double complex zdotc
> 	....
>        call foo(a, b, zdotc)
>        ....
> 	return
> 	end
> 
> 	subroutine(a, b, h)
> 	double complex h, t
> 	....
> 	t = h(..,..,..,..)
> 	....
> 	return
> 	end
> 
> In C, the qualifier (or whatever the technical term is) "external" is
> used to indicate that the function/variable/symbol is defined in
> another compilation unit.  In FORTRAN77, "external" is used to tell the
> compiler that you are passing a function to another
> function/subroutine.  At least that is my understanding from what I
> re-read in my FORTRAN documentation.

Not quite true.
It is required to use external if you are passing the name of a function/subroutine to another routine.
Otherwise it is just a statement telling the compile that the <external-name> is external to the function/subroutine/.. being compiled.

See http://www.fortran.com/F77_std/rjcnf0001-sh-8.html#sh-8.7


> 
> Thus, perhaps strangely, if there is only a 
> 	external double complex zdotc
> declaration in your subroutine, the compiler doesn't know that a call
> ....

If I am reading the above reference correctly, the syntax 

	external double complex zdotc

is simply incorrect (correct syntax uses commas to separate names e.g. A,B,C).
The compiler (gfortran) simply seems to ignore the "double" and the "complex" if you don't use implicit none.

Berend


From ripley at stats.ox.ac.uk  Tue Mar  6 15:17:29 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 06 Mar 2012 14:17:29 +0000
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <20120306213703.6a5a091f@absentia>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
	<20120306213703.6a5a091f@absentia>
Message-ID: <4F561C79.2090002@stats.ox.ac.uk>

On 06/03/2012 13:37, Berwin A Turlach wrote:
> G'day Berend,
>
> On Tue, 6 Mar 2012 13:06:34 +0100
> Berend Hasselman<bhh at xs4all.nl>  wrote:
>
> [... big snip ...]
>
>> But I would really like to hear from an Rexpert why you
>> shouldn't/can't use external here in the Fortran.
>
> Probably less a question for an Rexpert but for a Fortran expert....

Exactly ....

> If you insert "implicit none" (one of my favourite extensions that I
> always use) as the first statement after
> 	subroutine callzdotc(retval,n, zx, incx, zy, incy)
> you will see what is going on.  The compiler should refuse compilation
> and complain that the type of zdotc was not declared (at least my
> compiler does).  For FORTRAN to know that zdotc returns a double
> complex you need the
> 	double complex zdotc
> declaration in callzdotc.
>
> An
> 	external double complex zdotc
> would be necessary if you were to call another subroutine/function, say
> foo, that accepts functions as formal arguments and you want to pass
> zdotc via such an argument.  Something like
>
> 	subroutine callzdotc(....)
>          ....
>          external double complex zdotc
> 	....
>          call foo(a, b, zdotc)
>          ....
> 	return
> 	end
>
> 	subroutine(a, b, h)
> 	double complex h, t
> 	....
> 	t = h(..,..,..,..)
> 	....
> 	return
> 	end
>
> In C, the qualifier (or whatever the technical term is) "external" is

'extern' in C?

> used to indicate that the function/variable/symbol is defined in
> another compilation unit.  In FORTRAN77, "external" is used to tell the
> compiler that you are passing a function to another
> function/subroutine.  At least that is my understanding from what I
> re-read in my FORTRAN documentation.

Not quite.  It also means that you really want to externally link and 
not allow the compiler to find any routine of that name it knows about 
(e.g. an intrinsic).  See para 8.7 of 
http://www.fortran.com/F77_std/rjcnf-8.html (although I got this from my 
Fortran reference on my bookshelf).

> Thus, perhaps strangely, if there is only a
> 	external double complex zdotc
> declaration in your subroutine, the compiler doesn't know that a call

The only 'strangely' thing is that is accepted: AFAICS is it not valid 
according to the link above.

> to zdotc will return a double complex but will assume that the result
> has the implicitly defined type, a real*8 IIRC.

The Fortran default type for z* is real.

 > So zdotc is called, and
> puts a double complex as result on the stack (heap?), but within
> callzdotc a real as return is expected and that is taken from the
> stack (heap?), that real is than coerced to a double complex when
> assigned to retval.  Note that while I am pretty sure about the above,
> this last paragraph is more speculative. :)  But it would explain why
> the erroneous code returns 0 on little-endian machines.

We haven't been told which machines, and this actually matters down to 
the level of optimization used by the compilers.  But these days 
typically double complex gets passed in sse registers, and double is 
passed in fpu registers.

Note that passing double complex/Rcomplex as return values, from C or 
Fortran, is rather fragile in that it does depend on a pretty precise 
match of compilers (and R's configure does test the constructions it 
uses, and from time to time finds combinations which fail -- R 2.12.2 
was released to workaround one of them).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bhh at xs4all.nl  Tue Mar  6 15:46:29 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Mar 2012 15:46:29 +0100
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <4F561C79.2090002@stats.ox.ac.uk>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
	<20120306213703.6a5a091f@absentia>
	<4F561C79.2090002@stats.ox.ac.uk>
Message-ID: <D0D80B8E-E5A8-457E-9399-09EFA3570E79@xs4all.nl>


On 06-03-2012, at 15:17, Prof Brian Ripley wrote:

>> [..]
>> used to indicate that the function/variable/symbol is defined in
>> another compilation unit.  In FORTRAN77, "external" is used to tell the
>> compiler that you are passing a function to another
>> function/subroutine.  At least that is my understanding from what I
>> re-read in my FORTRAN documentation.
> 
> Not quite.  It also means that you really want to externally link and not allow the compiler to find any routine of that name it knows about (e.g. an intrinsic).  See para 8.7 of http://www.fortran.com/F77_std/rjcnf-8.html (although I got this from my Fortran reference on my bookshelf).
> 
>> Thus, perhaps strangely, if there is only a
>> 	external double complex zdotc
>> declaration in your subroutine, the compiler doesn't know that a call
> 
> The only 'strangely' thing is that is accepted: AFAICS is it not valid according to the link above.
> 

Agree. The fortran 77 standard doesn't allow that syntax and I'm really surprised that no error is flagged.

>> to zdotc will return a double complex but will assume that the result
>> has the implicitly defined type, a real*8 IIRC.
> 
> The Fortran default type for z* is real.
> 
> > So zdotc is called, and
>> puts a double complex as result on the stack (heap?), but within
>> callzdotc a real as return is expected and that is taken from the
>> stack (heap?), that real is than coerced to a double complex when
>> assigned to retval.  Note that while I am pretty sure about the above,
>> this last paragraph is more speculative. :)  But it would explain why
>> the erroneous code returns 0 on little-endian machines.
> 
> We haven't been told which machines, and this actually matters down to the level of optimization used by the compilers.  But these days typically double complex gets passed in sse registers, and double is passed in fpu registers.
> 

Mac OS X 10.6.8, Mini Core 2 Duo
Apple gcc (i686-apple-darwin10-gcc-4.2.1 (GCC) 4.2.1 (Apple Inc. build 5664))
and gfortran (GNU Fortran (GCC) 4.2.1 (Apple Inc. build 5664)) from r.research.att.com.

Output from  R CMD SHLIB --output=dozdot.so callzdotc.f czdot.c 

gfortran -arch x86_64   -fPIC  -g -O2 -c callzdotc.f -o callzdotc.o
gcc -arch x86_64 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64  -I/usr/local/include    -fPIC  -g -O2 -c czdot.c -o czdot.o
gcc -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o dozdot.so callzdotc.o czdot.o -lgfortran -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation

Same thing happens with gcc (Ubuntu/Linaro 4.6.1-9ubuntu3) 4.6.1 and gfortran on Xubuntu 11.10 64-bit.

Berend


From bhh at xs4all.nl  Tue Mar  6 16:00:45 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Mar 2012 16:00:45 +0100
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <D0D80B8E-E5A8-457E-9399-09EFA3570E79@xs4all.nl>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
	<20120306213703.6a5a091f@absentia>
	<4F561C79.2090002@stats.ox.ac.uk>
	<D0D80B8E-E5A8-457E-9399-09EFA3570E79@xs4all.nl>
Message-ID: <5441A736-5C06-43E2-ACA9-7AAE10438257@xs4all.nl>


On 06-03-2012, at 15:46, Berend Hasselman wrote:

> 
>> 
>>> Thus, perhaps strangely, if there is only a
>>> 	external double complex zdotc
>>> declaration in your subroutine, the compiler doesn't know that a call
>> 
>> The only 'strangely' thing is that is accepted: AFAICS is it not valid according to the link above.
>> 
> 
> Agree. The fortran 77 standard doesn't allow that syntax and I'm really surprised that no error is flagged.
> 

Got it.
See http://www.fortran.com/F77_std/rjcnf0001-sh-3.html#sh-3.1.6

Compiler ignores the blanks and

	external double complex zdotc

becomes

	external doublecomplexzdotc	

And that is legal.

And how long have I been using Fortran? I won't tell.

Berend


From djsamperi at gmail.com  Tue Mar  6 16:39:32 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 6 Mar 2012 10:39:32 -0500
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <4F561C79.2090002@stats.ox.ac.uk>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<B1B70BE3-2D8A-495B-8893-CC67026E1E9F@xs4all.nl>
	<20120306195608.7ec858c0@bossiaea>
	<879BAEC9-1963-4574-B962-CA8CC9D4F13B@xs4all.nl>
	<20120306213703.6a5a091f@absentia>
	<4F561C79.2090002@stats.ox.ac.uk>
Message-ID: <CADUbQ5gmAcy99MS0hGSmmzx0V1bAbDh29_oZLgJVN9OkegHFMw@mail.gmail.com>

On Tue, Mar 6, 2012 at 9:17 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 06/03/2012 13:37, Berwin A Turlach wrote:
>>
>> G'day Berend,
>>
>> On Tue, 6 Mar 2012 13:06:34 +0100
>> Berend Hasselman<bhh at xs4all.nl> ?wrote:
>>
>> [... big snip ...]
>>
>>> But I would really like to hear from an Rexpert why you
>>> shouldn't/can't use external here in the Fortran.
>>
>>
>> Probably less a question for an Rexpert but for a Fortran expert....
>
>
> Exactly ....
>
>
>> If you insert "implicit none" (one of my favourite extensions that I
>> always use) as the first statement after
>> ? ? ? ?subroutine callzdotc(retval,n, zx, incx, zy, incy)
>> you will see what is going on. ?The compiler should refuse compilation
>> and complain that the type of zdotc was not declared (at least my
>> compiler does). ?For FORTRAN to know that zdotc returns a double
>> complex you need the
>> ? ? ? ?double complex zdotc
>> declaration in callzdotc.
>>
>> An
>> ? ? ? ?external double complex zdotc
>> would be necessary if you were to call another subroutine/function, say
>> foo, that accepts functions as formal arguments and you want to pass
>> zdotc via such an argument. ?Something like
>>
>> ? ? ? ?subroutine callzdotc(....)
>> ? ? ? ? ....
>> ? ? ? ? external double complex zdotc
>> ? ? ? ?....
>> ? ? ? ? call foo(a, b, zdotc)
>> ? ? ? ? ....
>> ? ? ? ?return
>> ? ? ? ?end
>>
>> ? ? ? ?subroutine(a, b, h)
>> ? ? ? ?double complex h, t
>> ? ? ? ?....
>> ? ? ? ?t = h(..,..,..,..)
>> ? ? ? ?....
>> ? ? ? ?return
>> ? ? ? ?end
>>
>> In C, the qualifier (or whatever the technical term is) "external" is
>
>
> 'extern' in C?
>
>
>> used to indicate that the function/variable/symbol is defined in
>> another compilation unit. ?In FORTRAN77, "external" is used to tell the
>> compiler that you are passing a function to another
>> function/subroutine. ?At least that is my understanding from what I
>> re-read in my FORTRAN documentation.
>
>
> Not quite. ?It also means that you really want to externally link and not
> allow the compiler to find any routine of that name it knows about (e.g. an
> intrinsic). ?See para 8.7 of http://www.fortran.com/F77_std/rjcnf-8.html
> (although I got this from my Fortran reference on my bookshelf).
>
>
>> Thus, perhaps strangely, if there is only a
>> ? ? ? ?external double complex zdotc
>> declaration in your subroutine, the compiler doesn't know that a call
>
>
> The only 'strangely' thing is that is accepted: AFAICS is it not valid
> according to the link above.
>
>
>> to zdotc will return a double complex but will assume that the result
>> has the implicitly defined type, a real*8 IIRC.
>
>
> The Fortran default type for z* is real.
>
>
>> So zdotc is called, and
>>
>> puts a double complex as result on the stack (heap?), but within
>> callzdotc a real as return is expected and that is taken from the
>> stack (heap?), that real is than coerced to a double complex when
>> assigned to retval. ?Note that while I am pretty sure about the above,
>> this last paragraph is more speculative. :) ?But it would explain why
>> the erroneous code returns 0 on little-endian machines.
>
>
> We haven't been told which machines, and this actually matters down to the
> level of optimization used by the compilers. ?But these days typically
> double complex gets passed in sse registers, and double is passed in fpu
> registers.
>
> Note that passing double complex/Rcomplex as return values, from C or
> Fortran, is rather fragile in that it does depend on a pretty precise match
> of compilers (and R's configure does test the constructions it uses, and
> from time to time finds combinations which fail -- R 2.12.2 was released to
> workaround one of them).

It turns the problem reported above was discovered in a completely
different context, unrelated to R, and when I looked at how R handles
the problem I found similar issues. As Brian says, the C/Fortran
interface can be fragile and machine/compiler-dependent.

The code appended below may shed some light on the issues. The
Fortran code provides three interfaces to zdotc, two function interfaces
and one subroutine interface. The test driver exercises each interface
and the results are what you would expect.

This was tested using gfortran/gcc under Fedora 16 (64bit).

This depends on the particular way the gfortran and gcc
interact, specifically, the -std=gnu flag is important (it is
also the default). Also, it is important to remember that
REAL in Fortran maps to float in C, REAL*16 maps to
double, DOUBLE COMPLEX maps to complex, etc.

To run the executable you may have to use:
export LD_LIBRARY_PATH=.

*** Makefile ***
testzdotc:
	gfortran -std=gnu -fPIC -shared -o libmyblas.so zdotc.f
	gcc -o testzdotc testzdotc.c -L/home/dsamperi -lmyblas -lm

*** testzdotc.c ***

#include <stdio.h>
#include <complex.h>

extern double complex zdotc1_(int*,complex*,int*,complex*,int*);
extern void zdotc2_(complex*,int*,complex*,int*,complex*,int*);
extern float zdotc3_(int*,complex*,int*,complex*,int*);

int main() {
    int n=3;
    int incx = 1;
    int incy = 1;
    complex zx[3], zy[3], zdotc,zdotc2;
    double z;
    printf("Size complex: %d\n", sizeof(complex));
    printf("Size double = %d\n", sizeof(double));
    printf("Size float:   %d\n", sizeof(float));
    zx[0] = 1+0*I; zx[1] = 2+0*I; zx[2] = 3+0*I;
    zy[0] = 1+0*I; zy[1] = 2+0*I; zy[2] = 3+0*I;
    zdotc = zdotc1_(&n,zx,&incx,zy,&incy);
    zdotc2_(&zdotc2,&n,zx,&incx,zy,&incy);
    z = zdotc3_(&n,zx,&incx,zy,&incy);
    printf("Using zdotc1: %g,%g\n", creal(zdotc),cimag(zdotc));
    printf("Using zdotc2: %g,%g\n", creal(zdotc2),cimag(zdotc2));
    printf("Using zdotc3: %f\n", z);
}

*** zdotc.f ***

** Three variants of zdotc based on the BLAS code of jack dongarra (3/11/78).
      DOUBLE COMPLEX FUNCTION ZDOTC1(N,ZX,INCX,ZY,INCY)
      INTEGER INCX,INCY,N
      DOUBLE COMPLEX ZX(*),ZY(*)
      DOUBLE COMPLEX ZTEMP
      INTEGER I,IX,IY
      INTRINSIC DCONJG
      ZTEMP = (0.0d0,0.0d0)
      ZDOTC = (0.0d0,0.0d0)
      IF (N.LE.0) RETURN
      IF (INCX.EQ.1 .AND. INCY.EQ.1) THEN
         DO I = 1,N
            ZTEMP = ZTEMP + DCONJG(ZX(I))*ZY(I)
         END DO
      ELSE
         IX = 1
         IY = 1
         IF (INCX.LT.0) IX = (-N+1)*INCX + 1
         IF (INCY.LT.0) IY = (-N+1)*INCY + 1
         DO I = 1,N
            ZTEMP = ZTEMP + DCONJG(ZX(IX))*ZY(IY)
            IX = IX + INCX
            IY = IY + INCY
         END DO
      END IF
      ZDOTC1 = ZTEMP
      RETURN
      END

      SUBROUTINE ZDOTC2(ZDOTC,N,ZX,INCX,ZY,INCY)
      EXTERNAL ZDOTC1
      INTEGER INCX,INCY,N
      DOUBLE COMPLEX ZX(*),ZY(*),ZDOTC, ZDOTC1
      ZDOTC = ZDOTC1(N,ZX,INCX,ZY,INCY)
      RETURN
      END

      REAL FUNCTION ZDOTC3(N,ZX,INCX,ZY,INCY)
      EXTERNAL ZDOTC1
      INTEGER INCX,INCY,N
      DOUBLE COMPLEX ZX(*),ZY(*), ZDOTC1
      ZDOTC3 = ZDOTC1(N,ZX,INCX,ZY,INCY)
      RETURN
      END

>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar  6 16:51:08 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 06 Mar 2012 15:51:08 +0000
Subject: [Rd] Calling FORTRAN function from R issue?
In-Reply-To: <20120306142805.581283ab@bossiaea>
References: <CADUbQ5ghmCd-3K4hx=FrzhA8YwfohhUp0-g6rJHHU0s-uEfN+A@mail.gmail.com>
	<20120306142805.581283ab@bossiaea>
Message-ID: <4F56326C.9020706@stats.ox.ac.uk>

On 06/03/2012 06:28, Berwin A Turlach wrote:
> G'day Dominick,
>
> On Mon, 5 Mar 2012 19:21:01 -0500
> Dominick Samperi<djsamperi at gmail.com>  wrote:

...

>> This is consistent with the interface prototype for the BLAS
>> routine zdotc contained in<R>/include/R_ext/BLAS.h, namely,
>>
>> BLAS_extern Rcomplex
>>      F77_NAME(zdotc)(Rcomplex * ret_val, int *n,
>> 		    Rcomplex *zx, int *incx, Rcomplex *zy, int *incy);
>>
>> [...]
>>
>> On the other hand, this is not consistent with the standard
>> FORTRAN definition for zdotc that is contained in
>> <R>/src/extra/blas/cmplxblas.f, where the first argument is
>> n, not ret_val.
>
> This seems to be indeed inconsistent and, presumably, a bug.  Applying
> the attach patch to R's development version (compiles, installs and
> passes all checks with this patch), and changing in your code the line

As I said elsewhere in this thread, this really is very 
compiler-specific, and rather than being a bug, that header is not 
appropriate to the compilers used (it came from the days of f2c and 
Fortran compilers based on it such as g77).

I'll change the sources to follow your patch as I think it is much more 
likely to be correct these days, but also add a warning in the header.
I don't think it is safe to call these functions from C without 
configure-testing the effect.

>
> 	F77_CALL(zdotc)(&ret_val,&n, zx,&incx, zy,&incy);
>
> to
>
> 	ret_val = F77_CALL(zdotc)(&n, zx,&incx, zy,&incy);
>
> produces the expected output.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Tue Mar  6 17:44:49 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Mar 2012 16:44:49 +0000
Subject: [Rd] Julia
In-Reply-To: <20120306091143.GC1849@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
Message-ID: <E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>

S (and its derivatives and successors) promises that functions
will not change their arguments, so in an expression like
   val <- func(arg)
you know that arg will not be changed.  You can
do that by having func copy arg before doing anything,
but that uses space and time that you want to conserve.
If arg is not a named item in any environment then it
should be fine to write over the original because there
is no way the caller can detect that shortcut.  E.g., in
    cx <- cos(runif(n))
the cos function does not need to allocate new space for
its output, it can just write over its input because, without
a name attached to it, the caller has no way of looking
at what runif(n) returned.  If you did
    x <- runif(n)
    cx <- cos(x)
then cos would have to allocate new space for its output
because overwriting its input would affect a subsequent
    sum(x)
I suppose that end-users and function-writers could learn
to live with having to decide when to copy, but not having
to make that decision makes S more pleasant (and safer) to use.
I think that is a major reason that people are able to
share S code so easily.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: oliver [mailto:oliver at first.in-berlin.de]
> Sent: Tuesday, March 06, 2012 1:12 AM
> To: William Dunlap
> Cc: Herv? Pag?s; R-devel
> Subject: Re: [Rd] Julia
> 
> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
> [...]
> > I find R's (& S+'s & S's) copy-on-write-if-not-copying-would-be-discoverable-
> > by-the-uer machanism for giving the allusion of pass-by-value a good way
> > to structure the contract between the function writer and the function user.
> [...]
> 
> 
> Can you elaborate more on this,
> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
> stuff?
> 
> What do you mean with discoverability of not-copying?
> 
> Ciao,
>    Oliver

From djsamperi at gmail.com  Tue Mar  6 18:49:32 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 6 Mar 2012 12:49:32 -0500
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
Message-ID: <CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>

On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap <wdunlap at tibco.com> wrote:
> S (and its derivatives and successors) promises that functions
> will not change their arguments, so in an expression like
> ? val <- func(arg)
> you know that arg will not be changed. ?You can
> do that by having func copy arg before doing anything,
> but that uses space and time that you want to conserve.
> If arg is not a named item in any environment then it
> should be fine to write over the original because there
> is no way the caller can detect that shortcut. ?E.g., in
> ? ?cx <- cos(runif(n))
> the cos function does not need to allocate new space for
> its output, it can just write over its input because, without
> a name attached to it, the caller has no way of looking
> at what runif(n) returned. ?If you did
> ? ?x <- runif(n)
> ? ?cx <- cos(x)
> then cos would have to allocate new space for its output
> because overwriting its input would affect a subsequent
> ? ?sum(x)
> I suppose that end-users and function-writers could learn
> to live with having to decide when to copy, but not having
> to make that decision makes S more pleasant (and safer) to use.
> I think that is a major reason that people are able to
> share S code so easily.

But don't forget the "Holy Grail" that Doug mentioned at the
start of this thread: finding a flexible language that is also
fast. Currently many R packages employ C/C++ components
to compensate for the fact that the R interpreter can be slow,
and the pass-by-value semantics of S provides no protection
here.

In 2008 Ross Ihaka and Duncan Temple Lang published the
paper "Back to the Future: Lisp as a base for a statistical
computing system" where they propose Common
Lisp as a new foundation for R. They suggest that
this could be done while maintaining the same
familiar R syntax.

A key requirement of any strategy is to maintain
easy access to the huge universe of existing
C/C++/Fortran numerical and graphics libraries,
as these libraries are not likely to be rewritten.

Thus there will always be a need for a foreign
function interface, and the problem is to provide
a flexible and type-safe language that does not
force developers to use another unfamiliar,
less flexible, and error-prone language to
optimize the hot spots.

Dominick

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>> -----Original Message-----
>> From: oliver [mailto:oliver at first.in-berlin.de]
>> Sent: Tuesday, March 06, 2012 1:12 AM
>> To: William Dunlap
>> Cc: Herv? Pag?s; R-devel
>> Subject: Re: [Rd] Julia
>>
>> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
>> [...]
>> > I find R's (& S+'s & S's) copy-on-write-if-not-copying-would-be-discoverable-
>> > by-the-uer machanism for giving the allusion of pass-by-value a good way
>> > to structure the contract between the function writer and the function user.
>> [...]
>>
>>
>> Can you elaborate more on this,
>> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
>> stuff?
>>
>> What do you mean with discoverability of not-copying?
>>
>> Ciao,
>> ? ?Oliver
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhurlin at gwdg.de  Wed Mar  7 10:00:10 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Wed, 07 Mar 2012 10:00:10 +0100
Subject: [Rd] lubridate does not install on FreeBSD any more
In-Reply-To: <4F0D6B6A.9060704@gwdg.de>
References: <4F0D60DE.7020807@gwdg.de>
	<4F0D652D.4060103@statistik.tu-dortmund.de>
	<4F0D6B6A.9060704@gwdg.de>
Message-ID: <4F57239A.8010409@gwdg.de>

Am 11.01.2012 11:58 (UTC+1) schrieb Rainer Hurling:
> On 11.01.2012 11:32 (UTC+1), Uwe Ligges wrote:
>> On 11.01.2012 11:13, Rainer Hurling wrote:
>>> With newest R devel
>>>
>>> #sessionInfo()
>>> R Under development (unstable) (2012-01-10 r58085)
>>> Platform: amd64-portbld-freebsd10.0 (64-bit)
>>> locale:
>>> [1]
>>> de_DE.ISO8859-15/de_DE.ISO8859-15/de_DE.ISO8859-15/C/de_DE.ISO8859-15/de_DE.ISO8859-15
>>>
>>>
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> I get the following error when I try to build and install lubridate from
>>> sources on FreeBSD 10.0-CURRENT (amd64):
>>>
>>> #R CMD INSTALL lubridate_0.2.6.tar.gz
>>> * installing to library '/usr/local/lib/R/library'
>>> * installing *source* package 'lubridate' ...
>>> ** package 'lubridate' successfully unpacked and MD5 sums checked
>>> ** R
>>> ** data
>>> ** moving datasets to lazyload DB
>>> ** inst
>>> ** preparing package for lazy loading
>>> ** help
>>> *** installing help indices
>>> ** building package indices
>>> ** testing if installed package can be loaded
>>> During startup - Warning messages:
>>> 1: Setting LC_CTYPE failed, using "C"
>>> 2: Setting LC_TIME failed, using "C"
>>> 3: Setting LC_MESSAGES failed, using "C"
>>> 4: Setting LC_PAPER failed, using "C"
>>> Error : .onLoad failed in loadNamespace() for 'lubridate', details:
>>> call: utils::assignInNamespace("+.Date", add_dates, "base")
>>> error: locked binding of '+.Date' cannot be changed
>>> Error: loading failed
>>> Execution halted
>>> ERROR: loading failed
>>> * removing '/usr/local/lib/R/library/lubridate'
>>> * restoring previous '/usr/local/lib/R/library/lubridate'
>>>
>>>
>>> Do you have any idea what is going on here?
>>
>> Yes: locked bindings cannot be changed in R-devel any more, and
>> lubridate does that. The maintainer has been asked for an update already.
>>
>> Uwe Ligges
>>
>>> Thanks in advance,
>>> Rainer Hurling
>
> Thanks, Uwe Ligges and Peter Dalgaard, for clarifying this. So we have
> to wait for an update ...

Just for the record. With the new version 1.1.0 I am able to build and 
install lubridate on FreeBSD again.

Thanks for the work,
Rainer Hurling


From branch.lizard at gmail.com  Tue Mar  6 06:59:51 2012
From: branch.lizard at gmail.com (branch.lizard)
Date: Mon, 5 Mar 2012 21:59:51 -0800 (PST)
Subject: [Rd] R tcltk Gui and Rpy2
In-Reply-To: <1330838306717-4442989.post@n4.nabble.com>
References: <1330838306717-4442989.post@n4.nabble.com>
Message-ID: <1331013591689-4448848.post@n4.nabble.com>

I think I have it. I am using Tkinter and Rpy2. It seems to be working
nicely.

--
View this message in context: http://r.789695.n4.nabble.com/R-tcltk-Gui-and-Rpy2-tp4442989p4448848.html
Sent from the R devel mailing list archive at Nabble.com.


From ncrookston.fs at gmail.com  Tue Mar  6 01:54:05 2012
From: ncrookston.fs at gmail.com (Nicholas Crookston)
Date: Mon, 5 Mar 2012 16:54:05 -0800
Subject: [Rd] Julia
In-Reply-To: <20120306001928.GF5702@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<20120306001928.GF5702@siouxsie>
Message-ID: <CAAk+MXxjF-z-Kf4a4MkhsVeoZHEnzVWvh7r0QVYnAQ+pk59XOw@mail.gmail.com>

There are many experts on this topic.  I'll keep this short.

Newer Fortran Languages allow for call by value, but call by reference
is the typical and historically, the only approach (there was a time
when you could change the value of 1 to 2!).

C "only" calls by value except that the value can be a pointer! So,
havoc is just a * away.

I'm very pleased to be on this list and read the discussion. Thank you
Douglas Bates for sending the first message.

I like R and will continue to use it. However, I also think that
strict "call by value" can get you into trouble, just trouble of a
different kind. I'm not sure we will ever yearn for "Julia ouR-Julia",
but it is sure fun to think about what might be possible with this
language. And having fun is one key objective.

Nick Crookston

2012/3/5 oliver <oliver at first.in-berlin.de>:
> On Mon, Mar 05, 2012 at 03:58:59PM -0800, Herv? Pag?s wrote:
>> Hi Oliver,
>>
>> On 03/05/2012 09:08 AM, oliver wrote:
>> >On Mon, Mar 05, 2012 at 03:53:28PM +0000, William Dunlap wrote:
>> >>I haven't used Julia yet, but from my quick reading
>> >>of the docs it looks like arguments to functions are
>> >>passed by reference and not by value, so functions
>> >>can change their arguments. ?My recollection from when
>> >>I first started using S (in the course of a job helping
>> >>profs and grad students do statistical programming, c. 1983)
>> >>is that not having to worry about in-place algorithms changing
>> >>your data gave S a big advantage over Fortran or C.
>> >[...]
>> >
>> >
>> >C also uses Call-by-Value.
>>
>> C *only* uses Call-by-Value.
> [...]
>
>
> Yes, that's what I meant.
>
> With "also" I meant, that it uses call-by-value, as some
> other languages also do.
>
>
> Ciao,
> ? Oliver
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jbanerjee1 at gmail.com  Tue Mar  6 19:08:48 2012
From: jbanerjee1 at gmail.com (jbanerjee)
Date: Tue, 6 Mar 2012 10:08:48 -0800 (PST)
Subject: [Rd] Rserve compilation error
Message-ID: <1331057328261-4450774.post@n4.nabble.com>

Hi,

I am trying to install Rserve 1.7-0 on CentOS 6. But I get this compilation
error - 
/usr/lib64/Revo-5.0/R-2.13.2/lib64/R/lib/libiomp5.so: undefined reference to
`pthread_atfork'
I tried other versions of Rserve (0.6-5 and 0.6-8) without any success.
How do I get around this issue? My goal is to run FastRWeb (which uses
Rserve).

Thanks in advance.
Joydeep.


--
View this message in context: http://r.789695.n4.nabble.com/Rserve-compilation-error-tp4450774p4450774.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Wed Mar  7 14:58:16 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 07 Mar 2012 13:58:16 +0000
Subject: [Rd] Rserve compilation error
In-Reply-To: <1331057328261-4450774.post@n4.nabble.com>
References: <1331057328261-4450774.post@n4.nabble.com>
Message-ID: <4F576978.5000503@stats.ox.ac.uk>

On 06/03/2012 18:08, jbanerjee wrote:
> Hi,
>
> I am trying to install Rserve 1.7-0 on CentOS 6. But I get this compilation
> error -
> /usr/lib64/Revo-5.0/R-2.13.2/lib64/R/lib/libiomp5.so: undefined reference to
> `pthread_atfork'
> I tried other versions of Rserve (0.6-5 and 0.6-8) without any success.
> How do I get around this issue? My goal is to run FastRWeb (which uses
> Rserve).

That message is not from compilation (it is a linker message), and in 
any case comes from the (non-R-core) build of R you used.  R as 
distributed does not have any such library in $R_HOME/lib, so I think 
you need to ask the people who built your R (presumably Revolution) for 
help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From richierocks at gmail.com  Wed Mar  7 15:52:47 2012
From: richierocks at gmail.com (Richard Cotton)
Date: Wed, 7 Mar 2012 14:52:47 +0000
Subject: [Rd] .Internal(inspect(x)) gives overly verbose output for
	reference classes
Message-ID: <CAPp_+=dunqwtXPChpx+7+s_PNG2CH=D5fVsaoXWwN-sECkLk8Q@mail.gmail.com>

Even for an extremely simple instance of a reference class

x <- setRefClass("x")
y <- x$new()

calling the internal inspect function

.Internal(inspect(y))

produces enough output that it takes several minutes to print to the
console.? (Actually I gave up and terminated the command after ~10
mins.? It isn't clear whether the output would eventually complete.)

Are reference classes really so complicated inside, or is this a bug?


From djsamperi at gmail.com  Wed Mar  7 16:31:14 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 7 Mar 2012 10:31:14 -0500
Subject: [Rd] Julia
In-Reply-To: <20120306085658.GA1849@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<20120306001928.GF5702@siouxsie>
	<CAAk+MXxjF-z-Kf4a4MkhsVeoZHEnzVWvh7r0QVYnAQ+pk59XOw@mail.gmail.com>
	<20120306085658.GA1849@siouxsie>
Message-ID: <CADUbQ5iuF3avcB=1Q+T+5KYuL0M2AVUiSDm_32ePGONYA8FxpQ@mail.gmail.com>

On Tue, Mar 6, 2012 at 3:56 AM, oliver <oliver at first.in-berlin.de> wrote:
> On Mon, Mar 05, 2012 at 04:54:05PM -0800, Nicholas Crookston wrote:
>> There are many experts on this topic. ?I'll keep this short.
>>
>> Newer Fortran Languages allow for call by value, but call by reference
>> is the typical and historically, the only approach (there was a time
>> when you could change the value of 1 to 2!).
>
> Oh, strange.
>
>
>>
>> C "only" calls by value except that the value can be a pointer! So,
>> havoc is just a * away.
> [...]
>
> For me there was no "havoc" at this point, but for others maybe.
>
> There are also other languages that only use call-by-value...
> ...functional languages are that way in principal.
>
> ?Nevertheless internally they may heavily use pointers and
> ?even if you have values that are large arrays for example,
> ?they internally just give a pointer to that data structure.
> ?(That's, why functional languages are not necessarily slow
> ?just because you act on large data and have no references
> ?in that language. (A common misunderstanding about functional
> ?languages must be slow because they have nor references.)
> ?The pointer-stuff is just hidden.
>
> Even they ((non-purely) functional languages) may have references,
> their concept of references is different. (See OCaml for example.)
> There you can use references to change values in place, but the
> reference itself is a functional value, and you will never have
> access to the pointer stuff directly. Hence no problems with
> mem-arithmetics and dangling pointer's or Null-pointers.
>
>
>
> [...]
>> I like R and will continue to use it. However, I also think that
>> strict "call by value" can get you into trouble, just trouble of a
>> different kind.
>
> Can you elaborate more on this?
> What problems do you have in mind?
> And what kind of references do you have in mind?
> The C-like pointers or something like OCaml's ref's?

OCaml refs are an "escape hatch" from the pure
functional programming paradigm where nothing can
be changed once given a value, an extreme form of
pass-by-value. Similarly, most languages that are
advertised as pass-by-value include some kind of
escape hatch that permits you to work with pointers
(or mutable vectors) for improved runtime performance.

The speed issues arise for two main reasons: interpreting
code is much slower than running machine code, and
copying large data structures can be expensive.
Pass-by-value semantics forces this to happen in
many situations where the compiler/interpreter cannot
safely optimize it away.

Based on the video Julia manages the speed issue by
viewing everything like a template, thus generating new
methods based on type inference. This means there isn't
a lot of runtime type checking for dispatch, because
customized methods were already generated, but this
can lead to another problem: code bloat. There are
no free lunches.

>> I'm not sure we will ever yearn for "Julia ouR-Julia",
>> but it is sure fun to think about what might be possible with this
>> language. And having fun is one key objective.
>
> I have fun if things work.
> And if the tools do, what I want to achieve...
> ...and the fun is better, if they do it elegantly.
>
> Do you ask for references in R?
> And what kind of references do you have in mind,
> and why does it hurt you not to have them?
>
> Can you give examples, so that it's easier to see,
> whwere you miss something?
>
>
> Ciao,
> ? Oliver
>
> P.S.: The speed issue of R was coming up more than once;
> ? ? ?in some blog posts it was mentioned. would it make
> ? ? ?sense to start a seperated thread of it?
> ? ? ?In one ?of the blog-articles I read, it was mourned about
> ? ? ?how NA / missing values were handled, and that NA should
> ? ? ?maybe become thrown out, just to get higher speed.
> ? ? ?I would not like to have that. Handling NA as special
> ? ? ?case IMHO is a very good way. Don't remember if the
> ? ? ?article I have in mind just argued about HOW this was
> ? ? ?handled, or if it should be thrown out completely.
> ? ? ?Making the handling of it better and more performant I
> ? ? ?think is a good idea, ignoring NA IMHO is a bad idea.
>
> ? ? ?But maybe that really would be worth a seperate thread?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Mar  7 16:37:58 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 07 Mar 2012 10:37:58 -0500
Subject: [Rd] .Internal(inspect(x)) gives overly verbose output for
 reference classes
In-Reply-To: <CAPp_+=dunqwtXPChpx+7+s_PNG2CH=D5fVsaoXWwN-sECkLk8Q@mail.gmail.com>
References: <CAPp_+=dunqwtXPChpx+7+s_PNG2CH=D5fVsaoXWwN-sECkLk8Q@mail.gmail.com>
Message-ID: <4F5780D6.8020409@gmail.com>

On 12-03-07 9:52 AM, Richard Cotton wrote:
> Even for an extremely simple instance of a reference class
>
> x<- setRefClass("x")
> y<- x$new()
>
> calling the internal inspect function
>
> .Internal(inspect(y))
>
> produces enough output that it takes several minutes to print to the
> console.  (Actually I gave up and terminated the command after ~10
> mins.  It isn't clear whether the output would eventually complete.)
>
> Are reference classes really so complicated inside, or is this a bug?
>
> ______________________________________________

If you look at the output, you'll see it's looping.  When I hit Esc, I 
saw that .self is an S4SXP with an attribute .xData which is an 
environment containing the same .self, ad infinitum.

So I'd say it's a bug in inspect().  It can handle the case of an 
environment holding itself, but I think it was written before S4SXPs 
contained themselves, and it looks like it's not checking for that.

I'll take a look if someone else doesn't get there first...

Duncan Murdoch


From oliver at first.in-berlin.de  Wed Mar  7 16:50:47 2012
From: oliver at first.in-berlin.de (oliver)
Date: Wed, 7 Mar 2012 16:50:47 +0100
Subject: [Rd] Julia
In-Reply-To: <CADUbQ5iuF3avcB=1Q+T+5KYuL0M2AVUiSDm_32ePGONYA8FxpQ@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<20120306001928.GF5702@siouxsie>
	<CAAk+MXxjF-z-Kf4a4MkhsVeoZHEnzVWvh7r0QVYnAQ+pk59XOw@mail.gmail.com>
	<20120306085658.GA1849@siouxsie>
	<CADUbQ5iuF3avcB=1Q+T+5KYuL0M2AVUiSDm_32ePGONYA8FxpQ@mail.gmail.com>
Message-ID: <20120307155047.GH2349@siouxsie>

On Wed, Mar 07, 2012 at 10:31:14AM -0500, Dominick Samperi wrote:
> On Tue, Mar 6, 2012 at 3:56 AM, oliver <oliver at first.in-berlin.de> wrote:
> > On Mon, Mar 05, 2012 at 04:54:05PM -0800, Nicholas Crookston wrote:
> >> There are many experts on this topic. ?I'll keep this short.
> >>
> >> Newer Fortran Languages allow for call by value, but call by reference
> >> is the typical and historically, the only approach (there was a time
> >> when you could change the value of 1 to 2!).
> >
> > Oh, strange.
> >
> >
> >>
> >> C "only" calls by value except that the value can be a pointer! So,
> >> havoc is just a * away.
> > [...]
> >
> > For me there was no "havoc" at this point, but for others maybe.
> >
> > There are also other languages that only use call-by-value...
> > ...functional languages are that way in principal.
> >
> > ?Nevertheless internally they may heavily use pointers and
> > ?even if you have values that are large arrays for example,
> > ?they internally just give a pointer to that data structure.
> > ?(That's, why functional languages are not necessarily slow
> > ?just because you act on large data and have no references
> > ?in that language. (A common misunderstanding about functional
> > ?languages must be slow because they have nor references.)
> > ?The pointer-stuff is just hidden.
> >
> > Even they ((non-purely) functional languages) may have references,
> > their concept of references is different. (See OCaml for example.)
> > There you can use references to change values in place, but the
> > reference itself is a functional value, and you will never have
> > access to the pointer stuff directly. Hence no problems with
> > mem-arithmetics and dangling pointer's or Null-pointers.
> >
> >
> >
> > [...]
> >> I like R and will continue to use it. However, I also think that
> >> strict "call by value" can get you into trouble, just trouble of a
> >> different kind.
> >
> > Can you elaborate more on this?
> > What problems do you have in mind?
> > And what kind of references do you have in mind?
> > The C-like pointers or something like OCaml's ref's?
> 
> OCaml refs are an "escape hatch" from the pure
> functional programming paradigm where nothing can
> be changed once given a value, an extreme form of
> pass-by-value.

OCaml is not a purely functional language and has
not the claim to be one; hence it's not an "escape hatch"
(which seem to have a negative touch to me).

Arrays and strings in OCaml are also imperative.
And with the "mutable" attribute in records, you also can
crearte imperative record entries.

So, it's just a different design / approach than
Haskell for example. OCaml is coming from ML-languages.

Purely Functional on the one hand is beautiful, and 
therefore nice; but it also is dogmatic on the other hand.

> Similarly, most languages that are
> advertised as pass-by-value include some kind of
> escape hatch that permits you to work with pointers
> (or mutable vectors) for improved runtime performance.

References in OCaml are NOT pointers.
You do have access in an imperative / in-place way, but you
have NO POINTER STUFF in that language.

====================================================
# let a = ref 5;;
val a : int ref = {contents = 5}
# a := 7;;
- : unit = ()
# a;;
- : int ref = {contents = 7}
# 
====================================================

This is in-place modification of the contents of the ref,
without any pointer arithmetics.
"a" is a functional value which hosts an imperative one
on the inside.


> 
> The speed issues arise for two main reasons: interpreting
> code is much slower than running machine code, and
> copying large data structures can be expensive.

The functional approach often saves time and space.
This is just not well known.
And the distinction of imperative vs. functional has
nothing to do with interpreted vs. directly executed.


====================================================
# let mylist_1 = [ 3;5;323 ];;
val mylist_1 : int list = [3; 5; 323]
# let mylist_2 = 12 :: mylist_1;;
val mylist_2 : int list = [12; 3; 5; 323]
# mylist_1;;
- : int list = [3; 5; 323]
# mylist_2;;
- : int list = [12; 3; 5; 323]
# 
====================================================

Both lists share the common elements here.
No copy is done.
In this case the functional approach is very nice.

Just a counter-example to "functional is eating up space".

When thinking about the questions here, I think
the design of Ocaml addressed all this, and that this was
the design decision, why arrays are possible to be changed
imperatively.

====================================================
# let my_array = [| 1; 3; 54; 99 |];;
val my_array : int array = [|1; 3; 54; 99|]
# my_array;;
- : int array = [|1; 3; 54; 99|]
# my_array.(2) <- 99999;;
- : unit = ()
# my_array;;
- : int array = [|1; 3; 99999; 99|]
# 
====================================================

If R is rather purely functional here,
then the problem addressed here is, that
a pureley functional approach without any "escape hatches"
creates the problem.

If in-place modification is also not possible on arrays,
then this is the base of the problem.

But changing this behaviour in newer versions of R
would brake a lot of already existing R-code.


Ciao,
   Oliver


From oliver at first.in-berlin.de  Wed Mar  7 19:21:39 2012
From: oliver at first.in-berlin.de (oliver)
Date: Wed, 7 Mar 2012 19:21:39 +0100
Subject: [Rd] Julia
In-Reply-To: <CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
Message-ID: <20120307182139.GA5564@siouxsie>

On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap <wdunlap at tibco.com> wrote:
> > S (and its derivatives and successors) promises that functions
> > will not change their arguments, so in an expression like
> > ? val <- func(arg)
> > you know that arg will not be changed. ?You can
> > do that by having func copy arg before doing anything,
> > but that uses space and time that you want to conserve.
> > If arg is not a named item in any environment then it
> > should be fine to write over the original because there
> > is no way the caller can detect that shortcut. ?E.g., in
> > ? ?cx <- cos(runif(n))
> > the cos function does not need to allocate new space for
> > its output, it can just write over its input because, without
> > a name attached to it, the caller has no way of looking
> > at what runif(n) returned. ?If you did
> > ? ?x <- runif(n)
> > ? ?cx <- cos(x)

You have two names here, x and cx, hence
your example does not fit into what you want to explain.

A better example would be:
x <- runif(n)
x <- cos(x)



> > then cos would have to allocate new space for its output
> > because overwriting its input would affect a subsequent
> > ? ?sum(x)
> > I suppose that end-users and function-writers could learn
> > to live with having to decide when to copy, but not having
> > to make that decision makes S more pleasant (and safer) to use.
> > I think that is a major reason that people are able to
> > share S code so easily.
> 
> But don't forget the "Holy Grail" that Doug mentioned at the
> start of this thread: finding a flexible language that is also
> fast. Currently many R packages employ C/C++ components
> to compensate for the fact that the R interpreter can be slow,
> and the pass-by-value semantics of S provides no protection
> here.
[...]

The distinction imperative vs. functional has nothing to do
with the distinction interpreted vs. directly executed.




Thinking again on the problem that was mentioned here,
I think it might be circumvented.

Looking again at R's properties, looking again into U.Ligges "Programmieren in
R", I saw there was mentioned that in R anything (?!) is an object... so then it's
OOP; but also it was mentioned, R is a functional language. But this does not
mean it's purely functional or has no imperative data structures.

As R relies heavily on vectors, here we have an imperative datastructure.

So, it rather looks to me that "<-" does work in-place
on the vectors, even "<-" itself is a function (which does not matter for
the problem).

If thats true (I assume here, it is; correct me, if it's wrong),
then I think, assigning with "<<-" and assign() also would do an imperative
(in-place) change of the contents.

Then the copying-of-big-objects-when-passed-as-args problem can be circumvented
by working on either a variable in the GlobalEnv (and using "<<-", or using a
certain environment for the big data and passing it's name (and the variable)
as value to the function which then uses assign() and get() to work on that
data.
Then in-place modification should be possible.





> 
> In 2008 Ross Ihaka and Duncan Temple Lang published the
> paper "Back to the Future: Lisp as a base for a statistical
> computing system" where they propose Common
> Lisp as a new foundation for R. They suggest that
> this could be done while maintaining the same
> familiar R syntax.
> 
> A key requirement of any strategy is to maintain
> easy access to the huge universe of existing
> C/C++/Fortran numerical and graphics libraries,
> as these libraries are not likely to be rewritten.
> 
> Thus there will always be a need for a foreign
> function interface, and the problem is to provide
> a flexible and type-safe language that does not
> force developers to use another unfamiliar,
> less flexible, and error-prone language to
> optimize the hot spots.

If I here "type safe" I rather would think about OCaml
or maybe Ada, but not LISP.

Also, LISP has so many "("'s and ")"'s,
that it's making people going crazy ;-)

Ciao,
   Oliver


From wdunlap at tibco.com  Wed Mar  7 20:10:43 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 7 Mar 2012 19:10:43 +0000
Subject: [Rd] Julia
In-Reply-To: <20120307182139.GA5564@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
Message-ID: <E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>

No my examples are what I meant.  My point was that a function, say cos(),
can act like it does call-by-value but conserve memory when it can  if it can
distinguish between the case
    cx <- cos(x=runif(n)) # no allocation needed, use the input space for the return value
and and the case
   x <- runif(n)
   cx <- cos(x=x) # return value cannot reuse the argument's memory, so allocate space for return value
   sum(x)              # Otherwise sum(x) would return sum(cx)
The function needs to know if a memory block is referred to by a name in any environment
in order to do that.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: oliver [mailto:oliver at first.in-berlin.de]
> Sent: Wednesday, March 07, 2012 10:22 AM
> To: Dominick Samperi
> Cc: William Dunlap; R-devel
> Subject: Re: [Rd] Julia
> 
> On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
> > > S (and its derivatives and successors) promises that functions will
> > > not change their arguments, so in an expression like
> > > ? val <- func(arg)
> > > you know that arg will not be changed. ?You can do that by having
> > > func copy arg before doing anything, but that uses space and time
> > > that you want to conserve.
> > > If arg is not a named item in any environment then it should be fine
> > > to write over the original because there is no way the caller can
> > > detect that shortcut. ?E.g., in
> > > ? ?cx <- cos(runif(n))
> > > the cos function does not need to allocate new space for its output,
> > > it can just write over its input because, without a name attached to
> > > it, the caller has no way of looking at what runif(n) returned. ?If
> > > you did
> > > ? ?x <- runif(n)
> > > ? ?cx <- cos(x)
> 
> You have two names here, x and cx, hence your example does not fit into what
> you want to explain.
> 
> A better example would be:
> x <- runif(n)
> x <- cos(x)
> 
> 
> 
> > > then cos would have to allocate new space for its output because
> > > overwriting its input would affect a subsequent
> > > ? ?sum(x)
> > > I suppose that end-users and function-writers could learn to live
> > > with having to decide when to copy, but not having to make that
> > > decision makes S more pleasant (and safer) to use.
> > > I think that is a major reason that people are able to share S code
> > > so easily.
> >
> > But don't forget the "Holy Grail" that Doug mentioned at the start of
> > this thread: finding a flexible language that is also fast. Currently
> > many R packages employ C/C++ components to compensate for the fact
> > that the R interpreter can be slow, and the pass-by-value semantics of
> > S provides no protection here.
> [...]
> 
> The distinction imperative vs. functional has nothing to do with the distinction
> interpreted vs. directly executed.
> 
> 
> 
> 
> Thinking again on the problem that was mentioned here, I think it might be
> circumvented.
> 
> Looking again at R's properties, looking again into U.Ligges "Programmieren in
> R", I saw there was mentioned that in R anything (?!) is an object... so then it's
> OOP; but also it was mentioned, R is a functional language. But this does not
> mean it's purely functional or has no imperative data structures.
> 
> As R relies heavily on vectors, here we have an imperative datastructure.
> 
> So, it rather looks to me that "<-" does work in-place on the vectors, even "<-"
> itself is a function (which does not matter for the problem).
> 
> If thats true (I assume here, it is; correct me, if it's wrong), then I think, assigning
> with "<<-" and assign() also would do an imperative
> (in-place) change of the contents.
> 
> Then the copying-of-big-objects-when-passed-as-args problem can be
> circumvented by working on either a variable in the GlobalEnv (and using "<<-",
> or using a certain environment for the big data and passing it's name (and the
> variable) as value to the function which then uses assign() and get() to work on
> that data.
> Then in-place modification should be possible.
> 
> 
> 
> 
> 
> >
> > In 2008 Ross Ihaka and Duncan Temple Lang published the paper "Back to
> > the Future: Lisp as a base for a statistical computing system" where
> > they propose Common Lisp as a new foundation for R. They suggest that
> > this could be done while maintaining the same familiar R syntax.
> >
> > A key requirement of any strategy is to maintain easy access to the
> > huge universe of existing C/C++/Fortran numerical and graphics
> > libraries, as these libraries are not likely to be rewritten.
> >
> > Thus there will always be a need for a foreign function interface, and
> > the problem is to provide a flexible and type-safe language that does
> > not force developers to use another unfamiliar, less flexible, and
> > error-prone language to optimize the hot spots.
> 
> If I here "type safe" I rather would think about OCaml or maybe Ada, but not
> LISP.
> 
> Also, LISP has so many "("'s and ")"'s,
> that it's making people going crazy ;-)
> 
> Ciao,
>    Oliver

From hpages at fhcrc.org  Thu Mar  8 00:30:51 2012
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 07 Mar 2012 15:30:51 -0800
Subject: [Rd] isGeneric() can return an error
Message-ID: <4F57EFAB.8010709@fhcrc.org>

Hi,

I wonder if this is a feature or a bug:

   > isGeneric("&&")
   Error in genericForPrimitive(f) :
     methods may not be defined for primitive function ?&&? in this 
version of R
   > isGeneric(":")
   Error in genericForPrimitive(f) :
     methods may not be defined for primitive function ?:? in this 
version of R

According to the man page:

      ?isGeneric?: Is there a function named ?f?, and if so, is it a
           generic?

So it sounds like it should be a YES or NO answer.

In any case the error message is confusing: it suggests that I'm trying
to define methods for "&&", but I'm not.

This is with R 2.13, R 2.14 and R 2.15.0 alpha.

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Thu Mar  8 01:12:45 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 07 Mar 2012 19:12:45 -0500
Subject: [Rd] .Internal(inspect(x)) gives overly verbose output for
 reference classes
In-Reply-To: <4F5780D6.8020409@gmail.com>
References: <CAPp_+=dunqwtXPChpx+7+s_PNG2CH=D5fVsaoXWwN-sECkLk8Q@mail.gmail.com>
	<4F5780D6.8020409@gmail.com>
Message-ID: <4F57F97D.4050607@gmail.com>

On 12-03-07 10:37 AM, Duncan Murdoch wrote:
> On 12-03-07 9:52 AM, Richard Cotton wrote:
>> Even for an extremely simple instance of a reference class
>>
>> x<- setRefClass("x")
>> y<- x$new()
>>
>> calling the internal inspect function
>>
>> .Internal(inspect(y))
>>
>> produces enough output that it takes several minutes to print to the
>> console.  (Actually I gave up and terminated the command after ~10
>> mins.  It isn't clear whether the output would eventually complete.)
>>
>> Are reference classes really so complicated inside, or is this a bug?
>>
>> ______________________________________________
>
> If you look at the output, you'll see it's looping.  When I hit Esc, I
> saw that .self is an S4SXP with an attribute .xData which is an
> environment containing the same .self, ad infinitum.
>
> So I'd say it's a bug in inspect().  It can handle the case of an
> environment holding itself, but I think it was written before S4SXPs
> contained themselves, and it looks like it's not checking for that.
>
> I'll take a look if someone else doesn't get there first...

There are a couple of optional arguments to inspect that let you avoid 
this infinite recursion, e.g.

.Internal(inspect(y, 5))

will limit the recursion depth to 5, and that's sufficient for this example.

It would be possible to put loop detection into the function, or default 
to a finite depth, but I'd rather not mess it up:  keeping debugging 
aids simple but powerful seems like a good idea to me.  You can always 
hit Esc to stop the display if it goes into a loop, then set a depth 
limit as above.

Duncan Murdoch


From jbanerjee1 at gmail.com  Thu Mar  8 02:46:38 2012
From: jbanerjee1 at gmail.com (jbanerjee)
Date: Wed, 7 Mar 2012 17:46:38 -0800 (PST)
Subject: [Rd] Rserve compilation error
In-Reply-To: <4F576978.5000503@stats.ox.ac.uk>
References: <1331057328261-4450774.post@n4.nabble.com>
	<4F576978.5000503@stats.ox.ac.uk>
Message-ID: <1331171198224-4455308.post@n4.nabble.com>

Brian,
Thanks for your response. I tried this with R-core (version 2.14.0) and it
worked.


--
View this message in context: http://r.789695.n4.nabble.com/Rserve-compilation-error-tp4450774p4455308.html
Sent from the R devel mailing list archive at Nabble.com.


From hwborchers at googlemail.com  Thu Mar  8 12:16:54 2012
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Thu, 8 Mar 2012 12:16:54 +0100
Subject: [Rd] Task View on Numerical Analysis and Differential Equations
Message-ID: <CAML4n3PA-mdFTRxboys01Ze5YA-n6dyPtSnni8j9eHTcfacyOQ@mail.gmail.com>

I am wondering if it would be time to have a new Task View, this time
for the subject of "Numerical Analysis and Differential Equations".
The list of packages possibly appearing in such a task view is already
quite long and could, for example, include:

Numerical Analysis and Linear Algebra

Bessel        Bessel Functions Computations and Approximations
cubature      Adaptive multivariate integration over hypercubes
elliptic      Elliptic and related functions
expm          Matrix exponential, logarithm, etc.
fdim	      Functions for calculating fractal dimension
gaussquad     Collection of functions for Gaussian quadrature
gmp           Multiple precision arithmetic
gsl           Wrapper for the Gnu Scientific Library
hypergeo      The hypergeometric function
irlba         Fast partial SVD by Lanczos bidiagonalization
matlab        MATLAB emulation package
multipol      Multivariate polynomials
numDeriv      Accurate numerical derivatives
onion         Octonions and quaternions
orthogonalsplinebasis  Orthogonal Bspline basis functions
orthopolynom  Functions for orthogonal and orthonormal polynomials
polspline     Polynomial spline routines
polynom       Implement a class for univariate polynomial manipulations
PolynomF      Polynomials in R
pracma        Practical numerical math functions
pspline       Penalized smoothing splines
quaternions   Arithmetics and linear algebra with quaternions
R2Cuba        Multidimensional numerical integration
RcppArmadillo Rcpp integration for Armadillo templated linear algebra library
RcppEigen	  Rcpp integration for the Eigen templated linear algebra library
RcppOctave    Rcpp integration of Octave
R.matlab	  Read and write of MAT files and R-to-Matlab connectivity
Rmpfr	      Multiple precision floating-point reliable
sparseGrid    Sparse grid integration in R
spuRs         Functions and datasets scientific programming and simulation
sspline       Smoothing splines on the sphere
stinepack     Stineman: consistently well behaved method of interpolation
svd           Interfaces to various state-of-art SVD and eigensolvers
voronoi       Methods and applications related to Voronoi tessellations
wavelets...

Simulation and Differential Equations

bvpSolve	  Solvers for boundary value problems of ODEs
ddesolve      Solver for Delay Differential Equations
deSolve       General solvers for initial value problems of ordinary
              differential equations (ODE), partial differential equations
              (PDE), differential algebraic equations (DAE), and delay
              differential equations (DDE)
deTestSet	  Testset for differential equations
odesolve	  Solvers for Ordinary Differential Equations
PBSddesolve	  Solver for Delay Differential Equations
rootSolve     Root finding, equilibrium and steady-state analysis of ODEs
sde           Simulation and Inference for Stochastic Differential Equations
Sim.DiffProc  Simulation of diffusion processes
simecol       Simulation of ecological and other dynamic systems

and probably many more in the end. I left out the optimization
packages deliberately, but of course there would be a strong hint to
that task view.

Regards
Hans Werner Borchers


From oliver at first.in-berlin.de  Thu Mar  8 14:56:24 2012
From: oliver at first.in-berlin.de (oliver)
Date: Thu, 8 Mar 2012 14:56:24 +0100
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
References: <20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
Message-ID: <20120308135624.GA9947@siouxsie>

Hi,

ok, thank you for clarifiying what you meant.
You only referred to the reusage of the args,
not of an already existing vector.
So I overgenerealized your example.

But when looking at your example,
and how I would implement the cos()
I doubt I would use copying the args
before calculating the result.

Just allocate a result-vector, and then place the cos()
of the input-vector into the result vector.

I didn't looked at how it is done in R,
but I would guess it's like that.


  In pseudo-Code something like that:
    cos_val[idx] = cos( input_val[idx] );

But R also handles complex data with cos()
so it will look a bit more laborious.

What I have seen so far from implementing C-extensions
for R is rather C-ish, and so you have the control
on many details. Copying the input just to read it
would not make sense here.

I doubt that R internally is doing that.
Or did you found that in the R-code?

The other problem, someone mentioned, was *changing* the contents
of a matrix... and that this is NO>T done in-place, when using
a function for it.
But the namespace-name / variable-name as "references" to the matrix
might solve that problem.


Ciao,
  Oliver



On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> No my examples are what I meant.  My point was that a function, say cos(),
> can act like it does call-by-value but conserve memory when it can  if it can
> distinguish between the case
>     cx <- cos(x=runif(n)) # no allocation needed, use the input space for the return value
> and and the case
>    x <- runif(n)
>    cx <- cos(x=x) # return value cannot reuse the argument's memory, so allocate space for return value
>    sum(x)              # Otherwise sum(x) would return sum(cx)
> The function needs to know if a memory block is referred to by a name in any environment
> in order to do that.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> > -----Original Message-----
> > From: oliver [mailto:oliver at first.in-berlin.de]
> > Sent: Wednesday, March 07, 2012 10:22 AM
> > To: Dominick Samperi
> > Cc: William Dunlap; R-devel
> > Subject: Re: [Rd] Julia
> > 
> > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap <wdunlap at tibco.com>
> > wrote:
> > > > S (and its derivatives and successors) promises that functions will
> > > > not change their arguments, so in an expression like
> > > > ? val <- func(arg)
> > > > you know that arg will not be changed. ?You can do that by having
> > > > func copy arg before doing anything, but that uses space and time
> > > > that you want to conserve.
> > > > If arg is not a named item in any environment then it should be fine
> > > > to write over the original because there is no way the caller can
> > > > detect that shortcut. ?E.g., in
> > > > ? ?cx <- cos(runif(n))
> > > > the cos function does not need to allocate new space for its output,
> > > > it can just write over its input because, without a name attached to
> > > > it, the caller has no way of looking at what runif(n) returned. ?If
> > > > you did
> > > > ? ?x <- runif(n)
> > > > ? ?cx <- cos(x)
> > 
> > You have two names here, x and cx, hence your example does not fit into what
> > you want to explain.
> > 
> > A better example would be:
> > x <- runif(n)
> > x <- cos(x)
> > 
> > 
> > 
> > > > then cos would have to allocate new space for its output because
> > > > overwriting its input would affect a subsequent
> > > > ? ?sum(x)
> > > > I suppose that end-users and function-writers could learn to live
> > > > with having to decide when to copy, but not having to make that
> > > > decision makes S more pleasant (and safer) to use.
> > > > I think that is a major reason that people are able to share S code
> > > > so easily.
> > >
> > > But don't forget the "Holy Grail" that Doug mentioned at the start of
> > > this thread: finding a flexible language that is also fast. Currently
> > > many R packages employ C/C++ components to compensate for the fact
> > > that the R interpreter can be slow, and the pass-by-value semantics of
> > > S provides no protection here.
> > [...]
> > 
> > The distinction imperative vs. functional has nothing to do with the distinction
> > interpreted vs. directly executed.
> > 
> > 
> > 
> > 
> > Thinking again on the problem that was mentioned here, I think it might be
> > circumvented.
> > 
> > Looking again at R's properties, looking again into U.Ligges "Programmieren in
> > R", I saw there was mentioned that in R anything (?!) is an object... so then it's
> > OOP; but also it was mentioned, R is a functional language. But this does not
> > mean it's purely functional or has no imperative data structures.
> > 
> > As R relies heavily on vectors, here we have an imperative datastructure.
> > 
> > So, it rather looks to me that "<-" does work in-place on the vectors, even "<-"
> > itself is a function (which does not matter for the problem).
> > 
> > If thats true (I assume here, it is; correct me, if it's wrong), then I think, assigning
> > with "<<-" and assign() also would do an imperative
> > (in-place) change of the contents.
> > 
> > Then the copying-of-big-objects-when-passed-as-args problem can be
> > circumvented by working on either a variable in the GlobalEnv (and using "<<-",
> > or using a certain environment for the big data and passing it's name (and the
> > variable) as value to the function which then uses assign() and get() to work on
> > that data.
> > Then in-place modification should be possible.
> > 
> > 
> > 
> > 
> > 
> > >
> > > In 2008 Ross Ihaka and Duncan Temple Lang published the paper "Back to
> > > the Future: Lisp as a base for a statistical computing system" where
> > > they propose Common Lisp as a new foundation for R. They suggest that
> > > this could be done while maintaining the same familiar R syntax.
> > >
> > > A key requirement of any strategy is to maintain easy access to the
> > > huge universe of existing C/C++/Fortran numerical and graphics
> > > libraries, as these libraries are not likely to be rewritten.
> > >
> > > Thus there will always be a need for a foreign function interface, and
> > > the problem is to provide a flexible and type-safe language that does
> > > not force developers to use another unfamiliar, less flexible, and
> > > error-prone language to optimize the hot spots.
> > 
> > If I here "type safe" I rather would think about OCaml or maybe Ada, but not
> > LISP.
> > 
> > Also, LISP has so many "("'s and ")"'s,
> > that it's making people going crazy ;-)
> > 
> > Ciao,
> >    Oliver


From bhh at xs4all.nl  Thu Mar  8 15:58:38 2012
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 8 Mar 2012 15:58:38 +0100
Subject: [Rd] Task View on Numerical Analysis and Differential Equations
In-Reply-To: <CAML4n3PA-mdFTRxboys01Ze5YA-n6dyPtSnni8j9eHTcfacyOQ@mail.gmail.com>
References: <CAML4n3PA-mdFTRxboys01Ze5YA-n6dyPtSnni8j9eHTcfacyOQ@mail.gmail.com>
Message-ID: <C0F764D2-2D6F-486F-8612-09C781B02E73@xs4all.nl>


On 08-03-2012, at 12:16, Hans W Borchers wrote:

> I am wondering if it would be time to have a new Task View, this time
> for the subject of "Numerical Analysis and Differential Equations".
> The list of packages possibly appearing in such a task view is already
> quite long and could, for example, include:
> 
> Numerical Analysis and Linear Algebra
> 
> Bessel        Bessel Functions Computations and Approximations
> cubature      Adaptive multivariate integration over hypercubes
> elliptic      Elliptic and related functions
> expm          Matrix exponential, logarithm, etc.
> fdim	      Functions for calculating fractal dimension
> gaussquad     Collection of functions for Gaussian quadrature
> gmp           Multiple precision arithmetic
> gsl           Wrapper for the Gnu Scientific Library
> hypergeo      The hypergeometric function
> irlba         Fast partial SVD by Lanczos bidiagonalization
> matlab        MATLAB emulation package
> multipol      Multivariate polynomials
> numDeriv      Accurate numerical derivatives
> onion         Octonions and quaternions
> orthogonalsplinebasis  Orthogonal Bspline basis functions
> orthopolynom  Functions for orthogonal and orthonormal polynomials
> polspline     Polynomial spline routines
> polynom       Implement a class for univariate polynomial manipulations
> PolynomF      Polynomials in R
> pracma        Practical numerical math functions
> pspline       Penalized smoothing splines
> quaternions   Arithmetics and linear algebra with quaternions
> R2Cuba        Multidimensional numerical integration
> RcppArmadillo Rcpp integration for Armadillo templated linear algebra library
> RcppEigen	  Rcpp integration for the Eigen templated linear algebra library
> RcppOctave    Rcpp integration of Octave
> R.matlab	  Read and write of MAT files and R-to-Matlab connectivity
> Rmpfr	      Multiple precision floating-point reliable
> sparseGrid    Sparse grid integration in R
> spuRs         Functions and datasets scientific programming and simulation
> sspline       Smoothing splines on the sphere
> stinepack     Stineman: consistently well behaved method of interpolation
> svd           Interfaces to various state-of-art SVD and eigensolvers
> voronoi       Methods and applications related to Voronoi tessellations
> wavelets...
> 
> Simulation and Differential Equations
> 
> bvpSolve	  Solvers for boundary value problems of ODEs
> ddesolve      Solver for Delay Differential Equations
> deSolve       General solvers for initial value problems of ordinary
>              differential equations (ODE), partial differential equations
>              (PDE), differential algebraic equations (DAE), and delay
>              differential equations (DDE)
> deTestSet	  Testset for differential equations
> odesolve	  Solvers for Ordinary Differential Equations
> PBSddesolve	  Solver for Delay Differential Equations
> rootSolve     Root finding, equilibrium and steady-state analysis of ODEs
> sde           Simulation and Inference for Stochastic Differential Equations
> Sim.DiffProc  Simulation of diffusion processes
> simecol       Simulation of ecological and other dynamic systems
> 
> and probably many more in the end. I left out the optimization
> packages deliberately, but of course there would be a strong hint to
> that task view.


If you put pracma in "Numerical Analysis and Linear Algebra", then I feel you should also include  BB and nleqslv under that heading. Both of these do things that can be classified as Numerical Analysis. And both can of course also be used for simulation.

BB  solve  (sparse) systems of non linear equations using spectral gradient methods
nleqslv solve systems of nonlinear equations combining global strategies with a Broyden or Newron method.

Berend


From oliver at first.in-berlin.de  Thu Mar  8 16:39:51 2012
From: oliver at first.in-berlin.de (oliver)
Date: Thu, 8 Mar 2012 16:39:51 +0100
Subject: [Rd] Julia
In-Reply-To: <20120308135624.GA9947@siouxsie>
References: <E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
	<20120308135624.GA9947@siouxsie>
Message-ID: <20120308153951.GA11755@siouxsie>

Ah, and you mean if it's an anonymous array
it could be reused directly from the args.

OK, now I see why you insist on the anonymous data thing.
I didn't grasped it even in my last mail.



But that somehow also relates to what I wrote about reusing an already
existing, named vector.

Just the moment of in-place-modification is different.

From
  x  <- runif(n)
  cx <- cos(x)

instead of
> >     cx <- cos(x=runif(n)) # no allocation needed, use the input space for the return value

to something like

  cx  <- runif(n)
  cos( cx, inplace=TRUE)

or

  cos( runif(n), inplace=TRUE)




This way it would be possible to specify the reusage
of the input *explicitly* (without  implicit rules
like anonymous vs. named values).



In Pseudo-Code something like that:

   if (in_place == TRUE )
   {
     input_val[idx] = cos( input_val[idx] );
     return input_val;
   }
   else
   {
     result_val = alloc_vec( LENGTH(input_val), ... );
     result_val[idx] = cos( input_val[idx] );
     return result_val;
   }



Is this matching, what you were looking for?


Ciao,
   Oliver


On Thu, Mar 08, 2012 at 02:56:24PM +0100, oliver wrote:
> Hi,
> 
> ok, thank you for clarifiying what you meant.
> You only referred to the reusage of the args,
> not of an already existing vector.
> So I overgenerealized your example.
> 
> But when looking at your example,
> and how I would implement the cos()
> I doubt I would use copying the args
> before calculating the result.
> 
> Just allocate a result-vector, and then place the cos()
> of the input-vector into the result vector.
> 
> I didn't looked at how it is done in R,
> but I would guess it's like that.
> 
> 
>   In pseudo-Code something like that:
>     cos_val[idx] = cos( input_val[idx] );
> 
> But R also handles complex data with cos()
> so it will look a bit more laborious.
> 
> What I have seen so far from implementing C-extensions
> for R is rather C-ish, and so you have the control
> on many details. Copying the input just to read it
> would not make sense here.
> 
> I doubt that R internally is doing that.
> Or did you found that in the R-code?
> 
> The other problem, someone mentioned, was *changing* the contents
> of a matrix... and that this is NO>T done in-place, when using
> a function for it.
> But the namespace-name / variable-name as "references" to the matrix
> might solve that problem.
> 
> 
> Ciao,
>   Oliver
> 
> 
> 
> On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> > No my examples are what I meant.  My point was that a function, say cos(),
> > can act like it does call-by-value but conserve memory when it can  if it can
> > distinguish between the case
> >     cx <- cos(x=runif(n)) # no allocation needed, use the input space for the return value
> > and and the case
> >    x <- runif(n)
> >    cx <- cos(x=x) # return value cannot reuse the argument's memory, so allocate space for return value
> >    sum(x)              # Otherwise sum(x) would return sum(cx)
> > The function needs to know if a memory block is referred to by a name in any environment
> > in order to do that.
> > 
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> > 
> > > -----Original Message-----
> > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > Sent: Wednesday, March 07, 2012 10:22 AM
> > > To: Dominick Samperi
> > > Cc: William Dunlap; R-devel
> > > Subject: Re: [Rd] Julia
> > > 
> > > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap <wdunlap at tibco.com>
> > > wrote:
> > > > > S (and its derivatives and successors) promises that functions will
> > > > > not change their arguments, so in an expression like
> > > > > ? val <- func(arg)
> > > > > you know that arg will not be changed. ?You can do that by having
> > > > > func copy arg before doing anything, but that uses space and time
> > > > > that you want to conserve.
> > > > > If arg is not a named item in any environment then it should be fine
> > > > > to write over the original because there is no way the caller can
> > > > > detect that shortcut. ?E.g., in
> > > > > ? ?cx <- cos(runif(n))
> > > > > the cos function does not need to allocate new space for its output,
> > > > > it can just write over its input because, without a name attached to
> > > > > it, the caller has no way of looking at what runif(n) returned. ?If
> > > > > you did
> > > > > ? ?x <- runif(n)
> > > > > ? ?cx <- cos(x)
> > > 
> > > You have two names here, x and cx, hence your example does not fit into what
> > > you want to explain.
> > > 
> > > A better example would be:
> > > x <- runif(n)
> > > x <- cos(x)
> > > 
> > > 
> > > 
> > > > > then cos would have to allocate new space for its output because
> > > > > overwriting its input would affect a subsequent
> > > > > ? ?sum(x)
> > > > > I suppose that end-users and function-writers could learn to live
> > > > > with having to decide when to copy, but not having to make that
> > > > > decision makes S more pleasant (and safer) to use.
> > > > > I think that is a major reason that people are able to share S code
> > > > > so easily.
> > > >
> > > > But don't forget the "Holy Grail" that Doug mentioned at the start of
> > > > this thread: finding a flexible language that is also fast. Currently
> > > > many R packages employ C/C++ components to compensate for the fact
> > > > that the R interpreter can be slow, and the pass-by-value semantics of
> > > > S provides no protection here.
> > > [...]
> > > 
> > > The distinction imperative vs. functional has nothing to do with the distinction
> > > interpreted vs. directly executed.
> > > 
> > > 
> > > 
> > > 
> > > Thinking again on the problem that was mentioned here, I think it might be
> > > circumvented.
> > > 
> > > Looking again at R's properties, looking again into U.Ligges "Programmieren in
> > > R", I saw there was mentioned that in R anything (?!) is an object... so then it's
> > > OOP; but also it was mentioned, R is a functional language. But this does not
> > > mean it's purely functional or has no imperative data structures.
> > > 
> > > As R relies heavily on vectors, here we have an imperative datastructure.
> > > 
> > > So, it rather looks to me that "<-" does work in-place on the vectors, even "<-"
> > > itself is a function (which does not matter for the problem).
> > > 
> > > If thats true (I assume here, it is; correct me, if it's wrong), then I think, assigning
> > > with "<<-" and assign() also would do an imperative
> > > (in-place) change of the contents.
> > > 
> > > Then the copying-of-big-objects-when-passed-as-args problem can be
> > > circumvented by working on either a variable in the GlobalEnv (and using "<<-",
> > > or using a certain environment for the big data and passing it's name (and the
> > > variable) as value to the function which then uses assign() and get() to work on
> > > that data.
> > > Then in-place modification should be possible.
> > > 
> > > 
> > > 
> > > 
> > > 
> > > >
> > > > In 2008 Ross Ihaka and Duncan Temple Lang published the paper "Back to
> > > > the Future: Lisp as a base for a statistical computing system" where
> > > > they propose Common Lisp as a new foundation for R. They suggest that
> > > > this could be done while maintaining the same familiar R syntax.
> > > >
> > > > A key requirement of any strategy is to maintain easy access to the
> > > > huge universe of existing C/C++/Fortran numerical and graphics
> > > > libraries, as these libraries are not likely to be rewritten.
> > > >
> > > > Thus there will always be a need for a foreign function interface, and
> > > > the problem is to provide a flexible and type-safe language that does
> > > > not force developers to use another unfamiliar, less flexible, and
> > > > error-prone language to optimize the hot spots.
> > > 
> > > If I here "type safe" I rather would think about OCaml or maybe Ada, but not
> > > LISP.
> > > 
> > > Also, LISP has so many "("'s and ")"'s,
> > > that it's making people going crazy ;-)
> > > 
> > > Ciao,
> > >    Oliver
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rvaradhan at jhmi.edu  Thu Mar  8 16:40:38 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 8 Mar 2012 15:40:38 +0000
Subject: [Rd] Task View on Numerical Analysis and Differential Equations
In-Reply-To: <C0F764D2-2D6F-486F-8612-09C781B02E73@xs4all.nl>
References: <CAML4n3PA-mdFTRxboys01Ze5YA-n6dyPtSnni8j9eHTcfacyOQ@mail.gmail.com>
	<C0F764D2-2D6F-486F-8612-09C781B02E73@xs4all.nl>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3199D4A@DOM-EB-MAIL2.win.ad.jhu.edu>

Dear Hans Werner,

I like the idea overall.  Nothing prevents you from doing this, but you should be committed to getting it up and running and then keeping it updated.

In addition to concurring with Berend's comments, I also would like to mention that numerical analysis (NA) is an extremely broad category.  I am not sure how to restrict that in order to make the taskview manageable.  How about including (i) convergence acceleration of sequences, (ii) fourier transforms/wavelets, (iii) function approximation and special functions of mathematical physics?

Best regards,
Ravi

P.S. I have a package called "eiginv" for solving certain types of inverse eigenvalue problems (e.g., generating a matrix of a specific structure with a given set of eigenvalues)


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Berend Hasselman
Sent: Thursday, March 08, 2012 9:59 AM
To: Hans W Borchers
Cc: r-devel at r-project.org
Subject: Re: [Rd] Task View on Numerical Analysis and Differential Equations


On 08-03-2012, at 12:16, Hans W Borchers wrote:

> I am wondering if it would be time to have a new Task View, this time 
> for the subject of "Numerical Analysis and Differential Equations".
> The list of packages possibly appearing in such a task view is already 
> quite long and could, for example, include:
> 
> Numerical Analysis and Linear Algebra
> 
> Bessel        Bessel Functions Computations and Approximations
> cubature      Adaptive multivariate integration over hypercubes
> elliptic      Elliptic and related functions
> expm          Matrix exponential, logarithm, etc.
> fdim	      Functions for calculating fractal dimension
> gaussquad     Collection of functions for Gaussian quadrature
> gmp           Multiple precision arithmetic
> gsl           Wrapper for the Gnu Scientific Library
> hypergeo      The hypergeometric function
> irlba         Fast partial SVD by Lanczos bidiagonalization
> matlab        MATLAB emulation package
> multipol      Multivariate polynomials
> numDeriv      Accurate numerical derivatives
> onion         Octonions and quaternions
> orthogonalsplinebasis  Orthogonal Bspline basis functions orthopolynom  
> Functions for orthogonal and orthonormal polynomials
> polspline     Polynomial spline routines
> polynom       Implement a class for univariate polynomial manipulations
> PolynomF      Polynomials in R
> pracma        Practical numerical math functions
> pspline       Penalized smoothing splines
> quaternions   Arithmetics and linear algebra with quaternions
> R2Cuba        Multidimensional numerical integration
> RcppArmadillo Rcpp integration for Armadillo templated linear algebra library
> RcppEigen	  Rcpp integration for the Eigen templated linear algebra library
> RcppOctave    Rcpp integration of Octave
> R.matlab	  Read and write of MAT files and R-to-Matlab connectivity
> Rmpfr	      Multiple precision floating-point reliable
> sparseGrid    Sparse grid integration in R
> spuRs         Functions and datasets scientific programming and simulation
> sspline       Smoothing splines on the sphere
> stinepack     Stineman: consistently well behaved method of interpolation
> svd           Interfaces to various state-of-art SVD and eigensolvers
> voronoi       Methods and applications related to Voronoi tessellations
> wavelets...
> 
> Simulation and Differential Equations
> 
> bvpSolve	  Solvers for boundary value problems of ODEs
> ddesolve      Solver for Delay Differential Equations
> deSolve       General solvers for initial value problems of ordinary
>              differential equations (ODE), partial differential equations
>              (PDE), differential algebraic equations (DAE), and delay
>              differential equations (DDE)
> deTestSet	  Testset for differential equations
> odesolve	  Solvers for Ordinary Differential Equations
> PBSddesolve	  Solver for Delay Differential Equations
> rootSolve     Root finding, equilibrium and steady-state analysis of ODEs
> sde           Simulation and Inference for Stochastic Differential Equations
> Sim.DiffProc  Simulation of diffusion processes
> simecol       Simulation of ecological and other dynamic systems
> 
> and probably many more in the end. I left out the optimization 
> packages deliberately, but of course there would be a strong hint to 
> that task view.


If you put pracma in "Numerical Analysis and Linear Algebra", then I feel you should also include  BB and nleqslv under that heading. Both of these do things that can be classified as Numerical Analysis. And both can of course also be used for simulation.


BB  solve  (sparse) systems of non linear equations using spectral gradient methods nleqslv solve systems of nonlinear equations combining global strategies with a Broyden or Newron method.

Berend

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Mar  8 17:21:42 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 8 Mar 2012 16:21:42 +0000
Subject: [Rd] Julia
In-Reply-To: <20120308153951.GA11755@siouxsie>
References: <E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
	<20120308135624.GA9947@siouxsie> <20120308153951.GA11755@siouxsie>
Message-ID: <E66794E69CFDE04D9A70842786030B93284258@PA-MBX04.na.tibco.com>

So you propose an inplace=TRUE/FALSE entry for each
argument to each function which may may want to avoid
allocating memory?  The major problem is that the function
writer has no idea what the value of inplace should be,
as it depends on how the function gets called.  This makes
writing reusable functions (hence packages) difficult.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: oliver [mailto:oliver at first.in-berlin.de]
> Sent: Thursday, March 08, 2012 7:40 AM
> To: William Dunlap
> Cc: R-devel
> Subject: Re: [Rd] Julia
> 
> Ah, and you mean if it's an anonymous array it could be reused directly from the
> args.
> 
> OK, now I see why you insist on the anonymous data thing.
> I didn't grasped it even in my last mail.
> 
> 
> 
> But that somehow also relates to what I wrote about reusing an already
> existing, named vector.
> 
> Just the moment of in-place-modification is different.
> 
> From
>   x  <- runif(n)
>   cx <- cos(x)
> 
> instead of
> > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > space for the return value
> 
> to something like
> 
>   cx  <- runif(n)
>   cos( cx, inplace=TRUE)
> 
> or
> 
>   cos( runif(n), inplace=TRUE)
> 
> 
> 
> 
> This way it would be possible to specify the reusage of the input *explicitly*
> (without  implicit rules like anonymous vs. named values).
> 
> 
> 
> In Pseudo-Code something like that:
> 
>    if (in_place == TRUE )
>    {
>      input_val[idx] = cos( input_val[idx] );
>      return input_val;
>    }
>    else
>    {
>      result_val = alloc_vec( LENGTH(input_val), ... );
>      result_val[idx] = cos( input_val[idx] );
>      return result_val;
>    }
> 
> 
> 
> Is this matching, what you were looking for?
> 
> 
> Ciao,
>    Oliver
> 
> 
> On Thu, Mar 08, 2012 at 02:56:24PM +0100, oliver wrote:
> > Hi,
> >
> > ok, thank you for clarifiying what you meant.
> > You only referred to the reusage of the args, not of an already
> > existing vector.
> > So I overgenerealized your example.
> >
> > But when looking at your example,
> > and how I would implement the cos()
> > I doubt I would use copying the args
> > before calculating the result.
> >
> > Just allocate a result-vector, and then place the cos() of the
> > input-vector into the result vector.
> >
> > I didn't looked at how it is done in R, but I would guess it's like
> > that.
> >
> >
> >   In pseudo-Code something like that:
> >     cos_val[idx] = cos( input_val[idx] );
> >
> > But R also handles complex data with cos() so it will look a bit more
> > laborious.
> >
> > What I have seen so far from implementing C-extensions for R is rather
> > C-ish, and so you have the control on many details. Copying the input
> > just to read it would not make sense here.
> >
> > I doubt that R internally is doing that.
> > Or did you found that in the R-code?
> >
> > The other problem, someone mentioned, was *changing* the contents of a
> > matrix... and that this is NO>T done in-place, when using a function
> > for it.
> > But the namespace-name / variable-name as "references" to the matrix
> > might solve that problem.
> >
> >
> > Ciao,
> >   Oliver
> >
> >
> >
> > On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> > > No my examples are what I meant.  My point was that a function, say
> > > cos(), can act like it does call-by-value but conserve memory when
> > > it can  if it can distinguish between the case
> > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > space for the return value and and the case
> > >    x <- runif(n)
> > >    cx <- cos(x=x) # return value cannot reuse the argument's memory, so
> allocate space for return value
> > >    sum(x)              # Otherwise sum(x) would return sum(cx)
> > > The function needs to know if a memory block is referred to by a
> > > name in any environment in order to do that.
> > >
> > > Bill Dunlap
> > > Spotfire, TIBCO Software
> > > wdunlap tibco.com
> > >
> > > > -----Original Message-----
> > > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > > Sent: Wednesday, March 07, 2012 10:22 AM
> > > > To: Dominick Samperi
> > > > Cc: William Dunlap; R-devel
> > > > Subject: Re: [Rd] Julia
> > > >
> > > > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap
> > > > > <wdunlap at tibco.com>
> > > > wrote:
> > > > > > S (and its derivatives and successors) promises that functions
> > > > > > will not change their arguments, so in an expression like
> > > > > > ? val <- func(arg)
> > > > > > you know that arg will not be changed. ?You can do that by
> > > > > > having func copy arg before doing anything, but that uses
> > > > > > space and time that you want to conserve.
> > > > > > If arg is not a named item in any environment then it should
> > > > > > be fine to write over the original because there is no way the
> > > > > > caller can detect that shortcut. ?E.g., in
> > > > > > ? ?cx <- cos(runif(n))
> > > > > > the cos function does not need to allocate new space for its
> > > > > > output, it can just write over its input because, without a
> > > > > > name attached to it, the caller has no way of looking at what
> > > > > > runif(n) returned. ?If you did
> > > > > > ? ?x <- runif(n)
> > > > > > ? ?cx <- cos(x)
> > > >
> > > > You have two names here, x and cx, hence your example does not fit
> > > > into what you want to explain.
> > > >
> > > > A better example would be:
> > > > x <- runif(n)
> > > > x <- cos(x)
> > > >
> > > >
> > > >
> > > > > > then cos would have to allocate new space for its output
> > > > > > because overwriting its input would affect a subsequent
> > > > > > ? ?sum(x)
> > > > > > I suppose that end-users and function-writers could learn to
> > > > > > live with having to decide when to copy, but not having to
> > > > > > make that decision makes S more pleasant (and safer) to use.
> > > > > > I think that is a major reason that people are able to share S
> > > > > > code so easily.
> > > > >
> > > > > But don't forget the "Holy Grail" that Doug mentioned at the
> > > > > start of this thread: finding a flexible language that is also
> > > > > fast. Currently many R packages employ C/C++ components to
> > > > > compensate for the fact that the R interpreter can be slow, and
> > > > > the pass-by-value semantics of S provides no protection here.
> > > > [...]
> > > >
> > > > The distinction imperative vs. functional has nothing to do with
> > > > the distinction interpreted vs. directly executed.
> > > >
> > > >
> > > >
> > > >
> > > > Thinking again on the problem that was mentioned here, I think it
> > > > might be circumvented.
> > > >
> > > > Looking again at R's properties, looking again into U.Ligges
> > > > "Programmieren in R", I saw there was mentioned that in R anything
> > > > (?!) is an object... so then it's OOP; but also it was mentioned,
> > > > R is a functional language. But this does not mean it's purely functional or
> has no imperative data structures.
> > > >
> > > > As R relies heavily on vectors, here we have an imperative datastructure.
> > > >
> > > > So, it rather looks to me that "<-" does work in-place on the vectors, even
> "<-"
> > > > itself is a function (which does not matter for the problem).
> > > >
> > > > If thats true (I assume here, it is; correct me, if it's wrong),
> > > > then I think, assigning with "<<-" and assign() also would do an
> > > > imperative
> > > > (in-place) change of the contents.
> > > >
> > > > Then the copying-of-big-objects-when-passed-as-args problem can be
> > > > circumvented by working on either a variable in the GlobalEnv (and
> > > > using "<<-", or using a certain environment for the big data and
> > > > passing it's name (and the
> > > > variable) as value to the function which then uses assign() and
> > > > get() to work on that data.
> > > > Then in-place modification should be possible.
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > >
> > > > > In 2008 Ross Ihaka and Duncan Temple Lang published the paper
> > > > > "Back to the Future: Lisp as a base for a statistical computing
> > > > > system" where they propose Common Lisp as a new foundation for
> > > > > R. They suggest that this could be done while maintaining the same
> familiar R syntax.
> > > > >
> > > > > A key requirement of any strategy is to maintain easy access to
> > > > > the huge universe of existing C/C++/Fortran numerical and
> > > > > graphics libraries, as these libraries are not likely to be rewritten.
> > > > >
> > > > > Thus there will always be a need for a foreign function
> > > > > interface, and the problem is to provide a flexible and
> > > > > type-safe language that does not force developers to use another
> > > > > unfamiliar, less flexible, and error-prone language to optimize the hot
> spots.
> > > >
> > > > If I here "type safe" I rather would think about OCaml or maybe
> > > > Ada, but not LISP.
> > > >
> > > > Also, LISP has so many "("'s and ")"'s, that it's making people
> > > > going crazy ;-)
> > > >
> > > > Ciao,
> > > >    Oliver
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel

From kevin.r.coombes at gmail.com  Thu Mar  8 18:27:08 2012
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Thu, 08 Mar 2012 11:27:08 -0600
Subject: [Rd] Unexpected behaviour for RowSideColors in function heatmap
In-Reply-To: <2357666E-86E2-4805-AD50-010588BE11B7@ebi.ac.uk>
References: <2357666E-86E2-4805-AD50-010588BE11B7@ebi.ac.uk>
Message-ID: <4F58EBEC.6000004@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120308/2c1217cc/attachment.pl>

From oliver at first.in-berlin.de  Thu Mar  8 23:22:52 2012
From: oliver at first.in-berlin.de (oliver)
Date: Thu, 8 Mar 2012 23:22:52 +0100
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B93284258@PA-MBX04.na.tibco.com>
References: <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
	<20120308135624.GA9947@siouxsie> <20120308153951.GA11755@siouxsie>
	<E66794E69CFDE04D9A70842786030B93284258@PA-MBX04.na.tibco.com>
Message-ID: <20120308222251.GA1839@siouxsie>

I don't think that using in-place modification as a general property would make
sense.

In-place modification brings in side-effects and that would mean that
the order of evaluation can change the result.

To get reliable results, the order of evaluation should not be
the reason for different results, and thats the reason, why
the functional approach is much better for reliable programs.

So, in general I would say, this feature is a no-no.
In general I would rather discourage in-place modification.

For some certain cases it might help...
but for such certain cases either such a boolean flag
or programming a sparate module in C would make sense.

There could also be a global in-place-flag that might be used (via options
maybe) but if such a thing would be implemented, the default value should be
FALSE.



Ciao,
   Oliver


On Thu, Mar 08, 2012 at 04:21:42PM +0000, William Dunlap wrote:
> So you propose an inplace=TRUE/FALSE entry for each
> argument to each function which may may want to avoid
> allocating memory?  The major problem is that the function
> writer has no idea what the value of inplace should be,
> as it depends on how the function gets called.  This makes
> writing reusable functions (hence packages) difficult.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> > -----Original Message-----
> > From: oliver [mailto:oliver at first.in-berlin.de]
> > Sent: Thursday, March 08, 2012 7:40 AM
> > To: William Dunlap
> > Cc: R-devel
> > Subject: Re: [Rd] Julia
> > 
> > Ah, and you mean if it's an anonymous array it could be reused directly from the
> > args.
> > 
> > OK, now I see why you insist on the anonymous data thing.
> > I didn't grasped it even in my last mail.
> > 
> > 
> > 
> > But that somehow also relates to what I wrote about reusing an already
> > existing, named vector.
> > 
> > Just the moment of in-place-modification is different.
> > 
> > From
> >   x  <- runif(n)
> >   cx <- cos(x)
> > 
> > instead of
> > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > space for the return value
> > 
> > to something like
> > 
> >   cx  <- runif(n)
> >   cos( cx, inplace=TRUE)
> > 
> > or
> > 
> >   cos( runif(n), inplace=TRUE)
> > 
> > 
> > 
> > 
> > This way it would be possible to specify the reusage of the input *explicitly*
> > (without  implicit rules like anonymous vs. named values).
> > 
> > 
> > 
> > In Pseudo-Code something like that:
> > 
> >    if (in_place == TRUE )
> >    {
> >      input_val[idx] = cos( input_val[idx] );
> >      return input_val;
> >    }
> >    else
> >    {
> >      result_val = alloc_vec( LENGTH(input_val), ... );
> >      result_val[idx] = cos( input_val[idx] );
> >      return result_val;
> >    }
> > 
> > 
> > 
> > Is this matching, what you were looking for?
> > 
> > 
> > Ciao,
> >    Oliver
> > 
> > 
> > On Thu, Mar 08, 2012 at 02:56:24PM +0100, oliver wrote:
> > > Hi,
> > >
> > > ok, thank you for clarifiying what you meant.
> > > You only referred to the reusage of the args, not of an already
> > > existing vector.
> > > So I overgenerealized your example.
> > >
> > > But when looking at your example,
> > > and how I would implement the cos()
> > > I doubt I would use copying the args
> > > before calculating the result.
> > >
> > > Just allocate a result-vector, and then place the cos() of the
> > > input-vector into the result vector.
> > >
> > > I didn't looked at how it is done in R, but I would guess it's like
> > > that.
> > >
> > >
> > >   In pseudo-Code something like that:
> > >     cos_val[idx] = cos( input_val[idx] );
> > >
> > > But R also handles complex data with cos() so it will look a bit more
> > > laborious.
> > >
> > > What I have seen so far from implementing C-extensions for R is rather
> > > C-ish, and so you have the control on many details. Copying the input
> > > just to read it would not make sense here.
> > >
> > > I doubt that R internally is doing that.
> > > Or did you found that in the R-code?
> > >
> > > The other problem, someone mentioned, was *changing* the contents of a
> > > matrix... and that this is NO>T done in-place, when using a function
> > > for it.
> > > But the namespace-name / variable-name as "references" to the matrix
> > > might solve that problem.
> > >
> > >
> > > Ciao,
> > >   Oliver
> > >
> > >
> > >
> > > On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> > > > No my examples are what I meant.  My point was that a function, say
> > > > cos(), can act like it does call-by-value but conserve memory when
> > > > it can  if it can distinguish between the case
> > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > space for the return value and and the case
> > > >    x <- runif(n)
> > > >    cx <- cos(x=x) # return value cannot reuse the argument's memory, so
> > allocate space for return value
> > > >    sum(x)              # Otherwise sum(x) would return sum(cx)
> > > > The function needs to know if a memory block is referred to by a
> > > > name in any environment in order to do that.
> > > >
> > > > Bill Dunlap
> > > > Spotfire, TIBCO Software
> > > > wdunlap tibco.com
> > > >
> > > > > -----Original Message-----
> > > > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > > > Sent: Wednesday, March 07, 2012 10:22 AM
> > > > > To: Dominick Samperi
> > > > > Cc: William Dunlap; R-devel
> > > > > Subject: Re: [Rd] Julia
> > > > >
> > > > > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > > > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap
> > > > > > <wdunlap at tibco.com>
> > > > > wrote:
> > > > > > > S (and its derivatives and successors) promises that functions
> > > > > > > will not change their arguments, so in an expression like
> > > > > > > ? val <- func(arg)
> > > > > > > you know that arg will not be changed. ?You can do that by
> > > > > > > having func copy arg before doing anything, but that uses
> > > > > > > space and time that you want to conserve.
> > > > > > > If arg is not a named item in any environment then it should
> > > > > > > be fine to write over the original because there is no way the
> > > > > > > caller can detect that shortcut. ?E.g., in
> > > > > > > ? ?cx <- cos(runif(n))
> > > > > > > the cos function does not need to allocate new space for its
> > > > > > > output, it can just write over its input because, without a
> > > > > > > name attached to it, the caller has no way of looking at what
> > > > > > > runif(n) returned. ?If you did
> > > > > > > ? ?x <- runif(n)
> > > > > > > ? ?cx <- cos(x)
> > > > >
> > > > > You have two names here, x and cx, hence your example does not fit
> > > > > into what you want to explain.
> > > > >
> > > > > A better example would be:
> > > > > x <- runif(n)
> > > > > x <- cos(x)
> > > > >
> > > > >
> > > > >
> > > > > > > then cos would have to allocate new space for its output
> > > > > > > because overwriting its input would affect a subsequent
> > > > > > > ? ?sum(x)
> > > > > > > I suppose that end-users and function-writers could learn to
> > > > > > > live with having to decide when to copy, but not having to
> > > > > > > make that decision makes S more pleasant (and safer) to use.
> > > > > > > I think that is a major reason that people are able to share S
> > > > > > > code so easily.
> > > > > >
> > > > > > But don't forget the "Holy Grail" that Doug mentioned at the
> > > > > > start of this thread: finding a flexible language that is also
> > > > > > fast. Currently many R packages employ C/C++ components to
> > > > > > compensate for the fact that the R interpreter can be slow, and
> > > > > > the pass-by-value semantics of S provides no protection here.
> > > > > [...]
> > > > >
> > > > > The distinction imperative vs. functional has nothing to do with
> > > > > the distinction interpreted vs. directly executed.
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > Thinking again on the problem that was mentioned here, I think it
> > > > > might be circumvented.
> > > > >
> > > > > Looking again at R's properties, looking again into U.Ligges
> > > > > "Programmieren in R", I saw there was mentioned that in R anything
> > > > > (?!) is an object... so then it's OOP; but also it was mentioned,
> > > > > R is a functional language. But this does not mean it's purely functional or
> > has no imperative data structures.
> > > > >
> > > > > As R relies heavily on vectors, here we have an imperative datastructure.
> > > > >
> > > > > So, it rather looks to me that "<-" does work in-place on the vectors, even
> > "<-"
> > > > > itself is a function (which does not matter for the problem).
> > > > >
> > > > > If thats true (I assume here, it is; correct me, if it's wrong),
> > > > > then I think, assigning with "<<-" and assign() also would do an
> > > > > imperative
> > > > > (in-place) change of the contents.
> > > > >
> > > > > Then the copying-of-big-objects-when-passed-as-args problem can be
> > > > > circumvented by working on either a variable in the GlobalEnv (and
> > > > > using "<<-", or using a certain environment for the big data and
> > > > > passing it's name (and the
> > > > > variable) as value to the function which then uses assign() and
> > > > > get() to work on that data.
> > > > > Then in-place modification should be possible.
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > >
> > > > > > In 2008 Ross Ihaka and Duncan Temple Lang published the paper
> > > > > > "Back to the Future: Lisp as a base for a statistical computing
> > > > > > system" where they propose Common Lisp as a new foundation for
> > > > > > R. They suggest that this could be done while maintaining the same
> > familiar R syntax.
> > > > > >
> > > > > > A key requirement of any strategy is to maintain easy access to
> > > > > > the huge universe of existing C/C++/Fortran numerical and
> > > > > > graphics libraries, as these libraries are not likely to be rewritten.
> > > > > >
> > > > > > Thus there will always be a need for a foreign function
> > > > > > interface, and the problem is to provide a flexible and
> > > > > > type-safe language that does not force developers to use another
> > > > > > unfamiliar, less flexible, and error-prone language to optimize the hot
> > spots.
> > > > >
> > > > > If I here "type safe" I rather would think about OCaml or maybe
> > > > > Ada, but not LISP.
> > > > >
> > > > > Also, LISP has so many "("'s and ")"'s, that it's making people
> > > > > going crazy ;-)
> > > > >
> > > > > Ciao,
> > > > >    Oliver
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Mar  8 23:27:22 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 8 Mar 2012 22:27:22 +0000
Subject: [Rd] Julia
In-Reply-To: <20120308222251.GA1839@siouxsie>
References: <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
	<20120308135624.GA9947@siouxsie> <20120308153951.GA11755@siouxsie>
	<E66794E69CFDE04D9A70842786030B93284258@PA-MBX04.na.tibco.com>
	<20120308222251.GA1839@siouxsie>
Message-ID: <E66794E69CFDE04D9A70842786030B93284427@PA-MBX04.na.tibco.com>

I guess my point is not getting across.  The user should see
the functional programming style but under the hood the
evaluator should be able to use whatever memory and time
saving tricks it can.  Julia seems to want to be a nonfunctional
language, which I think makes it harder to write the sort of
easily reusable functions that S allows.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: oliver [mailto:oliver at first.in-berlin.de]
> Sent: Thursday, March 08, 2012 2:23 PM
> To: William Dunlap
> Cc: R-devel
> Subject: Re: [Rd] Julia
> 
> I don't think that using in-place modification as a general property would make
> sense.
> 
> In-place modification brings in side-effects and that would mean that the order
> of evaluation can change the result.
> 
> To get reliable results, the order of evaluation should not be the reason for
> different results, and thats the reason, why the functional approach is much
> better for reliable programs.
> 
> So, in general I would say, this feature is a no-no.
> In general I would rather discourage in-place modification.
> 
> For some certain cases it might help...
> but for such certain cases either such a boolean flag or programming a sparate
> module in C would make sense.
> 
> There could also be a global in-place-flag that might be used (via options
> maybe) but if such a thing would be implemented, the default value should be
> FALSE.
> 
> 
> 
> Ciao,
>    Oliver
> 
> 
> On Thu, Mar 08, 2012 at 04:21:42PM +0000, William Dunlap wrote:
> > So you propose an inplace=TRUE/FALSE entry for each argument to each
> > function which may may want to avoid allocating memory?  The major
> > problem is that the function writer has no idea what the value of
> > inplace should be, as it depends on how the function gets called.
> > This makes writing reusable functions (hence packages) difficult.
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> > > -----Original Message-----
> > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > Sent: Thursday, March 08, 2012 7:40 AM
> > > To: William Dunlap
> > > Cc: R-devel
> > > Subject: Re: [Rd] Julia
> > >
> > > Ah, and you mean if it's an anonymous array it could be reused
> > > directly from the args.
> > >
> > > OK, now I see why you insist on the anonymous data thing.
> > > I didn't grasped it even in my last mail.
> > >
> > >
> > >
> > > But that somehow also relates to what I wrote about reusing an
> > > already existing, named vector.
> > >
> > > Just the moment of in-place-modification is different.
> > >
> > > From
> > >   x  <- runif(n)
> > >   cx <- cos(x)
> > >
> > > instead of
> > > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > > space for the return value
> > >
> > > to something like
> > >
> > >   cx  <- runif(n)
> > >   cos( cx, inplace=TRUE)
> > >
> > > or
> > >
> > >   cos( runif(n), inplace=TRUE)
> > >
> > >
> > >
> > >
> > > This way it would be possible to specify the reusage of the input
> > > *explicitly* (without  implicit rules like anonymous vs. named values).
> > >
> > >
> > >
> > > In Pseudo-Code something like that:
> > >
> > >    if (in_place == TRUE )
> > >    {
> > >      input_val[idx] = cos( input_val[idx] );
> > >      return input_val;
> > >    }
> > >    else
> > >    {
> > >      result_val = alloc_vec( LENGTH(input_val), ... );
> > >      result_val[idx] = cos( input_val[idx] );
> > >      return result_val;
> > >    }
> > >
> > >
> > >
> > > Is this matching, what you were looking for?
> > >
> > >
> > > Ciao,
> > >    Oliver
> > >
> > >
> > > On Thu, Mar 08, 2012 at 02:56:24PM +0100, oliver wrote:
> > > > Hi,
> > > >
> > > > ok, thank you for clarifiying what you meant.
> > > > You only referred to the reusage of the args, not of an already
> > > > existing vector.
> > > > So I overgenerealized your example.
> > > >
> > > > But when looking at your example,
> > > > and how I would implement the cos() I doubt I would use copying
> > > > the args before calculating the result.
> > > >
> > > > Just allocate a result-vector, and then place the cos() of the
> > > > input-vector into the result vector.
> > > >
> > > > I didn't looked at how it is done in R, but I would guess it's
> > > > like that.
> > > >
> > > >
> > > >   In pseudo-Code something like that:
> > > >     cos_val[idx] = cos( input_val[idx] );
> > > >
> > > > But R also handles complex data with cos() so it will look a bit
> > > > more laborious.
> > > >
> > > > What I have seen so far from implementing C-extensions for R is
> > > > rather C-ish, and so you have the control on many details. Copying
> > > > the input just to read it would not make sense here.
> > > >
> > > > I doubt that R internally is doing that.
> > > > Or did you found that in the R-code?
> > > >
> > > > The other problem, someone mentioned, was *changing* the contents
> > > > of a matrix... and that this is NO>T done in-place, when using a
> > > > function for it.
> > > > But the namespace-name / variable-name as "references" to the
> > > > matrix might solve that problem.
> > > >
> > > >
> > > > Ciao,
> > > >   Oliver
> > > >
> > > >
> > > >
> > > > On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> > > > > No my examples are what I meant.  My point was that a function,
> > > > > say cos(), can act like it does call-by-value but conserve
> > > > > memory when it can  if it can distinguish between the case
> > > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > > space for the return value and and the case
> > > > >    x <- runif(n)
> > > > >    cx <- cos(x=x) # return value cannot reuse the argument's
> > > > > memory, so
> > > allocate space for return value
> > > > >    sum(x)              # Otherwise sum(x) would return sum(cx)
> > > > > The function needs to know if a memory block is referred to by a
> > > > > name in any environment in order to do that.
> > > > >
> > > > > Bill Dunlap
> > > > > Spotfire, TIBCO Software
> > > > > wdunlap tibco.com
> > > > >
> > > > > > -----Original Message-----
> > > > > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > > > > Sent: Wednesday, March 07, 2012 10:22 AM
> > > > > > To: Dominick Samperi
> > > > > > Cc: William Dunlap; R-devel
> > > > > > Subject: Re: [Rd] Julia
> > > > > >
> > > > > > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > > > > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap
> > > > > > > <wdunlap at tibco.com>
> > > > > > wrote:
> > > > > > > > S (and its derivatives and successors) promises that
> > > > > > > > functions will not change their arguments, so in an
> > > > > > > > expression like
> > > > > > > > ? val <- func(arg)
> > > > > > > > you know that arg will not be changed. ?You can do that by
> > > > > > > > having func copy arg before doing anything, but that uses
> > > > > > > > space and time that you want to conserve.
> > > > > > > > If arg is not a named item in any environment then it
> > > > > > > > should be fine to write over the original because there is
> > > > > > > > no way the caller can detect that shortcut. ?E.g., in
> > > > > > > > ? ?cx <- cos(runif(n))
> > > > > > > > the cos function does not need to allocate new space for
> > > > > > > > its output, it can just write over its input because,
> > > > > > > > without a name attached to it, the caller has no way of
> > > > > > > > looking at what
> > > > > > > > runif(n) returned. ?If you did
> > > > > > > > ? ?x <- runif(n)
> > > > > > > > ? ?cx <- cos(x)
> > > > > >
> > > > > > You have two names here, x and cx, hence your example does not
> > > > > > fit into what you want to explain.
> > > > > >
> > > > > > A better example would be:
> > > > > > x <- runif(n)
> > > > > > x <- cos(x)
> > > > > >
> > > > > >
> > > > > >
> > > > > > > > then cos would have to allocate new space for its output
> > > > > > > > because overwriting its input would affect a subsequent
> > > > > > > > ? ?sum(x)
> > > > > > > > I suppose that end-users and function-writers could learn
> > > > > > > > to live with having to decide when to copy, but not having
> > > > > > > > to make that decision makes S more pleasant (and safer) to use.
> > > > > > > > I think that is a major reason that people are able to
> > > > > > > > share S code so easily.
> > > > > > >
> > > > > > > But don't forget the "Holy Grail" that Doug mentioned at the
> > > > > > > start of this thread: finding a flexible language that is
> > > > > > > also fast. Currently many R packages employ C/C++ components
> > > > > > > to compensate for the fact that the R interpreter can be
> > > > > > > slow, and the pass-by-value semantics of S provides no protection
> here.
> > > > > > [...]
> > > > > >
> > > > > > The distinction imperative vs. functional has nothing to do
> > > > > > with the distinction interpreted vs. directly executed.
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > Thinking again on the problem that was mentioned here, I think
> > > > > > it might be circumvented.
> > > > > >
> > > > > > Looking again at R's properties, looking again into U.Ligges
> > > > > > "Programmieren in R", I saw there was mentioned that in R
> > > > > > anything
> > > > > > (?!) is an object... so then it's OOP; but also it was
> > > > > > mentioned, R is a functional language. But this does not mean
> > > > > > it's purely functional or
> > > has no imperative data structures.
> > > > > >
> > > > > > As R relies heavily on vectors, here we have an imperative
> datastructure.
> > > > > >
> > > > > > So, it rather looks to me that "<-" does work in-place on the
> > > > > > vectors, even
> > > "<-"
> > > > > > itself is a function (which does not matter for the problem).
> > > > > >
> > > > > > If thats true (I assume here, it is; correct me, if it's
> > > > > > wrong), then I think, assigning with "<<-" and assign() also
> > > > > > would do an imperative
> > > > > > (in-place) change of the contents.
> > > > > >
> > > > > > Then the copying-of-big-objects-when-passed-as-args problem
> > > > > > can be circumvented by working on either a variable in the
> > > > > > GlobalEnv (and using "<<-", or using a certain environment for
> > > > > > the big data and passing it's name (and the
> > > > > > variable) as value to the function which then uses assign()
> > > > > > and
> > > > > > get() to work on that data.
> > > > > > Then in-place modification should be possible.
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > >
> > > > > > > In 2008 Ross Ihaka and Duncan Temple Lang published the
> > > > > > > paper "Back to the Future: Lisp as a base for a statistical
> > > > > > > computing system" where they propose Common Lisp as a new
> > > > > > > foundation for R. They suggest that this could be done while
> > > > > > > maintaining the same
> > > familiar R syntax.
> > > > > > >
> > > > > > > A key requirement of any strategy is to maintain easy access
> > > > > > > to the huge universe of existing C/C++/Fortran numerical and
> > > > > > > graphics libraries, as these libraries are not likely to be rewritten.
> > > > > > >
> > > > > > > Thus there will always be a need for a foreign function
> > > > > > > interface, and the problem is to provide a flexible and
> > > > > > > type-safe language that does not force developers to use
> > > > > > > another unfamiliar, less flexible, and error-prone language
> > > > > > > to optimize the hot
> > > spots.
> > > > > >
> > > > > > If I here "type safe" I rather would think about OCaml or
> > > > > > maybe Ada, but not LISP.
> > > > > >
> > > > > > Also, LISP has so many "("'s and ")"'s, that it's making
> > > > > > people going crazy ;-)
> > > > > >
> > > > > > Ciao,
> > > > > >    Oliver
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel

From oliver at first.in-berlin.de  Thu Mar  8 23:35:25 2012
From: oliver at first.in-berlin.de (oliver)
Date: Thu, 8 Mar 2012 23:35:25 +0100
Subject: [Rd] Julia
In-Reply-To: <E66794E69CFDE04D9A70842786030B93284427@PA-MBX04.na.tibco.com>
References: <20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<CADUbQ5j-d2EcaqNU1cQN3SEEheF7YB+KV0==4iu8XkQbbytCnw@mail.gmail.com>
	<20120307182139.GA5564@siouxsie>
	<E66794E69CFDE04D9A70842786030B93283D0F@PA-MBX04.na.tibco.com>
	<20120308135624.GA9947@siouxsie> <20120308153951.GA11755@siouxsie>
	<E66794E69CFDE04D9A70842786030B93284258@PA-MBX04.na.tibco.com>
	<20120308222251.GA1839@siouxsie>
	<E66794E69CFDE04D9A70842786030B93284427@PA-MBX04.na.tibco.com>
Message-ID: <20120308223525.GE1839@siouxsie>

Aha, ok.

So you not especially look at that one feature (like the anonymous
evaluation tricks), but in general want to ask for better internal optimization.

Especially with your example of the anonymous (unnamed) values given to
a function, I would ask: do you want to write programs all without
using names/variables?
I think this would be much harder than just to add a boolean flag
with inplace=TRUE.
So your reply on the flag-proposal as too much of bad usability
I need to reply with: it's even worse to write code without
variable names and put anything into anonymous datastructures,
that are called inside function application, and inside each of the arguments
there will be more of unnamed calculations.
You will end up not only with a mess, but also with slower calculations,
because unnamed ressources must be calculated more than once if they will be used
more than once.

So I think that you are just asking for more internal optimizations.
Fine.

But I think internal intermediate code (that can be optimized)
would be better than that one "enhancement" of reusing anonymous
data for the output.


Ciao,
   Oliver


On Thu, Mar 08, 2012 at 10:27:22PM +0000, William Dunlap wrote:
> I guess my point is not getting across.  The user should see
> the functional programming style but under the hood the
> evaluator should be able to use whatever memory and time
> saving tricks it can.  Julia seems to want to be a nonfunctional
> language, which I think makes it harder to write the sort of
> easily reusable functions that S allows.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: oliver [mailto:oliver at first.in-berlin.de]
> > Sent: Thursday, March 08, 2012 2:23 PM
> > To: William Dunlap
> > Cc: R-devel
> > Subject: Re: [Rd] Julia
> > 
> > I don't think that using in-place modification as a general property would make
> > sense.
> > 
> > In-place modification brings in side-effects and that would mean that the order
> > of evaluation can change the result.
> > 
> > To get reliable results, the order of evaluation should not be the reason for
> > different results, and thats the reason, why the functional approach is much
> > better for reliable programs.
> > 
> > So, in general I would say, this feature is a no-no.
> > In general I would rather discourage in-place modification.
> > 
> > For some certain cases it might help...
> > but for such certain cases either such a boolean flag or programming a sparate
> > module in C would make sense.
> > 
> > There could also be a global in-place-flag that might be used (via options
> > maybe) but if such a thing would be implemented, the default value should be
> > FALSE.
> > 
> > 
> > 
> > Ciao,
> >    Oliver
> > 
> > 
> > On Thu, Mar 08, 2012 at 04:21:42PM +0000, William Dunlap wrote:
> > > So you propose an inplace=TRUE/FALSE entry for each argument to each
> > > function which may may want to avoid allocating memory?  The major
> > > problem is that the function writer has no idea what the value of
> > > inplace should be, as it depends on how the function gets called.
> > > This makes writing reusable functions (hence packages) difficult.
> > >
> > > Bill Dunlap
> > > Spotfire, TIBCO Software
> > > wdunlap tibco.com
> > >
> > > > -----Original Message-----
> > > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > > Sent: Thursday, March 08, 2012 7:40 AM
> > > > To: William Dunlap
> > > > Cc: R-devel
> > > > Subject: Re: [Rd] Julia
> > > >
> > > > Ah, and you mean if it's an anonymous array it could be reused
> > > > directly from the args.
> > > >
> > > > OK, now I see why you insist on the anonymous data thing.
> > > > I didn't grasped it even in my last mail.
> > > >
> > > >
> > > >
> > > > But that somehow also relates to what I wrote about reusing an
> > > > already existing, named vector.
> > > >
> > > > Just the moment of in-place-modification is different.
> > > >
> > > > From
> > > >   x  <- runif(n)
> > > >   cx <- cos(x)
> > > >
> > > > instead of
> > > > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > > > space for the return value
> > > >
> > > > to something like
> > > >
> > > >   cx  <- runif(n)
> > > >   cos( cx, inplace=TRUE)
> > > >
> > > > or
> > > >
> > > >   cos( runif(n), inplace=TRUE)
> > > >
> > > >
> > > >
> > > >
> > > > This way it would be possible to specify the reusage of the input
> > > > *explicitly* (without  implicit rules like anonymous vs. named values).
> > > >
> > > >
> > > >
> > > > In Pseudo-Code something like that:
> > > >
> > > >    if (in_place == TRUE )
> > > >    {
> > > >      input_val[idx] = cos( input_val[idx] );
> > > >      return input_val;
> > > >    }
> > > >    else
> > > >    {
> > > >      result_val = alloc_vec( LENGTH(input_val), ... );
> > > >      result_val[idx] = cos( input_val[idx] );
> > > >      return result_val;
> > > >    }
> > > >
> > > >
> > > >
> > > > Is this matching, what you were looking for?
> > > >
> > > >
> > > > Ciao,
> > > >    Oliver
> > > >
> > > >
> > > > On Thu, Mar 08, 2012 at 02:56:24PM +0100, oliver wrote:
> > > > > Hi,
> > > > >
> > > > > ok, thank you for clarifiying what you meant.
> > > > > You only referred to the reusage of the args, not of an already
> > > > > existing vector.
> > > > > So I overgenerealized your example.
> > > > >
> > > > > But when looking at your example,
> > > > > and how I would implement the cos() I doubt I would use copying
> > > > > the args before calculating the result.
> > > > >
> > > > > Just allocate a result-vector, and then place the cos() of the
> > > > > input-vector into the result vector.
> > > > >
> > > > > I didn't looked at how it is done in R, but I would guess it's
> > > > > like that.
> > > > >
> > > > >
> > > > >   In pseudo-Code something like that:
> > > > >     cos_val[idx] = cos( input_val[idx] );
> > > > >
> > > > > But R also handles complex data with cos() so it will look a bit
> > > > > more laborious.
> > > > >
> > > > > What I have seen so far from implementing C-extensions for R is
> > > > > rather C-ish, and so you have the control on many details. Copying
> > > > > the input just to read it would not make sense here.
> > > > >
> > > > > I doubt that R internally is doing that.
> > > > > Or did you found that in the R-code?
> > > > >
> > > > > The other problem, someone mentioned, was *changing* the contents
> > > > > of a matrix... and that this is NO>T done in-place, when using a
> > > > > function for it.
> > > > > But the namespace-name / variable-name as "references" to the
> > > > > matrix might solve that problem.
> > > > >
> > > > >
> > > > > Ciao,
> > > > >   Oliver
> > > > >
> > > > >
> > > > >
> > > > > On Wed, Mar 07, 2012 at 07:10:43PM +0000, William Dunlap wrote:
> > > > > > No my examples are what I meant.  My point was that a function,
> > > > > > say cos(), can act like it does call-by-value but conserve
> > > > > > memory when it can  if it can distinguish between the case
> > > > > >     cx <- cos(x=runif(n)) # no allocation needed, use the input
> > > > > > space for the return value and and the case
> > > > > >    x <- runif(n)
> > > > > >    cx <- cos(x=x) # return value cannot reuse the argument's
> > > > > > memory, so
> > > > allocate space for return value
> > > > > >    sum(x)              # Otherwise sum(x) would return sum(cx)
> > > > > > The function needs to know if a memory block is referred to by a
> > > > > > name in any environment in order to do that.
> > > > > >
> > > > > > Bill Dunlap
> > > > > > Spotfire, TIBCO Software
> > > > > > wdunlap tibco.com
> > > > > >
> > > > > > > -----Original Message-----
> > > > > > > From: oliver [mailto:oliver at first.in-berlin.de]
> > > > > > > Sent: Wednesday, March 07, 2012 10:22 AM
> > > > > > > To: Dominick Samperi
> > > > > > > Cc: William Dunlap; R-devel
> > > > > > > Subject: Re: [Rd] Julia
> > > > > > >
> > > > > > > On Tue, Mar 06, 2012 at 12:49:32PM -0500, Dominick Samperi wrote:
> > > > > > > > On Tue, Mar 6, 2012 at 11:44 AM, William Dunlap
> > > > > > > > <wdunlap at tibco.com>
> > > > > > > wrote:
> > > > > > > > > S (and its derivatives and successors) promises that
> > > > > > > > > functions will not change their arguments, so in an
> > > > > > > > > expression like
> > > > > > > > > ? val <- func(arg)
> > > > > > > > > you know that arg will not be changed. ?You can do that by
> > > > > > > > > having func copy arg before doing anything, but that uses
> > > > > > > > > space and time that you want to conserve.
> > > > > > > > > If arg is not a named item in any environment then it
> > > > > > > > > should be fine to write over the original because there is
> > > > > > > > > no way the caller can detect that shortcut. ?E.g., in
> > > > > > > > > ? ?cx <- cos(runif(n))
> > > > > > > > > the cos function does not need to allocate new space for
> > > > > > > > > its output, it can just write over its input because,
> > > > > > > > > without a name attached to it, the caller has no way of
> > > > > > > > > looking at what
> > > > > > > > > runif(n) returned. ?If you did
> > > > > > > > > ? ?x <- runif(n)
> > > > > > > > > ? ?cx <- cos(x)
> > > > > > >
> > > > > > > You have two names here, x and cx, hence your example does not
> > > > > > > fit into what you want to explain.
> > > > > > >
> > > > > > > A better example would be:
> > > > > > > x <- runif(n)
> > > > > > > x <- cos(x)
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > > > then cos would have to allocate new space for its output
> > > > > > > > > because overwriting its input would affect a subsequent
> > > > > > > > > ? ?sum(x)
> > > > > > > > > I suppose that end-users and function-writers could learn
> > > > > > > > > to live with having to decide when to copy, but not having
> > > > > > > > > to make that decision makes S more pleasant (and safer) to use.
> > > > > > > > > I think that is a major reason that people are able to
> > > > > > > > > share S code so easily.
> > > > > > > >
> > > > > > > > But don't forget the "Holy Grail" that Doug mentioned at the
> > > > > > > > start of this thread: finding a flexible language that is
> > > > > > > > also fast. Currently many R packages employ C/C++ components
> > > > > > > > to compensate for the fact that the R interpreter can be
> > > > > > > > slow, and the pass-by-value semantics of S provides no protection
> > here.
> > > > > > > [...]
> > > > > > >
> > > > > > > The distinction imperative vs. functional has nothing to do
> > > > > > > with the distinction interpreted vs. directly executed.
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > Thinking again on the problem that was mentioned here, I think
> > > > > > > it might be circumvented.
> > > > > > >
> > > > > > > Looking again at R's properties, looking again into U.Ligges
> > > > > > > "Programmieren in R", I saw there was mentioned that in R
> > > > > > > anything
> > > > > > > (?!) is an object... so then it's OOP; but also it was
> > > > > > > mentioned, R is a functional language. But this does not mean
> > > > > > > it's purely functional or
> > > > has no imperative data structures.
> > > > > > >
> > > > > > > As R relies heavily on vectors, here we have an imperative
> > datastructure.
> > > > > > >
> > > > > > > So, it rather looks to me that "<-" does work in-place on the
> > > > > > > vectors, even
> > > > "<-"
> > > > > > > itself is a function (which does not matter for the problem).
> > > > > > >
> > > > > > > If thats true (I assume here, it is; correct me, if it's
> > > > > > > wrong), then I think, assigning with "<<-" and assign() also
> > > > > > > would do an imperative
> > > > > > > (in-place) change of the contents.
> > > > > > >
> > > > > > > Then the copying-of-big-objects-when-passed-as-args problem
> > > > > > > can be circumvented by working on either a variable in the
> > > > > > > GlobalEnv (and using "<<-", or using a certain environment for
> > > > > > > the big data and passing it's name (and the
> > > > > > > variable) as value to the function which then uses assign()
> > > > > > > and
> > > > > > > get() to work on that data.
> > > > > > > Then in-place modification should be possible.
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > >
> > > > > > > > In 2008 Ross Ihaka and Duncan Temple Lang published the
> > > > > > > > paper "Back to the Future: Lisp as a base for a statistical
> > > > > > > > computing system" where they propose Common Lisp as a new
> > > > > > > > foundation for R. They suggest that this could be done while
> > > > > > > > maintaining the same
> > > > familiar R syntax.
> > > > > > > >
> > > > > > > > A key requirement of any strategy is to maintain easy access
> > > > > > > > to the huge universe of existing C/C++/Fortran numerical and
> > > > > > > > graphics libraries, as these libraries are not likely to be rewritten.
> > > > > > > >
> > > > > > > > Thus there will always be a need for a foreign function
> > > > > > > > interface, and the problem is to provide a flexible and
> > > > > > > > type-safe language that does not force developers to use
> > > > > > > > another unfamiliar, less flexible, and error-prone language
> > > > > > > > to optimize the hot
> > > > spots.
> > > > > > >
> > > > > > > If I here "type safe" I rather would think about OCaml or
> > > > > > > maybe Ada, but not LISP.
> > > > > > >
> > > > > > > Also, LISP has so many "("'s and ")"'s, that it's making
> > > > > > > people going crazy ;-)
> > > > > > >
> > > > > > > Ciao,
> > > > > > >    Oliver
> > > > >
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Fri Mar  9 00:41:45 2012
From: jmc at r-project.org (John Chambers)
Date: Thu, 08 Mar 2012 15:41:45 -0800
Subject: [Rd] isGeneric() can return an error
In-Reply-To: <4F57EFAB.8010709@fhcrc.org>
References: <4F57EFAB.8010709@fhcrc.org>
Message-ID: <4F5943B9.5030401@r-project.org>

Bug.  Should be fixed (rev 58642) in r-devel and R 2.15.0 alpha.

Thanks.

On 3/7/12 3:30 PM, Herv? Pag?s wrote:
> Hi,
>
> I wonder if this is a feature or a bug:
>
> > isGeneric("&&")
>   Error in genericForPrimitive(f) :
>     methods may not be defined for primitive function ?&&? in this 
> version of R
> > isGeneric(":")
>   Error in genericForPrimitive(f) :
>     methods may not be defined for primitive function ?:? in this 
> version of R
>
> According to the man page:
>
>      ?isGeneric?: Is there a function named ?f?, and if so, is it a
>           generic?
>
> So it sounds like it should be a YES or NO answer.
>
> In any case the error message is confusing: it suggests that I'm trying
> to define methods for "&&", but I'm not.
>
> This is with R 2.13, R 2.14 and R 2.15.0 alpha.
>
> Thanks,
> H.
>


From hb at biostat.ucsf.edu  Fri Mar  9 06:09:20 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 8 Mar 2012 21:09:20 -0800
Subject: [Rd] .conflicts.OK no longer working regardless of
 export(.conflicts.OK) due to "stoplist"
Message-ID: <CAFDcVCR8WjAHA_vOEM9NAWSd+uUJ4wc5tTS2D0Wy-SZO5RKWJA@mail.gmail.com>

Hi,

in (at least) R v2.14.2 and R v2.15.0 alpha, '.conflicts.OK' is not
exported and hence to seen by library().

DETAILS:
In R-devel thread '[Rd] Suggestion: Not having to export .conflicts.OK
in name spaces' on Mar 17-22, 2010
[https://stat.ethz.ch/pipermail/r-devel/2010-March/057017.html] it was
discussed that one had to export '.conflicts.OK' in the namespace,
otherwise it would not be found in the internal conflict test of
library(), cf. print(base::library):

...
if(warn.conflicts &&
                       !exists(".conflicts.OK", envir = env, inherits = FALSE))
                        checkConflicts(package, pkgname, pkgpath,
                                       nogenerics, ns)
...

By replacing envir=env with envir=ns, it will be found.  Here is what
I get if I use debug(library):

Browse[2]> exists(".conflicts.OK", envir=env, inherits=FALSE)
[1] FALSE
Browse[2]> exists(".conflicts.OK", envir=ns, inherits=FALSE)
[1] TRUE


This was never implemented, but export(.conflicts.OK) do the job.  So
far so good, but in rev 56711 (Aug 12, 2011) the following piece of
code was added to loadNamespace() [src/library/base/R/library.R],
which drops '.conflicts.OK' regardless:

        ## process exports, seal, and clear on.exit action
        exports <- nsInfo$exports

        for (p in nsInfo$exportPatterns)
            exports <- c(ls(env, pattern = p, all.names = TRUE), exports)
        ## certain things should never be exported.
        if (length(exports)) {
            stoplist <- c(".__NAMESPACE__.", ".__S3MethodsTable__.",
                          ".packageName", ".First.lib", ".onLoad",
                          ".onAttach", ".conflicts.OK", ".noGenerics")
            exports <- exports[! exports %in% stoplist]
        }


To confirm this is the problem one can load the package with
debug(loadNamespace), step through the function and after the above
"stoplist" filtering append '.conflicts.OK', e.g. exports <-
c(exports, ".conflicts.OK"), and '.conflicts.OK' is yet again visible
to library().

SOLUTION:
Thus, I propose to do the above 'envir=env' to 'envir=ns' update in
library() to fix this.

/Henrik

> sessionInfo()
R version 2.14.2 Patched (2012-02-29 r58590)
Platform: x86_64-pc-mingw32/x64 (64-bit)

> sessionInfo()
R version 2.15.0 alpha (2012-03-07 r58630)
Platform: x86_64-pc-mingw32/x64 (64-bit)


From hpages at fhcrc.org  Fri Mar  9 06:31:46 2012
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 08 Mar 2012 21:31:46 -0800
Subject: [Rd] isGeneric() can return an error
In-Reply-To: <4F5943B9.5030401@r-project.org>
References: <4F57EFAB.8010709@fhcrc.org> <4F5943B9.5030401@r-project.org>
Message-ID: <4F5995C2.3030403@fhcrc.org>

On 03/08/2012 03:41 PM, John Chambers wrote:
> Bug. Should be fixed (rev 58642) in r-devel and R 2.15.0 alpha.

Thank you.

H.

>
> Thanks.
>
> On 3/7/12 3:30 PM, Herv? Pag?s wrote:
>> Hi,
>>
>> I wonder if this is a feature or a bug:
>>
>> > isGeneric("&&")
>> Error in genericForPrimitive(f) :
>> methods may not be defined for primitive function ?&&? in this version
>> of R
>> > isGeneric(":")
>> Error in genericForPrimitive(f) :
>> methods may not be defined for primitive function ?:? in this version
>> of R
>>
>> According to the man page:
>>
>> ?isGeneric?: Is there a function named ?f?, and if so, is it a
>> generic?
>>
>> So it sounds like it should be a YES or NO answer.
>>
>> In any case the error message is confusing: it suggests that I'm trying
>> to define methods for "&&", but I'm not.
>>
>> This is with R 2.13, R 2.14 and R 2.15.0 alpha.
>>
>> Thanks,
>> H.
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jtalbot at cs.stanford.edu  Thu Mar  8 20:06:25 2012
From: jtalbot at cs.stanford.edu (Justin Talbot)
Date: Thu, 8 Mar 2012 11:06:25 -0800
Subject: [Rd] On R performance
Message-ID: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>

I've been working on an R performance academic project for the last
couple years which has involved writing an interpreter for R from
scratch and a JIT for R vector operations.

With the recent comments on Julia, I thought I'd share some thoughts
from my experience since they differ substantially from the common
speculation on R performance.

I went into the project thinking that R would be slow for the commonly
cited reasons: NAs, call-by-value, immutable values, ability to
dynamically add/remove variables from environments, etc. But this is
largely *not* true. It does require being somewhat clever, but most of
the cost of these features can be either eliminated or moved to
uncommon cases that won't affect most code. And there's plenty of room
for innovation here. The history of Javascript runtimes over the last
decade has shown that dramatic performance improvements are possible
even for difficult languages.

This is good news. I think we can keep essentially everything that
people like about R and still achieve great performance.

So why is R performance poor now? I think the fundamental reason is
related to software engineering: R is nearly impossible to experiment
with, so no one tries out new performance techniques on it. There are
two main issues here:

1) The R Language Definition doesn't get enough love. I could point
out plenty of specific problems, omissions, etc., but I think the
high-level problem is that the Language Definition currently conflates
three things: 1) the actual language definition, 2) the definition of
what is more properly the standard library, and 3) the implementation.
This conflation hides how simple the R/S language actually is and, by
assuming that the current implementation is the only implementation,
obscures performance improvements that could be made by changing the
implementation.

2) The R core implementation (e.g. everything in src/main) is too big.
There are ~900 functions listed in names.c. This has got to be simply
unmanageable. If one were to change the SEXP representation, how many
internal functions would have to be checked and updated? This is a
severe hinderance on improving performance.

I see little value is debating changes to the language semantics until
we've addressed this low hanging fruit and at least tried to make the
current R/S semantics run fast.

Justin


From taltman at AI.SRI.COM  Fri Mar  9 07:13:51 2012
From: taltman at AI.SRI.COM (Tomer Altman)
Date: Thu, 08 Mar 2012 22:13:51 -0800
Subject: [Rd] How to get R to connect to a Unix domain (AF_LOCAL or AF_UNIX)
	socket?
Message-ID: <4F599F9F.7080407@ai.sri.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120308/39d4ae19/attachment.pl>

From engstrom at ebi.ac.uk  Fri Mar  9 11:02:46 2012
From: engstrom at ebi.ac.uk (=?iso-8859-1?Q?P=E4r_Engstr=F6m?=)
Date: Fri, 9 Mar 2012 10:02:46 +0000
Subject: [Rd] Unexpected behaviour for RowSideColors in function heatmap
In-Reply-To: <4F58EBEC.6000004@gmail.com>
References: <2357666E-86E2-4805-AD50-010588BE11B7@ebi.ac.uk>
	<4F58EBEC.6000004@gmail.com>
Message-ID: <0ADEEA73-BA4E-46FA-9891-589B7B644389@ebi.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120309/76e24f9e/attachment.pl>

From djsamperi at gmail.com  Fri Mar  9 16:11:23 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 9 Mar 2012 10:11:23 -0500
Subject: [Rd] On R performance
In-Reply-To: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
Message-ID: <CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>

On Thu, Mar 8, 2012 at 2:06 PM, Justin Talbot <jtalbot at cs.stanford.edu> wrote:
> I've been working on an R performance academic project for the last
> couple years which has involved writing an interpreter for R from
> scratch and a JIT for R vector operations.
>
> With the recent comments on Julia, I thought I'd share some thoughts
> from my experience since they differ substantially from the common
> speculation on R performance.
>
> I went into the project thinking that R would be slow for the commonly
> cited reasons: NAs, call-by-value, immutable values, ability to
> dynamically add/remove variables from environments, etc. But this is
> largely *not* true. It does require being somewhat clever, but most of
> the cost of these features can be either eliminated or moved to
> uncommon cases that won't affect most code. And there's plenty of room
> for innovation here. The history of Javascript runtimes over the last
> decade has shown that dramatic performance improvements are possible
> even for difficult languages.
>
> This is good news. I think we can keep essentially everything that
> people like about R and still achieve great performance.
>
> So why is R performance poor now? I think the fundamental reason is
> related to software engineering: R is nearly impossible to experiment
> with, so no one tries out new performance techniques on it. There are
> two main issues here:
>
> 1) The R Language Definition doesn't get enough love. I could point
> out plenty of specific problems, omissions, etc., but I think the
> high-level problem is that the Language Definition currently conflates
> three things: 1) the actual language definition, 2) the definition of
> what is more properly the standard library, and 3) the implementation.
> This conflation hides how simple the R/S language actually is and, by
> assuming that the current implementation is the only implementation,
> obscures performance improvements that could be made by changing the
> implementation.
>
> 2) The R core implementation (e.g. everything in src/main) is too big.
> There are ~900 functions listed in names.c. This has got to be simply
> unmanageable. If one were to change the SEXP representation, how many
> internal functions would have to be checked and updated? This is a
> severe hinderance on improving performance.
>
> I see little value is debating changes to the language semantics until
> we've addressed this low hanging fruit and at least tried to make the
> current R/S semantics run fast.

Isn't R much like Lisp under the covers? Afterall, it evolved from Scheme.
Hasn't there been a great deal of work done on optimizing Lisp over the
last 30 years? This suggests that instead of dropping the R/S semantics
and moving to another language like Julia, the proposals of Ross Ihaka
and Duncan Temple Lang could be followed to provide the familiar
R/S syntax on top of an optimized Lisp engine.

One could view the R language as "syntactic sugar" for Lisp and focus
on optimizing the Lisp engine, in the same way that functional languages
are viewed as syntactic sugar for the lambda calculus.

Another possibility is to implement R/S on top of an optimized virtual
machine like the JVM, LLVM, etc.

Of course, no matter what strategy is followed a foreign function
interface will be very important to leverage the existing base of
C/C++/Fortran numerical and graphics libs.

Dominick

> Justin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Mar  9 16:28:30 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 9 Mar 2012 09:28:30 -0600
Subject: [Rd] On R performance
In-Reply-To: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
Message-ID: <20314.8606.455627.984097@max.nulle.part>


Justin,

On 8 March 2012 at 11:06, Justin Talbot wrote:
| I've been working on an R performance academic project for the last
| couple years which has involved writing an interpreter for R from
| scratch and a JIT for R vector operations.

Cool.  I think John mention that once or twice and I promptly forgot. 

Can you share some numbers?
 
| So why is R performance poor now? I think the fundamental reason is
| related to software engineering: R is nearly impossible to experiment
| with, so no one tries out new performance techniques on it. There are

Did you compare notes with the CXXR project by Andrew Runnalls and his
student(s)?  See http://www.cs.kent.ac.uk/projects/cxxr/

| I see little value is debating changes to the language semantics until
| we've addressed this low hanging fruit and at least tried to make the
| current R/S semantics run fast.

Fully agree.  

I'd add that helping expand R via the FFI also works, though it is of course
not as easy on the end user as making the core faster.

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From diedrich at math.uni-potsdam.de  Fri Mar  9 16:09:28 2012
From: diedrich at math.uni-potsdam.de (Holger Diedrich)
Date: Fri, 09 Mar 2012 16:09:28 +0100
Subject: [Rd] Eigenvalue calculation of sparse matrices
Message-ID: <4F5A1D28.7090502@math.uni-potsdam.de>

Dear all,

I am currently working on the calculation of eigenvalues (and -vectors) 
of large matrices. Since these are mostly sparse matrices and I remember 
some specific functionalities in MATLAB for sparse matrices, I started a 
research how to optimize the calculation of eigenvalues of a sparse matrix.
The function eigen itself works with the LAPACK library which has no 
special handling for sparse matrices, same for the EISPACK library. The 
ARPACK library is capable to work with sparse matrices but I couldn't 
find any useful R package using ARPACK.
The Matrix package can handle sparse matrices but has no further useful 
functionalities (concerning my tasks).

Does one of you have any advice how to optimize the eigenvalue 
calculation of sparse matrices in R?

Thanks in advance,
Holger


From jtalbot at cs.stanford.edu  Fri Mar  9 17:39:34 2012
From: jtalbot at cs.stanford.edu (Justin Talbot)
Date: Fri, 9 Mar 2012 08:39:34 -0800
Subject: [Rd] On R performance
In-Reply-To: <CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
	<CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>
Message-ID: <CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>

>
> Isn't R much like Lisp under the covers? Afterall, it evolved from Scheme.
> Hasn't there been a great deal of work done on optimizing Lisp over the
> last 30 years? This suggests that instead of dropping the R/S semantics
> and moving to another language like Julia, the proposals of Ross Ihaka
> and Duncan Temple Lang could be followed to provide the familiar
> R/S syntax on top of an optimized Lisp engine.
>

I think R started off as a Lisp-like language, but since adopting S
semantics, it has diverged quite a ways. I think it's better to think
of R as a combination of two languages: a dynamically-typed high-level
language, much like Javascript or Lua, and an array language, like
APL. I think those are the right places to be looking to see how to
make R fast. Fortunately, all three of those languages have had a lot
of performance work done already that R could just steal from
wholesale.

> Another possibility is to implement R/S on top of an optimized virtual
> machine like the JVM, LLVM, etc.
>

I like this in theory. But in practice, I'm not sure how well it would
work for R. JVM implementations of dynamic languages, like JRuby and
Jython run marginally faster (30-40%) than their C interpreters. You
do get the Java ecosystem, which is nice, but the performance
improvements probably aren't enough to make it worthwhile. And, of
course, R already has a pretty good Java connection story.

LLVM is a better option; I know there's another group out there
looking at R on LLVM. But I'll just note that the really high
performance dynamic languages (e.g. Google's V8 implementation of
Javascript and Mike Pall's LuaJIT) are hand-rolled JITs. LLVM-based
implementations of dynamic languages, like Unladen Swallow, have not
been particularly successful. It remains to be seen how well R would
map to LLVM.

Justin


From jtalbot at cs.stanford.edu  Fri Mar  9 19:06:54 2012
From: jtalbot at cs.stanford.edu (Justin Talbot)
Date: Fri, 9 Mar 2012 10:06:54 -0800
Subject: [Rd] On R performance
In-Reply-To: <20314.8606.455627.984097@max.nulle.part>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
	<20314.8606.455627.984097@max.nulle.part>
Message-ID: <CALLn38OL3zBHeOOizxXnyuEAdTxYVmFzpdk0jhBmZe7xjtnN3Q@mail.gmail.com>

>
> On 8 March 2012 at 11:06, Justin Talbot wrote:
> | I've been working on an R performance academic project for the last
> | couple years which has involved writing an interpreter for R from
> | scratch and a JIT for R vector operations.
>
> Cool. ?I think John mention that once or twice and I promptly forgot.
>
> Can you share some numbers?
>

Sure, I'll give a quick summary. We're writing a paper on it right now
which will have more details.

We currently execute scalar R code (non-vectorized) through an
interpreter we wrote from scratch. We haven't put a whole lot of time
into it; it supports most of the important R semantics, but does not
yet implement most of the functions in src/names.c, which limits the
scope of real world code we can run. On a set of microbenchmarks
(careful what you conclude from microbenchmarks!) it runs about 4-5x
faster than Luke's bytecode interpreter.

The interpreter is still about 3-4x slower than LuaJIT's interpreter,
probably the fastest dynamic language interpreter out there, so there
is room for further improvement, but not a lot. (Lua is a much cleaner
language from the performance standpoint and LuaJIT's interpreter is
written in assembly. We don't anticipate doing that anytime soon.)

We execute vectorized code through a JIT that generates SSE code and
can parallelize across multiple cores. Performance here depends
greatly on the vector size and number of vectors since our performance
gain primarily comes from eliminating memory accesses. For long
vectors (1M+ elements) we've seen gains from about 5x-50x on a single
core for plausible workloads. We don't have good numbers on the
parallelization yet, but we have seen linear scalability out to 32
cores for a couple of our workloads. Scalability is clearly very task
dependent and we don't expect to get large numbers across the board.

One implication of having a JIT is that we now implement a lot of
functionality at the R level rather than in C functions. For example,
we implement matrix-vector multiplication as:

r <- 0
for(i in 1L:ncol(m)) {
   r <- r + m[,i]*v[[i]]
}

This beats R's built-in matrix-vector multiplication by a factor of 2
for "large" matrices (at least one dimension larger than 1000 or so)
and will parallelize without any more work from the programmer. With
more work to squeeze out our JIT overheads this could be effective
even for much smaller matrices.


> | So why is R performance poor now? I think the fundamental reason is
> | related to software engineering: R is nearly impossible to experiment
> | with, so no one tries out new performance techniques on it. There are
>
> Did you compare notes with the CXXR project by Andrew Runnalls and his
> student(s)? ?See http://www.cs.kent.ac.uk/projects/cxxr/
>

I haven't talked to them, but I should! Looking at their slides it
looks like their approach will be effective at making the R core more
extensible, but it's somewhat antagonistic to pure interpreter
performance. I didn't see any performance numbers, but I would guess
that CXXR runs somewhat slower than the current interpreter.

The key for being able to experiment with performance is for the core
code to be small and well defined, not necessarily extensible.

> | I see little value is debating changes to the language semantics until
> | we've addressed this low hanging fruit and at least tried to make the
> | current R/S semantics run fast.
>
> Fully agree.
>
> I'd add that helping expand R via the FFI also works, though it is of course
> not as easy on the end user as making the core faster.
>

FFI is extremely important and Rcpp is a great step forward. I'll just
note that FFI and performance interact. An FFI like .Call/.External
exposes too much of R's internal implementation details to users,
making it difficult to improve performance in the core while
maintaining backwards compatibility. It would be much better if R's
high-performance FFI were something like Rcpp itself, hiding almost
all implementation details from the user.

Just one example on FFIs. .Call/.External lets users get raw pointers
to vector data (e.g. NUMERIC_POINTER). This is fine and dandy as long
as all implementations store vectors contiguously in memory. But, some
implementations may not want this. For example, Clojure gets
high-performance updates to its immutable arrays by storing them in a
tree data structure instead of flat in memory. This would be a nice
technique to port to R, but it breaks .Call packages. A better FFI
choice would have used something like NUMERIC_ELEMENT(x,i) to hide the
details of how element i is looked up in vector x. This would have
been just as fast for current packages while leaving a forward path
for more performance improvements.

Justin

Justin


From djsamperi at gmail.com  Sat Mar 10 15:41:36 2012
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sat, 10 Mar 2012 09:41:36 -0500
Subject: [Rd] On R performance
In-Reply-To: <CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
	<CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>
	<CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>
Message-ID: <CADUbQ5iN7V78+Eo1fQRRPGeoAFt991sDjdM590U3xtr-PF7YdA@mail.gmail.com>

On Fri, Mar 9, 2012 at 11:39 AM, Justin Talbot <jtalbot at cs.stanford.edu> wrote:
>>
>> Isn't R much like Lisp under the covers? Afterall, it evolved from Scheme.
>> Hasn't there been a great deal of work done on optimizing Lisp over the
>> last 30 years? This suggests that instead of dropping the R/S semantics
>> and moving to another language like Julia, the proposals of Ross Ihaka
>> and Duncan Temple Lang could be followed to provide the familiar
>> R/S syntax on top of an optimized Lisp engine.
>>
>
> I think R started off as a Lisp-like language, but since adopting S
> semantics, it has diverged quite a ways. I think it's better to think
> of R as a combination of two languages: a dynamically-typed high-level
> language, much like Javascript or Lua, and an array language, like
> APL. I think those are the right places to be looking to see how to
> make R fast. Fortunately, all three of those languages have had a lot
> of performance work done already that R could just steal from
> wholesale.

Thanks for the clarification Justin. What about the S4 classes
and methods? The design resembles CLOS, and currently this
is interpreted R code. Have you addressed performance issues
associated with this? What relative impact does this have compared
with other optimizations like vectorization?

Thanks,
Dominick

>> Another possibility is to implement R/S on top of an optimized virtual
>> machine like the JVM, LLVM, etc.
>>
>
> I like this in theory. But in practice, I'm not sure how well it would
> work for R. JVM implementations of dynamic languages, like JRuby and
> Jython run marginally faster (30-40%) than their C interpreters. You
> do get the Java ecosystem, which is nice, but the performance
> improvements probably aren't enough to make it worthwhile. And, of
> course, R already has a pretty good Java connection story.
>
> LLVM is a better option; I know there's another group out there
> looking at R on LLVM. But I'll just note that the really high
> performance dynamic languages (e.g. Google's V8 implementation of
> Javascript and Mike Pall's LuaJIT) are hand-rolled JITs. LLVM-based
> implementations of dynamic languages, like Unladen Swallow, have not
> been particularly successful. It remains to be seen how well R would
> map to LLVM.
>
> Justin


From Achim.Zeileis at uibk.ac.at  Sat Mar 10 16:36:04 2012
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 10 Mar 2012 16:36:04 +0100 (CET)
Subject: [Rd] Task View on Numerical Analysis and Differential Equations
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3199D4A@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <CAML4n3PA-mdFTRxboys01Ze5YA-n6dyPtSnni8j9eHTcfacyOQ@mail.gmail.com>
	<C0F764D2-2D6F-486F-8612-09C781B02E73@xs4all.nl>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3199D4A@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <alpine.DEB.2.02.1203101624240.21598@paninaro.uibk.ac.at>

Hans,

thanks for the suggestion and sorry for coming so late to the thread. I 
have only a little to add to Ravi's comments.

> I like the idea overall.  Nothing prevents you from doing this, but you 
> should be committed to getting it up and running and then keeping it 
> updated.

Yes completely d'accord with all comments.

If you want to put together a .ctv, please have a look at

vignette("ctv-howto", package = "ctv")

and send me the resulting .ctv.

> In addition to concurring with Berend's comments, I also would like to 
> mention that numerical analysis (NA) is an extremely broad category.  I 
> am not sure how to restrict that in order to make the taskview 
> manageable.

I also completely agree with this. I'm not sure what the best way to focus 
the task view is. Maybe differential equations should be in a separate 
(relatively small) view? The experience is that very large task views 
become harder to maintain in the future because the number of packages 
will grow over time.

In any case, I look forward to seeing a new task view.
Thanks & best regards,
Z

> How about including (i) convergence acceleration of sequences, (ii) 
> fourier transforms/wavelets, (iii) function approximation and special 
> functions of mathematical physics?
>
> Best regards,
> Ravi
>
> P.S. I have a package called "eiginv" for solving certain types of inverse eigenvalue problems (e.g., generating a matrix of a specific structure with a given set of eigenvalues)
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Berend Hasselman
> Sent: Thursday, March 08, 2012 9:59 AM
> To: Hans W Borchers
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Task View on Numerical Analysis and Differential Equations
>
>
> On 08-03-2012, at 12:16, Hans W Borchers wrote:
>
>> I am wondering if it would be time to have a new Task View, this time
>> for the subject of "Numerical Analysis and Differential Equations".
>> The list of packages possibly appearing in such a task view is already
>> quite long and could, for example, include:
>>
>> Numerical Analysis and Linear Algebra
>>
>> Bessel        Bessel Functions Computations and Approximations
>> cubature      Adaptive multivariate integration over hypercubes
>> elliptic      Elliptic and related functions
>> expm          Matrix exponential, logarithm, etc.
>> fdim	      Functions for calculating fractal dimension
>> gaussquad     Collection of functions for Gaussian quadrature
>> gmp           Multiple precision arithmetic
>> gsl           Wrapper for the Gnu Scientific Library
>> hypergeo      The hypergeometric function
>> irlba         Fast partial SVD by Lanczos bidiagonalization
>> matlab        MATLAB emulation package
>> multipol      Multivariate polynomials
>> numDeriv      Accurate numerical derivatives
>> onion         Octonions and quaternions
>> orthogonalsplinebasis  Orthogonal Bspline basis functions orthopolynom
>> Functions for orthogonal and orthonormal polynomials
>> polspline     Polynomial spline routines
>> polynom       Implement a class for univariate polynomial manipulations
>> PolynomF      Polynomials in R
>> pracma        Practical numerical math functions
>> pspline       Penalized smoothing splines
>> quaternions   Arithmetics and linear algebra with quaternions
>> R2Cuba        Multidimensional numerical integration
>> RcppArmadillo Rcpp integration for Armadillo templated linear algebra library
>> RcppEigen	  Rcpp integration for the Eigen templated linear algebra library
>> RcppOctave    Rcpp integration of Octave
>> R.matlab	  Read and write of MAT files and R-to-Matlab connectivity
>> Rmpfr	      Multiple precision floating-point reliable
>> sparseGrid    Sparse grid integration in R
>> spuRs         Functions and datasets scientific programming and simulation
>> sspline       Smoothing splines on the sphere
>> stinepack     Stineman: consistently well behaved method of interpolation
>> svd           Interfaces to various state-of-art SVD and eigensolvers
>> voronoi       Methods and applications related to Voronoi tessellations
>> wavelets...
>>
>> Simulation and Differential Equations
>>
>> bvpSolve	  Solvers for boundary value problems of ODEs
>> ddesolve      Solver for Delay Differential Equations
>> deSolve       General solvers for initial value problems of ordinary
>>              differential equations (ODE), partial differential equations
>>              (PDE), differential algebraic equations (DAE), and delay
>>              differential equations (DDE)
>> deTestSet	  Testset for differential equations
>> odesolve	  Solvers for Ordinary Differential Equations
>> PBSddesolve	  Solver for Delay Differential Equations
>> rootSolve     Root finding, equilibrium and steady-state analysis of ODEs
>> sde           Simulation and Inference for Stochastic Differential Equations
>> Sim.DiffProc  Simulation of diffusion processes
>> simecol       Simulation of ecological and other dynamic systems
>>
>> and probably many more in the end. I left out the optimization
>> packages deliberately, but of course there would be a strong hint to
>> that task view.
>
>
> If you put pracma in "Numerical Analysis and Linear Algebra", then I feel you should also include  BB and nleqslv under that heading. Both of these do things that can be classified as Numerical Analysis. And both can of course also be used for simulation.
>
>
> BB  solve  (sparse) systems of non linear equations using spectral gradient methods nleqslv solve systems of nonlinear equations combining global strategies with a Broyden or Newron method.
>
> Berend
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From kjetilbrinchmannhalvorsen at gmail.com  Sun Mar 11 00:02:29 2012
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Sat, 10 Mar 2012 17:02:29 -0600
Subject: [Rd] Eigenvalue calculation of sparse matrices
In-Reply-To: <4F5A1D28.7090502@math.uni-potsdam.de>
References: <4F5A1D28.7090502@math.uni-potsdam.de>
Message-ID: <CACU_Y088GO6skOu3x5=HGO-ZgA6FuAAjsyO-BrY6iOt_ORfmtQ@mail.gmail.com>

Hola!

This can be done with the CRAN package igraph, which contains (part
of) the arpack
library for computing only some eigenvalues/eigenvectors of sparse
matrices. arpack gives you the option of computing a few of the
smallest or a few of the largest eigenvalues/vectors.

You will need yourself to wrte a function doing matrix-vector
multiplication, so the arpack
methods itself is independent of the implementation of your sparse matrix.

Kjetil

On Fri, Mar 9, 2012 at 9:09 AM, Holger Diedrich
<diedrich at math.uni-potsdam.de> wrote:
> Dear all,
>
> I am currently working on the calculation of eigenvalues (and -vectors) of
> large matrices. Since these are mostly sparse matrices and I remember some
> specific functionalities in MATLAB for sparse matrices, I started a research
> how to optimize the calculation of eigenvalues of a sparse matrix.
> The function eigen itself works with the LAPACK library which has no special
> handling for sparse matrices, same for the EISPACK library. The ARPACK
> library is capable to work with sparse matrices but I couldn't find any
> useful R package using ARPACK.
> The Matrix package can handle sparse matrices but has no further useful
> functionalities (concerning my tasks).
>
> Does one of you have any advice how to optimize the eigenvalue calculation
> of sparse matrices in R?
>
> Thanks in advance,
> Holger
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From antonio at piccolboni.info  Sat Mar 10 16:29:16 2012
From: antonio at piccolboni.info (Antonio Piccolboni)
Date: Sat, 10 Mar 2012 07:29:16 -0800
Subject: [Rd] On R performance
In-Reply-To: <CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
	<CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>
	<CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>
Message-ID: <CA+VDHFWK22opG3Oi4DpJn_nehkNZC8xW2nQHJ5RKmCnU5Kq0iA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120310/60c885e5/attachment.pl>

From jtalbot at cs.stanford.edu  Sat Mar 10 16:39:44 2012
From: jtalbot at cs.stanford.edu (Justin Talbot)
Date: Sat, 10 Mar 2012 07:39:44 -0800
Subject: [Rd] On R performance
In-Reply-To: <CADUbQ5iN7V78+Eo1fQRRPGeoAFt991sDjdM590U3xtr-PF7YdA@mail.gmail.com>
References: <CALLn38PjixLnWw=uBwB-5QYDEa=tLNahuSnap_A_oQQ_=qS4TA@mail.gmail.com>
	<CADUbQ5jZEM1bV+xBdjgF8HxOTM7SGy3zkvefZZ4nKWQGVwQNtw@mail.gmail.com>
	<CALLn38Pmn8ZTYCc17R0QVjjLsQzo0jJOLinjZFzkhRhvDRVWwg@mail.gmail.com>
	<CADUbQ5iN7V78+Eo1fQRRPGeoAFt991sDjdM590U3xtr-PF7YdA@mail.gmail.com>
Message-ID: <CALLn38OEgxTYvzuiPw=9D+1t9rKu26MKdBv2F5jBzpuAYC+tVQ@mail.gmail.com>

>
> Thanks for the clarification Justin. What about the S4 classes
> and methods? The design resembles CLOS, and currently this
> is interpreted R code. Have you addressed performance issues
> associated with this? What relative impact does this have compared
> with other optimizations like vectorization?
>

Sorry for the delay in my response. My posts keep getting stuck in moderation.

I'll be honest that I haven't looked at S4 performance yet. That's the
big part of R's semantics that I haven't implemented yet. I chose to
delay this part largely because the language still feels very unstable
around the object systems.

I know R takes a lot of flak for having multiple incompatible object
systems. It's frustrating that that one object system hasn't come
dominate--they all have their pluses and minuses. However, one
response is to point out that Javascript is in the same situation, but
has still been very successful. There are lots of different OO
libraries for Javascript, each one taking a slightly different tack
(see this review from my office mate
https://github.com/njoubert/inheritance.js/blob/master/INHERITANCE.md
(caution some strong language)). I think part of the reason this has
worked out for Javascript is that none of the object systems are
considered part of the core language, leaving both the language
implementers and the OO library designers flexibility to experiment
without blocking each other.

R has taken the opposite approach...incorporating multiple object
systems into the core language, with the associated maintenance load
on R-Core...and I'm not sure that it's been as profitable. Perhaps
there are good reasons for this though. I'll admit that I haven't
thought through this area much.

Justin


From karl at huftis.org  Mon Mar 12 15:29:14 2012
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 12 Mar 2012 15:29:14 +0100
Subject: [Rd] Invalid date-times and as.POSIXct problems (remotely related
 to DST issues)
Message-ID: <1331562554.23180.4.camel@linux-mxk9.site>

I think this should be handled as a bug, but I?m not sure which
platforms and versions it applies to, so I?m writing to this list. The
problem is that as.POSIXct on character strings behaves in a strange way
if one of the date-times are invalid; it converts all the date-times to
dates (i.e., it discards the time part).

Example, which I suspect only works on my locale, with the UTC+1/UTC+2
timezone:

  $ dates=c("2003-10-13 00:15:00", "2008-06-03 14:45:00", "2003-03-30 02:00:00")

Note that the last date-time doesn?t actually exist 
(due to daylight saving time):
http://www.timeanddate.com/worldclock/meetingtime.html?day=30&month=3&year=2003&p1=187&iv=0

  $ d12=as.POSIXct(dates)
  $ d123=as.POSIXct(dates[1:2])
  $ d12
  [1] "2003-10-13 CEST" "2008-06-03 CEST" "2003-03-30 CET"
  $ d123
  [1] "2003-10-13 00:15:00 CEST" "2008-06-03 14:45:00 CEST"

When I include all values, they are all converted to (POSIXct) *dates*,
but if I exclude the invalid one, the rest are properly converted to
(POSIXct) date-times. Note that this is not just a display issue:

 $ unclass(d12)
 [1] 1065996000 1212444000 1048978800
 attr(,"tzone")
 [1] ""
 $ unclass(d123)
 [1] 1065996900 1212497100
 attr(,"tzone")
 [1] ""

I can only reproduce this on Windows; on Linux all the strings are
converted to date-times (the last one to 2003-03-30 01:00:00 CET).
However, if ones specifies a completely invalid time, e.g., 25:00, the
same thing does happen on Linux (2.14.2 Patched). I think the right/best
behaviour would be to convert the invalid date-time string to NA and
convert the other ones proper POSIXct date-times, and perhaps issue a
warning about NAs being generated.

(I originally discovered this problem on data from an Oracle database,
using sqlQuery() from the RODBC package, which automatically converts
date-times to date-times in current timezone (except if you specify
as.is=TRUE), and was surprised that for some queries the date-times were
truncated to dates. A warning that parts of the data were invalid would
be very welcome.)


Version details (for Windows):

$ version
                _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          14.2
year           2012
month          02
day            29
svn rev        58522
language       R
version.string R version 2.14.2 (2012-02-29)

$ sessionInfo()
R version 2.14.2 (2012-02-29)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Norwegian-Nynorsk_Norway.1252 
LC_CTYPE=Norwegian-Nynorsk_Norway.1252   
LC_MONETARY=Norwegian-Nynorsk_Norway.1252
[4] LC_NUMERIC=C                             
LC_TIME=Norwegian-Nynorsk_Norway.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

-- 
Karl Ove Hufthammer


From pauljohn32 at gmail.com  Mon Mar 12 17:00:55 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 12 Mar 2012 11:00:55 -0500
Subject: [Rd] --as-cran and need to ignore.svn directories
Message-ID: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>

Good morning:

I submitted a package update to CRAN and got a bounce because I had
not run R CMD check with "--as-cran".  I'd not heard of that before,
but I'm glad to know about it now.

I see it warns when my functions do use partial argument matching, and
I like that advice very much.

Also I see this warning

* checking package subdirectories ... WARNING
Found the following directory(s) with names of version control directories:
  ./.svn
  ./R/.svn
  ./data/.svn
  ./inst/.svn
  ./inst/doc/.svn
  ./inst/examples/.svn
  ./vignettes/.svn
These should not be in a package tarball.

Is there a way to cause R to ignore the .svn folders while running R
CMD check --as-cran or R CMD build?

It seems a little tedious to have to copy the whole directory tree to
some other place and remove the .svn folders before building. I can do
it, but it just seems, well, tedious. I have the feeling that you
"frequent flyers"  would have worked around this already.

-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From jari.oksanen at oulu.fi  Mon Mar 12 17:59:45 2012
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Mon, 12 Mar 2012 16:59:45 +0000
Subject: [Rd] --as-cran and need to ignore.svn directories
In-Reply-To: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
References: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
Message-ID: <E70FB403-8058-4BA8-B10D-ACE2EDB1F524@oulu.fi>


On 12/03/2012, at 18:03 PM, Paul Johnson wrote:

> Good morning:
> 
> I submitted a package update to CRAN and got a bounce because I had
> not run R CMD check with "--as-cran".  I'd not heard of that before,
> but I'm glad to know about it now.
> 
> I see it warns when my functions do use partial argument matching, and
> I like that advice very much.
> 
> Also I see this warning
> 
> * checking package subdirectories ... WARNING
> Found the following directory(s) with names of version control directories:
>  ./.svn
>  ./R/.svn
>  ./data/.svn
>  ./inst/.svn
>  ./inst/doc/.svn
>  ./inst/examples/.svn
>  ./vignettes/.svn
> These should not be in a package tarball.
> 
> Is there a way to cause R to ignore the .svn folders while running R
> CMD check --as-cran or R CMD build?
> 
> It seems a little tedious to have to copy the whole directory tree to
> some other place and remove the .svn folders before building. I can do
> it, but it just seems, well, tedious. I have the feeling that you
> "frequent flyers"  would have worked around this already.


Paul,

I think the best solution is to 'svn export' svn directory to a temporary directory/folder:

svn export my-svn-directory tmp-pkg-directory
R CMD build tmp-pkg-directory
R CMD check --as-cran ...

The two advantages of 'svn export' that it (1) strips the .svn specific files, and (2) it really exports only those files that really are under version control. More often than once I have had some non-svn files in my svn directory so that *my* version of the package works, but the one actually in subversion fails.

Cheers, Jari Oksanen 

-- 
Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland
jari.oksanen at oulu.fi, Ph. +358 400 408593, http://cc.oulu.fi/~jarioksa


From maechler at stat.math.ethz.ch  Mon Mar 12 18:42:32 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 Mar 2012 18:42:32 +0100
Subject: [Rd] Unexpected behaviour for RowSideColors in function heatmap
In-Reply-To: <0ADEEA73-BA4E-46FA-9891-589B7B644389@ebi.ac.uk>
References: <2357666E-86E2-4805-AD50-010588BE11B7@ebi.ac.uk>
	<4F58EBEC.6000004@gmail.com>
	<0ADEEA73-BA4E-46FA-9891-589B7B644389@ebi.ac.uk>
Message-ID: <20318.13704.600355.728549@stat.math.ethz.ch>


> Thanks Kevin, I experienced the same problems with heatmap.2, and therefore resorted to heatmap. For heatmap, the code change I suggested below fixes the problem with side color ordering as far as I can tell, and lets one create a symmetric heatmap with the origin at the top left (which I agree makes it easier to read). Unless this code change breaks something else, it would be nice if it could be incorporated into R.

It now has been incorporated:
For 2.15.0 (due in less than three weeks, see "Release Plans" on
    http://developer.r-project.org/)

Thanks you very much, P?r (and Kevin) !

Martin

> P?r

> On 8 Mar 2012, at 17:27, Kevin R. Coombes wrote:

> > First, I can confirm this problem exists today, and can now vaguely recall seeing it in previous version of R.
> > > sessionInfo()
> > R version 2.14.1 (2011-12-22)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > There is a bigger problem with heatmap.2 in the gplots package.  Using "symm=TRUE" with no other arguments causes it to fail to print one of the dendrograms:
> > > library(gplots)
> > > cU <- cor(USJudgeRatings)
> > > heatmap.2(cU, symm = TRUE)
> > Warning message:
> > In heatmap.2(cU, symm = TRUE) :
> >   Discrepancy: Colv is FALSE, while dendrogram is `row'. Omitting column dendogram.
> >
> > In order to get the column dendrogram displayed using heatmap.2, you must use "symm=TRUE, Colv=TRUE".  So this succeeds:
> > >  heatmap.2(cU, symm = TRUE, Colv=TRUE)
> >
> > To make things worse, heatmap.2 sometimes gets the direction of the column colors wrong.  If you omit "Colv=TRUE", it leaves out the column dendrogram and gets one set of colors wrong.  That, is, the following command fails in two ways:
> > > sideCols <- rainbow(ncol(cU))
> > > heatmap.2(cU, symm = TRUE, distfun = function(c) as.dist(1 - c),
> >        ColSideColors=sideCols, RowSideColors=sideCols)
> >
> > If you include "Colv=TRUE", then it prints the dendrogram and gets both sets of colorbars correct.  So the following command succeeds:
> > > heatmap.2(cU, symm = TRUE, Colv=TRUE, distfun = function(c) as.dist(1 - c),
> > +        ColSideColors=sideCols, RowSideColors=sideCols)
> >
> > It is a separate esthetic question as to which diagonal axis should be used for symmetry. When it works in heatmap.2, the "origin" is at the bottom left.  Since the dendrograms are printed on the top and left, however, the symmetry would be easier to see/confirm if the origin were put at the top left. One might be tempted to fit this by using "revC=TRUE".  However, this command fails because it gets the colorbar wrong:
> > > heatmap.2(cU, symm = TRUE, Colv=TRUE, revC=TRUE,
> >           distfun = function(c) as.dist(1 - c),
> >           ColSideColors=sideCols, RowSideColors=sideCols)
> >
> > I am occasionally of the opinion that both "heatmap" and "heatmap.2" are too complex to be used reliably by mortals....
> >     Kevin
> >
> > On 2/28/2012 4:04 AM, P?r Engstr?m wrote:
> >>
> >> Hello,
> >>
> >> I have come across some unexpected behaviour of the function heatmap in the stats package. This looks like a bug to me, but I might have misunderstood something.
> >>
> >> When calling the function in symmetric mode, the ColSideColors are plotted correctly, but RowSideColors appear in reverse order. This code (modified from the example on the help page) demonstrates the problem:
> >>
> >> cU <- cor(USJudgeRatings)
> >> sideCols <- rainbow(ncol(cU))
> >> heatmap(cU, symm = TRUE, distfun = function(c) as.dist(1 - c),
> >>        ColSideColors=sideCols, RowSideColors=sideCols)
> >>
> >> Reversing the RowSideColors argument does not solve the problem:
> >>
> >> heatmap(cU, symm = TRUE, distfun = function(c) as.dist(1 - c),
> >>        ColSideColors=sideCols, RowSideColors=rev(sideCols))
> >>
> >> I had a look at the the function code and found that this change fixes the problem:
> >>
> >> Replace
> >>
> >>        image(rbind(1L:nr), col = RowSideColors[rowInd], axes = FALSE)
> >>
> >> with
> >>
> >>        image(rbind(if(revC) nr:1L else 1L:nr), col = RowSideColors[rowInd], axes = FALSE)
> >>
> >> I am using the current version of R for Mac OS X:
> >>
> >>> sessionInfo()
> >> R version 2.14.1 (2011-12-22)
> >> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> >>
> >> locale:
> >> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >>
> >> Regards,
> >>
> >> P?r Engstr?m
> >>
> >> Postdoctoral Fellow
> >> EMBL European Bioinformatics Institute
> >> Wellcome Trust Genome Campus
> >> Hinxton, Cambridge, UK


From maechler at stat.math.ethz.ch  Mon Mar 12 18:47:47 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 Mar 2012 18:47:47 +0100
Subject: [Rd] --as-cran and need to ignore.svn directories
In-Reply-To: <E70FB403-8058-4BA8-B10D-ACE2EDB1F524@oulu.fi>
References: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
	<E70FB403-8058-4BA8-B10D-ACE2EDB1F524@oulu.fi>
Message-ID: <20318.14019.103384.356068@stat.math.ethz.ch>

>>>>> Jari Oksanen <jari.oksanen at oulu.fi>
>>>>>     on Mon, 12 Mar 2012 16:59:45 +0000 writes:

    > On 12/03/2012, at 18:03 PM, Paul Johnson wrote:

    >> Good morning:
    >> 
    >> I submitted a package update to CRAN and got a bounce because I had
    >> not run R CMD check with "--as-cran".  I'd not heard of that before,
    >> but I'm glad to know about it now.
    >> 
    >> I see it warns when my functions do use partial argument matching, and
    >> I like that advice very much.
    >> 
    >> Also I see this warning
    >> 
    >> * checking package subdirectories ... WARNING Found the following
    >> directory(s) with names of version control directories: ./.svn
    >> ./R/.svn ./data/.svn ./inst/.svn ./inst/doc/.svn ./inst/examples/.svn
    >> ./vignettes/.svn These should not be in a package tarball.
    >> 
    >> Is there a way to cause R to ignore the .svn folders while running R
    >> CMD check --as-cran or R CMD build?
    >> 
    >> It seems a little tedious to have to copy the whole directory tree to
    >> some other place and remove the .svn folders before building. I can do
    >> it, but it just seems, well, tedious. I have the feeling that you
    >> "frequent flyers" would have worked around this already.


    > Paul,

    > I think the best solution is to 'svn export' svn directory to a
    > temporary directory/folder:

No, I don't think that should not be needed.

When building the tarball,  'R CMD build' *does* ignore the .svn
folders, at least for me.

Paul's problem was using  --as-cran on his SVN *directory*
but that's a slight contradiction in itself, as the CRAN maintainers
always run the checks on a tarball...

Martin

    > svn export my-svn-directory tmp-pkg-directory
    > R CMD build tmp-pkg-directory
    > R CMD check --as-cran ...

    > The two advantages of 'svn export' that it (1) strips the .svn specific
    > files, and (2) it really exports only those files that really are under
    > version control. More often than once I have had some non-svn files in
    > my svn directory so that *my* version of the package works, but the one
    > actually in subversion fails.

    > Cheers, Jari Oksanen 

    > -- 
    > Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland
    > jari.oksanen at oulu.fi, Ph. +358 400 408593, http://cc.oulu.fi/~jarioksa

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Mar 12 18:49:03 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Mar 2012 17:49:03 +0000
Subject: [Rd] --as-cran and need to ignore.svn directories
In-Reply-To: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
References: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
Message-ID: <4F5E370F.6030506@stats.ox.ac.uk>

On 12/03/2012 16:00, Paul Johnson wrote:
> Good morning:
>
> I submitted a package update to CRAN and got a bounce because I had
> not run R CMD check with "--as-cran".  I'd not heard of that before,
> but I'm glad to know about it now.

Well, it has only existed for about a month, but the customizations its 
selects are often much older and were documented as being used by CRAN.

> I see it warns when my functions do use partial argument matching, and
> I like that advice very much.

It switches on a customization that has been documented for years ....
>
> Also I see this warning
>
> * checking package subdirectories ... WARNING
> Found the following directory(s) with names of version control directories:
>    ./.svn
>    ./R/.svn
>    ./data/.svn
>    ./inst/.svn
>    ./inst/doc/.svn
>    ./inst/examples/.svn
>    ./vignettes/.svn
> These should not be in a package tarball.
>
> Is there a way to cause R to ignore the .svn folders while running R
> CMD check --as-cran or R CMD build?
>
> It seems a little tedious to have to copy the whole directory tree to
> some other place and remove the .svn folders before building. I can do
> it, but it just seems, well, tedious. I have the feeling that you
> "frequent flyers"  would have worked around this already.
>

You are strongly recommended to run this *on the tarball to be 
submitted*.  If you have .svn directories in that tarball, then you do 
(or CRAN will) have a problem.  R CMD build does omit such directories, 
and you can of course use .Rbuildignore to ignore other things.

Or if you update to subversion 1.7.x the problem will evaporate, as that 
only stores .svn directories at the top level, in my case ~/R/svn/Rpkgs, 
above all the individual packages.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pauljohn32 at gmail.com  Mon Mar 12 19:43:06 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 12 Mar 2012 13:43:06 -0500
Subject: [Rd] --as-cran and need to ignore.svn directories
In-Reply-To: <20318.14019.103384.356068@stat.math.ethz.ch>
References: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
	<E70FB403-8058-4BA8-B10D-ACE2EDB1F524@oulu.fi>
	<20318.14019.103384.356068@stat.math.ethz.ch>
Message-ID: <CAErODj_iKChT44ucUadjznBCU+UN1uVWi6rZAGOmN8QuKFX68g@mail.gmail.com>

On Mon, Mar 12, 2012 at 12:47 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Jari Oksanen <jari.oksanen at oulu.fi>
[snip]
>
> ? ?> Paul,
>
> ? ?> I think the best solution is to 'svn export' svn directory to a
> ? ?> temporary directory/folder:
>
> No, I don't think that should not be needed.
>
> When building the tarball, ?'R CMD build' *does* ignore the .svn
> folders, at least for me.
>

My tarball was created by R CMD build, I don't know why the .svn
folders were included.  There are no .svn folders in the packages I
made with 2.14.1, so I suppose that is the first problem I have to
figure out.  This was my first build with R-2.14.2.  If I get an
answer, I will write back.

> Paul's problem was using ?--as-cran on his SVN *directory*
> but that's a slight contradiction in itself, as the CRAN maintainers
> always run the checks on a tarball...

I don't have an argument against what you say, and I'm glad to do it
however you recommend. But I don't understand this. How do you get the
tarball without first doing R CMD check and R CMD build on the working
directory where the package lives?  I just do what seems to be
recommended in the tutorial by Friedrich Leisch "Creating R Packages:
A Tutorial" and the R extensions document. Until now, I have done this
in the shell to create the package.

R CMD check rockchalk
R CMD build rockchalk

You mean everybody doesn't do it that way?

>From now on, I'm adding --as-cran with check, but what else?

After that finishes, I should be running check on the tarball that was
created by build?

While I'm asking basic packaging questions, I have a vignette
packaging question. My vignette is in

vignettes/outreg.Rnw

The R build process runs latex to make sure the vignette can be built.
But, as far as I can tell, it does not copy the pdf file into

inst/doc/outreg.pdf.

So when building the package, I should still manually compile the pdf
and move it over there?


>
> Martin
>
> ? ?> svn export my-svn-directory tmp-pkg-directory
> ? ?> R CMD build tmp-pkg-directory
> ? ?> R CMD check --as-cran ...
>
> ? ?> The two advantages of 'svn export' that it (1) strips the .svn specific
> ? ?> files, and (2) it really exports only those files that really are under
> ? ?> version control. More often than once I have had some non-svn files in
> ? ?> my svn directory so that *my* version of the package works, but the one
> ? ?> actually in subversion fails.
>
> ? ?> Cheers, Jari Oksanen
>
> ? ?> --
> ? ?> Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland
> ? ?> jari.oksanen at oulu.fi, Ph. +358 400 408593, http://cc.oulu.fi/~jarioksa


-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From brian at braverock.com  Mon Mar 12 19:53:48 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 12 Mar 2012 13:53:48 -0500
Subject: [Rd] --as-cran and need to ignore.svn directories
In-Reply-To: <CAErODj_iKChT44ucUadjznBCU+UN1uVWi6rZAGOmN8QuKFX68g@mail.gmail.com>
References: <CAErODj8FQXeTvT=pBjKo7ZjEGB8rHVyjLOGy409M5kA-xWYsFw@mail.gmail.com>
	<E70FB403-8058-4BA8-B10D-ACE2EDB1F524@oulu.fi>
	<20318.14019.103384.356068@stat.math.ethz.ch>
	<CAErODj_iKChT44ucUadjznBCU+UN1uVWi6rZAGOmN8QuKFX68g@mail.gmail.com>
Message-ID: <1331578428.28362.302.camel@brian-rcg>

On Mon, 2012-03-12 at 13:43 -0500, Paul Johnson wrote:
> R CMD check rockchalk
> R CMD build rockchalk 

do *build* first, then *check* on the tarball file.
 
-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From bbolker at gmail.com  Tue Mar 13 17:52:26 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Mar 2012 12:52:26 -0400
Subject: [Rd] "note: symbols.rds is not available"
Message-ID: <4F5F7B4A.5010108@gmail.com>


  I've encountered this note in checking packages with the latest
R-devel. Googling finds it only in other package checks; searching the
source tree finds in src/library/tools/R/sotools.R , but I'm not sure
what it's doing there.


'symbols.rds' shows up in the SVN log here:

r58591 | ripley | 2012-03-05 07:25:58 -0500 (Mon, 05 Mar 2012) | 1 line

treat non-symbols.rds reports on base packages differently

r58539 | ripley | 2012-03-01 04:54:39 -0500 (Thu, 01 Mar 2012) | 1 line

comment if expecting symbols.rds and not found


  Any thoughts? Is it harmless?  How would I fix the issue/suppress
the note?

  thanks
    Ben Bolker


From ligges at statistik.tu-dortmund.de  Tue Mar 13 18:23:32 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 13 Mar 2012 18:23:32 +0100
Subject: [Rd] "note: symbols.rds is not available"
In-Reply-To: <4F5F7B4A.5010108@gmail.com>
References: <4F5F7B4A.5010108@gmail.com>
Message-ID: <4F5F8294.4060002@statistik.tu-dortmund.de>

This is used for checking unsave symbols in compiled code (such as 
abort, exit or printf calls). For some reason you could not generate the 
symbols and hence a note. Therefore, this does not indicate a problem 
with the package.

Uwe Ligges


On 13.03.2012 17:52, Ben Bolker wrote:
>
>    I've encountered this note in checking packages with the latest
> R-devel. Googling finds it only in other package checks; searching the
> source tree finds in src/library/tools/R/sotools.R , but I'm not sure
> what it's doing there.
>
>
> 'symbols.rds' shows up in the SVN log here:
>
> r58591 | ripley | 2012-03-05 07:25:58 -0500 (Mon, 05 Mar 2012) | 1 line
>
> treat non-symbols.rds reports on base packages differently
>
> r58539 | ripley | 2012-03-01 04:54:39 -0500 (Thu, 01 Mar 2012) | 1 line
>
> comment if expecting symbols.rds and not found
>
>
>    Any thoughts? Is it harmless?  How would I fix the issue/suppress
> the note?
>
>    thanks
>      Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mdowle at mdowle.plus.com  Wed Mar 14 00:08:22 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 13 Mar 2012 23:08:22 +0000
Subject: [Rd] 111 FIXMEs in main/src
Message-ID: <1331680102.9039.115.camel@netbook>

Hi,

We sometimes see offers to contribute, asking what needs to be done. If
they know C, how about the 111 FIXMEs? But which ones would be most
useful to fix? Which are difficult and which are easy? Does R-core have
a process to list and prioritise the FIXMEs?

~/R/Rtrunk/src/main$ grep "[^/]FIXME" * | wc -l
111
~/R/Rtrunk/src/main$ grep -A 1 "[^/]FIXME" *
arithmetic.c:/* FIXME: consider using
arithmetic.c-    tmp = (long double)x1 - floor(q) * (long double)x2;
--
arithmetic.c:/* FIXME: with the y == 2.0 test now at the top that case
isn't
arithmetic.c-   reached here, but i have left it for someone who
understands the
--
arithmetic.c:    /* FIXME: Danger Will Robinson.
arithmetic.c-     * -----  We might be trashing arguments here.
--
array.c:	/* FIXME: the following is desirable, but pointless as long as
array.c-	   subset.c & others have a contrary version that leaves the
--
attrib.c:    /* FIXME:  1.e-5 should rather be == option('ts.eps') !! */
attrib.c-    if (fabs(end - start - (n - 1)/frequency) > 1.e-5)
--
attrib.c:	    /* FIXME : The whole "classgets" may as well die. */
attrib.c-
--
attrib.c:    /* FIXME */
attrib.c-    if (nvalues <= 0)
--
attrib.c:    /* FIXME */
attrib.c-    PROTECT(namesattr);
--
attrib.c:    /* FIXME: the code below treats pair-based structures */
attrib.c-    /* in a special way.  This can probably be dropped down */
--
base.c:/* FIXME: Make this a macro to avoid function call overhead?
base.c-   Inline it if you really think it matters.
--
bind.c:/* FIXME : is there another possibility? */
bind.c-
--
bind.c:		    /* FIXME: I'm not sure what the author intended when the
sequence was
bind.c-		       defined as raw < logical -- it is possible to represent
logical as
--
builtin.c:		/* FIXME -- Rstrlen allows for double-width chars */
builtin.c-		width += Rstrlen(STRING_ELT(labs, nlines % lablen), 0) + 1;
--
builtin.c:	      /* FIXME:	 call EncodeElement() for every element of
s.
builtin.c-
--
builtin.c:	    /* FIXME : cat(...) should handle ANYTHING */
builtin.c-	    w = strlen(p);
--
character.c:	    slen = strlen(ss); /* FIXME -- should handle embedded
nuls */
character.c-	    buf = R_AllocStringBuffer(slen+1, &cbuff);
--
character.c:		   FIXME: could prefer UTF-8 here
character.c-		 */
--
character.c:	    /* FIXME: could use R_Realloc instead */
character.c-	    cbuf = CallocCharBuf(strlen(tmp) + 1);
--
character.c:		    /* FIXME use this buffer for new string as well */
character.c-		    wc = (wchar_t *)
--
coerce.c:/* FIXME: Use
coerce.c-   =====
--
complex.c:/* FIXME: maybe add full IEC60559 support */
complex.c-static double complex clog(double complex x)
--
complex.c:/* FIXME: check/add full IEC60559 support */
complex.c-static double complex cexp(double complex x)
--
connections.c:    /* FIXME: is this correct for consoles? */
connections.c-    checkArity(op, args);
--
connections.c:/* FIXME: could do any MBCS locale, but would need
pushback */
connections.c-static SEXP
--
connections.c:	outlen = 1.01 * inlen + 600; /* FIXME, copied from bzip2
*/
connections.c-	buf = (unsigned char *) R_alloc(outlen, sizeof(unsigned
char));
--
datetime.c:		    /* FIXME some of this should be outside the loop */
datetime.c-		    int ns, nused = 4;
--
dcf.c:			/* FIXME:
dcf.c-			   Why are we doing this?
--
debug.c:	    /* FIXME: previous will have <0x....> whereas other values
are
debug.c-	       without the < > */
--
deriv.c:	/* FIXME: simplify exp(lgamma( E )) = gamma( E ) */
deriv.c-	ans = lang2(ExpSymbol, arg1);
--
deriv.c:	/* FIXME: simplify log(gamma( E )) = lgamma( E ) */
deriv.c-	ans = lang2(LogSymbol, arg1);
--
deriv.c:    /* FIXME */
deriv.c-#ifdef NOTYET
--
devices.c:    /* <FIXME> Disable this for now */
devices.c-    /*
--
devices.c:    /* FIXME: There should really be a formal graphics
finaliser
devices.c-     * but this is a good proxy for now.
--
devices.c:    /* FIXME:  there should be a way for a device to declare
its own
devices.c-               events, and return information on how to set
them */
--
dounzip.c:	   filename is in UTF-8, so FIXME */
dounzip.c-	SET_STRING_ELT(names, i, mkChar(filename_inzip));
--
duplicate.c:   <FIXME>: surely memcpy would be faster here?
duplicate.c-*/
--
engine.c:    /* FIXME: what about clipping? (if the device can't) 
engine.c-    */
--
engine.c:    /* FIXME: what about clipping? (if the device can't) 
engine.c-     * Maybe not too bad because it is just a matter of shaving
off
--
engine.c:					/* FIXME: This assumes that wchar_t is UCS-2/4,
engine.c-					   since that is what GEMetricInfo expects */
--
engine.c:/* FIXME: should we warn on more than one character here? */
engine.c-int GEstring_to_pch(SEXP pch)
--
envir.c:  FIXME ? should this also unbind the symbol value slot when rho
is
envir.c-  R_BaseEnv.
--
envir.c:	/* FIXME: This does not behave as described */
envir.c-	R_ObjectTable *table;
--
envir.c:    /* FIXME: should we install them all?) */
envir.c-
--
envir.c:		/* FIXME: duplicate the hash table and assign here */
envir.c-	    } else {
--
envir.c:	/* FIXME: A little inefficient */
envir.c-	while (R_HashSizeCheck(HASHTAB(s)))
--
errors.c:    /**** FIXME: should probably pre-allocate this */
errors.c-    SEXP cond, klass;
--
eval.c:    /*  Use the default code for unbound formals.  FIXME: It
looks like
eval.c-	this code should preceed the building of the environment so that
--
eval.c:    /* The default return value is NULL.  FIXME: Is this really
needed
eval.c-       or do we always get a sensible value returned?  */
--
eval.c:/* **** FIXME: This code is factored out of applyClosure.  If we
keep
eval.c-   **** it we should change applyClosure to run through this
routine
--
eval.c:    /* The default return value is NULL.  FIXME: Is this really
needed
eval.c-       or do we always get a sensible value returned?  */
--
eval.c:/* **** FIXME: Temporary code to execute S4 methods in a way that
eval.c-   **** preserves lexical scope. */
--
eval.c:    /*  FIXME: We need to ensure that this works for hashed
eval.c-	environments.  This code only works for unhashed ones.  the
--
eval.c:    /*  FIXME: This strategy will not work when we are working in
the
eval.c-	data frame defined by the system hash table.  The structure
there
--
format.c:	/* FIXME: we should really test for floorl, also C99.
format.c-	   But FreeBSD 7.x does have it, but not nearbyintl */
--
gram.c:    f = R_atof(s); /* FIXME: make certain the value is
legitimate. */
gram.c-
--
gramLatex.c:    /* FIXME:  check that begin and end match */
gramLatex.c-    setAttrib(ans, R_SrcrefSymbol, makeSrcref(lloc,
SrcFile));
--
gramLatex.y:    /* FIXME:  check that begin and end match */
gramLatex.y-    setAttrib(ans, R_SrcrefSymbol, makeSrcref(lloc,
SrcFile));
--
gram.y:    f = R_atof(s); /* FIXME: make certain the value is
legitimate. */
gram.y-
--
graphics.c:    case 's':/* FIXME --- implement  's' and 'e' axis
styles ! */
graphics.c-    case 'e':
--
graphics.c:/* FIXME: reorganize this as a memcpy */
graphics.c-
--
grep.c:/* FIXME: make more robust, and public */
grep.c-static SEXP mkCharWLen(const wchar_t *wc, int nc)
--
grep.c:		       strings, but <MBCS-FIXME> it would be more
grep.c-		       efficient to skip along by chars.
--
grep.c:	if (ptag.rm_eo == 0) { /* empty string matched => trouble;
FIXME: we may want to consider just advancing anyway */
grep.c-	    int infinite_match = 1;
--
grep.c:/* FIXME: use UCP for upper/lower conversion */
grep.c-static 
--
grep.c:	/* FIXME perhaps we ought to check validity here */
grep.c-	len = strlen(string);
--
inspect.c:/* FIXME: envir.c keeps this private - it should probably go
to Defn.h */
inspect.c-#define FRAME_LOCK_MASK (1<<14)
--
main.c:/* FIXME: this should be re-written to use Rf_ReplIteration
main.c-   since it gets out of sync with it over time */
--
main.c:    /* <FIXME> may need to reinstall this if we do recover. */
main.c-    struct sigaction sa;
--
memory.c:/* FIXME: consider inlining here */
memory.c-/* this has NA_STRING = NA_STRING */
--
model.c:    /* FIXME: this includes specials in the model */
model.c-    /* There perhaps needs to be a an extra pass */
--
model.c:    /* FIXME: this is also the point where nesting */
model.c-    /* needs to be taken care of. */
--
model.c:    /* FIXME: We need to allow a third argument to this function
*/
model.c-    /* which allows us to specify contrasts directly.  That
argument */
--
model.c:    /* FIXME : The body within these two loops should be
embedded */
model.c-    /* in its own function. */
--
objects.c:	// FIXME: fails if 'methods' is not attached.
objects.c-	PROTECT(clEnvCall = lang2(meth_classEnv, cl));
--
par.c:/* <FIXME>  do not need separate macros for a = b = c and b = a =
c */
par.c-#define R_DEV__(_P_) dpptr(dd)->_P_ = gpptr(dd)->_P_
--
platform.c:	/* FIXME convert to UTF-8 on Windows */
platform.c-	for (i = 0; i < n; i++) {
--
platform.c:	    /* FIXME: there are higher-resolution ways to do this on
Windows */
platform.c-	    REAL(mtime)[i] = (double) sb.st_mtime;
--
platform.c:	if (over || !R_WFileExists(dest)) { /* FIXME */
platform.c-	    if ((fp1 = _wfopen(this, L"rb")) == NULL ||
--
platform.c:	/* FIXME: perhaps manipulate mode as we do in Sys.chmod? */
platform.c-	if(perms) _wchmod(dest, sb.st_mode & 0777);
--
plot3d.c:/* FIXME - This could pretty easily be adapted to handle NA */
plot3d.c-/* values on the grid.  Just search the diagonals for cutpoints
*/
--
plot3d.c:/* FIXME: [Code consistency] Use macro for the parallel parts
of
plot3d.c-	  do_contour, do_filledcontour & do_image ...
--
plot.c:       FIXME: bg needs similar change, but that requires changes
to
plot.c-       the specific drivers. */
--
plot.c:		    /* FIXME: should this skip 0-sized symbols? */
plot.c-		    thiscol = INTEGER(col)[i % ncol];
--
plot.c:	/* FIXME?
plot.c-	 * Seems like the logic here is just draw from xmin to xmax
--
plot.c:		/* FIXME: should this skip 0-sized symbols? */
plot.c-		GRect(xx - rx, yy - rx, xx + rx, yy + rx, DEVICE,
--
plot.c:		/* FIXME: should this skip 0-sized symbols? */
plot.c-		GRect(xx - rx, yy - ry, xx + rx, yy + ry, DEVICE,
--
plot.c:		/* FIXME: should this skip 0-sized symbols? */
plot.c-		for(j = 0; j < nc; j++) {
--
printarray.c:/* FIXME: sort out encodings */
printarray.c-/* We need display width of a string */
--
printarray.c:    if(r_pr < r) /* FIXME? use _P() and "Defn.h" ? */
printarray.c-	Rprintf(ngettext(" [ reached getOption(\"max.print\") --
omitted last row ]]\n",
--
printarray.c:    if(r_pr < r) /* FIXME? use _P() and "Defn.h" ? */
printarray.c-	Rprintf(" [ reached getOption(\"max.print\") -- omitted %d
rows ]]\n",
--
print.c: *  <FIXME> These routines are not re-entrant: they reset the
print.c- *  global R_print.
--
print.c:/* FIXME : We need a general mechanism for "rendering" symbols.
*/
print.c-/* It should make sure that it quotes when there are special */
--
print.c:	/* FIXME: check (ns <= R_print.max +1) ? ns : R_print.max; */
print.c-	for (i = 0; i < ns; i++) {
--
printutils.c:/* <FIXME>
printutils.c-   encodeString and Rstrwid assume that the wchar_t
representation
--
saveload.c:    /* FIXME: rather than use strlen, use actual length of
string when
saveload.c-     * sized strings get implemented in R's save/load code.
*/
--
saveload.c:    /* FIXME : Ultimately we need to replace */
saveload.c-    /* this with a real string allocation. */
--
scan.c:			goto inquote; /* FIXME: Ick! Clean up logic */
scan.c-		    }
--
seq.c:	/* FIXME: possibly UTF-8 version */
seq.c-	for (i = 0; i < nls; i++) {
--
serialize.c:	stream->OutBytes(stream, (void *)s, length); /* FIXME: is
this case right? */
serialize.c-}
--
subassign.c:    /* FIXME : this should be a shallow copy for list */
subassign.c-    /* objects.  A full duplication is wasteful. */
--
subassign.c:    /* FIXME : this should be a shallow copy for list */
subassign.c-    /* objects.  A full duplication is wasteful. */
--
subassign.c:    /* FIXME : this should be a shallow copy for list */
subassign.c-    /* objects.  A full duplication is wasteful. */
--
subassign.c:	    /* FIXME: add name */
subassign.c-	    UNPROTECT(1);
--
subset.c:	/* FIXME:  this is wrong, because the slots are gone, so
result is an invalid object of the S4 class! JMC 3/3/09 */
subset.c-#ifdef _S4_subsettable
--
subset.c:    /* FIXME: replace the test by isNull ... ? */
subset.c-
--
summary.c:	/* FIXME : Need to be careful with the use of isVector() */
summary.c-	/* since this includes lists and expressions. */
--
summary.c:    /* FIXME : there is a lot of shared code here for vectors.
*/
summary.c-    /* It should be abstracted out and optimized. */
--
summary.c:	    /* FIXME : using mod like this causes */
summary.c-	    /* a potential performance hit. */
--
sysutils.c:	/* FIXME, is Cocoa's interface not const char*? */
sysutils.c-	cmdcpy = acopy_string(command);
--
unique.c:   <FIXME>  Integer keys are wasteful for logical and raw
vectors,
unique.c-   but the tables are small in that case.
--
unique.c:	    /* <FIXME>
unique.c-	       Currently no hashing when using bytes.
$


From karl at huftis.org  Wed Mar 14 09:10:17 2012
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Wed, 14 Mar 2012 09:10:17 +0100
Subject: [Rd] Invalid date-times and as.POSIXct problems (remotely
	related to DST issues)
References: <1331562554.23180.4.camel@linux-mxk9.site>
Message-ID: <jjpjp9$o6j$1@dough.gmane.org>

Karl Ove Hufthammer wrote:
> I think this should be handled as a bug, but I?m not sure which
> platforms and versions it applies to, so I?m writing to this list.

No response, so I?ve filed a bug at
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14845
(with some additional info).

-- 
Karl Ove Hufthammer


From spinuvit at gmail.com  Wed Mar 14 10:57:46 2012
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 14 Mar 2012 10:57:46 +0100
Subject: [Rd] [ESS] completion in [] (R internal completion fails)
In-Reply-To: <87399b4jld.fsf@gmail.com> (Vitalie Spinu's message of "Wed, 14
	Mar 2012 10:28:46 +0100")
References: <87ipi7mtb2.fsf@med.uni-goettingen.de> <87399b4jld.fsf@gmail.com>
Message-ID: <87r4wv33ol.fsf_-_@gmail.com>


Hello, 

I am forwarding this from ESS mailing list, as it's a failure of
internal R completion system:

This fails:

utils:::.assignLinebuffer('iris[iris$Spec')
utils:::.assignEnd(15)
utils:::.guessTokenFromLine()
utils:::.completeToken()
utils:::.retrieveCompletions() ## -> [1] "iris[iris$Spec"

This works

utils:::.assignLinebuffer('iris[ iris$Spec')  # note the space after [
utils:::.assignEnd(15)
utils:::.guessTokenFromLine()
utils:::.completeToken()
utils:::.retrieveCompletions() ## -> [1] "iris$Species"

Best, 
Vitalie.

>>>> Andreas Leha <andreas.leha at med.uni-goettingen.de>
>>>> on Wed, 14 Mar 2012 10:21:37 +0100 wrote:

  >> Hi all,
  >> I am seeing strange behaviour with completion inside [].

  >> Suppose I have
  >> ttt <- data.frame(aaa=1, bbb=1)
  >> and I want to run
  >> ttt$aaa[ttt$aaa == 1] <- 2

  >> then completion at this point fails:
  >> ttt$aaa[ttt$aa<TAB>

  >> On the other hand, strangly enough, this works as expected:
  >> ttt$aaa[ ttt$aa<TAB>

  >> Regards,
  >> Andreas

  >> ______________________________________________
  >> ESS-help at r-project.org mailing list
  >> https://stat.ethz.ch/mailman/listinfo/ess-help


From mdowle at mdowle.plus.com  Wed Mar 14 11:21:20 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 14 Mar 2012 10:21:20 -0000
Subject: [Rd] merge bug fix in R 2.15.0
Message-ID: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>


Is it intended that the first suffix can no longer be blank? Seems to be
caused by a bug fix to merge in R 2.15.0.

$Rdevel --vanilla
DF1 = data.frame(a=1:3,b=4:6)
DF2 = data.frame(a=1:3,b=7:9)
merge(DF1,DF2,by="a",suffixes=c("",".1"))
Error in merge.data.frame(DF1, DF2, by = "a", suffixes = c("", ".1")) :
  there is already a column named ?b?

$R --vanilla
R version 2.14.2 (2012-02-29)
> DF1 = data.frame(a=1:3,b=4:6)
> DF2 = data.frame(a=1:3,b=7:9)
> merge(DF1,DF2,by="a",suffixes=c("",".1"))
  a b b.1
1 1 4   7
2 2 5   8
3 3 6   9
>

Matthew


From jon.clayden at gmail.com  Wed Mar 14 13:15:37 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 14 Mar 2012 12:15:37 +0000
Subject: [Rd] Dealing with printf() &c. in third-party library code
Message-ID: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>

Dear all,

I recognise the reason for strongly discouraging use of printf() and
similar C functions in R packages, but I wonder what people do in
practice about third-party code which may be littered with such calls.
I maintain a package (RNiftyReg) which provides an R interface to a
third-party library which contains hundreds of calls to printf(...),
fprintf(stderr,...) and similar. It seems to me that there are several
possible approaches, but all have their issues:

1. Replace all such calls with equivalent Rprintf() calls, using
compiler preprocessing directives to ensure the library does not
become incompatible with other code. For example,

#ifdef RNIFTYREG
Rprintf(...);
#else
printf(...);
#endif

This will be very time-consuming if there are lots of calls, and also
makes the code very untidy and much harder to update when a new
version of the upstream library is released.

2. Remove all such calls from the code altogether, or comment them
out. The problem here is that doing this safely is hard, because the
call could be part of an "if" statement or similar. For example,

if (test)
 printf("Something");
do_something_important;

If the middle line here is removed, then the last line becomes
(erroneously) conditioned on the test. Plus, once again, you are
introducing a lot of small changes to the library itself.

3. Redefine printf to use Rprintf, viz.

#ifdef RNIFTYREG
#include <R.h>
#define printf Rprintf
#endif

This will compile as long as the R function is a drop-in replacement
for the original function, which I believe is true for Rprintf (vs.
printf), but isn't true for Calloc (vs. calloc), for example. And I'm
not sure whether this approach can be used to deal with cases of the
form fprintf(stderr,...), where stderr would need to be redefined.
This approach requires only modest changes to the library itself, but
may be fragile to future changes in R.

Are there any other (better?) alternatives? Any thoughts or advice
would be appreciated.

All the best,
Jon


From dtenenba at fhcrc.org  Wed Mar 14 21:13:20 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 14 Mar 2012 13:13:20 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
Message-ID: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>

Hi,

The following command:
R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test genefu-package.Rd
run against this file:
https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
(username: readonly; password: readonly)

produces a very verbose error (see below)
with R version 2.15.0 alpha (2012-03-07 r58622).

The .Rd file has these lines in it:

Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr

If I take these lines out, or take out the \Sexpr part, the Rd2pdf
command will complete successfully.

Is there some other step I need to run to evaluate the \Sexpr tags
before running Rd2pdf, or is there an issue that needs to be fixed?

Thanks,
Dan

Error output:

Converting Rd files to LaTeX ...
  genefu-package.Rd
Creating pdf output from LaTeX ...
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  Running 'texi2dvi' on 'Rd2.tex' failed.
Messages:
/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
/usr/bin/texi2dvi: see Rd2.log for errors.
Output:
This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
 restricted \write18 enabled.
entering extended mode
(/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
LaTeX2e <2011/06/27>
Babel <v3.8m> and hyphenation patterns for english, dumylang, nohyphenation, ge
rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus, arabi
c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
h, french, galician, german, ngerman, swissgerman, monogreek, greek, hungarian,
 icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, marathi, or
iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, kurmanji,
 lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk, pol
ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak, sloven
ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh, loaded
.
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
(/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
(/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
NOT loading lmodern
(/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
(/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
(/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
(/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
(/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
(/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))

Package hyperref Message: Driver (autodetected): hpdftex.

(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
(/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))

Package hyperref Warning: Option `hyperindex' has already been used,
(hyperref)                setting the option has no effect on input line 356.


Package hyperref Warning: Option `pagebackref' has already been used,
(hyperref)                setting the option has no effect on input line 356.

) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
Writing index file Rd2.idx
No file Rd2.aux.
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
(/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
(/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
[Loading MPS to PDF converter (version 2006.09.02).]
) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
(/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Missing \end
group inserted.
<inserted text>
                \endgroup
l.39 }

?
/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Emergency st
op.
<inserted text>
                \endgroup
l.39 }

/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:  ==> Fatal e
rror occurred, no output PDF file produced!
Transcript written on Rd2.log.
Error in running tools::texi2pdf


From jfox at mcmaster.ca  Wed Mar 14 23:45:06 2012
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 14 Mar 2012 18:45:06 -0400
Subject: [Rd] using predict() with poly(x, raw=TRUE)
Message-ID: <00ba01cd0234$1b079890$5116c9b0$@mcmaster.ca>

Dear r-devel list members,

I've recently encountered the following problem using predict() with a model
that has raw-polynomial terms. (Actually, I encountered the problem using
model.frame(), but the source of the error is the same.) The problem is
technical and concerns the design of poly(), which is why I'm sending this
message to r-devel rather than r-help.

To illustrate:

------------ snip -------------

> mod.pres <- lm(prestige ~ log(income, 10) + poly(education, 3) +
poly(women, 2), 
+                data=Prestige)  # Prestige data from car package

> predict(mod.pres, newdata=data.frame(education=10, income=6000, women=30))
# works
       1 
39.66414 

> model.frame(delete.response(terms(mod.pres)), data.frame(education=10,
income=6000, women=30))
  log(income, 10) poly(education, 3).1 poly(education, 3).2 poly(education,
3).3 poly(women, 2).1 poly(women, 2).2
1        3.778151          -0.02691558          -0.08720086
0.07199804      0.003202256     -0.138777837

> mod.pres.raw <- lm(prestige ~ log(income, 10) + poly(education, 3,
raw=TRUE) + poly(women, 2, raw=TRUE), 
+                    data=Prestige)

> predict(mod.pres.raw, newdata=data.frame(education=10, income=6000,
women=30)) # doesn't work
Error in poly(education, 3, raw = TRUE) : 
  'degree' must be less than number of unique points

> model.frame(delete.response(terms(mod.pres.raw)), data.frame(education=10,
income=6000, women=30))
Error in poly(education, 3, raw = TRUE) : 
  'degree' must be less than number of unique points

------------ snip -------------

I understand the source of the error, but what's unclear to me is why it's
necessary for poly() to check the degree of the polynomial against the
number of unique supplied points when raw=TRUE. For example, if I simply
remove this check from poly(), then

------------ snip -------------

> predict(mod.pres.raw, newdata=data.frame(education=10, income=6000,
women=30))
       1 
39.66414 

> model.frame(delete.response(terms(mod.pres.raw)), data.frame(education=10,
income=6000, women=30))
  log(income, 10) poly(education, 3, raw = TRUE).1 poly(education, 3, raw =
TRUE).2 poly(education, 3, raw = TRUE).3 poly(women, 2, raw = TRUE).1
poly(women, 2, raw = TRUE).2
1        3.778151                               10
100                             1000                           30
900

------------ snip -------------

Of course, if one then used the modified poly() in a regression with fewer
unique Xs than the degree of the polynomial, the model matrix would be
singular; but why not just let the error appear at that stage? 

I could solve my problem by maintaining a local version of poly(), but why
should it not be possible to get predictions under these circumstances?

Best,
 John

--------------------------------
John Fox
Senator William McMaster
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox


From mtmorgan at fhcrc.org  Thu Mar 15 05:48:15 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 14 Mar 2012 21:48:15 -0700
Subject: [Rd] methods::trace fails when signature specified
Message-ID: <4F61748F.6040009@fhcrc.org>

With

 > R.version.string
[1] "R version 2.15.0 alpha (2012-03-14 r58748)"

trying to trace a method using the 'signature' argument fails rather 
than enabling the trace:

 > trace(initialize, signature="ANY")
Error in matchSignature(signature, fdef, where) :
   trying to match a method signature of class ?signature?; expects a 
list or a character vector

-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Thu Mar 15 06:04:43 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 14 Mar 2012 22:04:43 -0700
Subject: [Rd] Dealing with printf() &c. in third-party library code
In-Reply-To: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>
References: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>
Message-ID: <4F61786B.6030200@fhcrc.org>

On 03/14/2012 05:15 AM, Jon Clayden wrote:
> Dear all,
>
> I recognise the reason for strongly discouraging use of printf() and
> similar C functions in R packages, but I wonder what people do in
> practice about third-party code which may be littered with such calls.
> I maintain a package (RNiftyReg) which provides an R interface to a
> third-party library which contains hundreds of calls to printf(...),
> fprintf(stderr,...) and similar. It seems to me that there are several
> possible approaches, but all have their issues:
>
> 1. Replace all such calls with equivalent Rprintf() calls, using
> compiler preprocessing directives to ensure the library does not
> become incompatible with other code. For example,
>
> #ifdef RNIFTYREG
> Rprintf(...);
> #else
> printf(...);
> #endif
>
> This will be very time-consuming if there are lots of calls, and also
> makes the code very untidy and much harder to update when a new
> version of the upstream library is released.
>
> 2. Remove all such calls from the code altogether, or comment them
> out. The problem here is that doing this safely is hard, because the
> call could be part of an "if" statement or similar. For example,
>
> if (test)
>   printf("Something");
> do_something_important;
>
> If the middle line here is removed, then the last line becomes
> (erroneously) conditioned on the test. Plus, once again, you are
> introducing a lot of small changes to the library itself.
>
> 3. Redefine printf to use Rprintf, viz.
>
> #ifdef RNIFTYREG
> #include<R.h>
> #define printf Rprintf
> #endif
>
> This will compile as long as the R function is a drop-in replacement
> for the original function, which I believe is true for Rprintf (vs.
> printf), but isn't true for Calloc (vs. calloc), for example. And I'm
> not sure whether this approach can be used to deal with cases of the
> form fprintf(stderr,...), where stderr would need to be redefined.
> This approach requires only modest changes to the library itself, but
> may be fragile to future changes in R.
>
> Are there any other (better?) alternatives? Any thoughts or advice
> would be appreciated.

In Makevars, I add -Dfprintf=my_fprintf to the pre-processor flags and 
then implement my_fprintf in a separate source file. This means that the 
source code of the 3rd party library is not touched, and there is some 
scope for re-mapping or otherwise intercepting function arguments. For 
abort and error, I throw an error that encourages the user to save and 
quit immediately, though this is far from ideal. I too would be 
interested in better practices for dealing with this, short of 
whole-sale modification of the third-party library.

Martin

>
> All the best,
> Jon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mdsumner at gmail.com  Thu Mar 15 07:29:38 2012
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 15 Mar 2012 17:29:38 +1100
Subject: [Rd] windows() device: plot does not refresh with new drawing after
 opening and closing a new device
Message-ID: <CAAcGz99QV+=YuovgMbjDd5vrXh6L-djf05Uj+H0e2BkGZnkncA@mail.gmail.com>

Hello,

I see this problem in 2.14.1, a recent dev, and 2.15.0 alpha, but not
in an older build.

Start the R windows console and run this code:

plot(1:10);windows();dev.off();points(10:1)

The second set of points does not show up until the window is
minimized and restored.

If the device is replaced with a file-based one (pdf, png) there's no problem.

I see this behaviour on these versions:

  R version 2.15.0 alpha (2012-03-13 r58726)
  Platform: x86_64-pc-mingw32/x64 (64-bit)

  R Under development (unstable) (2012-02-28 r58513)
  Platform: x86_64-pc-mingw32/x64 (64-bit)

  R version 2.14.1 (2011-12-22)
  Platform: x86_64-pc-mingw32/x64 (64-bit)

I have an old beta install of 2.13.2 where the problem does not occur:

  R version 2.13.2 beta (2011-09-22 r57035)
  Platform: x86_64-pc-mingw32/x64 (64-bit)

Cheers, Mike.


-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From murdoch.duncan at gmail.com  Thu Mar 15 11:54:26 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 15 Mar 2012 06:54:26 -0400
Subject: [Rd] windows() device: plot does not refresh with new drawing
 after opening and closing a new device
In-Reply-To: <CAAcGz99QV+=YuovgMbjDd5vrXh6L-djf05Uj+H0e2BkGZnkncA@mail.gmail.com>
References: <CAAcGz99QV+=YuovgMbjDd5vrXh6L-djf05Uj+H0e2BkGZnkncA@mail.gmail.com>
Message-ID: <4F61CA62.7040000@gmail.com>

On 12-03-15 2:29 AM, Michael Sumner wrote:
> Hello,
>
> I see this problem in 2.14.1, a recent dev, and 2.15.0 alpha, but not
> in an older build.
>
> Start the R windows console and run this code:
>
> plot(1:10);windows();dev.off();points(10:1)
>
> The second set of points does not show up until the window is
> minimized and restored.

Definitely looks like a bug.  I'll see if I can track it down.

Duncan Murdoch

>
> If the device is replaced with a file-based one (pdf, png) there's no problem.
>
> I see this behaviour on these versions:
>
>    R version 2.15.0 alpha (2012-03-13 r58726)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>    R Under development (unstable) (2012-02-28 r58513)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>    R version 2.14.1 (2011-12-22)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> I have an old beta install of 2.13.2 where the problem does not occur:
>
>    R version 2.13.2 beta (2011-09-22 r57035)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> Cheers, Mike.
>
>


From deepayan.sarkar at gmail.com  Thu Mar 15 18:51:51 2012
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 15 Mar 2012 23:21:51 +0530
Subject: [Rd] [ESS] completion in [] (R internal completion fails)
In-Reply-To: <87r4wv33ol.fsf_-_@gmail.com>
References: <87ipi7mtb2.fsf@med.uni-goettingen.de> <87399b4jld.fsf@gmail.com>
	<87r4wv33ol.fsf_-_@gmail.com>
Message-ID: <CADfFDC4gKALGtm-kwKrCmhMzRV=8CWuf96cqyhC0FTPv6S5xbw@mail.gmail.com>

On Wed, Mar 14, 2012 at 3:27 PM, Vitalie Spinu <spinuvit at gmail.com> wrote:
>
> Hello,
>
> I am forwarding this from ESS mailing list, as it's a failure of
> internal R completion system:
>
> This fails:
>
> utils:::.assignLinebuffer('iris[iris$Spec')
> utils:::.assignEnd(15)
> utils:::.guessTokenFromLine()
> utils:::.completeToken()
> utils:::.retrieveCompletions() ## -> [1] "iris[iris$Spec"
>
> This works
>
> utils:::.assignLinebuffer('iris[ iris$Spec') ?# note the space after [
> utils:::.assignEnd(15)
> utils:::.guessTokenFromLine()
> utils:::.completeToken()
> utils:::.retrieveCompletions() ## -> [1] "iris$Species"

This is controlled by

> getOption("rl_word_breaks")
[1] " \t\n\"\\'`><=%;,|&{()}"

Basically [ does not break words into tokens (space does). You can
change this to

options(rl_word_breaks = paste(getOption("rl_word_breaks"), "[]", sep = ""))

But then the following won't work:

> x = list(aaa = list(AAA = 1, BBB = 2))
> x[[1]]$A<TAB>

-Deepayan


> Best,
> Vitalie.
>
>>>>> Andreas Leha <andreas.leha at med.uni-goettingen.de>
>>>>> on Wed, 14 Mar 2012 10:21:37 +0100 wrote:
>
> ?>> Hi all,
> ?>> I am seeing strange behaviour with completion inside [].
>
> ?>> Suppose I have
> ?>> ttt <- data.frame(aaa=1, bbb=1)
> ?>> and I want to run
> ?>> ttt$aaa[ttt$aaa == 1] <- 2
>
> ?>> then completion at this point fails:
> ?>> ttt$aaa[ttt$aa<TAB>
>
> ?>> On the other hand, strangly enough, this works as expected:
> ?>> ttt$aaa[ ttt$aa<TAB>
>
> ?>> Regards,
> ?>> Andreas
>
> ?>> ______________________________________________
> ?>> ESS-help at r-project.org mailing list
> ?>> https://stat.ethz.ch/mailman/listinfo/ess-help
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Mar 15 19:34:30 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 15 Mar 2012 14:34:30 -0400
Subject: [Rd] windows() device: plot does not refresh with new drawing
 after opening and closing a new device
In-Reply-To: <CAAcGz99QV+=YuovgMbjDd5vrXh6L-djf05Uj+H0e2BkGZnkncA@mail.gmail.com>
References: <CAAcGz99QV+=YuovgMbjDd5vrXh6L-djf05Uj+H0e2BkGZnkncA@mail.gmail.com>
Message-ID: <4F623636.9090603@gmail.com>

On 15/03/2012 2:29 AM, Michael Sumner wrote:
> Hello,
>
> I see this problem in 2.14.1, a recent dev, and 2.15.0 alpha, but not
> in an older build.
>
> Start the R windows console and run this code:
>
> plot(1:10);windows();dev.off();points(10:1)
>
> The second set of points does not show up until the window is
> minimized and restored.
>
> If the device is replaced with a file-based one (pdf, png) there's no problem.

The problem is caused by events happening asynchronously:  the first 
device is made active before the second one is closed, and closing the 
second one cancels the pending updates.  We should be able to get it 
fixed before 2.15.0; in the meantime, a workaround is to call 
dev.flush(), e.g.

plot(1:10);windows();dev.off();points(10:1);dev.flush()

should be fine.

Duncan Murdoch

> I see this behaviour on these versions:
>
>    R version 2.15.0 alpha (2012-03-13 r58726)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>    R Under development (unstable) (2012-02-28 r58513)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>    R version 2.14.1 (2011-12-22)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> I have an old beta install of 2.13.2 where the problem does not occur:
>
>    R version 2.13.2 beta (2011-09-22 r57035)
>    Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> Cheers, Mike.
>
>


From jmc at r-project.org  Thu Mar 15 22:01:48 2012
From: jmc at r-project.org (John Chambers)
Date: Thu, 15 Mar 2012 14:01:48 -0700
Subject: [Rd] methods::trace fails when signature specified
In-Reply-To: <4F61748F.6040009@fhcrc.org>
References: <4F61748F.6040009@fhcrc.org>
Message-ID: <4F6258BC.2050306@r-project.org>

Thanks. Should be fixed in r-devel and 2.15 alpha from revision 58756.

(Nothing to do with trace() particularly.   Low-level code to create 
"signature" objects was not returning an S4 object.)


On 3/14/12 9:48 PM, Martin Morgan wrote:
> With
>
>  > R.version.string
> [1] "R version 2.15.0 alpha (2012-03-14 r58748)"
>
> trying to trace a method using the 'signature' argument fails rather
> than enabling the trace:
>
>  > trace(initialize, signature="ANY")
> Error in matchSignature(signature, fdef, where) :
> trying to match a method signature of class ?signature?; expects a list
> or a character vector
>


From jon.clayden at gmail.com  Thu Mar 15 22:24:17 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Thu, 15 Mar 2012 21:24:17 +0000
Subject: [Rd] Dealing with printf() &c. in third-party library code
In-Reply-To: <4F61786B.6030200@fhcrc.org>
References: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>
	<4F61786B.6030200@fhcrc.org>
Message-ID: <CAM9CR=2493iX8V4-5WXSC4461WoSVkWY_USs+J=RAYTCS-gY0w@mail.gmail.com>

Martin,

Thanks for your reply. I wonder if you'd be willing to post your
"my_fprintf" function, since I'm struggling to get around needing to
use the "stdout" and "stderr" symbols completely. This function has
the right effect...

void rniftyreg_fprintf (FILE *stream, const char *format, ...)
{
   va_list args;
   va_start(args, format);

   if (stream == stdout)
       Rvprintf(format, args);
   else if (stream == stderr)
       REvprintf(format, args);
   else
       vfprintf(stream, format, args);

   va_end(args);
}

... but the R CMD check info message still arises because stdout and
stderr still appear. I'm struggling to see how to get around this
without doing something really ugly, like casting integers to FILE*
pointers.

All the best,
Jon


On 15 March 2012 05:04, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> On 03/14/2012 05:15 AM, Jon Clayden wrote:
>>
>> Dear all,
>>
>> I recognise the reason for strongly discouraging use of printf() and
>> similar C functions in R packages, but I wonder what people do in
>> practice about third-party code which may be littered with such calls.
>> I maintain a package (RNiftyReg) which provides an R interface to a
>> third-party library which contains hundreds of calls to printf(...),
>> fprintf(stderr,...) and similar. It seems to me that there are several
>> possible approaches, but all have their issues:
>>
>> 1. Replace all such calls with equivalent Rprintf() calls, using
>> compiler preprocessing directives to ensure the library does not
>> become incompatible with other code. For example,
>>
>> #ifdef RNIFTYREG
>> Rprintf(...);
>> #else
>> printf(...);
>> #endif
>>
>> This will be very time-consuming if there are lots of calls, and also
>> makes the code very untidy and much harder to update when a new
>> version of the upstream library is released.
>>
>> 2. Remove all such calls from the code altogether, or comment them
>> out. The problem here is that doing this safely is hard, because the
>> call could be part of an "if" statement or similar. For example,
>>
>> if (test)
>> ?printf("Something");
>> do_something_important;
>>
>> If the middle line here is removed, then the last line becomes
>> (erroneously) conditioned on the test. Plus, once again, you are
>> introducing a lot of small changes to the library itself.
>>
>> 3. Redefine printf to use Rprintf, viz.
>>
>> #ifdef RNIFTYREG
>> #include<R.h>
>> #define printf Rprintf
>> #endif
>>
>> This will compile as long as the R function is a drop-in replacement
>> for the original function, which I believe is true for Rprintf (vs.
>> printf), but isn't true for Calloc (vs. calloc), for example. And I'm
>> not sure whether this approach can be used to deal with cases of the
>> form fprintf(stderr,...), where stderr would need to be redefined.
>> This approach requires only modest changes to the library itself, but
>> may be fragile to future changes in R.
>>
>> Are there any other (better?) alternatives? Any thoughts or advice
>> would be appreciated.
>
>
> In Makevars, I add -Dfprintf=my_fprintf to the pre-processor flags and then
> implement my_fprintf in a separate source file. This means that the source
> code of the 3rd party library is not touched, and there is some scope for
> re-mapping or otherwise intercepting function arguments. For abort and
> error, I throw an error that encourages the user to save and quit
> immediately, though this is far from ideal. I too would be interested in
> better practices for dealing with this, short of whole-sale modification of
> the third-party library.
>
> Martin
>
>>
>> All the best,
>> Jon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
> Location: M1-B861
> Telephone: 206 667-2793


From mdowle at mdowle.plus.com  Thu Mar 15 22:48:28 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 15 Mar 2012 21:48:28 -0000
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
Message-ID: <ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>


Anyone?

> Is it intended that the first suffix can no longer be blank? Seems to be
> caused by a bug fix to merge in R 2.15.0.
>
> $Rdevel --vanilla
> DF1 = data.frame(a=1:3,b=4:6)
> DF2 = data.frame(a=1:3,b=7:9)
> merge(DF1,DF2,by="a",suffixes=c("",".1"))
> Error in merge.data.frame(DF1, DF2, by = "a", suffixes = c("", ".1")) :
>   there is already a column named ?b?
>
> $R --vanilla
> R version 2.14.2 (2012-02-29)
>> DF1 = data.frame(a=1:3,b=4:6)
>> DF2 = data.frame(a=1:3,b=7:9)
>> merge(DF1,DF2,by="a",suffixes=c("",".1"))
>   a b b.1
> 1 1 4   7
> 2 2 5   8
> 3 3 6   9
>>
>
> Matthew
>


From mtmorgan at fhcrc.org  Fri Mar 16 01:48:30 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 15 Mar 2012 17:48:30 -0700
Subject: [Rd] Dealing with printf() &c. in third-party library code
In-Reply-To: <CAM9CR=2493iX8V4-5WXSC4461WoSVkWY_USs+J=RAYTCS-gY0w@mail.gmail.com>
References: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>	<4F61786B.6030200@fhcrc.org>
	<CAM9CR=2493iX8V4-5WXSC4461WoSVkWY_USs+J=RAYTCS-gY0w@mail.gmail.com>
Message-ID: <4F628DDE.9060808@fhcrc.org>

On 03/15/2012 02:24 PM, Jon Clayden wrote:
> Martin,
>
> Thanks for your reply. I wonder if you'd be willing to post your
> "my_fprintf" function, since I'm struggling to get around needing to
> use the "stdout" and "stderr" symbols completely. This function has
> the right effect...
>
> void rniftyreg_fprintf (FILE *stream, const char *format, ...)
> {
>     va_list args;
>     va_start(args, format);
>
>     if (stream == stdout)
>         Rvprintf(format, args);
>     else if (stream == stderr)
>         REvprintf(format, args);
>     else
>         vfprintf(stream, format, args);
>
>     va_end(args);
> }
>
> ... but the R CMD check info message still arises because stdout and
> stderr still appear. I'm struggling to see how to get around this
> without doing something really ugly, like casting integers to FILE*
> pointers.

Hi Jon --

My own implementation is like yours, where I still reference stderr / 
stdout. But it seems like the meaningful problem (writing to stderr / 
stdout, which R might have re-directed) has been addressed (except for 
the third branch, in your code above).

Martin
>
> All the best,
> Jon
>
>
> On 15 March 2012 05:04, Martin Morgan<mtmorgan at fhcrc.org>  wrote:
>> On 03/14/2012 05:15 AM, Jon Clayden wrote:
>>>
>>> Dear all,
>>>
>>> I recognise the reason for strongly discouraging use of printf() and
>>> similar C functions in R packages, but I wonder what people do in
>>> practice about third-party code which may be littered with such calls.
>>> I maintain a package (RNiftyReg) which provides an R interface to a
>>> third-party library which contains hundreds of calls to printf(...),
>>> fprintf(stderr,...) and similar. It seems to me that there are several
>>> possible approaches, but all have their issues:
>>>
>>> 1. Replace all such calls with equivalent Rprintf() calls, using
>>> compiler preprocessing directives to ensure the library does not
>>> become incompatible with other code. For example,
>>>
>>> #ifdef RNIFTYREG
>>> Rprintf(...);
>>> #else
>>> printf(...);
>>> #endif
>>>
>>> This will be very time-consuming if there are lots of calls, and also
>>> makes the code very untidy and much harder to update when a new
>>> version of the upstream library is released.
>>>
>>> 2. Remove all such calls from the code altogether, or comment them
>>> out. The problem here is that doing this safely is hard, because the
>>> call could be part of an "if" statement or similar. For example,
>>>
>>> if (test)
>>>   printf("Something");
>>> do_something_important;
>>>
>>> If the middle line here is removed, then the last line becomes
>>> (erroneously) conditioned on the test. Plus, once again, you are
>>> introducing a lot of small changes to the library itself.
>>>
>>> 3. Redefine printf to use Rprintf, viz.
>>>
>>> #ifdef RNIFTYREG
>>> #include<R.h>
>>> #define printf Rprintf
>>> #endif
>>>
>>> This will compile as long as the R function is a drop-in replacement
>>> for the original function, which I believe is true for Rprintf (vs.
>>> printf), but isn't true for Calloc (vs. calloc), for example. And I'm
>>> not sure whether this approach can be used to deal with cases of the
>>> form fprintf(stderr,...), where stderr would need to be redefined.
>>> This approach requires only modest changes to the library itself, but
>>> may be fragile to future changes in R.
>>>
>>> Are there any other (better?) alternatives? Any thoughts or advice
>>> would be appreciated.
>>
>>
>> In Makevars, I add -Dfprintf=my_fprintf to the pre-processor flags and then
>> implement my_fprintf in a separate source file. This means that the source
>> code of the 3rd party library is not touched, and there is some scope for
>> re-mapping or otherwise intercepting function arguments. For abort and
>> error, I throw an error that encourages the user to save and quit
>> immediately, though this is far from ideal. I too would be interested in
>> better practices for dealing with this, short of whole-sale modification of
>> the third-party library.
>>
>> Martin
>>
>>>
>>> All the best,
>>> Jon
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> Computational Biology
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>
>> Location: M1-B861
>> Telephone: 206 667-2793


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From nima.irt at gmail.com  Fri Mar 16 10:27:48 2012
From: nima.irt at gmail.com (Nima Mohammadi)
Date: Fri, 16 Mar 2012 12:57:48 +0330
Subject: [Rd] Segfault while calling fexact in C
Message-ID: <CAPpMX7Ro2aspvKUP2yOWXUzJ9XedLKs8kmeB8A_-Zhb057deUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120316/dec5ad8b/attachment.pl>

From jon.clayden at gmail.com  Fri Mar 16 12:30:59 2012
From: jon.clayden at gmail.com (Jon Clayden)
Date: Fri, 16 Mar 2012 11:30:59 +0000
Subject: [Rd] Dealing with printf() &c. in third-party library code
In-Reply-To: <4F628DDE.9060808@fhcrc.org>
References: <CAM9CR=2iwS1E3TFnh5y-SRCh5p3KEtSD1ChO7bVpXgMsRV_PrQ@mail.gmail.com>
	<4F61786B.6030200@fhcrc.org>
	<CAM9CR=2493iX8V4-5WXSC4461WoSVkWY_USs+J=RAYTCS-gY0w@mail.gmail.com>
	<4F628DDE.9060808@fhcrc.org>
Message-ID: <CAM9CR=2pnNcJsrtW1H3AMgG4-C8m9PFQaMpF4i=N34E=SxJSiA@mail.gmail.com>

On 16 March 2012 00:48, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> On 03/15/2012 02:24 PM, Jon Clayden wrote:
>>
>> Martin,
>>
>> Thanks for your reply. I wonder if you'd be willing to post your
>> "my_fprintf" function, since I'm struggling to get around needing to
>> use the "stdout" and "stderr" symbols completely. This function has
>> the right effect...
>>
>> void rniftyreg_fprintf (FILE *stream, const char *format, ...)
>> {
>> ? ?va_list args;
>> ? ?va_start(args, format);
>>
>> ? ?if (stream == stdout)
>> ? ? ? ?Rvprintf(format, args);
>> ? ?else if (stream == stderr)
>> ? ? ? ?REvprintf(format, args);
>> ? ?else
>> ? ? ? ?vfprintf(stream, format, args);
>>
>> ? ?va_end(args);
>> }
>>
>> ... but the R CMD check info message still arises because stdout and
>> stderr still appear. I'm struggling to see how to get around this
>> without doing something really ugly, like casting integers to FILE*
>> pointers.
>
>
> Hi Jon --
>
> My own implementation is like yours, where I still reference stderr /
> stdout. But it seems like the meaningful problem (writing to stderr /
> stdout, which R might have re-directed) has been addressed (except for the
> third branch, in your code above).

Yes, this certainly deals with the important issue - the check note
becomes a false positive. I need the third branch to allow things to
work properly for fprintf calls which write to actual files...

Thanks again,
Jon


From murdoch.duncan at gmail.com  Fri Mar 16 13:06:28 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Mar 2012 08:06:28 -0400
Subject: [Rd] Segfault while calling fexact in C
In-Reply-To: <CAPpMX7Ro2aspvKUP2yOWXUzJ9XedLKs8kmeB8A_-Zhb057deUg@mail.gmail.com>
References: <CAPpMX7Ro2aspvKUP2yOWXUzJ9XedLKs8kmeB8A_-Zhb057deUg@mail.gmail.com>
Message-ID: <4F632CC4.3040601@gmail.com>

On 12-03-16 5:27 AM, Nima Mohammadi wrote:
> Hi folks,
> I'm trying to call an R function (fisher.test) in my program for like a
> billion times! Though my program is in Python and I feel that using rpy2 to
> interface R to python doesn't give me satisfactory performance. So I looked
> into R code and found out that fisher.test is actually a wrapper around
> another function called fexact which is implemented in C. Using Cython I
> managed to directly call the function and get the desired results.
> But the weird problem is that after calling the function for like 4000
> times (with same parameters) a segmentation fault occurs! Eliminating the
> possibility that my interfacing code has any problem, I wrote a piece of
> code in C to call the fexact multiple times:

I don't think fexact is mentioned in Rmath.h, so it's not a function 
designed to be called from a standalone program.

Duncan Murdoch

>
> int main(){
>      int nr = 3, nc = 2;
>      int x[6] = {3, 1, 5, 1, 3, 6};
>      double expect = -1, percnt = 100, emin = 0, prt = 1;
>      double p;
>      int workspace = 200000, mult = 30;
>      int i;
>      for (i=0; i<100000; i++){
>          fexact(&nr,&nc, x,&nr,&expect,
>              &percnt,&emin,&prt,&p,&workspace,&mult);
>          printf("%d %f\n", i, p);
>      }
>      return 0;
> }
>
> I statically linked the program to libRmath, which I don't suppose has
> anything to do with problem. I also dynamically linked to libRmath.so which
> yielded the same problem.
>
> nima at nima-laptop:~/BioProject/fet$ gcc -I/usr/share/R/include -lm fexact.c
> /usr/lib/libRmath.a
>
> nima at nima-laptop:~/BioProject/fet$ ./a.out
> 0 0.408431
> 1 0.408431
> 2 0.408431
> 3 0.408431
> 4 0.408431
> ....
> ....
> 4003 0.408431
> 4004 0.408431
> 4005 0.408431
> Segmentation fault
>
> Any help would be highly appreciated :)
>
> *-- **Nima Mohammadi*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nima.irt at gmail.com  Fri Mar 16 13:41:28 2012
From: nima.irt at gmail.com (Nima Mohammadi)
Date: Fri, 16 Mar 2012 16:11:28 +0330
Subject: [Rd] Segfault while calling fexact in C
In-Reply-To: <4F632CC4.3040601@gmail.com>
References: <CAPpMX7Ro2aspvKUP2yOWXUzJ9XedLKs8kmeB8A_-Zhb057deUg@mail.gmail.com>
	<4F632CC4.3040601@gmail.com>
Message-ID: <CAPpMX7SH4hXigTXF9FQ6sSMn1i-xOp+qP_O=TDUKnOL8-vJYBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120316/527f21d1/attachment.pl>

From j.maspons at creaf.uab.cat  Fri Mar 16 18:41:37 2012
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Fri, 16 Mar 2012 18:41:37 +0100
Subject: [Rd] Beta binomial and Beta negative binomial
Message-ID: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>

Hi,
I need Beta binomial and Beta negative binomial functions but in R there is
only SuppDists package which provide this distributions using a limited
parameter space of the generalized hypergeometric distribution (dghyper & Co.)
which provide a limited parameter space for Beta binomial and Beta negative
binomial functions (e.g. alpha + beta <1 in the Beta negative binomial).

I've done a checkout to R svn to seek the code for the implementation of
distribution functions (dbinom et al.) but I haven't succeed. I don't know how
difficult could be to implement Beta binomial and Beta negative binomial
functions having the PDF  and CDF functions but I'm interested in implementing
it. I have programming skills but I don't know much about R internals.

Where is the code? Can I implement these new functions inside stats
package following the
same patterns as other probability distributions?

Yours,
-- 
Joan Maspons
CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
http://www.creaf.uab.cat


From dutangc at gmail.com  Fri Mar 16 20:34:43 2012
From: dutangc at gmail.com (Christophe Dutang)
Date: Fri, 16 Mar 2012 20:34:43 +0100
Subject: [Rd] Beta binomial and Beta negative binomial
In-Reply-To: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>
References: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>
Message-ID: <76F908AE-7BB0-40B8-A198-0BEA6EB18F53@gmail.com>

Hi,

Please look at the distribution task view (http://cran.r-project.org/web/views/Distributions.html) and the package gamlss.dist.

By the way, distributions in R are implemented in <source>/src/nmath directory and not <source>/src/library/stats

Regards

Christophe

--
Christophe Dutang
Ph.D. student at ISFA, Lyon, France
website: http://dutangc.free.fr

Le 16 mars 2012 ? 18:41, Joan Maspons a ?crit :

> Hi,
> I need Beta binomial and Beta negative binomial functions but in R there is
> only SuppDists package which provide this distributions using a limited
> parameter space of the generalized hypergeometric distribution (dghyper & Co.)
> which provide a limited parameter space for Beta binomial and Beta negative
> binomial functions (e.g. alpha + beta <1 in the Beta negative binomial).
> 
> I've done a checkout to R svn to seek the code for the implementation of
> distribution functions (dbinom et al.) but I haven't succeed. I don't know how
> difficult could be to implement Beta binomial and Beta negative binomial
> functions having the PDF  and CDF functions but I'm interested in implementing
> it. I have programming skills but I don't know much about R internals.
> 
> Where is the code? Can I implement these new functions inside stats
> package following the
> same patterns as other probability distributions?
> 
> Yours,
> -- 
> Joan Maspons
> CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
> Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
> Tel +34 93 581 2915            j.maspons at creaf.uab.cat
> http://www.creaf.uab.cat
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From freezhu8 at gmail.com  Sat Mar 17 15:56:17 2012
From: freezhu8 at gmail.com (zhu free)
Date: Sat, 17 Mar 2012 10:56:17 -0400
Subject: [Rd] How to install sqldf to R with version 2.10?
Message-ID: <CAOHYbfsaVOBNWwEa_cyahTepjXmDUV2qSXs-0RZeWJfWUTWmkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120317/cf905da1/attachment.pl>

From oliver at first.in-berlin.de  Sat Mar 17 16:35:22 2012
From: oliver at first.in-berlin.de (oliver)
Date: Sat, 17 Mar 2012 16:35:22 +0100
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
Message-ID: <20120317153522.GA4502@siouxsie>

Hello,

regarding the copying issue,
I would like to point to the 

"Writing R-Extensions" documentation.

There it is mentio9ned, that functions of extensions
that use the .C interface normally do get their arguments
pre-copied...


In section 5.2:

  "There can be up to 65 further arguments giving R objects to be
  passed to compiled code. Normally these are copied before being
  passed in, and copied again to an R list object when the compiled
  code returns."

But for the .Call and .Extension interfaces this is NOT the case.



In section 5.9:
  "The .Call and .External interfaces allow much more control, but
  they also impose much greater responsibilities so need to be used
  with care. Neither .Call nor .External copy their arguments. You
  should treat arguments you receive through these interfaces as
  read-only."


Why is read-only preferred?

Please, see the discussion in section 5.9.10.

It's mentioned there, that a copy of an object in the R-language
not necessarily doies a real copy of that object, but instead of
this, just a "rerference" to the real data is created (two names
referring to one bulk of data). That's typical functional
programming: not a variable, but a name (and possibly more than one
name) bound to an object.


Of course, if yo change the orgiginal named value, when there
would be no copy of it, before changing it, then both names
would refer to the changed data.
of course that is not, what is wanted.

But what you also can see in section 5.9.10 is, that
there already is a mechanism (reference counting) that allows
to distinguish between unnamed and named object.

So, this is directly adressing the points you have mentioned in your
examples.

So, at least in principial, R allows to do in-place modifications
of object with the .Call interface.

You seem to refer to the .C interface, and I had explored the .Call
interface. That's the reason why you may insist on "it's copyied
always" and I wondered, what you were talking about, because the
.Call interface allowed me rather C-like raw style of programming
(and the user of it to decide, if copying will be done or not).

The mechanism to descide, if copying should be done or not,
also is mentioined in section 5.9.10: NAMED and SET_NAMED macros.
with NAMED you can get the number of references.

But later in that section it is mentioned, that - at least for now -
NAMED always returns the value 2.


  "Currently all arguments to a .Call call will have NAMED set to 2,
  and so users must assume that they need to be duplicated before
  alteration."
               (section 5.9.10, last sentence)


So, the in-place modification can be done already with the .Call
intefcae for example. But the decision if it is safe or not
is not supported at the moment.

So the situation is somewhere between: "it is possible" and
"R does not support a safe decision if, what is possible, also
can be recommended".
At the moment R rather deprecates in-place modification by default
(the save way, and I agree with this default).

But it's not true, that R in general copies arguments.

But this seems to be true for the .C interface.

Maybe a lot of performance-/memory-problems can be solved
by rewriting already existing packages, by providing them
via .Call instead of .C.


Ciao,
   Oliver




On Tue, Mar 06, 2012 at 04:44:49PM +0000, William Dunlap wrote:
> S (and its derivatives and successors) promises that functions
> will not change their arguments, so in an expression like
>    val <- func(arg)
> you know that arg will not be changed.  You can
> do that by having func copy arg before doing anything,
> but that uses space and time that you want to conserve.
> If arg is not a named item in any environment then it
> should be fine to write over the original because there
> is no way the caller can detect that shortcut.  E.g., in
>     cx <- cos(runif(n))
> the cos function does not need to allocate new space for
> its output, it can just write over its input because, without
> a name attached to it, the caller has no way of looking
> at what runif(n) returned.  If you did
>     x <- runif(n)
>     cx <- cos(x)
> then cos would have to allocate new space for its output
> because overwriting its input would affect a subsequent
>     sum(x)
> I suppose that end-users and function-writers could learn
> to live with having to decide when to copy, but not having
> to make that decision makes S more pleasant (and safer) to use.
> I think that is a major reason that people are able to
> share S code so easily.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com 
> 
> > -----Original Message-----
> > From: oliver [mailto:oliver at first.in-berlin.de]
> > Sent: Tuesday, March 06, 2012 1:12 AM
> > To: William Dunlap
> > Cc: Herv? Pag?s; R-devel
> > Subject: Re: [Rd] Julia
> > 
> > On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
> > [...]
> > > I find R's (& S+'s & S's) copy-on-write-if-not-copying-would-be-discoverable-
> > > by-the-uer machanism for giving the allusion of pass-by-value a good way
> > > to structure the contract between the function writer and the function user.
> > [...]
> > 
> > 
> > Can you elaborate more on this,
> > especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
> > stuff?
> > 
> > What do you mean with discoverability of not-copying?
> > 
> > Ciao,
> >    Oliver


From josh.m.ulrich at gmail.com  Sat Mar 17 17:20:39 2012
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 17 Mar 2012 11:20:39 -0500
Subject: [Rd] How to install sqldf to R with version 2.10?
In-Reply-To: <CAOHYbfsaVOBNWwEa_cyahTepjXmDUV2qSXs-0RZeWJfWUTWmkw@mail.gmail.com>
References: <CAOHYbfsaVOBNWwEa_cyahTepjXmDUV2qSXs-0RZeWJfWUTWmkw@mail.gmail.com>
Message-ID: <CAPPM_gQtaUnwqWJy5g_9eVRnWYt65s8r-iKBeRNC9ohuefy6JQ@mail.gmail.com>

On Sat, Mar 17, 2012 at 9:56 AM, zhu free <freezhu8 at gmail.com> wrote:
> Hi,
> How to install sqldf to R with version 2.10? I used the R in the cluster of
> university and there seems no way to update the R version to 2.14. However,
> I do need sqldf. I tried to install and there is the problem of namespace.
> How could I solve the problem of namespace and run sqldf on R with version
> 2.10? Thank you!
>
Download and unpack the sqldf source, add a NAMESPACE file, then build
the Windows binary using R-2.10.x and Rtools210 or Rtools211.

All these steps are documented throughout the "Writing R Extensions" manual.
http://cran.r-project.org/doc/manuals/R-exts.html

HTH,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com

R/Finance 2012: Applied Finance with R
www.RinFinance.com


From ligges at statistik.tu-dortmund.de  Sat Mar 17 17:25:31 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 17 Mar 2012 17:25:31 +0100
Subject: [Rd] How to install sqldf to R with version 2.10?
In-Reply-To: <CAPPM_gQtaUnwqWJy5g_9eVRnWYt65s8r-iKBeRNC9ohuefy6JQ@mail.gmail.com>
References: <CAOHYbfsaVOBNWwEa_cyahTepjXmDUV2qSXs-0RZeWJfWUTWmkw@mail.gmail.com>
	<CAPPM_gQtaUnwqWJy5g_9eVRnWYt65s8r-iKBeRNC9ohuefy6JQ@mail.gmail.com>
Message-ID: <4F64BAFB.9090108@statistik.tu-dortmund.de>



On 17.03.2012 17:20, Joshua Ulrich wrote:
> On Sat, Mar 17, 2012 at 9:56 AM, zhu free<freezhu8 at gmail.com>  wrote:
>> Hi,
>> How to install sqldf to R with version 2.10? I used the R in the cluster of
>> university and there seems no way to update the R version to 2.14. However,
>> I do need sqldf. I tried to install and there is the problem of namespace.
>> How could I solve the problem of namespace and run sqldf on R with version
>> 2.10? Thank you!
>>
> Download and unpack the sqldf source, add a NAMESPACE file, then build
> the Windows binary using R-2.10.x and Rtools210 or Rtools211.


I don't think the OP is using Windows on a cluster.
The point is that the new sqldf may not be compatible with the old 
release of R - and I don't have such an old versionarounf for testing. 
Anyway: Go to CRAN and the package's archive, you will find old versions 
of the package that may work with the old R-2.10.x

Uwe Ligges




> All these steps are documented throughout the "Writing R Extensions" manual.
> http://cran.r-project.org/doc/manuals/R-exts.html
>
> HTH,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>
> R/Finance 2012: Applied Finance with R
> www.RinFinance.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sat Mar 17 17:26:25 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 17 Mar 2012 17:26:25 +0100
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
	<ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
Message-ID: <4F64BB31.7060609@statistik.tu-dortmund.de>



On 15.03.2012 22:48, Matthew Dowle wrote:
>
> Anyone?
>
>> Is it intended that the first suffix can no longer be blank? Seems to be
>> caused by a bug fix to merge in R 2.15.0.


Right, the user is now protected against confusing himself by using 
names that were not unique before the merge.

Uwe Ligges



>> $Rdevel --vanilla
>> DF1 = data.frame(a=1:3,b=4:6)
>> DF2 = data.frame(a=1:3,b=7:9)
>> merge(DF1,DF2,by="a",suffixes=c("",".1"))
>> Error in merge.data.frame(DF1, DF2, by = "a", suffixes = c("", ".1")) :
>>    there is already a column named ?b?
>>
>> $R --vanilla
>> R version 2.14.2 (2012-02-29)
>>> DF1 = data.frame(a=1:3,b=4:6)
>>> DF2 = data.frame(a=1:3,b=7:9)
>>> merge(DF1,DF2,by="a",suffixes=c("",".1"))
>>    a b b.1
>> 1 1 4   7
>> 2 2 5   8
>> 3 3 6   9
>>>
>>
>> Matthew
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Mar 17 17:44:19 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Mar 2012 16:44:19 +0000
Subject: [Rd] How to install sqldf to R with version 2.10?
In-Reply-To: <4F64BAFB.9090108@statistik.tu-dortmund.de>
References: <CAOHYbfsaVOBNWwEa_cyahTepjXmDUV2qSXs-0RZeWJfWUTWmkw@mail.gmail.com>
	<CAPPM_gQtaUnwqWJy5g_9eVRnWYt65s8r-iKBeRNC9ohuefy6JQ@mail.gmail.com>
	<4F64BAFB.9090108@statistik.tu-dortmund.de>
Message-ID: <4F64BF63.1080008@stats.ox.ac.uk>

On 17/03/2012 16:25, Uwe Ligges wrote:
>
>
> On 17.03.2012 17:20, Joshua Ulrich wrote:
>> On Sat, Mar 17, 2012 at 9:56 AM, zhu free<freezhu8 at gmail.com> wrote:
>>> Hi,
>>> How to install sqldf to R with version 2.10? I used the R in the
>>> cluster of
>>> university and there seems no way to update the R version to 2.14.
>>> However,
>>> I do need sqldf. I tried to install and there is the problem of
>>> namespace.
>>> How could I solve the problem of namespace and run sqldf on R with
>>> version
>>> 2.10? Thank you!
>>>
>> Download and unpack the sqldf source, add a NAMESPACE file, then build
>> the Windows binary using R-2.10.x and Rtools210 or Rtools211.
>
>
> I don't think the OP is using Windows on a cluster.
> The point is that the new sqldf may not be compatible with the old

And in any case, there is no 'R 2.10', as the posting guide points out.

> release of R - and I don't have such an old version around for testing.
> Anyway: Go to CRAN and the package's archive, you will find old versions
> of the package that may work with the old R-2.10.x

And possibly older versions of all the packages it depends on/imports to.

But, I do have R 2.10.1 around, so I can reproduce the problem:
* installing *source* package ?sqldf? ...
** R
** demo
** inst
** preparing package for lazy loading
Loading required package: proto
Error : package 'gsubfn' does not have a name space
ERROR: lazy loading failed for package ?sqldf?

So the unstated problem is that sqldf does not work with gsubfn in R < 
2.14.0.  And the solution as Uwe said is to use an older version of 
sqldf (at least).

'zhu free' really does need to study the posting guide at 
http://www.r-project.org/posting-guide.html, and learn to post 
answerable questions.

> Uwe Ligges
>
>
>
>
>> All these steps are documented throughout the "Writing R Extensions"
>> manual.
>> http://cran.r-project.org/doc/manuals/R-exts.html
>>
>> HTH,
>> --
>> Joshua Ulrich | FOSS Trading: www.fosstrading.com


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ken.knoblauch at inserm.fr  Sat Mar 17 18:03:07 2012
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 17 Mar 2012 18:03:07 +0100
Subject: [Rd] parApply vs parCapply
Message-ID: <20120317180307.ny4zemnj4gwoowww@imp.inserm.fr>

I've started to use the parallel package and it works very well speeding
things up.  Thank you for making this easy to do.

Should I have expected that parCapply would return a vector
when parApply returns a matrix?

library(parallel)

x <- matrix(rnorm(8), nc = 2)
apply(x, 2, function(y) y)

            [,1]       [,2]
[1,] -0.9649685 0.91339851
[2,] -1.4313140 0.13457671
[3,]  1.0499248 1.58967879
[4,] -1.8974411 0.03639876

cl <- makeCluster(getOption("cl.cores", detectCores()))
parApply(cl, x, 2, function(y) y)

            [,1]       [,2]
[1,] -0.9649685 0.91339851
[2,] -1.4313140 0.13457671
[3,]  1.0499248 1.58967879
[4,] -1.8974411 0.03639876

parCapply(cl, x, function(y) y)

[1] -0.96496852 -1.43131396  1.04992479 -1.89744113  0.91339851  0.13457671
[7]  1.58967879  0.03639876

stopCluster(cl)

> sessionInfo()
R version 2.15.0 beta (2012-03-15 r58760)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

Thank you.

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From j.maspons at creaf.uab.cat  Sat Mar 17 19:38:41 2012
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Sat, 17 Mar 2012 19:38:41 +0100
Subject: [Rd] Beta binomial and Beta negative binomial
In-Reply-To: <76F908AE-7BB0-40B8-A198-0BEA6EB18F53@gmail.com>
References: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>
	<76F908AE-7BB0-40B8-A198-0BEA6EB18F53@gmail.com>
Message-ID: <CANF72pOnJSrAgTcu0FfHS=qD0zAwDHgGBh_qoAsinLv_4QHNaw@mail.gmail.com>

Hello,


El 16 de mar? de 2012 20:34, Christophe Dutang <dutangc at gmail.com> ha escrit:
> Hi,
>
> Please look at the distribution task view (http://cran.r-project.org/web/views/Distributions.html) and the package gamlss.dist.

Thanks for the tip. There are Beta binomial functions but they don't
have the number of trials parameter so I supose it's a Beta Bernoulli
distribution.

>
> Regards
>
> Christophe
>
> --
> Christophe Dutang
> Ph.D. student at ISFA, Lyon, France
> website: http://dutangc.free.fr
>
> Le 16 mars 2012 ? 18:41, Joan Maspons a ?crit :
>
>> Hi,
>> I need Beta binomial and Beta negative binomial functions ...
>>
>> Can I implement these new functions inside stats
>> package following the
>> same patterns as other probability distributions?
>>
>> Yours,
>> --
>> Joan Maspons

I have implemented a prototype of the beta negative binomial:

FindParamBetaDist<- function(mu, sigma){ # return(data.frame(a=shape1,b=shape2))
# mu<- a/(a+b)          [mean]
# sigma<- ab/((a+b)^2 (a+b+1))  [variance]
# Maxima: solve([mu= a/(a+b) , sigma= a*b/((a+b)^2 * (a+b+1))], [a,b]);
  a<-  -(mu * sigma + mu^3 - mu^2) / sigma
  b<- ((mu-1) * sigma + mu^3 - 2 * mu^2 + mu) / sigma
  if (a <= 0 | b <= 0) return (NA)
  return (data.frame(a,b))
}

#Rmpfr::pochMpfr()?
pochhammer<- function (x, n){
    return (gamma(x+n)/gamma(x))
}

# PMF:
# P (X = x) = ((alpha)_n (n)_x (beta)_x)/(x! (alpha+beta)_n
(n+alpha+beta)_x) |  for  | x>=0
# (a)_b Pochhammer symbol
dbetanbinom<- function(x, size, mu, sigma){
    param<- FindParamBetaDist(mu, sigma)
    if (is.na(sum(param))) return (NA) #invalid Beta parameters
    if (length(which(x<0))) res<- 0
    else
        res<- (pochhammer(param$a, size) * pochhammer(size, x) *
pochhammer(param$b, x)
            / (factorial(x) * pochhammer(param$a + param$b, size)
            * pochhammer(size + param$a + param$b, x)))
    return (res)
}

curve(dbetanbinom(x, size=12, mu=0.75, sigma=.1), from=0, to=24, n=25, type="p")

# CDF:
# P (X<=x) = 1-(Gamma(n+floor(x)+1) beta(n+alpha, beta+floor(x)+1)
#            genhypergeo(1, n+floor(x)+1, beta+floor(x)+1;floor(x)+2,
n+alpha+beta+floor(x)+1;1))
#            /(Gamma(n) beta(alpha, beta) Gamma(floor(x)+2)) |  for  | x>=0
pbetanbinom<- function(q, size, mu, sigma){
    require(hypergeo)
    param<- FindParamBetaDist(mu, sigma)
    if (is.na(sum(param))) return (NA) #invalid Beta parameters
    res<- numeric(length(q))
    for (i in 1:length(q)){
        if (q[i]<0) res[i]<- 0
        else res[i]<- (1-(gamma(size+floor(q[i])+1) *
beta(size+param$a, param$b+floor(q[i])+1)
        * genhypergeo(c(1, 1+size+floor(q[i]), 1+param$b+floor(q[i])),
c(2+floor(q[i]),1+size+param$a+param$b+floor(q[i])), 1))
        / (beta(param$a, param$b) * gamma(size) * gamma(2+floor(q[i]))))
    }
    return (res)
}

## genhypergeo not converge. Increase iterations or tolerance?
pbetanbinom(0:10x, size=20, mu=0.75, sigma=0.03)

I have to investigate
http://mathworld.wolfram.com/GeneralizedHypergeometricFunction.html
Any tip on how to solve the problem?


-- 
Joan Maspons
CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
http://www.creaf.uab.cat


From ripley at stats.ox.ac.uk  Sat Mar 17 19:51:41 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Mar 2012 18:51:41 +0000
Subject: [Rd] parApply vs parCapply
In-Reply-To: <20120317180307.ny4zemnj4gwoowww@imp.inserm.fr>
References: <20120317180307.ny4zemnj4gwoowww@imp.inserm.fr>
Message-ID: <4F64DD3D.4090209@stats.ox.ac.uk>

On 17/03/2012 17:03, Ken Knoblauch wrote:
> I've started to use the parallel package and it works very well speeding
> things up. Thank you for making this easy to do.
>
> Should I have expected that parCapply would return a vector
> when parApply returns a matrix?

Maybe: I would have expected so, and AFAICS ?parCapply does not say what 
the value is so it is unspecified.  We probably should document it.

> library(parallel)
>
> x <- matrix(rnorm(8), nc = 2)
> apply(x, 2, function(y) y)
>
> [,1] [,2]
> [1,] -0.9649685 0.91339851
> [2,] -1.4313140 0.13457671
> [3,] 1.0499248 1.58967879
> [4,] -1.8974411 0.03639876
>
> cl <- makeCluster(getOption("cl.cores", detectCores()))
> parApply(cl, x, 2, function(y) y)
>
> [,1] [,2]
> [1,] -0.9649685 0.91339851
> [2,] -1.4313140 0.13457671
> [3,] 1.0499248 1.58967879
> [4,] -1.8974411 0.03639876
>
> parCapply(cl, x, function(y) y)
>
> [1] -0.96496852 -1.43131396 1.04992479 -1.89744113 0.91339851 0.13457671
> [7] 1.58967879 0.03639876
>
> stopCluster(cl)
>
>> sessionInfo()
> R version 2.15.0 beta (2012-03-15 r58760)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] parallel stats graphics grDevices utils datasets methods
> [8] base
>
> Thank you.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tim.triche at gmail.com  Sun Mar 18 02:46:21 2012
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Sat, 17 Mar 2012 18:46:21 -0700
Subject: [Rd] Beta binomial and Beta negative binomial
In-Reply-To: <CANF72pOnJSrAgTcu0FfHS=qD0zAwDHgGBh_qoAsinLv_4QHNaw@mail.gmail.com>
References: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>
	<76F908AE-7BB0-40B8-A198-0BEA6EB18F53@gmail.com>
	<CANF72pOnJSrAgTcu0FfHS=qD0zAwDHgGBh_qoAsinLv_4QHNaw@mail.gmail.com>
Message-ID: <CAC+N9BWHxC71r2kdt6=AgexzmvAUwgRGshK0Nd4wn9wQ5k7FKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120317/44d9f267/attachment.pl>

From oliver at first.in-berlin.de  Sun Mar 18 03:30:52 2012
From: oliver at first.in-berlin.de (oliver)
Date: Sun, 18 Mar 2012 03:30:52 +0100
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
Message-ID: <20120318023052.GB13699@siouxsie>

Hello,

when looking at "Writing R Extensions"
with mem-allocation in mind, I wondered,
which functions to use to substitute
malloc(), calloc(), realloc() and strdup() and free().

It looked like Calloc() or R_Calloc() might be useful for
some of my tasks, but when trying to use R_Calloc() for example,
I got some error messages which I don't see where they are coming from.

Maybe I just have forgotten to includ ethe right header file?

So, how to use Calloc() / R_Calloc()?
What is the prototype of this function/macro?

And: what if I just want to easily substitute strdup()/free()?

mkChar seems not to be the right thing, because, what I found in the
above mentioned documentation, says,m that a C-string is fed in, but
CHARSXP is what I get as result.

What I try to do, is, to pick some code and port it to R.
If I need to rewrite a lot of stuff, just because I need
to adapt to R, this would be more effort than if it would be possible
just to have some functions, that could make porting easier.

For example, if I want to resuse a function, that opens a file
and needs a   char* stringname
then it would add more effort if I need to go via CHARSXP or so.

I would need to rewrite many pieces of the code.

(Should I implement my own kind of R_str_alloc() ?)


My main problem at the moemnt is, that I can use R_alloc()
but when I try to use Calloc() or R_Calloc() I can't compile.

So, what header-files are necessary, and what are the prototypes
of these functions?

If nothing of that stuff works, I would need to use the original
calloc() / free() functions, which are deprecated in the above
mentioned manual.


Ciao,
   Oliver

P.S.: Also I wonder... R-alloc() does not need a free()-like call?
      Is it freed automaticlaly?
      And at which time?
      In the docs is mentioned, at the end of the .C/.Call/.External call.
      Does this mean, this is freed/reclaimed automatically, when returning
      from the C-world to the R-world?
      At (after) return of the extension's code?


From edd at debian.org  Sun Mar 18 04:08:05 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 17 Mar 2012 22:08:05 -0500
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
In-Reply-To: <20120318023052.GB13699@siouxsie>
References: <20120318023052.GB13699@siouxsie>
Message-ID: <20325.20885.364933.666819@max.nulle.part>


On 18 March 2012 at 03:30, oliver wrote:
| Hello,
| 
| when looking at "Writing R Extensions"
| with mem-allocation in mind, I wondered,
| which functions to use to substitute
| malloc(), calloc(), realloc() and strdup() and free().
| 
| It looked like Calloc() or R_Calloc() might be useful for
| some of my tasks, but when trying to use R_Calloc() for example,
| I got some error messages which I don't see where they are coming from.
| 
| Maybe I just have forgotten to includ ethe right header file?

Maybe, but we can't tell as you didn't post a reproducible example. Here is
one, and I turned verbose on to give you the (default) headers:

R> library(inline)
R> 
R> f <- cfunction(signature(), verbose=TRUE, body='
+    double *p = Calloc(5, double);
+    Free(p);
+    return R_NilValue;
+ ')
Compilation argument:
 /usr/lib/R/bin/R CMD SHLIB file25df49ab1ccf.cpp 2> file25df49ab1ccf.cpp.err.txt 
ccache g++-4.6 -I/usr/share/R/include      -fpic  -g0 -O3 -Wall -pipe -Wno-unused -pedantic -c file25df49ab1ccf.cpp -o file25df49ab1ccf.o
g++ -shared -o file25df49ab1ccf.so file25df49ab1ccf.o -L/usr/lib/R/lib -lR
Program source:
  1: #include <R.h>
  2: #include <Rdefines.h>
  3: #include <R_ext/Error.h>
  4: 
  5: 
  6: extern "C" {
  7:   SEXP file25df49ab1ccf (  );
  8: }
  9: 
 10: SEXP file25df49ab1ccf (  ) {
 11: 
 12:    double *p = Calloc(5, double);
 13:    Free(p);
 14:    return R_NilValue;
 15: 
 16:   warning("your C program does not return anything!");
 17:   return R_NilValue;
 18: }
R> 
R> str(f())
 NULL
R> 


Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From simon.urbanek at r-project.org  Sun Mar 18 04:47:24 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 17 Mar 2012 23:47:24 -0400
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
In-Reply-To: <20120318023052.GB13699@siouxsie>
References: <20120318023052.GB13699@siouxsie>
Message-ID: <D83F333D-7CC3-4973-BD0B-F7F08E82F4E4@r-project.org>


On Mar 17, 2012, at 10:30 PM, oliver wrote:

> Hello,
> 
> when looking at "Writing R Extensions"
> with mem-allocation in mind, I wondered,
> which functions to use to substitute
> malloc(), calloc(), realloc() and strdup() and free().
> 
> It looked like Calloc() or R_Calloc() might be useful for
> some of my tasks, but when trying to use R_Calloc() for example,
> I got some error messages which I don't see where they are coming from.
> 
> Maybe I just have forgotten to includ ethe right header file?
> 

Very likely.

#include <R.h>

... you'll need that in any case, obviously.


> So, how to use Calloc() / R_Calloc()?
> What is the prototype of this function/macro?
> 

See R-ext 6.1.2 (or the headers - whichever you prefer).


> And: what if I just want to easily substitute strdup()/free()?
> 

You can always define Strdup() since strdup() is just a shorthand for malloc()+strcpy() -- in fact in R it's easier since Calloc will never return NULL so trivially
#define Strdup(X) strcpy(Calloc(strlen(X)+1, char), X)

But when using Calloc be aware that you have to clean up -- even if there is an error (which is why it is generally not a good idea to use Calloc for anything but memory you want to keep beyond your call).

There are two reasons for removing malloc/calloc: a) R uses custom allocators on systems with poor OS allocators (like Windows) so R's allocation is more efficient [and combining different allocators even worsens the performance] and b) you should think twice about the life span of your objects under error conditions. It is quite challenging to keep that straight, so in most cases it is better to use managed memory instead (but there is a performance trade-off). There are still valid reasons for not using R's allocators, but those are special cases that the author must be conscious about (after weighing the options).


> mkChar seems not to be the right thing, because, what I found in the
> above mentioned documentation, says,m that a C-string is fed in, but
> CHARSXP is what I get as result.
> 
> What I try to do, is, to pick some code and port it to R.
> If I need to rewrite a lot of stuff, just because I need
> to adapt to R, this would be more effort than if it would be possible
> just to have some functions, that could make porting easier.
> 
> For example, if I want to resuse a function, that opens a file
> and needs a   char* stringname
> then it would add more effort if I need to go via CHARSXP or so.
> 

I'm not sure where you are going with this, since all strings will already come as CHARSXPs from R so typically you don't need to allocate anything. The only reason to allocate is to create persistent objects (for which you'd use Calloc) - your example doesn't fit here...


> I would need to rewrite many pieces of the code.
> 
> (Should I implement my own kind of R_str_alloc() ?)
> 
> 
> My main problem at the moemnt is, that I can use R_alloc()
> but when I try to use Calloc() or R_Calloc() I can't compile.
> 
> So, what header-files are necessary, and what are the prototypes
> of these functions?
> 

See above.


> If nothing of that stuff works, I would need to use the original
> calloc() / free() functions, which are deprecated in the above
> mentioned manual.
> 
> 
> Ciao,
>   Oliver
> 
> P.S.: Also I wonder... R-alloc() does not need a free()-like call?
>      Is it freed automaticlaly?
>      And at which time?
>      In the docs is mentioned, at the end of the .C/.Call/.External call.
>      Does this mean, this is freed/reclaimed automatically, when returning
>      from the C-world to the R-world?
>      At (after) return of the extension's code?
> 

Yes. It simply uses an R object so it is subject to regular R object rules and thus gets cleaned up on error as well (unlike anything you use Calloc for).

Cheers,
Simon


From oliver at first.in-berlin.de  Sun Mar 18 06:16:11 2012
From: oliver at first.in-berlin.de (oliver)
Date: Sun, 18 Mar 2012 06:16:11 +0100
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
In-Reply-To: <20325.20885.364933.666819@max.nulle.part>
References: <20120318023052.GB13699@siouxsie>
	<20325.20885.364933.666819@max.nulle.part>
Message-ID: <20120318051611.GA20315@siouxsie>

On Sat, Mar 17, 2012 at 10:08:05PM -0500, Dirk Eddelbuettel wrote:
> 
> On 18 March 2012 at 03:30, oliver wrote:
> | Hello,
> | 
> | when looking at "Writing R Extensions"
> | with mem-allocation in mind, I wondered,
> | which functions to use to substitute
> | malloc(), calloc(), realloc() and strdup() and free().
> | 
> | It looked like Calloc() or R_Calloc() might be useful for
> | some of my tasks, but when trying to use R_Calloc() for example,
> | I got some error messages which I don't see where they are coming from.
> | 
> | Maybe I just have forgotten to includ ethe right header file?
> 
> Maybe, but we can't tell as you didn't post a reproducible example. Here is
> one, and I turned verbose on to give you the (default) headers:
[...]

It was not a missing header-file.



> 
> R> library(inline)
> R> 
> R> f <- cfunction(signature(), verbose=TRUE, body='
> +    double *p = Calloc(5, double);
[...]

That line cleared the issue.
Thank you for providing an example.

When reading in the documentation I was not sure,
how to interpret "type" in setion 6.1.2.

It was meant as the name of the type, and that's, why my
sizeof() stuff created the problem.

I tried around and then saw, that the name of the type
is accepted, not only with typical base-types of C, but
it also eats the names of my structs/typedefed structs.

OK, so this is the solution... Calloc()'s snd arg is
a name of a type. So I assume it will internally use sizeof.

As this is rather untypical to the C-ish thinking,
and also not aequivalent to the calloc() which is
substituted by calloc(),
I think, it would be good, if this could be explained
clearer / more precise in the Writing Extensions document.

For example the R_alloc() prototype is like the one from calloc(). (*)
But Calloc() is different here.
My first impression was, that it's rather an accident / typo,
what was described in the docs, because it was a bit unusual.


The usage with names of types is nice; but explaining,
that this is not a typo, would be good too.


Ciao,
   Oliver

P.S.: (*) Not quite right: calloc() returns void*,
          but R_alloc() is mentioned to return char*.
          Here I'm also not sure if this is a typo,
          and one reason, why I thought the "type"
          in the following section might also be one.


From patrick.giraudoux at univ-fcomte.fr  Sun Mar 18 11:21:47 2012
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Mar 2012 11:21:47 +0100
Subject: [Rd] Namespace dependency not required
Message-ID: <4F65B73B.8010809@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120318/8c68651e/attachment.pl>

From j.maspons at creaf.uab.cat  Sun Mar 18 12:36:07 2012
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Sun, 18 Mar 2012 12:36:07 +0100
Subject: [Rd] Beta binomial and Beta negative binomial
In-Reply-To: <CAC+N9BWHxC71r2kdt6=AgexzmvAUwgRGshK0Nd4wn9wQ5k7FKQ@mail.gmail.com>
References: <CANF72pP7nw_nuoSz+P7j-jt5qtm2ohqmyX=tnWdNL=n3LG7=2Q@mail.gmail.com>
	<76F908AE-7BB0-40B8-A198-0BEA6EB18F53@gmail.com>
	<CANF72pOnJSrAgTcu0FfHS=qD0zAwDHgGBh_qoAsinLv_4QHNaw@mail.gmail.com>
	<CAC+N9BWHxC71r2kdt6=AgexzmvAUwgRGshK0Nd4wn9wQ5k7FKQ@mail.gmail.com>
Message-ID: <CANF72pOsVL6rw554zb5dpVuenpUq4ftz_u+bEYeC3Uv5XXekCQ@mail.gmail.com>

El 18 de mar? de 2012 2:46, Tim Triche, Jr. <tim.triche at gmail.com> ha escrit:
> use the gsl package for Kummer's hypergeometric and others.

I looks nice but I'm a little bit lost. Gsl have 10 hypergeometric functions:

hyperg_0F1(c, x, give=FALSE, strict=TRUE)
*hyperg_1F1_int(m, n, x, give=FALSE, strict=TRUE)
*hyperg_1F1(a, b, x, give=FALSE, strict=TRUE)
**hyperg_U_int(m, n, x, give=FALSE, strict=TRUE)
*hyperg_U(a, b, x, give=FALSE, strict=TRUE)
hyperg_2F1(a, b, c, x, give=FALSE, strict=TRUE)
hyperg_2F1_conj(aR, aI, c, x, give=FALSE, strict=TRUE)
hyperg_2F1_renorm(a, b, c, x, give=FALSE, strict=TRUE)
hyperg_2F1_conj_renorm(aR, aI, c, x, give=FALSE, strict=TRUE)
*hyperg_2F0(a, b, x, give=FALSE, strict=TRUE)

* functions with the same number of parameters
** functions with the swame number of parameters and types (a,b,c,x<-
integer, m,n<- real)
genhypergeo(c(1, 1+size+floor(q[i]), 1+param$b+floor(q[i])),
c(2+floor(q[i]),1+size+param$a+param$b+floor(q[i])), 1)
genhypergeo(c(int, int, real), c(int,real), 1)

I picked the hyperg_U_int(c(1,2,2.5),c(2,3.1),1) but this give a
vector of three numbers and a warning. I'm not mathematician and this
seems to much for me. Which function is the equivalent to
Mathematica's HypergeometricPQF [1,2]?

> you might find implementing the distributions in C or C++ worthwhile for
> speed.

I would like to but with the dependences I don't think it will fit
R-base. Is there any package who want to include these distributions
(BB and BNB)?

> thanks for doing this, by the way.
>
>
>
> On Sat, Mar 17, 2012 at 11:38 AM, Joan Maspons <j.maspons at creaf.uab.cat>
> wrote:
>>
>> Hello,
>>
>>
>> El 16 de mar? de 2012 20:34, Christophe Dutang <dutangc at gmail.com> ha
>> escrit:
>> > Hi,
>> >
>> > Please look at the distribution task view
>> > (http://cran.r-project.org/web/views/Distributions.html) and the package
>> > gamlss.dist.
>>
>> Thanks for the tip. There are Beta binomial functions but they don't
>> have the number of trials parameter so I suppose it's a Beta Bernoulli
>> distribution.
>>
>> >
>> > Regards
>> >
>> > Christophe
>> >
>> > --
>> > Christophe Dutang
>> > Ph.D. student at ISFA, Lyon, France
>> > website: http://dutangc.free.fr
>> >
>> > Le 16 mars 2012 ? 18:41, Joan Maspons a ?crit :
>> >
>> >> Hi,
>> >> I need Beta binomial and Beta negative binomial functions ...
>> >>
>> >> Can I implement these new functions inside stats
>> >> package following the
>> >> same patterns as other probability distributions?
>> >>
>> >> Yours,
>> >> --
>> >> Joan Maspons
>>
>> I have implemented a prototype of the beta negative binomial:
>>
>> FindParamBetaDist<- function(mu, sigma){ #
>> return(data.frame(a=shape1,b=shape2))
>> # mu<- a/(a+b) ? ? ? ? ?[mean]
>> # sigma<- ab/((a+b)^2 (a+b+1)) ?[variance]
>> # Maxima: solve([mu= a/(a+b) , sigma= a*b/((a+b)^2 * (a+b+1))], [a,b]);
>> ?a<- ?-(mu * sigma + mu^3 - mu^2) / sigma
>> ?b<- ((mu-1) * sigma + mu^3 - 2 * mu^2 + mu) / sigma
>> ?if (a <= 0 | b <= 0) return (NA)
>> ?return (data.frame(a,b))
>> }
>>
>> #Rmpfr::pochMpfr()?
>> pochhammer<- function (x, n){
>> ? ?return (gamma(x+n)/gamma(x))
>> }
>>
>> # PMF:
>> # P (X = x) = ((alpha)_n (n)_x (beta)_x)/(x! (alpha+beta)_n
>> (n+alpha+beta)_x) | ?for ?| x>=0
>> # (a)_b Pochhammer symbol
>> dbetanbinom<- function(x, size, mu, sigma){
>> ? ?param<- FindParamBetaDist(mu, sigma)
>> ? ?if (is.na(sum(param))) return (NA) #invalid Beta parameters
>> ? ?if (length(which(x<0))) res<- 0
>> ? ?else
>> ? ? ? ?res<- (pochhammer(param$a, size) * pochhammer(size, x) *
>> pochhammer(param$b, x)
>> ? ? ? ? ? ?/ (factorial(x) * pochhammer(param$a + param$b, size)
>> ? ? ? ? ? ?* pochhammer(size + param$a + param$b, x)))
>> ? ?return (res)
>> }
>>
>> curve(dbetanbinom(x, size=12, mu=0.75, sigma=.1), from=0, to=24, n=25,
>> type="p")
>>
>> # CDF:
>> # P (X<=x) = 1-(Gamma(n+floor(x)+1) beta(n+alpha, beta+floor(x)+1)
>> # ? ? ? ? ? ?genhypergeo(1, n+floor(x)+1, beta+floor(x)+1;floor(x)+2,
>> n+alpha+beta+floor(x)+1;1))
>> # ? ? ? ? ? ?/(Gamma(n) beta(alpha, beta) Gamma(floor(x)+2)) | ?for ?|
>> x>=0
>> pbetanbinom<- function(q, size, mu, sigma){
>> ? ?require(hypergeo)
>> ? ?param<- FindParamBetaDist(mu, sigma)
>> ? ?if (is.na(sum(param))) return (NA) #invalid Beta parameters
>> ? ?res<- numeric(length(q))
>> ? ?for (i in 1:length(q)){
>> ? ? ? ?if (q[i]<0) res[i]<- 0
>> ? ? ? ?else res[i]<- (1-(gamma(size+floor(q[i])+1) *
>> beta(size+param$a, param$b+floor(q[i])+1)
>> ? ? ? ?* genhypergeo(c(1, 1+size+floor(q[i]), 1+param$b+floor(q[i])),
>> c(2+floor(q[i]),1+size+param$a+param$b+floor(q[i])), 1))
>> ? ? ? ?/ (beta(param$a, param$b) * gamma(size) * gamma(2+floor(q[i]))))
>> ? ?}
>> ? ?return (res)
>> }
>>
>> ## genhypergeo not converge. Increase iterations or tolerance?
>> pbetanbinom(0:10x, size=20, mu=0.75, sigma=0.03)
>>
>> I have to investigate
>> http://mathworld.wolfram.com/GeneralizedHypergeometricFunction.html
>> Any tip on how to solve the problem?
>>
>>
>> --
>> Joan Maspons
>> CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
>> Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
>> Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
>> http://www.creaf.uab.cat
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> A model is a lie that helps you see the truth.
>
> Howard Skipper
>

[1] http://mathworld.wolfram.com/GeneralizedHypergeometricFunction.html
[2] http://reference.wolfram.com/mathematica/ref/BetaNegativeBinomialDistribution.html

-- 
Joan Maspons
CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
http://www.creaf.uab.cat


From edd at debian.org  Sun Mar 18 14:19:06 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 18 Mar 2012 08:19:06 -0500
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
In-Reply-To: <20120318051611.GA20315@siouxsie>
References: <20120318023052.GB13699@siouxsie>
	<20325.20885.364933.666819@max.nulle.part>
	<20120318051611.GA20315@siouxsie>
Message-ID: <20325.57546.463137.441482@max.nulle.part>


On 18 March 2012 at 06:16, oliver wrote:
| > R> library(inline)
| > R> 
| > R> f <- cfunction(signature(), verbose=TRUE, body='
| > +    double *p = Calloc(5, double);
| [...]
| 
| That line cleared the issue.
| Thank you for providing an example.
| 
| When reading in the documentation I was not sure,
| how to interpret "type" in setion 6.1.2.
| 
| It was meant as the name of the type, and that's, why my
| sizeof() stuff created the problem.
| 
| I tried around and then saw, that the name of the type
| is accepted, not only with typical base-types of C, but
| it also eats the names of my structs/typedefed structs.

Understandable, the manual is not toi clear there.  The easiest answer, in
such cases, is IMHO provided by other source packages.

Too bad the Google Code Search is now defunct.  But besides a recursive grep
in R's src/ directory, a simple Google search for "site:r-project.org Calloc"
also brings the solution up rightaway.

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From ligges at statistik.tu-dortmund.de  Sun Mar 18 14:57:03 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 18 Mar 2012 14:57:03 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F65B73B.8010809@univ-fcomte.fr>
References: <4F65B73B.8010809@univ-fcomte.fr>
Message-ID: <4F65E9AF.5080609@statistik.tu-dortmund.de>



On 18.03.2012 11:21, Patrick Giraudoux wrote:
> Hi,
>
> I am working at adding namespace to my packages, carefully following the
> doc "Writing R extensions" and some threads on the web. However I cannot
> find clear explanation about how to best deal with the import or
> importFrom functions in the name space. To make it short:
>
> To declare dependencies in the description file either after Depends:
> (packages including functions that are called from a package function)
> or after Suggests: (packages that are called eg from the doucmentation
> examples), works well. In this case one does not need to declare import
> in the namespace file.
>
> However, declaring dependencies sometimes for using only one function in
> a given package looks a bit over the top, and I though I could use
> importFrom in the namespace to deal with that. So removing the
> corresponding declaration in Depends (description file) and declaring
> eg  importFrom(splancs, inout) in the namespace always led to:
>
> * checking package dependencies ... ERROR
> Namespace dependency not required: 'splancs'
>
> Same thing with import(sp). I have the same trouble if I do not remove
> the declarations in Depends.
>
> So, I can hardly follow the meaning of the "Writing R extension" doc:
>
> Packages implicitly import the base namespace. Variables exported from
> other packages with namespaces need to be imported explicitly using the
> directives |import| and |importFrom|. The |import| directive imports all
> exported variables from the specified package(s). Thus the directives
>
>        import(foo, bar)
>
> specifies that all exported variables in the packages *foo* and *bar*
> are to be imported. If only some of the exported variables from a
> package are needed, then they can be imported using |importFrom|. The
> directive
>
>        importFrom(foo, f, g)
>
> specifies that the exported variables |f| and |g| of the package *foo*
> are to be imported.
>
> Can anybody tell us the conditions for which import and importFrom
> commands should be used in the NAMESPACE rather than in the Depends and
> Suggests declarations of the description file, and the conditions of
> their applicability (without error message... eg with a working example) ?

If you import from another namespace (which is the recommended way 
rather than just relying on search order), do not forget to declare it 
as "Imports" in your DESCRIPTION file. Your package depends on the other 
one: It could not be loaded without having the other one installed now.

Uwe Ligges



> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From oliver at first.in-berlin.de  Sun Mar 18 15:38:48 2012
From: oliver at first.in-berlin.de (oliver)
Date: Sun, 18 Mar 2012 15:38:48 +0100
Subject: [Rd] malloc/calloc/strdup and R's aequivalents
In-Reply-To: <D83F333D-7CC3-4973-BD0B-F7F08E82F4E4@r-project.org>
References: <20120318023052.GB13699@siouxsie>
	<D83F333D-7CC3-4973-BD0B-F7F08E82F4E4@r-project.org>
Message-ID: <20120318143848.GB1852@siouxsie>

On Sat, Mar 17, 2012 at 11:47:24PM -0400, Simon Urbanek wrote:
[...]
> You can always define Strdup() since strdup() is just a shorthand for
> malloc()+strcpy() -- in fact in R it's easier since Calloc will never return
> NULL so trivially
> #define Strdup(X) strcpy(Calloc(strlen(X)+1, char), X)
[...]

Yes, something like that I had in mind (and already implemented,
but nur used so far).
I thought maybe something might be also somehoew available as a
R-internal adaption.


> 
> But when using Calloc be aware that you have to clean up -- even if there is
> an error (which is why it is generally not a good idea to use Calloc for
> anything but memory you want to keep beyond your call).

Yes.

This seems not to be the case for R_alloc() ?


> There are two reasons for removing malloc/calloc: a) R uses custom allocators
> on systems with poor OS allocators (like Windows) so R's allocation is more
> efficient [and combining different allocators even worsens the performance] and
> b) you should think twice about the life span of your objects under error
> conditions. It is quite challenging to keep that straight, so in most cases it
> is better to use managed memory instead (but there is a performance trade-off).

Yes, good reasons.

> There are still valid reasons for not using R's allocators, but those are
> special cases that the author must be conscious about (after weighing the
> options).

Calloc() is provided by R, so it apears as being an R-allocator,
but rather seems to be a wrapper around calloc().
With R allocators you mean functions like allocVector()?
And R_alloc()?
The behaviour of the later one is not clear to me.
(A reason to prefer Calloc() here, then the behaviour
 is under my control, even of it's more "risky". That's the C-ish-way.)


> 
> 
> > mkChar seems not to be the right thing, because, what I found in the
> > above mentioned documentation, says,m that a C-string is fed in, but
> > CHARSXP is what I get as result.
> > 
> > What I try to do, is, to pick some code and port it to R.
> > If I need to rewrite a lot of stuff, just because I need
> > to adapt to R, this would be more effort than if it would be possible
> > just to have some functions, that could make porting easier.
> > 
> > For example, if I want to resuse a function, that opens a file
> > and needs a   char* stringname
> > then it would add more effort if I need to go via CHARSXP or so.
> > 
> 
> I'm not sure where you are going with this, since all strings will already
> come as CHARSXPs from R so typically you don't need to allocate anything. The
> only reason to allocate is to create persistent objects (for which you'd use
> Calloc) - your example doesn't fit here...


If I want to copy the filename into a C-struct and then pass (a pointer to)
that struct around, then using something like strdup() is a good idea.
Therwise the filename-pointer might have vanished and the pointer
points into nirvana.
That was, where it came from. I used some already existing code,
where this all made sense.

And extracting char* from the CARSXP once, instead of
using something like CHAR( STRING_ELT(filename_sexp, 0) )
at every place, where I may want to have access to that filename
makes the code clearer.

As this I reused existing code, I tried to change it
as less as possible (to make it easy).

But as I now see, for the special case here I can forget the
strdup() and maybe make my struct smaller (throwing out the filename),
because here I call the reader-function with filename as argument,
and do not pass around the structure-ptr too much.
And I store the filename in the list I give back to the user.
(I can do this even in the R-code which calls my C-code.)

So in this certain case the problem vanishes.
Nevertheless, in other cases it might be a problem.

But then maybe never touching the code and just live with the
already existing strdup()/malloc/calloc()/free()
would also work.

I can see the advantages of using R-provided functions.
But if they do not substitute all these deprecated functions,
then either porting the stand-alone-code to R is made
much effort, or the deprecated functions might just stay inside.

Do you see what I mean?

> 
> > If nothing of that stuff works, I would need to use the original
> > calloc() / free() functions, which are deprecated in the above
> > mentioned manual.
> > 
> > 
> > Ciao,
> >   Oliver
> > 
> > P.S.: Also I wonder... R-alloc() does not need a free()-like call?
> >      Is it freed automaticlaly?
> >      And at which time?
> >      In the docs is mentioned, at the end of the .C/.Call/.External call.
> >      Does this mean, this is freed/reclaimed automatically, when returning
> >      from the C-world to the R-world?
> >      At (after) return of the extension's code?
> > 
> 
> Yes. It simply uses an R object so it is subject to regular R object rules
> and thus gets cleaned up on error as well (unlike anything you use Calloc for).

This point is not so clear to me.

The prototype of R_alloc() looks like as if R_alloc() is just the same as calloc().
But now you say, it's an R-object that will be handled like any R-object.

But then... why is PROTECT not mentioned there in section 6.1.1?
Would a GC-run possibly vanish that memory?

What rules are there for it?

Is it save to use it from entry-point to my code to the return-point of my code?

So, does it behave like an environment in functional languages?

Can I allocate memory with R_alloc() somewehere  deep in my code
and pass that memory until the return of my .Call-entry-return-point?
Without GC claiming it until returning?


Can you please clarify theese points?


Ciao,
   Oliver


From patrick.giraudoux at univ-fcomte.fr  Sun Mar 18 16:08:29 2012
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Mar 2012 16:08:29 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F65E9AF.5080609@statistik.tu-dortmund.de>
References: <4F65B73B.8010809@univ-fcomte.fr>
	<4F65E9AF.5080609@statistik.tu-dortmund.de>
Message-ID: <4F65FA6D.10205@univ-fcomte.fr>

Le 18/03/2012 14:57, Uwe Ligges a ?crit :
>
>
> On 18.03.2012 11:21, Patrick Giraudoux wrote:
>> Hi,
>>
>> I am working at adding namespace to my packages, carefully following the
>> doc "Writing R extensions" and some threads on the web. However I cannot
>> find clear explanation about how to best deal with the import or
>> importFrom functions in the name space. To make it short:
>>
>> To declare dependencies in the description file either after Depends:
>> (packages including functions that are called from a package function)
>> or after Suggests: (packages that are called eg from the doucmentation
>> examples), works well. In this case one does not need to declare import
>> in the namespace file.
>>
>> However, declaring dependencies sometimes for using only one function in
>> a given package looks a bit over the top, and I though I could use
>> importFrom in the namespace to deal with that. So removing the
>> corresponding declaration in Depends (description file) and declaring
>> eg  importFrom(splancs, inout) in the namespace always led to:
>>
>> * checking package dependencies ... ERROR
>> Namespace dependency not required: 'splancs'
>>
>> Same thing with import(sp). I have the same trouble if I do not remove
>> the declarations in Depends.
>>
>> So, I can hardly follow the meaning of the "Writing R extension" doc:
>>
>> Packages implicitly import the base namespace. Variables exported from
>> other packages with namespaces need to be imported explicitly using the
>> directives |import| and |importFrom|. The |import| directive imports all
>> exported variables from the specified package(s). Thus the directives
>>
>>        import(foo, bar)
>>
>> specifies that all exported variables in the packages *foo* and *bar*
>> are to be imported. If only some of the exported variables from a
>> package are needed, then they can be imported using |importFrom|. The
>> directive
>>
>>        importFrom(foo, f, g)
>>
>> specifies that the exported variables |f| and |g| of the package *foo*
>> are to be imported.
>>
>> Can anybody tell us the conditions for which import and importFrom
>> commands should be used in the NAMESPACE rather than in the Depends and
>> Suggests declarations of the description file, and the conditions of
>> their applicability (without error message... eg with a working 
>> example) ?
>
> If you import from another namespace (which is the recommended way 
> rather than just relying on search order), do not forget to declare it 
> as "Imports" in your DESCRIPTION file. Your package depends on the 
> other one: It could not be loaded without having the other one 
> installed now.
>
> Uwe Ligges
>

OK. got it (more or less).

With this in the description file:

Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>= 
0.9-97), spdep (>= 0.5-43), splancs (>= 2.01-31)

importFrom(splancs, inout) is accepted in the NAMESPACE file and I have 
no error message with rcmd check.

Irr works also with:

Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>= 
0.9-97), spdep (>= 0.5-43)
Imports: splancs (>= 2.01-31)

Practically, I a am safe (thanks a lot), but I am however still hungry 
to learn a bit more. I hardly understand what R does when reading the 
suggests and imports in the DESCRIPTION file compared to what it does 
reading the NAMESPACE (my mistake was to believe that one was a 
substitute for the other). From a practical point of view, why is it 
important to use import or importFrom in the NAMESPACE when everything 
looks like working well when declarations are done in the DESCRIPTION 
file only (eg in depends or imports)?  It is not crystal clear to me 
even reading carefully "Writing R extension". DESCRIPTION file is used 
to get the "list of packages that will be attached (...) before the 
current package" (indeed, now, I no longer needs to use 'require' within 
my package functions). In simple words, what may add the NAMESPACE to 
that ?

Apologize to be so poorly aware (= so much stupid) about the role of 
each of those declaration spaces.

Best,

Patrick


From j.hadfield at ed.ac.uk  Sun Mar 18 15:20:23 2012
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 18 Mar 2012 14:20:23 +0000
Subject: [Rd] Rinstignore
Message-ID: <20120318142023.711510cg5m8y8obk@www.staffmail.ed.ac.uk>

Hi,

My updated CRAN package keeps getting bounced by CRAN because the  
inst/doc folder is too large. I have included a .Rinstignore file in  
the top-level directory using both

doc/Lecture1-*.*pdf$

and

inst/doc/Lecture1-*.*pdf$

The files seem to be removed if I use R --as-cran CMD check  
package.name (I no longer get the NOTE with "checking installed  
package size"), but on CRAN (and if I run the check on the built  
tarball) the note reappears.

I see this has come up before, but with no answer:

http://r.789695.n4.nabble.com/R-devel-now-triggers-nags-on-notes-from-vignettes-td4324303.html

Any help, would be very useful,

Cheers,

Jarrod

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From nashjc at uottawa.ca  Sun Mar 18 18:01:20 2012
From: nashjc at uottawa.ca (John C Nash)
Date: Sun, 18 Mar 2012 13:01:20 -0400
Subject: [Rd] Converting expression to a function
Message-ID: <4F6614E0.70000@uottawa.ca>

Previously, I've posted queries about this, and thanks to postings and messages in
response have recently had some success, to the extent that there is now a package called
nlmrt on the R-forge project https://r-forge.r-project.org/R/?group_id=395 for solving
nonlinear least squares problems that include small or zero residual problems via a
Marquardt method using a call that mirrors the nls() function. nls() specifically warns
against zero residual problems.

However, I would still like to be able to convert expressions with example vectors of
parameters to functions that optim() and related functions can use. The code below gets
"almost" there, but

1) Can the code be improved / cleaned up?

2) Can the eval() of the output of the Form2resfun be avoided?

3) Can the extraction of the parameter names be embedded in the function rather than put
separately?

Off-list responses are likely best at this stage, while the tedious details are sorted
out. I will post a summary in a couple of weeks of the results. Collaborations re: this
and the larger package welcome, as there is considerable testing and tuning to do, but
preliminary experience is encouraging.

John Nash


# --------- code block -----------
rm(list=ls()) # clear workspace
Form2resfun <- function(f, p ) {
        cat("In Form2resfun\n")
        xx <- all.vars(f)
        fp <- match(names(p), xx) # Problem in matching the names of params
        xx2 <- c(xx[fp], xx[-fp])
        ff <- vector("list", length(xx2))
        names(ff) <- xx2
        sf<-as.character(f)
        if ((length(sf)!=3) && (sf[1]!="~")) stop("Bad model formula expression")
        lhs<-sf[2] # NOTE ORDER formula with ~ puts ~, lhs, rhs
        rhs<-sf[3]
# And build the residual at the parameters
        resexp<-paste(rhs,"-",lhs, collapse=" ")
        fnexp<-paste("crossprod(",resexp,")", sep="")
        ff[[length(ff) + 1]] <- parse(text=fnexp)
#  want crossprod(resexp)
        myfn<-as.function(ff, parent.frame())
}
# a test
    y<-c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443,
          38.558, 50.156, 62.948, 75.995, 91.972) # for testing
    t<-1:length(y) # for testing
    f<- y ~ b1/(1+b2*exp(-1*b3*t))
    p<-c(b1=1, b2=1, b3=1)
    b<-p
    npar<-length(b)
    for (i in 1:npar){
                bbit<-paste(names(b)[[i]],"<-",b[[i]])
                eval(parse(text=bbit))
    }
    tfn<-Form2resfun(f, b)
    ans<-eval(tfn(t=t,y=y, b))
    print(ans)
# --------- end code block -----------


From ligges at statistik.tu-dortmund.de  Sun Mar 18 18:02:57 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 18 Mar 2012 18:02:57 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F65FA6D.10205@univ-fcomte.fr>
References: <4F65B73B.8010809@univ-fcomte.fr>
	<4F65E9AF.5080609@statistik.tu-dortmund.de>
	<4F65FA6D.10205@univ-fcomte.fr>
Message-ID: <4F661541.5080303@statistik.tu-dortmund.de>



On 18.03.2012 16:08, Patrick Giraudoux wrote:
> Le 18/03/2012 14:57, Uwe Ligges a ?crit :
>>
>>
>> On 18.03.2012 11:21, Patrick Giraudoux wrote:
>>> Hi,
>>>
>>> I am working at adding namespace to my packages, carefully following the
>>> doc "Writing R extensions" and some threads on the web. However I cannot
>>> find clear explanation about how to best deal with the import or
>>> importFrom functions in the name space. To make it short:
>>>
>>> To declare dependencies in the description file either after Depends:
>>> (packages including functions that are called from a package function)
>>> or after Suggests: (packages that are called eg from the doucmentation
>>> examples), works well. In this case one does not need to declare import
>>> in the namespace file.
>>>
>>> However, declaring dependencies sometimes for using only one function in
>>> a given package looks a bit over the top, and I though I could use
>>> importFrom in the namespace to deal with that. So removing the
>>> corresponding declaration in Depends (description file) and declaring
>>> eg importFrom(splancs, inout) in the namespace always led to:
>>>
>>> * checking package dependencies ... ERROR
>>> Namespace dependency not required: 'splancs'
>>>
>>> Same thing with import(sp). I have the same trouble if I do not remove
>>> the declarations in Depends.
>>>
>>> So, I can hardly follow the meaning of the "Writing R extension" doc:
>>>
>>> Packages implicitly import the base namespace. Variables exported from
>>> other packages with namespaces need to be imported explicitly using the
>>> directives |import| and |importFrom|. The |import| directive imports all
>>> exported variables from the specified package(s). Thus the directives
>>>
>>> import(foo, bar)
>>>
>>> specifies that all exported variables in the packages *foo* and *bar*
>>> are to be imported. If only some of the exported variables from a
>>> package are needed, then they can be imported using |importFrom|. The
>>> directive
>>>
>>> importFrom(foo, f, g)
>>>
>>> specifies that the exported variables |f| and |g| of the package *foo*
>>> are to be imported.
>>>
>>> Can anybody tell us the conditions for which import and importFrom
>>> commands should be used in the NAMESPACE rather than in the Depends and
>>> Suggests declarations of the description file, and the conditions of
>>> their applicability (without error message... eg with a working
>>> example) ?
>>
>> If you import from another namespace (which is the recommended way
>> rather than just relying on search order), do not forget to declare it
>> as "Imports" in your DESCRIPTION file. Your package depends on the
>> other one: It could not be loaded without having the other one
>> installed now.
>>
>> Uwe Ligges
>>
>
> OK. got it (more or less).
>
> With this in the description file:
>
> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
> 0.9-97), spdep (>= 0.5-43), splancs (>= 2.01-31)
>
> importFrom(splancs, inout) is accepted in the NAMESPACE file and I have
> no error message with rcmd check.
>
> Irr works also with:
>
> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
> 0.9-97), spdep (>= 0.5-43)
> Imports: splancs (>= 2.01-31)
>
> Practically, I a am safe (thanks a lot), but I am however still hungry
> to learn a bit more. I hardly understand what R does when reading the
> suggests and imports in the DESCRIPTION file compared to what it does
> reading the NAMESPACE (my mistake was to believe that one was a
> substitute for the other). From a practical point of view, why is it
> important to use import or importFrom in the NAMESPACE when everything
> looks like working well when declarations are done in the DESCRIPTION
> file only (eg in depends or imports)? It is not crystal clear to me even
> reading carefully "Writing R extension". DESCRIPTION file is used to get
> the "list of packages that will be attached (...) before the current
> package" (indeed, now, I no longer needs to use 'require' within my
> package functions). In simple words, what may add the NAMESPACE to that ?
>
> Apologize to be so poorly aware (= so much stupid) about the role of
> each of those declaration spaces.

Please read some literature about NAMESPACES, e.g. documentation in 
Writing R Extensions plus Luke Tierney's articles in R News.

A NAMESPACE import imports functionality of another namespace into your 
own namespace and hence avoids problems caused by name clashes.
The DESCRIPTION file is required to derive dependency structure of 
packages, i.e. derive which package has to be *installed* first etc.

Uwe Ligges





>
> Best,
>
> Patrick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From patrick.giraudoux at univ-fcomte.fr  Sun Mar 18 19:27:54 2012
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Mar 2012 19:27:54 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F661541.5080303@statistik.tu-dortmund.de>
References: <4F65B73B.8010809@univ-fcomte.fr>
	<4F65E9AF.5080609@statistik.tu-dortmund.de>
	<4F65FA6D.10205@univ-fcomte.fr>
	<4F661541.5080303@statistik.tu-dortmund.de>
Message-ID: <4F66292A.2000400@univ-fcomte.fr>

Le 18/03/2012 18:02, Uwe Ligges a ?crit :
>
>
> On 18.03.2012 16:08, Patrick Giraudoux wrote:
>> Le 18/03/2012 14:57, Uwe Ligges a ?crit :
>>>
>>>
>>> On 18.03.2012 11:21, Patrick Giraudoux wrote:
>>>> Hi,
>>>>
>>>> I am working at adding namespace to my packages, carefully 
>>>> following the
>>>> doc "Writing R extensions" and some threads on the web. However I 
>>>> cannot
>>>> find clear explanation about how to best deal with the import or
>>>> importFrom functions in the name space. To make it short:
>>>>
>>>> To declare dependencies in the description file either after Depends:
>>>> (packages including functions that are called from a package function)
>>>> or after Suggests: (packages that are called eg from the doucmentation
>>>> examples), works well. In this case one does not need to declare 
>>>> import
>>>> in the namespace file.
>>>>
>>>> However, declaring dependencies sometimes for using only one 
>>>> function in
>>>> a given package looks a bit over the top, and I though I could use
>>>> importFrom in the namespace to deal with that. So removing the
>>>> corresponding declaration in Depends (description file) and declaring
>>>> eg importFrom(splancs, inout) in the namespace always led to:
>>>>
>>>> * checking package dependencies ... ERROR
>>>> Namespace dependency not required: 'splancs'
>>>>
>>>> Same thing with import(sp). I have the same trouble if I do not remove
>>>> the declarations in Depends.
>>>>
>>>> So, I can hardly follow the meaning of the "Writing R extension" doc:
>>>>
>>>> Packages implicitly import the base namespace. Variables exported from
>>>> other packages with namespaces need to be imported explicitly using 
>>>> the
>>>> directives |import| and |importFrom|. The |import| directive 
>>>> imports all
>>>> exported variables from the specified package(s). Thus the directives
>>>>
>>>> import(foo, bar)
>>>>
>>>> specifies that all exported variables in the packages *foo* and *bar*
>>>> are to be imported. If only some of the exported variables from a
>>>> package are needed, then they can be imported using |importFrom|. The
>>>> directive
>>>>
>>>> importFrom(foo, f, g)
>>>>
>>>> specifies that the exported variables |f| and |g| of the package *foo*
>>>> are to be imported.
>>>>
>>>> Can anybody tell us the conditions for which import and importFrom
>>>> commands should be used in the NAMESPACE rather than in the Depends 
>>>> and
>>>> Suggests declarations of the description file, and the conditions of
>>>> their applicability (without error message... eg with a working
>>>> example) ?
>>>
>>> If you import from another namespace (which is the recommended way
>>> rather than just relying on search order), do not forget to declare it
>>> as "Imports" in your DESCRIPTION file. Your package depends on the
>>> other one: It could not be loaded without having the other one
>>> installed now.
>>>
>>> Uwe Ligges
>>>
>>
>> OK. got it (more or less).
>>
>> With this in the description file:
>>
>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>> 0.9-97), spdep (>= 0.5-43), splancs (>= 2.01-31)
>>
>> importFrom(splancs, inout) is accepted in the NAMESPACE file and I have
>> no error message with rcmd check.
>>
>> Irr works also with:
>>
>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>> 0.9-97), spdep (>= 0.5-43)
>> Imports: splancs (>= 2.01-31)
>>
>> Practically, I a am safe (thanks a lot), but I am however still hungry
>> to learn a bit more. I hardly understand what R does when reading the
>> suggests and imports in the DESCRIPTION file compared to what it does
>> reading the NAMESPACE (my mistake was to believe that one was a
>> substitute for the other). From a practical point of view, why is it
>> important to use import or importFrom in the NAMESPACE when everything
>> looks like working well when declarations are done in the DESCRIPTION
>> file only (eg in depends or imports)? It is not crystal clear to me even
>> reading carefully "Writing R extension". DESCRIPTION file is used to get
>> the "list of packages that will be attached (...) before the current
>> package" (indeed, now, I no longer needs to use 'require' within my
>> package functions). In simple words, what may add the NAMESPACE to 
>> that ?
>>
>> Apologize to be so poorly aware (= so much stupid) about the role of
>> each of those declaration spaces.
>
> Please read some literature about NAMESPACES, e.g. documentation in 
> Writing R Extensions plus Luke Tierney's articles in R News.

ok. Will do it with Luke Tierney's articles. I read Writing R extensions 
already and also S programming (Venables and Ripley), but indeed should 
come down to more basic text for dudes :-) .

Best,

Patrick


>
> A NAMESPACE import imports functionality of another namespace into 
> your own namespace and hence avoids problems caused by name clashes.
> The DESCRIPTION file is required to derive dependency structure of 
> packages, i.e. derive which package has to be *installed* first etc.
>
> Uwe Ligges
>


From ligges at statistik.tu-dortmund.de  Sun Mar 18 19:30:50 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 18 Mar 2012 19:30:50 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F66292A.2000400@univ-fcomte.fr>
References: <4F65B73B.8010809@univ-fcomte.fr>
	<4F65E9AF.5080609@statistik.tu-dortmund.de>
	<4F65FA6D.10205@univ-fcomte.fr>
	<4F661541.5080303@statistik.tu-dortmund.de>
	<4F66292A.2000400@univ-fcomte.fr>
Message-ID: <4F6629DA.2070700@statistik.tu-dortmund.de>



On 18.03.2012 19:27, Patrick Giraudoux wrote:
> Le 18/03/2012 18:02, Uwe Ligges a ?crit :
>>
>>
>> On 18.03.2012 16:08, Patrick Giraudoux wrote:
>>> Le 18/03/2012 14:57, Uwe Ligges a ?crit :
>>>>
>>>>
>>>> On 18.03.2012 11:21, Patrick Giraudoux wrote:
>>>>> Hi,
>>>>>
>>>>> I am working at adding namespace to my packages, carefully
>>>>> following the
>>>>> doc "Writing R extensions" and some threads on the web. However I
>>>>> cannot
>>>>> find clear explanation about how to best deal with the import or
>>>>> importFrom functions in the name space. To make it short:
>>>>>
>>>>> To declare dependencies in the description file either after Depends:
>>>>> (packages including functions that are called from a package function)
>>>>> or after Suggests: (packages that are called eg from the doucmentation
>>>>> examples), works well. In this case one does not need to declare
>>>>> import
>>>>> in the namespace file.
>>>>>
>>>>> However, declaring dependencies sometimes for using only one
>>>>> function in
>>>>> a given package looks a bit over the top, and I though I could use
>>>>> importFrom in the namespace to deal with that. So removing the
>>>>> corresponding declaration in Depends (description file) and declaring
>>>>> eg importFrom(splancs, inout) in the namespace always led to:
>>>>>
>>>>> * checking package dependencies ... ERROR
>>>>> Namespace dependency not required: 'splancs'
>>>>>
>>>>> Same thing with import(sp). I have the same trouble if I do not remove
>>>>> the declarations in Depends.
>>>>>
>>>>> So, I can hardly follow the meaning of the "Writing R extension" doc:
>>>>>
>>>>> Packages implicitly import the base namespace. Variables exported from
>>>>> other packages with namespaces need to be imported explicitly using
>>>>> the
>>>>> directives |import| and |importFrom|. The |import| directive
>>>>> imports all
>>>>> exported variables from the specified package(s). Thus the directives
>>>>>
>>>>> import(foo, bar)
>>>>>
>>>>> specifies that all exported variables in the packages *foo* and *bar*
>>>>> are to be imported. If only some of the exported variables from a
>>>>> package are needed, then they can be imported using |importFrom|. The
>>>>> directive
>>>>>
>>>>> importFrom(foo, f, g)
>>>>>
>>>>> specifies that the exported variables |f| and |g| of the package *foo*
>>>>> are to be imported.
>>>>>
>>>>> Can anybody tell us the conditions for which import and importFrom
>>>>> commands should be used in the NAMESPACE rather than in the Depends
>>>>> and
>>>>> Suggests declarations of the description file, and the conditions of
>>>>> their applicability (without error message... eg with a working
>>>>> example) ?
>>>>
>>>> If you import from another namespace (which is the recommended way
>>>> rather than just relying on search order), do not forget to declare it
>>>> as "Imports" in your DESCRIPTION file. Your package depends on the
>>>> other one: It could not be loaded without having the other one
>>>> installed now.
>>>>
>>>> Uwe Ligges
>>>>
>>>
>>> OK. got it (more or less).
>>>
>>> With this in the description file:
>>>
>>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>>> 0.9-97), spdep (>= 0.5-43), splancs (>= 2.01-31)
>>>
>>> importFrom(splancs, inout) is accepted in the NAMESPACE file and I have
>>> no error message with rcmd check.
>>>
>>> Irr works also with:
>>>
>>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>>> 0.9-97), spdep (>= 0.5-43)
>>> Imports: splancs (>= 2.01-31)
>>>
>>> Practically, I a am safe (thanks a lot), but I am however still hungry
>>> to learn a bit more. I hardly understand what R does when reading the
>>> suggests and imports in the DESCRIPTION file compared to what it does
>>> reading the NAMESPACE (my mistake was to believe that one was a
>>> substitute for the other). From a practical point of view, why is it
>>> important to use import or importFrom in the NAMESPACE when everything
>>> looks like working well when declarations are done in the DESCRIPTION
>>> file only (eg in depends or imports)? It is not crystal clear to me even
>>> reading carefully "Writing R extension". DESCRIPTION file is used to get
>>> the "list of packages that will be attached (...) before the current
>>> package" (indeed, now, I no longer needs to use 'require' within my
>>> package functions). In simple words, what may add the NAMESPACE to
>>> that ?
>>>
>>> Apologize to be so poorly aware (= so much stupid) about the role of
>>> each of those declaration spaces.
>>
>> Please read some literature about NAMESPACES, e.g. documentation in
>> Writing R Extensions plus Luke Tierney's articles in R News.
>
> ok. Will do it with Luke Tierney's articles. I read Writing R extensions
> already and also S programming (Venables and Ripley), but indeed should
> come down to more basic text for dudes :-) .

S Programming is excellent, but it was written before Namespaces were 
introduced to R.

Uwe Ligges




>
> Best,
>
> Patrick
>
>
>>
>> A NAMESPACE import imports functionality of another namespace into
>> your own namespace and hence avoids problems caused by name clashes.
>> The DESCRIPTION file is required to derive dependency structure of
>> packages, i.e. derive which package has to be *installed* first etc.
>>
>> Uwe Ligges
>>
>


From patrick.giraudoux at univ-fcomte.fr  Sun Mar 18 20:05:02 2012
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 18 Mar 2012 20:05:02 +0100
Subject: [Rd] Namespace dependency not required
In-Reply-To: <4F6629DA.2070700@statistik.tu-dortmund.de>
References: <4F65B73B.8010809@univ-fcomte.fr>
	<4F65E9AF.5080609@statistik.tu-dortmund.de>
	<4F65FA6D.10205@univ-fcomte.fr>
	<4F661541.5080303@statistik.tu-dortmund.de>
	<4F66292A.2000400@univ-fcomte.fr>
	<4F6629DA.2070700@statistik.tu-dortmund.de>
Message-ID: <4F6631DE.7020608@univ-fcomte.fr>

Le 18/03/2012 19:30, Uwe Ligges a ?crit :
>
>
> On 18.03.2012 19:27, Patrick Giraudoux wrote:
>> Le 18/03/2012 18:02, Uwe Ligges a ?crit :
>>>
>>>
>>> On 18.03.2012 16:08, Patrick Giraudoux wrote:
>>>> Le 18/03/2012 14:57, Uwe Ligges a ?crit :
>>>>>
>>>>>
>>>>> On 18.03.2012 11:21, Patrick Giraudoux wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I am working at adding namespace to my packages, carefully
>>>>>> following the
>>>>>> doc "Writing R extensions" and some threads on the web. However I
>>>>>> cannot
>>>>>> find clear explanation about how to best deal with the import or
>>>>>> importFrom functions in the name space. To make it short:
>>>>>>
>>>>>> To declare dependencies in the description file either after 
>>>>>> Depends:
>>>>>> (packages including functions that are called from a package 
>>>>>> function)
>>>>>> or after Suggests: (packages that are called eg from the 
>>>>>> doucmentation
>>>>>> examples), works well. In this case one does not need to declare
>>>>>> import
>>>>>> in the namespace file.
>>>>>>
>>>>>> However, declaring dependencies sometimes for using only one
>>>>>> function in
>>>>>> a given package looks a bit over the top, and I though I could use
>>>>>> importFrom in the namespace to deal with that. So removing the
>>>>>> corresponding declaration in Depends (description file) and 
>>>>>> declaring
>>>>>> eg importFrom(splancs, inout) in the namespace always led to:
>>>>>>
>>>>>> * checking package dependencies ... ERROR
>>>>>> Namespace dependency not required: 'splancs'
>>>>>>
>>>>>> Same thing with import(sp). I have the same trouble if I do not 
>>>>>> remove
>>>>>> the declarations in Depends.
>>>>>>
>>>>>> So, I can hardly follow the meaning of the "Writing R extension" 
>>>>>> doc:
>>>>>>
>>>>>> Packages implicitly import the base namespace. Variables exported 
>>>>>> from
>>>>>> other packages with namespaces need to be imported explicitly using
>>>>>> the
>>>>>> directives |import| and |importFrom|. The |import| directive
>>>>>> imports all
>>>>>> exported variables from the specified package(s). Thus the 
>>>>>> directives
>>>>>>
>>>>>> import(foo, bar)
>>>>>>
>>>>>> specifies that all exported variables in the packages *foo* and 
>>>>>> *bar*
>>>>>> are to be imported. If only some of the exported variables from a
>>>>>> package are needed, then they can be imported using |importFrom|. 
>>>>>> The
>>>>>> directive
>>>>>>
>>>>>> importFrom(foo, f, g)
>>>>>>
>>>>>> specifies that the exported variables |f| and |g| of the package 
>>>>>> *foo*
>>>>>> are to be imported.
>>>>>>
>>>>>> Can anybody tell us the conditions for which import and importFrom
>>>>>> commands should be used in the NAMESPACE rather than in the Depends
>>>>>> and
>>>>>> Suggests declarations of the description file, and the conditions of
>>>>>> their applicability (without error message... eg with a working
>>>>>> example) ?
>>>>>
>>>>> If you import from another namespace (which is the recommended way
>>>>> rather than just relying on search order), do not forget to 
>>>>> declare it
>>>>> as "Imports" in your DESCRIPTION file. Your package depends on the
>>>>> other one: It could not be loaded without having the other one
>>>>> installed now.
>>>>>
>>>>> Uwe Ligges
>>>>>
>>>>
>>>> OK. got it (more or less).
>>>>
>>>> With this in the description file:
>>>>
>>>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>>>> 0.9-97), spdep (>= 0.5-43), splancs (>= 2.01-31)
>>>>
>>>> importFrom(splancs, inout) is accepted in the NAMESPACE file and I 
>>>> have
>>>> no error message with rcmd check.
>>>>
>>>> Irr works also with:
>>>>
>>>> Depends: boot (>= 1.3-4), nlme(>= 3.1-64), rgdal (>= 0.7-8), sp (>=
>>>> 0.9-97), spdep (>= 0.5-43)
>>>> Imports: splancs (>= 2.01-31)
>>>>
>>>> Practically, I a am safe (thanks a lot), but I am however still hungry
>>>> to learn a bit more. I hardly understand what R does when reading the
>>>> suggests and imports in the DESCRIPTION file compared to what it does
>>>> reading the NAMESPACE (my mistake was to believe that one was a
>>>> substitute for the other). From a practical point of view, why is it
>>>> important to use import or importFrom in the NAMESPACE when everything
>>>> looks like working well when declarations are done in the DESCRIPTION
>>>> file only (eg in depends or imports)? It is not crystal clear to me 
>>>> even
>>>> reading carefully "Writing R extension". DESCRIPTION file is used 
>>>> to get
>>>> the "list of packages that will be attached (...) before the current
>>>> package" (indeed, now, I no longer needs to use 'require' within my
>>>> package functions). In simple words, what may add the NAMESPACE to
>>>> that ?
>>>>
>>>> Apologize to be so poorly aware (= so much stupid) about the role of
>>>> each of those declaration spaces.
>>>
>>> Please read some literature about NAMESPACES, e.g. documentation in
>>> Writing R Extensions plus Luke Tierney's articles in R News.
>>
>> ok. Will do it with Luke Tierney's articles. I read Writing R extensions
>> already and also S programming (Venables and Ripley), but indeed should
>> come down to more basic text for dudes :-) .
>
> S Programming is excellent, but it was written before Namespaces were 
> introduced to R.
>
> Uwe Ligges
>
>
>
>
>>
>> Best,
>>
>> Patrick
>>
>>
>>>
>>> A NAMESPACE import imports functionality of another namespace into
>>> your own namespace and hence avoids problems caused by name clashes.
>>> The DESCRIPTION file is required to derive dependency structure of
>>> packages, i.e. derive which package has to be *installed* first etc.
>>>
>>> Uwe Ligges
>>>
>>
>


Great ! Luke Tierney's article in R news is particularly clear (to me) 
with nice examples on how namespace avoids variable shadowing. I give 
the link here for any user/developper who may follow the thread on this 
issue: http://journal.r-project.org/archive.html Volume 3/1 June 2003, 
Name Space Management for R by Luke Tierney.

Thanks Uwe for the hint.

Best,

Patrick


From mailinglist.honeypot at gmail.com  Sun Mar 18 20:48:30 2012
From: mailinglist.honeypot at gmail.com (Steve Lianoglou)
Date: Sun, 18 Mar 2012 15:48:30 -0400
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <4F64BB31.7060609@statistik.tu-dortmund.de>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
	<ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
	<4F64BB31.7060609@statistik.tu-dortmund.de>
Message-ID: <CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA@mail.gmail.com>

Hi Uwe,

2012/3/17 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 15.03.2012 22:48, Matthew Dowle wrote:
>>
>>
>> Anyone?
>>
>>> Is it intended that the first suffix can no longer be blank? Seems to be
>>> caused by a bug fix to merge in R 2.15.0.
>
>
>
> Right, the user is now protected against confusing himself by using names
> that were not unique before the merge.

... now I'm confused :-)

If the user explicitly asks for a NULL/0/empty/whatever suffix,
they're not really going to be confusing themselves, right?

I actually feel like I do this often, where "this" is explicitly
asking to not add a suffix to one group of columns ... I do confuse
myself every and now and again, but not in this context, yet.

I can see that *this* confusing case is now handled w/ this change
(which wasn't before):

## I'm using R-devel compiled back in November, 2011 (r57571)
R> d1 <- data.frame(a=letters[1:10], b=rnorm(10), b.x=tail(letters, 10))
R> d2 <- data.frame(a=letters[1:10], b=101:110)
R> merge(d1, d2, by='a', suffixes=c('.x', '.y'))
   a         b.x b.x b.y
1  a -1.52250626   q 101
2  b -0.99865341   r 102
... ## Let's call this "exhibit A"

But if I do this:
R> merge(d1, d2, by='a', suffixes=c("", ".y"))

I totally expect:

   a           b b.x b.y
1  a -1.52250626   q 101
2  b -0.99865341   r 102
## Let's call this "exhibit B"
...

and not (using R-2.15.0 beta) (exhibit B):

Error in merge.data.frame(d1, d2, by = "a", suffixes = c("", ".y")) :
  there is already a column named 'b'

I can take a crack at a patch to keep the "rescue user from surprises"
example outlined in "exhibit A," but also letting user accomplish
"exhibit B" if there is a consensus of agreement on this particular
world view.

-steve

-- 
Steve Lianoglou
Graduate Student: Computational Systems Biology
?| Memorial Sloan-Kettering Cancer Center
?| Weill Medical College of Cornell University
Contact Info: http://cbio.mskcc.org/~lianos/contact


From mailinglist.honeypot at gmail.com  Sun Mar 18 21:50:30 2012
From: mailinglist.honeypot at gmail.com (Steve Lianoglou)
Date: Sun, 18 Mar 2012 16:50:30 -0400
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <CAJoaRhY3wsaGZBxmg4MtTV8dCKAuFx020ejKunjc15fWSBrzFQ@mail.gmail.com>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
	<ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
	<4F64BB31.7060609@statistik.tu-dortmund.de>
	<CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA@mail.gmail.com>
	<CAJoaRhY3wsaGZBxmg4MtTV8dCKAuFx020ejKunjc15fWSBrzFQ@mail.gmail.com>
Message-ID: <CAHA9McNLrTLN4bBpWRQDFU4vJD6s+kFcuCCfYJqQzs7GzeXOsA@mail.gmail.com>

Hi,

I'm not sure I follow ... I think we're in total agreement, but it
sounds like you're suggesting we aren't.

On Sun, Mar 18, 2012 at 4:40 PM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
> On Sun, Mar 18, 2012 at 12:48 PM, Steve Lianoglou
> <mailinglist.honeypot at gmail.com> wrote:
[snip]

>> > Right, the user is now protected against confusing himself by using
>> > names
>> > that were not unique before the merge.
>>
>> ... now I'm confused :-)
>>
>> If the user explicitly asks for a NULL/0/empty/whatever suffix,
>> they're not really going to be confusing themselves, right?
>
>
> If the user asks for a blank suffix and you still give back ".x" or ".y" ?as
> a suffix, then yes that is confusing.

I agree, that is confusing -- where did this happen?

> As a user I would expect that the rule for column names produced by "merge"
> would be simple: the output column name is the concatenation of the input
> column name and the corresponding suffix.

Total agreement here.

> When I use 'merge" I don't expect
> a more complicated behavior that somehow still uses '.x' even though I asked
> it not to, as in your second example. So I would say that the new behavior
> is more consistent.

But it didn't "still use '.x'" ... it didn't do anything.

There was a column name in the original table that ended with '.x' and
it wasn't changed since the call to merge asked for a blank suffix.
These were the two data.frames, for reference:

d1 <- data.frame(a=letters[1:10], b=rnorm(10), b.x=tail(letters, 10))
d2 <- data.frame(a=letters[1:10], b=101:110)

If you had those two data.frames, and you did this:

merge(d1, d2, by='a', suffixes=c("", ".y")

How is the following result surprising?

   a           b b.x b.y
1  a -1.52250626   q 101
2  b -0.99865341   r 102
...

> When I write functions that use "merge" on general data frames, I can
> anticipate and use the simpler rule, but it is difficult to anticipate the
> results of the more complicated rule in a way that my subsequent lines of
> code will work.
>
> If the inputs I give to merge are inconsistent with the simple rule

I agree that the rule should be simple. I'm not sure why asking for a
blank ("") suffix somehow isn't simple.

> I would
> much rather have an exception (highlighting exactly where my code has gone
> wrong) than a surprising column name change (which makes my code
> mysteriously fail ten or a hundred lines later).

What was "the surprising name change" you are referring to?

-steve

-- 
Steve Lianoglou
Graduate Student: Computational Systems Biology
?| Memorial Sloan-Kettering Cancer Center
?| Weill Medical College of Cornell University
Contact Info: http://cbio.mskcc.org/~lianos/contact


From peter.meilstrup at gmail.com  Sun Mar 18 21:40:46 2012
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Sun, 18 Mar 2012 13:40:46 -0700
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA@mail.gmail.com>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
	<ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
	<4F64BB31.7060609@statistik.tu-dortmund.de>
	<CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA@mail.gmail.com>
Message-ID: <CAJoaRhY3wsaGZBxmg4MtTV8dCKAuFx020ejKunjc15fWSBrzFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120318/ff8b545c/attachment.pl>

From peter.meilstrup at gmail.com  Sun Mar 18 22:01:12 2012
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Sun, 18 Mar 2012 14:01:12 -0700
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <CAHA9McNLrTLN4bBpWRQDFU4vJD6s+kFcuCCfYJqQzs7GzeXOsA@mail.gmail.com>
References: <faaeae7eaeb52d6007d62285a676364c.squirrel@webmail.plus.net>
	<ec32103ec8b4497fb9028095a195129c.squirrel@webmail.plus.net>
	<4F64BB31.7060609@statistik.tu-dortmund.de>
	<CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA@mail.gmail.com>
	<CAJoaRhY3wsaGZBxmg4MtTV8dCKAuFx020ejKunjc15fWSBrzFQ@mail.gmail.com>
	<CAHA9McNLrTLN4bBpWRQDFU4vJD6s+kFcuCCfYJqQzs7GzeXOsA@mail.gmail.com>
Message-ID: <CAJoaRhaFXd4bKJ90nM=1tAXZjJmEbS_HcayOfmvVrDwpN8byMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120318/4620bf15/attachment.pl>

From troy.robertson2 at bigpond.com  Mon Mar 19 03:32:22 2012
From: troy.robertson2 at bigpond.com (Troy Robertson)
Date: Mon, 19 Mar 2012 09:32:22 +0700
Subject: [Rd] R inline package
In-Reply-To: <4F6693F8.9060303@bigpond.com>
References: <4F6693F8.9060303@bigpond.com>
Message-ID: <4F669AB6.2050207@bigpond.com>


Hi all,

I am having some problems with the inline package and maybe someone can
point out what is going wrong?
I have developed a C++ library to assist with an S4 R project I have
been working on for some time.  I need to be able to include my package
using the setCMethod() function but it fails to find library header
files and/or the Rcpp.h header if I include that.  Yet if I use the
cfunction call first, the exact same setCMethod() call will then work.
I am assuming the Rcpp plugin is being called because of the Rcpp=TRUE
argument to cfunction(), which is setting up the paths to cause the
success of the later setCMethod?  I know the setCMethod() call will work
without the includes argument, but I need to be able to add the include
to my library, which also fails unless the cfunction() call has been
made first.

I am using R-2.14.1, Windows 7, inline (0.3.8), Rcpp (0.9.10).
I had to downgrade rTools to 2.14 because of the following problem I
encountered building my dll originally:
http://www.mail-archive.com/rcpp-devel at lists.r-forge.r-project.org/msg03133.html


example:

library(inline)
inc<-c("#include<Rcpp.h>");
sig<-signature(item="character")
code<-"return item;"
setCMethod("getSigItem", sig, body=code, includes=inc, Rcpp=TRUE,
verbose=TRUE)

The above call fails with:
fatal error: Rcpp.h: No such file or directory

The following call works fine:
f<-cfunction(sig, body=code, includes=inc, cppargs=cppa, libargs=liba,
Rcpp=TRUE, verbose=TRUE)

And now the same setCMethod call from above will work:
setCMethod("getSigItem", sig, body=code, includes=inc, Rcpp=TRUE,
verbose=TRUE)


Thanks for any help you can provide

Troy


From Thorn.Thaler at rdls.nestle.com  Mon Mar 19 15:44:37 2012
From: Thorn.Thaler at rdls.nestle.com (Thaler,Thorn,LAUSANNE,Applied Mathematics)
Date: Mon, 19 Mar 2012 15:44:37 +0100
Subject: [Rd] Design choice of plot.design for formulas
Message-ID: <F54EF8F1B477CF448729593FE421F646714F9B@HQVEVE0032.nestle.com>

Dear all,

Today I figured out that the formula interface of plot.design is kind of
counter intuitive. Suppose the following setting

ddf <- expand.grid(a=factor(1:3), b=factor(1:3))
ddf$y <- rnorm(9)
plot.design(y ~ a + b, data=ddf)

which does what it should do, basically printing the means for the
respective levels of the factors. I had to learn that the function does
not care at all whether I specify a variable at the LHS or the RHS of
the formula. Thus, the following commands are all equivalent

plot.design(~ y + a + b, data=ddf)
plot.design(a ~ y + b, data=ddf)
plot.design(b ~ y + a, data=ddf)

A closer look into the code revealed that the function basically looks
whether a variable is numeric or a factor. All factors are supposed to
be stratification factors, while all numerical variables are supposed to
be responses. While the former assumption makes sense, the latter is
misleading in conjunction with the formula interface:

ddf$z <- sample(3, 9, TRUE)
plot.design(y ~ a + z, data=ddf)

In my reading that should produce a plot where a and z are regarded as
stratification factors, while y is the response. Instead the function
regards y and z as responses.

So my question: is there a particular reason why the formatting of a
variable in a data frame (factor vs. numerical) takes precedence over
the specification in the formula interface of plot.design? Is it the
case that one cannot specify multiple responses otherwise? In this case,
I was wondering whether an approach like in lattice where one can
specify multiple responses would be useful:

ddf$y.new <- rnorm(9)
lattice:::xyplot(y + y.new ~ a, data = ddf, pch = 15) 

Thanks for your feedback.

Kind regards,

-Thorn


From hadley at rice.edu  Mon Mar 19 17:53:05 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 19 Mar 2012 11:53:05 -0500
Subject: [Rd] Converting expression to a function
In-Reply-To: <4F6614E0.70000@uottawa.ca>
References: <4F6614E0.70000@uottawa.ca>
Message-ID: <CABdHhvGQksD3JpoGSFO3QK4T+j89B9PYo3hVoDCFkxszXypreg@mail.gmail.com>

Hi John,

Here's a somewhat streamlined version of the code:

Form2resfun <- function(f, params) {
  stopifnot(inherits(f, "formula"), length(f) == 3)

  # Create function body
  body <- substitute(
    crossprod(rhs - lhs), list(lhs = f[[2]], rhs = f[[3]])
  )

  # Create argument list
  free_params <- setdiff(all.vars(f), names(params))
  missing_args <- setNames(rep(list(bquote()), length(free_params)),
    free_params)
  args <- as.pairlist(c(missing_args, params))

  eval(call("function", args, body))
}

# a test
tfn <- Form2resfun(y ~ b1 / (1 + b2 * exp(-1 * b3 * t)),
  c(b1 = 1, b2 = 1, b3 = 1))

tfn

y <- c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443,
     38.558, 50.156, 62.948, 75.995, 91.972)
tfn(y, seq_along(y))


It basically works by generating the call to "function", so you get
back a regular function (although I haven't made sure it has the
environment that you might expect).  A couple of tricks:

* bquote() generates a call that represents a missing value

* using as.pairlist to make sure that the arugments argument to
function is a pairlist - as far as I know this is the only case where
you need to care about the difference between lists and pairlists

You may also want to chat with Randy Pruim, who seems to be working on
similar stuff.

Hadley


On Sun, Mar 18, 2012 at 12:01 PM, John C Nash <nashjc at uottawa.ca> wrote:
> Previously, I've posted queries about this, and thanks to postings and messages in
> response have recently had some success, to the extent that there is now a package called
> nlmrt on the R-forge project https://r-forge.r-project.org/R/?group_id=395 for solving
> nonlinear least squares problems that include small or zero residual problems via a
> Marquardt method using a call that mirrors the nls() function. nls() specifically warns
> against zero residual problems.
>
> However, I would still like to be able to convert expressions with example vectors of
> parameters to functions that optim() and related functions can use. The code below gets
> "almost" there, but
>
> 1) Can the code be improved / cleaned up?
>
> 2) Can the eval() of the output of the Form2resfun be avoided?
>
> 3) Can the extraction of the parameter names be embedded in the function rather than put
> separately?
>
> Off-list responses are likely best at this stage, while the tedious details are sorted
> out. I will post a summary in a couple of weeks of the results. Collaborations re: this
> and the larger package welcome, as there is considerable testing and tuning to do, but
> preliminary experience is encouraging.
>
> John Nash
>
>
> # --------- code block -----------
> rm(list=ls()) # clear workspace
> Form2resfun <- function(f, p ) {
> ? ? ? ?cat("In Form2resfun\n")
> ? ? ? ?xx <- all.vars(f)
> ? ? ? ?fp <- match(names(p), xx) # Problem in matching the names of params
> ? ? ? ?xx2 <- c(xx[fp], xx[-fp])
> ? ? ? ?ff <- vector("list", length(xx2))
> ? ? ? ?names(ff) <- xx2
> ? ? ? ?sf<-as.character(f)
> ? ? ? ?if ((length(sf)!=3) && (sf[1]!="~")) stop("Bad model formula expression")
> ? ? ? ?lhs<-sf[2] # NOTE ORDER formula with ~ puts ~, lhs, rhs
> ? ? ? ?rhs<-sf[3]
> # And build the residual at the parameters
> ? ? ? ?resexp<-paste(rhs,"-",lhs, collapse=" ")
> ? ? ? ?fnexp<-paste("crossprod(",resexp,")", sep="")
> ? ? ? ?ff[[length(ff) + 1]] <- parse(text=fnexp)
> # ?want crossprod(resexp)
> ? ? ? ?myfn<-as.function(ff, parent.frame())
> }
> # a test
> ? ?y<-c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443,
> ? ? ? ? ?38.558, 50.156, 62.948, 75.995, 91.972) # for testing
> ? ?t<-1:length(y) # for testing
> ? ?f<- y ~ b1/(1+b2*exp(-1*b3*t))
> ? ?p<-c(b1=1, b2=1, b3=1)
> ? ?b<-p
> ? ?npar<-length(b)
> ? ?for (i in 1:npar){
> ? ? ? ? ? ? ? ?bbit<-paste(names(b)[[i]],"<-",b[[i]])
> ? ? ? ? ? ? ? ?eval(parse(text=bbit))
> ? ?}
> ? ?tfn<-Form2resfun(f, b)
> ? ?ans<-eval(tfn(t=t,y=y, b))
> ? ?print(ans)
> # --------- end code block -----------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From therneau at mayo.edu  Mon Mar 19 18:01:38 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 19 Mar 2012 12:01:38 -0500
Subject: [Rd] Problem with table
Message-ID: <4F676672.6070303@mayo.edu>

R version 2.14.0, started with --vanilla

 > table(c(1,2,3,4,NA), exclude=2, useNA='ifany')
    1    3    4 <NA>
    1    1    1    2

This came from a local user who wanted to remove one particular response 
from some tables, but also wants to have NA always reported for data 
checking purposes.
   I don't think the above is what anyone would want.

PS.
This is on a background of our local desires, which is to have the 
default action of the table command be
to report NA, if present.  (It's one of the only commands that we 
globally override at Mayo.)  The user had
added only the exclude=2 argument, and the useNA value is our default.

The above makes this harder to do without rewriting the command 
wholesale, which is ok (we've done it before at
various times in R and Splus) but we would avoid it if possible.  Please 
no wars about whether this is the "right" decison or not, we've done it 
for 10+ years and quite firmly believe the extra robustness gained by 
having NA appear
is worth the maintainance bother, correctness being paramount in medical 
research.  We're not trying to convert anyone
else, just get feedback on the best way to approach this.

Terry T.


From sdmorris at u.washington.edu  Mon Mar 19 20:17:39 2012
From: sdmorris at u.washington.edu (Stephanie M. Gogarten)
Date: Mon, 19 Mar 2012 12:17:39 -0700
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <mailman.21.1332154808.27988.r-devel@r-project.org>
References: <mailman.21.1332154808.27988.r-devel@r-project.org>
Message-ID: <4F678653.7010904@u.washington.edu>

I would like to add a vote for keeping blank suffixes in merge(), as I 
routinely use this functionality.  An example use case:

# using R 2.14.1
# d1 is some data that I've been working on for a while
d1 <- data.frame(a=letters[1:10], b=1:10)
# d2 is some new data from a collaborator.  I want to add one of these # 
columns to d1, and also check that the existing columns are consistent
d2 <- data.frame(a=letters[1:10], b=1:10, c=101:110)

# use blank suffix to avoid changing the column names of my
# original data frame
d3 <- merge(d1, d2, by="a", suffixes=c("", ".new"))
all(d3$b == d3$b.new)
# if this is FALSE, time to email collaborator
d3$b.new <- NULL

In real usage d1 would have many more columns than d2, so adding 
suffixes to d1 would be tedious to undo after the merge.

Stephanie Gogarten
Research Scientist, Biostatistics
University of Washington

On 3/19/12 4:00 AM, r-devel-request at r-project.org wrote:
> Message: 12
> Date: Sun, 18 Mar 2012 15:48:30 -0400
> From: Steve Lianoglou<mailinglist.honeypot at gmail.com>
> To: Uwe Ligges<ligges at statistik.tu-dortmund.de>
> Cc: Matthew Dowle<mdowle at mdowle.plus.com>,r-devel at r-project.org
> Subject: Re: [Rd] merge bug fix in R 2.15.0
> Message-ID:
> 	<CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Hi Uwe,
>
> 2012/3/17 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>> >
>> >
>> >  On 15.03.2012 22:48, Matthew Dowle wrote:
>>> >>
>>> >>
>>> >>  Anyone?
>>> >>
>>>> >>>  Is it intended that the first suffix can no longer be blank? Seems to be
>>>> >>>  caused by a bug fix to merge in R 2.15.0.
>> >
>> >
>> >
>> >  Right, the user is now protected against confusing himself by using names
>> >  that were not unique before the merge.
> ... now I'm confused:-)
>
> If the user explicitly asks for a NULL/0/empty/whatever suffix,
> they're not really going to be confusing themselves, right?
>
> I actually feel like I do this often, where "this" is explicitly
> asking to not add a suffix to one group of columns ... I do confuse
> myself every and now and again, but not in this context, yet.
>
> I can see that*this*  confusing case is now handled w/ this change
> (which wasn't before):
>
> ## I'm using R-devel compiled back in November, 2011 (r57571)
> R>  d1<- data.frame(a=letters[1:10], b=rnorm(10), b.x=tail(letters, 10))
> R>  d2<- data.frame(a=letters[1:10], b=101:110)
> R>  merge(d1, d2, by='a', suffixes=c('.x', '.y'))
>     a         b.x b.x b.y
> 1  a -1.52250626   q 101
> 2  b -0.99865341   r 102
> ... ## Let's call this "exhibit A"
>
> But if I do this:
> R>  merge(d1, d2, by='a', suffixes=c("", ".y"))
>
> I totally expect:
>
>     a           b b.x b.y
> 1  a -1.52250626   q 101
> 2  b -0.99865341   r 102
> ## Let's call this "exhibit B"
> ...
>
> and not (using R-2.15.0 beta) (exhibit B):
>
> Error in merge.data.frame(d1, d2, by = "a", suffixes = c("", ".y")) :
>    there is already a column named 'b'
>
> I can take a crack at a patch to keep the "rescue user from surprises"
> example outlined in "exhibit A," but also letting user accomplish
> "exhibit B" if there is a consensus of agreement on this particular
> world view.
>
> -steve
>
> -- Steve Lianoglou Graduate Student: Computational Systems Biology ?|
> Memorial Sloan-Kettering Cancer Center ?| Weill Medical College of
> Cornell University Contact Info: http://cbio.mskcc.org/~lianos/contact


From spluque at gmail.com  Mon Mar 19 21:25:20 2012
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 19 Mar 2012 15:25:20 -0500
Subject: [Rd] bzip2'ed data under data/
Message-ID: <877gygtk27.fsf@kolob.subpolar.dyndns.org>

Hi,

R CMD check PACKAGE_VERSION_tar.gz gives warning:

Files not of a type allowed in a ?data? directory:
  ?tser1.csv.bz2? ?tser2.csv.bz2?
Please use e.g. ?inst/extdata? for non-R data files

which I didn't expect, based on section 1.1.5 (Data in packages) of the
Writing R Extensions manual:

Tables (`.tab', `.txt', or `.csv' files) can be compressed by
`gzip', `bzip2' or `xz', optionally with additional extension `.gz',
`.bz2' or `.xz'.  However, such files can only be used with R 2.10.0 or
later, and so the package should have an appropriate `Depends' entry in
its DESCRIPTION file.

In this case, I have a Depends: R (>= 2.13.0), and the package was built
with R version 2.15.0 beta (2012-03-16 r58769), Platform:
x86_64-pc-linux-gnu (64-bit), so I don't understand the warning.

Cheers,

-- 
Seb


From spencer.graves at structuremonitoring.com  Mon Mar 19 23:27:10 2012
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 19 Mar 2012 15:27:10 -0700
Subject: [Rd] diff(time) vs. difftime?
Message-ID: <4F67B2BE.2040307@structuremonitoring.com>

       I just encountered another RTFM problem:  With 
diff(as.POSIXct(...), ...) I was unable to control the units of the 
results.  Examples:


 > (d.d <- diff(as.POSIXct(c('2012-12-12', '2012-12-13'))))
Time difference of 1 days
 > (d.h <- diff(as.POSIXct(c('2012-12-12 08:00', '2012-12-12 09:00'))))
Time difference of 1 hours
 > (d.m <- diff(as.POSIXct(c('2012-12-12 08:00', '2012-12-12 08:01'))))
Time difference of 1 mins
 > (d.s <- diff(as.POSIXct(c('2012-12-12 08:00:00', '2012-12-12 
08:00:01'))))
Time difference of 1 secs
 > as.numeric(d.d)
[1] 1
 > as.numeric(d.s)
[1] 1


       methods('diff') identified the following:


[1] diff.Date    diff.default diff.POSIXt  diff.ts      diff.zoo*


       In looking at the help pages for each of these functions, I found 
no mention of "difftime" or any other way to control the units.


  methods('-')
[1] -.Date     -.POSIXt   -.yearmon* -.yearqtr*


        ?"-.Date" didn't seem helpful on this, either.  ?"-.POSIXt" 
contained a link to "difftime", but I didn't see that until after I read 
the code for "-.POSIXt" and found "difftime".


       I humbly beseech ye to consider adding a difftime example to all 
these help pages.


       Thanks,
       Spencer


p.s.  In case there is any doubt, I very much appreciate all the work 
that the R Core team has invested in making R what it is today.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From spencer.graves at structuremonitoring.com  Tue Mar 20 00:07:59 2012
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 19 Mar 2012 16:07:59 -0700
Subject: [Rd] diff(time) vs. difftime?
Message-ID: <4F67BC4F.5090402@structuremonitoring.com>

	  I've just uncovered an infelicity in as.difftime:


 > as.difftime(diff(as.POSIXct(c('2012-12-12', '2012-12-13'))), 
units='hours')
Time difference of 1 days


	  Is this a bug in the code or in my understanding?


	  Thanks again for all your hard work in making R the great product it 
is and in answering so many questions.


	  Best Wishes,
	  Spencer


 > sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] zoo_1.7-7      RODBC_1.3-4    WriteXLS_2.1.0 sos_1.3-1 
brew_1.0-6

loaded via a namespace (and not attached):
[1] grid_2.14.1    lattice_0.20-0 tools_2.14.1


############################


       I just encountered another RTFM problem:  With 
diff(as.POSIXct(...), ...) I was unable to control the units of the 
results.  Examples:


> (d.d <- diff(as.POSIXct(c('2012-12-12', '2012-12-13'))))
Time difference of 1 days
> (d.h <- diff(as.POSIXct(c('2012-12-12 08:00', '2012-12-12 09:00'))))
Time difference of 1 hours
> (d.m <- diff(as.POSIXct(c('2012-12-12 08:00', '2012-12-12 08:01'))))
Time difference of 1 mins
> (d.s <- diff(as.POSIXct(c('2012-12-12 08:00:00', '2012-12-12
08:00:01'))))
Time difference of 1 secs
> as.numeric(d.d)
[1] 1
> as.numeric(d.s)
[1] 1


       methods('diff') identified the following:


[1] diff.Date    diff.default diff.POSIXt  diff.ts      diff.zoo*


       In looking at the help pages for each of these functions, I found 
no mention of "difftime" or any other way to control the units.


  methods('-')
[1] -.Date     -.POSIXt   -.yearmon* -.yearqtr*


        ?"-.Date" didn't seem helpful on this, either.  ?"-.POSIXt" 
contained a link to "difftime", but I didn't see that until after I read 
the code for "-.POSIXt" and found "difftime".


       I humbly beseech ye to consider adding a difftime example to all 
these help pages.


       Thanks,
       Spencer


p.s.  In case there is any doubt, I very much appreciate all the work 
that the R Core team has invested in making R what it is today.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From dtenenba at fhcrc.org  Tue Mar 20 03:27:07 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 19 Mar 2012 19:27:07 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
Message-ID: <CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>

Hello,

Sorry to repeat myself, but I was wondering if anyone had taken a look at this.

Because of this problem, reference manuals are not being created for
many Bioconductor packages (any package where there is a \Sexpr in an
.Rd file).

Thanks in advance--we appreciate your help very much.
Dan


On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> Hi,
>
> The following command:
> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test genefu-package.Rd
> run against this file:
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
> (username: readonly; password: readonly)
>
> produces a very verbose error (see below)
> with R version 2.15.0 alpha (2012-03-07 r58622).
>
> The .Rd file has these lines in it:
>
> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>
> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
> command will complete successfully.
>
> Is there some other step I need to run to evaluate the \Sexpr tags
> before running Rd2pdf, or is there an issue that needs to be fixed?
>
> Thanks,
> Dan
>
> Error output:
>
> Converting Rd files to LaTeX ...
> ?genefu-package.Rd
> Creating pdf output from LaTeX ...
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet, ?:
> ?Running 'texi2dvi' on 'Rd2.tex' failed.
> Messages:
> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
> /usr/bin/texi2dvi: see Rd2.log for errors.
> Output:
> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
> ?restricted \write18 enabled.
> entering extended mode
> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
> LaTeX2e <2011/06/27>
> Babel <v3.8m> and hyphenation patterns for english, dumylang, nohyphenation, ge
> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus, arabi
> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
> h, french, galician, german, ngerman, swissgerman, monogreek, greek, hungarian,
> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, marathi, or
> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, kurmanji,
> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk, pol
> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak, sloven
> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh, loaded
> .
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
> NOT loading lmodern
> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>
> Package hyperref Message: Driver (autodetected): hpdftex.
>
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>
> Package hyperref Warning: Option `hyperindex' has already been used,
> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line 356.
>
>
> Package hyperref Warning: Option `pagebackref' has already been used,
> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line 356.
>
> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
> Writing index file Rd2.idx
> No file Rd2.aux.
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
> [Loading MPS to PDF converter (version 2006.09.02).]
> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Missing \end
> group inserted.
> <inserted text>
> ? ? ? ? ? ? ? ?\endgroup
> l.39 }
>
> ?
> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Emergency st
> op.
> <inserted text>
> ? ? ? ? ? ? ? ?\endgroup
> l.39 }
>
> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: ?==> Fatal e
> rror occurred, no output PDF file produced!
> Transcript written on Rd2.log.
> Error in running tools::texi2pdf


From michael.weylandt at gmail.com  Mon Mar 19 21:00:39 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 19 Mar 2012 16:00:39 -0400
Subject: [Rd] enableJIT(3) with Primitives
Message-ID: <CAAmySGO4mGfYU=aaSN6V7exKWo3YDAEcM4M6xeFDRhevRZt_4g@mail.gmail.com>

I'm not sure if this is a bug or expected behavior, but I don't see
anything in the documentation that explains it, so I thought I'd
mention it:

~ michaelweylandt$ R -q --vanilla

library(compiler)
enableJIT(3)

`+` # Throws an error
`+` # Throws a warning
`+` # Prints the primitive as expected

sessionInfo()

R version 2.14.1 (2011-12-22)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] compiler  stats     graphics  grDevices utils     datasets  methods
[8] base

It seems to be independent of which primitives are used and I get the
same behavior with r58785 built locally.

Michael


From luke-tierney at uiowa.edu  Tue Mar 20 15:16:56 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 20 Mar 2012 09:16:56 -0500
Subject: [Rd] enableJIT(3) with Primitives
In-Reply-To: <CAAmySGO4mGfYU=aaSN6V7exKWo3YDAEcM4M6xeFDRhevRZt_4g@mail.gmail.com>
References: <CAAmySGO4mGfYU=aaSN6V7exKWo3YDAEcM4M6xeFDRhevRZt_4g@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1203200916360.980@luke-Latitude>

Bug -- will look into it.

luke

On Mon, 19 Mar 2012, R. Michael Weylandt wrote:

> I'm not sure if this is a bug or expected behavior, but I don't see
> anything in the documentation that explains it, so I thought I'd
> mention it:
>
> ~ michaelweylandt$ R -q --vanilla
>
> library(compiler)
> enableJIT(3)
>
> `+` # Throws an error
> `+` # Throws a warning
> `+` # Prints the primitive as expected
>
> sessionInfo()
>
> R version 2.14.1 (2011-12-22)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] compiler  stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> It seems to be independent of which primitives are used and I get the
> same behavior with r58785 built locally.
>
> Michael
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From pauljohn32 at gmail.com  Tue Mar 20 16:24:30 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 20 Mar 2012 10:24:30 -0500
Subject: [Rd] overriding "summary.default" or "summary.data.frame". How?
Message-ID: <CAErODj_AE31DneOFZi6XBKY-PZV9WEo=oHuEt6MdMJFw0QCeBg@mail.gmail.com>

I suppose everybody who makes a package for the first time thinks "I
can change anything!" and then runs into this same question. Has
anybody written out information on how a package can override
functions in R base in the R 2.14 (mandatory NAMESPACE era)?

Suppose I want to alphabetize variables in a summary.data.frame, or
return the standard deviation with the mean in summary output.  I'm
pasting in a working example below.  It has new "summary.factor"
method. It also has a function summarize that I might like to use in
place of summary.data.frame.

How would my new methods "drop on top" of R base functions?  It
appears my functions (summarizeFactors) can find my summary.factor,
but R's own summary uses its own summary.factor.


## summarizeNumerics takes a data frame or matrix, scans the columns
## to select only the numeric variables.  By default it alphabetizes
## the columns (use alphaSort = FALSE to stop that). It then
## calculates the quantiles for each variable, as well as the mean,
## standard deviation, and variance, and then packs those results into
## a matrix. The main benefits from this compared to R's default
## summary are 1) more summary information is returned for each
## variable, and the results are returned in a matrix that is easy to
## use in further analysis.
summarizeNumerics <- function(dat, alphaSort = TRUE,  digits = max(3,
getOption("digits") - 3)){
  if (!is.data.frame(dat)) dat <- as.data.frame(dat)
  nums <- sapply(dat, is.numeric)
  datn <- dat[ , nums, drop = FALSE]
  if (alphaSort) datn <- datn[ , sort(colnames(datn)), drop = FALSE]
  sumdat <- apply(datn, 2, stats::quantile, na.rm=TRUE)
  sumdat <- rbind(sumdat, mean= apply(datn, 2, mean, na.rm=TRUE))
  sumdat <- rbind(sumdat, sd= apply(datn, 2, sd, na.rm=TRUE))
  sumdat <- rbind(sumdat, var= apply(datn, 2, var, na.rm=TRUE))
  sumdat <- rbind(sumdat, "NA's"=apply(datn, 2, function(x) sum(is.na(x))))
  signif(sumdat, digits)
}


summary.factor <- function(y, numLevels) {
  ## 5 nested functions to be used later

  divr <- function(p=0){
    ifelse ( p>0 & p < 1, -p * log2(p), 0)
  }
  entropy <- function(p){
    sum ( divr(p) )
  }
  maximumEntropy <- function(N) -log2(1/N)
  normedEntropy <- function(x) entropy(x)/ maximumEntropy(length(x))
  nas <- is.na(y)
  y <- factor(y)
  ll <- levels(y)
  tbl <- table(y)
  tt <- c(tbl)
  names(tt) <- dimnames(tbl)[[1L]]
  o <- sort.list(tt, decreasing = TRUE)
  if (length(ll) > numLevels){
    toExclude <- numLevels:length(ll)
    tt <- c(tt[o[-toExclude]], `(All Others)` = sum(tt[o[toExclude]]),
`NA's`=sum(nas))
  }else{
    tt <- c(tt[o], `NA's`=sum(nas))
  }
  props <- prop.table(tbl);
  tt <- c(tt, "Entropy"=entropy(props), "NormedEntropy"= normedEntropy(props))
}


## Takes a data frame or matrix, scans the columns to find the
## variables that are not numeric and keeps them. By default it
## alphabetizes them (alphaSort = FALSE to stop that).  It then treats
## all non-numeric variables as if they were factors, and summarizes
## each in a say that I find useful. In particular, for each factor,
## it provides a table of the most frequently occurring values (the
## top "numLevels" values are represented).  As a diversity indictor,
## it calculates the Entropy and NormedEntropy values for each
## variable.  Note not all of this is original. It combines my code
## and R code from base/summary.R
summarizeFactors  <- function(dat = NULL, numLevels = 10, alphaSort =
TRUE, digits = max(3, getOption("digits") - 3))
{

  ##copies from R base::summary.R summary.data.frame
  ncw <- function(x) {
    z <- nchar(x, type="w")
    if (any(na <- is.na(z))) {
            # FIXME: can we do better
      z[na] <- nchar(encodeString(z[na]), "b")
    }
    z
  }

  if (!is.data.frame(dat)) dat <- as.data.frame(dat)
  ##treat any nonnumeric as a factor
  factors <- sapply(dat, function(x) {!is.numeric(x) })
  ##If only one factor, need drop=FALSE.
  datf <- dat[ , factors, drop = FALSE]
  if (alphaSort) datf <- datf[ , sort(colnames(datf)), drop = FALSE]
  z  <- lapply(datf, summary.factor, numLevels=numLevels)
  nv <- length(datf)
  nm <- names(datf)
  lw <- numeric(nv)
  nr <- max(unlist(lapply(z, NROW)))
  for(i in 1L:nv) {
    sms <- z[[i]]
    lbs <- format(names(sms))
    sms <- paste(lbs, ":", format(sms, digits = digits), "  ",
                 sep = "")
    lw[i] <- ncw(lbs[1L])
    length(sms) <- nr
    z[[i]] <- sms
  }
  z <- unlist(z, use.names=TRUE)
  dim(z) <- c(nr, nv)
  if(any(is.na(lw)))
    warning("probably wrong encoding in names(.) of column ",
            paste(which(is.na(lw)), collapse = ", "))
    blanks <- paste(character(max(lw, na.rm=TRUE) + 2L), collapse = " ")
  pad <- floor(lw - ncw(nm)/2)
  nm <- paste(substring(blanks, 1, pad), nm, sep = "")
  dimnames(z) <- list(rep.int("", nr), nm)
  attr(z, "class") <- c("table")
  z
}

##
## want to override summary.data.frame, but confusing.  When
## will R find my summary.data.frame, when will it find the one in base.
## use ... for numLevels, digits, alphaSort
summarize <- function(dat, ...)
{
  dots <- list(...)
  dotnames <- names(dots)
  ## next should give c("digits", "alphaSort")
  nnames <-  names(formals(summarizeNumerics))[-1L]
  ## names that need keeping if in dots:
  keepnames <- dotnames %in% nnames
  if( sum(keepnames) > 0 ) {
    argList <- modifyList( list("dat"=quote(dat)), dots[keepnames] )
    datn <- do.call("summarizeNumerics", argList)
   } else {
    datn <- do.call("summarizeNumerics", args=list("dat"= quote(dat)))
  }

  ## all ... can go to summarizeFactors
  datf <- summarizeFactors(dat, ...)

  value <- list(numerics = datn, factors = datf)
  value
}




set.seed(23452345)
x1 <- gl(12,2, labels=LETTERS[1:12])
x2 <- gl(8,3, labels=LETTERS[12:24])
z1 <- rnorm(24)
a1 <- rnorm(24, mean=1.2, sd = 1.7)
a2 <- rpois(24, lambda=10 + a1)
a3 <- rgamma(24, 0.5, 4)
b1 <- rnorm(24, mean=1.3, sd = 1.4)
dat <- data.frame(z1, a1, x2, a2, x1, a3, b1)
summary(dat)


summarize(dat)


summarizeNumerics(dat)
summarizeFactors(dat, numLevels=5)

summarize(dat, alphaSort=FALSE)

summarize(dat, digits=6, alphaSort=FALSE)

summarize(dat, digits=22, alphaSort=FALSE)

summarize(dat, numLevels= 2)

datsumm <- summarize(dat)

datsumm$numerics
datsumm[[1]] ## same: gets numerics

datsumm$factors
datsumm[[2]]


## Use numerics output to make plots. First,
## transpose gives varnames x summary stat matrix
datsummNT <- t(datsumm$numerics)
datsummNT <- as.data.frame(datsummNT)

plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The Variances")

plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
Variances", type="n")
text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT))

## Here's a little plot wrinkle.  Note variable names are "out to the
## edge" of the plot. If names are longer they don't stay inside
## figure. See?

## Make the variable names longer

rownames(datsummNT)
rownames(datsummNT) <- c("boring var","var with long name", "tedious
name var", "stupid varname", "buffoon not baboon")
plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
Variances", type="n")
text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)
## That's no good. Names across the edges

## We could brute force the names outside the edges like this
par(xpd=T)
text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)
## but that is not much better
par(xpd=F)

## Here is one fix. Make the unused space inside the plot larger by
## making xlim and ylim bigger.  I use the magRange function from
## rockchalk to easily expand range to 1.2 times its current size.
## otherwise, long variable names do not fit inside plot. magRange
## could be asymmetric if we want, but this use is symmetric.
library(rockchalk)

rownames(datsummNT)
rownames(datsummNT) <- c("boring var","var with long name", "tedious
name var", "stupid varname", "buffoon not baboon")
plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
Variances", type="n", xlim=magRange(datsummNT$mean, 1.2),
ylim=magRange(datsummNT$var, 1.2))
text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)

## Here's another little plot wrinkle.
## If we don't do that to keep the names in bounds, we need some
## fancy footwork.  Note when a point is near the edge, I make sure
## the text prints toward the center of the graph.
plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The Variances")
## calculate label positions. This is not as fancy as it could be.
## If there were lots of variables, we'd have to get smarter about
## positioning labels on above, below, left, or right.
labelPos <- ifelse(datsummNT$mean - mean(datsummNT$mean, na.rm=T) > 0, 2, 4)
text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT),
cex=0.8, pos=labelPos)



x <- data.frame(x=rnorm(100), y = gl(50,2), z = rep(1:4, 25), ab = gl(2,50))

summarize(x)
summarize(x, numLevels=15)

sumry <- summarize(x)
sumry[[1]] ##another way to get the numerics output
sumry[[2]] ##another way to get the factors output

dat <- data.frame(x=rnorm(100), y = gl(50,2), z = factor(rep(1:4, 25),
labels=c("A","B","C","D")), animal=factor(ifelse(runif(100)< 0.2,
"cow", ifelse(runif(100) < 0.5,"pig","duck"))))

summarize(dat)

dat <- read.table(url("http://pj.freefaculty.org/guides/stat/DataSets/USNewsCollege/USNewsCollege.csv"),
sep=",")

colnames(dat) <- c("fice", "name", "state", "private", "avemath", "aveverb",
    "avecomb", "aveact", "fstmath", "trdmath", "fstverb", "trdverb",
    "fstact", "trdact", "numapps", "numacc", "numenr", "pctten",
    "pctquart", "numfull", "numpart", "instate", "outstate",
    "rmbrdcst", "roomcst", "brdcst", "addfees", "bookcst", "prsnl",
    "pctphd", "pctterm", "stdtofac", "pctdonat", "instcst", "gradrate")

dat$private <- factor(dat$private, labels=c("public","private"))
sumry <- summarize(dat, digits=2)
sumry

sumry[[1]]
sumry[[2]]

summarize(dat[ , c("fice","name","private","fstverb","avemath")], digits=4)


-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From murdoch.duncan at gmail.com  Tue Mar 20 18:21:05 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Mar 2012 13:21:05 -0400
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
Message-ID: <4F68BC81.20506@gmail.com>

On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
> Hello,
>
> Sorry to repeat myself, but I was wondering if anyone had taken a look at this.

No.  Could you put together a simple self contained example?  I don't 
have any BioC packages installed.

Alternatively, you could take a look at the .tex files generated, and 
identify what the problem is.

Duncan Murdoch

>
> Because of this problem, reference manuals are not being created for
> many Bioconductor packages (any package where there is a \Sexpr in an
> .Rd file).
>
> Thanks in advance--we appreciate your help very much.
> Dan
>
>
> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>  wrote:
>> Hi,
>>
>> The following command:
>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test genefu-package.Rd
>> run against this file:
>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>> (username: readonly; password: readonly)
>>
>> produces a very verbose error (see below)
>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>
>> The .Rd file has these lines in it:
>>
>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>
>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>> command will complete successfully.
>>
>> Is there some other step I need to run to evaluate the \Sexpr tags
>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>
>> Thanks,
>> Dan
>>
>> Error output:
>>
>> Converting Rd files to LaTeX ...
>>   genefu-package.Rd
>> Creating pdf output from LaTeX ...
>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>>   Running 'texi2dvi' on 'Rd2.tex' failed.
>> Messages:
>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>> /usr/bin/texi2dvi: see Rd2.log for errors.
>> Output:
>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>   restricted \write18 enabled.
>> entering extended mode
>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>> LaTeX2e<2011/06/27>
>> Babel<v3.8m>  and hyphenation patterns for english, dumylang, nohyphenation, ge
>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus, arabi
>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
>> h, french, galician, german, ngerman, swissgerman, monogreek, greek, hungarian,
>>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, marathi, or
>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, kurmanji,
>>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk, pol
>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak, sloven
>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh, loaded
>> .
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>> NOT loading lmodern
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>
>> Package hyperref Message: Driver (autodetected): hpdftex.
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>
>> Package hyperref Warning: Option `hyperindex' has already been used,
>> (hyperref)                setting the option has no effect on input line 356.
>>
>>
>> Package hyperref Warning: Option `pagebackref' has already been used,
>> (hyperref)                setting the option has no effect on input line 356.
>>
>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>> Writing index file Rd2.idx
>> No file Rd2.aux.
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>> [Loading MPS to PDF converter (version 2006.09.02).]
>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Missing \end
>> group inserted.
>> <inserted text>
>>                 \endgroup
>> l.39 }
>>
>> ?
>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: Emergency st
>> op.
>> <inserted text>
>>                 \endgroup
>> l.39 }
>>
>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:  ==>  Fatal e
>> rror occurred, no output PDF file produced!
>> Transcript written on Rd2.log.
>> Error in running tools::texi2pdf
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Tue Mar 20 18:25:13 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 20 Mar 2012 10:25:13 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <4F68BC81.20506@gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
Message-ID: <CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>

On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>
>> Hello,
>>
>> Sorry to repeat myself, but I was wondering if anyone had taken a look at
>> this.
>
>
> No. ?Could you put together a simple self contained example? ?I don't have
> any BioC packages installed.
>

I did supply a self-contained example.
You do not need any BioC packages installed.
All you need is this file:

https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
(username: readonly, password: readonly)
And this command:
R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test genefu-package.Rd
No .tex file is generated.

Thanks!
Dan


> Alternatively, you could take a look at the .tex files generated, and
> identify what the problem is.
>
> Duncan Murdoch
>
>>
>> Because of this problem, reference manuals are not being created for
>> many Bioconductor packages (any package where there is a \Sexpr in an
>> .Rd file).
>>
>> Thanks in advance--we appreciate your help very much.
>> Dan
>>
>>
>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org> ?wrote:
>>>
>>> Hi,
>>>
>>> The following command:
>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>> genefu-package.Rd
>>> run against this file:
>>>
>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>> (username: readonly; password: readonly)
>>>
>>> produces a very verbose error (see below)
>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>
>>> The .Rd file has these lines in it:
>>>
>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>
>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>> command will complete successfully.
>>>
>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>
>>> Thanks,
>>> Dan
>>>
>>> Error output:
>>>
>>> Converting Rd files to LaTeX ...
>>> ?genefu-package.Rd
>>> Creating pdf output from LaTeX ...
>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
>>> ?:
>>> ?Running 'texi2dvi' on 'Rd2.tex' failed.
>>> Messages:
>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>> Output:
>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>> ?restricted \write18 enabled.
>>> entering extended mode
>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>> LaTeX2e<2011/06/27>
>>> Babel<v3.8m> ?and hyphenation patterns for english, dumylang,
>>> nohyphenation, ge
>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus,
>>> arabi
>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech,
>>> danis
>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi,
>>> finnis
>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>> hungarian,
>>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>> marathi, or
>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>> kurmanji,
>>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>> nynorsk, pol
>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak,
>>> sloven
>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh,
>>> loaded
>>> .
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>> NOT loading lmodern
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>
>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>
>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>>> 356.
>>>
>>>
>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>>> 356.
>>>
>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>> Writing index file Rd2.idx
>>> No file Rd2.aux.
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>> Missing \end
>>> group inserted.
>>> <inserted text>
>>> ? ? ? ? ? ? ? ?\endgroup
>>> l.39 }
>>>
>>> ?
>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>> Emergency st
>>> op.
>>> <inserted text>
>>> ? ? ? ? ? ? ? ?\endgroup
>>> l.39 }
>>>
>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: ?==>
>>> ?Fatal e
>>> rror occurred, no output PDF file produced!
>>> Transcript written on Rd2.log.
>>> Error in running tools::texi2pdf
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Tue Mar 20 18:41:15 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Mar 2012 13:41:15 -0400
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
Message-ID: <4F68C13B.7080806@gmail.com>

On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>
>>> Hello,
>>>
>>> Sorry to repeat myself, but I was wondering if anyone had taken a look at
>>> this.
>>
>>
>> No.  Could you put together a simple self contained example?  I don't have
>> any BioC packages installed.
>>
>
> I did supply a self-contained example.
> You do not need any BioC packages installed.
> All you need is this file:
>
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
> (username: readonly, password: readonly)
> And this command:
> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test genefu-package.Rd

Sorry, I didn't see that.

> No .tex file is generated.

If you use the --no-clean command line option, then the temporary 
directory containing the .tex file will not be deleted.  It contains 
your \Sexpr expressions wrapped in verbatim environments.  I suspect 
this is happening because Rd2pdf isn't running the Sexpr evaluation 
step.  I'll try to take a look and fix it.

Duncan Murdoch

>
> Thanks!
> Dan
>
>
>> Alternatively, you could take a look at the .tex files generated, and
>> identify what the problem is.
>>
>> Duncan Murdoch
>>
>>>
>>> Because of this problem, reference manuals are not being created for
>>> many Bioconductor packages (any package where there is a \Sexpr in an
>>> .Rd file).
>>>
>>> Thanks in advance--we appreciate your help very much.
>>> Dan
>>>
>>>
>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>    wrote:
>>>>
>>>> Hi,
>>>>
>>>> The following command:
>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>> genefu-package.Rd
>>>> run against this file:
>>>>
>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>> (username: readonly; password: readonly)
>>>>
>>>> produces a very verbose error (see below)
>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>
>>>> The .Rd file has these lines in it:
>>>>
>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>
>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>> command will complete successfully.
>>>>
>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>
>>>> Thanks,
>>>> Dan
>>>>
>>>> Error output:
>>>>
>>>> Converting Rd files to LaTeX ...
>>>>   genefu-package.Rd
>>>> Creating pdf output from LaTeX ...
>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
>>>>   :
>>>>   Running 'texi2dvi' on 'Rd2.tex' failed.
>>>> Messages:
>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>> Output:
>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>   restricted \write18 enabled.
>>>> entering extended mode
>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>> LaTeX2e<2011/06/27>
>>>> Babel<v3.8m>    and hyphenation patterns for english, dumylang,
>>>> nohyphenation, ge
>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus,
>>>> arabi
>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech,
>>>> danis
>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi,
>>>> finnis
>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>> hungarian,
>>>>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>> marathi, or
>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>> kurmanji,
>>>>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>> nynorsk, pol
>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak,
>>>> sloven
>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh,
>>>> loaded
>>>> .
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>> NOT loading lmodern
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>
>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>
>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>> (hyperref)                setting the option has no effect on input line
>>>> 356.
>>>>
>>>>
>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>> (hyperref)                setting the option has no effect on input line
>>>> 356.
>>>>
>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>> Writing index file Rd2.idx
>>>> No file Rd2.aux.
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>> Missing \end
>>>> group inserted.
>>>> <inserted text>
>>>>                 \endgroup
>>>> l.39 }
>>>>
>>>> ?
>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>> Emergency st
>>>> op.
>>>> <inserted text>
>>>>                 \endgroup
>>>> l.39 }
>>>>
>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:  ==>
>>>>   Fatal e
>>>> rror occurred, no output PDF file produced!
>>>> Transcript written on Rd2.log.
>>>> Error in running tools::texi2pdf
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From dtenenba at fhcrc.org  Tue Mar 20 18:46:07 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 20 Mar 2012 10:46:07 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <4F68C13B.7080806@gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
	<4F68C13B.7080806@gmail.com>
Message-ID: <CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>

On Tue, Mar 20, 2012 at 10:41 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
>>
>> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>>
>>>>
>>>> Hello,
>>>>
>>>> Sorry to repeat myself, but I was wondering if anyone had taken a look
>>>> at
>>>> this.
>>>
>>>
>>>
>>> No. ?Could you put together a simple self contained example? ?I don't
>>> have
>>> any BioC packages installed.
>>>
>>
>> I did supply a self-contained example.
>> You do not need any BioC packages installed.
>> All you need is this file:
>>
>>
>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>> (username: readonly, password: readonly)
>> And this command:
>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>> genefu-package.Rd
>
>
> Sorry, I didn't see that.
>

Actually,  I goofed, because that file contains the lines:
Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr

And those lines require you to have the 'genefu' package installed.
 I changed those lines to more innocuous \Sexprs:

Version: \tab \Sexpr{cat("hello")}\cr
Date: \tab \Sexpr{cat("world")}\cr



>
>> No .tex file is generated.
>
>
> If you use the --no-clean command line option, then the temporary directory
> containing the .tex file will not be deleted. ?It contains your \Sexpr
> expressions wrapped in verbatim environments. ?I suspect this is happening
> because Rd2pdf isn't running the Sexpr evaluation step.

Yes, that's what I think is happening.

>?I'll try to take a
> look and fix it.

Thanks very much!

I added the --no-clean flag and still got no .tex file. Here is my new
error output, looks the same as the original error output.

Thanks,
Dan

Converting Rd files to LaTeX ...
  genefu-package.Rd
Creating pdf output from LaTeX ...
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  Running 'texi2dvi' on 'Rd2.tex' failed.
LaTeX errors:
/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==> Fatal error occurred, no outpu
t PDF file produced!
Output:
This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
 restricted \write18 enabled.
entering extended mode
(/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex
LaTeX2e <2011/06/27>
Babel <v3.8m> and hyphenation patterns for english, dumylang, nohyphenation, ge
rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus, arabi
c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
h, french, galician, german, ngerman, swissgerman, monogreek, greek, hungarian,
 icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, marathi, or
iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, kurmanji,
 lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk, pol
ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak, sloven
ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh, loaded
.
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
(/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
(/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
NOT loading lmodern
(/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
(/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
(/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
(/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
(/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
(/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))

Package hyperref Message: Driver (autodetected): hpdftex.

(/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
(/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))

Package hyperref Warning: Option `hyperindex' has already been used,
(hyperref)                setting the option has no effect on input line 356.


Package hyperref Warning: Option `pagebackref' has already been used,
(hyperref)                setting the option has no effect on input line 356.

) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
Writing index file Rd2.idx
No file Rd2.aux.
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
(/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
(/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
[Loading MPS to PDF converter (version 2006.09.02).]
) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
(/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
(/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
(/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Missing \endgroup inserted.
<inserted text>
                \endgroup
l.39 }

?
/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Emergency stop.
<inserted text>
                \endgroup
l.39 }

/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==> Fatal error occurred, no outpu
t PDF file produced!
Transcript written on Rd2.log.
Error in running tools::texi2pdf
You may want to clean up by 'rm -rf .Rd2pdf4804'



>
> Duncan Murdoch
>
>
>>
>> Thanks!
>> Dan
>>
>>
>>> Alternatively, you could take a look at the .tex files generated, and
>>> identify what the problem is.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> Because of this problem, reference manuals are not being created for
>>>> many Bioconductor packages (any package where there is a \Sexpr in an
>>>> .Rd file).
>>>>
>>>> Thanks in advance--we appreciate your help very much.
>>>> Dan
>>>>
>>>>
>>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>
>>>> ?wrote:
>>>>>
>>>>>
>>>>> Hi,
>>>>>
>>>>> The following command:
>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>> genefu-package.Rd
>>>>> run against this file:
>>>>>
>>>>>
>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>> (username: readonly; password: readonly)
>>>>>
>>>>> produces a very verbose error (see below)
>>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>>
>>>>> The .Rd file has these lines in it:
>>>>>
>>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>>
>>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>>> command will complete successfully.
>>>>>
>>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>>
>>>>> Thanks,
>>>>> Dan
>>>>>
>>>>> Error output:
>>>>>
>>>>> Converting Rd files to LaTeX ...
>>>>> ?genefu-package.Rd
>>>>> Creating pdf output from LaTeX ...
>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>>>> quiet,
>>>>> ?:
>>>>> ?Running 'texi2dvi' on 'Rd2.tex' failed.
>>>>> Messages:
>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>>> Output:
>>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>> ?restricted \write18 enabled.
>>>>> entering extended mode
>>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>>> LaTeX2e<2011/06/27>
>>>>> Babel<v3.8m> ? ?and hyphenation patterns for english, dumylang,
>>>>> nohyphenation, ge
>>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>>> ibycus,
>>>>> arabi
>>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>>> czech,
>>>>> danis
>>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic,
>>>>> farsi,
>>>>> finnis
>>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>>> hungarian,
>>>>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>>> marathi, or
>>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>>> kurmanji,
>>>>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>>> nynorsk, pol
>>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc,
>>>>> slovak,
>>>>> sloven
>>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian,
>>>>> welsh,
>>>>> loaded
>>>>> .
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading
>>>>> ae
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>>> NOT loading lmodern
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>>
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>>
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>>
>>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>>
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>>
>>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>> line
>>>>> 356.
>>>>>
>>>>>
>>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>> line
>>>>> 356.
>>>>>
>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>>> Writing index file Rd2.idx
>>>>> No file Rd2.aux.
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>>
>>>>>
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>> Missing \end
>>>>> group inserted.
>>>>> <inserted text>
>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>> l.39 }
>>>>>
>>>>> ?
>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>> Emergency st
>>>>> op.
>>>>> <inserted text>
>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>> l.39 }
>>>>>
>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39: ?==>
>>>>> ?Fatal e
>>>>> rror occurred, no output PDF file produced!
>>>>> Transcript written on Rd2.log.
>>>>> Error in running tools::texi2pdf
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>


From murdoch.duncan at gmail.com  Tue Mar 20 19:51:54 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Mar 2012 14:51:54 -0400
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
	<4F68C13B.7080806@gmail.com>
	<CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>
Message-ID: <4F68D1CA.6050900@gmail.com>

On 12-03-20 1:46 PM, Dan Tenenbaum wrote:
> On Tue, Mar 20, 2012 at 10:41 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
>>>
>>> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>    wrote:
>>>>
>>>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>>>
>>>>>
>>>>> Hello,
>>>>>
>>>>> Sorry to repeat myself, but I was wondering if anyone had taken a look
>>>>> at
>>>>> this.
>>>>
>>>>
>>>>
>>>> No.  Could you put together a simple self contained example?  I don't
>>>> have
>>>> any BioC packages installed.
>>>>
>>>
>>> I did supply a self-contained example.
>>> You do not need any BioC packages installed.
>>> All you need is this file:
>>>
>>>
>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>> (username: readonly, password: readonly)
>>> And this command:
>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>> genefu-package.Rd
>>
>>
>> Sorry, I didn't see that.
>>
>
> Actually,  I goofed, because that file contains the lines:
> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>
> And those lines require you to have the 'genefu' package installed.
>   I changed those lines to more innocuous \Sexprs:
>
> Version: \tab \Sexpr{cat("hello")}\cr
> Date: \tab \Sexpr{cat("world")}\cr
>
>
>
>>
>>> No .tex file is generated.
>>
>>
>> If you use the --no-clean command line option, then the temporary directory
>> containing the .tex file will not be deleted.  It contains your \Sexpr
>> expressions wrapped in verbatim environments.  I suspect this is happening
>> because Rd2pdf isn't running the Sexpr evaluation step.
>
> Yes, that's what I think is happening.
>
>>   I'll try to take a
>> look and fix it.
>
> Thanks very much!
>
> I added the --no-clean flag and still got no .tex file. Here is my new
> error output, looks the same as the original error output.
>
> Thanks,
> Dan
>
> Converting Rd files to LaTeX ...
>    genefu-package.Rd
> Creating pdf output from LaTeX ...
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>    Running 'texi2dvi' on 'Rd2.tex' failed.
> LaTeX errors:
> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==>  Fatal error occurred, no outpu
> t PDF file produced!
> Output:
> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>   restricted \write18 enabled.
> entering extended mode
> (/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex
> LaTeX2e<2011/06/27>
> Babel<v3.8m>  and hyphenation patterns for english, dumylang, nohyphenation, ge
> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus, arabi
> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech, danis
> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi, finnis
> h, french, galician, german, ngerman, swissgerman, monogreek, greek, hungarian,
>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam, marathi, or
> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian, kurmanji,
>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal, nynorsk, pol
> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak, sloven
> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh, loaded
> .
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
> NOT loading lmodern
> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>
> Package hyperref Message: Driver (autodetected): hpdftex.
>
> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>
> Package hyperref Warning: Option `hyperindex' has already been used,
> (hyperref)                setting the option has no effect on input line 356.
>
>
> Package hyperref Warning: Option `pagebackref' has already been used,
> (hyperref)                setting the option has no effect on input line 356.
>
> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
> Writing index file Rd2.idx
> No file Rd2.aux.
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
> [Loading MPS to PDF converter (version 2006.09.02).]
> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Missing \endgroup inserted.
> <inserted text>
>                  \endgroup
> l.39 }
>
> ?
> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Emergency stop.

That's the file to look at.  With --no-clean, it should still be there 
after the run, but ls won't show the directory because of the dot in the 
name.

Duncan Murdoch

> <inserted text>
>                  \endgroup
> l.39 }
>
> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==>  Fatal error occurred, no outpu
> t PDF file produced!
> Transcript written on Rd2.log.
> Error in running tools::texi2pdf
> You may want to clean up by 'rm -rf .Rd2pdf4804'
>
>
>
>>
>> Duncan Murdoch
>>
>>
>>>
>>> Thanks!
>>> Dan
>>>
>>>
>>>> Alternatively, you could take a look at the .tex files generated, and
>>>> identify what the problem is.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>> Because of this problem, reference manuals are not being created for
>>>>> many Bioconductor packages (any package where there is a \Sexpr in an
>>>>> .Rd file).
>>>>>
>>>>> Thanks in advance--we appreciate your help very much.
>>>>> Dan
>>>>>
>>>>>
>>>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>
>>>>>   wrote:
>>>>>>
>>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> The following command:
>>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>>> genefu-package.Rd
>>>>>> run against this file:
>>>>>>
>>>>>>
>>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>>> (username: readonly; password: readonly)
>>>>>>
>>>>>> produces a very verbose error (see below)
>>>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>>>
>>>>>> The .Rd file has these lines in it:
>>>>>>
>>>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>>>
>>>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>>>> command will complete successfully.
>>>>>>
>>>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>>>
>>>>>> Thanks,
>>>>>> Dan
>>>>>>
>>>>>> Error output:
>>>>>>
>>>>>> Converting Rd files to LaTeX ...
>>>>>>   genefu-package.Rd
>>>>>> Creating pdf output from LaTeX ...
>>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>>>>> quiet,
>>>>>>   :
>>>>>>   Running 'texi2dvi' on 'Rd2.tex' failed.
>>>>>> Messages:
>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>>>> Output:
>>>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>>>   restricted \write18 enabled.
>>>>>> entering extended mode
>>>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>>>> LaTeX2e<2011/06/27>
>>>>>> Babel<v3.8m>      and hyphenation patterns for english, dumylang,
>>>>>> nohyphenation, ge
>>>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>>>> ibycus,
>>>>>> arabi
>>>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>>>> czech,
>>>>>> danis
>>>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic,
>>>>>> farsi,
>>>>>> finnis
>>>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>>>> hungarian,
>>>>>>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>>>> marathi, or
>>>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>>>> kurmanji,
>>>>>>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>>>> nynorsk, pol
>>>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc,
>>>>>> slovak,
>>>>>> sloven
>>>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian,
>>>>>> welsh,
>>>>>> loaded
>>>>>> .
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading
>>>>>> ae
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>>>> NOT loading lmodern
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>>>
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>>>
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>>>
>>>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>>>
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>>>
>>>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>>>> (hyperref)                setting the option has no effect on input
>>>>>> line
>>>>>> 356.
>>>>>>
>>>>>>
>>>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>>>> (hyperref)                setting the option has no effect on input
>>>>>> line
>>>>>> 356.
>>>>>>
>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>>>> Writing index file Rd2.idx
>>>>>> No file Rd2.aux.
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>>>
>>>>>>
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>> Missing \end
>>>>>> group inserted.
>>>>>> <inserted text>
>>>>>>                 \endgroup
>>>>>> l.39 }
>>>>>>
>>>>>> ?
>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>> Emergency st
>>>>>> op.
>>>>>> <inserted text>
>>>>>>                 \endgroup
>>>>>> l.39 }
>>>>>>
>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:  ==>
>>>>>>   Fatal e
>>>>>> rror occurred, no output PDF file produced!
>>>>>> Transcript written on Rd2.log.
>>>>>> Error in running tools::texi2pdf
>>>>>
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>


From dtenenba at fhcrc.org  Tue Mar 20 19:54:40 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 20 Mar 2012 11:54:40 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <4F68D1CA.6050900@gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
	<4F68C13B.7080806@gmail.com>
	<CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>
	<4F68D1CA.6050900@gmail.com>
Message-ID: <CAF42j23qhzGMuhUp5qiEf2oSY+mOf38aTbTtB=zM_kDupno7eg@mail.gmail.com>

On Tue, Mar 20, 2012 at 11:51 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-03-20 1:46 PM, Dan Tenenbaum wrote:
>>
>> On Tue, Mar 20, 2012 at 10:41 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
>>>>
>>>>
>>>> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> ? ?wrote:
>>>>>
>>>>>
>>>>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Sorry to repeat myself, but I was wondering if anyone had taken a look
>>>>>> at
>>>>>> this.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> No. ?Could you put together a simple self contained example? ?I don't
>>>>> have
>>>>> any BioC packages installed.
>>>>>
>>>>
>>>> I did supply a self-contained example.
>>>> You do not need any BioC packages installed.
>>>> All you need is this file:
>>>>
>>>>
>>>>
>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>> (username: readonly, password: readonly)
>>>> And this command:
>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>> genefu-package.Rd
>>>
>>>
>>>
>>> Sorry, I didn't see that.
>>>
>>
>> Actually, ?I goofed, because that file contains the lines:
>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>
>> And those lines require you to have the 'genefu' package installed.
>> ?I changed those lines to more innocuous \Sexprs:
>>
>> Version: \tab \Sexpr{cat("hello")}\cr
>> Date: \tab \Sexpr{cat("world")}\cr
>>
>>
>>
>>>
>>>> No .tex file is generated.
>>>
>>>
>>>
>>> If you use the --no-clean command line option, then the temporary
>>> directory
>>> containing the .tex file will not be deleted. ?It contains your \Sexpr
>>> expressions wrapped in verbatim environments. ?I suspect this is
>>> happening
>>> because Rd2pdf isn't running the Sexpr evaluation step.
>>
>>
>> Yes, that's what I think is happening.
>>
>>> ?I'll try to take a
>>> look and fix it.
>>
>>
>> Thanks very much!
>>
>> I added the --no-clean flag and still got no .tex file. Here is my new
>> error output, looks the same as the original error output.
>>
>> Thanks,
>> Dan
>>
>> Converting Rd files to LaTeX ...
>> ? genefu-package.Rd
>> Creating pdf output from LaTeX ...
>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
>> ?:
>> ? Running 'texi2dvi' on 'Rd2.tex' failed.
>> LaTeX errors:
>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: ?==> ?Fatal error occurred, no
>> outpu
>> t PDF file produced!
>> Output:
>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>> ?restricted \write18 enabled.
>> entering extended mode
>> (/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex
>> LaTeX2e<2011/06/27>
>> Babel<v3.8m> ?and hyphenation patterns for english, dumylang,
>> nohyphenation, ge
>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus,
>> arabi
>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech,
>> danis
>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi,
>> finnis
>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>> hungarian,
>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>> marathi, or
>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>> kurmanji,
>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>> nynorsk, pol
>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak,
>> sloven
>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh,
>> loaded
>> .
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>> NOT loading lmodern
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>
>> Package hyperref Message: Driver (autodetected): hpdftex.
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>
>> Package hyperref Warning: Option `hyperindex' has already been used,
>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>> 356.
>>
>>
>> Package hyperref Warning: Option `pagebackref' has already been used,
>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>> 356.
>>
>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>> Writing index file Rd2.idx
>> No file Rd2.aux.
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>> [Loading MPS to PDF converter (version 2006.09.02).]
>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>
>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Missing \endgroup inserted.
>> <inserted text>
>> ? ? ? ? ? ? ? ? \endgroup
>> l.39 }
>>
>> ?
>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Emergency stop.
>
>
> That's the file to look at. ?With --no-clean, it should still be there after
> the run, but ls won't show the directory because of the dot in the name.

Here are the contents of that .tex file:

\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge test}}
\par\bigskip{\large \today}
\end{center}
\inputencoding{utf8}
\HeaderA{genefu-package}{Relevant Functions for Gene Expression
Analysis, Especially in Breast Cancer.}{genefu.Rdash.package}
\aliasA{genefu}{genefu-package}{genefu}
\keyword{clustering}{genefu-package}
\keyword{models}{genefu-package}
\keyword{breast cancer}{genefu-package}
\keyword{prognosis}{genefu-package}
%
\begin{Description}\relax
This package contains functions implementing various tasks usually
required by gene expression analysis, especially in breast cancer
studies: gene mapping between different microarray platforms,
identification of molecular subtypes, implementation of published gene
signatures, gene selection, survival analysis, ...
\end{Description}
%
\begin{Details}\relax

\Tabular{ll}{
Package: & genefu\\{}
Type: & Package\\{}
Version: & \begin{verbatim}
\Sexpr{cat("hello")}
\end{verbatim}
\\{}
Date: & \begin{verbatim}
\Sexpr{cat("world")}
\end{verbatim}
\\{}
License: & Artistic-2.0\\{}
}
\end{Details}
%
\begin{Author}\relax
\bold{Benjamin Haibe-Kains}

- Computational Biology and Functional Genomics, Dana-Farber Cancer
Institute, Boston, MA, USA

\url{http://compbio.dfci.harvard.edu/}

- Center for Cancer Computational Biology, Dana-Farber Cancer
Institute, Boston, MA, USA

\url{http://cccb.dfci.harvard.edu/index.html}

Former labs:

- Machine Learning Group (MLG), Universite Libre de Bruxelles,
Bruxelles, Belgium

\url{http://www.ulb.ac.be/di/mlg/}

- Breast Cancer Translational Laboratory (BCTL), Institut Jules
Bordet, Bruxelles, Belgium

\url{http://www.bordet.be/en/services/medical/array/practical.htm}


\bold{Maintainer}: \bold{Benjamin Haibe-Kains}

\email{bhaibeka at jimmy.harvard.edu}

\email{bhaibeka at ulb.ac.be}

\bold{Markus Schroeder}

\email{mschroed at jimmy.harvard.edu}
\end{Author}
%
\begin{SeeAlso}\relax
\code{survcomp}
\end{SeeAlso}
\printindex{}
\end{document}


Thanks,
Dan



>
> Duncan Murdoch
>
>
>> <inserted text>
>> ? ? ? ? ? ? ? ? \endgroup
>> l.39 }
>>
>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: ?==> ?Fatal error occurred, no
>> outpu
>> t PDF file produced!
>> Transcript written on Rd2.log.
>> Error in running tools::texi2pdf
>> You may want to clean up by 'rm -rf .Rd2pdf4804'
>>
>>
>>
>>>
>>> Duncan Murdoch
>>>
>>>
>>>>
>>>> Thanks!
>>>> Dan
>>>>
>>>>
>>>>> Alternatively, you could take a look at the .tex files generated, and
>>>>> identify what the problem is.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> Because of this problem, reference manuals are not being created for
>>>>>> many Bioconductor packages (any package where there is a \Sexpr in an
>>>>>> .Rd file).
>>>>>>
>>>>>> Thanks in advance--we appreciate your help very much.
>>>>>> Dan
>>>>>>
>>>>>>
>>>>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>
>>>>>> ?wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> The following command:
>>>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>>>> genefu-package.Rd
>>>>>>> run against this file:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>>>> (username: readonly; password: readonly)
>>>>>>>
>>>>>>> produces a very verbose error (see below)
>>>>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>>>>
>>>>>>> The .Rd file has these lines in it:
>>>>>>>
>>>>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>>>>
>>>>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>>>>> command will complete successfully.
>>>>>>>
>>>>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>>>>
>>>>>>> Thanks,
>>>>>>> Dan
>>>>>>>
>>>>>>> Error output:
>>>>>>>
>>>>>>> Converting Rd files to LaTeX ...
>>>>>>> ?genefu-package.Rd
>>>>>>> Creating pdf output from LaTeX ...
>>>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>>>>>> quiet,
>>>>>>> ?:
>>>>>>> ?Running 'texi2dvi' on 'Rd2.tex' failed.
>>>>>>> Messages:
>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>>>>> Output:
>>>>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>>>> ?restricted \write18 enabled.
>>>>>>> entering extended mode
>>>>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>>>>> LaTeX2e<2011/06/27>
>>>>>>> Babel<v3.8m> ? ? ?and hyphenation patterns for english, dumylang,
>>>>>>> nohyphenation, ge
>>>>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>>>>> ibycus,
>>>>>>> arabi
>>>>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>>>>> czech,
>>>>>>> danis
>>>>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic,
>>>>>>> farsi,
>>>>>>> finnis
>>>>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>>>>> hungarian,
>>>>>>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>>>>> marathi, or
>>>>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>>>>> kurmanji,
>>>>>>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>>>>> nynorsk, pol
>>>>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc,
>>>>>>> slovak,
>>>>>>> sloven
>>>>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian,
>>>>>>> welsh,
>>>>>>> loaded
>>>>>>> .
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>>>>>
>>>>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT
>>>>>>> loading
>>>>>>> ae
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>>>>> NOT loading lmodern
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>>>>
>>>>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>>>>
>>>>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>>>> line
>>>>>>> 356.
>>>>>>>
>>>>>>>
>>>>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>>>> line
>>>>>>> 356.
>>>>>>>
>>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>>>>> Writing index file Rd2.idx
>>>>>>> No file Rd2.aux.
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>> Missing \end
>>>>>>> group inserted.
>>>>>>> <inserted text>
>>>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>>>> l.39 }
>>>>>>>
>>>>>>> ?
>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>> Emergency st
>>>>>>> op.
>>>>>>> <inserted text>
>>>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>>>> l.39 }
>>>>>>>
>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>> ?==>
>>>>>>> ?Fatal e
>>>>>>> rror occurred, no output PDF file produced!
>>>>>>> Transcript written on Rd2.log.
>>>>>>> Error in running tools::texi2pdf
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>>
>>>>>
>>>
>


From hpages at fhcrc.org  Tue Mar 20 20:08:12 2012
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 20 Mar 2012 12:08:12 -0700
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <20120317153522.GA4502@siouxsie>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<20120317153522.GA4502@siouxsie>
Message-ID: <4F68D59C.5060605@fhcrc.org>

Hi Oliver,

On 03/17/2012 08:35 AM, oliver wrote:
> Hello,
>
> regarding the copying issue,
> I would like to point to the
>
> "Writing R-Extensions" documentation.
>
> There it is mentio9ned, that functions of extensions
> that use the .C interface normally do get their arguments
> pre-copied...
>
>
> In section 5.2:
>
>    "There can be up to 65 further arguments giving R objects to be
>    passed to compiled code. Normally these are copied before being
>    passed in, and copied again to an R list object when the compiled
>    code returns."
>
> But for the .Call and .Extension interfaces this is NOT the case.
>
>
>
> In section 5.9:
>    "The .Call and .External interfaces allow much more control, but
>    they also impose much greater responsibilities so need to be used
>    with care. Neither .Call nor .External copy their arguments. You
>    should treat arguments you receive through these interfaces as
>    read-only."
>
>
> Why is read-only preferred?
>
> Please, see the discussion in section 5.9.10.
>
> It's mentioned there, that a copy of an object in the R-language
> not necessarily doies a real copy of that object, but instead of
> this, just a "rerference" to the real data is created (two names
> referring to one bulk of data). That's typical functional
> programming: not a variable, but a name (and possibly more than one
> name) bound to an object.
>
>
> Of course, if yo change the orgiginal named value, when there
> would be no copy of it, before changing it, then both names
> would refer to the changed data.
> of course that is not, what is wanted.
>
> But what you also can see in section 5.9.10 is, that
> there already is a mechanism (reference counting) that allows
> to distinguish between unnamed and named object.
>
> So, this is directly adressing the points you have mentioned in your
> examples.
>
> So, at least in principial, R allows to do in-place modifications
> of object with the .Call interface.
>
> You seem to refer to the .C interface, and I had explored the .Call
> interface. That's the reason why you may insist on "it's copyied
> always" and I wondered, what you were talking about, because the
> .Call interface allowed me rather C-like raw style of programming
> (and the user of it to decide, if copying will be done or not).
>
> The mechanism to descide, if copying should be done or not,
> also is mentioined in section 5.9.10: NAMED and SET_NAMED macros.
> with NAMED you can get the number of references.
>
> But later in that section it is mentioned, that - at least for now -
> NAMED always returns the value 2.
>
>
>    "Currently all arguments to a .Call call will have NAMED set to 2,
>    and so users must assume that they need to be duplicated before
>    alteration."
>                 (section 5.9.10, last sentence)
>
>
> So, the in-place modification can be done already with the .Call
> intefcae for example. But the decision if it is safe or not
> is not supported at the moment.
>
> So the situation is somewhere between: "it is possible" and
> "R does not support a safe decision if, what is possible, also
> can be recommended".
> At the moment R rather deprecates in-place modification by default
> (the save way, and I agree with this default).
>
> But it's not true, that R in general copies arguments.
>
> But this seems to be true for the .C interface.
>
> Maybe a lot of performance-/memory-problems can be solved
> by rewriting already existing packages, by providing them
> via .Call instead of .C.

My understanding is that most packages use the .C interface
because it's simpler to deal with and because they don't need
to pass complicated objects at the C level, just atomic vectors.
My guess is that it's probably rarely the case that the cost
of copying the arguments passed to .C is significant, but,
if that was the case, then they could always call .C() with
DUP=FALSE. However, using DUP=FALSE is dangerous (see Warning
section in the man page).

No need to switch to .Call

Cheers,
H.

>
>
> Ciao,
>     Oliver
>
>
>
>
> On Tue, Mar 06, 2012 at 04:44:49PM +0000, William Dunlap wrote:
>> S (and its derivatives and successors) promises that functions
>> will not change their arguments, so in an expression like
>>     val<- func(arg)
>> you know that arg will not be changed.  You can
>> do that by having func copy arg before doing anything,
>> but that uses space and time that you want to conserve.
>> If arg is not a named item in any environment then it
>> should be fine to write over the original because there
>> is no way the caller can detect that shortcut.  E.g., in
>>      cx<- cos(runif(n))
>> the cos function does not need to allocate new space for
>> its output, it can just write over its input because, without
>> a name attached to it, the caller has no way of looking
>> at what runif(n) returned.  If you did
>>      x<- runif(n)
>>      cx<- cos(x)
>> then cos would have to allocate new space for its output
>> because overwriting its input would affect a subsequent
>>      sum(x)
>> I suppose that end-users and function-writers could learn
>> to live with having to decide when to copy, but not having
>> to make that decision makes S more pleasant (and safer) to use.
>> I think that is a major reason that people are able to
>> share S code so easily.
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>> -----Original Message-----
>>> From: oliver [mailto:oliver at first.in-berlin.de]
>>> Sent: Tuesday, March 06, 2012 1:12 AM
>>> To: William Dunlap
>>> Cc: Herv? Pag?s; R-devel
>>> Subject: Re: [Rd] Julia
>>>
>>> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
>>> [...]
>>>> I find R's (&  S+'s&  S's) copy-on-write-if-not-copying-would-be-discoverable-
>>>> by-the-uer machanism for giving the allusion of pass-by-value a good way
>>>> to structure the contract between the function writer and the function user.
>>> [...]
>>>
>>>
>>> Can you elaborate more on this,
>>> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
>>> stuff?
>>>
>>> What do you mean with discoverability of not-copying?
>>>
>>> Ciao,
>>>     Oliver
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Tue Mar 20 20:14:22 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Mar 2012 15:14:22 -0400
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <CAF42j23qhzGMuhUp5qiEf2oSY+mOf38aTbTtB=zM_kDupno7eg@mail.gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
	<4F68C13B.7080806@gmail.com>
	<CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>
	<4F68D1CA.6050900@gmail.com>
	<CAF42j23qhzGMuhUp5qiEf2oSY+mOf38aTbTtB=zM_kDupno7eg@mail.gmail.com>
Message-ID: <4F68D70E.7080906@gmail.com>

This should now be fixed in R-devel, and shortly in the 2.15.0 beta.

Duncan Murdoch

On 12-03-20 2:54 PM, Dan Tenenbaum wrote:
> On Tue, Mar 20, 2012 at 11:51 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 12-03-20 1:46 PM, Dan Tenenbaum wrote:
>>>
>>> On Tue, Mar 20, 2012 at 10:41 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>    wrote:
>>>>
>>>> On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
>>>>>
>>>>>
>>>>> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com>      wrote:
>>>>>>
>>>>>>
>>>>>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> Sorry to repeat myself, but I was wondering if anyone had taken a look
>>>>>>> at
>>>>>>> this.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> No.  Could you put together a simple self contained example?  I don't
>>>>>> have
>>>>>> any BioC packages installed.
>>>>>>
>>>>>
>>>>> I did supply a self-contained example.
>>>>> You do not need any BioC packages installed.
>>>>> All you need is this file:
>>>>>
>>>>>
>>>>>
>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>> (username: readonly, password: readonly)
>>>>> And this command:
>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>> genefu-package.Rd
>>>>
>>>>
>>>>
>>>> Sorry, I didn't see that.
>>>>
>>>
>>> Actually,  I goofed, because that file contains the lines:
>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>
>>> And those lines require you to have the 'genefu' package installed.
>>>   I changed those lines to more innocuous \Sexprs:
>>>
>>> Version: \tab \Sexpr{cat("hello")}\cr
>>> Date: \tab \Sexpr{cat("world")}\cr
>>>
>>>
>>>
>>>>
>>>>> No .tex file is generated.
>>>>
>>>>
>>>>
>>>> If you use the --no-clean command line option, then the temporary
>>>> directory
>>>> containing the .tex file will not be deleted.  It contains your \Sexpr
>>>> expressions wrapped in verbatim environments.  I suspect this is
>>>> happening
>>>> because Rd2pdf isn't running the Sexpr evaluation step.
>>>
>>>
>>> Yes, that's what I think is happening.
>>>
>>>>   I'll try to take a
>>>> look and fix it.
>>>
>>>
>>> Thanks very much!
>>>
>>> I added the --no-clean flag and still got no .tex file. Here is my new
>>> error output, looks the same as the original error output.
>>>
>>> Thanks,
>>> Dan
>>>
>>> Converting Rd files to LaTeX ...
>>>    genefu-package.Rd
>>> Creating pdf output from LaTeX ...
>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
>>>   :
>>>    Running 'texi2dvi' on 'Rd2.tex' failed.
>>> LaTeX errors:
>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==>    Fatal error occurred, no
>>> outpu
>>> t PDF file produced!
>>> Output:
>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>   restricted \write18 enabled.
>>> entering extended mode
>>> (/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex
>>> LaTeX2e<2011/06/27>
>>> Babel<v3.8m>    and hyphenation patterns for english, dumylang,
>>> nohyphenation, ge
>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek, ibycus,
>>> arabi
>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian, czech,
>>> danis
>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi,
>>> finnis
>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>> hungarian,
>>>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>> marathi, or
>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>> kurmanji,
>>>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>> nynorsk, pol
>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak,
>>> sloven
>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh,
>>> loaded
>>> .
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading ae
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>> NOT loading lmodern
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>
>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>
>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>> (hyperref)                setting the option has no effect on input line
>>> 356.
>>>
>>>
>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>> (hyperref)                setting the option has no effect on input line
>>> 356.
>>>
>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>> Writing index file Rd2.idx
>>> No file Rd2.aux.
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>
>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Missing \endgroup inserted.
>>> <inserted text>
>>>                  \endgroup
>>> l.39 }
>>>
>>> ?
>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Emergency stop.
>>
>>
>> That's the file to look at.  With --no-clean, it should still be there after
>> the run, but ls won't show the directory because of the dot in the name.
>
> Here are the contents of that .tex file:
>
> \documentclass[a4paper]{book}
> \usepackage[times,inconsolata,hyper]{Rd}
> \usepackage{makeidx}
> \usepackage[utf8,latin1]{inputenc}
> % \usepackage{graphicx} % @USE GRAPHICX@
> \makeindex{}
> \begin{document}
> \chapter*{}
> \begin{center}
> {\textbf{\huge test}}
> \par\bigskip{\large \today}
> \end{center}
> \inputencoding{utf8}
> \HeaderA{genefu-package}{Relevant Functions for Gene Expression
> Analysis, Especially in Breast Cancer.}{genefu.Rdash.package}
> \aliasA{genefu}{genefu-package}{genefu}
> \keyword{clustering}{genefu-package}
> \keyword{models}{genefu-package}
> \keyword{breast cancer}{genefu-package}
> \keyword{prognosis}{genefu-package}
> %
> \begin{Description}\relax
> This package contains functions implementing various tasks usually
> required by gene expression analysis, especially in breast cancer
> studies: gene mapping between different microarray platforms,
> identification of molecular subtypes, implementation of published gene
> signatures, gene selection, survival analysis, ...
> \end{Description}
> %
> \begin{Details}\relax
>
> \Tabular{ll}{
> Package:&  genefu\\{}
> Type:&  Package\\{}
> Version:&  \begin{verbatim}
> \Sexpr{cat("hello")}
> \end{verbatim}
> \\{}
> Date:&  \begin{verbatim}
> \Sexpr{cat("world")}
> \end{verbatim}
> \\{}
> License:&  Artistic-2.0\\{}
> }
> \end{Details}
> %
> \begin{Author}\relax
> \bold{Benjamin Haibe-Kains}
>
> - Computational Biology and Functional Genomics, Dana-Farber Cancer
> Institute, Boston, MA, USA
>
> \url{http://compbio.dfci.harvard.edu/}
>
> - Center for Cancer Computational Biology, Dana-Farber Cancer
> Institute, Boston, MA, USA
>
> \url{http://cccb.dfci.harvard.edu/index.html}
>
> Former labs:
>
> - Machine Learning Group (MLG), Universite Libre de Bruxelles,
> Bruxelles, Belgium
>
> \url{http://www.ulb.ac.be/di/mlg/}
>
> - Breast Cancer Translational Laboratory (BCTL), Institut Jules
> Bordet, Bruxelles, Belgium
>
> \url{http://www.bordet.be/en/services/medical/array/practical.htm}
>
>
> \bold{Maintainer}: \bold{Benjamin Haibe-Kains}
>
> \email{bhaibeka at jimmy.harvard.edu}
>
> \email{bhaibeka at ulb.ac.be}
>
> \bold{Markus Schroeder}
>
> \email{mschroed at jimmy.harvard.edu}
> \end{Author}
> %
> \begin{SeeAlso}\relax
> \code{survcomp}
> \end{SeeAlso}
> \printindex{}
> \end{document}
>
>
> Thanks,
> Dan
>
>
>
>>
>> Duncan Murdoch
>>
>>
>>> <inserted text>
>>>                  \endgroup
>>> l.39 }
>>>
>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39:  ==>    Fatal error occurred, no
>>> outpu
>>> t PDF file produced!
>>> Transcript written on Rd2.log.
>>> Error in running tools::texi2pdf
>>> You may want to clean up by 'rm -rf .Rd2pdf4804'
>>>
>>>
>>>
>>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>>>
>>>>> Thanks!
>>>>> Dan
>>>>>
>>>>>
>>>>>> Alternatively, you could take a look at the .tex files generated, and
>>>>>> identify what the problem is.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>>>
>>>>>>> Because of this problem, reference manuals are not being created for
>>>>>>> many Bioconductor packages (any package where there is a \Sexpr in an
>>>>>>> .Rd file).
>>>>>>>
>>>>>>> Thanks in advance--we appreciate your help very much.
>>>>>>> Dan
>>>>>>>
>>>>>>>
>>>>>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>
>>>>>>>   wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> The following command:
>>>>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>>>>> genefu-package.Rd
>>>>>>>> run against this file:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>>>>> (username: readonly; password: readonly)
>>>>>>>>
>>>>>>>> produces a very verbose error (see below)
>>>>>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>>>>>
>>>>>>>> The .Rd file has these lines in it:
>>>>>>>>
>>>>>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>>>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>>>>>
>>>>>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>>>>>> command will complete successfully.
>>>>>>>>
>>>>>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>>>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Dan
>>>>>>>>
>>>>>>>> Error output:
>>>>>>>>
>>>>>>>> Converting Rd files to LaTeX ...
>>>>>>>>   genefu-package.Rd
>>>>>>>> Creating pdf output from LaTeX ...
>>>>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>>>>>>> quiet,
>>>>>>>>   :
>>>>>>>>   Running 'texi2dvi' on 'Rd2.tex' failed.
>>>>>>>> Messages:
>>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>>>>>> Output:
>>>>>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>>>>>   restricted \write18 enabled.
>>>>>>>> entering extended mode
>>>>>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>>>>>> LaTeX2e<2011/06/27>
>>>>>>>> Babel<v3.8m>        and hyphenation patterns for english, dumylang,
>>>>>>>> nohyphenation, ge
>>>>>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>>>>>> ibycus,
>>>>>>>> arabi
>>>>>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>>>>>> czech,
>>>>>>>> danis
>>>>>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic,
>>>>>>>> farsi,
>>>>>>>> finnis
>>>>>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>>>>>> hungarian,
>>>>>>>>   icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>>>>>> marathi, or
>>>>>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>>>>>> kurmanji,
>>>>>>>>   lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>>>>>> nynorsk, pol
>>>>>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc,
>>>>>>>> slovak,
>>>>>>>> sloven
>>>>>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian,
>>>>>>>> welsh,
>>>>>>>> loaded
>>>>>>>> .
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>>>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>>>>>>
>>>>>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT
>>>>>>>> loading
>>>>>>>> ae
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>>>>>> NOT loading lmodern
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>>>>>
>>>>>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>>>>>
>>>>>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>>>>>> (hyperref)                setting the option has no effect on input
>>>>>>>> line
>>>>>>>> 356.
>>>>>>>>
>>>>>>>>
>>>>>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>>>>>> (hyperref)                setting the option has no effect on input
>>>>>>>> line
>>>>>>>> 356.
>>>>>>>>
>>>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>>>>>> Writing index file Rd2.idx
>>>>>>>> No file Rd2.aux.
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>>>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>> Missing \end
>>>>>>>> group inserted.
>>>>>>>> <inserted text>
>>>>>>>>                 \endgroup
>>>>>>>> l.39 }
>>>>>>>>
>>>>>>>> ?
>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>> Emergency st
>>>>>>>> op.
>>>>>>>> <inserted text>
>>>>>>>>                 \endgroup
>>>>>>>> l.39 }
>>>>>>>>
>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>>   ==>
>>>>>>>>   Fatal e
>>>>>>>> rror occurred, no output PDF file produced!
>>>>>>>> Transcript written on Rd2.log.
>>>>>>>> Error in running tools::texi2pdf
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>
>>


From dtenenba at fhcrc.org  Tue Mar 20 20:19:49 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 20 Mar 2012 12:19:49 -0700
Subject: [Rd] issue with Rd2pdf and \Sexpr in Rd files
In-Reply-To: <4F68D70E.7080906@gmail.com>
References: <CAF42j22X+B8aLCEDhY7PzXpPobDcZT80rhNT5DFKFNBa0vkYLg@mail.gmail.com>
	<CAF42j20FGqHq67xPwAbYN2K_AmQKZ3PHwW6BVtQTjZVeLEvyTQ@mail.gmail.com>
	<4F68BC81.20506@gmail.com>
	<CAF42j22icfTTsN6=2ocJw2pVWh4QxoYyFNaZ9BkdNuotLnu6Ng@mail.gmail.com>
	<4F68C13B.7080806@gmail.com>
	<CAF42j223UuHwMwQ+tNVt3rEwUA4FB+mR8uQX4yEZjd3bn0C4=Q@mail.gmail.com>
	<4F68D1CA.6050900@gmail.com>
	<CAF42j23qhzGMuhUp5qiEf2oSY+mOf38aTbTtB=zM_kDupno7eg@mail.gmail.com>
	<4F68D70E.7080906@gmail.com>
Message-ID: <CAF42j21ebRvARj77XYBffiy-FNYOXzNZAXhFsB50RwZsQVGsqA@mail.gmail.com>

On Tue, Mar 20, 2012 at 12:14 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> This should now be fixed in R-devel, and shortly in the 2.15.0 beta.

Thanks very much.
Dan

>
> Duncan Murdoch
>
>
> On 12-03-20 2:54 PM, Dan Tenenbaum wrote:
>>
>> On Tue, Mar 20, 2012 at 11:51 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 12-03-20 1:46 PM, Dan Tenenbaum wrote:
>>>>
>>>>
>>>> On Tue, Mar 20, 2012 at 10:41 AM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> ? ?wrote:
>>>>>
>>>>>
>>>>> On 12-03-20 1:25 PM, Dan Tenenbaum wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Tue, Mar 20, 2012 at 10:21 AM, Duncan Murdoch
>>>>>> <murdoch.duncan at gmail.com> ? ? ?wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 12-03-19 10:27 PM, Dan Tenenbaum wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Hello,
>>>>>>>>
>>>>>>>> Sorry to repeat myself, but I was wondering if anyone had taken a
>>>>>>>> look
>>>>>>>> at
>>>>>>>> this.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> No. ?Could you put together a simple self contained example? ?I don't
>>>>>>> have
>>>>>>> any BioC packages installed.
>>>>>>>
>>>>>>
>>>>>> I did supply a self-contained example.
>>>>>> You do not need any BioC packages installed.
>>>>>> All you need is this file:
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>>> (username: readonly, password: readonly)
>>>>>> And this command:
>>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>>> genefu-package.Rd
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Sorry, I didn't see that.
>>>>>
>>>>
>>>> Actually, ?I goofed, because that file contains the lines:
>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>
>>>> And those lines require you to have the 'genefu' package installed.
>>>> ?I changed those lines to more innocuous \Sexprs:
>>>>
>>>> Version: \tab \Sexpr{cat("hello")}\cr
>>>> Date: \tab \Sexpr{cat("world")}\cr
>>>>
>>>>
>>>>
>>>>>
>>>>>> No .tex file is generated.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> If you use the --no-clean command line option, then the temporary
>>>>> directory
>>>>> containing the .tex file will not be deleted. ?It contains your \Sexpr
>>>>> expressions wrapped in verbatim environments. ?I suspect this is
>>>>> happening
>>>>> because Rd2pdf isn't running the Sexpr evaluation step.
>>>>
>>>>
>>>>
>>>> Yes, that's what I think is happening.
>>>>
>>>>> ?I'll try to take a
>>>>> look and fix it.
>>>>
>>>>
>>>>
>>>> Thanks very much!
>>>>
>>>> I added the --no-clean flag and still got no .tex file. Here is my new
>>>> error output, looks the same as the original error output.
>>>>
>>>> Thanks,
>>>> Dan
>>>>
>>>> Converting Rd files to LaTeX ...
>>>> ? genefu-package.Rd
>>>> Creating pdf output from LaTeX ...
>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
>>>> ?:
>>>> ? Running 'texi2dvi' on 'Rd2.tex' failed.
>>>> LaTeX errors:
>>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: ?==> ? ?Fatal error
>>>> occurred, no
>>>> outpu
>>>> t PDF file produced!
>>>> Output:
>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>> ?restricted \write18 enabled.
>>>> entering extended mode
>>>> (/Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex
>>>> LaTeX2e<2011/06/27>
>>>> Babel<v3.8m> ? ?and hyphenation patterns for english, dumylang,
>>>> nohyphenation, ge
>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>> ibycus,
>>>> arabi
>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>> czech,
>>>> danis
>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic, farsi,
>>>> finnis
>>>> h, french, galician, german, ngerman, swissgerman, monogreek, greek,
>>>> hungarian,
>>>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>> marathi, or
>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish, italian,
>>>> kurmanji,
>>>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>> nynorsk, pol
>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc, slovak,
>>>> sloven
>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian, welsh,
>>>> loaded
>>>> .
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT loading
>>>> ae
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>> NOT loading lmodern
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>
>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>
>>>> Package hyperref Warning: Option `hyperindex' has already been used,
>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>>>> 356.
>>>>
>>>>
>>>> Package hyperref Warning: Option `pagebackref' has already been used,
>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input line
>>>> 356.
>>>>
>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>> Writing index file Rd2.idx
>>>> No file Rd2.aux.
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>
>>>>
>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Missing \endgroup inserted.
>>>> <inserted text>
>>>> ? ? ? ? ? ? ? ? \endgroup
>>>> l.39 }
>>>>
>>>> ?
>>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: Emergency stop.
>>>
>>>
>>>
>>> That's the file to look at. ?With --no-clean, it should still be there
>>> after
>>> the run, but ls won't show the directory because of the dot in the name.
>>
>>
>> Here are the contents of that .tex file:
>>
>> \documentclass[a4paper]{book}
>> \usepackage[times,inconsolata,hyper]{Rd}
>> \usepackage{makeidx}
>> \usepackage[utf8,latin1]{inputenc}
>> % \usepackage{graphicx} % @USE GRAPHICX@
>> \makeindex{}
>> \begin{document}
>> \chapter*{}
>> \begin{center}
>> {\textbf{\huge test}}
>> \par\bigskip{\large \today}
>> \end{center}
>> \inputencoding{utf8}
>> \HeaderA{genefu-package}{Relevant Functions for Gene Expression
>> Analysis, Especially in Breast Cancer.}{genefu.Rdash.package}
>> \aliasA{genefu}{genefu-package}{genefu}
>> \keyword{clustering}{genefu-package}
>> \keyword{models}{genefu-package}
>> \keyword{breast cancer}{genefu-package}
>> \keyword{prognosis}{genefu-package}
>> %
>> \begin{Description}\relax
>> This package contains functions implementing various tasks usually
>> required by gene expression analysis, especially in breast cancer
>> studies: gene mapping between different microarray platforms,
>> identification of molecular subtypes, implementation of published gene
>> signatures, gene selection, survival analysis, ...
>> \end{Description}
>> %
>> \begin{Details}\relax
>>
>> \Tabular{ll}{
>> Package:& ?genefu\\{}
>> Type:& ?Package\\{}
>> Version:& ?\begin{verbatim}
>> \Sexpr{cat("hello")}
>> \end{verbatim}
>> \\{}
>> Date:& ?\begin{verbatim}
>> \Sexpr{cat("world")}
>> \end{verbatim}
>> \\{}
>> License:& ?Artistic-2.0\\{}
>> }
>> \end{Details}
>> %
>> \begin{Author}\relax
>> \bold{Benjamin Haibe-Kains}
>>
>> - Computational Biology and Functional Genomics, Dana-Farber Cancer
>> Institute, Boston, MA, USA
>>
>> \url{http://compbio.dfci.harvard.edu/}
>>
>> - Center for Cancer Computational Biology, Dana-Farber Cancer
>> Institute, Boston, MA, USA
>>
>> \url{http://cccb.dfci.harvard.edu/index.html}
>>
>> Former labs:
>>
>> - Machine Learning Group (MLG), Universite Libre de Bruxelles,
>> Bruxelles, Belgium
>>
>> \url{http://www.ulb.ac.be/di/mlg/}
>>
>> - Breast Cancer Translational Laboratory (BCTL), Institut Jules
>> Bordet, Bruxelles, Belgium
>>
>> \url{http://www.bordet.be/en/services/medical/array/practical.htm}
>>
>>
>> \bold{Maintainer}: \bold{Benjamin Haibe-Kains}
>>
>> \email{bhaibeka at jimmy.harvard.edu}
>>
>> \email{bhaibeka at ulb.ac.be}
>>
>> \bold{Markus Schroeder}
>>
>> \email{mschroed at jimmy.harvard.edu}
>> \end{Author}
>> %
>> \begin{SeeAlso}\relax
>> \code{survcomp}
>> \end{SeeAlso}
>> \printindex{}
>> \end{document}
>>
>>
>> Thanks,
>> Dan
>>
>>
>>
>>>
>>> Duncan Murdoch
>>>
>>>
>>>> <inserted text>
>>>> ? ? ? ? ? ? ? ? \endgroup
>>>> l.39 }
>>>>
>>>> /Users/dtenenba/tmp/.Rd2pdf4804/Rd2.tex:39: ?==> ? ?Fatal error
>>>> occurred, no
>>>> outpu
>>>> t PDF file produced!
>>>> Transcript written on Rd2.log.
>>>> Error in running tools::texi2pdf
>>>> You may want to clean up by 'rm -rf .Rd2pdf4804'
>>>>
>>>>
>>>>
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>>>
>>>>>> Thanks!
>>>>>> Dan
>>>>>>
>>>>>>
>>>>>>> Alternatively, you could take a look at the .tex files generated, and
>>>>>>> identify what the problem is.
>>>>>>>
>>>>>>> Duncan Murdoch
>>>>>>>
>>>>>>>>
>>>>>>>> Because of this problem, reference manuals are not being created for
>>>>>>>> many Bioconductor packages (any package where there is a \Sexpr in
>>>>>>>> an
>>>>>>>> .Rd file).
>>>>>>>>
>>>>>>>> Thanks in advance--we appreciate your help very much.
>>>>>>>> Dan
>>>>>>>>
>>>>>>>>
>>>>>>>> On Wed, Mar 14, 2012 at 1:13 PM, Dan Tenenbaum<dtenenba at fhcrc.org>
>>>>>>>> ?wrote:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>>
>>>>>>>>> The following command:
>>>>>>>>> R CMD Rd2pdf --no-preview --output=./tmp.pdf --title=test
>>>>>>>>> genefu-package.Rd
>>>>>>>>> run against this file:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/genefu/man/genefu-package.Rd
>>>>>>>>> (username: readonly; password: readonly)
>>>>>>>>>
>>>>>>>>> produces a very verbose error (see below)
>>>>>>>>> with R version 2.15.0 alpha (2012-03-07 r58622).
>>>>>>>>>
>>>>>>>>> The .Rd file has these lines in it:
>>>>>>>>>
>>>>>>>>> Version: \tab \Sexpr{packageDescription("genefu")$Version}\cr
>>>>>>>>> Date: \tab \Sexpr{packageDescription("genefu")$Date}\cr
>>>>>>>>>
>>>>>>>>> If I take these lines out, or take out the \Sexpr part, the Rd2pdf
>>>>>>>>> command will complete successfully.
>>>>>>>>>
>>>>>>>>> Is there some other step I need to run to evaluate the \Sexpr tags
>>>>>>>>> before running Rd2pdf, or is there an issue that needs to be fixed?
>>>>>>>>>
>>>>>>>>> Thanks,
>>>>>>>>> Dan
>>>>>>>>>
>>>>>>>>> Error output:
>>>>>>>>>
>>>>>>>>> Converting Rd files to LaTeX ...
>>>>>>>>> ?genefu-package.Rd
>>>>>>>>> Creating pdf output from LaTeX ...
>>>>>>>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>>>>>>>> quiet,
>>>>>>>>> ?:
>>>>>>>>> ?Running 'texi2dvi' on 'Rd2.tex' failed.
>>>>>>>>> Messages:
>>>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>>> /usr/bin/texi2dvi: see Rd2.log for errors.
>>>>>>>>> Output:
>>>>>>>>> This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011)
>>>>>>>>> ?restricted \write18 enabled.
>>>>>>>>> entering extended mode
>>>>>>>>> (/Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex
>>>>>>>>> LaTeX2e<2011/06/27>
>>>>>>>>> Babel<v3.8m> ? ? ? ?and hyphenation patterns for english, dumylang,
>>>>>>>>> nohyphenation, ge
>>>>>>>>> rman-x-2011-07-01, ngerman-x-2011-07-01, afrikaans, ancientgreek,
>>>>>>>>> ibycus,
>>>>>>>>> arabi
>>>>>>>>> c, armenian, basque, bulgarian, catalan, pinyin, coptic, croatian,
>>>>>>>>> czech,
>>>>>>>>> danis
>>>>>>>>> h, dutch, ukenglish, usenglishmax, esperanto, estonian, ethiopic,
>>>>>>>>> farsi,
>>>>>>>>> finnis
>>>>>>>>> h, french, galician, german, ngerman, swissgerman, monogreek,
>>>>>>>>> greek,
>>>>>>>>> hungarian,
>>>>>>>>> ?icelandic, assamese, bengali, gujarati, hindi, kannada, malayalam,
>>>>>>>>> marathi, or
>>>>>>>>> iya, panjabi, tamil, telugu, indonesian, interlingua, irish,
>>>>>>>>> italian,
>>>>>>>>> kurmanji,
>>>>>>>>> ?lao, latin, latvian, lithuanian, mongolian, mongolianlmc, bokmal,
>>>>>>>>> nynorsk, pol
>>>>>>>>> ish, portuguese, romanian, russian, sanskrit, serbian, serbianc,
>>>>>>>>> slovak,
>>>>>>>>> sloven
>>>>>>>>> ian, spanish, swedish, turkish, turkmen, ukrainian, uppersorbian,
>>>>>>>>> welsh,
>>>>>>>>> loaded
>>>>>>>>> .
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/book.cls
>>>>>>>>> Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/bk10.clo))
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/Library/Frameworks/R.framework/Resources/share/texmf/tex/latex/Rd.sty
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ifthen.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/longtable.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/bm.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/alltt.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/tools/verbatim.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/url/url.sty) NOT
>>>>>>>>> loading
>>>>>>>>> ae
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/fontenc.sty
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.def))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/times.sty)
>>>>>>>>> NOT loading lmodern
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/inconsolata.sty
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/textcomp.sty
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.def))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/keyval.sty))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/graphics/color.sty
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/color.cfg)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/pdftex-def/pdftex.def
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/infwarerr.sty)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hyperref.sty
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/ifxetex/ifxetex.sty)
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/kvoptions.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/pd1enc.def)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/latexconfig/hyperref.cfg))
>>>>>>>>>
>>>>>>>>> Package hyperref Message: Driver (autodetected): hpdftex.
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/hpdftex.def
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))
>>>>>>>>>
>>>>>>>>> Package hyperref Warning: Option `hyperindex' has already been
>>>>>>>>> used,
>>>>>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>>>>>> line
>>>>>>>>> 356.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Package hyperref Warning: Option `pagebackref' has already been
>>>>>>>>> used,
>>>>>>>>> (hyperref) ? ? ? ? ? ? ? ?setting the option has no effect on input
>>>>>>>>> line
>>>>>>>>> 356.
>>>>>>>>>
>>>>>>>>> ) (/usr/local/texlive/2011/texmf-dist/tex/latex/base/makeidx.sty)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/inputenc.sty
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/t1enc.dfu)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ot1enc.dfu)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/omsenc.dfu)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1enc.dfu))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/latin1.def))
>>>>>>>>> Writing index file Rd2.idx
>>>>>>>>> No file Rd2.aux.
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/ts1cmr.fd)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/psnfss/t1ptm.fd)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/context/base/supp-pdf.mkii
>>>>>>>>> [Loading MPS to PDF converter (version 2006.09.02).]
>>>>>>>>> )
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/hyperref/nameref.sty
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/base/utf8.def)
>>>>>>>>> (/usr/local/texlive/2011/texmf-dist/tex/latex/inconsolata/t1fi4.fd)
>>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>>> Missing \end
>>>>>>>>> group inserted.
>>>>>>>>> <inserted text>
>>>>>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>>>>>> l.39 }
>>>>>>>>>
>>>>>>>>> ?
>>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>>> Emergency st
>>>>>>>>> op.
>>>>>>>>> <inserted text>
>>>>>>>>> ? ? ? ? ? ? ? ?\endgroup
>>>>>>>>> l.39 }
>>>>>>>>>
>>>>>>>>> /Users/dtenenba/dev/bioc_devel/genefu/man/.Rd2pdf62869/Rd2.tex:39:
>>>>>>>>> ?==>
>>>>>>>>> ?Fatal e
>>>>>>>>> rror occurred, no output PDF file produced!
>>>>>>>>> Transcript written on Rd2.log.
>>>>>>>>> Error in running tools::texi2pdf
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>
>>>
>


From spencer.graves at prodsyse.com  Tue Mar 20 21:40:03 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 20 Mar 2012 13:40:03 -0700
Subject: [Rd] S3 methods with full name in documentation?
Message-ID: <4F68EB23.5080201@prodsyse.com>

Hello:


       Is there a recommended way to inform "R CMD check" that a 
function like "as.numeric" is NOT a method for the S3 generic function 
"as" for objects of class "numeric"?


       I ask, because I'm getting "NOTE" messages for many function 
names like this (e.g., "density.fd" in the "fda" package):  If there 
were a way to tell "R CMD check" that a function name is NOT a method 
for an S3 generic, it would make it easier for me to see the messages I 
should take seriously.


       Thanks,
       Spencer


From oliver at first.in-berlin.de  Tue Mar 20 22:14:16 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 20 Mar 2012 22:14:16 +0100
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <4F68D59C.5060605@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<20120317153522.GA4502@siouxsie> <4F68D59C.5060605@fhcrc.org>
Message-ID: <20120320211416.GC3352@siouxsie>

On Tue, Mar 20, 2012 at 12:08:12PM -0700, Herv? Pag?s wrote:
[...]
> >So the situation is somewhere between: "it is possible" and
> >"R does not support a safe decision if, what is possible, also
> >can be recommended".
> >At the moment R rather deprecates in-place modification by default
> >(the save way, and I agree with this default).
> >
> >But it's not true, that R in general copies arguments.
> >
> >But this seems to be true for the .C interface.
> >
> >Maybe a lot of performance-/memory-problems can be solved
> >by rewriting already existing packages, by providing them
> >via .Call instead of .C.
> 
> My understanding is that most packages use the .C interface
> because it's simpler to deal with and because they don't need
> to pass complicated objects at the C level, just atomic vectors.
> My guess is that it's probably rarely the case that the cost
> of copying the arguments passed to .C is significant, but,
> if that was the case, then they could always call .C() with
> DUP=FALSE. However, using DUP=FALSE is dangerous (see Warning
> section in the man page).
[...]

Yes. I have seen that (DUP=FALSE) in the docs, but while I was
writing the answer like a maniac, I forgot it. ;-)

Thanks for mentionig it.

In the manual also was mentioned, that .Call allows more control.
I did not looked at .C and used .Call from the beginning on.
It did not looked very complicated. But maybe .C would be much easier.
Don't know.


> 
> No need to switch to .Call

OK, at least not for the point of DUP-arg.
But it seems to me, that when later the names-result will
be correctly set to 0, 1 and 2, then such optimisations,
which were asked for, could be done "automagically".
And to do it safely too.

The .C interface with the DUP-arg seems not to allow this.


Ciao,
   Oliver


From hadley at rice.edu  Tue Mar 20 22:31:40 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 20 Mar 2012 16:31:40 -0500
Subject: [Rd] Substitute adds id attribute?
Message-ID: <CABdHhvEKaDNRDjf-3Rp=b=wvnMO-ZNvk8aLge9-U6K8BkJz4Sg@mail.gmail.com>

Hi all,

I can't figure out how to make this problem easily reproducible, but I
can demonstrate it very simply, so I hoped someone might be able to
suggest a place to start:

> f <- function(x) substitute(x)
> f(x)
x
> f(mpg)
mpg
attr(,"id")
[1] 11

It works as expected in a clean R session:

> f <- function(x) substitute(x)
> f(x)
x
> f(mpg)
mpg

but not after the following code

library(devtools)
install_github("staticdocs")
library(staticdocs)
build_package("ggplot2", tempdir())

Any ideas?

Thanks,

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From pdalgd at gmail.com  Wed Mar 21 00:58:20 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Mar 2012 00:58:20 +0100
Subject: [Rd] Substitute adds id attribute?
In-Reply-To: <CABdHhvEKaDNRDjf-3Rp=b=wvnMO-ZNvk8aLge9-U6K8BkJz4Sg@mail.gmail.com>
References: <CABdHhvEKaDNRDjf-3Rp=b=wvnMO-ZNvk8aLge9-U6K8BkJz4Sg@mail.gmail.com>
Message-ID: <4D12E7A7-015E-44BC-8C93-C3199078B144@gmail.com>


On Mar 20, 2012, at 22:31 , Hadley Wickham wrote:

> Hi all,
> 
> I can't figure out how to make this problem easily reproducible, but I
> can demonstrate it very simply, so I hoped someone might be able to
> suggest a place to start:
> 
>> f <- function(x) substitute(x)
>> f(x)
> x
>> f(mpg)
> mpg
> attr(,"id")
> [1] 11
> 
> It works as expected in a clean R session:
> 
>> f <- function(x) substitute(x)
>> f(x)
> x
>> f(mpg)
> mpg
> 
> but not after the following code
> 
> library(devtools)
> install_github("staticdocs")
> library(staticdocs)
> build_package("ggplot2", tempdir())
> 
> Any ideas?
> 

Well, yes; you can get there more quickly as follows:

> x <- as.name("foo")
> attr(x,"id") <- 7913
> x
foo
attr(,"id")
[1] 7913
> substitute(foo)
foo
attr(,"id")
[1] 7913

I.e. if you ever put an attribute on a symbol, it stays there "forever". The fix is probably to forbid setting attributes on symbols (as we already do for environments and NULL) but I bet that breaks something...
 




> Thanks,
> 
> Hadley
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hadley at rice.edu  Wed Mar 21 02:05:50 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 20 Mar 2012 20:05:50 -0500
Subject: [Rd] Substitute adds id attribute?
In-Reply-To: <4D12E7A7-015E-44BC-8C93-C3199078B144@gmail.com>
References: <CABdHhvEKaDNRDjf-3Rp=b=wvnMO-ZNvk8aLge9-U6K8BkJz4Sg@mail.gmail.com>
	<4D12E7A7-015E-44BC-8C93-C3199078B144@gmail.com>
Message-ID: <CABdHhvFoRb7jaG6SdL54S8NMiJyB9VDKR1Qq3grUynbwyfEctA@mail.gmail.com>

> Well, yes; you can get there more quickly as follows:
>
>> x <- as.name("foo")
>> attr(x,"id") <- 7913
>> x
> foo
> attr(,"id")
> [1] 7913
>> substitute(foo)
> foo
> attr(,"id")
> [1] 7913
>
> I.e. if you ever put an attribute on a symbol, it stays there "forever". The fix is probably to forbid setting attributes on symbols (as we already do for environments and NULL) but I bet that breaks something...

Hmmm, thanks.  No idea what's putting it there, but at least I know
where to start.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From murdoch.duncan at gmail.com  Wed Mar 21 02:43:22 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Mar 2012 21:43:22 -0400
Subject: [Rd] S3 methods with full name in documentation?
In-Reply-To: <4F68EB23.5080201@prodsyse.com>
References: <4F68EB23.5080201@prodsyse.com>
Message-ID: <4F69323A.4020109@gmail.com>

On 12-03-20 4:40 PM, Spencer Graves wrote:
> Hello:
>
>
>         Is there a recommended way to inform "R CMD check" that a
> function like "as.numeric" is NOT a method for the S3 generic function
> "as" for objects of class "numeric"?
>
>
>         I ask, because I'm getting "NOTE" messages for many function
> names like this (e.g., "density.fd" in the "fda" package):  If there
> were a way to tell "R CMD check" that a function name is NOT a method
> for an S3 generic, it would make it easier for me to see the messages I
> should take seriously.

I don't think so.  The problem you are seeing is that "density" is a 
generic, so density.fd looks like a method for it.  In fact, if you 
define an object of class "fd" and call density() on it while fda is 
attached, your density.fd function will be called:

 > x <- structure(1, class="fd")
 > density(x)
Error in inherits(WfdParobj, "fdPar") :
   argument "WfdParobj" is missing, with no default

So in fact, density.fd *is* an S3 method, even though you didn't know it.

Nowadays every package has a namespace, and eventually maybe S3 methods 
that aren't declared in the namespace as S3 methods won't be recognized 
as S3 methods.  But for now, the only real way around these warnings is 
not to name things in a way that makes them appear to be S3 methods.

Duncan Murdoch


From spencer.graves at prodsyse.com  Wed Mar 21 08:11:01 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 21 Mar 2012 00:11:01 -0700
Subject: [Rd] S3 methods with full name in documentation?
In-Reply-To: <4F69323A.4020109@gmail.com>
References: <4F68EB23.5080201@prodsyse.com> <4F69323A.4020109@gmail.com>
Message-ID: <4F697F05.6040306@prodsyse.com>

Hi, Duncan:


On 3/20/2012 6:43 PM, Duncan Murdoch wrote:
> On 12-03-20 4:40 PM, Spencer Graves wrote:
>> Hello:
>>
>>
>>         Is there a recommended way to inform "R CMD check" that a
>> function like "as.numeric" is NOT a method for the S3 generic function
>> "as" for objects of class "numeric"?
>>
>>
>>         I ask, because I'm getting "NOTE" messages for many function
>> names like this (e.g., "density.fd" in the "fda" package):  If there
>> were a way to tell "R CMD check" that a function name is NOT a method
>> for an S3 generic, it would make it easier for me to see the messages I
>> should take seriously.
>
> I don't think so.  The problem you are seeing is that "density" is a 
> generic, so density.fd looks like a method for it.  In fact, if you 
> define an object of class "fd" and call density() on it while fda is 
> attached, your density.fd function will be called:
>
> > x <- structure(1, class="fd")
> > density(x)
> Error in inherits(WfdParobj, "fdPar") :
>   argument "WfdParobj" is missing, with no default
>
> So in fact, density.fd *is* an S3 method, even though you didn't know it.


       Well, yes, I guess I knew that, but I also knew that "density.fd" 
should not be called with the first argument having class "fd", even 
more that "as.numeric", which is also recognized as the "numeric" method 
for the presumed generic function "as".  [Yes, I know that "as" does not 
call methods dispatch such as "UseMethod" called by "density", so 
"as.numeric" is different from that perspective.]

>
> Nowadays every package has a namespace, and eventually maybe S3 
> methods that aren't declared in the namespace as S3 methods won't be 
> recognized as S3 methods.  But for now, the only real way around these 
> warnings is not to name things in a way that makes them appear to be 
> S3 methods.


       Thanks.  I asked, because I thought there might be something one 
could do in a NAMESPACE to avoid this.  "density.fd" has been around for 
some time, and picking a different name for it (and similar functions in 
the fda package) would break too much existing code and impose an 
unacceptable burden on long-time fda users to justify that option -- 
similar to "as.numeric".


       Thanks, again.


       Best Wishes,
       Spencer
>
> Duncan Murdoch


From spinuvit at gmail.com  Wed Mar 21 10:07:43 2012
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 21 Mar 2012 10:07:43 +0100
Subject: [Rd] enableJIT() and internal R completions (was: [ESS-bugs]
	ess-mode 12.03; ess hangs emacs)
In-Reply-To: <87limvnqrw.fsf@gnu.org> (Sam Steingold's message of "Tue, 20 Mar
	2012 13:09:07 -0400")
References: <87limvnqrw.fsf@gnu.org>
Message-ID: <87r4wml3ts.fsf@gmail.com>


Hello, 

JIT compiler interferes with internal R completions:

compiler::enableJIT(2)
utils:::functionArgs("density", '')

gives:

utils:::functionArgs("density", '')
Note: no visible global function definition for 'bw.nrd0' 
Note: no visible global function definition for 'bw.nrd' 
Note: no visible global function definition for 'bw.ucv' 
Note: no visible global function definition for 'bw.bcv' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible binding for global variable 'C_massdist' 
Note: no visible global function definition for 'dnorm' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'approx' 
Note: no visible global function definition for 'bw.nrd0' 
Note: no visible global function definition for 'bw.nrd' 
Note: no visible global function definition for 'bw.ucv' 
Note: no visible global function definition for 'bw.bcv' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible binding for global variable 'C_massdist' 
Note: no visible global function definition for 'dnorm' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'approx' 
Note: no visible global function definition for 'bw.nrd0' 
Note: no visible global function definition for 'bw.nrd' 
Note: no visible global function definition for 'bw.ucv' 
Note: no visible global function definition for 'bw.bcv' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible global function definition for 'bw.SJ' 
Note: no visible binding for global variable 'C_massdist' 
Note: no visible global function definition for 'dnorm' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'fft' 
Note: no visible global function definition for 'approx' 
 [1] "x="          "...="        "bw="         "adjust="     "kernel="     "weights="   
 [7] "window="     "width="      "give.Rkern=" "n="          "from="       "to="        
[13] "cut="        "na.rm="     


Disabling JIT warnings removes the notes, but the call remains to be
extremely slow, as the compiler still processes all the exceptions.

Thanks, 
Vitalie.

>>>> Sam Steingold <sds at gnu.org>
>>>> on Tue, 20 Mar 2012 13:09:07 -0400 wrote:

  > ess hangs emacs completely.

  > I just created a brand new Rprofile

  > options(error = utils::recover)
  > library(compiler)
  > compiler::enableJIT(3)


  > and now and I start R and start typing I see this:
  >> options(STERM=.....)
  >> matrix(nrow=|)
  > ("|" stands for my cursor)
  > and "nrow: x" in the minibuffer.
  > that's it.
  > emacs is stuck.

  > Program received signal SIGTSTP, Stopped (user).
  > 0x00000000005a115a in exec_byte_code (bytestr=8748337, vector=8748373, maxdepth=<optimized out>, args_template=11970946, 
  >     nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:487
  > 487       stack.pc = stack.byte_string_start = SDATA (bytestr);
  > (gdb) where
  > #0  0x00000000005a115a in exec_byte_code (bytestr=8748337, vector=8748373, maxdepth=<optimized out>, args_template=11970946, 
  >     nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:487
  > #1  0x0000000000569111 in funcall_lambda (fun=8748253, nargs=<optimized out>, arg_vector=0x7fffffffb0b8)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #2  0x000000000056948b in Ffuncall (nargs=3, args=0x7fffffffb0b0) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #3  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #4  0x0000000000569111 in funcall_lambda (fun=20119685, nargs=<optimized out>, arg_vector=0x7fffffffb278)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #5  0x000000000056948b in Ffuncall (nargs=4, args=0x7fffffffb270) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #6  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #7  0x0000000000569111 in funcall_lambda (fun=20126229, nargs=<optimized out>, arg_vector=0x7fffffffb448)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #8  0x000000000056948b in Ffuncall (nargs=6, args=0x7fffffffb440) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #9  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #10 0x0000000000569111 in funcall_lambda (fun=19976549, nargs=<optimized out>, arg_vector=0x7fffffffb618)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #11 0x000000000056948b in Ffuncall (nargs=4, args=0x7fffffffb610) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #12 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #13 0x0000000000569111 in funcall_lambda (fun=20815797, nargs=<optimized out>, arg_vector=0x7fffffffb7e8)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #14 0x000000000056948b in Ffuncall (nargs=2, args=0x7fffffffb7e0) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #15 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #16 0x0000000000569111 in funcall_lambda (fun=20802901, nargs=<optimized out>, arg_vector=0x7fffffffb9b0)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #17 0x000000000056948b in Ffuncall (nargs=1, args=0x7fffffffb9a8) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #18 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #19 0x0000000000568aa3 in eval_sub (form=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2356
  > #20 0x000000000056bd44 in internal_lisp_condition_case (var=12376962, bodyform=18220518, handlers=18218726)
  >     at /home/sds/src/emacs/trunk/src/eval.c:1469
  > #21 0x00000000005a2699 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:981
  > #22 0x0000000000569111 in funcall_lambda (fun=19912645, nargs=<optimized out>, arg_vector=0x7fffffffbfa0)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #23 0x000000000056948b in Ffuncall (nargs=1, args=0x7fffffffbf98) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #24 0x000000000056a55b in Fapply (nargs=2, args=0x7fffffffbf98) at /home/sds/src/emacs/trunk/src/eval.c:2450
  > #25 0x00000000005696cc in Ffuncall (nargs=3, args=0x7fffffffbf90) at /home/sds/src/emacs/trunk/src/eval.c:2984
  > #26 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
  > #27 0x0000000000568aa3 in eval_sub (form=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2356
  > #28 0x000000000056bd44 in internal_lisp_condition_case (var=11970946, bodyform=9986302, handlers=8751622)
  >     at /home/sds/src/emacs/trunk/src/eval.c:1469
  > #29 0x00000000005a2699 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>, 
  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:981
  > #30 0x0000000000569111 in funcall_lambda (fun=9985997, nargs=<optimized out>, arg_vector=0x7fffffffc488)
  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
  > #31 0x000000000056948b in Ffuncall (nargs=2, args=0x7fffffffc480) at /home/sds/src/emacs/trunk/src/eval.c:3063
  > #32 0x00000000005698fa in call1 (fn=<optimized out>, arg1=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2771
  > #33 0x00000000004f815e in timer_check_2 () at /home/sds/src/emacs/trunk/src/keyboard.c:4463
  > #34 timer_check () at /home/sds/src/emacs/trunk/src/keyboard.c:4509
  > #35 0x00000000004f8489 in readable_events (flags=<optimized out>) at /home/sds/src/emacs/trunk/src/keyboard.c:3390
  > #36 0x00000000004fa9e5 in get_input_pending (flags=1, addr=0xb5a970) at /home/sds/src/emacs/trunk/src/keyboard.c:6739
  > #37 0x00000000004fd06a in detect_input_pending_run_timers (do_display=1) at /home/sds/src/emacs/trunk/src/keyboard.c:10506
  > #38 0x00000000005a82e0 in wait_reading_process_output (time_limit=30, microsecs=0, read_kbd=<optimized out>, do_display=1, 
  >     wait_for_cell=11970946, wait_proc=<optimized out>, just_wait_proc=0) at /home/sds/src/emacs/trunk/src/process.c:4733
  > #39 0x000000000041add4 in sit_for (timeout=120, reading=1, do_display=1) at /home/sds/src/emacs/trunk/src/dispnew.c:6063
  > #40 0x00000000004ff345 in read_char (commandflag=1, nmaps=2, maps=0x7fffffffcd50, prev_event=11970946, 
  >     used_mouse_menu=0x7fffffffced0, end_time=0x0) at /home/sds/src/emacs/trunk/src/keyboard.c:2690
  > #41 0x00000000005000c7 in read_key_sequence (keybuf=0x7fffffffcf30, prompt=11970946, dont_downcase_last=0, 
  >     can_return_switch_frame=1, fix_current_buffer=1, bufsize=30) at /home/sds/src/emacs/trunk/src/keyboard.c:9326
  > #42 0x0000000000501da5 in command_loop_1 () at /home/sds/src/emacs/trunk/src/keyboard.c:1448
  > #43 0x00000000005677b6 in internal_condition_case (bfun=0x501bd0 <command_loop_1>, handlers=12023138, hfun=0x4f6980 <cmd_error>)
  >     at /home/sds/src/emacs/trunk/src/eval.c:1515
  > #44 0x00000000004f4dee in command_loop_2 (ignore=<optimized out>) at /home/sds/src/emacs/trunk/src/keyboard.c:1159
  > #45 0x0000000000567698 in internal_catch (tag=2738188573441308546, func=0x4f4dd0 <command_loop_2>, arg=11970946)
  >     at /home/sds/src/emacs/trunk/src/eval.c:1272
  > #46 0x00000000004f6457 in command_loop () at /home/sds/src/emacs/trunk/src/keyboard.c:1138
  > #47 recursive_edit_1 () at /home/sds/src/emacs/trunk/src/keyboard.c:758
  > #48 0x00000000004f678c in Frecursive_edit () at /home/sds/src/emacs/trunk/src/keyboard.c:822
  > #49 0x000000000040fbad in main (argc=1, argv=<optimized out>) at /home/sds/src/emacs/trunk/src/emacs.c:1715

  > Lisp Backtrace:
  > "process-get" (0xffffb0b8)
  > "ess-wait-for-process" (0xffffb278)
  > "ess-command" (0xffffb448)
  > "ess-get-words-from-vector" (0xffffb618)
  > "ess-function-arguments" (0xffffb7e8)
  > "ess-eldoc-function" (0xffffb9b0)
  > "byte-code" (0xffffba90)
  > "eldoc-print-current-symbol-info" (0xffffbfa0)
  > "apply" (0xffffbf98)
  > "byte-code" (0xffffc080)
  > "timer-event-handler" (0xffffc488)
  > (gdb) 

  > killing R does not help - R is dead but Emacs is still stuck.

  > Emacs  : GNU Emacs 24.0.94.2 (x86_64-unknown-linux-gnu, X toolkit, Xaw3d scroll bars)
  >  of 2012-03-20 on t520sds
  > Package: ess-mode 12.03

  > current state:
  > ==============
  > (setq
  >  ess-language "Initial"
  >  ess-dialect nil
  >  ess-ask-for-ess-directory t
  >  ess-ask-about-transfile nil
  >  ess-directory nil
  >  ess-keep-dump-files "always"
  >  ess-source-directory "/tmp/"
  >  )


From spinuvit at gmail.com  Wed Mar 21 10:19:24 2012
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 21 Mar 2012 10:19:24 +0100
Subject: [Rd] enableJIT() prohibits usual R debugging
Message-ID: <87mx7al3ab.fsf@gmail.com>


Hi, 

Browser doesn't work properly with the compiler enabled. It might be
intended behavior, but it's not documented.


compiler::enableJIT(1)
foo <- function(){
    browser()
    cat("here\n")
}



Browser doesn't stop, and I am getting:

> foo()
Called from: foo()
Browse[1]> here
> 

Thanks, 
Vitalie.

> sessionInfo()
R version 2.14.2 (2012-02-29)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] compiler  stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.14.2
>


From m at feng.li  Wed Mar 21 12:08:17 2012
From: m at feng.li (Feng Li)
Date: Wed, 21 Mar 2012 12:08:17 +0100
Subject: [Rd] enableJIT() prohibits usual R debugging
In-Reply-To: <87mx7al3ab.fsf@gmail.com>
References: <87mx7al3ab.fsf@gmail.com>
Message-ID: <4F69B6A1.803@feng.li>

FYI

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14594


On 03/21/2012 10:19 AM, Vitalie Spinu wrote:
>
> Hi,
>
> Browser doesn't work properly with the compiler enabled. It might be
> intended behavior, but it's not documented.
>
>
> compiler::enableJIT(1)
> foo<- function(){
>      browser()
>      cat("here\n")
> }
>
>
>
> Browser doesn't stop, and I am getting:
>
>> foo()
> Called from: foo()
> Browse[1]>  here
>>
>
> Thanks,
> Vitalie.
>
>> sessionInfo()
> R version 2.14.2 (2012-02-29)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8
>   [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] compiler  stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.2
>>
>

-- 
Feng Li
Department of Statistics
Stockholm University
SE-106 91 Stockholm, Sweden
http://feng.li/


From luke-tierney at uiowa.edu  Wed Mar 21 13:46:21 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 21 Mar 2012 07:46:21 -0500
Subject: [Rd] enableJIT() prohibits usual R debugging
In-Reply-To: <87mx7al3ab.fsf@gmail.com>
References: <87mx7al3ab.fsf@gmail.com>
Message-ID: <alpine.DEB.2.02.1203210744180.980@luke-Latitude>

I can't reproduce this in either 2.14.1 or R-devel.

luke

On Wed, 21 Mar 2012, Vitalie Spinu wrote:

>
> Hi,
>
> Browser doesn't work properly with the compiler enabled. It might be
> intended behavior, but it's not documented.
>
>
> compiler::enableJIT(1)
> foo <- function(){
>    browser()
>    cat("here\n")
> }
>
>
>
> Browser doesn't stop, and I am getting:
>
>> foo()
> Called from: foo()
> Browse[1]> here
>>
>
> Thanks,
> Vitalie.
>
>> sessionInfo()
> R version 2.14.2 (2012-02-29)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8
> [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] compiler  stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.2
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From spinuvit at gmail.com  Wed Mar 21 14:39:52 2012
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 21 Mar 2012 14:39:52 +0100
Subject: [Rd] enableJIT() prohibits usual R debugging
In-Reply-To: <alpine.DEB.2.02.1203210744180.980@luke-Latitude>
	(luke-tierney@uiowa.edu's message of "Wed, 21 Mar 2012 07:46:21
	-0500")
References: <87mx7al3ab.fsf@gmail.com>
	<alpine.DEB.2.02.1203210744180.980@luke-Latitude>
Message-ID: <87aa3akr87.fsf@gmail.com>

>>>> <luke-tierney at uiowa.edu>
>>>> on Wed, 21 Mar 2012 07:46:21 -0500 wrote:

  > I can't reproduce this in either 2.14.1 or R-devel.

Hm .. I cannot reproduce it, nor with the latest R-devel, nor with 2.14.2
anymore. Some local glitch or something ...

Vitalie.


From friendly at yorku.ca  Wed Mar 21 14:58:02 2012
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 21 Mar 2012 09:58:02 -0400
Subject: [Rd] uncompressed saves warning
Message-ID: <4F69DE6A.90701@yorku.ca>

[Env:  Windows XP Pro / R 2.14.1 / StatET / R-Forge]

A package of mine now generates a Warning under R 2.15.0 beta on CRAN 
checks:

* checking data for ASCII and uncompressed saves ... WARNING

   Note: significantly better compression could be obtained
         by using R CMD build --resave-data
                 old_size new_size compress
   gfrance.rda      300Kb    179Kb       xz
   gfrance85.rda    295Kb    176Kb       xz

What is the equivalent R command to compress these files in my project tree?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From spinuvit at gmail.com  Wed Mar 21 15:12:18 2012
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 21 Mar 2012 15:12:18 +0100
Subject: [Rd] enableJIT() prohibits usual R debugging
In-Reply-To: <87aa3akr87.fsf@gmail.com> (Vitalie Spinu's message of "Wed, 21
	Mar 2012 14:39:52 +0100")
References: <87mx7al3ab.fsf@gmail.com>
	<alpine.DEB.2.02.1203210744180.980@luke-Latitude>
	<87aa3akr87.fsf@gmail.com>
Message-ID: <873992kpq5.fsf@gmail.com>

>>>> Vitalie Spinu <spinuvit at gmail.com>
>>>> on Wed, 21 Mar 2012 14:39:52 +0100 wrote:

>>>> <luke-tierney at uiowa.edu>
>>>> on Wed, 21 Mar 2012 07:46:21 -0500 wrote:

  >> I can't reproduce this in either 2.14.1 or R-devel.

  > Hm .. I cannot reproduce it, nor with the latest R-devel, nor with 2.14.2
  > anymore. Some local glitch or something ...

Instead I can reproduce similar problem as pointed by Feng:

compiler::enableJIT(1)
foo <- function(){
    browser()
    cat("here\n")
    cat("here\n")
}

foo()

and then "n RET". Everything is skipped. 

If this is the intended behavior then a very loud note would be really
welcome in the "compile" help page.

Thanks, 
Vitalie.

> version
               _                                                 
platform       i686-pc-linux-gnu                                 
arch           i686                                              
os             linux-gnu                                         
system         i686, linux-gnu                                   
status         Under development (unstable)                      
major          2                                                 
minor          16.0                                              
year           2012                                              
month          03                                                
day            20                                                
svn rev        58793                                             
language       R                                                 
version.string R Under development (unstable) (2012-03-20 r58793)
>


From luke-tierney at uiowa.edu  Wed Mar 21 15:25:21 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 21 Mar 2012 09:25:21 -0500
Subject: [Rd] enableJIT() prohibits usual R debugging
In-Reply-To: <873992kpq5.fsf@gmail.com>
References: <87mx7al3ab.fsf@gmail.com>
	<alpine.DEB.2.02.1203210744180.980@luke-Latitude>
	<87aa3akr87.fsf@gmail.com> <873992kpq5.fsf@gmail.com>
Message-ID: <alpine.DEB.2.02.1203210920090.980@luke-Latitude>

On Wed, 21 Mar 2012, Vitalie Spinu wrote:

>>>>> Vitalie Spinu <spinuvit at gmail.com>
>>>>> on Wed, 21 Mar 2012 14:39:52 +0100 wrote:
>
>>>>> <luke-tierney at uiowa.edu>
>>>>> on Wed, 21 Mar 2012 07:46:21 -0500 wrote:
>
>  >> I can't reproduce this in either 2.14.1 or R-devel.
>
>  > Hm .. I cannot reproduce it, nor with the latest R-devel, nor with 2.14.2
>  > anymore. Some local glitch or something ...
>
> Instead I can reproduce similar problem as pointed by Feng:
>
> compiler::enableJIT(1)
> foo <- function(){
>    browser()
>    cat("here\n")
>    cat("here\n")
> }
>
> foo()
>
> and then "n RET". Everything is skipped.

Then the cunction call continues as it would vor 'c' -- you can't
single step through compiled code (and debugging a compiled function
switches to the interpreted version for that reason). I thought I had
put a note about this in ?browser and ?debug but apparently not --
will do soon. Thanks for pointing this out.

luke

>
> If this is the intended behavior then a very loud note would be really
> welcome in the "compile" help page.
>
> Thanks,
> Vitalie.
>
>> version
>               _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          16.0
> year           2012
> month          03
> day            20
> svn rev        58793
> language       R
> version.string R Under development (unstable) (2012-03-20 r58793)
>>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ligges at statistik.tu-dortmund.de  Wed Mar 21 18:22:44 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 21 Mar 2012 18:22:44 +0100
Subject: [Rd] uncompressed saves warning
In-Reply-To: <4F69DE6A.90701@yorku.ca>
References: <4F69DE6A.90701@yorku.ca>
Message-ID: <4F6A0E64.5010603@statistik.tu-dortmund.de>



On 21.03.2012 14:58, Michael Friendly wrote:
> [Env: Windows XP Pro / R 2.14.1 / StatET / R-Forge]
>
> A package of mine now generates a Warning under R 2.15.0 beta on CRAN
> checks:
>
> * checking data for ASCII and uncompressed saves ... WARNING
>
> Note: significantly better compression could be obtained
> by using R CMD build --resave-data
> old_size new_size compress
> gfrance.rda 300Kb 179Kb xz
> gfrance85.rda 295Kb 176Kb xz
>
> What is the equivalent R command to compress these files in my project
> tree?
>

Michael,

if you use
R CMD build --resave-data
to build the tar archive, the versions therein are recompressed.

Otherwise, you can also open the files and resave them via save() and 
appropriate arguments.

Or use  resaveRdaFiles() in package tools to runn it on a whole folder 
automatically.

Best,
uwe


From ligges at statistik.tu-dortmund.de  Wed Mar 21 18:26:59 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 21 Mar 2012 18:26:59 +0100
Subject: [Rd] overriding "summary.default" or "summary.data.frame". How?
In-Reply-To: <CAErODj_AE31DneOFZi6XBKY-PZV9WEo=oHuEt6MdMJFw0QCeBg@mail.gmail.com>
References: <CAErODj_AE31DneOFZi6XBKY-PZV9WEo=oHuEt6MdMJFw0QCeBg@mail.gmail.com>
Message-ID: <4F6A0F63.5090107@statistik.tu-dortmund.de>

Simple answer: Never ever override R base functionality.

Best,
Uwe Ligges





On 20.03.2012 16:24, Paul Johnson wrote:
> I suppose everybody who makes a package for the first time thinks "I
> can change anything!" and then runs into this same question. Has
> anybody written out information on how a package can override
> functions in R base in the R 2.14 (mandatory NAMESPACE era)?
>
> Suppose I want to alphabetize variables in a summary.data.frame, or
> return the standard deviation with the mean in summary output.  I'm
> pasting in a working example below.  It has new "summary.factor"
> method. It also has a function summarize that I might like to use in
> place of summary.data.frame.
>
> How would my new methods "drop on top" of R base functions?  It
> appears my functions (summarizeFactors) can find my summary.factor,
> but R's own summary uses its own summary.factor.
>
>
> ## summarizeNumerics takes a data frame or matrix, scans the columns
> ## to select only the numeric variables.  By default it alphabetizes
> ## the columns (use alphaSort = FALSE to stop that). It then
> ## calculates the quantiles for each variable, as well as the mean,
> ## standard deviation, and variance, and then packs those results into
> ## a matrix. The main benefits from this compared to R's default
> ## summary are 1) more summary information is returned for each
> ## variable, and the results are returned in a matrix that is easy to
> ## use in further analysis.
> summarizeNumerics<- function(dat, alphaSort = TRUE,  digits = max(3,
> getOption("digits") - 3)){
>    if (!is.data.frame(dat)) dat<- as.data.frame(dat)
>    nums<- sapply(dat, is.numeric)
>    datn<- dat[ , nums, drop = FALSE]
>    if (alphaSort) datn<- datn[ , sort(colnames(datn)), drop = FALSE]
>    sumdat<- apply(datn, 2, stats::quantile, na.rm=TRUE)
>    sumdat<- rbind(sumdat, mean= apply(datn, 2, mean, na.rm=TRUE))
>    sumdat<- rbind(sumdat, sd= apply(datn, 2, sd, na.rm=TRUE))
>    sumdat<- rbind(sumdat, var= apply(datn, 2, var, na.rm=TRUE))
>    sumdat<- rbind(sumdat, "NA's"=apply(datn, 2, function(x) sum(is.na(x))))
>    signif(sumdat, digits)
> }
>
>
> summary.factor<- function(y, numLevels) {
>    ## 5 nested functions to be used later
>
>    divr<- function(p=0){
>      ifelse ( p>0&  p<  1, -p * log2(p), 0)
>    }
>    entropy<- function(p){
>      sum ( divr(p) )
>    }
>    maximumEntropy<- function(N) -log2(1/N)
>    normedEntropy<- function(x) entropy(x)/ maximumEntropy(length(x))
>    nas<- is.na(y)
>    y<- factor(y)
>    ll<- levels(y)
>    tbl<- table(y)
>    tt<- c(tbl)
>    names(tt)<- dimnames(tbl)[[1L]]
>    o<- sort.list(tt, decreasing = TRUE)
>    if (length(ll)>  numLevels){
>      toExclude<- numLevels:length(ll)
>      tt<- c(tt[o[-toExclude]], `(All Others)` = sum(tt[o[toExclude]]),
> `NA's`=sum(nas))
>    }else{
>      tt<- c(tt[o], `NA's`=sum(nas))
>    }
>    props<- prop.table(tbl);
>    tt<- c(tt, "Entropy"=entropy(props), "NormedEntropy"= normedEntropy(props))
> }
>
>
> ## Takes a data frame or matrix, scans the columns to find the
> ## variables that are not numeric and keeps them. By default it
> ## alphabetizes them (alphaSort = FALSE to stop that).  It then treats
> ## all non-numeric variables as if they were factors, and summarizes
> ## each in a say that I find useful. In particular, for each factor,
> ## it provides a table of the most frequently occurring values (the
> ## top "numLevels" values are represented).  As a diversity indictor,
> ## it calculates the Entropy and NormedEntropy values for each
> ## variable.  Note not all of this is original. It combines my code
> ## and R code from base/summary.R
> summarizeFactors<- function(dat = NULL, numLevels = 10, alphaSort =
> TRUE, digits = max(3, getOption("digits") - 3))
> {
>
>    ##copies from R base::summary.R summary.data.frame
>    ncw<- function(x) {
>      z<- nchar(x, type="w")
>      if (any(na<- is.na(z))) {
>              # FIXME: can we do better
>        z[na]<- nchar(encodeString(z[na]), "b")
>      }
>      z
>    }
>
>    if (!is.data.frame(dat)) dat<- as.data.frame(dat)
>    ##treat any nonnumeric as a factor
>    factors<- sapply(dat, function(x) {!is.numeric(x) })
>    ##If only one factor, need drop=FALSE.
>    datf<- dat[ , factors, drop = FALSE]
>    if (alphaSort) datf<- datf[ , sort(colnames(datf)), drop = FALSE]
>    z<- lapply(datf, summary.factor, numLevels=numLevels)
>    nv<- length(datf)
>    nm<- names(datf)
>    lw<- numeric(nv)
>    nr<- max(unlist(lapply(z, NROW)))
>    for(i in 1L:nv) {
>      sms<- z[[i]]
>      lbs<- format(names(sms))
>      sms<- paste(lbs, ":", format(sms, digits = digits), "  ",
>                   sep = "")
>      lw[i]<- ncw(lbs[1L])
>      length(sms)<- nr
>      z[[i]]<- sms
>    }
>    z<- unlist(z, use.names=TRUE)
>    dim(z)<- c(nr, nv)
>    if(any(is.na(lw)))
>      warning("probably wrong encoding in names(.) of column ",
>              paste(which(is.na(lw)), collapse = ", "))
>      blanks<- paste(character(max(lw, na.rm=TRUE) + 2L), collapse = " ")
>    pad<- floor(lw - ncw(nm)/2)
>    nm<- paste(substring(blanks, 1, pad), nm, sep = "")
>    dimnames(z)<- list(rep.int("", nr), nm)
>    attr(z, "class")<- c("table")
>    z
> }
>
> ##
> ## want to override summary.data.frame, but confusing.  When
> ## will R find my summary.data.frame, when will it find the one in base.
> ## use ... for numLevels, digits, alphaSort
> summarize<- function(dat, ...)
> {
>    dots<- list(...)
>    dotnames<- names(dots)
>    ## next should give c("digits", "alphaSort")
>    nnames<-  names(formals(summarizeNumerics))[-1L]
>    ## names that need keeping if in dots:
>    keepnames<- dotnames %in% nnames
>    if( sum(keepnames)>  0 ) {
>      argList<- modifyList( list("dat"=quote(dat)), dots[keepnames] )
>      datn<- do.call("summarizeNumerics", argList)
>     } else {
>      datn<- do.call("summarizeNumerics", args=list("dat"= quote(dat)))
>    }
>
>    ## all ... can go to summarizeFactors
>    datf<- summarizeFactors(dat, ...)
>
>    value<- list(numerics = datn, factors = datf)
>    value
> }
>
>
>
>
> set.seed(23452345)
> x1<- gl(12,2, labels=LETTERS[1:12])
> x2<- gl(8,3, labels=LETTERS[12:24])
> z1<- rnorm(24)
> a1<- rnorm(24, mean=1.2, sd = 1.7)
> a2<- rpois(24, lambda=10 + a1)
> a3<- rgamma(24, 0.5, 4)
> b1<- rnorm(24, mean=1.3, sd = 1.4)
> dat<- data.frame(z1, a1, x2, a2, x1, a3, b1)
> summary(dat)
>
>
> summarize(dat)
>
>
> summarizeNumerics(dat)
> summarizeFactors(dat, numLevels=5)
>
> summarize(dat, alphaSort=FALSE)
>
> summarize(dat, digits=6, alphaSort=FALSE)
>
> summarize(dat, digits=22, alphaSort=FALSE)
>
> summarize(dat, numLevels= 2)
>
> datsumm<- summarize(dat)
>
> datsumm$numerics
> datsumm[[1]] ## same: gets numerics
>
> datsumm$factors
> datsumm[[2]]
>
>
> ## Use numerics output to make plots. First,
> ## transpose gives varnames x summary stat matrix
> datsummNT<- t(datsumm$numerics)
> datsummNT<- as.data.frame(datsummNT)
>
> plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The Variances")
>
> plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
> Variances", type="n")
> text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT))
>
> ## Here's a little plot wrinkle.  Note variable names are "out to the
> ## edge" of the plot. If names are longer they don't stay inside
> ## figure. See?
>
> ## Make the variable names longer
>
> rownames(datsummNT)
> rownames(datsummNT)<- c("boring var","var with long name", "tedious
> name var", "stupid varname", "buffoon not baboon")
> plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
> Variances", type="n")
> text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)
> ## That's no good. Names across the edges
>
> ## We could brute force the names outside the edges like this
> par(xpd=T)
> text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)
> ## but that is not much better
> par(xpd=F)
>
> ## Here is one fix. Make the unused space inside the plot larger by
> ## making xlim and ylim bigger.  I use the magRange function from
> ## rockchalk to easily expand range to 1.2 times its current size.
> ## otherwise, long variable names do not fit inside plot. magRange
> ## could be asymmetric if we want, but this use is symmetric.
> library(rockchalk)
>
> rownames(datsummNT)
> rownames(datsummNT)<- c("boring var","var with long name", "tedious
> name var", "stupid varname", "buffoon not baboon")
> plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The
> Variances", type="n", xlim=magRange(datsummNT$mean, 1.2),
> ylim=magRange(datsummNT$var, 1.2))
> text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT), cex=0.8)
>
> ## Here's another little plot wrinkle.
> ## If we don't do that to keep the names in bounds, we need some
> ## fancy footwork.  Note when a point is near the edge, I make sure
> ## the text prints toward the center of the graph.
> plot(datsummNT$mean, datsummNT$var, xlab="The Means", ylab="The Variances")
> ## calculate label positions. This is not as fancy as it could be.
> ## If there were lots of variables, we'd have to get smarter about
> ## positioning labels on above, below, left, or right.
> labelPos<- ifelse(datsummNT$mean - mean(datsummNT$mean, na.rm=T)>  0, 2, 4)
> text(datsummNT$mean, datsummNT$var, labels=rownames(datsummNT),
> cex=0.8, pos=labelPos)
>
>
>
> x<- data.frame(x=rnorm(100), y = gl(50,2), z = rep(1:4, 25), ab = gl(2,50))
>
> summarize(x)
> summarize(x, numLevels=15)
>
> sumry<- summarize(x)
> sumry[[1]] ##another way to get the numerics output
> sumry[[2]] ##another way to get the factors output
>
> dat<- data.frame(x=rnorm(100), y = gl(50,2), z = factor(rep(1:4, 25),
> labels=c("A","B","C","D")), animal=factor(ifelse(runif(100)<  0.2,
> "cow", ifelse(runif(100)<  0.5,"pig","duck"))))
>
> summarize(dat)
>
> dat<- read.table(url("http://pj.freefaculty.org/guides/stat/DataSets/USNewsCollege/USNewsCollege.csv"),
> sep=",")
>
> colnames(dat)<- c("fice", "name", "state", "private", "avemath", "aveverb",
>      "avecomb", "aveact", "fstmath", "trdmath", "fstverb", "trdverb",
>      "fstact", "trdact", "numapps", "numacc", "numenr", "pctten",
>      "pctquart", "numfull", "numpart", "instate", "outstate",
>      "rmbrdcst", "roomcst", "brdcst", "addfees", "bookcst", "prsnl",
>      "pctphd", "pctterm", "stdtofac", "pctdonat", "instcst", "gradrate")
>
> dat$private<- factor(dat$private, labels=c("public","private"))
> sumry<- summarize(dat, digits=2)
> sumry
>
> sumry[[1]]
> sumry[[2]]
>
> summarize(dat[ , c("fice","name","private","fstverb","avemath")], digits=4)
>
>


From ripley at stats.ox.ac.uk  Wed Mar 21 19:35:15 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Mar 2012 18:35:15 +0000
Subject: [Rd] bzip2'ed data under data/
In-Reply-To: <877gygtk27.fsf@kolob.subpolar.dyndns.org>
References: <877gygtk27.fsf@kolob.subpolar.dyndns.org>
Message-ID: <4F6A1F63.807@stats.ox.ac.uk>

On 19/03/2012 20:25, Sebastian P. Luque wrote:
> Hi,
>
> R CMD check PACKAGE_VERSION_tar.gz gives warning:
>
> Files not of a type allowed in a ?data? directory:
>    ?tser1.csv.bz2? ?tser2.csv.bz2?
> Please use e.g. ?inst/extdata? for non-R data files
>
> which I didn't expect, based on section 1.1.5 (Data in packages) of the
> Writing R Extensions manual:
>
> Tables (`.tab', `.txt', or `.csv' files) can be compressed by
> `gzip', `bzip2' or `xz', optionally with additional extension `.gz',
> `.bz2' or `.xz'.  However, such files can only be used with R 2.10.0 or
> later, and so the package should have an appropriate `Depends' entry in
> its DESCRIPTION file.
>
> In this case, I have a Depends: R (>= 2.13.0), and the package was built
> with R version 2.15.0 beta (2012-03-16 r58769), Platform:
> x86_64-pc-linux-gnu (64-bit), so I don't understand the warning.
>
> Cheers,
>

Well, the extension is allowed 'optionally' to be .csv.bz2, but that 
does not make it good practice and I would suggest not using it.

But that 'check' picked it up was a typo in the code 'check' used to 
specify types of data() files, corrected since your build of R so I 
would expect current R-devel or R-pre-release not to give the NOTE.  I 
am not sure whether or not that has any ramifications for users of the 
package with older versions of R, but we know calling the compressed 
file foo.csv would work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke-tierney at uiowa.edu  Wed Mar 21 20:48:52 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 21 Mar 2012 14:48:52 -0500
Subject: [Rd] enableJIT() and internal R completions (was: [ESS-bugs]
 ess-mode 12.03; ess hangs emacs)
In-Reply-To: <87r4wml3ts.fsf@gmail.com>
References: <87limvnqrw.fsf@gnu.org> <87r4wml3ts.fsf@gmail.com>
Message-ID: <alpine.DEB.2.02.1203211432320.980@luke-Latitude>

The compiler/JIT is behaving as expected. The idea of compiling on
duplicate, which level 2 enables, is to address some idioms where
functions are modified at runtime.  Ideally it would be good to avoid
these idioms, and we may eventually get there, but for now they are an
issue.

In this particular case getAnywhere contains

         if (is.function(x))
             environment(x) <- baseenv()
         x

and the new function is duplicated and compiled in an lapply() call,
but the function doesn't make much sense with the baseenv()
environment, hence all the warnings.  This seems to be done so that
identical() can be used to compare functions and consider functions
that only differ in the environment to be edentical. It would probably
be better to do this in another more explicit way -- I'll look into
it.

(This does not occur in 2.4.1 because of a lack of duplicating bug in
lapply that has since been fixed.)

luke

On Wed, 21 Mar 2012, Vitalie Spinu wrote:

>
> Hello,
>
> JIT compiler interferes with internal R completions:
>
> compiler::enableJIT(2)
> utils:::functionArgs("density", '')
>
> gives:
>
> utils:::functionArgs("density", '')
> Note: no visible global function definition for 'bw.nrd0'
> Note: no visible global function definition for 'bw.nrd'
> Note: no visible global function definition for 'bw.ucv'
> Note: no visible global function definition for 'bw.bcv'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible binding for global variable 'C_massdist'
> Note: no visible global function definition for 'dnorm'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'approx'
> Note: no visible global function definition for 'bw.nrd0'
> Note: no visible global function definition for 'bw.nrd'
> Note: no visible global function definition for 'bw.ucv'
> Note: no visible global function definition for 'bw.bcv'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible binding for global variable 'C_massdist'
> Note: no visible global function definition for 'dnorm'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'approx'
> Note: no visible global function definition for 'bw.nrd0'
> Note: no visible global function definition for 'bw.nrd'
> Note: no visible global function definition for 'bw.ucv'
> Note: no visible global function definition for 'bw.bcv'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible global function definition for 'bw.SJ'
> Note: no visible binding for global variable 'C_massdist'
> Note: no visible global function definition for 'dnorm'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'fft'
> Note: no visible global function definition for 'approx'
> [1] "x="          "...="        "bw="         "adjust="     "kernel="     "weights="
> [7] "window="     "width="      "give.Rkern=" "n="          "from="       "to="
> [13] "cut="        "na.rm="
>
>
> Disabling JIT warnings removes the notes, but the call remains to be
> extremely slow, as the compiler still processes all the exceptions.
>
> Thanks,
> Vitalie.
>
>>>>> Sam Steingold <sds at gnu.org>
>>>>> on Tue, 20 Mar 2012 13:09:07 -0400 wrote:
>
>  > ess hangs emacs completely.
>
>  > I just created a brand new Rprofile
>
>  > options(error = utils::recover)
>  > library(compiler)
>  > compiler::enableJIT(3)
>
>
>  > and now and I start R and start typing I see this:
>  >> options(STERM=.....)
>  >> matrix(nrow=|)
>  > ("|" stands for my cursor)
>  > and "nrow: x" in the minibuffer.
>  > that's it.
>  > emacs is stuck.
>
>  > Program received signal SIGTSTP, Stopped (user).
>  > 0x00000000005a115a in exec_byte_code (bytestr=8748337, vector=8748373, maxdepth=<optimized out>, args_template=11970946,
>  >     nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:487
>  > 487       stack.pc = stack.byte_string_start = SDATA (bytestr);
>  > (gdb) where
>  > #0  0x00000000005a115a in exec_byte_code (bytestr=8748337, vector=8748373, maxdepth=<optimized out>, args_template=11970946,
>  >     nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:487
>  > #1  0x0000000000569111 in funcall_lambda (fun=8748253, nargs=<optimized out>, arg_vector=0x7fffffffb0b8)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #2  0x000000000056948b in Ffuncall (nargs=3, args=0x7fffffffb0b0) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #3  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #4  0x0000000000569111 in funcall_lambda (fun=20119685, nargs=<optimized out>, arg_vector=0x7fffffffb278)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #5  0x000000000056948b in Ffuncall (nargs=4, args=0x7fffffffb270) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #6  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #7  0x0000000000569111 in funcall_lambda (fun=20126229, nargs=<optimized out>, arg_vector=0x7fffffffb448)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #8  0x000000000056948b in Ffuncall (nargs=6, args=0x7fffffffb440) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #9  0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #10 0x0000000000569111 in funcall_lambda (fun=19976549, nargs=<optimized out>, arg_vector=0x7fffffffb618)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #11 0x000000000056948b in Ffuncall (nargs=4, args=0x7fffffffb610) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #12 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #13 0x0000000000569111 in funcall_lambda (fun=20815797, nargs=<optimized out>, arg_vector=0x7fffffffb7e8)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #14 0x000000000056948b in Ffuncall (nargs=2, args=0x7fffffffb7e0) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #15 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #16 0x0000000000569111 in funcall_lambda (fun=20802901, nargs=<optimized out>, arg_vector=0x7fffffffb9b0)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #17 0x000000000056948b in Ffuncall (nargs=1, args=0x7fffffffb9a8) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #18 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #19 0x0000000000568aa3 in eval_sub (form=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2356
>  > #20 0x000000000056bd44 in internal_lisp_condition_case (var=12376962, bodyform=18220518, handlers=18218726)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:1469
>  > #21 0x00000000005a2699 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:981
>  > #22 0x0000000000569111 in funcall_lambda (fun=19912645, nargs=<optimized out>, arg_vector=0x7fffffffbfa0)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #23 0x000000000056948b in Ffuncall (nargs=1, args=0x7fffffffbf98) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #24 0x000000000056a55b in Fapply (nargs=2, args=0x7fffffffbf98) at /home/sds/src/emacs/trunk/src/eval.c:2450
>  > #25 0x00000000005696cc in Ffuncall (nargs=3, args=0x7fffffffbf90) at /home/sds/src/emacs/trunk/src/eval.c:2984
>  > #26 0x00000000005a1d46 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:785
>  > #27 0x0000000000568aa3 in eval_sub (form=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2356
>  > #28 0x000000000056bd44 in internal_lisp_condition_case (var=11970946, bodyform=9986302, handlers=8751622)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:1469
>  > #29 0x00000000005a2699 in exec_byte_code (bytestr=<optimized out>, vector=<optimized out>, maxdepth=<optimized out>,
>  >     args_template=<optimized out>, nargs=<optimized out>, args=<optimized out>) at /home/sds/src/emacs/trunk/src/bytecode.c:981
>  > #30 0x0000000000569111 in funcall_lambda (fun=9985997, nargs=<optimized out>, arg_vector=0x7fffffffc488)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:3233
>  > #31 0x000000000056948b in Ffuncall (nargs=2, args=0x7fffffffc480) at /home/sds/src/emacs/trunk/src/eval.c:3063
>  > #32 0x00000000005698fa in call1 (fn=<optimized out>, arg1=<optimized out>) at /home/sds/src/emacs/trunk/src/eval.c:2771
>  > #33 0x00000000004f815e in timer_check_2 () at /home/sds/src/emacs/trunk/src/keyboard.c:4463
>  > #34 timer_check () at /home/sds/src/emacs/trunk/src/keyboard.c:4509
>  > #35 0x00000000004f8489 in readable_events (flags=<optimized out>) at /home/sds/src/emacs/trunk/src/keyboard.c:3390
>  > #36 0x00000000004fa9e5 in get_input_pending (flags=1, addr=0xb5a970) at /home/sds/src/emacs/trunk/src/keyboard.c:6739
>  > #37 0x00000000004fd06a in detect_input_pending_run_timers (do_display=1) at /home/sds/src/emacs/trunk/src/keyboard.c:10506
>  > #38 0x00000000005a82e0 in wait_reading_process_output (time_limit=30, microsecs=0, read_kbd=<optimized out>, do_display=1,
>  >     wait_for_cell=11970946, wait_proc=<optimized out>, just_wait_proc=0) at /home/sds/src/emacs/trunk/src/process.c:4733
>  > #39 0x000000000041add4 in sit_for (timeout=120, reading=1, do_display=1) at /home/sds/src/emacs/trunk/src/dispnew.c:6063
>  > #40 0x00000000004ff345 in read_char (commandflag=1, nmaps=2, maps=0x7fffffffcd50, prev_event=11970946,
>  >     used_mouse_menu=0x7fffffffced0, end_time=0x0) at /home/sds/src/emacs/trunk/src/keyboard.c:2690
>  > #41 0x00000000005000c7 in read_key_sequence (keybuf=0x7fffffffcf30, prompt=11970946, dont_downcase_last=0,
>  >     can_return_switch_frame=1, fix_current_buffer=1, bufsize=30) at /home/sds/src/emacs/trunk/src/keyboard.c:9326
>  > #42 0x0000000000501da5 in command_loop_1 () at /home/sds/src/emacs/trunk/src/keyboard.c:1448
>  > #43 0x00000000005677b6 in internal_condition_case (bfun=0x501bd0 <command_loop_1>, handlers=12023138, hfun=0x4f6980 <cmd_error>)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:1515
>  > #44 0x00000000004f4dee in command_loop_2 (ignore=<optimized out>) at /home/sds/src/emacs/trunk/src/keyboard.c:1159
>  > #45 0x0000000000567698 in internal_catch (tag=2738188573441308546, func=0x4f4dd0 <command_loop_2>, arg=11970946)
>  >     at /home/sds/src/emacs/trunk/src/eval.c:1272
>  > #46 0x00000000004f6457 in command_loop () at /home/sds/src/emacs/trunk/src/keyboard.c:1138
>  > #47 recursive_edit_1 () at /home/sds/src/emacs/trunk/src/keyboard.c:758
>  > #48 0x00000000004f678c in Frecursive_edit () at /home/sds/src/emacs/trunk/src/keyboard.c:822
>  > #49 0x000000000040fbad in main (argc=1, argv=<optimized out>) at /home/sds/src/emacs/trunk/src/emacs.c:1715
>
>  > Lisp Backtrace:
>  > "process-get" (0xffffb0b8)
>  > "ess-wait-for-process" (0xffffb278)
>  > "ess-command" (0xffffb448)
>  > "ess-get-words-from-vector" (0xffffb618)
>  > "ess-function-arguments" (0xffffb7e8)
>  > "ess-eldoc-function" (0xffffb9b0)
>  > "byte-code" (0xffffba90)
>  > "eldoc-print-current-symbol-info" (0xffffbfa0)
>  > "apply" (0xffffbf98)
>  > "byte-code" (0xffffc080)
>  > "timer-event-handler" (0xffffc488)
>  > (gdb)
>
>  > killing R does not help - R is dead but Emacs is still stuck.
>
>  > Emacs  : GNU Emacs 24.0.94.2 (x86_64-unknown-linux-gnu, X toolkit, Xaw3d scroll bars)
>  >  of 2012-03-20 on t520sds
>  > Package: ess-mode 12.03
>
>  > current state:
>  > ==============
>  > (setq
>  >  ess-language "Initial"
>  >  ess-dialect nil
>  >  ess-ask-for-ess-directory t
>  >  ess-ask-about-transfile nil
>  >  ess-directory nil
>  >  ess-keep-dump-files "always"
>  >  ess-source-directory "/tmp/"
>  >  )
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From richierocks at gmail.com  Wed Mar 21 22:51:13 2012
From: richierocks at gmail.com (Richard Cotton)
Date: Wed, 21 Mar 2012 21:51:13 +0000
Subject: [Rd] Why is there no within.environment function?
Message-ID: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>

If I want to assign some variables into an environment, it seems
natural to do something like

e <- new.env()
within(e,
    {
      x <- 1:5
      y <- runif(5)
    }
)

This throws an error, since within.environment doesn't exist.? I
realise I can work around it using

as.environment(within(as.list(e),
    {
      x <- 1:5
      y <- runif(5)
    }
))

Just wondering why I can't use within directly with environments.

--
4dpiecharts.com


From ggrothendieck at gmail.com  Wed Mar 21 23:00:53 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 21 Mar 2012 18:00:53 -0400
Subject: [Rd] Why is there no within.environment function?
In-Reply-To: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
References: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
Message-ID: <CAP01uRkYxfKtcJzbk5S3mNTNW3ugh8WDaLLF9x8N1yNzs-3tTQ@mail.gmail.com>

On Wed, Mar 21, 2012 at 5:51 PM, Richard Cotton <richierocks at gmail.com> wrote:
> If I want to assign some variables into an environment, it seems
> natural to do something like
>
> e <- new.env()
> within(e,
> ? ?{
> ? ? ?x <- 1:5
> ? ? ?y <- runif(5)
> ? ?}
> )
>
> This throws an error, since within.environment doesn't exist.? I
> realise I can work around it using
>

'with' already does that:

e <- new.env()
with(e, {
   x <- 1.5
   y <- runif(5)
})
ls(e) # lists x and y

Also since proto objects are environments this works:

library(proto)
p <- proto(x = 1.5, y = runif(5))
p$ls() # lists x and y

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Wed Mar 21 23:01:06 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 21 Mar 2012 22:01:06 +0000
Subject: [Rd] Why is there no within.environment function?
In-Reply-To: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
References: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9328AE11@PA-MBX04.na.tibco.com>

Wouldn't within.environment be identical to with.environment?
  > e <- new.env()
  > with(e, { One <- 1 ; Two <- 2+2i ; Theee <- One + Two })
  > objects(e)
  [1] "One"   "Theee" "Two"
It might make the transition between lists and environments
simpler if within.environment  existed.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Richard Cotton
> Sent: Wednesday, March 21, 2012 2:51 PM
> To: r-devel at r-project.org
> Subject: [Rd] Why is there no within.environment function?
> 
> If I want to assign some variables into an environment, it seems
> natural to do something like
> 
> e <- new.env()
> within(e,
>     {
>       x <- 1:5
>       y <- runif(5)
>     }
> )
> 
> This throws an error, since within.environment doesn't exist.? I
> realise I can work around it using
> 
> as.environment(within(as.list(e),
>     {
>       x <- 1:5
>       y <- runif(5)
>     }
> ))
> 
> Just wondering why I can't use within directly with environments.
> 
> --
> 4dpiecharts.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From pdalgd at gmail.com  Wed Mar 21 23:23:11 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Mar 2012 23:23:11 +0100
Subject: [Rd] Why is there no within.environment function?
In-Reply-To: <E66794E69CFDE04D9A70842786030B9328AE11@PA-MBX04.na.tibco.com>
References: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9328AE11@PA-MBX04.na.tibco.com>
Message-ID: <B1C80815-4183-4B2C-B83E-615DE87ACCC5@gmail.com>


On Mar 21, 2012, at 23:01 , William Dunlap wrote:

> Wouldn't within.environment be identical to with.environment?
>> e <- new.env()
>> with(e, { One <- 1 ; Two <- 2+2i ; Theee <- One + Two })
>> objects(e)
>  [1] "One"   "Theee" "Two"
> It might make the transition between lists and environments
> simpler if within.environment  existed.
> 

evalq() would be rather more to the point. Then again, with() _is_ really just a sugar-coated evalq(). 

within() was quite specifically created because you couldn't do the same kind of things with data frames that you could do with environments, so the current thread does seem a bit peculiar to me... (The original design of within() would modify the object in-place, like fix(), but Luke objected.)


  


> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Richard Cotton
>> Sent: Wednesday, March 21, 2012 2:51 PM
>> To: r-devel at r-project.org
>> Subject: [Rd] Why is there no within.environment function?
>> 
>> If I want to assign some variables into an environment, it seems
>> natural to do something like
>> 
>> e <- new.env()
>> within(e,
>>    {
>>      x <- 1:5
>>      y <- runif(5)
>>    }
>> )
>> 
>> This throws an error, since within.environment doesn't exist.  I
>> realise I can work around it using
>> 
>> as.environment(within(as.list(e),
>>    {
>>      x <- 1:5
>>      y <- runif(5)
>>    }
>> ))
>> 
>> Just wondering why I can't use within directly with environments.
>> 
>> --
>> 4dpiecharts.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gavin.simpson at ucl.ac.uk  Wed Mar 21 23:24:12 2012
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 21 Mar 2012 22:24:12 +0000
Subject: [Rd] Why is there no within.environment function?
In-Reply-To: <E66794E69CFDE04D9A70842786030B9328AE11@PA-MBX04.na.tibco.com>
References: <CAPp_+=dLEZzw+ENwTkNmWz-cKZXpQ67NwwUje6EqxWLwMuBufA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9328AE11@PA-MBX04.na.tibco.com>
Message-ID: <1332368652.2002.5.camel@chrysothemis.geog.ucl.ac.uk>

On Wed, 2012-03-21 at 22:01 +0000, William Dunlap wrote:
> Wouldn't within.environment be identical to with.environment?
>   > e <- new.env()
>   > with(e, { One <- 1 ; Two <- 2+2i ; Theee <- One + Two })
>   > objects(e)
>   [1] "One"   "Theee" "Two"
> It might make the transition between lists and environments
> simpler if within.environment  existed.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com

One doesn't normally think of `with()` as changing it's `data` argument,
which might be one reason the connection to `with.environment()` was not
made here.

> d <- data.frame()
> with(d, {
+ A <- 1:3
+ B <- 1:3
+ })
> d
data frame with 0 columns and 0 rows

The behaviour of `with.environment()` makes sense once you think about
it as there is only one environment `e` (from your example), and when it
is updated during the call to `with()` it isn't a copy that is being
updated but the real thing. So I can see why it was overlooked.

G

> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> > Of Richard Cotton
> > Sent: Wednesday, March 21, 2012 2:51 PM
> > To: r-devel at r-project.org
> > Subject: [Rd] Why is there no within.environment function?
> > 
> > If I want to assign some variables into an environment, it seems
> > natural to do something like
> > 
> > e <- new.env()
> > within(e,
> >     {
> >       x <- 1:5
> >       y <- runif(5)
> >     }
> > )
> > 
> > This throws an error, since within.environment doesn't exist.  I
> > realise I can work around it using
> > 
> > as.environment(within(as.list(e),
> >     {
> >       x <- 1:5
> >       y <- runif(5)
> >     }
> > ))
> > 
> > Just wondering why I can't use within directly with environments.
> > 
> > --
> > 4dpiecharts.com
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From simon.urbanek at r-project.org  Thu Mar 22 02:23:18 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Mar 2012 21:23:18 -0400
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <4F68D59C.5060605@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<20120317153522.GA4502@siouxsie> <4F68D59C.5060605@fhcrc.org>
Message-ID: <19B0A4DB-5133-41CE-9C74-1F4A11FACDED@r-project.org>


On Mar 20, 2012, at 3:08 PM, Herv? Pag?s wrote:

> Hi Oliver,
> 
> On 03/17/2012 08:35 AM, oliver wrote:
>> Hello,
>> 
>> regarding the copying issue,
>> I would like to point to the
>> 
>> "Writing R-Extensions" documentation.
>> 
>> There it is mentio9ned, that functions of extensions
>> that use the .C interface normally do get their arguments
>> pre-copied...
>> 
>> 
>> In section 5.2:
>> 
>>   "There can be up to 65 further arguments giving R objects to be
>>   passed to compiled code. Normally these are copied before being
>>   passed in, and copied again to an R list object when the compiled
>>   code returns."
>> 
>> But for the .Call and .Extension interfaces this is NOT the case.
>> 
>> 
>> 
>> In section 5.9:
>>   "The .Call and .External interfaces allow much more control, but
>>   they also impose much greater responsibilities so need to be used
>>   with care. Neither .Call nor .External copy their arguments. You
>>   should treat arguments you receive through these interfaces as
>>   read-only."
>> 
>> 
>> Why is read-only preferred?
>> 
>> Please, see the discussion in section 5.9.10.
>> 
>> It's mentioned there, that a copy of an object in the R-language
>> not necessarily doies a real copy of that object, but instead of
>> this, just a "rerference" to the real data is created (two names
>> referring to one bulk of data). That's typical functional
>> programming: not a variable, but a name (and possibly more than one
>> name) bound to an object.
>> 
>> 
>> Of course, if yo change the orgiginal named value, when there
>> would be no copy of it, before changing it, then both names
>> would refer to the changed data.
>> of course that is not, what is wanted.
>> 
>> But what you also can see in section 5.9.10 is, that
>> there already is a mechanism (reference counting) that allows
>> to distinguish between unnamed and named object.
>> 
>> So, this is directly adressing the points you have mentioned in your
>> examples.
>> 
>> So, at least in principial, R allows to do in-place modifications
>> of object with the .Call interface.
>> 
>> You seem to refer to the .C interface, and I had explored the .Call
>> interface. That's the reason why you may insist on "it's copyied
>> always" and I wondered, what you were talking about, because the
>> .Call interface allowed me rather C-like raw style of programming
>> (and the user of it to decide, if copying will be done or not).
>> 
>> The mechanism to descide, if copying should be done or not,
>> also is mentioined in section 5.9.10: NAMED and SET_NAMED macros.
>> with NAMED you can get the number of references.
>> 
>> But later in that section it is mentioned, that - at least for now -
>> NAMED always returns the value 2.
>> 
>> 
>>   "Currently all arguments to a .Call call will have NAMED set to 2,
>>   and so users must assume that they need to be duplicated before
>>   alteration."
>>                (section 5.9.10, last sentence)
>> 
>> 
>> So, the in-place modification can be done already with the .Call
>> intefcae for example. But the decision if it is safe or not
>> is not supported at the moment.
>> 
>> So the situation is somewhere between: "it is possible" and
>> "R does not support a safe decision if, what is possible, also
>> can be recommended".
>> At the moment R rather deprecates in-place modification by default
>> (the save way, and I agree with this default).
>> 
>> But it's not true, that R in general copies arguments.
>> 
>> But this seems to be true for the .C interface.
>> 
>> Maybe a lot of performance-/memory-problems can be solved
>> by rewriting already existing packages, by providing them
>> via .Call instead of .C.
> 
> My understanding is that most packages use the .C interface
> because it's simpler to deal with and because they don't need
> to pass complicated objects at the C level, just atomic vectors.
> My guess is that it's probably rarely the case that the cost
> of copying the arguments passed to .C is significant, but,
> if that was the case, then they could always call .C() with
> DUP=FALSE. However, using DUP=FALSE is dangerous (see Warning
> section in the man page).
> 
> No need to switch to .Call
> 

I strongly disagree. I'm appalled to see that sentence here. The overhead is significant for any large vector and it is in particular unnecessary since in .C you have to allocate *and copy* space even for results (twice!). Also it is very error-prone, because you have no information about the length of vectors so it's easy to run out of bounds and there is no way to check. IMHO .C should not be used for any code written in this century (the only exception may be if you are passing no data, e.g. if all you do is to pass a flag and expect no result, you can get away with it even if it is more dangerous). It is a legacy interface that dates way back and is essentially just re-named .Fortran interface. Again, I would strongly recommend the use of .Call in any recent code because it is safer and more efficient (if you don't care about either attribute, well, feel free ;)).

Cheers,
Simon






> Cheers,
> H.
> 
>> 
>> 
>> Ciao,
>>    Oliver
>> 
>> 
>> 
>> 
>> On Tue, Mar 06, 2012 at 04:44:49PM +0000, William Dunlap wrote:
>>> S (and its derivatives and successors) promises that functions
>>> will not change their arguments, so in an expression like
>>>    val<- func(arg)
>>> you know that arg will not be changed.  You can
>>> do that by having func copy arg before doing anything,
>>> but that uses space and time that you want to conserve.
>>> If arg is not a named item in any environment then it
>>> should be fine to write over the original because there
>>> is no way the caller can detect that shortcut.  E.g., in
>>>     cx<- cos(runif(n))
>>> the cos function does not need to allocate new space for
>>> its output, it can just write over its input because, without
>>> a name attached to it, the caller has no way of looking
>>> at what runif(n) returned.  If you did
>>>     x<- runif(n)
>>>     cx<- cos(x)
>>> then cos would have to allocate new space for its output
>>> because overwriting its input would affect a subsequent
>>>     sum(x)
>>> I suppose that end-users and function-writers could learn
>>> to live with having to decide when to copy, but not having
>>> to make that decision makes S more pleasant (and safer) to use.
>>> I think that is a major reason that people are able to
>>> share S code so easily.
>>> 
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>> 
>>>> -----Original Message-----
>>>> From: oliver [mailto:oliver at first.in-berlin.de]
>>>> Sent: Tuesday, March 06, 2012 1:12 AM
>>>> To: William Dunlap
>>>> Cc: Herv? Pag?s; R-devel
>>>> Subject: Re: [Rd] Julia
>>>> 
>>>> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
>>>> [...]
>>>>> I find R's (&  S+'s&  S's) copy-on-write-if-not-copying-would-be-discoverable-
>>>>> by-the-uer machanism for giving the allusion of pass-by-value a good way
>>>>> to structure the contract between the function writer and the function user.
>>>> [...]
>>>> 
>>>> 
>>>> Can you elaborate more on this,
>>>> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
>>>> stuff?
>>>> 
>>>> What do you mean with discoverability of not-copying?
>>>> 
>>>> Ciao,
>>>>    Oliver
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Thu Mar 22 02:31:12 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 21 Mar 2012 18:31:12 -0700
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <19B0A4DB-5133-41CE-9C74-1F4A11FACDED@r-project.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<20120317153522.GA4502@siouxsie> <4F68D59C.5060605@fhcrc.org>
	<19B0A4DB-5133-41CE-9C74-1F4A11FACDED@r-project.org>
Message-ID: <4F6A80E0.1050108@fhcrc.org>

On 03/21/2012 06:23 PM, Simon Urbanek wrote:
>
> On Mar 20, 2012, at 3:08 PM, Herv? Pag?s wrote:
>
>> Hi Oliver,
>>
>> On 03/17/2012 08:35 AM, oliver wrote:
>>> Hello,
>>>
>>> regarding the copying issue,
>>> I would like to point to the
>>>
>>> "Writing R-Extensions" documentation.
>>>
>>> There it is mentio9ned, that functions of extensions
>>> that use the .C interface normally do get their arguments
>>> pre-copied...
>>>
>>>
>>> In section 5.2:
>>>
>>>    "There can be up to 65 further arguments giving R objects to be
>>>    passed to compiled code. Normally these are copied before being
>>>    passed in, and copied again to an R list object when the compiled
>>>    code returns."
>>>
>>> But for the .Call and .Extension interfaces this is NOT the case.
>>>
>>>
>>>
>>> In section 5.9:
>>>    "The .Call and .External interfaces allow much more control, but
>>>    they also impose much greater responsibilities so need to be used
>>>    with care. Neither .Call nor .External copy their arguments. You
>>>    should treat arguments you receive through these interfaces as
>>>    read-only."
>>>
>>>
>>> Why is read-only preferred?
>>>
>>> Please, see the discussion in section 5.9.10.
>>>
>>> It's mentioned there, that a copy of an object in the R-language
>>> not necessarily doies a real copy of that object, but instead of
>>> this, just a "rerference" to the real data is created (two names
>>> referring to one bulk of data). That's typical functional
>>> programming: not a variable, but a name (and possibly more than one
>>> name) bound to an object.
>>>
>>>
>>> Of course, if yo change the orgiginal named value, when there
>>> would be no copy of it, before changing it, then both names
>>> would refer to the changed data.
>>> of course that is not, what is wanted.
>>>
>>> But what you also can see in section 5.9.10 is, that
>>> there already is a mechanism (reference counting) that allows
>>> to distinguish between unnamed and named object.
>>>
>>> So, this is directly adressing the points you have mentioned in your
>>> examples.
>>>
>>> So, at least in principial, R allows to do in-place modifications
>>> of object with the .Call interface.
>>>
>>> You seem to refer to the .C interface, and I had explored the .Call
>>> interface. That's the reason why you may insist on "it's copyied
>>> always" and I wondered, what you were talking about, because the
>>> .Call interface allowed me rather C-like raw style of programming
>>> (and the user of it to decide, if copying will be done or not).
>>>
>>> The mechanism to descide, if copying should be done or not,
>>> also is mentioined in section 5.9.10: NAMED and SET_NAMED macros.
>>> with NAMED you can get the number of references.
>>>
>>> But later in that section it is mentioned, that - at least for now -
>>> NAMED always returns the value 2.
>>>
>>>
>>>    "Currently all arguments to a .Call call will have NAMED set to 2,
>>>    and so users must assume that they need to be duplicated before
>>>    alteration."
>>>                 (section 5.9.10, last sentence)
>>>
>>>
>>> So, the in-place modification can be done already with the .Call
>>> intefcae for example. But the decision if it is safe or not
>>> is not supported at the moment.
>>>
>>> So the situation is somewhere between: "it is possible" and
>>> "R does not support a safe decision if, what is possible, also
>>> can be recommended".
>>> At the moment R rather deprecates in-place modification by default
>>> (the save way, and I agree with this default).
>>>
>>> But it's not true, that R in general copies arguments.
>>>
>>> But this seems to be true for the .C interface.
>>>
>>> Maybe a lot of performance-/memory-problems can be solved
>>> by rewriting already existing packages, by providing them
>>> via .Call instead of .C.
>>
>> My understanding is that most packages use the .C interface
>> because it's simpler to deal with and because they don't need
>> to pass complicated objects at the C level, just atomic vectors.
>> My guess is that it's probably rarely the case that the cost
>> of copying the arguments passed to .C is significant, but,
>> if that was the case, then they could always call .C() with
>> DUP=FALSE. However, using DUP=FALSE is dangerous (see Warning
>> section in the man page).
>>
>> No need to switch to .Call
>>
>
> I strongly disagree. I'm appalled to see that sentence here.

Come on!

> The overhead is significant for any large vector and it is in particular unnecessary since in .C you have to allocate *and copy* space even for results (twice!). Also it is very error-prone, because you have no information about the length of vectors so it's easy to run out of bounds and there is no way to check. IMHO .C should not be used for any code written in this century (the only exception may be if you are passing no data, e.g. if all you do is to pass a flag and expect no result, you can get away with it even if it is more dangerous). It is a legacy interface that dates way back and is essentially just re-named .Fortran interface. Again, I would strongly recommend the use of .Call in any recent code because it is safer and more efficient (if you don't care about either attribute, well, feel free ;)).

So aleph will not support the .C interface? ;-)

H.

>
> Cheers,
> Simon
>
>
>
>
>
>
>> Cheers,
>> H.
>>
>>>
>>>
>>> Ciao,
>>>     Oliver
>>>
>>>
>>>
>>>
>>> On Tue, Mar 06, 2012 at 04:44:49PM +0000, William Dunlap wrote:
>>>> S (and its derivatives and successors) promises that functions
>>>> will not change their arguments, so in an expression like
>>>>     val<- func(arg)
>>>> you know that arg will not be changed.  You can
>>>> do that by having func copy arg before doing anything,
>>>> but that uses space and time that you want to conserve.
>>>> If arg is not a named item in any environment then it
>>>> should be fine to write over the original because there
>>>> is no way the caller can detect that shortcut.  E.g., in
>>>>      cx<- cos(runif(n))
>>>> the cos function does not need to allocate new space for
>>>> its output, it can just write over its input because, without
>>>> a name attached to it, the caller has no way of looking
>>>> at what runif(n) returned.  If you did
>>>>      x<- runif(n)
>>>>      cx<- cos(x)
>>>> then cos would have to allocate new space for its output
>>>> because overwriting its input would affect a subsequent
>>>>      sum(x)
>>>> I suppose that end-users and function-writers could learn
>>>> to live with having to decide when to copy, but not having
>>>> to make that decision makes S more pleasant (and safer) to use.
>>>> I think that is a major reason that people are able to
>>>> share S code so easily.
>>>>
>>>> Bill Dunlap
>>>> Spotfire, TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>> -----Original Message-----
>>>>> From: oliver [mailto:oliver at first.in-berlin.de]
>>>>> Sent: Tuesday, March 06, 2012 1:12 AM
>>>>> To: William Dunlap
>>>>> Cc: Herv? Pag?s; R-devel
>>>>> Subject: Re: [Rd] Julia
>>>>>
>>>>> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
>>>>> [...]
>>>>>> I find R's (&   S+'s&   S's) copy-on-write-if-not-copying-would-be-discoverable-
>>>>>> by-the-uer machanism for giving the allusion of pass-by-value a good way
>>>>>> to structure the contract between the function writer and the function user.
>>>>> [...]
>>>>>
>>>>>
>>>>> Can you elaborate more on this,
>>>>> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
>>>>> stuff?
>>>>>
>>>>> What do you mean with discoverability of not-copying?
>>>>>
>>>>> Ciao,
>>>>>     Oliver
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Thu Mar 22 02:45:04 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Mar 2012 21:45:04 -0400
Subject: [Rd] R's copying of arguments (Re:  Julia)
In-Reply-To: <4F6A80E0.1050108@fhcrc.org>
References: <CAO7JsnRykFo22Jc+pTGsZhg9EvFE=zxE3XpVvSnzc-=mp=AfKw@mail.gmail.com>
	<20120303011413.GA18995@siouxsie>
	<E66794E69CFDE04D9A70842786030B93282DF1@PA-MBX04.na.tibco.com>
	<20120305170835.GA4134@siouxsie> <4F555343.8020007@fhcrc.org>
	<E66794E69CFDE04D9A70842786030B932831A9@PA-MBX04.na.tibco.com>
	<20120306091143.GC1849@siouxsie>
	<E66794E69CFDE04D9A70842786030B932834C7@PA-MBX04.na.tibco.com>
	<20120317153522.GA4502@siouxsie> <4F68D59C.5060605@fhcrc.org>
	<19B0A4DB-5133-41CE-9C74-1F4A11FACDED@r-project.org>
	<4F6A80E0.1050108@fhcrc.org>
Message-ID: <AB0BCF48-2D2A-4A63-9203-7FBE1F4637CC@r-project.org>


On Mar 21, 2012, at 9:31 PM, Herv? Pag?s wrote:

> On 03/21/2012 06:23 PM, Simon Urbanek wrote:
>> 
>> On Mar 20, 2012, at 3:08 PM, Herv? Pag?s wrote:
>> 
>>> Hi Oliver,
>>> 
>>> On 03/17/2012 08:35 AM, oliver wrote:
>>>> Hello,
>>>> 
>>>> regarding the copying issue,
>>>> I would like to point to the
>>>> 
>>>> "Writing R-Extensions" documentation.
>>>> 
>>>> There it is mentio9ned, that functions of extensions
>>>> that use the .C interface normally do get their arguments
>>>> pre-copied...
>>>> 
>>>> 
>>>> In section 5.2:
>>>> 
>>>>   "There can be up to 65 further arguments giving R objects to be
>>>>   passed to compiled code. Normally these are copied before being
>>>>   passed in, and copied again to an R list object when the compiled
>>>>   code returns."
>>>> 
>>>> But for the .Call and .Extension interfaces this is NOT the case.
>>>> 
>>>> 
>>>> 
>>>> In section 5.9:
>>>>   "The .Call and .External interfaces allow much more control, but
>>>>   they also impose much greater responsibilities so need to be used
>>>>   with care. Neither .Call nor .External copy their arguments. You
>>>>   should treat arguments you receive through these interfaces as
>>>>   read-only."
>>>> 
>>>> 
>>>> Why is read-only preferred?
>>>> 
>>>> Please, see the discussion in section 5.9.10.
>>>> 
>>>> It's mentioned there, that a copy of an object in the R-language
>>>> not necessarily doies a real copy of that object, but instead of
>>>> this, just a "rerference" to the real data is created (two names
>>>> referring to one bulk of data). That's typical functional
>>>> programming: not a variable, but a name (and possibly more than one
>>>> name) bound to an object.
>>>> 
>>>> 
>>>> Of course, if yo change the orgiginal named value, when there
>>>> would be no copy of it, before changing it, then both names
>>>> would refer to the changed data.
>>>> of course that is not, what is wanted.
>>>> 
>>>> But what you also can see in section 5.9.10 is, that
>>>> there already is a mechanism (reference counting) that allows
>>>> to distinguish between unnamed and named object.
>>>> 
>>>> So, this is directly adressing the points you have mentioned in your
>>>> examples.
>>>> 
>>>> So, at least in principial, R allows to do in-place modifications
>>>> of object with the .Call interface.
>>>> 
>>>> You seem to refer to the .C interface, and I had explored the .Call
>>>> interface. That's the reason why you may insist on "it's copyied
>>>> always" and I wondered, what you were talking about, because the
>>>> .Call interface allowed me rather C-like raw style of programming
>>>> (and the user of it to decide, if copying will be done or not).
>>>> 
>>>> The mechanism to descide, if copying should be done or not,
>>>> also is mentioined in section 5.9.10: NAMED and SET_NAMED macros.
>>>> with NAMED you can get the number of references.
>>>> 
>>>> But later in that section it is mentioned, that - at least for now -
>>>> NAMED always returns the value 2.
>>>> 
>>>> 
>>>>   "Currently all arguments to a .Call call will have NAMED set to 2,
>>>>   and so users must assume that they need to be duplicated before
>>>>   alteration."
>>>>                (section 5.9.10, last sentence)
>>>> 
>>>> 
>>>> So, the in-place modification can be done already with the .Call
>>>> intefcae for example. But the decision if it is safe or not
>>>> is not supported at the moment.
>>>> 
>>>> So the situation is somewhere between: "it is possible" and
>>>> "R does not support a safe decision if, what is possible, also
>>>> can be recommended".
>>>> At the moment R rather deprecates in-place modification by default
>>>> (the save way, and I agree with this default).
>>>> 
>>>> But it's not true, that R in general copies arguments.
>>>> 
>>>> But this seems to be true for the .C interface.
>>>> 
>>>> Maybe a lot of performance-/memory-problems can be solved
>>>> by rewriting already existing packages, by providing them
>>>> via .Call instead of .C.
>>> 
>>> My understanding is that most packages use the .C interface
>>> because it's simpler to deal with and because they don't need
>>> to pass complicated objects at the C level, just atomic vectors.
>>> My guess is that it's probably rarely the case that the cost
>>> of copying the arguments passed to .C is significant, but,
>>> if that was the case, then they could always call .C() with
>>> DUP=FALSE. However, using DUP=FALSE is dangerous (see Warning
>>> section in the man page).
>>> 
>>> No need to switch to .Call
>>> 
>> 
>> I strongly disagree. I'm appalled to see that sentence here.
> 
> Come on!
> 
>> The overhead is significant for any large vector and it is in particular unnecessary since in .C you have to allocate *and copy* space even for results (twice!). Also it is very error-prone, because you have no information about the length of vectors so it's easy to run out of bounds and there is no way to check. IMHO .C should not be used for any code written in this century (the only exception may be if you are passing no data, e.g. if all you do is to pass a flag and expect no result, you can get away with it even if it is more dangerous). It is a legacy interface that dates way back and is essentially just re-named .Fortran interface. Again, I would strongly recommend the use of .Call in any recent code because it is safer and more efficient (if you don't care about either attribute, well, feel free ;)).
> 
> So aleph will not support the .C interface? ;-)
> 

It will look at the timestamp of the source file and delete the package if it is not before 1980 ;). Otherwise it will send a request for punch cards with ".C is deprecated, please upgrade to .Call" stamped out :P At that point I'll be flaming about using the native Aleph interface and not the R compatibility layer ;)

Cheers,
S



> H.
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> 
>> 
>> 
>>> Cheers,
>>> H.
>>> 
>>>> 
>>>> 
>>>> Ciao,
>>>>    Oliver
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On Tue, Mar 06, 2012 at 04:44:49PM +0000, William Dunlap wrote:
>>>>> S (and its derivatives and successors) promises that functions
>>>>> will not change their arguments, so in an expression like
>>>>>    val<- func(arg)
>>>>> you know that arg will not be changed.  You can
>>>>> do that by having func copy arg before doing anything,
>>>>> but that uses space and time that you want to conserve.
>>>>> If arg is not a named item in any environment then it
>>>>> should be fine to write over the original because there
>>>>> is no way the caller can detect that shortcut.  E.g., in
>>>>>     cx<- cos(runif(n))
>>>>> the cos function does not need to allocate new space for
>>>>> its output, it can just write over its input because, without
>>>>> a name attached to it, the caller has no way of looking
>>>>> at what runif(n) returned.  If you did
>>>>>     x<- runif(n)
>>>>>     cx<- cos(x)
>>>>> then cos would have to allocate new space for its output
>>>>> because overwriting its input would affect a subsequent
>>>>>     sum(x)
>>>>> I suppose that end-users and function-writers could learn
>>>>> to live with having to decide when to copy, but not having
>>>>> to make that decision makes S more pleasant (and safer) to use.
>>>>> I think that is a major reason that people are able to
>>>>> share S code so easily.
>>>>> 
>>>>> Bill Dunlap
>>>>> Spotfire, TIBCO Software
>>>>> wdunlap tibco.com
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: oliver [mailto:oliver at first.in-berlin.de]
>>>>>> Sent: Tuesday, March 06, 2012 1:12 AM
>>>>>> To: William Dunlap
>>>>>> Cc: Herv? Pag?s; R-devel
>>>>>> Subject: Re: [Rd] Julia
>>>>>> 
>>>>>> On Tue, Mar 06, 2012 at 12:35:32AM +0000, William Dunlap wrote:
>>>>>> [...]
>>>>>>> I find R's (&   S+'s&   S's) copy-on-write-if-not-copying-would-be-discoverable-
>>>>>>> by-the-uer machanism for giving the allusion of pass-by-value a good way
>>>>>>> to structure the contract between the function writer and the function user.
>>>>>> [...]
>>>>>> 
>>>>>> 
>>>>>> Can you elaborate more on this,
>>>>>> especially on the ...-...-...-if-not-copying-would-be-discoverable-by-the-uer
>>>>>> stuff?
>>>>>> 
>>>>>> What do you mean with discoverability of not-copying?
>>>>>> 
>>>>>> Ciao,
>>>>>>    Oliver
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>>> --
>>> Herv? Pag?s
>>> 
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>> 
>>> E-mail: hpages at fhcrc.org
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> 


From htl10 at users.sourceforge.net  Thu Mar 22 04:14:41 2012
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 22 Mar 2012 03:14:41 +0000
Subject: [Rd] Thai vignette, cross-compile for Mac OS X,
 universal/multiarch (Fwd: Mac OS X builds of CelQuantileNorm,
 vcftools/samtools/tabix, and snpStats)
In-Reply-To: <1331693982.63234.YahooMailClassic@web29401.mail.ird.yahoo.com>
References: <1331693982.63234.YahooMailClassic@web29401.mail.ird.yahoo.com>
Message-ID: <4F6A9921.2050702@users.sourceforge.net>

FYI.

There is a Thai vignette - and it went a lot further doing some Thai text 
processing in R, than the earlier Chinese/Tibetan/LiangshanYi/Arabic vignette, 
which was in reality just Chinese + Cairo graphics.

Managed to cross-compile an R package for Mac OS X from Linux; and it seems to 
be working. See screenshots below. I'd be interested to know if there are less 
obvious bugs; however numerical difference with native snpStats 1.5.5 is more 
likely because 1.5.5 is buggy than 1.5.5.1 mis-compiled.

Also noticed that R on Mac OS X is universal, with symlinks to the per-arch 
multiarch dylibs. Is there any plans for R packages to switch over to universal 
instead of multi-arch?
(the sentence below as strictly speaking wrong - the R package was 
cross-compiled to multi-arch rather than universal).

FYI a few other not-so-relevant things but may be useful to some.

-------- Original Message --------
Subject: Mac OS X builds of CelQuantileNorm, vcftools/samtools/tabix, and snpStats
Date: Wed, 14 Mar 2012 02:59:42 +0000 (GMT)
From: Hin-Tak Leung <htl10 at users.sourceforge.net>
Reply-To: htl10 at users.sourceforge.net
To: bonsai list <outmodedbonsai-announce at lists.sourceforge.net>

CelQantileNorm, vcftools/samtools/tabix are bult for Mac OS X. These are 
universal binaries and work for all recent variants of Powerpc-, Intel 
32-bit/64-bit Macs.

snpStats 1.5.5 (out a week ago) turned out to be "differently buggy" from 
previous, so there are windows and Mac OS X build of 1.5.5.1 . The Mac OS X 
build is also Universal and was tested for both intel 32-bit/64-bit macs. See also
http://outmodedbonsai.sourceforge.net/InstallingLocalRPackages.html
for a few brief instructions and screenshots for installing R packages from 
downloads.

Here is the new Mac OS X area:
http://sourceforge.net/projects/outmodedbonsai/files/Packages%20for%20Mac%20OS%20X/


-------- Original Message --------
Subject: Two new vignettes, and a bunch of updates here and elsewhere
Date: Tue, 06 Mar 2012 06:39:38 +0000
From: Hin-Tak Leung <htl10 at users.sourceforge.net>
To: outmodedbonsai-announce at lists.sourceforge.net

There is a new vignette, "Algorithms and Thailand", which covers
text/stream/sequence and spatial algorithms, and the use of Thai language in a
vignette.
(Chinese/Tibetan/Arabic/Liangshan Yi was covered in a different vignette
previously).
More on this and emacs's multilingual extension further down.

"snpMatrix Tutorial 2007" was the first ever tutorial written in spring 2007
[1]; it was pre-vignette and therefore had all the hapmap/pedfile output
recorded verbatim; newly revived to work as a testsuite for input/output of
hapmap/ped files (and flaged and fixed a few bugs introduced in the last few
years). The bug fixes will appear in the upcoming snpMatrix 1.19.0.12, which
hopefully will include some continual work to add read.tped() and read.vcf().

The usual suspects:

- new linux and win32 mono 2.10.8.1 builds with the large heap patch;

- "less buggy" snpStats 1.4.1.1, 1.5.2.1, 1.5.4.1 ;

- snpMatrix124 1.2.4.6, fixes a small bug;

- new BeanSprout manual which have a bit more information about various Genome
Studio versions;

- new linux native and non-native build of the whole BeanSprout family against
Genome Studio 2011.1 (they were supposed to happen when I release the android
port, but then I forgot).

There are the 2nd monthly snapshots of win32 and android builds of vcftools,
tabix, samtools. I'd probably continue on a semi-regular monthly basis until
after snpMatrix 1.19.0.12 before I tidy up the adaptations and send upstream.

Besides the two 2.10.8.1 builds, there is a mono 2.11pre snapshot, (mono
2.11pre-push-1480-g0ed3827.x86_64.fc16.tbz2) to address a bug [2].

Lastly, while writing Thai vignette, I fixed a problem which was filed against
emacs [3] ; My notes on 'Typesetting Thai', the emacs lisp script which fixed
that problem and other enhancements mentioned in the notes, a snapshot of
CJK/LaTeX with those enhancements, and perl/python script for unpacking zip
files generated on Chinese windows onto linux/mac's correctly, are housed
elsewhere [4]. While these have nothing to do with science, people processing
non-english data (and specifically Chinese data) may find them useful.

Unless otherwise stated, all of these are somewhere under:
http://sourceforge.net/projects/outmodedbonsai/files/

[1] The original is in the 'historical' section and the updated in 'next/1.19.0.12'.

[2] https://bugzilla.novell.com/show_bug.cgi?id=720031

[3] http://debbugs.gnu.org/cgi/bugreport.cgi?bug=8108

[4] http://htl10.users.sourceforge.net/Languages/


From spencer.graves at prodsyse.com  Thu Mar 22 06:14:43 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 21 Mar 2012 22:14:43 -0700
Subject: [Rd] R 2.14.1 memory management under Windows
Message-ID: <4F6AB543.10603@prodsyse.com>

I computed "system.time(diag(30000))" with R 2.12.0 on Fedora 13 Linux 
with 4 GB RAM and with R 2.14.1 on Windows 7 with 8 GB RAM:


Linux (4 GB RAM):  0, 0.21, 0.21 -- a fifth of a second


Windows 7 (8 GB RAM):  11.37 7.47 93.19 -- over 1.5 minutes.  Moreover, 
during most of that time, I could not switch windows or get any response 
from the system.  When I first encountered this, I thought Windows was 
hung permanently and the only way out was a hard reset and reboot.


       On both systems, diag(30000) generated, "Error:  cannot allocate 
vector of size ___ Gb", with "___" = 3.4 for Linux with 4 GB RAM and 6.7 
for Windows with 8 GB RAM.  Linux with half the RAM and an older version 
of R was done with this in 0.21 seconds.  Windows 7 went into suspension 
for over 93 seconds -- 1.5 minutes before giving an error message.


        I don't know how easy this would be to fix under Windows, but I 
felt a need to report it.


       Best Wishes,
       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From jwiley.psych at gmail.com  Thu Mar 22 07:07:09 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 21 Mar 2012 23:07:09 -0700
Subject: [Rd] R 2.14.1 memory management under Windows
In-Reply-To: <4F6AB543.10603@prodsyse.com>
References: <4F6AB543.10603@prodsyse.com>
Message-ID: <CANz9Z_KaDARts0gB5AEwjHVE3oSVMLSpLuDeXzgWJy0UHYy7Bg@mail.gmail.com>

On Wed, Mar 21, 2012 at 10:14 PM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> I computed "system.time(diag(30000))" with R 2.12.0 on Fedora 13 Linux with
> 4 GB RAM and with R 2.14.1 on Windows 7 with 8 GB RAM:
>
>
> Linux (4 GB RAM): ?0, 0.21, 0.21 -- a fifth of a second
>
>
> Windows 7 (8 GB RAM): ?11.37 7.47 93.19 -- over 1.5 minutes. ?Moreover,
> during most of that time, I could not switch windows or get any response
> from the system. ?When I first encountered this, I thought Windows was hung
> permanently and the only way out was a hard reset and reboot.
>
>
> ? ? ?On both systems, diag(30000) generated, "Error: ?cannot allocate vector
> of size ___ Gb", with "___" = 3.4 for Linux with 4 GB RAM and 6.7 for
> Windows with 8 GB RAM. ?Linux with half the RAM and an older version of R
> was done with this in 0.21 seconds. ?Windows 7 went into suspension for over
> 93 seconds -- 1.5 minutes before giving an error message.
>
>
> ? ? ? I don't know how easy this would be to fix under Windows, but I felt a
> need to report it.

This seems like it may be an issue with paging, which Windows has
traditionally not excelled at.  That said, on Windows 7 x64 with 6GB
RAM and another 6GB paging file with R version 2.14.1 (2011-12-22), I
get:

> system.time(diag(30000))
Error: cannot allocate vector of size 3.4 Gb
Timing stopped at: 0.01 0 0.01


Cheers,

Josh

so the timing is comparable to nix.
>
>
> ? ? ?Best Wishes,
> ? ? ?Spencer
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph: ?408-655-4567
> web: ?www.structuremonitoring.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From peter.meilstrup at gmail.com  Thu Mar 22 07:11:37 2012
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Wed, 21 Mar 2012 23:11:37 -0700
Subject: [Rd] R 2.14.1 memory management under Windows
In-Reply-To: <4F6AB543.10603@prodsyse.com>
References: <4F6AB543.10603@prodsyse.com>
Message-ID: <CAJoaRhZEXpizR7GZKvGE8MU-=AMMkBbr4sAaC7Gppi9nZ3kUAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120321/f77743da/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Mar 22 13:02:08 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Mar 2012 12:02:08 +0000
Subject: [Rd] R 2.14.1 memory management under Windows
In-Reply-To: <CAJoaRhZEXpizR7GZKvGE8MU-=AMMkBbr4sAaC7Gppi9nZ3kUAw@mail.gmail.com>
References: <4F6AB543.10603@prodsyse.com>
	<CAJoaRhZEXpizR7GZKvGE8MU-=AMMkBbr4sAaC7Gppi9nZ3kUAw@mail.gmail.com>
Message-ID: <4F6B14C0.2070108@stats.ox.ac.uk>

On 22/03/2012 06:11, Peter Meilstrup wrote:
> My guess would be that it's a matter of having swap space be a dedicated
> partition or fixed-size file (Linux, usually) versus swapping to a regular
> file that grows as needed (Windows and OS X, usually.) So if you
> defragmented your drive and set Windows to have a fixedsize swap file, it
> would probably behave more like your Linux machine.

There is far more to the topic than that, but the answer here appears to 
be a complete failure to supply the relevant information.

We haven't even been told the 'at a minumum' information required by the 
posting guide, so we do not know what architectures are in use.  The 
messages suggest that 'Linux' is 32-bit and 'Windows' is 64-bit, in 
which case the tasks are simply not comparable.  On 32-bit R on Windows 
I got the message about 3.4GB after 0.05 sec.  Conversely, with 64-bit R 
on an 8GB Linux box with 16GB swap it swapped away for about 10 minutes. 
  On a 32GB box it succeeded after 270s, typically using 8-14GB.  The 
object SG tried to create is a bit over 7GB.

But Windows' memory management is notoriously slow, and R actually adds 
a layer on top to make it tolerable for routine use of R.

I have no idea why this was posted on R-devel: it did not involve R 
development nor programming, just a basic understanding of 32- vs 64-bit R.

>
> Peter
>
> On Wed, Mar 21, 2012 at 10:14 PM, Spencer Graves<
> spencer.graves at prodsyse.com>  wrote:
>
>> I computed "system.time(diag(30000))" with R 2.12.0 on Fedora 13 Linux
>> with 4 GB RAM and with R 2.14.1 on Windows 7 with 8 GB RAM:
>>
>>
>> Linux (4 GB RAM):  0, 0.21, 0.21 -- a fifth of a second
>>
>>
>> Windows 7 (8 GB RAM):  11.37 7.47 93.19 -- over 1.5 minutes.  Moreover,
>> during most of that time, I could not switch windows or get any response
>> from the system.  When I first encountered this, I thought Windows was hung
>> permanently and the only way out was a hard reset and reboot.
>>
>>
>>       On both systems, diag(30000) generated, "Error:  cannot allocate
>> vector of size ___ Gb", with "___" = 3.4 for Linux with 4 GB RAM and 6.7
>> for Windows with 8 GB RAM.  Linux with half the RAM and an older version of
>> R was done with this in 0.21 seconds.  Windows 7 went into suspension for
>> over 93 seconds -- 1.5 minutes before giving an error message.
>>
>>
>>        I don't know how easy this would be to fix under Windows, but I felt
>> a need to report it.
>>
>>
>>       Best Wishes,
>>       Spencer
>>
>>
>> --
>> Spencer Graves, PE, PhD
>> President and Chief Technology Officer
>> Structure Inspection and Monitoring, Inc.
>> 751 Emerson Ct.
>> San Jos?, CA 95126
>> ph:  408-655-4567
>> web:  www.structuremonitoring.com
>>
>> ______________________________**________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From friendly at yorku.ca  Thu Mar 22 13:43:09 2012
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 22 Mar 2012 08:43:09 -0400
Subject: [Rd] uncompressed saves warning
In-Reply-To: <4F6A0E64.5010603@statistik.tu-dortmund.de>
References: <4F69DE6A.90701@yorku.ca>
	<4F6A0E64.5010603@statistik.tu-dortmund.de>
Message-ID: <4F6B1E5D.20305@yorku.ca>

On 3/21/2012 1:22 PM, Uwe Ligges wrote:
>> What is the equivalent R command to compress these files in my project
>> tree?
>>
>
> Michael,
>
> if you use
> R CMD build --resave-data
> to build the tar archive, the versions therein are recompressed.
But AFAIK, in StatET, R CMD build  builds a separate .tar.gz file under 
c:/eclipse, and does not affect
the project directory where these files are stored and sync'd with R-Forge.
>
> Otherwise, you can also open the files and resave them via save() and 
> appropriate arguments.
I exported the .rda files to c:/R/data and ran

 > load("gfrance.rda")
 > load("gfrance85.rda")
 > save(gfrance, file="gfrance.RData", compress="xz")
Error in xzfile(file, "wb", compression = 9) : cannot open the connection
In addition: Warning message:
In xzfile(file, "wb", compression = 9) :
   cannot initialize lzma encoder, error 5

Why doesn't this work?

 > save(gfrance, file="gfrance.RData", compress=TRUE)

The above works, but only compresses a 300K file to 299K
>
> Or use  resaveRdaFiles() in package tools to runn it on a whole folder 
> automatically.
>

 > sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United 
States.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  
methods   base

other attached packages:
[1] p3d_0.02-4       mgcv_1.7-13      car_2.0-12       nnet_7.3-1       
rgl_0.92.798     vcd_1.2-13       colorspace_1.1-1 MASS_7.3-17

loaded via a namespace (and not attached):
[1] lattice_0.20-6 Matrix_1.0-4   nlme_3.1-103   tools_2.14.1
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From spencer.graves at prodsyse.com  Thu Mar 22 13:56:56 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 22 Mar 2012 05:56:56 -0700
Subject: [Rd] R 2.14.1 memory management under Windows
In-Reply-To: <4F6B14C0.2070108@stats.ox.ac.uk>
References: <4F6AB543.10603@prodsyse.com>
	<CAJoaRhZEXpizR7GZKvGE8MU-=AMMkBbr4sAaC7Gppi9nZ3kUAw@mail.gmail.com>
	<4F6B14C0.2070108@stats.ox.ac.uk>
Message-ID: <4F6B2198.7030605@prodsyse.com>

Thanks for the replies and please excuse my failure to provide 
sessionInfo():


WINDOWS 7 WITH 8 GB RAM:


 > sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] fda_2.2.8 zoo_1.7-7

loaded via a namespace (and not attached):
[1] grid_2.14.1    lattice_0.20-0


FEDORA 13 LINUX WITH 4 GB RAM (copied manually, thereby increasing the 
risks of copying errors):


 > sessionInfo()
R version 2.12.0 (2010-10-15)
Platform:  i386-redhat-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US.utf8        LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=C            LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8    LC_NAME=C
  [9] LC_ADDRESS=C            LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8    LC_IDENTIFICATION=C

attached base packages:
[1] splines  stats  graphics  grDevices  utils  datgasets  methods
[8] base

other attached packages:
[1] fda_2.2.6  zoo_1.6-5

loaded via a namespace (and not attached):
[1] grid_2.12.0  lattice_0.19-30


       Thanks again,
       Spencer


On 3/22/2012 5:02 AM, Prof Brian Ripley wrote:
> On 22/03/2012 06:11, Peter Meilstrup wrote:
>> My guess would be that it's a matter of having swap space be a dedicated
>> partition or fixed-size file (Linux, usually) versus swapping to a 
>> regular
>> file that grows as needed (Windows and OS X, usually.) So if you
>> defragmented your drive and set Windows to have a fixedsize swap 
>> file, it
>> would probably behave more like your Linux machine.
>
> There is far more to the topic than that, but the answer here appears 
> to be a complete failure to supply the relevant information.
>
> We haven't even been told the 'at a minumum' information required by 
> the posting guide, so we do not know what architectures are in use.  
> The messages suggest that 'Linux' is 32-bit and 'Windows' is 64-bit, 
> in which case the tasks are simply not comparable.  On 32-bit R on 
> Windows I got the message about 3.4GB after 0.05 sec.  Conversely, 
> with 64-bit R on an 8GB Linux box with 16GB swap it swapped away for 
> about 10 minutes.  On a 32GB box it succeeded after 270s, typically 
> using 8-14GB.  The object SG tried to create is a bit over 7GB.
>
> But Windows' memory management is notoriously slow, and R actually 
> adds a layer on top to make it tolerable for routine use of R.
>
> I have no idea why this was posted on R-devel: it did not involve R 
> development nor programming, just a basic understanding of 32- vs 
> 64-bit R.
>
>>
>> Peter
>>
>> On Wed, Mar 21, 2012 at 10:14 PM, Spencer Graves<
>> spencer.graves at prodsyse.com>  wrote:
>>
>>> I computed "system.time(diag(30000))" with R 2.12.0 on Fedora 13 Linux
>>> with 4 GB RAM and with R 2.14.1 on Windows 7 with 8 GB RAM:
>>>
>>>
>>> Linux (4 GB RAM):  0, 0.21, 0.21 -- a fifth of a second
>>>
>>>
>>> Windows 7 (8 GB RAM):  11.37 7.47 93.19 -- over 1.5 minutes.  Moreover,
>>> during most of that time, I could not switch windows or get any 
>>> response
>>> from the system.  When I first encountered this, I thought Windows 
>>> was hung
>>> permanently and the only way out was a hard reset and reboot.
>>>
>>>
>>>       On both systems, diag(30000) generated, "Error:  cannot allocate
>>> vector of size ___ Gb", with "___" = 3.4 for Linux with 4 GB RAM and 
>>> 6.7
>>> for Windows with 8 GB RAM.  Linux with half the RAM and an older 
>>> version of
>>> R was done with this in 0.21 seconds.  Windows 7 went into 
>>> suspension for
>>> over 93 seconds -- 1.5 minutes before giving an error message.
>>>
>>>
>>>        I don't know how easy this would be to fix under Windows, but 
>>> I felt
>>> a need to report it.
>>>
>>>
>>>       Best Wishes,
>>>       Spencer
>>>
>>>
>>> -- 
>>> Spencer Graves, PE, PhD
>>> President and Chief Technology Officer
>>> Structure Inspection and Monitoring, Inc.
>>> 751 Emerson Ct.
>>> San Jos?, CA 95126
>>> ph:  408-655-4567
>>> web:  www.structuremonitoring.com
>>>
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel> 
>>>
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From therneau at mayo.edu  Thu Mar 22 14:45:13 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 22 Mar 2012 08:45:13 -0500
Subject: [Rd] R-devel Digest, Vol 109, Issue 22
In-Reply-To: <mailman.29.1332414009.26932.r-devel@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
Message-ID: <4F6B2CE9.2090600@mayo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120322/5231db82/attachment.pl>

From simon.urbanek at r-project.org  Thu Mar 22 15:38:55 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 22 Mar 2012 10:38:55 -0400
Subject: [Rd] R-devel Digest, Vol 109, Issue 22
In-Reply-To: <4F6B2CE9.2090600@mayo.edu>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
Message-ID: <2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120322/8b88d372/attachment.pl>

From rdiaz02 at gmail.com  Thu Mar 22 16:15:32 2012
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Thu, 22 Mar 2012 16:15:32 +0100
Subject: [Rd] .Call ref card [was Re:  R-devel Digest, Vol 109, Issue 22]
In-Reply-To: <2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
Message-ID: <87obror7jf.wl%rdiaz02@gmail.com>




On Thu, 22 Mar 2012 10:38:55 -0400,Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Mar 22, 2012, at 9:45 AM, Terry Therneau <therneau at mayo.edu> wrote:

> > 
> >> 
> >>> 
> >>>>  strongly disagree. I'm appalled to see that sentence here.
> >>> > 
> >>> > Come on!
> >>> > 
> >>>> >> The overhead is significant for any large vector and it is in particular unnecessary since in .C you have to allocate *and copy* space even for results (twice!). Also it is very error-prone, because you have no information about the length of vectors so it's easy to run out of bounds and there is no way to check. IMHO .C should not be used for any code written in this century (the only exception may be if you are passing no data, e.g. if all you do is to pass a flag and expect no result, you can get away with it even if it is more dangerous). It is a legacy interface that dates way back and is essentially just re-named .Fortran interface. Again, I would strongly recommend the use of .Call in any recent code because it is safer and more efficient (if you don't care about either attribute, well, feel free ;)).
> >>> > 
> >>> > So aleph will not support the .C interface? ;-)
> >>> > 
> >> It will look at the timestamp of the source file and delete the package if it is not before 1980 ;). Otherwise it will send a request for punch cards with ".C is deprecated, please upgrade to .Call" stamped out :P At that point I'll be flaming about using the native Aleph interface and not the R compatibility layer ;)
> >> 
> >> Cheers,
> >> S
> > I'll dissent -- I don't think .C is inherently any more dangerous than .Call and prefer it's simplicity in many cases.  Calling C at all is what is inherently dangerous -- I can reference beyond the end of a vector, write over objects that should be read only, and branch to random places using either interface. 

> You can always do so deliberately, but with .C you have no way of preventing it since you don't even know what is the length! That is certainly far more dangerous than .Call where you can simply loop over the length, check that the lengths are compatible etc. Also for types like strings .C is a minefield that is hard to not blow up whereas .Call it is even more safe than scalar arrays. You can do none of that with .C which relies entirely on conventions with no recorded semantics.


> > If you are dealing with large objects and worry about memory efficiency then .Call puts more tools at your disposal and is worth the effort.  However, I did not find the .Call interface at all easy to use at first

> I guess this depends on the developer and is certainly a
> factor. Personally, I find the subset of the R API needed for .Call
> fairly small and intuitive (in particular when you are just writing a
> safer replacement for .C), but I'm obviously biased. Maybe in a separate
> thread we could discuss this - I'd be happy to write a ref card or cheat
> sheet if I find out what people find challenging on .Call. Nonetheless,
> my point is that it is more than worth investing the effort both in
> safety and performance.


After your previous email I made a mental note "try to finally learn to
use .Call since I often deal with large objects". So, yes, I'd love to see
a ref card and cheat sheet: I have tried learning to use .Call a few
times, but have always gone back to .C since (it seems that) all I needed
to know are just a couple of conventions, and the rest is "C as usual".



You say "if I find out what people find challenging on
.Call". Hummm... can I answer "basically everything"?  I think Terry
Thereneau says, "the things I needed to know are scattered about in
multiple places". When I see the convolve example (5.2 in Writing R
extensions) I understand the C code; when I see the convolve2 example in
5.10.1 I think I can guess what lines "PROTECT(a ..." to "xab =
NUMERIC_POINTER ..."  might be doing, but I would not know how to do that
on my own. Yes, I can go to 5.9.1 to read about PROTECT, then search for
... But, at that point, I've gone back to .C. Of course, this might just
be my laziness/incompetence/whatever.

 

Best,


R.









> > and we should keep that in mind before getting too pompous in our lectures to the "sinners of .C".  (Mostly because the things I needed to know are scattered about in multiple places.)
> > 
> > I might have to ask for an exemption on that timestamp -- the first bits of the survival package only reach back to 1986.  And I've had to change source code systems multiple times which plays hob with the file times, though I did try to preserve the changelog history to forstall some future litigious soul who claims they wrote it first  (sccs -> rcs -> cvs -> svn -> mercurial).   :-)
> > 

> ;) Maybe the rule should be based on the date of the first appearance of the package, fair enough :)

> Cheers,
> Simon
> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina 
Universidad Aut?noma de Madrid 
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From pdalgd at gmail.com  Thu Mar 22 17:03:51 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 22 Mar 2012 17:03:51 +0100
Subject: [Rd] .Call ref card [was Re:  R-devel Digest, Vol 109, Issue 22]
In-Reply-To: <87obror7jf.wl%rdiaz02@gmail.com>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
Message-ID: <928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>

Don't know how useful it is any more, but back in the days, I gave this talk in Vienna

http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Dalgaard.pdf

Looking at it now, perhaps it moves a little too quickly into the hairy stuff. On the other hand, those were the things that I had found important to figure out at the time. At a quick glance, I didn't spot anything obviously outdated. 


On Mar 22, 2012, at 16:15 , Ramon Diaz-Uriarte wrote:

> 
> 
> 
> On Thu, 22 Mar 2012 10:38:55 -0400,Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> On Mar 22, 2012, at 9:45 AM, Terry Therneau <therneau at mayo.edu> wrote:
> 
>>> 
>>>> 
>>>>> 
>>>>>> strongly disagree. I'm appalled to see that sentence here.
>>>>>> 
>>>>>> Come on!
>>>>>> 
>>>>>>>> The overhead is significant for any large vector and it is in particular unnecessary since in .C you have to allocate *and copy* space even for results (twice!). Also it is very error-prone, because you have no information about the length of vectors so it's easy to run out of bounds and there is no way to check. IMHO .C should not be used for any code written in this century (the only exception may be if you are passing no data, e.g. if all you do is to pass a flag and expect no result, you can get away with it even if it is more dangerous). It is a legacy interface that dates way back and is essentially just re-named .Fortran interface. Again, I would strongly recommend the use of .Call in any recent code because it is safer and more efficient (if you don't care about either attribute, well, feel free ;)).
>>>>>> 
>>>>>> So aleph will not support the .C interface? ;-)
>>>>>> 
>>>> It will look at the timestamp of the source file and delete the package if it is not before 1980 ;). Otherwise it will send a request for punch cards with ".C is deprecated, please upgrade to .Call" stamped out :P At that point I'll be flaming about using the native Aleph interface and not the R compatibility layer ;)
>>>> 
>>>> Cheers,
>>>> S
>>> I'll dissent -- I don't think .C is inherently any more dangerous than .Call and prefer it's simplicity in many cases.  Calling C at all is what is inherently dangerous -- I can reference beyond the end of a vector, write over objects that should be read only, and branch to random places using either interface. 
> 
>> You can always do so deliberately, but with .C you have no way of preventing it since you don't even know what is the length! That is certainly far more dangerous than .Call where you can simply loop over the length, check that the lengths are compatible etc. Also for types like strings .C is a minefield that is hard to not blow up whereas .Call it is even more safe than scalar arrays. You can do none of that with .C which relies entirely on conventions with no recorded semantics.
> 
> 
>>> If you are dealing with large objects and worry about memory efficiency then .Call puts more tools at your disposal and is worth the effort.  However, I did not find the .Call interface at all easy to use at first
> 
>> I guess this depends on the developer and is certainly a
>> factor. Personally, I find the subset of the R API needed for .Call
>> fairly small and intuitive (in particular when you are just writing a
>> safer replacement for .C), but I'm obviously biased. Maybe in a separate
>> thread we could discuss this - I'd be happy to write a ref card or cheat
>> sheet if I find out what people find challenging on .Call. Nonetheless,
>> my point is that it is more than worth investing the effort both in
>> safety and performance.
> 
> 
> After your previous email I made a mental note "try to finally learn to
> use .Call since I often deal with large objects". So, yes, I'd love to see
> a ref card and cheat sheet: I have tried learning to use .Call a few
> times, but have always gone back to .C since (it seems that) all I needed
> to know are just a couple of conventions, and the rest is "C as usual".
> 
> 
> 
> You say "if I find out what people find challenging on
> .Call". Hummm... can I answer "basically everything"?  I think Terry
> Thereneau says, "the things I needed to know are scattered about in
> multiple places". When I see the convolve example (5.2 in Writing R
> extensions) I understand the C code; when I see the convolve2 example in
> 5.10.1 I think I can guess what lines "PROTECT(a ..." to "xab =
> NUMERIC_POINTER ..."  might be doing, but I would not know how to do that
> on my own. Yes, I can go to 5.9.1 to read about PROTECT, then search for
> ... But, at that point, I've gone back to .C. Of course, this might just
> be my laziness/incompetence/whatever.
> 
> 
> 
> Best,
> 
> 
> R.
> 
> 
> 
> 
> 
> 
> 
> 
> 
>>> and we should keep that in mind before getting too pompous in our lectures to the "sinners of .C".  (Mostly because the things I needed to know are scattered about in multiple places.)
>>> 
>>> I might have to ask for an exemption on that timestamp -- the first bits of the survival package only reach back to 1986.  And I've had to change source code systems multiple times which plays hob with the file times, though I did try to preserve the changelog history to forstall some future litigious soul who claims they wrote it first  (sccs -> rcs -> cvs -> svn -> mercurial).   :-)
>>> 
> 
>> ;) Maybe the rule should be based on the date of the first appearance of the package, fair enough :)
> 
>> Cheers,
>> Simon
>> 	[[alternative HTML version deleted]]
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> -- 
> Ramon Diaz-Uriarte
> Department of Biochemistry, Lab B-25
> Facultad de Medicina 
> Universidad Aut?noma de Madrid 
> Arzobispo Morcillo, 4
> 28029 Madrid
> Spain
> 
> Phone: +34-91-497-2412
> 
> Email: rdiaz02 at gmail.com
>       ramon.diaz at iib.uam.es
> 
> http://ligarto.org/rdiaz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Thu Mar 22 18:03:25 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 22 Mar 2012 12:03:25 -0500
Subject: [Rd] R-devel Digest, Vol 109, Issue 22
In-Reply-To: <2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
Message-ID: <4F6B5B5D.7070507@mayo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120322/06065c74/attachment.pl>

From therneau at mayo.edu  Thu Mar 22 18:45:14 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 22 Mar 2012 12:45:14 -0500
Subject: [Rd] .Call ref card
In-Reply-To: <928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
Message-ID: <4F6B652A.6050209@mayo.edu>

On 03/22/2012 11:03 AM, peter dalgaard wrote:
> Don't know how useful it is any more, but back in the days, I gave this talk in Vienna
>
> http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Dalgaard.pdf
>
> Looking at it now, perhaps it moves a little too quickly into the hairy stuff. On the other hand, those were the things that I had found important to figure out at the time. At a quick glance, I didn't spot anything obviously outdated.
>
Peter,
   I just looked at this, and I'd say that moved into the hairy stuff 
way too quickly.  Much of what it covered I would never expect to use.  
Some I ddn't understand.  Part of this of course is that slides for a 
talk are rarely very useful without the talker.

  Something simpler for the layman would be good.

Terry T.


From antonio at piccolboni.info  Thu Mar 22 17:34:00 2012
From: antonio at piccolboni.info (Antonio Piccolboni)
Date: Thu, 22 Mar 2012 09:34:00 -0700
Subject: [Rd] Serializing many small objects efficiently
Message-ID: <CA+VDHFUhC5F5zMcGfeO1x0WRhe9Z5r78bUrGJ_V=W8sMEgYBJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120322/e52c82d4/attachment.pl>

From armstrong.whit at gmail.com  Fri Mar 23 00:56:36 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 22 Mar 2012 19:56:36 -0400
Subject: [Rd] Serializing many small objects efficiently
In-Reply-To: <CA+VDHFUhC5F5zMcGfeO1x0WRhe9Z5r78bUrGJ_V=W8sMEgYBJA@mail.gmail.com>
References: <CA+VDHFUhC5F5zMcGfeO1x0WRhe9Z5r78bUrGJ_V=W8sMEgYBJA@mail.gmail.com>
Message-ID: <CAMi=pg5LFYd6FyCEEvBQ9hBM0Pjpg5hYNhZGBpQ2xFQdibZGSw@mail.gmail.com>

Here's a snip from r-hcp. You can probably find it in the archive:

From: Michael Spiegel
Date: Thu, Sep 29, 2011 at 11:38 AM
Subject: RE: [R-sig-hpc] [zeromq-dev] rzmq package

Calling serialize/serialize from c/c++ is not too convoluted. You can
find a good example in
https://github.com/mspiegel/PiebaldMPI/blob/master/src/lapply_workers_helpers.c,
look for the function "generateReturnList". I'm doing both
serialization and unserialization in that function, but you'll be able
to tease apart the two calls.




On Thu, Mar 22, 2012 at 12:34 PM, Antonio Piccolboni
<antonio at piccolboni.info> wrote:
> Hi,
> sorry if this question is trivial or unclear, this is my first venture into
> mixed C/R programming (I am reasonably experienced in each separately).
> I am trying to write a serialization function for a format called
> typedbytes, which is used as an interchange format in Hadoop circles. Since
> I would need to serialize according to the internal R format many small R
> objects I looked at the c interface
>
> void R_Serialize(SEXP s, R_outpstream_t ops);
> SEXP R_Unserialize(R_inpstream_t ips);
>
> If I look at the source for e.g. unserialize is see a
>
> ?.Call("R_unserialize", connection, refhook, PACKAGE = "base")
>
> which, despite the name of the second argument, accepts as 'connection' a
> raw vector. Is there any way to call that function from C -- without
> calling the R function? Failing that, from what I've read I gather that it
> is not possible to get a C stream from a connection, so unless I am wrong
> using R_serialize directly is not possible. If all else fails I would have
> probably to use a hack requiring knowledge of the serialization format,
> which I'd much rather avoid. Suggestions? Thanks
>
>
> Antonio
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rdiaz02 at gmail.com  Fri Mar 23 11:35:29 2012
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Fri, 23 Mar 2012 11:35:29 +0100
Subject: [Rd] .Call ref card
In-Reply-To: <4F6B652A.6050209@mayo.edu>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu>
Message-ID: <87fwczr4em.wl%rdiaz02@gmail.com>



Peter, thanks for the slides. However, I felt like Terry and I think
because I am missing the "big picture" that I was somewhat surprised by
some of the content and organization (e.g., the detail about character
vectors, the usage of the tcltk package as example code).

Best,

R.


On Thu, 22 Mar 2012 12:45:14 -0500,Terry Therneau <therneau at mayo.edu> wrote:
> On 03/22/2012 11:03 AM, peter dalgaard wrote:
> > Don't know how useful it is any more, but back in the days, I gave this talk in Vienna
> >
> > http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Dalgaard.pdf
> >
> > Looking at it now, perhaps it moves a little too quickly into the hairy stuff. On the other hand, those were the things that I had found important to figure out at the time. At a quick glance, I didn't spot anything obviously outdated.
> >
> Peter,
>    I just looked at this, and I'd say that moved into the hairy stuff 
> way too quickly.  Much of what it covered I would never expect to use.  
> Some I ddn't understand.  Part of this of course is that slides for a 
> talk are rarely very useful without the talker.

>   Something simpler for the layman would be good.

> Terry T.

-- 
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina 
Universidad Aut?noma de Madrid 
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From simon.urbanek at r-project.org  Fri Mar 23 16:58:39 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 23 Mar 2012 11:58:39 -0400
Subject: [Rd] .Call ref card
In-Reply-To: <87fwczr4em.wl%rdiaz02@gmail.com>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu> <87fwczr4em.wl%rdiaz02@gmail.com>
Message-ID: <EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>

This is my shot at a cheat sheet.
comments are welcome.

Simon

-------------- next part --------------
A non-text attachment was scrubbed...
Name: R API cheat sheet.pdf
Type: application/pdf
Size: 51661 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120323/a13f948a/attachment.pdf>
-------------- next part --------------


On Mar 23, 2012, at 6:35 AM, Ramon Diaz-Uriarte wrote:

> 
> 
> Peter, thanks for the slides. However, I felt like Terry and I think
> because I am missing the "big picture" that I was somewhat surprised by
> some of the content and organization (e.g., the detail about character
> vectors, the usage of the tcltk package as example code).
> 
> Best,
> 
> R.
> 
> 
> On Thu, 22 Mar 2012 12:45:14 -0500,Terry Therneau <therneau at mayo.edu> wrote:
>> On 03/22/2012 11:03 AM, peter dalgaard wrote:
>>> Don't know how useful it is any more, but back in the days, I gave this talk in Vienna
>>> 
>>> http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Dalgaard.pdf
>>> 
>>> Looking at it now, perhaps it moves a little too quickly into the hairy stuff. On the other hand, those were the things that I had found important to figure out at the time. At a quick glance, I didn't spot anything obviously outdated.
>>> 
>> Peter,
>>   I just looked at this, and I'd say that moved into the hairy stuff 
>> way too quickly.  Much of what it covered I would never expect to use.  
>> Some I ddn't understand.  Part of this of course is that slides for a 
>> talk are rarely very useful without the talker.
> 
>>  Something simpler for the layman would be good.
> 
>> Terry T.
> 
> -- 
> Ramon Diaz-Uriarte
> Department of Biochemistry, Lab B-25
> Facultad de Medicina 
> Universidad Aut?noma de Madrid 
> Arzobispo Morcillo, 4
> 28029 Madrid
> Spain
> 
> Phone: +34-91-497-2412
> 
> Email: rdiaz02 at gmail.com
>       ramon.diaz at iib.uam.es
> 
> http://ligarto.org/rdiaz
> 
> 


From edd at debian.org  Fri Mar 23 18:21:45 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 23 Mar 2012 12:21:45 -0500
Subject: [Rd] .Call ref card
In-Reply-To: <EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu> <87fwczr4em.wl%rdiaz02@gmail.com>
	<EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
Message-ID: <20332.45353.257614.562136@max.nulle.part>


Awesome. I love the reference card. This will be useful.

But I couldn't resist recasting your final "silly" example into 

  a) inline use which I find generally easier than having to do R CMD SHLIB
     followed by dyn.load() 

  b) a comparison with Rcpp which looks just about the same minus some
     UPPERCASE terms stemming from the R API.  

     We turn error() into Rf_error() as that is a toggle Rcpp sets (given how
     error(), length(), etc conflict at times with things of the same name
     coming from somewhere else). Alternatively, we could also use 'throw
     std::range_error("invalid n")' which then calls Rf_error for us.

     It uses one templated cast to int, but the intent is as readable as
     asInteger. You could of course use asInteger too, as Doug eg prefers.

     It then declares on list type of the right size. Alloc and all that is
     done behind the scenes -- abstraction.  And the assignment of the
     unaltered SEXP type x that is prelicated may just be simpler. 

Code is below for both variants, and the same outputs.

Dirk

R> library(inline)
R> 
R> replicateToListC <- cfunction(signature(x="any", N="integer"), body='
+    int n = asInteger(N);
+    if (n < 0) error("N must be non-negative");
+    SEXP res = allocVector(VECSXP, n);
+    for (int i = 0; i < n; i++) SET_VECTOR_ELT(res, i, x);
+    return res;
+ ')
R> 
R> replicateToListC(1:2, -2)
Error in replicateToListC(1:2, -2) : N must be non-negative
R> replicateToListC(1:2, 2)
[[1]]
[1] 1 2

[[2]]
[1] 1 2

R> 
R> replicateToListCpp <- cxxfunction(signature(x="any", N="integer"), plugin="Rcpp", body='
+    int n = as<int>(N);
+    if (n < 0) Rf_error("N must be non-negative");
+    List res(n);
+    for (int i = 0; i < n; i++) res[i] = x;
+    return res;
+ ')
R> 
R> replicateToListCpp(1:2, -2)
Error in replicateToListCpp(1:2, -2) : N must be non-negative
R> replicateToListCpp(1:2, 2)
[[1]]
[1] 1 2

[[2]]
[1] 1 2

R> 
R> 


-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From ligges at statistik.tu-dortmund.de  Fri Mar 23 19:32:40 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 23 Mar 2012 19:32:40 +0100
Subject: [Rd] uncompressed saves warning
In-Reply-To: <4F6B1E5D.20305@yorku.ca>
References: <4F69DE6A.90701@yorku.ca>
	<4F6A0E64.5010603@statistik.tu-dortmund.de>
	<4F6B1E5D.20305@yorku.ca>
Message-ID: <4F6CC1C8.7060801@statistik.tu-dortmund.de>



On 22.03.2012 13:43, Michael Friendly wrote:
> On 3/21/2012 1:22 PM, Uwe Ligges wrote:
>>> What is the equivalent R command to compress these files in my project
>>> tree?
>>>
>>
>> Michael,
>>
>> if you use
>> R CMD build --resave-data
>> to build the tar archive, the versions therein are recompressed.
> But AFAIK, in StatET, R CMD build builds a separate .tar.gz file under
> c:/eclipse, and does not affect
> the project directory where these files are stored and sync'd with R-Forge.
>>
>> Otherwise, you can also open the files and resave them via save() and
>> appropriate arguments.
> I exported the .rda files to c:/R/data and ran
>
>  > load("gfrance.rda")
>  > load("gfrance85.rda")
>  > save(gfrance, file="gfrance.RData", compress="xz")
> Error in xzfile(file, "wb", compression = 9) : cannot open the connection
> In addition: Warning message:
> In xzfile(file, "wb", compression = 9) :
> cannot initialize lzma encoder, error 5
>
> Why doesn't this work?
>


Don't know, works for me with R-2.14.2 (at least with another object - I 
do noit have yours) but tested with R-2.14.2 and R-2.15.0 RC, I do not 
have an R-2.14.1 around any more.

Uwe


>  > save(gfrance, file="gfrance.RData", compress=TRUE)
>
> The above works, but only compresses a 300K file to 299K
>>
>> Or use resaveRdaFiles() in package tools to runn it on a whole folder
>> automatically.
>>
>
>  > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United
> States.1252 LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C LC_TIME=English_United States.1252
>
> attached base packages:
> [1] grid stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] p3d_0.02-4 mgcv_1.7-13 car_2.0-12 nnet_7.3-1 rgl_0.92.798 vcd_1.2-13
> colorspace_1.1-1 MASS_7.3-17
>
> loaded via a namespace (and not attached):
> [1] lattice_0.20-6 Matrix_1.0-4 nlme_3.1-103 tools_2.14.1
>  >
>


From dtenenba at fhcrc.org  Fri Mar 23 20:20:59 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 23 Mar 2012 12:20:59 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
Message-ID: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>

Hi,

The page
http://cran.r-project.org/bin/windows/base/rtest.html
has a link to:
http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe

However, clicking on that link gives a 404 "Object not found' error.

FYI.
Dan


From djnordlund at frontier.com  Sat Mar 24 00:52:55 2012
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 23 Mar 2012 16:52:55 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
Message-ID: <EACEB08BE443481683B79A7D796D43A9@Gandalf>

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Dan Tenenbaum
> Sent: Friday, March 23, 2012 12:21 PM
> To: r-devel at r-project.org
> Subject: [Rd] Missing Windows binary for R-2.15RC?
> 
> Hi,
> 
> The page
> http://cran.r-project.org/bin/windows/base/rtest.html
> has a link to:
> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
> 
> However, clicking on that link gives a 404 "Object not found' error.
> 
> FYI.
> Dan
> 

I experienced the same error you did using the link you provided.  However, if you use the CRAN mirror hosted by YOUR organization, you can get the file. :-)

Hope this is helpful,

Dan 

Daniel Nordlund
Bothell, WA USA
 


From dtenenba at fhcrc.org  Sat Mar 24 01:47:58 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 23 Mar 2012 17:47:58 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
	<7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
Message-ID: <CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>

On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
<djnordlund at frontier.com> wrote:
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
>> On Behalf Of Dan Tenenbaum
>> Sent: Friday, March 23, 2012 12:21 PM
>> To: r-devel at r-project.org
>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>
>> Hi,
>>
>> The page
>> http://cran.r-project.org/bin/windows/base/rtest.html
>> has a link to:
>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>
>> However, clicking on that link gives a 404 "Object not found' error.
>>
>> FYI.
>> Dan
>>
>
> I experienced the same error you did using the link you provided. ?However, if you use the CRAN mirror hosted by YOUR organization, you can get the file. :-)
>

I don't think so:

http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe

gives me a 404 as well.

Dan


> Hope this is helpful,
>
> Dan
>
> Daniel Nordlund
> Bothell, WA USA
>
>
>


From djnordlund at frontier.com  Sat Mar 24 06:58:41 2012
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 23 Mar 2012 22:58:41 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
Message-ID: <885DBD479155497D9548FC35D83B64B2@Gandalf>

> -----Original Message-----
> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
> Sent: Friday, March 23, 2012 5:48 PM
> To: Daniel Nordlund
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
> 
> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
> <djnordlund at frontier.com> wrote:
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org]
> >> On Behalf Of Dan Tenenbaum
> >> Sent: Friday, March 23, 2012 12:21 PM
> >> To: r-devel at r-project.org
> >> Subject: [Rd] Missing Windows binary for R-2.15RC?
> >>
> >> Hi,
> >>
> >> The page
> >> http://cran.r-project.org/bin/windows/base/rtest.html
> >> has a link to:
> >> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
> >>
> >> However, clicking on that link gives a 404 "Object not found' error.
> >>
> >> FYI.
> >> Dan
> >>
> >
> > I experienced the same error you did using the link you provided.
>  However, if you use the CRAN mirror hosted by YOUR organization, you can
> get the file. :-)
> >
> 
> I don't think so:
> 
> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
> 
> gives me a 404 as well.
> 
> Dan
> 
> 

I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.

Dan

Daniel Nordlund
Bothell, WA USA


From ligges at statistik.tu-dortmund.de  Sat Mar 24 15:53:25 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 24 Mar 2012 15:53:25 +0100
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <885DBD479155497D9548FC35D83B64B2@Gandalf>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
Message-ID: <4F6DDFE5.7000803@statistik.tu-dortmund.de>



On 24.03.2012 06:58, Daniel Nordlund wrote:
>> -----Original Message-----
>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>> Sent: Friday, March 23, 2012 5:48 PM
>> To: Daniel Nordlund
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>
>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>> <djnordlund at frontier.com>  wrote:
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org]
>>>> On Behalf Of Dan Tenenbaum
>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>
>>>> Hi,
>>>>
>>>> The page
>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>> has a link to:
>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>
>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>
>>>> FYI.
>>>> Dan
>>>>
>>>
>>> I experienced the same error you did using the link you provided.
>>   However, if you use the CRAN mirror hosted by YOUR organization, you can
>> get the file. :-)
>>>
>>
>> I don't think so:
>>
>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>
>> gives me a 404 as well.
>>
>> Dan
>>
>>
>
> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.

It may have happened that the scripts generated the webpages before the 
binary was built and checked (since "beta" became "rc" yesterday).

Uwe

>
> Dan
>
> Daniel Nordlund
> Bothell, WA USA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat Mar 24 17:43:57 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Mar 2012 12:43:57 -0400
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <4F6DDFE5.7000803@statistik.tu-dortmund.de>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
Message-ID: <4F6DF9CD.6030709@gmail.com>

On 12-03-24 10:53 AM, Uwe Ligges wrote:
>
>
> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>> -----Original Message-----
>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>> Sent: Friday, March 23, 2012 5:48 PM
>>> To: Daniel Nordlund
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>
>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>> <djnordlund at frontier.com>   wrote:
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>> project.org]
>>>>> On Behalf Of Dan Tenenbaum
>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>> To: r-devel at r-project.org
>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>
>>>>> Hi,
>>>>>
>>>>> The page
>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>> has a link to:
>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>
>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>
>>>>> FYI.
>>>>> Dan
>>>>>
>>>>
>>>> I experienced the same error you did using the link you provided.
>>>    However, if you use the CRAN mirror hosted by YOUR organization, you can
>>> get the file. :-)
>>>>
>>>
>>> I don't think so:
>>>
>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>
>>> gives me a 404 as well.
>>>
>>> Dan
>>>
>>>
>>
>> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.
>
> It may have happened that the scripts generated the webpages before the
> binary was built and checked (since "beta" became "rc" yesterday).

Yes, they need manual tweaking at the conversion, and I did it after the 
first upload.

If this happens again (which is pretty likely), you can manually 
download the previous version by editing the URL to put in "alpha" in 
place of "beta", or "beta" in place of "rc".

I'd like to have this handled automatically as it was in the past, but I 
don't know the Windows CMD script language well enough to do it.  If any 
experts want to volunteer to fix this (I think you need to create a 
batch script variable from the suffix in a filename), please write to me 
offline.

Duncan Murdoch


From simon.urbanek at r-project.org  Sat Mar 24 19:31:14 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 24 Mar 2012 14:31:14 -0400
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <4F6DF9CD.6030709@gmail.com>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
Message-ID: <9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>


On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:

> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>> 
>> 
>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>> -----Original Message-----
>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>> To: Daniel Nordlund
>>>> Cc: r-devel at r-project.org
>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>> 
>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>> <djnordlund at frontier.com>   wrote:
>>>>>> -----Original Message-----
>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>> project.org]
>>>>>> On Behalf Of Dan Tenenbaum
>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>> To: r-devel at r-project.org
>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> The page
>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>> has a link to:
>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>> 
>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>> 
>>>>>> FYI.
>>>>>> Dan
>>>>>> 
>>>>> 
>>>>> I experienced the same error you did using the link you provided.
>>>>   However, if you use the CRAN mirror hosted by YOUR organization, you can
>>>> get the file. :-)
>>>>> 
>>>> 
>>>> I don't think so:
>>>> 
>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>> 
>>>> gives me a 404 as well.
>>>> 
>>>> Dan
>>>> 
>>>> 
>>> 
>>> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.
>> 
>> It may have happened that the scripts generated the webpages before the
>> binary was built and checked (since "beta" became "rc" yesterday).
> 
> Yes, they need manual tweaking at the conversion, and I did it after the first upload.
> 
> If this happens again (which is pretty likely), you can manually download the previous version by editing the URL to put in "alpha" in place of "beta", or "beta" in place of "rc".
> 

... or have a fixed name instead (on OS X we just use 2.15-branch which is unambiguous). For the record I find it extremely annoying that even the installation target name changes in the installer - I keep having to change it to R-2.15 all the time, because I don't see why you would want to have alpha/beta/rc/release of the same R version installed in separate directories by default  - but that may be just me ;). To a lesser degree the same applies to patch versions, but since those are released I could see an argument for that, even though in practice I think it is not useful either (because typically you just want to upgrade and not another copy).

Cheers,
Simon


> I'd like to have this handled automatically as it was in the past, but I don't know the Windows CMD script language well enough to do it.  If any experts want to volunteer to fix this (I think you need to create a batch script variable from the suffix in a filename), please write to me offline.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ligges at statistik.tu-dortmund.de  Sat Mar 24 19:47:16 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 24 Mar 2012 19:47:16 +0100
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
Message-ID: <4F6E16B4.3000400@statistik.tu-dortmund.de>



On 24.03.2012 19:31, Simon Urbanek wrote:
>
> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>
>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>
>>>
>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>> -----Original Message-----
>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>> To: Daniel Nordlund
>>>>> Cc: r-devel at r-project.org
>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>
>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>> <djnordlund at frontier.com>    wrote:
>>>>>>> -----Original Message-----
>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>> project.org]
>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>> To: r-devel at r-project.org
>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> The page
>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>> has a link to:
>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>
>>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>>>
>>>>>>> FYI.
>>>>>>> Dan
>>>>>>>
>>>>>>
>>>>>> I experienced the same error you did using the link you provided.
>>>>>    However, if you use the CRAN mirror hosted by YOUR organization, you can
>>>>> get the file. :-)
>>>>>>
>>>>>
>>>>> I don't think so:
>>>>>
>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>
>>>>> gives me a 404 as well.
>>>>>
>>>>> Dan
>>>>>
>>>>>
>>>>
>>>> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.
>>>
>>> It may have happened that the scripts generated the webpages before the
>>> binary was built and checked (since "beta" became "rc" yesterday).
>>
>> Yes, they need manual tweaking at the conversion, and I did it after the first upload.
>>
>> If this happens again (which is pretty likely), you can manually download the previous version by editing the URL to put in "alpha" in place of "beta", or "beta" in place of "rc".
>>
>
> ... or have a fixed name instead (on OS X we just use 2.15-branch which is unambiguous). For the record I find it extremely annoying that even the installation target name changes in the installer - I keep having to change it to R-2.15 all the time, because I don't see why you would want to have alpha/beta/rc/release of the same R version installed in separate directories by default  - but that may be just me ;). To a lesser degree the same applies to patch versions, but since those are released I could see an argument for that, even though in practice I think it is not useful either (because typically you just want to upgrade and not another copy).

I install it to the same location anyway, but I think it is also a good 
idea to indicate we have a progress in the prerelerase version and make 
it easy to distinguish release / prerelease versions for users.

Adapting the script won't be too hard, because -  as reported to Duncan 
in a private message already - we also have R and Rtools installed and 
do not need to rely entirely on cmd.exe.

Uwe



>
> Cheers,
> Simon
>
>
>> I'd like to have this handled automatically as it was in the past, but I don't know the Windows CMD script language well enough to do it.  If any experts want to volunteer to fix this (I think you need to create a batch script variable from the suffix in a filename), please write to me offline.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Sat Mar 24 20:00:11 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 24 Mar 2012 15:00:11 -0400
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <4F6E16B4.3000400@statistik.tu-dortmund.de>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
	<4F6E16B4.3000400@statistik.tu-dortmund.de>
Message-ID: <EC719A2E-6A21-4675-9D5A-D4FA74E97993@r-project.org>


On Mar 24, 2012, at 2:47 PM, Uwe Ligges wrote:

> 
> 
> On 24.03.2012 19:31, Simon Urbanek wrote:
>> 
>> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>> 
>>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>> 
>>>> 
>>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>>> -----Original Message-----
>>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>>> To: Daniel Nordlund
>>>>>> Cc: r-devel at r-project.org
>>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>> 
>>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>>> <djnordlund at frontier.com>    wrote:
>>>>>>>> -----Original Message-----
>>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>>> project.org]
>>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>>> To: r-devel at r-project.org
>>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> 
>>>>>>>> The page
>>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>>> has a link to:
>>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>> 
>>>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>>>> 
>>>>>>>> FYI.
>>>>>>>> Dan
>>>>>>>> 
>>>>>>> 
>>>>>>> I experienced the same error you did using the link you provided.
>>>>>>   However, if you use the CRAN mirror hosted by YOUR organization, you can
>>>>>> get the file. :-)
>>>>>>> 
>>>>>> 
>>>>>> I don't think so:
>>>>>> 
>>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>> 
>>>>>> gives me a 404 as well.
>>>>>> 
>>>>>> Dan
>>>>>> 
>>>>>> 
>>>>> 
>>>>> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.
>>>> 
>>>> It may have happened that the scripts generated the webpages before the
>>>> binary was built and checked (since "beta" became "rc" yesterday).
>>> 
>>> Yes, they need manual tweaking at the conversion, and I did it after the first upload.
>>> 
>>> If this happens again (which is pretty likely), you can manually download the previous version by editing the URL to put in "alpha" in place of "beta", or "beta" in place of "rc".
>>> 
>> 
>> ... or have a fixed name instead (on OS X we just use 2.15-branch which is unambiguous). For the record I find it extremely annoying that even the installation target name changes in the installer - I keep having to change it to R-2.15 all the time, because I don't see why you would want to have alpha/beta/rc/release of the same R version installed in separate directories by default  - but that may be just me ;). To a lesser degree the same applies to patch versions, but since those are released I could see an argument for that, even though in practice I think it is not useful either (because typically you just want to upgrade and not another copy).
> 
> I install it to the same location anyway, but I think it is also a good idea to indicate we have a progress in the prerelerase version and make it easy to distinguish release / prerelease versions for users.
> 

Well, the distinction should certainly be in the stuff displayed to the user at installation time (i.e. showing what they are about to install). Also we put the full current version on the page that they download from, but I don't think it needs to be part of the file name *and* the target location to be installed to. Aa I said, I care less about the former than the latter so it's OT but inspired by the original question ;).

Cheers,
Simon





> Adapting the script won't be too hard, because -  as reported to Duncan in a private message already - we also have R and Rtools installed and do not need to rely entirely on cmd.exe.
> 
> Uwe
> 
> 
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> I'd like to have this handled automatically as it was in the past, but I don't know the Windows CMD script language well enough to do it.  If any experts want to volunteer to fix this (I think you need to create a batch script variable from the suffix in a filename), please write to me offline.
>>> 
>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Sat Mar 24 21:07:08 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Mar 2012 16:07:08 -0400
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com><7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
Message-ID: <4F6E296C.3010101@gmail.com>

On 12-03-24 2:31 PM, Simon Urbanek wrote:
>
> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>
>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>
>>>
>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>> -----Original Message-----
>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>> To: Daniel Nordlund
>>>>> Cc: r-devel at r-project.org
>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>
>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>> <djnordlund at frontier.com>    wrote:
>>>>>>> -----Original Message-----
>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>> project.org]
>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>> To: r-devel at r-project.org
>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> The page
>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>> has a link to:
>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>
>>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>>>
>>>>>>> FYI.
>>>>>>> Dan
>>>>>>>
>>>>>>
>>>>>> I experienced the same error you did using the link you provided.
>>>>>    However, if you use the CRAN mirror hosted by YOUR organization, you can
>>>>> get the file. :-)
>>>>>>
>>>>>
>>>>> I don't think so:
>>>>>
>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>
>>>>> gives me a 404 as well.
>>>>>
>>>>> Dan
>>>>>
>>>>>
>>>>
>>>> I didn't look closely enough at what you were asking for (RC versus beta).  R-2.15RC may not have been up-loaded yet.  However, I just downloaded it from the original link that was posted, so it appears to be available now.
>>>
>>> It may have happened that the scripts generated the webpages before the
>>> binary was built and checked (since "beta" became "rc" yesterday).
>>
>> Yes, they need manual tweaking at the conversion, and I did it after the first upload.
>>
>> If this happens again (which is pretty likely), you can manually download the previous version by editing the URL to put in "alpha" in place of "beta", or "beta" in place of "rc".
>>
>
> ... or have a fixed name instead (on OS X we just use 2.15-branch which is unambiguous). For the record I find it extremely annoying that even the installation target name changes in the installer - I keep having to change it to R-2.15 all the time, because I don't see why you would want to have alpha/beta/rc/release of the same R version installed in separate directories by default  - but that may be just me ;). To a lesser degree the same applies to patch versions, but since those are released I could see an argument for that, even though in practice I think it is not useful either (because typically you just want to upgrade and not another copy).

I'm neutral about the name changes, but I don't think any of this is 
enough of a problem to be worth the time to fix.  If someone else wants 
to do it, then I'd be happy to let you take over.

Duncan Murdoch


From pgilbert902 at gmail.com  Sat Mar 24 21:29:59 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 24 Mar 2012 16:29:59 -0400
Subject: [Rd] RC / methods package
Message-ID: <4F6E2EC7.2060001@gmail.com>

(I think this is being caused by the new methods package in RC.)

In the RC (March 24) some of my packages are generating a Note

Note: Method with signature "MySQLConnection#integer" chosen for 
function "coerce",
  target signature "TSMySQLConnection#integer".
  "dbObjectId#integer" would also be valid

This is coming from a call to dbGetQuery() in package DBI. The method 
with the signature "TSMySQLConnection#integer" is generated 
automatically because TSMySQLConnection inherits from
MySQLConnection. (More details below.)

Is there a way to pass this information along to coerce when the method 
is generated, or otherwise suppress the Note?

BTW,
  1/ It would be nice if the Note mentioned what method is generating 
it, in addition to the signature. Debugging for a call several levels 
deep in the stack is already hard enough.

  2/ The note only seems to get generated on the first call and then 
gets suppressed. This will be nice for users, but makes debugging 
harder. Is there a way to prevent suppressing the message?

  3/ It seems strange that  getMethod() cannot find the methods even 
though showMethods() shows it. (See below.)

Paul
________

 >showMethods("dbGetQuery")
Function: dbGetQuery (package DBI)
conn="MySQLConnection", statement="character"

 >   z <- TSget("Series 1", con, TSrepresentation="timeSeries")
Note: Method with signature "MySQLConnection#integer" chosen for 
function "coerce",
  target signature "TSMySQLConnection#integer".
  "dbObjectId#integer" would also be valid
Loading required package: zoo

Attaching package: ?zoo?

The following object(s) are masked from ?package:timeSeries?:

     time<-

The following object(s) are masked from ?package:base?:

     as.Date, as.Date.numeric

 >  showMethods("dbGetQuery")
Function: dbGetQuery (package DBI)
conn="MySQLConnection", statement="character"
conn="TSMySQLConnection", statement="character"
     (inherited from: conn="MySQLConnection", statement="character")

 > getMethod("dbGetQuery",  signature = c("TSMySQLConnection", 
statement="character"))
Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection", 
statement = "character")) :
   No method found for function "dbGetQuery" and signature 
TSMySQLConnection, character
 >


From jmc at r-project.org  Sun Mar 25 01:11:55 2012
From: jmc at r-project.org (John Chambers)
Date: Sat, 24 Mar 2012 17:11:55 -0700
Subject: [Rd] RC / methods package
In-Reply-To: <4F6E2EC7.2060001@gmail.com>
References: <4F6E2EC7.2060001@gmail.com>
Message-ID: <4F6E62CB.40109@r-project.org>



On 3/24/12 1:29 PM, Paul Gilbert wrote:
> (I think this is being caused by the new methods package in RC.)
Possibly, but the methods package isn't particularly "new" in its method 
selection.

We need to see the definition of the class.  The note implies that it 
inherits from both "MySQLConnection" and "dbObjectId", both of which 
have methods for coercing to "integer".  Hence the ambiguity.
>
> In the RC (March 24) some of my packages are generating a Note
>
> Note: Method with signature "MySQLConnection#integer" chosen for 
> function "coerce",
>  target signature "TSMySQLConnection#integer".
>  "dbObjectId#integer" would also be valid
>
> This is coming from a call to dbGetQuery() in package DBI. The method 
> with the signature "TSMySQLConnection#integer" is generated 
> automatically because TSMySQLConnection inherits from
> MySQLConnection. (More details below.)
>
> Is there a way to pass this information along to coerce when the 
> method is generated, or otherwise suppress the Note?
No.  Methods are inherited according to rules implied by the class 
inheritance; R doesn't allow you to override the inheritance, other than 
by being more explicit about the method definition.  (It's only a note, 
and IMO a relevant one.  Be glad the language isn't Dylan, which treats 
similar ambiguities as a programming error. :-))
>
> BTW,
>  1/ It would be nice if the Note mentioned what method is generating 
> it, in addition to the signature. Debugging for a call several levels 
> deep in the stack is already hard enough.
?? it does, for coerce()  which admittedly you have to know is the 
method defined for as(thing, "integer") either directly or indirectly.  
Unless you mean showing you the whole method definition, but that seems 
not relevant to selection.

If you wanted to see the coerce() method, you need to do 
showMethods("coerce"), but I don't think that's relevant.  As mentioned, 
it's the class hierarchy that matters.
>
>  2/ The note only seems to get generated on the first call and then 
> gets suppressed. This will be nice for users, but makes debugging 
> harder. Is there a way to prevent suppressing the message?
No.  the note is generated when an inherited method is found.  That 
method is then cached, so the computations required are (fortunately) 
not repeated.

It would be nice to have tools that the package writer could apply to 
generate all possible inheritance patterns, and flag possible 
ambiguities at package INSTALL time, as opposed to when the package is 
used.  But it's likely that would generate so many cases unlikely to 
occur that the package developer would ignore it, even assuming the 
developer was energetic enough to use the tool in the first place.
> o
>  3/ It seems strange that  getMethod() cannot find the methods even 
> though showMethods() shows it. (See below.)
I think you're confusing getMethod(), which only finds directly defined 
methods, with selectMethod() which replicates the inheritance computations.

In any case the selection of the method has been specified for you already.

John
>
> Paul
> ________
>
> >showMethods("dbGetQuery")
> Function: dbGetQuery (package DBI)
> conn="MySQLConnection", statement="character"
>
> >   z <- TSget("Series 1", con, TSrepresentation="timeSeries")
> Note: Method with signature "MySQLConnection#integer" chosen for 
> function "coerce",
>  target signature "TSMySQLConnection#integer".
>  "dbObjectId#integer" would also be valid
> Loading required package: zoo
>
> Attaching package: ?zoo?
>
> The following object(s) are masked from ?package:timeSeries?:
>
>     time<-
>
> The following object(s) are masked from ?package:base?:
>
>     as.Date, as.Date.numeric
>
> >  showMethods("dbGetQuery")
> Function: dbGetQuery (package DBI)
> conn="MySQLConnection", statement="character"
> conn="TSMySQLConnection", statement="character"
>     (inherited from: conn="MySQLConnection", statement="character")
>
> > getMethod("dbGetQuery",  signature = c("TSMySQLConnection", 
> statement="character"))
> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection", 
> statement = "character")) :
>   No method found for function "dbGetQuery" and signature 
> TSMySQLConnection, character
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Sun Mar 25 16:34:03 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 Mar 2012 15:34:03 +0100 (BST)
Subject: [Rd] merge bug fix in R 2.15.0
In-Reply-To: <4F678653.7010904@u.washington.edu>
References: <mailman.21.1332154808.27988.r-devel@r-project.org>
	<4F678653.7010904@u.washington.edu>
Message-ID: <alpine.LFD.2.02.1203251523460.15478@gannet.stats.ox.ac.uk>

On Mon, 19 Mar 2012, Stephanie M. Gogarten wrote:

> I would like to add a vote for keeping blank suffixes in merge(), as I 
> routinely use this functionality.  An example use case:

But you don't have a vote ....

An exception has been made for "" in R 2.15.0.  However, further cases 
of unintended results resulting from duplicate names using merge() 
have come to light, so there will be further restrictions imposed in 
future to protect users from failing to consider duplicate names.

>
> # using R 2.14.1
> # d1 is some data that I've been working on for a while
> d1 <- data.frame(a=letters[1:10], b=1:10)
> # d2 is some new data from a collaborator.  I want to add one of these # 
> columns to d1, and also check that the existing columns are consistent
> d2 <- data.frame(a=letters[1:10], b=1:10, c=101:110)
>
> # use blank suffix to avoid changing the column names of my
> # original data frame
> d3 <- merge(d1, d2, by="a", suffixes=c("", ".new"))
> all(d3$b == d3$b.new)
> # if this is FALSE, time to email collaborator
> d3$b.new <- NULL
>
> In real usage d1 would have many more columns than d2, so adding suffixes to 
> d1 would be tedious to undo after the merge.
>
> Stephanie Gogarten
> Research Scientist, Biostatistics
> University of Washington
>
> On 3/19/12 4:00 AM, r-devel-request at r-project.org wrote:
>> Message: 12
>> Date: Sun, 18 Mar 2012 15:48:30 -0400
>> From: Steve Lianoglou<mailinglist.honeypot at gmail.com>
>> To: Uwe Ligges<ligges at statistik.tu-dortmund.de>
>> Cc: Matthew Dowle<mdowle at mdowle.plus.com>,r-devel at r-project.org
>> Subject: Re: [Rd] merge bug fix in R 2.15.0
>> Message-ID:
>> 	<CAHA9McMGy0U9B_8x=RSBfjCCUMsuEhUUxB03wdtfTRBGAFsJtA at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>> 
>> Hi Uwe,
>> 
>> 2012/3/17 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>> >
>>> >
>>> >  On 15.03.2012 22:48, Matthew Dowle wrote:
>>>> >>
>>>> >>
>>>> >>  Anyone?
>>>> >>
>>>>> >>>  Is it intended that the first suffix can no longer be blank? Seems 
>>>>> to be
>>>>> >>>  caused by a bug fix to merge in R 2.15.0.
>>> >
>>> >
>>> >
>>> >  Right, the user is now protected against confusing himself by using 
>>> names
>>> >  that were not unique before the merge.
>> ... now I'm confused:-)
>> 
>> If the user explicitly asks for a NULL/0/empty/whatever suffix,
>> they're not really going to be confusing themselves, right?
>> 
>> I actually feel like I do this often, where "this" is explicitly
>> asking to not add a suffix to one group of columns ... I do confuse
>> myself every and now and again, but not in this context, yet.
>> 
>> I can see that*this*  confusing case is now handled w/ this change
>> (which wasn't before):
>> 
>> ## I'm using R-devel compiled back in November, 2011 (r57571)
>> R>  d1<- data.frame(a=letters[1:10], b=rnorm(10), b.x=tail(letters, 10))
>> R>  d2<- data.frame(a=letters[1:10], b=101:110)
>> R>  merge(d1, d2, by='a', suffixes=c('.x', '.y'))
>>     a         b.x b.x b.y
>> 1  a -1.52250626   q 101
>> 2  b -0.99865341   r 102
>> ... ## Let's call this "exhibit A"
>> 
>> But if I do this:
>> R>  merge(d1, d2, by='a', suffixes=c("", ".y"))
>> 
>> I totally expect:
>>
>>     a           b b.x b.y
>> 1  a -1.52250626   q 101
>> 2  b -0.99865341   r 102
>> ## Let's call this "exhibit B"
>> ...
>> 
>> and not (using R-2.15.0 beta) (exhibit B):
>> 
>> Error in merge.data.frame(d1, d2, by = "a", suffixes = c("", ".y")) :
>>    there is already a column named 'b'
>> 
>> I can take a crack at a patch to keep the "rescue user from surprises"
>> example outlined in "exhibit A," but also letting user accomplish
>> "exhibit B" if there is a consensus of agreement on this particular
>> world view.
>> 
>> -steve
>> 
>> -- Steve Lianoglou Graduate Student: Computational Systems Biology ?|
>> Memorial Sloan-Kettering Cancer Center ?| Weill Medical College of
>> Cornell University Contact Info: http://cbio.mskcc.org/~lianos/contact
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Sun Mar 25 21:24:01 2012
From: jmc at r-project.org (John Chambers)
Date: Sun, 25 Mar 2012 12:24:01 -0700
Subject: [Rd] RC / methods package
In-Reply-To: <4F6E6A3F.1050104@gmail.com>
References: <4F6E2EC7.2060001@gmail.com> <4F6E62CB.40109@r-project.org>
	<4F6E6A3F.1050104@gmail.com>
Message-ID: <4F6F70D1.4040905@r-project.org>

On 3/24/12 5:43 PM, Paul Gilbert wrote:
>
>
> On 12-03-24 08:11 PM, John Chambers wrote:
>>
>>
>> On 3/24/12 1:29 PM, Paul Gilbert wrote:
>>> (I think this is being caused by the new methods package in RC.)
>> Possibly, but the methods package isn't particularly "new" in its method
>> selection.
>>
>> We need to see the definition of the class.
>
> Is there a way to know which class it is that we need to see the
> definition for?

It's in the note:  'target signature "TSMySQLConnection#integer"'.  In 
functional OOP with multiple dispatch, it's all the classes that matter 
in general, but in this and most cases, one class is likely the relevant 
one:  "TSMySQLConnection".  That was why I said what I did before.

(We could go to a bit more effort and back-translate the dispatch string 
"TSMySQLConnection#integer" into the corresponding formal arguments. 
Would be more natural with the INSTALL time tool I mentioned before. 
That's the real challenge here -- to give information about this to the 
package developer, not the poor user.)

John

>
> Paul
>
>> The note implies that it
>> inherits from both "MySQLConnection" and "dbObjectId", both of which
>> have methods for coercing to "integer". Hence the ambiguity.
>>>
>>> In the RC (March 24) some of my packages are generating a Note
>>>
>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>> function "coerce",
>>> target signature "TSMySQLConnection#integer".
>>> "dbObjectId#integer" would also be valid
>>>
>>> This is coming from a call to dbGetQuery() in package DBI. The method
>>> with the signature "TSMySQLConnection#integer" is generated
>>> automatically because TSMySQLConnection inherits from
>>> MySQLConnection. (More details below.)
>>>
>>> Is there a way to pass this information along to coerce when the
>>> method is generated, or otherwise suppress the Note?
>> No. Methods are inherited according to rules implied by the class
>> inheritance; R doesn't allow you to override the inheritance, other than
>> by being more explicit about the method definition. (It's only a note,
>> and IMO a relevant one. Be glad the language isn't Dylan, which treats
>> similar ambiguities as a programming error. :-))
>>>
>>> BTW,
>>> 1/ It would be nice if the Note mentioned what method is generating
>>> it, in addition to the signature. Debugging for a call several levels
>>> deep in the stack is already hard enough.
>> ?? it does, for coerce() which admittedly you have to know is the method
>> defined for as(thing, "integer") either directly or indirectly. Unless
>> you mean showing you the whole method definition, but that seems not
>> relevant to selection.
>>
>> If you wanted to see the coerce() method, you need to do
>> showMethods("coerce"), but I don't think that's relevant. As mentioned,
>> it's the class hierarchy that matters.
>>>
>>> 2/ The note only seems to get generated on the first call and then
>>> gets suppressed. This will be nice for users, but makes debugging
>>> harder. Is there a way to prevent suppressing the message?
>> No. the note is generated when an inherited method is found. That method
>> is then cached, so the computations required are (fortunately) not
>> repeated.
>>
>> It would be nice to have tools that the package writer could apply to
>> generate all possible inheritance patterns, and flag possible
>> ambiguities at package INSTALL time, as opposed to when the package is
>> used. But it's likely that would generate so many cases unlikely to
>> occur that the package developer would ignore it, even assuming the
>> developer was energetic enough to use the tool in the first place.
>>> o
>>> 3/ It seems strange that getMethod() cannot find the methods even
>>> though showMethods() shows it. (See below.)
>> I think you're confusing getMethod(), which only finds directly defined
>> methods, with selectMethod() which replicates the inheritance
>> computations.
>>
>> In any case the selection of the method has been specified for you
>> already.
>>
>> John
>>>
>>> Paul
>>> ________
>>>
>>> >showMethods("dbGetQuery")
>>> Function: dbGetQuery (package DBI)
>>> conn="MySQLConnection", statement="character"
>>>
>>> > z <- TSget("Series 1", con, TSrepresentation="timeSeries")
>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>> function "coerce",
>>> target signature "TSMySQLConnection#integer".
>>> "dbObjectId#integer" would also be valid
>>> Loading required package: zoo
>>>
>>> Attaching package: ?zoo?
>>>
>>> The following object(s) are masked from ?package:timeSeries?:
>>>
>>> time<-
>>>
>>> The following object(s) are masked from ?package:base?:
>>>
>>> as.Date, as.Date.numeric
>>>
>>> > showMethods("dbGetQuery")
>>> Function: dbGetQuery (package DBI)
>>> conn="MySQLConnection", statement="character"
>>> conn="TSMySQLConnection", statement="character"
>>> (inherited from: conn="MySQLConnection", statement="character")
>>>
>>> > getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>> statement="character"))
>>> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>> statement = "character")) :
>>> No method found for function "dbGetQuery" and signature
>>> TSMySQLConnection, character
>>> >
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>


From bg2382 at columbia.edu  Sat Mar 24 00:13:46 2012
From: bg2382 at columbia.edu (Ben Goodrich)
Date: Fri, 23 Mar 2012 19:13:46 -0400
Subject: [Rd] serialization regression in 2.15.0 beta
Message-ID: <20120323191346.lmq6atwzhcgcsg00@cubmail.cc.columbia.edu>

Hi,

I am experiencing a problem related to serialization behavior in  
2.15.0 beta (binary installed from Debian unstable) and 2.16.0 (from  
svn) that is not present in 2.14.2 (binary from Debian testing).

I don't fully understand the problem. Also, I tried but have not yet  
been able to create a small, self-contained example that reproduces  
the problem. However, I do have a large, not self-contained example,  
which requires an alpha version (not yet on CRAN) of the mi package  
(the mi package on CRAN would not exhibit this issue). Anyone  
interested in reproducing the problem can follow the readme.txt file  
in this directory:

http://www.columbia.edu/~bg2382/mi/serialization/

I track r-devel with git-svn and was able to git bisect to svn commit r58219

commit 799102bd9d0266fe89c3120981decf0b1f17ef11
Author: ripley <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
Date:   Sat Jan 28 15:02:34 2012 +0000

     make use of non-xdr serialization;.

although this commit could merely expose the problem rather than cause it.

The problem occurs when the FUN called by mclapply() in the parallel  
package returns a S4 object that contains a slot (called X) that is a  
large matrix, specifically a "model matrix" similar to that produced  
by glm(). Some columns of this matrix get corrupted with wrong values  
(usually zero, but sometimes NaN or 10^300ish), which can be seen by  
examining X right before FUN returns (to mclapply()'s environment) and  
comparing to the "same" X after mclapply() returns to the calling  
environment.

Part of svn commit r58219 is this hunk

diff --git a/src/library/parallel/R/unix/mcfork.R  
b/src/library/parallel/R/unix/mcfork.R
index 8e27534..4f92193 100644
--- a/src/library/parallel/R/unix/mcfork.R
+++ b/src/library/parallel/R/unix/mcfork.R
@@ -82,7 +82,8 @@ mckill <- function(process, signal = 2L)
  ## used by mcparallel, mclapply
  sendMaster <- function(what)
  {
-    if (!is.raw(what)) what <- serialize(what, NULL, FALSE)
+    # This is talking to the same machine, so no point in using xdr.
+    if (!is.raw(what)) what <- serialize(what, NULL, xdr = FALSE)
      .Call(C_mc_send_master, what, PACKAGE = "parallel")
  }

Contrary to the comment, I have found that if I specify xdr = TRUE, I  
get the expected (non-corrupted X slot) behavior in 2.16.0, even  
though it is forking locally on my 64bit Debian laptop with a little  
endian i7 processor, whose specs are

goodrich at CYBERPOWERPC:/tmp/serialization$ cat /proc/cpuinfo
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 42
model name      : Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz
stepping        : 7
microcode       : 0x17
cpu MHz         : 800.000
cache size      : 6144 KB
physical id     : 0
siblings        : 8
core id         : 0
cpu cores       : 4
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 13
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge  
mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe  
syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl  
xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl  
vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt  
tsc_deadline_timer xsave avx lahf_lm ida arat epb xsaveopt pln pts dts  
tpr_shadow vnmi flexpriority ept vpid
bogomips        : 3990.83
clflush size    : 64
cache_alignment : 64
address sizes   : 36 bits physical, 48 bits virtual
power management:

...

processor       : 7
[same as processor 0]

So, to summarize I get the good behavior on R 2.14.2 when using  
mclapply(), on 2.15.0 beta when using lapply(), and on 2.16.0 using  
mclapply() iff I patch in xdr = TRUE in sendMaster(). I get the bad  
behavior on 2.15.0 beta and unpatched 2.16.0 when using mclapply().

My session info:

> sessionInfo()
R version 2.15.0 beta (2012-03-16 r58769)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
  [1] mi_0.9-83        bigmemory_4.2.11 arm_1.5-03       foreign_0.8-49
  [5] abind_1.4-0      R2WinBUGS_2.1-18 coda_0.14-5      lme4_0.999375-42
  [9] Matrix_1.0-4     lattice_0.20-0   MASS_7.3-17

loaded via a namespace (and not attached):
[1] grid_2.15.0  nlme_3.1-103

Thanks,
Ben


From francisco.garau at gmail.com  Sat Mar 24 18:41:14 2012
From: francisco.garau at gmail.com (Francisco Garau)
Date: Sat, 24 Mar 2012 17:41:14 +0000
Subject: [Rd] Smalltalk binding to R
Message-ID: <CAKAN0GfYxhoMvHoCywtw4QizKE90wacUzuiOFm2Wq7TPg3Fwow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120324/e86b6448/attachment.pl>

From josh.m.ulrich at gmail.com  Sun Mar 25 22:01:35 2012
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 25 Mar 2012 15:01:35 -0500
Subject: [Rd] Smalltalk binding to R
In-Reply-To: <CAKAN0GfYxhoMvHoCywtw4QizKE90wacUzuiOFm2Wq7TPg3Fwow@mail.gmail.com>
References: <CAKAN0GfYxhoMvHoCywtw4QizKE90wacUzuiOFm2Wq7TPg3Fwow@mail.gmail.com>
Message-ID: <CAPPM_gR4JnZxOgXeJK5kSADkny_T-qii+7OxDrOWigQPSBsdhg@mail.gmail.com>

Hi Francisco,

R-devel probably isn't the best venue for this.  If you're looking for
a GSoC student/mentor and you visit the R Project webpage on GSoC's
site:
http://www.google-melange.com/gsoc/org/google/gsoc2012/rproject

you will see a link to the "Ideas page >>":
http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2012&s=gsoc

which says you should have sent this email to the GSoC-R Google group.
 Please join and continue the discussion there.  I have already cc'd
the GSoC-R group.

Best,
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com

R/Finance 2012: Applied Finance with R
www.RinFinance.com



On Sat, Mar 24, 2012 at 12:41 PM, Francisco Garau
<francisco.garau at gmail.com> wrote:
> Hi - any person interested in building a binding between Smalltalk and R,
> please contact myself or Hernan.
>
> This could be done as the Google Summer of Code (GSoC).
>
> http://www.google-melange.com/gsoc/homepage/google/gsoc2012
> http://gsoc2012.esug.org/projects/r-statistics
>
> For those who don't know Smalltalk it is an Object Oriented language that
> was created back in the '80s in the Xerox Parc research center. Although it
> never achieved high popularity it remains strong in some niche areas and
> growing in popularity thanks to a very cool Web development framework.
>
> Smalltalk has only one disadvantage: once you try it, you don't want to
> leave it!
>
> Please, join us in helping connect the world of Smalltalk and all the
> amazing R libraries.
>
> - Francisco
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert902 at gmail.com  Sun Mar 25 23:29:52 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 25 Mar 2012 17:29:52 -0400
Subject: [Rd] RC / methods package
In-Reply-To: <4F6F70D1.4040905@r-project.org>
References: <4F6E2EC7.2060001@gmail.com> <4F6E62CB.40109@r-project.org>
	<4F6E6A3F.1050104@gmail.com> <4F6F70D1.4040905@r-project.org>
Message-ID: <4F6F8E50.8020407@gmail.com>

John

Here is the definition of the TSMySQLConnection class, and a few other 
things. This is a simplified example that produces the message, but 
unfortunately will not work unless you have a MySQL database to connect 
to. (I do get the same problem with PostgreSQL, and may with SQLLite, 
but I have not tested the last yet.)

require("methods")
require("DBI")
require("RMySQL")

setClassUnion("OptionalPOSIXct",   c("POSIXct",   "logical"))
setClass("conType", representation( drv="character"), "VIRTUAL" )

setClass("TSdb", representation( dbname="character",
     hasVintages="logical", hasPanels="logical"), "VIRTUAL" )


setClass("TSMySQLConnection", contains=c("MySQLConnection", "conType", 
"TSdb"))


setGeneric("TSconnect", def= function(drv, dbname, ...) 
standardGeneric("TSconnect"))


setMethod("TSconnect",   signature(drv="MySQLDriver", dbname="character"),
    definition=function(drv, dbname, ...) {
         con <- dbConnect(drv, dbname=dbname, ...)
	new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
   	       hasVintages=dbExistsTable(con, "vintageAlias"),
   	       hasPanels  =dbExistsTable(con, "panels"))
	})

con <- TSconnect(dbDriver("MySQL"), "test")

dbGetQuery(con, "show tables")
Note: Method with signature "MySQLConnection#integer" chosen for 
function "coerce",
  target signature "TSMySQLConnection#integer".
  "dbObjectId#integer" would also be valid
    Tables_in_test
1               A
2               B
 >

The message also seems to go away, even quitting R and restarting to 
clear the cache, if I change the TSconnect method as follow

setMethod("TSconnect",   signature(drv="MySQLDriver", dbname="character"),
    definition=function(drv, dbname, ...) {
         con <- dbConnect(drv, dbname=dbname, ...)
	new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
   	       hasVintages=FALSE,
   	       hasPanels  =FALSE)
	})

Why this would happen makes absolutely no sense to me. In the first 
version is  dbExistsTable(con, "vintageAlias") left unevaluated in the 
result from new?

As you can tell, I'm struggling a bit with interpreting the information 
from the note. Also, if it were a warning I could set it to stop, and 
then traceback to what was causing the problem. As it is, it took me a 
fairly long time just to get the fact that the call to dbGetQuery() was 
generating the message. And caching the methods may be good for 
performance, but when things change the second time you call them it 
sure makes debugging difficult.

Best,
Paul


On 12-03-25 03:24 PM, John Chambers wrote:
> On 3/24/12 5:43 PM, Paul Gilbert wrote:
>>
>>
>> On 12-03-24 08:11 PM, John Chambers wrote:
>>>
>>>
>>> On 3/24/12 1:29 PM, Paul Gilbert wrote:
>>>> (I think this is being caused by the new methods package in RC.)
>>> Possibly, but the methods package isn't particularly "new" in its method
>>> selection.
>>>
>>> We need to see the definition of the class.
>>
>> Is there a way to know which class it is that we need to see the
>> definition for?
>
> It's in the note: 'target signature "TSMySQLConnection#integer"'. In
> functional OOP with multiple dispatch, it's all the classes that matter
> in general, but in this and most cases, one class is likely the relevant
> one: "TSMySQLConnection". That was why I said what I did before.
>
> (We could go to a bit more effort and back-translate the dispatch string
> "TSMySQLConnection#integer" into the corresponding formal arguments.
> Would be more natural with the INSTALL time tool I mentioned before.
> That's the real challenge here -- to give information about this to the
> package developer, not the poor user.)
>
> John
>
>>
>> Paul
>>
>>> The note implies that it
>>> inherits from both "MySQLConnection" and "dbObjectId", both of which
>>> have methods for coercing to "integer". Hence the ambiguity.
>>>>
>>>> In the RC (March 24) some of my packages are generating a Note
>>>>
>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>> function "coerce",
>>>> target signature "TSMySQLConnection#integer".
>>>> "dbObjectId#integer" would also be valid
>>>>
>>>> This is coming from a call to dbGetQuery() in package DBI. The method
>>>> with the signature "TSMySQLConnection#integer" is generated
>>>> automatically because TSMySQLConnection inherits from
>>>> MySQLConnection. (More details below.)
>>>>
>>>> Is there a way to pass this information along to coerce when the
>>>> method is generated, or otherwise suppress the Note?
>>> No. Methods are inherited according to rules implied by the class
>>> inheritance; R doesn't allow you to override the inheritance, other than
>>> by being more explicit about the method definition. (It's only a note,
>>> and IMO a relevant one. Be glad the language isn't Dylan, which treats
>>> similar ambiguities as a programming error. :-))
>>>>
>>>> BTW,
>>>> 1/ It would be nice if the Note mentioned what method is generating
>>>> it, in addition to the signature. Debugging for a call several levels
>>>> deep in the stack is already hard enough.
>>> ?? it does, for coerce() which admittedly you have to know is the method
>>> defined for as(thing, "integer") either directly or indirectly. Unless
>>> you mean showing you the whole method definition, but that seems not
>>> relevant to selection.
>>>
>>> If you wanted to see the coerce() method, you need to do
>>> showMethods("coerce"), but I don't think that's relevant. As mentioned,
>>> it's the class hierarchy that matters.
>>>>
>>>> 2/ The note only seems to get generated on the first call and then
>>>> gets suppressed. This will be nice for users, but makes debugging
>>>> harder. Is there a way to prevent suppressing the message?
>>> No. the note is generated when an inherited method is found. That method
>>> is then cached, so the computations required are (fortunately) not
>>> repeated.
>>>
>>> It would be nice to have tools that the package writer could apply to
>>> generate all possible inheritance patterns, and flag possible
>>> ambiguities at package INSTALL time, as opposed to when the package is
>>> used. But it's likely that would generate so many cases unlikely to
>>> occur that the package developer would ignore it, even assuming the
>>> developer was energetic enough to use the tool in the first place.
>>>> o
>>>> 3/ It seems strange that getMethod() cannot find the methods even
>>>> though showMethods() shows it. (See below.)
>>> I think you're confusing getMethod(), which only finds directly defined
>>> methods, with selectMethod() which replicates the inheritance
>>> computations.
>>>
>>> In any case the selection of the method has been specified for you
>>> already.
>>>
>>> John
>>>>
>>>> Paul
>>>> ________
>>>>
>>>> >showMethods("dbGetQuery")
>>>> Function: dbGetQuery (package DBI)
>>>> conn="MySQLConnection", statement="character"
>>>>
>>>> > z <- TSget("Series 1", con, TSrepresentation="timeSeries")
>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>> function "coerce",
>>>> target signature "TSMySQLConnection#integer".
>>>> "dbObjectId#integer" would also be valid
>>>> Loading required package: zoo
>>>>
>>>> Attaching package: ?zoo?
>>>>
>>>> The following object(s) are masked from ?package:timeSeries?:
>>>>
>>>> time<-
>>>>
>>>> The following object(s) are masked from ?package:base?:
>>>>
>>>> as.Date, as.Date.numeric
>>>>
>>>> > showMethods("dbGetQuery")
>>>> Function: dbGetQuery (package DBI)
>>>> conn="MySQLConnection", statement="character"
>>>> conn="TSMySQLConnection", statement="character"
>>>> (inherited from: conn="MySQLConnection", statement="character")
>>>>
>>>> > getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>> statement="character"))
>>>> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>> statement = "character")) :
>>>> No method found for function "dbGetQuery" and signature
>>>> TSMySQLConnection, character
>>>> >
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>


From pgilbert902 at gmail.com  Mon Mar 26 15:23:31 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 26 Mar 2012 09:23:31 -0400
Subject: [Rd] RC / methods package
In-Reply-To: <4F6F8E50.8020407@gmail.com>
References: <4F6E2EC7.2060001@gmail.com> <4F6E62CB.40109@r-project.org>
	<4F6E6A3F.1050104@gmail.com> <4F6F70D1.4040905@r-project.org>
	<4F6F8E50.8020407@gmail.com>
Message-ID: <4F706DD3.2040001@gmail.com>



On 12-03-25 05:29 PM, Paul Gilbert wrote:
> John
>
> Here is the definition of the TSMySQLConnection class, and a few other
> things. This is a simplified example that produces the message, but
> unfortunately will not work unless you have a MySQL database to connect
> to. (I do get the same problem with PostgreSQL, and may with SQLLite,
> but I have not tested the last yet.)
>
> require("methods")
> require("DBI")
> require("RMySQL")
>
> setClassUnion("OptionalPOSIXct", c("POSIXct", "logical"))
> setClass("conType", representation( drv="character"), "VIRTUAL" )
>
> setClass("TSdb", representation( dbname="character",
> hasVintages="logical", hasPanels="logical"), "VIRTUAL" )
>
>
> setClass("TSMySQLConnection", contains=c("MySQLConnection", "conType",
> "TSdb"))
>
>
> setGeneric("TSconnect", def= function(drv, dbname, ...)
> standardGeneric("TSconnect"))
>
>
> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
> definition=function(drv, dbname, ...) {
> con <- dbConnect(drv, dbname=dbname, ...)
> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
> hasVintages=dbExistsTable(con, "vintageAlias"),
> hasPanels =dbExistsTable(con, "panels"))
> })
>
> con <- TSconnect(dbDriver("MySQL"), "test")
>
> dbGetQuery(con, "show tables")
> Note: Method with signature "MySQLConnection#integer" chosen for
> function "coerce",
> target signature "TSMySQLConnection#integer".
> "dbObjectId#integer" would also be valid
> Tables_in_test
> 1 A
> 2 B
>  >
>
> The message also seems to go away, even quitting R and restarting to
> clear the cache, if I change the TSconnect method as follow
>
> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
> definition=function(drv, dbname, ...) {
> con <- dbConnect(drv, dbname=dbname, ...)
> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
> hasVintages=FALSE,
> hasPanels =FALSE)
> })
>
> Why this would happen makes absolutely no sense to me. In the first
> version is dbExistsTable(con, "vintageAlias") left unevaluated in the
> result from new?

This is very strange. With

setMethod("TSconnect",   signature(drv="MySQLDriver", dbname="character"),
    definition=function(drv, dbname, ...) {
         con <- dbConnect(drv, dbname=dbname, ...)
   	hasVintages <- as.logical(dbExistsTable(con, "vintageAlias") )
   	hasPanels   <- as.logical(dbExistsTable(con, "panels") )
	new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
   	       hasVintages=FALSE,
   	       hasPanels  =FALSE)
	})

I get the note, but if I remove the two lines that appear to do nothing:

setMethod("TSconnect",   signature(drv="MySQLDriver", dbname="character"),
    definition=function(drv, dbname, ...) {
         con <- dbConnect(drv, dbname=dbname, ...)
	new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
   	       hasVintages=FALSE,
   	       hasPanels  =FALSE)
	})

I no longer get the note. I am restarting R each time to be sure nothing 
is cached.

[ R version 2.15.0 RC (2012-03-25 r58832) ]

Paul

>
> As you can tell, I'm struggling a bit with interpreting the information
> from the note. Also, if it were a warning I could set it to stop, and
> then traceback to what was causing the problem. As it is, it took me a
> fairly long time just to get the fact that the call to dbGetQuery() was
> generating the message. And caching the methods may be good for
> performance, but when things change the second time you call them it
> sure makes debugging difficult.
>
> Best,
> Paul
>
>
> On 12-03-25 03:24 PM, John Chambers wrote:
>> On 3/24/12 5:43 PM, Paul Gilbert wrote:
>>>
>>>
>>> On 12-03-24 08:11 PM, John Chambers wrote:
>>>>
>>>>
>>>> On 3/24/12 1:29 PM, Paul Gilbert wrote:
>>>>> (I think this is being caused by the new methods package in RC.)
>>>> Possibly, but the methods package isn't particularly "new" in its
>>>> method
>>>> selection.
>>>>
>>>> We need to see the definition of the class.
>>>
>>> Is there a way to know which class it is that we need to see the
>>> definition for?
>>
>> It's in the note: 'target signature "TSMySQLConnection#integer"'. In
>> functional OOP with multiple dispatch, it's all the classes that matter
>> in general, but in this and most cases, one class is likely the relevant
>> one: "TSMySQLConnection". That was why I said what I did before.
>>
>> (We could go to a bit more effort and back-translate the dispatch string
>> "TSMySQLConnection#integer" into the corresponding formal arguments.
>> Would be more natural with the INSTALL time tool I mentioned before.
>> That's the real challenge here -- to give information about this to the
>> package developer, not the poor user.)
>>
>> John
>>
>>>
>>> Paul
>>>
>>>> The note implies that it
>>>> inherits from both "MySQLConnection" and "dbObjectId", both of which
>>>> have methods for coercing to "integer". Hence the ambiguity.
>>>>>
>>>>> In the RC (March 24) some of my packages are generating a Note
>>>>>
>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>> function "coerce",
>>>>> target signature "TSMySQLConnection#integer".
>>>>> "dbObjectId#integer" would also be valid
>>>>>
>>>>> This is coming from a call to dbGetQuery() in package DBI. The method
>>>>> with the signature "TSMySQLConnection#integer" is generated
>>>>> automatically because TSMySQLConnection inherits from
>>>>> MySQLConnection. (More details below.)
>>>>>
>>>>> Is there a way to pass this information along to coerce when the
>>>>> method is generated, or otherwise suppress the Note?
>>>> No. Methods are inherited according to rules implied by the class
>>>> inheritance; R doesn't allow you to override the inheritance, other
>>>> than
>>>> by being more explicit about the method definition. (It's only a note,
>>>> and IMO a relevant one. Be glad the language isn't Dylan, which treats
>>>> similar ambiguities as a programming error. :-))
>>>>>
>>>>> BTW,
>>>>> 1/ It would be nice if the Note mentioned what method is generating
>>>>> it, in addition to the signature. Debugging for a call several levels
>>>>> deep in the stack is already hard enough.
>>>> ?? it does, for coerce() which admittedly you have to know is the
>>>> method
>>>> defined for as(thing, "integer") either directly or indirectly. Unless
>>>> you mean showing you the whole method definition, but that seems not
>>>> relevant to selection.
>>>>
>>>> If you wanted to see the coerce() method, you need to do
>>>> showMethods("coerce"), but I don't think that's relevant. As mentioned,
>>>> it's the class hierarchy that matters.
>>>>>
>>>>> 2/ The note only seems to get generated on the first call and then
>>>>> gets suppressed. This will be nice for users, but makes debugging
>>>>> harder. Is there a way to prevent suppressing the message?
>>>> No. the note is generated when an inherited method is found. That
>>>> method
>>>> is then cached, so the computations required are (fortunately) not
>>>> repeated.
>>>>
>>>> It would be nice to have tools that the package writer could apply to
>>>> generate all possible inheritance patterns, and flag possible
>>>> ambiguities at package INSTALL time, as opposed to when the package is
>>>> used. But it's likely that would generate so many cases unlikely to
>>>> occur that the package developer would ignore it, even assuming the
>>>> developer was energetic enough to use the tool in the first place.
>>>>> o
>>>>> 3/ It seems strange that getMethod() cannot find the methods even
>>>>> though showMethods() shows it. (See below.)
>>>> I think you're confusing getMethod(), which only finds directly defined
>>>> methods, with selectMethod() which replicates the inheritance
>>>> computations.
>>>>
>>>> In any case the selection of the method has been specified for you
>>>> already.
>>>>
>>>> John
>>>>>
>>>>> Paul
>>>>> ________
>>>>>
>>>>> >showMethods("dbGetQuery")
>>>>> Function: dbGetQuery (package DBI)
>>>>> conn="MySQLConnection", statement="character"
>>>>>
>>>>> > z <- TSget("Series 1", con, TSrepresentation="timeSeries")
>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>> function "coerce",
>>>>> target signature "TSMySQLConnection#integer".
>>>>> "dbObjectId#integer" would also be valid
>>>>> Loading required package: zoo
>>>>>
>>>>> Attaching package: ?zoo?
>>>>>
>>>>> The following object(s) are masked from ?package:timeSeries?:
>>>>>
>>>>> time<-
>>>>>
>>>>> The following object(s) are masked from ?package:base?:
>>>>>
>>>>> as.Date, as.Date.numeric
>>>>>
>>>>> > showMethods("dbGetQuery")
>>>>> Function: dbGetQuery (package DBI)
>>>>> conn="MySQLConnection", statement="character"
>>>>> conn="TSMySQLConnection", statement="character"
>>>>> (inherited from: conn="MySQLConnection", statement="character")
>>>>>
>>>>> > getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>> statement="character"))
>>>>> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>> statement = "character")) :
>>>>> No method found for function "dbGetQuery" and signature
>>>>> TSMySQLConnection, character
>>>>> >
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>


From spluque at gmail.com  Mon Mar 26 17:34:57 2012
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 26 Mar 2012 10:34:57 -0500
Subject: [Rd] bzip2'ed data under data/
In-Reply-To: <4F6A1F63.807@stats.ox.ac.uk> (Brian Ripley's message of "Wed, 21
	Mar 2012 18:35:15 +0000")
References: <877gygtk27.fsf@kolob.subpolar.dyndns.org>
	<4F6A1F63.807@stats.ox.ac.uk>
Message-ID: <87wr67pe8u.fsf@kolob.subpolar.dyndns.org>

On Wed, 21 Mar 2012 18:35:15 +0000,
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 19/03/2012 20:25, Sebastian P. Luque wrote:
>> Hi,

>> R CMD check PACKAGE_VERSION_tar.gz gives warning:

>> Files not of a type allowed in a ?data? directory: ?tser1.csv.bz2?
>> ?tser2.csv.bz2? Please use e.g. ?inst/extdata? for non-R data files

>> which I didn't expect, based on section 1.1.5 (Data in packages) of
>> the Writing R Extensions manual:

>> Tables (`.tab', `.txt', or `.csv' files) can be compressed by `gzip',
>> `bzip2' or `xz', optionally with additional extension `.gz', `.bz2'
>> or `.xz'.  However, such files can only be used with R 2.10.0 or
>> later, and so the package should have an appropriate `Depends' entry
>> in its DESCRIPTION file.

>> In this case, I have a Depends: R (>= 2.13.0), and the package was
>> built with R version 2.15.0 beta (2012-03-16 r58769), Platform:
>> x86_64-pc-linux-gnu (64-bit), so I don't understand the warning.

>> Cheers,


> Well, the extension is allowed 'optionally' to be .csv.bz2, but that
> does not make it good practice and I would suggest not using it.

Does this mean we can still compress the files, but leave the file name
with suffix *.csv (i.e. not adding the compression-specific suffix)?
The 2 files I'm including in the package are a little over 1 Mb, and
bzip2 gets them down to < 150 Kb.


> But that 'check' picked it up was a typo in the code 'check' used to
> specify types of data() files, corrected since your build of R so I
> would expect current R-devel or R-pre-release not to give the NOTE.  I
> am not sure whether or not that has any ramifications for users of the
> package with older versions of R, but we know calling the compressed
> file foo.csv would work.

Up to R 2.14.2, R CMD check was reporting a Warning, rather than a Note,
but indeed the latest R-devel and R-pre-release don't.  Thanks.

Cheers,

-- 
Seb


From ripley at stats.ox.ac.uk  Mon Mar 26 17:44:58 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Mar 2012 16:44:58 +0100
Subject: [Rd] bzip2'ed data under data/
In-Reply-To: <87wr67pe8u.fsf@kolob.subpolar.dyndns.org>
References: <877gygtk27.fsf@kolob.subpolar.dyndns.org>
	<4F6A1F63.807@stats.ox.ac.uk>
	<87wr67pe8u.fsf@kolob.subpolar.dyndns.org>
Message-ID: <4F708EFA.50502@stats.ox.ac.uk>

On 26/03/2012 16:34, Sebastian P. Luque wrote:
> On Wed, 21 Mar 2012 18:35:15 +0000,
> Prof Brian Ripley<ripley at stats.ox.ac.uk>  wrote:
>
>> On 19/03/2012 20:25, Sebastian P. Luque wrote:
>>> Hi,
>
>>> R CMD check PACKAGE_VERSION_tar.gz gives warning:
>
>>> Files not of a type allowed in a ?data? directory: ?tser1.csv.bz2?
>>> ?tser2.csv.bz2? Please use e.g. ?inst/extdata? for non-R data files
>
>>> which I didn't expect, based on section 1.1.5 (Data in packages) of
>>> the Writing R Extensions manual:
>
>>> Tables (`.tab', `.txt', or `.csv' files) can be compressed by `gzip',
>>> `bzip2' or `xz', optionally with additional extension `.gz', `.bz2'
>>> or `.xz'.  However, such files can only be used with R 2.10.0 or
>>> later, and so the package should have an appropriate `Depends' entry
>>> in its DESCRIPTION file.
>
>>> In this case, I have a Depends: R (>= 2.13.0), and the package was
>>> built with R version 2.15.0 beta (2012-03-16 r58769), Platform:
>>> x86_64-pc-linux-gnu (64-bit), so I don't understand the warning.
>
>>> Cheers,
>
>
>> Well, the extension is allowed 'optionally' to be .csv.bz2, but that
>> does not make it good practice and I would suggest not using it.
>
> Does this mean we can still compress the files, but leave the file name
> with suffix *.csv (i.e. not adding the compression-specific suffix)?
> The 2 files I'm including in the package are a little over 1 Mb, and
> bzip2 gets them down to<  150 Kb.

Yes, that is what the help file says.
>
>> But that 'check' picked it up was a typo in the code 'check' used to
>> specify types of data() files, corrected since your build of R so I
>> would expect current R-devel or R-pre-release not to give the NOTE.  I
>> am not sure whether or not that has any ramifications for users of the
>> package with older versions of R, but we know calling the compressed
>> file foo.csv would work.
>
> Up to R 2.14.2, R CMD check was reporting a Warning, rather than a Note,
> but indeed the latest R-devel and R-pre-release don't.  Thanks.
>
> Cheers,
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spluque at gmail.com  Mon Mar 26 20:23:42 2012
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 26 Mar 2012 13:23:42 -0500
Subject: [Rd] bzip2'ed data under data/
In-Reply-To: <4F708EFA.50502@stats.ox.ac.uk> (Brian Ripley's message of "Mon, 
	26 Mar 2012 16:44:58 +0100")
References: <877gygtk27.fsf@kolob.subpolar.dyndns.org>
	<4F6A1F63.807@stats.ox.ac.uk>
	<87wr67pe8u.fsf@kolob.subpolar.dyndns.org>
	<4F708EFA.50502@stats.ox.ac.uk>
Message-ID: <87k427p6fl.fsf@kolob.subpolar.dyndns.org>

On Mon, 26 Mar 2012 16:44:58 +0100,
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

[...]

>>> Well, the extension is allowed 'optionally' to be .csv.bz2, but that
>>> does not make it good practice and I would suggest not using it.

>> Does this mean we can still compress the files, but leave the file
>> name with suffix *.csv (i.e. not adding the compression-specific
>> suffix)?  The 2 files I'm including in the package are a little over
>> 1 Mb, and bzip2 gets them down to< 150 Kb.

> Yes, that is what the help file says.

If I do that, however, R CMD build builds the package adding the .gz
suffix to these files (i.e. I end up with data/*.csv.gz), presumably
because --resave-data is the default, which uses gzip, provided no
BuildResaveData field is present in DESCRIPTION.  Adding
"BuildResaveData: no" to DESCRIPTION solves this.  For package
maintenance it might be easier to leave the uncompressed data/*.csv and
add "BuildResaveData: bzip2" to DESCRIPTION, but then R CMD build
generates data/*.csv.xz with R-devel (2012-03-22 r58801), so something
seems wrong.  Should we simply stick to doing the compression manually
and adding "BuildResaveData: no" to DESCRIPTION?

Thanks,

-- 
Seb


From michael.weylandt at gmail.com  Mon Mar 26 20:29:31 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 26 Mar 2012 14:29:31 -0400
Subject: [Rd] Typo in ?Logistic
Message-ID: <CAAmySGNuk3yzH_JnGGJoLm9XCbGg+HDLxn9_XRQxnvk=EhvP_Q@mail.gmail.com>

In the source section of ?rlogis, we see:

Source:

     ?[dpr]logis? are calculated directly from the definitions.

     ?rlogis? uses inversion.

Should that read "[dpq]logis" instead?

Michael


From jmc at r-project.org  Mon Mar 26 20:47:06 2012
From: jmc at r-project.org (John Chambers)
Date: Mon, 26 Mar 2012 11:47:06 -0700
Subject: [Rd] RC / methods package
In-Reply-To: <4F706DD3.2040001@gmail.com>
References: <4F6E2EC7.2060001@gmail.com> <4F6E62CB.40109@r-project.org>
	<4F6E6A3F.1050104@gmail.com> <4F6F70D1.4040905@r-project.org>
	<4F6F8E50.8020407@gmail.com> <4F706DD3.2040001@gmail.com>
Message-ID: <4F70B9AA.9040608@r-project.org>

This direction is perhaps adding to the confusion rather than reducing it.

Let's go back to the original note:

Note: Method with signature "MySQLConnection#integer" chosen for 
function "coerce",
  target signature "TSMySQLConnection#integer".
  "dbObjectId#integer" would also be valid

The purpose of the note is just to make you (the programmer) aware that 
in fact two methods are available for coercing from "TSMySQLConnection" 
to "integer".  Which do you want, if either?

If it's not the one from "MySQLConnection" then one needs to say 
explicitly what it should be.  In any case, being explicit would remove 
the note, if that's what is bothering people.

The "coerce" generic is abnormal, in that its methods are rarely 
specified directly, but via a setAs() call and it's never invoked 
directly, but rather from an as(thing, "integer")--this may in part be 
why the behavior is confusing.

If you have an example that produces the note, the relevant methods can 
be examined by following that example with
   getMethod("coerce", c("MySQLConnection","integer"))
   getMethod("coerce", c("dbObject","integer"))
You DO have to wait until the note is produced because the as() 
calculations may install methods for coerce() in response to particular 
calls.

Then it's likely you want to insert a
   setAs("TSMySQLConnection", "integer", ....)
into the package that defines "TSMySQLConnection", with the chosen 
definition.

Just to repeat:  This is a "Note" and doesn't necessarily indicate a 
bug.  It's in the nature of functional OOP with multiple dispatch that 
there can be multiple eligible methods.  It may or may not matter which 
is chosen, and one can't guarantee that any automatic selection will get 
the "right" one.  It's nearly always helpful to be as specific as 
possible where ambiguities do exist.

John

On 3/26/12 6:23 AM, Paul Gilbert wrote:
>
>
> On 12-03-25 05:29 PM, Paul Gilbert wrote:
>> John
>>
>> Here is the definition of the TSMySQLConnection class, and a few other
>> things. This is a simplified example that produces the message, but
>> unfortunately will not work unless you have a MySQL database to connect
>> to. (I do get the same problem with PostgreSQL, and may with SQLLite,
>> but I have not tested the last yet.)
>>
>> require("methods")
>> require("DBI")
>> require("RMySQL")
>>
>> setClassUnion("OptionalPOSIXct", c("POSIXct", "logical"))
>> setClass("conType", representation( drv="character"), "VIRTUAL" )
>>
>> setClass("TSdb", representation( dbname="character",
>> hasVintages="logical", hasPanels="logical"), "VIRTUAL" )
>>
>>
>> setClass("TSMySQLConnection", contains=c("MySQLConnection", "conType",
>> "TSdb"))
>>
>>
>> setGeneric("TSconnect", def= function(drv, dbname, ...)
>> standardGeneric("TSconnect"))
>>
>>
>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>> definition=function(drv, dbname, ...) {
>> con <- dbConnect(drv, dbname=dbname, ...)
>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>> hasVintages=dbExistsTable(con, "vintageAlias"),
>> hasPanels =dbExistsTable(con, "panels"))
>> })
>>
>> con <- TSconnect(dbDriver("MySQL"), "test")
>>
>> dbGetQuery(con, "show tables")
>> Note: Method with signature "MySQLConnection#integer" chosen for
>> function "coerce",
>> target signature "TSMySQLConnection#integer".
>> "dbObjectId#integer" would also be valid
>> Tables_in_test
>> 1 A
>> 2 B
>> >
>>
>> The message also seems to go away, even quitting R and restarting to
>> clear the cache, if I change the TSconnect method as follow
>>
>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>> definition=function(drv, dbname, ...) {
>> con <- dbConnect(drv, dbname=dbname, ...)
>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>> hasVintages=FALSE,
>> hasPanels =FALSE)
>> })
>>
>> Why this would happen makes absolutely no sense to me. In the first
>> version is dbExistsTable(con, "vintageAlias") left unevaluated in the
>> result from new?
>
> This is very strange. With
>
> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
> definition=function(drv, dbname, ...) {
> con <- dbConnect(drv, dbname=dbname, ...)
> hasVintages <- as.logical(dbExistsTable(con, "vintageAlias") )
> hasPanels <- as.logical(dbExistsTable(con, "panels") )
> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
> hasVintages=FALSE,
> hasPanels =FALSE)
> })
>
> I get the note, but if I remove the two lines that appear to do nothing:
>
> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
> definition=function(drv, dbname, ...) {
> con <- dbConnect(drv, dbname=dbname, ...)
> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
> hasVintages=FALSE,
> hasPanels =FALSE)
> })
>
> I no longer get the note. I am restarting R each time to be sure nothing
> is cached.
>
> [ R version 2.15.0 RC (2012-03-25 r58832) ]
>
> Paul
>
>>
>> As you can tell, I'm struggling a bit with interpreting the information
>> from the note. Also, if it were a warning I could set it to stop, and
>> then traceback to what was causing the problem. As it is, it took me a
>> fairly long time just to get the fact that the call to dbGetQuery() was
>> generating the message. And caching the methods may be good for
>> performance, but when things change the second time you call them it
>> sure makes debugging difficult.
>>
>> Best,
>> Paul
>>
>>
>> On 12-03-25 03:24 PM, John Chambers wrote:
>>> On 3/24/12 5:43 PM, Paul Gilbert wrote:
>>>>
>>>>
>>>> On 12-03-24 08:11 PM, John Chambers wrote:
>>>>>
>>>>>
>>>>> On 3/24/12 1:29 PM, Paul Gilbert wrote:
>>>>>> (I think this is being caused by the new methods package in RC.)
>>>>> Possibly, but the methods package isn't particularly "new" in its
>>>>> method
>>>>> selection.
>>>>>
>>>>> We need to see the definition of the class.
>>>>
>>>> Is there a way to know which class it is that we need to see the
>>>> definition for?
>>>
>>> It's in the note: 'target signature "TSMySQLConnection#integer"'. In
>>> functional OOP with multiple dispatch, it's all the classes that matter
>>> in general, but in this and most cases, one class is likely the relevant
>>> one: "TSMySQLConnection". That was why I said what I did before.
>>>
>>> (We could go to a bit more effort and back-translate the dispatch string
>>> "TSMySQLConnection#integer" into the corresponding formal arguments.
>>> Would be more natural with the INSTALL time tool I mentioned before.
>>> That's the real challenge here -- to give information about this to the
>>> package developer, not the poor user.)
>>>
>>> John
>>>
>>>>
>>>> Paul
>>>>
>>>>> The note implies that it
>>>>> inherits from both "MySQLConnection" and "dbObjectId", both of which
>>>>> have methods for coercing to "integer". Hence the ambiguity.
>>>>>>
>>>>>> In the RC (March 24) some of my packages are generating a Note
>>>>>>
>>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>>> function "coerce",
>>>>>> target signature "TSMySQLConnection#integer".
>>>>>> "dbObjectId#integer" would also be valid
>>>>>>
>>>>>> This is coming from a call to dbGetQuery() in package DBI. The method
>>>>>> with the signature "TSMySQLConnection#integer" is generated
>>>>>> automatically because TSMySQLConnection inherits from
>>>>>> MySQLConnection. (More details below.)
>>>>>>
>>>>>> Is there a way to pass this information along to coerce when the
>>>>>> method is generated, or otherwise suppress the Note?
>>>>> No. Methods are inherited according to rules implied by the class
>>>>> inheritance; R doesn't allow you to override the inheritance, other
>>>>> than
>>>>> by being more explicit about the method definition. (It's only a note,
>>>>> and IMO a relevant one. Be glad the language isn't Dylan, which treats
>>>>> similar ambiguities as a programming error. :-))
>>>>>>
>>>>>> BTW,
>>>>>> 1/ It would be nice if the Note mentioned what method is generating
>>>>>> it, in addition to the signature. Debugging for a call several levels
>>>>>> deep in the stack is already hard enough.
>>>>> ?? it does, for coerce() which admittedly you have to know is the
>>>>> method
>>>>> defined for as(thing, "integer") either directly or indirectly. Unless
>>>>> you mean showing you the whole method definition, but that seems not
>>>>> relevant to selection.
>>>>>
>>>>> If you wanted to see the coerce() method, you need to do
>>>>> showMethods("coerce"), but I don't think that's relevant. As
>>>>> mentioned,
>>>>> it's the class hierarchy that matters.
>>>>>>
>>>>>> 2/ The note only seems to get generated on the first call and then
>>>>>> gets suppressed. This will be nice for users, but makes debugging
>>>>>> harder. Is there a way to prevent suppressing the message?
>>>>> No. the note is generated when an inherited method is found. That
>>>>> method
>>>>> is then cached, so the computations required are (fortunately) not
>>>>> repeated.
>>>>>
>>>>> It would be nice to have tools that the package writer could apply to
>>>>> generate all possible inheritance patterns, and flag possible
>>>>> ambiguities at package INSTALL time, as opposed to when the package is
>>>>> used. But it's likely that would generate so many cases unlikely to
>>>>> occur that the package developer would ignore it, even assuming the
>>>>> developer was energetic enough to use the tool in the first place.
>>>>>> o
>>>>>> 3/ It seems strange that getMethod() cannot find the methods even
>>>>>> though showMethods() shows it. (See below.)
>>>>> I think you're confusing getMethod(), which only finds directly
>>>>> defined
>>>>> methods, with selectMethod() which replicates the inheritance
>>>>> computations.
>>>>>
>>>>> In any case the selection of the method has been specified for you
>>>>> already.
>>>>>
>>>>> John
>>>>>>
>>>>>> Paul
>>>>>> ________
>>>>>>
>>>>>> >showMethods("dbGetQuery")
>>>>>> Function: dbGetQuery (package DBI)
>>>>>> conn="MySQLConnection", statement="character"
>>>>>>
>>>>>> > z <- TSget("Series 1", con, TSrepresentation="timeSeries")
>>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>>> function "coerce",
>>>>>> target signature "TSMySQLConnection#integer".
>>>>>> "dbObjectId#integer" would also be valid
>>>>>> Loading required package: zoo
>>>>>>
>>>>>> Attaching package: ?zoo?
>>>>>>
>>>>>> The following object(s) are masked from ?package:timeSeries?:
>>>>>>
>>>>>> time<-
>>>>>>
>>>>>> The following object(s) are masked from ?package:base?:
>>>>>>
>>>>>> as.Date, as.Date.numeric
>>>>>>
>>>>>> > showMethods("dbGetQuery")
>>>>>> Function: dbGetQuery (package DBI)
>>>>>> conn="MySQLConnection", statement="character"
>>>>>> conn="TSMySQLConnection", statement="character"
>>>>>> (inherited from: conn="MySQLConnection", statement="character")
>>>>>>
>>>>>> > getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>>> statement="character"))
>>>>>> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>>> statement = "character")) :
>>>>>> No method found for function "dbGetQuery" and signature
>>>>>> TSMySQLConnection, character
>>>>>> >
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pgilbert902 at gmail.com  Mon Mar 26 22:44:36 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 26 Mar 2012 16:44:36 -0400
Subject: [Rd] RC / methods package
In-Reply-To: <4F70B9AA.9040608@r-project.org>
References: <4F6E2EC7.2060001@gmail.com> <4F6E62CB.40109@r-project.org>
	<4F6E6A3F.1050104@gmail.com> <4F6F70D1.4040905@r-project.org>
	<4F6F8E50.8020407@gmail.com> <4F706DD3.2040001@gmail.com>
	<4F70B9AA.9040608@r-project.org>
Message-ID: <4F70D534.70903@gmail.com>



On 12-03-26 02:47 PM, John Chambers wrote:
> This direction is perhaps adding to the confusion rather than reducing it.
>
> Let's go back to the original note:
>
> Note: Method with signature "MySQLConnection#integer" chosen for
> function "coerce",
> target signature "TSMySQLConnection#integer".
> "dbObjectId#integer" would also be valid
>
> The purpose of the note is just to make you (the programmer) aware that
> in fact two methods are available for coercing from "TSMySQLConnection"
> to "integer". Which do you want, if either?
>
> If it's not the one from "MySQLConnection" then one needs to say
> explicitly what it should be. In any case, being explicit would remove
> the note, if that's what is bothering people.
>
> The "coerce" generic is abnormal, in that its methods are rarely
> specified directly, but via a setAs() call and it's never invoked
> directly, but rather from an as(thing, "integer")--this may in part be
> why the behavior is confusing.
>
> If you have an example that produces the note, the relevant methods can
> be examined by following that example with
> getMethod("coerce", c("MySQLConnection","integer"))
> getMethod("coerce", c("dbObject","integer"))
> You DO have to wait until the note is produced because the as()
> calculations may install methods for coerce() in response to particular
> calls.
>
> Then it's likely you want to insert a
> setAs("TSMySQLConnection", "integer", ....)
> into the package that defines "TSMySQLConnection", with the chosen
> definition.

Ok, if I understand correctly, when my code made the call to 
dbExistsTable(), a method for "coerce" with signature 
c("MySQLConnection","integer") was automatically generated. I can see 
that when I do showMethods("coerce"):

from="MySQLConnection", to="integer"
   (inherited from: from="dbObjectId", to="integer")

and also from looking at the RMySQL package source and seeing that
    setAs("MySQLConnection", "integer", ....)
has not been done.

Then when I execute

   dbGetQuery(con, "show tables")

the note reflects that it has to choose between the automatically 
generated one and the one that the automatically generated one was 
inherited from, so there is an ambiguity. If I do not do dbExistsTable() 
first, then the automatically generated one has not been generated yet, 
so there is no ambiguity and I do not get the note.

I can prevent getting the note by using

    setAs("TSMySQLConnection", "integer",
   def=getMethod("coerce", c("dbObjectId","integer")))

in my package. It make sense to specify the original rather than the 
automatically generated one, but I am still a bit confused why the note 
says it is using the automatically generated one, but if I try to set 
that one explicitly I get an error:

 > dbGetQuery(con, "show tables")
Note: Method with signature "MySQLConnection#integer" chosen for 
function "coerce",
  target signature "TSMySQLConnection#integer".
  "dbObjectId#integer" would also be valid
    Tables_in_test
1               A
2               B

 > setAs("TSMySQLConnection", "integer",
+   def=getMethod("coerce", c("MySQLConnection","integer")))
Error in getMethod("coerce", c("MySQLConnection", "integer")) :
   No method found for function "coerce" and signature MySQLConnection, 
integer
 >
(A this point I think I have a fix, so this is just for my general 
understanding.)

> Just to repeat: This is a "Note" and doesn't necessarily indicate a bug.

Even though in my case either would have worked, my feeling is that 
there could be cases where it is a problem, so package developers should 
be using setAs() explicitly to reduce ambiguities, as you say. And 
because of this you should be issuing a warning not just a note. And, if 
you do issue a warning, then that makes it a bug in my package, so I 
want to fix it.

Thanks again,
Paul

> It's in the nature of functional OOP with multiple dispatch that there
> can be multiple eligible methods. It may or may not matter which is
> chosen, and one can't guarantee that any automatic selection will get
> the "right" one. It's nearly always helpful to be as specific as
> possible where ambiguities do exist.
>
> John
>
> On 3/26/12 6:23 AM, Paul Gilbert wrote:
>>
>>
>> On 12-03-25 05:29 PM, Paul Gilbert wrote:
>>> John
>>>
>>> Here is the definition of the TSMySQLConnection class, and a few other
>>> things. This is a simplified example that produces the message, but
>>> unfortunately will not work unless you have a MySQL database to connect
>>> to. (I do get the same problem with PostgreSQL, and may with SQLLite,
>>> but I have not tested the last yet.)
>>>
>>> require("methods")
>>> require("DBI")
>>> require("RMySQL")
>>>
>>> setClassUnion("OptionalPOSIXct", c("POSIXct", "logical"))
>>> setClass("conType", representation( drv="character"), "VIRTUAL" )
>>>
>>> setClass("TSdb", representation( dbname="character",
>>> hasVintages="logical", hasPanels="logical"), "VIRTUAL" )
>>>
>>>
>>> setClass("TSMySQLConnection", contains=c("MySQLConnection", "conType",
>>> "TSdb"))
>>>
>>>
>>> setGeneric("TSconnect", def= function(drv, dbname, ...)
>>> standardGeneric("TSconnect"))
>>>
>>>
>>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>>> definition=function(drv, dbname, ...) {
>>> con <- dbConnect(drv, dbname=dbname, ...)
>>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>>> hasVintages=dbExistsTable(con, "vintageAlias"),
>>> hasPanels =dbExistsTable(con, "panels"))
>>> })
>>>
>>> con <- TSconnect(dbDriver("MySQL"), "test")
>>>
>>> dbGetQuery(con, "show tables")
>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>> function "coerce",
>>> target signature "TSMySQLConnection#integer".
>>> "dbObjectId#integer" would also be valid
>>> Tables_in_test
>>> 1 A
>>> 2 B
>>> >
>>>
>>> The message also seems to go away, even quitting R and restarting to
>>> clear the cache, if I change the TSconnect method as follow
>>>
>>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>>> definition=function(drv, dbname, ...) {
>>> con <- dbConnect(drv, dbname=dbname, ...)
>>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>>> hasVintages=FALSE,
>>> hasPanels =FALSE)
>>> })
>>>
>>> Why this would happen makes absolutely no sense to me. In the first
>>> version is dbExistsTable(con, "vintageAlias") left unevaluated in the
>>> result from new?
>>
>> This is very strange. With
>>
>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>> definition=function(drv, dbname, ...) {
>> con <- dbConnect(drv, dbname=dbname, ...)
>> hasVintages <- as.logical(dbExistsTable(con, "vintageAlias") )
>> hasPanels <- as.logical(dbExistsTable(con, "panels") )
>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>> hasVintages=FALSE,
>> hasPanels =FALSE)
>> })
>>
>> I get the note, but if I remove the two lines that appear to do nothing:
>>
>> setMethod("TSconnect", signature(drv="MySQLDriver", dbname="character"),
>> definition=function(drv, dbname, ...) {
>> con <- dbConnect(drv, dbname=dbname, ...)
>> new("TSMySQLConnection" , con, drv="MySQL", dbname=dbname,
>> hasVintages=FALSE,
>> hasPanels =FALSE)
>> })
>>
>> I no longer get the note. I am restarting R each time to be sure nothing
>> is cached.
>>
>> [ R version 2.15.0 RC (2012-03-25 r58832) ]
>>
>> Paul
>>
>>>
>>> As you can tell, I'm struggling a bit with interpreting the information
>>> from the note. Also, if it were a warning I could set it to stop, and
>>> then traceback to what was causing the problem. As it is, it took me a
>>> fairly long time just to get the fact that the call to dbGetQuery() was
>>> generating the message. And caching the methods may be good for
>>> performance, but when things change the second time you call them it
>>> sure makes debugging difficult.
>>>
>>> Best,
>>> Paul
>>>
>>>
>>> On 12-03-25 03:24 PM, John Chambers wrote:
>>>> On 3/24/12 5:43 PM, Paul Gilbert wrote:
>>>>>
>>>>>
>>>>> On 12-03-24 08:11 PM, John Chambers wrote:
>>>>>>
>>>>>>
>>>>>> On 3/24/12 1:29 PM, Paul Gilbert wrote:
>>>>>>> (I think this is being caused by the new methods package in RC.)
>>>>>> Possibly, but the methods package isn't particularly "new" in its
>>>>>> method
>>>>>> selection.
>>>>>>
>>>>>> We need to see the definition of the class.
>>>>>
>>>>> Is there a way to know which class it is that we need to see the
>>>>> definition for?
>>>>
>>>> It's in the note: 'target signature "TSMySQLConnection#integer"'. In
>>>> functional OOP with multiple dispatch, it's all the classes that matter
>>>> in general, but in this and most cases, one class is likely the
>>>> relevant
>>>> one: "TSMySQLConnection". That was why I said what I did before.
>>>>
>>>> (We could go to a bit more effort and back-translate the dispatch
>>>> string
>>>> "TSMySQLConnection#integer" into the corresponding formal arguments.
>>>> Would be more natural with the INSTALL time tool I mentioned before.
>>>> That's the real challenge here -- to give information about this to the
>>>> package developer, not the poor user.)
>>>>
>>>> John
>>>>
>>>>>
>>>>> Paul
>>>>>
>>>>>> The note implies that it
>>>>>> inherits from both "MySQLConnection" and "dbObjectId", both of which
>>>>>> have methods for coercing to "integer". Hence the ambiguity.
>>>>>>>
>>>>>>> In the RC (March 24) some of my packages are generating a Note
>>>>>>>
>>>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>>>> function "coerce",
>>>>>>> target signature "TSMySQLConnection#integer".
>>>>>>> "dbObjectId#integer" would also be valid
>>>>>>>
>>>>>>> This is coming from a call to dbGetQuery() in package DBI. The
>>>>>>> method
>>>>>>> with the signature "TSMySQLConnection#integer" is generated
>>>>>>> automatically because TSMySQLConnection inherits from
>>>>>>> MySQLConnection. (More details below.)
>>>>>>>
>>>>>>> Is there a way to pass this information along to coerce when the
>>>>>>> method is generated, or otherwise suppress the Note?
>>>>>> No. Methods are inherited according to rules implied by the class
>>>>>> inheritance; R doesn't allow you to override the inheritance, other
>>>>>> than
>>>>>> by being more explicit about the method definition. (It's only a
>>>>>> note,
>>>>>> and IMO a relevant one. Be glad the language isn't Dylan, which
>>>>>> treats
>>>>>> similar ambiguities as a programming error. :-))
>>>>>>>
>>>>>>> BTW,
>>>>>>> 1/ It would be nice if the Note mentioned what method is generating
>>>>>>> it, in addition to the signature. Debugging for a call several
>>>>>>> levels
>>>>>>> deep in the stack is already hard enough.
>>>>>> ?? it does, for coerce() which admittedly you have to know is the
>>>>>> method
>>>>>> defined for as(thing, "integer") either directly or indirectly.
>>>>>> Unless
>>>>>> you mean showing you the whole method definition, but that seems not
>>>>>> relevant to selection.
>>>>>>
>>>>>> If you wanted to see the coerce() method, you need to do
>>>>>> showMethods("coerce"), but I don't think that's relevant. As
>>>>>> mentioned,
>>>>>> it's the class hierarchy that matters.
>>>>>>>
>>>>>>> 2/ The note only seems to get generated on the first call and then
>>>>>>> gets suppressed. This will be nice for users, but makes debugging
>>>>>>> harder. Is there a way to prevent suppressing the message?
>>>>>> No. the note is generated when an inherited method is found. That
>>>>>> method
>>>>>> is then cached, so the computations required are (fortunately) not
>>>>>> repeated.
>>>>>>
>>>>>> It would be nice to have tools that the package writer could apply to
>>>>>> generate all possible inheritance patterns, and flag possible
>>>>>> ambiguities at package INSTALL time, as opposed to when the
>>>>>> package is
>>>>>> used. But it's likely that would generate so many cases unlikely to
>>>>>> occur that the package developer would ignore it, even assuming the
>>>>>> developer was energetic enough to use the tool in the first place.
>>>>>>> o
>>>>>>> 3/ It seems strange that getMethod() cannot find the methods even
>>>>>>> though showMethods() shows it. (See below.)
>>>>>> I think you're confusing getMethod(), which only finds directly
>>>>>> defined
>>>>>> methods, with selectMethod() which replicates the inheritance
>>>>>> computations.
>>>>>>
>>>>>> In any case the selection of the method has been specified for you
>>>>>> already.
>>>>>>
>>>>>> John
>>>>>>>
>>>>>>> Paul
>>>>>>> ________
>>>>>>>
>>>>>>> >showMethods("dbGetQuery")
>>>>>>> Function: dbGetQuery (package DBI)
>>>>>>> conn="MySQLConnection", statement="character"
>>>>>>>
>>>>>>> > z <- TSget("Series 1", con, TSrepresentation="timeSeries")
>>>>>>> Note: Method with signature "MySQLConnection#integer" chosen for
>>>>>>> function "coerce",
>>>>>>> target signature "TSMySQLConnection#integer".
>>>>>>> "dbObjectId#integer" would also be valid
>>>>>>> Loading required package: zoo
>>>>>>>
>>>>>>> Attaching package: ?zoo?
>>>>>>>
>>>>>>> The following object(s) are masked from ?package:timeSeries?:
>>>>>>>
>>>>>>> time<-
>>>>>>>
>>>>>>> The following object(s) are masked from ?package:base?:
>>>>>>>
>>>>>>> as.Date, as.Date.numeric
>>>>>>>
>>>>>>> > showMethods("dbGetQuery")
>>>>>>> Function: dbGetQuery (package DBI)
>>>>>>> conn="MySQLConnection", statement="character"
>>>>>>> conn="TSMySQLConnection", statement="character"
>>>>>>> (inherited from: conn="MySQLConnection", statement="character")
>>>>>>>
>>>>>>> > getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>>>> statement="character"))
>>>>>>> Error in getMethod("dbGetQuery", signature = c("TSMySQLConnection",
>>>>>>> statement = "character")) :
>>>>>>> No method found for function "dbGetQuery" and signature
>>>>>>> TSMySQLConnection, character
>>>>>>> >
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ripley at stats.ox.ac.uk  Tue Mar 27 09:05:20 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2012 08:05:20 +0100
Subject: [Rd] Problem with table
In-Reply-To: <4F676672.6070303@mayo.edu>
References: <4F676672.6070303@mayo.edu>
Message-ID: <4F7166B0.6050400@stats.ox.ac.uk>

On 19/03/2012 17:01, Terry Therneau wrote:
> R version 2.14.0, started with --vanilla
>
>  > table(c(1,2,3,4,NA), exclude=2, useNA='ifany')
> 1 3 4 <NA>
> 1 1 1 2
>
> This came from a local user who wanted to remove one particular response
> from some tables, but also wants to have NA always reported for data
> checking purposes.
> I don't think the above is what anyone would want.

You have not told us what you want!

Try

 >  table(as.factor(c(1,2,3,4,NA)), exclude=2, useNA='ifany')

    1    3    4 <NA>
    1    1    1    1

Note carefully how 'exclude' is defined:

  exclude: levels to remove from all factors in ?...?. If set to ?NULL?,
           it implies ?useNA="always"?.

As you did not specify a factor, 'exclude' was used in forming the 'levels'.

>
> PS.
> This is on a background of our local desires, which is to have the
> default action of the table command be
> to report NA, if present. (It's one of the only commands that we
> globally override at Mayo.) The user had
> added only the exclude=2 argument, and the useNA value is our default.
>
> The above makes this harder to do without rewriting the command
> wholesale, which is ok (we've done it before at
> various times in R and Splus) but we would avoid it if possible. Please
> no wars about whether this is the "right" decison or not, we've done it
> for 10+ years and quite firmly believe the extra robustness gained by
> having NA appear
> is worth the maintainance bother, correctness being paramount in medical
> research. We're not trying to convert anyone
> else, just get feedback on the best way to approach this.

Most likely, feed table() a factor with the properties you want.

>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ricardosousa2000 at clix.pt  Tue Mar 27 11:14:49 2012
From: ricardosousa2000 at clix.pt (MSousa)
Date: Tue, 27 Mar 2012 02:14:49 -0700 (PDT)
Subject: [Rd] drawing the graph with many nodes
Message-ID: <1332839689109-4508319.post@n4.nabble.com>

Good morning, 


I'm trying to draw a graph, and I'm using the following code.

test.matrix<-read.table("~/Desktop/Results/testgephi.csv", header = T,
sep=",")
colnames(test.matrix) <- gsub("X", "", colnames(test.matrix)) 
#drop first column
drops <- c("")
test.matrix<-test.matrix[,!(names(test.matrix) %in% drops)]
test.matrix
test.matrix<-data.matrix(test.matrix)
am.graph<-new("graphAM", adjMat=test.matrix, edgemode="directed")
am.graph
plot(am.graph, attrs = list(node = list(fillcolor = "lightblue"),edge =
list(arrowsize=0.5)))


The file testgephi.csv is following.
"","1","2","3","4","5"
"1",393,55,66,44,88
"2",44,23,47,57,89
"3",57,87,98,456,43
"4",77,767,86,32,77
"5",43,88,23,76,46

  In the example graph of the drawing works well, the problem is when I'm
trying to draw the graph from a file wih A graphAM graph with directed edges
Number of Nodes = 217 
Number of Edges = 32804 

is there any package or tool that can draw a structure like this


   Thanks


--
View this message in context: http://r.789695.n4.nabble.com/drawing-the-graph-with-many-nodes-tp4508319p4508319.html
Sent from the R devel mailing list archive at Nabble.com.


From armstrong.whit at gmail.com  Tue Mar 27 13:11:28 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 27 Mar 2012 07:11:28 -0400
Subject: [Rd] drawing the graph with many nodes
In-Reply-To: <1332839689109-4508319.post@n4.nabble.com>
References: <1332839689109-4508319.post@n4.nabble.com>
Message-ID: <CAMi=pg7+yvBZDC7F3UpSrupUDej8JGfN4KCQF-mZQVAYDM=0oA@mail.gmail.com>

if you don't mind going outside of R to create it, then check out
Graphviz: http://www.graphviz.org/Gallery.php

you may have to reformat your data a little, but this tool is great
for drawing graphs.

-Whit


On Tue, Mar 27, 2012 at 5:14 AM, MSousa <ricardosousa2000 at clix.pt> wrote:
> Good morning,
>
>
> I'm trying to draw a graph, and I'm using the following code.
>
> test.matrix<-read.table("~/Desktop/Results/testgephi.csv", header = T,
> sep=",")
> colnames(test.matrix) <- gsub("X", "", colnames(test.matrix))
> #drop first column
> drops <- c("")
> test.matrix<-test.matrix[,!(names(test.matrix) %in% drops)]
> test.matrix
> test.matrix<-data.matrix(test.matrix)
> am.graph<-new("graphAM", adjMat=test.matrix, edgemode="directed")
> am.graph
> plot(am.graph, attrs = list(node = list(fillcolor = "lightblue"),edge =
> list(arrowsize=0.5)))
>
>
> The file testgephi.csv is following.
> "","1","2","3","4","5"
> "1",393,55,66,44,88
> "2",44,23,47,57,89
> "3",57,87,98,456,43
> "4",77,767,86,32,77
> "5",43,88,23,76,46
>
> ?In the example graph of the drawing works well, the problem is when I'm
> trying to draw the graph from a file wih A graphAM graph with directed edges
> Number of Nodes = 217
> Number of Edges = 32804
>
> is there any package or tool that can draw a structure like this
>
>
> ? Thanks
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/drawing-the-graph-with-many-nodes-tp4508319p4508319.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar 27 13:52:42 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2012 12:52:42 +0100
Subject: [Rd] CRAN policies
In-Reply-To: <4F71A2F3.2000203@stats.ox.ac.uk>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
Message-ID: <4F71AA0A.9050702@stats.ox.ac.uk>

CRAN has for some time had a policies page at
http://cran.r-project.org/web/packages/policies.html
and we would like to draw this to the attention of package maintainers. 
  In particular, please

- always send a submission email to CRAN at r-project.org with the package
name and version on the subject line.  Emails sent to individual members 
of the team will result in delays at best.

- run R CMD check --as-cran on the tarball before you submit it.  Do
this with the latest version of R possible: definitely R 2.14.2,
preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R are
able to give better diagnostics, e.g. for compiled code and especially
on Windows. They may also have extra checks for recently uncovered
problems.)

Also, please note that CRAN has a very heavy workload (186 packages were 
published last week) and to remain viable needs package maintainers to 
make its life as easy as possible.

Kurt Hornik
Uwe Ligges
Brian Ripley


From maechler at stat.math.ethz.ch  Tue Mar 27 14:43:21 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 27 Mar 2012 14:43:21 +0200
Subject: [Rd] Typo in ?Logistic
In-Reply-To: <CAAmySGNuk3yzH_JnGGJoLm9XCbGg+HDLxn9_XRQxnvk=EhvP_Q@mail.gmail.com>
References: <CAAmySGNuk3yzH_JnGGJoLm9XCbGg+HDLxn9_XRQxnvk=EhvP_Q@mail.gmail.com>
Message-ID: <20337.46569.693439.51145@stat.math.ethz.ch>

>>>>> R Michael Weylandt <michael.weylandt at gmail.com>
>>>>>     on Mon, 26 Mar 2012 14:29:31 -0400 writes:

    > In the source section of ?rlogis, we see:
    > Source:

    > ?[dpr]logis? are calculated directly from the definitions.

    > ?rlogis? uses inversion.

    > Should that read "[dpq]logis" instead?

yes, indeed; now fixed.  Thank you very much!
Martin


From oliver at first.in-berlin.de  Tue Mar 27 15:10:04 2012
From: oliver at first.in-berlin.de (oliver)
Date: Tue, 27 Mar 2012 15:10:04 +0200
Subject: [Rd] drawing the graph with many nodes
In-Reply-To: <1332839689109-4508319.post@n4.nabble.com>
References: <1332839689109-4508319.post@n4.nabble.com>
Message-ID: <20120327131004.GC1829@siouxsie>

Hi,

your code does not run in a fresh R environment:

  Error in getClass(Class, where = topenv(parent.frame())) : 
    "graphAM" is not a defined class

If you don't provide working code, it's (too) much effort to help.

There are some graph packages arround.
Which you need depends on what you want to do.
I can't decide that easily, without seeing your example running.


Ciao,
   Oliver


From therneau at mayo.edu  Tue Mar 27 15:12:08 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 27 Mar 2012 08:12:08 -0500
Subject: [Rd] Problem with table
In-Reply-To: <4F7166B0.6050400@stats.ox.ac.uk>
References: <4F676672.6070303@mayo.edu> <4F7166B0.6050400@stats.ox.ac.uk>
Message-ID: <4F71BCA8.6090908@mayo.edu>

On 03/27/2012 02:05 AM, Prof Brian Ripley wrote:
> n 19/03/2012 17:01, Terry Therneau wrote:
>> R version 2.14.0, started with --vanilla
>>
>> > table(c(1,2,3,4,NA), exclude=2, useNA='ifany')
>> 1 3 4 <NA>
>> 1 1 1 2
>>
>> This came from a local user who wanted to remove one particular response
>> from some tables, but also wants to have NA always reported for data
>> checking purposes.
>> I don't think the above is what anyone would want.
>
> You have not told us what you want!
Want: that the resulting table exclude values of "2" from the printout, 
while still reporting NA.  This is what the local user expected, the one 
who came to me with their query.

There are lots of ways to get the program to do the right thing, the 
simplest is
      table(c(1,2,3,4,NA), exclude=2)     # keeping the default for useNA

You show another below.

>
> Try
>
> >  table(as.factor(c(1,2,3,4,NA)), exclude=2, useNA='ifany')
>
>    1    3    4 <NA>
>    1    1    1    1
>
> Note carefully how 'exclude' is defined:
>
>  exclude: levels to remove from all factors in ?...?. If set to ?NULL?,
>           it implies ?useNA="always"?.
>
> As you did not specify a factor, 'exclude' was used in forming the 
> 'levels'.
>
That is almost a "legal loophole" reading of the manual.  I would never 
have seen through to that level of subtlety.  A primary reason is that a 
simple test shows that exclude works on non-factors.

I'm not sure what the best course of action is.  What I've reported is a 
case where use of the options in a fairly obvious way gives an 
unexpected answer.  On the other hand, I have never  before seen or 
considered the case where someone wanted to exclude an actual data level 
from table: I myself would always have removed a column from the 
result.   If fixing this causes other problems, then perhaps we just 
give up on this rare case.

As to our local choices, we figured out a way to make display of NA the 
default without causing the above problem.   As is often the case, a 
fairly simple solution became obvious to us about 30 minutes after 
submitting a question to the list.

Terry T.


From therneau at mayo.edu  Tue Mar 27 15:22:38 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 27 Mar 2012 08:22:38 -0500
Subject: [Rd] PROTECT help
In-Reply-To: <4F7179A3.9060608@kent.ac.uk>
References: <4F7179A3.9060608@kent.ac.uk>
Message-ID: <4F71BF1E.7050600@mayo.edu>

I received the following note this AM.  The problem is, I'm not quite 
sure how to fix it.
Can one use PROTECT(coxlist(eval(PROTECT.... , do I create an 
intermediate variable, or otherwise?

I'm willing to update the code if someone will give me a pointer to the 
right documentation.  This particular chunk was written when there was a 
lot of change going on in the callback mechanism and so there might be a 
safer and/or simpler and/or more standard aproach by now. The routine in 
question has to do with penalized Cox models, the C code needs to get 
the value of the penalty and the penalty is an arbitrary S expression 
passed down from top level.

Terry T

----------------------------

In survival_2.36-12 (and earlier), in the function cox_callback() at
cox_Rcallback.c:40:

     PROTECT(coxlist=eval(lang2(fexpr,data),rho));

the return value of the call to lang2() is vulnerable if allocations
within eval() give rise to garbage collection.

(Discovered during CXXR development.)

Andrew


From ripley at stats.ox.ac.uk  Tue Mar 27 15:41:21 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2012 14:41:21 +0100
Subject: [Rd] PROTECT help
In-Reply-To: <4F71BF1E.7050600@mayo.edu>
References: <4F7179A3.9060608@kent.ac.uk> <4F71BF1E.7050600@mayo.edu>
Message-ID: <4F71C381.3080103@stats.ox.ac.uk>

On 27/03/2012 14:22, Terry Therneau wrote:
> I received the following note this AM. The problem is, I'm not quite
> sure how to fix it.
> Can one use PROTECT(coxlist(eval(PROTECT.... , do I create an
> intermediate variable, or otherwise?

You can, but I find it easiest to follow if you create an intermediate 
variable.  Look for example at unique.c:

             SEXP call, r;
             PROTECT(call = lang2(install("as.character"), s));
             PROTECT(r = eval(call, env));
             UNPROTECT(2);
             return r;



>
> I'm willing to update the code if someone will give me a pointer to the
> right documentation. This particular chunk was written when there was a
> lot of change going on in the callback mechanism and so there might be a
> safer and/or simpler and/or more standard aproach by now. The routine in
> question has to do with penalized Cox models, the C code needs to get
> the value of the penalty and the penalty is an arbitrary S expression
> passed down from top level.
>
> Terry T
>
> ----------------------------
>
> In survival_2.36-12 (and earlier), in the function cox_callback() at
> cox_Rcallback.c:40:
>
> PROTECT(coxlist=eval(lang2(fexpr,data),rho));
>
> the return value of the call to lang2() is vulnerable if allocations
> within eval() give rise to garbage collection.
>
> (Discovered during CXXR development.)
>
> Andrew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Tue Mar 27 15:49:15 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Mar 2012 09:49:15 -0400
Subject: [Rd] PROTECT help
In-Reply-To: <4F71BF1E.7050600@mayo.edu>
References: <4F7179A3.9060608@kent.ac.uk> <4F71BF1E.7050600@mayo.edu>
Message-ID: <4F71C55B.3020005@gmail.com>

On 12-03-27 9:22 AM, Terry Therneau wrote:
> I received the following note this AM.  The problem is, I'm not quite
> sure how to fix it.
> Can one use PROTECT(coxlist(eval(PROTECT.... , do I create an
> intermediate variable, or otherwise?

I think both would work.  The usual style in R sources is to use an 
intermediate variable, assigned within the PROTECT call, e.g.

PROTECT(var = f());

but this would act the same as

var = PROTECT(f());

I don't know where the best docs are, but here is my understanding of 
PROTECT:

What PROTECT(x) does is to make a copy of the pointer x in a stack of 
protected pointers.  When garbage collection happens, nothing in that 
stack will be released.  It is safe to protect things that don't need 
protection, but it is a little inefficient.  (You shouldn't call 
PROTECT() on a pointer that isn't an R object declared as a SEXP, but it 
will only cause trouble in certain debugging modes.)

PROTECT(x) does return the value of x, so f(PROTECT(x)) should evaluate 
the same as f(x) (but x will be protected from collection).

The main thing to watch when you use PROTECT is that you keep track of 
how many times it is called, because UNPROTECT just pops a number of 
pointers off the protection stack.


>
> I'm willing to update the code if someone will give me a pointer to the
> right documentation.  This particular chunk was written when there was a
> lot of change going on in the callback mechanism and so there might be a
> safer and/or simpler and/or more standard aproach by now. The routine in
> question has to do with penalized Cox models, the C code needs to get
> the value of the penalty and the penalty is an arbitrary S expression
> passed down from top level.
>
> Terry T
>
> ----------------------------
>
> In survival_2.36-12 (and earlier), in the function cox_callback() at
> cox_Rcallback.c:40:
>
>       PROTECT(coxlist=eval(lang2(fexpr,data),rho));
>
> the return value of the call to lang2() is vulnerable if allocations
> within eval() give rise to garbage collection.
>
> (Discovered during CXXR development.)
>
> Andrew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Tue Mar 27 16:05:04 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 27 Mar 2012 09:05:04 -0500
Subject: [Rd] PROTECT help
In-Reply-To: <4F71C381.3080103@stats.ox.ac.uk>
References: <4F7179A3.9060608@kent.ac.uk> <4F71BF1E.7050600@mayo.edu>
	<4F71C381.3080103@stats.ox.ac.uk>
Message-ID: <4F71C910.3060002@mayo.edu>


Brian & Duncan:
   Thanks.  This was exactly what I needed to know.

Terry

On 03/27/2012 08:41 AM, Prof Brian Ripley wrote:
> On 27/03/2012 14:22, Terry Therneau wrote:
>> I received the following note this AM. The problem is, I'm not quite
>> sure how to fix it.
>> Can one use PROTECT(coxlist(eval(PROTECT.... , do I create an
>> intermediate variable, or otherwise?
>
> You can, but I find it easiest to follow if you create an intermediate 
> variable.  Look for example at unique.c:
>
>             SEXP call, r;
>             PROTECT(call = lang2(install("as.character"), s));
>             PROTECT(r = eval(call, env));
>             UNPROTECT(2);
>             return r;
>
>
>
>>
>> I'm willing to update the code if someone will give me a pointer to the
>> right documentation. This particular chunk was written when there was a
>> lot of change going on in the callback mechanism and so there might be a
>> safer and/or simpler and/or more standard aproach by now. The routine in
>> question has to do with penalized Cox models, the C code needs to get
>> the value of the penalty and the penalty is an arbitrary S expression
>> passed down from top level.
>>
>> Terry T
>>
>> ----------------------------
>>
>> In survival_2.36-12 (and earlier), in the function cox_callback() at
>> cox_Rcallback.c:40:
>>
>> PROTECT(coxlist=eval(lang2(fexpr,data),rho));
>>
>> the return value of the call to lang2() is vulnerable if allocations
>> within eval() give rise to garbage collection.
>>
>> (Discovered during CXXR development.)
>>
>> Andrew
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From pgilbert902 at gmail.com  Tue Mar 27 16:17:09 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 27 Mar 2012 10:17:09 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F71AA0A.9050702@stats.ox.ac.uk>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
Message-ID: <4F71CBE5.6090300@gmail.com>

One of the things I have noticed with the R 2.15.0 RC and --as-cran is 
that the I have to bump the version number of the working copy of my 
packages immediately after putting a version on CRAN, or I get an 
message about version suitability. This is probably a good thing for 
packages that I have changed, compared with my old habit of bumping the 
version number at arbitrary times, although the mechanics are a nuisance 
because I do not actually want to commit to the next version number at 
that point. For packages that I have not changed it is a bit worse, 
because I have to change the version number even though I have not yet 
made any changes to the package. This will mean, for example, that on 
R-forge it will look like there is a slightly newer version, even though 
there is not really.

I am curious how other developers approach this. Is it better to not 
specify --as-cran most of the time?  My feeling is that it is better to 
specify it all of the time so that I catch errors sooner rather than 
later, but maybe there is a better solution?

Paul

On 12-03-27 07:52 AM, Prof Brian Ripley wrote:
> CRAN has for some time had a policies page at
> http://cran.r-project.org/web/packages/policies.html
> and we would like to draw this to the attention of package maintainers.
> In particular, please
>
> - always send a submission email to CRAN at r-project.org with the package
> name and version on the subject line. Emails sent to individual members
> of the team will result in delays at best.
>
> - run R CMD check --as-cran on the tarball before you submit it. Do
> this with the latest version of R possible: definitely R 2.14.2,
> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
> able to give better diagnostics, e.g. for compiled code and especially
> on Windows. They may also have extra checks for recently uncovered
> problems.)
>
> Also, please note that CRAN has a very heavy workload (186 packages were
> published last week) and to remain viable needs package maintainers to
> make its life as easy as possible.
>
> Kurt Hornik
> Uwe Ligges
> Brian Ripley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Tue Mar 27 16:59:53 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 27 Mar 2012 16:59:53 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <4F71CBE5.6090300@gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
Message-ID: <4F71D5E9.3090406@statistik.tu-dortmund.de>



On 27.03.2012 16:17, Paul Gilbert wrote:
> One of the things I have noticed with the R 2.15.0 RC and --as-cran is
> that the I have to bump the version number of the working copy of my
> packages immediately after putting a version on CRAN, or I get an
> message about version suitability. This is probably a good thing for
> packages that I have changed, compared with my old habit of bumping the
> version number at arbitrary times, although the mechanics are a nuisance
> because I do not actually want to commit to the next version number at
> that point. For packages that I have not changed it is a bit worse,
> because I have to change the version number even though I have not yet
> made any changes to the package. This will mean, for example, that on
> R-forge it will look like there is a slightly newer version, even though
> there is not really.
>
> I am curious how other developers approach this. Is it better to not
> specify --as-cran most of the time? My feeling is that it is better to
> specify it all of the time so that I catch errors sooner rather than
> later, but maybe there is a better solution?


--as-cran is modelled rather closely after the CRAN incoming checks. 
CRAN checks if a new version has a new version number. Of course, you 
can ignore its result if you do not want to submit. The idea of using 
--as-cran is to apply it before you actually submit. Some parts require 
network connection etc.

Uwe




> Paul
>
> On 12-03-27 07:52 AM, Prof Brian Ripley wrote:
>> CRAN has for some time had a policies page at
>> http://cran.r-project.org/web/packages/policies.html
>> and we would like to draw this to the attention of package maintainers.
>> In particular, please
>>
>> - always send a submission email to CRAN at r-project.org with the package
>> name and version on the subject line. Emails sent to individual members
>> of the team will result in delays at best.
>>
>> - run R CMD check --as-cran on the tarball before you submit it. Do
>> this with the latest version of R possible: definitely R 2.14.2,
>> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
>> able to give better diagnostics, e.g. for compiled code and especially
>> on Windows. They may also have extra checks for recently uncovered
>> problems.)
>>
>> Also, please note that CRAN has a very heavy workload (186 packages were
>> published last week) and to remain viable needs package maintainers to
>> make its life as easy as possible.
>>
>> Kurt Hornik
>> Uwe Ligges
>> Brian Ripley
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Mar 27 17:09:28 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 27 Mar 2012 11:09:28 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F71AA0A.9050702@stats.ox.ac.uk>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
Message-ID: <CAP01uRmFHCHPkSX=7WHUo+yWEGum0u3910qJLSqFzf95ndkqBQ@mail.gmail.com>

On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> CRAN has for some time had a policies page at
> http://cran.r-project.org/web/packages/policies.html
> and we would like to draw this to the attention of package maintainers. ?In
> particular, please
>
> - always send a submission email to CRAN at r-project.org with the package
> name and version on the subject line. ?Emails sent to individual members of
> the team will result in delays at best.
>
> - run R CMD check --as-cran on the tarball before you submit it. ?Do
> this with the latest version of R possible: definitely R 2.14.2,
> preferably R 2.15.0 RC or a recent R-devel. ?(Later versions of R are
> able to give better diagnostics, e.g. for compiled code and especially
> on Windows. They may also have extra checks for recently uncovered
> problems.)
>
> Also, please note that CRAN has a very heavy workload (186 packages were
> published last week) and to remain viable needs package maintainers to make
> its life as easy as possible.
>

Regarding the part about "warnings or significant notes" in that page,
its impossible to know which notes are significant and which ones are
not significant except by trial and error.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pgilbert902 at gmail.com  Tue Mar 27 17:22:06 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 27 Mar 2012 11:22:06 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F71D5E9.3090406@statistik.tu-dortmund.de>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
	<4F71D5E9.3090406@statistik.tu-dortmund.de>
Message-ID: <4F71DB1E.30405@gmail.com>



On 12-03-27 10:59 AM, Uwe Ligges wrote:
>
>
> On 27.03.2012 16:17, Paul Gilbert wrote:
>> One of the things I have noticed with the R 2.15.0 RC and --as-cran is
>> that the I have to bump the version number of the working copy of my
>> packages immediately after putting a version on CRAN, or I get an
>> message about version suitability. This is probably a good thing for
>> packages that I have changed, compared with my old habit of bumping the
>> version number at arbitrary times, although the mechanics are a nuisance
>> because I do not actually want to commit to the next version number at
>> that point. For packages that I have not changed it is a bit worse,
>> because I have to change the version number even though I have not yet
>> made any changes to the package. This will mean, for example, that on
>> R-forge it will look like there is a slightly newer version, even though
>> there is not really.
>>
>> I am curious how other developers approach this. Is it better to not
>> specify --as-cran most of the time? My feeling is that it is better to
>> specify it all of the time so that I catch errors sooner rather than
>> later, but maybe there is a better solution?
>
>
> --as-cran is modelled rather closely after the CRAN incoming checks.
> CRAN checks if a new version has a new version number. Of course, you
> can ignore its result if you do not want to submit. The idea of using
> --as-cran is to apply it before you actually submit. Some parts require
> network connection etc.
>
> Uwe

Yes but, for example, will R-forge run checks with --as-cran, and thus 
give warnings for any package unchanged from the one on CRAN, or run 
without --as-cran, and thus not give a true indication of whether the 
package is good to submit?

(No doubt R-forge will customise more, but I am trying to work out a 
strategy for my own automatic testing.)

Paul
>
>
>
>
>> Paul
>>
>> On 12-03-27 07:52 AM, Prof Brian Ripley wrote:
>>> CRAN has for some time had a policies page at
>>> http://cran.r-project.org/web/packages/policies.html
>>> and we would like to draw this to the attention of package maintainers.
>>> In particular, please
>>>
>>> - always send a submission email to CRAN at r-project.org with the package
>>> name and version on the subject line. Emails sent to individual members
>>> of the team will result in delays at best.
>>>
>>> - run R CMD check --as-cran on the tarball before you submit it. Do
>>> this with the latest version of R possible: definitely R 2.14.2,
>>> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
>>> able to give better diagnostics, e.g. for compiled code and especially
>>> on Windows. They may also have extra checks for recently uncovered
>>> problems.)
>>>
>>> Also, please note that CRAN has a very heavy workload (186 packages were
>>> published last week) and to remain viable needs package maintainers to
>>> make its life as easy as possible.
>>>
>>> Kurt Hornik
>>> Uwe Ligges
>>> Brian Ripley
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Tue Mar 27 17:24:03 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 27 Mar 2012 17:24:03 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <4F71DB1E.30405@gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
	<4F71D5E9.3090406@statistik.tu-dortmund.de>
	<4F71DB1E.30405@gmail.com>
Message-ID: <4F71DB93.1000508@statistik.tu-dortmund.de>



On 27.03.2012 17:22, Paul Gilbert wrote:
>
>
> On 12-03-27 10:59 AM, Uwe Ligges wrote:
>>
>>
>> On 27.03.2012 16:17, Paul Gilbert wrote:
>>> One of the things I have noticed with the R 2.15.0 RC and --as-cran is
>>> that the I have to bump the version number of the working copy of my
>>> packages immediately after putting a version on CRAN, or I get an
>>> message about version suitability. This is probably a good thing for
>>> packages that I have changed, compared with my old habit of bumping the
>>> version number at arbitrary times, although the mechanics are a nuisance
>>> because I do not actually want to commit to the next version number at
>>> that point. For packages that I have not changed it is a bit worse,
>>> because I have to change the version number even though I have not yet
>>> made any changes to the package. This will mean, for example, that on
>>> R-forge it will look like there is a slightly newer version, even though
>>> there is not really.
>>>
>>> I am curious how other developers approach this. Is it better to not
>>> specify --as-cran most of the time? My feeling is that it is better to
>>> specify it all of the time so that I catch errors sooner rather than
>>> later, but maybe there is a better solution?
>>
>>
>> --as-cran is modelled rather closely after the CRAN incoming checks.
>> CRAN checks if a new version has a new version number. Of course, you
>> can ignore its result if you do not want to submit. The idea of using
>> --as-cran is to apply it before you actually submit. Some parts require
>> network connection etc.
>>
>> Uwe
>
> Yes but, for example, will R-forge run checks with --as-cran, and thus
> give warnings for any package unchanged from the one on CRAN, or run
> without --as-cran, and thus not give a true indication of whether the
> package is good to submit?


This is a question for the R-forge maintainer. I would not expect it 
runs checks --as-cran, but I do now know.

Best,
Uwe



> (No doubt R-forge will customise more, but I am trying to work out a
> strategy for my own automatic testing.)
>
> Paul
>>
>>
>>
>>
>>> Paul
>>>
>>> On 12-03-27 07:52 AM, Prof Brian Ripley wrote:
>>>> CRAN has for some time had a policies page at
>>>> http://cran.r-project.org/web/packages/policies.html
>>>> and we would like to draw this to the attention of package maintainers.
>>>> In particular, please
>>>>
>>>> - always send a submission email to CRAN at r-project.org with the package
>>>> name and version on the subject line. Emails sent to individual members
>>>> of the team will result in delays at best.
>>>>
>>>> - run R CMD check --as-cran on the tarball before you submit it. Do
>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
>>>> able to give better diagnostics, e.g. for compiled code and especially
>>>> on Windows. They may also have extra checks for recently uncovered
>>>> problems.)
>>>>
>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>> were
>>>> published last week) and to remain viable needs package maintainers to
>>>> make its life as easy as possible.
>>>>
>>>> Kurt Hornik
>>>> Uwe Ligges
>>>> Brian Ripley
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Tue Mar 27 17:25:31 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 27 Mar 2012 17:25:31 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CAP01uRmFHCHPkSX=7WHUo+yWEGum0u3910qJLSqFzf95ndkqBQ@mail.gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
	<CAP01uRmFHCHPkSX=7WHUo+yWEGum0u3910qJLSqFzf95ndkqBQ@mail.gmail.com>
Message-ID: <4F71DBEB.2010508@statistik.tu-dortmund.de>



On 27.03.2012 17:09, Gabor Grothendieck wrote:
> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> CRAN has for some time had a policies page at
>> http://cran.r-project.org/web/packages/policies.html
>> and we would like to draw this to the attention of package maintainers.  In
>> particular, please
>>
>> - always send a submission email to CRAN at r-project.org with the package
>> name and version on the subject line.  Emails sent to individual members of
>> the team will result in delays at best.
>>
>> - run R CMD check --as-cran on the tarball before you submit it.  Do
>> this with the latest version of R possible: definitely R 2.14.2,
>> preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R are
>> able to give better diagnostics, e.g. for compiled code and especially
>> on Windows. They may also have extra checks for recently uncovered
>> problems.)
>>
>> Also, please note that CRAN has a very heavy workload (186 packages were
>> published last week) and to remain viable needs package maintainers to make
>> its life as easy as possible.
>>
>
> Regarding the part about "warnings or significant notes" in that page,
> its impossible to know which notes are significant and which ones are
> not significant except by trial and error.


Right, it needs human inspection to identify false positives. We believe 
most package maintainers are able to see if he or she is hit by such a 
false positive.

Uwe Ligges


From ripley at stats.ox.ac.uk  Tue Mar 27 17:41:45 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2012 16:41:45 +0100
Subject: [Rd] CRAN policies
In-Reply-To: <4F71CBE5.6090300@gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
Message-ID: <4F71DFB9.6010109@stats.ox.ac.uk>

On 27/03/2012 15:17, Paul Gilbert wrote:
> One of the things I have noticed with the R 2.15.0 RC and --as-cran is
> that the I have to bump the version number of the working copy of my
> packages immediately after putting a version on CRAN, or I get an
> message about version suitability. This is probably a good thing for
> packages that I have changed, compared with my old habit of bumping the
> version number at arbitrary times, although the mechanics are a nuisance
> because I do not actually want to commit to the next version number at
> that point. For packages that I have not changed it is a bit worse,
> because I have to change the version number even though I have not yet
> made any changes to the package. This will mean, for example, that on
> R-forge it will look like there is a slightly newer version, even though
> there is not really.
>
> I am curious how other developers approach this. Is it better to not
> specify --as-cran most of the time? My feeling is that it is better to
> specify it all of the time so that I catch errors sooner rather than
> later, but maybe there is a better solution?

Yes.  It is only recommended for use just before submission.  It is not 
used by the CRAN daily checks, for example.

All it does it set some environment variables that you can also set in 
~/.R/check.Renviron, scripts ... and that is what the CRAN team do.  We 
introduced --as-cran to make it easier to explain to submitters how to 
get the check results we reported [*].

As for what the set is, read 'R Internals' or the code (it will vary by 
R version).

Given that we get several submissions per week with the same version 
number or name as a package already on CRAN, we do need submitters to 
run the 'incoming' check before submission.

[*] Since answering several emails a day about why their results were 
different was taking up far too much time.

>
> Paul
>
> On 12-03-27 07:52 AM, Prof Brian Ripley wrote:
>> CRAN has for some time had a policies page at
>> http://cran.r-project.org/web/packages/policies.html
>> and we would like to draw this to the attention of package maintainers.
>> In particular, please
>>
>> - always send a submission email to CRAN at r-project.org with the package
>> name and version on the subject line. Emails sent to individual members
>> of the team will result in delays at best.
>>
>> - run R CMD check --as-cran on the tarball before you submit it. Do
>> this with the latest version of R possible: definitely R 2.14.2,
>> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
>> able to give better diagnostics, e.g. for compiled code and especially
>> on Windows. They may also have extra checks for recently uncovered
>> problems.)
>>
>> Also, please note that CRAN has a very heavy workload (186 packages were
>> published last week) and to remain viable needs package maintainers to
>> make its life as easy as possible.
>>
>> Kurt Hornik
>> Uwe Ligges
>> Brian Ripley
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Tue Mar 27 18:03:49 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 27 Mar 2012 11:03:49 -0500
Subject: [Rd] .Call ref card
In-Reply-To: <EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu> <87fwczr4em.wl%rdiaz02@gmail.com>
	<EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
Message-ID: <4F71E4E5.5070406@mayo.edu>

On 03/23/2012 10:58 AM, Simon Urbanek wrote:
> This is my shot at a cheat sheet.
> comments are welcome.
>
> Simon
>
I was looking through the cheat sheet.  It's nice.  There are a few 
things in it that I can't find in the documentation though.  Where would 
one find a description?  (I can guess, but that may be dangerous).

mkNamed
R_Naint   (I don't see quite how this differs from using NA_INTEGER to 
set a result)
R_PreserveObject, R_ReleaseObject   (Advantages/disadvantages wrt PRESERVE?)

The last is the most interesting to me.

Terry T.



-------------- next part --------------
A non-text attachment was scrubbed...
Name: R API cheat sheet.pdf
Type: application/pdf
Size: 51660 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120327/2098440a/attachment.pdf>

From ggrothendieck at gmail.com  Tue Mar 27 18:09:52 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 27 Mar 2012 12:09:52 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F71DBEB.2010508@statistik.tu-dortmund.de>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
	<CAP01uRmFHCHPkSX=7WHUo+yWEGum0u3910qJLSqFzf95ndkqBQ@mail.gmail.com>
	<4F71DBEB.2010508@statistik.tu-dortmund.de>
Message-ID: <CAP01uRk4ONPV3xZFgqBvZ4EhjK-XjggFKqktBciDBt0chTy=hg@mail.gmail.com>

2012/3/27 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>
>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> ?wrote:
>>>
>>> CRAN has for some time had a policies page at
>>> http://cran.r-project.org/web/packages/policies.html
>>> and we would like to draw this to the attention of package maintainers.
>>> ?In
>>> particular, please
>>>
>>> - always send a submission email to CRAN at r-project.org with the package
>>> name and version on the subject line. ?Emails sent to individual members
>>> of
>>> the team will result in delays at best.
>>>
>>> - run R CMD check --as-cran on the tarball before you submit it. ?Do
>>> this with the latest version of R possible: definitely R 2.14.2,
>>> preferably R 2.15.0 RC or a recent R-devel. ?(Later versions of R are
>>> able to give better diagnostics, e.g. for compiled code and especially
>>> on Windows. They may also have extra checks for recently uncovered
>>> problems.)
>>>
>>> Also, please note that CRAN has a very heavy workload (186 packages were
>>> published last week) and to remain viable needs package maintainers to
>>> make
>>> its life as easy as possible.
>>>
>>
>> Regarding the part about "warnings or significant notes" in that page,
>> its impossible to know which notes are significant and which ones are
>> not significant except by trial and error.
>
>
>
> Right, it needs human inspection to identify false positives. We believe
> most package maintainers are able to see if he or she is hit by such a false
> positive.

The problem is that a note is generated and the note is correct. Its
not a false positive.  But that does not tell you whether its
"significant" or not.  There is no way to know.  One can either try to
remove all notes (which may not be feasible) or just upload it and by
trial and error find out if its accepted or not.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Tue Mar 27 18:20:39 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 27 Mar 2012 12:20:39 -0400
Subject: [Rd] .Call ref card
In-Reply-To: <4F71E4E5.5070406@mayo.edu>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu> <87fwczr4em.wl%rdiaz02@gmail.com>
	<EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
	<4F71E4E5.5070406@mayo.edu>
Message-ID: <862ADA50-3FE4-4727-9FCD-E7001796138B@r-project.org>


On Mar 27, 2012, at 12:03 PM, Terry Therneau wrote:

> On 03/23/2012 10:58 AM, Simon Urbanek wrote:
>> This is my shot at a cheat sheet.
>> comments are welcome.
>> 
>> Simon
>> 
>> 
> I was looking through the cheat sheet.  It's nice.  There are a few things in it that I can't find in the documentation though.  Where would one find a description?  (I can guess, but that may be dangerous).
> 
> mkNamed

It is a shorthand for using allocVector and then setting names (which can be tedious). It's a simple way to create a result list/object (a very common thing to do):

    SEXP res = PROTECT(mkNamed(VECSXP, (const char*[]) { "foo", "bar", ""}));
    // fill res with SET_VECTOR_ELT(res, ..) 
    setAttrib(res, R_ClassSymbol, mkString("myClass"));
    UNPROTECT(1);
    return res;

Note that the sentinel is "" (not not NULL as commonly used in other APIs). Also you don't specify the length because it is determined from the names.


> R_Naint   (I don't see quite how this differs from using NA_INTEGER to set a result)

It doesn't really -- NA_INTEGER is defined to be R_NaInt. In theory NA_INTEGER being a macro could be a constant instead -- maybe for efficiency -- but currently it's not.


> R_PreserveObject, R_ReleaseObject   (Advantages/disadvantages wrt PRESERVE?)
> 

I guess you mean wrt PROTECT? Preserve/Release is used for objects that you want to be globally preserved - i.e. they will survive exit from the function. In contrast, the protection stack is popped when you exit the function (both by error or success).

Cheers,
Simon


From simon.urbanek at r-project.org  Tue Mar 27 18:35:42 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 27 Mar 2012 12:35:42 -0400
Subject: [Rd] .Call ref card
In-Reply-To: <862ADA50-3FE4-4727-9FCD-E7001796138B@r-project.org>
References: <mailman.29.1332414009.26932.r-devel@r-project.org>
	<4F6B2CE9.2090600@mayo.edu>
	<2933F897-6D3D-4DC0-AD38-2C73C8F01A4E@r-project.org>
	<87obror7jf.wl%rdiaz02@gmail.com>
	<928F07E9-B0AE-4E8A-839C-59A20CDA23C1@gmail.com>
	<4F6B652A.6050209@mayo.edu> <87fwczr4em.wl%rdiaz02@gmail.com>
	<EA95C1C3-6C6D-4DEB-81EC-A3D7BFF3EA21@r-project.org>
	<4F71E4E5.5070406@mayo.edu>
	<862ADA50-3FE4-4727-9FCD-E7001796138B@r-project.org>
Message-ID: <14940263-F8AA-4F48-9CB8-A9AA176BB583@r-project.org>

FWIW: I have put the (slightly updated) sheet at

http://r.research.att.com/man/R-API-cheat-sheet.pdf

Note that it is certainly incomplete - but that is intentional to a) to fit the space constraints and b) to show only the most basic things since we are talking about starting with .Call -- advanced users may need a different sheet but then they just go straight to the headers anyway ...

Cheers,
Simon




On Mar 27, 2012, at 12:20 PM, Simon Urbanek wrote:

> 
> On Mar 27, 2012, at 12:03 PM, Terry Therneau wrote:
> 
>> On 03/23/2012 10:58 AM, Simon Urbanek wrote:
>>> This is my shot at a cheat sheet.
>>> comments are welcome.
>>> 
>>> Simon
>>> 
>>> 
>> I was looking through the cheat sheet.  It's nice.  There are a few things in it that I can't find in the documentation though.  Where would one find a description?  (I can guess, but that may be dangerous).
>> 
>> mkNamed
> 
> It is a shorthand for using allocVector and then setting names (which can be tedious). It's a simple way to create a result list/object (a very common thing to do):
> 
>    SEXP res = PROTECT(mkNamed(VECSXP, (const char*[]) { "foo", "bar", ""}));
>    // fill res with SET_VECTOR_ELT(res, ..) 
>    setAttrib(res, R_ClassSymbol, mkString("myClass"));
>    UNPROTECT(1);
>    return res;
> 
> Note that the sentinel is "" (not not NULL as commonly used in other APIs). Also you don't specify the length because it is determined from the names.
> 
> 
>> R_Naint   (I don't see quite how this differs from using NA_INTEGER to set a result)
> 
> It doesn't really -- NA_INTEGER is defined to be R_NaInt. In theory NA_INTEGER being a macro could be a constant instead -- maybe for efficiency -- but currently it's not.
> 
> 
>> R_PreserveObject, R_ReleaseObject   (Advantages/disadvantages wrt PRESERVE?)
>> 
> 
> I guess you mean wrt PROTECT? Preserve/Release is used for objects that you want to be globally preserved - i.e. they will survive exit from the function. In contrast, the protection stack is popped when you exit the function (both by error or success).
> 
> Cheers,
> Simon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From dtenenba at fhcrc.org  Tue Mar 27 18:48:37 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 27 Mar 2012 09:48:37 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <22897_1332619661_4F6E298D_22897_15424_1_4F6E296C.3010101@gmail.com>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
	<7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
	<22897_1332619661_4F6E298D_22897_15424_1_4F6E296C.3010101@gmail.com>
Message-ID: <CAF42j23dLV5W-RrLrtu+mrGZVbQwX4WXFpzcK8Uw_6X0Ln881g@mail.gmail.com>

On Sat, Mar 24, 2012 at 1:07 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-03-24 2:31 PM, Simon Urbanek wrote:
>>
>>
>> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>>
>>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>>
>>>>
>>>>
>>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>>> To: Daniel Nordlund
>>>>>> Cc: r-devel at r-project.org
>>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>
>>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>>> <djnordlund at frontier.com> ? ?wrote:
>>>>>>>>
>>>>>>>> -----Original Message-----
>>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>>>
>>>>>> project.org]
>>>>>>>>
>>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>>> To: r-devel at r-project.org
>>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>>
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> The page
>>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>>> has a link to:
>>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>>
>>>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>>>>
>>>>>>>> FYI.
>>>>>>>> Dan
>>>>>>>>
>>>>>>>
>>>>>>> I experienced the same error you did using the link you provided.
>>>>>>
>>>>>> ? However, if you use the CRAN mirror hosted by YOUR organization, you
>>>>>> can
>>>>>> get the file. :-)
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> I don't think so:
>>>>>>
>>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>
>>>>>> gives me a 404 as well.
>>>>>>
>>>>>> Dan
>>>>>>
>>>>>>
>>>>>
>>>>> I didn't look closely enough at what you were asking for (RC versus
>>>>> beta). ?R-2.15RC may not have been up-loaded yet. ?However, I just
>>>>> downloaded it from the original link that was posted, so it appears to be
>>>>> available now.
>>>>
>>>>
>>>> It may have happened that the scripts generated the webpages before the
>>>> binary was built and checked (since "beta" became "rc" yesterday).
>>>
>>>
>>> Yes, they need manual tweaking at the conversion, and I did it after the
>>> first upload.
>>>
>>> If this happens again (which is pretty likely), you can manually download
>>> the previous version by editing the URL to put in "alpha" in place of
>>> "beta", or "beta" in place of "rc".
>>>
>>
>> ... or have a fixed name instead (on OS X we just use 2.15-branch which is
>> unambiguous). For the record I find it extremely annoying that even the
>> installation target name changes in the installer - I keep having to change
>> it to R-2.15 all the time, because I don't see why you would want to have
>> alpha/beta/rc/release of the same R version installed in separate
>> directories by default ?- but that may be just me ;). To a lesser degree the
>> same applies to patch versions, but since those are released I could see an
>> argument for that, even though in practice I think it is not useful either
>> (because typically you just want to upgrade and not another copy).
>
>
> I'm neutral about the name changes, but I don't think any of this is enough
> of a problem to be worth the time to fix. ?If someone else wants to do it,
> then I'd be happy to let you take over.
>

Thanks all of you for looking into this. Bioconductor usually needs
the binaries as soon as they are available so if there is a
sustainable way to solve this, we'd appreciate it very much.

Dan


>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tim.triche at gmail.com  Tue Mar 27 18:53:03 2012
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Tue, 27 Mar 2012 09:53:03 -0700
Subject: [Rd] drawing the graph with many nodes
In-Reply-To: <CAMi=pg7+yvBZDC7F3UpSrupUDej8JGfN4KCQF-mZQVAYDM=0oA@mail.gmail.com>
References: <1332839689109-4508319.post@n4.nabble.com>
	<CAMi=pg7+yvBZDC7F3UpSrupUDej8JGfN4KCQF-mZQVAYDM=0oA@mail.gmail.com>
Message-ID: <CAC+N9BVqg1Y9VuHF3Q=Gos=LgW+A8yZ6QPaw77SbrtYrTKgTWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120327/34acb802/attachment.pl>

From jeff.a.ryan at gmail.com  Tue Mar 27 19:10:00 2012
From: jeff.a.ryan at gmail.com (Jeffrey Ryan)
Date: Tue, 27 Mar 2012 12:10:00 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <CAP01uRk4ONPV3xZFgqBvZ4EhjK-XjggFKqktBciDBt0chTy=hg@mail.gmail.com>
Message-ID: <CB975D84.36D85%jeff.a.ryan@gmail.com>

Is there a distinction as to NOTE vs. WARNING that is documented?  I've
always assumed (wrongly?) that NOTES weren't an issue with publishing on
CRAN, but that they may change to WARNINGS at some point.

Is the process by which this happens documented somewhere?

Jeff

On 3/27/12 11:09 AM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:

>2012/3/27 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>>
>>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>>> <ripley at stats.ox.ac.uk>  wrote:
>>>>
>>>> CRAN has for some time had a policies page at
>>>> http://cran.r-project.org/web/packages/policies.html
>>>> and we would like to draw this to the attention of package
>>>>maintainers.
>>>>  In
>>>> particular, please
>>>>
>>>> - always send a submission email to CRAN at r-project.org with the
>>>>package
>>>> name and version on the subject line.  Emails sent to individual
>>>>members
>>>> of
>>>> the team will result in delays at best.
>>>>
>>>> - run R CMD check --as-cran on the tarball before you submit it.  Do
>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>> preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R are
>>>> able to give better diagnostics, e.g. for compiled code and especially
>>>> on Windows. They may also have extra checks for recently uncovered
>>>> problems.)
>>>>
>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>>were
>>>> published last week) and to remain viable needs package maintainers to
>>>> make
>>>> its life as easy as possible.
>>>>
>>>
>>> Regarding the part about "warnings or significant notes" in that page,
>>> its impossible to know which notes are significant and which ones are
>>> not significant except by trial and error.
>>
>>
>>
>> Right, it needs human inspection to identify false positives. We believe
>> most package maintainers are able to see if he or she is hit by such a
>>false
>> positive.
>
>The problem is that a note is generated and the note is correct. Its
>not a false positive.  But that does not tell you whether its
>"significant" or not.  There is no way to know.  One can either try to
>remove all notes (which may not be feasible) or just upload it and by
>trial and error find out if its accepted or not.
>
>-- 
>Statistics & Software Consulting
>GKX Group, GKX Associates Inc.
>tel: 1-877-GKX-GROUP
>email: ggrothendieck at gmail.com
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Mar 27 19:30:36 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2012 18:30:36 +0100
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <CAF42j23dLV5W-RrLrtu+mrGZVbQwX4WXFpzcK8Uw_6X0Ln881g@mail.gmail.com>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
	<7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
	<22897_1332619661_4F6E298D_22897_15424_1_4F6E296C.3010101@gmail.com>
	<CAF42j23dLV5W-RrLrtu+mrGZVbQwX4WXFpzcK8Uw_6X0Ln881g@mail.gmail.com>
Message-ID: <4F71F93C.8030600@stats.ox.ac.uk>

You should be capable of building R on Windows from the SVN sources or 
daily source tarballs.

After all, when (as often happens) BioC has an inconsistent set of 
source or binaries (like released packages depending on unreleased 
packages, on unreleased versions), the BioC core team tell me to get the 
sources from your SVN.

On 27/03/2012 17:48, Dan Tenenbaum wrote:
> On Sat, Mar 24, 2012 at 1:07 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 12-03-24 2:31 PM, Simon Urbanek wrote:
>>>
>>>
>>> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>>>
>>>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>>>
>>>>>
>>>>>
>>>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>>>> To: Daniel Nordlund
>>>>>>> Cc: r-devel at r-project.org
>>>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>
>>>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>>>> <djnordlund at frontier.com>      wrote:
>>>>>>>>>
>>>>>>>>> -----Original Message-----
>>>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>>>>
>>>>>>> project.org]
>>>>>>>>>
>>>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>>>> To: r-devel at r-project.org
>>>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>>
>>>>>>>>> The page
>>>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>>>> has a link to:
>>>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>>>
>>>>>>>>> However, clicking on that link gives a 404 "Object not found' error.
>>>>>>>>>
>>>>>>>>> FYI.
>>>>>>>>> Dan
>>>>>>>>>
>>>>>>>>
>>>>>>>> I experienced the same error you did using the link you provided.
>>>>>>>
>>>>>>>    However, if you use the CRAN mirror hosted by YOUR organization, you
>>>>>>> can
>>>>>>> get the file. :-)
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>> I don't think so:
>>>>>>>
>>>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>
>>>>>>> gives me a 404 as well.
>>>>>>>
>>>>>>> Dan
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> I didn't look closely enough at what you were asking for (RC versus
>>>>>> beta).  R-2.15RC may not have been up-loaded yet.  However, I just
>>>>>> downloaded it from the original link that was posted, so it appears to be
>>>>>> available now.
>>>>>
>>>>>
>>>>> It may have happened that the scripts generated the webpages before the
>>>>> binary was built and checked (since "beta" became "rc" yesterday).
>>>>
>>>>
>>>> Yes, they need manual tweaking at the conversion, and I did it after the
>>>> first upload.
>>>>
>>>> If this happens again (which is pretty likely), you can manually download
>>>> the previous version by editing the URL to put in "alpha" in place of
>>>> "beta", or "beta" in place of "rc".
>>>>
>>>
>>> ... or have a fixed name instead (on OS X we just use 2.15-branch which is
>>> unambiguous). For the record I find it extremely annoying that even the
>>> installation target name changes in the installer - I keep having to change
>>> it to R-2.15 all the time, because I don't see why you would want to have
>>> alpha/beta/rc/release of the same R version installed in separate
>>> directories by default  - but that may be just me ;). To a lesser degree the
>>> same applies to patch versions, but since those are released I could see an
>>> argument for that, even though in practice I think it is not useful either
>>> (because typically you just want to upgrade and not another copy).
>>
>>
>> I'm neutral about the name changes, but I don't think any of this is enough
>> of a problem to be worth the time to fix.  If someone else wants to do it,
>> then I'd be happy to let you take over.
>>
>
> Thanks all of you for looking into this. Bioconductor usually needs
> the binaries as soon as they are available so if there is a
> sustainable way to solve this, we'd appreciate it very much.
>
> Dan
>
>
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dtenenba at fhcrc.org  Tue Mar 27 19:31:58 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 27 Mar 2012 10:31:58 -0700
Subject: [Rd] Missing Windows binary for R-2.15RC?
In-Reply-To: <24052_1332869444_4F71F944_24052_3315_1_4F71F93C.8030600@stats.ox.ac.uk>
References: <CAF42j20hrmjxoLwY=W=xmCuCAjjCvMipC0a0oYOtZPSF6E5cCg@mail.gmail.com>
	<7842_1332546773_4F6D0CD5_7842_8701_1_EACEB08BE443481683B79A7D796D43A9@Gandalf>
	<CAF42j20rZzkRUvSLH4z6v6ZVcdjjn6Azs1yWA-nnhWXL3rfXrw@mail.gmail.com>
	<885DBD479155497D9548FC35D83B64B2@Gandalf>
	<4F6DDFE5.7000803@statistik.tu-dortmund.de>
	<4F6DF9CD.6030709@gmail.com>
	<9784221D-D031-4089-BBF2-54E32C9F767C@r-project.org>
	<22897_1332619661_4F6E298D_22897_15424_1_4F6E296C.3010101@gmail.com>
	<CAF42j23dLV5W-RrLrtu+mrGZVbQwX4WXFpzcK8Uw_6X0Ln881g@mail.gmail.com>
	<24052_1332869444_4F71F944_24052_3315_1_4F71F93C.8030600@stats.ox.ac.uk>
Message-ID: <CAF42j22ayjyVtFvu1TcLSncHgJz_ABv9Jsx3aq91MkvAg2kFFw@mail.gmail.com>

On Tue, Mar 27, 2012 at 10:30 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> You should be capable of building R on Windows from the SVN sources or daily
> source tarballs.
>

We are.


> After all, when (as often happens) BioC has an inconsistent set of source or
> binaries (like released packages depending on unreleased packages, on
> unreleased versions), the BioC core team tell me to get the sources from
> your SVN.
>

We like to hew as closely as possible to what CRAN is doing. We like
to build with the identical binaries that CRAN is using, if possible.
If not, we build from source.

Dan


>
> On 27/03/2012 17:48, Dan Tenenbaum wrote:
>>
>> On Sat, Mar 24, 2012 at 1:07 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>>>
>>> On 12-03-24 2:31 PM, Simon Urbanek wrote:
>>>>
>>>>
>>>>
>>>> On Mar 24, 2012, at 12:43 PM, Duncan Murdoch wrote:
>>>>
>>>>> On 12-03-24 10:53 AM, Uwe Ligges wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 24.03.2012 06:58, Daniel Nordlund wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> -----Original Message-----
>>>>>>>> From: Dan Tenenbaum [mailto:dtenenba at fhcrc.org]
>>>>>>>> Sent: Friday, March 23, 2012 5:48 PM
>>>>>>>> To: Daniel Nordlund
>>>>>>>> Cc: r-devel at r-project.org
>>>>>>>> Subject: Re: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>>
>>>>>>>> On Fri, Mar 23, 2012 at 4:52 PM, Daniel Nordlund
>>>>>>>> <djnordlund at frontier.com> ? ? ?wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> -----Original Message-----
>>>>>>>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>>>>>>>>
>>>>>>>>
>>>>>>>> project.org]
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Behalf Of Dan Tenenbaum
>>>>>>>>>> Sent: Friday, March 23, 2012 12:21 PM
>>>>>>>>>> To: r-devel at r-project.org
>>>>>>>>>> Subject: [Rd] Missing Windows binary for R-2.15RC?
>>>>>>>>>>
>>>>>>>>>> Hi,
>>>>>>>>>>
>>>>>>>>>> The page
>>>>>>>>>> http://cran.r-project.org/bin/windows/base/rtest.html
>>>>>>>>>> has a link to:
>>>>>>>>>> http://cran.r-project.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>>>>
>>>>>>>>>> However, clicking on that link gives a 404 "Object not found'
>>>>>>>>>> error.
>>>>>>>>>>
>>>>>>>>>> FYI.
>>>>>>>>>> Dan
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> I experienced the same error you did using the link you provided.
>>>>>>>>
>>>>>>>>
>>>>>>>> ? However, if you use the CRAN mirror hosted by YOUR organization,
>>>>>>>> you
>>>>>>>> can
>>>>>>>> get the file. :-)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>> I don't think so:
>>>>>>>>
>>>>>>>> http://cran.fhcrc.org/bin/windows/base/R-2.15.0rc-win.exe
>>>>>>>>
>>>>>>>> gives me a 404 as well.
>>>>>>>>
>>>>>>>> Dan
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>> I didn't look closely enough at what you were asking for (RC versus
>>>>>>> beta). ?R-2.15RC may not have been up-loaded yet. ?However, I just
>>>>>>> downloaded it from the original link that was posted, so it appears
>>>>>>> to be
>>>>>>> available now.
>>>>>>
>>>>>>
>>>>>>
>>>>>> It may have happened that the scripts generated the webpages before
>>>>>> the
>>>>>> binary was built and checked (since "beta" became "rc" yesterday).
>>>>>
>>>>>
>>>>>
>>>>> Yes, they need manual tweaking at the conversion, and I did it after
>>>>> the
>>>>> first upload.
>>>>>
>>>>> If this happens again (which is pretty likely), you can manually
>>>>> download
>>>>> the previous version by editing the URL to put in "alpha" in place of
>>>>> "beta", or "beta" in place of "rc".
>>>>>
>>>>
>>>> ... or have a fixed name instead (on OS X we just use 2.15-branch which
>>>> is
>>>> unambiguous). For the record I find it extremely annoying that even the
>>>> installation target name changes in the installer - I keep having to
>>>> change
>>>> it to R-2.15 all the time, because I don't see why you would want to
>>>> have
>>>> alpha/beta/rc/release of the same R version installed in separate
>>>> directories by default ?- but that may be just me ;). To a lesser degree
>>>> the
>>>> same applies to patch versions, but since those are released I could see
>>>> an
>>>> argument for that, even though in practice I think it is not useful
>>>> either
>>>> (because typically you just want to upgrade and not another copy).
>>>
>>>
>>>
>>> I'm neutral about the name changes, but I don't think any of this is
>>> enough
>>> of a problem to be worth the time to fix. ?If someone else wants to do
>>> it,
>>> then I'd be happy to let you take over.
>>>
>>
>> Thanks all of you for looking into this. Bioconductor usually needs
>> the binaries as soon as they are available so if there is a
>> sustainable way to solve this, we'd appreciate it very much.
>>
>> Dan
>>
>>
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From ligges at statistik.tu-dortmund.de  Tue Mar 27 20:19:16 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 27 Mar 2012 20:19:16 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CB975D84.36D85%jeff.a.ryan@gmail.com>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
Message-ID: <4F7204A4.9040803@statistik.tu-dortmund.de>



On 27.03.2012 19:10, Jeffrey Ryan wrote:
> Is there a distinction as to NOTE vs. WARNING that is documented?  I've
> always assumed (wrongly?) that NOTES weren't an issue with publishing on
> CRAN, but that they may change to WARNINGS at some point.

We won't kick packages off CRAN for Notes (but we will if Warnings are 
not fixed), but we may not accept new submissions with significant Notes.

Best,
Uwe Ligges



> Is the process by which this happens documented somewhere?
>
> Jeff
>
> On 3/27/12 11:09 AM, "Gabor Grothendieck"<ggrothendieck at gmail.com>  wrote:
>
>> 2012/3/27 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>>>
>>>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>>>> <ripley at stats.ox.ac.uk>   wrote:
>>>>>
>>>>> CRAN has for some time had a policies page at
>>>>> http://cran.r-project.org/web/packages/policies.html
>>>>> and we would like to draw this to the attention of package
>>>>> maintainers.
>>>>>   In
>>>>> particular, please
>>>>>
>>>>> - always send a submission email to CRAN at r-project.org with the
>>>>> package
>>>>> name and version on the subject line.  Emails sent to individual
>>>>> members
>>>>> of
>>>>> the team will result in delays at best.
>>>>>
>>>>> - run R CMD check --as-cran on the tarball before you submit it.  Do
>>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>>> preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R are
>>>>> able to give better diagnostics, e.g. for compiled code and especially
>>>>> on Windows. They may also have extra checks for recently uncovered
>>>>> problems.)
>>>>>
>>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>>> were
>>>>> published last week) and to remain viable needs package maintainers to
>>>>> make
>>>>> its life as easy as possible.
>>>>>
>>>>
>>>> Regarding the part about "warnings or significant notes" in that page,
>>>> its impossible to know which notes are significant and which ones are
>>>> not significant except by trial and error.
>>>
>>>
>>>
>>> Right, it needs human inspection to identify false positives. We believe
>>> most package maintainers are able to see if he or she is hit by such a
>>> false
>>> positive.
>>
>> The problem is that a note is generated and the note is correct. Its
>> not a false positive.  But that does not tell you whether its
>> "significant" or not.  There is no way to know.  One can either try to
>> remove all notes (which may not be feasible) or just upload it and by
>> trial and error find out if its accepted or not.
>>
>> --
>> Statistics&  Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jeff.a.ryan at gmail.com  Tue Mar 27 20:33:14 2012
From: jeff.a.ryan at gmail.com (Jeffrey Ryan)
Date: Tue, 27 Mar 2012 13:33:14 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <4F7204A4.9040803@statistik.tu-dortmund.de>
Message-ID: <CB9770B4.36D98%jeff.a.ryan@gmail.com>

Thanks Uwe for the clarification on what goes and what stays.

Still fuzzy on the notion of "significant" though.  Do you have an example
or two for the list?

Jeff

P.S.
I meant to also thank all of CRAN volunteers for the momentous efforts
involved, and it is nice to see some explanation of how we can help, as
well as a peek into what goes on 'behind the curtain' ;-)

On 3/27/12 1:19 PM, "Uwe Ligges" <ligges at statistik.tu-dortmund.de> wrote:

>
>
>On 27.03.2012 19:10, Jeffrey Ryan wrote:
>> Is there a distinction as to NOTE vs. WARNING that is documented?  I've
>> always assumed (wrongly?) that NOTES weren't an issue with publishing on
>> CRAN, but that they may change to WARNINGS at some point.
>
>We won't kick packages off CRAN for Notes (but we will if Warnings are
>not fixed), but we may not accept new submissions with significant Notes.
>
>Best,
>Uwe Ligges
>
>
>
>> Is the process by which this happens documented somewhere?
>>
>> Jeff
>>
>> On 3/27/12 11:09 AM, "Gabor Grothendieck"<ggrothendieck at gmail.com>
>>wrote:
>>
>>> 2012/3/27 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>>>>
>>>>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>>>>> <ripley at stats.ox.ac.uk>   wrote:
>>>>>>
>>>>>> CRAN has for some time had a policies page at
>>>>>> http://cran.r-project.org/web/packages/policies.html
>>>>>> and we would like to draw this to the attention of package
>>>>>> maintainers.
>>>>>>   In
>>>>>> particular, please
>>>>>>
>>>>>> - always send a submission email to CRAN at r-project.org with the
>>>>>> package
>>>>>> name and version on the subject line.  Emails sent to individual
>>>>>> members
>>>>>> of
>>>>>> the team will result in delays at best.
>>>>>>
>>>>>> - run R CMD check --as-cran on the tarball before you submit it.  Do
>>>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>>>> preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R
>>>>>>are
>>>>>> able to give better diagnostics, e.g. for compiled code and
>>>>>>especially
>>>>>> on Windows. They may also have extra checks for recently uncovered
>>>>>> problems.)
>>>>>>
>>>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>>>> were
>>>>>> published last week) and to remain viable needs package maintainers
>>>>>>to
>>>>>> make
>>>>>> its life as easy as possible.
>>>>>>
>>>>>
>>>>> Regarding the part about "warnings or significant notes" in that
>>>>>page,
>>>>> its impossible to know which notes are significant and which ones are
>>>>> not significant except by trial and error.
>>>>
>>>>
>>>>
>>>> Right, it needs human inspection to identify false positives. We
>>>>believe
>>>> most package maintainers are able to see if he or she is hit by such a
>>>> false
>>>> positive.
>>>
>>> The problem is that a note is generated and the note is correct. Its
>>> not a false positive.  But that does not tell you whether its
>>> "significant" or not.  There is no way to know.  One can either try to
>>> remove all notes (which may not be feasible) or just upload it and by
>>> trial and error find out if its accepted or not.
>>>
>>> --
>>> Statistics&  Software Consulting
>>> GKX Group, GKX Associates Inc.
>>> tel: 1-877-GKX-GROUP
>>> email: ggrothendieck at gmail.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From ggrothendieck at gmail.com  Tue Mar 27 20:36:40 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 27 Mar 2012 14:36:40 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F7204A4.9040803@statistik.tu-dortmund.de>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
	<4F7204A4.9040803@statistik.tu-dortmund.de>
Message-ID: <CAP01uRnxqqOTQQ_0sh8urYX6rYHQFXyTwTwJ1cUveQ-X2bVNyA@mail.gmail.com>

2012/3/27 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 27.03.2012 19:10, Jeffrey Ryan wrote:
>>
>> Is there a distinction as to NOTE vs. WARNING that is documented? ?I've
>> always assumed (wrongly?) that NOTES weren't an issue with publishing on
>> CRAN, but that they may change to WARNINGS at some point.
>
>
> We won't kick packages off CRAN for Notes (but we will if Warnings are not
> fixed), but we may not accept new submissions with significant Notes.

Yes, I understand that but that does not really address the problem
that one has no idea of whether a Note is significant or not so the
only way to determine its significance is to submit your package and
see if its accepted or not.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pgilbert902 at gmail.com  Tue Mar 27 20:59:40 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 27 Mar 2012 14:59:40 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F7204A4.9040803@statistik.tu-dortmund.de>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
	<4F7204A4.9040803@statistik.tu-dortmund.de>
Message-ID: <4F720E1C.2000906@gmail.com>

An associated problem, for the wish list, is that it would be nice for 
package developers to have a way to automatically distinguish between 
NOTEs that can usually be ignored (e.g. a package suggests a package 
that is not available for cross reference checks - I have several case 
where the suggested package depends on the package being built, so this 
NOTE occurs all the time), and NOTEs that are really pre-WARNINGS, so 
that one can flag these and spend time fixing them before they become a 
WARNING or ERROR. Perhaps two different kinds of notes?

(And, BTW, having been responsible for a certain amount of the
   >[*] Since answering several emails a day about why their
   >results were different was taking up far too much time.
I think --as-cran is great.)

Paul

On 12-03-27 02:19 PM, Uwe Ligges wrote:
>
>
> On 27.03.2012 19:10, Jeffrey Ryan wrote:
>> Is there a distinction as to NOTE vs. WARNING that is documented? I've
>> always assumed (wrongly?) that NOTES weren't an issue with publishing on
>> CRAN, but that they may change to WARNINGS at some point.
>
> We won't kick packages off CRAN for Notes (but we will if Warnings are
> not fixed), but we may not accept new submissions with significant Notes.
>
> Best,
> Uwe Ligges
>
>
>
>> Is the process by which this happens documented somewhere?
>>
>> Jeff
>>
>> On 3/27/12 11:09 AM, "Gabor Grothendieck"<ggrothendieck at gmail.com> wrote:
>>
>>> 2012/3/27 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>>>>
>>>>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>>>>> <ripley at stats.ox.ac.uk> wrote:
>>>>>>
>>>>>> CRAN has for some time had a policies page at
>>>>>> http://cran.r-project.org/web/packages/policies.html
>>>>>> and we would like to draw this to the attention of package
>>>>>> maintainers.
>>>>>> In
>>>>>> particular, please
>>>>>>
>>>>>> - always send a submission email to CRAN at r-project.org with the
>>>>>> package
>>>>>> name and version on the subject line. Emails sent to individual
>>>>>> members
>>>>>> of
>>>>>> the team will result in delays at best.
>>>>>>
>>>>>> - run R CMD check --as-cran on the tarball before you submit it. Do
>>>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>>>> preferably R 2.15.0 RC or a recent R-devel. (Later versions of R are
>>>>>> able to give better diagnostics, e.g. for compiled code and
>>>>>> especially
>>>>>> on Windows. They may also have extra checks for recently uncovered
>>>>>> problems.)
>>>>>>
>>>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>>>> were
>>>>>> published last week) and to remain viable needs package
>>>>>> maintainers to
>>>>>> make
>>>>>> its life as easy as possible.
>>>>>>
>>>>>
>>>>> Regarding the part about "warnings or significant notes" in that page,
>>>>> its impossible to know which notes are significant and which ones are
>>>>> not significant except by trial and error.
>>>>
>>>>
>>>>
>>>> Right, it needs human inspection to identify false positives. We
>>>> believe
>>>> most package maintainers are able to see if he or she is hit by such a
>>>> false
>>>> positive.
>>>
>>> The problem is that a note is generated and the note is correct. Its
>>> not a false positive. But that does not tell you whether its
>>> "significant" or not. There is no way to know. One can either try to
>>> remove all notes (which may not be feasible) or just upload it and by
>>> trial and error find out if its accepted or not.
>>>
>>> --
>>> Statistics& Software Consulting
>>> GKX Group, GKX Associates Inc.
>>> tel: 1-877-GKX-GROUP
>>> email: ggrothendieck at gmail.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bg2382 at columbia.edu  Tue Mar 27 23:01:01 2012
From: bg2382 at columbia.edu (Ben Goodrich)
Date: Tue, 27 Mar 2012 17:01:01 -0400
Subject: [Rd] serialization regression in 2.15.0 beta
In-Reply-To: <20120323191346.lmq6atwzhcgcsg00@cubmail.cc.columbia.edu>
References: <20120323191346.lmq6atwzhcgcsg00@cubmail.cc.columbia.edu>
Message-ID: <4F722A8D.6090105@columbia.edu>

In case anyone is concerned that this regression will affect them, the
code was reverted to the 2.14.x behavior by

------------------------------------------------------------------------
r58842 | ripley | 2012-03-26 08:12:43 -0400 (Mon, 26 Mar 2012) | 1 line
Changed paths:
   M /branches/R-2-15-branch/doc/NEWS.Rd
   M /branches/R-2-15-branch/src/library/parallel/R/unix/forkCluster.R
   M /branches/R-2-15-branch/src/library/parallel/R/unix/mcfork.R

revert to XDR serialization for 2.15.0
------------------------------------------------------------------------

Thanks,
Ben


> I am experiencing a problem related to serialization behavior in  
> 2.15.0 beta (binary installed from Debian unstable) and 2.16.0 (from  
> svn) that is not present in 2.14.2 (binary from Debian testing).
> 
> I don't fully understand the problem. Also, I tried but have not yet  
> been able to create a small, self-contained example that reproduces  
> the problem. However, I do have a large, not self-contained example,  
> which requires an alpha version (not yet on CRAN) of the mi package  
> (the mi package on CRAN would not exhibit this issue). Anyone  
> interested in reproducing the problem can follow the readme.txt file  
> in this directory:
> 
> http://www.columbia.edu/~bg2382/mi/serialization/
> 
> I track r-devel with git-svn and was able to git bisect to svn commit r58219
> 
> commit 799102bd9d0266fe89c3120981decf0b1f17ef11
> Author: ripley <ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
> Date:   Sat Jan 28 15:02:34 2012 +0000
> 
>      make use of non-xdr serialization;.
> 
> although this commit could merely expose the problem rather than cause it.
> 
> The problem occurs when the FUN called by mclapply() in the parallel  
> package returns a S4 object that contains a slot (called X) that is a  
> large matrix, specifically a "model matrix" similar to that produced  
> by glm(). Some columns of this matrix get corrupted with wrong values  
> (usually zero, but sometimes NaN or 10^300ish), which can be seen by  
> examining X right before FUN returns (to mclapply()'s environment) and  
> comparing to the "same" X after mclapply() returns to the calling  
> environment.
> 
> Part of svn commit r58219 is this hunk
> 
> diff --git a/src/library/parallel/R/unix/mcfork.R  
> b/src/library/parallel/R/unix/mcfork.R
> index 8e27534..4f92193 100644
> --- a/src/library/parallel/R/unix/mcfork.R
> +++ b/src/library/parallel/R/unix/mcfork.R
> @@ -82,7 +82,8 @@ mckill <- function(process, signal = 2L)
>   ## used by mcparallel, mclapply
>   sendMaster <- function(what)
>   {
> -    if (!is.raw(what)) what <- serialize(what, NULL, FALSE)
> +    # This is talking to the same machine, so no point in using xdr.
> +    if (!is.raw(what)) what <- serialize(what, NULL, xdr = FALSE)
>       .Call(C_mc_send_master, what, PACKAGE = "parallel")
>   }
> 
> Contrary to the comment, I have found that if I specify xdr = TRUE, I  
> get the expected (non-corrupted X slot) behavior in 2.16.0, even  
> though it is forking locally on my 64bit Debian laptop with a little  
> endian i7 processor, whose specs are
> 
> goodrich at CYBERPOWERPC:/tmp/serialization$ cat /proc/cpuinfo
> processor       : 0
> vendor_id       : GenuineIntel
> cpu family      : 6
> model           : 42
> model name      : Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz
> stepping        : 7
> microcode       : 0x17
> cpu MHz         : 800.000
> cache size      : 6144 KB
> physical id     : 0
> siblings        : 8
> core id         : 0
> cpu cores       : 4
> apicid          : 0
> initial apicid  : 0
> fpu             : yes
> fpu_exception   : yes
> cpuid level     : 13
> wp              : yes
> flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge  
> mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe  
> syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl  
> xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl  
> vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt  
> tsc_deadline_timer xsave avx lahf_lm ida arat epb xsaveopt pln pts dts  
> tpr_shadow vnmi flexpriority ept vpid
> bogomips        : 3990.83
> clflush size    : 64
> cache_alignment : 64
> address sizes   : 36 bits physical, 48 bits virtual
> power management:
> 
> ...
> 
> processor       : 7
> [same as processor 0]
> 
> So, to summarize I get the good behavior on R 2.14.2 when using  
> mclapply(), on 2.15.0 beta when using lapply(), and on 2.16.0 using  
> mclapply() iff I patch in xdr = TRUE in sendMaster(). I get the bad  
> behavior on 2.15.0 beta and unpatched 2.16.0 when using mclapply().
> 
> My session info:
> 
>> sessionInfo()
> R version 2.15.0 beta (2012-03-16 r58769)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats4    stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
>   [1] mi_0.9-83        bigmemory_4.2.11 arm_1.5-03       foreign_0.8-49
>   [5] abind_1.4-0      R2WinBUGS_2.1-18 coda_0.14-5      lme4_0.999375-42
>   [9] Matrix_1.0-4     lattice_0.20-0   MASS_7.3-17
> 
> loaded via a namespace (and not attached):
> [1] grid_2.15.0  nlme_3.1-103
> 
> Thanks,
> Ben


From xie at yihui.name  Tue Mar 27 23:40:04 2012
From: xie at yihui.name (Yihui Xie)
Date: Tue, 27 Mar 2012 16:40:04 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <4F720E1C.2000906@gmail.com>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
	<4F7204A4.9040803@statistik.tu-dortmund.de>
	<4F720E1C.2000906@gmail.com>
Message-ID: <CANROs4eNL32zQvYK-+=hEjpO1nLP=y4Eq=E24qpEm9fAokUL6A@mail.gmail.com>

I have been wondering if it is possible to automate the checking
process to reduce human efforts, e.g. automatically check the packages
submitted to FTP, and send the package maintainer an email in case of
warnings or errors (otherwise just move it to CRAN); package
maintainers can appeal for a manual check by CRAN maintainers in case
of false positives. As a package author, I really hate to bother CRAN
maintainers each time I upload a new version and it passes R CMD check
successfully, in which case I should have received an automatic email
instead of Kurt's "hand-writing" "thanks, on CRAN now". Frankly
speaking, it makes me feel guilty sometimes to update my packages,
thinking of other 3700 packages on CRAN and how much time you CRAN
maintainers are spending on checking the packages.

I do not know how many package authors actually read this mailing
list, so these policies may not really reach some authors at all.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From hadley at rice.edu  Tue Mar 27 23:58:39 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 27 Mar 2012 16:58:39 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <CANROs4eNL32zQvYK-+=hEjpO1nLP=y4Eq=E24qpEm9fAokUL6A@mail.gmail.com>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
	<4F7204A4.9040803@statistik.tu-dortmund.de>
	<4F720E1C.2000906@gmail.com>
	<CANROs4eNL32zQvYK-+=hEjpO1nLP=y4Eq=E24qpEm9fAokUL6A@mail.gmail.com>
Message-ID: <CABdHhvFMyrjUyE4TuEWbJQasQd-7qx-hG50yLzaSMakVjbN4cQ@mail.gmail.com>

> I have been wondering if it is possible to automate the checking
> process to reduce human efforts, e.g. automatically check the packages
> submitted to FTP, and send the package maintainer an email in case of
> warnings or errors (otherwise just move it to CRAN); package
> maintainers can appeal for a manual check by CRAN maintainers in case
> of false positives.

I've started using win-builder before submitting to CRAN.  This often
picks up problems that I don't see locally.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hadley at rice.edu  Wed Mar 28 00:07:51 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 27 Mar 2012 17:07:51 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <4F71AA0A.9050702@stats.ox.ac.uk>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
Message-ID: <CABdHhvF7Uf0M=8LmC==voQoeTNazNJD0ViiLBTWoZznFzO-SWw@mail.gmail.com>

On Tue, Mar 27, 2012 at 6:52 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> CRAN has for some time had a policies page at
> http://cran.r-project.org/web/packages/policies.html
> and we would like to draw this to the attention of package maintainers. ?In
> particular, please

Thanks for the pointer - I did not know that this page existed. In
general, is there some easy way to track changes to this page and the
R extension manual over time?  It is difficult to keep track of the
best practices.

I'd also like to get clarification on "Packages should not write in
the users' home filespace, nor anywhere else on the file system apart
from the R session's temporary directory (or during installation in
the location pointed to by TMPDIR: and such usage should be cleaned
up)." - what is recommended practice for packages to maintain state
across instances?  Operating systems have standards for where
applications can store settings (e.g. as described in
http://pypi.python.org/pypi/appdirs/1.2.0).  Is it acceptable to for
packages to follow these conventions?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From mstokely at google.com  Wed Mar 28 01:35:42 2012
From: mstokely at google.com (Murray Stokely)
Date: Tue, 27 Mar 2012 16:35:42 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <4F71AA0A.9050702@stats.ox.ac.uk>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
Message-ID: <CADiBzwT5KCRBk0_3k1D66hfqeSh-ph9p4zj7gGT_85pUpUr9hg@mail.gmail.com>

Lots of very sensible policies here.  I have one request as someone
who has in several cases had to involve company lawyers over
intellectual property issues with packages on CRAN -- the first bullet
point on ownership of copyright and intellectual property rights could
be strengthened further.

To the existing text "The ownership of copyright and intellectual
property rights of all components of the package must be clear and
unambiguous (including from the authors specification in the
DESCRIPTION file). Where code is copied (or derived) from the work of
others (including from R itself), care must be taken that any
copyright statements are preserved and authorship is not
misrepresented.
Trademarks must be respected."

I would add a few additional points :

1. The text of the license itself should be included in the package in
a LICENSE or COPYING file, as most of these licenses have things that
need to be filled in with names and other data, and just referencing a
license name in the DESCRIPTION file is not really a great way to deal
with licensing metadata when used exclusively (it's a great complement
to a full, filled-out license in the package itself).

2. Per file copyright comment headers can help immensely with ensuring
compliance and the accidental incorporation of files under a different
license.  Comment header blocks with the author name and terms of
distribution could be recommended for all source files.

               - Murray

On Tue, Mar 27, 2012 at 4:52 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> CRAN has for some time had a policies page at
> http://cran.r-project.org/web/packages/policies.html
> and we would like to draw this to the attention of package maintainers. ?In
> particular, please
>
> - always send a submission email to CRAN at r-project.org with the package
> name and version on the subject line. ?Emails sent to individual members of
> the team will result in delays at best.
>
> - run R CMD check --as-cran on the tarball before you submit it. ?Do
> this with the latest version of R possible: definitely R 2.14.2,
> preferably R 2.15.0 RC or a recent R-devel. ?(Later versions of R are
> able to give better diagnostics, e.g. for compiled code and especially
> on Windows. They may also have extra checks for recently uncovered
> problems.)
>
> Also, please note that CRAN has a very heavy workload (186 packages were
> published last week) and to remain viable needs package maintainers to make
> its life as easy as possible.
>
> Kurt Hornik
> Uwe Ligges
> Brian Ripley
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Mar 28 07:56:58 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Mar 2012 06:56:58 +0100
Subject: [Rd] serialization regression in 2.15.0 beta
In-Reply-To: <4F722A8D.6090105@columbia.edu>
References: <20120323191346.lmq6atwzhcgcsg00@cubmail.cc.columbia.edu>
	<4F722A8D.6090105@columbia.edu>
Message-ID: <4F72A82A.4080008@stats.ox.ac.uk>

On 27/03/2012 22:01, Ben Goodrich wrote:
> In case anyone is concerned that this regression will affect them, the
> code was reverted to the 2.14.x behavior by
>
> ------------------------------------------------------------------------
> r58842 | ripley | 2012-03-26 08:12:43 -0400 (Mon, 26 Mar 2012) | 1 line
> Changed paths:
>     M /branches/R-2-15-branch/doc/NEWS.Rd
>     M /branches/R-2-15-branch/src/library/parallel/R/unix/forkCluster.R
>     M /branches/R-2-15-branch/src/library/parallel/R/unix/mcfork.R
>
> revert to XDR serialization for 2.15.0
> ------------------------------------------------------------------------

But the underlying problem (in non-xdr binary unserialization) is AFAWK 
fixed: it was just that at this late stage there was too little time to 
test thoroughly before release.

Please test R-devel on your own problem (we haven't: the issue was found 
using a different example from elsewhere).

> Thanks,
> Ben
>
>
>> I am experiencing a problem related to serialization behavior in
>> 2.15.0 beta (binary installed from Debian unstable) and 2.16.0 (from
>> svn) that is not present in 2.14.2 (binary from Debian testing).
>>
>> I don't fully understand the problem. Also, I tried but have not yet
>> been able to create a small, self-contained example that reproduces
>> the problem. However, I do have a large, not self-contained example,
>> which requires an alpha version (not yet on CRAN) of the mi package
>> (the mi package on CRAN would not exhibit this issue). Anyone
>> interested in reproducing the problem can follow the readme.txt file
>> in this directory:
>>
>> http://www.columbia.edu/~bg2382/mi/serialization/
>>
>> I track r-devel with git-svn and was able to git bisect to svn commit r58219
>>
>> commit 799102bd9d0266fe89c3120981decf0b1f17ef11
>> Author: ripley<ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
>> Date:   Sat Jan 28 15:02:34 2012 +0000
>>
>>       make use of non-xdr serialization;.
>>
>> although this commit could merely expose the problem rather than cause it.
>>
>> The problem occurs when the FUN called by mclapply() in the parallel
>> package returns a S4 object that contains a slot (called X) that is a
>> large matrix, specifically a "model matrix" similar to that produced
>> by glm(). Some columns of this matrix get corrupted with wrong values
>> (usually zero, but sometimes NaN or 10^300ish), which can be seen by
>> examining X right before FUN returns (to mclapply()'s environment) and
>> comparing to the "same" X after mclapply() returns to the calling
>> environment.
>>
>> Part of svn commit r58219 is this hunk
>>
>> diff --git a/src/library/parallel/R/unix/mcfork.R
>> b/src/library/parallel/R/unix/mcfork.R
>> index 8e27534..4f92193 100644
>> --- a/src/library/parallel/R/unix/mcfork.R
>> +++ b/src/library/parallel/R/unix/mcfork.R
>> @@ -82,7 +82,8 @@ mckill<- function(process, signal = 2L)
>>    ## used by mcparallel, mclapply
>>    sendMaster<- function(what)
>>    {
>> -    if (!is.raw(what)) what<- serialize(what, NULL, FALSE)
>> +    # This is talking to the same machine, so no point in using xdr.
>> +    if (!is.raw(what)) what<- serialize(what, NULL, xdr = FALSE)
>>        .Call(C_mc_send_master, what, PACKAGE = "parallel")
>>    }
>>
>> Contrary to the comment, I have found that if I specify xdr = TRUE, I
>> get the expected (non-corrupted X slot) behavior in 2.16.0, even
>> though it is forking locally on my 64bit Debian laptop with a little
>> endian i7 processor, whose specs are
>>
>> goodrich at CYBERPOWERPC:/tmp/serialization$ cat /proc/cpuinfo
>> processor       : 0
>> vendor_id       : GenuineIntel
>> cpu family      : 6
>> model           : 42
>> model name      : Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz
>> stepping        : 7
>> microcode       : 0x17
>> cpu MHz         : 800.000
>> cache size      : 6144 KB
>> physical id     : 0
>> siblings        : 8
>> core id         : 0
>> cpu cores       : 4
>> apicid          : 0
>> initial apicid  : 0
>> fpu             : yes
>> fpu_exception   : yes
>> cpuid level     : 13
>> wp              : yes
>> flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge
>> mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe
>> syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl
>> xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl
>> vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt
>> tsc_deadline_timer xsave avx lahf_lm ida arat epb xsaveopt pln pts dts
>> tpr_shadow vnmi flexpriority ept vpid
>> bogomips        : 3990.83
>> clflush size    : 64
>> cache_alignment : 64
>> address sizes   : 36 bits physical, 48 bits virtual
>> power management:
>>
>> ...
>>
>> processor       : 7
>> [same as processor 0]
>>
>> So, to summarize I get the good behavior on R 2.14.2 when using
>> mclapply(), on 2.15.0 beta when using lapply(), and on 2.16.0 using
>> mclapply() iff I patch in xdr = TRUE in sendMaster(). I get the bad
>> behavior on 2.15.0 beta and unpatched 2.16.0 when using mclapply().
>>
>> My session info:
>>
>>> sessionInfo()
>> R version 2.15.0 beta (2012-03-16 r58769)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>    [7] LC_PAPER=C                 LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats4    stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> other attached packages:
>>    [1] mi_0.9-83        bigmemory_4.2.11 arm_1.5-03       foreign_0.8-49
>>    [5] abind_1.4-0      R2WinBUGS_2.1-18 coda_0.14-5      lme4_0.999375-42
>>    [9] Matrix_1.0-4     lattice_0.20-0   MASS_7.3-17
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.15.0  nlme_3.1-103
>>
>> Thanks,
>> Ben
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jinghuazhao at hotmail.com  Wed Mar 28 11:46:18 2012
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Wed, 28 Mar 2012 09:46:18 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <CANROs4eNL32zQvYK-+=hEjpO1nLP=y4Eq=E24qpEm9fAokUL6A@mail.gmail.com>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>,
	<4F7204A4.9040803@statistik.tu-dortmund.de>,
	<4F720E1C.2000906@gmail.com>,
	<CANROs4eNL32zQvYK-+=hEjpO1nLP=y4Eq=E24qpEm9fAokUL6A@mail.gmail.com>
Message-ID: <COL105-W15140B0AD4F45D0CCEEB98A54B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120328/16326046/attachment.pl>

From ligges at statistik.tu-dortmund.de  Wed Mar 28 16:00:02 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Mar 2012 16:00:02 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CABdHhvF7Uf0M=8LmC==voQoeTNazNJD0ViiLBTWoZznFzO-SWw@mail.gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk> <4F71AA0A.9050702@stats.ox.ac.uk>
	<CABdHhvF7Uf0M=8LmC==voQoeTNazNJD0ViiLBTWoZznFzO-SWw@mail.gmail.com>
Message-ID: <4F731962.4020407@statistik.tu-dortmund.de>



On 28.03.2012 00:07, Hadley Wickham wrote:
> On Tue, Mar 27, 2012 at 6:52 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> CRAN has for some time had a policies page at
>> http://cran.r-project.org/web/packages/policies.html
>> and we would like to draw this to the attention of package maintainers.  In
>> particular, please
>
> Thanks for the pointer - I did not know that this page existed. In
> general, is there some easy way to track changes to this page and the
> R extension manual over time?  It is difficult to keep track of the
> best practices.
>
> I'd also like to get clarification on "Packages should not write in
> the users' home filespace, nor anywhere else on the file system apart
> from the R session's temporary directory (or during installation in
> the location pointed to by TMPDIR: and such usage should be cleaned
> up)." - what is recommended practice for packages to maintain state
> across instances?  Operating systems have standards for where
> applications can store settings (e.g. as described in
> http://pypi.python.org/pypi/appdirs/1.2.0).  Is it acceptable to for
> packages to follow these conventions?


The policy is meant not to overwrite user data or generate loads of 
temporary files from examples and pollute, e.g., the owkring directory.

Uwe Ligges




> Hadley
>


From ligges at statistik.tu-dortmund.de  Wed Mar 28 16:07:05 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Mar 2012 16:07:05 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
Message-ID: <4F731B09.5000203@statistik.tu-dortmund.de>



On 27.03.2012 20:33, Jeffrey Ryan wrote:
> Thanks Uwe for the clarification on what goes and what stays.
>
> Still fuzzy on the notion of "significant" though.  Do you have an example
> or two for the list?


We have to look at those notes again and again in order to find if 
something important is noted, hence please always try to avoid all notes 
unless the effect is really intended!


Consider the Note "No visible binding for global variable"
We cannot know if your code intends to use such a global variable (which 
is undesirable in most cases), hence would let is pass if it seems to be 
sensible.

Another Note such as "empty section" or "partial argument match" can 
quickly be fixed, hence just do it and don't waste our time.

Best,
Uwe Ligges


>
> Jeff
>
> P.S.
> I meant to also thank all of CRAN volunteers for the momentous efforts
> involved, and it is nice to see some explanation of how we can help, as
> well as a peek into what goes on 'behind the curtain' ;-)
>
> On 3/27/12 1:19 PM, "Uwe Ligges"<ligges at statistik.tu-dortmund.de>  wrote:
>
>>
>>
>> On 27.03.2012 19:10, Jeffrey Ryan wrote:
>>> Is there a distinction as to NOTE vs. WARNING that is documented?  I've
>>> always assumed (wrongly?) that NOTES weren't an issue with publishing on
>>> CRAN, but that they may change to WARNINGS at some point.
>>
>> We won't kick packages off CRAN for Notes (but we will if Warnings are
>> not fixed), but we may not accept new submissions with significant Notes.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>> Is the process by which this happens documented somewhere?
>>>
>>> Jeff
>>>
>>> On 3/27/12 11:09 AM, "Gabor Grothendieck"<ggrothendieck at gmail.com>
>>> wrote:
>>>
>>>> 2012/3/27 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>
>>>>>
>>>>> On 27.03.2012 17:09, Gabor Grothendieck wrote:
>>>>>>
>>>>>> On Tue, Mar 27, 2012 at 7:52 AM, Prof Brian Ripley
>>>>>> <ripley at stats.ox.ac.uk>    wrote:
>>>>>>>
>>>>>>> CRAN has for some time had a policies page at
>>>>>>> http://cran.r-project.org/web/packages/policies.html
>>>>>>> and we would like to draw this to the attention of package
>>>>>>> maintainers.
>>>>>>>    In
>>>>>>> particular, please
>>>>>>>
>>>>>>> - always send a submission email to CRAN at r-project.org with the
>>>>>>> package
>>>>>>> name and version on the subject line.  Emails sent to individual
>>>>>>> members
>>>>>>> of
>>>>>>> the team will result in delays at best.
>>>>>>>
>>>>>>> - run R CMD check --as-cran on the tarball before you submit it.  Do
>>>>>>> this with the latest version of R possible: definitely R 2.14.2,
>>>>>>> preferably R 2.15.0 RC or a recent R-devel.  (Later versions of R
>>>>>>> are
>>>>>>> able to give better diagnostics, e.g. for compiled code and
>>>>>>> especially
>>>>>>> on Windows. They may also have extra checks for recently uncovered
>>>>>>> problems.)
>>>>>>>
>>>>>>> Also, please note that CRAN has a very heavy workload (186 packages
>>>>>>> were
>>>>>>> published last week) and to remain viable needs package maintainers
>>>>>>> to
>>>>>>> make
>>>>>>> its life as easy as possible.
>>>>>>>
>>>>>>
>>>>>> Regarding the part about "warnings or significant notes" in that
>>>>>> page,
>>>>>> its impossible to know which notes are significant and which ones are
>>>>>> not significant except by trial and error.
>>>>>
>>>>>
>>>>>
>>>>> Right, it needs human inspection to identify false positives. We
>>>>> believe
>>>>> most package maintainers are able to see if he or she is hit by such a
>>>>> false
>>>>> positive.
>>>>
>>>> The problem is that a note is generated and the note is correct. Its
>>>> not a false positive.  But that does not tell you whether its
>>>> "significant" or not.  There is no way to know.  One can either try to
>>>> remove all notes (which may not be feasible) or just upload it and by
>>>> trial and error find out if its accepted or not.
>>>>
>>>> --
>>>> Statistics&   Software Consulting
>>>> GKX Group, GKX Associates Inc.
>>>> tel: 1-877-GKX-GROUP
>>>> email: ggrothendieck at gmail.com
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Mar 28 16:07:46 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Mar 2012 16:07:46 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CAP01uRnxqqOTQQ_0sh8urYX6rYHQFXyTwTwJ1cUveQ-X2bVNyA@mail.gmail.com>
References: <CB975D84.36D85%jeff.a.ryan@gmail.com>
	<4F7204A4.9040803@statistik.tu-dortmund.de>
	<CAP01uRnxqqOTQQ_0sh8urYX6rYHQFXyTwTwJ1cUveQ-X2bVNyA@mail.gmail.com>
Message-ID: <4F731B32.6010201@statistik.tu-dortmund.de>



On 27.03.2012 20:36, Gabor Grothendieck wrote:
> 2012/3/27 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 27.03.2012 19:10, Jeffrey Ryan wrote:
>>>
>>> Is there a distinction as to NOTE vs. WARNING that is documented?  I've
>>> always assumed (wrongly?) that NOTES weren't an issue with publishing on
>>> CRAN, but that they may change to WARNINGS at some point.
>>
>>
>> We won't kick packages off CRAN for Notes (but we will if Warnings are not
>> fixed), but we may not accept new submissions with significant Notes.
>
> Yes, I understand that but that does not really address the problem
> that one has no idea of whether a Note is significant or not so the
> only way to determine its significance is to submit your package and
> see if its accepted or not.
>

We have to look at those notes again and again in order to find if 
something important is noted, hence please always try to avoid all notes 
unless the effect is really intended!


Consider the Note "No visible binding for global variable"
We cannot know if your code intends to use such a global variable (which 
is undesirable in most cases), hence would let is pass if it seems to be 
sensible.

Another Note such as "empty section" or "partial argument match" can 
quickly be fixed, hence just do it and don't waste our time.

Best,
Uwe Ligges


From ggrothendieck at gmail.com  Wed Mar 28 16:30:34 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 28 Mar 2012 10:30:34 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F731B09.5000203@statistik.tu-dortmund.de>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
Message-ID: <CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>

2012/3/28 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 27.03.2012 20:33, Jeffrey Ryan wrote:
>>
>> Thanks Uwe for the clarification on what goes and what stays.
>>
>> Still fuzzy on the notion of "significant" though. ?Do you have an example
>> or two for the list?
>
>
>
> We have to look at those notes again and again in order to find if something
> important is noted, hence please always try to avoid all notes unless the
> effect is really intended!
>
>
> Consider the Note "No visible binding for global variable"
> We cannot know if your code intends to use such a global variable (which is
> undesirable in most cases), hence would let is pass if it seems to be
> sensible.
>
> Another Note such as "empty section" or "partial argument match" can quickly
> be fixed, hence just do it and don't waste our time.
>
> Best,
> Uwe Ligges

What is the point of notes vs warnings if you have to get rid of both
of them?  Furthermore, if there are notes that you don't have to get
rid of its not fair that package developers should have to waste their
time on things that are actually acceptable.  Finally, it makes the
whole system arbitrary since packages can be rejected based on
undefined rules.

Either divide notes into significant notes and ordinary notes and
clearly label them as such in the output of   R CMD check   or else
make the significant notes warnings so one can know in advance whether
the package passes R CMD check or not.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bg2382 at columbia.edu  Wed Mar 28 17:20:33 2012
From: bg2382 at columbia.edu (Ben Goodrich)
Date: Wed, 28 Mar 2012 11:20:33 -0400
Subject: [Rd] serialization regression in 2.15.0 beta
In-Reply-To: <4F72A82A.4080008@stats.ox.ac.uk>
References: <20120323191346.lmq6atwzhcgcsg00@cubmail.cc.columbia.edu>
	<4F722A8D.6090105@columbia.edu> <4F72A82A.4080008@stats.ox.ac.uk>
Message-ID: <20120328112033.o329uzutgk88kswo@cubmail.cc.columbia.edu>

Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> On 27/03/2012 22:01, Ben Goodrich wrote:
>> In case anyone is concerned that this regression will affect them, the
>> code was reverted to the 2.14.x behavior by
>>
>> ------------------------------------------------------------------------
>> r58842 | ripley | 2012-03-26 08:12:43 -0400 (Mon, 26 Mar 2012) | 1 line
>> Changed paths:
>>    M /branches/R-2-15-branch/doc/NEWS.Rd
>>    M /branches/R-2-15-branch/src/library/parallel/R/unix/forkCluster.R
>>    M /branches/R-2-15-branch/src/library/parallel/R/unix/mcfork.R
>>
>> revert to XDR serialization for 2.15.0
>> ------------------------------------------------------------------------
>
> But the underlying problem (in non-xdr binary unserialization) is AFAWK
> fixed: it was just that at this late stage there was too little time to
> test thoroughly before release.
>
> Please test R-devel on your own problem (we haven't: the issue was
> found using a different example from elsewhere).

Indeed, the issue seems to be fixed in r-devel for my example.

Thanks,
Ben


>>> I am experiencing a problem related to serialization behavior in
>>> 2.15.0 beta (binary installed from Debian unstable) and 2.16.0 (from
>>> svn) that is not present in 2.14.2 (binary from Debian testing).
>>>
>>> I don't fully understand the problem. Also, I tried but have not yet
>>> been able to create a small, self-contained example that reproduces
>>> the problem. However, I do have a large, not self-contained example,
>>> which requires an alpha version (not yet on CRAN) of the mi package
>>> (the mi package on CRAN would not exhibit this issue). Anyone
>>> interested in reproducing the problem can follow the readme.txt file
>>> in this directory:
>>>
>>> http://www.columbia.edu/~bg2382/mi/serialization/
>>>
>>> I track r-devel with git-svn and was able to git bisect to svn   
>>> commit r58219
>>>
>>> commit 799102bd9d0266fe89c3120981decf0b1f17ef11
>>> Author: ripley<ripley at 00db46b3-68df-0310-9c12-caf00c1e9a41>
>>> Date:   Sat Jan 28 15:02:34 2012 +0000
>>>
>>>      make use of non-xdr serialization;.
>>>
>>> although this commit could merely expose the problem rather than cause it.
>>>
>>> The problem occurs when the FUN called by mclapply() in the parallel
>>> package returns a S4 object that contains a slot (called X) that is a
>>> large matrix, specifically a "model matrix" similar to that produced
>>> by glm(). Some columns of this matrix get corrupted with wrong values
>>> (usually zero, but sometimes NaN or 10^300ish), which can be seen by
>>> examining X right before FUN returns (to mclapply()'s environment) and
>>> comparing to the "same" X after mclapply() returns to the calling
>>> environment.
>>>
>>> Part of svn commit r58219 is this hunk
>>>
>>> diff --git a/src/library/parallel/R/unix/mcfork.R
>>> b/src/library/parallel/R/unix/mcfork.R
>>> index 8e27534..4f92193 100644
>>> --- a/src/library/parallel/R/unix/mcfork.R
>>> +++ b/src/library/parallel/R/unix/mcfork.R
>>> @@ -82,7 +82,8 @@ mckill<- function(process, signal = 2L)
>>>   ## used by mcparallel, mclapply
>>>   sendMaster<- function(what)
>>>   {
>>> -    if (!is.raw(what)) what<- serialize(what, NULL, FALSE)
>>> +    # This is talking to the same machine, so no point in using xdr.
>>> +    if (!is.raw(what)) what<- serialize(what, NULL, xdr = FALSE)
>>>       .Call(C_mc_send_master, what, PACKAGE = "parallel")
>>>   }
>>>
>>> Contrary to the comment, I have found that if I specify xdr = TRUE, I
>>> get the expected (non-corrupted X slot) behavior in 2.16.0, even
>>> though it is forking locally on my 64bit Debian laptop with a little
>>> endian i7 processor, whose specs are
>>>
>>> goodrich at CYBERPOWERPC:/tmp/serialization$ cat /proc/cpuinfo
>>> processor       : 0
>>> vendor_id       : GenuineIntel
>>> cpu family      : 6
>>> model           : 42
>>> model name      : Intel(R) Core(TM) i7-2630QM CPU @ 2.00GHz
>>> stepping        : 7
>>> microcode       : 0x17
>>> cpu MHz         : 800.000
>>> cache size      : 6144 KB
>>> physical id     : 0
>>> siblings        : 8
>>> core id         : 0
>>> cpu cores       : 4
>>> apicid          : 0
>>> initial apicid  : 0
>>> fpu             : yes
>>> fpu_exception   : yes
>>> cpuid level     : 13
>>> wp              : yes
>>> flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge
>>> mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe
>>> syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl
>>> xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl
>>> vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt
>>> tsc_deadline_timer xsave avx lahf_lm ida arat epb xsaveopt pln pts dts
>>> tpr_shadow vnmi flexpriority ept vpid
>>> bogomips        : 3990.83
>>> clflush size    : 64
>>> cache_alignment : 64
>>> address sizes   : 36 bits physical, 48 bits virtual
>>> power management:
>>>
>>> ...
>>>
>>> processor       : 7
>>> [same as processor 0]
>>>
>>> So, to summarize I get the good behavior on R 2.14.2 when using
>>> mclapply(), on 2.15.0 beta when using lapply(), and on 2.16.0 using
>>> mclapply() iff I patch in xdr = TRUE in sendMaster(). I get the bad
>>> behavior on 2.15.0 beta and unpatched 2.16.0 when using mclapply().
>>>
>>> My session info:
>>>
>>>> sessionInfo()
>>> R version 2.15.0 beta (2012-03-16 r58769)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>   [7] LC_PAPER=C                 LC_NAME=C
>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats4    stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>>
>>> other attached packages:
>>>   [1] mi_0.9-83        bigmemory_4.2.11 arm_1.5-03       foreign_0.8-49
>>>   [5] abind_1.4-0      R2WinBUGS_2.1-18 coda_0.14-5      lme4_0.999375-42
>>>   [9] Matrix_1.0-4     lattice_0.20-0   MASS_7.3-17
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.15.0  nlme_3.1-103
>>>
>>> Thanks,
>>> Ben
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert902 at gmail.com  Wed Mar 28 18:07:12 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 28 Mar 2012 12:07:12 -0400
Subject: [Rd] --as-cran  / BuildVignettes: false
Message-ID: <4F733730.5030104@gmail.com>


I have packages where I know CRAN and other test platforms do not have 
all the resources to build the vignettes, for example, access to 
databases. Previously I think putting

  BuildVignettes: false

in the DESCRIPTION file resolved this, by preventing CRAN checks from 
attempting to run the vignette code. (If it was not this, then there was 
some other magic I don't understand.)

Now, when I specify --as-cran, the checks fail when attempting to check 
R code from vignettes, even though I have "BuildVignettes: false" in the 
DESCRIPTION file.

What is the mechanism for indicating that CRAN should not attempt to 
check this code?  Perhaps it is intentionally difficult - I can see an 
argument for that.  (For running tests there are environment variables, 
e.g._R_CHECK_HAVE_MYSQL_, but using these really clutters up a vignette, 
and it did not seem necessary to use them before.)

(The difficult also occurs on R-forge, possibly because it is using 
--as-cran like settings.)

Paul


From ligges at statistik.tu-dortmund.de  Wed Mar 28 22:21:37 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Mar 2012 22:21:37 +0200
Subject: [Rd] --as-cran  / BuildVignettes: false
In-Reply-To: <4F733730.5030104@gmail.com>
References: <4F733730.5030104@gmail.com>
Message-ID: <4F7372D1.1070609@statistik.tu-dortmund.de>



On 28.03.2012 18:07, Paul Gilbert wrote:
>
> I have packages where I know CRAN and other test platforms do not have
> all the resources to build the vignettes, for example, access to
> databases. Previously I think putting
>
> BuildVignettes: false
>
> in the DESCRIPTION file resolved this, by preventing CRAN checks from
> attempting to run the vignette code. (If it was not this, then there was
> some other magic I don't understand.)
>
> Now, when I specify --as-cran, the checks fail when attempting to check
> R code from vignettes, even though I have "BuildVignettes: false" in the
> DESCRIPTION file.

Paul, it says "BuiltVignettes" rather than "CheckVignettes".
If you want CRAN to disable those checks for some very good reason, 
please tell the CRAN maintainers, they will move your package to the 
exclude list for vignette checking.

Best,
Uwe


>
> What is the mechanism for indicating that CRAN should not attempt to
> check this code? Perhaps it is intentionally difficult - I can see an
> argument for that. (For running tests there are environment variables,
> e.g._R_CHECK_HAVE_MYSQL_, but using these really clutters up a vignette,
> and it did not seem necessary to use them before.)
>
> (The difficult also occurs on R-forge, possibly because it is using
> --as-cran like settings.)
>
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Mar 28 22:25:16 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 28 Mar 2012 22:25:16 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
Message-ID: <4F7373AC.4010409@statistik.tu-dortmund.de>



On 28.03.2012 16:30, Gabor Grothendieck wrote:
> 2012/3/28 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 27.03.2012 20:33, Jeffrey Ryan wrote:
>>>
>>> Thanks Uwe for the clarification on what goes and what stays.
>>>
>>> Still fuzzy on the notion of "significant" though.  Do you have an example
>>> or two for the list?
>>
>>
>>
>> We have to look at those notes again and again in order to find if something
>> important is noted, hence please always try to avoid all notes unless the
>> effect is really intended!
>>
>>
>> Consider the Note "No visible binding for global variable"
>> We cannot know if your code intends to use such a global variable (which is
>> undesirable in most cases), hence would let is pass if it seems to be
>> sensible.
>>
>> Another Note such as "empty section" or "partial argument match" can quickly
>> be fixed, hence just do it and don't waste our time.
>>
>> Best,
>> Uwe Ligges
>
> What is the point of notes vs warnings if you have to get rid of both
> of them?  Furthermore, if there are notes that you don't have to get
> rid of its not fair that package developers should have to waste their
> time on things that are actually acceptable.  Finally, it makes the
> whole system arbitrary since packages can be rejected based on
> undefined rules.
>
> Either divide notes into significant notes and ordinary notes and
> clearly label them as such in the output of   R CMD check   or else
> make the significant notes warnings so one can know in advance whether
> the package passes R CMD check or not.
>


I tried to make clear that we cannot decide that automatically and it 
needs human inspection and thinking if some Note is significant or not. 
That why we have not made them Warnings where we are sure things have to 
be fixed.

Please always try to avoid all notes unless the effect is really 
intended! How hard can it be? If Notes could be completely ignored, they 
would not be Notes.

Uwe


From tlumley at uw.edu  Thu Mar 29 05:52:13 2012
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 29 Mar 2012 16:52:13 +1300
Subject: [Rd] CRAN policies
In-Reply-To: <CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
Message-ID: <CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>

On Thu, Mar 29, 2012 at 3:30 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> 2012/3/28 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 27.03.2012 20:33, Jeffrey Ryan wrote:
>>>
>>> Thanks Uwe for the clarification on what goes and what stays.
>>>
>>> Still fuzzy on the notion of "significant" though. ?Do you have an example
>>> or two for the list?
>>
>>
>>
>> We have to look at those notes again and again in order to find if something
>> important is noted, hence please always try to avoid all notes unless the
>> effect is really intended!
>>
>>
>> Consider the Note "No visible binding for global variable"
>> We cannot know if your code intends to use such a global variable (which is
>> undesirable in most cases), hence would let is pass if it seems to be
>> sensible.
>>
>> Another Note such as "empty section" or "partial argument match" can quickly
>> be fixed, hence just do it and don't waste our time.
>>
>> Best,
>> Uwe Ligges
>
> What is the point of notes vs warnings if you have to get rid of both
> of them? ?Furthermore, if there are notes that you don't have to get
> rid of its not fair that package developers should have to waste their
> time on things that are actually acceptable. ?Finally, it makes the
> whole system arbitrary since packages can be rejected based on
> undefined rules.
>

The "notes" are precisely the things for which clear rules can't be
written.  They are reported by CMD check because they are usually
signs of coding errors, but are not warnings because their use is
sometimes justified.

The 'No visible binding for global variable" is a good example.  This
found some bugs in my 'survey' package, which I removed. There is
still one note of this type, which arises when I have to handle two
different versions of the hexbin package with different internal
structures.  The note is a false positive because the use is guarded
by an if(), but  CMD check can't tell this.   So, it's a good idea to
remove all Notes that can be removed without introducing other code
problems, which is nearly all of them, but occasionally there may be a
good reason for code that produces a Note.

But if you want a simple, unambiguous, mechanical rule for *your*
packages, just eliminate all Notes.

   -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From hdai at cmh.edu  Wed Mar 28 23:34:19 2012
From: hdai at cmh.edu (Dai, Hongying,)
Date: Wed, 28 Mar 2012 16:34:19 -0500
Subject: [Rd] How to create arbitrary number of loops
Message-ID: <1F3EE502B66950448F4408BD16CBFDEF750B616F@CMHMAIL0.CMH.Internal>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120328/cce9ae82/attachment.pl>

From ggrothendieck at gmail.com  Thu Mar 29 13:50:50 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 29 Mar 2012 07:50:50 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
	<CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
Message-ID: <CAP01uR=Va5UmGdqk0nOVNsCr1Rq+zJji=RDO=_8DEjCqSQ5kXg@mail.gmail.com>

On Wed, Mar 28, 2012 at 11:52 PM, Thomas Lumley <tlumley at uw.edu> wrote:
> On Thu, Mar 29, 2012 at 3:30 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> 2012/3/28 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 27.03.2012 20:33, Jeffrey Ryan wrote:
>>>>
>>>> Thanks Uwe for the clarification on what goes and what stays.
>>>>
>>>> Still fuzzy on the notion of "significant" though. ?Do you have an example
>>>> or two for the list?
>>>
>>>
>>>
>>> We have to look at those notes again and again in order to find if something
>>> important is noted, hence please always try to avoid all notes unless the
>>> effect is really intended!
>>>
>>>
>>> Consider the Note "No visible binding for global variable"
>>> We cannot know if your code intends to use such a global variable (which is
>>> undesirable in most cases), hence would let is pass if it seems to be
>>> sensible.
>>>
>>> Another Note such as "empty section" or "partial argument match" can quickly
>>> be fixed, hence just do it and don't waste our time.
>>>
>>> Best,
>>> Uwe Ligges
>>
>> What is the point of notes vs warnings if you have to get rid of both
>> of them? ?Furthermore, if there are notes that you don't have to get
>> rid of its not fair that package developers should have to waste their
>> time on things that are actually acceptable. ?Finally, it makes the
>> whole system arbitrary since packages can be rejected based on
>> undefined rules.
>>
>
> The "notes" are precisely the things for which clear rules can't be
> written. ?They are reported by CMD check because they are usually
> signs of coding errors, but are not warnings because their use is
> sometimes justified.
>
> The 'No visible binding for global variable" is a good example. ?This
> found some bugs in my 'survey' package, which I removed. There is
> still one note of this type, which arises when I have to handle two
> different versions of the hexbin package with different internal
> structures. ?The note is a false positive because the use is guarded
> by an if(), but ?CMD check can't tell this. ? So, it's a good idea to
> remove all Notes that can be removed without introducing other code
> problems, which is nearly all of them, but occasionally there may be a
> good reason for code that produces a Note.
>
> But if you want a simple, unambiguous, mechanical rule for *your*
> packages, just eliminate all Notes.

I think it would be more objective and also easiest for everyone if
notes were accepted.

It might be that over time some notes could be split into multiple
cases some of which are warnings and others continue to be notes.

That way package developers don't have to waste their time on getting
rid of notes which don't matter and the CRAN maintainers can turn the
task of reviewing notes over to the computer.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From brian at braverock.com  Thu Mar 29 14:58:12 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 29 Mar 2012 07:58:12 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
	<CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
Message-ID: <1333025892.27217.141.camel@brian-rcg>

On Thu, 2012-03-29 at 16:52 +1300, Thomas Lumley wrote:
> The 'No visible binding for global variable" is a good example.  This
> found some bugs in my 'survey' package, which I removed. There is
> still one note of this type, which arises when I have to handle two
> different versions of the hexbin package with different internal
> structures.  The note is a false positive because the use is guarded
> by an if(), but  CMD check can't tell this.   So, it's a good idea to
> remove all Notes that can be removed without introducing other code
> problems, which is nearly all of them, but occasionally there may be a
> good reason for code that produces a Note.
> 
'occasionally' seems like an understatement.

Here's an example:

data(cars)
lm(speed ~ dist,cars) #would produce global variables NOTE
lm("speed ~ dist",cars) # would not produce the NOTE

While the change required to avoid the CRAN NOTE is small, I can't think
of a single example or text on using formulas that recommends quoting
the formula as a best practice.  I'm not sure how users or package
authors are supposed to know that they should use a (non standard) way
of specifying the formula to avoid wasting their time, and the CRAN
volunteers time.  I'm certain that there are many other examples, but
this one was easy to demonstrate.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From sarah.goslee at gmail.com  Thu Mar 29 15:35:27 2012
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 29 Mar 2012 09:35:27 -0400
Subject: [Rd] How to create arbitrary number of loops
In-Reply-To: <1F3EE502B66950448F4408BD16CBFDEF750B616F@CMHMAIL0.CMH.Internal>
References: <1F3EE502B66950448F4408BD16CBFDEF750B616F@CMHMAIL0.CMH.Internal>
Message-ID: <CAM_vjukTv1fUCjdcDi9RMGd=W8LJgMcEuGO8KsHX5YrsZOoPtg@mail.gmail.com>

That sounds like a job for recursion.

And also, a question for r-help and not r-devel.

Sarah

On Wed, Mar 28, 2012 at 5:34 PM, Dai, Hongying, <hdai at cmh.edu> wrote:
> Dear R users,
>
> I'm wondering how I can generate an arbitrary number of loops in R.
> For instance, I can generate two "for" loops to get ICC among any two-way combination among 10 variables. Here is the code
>
> n<-10
> for (i in 1:(n-1))
> {
> for (j in (i+1):n)
> {
> icc(cbind(DATA[,i],DATA[,j]))
> }
> }
> If I need three-way combination, then a code with three "for" loops will be:
> n<-10
> for (i in 1:(n-2))
> {
> for (j in (i+1):(n-1))
> {
> for (k in (j+1):n)
> {
> icc(cbind(DATA[,i],DATA[,j],DATA[,k]))
> }
> }
> }
> But how can I write a code if I need all m=2, 3, 4,... loops for arbitrary m-way combinations?
> Thanks!
> Daisy

-- 
Sarah Goslee
http://www.functionaldiversity.org


From pdalgd at gmail.com  Thu Mar 29 15:47:14 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 29 Mar 2012 15:47:14 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <1333025892.27217.141.camel@brian-rcg>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
	<CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
	<1333025892.27217.141.camel@brian-rcg>
Message-ID: <EF098E2D-F06A-4F97-980A-084E73ED6129@gmail.com>


On Mar 29, 2012, at 14:58 , Brian G. Peterson wrote:

> On Thu, 2012-03-29 at 16:52 +1300, Thomas Lumley wrote:
>> The 'No visible binding for global variable" is a good example.  This
>> found some bugs in my 'survey' package, which I removed. There is
>> still one note of this type, which arises when I have to handle two
>> different versions of the hexbin package with different internal
>> structures.  The note is a false positive because the use is guarded
>> by an if(), but  CMD check can't tell this.   So, it's a good idea to
>> remove all Notes that can be removed without introducing other code
>> problems, which is nearly all of them, but occasionally there may be a
>> good reason for code that produces a Note.
>> 
> 'occasionally' seems like an understatement.
> 
> Here's an example:
> 
> data(cars)
> lm(speed ~ dist,cars) #would produce global variables NOTE
> lm("speed ~ dist",cars) # would not produce the NOTE

Context, please. Where does this happen? (and why do you need data(cars)?)

I find it hard to believe that quoting the formula should be the solution to this issue. There must be tons of examples to the contrary.


> 
> While the change required to avoid the CRAN NOTE is small, I can't think
> of a single example or text on using formulas that recommends quoting
> the formula as a best practice.  I'm not sure how users or package
> authors are supposed to know that they should use a (non standard) way
> of specifying the formula to avoid wasting their time, and the CRAN
> volunteers time.  I'm certain that there are many other examples, but
> this one was easy to demonstrate.
> 
> Regards,
> 
>   - Brian
> 
> -- 
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Thu Mar 29 16:01:56 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 29 Mar 2012 09:01:56 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <mailman.19.1333015207.14516.r-devel@r-project.org>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
Message-ID: <4F746B54.2050601@mayo.edu>

On 03/29/2012 05:00 AM, r-devel-request at r-project.org wrote:
> The 'No visible binding for global variable" is a good example.  This
> found some bugs in my 'survey' package, which I removed. There is
> still one note of this type, which arises when I have to handle two
> different versions of the hexbin package with different internal
> structures.  The note is a false positive because the use is guarded
> by an if(), but  CMD check can't tell this.   So, it's a good idea to
> remove all Notes that can be removed without introducing other code
> problems, which is nearly all of them, but occasionally there may be a
> good reason for code that produces a Note.
The survival package has a similar special case: the routines for 
expected population survival are set up to accept multiple types of date 
format so have lines like
     if (class(x) == 'chron') { y <- as.numeric(x - chron("01/01/1960")}
This leaves me with two extraneous "no visible binding" messages.  There 
used to be half a dozen but I've tried to remove as many as possible, 
for all the good reasons already articulated by the maintainers.

It still remains that 99/100 of the "no visible binding" messages I've 
seen over the years were misspelled variable names, and the message is a 
very welcome check.

Terry Therneau


From edd at debian.org  Thu Mar 29 16:07:07 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 29 Mar 2012 09:07:07 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <1333025892.27217.141.camel@brian-rcg>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
	<CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
	<1333025892.27217.141.camel@brian-rcg>
Message-ID: <20340.27787.279109.551834@max.nulle.part>


On 29 March 2012 at 07:58, Brian G. Peterson wrote:
| On Thu, 2012-03-29 at 16:52 +1300, Thomas Lumley wrote:
| > The 'No visible binding for global variable" is a good example.  This
| > found some bugs in my 'survey' package, which I removed. There is
| > still one note of this type, which arises when I have to handle two
| > different versions of the hexbin package with different internal
| > structures.  The note is a false positive because the use is guarded
| > by an if(), but  CMD check can't tell this.   So, it's a good idea to
| > remove all Notes that can be removed without introducing other code
| > problems, which is nearly all of them, but occasionally there may be a
| > good reason for code that produces a Note.
| > 
| 'occasionally' seems like an understatement.
| 
| Here's an example:
| 
| data(cars)
| lm(speed ~ dist,cars) #would produce global variables NOTE
| lm("speed ~ dist",cars) # would not produce the NOTE
| 
| While the change required to avoid the CRAN NOTE is small, I can't think
| of a single example or text on using formulas that recommends quoting
| the formula as a best practice.  I'm not sure how users or package
| authors are supposed to know that they should use a (non standard) way
| of specifying the formula to avoid wasting their time, and the CRAN
| volunteers time.  I'm certain that there are many other examples, but
| this one was easy to demonstrate.

And it's close to my personal favourite of 

    with( cars,  ... some expression involving dist and / or speed ... )

which gives the same warning about dist and speed being unknown globals.
Punishment for good coding style -- gotta love it.


Now, we all want high-quality packages. 

We all strive to have as few false positives. 

And we all understand that writing a parser if freaking hard.

One fudge-y way of helping with this may be via an overrides file. 

This is what Debian does to suppress known / tolerated violations of what the
'lintian' package checker picks up on.  For the R package, I have a fair
number of these: the file for the r-base-core binary is currently 83 lines
long and this ends on

  r-base-core: executable-not-elf-or-script usr/lib/R/bin/Rdiff
  r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/mai.png
  r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/oma.png
  r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/pch.png
  r-base-core: executable-not-elf-or-script usr/lib/R/bin/Rd2pdf

two warnings on files with 755 modes in a non-PATH location (fine, that's how
R works) and idem with image files below /usr/lib (when the FHS probably
prefers them below /usr/share/).

You pipe the output of a lintian run into 'lintian-info' and you get longer
one or two paragraph descriptions with further pointers on the violations.

Does this sounds like something worthwhile to add to the R CMD check system ?

Should we consider to allow overrides to make known good exceptions good away?

Dirk

-- 
R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
See agenda, registration details and more at http://www.RinFinance.com


From spencer.graves at prodsyse.com  Thu Mar 29 16:43:02 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 29 Mar 2012 07:43:02 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <20340.27787.279109.551834@max.nulle.part>
References: <CB9770B4.36D98%jeff.a.ryan@gmail.com>
	<4F731B09.5000203@statistik.tu-dortmund.de>
	<CAP01uRmob_VSmgVc80yek3g4D3K0tedmmU1EbmHJ3CCpgRQDgw@mail.gmail.com>
	<CAJ55+d+cTBjmhWt86W=fQMJq2_Zxib-4ufTobbF7z7W1LYfDyg@mail.gmail.com>
	<1333025892.27217.141.camel@brian-rcg>
	<20340.27787.279109.551834@max.nulle.part>
Message-ID: <4F7474F6.6040300@prodsyse.com>

On 3/29/2012 7:07 AM, Dirk Eddelbuettel wrote:
> On 29 March 2012 at 07:58, Brian G. Peterson wrote:
> | On Thu, 2012-03-29 at 16:52 +1300, Thomas Lumley wrote:
> |>  The 'No visible binding for global variable" is a good example.  This
> |>  found some bugs in my 'survey' package, which I removed. There is
> |>  still one note of this type, which arises when I have to handle two
> |>  different versions of the hexbin package with different internal
> |>  structures.  The note is a false positive because the use is guarded
> |>  by an if(), but  CMD check can't tell this.   So, it's a good idea to
> |>  remove all Notes that can be removed without introducing other code
> |>  problems, which is nearly all of them, but occasionally there may be a
> |>  good reason for code that produces a Note.
> |>
> | 'occasionally' seems like an understatement.
> |
> | Here's an example:
> |
> | data(cars)
> | lm(speed ~ dist,cars) #would produce global variables NOTE
> | lm("speed ~ dist",cars) # would not produce the NOTE


Another example using library(ggplot2):


=qplot(time., value, data=X, geom='line',
                     facets=facets, color=variable, xlim=xlim, ylim=ylim,
                     xlab='days', ylab='displacement (inches)', ...),


       "value" and "variable" are columns of "X".  If I knew how to list 
this in an "overrides" file, I would do so.  My experience is similar to 
what others mentioned:  99 percent of the "No visible bindings" messages 
I've seen are my coding errors.  This one is not.  I don't recall for 
sure, but I think I checked trying putting "value" and "variable" in 
quotes, and it didn't work.


       The function that includes this call to "qplot" actually includes 
the definition of a global variable "time.", which is NOT used, because 
"X" has a column named "time.".  The global variable "time." is a 
character string, while "X$time." is class POSIXct.


       I mention this, because this discussion suddenly told me how to 
get rid of this NOTE:  Precede this call to qplot with something like 
the following:


       value <- variable <- "NOTE:  Define these variables to override 
the NOTE impulse in R CMD check'


       I haven't tried this with "qplot", but it ignores the global 
variable "Time." and uses the "Time." column of "X", so it should work.  
I just tried something similar with "lm", and it ignored a global 
variable in favor of a column of "X".  This is a silly kludge, but it's 
simple and does not require a modification to "R CMD check".


       Spencer


> |
> | While the change required to avoid the CRAN NOTE is small, I can't think
> | of a single example or text on using formulas that recommends quoting
> | the formula as a best practice.  I'm not sure how users or package
> | authors are supposed to know that they should use a (non standard) way
> | of specifying the formula to avoid wasting their time, and the CRAN
> | volunteers time.  I'm certain that there are many other examples, but
> | this one was easy to demonstrate.
>
> And it's close to my personal favourite of
>
>      with( cars,  ... some expression involving dist and / or speed ... )
>
> which gives the same warning about dist and speed being unknown globals.
> Punishment for good coding style -- gotta love it.
>
>
> Now, we all want high-quality packages.
>
> We all strive to have as few false positives.
>
> And we all understand that writing a parser if freaking hard.
>
> One fudge-y way of helping with this may be via an overrides file.
>
> This is what Debian does to suppress known / tolerated violations of what the
> 'lintian' package checker picks up on.  For the R package, I have a fair
> number of these: the file for the r-base-core binary is currently 83 lines
> long and this ends on
>
>    r-base-core: executable-not-elf-or-script usr/lib/R/bin/Rdiff
>    r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/mai.png
>    r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/oma.png
>    r-base-core: image-file-in-usr-lib usr/lib/R/library/graphics/help/figures/pch.png
>    r-base-core: executable-not-elf-or-script usr/lib/R/bin/Rd2pdf
>
> two warnings on files with 755 modes in a non-PATH location (fine, that's how
> R works) and idem with image files below /usr/lib (when the FHS probably
> prefers them below /usr/share/).
>
> You pipe the output of a lintian run into 'lintian-info' and you get longer
> one or two paragraph descriptions with further pointers on the violations.
>
> Does this sounds like something worthwhile to add to the R CMD check system ?
>
> Should we consider to allow overrides to make known good exceptions good away?
>
> Dirk
>


From wdunlap at tibco.com  Thu Mar 29 18:19:14 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 29 Mar 2012 16:19:14 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <4F746B54.2050601@mayo.edu>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Terry Therneau
> Sent: Thursday, March 29, 2012 7:02 AM
> To: r-devel at r-project.org
> Subject: Re: [Rd] CRAN policies
> 
> On 03/29/2012 05:00 AM, r-devel-request at r-project.org wrote:
> > The 'No visible binding for global variable" is a good example.  This
> > found some bugs in my 'survey' package, which I removed. There is
> > still one note of this type, which arises when I have to handle two
> > different versions of the hexbin package with different internal
> > structures.  The note is a false positive because the use is guarded
> > by an if(), but  CMD check can't tell this.   So, it's a good idea to
> > remove all Notes that can be removed without introducing other code
> > problems, which is nearly all of them, but occasionally there may be a
> > good reason for code that produces a Note.
> The survival package has a similar special case: the routines for
> expected population survival are set up to accept multiple types of date
> format so have lines like
>      if (class(x) == 'chron') { y <- as.numeric(x - chron("01/01/1960")}
> This leaves me with two extraneous "no visible binding" messages.

Suppose we defined a function like
  NO_VISIBLE_BINDING(expr) expr
and added an entry to the stuff in codetools so that it
would not check for misspelled object names in call to
NO_VISIBLE_BINDING.  Then Terry could write that line as
     if (class(x) == "chron") { y <- as.numeric(x - NO_VISIBLE_BINDING(chron)("01/01/1960")}
and the Notes would disappear.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> There
> used to be half a dozen but I've tried to remove as many as possible,
> for all the good reasons already articulated by the maintainers.
> 
> It still remains that 99/100 of the "no visible binding" messages I've
> seen over the years were misspelled variable names, and the message is a
> very welcome check.
> 
> Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Thu Mar 29 18:58:49 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 29 Mar 2012 11:58:49 -0500
Subject: [Rd] Vignettes and CRAN checks
Message-ID: <4F7494C9.50208@mayo.edu>

I'l like to chime in on the subject of vignette checks.
I have one vignette in the coxme library that would be better described 
as a white paper. It discusses the adequacy of the Laplace transform 
under various scenarios.  It contains some substantial computations, so 
I'd like to mark it as "never ever run this" for both CRAN and my local 
builds, my next update of it will turn it into a 30+ minute 
compuatation.  Almost all users will need only the pdf;  however, my 
master file for creating it is .Rnw form and I'd like to make it 
available to those who might want to dig deeper.  I (and every other 
program I know of) had always assumed that the Laplace approx was 
excellent for a mixed effects Cox model, I'm finding out that that there 
are a few cases where this isn't so.  Luckily only a few, but this is 
important documentation.

I also have more conventional vignettes of the "how to use this package" 
variety, the standard CRAN check process for those is both welcome and 
appropriate.

Terry T.


From mdowle at mdowle.plus.com  Thu Mar 29 19:40:34 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 29 Mar 2012 17:40:34 +0000
Subject: [Rd] CRAN policies
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
Message-ID: <loom.20120329T190333-975@post.gmane.org>

William Dunlap <wdunlap <at> tibco.com> writes:

> > -----Original Message-----
> > The survival package has a similar special case: the routines for
> > expected population survival are set up to accept multiple types of date
> > format so have lines like
> >      if (class(x) == 'chron') { y <- as.numeric(x - chron("01/01/1960")}
> > This leaves me with two extraneous "no visible binding" messages.
> 
> Suppose we defined a function like
>   NO_VISIBLE_BINDING(expr) expr
> and added an entry to the stuff in codetools so that it
> would not check for misspelled object names in call to
> NO_VISIBLE_BINDING.  Then Terry could write that line as
>      if (class(x) == "chron") { y <- as.numeric(x - NO_VISIBLE_BINDING(chron)
("01/01/1960")}
> and the Notes would disappear.
> 

That's ok for package code, but what about test suites?  Say there was a test 
on the result of "with(DF,a+b)", you wouldn't want to change the test to "with
(DF,NO_VISIBLE_BINDING(a)+NO_VISIBLE_BINDING(b))" not just because that's long 
and onerous, but because that's *changing* the test i.e. introducing a 
difference between what's tested and what user code will do.

As others suggested, how about a new category: MEMO. The "no visible binding" 
NOTE would be downgraded to MEMO. CRAN maintainers could then ignore MEMOs more 
easily.

What I really like about NOTES is that when new checks are added to R then as a 
package maintainer you know you don't have to fix them straight away. If a new 
WARNING shows up on r-devel daily checks, however, then you've got some warning 
about the WARNING that you need to fix more urgently and may even accelerate a 
release. So it's not just about checks when submitting a package, but what 
happens afterwards as R itself (and packages in Depends) move on. In other 
words, you know you need to fix new NOTES but not as urgently as new WARNINGS.

Matthew


From wdunlap at tibco.com  Thu Mar 29 20:29:58 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 29 Mar 2012 18:29:58 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <loom.20120329T190333-975@post.gmane.org>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
Message-ID: <E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>



Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Matthew Dowle
> Sent: Thursday, March 29, 2012 10:41 AM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
> William Dunlap <wdunlap <at> tibco.com> writes:
> 
> > > -----Original Message-----
> > > The survival package has a similar special case: the routines for
> > > expected population survival are set up to accept multiple types of date
> > > format so have lines like
> > >      if (class(x) == 'chron') { y <- as.numeric(x - chron("01/01/1960")}
> > > This leaves me with two extraneous "no visible binding" messages.
> >
> > Suppose we defined a function like
> >   NO_VISIBLE_BINDING(expr) expr
> > and added an entry to the stuff in codetools so that it
> > would not check for misspelled object names in call to
> > NO_VISIBLE_BINDING.  Then Terry could write that line as
> >      if (class(x) == "chron") { y <- as.numeric(x - NO_VISIBLE_BINDING(chron)
> ("01/01/1960")}
> > and the Notes would disappear.
> >
> 
> That's ok for package code, but what about test suites?  Say there was a test
> on the result of "with(DF,a+b)", you wouldn't want to change the test to "with
> (DF,NO_VISIBLE_BINDING(a)+NO_VISIBLE_BINDING(b))" not just because that's long
> and onerous, but because that's *changing* the test i.e. introducing a
> difference between what's tested and what user code will do.

I don't know if test suites need to be checked for no visible bindings -
if there is a real problem the test ought to fail.

codetools should be able to do special checks for known functions that
do not following the standard evaluation rules .   E.g., do not check any
arguments of `~`, do not check the 'expr' argument of with, do not check
the subset or weights arguments of lm.

If a package writer introduces a new function with nonstandard evaluation,
perhaps the package could include some information about the matter
in a file that codetools could could source before running its checks.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com
> 
> As others suggested, how about a new category: MEMO. The "no visible binding"
> NOTE would be downgraded to MEMO. CRAN maintainers could then ignore MEMOs
> more
> easily.
> 
> What I really like about NOTES is that when new checks are added to R then as a
> package maintainer you know you don't have to fix them straight away. If a new
> WARNING shows up on r-devel daily checks, however, then you've got some warning
> about the WARNING that you need to fix more urgently and may even accelerate a
> release. So it's not just about checks when submitting a package, but what
> happens afterwards as R itself (and packages in Depends) move on. In other
> words, you know you need to fix new NOTES but not as urgently as new WARNINGS.
> 
> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From brechbuehler at gmail.com  Thu Mar 29 21:05:34 2012
From: brechbuehler at gmail.com (=?ISO-8859-1?Q?Christian_Brechb=FChler?=)
Date: Thu, 29 Mar 2012 15:05:34 -0400
Subject: [Rd] How to create arbitrary number of loops
In-Reply-To: <1F3EE502B66950448F4408BD16CBFDEF750B616F@CMHMAIL0.CMH.Internal>
References: <1F3EE502B66950448F4408BD16CBFDEF750B616F@CMHMAIL0.CMH.Internal>
Message-ID: <CAJLQA-46eDAZRse-=0ZLf_UBjOjk9kky0KJi-UWEaya3kav1AQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120329/847aa254/attachment.pl>

From spencer.graves at prodsyse.com  Thu Mar 29 21:21:59 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 29 Mar 2012 12:21:59 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
Message-ID: <4F74B657.5040807@prodsyse.com>

On 3/29/2012 11:29 AM, William Dunlap wrote:
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Matthew Dowle
>> Sent: Thursday, March 29, 2012 10:41 AM
>> To: r-devel at stat.math.ethz.ch
>> Subject: Re: [Rd] CRAN policies
>>
>> William Dunlap<wdunlap<at>  tibco.com>  writes:
>>
>>>> -----Original Message-----
>>>> The survival package has a similar special case: the routines for
>>>> expected population survival are set up to accept multiple types of date
>>>> format so have lines like
>>>>       if (class(x) == 'chron') { y<- as.numeric(x - chron("01/01/1960")}
>>>> This leaves me with two extraneous "no visible binding" messages.
>>> Suppose we defined a function like
>>>    NO_VISIBLE_BINDING(expr) expr
>>> and added an entry to the stuff in codetools so that it
>>> would not check for misspelled object names in call to
>>> NO_VISIBLE_BINDING.  Then Terry could write that line as
>>>       if (class(x) == "chron") { y<- as.numeric(x - NO_VISIBLE_BINDING(chron)
>> ("01/01/1960")}
>>> and the Notes would disappear.
>>>
>> That's ok for package code, but what about test suites?  Say there was a test
>> on the result of "with(DF,a+b)", you wouldn't want to change the test to "with
>> (DF,NO_VISIBLE_BINDING(a)+NO_VISIBLE_BINDING(b))" not just because that's long
>> and onerous, but because that's *changing* the test i.e. introducing a
>> difference between what's tested and what user code will do.
> I don't know if test suites need to be checked for no visible bindings -
> if there is a real problem the test ought to fail.
>
> codetools should be able to do special checks for known functions that
> do not following the standard evaluation rules .   E.g., do not check any
> arguments of `~`, do not check the 'expr' argument of with, do not check
> the subset or weights arguments of lm.
>
> If a package writer introduces a new function with nonstandard evaluation,
> perhaps the package could include some information about the matter
> in a file that codetools could could source before running its checks.


       This gets my vote -- but I don't have the bandwidth nor authority 
to effect the change ;-)  Spencer
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>> As others suggested, how about a new category: MEMO. The "no visible binding"
>> NOTE would be downgraded to MEMO. CRAN maintainers could then ignore MEMOs
>> more
>> easily.
>>
>> What I really like about NOTES is that when new checks are added to R then as a
>> package maintainer you know you don't have to fix them straight away. If a new
>> WARNING shows up on r-devel daily checks, however, then you've got some warning
>> about the WARNING that you need to fix more urgently and may even accelerate a
>> release. So it's not just about checks when submitting a package, but what
>> happens afterwards as R itself (and packages in Depends) move on. In other
>> words, you know you need to fix new NOTES but not as urgently as new WARNINGS.
>>
>> Matthew
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Mar 29 20:29:58 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 29 Mar 2012 18:29:58 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <loom.20120329T190333-975@post.gmane.org>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
Message-ID: <E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>



Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Matthew Dowle
> Sent: Thursday, March 29, 2012 10:41 AM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
> William Dunlap <wdunlap <at> tibco.com> writes:
> 
> > > -----Original Message-----
> > > The survival package has a similar special case: the routines for
> > > expected population survival are set up to accept multiple types of date
> > > format so have lines like
> > >      if (class(x) == 'chron') { y <- as.numeric(x - chron("01/01/1960")}
> > > This leaves me with two extraneous "no visible binding" messages.
> >
> > Suppose we defined a function like
> >   NO_VISIBLE_BINDING(expr) expr
> > and added an entry to the stuff in codetools so that it
> > would not check for misspelled object names in call to
> > NO_VISIBLE_BINDING.  Then Terry could write that line as
> >      if (class(x) == "chron") { y <- as.numeric(x - NO_VISIBLE_BINDING(chron)
> ("01/01/1960")}
> > and the Notes would disappear.
> >
> 
> That's ok for package code, but what about test suites?  Say there was a test
> on the result of "with(DF,a+b)", you wouldn't want to change the test to "with
> (DF,NO_VISIBLE_BINDING(a)+NO_VISIBLE_BINDING(b))" not just because that's long
> and onerous, but because that's *changing* the test i.e. introducing a
> difference between what's tested and what user code will do.

I don't know if test suites need to be checked for no visible bindings -
if there is a real problem the test ought to fail.

codetools should be able to do special checks for known functions that
do not following the standard evaluation rules .   E.g., do not check any
arguments of `~`, do not check the 'expr' argument of with, do not check
the subset or weights arguments of lm.

If a package writer introduces a new function with nonstandard evaluation,
perhaps the package could include some information about the matter
in a file that codetools could could source before running its checks.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com
> 
> As others suggested, how about a new category: MEMO. The "no visible binding"
> NOTE would be downgraded to MEMO. CRAN maintainers could then ignore MEMOs
> more
> easily.
> 
> What I really like about NOTES is that when new checks are added to R then as a
> package maintainer you know you don't have to fix them straight away. If a new
> WARNING shows up on r-devel daily checks, however, then you've got some warning
> about the WARNING that you need to fix more urgently and may even accelerate a
> release. So it's not just about checks when submitting a package, but what
> happens afterwards as R itself (and packages in Depends) move on. In other
> words, you know you need to fix new NOTES but not as urgently as new WARNINGS.
> 
> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Mar 29 22:21:38 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 29 Mar 2012 20:21:38 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <4F74B657.5040807@prodsyse.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>

> > codetools should be able to do special checks for known functions that
> > do not following the standard evaluation rules .   E.g., do not check any
> > arguments of `~`, do not check the 'expr' argument of with, do not check
> > the subset or weights arguments of lm.
> >
> > If a package writer introduces a new function with nonstandard evaluation,
> > perhaps the package could include some information about the matter
> > in a file that codetools could could source before running its checks.
> 
> 
>        This gets my vote -- but I don't have the bandwidth nor authority
> to effect the change ;-)  Spencer

Most of that stuff is already in codetools, at least when it is checking functions
with checkUsage().  E.g., arguments of ~ are not checked.  The  expr argument
to with() will not be checked if you add  skipWith=FALSE to the call to checkUsage.

  > library(codetools)

  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}))
  <anonymous>: no visible binding for global variable 'Num' (:1)
  <anonymous>: no visible binding for global variable 'Den' (:1)

  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)

  > checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)
  <anonymous>: no visible binding for global variable 'DataFrame'

The only part that I don't see is the mechanism to add code-walker functions to
the environment in codetools that has the standard list of them for functions with
nonstandard evaluation:
  > objects(codetools:::collectUsageHandlers, all=TRUE)
   [1] "$"             "$<-"           ".Internal"    
   [4] "::"            ":::"           "@"            
   [7] "@<-"           "{"             "~"            
  [10] "<-"            "<<-"           "="            
  [13] "assign"        "binomial"      "bquote"       
  [16] "data"          "detach"        "expression"   
  [19] "for"           "function"      "Gamma"        
  [22] "gaussian"      "if"            "library"      
  [25] "local"         "poisson"       "quasi"        
  [28] "quasibinomial" "quasipoisson"  "quote"        
  [31] "Quote"         "require"       "substitute"   
  [34] "with"         

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at prodsyse.com]
> Sent: Thursday, March 29, 2012 12:22 PM
> To: William Dunlap
> Cc: Matthew Dowle; r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
> On 3/29/2012 11:29 AM, William Dunlap wrote:
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On
> Behalf
> >> Of Matthew Dowle
> >> Sent: Thursday, March 29, 2012 10:41 AM
> >> To: r-devel at stat.math.ethz.ch
> >> Subject: Re: [Rd] CRAN policies
> >>
> >> William Dunlap<wdunlap<at>  tibco.com>  writes:
> >>
> >>>> -----Original Message-----
> >>>> The survival package has a similar special case: the routines for
> >>>> expected population survival are set up to accept multiple types of date
> >>>> format so have lines like
> >>>>       if (class(x) == 'chron') { y<- as.numeric(x - chron("01/01/1960")}
> >>>> This leaves me with two extraneous "no visible binding" messages.
> >>> Suppose we defined a function like
> >>>    NO_VISIBLE_BINDING(expr) expr
> >>> and added an entry to the stuff in codetools so that it
> >>> would not check for misspelled object names in call to
> >>> NO_VISIBLE_BINDING.  Then Terry could write that line as
> >>>       if (class(x) == "chron") { y<- as.numeric(x - NO_VISIBLE_BINDING(chron)
> >> ("01/01/1960")}
> >>> and the Notes would disappear.
> >>>
> >> That's ok for package code, but what about test suites?  Say there was a test
> >> on the result of "with(DF,a+b)", you wouldn't want to change the test to "with
> >> (DF,NO_VISIBLE_BINDING(a)+NO_VISIBLE_BINDING(b))" not just because that's long
> >> and onerous, but because that's *changing* the test i.e. introducing a
> >> difference between what's tested and what user code will do.
> > I don't know if test suites need to be checked for no visible bindings -
> > if there is a real problem the test ought to fail.
> >
> > codetools should be able to do special checks for known functions that
> > do not following the standard evaluation rules .   E.g., do not check any
> > arguments of `~`, do not check the 'expr' argument of with, do not check
> > the subset or weights arguments of lm.
> >
> > If a package writer introduces a new function with nonstandard evaluation,
> > perhaps the package could include some information about the matter
> > in a file that codetools could could source before running its checks.
> 
> 
>        This gets my vote -- but I don't have the bandwidth nor authority
> to effect the change ;-)  Spencer
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >> As others suggested, how about a new category: MEMO. The "no visible binding"
> >> NOTE would be downgraded to MEMO. CRAN maintainers could then ignore MEMOs
> >> more
> >> easily.
> >>
> >> What I really like about NOTES is that when new checks are added to R then as a
> >> package maintainer you know you don't have to fix them straight away. If a new
> >> WARNING shows up on r-devel daily checks, however, then you've got some warning
> >> about the WARNING that you need to fix more urgently and may even accelerate a
> >> release. So it's not just about checks when submitting a package, but what
> >> happens afterwards as R itself (and packages in Depends) move on. In other
> >> words, you know you need to fix new NOTES but not as urgently as new WARNINGS.
> >>
> >> Matthew
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From hadley at rice.edu  Thu Mar 29 22:42:25 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 29 Mar 2012 15:42:25 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
Message-ID: <CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>

> Most of that stuff is already in codetools, at least when it is checking functions
> with checkUsage(). ?E.g., arguments of ~ are not checked. ?The ?expr argument
> to with() will not be checked if you add ?skipWith=FALSE to the call to checkUsage.
>
> ?> library(codetools)
>
> ?> checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}))
> ?<anonymous>: no visible binding for global variable 'Num' (:1)
> ?<anonymous>: no visible binding for global variable 'Den' (:1)
>
> ?> checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)
>
> ?> checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)
> ?<anonymous>: no visible binding for global variable 'DataFrame'
>
> The only part that I don't see is the mechanism to add code-walker functions to
> the environment in codetools that has the standard list of them for functions with
> nonstandard evaluation:
> ?> objects(codetools:::collectUsageHandlers, all=TRUE)
> ? [1] "$" ? ? ? ? ? ? "$<-" ? ? ? ? ? ".Internal"
> ? [4] "::" ? ? ? ? ? ?":::" ? ? ? ? ? "@"
> ? [7] "@<-" ? ? ? ? ? "{" ? ? ? ? ? ? "~"
> ?[10] "<-" ? ? ? ? ? ?"<<-" ? ? ? ? ? "="
> ?[13] "assign" ? ? ? ?"binomial" ? ? ?"bquote"
> ?[16] "data" ? ? ? ? ?"detach" ? ? ? ?"expression"
> ?[19] "for" ? ? ? ? ? "function" ? ? ?"Gamma"
> ?[22] "gaussian" ? ? ?"if" ? ? ? ? ? ?"library"
> ?[25] "local" ? ? ? ? "poisson" ? ? ? "quasi"
> ?[28] "quasibinomial" "quasipoisson" ?"quote"
> ?[31] "Quote" ? ? ? ? "require" ? ? ? "substitute"
> ?[34] "with"

It seems like we really need a standard way to add metadata to functions:

attr(with, "special_args") <- "expr"
attr(lm, "special_args") <- c("formula", "weights", "subset")

This would be useful because it could automatically contribute to the
documentation.

Similarly,

attr(my.new.method, "s3method") <- c("my.new", "method")

could be useful.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From bbolker at gmail.com  Thu Mar 29 22:54:52 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Mar 2012 16:54:52 -0400
Subject: [Rd] r-forge build failure bafflement
Message-ID: <4F74CC1C.30802@gmail.com>


  I am attempting to build a package on r-forge and running into a
weird error.  I have been in correspondence with the R-forge admins
and am turning to r-devel on the remote chance that someone might have
a guess as to what is going wrong or a suggestion about further
diagnostics/experiments I could try ...

  The package seems to build fine on my system(s) with

R CMD build --compact-vignettes --resave-data=best pkg

(these are the R-forge build arguments, according to the r-forge admins)

 -- I've tried it with R-devel on Linux-32 and R 2.14.2 on MacOS-64.

The build log (basically identical across linux64/win64/macos64) is as
follows:

--------------
Thu Mar 29 20:15:21 2012: Building tarball for package glmmADMB (SVN
revision 204)
using R version 2.14.2 (2012-02-29) ...

* checking for file 'glmmADMB/DESCRIPTION' ... OK
* preparing 'glmmADMB':
* checking DESCRIPTION meta-information ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* looking to see if a 'data/datalist' file should be added
* re-saving image files
Error in loadNamespace(name) : there is no package called 'glmmADMB'
Execution halted
Run time: 0.51 seconds.
----------

  so apparently the package is failing because it doesn't exist (!!)
  I originally thought this was a circular dependency problem, because
glmmADMB and coefplot2 (another r-forge package) depended on each
other, but I have (at least for now) removed glmmADMB's coefplot2
dependency.  As far as I can tell there are *no* packages on r-forge
that depend on/suggest/import glmmADMB.

a1 <- available.packages(contriburl=
   contrib.url("http://r-forge.r-project.org"))
> rownames(a1)["glmmADMB" %in% a1[,"Suggests"]]
character(0)
> rownames(a1)["glmmADMB" %in% a1[,"Depends"]]
character(0)
> rownames(a1)["glmmADMB" %in% a1[,"Imports"]]
character(0)

The perhaps-relevant parts of the DESCRIPTION file:
=========
BuildVignettes: no
Description: Fits mixed-effects models using a variety of distributions
Imports: stats, nlme
Depends: R (>= 2.13), methods, MASS, R2admb
Suggests: lattice, lme4, lme4.0, coda, mlmRev, scapeMCMC, ggplot2,
bbmle, pscl, knitr, car
=====

  The only other thing I can think of is backing up a few SVN
revisions and seeing whether I can get back to a working version, but
I'd like to see if I can get it fixed by moving forward rather than
backward ...


  For anyone who is intrigued and wants to investigate farther:

http://r-forge.r-project.org/R/?group_id=847
http://r-forge.r-project.org/scm/?group_id=847

  cheers
   Ben Bolker


From ligges at statistik.tu-dortmund.de  Thu Mar 29 23:10:53 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 29 Mar 2012 23:10:53 +0200
Subject: [Rd] r-forge build failure bafflement
In-Reply-To: <4F74CC1C.30802@gmail.com>
References: <4F74CC1C.30802@gmail.com>
Message-ID: <4F74CFDD.5090001@statistik.tu-dortmund.de>



On 29.03.2012 22:54, Ben Bolker wrote:
>
>    I am attempting to build a package on r-forge and running into a
> weird error.  I have been in correspondence with the R-forge admins
> and am turning to r-devel on the remote chance that someone might have
> a guess as to what is going wrong or a suggestion about further
> diagnostics/experiments I could try ...
>
>    The package seems to build fine on my system(s) with
>
> R CMD build --compact-vignettes --resave-data=best pkg
>
> (these are the R-forge build arguments, according to the r-forge admins)
>
>   -- I've tried it with R-devel on Linux-32 and R 2.14.2 on MacOS-64.
>
> The build log (basically identical across linux64/win64/macos64) is as
> follows:
>
> --------------
> Thu Mar 29 20:15:21 2012: Building tarball for package glmmADMB (SVN
> revision 204)
> using R version 2.14.2 (2012-02-29) ...
>
> * checking for file 'glmmADMB/DESCRIPTION' ... OK
> * preparing 'glmmADMB':
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * looking to see if a 'data/datalist' file should be added
> * re-saving image files
> Error in loadNamespace(name) : there is no package called 'glmmADMB'
> Execution halted

Untested: Get rid of .First.lib and use .onAttach - you have a NAMESPACE.

Uwe

> Run time: 0.51 seconds.
> ----------
>
>    so apparently the package is failing because it doesn't exist (!!)
>    I originally thought this was a circular dependency problem, because
> glmmADMB and coefplot2 (another r-forge package) depended on each
> other, but I have (at least for now) removed glmmADMB's coefplot2
> dependency.  As far as I can tell there are *no* packages on r-forge
> that depend on/suggest/import glmmADMB.
>
> a1<- available.packages(contriburl=
>     contrib.url("http://r-forge.r-project.org"))
>> rownames(a1)["glmmADMB" %in% a1[,"Suggests"]]
> character(0)
>> rownames(a1)["glmmADMB" %in% a1[,"Depends"]]
> character(0)
>> rownames(a1)["glmmADMB" %in% a1[,"Imports"]]
> character(0)
>
> The perhaps-relevant parts of the DESCRIPTION file:
> =========
> BuildVignettes: no
> Description: Fits mixed-effects models using a variety of distributions
> Imports: stats, nlme
> Depends: R (>= 2.13), methods, MASS, R2admb
> Suggests: lattice, lme4, lme4.0, coda, mlmRev, scapeMCMC, ggplot2,
> bbmle, pscl, knitr, car
> =====
>
>    The only other thing I can think of is backing up a few SVN
> revisions and seeing whether I can get back to a working version, but
> I'd like to see if I can get it fixed by moving forward rather than
> backward ...
>
>
>    For anyone who is intrigued and wants to investigate farther:
>
> http://r-forge.r-project.org/R/?group_id=847
> http://r-forge.r-project.org/scm/?group_id=847
>
>    cheers
>     Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Mark.Bravington at csiro.au  Fri Mar 30 03:29:53 2012
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 30 Mar 2012 12:29:53 +1100
Subject: [Rd] CRAN policies
In-Reply-To: <CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>,
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>

I'm concerned this thread is heading the wrong way, towards techno-fixes for imaginary problems. R package-building is already encumbered with a huge set of complicated rules, and more instructions/rules eg for metadata would make things worse not better.

RCMD CHECK on the 'mvbutils' package generates over 300 Notes about "no visible binding...", which inevitably I just ignore. They arise because RCMD CHECK is too "stupid" to understand one of my preferred coding idioms (I'm not going to explain what-- that's beside the point). And RCMD CHECK always will be too "stupid" to understand everything that a rich language like R might quite reasonably cause experienced coders to do.

It should not be CRAN's business how I write my code, or even whether my code does what it is supposed to. It might be CRAN's business to try to work out whether my code breaks CRAN's policies, eg by causing R to crash horribly-- that's presumably what Warnings are for (but see below). And maybe there could be circumstances where an automatic check might be "worried" enough to alert the CRANia and require manual explanation and emails etc from a developer, but even that seems doomed given the growing deluge of packages.

RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as a developer-tool. But the fact that the one programl does both things seems accidental to me, and I think this dual-use is muddying the discussion. There's a big distinction between (i) code-checks that developers themselves might or might not find useful-- which should be left to the developer, and will vary from person to person-- and (ii) code-checks that CRAN enforces for its own peace-of-mind. Maybe it's convenient to have both functions in the same place, and it'd be fine to use Notes for one and Warnings for the other, but the different purposes should surely be kept clear. 

Personally, in building over 10 packages (only 2 on CRAN), I haven't found RCMD CHECK to be of any use, except for the code-documentation and example-running bits. I know other people have different opinions, but that's the point: one-size-does-not-fit-all when it comes to coding tools.

And wrto the Warnings themselves: I feel compelled to point out that it's logically impossible to fully check whether R code will do bad things. One has to wonder at what point adding new checks becomes futile or counterproductive. There must be over 2000 people who have written CRAN packages by now; every extra check and non-back-compatible additional requirement runs the risk of generating false-negatives and incurring many extra person-hours to "fix" non-problems. Plus someone needs to document and explain the check (adding to the rule mountain), plus there is the time spent in discussions like this..!

Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Hadley Wickham [hadley at rice.edu]
Sent: 30 March 2012 07:42
To: William Dunlap
Cc: r-devel at stat.math.ethz.ch; Spencer Graves
Subject: Re: [Rd] CRAN policies

> Most of that stuff is already in codetools, at least when it is checking functions
> with checkUsage().  E.g., arguments of ~ are not checked.  The  expr argument
> to with() will not be checked if you add  skipWith=FALSE to the call to checkUsage.
>
>  > library(codetools)
>
>  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}))
>  <anonymous>: no visible binding for global variable 'Num' (:1)
>  <anonymous>: no visible binding for global variable 'Den' (:1)
>
>  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)
>
>  > checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~ Pred}), skipWith=TRUE)
>  <anonymous>: no visible binding for global variable 'DataFrame'
>
> The only part that I don't see is the mechanism to add code-walker functions to
> the environment in codetools that has the standard list of them for functions with
> nonstandard evaluation:
>  > objects(codetools:::collectUsageHandlers, all=TRUE)
>   [1] "$"             "$<-"           ".Internal"
>   [4] "::"            ":::"           "@"
>   [7] "@<-"           "{"             "~"
>  [10] "<-"            "<<-"           "="
>  [13] "assign"        "binomial"      "bquote"
>  [16] "data"          "detach"        "expression"
>  [19] "for"           "function"      "Gamma"
>  [22] "gaussian"      "if"            "library"
>  [25] "local"         "poisson"       "quasi"
>  [28] "quasibinomial" "quasipoisson"  "quote"
>  [31] "Quote"         "require"       "substitute"
>  [34] "with"

It seems like we really need a standard way to add metadata to functions:

attr(with, "special_args") <- "expr"
attr(lm, "special_args") <- c("formula", "weights", "subset")

This would be useful because it could automatically contribute to the
documentation.

Similarly,

attr(my.new.method, "s3method") <- c("my.new", "method")

could be useful.

Hadley


--
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert902 at gmail.com  Fri Mar 30 05:39:02 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 29 Mar 2012 23:39:02 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>,
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
Message-ID: <4F752AD6.6040903@gmail.com>


On 12-03-29 09:29 PM, Mark.Bravington at csiro.au wrote:
 > I'm concerned this thread is heading the wrong way, towards
 > techno-fixes for imaginary problems. R package-building is already
 > encumbered with a huge set of complicated rules, and more
 > instructions/rules eg for metadata would make things worse not better.
 >
 > RCMD CHECK on the 'mvbutils' package generates over 300 Notes about
 > "no visible binding...", which inevitably I just ignore. They arise
 > because RCMD CHECK is too "stupid" to understand one of my preferred
 > coding idioms (I'm not going to explain what-- that's beside the
 > point).

Actually, I think that is the point. If your code is generating that 
many notes then I think you should explain your idiom, so the checks can 
be made to accommodate it if it really is good. Otherwise, I'd be 
worried about the quality of your code.

 > And RCMD CHECK always will be too "stupid" to understand everything
 > that a rich language like R might quite reasonably cause experienced
 > coders to do.

Possibly the interpreter is too stupid to understand it too?

 > It should not be CRAN's business how I write my code, or even whether
 > my code does what it is supposed to. It might be CRAN's business to
 > try to work out whether my code breaks CRAN's policies, eg by causing 
 > R to crash horribly-- that's presumably what Warnings are for (but
 > see below). And maybe there could be circumstances where an automatic
 > check might be "worried" enough to alert the CRANia and require manual
 > explanation and emails etc from a developer, but even that seems
 > doomed given the growing deluge of packages.
 >
 > RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as
 > a developer-tool. But the fact that the one programl does both things
 > seems accidental to me, and I think this dual-use is muddying the
 > discussion. There's a big distinction between (i) code-checks that
 > developers themselves might or might not find useful-- which should
 > be left to the developer, and will vary from person to person--

I think this a case of two heads are better than one. I did lots of
checks before the CRAN checks existed, but the CRAN checks still found 
bugs in code that I considerer very mature, including bugs in code has 
been running without noticeable problems for over 15 years. Despite all 
the noise today, most of us are only talking about a small inconvenience 
around the intended meaning of "note", not about whether quality control 
is a bad thing. I've found the errors and warnings are always valid, 
even though I do not always like having to fix the bugs, and the notes 
are most often valid too. But there are a few false positives, so the 
checks that give notes are not yet reliable enough to give warnings or 
errors. But they should be sometime, so one should usually consider 
fixing the package code.

 >   and (ii) code-checks that CRAN enforces for its own peace-of-mind.

I think of this as being for the piece-of-mind of your package users.

 > Maybe it's convenient to have both functions in the same place, and
 > it'd be fine to use Notes for one and Warnings for the other, but the
 > different purposes should surely be kept clear.
 >
 > Personally, in building over 10 packages (only 2 on CRAN), I haven't
 > found RCMD CHECK to be of any use, except for the code-documentation
 > and example-running bits. I know other people have different
 > opinions, but that's the point: one-size-does-not-fit-all when it
 > comes to coding tools.
 >
 > And wrto the Warnings themselves: I feel compelled to point out that
 > it's logically impossible to fully check whether R code will do bad
 > things. One has to wonder at what point adding new checks becomes
 > futile or counterproductive. There must be over 2000 people who have
 > written CRAN packages by now; every extra check and non-back-
 > compatible additional requirement runs the risk of generating false-
 > negatives and incurring many extra person-hours to "fix"
 > non-problems.
 > Plus someone needs to document and explain the check (adding to the
 > rule mountain), plus there is the time spent in discussions like
 > this..!

Bugs in your packages will require users to waste a lot of time too, and 
possibly reach faulty results with much more serious consequences. Just 
because perfection may never be attained, this does not mean that 
progress should not be attempted, in small steps. Compared to Statlib, 
which basicly followed your recommended approach, CRAN is a vast 
improvement.

Paul
 >
 > Mark
 >
 > Mark Bravington
 > CSIRO CMIS
 > Marine Lab
 > Hobart
 > Australia
 > ________________________________________
 > From:r-devel-bounces at r-project.org  [r-devel-bounces at r-project.org] 
On Behalf Of Hadley Wickham [hadley at rice.edu]
 > Sent: 30 March 2012 07:42
 > To: William Dunlap
 > Cc:r-devel at stat.math.ethz.ch; Spencer Graves
 > Subject: Re: [Rd] CRAN policies
 >
 >> Most of that stuff is already in codetools, at least when it is 
checking functions
 >> with checkUsage().  E.g., arguments of ~ are not checked.  The  expr 
argument
 >> to with() will not be checked if you add  skipWith=FALSE to the call 
to checkUsage.
 >>
 >>   >  library(codetools)
 >>
 >>   >  checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp 
~ Pred}))
 >>   <anonymous>: no visible binding for global variable 'Num' (:1)
 >>   <anonymous>: no visible binding for global variable 'Den' (:1)
 >>
 >>   >  checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp 
~ Pred}), skipWith=TRUE)
 >>
 >>   >  checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp 
~ Pred}), skipWith=TRUE)
 >>   <anonymous>: no visible binding for global variable 'DataFrame'
 >>
 >> The only part that I don't see is the mechanism to add code-walker 
functions to
 >> the environment in codetools that has the standard list of them for 
functions with
 >> nonstandard evaluation:
 >>   >  objects(codetools:::collectUsageHandlers, all=TRUE)
 >>    [1] "$"             "$<-"           ".Internal"
 >>    [4] "::"            ":::"           "@"
 >>    [7] "@<-"           "{"             "~"
 >>   [10] "<-"            "<<-"           "="
 >>   [13] "assign"        "binomial"      "bquote"
 >>   [16] "data"          "detach"        "expression"
 >>   [19] "for"           "function"      "Gamma"
 >>   [22] "gaussian"      "if"            "library"
 >>   [25] "local"         "poisson"       "quasi"
 >>   [28] "quasibinomial" "quasipoisson"  "quote"
 >>   [31] "Quote"         "require"       "substitute"
 >>   [34] "with"
 > It seems like we really need a standard way to add metadata to functions:
 >
 > attr(with, "special_args")<- "expr"
 > attr(lm, "special_args")<- c("formula", "weights", "subset")
 >
 > This would be useful because it could automatically contribute to the
 > documentation.
 >
 > Similarly,
 >
 > attr(my.new.method, "s3method")<- c("my.new", "method")
 >
 > could be useful.
 >
 > Hadley
 >
 >
 > --
 > Assistant Professor / Dobelman Family Junior Chair
 > Department of Statistics / Rice University
 > http://had.co.nz/
 >
 > ______________________________________________
 > R-devel at r-project.org  mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-devel
 >
 > ______________________________________________
 > R-devel at r-project.org  mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Fri Mar 30 06:19:29 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 29 Mar 2012 21:19:29 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <4F752AD6.6040903@gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>,
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<4F752AD6.6040903@gmail.com>
Message-ID: <4F753451.5090305@prodsyse.com>

On 3/29/2012 8:39 PM, Paul Gilbert wrote:
>
> On 12-03-29 09:29 PM, Mark.Bravington at csiro.au wrote:
> > I'm concerned this thread is heading the wrong way, towards
> > techno-fixes for imaginary problems. R package-building is already
> > encumbered with a huge set of complicated rules, and more
> > instructions/rules eg for metadata would make things worse not better.
> >
> > RCMD CHECK on the 'mvbutils' package generates over 300 Notes about
> > "no visible binding...", which inevitably I just ignore. They arise
> > because RCMD CHECK is too "stupid" to understand one of my preferred
> > coding idioms (I'm not going to explain what-- that's beside the
> > point).
>
> Actually, I think that is the point. If your code is generating that 
> many notes then I think you should explain your idiom, so the checks 
> can be made to accommodate it if it really is good. Otherwise, I'd be 
> worried about the quality of your code.


       The "R CMD check" process is by far the best system I know for 
producing "trustworthy software" (Bill Chambers' term).  I'm not leading 
researcher in software development, merely a guy who has written a fair 
amount of code over the past half century in a number of different 
languages.  I'm now bald, having torn all my hair out trying to debug 
mountains of spaghetti code ;-)  With "R CMD check" (including all those 
pesky notes), I get working code in a third the time (subjective 
guestimate) AND documentation I can had to others as a byproduct for free.


       I've been so impressed with it that I wrote the Wikipedia article 
on "Package development process" and added a table (with help from 
Sundar Dorai-Raj) to the "Software repository" article identifying 
software repositories for different languages, trying to suggest that 
users of other languages could benefit from developing some similar code 
quality checking system for other languages and accompanying repositories.


       I mention this, in case any of you know a researcher in 
information technology / computer science / software engineering who 
might be invited to do a comparison of "R CMD check" with what's 
available for other languages.  I think it could help people writing 
code in other languages -- and it might even generate ideas to help the 
R community.


       Best Wishes,
       Spencer


> > And RCMD CHECK always will be too "stupid" to understand everything
> > that a rich language like R might quite reasonably cause experienced
> > coders to do.
>
> Possibly the interpreter is too stupid to understand it too?
>
> > It should not be CRAN's business how I write my code, or even whether
> > my code does what it is supposed to. It might be CRAN's business to
> > try to work out whether my code breaks CRAN's policies, eg by 
> causing > R to crash horribly-- that's presumably what Warnings are 
> for (but
> > see below). And maybe there could be circumstances where an automatic
> > check might be "worried" enough to alert the CRANia and require manual
> > explanation and emails etc from a developer, but even that seems
> > doomed given the growing deluge of packages.
> >
> > RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as
> > a developer-tool. But the fact that the one programl does both things
> > seems accidental to me, and I think this dual-use is muddying the
> > discussion. There's a big distinction between (i) code-checks that
> > developers themselves might or might not find useful-- which should
> > be left to the developer, and will vary from person to person--
>
> I think this a case of two heads are better than one. I did lots of
> checks before the CRAN checks existed, but the CRAN checks still found 
> bugs in code that I considerer very mature, including bugs in code has 
> been running without noticeable problems for over 15 years. Despite 
> all the noise today, most of us are only talking about a small 
> inconvenience around the intended meaning of "note", not about whether 
> quality control is a bad thing. I've found the errors and warnings are 
> always valid, even though I do not always like having to fix the bugs, 
> and the notes are most often valid too. But there are a few false 
> positives, so the checks that give notes are not yet reliable enough 
> to give warnings or errors. But they should be sometime, so one should 
> usually consider fixing the package code.
>
> >   and (ii) code-checks that CRAN enforces for its own peace-of-mind.
>
> I think of this as being for the piece-of-mind of your package users.
>
> > Maybe it's convenient to have both functions in the same place, and
> > it'd be fine to use Notes for one and Warnings for the other, but the
> > different purposes should surely be kept clear.
> >
> > Personally, in building over 10 packages (only 2 on CRAN), I haven't
> > found RCMD CHECK to be of any use, except for the code-documentation
> > and example-running bits. I know other people have different
> > opinions, but that's the point: one-size-does-not-fit-all when it
> > comes to coding tools.
> >
> > And wrto the Warnings themselves: I feel compelled to point out that
> > it's logically impossible to fully check whether R code will do bad
> > things. One has to wonder at what point adding new checks becomes
> > futile or counterproductive. There must be over 2000 people who have
> > written CRAN packages by now; every extra check and non-back-
> > compatible additional requirement runs the risk of generating false-
> > negatives and incurring many extra person-hours to "fix"
> > non-problems.
> > Plus someone needs to document and explain the check (adding to the
> > rule mountain), plus there is the time spent in discussions like
> > this..!
>
> Bugs in your packages will require users to waste a lot of time too, 
> and possibly reach faulty results with much more serious consequences. 
> Just because perfection may never be attained, this does not mean that 
> progress should not be attempted, in small steps. Compared to Statlib, 
> which basicly followed your recommended approach, CRAN is a vast 
> improvement.
>
> Paul
> >
> > Mark
> >
> > Mark Bravington
> > CSIRO CMIS
> > Marine Lab
> > Hobart
> > Australia
> > ________________________________________
> > From:r-devel-bounces at r-project.org  [r-devel-bounces at r-project.org] 
> On Behalf Of Hadley Wickham [hadley at rice.edu]
> > Sent: 30 March 2012 07:42
> > To: William Dunlap
> > Cc:r-devel at stat.math.ethz.ch; Spencer Graves
> > Subject: Re: [Rd] CRAN policies
> >
> >> Most of that stuff is already in codetools, at least when it is 
> checking functions
> >> with checkUsage().  E.g., arguments of ~ are not checked.  The  
> expr argument
> >> to with() will not be checked if you add  skipWith=FALSE to the 
> call to checkUsage.
> >>
> >> >  library(codetools)
> >>
> >> >  checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ 
> Pred}))
> >> <anonymous>: no visible binding for global variable 'Num' (:1)
> >> <anonymous>: no visible binding for global variable 'Den' (:1)
> >>
> >> >  checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ 
> Pred}), skipWith=TRUE)
> >>
> >> >  checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~ 
> Pred}), skipWith=TRUE)
> >> <anonymous>: no visible binding for global variable 'DataFrame'
> >>
> >> The only part that I don't see is the mechanism to add code-walker 
> functions to
> >> the environment in codetools that has the standard list of them for 
> functions with
> >> nonstandard evaluation:
> >> >  objects(codetools:::collectUsageHandlers, all=TRUE)
> >>    [1] "$"             "$<-"           ".Internal"
> >>    [4] "::"            ":::"           "@"
> >>    [7] "@<-"           "{"             "~"
> >>   [10] "<-"            "<<-"           "="
> >>   [13] "assign"        "binomial"      "bquote"
> >>   [16] "data"          "detach"        "expression"
> >>   [19] "for"           "function"      "Gamma"
> >>   [22] "gaussian"      "if"            "library"
> >>   [25] "local"         "poisson"       "quasi"
> >>   [28] "quasibinomial" "quasipoisson"  "quote"
> >>   [31] "Quote"         "require"       "substitute"
> >>   [34] "with"
> > It seems like we really need a standard way to add metadata to 
> functions:
> >
> > attr(with, "special_args")<- "expr"
> > attr(lm, "special_args")<- c("formula", "weights", "subset")
> >
> > This would be useful because it could automatically contribute to the
> > documentation.
> >
> > Similarly,
> >
> > attr(my.new.method, "s3method")<- c("my.new", "method")
> >
> > could be useful.
> >
> > Hadley
> >
> >
> > --
> > Assistant Professor / Dobelman Family Junior Chair
> > Department of Statistics / Rice University
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-devel at r-project.org  mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org  mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Mar 30 07:38:04 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Mar 2012 06:38:04 +0100
Subject: [Rd] r-forge build failure bafflement
In-Reply-To: <4F74CC1C.30802@gmail.com>
References: <4F74CC1C.30802@gmail.com>
Message-ID: <4F7546BC.70508@stats.ox.ac.uk>

We've seen similar things several times with CRAN submissions.  Basic 
scenario was

- INSTALL (via build or check) is trying to install a package that is 
not already installed, into a private library not on the usual .libPaths().

- Start-up code in that package is looking for the package, and does not 
respect lib[name] as passed to .First.lib or .onLoad/.onAttach.  E.g. a 
call to installed.package() or packageDescription.

- As the maintainer has an earlier version installed in .Library (s)he 
cannot reproduce it.

I took a very quick look at the package: it has .First.lib and not 
.onLoad/.onAttach, and of course it has a namespace (all packages now 
do).  I would start by fixing that.


On 29/03/2012 21:54, Ben Bolker wrote:
>
>    I am attempting to build a package on r-forge and running into a
> weird error.  I have been in correspondence with the R-forge admins
> and am turning to r-devel on the remote chance that someone might have
> a guess as to what is going wrong or a suggestion about further
> diagnostics/experiments I could try ...
>
>    The package seems to build fine on my system(s) with
>
> R CMD build --compact-vignettes --resave-data=best pkg
>
> (these are the R-forge build arguments, according to the r-forge admins)
>
>   -- I've tried it with R-devel on Linux-32 and R 2.14.2 on MacOS-64.
>
> The build log (basically identical across linux64/win64/macos64) is as
> follows:
>
> --------------
> Thu Mar 29 20:15:21 2012: Building tarball for package glmmADMB (SVN
> revision 204)
> using R version 2.14.2 (2012-02-29) ...
>
> * checking for file 'glmmADMB/DESCRIPTION' ... OK
> * preparing 'glmmADMB':
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * looking to see if a 'data/datalist' file should be added
> * re-saving image files
> Error in loadNamespace(name) : there is no package called 'glmmADMB'
> Execution halted
> Run time: 0.51 seconds.
> ----------
>
>    so apparently the package is failing because it doesn't exist (!!)
>    I originally thought this was a circular dependency problem, because
> glmmADMB and coefplot2 (another r-forge package) depended on each
> other, but I have (at least for now) removed glmmADMB's coefplot2
> dependency.  As far as I can tell there are *no* packages on r-forge
> that depend on/suggest/import glmmADMB.
>
> a1<- available.packages(contriburl=
>     contrib.url("http://r-forge.r-project.org"))
>> rownames(a1)["glmmADMB" %in% a1[,"Suggests"]]
> character(0)
>> rownames(a1)["glmmADMB" %in% a1[,"Depends"]]
> character(0)
>> rownames(a1)["glmmADMB" %in% a1[,"Imports"]]
> character(0)
>
> The perhaps-relevant parts of the DESCRIPTION file:
> =========
> BuildVignettes: no
> Description: Fits mixed-effects models using a variety of distributions
> Imports: stats, nlme
> Depends: R (>= 2.13), methods, MASS, R2admb
> Suggests: lattice, lme4, lme4.0, coda, mlmRev, scapeMCMC, ggplot2,
> bbmle, pscl, knitr, car
> =====
>
>    The only other thing I can think of is backing up a few SVN
> revisions and seeing whether I can get back to a working version, but
> I'd like to see if I can get it fixed by moving forward rather than
> backward ...
>
>
>    For anyone who is intrigued and wants to investigate farther:
>
> http://r-forge.r-project.org/R/?group_id=847
> http://r-forge.r-project.org/scm/?group_id=847
>
>    cheers
>     Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mdowle at mdowle.plus.com  Fri Mar 30 10:49:04 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Fri, 30 Mar 2012 08:49:04 +0000
Subject: [Rd] CRAN policies
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>,
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
Message-ID: <loom.20120330T102301-566@post.gmane.org>

<Mark.Bravington <at> csiro.au> writes:

> There must be over 2000 people who have written CRAN packages by now; every 
extra
> check and non-back-compatible additional requirement runs the risk of 
generating false-negatives and
> incurring many extra person-hours to "fix" non-problems. Plus someone needs 
to document and explain the
> check (adding to the rule mountain), plus there is the time spent in 
discussions like this..!

Not sure where you're coming from on that. For example, Prof Ripley has added 
quite a few new NOTEs to QC.R over the last few months. These caught things I 
wasn't aware of in the two packages I maintain and I was more than happy to fix 
them. It improves quality, surely.

There's only one particular NOTE causing an issue: 'no visible binding'. If it 
were made a MEMO, we can move on. All the other NOTEs can (and should) be 
fixed, can't they?

Matthew


From claudia.beleites at ipht-jena.de  Fri Mar 30 16:12:43 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Fri, 30 Mar 2012 16:12:43 +0200
Subject: [Rd] --as-cran  / BuildVignettes: false
In-Reply-To: <4F733730.5030104@gmail.com>
References: <4F733730.5030104@gmail.com>
Message-ID: <4F75BF5B.8010604@ipht-jena.de>

Paul,

> I have packages where I know CRAN and other test platforms do not have 
> all the resources to build the vignettes, for example, access to 
> databases.
For some of my vignettes that is true, too. For those, the vignette
directory contains the .pdf produced on my machine and a "fake" .Rnw,
which contains only the \Vignette*{} entries needed to get the vignette
listed properly and an additional comment pointing users to the package
homepage at r-forge where the real .Rnw and the raw data files are
available.
To prevent the fake .Rnw producing an empty pdf that overwrites the one
I provide, I use a Makefile - learnt that from one of Dirk Eddelb?ttel's
packages (forget which, but thanks, Dirk!)

Claudia

-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From claudia.beleites at ipht-jena.de  Fri Mar 30 16:38:50 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Fri, 30 Mar 2012 16:38:50 +0200
Subject: [Rd] CRAN policies
In-Reply-To: <4F71CBE5.6090300@gmail.com>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
Message-ID: <4F75C57A.3010107@ipht-jena.de>

Paul,

> One of the things I have noticed with the R 2.15.0 RC and --as-cran is 
> that the I have to bump the version number of the working copy of my 
[snip]
> 
> I am curious how other developers approach this.

Regardless of --as-cran I find it very useful to use the date as minor
part of the version number (e.g. hyperSpec 0.98-20120320), which I set
automatically.

Claudia





-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From pgilbert902 at gmail.com  Fri Mar 30 17:29:06 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 30 Mar 2012 11:29:06 -0400
Subject: [Rd] R-forge  --as-cran
In-Reply-To: <4F75C57A.3010107@ipht-jena.de>
References: <4F71A2F3.2000203@stats.ox.ac.uk>
	<4F71AA0A.9050702@stats.ox.ac.uk> <4F71CBE5.6090300@gmail.com>
	<4F75C57A.3010107@ipht-jena.de>
Message-ID: <4F75D142.90409@gmail.com>

(Renamed from  "Re: [Rd] CRAN policies" because the of the 
muli-threading of that subject.)

Claudia

Actually, my version numbers are year-month dates, eg 2012.3-1, although 
I don't set them automatically.

I have had some additional off-line discussion on this. The problem is this:

Now when I submit version 2012.3-1 to CRAN, any checks of that package 
on R-forge will fail, until I change the version number. This is by 
specific request of the CRAN maintainers to the R-forge maintainers, the 
reason being, understandably, that the CRAN maintainers do not like 
getting submissions without the version number changed. One implication 
of this is that I should change the R-forge version number as soon as I 
make any changes to the package, even if I am going to change it again 
before I actually release to CRAN. This seems like a reasonable 
practice, even if I have not always done that.

The case where the code on R-forge remains unchanged for some time after 
it is released to CRAN is more subtle. If R-forge does not re-run the 
checks until I make a change, as is the current situation, then the 
package will still be indicated as ok on the R-forge pkg page. However, 
when R is upgraded, I would like the checks to be re-run on all 
platforms, not just on my own testing platform. But when that is done, 
the R-forge indication is going to be that the package failed, because 
the version number is the same as on CRAN. The information I want is 
actually available on the CRAN daily check. I just need to know that 
when my package is unchanged from the version on CRAN, I should look at 
CRAN daily rather than at the R-forge result.

Paul

On 12-03-30 10:38 AM, Claudia Beleites wrote:
> Paul,
>
>> One of the things I have noticed with the R 2.15.0 RC and --as-cran is
>> that the I have to bump the version number of the working copy of my
> [snip]
>>
>> I am curious how other developers approach this.
>
> Regardless of --as-cran I find it very useful to use the date as minor
> part of the version number (e.g. hyperSpec 0.98-20120320), which I set
> automatically.
>
> Claudia
>
>
>
>
>


From wdunlap at tibco.com  Fri Mar 30 18:07:52 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Mar 2012 16:07:52 +0000
Subject: [Rd] CRAN policies
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>,
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
Message-ID: <E66794E69CFDE04D9A70842786030B9328F467@PA-MBX04.na.tibco.com>

It looks like you define a few functions that use substitute() or sys.call()
or similar functions to look at the unevaluated argument list.  E.g.,

  "cq" <-
  function( ...) {
  # Saves putting in quotes!
  # E.G.: quoted( first, second, third) is the same as c( 'first', 'second', 'third')
  # wrapping by as.character means cq() returns character(0) not list()
    as.character( sapply( as.list( match.call( expand.dots=TRUE))[-1], as.character))
  }
%such.that% and %SUCH.THAT% do similar things.

Almost all the complaints from check involve calls to a handful of such
functions.  If you could tell codetools:::checkUsage that that these functions
did nonstandard evaluation on all or some of their arguments then the
complaints would go away and other checks for  real errors like misspellings
would still be done.

Another possible part of the problem is that if checkUsage is checking a function like
  f <- function(x) paste(x, cq(suffix), sep=".")
it attributes the out-of-scope suffix problem to 'f' and doesn't mention that the immediate
caller is 'cq', so you cannot easily filter output complaints about cq.  (CRAN would
not do such filtering, but a developer might.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Mark.Bravington at csiro.au
> Sent: Thursday, March 29, 2012 6:30 PM
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
> I'm concerned this thread is heading the wrong way, towards techno-fixes for imaginary
> problems. R package-building is already encumbered with a huge set of complicated
> rules, and more instructions/rules eg for metadata would make things worse not better.
> 
> 
> RCMD CHECK on the 'mvbutils' package generates over 300 Notes about "no visible
> binding...", which inevitably I just ignore. They arise because RCMD CHECK is too "stupid"
> to understand one of my preferred coding idioms (I'm not going to explain what-- that's
> beside the point). And RCMD CHECK always will be too "stupid" to understand everything
> that a rich language like R might quite reasonably cause experienced coders to do.
> 
> It should not be CRAN's business how I write my code, or even whether my code does
> what it is supposed to. It might be CRAN's business to try to work out whether my code
> breaks CRAN's policies, eg by causing R to crash horribly-- that's presumably what
> Warnings are for (but see below). And maybe there could be circumstances where an
> automatic check might be "worried" enough to alert the CRANia and require manual
> explanation and emails etc from a developer, but even that seems doomed given the
> growing deluge of packages.
> 
> RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as a developer-tool.
> But the fact that the one programl does both things seems accidental to me, and I think
> this dual-use is muddying the discussion. There's a big distinction between (i) code-checks
> that developers themselves might or might not find useful-- which should be left to the
> developer, and will vary from person to person-- and (ii) code-checks that CRAN enforces
> for its own peace-of-mind. Maybe it's convenient to have both functions in the same
> place, and it'd be fine to use Notes for one and Warnings for the other, but the different
> purposes should surely be kept clear.
> 
> Personally, in building over 10 packages (only 2 on CRAN), I haven't found RCMD CHECK
> to be of any use, except for the code-documentation and example-running bits. I know
> other people have different opinions, but that's the point: one-size-does-not-fit-all when
> it comes to coding tools.
> 
> And wrto the Warnings themselves: I feel compelled to point out that it's logically
> impossible to fully check whether R code will do bad things. One has to wonder at what
> point adding new checks becomes futile or counterproductive. There must be over 2000
> people who have written CRAN packages by now; every extra check and non-back-
> compatible additional requirement runs the risk of generating false-negatives and
> incurring many extra person-hours to "fix" non-problems. Plus someone needs to
> document and explain the check (adding to the rule mountain), plus there is the time
> spent in discussions like this..!
> 
> Mark
> 
> Mark Bravington
> CSIRO CMIS
> Marine Lab
> Hobart
> Australia
> ________________________________________
> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of
> Hadley Wickham [hadley at rice.edu]
> Sent: 30 March 2012 07:42
> To: William Dunlap
> Cc: r-devel at stat.math.ethz.ch; Spencer Graves
> Subject: Re: [Rd] CRAN policies
> 
> > Most of that stuff is already in codetools, at least when it is checking functions
> > with checkUsage().  E.g., arguments of ~ are not checked.  The  expr argument
> > to with() will not be checked if you add  skipWith=FALSE to the call to checkUsage.
> >
> >  > library(codetools)
> >
> >  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}))
> >  <anonymous>: no visible binding for global variable 'Num' (:1)
> >  <anonymous>: no visible binding for global variable 'Den' (:1)
> >
> >  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~ Pred}),
> skipWith=TRUE)
> >
> >  > checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~ Pred}),
> skipWith=TRUE)
> >  <anonymous>: no visible binding for global variable 'DataFrame'
> >
> > The only part that I don't see is the mechanism to add code-walker functions to
> > the environment in codetools that has the standard list of them for functions with
> > nonstandard evaluation:
> >  > objects(codetools:::collectUsageHandlers, all=TRUE)
> >   [1] "$"             "$<-"           ".Internal"
> >   [4] "::"            ":::"           "@"
> >   [7] "@<-"           "{"             "~"
> >  [10] "<-"            "<<-"           "="
> >  [13] "assign"        "binomial"      "bquote"
> >  [16] "data"          "detach"        "expression"
> >  [19] "for"           "function"      "Gamma"
> >  [22] "gaussian"      "if"            "library"
> >  [25] "local"         "poisson"       "quasi"
> >  [28] "quasibinomial" "quasipoisson"  "quote"
> >  [31] "Quote"         "require"       "substitute"
> >  [34] "with"
> 
> It seems like we really need a standard way to add metadata to functions:
> 
> attr(with, "special_args") <- "expr"
> attr(lm, "special_args") <- c("formula", "weights", "subset")
> 
> This would be useful because it could automatically contribute to the
> documentation.
> 
> Similarly,
> 
> attr(my.new.method, "s3method") <- c("my.new", "method")
> 
> could be useful.
> 
> Hadley
> 
> 
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kw.stat at gmail.com  Fri Mar 30 20:41:17 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 30 Mar 2012 13:41:17 -0500
Subject: [Rd] CRAN policies
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
Message-ID: <CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120330/de0e2830/attachment.pl>

From jwiley.psych at gmail.com  Fri Mar 30 21:03:09 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 30 Mar 2012 12:03:09 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>
Message-ID: <CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>

On Fri, Mar 30, 2012 at 11:41 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> I'll echo Mark's concerns. ?R _used_ to be a language for "turning ideas
> into software quickly". ?Now it is more like "prototyping ideas in software
> quickly", and then spend a substantial amount of time trying to follow
> administrative rules to package the code.

..if you want to submit to CRAN.  There are practically zero if you
host on your own website.  Of course developers are free to do
whatever they want and R core does not get to tell them what/how to do
it.  R core does get a say when you ask them to host your source and
build your package binaries.

> Quality has its costs.

So does using CRAN.  If it is not the best solution for your problem,
use something else.  Hadley uses github from development ggplot2, and
with the dev_tools package, it is relatively easy for users to install
the source ggplot2 code.  Something like that might be appropriate for
code/packages wehre you just want to 'turn ideas into software
quickly'.  There is an extra step required for users to use it, but
that makes sense because it weeds out inept users from using code with
less quality control.

>
> Many of the code checks I find quite useful, but the "no visible binding"
> one generates lots of nuisance notes for me. ?I must have a similar coding
> style to Mark.
>
> Kevin
>
>
> On Thu, Mar 29, 2012 at 8:29 PM, <Mark.Bravington at csiro.au> wrote:
>
>> I'm concerned this thread is heading the wrong way, towards techno-fixes
>> for imaginary problems. R package-building is already encumbered with a
>> huge set of complicated rules, and more instructions/rules eg for metadata
>> would make things worse not better.
>>
>> RCMD CHECK on the 'mvbutils' package generates over 300 Notes about "no
>> visible binding...", which inevitably I just ignore. They arise because
>> RCMD CHECK is too "stupid" to understand one of my preferred coding idioms
>> (I'm not going to explain what-- that's beside the point). And RCMD CHECK
>> always will be too "stupid" to understand everything that a rich language
>> like R might quite reasonably cause experienced coders to do.
>>
>> It should not be CRAN's business how I write my code, or even whether my
>> code does what it is supposed to. It might be CRAN's business to try to
>> work out whether my code breaks CRAN's policies, eg by causing R to crash
>> horribly-- that's presumably what Warnings are for (but see below). And
>> maybe there could be circumstances where an automatic check might be
>> "worried" enough to alert the CRANia and require manual explanation and
>> emails etc from a developer, but even that seems doomed given the growing
>> deluge of packages.
>>
>> RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as a
>> developer-tool. But the fact that the one programl does both things seems
>> accidental to me, and I think this dual-use is muddying the discussion.
>> There's a big distinction between (i) code-checks that developers
>> themselves might or might not find useful-- which should be left to the
>> developer, and will vary from person to person-- and (ii) code-checks that
>> CRAN enforces for its own peace-of-mind. Maybe it's convenient to have both
>> functions in the same place, and it'd be fine to use Notes for one and
>> Warnings for the other, but the different purposes should surely be kept
>> clear.
>>
>> Personally, in building over 10 packages (only 2 on CRAN), I haven't found
>> RCMD CHECK to be of any use, except for the code-documentation and
>> example-running bits. I know other people have different opinions, but
>> that's the point: one-size-does-not-fit-all when it comes to coding tools.
>>
>> And wrto the Warnings themselves: I feel compelled to point out that it's
>> logically impossible to fully check whether R code will do bad things. One
>> has to wonder at what point adding new checks becomes futile or
>> counterproductive. There must be over 2000 people who have written CRAN
>> packages by now; every extra check and non-back-compatible additional
>> requirement runs the risk of generating false-negatives and incurring many
>> extra person-hours to "fix" non-problems. Plus someone needs to document
>> and explain the check (adding to the rule mountain), plus there is the time
>> spent in discussions like this..!
>>
>> Mark
>>
>> Mark Bravington
>> CSIRO CMIS
>> Marine Lab
>> Hobart
>> Australia
>> ________________________________________
>> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On
>> Behalf Of Hadley Wickham [hadley at rice.edu]
>> Sent: 30 March 2012 07:42
>> To: William Dunlap
>> Cc: r-devel at stat.math.ethz.ch; Spencer Graves
>> Subject: Re: [Rd] CRAN policies
>>
>> > Most of that stuff is already in codetools, at least when it is checking
>> functions
>> > with checkUsage(). ?E.g., arguments of ~ are not checked. ?The ?expr
>> argument
>> > to with() will not be checked if you add ?skipWith=FALSE to the call to
>> checkUsage.
>> >
>> > ?> library(codetools)
>> >
>> > ?> checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~
>> Pred}))
>> > ?<anonymous>: no visible binding for global variable 'Num' (:1)
>> > ?<anonymous>: no visible binding for global variable 'Den' (:1)
>> >
>> > ?> checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~
>> Pred}), skipWith=TRUE)
>> >
>> > ?> checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~
>> Pred}), skipWith=TRUE)
>> > ?<anonymous>: no visible binding for global variable 'DataFrame'
>> >
>> > The only part that I don't see is the mechanism to add code-walker
>> functions to
>> > the environment in codetools that has the standard list of them for
>> functions with
>> > nonstandard evaluation:
>> > ?> objects(codetools:::collectUsageHandlers, all=TRUE)
>> > ? [1] "$" ? ? ? ? ? ? "$<-" ? ? ? ? ? ".Internal"
>> > ? [4] "::" ? ? ? ? ? ?":::" ? ? ? ? ? "@"
>> > ? [7] "@<-" ? ? ? ? ? "{" ? ? ? ? ? ? "~"
>> > ?[10] "<-" ? ? ? ? ? ?"<<-" ? ? ? ? ? "="
>> > ?[13] "assign" ? ? ? ?"binomial" ? ? ?"bquote"
>> > ?[16] "data" ? ? ? ? ?"detach" ? ? ? ?"expression"
>> > ?[19] "for" ? ? ? ? ? "function" ? ? ?"Gamma"
>> > ?[22] "gaussian" ? ? ?"if" ? ? ? ? ? ?"library"
>> > ?[25] "local" ? ? ? ? "poisson" ? ? ? "quasi"
>> > ?[28] "quasibinomial" "quasipoisson" ?"quote"
>> > ?[31] "Quote" ? ? ? ? "require" ? ? ? "substitute"
>> > ?[34] "with"
>>
>> It seems like we really need a standard way to add metadata to functions:
>>
>> attr(with, "special_args") <- "expr"
>> attr(lm, "special_args") <- c("formula", "weights", "subset")
>>
>> This would be useful because it could automatically contribute to the
>> documentation.
>>
>> Similarly,
>>
>> attr(my.new.method, "s3method") <- c("my.new", "method")
>>
>> could be useful.
>>
>> Hadley
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Kevin Wright
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From baron at psych.upenn.edu  Fri Mar 30 22:29:56 2012
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 30 Mar 2012 16:29:56 -0400
Subject: [Rd] RSiteSearch
In-Reply-To: <20100131133341.GA25898@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
References: <20100131133341.GA25898@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
Message-ID: <20120330202956.GA1521@psych.upenn.edu>

I don't know what the RSiteSearch function does anymore, or who
maintains it. Please ignore this if you have nothing to do with it.

I recently moved my R site, finzi.psych.upenn.edu to a new
computer. Somehow some of the mailing-list search capabilities were
lost, and I do not have time to find the problem. Because I have not
been maintaining these lists at all since 2010, I decided that the
simplest thing was just to remove them all from the search
path. Again, some of them haven't been working anyway for a few weeks,
and I have had only one complaint. (And there are much better ways to
search mailing lists now.)

The functions, task views, and vignette searches still work.

Eventually I would like to move to a different search engine for
functions, task views, and vignettes. But it isn't that hard to
maintain the current one (Namazu) as well, if you want me to do that.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From bbolker at gmail.com  Fri Mar 30 23:12:34 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 17:12:34 -0400
Subject: [Rd] r-forge build failure bafflement
In-Reply-To: <4F7546BC.70508@stats.ox.ac.uk>
References: <4F74CC1C.30802@gmail.com> <4F7546BC.70508@stats.ox.ac.uk>
Message-ID: <4F7621C2.5070903@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Figured it out (I think: I haven't gotten through restructuring and
testing, but I think it's going to work now).  I was paying
insufficient attention to the build arguments, in particular
- --resave-data=best.

  I previously had the clever idea to save some fitted models with the
package so that they would be available to users who wanted to work
with them without taking the time and trouble of re-running the model
fits (some of which are very slow, especially for MCMC variants).  So
I saved these in a .rda file in the data section, which seemed like a
good idea at the time.  However, that means that resaving the data now
requires loading the package with which the class of those model
objects is associated ... and voila, a mysterious, apparently
self-referential, error message.

   For now I'm experimenting with moving those fits to a .rda file
inst/extdata ... (I thought using to dput() instead of save() to save
them might fix the problem, but it doesn't seem to) but this does seem
like a bit of a pain (I have included anther function, getdata(), so
that users don't have to mess around with system.file("extdata",
[model_obj], package="glmmADMB"). I would be curious if anyone has any
other suggestions for ways to work around this issue, or if they feel
that I am subverting the intended use of the data/ directory (and so
it's my own fault).

  happy friday, and thanks to all for their suggestions.

    Ben Bolker

On 12-03-30 01:38 AM, Prof Brian Ripley wrote:
> We've seen similar things several times with CRAN submissions.
> Basic scenario was
> 
> - INSTALL (via build or check) is trying to install a package that
> is not already installed, into a private library not on the usual
> .libPaths().
> 
> - Start-up code in that package is looking for the package, and
> does not respect lib[name] as passed to .First.lib or
> .onLoad/.onAttach.  E.g. a call to installed.package() or
> packageDescription.
> 
> - As the maintainer has an earlier version installed in .Library
> (s)he cannot reproduce it.
> 
> I took a very quick look at the package: it has .First.lib and not 
> .onLoad/.onAttach, and of course it has a namespace (all packages
> now do).  I would start by fixing that.
> 
> On 29/03/2012 21:54, Ben Bolker wrote:
>> 
>> I am attempting to build a package on r-forge and running into a 
>> weird error.  I have been in correspondence with the R-forge
>> admins and am turning to r-devel on the remote chance that
>> someone might have a guess as to what is going wrong or a
>> suggestion about further diagnostics/experiments I could try ...
>> 
>> The package seems to build fine on my system(s) with
>> 
>> R CMD build --compact-vignettes --resave-data=best pkg
>> 
>> (these are the R-forge build arguments, according to the r-forge
>> admins)
>> 
>> -- I've tried it with R-devel on Linux-32 and R 2.14.2 on
>> MacOS-64.
>> 
>> The build log (basically identical across linux64/win64/macos64)
>> is as follows:
>> 
>> -------------- Thu Mar 29 20:15:21 2012: Building tarball for
>> package glmmADMB (SVN revision 204) using R version 2.14.2
>> (2012-02-29) ...
>> 
>> * checking for file 'glmmADMB/DESCRIPTION' ... OK * preparing
>> 'glmmADMB': * checking DESCRIPTION meta-information ... OK *
>> checking for LF line-endings in source and make files * checking
>> for empty or unneeded directories * looking to see if a
>> 'data/datalist' file should be added * re-saving image files 
>> Error in loadNamespace(name) : there is no package called
>> 'glmmADMB' Execution halted Run time: 0.51 seconds. ----------
>> 
>> so apparently the package is failing because it doesn't exist
>> (!!) I originally thought this was a circular dependency problem,
>> because glmmADMB and coefplot2 (another r-forge package) depended
>> on each other, but I have (at least for now) removed glmmADMB's
>> coefplot2 dependency.  As far as I can tell there are *no*
>> packages on r-forge that depend on/suggest/import glmmADMB.
>> 
>> a1<- available.packages(contriburl= 
>> contrib.url("http://r-forge.r-project.org"))
>>> rownames(a1)["glmmADMB" %in% a1[,"Suggests"]]
>> character(0)
>>> rownames(a1)["glmmADMB" %in% a1[,"Depends"]]
>> character(0)
>>> rownames(a1)["glmmADMB" %in% a1[,"Imports"]]
>> character(0)
>> 
>> The perhaps-relevant parts of the DESCRIPTION file: ========= 
>> BuildVignettes: no Description: Fits mixed-effects models using a
>> variety of distributions Imports: stats, nlme Depends: R (>=
>> 2.13), methods, MASS, R2admb Suggests: lattice, lme4, lme4.0,
>> coda, mlmRev, scapeMCMC, ggplot2, bbmle, pscl, knitr, car =====
>> 
>> The only other thing I can think of is backing up a few SVN 
>> revisions and seeing whether I can get back to a working version,
>> but I'd like to see if I can get it fixed by moving forward
>> rather than backward ...
>> 
>> 
>> For anyone who is intrigued and wants to investigate farther:
>> 
>> http://r-forge.r-project.org/R/?group_id=847 
>> http://r-forge.r-project.org/scm/?group_id=847
>> 
>> cheers Ben Bolker
>> 
>> ______________________________________________ 
>> R-devel at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJPdiHCAAoJED2whTVMEyK9pnAH/jfg9Sf7F1AMbnQZIzlkX4Ue
nkYqG+9Ec6B+c+z1dHv/pZGzhDKK+CT7H15GVTqzSgiJLRw8sWxsWeAEc1hDJLbs
m0tRykJvyaLVIuE4oBvZ19iwbFnS9r8CKbRJeZdHS589oI9uv4ugYE41jbqOExuD
uLAoQVOvemxcEaggyhA04ItHuVtXMhFMGCw+4AmI2LxsKuncuD5LJchUjnTsI9jm
TrV+nBKvQjsUxL9So5aCOTJmsv1+DrXQhz1DrkOo0A+bb7V9EeGefLC0SOFlxZFo
VLo4vRznUbAdA/iKWqu7vL2GImw9b9Wpc2CyyEqpCZ/y24mrmSnC0W7hhVdF030=
=reN8
-----END PGP SIGNATURE-----


From bbolker at gmail.com  Sat Mar 31 02:47:59 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Mar 2012 20:47:59 -0400
Subject: [Rd] r-forge build failure bafflement
In-Reply-To: <74449668-a1fa-4f83-9f4e-81707c0827bb@email.android.com>
References: <4F74CC1C.30802@gmail.com> <4F7546BC.70508@stats.ox.ac.uk>
	<4F7621C2.5070903@gmail.com>
	<74449668-a1fa-4f83-9f4e-81707c0827bb@email.android.com>
Message-ID: <4F76543F.3060206@gmail.com>

On 12-03-30 08:14 PM, Brian G. Peterson wrote:
> On my phone, so replying off-list, but wouldn't loading the data
> objects in a running R session and using the appropriate
> compression arguments to save() do the trick? - Brian

  I might try that, but I have a strong suspicion that R will try to
load the data objects anyway to see if they are compressible ...  I'd
have to look more carefully at resaveRdaFiles (in
src/library/tools/admin.R) to be sure, but it looks like line 860

        suppressPackageStartupMessages(load(p, envir = env))

unconditionally loads the files and would trigger the search for the
package -- I don't think this is avoidable.

 [cc'd back to r-devel for discussion/archival purposes]

> -- Sent from my Android phone with K-9 Mail. Please excuse my
> brevity.
> 
> Ben Bolker <bbolker at gmail.com> wrote:
> 
> Figured it out (I think: I haven't gotten through restructuring
> and testing, but I think it's going to work now).  I was paying 
> insufficient attention to the build arguments, in particular 
> --resave-data=best.
> 
> I previously had the clever idea to save some fitted models with
> the package so that they would be available to users who wanted to
> work with them without taking the time and trouble of re-running
> the model fits (some of which are very slow, especially for MCMC
> variants).  So I saved these in a .rda file in the data section,
> which seemed like a good idea at the time.  However, that means
> that resaving the data now requires loading the package with which
> the class of those model objects is associated ... and voila, a
> mysterious, apparently self-referential, e! rror message.
> 
> For now I'm experimenting with moving those fits to a .rda file 
> inst/extdata ... (I thought using to dput() instead of save() to
> save them might fix the problem, but it doesn't seem to) but this
> does seem like a bit of a pain (I have included anther function,
> getdata(), so that users don't have to mess around with
> system.file("extdata", [model_obj], package="glmmADMB"). I would be
> curious if anyone has any other suggestions for ways to work around
> this issue, or if they feel that I am subverting the intended use
> of the data/ directory (and so it's my own fault).
> 
> happy friday, and thanks to all for their suggestions.
> 
> Ben Bolker
> 
> On 12-03-30 01:38 AM, Prof Brian Ripley wrote:
>> We've seen similar things several times with CRAN submissions. 
>> Basic scenario was
> 
>> - INSTALL (via build or check) is trying to install a package
>> that is not
> already installed, into a private library not on the usual
>> .libPaths().
> 
>> - Start-up code in that package is looking for the package, and 
>> does not respect lib[name] as passed to .First.lib or 
>> .onLoad/.onAttach.  E.g. a call to installed.package() or 
>> packageDescription.
> 
>> - As the maintainer has an earlier version installed in .Library 
>> (s)he cannot reproduce it.
> 
>> I took a very quick look at the package: it has .First.lib and
>> not .onLoad/.onAttach, and of course it has a namespace (all
>> packages now do).  I would start by fixing that.
> 
>> On 29/03/2012 21:54, Ben Bolker wrote:
>>> 
>>> I am attempting to build a package on r-forge and running into
>>> a weird error.  I have been in correspondence with the R-forge 
>>> admins and am turning to r-devel on the remote chance that 
>>> someo!
> ne might have a guess as to what is going wrong or a
>>> suggestion about further diagnostics/experiments I could try
>>> ...
>>> 
>>> The package seems to build fine on my system(s) with
>>> 
>>> R CMD build --compact-vignettes --resave-data=best pkg
>>> 
>>> (these are the R-forge build arguments, according to the
>>> r-forge admins)
>>> 
>>> -- I've tried it with R-devel on Linux-32 and R 2.14.2 on 
>>> MacOS-64.
>>> 
>>> The build log (basically identical across
>>> linux64/win64/macos64) is as follows:
>>> 
>>> -------------- Thu Mar 29 20:15:21 2012: Building tarball for 
>>> package glmmADMB (SVN revision 204) using R version 2.14.2 
>>> (2012-02-29) ...
>>> 
>>> * checking for file 'glmmADMB/DESCRIPTION' ... OK * preparing 
>>> 'glmmADMB': * checking DESCRIPTION meta-informatio!
> n ... OK *
>>> checking for LF line-endings in source and make files *
>>> checking for empty or unneeded directories * looking to see if
>>> a 'data/datalist' file should be added * re-saving image files
>>>  Error in loadNamespace(name) : there is no package called 
>>> 'glmmADMB' Execution halted Run time: 0.51 seconds. ----------
>>> 
>>> so apparently the package is failing because it doesn't exist 
>>> (!!) I originally thought this was a circular dependency
>>> problem, because glmmADMB and coefplot2 (another r-forge
>>> package) depended on each other, but I have (at least for now)
>>> removed glmmADMB's coefplot2 dependency.  As far as I can tell
>>> there are *no* packages on r-forge that depend
>>> on/suggest/import glmmADMB.
>>> 
>>> a1<- available.packages(contriburl= 
>>> contrib.url("http://r-forge.r-project.org"))
>>>> rownames(a1)["glmmADMB" %in% a1[,"Suggests"]]
>>> character(0)
>>>> rownames(a1)["glmmADMB" %in% a1[,"Depends"]]
>>> character(0)
>>>> rownames(a1)["glmmADMB" %in% a1[,"Imports"]]
>>> character(0)
>>> 
>>> The perhaps-relevant parts of the DESCRIPTION file: ========= 
>>> BuildVignettes: no Description: Fits mixed-effects models using
>>> a variety of distributions Imports: stats, nlme Depends: R (>= 
>>> 2.13), methods, MASS, R2admb Suggests: lattice, lme4, lme4.0, 
>>> coda, mlmRev, scapeMCMC, ggplot2, bbmle, pscl, knitr, car
>>> =====
>>> 
>>> The only other thing I can think of is backing up a few SVN 
>>> revisions and seeing whether I can get back to a working
>>> version, but I'd like to see if I can get it fixed by moving
>>> forwar!
> d
>>> rather than backward ...
>>> 
>>> 
>>> For anyone who is intrigued and wants to investigate farther:
>>> 
>>> http://r-forge.r-project.org/R/?group_id=847 
>>> http://r-forge.r-project.org/scm/?group_id=847
>>> 
>>> cheers Ben Bolker
>>> 
>>> 
> ------------------------------------------------------------------------
>
> 
>>> R-devel at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> 
> ------------------------------------------------------------------------
>
>  R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Mark.Bravington at csiro.au  Sat Mar 31 10:41:19 2012
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Sat, 31 Mar 2012 19:41:19 +1100
Subject: [Rd] CRAN policies
In-Reply-To: <CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>,
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>

Herewith comments on some replies to my earlier post. To avoid burying my own points, I'll briefly restate my views (which may have evolved a bit):

 - We should not be concocting yet more complicated rules to solve imaginary problems;

 - RCMD CHECK should have (i) Notes, which are up to the individual to ponder and are not CRAN's concern, and (ii) Warnings, which trigger rejection from CRAN. And Warnings should be for a really good reason. Then developers have clarity, and the CRANia have less to do. Surely the CRANia are on a hiding-to-nothing if they create work for themselves by continuing to require manual inspection; the torrent of packages is only going to get deeper.

 - Given the vast number of packages, the burden of work imposed by false positives from new Warnings (or "significant Notes", mmmm) should be very carefully considered against any benefits of true positives. I think the balance is going wrong.

Righto, here are my comments on responses, some of which overlap. Thanks for those; I've snipped heavily and paraphrased to save space, no offence intended.

 - Matthew D: "It [all additions of Notes in RCMD CHECK] improves quality, surely." My comments in the final para were actually about Warnings sensu above, not Notes-- sorry if that was unclear. If someone is willing to add checks that lead just to Notes sensu above, then good on 'em. But, from my own experience and reports from others, I certainly do not consider that all Notes/Warnings really do indicate lack-of-quality (even excluding visible-bindings). I don't know exactly what's in QC.R, but one recent new thing did trigger a complaint from CRAN about a non-problem in 10-year-old code. The ensuing discussion cost me, and CRAN, time that neither of us have to spare. My job does not give me time to keep re-hitting a moving target. As to Memos vs Notes vs Warnings: why wouldn't two categories do? Packaging rules are quite complicated enough already!  (The temptation to make them even more baroque just to try to stem the flood is understandable, but not laudable...)

 Footnote: I've just glanced at the check results for mvbutils under R-devel. Another new and in my opinion unreasonable Warning has cropped up on 10-year-old perfectly functional code (beside others which may have a point). I'll start a separate thread, but this reinforces my view that fixing Notes or even Warnings doesn't necessarily improve quality-- and it's not limited to the visible-bindings case.

 - Spencer G: well, I didn't say "RCMD CHECK is bad"! I'm not advocating anarchy, merely pointing out that: there are limits to what RCMD CHECK can and should do, that it is fulfilling two different roles which are getting muddled, and that not everyone finds all of it useful. I'm honestly glad you do, but I don't (except Codoc, as I said), so one-size-does-not-fit-all. FWIW, my own pathway to efficient writing relies on (i) a good debugger (the debug package), and (ii) a really seamless method for editing my packages on-the-fly (one part of the mvbutils package).


 - Paul G: [300 Notes? Please explain!] Actually, I could explain the idiom quicker than I can write this paragraph, but I don't want to here because I'm opposed on principle to Notes requiring an explanation. This part of mvbutils has worked for 10 years. Someone has subsequently decided that code should look a certain way, and has added a check that isn't in the language itself-- but they haven't thought of everything, and of course they never could. (That might be paranoid. Maybe they aren't trying to impose how things should look, and rather are just trying to be helpful, which would be fine. It depends on how Notes are being interpreted, which from this thread is no longer clear. The R-core line used to be "Notes are just notes" but now we seem to have "significant Notes" and vague threats about "lots of Notes" etc. Paranoia seems reasonable.) However, anyone interested is welcome to look at the mvbutils package, as Bill did. The main idiom is clearly documented in ?mlocal, and the other cases are usually eval() I think. Since there is no reliable way for a static check to figure out where the eval() happens, it hasn't got a hope of assessing whether bindings exist. Dammit, now I'm explaining, which I didn't want to, but only so that someone can change the check, mind...

  As to peace-of-mind from RCMD CHECK: well, I certainly don't have it! Two reasons:

  (1) You don't have to look far on CRAN to find packages that are badly written (and more often badly documented) but pass their RCMD CHECK fine. I tried this just now and got a result on my first go.

  (2) I know very well how to modify my code to evade the notes and most warnings, without changing any of what it does-- as could anyone with a bit of creativity. If I had inclination and time, I could do it. In no reasonable sense would it be "better" code, though.

 So RCMD CHECK is neither a necessary nor sufficient condition for virtue. Inspection of a language as rich as R will never be foolproof. The user simply has to take it on trust that a package does what it claims, or otherwise decide not to use it. How the package does it, is up to the author. My experience of other people's software is: peace-of-mind starts with helpful documentation, and also depends on whether I get a sense from the archives that the author might actually help if I run into something odd. Several well-known packages fail these tests, so I avoid them. Automated checks, beyond a certain limited point which they have probably reached, seem to me to be playing the wrong game.

 Bill D: [proposal for additional "documentation" mechanism] Thanks for going to the trouble of looking at my code; I certainly appreciate the effort, but your proposal is exactly what I am against! The issue is with the check, not with my code, and as above I do not see why I should need to add elaborate justifications. For some, this particular check (visible-binding) is apparently useful. For others, it's not. So why not just leave it as a Note that people can worry about or not if they want? It should not be of concern to those very busy CRANia people.

 Joshua W: [CRAN can set its own rules, and if a package doesn't easily fit them, maybe it should be put elsewhere.] Certainly CRAN/R-core (the distinction is shadowy to me) can, and frequently does, decide to do whatever it wants, including decisions about what to host. But it does not follow that every decision taken is axiomatically a Good Thing for R. More effort now goes into R development from people outside R core than inside it (>3000 packages). If a CRAN/Rcore decision entails a lot of work for others to amend code in ways that do not make the code work better, then it doesn't strike me as a good decision. Ditto if perfectly functional code is forced off CRAN, where it is (sort of) easy to find-- it becomes more difficult for the wider R community to get it, and of course it may not get *any* checks that way. NB I am not commenting here on individual aspects of RCMD CHECK etc-- this is a general point about mission creep, helps and hindrances, and balance of workload.


 Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: Joshua Wiley [jwiley.psych at gmail.com]
Sent: 31 March 2012 06:03
To: Kevin Wright
Cc: Bravington, Mark (CMIS, Hobart); r-devel at stat.math.ethz.ch
Subject: Re: [Rd] CRAN policies

On Fri, Mar 30, 2012 at 11:41 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> I'll echo Mark's concerns.  R _used_ to be a language for "turning ideas
> into software quickly".  Now it is more like "prototyping ideas in software
> quickly", and then spend a substantial amount of time trying to follow
> administrative rules to package the code.

..if you want to submit to CRAN.  There are practically zero if you
host on your own website.  Of course developers are free to do
whatever they want and R core does not get to tell them what/how to do
it.  R core does get a say when you ask them to host your source and
build your package binaries.

> Quality has its costs.

So does using CRAN.  If it is not the best solution for your problem,
use something else.  Hadley uses github from development ggplot2, and
with the dev_tools package, it is relatively easy for users to install
the source ggplot2 code.  Something like that might be appropriate for
code/packages wehre you just want to 'turn ideas into software
quickly'.  There is an extra step required for users to use it, but
that makes sense because it weeds out inept users from using code with
less quality control.

>
> Many of the code checks I find quite useful, but the "no visible binding"
> one generates lots of nuisance notes for me.  I must have a similar coding
> style to Mark.
>
> Kevin
>
>
> On Thu, Mar 29, 2012 at 8:29 PM, <Mark.Bravington at csiro.au> wrote:
>
>> I'm concerned this thread is heading the wrong way, towards techno-fixes
>> for imaginary problems. R package-building is already encumbered with a
>> huge set of complicated rules, and more instructions/rules eg for metadata
>> would make things worse not better.
>>
>> RCMD CHECK on the 'mvbutils' package generates over 300 Notes about "no
>> visible binding...", which inevitably I just ignore. They arise because
>> RCMD CHECK is too "stupid" to understand one of my preferred coding idioms
>> (I'm not going to explain what-- that's beside the point). And RCMD CHECK
>> always will be too "stupid" to understand everything that a rich language
>> like R might quite reasonably cause experienced coders to do.
>>
>> It should not be CRAN's business how I write my code, or even whether my
>> code does what it is supposed to. It might be CRAN's business to try to
>> work out whether my code breaks CRAN's policies, eg by causing R to crash
>> horribly-- that's presumably what Warnings are for (but see below). And
>> maybe there could be circumstances where an automatic check might be
>> "worried" enough to alert the CRANia and require manual explanation and
>> emails etc from a developer, but even that seems doomed given the growing
>> deluge of packages.
>>
>> RCMD CHECK currently functions both as a "sanitizer" for CRAN, and as a
>> developer-tool. But the fact that the one programl does both things seems
>> accidental to me, and I think this dual-use is muddying the discussion.
>> There's a big distinction between (i) code-checks that developers
>> themselves might or might not find useful-- which should be left to the
>> developer, and will vary from person to person-- and (ii) code-checks that
>> CRAN enforces for its own peace-of-mind. Maybe it's convenient to have both
>> functions in the same place, and it'd be fine to use Notes for one and
>> Warnings for the other, but the different purposes should surely be kept
>> clear.
>>
>> Personally, in building over 10 packages (only 2 on CRAN), I haven't found
>> RCMD CHECK to be of any use, except for the code-documentation and
>> example-running bits. I know other people have different opinions, but
>> that's the point: one-size-does-not-fit-all when it comes to coding tools.
>>
>> And wrto the Warnings themselves: I feel compelled to point out that it's
>> logically impossible to fully check whether R code will do bad things. One
>> has to wonder at what point adding new checks becomes futile or
>> counterproductive. There must be over 2000 people who have written CRAN
>> packages by now; every extra check and non-back-compatible additional
>> requirement runs the risk of generating false-negatives and incurring many
>> extra person-hours to "fix" non-problems. Plus someone needs to document
>> and explain the check (adding to the rule mountain), plus there is the time
>> spent in discussions like this..!
>>
>> Mark
>>
>> Mark Bravington
>> CSIRO CMIS
>> Marine Lab
>> Hobart
>> Australia
>> ________________________________________
>> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On
>> Behalf Of Hadley Wickham [hadley at rice.edu]
>> Sent: 30 March 2012 07:42
>> To: William Dunlap
>> Cc: r-devel at stat.math.ethz.ch; Spencer Graves
>> Subject: Re: [Rd] CRAN policies
>>
>> > Most of that stuff is already in codetools, at least when it is checking
>> functions
>> > with checkUsage().  E.g., arguments of ~ are not checked.  The  expr
>> argument
>> > to with() will not be checked if you add  skipWith=FALSE to the call to
>> checkUsage.
>> >
>> >  > library(codetools)
>> >
>> >  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~
>> Pred}))
>> >  <anonymous>: no visible binding for global variable 'Num' (:1)
>> >  <anonymous>: no visible binding for global variable 'Den' (:1)
>> >
>> >  > checkUsage(function(dataFrame) with(dataFrame, {Num/Den ; Resp ~
>> Pred}), skipWith=TRUE)
>> >
>> >  > checkUsage(function(dataFrame) with(DataFrame, {Num/Den ; Resp ~
>> Pred}), skipWith=TRUE)
>> >  <anonymous>: no visible binding for global variable 'DataFrame'
>> >
>> > The only part that I don't see is the mechanism to add code-walker
>> functions to
>> > the environment in codetools that has the standard list of them for
>> functions with
>> > nonstandard evaluation:
>> >  > objects(codetools:::collectUsageHandlers, all=TRUE)
>> >   [1] "$"             "$<-"           ".Internal"
>> >   [4] "::"            ":::"           "@"
>> >   [7] "@<-"           "{"             "~"
>> >  [10] "<-"            "<<-"           "="
>> >  [13] "assign"        "binomial"      "bquote"
>> >  [16] "data"          "detach"        "expression"
>> >  [19] "for"           "function"      "Gamma"
>> >  [22] "gaussian"      "if"            "library"
>> >  [25] "local"         "poisson"       "quasi"
>> >  [28] "quasibinomial" "quasipoisson"  "quote"
>> >  [31] "Quote"         "require"       "substitute"
>> >  [34] "with"
>>
>> It seems like we really need a standard way to add metadata to functions:
>>
>> attr(with, "special_args") <- "expr"
>> attr(lm, "special_args") <- c("formula", "weights", "subset")
>>
>> This would be useful because it could automatically contribute to the
>> documentation.
>>
>> Similarly,
>>
>> attr(my.new.method, "s3method") <- c("my.new", "method")
>>
>> could be useful.
>>
>> Hadley
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Kevin Wright
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



--
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From pgilbert902 at gmail.com  Sat Mar 31 15:57:06 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 31 Mar 2012 09:57:06 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>,
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
Message-ID: <4F770D32.6090608@gmail.com>

Mark

I would like to clarify two specific points.

On 12-03-31 04:41 AM, Mark.Bravington at csiro.au wrote:
 > ...
> Someone has subsequently decided that code should look a certain way, and has added a check that
> isn't in the language itself-- but they haven't thought of everything, and of course they never could.

There is a large overlap between people writing the checks and people 
writing the interpreter. Even though your code may have been working, if 
your understanding of the language definition is not consistent with 
that of the people writing the interpreter, there is no guarantee that 
it will continue to work, and in some cases the way in which it fails 
could be that it produces spurious results. I am inclined to think of 
code checks as an additional way to be sure my understanding of the R 
language is close to that of the people writing the interpreter.

> It depends on how Notes are being interpreted, which from this thread is no longer clear.
 > The R-core line used to be "Notes are just notes" but now we seem to 
have "significant Notes" and ...

My understanding, and I think that of a few other people, was incorrect, 
in that I thought some notes were intended always to remain as notes, 
and others were more serious in that they would eventually become 
warnings or errors. I think Uwe addressed this misunderstanding by 
saying that all notes are intended to become warnings or errors. In 
several cases the reason they are not yet warnings or errors is that the 
checks are not yet good enough, they produce too many false positives. 
So, this means that it is very important for us to look at the notes and 
to point out the reasons for the false positives, otherwise they may 
become warnings or errors without being recognised as such.

 > ...

Paul


From ggrothendieck at gmail.com  Sat Mar 31 16:26:43 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Mar 2012 10:26:43 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F770D32.6090608@gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
	<4F770D32.6090608@gmail.com>
Message-ID: <CAP01uR=Xxzu2kUxr4c-JZRjCcD1ZPL3zzPzCP3dXLp4Lv1b7Ng@mail.gmail.com>

On Sat, Mar 31, 2012 at 9:57 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> Mark
>
> I would like to clarify two specific points.
>
> On 12-03-31 04:41 AM, Mark.Bravington at csiro.au wrote:
>> ...
>
>> Someone has subsequently decided that code should look a certain way, and
>> has added a check that
>> isn't in the language itself-- but they haven't thought of everything, and
>> of course they never could.
>
>
> There is a large overlap between people writing the checks and people
> writing the interpreter. Even though your code may have been working, if
> your understanding of the language definition is not consistent with that of
> the people writing the interpreter, there is no guarantee that it will
> continue to work, and in some cases the way in which it fails could be that
> it produces spurious results. I am inclined to think of code checks as an
> additional way to be sure my understanding of the R language is close to
> that of the people writing the interpreter.

The point is that it has been historically possible to push R in
different directions even without the blessing of the core team but if
its locked down too tightly then we lose that facility and its that
loss or potential loss that is worrying.  The idea of the package
system is that it should be possible to extend R without having to
modify the core of R itself.

>> It depends on how Notes are being interpreted, which from this thread is
>> no longer clear.
>
>> The R-core line used to be "Notes are just notes" but now we seem to have
>> "significant Notes" and ...
>
> My understanding, and I think that of a few other people, was incorrect, in

I don't think so.  I think it was changed on us and I think it ought
to be changed back.

Some people on this thread seem to be framing this as a quality issue
but its nothing of the sort.  The specifics cited make it clear that
the current handling of  Notes is not improving the quality of any
package but is potentially causing thousands of package developers
needless work on packages that have been working for years.  If the
Notes are just there to be helpful that is one thing but changing the
idea of Notes so that an undefined subset of them are arbitrarily
imposed at the whim of the R core group is what is objectionable.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From r.ted.byers at gmail.com  Sat Mar 31 17:29:37 2012
From: r.ted.byers at gmail.com (Ted Byers)
Date: Sat, 31 Mar 2012 11:29:37 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F770D32.6090608@gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>,
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
	<4F770D32.6090608@gmail.com>
Message-ID: <0a0d01cd0f53$15e82510$41b86f30$@gmail.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Paul Gilbert
> Sent: March-31-12 9:57 AM
> To: Mark.Bravington at csiro.au
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
Greetings all

> Mark
> 
> I would like to clarify two specific points.
> 
> On 12-03-31 04:41 AM, Mark.Bravington at csiro.au wrote:
>  > ...
> > Someone has subsequently decided that code should look a certain way,
> > and has added a check that isn't in the language itself-- but they
haven't
> thought of everything, and of course they never could.
> 
> There is a large overlap between people writing the checks and people
writing
> the interpreter. Even though your code may have been working, if your
> understanding of the language definition is not consistent with that of
the
> people writing the interpreter, there is no guarantee that it will
continue to
> work, and in some cases the way in which it fails could be that it
produces
> spurious results. I am inclined to think of code checks as an additional
way to be
> sure my understanding of the R language is close to that of the people
writing
> the interpreter.
> 
> > It depends on how Notes are being interpreted, which from this thread is
no
> longer clear.
>  > The R-core line used to be "Notes are just notes" but now we seem to
have
> "significant Notes" and ...
> 
> My understanding, and I think that of a few other people, was incorrect,
in that
> I thought some notes were intended always to remain as notes, and others
> were more serious in that they would eventually become warnings or errors.
I
> think Uwe addressed this misunderstanding by saying that all notes are
> intended to become warnings or errors. In several cases the reason they
are
> not yet warnings or errors is that the checks are not yet good enough,
they
> produce too many false positives.
> So, this means that it is very important for us to look at the notes and
to point
> out the reasons for the false positives, otherwise they may become
warnings or
> errors without being recognised as such.
>
I left the above intact as it nicely illustrates what much of this
discussion reminds me of.  Let me illustrate with the question of software
development in one of my favourite languages: C++.

The first issue to consider is, "What is the language definition and who
decides?"  Believe it or not, there are two answers from two very different
perspectives.  The first is favoured by language lawyers, who point to the
ANSI standard, and who will argue incessantly about the finest of details.
But to understand this, you have to understand what ANSI is: it is an
industry organization and to construct the standard, they have industry
representatives gathered, divided up into subcommittees each of which is
charged with defining the language.  And of course everyone knows that,
being human, they can get it wrong, and thus ANSI standards evolve ever so
slowly through time.  To my mind, that is not much different from what
R/core or Cran are involved in.  But the other answer comes from the
perspective of a professional software developer, and that is, that the
final arbiter of what the language is is your compiler.  If you want to get
product out the door, it doesn't matter if the standard says 'X' if the
compiler doesn't support it, or worse, implements it incorrectly.  Most
compilers have warnings and errors, and I like the idea of extending that to
have notes, but that is a matter of taste vs pragmatism.  I know many
software developers that choose to ignore warnings and fix only the errors.
Their rationale is that it takes time they don't have to fix the warnings
too.  And I know others who treat all warnings as errors unless they have
discovered that there is a compiler bug that generates spurious warnings of
a particular kind (in which case that specific warning can usually be turned
off).  Guess which group has lower bug rates on average.  I tend to fall in
the latter group, having observed that with many of these things, you either
fix them now or you will fix them, at greater cost, later.

The second issue to consider is, "What constitutes good code, and what is
necessary to produce it?"  That I won't answer beyond saying, 'whatever
works.'  That is because it is ultimately defined by the end users'
requirements.  that is why we have software engineers who specialize in
requirements engineering.  these are bright people who translate the wish
lists of non-technical users into functional and environmental requirements,
that the rest of us can code to.  But before we begin coding, we have QA
specialists that design a variety of tests from finely focussed unit tests
through integration tests to broadly focussed usability tests, ending with a
suite of tests that basically confirm that the requirements defined for the
product are satisfied.  Standard practice in good software houses is that
nothing gets added to the codebase unless the entire code base, with the new
or revised code,  compiles and passes the entire test suite.  When new code
stresses the codebase in such a way as to trigger a failure in the existing
code, then when it is diagnosed and fixed, new tests are designed and added
to the test suite codebase (which has the same requirement of everything
building and passing all tests).  of course, some do this better than others
as there are reasons NASA may spend $5 per line of code while many industry
players spend $0.05 per line of code.

It is sheer folly for anyone to suggest that reliance on warnings and
errors, even extending this to notes, ensures good code.  At best, these are
necessary to support development of good code, but they do not come close to
being sufficient.  it is trivial to find examples of C code, for computing a
mean, variance and standard deviation, that is correct both WRT the ANSI
standard and the compiler, and yet it is really bad code (look for single
pass algorithms, and you'll find one of the most commonly recommended
algorithms is also one of the worst, In terms of accuracy under some inputs,
and yet an infrequently recommended algorithm is one of the best both in
terms of ease of implementation, speed and accuracy).  And you will still
find good mathematicians defending the bad code by saying it is
mathematically correct, but this is because they do not understand the
consequences of finite precision arithmetic and rounding error.

I would observe, as an outsider, that what CRAN is apparently doing is
primarily focussed on the first issue above, but going beyond what the R
interpreter does to get a better handle on a system of warnings with an
extension to notes.  The notes question I can understand as a pragmatic
matter.  If I were assigned to do the same sort of thing, I would probably
do it in a similar manner, leaving some things as notes until both I and the
community I serve develop a better understanding of the issues involved in
the subject of the notes to the point of being better able to either have
them evolve into more precisely defined warnings or die.  I understand that
getting many of these things can get tedious and time consuming, but in fact
there is no other way for a community to analyse the issues involved and
develop a good understanding of how best to handle them.

But since CRAN does not appear to require requirements engineering to be
completed along with a comprehensive suite of QA tests, there is no possible
way they can offer any guarantees or even recommendations that any package
on CRAN is good quality.  From the current reaction to mere notes, I can
imagine the reaction that would arise should they ever decide to do so.  It
is very much up to the 'consumer' to search CRAN, and evaluate each
interesting package to ensure it works as advertised, and I have no doubt
that some are gems while others are best avoided.

Just my $0.02 ...

Cheers

Ted


From spencer.graves at prodsyse.com  Sat Mar 31 19:56:04 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 31 Mar 2012 10:56:04 -0700
Subject: [Rd] CRAN policies
In-Reply-To: <0a0d01cd0f53$15e82510$41b86f30$@gmail.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>,
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
	<4F770D32.6090608@gmail.com>
	<0a0d01cd0f53$15e82510$41b86f30$@gmail.com>
Message-ID: <4F774534.8010502@prodsyse.com>

Hi, Ted:


       Thank you for the most eloquent and complete description of the 
problem and opportunity I've seen in a while.


       Might you have time to review the Wikipedia articles on "Package 
development process" and "Software repository" 
(http://en.wikipedia.org/wiki/Package_development_process; 
http://en.wikipedia.org/wiki/Software_repository) and share with me your 
reactions?


       I wrote the "Package development process" article and part of the 
"Software repository" article, because the R package development process 
is superior to similar processes I've seen for other languages.  
However, I'm not a leading researcher on these issues, and your comments 
suggest that you know far more than I about this.  Humanity might 
benefit from your review of these articles.  (If you have any changes 
you might like to see, please make them or ask me to make them.  
Contributing to Wikipedia can be a very high leverage activity, as 
witnessed by the fact that the Wikipedia article on SOPA received a 
million views between the US holidays of Thanksgiving and Christmas last 
year.)


       Thanks again,
       Spencer


On 3/31/2012 8:29 AM, Ted Byers wrote:
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
>> On Behalf Of Paul Gilbert
>> Sent: March-31-12 9:57 AM
>> To: Mark.Bravington at csiro.au
>> Cc: r-devel at stat.math.ethz.ch
>> Subject: Re: [Rd] CRAN policies
>>
> Greetings all
>
>> Mark
>>
>> I would like to clarify two specific points.
>>
>> On 12-03-31 04:41 AM, Mark.Bravington at csiro.au wrote:
>>   >  ...
>>> Someone has subsequently decided that code should look a certain way,
>>> and has added a check that isn't in the language itself-- but they
> haven't
>> thought of everything, and of course they never could.
>>
>> There is a large overlap between people writing the checks and people
> writing
>> the interpreter. Even though your code may have been working, if your
>> understanding of the language definition is not consistent with that of
> the
>> people writing the interpreter, there is no guarantee that it will
> continue to
>> work, and in some cases the way in which it fails could be that it
> produces
>> spurious results. I am inclined to think of code checks as an additional
> way to be
>> sure my understanding of the R language is close to that of the people
> writing
>> the interpreter.
>>
>>> It depends on how Notes are being interpreted, which from this thread is
> no
>> longer clear.
>>   >  The R-core line used to be "Notes are just notes" but now we seem to
> have
>> "significant Notes" and ...
>>
>> My understanding, and I think that of a few other people, was incorrect,
> in that
>> I thought some notes were intended always to remain as notes, and others
>> were more serious in that they would eventually become warnings or errors.
> I
>> think Uwe addressed this misunderstanding by saying that all notes are
>> intended to become warnings or errors. In several cases the reason they
> are
>> not yet warnings or errors is that the checks are not yet good enough,
> they
>> produce too many false positives.
>> So, this means that it is very important for us to look at the notes and
> to point
>> out the reasons for the false positives, otherwise they may become
> warnings or
>> errors without being recognised as such.
>>
> I left the above intact as it nicely illustrates what much of this
> discussion reminds me of.  Let me illustrate with the question of software
> development in one of my favourite languages: C++.
>
> The first issue to consider is, "What is the language definition and who
> decides?"  Believe it or not, there are two answers from two very different
> perspectives.  The first is favoured by language lawyers, who point to the
> ANSI standard, and who will argue incessantly about the finest of details.
> But to understand this, you have to understand what ANSI is: it is an
> industry organization and to construct the standard, they have industry
> representatives gathered, divided up into subcommittees each of which is
> charged with defining the language.  And of course everyone knows that,
> being human, they can get it wrong, and thus ANSI standards evolve ever so
> slowly through time.  To my mind, that is not much different from what
> R/core or Cran are involved in.  But the other answer comes from the
> perspective of a professional software developer, and that is, that the
> final arbiter of what the language is is your compiler.  If you want to get
> product out the door, it doesn't matter if the standard says 'X' if the
> compiler doesn't support it, or worse, implements it incorrectly.  Most
> compilers have warnings and errors, and I like the idea of extending that to
> have notes, but that is a matter of taste vs pragmatism.  I know many
> software developers that choose to ignore warnings and fix only the errors.
> Their rationale is that it takes time they don't have to fix the warnings
> too.  And I know others who treat all warnings as errors unless they have
> discovered that there is a compiler bug that generates spurious warnings of
> a particular kind (in which case that specific warning can usually be turned
> off).  Guess which group has lower bug rates on average.  I tend to fall in
> the latter group, having observed that with many of these things, you either
> fix them now or you will fix them, at greater cost, later.
>
> The second issue to consider is, "What constitutes good code, and what is
> necessary to produce it?"  That I won't answer beyond saying, 'whatever
> works.'  That is because it is ultimately defined by the end users'
> requirements.  that is why we have software engineers who specialize in
> requirements engineering.  these are bright people who translate the wish
> lists of non-technical users into functional and environmental requirements,
> that the rest of us can code to.  But before we begin coding, we have QA
> specialists that design a variety of tests from finely focussed unit tests
> through integration tests to broadly focussed usability tests, ending with a
> suite of tests that basically confirm that the requirements defined for the
> product are satisfied.  Standard practice in good software houses is that
> nothing gets added to the codebase unless the entire code base, with the new
> or revised code,  compiles and passes the entire test suite.  When new code
> stresses the codebase in such a way as to trigger a failure in the existing
> code, then when it is diagnosed and fixed, new tests are designed and added
> to the test suite codebase (which has the same requirement of everything
> building and passing all tests).  of course, some do this better than others
> as there are reasons NASA may spend $5 per line of code while many industry
> players spend $0.05 per line of code.
>
> It is sheer folly for anyone to suggest that reliance on warnings and
> errors, even extending this to notes, ensures good code.  At best, these are
> necessary to support development of good code, but they do not come close to
> being sufficient.  it is trivial to find examples of C code, for computing a
> mean, variance and standard deviation, that is correct both WRT the ANSI
> standard and the compiler, and yet it is really bad code (look for single
> pass algorithms, and you'll find one of the most commonly recommended
> algorithms is also one of the worst, In terms of accuracy under some inputs,
> and yet an infrequently recommended algorithm is one of the best both in
> terms of ease of implementation, speed and accuracy).  And you will still
> find good mathematicians defending the bad code by saying it is
> mathematically correct, but this is because they do not understand the
> consequences of finite precision arithmetic and rounding error.
>
> I would observe, as an outsider, that what CRAN is apparently doing is
> primarily focussed on the first issue above, but going beyond what the R
> interpreter does to get a better handle on a system of warnings with an
> extension to notes.  The notes question I can understand as a pragmatic
> matter.  If I were assigned to do the same sort of thing, I would probably
> do it in a similar manner, leaving some things as notes until both I and the
> community I serve develop a better understanding of the issues involved in
> the subject of the notes to the point of being better able to either have
> them evolve into more precisely defined warnings or die.  I understand that
> getting many of these things can get tedious and time consuming, but in fact
> there is no other way for a community to analyse the issues involved and
> develop a good understanding of how best to handle them.
>
> But since CRAN does not appear to require requirements engineering to be
> completed along with a comprehensive suite of QA tests, there is no possible
> way they can offer any guarantees or even recommendations that any package
> on CRAN is good quality.  From the current reaction to mere notes, I can
> imagine the reaction that would arise should they ever decide to do so.  It
> is very much up to the 'consumer' to search CRAN, and evaluate each
> interesting package to ensure it works as advertised, and I have no doubt
> that some are gems while others are best avoided.
>
> Just my $0.02 ...
>
> Cheers
>
> Ted
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From r.ted.byers at gmail.com  Sat Mar 31 21:03:27 2012
From: r.ted.byers at gmail.com (Ted Byers)
Date: Sat, 31 Mar 2012 15:03:27 -0400
Subject: [Rd] CRAN policies
In-Reply-To: <4F774534.8010502@prodsyse.com>
References: <mailman.19.1333015207.14516.r-devel@r-project.org>
	<4F746B54.2050601@mayo.edu>
	<E66794E69CFDE04D9A70842786030B9328EC77@PA-MBX04.na.tibco.com>
	<loom.20120329T190333-975@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B9328EDE3@PA-MBX04.na.tibco.com>
	<4F74B657.5040807@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B9328EEFC@PA-MBX04.na.tibco.com>
	<CABdHhvGp4f6KAqa5ba8xB-JH0sh0y87J+xRZeTW9DSwzowpV2g@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B0@exvic-mbx04.nexus.csiro.au>
	<CAKFxdiT3pgcVXfksF_7GnsbReWCDPHynqSnLXzPF88muSuQtqg@mail.gmail.com>,
	<CANz9Z_+fUnDmbUuzpWzpH2Q7fK+RQjdkoORNx6dVRPw9FMfEGA@mail.gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F820247B7@exvic-mbx04.nexus.csiro.au>
	<4F770D32.6090608@gmail.com>
	<0a0d01cd0f53$15e82510$41b86f30$@gmail.com>
	<4F774534.8010502@prodsyse.com>
Message-ID: <0ad501cd0f70$f518a800$df49f800$@gmail.com>

> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at prodsyse.com]
> Sent: March-31-12 1:56 PM
> To: Ted Byers
> Cc: 'Paul Gilbert'; Mark.Bravington at csiro.au; r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] CRAN policies
> 
> Hi, Ted:
> 
> 
>        Thank you for the most eloquent and complete description of the
problem
> and opportunity I've seen in a while.
> 
To paraphrase and flagrantly plagiarize a better scholar than I, 'If I have
seen farther, it is because I stand on the shoulders of giants.'

No really, I have been doing this since the stone age, when we used rocks,
or marks cut into sticks, or knots tied in string made from hemp, as our
computing devices.  And the extent to which most of us could count was
'1,2,3, many'  ;-)

Might I suggest an additional essay for you about the place of documentation
in quality software production?  We all know the benefits of design
documentation, but documentation intended for users is, in my view,
critical.  In my view, though, I have a successful interface if users find
it so intuitive that they have no need for the wonderful documentation I
write.  I'll say no more but to give an example of the best documentation of
a software product I have seen in more than 30 years (no, I wrote neither it
nor the software it describes): http://eigen.tuxfamily.org/dox/index.html.
It is so nice to be able to commend someone who has done well!

Eigen is a C++ library supporting very efficient and fast matrix algebra,
and then some.

GSL is another very good example:
http://www.gnu.org/software/gsl/manual/html_node/ but not quite as good, in
my view, as Eigen

There is a SCM product, primarily Unix, though it does build under Cygwin,
called Aegis.  The last I looked, it had a nice explanation of the protocol
of testing, and ensuring that everything builds and passes all tests before
adding new or revised code to the codebase.  There may be support for it in
more recent products like GIT or Subversion, but to be honest I haven't had
the time to look.

To gather material for requirements gathering, and use of that to guide QA
processes and the design of one of the several suites of tests a project
usually needs, the place where the best info is in the many references
dealing with UML.

You have made a good start on those pages, but it needs to be fleshed out.
I do not recommend making either of them longer than 50% more than their
current length.  Rather, I suggest fleshing it out hypertext fashion, by
adding (links to) pages dealing with different issues in more detail than is
possible in an executive summary.

But, overall, well done.

Cheers

Ted

> 
>        Might you have time to review the Wikipedia articles on "Package
> development process" and "Software repository"
> (http://en.wikipedia.org/wiki/Package_development_process;
> http://en.wikipedia.org/wiki/Software_repository) and share with me your
> reactions?
> 
> 
>        I wrote the "Package development process" article and part of the
> "Software repository" article, because the R package development process
> is superior to similar processes I've seen for other languages.
> However, I'm not a leading researcher on these issues, and your comments
> suggest that you know far more than I about this.  Humanity might
> benefit from your review of these articles.  (If you have any changes
> you might like to see, please make them or ask me to make them.
> Contributing to Wikipedia can be a very high leverage activity, as
> witnessed by the fact that the Wikipedia article on SOPA received a
> million views between the US holidays of Thanksgiving and Christmas last
> year.)
> 
> 
>        Thanks again,
>        Spencer
> 
> 
> On 3/31/2012 8:29 AM, Ted Byers wrote:
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org]
> >> On Behalf Of Paul Gilbert
> >> Sent: March-31-12 9:57 AM
> >> To: Mark.Bravington at csiro.au
> >> Cc: r-devel at stat.math.ethz.ch
> >> Subject: Re: [Rd] CRAN policies
> >>
> > Greetings all
> >
> >> Mark
> >>
> >> I would like to clarify two specific points.
> >>
> >> On 12-03-31 04:41 AM, Mark.Bravington at csiro.au wrote:
> >>   >  ...
> >>> Someone has subsequently decided that code should look a certain way,
> >>> and has added a check that isn't in the language itself-- but they
> > haven't
> >> thought of everything, and of course they never could.
> >>
> >> There is a large overlap between people writing the checks and people
> > writing
> >> the interpreter. Even though your code may have been working, if your
> >> understanding of the language definition is not consistent with that of
> > the
> >> people writing the interpreter, there is no guarantee that it will
> > continue to
> >> work, and in some cases the way in which it fails could be that it
> > produces
> >> spurious results. I am inclined to think of code checks as an
additional
> > way to be
> >> sure my understanding of the R language is close to that of the people
> > writing
> >> the interpreter.
> >>
> >>> It depends on how Notes are being interpreted, which from this thread
is
> > no
> >> longer clear.
> >>   >  The R-core line used to be "Notes are just notes" but now we seem
to
> > have
> >> "significant Notes" and ...
> >>
> >> My understanding, and I think that of a few other people, was
incorrect,
> > in that
> >> I thought some notes were intended always to remain as notes, and
others
> >> were more serious in that they would eventually become warnings or
errors.
> > I
> >> think Uwe addressed this misunderstanding by saying that all notes are
> >> intended to become warnings or errors. In several cases the reason they
> > are
> >> not yet warnings or errors is that the checks are not yet good enough,
> > they
> >> produce too many false positives.
> >> So, this means that it is very important for us to look at the notes
and
> > to point
> >> out the reasons for the false positives, otherwise they may become
> > warnings or
> >> errors without being recognised as such.
> >>
> > I left the above intact as it nicely illustrates what much of this
> > discussion reminds me of.  Let me illustrate with the question of
software
> > development in one of my favourite languages: C++.
> >
> > The first issue to consider is, "What is the language definition and who
> > decides?"  Believe it or not, there are two answers from two very
different
> > perspectives.  The first is favoured by language lawyers, who point to
the
> > ANSI standard, and who will argue incessantly about the finest of
details.
> > But to understand this, you have to understand what ANSI is: it is an
> > industry organization and to construct the standard, they have industry
> > representatives gathered, divided up into subcommittees each of which is
> > charged with defining the language.  And of course everyone knows that,
> > being human, they can get it wrong, and thus ANSI standards evolve ever
so
> > slowly through time.  To my mind, that is not much different from what
> > R/core or Cran are involved in.  But the other answer comes from the
> > perspective of a professional software developer, and that is, that the
> > final arbiter of what the language is is your compiler.  If you want to
get
> > product out the door, it doesn't matter if the standard says 'X' if the
> > compiler doesn't support it, or worse, implements it incorrectly.  Most
> > compilers have warnings and errors, and I like the idea of extending
that to
> > have notes, but that is a matter of taste vs pragmatism.  I know many
> > software developers that choose to ignore warnings and fix only the
errors.
> > Their rationale is that it takes time they don't have to fix the
warnings
> > too.  And I know others who treat all warnings as errors unless they
have
> > discovered that there is a compiler bug that generates spurious warnings
of
> > a particular kind (in which case that specific warning can usually be
turned
> > off).  Guess which group has lower bug rates on average.  I tend to fall
in
> > the latter group, having observed that with many of these things, you
either
> > fix them now or you will fix them, at greater cost, later.
> >
> > The second issue to consider is, "What constitutes good code, and what
is
> > necessary to produce it?"  That I won't answer beyond saying, 'whatever
> > works.'  That is because it is ultimately defined by the end users'
> > requirements.  that is why we have software engineers who specialize in
> > requirements engineering.  these are bright people who translate the
wish
> > lists of non-technical users into functional and environmental
requirements,
> > that the rest of us can code to.  But before we begin coding, we have QA
> > specialists that design a variety of tests from finely focussed unit
tests
> > through integration tests to broadly focussed usability tests, ending
with a
> > suite of tests that basically confirm that the requirements defined for
the
> > product are satisfied.  Standard practice in good software houses is
that
> > nothing gets added to the codebase unless the entire code base, with the
new
> > or revised code,  compiles and passes the entire test suite.  When new
code
> > stresses the codebase in such a way as to trigger a failure in the
existing
> > code, then when it is diagnosed and fixed, new tests are designed and
added
> > to the test suite codebase (which has the same requirement of everything
> > building and passing all tests).  of course, some do this better than
others
> > as there are reasons NASA may spend $5 per line of code while many
industry
> > players spend $0.05 per line of code.
> >
> > It is sheer folly for anyone to suggest that reliance on warnings and
> > errors, even extending this to notes, ensures good code.  At best, these
are
> > necessary to support development of good code, but they do not come
close
> to
> > being sufficient.  it is trivial to find examples of C code, for
computing a
> > mean, variance and standard deviation, that is correct both WRT the ANSI
> > standard and the compiler, and yet it is really bad code (look for
single
> > pass algorithms, and you'll find one of the most commonly recommended
> > algorithms is also one of the worst, In terms of accuracy under some
inputs,
> > and yet an infrequently recommended algorithm is one of the best both in
> > terms of ease of implementation, speed and accuracy).  And you will
still
> > find good mathematicians defending the bad code by saying it is
> > mathematically correct, but this is because they do not understand the
> > consequences of finite precision arithmetic and rounding error.
> >
> > I would observe, as an outsider, that what CRAN is apparently doing is
> > primarily focussed on the first issue above, but going beyond what the R
> > interpreter does to get a better handle on a system of warnings with an
> > extension to notes.  The notes question I can understand as a pragmatic
> > matter.  If I were assigned to do the same sort of thing, I would
probably
> > do it in a similar manner, leaving some things as notes until both I and
the
> > community I serve develop a better understanding of the issues involved
in
> > the subject of the notes to the point of being better able to either
have
> > them evolve into more precisely defined warnings or die.  I understand
that
> > getting many of these things can get tedious and time consuming, but in
fact
> > there is no other way for a community to analyse the issues involved and
> > develop a good understanding of how best to handle them.
> >
> > But since CRAN does not appear to require requirements engineering to be
> > completed along with a comprehensive suite of QA tests, there is no
possible
> > way they can offer any guarantees or even recommendations that any
> package
> > on CRAN is good quality.  From the current reaction to mere notes, I can
> > imagine the reaction that would arise should they ever decide to do so.
It
> > is very much up to the 'consumer' to search CRAN, and evaluate each
> > interesting package to ensure it works as advertised, and I have no
doubt
> > that some are gems while others are best avoided.
> >
> > Just my $0.02 ...
> >
> > Cheers
> >
> > Ted
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com


