From murdoch.duncan at gmail.com  Fri Sep  1 00:13:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 31 Aug 2017 18:13:42 -0400
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
Message-ID: <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>

On 31/08/2017 5:38 PM, Paul McQuesten wrote:
> The R signon banner includes this statement:
>       Natural language support but running in an English locale
> 
> Should that not say 'National' instead of 'Natural'?
> Meaning that LOCALE support is enabled, not that the interface understands
> human language?
> 

No, "natural language" refers to human languages, but it doesn't imply 
that R understands them.  NLS just means that messages may be presented 
in (or translated to) other human languages in an appropriate context.

For example, you can start R on most platforms from the console using

LANGUAGE=de R

and instead of the start message you saw, you'll see

R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu verbreiten.
Tippen Sie 'license()' or 'licence()' f?r Details dazu.

and so on.

> Please ignore this and forgive me if this is an inappropriate post. I am a
> N00B in R.

I don't think it is inappropriate.

Duncan Murdoch


From mcquesten at gmail.com  Fri Sep  1 01:48:12 2017
From: mcquesten at gmail.com (Paul McQuesten)
Date: Thu, 31 Aug 2017 18:48:12 -0500
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
 <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>
 <CAN6Gc-2WtBvhSMG2Z9p0X6pYea2vrCpozJ7gUjoBk39b8SS15w@mail.gmail.com>
 <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
Message-ID: <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>

Actually, I do agree with you about Microsoft.
But they have so many users that their terminology should not be ignored.

Here are a few more views:

https://www.ibm.com/support/knowledgecenter/ssw_aix_71/com.ibm.aix.performance/natl_lang_supp_locale_speed.htm
https://docs.oracle.com/cd/E23824_01/html/E26033/glmbx.html
http://support.sas.com/documentation/cdl/en/nlsref/69741/HTML/default/viewer.htm#n1n9bwctsthuqbn1xgipyw5xwujl.htm
https://docs.intersystems.com/latest/csp/docbook/DocBook.UI.Page.cls?KEY=GSA_config_nls
https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixprggd/genprogc/nls.htm
http://scc.ustc.edu.cn/zlsc/tc4600/intel/2017.0.098/compiler_f/common/core/GUID-1AEC889E-98A7-4A7D-91B3-865C476F603D.html

It does appear, however, that what I call 'National Language' is often
referred to as 'Native Language'. And the 'National Language' terminology
is said to not be used consistently:
https://en.wikipedia.org/wiki/National_language

I do still feel, however, that claiming 'Natural Language' support in R
sets expectations of new users overly high.

Thank you for spending so much time on such a minor nit.

Regards



On Thu, Aug 31, 2017 at 5:45 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 31/08/2017 6:37 PM, Paul McQuesten wrote:
>
>> Thanks, Duncan. But if it is not inappropriate, I feel empowered to argue.
>>
>> According to this definition, https://en.wikipedia.org/wiki/
>> Natural_language:
>>       In neuropsychology, linguistics and the philosophy of language, a
>> natural language or ordinary language is any language that has evolved
>> naturally in humans ...
>>
>> Thus this banner statement may appear over-claiming to a significant
>> fraction of R users.
>>
>> It seems that LOCALE is called 'National language' support in other
>> software systems.
>> Eg: https://www.microsoft.com/resources/msdn/goglobal/default.mspx
>>
>
> I wouldn't take Microsoft as an authority on this (or much of anything).
> They really are amazingly incompetent, considering how much money they earn.
>
> Duncan Murdoch
>
>
>> And, yes, this is a low priority issue. All of you have better things to
>> do.
>>
>> R is an extremely powerful and comprehensive software system.
>> Thank you all for that.
>> And I would like to clean one gnat from the windshield.
>>
>> I just wax pedantic at times.
>>
>> On Thu, Aug 31, 2017 at 5:13 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 31/08/2017 5:38 PM, Paul McQuesten wrote:
>>
>>         The R signon banner includes this statement:
>>                Natural language support but running in an English locale
>>
>>         Should that not say 'National' instead of 'Natural'?
>>         Meaning that LOCALE support is enabled, not that the interface
>>         understands
>>         human language?
>>
>>
>>     No, "natural language" refers to human languages, but it doesn't
>>     imply that R understands them.  NLS just means that messages may be
>>     presented in (or translated to) other human languages in an
>>     appropriate context.
>>
>>     For example, you can start R on most platforms from the console using
>>
>>     LANGUAGE=de R
>>
>>     and instead of the start message you saw, you'll see
>>
>>     R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
>>     Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu
>>     verbreiten.
>>     Tippen Sie 'license()' or 'licence()' f?r Details dazu.
>>
>>     and so on.
>>
>>         Please ignore this and forgive me if this is an inappropriate
>>         post. I am a
>>         N00B in R.
>>
>>
>>     I don't think it is inappropriate.
>>
>>     Duncan Murdoch
>>
>>
>>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Sep  1 09:25:28 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Sep 2017 09:25:28 +0200
Subject: [Rd] I have corrected a dead link in the treering documentation
In-Reply-To: <20170728185317.E246C7E65E@mailuser.nyi.internal>
References: <20170728185317.E246C7E65E@mailuser.nyi.internal>
Message-ID: <22953.2920.615673.556828@stat.math.ethz.ch>

>>>>> Thomas Levine <_ at thomaslevine.com>
>>>>>     on Fri, 28 Jul 2017 18:53:16 +0000 writes:

    > The attached patch corrects a dead link in the treering
    > documentation.  The URL in the manual [1] refers to a
    > personal home page belonging to Christine Hallman (user
    > "hallman") on the website of the University of Arizona
    > Laboratory of Tree-Ring Research (LTRR). It seems that the
    > LTRR personal homepages have been moved to a new root
    > directory [2] and that Hallman's webpage is no longer
    > there.

    > I have contacted Dr. Hallman. She confirmed that the LTRR
    > hosting has changed and that she has not set up her
    > website on a new host. Also, I have not managed to find
    > any other photographs of the Methuselah Walk.  So the page
    > on the Wayback Machine [3] is the best option I see for
    > now.

    > Dr. Hallman also told me that she has more photographs of
    > the tree, and she has offered to publish them in order
    > that we may reference more photographs eventually.

Dear Thomas,
thank you very much for your careful work about this.
I'm sorry it took so long before anyone reacted to this - and so
thank you as well for the reminder.

 [..........]
 
The web.archive.org  aka Wayback Machine aka Internet Archive
URL does work and your patch is formally fine.

There may be one small problem:  IIUC, the wayback machine is a
+- private endeavor and really great and phantastic but it does
need (US? tax deductible) donations, https://archive.org/donate/,
to continue thriving.
This makes me hesitate a bit to link to it within the "base R"
documentation.  But that may be wrong -- and I should really use
it to *help* the project ?

    > I found other dead links in the base documentation, but I thought most
    > should be kept for reference, as they were usually links to a
    > publisher's webpage for a particular journal article or book. The link
    > of present interest just provides context about the tree whose rings
    > were measured, so I think it is okay to change the link.

    > [1] http://www.ltrr.arizona.edu/~hallman/sitephotos/meth.html
    > [2] http://www.ltrr.arizona.edu/webhome/
    > [3] https://web.archive.org/web/20110523225828/http://www.ltrr.arizona.edu/~hallman/sitephotos/meth.html

    > ----------------------------------------------------------------------
    > Index: src/library/datasets/man/treering.Rd
    > ===================================================================
    > --- src/library/datasets/man/treering.Rd	(revision 72947)
    > +++ src/library/datasets/man/treering.Rd	(working copy)
    > @@ -32,6 +32,6 @@
    > }
    > \references{
    > For some photos of Methuselah Walk see
    > -  \url{http://www.ltrr.arizona.edu/~hallman/sitephotos/meth.html}
    > +  \url{https://web.archive.org/web/20110523225828/http://www.ltrr.arizona.edu/~hallman/sitephotos/meth.html}
    > }
    > \keyword{datasets}


From maechler at stat.math.ethz.ch  Fri Sep  1 09:37:42 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Sep 2017 09:37:42 +0200
Subject: [Rd] Missing y label
In-Reply-To: <9153c6$7s2gdm@ironport10.mayo.edu>
References: <9153c6$7s2gdm@ironport10.mayo.edu>
Message-ID: <22953.3654.62340.915319@stat.math.ethz.ch>

>>>>> Therneau, Terry M , Ph D <therneau at mayo.edu>
>>>>>     on Thu, 31 Aug 2017 16:08:24 -0500 writes:

    > My on-screen plots with the latest build are acting
    > strange.  If the y label is longer than some small value it is not shown.

[MM: moved the important part of the script up here:]

    plot(1:5, 1:5, ylab="abcde")  # has a y label

    plot(1:5, 1:5, ylab="abcdefghi")  # no label

That is amazing.
I don't see a problem here (Linux Fedora F24, or F26, in both
case using GNOME as windowing system),
also with this, both interactive or pdf :

plot(1:5, 1:5, ylab="abcdefghi or even quite an order of magnitude longer")

pdf("long-ylab.pdf")
plot(1:5, 1:5, ylab="abcdefghi or even quite an order of magnitude longer")
dev.off(); system("evince long-ylab.pdf &")

I have no further idea but guess this must be specific to your platform.

Did you try the same thing with R 3.4.1?
Did you install both in the same way -- from the sources ??

Best,
Martin


    > Here is the script of a job.  A pdf graph is fine.  I use xubuntu as the windowing system.


    > tmt-local1334% R --vanilla

    > R Under development (unstable) (2017-08-31 r73172) -- "Unsuffered Consequences"
    > Copyright (C) 2017 The R Foundation for Statistical Computing
    > Platform: x86_64-pc-linux-gnu (64-bit)

    [.........]
    >> sessionInfo()
    > R Under development (unstable) (2017-08-31 r73172)
    > Platform: x86_64-pc-linux-gnu (64-bit)
    > Running under: Ubuntu 16.04.2 LTS

    > Matrix products: default
    > BLAS: /usr/local/src/R-devel/lib/libRblas.so
    > LAPACK: /usr/local/src/R-devel/lib/libRlapack.so

    > locale:
    > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
    > [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
    > [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
    > [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
    > [9] LC_ADDRESS=C               LC_TELEPHONE=C
    > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods base

    > loaded via a namespace (and not attached):
    > [1] compiler_3.5.0


From maechler at stat.math.ethz.ch  Fri Sep  1 09:45:38 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Sep 2017 09:45:38 +0200
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
 <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>
 <CAN6Gc-2WtBvhSMG2Z9p0X6pYea2vrCpozJ7gUjoBk39b8SS15w@mail.gmail.com>
 <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
 <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>
Message-ID: <22953.4130.656513.835219@stat.math.ethz.ch>

>>>>> Paul McQuesten <mcquesten at gmail.com>
>>>>>     on Thu, 31 Aug 2017 18:48:12 -0500 writes:

    > Actually, I do agree with you about Microsoft.
    > But they have so many users that their terminology should not be ignored.

    > Here are a few more views:

    > https://www.ibm.com/support/knowledgecenter/ssw_aix_71/com.ibm.aix.performance/natl_lang_supp_locale_speed.htm
    > https://docs.oracle.com/cd/E23824_01/html/E26033/glmbx.html
    > http://support.sas.com/documentation/cdl/en/nlsref/69741/HTML/default/viewer.htm#n1n9bwctsthuqbn1xgipyw5xwujl.htm
    > https://docs.intersystems.com/latest/csp/docbook/DocBook.UI.Page.cls?KEY=GSA_config_nls
    > https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixprggd/genprogc/nls.htm
    > http://scc.ustc.edu.cn/zlsc/tc4600/intel/2017.0.098/compiler_f/common/core/GUID-1AEC889E-98A7-4A7D-91B3-865C476F603D.html

    > It does appear, however, that what I call 'National Language' is often
    > referred to as 'Native Language'. And the 'National Language' terminology
    > is said to not be used consistently:
    > https://en.wikipedia.org/wiki/National_language

    > I do still feel, however, that claiming 'Natural Language' support in R
    > sets expectations of new users overly high.

    > Thank you for spending so much time on such a minor nit.

continuing the nits and gnats :

I think I now understand what you mean.  From the little I
understand about English intricacies and with my not
fully developed gut feeling of good English (which I rarely
speak but sometimes appreciate when reading / listening),
I would indeed

prefer  'Native Language'
to	'Natural Language'	

Martin Maechler
ETH Zurich

    > Regards



    > On Thu, Aug 31, 2017 at 5:45 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
    > wrote:

    >> On 31/08/2017 6:37 PM, Paul McQuesten wrote:
    >> 
    >>> Thanks, Duncan. But if it is not inappropriate, I feel empowered to argue.
    >>> 
    >>> According to this definition, https://en.wikipedia.org/wiki/
    >>> Natural_language:
    >>> In neuropsychology, linguistics and the philosophy of language, a
    >>> natural language or ordinary language is any language that has evolved
    >>> naturally in humans ...
    >>> 
    >>> Thus this banner statement may appear over-claiming to a significant
    >>> fraction of R users.
    >>> 
    >>> It seems that LOCALE is called 'National language' support in other
    >>> software systems.
    >>> Eg: https://www.microsoft.com/resources/msdn/goglobal/default.mspx
    >>> 
    >> 
    >> I wouldn't take Microsoft as an authority on this (or much of anything).
    >> They really are amazingly incompetent, considering how much money they earn.
    >> 
    >> Duncan Murdoch
    >> 
    >> 
    >>> And, yes, this is a low priority issue. All of you have better things to
    >>> do.
    >>> 
    >>> R is an extremely powerful and comprehensive software system.
    >>> Thank you all for that.
    >>> And I would like to clean one gnat from the windshield.
    >>> 
    >>> I just wax pedantic at times.
    >>> 
    >>> On Thu, Aug 31, 2017 at 5:13 PM, Duncan Murdoch <murdoch.duncan at gmail.com
    >>> <mailto:murdoch.duncan at gmail.com>> wrote:
    >>> 
    >>> On 31/08/2017 5:38 PM, Paul McQuesten wrote:
    >>> 
    >>> The R signon banner includes this statement:
    >>> Natural language support but running in an English locale
    >>> 
    >>> Should that not say 'National' instead of 'Natural'?
    >>> Meaning that LOCALE support is enabled, not that the interface
    >>> understands
    >>> human language?
    >>> 
    >>> 
    >>> No, "natural language" refers to human languages, but it doesn't
    >>> imply that R understands them.  NLS just means that messages may be
    >>> presented in (or translated to) other human languages in an
    >>> appropriate context.
    >>> 
    >>> For example, you can start R on most platforms from the console using
    >>> 
    >>> LANGUAGE=de R
    >>> 
    >>> and instead of the start message you saw, you'll see
    >>> 
    >>> R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
    >>> Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu
    >>> verbreiten.
    >>> Tippen Sie 'license()' or 'licence()' f?r Details dazu.
    >>> 
    >>> and so on.
    >>> 
    >>> Please ignore this and forgive me if this is an inappropriate
    >>> post. I am a
    >>> N00B in R.
    >>> 
    >>> 
    >>> I don't think it is inappropriate.
    >>> 
    >>> Duncan Murdoch


From r_goertz at web.de  Fri Sep  1 10:23:21 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Fri, 1 Sep 2017 10:23:21 +0200
Subject: [Rd] patch: automatically adjust width option when terminal is
 resized
In-Reply-To: <20170828093331.39607d5b@delligoertz.fritz.box>
References: <20170828093331.39607d5b@delligoertz.fritz.box>
Message-ID: <20170901102321.6921e48a@delligoertz.fritz.box>

Am Mon, 28 Aug 2017 09:33:31 +0200
schrieb Ralf Goertz <r_goertz at web.de>:


Hello, me again

> Hi,
> 
> I guess there have been discussions about this in the past and from
> what I understood hooking an R-function to facilitate automatic
> adjustment is problematic. So why not doing it like this:

would anybody care to comment? I think it is quite important to have an
automatic adjustment of R's idea of the width of its terminal window. I
quite often find myself in the situation that I started R in its own
(wide) xterm. Then I look at some data frame or vector like this (using
small width here in order to stay within the ususal width of a text
posting):

> (r=rnorm(20))
 [1]  0.05672115  0.59047528  0.41337747  0.01737960 -0.78133482
 [6]  0.49218494 -0.78793312 -1.26125820  0.56748784  0.65725277
[11] -0.04419487  0.14463142 -0.48613097  0.42789592  1.22424913
[16]  0.43272842 -0.70089673  0.14313221 -0.97159181 -1.29164930


Then I want to plot something

> hist(r)

Because the plot window and the xterm don't fit side by side I resize
the xterm to be smaller. Then I want to see the data again:

> r
 [1]  0.05672115  0.59047528  0.41337747  0.01737960 -
0.78133482
 [6]  0.49218494 -0.78793312 -1.26125820  0.56748784  
0.65725277
[11] -0.04419487  0.14463142 -0.48613097  0.42789592  
1.22424913
[16]  0.43272842 -0.70089673  0.14313221 -0.97159181 -
1.29164930

This is ugly and hard to read. Many good programs like vim adjust their
internal width representation automatically. Why shouldn't R do the
same? It seems quite easy, at least when readline is used:

 
--- R-3.4.1/src/unix/sys-std.c  2017-03-24 00:03:59.000000000 +0100
+++ R-3.4.1/src/unix/sys-std.patched.c  2017-08-28 09:16:02.714204023
+0200 @@ -1005,6 +1005,9 @@
                // introduced in readline 4.0: only used for >= 6.3
 #ifdef HAVE_RL_RESIZE_TERMINAL
                rl_resize_terminal();
+               int rl_height, rl_width;
+               rl_get_screen_size(&rl_height,&rl_width);
+               R_SetOptionWidth(rl_width);
 #endif
             }
 #endif

> I tried it out and it works perfectly here. Of course there should be
> an option to switch this on and off but you get the idea. What do you
> think?

It would be much appreciated if you considered it.

Thanks Ralf


From pdalgd at gmail.com  Fri Sep  1 10:59:42 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Fri, 1 Sep 2017 10:59:42 +0200
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <22953.4130.656513.835219@stat.math.ethz.ch>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
 <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>
 <CAN6Gc-2WtBvhSMG2Z9p0X6pYea2vrCpozJ7gUjoBk39b8SS15w@mail.gmail.com>
 <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
 <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>
 <22953.4130.656513.835219@stat.math.ethz.ch>
Message-ID: <95DB024B-D5A4-4F00-BBBC-CD998FF32E4D@gmail.com>

Just leave it, I think. Some nations have 4 national languages (as Martin will know), some languages are not national, and adopted children often do not speak their native (=born) language... I suspect someone already put a substantial amount of thought into the terminology.

-pd


> On 1 Sep 2017, at 09:45 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Paul McQuesten <mcquesten at gmail.com>
>>>>>>    on Thu, 31 Aug 2017 18:48:12 -0500 writes:
> 
>> Actually, I do agree with you about Microsoft.
>> But they have so many users that their terminology should not be ignored.
> 
>> Here are a few more views:
> 
>> https://www.ibm.com/support/knowledgecenter/ssw_aix_71/com.ibm.aix.performance/natl_lang_supp_locale_speed.htm
>> https://docs.oracle.com/cd/E23824_01/html/E26033/glmbx.html
>> http://support.sas.com/documentation/cdl/en/nlsref/69741/HTML/default/viewer.htm#n1n9bwctsthuqbn1xgipyw5xwujl.htm
>> https://docs.intersystems.com/latest/csp/docbook/DocBook.UI.Page.cls?KEY=GSA_config_nls
>> https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixprggd/genprogc/nls.htm
>> http://scc.ustc.edu.cn/zlsc/tc4600/intel/2017.0.098/compiler_f/common/core/GUID-1AEC889E-98A7-4A7D-91B3-865C476F603D.html
> 
>> It does appear, however, that what I call 'National Language' is often
>> referred to as 'Native Language'. And the 'National Language' terminology
>> is said to not be used consistently:
>> https://en.wikipedia.org/wiki/National_language
> 
>> I do still feel, however, that claiming 'Natural Language' support in R
>> sets expectations of new users overly high.
> 
>> Thank you for spending so much time on such a minor nit.
> 
> continuing the nits and gnats :
> 
> I think I now understand what you mean.  From the little I
> understand about English intricacies and with my not
> fully developed gut feeling of good English (which I rarely
> speak but sometimes appreciate when reading / listening),
> I would indeed
> 
> prefer  'Native Language'
> to	'Natural Language'	
> 
> Martin Maechler
> ETH Zurich
> 
>> Regards
> 
> 
> 
>> On Thu, Aug 31, 2017 at 5:45 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
> 
>>> On 31/08/2017 6:37 PM, Paul McQuesten wrote:
>>> 
>>>> Thanks, Duncan. But if it is not inappropriate, I feel empowered to argue.
>>>> 
>>>> According to this definition, https://en.wikipedia.org/wiki/
>>>> Natural_language:
>>>> In neuropsychology, linguistics and the philosophy of language, a
>>>> natural language or ordinary language is any language that has evolved
>>>> naturally in humans ...
>>>> 
>>>> Thus this banner statement may appear over-claiming to a significant
>>>> fraction of R users.
>>>> 
>>>> It seems that LOCALE is called 'National language' support in other
>>>> software systems.
>>>> Eg: https://www.microsoft.com/resources/msdn/goglobal/default.mspx
>>>> 
>>> 
>>> I wouldn't take Microsoft as an authority on this (or much of anything).
>>> They really are amazingly incompetent, considering how much money they earn.
>>> 
>>> Duncan Murdoch
>>> 
>>> 
>>>> And, yes, this is a low priority issue. All of you have better things to
>>>> do.
>>>> 
>>>> R is an extremely powerful and comprehensive software system.
>>>> Thank you all for that.
>>>> And I would like to clean one gnat from the windshield.
>>>> 
>>>> I just wax pedantic at times.
>>>> 
>>>> On Thu, Aug 31, 2017 at 5:13 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>>>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>>> 
>>>> On 31/08/2017 5:38 PM, Paul McQuesten wrote:
>>>> 
>>>> The R signon banner includes this statement:
>>>> Natural language support but running in an English locale
>>>> 
>>>> Should that not say 'National' instead of 'Natural'?
>>>> Meaning that LOCALE support is enabled, not that the interface
>>>> understands
>>>> human language?
>>>> 
>>>> 
>>>> No, "natural language" refers to human languages, but it doesn't
>>>> imply that R understands them.  NLS just means that messages may be
>>>> presented in (or translated to) other human languages in an
>>>> appropriate context.
>>>> 
>>>> For example, you can start R on most platforms from the console using
>>>> 
>>>> LANGUAGE=de R
>>>> 
>>>> and instead of the start message you saw, you'll see
>>>> 
>>>> R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
>>>> Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu
>>>> verbreiten.
>>>> Tippen Sie 'license()' or 'licence()' f?r Details dazu.
>>>> 
>>>> and so on.
>>>> 
>>>> Please ignore this and forgive me if this is an inappropriate
>>>> post. I am a
>>>> N00B in R.
>>>> 
>>>> 
>>>> I don't think it is inappropriate.
>>>> 
>>>> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mark.vanderloo at gmail.com  Fri Sep  1 11:17:08 2017
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Fri, 01 Sep 2017 09:17:08 +0000
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <95DB024B-D5A4-4F00-BBBC-CD998FF32E4D@gmail.com>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
 <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>
 <CAN6Gc-2WtBvhSMG2Z9p0X6pYea2vrCpozJ7gUjoBk39b8SS15w@mail.gmail.com>
 <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
 <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>
 <22953.4130.656513.835219@stat.math.ethz.ch>
 <95DB024B-D5A4-4F00-BBBC-CD998FF32E4D@gmail.com>
Message-ID: <CAOKDuOiiShpCWB_DRqB_fpUnwAhGo4x6Yd63V=+vUy85XhN_CQ@mail.gmail.com>

The way it's phrased now makes it seem that English is not a Natural
language ("Natural language support *but* running in an English locale").
Why not just state: "running in an English locale" and leave it with that?
Better to leave something out than to be unclear (being correct formally
does not always mean being clear to all users).
-M

Op vr 1 sep. 2017 om 11:00 schreef Peter Dalgaard <pdalgd at gmail.com>:

> Just leave it, I think. Some nations have 4 national languages (as Martin
> will know), some languages are not national, and adopted children often do
> not speak their native (=born) language... I suspect someone already put a
> substantial amount of thought into the terminology.
>
> -pd
>
>
> > On 1 Sep 2017, at 09:45 , Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
> >
> >>>>>> Paul McQuesten <mcquesten at gmail.com>
> >>>>>>    on Thu, 31 Aug 2017 18:48:12 -0500 writes:
> >
> >> Actually, I do agree with you about Microsoft.
> >> But they have so many users that their terminology should not be
> ignored.
> >
> >> Here are a few more views:
> >
> >>
> https://www.ibm.com/support/knowledgecenter/ssw_aix_71/com.ibm.aix.performance/natl_lang_supp_locale_speed.htm
> >> https://docs.oracle.com/cd/E23824_01/html/E26033/glmbx.html
> >>
> http://support.sas.com/documentation/cdl/en/nlsref/69741/HTML/default/viewer.htm#n1n9bwctsthuqbn1xgipyw5xwujl.htm
> >>
> https://docs.intersystems.com/latest/csp/docbook/DocBook.UI.Page.cls?KEY=GSA_config_nls
> >>
> https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixprggd/genprogc/nls.htm
> >>
> http://scc.ustc.edu.cn/zlsc/tc4600/intel/2017.0.098/compiler_f/common/core/GUID-1AEC889E-98A7-4A7D-91B3-865C476F603D.html
> >
> >> It does appear, however, that what I call 'National Language' is often
> >> referred to as 'Native Language'. And the 'National Language'
> terminology
> >> is said to not be used consistently:
> >> https://en.wikipedia.org/wiki/National_language
> >
> >> I do still feel, however, that claiming 'Natural Language' support in R
> >> sets expectations of new users overly high.
> >
> >> Thank you for spending so much time on such a minor nit.
> >
> > continuing the nits and gnats :
> >
> > I think I now understand what you mean.  From the little I
> > understand about English intricacies and with my not
> > fully developed gut feeling of good English (which I rarely
> > speak but sometimes appreciate when reading / listening),
> > I would indeed
> >
> > prefer  'Native Language'
> > to    'Natural Language'
> >
> > Martin Maechler
> > ETH Zurich
> >
> >> Regards
> >
> >
> >
> >> On Thu, Aug 31, 2017 at 5:45 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> >> wrote:
> >
> >>> On 31/08/2017 6:37 PM, Paul McQuesten wrote:
> >>>
> >>>> Thanks, Duncan. But if it is not inappropriate, I feel empowered to
> argue.
> >>>>
> >>>> According to this definition, https://en.wikipedia.org/wiki/
> >>>> Natural_language:
> >>>> In neuropsychology, linguistics and the philosophy of language, a
> >>>> natural language or ordinary language is any language that has evolved
> >>>> naturally in humans ...
> >>>>
> >>>> Thus this banner statement may appear over-claiming to a significant
> >>>> fraction of R users.
> >>>>
> >>>> It seems that LOCALE is called 'National language' support in other
> >>>> software systems.
> >>>> Eg: https://www.microsoft.com/resources/msdn/goglobal/default.mspx
> >>>>
> >>>
> >>> I wouldn't take Microsoft as an authority on this (or much of
> anything).
> >>> They really are amazingly incompetent, considering how much money they
> earn.
> >>>
> >>> Duncan Murdoch
> >>>
> >>>
> >>>> And, yes, this is a low priority issue. All of you have better things
> to
> >>>> do.
> >>>>
> >>>> R is an extremely powerful and comprehensive software system.
> >>>> Thank you all for that.
> >>>> And I would like to clean one gnat from the windshield.
> >>>>
> >>>> I just wax pedantic at times.
> >>>>
> >>>> On Thu, Aug 31, 2017 at 5:13 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com
> >>>> <mailto:murdoch.duncan at gmail.com>> wrote:
> >>>>
> >>>> On 31/08/2017 5:38 PM, Paul McQuesten wrote:
> >>>>
> >>>> The R signon banner includes this statement:
> >>>> Natural language support but running in an English locale
> >>>>
> >>>> Should that not say 'National' instead of 'Natural'?
> >>>> Meaning that LOCALE support is enabled, not that the interface
> >>>> understands
> >>>> human language?
> >>>>
> >>>>
> >>>> No, "natural language" refers to human languages, but it doesn't
> >>>> imply that R understands them.  NLS just means that messages may be
> >>>> presented in (or translated to) other human languages in an
> >>>> appropriate context.
> >>>>
> >>>> For example, you can start R on most platforms from the console using
> >>>>
> >>>> LANGUAGE=de R
> >>>>
> >>>> and instead of the start message you saw, you'll see
> >>>>
> >>>> R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
> >>>> Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu
> >>>> verbreiten.
> >>>> Tippen Sie 'license()' or 'licence()' f?r Details dazu.
> >>>>
> >>>> and so on.
> >>>>
> >>>> Please ignore this and forgive me if this is an inappropriate
> >>>> post. I am a
> >>>> N00B in R.
> >>>>
> >>>>
> >>>> I don't think it is inappropriate.
> >>>>
> >>>> Duncan Murdoch
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501 <+45%2038%2015%2035%2001>
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From simon.barthelme at gipsa-lab.fr  Fri Sep  1 12:57:13 2017
From: simon.barthelme at gipsa-lab.fr (=?UTF-8?Q?Simon_Barthelm=c3=a9?=)
Date: Fri, 1 Sep 2017 12:57:13 +0200
Subject: [Rd] side-effect of calling functions via `::`
Message-ID: <59A93D09.8010006@gipsa-lab.fr>

Dear list

I'm not sure whether this is a bug or an unavoidable consequence of the 
way packages are loaded, but there can be surprising side effects of 
calling a function via package::function. Here's an example using the 
formula.tools package:

form <- a ~ b
as.character(form)
formula.tools::lhs(form)
as.character(form)

The first call to as.character returns:
[1] "~" "a" "b"
The second returns:
[1] "a ~ b"

The reason being that formula.tools has:
S3method(as.character,formula)
in its namespace, which quietly supersedes the default one. In my case 
it led to a bug that was rather hard to track down because it looked 
like non-deterministic behaviour.
Shouldn't there at least be a warning about such side effects, the way 
library() tells you about masking?

Best

Simon Barthelme


From lionel at rstudio.com  Fri Sep  1 13:47:07 2017
From: lionel at rstudio.com (Lionel Henry)
Date: Fri, 1 Sep 2017 13:47:07 +0200
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <59A93D09.8010006@gipsa-lab.fr>
References: <59A93D09.8010006@gipsa-lab.fr>
Message-ID: <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>

A package should probably never register a S3 method unless it owns
either the generic or the class. Here `formula.tools` owns neither.
Instead of registering the method, it should export it like a regular
function. This way S3 dispatch is based on lexical scoping rather than
session-wide side effect.

Lionel

> On 1 sept. 2017, at 12:57, Simon Barthelm? <simon.barthelme at gipsa-lab.fr> wrote:
> 
> Dear list
> 
> I'm not sure whether this is a bug or an unavoidable consequence of the way packages are loaded, but there can be surprising side effects of calling a function via package::function. Here's an example using the formula.tools package:
> 
> form <- a ~ b
> as.character(form)
> formula.tools::lhs(form)
> as.character(form)
> 
> The first call to as.character returns:
> [1] "~" "a" "b"
> The second returns:
> [1] "a ~ b"
> 
> The reason being that formula.tools has:
> S3method(as.character,formula)
> in its namespace, which quietly supersedes the default one. In my case it led to a bug that was rather hard to track down because it looked like non-deterministic behaviour.
> Shouldn't there at least be a warning about such side effects, the way library() tells you about masking?
> 
> Best
> 
> Simon Barthelme
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Sep  1 13:55:23 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Sep 2017 13:55:23 +0200
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <59A93D09.8010006@gipsa-lab.fr>
References: <59A93D09.8010006@gipsa-lab.fr>
Message-ID: <22953.19115.608794.137332@stat.math.ethz.ch>

>>>>> Simon Barthelm? <simon.barthelme at gipsa-lab.fr>
>>>>>     on Fri, 1 Sep 2017 12:57:13 +0200 writes:

    > Dear list
    > I'm not sure whether this is a bug or an unavoidable consequence of the 
    > way packages are loaded, but there can be surprising side effects of 
    > calling a function via package::function. Here's an example using the 
    > formula.tools package:

    > form <- a ~ b
    > as.character(form)
    > formula.tools::lhs(form)
    > as.character(form)

    > The first call to as.character returns:
    > [1] "~" "a" "b"
    > The second returns:
    > [1] "a ~ b"

    > The reason being that formula.tools has:
    > S3method(as.character,formula)
    > in its namespace, which quietly supersedes the default one. 

Sure. 

    > In my case it led to a bug that was rather hard to track
    > down because it looked like non-deterministic behaviour.

well, it shouldn't have been hard to track I think ... see below

    > Shouldn't there at least be a warning about such side effects, the way 
    > library() tells you about masking?

The help page on  "::"  is pretty clear about the fact that the
namespace is loaded if necessary.

Personally I've got the impression that  <namespace>::<name>  is
much "overused" nowadays, notably in packages where I'd strongly
advocate using  importFrom() in NAMESPACE, so all this happens
at package load time, and then _not_ using `::` in the package
sources itself.

Many people seem to forget that every use of `::` is an R
function call and using it is ineffecient compared to just using
the already imported name.

Best,
Martin Maechler
ETH Zurich and R Core Team

    > Best
    > Simon Barthelme


From maechler at stat.math.ethz.ch  Fri Sep  1 14:03:22 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 Sep 2017 14:03:22 +0200
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
References: <59A93D09.8010006@gipsa-lab.fr>
 <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
Message-ID: <22953.19594.227858.248280@stat.math.ethz.ch>

>>>>> Lionel Henry <lionel at rstudio.com>
>>>>>     on Fri, 1 Sep 2017 13:47:07 +0200 writes:

    > A package should probably never register a S3 method unless it owns
    > either the generic or the class.

I agree... (and typically it does "own" the class)

    > Here `formula.tools` owns neither.

i.e., it neither defines as.character() nor class "formula".

    > Instead of registering the method, it should export it like a regular
    > function. This way S3 dispatch is based on lexical scoping rather than
    > session-wide side effect.

I don't the 2nd sentence above is quite correct.  S3 method
registration should be done (in the case it should) and S3
dispatch is not just based on lexical scoping but also on S3
method registration.

    > Lionel

It is still the case that :: silently loads the namespace if
needed, and that "things may behave differently" after the use '::', because
loading a namespace does have an effect on the R session ...,
(and I still think  `::`  is much  "over used")

Martin



    >> On 1 sept. 2017, at 12:57, Simon Barthelm? <simon.barthelme at gipsa-lab.fr> wrote:
    >> 
    >> Dear list
    >> 
    >> I'm not sure whether this is a bug or an unavoidable consequence of the way packages are loaded, but there can be surprising side effects of calling a function via package::function. Here's an example using the formula.tools package:
    >> 
    >> form <- a ~ b
    >> as.character(form)
    >> formula.tools::lhs(form)
    >> as.character(form)
    >> 
    >> The first call to as.character returns:
    >> [1] "~" "a" "b"
    >> The second returns:
    >> [1] "a ~ b"
    >> 
    >> The reason being that formula.tools has:
    >> S3method(as.character,formula)
    >> in its namespace, which quietly supersedes the default one. In my case it led to a bug that was rather hard to track down because it looked like non-deterministic behaviour.
    >> Shouldn't there at least be a warning about such side effects, the way library() tells you about masking?
    >> 
    >> Best
    >> 
    >> Simon Barthelme
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Fri Sep  1 14:20:58 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 1 Sep 2017 07:20:58 -0500 (CDT)
Subject: [Rd] patch: automatically adjust width option when terminal is
 resized
In-Reply-To: <20170901102321.6921e48a@delligoertz.fritz.box>
References: <20170828093331.39607d5b@delligoertz.fritz.box>
 <20170901102321.6921e48a@delligoertz.fritz.box>
Message-ID: <alpine.DEB.2.20.1709010710340.2718@luke-Latitude>

On Fri, 1 Sep 2017, Ralf Goertz wrote:

> Am Mon, 28 Aug 2017 09:33:31 +0200
> schrieb Ralf Goertz <r_goertz at web.de>:
>
>
> Hello, me again
>
>> Hi,
>>
>> I guess there have been discussions about this in the past and from
>> what I understood hooking an R-function to facilitate automatic
>> adjustment is problematic. So why not doing it like this:
>
> would anybody care to comment? I think it is quite important to have an
> automatic adjustment of R's idea of the width of its terminal window. I
> quite often find myself in the situation that I started R in its own
> (wide) xterm. Then I look at some data frame or vector like this (using
> small width here in order to stay within the ususal width of a text
> posting):
>
>> (r=rnorm(20))
> [1]  0.05672115  0.59047528  0.41337747  0.01737960 -0.78133482
> [6]  0.49218494 -0.78793312 -1.26125820  0.56748784  0.65725277
> [11] -0.04419487  0.14463142 -0.48613097  0.42789592  1.22424913
> [16]  0.43272842 -0.70089673  0.14313221 -0.97159181 -1.29164930
>
>
> Then I want to plot something
>
>> hist(r)
>
> Because the plot window and the xterm don't fit side by side I resize
> the xterm to be smaller. Then I want to see the data again:
>
>> r
> [1]  0.05672115  0.59047528  0.41337747  0.01737960 -
> 0.78133482
> [6]  0.49218494 -0.78793312 -1.26125820  0.56748784
> 0.65725277
> [11] -0.04419487  0.14463142 -0.48613097  0.42789592
> 1.22424913
> [16]  0.43272842 -0.70089673  0.14313221 -0.97159181 -
> 1.29164930
>
> This is ugly and hard to read. Many good programs like vim adjust their
> internal width representation automatically. Why shouldn't R do the
> same? It seems quite easy, at least when readline is used:
>
>
> --- R-3.4.1/src/unix/sys-std.c  2017-03-24 00:03:59.000000000 +0100
> +++ R-3.4.1/src/unix/sys-std.patched.c  2017-08-28 09:16:02.714204023
> +0200 @@ -1005,6 +1005,9 @@
>                // introduced in readline 4.0: only used for >= 6.3
> #ifdef HAVE_RL_RESIZE_TERMINAL
>                rl_resize_terminal();
> +               int rl_height, rl_width;
> +               rl_get_screen_size(&rl_height,&rl_width);
> +               R_SetOptionWidth(rl_width);
> #endif
>             }
> #endif

The 'width' option affects more than printing to the console; it also
affects, for example, printing to a file via sink() or
capture.output(). So doing this unconditionally would not be a good
idea.  Making it available as an option for those who want it seems
reasonable but still involves a lot more work than these three lines.
It requires designing a protocol for enabling this feature, ideally in
a way that can be made to work well on other interfaces (e.g. Windows,
Mac, RStudio) as well, and it requires documenting all this in a
sensible place. A more complete proposal might well be considered for
adoption.

Best,

luke

>
>> I tried it out and it works perfectly here. Of course there should be
>> an option to switch this on and off but you get the idea. What do you
>> think?
>
> It would be much appreciated if you considered it.
>
> Thanks Ralf
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From simon.urbanek at R-project.org  Fri Sep  1 14:49:22 2017
From: simon.urbanek at R-project.org (Simon Urbanek)
Date: Fri, 1 Sep 2017 08:49:22 -0400
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <22953.19594.227858.248280@stat.math.ethz.ch>
References: <59A93D09.8010006@gipsa-lab.fr>
 <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
 <22953.19594.227858.248280@stat.math.ethz.ch>
Message-ID: <C8A28464-1347-45D7-9DCB-1C8E8F008855@R-project.org>

Really, we have three levels of behavior related to dispatch: not loaded, loaded and attached. The loaded state is the most fragile - it does change some behavior (like the one below) but not others (when the package defines a new version of a generic). So it is true that the dispatch is the most problematic, in some sense you'd want it to be local to the package code when the package is not attached, but that's not supported in R as it is now.

Martin, re :: - I strongly disagree, semantically I find :: much cleaner than imports because you know exactly which function you call at all times and you don't pollute you package unnecessarily. It is unfortunate that the construct is inefficient in R, but that's an implementation problem, it shouldn't be because in fact it's immediately clear which symbol is meant. I believe the compiler should be able to fix that so in principle it shouldn't make a difference performance wise.

Cheers,
Simon


> On Sep 1, 2017, at 8:03 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Lionel Henry <lionel at rstudio.com>
>>>>>>   on Fri, 1 Sep 2017 13:47:07 +0200 writes:
> 
>> A package should probably never register a S3 method unless it owns
>> either the generic or the class.
> 
> I agree... (and typically it does "own" the class)
> 
>> Here `formula.tools` owns neither.
> 
> i.e., it neither defines as.character() nor class "formula".
> 
>> Instead of registering the method, it should export it like a regular
>> function. This way S3 dispatch is based on lexical scoping rather than
>> session-wide side effect.
> 
> I don't the 2nd sentence above is quite correct.  S3 method
> registration should be done (in the case it should) and S3
> dispatch is not just based on lexical scoping but also on S3
> method registration.
> 
>> Lionel
> 
> It is still the case that :: silently loads the namespace if
> needed, and that "things may behave differently" after the use '::', because
> loading a namespace does have an effect on the R session ...,
> (and I still think  `::`  is much  "over used")
> 
> Martin
> 
> 
> 
>>> On 1 sept. 2017, at 12:57, Simon Barthelm? <simon.barthelme at gipsa-lab.fr> wrote:
>>> 
>>> Dear list
>>> 
>>> I'm not sure whether this is a bug or an unavoidable consequence of the way packages are loaded, but there can be surprising side effects of calling a function via package::function. Here's an example using the formula.tools package:
>>> 
>>> form <- a ~ b
>>> as.character(form)
>>> formula.tools::lhs(form)
>>> as.character(form)
>>> 
>>> The first call to as.character returns:
>>> [1] "~" "a" "b"
>>> The second returns:
>>> [1] "a ~ b"
>>> 
>>> The reason being that formula.tools has:
>>> S3method(as.character,formula)
>>> in its namespace, which quietly supersedes the default one. In my case it led to a bug that was rather hard to track down because it looked like non-deterministic behaviour.
>>> Shouldn't there at least be a warning about such side effects, the way library() tells you about masking?
>>> 
>>> Best
>>> 
>>> Simon Barthelme
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From r at dune.urbanek.info  Fri Sep  1 14:47:59 2017
From: r at dune.urbanek.info (Simon Urbanek)
Date: Fri, 1 Sep 2017 08:47:59 -0400
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <22953.19594.227858.248280@stat.math.ethz.ch>
References: <59A93D09.8010006@gipsa-lab.fr>
 <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
 <22953.19594.227858.248280@stat.math.ethz.ch>
Message-ID: <4FDACBA0-F54E-406E-908C-0B4277697702@dune.urbanek.info>

Really, we have three levels of behavior related to dispatch: not loaded, loaded and attached. The loaded state is the most fragile - it does change some behavior (like the one below) but not others (when the package defines a new version of a generic). So it is true that the dispatch is the most problematic, in some sense you'd want it to be local to the package code when the package is not attached, but that's not supported in R as it is now.

Martin, re :: - I strongly disagree, semantically I find :: much cleaner than imports because you know exactly which function you call at all times and you don't pollute you package unnecessarily. It is unfortunate that the construct is inefficient in R, but that's an implementation problem, it shouldn't be because in fact it's immediately clear which symbol is meant. I believe the compiler should be able to fix that so in principle it shouldn't make a difference performance wise.

Cheers,
Simon


> On Sep 1, 2017, at 8:03 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Lionel Henry <lionel at rstudio.com>
>>>>>>    on Fri, 1 Sep 2017 13:47:07 +0200 writes:
> 
>> A package should probably never register a S3 method unless it owns
>> either the generic or the class.
> 
> I agree... (and typically it does "own" the class)
> 
>> Here `formula.tools` owns neither.
> 
> i.e., it neither defines as.character() nor class "formula".
> 
>> Instead of registering the method, it should export it like a regular
>> function. This way S3 dispatch is based on lexical scoping rather than
>> session-wide side effect.
> 
> I don't the 2nd sentence above is quite correct.  S3 method
> registration should be done (in the case it should) and S3
> dispatch is not just based on lexical scoping but also on S3
> method registration.
> 
>> Lionel
> 
> It is still the case that :: silently loads the namespace if
> needed, and that "things may behave differently" after the use '::', because
> loading a namespace does have an effect on the R session ...,
> (and I still think  `::`  is much  "over used")
> 
> Martin
> 
> 
> 
>>> On 1 sept. 2017, at 12:57, Simon Barthelm? <simon.barthelme at gipsa-lab.fr> wrote:
>>> 
>>> Dear list
>>> 
>>> I'm not sure whether this is a bug or an unavoidable consequence of the way packages are loaded, but there can be surprising side effects of calling a function via package::function. Here's an example using the formula.tools package:
>>> 
>>> form <- a ~ b
>>> as.character(form)
>>> formula.tools::lhs(form)
>>> as.character(form)
>>> 
>>> The first call to as.character returns:
>>> [1] "~" "a" "b"
>>> The second returns:
>>> [1] "a ~ b"
>>> 
>>> The reason being that formula.tools has:
>>> S3method(as.character,formula)
>>> in its namespace, which quietly supersedes the default one. In my case it led to a bug that was rather hard to track down because it looked like non-deterministic behaviour.
>>> Shouldn't there at least be a warning about such side effects, the way library() tells you about masking?
>>> 
>>> Best
>>> 
>>> Simon Barthelme
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From lionel at rstudio.com  Fri Sep  1 15:07:25 2017
From: lionel at rstudio.com (Lionel Henry)
Date: Fri, 1 Sep 2017 15:07:25 +0200
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <C8A28464-1347-45D7-9DCB-1C8E8F008855@R-project.org>
References: <59A93D09.8010006@gipsa-lab.fr>
 <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
 <22953.19594.227858.248280@stat.math.ethz.ch>
 <C8A28464-1347-45D7-9DCB-1C8E8F008855@R-project.org>
Message-ID: <E072B7FA-285B-4A48-B8C6-0C5D36341C60@rstudio.com>

> in some sense you'd want it to be local to the package code when the
> package is not attached, but that's not supported in R as it is now.

Lexically scoped methods work well (e.g. all methods in the base package)
but they are discouraged by a WARNING in R CMD check:

```
Found the following apparent S3 methods exported but not registered:
  as.character.formula
See section ?Registering S3 methods? in the ?Writing R Extensions?
manual.
```

I think that's too bad because they seem like a legitimate way of
providing encapsulated dispatch.

Lionel


> On 1 sept. 2017, at 14:49, Simon Urbanek <simon.urbanek at R-project.org> wrote:
> 
> Really, we have three levels of behavior related to dispatch: not loaded, loaded and attached. The loaded state is the most fragile - it does change some behavior (like the one below) but not others (when the package defines a new version of a generic). So it is true that the dispatch is the most problematic, in some sense you'd want it to be local to the package code when the package is not attached, but that's not supported in R as it is now.
> 
> Martin, re :: - I strongly disagree, semantically I find :: much cleaner than imports because you know exactly which function you call at all times and you don't pollute you package unnecessarily. It is unfortunate that the construct is inefficient in R, but that's an implementation problem, it shouldn't be because in fact it's immediately clear which symbol is meant. I believe the compiler should be able to fix that so in principle it shouldn't make a difference performance wise.
> 
> Cheers,
> Simon
> 
> 
>> On Sep 1, 2017, at 8:03 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>> 
>>>>>>> Lionel Henry <lionel at rstudio.com>
>>>>>>>  on Fri, 1 Sep 2017 13:47:07 +0200 writes:
>> 
>>> A package should probably never register a S3 method unless it owns
>>> either the generic or the class.
>> 
>> I agree... (and typically it does "own" the class)
>> 
>>> Here `formula.tools` owns neither.
>> 
>> i.e., it neither defines as.character() nor class "formula".
>> 
>>> Instead of registering the method, it should export it like a regular
>>> function. This way S3 dispatch is based on lexical scoping rather than
>>> session-wide side effect.
>> 
>> I don't the 2nd sentence above is quite correct.  S3 method
>> registration should be done (in the case it should) and S3
>> dispatch is not just based on lexical scoping but also on S3
>> method registration.
>> 
>>> Lionel
>> 
>> It is still the case that :: silently loads the namespace if
>> needed, and that "things may behave differently" after the use '::', because
>> loading a namespace does have an effect on the R session ...,
>> (and I still think  `::`  is much  "over used")
>> 
>> Martin
>> 
>> 
>> 
>>>> On 1 sept. 2017, at 12:57, Simon Barthelm? <simon.barthelme at gipsa-lab.fr> wrote:
>>>> 
>>>> Dear list
>>>> 
>>>> I'm not sure whether this is a bug or an unavoidable consequence of the way packages are loaded, but there can be surprising side effects of calling a function via package::function. Here's an example using the formula.tools package:
>>>> 
>>>> form <- a ~ b
>>>> as.character(form)
>>>> formula.tools::lhs(form)
>>>> as.character(form)
>>>> 
>>>> The first call to as.character returns:
>>>> [1] "~" "a" "b"
>>>> The second returns:
>>>> [1] "a ~ b"
>>>> 
>>>> The reason being that formula.tools has:
>>>> S3method(as.character,formula)
>>>> in its namespace, which quietly supersedes the default one. In my case it led to a bug that was rather hard to track down because it looked like non-deterministic behaviour.
>>>> Shouldn't there at least be a warning about such side effects, the way library() tells you about masking?
>>>> 
>>>> Best
>>>> 
>>>> Simon Barthelme
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 


From _ at thomaslevine.com  Fri Sep  1 15:23:47 2017
From: _ at thomaslevine.com (Thomas Levine)
Date: Fri, 01 Sep 2017 13:23:47 +0000
Subject: [Rd] I have corrected a dead link in the treering documentation
In-Reply-To: <22953.2920.615673.556828@stat.math.ethz.ch>
References: <20170728185317.E246C7E65E@mailuser.nyi.internal>
 <22953.2920.615673.556828@stat.math.ethz.ch>
Message-ID: <20170901132354.0C65C7E271@mailuser.nyi.internal>

Martin Maechler writes:
> There may be one small problem:  IIUC, the wayback machine is a
> +- private endeavor and really great and phantastic but it does
> need (US? tax deductible) donations, https://archive.org/donate/,
> to continue thriving.
> This makes me hesitate a bit to link to it within the "base R"
> documentation.  But that may be wrong -- and I should really use
> it to *help* the project ?

I agree that the Wayback Machine is a private endeavor. After reviewing
other base library documentation, I have concluded that it would
regardless be consistent with current practice to reference it in the
base documentation.

I share your concern regarding the support of other institutions, and
I have found some references that are more problematic to me than the
one of present interest. I would thus support an initiative to consider
the social implications of the different references and to adjust the
references accordingly.

Below I start by making a distinction between two types of references
that I think should be treated differently in terms of your concern.
Next, I assess whether there is a precedent for inclusion of references
to private publishers, as in the present patch; I include that there
is such a president. Then I present my opinion regarding the present
patch. Finally, I present some other considerations that I find relevant
to the discussion.

Distinguishing between two link types
-------------------------------------
For discussion of this issue, I think it is helpful to distinguish
between references to sources and references to other materials.

In the case of references of to sources, there is little choice but to
reference the publisher, even though the overwhelming majority of
referenced publishers are private companies that impose restrictive
licenses on their journals and books and cannot be reasonably trusted
to maintain access to the materials nor availability of webpages.

With other references, it is possible to replace the reference
with a different document that contains similar information.

For example, if a function implements an method based on a particular
journal article, that article's citation needs to stay, even if the
journal is published by a private institution. On the other hand, if the
reference just provides context or suggestions related to usage, then
the reference is provided just as information and can be replaced.

Precedent for inclusion of private non-source materials
-------------------------------------------------------
The dead link of interest is only informational, not a citation of a
source, and so it could be replaced. So I assessed whether it would
match current practice to include it, and I concluded that there is
substantial precedent for inclusion of private reference materials other
than strict sources. Not having access to a good library at the moment,
I have limited my research on this matter to website references.

In SVN revision 73164, \url calls are distributed among 148 files, from
1 call to 13 calls per file, with mean of 1.75 and median of 1.

  grep '\\url' src/library/*/*/*.Rd | cut -d: -f1 | uniq -c | sort -n

Total number of library documentation files is 1419.

  find src/library/ -name \*.Rd | wc -l

I randomly selected 20 matching files for further study.

  % grep '\\url' src/library/*/*/*.Rd | 
    cut -d: -f1 | uniq -c | sort -R | head -n 20 | tee /tmp/rd
   2 src/library/grDevices/man/pdf.Rd
   1 src/library/base/man/taskCallbackNames.Rd
   1 src/library/stats/man/shapiro.test.Rd
   1 src/library/tcltk/man/TkWidgets.Rd
   2 src/library/graphics/man/assocplot.Rd
   1 src/library/base/man/sprintf.Rd
   6 src/library/base/man/regex.Rd
   3 src/library/datasets/man/HairEyeColor.Rd
   1 src/library/stats/man/optimize.Rd
   1 src/library/datasets/man/UKDriverDeaths.Rd
   1 src/library/utils/man/object.size.Rd
   1 src/library/utils/man/unzip.Rd
   1 src/library/base/man/dcf.Rd
   1 src/library/base/man/DateTimeClasses.Rd
   3 src/library/stats/man/GammaDist.Rd
   2 src/library/utils/man/maintainer.Rd
   2 src/library/base/man/libcurlVersion.Rd
   2 src/library/base/man/eigen.Rd
   2 src/library/base/man/chol2inv.Rd
   1 src/library/tools/man/update_pkg_po.Rd

>From these 20 I composed a table with statistical unit of \url call and
with variables filename, url, type of reference, and type of publisher.
The following commands were helpful.

  sed -e 's/^[ 0-9]*//' /tmp/rd | xargs grep \\\\url |
    sed -e 's/$/::/' -e 's/:.*\\url./:/' > urls.csv
  sed 's/^[ 0-9]*//' /tmp/rd | xargs grep -A5 -B5 \\\\url | less

I realized that I need to be a bit more precise about what I mean by a
"source". I wound up grouping the type of reference for \url calls into
the following categories.

1 Necessary sources, such as the specific file from which an algorithm
  or dataset was copied (as in stats/man/optimize.Rd)
2 Upstream documentation for bound libraries (tcltk/man/TkWidgets.Rd)
3 Extra information, such as tutorials on portable programming
  referenced in base/man/sprintf.Rd
4 Ambiguous, such as an general introduction on the topic that may have
  been used during the development of the function or may have been
  added just as further documentation (as in grDevices/man/pdf.Rd).
  These references did not include the date on which the webpage was
  accessed, so they aren't clear enough to count as source references
  even if they were in fact used during the development of the function.
5 Comments (stats/man/shapiro.test.Rd) and duplicates
  (stats/man/GammaDist.Rd)

Earlier, I distinguished between references to sources and references to
other materials. I think that the first and second categories should be
considered the source type references and the third and fourth should be
considered the non-source type references.

I separated publisher types into the following

* academic (I think that they were all public universities, but I did
  not check very thoroughly.)
* government
* private
* R project

Resulting categorization was as follows (attached urls.csv and urls.r).

             publisher
source        academic government private r-project
  1 necessary        8          0       5         3
  2 upstream         3          0       6         0
  3 extra            0          0       1         1
  4 ambiguous        0          1       4         0
  5 ignore           0          1       1         1

The references of concern are the replaceable sources (types 3 and 4)
to private publishers, which account for 5 out of the 35 \url calls
and 5 of the 20 files. To fit the table in an email, I have truncated
the URLs to their domains.

                             filename                  domain
     src/library/grDevices/man/pdf.Rd        en.wikipedia.org
      src/library/base/man/sprintf.Rd developer.r-project.org
        src/library/base/man/regex.Rd        perldoc.perl.org
 src/library/utils/man/object.size.Rd        en.wikipedia.org
   src/library/stats/man/GammaDist.Rd        en.wikipedia.org

Note that the sprintf documentation is in fact a link to an r-project
page (https://developer.r-project.org/Portability.html) that has lots of
other links on it, including links to fortran.com, en.wikipedia.org,
pubs.opengroup.org, and people.redhat.com.

So we see that several \url calls reference private publishers even
though the links could be replaced with alternatives. By my
categorization, 5 out of 20 sampled files (95% confidence interval of 9
files to 65 files of the population of 148 matching files, based on a
bespoke t-test with finite population correction because I had trouble
compiling the sampling package, see urls.r) include a replaceable
reference to a private publisher.

I briefly looked through the full population of Rd files, and I got the
impression that this sort of private reference may be restricted to a
just a few publishers, with Wikimedia possibly being the most prominent.

To summarize, several other documentation files already reference
private publishers, and the set of publishers is small enough that
it would be feasible to review each publisher in order consider whether
the references to it should replaced with alternatives.

Opinion regarding the present patch
-----------------------------------
I think that linking to the Wayback Machine, by the Internet Archive, is
consistent with the practice in many other base libraries and that it is
thus acceptable.

At present, base makes no references to the Wayback Machine but makes
several references to English Wikipedia. An even more consistent option
is thus to link to the English Wikipedia article for Great Basin
bristlecone pine (https://en.wikipedia.org/wiki/Pinus_longaeva) or for
Methuselah (https://en.wikipedia.org/wiki/Methuselah_(tree)) instead of
the Wayback Machine page that I reference in the patch. (Note that the
treering data are from a tree in the Methuselah Walk but not from
Methuselah itself.)

On the other hand, if we are to avoid referencing private institutions
unnecessarily, we should create a broader initiative to replace private
non-source references in base documentation. For me, more worrisome than
references to the Open Group or to Wikimedia are the references to the
private company GitHub, as in utils/man/tar.Rd; aside from the social
implications of supporting a private company whose repository hosting
service has been accessed by the Free Software Foundation as unethical
(https://www.gnu.org/software/repo-criteria-evaluation.html), I do not
even trust in the long-term availability of its webpages.

And of course, if we do not correct the dead link in treering, I think
we should remove the dead link. We can optionally replace it with a very
short description of Great Basin bristlecone pines.

Further discussion
------------------

RESTRICTION CRITERIA

If R is to have formal restrictions as to what sorts of references may
be included in the base documentation, I think that private versus
public is not an appropriate criterion. To start, private universities
may be similarly acceptable to public universities, and certain
government institutions may be problematic. Also, most of the present
references to software specifications refer to private institutions.
Considering the goals of the R project and its status as a component
of the GNU project, I think that it would make more sense for the
criteria to be based on the license of the referenced work, rather than
on characteristics of the legal entity that has published it.

AVOIDING LINKS

For practical reasons, I think it would be nice to avoid the sort of
link that we are presently discussing and instead to distribute the
contents of that link. If the contents are incorporated into R, then
dead links are not an issue, we are free to edit the extra documentation
that otherwise would have been linked, and users can view the
documentation without a internet connection. I think that the datasets
documentation, in particular, could benefit substantially from a few
sentences of context being added to each documentation file.

That said, it is possible that this would be enough work that it would
not be worthwhile; this extra documentation could easily become much
larger than the rest of the R source code, especially if images are
included as in the case of the Methuselah Walk photographs, so
implementing this would be more involved than simply obtaining
acceptable licenses on the extra documentation and copying passages to
Rd files.
-------------- next part --------------
filename,url,source,publisher
src/library/grDevices/man/pdf.Rd,https://en.wikipedia.org/wiki/CMYK_color_model#Mapping_RGB_to_CMYK,4,private
src/library/grDevices/man/pdf.Rd,https://www.r-project.org/doc/Rnews/Rnews_2006-2.pdf,1,r-project
src/library/base/man/taskCallbackNames.Rd,https://developer.r-project.org/TaskHandlers.pdf,3,r-project
src/library/stats/man/shapiro.test.Rd,http://lib.stat.cmu.edu/apstat/R94,5,private
src/library/tcltk/man/TkWidgets.Rd,http://www.tkdocs.com,2,private
src/library/graphics/man/assocplot.Rd,http://www.math.yorku.ca/SCS/sugi/sugi17-paper.html,1,academic
src/library/graphics/man/assocplot.Rd,http://epub.wu.ac.at/dyn/openURL?id=oai:epub.wu-wien.ac.at:epub-wu-01_8a1,1,academic
src/library/base/man/sprintf.Rd,https://developer.r-project.org/Portability.html,3,private
src/library/base/man/regex.Rd,http://www.pcre.org,2,private
src/library/base/man/regex.Rd,http://www.pcre.org/original/doc/html/,2,private
src/library/base/man/regex.Rd,http://laurikari.net/tre/documentation/regex-syntax/,2,private
src/library/base/man/regex.Rd,http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html,1,private
src/library/base/man/regex.Rd,http://www.pcre.org/original/pcre.txt,1,private
src/library/base/man/regex.Rd,http://perldoc.perl.org/perlre.html,4,private
src/library/datasets/man/HairEyeColor.Rd,http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/haireye.sas,1,academic
src/library/datasets/man/HairEyeColor.Rd,http://www.math.yorku.ca/SCS/sugi/sugi17-paper.html,1,academic
src/library/datasets/man/HairEyeColor.Rd,http://www.math.yorku.ca/SCS/Papers/asa92.html,1,academic
src/library/stats/man/optimize.Rd,http://www.netlib.org/fmm/fmin.f,1,academic
src/library/datasets/man/UKDriverDeaths.Rd,http://www.ssfpack.com/dkbook/,1,private
src/library/utils/man/object.size.Rd,https://en.wikipedia.org/wiki/Binary_prefix,4,private
src/library/utils/man/unzip.Rd,http://zlib.net,1,private
src/library/base/man/dcf.Rd,https://www.debian.org/doc/debian-policy/ch-controlfields.html,1,private
src/library/base/man/DateTimeClasses.Rd,https://www.r-project.org/doc/Rnews/Rnews_2001-2.pdf,1,r-project
src/library/stats/man/GammaDist.Rd,https://en.wikipedia.org/wiki/Incomplete_gamma_function,4,private
src/library/stats/man/GammaDist.Rd,http://dlmf.nist.gov/8.2#i,4,government
src/library/stats/man/GammaDist.Rd,http://dlmf.nist.gov/,5,government
src/library/utils/man/maintainer.Rd,https://stat.ethz.ch/pipermail/r-help/2010-February/230027.html,1,r-project
src/library/utils/man/maintainer.Rd,http://n4.nabble.com/R-help-question-How-can-we-enable-useRs-to-contribute-corrections-to-help-files-faster-tp1572568p1572868.html,5,r-project
src/library/base/man/libcurlVersion.Rd,http://curl.haxx.se/docs/sslcerts.html,2,private
src/library/base/man/libcurlVersion.Rd,http://curl.haxx.se/docs/ssl-compared.html,2,private
src/library/base/man/eigen.Rd,http://www.netlib.org/lapack,1,academic
src/library/base/man/eigen.Rd,http://www.netlib.org/lapack/lug/lapack_lug.html,2,academic
src/library/base/man/chol2inv.Rd,http://www.netlib.org/lapack,1,academic
src/library/base/man/chol2inv.Rd,http://www.netlib.org/lapack/lug/lapack_lug.html,2,academic
src/library/tools/man/update_pkg_po.Rd,https://www.stats.ox.ac.uk/pub/Rtools/goodies/gettext-tools.zip,2,academic
-------------- next part --------------
urls <- read.csv('urls.csv')

urls.tab <- function(urls) {
  urls$source <- factor(urls$source)
  levels(urls$source) <- paste(levels(urls$source), c('necessary', 'upstream', 'extra', 'ambiguous', 'ignore'))
  print(table(urls[c('source', 'publisher')]))
}

urls.tab(urls)
interesting <- (urls$source==3|urls$source==4) & (urls$publisher=='private')
urls.interesting <- urls[interesting,1:2]

N <- 148
n <- length(levels(urls$filename))
x <- nrow(urls.interesting)
p <- x/n
fpc <- sqrt((N-n)/(N-1))
se <- (sqrt(p*(1-p))/sqrt(n)) * fpc
t <- qt(1-.025, n-1)

print(round(N*(p+c(-1,1)*t*se)))

From S.Ellison at LGCGroup.com  Fri Sep  1 16:27:00 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 1 Sep 2017 15:27:00 +0100
Subject: [Rd] side-effect of calling functions via `::`
In-Reply-To: <22953.19594.227858.248280@stat.math.ethz.ch>
References: <59A93D09.8010006@gipsa-lab.fr>
 <986041A4-19BE-4500-AD7E-4B2A32504D76@rstudio.com>
 <22953.19594.227858.248280@stat.math.ethz.ch>
Message-ID: <1A8C1289955EF649A09086A153E267240BD80E9070@GBTEDVPEXCMB04.corp.lgc-group.com>



> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Maechler
> ...
> >>>>> Lionel Henry <lionel at rstudio.com>
>     > A package should probably never register a S3 method unless it owns
>     > either the generic or the class.
> 
> I agree... (and typically it does "own" the class)

If that is true and a good general guide, is it worth adding something to that effect to 1.5.2 of "Writing R extensions"?
At present, nothing in 1.5.2 requires or recommends that a package using S3method owns either class or generic. 


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From r_goertz at web.de  Fri Sep  1 16:38:36 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Fri, 1 Sep 2017 16:38:36 +0200
Subject: [Rd] patch: automatically adjust width option when terminal is
 resized
In-Reply-To: <alpine.DEB.2.20.1709010710340.2718@luke-Latitude>
References: <20170828093331.39607d5b@delligoertz.fritz.box>
 <20170901102321.6921e48a@delligoertz.fritz.box>
 <alpine.DEB.2.20.1709010710340.2718@luke-Latitude>
Message-ID: <20170901163836.26590c10@delligoertz.fritz.box>

Am Fri, 1 Sep 2017 07:20:58 -0500 (CDT)
schrieb luke-tierney at uiowa.edu:

> On Fri, 1 Sep 2017, Ralf Goertz wrote:
> 
> > Many good programs like vim adjust their internal width
> > representation automatically. Why shouldn't R do the same? It seems
> > quite easy, at least when readline is used:
> >
> >
> > --- R-3.4.1/src/unix/sys-std.c  2017-03-24 00:03:59.000000000 +0100
> > +++ R-3.4.1/src/unix/sys-std.patched.c  2017-08-28
> > 09:16:02.714204023 +0200 @@ -1005,6 +1005,9 @@
> >                // introduced in readline 4.0: only used for >= 6.3
> > #ifdef HAVE_RL_RESIZE_TERMINAL
> >                rl_resize_terminal();
> > +               int rl_height, rl_width;
> > +               rl_get_screen_size(&rl_height,&rl_width);
> > +               R_SetOptionWidth(rl_width);
> > #endif
> >             }
> > #endif  
> 
> The 'width' option affects more than printing to the console; it also
> affects, for example, printing to a file via sink() or
> capture.output(). So doing this unconditionally would not be a good
> idea.  Making it available as an option for those who want it seems
> reasonable but still involves a lot more work than these three lines.
> It requires designing a protocol for enabling this feature, ideally in
> a way that can be made to work well on other interfaces (e.g. Windows,
> Mac, RStudio) as well, and it requires documenting all this in a
> sensible place. A more complete proposal might well be considered for
> adoption.

Hi Luke,

thanks for your explanation. I am not at all familiar with the R source
code nor am I a professional programmer. I found the place to do that
simply by grepping for the signal SIGWINCH. I was, however, aware that
it would need more than those three lines.

As to the other uses of the width option, wouldn't it make sense to have
a separate option for output redirection? Or even have file output
always use the same fixed width, say 80? After all, if the output is
saved to a file this file is probably meant to be viewed in another
context than the R terminal. And even if the width of file output is
affected I don't see any real harm since that is the way it is now. If
one really needs a specific width in such a case s/he can request it by
setting the option manually before outputting to a file. On the other
hand, the documentation says

	 ?width?: controls the maximum number of columns on a line used in
		  ?
		  ?Print.h? and can be changed by re-compiling R.)  Some R
		  consoles automatically change the value when they are resized.

If *some* consoles already do automatically change the value when
resized why should an instance of R running in a pure terminal emulator
not be allowed to do so? In case there is a good reason, my idea for the
option is as follows. It stays as it is but it can also be negative
indicating that SIGWINCH will lead to an adjustment. That way nothing
changes for those users who do not bother at all. Also, this can easily
be documented, e.g. by appending the following line to the block quoted
above.

		  Others do so when 'width? is negative.

Interfaces which don't or can't use that feature or functions like print
merely have to call "abs(GetOptionWidth())" instead of
"GetOptionWidth()". Luckily, both "int GetOptionWidth()" and "int
attribute_hidden R_SetOptionWidth(int w)" are defined in terms of int,
so it is possible to send and receive negative values. I don't know
about the Windows or Mac interface. But I would imagine that they can
also be made to swallow negative width values rather easily.

Digging a little more I found that there had been the setwidth package
which basically did what I am asking for. Here
<https://groups.google.com/forum/#!topic/vim-r-plugin/SeQCNWxEPwk> the
author of that package (Jakson Aquino) explains that it stopped working
because R started to catch SIGWINCH itself. He continues: ?Perhaps this
feature could be implemented directly in R if someone requested it to
the R Core Team.? There really seems to be a need for this.

Ralf


From henrik.bengtsson at gmail.com  Fri Sep  1 17:28:43 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 1 Sep 2017 08:28:43 -0700
Subject: [Rd] BUG: HMTL-based help.search() on vignettes may generate
 error (with PATCH)
In-Reply-To: <CAFDcVCQgEvHhGFsRSt+tmg_kaW3F1=B_y-20KcsNW-DJGjx4Rw@mail.gmail.com>
References: <CAFDcVCQgEvHhGFsRSt+tmg_kaW3F1=B_y-20KcsNW-DJGjx4Rw@mail.gmail.com>
Message-ID: <CAFDcVCT-bN7wk_kKGcB6EGj8bF4Y47+Tza7xo-18nFwSzwT_yg@mail.gmail.com>

UPDATE: This has been fixed in R-devel (rev 73170) by Kurt H.  I
checked with him and he'll also try to get it into the upcoming R
3.4.2 (ETA 2017-09-28).

/Henrik

On Tue, Aug 29, 2017 at 4:19 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> REPRODUCIBLE EXAMPLE:
>
> With the R.rsp package installed, the following search, which gives a hit:
>
>     options(help_type = "html")
>     help.search("rsp")
>
> generates:
>
>     Error in if (nchar(Outfile)) Outfile else File :
>       argument is not interpretable as logical
>
> in the browser (e.g. http://127.0.0.1:30410/doc/html/Search?results=1).
>
> Another example is help.search("tm") with jsonlite installed.
>
>
> TROUBLESHOOTING:
>
> This occurs because utils:::merge_vignette_index() uses:
>
>     base[, "Name"] <- sub("\\.[^.]*$", "", basename(vDB$File))
>     base[, "Topic"] <- base[, "Name"]
>
> which assumes that the 'Name' (and hence the 'Topic') can be inferred
> from the basename of the vignette source file by dropping the filename
> extension.  This assumption was valid in R (< 3.0.0), but with the
> introduction of generic vignette engines, we may now have multiple
> ("nested") file-name extensions on vignette source files.  For
> instance, vignette source file 'vignette.tex.rsp' outputs
> 'vignette.pdf'.  Another example is 'vignette.pdf.asis' that outputs
> 'vignette.pdf'.
>
> Now, the assumption on a single file-name extension is still valid on
> the vignette output product file, where we can only have file name
> extensions *.pdf and *.html.  Because of this, a solution is to use
> 'basename(vDB$PDF)' instead of 'basename(vDB$File)'.  This is also
> what tools:::httpd() uses internally and the difference between the
> two approach is what causes the error in help.search() above.
>
>
> PATCH:
>
> A patch (against R-devel) is:
>
> svn diff src/library/utils/R/help.search.R
> Index: src/library/utils/R/help.search.R
> ===================================================================
> --- src/library/utils/R/help.search.R (revision 73159)
> +++ src/library/utils/R/help.search.R (working copy)
> @@ -43,7 +43,7 @@
>   base[, "LibPath"] <- path
>   id <- as.character(1:nrow(vDB) + NROW(hDB[[1L]]))
>   base[, "ID"] <- id
> - base[, "Name"] <- sub("\\.[^.]*$", "", basename(vDB$File))
> + base[, "Name"] <- tools::file_path_sans_ext(basename(vDB$PDF))
>   base[, "Topic"] <- base[, "Name"]
>   base[, "Title"] <- vDB$Title
>   base[, "Type"] <- "vignette"
>
> I have verified that the above patch solves the problem.  I thought it
> is ok to use tools::file_path_sans_ext() since other functions in
> 'utils' already do so.
>
> I'm happy to submit this one via https://bugs.r-project.org/bugzilla3/ as well.
>
>
> APPENDIX:
>
>> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.3 LTS
>
> Matrix products: default
> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1
>
> /Henrik


From luke-tierney at uiowa.edu  Fri Sep  1 17:47:48 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 1 Sep 2017 10:47:48 -0500 (CDT)
Subject: [Rd] Please avoid direct use of NAMED and SET_NAMED macros
Message-ID: <alpine.DEB.2.20.1709011047210.2718@luke-Latitude>

To allow for future changes in the way the need for duplication is
detected in R internal C code, package C code should avoid direct
use of NAMED,and SET_NAMED, or assumptions on the maximal value
of NAMED. Use the macros MAYBE_REFERENCED, MAYBE_SHARED, and
MARK_NOT_MUTABLE instead. These currently correspond to

MAYBE_REFERENCED(x):   NAMED(x) > 0
MAYBE_SHARED(x):       NAMED(x) > 1
MARK_NOT_MUTABLE(x):   SET_NAMED(c, NAMEDMAX)

Best,

luke


-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From S.Ellison at LGCGroup.com  Fri Sep  1 18:06:44 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 1 Sep 2017 17:06:44 +0100
Subject: [Rd] Wayback and related questions (was: RE: I have corrected a
 dead link ...)
Message-ID: <1A8C1289955EF649A09086A153E267240BD80E9092@GBTEDVPEXCMB04.corp.lgc-group.com>

Appreciated that this is something of a 'private discussion in the open', but the issues here seem to be relevant to almost any website cited as a reference. As such, package authors may find themselves falling foul of some policy we haven't heard of.
So ...
> There may be one small problem:  IIUC, the wayback machine is a
> +- private endeavor and really great and phantastic but it does
> need (US? tax deductible) donations, https://archive.org/donate/, to
> continue thriving.
> This makes me hesitate a bit to link to it within the "base R"
> documentation. 

Why, exactly? The donors have paid for the site to be available with minimal restrictions precisely so that people can use it. Were there terms of use that prevent you?

Also, on GitHub's GNU ethical repository rating...
I _can_ see it as reasonable for sites aspiring to be GNU projects to subscribe to the principles Stallman aspires to; but I cannot see it as sensible for them to refuse to reference sites that do not wish to make the same claims. If the R project cannot use or reference any site that uses non-open code, including minified javascript - which appears to be the principle issue for GitHub - I suspect that you will be obliged to discontinue links to almost every journal, university, charity, government and research establishment site currently in existence as soon as GNU get round to assessing them.  I personally have great difficulty seeing that as sensible. 

But that's a personal opinion. If these really are serious issues, somebody needs to work up a consistent policy for R projects; otherwise we'll all be walking on eggshells.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From luke-tierney at uiowa.edu  Fri Sep  1 21:13:32 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 1 Sep 2017 14:13:32 -0500 (CDT)
Subject: [Rd] patch: automatically adjust width option when terminal is
 resized
In-Reply-To: <alpine.DEB.2.20.1709011403350.2718@luke-Latitude>
References: <20170828093331.39607d5b@delligoertz.fritz.box>
 <20170901102321.6921e48a@delligoertz.fritz.box>
 <alpine.DEB.2.20.1709010710340.2718@luke-Latitude>
 <20170901163836.26590c10@delligoertz.fritz.box>
 <alpine.DEB.2.20.1709011403350.2718@luke-Latitude>
Message-ID: <alpine.DEB.2.20.1709011412370.2718@luke-Latitude>

Accidentally dropped R-devel from this reply.

On Fri, 1 Sep 2017, luke-tierney at uiowa.edu wrote:

> On Fri, 1 Sep 2017, Ralf Goertz wrote:
>
>> Am Fri, 1 Sep 2017 07:20:58 -0500 (CDT)
>> schrieb luke-tierney at uiowa.edu:
>> 
>>> On Fri, 1 Sep 2017, Ralf Goertz wrote:
>>> 
>>>> Many good programs like vim adjust their internal width
>>>> representation automatically. Why shouldn't R do the same? It seems
>>>> quite easy, at least when readline is used:
>>>> 
>>>> 
>>>> --- R-3.4.1/src/unix/sys-std.c  2017-03-24 00:03:59.000000000 +0100
>>>> +++ R-3.4.1/src/unix/sys-std.patched.c  2017-08-28
>>>> 09:16:02.714204023 +0200 @@ -1005,6 +1005,9 @@
>>>>                // introduced in readline 4.0: only used for >= 6.3
>>>> #ifdef HAVE_RL_RESIZE_TERMINAL
>>>>                rl_resize_terminal();
>>>> +               int rl_height, rl_width;
>>>> +               rl_get_screen_size(&rl_height,&rl_width);
>>>> +               R_SetOptionWidth(rl_width);
>>>> #endif
>>>>             }
>>>> #endif
>>> 
>>> The 'width' option affects more than printing to the console; it also
>>> affects, for example, printing to a file via sink() or
>>> capture.output(). So doing this unconditionally would not be a good
>>> idea.  Making it available as an option for those who want it seems
>>> reasonable but still involves a lot more work than these three lines.
>>> It requires designing a protocol for enabling this feature, ideally in
>>> a way that can be made to work well on other interfaces (e.g. Windows,
>>> Mac, RStudio) as well, and it requires documenting all this in a
>>> sensible place. A more complete proposal might well be considered for
>>> adoption.
>> 
>> Hi Luke,
>> 
>> thanks for your explanation. I am not at all familiar with the R source
>> code nor am I a professional programmer. I found the place to do that
>> simply by grepping for the signal SIGWINCH. I was, however, aware that
>> it would need more than those three lines.
>> 
>> As to the other uses of the width option, wouldn't it make sense to have
>> a separate option for output redirection? Or even have file output
>> always use the same fixed width, say 80? After all, if the output is
>> saved to a file this file is probably meant to be viewed in another
>> context than the R terminal. And even if the width of file output is
>> affected I don't see any real harm since that is the way it is now. If
>> one really needs a specific width in such a case s/he can request it by
>> setting the option manually before outputting to a file.
>
> This could have been designed differently, but it wasn't and making
> chnages would cause code to break.
>
>> On the other
>> hand, the documentation says
>>
>> 	 ?width?: controls the maximum number of columns on a line used in
>> 		  ?
>> 		  ?Print.h? and can be changed by re-compiling R.)  Some R
>> 		  consoles automatically change the value when they are 
>> resized.
>
>
> Good point.
>
> The Windows R GUI does this if a preference option is set; I don't
> know what the default is from just a quick look at the sources.
>
> RStudio does this by default and there is no obvious way, to me at
> least, to turn it off, which is unfortunate given the
> sink/capture.output issues.
>
> I made changes to R-devel in r73180 to set width if the you set
> options(setWidthOnResize = TRUE). By default this option is not set
> and the width option is not changed. We'll see if it causes any
> problems.
>
> Best,
>
> luke
>
>
>> If *some* consoles already do automatically change the value when
>> resized why should an instance of R running in a pure terminal emulator
>> not be allowed to do so? In case there is a good reason, my idea for the
>> option is as follows. It stays as it is but it can also be negative
>> indicating that SIGWINCH will lead to an adjustment. That way nothing
>> changes for those users who do not bother at all. Also, this can easily
>> be documented, e.g. by appending the following line to the block quoted
>> above.
>>
>> 		  Others do so when 'width? is negative.
>> 
>> Interfaces which don't or can't use that feature or functions like print
>> merely have to call "abs(GetOptionWidth())" instead of
>> "GetOptionWidth()". Luckily, both "int GetOptionWidth()" and "int
>> attribute_hidden R_SetOptionWidth(int w)" are defined in terms of int,
>> so it is possible to send and receive negative values. I don't know
>> about the Windows or Mac interface. But I would imagine that they can
>> also be made to swallow negative width values rather easily.
>> 
>> Digging a little more I found that there had been the setwidth package
>> which basically did what I am asking for. Here
>> <https://groups.google.com/forum/#!topic/vim-r-plugin/SeQCNWxEPwk> the
>> author of that package (Jakson Aquino) explains that it stopped working
>> because R started to catch SIGWINCH itself. He continues: ?Perhaps this
>> feature could be implemented directly in R if someone requested it to
>> the R Core Team.? There really seems to be a need for this.
>> 
>> Ralf
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From therneau at mayo.edu  Fri Sep  1 21:28:23 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 01 Sep 2017 14:28:23 -0500
Subject: [Rd] Missing y label
In-Reply-To: <22953.3654.62340.915319@stat.math.ethz.ch>
References: <9153c6$7s2gdm@ironport10.mayo.edu>
 <22953.3654.62340.915319@stat.math.ethz.ch>
Message-ID: <9153c6$7s9eip@ironport10.mayo.edu>

Martin,
   Thanks for taking a quick look.  Yes it looks like it must be something local.
I've done the following to make sure I have a clean box:
   reboot
   sudo apt-get update
   sudo apt-get upgrade

Rerun the "svn up" command and do a
    make distclean
    svn up
    tools/rsync-recommended
    ./configure
    make

The problem persists in 2017-09-01 r73179
I pulled the source code for 3.4-1 and compiled it, the problem persists.

I then did sudo apt-get install R, which installs version 3.2.3 on the machine.  The plots 
work as expected there.

The new plots are the same size, same layout and margins, but the text and lines are 
definitely thinner.  According to the package manager I have the latest version of 
texlive-fonts-extra.

I don't see how to get it to pull a newer compiled version than 3.2.

Anything else that would help?

Terry T.




On 09/01/2017 02:37 AM, Martin Maechler wrote:
>      > My on-screen plots with the latest build are acting
>      > strange.  If the y label is longer than some small value it is not shown.
> 
> [MM: moved the important part of the script up here:]
> 
>      plot(1:5, 1:5, ylab="abcde")  # has a y label
> 
>      plot(1:5, 1:5, ylab="abcdefghi")  # no label
> 
> That is amazing.
> I don't see a problem here (Linux Fedora F24, or F26, in both
> case using GNOME as windowing system),
> also with this, both interactive or pdf :
> 
> plot(1:5, 1:5, ylab="abcdefghi or even quite an order of magnitude longer")
> 
> pdf("long-ylab.pdf")
> plot(1:5, 1:5, ylab="abcdefghi or even quite an order of magnitude longer")
> dev.off(); system("evince long-ylab.pdf &")
> 
> I have no further idea but guess this must be specific to your platform.
> 
> Did you try the same thing with R 3.4.1?
> Did you install both in the same way -- from the sources ??


From dwinsemius at comcast.net  Fri Sep  1 21:47:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 Sep 2017 12:47:11 -0700
Subject: [Rd] Natural vs National in R signon banner?
In-Reply-To: <CAOKDuOiiShpCWB_DRqB_fpUnwAhGo4x6Yd63V=+vUy85XhN_CQ@mail.gmail.com>
References: <CAN6Gc-2OHSQfs3c+Wyyf8xPUzfnRYMGhYQjrjvLMfD6TC6pc9Q@mail.gmail.com>
 <e4153b84-a8a7-9880-25d5-0d91abf24bd1@gmail.com>
 <CAN6Gc-2WtBvhSMG2Z9p0X6pYea2vrCpozJ7gUjoBk39b8SS15w@mail.gmail.com>
 <e0aa99b4-c8b5-86b5-aff0-f882d7de42b8@gmail.com>
 <CAN6Gc-3n6bc+nH2589V771=Gq4JwKfotm8RtiMkzYKLjFekYCg@mail.gmail.com>
 <22953.4130.656513.835219@stat.math.ethz.ch>
 <95DB024B-D5A4-4F00-BBBC-CD998FF32E4D@gmail.com>
 <CAOKDuOiiShpCWB_DRqB_fpUnwAhGo4x6Yd63V=+vUy85XhN_CQ@mail.gmail.com>
Message-ID: <817092E7-28A1-4991-A74C-65DFE17477E6@comcast.net>


> On Sep 1, 2017, at 2:17 AM, Mark van der Loo <mark.vanderloo at gmail.com> wrote:
> 
> The way it's phrased now makes it seem that English is not a Natural
> language ("Natural language support *but* running in an English locale").
> Why not just state: "running in an English locale" and leave it with that?
> Better to leave something out than to be unclear (being correct formally
> does not always mean being clear to all users).

I think the goal is to notify the user that "internationalization" efforts have been made, so something like:

"Internationalization support of messages may be available,
 but currently running in an English locale."

That would have the desirable side-effect of alerting new users to the effective search strategy to use.

-- 

David.

> -M
> 
> Op vr 1 sep. 2017 om 11:00 schreef Peter Dalgaard <pdalgd at gmail.com>:
> 
>> Just leave it, I think. Some nations have 4 national languages (as Martin
>> will know), some languages are not national, and adopted children often do
>> not speak their native (=born) language... I suspect someone already put a
>> substantial amount of thought into the terminology.
>> 
>> -pd
>> 
>> 
>>> On 1 Sep 2017, at 09:45 , Martin Maechler <maechler at stat.math.ethz.ch>
>> wrote:
>>> 
>>>>>>>> Paul McQuesten <mcquesten at gmail.com>
>>>>>>>>   on Thu, 31 Aug 2017 18:48:12 -0500 writes:
>>> 
>>>> Actually, I do agree with you about Microsoft.
>>>> But they have so many users that their terminology should not be
>> ignored.
>>> 
>>>> Here are a few more views:
>>> 
>>>> 
>> https://www.ibm.com/support/knowledgecenter/ssw_aix_71/com.ibm.aix.performance/natl_lang_supp_locale_speed.htm
>>>> https://docs.oracle.com/cd/E23824_01/html/E26033/glmbx.html
>>>> 
>> http://support.sas.com/documentation/cdl/en/nlsref/69741/HTML/default/viewer.htm#n1n9bwctsthuqbn1xgipyw5xwujl.htm
>>>> 
>> https://docs.intersystems.com/latest/csp/docbook/DocBook.UI.Page.cls?KEY=GSA_config_nls
>>>> 
>> https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixprggd/genprogc/nls.htm
>>>> 
>> http://scc.ustc.edu.cn/zlsc/tc4600/intel/2017.0.098/compiler_f/common/core/GUID-1AEC889E-98A7-4A7D-91B3-865C476F603D.html
>>> 
>>>> It does appear, however, that what I call 'National Language' is often
>>>> referred to as 'Native Language'. And the 'National Language'
>> terminology
>>>> is said to not be used consistently:
>>>> https://en.wikipedia.org/wiki/National_language
>>> 
>>>> I do still feel, however, that claiming 'Natural Language' support in R
>>>> sets expectations of new users overly high.
>>> 
>>>> Thank you for spending so much time on such a minor nit.
>>> 
>>> continuing the nits and gnats :
>>> 
>>> I think I now understand what you mean.  From the little I
>>> understand about English intricacies and with my not
>>> fully developed gut feeling of good English (which I rarely
>>> speak but sometimes appreciate when reading / listening),
>>> I would indeed
>>> 
>>> prefer  'Native Language'
>>> to    'Natural Language'
>>> 
>>> Martin Maechler
>>> ETH Zurich
>>> 
>>>> Regards
>>> 
>>> 
>>> 
>>>> On Thu, Aug 31, 2017 at 5:45 PM, Duncan Murdoch <
>> murdoch.duncan at gmail.com>
>>>> wrote:
>>> 
>>>>> On 31/08/2017 6:37 PM, Paul McQuesten wrote:
>>>>> 
>>>>>> Thanks, Duncan. But if it is not inappropriate, I feel empowered to
>> argue.
>>>>>> 
>>>>>> According to this definition, https://en.wikipedia.org/wiki/
>>>>>> Natural_language:
>>>>>> In neuropsychology, linguistics and the philosophy of language, a
>>>>>> natural language or ordinary language is any language that has evolved
>>>>>> naturally in humans ...
>>>>>> 
>>>>>> Thus this banner statement may appear over-claiming to a significant
>>>>>> fraction of R users.
>>>>>> 
>>>>>> It seems that LOCALE is called 'National language' support in other
>>>>>> software systems.
>>>>>> Eg: https://www.microsoft.com/resources/msdn/goglobal/default.mspx
>>>>>> 
>>>>> 
>>>>> I wouldn't take Microsoft as an authority on this (or much of
>> anything).
>>>>> They really are amazingly incompetent, considering how much money they
>> earn.
>>>>> 
>>>>> Duncan Murdoch
>>>>> 
>>>>> 
>>>>>> And, yes, this is a low priority issue. All of you have better things
>> to
>>>>>> do.
>>>>>> 
>>>>>> R is an extremely powerful and comprehensive software system.
>>>>>> Thank you all for that.
>>>>>> And I would like to clean one gnat from the windshield.
>>>>>> 
>>>>>> I just wax pedantic at times.
>>>>>> 
>>>>>> On Thu, Aug 31, 2017 at 5:13 PM, Duncan Murdoch <
>> murdoch.duncan at gmail.com
>>>>>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>>>>> 
>>>>>> On 31/08/2017 5:38 PM, Paul McQuesten wrote:
>>>>>> 
>>>>>> The R signon banner includes this statement:
>>>>>> Natural language support but running in an English locale
>>>>>> 
>>>>>> Should that not say 'National' instead of 'Natural'?
>>>>>> Meaning that LOCALE support is enabled, not that the interface
>>>>>> understands
>>>>>> human language?
>>>>>> 
>>>>>> 
>>>>>> No, "natural language" refers to human languages, but it doesn't
>>>>>> imply that R understands them.  NLS just means that messages may be
>>>>>> presented in (or translated to) other human languages in an
>>>>>> appropriate context.
>>>>>> 
>>>>>> For example, you can start R on most platforms from the console using
>>>>>> 
>>>>>> LANGUAGE=de R
>>>>>> 
>>>>>> and instead of the start message you saw, you'll see
>>>>>> 
>>>>>> R ist freie Software und kommt OHNE JEGLICHE GARANTIE.
>>>>>> Sie sind eingeladen, es unter bestimmten Bedingungen weiter zu
>>>>>> verbreiten.
>>>>>> Tippen Sie 'license()' or 'licence()' f?r Details dazu.
>>>>>> 
>>>>>> and so on.
>>>>>> 
>>>>>> Please ignore this and forgive me if this is an inappropriate
>>>>>> post. I am a
>>>>>> N00B in R.
>>>>>> 
>>>>>> 
>>>>>> I don't think it is inappropriate.
>>>>>> 
>>>>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501 <+45%2038%2015%2035%2001>
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From edd at debian.org  Fri Sep  1 21:58:49 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 1 Sep 2017 14:58:49 -0500
Subject: [Rd] Missing y label
In-Reply-To: <9153c6$7s9eip@ironport10.mayo.edu>
References: <9153c6$7s2gdm@ironport10.mayo.edu>
 <22953.3654.62340.915319@stat.math.ethz.ch>
 <9153c6$7s9eip@ironport10.mayo.edu>
Message-ID: <22953.48121.13110.355737@bud.eddelbuettel.com>


On 1 September 2017 at 14:28, Therneau, Terry M., Ph.D. wrote:
| Martin,
|    Thanks for taking a quick look.  Yes it looks like it must be something local.
| I've done the following to make sure I have a clean box:
|    reboot
|    sudo apt-get update
|    sudo apt-get upgrade
| 
| Rerun the "svn up" command and do a
|     make distclean
|     svn up
|     tools/rsync-recommended
|     ./configure
|     make
| 
| The problem persists in 2017-09-01 r73179
| I pulled the source code for 3.4-1 and compiled it, the problem persists.
| 
| I then did sudo apt-get install R, which installs version 3.2.3 on the machine.  The plots 
| work as expected there.

Read the fine README here:  https://cloud.r-project.org/bin/linux/ubuntu/README.html
Similar one for Debian at   https://cloud.r-project.org/bin/linux/debian/

Many of us have been using R from CRAN on Ubuntu and Debian for many years,
and many update cycles.  I try hard to get new R versions into Debian the
morning of the release [1] and Michael and Johannes usually produce binary
for the mirrors within a day or two too. On this box still running 16.10:

edd at bud:~$ apt-cache policy r-base-core
r-base-core:
  Installed: 3.4.1-2yakkety0
  Candidate: 3.4.1-2yakkety0
  Version table:
 *** 3.4.1-2yakkety0 500
        500 https://cloud.r-project.org/bin/linux/ubuntu yakkety/ Packages
        100 /var/lib/dpkg/status
     3.4.1-1yakkety0 500
        500 https://cloud.r-project.org/bin/linux/ubuntu yakkety/ Packages
     3.4.0-1yakkety0 500
        500 https://cloud.r-project.org/bin/linux/ubuntu yakkety/ Packages
     3.3.3-1yakkety0 500
        500 https://cloud.r-project.org/bin/linux/ubuntu yakkety/ Packages
     3.3.2-1yakkety0 500
        500 https://cloud.r-project.org/bin/linux/ubuntu yakkety/ Packages
     3.3.1-1build1 500
        500 http://us.archive.ubuntu.com/ubuntu yakkety/universe amd64 Packages
edd at bud:~$ 


Dirk

[1] And once every couple of years I get to do it on a high-speed train...


-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From therneau at mayo.edu  Fri Sep  1 22:50:44 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 01 Sep 2017 15:50:44 -0500
Subject: [Rd] Missing y label
In-Reply-To: <22953.48121.13110.355737@bud.eddelbuettel.com>
References: <9153c6$7s2gdm@ironport10.mayo.edu>
 <22953.3654.62340.915319@stat.math.ethz.ch>
 <9153c6$7s9eip@ironport10.mayo.edu>
 <22953.48121.13110.355737@bud.eddelbuettel.com>
Message-ID: <9153c6$7sa5f2@ironport10.mayo.edu>

I did read that fine file.
I added the following line to my /etc/apt/sources.list file:

tmt-local2023% tail -2 /etc/apt/sources.list
# R sources
deb https://mirror.las.iastate.edu/bin/linux/ubuntu xenial/

Here is what apt says on my machine

tmt-local2024% apt-cache policy r-base-core r-base-core: Installed: 3.2.3-4 Candidate: 
3.2.3-4 Version table: *** 3.2.3-4 500 500 http://us.archive.ubuntu.com/ubuntu 
xenial/universe amd64 Packages 100 /var/lib/dpkg/status My long term habit is to stick to 
LTS versions, which currently is 16.04: "still running 16.10" is a different outlook. The 
system admins here tend to be more conservative than me. Again, thanks for any input. 
Getting this particular box straightened out quickly isn't critical, but I would like to 
understand the root of the issue. Terry T.

On 09/01/2017 02:58 PM, Dirk Eddelbuettel wrote:
> Read the fine README here:https://cloud.r-project.org/bin/linux/ubuntu/README.html
> Similar one for Debian athttps://cloud.r-project.org/bin/linux/debian/
>
> Many of us have been using R from CRAN on Ubuntu and Debian for many years,
> and many update cycles.  I try hard to get new R versions into Debian the
> morning of the release [1] and Michael and Johannes usually produce binary
> for the mirrors within a day or two too. On this box still running 16.10:
>
> edd at bud:~$ apt-cache policy r-base-core
> r-base-core:
>    Installed: 3.4.1-2yakkety0
>    Candidate: 3.4.1-2yakkety0
>    Version table:
>   *** 3.4.1-2yakkety0 500
>    


	[[alternative HTML version deleted]]


From r_goertz at web.de  Sat Sep  2 08:35:47 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Sat, 2 Sep 2017 08:35:47 +0200
Subject: [Rd] patch: automatically adjust width option when terminal is
 resized
In-Reply-To: <alpine.DEB.2.20.1709011403350.2718@luke-Latitude>
References: <20170828093331.39607d5b@delligoertz.fritz.box>
 <20170901102321.6921e48a@delligoertz.fritz.box>
 <alpine.DEB.2.20.1709010710340.2718@luke-Latitude>
 <20170901163836.26590c10@delligoertz.fritz.box>
 <alpine.DEB.2.20.1709011403350.2718@luke-Latitude>
Message-ID: <20170902083547.6d694e9a@assi.home.local>

Am Fri, 1 Sep 2017 14:11:19 -0500 (CDT)
schrieb luke-tierney at uiowa.edu:

> On Fri, 1 Sep 2017, Ralf Goertz wrote:
> 
> 
> > On the other
> > hand, the documentation says
> >
> > 	 ?width?: controls the maximum number of columns on a line
> > used in ?
> > 		  ?Print.h? and can be changed by re-compiling R.)
> > Some R consoles automatically change the value when they are
> > resized.  
> 
> 
> Good point.
> 
> The Windows R GUI does this if a preference option is set; I don't
> know what the default is from just a quick look at the sources.
> 
> RStudio does this by default and there is no obvious way, to me at
> least, to turn it off, which is unfortunate given the
> sink/capture.output issues.
> 
> I made changes to R-devel in r73180 to set width if the you set
> options(setWidthOnResize = TRUE). By default this option is not set
> and the width option is not changed. We'll see if it causes any
> problems.
> 
> Best,
> 
> luke


Thanks Luke, appreciate it.

Ralf


From _ at thomaslevine.com  Sat Sep  2 12:17:42 2017
From: _ at thomaslevine.com (Thomas Levine)
Date: Sat, 02 Sep 2017 10:17:42 +0000
Subject: [Rd] Wayback and related questions (was: RE: I have corrected a
	dead link ...)
In-Reply-To: <1A8C1289955EF649A09086A153E267240BD80E9092@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <1A8C1289955EF649A09086A153E267240BD80E9092@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <20170902101746.2177F7F988@mailuser.nyi.internal>

> If the R project cannot use or reference any site that uses non-open
> code, including minified javascript - which appears to be the
> principle issue for GitHub - I suspect that you will be obliged to
> discontinue links to almost every journal, university, charity,
> government and research establishment site currently in existence as
> soon as GNU get round to assessing them.  I personally have great
> difficulty seeing that as sensible. 

The policy that you suggest would indeed be completely stupid.
Fortunately, a reasonable policy that vaguely matches the current
practices is likely to affect hardly any documentation files.

I don't have a strong opinion as to whether publishing characteristics
of references should be a consideration during the composition of R
documentation files, and I trust the R developers to decide well.


From edd at debian.org  Sat Sep  2 14:18:39 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 2 Sep 2017 07:18:39 -0500
Subject: [Rd] Missing y label
In-Reply-To: <9153c6$7sa5f2@ironport10.mayo.edu>
References: <9153c6$7s2gdm@ironport10.mayo.edu>
 <22953.3654.62340.915319@stat.math.ethz.ch>
 <9153c6$7s9eip@ironport10.mayo.edu>
 <22953.48121.13110.355737@bud.eddelbuettel.com>
 <9153c6$7sa5f2@ironport10.mayo.edu>
Message-ID: <22954.41375.655519.749014@bud.eddelbuettel.com>


On 1 September 2017 at 15:50, Therneau, Terry M., Ph.D. wrote:
| The system admins here ...

I suggest you get these local admins to help you.

These CRAN repos for Ubuntu are used by thousands of people every day, and
they "just work", for both the recent releases and the most recent LTS.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From radford at cs.toronto.edu  Sat Sep  2 17:20:42 2017
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 2 Sep 2017 11:20:42 -0400
Subject: [Rd] Please avoid direct use of NAMED and SET_NAMED macros
In-Reply-To: <mailman.7.1504346401.17359.r-devel@r-project.org>
References: <mailman.7.1504346401.17359.r-devel@r-project.org>
Message-ID: <20170902152042.GA32423@mail.cs.toronto.edu>

> To allow for future changes in the way the need for duplication is
> detected in R internal C code, package C code should avoid direct
> use of NAMED,and SET_NAMED, or assumptions on the maximal value
> of NAMED. Use the macros MAYBE_REFERENCED, MAYBE_SHARED, and
> MARK_NOT_MUTABLE instead. These currently correspond to
> 
> MAYBE_REFERENCED(x):   NAMED(x) > 0
> MAYBE_SHARED(x):       NAMED(x) > 1
> MARK_NOT_MUTABLE(x):   SET_NAMED(c, NAMEDMAX)
> 
> Best,
> 
> luke


Checking https://cran.r-project.org/doc/manuals/r-release/R-exts.html
shows that currently there is no mention of these macros in the
documentation for package writers.  Of course, the explanation of
NAMED there also does not adequtely describe what it is supposed to
mean, which may explain why it's often not used correctly.

Before embarking on a major change to the C API, I'd suggest that you
produce clear and complete documention on the new scheme.

    Radford Neal


From luke-tierney at uiowa.edu  Sat Sep  2 17:37:04 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sat, 2 Sep 2017 10:37:04 -0500 (CDT)
Subject: [Rd] Please avoid direct use of NAMED and SET_NAMED macros
In-Reply-To: <20170902152042.GA32423@mail.cs.toronto.edu>
References: <mailman.7.1504346401.17359.r-devel@r-project.org>
 <20170902152042.GA32423@mail.cs.toronto.edu>
Message-ID: <alpine.DEB.2.20.1709021034580.30468@luke-Latitude>

On Sat, 2 Sep 2017, Radford Neal wrote:

>> To allow for future changes in the way the need for duplication is
>> detected in R internal C code, package C code should avoid direct
>> use of NAMED,and SET_NAMED, or assumptions on the maximal value
>> of NAMED. Use the macros MAYBE_REFERENCED, MAYBE_SHARED, and
>> MARK_NOT_MUTABLE instead. These currently correspond to
>>
>> MAYBE_REFERENCED(x):   NAMED(x) > 0
>> MAYBE_SHARED(x):       NAMED(x) > 1
>> MARK_NOT_MUTABLE(x):   SET_NAMED(c, NAMEDMAX)
>>
>> Best,
>>
>> luke
>
>
> Checking https://cran.r-project.org/doc/manuals/r-release/R-exts.html
> shows that currently there is no mention of these macros in the
> documentation for package writers.  Of course, the explanation of
> NAMED there also does not adequtely describe what it is supposed to
> mean, which may explain why it's often not used correctly.

As of yesterday they are mentioned in the R-devel version of this
manual, which will make it to the web in due course.

> Before embarking on a major change to the C API, I'd suggest that you
> produce clear and complete documention on the new scheme.
>
>    Radford Neal
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jennifer.s.lyon at gmail.com  Sat Sep  2 20:58:15 2017
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Sat, 2 Sep 2017 12:58:15 -0600
Subject: [Rd] readLines() segfaults on large file & question on how to work
	around
Message-ID: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>

Hi:

I have a 2.1GB JSON file. Typically I use readLines() and
jsonlite:fromJSON() to extract data from a JSON file.

When I try and read in this file using readLines() R segfaults.

I believe the two salient issues with this file are
1). Its size
2). It is a single line (no line breaks)

I can reproduce this issue as follows
#Generate a big file with no line breaks
# In R
> writeLines(paste0(c(letters, 0:9), collapse=""), "alpha.txt", sep="")

# in unix shell
cp alpha.txt file.txt
for i in {1..26}; do cat file.txt file.txt > file2.txt && mv -f file2.txt
file.txt; done

This generates a 2.3GB file with no line breaks

in R:
> moo <- readLines("file.txt")

 *** caught segfault ***
address 0x7cffffff, cause 'memory not mapped'

Traceback:
 1: readLines("file.txt")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 3

I conclude:
 I am potentially running up against a limit in R, which should give a
reasonable error, but currently just segfaults.

My question:
Most of the content of the JSON is an approximately 100K x 6K JSON
equivalent of a dataframe, and I know R can handle much bigger than this
size. I am expecting these JSON files to get even larger. My R code lives
in a bigger system, and the JSON comes in via stdin, so I have absolutely
no control over the data format. I can imagine trying to incrementally
parse the JSON so I don't bump up against the limit, but I am eager for
suggestions of simpler solutions.

Also, I apologize for the timing of this bug report, as I know folks are
working to get out the next release of R, but like so many things I have no
control over when bugs leap up.

Thanks.

Jen

> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: R-3.4.1/lib/libRblas.so
LAPACK:R-3.4.1/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.1

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Sat Sep  2 21:38:16 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 2 Sep 2017 15:38:16 -0400
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
Message-ID: <CA+vqiLHtN7qXzrdhh=+G8ZfPTW7=oLQUCgwFyyvEVS1zoadEOQ@mail.gmail.com>

As s work-around I  suggest readr::read_file.

--Ista


On Sep 2, 2017 2:58 PM, "Jennifer Lyon" <jennifer.s.lyon at gmail.com> wrote:

> Hi:
>
> I have a 2.1GB JSON file. Typically I use readLines() and
> jsonlite:fromJSON() to extract data from a JSON file.
>
> When I try and read in this file using readLines() R segfaults.
>
> I believe the two salient issues with this file are
> 1). Its size
> 2). It is a single line (no line breaks)
>
> I can reproduce this issue as follows
> #Generate a big file with no line breaks
> # In R
> > writeLines(paste0(c(letters, 0:9), collapse=""), "alpha.txt", sep="")
>
> # in unix shell
> cp alpha.txt file.txt
> for i in {1..26}; do cat file.txt file.txt > file2.txt && mv -f file2.txt
> file.txt; done
>
> This generates a 2.3GB file with no line breaks
>
> in R:
> > moo <- readLines("file.txt")
>
>  *** caught segfault ***
> address 0x7cffffff, cause 'memory not mapped'
>
> Traceback:
>  1: readLines("file.txt")
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 3
>
> I conclude:
>  I am potentially running up against a limit in R, which should give a
> reasonable error, but currently just segfaults.
>
> My question:
> Most of the content of the JSON is an approximately 100K x 6K JSON
> equivalent of a dataframe, and I know R can handle much bigger than this
> size. I am expecting these JSON files to get even larger. My R code lives
> in a bigger system, and the JSON comes in via stdin, so I have absolutely
> no control over the data format. I can imagine trying to incrementally
> parse the JSON so I don't bump up against the limit, but I am eager for
> suggestions of simpler solutions.
>
> Also, I apologize for the timing of this bug report, as I know folks are
> working to get out the next release of R, but like so many things I have no
> control over when bugs leap up.
>
> Thanks.
>
> Jen
>
> > sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
>
> Matrix products: default
> BLAS: R-3.4.1/lib/libRblas.so
> LAPACK:R-3.4.1/lib/libRlapack.so
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jennifer.s.lyon at gmail.com  Sat Sep  2 23:15:35 2017
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Sat, 2 Sep 2017 15:15:35 -0600
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CA+vqiLHtN7qXzrdhh=+G8ZfPTW7=oLQUCgwFyyvEVS1zoadEOQ@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
 <CA+vqiLHtN7qXzrdhh=+G8ZfPTW7=oLQUCgwFyyvEVS1zoadEOQ@mail.gmail.com>
Message-ID: <CAKstpn7nc8Ln_mMFMMjjt4RBekbYe4y3XP9RsB29Np03dafn=w@mail.gmail.com>

Thank you for your suggestion. Unfortunately, while R doesn't segfault
calling readr::read_file() on the test file I described, I get the error
message:

Error in read_file_(ds, locale) : negative length vectors are not allowed

Jen

On Sat, Sep 2, 2017 at 1:38 PM, Ista Zahn <istazahn at gmail.com> wrote:

> As s work-around I  suggest readr::read_file.
>
> --Ista
>
>
> On Sep 2, 2017 2:58 PM, "Jennifer Lyon" <jennifer.s.lyon at gmail.com> wrote:
>
>> Hi:
>>
>> I have a 2.1GB JSON file. Typically I use readLines() and
>> jsonlite:fromJSON() to extract data from a JSON file.
>>
>> When I try and read in this file using readLines() R segfaults.
>>
>> I believe the two salient issues with this file are
>> 1). Its size
>> 2). It is a single line (no line breaks)
>>
>> I can reproduce this issue as follows
>> #Generate a big file with no line breaks
>> # In R
>> > writeLines(paste0(c(letters, 0:9), collapse=""), "alpha.txt", sep="")
>>
>> # in unix shell
>> cp alpha.txt file.txt
>> for i in {1..26}; do cat file.txt file.txt > file2.txt && mv -f file2.txt
>> file.txt; done
>>
>> This generates a 2.3GB file with no line breaks
>>
>> in R:
>> > moo <- readLines("file.txt")
>>
>>  *** caught segfault ***
>> address 0x7cffffff, cause 'memory not mapped'
>>
>> Traceback:
>>  1: readLines("file.txt")
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection: 3
>>
>> I conclude:
>>  I am potentially running up against a limit in R, which should give a
>> reasonable error, but currently just segfaults.
>>
>> My question:
>> Most of the content of the JSON is an approximately 100K x 6K JSON
>> equivalent of a dataframe, and I know R can handle much bigger than this
>> size. I am expecting these JSON files to get even larger. My R code lives
>> in a bigger system, and the JSON comes in via stdin, so I have absolutely
>> no control over the data format. I can imagine trying to incrementally
>> parse the JSON so I don't bump up against the limit, but I am eager for
>> suggestions of simpler solutions.
>>
>> Also, I apologize for the timing of this bug report, as I know folks are
>> working to get out the next release of R, but like so many things I have
>> no
>> control over when bugs leap up.
>>
>> Thanks.
>>
>> Jen
>>
>> > sessionInfo()
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>>
>> Matrix products: default
>> BLAS: R-3.4.1/lib/libRblas.so
>> LAPACK:R-3.4.1/lib/libRlapack.so
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.1
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Sat Sep  2 23:37:48 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 2 Sep 2017 23:37:48 +0200
Subject: [Rd] I have corrected a dead link in the treering documentation
In-Reply-To: <20170901132354.0C65C7E271@mailuser.nyi.internal>
References: <20170728185317.E246C7E65E@mailuser.nyi.internal>
 <22953.2920.615673.556828@stat.math.ethz.ch>
 <20170901132354.0C65C7E271@mailuser.nyi.internal>
Message-ID: <22955.9388.397636.789213@stat.math.ethz.ch>

>>>>> Thomas Levine <_ at thomaslevine.com>
>>>>>     on Fri, 1 Sep 2017 13:23:47 +0000 writes:

    > Martin Maechler writes:
    >> There may be one small problem: IIUC, the wayback machine
    >> is a +- private endeavor and really great and phantastic
    >> but it does need (US? tax deductible) donations,
    >> https://archive.org/donate/, to continue thriving.  This
    >> makes me hesitate a bit to link to it within the "base R"
    >> documentation.  But that may be wrong -- and I should
    >> really use it to *help* the project ?

    > I agree that the Wayback Machine is a private
    > endeavor. After reviewing other base library
    > documentation, I have concluded that it would regardless
    > be consistent with current practice to reference it in the
    > base documentation.

    > I share your concern regarding the support of other
    > institutions, and I have found some references that are
    > more problematic to me than the one of present interest. I
    > would thus support an initiative to consider the social
    > implications of the different references and to adjust the
    > references accordingly.

    > Below I start by making a distinction between two types of
    > references that I think should be treated differently in
    > terms of your concern.  Next, I assess whether there is a
    > precedent for inclusion of references to private
    > publishers, as in the present patch; I include that there
    > is such a president. Then I present my opinion regarding
    > the present patch. Finally, I present some other
    > considerations that I find relevant to the discussion.

    > Distinguishing between two link types
    > -------------------------------------
    > For discussion of this issue, I think it is helpful to
    > distinguish between references to sources and references
    > to other materials.

    > In the case of references of to sources, there is little
    > choice but to reference the publisher, even though the
    > overwhelming majority of referenced publishers are private
    > companies that impose restrictive licenses on their
    > journals and books and cannot be reasonably trusted to
    > maintain access to the materials nor availability of
    > webpages.

    > With other references, it is possible to replace the
    > reference with a different document that contains similar
    > information.

    > For example, if a function implements an method based on a
    > particular journal article, that article's citation needs
    > to stay, even if the journal is published by a private
    > institution. On the other hand, if the reference just
    > provides context or suggestions related to usage, then the
    > reference is provided just as information and can be
    > replaced.

    > Precedent for inclusion of private non-source materials
    > -------------------------------------------------------
    > The dead link of interest is only informational, not a
    > citation of a source, and so it could be replaced. So I
    > assessed whether it would match current practice to
    > include it, and I concluded that there is substantial
    > precedent for inclusion of private reference materials
    > other than strict sources. Not having access to a good
    > library at the moment, I have limited my research on this
    > matter to website references.

    > In SVN revision 73164, \url calls are distributed among
    > 148 files, from 1 call to 13 calls per file, with mean of
    > 1.75 and median of 1.

    >   grep '\\url' src/library/*/*/*.Rd | cut -d: -f1 | uniq
    > -c | sort -n

    > Total number of library documentation files is 1419.

    >   find src/library/ -name \*.Rd | wc -l

    > I randomly selected 20 matching files for further study.

    >   % grep '\\url' src/library/*/*/*.Rd | cut -d: -f1 | uniq
    > -c | sort -R | head -n 20 | tee /tmp/rd 2
    > src/library/grDevices/man/pdf.Rd 1
    > src/library/base/man/taskCallbackNames.Rd 1
    > src/library/stats/man/shapiro.test.Rd 1
    > src/library/tcltk/man/TkWidgets.Rd 2
    > src/library/graphics/man/assocplot.Rd 1
    > src/library/base/man/sprintf.Rd 6
    > src/library/base/man/regex.Rd 3
    > src/library/datasets/man/HairEyeColor.Rd 1
    > src/library/stats/man/optimize.Rd 1
    > src/library/datasets/man/UKDriverDeaths.Rd 1
    > src/library/utils/man/object.size.Rd 1
    > src/library/utils/man/unzip.Rd 1
    > src/library/base/man/dcf.Rd 1
    > src/library/base/man/DateTimeClasses.Rd 3
    > src/library/stats/man/GammaDist.Rd 2
    > src/library/utils/man/maintainer.Rd 2
    > src/library/base/man/libcurlVersion.Rd 2
    > src/library/base/man/eigen.Rd 2
    > src/library/base/man/chol2inv.Rd 1
    > src/library/tools/man/update_pkg_po.Rd

    >> From these 20 I composed a table with statistical unit of
    >> \url call and
    > with variables filename, url, type of reference, and type
    > of publisher.  The following commands were helpful.

    >   sed -e 's/^[ 0-9]*//' /tmp/rd | xargs grep \\\\url | sed
    > -e 's/$/::/' -e 's/:.*\\url./:/' > urls.csv sed 's/^[
    > 0-9]*//' /tmp/rd | xargs grep -A5 -B5 \\\\url | less

    > I realized that I need to be a bit more precise about what
    > I mean by a "source". I wound up grouping the type of
    > reference for \url calls into the following categories.

    > 1 Necessary sources, such as the specific file from which
    > an algorithm or dataset was copied (as in
    > stats/man/optimize.Rd) 2 Upstream documentation for bound
    > libraries (tcltk/man/TkWidgets.Rd) 3 Extra information,
    > such as tutorials on portable programming referenced in
    > base/man/sprintf.Rd 4 Ambiguous, such as an general
    > introduction on the topic that may have been used during
    > the development of the function or may have been added
    > just as further documentation (as in
    > grDevices/man/pdf.Rd).  These references did not include
    > the date on which the webpage was accessed, so they aren't
    > clear enough to count as source references even if they
    > were in fact used during the development of the function.
    > 5 Comments (stats/man/shapiro.test.Rd) and duplicates
    > (stats/man/GammaDist.Rd)

    > Earlier, I distinguished between references to sources and
    > references to other materials. I think that the first and
    > second categories should be considered the source type
    > references and the third and fourth should be considered
    > the non-source type references.

    > I separated publisher types into the following

    > * academic (I think that they were all public
    > universities, but I did not check very thoroughly.)  *
    > government * private * R project

    > Resulting categorization was as follows (attached urls.csv
    > and urls.r).

    >              publisher source academic government private
    > r-project 1 necessary 8 0 5 3 2 upstream 3 0 6 0 3 extra 0
    > 0 1 1 4 ambiguous 0 1 4 0 5 ignore 0 1 1 1

    > The references of concern are the replaceable sources
    > (types 3 and 4) to private publishers, which account for 5
    > out of the 35 \url calls and 5 of the 20 files. To fit the
    > table in an email, I have truncated the URLs to their
    > domains.

    >                              filename domain
    > src/library/grDevices/man/pdf.Rd en.wikipedia.org
    > src/library/base/man/sprintf.Rd developer.r-project.org
    > src/library/base/man/regex.Rd perldoc.perl.org
    > src/library/utils/man/object.size.Rd en.wikipedia.org
    > src/library/stats/man/GammaDist.Rd en.wikipedia.org

    > Note that the sprintf documentation is in fact a link to
    > an r-project page
    > (https://developer.r-project.org/Portability.html) that
    > has lots of other links on it, including links to
    > fortran.com, en.wikipedia.org, pubs.opengroup.org, and
    > people.redhat.com.

    > So we see that several \url calls reference private
    > publishers even though the links could be replaced with
    > alternatives. By my categorization, 5 out of 20 sampled
    > files (95% confidence interval of 9 files to 65 files of
    > the population of 148 matching files, based on a bespoke
    > t-test with finite population correction because I had
    > trouble compiling the sampling package, see urls.r)
    > include a replaceable reference to a private publisher.

    > I briefly looked through the full population of Rd files,
    > and I got the impression that this sort of private
    > reference may be restricted to a just a few publishers,
    > with Wikimedia possibly being the most prominent.

    > To summarize, several other documentation files already
    > reference private publishers, and the set of publishers is
    > small enough that it would be feasible to review each
    > publisher in order consider whether the references to it
    > should replaced with alternatives.

    > Opinion regarding the present patch
    > -----------------------------------
    > I think that linking to the Wayback Machine, by the
    > Internet Archive, is consistent with the practice in many
    > other base libraries and that it is thus acceptable.

    > At present, base makes no references to the Wayback
    > Machine but makes several references to English
    > Wikipedia. An even more consistent option is thus to link
    > to the English Wikipedia article for Great Basin
    > bristlecone pine
    > (https://en.wikipedia.org/wiki/Pinus_longaeva) or for
    > Methuselah
    > (https://en.wikipedia.org/wiki/Methuselah_(tree)) instead
    > of the Wayback Machine page that I reference in the
    > patch. (Note that the treering data are from a tree in the
    > Methuselah Walk but not from Methuselah itself.)

    > On the other hand, if we are to avoid referencing private
    > institutions unnecessarily, we should create a broader
    > initiative to replace private non-source references in
    > base documentation. For me, more worrisome than references
    > to the Open Group or to Wikimedia are the references to
    > the private company GitHub, as in utils/man/tar.Rd; aside
    > from the social implications of supporting a private
    > company whose repository hosting service has been accessed
    > by the Free Software Foundation as unethical
    > (https://www.gnu.org/software/repo-criteria-evaluation.html),
    > I do not even trust in the long-term availability of its
    > webpages.

    > And of course, if we do not correct the dead link in
    > treering, I think we should remove the dead link. We can
    > optionally replace it with a very short description of
    > Great Basin bristlecone pines.

    > Further discussion
    > ------------------

    > RESTRICTION CRITERIA

    > If R is to have formal restrictions as to what sorts of
    > references may be included in the base documentation, I
    > think that private versus public is not an appropriate
    > criterion.

I was not at all aiming for formal restrictions... I'm sorry if
what I said looked like that.

One reason for not using internet archive links would be that
they are "somewhat costly" for the archive itself, because often
"serving the URL" may be a somewhat expensive data base access
.. and as I said they are not a big fat company with lots of
resources.

Anyway you've made your very good points,
and also for reason of efficiency on this list, I've committed
your proposed change ... with thanks to you.

Martin


    > To start, private universities may be similarly
    > acceptable to public universities, and certain government
    > institutions may be problematic. Also, most of the present
    > references to software specifications refer to private
    > institutions.  Considering the goals of the R project and
    > its status as a component of the GNU project, I think that
    > it would make more sense for the criteria to be based on
    > the license of the referenced work, rather than on
    > characteristics of the legal entity that has published it.

    > AVOIDING LINKS

    > For practical reasons, I think it would be nice to avoid
    > the sort of link that we are presently discussing and
    > instead to distribute the contents of that link. If the
    > contents are incorporated into R, then dead links are not
    > an issue, we are free to edit the extra documentation that
    > otherwise would have been linked, and users can view the
    > documentation without a internet connection. I think that
    > the datasets documentation, in particular, could benefit
    > substantially from a few sentences of context being added
    > to each documentation file.

    > That said, it is possible that this would be enough work
    > that it would not be worthwhile; this extra documentation
    > could easily become much larger than the rest of the R
    > source code, especially if images are included as in the
    > case of the Methuselah Walk photographs, so implementing
    > this would be more involved than simply obtaining
    > acceptable licenses on the extra documentation and copying
    > passages to Rd files.


From i.ucar86 at gmail.com  Sun Sep  3 01:18:51 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Sun, 3 Sep 2017 01:18:51 +0200
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
Message-ID: <CALEXWq150zrG0Ao7c4OBW-Ju=v7zER2RaT6A=Rahq+b1=nLEtQ@mail.gmail.com>

2017-09-02 20:58 GMT+02:00 Jennifer Lyon <jennifer.s.lyon at gmail.com>:
> Hi:
>
> I have a 2.1GB JSON file. Typically I use readLines() and
> jsonlite:fromJSON() to extract data from a JSON file.
>
> When I try and read in this file using readLines() R segfaults.
>
> I believe the two salient issues with this file are
> 1). Its size
> 2). It is a single line (no line breaks)

As a workaround you can pipe something like "sed s/,/,\\n/g" before
your R script to insert line breaks.

I?aki


From msuzen at gmail.com  Sun Sep  3 01:27:43 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sun, 3 Sep 2017 01:27:43 +0200
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CAKstpn7nc8Ln_mMFMMjjt4RBekbYe4y3XP9RsB29Np03dafn=w@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
 <CA+vqiLHtN7qXzrdhh=+G8ZfPTW7=oLQUCgwFyyvEVS1zoadEOQ@mail.gmail.com>
 <CAKstpn7nc8Ln_mMFMMjjt4RBekbYe4y3XP9RsB29Np03dafn=w@mail.gmail.com>
Message-ID: <CAPtbhHzdsazu=KHsRUrVtAhc7UwbQw4JD=UP64wQ4H_j_4Wfng@mail.gmail.com>

Jennifer, Why do you try Sparkr?

https://spark.apache.org/docs/1.6.1/api/R/read.json.html

On 2 September 2017 at 23:15, Jennifer Lyon <jennifer.s.lyon at gmail.com> wrote:
> Thank you for your suggestion. Unfortunately, while R doesn't segfault
> calling readr::read_file() on the test file I described, I get the error
> message:
>
> Error in read_file_(ds, locale) : negative length vectors are not allowed
>
> Jen
>
> On Sat, Sep 2, 2017 at 1:38 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> As s work-around I  suggest readr::read_file.
>>
>> --Ista
>>
>>
>> On Sep 2, 2017 2:58 PM, "Jennifer Lyon" <jennifer.s.lyon at gmail.com> wrote:
>>
>>> Hi:
>>>
>>> I have a 2.1GB JSON file. Typically I use readLines() and
>>> jsonlite:fromJSON() to extract data from a JSON file.
>>>
>>> When I try and read in this file using readLines() R segfaults.
>>>
>>> I believe the two salient issues with this file are
>>> 1). Its size
>>> 2). It is a single line (no line breaks)
>>>
>>> I can reproduce this issue as follows
>>> #Generate a big file with no line breaks
>>> # In R
>>> > writeLines(paste0(c(letters, 0:9), collapse=""), "alpha.txt", sep="")
>>>
>>> # in unix shell
>>> cp alpha.txt file.txt
>>> for i in {1..26}; do cat file.txt file.txt > file2.txt && mv -f file2.txt
>>> file.txt; done
>>>
>>> This generates a 2.3GB file with no line breaks
>>>
>>> in R:
>>> > moo <- readLines("file.txt")
>>>
>>>  *** caught segfault ***
>>> address 0x7cffffff, cause 'memory not mapped'
>>>
>>> Traceback:
>>>  1: readLines("file.txt")
>>>
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> Selection: 3
>>>
>>> I conclude:
>>>  I am potentially running up against a limit in R, which should give a
>>> reasonable error, but currently just segfaults.
>>>
>>> My question:
>>> Most of the content of the JSON is an approximately 100K x 6K JSON
>>> equivalent of a dataframe, and I know R can handle much bigger than this
>>> size. I am expecting these JSON files to get even larger. My R code lives
>>> in a bigger system, and the JSON comes in via stdin, so I have absolutely
>>> no control over the data format. I can imagine trying to incrementally
>>> parse the JSON so I don't bump up against the limit, but I am eager for
>>> suggestions of simpler solutions.
>>>
>>> Also, I apologize for the timing of this bug report, as I know folks are
>>> working to get out the next release of R, but like so many things I have
>>> no
>>> control over when bugs leap up.
>>>
>>> Thanks.
>>>
>>> Jen
>>>
>>> > sessionInfo()
>>> R version 3.4.1 (2017-06-30)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 14.04.5 LTS
>>>
>>> Matrix products: default
>>> BLAS: R-3.4.1/lib/libRblas.so
>>> LAPACK:R-3.4.1/lib/libRlapack.so
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.1
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Sun Sep  3 10:15:29 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sun, 3 Sep 2017 10:15:29 +0200
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
Message-ID: <CABFfbXuoMGTX4XSkOK0A=f6GSjCaBLr0s0EXiMbHB=Z8gF9+EQ@mail.gmail.com>

On Sat, Sep 2, 2017 at 8:58 PM, Jennifer Lyon <jennifer.s.lyon at gmail.com> wrote:
> I have a 2.1GB JSON file. Typically I use readLines() and
> jsonlite:fromJSON() to extract data from a JSON file.

If your data consists of one json object per line, this is called
'ndjson'. There are several packages specialized to read ndjon files:

 - corpus::read_ndjson
 - ndjson::stream_in
 - jsonlite::stream_in

In particular the 'corpus' package handles large files really well
because it has an option to memory-map the file instead of reading all
of its data into memory.

If the data is too large to read, you can preprocess it using
https://stedolan.github.io/jq/ to extract the fields that you need.

You really don't need hadoop/spark/etc for this.


From jennifer.s.lyon at gmail.com  Sun Sep  3 20:50:49 2017
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Sun, 3 Sep 2017 12:50:49 -0600
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CABFfbXuoMGTX4XSkOK0A=f6GSjCaBLr0s0EXiMbHB=Z8gF9+EQ@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
 <CABFfbXuoMGTX4XSkOK0A=f6GSjCaBLr0s0EXiMbHB=Z8gF9+EQ@mail.gmail.com>
Message-ID: <CAKstpn6w=bovKYk_3Sbg3Ri4MJGtM1gY6o4z_1d4MBOQ0pLmug@mail.gmail.com>

Jeroen:

Thank you for pointing me to ndjson, which I had not heard of and is
exactly my case.

My experience:
jsonlite::stream_in - segfaults
ndjson::stream_in - my fault, I am running Ubuntu 14.04 and it is too old
      so it won't compile the package
corpus::read_ndjson - works!!! Of course it does a different simplification
     than jsonlite::fromJSON, so I have to change some code, but it works
     beautifully at least in simple tests. The memory-map option may be of
     use in the future.

Another correspondent said that strings in R can only be 2^31-1 long, which
is why any "solution" that tries to load the whole file into R first as a
string, will fail.

Thanks for suggesting a path forward for me!

Jen

On Sun, Sep 3, 2017 at 2:15 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> On Sat, Sep 2, 2017 at 8:58 PM, Jennifer Lyon <jennifer.s.lyon at gmail.com>
> wrote:
> > I have a 2.1GB JSON file. Typically I use readLines() and
> > jsonlite:fromJSON() to extract data from a JSON file.
>
> If your data consists of one json object per line, this is called
> 'ndjson'. There are several packages specialized to read ndjon files:
>
>  - corpus::read_ndjson
>  - ndjson::stream_in
>  - jsonlite::stream_in
>
> In particular the 'corpus' package handles large files really well
> because it has an option to memory-map the file instead of reading all
> of its data into memory.
>
> If the data is too large to read, you can preprocess it using
> https://stedolan.github.io/jq/ to extract the fields that you need.
>
> You really don't need hadoop/spark/etc for this.
>

	[[alternative HTML version deleted]]


From rhelp at eoos.dds.nl  Mon Sep  4 08:46:58 2017
From: rhelp at eoos.dds.nl (rhelp at eoos.dds.nl)
Date: Mon, 4 Sep 2017 08:46:58 +0200
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <CAKstpn6w=bovKYk_3Sbg3Ri4MJGtM1gY6o4z_1d4MBOQ0pLmug@mail.gmail.com>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
 <CABFfbXuoMGTX4XSkOK0A=f6GSjCaBLr0s0EXiMbHB=Z8gF9+EQ@mail.gmail.com>
 <CAKstpn6w=bovKYk_3Sbg3Ri4MJGtM1gY6o4z_1d4MBOQ0pLmug@mail.gmail.com>
Message-ID: <91a8751a-7092-c4ae-2e7f-7ff1eebe13ea@dds.nl>

Although the problem can apparently be avoided in this case. readLines 
causing a segfault still seems unwanted behaviour to me. I can replicate 
this with the example below (sessionInfo is further down):


# Generate an example file
l <- paste0(sample(c(letters, LETTERS), 1E6, replace = TRUE),
   collapse="")
con <- file("test.txt", "wt")
for (i in seq_len(2500)) {
   writeLines(l, con, sep ="")
}
close(con)


# Causes segfault:
readLines("test.txt")

Also the error reported by readr is also reproduced (a more informative 
error message and checking for integer overflows would be nice). I will 
report this with readr.

library(readr)
read_file("test.txt")
# Error in read_file_(ds, locale) : negative length vectors are not
# allowed


--
Jan








 > sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.04

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.7.0
LAPACK: /usr/lib/lapack/liblapack.so.3.7.0

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
LC_TIME=nl_NL.UTF-8
  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=nl_NL.UTF-8 
LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=nl_NL.UTF-8       LC_NAME=C                  LC_ADDRESS=C 

[10] LC_TELEPHONE=C             LC_MEASUREMENT=nl_NL.UTF-8 
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] readr_1.1.1

loaded via a namespace (and not attached):
[1] compiler_3.4.1 R6_2.2.2       hms_0.3        tools_3.4.1 
tibble_1.3.3   Rcpp_0.12.12   rlang_0.1.2







On 03-09-17 20:50, Jennifer Lyon wrote:
> Jeroen:
> 
> Thank you for pointing me to ndjson, which I had not heard of and is
> exactly my case.
> 
> My experience:
> jsonlite::stream_in - segfaults
> ndjson::stream_in - my fault, I am running Ubuntu 14.04 and it is too old
>        so it won't compile the package
> corpus::read_ndjson - works!!! Of course it does a different simplification
>       than jsonlite::fromJSON, so I have to change some code, but it works
>       beautifully at least in simple tests. The memory-map option may be of
>       use in the future.
> 
> Another correspondent said that strings in R can only be 2^31-1 long, which
> is why any "solution" that tries to load the whole file into R first as a
> string, will fail.
> 
> Thanks for suggesting a path forward for me!
> 
> Jen
> 
> On Sun, Sep 3, 2017 at 2:15 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> 
>> On Sat, Sep 2, 2017 at 8:58 PM, Jennifer Lyon <jennifer.s.lyon at gmail.com>
>> wrote:
>>> I have a 2.1GB JSON file. Typically I use readLines() and
>>> jsonlite:fromJSON() to extract data from a JSON file.
>>
>> If your data consists of one json object per line, this is called
>> 'ndjson'. There are several packages specialized to read ndjon files:
>>
>>   - corpus::read_ndjson
>>   - ndjson::stream_in
>>   - jsonlite::stream_in
>>
>> In particular the 'corpus' package handles large files really well
>> because it has an option to memory-map the file instead of reading all
>> of its data into memory.
>>
>> If the data is too large to read, you can preprocess it using
>> https://stedolan.github.io/jq/ to extract the fields that you need.
>>
>> You really don't need hadoop/spark/etc for this.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jtelleriar at gmail.com  Sun Sep  3 20:38:11 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Sun, 3 Sep 2017 20:38:11 +0200
Subject: [Rd] Suggestion: Create On-Disk Dataframes
In-Reply-To: <CANNd7=nsbOv53+vPYrfyeP5tUgnzEFJe0pb5sW5iOxmSz-+1iw@mail.gmail.com>
References: <CANNd7=nZ1HSSv9WrQ7Zqnqtby0kUGGMSDAj8e0WFZCJ46xS3pw@mail.gmail.com>
 <CANNd7=n4SZTy1TO2B=wk3SLBh0SuC-wrcJDfBVLbdFYxeeEfgQ@mail.gmail.com>
 <CANNd7=nO2c0jzFBBLmsKYubBA87wqxMPtU3uv3JuzrUaVtj0pA@mail.gmail.com>
 <CANNd7=kYm9O0y4SJbRxpDWR_8BFYRruatCd_BP_RXWf+bdrw7A@mail.gmail.com>
 <CANNd7==4bmosbdRzuNwn3kORYRWivbi0T885s6t+TWCR4oRefQ@mail.gmail.com>
 <CANNd7=nyvPMx9myXrox0=KU-v6hB_pTg-j5gpj_+18K31uBRqg@mail.gmail.com>
 <CANNd7=n3x-y9dV2==-uiCu7MCMcWEiPES3TfoFi-m6JbLWHqTw@mail.gmail.com>
 <CANNd7=nsOBSRt0tmzpLyvf9q2a6RrvhwbHcQAJvCagZi28L6Ng@mail.gmail.com>
 <CANNd7=kg1z6rpC83QEQ8GamS4jSaWJT0Bs2aotq=_TDgyFwrBA@mail.gmail.com>
 <CANNd7=m3kMV+3ny0t5d-8m3XVj1dZKXNkrimS28UAVSHOMTiPw@mail.gmail.com>
 <CANNd7==GsZyquFb+dVx_GGnrGdpC6KgK=xp_apNp5jp0tHUBAg@mail.gmail.com>
 <CANNd7=nsbOv53+vPYrfyeP5tUgnzEFJe0pb5sW5iOxmSz-+1iw@mail.gmail.com>
Message-ID: <CANNd7=n0Eq0jytoaxxFJeWU8uonxivfHSDbp7-fw0=_AwHFiDQ@mail.gmail.com>

Dear R Developers,

I would like to suggest the creation of a new S4 object class for On-Disk
data.frames which do not fit in RAM memory, which could be called
disk.data.frame()

It could be based in rsqlite for example (By translating R syntax to SQL
syntax for example), and the syntax and way of working of the
disk.data.frame() class could be exactly the same than with data.frame
objects.

When the session is of, is such disk.data.frames are not saved, and
implicit DROP TABLE could be done in all the schemas created in rsqlite.

Nowadays, with the SSD disk drives such new data.frame() class could have
sense, specially when dealing with Big Data.

It is true that this new class might be slower than regular data.frame,
data.table or tibble classes, but we would be able to handle much more
data, even if it is at cost of speed.

Also with data sampling, and use of a regular odbc connection we could do
all the work, but for people who do not know how to use RDBMS or specific
purpose R packages for this job, this could work.

Another option would be to base this new S4 class  on feather files, but
maybe making it with rsqlite is simply easier.

A GitHub project could be created for such purpose, so that all the
community can contribute (included me :D ).

Thank you,
Juan

	[[alternative HTML version deleted]]


From msuzen at gmail.com  Mon Sep  4 11:35:34 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 4 Sep 2017 11:35:34 +0200
Subject: [Rd] Suggestion: Create On-Disk Dataframes
In-Reply-To: <CANNd7=n0Eq0jytoaxxFJeWU8uonxivfHSDbp7-fw0=_AwHFiDQ@mail.gmail.com>
References: <CANNd7=nZ1HSSv9WrQ7Zqnqtby0kUGGMSDAj8e0WFZCJ46xS3pw@mail.gmail.com>
 <CANNd7=n4SZTy1TO2B=wk3SLBh0SuC-wrcJDfBVLbdFYxeeEfgQ@mail.gmail.com>
 <CANNd7=nO2c0jzFBBLmsKYubBA87wqxMPtU3uv3JuzrUaVtj0pA@mail.gmail.com>
 <CANNd7=kYm9O0y4SJbRxpDWR_8BFYRruatCd_BP_RXWf+bdrw7A@mail.gmail.com>
 <CANNd7==4bmosbdRzuNwn3kORYRWivbi0T885s6t+TWCR4oRefQ@mail.gmail.com>
 <CANNd7=nyvPMx9myXrox0=KU-v6hB_pTg-j5gpj_+18K31uBRqg@mail.gmail.com>
 <CANNd7=n3x-y9dV2==-uiCu7MCMcWEiPES3TfoFi-m6JbLWHqTw@mail.gmail.com>
 <CANNd7=nsOBSRt0tmzpLyvf9q2a6RrvhwbHcQAJvCagZi28L6Ng@mail.gmail.com>
 <CANNd7=kg1z6rpC83QEQ8GamS4jSaWJT0Bs2aotq=_TDgyFwrBA@mail.gmail.com>
 <CANNd7=m3kMV+3ny0t5d-8m3XVj1dZKXNkrimS28UAVSHOMTiPw@mail.gmail.com>
 <CANNd7==GsZyquFb+dVx_GGnrGdpC6KgK=xp_apNp5jp0tHUBAg@mail.gmail.com>
 <CANNd7=nsbOv53+vPYrfyeP5tUgnzEFJe0pb5sW5iOxmSz-+1iw@mail.gmail.com>
 <CANNd7=n0Eq0jytoaxxFJeWU8uonxivfHSDbp7-fw0=_AwHFiDQ@mail.gmail.com>
Message-ID: <CAPtbhHxgyZxpXBQKKSTPyGSZBMa-YiyHgQibcmSG-uNT65s3Ew@mail.gmail.com>

It is not needed. There is a large community of developer using SparkR.
https://spark.apache.org/docs/latest/sparkr.html
It does exactly what you want.

On 3 September 2017 at 20:38, Juan Telleria <jtelleriar at gmail.com> wrote:
> Dear R Developers,
>
> I would like to suggest the creation of a new S4 object class for On-Disk
> data.frames which do not fit in RAM memory, which could be called
> disk.data.frame()
>
> It could be based in rsqlite for example (By translating R syntax to SQL
> syntax for example), and the syntax and way of working of the
> disk.data.frame() class could be exactly the same than with data.frame
> objects.
>
> When the session is of, is such disk.data.frames are not saved, and
> implicit DROP TABLE could be done in all the schemas created in rsqlite.
>
> Nowadays, with the SSD disk drives such new data.frame() class could have
> sense, specially when dealing with Big Data.
>
> It is true that this new class might be slower than regular data.frame,
> data.table or tibble classes, but we would be able to handle much more
> data, even if it is at cost of speed.
>
> Also with data sampling, and use of a regular odbc connection we could do
> all the work, but for people who do not know how to use RDBMS or specific
> purpose R packages for this job, this could work.
>
> Another option would be to base this new S4 class  on feather files, but
> maybe making it with rsqlite is simply easier.
>
> A GitHub project could be created for such purpose, so that all the
> community can contribute (included me :D ).
>
> Thank you,
> Juan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Mon Sep  4 13:36:55 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 4 Sep 2017 13:36:55 +0200
Subject: [Rd] readLines() segfaults on large file & question on how to
 work around
In-Reply-To: <91a8751a-7092-c4ae-2e7f-7ff1eebe13ea@dds.nl>
References: <CAKstpn6YTRRRjr=GVUv3o9u9PzftHPn9AVSTfXAss50YwBjBYA@mail.gmail.com>
 <CABFfbXuoMGTX4XSkOK0A=f6GSjCaBLr0s0EXiMbHB=Z8gF9+EQ@mail.gmail.com>
 <CAKstpn6w=bovKYk_3Sbg3Ri4MJGtM1gY6o4z_1d4MBOQ0pLmug@mail.gmail.com>
 <91a8751a-7092-c4ae-2e7f-7ff1eebe13ea@dds.nl>
Message-ID: <a048defd-4a61-2fd3-ed98-06d7b83f4509@gmail.com>

As of R-devel 72925 one gets a proper error message instead of the crash.

Tomas


On 09/04/2017 08:46 AM, rhelp at eoos.dds.nl wrote:
> Although the problem can apparently be avoided in this case. readLines 
> causing a segfault still seems unwanted behaviour to me. I can 
> replicate this with the example below (sessionInfo is further down):
>
>
> # Generate an example file
> l <- paste0(sample(c(letters, LETTERS), 1E6, replace = TRUE),
>   collapse="")
> con <- file("test.txt", "wt")
> for (i in seq_len(2500)) {
>   writeLines(l, con, sep ="")
> }
> close(con)
>
>
> # Causes segfault:
> readLines("test.txt")
>
> Also the error reported by readr is also reproduced (a more 
> informative error message and checking for integer overflows would be 
> nice). I will report this with readr.
>
> library(readr)
> read_file("test.txt")
> # Error in read_file_(ds, locale) : negative length vectors are not
> # allowed
>
>
> -- 
> Jan
>
>
>
>
>
>
>
>
> > sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 17.04
>
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.7.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.7.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=nl_NL.UTF-8
>  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=nl_NL.UTF-8 
> LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=nl_NL.UTF-8       LC_NAME=C LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=nl_NL.UTF-8 
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] readr_1.1.1
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 R6_2.2.2       hms_0.3        tools_3.4.1 
> tibble_1.3.3   Rcpp_0.12.12   rlang_0.1.2
>
>
>
>
>
>
>
> On 03-09-17 20:50, Jennifer Lyon wrote:
>> Jeroen:
>>
>> Thank you for pointing me to ndjson, which I had not heard of and is
>> exactly my case.
>>
>> My experience:
>> jsonlite::stream_in - segfaults
>> ndjson::stream_in - my fault, I am running Ubuntu 14.04 and it is too 
>> old
>>        so it won't compile the package
>> corpus::read_ndjson - works!!! Of course it does a different 
>> simplification
>>       than jsonlite::fromJSON, so I have to change some code, but it 
>> works
>>       beautifully at least in simple tests. The memory-map option may 
>> be of
>>       use in the future.
>>
>> Another correspondent said that strings in R can only be 2^31-1 long, 
>> which
>> is why any "solution" that tries to load the whole file into R first 
>> as a
>> string, will fail.
>>
>> Thanks for suggesting a path forward for me!
>>
>> Jen
>>
>> On Sun, Sep 3, 2017 at 2:15 AM, Jeroen Ooms <jeroenooms at gmail.com> 
>> wrote:
>>
>>> On Sat, Sep 2, 2017 at 8:58 PM, Jennifer Lyon 
>>> <jennifer.s.lyon at gmail.com>
>>> wrote:
>>>> I have a 2.1GB JSON file. Typically I use readLines() and
>>>> jsonlite:fromJSON() to extract data from a JSON file.
>>>
>>> If your data consists of one json object per line, this is called
>>> 'ndjson'. There are several packages specialized to read ndjon files:
>>>
>>>   - corpus::read_ndjson
>>>   - ndjson::stream_in
>>>   - jsonlite::stream_in
>>>
>>> In particular the 'corpus' package handles large files really well
>>> because it has an option to memory-map the file instead of reading all
>>> of its data into memory.
>>>
>>> If the data is too large to read, you can preprocess it using
>>> https://stedolan.github.io/jq/ to extract the fields that you need.
>>>
>>> You really don't need hadoop/spark/etc for this.
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Mon Sep  4 14:43:50 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 4 Sep 2017 07:43:50 -0500
Subject: [Rd] Suggestion: Create On-Disk Dataframes
In-Reply-To: <CAPtbhHxgyZxpXBQKKSTPyGSZBMa-YiyHgQibcmSG-uNT65s3Ew@mail.gmail.com>
References: <CANNd7=nZ1HSSv9WrQ7Zqnqtby0kUGGMSDAj8e0WFZCJ46xS3pw@mail.gmail.com>
 <CANNd7=n4SZTy1TO2B=wk3SLBh0SuC-wrcJDfBVLbdFYxeeEfgQ@mail.gmail.com>
 <CANNd7=nO2c0jzFBBLmsKYubBA87wqxMPtU3uv3JuzrUaVtj0pA@mail.gmail.com>
 <CANNd7=kYm9O0y4SJbRxpDWR_8BFYRruatCd_BP_RXWf+bdrw7A@mail.gmail.com>
 <CANNd7==4bmosbdRzuNwn3kORYRWivbi0T885s6t+TWCR4oRefQ@mail.gmail.com>
 <CANNd7=nyvPMx9myXrox0=KU-v6hB_pTg-j5gpj_+18K31uBRqg@mail.gmail.com>
 <CANNd7=n3x-y9dV2==-uiCu7MCMcWEiPES3TfoFi-m6JbLWHqTw@mail.gmail.com>
 <CANNd7=nsOBSRt0tmzpLyvf9q2a6RrvhwbHcQAJvCagZi28L6Ng@mail.gmail.com>
 <CANNd7=kg1z6rpC83QEQ8GamS4jSaWJT0Bs2aotq=_TDgyFwrBA@mail.gmail.com>
 <CANNd7=m3kMV+3ny0t5d-8m3XVj1dZKXNkrimS28UAVSHOMTiPw@mail.gmail.com>
 <CANNd7==GsZyquFb+dVx_GGnrGdpC6KgK=xp_apNp5jp0tHUBAg@mail.gmail.com>
 <CANNd7=nsbOv53+vPYrfyeP5tUgnzEFJe0pb5sW5iOxmSz-+1iw@mail.gmail.com>
 <CANNd7=n0Eq0jytoaxxFJeWU8uonxivfHSDbp7-fw0=_AwHFiDQ@mail.gmail.com>
 <CAPtbhHxgyZxpXBQKKSTPyGSZBMa-YiyHgQibcmSG-uNT65s3Ew@mail.gmail.com>
Message-ID: <22957.19078.986857.731735@bud.eddelbuettel.com>


On 4 September 2017 at 11:35, Suzen, Mehmet wrote:
| It is not needed. There is a large community of developer using SparkR.
| https://spark.apache.org/docs/latest/sparkr.html
| It does exactly what you want.

I hope you are not going to mail a sparkr commercial to this list every day.
As the count is now at two, this may be an excellent good time to stop it.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From frederik at ofb.net  Mon Sep  4 21:48:11 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 4 Sep 2017 12:48:11 -0700
Subject: [Rd] Suggestion: Create On-Disk Dataframes; SparkR
In-Reply-To: <22957.19078.986857.731735@bud.eddelbuettel.com>
References: <CANNd7=nyvPMx9myXrox0=KU-v6hB_pTg-j5gpj_+18K31uBRqg@mail.gmail.com>
 <CANNd7=n3x-y9dV2==-uiCu7MCMcWEiPES3TfoFi-m6JbLWHqTw@mail.gmail.com>
 <CANNd7=nsOBSRt0tmzpLyvf9q2a6RrvhwbHcQAJvCagZi28L6Ng@mail.gmail.com>
 <CANNd7=kg1z6rpC83QEQ8GamS4jSaWJT0Bs2aotq=_TDgyFwrBA@mail.gmail.com>
 <CANNd7=m3kMV+3ny0t5d-8m3XVj1dZKXNkrimS28UAVSHOMTiPw@mail.gmail.com>
 <CANNd7==GsZyquFb+dVx_GGnrGdpC6KgK=xp_apNp5jp0tHUBAg@mail.gmail.com>
 <CANNd7=nsbOv53+vPYrfyeP5tUgnzEFJe0pb5sW5iOxmSz-+1iw@mail.gmail.com>
 <CANNd7=n0Eq0jytoaxxFJeWU8uonxivfHSDbp7-fw0=_AwHFiDQ@mail.gmail.com>
 <CAPtbhHxgyZxpXBQKKSTPyGSZBMa-YiyHgQibcmSG-uNT65s3Ew@mail.gmail.com>
 <22957.19078.986857.731735@bud.eddelbuettel.com>
Message-ID: <20170904194811.GD9002@ofb.net>

What's wrong with SparkR? I never heard of either Spark or SparkR.

For on-disk dataframes there is a package called 'ff'. I looked into
using it, it works well but there are some drawbacks with the
implementation. I think that it should be possible to mmap an object
from disk and use it as a vector, but 'ff' is doing something else:

https://github.com/edwindj/ffbase/issues/52

I think you'd need something called a "weak reference" to do this
properly:

http://homepage.divms.uiowa.edu/~luke/R/references/weakfinex.html

I don't know what SparkR is doing under the hood.

Then again I was mostly interested in having large data sets which
persist across R sessions, while Juan seems to be interested in
supporting data which doesn't fit in RAM. But if something doesn't fit
in RAM, it can be swapped out to disk by the OS, no? So I'm not sure
why you'd want a special interface for that situation, aside from
giving the programmer more control.

Thanks,

Frederick

On Mon, Sep 04, 2017 at 07:43:50AM -0500, Dirk Eddelbuettel wrote:
> 
> On 4 September 2017 at 11:35, Suzen, Mehmet wrote:
> | It is not needed. There is a large community of developer using SparkR.
> | https://spark.apache.org/docs/latest/sparkr.html
> | It does exactly what you want.
> 
> I hope you are not going to mail a sparkr commercial to this list every day.
> As the count is now at two, this may be an excellent good time to stop it.
> 
> Dirk
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tomas.kalibera at gmail.com  Thu Sep  7 15:50:35 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 7 Sep 2017 15:50:35 +0200
Subject: [Rd] strange behaviour read.table and clipboard
In-Reply-To: <2db5f6b0-e83e-3a27-8d0f-37beafa6c47e@gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAAB50@SRVEXCHCM301.precheza.cz>
 <da145467-18b0-bc61-e3b1-6f18281d88ac@gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAABF0@SRVEXCHCM301.precheza.cz>
 <e6fd3266-28fb-6836-40e3-90743aecb2db@atsu.edu>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAAE54@SRVEXCHCM301.precheza.cz>
 <2db5f6b0-e83e-3a27-8d0f-37beafa6c47e@gmail.com>
Message-ID: <b25c5f81-ee3a-0eb1-a60d-149e46a7a419@gmail.com>

Fixed in R-devel 73212 (and 73121).

Best
Tomas

On 08/17/2017 11:58 AM, Tomas Kalibera wrote:
> Thank you for the report, it is a bug in buffering in R (not specific 
> to Windows) and will be fixed.
>
> Best
> Tomas
>
> On 08/17/2017 10:37 AM, PIKAL Petr wrote:
>> Hi
>>
>>> -----Original Message-----
>>> From: Robert Baer [mailto:rbaer at atsu.edu]
>>> Sent: Wednesday, August 16, 2017 3:04 PM
>>> To: PIKAL Petr <petr.pikal at precheza.cz>; Duncan Murdoch
>>> <murdoch.duncan at gmail.com>
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] strange behaviour read.table and clipboard
>>>
>>> You said, "put a name in the cell".  Does that mean you forgot a 
>>> header =
>>> TRUE?
>> No
>>
>> for read.delim header=TRUE is default option.
>>
>> The mentioned issue starts between R-devel r71964 and r73003
>>
>> I cannot narrow this range as I do not have available other versions 
>> between this date range.
>>
>> I tested other read.* functions and all seems to work as expected.
>>
>> The problem is connected **only** with reading from clipboard. Maybe 
>> it is the issue of Windows, but I cannot see anything weird when 
>> copying e.g. from Excel to Notepad
>>
>> Cheers
>> Petr
>>
>>>
>>>
>>> On 8/16/2017 1:25 AM, PIKAL Petr wrote:
>>>> Hi Duncan
>>>>
>>>> The simples spreadsheet is:
>>>>
>>>> Put a name in the cell, let say "a1"
>>>> Put number e.g. 1 below "a1"
>>>> Copy the number to enough rows
>>>> Select this column and press ctrl-c
>>>>
>>>> result is
>>>>
>>>>> temp<- read.delim("clipboard")
>>>>> str(temp)
>>>> 'data.frame':   1513 obs. of  1 variable:
>>>>    $ a1: Factor w/ 2 levels "1","a1": 1 1 1 1 1 1 1 1 1 1 ...
>>>>> which(temp$a1=="a1")
>>>> [1] 1365
>>>> I tested it in vanilla R
>>>>
>>>>> sessionInfo()
>>>> R Under development (unstable) (2017-07-31 r73003)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 10 x64 (build 14393)
>>>>
>>>> Matrix products: default
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=Czech_Czech Republic.1250 LC_CTYPE=Czech_Czech
>>> Republic.1250
>>>> [3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
>>>> [5] LC_TIME=Czech_Czech Republic.1250
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.5.0
>>>> Excel 16 or 15 I am not sure.
>>>>
>>>> R-devel 2015 (69443) works as expected so it started a believe 
>>>> around May
>>> or June this year, when I installed new R version.
>>>> I hope it could help to trace the problem. If I can help any 
>>>> further, let me
>>> know.
>>>> Best regards
>>>> Petr
>>>>
>>>>
>>>>
>>>>> -----Original Message-----
>>>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>>>> Sent: Wednesday, August 16, 2017 12:35 AM
>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>; r-devel at r-project.org
>>>>> Subject: Re: [Rd] strange behaviour read.table and clipboard
>>>>>
>>>>> On 15/08/2017 10:03 AM, PIKAL Petr wrote:
>>>>>> Dear all
>>>>>>
>>>>>> I used to transfer data from excel to R by simple ctrl-c and
>>>>> read.delim("clipboard") construction. I know it is a bad practice 
>>>>> but it is easy
>>>>> and for quick exploratory work it is OK. However after changing to 
>>>>> new R
>>> devel
>>>>> few days ago I encountered weird behaviour. I tried one or two 
>>>>> columns.
>>>>>
>>>>> You haven't posted something that is reproducible.  I don't have 
>>>>> Excel, but I
>>> can
>>>>> cut and paste from Libreoffice, and I don't see this.
>>>>> However, it's not the same spreadsheet as you used, so I wouldn't be
>>>>> comfortable saying I did what you did.
>>>>>
>>>>> Please reduce the size of your spreadsheet if you can, and then post
>>>>> instructions for how to construct it, and what to cut and paste 
>>>>> from it.
>>>>>     Then others can try what you did and see if this is specific 
>>>>> to your machine,
>>> to
>>>>> that particular version of R-devel, to Excel, etc.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>>> In case of 2 columns, header is repeated after 526 items
>>>>>>> mar<-read.delim("clipboard")
>>>>>>> which(mar$a2=="a1")
>>>>>> [1]  525 1051 1577
>>>>>>> diff(which(mar$a2=="a1"))
>>>>>> [1] 526 526
>>>>>> and only first header item is repeated.
>>>>>>
>>>>>> In case of one column, header is repeated after 1107 items
>>>>>>
>>>>>>> mar<-read.delim("clipboard")
>>>>>>> diff(which(mar$a2=="a2"))
>>>>>> [1] 1107 1107
>>>>>>
>>>>>> And all items in object are therefore changed to factor.
>>>>>>
>>>>>> BTW, readxl package works on same excel file smoothly.
>>>>>>
>>>>>> I will try to download the most recent R version to check it, but 
>>>>>> it could
>>> take
>>>>> some time due to our IT issues.
>>>>>> Best regards
>>>>>> Petr
>>>>>>
>>>>>>> version
>>>>>>                  _
>>>>>> platform       x86_64-w64-mingw32
>>>>>> arch           x86_64
>>>>>> os             mingw32
>>>>>> system         x86_64, mingw32
>>>>>> status         Under development (unstable)
>>>>>> major          3
>>>>>> minor          5.0
>>>>>> year           2017
>>>>>> month          07
>>>>>> day            31
>>>>>> svn rev        73003
>>>>>> language       R
>>>>>> version.string R Under development (unstable) (2017-07-31 r73003)
>>>>>> nickname       Unsuffered Consequences
>>>>>>
>>>>>>
>>>>>> ________________________________
>>>>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? 
>>>>>> a jsou
>>>>> ur?eny pouze jeho adres?t?m.
>>>>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>>>>>> neprodlen?
>>>>> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie 
>>>>> vyma?te ze
>>>>> sv?ho syst?mu.
>>>>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>> email
>>>>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi
>>>>> ?i zpo?d?n?m p?enosu e-mailu.
>>>>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o 
>>>>>> uzav?en? smlouvy,
>>> a
>>>>> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? 
>>>>>> p?ijmout;
>>>>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze 
>>>>> strany
>>> p??jemce s
>>>>> dodatkem ?i odchylkou.
>>>>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>>>>>> v?slovn?m
>>>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> spole?nost
>>>>> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
>>>>> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi 
>>>>> tohoto
>>>>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo 
>>>>> jejich
>>>>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>>> This e-mail and any documents attached to it may be confidential 
>>>>>> and are
>>>>> intended only for its intended recipients.
>>>>>> If you received this e-mail by mistake, please immediately inform 
>>>>>> its
>>> sender.
>>>>> Delete the contents of this e-mail with all attachments and its 
>>>>> copies from
>>> your
>>>>> system.
>>>>>> If you are not the intended recipient of this e-mail, you are not 
>>>>>> authorized
>>> to
>>>>> use, disseminate, copy or disclose this e-mail in any manner.
>>>>>> The sender of this e-mail shall not be liable for any possible 
>>>>>> damage caused
>>>>> by modifications of the e-mail or by delay with transfer of the 
>>>>> email.
>>>>>> In case that this e-mail forms part of business dealings:
>>>>>> - the sender reserves the right to end negotiations about 
>>>>>> entering into a
>>>>> contract in any time, for any reason, and without stating any 
>>>>> reasoning.
>>>>>> - if the e-mail contains an offer, the recipient is entitled to 
>>>>>> immediately
>>>>> accept such offer; The sender of this e-mail (offer) excludes any 
>>>>> acceptance
>>> of
>>>>> the offer on the part of the recipient containing any amendment or
>>> variation.
>>>>>> - the sender insists on that the respective contract is concluded 
>>>>>> only upon
>>> an
>>>>> express mutual agreement on all its aspects.
>>>>>> - the sender of this e-mail informs that he/she is not authorized 
>>>>>> to enter
>>> into
>>>>> any contracts on behalf of the company except for cases in which 
>>>>> he/she is
>>>>> expressly authorized to do so in writing, and such authorization 
>>>>> or power of
>>>>> attorney is submitted to the recipient or the person represented 
>>>>> by the
>>>>> recipient, or the existence of such authorization is known to the 
>>>>> recipient of
>>> the
>>>>> person represented by the recipient.
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>> ________________________________
>>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a 
>>>> jsou
>>> ur?eny pouze jeho adres?t?m.
>>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>>>> neprodlen?
>>> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie 
>>> vyma?te ze
>>> sv?ho syst?mu.
>>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni 
>>>> tento email
>>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou 
>>>> modifikacemi
>>> ?i zpo?d?n?m p?enosu e-mailu.
>>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>>>> smlouvy, a
>>> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? 
>>>> p?ijmout;
>>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze 
>>> strany p??jemce s
>>> dodatkem ?i odchylkou.
>>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>>>> v?slovn?m
>>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>>>> spole?nost
>>> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
>>> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>> This e-mail and any documents attached to it may be confidential 
>>>> and are
>>> intended only for its intended recipients.
>>>> If you received this e-mail by mistake, please immediately inform 
>>>> its sender.
>>> Delete the contents of this e-mail with all attachments and its 
>>> copies from your
>>> system.
>>>> If you are not the intended recipient of this e-mail, you are not 
>>>> authorized to
>>> use, disseminate, copy or disclose this e-mail in any manner.
>>>> The sender of this e-mail shall not be liable for any possible 
>>>> damage caused
>>> by modifications of the e-mail or by delay with transfer of the email.
>>>> In case that this e-mail forms part of business dealings:
>>>> - the sender reserves the right to end negotiations about entering 
>>>> into a
>>> contract in any time, for any reason, and without stating any 
>>> reasoning.
>>>> - if the e-mail contains an offer, the recipient is entitled to 
>>>> immediately
>>> accept such offer; The sender of this e-mail (offer) excludes any 
>>> acceptance of
>>> the offer on the part of the recipient containing any amendment or 
>>> variation.
>>>> - the sender insists on that the respective contract is concluded 
>>>> only upon an
>>> express mutual agreement on all its aspects.
>>>> - the sender of this e-mail informs that he/she is not authorized 
>>>> to enter into
>>> any contracts on behalf of the company except for cases in which 
>>> he/she is
>>> expressly authorized to do so in writing, and such authorization or 
>>> power of
>>> attorney is submitted to the recipient or the person represented by the
>>> recipient, or the existence of such authorization is known to the 
>>> recipient of the
>>> person represented by the recipient.
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> -- 
>>>
>>>
>>> -- 
>>> Robert W. Baer, Ph.D.
>>> Professor of Physiology
>>> Kirksville College of Osteopathic Medicine
>>> A T Still University of Health Sciences
>>> 800 W. Jefferson St
>>> Kirksville, MO 63501
>>> 660-626-2321 Department
>>> 660-626-2965 FAX
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a 
>> jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
>> kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento 
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou 
>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? 
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? 
>> nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m 
>> zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and 
>> are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its 
>> sender. Delete the contents of this e-mail with all attachments and 
>> its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not 
>> authorized to use, disseminate, copy or disclose this e-mail in any 
>> manner.
>> The sender of this e-mail shall not be liable for any possible damage 
>> caused by modifications of the e-mail or by delay with transfer of 
>> the email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering 
>> into a contract in any time, for any reason, and without stating any 
>> reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to 
>> immediately accept such offer; The sender of this e-mail (offer) 
>> excludes any acceptance of the offer on the part of the recipient 
>> containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded 
>> only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to 
>> enter into any contracts on behalf of the company except for cases in 
>> which he/she is expressly authorized to do so in writing, and such 
>> authorization or power of attorney is submitted to the recipient or 
>> the person represented by the recipient, or the existence of such 
>> authorization is known to the recipient of the person represented by 
>> the recipient.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From lille.stor at gmx.com  Fri Sep  8 16:08:01 2017
From: lille.stor at gmx.com (lille stor)
Date: Fri, 8 Sep 2017 16:08:01 +0200
Subject: [Rd] Change of variable address due to GC
Message-ID: <trinity-8a6a4fc3-add7-4837-9b62-f488286205e9-1504879681153@3c-app-mailcom-bs14>

Hi,
?
I would like to know if the Garbage Collector (GC) changes the address of a variable in R. In other words, assuming the following code:
?
??? ? library(pryr)
?
? ??? x <- 1:1024
?
??? ? addr <- address(x)? # save address of variable "x" in "addr"

  ???????   ? .
??  ?????   ? .
????  ???   ? .
????? (execution of operations that create/destroy many small/big objects in memory, which will likely make the GC to be called)
?????   ???   .
??? ????  ?   .
? ??????    ? .
?
????? if (addr != address(x))
????? {
? ??????? print("Address of x changed!")
?? ?? }
?
?
Will the message "Address of x changed!" be ever printed?
?
Thank you!


From tomas.kalibera at gmail.com  Fri Sep  8 17:10:07 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 8 Sep 2017 17:10:07 +0200
Subject: [Rd] Change of variable address due to GC
In-Reply-To: <trinity-8a6a4fc3-add7-4837-9b62-f488286205e9-1504879681153@3c-app-mailcom-bs14>
References: <trinity-8a6a4fc3-add7-4837-9b62-f488286205e9-1504879681153@3c-app-mailcom-bs14>
Message-ID: <ceee71d9-801a-bd3c-6013-74ae427e4c47@gmail.com>


I think you might get a more useful answer if you say what you want to 
achieve.

"address(x)" does not give you an address of variable "x" but of an 
object bound to x. The GC in R is non-moving, it does not relocate 
objects. However, a number of things can happen that will change the 
binding of "x" to point to a (modified) copy of the original object 
(such as replacement operations like x[3] <- 4 or class(x) <- "foo"). 
When these copies are made is implementation dependent and may change 
between R versions or may become unpredictable to the R program. An R 
program should only depend on values stored in an object, not on the 
location of that object, and this is also why "address(x)" is not part 
of the base packages.

Best
Tomas

On 09/08/2017 04:08 PM, lille stor wrote:
> Hi,
>   
> I would like to know if the Garbage Collector (GC) changes the address of a variable in R. In other words, assuming the following code:
>   
>        library(pryr)
>   
>        x <- 1:1024
>   
>        addr <- address(x)  # save address of variable "x" in "addr"
>
>                .
>                .
>                .
>        (execution of operations that create/destroy many small/big objects in memory, which will likely make the GC to be called)
>                .
>                .
>                .
>   
>        if (addr != address(x))
>        {
>            print("Address of x changed!")
>        }
>   
>   
> Will the message "Address of x changed!" be ever printed?
>   
> Thank you!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri Sep  8 18:54:58 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 8 Sep 2017 09:54:58 -0700
Subject: [Rd] file.copy(from=Directory, to=File) oddity
Message-ID: <CAF8bMcaP2dHS3KAZVyXifuigZ3B2LmoR6N+=vdzBaCF5svGrhg@mail.gmail.com>

When I mistakenly use file.copy() with a directory for the 'from' argument
and a non-directory for the 'to' and overwrite=TRUE, file.copy returns
FALSE, meaning it could not do the copying.  However, it also replaces the
'to' file with a zero-length file.

dir.create( fromDir <- tempfile() )
cat(file = toFile <- tempfile(), "existing file\n")
readLines(toFile)
#[1] "existing file"
file.copy(fromDir, toFile, recursive=FALSE, overwrite=TRUE)
#[1] FALSE
readLines(toFile)
#character(0)

or, with recursive=TRUE,

dir.create( fromDir <- tempfile() )
cat(file = toFile <- tempfile(), "existing file\n")
readLines(toFile)
#[1] "existing file"
file.copy(fromDir, toFile, recursive=TRUE, overwrite=TRUE)
#[1] FALSE
#Warning message:
#In file.copy(fromDir, toFile, recursive = TRUE, overwrite = TRUE) :
#  'recursive' will be ignored as 'to' is not a single existing directory
readLines(toFile)
#character(0)

Is this behavior intended?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From neal.p.richardson at gmail.com  Fri Sep  8 19:52:32 2017
From: neal.p.richardson at gmail.com (Neal Richardson)
Date: Fri, 8 Sep 2017 10:52:32 -0700
Subject: [Rd] Bug: dput/deparse with named character vector inside list
Message-ID: <CAOCv4hioP-To2r0cxRtMyEAGGFvHNBDQ0J_2WTOEegUVxzP3ug@mail.gmail.com>

Hi,
I noticed some R-devel failures on CRAN on a package I maintain:
https://cloud.r-project.org/web/checks/check_results_httptest.html

It appears that 'dput'/'deparse' is returning an invalid object when
there is a named character vector inside a list. Here is a minimal
example that reproduces the issue:

> z <- list(a=c(b="foo"))
> str(z)
List of 1
 $ a: Named chr "foo"
  ..- attr(*, "names")= chr "b"

> dput(z)
list(a = b = "foo")
> parse(text=deparse(z))
Error in parse(text = deparse(z)) : <text>:1:12: unexpected '='
1: list(a = b =
               ^

But it works fine if you just provide a named character vector:


> dput(z$a)
structure("foo", .Names = "b")


I know that there were some recent improvements to 'deparse' (c73120,
73144). Among the failures on my package on R-devel on CRAN, a test
run on version as old as r73150 does manifest this bug
(https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-gcc/httptest-00check.html),
so the timing does suggest that those changes could be related.

Neal


> sessionInfo()
R Under development (unstable) (2017-09-07 r73219)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.0


From richcala at microsoft.com  Sat Sep  9 01:05:05 2017
From: richcala at microsoft.com (Rich Calaway)
Date: Fri, 8 Sep 2017 23:05:05 +0000
Subject: [Rd] Default repositories in WIndows
Message-ID: <CY4PR21MB0167C8A16F891D0D07FDF8CADE950@CY4PR21MB0167.namprd21.prod.outlook.com>

In the NEWS for R 3.1.0, there is this item:

      The CRANextra repository is no longer a default repository on Windows: all the binary versions of packages from CRAN are now on CRAN, although CRANextra contains packages from Omegahat and elsewhere used by CRAN packages.

However, the .onLoad function in package utils still appends CRANextra to the Windows repos list and sets the repos option, so that CRANextra does indeed still appear as a default repository on Windows. This patch should make the reality agree with the NEWS...

Index: zzz.R
===================================================================
--- zzz.R	(revision 73224)
+++ zzz.R	(working copy)
@@ -39,8 +39,7 @@
         if(.Platform$OS.type == "windows") {
             list(unzip = "internal",
                  editor = if(length(grep("Rgui", commandArgs(), TRUE))) "internal" else "notepad",
-                 repos = c(CRAN = "@CRAN@",
-                           CRANextra = "http://www.stats.ox.ac.uk/pub/RWin")
+                 repos = c(CRAN = "@CRAN@")
                  )
         } else
             list(unzip = Sys.getenv("R_UNZIPCMD"),

(This patch was against R-patched; the same change needs to be made to R-devel as well...)

Cheers,

Rich Calaway
Microsoft R Product Team
24/1341
+1 (425) 4219919 X19919


From maechler at stat.math.ethz.ch  Mon Sep 11 16:01:12 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 Sep 2017 16:01:12 +0200
Subject: [Rd] file.copy(from=Directory, to=File) oddity
In-Reply-To: <CAF8bMcaP2dHS3KAZVyXifuigZ3B2LmoR6N+=vdzBaCF5svGrhg@mail.gmail.com>
References: <CAF8bMcaP2dHS3KAZVyXifuigZ3B2LmoR6N+=vdzBaCF5svGrhg@mail.gmail.com>
Message-ID: <22966.38696.682122.399296@stat.math.ethz.ch>

>>>>> William Dunlap via R-devel <r-devel at r-project.org>
>>>>>     on Fri, 8 Sep 2017 09:54:58 -0700 writes:

    > When I mistakenly use file.copy() with a directory for the 'from' argument
    > and a non-directory for the 'to' and overwrite=TRUE, file.copy returns
    > FALSE, meaning it could not do the copying.  However, it also replaces the
    > 'to' file with a zero-length file.

    > dir.create( fromDir <- tempfile() )
    > cat(file = toFile <- tempfile(), "existing file\n")
    > readLines(toFile)
    > #[1] "existing file"
    > file.copy(fromDir, toFile, recursive=FALSE, overwrite=TRUE)
    > #[1] FALSE

I get TRUE here, on Fedora Linux F24 and F26,
for R 3.3.3, 3.4.1 and R-devel

    > readLines(toFile)
    > #character(0)

(and I get the same here)

    > or, with recursive=TRUE,

    > dir.create( fromDir <- tempfile() )
    > cat(file = toFile <- tempfile(), "existing file\n")
    > readLines(toFile)
    > #[1] "existing file"
    > file.copy(fromDir, toFile, recursive=TRUE, overwrite=TRUE)
    > #[1] FALSE
again I get TRUE  instead,
otherwise the same bahavior.

    > #Warning message:
    > #In file.copy(fromDir, toFile, recursive = TRUE, overwrite = TRUE) :
    > #  'recursive' will be ignored as 'to' is not a single existing directory
    > readLines(toFile)
    > #character(0)

    > Is this behavior intended?

I don't think so (but I had not been involved in writing these).

Effectively, 
	      file.copy(from, to, overwrite=TRUE)
in the case where 'to' is not a directory and from, to are both of length 1,
is basically the following

   ok <- file.create(to)
   if(ok) ok <- file.append(to, from)
   return(ok)

Since you get FALSE when I get TRUE, it is not quite sure if in
your case file.append() is called at all... but I'd guess so.

I think the bug is that file.append(to, from) does not give an
error in our case where 'from' is a directory.

   > dir.exists(fromDir) && file.exists(toFile)
   [1] TRUE
   > file.append(toFile, fromDir) # should signal a warning and give FALSE 
   [1] TRUE
   > 

I'd be grateful if you'd file a bug report.
Martin

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com


From maechler at stat.math.ethz.ch  Mon Sep 11 16:52:49 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 Sep 2017 16:52:49 +0200
Subject: [Rd] Bug: dput/deparse with named character vector inside list
In-Reply-To: <CAOCv4hioP-To2r0cxRtMyEAGGFvHNBDQ0J_2WTOEegUVxzP3ug@mail.gmail.com>
References: <CAOCv4hioP-To2r0cxRtMyEAGGFvHNBDQ0J_2WTOEegUVxzP3ug@mail.gmail.com>
Message-ID: <22966.41793.781393.564044@stat.math.ethz.ch>

>>>>> Neal Richardson <neal.p.richardson at gmail.com>
>>>>>     on Fri, 8 Sep 2017 10:52:32 -0700 writes:

    > Hi,
    > I noticed some R-devel failures on CRAN on a package I maintain:
    > https://cloud.r-project.org/web/checks/check_results_httptest.html

    > It appears that 'dput'/'deparse' is returning an invalid object when
    > there is a named character vector inside a list. Here is a minimal
    > example that reproduces the issue:

    >> z <- list(a=c(b="foo"))
    >> str(z)
    > List of 1
    > $ a: Named chr "foo"
    > ..- attr(*, "names")= chr "b"

    >> dput(z)
    > list(a = b = "foo")
    >> parse(text=deparse(z))
    > Error in parse(text = deparse(z)) : <text>:1:12: unexpected '='
    > 1: list(a = b =
    > ^

    > But it works fine if you just provide a named character vector:


    >> dput(z$a)
    > structure("foo", .Names = "b")

("of course", because that had been tested quite extensively).

Thank you for reporting.  It is clearly a bug.
We're happy if your report it formally (https://bugs.r-project.org),
but as it is only in "R-devel", the development version of R, to
report here is indeed perfect.

    > I know that there were some recent improvements to 'deparse' (c73120,
    > 73144). Among the failures on my package on R-devel on CRAN, a test
    > run on version as old as r73150 does manifest this bug
    > (https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-gcc/httptest-00check.html),
    > so the timing does suggest that those changes could be related.

I'm sure they are (and it is mea culpa).
I will address this ASAP.

Martin

    > Neal


    >> sessionInfo()
    > R Under development (unstable) (2017-09-07 r73219)
    > Platform: x86_64-apple-darwin15.6.0 (64-bit)
    > Running under: macOS Sierra 10.12.6

    > Matrix products: default
    > BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
    > LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

    > locale:
    > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > loaded via a namespace (and not attached):
    > [1] compiler_3.5.0


From wdunlap at tibco.com  Mon Sep 11 20:50:48 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Sep 2017 11:50:48 -0700
Subject: [Rd] file.copy(from=Directory, to=File) oddity
In-Reply-To: <22966.38696.682122.399296@stat.math.ethz.ch>
References: <CAF8bMcaP2dHS3KAZVyXifuigZ3B2LmoR6N+=vdzBaCF5svGrhg@mail.gmail.com>
 <22966.38696.682122.399296@stat.math.ethz.ch>
Message-ID: <CAF8bMcbMYxfHyQrGTm4tR+BMVV557RJxsJ2USBEYByaMvKn6yw@mail.gmail.com>

Bug 17337.  Note that I get R making the zero-length file on both Windows
and Linux, but the return values are different.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Sep 11, 2017 at 7:01 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> William Dunlap via R-devel <r-devel at r-project.org>
> >>>>>     on Fri, 8 Sep 2017 09:54:58 -0700 writes:
>
>     > When I mistakenly use file.copy() with a directory for the 'from'
> argument
>     > and a non-directory for the 'to' and overwrite=TRUE, file.copy
> returns
>     > FALSE, meaning it could not do the copying.  However, it also
> replaces the
>     > 'to' file with a zero-length file.
>
>     > dir.create( fromDir <- tempfile() )
>     > cat(file = toFile <- tempfile(), "existing file\n")
>     > readLines(toFile)
>     > #[1] "existing file"
>     > file.copy(fromDir, toFile, recursive=FALSE, overwrite=TRUE)
>     > #[1] FALSE
>
> I get TRUE here, on Fedora Linux F24 and F26,
> for R 3.3.3, 3.4.1 and R-devel
>
>     > readLines(toFile)
>     > #character(0)
>
> (and I get the same here)
>
>     > or, with recursive=TRUE,
>
>     > dir.create( fromDir <- tempfile() )
>     > cat(file = toFile <- tempfile(), "existing file\n")
>     > readLines(toFile)
>     > #[1] "existing file"
>     > file.copy(fromDir, toFile, recursive=TRUE, overwrite=TRUE)
>     > #[1] FALSE
> again I get TRUE  instead,
> otherwise the same bahavior.
>
>     > #Warning message:
>     > #In file.copy(fromDir, toFile, recursive = TRUE, overwrite = TRUE) :
>     > #  'recursive' will be ignored as 'to' is not a single existing
> directory
>     > readLines(toFile)
>     > #character(0)
>
>     > Is this behavior intended?
>
> I don't think so (but I had not been involved in writing these).
>
> Effectively,
>               file.copy(from, to, overwrite=TRUE)
> in the case where 'to' is not a directory and from, to are both of length
> 1,
> is basically the following
>
>    ok <- file.create(to)
>    if(ok) ok <- file.append(to, from)
>    return(ok)
>
> Since you get FALSE when I get TRUE, it is not quite sure if in
> your case file.append() is called at all... but I'd guess so.
>
> I think the bug is that file.append(to, from) does not give an
> error in our case where 'from' is a directory.
>
>    > dir.exists(fromDir) && file.exists(toFile)
>    [1] TRUE
>    > file.append(toFile, fromDir) # should signal a warning and give FALSE
>    [1] TRUE
>    >
>
> I'd be grateful if you'd file a bug report.
> Martin
>
>     > Bill Dunlap
>     > TIBCO Software
>     > wdunlap tibco.com
>

	[[alternative HTML version deleted]]


From realitix at gmail.com  Tue Sep 12 15:05:15 2017
From: realitix at gmail.com (=?UTF-8?Q?Jean=2DS=C3=A9bastien_Bevilacqua?=)
Date: Tue, 12 Sep 2017 15:05:15 +0200
Subject: [Rd] File listing on windows shows hidden files
Message-ID: <CAPXDfFk31-v+LPB7qn+8YmWjdJ8O2_9RCOK=VPh51ikkqyuq4A@mail.gmail.com>

Hello,

I encounter a problem with file listing. On Linux, a hidden file is just a
file starting with a "dot" but on Windows, it's a file with a special
attribute.
Currently, R checks if the file starts with a "dot", so it's not working on
Windows.

I have opened an issue in the bug tracker and proposed a patch :
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17334

Thanks in advance,
Sincerely,
Jean-S?bastien Bevilacqua

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Tue Sep 12 20:28:48 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 12 Sep 2017 13:28:48 -0500 (CDT)
Subject: [Rd] R-devel object header changes that require reinstalling
	packages
Message-ID: <alpine.DEB.2.20.1709121326430.30468@luke-Latitude>

For anyone using the development version of R:

svn revision 73243 introduces some changes to the memory layout of R
objects that require reinstalling packages using compiled
code. Attempting to load incompatible packages should signal an
error. These changes are to support a new extension framework for
basic R objects
(https://svn.r-project.org/R/branches/ALTREP/ALTREP.html outlines the
framework).  Merging the remainder of the framework should not
introduce more binary changes and is expected to occur in the next few
months.

Best,

luke

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ligges at statistik.tu-dortmund.de  Wed Sep 13 09:20:39 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 13 Sep 2017 09:20:39 +0200
Subject: [Rd] CRAN incoming checks / winbuilder on demand results for R-devel
Message-ID: <3ddc760d-ea7c-6380-64ff-d52d2ab14bca@statistik.tu-dortmund.de>

Dear package developers,

given some very recent changes in R-devel, many packages under R-devel 
have to be reinstalled. Due to maintainance work on CRAN we probably 
won't process submissions today. R-devel results from winbuilder will be 
flaky at least during the next 10 hours.

Best,
Uwe Ligges


From mwtoews at gmail.com  Wed Sep 13 01:40:55 2017
From: mwtoews at gmail.com (Mike Toews)
Date: Wed, 13 Sep 2017 11:40:55 +1200
Subject: [Rd] unpackPkgZip: "unable to move temporary installation" due to
	antivirus
Message-ID: <CAM2FmMro4LgtkbjJjNvQ5y0ZTpVAqoDSvc4HUeNW31SvnWwbgA@mail.gmail.com>

Hi,

Me and an office colleague on Microsoft Windows 10 PCs are having
difficulty installing any package. This is a recent issue for us, and
we suspect our McAfee antivirus has modified by our IT department.
Let's take, for example, install.packages("mypackage"), here is the
output:

package ?mypackage? successfully unpacked and MD5 sums checked
Warning in install.packages :
  unable to move temporary installation
?C:\Users\mtoews\Documents\R\win-library\3.3\file382064842da2\mypackage?
to ?C:\Users\mtoews\Documents\R\win-library\3.3\mypackage?

Debugging, I found the issue around here:
https://github.com/wch/r-source/blob/980c15af89d99c04e09a40708512a57c49d1c6ee/src/library/utils/R/windows/install.packages.R#L173-L174
> ## To avoid anti-virus interference, wait a little
> Sys.sleep(0.5)

As indicated by an answer
(https://stackoverflow.com/a/44256437/327026), debugging slows down
the function to allow the package to be installed. A simple fix is to
increase the sleep time to a time that is longer than 0.5 seconds.
(I've tried testing new times, but I can't seem to overload this
function). Or use a different strategy, such as using a few attempts
with increasing wait times, or using a custom unlink function.

Happy to help out or test more on this issue. Also, if any R Core
member could add me to R's Bugzilla members, that would be convenient
for me.

Cheers,
Mike

R version 3.3.3 (2017-03-06) -- "Another Canoe"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)


From msuzen at gmail.com  Wed Sep 13 12:54:38 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 13 Sep 2017 12:54:38 +0200
Subject: [Rd] establishing a Code of Conduct for R
Message-ID: <CAPtbhHyGeOnm8TBNDfnzu85vZh7PdNLi4k2Z-G3pFkzc4Kf5cg@mail.gmail.com>

Dear Colleagues/Developers/R enthusiasts,

Would it be possible to develop a code of conduct (CoC) document for
R lists, CRAN submissions that all developers/maintainers to follow?
This may help all of us to better communicate and move forward together.
There is a similar effort from Python community, here are the links:

* https://mail.python.org/pipermail/scipy-dev/2017-August/022044.html
* https://opensource.guide/code-of-conduct/

Kind regards,
Mehmet


From brian at braverock.com  Wed Sep 13 13:22:53 2017
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 13 Sep 2017 06:22:53 -0500
Subject: [Rd] establishing a Code of Conduct for R
In-Reply-To: <CAPtbhHyGeOnm8TBNDfnzu85vZh7PdNLi4k2Z-G3pFkzc4Kf5cg@mail.gmail.com>
References: <CAPtbhHyGeOnm8TBNDfnzu85vZh7PdNLi4k2Z-G3pFkzc4Kf5cg@mail.gmail.com>
Message-ID: <1505301773.2677.28.camel@braverock.com>


On Wed, 2017-09-13 at 12:54 +0200, Suzen, Mehmet wrote:
> Dear Colleagues/Developers/R enthusiasts,
> 
> Would it be possible to develop a code of conduct (CoC) document for
> R lists, CRAN submissions that all developers/maintainers to follow?
> This may help all of us to better communicate and move forward
> together.
> There is a similar effort from Python community, here are the links:
> 
> * https://mail.python.org/pipermail/scipy-dev/2017-August/022044.html
> * https://opensource.guide/code-of-conduct/
> 

I am not an official representative of the R team, so this is only my
opinion.

It seems to me that you are trying to create a solution to a problem
which does not exist.

All the R mailing lists have posting guides.  The mailing list
community is largely self-policing to unwelcome behavior and corrects
it quickly.

In over 15 years as an active part of this community, it has always
appeared to me that the community as a whole already conducts itself in
a spirit of professionalism and cooperation.

So I don't see the point in asking already overworked volunteers to
take on and police more formal policies that really seem unnecessary.

Regards,

Brian

--?
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From therneau at mayo.edu  Wed Sep 13 18:03:33 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 Sep 2017 11:03:33 -0500
Subject: [Rd] y label for X11 graphics
Message-ID: <9153c6$7udq2s@ironport10.mayo.edu>

In the following plot, the y label is missing if it is too long.

x11(type="Xlib")
plot(1:5, 1:5, ylab="Do, a deer, a female deer")   # missing label
plot(1:5, 1:5, ylab="Do")                          # label is present

All is well for x11(type="cairo")

This is true both under R devel 2017-09-01 on xubuntu (my desktop), and 3.4.1 on Centos 
6.9 (department servers).


A minor question is why my locally compiled version defaults to Xlib rather than cairo, 
since both work as explicit arguments to the x11() command.

Terry T.


From therneau at mayo.edu  Thu Sep 14 00:19:17 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 Sep 2017 17:19:17 -0500
Subject: [Rd] vcov and survival
Message-ID: <9153c6$7uhrg4@ironport10.mayo.edu>

I have just noticed a difference in behavior between coxph and lm/glm: if one or more of 
the coefficients from the fit in NA, then lm and glm omit that row/column from the 
variance matrix; while coxph retains it but sets the values to zero.

   Is this something that should be "fixed", i.e., made to agree? I suspect that doing so 
will break other packages, but then NA coefs are rather rare so perhaps not.

Terry Therneau


From jfox at mcmaster.ca  Thu Sep 14 00:45:07 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 13 Sep 2017 22:45:07 +0000
Subject: [Rd] vcov and survival
In-Reply-To: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>

Dear Terry,

Even the behaviour of lm() and glm() isn't entirely consistent. In both cases, singularity results in NA coefficients by default, and these are reported in the model summary and coefficient vector, but not in the coefficient covariance matrix:

----------------	

> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
+              data=longley)
> summary(mod.lm)

Call:
lm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    data = longley)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.80899 -0.33282 -0.02329  0.25895  1.08800 

Coefficients: (1 not defined because of singularities)
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
GNP                  0.06317    0.01065   5.933 4.96e-05 ***
Population          -0.40974    0.15214  -2.693   0.0184 *  
I(GNP + Population)       NA         NA      NA       NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5459 on 13 degrees of freedom
Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758 
F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11

> vcov(mod.lm)
            (Intercept)           GNP Population
(Intercept) 190.0269691  0.1445617813 -2.0954381
GNP           0.1445618  0.0001133631 -0.0016054
Population   -2.0954381 -0.0016053999  0.0231456
> coef(mod.lm)
        (Intercept)                 GNP          Population I(GNP + Population) 
        88.93879831          0.06317244         -0.40974292                  NA 
> 
> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population), 
+               data=longley)
> summary(mod.glm)

Call:
glm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    data = longley)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-0.80899  -0.33282  -0.02329   0.25895   1.08800  

Coefficients: (1 not defined because of singularities)
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
GNP                  0.06317    0.01065   5.933 4.96e-05 ***
Population          -0.40974    0.15214  -2.693   0.0184 *  
I(GNP + Population)       NA         NA      NA       NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for gaussian family taken to be 0.2980278)

    Null deviance: 185.0088  on 15  degrees of freedom
Residual deviance:   3.8744  on 13  degrees of freedom
AIC: 30.715

Number of Fisher Scoring iterations: 2

> coef(mod.glm)
        (Intercept)                 GNP          Population I(GNP + Population) 
        88.93879831          0.06317244         -0.40974292                  NA 
> vcov(mod.glm)
            (Intercept)           GNP Population
(Intercept) 190.0269691  0.1445617813 -2.0954381
GNP           0.1445618  0.0001133631 -0.0016054
Population   -2.0954381 -0.0016053999  0.0231456

----------------	

Moreoever, lm() has a singular.ok() argument that defaults to TRUE, but glm() doesn't have this argument:

----------------	

> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
+              data=longley, singular.ok=FALSE)
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
  singular fit encountered

----------------	

In my opinion, singularity should at least produce a warning, both in calls to lm() and glm(), and in summary() output. Even better, again in my opinion, would be to produce an error by default in this situation, but doing so would likely break too much existing code. 

I prefer NA to 0 for the redundant coefficients because it at least suggests that the decision about what to exclude is arbitrary, and of course simply excluding coefficients isn't the only way to proceed. 

Finally, the differences in behaviour between coef() and vcov() and between lm() and glm() aren't really sensible.

Maybe there's some reason for all this that escapes me.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
> Therneau, Terry M., Ph.D.
> Sent: Wednesday, September 13, 2017 6:19 PM
> To: r-devel at r-project.org
> Subject: [Rd] vcov and survival
> 
> I have just noticed a difference in behavior between coxph and lm/glm:
> if one or more of the coefficients from the fit in NA, then lm and glm
> omit that row/column from the variance matrix; while coxph retains it
> but sets the values to zero.
> 
>    Is this something that should be "fixed", i.e., made to agree? I
> suspect that doing so will break other packages, but then NA coefs are
> rather rare so perhaps not.
> 
> Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From msuzen at gmail.com  Thu Sep 14 03:15:46 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 14 Sep 2017 03:15:46 +0200
Subject: [Rd] establishing a Code of Conduct for R
In-Reply-To: <1505301773.2677.28.camel@braverock.com>
References: <CAPtbhHyGeOnm8TBNDfnzu85vZh7PdNLi4k2Z-G3pFkzc4Kf5cg@mail.gmail.com>
 <1505301773.2677.28.camel@braverock.com>
Message-ID: <CAPtbhHxUs51UxY3PqrGqLhbuAoVN_yZ8-3PuhGKwyptBHs7g=g@mail.gmail.com>

On 13 September 2017 at 13:22, Brian G. Peterson <brian at braverock.com> wrote:
> I am not an official representative of the R team, so this is only my
> opinion.
>

Thank you.

> It seems to me that you are trying to create a solution to a problem
> which does not exist.

I am not trying to create any solution and not my decision if this is
really needed for r-project. It was just a naive suggestion, c.f,
https://opensource.guide/code-of-conduct/#why-do-i-need-a-code-of-conduct
https://www.contributor-covenant.org/

Best
Mehmet


From possenriede at gmail.com  Thu Sep 14 09:40:24 2017
From: possenriede at gmail.com (Daniel Possenriede)
Date: Thu, 14 Sep 2017 09:40:24 +0200
Subject: [Rd] special latin1 do not print as glyphs in current devel on
 windows
In-Reply-To: <59A2E7FC.9090303@stern.nyu.edu>
References: <CANu2KkOOSz1yRy0iszE47uTniAms=_LgBOW8ZbEJpCCfhJyUuA@mail.gmail.com>
 <59A2E7FC.9090303@stern.nyu.edu>
Message-ID: <ff34748c-cac7-a079-460d-601e150e3a6d@gmail.com>

This is a follow-up on my initial posts regarding character encodings on 
Windows (https://stat.ethz.ch/pipermail/r-devel/2017-August/074728.html) 
and Patrick Perry's reply 
(https://stat.ethz.ch/pipermail/r-devel/2017-August/074830.html) in 
particular (thank you for the links and the bug report!). My initial 
posts were quite chaotic (and partly wrong), so I am trying to clear 
things up a bit.

Actually, the title of my original message "special latin1 [characters] 
do not print as glyphs in current devel on windows" is already wrong, 
because the problem exists with characters with CP1252 encoding in the 
80-9F (hex) range. Like Brian Ripley rightfully pointed out, latin1 != 
CP1252. The characters in the 80-9F code point range are not even part 
of ISO/IEC 8859-1 a.k.a. latin1, see for example 
https://en.wikipedia.org/wiki/Windows-1252. R treats them as if they 
were, however, and that is exactly the problem, IMHO.

Let me show you what I mean. (All output from R 3.5 r73238, see 
sessionInfo at the end)

 > Sys.getlocale("LC_CTYPE")
[1] "German_Germany.1252"
 > x <- c("?", "?", "?", "?")
 > sapply(x, charToRaw)
\u0080 \u009e \u009a? ?
80 9e 9a fc

"?", "?", "?" serve as examples in the 80-9F range of CP1252. I also 
show the "?" just as an example of a non-ASCII character outside that 
range (and because Patrick Perry used it in his bug report which might 
be a (slightly) different problem, but I will get to that later.)

 > print(x)
[1] "\u0080" "\u009e" "\u009a" "?"

"?", "?", and "?" are printed as (incorrect) unicode escapes. "?" for 
example should be \u20ac not \u0080.
(In R 3.4.1, print(x) shows the glyphs and not the unicode escapes. 
Apparently, as of v3.5, print() calls enc2utf8() (or its equivalent in C 
(translateCharUTF8?))?)

 > print("\u20ac")
[1] "?"

The characters in x are marked as "latin1".

 > Encoding(x)
[1] "latin1" "latin1" "latin1" "latin1"

Looking at the CP1252 table (e.g. link above), we see that this is 
incorrect for "?", "?", and "?", which simply do not exist in latin1.

As per the documentation, "enc2utf8 convert[s] elements of character 
vectors to [...] UTF-8 [...], taking any marked encoding into account." 
Since the marked encoding is wrong, so is the output of enc2utf8().

 > enc2utf8(x)
[1] "\u0080" "\u009e" "\u009a" "?"

Now, when we set the encoding to "unknown" everything works fine.

 > x_un <- x
 > Encoding(x_un) <- "unknown"
 > print(x_un)
[1] "?" "?" "?" "?"
 > (x_un2utf8 <- enc2utf8(x_un))
[1] "?" "?" "?" "?"

Long story short: The characters in the 80 to 9F range should not be 
marked as "latin1" on CP1252 locales, IMHO.

As a side-note: the output of localeToCharset() is also problematic, 
since ISO8859-1 != CP1252.

 > localeToCharset()
[1] "ISO8859-1"

Finally on to Patrick Perry's bug report 
(https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17329): 'On 
Windows, enc2utf8("?") yields "|".'

Unfortunately, I cannot reproduce this with the CP1252 locale, as can be 
seen above. Probably, because the bug applies to the C locale (sorry if 
this is somewhere apparent in the bug report and I missed it).

 > Sys.setlocale("LC_CTYPE", "C")
[1] "C"
 > enc2utf8("?")
[1] "|"
 > charToRaw("?")
[1] fc
 > Encoding("?")
[1] "unknown"

This does not seem to be related to the marked encoding of the string, 
so it seems to me that this is a different problem than the one above.

Any advice on how to proceed further would be highly appreciated.

Thanks!
Daniel

 > sessionInfo()
R Under development (unstable) (2017-09-11 r73238)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 14393)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252? LC_CTYPE=C
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
[1] compiler_3.5.0


From maechler at stat.math.ethz.ch  Thu Sep 14 10:13:02 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 14 Sep 2017 10:13:02 +0200
Subject: [Rd] vcov and survival
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <22970.14862.518011.162206@stat.math.ethz.ch>

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Wed, 13 Sep 2017 22:45:07 +0000 writes:

    > Dear Terry,
    > Even the behaviour of lm() and glm() isn't entirely consistent. In both cases, singularity results in NA coefficients by default, and these are reported in the model summary and coefficient vector, but not in the coefficient covariance matrix:

    > ----------------	

    >> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
    > +              data=longley)
    >> summary(mod.lm)

    > Call:
    > lm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    > data = longley)

    > Residuals:
    > Min       1Q   Median       3Q      Max 
    > -0.80899 -0.33282 -0.02329  0.25895  1.08800 

    > Coefficients: (1 not defined because of singularities)
    > Estimate Std. Error t value Pr(>|t|)    
    > (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
    > GNP                  0.06317    0.01065   5.933 4.96e-05 ***
    > Population          -0.40974    0.15214  -2.693   0.0184 *  
    > I(GNP + Population)       NA         NA      NA       NA    
    > ---
    > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    > Residual standard error: 0.5459 on 13 degrees of freedom
    > Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758 
    > F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11

    >> vcov(mod.lm)
    > (Intercept)           GNP Population
    > (Intercept) 190.0269691  0.1445617813 -2.0954381
    > GNP           0.1445618  0.0001133631 -0.0016054
    > Population   -2.0954381 -0.0016053999  0.0231456
    >> coef(mod.lm)
    > (Intercept)                 GNP          Population I(GNP + Population) 
    > 88.93879831          0.06317244         -0.40974292                  NA 
    >> 
    >> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population), 
    > +               data=longley)
    >> summary(mod.glm)

    > Call:
    > glm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    > data = longley)

    > Deviance Residuals: 
    > Min        1Q    Median        3Q       Max  
    > -0.80899  -0.33282  -0.02329   0.25895   1.08800  

    > Coefficients: (1 not defined because of singularities)
    > Estimate Std. Error t value Pr(>|t|)    
    > (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
    > GNP                  0.06317    0.01065   5.933 4.96e-05 ***
    > Population          -0.40974    0.15214  -2.693   0.0184 *  
    > I(GNP + Population)       NA         NA      NA       NA    
    > ---
    > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    > (Dispersion parameter for gaussian family taken to be 0.2980278)

    > Null deviance: 185.0088  on 15  degrees of freedom
    > Residual deviance:   3.8744  on 13  degrees of freedom
    > AIC: 30.715

    > Number of Fisher Scoring iterations: 2

    >> coef(mod.glm)
    > (Intercept)                 GNP          Population I(GNP + Population) 
    > 88.93879831          0.06317244         -0.40974292                  NA 
    >> vcov(mod.glm)
    > (Intercept)           GNP Population
    > (Intercept) 190.0269691  0.1445617813 -2.0954381
    > GNP           0.1445618  0.0001133631 -0.0016054
    > Population   -2.0954381 -0.0016053999  0.0231456

    > ----------------	

    > Moreoever, lm() has a singular.ok() argument that defaults to TRUE, but glm() doesn't have this argument:

    > ----------------	

    >> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
    > +              data=longley, singular.ok=FALSE)
    > Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
    > singular fit encountered

    > ----------------	

    > In my opinion, singularity should at least produce a warning, both in calls to lm() and glm(), and in summary() output. Even better, again in my opinion, would be to produce an error by default in this situation, but doing so would likely break too much existing code. 

Yes, I would not want to change.  Note that this is from S
already, i.e., long "ingrained".  I think there one argument was
that there are situations with factor predictors of many levels
and conceptually their 2- or even 3-way interactions (!)
where it is neat to just fit the model, (-> get residuals and
fitted values) and also see implicitly the "necessary rank" of
prediction space, or rather even more specifically, you see for
every factor how many levels are "distinguishable"/useful for
prediction, given the data.

    > I prefer NA to 0 for the redundant coefficients because it at least suggests that the decision about what to exclude is arbitrary, and of course simply excluding coefficients isn't the only way to proceed. 

I'm less modest and would say *definitely*, NA's are highly
prefered in such a situation.

    > Finally, the differences in behaviour between coef() and vcov() and between lm() and glm() aren't really sensible.

I really haven't seen any difference between lm() and glm() in
the example above.  Maybe you can point them out for me.

I do quite agree that  vcov() should be compatible with
coef() [and summary()]  for both 'lm' and 'glm' methods, i.e.,
should get NA rows and columns there.  This would require
eliminating these before e.g. using it in solve(<vcov>, *) etc,
but I think it would be a good idea that the useR must deal with
these NAs actively.

Shall "we" try and see the fallout in CRAN space?

    > Maybe there's some reason for all this that escapes me.
(for the first one---"no error"--- I gave a reason)

    > Best,
    > John

    > --------------------------------------
    > John Fox, Professor Emeritus
    > McMaster University
    > Hamilton, Ontario, Canada
    > Web: socserv.mcmaster.ca/jfox




    >> -----Original Message-----
    >> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
    >> Therneau, Terry M., Ph.D.
    >> Sent: Wednesday, September 13, 2017 6:19 PM
    >> To: r-devel at r-project.org
    >> Subject: [Rd] vcov and survival
    >> 
    >> I have just noticed a difference in behavior between coxph and lm/glm:
    >> if one or more of the coefficients from the fit in NA, then lm and glm
    >> omit that row/column from the variance matrix; while coxph retains it
    >> but sets the values to zero.
    >> 
    >> Is this something that should be "fixed", i.e., made to agree? I
    >> suspect that doing so will break other packages, but then NA coefs are
    >> rather rare so perhaps not.
    >> 
    >> Terry Therneau
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Sep 14 10:23:05 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 14 Sep 2017 10:23:05 +0200
Subject: [Rd] vcov and survival
In-Reply-To: <22970.14862.518011.162206@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
Message-ID: <22970.15465.494390.45636@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 14 Sep 2017 10:13:02 +0200 writes:

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Wed, 13 Sep 2017 22:45:07 +0000 writes:

    >> Dear Terry,
    >> Even the behaviour of lm() and glm() isn't entirely consistent. In both cases, singularity results in NA coefficients by default, and these are reported in the model summary and coefficient vector, but not in the coefficient covariance matrix:

    >> ----------------	

    >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
    >> +              data=longley)
    >>> summary(mod.lm)

    >> Call:
    >> lm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    >> data = longley)

    >> Residuals:
    >> Min       1Q   Median       3Q      Max 
    >> -0.80899 -0.33282 -0.02329  0.25895  1.08800 

    >> Coefficients: (1 not defined because of singularities)
    >> Estimate Std. Error t value Pr(>|t|)    
    >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
    >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
    >> Population          -0.40974    0.15214  -2.693   0.0184 *  
    >> I(GNP + Population)       NA         NA      NA       NA    
    >> ---
    >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    >> Residual standard error: 0.5459 on 13 degrees of freedom
    >> Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758 
    >> F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11

    >>> vcov(mod.lm)
    >> (Intercept)           GNP Population
    >> (Intercept) 190.0269691  0.1445617813 -2.0954381
    >> GNP           0.1445618  0.0001133631 -0.0016054
    >> Population   -2.0954381 -0.0016053999  0.0231456
    >>> coef(mod.lm)
    >> (Intercept)                 GNP          Population I(GNP + Population) 
    >> 88.93879831          0.06317244         -0.40974292                  NA 
    >>> 
    >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population), 
    >> +               data=longley)
    >>> summary(mod.glm)

    >> Call:
    >> glm(formula = Employed ~ GNP + Population + I(GNP + Population), 
    >> data = longley)

    >> Deviance Residuals: 
    >> Min        1Q    Median        3Q       Max  
    >> -0.80899  -0.33282  -0.02329   0.25895   1.08800  

    >> Coefficients: (1 not defined because of singularities)
    >> Estimate Std. Error t value Pr(>|t|)    
    >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
    >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
    >> Population          -0.40974    0.15214  -2.693   0.0184 *  
    >> I(GNP + Population)       NA         NA      NA       NA    
    >> ---
    >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    >> (Dispersion parameter for gaussian family taken to be 0.2980278)

    >> Null deviance: 185.0088  on 15  degrees of freedom
    >> Residual deviance:   3.8744  on 13  degrees of freedom
    >> AIC: 30.715

    >> Number of Fisher Scoring iterations: 2

    >>> coef(mod.glm)
    >> (Intercept)                 GNP          Population I(GNP + Population) 
    >> 88.93879831          0.06317244         -0.40974292                  NA 
    >>> vcov(mod.glm)
    >> (Intercept)           GNP Population
    >> (Intercept) 190.0269691  0.1445617813 -2.0954381
    >> GNP           0.1445618  0.0001133631 -0.0016054
    >> Population   -2.0954381 -0.0016053999  0.0231456

    >> ----------------	

    >> Moreoever, lm() has a singular.ok() argument that defaults to TRUE, but glm() doesn't have this argument:

    >> ----------------	

    >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population), 
    >> +              data=longley, singular.ok=FALSE)
    >> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
    >> singular fit encountered

    >> ----------------	

    >> In my opinion, singularity should at least produce a warning, both in calls to lm() and glm(), and in summary() output. Even better, again in my opinion, would be to produce an error by default in this situation, but doing so would likely break too much existing code. 

    > Yes, I would not want to change.  Note that this is from S
    > already, i.e., long "ingrained".  I think there one argument was
    > that there are situations with factor predictors of many levels
    > and conceptually their 2- or even 3-way interactions (!)
    > where it is neat to just fit the model, (-> get residuals and
    > fitted values) and also see implicitly the "necessary rank" of
    > prediction space, or rather even more specifically, you see for
    > every factor how many levels are "distinguishable"/useful for
    > prediction, given the data.

    >> I prefer NA to 0 for the redundant coefficients because it at least suggests that the decision about what to exclude is arbitrary, and of course simply excluding coefficients isn't the only way to proceed. 

    > I'm less modest and would say *definitely*, NA's are highly
    > prefered in such a situation.

    >> Finally, the differences in behaviour between coef() and vcov() and between lm() and glm() aren't really sensible.

    > I really haven't seen any difference between lm() and glm() in
    > the example above.  Maybe you can point them out for me.

.. now I saw it:
   lm() has  a 'singular.ok = TRUE' argument
   which you can set to FALSE if you prefer an error to NA coefficients.

I also agree with you John that it would be nice if  glm() also
got such an argument.
Patches are welcome and seem easy. Nowadays we prefer them
as attachments (diff/patch file!) at R's
  https://bugs.r-project.org bugzilla 
against the svn source, here
  https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
and
  https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd

    > I do quite agree that  vcov() should be compatible with
    > coef() [and summary()]  for both 'lm' and 'glm' methods, i.e.,
    > should get NA rows and columns there.  This would require
    > eliminating these before e.g. using it in solve(<vcov>, *) etc,
    > but I think it would be a good idea that the useR must deal with
    > these NAs actively.

    > Shall "we" try and see the fallout in CRAN space?

    >> Maybe there's some reason for all this that escapes me.
    > (for the first one---"no error"--- I gave a reason)

    >> Best,
    >> John

    >> --------------------------------------
    >> John Fox, Professor Emeritus
    >> McMaster University
    >> Hamilton, Ontario, Canada
    >> Web: socserv.mcmaster.ca/jfox




    >>> -----Original Message-----
    >>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
    >>> Therneau, Terry M., Ph.D.
    >>> Sent: Wednesday, September 13, 2017 6:19 PM
    >>> To: r-devel at r-project.org
    >>> Subject: [Rd] vcov and survival
    >>> 
    >>> I have just noticed a difference in behavior between coxph and lm/glm:
    >>> if one or more of the coefficients from the fit in NA, then lm and glm
    >>> omit that row/column from the variance matrix; while coxph retains it
    >>> but sets the values to zero.
    >>> 
    >>> Is this something that should be "fixed", i.e., made to agree? I
    >>> suspect that doing so will break other packages, but then NA coefs are
    >>> rather rare so perhaps not.
    >>> 
    >>> Terry Therneau


From pperry at stern.nyu.edu  Thu Sep 14 13:47:33 2017
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Thu, 14 Sep 2017 07:47:33 -0400
Subject: [Rd] special latin1 do not print as glyphs in current devel on
 windows
In-Reply-To: <ff34748c-cac7-a079-460d-601e150e3a6d@gmail.com>
References: <CANu2KkOOSz1yRy0iszE47uTniAms=_LgBOW8ZbEJpCCfhJyUuA@mail.gmail.com>
 <59A2E7FC.9090303@stern.nyu.edu>
 <ff34748c-cac7-a079-460d-601e150e3a6d@gmail.com>
Message-ID: <59BA6C55.9020405@stern.nyu.edu>

This particular issue has a simple fix. Currently, the "R_check_locale" 
function includes the following code starting at line 244 in 
src/main/platform.c:

#ifdef Win32
     {
     char *ctype = setlocale(LC_CTYPE, NULL), *p;
     p = strrchr(ctype, '.');
     if (p && isdigit(p[1])) localeCP = atoi(p+1); else localeCP = 0;
     /* Not 100% correct, but CP1252 is a superset */
     known_to_be_latin1 = latin1locale = (localeCP == 1252);
     }
#endif

The "1252" should be "28591"; see 
https://msdn.microsoft.com/en-us/library/windows/desktop/dd317756(v=vs.85).aspx 
.

> Daniel Possenriede <mailto:possenriede at gmail.com>
> September 14, 2017 at 3:40 AM
> This is a follow-up on my initial posts regarding character encodings 
> on Windows 
> (https://stat.ethz.ch/pipermail/r-devel/2017-August/074728.html) and 
> Patrick Perry's reply 
> (https://stat.ethz.ch/pipermail/r-devel/2017-August/074830.html) in 
> particular (thank you for the links and the bug report!). My initial 
> posts were quite chaotic (and partly wrong), so I am trying to clear 
> things up a bit.
>
> Actually, the title of my original message "special latin1 
> [characters] do not print as glyphs in current devel on windows" is 
> already wrong, because the problem exists with characters with CP1252 
> encoding in the 80-9F (hex) range. Like Brian Ripley rightfully 
> pointed out, latin1 != CP1252. The characters in the 80-9F code point 
> range are not even part of ISO/IEC 8859-1 a.k.a. latin1, see for 
> example https://en.wikipedia.org/wiki/Windows-1252. R treats them as 
> if they were, however, and that is exactly the problem, IMHO.
>
> Let me show you what I mean. (All output from R 3.5 r73238, see 
> sessionInfo at the end)
>
> > Sys.getlocale("LC_CTYPE")
> [1] "German_Germany.1252"
> > x <- c("?", "?", "?", "?")
> > sapply(x, charToRaw)
> \u0080 \u009e \u009a  ?
> 80 9e 9a fc
>
> "?", "?", "?" serve as examples in the 80-9F range of CP1252. I also 
> show the "?" just as an example of a non-ASCII character outside that 
> range (and because Patrick Perry used it in his bug report which might 
> be a (slightly) different problem, but I will get to that later.)
>
> > print(x)
> [1] "\u0080" "\u009e" "\u009a" "?"
>
> "?", "?", and "?" are printed as (incorrect) unicode escapes. "?" for 
> example should be \u20ac not \u0080.
> (In R 3.4.1, print(x) shows the glyphs and not the unicode escapes. 
> Apparently, as of v3.5, print() calls enc2utf8() (or its equivalent in 
> C (translateCharUTF8?))?)
>
> > print("\u20ac")
> [1] "?"
>
> The characters in x are marked as "latin1".
>
> > Encoding(x)
> [1] "latin1" "latin1" "latin1" "latin1"
>
> Looking at the CP1252 table (e.g. link above), we see that this is 
> incorrect for "?", "?", and "?", which simply do not exist in latin1.
>
> As per the documentation, "enc2utf8 convert[s] elements of character 
> vectors to [...] UTF-8 [...], taking any marked encoding into 
> account." Since the marked encoding is wrong, so is the output of 
> enc2utf8().
>
> > enc2utf8(x)
> [1] "\u0080" "\u009e" "\u009a" "?"
>
> Now, when we set the encoding to "unknown" everything works fine.
>
> > x_un <- x
> > Encoding(x_un) <- "unknown"
> > print(x_un)
> [1] "?" "?" "?" "?"
> > (x_un2utf8 <- enc2utf8(x_un))
> [1] "?" "?" "?" "?"
>
> Long story short: The characters in the 80 to 9F range should not be 
> marked as "latin1" on CP1252 locales, IMHO.
>
> As a side-note: the output of localeToCharset() is also problematic, 
> since ISO8859-1 != CP1252.
>
> > localeToCharset()
> [1] "ISO8859-1"
>
> Finally on to Patrick Perry's bug report 
> (https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17329): 'On 
> Windows, enc2utf8("?") yields "|".'
>
> Unfortunately, I cannot reproduce this with the CP1252 locale, as can 
> be seen above. Probably, because the bug applies to the C locale 
> (sorry if this is somewhere apparent in the bug report and I missed it).
>
> > Sys.setlocale("LC_CTYPE", "C")
> [1] "C"
> > enc2utf8("?")
> [1] "|"
> > charToRaw("?")
> [1] fc
> > Encoding("?")
> [1] "unknown"
>
> This does not seem to be related to the marked encoding of the string, 
> so it seems to me that this is a different problem than the one above.
>
> Any advice on how to proceed further would be highly appreciated.
>
> Thanks!
> Daniel
>
> > sessionInfo()
> R Under development (unstable) (2017-09-11 r73238)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 14393)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=C
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0
>


	[[alternative HTML version deleted]]


From therneau at mayo.edu  Thu Sep 14 14:41:07 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 14 Sep 2017 07:41:07 -0500
Subject: [Rd] vcov and survival
In-Reply-To: <22970.15465.494390.45636@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
Message-ID: <9153c6$7ujt11@ironport10.mayo.edu>

Thanks all for your comments.  No one said "all the other vcov methods do ....", so I took 
some time this AM to look at several listed in the vcov help page.
Here is the code for the first few examples: data2 is constructed specifically to create 
an NA coef midway in the list.

data1 <- data.frame(y = c(1,2,10,50, 5, 4, 8, 40, 60, 20, 21, 22,
                           3,5,12,52, 7, 8,16, 48, 58, 28, 20,5),
                     x1 = factor(letters[rep(1:3, length=24)]),
                     x2 = factor(LETTERS[rep(1:4, length=24)]),
                     x3 = factor(rep(1:7, length=24)))
data2 <- subset(data1, x1 !='a' | x2 != 'C')

fit1 <- lm(y ~ x1*x2, data2)
table(is.na(coef(fit1)))
dim(vcov(fit1))

fit2 <- glm(y ~ x1*x2, data=data2, poisson)
table(is.na(coef(fit2)))
dim(vcov(fit2))

fit3 <- lme(y ~ x1*x2, random= ~1|x3, data2)

1. lm, mlm, glm, negbin objects all have an NA in coef(fit); and remove NA columns from 
the vcov object.

2. I expected polr to return a generalized inverse of the Hessian since vcov.polr has a 
call to ginv(object$Hessian), but it shortcuts earlier with a message
  "design appears to be rank-deficient, so dropping some coefs"
The undetermined coef appears in neither coef() more vcov().

3. rlm declares that it does not work with singular data.

4. multinom returns values for all coefficients and a full variance matrix.  However, the 
returned variance is rank-deficient.  It is essentially a g-inverse of the Hessian.

5. coxph and survreg report an NA coef, and return a generalized inverse of the Hessian 
matrix.  The g-inverse was chosen to be a particularly easy one in that you can spot 
redundant colums via a row/col of zeros.

6. nlme fails with a singularity error.  I didn't check out gls.

So my original question of whether I should make coxph consistent with the others has no 
answer, the 'others' are not consistent.

In response to two other points:
  >> In my opinion singularity should at least produce a warning...
I was one of those who lobbied heavily to change the singular.ok=FALSE default of lm to 
TRUE.  Data is messy, I have work to do, and don't need a package constantly harping at me.

In the same vein, stuffing NA into the vcov result is more pure, but would cause a lot of 
hassle.  I'm not sure that it is worth it.

For now, coxph will stay as is.
But again, thanks to all for comments and I'll look forward to any more discussion.

Terry T.


On 09/14/2017 03:23 AM, Martin Maechler wrote:
>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>      on Thu, 14 Sep 2017 10:13:02 +0200 writes:
> 
>>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>>      on Wed, 13 Sep 2017 22:45:07 +0000 writes:
> 
>      >> Dear Terry,
>      >> Even the behaviour of lm() and glm() isn't entirely consistent. In both cases, singularity results in NA coefficients by default, and these are reported in the model summary and coefficient vector, but not in the coefficient covariance matrix:
> 
>      >> ----------------	
> 
>      >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
>      >> +              data=longley)
>      >>> summary(mod.lm)
> 
>      >> Call:
>      >> lm(formula = Employed ~ GNP + Population + I(GNP + Population),
>      >> data = longley)
> 
>      >> Residuals:
>      >> Min       1Q   Median       3Q      Max
>      >> -0.80899 -0.33282 -0.02329  0.25895  1.08800
> 
>      >> Coefficients: (1 not defined because of singularities)
>      >> Estimate Std. Error t value Pr(>|t|)
>      >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
>      >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
>      >> Population          -0.40974    0.15214  -2.693   0.0184 *
>      >> I(GNP + Population)       NA         NA      NA       NA
>      >> ---
>      >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
>      >> Residual standard error: 0.5459 on 13 degrees of freedom
>      >> Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758
>      >> F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11
> 
>      >>> vcov(mod.lm)
>      >> (Intercept)           GNP Population
>      >> (Intercept) 190.0269691  0.1445617813 -2.0954381
>      >> GNP           0.1445618  0.0001133631 -0.0016054
>      >> Population   -2.0954381 -0.0016053999  0.0231456
>      >>> coef(mod.lm)
>      >> (Intercept)                 GNP          Population I(GNP + Population)
>      >> 88.93879831          0.06317244         -0.40974292                  NA
>      >>>
>      >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population),
>      >> +               data=longley)
>      >>> summary(mod.glm)
> 
>      >> Call:
>      >> glm(formula = Employed ~ GNP + Population + I(GNP + Population),
>      >> data = longley)
> 
>      >> Deviance Residuals:
>      >> Min        1Q    Median        3Q       Max
>      >> -0.80899  -0.33282  -0.02329   0.25895   1.08800
> 
>      >> Coefficients: (1 not defined because of singularities)
>      >> Estimate Std. Error t value Pr(>|t|)
>      >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
>      >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
>      >> Population          -0.40974    0.15214  -2.693   0.0184 *
>      >> I(GNP + Population)       NA         NA      NA       NA
>      >> ---
>      >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
>      >> (Dispersion parameter for gaussian family taken to be 0.2980278)
> 
>      >> Null deviance: 185.0088  on 15  degrees of freedom
>      >> Residual deviance:   3.8744  on 13  degrees of freedom
>      >> AIC: 30.715
> 
>      >> Number of Fisher Scoring iterations: 2
> 
>      >>> coef(mod.glm)
>      >> (Intercept)                 GNP          Population I(GNP + Population)
>      >> 88.93879831          0.06317244         -0.40974292                  NA
>      >>> vcov(mod.glm)
>      >> (Intercept)           GNP Population
>      >> (Intercept) 190.0269691  0.1445617813 -2.0954381
>      >> GNP           0.1445618  0.0001133631 -0.0016054
>      >> Population   -2.0954381 -0.0016053999  0.0231456
> 
>      >> ----------------	
> 
>      >> Moreoever, lm() has a singular.ok() argument that defaults to TRUE, but glm() doesn't have this argument:
> 
>      >> ----------------	
> 
>      >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
>      >> +              data=longley, singular.ok=FALSE)
>      >> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>      >> singular fit encountered
> 
>      >> ----------------	
> 
>      >> In my opinion, singularity should at least produce a warning, both in calls to lm() and glm(), and in summary() output. Even better, again in my opinion, would be to produce an error by default in this situation, but doing so would likely break too much existing code.
> 
>      > Yes, I would not want to change.  Note that this is from S
>      > already, i.e., long "ingrained".  I think there one argument was
>      > that there are situations with factor predictors of many levels
>      > and conceptually their 2- or even 3-way interactions (!)
>      > where it is neat to just fit the model, (-> get residuals and
>      > fitted values) and also see implicitly the "necessary rank" of
>      > prediction space, or rather even more specifically, you see for
>      > every factor how many levels are "distinguishable"/useful for
>      > prediction, given the data.
> 
>      >> I prefer NA to 0 for the redundant coefficients because it at least suggests that the decision about what to exclude is arbitrary, and of course simply excluding coefficients isn't the only way to proceed.
> 
>      > I'm less modest and would say *definitely*, NA's are highly
>      > prefered in such a situation.
> 
>      >> Finally, the differences in behaviour between coef() and vcov() and between lm() and glm() aren't really sensible.
> 
>      > I really haven't seen any difference between lm() and glm() in
>      > the example above.  Maybe you can point them out for me.
> 
> .. now I saw it:
>     lm() has  a 'singular.ok = TRUE' argument
>     which you can set to FALSE if you prefer an error to NA coefficients.
> 
> I also agree with you John that it would be nice if  glm() also
> got such an argument.
> Patches are welcome and seem easy. Nowadays we prefer them
> as attachments (diff/patch file!) at R's
>    https://bugs.r-project.org bugzilla
> against the svn source, here
>    https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
> and
>    https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd
> 
>      > I do quite agree that  vcov() should be compatible with
>      > coef() [and summary()]  for both 'lm' and 'glm' methods, i.e.,
>      > should get NA rows and columns there.  This would require
>      > eliminating these before e.g. using it in solve(<vcov>, *) etc,
>      > but I think it would be a good idea that the useR must deal with
>      > these NAs actively.
> 
>      > Shall "we" try and see the fallout in CRAN space?
> 
>      >> Maybe there's some reason for all this that escapes me.
>      > (for the first one---"no error"--- I gave a reason)
> 
>      >> Best,
>      >> John
> 
>      >> --------------------------------------
>      >> John Fox, Professor Emeritus
>      >> McMaster University
>      >> Hamilton, Ontario, Canada
>      >> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
>      >>> -----Original Message-----
>      >>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
>      >>> Therneau, Terry M., Ph.D.
>      >>> Sent: Wednesday, September 13, 2017 6:19 PM
>      >>> To: r-devel at r-project.org
>      >>> Subject: [Rd] vcov and survival
>      >>>
>      >>> I have just noticed a difference in behavior between coxph and lm/glm:
>      >>> if one or more of the coefficients from the fit in NA, then lm and glm
>      >>> omit that row/column from the variance matrix; while coxph retains it
>      >>> but sets the values to zero.
>      >>>
>      >>> Is this something that should be "fixed", i.e., made to agree? I
>      >>> suspect that doing so will break other packages, but then NA coefs are
>      >>> rather rare so perhaps not.
>      >>>
>      >>> Terry Therneau
>


From jfox at mcmaster.ca  Thu Sep 14 15:46:44 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 14 Sep 2017 13:46:44 +0000
Subject: [Rd] vcov and survival
In-Reply-To: <22970.15465.494390.45636@stat.math.ethz.ch>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>

Dear Martin,

I made three points which likely got lost because of the way I presented them:

(1) Singularity is an unusual situation and should be made more prominent. It typically reflects a problem with the data or the specification of the model. That's not to say that it *never* makes sense to allow singular fits (as in the situations you mentions). 

I'd favour setting singular.ok=FALSE as the default, but in the absence of that a warning or at least a note. A compromise would be to have a singular.ok option() that would be FALSE out of the box. 

Any changes would have to be made very carefully so as not to create chaos. That goes for the points below as well.

(2) coef() and vcov() behave inconsistently, which can be problematic because one often uses them together in code. 

(3) As you noticed in your second message, lm() has a singular.ok argument and glm() doesn't.

I'll take a look at the code for glm() with an eye towards creating a patch, but I'm a bit reluctant to mess with the code for something as important as glm().

Best,
 John



> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Thursday, September 14, 2017 4:23 AM
> To: Martin Maechler <maechler at stat.math.ethz.ch>
> Cc: Fox, John <jfox at mcmaster.ca>; Therneau, Terry M., Ph.D.
> <therneau at mayo.edu>; r-devel at r-project.org
> Subject: Re: [Rd] vcov and survival
> 
> >>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>     on Thu, 14 Sep 2017 10:13:02 +0200 writes:
> 
> >>>>> Fox, John <jfox at mcmaster.ca>
> >>>>>     on Wed, 13 Sep 2017 22:45:07 +0000 writes:
> 
>     >> Dear Terry,
>     >> Even the behaviour of lm() and glm() isn't entirely consistent. In both
> cases, singularity results in NA coefficients by default, and these are reported
> in the model summary and coefficient vector, but not in the coefficient
> covariance matrix:
> 
>     >> ----------------
> 
>     >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
>     >> +              data=longley)
>     >>> summary(mod.lm)
> 
>     >> Call:
>     >> lm(formula = Employed ~ GNP + Population + I(GNP + Population),
>     >> data = longley)
> 
>     >> Residuals:
>     >> Min       1Q   Median       3Q      Max
>     >> -0.80899 -0.33282 -0.02329  0.25895  1.08800
> 
>     >> Coefficients: (1 not defined because of singularities)
>     >> Estimate Std. Error t value Pr(>|t|)
>     >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
>     >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
>     >> Population          -0.40974    0.15214  -2.693   0.0184 *
>     >> I(GNP + Population)       NA         NA      NA       NA
>     >> ---
>     >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
>     >> Residual standard error: 0.5459 on 13 degrees of freedom
>     >> Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758
>     >> F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11
> 
>     >>> vcov(mod.lm)
>     >> (Intercept)           GNP Population
>     >> (Intercept) 190.0269691  0.1445617813 -2.0954381
>     >> GNP           0.1445618  0.0001133631 -0.0016054
>     >> Population   -2.0954381 -0.0016053999  0.0231456
>     >>> coef(mod.lm)
>     >> (Intercept)                 GNP          Population I(GNP + Population)
>     >> 88.93879831          0.06317244         -0.40974292                  NA
>     >>>
>     >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population),
>     >> +               data=longley)
>     >>> summary(mod.glm)
> 
>     >> Call:
>     >> glm(formula = Employed ~ GNP + Population + I(GNP + Population),
>     >> data = longley)
> 
>     >> Deviance Residuals:
>     >> Min        1Q    Median        3Q       Max
>     >> -0.80899  -0.33282  -0.02329   0.25895   1.08800
> 
>     >> Coefficients: (1 not defined because of singularities)
>     >> Estimate Std. Error t value Pr(>|t|)
>     >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
>     >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
>     >> Population          -0.40974    0.15214  -2.693   0.0184 *
>     >> I(GNP + Population)       NA         NA      NA       NA
>     >> ---
>     >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
>     >> (Dispersion parameter for gaussian family taken to be 0.2980278)
> 
>     >> Null deviance: 185.0088  on 15  degrees of freedom
>     >> Residual deviance:   3.8744  on 13  degrees of freedom
>     >> AIC: 30.715
> 
>     >> Number of Fisher Scoring iterations: 2
> 
>     >>> coef(mod.glm)
>     >> (Intercept)                 GNP          Population I(GNP + Population)
>     >> 88.93879831          0.06317244         -0.40974292                  NA
>     >>> vcov(mod.glm)
>     >> (Intercept)           GNP Population
>     >> (Intercept) 190.0269691  0.1445617813 -2.0954381
>     >> GNP           0.1445618  0.0001133631 -0.0016054
>     >> Population   -2.0954381 -0.0016053999  0.0231456
> 
>     >> ----------------
> 
>     >> Moreoever, lm() has a singular.ok() argument that defaults to TRUE, but
> glm() doesn't have this argument:
> 
>     >> ----------------
> 
>     >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
>     >> +              data=longley, singular.ok=FALSE)
>     >> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>     >> singular fit encountered
> 
>     >> ----------------
> 
>     >> In my opinion, singularity should at least produce a warning, both in calls
> to lm() and glm(), and in summary() output. Even better, again in my opinion,
> would be to produce an error by default in this situation, but doing so would
> likely break too much existing code.
> 
>     > Yes, I would not want to change.  Note that this is from S
>     > already, i.e., long "ingrained".  I think there one argument was
>     > that there are situations with factor predictors of many levels
>     > and conceptually their 2- or even 3-way interactions (!)
>     > where it is neat to just fit the model, (-> get residuals and
>     > fitted values) and also see implicitly the "necessary rank" of
>     > prediction space, or rather even more specifically, you see for
>     > every factor how many levels are "distinguishable"/useful for
>     > prediction, given the data.
> 
>     >> I prefer NA to 0 for the redundant coefficients because it at least suggests
> that the decision about what to exclude is arbitrary, and of course simply
> excluding coefficients isn't the only way to proceed.
> 
>     > I'm less modest and would say *definitely*, NA's are highly
>     > prefered in such a situation.
> 
>     >> Finally, the differences in behaviour between coef() and vcov() and
> between lm() and glm() aren't really sensible.
> 
>     > I really haven't seen any difference between lm() and glm() in
>     > the example above.  Maybe you can point them out for me.
> 
> .. now I saw it:
>    lm() has  a 'singular.ok = TRUE' argument
>    which you can set to FALSE if you prefer an error to NA coefficients.
> 
> I also agree with you John that it would be nice if  glm() also got such an
> argument.
> Patches are welcome and seem easy. Nowadays we prefer them as
> attachments (diff/patch file!) at R's
>   https://bugs.r-project.org bugzilla
> against the svn source, here
>   https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
> and
>   https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd
> 
>     > I do quite agree that  vcov() should be compatible with
>     > coef() [and summary()]  for both 'lm' and 'glm' methods, i.e.,
>     > should get NA rows and columns there.  This would require
>     > eliminating these before e.g. using it in solve(<vcov>, *) etc,
>     > but I think it would be a good idea that the useR must deal with
>     > these NAs actively.
> 
>     > Shall "we" try and see the fallout in CRAN space?
> 
>     >> Maybe there's some reason for all this that escapes me.
>     > (for the first one---"no error"--- I gave a reason)
> 
>     >> Best,
>     >> John
> 
>     >> --------------------------------------
>     >> John Fox, Professor Emeritus
>     >> McMaster University
>     >> Hamilton, Ontario, Canada
>     >> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
>     >>> -----Original Message-----
>     >>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
>     >>> Therneau, Terry M., Ph.D.
>     >>> Sent: Wednesday, September 13, 2017 6:19 PM
>     >>> To: r-devel at r-project.org
>     >>> Subject: [Rd] vcov and survival
>     >>>
>     >>> I have just noticed a difference in behavior between coxph and lm/glm:
>     >>> if one or more of the coefficients from the fit in NA, then lm and glm
>     >>> omit that row/column from the variance matrix; while coxph retains it
>     >>> but sets the values to zero.
>     >>>
>     >>> Is this something that should be "fixed", i.e., made to agree? I
>     >>> suspect that doing so will break other packages, but then NA coefs are
>     >>> rather rare so perhaps not.
>     >>>
>     >>> Terry Therneau


From jfox at mcmaster.ca  Thu Sep 14 15:52:32 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 14 Sep 2017 13:52:32 +0000
Subject: [Rd] vcov and survival
In-Reply-To: <9153c6$7ujt10@ironport10.mayo.edu>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <9153c6$7ujt10@ironport10.mayo.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366C35AA@FHSDB4H16-2.csu.mcmaster.ca>

Dear Terry,

It's not surprising that different modeling functions behave differently in this respect because there's no articulated standard. 

Please see my response to Martin for my take on the singular.ok argument. For a highly sophisticated user like you, singular.ok=TRUE isn't problematic -- you're not going to fail to notice an NA in the coefficient vector -- but I've seen students, e.g., doing exactly that. In principle having a singular.ok option defaulting to FALSE would satisfy everyone, but would probably break too much existing code.

Best,
 John

> -----Original Message-----
> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu]
> Sent: Thursday, September 14, 2017 8:41 AM
> To: Martin Maechler <maechler at stat.math.ethz.ch>
> Cc: Fox, John <jfox at mcmaster.ca>; Therneau, Terry M., Ph.D.
> <therneau at mayo.edu>; r-devel at r-project.org
> Subject: Re: [Rd] vcov and survival
> 
> Thanks all for your comments.  No one said "all the other vcov methods do
> ....", so I took some time this AM to look at several listed in the vcov help page.
> Here is the code for the first few examples: data2 is constructed specifically to
> create an NA coef midway in the list.
> 
> data1 <- data.frame(y = c(1,2,10,50, 5, 4, 8, 40, 60, 20, 21, 22,
>                            3,5,12,52, 7, 8,16, 48, 58, 28, 20,5),
>                      x1 = factor(letters[rep(1:3, length=24)]),
>                      x2 = factor(LETTERS[rep(1:4, length=24)]),
>                      x3 = factor(rep(1:7, length=24)))
> data2 <- subset(data1, x1 !='a' | x2 != 'C')
> 
> fit1 <- lm(y ~ x1*x2, data2)
> table(is.na(coef(fit1)))
> dim(vcov(fit1))
> 
> fit2 <- glm(y ~ x1*x2, data=data2, poisson)
> table(is.na(coef(fit2)))
> dim(vcov(fit2))
> 
> fit3 <- lme(y ~ x1*x2, random= ~1|x3, data2)
> 
> 1. lm, mlm, glm, negbin objects all have an NA in coef(fit); and remove NA
> columns from the vcov object.
> 
> 2. I expected polr to return a generalized inverse of the Hessian since vcov.polr
> has a call to ginv(object$Hessian), but it shortcuts earlier with a message
>   "design appears to be rank-deficient, so dropping some coefs"
> The undetermined coef appears in neither coef() more vcov().
> 
> 3. rlm declares that it does not work with singular data.
> 
> 4. multinom returns values for all coefficients and a full variance matrix.
> However, the returned variance is rank-deficient.  It is essentially a g-inverse of
> the Hessian.
> 
> 5. coxph and survreg report an NA coef, and return a generalized inverse of the
> Hessian matrix.  The g-inverse was chosen to be a particularly easy one in that
> you can spot redundant colums via a row/col of zeros.
> 
> 6. nlme fails with a singularity error.  I didn't check out gls.
> 
> So my original question of whether I should make coxph consistent with the
> others has no answer, the 'others' are not consistent.
> 
> In response to two other points:
>   >> In my opinion singularity should at least produce a warning...
> I was one of those who lobbied heavily to change the singular.ok=FALSE
> default of lm to TRUE.  Data is messy, I have work to do, and don't need a
> package constantly harping at me.
> 
> In the same vein, stuffing NA into the vcov result is more pure, but would
> cause a lot of hassle.  I'm not sure that it is worth it.
> 
> For now, coxph will stay as is.
> But again, thanks to all for comments and I'll look forward to any more
> discussion.
> 
> Terry T.
> 
> 
> On 09/14/2017 03:23 AM, Martin Maechler wrote:
> >>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >>>>>>      on Thu, 14 Sep 2017 10:13:02 +0200 writes:
> >
> >>>>>> Fox, John <jfox at mcmaster.ca>
> >>>>>>      on Wed, 13 Sep 2017 22:45:07 +0000 writes:
> >
> >      >> Dear Terry,
> >      >> Even the behaviour of lm() and glm() isn't entirely consistent. In both
> cases, singularity results in NA coefficients by default, and these are reported
> in the model summary and coefficient vector, but not in the coefficient
> covariance matrix:
> >
> >      >> ----------------
> >
> >      >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
> >      >> +              data=longley)
> >      >>> summary(mod.lm)
> >
> >      >> Call:
> >      >> lm(formula = Employed ~ GNP + Population + I(GNP + Population),
> >      >> data = longley)
> >
> >      >> Residuals:
> >      >> Min       1Q   Median       3Q      Max
> >      >> -0.80899 -0.33282 -0.02329  0.25895  1.08800
> >
> >      >> Coefficients: (1 not defined because of singularities)
> >      >> Estimate Std. Error t value Pr(>|t|)
> >      >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
> >      >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
> >      >> Population          -0.40974    0.15214  -2.693   0.0184 *
> >      >> I(GNP + Population)       NA         NA      NA       NA
> >      >> ---
> >      >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >      >> Residual standard error: 0.5459 on 13 degrees of freedom
> >      >> Multiple R-squared:  0.9791,	Adjusted R-squared:  0.9758
> >      >> F-statistic: 303.9 on 2 and 13 DF,  p-value: 1.221e-11
> >
> >      >>> vcov(mod.lm)
> >      >> (Intercept)           GNP Population
> >      >> (Intercept) 190.0269691  0.1445617813 -2.0954381
> >      >> GNP           0.1445618  0.0001133631 -0.0016054
> >      >> Population   -2.0954381 -0.0016053999  0.0231456
> >      >>> coef(mod.lm)
> >      >> (Intercept)                 GNP          Population I(GNP + Population)
> >      >> 88.93879831          0.06317244         -0.40974292                  NA
> >      >>>
> >      >>> mod.glm <- glm(Employed ~ GNP + Population + I(GNP + Population),
> >      >> +               data=longley)
> >      >>> summary(mod.glm)
> >
> >      >> Call:
> >      >> glm(formula = Employed ~ GNP + Population + I(GNP + Population),
> >      >> data = longley)
> >
> >      >> Deviance Residuals:
> >      >> Min        1Q    Median        3Q       Max
> >      >> -0.80899  -0.33282  -0.02329   0.25895   1.08800
> >
> >      >> Coefficients: (1 not defined because of singularities)
> >      >> Estimate Std. Error t value Pr(>|t|)
> >      >> (Intercept)         88.93880   13.78503   6.452 2.16e-05 ***
> >      >> GNP                  0.06317    0.01065   5.933 4.96e-05 ***
> >      >> Population          -0.40974    0.15214  -2.693   0.0184 *
> >      >> I(GNP + Population)       NA         NA      NA       NA
> >      >> ---
> >      >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >      >> (Dispersion parameter for gaussian family taken to be
> > 0.2980278)
> >
> >      >> Null deviance: 185.0088  on 15  degrees of freedom
> >      >> Residual deviance:   3.8744  on 13  degrees of freedom
> >      >> AIC: 30.715
> >
> >      >> Number of Fisher Scoring iterations: 2
> >
> >      >>> coef(mod.glm)
> >      >> (Intercept)                 GNP          Population I(GNP + Population)
> >      >> 88.93879831          0.06317244         -0.40974292                  NA
> >      >>> vcov(mod.glm)
> >      >> (Intercept)           GNP Population
> >      >> (Intercept) 190.0269691  0.1445617813 -2.0954381
> >      >> GNP           0.1445618  0.0001133631 -0.0016054
> >      >> Population   -2.0954381 -0.0016053999  0.0231456
> >
> >      >> ----------------
> >
> >      >> Moreoever, lm() has a singular.ok() argument that defaults to TRUE,
> but glm() doesn't have this argument:
> >
> >      >> ----------------
> >
> >      >>> mod.lm <- lm(Employed ~ GNP + Population + I(GNP + Population),
> >      >> +              data=longley, singular.ok=FALSE)
> >      >> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
> >      >> singular fit encountered
> >
> >      >> ----------------
> >
> >      >> In my opinion, singularity should at least produce a warning, both in
> calls to lm() and glm(), and in summary() output. Even better, again in my
> opinion, would be to produce an error by default in this situation, but doing so
> would likely break too much existing code.
> >
> >      > Yes, I would not want to change.  Note that this is from S
> >      > already, i.e., long "ingrained".  I think there one argument was
> >      > that there are situations with factor predictors of many levels
> >      > and conceptually their 2- or even 3-way interactions (!)
> >      > where it is neat to just fit the model, (-> get residuals and
> >      > fitted values) and also see implicitly the "necessary rank" of
> >      > prediction space, or rather even more specifically, you see for
> >      > every factor how many levels are "distinguishable"/useful for
> >      > prediction, given the data.
> >
> >      >> I prefer NA to 0 for the redundant coefficients because it at least
> suggests that the decision about what to exclude is arbitrary, and of course
> simply excluding coefficients isn't the only way to proceed.
> >
> >      > I'm less modest and would say *definitely*, NA's are highly
> >      > prefered in such a situation.
> >
> >      >> Finally, the differences in behaviour between coef() and vcov() and
> between lm() and glm() aren't really sensible.
> >
> >      > I really haven't seen any difference between lm() and glm() in
> >      > the example above.  Maybe you can point them out for me.
> >
> > .. now I saw it:
> >     lm() has  a 'singular.ok = TRUE' argument
> >     which you can set to FALSE if you prefer an error to NA coefficients.
> >
> > I also agree with you John that it would be nice if  glm() also got
> > such an argument.
> > Patches are welcome and seem easy. Nowadays we prefer them as
> > attachments (diff/patch file!) at R's
> >    https://bugs.r-project.org bugzilla against the svn source, here
> >    https://svn.r-project.org/R/trunk/src/library/stats/R/glm.R
> > and
> >    https://svn.r-project.org/R/trunk/src/library/stats/man/glm.Rd
> >
> >      > I do quite agree that  vcov() should be compatible with
> >      > coef() [and summary()]  for both 'lm' and 'glm' methods, i.e.,
> >      > should get NA rows and columns there.  This would require
> >      > eliminating these before e.g. using it in solve(<vcov>, *) etc,
> >      > but I think it would be a good idea that the useR must deal with
> >      > these NAs actively.
> >
> >      > Shall "we" try and see the fallout in CRAN space?
> >
> >      >> Maybe there's some reason for all this that escapes me.
> >      > (for the first one---"no error"--- I gave a reason)
> >
> >      >> Best,
> >      >> John
> >
> >      >> --------------------------------------
> >      >> John Fox, Professor Emeritus
> >      >> McMaster University
> >      >> Hamilton, Ontario, Canada
> >      >> Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >
> >      >>> -----Original Message-----
> >      >>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
> >      >>> Therneau, Terry M., Ph.D.
> >      >>> Sent: Wednesday, September 13, 2017 6:19 PM
> >      >>> To: r-devel at r-project.org
> >      >>> Subject: [Rd] vcov and survival
> >      >>>
> >      >>> I have just noticed a difference in behavior between coxph and
> lm/glm:
> >      >>> if one or more of the coefficients from the fit in NA, then lm and glm
> >      >>> omit that row/column from the variance matrix; while coxph retains it
> >      >>> but sets the values to zero.
> >      >>>
> >      >>> Is this something that should be "fixed", i.e., made to agree? I
> >      >>> suspect that doing so will break other packages, but then NA coefs
> are
> >      >>> rather rare so perhaps not.
> >      >>>
> >      >>> Terry Therneau
> >

From therneau at mayo.edu  Thu Sep 14 18:07:27 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 14 Sep 2017 11:07:27 -0500
Subject: [Rd] vcov and survival
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
References: <24682_1505341169_v8DMJSsK025685_9153c6$7uhrg4@ironport10.mayo.edu>
 <ACD1644AA6C67E4FBD0C350625508EC8366C32DC@FHSDB4H16-2.csu.mcmaster.ca>
 <22970.14862.518011.162206@stat.math.ethz.ch>
 <22970.15465.494390.45636@stat.math.ethz.ch>
 <ACD1644AA6C67E4FBD0C350625508EC8366C359A@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <9153c6$7umii9@ironport10.mayo.edu>



On 09/14/2017 08:46 AM, Fox, John wrote:
> Dear Martin,
> 
> I made three points which likely got lost because of the way I presented them:
> 
> (1) Singularity is an unusual situation and should be made more prominent. It typically reflects a problem with the data or the specification of the model. That's not to say that it*never*  makes sense to allow singular fits (as in the situations you mentions).

In my medical work singularity is far from unusual.  It often results from imbalance in a 
covariate, e.g., there are 4 pathological stages but one of them turns out to be rare.

> 
> I'd favour setting singular.ok=FALSE as the default, but in the absence of that a warning or at least a note. A compromise would be to have a singular.ok option() that would be FALSE out of the box.

Originally the lm() default was singular.ok=FALSE.  It was a major pain in the ass and 
there was widespread unhappiness.  Enough so that Splus changed it.  (And they were not 
always very responsive to the users, so it took a lot of unrest.)   Another early default 
was na.fail, based on similar logic that "missings are unusual and should require an 
explicit response".  Don't repeat these mistakes.

Terry T.

> 
> Any changes would have to be made very carefully so as not to create chaos. That goes for the points below as well.
> 
> (2) coef() and vcov() behave inconsistently, which can be problematic because one often uses them together in code.
> 
> (3) As you noticed in your second message, lm() has a singular.ok argument and glm() doesn't.
> 
> I'll take a look at the code for glm() with an eye towards creating a patch, but I'm a bit reluctant to mess with the code for something as important as glm().
> 
> Best,
>   John


From paul at stat.auckland.ac.nz  Fri Sep 15 00:39:25 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 15 Sep 2017 10:39:25 +1200
Subject: [Rd] y label for X11 graphics
In-Reply-To: <9153c6$7udq2s@ironport10.mayo.edu>
References: <9153c6$7udq2s@ironport10.mayo.edu>
Message-ID: <b4053915-bb5c-42b4-15f7-807a0e71916e@stat.auckland.ac.nz>


Sorry, can't reproduce on ...

 > sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

locale:
  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.1

... or on ...

 > sessionInfo()
R Under development (unstable) (2017-09-12 r73246)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pmur002/R/r-devel/BUILD/lib/libRblas.so
LAPACK: /home/pmur002/R/r-devel/BUILD/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.0

Paul

On 14/09/17 04:03, Therneau, Terry M., Ph.D. wrote:
> In the following plot, the y label is missing if it is too long.
> 
> x11(type="Xlib")
> plot(1:5, 1:5, ylab="Do, a deer, a female deer")   # missing label
> plot(1:5, 1:5, ylab="Do")                          # label is present
> 
> All is well for x11(type="cairo")
> 
> This is true both under R devel 2017-09-01 on xubuntu (my desktop), and 
> 3.4.1 on Centos 6.9 (department servers).
> 
> 
> A minor question is why my locally compiled version defaults to Xlib 
> rather than cairo, since both work as explicit arguments to the x11() 
> command.
> 
> Terry T.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From karl.nordstroem at uni-saarland.de  Thu Sep 14 17:03:00 2017
From: karl.nordstroem at uni-saarland.de (=?UTF-8?Q?Karl_Nordstr=c3=b6m?=)
Date: Thu, 14 Sep 2017 17:03:00 +0200
Subject: [Rd] Bug in order function
Message-ID: <94542694-45f6-27a8-6aa3-9c6dea53ffc3@uni-saarland.de>

Dear R-devel(opers),

I wanted to draw your attention to a small problem with the order 
function in base. According to the documentation, radix sort supports 
different orders for each argument. This breaks when one of the 
arguments is an object.

Please have a look to this stackoverflow question:

https://stackoverflow.com/questions/39737871/r-order-method-on-multiple-columns-gives-error-argument-lengths-differ

It describes the problem well and suggests a solution.

Although it is a niche case, it's a very easy thing to fix :)

Best regards,

Karl Nordstr?m


From jtelleriar at gmail.com  Sun Sep 17 00:39:18 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Sun, 17 Sep 2017 00:39:18 +0200
Subject: [Rd] R Configuration Variable: Maximum Memory Allocation per R
	Instance
In-Reply-To: <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
References: <CANNd7==ii2RReuCqgJNb0hw3AMycvmdKFLW8=wN-vADSc3aSXA@mail.gmail.com>
 <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
Message-ID: <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>

Dear R Developers,

In the same way that MySQL/MariaDB's Engine InnoDB or MyISAM/Aria have the
innodb_buffer_pool_size or the key_buffer_size for setting the maximum
amount of RAM which can be used by a Server Instance:

?Would it be possible to create an R Configuration Variable which fixes the
maximum amount of RAM memory to be used as Commit / Dynamic Memory
Allocation?

Thank you.
Juan

	[[alternative HTML version deleted]]


From mark.vanderloo at gmail.com  Sun Sep 17 10:24:31 2017
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Sun, 17 Sep 2017 08:24:31 +0000
Subject: [Rd] R Configuration Variable: Maximum Memory Allocation per R
	Instance
In-Reply-To: <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
References: <CANNd7==ii2RReuCqgJNb0hw3AMycvmdKFLW8=wN-vADSc3aSXA@mail.gmail.com>
 <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
 <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
Message-ID: <CAOKDuOhQ_pAh9cJH-Sd7CYy7rcakoH=1=e0CJ6vKDzCOqZen-w@mail.gmail.com>

Dear Juan,

I'm not deeply familiar with the DB's you mention but it seems to me that
me that 'memory.limits' does what you want on one OS and you can use shell
commands to limit R's memory usage for *nix-alike systems (see
?memory.limits). Also, Jeroen Ooms wrote a nice article about this in the
JSS: https://www.jstatsoft.org/article/view/v055i07 . There's also a
package for it: RAppArmor.

-M




Op zo 17 sep. 2017 om 00:39 schreef Juan Telleria <jtelleriar at gmail.com>:

> Dear R Developers,
>
> In the same way that MySQL/MariaDB's Engine InnoDB or MyISAM/Aria have the
> innodb_buffer_pool_size or the key_buffer_size for setting the maximum
> amount of RAM which can be used by a Server Instance:
>
> ?Would it be possible to create an R Configuration Variable which fixes the
> maximum amount of RAM memory to be used as Commit / Dynamic Memory
> Allocation?
>
> Thank you.
> Juan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From jtelleriar at gmail.com  Sun Sep 17 11:33:12 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Sun, 17 Sep 2017 11:33:12 +0200
Subject: [Rd] R Configuration Variable: Maximum Memory Allocation per R
	Instance
In-Reply-To: <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
References: <CANNd7==ii2RReuCqgJNb0hw3AMycvmdKFLW8=wN-vADSc3aSXA@mail.gmail.com>
 <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
 <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
Message-ID: <CANNd7=n8OGnhS+uKj8Rpqf_aVsXLiqN8VZ3E62nNc9GHgwLYtA@mail.gmail.com>

This variables already exist as I have been said, and are:
* memory.size
* memory.limit

R Documentation:

https://stat.ethz.ch/R-manual/R-devel/library/utils/html/memory.size.html

Thank you,
Juan

El 17/9/2017 12:39 a. m., "Juan Telleria" <jtelleriar at gmail.com> escribi?:

> Dear R Developers,
>
> In the same way that MySQL/MariaDB's Engine InnoDB or MyISAM/Aria have the
> innodb_buffer_pool_size or the key_buffer_size for setting the maximum
> amount of RAM which can be used by a Server Instance:
>
> ?Would it be possible to create an R Configuration Variable which fixes
> the maximum amount of RAM memory to be used as Commit / Dynamic Memory
> Allocation?
>
> Thank you.
> Juan
>

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Sun Sep 17 14:14:09 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sun, 17 Sep 2017 14:14:09 +0200
Subject: [Rd] R Configuration Variable: Maximum Memory Allocation per R
	Instance
In-Reply-To: <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
References: <CANNd7==ii2RReuCqgJNb0hw3AMycvmdKFLW8=wN-vADSc3aSXA@mail.gmail.com>
 <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
 <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
Message-ID: <CABFfbXv_X11JF2u0XWuwhPR7XxGcqtNYf9t7_ne9gZ61Lemebg@mail.gmail.com>

On Sun, Sep 17, 2017 at 12:39 AM, Juan Telleria <jtelleriar at gmail.com> wrote:
> Dear R Developers,
>
> In the same way that MySQL/MariaDB's Engine InnoDB or MyISAM/Aria have the
> innodb_buffer_pool_size or the key_buffer_size for setting the maximum
> amount of RAM which can be used by a Server Instance.

Memory is not controlled by R itself because packages may malloc()
directly. However most operating systems have features to limit
resources of a given process. The CRAN package 'unix' has wrappers for
posix setrlimit [1] e.g. unix::rlimit_as() limits address space. This
works pretty well, however I found that the way memory is managed and
counted varies a lot per OS and malloc implementation.

You can also set rlimits on a single evaluation via the rlimit
parameter in sys::eval_safe().


[1] http://pubs.opengroup.org/onlinepubs/009695399/functions/getrlimit.html


From jeroenooms at gmail.com  Mon Sep 18 00:11:37 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 18 Sep 2017 00:11:37 +0200
Subject: [Rd] R-devel object header changes that require reinstalling
	packages
In-Reply-To: <alpine.DEB.2.20.1709121326430.30468@luke-Latitude>
References: <alpine.DEB.2.20.1709121326430.30468@luke-Latitude>
Message-ID: <CABFfbXtOwdmeXO8cfyy3qvDpcWqgCZspd0btZ0GB8JVTDU7tVA@mail.gmail.com>

On Tue, Sep 12, 2017 at 8:28 PM,  <luke-tierney at uiowa.edu> wrote:
> (https://svn.r-project.org/R/branches/ALTREP/ALTREP.html outlines the
> framework).

Thank you for the nice writeup, hope this makes it into the R journal.
The spelling package finds a few typos:

> spelling::spell_check_files('ALTREP.md', lang = 'en_US')

  WORD              FOUND IN
abstrct           altrep.md:39
attemps           altrep.md:776
defern            altrep.md:767
hanling           altrep.md:699
representaitons   altrep.md:21

 (omitting false positives)


From skostyshak at ufl.edu  Mon Sep 18 05:09:58 2017
From: skostyshak at ufl.edu (Scott Kostyshak)
Date: Sun, 17 Sep 2017 23:09:58 -0400
Subject: [Rd] specifying name in the error message "promise already under
 evaluation"
Message-ID: <20170918030958.kq35oarjze4vupxm@steph>

Consider the following R code:

    abc <- function(x, y = y) {
      x + y
    }
    
    abc(x = 3)

which gives the following error:

    promise already under evaluation: recursive default argument
    reference or earlier problems?

If you google that error, you will find that it usually refers to the
situation given in the example above, although I'm sure the error is
more general and could be triggered in other situations.

I'm trying to think about how to improve the error for the most common
situation that triggers it. One simple way would be to give the name of
the promise. For example, I think that the following would already be an
improvement:

    promise "y" already under evaluation: recursive default argument
    reference or earlier problems?

Any thoughts?

Scott


-- 
Scott Kostyshak
Assistant Professor of Economics
University of Florida
https://people.clas.ufl.edu/skostyshak/


From zbbjornson at gmail.com  Sun Sep 17 20:23:58 2017
From: zbbjornson at gmail.com (Zach Bjornson)
Date: Sun, 17 Sep 2017 11:23:58 -0700
Subject: [Rd] Bug: Issues on Windows with SFN disabled
Message-ID: <CAD7tZLXB=73wY9tqLmYhTXyBB9DMO1WZXGz3U9pHz9KgEX4K=Q@mail.gmail.com>

Hello,

R appears to assume that Windows drives have short file names (SFN, 8.3)
enabled; for example, that "C:/Program Files/..." is addressable as
"C:/Progra~1/...". Newer versions of Windows have SFN disabled on non-OS
drives, however.

This means that if you install R on a non-OS drive, you
- can't start R.exe from the command line.
- consequently, anything that attempts to spawn a new R process also fails.
This includes a lot of the commands from the popular devtools package. More
discussion and background: https://github.com/hadley/devtools/issues/1514

I don't have access to bugzilla to file this there.

Thanks and best,
Zach

	[[alternative HTML version deleted]]


From will.landau at lilly.com  Mon Sep 18 00:25:58 2017
From: will.landau at lilly.com (Will Landau)
Date: Sun, 17 Sep 2017 22:25:58 +0000
Subject: [Rd] R-devel r73293 and the testthat package
Message-ID: <DM5P162MB0078AD3A8A59FA3E27C43645EA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>

Hello,


Windows R-devel no longer lets me use testthat even though the CRAN checks are pretty much clean. I have copied my session output below. 

Will


R Under development (unstable) (2017-09-16 r73293) -- "Unsuffered Consequences"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(testthat)
Error: package 'testthat' was installed by an R version with different internals; it needs to be reinstalled for use with this R version
> remove.packages("testthat")
Removing package from 'C:/Users/c240390/Documents/R/win-library/3.5'
(as 'lib' is unspecified)
> library(testthat)
Error in library(testthat) : there is no package called 'testthat'
> install.packages("testthat")
Installing package into 'C:/Users/c240390/Documents/R/win-library/3.5'
(as 'lib' is unspecified)
Warning in install.packages :
  unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5/PACKAGES'
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.5/testthat_1.0.2.zip'
Content type 'application/zip' length 1057889 bytes (1.0 MB)
downloaded 1.0 MB

package 'testthat' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\c240390\AppData\Local\Temp\RtmpS0Se9u\downloaded_packages
> library(testthat)
Error: package 'testthat' was installed by an R version with different internals; it needs to be reinstalled for use with this R version
> sessionInfo()
R Under development (unstable) (2017-09-16 r73293)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0


From will.landau at lilly.com  Mon Sep 18 00:33:36 2017
From: will.landau at lilly.com (Will Landau)
Date: Sun, 17 Sep 2017 22:33:36 +0000
Subject: [Rd] FW: CRAN check errors: drake 4.1.0 on
 r-devel-linux-x86_64-debian-clang
Message-ID: <DM5P162MB0078BF75B046A29FE9DBB91CEA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>

Hello,


The CRAN checks for the drake package (4.1.0) fail for r-devel-linux-x86_64-debian-clang. This happened right when crayon 1.3.4 was released, but I suspect the problem is not with crayon or drake, but with base R-devel. I cannot reproduce the error myself, but I have copied a minimal working example (MWE) below that should theoretically isolate the problem. 

`find_namespaced_functions()` is an internal function in drake that should work as long as base R is working, and all the failures appear to trace back there. Below the MWE is part of an existing email thread on this.

Will


# Walk through the body of f
# and find functions called with `::` or `:::`.
find_namespaced_functions <- function(f, found = character(0)){
  if (is.function(f)){
    return(find_namespaced_functions(body(f), found))
  } else if (is.call(f) && deparse(f[[1]]) %in% c("::", ":::")){
    found <- c(found, deparse(f))
  } else if (is.recursive(f)){
    v <- lapply(as.list(f), find_namespaced_functions, found)
    found <- unique(c(found, unlist(v)))
  }
  found
}

f <- function(x){
  digest::digest("Should be found.")
  digest:::digest("Should also be found.")
  digest("Should NOT be found.")
}

print(find_namespaced_functions(f))
# Expected output:
# [1] "digest::digest"  "digest:::digest"


From: Will Landau 
Sent: Saturday, September 16, 2017 11:16 PM
To: 'G?bor Cs?rdi' <csardi.gabor at gmail.com>; 'ligges at statistik.tu-dortmund.de' <ligges at statistik.tu-dortmund.de>
Subject: RE: [EXTERNAL] Re: CRAN submission crayon 1.3.4

Gabor and Uwe,


Thank you for promptly notifying me. I saw the https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-debian-clang/drake-00check.html, and I could not reproduce it either. I tried:

? Ubuntu 17.04 with gcc (though drake has no complied code)
? a fresh copy of 64-bit R-devel r73293 (2017-09-16)
? the latest version of all required packages, including crayon 1.3.4 
? `R CMD check --as-cran drake_4.1.0.tar.gz` with a https://cran.r-project.org/src/contrib/drake_4.1.0.tar.gz

From looking at the https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-debian-clang/drake-00check.html (which are exactly the ones Uwe mentioned), I strongly believe that the problem has nothing to do with Gabor?s `crayon` package. Rather, all the CRAN errors are closely related to a function in drake 4.1.0 called https://github.com/wlandau-lilly/drake/blob/master/R/dependencies.R#L73, which only depends on base R. I have attached a minimal working example that should theoretically isolate and reproduce the https://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-debian-clang/drake-00check.html.

Please let me know how you think we can proceed. I am actively maintaining `drake`, and I have a strong desire to fix all the problems and keep a clean production version on CRAN.

Will

-----Original Message-----
From: G?bor Cs?rdi [mailto:csardi.gabor at gmail.com] 
Sent: Saturday, September 16, 2017 3:43 PM
To: Will Landau <mailto:will.landau at lilly.com>
Subject: [EXTERNAL] Re: CRAN submission crayon 1.3.4

Hi,

I am sorry, the new crayon version, coming to CRAN, seems to break your package, drake. Hopefully CRAN can tell you on which platform and which R version this happens. I cannot reproduce this, unfortunately.

Let me know if you think this is my fault.

Gabor

On Sat, Sep 16, 2017 at 8:17 PM, Uwe Ligges <mailto:ligges at statistik.tu-dortmund.de> wrote:
> Thanks, we see in reverse dependencies:
>
> Package: drake
> Check: tests
> New result: ERROR
>???? Running ?testthat.R? [55s/138s]
>?? Running the tests in ?tests/testthat.R? failed.
>?? Complete output:
>???? > Sys.setenv("R_TESTS" = "")
>???? >
>???? > library(testthat)
>???? > library(drake)
>???? >
>???? > test_check("drake")
>???? 1. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#19)
>???? sort(find_namespaced_functions(crazy)) not equal to `ns`.
>???? Lengths differ: 0 vs 7
>
>
>???? 2. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#20)
>???? function_dependencies(crazy) not equal to list(functions = 
> sort(c(ns, "g", "runif", "sqrt")), variables = character(0)).
>???? Component "functions": Lengths (3, 10) differ (string compare on 
> first
> 3)
>???? Component "functions": 3 string mismatches
>
>
>???? 3. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#25)
>???? `d` not equal to sort(c("digest::digest", "runif", "stats::rnorm", 
> "stats::rpois")).
>???? Lengths differ: 1 vs 4
>
>
>???? 4. Error: namespaced workflow works (@test-namespaced.R#40)
> --------------------
>???? key 'base::list' ('objects') not found
>???? 1: readd("base::list", character_only = TRUE) at
> testthat/test-namespaced.R:40
>???? 2: cache$get(target)
>???? 3: self$get_value(self$get_hash(key, namespace), use_cache)
>???? 4: exists0(hash, envir)
>???? 5: vlapply(name, exists, envir = envir, inherits = FALSE, 
> USE.NAMES =
> FALSE)
>???? 6: vapply(X, FUN, logical(1), ...)
>???? 7: self$get_hash(key, namespace)
>
>???? testthat results
> ================================================================
>???? OK: 358 SKIPPED: 0 FAILED: 4
>???? 1. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#19)
>???? 2. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#20)
>???? 3. Failure: function_dependencies() works on :: and :::
> (@test-namespaced.R#25)
>???? 4. Error: namespaced workflow works (@test-namespaced.R#40)
>
>???? Error: testthat unit tests failed
>???? Execution halted
>
>
> Is this expected and has the author been informed?
>
> Best,
> Uwe
>
>
>
>
>
>
>
> On 15.09.2017 20:15, CRAN submission wrote:
>>
>> [This was generated from CRAN.R-project.org/submit.html]
>>
>> The following package was uploaded to CRAN:
>> ===========================================
>>
>> Package Information:
>> Package: crayon
>> Version: 1.3.4
>> Title: Colored Terminal Output
>> Author(s): G?bor Cs?rdi [aut, cre], Brodie Gaslam [ctb]
>> Maintainer: G?bor Cs?rdi <mailto:csardi.gabor at gmail.com>
>> Suggests: mockery, rstudioapi, testthat, withr
>> Description: Colored terminal output on terminals that support 'ANSI'
>>??? color and highlight codes. It also works in 'Emacs' 'ESS'.
>>??? 'ANSI' color support is automatically detected. Colors and
>>??? highlighting can be combined and nested. New styles can also
>>??? be created easily. This package was inspired by the 'chalk'
>>??? 'JavaScript' project.
>> License: MIT + file LICENSE
>> Imports: grDevices, methods, utils
>>
>>
>> The maintainer confirms that he or she has read and agrees to the 
>> CRAN policies.
>>
>> Submitter's comment: Please publish this one instead of the previously
>>??? submitted 1.3.3 version, that one has a bug that
>>??? breaks colors on some platforms.
>>
>> =================================================
>>
>> Original content of DESCRIPTION file:
>>
>> Package: crayon
>> Title: Colored Terminal Output
>> Version: 1.3.4
>> Authors at R: c(
>>????? person("G?bor", "Cs?rdi", , "mailto:csardi.gabor at gmail.com",
>>????? role = c("aut", "cre")),
>>????? person(
>>????? "Brodie", "Gaslam", email="mailto:brodie.gaslam at yahoo.com",
>>????? role=c("ctb"))
>>????? )
>> Description: Colored terminal output on terminals that support 'ANSI'
>>????? color and highlight codes. It also works in 'Emacs' 'ESS'. 'ANSI'
>>????? color support is automatically detected. Colors and highlighting can
>>????? be combined and nested. New styles can also be created easily.
>>????? This package was inspired by the 'chalk' 'JavaScript' project.
>> License: MIT + file LICENSE
>> LazyData: true
>> URL: https://github.com/r-lib/crayon#readme
>> BugReports: https://github.com/r-lib/crayon/issues
>> Collate: 'ansi-256.r' 'combine.r' 'string.r' 'utils.r'
>>????????? 'crayon-package.r' 'disposable.r' 'has_ansi.r' 'has_color.r'
>>????????? 'styles.r' 'machinery.r' 'parts.r' 'print.r' 'style-var.r'
>>????????? 'show.r' 'string_operations.r'
>> Imports: grDevices, methods, utils
>> Suggests: mockery, rstudioapi, testthat, withr
>> RoxygenNote: 6.0.1.9000
>> Encoding: UTF-8
>> Roxygen: list(markdown = TRUE)
>> NeedsCompilation: no
>> Packaged: 2017-09-15 18:14:04 UTC; gaborcsardi
>> Author: G?bor Cs?rdi [aut, cre],
>>??? Brodie Gaslam [ctb]
>> Maintainer: G?bor Cs?rdi <mailto:csardi.gabor at gmail.com>
>>
>

From pdalgd at gmail.com  Mon Sep 18 11:05:01 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 18 Sep 2017 11:05:01 +0200
Subject: [Rd] R-devel r73293 and the testthat package
In-Reply-To: <DM5P162MB0078AD3A8A59FA3E27C43645EA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>
References: <DM5P162MB0078AD3A8A59FA3E27C43645EA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>
Message-ID: <2DEC1C08-2FF2-4B31-B8E3-C442DC9E7198@gmail.com>


> On 18 Sep 2017, at 00:25 , Will Landau <will.landau at lilly.com> wrote:
> 
> Hello,
> 
> 
> Windows R-devel no longer lets me use testthat even though the CRAN checks are pretty much clean. I have copied my session output below. 
> 
> Will


Well, there us a reason for the nickname of R-devel:

> R Under development (unstable) (2017-09-16 r73293) -- "Unsuffered Consequences"

Re-stabilizing after the ALTREP updates took longer than expected, so some packages may not be updated yet. I suspect you should just wait and see if it comes around by itself.

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Mon Sep 18 11:10:39 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 18 Sep 2017 05:10:39 -0400
Subject: [Rd] R-devel r73293 and the testthat package
In-Reply-To: <DM5P162MB0078AD3A8A59FA3E27C43645EA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>
References: <DM5P162MB0078AD3A8A59FA3E27C43645EA620@DM5P162MB0078.NAMP162.PROD.OUTLOOK.COM>
Message-ID: <062f7d55-7442-60a4-5f41-a98006afc88c@gmail.com>

On 17/09/2017 6:25 PM, Will Landau wrote:
> Hello,
> 
> 
> Windows R-devel no longer lets me use testthat even though the CRAN checks are pretty much clean. I have copied my session output below.

There was a recent change in R-devel that means all packages with 
compiled code need to be re-installed from source.  Apparently the 
mirror you're using hasn't done that yet.  (Binary packages, i.e. .zip 
files, are essentially copies of installed packages.)

So you may be able to get it using

install.packages("testthat", type = "source")

if you have the tools installed.  Otherwise, you'll just need to wait 
until the new version shows up on your mirror.

Duncan Murdoch

> 
> Will
> 
> 
> R Under development (unstable) (2017-09-16 r73293) -- "Unsuffered Consequences"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> library(testthat)
> Error: package 'testthat' was installed by an R version with different internals; it needs to be reinstalled for use with this R version
>> remove.packages("testthat")
> Removing package from 'C:/Users/c240390/Documents/R/win-library/3.5'
> (as 'lib' is unspecified)
>> library(testthat)
> Error in library(testthat) : there is no package called 'testthat'
>> install.packages("testthat")
> Installing package into 'C:/Users/c240390/Documents/R/win-library/3.5'
> (as 'lib' is unspecified)
> Warning in install.packages :
>    unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5:
>    cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5/PACKAGES'
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.5/testthat_1.0.2.zip'
> Content type 'application/zip' length 1057889 bytes (1.0 MB)
> downloaded 1.0 MB
> 
> package 'testthat' successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
> 	C:\Users\c240390\AppData\Local\Temp\RtmpS0Se9u\downloaded_packages
>> library(testthat)
> Error: package 'testthat' was installed by an R version with different internals; it needs to be reinstalled for use with this R version
>> sessionInfo()
> R Under development (unstable) (2017-09-16 r73293)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jtelleriar at gmail.com  Mon Sep 18 11:46:04 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Mon, 18 Sep 2017 11:46:04 +0200
Subject: [Rd] R Configuration Variable: Maximum Memory Allocation per R
	Instance
In-Reply-To: <CABFfbXv_X11JF2u0XWuwhPR7XxGcqtNYf9t7_ne9gZ61Lemebg@mail.gmail.com>
References: <CANNd7==ii2RReuCqgJNb0hw3AMycvmdKFLW8=wN-vADSc3aSXA@mail.gmail.com>
 <CANNd7=k+urWYQxJufX1hV9v0bgmORPJku6BWZ4cN-nXATpYA4g@mail.gmail.com>
 <CANNd7==_05ZtU3KBm2OPJ1DrdN7KzGEbqSRx6sm5JWLeF=ZYkw@mail.gmail.com>
 <CABFfbXv_X11JF2u0XWuwhPR7XxGcqtNYf9t7_ne9gZ61Lemebg@mail.gmail.com>
Message-ID: <CANNd7=ndQ_RdoJo4nnLp8k17DbVbrHoKpo5VFBAQyH1COVF0pg@mail.gmail.com>

Very very interesting, if it is ok with it, I will post these observations
to Stack Overflow so that they are useful to other R Programmers, and make
more research on the topic, putting it all together. I could even do a
small article with my research.

I think this is a critical point if you want to have an R Instance and a
RDBMS in the same Server.

Thank you,
Juan

2017-09-17 14:14 GMT+02:00 Jeroen Ooms <jeroenooms at gmail.com>:

> On Sun, Sep 17, 2017 at 12:39 AM, Juan Telleria <jtelleriar at gmail.com>
> wrote:
> > Dear R Developers,
> >
> > In the same way that MySQL/MariaDB's Engine InnoDB or MyISAM/Aria have
> the
> > innodb_buffer_pool_size or the key_buffer_size for setting the maximum
> > amount of RAM which can be used by a Server Instance.
>
> Memory is not controlled by R itself because packages may malloc()
> directly. However most operating systems have features to limit
> resources of a given process. The CRAN package 'unix' has wrappers for
> posix setrlimit [1] e.g. unix::rlimit_as() limits address space. This
> works pretty well, however I found that the way memory is managed and
> counted varies a lot per OS and malloc implementation.
>
> You can also set rlimits on a single evaluation via the rlimit
> parameter in sys::eval_safe().
>
>
> [1] http://pubs.opengroup.org/onlinepubs/009695399/
> functions/getrlimit.html
>

	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Mon Sep 18 18:11:53 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Mon, 18 Sep 2017 16:11:53 +0000 (UTC)
Subject: [Rd] NEWS item about PR#17284
References: <920022160.3521219.1505751113145.ref@mail.yahoo.com>
Message-ID: <920022160.3521219.1505751113145@mail.yahoo.com>

Previous mentions:
- https://stat.ethz.ch/pipermail/r-devel/2017-July/074723.html
- https://stat.ethz.ch/pipermail/r-devel/2017-August/074737.html

The NEWS item corresponding to PR#17284 is in "CHANGES in R-devel". However, fix for PR#17284 is already included in R 3.4.2 beta.


From maechler at stat.math.ethz.ch  Tue Sep 19 09:18:46 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 Sep 2017 09:18:46 +0200
Subject: [Rd] NEWS item about PR#17284
In-Reply-To: <920022160.3521219.1505751113145@mail.yahoo.com>
References: <920022160.3521219.1505751113145.ref@mail.yahoo.com>
 <920022160.3521219.1505751113145@mail.yahoo.com>
Message-ID: <22976.50390.369501.968865@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Mon, 18 Sep 2017 16:11:53 +0000 writes:

    > Previous mentions:
    > - https://stat.ethz.ch/pipermail/r-devel/2017-July/074723.html
    > - https://stat.ethz.ch/pipermail/r-devel/2017-August/074737.html

    > The NEWS item corresponding to PR#17284 is in "CHANGES in R-devel". However, fix for PR#17284 is already included in R 3.4.2 beta.

Thank you, I'm sorry for not having acted sooner on this... and
will do now.

Note that this *also* applies to the PR#17292.
R/src/main/bind.c has been identical in R-devel and R-patched
(i.e. 3.4.2 beta) for quite some time, and the NEWS entries must
be moved to 3.4.2 beta.

Martin


From maechler at stat.math.ethz.ch  Tue Sep 19 09:27:59 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 Sep 2017 09:27:59 +0200
Subject: [Rd] NEWS item about PR#17284
In-Reply-To: <22976.50390.369501.968865@stat.math.ethz.ch>
References: <920022160.3521219.1505751113145.ref@mail.yahoo.com>
 <920022160.3521219.1505751113145@mail.yahoo.com>
 <22976.50390.369501.968865@stat.math.ethz.ch>
Message-ID: <22976.50943.59140.988803@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 19 Sep 2017 09:18:46 +0200 writes:

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Mon, 18 Sep 2017 16:11:53 +0000 writes:

    >> Previous mentions:
    >> - https://stat.ethz.ch/pipermail/r-devel/2017-July/074723.html
    >> - https://stat.ethz.ch/pipermail/r-devel/2017-August/074737.html

    >> The NEWS item corresponding to PR#17284 is in "CHANGES in R-devel". However, fix for PR#17284 is already included in R 3.4.2 beta.

    > Thank you, I'm sorry for not having acted sooner on this... and
    > will do now.

done.

The following is partly wrong:  The news entry for PR#17292 had
been in NEWS for R 3.4.2 beta already.

    > Note that this *also* applies to the PR#17292.
    > R/src/main/bind.c has been identical in R-devel and R-patched
    > (i.e. 3.4.2 beta) for quite some time, and the NEWS entries must
    > be moved to 3.4.2 beta.

    > Martin


From homerhanumat at gmail.com  Mon Sep 18 19:06:53 2017
From: homerhanumat at gmail.com (Homer White)
Date: Mon, 18 Sep 2017 13:06:53 -0400
Subject: [Rd] issue with promises for time parameter of rep()
Message-ID: <CAPYa3vTG0zEMoJonD1yEc8+9=yZ-2Lnp8FLG8U1o4iGT+d9ktg@mail.gmail.com>

Greetings,

The following is based on a question I raised on Stackoverflow:

https://stackoverflow.com/questions/46280120/calling-printls-str-in-function-affect-behavior-of-rep/46283979#46283979

Start a new R session with an empty Global Env.  Then define:

f <- function(n) {
  print(ls.str())
  rep("hello", times = n)
}

Now run:

f(x)

Instead of getting the expected "object 'x' not found" error, you get:

n : <missing>[1] "hello"

It was suggested that I file the issue here as a possible bug.


Regards,

Homer

	[[alternative HTML version deleted]]


From lionel at rstudio.com  Tue Sep 19 10:49:14 2017
From: lionel at rstudio.com (Lionel Henry)
Date: Tue, 19 Sep 2017 10:49:14 +0200
Subject: [Rd] issue with promises for time parameter of rep()
In-Reply-To: <CAPYa3vTG0zEMoJonD1yEc8+9=yZ-2Lnp8FLG8U1o4iGT+d9ktg@mail.gmail.com>
References: <CAPYa3vTG0zEMoJonD1yEc8+9=yZ-2Lnp8FLG8U1o4iGT+d9ktg@mail.gmail.com>
Message-ID: <992E43D2-18E4-4AEF-ABC3-A1C16FE87E5E@rstudio.com>

Here is the same issue with closures:

    g <- function(n) {
      missing(n)
    }
    f <- function(n, force) {
      if (force) {
        tryCatch(n, error = function(...) NULL)
      }
      g(n)
    }

    g(`_x`)
    #> [1] FALSE

    f(`_x`, force = FALSE)
    #> [1] FALSE

    f(`_x`, force = TRUE)
    #> [1] TRUE

Lionel

> On 18 sept. 2017, at 19:06, Homer White <homerhanumat at gmail.com> wrote:
> 
> Greetings,
> 
> The following is based on a question I raised on Stackoverflow:
> 
> https://stackoverflow.com/questions/46280120/calling-printls-str-in-function-affect-behavior-of-rep/46283979#46283979
> 
> Start a new R session with an empty Global Env.  Then define:
> 
> f <- function(n) {
>  print(ls.str())
>  rep("hello", times = n)
> }
> 
> Now run:
> 
> f(x)
> 
> Instead of getting the expected "object 'x' not found" error, you get:
> 
> n : <missing>[1] "hello"
> 
> It was suggested that I file the issue here as a possible bug.
> 
> 
> Regards,
> 
> Homer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lille.stor at gmx.com  Tue Sep 19 12:53:38 2017
From: lille.stor at gmx.com (lille stor)
Date: Tue, 19 Sep 2017 12:53:38 +0200
Subject: [Rd] R and Visual Studio
References: <trinity-170edabd-6be0-4bb8-844a-b48f58def3f5-1505818344254@3c-app-mailcom-bs13>
Message-ID: <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>

Hi,
?
I am trying to build R using Visual Studio 2010 but without success. My question is if it possible build?R with this compiler anyway?
?
If not, could someone please tell how to link one's C code against both the static and shared libraries of R for Windows (that comes from the official website found here https://cran.r-project.org/mirrors.html)?
?
Thank you!


From edd at debian.org  Tue Sep 19 14:07:42 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Sep 2017 07:07:42 -0500
Subject: [Rd] R and Visual Studio
In-Reply-To: <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>
References: <trinity-170edabd-6be0-4bb8-844a-b48f58def3f5-1505818344254@3c-app-mailcom-bs13>
 <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>
Message-ID: <22977.2190.558095.267328@bud.eddelbuettel.com>


On 19 September 2017 at 12:53, lille stor wrote:
| I am trying to build R using Visual Studio 2010 but without success. My question is if it possible build?R with this compiler anyway?

In general, no.

[ I believe there is an exception if you're a true compiler expert and really
know what you're doing. No such person is part of the wider R community as
far as I know. ]

| If not, could someone please tell how to link one's C code against both the static and shared libraries of R for Windows (that comes from the official website found here https://cran.r-project.org/mirrors.html)?

By reading the Fine Manuals that came with your version of R, in particular
'R Installation and Administration' and 'Writing R Extensions'.  You will
need to install Rtools which provides the compiler R uses on Windows.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd at debian.org  Tue Sep 19 14:09:59 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Sep 2017 07:09:59 -0500
Subject: [Rd] R and Visual Studio
In-Reply-To: <22977.2190.558095.267328@bud.eddelbuettel.com>
References: <trinity-170edabd-6be0-4bb8-844a-b48f58def3f5-1505818344254@3c-app-mailcom-bs13>
 <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>
 <22977.2190.558095.267328@bud.eddelbuettel.com>
Message-ID: <22977.2327.623294.29339@bud.eddelbuettel.com>


On 19 September 2017 at 07:07, Dirk Eddelbuettel wrote:
| [ I believe there is an exception if you're a true compiler expert and really
| know what you're doing. No such person is part of the wider R community as
| far as I know. ]

This was missing an important qualifier for "with particular knowledge of
visual c/++ and windows". 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From pauljohn32 at gmail.com  Tue Sep 19 19:04:38 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 19 Sep 2017 12:04:38 -0500
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
Message-ID: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>

Last week one of our clients reported trouble with a csv file I
generated with write.table.  He said that columns with quotes for
character variables were rejected by their data importer, which was
revised to match the way Microsoft Excel uses quotation marks in
character variables.  I explained to them that quoted character
variables are virtuous and wise, of course, but they say Microsoft
Excel CSV export no longer quotes characters unless they include
commas in the values.

They showed me a CSV file from Excel that looked like this

x1,x2,x3,x4 5 6
fred,barney,betty,x
bambam,"fred,wilma",pebbles,y

Note how the quotes only happen on row 2 column 2. I was surprised it
did that, but now I have some pressure to write a csv maker that has
that structure.  Its weird, even when there are spaces in values there
are no quotation marks.

Has anybody done this and verified that it matches CSV from MS Excel?
If I succeed will you consider a patch?

pj
-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From luke-tierney at uiowa.edu  Tue Sep 19 20:56:15 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 19 Sep 2017 13:56:15 -0500 (CDT)
Subject: [Rd] issue with promises for time parameter of rep()
In-Reply-To: <CAPYa3vTG0zEMoJonD1yEc8+9=yZ-2Lnp8FLG8U1o4iGT+d9ktg@mail.gmail.com>
References: <CAPYa3vTG0zEMoJonD1yEc8+9=yZ-2Lnp8FLG8U1o4iGT+d9ktg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1709191354470.5458@luke-Latitude>

Thanks. Fixed in R-devel and R-patched. This now gives

f <- function(n) {
     print(ls.str())
     rep("hello", times = n)
}
f(n)
## n : <missing>
## Error in f(n) : object 'n' not found
## In addition: Warning message:
## In f(n) : restarting interrupted promise evaluation

Best,

luke

On Mon, 18 Sep 2017, Homer White wrote:

> Greetings,
>
> The following is based on a question I raised on Stackoverflow:
>
> https://stackoverflow.com/questions/46280120/calling-printls-str-in-function-affect-behavior-of-rep/46283979#46283979
>
> Start a new R session with an empty Global Env.  Then define:
>
> f <- function(n) {
>  print(ls.str())
>  rep("hello", times = n)
> }
>
> Now run:
>
> f(x)
>
> Instead of getting the expected "object 'x' not found" error, you get:
>
> n : <missing>[1] "hello"
>
> It was suggested that I file the issue here as a possible bug.
>
>
> Regards,
>
> Homer
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From edd at debian.org  Tue Sep 19 21:09:09 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 19 Sep 2017 14:09:09 -0500
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
In-Reply-To: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
References: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
Message-ID: <22977.27478.303.764144@bud.eddelbuettel.com>


On 19 September 2017 at 12:04, Paul Johnson wrote:
| They showed me a CSV file from Excel that looked like this
| 
| x1,x2,x3,x4 5 6
| fred,barney,betty,x
| bambam,"fred,wilma",pebbles,y
| 
| Note how the quotes only happen on row 2 column 2. I was surprised it
| did that, but now I have some pressure to write a csv maker that has
| that structure.  Its weird, even when there are spaces in values there
| are no quotation marks.
| 
| Has anybody done this and verified that it matches CSV from MS Excel?
| If I succeed will you consider a patch?

R> data.table::fread("/tmp/paul.csv")
       x1         x2      x3 x4 5 6
1:   fred     barney   betty      x
2: bambam fred,wilma pebbles      y
R> data.table::fread("/tmp/paul.csv")
       x1         x2      x3 x4
1:   fred     barney   betty  x
2: bambam fred,wilma pebbles  y
R> 

The only difference is that between calls one and two, I removed the stray
    "5 6"
from the first line.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From istazahn at gmail.com  Tue Sep 19 22:10:50 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 19 Sep 2017 16:10:50 -0400
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
In-Reply-To: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
References: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
Message-ID: <CA+vqiLFmSb3QNTvHUM=9xzyB+y062R3CW9e7JT-McBXDcU0=_A@mail.gmail.com>

On Tue, Sep 19, 2017 at 1:04 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Last week one of our clients reported trouble with a csv file I
> generated with write.table.  He said that columns with quotes for
> character variables were rejected by their data importer, which was
> revised to match the way Microsoft Excel uses quotation marks in
> character variables.  I explained to them that quoted character
> variables are virtuous and wise, of course, but they say Microsoft
> Excel CSV export no longer quotes characters unless they include
> commas in the values.
>
> They showed me a CSV file from Excel that looked like this
>
> x1,x2,x3,x4 5 6
> fred,barney,betty,x
> bambam,"fred,wilma",pebbles,y
>
> Note how the quotes only happen on row 2 column 2. I was surprised it
> did that, but now I have some pressure to write a csv maker that has
> that structure.

I think you should resist that pressure. It really makes no sense to
write a .csv parser that _only_ supports .csv files created by Excel.
If you're going to use Excel as a model, a more sensible approach
would be to write a csv parser that supports all the formats that
Excel itself supports; Excel of course has no problem importing

"x1","x2","x3","x4"
"fred","barney","betty","x"
"bambam","fred,wilma","pebbles","y"

So, seriously, tell them to just fix their csv parser. Since they seem
hung up on Excel, it may help to point out that it does in fact import
csv produced by write.csv without complaint.

Best,
Ista

 Its weird, even when there are spaces in values there
> are no quotation marks.
>
> Has anybody done this and verified that it matches CSV from MS Excel?
> If I succeed will you consider a patch?
>
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Sep 19 23:45:13 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Sep 2017 17:45:13 -0400
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
In-Reply-To: <CA+vqiLFmSb3QNTvHUM=9xzyB+y062R3CW9e7JT-McBXDcU0=_A@mail.gmail.com>
References: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
 <CA+vqiLFmSb3QNTvHUM=9xzyB+y062R3CW9e7JT-McBXDcU0=_A@mail.gmail.com>
Message-ID: <6c9c1135-afcc-2575-ab7e-afde81f9f913@gmail.com>

On 19/09/2017 4:10 PM, Ista Zahn wrote:
> On Tue, Sep 19, 2017 at 1:04 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> Last week one of our clients reported trouble with a csv file I
>> generated with write.table.  He said that columns with quotes for
>> character variables were rejected by their data importer, which was
>> revised to match the way Microsoft Excel uses quotation marks in
>> character variables.  I explained to them that quoted character
>> variables are virtuous and wise, of course, but they say Microsoft
>> Excel CSV export no longer quotes characters unless they include
>> commas in the values.
>>
>> They showed me a CSV file from Excel that looked like this
>>
>> x1,x2,x3,x4 5 6
>> fred,barney,betty,x
>> bambam,"fred,wilma",pebbles,y
>>
>> Note how the quotes only happen on row 2 column 2. I was surprised it
>> did that, but now I have some pressure to write a csv maker that has
>> that structure.
> 
> I think you should resist that pressure.

That depends on whether this is a paying client or not.

 > It really makes no sense to
> write a .csv parser that _only_ supports .csv files created by Excel.

That's true, but if that's what they want to do, and they're willing to 
pay to be able to write files that imitate Excel, then why not do what 
they ask?

On the other hand, if they aren't willing to pay for the work, then you 
should lecture them on how silly their request is.

In any case, base R functions should not include nonsense, so this is 
not something that should go into R.

Duncan Murdoch

> If you're going to use Excel as a model, a more sensible approach
> would be to write a csv parser that supports all the formats that
> Excel itself supports; Excel of course has no problem importing
> 
> "x1","x2","x3","x4"
> "fred","barney","betty","x"
> "bambam","fred,wilma","pebbles","y"
> 
> So, seriously, tell them to just fix their csv parser. Since they seem
> hung up on Excel, it may help to point out that it does in fact import
> csv produced by write.csv without complaint.
> 
> Best,
> Ista
> 
>   Its weird, even when there are spaces in values there
>> are no quotation marks.
>>
>> Has anybody done this and verified that it matches CSV from MS Excel?
>> If I succeed will you consider a patch?
>>
>> pj
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Wed Sep 20 10:02:32 2017
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Wed, 20 Sep 2017 09:02:32 +0100
Subject: [Rd] R and Visual Studio
In-Reply-To: <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>
References: <trinity-170edabd-6be0-4bb8-844a-b48f58def3f5-1505818344254@3c-app-mailcom-bs13>
 <trinity-cddc4f47-6b93-4b2a-a871-008b244b7b05-1505818418311@3c-app-mailcom-bs13>
Message-ID: <4A4BC300-51CB-4A47-A96F-6424EC84832F@stats.ox.ac.uk>



> On 19 Sep 2017, at 11:53, lille stor <lille.stor at gmx.com> wrote:
> 
> Hi,
> 
> I am trying to build R using Visual Studio 2010 but without success. My question is if it possible build R with this compiler anyway?

It has been done, in the distant past.  However, none of the attempts produced a build which could pass R's checks.
> 
> If not, could someone please tell how to link one's C code against both the static and shared libraries of R for Windows (that comes from the official website found here https://cran.r-project.org/mirrors.html)?

It is not too difficult to make and load a DLL with VS and even link to R internals using an import library.  Details are in the manual or linked from there (section 5.5).  (There is no static library for R on Windows.)

> 
> Thank you!
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pauljohn32 at gmail.com  Wed Sep 20 18:53:05 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 20 Sep 2017 11:53:05 -0500
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
In-Reply-To: <6c9c1135-afcc-2575-ab7e-afde81f9f913@gmail.com>
References: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
 <CA+vqiLFmSb3QNTvHUM=9xzyB+y062R3CW9e7JT-McBXDcU0=_A@mail.gmail.com>
 <6c9c1135-afcc-2575-ab7e-afde81f9f913@gmail.com>
Message-ID: <CAErODj_8ULqzYPb5tyXPzady9NMJ9RYG=Zqo4u=GwxRGQTyvig@mail.gmail.com>

On Tue, Sep 19, 2017 at 4:45 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
>
> That's true, but if that's what they want to do, and they're willing to pay
> to be able to write files that imitate Excel, then why not do what they ask?
>
> On the other hand, if they aren't willing to pay for the work, then you
> should lecture them on how silly their request is.
>
> In any case, base R functions should not include nonsense, so this is not
> something that should go into R.
>
> Duncan Murdoch
>

I understand.  This is a paying client, I'm going where the money goes.

Here's my current working example of a function that writes a CSV
exactly as Excel does. I've posted this into StackOverflow
(https://stackoverflow.com/questions/25743018/how-to-conditionally-remove-quotes-in-write-csv).
It is buried under a thread, maybe will not get much attention and
bug-checking. Oh, well, I can hope. Processes variables
column-by-column, I don't know how to do it differently.



##' Write CSV files with quotes same as MS Excel 2013 or newer
##'
##' R's write.csv inserts quotes around all elements in a character
##' vector (if quote = TRUE).  In contrast, MS Excel CSV export no
##' longer inserts quotation marks on all elements in character
##' variables, except when the cells include commas or quotation
##' marks.  This function generates CSV files that are, so far as we
##' know, exactly the same "quoted style" as MS Excel CSV export
##' files.
##'
##' This works by manually inserting quotation marks where necessary and
##' turning FALSE R's own method to insert quotation marks.
##' @param x a data frame
##' @param file character string for file name
##' @param row.names Default FALSE for row.names
##' @importFrom utils write.table
##' @return the return from write.table, using revised quotes
##' @export
##' @author Paul Johnson
##' @examples
##' set.seed(234)
##' x1 <- data.frame(x1 = c("a", "b,c", "b", "The \"Washington, DC\""),
##'       x2 = rnorm(4), stringsAsFactors = FALSE)
##' x1
##' fn <- tempfile(pattern = "testcsv", fileext = ".csv")
##' writeCSV(x1, file = fn)
##' readLines(fn)
##' x2 <- read.table(fn, sep = ",", header = TRUE, stringsAsFactors = FALSE)
##' all.equal(x1,x2)
writeCSV <- function(x, file, row.names = FALSE){
    xischar <- colnames(x)[sapply(x, is.character)]
    for(jj in xischar){
        x[ , jj] <- gsub('"', '""', x[ , jj], fixed = TRUE)
        needsquotes <- grep('[\",]', x[ ,jj])
        x[needsquotes, jj] <- paste0("\"", x[needsquotes, jj], "\"")
    }
    write.table(x, file = file, sep = ",", quote = FALSE,
                row.names = row.names)
}

Output:

>  set.seed(234)
>  x1 <- data.frame(x1 = c("a", "b,c", "b", "The \"Washington, DC\""),
+        x2 = rnorm(4), stringsAsFactors = FALSE)
>  x1
                    x1         x2
1                    a  0.6607697
2                  b,c -2.0529830
3                    b -1.4992061
4 The "Washington, DC"  1.4712331
>  fn <- tempfile(pattern = "testcsv", fileext = ".csv")
>  writeCSV(x1, file = fn)
>  readLines(fn)
[1] "x1,x2"
[2] "a,0.660769736644892"
[3] "\"b,c\",-2.052983003941"
[4] "b,-1.49920605110092"
[5] "\"The \"\"Washington, DC\"\"\",1.4712331168047"
>  x2 <- read.table(fn, sep = ",", header = TRUE, stringsAsFactors = FALSE)
>  all.equal(x1,x2)
[1] TRUE

I already see one problem, that I've got no special arrangement for
column names with commas or quotes. People who want column names with
those things are even more wrong than the people write a parser that
can't understand quotes on character variables.

-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From dwinsemius at comcast.net  Wed Sep 20 19:39:50 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Sep 2017 10:39:50 -0700
Subject: [Rd] what do you think about write.table(... qmethod = "excel")?
In-Reply-To: <CAErODj_8ULqzYPb5tyXPzady9NMJ9RYG=Zqo4u=GwxRGQTyvig@mail.gmail.com>
References: <CAErODj-3gXgtoDZf8LMiw=1eQZOfUeTy=-vqr1pgstW-JdBFUw@mail.gmail.com>
 <CA+vqiLFmSb3QNTvHUM=9xzyB+y062R3CW9e7JT-McBXDcU0=_A@mail.gmail.com>
 <6c9c1135-afcc-2575-ab7e-afde81f9f913@gmail.com>
 <CAErODj_8ULqzYPb5tyXPzady9NMJ9RYG=Zqo4u=GwxRGQTyvig@mail.gmail.com>
Message-ID: <F03655EC-1C9C-47C7-91FB-350470103A6B@comcast.net>


> On Sep 20, 2017, at 9:53 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
> On Tue, Sep 19, 2017 at 4:45 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> 
>> 
>> That's true, but if that's what they want to do, and they're willing to pay
>> to be able to write files that imitate Excel, then why not do what they ask?
>> 
>> On the other hand, if they aren't willing to pay for the work, then you
>> should lecture them on how silly their request is.
>> 
>> In any case, base R functions should not include nonsense, so this is not
>> something that should go into R.
>> 
>> Duncan Murdoch
>> 
> 
> I understand.  This is a paying client, I'm going where the money goes.
> 
> Here's my current working example of a function that writes a CSV
> exactly as Excel does. I've posted this into StackOverflow
> (https://stackoverflow.com/questions/25743018/how-to-conditionally-remove-quotes-in-write-csv).
> It is buried under a thread, maybe will not get much attention and
> bug-checking. Oh, well, I can hope. Processes variables
> column-by-column, I don't know how to do it differently.
> 
> 
> 
> ##' Write CSV files with quotes same as MS Excel 2013 or newer
> ##'
> ##' R's write.csv inserts quotes around all elements in a character
> ##' vector (if quote = TRUE).  In contrast, MS Excel CSV export no
> ##' longer inserts quotation marks on all elements in character
> ##' variables, except when the cells include commas or quotation
> ##' marks.  This function generates CSV files that are, so far as we
> ##' know, exactly the same "quoted style" as MS Excel CSV export
> ##' files.
> ##'
> ##' This works by manually inserting quotation marks where necessary and
> ##' turning FALSE R's own method to insert quotation marks.
> ##' @param x a data frame
> ##' @param file character string for file name
> ##' @param row.names Default FALSE for row.names
> ##' @importFrom utils write.table
> ##' @return the return from write.table, using revised quotes
> ##' @export
> ##' @author Paul Johnson
> ##' @examples
> ##' set.seed(234)
> ##' x1 <- data.frame(x1 = c("a", "b,c", "b", "The \"Washington, DC\""),
> ##'       x2 = rnorm(4), stringsAsFactors = FALSE)
> ##' x1
> ##' fn <- tempfile(pattern = "testcsv", fileext = ".csv")
> ##' writeCSV(x1, file = fn)
> ##' readLines(fn)
> ##' x2 <- read.table(fn, sep = ",", header = TRUE, stringsAsFactors = FALSE)
> ##' all.equal(x1,x2)
> writeCSV <- function(x, file, row.names = FALSE){
>    xischar <- colnames(x)[sapply(x, is.character)]

? Should that be:


    xIsCharOrFactor <- colnames(x)[sapply(x, function(z) is.character(z) | is.factor(z) )]

Just asking. No testing done.
__ 
David.

>    for(jj in xischar){
>        x[ , jj] <- gsub('"', '""', x[ , jj], fixed = TRUE)
>        needsquotes <- grep('[\",]', x[ ,jj])
>        x[needsquotes, jj] <- paste0("\"", x[needsquotes, jj], "\"")
>    }
>    write.table(x, file = file, sep = ",", quote = FALSE,
>                row.names = row.names)
> }
> 
> Output:
> 
>> set.seed(234)
>> x1 <- data.frame(x1 = c("a", "b,c", "b", "The \"Washington, DC\""),
> +        x2 = rnorm(4), stringsAsFactors = FALSE)
>> x1
>                    x1         x2
> 1                    a  0.6607697
> 2                  b,c -2.0529830
> 3                    b -1.4992061
> 4 The "Washington, DC"  1.4712331
>> fn <- tempfile(pattern = "testcsv", fileext = ".csv")
>> writeCSV(x1, file = fn)
>> readLines(fn)
> [1] "x1,x2"
> [2] "a,0.660769736644892"
> [3] "\"b,c\",-2.052983003941"
> [4] "b,-1.49920605110092"
> [5] "\"The \"\"Washington, DC\"\"\",1.4712331168047"
>> x2 <- read.table(fn, sep = ",", header = TRUE, stringsAsFactors = FALSE)
>> all.equal(x1,x2)
> [1] TRUE
> 
> I already see one problem, that I've got no special arrangement for
> column names with commas or quotes. People who want column names with
> those things are even more wrong than the people write a parser that
> can't understand quotes on character variables.
> 
> -- 
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From tomas.kalibera at gmail.com  Thu Sep 21 12:20:54 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 21 Sep 2017 12:20:54 +0200
Subject: [Rd] unpackPkgZip: "unable to move temporary installation" due
 to antivirus
In-Reply-To: <CAM2FmMro4LgtkbjJjNvQ5y0ZTpVAqoDSvc4HUeNW31SvnWwbgA@mail.gmail.com>
References: <CAM2FmMro4LgtkbjJjNvQ5y0ZTpVAqoDSvc4HUeNW31SvnWwbgA@mail.gmail.com>
Message-ID: <1d11b8ba-cd5a-87bc-1604-e18b83b1f181@gmail.com>

This windows/anti-virus problem has been worked around in R-devel 73329.
Thanks to Mike for reporting this and testing the changes.

Best
Tomas

On 09/13/2017 01:40 AM, Mike Toews wrote:
> Hi,
>
> Me and an office colleague on Microsoft Windows 10 PCs are having
> difficulty installing any package. This is a recent issue for us, and
> we suspect our McAfee antivirus has modified by our IT department.
> Let's take, for example, install.packages("mypackage"), here is the
> output:
>
> package ?mypackage? successfully unpacked and MD5 sums checked
> Warning in install.packages :
>    unable to move temporary installation
> ?C:\Users\mtoews\Documents\R\win-library\3.3\file382064842da2\mypackage?
> to ?C:\Users\mtoews\Documents\R\win-library\3.3\mypackage?
>
> Debugging, I found the issue around here:
> https://github.com/wch/r-source/blob/980c15af89d99c04e09a40708512a57c49d1c6ee/src/library/utils/R/windows/install.packages.R#L173-L174
>> ## To avoid anti-virus interference, wait a little
>> Sys.sleep(0.5)
> As indicated by an answer
> (https://stackoverflow.com/a/44256437/327026), debugging slows down
> the function to allow the package to be installed. A simple fix is to
> increase the sleep time to a time that is longer than 0.5 seconds.
> (I've tried testing new times, but I can't seem to overload this
> function). Or use a different strategy, such as using a few attempts
> with increasing wait times, or using a custom unlink function.
>
> Happy to help out or test more on this issue. Also, if any R Core
> member could add me to R's Bugzilla members, that would be convenient
> for me.
>
> Cheers,
> Mike
>
> R version 3.3.3 (2017-03-06) -- "Another Canoe"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lukas.stadler at oracle.com  Thu Sep 21 16:41:04 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Thu, 21 Sep 2017 16:41:04 +0200
Subject: [Rd] calling R API functions after engine shutdown
Message-ID: <D76B3D36-9D77-4B93-8988-BCB21D927046@oracle.com>

Hi!

We?ve recently come across an example where a package (minqa) creates an Rcpp Function object in a static variable.
This causes R_ReleaseObject to be called by the destructor at a very late point in time - as part of the system exit function:

static Function cf("c");

I?m wondering if that is considered to be ?safe??
Is the R engine supposed to stay in a state where calls to API functions are valid, even after it has shut down?
It probably only ever happens with the ReleaseObject function, but even that could cause problems, e.g., with more elaborate refcounting schemes.

- Lukas

From tomas.kalibera at gmail.com  Thu Sep 21 17:53:31 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 21 Sep 2017 17:53:31 +0200
Subject: [Rd] calling R API functions after engine shutdown
In-Reply-To: <D76B3D36-9D77-4B93-8988-BCB21D927046@oracle.com>
References: <D76B3D36-9D77-4B93-8988-BCB21D927046@oracle.com>
Message-ID: <c642f7e8-58c3-212f-1a7f-ebc031d65108@gmail.com>


Calling R_ReleaseObject in a C++ destructor is not reliable - it can be 
bypassed by a non-local return, such as an error. Generally in R one 
cannot use C++ destructors reliably for anything that the R runtime 
wouldn't do on its own in case of a non-local return.

A destructor that calls just UNPROTECT, in a way that balances out the 
protection stack (e.g. Rcpp Shield), is safe because R runtime balances 
the protection stack on non-local return. Destructors used in code that 
will never call into any R API (such as in a third party library) are 
safe, because the R runtime could not do non-local return. All other 
destructors are a problem.

UNPROTECT will work even during R shutdown.

In some cases cleanup code that would be put in C++ destructors, if they 
were safe with R, can instead be put into R finalizers.

Tomas



On 09/21/2017 04:41 PM, Lukas Stadler wrote:
> Hi!
>
> We?ve recently come across an example where a package (minqa) creates an Rcpp Function object in a static variable.
> This causes R_ReleaseObject to be called by the destructor at a very late point in time - as part of the system exit function:
>
> static Function cf("c");
>
> I?m wondering if that is considered to be ?safe??
> Is the R engine supposed to stay in a state where calls to API functions are valid, even after it has shut down?
> It probably only ever happens with the ReleaseObject function, but even that could cause problems, e.g., with more elaborate refcounting schemes.
>
> - Lukas
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hugh.parsonage at gmail.com  Fri Sep 22 02:14:24 2017
From: hugh.parsonage at gmail.com (Hugh Parsonage)
Date: Fri, 22 Sep 2017 00:14:24 +0000
Subject: [Rd] R CMD build errors if files cannot be moved,
	even if they are in Rbuildignore
Message-ID: <CAJmOi+N=oEhW4ZAnRY0f1-6QBP9stPdc+2Y=W6Sx8BgAhF4T-w@mail.gmail.com>

When a package is built it is first moved to a temporary directory (lines
962-980 in build.R). However, this moves *all* files to the temporary
directory, even those in Rbuildignore; only later (lines 997-1024) are
Rbuildignore files excluded.

The problem with this approach is that some files in the package directory
may not be movable. On Windows at least, the full path name to a file must
not be overly long (around 250 chars). Attempting to copy such files using
`file.copy` is a warning, and ultimately fails. In particular, if a package
uses a `data-raw` folder to prepare data, and data-raw/ contains such long
files, R CMD build will not work, meaning that the data-raw folder has to
be manually stashed before building.

I propose that the following line

if (!file.copy(pkgname, Tdir, recursive = TRUE, copy.date = TRUE))

should be replaced by something like the following

include <- allfiles[!inRbuildignore(allfiles, pkgdir)] # possibly the rest
of the exclude conds too
mov2Tdir <- function(x) {
file.copy(x, file.path(Tdir, x), copy.date = TRUE)
}
if (any(!vapply(include, mov2Tdir, FUN.VALUE = logical(1))))

This change would preserve the error condition, but not erroneously when
failing to copy files which will never be built.
This may or may not make the unlink(allfiles[exclude], recursive = TRUE,
force = TRUE) line redundant; I'm not sure.


Hugh Parsonage
Grattan Institute.

	[[alternative HTML version deleted]]


From i.ucar86 at gmail.com  Fri Sep 22 14:44:48 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Fri, 22 Sep 2017 14:44:48 +0200
Subject: [Rd] S4 method implementation for S3 class
Message-ID: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>

Hi all,

I'm trying to implement the matrix multiplication operator, which is
S4 generic, for an old-style S3 class. The following works as
expected:

x <- 1:10
class(x) <- "myClass"

setOldClass("myClass")
setGeneric("myMethod", function(x, y) standardGeneric("myMethod"))
setMethod("myMethod", c("myClass", "myClass"), function(x, y)
message("dispatched!"))

myMethod(x, x)
#> dispatched!

but I don't understand why the following won't:

setMethod("%*%", c("myClass", "myClass"), function(x, y) message("dispatched!"))

x %*% x
#>      [,1]
#> [1,]  385

Is this approach wrong?

Regards,
I?aki


From lawrence.michael at gene.com  Fri Sep 22 19:04:33 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 22 Sep 2017 10:04:33 -0700
Subject: [Rd] S4 method implementation for S3 class
In-Reply-To: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
References: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
Message-ID: <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>

The %*% function is a primitive. As it says in the documentation under
?Methods_Details

     Methods may be defined for most primitives, and corresponding
     metadata objects will be created to store them. Calls to the
     primitive still go directly to the C code, which will sometimes
     check for applicable methods. The definition of ?sometimes? is
     that methods must have been detected for the function in some
     package loaded in the session and ?isS4(x)? is ?TRUE? for the
     first argument (or for the second argument, in the case of binary
     operators).

But:
> isS4(x)
[1] FALSE

I think this behavior is in the interest of performance. It avoids
adding S4 dispatch overhead to e.g. matrix objects.

In general, it's best to define an S4 class when using S4 dispatch,
but it sounds like you're stuck using some legacy S3 objects. In that
case, one would normally define an S3 method for `%*%()` that
delegates to a custom non-primitive generic, perhaps "matmult" in this
case. But since %*% is not an S3 generic, that's not an option.

It would help to hear more about the context of the problem.

Michael



On Fri, Sep 22, 2017 at 5:44 AM, I?aki ?car <i.ucar86 at gmail.com> wrote:
> Hi all,
>
> I'm trying to implement the matrix multiplication operator, which is
> S4 generic, for an old-style S3 class. The following works as
> expected:
>
> x <- 1:10
> class(x) <- "myClass"
>
> setOldClass("myClass")
> setGeneric("myMethod", function(x, y) standardGeneric("myMethod"))
> setMethod("myMethod", c("myClass", "myClass"), function(x, y)
> message("dispatched!"))
>
> myMethod(x, x)
> #> dispatched!
>
> but I don't understand why the following won't:
>
> setMethod("%*%", c("myClass", "myClass"), function(x, y) message("dispatched!"))
>
> x %*% x
> #>      [,1]
> #> [1,]  385
>
> Is this approach wrong?
>
> Regards,
> I?aki
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From i.ucar86 at gmail.com  Fri Sep 22 19:28:05 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Fri, 22 Sep 2017 19:28:05 +0200
Subject: [Rd] S4 method implementation for S3 class
In-Reply-To: <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>
References: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
 <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>
Message-ID: <CALEXWq0z7UQaoHzfvNbfvQ8Q3vkc5Nvu1Zw4VKSMM9vQzJpphw@mail.gmail.com>

2017-09-22 19:04 GMT+02:00 Michael Lawrence <lawrence.michael at gene.com>:
> The %*% function is a primitive. As it says in the documentation under
> ?Methods_Details
>
>      Methods may be defined for most primitives, and corresponding
>      metadata objects will be created to store them. Calls to the
>      primitive still go directly to the C code, which will sometimes
>      check for applicable methods. The definition of ?sometimes? is
>      that methods must have been detected for the function in some
>      package loaded in the session and ?isS4(x)? is ?TRUE? for the
>      first argument (or for the second argument, in the case of binary
>      operators).
>
> But:
>> isS4(x)
> [1] FALSE
>
> I think this behavior is in the interest of performance. It avoids
> adding S4 dispatch overhead to e.g. matrix objects.

I see, thanks for the explanation.

> In general, it's best to define an S4 class when using S4 dispatch,
> but it sounds like you're stuck using some legacy S3 objects. In that
> case, one would normally define an S3 method for `%*%()` that
> delegates to a custom non-primitive generic, perhaps "matmult" in this
> case. But since %*% is not an S3 generic, that's not an option.
>
> It would help to hear more about the context of the problem.

This is a problem that Edzer Pebesma and I are facing in our packages
units and errors respectively (you can find both on CRAN). They are
designed in a similar way: units or errors are attached to numeric
vectors as an attribute of an S3 class, and Ops, Math and Summary are
redefined to cope with such units/errors.

Then Edzer found that the %*% operator silently drops the attributes,
so we were trying, without success, to set a method for our respective
S3 classes to at least show a warning stating that the units/errors
are being dropped.

Ours are perfect use cases for S3 classes, and it would be a pitty if
we have to switch everything to S4 just to show a warning. Clearly
overkilling. Isn't there another way?

I?aki


From lawrence.michael at gene.com  Fri Sep 22 19:53:34 2017
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 22 Sep 2017 10:53:34 -0700
Subject: [Rd] S4 method implementation for S3 class
In-Reply-To: <CALEXWq0z7UQaoHzfvNbfvQ8Q3vkc5Nvu1Zw4VKSMM9vQzJpphw@mail.gmail.com>
References: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
 <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>
 <CALEXWq0z7UQaoHzfvNbfvQ8Q3vkc5Nvu1Zw4VKSMM9vQzJpphw@mail.gmail.com>
Message-ID: <CAOQ5NyfS7dDLWm+W-k99YCndPd7C8C2WzU3Two3vSXFeeOBvfw@mail.gmail.com>

On Fri, Sep 22, 2017 at 10:28 AM, I?aki ?car <i.ucar86 at gmail.com> wrote:
> 2017-09-22 19:04 GMT+02:00 Michael Lawrence <lawrence.michael at gene.com>:
>> The %*% function is a primitive. As it says in the documentation under
>> ?Methods_Details
>>
>>      Methods may be defined for most primitives, and corresponding
>>      metadata objects will be created to store them. Calls to the
>>      primitive still go directly to the C code, which will sometimes
>>      check for applicable methods. The definition of ?sometimes? is
>>      that methods must have been detected for the function in some
>>      package loaded in the session and ?isS4(x)? is ?TRUE? for the
>>      first argument (or for the second argument, in the case of binary
>>      operators).
>>
>> But:
>>> isS4(x)
>> [1] FALSE
>>
>> I think this behavior is in the interest of performance. It avoids
>> adding S4 dispatch overhead to e.g. matrix objects.
>
> I see, thanks for the explanation.
>
>> In general, it's best to define an S4 class when using S4 dispatch,
>> but it sounds like you're stuck using some legacy S3 objects. In that
>> case, one would normally define an S3 method for `%*%()` that
>> delegates to a custom non-primitive generic, perhaps "matmult" in this
>> case. But since %*% is not an S3 generic, that's not an option.
>>
>> It would help to hear more about the context of the problem.
>
> This is a problem that Edzer Pebesma and I are facing in our packages
> units and errors respectively (you can find both on CRAN). They are
> designed in a similar way: units or errors are attached to numeric
> vectors as an attribute of an S3 class, and Ops, Math and Summary are
> redefined to cope with such units/errors.
>
> Then Edzer found that the %*% operator silently drops the attributes,
> so we were trying, without success, to set a method for our respective
> S3 classes to at least show a warning stating that the units/errors
> are being dropped.
>
> Ours are perfect use cases for S3 classes, and it would be a pitty if
> we have to switch everything to S4 just to show a warning. Clearly
> overkilling. Isn't there another way?
>

There is formally no such thing as an S3 class. Just S3 objects with a
class attribute. You could extend a base class with an S4 class, like
setClass("IntegerWithUnits", slots=c(units="Units"),
contains="integer"). Sure, that's a disruptive change, but it would be
in the right direction.

Extending base classes is always a risky proposition, as you've
discovered. Ideally you would override every transformation in order
to adjust or carry over the representation accordingly. The problem is
that there's a huge amount of transformations available for base
classes, mostly not encapsulated by generics.

Other possibilities include:
- Convincing someone to make %*% an internal S3 generic
- Promoting %*% to an R-level S3 generic, which would only work with
code that sees your namespace

Hopefully others have better ideas,
Michael

> I?aki
>


From selivanov.dmitriy at gmail.com  Sat Sep 23 14:56:51 2017
From: selivanov.dmitriy at gmail.com (Dmitriy Selivanov)
Date: Sat, 23 Sep 2017 16:56:51 +0400
Subject: [Rd] Help to create bugzilla account
In-Reply-To: <7748612.7Mr2eFXGTA@x2>
References: <CAJdZCv3oUhwiqJUTwKy0ZvwkcB=qdA5WcBdfMsdAcJED9f356w@mail.gmail.com>
 <alpine.DEB.2.20.1708121453120.4008@luke-Latitude>
 <22927.29924.782435.781870@bud.eddelbuettel.com>
 <7748612.7Mr2eFXGTA@x2>
Message-ID: <CAJdZCv1haDU2yKnZmc69hWn5jk7LYaFQOiaVjwgtPPn=obkuzQ@mail.gmail.com>

I've created repo with initial investigation -
https://github.com/dselivanov/r-malloc/blob/master/README.md. At first
glance it seems jemalloc, tcmalloc, glibc with malloc_trim all work better
than default malloc with glibc. Interesting thing is that glibc with
malloc_trim finishes benchmark a bit faster than vanilla glibc (I've
checked several times - result is consistent).
Another observation is that with jemalloc virtual memory grows much faster
than with tcmalloc or glibc malloc (this could be an issue for those who
limit process memory with `ulimit`).

2017-08-14 6:16 GMT+04:00 Steve Grubb <sgrubb at redhat.com>:

> On Saturday, August 12, 2017 5:36:36 PM EDT Dirk Eddelbuettel wrote:
> > On 12 August 2017 at 15:10, luke-tierney at uiowa.edu wrote:
> > | As the Python posts poitns out, it is possible to use alternate malloc
> > | implementations, either rebuilding R to use them or using LD_PRELOAD.
> > | On Ubuntu for example, you can have R use jemalloc with
> > |
> > | sudo apt-get install libjemalloc1
> > | env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.1 R
> > |
> > | This does not seem to hold onto memory to the same degree, but I don't
> > | know about any other aspect of its performance.
> >
> > Interesting.
> >
> > I don't really know anything about malloc versus jemalloc internals but I
> > can affirm that redis -- an in-memory database written in
> single-threaded C
> > for high performance -- in its Debian builds has been using jemalloc for
> > years, presumably by choice of the maintainer. (We are very happy users
> of
> > [a gently patched] redis at work; lots of writes; very good uptime.)
> >
> > Having the ability to switch to jemalloc, we could design a test bench
> and
> > compare what the impact is.
> >
> > Similarly, if someone cared, I could (presumably) alter the default R
> build
> > for Debian and Ubunto to also switch to jemalloc.
>
> Depending on how this turns out, Fedora, RHEL, Centos also have jemalloc
> and
> tcmalloc. Meaning, if its good on those two, its good on Linux in general.
> Basically, jemalloc is faster for many work loads but its harder to spot
> problems. Glibc is better at spotting memory bugs but not as fast.
>
> -Steve
>
> > Anybody feel like doing some empirics?
> >
> > Dirk
>
>
>


-- 
Regards
Dmitriy Selivanov

	[[alternative HTML version deleted]]


From i.ucar86 at gmail.com  Sat Sep 23 18:17:22 2017
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Sat, 23 Sep 2017 18:17:22 +0200
Subject: [Rd] S4 method implementation for S3 class
In-Reply-To: <CAOQ5NyfS7dDLWm+W-k99YCndPd7C8C2WzU3Two3vSXFeeOBvfw@mail.gmail.com>
References: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
 <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>
 <CALEXWq0z7UQaoHzfvNbfvQ8Q3vkc5Nvu1Zw4VKSMM9vQzJpphw@mail.gmail.com>
 <CAOQ5NyfS7dDLWm+W-k99YCndPd7C8C2WzU3Two3vSXFeeOBvfw@mail.gmail.com>
Message-ID: <CALEXWq1seCSkhZ7Qpbz_vq24ph0fKO06xdnDWeOi72_ZcKvsJg@mail.gmail.com>

> There is formally no such thing as an S3 class. Just S3 objects with a
> class attribute. You could extend a base class with an S4 class, like
> setClass("IntegerWithUnits", slots=c(units="Units"),
> contains="integer"). Sure, that's a disruptive change, but it would be
> in the right direction.
>
> Extending base classes is always a risky proposition, as you've
> discovered. Ideally you would override every transformation in order
> to adjust or carry over the representation accordingly. The problem is
> that there's a huge amount of transformations available for base
> classes, mostly not encapsulated by generics.
>
> Other possibilities include:
> - Convincing someone to make %*% an internal S3 generic
> - Promoting %*% to an R-level S3 generic, which would only work with
> code that sees your namespace
>
> Hopefully others have better ideas,
> Michael

Thanks for your kind help and suggestions, Michael. I think I'll take
the last option as a workaround, at least until I evaluate the
advantages and drawbacks of a complete redesign.

I?aki


From jorismeys at gmail.com  Sun Sep 24 13:51:24 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Sun, 24 Sep 2017 13:51:24 +0200
Subject: [Rd] S4 method implementation for S3 class
In-Reply-To: <CALEXWq1seCSkhZ7Qpbz_vq24ph0fKO06xdnDWeOi72_ZcKvsJg@mail.gmail.com>
References: <CALEXWq2Pfutuh1Na5cUaopUyup7WYPddd2HYKBhYGdxesabm0A@mail.gmail.com>
 <CAOQ5NycG-TAu-QAj74Z_LZOurNTPB-yRyGuCpOTkBpGfytvFoQ@mail.gmail.com>
 <CALEXWq0z7UQaoHzfvNbfvQ8Q3vkc5Nvu1Zw4VKSMM9vQzJpphw@mail.gmail.com>
 <CAOQ5NyfS7dDLWm+W-k99YCndPd7C8C2WzU3Two3vSXFeeOBvfw@mail.gmail.com>
 <CALEXWq1seCSkhZ7Qpbz_vq24ph0fKO06xdnDWeOi72_ZcKvsJg@mail.gmail.com>
Message-ID: <CAO1zAVYukjG1m8i4EK815W4BAe-ykqUDQsuB13BovJt29ossmw@mail.gmail.com>

You can always check eg the Matrix package to show you how it's done.

Cheers
Joris

On Sat, Sep 23, 2017 at 6:17 PM, I?aki ?car <i.ucar86 at gmail.com> wrote:

> > There is formally no such thing as an S3 class. Just S3 objects with a
> > class attribute. You could extend a base class with an S4 class, like
> > setClass("IntegerWithUnits", slots=c(units="Units"),
> > contains="integer"). Sure, that's a disruptive change, but it would be
> > in the right direction.
> >
> > Extending base classes is always a risky proposition, as you've
> > discovered. Ideally you would override every transformation in order
> > to adjust or carry over the representation accordingly. The problem is
> > that there's a huge amount of transformations available for base
> > classes, mostly not encapsulated by generics.
> >
> > Other possibilities include:
> > - Convincing someone to make %*% an internal S3 generic
> > - Promoting %*% to an R-level S3 generic, which would only work with
> > code that sees your namespace
> >
> > Hopefully others have better ideas,
> > Michael
>
> Thanks for your kind help and suggestions, Michael. I think I'll take
> the last option as a workaround, at least until I evaluate the
> advantages and drawbacks of a complete redesign.
>
> I?aki
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
-----------

Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-----------

Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From dstr7320 at uni.sydney.edu.au  Mon Sep 25 09:00:03 2017
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Mon, 25 Sep 2017 07:00:03 +0000
Subject: [Rd] Incorrect Import by Data for CSV File
Message-ID: <SY3PR01MB0747080D898AADCAABADDD53CD7A0@SY3PR01MB0747.ausprd01.prod.outlook.com>

Good day,

The data function can import a variety of file formats, one of them being C.S.V. Problematically, all of the table columns are collapsed into a single data frame column. This occurs because "files ending .csv or .CSV are read using read.table(..., header = TRUE, sep = ";", as.is=FALSE)". I suggest that the semi-colon used as the column separator be changed to a comma.

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia


From ripley at stats.ox.ac.uk  Mon Sep 25 14:27:25 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 Sep 2017 13:27:25 +0100
Subject: [Rd] Incorrect Import by Data for CSV File
In-Reply-To: <SY3PR01MB0747080D898AADCAABADDD53CD7A0@SY3PR01MB0747.ausprd01.prod.outlook.com>
References: <SY3PR01MB0747080D898AADCAABADDD53CD7A0@SY3PR01MB0747.ausprd01.prod.outlook.com>
Message-ID: <8b659650-9632-cf7c-a41a-82d688336444@stats.ox.ac.uk>

On 25/09/2017 08:00, Dario Strbenac wrote:
> Good day,
> 
> The data function can import a variety of file formats, one of them being C.S.V. 

That isn't its documented purpose.  It was the original way for packages 
to provide datasets as needed (before lazy data was added).

Problematically, all of the table columns are collapsed into a single 
data frame column. This occurs because "files ending .csv or .CSV are 
read using read.table(..., header = TRUE, sep = ";", as.is=FALSE)". I 
suggest that the semi-colon used as the column separator be changed to a 
comma.

We suggest you read the documentation ... the (non-English-locales) 
version with a semicolon separator is one of four documented formats, 
and the English-language one is not.  Even if it were desirable it would 
not be possible to make a backwards-incompatible change after almost 20 
years.

It really isn't clear why anyone would want to use anything other than 
the second option (.rda) for data() unless other manipulations are 
needed (e.g. to attach a package).  But that option was not part of the 
original implementation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From pdalgd at gmail.com  Mon Sep 25 18:03:44 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 25 Sep 2017 18:03:44 +0200
Subject: [Rd] Incorrect Import by Data for CSV File
In-Reply-To: <8b659650-9632-cf7c-a41a-82d688336444@stats.ox.ac.uk>
References: <SY3PR01MB0747080D898AADCAABADDD53CD7A0@SY3PR01MB0747.ausprd01.prod.outlook.com>
 <8b659650-9632-cf7c-a41a-82d688336444@stats.ox.ac.uk>
Message-ID: <50EEB4D6-ADAD-4FFF-999F-2ED18475963C@gmail.com>


> On 25 Sep 2017, at 14:27 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> On 25/09/2017 08:00, Dario Strbenac wrote:
>> Good day,
>> The data function can import a variety of file formats, one of them being C.S.V. 
> 
> That isn't its documented purpose.  It was the original way for packages to provide datasets as needed (before lazy data was added).
> 
> Problematically, all of the table columns are collapsed into a single data frame column. This occurs because "files ending .csv or .CSV are read using read.table(..., header = TRUE, sep = ";", as.is=FALSE)". I suggest that the semi-colon used as the column separator be changed to a comma.
> 
> We suggest you read the documentation ... the (non-English-locales) version with a semicolon separator is one of four documented formats, and the English-language one is not.  Even if it were desirable it would not be possible to make a backwards-incompatible change after almost 20 years.
> 
> It really isn't clear why anyone would want to use anything other than the second option (.rda) for data() unless other manipulations are needed (e.g. to attach a package).  But that option was not part of the original implementation.
> 

It can be handy to have raw ascii data included in a package for people to see, but then you can use the .R mechanism to read the data. It is done for a couple of cases in the ISwR package, see e.g. the stroke.R and stroke.csv pair. This also allows you to fix up other things that you have no chcance of specifying directly in the file:

stroke <-  read.csv2("stroke.csv", na.strings=".")
names(stroke) <- tolower(names(stroke))
stroke <-  within(stroke,{
    sex <- factor(sex,levels=0:1,labels=c("Female","Male"))
    dgn <- factor(dgn)
    coma <- factor(coma, levels=0:1, labels=c("No","Yes"))
    minf <- factor(minf, levels=0:1, labels=c("No","Yes"))
    diab <- factor(diab, levels=0:1, labels=c("No","Yes"))
    han <- factor(han, levels=0:1, labels=c("No","Yes"))
    died <- as.Date(died, format="%d.%m.%Y")
    end <- pmin(died, as.Date("1996-01-01"), na.rm=TRUE)
    dstr <- as.Date(dstr,format="%d.%m.%Y")
    obsmonths <- as.numeric(end-dstr, "days")/30.6
    obsmonths[obsmonths==0] <- 0.1
    dead <- !is.na(died) & died < as.Date("1996-01-01")
    died[!dead] <- NA
    rm(end)
})


-pd


> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kasperdanielhansen at gmail.com  Wed Sep 27 04:27:47 2017
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 26 Sep 2017 22:27:47 -0400
Subject: [Rd] possible bug in R CMD Rd2pdf
Message-ID: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>

When I include the macros \packageAuthor, \packageDescription,
\packageTitle, \packageMaintainer in a XX-package.Rd file, R CMD Rd2pdf
fails with

$ R CMD Rd2pdf mpra
Hmm ... looks like a package
Converting Rd files to LaTeX Error : mpra/man/mpra-package.Rd:6: file
'./DESCRIPTION' does not exist

This does not happen if I comment out 4 occurrences of these 4 macros in
mpra-package.Rd.

This is with

R Under development (unstable) (2017-09-26 r73351) -- "Unsuffered
Consequences"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin16.7.0 (64-bit)

or

R version 3.4.2 RC (2017-09-26 r73351) -- "Short Summer"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin16.7.0 (64-bit)

and MacTex 2017.

Best,
Kasper

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Sep 27 09:56:15 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Sep 2017 09:56:15 +0200
Subject: [Rd] possible bug in R CMD Rd2pdf
In-Reply-To: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
References: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
Message-ID: <EB533C72-21A7-441C-B436-C1B1BDBA2EEB@gmail.com>

If it is looking for ./DESCRIPTION, perhaps it matters which directory you invoke it from?

-pd

> On 27 Sep 2017, at 04:27 , Kasper Daniel Hansen <kasperdanielhansen at gmail.com> wrote:
> 
> When I include the macros \packageAuthor, \packageDescription,
> \packageTitle, \packageMaintainer in a XX-package.Rd file, R CMD Rd2pdf
> fails with
> 
> $ R CMD Rd2pdf mpra
> Hmm ... looks like a package
> Converting Rd files to LaTeX Error : mpra/man/mpra-package.Rd:6: file
> './DESCRIPTION' does not exist
> 
> This does not happen if I comment out 4 occurrences of these 4 macros in
> mpra-package.Rd.
> 
> This is with
> 
> R Under development (unstable) (2017-09-26 r73351) -- "Unsuffered
> Consequences"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
> or
> 
> R version 3.4.2 RC (2017-09-26 r73351) -- "Short Summer"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
> and MacTex 2017.
> 
> Best,
> Kasper
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Wed Sep 27 13:03:09 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 Sep 2017 07:03:09 -0400
Subject: [Rd] possible bug in R CMD Rd2pdf
In-Reply-To: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
References: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
Message-ID: <be650877-f5af-c75e-e6aa-c58403ccdae1@gmail.com>

On 26/09/2017 10:27 PM, Kasper Daniel Hansen wrote:
> When I include the macros \packageAuthor, \packageDescription,
> \packageTitle, \packageMaintainer in a XX-package.Rd file, R CMD Rd2pdf
> fails with
> 
> $ R CMD Rd2pdf mpra
> Hmm ... looks like a package
> Converting Rd files to LaTeX Error : mpra/man/mpra-package.Rd:6: file
> './DESCRIPTION' does not exist
> 
> This does not happen if I comment out 4 occurrences of these 4 macros in
> mpra-package.Rd.
> 
> This is with
> 
> R Under development (unstable) (2017-09-26 r73351) -- "Unsuffered
> Consequences"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
> or
> 
> R version 3.4.2 RC (2017-09-26 r73351) -- "Short Summer"
> Copyright (C) 2017 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
> and MacTex 2017.

Those errors are coming from tools:::Rd_package_author and related 
functions, because the system-defined macros call them.  Current 
definition of the \packageAuthor macro is

\newcommand{\packageAuthor}{\Sexpr[results=rd,stage=build]{tools:::Rd_package_author("#1")}}

and the function is defined as

function (pkg, dir = ".")
{
     desc <- .read_description(file.path(dir, "DESCRIPTION"))
     if (pkg != desc["Package"])
         stop(gettextf("DESCRIPTION file is for package '%s', not '%s'",
             desc["Package"], pkg))
     desc["Author"]
}

So Peter is right, this would likely work if the current working 
directory was the top level directory of the package, but it can't work 
in general.

The easiest fix would probably be to change the code underlying R CMD 
Rd2pdf so that it works from the top level directory; another 
possibility might be to come up with a better default for the "dir" 
parameter.

Duncan Murdoch


From therneau at mayo.edu  Wed Sep 27 14:00:11 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 27 Sep 2017 07:00:11 -0500
Subject: [Rd] y label for X11 graphics (solved)
In-Reply-To: <b4053915-bb5c-42b4-15f7-807a0e71916e@stat.auckland.ac.nz>
References: <9153c6$7udq2s@ironport10.mayo.edu>
 <b4053915-bb5c-42b4-15f7-807a0e71916e@stat.auckland.ac.nz>
Message-ID: <9153c6$81d79k@ironport10.mayo.edu>

Family matters have kept me away, I'm finally coming back to this thread.

In summary, this is an issue with a particular workstation, not with R.  Graphics with 
X11(type="Xlib") have a y label problem when displayed on this particular box, whether 
using R locally or from a server via ssh -X.  The same server's output is fine on another 
machine in the department.

I remain mildly curious as to why, but not enough to dig in since X11(type='cairo') 
displays without issue.  I first noticed this in R-devel which prompted my "bug report". 
Sorry for the noise and thanks for the responses which pointed me in the right direction.

Terry T.


From lukas.stadler at oracle.com  Wed Sep 27 17:36:15 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Wed, 27 Sep 2017 17:36:15 +0200
Subject: [Rd] logic ops with zero-extent raw vectors
Message-ID: <F18AEA1F-3000-4FA7-9BA1-A5DC447500CC@oracle.com>

Hi,

there was a change concerning logical operations about a year ago:
https://github.com/wch/r-source/commit/9e19d3e3dd5f657b5cfefe562bdd7ede2e2b8786
It's related to a discussion on this list:
https://hypatia.math.ethz.ch/pipermail/r-devel/2016-September/073068.html <https://hypatia.math.ethz.ch/pipermail/r-devel/2016-September/073068.html>

A change in logic.c:134 influences the result type of operations on zero-extent raw vectors.
Old behavior:
> raw(1) & raw(1)
[1] 00
> raw(0) & raw(0)
raw(0)
New behavior:
> raw(1) & raw(1)
[1] 00
> raw(0) & raw(0)
logical(0)

I'm wondering whether the logical result type was intentional, because, to me, the old behavior seems more consistent.

Best,
 Lukas
	[[alternative HTML version deleted]]


From kasperdanielhansen at gmail.com  Wed Sep 27 19:57:05 2017
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 27 Sep 2017 13:57:05 -0400
Subject: [Rd] possible bug in R CMD Rd2pdf
In-Reply-To: <be650877-f5af-c75e-e6aa-c58403ccdae1@gmail.com>
References: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
 <be650877-f5af-c75e-e6aa-c58403ccdae1@gmail.com>
Message-ID: <CAC2h7usT7vE7sw19r7Zbcx871DdH5nZ-YntqZk3qa9ROto+X5A@mail.gmail.com>

Sorry for the noise.

I assumed I could run this in the same directory as R CMD check. If I cd
into the package dir, and run it like
  R CMD Rd2pdf man
it works. I was a bit sleep deprived yesterday.

The fact that the output starts by
  Hmm ... looks like a package
threw me off. That output suggests it should work, I think. So I would
suggests either
  1) handling both package and man directories
  2) check that the input dir is a collection of man pages with a
DESCRIPTION file in the same directory

Best,
Kasper


On Wed, Sep 27, 2017 at 7:03 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 26/09/2017 10:27 PM, Kasper Daniel Hansen wrote:
>
>> When I include the macros \packageAuthor, \packageDescription,
>> \packageTitle, \packageMaintainer in a XX-package.Rd file, R CMD Rd2pdf
>> fails with
>>
>> $ R CMD Rd2pdf mpra
>> Hmm ... looks like a package
>> Converting Rd files to LaTeX Error : mpra/man/mpra-package.Rd:6: file
>> './DESCRIPTION' does not exist
>>
>> This does not happen if I comment out 4 occurrences of these 4 macros in
>> mpra-package.Rd.
>>
>> This is with
>>
>> R Under development (unstable) (2017-09-26 r73351) -- "Unsuffered
>> Consequences"
>> Copyright (C) 2017 The R Foundation for Statistical Computing
>> Platform: x86_64-apple-darwin16.7.0 (64-bit)
>>
>> or
>>
>> R version 3.4.2 RC (2017-09-26 r73351) -- "Short Summer"
>> Copyright (C) 2017 The R Foundation for Statistical Computing
>> Platform: x86_64-apple-darwin16.7.0 (64-bit)
>>
>> and MacTex 2017.
>>
>
> Those errors are coming from tools:::Rd_package_author and related
> functions, because the system-defined macros call them.  Current definition
> of the \packageAuthor macro is
>
> \newcommand{\packageAuthor}{\Sexpr[results=rd,stage=build]{t
> ools:::Rd_package_author("#1")}}
>
> and the function is defined as
>
> function (pkg, dir = ".")
> {
>     desc <- .read_description(file.path(dir, "DESCRIPTION"))
>     if (pkg != desc["Package"])
>         stop(gettextf("DESCRIPTION file is for package '%s', not '%s'",
>             desc["Package"], pkg))
>     desc["Author"]
> }
>
> So Peter is right, this would likely work if the current working directory
> was the top level directory of the package, but it can't work in general.
>
> The easiest fix would probably be to change the code underlying R CMD
> Rd2pdf so that it works from the top level directory; another possibility
> might be to come up with a better default for the "dir" parameter.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Sep 27 20:38:35 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 Sep 2017 14:38:35 -0400
Subject: [Rd] possible bug in R CMD Rd2pdf
In-Reply-To: <CAC2h7usT7vE7sw19r7Zbcx871DdH5nZ-YntqZk3qa9ROto+X5A@mail.gmail.com>
References: <CAC2h7uuWF4auswUdFMLcW0uw24HXZhqT7erefta3h=2G+X6eoA@mail.gmail.com>
 <be650877-f5af-c75e-e6aa-c58403ccdae1@gmail.com>
 <CAC2h7usT7vE7sw19r7Zbcx871DdH5nZ-YntqZk3qa9ROto+X5A@mail.gmail.com>
Message-ID: <fbd1cdb6-ee70-5771-840f-a134598adecc@gmail.com>

On 27/09/2017 1:57 PM, Kasper Daniel Hansen wrote:
> Sorry for the noise.

I wouldn't call this noise, it's a bug that happens to have a fairly 
easy workaround.  The tools functions are mainly for use by R utilities, 
so they sometimes make strong assumptions about the context in which 
they are used; this is a case where something that was thought of as 
internal leaked out into user-land.


> 
> I assumed I could run this in the same directory as R CMD check. If I cd 
> into the package dir, and run it like
>  ? R CMD Rd2pdf man
> it works. I was a bit sleep deprived yesterday.

You could also use

R CMD Rd2pdf .

while in that directory.

Duncan Murdoch

> 
> The fact that the output starts by
> Hmm ... looks like a package
> threw me off. That output suggests it should work, I think. So I would 
> suggests either
>  ? 1) handling both package and man directories
>  ? 2) check that the input dir is a collection of man pages with a 
> DESCRIPTION file in the same directory
> 
> Best,
> Kasper
> 
> 
> On Wed, Sep 27, 2017 at 7:03 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 26/09/2017 10:27 PM, Kasper Daniel Hansen wrote:
> 
>         When I include the macros \packageAuthor, \packageDescription,
>         \packageTitle, \packageMaintainer in a XX-package.Rd file, R CMD
>         Rd2pdf
>         fails with
> 
>         $ R CMD Rd2pdf mpra
>         Hmm ... looks like a package
>         Converting Rd files to LaTeX Error : mpra/man/mpra-package.Rd:6:
>         file
>         './DESCRIPTION' does not exist
> 
>         This does not happen if I comment out 4 occurrences of these 4
>         macros in
>         mpra-package.Rd.
> 
>         This is with
> 
>         R Under development (unstable) (2017-09-26 r73351) -- "Unsuffered
>         Consequences"
>         Copyright (C) 2017 The R Foundation for Statistical Computing
>         Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
>         or
> 
>         R version 3.4.2 RC (2017-09-26 r73351) -- "Short Summer"
>         Copyright (C) 2017 The R Foundation for Statistical Computing
>         Platform: x86_64-apple-darwin16.7.0 (64-bit)
> 
>         and MacTex 2017.
> 
> 
>     Those errors are coming from tools:::Rd_package_author and related
>     functions, because the system-defined macros call them.? Current
>     definition of the \packageAuthor macro is
> 
>     \newcommand{\packageAuthor}{\Sexpr[results=rd,stage=build]{tools:::Rd_package_author("#1")}}
> 
>     and the function is defined as
> 
>     function (pkg, dir = ".")
>     {
>      ? ? desc <- .read_description(file.path(dir, "DESCRIPTION"))
>      ? ? if (pkg != desc["Package"])
>      ? ? ? ? stop(gettextf("DESCRIPTION file is for package '%s', not '%s'",
>      ? ? ? ? ? ? desc["Package"], pkg))
>      ? ? desc["Author"]
>     }
> 
>     So Peter is right, this would likely work if the current working
>     directory was the top level directory of the package, but it can't
>     work in general.
> 
>     The easiest fix would probably be to change the code underlying R
>     CMD Rd2pdf so that it works from the top level directory; another
>     possibility might be to come up with a better default for the "dir"
>     parameter.
> 
>     Duncan Murdoch
> 
>


From maechler at stat.math.ethz.ch  Thu Sep 28 10:17:04 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 28 Sep 2017 10:17:04 +0200
Subject: [Rd] logic ops with zero-extent raw vectors
In-Reply-To: <F18AEA1F-3000-4FA7-9BA1-A5DC447500CC@oracle.com>
References: <F18AEA1F-3000-4FA7-9BA1-A5DC447500CC@oracle.com>
Message-ID: <22988.45056.833307.378675@stat.math.ethz.ch>

>>>>> Lukas Stadler <lukas.stadler at oracle.com>
>>>>>     on Wed, 27 Sep 2017 17:36:15 +0200 writes:

    > Hi,
    > there was a change concerning logical operations about a year ago:
    > https://github.com/wch/r-source/commit/9e19d3e3dd5f657b5cfefe562bdd7ede2e2b8786
    > It's related to a discussion on this list:
    > https://hypatia.math.ethz.ch/pipermail/r-devel/2016-September/073068.html <https://hypatia.math.ethz.ch/pipermail/r-devel/2016-September/073068.html>

    > A change in logic.c:134 influences the result type of operations on zero-extent raw vectors.
    > Old behavior:
    >> raw(1) & raw(1)
    > [1] 00
    >> raw(0) & raw(0)
    > raw(0)
    > New behavior:
    >> raw(1) & raw(1)
    > [1] 00
    >> raw(0) & raw(0)
    > logical(0)

    > I'm wondering whether the logical result type was intentional, because, to me, the old behavior seems more consistent.

Yes, logic operations on raw()s should remain raw() as always
documented.  Indeed, this is a bug introduced (to the source)
more than a year ago.  It is amazing that it had not been
noticed earlier.

Thank you, Lukas, for the report!

I'll fix it .. but of course too late for R version 3.4.2  which
has been released  about one hour ago (!).

Martin Maechler
ETH Zurich

    > Best,
    > Lukas
    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Thu Sep 28 17:27:46 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 28 Sep 2017 17:27:46 +0200
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
Message-ID: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>

Dear dev team,

I was sorry to see the announcement of Duncan about his retirement from
maintaining the R Windows build and Rtools. Duncan, thank you incredibly
much for your 15 years of devotion and your impressive contribution to the
R community as a whole.

Thinking about the future, I wondered whether there were plans for the
succession of Duncan. Is it the intention to continue providing Rtools and
a Windows build, or are these tasks left open for anyone (possibly
Microsoft itself) to take them over? And if so, how will the decision be
made on that?

Cheers
Joris
-- 
-----------

Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-----------

Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Thu Sep 28 17:47:15 2017
From: davidsmi at microsoft.com (David Smith)
Date: Thu, 28 Sep 2017 15:47:15 +0000
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
Message-ID: <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>

Likewise, a hearty THANK YOU from me and the rest of the team at Microsoft for all the work you, Duncan, have put into making R available for Windows users around the world over the past 15 years. I know it wasn't easy (Windows is not without its quirks), but R users everywhere, ourselves included, are deeply appreciative and have benefited greatly.

The Microsoft R team is willing and able to produce builds for R on Windows going forward. As Duncan noted, we've been doing this already for some time for MRAN. I'd love to hear thoughts from this community on what that might mean, and Duncan I'll also reach out to you directly off-list. 

Cheers,
# David   

-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Joris Meys
Sent: Thursday, September 28, 2017 08:28
To: r-devel at r-project.org
Subject: [Rd] Duncan's retirement: who's taking over Rtools?

Dear dev team,

I was sorry to see the announcement of Duncan about his retirement from maintaining the R Windows build and Rtools. Duncan, thank you incredibly much for your 15 years of devotion and your impressive contribution to the R community as a whole.

Thinking about the future, I wondered whether there were plans for the succession of Duncan. Is it the intention to continue providing Rtools and a Windows build, or are these tasks left open for anyone (possibly Microsoft itself) to take them over? And if so, how will the decision be made on that?

Cheers
Joris
--
-----------

Biowiskundedagen 2017-2018
https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.biowiskundedagen.ugent.be%2F&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=BK7GESC6ladsk6cig0ima%2BbdV1sQ5Gdeng%2BhWvtgwj4%3D&reserved=0

-----------

Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fhelpdesk.ugent.be%2Fe-maildisclaimer.php&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=PFbW9gv7%2Byi6puj42LyWHPPBqeYd83L3oQunaLTTSnw%3D&reserved=0

	[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=7ZzH9QJUaGLOIR8u2b72PMK6ze7r7hk0mleytyLC7pk%3D&reserved=0


From avraham.adler at gmail.com  Thu Sep 28 17:50:23 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 28 Sep 2017 11:50:23 -0400
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
Message-ID: <CAL6gwn+-3u+BWVO3VAXcgz6GmKrE1X87gpM-_pgDhjOh2g5Ntg@mail.gmail.com>

On Thu, Sep 28, 2017 at 11:27 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Dear dev team,
>
> I was sorry to see the announcement of Duncan about his retirement from
> maintaining the R Windows build and Rtools. Duncan, thank you incredibly
> much for your 15 years of devotion and your impressive contribution to the
> R community as a whole.
>
> Thinking about the future, I wondered whether there were plans for the
> succession of Duncan. Is it the intention to continue providing Rtools and
> a Windows build, or are these tasks left open for anyone (possibly
> Microsoft itself) to take them over? And if so, how will the decision be
> made on that?
>

Always willing to volunteer someone else, my first thoughts would be
to contact Jeroen Ooms and Kevin Ushey. Both, especially Jeroen, were
integral to the successful deployemnt of the 4.9.3 version of Rtools.

Avi


From avraham.adler at gmail.com  Thu Sep 28 17:57:22 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 28 Sep 2017 11:57:22 -0400
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
Message-ID: <CAL6gwnLEyUTrPdDRSzTf0Pj=6gK1kkFcdKsu3ro0Omg1gWB0fQ@mail.gmail.com>

On Thu, Sep 28, 2017 at 11:47 AM, David Smith via R-devel
<r-devel at r-project.org> wrote:
> The Microsoft R team is willing and able to produce builds for R on Windows going forward. As Duncan noted, we've been doing this already for some time for MRAN. I'd love to hear thoughts from this community on what that might mean, and Duncan I'll also reach out to you directly off-list.

Hi, David.

If the Microsoft R team takes over that responsibility, will they also
take over the testing and maintenance of the scripts for building R
from source on Windows as Duncan has?

Thanks,

Avi


From plummerm at iarc.fr  Thu Sep 28 18:50:43 2017
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 28 Sep 2017 16:50:43 +0000
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
Message-ID: <1506617442.8344.173.camel@iarc.fr>

David,

I think ideally we want to appoint a single person to take primary
responsibility for the Windows builds. We are currently discussing this
within R Core.

We also recognize that Microsoft is a stakeholder in R for Windows. The
same is true of other members of the R Consortium. Going forward, it
would be useful if all stakeholders could contribute to both support
and strategic discussions in this area.

best
Martyn

On Thu, 2017-09-28 at 15:47 +0000, David Smith via R-devel wrote:
> Likewise, a hearty THANK YOU from me and the rest of the team at
> Microsoft for all the work you, Duncan, have put into making R
> available for Windows users around the world over the past 15 years.
> I know it wasn't easy (Windows is not without its quirks), but R
> users everywhere, ourselves included, are deeply appreciative and
> have benefited greatly.
> 
> The Microsoft R team is willing and able to produce builds for R on
> Windows going forward. As Duncan noted, we've been doing this already
> for some time for MRAN. I'd love to hear thoughts from this community
> on what that might mean, and Duncan I'll also reach out to you
> directly off-list. 
> 
> Cheers,
> # David   
> 
> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
> Joris Meys
> Sent: Thursday, September 28, 2017 08:28
> To: r-devel at r-project.org
> Subject: [Rd] Duncan's retirement: who's taking over Rtools?
> 
> Dear dev team,
> 
> I was sorry to see the announcement of Duncan about his retirement
> from maintaining the R Windows build and Rtools. Duncan, thank you
> incredibly much for your 15 years of devotion and your impressive
> contribution to the R community as a whole.
> 
> Thinking about the future, I wondered whether there were plans for
> the succession of Duncan. Is it the intention to continue providing
> Rtools and a Windows build, or are these tasks left open for anyone
> (possibly Microsoft itself) to take them over? And if so, how will
> the decision be made on that?
> 
> Cheers
> Joris
> --
> -----------
> 
> Biowiskundedagen 2017-2018
> https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.b
> iowiskundedagen.ugent.be%2F&data=02%7C01%7Cdavidsmi%40microsoft.com%7
> C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%
> 7C1%7C0%7C636422092884858146&sdata=BK7GESC6ladsk6cig0ima%2BbdV1sQ5Gde
> ng%2BhWvtgwj4%3D&reserved=0
> 
> -----------
> 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : https://na01.safelinks.protection.outlook.com/?url=http%
> 3A%2F%2Fhelpdesk.ugent.be%2Fe-
> maildisclaimer.php&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da
> 9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7
> C636422092884858146&sdata=PFbW9gv7%2Byi6puj42LyWHPPBqeYd83L3oQunaLTTS
> nw%3D&reserved=0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-
> devel&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b50
> 8d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884
> 858146&sdata=7ZzH9QJUaGLOIR8u2b72PMK6ze7r7hk0mleytyLC7pk%3D&reserved=
> 0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From m_olshansky at yahoo.com  Fri Sep 29 02:03:49 2017
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Fri, 29 Sep 2017 00:03:49 +0000 (UTC)
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
Message-ID: <1860505228.199005.1506643429810@mail.yahoo.com>

I think that even though some Microsoft employees may have good intentions Microsoft as a company can not be trusted. There will be always a danger that they will try to create their own version of R which works only on Windows and that will become increasingly divergent from "other" R. We witnessed such (cursed in my opinion) attempts with their treatment of Java and Internet Explorer. So I think that if we want to keep R as one language it is very important that the person(s) responsible for R on Windows will have no association with Microsoft.
Best regards,Moshe.
 

    On Friday, 29 September 2017, 1:47:36 am GMT+10, David Smith via R-devel <r-devel at r-project.org> wrote:  
 
 Likewise, a hearty THANK YOU from me and the rest of the team at Microsoft for all the work you, Duncan, have put into making R available for Windows users around the world over the past 15 years. I know it wasn't easy (Windows is not without its quirks), but R users everywhere, ourselves included, are deeply appreciative and have benefited greatly.

The Microsoft R team is willing and able to produce builds for R on Windows going forward. As Duncan noted, we've been doing this already for some time for MRAN. I'd love to hear thoughts from this community on what that might mean, and Duncan I'll also reach out to you directly off-list. 

Cheers,
# David? 

-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Joris Meys
Sent: Thursday, September 28, 2017 08:28
To: r-devel at r-project.org
Subject: [Rd] Duncan's retirement: who's taking over Rtools?

Dear dev team,

I was sorry to see the announcement of Duncan about his retirement from maintaining the R Windows build and Rtools. Duncan, thank you incredibly much for your 15 years of devotion and your impressive contribution to the R community as a whole.

Thinking about the future, I wondered whether there were plans for the succession of Duncan. Is it the intention to continue providing Rtools and a Windows build, or are these tasks left open for anyone (possibly Microsoft itself) to take them over? And if so, how will the decision be made on that?

Cheers
Joris
--
-----------

Biowiskundedagen 2017-2018
https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.biowiskundedagen.ugent.be%2F&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=BK7GESC6ladsk6cig0ima%2BbdV1sQ5Gdeng%2BhWvtgwj4%3D&reserved=0

-----------

Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :? +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fhelpdesk.ugent.be%2Fe-maildisclaimer.php&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=PFbW9gv7%2Byi6puj42LyWHPPBqeYd83L3oQunaLTTSnw%3D&reserved=0

??? [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=7ZzH9QJUaGLOIR8u2b72PMK6ze7r7hk0mleytyLC7pk%3D&reserved=0

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
  
	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Fri Sep 29 02:27:02 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Thu, 28 Sep 2017 19:27:02 -0500
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <1860505228.199005.1506643429810@mail.yahoo.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
 <1860505228.199005.1506643429810@mail.yahoo.com>
Message-ID: <66d6536a-7677-3933-7c47-6ea35b022015@prodsyse.com>

 ????? I concur with Moshe.? David and his team have done great thing 
for R, but a lion will not become a vegetarian.? I think that any 
reasonable reading of Microsoft's history will supports that 
perspective.? However, this is a fairly well documented phenomenon far 
beyond Microsoft.? Jean Tirole won the 2014 Nobel Memorial Prize in 
Economics for establishing that, especially regarding 
telecommunications.[1]? It is unwise to permit too much power to be held 
too tightly.


 ????? Spencer Graves, PhD
 ????? Founder
 ????? EffectiveDefense.org
 ????? 7300 W. 107th St. # 506
 ????? Overland Park, KS 66212


[1] See the discussion of this and the related work of Eli Noam in the 
Wikiversity article on "Net neutrality and 'Restoring Internet freedom'" 
(https://en.wikiversity.org/wiki/Net_neutrality_and_%27Restoring_Internet_freedom%27). 



On 2017-09-28 7:03 PM, Moshe Olshansky via R-devel wrote:
> I think that even though some Microsoft employees may have good intentions Microsoft as a company can not be trusted. There will be always a danger that they will try to create their own version of R which works only on Windows and that will become increasingly divergent from "other" R. We witnessed such (cursed in my opinion) attempts with their treatment of Java and Internet Explorer. So I think that if we want to keep R as one language it is very important that the person(s) responsible for R on Windows will have no association with Microsoft.
> Best regards,Moshe.
>   
>
>      On Friday, 29 September 2017, 1:47:36 am GMT+10, David Smith via R-devel <r-devel at r-project.org> wrote:
>   
>   Likewise, a hearty THANK YOU from me and the rest of the team at Microsoft for all the work you, Duncan, have put into making R available for Windows users around the world over the past 15 years. I know it wasn't easy (Windows is not without its quirks), but R users everywhere, ourselves included, are deeply appreciative and have benefited greatly.
>
> The Microsoft R team is willing and able to produce builds for R on Windows going forward. As Duncan noted, we've been doing this already for some time for MRAN. I'd love to hear thoughts from this community on what that might mean, and Duncan I'll also reach out to you directly off-list.
>
> Cheers,
> # David
>
> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Joris Meys
> Sent: Thursday, September 28, 2017 08:28
> To: r-devel at r-project.org
> Subject: [Rd] Duncan's retirement: who's taking over Rtools?
>
> Dear dev team,
>
> I was sorry to see the announcement of Duncan about his retirement from maintaining the R Windows build and Rtools. Duncan, thank you incredibly much for your 15 years of devotion and your impressive contribution to the R community as a whole.
>
> Thinking about the future, I wondered whether there were plans for the succession of Duncan. Is it the intention to continue providing Rtools and a Windows build, or are these tasks left open for anyone (possibly Microsoft itself) to take them over? And if so, how will the decision be made on that?
>
> Cheers
> Joris
> --
> -----------
>
> Biowiskundedagen 2017-2018
> https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.biowiskundedagen.ugent.be%2F&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=BK7GESC6ladsk6cig0ima%2BbdV1sQ5Gdeng%2BhWvtgwj4%3D&reserved=0
>
> -----------
>
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :? +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fhelpdesk.ugent.be%2Fe-maildisclaimer.php&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=PFbW9gv7%2Byi6puj42LyWHPPBqeYd83L3oQunaLTTSnw%3D&reserved=0
>
>  ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Cdavidsmi%40microsoft.com%7C2fd515da9138451611b508d50685822b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636422092884858146&sdata=7ZzH9QJUaGLOIR8u2b72PMK6ze7r7hk0mleytyLC7pk%3D&reserved=0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>    
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jtelleriar at gmail.com  Fri Sep 29 14:23:12 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Fri, 29 Sep 2017 14:23:12 +0200
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <66d6536a-7677-3933-7c47-6ea35b022015@prodsyse.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
 <1860505228.199005.1506643429810@mail.yahoo.com>
 <66d6536a-7677-3933-7c47-6ea35b022015@prodsyse.com>
Message-ID: <CANNd7=njtxzAGNb+niAHu5DQYUGCsskw-ptdf9YL93qPjTqLwA@mail.gmail.com>

I agree with Moshe.

It is important to maintain the independence of R as a programming language
by itselft, even if it could benefit from Microsoft work (C++ Base Code,
etc.), it is better in my opinion to keep it independent.

Also, Duncan work and know-how shall be transferred to the next future R
Core Developer which will be in charge of Duncan's roles. And, if
appropriate, transfer the scripts Duncan might use, the documentation, etc.

Thank you,
Juan

	[[alternative HTML version deleted]]


From hongooi at microsoft.com  Fri Sep 29 17:00:08 2017
From: hongooi at microsoft.com (Hong Ooi)
Date: Fri, 29 Sep 2017 15:00:08 +0000
Subject: [Rd] Unexpected behaviour with download.packages on Windows
Message-ID: <SG2P15301MB0093271671C7ABCA1DA5E76BA67E0@SG2P15301MB0093.APCP153.PROD.OUTLOOK.COM>

If no 'type' is specified, download.packages("pkgname") will download source packages (.tar.gz files), even on Windows. However, the help says


  type   character string, indicate which type of packages: see install.packages.


and on Windows, install.packages defaults to downloading binary packages.

Is this intended behaviour on the part of download.packages? This is on R 3.3.3 and 3.4.1; I haven't tested on 3.4.2 but there's no indication the function has changed.


From ruipbarradas at sapo.pt  Fri Sep 29 18:44:43 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 29 Sep 2017 17:44:43 +0100
Subject: [Rd] Unexpected behaviour with download.packages on Windows
In-Reply-To: <SG2P15301MB0093271671C7ABCA1DA5E76BA67E0@SG2P15301MB0093.APCP153.PROD.OUTLOOK.COM>
References: <SG2P15301MB0093271671C7ABCA1DA5E76BA67E0@SG2P15301MB0093.APCP153.PROD.OUTLOOK.COM>
Message-ID: <59CE787B.50107@sapo.pt>

Hello,

The help pages for download.packages and install.packages say
'type = getOption("pkgType")'.
And on Windows I get

getOption("pkgType")
[1] "both"

which means in ?getOptions

pkgType:

     The default type of packages to be downloaded and installed ? see 
install.packages. Possible values are "win.binary", "source" and "both" 
(the default).

Are you sure the package you're downloading has a binary version or is 
it source only?

sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] Hmisc_4.0-3          Formula_1.2-2        survival_2.41-3
  [4] lattice_0.20-35      DescTools_0.99.22    RecordLinkage_0.4-10
  [7] ffbase_0.12.3        ff_2.2-13            bit_1.1-12
[10] RSQLite_2.0          DBI_0.7              tcR_2.2.1.11
[13] igraph_1.1.2         reshape2_1.4.2       gridExtra_2.2.1
[16] dplyr_0.7.1          ggplot2_2.2.1        sos_2.0-0
[19] brew_1.0-6

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.11        stringdist_0.9.4.6  mvtnorm_1.0-6
  [4] class_7.3-14        assertthat_0.2.0    digest_0.6.12
  [7] ipred_0.9-6         R6_2.2.2            plyr_1.8.4
[10] backports_1.1.0     acepack_1.4.1       ada_2.0-5
[13] e1071_1.6-8         rlang_0.1.1         lazyeval_0.2.0
[16] data.table_1.10.4   blob_1.1.0          rpart_4.1-11
[19] Matrix_1.2-10       checkmate_1.8.3     splines_3.4.1
[22] stringr_1.2.0       foreign_0.8-69      htmlwidgets_0.9
[25] munsell_0.4.3       compiler_3.4.1      pkgconfig_2.0.1
[28] base64enc_0.1-3     manipulate_1.0.1    htmltools_0.3.6
[31] nnet_7.3-12         evd_2.3-2           htmlTable_1.9
[34] tibble_1.3.3        prodlim_1.6.1       expm_0.999-2
[37] MASS_7.3-47         grid_3.4.1          xtable_1.8-2
[40] gtable_0.2.0        magrittr_1.5        scales_0.4.1
[43] stringi_1.1.5       bindrcpp_0.2        latticeExtra_0.6-28
[46] boot_1.3-19         fastmatch_1.1-0     lava_1.5.1
[49] RColorBrewer_1.1-2  tools_3.4.1         bit64_0.9-7
[52] glue_1.1.1          parallel_3.4.1      colorspace_1.3-2
[55] cluster_2.0.6       memoise_1.1.0       knitr_1.16
[58] bindr_0.1


Hope this helps,

Rui Barradas

Em 29-09-2017 16:00, Hong Ooi via R-devel escreveu:
> If no 'type' is specified, download.packages("pkgname") will download source packages (.tar.gz files), even on Windows. However, the help says
>
>
>    type   character string, indicate which type of packages: see install.packages.
>
>
> and on Windows, install.packages defaults to downloading binary packages.
>
> Is this intended behaviour on the part of download.packages? This is on R 3.3.3 and 3.4.1; I haven't tested on 3.4.2 but there's no indication the function has changed.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Fri Sep 29 18:55:27 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 29 Sep 2017 12:55:27 -0400
Subject: [Rd] Unexpected behaviour with download.packages on Windows
In-Reply-To: <59CE787B.50107@sapo.pt>
References: <SG2P15301MB0093271671C7ABCA1DA5E76BA67E0@SG2P15301MB0093.APCP153.PROD.OUTLOOK.COM>
 <59CE787B.50107@sapo.pt>
Message-ID: <29eadcc2-a2d2-b8f8-bdb5-38d1717ff23f@gmail.com>

On 29/09/2017 12:44 PM, Rui Barradas wrote:
> Hello,
> 
> The help pages for download.packages and install.packages say
> 'type = getOption("pkgType")'.
> And on Windows I get
> 
> getOption("pkgType")
> [1] "both"
> 
> which means in ?getOptions
> 
> pkgType:
> 
>       The default type of packages to be downloaded and installed ? see
> install.packages. Possible values are "win.binary", "source" and "both"
> (the default).
> 
> Are you sure the package you're downloading has a binary version or is
> it source only?

The claim is right -- download.packages() interprets "both" as "source". 
  The documentation is unclear about this, but the source is pretty 
simple.  The source to install.packages() is a lot more complicated, but 
I believe it would normally interpret "both" as "win.binary" on Windows, 
as documented.

Duncan Murdoch

> 
> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.1252
> LC_CTYPE=Portuguese_Portugal.1252
> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
> 
> [5] LC_TIME=Portuguese_Portugal.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
>    [1] Hmisc_4.0-3          Formula_1.2-2        survival_2.41-3
>    [4] lattice_0.20-35      DescTools_0.99.22    RecordLinkage_0.4-10
>    [7] ffbase_0.12.3        ff_2.2-13            bit_1.1-12
> [10] RSQLite_2.0          DBI_0.7              tcR_2.2.1.11
> [13] igraph_1.1.2         reshape2_1.4.2       gridExtra_2.2.1
> [16] dplyr_0.7.1          ggplot2_2.2.1        sos_2.0-0
> [19] brew_1.0-6
> 
> loaded via a namespace (and not attached):
>    [1] Rcpp_0.12.11        stringdist_0.9.4.6  mvtnorm_1.0-6
>    [4] class_7.3-14        assertthat_0.2.0    digest_0.6.12
>    [7] ipred_0.9-6         R6_2.2.2            plyr_1.8.4
> [10] backports_1.1.0     acepack_1.4.1       ada_2.0-5
> [13] e1071_1.6-8         rlang_0.1.1         lazyeval_0.2.0
> [16] data.table_1.10.4   blob_1.1.0          rpart_4.1-11
> [19] Matrix_1.2-10       checkmate_1.8.3     splines_3.4.1
> [22] stringr_1.2.0       foreign_0.8-69      htmlwidgets_0.9
> [25] munsell_0.4.3       compiler_3.4.1      pkgconfig_2.0.1
> [28] base64enc_0.1-3     manipulate_1.0.1    htmltools_0.3.6
> [31] nnet_7.3-12         evd_2.3-2           htmlTable_1.9
> [34] tibble_1.3.3        prodlim_1.6.1       expm_0.999-2
> [37] MASS_7.3-47         grid_3.4.1          xtable_1.8-2
> [40] gtable_0.2.0        magrittr_1.5        scales_0.4.1
> [43] stringi_1.1.5       bindrcpp_0.2        latticeExtra_0.6-28
> [46] boot_1.3-19         fastmatch_1.1-0     lava_1.5.1
> [49] RColorBrewer_1.1-2  tools_3.4.1         bit64_0.9-7
> [52] glue_1.1.1          parallel_3.4.1      colorspace_1.3-2
> [55] cluster_2.0.6       memoise_1.1.0       knitr_1.16
> [58] bindr_0.1
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 29-09-2017 16:00, Hong Ooi via R-devel escreveu:
>> If no 'type' is specified, download.packages("pkgname") will download source packages (.tar.gz files), even on Windows. However, the help says
>>
>>
>>     type   character string, indicate which type of packages: see install.packages.
>>
>>
>> and on Windows, install.packages defaults to downloading binary packages.
>>
>> Is this intended behaviour on the part of download.packages? This is on R 3.3.3 and 3.4.1; I haven't tested on 3.4.2 but there's no indication the function has changed.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jtelleriar at gmail.com  Fri Sep 29 19:09:58 2017
From: jtelleriar at gmail.com (Juan Telleria)
Date: Fri, 29 Sep 2017 19:09:58 +0200
Subject: [Rd] Duncan's retirement: who's taking over Rtools?
In-Reply-To: <CANNd7=njtxzAGNb+niAHu5DQYUGCsskw-ptdf9YL93qPjTqLwA@mail.gmail.com>
References: <CAO1zAVapW6yeCE-3iRys3BGcy=eNSrh0Bf2ord=6uxPmmkgD7w@mail.gmail.com>
 <BN6PR21MB049762165FF5E9D5B46A5D04C8790@BN6PR21MB0497.namprd21.prod.outlook.com>
 <1860505228.199005.1506643429810@mail.yahoo.com>
 <66d6536a-7677-3933-7c47-6ea35b022015@prodsyse.com>
 <CANNd7=njtxzAGNb+niAHu5DQYUGCsskw-ptdf9YL93qPjTqLwA@mail.gmail.com>
Message-ID: <CANNd7=n0q-+Jn5LQ2+wKNd-PbkRNic87sJ12X2Jp6NqL5+RmKQ@mail.gmail.com>

The Apache Foundation has a whole article stating that open source projects
shall be managed and used independently of any commercial interest:

https://community.apache.org/projectIndependence.html

So Microsoft could donate, if interested, money or other resources for such
specific role, but always taking special care of company interest
independence.

Juan



El 29/9/2017 2:23 p. m., "Juan Telleria" <jtelleriar at gmail.com> escribi?:

> I agree with Moshe.
>
> It is important to maintain the independence of R as a programming
> language by itselft, even if it could benefit from Microsoft work (C++ Base
> Code, etc.), it is better in my opinion to keep it independent.
>
> Also, Duncan work and know-how shall be transferred to the next future R
> Core Developer which will be in charge of Duncan's roles. And, if
> appropriate, transfer the scripts Duncan might use, the documentation, etc.
>
> Thank you,
> Juan
>

	[[alternative HTML version deleted]]


