From hb at biostat.ucsf.edu  Wed Oct  1 01:55:35 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 30 Sep 2014 16:55:35 -0700
Subject: [Rd] Shallow copies
In-Reply-To: <CAE2Fiwnz9RkqpPvKfU=WkgqJiLfZyH-Xw=mmzR+c6F-7BVhpQg@mail.gmail.com>
References: <CAE2Fiwnz9RkqpPvKfU=WkgqJiLfZyH-Xw=mmzR+c6F-7BVhpQg@mail.gmail.com>
Message-ID: <CAFDcVCTq-28FFiQVnTTnbC3XwrkcDE1cv7W3VN1-YiGkR_N3jw@mail.gmail.com>

On Tue, Sep 30, 2014 at 2:20 PM, Matthieu Gomez
<gomez.matthieu at gmail.com> wrote:
> I have a question about shallow copies in R. Since R 3.1.0, subsetting
> a dataframe with respect to its columns no longer result in deep
> copies. This is an amazing change in my opinion. Now, subsetting a
> data.frame by rows (or subsetting a matrix by columns or rows) still
> does deep copies. In particular, it is my understanding that running a
> command on a very large subset of rows (say "sum" or "biglm" on non
> outliers observations) results in a deep copy of these rows first,
> which can require twice as much the memory of the original
> data.frame/matrix. If this is correct, I would be very interested to
> know more on whether this behavior can/may change in future versions
> of R.

I let the experts comment on this, but subsetting/reshuffling columns
in data.frame:s sound easy compared with what you're asking for.
Columns of a data frame are basically just elements in a list and they
don't have to be contiguous in memory whereas the elements in a matrix
(of a basic data type) needs to be contiguous in memory.

However, somewhat related: Having lots of these temporary copies can
be quite time consuming for the garbage collector, so it's not just
about the memory but also about the overall processing time.  One of
the next improvements in the 'matrixStats' package is to add support
for specifying subsets of rows/columns to operate over - for the
purpose of avoiding the auxiliary copies that you talk about, e.g.

  cols <- c(1:14, 87:103)
  rows <- seq(from=1, to=nrow(X), by=2)
  y <- rowMedians(X, rows=rows, columns=cols)

instead of

  y <- rowMedians(X[rows,cols])

It's a fairly simple task to implement, but I've got lots on my plate
so I don't know when this will happen. (I welcome contributions via
github.com/HenrikBengtsson/matrixStats.) Similar methods in R (e.g.
rowSums()) could gain from this too.

/Henrik
(matrixStats)

PS. Code compilation could translate rowMedians(X[rows,cols]) to
rowMedians(X, rows=rows, columns=cols) but that's far in the future (I
think).

>
> Thanks a lot!,
> Matthew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From b.rowlingson at lancaster.ac.uk  Wed Oct  1 10:18:30 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 1 Oct 2014 09:18:30 +0100
Subject: [Rd] Intel Fortran compiler returns a -1 TRUE value
In-Reply-To: <e9d4e220b92c4cfcb78efe5540f85845@EX-0-HT0.lancs.local>
References: <CANVKczM_RkKjX_8U62Zb4BG=afNin3t=bjMb+CJKLEv6O2U-DQ@mail.gmail.com>
	<d78ed9a7be1e4540a70714bf81af0cd6@EX-0-HT0.lancs.local>
	<CANVKczNY2JtHkf=0bcwdZOstwSBPaWCYVRWRkq3wOS7d33cjMA@mail.gmail.com>
	<e9d4e220b92c4cfcb78efe5540f85845@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOHG5aFbsoL7DpS01Lge6bdtGaT0np=jjSor-wCBgAoeQ@mail.gmail.com>

On Tue, Sep 30, 2014 at 6:25 PM, William Dunlap <wdunlap at tibco.com> wrote:

> In S+ and S it was valid to pass logicals to .Fortran, where they got
> mapped into the
> appropriate bit pattern.  (The trouble was that 'appropriate' was
> compiled into the program -
> so you were locked into our compiler vendor's choice).   Passing them
> between Fortran
> code and C code has always been a problem (as has passing character
> data between them).
>

 That makes sense. The code was originally written for S-plus, and the
accompanying R code is still in files with a .S extension....

 The maintainer has now fixed it.

Barry

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Wed Oct  1 16:27:49 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 Oct 2014 10:27:49 -0400
Subject: [Rd] Shallow copies
In-Reply-To: <CAE2Fiwnz9RkqpPvKfU=WkgqJiLfZyH-Xw=mmzR+c6F-7BVhpQg@mail.gmail.com>
References: <CAE2Fiwnz9RkqpPvKfU=WkgqJiLfZyH-Xw=mmzR+c6F-7BVhpQg@mail.gmail.com>
Message-ID: <8F225482-56B6-4CD2-A3CD-EFB558656B25@r-project.org>

On Sep 30, 2014, at 5:20 PM, Matthieu Gomez <gomez.matthieu at gmail.com> wrote:
> 
> I have a question about shallow copies in R. Since R 3.1.0, subsetting a dataframe with respect to its columns no longer result in deep copies. This is an amazing change in my opinion. Now, subsetting a data.frame by rows (or subsetting a matrix by columns or rows) still does deep copies. In particular, it is my understanding that running a command on a very large subset of rows (say "sum" or "biglm" on non outliers observations) results in a deep copy of these rows first, which can require twice as much the memory of the original data.frame/matrix. If this is correct, I would be very interested to know more on whether this behavior can/may change in future versions of R.
> 

No. Subsetting a vector always requires a copy by definition*. Each column in a dataframe and each matrix is a vector, so any subset thereof always requires a copy no matter what you do.
Subsetting columns of a dataframe only requires a copy of the dataframe vector itself which is small by comparison (at least for datasets that use data frames).

Cheers,
Simon

* - you could try to do tricks where you fake a copy with things like COW mmaps, but you still need to have a copy conceptually. There are other tricks like deferred execution (you don't actually compute the result but only store the recipe for creating it), but those are more specialized and not generally available.

From hankin.robin at gmail.com  Wed Oct  1 22:58:02 2014
From: hankin.robin at gmail.com (robin hankin)
Date: Thu, 2 Oct 2014 09:58:02 +1300
Subject: [Rd] gsl package on mavericks
Message-ID: <CAHHjBM5rjhV51rdqmkueUuNqD4tnKxQ6P7vkk7Kxdci8xdtUkA@mail.gmail.com>

hello

I maintain the gsl R package, and many users have recently reported that
the package
does not install from source under macosx 10.9 ("mavericks").

Users typically install the gnu GSL library and are able to compile and run
a small "hello world" program which executes some of the Bessel functionality
of the library; but under mavericks the configure script (which uses
gsl-config as a probe) does not seem to detect which version of the
installed library is, giving a "Need GSL version >= 1.12" error.  The most
recent version of the gnu GSL library is 1.16.

The CRAN package check page shows that the gsl R package is clean under
every other architecture.

There is a thread on stackoverflow about this very issue:

http://stackoverflow.com/questions/24781125/installing-r-gsl-package-on-mac

where several people post either workarounds or suggestions.  However, it
is not clear whether there is some defect in the configure.ac script, or
the problem is due to mavericks, or it might even lie in newer versions of
the gnu GSL library.

The package gsl_1.9-10.tar.gz  installs correctly from source for me on my
system, macosx 10.9.4, R-3.1.1, GSL-1.16, so it is difficult for me to
investigate users' reports.


Can anyone advise?


-- 
Robin Hankin
Neutral theorist
hankin.robin at gmail.com

	[[alternative HTML version deleted]]


From kasperdanielhansen at gmail.com  Thu Oct  2 01:39:20 2014
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 1 Oct 2014 19:39:20 -0400
Subject: [Rd] gsl package on mavericks
In-Reply-To: <CAHHjBM5rjhV51rdqmkueUuNqD4tnKxQ6P7vkk7Kxdci8xdtUkA@mail.gmail.com>
References: <CAHHjBM5rjhV51rdqmkueUuNqD4tnKxQ6P7vkk7Kxdci8xdtUkA@mail.gmail.com>
Message-ID: <CAC2h7uv_3vgXhJUWfsuYyt08kcrAYwkCcp=37dob3kOCKE=upA@mail.gmail.com>

I have only skimmed this issue.  But you check gsl version by compiling a
program with
#include <gsl/gsl.h>
This assumes, as far as I can see, that gsl/gsl.h is in the search path (I
know, it is the wrong technical term) of the compiler, which may not be the
case for a non-standard installation.  Above this code you end up with a
variable called GSL_CFLAGS.  Somehow, I would expect that the test program
has to be compiled using the settings revealed by GSL_CFLAGS, but I don't
see that happening (I am not an expert on autoconf, so it may happen behind
the scenes).  I think you need to somehow pass GSL_CFLAGS to AC_LANG_SOURCE.

This seems consistent with the reports on SO, where some people are using
brew which installs it in a location not part of the standard search path,
I think.

Best,
Kasper

On Wed, Oct 1, 2014 at 4:58 PM, robin hankin <hankin.robin at gmail.com> wrote:

> hello
>
> I maintain the gsl R package, and many users have recently reported that
> the package
> does not install from source under macosx 10.9 ("mavericks").
>
> Users typically install the gnu GSL library and are able to compile and run
> a small "hello world" program which executes some of the Bessel
> functionality
> of the library; but under mavericks the configure script (which uses
> gsl-config as a probe) does not seem to detect which version of the
> installed library is, giving a "Need GSL version >= 1.12" error.  The most
> recent version of the gnu GSL library is 1.16.
>
> The CRAN package check page shows that the gsl R package is clean under
> every other architecture.
>
> There is a thread on stackoverflow about this very issue:
>
> http://stackoverflow.com/questions/24781125/installing-r-gsl-package-on-mac
>
> where several people post either workarounds or suggestions.  However, it
> is not clear whether there is some defect in the configure.ac script, or
> the problem is due to mavericks, or it might even lie in newer versions of
> the gnu GSL library.
>
> The package gsl_1.9-10.tar.gz  installs correctly from source for me on my
> system, macosx 10.9.4, R-3.1.1, GSL-1.16, so it is difficult for me to
> investigate users' reports.
>
>
> Can anyone advise?
>
>
> --
> Robin Hankin
> Neutral theorist
> hankin.robin at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Oct  2 16:55:34 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Oct 2014 16:55:34 +0200
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <542D34C6.2040301@gmail.com>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>
	<21549.6213.346772.105674@stat.math.ethz.ch>
	<542D1DAC.4090809@gmail.com>
	<21549.10935.269659.495307@stat.math.ethz.ch>
	<542D34C6.2040301@gmail.com>
Message-ID: <21549.26470.777198.46400@stat.math.ethz.ch>

We have had some conversation within R core, 
lead by Duncan Murdoch and me, about a proposal
to extend  the current  tracingState() functionality
by something tentatively called debuggingState().

Duncan has allowed me to copy the previous conversation
(after very minor editing):

The following is quite technical and assumes you know more about
R's debug()ing and trace()ing than an estimated 99.9% of the R users:

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Thu, 2 Oct 2014 07:19:34 -0400 writes:

 > On 02/10/2014, 6:36 AM, Martin Maechler wrote:
 >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
 >>>>>>> on Thu, 2 Oct 2014 05:41:00 -0400 writes:
 >> 
 >> > On 02/10/2014, 5:17 AM, Martin Maechler wrote:
 >> >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
 >> >>>>>>> on Sat, 27 Sep 2014 22:55:21 +0200 writes:
 >> >> 
 >> >> > It would be really nice to temporarily disable debugging similar to
 >> >> > tracingState() being able to turn of trace()ing.
 >> >> 
 >> >> > In eval.c  the corresponding C code would be used as the  tracingState()
 >> >> > analogue is used.
 >> >> 
 >> >> > [...........]
 >> >> > ???
 >> >> 
 >> >> It seems to work ok, the few cases I've tried.
 >> >> 
 >> >> I wonder a bit about the R / C interface.
 >> >> Using an extra function  debuggingState() seems a bit of a
 >> >> waste, and I was thinking of enhancing
 >> >> tracingState() from a 1-argument to a 2-argument form.
 >> >> 
 >> >> something like
 >> >> 
 >> >> tracingState <- function(on = NULL, debug = on)
 >> >>         .Internal(traceOnOff(on, debug))
 >> >> 
 >> >> but I don't see how to keep usages such as
 >> >> 
 >> >>   on <- tracingState(FALSE)	 # turn it off QUICKLY (via a .Internal)
 >> >>   if(on) {
 >> >>     on.exit(tracingState(TRUE)) # restore on exit, keep off during trace
 >> >>     ............
 >> >>   }
 >> >> 
 >> >> working back compatibly. 
 >> >> 
 >> >> We could think of tracingState() only returning length one when
 >> >> called with one argument, and returning length two when called
 >> >> with a second argument... but that seems messy.
 >> >> 
 >> >> If nobody has a better idea, I'd commit a new   debuggingState() 
 >> >> function which is very much "parallel" to  tracingState().
 >> 
 >> > It's hard to comment on this, because I don't know exactly what
 >> > behaviour is controlled by the debugging flag.  
 >> 
 >> Good point.  The flag, accessed via RDEBUG(.), is used in quite a few places,
 >> and the intent and my experiments have replaced
 >> 
 >>      RDEBUG(.)
 >> by   RDEBUG(.) && R_current_debug_state()
 >> 
 >> in some places, but not in most places.
 >> 
 >> > Will it cause an
 >> > explicit call to browser() to be a no-op, or does it just control breaks
 >> > triggered by entry into a function that has been marked by debug()?
 >> 
 >> What would you want?  Probably the latter, right?
 >> With my use case below, however, I could argue I'd even want  browser()
 >> to be a no-op in that case.  It is not so important to me.
 >> 
 >> > What is the effect of a call to a function marked with debugOnce()?
 >> 
 >> Good question.  Here my code was such that the function would also
 >> not have been debugged.
 >> But of course, that is open for "debate",  and I am glad you've
 >> started / continued the discussion.
 >> 
 >> My main use case for
 >>         debuggingState(FALSE)
 >> 
 >> would be when I want to call some R function that  "just runs
 >> through" and gives me its result, even though the user may have
 >> added the debug flag to a very basic R function which is called
 >> by my R function.
 >> 
 >> Given these question, you could start arguing we'd want more
 >> than just  TRUE or FALSE for debugging state,
 >> just so one could apply differing behaviour in the above cases.

 > Or the alternative:  expand the use of the tracingState() flag to affect
 > RDEBUG as well.

Indeed.  If we additionally want to remain backcompatible, I think,
we'd need to add new values in addition to {TRUE, FALSE} (and
NULL for input).

E.g., --- making up something to be improved ---
using bit patterns which when added give an integer "tracing+debugging-state"

1 : tracing-turned-off
2 : debugging turned off, allowing browser() and debugonce()
4 : making browser()   a no-op
8 : making debugonce() a no-op

and hence 1+2+4+8 = 15 turns off all "browsing/debugging"
for which I'd typically want a convenient short cut.

for back compatibility,
FALSE = 1
TRUE  = 0

I'd use UI with a vector of character strings, that can be
translated to integer codes entirely analogous to
.deparseOpts()   {used from deparse(), dput() and dump()}.

-----

A considerably simpler interface which would be good enough for
my use, was to simply add a new  debuggingState() function with
TRUE/FALSE option, and we would just have to decide how much
"turning off debugging" should happen when the state is set to FALSE.
In that case, I would still like the ability (on the level of R)
to simultaneously turn off debugging and tracing and turn them
back on as easily.  So I'd consider setting up debuggingState()
in a way that it can simultaneously turn off and on both tracing
and debugging.

 > I don't have much of an opinion on these questions.  I've never used the
 > tracingState() function, though I use trace() all the time (via
 > setBreakpoint()).  You might want to consult people who write debugger
 > front-ends.  

which I am now doing: I'm including ESS-core, 
Jonathan (RStudio) and Tobias (StatET) which Duncan mentioned as
being interested and having asked for better debugging support
functionality in the past, such as

 > the ability to add a breakpoint to a function that is
 > currently being evaluated. 

So, after quite a bit of musing, we are grateful for your
thoughtful comments on this
(and yes: I am fan of  "keep it simple!"  and  "small is beautiful!"
 also inside R's code base).

Martin Maechler,
ETH Zurich


From nakama at ki.rim.or.jp  Thu Oct  2 17:25:34 2014
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Fri, 3 Oct 2014 00:25:34 +0900
Subject: [Rd] Intel Fortran compiler returns a -1 TRUE value
In-Reply-To: <CANVKczM_RkKjX_8U62Zb4BG=afNin3t=bjMb+CJKLEv6O2U-DQ@mail.gmail.com>
References: <CANVKczM_RkKjX_8U62Zb4BG=afNin3t=bjMb+CJKLEv6O2U-DQ@mail.gmail.com>
Message-ID: <CAJqeyYbSfH2DOU8e_YNwwq_=7hvMrbcJumfgQ7UvfXbSgmJWxA@mail.gmail.com>

Hello

> The value generated by Fortran's .TRUE. evaluates as "truthy" -- as in
> all(z[[1]]) -- but is neither equal to nor identical to TRUE. Its numeric
> conversion to -1 is most unusual, every other system I've tried converts to
> +1.

Please read the -fpscomp logicals option of ifort.

--
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From rmh at temple.edu  Thu Oct  2 17:55:49 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 2 Oct 2014 11:55:49 -0400
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <21549.26470.777198.46400@stat.math.ethz.ch>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>
	<21549.6213.346772.105674@stat.math.ethz.ch>
	<542D1DAC.4090809@gmail.com>
	<21549.10935.269659.495307@stat.math.ethz.ch>
	<542D34C6.2040301@gmail.com>
	<21549.26470.777198.46400@stat.math.ethz.ch>
Message-ID: <CAGx1TMDxFRMPK2UV979R7r55cFfgrz7G2oKEBN=CTn9iEVhpVA@mail.gmail.com>

Interesting timing.  I could have used this additional control
yesterday in class.

I am teaching a graduate Statistical Computing class.  Last night I
went through the symbolic deriviatives (the deriv and D functions) in
Section 9.6 of the Blue Book.  The D function is recursive.  I
illustrated its behavior with debug(D) and then studied the statement
    D(expression(x^2+4), "x")

At each step the console displays the entire switch() statement.  And
inside ESS the entire switch statement in the derivative.R buffer is
highlighted.  That is too much redundancy.  I would like to have the
.R buffer highlighted and maybe a truncated version of the statement
displayed in the *R* (console) buffer.  I am thinking of a trunctation
similar to what C-c C-c in ESS does when it sends over a function
definition.  Somewhere around the third or fourth level of recursion I
would truncate it even further.  When investigating
   3*x^2 + 4*x^5
It would be nice to see the detail of several levels of recursion for
the 3*x^2 term and turn off the debug/trace behavior of the 4*x^5
term, with the debug/trace beahvior automatically coming back on when
the two terms are merged.


I discovered I would like an additional stop during debug.

Here is a simple function to illustrate.

simple <- function(x) {
   y <- x + x
   2*y
}

debug stops before the 'y <- x+x 'and again before the '2*y' is
evaluated and I can do regular browser investigations.  When I hit
enter, I want it to stop again after 2*y has been evaluated and before
it returns to the console.  I would like to investigate the result and
then go back and investigate the intermediate variables with the
result in view.  Obviously I can redefine my own function to

redesignedsimple <- function(x) {
   y <- x + x
   z <- 2*y
   z
}

but doing that to a function inside a NAMESPACE is very difficult to
get right.


Rich

On Thu, Oct 2, 2014 at 10:55 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> We have had some conversation within R core,
> lead by Duncan Murdoch and me, about a proposal
> to extend  the current  tracingState() functionality
> by something tentatively called debuggingState().
>
> Duncan has allowed me to copy the previous conversation
> (after very minor editing):
>
> The following is quite technical and assumes you know more about
> R's debug()ing and trace()ing than an estimated 99.9% of the R users:
>
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Thu, 2 Oct 2014 07:19:34 -0400 writes:
>
>  > On 02/10/2014, 6:36 AM, Martin Maechler wrote:
>  >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>  >>>>>>> on Thu, 2 Oct 2014 05:41:00 -0400 writes:
>  >>
>  >> > On 02/10/2014, 5:17 AM, Martin Maechler wrote:
>  >> >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>  >> >>>>>>> on Sat, 27 Sep 2014 22:55:21 +0200 writes:
>  >> >>
>  >> >> > It would be really nice to temporarily disable debugging similar to
>  >> >> > tracingState() being able to turn of trace()ing.
>  >> >>
>  >> >> > In eval.c  the corresponding C code would be used as the  tracingState()
>  >> >> > analogue is used.
>  >> >>
>  >> >> > [...........]
>  >> >> > ???
>  >> >>
>  >> >> It seems to work ok, the few cases I've tried.
>  >> >>
>  >> >> I wonder a bit about the R / C interface.
>  >> >> Using an extra function  debuggingState() seems a bit of a
>  >> >> waste, and I was thinking of enhancing
>  >> >> tracingState() from a 1-argument to a 2-argument form.
>  >> >>
>  >> >> something like
>  >> >>
>  >> >> tracingState <- function(on = NULL, debug = on)
>  >> >>         .Internal(traceOnOff(on, debug))
>  >> >>
>  >> >> but I don't see how to keep usages such as
>  >> >>
>  >> >>   on <- tracingState(FALSE)       # turn it off QUICKLY (via a .Internal)
>  >> >>   if(on) {
>  >> >>     on.exit(tracingState(TRUE)) # restore on exit, keep off during trace
>  >> >>     ............
>  >> >>   }
>  >> >>
>  >> >> working back compatibly.
>  >> >>
>  >> >> We could think of tracingState() only returning length one when
>  >> >> called with one argument, and returning length two when called
>  >> >> with a second argument... but that seems messy.
>  >> >>
>  >> >> If nobody has a better idea, I'd commit a new   debuggingState()
>  >> >> function which is very much "parallel" to  tracingState().
>  >>
>  >> > It's hard to comment on this, because I don't know exactly what
>  >> > behaviour is controlled by the debugging flag.
>  >>
>  >> Good point.  The flag, accessed via RDEBUG(.), is used in quite a few places,
>  >> and the intent and my experiments have replaced
>  >>
>  >>      RDEBUG(.)
>  >> by   RDEBUG(.) && R_current_debug_state()
>  >>
>  >> in some places, but not in most places.
>  >>
>  >> > Will it cause an
>  >> > explicit call to browser() to be a no-op, or does it just control breaks
>  >> > triggered by entry into a function that has been marked by debug()?
>  >>
>  >> What would you want?  Probably the latter, right?
>  >> With my use case below, however, I could argue I'd even want  browser()
>  >> to be a no-op in that case.  It is not so important to me.
>  >>
>  >> > What is the effect of a call to a function marked with debugOnce()?
>  >>
>  >> Good question.  Here my code was such that the function would also
>  >> not have been debugged.
>  >> But of course, that is open for "debate",  and I am glad you've
>  >> started / continued the discussion.
>  >>
>  >> My main use case for
>  >>         debuggingState(FALSE)
>  >>
>  >> would be when I want to call some R function that  "just runs
>  >> through" and gives me its result, even though the user may have
>  >> added the debug flag to a very basic R function which is called
>  >> by my R function.
>  >>
>  >> Given these question, you could start arguing we'd want more
>  >> than just  TRUE or FALSE for debugging state,
>  >> just so one could apply differing behaviour in the above cases.
>
>  > Or the alternative:  expand the use of the tracingState() flag to affect
>  > RDEBUG as well.
>
> Indeed.  If we additionally want to remain backcompatible, I think,
> we'd need to add new values in addition to {TRUE, FALSE} (and
> NULL for input).
>
> E.g., --- making up something to be improved ---
> using bit patterns which when added give an integer "tracing+debugging-state"
>
> 1 : tracing-turned-off
> 2 : debugging turned off, allowing browser() and debugonce()
> 4 : making browser()   a no-op
> 8 : making debugonce() a no-op
>
> and hence 1+2+4+8 = 15 turns off all "browsing/debugging"
> for which I'd typically want a convenient short cut.
>
> for back compatibility,
> FALSE = 1
> TRUE  = 0
>
> I'd use UI with a vector of character strings, that can be
> translated to integer codes entirely analogous to
> .deparseOpts()   {used from deparse(), dput() and dump()}.
>
> -----
>
> A considerably simpler interface which would be good enough for
> my use, was to simply add a new  debuggingState() function with
> TRUE/FALSE option, and we would just have to decide how much
> "turning off debugging" should happen when the state is set to FALSE.
> In that case, I would still like the ability (on the level of R)
> to simultaneously turn off debugging and tracing and turn them
> back on as easily.  So I'd consider setting up debuggingState()
> in a way that it can simultaneously turn off and on both tracing
> and debugging.
>
>  > I don't have much of an opinion on these questions.  I've never used the
>  > tracingState() function, though I use trace() all the time (via
>  > setBreakpoint()).  You might want to consult people who write debugger
>  > front-ends.
>
> which I am now doing: I'm including ESS-core,
> Jonathan (RStudio) and Tobias (StatET) which Duncan mentioned as
> being interested and having asked for better debugging support
> functionality in the past, such as
>
>  > the ability to add a breakpoint to a function that is
>  > currently being evaluated.
>
> So, after quite a bit of musing, we are grateful for your
> thoughtful comments on this
> (and yes: I am fan of  "keep it simple!"  and  "small is beautiful!"
>  also inside R's code base).
>
> Martin Maechler,
> ETH Zurich
>
> _______________________________________________
> ESS-core list: https://stat.ethz.ch/mailman/listinfo/ess-core


From murdoch.duncan at gmail.com  Thu Oct  2 18:07:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 02 Oct 2014 12:07:59 -0400
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <CAGx1TMDxFRMPK2UV979R7r55cFfgrz7G2oKEBN=CTn9iEVhpVA@mail.gmail.com>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>	<21549.6213.346772.105674@stat.math.ethz.ch>	<542D1DAC.4090809@gmail.com>	<21549.10935.269659.495307@stat.math.ethz.ch>	<542D34C6.2040301@gmail.com>	<21549.26470.777198.46400@stat.math.ethz.ch>
	<CAGx1TMDxFRMPK2UV979R7r55cFfgrz7G2oKEBN=CTn9iEVhpVA@mail.gmail.com>
Message-ID: <542D785F.5030006@gmail.com>

On 02/10/2014 11:55 AM, Richard M. Heiberger wrote:
> Interesting timing.  I could have used this additional control
> yesterday in class.
>
> I am teaching a graduate Statistical Computing class.  Last night I
> went through the symbolic deriviatives (the deriv and D functions) in
> Section 9.6 of the Blue Book.  The D function is recursive.  I
> illustrated its behavior with debug(D) and then studied the statement
>      D(expression(x^2+4), "x")
>
> At each step the console displays the entire switch() statement.  And
> inside ESS the entire switch statement in the derivative.R buffer is
> highlighted.  That is too much redundancy.  I would like to have the
> .R buffer highlighted and maybe a truncated version of the statement
> displayed in the *R* (console) buffer.  I am thinking of a trunctation
> similar to what C-c C-c in ESS does when it sends over a function
> definition.  Somewhere around the third or fourth level of recursion I
> would truncate it even further.  When investigating
>     3*x^2 + 4*x^5
> It would be nice to see the detail of several levels of recursion for
> the 3*x^2 term and turn off the debug/trace behavior of the 4*x^5
> term, with the debug/trace beahvior automatically coming back on when
> the two terms are merged.
>
>
> I discovered I would like an additional stop during debug.
>
> Here is a simple function to illustrate.
>
> simple <- function(x) {
>     y <- x + x
>     2*y
> }
>
> debug stops before the 'y <- x+x 'and again before the '2*y' is
> evaluated and I can do regular browser investigations.  When I hit
> enter, I want it to stop again after 2*y has been evaluated and before
> it returns to the console.
You can add on.exit(browser()) to do that, or use the exit option of 
trace().  The new (R-devel only) function returnValue() will tell you 
what is about to be returned.  In the current release, the return value 
isn't available at that point.

Duncan Murdoch

> I would like to investigate the result and
> then go back and investigate the intermediate variables with the
> result in view.  Obviously I can redefine my own function to
>
> redesignedsimple <- function(x) {
>     y <- x + x
>     z <- 2*y
>     z
> }
>
> but doing that to a function inside a NAMESPACE is very difficult to
> get right.
>
>
> Rich
>
> On Thu, Oct 2, 2014 at 10:55 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> > We have had some conversation within R core,
> > lead by Duncan Murdoch and me, about a proposal
> > to extend  the current  tracingState() functionality
> > by something tentatively called debuggingState().
> >
> > Duncan has allowed me to copy the previous conversation
> > (after very minor editing):
> >
> > The following is quite technical and assumes you know more about
> > R's debug()ing and trace()ing than an estimated 99.9% of the R users:
> >
> >>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
> >>>>>>     on Thu, 2 Oct 2014 07:19:34 -0400 writes:
> >
> >  > On 02/10/2014, 6:36 AM, Martin Maechler wrote:
> >  >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
> >  >>>>>>> on Thu, 2 Oct 2014 05:41:00 -0400 writes:
> >  >>
> >  >> > On 02/10/2014, 5:17 AM, Martin Maechler wrote:
> >  >> >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
> >  >> >>>>>>> on Sat, 27 Sep 2014 22:55:21 +0200 writes:
> >  >> >>
> >  >> >> > It would be really nice to temporarily disable debugging similar to
> >  >> >> > tracingState() being able to turn of trace()ing.
> >  >> >>
> >  >> >> > In eval.c  the corresponding C code would be used as the  tracingState()
> >  >> >> > analogue is used.
> >  >> >>
> >  >> >> > [...........]
> >  >> >> > ???
> >  >> >>
> >  >> >> It seems to work ok, the few cases I've tried.
> >  >> >>
> >  >> >> I wonder a bit about the R / C interface.
> >  >> >> Using an extra function  debuggingState() seems a bit of a
> >  >> >> waste, and I was thinking of enhancing
> >  >> >> tracingState() from a 1-argument to a 2-argument form.
> >  >> >>
> >  >> >> something like
> >  >> >>
> >  >> >> tracingState <- function(on = NULL, debug = on)
> >  >> >>         .Internal(traceOnOff(on, debug))
> >  >> >>
> >  >> >> but I don't see how to keep usages such as
> >  >> >>
> >  >> >>   on <- tracingState(FALSE)       # turn it off QUICKLY (via a .Internal)
> >  >> >>   if(on) {
> >  >> >>     on.exit(tracingState(TRUE)) # restore on exit, keep off during trace
> >  >> >>     ............
> >  >> >>   }
> >  >> >>
> >  >> >> working back compatibly.
> >  >> >>
> >  >> >> We could think of tracingState() only returning length one when
> >  >> >> called with one argument, and returning length two when called
> >  >> >> with a second argument... but that seems messy.
> >  >> >>
> >  >> >> If nobody has a better idea, I'd commit a new   debuggingState()
> >  >> >> function which is very much "parallel" to  tracingState().
> >  >>
> >  >> > It's hard to comment on this, because I don't know exactly what
> >  >> > behaviour is controlled by the debugging flag.
> >  >>
> >  >> Good point.  The flag, accessed via RDEBUG(.), is used in quite a few places,
> >  >> and the intent and my experiments have replaced
> >  >>
> >  >>      RDEBUG(.)
> >  >> by   RDEBUG(.) && R_current_debug_state()
> >  >>
> >  >> in some places, but not in most places.
> >  >>
> >  >> > Will it cause an
> >  >> > explicit call to browser() to be a no-op, or does it just control breaks
> >  >> > triggered by entry into a function that has been marked by debug()?
> >  >>
> >  >> What would you want?  Probably the latter, right?
> >  >> With my use case below, however, I could argue I'd even want  browser()
> >  >> to be a no-op in that case.  It is not so important to me.
> >  >>
> >  >> > What is the effect of a call to a function marked with debugOnce()?
> >  >>
> >  >> Good question.  Here my code was such that the function would also
> >  >> not have been debugged.
> >  >> But of course, that is open for "debate",  and I am glad you've
> >  >> started / continued the discussion.
> >  >>
> >  >> My main use case for
> >  >>         debuggingState(FALSE)
> >  >>
> >  >> would be when I want to call some R function that  "just runs
> >  >> through" and gives me its result, even though the user may have
> >  >> added the debug flag to a very basic R function which is called
> >  >> by my R function.
> >  >>
> >  >> Given these question, you could start arguing we'd want more
> >  >> than just  TRUE or FALSE for debugging state,
> >  >> just so one could apply differing behaviour in the above cases.
> >
> >  > Or the alternative:  expand the use of the tracingState() flag to affect
> >  > RDEBUG as well.
> >
> > Indeed.  If we additionally want to remain backcompatible, I think,
> > we'd need to add new values in addition to {TRUE, FALSE} (and
> > NULL for input).
> >
> > E.g., --- making up something to be improved ---
> > using bit patterns which when added give an integer "tracing+debugging-state"
> >
> > 1 : tracing-turned-off
> > 2 : debugging turned off, allowing browser() and debugonce()
> > 4 : making browser()   a no-op
> > 8 : making debugonce() a no-op
> >
> > and hence 1+2+4+8 = 15 turns off all "browsing/debugging"
> > for which I'd typically want a convenient short cut.
> >
> > for back compatibility,
> > FALSE = 1
> > TRUE  = 0
> >
> > I'd use UI with a vector of character strings, that can be
> > translated to integer codes entirely analogous to
> > .deparseOpts()   {used from deparse(), dput() and dump()}.
> >
> > -----
> >
> > A considerably simpler interface which would be good enough for
> > my use, was to simply add a new  debuggingState() function with
> > TRUE/FALSE option, and we would just have to decide how much
> > "turning off debugging" should happen when the state is set to FALSE.
> > In that case, I would still like the ability (on the level of R)
> > to simultaneously turn off debugging and tracing and turn them
> > back on as easily.  So I'd consider setting up debuggingState()
> > in a way that it can simultaneously turn off and on both tracing
> > and debugging.
> >
> >  > I don't have much of an opinion on these questions.  I've never used the
> >  > tracingState() function, though I use trace() all the time (via
> >  > setBreakpoint()).  You might want to consult people who write debugger
> >  > front-ends.
> >
> > which I am now doing: I'm including ESS-core,
> > Jonathan (RStudio) and Tobias (StatET) which Duncan mentioned as
> > being interested and having asked for better debugging support
> > functionality in the past, such as
> >
> >  > the ability to add a breakpoint to a function that is
> >  > currently being evaluated.
> >
> > So, after quite a bit of musing, we are grateful for your
> > thoughtful comments on this
> > (and yes: I am fan of  "keep it simple!"  and  "small is beautiful!"
> >  also inside R's code base).
> >
> > Martin Maechler,
> > ETH Zurich
> >
> > _______________________________________________
> > ESS-core list: https://stat.ethz.ch/mailman/listinfo/ess-core


From jonathan at rstudio.com  Thu Oct  2 19:56:01 2014
From: jonathan at rstudio.com (Jonathan McPherson)
Date: Thu, 2 Oct 2014 10:56:01 -0700
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <21549.26470.777198.46400@stat.math.ethz.ch>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>
	<21549.6213.346772.105674@stat.math.ethz.ch>
	<542D1DAC.4090809@gmail.com>
	<21549.10935.269659.495307@stat.math.ethz.ch>
	<542D34C6.2040301@gmail.com>
	<21549.26470.777198.46400@stat.math.ethz.ch>
Message-ID: <CAAU5OYB+f3RUvEDqWFodTE6cVVp0+urzGhn2qSUo5h67eKunHw@mail.gmail.com>

>
>  > I don't have much of an opinion on these questions.  I've never used the
>  > tracingState() function, though I use trace() all the time (via
>  > setBreakpoint()).  You might want to consult people who write debugger
>  > front-ends.
>
> which I am now doing: I'm including ESS-core,
> Jonathan (RStudio) and Tobias (StatET) which Duncan mentioned as
> being interested and having asked for better debugging support
> functionality in the past, such as
>
>
Some observations from RStudio which may or may not be helpful:

We don't expose any UI that allows the user to modify tracingState(). In
fact, turning off tracingState() will make RStudio's breakpoints stop
working (as they rely on trace()), without any warning or feedback from the
UI. We've never received complaints about this, and so my presumption is
that very few people need to turn off tracing globally, and those who do
know what they're doing and/or aren't using the IDE debugging features.

Some mechanism for globally altering debugging state would be very useful.
Right now we have a problem wherein during debugging the R functions
RStudio calls to e.g. analyze and compose the list of objects in the
workspace are themselves debugged. Today we're solving this by manually
tripping the RDEBUG flag on an environment before we evaluate expressions
in it, which I think we can all agree is less than ideal.

Do you foresee any non-interactive use for debuggingState()? If so, it
might be nice if the state had push/pop rather than on/off semantics, to
make the pattern of disabling locally easier to express.

 > the ability to add a breakpoint to a function that is
 > currently being evaluated.

Yes, this would be useful to us, although unless I'm missing something it
seems pretty orthogonal to the rest of the thread. It's not a common
feature request.

One thing that would be useful is some officially supported way to debug
during source(). Lots of people don't use functions and just have R scripts
full of straight-line statements (sometimes containing references to other
code via source()). RStudio will let you set breakpoints on top-level
statements, and this has proven to be a popular feature, but its
implementation is very messy--we effectively create a function from the
statements in the file and then use the function debugger, which works for
simple scenarios but starts falling apart if you do anything complicated.

Thanks,
Jonathan.

	[[alternative HTML version deleted]]


From stephan.wahlbrink at walware.de  Thu Oct  2 21:59:43 2014
From: stephan.wahlbrink at walware.de (Stephan Wahlbrink)
Date: Thu, 02 Oct 2014 21:59:43 +0200
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <21549.26470.777198.46400@stat.math.ethz.ch>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>	<21549.6213.346772.105674@stat.math.ethz.ch>	<542D1DAC.4090809@gmail.com>	<21549.10935.269659.495307@stat.math.ethz.ch>	<542D34C6.2040301@gmail.com>
	<21549.26470.777198.46400@stat.math.ethz.ch>
Message-ID: <542DAEAF.3080504@walware.de>

The possibility to temporarily turn off debugging sounds interesting. A 
short comment at the end

Am 2014-10-02 um 16:55 schrieb Martin Maechler:
> We have had some conversation within R core,
> lead by Duncan Murdoch and me, about a proposal
> to extend  the current  tracingState() functionality
> by something tentatively called debuggingState().
>
> Duncan has allowed me to copy the previous conversation
> (after very minor editing):
>
> The following is quite technical and assumes you know more about
> R's debug()ing and trace()ing than an estimated 99.9% of the R users:
>
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>      on Thu, 2 Oct 2014 07:19:34 -0400 writes:
>
>   > On 02/10/2014, 6:36 AM, Martin Maechler wrote:
>   >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>   >>>>>>> on Thu, 2 Oct 2014 05:41:00 -0400 writes:
>   >>
>   >> > On 02/10/2014, 5:17 AM, Martin Maechler wrote:
>   >> >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>   >> >>>>>>> on Sat, 27 Sep 2014 22:55:21 +0200 writes:
>   >> >>
>   >> >> > It would be really nice to temporarily disable debugging similar to
>   >> >> > tracingState() being able to turn of trace()ing.
>   >> >>
>   >> >> > In eval.c  the corresponding C code would be used as the  tracingState()
>   >> >> > analogue is used.
>   >> >>
>   >> >> > [...........]
>   >> >> > ???
>   >> >>
>   >> >> It seems to work ok, the few cases I've tried.
>   >> >>
>   >> >> I wonder a bit about the R / C interface.
>   >> >> Using an extra function  debuggingState() seems a bit of a
>   >> >> waste, and I was thinking of enhancing
>   >> >> tracingState() from a 1-argument to a 2-argument form.
>   >> >>
>   >> >> something like
>   >> >>
>   >> >> tracingState <- function(on = NULL, debug = on)
>   >> >>         .Internal(traceOnOff(on, debug))
>   >> >>
>   >> >> but I don't see how to keep usages such as
>   >> >>
>   >> >>   on <- tracingState(FALSE)	 # turn it off QUICKLY (via a .Internal)
>   >> >>   if(on) {
>   >> >>     on.exit(tracingState(TRUE)) # restore on exit, keep off during trace
>   >> >>     ............
>   >> >>   }
>   >> >>
>   >> >> working back compatibly.
>   >> >>
>   >> >> We could think of tracingState() only returning length one when
>   >> >> called with one argument, and returning length two when called
>   >> >> with a second argument... but that seems messy.
>   >> >>
>   >> >> If nobody has a better idea, I'd commit a new   debuggingState()
>   >> >> function which is very much "parallel" to  tracingState().
>   >>
>   >> > It's hard to comment on this, because I don't know exactly what
>   >> > behaviour is controlled by the debugging flag.
>   >>
>   >> Good point.  The flag, accessed via RDEBUG(.), is used in quite a few places,
>   >> and the intent and my experiments have replaced
>   >>
>   >>      RDEBUG(.)
>   >> by   RDEBUG(.) && R_current_debug_state()
>   >>
>   >> in some places, but not in most places.
>   >>
>   >> > Will it cause an
>   >> > explicit call to browser() to be a no-op, or does it just control breaks
>   >> > triggered by entry into a function that has been marked by debug()?
>   >>
>   >> What would you want?  Probably the latter, right?
>   >> With my use case below, however, I could argue I'd even want  browser()
>   >> to be a no-op in that case.  It is not so important to me.
>   >>
>   >> > What is the effect of a call to a function marked with debugOnce()?
>   >>
>   >> Good question.  Here my code was such that the function would also
>   >> not have been debugged.
>   >> But of course, that is open for "debate",  and I am glad you've
>   >> started / continued the discussion.
>   >>
>   >> My main use case for
>   >>         debuggingState(FALSE)
>   >>
>   >> would be when I want to call some R function that  "just runs
>   >> through" and gives me its result, even though the user may have
>   >> added the debug flag to a very basic R function which is called
>   >> by my R function.
>   >>
>   >> Given these question, you could start arguing we'd want more
>   >> than just  TRUE or FALSE for debugging state,
>   >> just so one could apply differing behaviour in the above cases.
>
>   > Or the alternative:  expand the use of the tracingState() flag to affect
>   > RDEBUG as well.
>
> Indeed.  If we additionally want to remain backcompatible, I think,
> we'd need to add new values in addition to {TRUE, FALSE} (and
> NULL for input).
>
> E.g., --- making up something to be improved ---
> using bit patterns which when added give an integer "tracing+debugging-state"
>
> 1 : tracing-turned-off
> 2 : debugging turned off, allowing browser() and debugonce()
> 4 : making browser()   a no-op
> 8 : making debugonce() a no-op
>
> and hence 1+2+4+8 = 15 turns off all "browsing/debugging"
> for which I'd typically want a convenient short cut.
>
> for back compatibility,
> FALSE = 1
> TRUE  = 0
>
> I'd use UI with a vector of character strings, that can be
> translated to integer codes entirely analogous to
> .deparseOpts()   {used from deparse(), dput() and dump()}.
>
> -----
>
> A considerably simpler interface which would be good enough for
> my use, was to simply add a new  debuggingState() function with
> TRUE/FALSE option, and we would just have to decide how much
> "turning off debugging" should happen when the state is set to FALSE.
> In that case, I would still like the ability (on the level of R)
> to simultaneously turn off debugging and tracing and turn them
> back on as easily.  So I'd consider setting up debuggingState()
> in a way that it can simultaneously turn off and on both tracing
> and debugging.

I think a common pattern could be:

state <- debuggingState(FALSE) # disable debugging
# run special code...
debuggingState(state) # restore state

If the first line disables both, debugging _and_ tracing, it would be 
convenient if the last line restores the exact state; also mixed state 
like debugging= on but tracing= off, if tracing was disabled.


Stephan


From Mark.Bravington at csiro.au  Fri Oct  3 00:14:28 2014
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 2 Oct 2014 22:14:28 +0000
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <CAGx1TMDxFRMPK2UV979R7r55cFfgrz7G2oKEBN=CTn9iEVhpVA@mail.gmail.com>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>
	<21549.6213.346772.105674@stat.math.ethz.ch>	<542D1DAC.4090809@gmail.com>
	<21549.10935.269659.495307@stat.math.ethz.ch>	<542D34C6.2040301@gmail.com>
	<21549.26470.777198.46400@stat.math.ethz.ch>,
	<CAGx1TMDxFRMPK2UV979R7r55cFfgrz7G2oKEBN=CTn9iEVhpVA@mail.gmail.com>
Message-ID: <1D2694C7C3A6C04AA75E11C592A882E44F8E516A@exmbx05-cdc.nexus.csiro.au>

Just FYI: the 'debug' package lets you set a stop-before-exit, and of course the ability to adjust breakpoints while the function is running. You can get the current return value via 'get.retval()'.

There is some rough-edged support for debugging scripts, too.

Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Richard M. Heiberger [rmh at temple.edu]
Sent: 03 October 2014 01:55
To: Martin Maechler
Cc: ESS-core; r-devel; Jonathan.McPherson.jonathan at rstudio.com
Subject: Re: [Rd] debuggingState() analogous to tracingState() ?

Interesting timing.  I could have used this additional control
yesterday in class.

I am teaching a graduate Statistical Computing class.  Last night I
went through the symbolic deriviatives (the deriv and D functions) in
Section 9.6 of the Blue Book.  The D function is recursive.  I
illustrated its behavior with debug(D) and then studied the statement
    D(expression(x^2+4), "x")

At each step the console displays the entire switch() statement.  And
inside ESS the entire switch statement in the derivative.R buffer is
highlighted.  That is too much redundancy.  I would like to have the
.R buffer highlighted and maybe a truncated version of the statement
displayed in the *R* (console) buffer.  I am thinking of a trunctation
similar to what C-c C-c in ESS does when it sends over a function
definition.  Somewhere around the third or fourth level of recursion I
would truncate it even further.  When investigating
   3*x^2 + 4*x^5
It would be nice to see the detail of several levels of recursion for
the 3*x^2 term and turn off the debug/trace behavior of the 4*x^5
term, with the debug/trace beahvior automatically coming back on when
the two terms are merged.


I discovered I would like an additional stop during debug.

Here is a simple function to illustrate.

simple <- function(x) {
   y <- x + x
   2*y
}

debug stops before the 'y <- x+x 'and again before the '2*y' is
evaluated and I can do regular browser investigations.  When I hit
enter, I want it to stop again after 2*y has been evaluated and before
it returns to the console.  I would like to investigate the result and
then go back and investigate the intermediate variables with the
result in view.  Obviously I can redefine my own function to

redesignedsimple <- function(x) {
   y <- x + x
   z <- 2*y
   z
}

but doing that to a function inside a NAMESPACE is very difficult to
get right.


Rich

On Thu, Oct 2, 2014 at 10:55 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> We have had some conversation within R core,
> lead by Duncan Murdoch and me, about a proposal
> to extend  the current  tracingState() functionality
> by something tentatively called debuggingState().
>
> Duncan has allowed me to copy the previous conversation
> (after very minor editing):
>
> The following is quite technical and assumes you know more about
> R's debug()ing and trace()ing than an estimated 99.9% of the R users:
>
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Thu, 2 Oct 2014 07:19:34 -0400 writes:
>
>  > On 02/10/2014, 6:36 AM, Martin Maechler wrote:
>  >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>  >>>>>>> on Thu, 2 Oct 2014 05:41:00 -0400 writes:
>  >>
>  >> > On 02/10/2014, 5:17 AM, Martin Maechler wrote:
>  >> >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>  >> >>>>>>> on Sat, 27 Sep 2014 22:55:21 +0200 writes:
>  >> >>
>  >> >> > It would be really nice to temporarily disable debugging similar to
>  >> >> > tracingState() being able to turn of trace()ing.
>  >> >>
>  >> >> > In eval.c  the corresponding C code would be used as the  tracingState()
>  >> >> > analogue is used.
>  >> >>
>  >> >> > [...........]
>  >> >> > ???
>  >> >>
>  >> >> It seems to work ok, the few cases I've tried.
>  >> >>
>  >> >> I wonder a bit about the R / C interface.
>  >> >> Using an extra function  debuggingState() seems a bit of a
>  >> >> waste, and I was thinking of enhancing
>  >> >> tracingState() from a 1-argument to a 2-argument form.
>  >> >>
>  >> >> something like
>  >> >>
>  >> >> tracingState <- function(on = NULL, debug = on)
>  >> >>         .Internal(traceOnOff(on, debug))
>  >> >>
>  >> >> but I don't see how to keep usages such as
>  >> >>
>  >> >>   on <- tracingState(FALSE)       # turn it off QUICKLY (via a .Internal)
>  >> >>   if(on) {
>  >> >>     on.exit(tracingState(TRUE)) # restore on exit, keep off during trace
>  >> >>     ............
>  >> >>   }
>  >> >>
>  >> >> working back compatibly.
>  >> >>
>  >> >> We could think of tracingState() only returning length one when
>  >> >> called with one argument, and returning length two when called
>  >> >> with a second argument... but that seems messy.
>  >> >>
>  >> >> If nobody has a better idea, I'd commit a new   debuggingState()
>  >> >> function which is very much "parallel" to  tracingState().
>  >>
>  >> > It's hard to comment on this, because I don't know exactly what
>  >> > behaviour is controlled by the debugging flag.
>  >>
>  >> Good point.  The flag, accessed via RDEBUG(.), is used in quite a few places,
>  >> and the intent and my experiments have replaced
>  >>
>  >>      RDEBUG(.)
>  >> by   RDEBUG(.) && R_current_debug_state()
>  >>
>  >> in some places, but not in most places.
>  >>
>  >> > Will it cause an
>  >> > explicit call to browser() to be a no-op, or does it just control breaks
>  >> > triggered by entry into a function that has been marked by debug()?
>  >>
>  >> What would you want?  Probably the latter, right?
>  >> With my use case below, however, I could argue I'd even want  browser()
>  >> to be a no-op in that case.  It is not so important to me.
>  >>
>  >> > What is the effect of a call to a function marked with debugOnce()?
>  >>
>  >> Good question.  Here my code was such that the function would also
>  >> not have been debugged.
>  >> But of course, that is open for "debate",  and I am glad you've
>  >> started / continued the discussion.
>  >>
>  >> My main use case for
>  >>         debuggingState(FALSE)
>  >>
>  >> would be when I want to call some R function that  "just runs
>  >> through" and gives me its result, even though the user may have
>  >> added the debug flag to a very basic R function which is called
>  >> by my R function.
>  >>
>  >> Given these question, you could start arguing we'd want more
>  >> than just  TRUE or FALSE for debugging state,
>  >> just so one could apply differing behaviour in the above cases.
>
>  > Or the alternative:  expand the use of the tracingState() flag to affect
>  > RDEBUG as well.
>
> Indeed.  If we additionally want to remain backcompatible, I think,
> we'd need to add new values in addition to {TRUE, FALSE} (and
> NULL for input).
>
> E.g., --- making up something to be improved ---
> using bit patterns which when added give an integer "tracing+debugging-state"
>
> 1 : tracing-turned-off
> 2 : debugging turned off, allowing browser() and debugonce()
> 4 : making browser()   a no-op
> 8 : making debugonce() a no-op
>
> and hence 1+2+4+8 = 15 turns off all "browsing/debugging"
> for which I'd typically want a convenient short cut.
>
> for back compatibility,
> FALSE = 1
> TRUE  = 0
>
> I'd use UI with a vector of character strings, that can be
> translated to integer codes entirely analogous to
> .deparseOpts()   {used from deparse(), dput() and dump()}.
>
> -----
>
> A considerably simpler interface which would be good enough for
> my use, was to simply add a new  debuggingState() function with
> TRUE/FALSE option, and we would just have to decide how much
> "turning off debugging" should happen when the state is set to FALSE.
> In that case, I would still like the ability (on the level of R)
> to simultaneously turn off debugging and tracing and turn them
> back on as easily.  So I'd consider setting up debuggingState()
> in a way that it can simultaneously turn off and on both tracing
> and debugging.
>
>  > I don't have much of an opinion on these questions.  I've never used the
>  > tracingState() function, though I use trace() all the time (via
>  > setBreakpoint()).  You might want to consult people who write debugger
>  > front-ends.
>
> which I am now doing: I'm including ESS-core,
> Jonathan (RStudio) and Tobias (StatET) which Duncan mentioned as
> being interested and having asked for better debugging support
> functionality in the past, such as
>
>  > the ability to add a breakpoint to a function that is
>  > currently being evaluated.
>
> So, after quite a bit of musing, we are grateful for your
> thoughtful comments on this
> (and yes: I am fan of  "keep it simple!"  and  "small is beautiful!"
>  also inside R's code base).
>
> Martin Maechler,
> ETH Zurich
>
> _______________________________________________
> ESS-core list: https://stat.ethz.ch/mailman/listinfo/ess-core

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Fri Oct  3 14:32:16 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 3 Oct 2014 14:32:16 +0200
Subject: [Rd] How I() works in a formula
Message-ID: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>

Dear all,

I'm updating a package regarding a new type of models, and I'm looking to
extend the formula interface with two functions (L() and R() ) for
construction of these models. I want to use as much of the formula
interface as possible, and hoped to do something similarly to I().

I know the I() function does nothing more than add the class "AsIs". I've
been browsing the source code of R for a couple of days now trying to
locate where this class assignment gets translated into a specific action,
but i couldn't locate it. I've been as far as the internal C function
modelframe.

Any pointers on how I() is processed internally are greatly appreciated.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct  3 15:02:31 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Oct 2014 15:02:31 +0200
Subject: [Rd] How I() works in a formula
In-Reply-To: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>
References: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>
Message-ID: <8DCBE024-DA8D-48B4-947A-FA69501F3C77@gmail.com>


On 03 Oct 2014, at 14:32 , Joris Meys <jorismeys at gmail.com> wrote:

> Dear all,
> 
> I'm updating a package regarding a new type of models, and I'm looking to
> extend the formula interface with two functions (L() and R() ) for
> construction of these models. I want to use as much of the formula
> interface as possible, and hoped to do something similarly to I().
> 
> I know the I() function does nothing more than add the class "AsIs". I've
> been browsing the source code of R for a couple of days now trying to
> locate where this class assignment gets translated into a specific action,
> but i couldn't locate it. I've been as far as the internal C function
> modelframe.
> 
> Any pointers on how I() is processed internally are greatly appreciated.

It isn't...

> E <- function(x)x
> x <- rnorm(10)
> y <- rnorm(10)
> lm(y~x+E(x^2))

Call:
lm(formula = y ~ x + E(x^2))

Coefficients:
(Intercept)            x       E(x^2)  
     0.2757       0.1725      -0.3823  


The point is that special interpretation of operators never happens inside function calls. I() is just a convenient do-nothing function call.

If you want to add special operators, one place to look is in the handling of specials for survival::coxph.


> 
> Cheers
> Joris
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lorenz at usgs.gov  Fri Oct  3 14:55:28 2014
From: lorenz at usgs.gov (Lorenz, David)
Date: Fri, 3 Oct 2014 07:55:28 -0500
Subject: [Rd] How I() works in a formula
In-Reply-To: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>
References: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>
Message-ID: <CALxY2Le4KwZM09PrDiPe-JDca=0Wi4QNXBH7YyCUoyvH2AY5Ww@mail.gmail.com>

Joris,
  Basically, the I() function, as it is used in a regression model, allows
the user to perform arithmetic operations on a variable that would
otherwise be interpreted by the formula. It is not trapped as a special
function as Error() is in aov().
  There may be other applications where the class "AsIs" is needed, so
there are support functions for subscripting, formatting, printing and so
forth.
Dave

On Fri, Oct 3, 2014 at 7:32 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Dear all,
>
> I'm updating a package regarding a new type of models, and I'm looking to
> extend the formula interface with two functions (L() and R() ) for
> construction of these models. I want to use as much of the formula
> interface as possible, and hoped to do something similarly to I().
>
> I know the I() function does nothing more than add the class "AsIs". I've
> been browsing the source code of R for a couple of days now trying to
> locate where this class assignment gets translated into a specific action,
> but i couldn't locate it. I've been as far as the internal C function
> modelframe.
>
> Any pointers on how I() is processed internally are greatly appreciated.
>
> Cheers
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Fri Oct  3 16:20:49 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 3 Oct 2014 16:20:49 +0200
Subject: [Rd] How I() works in a formula
In-Reply-To: <8DCBE024-DA8D-48B4-947A-FA69501F3C77@gmail.com>
References: <CAO1zAVYHdBEqX0M-wH5OsGNxe2P1BKLS07cXBba9yQTnBtPN5g@mail.gmail.com>
	<8DCBE024-DA8D-48B4-947A-FA69501F3C77@gmail.com>
Message-ID: <CAO1zAVZUoFfqU5L=ogxxdS5tcX=8MUAxOvO-eTYfqRD0thUUSQ@mail.gmail.com>

Thanks Peter! That clarifies why it felt I was chasing ghosts these past
days :) Thanks for the tip about coxph as well, there's some nice ideas to
be discovered there.

Cheers
Joris

On Fri, Oct 3, 2014 at 3:02 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 03 Oct 2014, at 14:32 , Joris Meys <jorismeys at gmail.com> wrote:
>
> > Dear all,
> >
> > I'm updating a package regarding a new type of models, and I'm looking to
> > extend the formula interface with two functions (L() and R() ) for
> > construction of these models. I want to use as much of the formula
> > interface as possible, and hoped to do something similarly to I().
> >
> > I know the I() function does nothing more than add the class "AsIs". I've
> > been browsing the source code of R for a couple of days now trying to
> > locate where this class assignment gets translated into a specific
> action,
> > but i couldn't locate it. I've been as far as the internal C function
> > modelframe.
> >
> > Any pointers on how I() is processed internally are greatly appreciated.
>
> It isn't...
>
> > E <- function(x)x
> > x <- rnorm(10)
> > y <- rnorm(10)
> > lm(y~x+E(x^2))
>
> Call:
> lm(formula = y ~ x + E(x^2))
>
> Coefficients:
> (Intercept)            x       E(x^2)
>      0.2757       0.1725      -0.3823
>
>
> The point is that special interpretation of operators never happens inside
> function calls. I() is just a convenient do-nothing function call.
>
> If you want to add special operators, one place to look is in the handling
> of specials for survival::coxph.
>
>
> >
> > Cheers
> > Joris
> >
> > --
> > Joris Meys
> > Statistical consultant
> >
> > Ghent University
> > Faculty of Bioscience Engineering
> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >
> > tel : +32 9 264 59 87
> > Joris.Meys at Ugent.be
> > -------------------------------
> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Fri Oct  3 18:11:25 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 3 Oct 2014 17:11:25 +0100
Subject: [Rd] Intel Fortran compiler returns a -1 TRUE value
In-Reply-To: <a13204d90a5c4f5081b1b149a47dd92a@EX-1-HT0.lancs.local>
References: <CANVKczM_RkKjX_8U62Zb4BG=afNin3t=bjMb+CJKLEv6O2U-DQ@mail.gmail.com>
	<a13204d90a5c4f5081b1b149a47dd92a@EX-1-HT0.lancs.local>
Message-ID: <CANVKczOZynpkVBaFAvg9JB3rPka5nicY4mc4BxMAqx0hP3i5Xw@mail.gmail.com>

On Thu, Oct 2, 2014 at 4:25 PM, Ei-ji Nakama <nakama at ki.rim.or.jp> wrote:

> Hello
>
> > The value generated by Fortran's .TRUE. evaluates as "truthy" -- as in
> > all(z[[1]]) -- but is neither equal to nor identical to TRUE. Its numeric
> > conversion to -1 is most unusual, every other system I've tried converts
> to
> > +1.
>
> Please read the -fpscomp logicals option of ifort.
>

 Wow that's an interesting read, and the line

"Intel recommends that you avoid coding practices that
              depend on the internal representation of LOGICAL values"

says it all with regard to R and Fortran LOGICALS, I think!

Barry

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Fri Oct  3 19:28:58 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 3 Oct 2014 10:28:58 -0700
Subject: [Rd] Any penalty for using gzfile() in place of file() for reading?
Message-ID: <CAFDcVCQKaRv=knZe7XcFRjE9x+ZePzijx8o3_g0MrubGXYwMDA@mail.gmail.com>

A question I meant to ask for a very long time:

I have several functions that temporarily open files using file(...,
open="rb").  I'd like to support gzip'ed files also and noticed that
gzfile(..., open="rb") handles also non-compressed files, cf.
help("gzfile"):

 For 'gzfile' the description is the path to a file compressed by
'gzip': it can also open for reading uncompressed files and those
compressed by 'bzip2', 'xz' or 'lzma'.

>From simple benchmarking I cannot measure any overhead from using
gzfile().  I assume the only overhead would come from inspecting the
first few bytes in the file.  Also, there is no risk that my
non-compressed files have gzip header (by chance), so that is not a
concern.

Does anyone see a reason for not just using gzfile(..., open="rb")
everywhere I use file(..., open="rb") today?

/Henrik


From drf28 at cornell.edu  Sat Oct  4 01:17:27 2014
From: drf28 at cornell.edu (Daniel Fuka)
Date: Fri, 3 Oct 2014 19:17:27 -0400
Subject: [Rd] mpi.h errors on Mavericks packages
Message-ID: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>

Dear mac folks,

I have started porting a large legacy toolset maintained in windows
and heavily mpi laden so it can be used across platforms in R... so I
am building a package out of it. On this note, I am noticing that
almost all of the mpi dependent packages do not compile on the CRAN
repositories.... with the basic issue that it appears it can not find
mpi installed:

configure: error: "Cannot find mpi.h header file"

I do not see any chatter about mpi issues in the lists since the
inception of mavericks.. and possibly this question should go to
Simon.. but in case I missed a discussion, or if anyone has any
suggestions on how to proceed, or what might be missing from the Rmpi,
npRmpi, etc. packages for compilation on Mavericks, it would be
greatly appreciated if you could let me know.. and maybe I can help
fix the other packages as well.

Thanks for any help or pointers to guide me!
dan


From mtmorgan at fhcrc.org  Sat Oct  4 01:58:23 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 03 Oct 2014 16:58:23 -0700
Subject: [Rd] mpi.h errors on Mavericks packages
In-Reply-To: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
References: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
Message-ID: <542F381F.4040207@fhcrc.org>

On 10/03/2014 04:17 PM, Daniel Fuka wrote:
> Dear mac folks,
>
> I have started porting a large legacy toolset maintained in windows
> and heavily mpi laden so it can be used across platforms in R... so I
> am building a package out of it. On this note, I am noticing that
> almost all of the mpi dependent packages do not compile on the CRAN
> repositories.... with the basic issue that it appears it can not find
> mpi installed:
>
> configure: error: "Cannot find mpi.h header file"

Hi Dan -- not a mac folk, or particularly expert on the subject, but have you 
looked at section 1.2.1.1 of RShowDoc("R-exts")? The basic idea is

a) check for compiler support via a src/Makevars file that might be like

PKG_CFLAGS = $(SHLIB_OPENMP_CFLAGS)
PKG_LIBS = $(SHLIB_OPENMP_CFLAGS)

b) conditionally include mpi header files and execute mpi code with

#ifdef SUPPORT_OPENMP
#include <mpi.h>
#endif

and similarly for #pragma's and other mpi-isms littered through your code? 
Likely this gets quite tedious for projects making extensive use of openMP.

Martin


>
> I do not see any chatter about mpi issues in the lists since the
> inception of mavericks.. and possibly this question should go to
> Simon.. but in case I missed a discussion, or if anyone has any
> suggestions on how to proceed, or what might be missing from the Rmpi,
> npRmpi, etc. packages for compilation on Mavericks, it would be
> greatly appreciated if you could let me know.. and maybe I can help
> fix the other packages as well.
>
> Thanks for any help or pointers to guide me!
> dan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From mtmorgan at fhcrc.org  Sat Oct  4 02:28:29 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 03 Oct 2014 17:28:29 -0700
Subject: [Rd] mpi.h errors on Mavericks packages
In-Reply-To: <542F381F.4040207@fhcrc.org>
References: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
	<542F381F.4040207@fhcrc.org>
Message-ID: <542F3F2D.80301@fhcrc.org>

On 10/03/2014 04:58 PM, Martin Morgan wrote:
> On 10/03/2014 04:17 PM, Daniel Fuka wrote:
>> Dear mac folks,
>>
>> I have started porting a large legacy toolset maintained in windows
>> and heavily mpi laden so it can be used across platforms in R... so I
>> am building a package out of it. On this note, I am noticing that
>> almost all of the mpi dependent packages do not compile on the CRAN
>> repositories.... with the basic issue that it appears it can not find
>> mpi installed:
>>
>> configure: error: "Cannot find mpi.h header file"
>

sorry for the noise! you're after mpi and not openMP. Arrgh Martin

> Hi Dan -- not a mac folk, or particularly expert on the subject, but have you
> looked at section 1.2.1.1 of RShowDoc("R-exts")? The basic idea is
>
> a) check for compiler support via a src/Makevars file that might be like
>
> PKG_CFLAGS = $(SHLIB_OPENMP_CFLAGS)
> PKG_LIBS = $(SHLIB_OPENMP_CFLAGS)
>
> b) conditionally include mpi header files and execute mpi code with
>
> #ifdef SUPPORT_OPENMP
> #include <mpi.h>
> #endif
>
> and similarly for #pragma's and other mpi-isms littered through your code?
> Likely this gets quite tedious for projects making extensive use of openMP.
>
> Martin
>
>
>>
>> I do not see any chatter about mpi issues in the lists since the
>> inception of mavericks.. and possibly this question should go to
>> Simon.. but in case I missed a discussion, or if anyone has any
>> suggestions on how to proceed, or what might be missing from the Rmpi,
>> npRmpi, etc. packages for compilation on Mavericks, it would be
>> greatly appreciated if you could let me know.. and maybe I can help
>> fix the other packages as well.
>>
>> Thanks for any help or pointers to guide me!
>> dan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From simon.urbanek at r-project.org  Sat Oct  4 03:10:00 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 Oct 2014 21:10:00 -0400
Subject: [Rd] mpi.h errors on Mavericks packages
In-Reply-To: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
References: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
Message-ID: <8BABC185-502F-4F78-973E-AA625CAB5602@r-project.org>

Daniel,

On Oct 3, 2014, at 7:17 PM, Daniel Fuka <drf28 at cornell.edu> wrote:

> Dear mac folks,
> 
> I have started porting a large legacy toolset maintained in windows
> and heavily mpi laden so it can be used across platforms in R... so I
> am building a package out of it. On this note, I am noticing that
> almost all of the mpi dependent packages do not compile on the CRAN
> repositories.... with the basic issue that it appears it can not find
> mpi installed:
> 
> configure: error: "Cannot find mpi.h header file"
> 
> I do not see any chatter about mpi issues in the lists since the
> inception of mavericks.. and possibly this question should go to
> Simon.. but in case I missed a discussion, or if anyone has any
> suggestions on how to proceed, or what might be missing from the Rmpi,
> npRmpi, etc. packages for compilation on Mavericks, it would be
> greatly appreciated if you could let me know.. and maybe I can help
> fix the other packages as well.


Apple has removed MPI from recent OS X versions so it is not available there.

So currently, you have to install whatever MPI implementation you prefer from sources since neither the libraries nor the toolchain are available. What Apple used to ship was OpenMPI which still exists, but to my best knowledge there is no official, maintained binary for OS X so on Mavericks we have nothing to build CRAN binaries against, so you have to install everything from sources.

Cheers,
Simon


From wccsnow at gmail.com  Sat Oct  4 03:39:12 2014
From: wccsnow at gmail.com (Wei-Chen Chen)
Date: Fri, 3 Oct 2014 21:39:12 -0400
Subject: [Rd] mpi.h errors on Mavericks packages
In-Reply-To: <8BABC185-502F-4F78-973E-AA625CAB5602@r-project.org>
References: <CAB9w6XyTH2h_rizZogW4hE0-O65-J2zB9VxDmpWBdvdDoS5CvA@mail.gmail.com>
	<8BABC185-502F-4F78-973E-AA625CAB5602@r-project.org>
Message-ID: <CAB2DcavrcwF=gQguJBtjGhQxurq5w1KhP2vE=GetZBFdkMUxFA@mail.gmail.com>

FYI
https://groups.google.com/forum/#!topic/rbigdataprogramming/k1uZWmzd1L8
or FAQ, Section 8.3, question 10 at
https://github.com/snoweye/pbdMPI/blob/master/inst/doc/pbdMPI-guide.pdf?raw=true
may be useful.

On Fri, Oct 3, 2014 at 9:10 PM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Daniel,
>
> On Oct 3, 2014, at 7:17 PM, Daniel Fuka <drf28 at cornell.edu> wrote:
>
> > Dear mac folks,
> >
> > I have started porting a large legacy toolset maintained in windows
> > and heavily mpi laden so it can be used across platforms in R... so I
> > am building a package out of it. On this note, I am noticing that
> > almost all of the mpi dependent packages do not compile on the CRAN
> > repositories.... with the basic issue that it appears it can not find
> > mpi installed:
> >
> > configure: error: "Cannot find mpi.h header file"
> >
> > I do not see any chatter about mpi issues in the lists since the
> > inception of mavericks.. and possibly this question should go to
> > Simon.. but in case I missed a discussion, or if anyone has any
> > suggestions on how to proceed, or what might be missing from the Rmpi,
> > npRmpi, etc. packages for compilation on Mavericks, it would be
> > greatly appreciated if you could let me know.. and maybe I can help
> > fix the other packages as well.
>
>
> Apple has removed MPI from recent OS X versions so it is not available
> there.
>
> So currently, you have to install whatever MPI implementation you prefer
> from sources since neither the libraries nor the toolchain are available.
> What Apple used to ship was OpenMPI which still exists, but to my best
> knowledge there is no official, maintained binary for OS X so on Mavericks
> we have nothing to build CRAN binaries against, so you have to install
> everything from sources.
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Sun Oct  5 12:20:15 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 5 Oct 2014 12:20:15 +0200
Subject: [Rd] Using Rtools with gcc 4.8.3
Message-ID: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>

I started working on some R bindings for mongo-c-driver [1]. The C
library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
might be a problem in older versions of mingw-w64. So I grabbed a copy
of mingw-w64 version 4.8.3 and indeed, here the library compiles
without errors.

Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
package Makevars contains

  CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"

However it seems like R still uses the old gcc 4.6.3 for R CMD
INSTALL. What am I doing wrong? Is there a recommended setup for
building packages on Windows using a Rtools but with another compiler?

In addition: will I be able to publish this package to CRAN, or do I
have to wait for Rtools to get updated with a more recent gcc?


[1] https://github.com/mongodb/mongo-c-driver
[2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/


From ligges at statistik.tu-dortmund.de  Sun Oct  5 12:51:02 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 05 Oct 2014 12:51:02 +0200
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
Message-ID: <54312296.5060506@statistik.tu-dortmund.de>



On 05.10.2014 12:20, Jeroen Ooms wrote:
> I started working on some R bindings for mongo-c-driver [1]. The C
> library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
> however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
> with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
> might be a problem in older versions of mingw-w64. So I grabbed a copy
> of mingw-w64 version 4.8.3 and indeed, here the library compiles
> without errors.
>
> Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
> the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
> package Makevars contains
>
>    CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"
>
> However it seems like R still uses the old gcc 4.6.3 for R CMD
> INSTALL. What am I doing wrong? Is there a recommended setup for
> building packages on Windows using a Rtools but with another compiler?
>
> In addition: will I be able to publish this package to CRAN, or do I
> have to wait for Rtools to get updated with a more recent gcc?

Currently only 4.6.3 is supported and that is the one used to build 
binary packages on CRAN. Hence you need to wait until it is updated.

Best,
Uwe Ligges

>
> [1] https://github.com/mongodb/mongo-c-driver
> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Sun Oct  5 13:14:49 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 5 Oct 2014 07:14:49 -0400
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <54312296.5060506@statistik.tu-dortmund.de>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
	<54312296.5060506@statistik.tu-dortmund.de>
Message-ID: <CAP01uRkTa4uChReNuL+Nr3q=22MgmaG2Ap=eQ7ZwTkKnt4pphw@mail.gmail.com>

On Sun, Oct 5, 2014 at 6:51 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 05.10.2014 12:20, Jeroen Ooms wrote:
>>
>> I started working on some R bindings for mongo-c-driver [1]. The C
>> library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
>> however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
>> with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
>> might be a problem in older versions of mingw-w64. So I grabbed a copy
>> of mingw-w64 version 4.8.3 and indeed, here the library compiles
>> without errors.
>>
>> Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
>> the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
>> package Makevars contains
>>
>>    CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"
>>
>> However it seems like R still uses the old gcc 4.6.3 for R CMD
>> INSTALL. What am I doing wrong? Is there a recommended setup for
>> building packages on Windows using a Rtools but with another compiler?
>>
>> In addition: will I be able to publish this package to CRAN, or do I
>> have to wait for Rtools to get updated with a more recent gcc?
>
>
> Currently only 4.6.3 is supported and that is the one used to build binary
> packages on CRAN. Hence you need to wait until it is updated.
>
> Best,
> Uwe Ligges
>
>
>>
>> [1] https://github.com/mongodb/mongo-c-driver
>> [2]
>> http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/
>>

Are there any plans for this?  gcc is already up to 4.9.1 and I am
sure a lot of people would like to see the latest version available as
part of Rtools.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From romain at r-enthusiasts.com  Sun Oct  5 13:56:39 2014
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Sun, 5 Oct 2014 13:56:39 +0200
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <CAP01uRkTa4uChReNuL+Nr3q=22MgmaG2Ap=eQ7ZwTkKnt4pphw@mail.gmail.com>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
	<54312296.5060506@statistik.tu-dortmund.de>
	<CAP01uRkTa4uChReNuL+Nr3q=22MgmaG2Ap=eQ7ZwTkKnt4pphw@mail.gmail.com>
Message-ID: <13C5F826-F7FC-4B82-98BD-8BE0A451518F@r-enthusiasts.com>


Le 5 oct. 2014 ? 13:14, Gabor Grothendieck <ggrothendieck at gmail.com> a ?crit :

> On Sun, Oct 5, 2014 at 6:51 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>> 
>> 
>> On 05.10.2014 12:20, Jeroen Ooms wrote:
>>> 
>>> I started working on some R bindings for mongo-c-driver [1]. The C
>>> library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
>>> however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
>>> with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
>>> might be a problem in older versions of mingw-w64. So I grabbed a copy
>>> of mingw-w64 version 4.8.3 and indeed, here the library compiles
>>> without errors.
>>> 
>>> Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
>>> the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
>>> package Makevars contains
>>> 
>>>   CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"
>>> 
>>> However it seems like R still uses the old gcc 4.6.3 for R CMD
>>> INSTALL. What am I doing wrong? Is there a recommended setup for
>>> building packages on Windows using a Rtools but with another compiler?
>>> 
>>> In addition: will I be able to publish this package to CRAN, or do I
>>> have to wait for Rtools to get updated with a more recent gcc?
>> 
>> 
>> Currently only 4.6.3 is supported and that is the one used to build binary
>> packages on CRAN. Hence you need to wait until it is updated.
>> 
>> Best,
>> Uwe Ligges
>> 
>> 
>>> 
>>> [1] https://github.com/mongodb/mongo-c-driver
>>> [2]
>>> http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/
>>> 
> 
> Are there any plans for this?  gcc is already up to 4.9.1 and I am
> sure a lot of people would like to see the latest version available as
> part of Rtools.

+1. Please. I?d like a newer gcc as part of Rtools too. My reason for it is that it would bring actual C++11, rather than unfinished C++0x as gcc 4.6.3 currently ships. That would allow more adoption of the newer C++ standard for packages [*]. 

Furthermore, a current version of gcc will also give a good support for C++14, the current C++ standard. 

I said it in the past, I don?t have the skills to make this happen myself but I would consider funding someone?s time (within reason) and offer mine for testing it. 

Romain

*: currently Rcpp11, the best way to connect R and C++11, has to compromise on what C++11 means so that it works on windows. This is bad. The compromise is minimal, but still. 


From romain at r-enthusiasts.com  Sun Oct  5 14:09:30 2014
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Sun, 5 Oct 2014 14:09:30 +0200
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <13C5F826-F7FC-4B82-98BD-8BE0A451518F@r-enthusiasts.com>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
	<54312296.5060506@statistik.tu-dortmund.de>
	<CAP01uRkTa4uChReNuL+Nr3q=22MgmaG2Ap=eQ7ZwTkKnt4pphw@mail.gmail.com>
	<13C5F826-F7FC-4B82-98BD-8BE0A451518F@r-enthusiasts.com>
Message-ID: <44FF9484-F7F4-4456-B85C-B3603AA3446A@r-enthusiasts.com>


Le 5 oct. 2014 ? 13:56, Romain Fran?ois <romain at r-enthusiasts.com> a ?crit :

> 
> Le 5 oct. 2014 ? 13:14, Gabor Grothendieck <ggrothendieck at gmail.com> a ?crit :
> 
>> On Sun, Oct 5, 2014 at 6:51 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de> wrote:
>>> 
>>> 
>>> On 05.10.2014 12:20, Jeroen Ooms wrote:
>>>> 
>>>> I started working on some R bindings for mongo-c-driver [1]. The C
>>>> library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
>>>> however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
>>>> with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
>>>> might be a problem in older versions of mingw-w64. So I grabbed a copy
>>>> of mingw-w64 version 4.8.3 and indeed, here the library compiles
>>>> without errors.
>>>> 
>>>> Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
>>>> the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
>>>> package Makevars contains
>>>> 
>>>>  CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"
>>>> 
>>>> However it seems like R still uses the old gcc 4.6.3 for R CMD
>>>> INSTALL. What am I doing wrong? Is there a recommended setup for
>>>> building packages on Windows using a Rtools but with another compiler?
>>>> 
>>>> In addition: will I be able to publish this package to CRAN, or do I
>>>> have to wait for Rtools to get updated with a more recent gcc?
>>> 
>>> 
>>> Currently only 4.6.3 is supported and that is the one used to build binary
>>> packages on CRAN. Hence you need to wait until it is updated.
>>> 
>>> Best,
>>> Uwe Ligges
>>> 
>>> 
>>>> 
>>>> [1] https://github.com/mongodb/mongo-c-driver
>>>> [2]
>>>> http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/
>>>> 
>> 
>> Are there any plans for this?  gcc is already up to 4.9.1 and I am
>> sure a lot of people would like to see the latest version available as
>> part of Rtools.
> 
> +1. Please. I?d like a newer gcc as part of Rtools too. My reason for it is that it would bring actual C++11, rather than unfinished C++0x as gcc 4.6.3 currently ships. That would allow more adoption of the newer C++ standard for packages [*]. 
> 
> Furthermore, a current version of gcc will also give a good support for C++14, the current C++ standard. 
> 
> I said it in the past, I don?t have the skills to make this happen myself but I would consider funding someone?s time (within reason) and offer mine for testing it. 
> 
> Romain
> 
> *: currently Rcpp11, the best way to connect R and C++11, has to compromise on what C++11 means so that it works on windows. This is bad. The compromise is minimal, but still. 

Those missing features in C++0x from 4.6.3 include: 
 - delegate constructors
 - template aliases (a more powerful `using` keyword

We?ve worked around that, but at the expense of some code clarity, safety and boilerplateness (esp. the delegate constructor feature). 


From murdoch.duncan at gmail.com  Sun Oct  5 14:29:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 05 Oct 2014 08:29:19 -0400
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
Message-ID: <5431399F.1040706@gmail.com>

On 05/10/2014, 6:20 AM, Jeroen Ooms wrote:
> I started working on some R bindings for mongo-c-driver [1]. The C
> library compiles fine on Ubuntu Trusty (gcc 4.8.2) and osx (clang),
> however on my windows machine (gcc 4.6.3 from Rtools 3.1) it fails
> with:  'INIT_ONCE_STATIC_INIT' undeclared. Google suggests that this
> might be a problem in older versions of mingw-w64. So I grabbed a copy
> of mingw-w64 version 4.8.3 and indeed, here the library compiles
> without errors.
> 
> Now I am unsure how to make mingw 4.8.3 work with Rtools. I extracted
> the contents of [2] into "C:\RBuildTools\3.1\gcc-4.8.3\" and my
> package Makevars contains
> 
>   CC = "c:/RBuildTools/3.1/gcc-4.8.3/bin/gcc"
> 
> However it seems like R still uses the old gcc 4.6.3 for R CMD
> INSTALL. What am I doing wrong? Is there a recommended setup for
> building packages on Windows using a Rtools but with another compiler?

No, but I'd like to update Rtools to use the new compiler.  Have you got
some time to help with that?

Duncan Murdoch

> 
> In addition: will I be able to publish this package to CRAN, or do I
> have to wait for Rtools to get updated with a more recent gcc?
> 
> 
> [1] https://github.com/mongodb/mongo-c-driver
> [2] http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/4.8.3/threads-posix/dwarf/


From jeroen.ooms at stat.ucla.edu  Sun Oct  5 15:10:23 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 5 Oct 2014 15:10:23 +0200
Subject: [Rd] Using Rtools with gcc 4.8.3
In-Reply-To: <5431399F.1040706@gmail.com>
References: <CABFfbXtyWxH4nC27idagHdYZEX3hHqqD07uiZc7CvHxuv2nASw@mail.gmail.com>
	<5431399F.1040706@gmail.com>
Message-ID: <CABFfbXsuoTLtBkKoz51LXWgKkNvwc7AjtjMcYeXv1qtMqRQpPg@mail.gmail.com>

On Sun, Oct 5, 2014 at 2:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> No, but I'd like to update Rtools to use the new compiler.  Have you got
> some time to help with that?

Sure I'm not exactly a windows expert but I'll help where I can (and
it seems others on the list are willing to jump in as well)


From pdalgd at gmail.com  Mon Oct  6 23:36:10 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Oct 2014 23:36:10 +0200
Subject: [Rd] R 3.1.2 planned for Oct 31
Message-ID: <FE4FF5D1-795F-477D-85FD-083EB3B659AB@gmail.com>

Just a quick indication for package maintainers and others who want to know about releases some time in advance:

We plan to release the next patch release of R on Friday Oct 31. Intended nickname "Pumpkin Helmet". Further details about release schedule etc. will follow.

For the R Core Team

- Peter D.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dstr7320 at uni.sydney.edu.au  Tue Oct  7 10:00:10 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Tue, 7 Oct 2014 08:00:10 +0000
Subject: [Rd] S4 Method Dispatch for Class Defined as Attribute
Message-ID: <1412672663198.7327@uni.sydney.edu.au>

Hello,

I am writing an interface to some functions from the CRAN package pamr, which is poorly written.

I have a S4 method I declared with setMethod. I'd like to provide a signature of "pamrtrained" which is the class of object that training creates. The last two lines of code of pamr.train are :

    class(junk) = "pamrtrained"
    junk

How can I dispatch on these kinds of objects, other than making the signature be "ANY" and checking the class inside the S4 method ? Might these kinds of class assignments be deprecated in a future version of R ?

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From sven.templer at gmail.com  Tue Oct  7 11:01:24 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Tue, 7 Oct 2014 11:01:24 +0200
Subject: [Rd] S4 Method Dispatch for Class Defined as Attribute
In-Reply-To: <1412672663198.7327@uni.sydney.edu.au>
References: <1412672663198.7327@uni.sydney.edu.au>
Message-ID: <CAHuTOvqsQPODLQ+JKoN-_dH4nzLgXk7_up2yR1vAPkun+AjfPg@mail.gmail.com>

Is setOldClass the solution?

e.g.

x <- list()
class(x) <- "foo"
setGeneric("bar", function(x) "bar generic")
setOldClass("foo")
setMethod("bar", "foo", function(x) "bar foo")
bar(x)

On 7 October 2014 10:00, Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
> Hello,
>
> I am writing an interface to some functions from the CRAN package pamr, which is poorly written.
>
> I have a S4 method I declared with setMethod. I'd like to provide a signature of "pamrtrained" which is the class of object that training creates. The last two lines of code of pamr.train are :
>
>     class(junk) = "pamrtrained"
>     junk
>
> How can I dispatch on these kinds of objects, other than making the signature be "ANY" and checking the class inside the S4 method ? Might these kinds of class assignments be deprecated in a future version of R ?
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From shivali at ncmrwf.gov.in  Tue Oct  7 11:34:53 2014
From: shivali at ncmrwf.gov.in (shivali at ncmrwf.gov.in)
Date: Tue, 7 Oct 2014 15:04:53 +0530
Subject: [Rd] Issue installing Matrix Package
Message-ID: <771dd37aff6b886900d46627bcb5cf88.squirrel@mail.ncmrwf.gov.in>

Hi,

I installed R-3.1.1 on AIX-5.3 and my installation hanged up while
installing Matrix Package.
so i killed the gmake ; gmake install the software nad tired installing
Matrix package manually -

[ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1/bin/package]>
/gpfs1/home/shivali/gang/R-3.1.1/bin/R CMD INSTALL Matrix

the package compiled successfully but while loading Matrix package the
installation hanged up -
in method for 'coerce' with signature '"sparseMatrix","graphNEL"': no
definition for class "graphNEL"
in method for 'coerce' with signature '"TsparseMatrix","graphNEL"': no
definition for class "graphNEL"
Creating a generic function for 'format' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.R' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.Q' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.qy' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.qty' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.coef' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.resid' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.fitted' from package 'base' in package
'Matrix'
** help
*** installing help indices
** building package indices
Loading required package: Matrix


On checking more i come accross the CPU utilization for thread using ps
-ef command (CPU priority penalty ) is inreasing upto 120 max limit.


[ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1]> ps -ef | grep R-3.1.1
 shivali 323978 459010   0 14:36:14 pts/14  0:00 grep R-3.1.1
    root 492034 336504   0 14:34:36 pts/11  0:00 sh
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix
    root 525188 492034 120 14:34:37 pts/11  0:30
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/exec/R --args --args --args
nextArgMatrix
[ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1]>


Please help

Regards,
Shivali Gangwar



Email secured by Check Point


From bt at datak.fr  Tue Oct  7 13:04:34 2014
From: bt at datak.fr (DataK - B. THIEURMEL)
Date: Tue, 07 Oct 2014 13:04:34 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
Message-ID: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>

Hi,

With the use of R in production, it is necessary to have a system of 
logs effective, and light.

Package exist as to futile.logger, but it require the additional coding 
of logs. So it is thus impossible / very difficult to use it with all 
package them used in the calculation

Our idea is to develop one packages global, simple, who would allow to 
identify all the errors, warning, message generated by the functions 
stop(), warning() and message() stop as well as by signals and 
internally code, with log levels configurable later by package, 
functions...

One way is to overwrite temporarily the functions stop(), warning() and 
message() of base package, but I think is not a good thing, and 
furthermore, we lose all signals and internally "message"...

A good use of options(error) seems to do the perfect job, but only for 
error...

Our problem / question :
- At present, how it is possible to have the same features for messages 
and warnings? (like options(errors)) (I don't find...)
- Would new options be possible in a near future R ?
- Have there better / other possibilities to handle all the warnings, 
message of the way which we wish?

Hope is clear. Open to any suggestions.

Thank you in advance

-- 
Benoit Thieurmel
+33 6 69 04 06 11

DataKnowledge
46 rue Amsterdam - 75009 Paris


From murdoch.duncan at gmail.com  Tue Oct  7 14:21:36 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 07 Oct 2014 08:21:36 -0400
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
Message-ID: <5433DAD0.8080305@gmail.com>

On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
> Hi,
> 
> With the use of R in production, it is necessary to have a system of 
> logs effective, and light.
> 
> Package exist as to futile.logger, but it require the additional coding 
> of logs. So it is thus impossible / very difficult to use it with all 
> package them used in the calculation
> 
> Our idea is to develop one packages global, simple, who would allow to 
> identify all the errors, warning, message generated by the functions 
> stop(), warning() and message() stop as well as by signals and 
> internally code, with log levels configurable later by package, 
> functions...
> 
> One way is to overwrite temporarily the functions stop(), warning() and 
> message() of base package, but I think is not a good thing, and 
> furthermore, we lose all signals and internally "message"...
> 
> A good use of options(error) seems to do the perfect job, but only for 
> error...
> 
> Our problem / question :
> - At present, how it is possible to have the same features for messages 
> and warnings? (like options(errors)) (I don't find...)
> - Would new options be possible in a near future R ?
> - Have there better / other possibilities to handle all the warnings, 
> message of the way which we wish?
> 

withCallingHandlers() lets you evaluate expressions with code to catch
messages, warnings and errors.

I don't know if there's a way to evaluate every expression entered at
the console within withCallingHandlers() for an effect like
options(error=), but you can certainly write code to read a file and
evaluate every expression in it within a withCallingHandlers() call.

Duncan Murdoch

> Hope is clear. Open to any suggestions.
> 
> Thank you in advance
>


From bt at datak.fr  Tue Oct  7 16:16:53 2014
From: bt at datak.fr (DataK - B. THIEURMEL)
Date: Tue, 07 Oct 2014 16:16:53 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
Message-ID: <50055615b4a67b88787ba18dc0c607b8@datak.fr>

Thank. withCallingHandlers() and "pander::evals" seem to be very 
interesting, but little adapted to the analysis of one or several 
scripts R / of many lines of code. Our goal is one packages requiring no 
modifications of code R to be able to get back all the desired 
information.

Is-there a hope in seeing R core team adding two options warn and 
message with the same features as options(error) ? Or if we try (and 
succeed) to code a patch for it, to see it integrating in R ?

I think that it would be very useful.

Benoit

Le 2014-10-07 14:38, Gergely Dar?czi a ?crit?:
> On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
>> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>> Hi,
>>> 
>>> With the use of R in production, it is necessary to have a system
>> of
>>> logs effective, and light.
>>> 
>>> Package exist as to futile.logger, but it require the additional
>> coding
>>> of logs. So it is thus impossible / very difficult to use it with
>> all
>>> package them used in the calculation
>>> 
>>> Our idea is to develop one packages global, simple, who would
>> allow to
>>> identify all the errors, warning, message generated by the
>> functions
>>> stop(), warning() and message() stop as well as by signals and
>>> internally code, with log levels configurable later by package,
>>> functions...
>>> 
>>> One way is to overwrite temporarily the functions stop(),
>> warning() and
>>> message() of base package, but I think is not a good thing, and
>>> furthermore, we lose all signals and internally "message"...
>>> 
>>> A good use of options(error) seems to do the perfect job, but
>> only for
>>> error...
>>> 
>>> Our problem / question :
>>> - At present, how it is possible to have the same features for
>> messages
>>> and warnings? (like options(errors)) (I don't find...)
>>> - Would new options be possible in a near future R ?
>>> - Have there better / other possibilities to handle all the
>> warnings,
>>> message of the way which we wish?
>>> 
>> 
>> ??withCallingHandlers() lets you evaluate expressions with code
>> to catch
>> messages, warnings and errors.
> 
> That's exactly what I'm using in "pander::evals" to capture all
> error/warning/normal messages while evaluating an R command, and to
> also capture the results (as R objects), stdout and the printed
> version of the object -- which might be useful in a custom
> environment. E.g. I use this function to evaluate all R chunks in
> markdown document and also to store all R messages run at the
> rapporter.net [2] API. Please let me know if anyone is interested, and
> I will start cleaning up the related codebase and publish on GH --
> although "pander" and "evals" is already
> there:?https://github.com/Rapporter/pander [3]
> 
> Quick demo:?http://pastebin.com/jCUkgKim [4]
> ?
> 
>> I don't know if there's a way to evaluate every expression entered
>> at
>> the console within withCallingHandlers() for an effect like
>> options(error=), but you can certainly write code to read a file
>> and
>> evaluate every expression in it within a withCallingHandlers()
>> call.
>> 
>> Duncan Murdoch
>> 
>>> Hope is clear. Open to any suggestions.
>>> 
>>> Thank you in advance
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
> 
> 
> 
> Links:
> ------
> [1] https://stat.ethz.ch/mailman/listinfo/r-devel
> [2] http://rapporter.net
> [3] https://github.com/Rapporter/pander
> [4] http://pastebin.com/jCUkgKim

-- 
Benoit Thieurmel
+33 6 69 04 06 11

DataKnowledge
46 rue Amsterdam - 75009 Paris


From daroczig at rapporter.net  Tue Oct  7 14:38:50 2014
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Tue, 7 Oct 2014 14:38:50 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <5433DAD0.8080305@gmail.com>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
Message-ID: <CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>

On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
> > Hi,
> >
> > With the use of R in production, it is necessary to have a system of
> > logs effective, and light.
> >
> > Package exist as to futile.logger, but it require the additional coding
> > of logs. So it is thus impossible / very difficult to use it with all
> > package them used in the calculation
> >
> > Our idea is to develop one packages global, simple, who would allow to
> > identify all the errors, warning, message generated by the functions
> > stop(), warning() and message() stop as well as by signals and
> > internally code, with log levels configurable later by package,
> > functions...
> >
> > One way is to overwrite temporarily the functions stop(), warning() and
> > message() of base package, but I think is not a good thing, and
> > furthermore, we lose all signals and internally "message"...
> >
> > A good use of options(error) seems to do the perfect job, but only for
> > error...
> >
> > Our problem / question :
> > - At present, how it is possible to have the same features for messages
> > and warnings? (like options(errors)) (I don't find...)
> > - Would new options be possible in a near future R ?
> > - Have there better / other possibilities to handle all the warnings,
> > message of the way which we wish?
> >
>
> ??
> withCallingHandlers() lets you evaluate expressions with code to catch
> messages, warnings and errors.
>

That's exactly what I'm using in "pander::evals" to capture all
error/warning/normal messages while evaluating an R command, and to also
capture the results (as R objects), stdout and the printed version of the
object -- which might be useful in a custom environment. E.g. I use this
function to evaluate all R chunks in markdown document and also to store
all R messages run at the rapporter.net API. Please let me know if anyone
is interested, and I will start cleaning up the related codebase and
publish on GH -- although "pander" and "evals" is already there:
https://github.com/Rapporter/pander

Quick demo: http://pastebin.com/jCUkgKim


>
> I don't know if there's a way to evaluate every expression entered at
> the console within withCallingHandlers() for an effect like
> options(error=), but you can certainly write code to read a file and
> evaluate every expression in it within a withCallingHandlers() call.
>
> Duncan Murdoch
>
> > Hope is clear. Open to any suggestions.
> >
> > Thank you in advance
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Oct  7 16:29:48 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 07 Oct 2014 10:29:48 -0400
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <50055615b4a67b88787ba18dc0c607b8@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
Message-ID: <5433F8DC.8040009@gmail.com>

On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
> Thank. withCallingHandlers() and "pander::evals" seem to be very
> interesting, but little adapted to the analysis of one or several
> scripts R / of many lines of code. Our goal is one packages requiring no
> modifications of code R to be able to get back all the desired
> information.
>
> Is-there a hope in seeing R core team adding two options warn and
> message with the same features as options(error) ? Or if we try (and
> succeed) to code a patch for it, to see it integrating in R ?

No, I don't think so.  withCallingHandlers is all you need for your purpose.

Duncan Murdoch

>
> I think that it would be very useful.
>
> Benoit
>
> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> >
> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
> >>> Hi,
> >>>
> >>> With the use of R in production, it is necessary to have a system
> >> of
> >>> logs effective, and light.
> >>>
> >>> Package exist as to futile.logger, but it require the additional
> >> coding
> >>> of logs. So it is thus impossible / very difficult to use it with
> >> all
> >>> package them used in the calculation
> >>>
> >>> Our idea is to develop one packages global, simple, who would
> >> allow to
> >>> identify all the errors, warning, message generated by the
> >> functions
> >>> stop(), warning() and message() stop as well as by signals and
> >>> internally code, with log levels configurable later by package,
> >>> functions...
> >>>
> >>> One way is to overwrite temporarily the functions stop(),
> >> warning() and
> >>> message() of base package, but I think is not a good thing, and
> >>> furthermore, we lose all signals and internally "message"...
> >>>
> >>> A good use of options(error) seems to do the perfect job, but
> >> only for
> >>> error...
> >>>
> >>> Our problem / question :
> >>> - At present, how it is possible to have the same features for
> >> messages
> >>> and warnings? (like options(errors)) (I don't find...)
> >>> - Would new options be possible in a near future R ?
> >>> - Have there better / other possibilities to handle all the
> >> warnings,
> >>> message of the way which we wish?
> >>>
> >>
> >> ??withCallingHandlers() lets you evaluate expressions with code
> >> to catch
> >> messages, warnings and errors.
> >
> > That's exactly what I'm using in "pander::evals" to capture all
> > error/warning/normal messages while evaluating an R command, and to
> > also capture the results (as R objects), stdout and the printed
> > version of the object -- which might be useful in a custom
> > environment. E.g. I use this function to evaluate all R chunks in
> > markdown document and also to store all R messages run at the
> > rapporter.net [2] API. Please let me know if anyone is interested, and
> > I will start cleaning up the related codebase and publish on GH --
> > although "pander" and "evals" is already
> > there: https://github.com/Rapporter/pander [3]
> >
> > Quick demo: http://pastebin.com/jCUkgKim [4]
> >
> >
> >> I don't know if there's a way to evaluate every expression entered
> >> at
> >> the console within withCallingHandlers() for an effect like
> >> options(error=), but you can certainly write code to read a file
> >> and
> >> evaluate every expression in it within a withCallingHandlers()
> >> call.
> >>
> >> Duncan Murdoch
> >>
> >>> Hope is clear. Open to any suggestions.
> >>>
> >>> Thank you in advance
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
> >
> >
> >
> > Links:
> > ------
> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
> > [2] http://rapporter.net
> > [3] https://github.com/Rapporter/pander
> > [4] http://pastebin.com/jCUkgKim
>


From bt at datak.fr  Tue Oct  7 16:41:05 2014
From: bt at datak.fr (DataK - B. THIEURMEL)
Date: Tue, 07 Oct 2014 16:41:05 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <5433F8DC.8040009@gmail.com>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
	<5433F8DC.8040009@gmail.com>
Message-ID: <e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>

OK, thank you for your answers. We are thus going to continue by 
analyzing these features

Le 2014-10-07 16:29, Duncan Murdoch a ?crit?:
> On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>> Thank. withCallingHandlers() and "pander::evals" seem to be very
>> interesting, but little adapted to the analysis of one or several
>> scripts R / of many lines of code. Our goal is one packages requiring 
>> no
>> modifications of code R to be able to get back all the desired
>> information.
>> 
>> Is-there a hope in seeing R core team adding two options warn and
>> message with the same features as options(error) ? Or if we try (and
>> succeed) to code a patch for it, to see it integrating in R ?
> 
> No, I don't think so.  withCallingHandlers is all you need for your 
> purpose.
> 
> Duncan Murdoch
> 
>> 
>> I think that it would be very useful.
>> 
>> Benoit
>> 
>> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> > <murdoch.duncan at gmail.com> wrote:
>> >
>> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> >>> Hi,
>> >>>
>> >>> With the use of R in production, it is necessary to have a system
>> >> of
>> >>> logs effective, and light.
>> >>>
>> >>> Package exist as to futile.logger, but it require the additional
>> >> coding
>> >>> of logs. So it is thus impossible / very difficult to use it with
>> >> all
>> >>> package them used in the calculation
>> >>>
>> >>> Our idea is to develop one packages global, simple, who would
>> >> allow to
>> >>> identify all the errors, warning, message generated by the
>> >> functions
>> >>> stop(), warning() and message() stop as well as by signals and
>> >>> internally code, with log levels configurable later by package,
>> >>> functions...
>> >>>
>> >>> One way is to overwrite temporarily the functions stop(),
>> >> warning() and
>> >>> message() of base package, but I think is not a good thing, and
>> >>> furthermore, we lose all signals and internally "message"...
>> >>>
>> >>> A good use of options(error) seems to do the perfect job, but
>> >> only for
>> >>> error...
>> >>>
>> >>> Our problem / question :
>> >>> - At present, how it is possible to have the same features for
>> >> messages
>> >>> and warnings? (like options(errors)) (I don't find...)
>> >>> - Would new options be possible in a near future R ?
>> >>> - Have there better / other possibilities to handle all the
>> >> warnings,
>> >>> message of the way which we wish?
>> >>>
>> >>
>> >> ??withCallingHandlers() lets you evaluate expressions with code
>> >> to catch
>> >> messages, warnings and errors.
>> >
>> > That's exactly what I'm using in "pander::evals" to capture all
>> > error/warning/normal messages while evaluating an R command, and to
>> > also capture the results (as R objects), stdout and the printed
>> > version of the object -- which might be useful in a custom
>> > environment. E.g. I use this function to evaluate all R chunks in
>> > markdown document and also to store all R messages run at the
>> > rapporter.net [2] API. Please let me know if anyone is interested, and
>> > I will start cleaning up the related codebase and publish on GH --
>> > although "pander" and "evals" is already
>> > there: https://github.com/Rapporter/pander [3]
>> >
>> > Quick demo: http://pastebin.com/jCUkgKim [4]
>> >
>> >
>> >> I don't know if there's a way to evaluate every expression entered
>> >> at
>> >> the console within withCallingHandlers() for an effect like
>> >> options(error=), but you can certainly write code to read a file
>> >> and
>> >> evaluate every expression in it within a withCallingHandlers()
>> >> call.
>> >>
>> >> Duncan Murdoch
>> >>
>> >>> Hope is clear. Open to any suggestions.
>> >>>
>> >>> Thank you in advance
>> >>>
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>> >
>> >
>> >
>> > Links:
>> > ------
>> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> > [2] http://rapporter.net
>> > [3] https://github.com/Rapporter/pander
>> > [4] http://pastebin.com/jCUkgKim
>> 

-- 
Benoit Thieurmel
+33 6 69 04 06 11

DataKnowledge
46 rue Amsterdam - 75009 Paris


From murdoch.duncan at gmail.com  Tue Oct  7 16:51:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 07 Oct 2014 10:51:44 -0400
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
	<5433F8DC.8040009@gmail.com>
	<e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>
Message-ID: <5433FE00.3090605@gmail.com>

On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
> OK, thank you for your answers. We are thus going to continue by
> analyzing these features

The general outline would be this:

1.  Call parse() on the whole file.  This will catch any syntax errors.  
If it parses okay, you'll get a vector of expressions to evaluate.

2.  Evaluate each expression in sequence within withCallingHandlers().  
You need to decide what to do if you get an error(); source() would quit 
the script at that point, so that's probably a good idea.

Duncan Murdoch
>
> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
> >> interesting, but little adapted to the analysis of one or several
> >> scripts R / of many lines of code. Our goal is one packages requiring
> >> no
> >> modifications of code R to be able to get back all the desired
> >> information.
> >>
> >> Is-there a hope in seeing R core team adding two options warn and
> >> message with the same features as options(error) ? Or if we try (and
> >> succeed) to code a patch for it, to see it integrating in R ?
> >
> > No, I don't think so.  withCallingHandlers is all you need for your
> > purpose.
> >
> > Duncan Murdoch
> >
> >>
> >> I think that it would be very useful.
> >>
> >> Benoit
> >>
> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
> >> > <murdoch.duncan at gmail.com> wrote:
> >> >
> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
> >> >>> Hi,
> >> >>>
> >> >>> With the use of R in production, it is necessary to have a system
> >> >> of
> >> >>> logs effective, and light.
> >> >>>
> >> >>> Package exist as to futile.logger, but it require the additional
> >> >> coding
> >> >>> of logs. So it is thus impossible / very difficult to use it with
> >> >> all
> >> >>> package them used in the calculation
> >> >>>
> >> >>> Our idea is to develop one packages global, simple, who would
> >> >> allow to
> >> >>> identify all the errors, warning, message generated by the
> >> >> functions
> >> >>> stop(), warning() and message() stop as well as by signals and
> >> >>> internally code, with log levels configurable later by package,
> >> >>> functions...
> >> >>>
> >> >>> One way is to overwrite temporarily the functions stop(),
> >> >> warning() and
> >> >>> message() of base package, but I think is not a good thing, and
> >> >>> furthermore, we lose all signals and internally "message"...
> >> >>>
> >> >>> A good use of options(error) seems to do the perfect job, but
> >> >> only for
> >> >>> error...
> >> >>>
> >> >>> Our problem / question :
> >> >>> - At present, how it is possible to have the same features for
> >> >> messages
> >> >>> and warnings? (like options(errors)) (I don't find...)
> >> >>> - Would new options be possible in a near future R ?
> >> >>> - Have there better / other possibilities to handle all the
> >> >> warnings,
> >> >>> message of the way which we wish?
> >> >>>
> >> >>
> >> >> ??withCallingHandlers() lets you evaluate expressions with code
> >> >> to catch
> >> >> messages, warnings and errors.
> >> >
> >> > That's exactly what I'm using in "pander::evals" to capture all
> >> > error/warning/normal messages while evaluating an R command, and to
> >> > also capture the results (as R objects), stdout and the printed
> >> > version of the object -- which might be useful in a custom
> >> > environment. E.g. I use this function to evaluate all R chunks in
> >> > markdown document and also to store all R messages run at the
> >> > rapporter.net [2] API. Please let me know if anyone is interested, and
> >> > I will start cleaning up the related codebase and publish on GH --
> >> > although "pander" and "evals" is already
> >> > there: https://github.com/Rapporter/pander [3]
> >> >
> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
> >> >
> >> >
> >> >> I don't know if there's a way to evaluate every expression entered
> >> >> at
> >> >> the console within withCallingHandlers() for an effect like
> >> >> options(error=), but you can certainly write code to read a file
> >> >> and
> >> >> evaluate every expression in it within a withCallingHandlers()
> >> >> call.
> >> >>
> >> >> Duncan Murdoch
> >> >>
> >> >>> Hope is clear. Open to any suggestions.
> >> >>>
> >> >>> Thank you in advance
> >> >>>
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
> >> >
> >> >
> >> >
> >> > Links:
> >> > ------
> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
> >> > [2] http://rapporter.net
> >> > [3] https://github.com/Rapporter/pander
> >> > [4] http://pastebin.com/jCUkgKim
> >>
>


From bt at datak.fr  Tue Oct  7 17:11:08 2014
From: bt at datak.fr (DataK - B. THIEURMEL)
Date: Tue, 07 Oct 2014 17:11:08 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <5433FE00.3090605@gmail.com>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
	<5433F8DC.8040009@gmail.com>
	<e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>
	<5433FE00.3090605@gmail.com>
Message-ID: <a5c4d7cbc69d368488567170490b8e2d@datak.fr>

Do you think there is a way to apply a "global" withCallingHandlers() on 
all environement / packages loaded, and then all R code will be executed 
with the defined handler ? With this way, we can define what we want for 
warning, message, error, ... one time, and apply it without needed of 
parse() or added withCallingHandlers in initial code...

Something like this :

withCallingHandlersGlobal <- function(...) {
   handlers <- list(...)
   classes <- names(handlers)
   parentenv <- all.environment
   if (length(classes) != length(handlers))
     stop("bad handler specification")
   .Internal(.addCondHands(classes, handlers, parentenv, NULL, TRUE))
}

withCallingHandlersGlobal(warning = function(w) {print("Global 
handler")})

warning("A")
> "Global handler"
rnorm("A")
> "Global handler"



Le 2014-10-07 16:51, Duncan Murdoch a ?crit?:
> On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
>> OK, thank you for your answers. We are thus going to continue by
>> analyzing these features
> 
> The general outline would be this:
> 
> 1.  Call parse() on the whole file.  This will catch any syntax
> errors.  If it parses okay, you'll get a vector of expressions to
> evaluate.
> 
> 2.  Evaluate each expression in sequence within withCallingHandlers().
>  You need to decide what to do if you get an error(); source() would
> quit the script at that point, so that's probably a good idea.
> 
> Duncan Murdoch
>> 
>> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
>> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
>> >> interesting, but little adapted to the analysis of one or several
>> >> scripts R / of many lines of code. Our goal is one packages requiring
>> >> no
>> >> modifications of code R to be able to get back all the desired
>> >> information.
>> >>
>> >> Is-there a hope in seeing R core team adding two options warn and
>> >> message with the same features as options(error) ? Or if we try (and
>> >> succeed) to code a patch for it, to see it integrating in R ?
>> >
>> > No, I don't think so.  withCallingHandlers is all you need for your
>> > purpose.
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >> I think that it would be very useful.
>> >>
>> >> Benoit
>> >>
>> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> >> > <murdoch.duncan at gmail.com> wrote:
>> >> >
>> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> >> >>> Hi,
>> >> >>>
>> >> >>> With the use of R in production, it is necessary to have a system
>> >> >> of
>> >> >>> logs effective, and light.
>> >> >>>
>> >> >>> Package exist as to futile.logger, but it require the additional
>> >> >> coding
>> >> >>> of logs. So it is thus impossible / very difficult to use it with
>> >> >> all
>> >> >>> package them used in the calculation
>> >> >>>
>> >> >>> Our idea is to develop one packages global, simple, who would
>> >> >> allow to
>> >> >>> identify all the errors, warning, message generated by the
>> >> >> functions
>> >> >>> stop(), warning() and message() stop as well as by signals and
>> >> >>> internally code, with log levels configurable later by package,
>> >> >>> functions...
>> >> >>>
>> >> >>> One way is to overwrite temporarily the functions stop(),
>> >> >> warning() and
>> >> >>> message() of base package, but I think is not a good thing, and
>> >> >>> furthermore, we lose all signals and internally "message"...
>> >> >>>
>> >> >>> A good use of options(error) seems to do the perfect job, but
>> >> >> only for
>> >> >>> error...
>> >> >>>
>> >> >>> Our problem / question :
>> >> >>> - At present, how it is possible to have the same features for
>> >> >> messages
>> >> >>> and warnings? (like options(errors)) (I don't find...)
>> >> >>> - Would new options be possible in a near future R ?
>> >> >>> - Have there better / other possibilities to handle all the
>> >> >> warnings,
>> >> >>> message of the way which we wish?
>> >> >>>
>> >> >>
>> >> >> ??withCallingHandlers() lets you evaluate expressions with code
>> >> >> to catch
>> >> >> messages, warnings and errors.
>> >> >
>> >> > That's exactly what I'm using in "pander::evals" to capture all
>> >> > error/warning/normal messages while evaluating an R command, and to
>> >> > also capture the results (as R objects), stdout and the printed
>> >> > version of the object -- which might be useful in a custom
>> >> > environment. E.g. I use this function to evaluate all R chunks in
>> >> > markdown document and also to store all R messages run at the
>> >> > rapporter.net [2] API. Please let me know if anyone is interested, and
>> >> > I will start cleaning up the related codebase and publish on GH --
>> >> > although "pander" and "evals" is already
>> >> > there: https://github.com/Rapporter/pander [3]
>> >> >
>> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
>> >> >
>> >> >
>> >> >> I don't know if there's a way to evaluate every expression entered
>> >> >> at
>> >> >> the console within withCallingHandlers() for an effect like
>> >> >> options(error=), but you can certainly write code to read a file
>> >> >> and
>> >> >> evaluate every expression in it within a withCallingHandlers()
>> >> >> call.
>> >> >>
>> >> >> Duncan Murdoch
>> >> >>
>> >> >>> Hope is clear. Open to any suggestions.
>> >> >>>
>> >> >>> Thank you in advance
>> >> >>>
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>> >> >
>> >> >
>> >> >
>> >> > Links:
>> >> > ------
>> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> > [2] http://rapporter.net
>> >> > [3] https://github.com/Rapporter/pander
>> >> > [4] http://pastebin.com/jCUkgKim
>> >>
>> 

-- 
Benoit Thieurmel
+33 6 69 04 06 11

DataKnowledge
46 rue Amsterdam - 75009 Paris


From daroczig at rapporter.net  Tue Oct  7 18:05:03 2014
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Tue, 7 Oct 2014 18:05:03 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <5433FE00.3090605@gmail.com>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
	<5433F8DC.8040009@gmail.com>
	<e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>
	<5433FE00.3090605@gmail.com>
Message-ID: <CAPvvxJX-cs7se4cicZ+BZyzPbAL02OmQq-z662e=ad74+uxNfQ@mail.gmail.com>

On Tue, Oct 7, 2014 at 4:51 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
>
>> OK, thank you for your answers. We are thus going to continue by
>> analyzing these features
>>
>
> The general outline would be this:
>
> 1.  Call parse() on the whole file.  This will catch any syntax errors.
> If it parses okay, you'll get a vector of expressions to evaluate.
>
> 2.  Evaluate each expression in sequence within withCallingHandlers().
> You need to decide what to do if you get an error(); source() would quit
> the script at that point, so that's probably a good idea.


Quick demo with "pander::evals":
https://gist.github.com/daroczig/480af8ad766e96dd25f4


>
>
> Duncan Murdoch
>
>
>> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
>> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
>> >> interesting, but little adapted to the analysis of one or several
>> >> scripts R / of many lines of code. Our goal is one packages requiring
>> >> no
>> >> modifications of code R to be able to get back all the desired
>> >> information.
>> >>
>> >> Is-there a hope in seeing R core team adding two options warn and
>> >> message with the same features as options(error) ? Or if we try (and
>> >> succeed) to code a patch for it, to see it integrating in R ?
>> >
>> > No, I don't think so.  withCallingHandlers is all you need for your
>> > purpose.
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >> I think that it would be very useful.
>> >>
>> >> Benoit
>> >>
>> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> >> > <murdoch.duncan at gmail.com> wrote:
>> >> >
>> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> >> >>> Hi,
>> >> >>>
>> >> >>> With the use of R in production, it is necessary to have a system
>> >> >> of
>> >> >>> logs effective, and light.
>> >> >>>
>> >> >>> Package exist as to futile.logger, but it require the additional
>> >> >> coding
>> >> >>> of logs. So it is thus impossible / very difficult to use it with
>> >> >> all
>> >> >>> package them used in the calculation
>> >> >>>
>> >> >>> Our idea is to develop one packages global, simple, who would
>> >> >> allow to
>> >> >>> identify all the errors, warning, message generated by the
>> >> >> functions
>> >> >>> stop(), warning() and message() stop as well as by signals and
>> >> >>> internally code, with log levels configurable later by package,
>> >> >>> functions...
>> >> >>>
>> >> >>> One way is to overwrite temporarily the functions stop(),
>> >> >> warning() and
>> >> >>> message() of base package, but I think is not a good thing, and
>> >> >>> furthermore, we lose all signals and internally "message"...
>> >> >>>
>> >> >>> A good use of options(error) seems to do the perfect job, but
>> >> >> only for
>> >> >>> error...
>> >> >>>
>> >> >>> Our problem / question :
>> >> >>> - At present, how it is possible to have the same features for
>> >> >> messages
>> >> >>> and warnings? (like options(errors)) (I don't find...)
>> >> >>> - Would new options be possible in a near future R ?
>> >> >>> - Have there better / other possibilities to handle all the
>> >> >> warnings,
>> >> >>> message of the way which we wish?
>> >> >>>
>> >> >>
>> >> >> ??withCallingHandlers() lets you evaluate expressions with code
>> >> >> to catch
>> >> >> messages, warnings and errors.
>> >> >
>> >> > That's exactly what I'm using in "pander::evals" to capture all
>> >> > error/warning/normal messages while evaluating an R command, and to
>> >> > also capture the results (as R objects), stdout and the printed
>> >> > version of the object -- which might be useful in a custom
>> >> > environment. E.g. I use this function to evaluate all R chunks in
>> >> > markdown document and also to store all R messages run at the
>> >> > rapporter.net [2] API. Please let me know if anyone is interested,
>> and
>> >> > I will start cleaning up the related codebase and publish on GH --
>> >> > although "pander" and "evals" is already
>> >> > there: https://github.com/Rapporter/pander [3]
>> >> >
>> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
>> >> >
>> >> >
>> >> >> I don't know if there's a way to evaluate every expression entered
>> >> >> at
>> >> >> the console within withCallingHandlers() for an effect like
>> >> >> options(error=), but you can certainly write code to read a file
>> >> >> and
>> >> >> evaluate every expression in it within a withCallingHandlers()
>> >> >> call.
>> >> >>
>> >> >> Duncan Murdoch
>> >> >>
>> >> >>> Hope is clear. Open to any suggestions.
>> >> >>>
>> >> >>> Thank you in advance
>> >> >>>
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>> >> >
>> >> >
>> >> >
>> >> > Links:
>> >> > ------
>> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> > [2] http://rapporter.net
>> >> > [3] https://github.com/Rapporter/pander
>> >> > [4] http://pastebin.com/jCUkgKim
>> >>
>>
>>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Oct  7 18:28:06 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Oct 2014 18:28:06 +0200
Subject: [Rd] AIX-5.3 Issue installing Matrix Package
In-Reply-To: <771dd37aff6b886900d46627bcb5cf88.squirrel@mail.ncmrwf.gov.in>
References: <771dd37aff6b886900d46627bcb5cf88.squirrel@mail.ncmrwf.gov.in>
Message-ID: <21556.5270.527132.88858@stat.math.ethz.ch>

I've changed the subject to draw attention to this issue.

For more, see inline below

> Hi,
> I installed R-3.1.1 on AIX-5.3 and my installation hanged up while
> installing Matrix Package.
> so i killed the gmake ; gmake install the software nad tired installing
> Matrix package manually -

> [ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1/bin/package]>
> /gpfs1/home/shivali/gang/R-3.1.1/bin/R CMD INSTALL Matrix

> the package compiled successfully but while loading Matrix package the
> installation hanged up -
> in method for 'coerce' with signature '"sparseMatrix","graphNEL"': no
> definition for class "graphNEL"
> in method for 'coerce' with signature '"TsparseMatrix","graphNEL"': no
> definition for class "graphNEL"
> Creating a generic function for 'format' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.R' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.Q' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.qy' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.qty' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.coef' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.resid' from package 'base' in package 'Matrix'
> Creating a generic function for 'qr.fitted' from package 'base' in package 'Matrix'
> ** help
> *** installing help indices
> ** building package indices
> Loading required package: Matrix

> On checking more i come accross the CPU utilization for thread using
> ps -ef command (CPU priority penalty ) is inreasing upto 120 max limit.

> [ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1]> ps -ef | grep R-3.1.1
>  shivali 323978 459010   0 14:36:14 pts/14  0:00 grep R-3.1.1
>     root 492034 336504   0 14:34:36 pts/11  0:00 sh /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix
>     root 525188 492034 120 14:34:37 pts/11  0:30 /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/exec/R --args --args --args nextArgMatrix
> [ncmr0202][/gpfs1/home/shivali/gang/R-3.1.1]>

As maintainer of the Matrix package I'm currently claiming that
this is more an issue of AIX configuration when installing R
(and hence the Matrix package) than an issue of the Matrix
package per se.

> Please help

I'm trying,  asking a few questions:

- Have made use of the many hints and consideration about AIX
  installation in the official "R Administration and Installation"
  Manual, notably section 'C.5 AIX', see, e.g.,
	 http://cran.rstudio.org/doc/manuals/r-release/R-admin.html#AIX

- What was the exact output when running  ..../configure ?

- Have you set environment variables / PATH for compilers,
  libraries, etc?  If yes, which one?

Hoping this will lead further,
Martin Maechler

> Regards,
> Shivali Gangwar


From murdoch.duncan at gmail.com  Tue Oct  7 18:27:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 07 Oct 2014 12:27:58 -0400
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <a5c4d7cbc69d368488567170490b8e2d@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
	<5433F8DC.8040009@gmail.com>
	<e630f94c1003f37cc1eb9a47ff8b5152@datak.fr>
	<5433FE00.3090605@gmail.com>
	<a5c4d7cbc69d368488567170490b8e2d@datak.fr>
Message-ID: <5434148E.2020207@gmail.com>

On 07/10/2014 11:11 AM, DataK - B. THIEURMEL wrote:
> Do you think there is a way to apply a "global" withCallingHandlers() on
> all environement / packages loaded, and then all R code will be executed
> with the defined handler ?

That question makes no sense.  withCallingHandlers is not applied to 
environments or packages, it is applied to expressions.

> With this way, we can define what we want for
> warning, message, error, ... one time, and apply it without needed of
> parse() or added withCallingHandlers in initial code...
>
> Something like this :
>
> withCallingHandlersGlobal <- function(...) {
>     handlers <- list(...)
>     classes <- names(handlers)
>     parentenv <- all.environment
>     if (length(classes) != length(handlers))
>       stop("bad handler specification")
>     .Internal(.addCondHands(classes, handlers, parentenv, NULL, TRUE))
> }
>
> withCallingHandlersGlobal(warning = function(w) {print("Global
> handler")})
>
> warning("A")
> > "Global handler"
> rnorm("A")
> > "Global handler"
>

You would need to write the read-eval-print loop.  Read text from the 
console until you have a complete expression, then evaluate it in 
withCallingHandlers.  Repeat.

Duncan Murdoch
>
> Le 2014-10-07 16:51, Duncan Murdoch a ?crit :
> > On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
> >> OK, thank you for your answers. We are thus going to continue by
> >> analyzing these features
> >
> > The general outline would be this:
> >
> > 1.  Call parse() on the whole file.  This will catch any syntax
> > errors.  If it parses okay, you'll get a vector of expressions to
> > evaluate.
> >
> > 2.  Evaluate each expression in sequence within withCallingHandlers().
> >  You need to decide what to do if you get an error(); source() would
> > quit the script at that point, so that's probably a good idea.
> >
> > Duncan Murdoch
> >>
> >> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
> >> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
> >> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
> >> >> interesting, but little adapted to the analysis of one or several
> >> >> scripts R / of many lines of code. Our goal is one packages requiring
> >> >> no
> >> >> modifications of code R to be able to get back all the desired
> >> >> information.
> >> >>
> >> >> Is-there a hope in seeing R core team adding two options warn and
> >> >> message with the same features as options(error) ? Or if we try (and
> >> >> succeed) to code a patch for it, to see it integrating in R ?
> >> >
> >> > No, I don't think so.  withCallingHandlers is all you need for your
> >> > purpose.
> >> >
> >> > Duncan Murdoch
> >> >
> >> >>
> >> >> I think that it would be very useful.
> >> >>
> >> >> Benoit
> >> >>
> >> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
> >> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
> >> >> > <murdoch.duncan at gmail.com> wrote:
> >> >> >
> >> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
> >> >> >>> Hi,
> >> >> >>>
> >> >> >>> With the use of R in production, it is necessary to have a system
> >> >> >> of
> >> >> >>> logs effective, and light.
> >> >> >>>
> >> >> >>> Package exist as to futile.logger, but it require the additional
> >> >> >> coding
> >> >> >>> of logs. So it is thus impossible / very difficult to use it with
> >> >> >> all
> >> >> >>> package them used in the calculation
> >> >> >>>
> >> >> >>> Our idea is to develop one packages global, simple, who would
> >> >> >> allow to
> >> >> >>> identify all the errors, warning, message generated by the
> >> >> >> functions
> >> >> >>> stop(), warning() and message() stop as well as by signals and
> >> >> >>> internally code, with log levels configurable later by package,
> >> >> >>> functions...
> >> >> >>>
> >> >> >>> One way is to overwrite temporarily the functions stop(),
> >> >> >> warning() and
> >> >> >>> message() of base package, but I think is not a good thing, and
> >> >> >>> furthermore, we lose all signals and internally "message"...
> >> >> >>>
> >> >> >>> A good use of options(error) seems to do the perfect job, but
> >> >> >> only for
> >> >> >>> error...
> >> >> >>>
> >> >> >>> Our problem / question :
> >> >> >>> - At present, how it is possible to have the same features for
> >> >> >> messages
> >> >> >>> and warnings? (like options(errors)) (I don't find...)
> >> >> >>> - Would new options be possible in a near future R ?
> >> >> >>> - Have there better / other possibilities to handle all the
> >> >> >> warnings,
> >> >> >>> message of the way which we wish?
> >> >> >>>
> >> >> >>
> >> >> >> ??withCallingHandlers() lets you evaluate expressions with code
> >> >> >> to catch
> >> >> >> messages, warnings and errors.
> >> >> >
> >> >> > That's exactly what I'm using in "pander::evals" to capture all
> >> >> > error/warning/normal messages while evaluating an R command, and to
> >> >> > also capture the results (as R objects), stdout and the printed
> >> >> > version of the object -- which might be useful in a custom
> >> >> > environment. E.g. I use this function to evaluate all R chunks in
> >> >> > markdown document and also to store all R messages run at the
> >> >> > rapporter.net [2] API. Please let me know if anyone is interested, and
> >> >> > I will start cleaning up the related codebase and publish on GH --
> >> >> > although "pander" and "evals" is already
> >> >> > there: https://github.com/Rapporter/pander [3]
> >> >> >
> >> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
> >> >> >
> >> >> >
> >> >> >> I don't know if there's a way to evaluate every expression entered
> >> >> >> at
> >> >> >> the console within withCallingHandlers() for an effect like
> >> >> >> options(error=), but you can certainly write code to read a file
> >> >> >> and
> >> >> >> evaluate every expression in it within a withCallingHandlers()
> >> >> >> call.
> >> >> >>
> >> >> >> Duncan Murdoch
> >> >> >>
> >> >> >>> Hope is clear. Open to any suggestions.
> >> >> >>>
> >> >> >>> Thank you in advance
> >> >> >>>
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-devel at r-project.org mailing list
> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
> >> >> >
> >> >> >
> >> >> >
> >> >> > Links:
> >> >> > ------
> >> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> > [2] http://rapporter.net
> >> >> > [3] https://github.com/Rapporter/pander
> >> >> > [4] http://pastebin.com/jCUkgKim
> >> >>
> >>
>


From wdunlap at tibco.com  Tue Oct  7 18:34:24 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 7 Oct 2014 09:34:24 -0700
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <50055615b4a67b88787ba18dc0c607b8@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
	<5433DAD0.8080305@gmail.com>
	<CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw@mail.gmail.com>
	<50055615b4a67b88787ba18dc0c607b8@datak.fr>
Message-ID: <CAF8bMcap0CE9AMOpLZWjvO8sV=YmUu83qcL7mDfEjqZBnhhNmg@mail.gmail.com>

R has support for options(warning.expression=...), but it acts
differently than the options(error=...).

S (and S+) let the user override the default '.Program' expression.
Its default value was essentially
   print(.Last.value <- eval(parse(file=stdin())))
but a replacement could add stuff like print the time it took to do
the evaluation, put errors and warnings
into a log file, or even read input expressions from an alternate source.

R has some hook functions that let you do some of that, but I don't
know how much they let you do.



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 7, 2014 at 7:16 AM, DataK - B. THIEURMEL <bt at datak.fr> wrote:
> Thank. withCallingHandlers() and "pander::evals" seem to be very
> interesting, but little adapted to the analysis of one or several scripts R
> / of many lines of code. Our goal is one packages requiring no modifications
> of code R to be able to get back all the desired information.
>
> Is-there a hope in seeing R core team adding two options warn and message
> with the same features as options(error) ? Or if we try (and succeed) to
> code a patch for it, to see it integrating in R ?
>
> I think that it would be very useful.
>
> Benoit
>
> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>>
>> On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>
>>> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>>>
>>>> Hi,
>>>>
>>>> With the use of R in production, it is necessary to have a system
>>>
>>> of
>>>>
>>>> logs effective, and light.
>>>>
>>>> Package exist as to futile.logger, but it require the additional
>>>
>>> coding
>>>>
>>>> of logs. So it is thus impossible / very difficult to use it with
>>>
>>> all
>>>>
>>>> package them used in the calculation
>>>>
>>>> Our idea is to develop one packages global, simple, who would
>>>
>>> allow to
>>>>
>>>> identify all the errors, warning, message generated by the
>>>
>>> functions
>>>>
>>>> stop(), warning() and message() stop as well as by signals and
>>>> internally code, with log levels configurable later by package,
>>>> functions...
>>>>
>>>> One way is to overwrite temporarily the functions stop(),
>>>
>>> warning() and
>>>>
>>>> message() of base package, but I think is not a good thing, and
>>>> furthermore, we lose all signals and internally "message"...
>>>>
>>>> A good use of options(error) seems to do the perfect job, but
>>>
>>> only for
>>>>
>>>> error...
>>>>
>>>> Our problem / question :
>>>> - At present, how it is possible to have the same features for
>>>
>>> messages
>>>>
>>>> and warnings? (like options(errors)) (I don't find...)
>>>> - Would new options be possible in a near future R ?
>>>> - Have there better / other possibilities to handle all the
>>>
>>> warnings,
>>>>
>>>> message of the way which we wish?
>>>>
>>>
>>> withCallingHandlers() lets you evaluate expressions with code
>>> to catch
>>> messages, warnings and errors.
>>
>>
>> That's exactly what I'm using in "pander::evals" to capture all
>> error/warning/normal messages while evaluating an R command, and to
>> also capture the results (as R objects), stdout and the printed
>> version of the object -- which might be useful in a custom
>> environment. E.g. I use this function to evaluate all R chunks in
>> markdown document and also to store all R messages run at the
>> rapporter.net [2] API. Please let me know if anyone is interested, and
>> I will start cleaning up the related codebase and publish on GH --
>> although "pander" and "evals" is already
>> there: https://github.com/Rapporter/pander [3]
>>
>> Quick demo: http://pastebin.com/jCUkgKim [4]
>>
>>
>>> I don't know if there's a way to evaluate every expression entered
>>> at
>>> the console within withCallingHandlers() for an effect like
>>> options(error=), but you can certainly write code to read a file
>>> and
>>> evaluate every expression in it within a withCallingHandlers()
>>> call.
>>>
>>> Duncan Murdoch
>>>
>>>> Hope is clear. Open to any suggestions.
>>>>
>>>> Thank you in advance
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>>
>>
>>
>>
>> Links:
>> ------
>> [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> [2] http://rapporter.net
>> [3] https://github.com/Rapporter/pander
>> [4] http://pastebin.com/jCUkgKim
>
>
> --
> Benoit Thieurmel
> +33 6 69 04 06 11
>
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nakama at ki.rim.or.jp  Wed Oct  8 08:21:15 2014
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Wed, 8 Oct 2014 15:21:15 +0900
Subject: [Rd] AIX-5.3 Issue installing Matrix Package
In-Reply-To: <21556.5270.527132.88858@stat.math.ethz.ch>
References: <771dd37aff6b886900d46627bcb5cf88.squirrel@mail.ncmrwf.gov.in>
	<21556.5270.527132.88858@stat.math.ethz.ch>
Message-ID: <CAJqeyYa48GWW+OTJezQwMXc8WH2K_bEsYgqOPHo8Bm8euTM7Aw@mail.gmail.com>

hi,

>>     root 492034 336504   0 14:34:36 pts/11  0:00 sh /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix

maybe sh running is not good.
please install bash.
CONFIG_SHELL=/boo/foo/bash before running `configure && make'.

-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From shivali at ncmrwf.gov.in  Wed Oct  8 12:01:06 2014
From: shivali at ncmrwf.gov.in (shivali at ncmrwf.gov.in)
Date: Wed, 8 Oct 2014 15:31:06 +0530
Subject: [Rd] AIX-5.3 Issue installing Matrix Package
In-Reply-To: <CAJqeyYa48GWW+OTJezQwMXc8WH2K_bEsYgqOPHo8Bm8euTM7Aw@mail.gmail.com>
References: <771dd37aff6b886900d46627bcb5cf88.squirrel@mail.ncmrwf.gov.in>
	<21556.5270.527132.88858@stat.math.ethz.ch>
	<CAJqeyYa48GWW+OTJezQwMXc8WH2K_bEsYgqOPHo8Bm8euTM7Aw@mail.gmail.com>
Message-ID: <63e8511762655862c8076aede2444390.squirrel@mail.ncmrwf.gov.in>

Hi ,

Thanks, but i tried with bash also result is same -
Package Matrix facing issue while Loading  -
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`
Creating a generic function for 'qr.qty' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.coef' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.resid' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.fitted' from package 'base' in package
'Matrix'
** help
*** installing help indices
** building package indices
Loading required package: Matrix              ==> Hanged up here
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~``



[ncmr0202][/gpfs1/home/shivali]> ps -ef | grep R-3.1.1
 shivali 413756 480210   0 12:49:03 pts/31  0:00 bash
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL
Matrix_1.1-4.tar.gz
 shivali 291478 413756 120 12:49:03 pts/31 146:54
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/exec/R --args --args --args
nextArgMatrix_1.1-4.tar.gz
 shivali 356902 254484   0 15:17:37 pts/24  0:00 grep R-3.1.1
[ncmr0202][/gpfs1/home/shivali]>

Regards,
Shivali Gangwar

> hi,
>
>>>     root 492034 336504   0 14:34:36 pts/11  0:00 sh
>>> /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix
>
> maybe sh running is not good.
> please install bash.
> CONFIG_SHELL=/boo/foo/bash before running `configure && make'.
>
> --
> Best Regards,
> --
> Eiji NAKAMA <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
>
> Email secured by Check Point
>



Email secured by Check Point


From thosjleeper at gmail.com  Wed Oct  8 12:49:19 2014
From: thosjleeper at gmail.com (Thomas J. Leeper)
Date: Wed, 8 Oct 2014 12:49:19 +0200
Subject: [Rd] [R logs] Help in develop a simply logs package
Message-ID: <CAOC91MTyeLS2oAS7fd3FNJbk+RReMtutw_QPwJom497qUyfMAg@mail.gmail.com>

Maybe this isn't what you're going for, but to implement the
"ritesink" widget in my package rite (which is a colored tcltk widget
to display output, messages, warnings, and errors), I use a
combination of `sink`, `addTaskCallback`, and a modification of
`options("error")`. In short, the task callback is executed after
every top-level evaluation. The function in that callback reads
contents from `sink`ed output and message streams and, if anything new
has been added to either, it writes those contents to the widget. The
custom error handler similarly writes to the widget instead of the
console. Following this design, instead of writing to the widget, you
could write all of that to some kind of formatted log file.

The package is on CRAN and you can take quick look at the source code
on GitHub: https://github.com/leeper/rite/blob/master/R/ritesink.r

Thomas J. Leeper
http://www.thomasleeper.com


On Wed, Oct 8, 2014 at 12:00 PM,  <r-devel-request at r-project.org> wrote:
> Message: 2
> Date: Tue, 07 Oct 2014 13:04:34 +0200
> From: "DataK - B. THIEURMEL" <bt at datak.fr>
> To: r-devel at r-project.org
> Subject: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <4726f6636a227512e8a3ec4ae1562e73 at datak.fr>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> Hi,
>
> With the use of R in production, it is necessary to have a system of
> logs effective, and light.
>
> Package exist as to futile.logger, but it require the additional coding
> of logs. So it is thus impossible / very difficult to use it with all
> package them used in the calculation
>
> Our idea is to develop one packages global, simple, who would allow to
> identify all the errors, warning, message generated by the functions
> stop(), warning() and message() stop as well as by signals and
> internally code, with log levels configurable later by package,
> functions...
>
> One way is to overwrite temporarily the functions stop(), warning() and
> message() of base package, but I think is not a good thing, and
> furthermore, we lose all signals and internally "message"...
>
> A good use of options(error) seems to do the perfect job, but only for
> error...
>
> Our problem / question :
> - At present, how it is possible to have the same features for messages
> and warnings? (like options(errors)) (I don't find...)
> - Would new options be possible in a near future R ?
> - Have there better / other possibilities to handle all the warnings,
> message of the way which we wish?
>
> Hope is clear. Open to any suggestions.
>
> Thank you in advance
>
> --
> Benoit Thieurmel
> +33 6 69 04 06 11
>
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
>
>
>
> ------------------------------
>
> Message: 3
> Date: Tue, 07 Oct 2014 08:21:36 -0400
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: "DataK - B. THIEURMEL" <bt at datak.fr>, r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <5433DAD0.8080305 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> Hi,
>>
>> With the use of R in production, it is necessary to have a system of
>> logs effective, and light.
>>
>> Package exist as to futile.logger, but it require the additional coding
>> of logs. So it is thus impossible / very difficult to use it with all
>> package them used in the calculation
>>
>> Our idea is to develop one packages global, simple, who would allow to
>> identify all the errors, warning, message generated by the functions
>> stop(), warning() and message() stop as well as by signals and
>> internally code, with log levels configurable later by package,
>> functions...
>>
>> One way is to overwrite temporarily the functions stop(), warning() and
>> message() of base package, but I think is not a good thing, and
>> furthermore, we lose all signals and internally "message"...
>>
>> A good use of options(error) seems to do the perfect job, but only for
>> error...
>>
>> Our problem / question :
>> - At present, how it is possible to have the same features for messages
>> and warnings? (like options(errors)) (I don't find...)
>> - Would new options be possible in a near future R ?
>> - Have there better / other possibilities to handle all the warnings,
>> message of the way which we wish?
>>
>
> withCallingHandlers() lets you evaluate expressions with code to catch
> messages, warnings and errors.
>
> I don't know if there's a way to evaluate every expression entered at
> the console within withCallingHandlers() for an effect like
> options(error=), but you can certainly write code to read a file and
> evaluate every expression in it within a withCallingHandlers() call.
>
> Duncan Murdoch
>
>> Hope is clear. Open to any suggestions.
>>
>> Thank you in advance
>>
>
>
>
> ------------------------------
>
> Message: 4
> Date: Tue, 07 Oct 2014 16:16:53 +0200
> From: "DataK - B. THIEURMEL" <bt at datak.fr>
> To: Gergely Dar?czi <daroczig at rapporter.net>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <50055615b4a67b88787ba18dc0c607b8 at datak.fr>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> Thank. withCallingHandlers() and "pander::evals" seem to be very
> interesting, but little adapted to the analysis of one or several
> scripts R / of many lines of code. Our goal is one packages requiring no
> modifications of code R to be able to get back all the desired
> information.
>
> Is-there a hope in seeing R core team adding two options warn and
> message with the same features as options(error) ? Or if we try (and
> succeed) to code a patch for it, to see it integrating in R ?
>
> I think that it would be very useful.
>
> Benoit
>
> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit?:
>> On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>
>>> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>>> Hi,
>>>>
>>>> With the use of R in production, it is necessary to have a system
>>> of
>>>> logs effective, and light.
>>>>
>>>> Package exist as to futile.logger, but it require the additional
>>> coding
>>>> of logs. So it is thus impossible / very difficult to use it with
>>> all
>>>> package them used in the calculation
>>>>
>>>> Our idea is to develop one packages global, simple, who would
>>> allow to
>>>> identify all the errors, warning, message generated by the
>>> functions
>>>> stop(), warning() and message() stop as well as by signals and
>>>> internally code, with log levels configurable later by package,
>>>> functions...
>>>>
>>>> One way is to overwrite temporarily the functions stop(),
>>> warning() and
>>>> message() of base package, but I think is not a good thing, and
>>>> furthermore, we lose all signals and internally "message"...
>>>>
>>>> A good use of options(error) seems to do the perfect job, but
>>> only for
>>>> error...
>>>>
>>>> Our problem / question :
>>>> - At present, how it is possible to have the same features for
>>> messages
>>>> and warnings? (like options(errors)) (I don't find...)
>>>> - Would new options be possible in a near future R ?
>>>> - Have there better / other possibilities to handle all the
>>> warnings,
>>>> message of the way which we wish?
>>>>
>>>
>>> ??withCallingHandlers() lets you evaluate expressions with code
>>> to catch
>>> messages, warnings and errors.
>>
>> That's exactly what I'm using in "pander::evals" to capture all
>> error/warning/normal messages while evaluating an R command, and to
>> also capture the results (as R objects), stdout and the printed
>> version of the object -- which might be useful in a custom
>> environment. E.g. I use this function to evaluate all R chunks in
>> markdown document and also to store all R messages run at the
>> rapporter.net [2] API. Please let me know if anyone is interested, and
>> I will start cleaning up the related codebase and publish on GH --
>> although "pander" and "evals" is already
>> there:?https://github.com/Rapporter/pander [3]
>>
>> Quick demo:?http://pastebin.com/jCUkgKim [4]
>> ?
>>
>>> I don't know if there's a way to evaluate every expression entered
>>> at
>>> the console within withCallingHandlers() for an effect like
>>> options(error=), but you can certainly write code to read a file
>>> and
>>> evaluate every expression in it within a withCallingHandlers()
>>> call.
>>>
>>> Duncan Murdoch
>>>
>>>> Hope is clear. Open to any suggestions.
>>>>
>>>> Thank you in advance
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>>
>>
>>
>> Links:
>> ------
>> [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> [2] http://rapporter.net
>> [3] https://github.com/Rapporter/pander
>> [4] http://pastebin.com/jCUkgKim
>
> --
> Benoit Thieurmel
> +33 6 69 04 06 11
>
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
>
>
>
> ------------------------------
>
> Message: 5
> Date: Tue, 7 Oct 2014 14:38:50 +0200
> From: Gergely Dar?czi <daroczig at rapporter.net>
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID:
>         <CAPvvxJV=P4Hj3hL+cic2XN1CRtH5BrQROZHb8AHWY501Pq5FBw at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> > Hi,
>> >
>> > With the use of R in production, it is necessary to have a system of
>> > logs effective, and light.
>> >
>> > Package exist as to futile.logger, but it require the additional coding
>> > of logs. So it is thus impossible / very difficult to use it with all
>> > package them used in the calculation
>> >
>> > Our idea is to develop one packages global, simple, who would allow to
>> > identify all the errors, warning, message generated by the functions
>> > stop(), warning() and message() stop as well as by signals and
>> > internally code, with log levels configurable later by package,
>> > functions...
>> >
>> > One way is to overwrite temporarily the functions stop(), warning() and
>> > message() of base package, but I think is not a good thing, and
>> > furthermore, we lose all signals and internally "message"...
>> >
>> > A good use of options(error) seems to do the perfect job, but only for
>> > error...
>> >
>> > Our problem / question :
>> > - At present, how it is possible to have the same features for messages
>> > and warnings? (like options(errors)) (I don't find...)
>> > - Would new options be possible in a near future R ?
>> > - Have there better / other possibilities to handle all the warnings,
>> > message of the way which we wish?
>> >
>>
>> ??
>> withCallingHandlers() lets you evaluate expressions with code to catch
>> messages, warnings and errors.
>>
>
> That's exactly what I'm using in "pander::evals" to capture all
> error/warning/normal messages while evaluating an R command, and to also
> capture the results (as R objects), stdout and the printed version of the
> object -- which might be useful in a custom environment. E.g. I use this
> function to evaluate all R chunks in markdown document and also to store
> all R messages run at the rapporter.net API. Please let me know if anyone
> is interested, and I will start cleaning up the related codebase and
> publish on GH -- although "pander" and "evals" is already there:
> https://github.com/Rapporter/pander
>
> Quick demo: http://pastebin.com/jCUkgKim
>
>
>>
>> I don't know if there's a way to evaluate every expression entered at
>> the console within withCallingHandlers() for an effect like
>> options(error=), but you can certainly write code to read a file and
>> evaluate every expression in it within a withCallingHandlers() call.
>>
>> Duncan Murdoch
>>
>> > Hope is clear. Open to any suggestions.
>> >
>> > Thank you in advance
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 6
> Date: Tue, 07 Oct 2014 10:29:48 -0400
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: "DataK - B. THIEURMEL" <bt at datak.fr>, Gergely Dar?czi
>         <daroczig at rapporter.net>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <5433F8DC.8040009 at gmail.com>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>> Thank. withCallingHandlers() and "pander::evals" seem to be very
>> interesting, but little adapted to the analysis of one or several
>> scripts R / of many lines of code. Our goal is one packages requiring no
>> modifications of code R to be able to get back all the desired
>> information.
>>
>> Is-there a hope in seeing R core team adding two options warn and
>> message with the same features as options(error) ? Or if we try (and
>> succeed) to code a patch for it, to see it integrating in R ?
>
> No, I don't think so.  withCallingHandlers is all you need for your purpose.
>
> Duncan Murdoch
>
>>
>> I think that it would be very useful.
>>
>> Benoit
>>
>> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> > <murdoch.duncan at gmail.com> wrote:
>> >
>> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> >>> Hi,
>> >>>
>> >>> With the use of R in production, it is necessary to have a system
>> >> of
>> >>> logs effective, and light.
>> >>>
>> >>> Package exist as to futile.logger, but it require the additional
>> >> coding
>> >>> of logs. So it is thus impossible / very difficult to use it with
>> >> all
>> >>> package them used in the calculation
>> >>>
>> >>> Our idea is to develop one packages global, simple, who would
>> >> allow to
>> >>> identify all the errors, warning, message generated by the
>> >> functions
>> >>> stop(), warning() and message() stop as well as by signals and
>> >>> internally code, with log levels configurable later by package,
>> >>> functions...
>> >>>
>> >>> One way is to overwrite temporarily the functions stop(),
>> >> warning() and
>> >>> message() of base package, but I think is not a good thing, and
>> >>> furthermore, we lose all signals and internally "message"...
>> >>>
>> >>> A good use of options(error) seems to do the perfect job, but
>> >> only for
>> >>> error...
>> >>>
>> >>> Our problem / question :
>> >>> - At present, how it is possible to have the same features for
>> >> messages
>> >>> and warnings? (like options(errors)) (I don't find...)
>> >>> - Would new options be possible in a near future R ?
>> >>> - Have there better / other possibilities to handle all the
>> >> warnings,
>> >>> message of the way which we wish?
>> >>>
>> >>
>> >> ??withCallingHandlers() lets you evaluate expressions with code
>> >> to catch
>> >> messages, warnings and errors.
>> >
>> > That's exactly what I'm using in "pander::evals" to capture all
>> > error/warning/normal messages while evaluating an R command, and to
>> > also capture the results (as R objects), stdout and the printed
>> > version of the object -- which might be useful in a custom
>> > environment. E.g. I use this function to evaluate all R chunks in
>> > markdown document and also to store all R messages run at the
>> > rapporter.net [2] API. Please let me know if anyone is interested, and
>> > I will start cleaning up the related codebase and publish on GH --
>> > although "pander" and "evals" is already
>> > there: https://github.com/Rapporter/pander [3]
>> >
>> > Quick demo: http://pastebin.com/jCUkgKim [4]
>> >
>> >
>> >> I don't know if there's a way to evaluate every expression entered
>> >> at
>> >> the console within withCallingHandlers() for an effect like
>> >> options(error=), but you can certainly write code to read a file
>> >> and
>> >> evaluate every expression in it within a withCallingHandlers()
>> >> call.
>> >>
>> >> Duncan Murdoch
>> >>
>> >>> Hope is clear. Open to any suggestions.
>> >>>
>> >>> Thank you in advance
>> >>>
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>> >
>> >
>> >
>> > Links:
>> > ------
>> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> > [2] http://rapporter.net
>> > [3] https://github.com/Rapporter/pander
>> > [4] http://pastebin.com/jCUkgKim
>>
>
>
>
> ------------------------------
>
> Message: 7
> Date: Tue, 07 Oct 2014 16:41:05 +0200
> From: "DataK - B. THIEURMEL" <bt at datak.fr>
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <e630f94c1003f37cc1eb9a47ff8b5152 at datak.fr>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> OK, thank you for your answers. We are thus going to continue by
> analyzing these features
>
> Le 2014-10-07 16:29, Duncan Murdoch a ?crit?:
>> On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>>> Thank. withCallingHandlers() and "pander::evals" seem to be very
>>> interesting, but little adapted to the analysis of one or several
>>> scripts R / of many lines of code. Our goal is one packages requiring
>>> no
>>> modifications of code R to be able to get back all the desired
>>> information.
>>>
>>> Is-there a hope in seeing R core team adding two options warn and
>>> message with the same features as options(error) ? Or if we try (and
>>> succeed) to code a patch for it, to see it integrating in R ?
>>
>> No, I don't think so.  withCallingHandlers is all you need for your
>> purpose.
>>
>> Duncan Murdoch
>>
>>>
>>> I think that it would be very useful.
>>>
>>> Benoit
>>>
>>> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>>> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>>> > <murdoch.duncan at gmail.com> wrote:
>>> >
>>> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>> >>> Hi,
>>> >>>
>>> >>> With the use of R in production, it is necessary to have a system
>>> >> of
>>> >>> logs effective, and light.
>>> >>>
>>> >>> Package exist as to futile.logger, but it require the additional
>>> >> coding
>>> >>> of logs. So it is thus impossible / very difficult to use it with
>>> >> all
>>> >>> package them used in the calculation
>>> >>>
>>> >>> Our idea is to develop one packages global, simple, who would
>>> >> allow to
>>> >>> identify all the errors, warning, message generated by the
>>> >> functions
>>> >>> stop(), warning() and message() stop as well as by signals and
>>> >>> internally code, with log levels configurable later by package,
>>> >>> functions...
>>> >>>
>>> >>> One way is to overwrite temporarily the functions stop(),
>>> >> warning() and
>>> >>> message() of base package, but I think is not a good thing, and
>>> >>> furthermore, we lose all signals and internally "message"...
>>> >>>
>>> >>> A good use of options(error) seems to do the perfect job, but
>>> >> only for
>>> >>> error...
>>> >>>
>>> >>> Our problem / question :
>>> >>> - At present, how it is possible to have the same features for
>>> >> messages
>>> >>> and warnings? (like options(errors)) (I don't find...)
>>> >>> - Would new options be possible in a near future R ?
>>> >>> - Have there better / other possibilities to handle all the
>>> >> warnings,
>>> >>> message of the way which we wish?
>>> >>>
>>> >>
>>> >> ??withCallingHandlers() lets you evaluate expressions with code
>>> >> to catch
>>> >> messages, warnings and errors.
>>> >
>>> > That's exactly what I'm using in "pander::evals" to capture all
>>> > error/warning/normal messages while evaluating an R command, and to
>>> > also capture the results (as R objects), stdout and the printed
>>> > version of the object -- which might be useful in a custom
>>> > environment. E.g. I use this function to evaluate all R chunks in
>>> > markdown document and also to store all R messages run at the
>>> > rapporter.net [2] API. Please let me know if anyone is interested, and
>>> > I will start cleaning up the related codebase and publish on GH --
>>> > although "pander" and "evals" is already
>>> > there: https://github.com/Rapporter/pander [3]
>>> >
>>> > Quick demo: http://pastebin.com/jCUkgKim [4]
>>> >
>>> >
>>> >> I don't know if there's a way to evaluate every expression entered
>>> >> at
>>> >> the console within withCallingHandlers() for an effect like
>>> >> options(error=), but you can certainly write code to read a file
>>> >> and
>>> >> evaluate every expression in it within a withCallingHandlers()
>>> >> call.
>>> >>
>>> >> Duncan Murdoch
>>> >>
>>> >>> Hope is clear. Open to any suggestions.
>>> >>>
>>> >>> Thank you in advance
>>> >>>
>>> >>
>>> >> ______________________________________________
>>> >> R-devel at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>>> >
>>> >
>>> >
>>> > Links:
>>> > ------
>>> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>>> > [2] http://rapporter.net
>>> > [3] https://github.com/Rapporter/pander
>>> > [4] http://pastebin.com/jCUkgKim
>>>
>
> --
> Benoit Thieurmel
> +33 6 69 04 06 11
>
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
>
>
>
> ------------------------------
>
> Message: 8
> Date: Tue, 07 Oct 2014 10:51:44 -0400
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: "DataK - B. THIEURMEL" <bt at datak.fr>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <5433FE00.3090605 at gmail.com>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
>> OK, thank you for your answers. We are thus going to continue by
>> analyzing these features
>
> The general outline would be this:
>
> 1.  Call parse() on the whole file.  This will catch any syntax errors.
> If it parses okay, you'll get a vector of expressions to evaluate.
>
> 2.  Evaluate each expression in sequence within withCallingHandlers().
> You need to decide what to do if you get an error(); source() would quit
> the script at that point, so that's probably a good idea.
>
> Duncan Murdoch
>>
>> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
>> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
>> >> interesting, but little adapted to the analysis of one or several
>> >> scripts R / of many lines of code. Our goal is one packages requiring
>> >> no
>> >> modifications of code R to be able to get back all the desired
>> >> information.
>> >>
>> >> Is-there a hope in seeing R core team adding two options warn and
>> >> message with the same features as options(error) ? Or if we try (and
>> >> succeed) to code a patch for it, to see it integrating in R ?
>> >
>> > No, I don't think so.  withCallingHandlers is all you need for your
>> > purpose.
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >> I think that it would be very useful.
>> >>
>> >> Benoit
>> >>
>> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>> >> > <murdoch.duncan at gmail.com> wrote:
>> >> >
>> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>> >> >>> Hi,
>> >> >>>
>> >> >>> With the use of R in production, it is necessary to have a system
>> >> >> of
>> >> >>> logs effective, and light.
>> >> >>>
>> >> >>> Package exist as to futile.logger, but it require the additional
>> >> >> coding
>> >> >>> of logs. So it is thus impossible / very difficult to use it with
>> >> >> all
>> >> >>> package them used in the calculation
>> >> >>>
>> >> >>> Our idea is to develop one packages global, simple, who would
>> >> >> allow to
>> >> >>> identify all the errors, warning, message generated by the
>> >> >> functions
>> >> >>> stop(), warning() and message() stop as well as by signals and
>> >> >>> internally code, with log levels configurable later by package,
>> >> >>> functions...
>> >> >>>
>> >> >>> One way is to overwrite temporarily the functions stop(),
>> >> >> warning() and
>> >> >>> message() of base package, but I think is not a good thing, and
>> >> >>> furthermore, we lose all signals and internally "message"...
>> >> >>>
>> >> >>> A good use of options(error) seems to do the perfect job, but
>> >> >> only for
>> >> >>> error...
>> >> >>>
>> >> >>> Our problem / question :
>> >> >>> - At present, how it is possible to have the same features for
>> >> >> messages
>> >> >>> and warnings? (like options(errors)) (I don't find...)
>> >> >>> - Would new options be possible in a near future R ?
>> >> >>> - Have there better / other possibilities to handle all the
>> >> >> warnings,
>> >> >>> message of the way which we wish?
>> >> >>>
>> >> >>
>> >> >> ??withCallingHandlers() lets you evaluate expressions with code
>> >> >> to catch
>> >> >> messages, warnings and errors.
>> >> >
>> >> > That's exactly what I'm using in "pander::evals" to capture all
>> >> > error/warning/normal messages while evaluating an R command, and to
>> >> > also capture the results (as R objects), stdout and the printed
>> >> > version of the object -- which might be useful in a custom
>> >> > environment. E.g. I use this function to evaluate all R chunks in
>> >> > markdown document and also to store all R messages run at the
>> >> > rapporter.net [2] API. Please let me know if anyone is interested, and
>> >> > I will start cleaning up the related codebase and publish on GH --
>> >> > although "pander" and "evals" is already
>> >> > there: https://github.com/Rapporter/pander [3]
>> >> >
>> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
>> >> >
>> >> >
>> >> >> I don't know if there's a way to evaluate every expression entered
>> >> >> at
>> >> >> the console within withCallingHandlers() for an effect like
>> >> >> options(error=), but you can certainly write code to read a file
>> >> >> and
>> >> >> evaluate every expression in it within a withCallingHandlers()
>> >> >> call.
>> >> >>
>> >> >> Duncan Murdoch
>> >> >>
>> >> >>> Hope is clear. Open to any suggestions.
>> >> >>>
>> >> >>> Thank you in advance
>> >> >>>
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-devel at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>> >> >
>> >> >
>> >> >
>> >> > Links:
>> >> > ------
>> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> > [2] http://rapporter.net
>> >> > [3] https://github.com/Rapporter/pander
>> >> > [4] http://pastebin.com/jCUkgKim
>> >>
>>
>
>
>
> ------------------------------
>
> Message: 9
> Date: Tue, 07 Oct 2014 17:11:08 +0200
> From: "DataK - B. THIEURMEL" <bt at datak.fr>
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID: <a5c4d7cbc69d368488567170490b8e2d at datak.fr>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> Do you think there is a way to apply a "global" withCallingHandlers() on
> all environement / packages loaded, and then all R code will be executed
> with the defined handler ? With this way, we can define what we want for
> warning, message, error, ... one time, and apply it without needed of
> parse() or added withCallingHandlers in initial code...
>
> Something like this :
>
> withCallingHandlersGlobal <- function(...) {
>    handlers <- list(...)
>    classes <- names(handlers)
>    parentenv <- all.environment
>    if (length(classes) != length(handlers))
>      stop("bad handler specification")
>    .Internal(.addCondHands(classes, handlers, parentenv, NULL, TRUE))
> }
>
> withCallingHandlersGlobal(warning = function(w) {print("Global
> handler")})
>
> warning("A")
>> "Global handler"
> rnorm("A")
>> "Global handler"
>
>
>
> Le 2014-10-07 16:51, Duncan Murdoch a ?crit?:
>> On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
>>> OK, thank you for your answers. We are thus going to continue by
>>> analyzing these features
>>
>> The general outline would be this:
>>
>> 1.  Call parse() on the whole file.  This will catch any syntax
>> errors.  If it parses okay, you'll get a vector of expressions to
>> evaluate.
>>
>> 2.  Evaluate each expression in sequence within withCallingHandlers().
>>  You need to decide what to do if you get an error(); source() would
>> quit the script at that point, so that's probably a good idea.
>>
>> Duncan Murdoch
>>>
>>> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
>>> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>>> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
>>> >> interesting, but little adapted to the analysis of one or several
>>> >> scripts R / of many lines of code. Our goal is one packages requiring
>>> >> no
>>> >> modifications of code R to be able to get back all the desired
>>> >> information.
>>> >>
>>> >> Is-there a hope in seeing R core team adding two options warn and
>>> >> message with the same features as options(error) ? Or if we try (and
>>> >> succeed) to code a patch for it, to see it integrating in R ?
>>> >
>>> > No, I don't think so.  withCallingHandlers is all you need for your
>>> > purpose.
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>
>>> >> I think that it would be very useful.
>>> >>
>>> >> Benoit
>>> >>
>>> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>>> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>>> >> > <murdoch.duncan at gmail.com> wrote:
>>> >> >
>>> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>> >> >>> Hi,
>>> >> >>>
>>> >> >>> With the use of R in production, it is necessary to have a system
>>> >> >> of
>>> >> >>> logs effective, and light.
>>> >> >>>
>>> >> >>> Package exist as to futile.logger, but it require the additional
>>> >> >> coding
>>> >> >>> of logs. So it is thus impossible / very difficult to use it with
>>> >> >> all
>>> >> >>> package them used in the calculation
>>> >> >>>
>>> >> >>> Our idea is to develop one packages global, simple, who would
>>> >> >> allow to
>>> >> >>> identify all the errors, warning, message generated by the
>>> >> >> functions
>>> >> >>> stop(), warning() and message() stop as well as by signals and
>>> >> >>> internally code, with log levels configurable later by package,
>>> >> >>> functions...
>>> >> >>>
>>> >> >>> One way is to overwrite temporarily the functions stop(),
>>> >> >> warning() and
>>> >> >>> message() of base package, but I think is not a good thing, and
>>> >> >>> furthermore, we lose all signals and internally "message"...
>>> >> >>>
>>> >> >>> A good use of options(error) seems to do the perfect job, but
>>> >> >> only for
>>> >> >>> error...
>>> >> >>>
>>> >> >>> Our problem / question :
>>> >> >>> - At present, how it is possible to have the same features for
>>> >> >> messages
>>> >> >>> and warnings? (like options(errors)) (I don't find...)
>>> >> >>> - Would new options be possible in a near future R ?
>>> >> >>> - Have there better / other possibilities to handle all the
>>> >> >> warnings,
>>> >> >>> message of the way which we wish?
>>> >> >>>
>>> >> >>
>>> >> >> ??withCallingHandlers() lets you evaluate expressions with code
>>> >> >> to catch
>>> >> >> messages, warnings and errors.
>>> >> >
>>> >> > That's exactly what I'm using in "pander::evals" to capture all
>>> >> > error/warning/normal messages while evaluating an R command, and to
>>> >> > also capture the results (as R objects), stdout and the printed
>>> >> > version of the object -- which might be useful in a custom
>>> >> > environment. E.g. I use this function to evaluate all R chunks in
>>> >> > markdown document and also to store all R messages run at the
>>> >> > rapporter.net [2] API. Please let me know if anyone is interested, and
>>> >> > I will start cleaning up the related codebase and publish on GH --
>>> >> > although "pander" and "evals" is already
>>> >> > there: https://github.com/Rapporter/pander [3]
>>> >> >
>>> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
>>> >> >
>>> >> >
>>> >> >> I don't know if there's a way to evaluate every expression entered
>>> >> >> at
>>> >> >> the console within withCallingHandlers() for an effect like
>>> >> >> options(error=), but you can certainly write code to read a file
>>> >> >> and
>>> >> >> evaluate every expression in it within a withCallingHandlers()
>>> >> >> call.
>>> >> >>
>>> >> >> Duncan Murdoch
>>> >> >>
>>> >> >>> Hope is clear. Open to any suggestions.
>>> >> >>>
>>> >> >>> Thank you in advance
>>> >> >>>
>>> >> >>
>>> >> >> ______________________________________________
>>> >> >> R-devel at r-project.org mailing list
>>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>>> >> >
>>> >> >
>>> >> >
>>> >> > Links:
>>> >> > ------
>>> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >> > [2] http://rapporter.net
>>> >> > [3] https://github.com/Rapporter/pander
>>> >> > [4] http://pastebin.com/jCUkgKim
>>> >>
>>>
>
> --
> Benoit Thieurmel
> +33 6 69 04 06 11
>
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
>
>
>
> ------------------------------
>
> Message: 10
> Date: Tue, 7 Oct 2014 18:05:03 +0200
> From: Gergely Dar?czi <daroczig at rapporter.net>
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] [R logs] Help in develop a simply logs package
> Message-ID:
>         <CAPvvxJX-cs7se4cicZ+BZyzPbAL02OmQq-z662e=ad74+uxNfQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> On Tue, Oct 7, 2014 at 4:51 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 07/10/2014 10:41 AM, DataK - B. THIEURMEL wrote:
>>
>>> OK, thank you for your answers. We are thus going to continue by
>>> analyzing these features
>>>
>>
>> The general outline would be this:
>>
>> 1.  Call parse() on the whole file.  This will catch any syntax errors.
>> If it parses okay, you'll get a vector of expressions to evaluate.
>>
>> 2.  Evaluate each expression in sequence within withCallingHandlers().
>> You need to decide what to do if you get an error(); source() would quit
>> the script at that point, so that's probably a good idea.
>
>
> Quick demo with "pander::evals":
> https://gist.github.com/daroczig/480af8ad766e96dd25f4
>
>
>>
>>
>> Duncan Murdoch
>>
>>
>>> Le 2014-10-07 16:29, Duncan Murdoch a ?crit :
>>> > On 07/10/2014 10:16 AM, DataK - B. THIEURMEL wrote:
>>> >> Thank. withCallingHandlers() and "pander::evals" seem to be very
>>> >> interesting, but little adapted to the analysis of one or several
>>> >> scripts R / of many lines of code. Our goal is one packages requiring
>>> >> no
>>> >> modifications of code R to be able to get back all the desired
>>> >> information.
>>> >>
>>> >> Is-there a hope in seeing R core team adding two options warn and
>>> >> message with the same features as options(error) ? Or if we try (and
>>> >> succeed) to code a patch for it, to see it integrating in R ?
>>> >
>>> > No, I don't think so.  withCallingHandlers is all you need for your
>>> > purpose.
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>
>>> >> I think that it would be very useful.
>>> >>
>>> >> Benoit
>>> >>
>>> >> Le 2014-10-07 14:38, Gergely Dar?czi a ?crit :
>>> >> > On Tue, Oct 7, 2014 at 2:21 PM, Duncan Murdoch
>>> >> > <murdoch.duncan at gmail.com> wrote:
>>> >> >
>>> >> >> On 07/10/2014, 7:04 AM, DataK - B. THIEURMEL wrote:
>>> >> >>> Hi,
>>> >> >>>
>>> >> >>> With the use of R in production, it is necessary to have a system
>>> >> >> of
>>> >> >>> logs effective, and light.
>>> >> >>>
>>> >> >>> Package exist as to futile.logger, but it require the additional
>>> >> >> coding
>>> >> >>> of logs. So it is thus impossible / very difficult to use it with
>>> >> >> all
>>> >> >>> package them used in the calculation
>>> >> >>>
>>> >> >>> Our idea is to develop one packages global, simple, who would
>>> >> >> allow to
>>> >> >>> identify all the errors, warning, message generated by the
>>> >> >> functions
>>> >> >>> stop(), warning() and message() stop as well as by signals and
>>> >> >>> internally code, with log levels configurable later by package,
>>> >> >>> functions...
>>> >> >>>
>>> >> >>> One way is to overwrite temporarily the functions stop(),
>>> >> >> warning() and
>>> >> >>> message() of base package, but I think is not a good thing, and
>>> >> >>> furthermore, we lose all signals and internally "message"...
>>> >> >>>
>>> >> >>> A good use of options(error) seems to do the perfect job, but
>>> >> >> only for
>>> >> >>> error...
>>> >> >>>
>>> >> >>> Our problem / question :
>>> >> >>> - At present, how it is possible to have the same features for
>>> >> >> messages
>>> >> >>> and warnings? (like options(errors)) (I don't find...)
>>> >> >>> - Would new options be possible in a near future R ?
>>> >> >>> - Have there better / other possibilities to handle all the
>>> >> >> warnings,
>>> >> >>> message of the way which we wish?
>>> >> >>>
>>> >> >>
>>> >> >> ??withCallingHandlers() lets you evaluate expressions with code
>>> >> >> to catch
>>> >> >> messages, warnings and errors.
>>> >> >
>>> >> > That's exactly what I'm using in "pander::evals" to capture all
>>> >> > error/warning/normal messages while evaluating an R command, and to
>>> >> > also capture the results (as R objects), stdout and the printed
>>> >> > version of the object -- which might be useful in a custom
>>> >> > environment. E.g. I use this function to evaluate all R chunks in
>>> >> > markdown document and also to store all R messages run at the
>>> >> > rapporter.net [2] API. Please let me know if anyone is interested,
>>> and
>>> >> > I will start cleaning up the related codebase and publish on GH --
>>> >> > although "pander" and "evals" is already
>>> >> > there: https://github.com/Rapporter/pander [3]
>>> >> >
>>> >> > Quick demo: http://pastebin.com/jCUkgKim [4]
>>> >> >
>>> >> >
>>> >> >> I don't know if there's a way to evaluate every expression entered
>>> >> >> at
>>> >> >> the console within withCallingHandlers() for an effect like
>>> >> >> options(error=), but you can certainly write code to read a file
>>> >> >> and
>>> >> >> evaluate every expression in it within a withCallingHandlers()
>>> >> >> call.
>>> >> >>
>>> >> >> Duncan Murdoch
>>> >> >>
>>> >> >>> Hope is clear. Open to any suggestions.
>>> >> >>>
>>> >> >>> Thank you in advance
>>> >> >>>
>>> >> >>
>>> >> >> ______________________________________________
>>> >> >> R-devel at r-project.org mailing list
>>> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel [1]
>>> >> >
>>> >> >
>>> >> >
>>> >> > Links:
>>> >> > ------
>>> >> > [1] https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >> > [2] http://rapporter.net
>>> >> > [3] https://github.com/Rapporter/pander
>>> >> > [4] http://pastebin.com/jCUkgKim
>>> >>
>>>
>>>
>>


From qk at st-andrews.ac.uk  Wed Oct  8 18:57:12 2014
From: qk at st-andrews.ac.uk (Qiao Kang)
Date: Wed, 8 Oct 2014 17:57:12 +0100
Subject: [Rd] RCMD SHLIB problem in 64 bits
Message-ID: <CAGKjpr6bZ7UpDnaVwY-i5wxc5c9KQXju4pvodXD1EUcaOgTkbw@mail.gmail.com>

I am trying to build a dll writen in C to be called by R.

Interestingly, when I set the global environment variable PATH to be
"c:\Rtools\bin;C:\Rtools\gcc-4.6.3;C:\Program Files\R\R-3.1.1\bin\*i386*;"
and I typed "RCMD SHLIB Permutation.c" in Cygwin, the dll was compiled and
I can sucessfully call functions after I had loaded it into 32 bits R via
.Call.

However,  now I want to run the same function in 64 bits R. I changed
the global environment variable PATH to be
"c:\Rtools\bin;C:\Rtools\gcc-4.6.3;C:\Program Files\R\R-3.1.1\bin\*x64*;",
opened Cygwin again and typed "RCMD SHLIB Permutation.c" in Cygwin. Error
message appeared on Cywin console.

$ RCMD SHLIB Permutation.c
gcc -m64 -shared -s -static-libgcc -o Permutation.dll tmp.def Permutation.o
-Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64
-Ld:/RCompile/CRANpkg/extralibs64/local/lib
-LC:/PROGRA~1/R/R-31~1.1/bin/x64 -lR
C:/PROGRA~1/R/R-31~1.1/bin/x64/R.dll: file not recognized:

My version of R is the latest 3.1.1 and my Rtools is also the latest
version 31

I am not sure why this is happening and I have been struggled about this
for two days.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Oct  8 20:17:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Oct 2014 14:17:51 -0400
Subject: [Rd] RCMD SHLIB problem in 64 bits
In-Reply-To: <CAGKjpr6bZ7UpDnaVwY-i5wxc5c9KQXju4pvodXD1EUcaOgTkbw@mail.gmail.com>
References: <CAGKjpr6bZ7UpDnaVwY-i5wxc5c9KQXju4pvodXD1EUcaOgTkbw@mail.gmail.com>
Message-ID: <54357FCF.3050200@gmail.com>

On 08/10/2014, 12:57 PM, Qiao Kang wrote:
> I am trying to build a dll writen in C to be called by R.
> 
> Interestingly, when I set the global environment variable PATH to be
> "c:\Rtools\bin;C:\Rtools\gcc-4.6.3;C:\Program Files\R\R-3.1.1\bin\*i386*;"
> and I typed "RCMD SHLIB Permutation.c" in Cygwin, the dll was compiled and
> I can sucessfully call functions after I had loaded it into 32 bits R via
> .Call.
> 
> However,  now I want to run the same function in 64 bits R. I changed
> the global environment variable PATH to be
> "c:\Rtools\bin;C:\Rtools\gcc-4.6.3;C:\Program Files\R\R-3.1.1\bin\*x64*;",
> opened Cygwin again and typed "RCMD SHLIB Permutation.c" in Cygwin. Error
> message appeared on Cywin console.
> 
> $ RCMD SHLIB Permutation.c
> gcc -m64 -shared -s -static-libgcc -o Permutation.dll tmp.def Permutation.o
> -Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64
> -Ld:/RCompile/CRANpkg/extralibs64/local/lib
> -LC:/PROGRA~1/R/R-31~1.1/bin/x64 -lR
> C:/PROGRA~1/R/R-31~1.1/bin/x64/R.dll: file not recognized:
> 
> My version of R is the latest 3.1.1 and my Rtools is also the latest
> version 31
> 
> I am not sure why this is happening and I have been struggled about this
> for two days.

This sounds related to a bug that is fixed in R-patched.  Some of the
build scripts use the bin/R or bin/Rscript executables; they are 32 bit
only.

Could you please download a recent R-patched, and confirm that the fix
works for you?

Thanks.

Duncan Murdoch


From daroczig at rapporter.net  Wed Oct  8 21:28:07 2014
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Wed, 8 Oct 2014 21:28:07 +0200
Subject: [Rd] Open Software License v. 3.0
Message-ID: <CAPvvxJXq1-ukrH4Qexx2Uh0b_70EzfCVSNiy5RWKgJaVG2KOrg@mail.gmail.com>

Dear All,

I would like to propose adding the OSL-3.0 license to the list of
"standard" licenses bundled with R:

Index: share/licenses/license.db
===================================================================
--- share/licenses/license.db (revision 66733)
+++ share/licenses/license.db (working copy)
@@ -317,3 +317,12 @@
 URL: http://www.acm.org/publications/policies/softwarecrnotice
 FOSS: no
 Restricts_use: yes
+
+Name: Open Software License
+Abbrev: OSL
+Version: 3.0
+SSS: OSL-3.0
+FSF: free_and_GPLv3_incompatible (
http://www.gnu.org/licenses/license-list.html#OSL)
+OSI: open (http://opensource.org/licenses/OSL-3.0)
+URL: http://rosenlaw.com/pdf-files/OSL3.0-comparison.pdf
+FOSS: yes

The great advantage of OSL is that it's similar to AGPL in the means of
requesting the derivative works to be published with an open source license
even if the program is not distributed, only used in a network service --
which is more and more common nowadays.

But AGPL is not supported by bunch of companies (like Google) due to that
license might seem too restrictive with "linked programs": some lawyers say
that any program including AGPL software should be released with AGPL
license -- which is non-sense of course, but OSL request to publish only
those updates, that are related to the original work -- so thus this is a
not neater solution, and also supporter by e.g. Google.

Thanks for considering this.

Best,
Gergely
-------------- next part --------------
Index: share/licenses/license.db
===================================================================
--- share/licenses/license.db	(revision 66733)
+++ share/licenses/license.db	(working copy)
@@ -317,3 +317,12 @@
 URL: http://www.acm.org/publications/policies/softwarecrnotice
 FOSS: no
 Restricts_use: yes
+
+Name: Open Software License
+Abbrev: OSL
+Version: 3.0
+SSS: OSL-3.0
+FSF: free_and_GPLv3_incompatible (http://www.gnu.org/licenses/license-list.html#OSL)
+OSI: open (http://opensource.org/licenses/OSL-3.0)
+URL: http://rosenlaw.com/pdf-files/OSL3.0-comparison.pdf
+FOSS: yes

From izmirlig at mail.nih.gov  Thu Oct  9 19:24:52 2014
From: izmirlig at mail.nih.gov (izmirlig)
Date: Thu, 9 Oct 2014 10:24:52 -0700 (PDT)
Subject: [Rd] can someone help me understand LAM/MPI and Rmpi for use on
 a cluster
In-Reply-To: <6ph3bk5yvrr.fsf@gopher3.fhcrc.org>
References: <CE0E73903DB53F43B4B0938747F34F8A01242D08@nihexchange7.nih.gov>
	<6ph3bk5yvrr.fsf@gopher3.fhcrc.org>
Message-ID: <1412875492607-4698132.post@n4.nabble.com>

Thank you! Very Helpful indeed



--
View this message in context: http://r.789695.n4.nabble.com/can-someone-help-me-understand-LAM-MPI-and-Rmpi-for-use-on-a-cluster-tp909189p4698132.html
Sent from the R devel mailing list archive at Nabble.com.


From skostysh at princeton.edu  Sun Oct 12 07:11:56 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sun, 12 Oct 2014 01:11:56 -0400
Subject: [Rd] Turn warnings or notes into errors on CMD check ?
Message-ID: <CAE3=dmdubEvKOfSjZ_YQ2MN_BNaEux6vK9RVBLCQW7KosdkM0Q@mail.gmail.com>

Hi,

I am using a local patch to have CMD check exit with error if there is
a note or warning. Am I missing an already existing way to do this?

If not, Is there any interest in having an option or environment
variable for this upstream? I would be interested in making a patch.
If so, option or environment variable? Any suggestions for the name?
Should this be two options or one option with "1" means only turn
warnings into errors and "2" means turn both warnings and notes into
errors?

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From h.wickham at gmail.com  Sun Oct 12 16:44:17 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 12 Oct 2014 09:44:17 -0500
Subject: [Rd] Turn warnings or notes into errors on CMD check ?
In-Reply-To: <CAE3=dmdubEvKOfSjZ_YQ2MN_BNaEux6vK9RVBLCQW7KosdkM0Q@mail.gmail.com>
References: <CAE3=dmdubEvKOfSjZ_YQ2MN_BNaEux6vK9RVBLCQW7KosdkM0Q@mail.gmail.com>
Message-ID: <CABdHhvGthxSWuDp60L=Qtks+1HxwHE5k=7G5jOVHWiyBQkGNDg@mail.gmail.com>

And maybe turning warnings into errors should be the default for --as-cran?

Hadley

On Sun, Oct 12, 2014 at 12:11 AM, Scott Kostyshak
<skostysh at princeton.edu> wrote:
> Hi,
>
> I am using a local patch to have CMD check exit with error if there is
> a note or warning. Am I missing an already existing way to do this?
>
> If not, Is there any interest in having an option or environment
> variable for this upstream? I would be interested in making a patch.
> If so, option or environment variable? Any suggestions for the name?
> Should this be two options or one option with "1" means only turn
> warnings into errors and "2" means turn both warnings and notes into
> errors?
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From musically.ut at gmail.com  Sun Oct 12 17:13:10 2014
From: musically.ut at gmail.com (Utkarsh Upadhyay)
Date: Sun, 12 Oct 2014 17:13:10 +0200
Subject: [Rd] Is this an incorrect use of the R-API?
Message-ID: <CALh3q9yLnnN8fs5Jq0LKU8D5pKh6ZDe5EDbUS2YYiMbh+-6LDA@mail.gmail.com>

Hi,

I am trying to create a small extension for R here for embedding the
current time on the R prompt: https://github.com/musically-ut/extPrompt

Things seem to be working overall, but `R CMD check .` raised a warning:

> File '[truncated]..Rcheck/extPrompt/libs/extPrompt.so?:
>  Found non-API call to R: ?ptr_R_ReadConsole?
>
> Compiled code should not call non-API entry points in R.

The concerned file is this:
https://github.com/musically-ut/extPrompt/blob/master/src/extPrompt.c and
occurs on line 38, I think [1].

I am trying to make the R_ReadConsole API call. However, since a different
plugin (like mine) could have overridden it already, I do not want to
directly invoke `R_ReadConsole` but the function which previously was at
`ptr_R_ReadConsole`.

Is this an incorrect use of the API?

Thanks!

Best Regards,
Utkarsh Upadhyay
http://musicallyut.in

[1]: I am impressed at how well the static code analysis works for R CMD
check.

	[[alternative HTML version deleted]]


From dtemplelang at ucdavis.edu  Sun Oct 12 21:45:24 2014
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Sun, 12 Oct 2014 12:45:24 -0700
Subject: [Rd] Is this an incorrect use of the R-API?
In-Reply-To: <CALh3q9yLnnN8fs5Jq0LKU8D5pKh6ZDe5EDbUS2YYiMbh+-6LDA@mail.gmail.com>
References: <CALh3q9yLnnN8fs5Jq0LKU8D5pKh6ZDe5EDbUS2YYiMbh+-6LDA@mail.gmail.com>
Message-ID: <543ADA54.2090809@ucdavis.edu>

Hi Utkarsh

 If the package is an experiment and exploration, great - good for you 
 getting into this level of detail.
 However, if your goal is to get the dynamic prompt, a simpler mechanism
 that is almost equivalent is the R code

 invisible(addTaskCallback(function(...) { 
                             options(prompt = format(Sys.time(), "[%H:%M:%S] >"))
                             TRUE
                           }))

  The only difference is that when you hit return at the prompt with no expression,
  the prompt doesn't change (since there was no task).


  As for incorrectly using the API - yes. Since R CMD check is telling you this is a
  problem, it is officially a problem. This is of no consequence if the package works for you and any
  users of it, and the package is not to be hosted on CRAN. However, using this symbol in your code may not 
  work on all platforms, and is not guaranteed to work in the future (but probably will!). 

   D.
   

On 10/12/14, 8:13 AM, Utkarsh Upadhyay wrote:
> Hi,
> 
> I am trying to create a small extension for R here for embedding the
> current time on the R prompt: https://github.com/musically-ut/extPrompt
> 
> Things seem to be working overall, but `R CMD check .` raised a warning:
> 
>> File '[truncated]..Rcheck/extPrompt/libs/extPrompt.so?:
>>  Found non-API call to R: ?ptr_R_ReadConsole?
>>
>> Compiled code should not call non-API entry points in R.
> 
> The concerned file is this:
> https://github.com/musically-ut/extPrompt/blob/master/src/extPrompt.c and
> occurs on line 38, I think [1].
> 
> I am trying to make the R_ReadConsole API call. However, since a different
> plugin (like mine) could have overridden it already, I do not want to
> directly invoke `R_ReadConsole` but the function which previously was at
> `ptr_R_ReadConsole`.
> 
> Is this an incorrect use of the API?
> 
> Thanks!
> 
> Best Regards,
> Utkarsh Upadhyay
> http://musicallyut.in
> 
> [1]: I am impressed at how well the static code analysis works for R CMD
> check.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Mon Oct 13 16:34:49 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 13 Oct 2014 10:34:49 -0400
Subject: [Rd] [R logs] Help in develop a simply logs package
In-Reply-To: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
References: <4726f6636a227512e8a3ec4ae1562e73@datak.fr>
Message-ID: <17476C12-88F7-42B3-A9BF-7D2F3D8312D4@r-project.org>

On Oct 7, 2014, at 7:04 AM, DataK - B. THIEURMEL <bt at datak.fr> wrote:
> 
> Hi,
> 
> With the use of R in production, it is necessary to have a system of logs effective, and light.
> 
> Package exist as to futile.logger, but it require the additional coding of logs. So it is thus impossible / very difficult to use it with all package them used in the calculation
> 
> Our idea is to develop one packages global, simple, who would allow to identify all the errors, warning, message generated by the functions stop(), warning() and message() stop as well as by signals and internally code, with log levels configurable later by package, functions...
> 
> One way is to overwrite temporarily the functions stop(), warning() and message() of base package, but I think is not a good thing, and furthermore, we lose all signals and internally "message"...
> 
> A good use of options(error) seems to do the perfect job, but only for error...
> 
> Our problem / question :
> - At present, how it is possible to have the same features for messages and warnings? (like options(errors)) (I don't find...)
> - Would new options be possible in a near future R ?
> - Have there better / other possibilities to handle all the warnings, message of the way which we wish?
> 
> Hope is clear. Open to any suggestions.
> 

It really depends on what you're after. If you really mean log as in recording errors/message that go to the console the you can use the console interface API to override WriteConsole and ShowMessage to tie the messages to another place in addition to printing it out. But what is feasible really depends on how you run R in the first place (and on which OS).

Cheers,
Simon


> Thank you in advance
> 
> -- 
> Benoit Thieurmel
> +33 6 69 04 06 11
> 
> DataKnowledge
> 46 rue Amsterdam - 75009 Paris
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From maechler at stat.math.ethz.ch  Mon Oct 13 17:39:20 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 13 Oct 2014 17:39:20 +0200
Subject: [Rd] debuggingState() analogous to tracingState() ?
In-Reply-To: <CAAU5OYB+f3RUvEDqWFodTE6cVVp0+urzGhn2qSUo5h67eKunHw@mail.gmail.com>
References: <CAPRP4-f2d_u90HQqzY5660xqC3ZKMG4ZmEnsFCRY9LB_W98TFg@mail.gmail.com>
	<21549.6213.346772.105674@stat.math.ethz.ch>
	<542D1DAC.4090809@gmail.com>
	<21549.10935.269659.495307@stat.math.ethz.ch>
	<542D34C6.2040301@gmail.com>
	<21549.26470.777198.46400@stat.math.ethz.ch>
	<CAAU5OYB+f3RUvEDqWFodTE6cVVp0+urzGhn2qSUo5h67eKunHw@mail.gmail.com>
Message-ID: <21563.61992.897793.116275@stat.math.ethz.ch>

I'm taking up an open strand ...

>>>>> Jonathan McPherson <jonathan at rstudio.com>
>>>>>     on Thu, 2 Oct 2014 10:56:01 -0700 writes:

    >> 
    >> > I don't have much of an opinion on these questions.
    >> I've never used the > tracingState() function, though I
    >> use trace() all the time (via > setBreakpoint()).  You
    >> might want to consult people who write debugger >
    >> front-ends.
    >> 
    >> which I am now doing: I'm including ESS-core, Jonathan
    >> (RStudio) and Tobias (StatET) which Duncan mentioned as
    >> being interested and having asked for better debugging
    >> support functionality in the past, such as
    >> 
    >> 
    > Some observations from RStudio which may or may not be
    > helpful:

    > We don't expose any UI that allows the user to modify
    > tracingState(). In fact, turning off tracingState() will
    > make RStudio's breakpoints stop working (as they rely on
    > trace()), without any warning or feedback from the
    > UI. We've never received complaints about this, and so my
    > presumption is that very few people need to turn off
    > tracing globally, and those who do know what they're doing
    > and/or aren't using the IDE debugging features.

    > Some mechanism for globally altering debugging state would
    > be very useful.  Right now we have a problem wherein
    > during debugging the R functions RStudio calls to
    > e.g. analyze and compose the list of objects in the
    > workspace are themselves debugged. Today we're solving
    > this by manually tripping the RDEBUG flag on an
    > environment before we evaluate expressions in it, which I
    > think we can all agree is less than ideal.

    > Do you foresee any non-interactive use for
    > debuggingState()? If so, it might be nice if the state had
    > push/pop rather than on/off semantics, to make the pattern
    > of disabling locally easier to express.

    >> the ability to add a breakpoint to a function that is
    >> currently being evaluated.

    > Yes, this would be useful to us, although unless I'm
    > missing something it seems pretty orthogonal to the rest
    > of the thread. It's not a common feature request.

You are right, that it seems pretty orthogonal to me, too.

    > One thing that would be useful is some officially
    > supported way to debug during source(). Lots of people
    > don't use functions and just have R scripts full of
    > straight-line statements (sometimes containing references
    > to other code via source()). RStudio will let you set
    > breakpoints on top-level statements, and this has proven
    > to be a popular feature, but its implementation is very
    > messy--we effectively create a function from the
    > statements in the file and then use the function debugger,
    > which works for simple scenarios but starts falling apart
    > if you do anything complicated.

Yes, that's yet another interesting idea...
though I'm still overly optimistically assuming that we can educate
users to use functions much more often, also as simple vehicles
and to debug them..  

Thank you, Jonathan, and the other commenters.
My main question (probably buried in too many other musings and statements)
about a good (function-based) UI for different kinds of
debuggingState()s has not been addressed and by any one, so I
assume that did not seem interesting enough and not worth
bothering complicating the interface.

I've finally committed  [to R-devel only]
what I had and looks working fine to me.  With a simple 
"on/off" switch only:

------------------------------------------------------------------------
r66751 | maechler | 2014-10-13 16:57:02 +0200 (Mon, 13 Oct 2014) | 1 line
Changed paths:
   M doc/NEWS.Rd
   M src/include/Defn.h
   M src/library/base/R/debug.R
   M src/library/base/man/debug.Rd
   M src/library/base/man/trace.Rd
   M src/main/debug.c
   M src/main/eval.c
   M src/main/names.c
   M src/main/objects.c

new debuggingState() - possibly to be tweaked
------------------------------------------------------------------------

This -- i.e. debuggingState(TRUE) -- does not (or *should* not)
influence the functioning of explicit browser() calls.

Currently it has an effect on debugonce() , not only on debug()
and this is something that I think should be changed,  but did
not easily see how [there are the RSTEP() vs RDEBUG() flags inside
the C code ...], and did not find too important for now.

Rather get the current proposal out, for you all to look and
hammer at ...

Martin


From shivali at ncmrwf.gov.in  Tue Oct 14 07:14:32 2014
From: shivali at ncmrwf.gov.in (shivali at ncmrwf.gov.in)
Date: Tue, 14 Oct 2014 10:44:32 +0530
Subject: [Rd] [Fwd: Re:  AIX-5.3 Issue installing Matrix Package]
Message-ID: <593612c62a3e91de06cf7cabf0924390.squirrel@mail.ncmrwf.gov.in>

Hi,
Please help.

Regards,
Shivali

---------------------------- Original Message ----------------------------
Subject: Re: [Rd] AIX-5.3 Issue installing Matrix Package
From:    shivali at mail.ncmrwf.gov.in
Date:    Wed, October 8, 2014 3:31 pm
To:      "Ei-ji Nakama" <nakama at ki.rim.or.jp>
Cc:      "Martin Maechler" <maechler at stat.math.ethz.ch>
         "R Development List" <r-devel at r-project.org>
--------------------------------------------------------------------------

Hi ,

Thanks, but i tried with bash also result is same -
Package Matrix facing issue while Loading  -
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`
Creating a generic function for 'qr.qty' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.coef' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.resid' from package 'base' in package
'Matrix'
Creating a generic function for 'qr.fitted' from package 'base' in package
'Matrix'
** help
*** installing help indices
** building package indices
Loading required package: Matrix              ==> Hanged up here
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~``



[ncmr0202][/gpfs1/home/shivali]> ps -ef | grep R-3.1.1
 shivali 413756 480210   0 12:49:03 pts/31  0:00 bash
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL
Matrix_1.1-4.tar.gz
 shivali 291478 413756 120 12:49:03 pts/31 146:54
/gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/exec/R --args --args --args
nextArgMatrix_1.1-4.tar.gz
 shivali 356902 254484   0 15:17:37 pts/24  0:00 grep R-3.1.1
[ncmr0202][/gpfs1/home/shivali]>

Regards,
Shivali Gangwar

> hi,
>
>>>     root 492034 336504   0 14:34:36 pts/11  0:00 sh
>>> /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix
>
> maybe sh running is not good.
> please install bash.
> CONFIG_SHELL=/boo/foo/bash before running `configure && make'.
>
> --
> Best Regards,
> --
> Eiji NAKAMA <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
>
> Email secured by Check Point
>




Email secured by Check Point


From nakama at ki.rim.or.jp  Tue Oct 14 09:15:21 2014
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Tue, 14 Oct 2014 16:15:21 +0900
Subject: [Rd] [Fwd: Re: AIX-5.3 Issue installing Matrix Package]
In-Reply-To: <593612c62a3e91de06cf7cabf0924390.squirrel@mail.ncmrwf.gov.in>
References: <593612c62a3e91de06cf7cabf0924390.squirrel@mail.ncmrwf.gov.in>
Message-ID: <CAJqeyYY_z75cEcpSut8z8J=YAy555RKHTmed=wA1iw8FoCSHsg@mail.gmail.com>

did you use and try gmake?
i have not AIX now ...
and all most know-how is written on R-Admin manuals.

2014-10-14 14:14 GMT+09:00  <shivali at ncmrwf.gov.in>:
> Hi,
> Please help.
>
> Regards,
> Shivali
>
> ---------------------------- Original Message ----------------------------
> Subject: Re: [Rd] AIX-5.3 Issue installing Matrix Package
> From:    shivali at mail.ncmrwf.gov.in
> Date:    Wed, October 8, 2014 3:31 pm
> To:      "Ei-ji Nakama" <nakama at ki.rim.or.jp>
> Cc:      "Martin Maechler" <maechler at stat.math.ethz.ch>
>          "R Development List" <r-devel at r-project.org>
> --------------------------------------------------------------------------
>
> Hi ,
>
> Thanks, but i tried with bash also result is same -
> Package Matrix facing issue while Loading  -
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`
> Creating a generic function for 'qr.qty' from package 'base' in package
> 'Matrix'
> Creating a generic function for 'qr.coef' from package 'base' in package
> 'Matrix'
> Creating a generic function for 'qr.resid' from package 'base' in package
> 'Matrix'
> Creating a generic function for 'qr.fitted' from package 'base' in package
> 'Matrix'
> ** help
> *** installing help indices
> ** building package indices
> Loading required package: Matrix              ==> Hanged up here
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~``
>
>
>
> [ncmr0202][/gpfs1/home/shivali]> ps -ef | grep R-3.1.1
>  shivali 413756 480210   0 12:49:03 pts/31  0:00 bash
> /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL
> Matrix_1.1-4.tar.gz
>  shivali 291478 413756 120 12:49:03 pts/31 146:54
> /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/exec/R --args --args --args
> nextArgMatrix_1.1-4.tar.gz
>  shivali 356902 254484   0 15:17:37 pts/24  0:00 grep R-3.1.1
> [ncmr0202][/gpfs1/home/shivali]>
>
> Regards,
> Shivali Gangwar
>
>> hi,
>>
>>>>     root 492034 336504   0 14:34:36 pts/11  0:00 sh
>>>> /gpfs1/home/shivali/gang/R-3.1.1/lib/R/bin/Rcmd INSTALL Matrix
>>
>> maybe sh running is not good.
>> please install bash.
>> CONFIG_SHELL=/boo/foo/bash before running `configure && make'.
>>
>> --
>> Best Regards,
>> --
>> Eiji NAKAMA <nakama (a) ki.rim.or.jp>
>> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
>>
>> Email secured by Check Point
>>
>
>
>
>
> Email secured by Check Point
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From gregridgeway at gmail.com  Wed Oct 15 16:11:14 2014
From: gregridgeway at gmail.com (Greg Ridgeway)
Date: Wed, 15 Oct 2014 10:11:14 -0400
Subject: [Rd] Advice on package design for handling of dots in a formula
Message-ID: <0b3f01cfe881$e3613ea0$aa23bbe0$@gmail.com>

I am working on a new package, one in which the user needs to specify the
role that different variables play in the analysis. Where I'm stumped is the
best way to have users specify those roles.

Approach #1: Separate formula for each special component

First I thought to have users specify each formula separately, like:

new.function(formula=y~X1+X2+X3,
             weights=~w,
             observationID=~ID,
             strata=~site,
             data=mydata)

This seems to be a common approach in other packages. However, one of my
testers noted that if he put formula=y~. then w, ID, and site showed up in
the model where they weren't supposed to be. I could add some code to try to
prevent that (string matching and editing the terms object, perhaps?), but
that seemed a little clumsy to me.

Approach #2: Create specials to label special variables

So I turned to the user interface design in coxph where the user can specify
strata and cluster in a single formula. So my approach would look something
like:

new.function(formula=y~weights(w)+strata(site)+observationID(ID)+X1+X2+X3,
             data=mydata)

My aim would be that the user could use a dot instead of X1+X2+X3 and the
dot would not expand to include w, site, and ID. However, at least as
implemented in coxph(), this approach does not handle the dot in the formula
any better than the first approach.

Call:
coxph(formula = Surv(time, status) ~ strata(sex) + ., data = test1)

     coef exp(coef) se(coef)     z    p
x   0.802      2.23    0.822 0.976 0.33
sex    NA        NA    0.000    NA   NA

Surely the user wants the dot to mean all the other variables but not the
ones that are already in the model, like sex. I could also develop some code
(again perhaps clumsily) to search after the fact for variables (like sex)
that shouldn't be in there.

Approach #3: Require the user to first describe a separate study design
object

Lastly I looked at the design for the survey package. This package first
requires the user to create an object that describes the key components of
the dataset. So I would have the user do something like this:

mystudy <- study.design(weights=~w,
                        observationID=~ID,
                        strata=~site,
                        data=mydata)
myresults <- doanalysis(formula=y~X1+X2+X3, design=mystudy)

But it seems that the survey package is also not designed to handle the dot.

data(api)
dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
svyglm(api00~., design=dstrat)
Error in svyglm.survey.design(api00 ~ ., design = dstrat) : 
  all variables must be in design= argument

Does anyone have advice on how best to handle this? 
1. Tell my tester "Tough, you can't use dots in a formula in my
package".essentially what the survey package seems to do. Encourage the use
of survey::make.formula()?
2. Fix Approach #1 to search for duplicates in the weights, observation ID,
and strata parameters. Any elegant ways to do that?
3. Fix Approach #2, the coxph style, to try to remove redundant covariates.
Not sure if there's a graceful way not involving string matching
4. Any existing elegant approaches to interpreting the dot? Or should I just
do string matching to delete duplicate variables from the terms object.

Thanks,
Greg

Greg Ridgeway
Associate Professor
University of Pennsylvania


From S.Ellison at LGCGroup.com  Wed Oct 15 17:50:10 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 15 Oct 2014 16:50:10 +0100
Subject: [Rd] Advice on package design for handling of dots in a formula
In-Reply-To: <0b3f01cfe881$e3613ea0$aa23bbe0$@gmail.com>
References: <0b3f01cfe881$e3613ea0$aa23bbe0$@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412B87D30@GOLD.corp.lgc-group.com>

> This seems to be a common approach in other packages. However, one of my
> testers noted that if he put formula=y~. then w, ID, and site showed up in the
> model where they weren't supposed to be. 

This is the documented behaviour for '.' in a formula - it means 'everything else in the data object'

Without changing your current code, though, your user could have said something like
y~.-w-ID-site

if they wanted to specify 'everything _except_ the subtracted terms', so it's not as bad as having no shortcuts at all.

If you want to do the work for them, one (probably crude) way of doing it could use drop.terms() in combination with some work with the term labels:

#A function that drops the terms in two later arguments from the terms in the first and returns the resulting trimmed terms object.
f <- function(form, dropthis, dropthattoo, data) {
	everything <- attr(terms(form, data=data), "term.labels") #needs data to expand '.'
	drops <- c(attr(terms(dropthis, data=data), "term.labels"), 
			attr(terms(dropthattoo, data=data), "term.labels")) #could probably do without 'data'
	excludes <-which(everything %in% drops)
	terms(form, data=data)[-excludes]
}

d <- data.frame(a=1:10, b=10:1, g=gl(5,2), g2=gl(2,5), y=rnorm(10))

f(y~., ~g, ~b, data=d)
	#This returns a terms object, but there's a formula in that if you want it....

formula(f(y~., ~g, ~b, data=d))

 You'll need to be careful about evaluating that though; don't forget to give any relevant model or model matrix functions the environment (data frame) to go with it or you'll get nonsense.


S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ccberry at ucsd.edu  Wed Oct 15 17:55:53 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Wed, 15 Oct 2014 15:55:53 +0000
Subject: [Rd] Advice on package design for handling of dots in a formula
References: <0b3f01cfe881$e3613ea0$aa23bbe0$@gmail.com>
Message-ID: <loom.20141015T173808-550@post.gmane.org>

Greg Ridgeway <gregridgeway <at> gmail.com> writes:

> 
> I am working on a new package, one in which the user needs to specify the
> role that different variables play in the analysis. Where I'm stumped is >
the best way to have users specify those roles.

[delete discussion of dot in formula and specials]
> 
> Does anyone have advice on how best to handle this? 
> 1. Tell my tester "Tough, you can't use dots in a formula in my
> package".essentially what the survey package seems to do. Encourage the 
> use of survey::make.formula()?
> 2. Fix Approach #1 to search for duplicates in the weights, observation 
> ID,and strata parameters. Any elegant ways to do that?
> 3. Fix Approach #2, the coxph style, to try to remove redundant 
> covariates.
> Not sure if there's a graceful way not involving string matching
> 4. Any existing elegant approaches to interpreting the dot? Or should I 
> just do string matching to delete duplicate variables from the terms 
> object.
> 

See ?terms.formula and note the `allowDotAsName' arg.

> trms <- terms(y~speshul(x)+.,allowDotAsName=TRUE,specials="speshul")
> attr(trms,"term.labels")
[1] "speshul(x)" "."         

See ?all.vars

> all.vars(trms)
[1] "y" "x" "."
> setdiff( all.vars(trms) , "." )
[1] "y" "x"
> 

HTH,

Chuck


From therneau at mayo.edu  Thu Oct 16 18:11:25 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 16 Oct 2014 11:11:25 -0500
Subject: [Rd] Advice on package design for handling of dots in a formula
In-Reply-To: <mailman.19.1413453607.19764.r-devel@r-project.org>
References: <mailman.19.1413453607.19764.r-devel@r-project.org>
Message-ID: <31062c$99d8q9@ironport10.mayo.edu>

There is the issue of best design and the issue of dots, which I think are separate.

As to the dots, I don't think there is any way out but to handle it yourself.  The formula 
parser has defined "." to mean everything in the frame that is not listed in the response. 
  For good or ill it allows one to type y~ log(age) + . and get a model that has both 
log(age) and age --- perhaps that is what the user wanted.

Only you know that having strata(x) and x both on the right hand side does not make sense.

I have never been sympathetic to the use of ., I suppose because it never applies to my 
own data sets.  My data always contain idenifier variables: subject id, address, 
enrollment date, etc, which would never be used in a fit.
Use of "." simply never occurs outside of toy examples.  My primary advice would be to 
stop worrying about it.  (Or prehaps give me a context of why you do need to use it.)

Beyond that, a couple of design comments:
  1. When an option refers to only a single variable, there is not need for a "~", and in 
fact things are
easier without it.  Look for example at the etastart option in glm().  I think we should 
use this more.  If coxph were being rewritten today the cluster(id) term now used in a 
formula to signal grouping would instead be an
id= option.

  2. I like the idea of marking variables in the formula, like strata() does in coxph. 
The variable is part of the prediction but plays a different role.  I also now prefer 
setting those up so that they are not global variables, i.e. tt() makes sense only within 
the coxph call.  It took me a long time to see exactly how to do this, you will find the 
example code in coxph.  If redoing things today, strata() would be local as well.

  3. Make the formula and call easy for the user, even if you have to do more work.  This 
was the approach taken in coxme, which tears it apart and reassembles.

If you intend to study coxph, then you should pull up the file "sourcecode.pdf", found in 
the "doc" directory of the installed survival library.  It has a lot more comments about 
my design decisions.  Certainly do this if you want to emulate the custom formula 
processing of coxme, though for that document you'll need to grab the source code and do 
"make all.pdf" in its noweb directory.


Terry Therneau

On 10/16/2014 05:00 AM, r-devel-request at r-project.org wrote:
> I am working on a new package, one in which the user needs to specify the
> role that different variables play in the analysis. Where I'm stumped is the
> best way to have users specify those roles.
>
> Approach #1: Separate formula for each special component
>
> First I thought to have users specify each formula separately, like:
>
> new.function(formula=y~X1+X2+X3,
>               weights=~w,
>               observationID=~ID,
>               strata=~site,
>               data=mydata)
>
> This seems to be a common approach in other packages. However, one of my
> testers noted that if he put formula=y~. then w, ID, and site showed up in
> the model where they weren't supposed to be. I could add some code to try to
> prevent that (string matching and editing the terms object, perhaps?), but
> that seemed a little clumsy to me.
...  rest of note not copied


From kmillar at google.com  Fri Oct 17 08:11:54 2014
From: kmillar at google.com (Karl Millar)
Date: Thu, 16 Oct 2014 23:11:54 -0700
Subject: [Rd] Making parent.env<- an error for package namespaces and
	package imports
Message-ID: <CABz6aZeDDsjM-pmfGwRK220LLakd9OXPb3ArLP6uZDEaHp3akQ@mail.gmail.com>

I'd like to propose a change to the R language so that calling
'parent.env<-' on a package namespace or package imports is a runtime
error.

Currently the documentation warns that it's dangerous behaviour and
might go away:
     The replacement function ?parent.env<-? is extremely dangerous as
     it can be used to destructively change environments in ways that
     violate assumptions made by the internal C code.  It may be
     removed in the near future.

This change would both eliminate some potential dangerous behaviours,
and make it significantly easier for runtime compilation systems to
optimize symbol lookups for code in packages.

The following patch against current svn implements this functionality.
It allows calls to 'parent.env<-' only until the namespace is locked,
allowing the namespace to be built correctly while preventing user
code from subsequently messing with it.

I'd also like to make calling parent.env<- on an environment on the
call stack an error, for the same reasons, but it's not so obvious to
me how to implement that efficiently right now.  Could we at least
document that as being 'undefined behaviour'?

Thanks,

Karl


Index: src/main/builtin.c
===================================================================
--- src/main/builtin.c (revision 66783)
+++ src/main/builtin.c (working copy)
@@ -356,6 +356,24 @@
     return( ENCLOS(arg) );
 }

+static Rboolean R_IsImportsEnv(SEXP env)
+{
+    if (isNull(env) || !isEnvironment(env))
+        return FALSE;
+    if (ENCLOS(env) != R_BaseNamespace)
+        return FALSE;
+    SEXP name = getAttrib(env, R_NameSymbol);
+    if (!isString(name) || length(name) != 1)
+        return FALSE;
+
+    const char *imports_prefix = "imports:";
+    const char *name_string = CHAR(STRING_ELT(name, 0));
+    if (!strncmp(name_string, imports_prefix, strlen(imports_prefix)))
+        return TRUE;
+    else
+        return FALSE;
+}
+
 SEXP attribute_hidden do_parentenvgets(SEXP call, SEXP op, SEXP args, SEXP rho)
 {
     SEXP env, parent;
@@ -371,6 +389,10 @@
  error(_("argument is not an environment"));
     if( env == R_EmptyEnv )
  error(_("can not set parent of the empty environment"));
+    if (R_EnvironmentIsLocked(env) && R_IsNamespaceEnv(env))
+      error(_("can not set the parent environment of a namespace"));
+    if (R_EnvironmentIsLocked(env) && R_IsImportsEnv(env))
+      error(_("can not set the parent environment of package imports"));
     parent = CADR(args);
     if (isNull(parent)) {
  error(_("use of NULL environment is defunct"));
?


From sleepingwell at gmail.com  Fri Oct 17 13:31:55 2014
From: sleepingwell at gmail.com (Simon Knapp)
Date: Fri, 17 Oct 2014 22:31:55 +1100
Subject: [Rd] Holding a large number of SEXPs in C++
Message-ID: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>

Background:
I have an algorithm which produces a large number of small polygons (of the
spatial kind) which I would like to use within R using objects from sp. I
can't predict the exact number of polygons a-priori, the polygons will be
grouped into regions, and each region will be filled sequentially, so an
appropriate C++ 'framework' (for the point of illustration) might be:

typedef std::pair<double, double> Point;
typedef std::vector<Point> Polygon;
typedef std::vector<Polygon> Polygons;
typedef std::vector<Polygons> Regions;

struct Holder {
    void notifyNewRegion(void) const {
        regions.push_back(Polygons());
    }

    template<typename Iter>
    void addSubPoly(Iter b, Iter e) {
        regions.back().push_back(Polygon(b, e));
    }

private:
    Regions regions;
};

where the reference_type of Iter is convertible to Point. In practice I use
pointers in a couple of places to avoid resizing in push_back becoming too
expensive.

To construct the corresponding sp::Polygon, sp::Polygons and
sp::SpatialPolygons at the end of the algorithm, I iterate over the result
turning each Polygon into a two column matrix and calling the C functions
corresponding to the 'constructors' for these objects.

This is all working fine, but I could cut my memory consumption in half if
I could construct the sp::Polygon objects in addSubPoly, and the
sp::Polygons objects in notifyNewRegion. My vector typedefs would then all
be:

typedef std::vector<SEXP>




Question:
What I'm not sure about (and finally my question) is: I will have datasets
where I have more than 10,000 SEXPs in the Polygon and Polygons objects for
a single region, and possibly more than 10,000 regions, so how do I PROTECT
all those SEXPs (noting that the protection stack is limited to 10,000 and
bearing in mind that I don't know how many there will be before I start)?

I am also interested in this just out of general curiosity.




Thoughts:

1) I could create an environment and store the objects themselves in there
while keeping pointers in the vectors, but am not sure if this would be
that efficient (guidance would be appreciated), or

2) Just keep them in R vectors and grow these myself (as push_back is doing
for me in the above), but that sounds like a pain and I'm not sure if the
objects or just the pointers would be copied when I reassigned things
(guidance would be appreciated again). Bare in mind that I keep pointers in
the vectors, but omitted that for the sake of clarity.




Is there some other R type that would be suited to this, or a general
approach?

Cheers and thanks in advance,
Simon Knapp

	[[alternative HTML version deleted]]


From patrick.a.oreilly at gmail.com  Fri Oct 17 13:34:28 2014
From: patrick.a.oreilly at gmail.com (Patrick O'Reilly)
Date: Fri, 17 Oct 2014 12:34:28 +0100
Subject: [Rd] model.matrix metadata
Message-ID: <CA+BxRLaXUQX=gQfF26d0fcoT5Bg3tSbijtBzPMuR1Pugf7WcKw@mail.gmail.com>

Hi,

As far as I am aware, the model.matrix function does not return
perfect metadata on what each column of the model matrix "means".

The columns are named (e.g. age:genderM), but encoding the metadata as
strings can result in ambiguity. For example, the dummy variables
created when the factors var0 = 0 and var = 00 both are named var00.
Additionally, if a level of a factor variable contains a colon, this
could be confused for an interaction.

While a human can generally work out the meaning of each column
somewhat manually, I am interested in achieving this programmatically.

My solution is to edit the modelmatrix function in
/src/library/stats/src/model.c to additionally return the following:

intrcept
factors
contr1
contr2
count

With the availability of these in R it is possible to determine the
precise meaning of each column without the error-prone parsing of
strings. I have attached my edit: see lines 753-764.

I am seeking advice on this approach. Am I missing a simpler way of
achieving this (which perhaps avoids rebuilding R)?

Since model.matrix is used in so many modeling functions this would be
very helpful for the programmatic interpretation of model output. A
search on the Internet suggests there are other R users who would
welcome such functionality.

Many thanks in advance,

Pat O'Reilly
-------------- next part --------------
A non-text attachment was scrubbed...
Name: model.c
Type: text/x-csrc
Size: 56318 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20141017/5ba1e6aa/attachment.bin>

From simon.urbanek at r-project.org  Fri Oct 17 17:10:38 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 17 Oct 2014 11:10:38 -0400
Subject: [Rd] Holding a large number of SEXPs in C++
In-Reply-To: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
References: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
Message-ID: <5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>


On Oct 17, 2014, at 7:31 AM, Simon Knapp <sleepingwell at gmail.com> wrote:

> Background:
> I have an algorithm which produces a large number of small polygons (of the
> spatial kind) which I would like to use within R using objects from sp. I
> can't predict the exact number of polygons a-priori, the polygons will be
> grouped into regions, and each region will be filled sequentially, so an
> appropriate C++ 'framework' (for the point of illustration) might be:
> 
> typedef std::pair<double, double> Point;
> typedef std::vector<Point> Polygon;
> typedef std::vector<Polygon> Polygons;
> typedef std::vector<Polygons> Regions;
> 
> struct Holder {
>    void notifyNewRegion(void) const {
>        regions.push_back(Polygons());
>    }
> 
>    template<typename Iter>
>    void addSubPoly(Iter b, Iter e) {
>        regions.back().push_back(Polygon(b, e));
>    }
> 
> private:
>    Regions regions;
> };
> 
> where the reference_type of Iter is convertible to Point. In practice I use
> pointers in a couple of places to avoid resizing in push_back becoming too
> expensive.
> 
> To construct the corresponding sp::Polygon, sp::Polygons and
> sp::SpatialPolygons at the end of the algorithm, I iterate over the result
> turning each Polygon into a two column matrix and calling the C functions
> corresponding to the 'constructors' for these objects.
> 
> This is all working fine, but I could cut my memory consumption in half if
> I could construct the sp::Polygon objects in addSubPoly, and the
> sp::Polygons objects in notifyNewRegion. My vector typedefs would then all
> be:
> 
> typedef std::vector<SEXP>
> 
> 
> 
> 
> Question:
> What I'm not sure about (and finally my question) is: I will have datasets
> where I have more than 10,000 SEXPs in the Polygon and Polygons objects for
> a single region, and possibly more than 10,000 regions, so how do I PROTECT
> all those SEXPs (noting that the protection stack is limited to 10,000 and
> bearing in mind that I don't know how many there will be before I start)?
> 
> I am also interested in this just out of general curiosity.
> 
> 
> 
> 
> Thoughts:
> 
> 1) I could create an environment and store the objects themselves in there
> while keeping pointers in the vectors, but am not sure if this would be
> that efficient (guidance would be appreciated), or
> 
> 2) Just keep them in R vectors and grow these myself (as push_back is doing
> for me in the above), but that sounds like a pain and I'm not sure if the
> objects or just the pointers would be copied when I reassigned things
> (guidance would be appreciated again). Bare in mind that I keep pointers in
> the vectors, but omitted that for the sake of clarity.
> 
> 
> 
> 
> Is there some other R type that would be suited to this, or a general
> approach?
> 

Lists in R (LISTSXP aka pairlists) are suited to appending (since that is fast and trivial) and sequential processing. The only issue is that pairlists are slow for random access. If you only want to load the polygons and finalize, then you can hold them in a pairlist and at the end copy to a generic vector (if random access is expected). DB applications typically use a hybrid approach -  allocate vector blocks and keep them in pairlists, but that's probably an overkill for your use (if you really cared about performance you wouldn't use sp objects for this ;))

Note that you only have to protect the top-level object, so you don't need to protect the individual elements.

Cheers,
Simon


> Cheers and thanks in advance,
> Simon Knapp
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ccberry at ucsd.edu  Fri Oct 17 18:43:40 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Fri, 17 Oct 2014 16:43:40 +0000
Subject: [Rd] model.matrix metadata
References: <CA+BxRLaXUQX=gQfF26d0fcoT5Bg3tSbijtBzPMuR1Pugf7WcKw@mail.gmail.com>
Message-ID: <loom.20141017T183457-789@post.gmane.org>

Patrick O'Reilly <patrick.a.oreilly <at> gmail.com> writes:

> 
> Hi,
> 
> As far as I am aware, the model.matrix function does not return
> perfect metadata on what each column of the model matrix "means".
> 
> The columns are named (e.g. age:genderM), but encoding the metadata as
> strings can result in ambiguity. For example, the dummy variables
> created when the factors var0 = 0 and var = 00 both are named var00.
> Additionally, if a level of a factor variable contains a colon, this
> could be confused for an interaction.
> 
> While a human can generally work out the meaning of each column
> somewhat manually, I am interested in achieving this programmatically.
> 

Why don't you just retain the terms.object?

i.e

my.terms <- terms( my.formula, data=my.data.frame )
my.model.matrix <- model.matrix( my.terms, data= my.data.frame )

attributes(my.terms)


See ?terms, ?terms.object, ?model.frame (which contains a terms.object)


HTH,

Chuck


From jorismeys at gmail.com  Fri Oct 17 20:04:33 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 17 Oct 2014 20:04:33 +0200
Subject: [Rd] Most efficient way to check the length of a variable mentioned
	in a formula.
Message-ID: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>

Dear R gurus,

I need to know the length of a variable (let's call that X) that is
mentioned in a formula. So obviously I look for the environment from which
the formula is called and then I have two options:

- using eval(parse(text='length(X)'),
                    envir=environment(formula) )

- using length(get('X'),
            envir=environment(formula) )

a bit of benchmarking showed that the first option is about 20 times
slower, to that extent that if I repeat it 10,000 times I save more than
half a second. So speed is not really an issue here.

Personally I'd go for option 2 as that one is easier to read and does the
job nicely, but with these functions I'm always a bit afraid that I'm
overseeing important details or side effects here (possibly memory issues
when working with larger data).

Anybody an idea what the dangers are of these methods, and which one is the
most robust method?

Thank you
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Fri Oct 17 20:23:04 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 17 Oct 2014 11:23:04 -0700
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
Message-ID: <CADwqtCPfQjy+A9mtxHNmJXzsvemLfqvRNscUzoj4m_rLeC1ZSw@mail.gmail.com>

Joris,

For me

length(environment(form)[["x"]])

Was about twice as fast as

length(get("x",environment(form))))

In the year-old version of R (3.0.2) that I have on the virtual machine i'm
currently using.

As for you, the eval method was much slower (though my factor was much
larger than 20)

> system.time({thing <- replicate(10000,length(environment(form)[["x"]]))})
   user  system elapsed
  0.018   0.000   0.018
> system.time({thing <-
replicate(10000,length(get("x",environment(form))))})   user  system
elapsed
  0.031   0.000   0.033
> system.time({thing <- replicate(10000,eval(parse(text = "length(x)"),
envir=environment(form)))})
   user  system elapsed
  4.528   0.003   4.656

I can't speak this second to whether this pattern will hold in the more
modern versions of R I typically use.

~G

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base






On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Dear R gurus,
>
> I need to know the length of a variable (let's call that X) that is
> mentioned in a formula. So obviously I look for the environment from which
> the formula is called and then I have two options:
>
> - using eval(parse(text='length(X)'),
>                     envir=environment(formula) )
>
> - using length(get('X'),
>             envir=environment(formula) )
>
> a bit of benchmarking showed that the first option is about 20 times
> slower, to that extent that if I repeat it 10,000 times I save more than
> half a second. So speed is not really an issue here.
>
> Personally I'd go for option 2 as that one is easier to read and does the
> job nicely, but with these functions I'm always a bit afraid that I'm
> overseeing important details or side effects here (possibly memory issues
> when working with larger data).
>
> Anybody an idea what the dangers are of these methods, and which one is the
> most robust method?
>
> Thank you
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 17 20:57:30 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Oct 2014 11:57:30 -0700
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
Message-ID: <CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>

I would use eval(), but I think that most formula-using functions do
it more like the following.

getRHSLength <-
function (formula, data = parent.frame())
{
    rhsExpr <- formula[[length(formula)]]
    rhsValue <- eval(rhsExpr, envir = data, enclos = environment(formula))
    length(rhsValue)
}

* use eval() instead of get() so you will find variables are in
ancestral environments
of envir (if envir is an environment), not just envir itself.
* just evaluate the stuff in the formula using the non-standard
evaluation frame,
call length() in the current frame.  Otherwise, if  envir inherits
directly from emptyenv() the 'length' function will not be found.
* use envir=data so it looks first in the data argument for variables
* the enclos argument is used if envir is not an environment and is used to
find variables that are not in envir.

Here are some examples:
  > X <- 1:10
  > getRHSLength(~X)
  [1] 10
  > getRHSLength(~X, data=data.frame(X=1:2))
  [1] 2
  > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame())
  [1] 4
  > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame(X=1:2))
  [1] 2
  > getRHSLength((function(){X <- 1:4; ~X})(), data=list2env(data.frame()))
  [1] 10
  > getRHSLength((function(){X <- 1:4; ~X})(), data=emptyenv())
  Error in eval(expr, envir, enclos) : object 'X' not found

I think you will see the same lookups if you try analogous things with lm().
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Dear R gurus,
>
> I need to know the length of a variable (let's call that X) that is
> mentioned in a formula. So obviously I look for the environment from which
> the formula is called and then I have two options:
>
> - using eval(parse(text='length(X)'),
>                     envir=environment(formula) )
>
> - using length(get('X'),
>             envir=environment(formula) )
>
> a bit of benchmarking showed that the first option is about 20 times
> slower, to that extent that if I repeat it 10,000 times I save more than
> half a second. So speed is not really an issue here.
>
> Personally I'd go for option 2 as that one is easier to read and does the
> job nicely, but with these functions I'm always a bit afraid that I'm
> overseeing important details or side effects here (possibly memory issues
> when working with larger data).
>
> Anybody an idea what the dangers are of these methods, and which one is the
> most robust method?
>
> Thank you
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri Oct 17 22:16:35 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Oct 2014 13:16:35 -0700
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>
Message-ID: <CAF8bMcZ0s8kq-GkfVT-G9o-GvSKR_n6v51Ln0YV_0u6N8mbGZQ@mail.gmail.com>

I got the default value for getRHSLength's data argument wrong - it
should be NULL, not parent.env().
   getRHSLength <- function (formula, data = NULL)
   {
       rhsExpr <- formula[[length(formula)]]
       rhsValue <- eval(rhsExpr, envir = data, enclos = environment(formula))
       length(rhsValue)
   }
so that the function firstHalf is found in the following
   > X <- 1:10
   > getRHSLength((function(){firstHalf<-function(x)x[seq_len(floor(length(x)/2))];
~firstHalf(X)})())
   [1] 5


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 17, 2014 at 11:57 AM, William Dunlap <wdunlap at tibco.com> wrote:
> I would use eval(), but I think that most formula-using functions do
> it more like the following.
>
> getRHSLength <-
> function (formula, data = parent.frame())
> {
>     rhsExpr <- formula[[length(formula)]]
>     rhsValue <- eval(rhsExpr, envir = data, enclos = environment(formula))
>     length(rhsValue)
> }
>
> * use eval() instead of get() so you will find variables are in
> ancestral environments
> of envir (if envir is an environment), not just envir itself.
> * just evaluate the stuff in the formula using the non-standard
> evaluation frame,
> call length() in the current frame.  Otherwise, if  envir inherits
> directly from emptyenv() the 'length' function will not be found.
> * use envir=data so it looks first in the data argument for variables
> * the enclos argument is used if envir is not an environment and is used to
> find variables that are not in envir.
>
> Here are some examples:
>   > X <- 1:10
>   > getRHSLength(~X)
>   [1] 10
>   > getRHSLength(~X, data=data.frame(X=1:2))
>   [1] 2
>   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame())
>   [1] 4
>   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame(X=1:2))
>   [1] 2
>   > getRHSLength((function(){X <- 1:4; ~X})(), data=list2env(data.frame()))
>   [1] 10
>   > getRHSLength((function(){X <- 1:4; ~X})(), data=emptyenv())
>   Error in eval(expr, envir, enclos) : object 'X' not found
>
> I think you will see the same lookups if you try analogous things with lm().
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com> wrote:
>> Dear R gurus,
>>
>> I need to know the length of a variable (let's call that X) that is
>> mentioned in a formula. So obviously I look for the environment from which
>> the formula is called and then I have two options:
>>
>> - using eval(parse(text='length(X)'),
>>                     envir=environment(formula) )
>>
>> - using length(get('X'),
>>             envir=environment(formula) )
>>
>> a bit of benchmarking showed that the first option is about 20 times
>> slower, to that extent that if I repeat it 10,000 times I save more than
>> half a second. So speed is not really an issue here.
>>
>> Personally I'd go for option 2 as that one is easier to read and does the
>> job nicely, but with these functions I'm always a bit afraid that I'm
>> overseeing important details or side effects here (possibly memory issues
>> when working with larger data).
>>
>> Anybody an idea what the dangers are of these methods, and which one is the
>> most robust method?
>>
>> Thank you
>> Joris
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Mathematical Modelling, Statistics and Bio-Informatics
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Fri Oct 17 22:50:53 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 17 Oct 2014 22:50:53 +0200
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAF8bMcZ0s8kq-GkfVT-G9o-GvSKR_n6v51Ln0YV_0u6N8mbGZQ@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>
	<CAF8bMcZ0s8kq-GkfVT-G9o-GvSKR_n6v51Ln0YV_0u6N8mbGZQ@mail.gmail.com>
Message-ID: <CAO1zAVamZXVmL6O4xB5NN1HNm+0jrtCY+T=QttMJhoCa8oRjNQ@mail.gmail.com>

Thank you both, great ideas.  William, I see the point of using eval, but
the problem is that I can't evaluate the formula itself yet. I need to know
the length of these variables to create a function that is used to
evaluate. So if I try to evaluate the formula in some way before I created
the function, it will just return an error.

Now I use the attribute variables of the formula terms to get the variables
that -after some more manipulation- eventually will be the model matrix.
Something like this :

afun <- function(formula, ...){

    varnames <- all.vars(formula)
    fenv <- environment(formula)

    txt <- paste('length(',varnames[1],')')
    n <- eval(parse(text=txt), envir=fenv)

    fun <- function(x) x/n

    myterms <- terms(formula)
    eval(attr(myterms, 'variables'))

}

And that should give:

> x <- 1:10
> y <- 10:1
> z <- 11:20
> afun(z ~ fun(x) + y)
[[1]]
 [1] 11 12 13 14 15 16 17 18 19 20

[[2]]
 [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0

[[3]]
 [1] 10  9  8  7  6  5  4  3  2  1

It might be I'm walking to Paris over Singapore, but I couldn't find a
better way to do it.

Cheers
Joris

On Fri, Oct 17, 2014 at 10:16 PM, William Dunlap <wdunlap at tibco.com> wrote:

> I got the default value for getRHSLength's data argument wrong - it
> should be NULL, not parent.env().
>    getRHSLength <- function (formula, data = NULL)
>    {
>        rhsExpr <- formula[[length(formula)]]
>        rhsValue <- eval(rhsExpr, envir = data, enclos =
> environment(formula))
>        length(rhsValue)
>    }
> so that the function firstHalf is found in the following
>    > X <- 1:10
>    >
> getRHSLength((function(){firstHalf<-function(x)x[seq_len(floor(length(x)/2))];
> ~firstHalf(X)})())
>    [1] 5
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Oct 17, 2014 at 11:57 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
> > I would use eval(), but I think that most formula-using functions do
> > it more like the following.
> >
> > getRHSLength <-
> > function (formula, data = parent.frame())
> > {
> >     rhsExpr <- formula[[length(formula)]]
> >     rhsValue <- eval(rhsExpr, envir = data, enclos =
> environment(formula))
> >     length(rhsValue)
> > }
> >
> > * use eval() instead of get() so you will find variables are in
> > ancestral environments
> > of envir (if envir is an environment), not just envir itself.
> > * just evaluate the stuff in the formula using the non-standard
> > evaluation frame,
> > call length() in the current frame.  Otherwise, if  envir inherits
> > directly from emptyenv() the 'length' function will not be found.
> > * use envir=data so it looks first in the data argument for variables
> > * the enclos argument is used if envir is not an environment and is used
> to
> > find variables that are not in envir.
> >
> > Here are some examples:
> >   > X <- 1:10
> >   > getRHSLength(~X)
> >   [1] 10
> >   > getRHSLength(~X, data=data.frame(X=1:2))
> >   [1] 2
> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame())
> >   [1] 4
> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame(X=1:2))
> >   [1] 2
> >   > getRHSLength((function(){X <- 1:4; ~X})(),
> data=list2env(data.frame()))
> >   [1] 10
> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=emptyenv())
> >   Error in eval(expr, envir, enclos) : object 'X' not found
> >
> > I think you will see the same lookups if you try analogous things with
> lm().
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> > On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com>
> wrote:
> >> Dear R gurus,
> >>
> >> I need to know the length of a variable (let's call that X) that is
> >> mentioned in a formula. So obviously I look for the environment from
> which
> >> the formula is called and then I have two options:
> >>
> >> - using eval(parse(text='length(X)'),
> >>                     envir=environment(formula) )
> >>
> >> - using length(get('X'),
> >>             envir=environment(formula) )
> >>
> >> a bit of benchmarking showed that the first option is about 20 times
> >> slower, to that extent that if I repeat it 10,000 times I save more than
> >> half a second. So speed is not really an issue here.
> >>
> >> Personally I'd go for option 2 as that one is easier to read and does
> the
> >> job nicely, but with these functions I'm always a bit afraid that I'm
> >> overseeing important details or side effects here (possibly memory
> issues
> >> when working with larger data).
> >>
> >> Anybody an idea what the dangers are of these methods, and which one is
> the
> >> most robust method?
> >>
> >> Thank you
> >> Joris
> >>
> >> --
> >> Joris Meys
> >> Statistical consultant
> >>
> >> Ghent University
> >> Faculty of Bioscience Engineering
> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
> >>
> >> tel : +32 9 264 59 87
> >> Joris.Meys at Ugent.be
> >> -------------------------------
> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 17 23:36:08 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Oct 2014 14:36:08 -0700
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAO1zAVamZXVmL6O4xB5NN1HNm+0jrtCY+T=QttMJhoCa8oRjNQ@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>
	<CAF8bMcZ0s8kq-GkfVT-G9o-GvSKR_n6v51Ln0YV_0u6N8mbGZQ@mail.gmail.com>
	<CAO1zAVamZXVmL6O4xB5NN1HNm+0jrtCY+T=QttMJhoCa8oRjNQ@mail.gmail.com>
Message-ID: <CAF8bMcYU94yeHesbcWt6nBPq9z+KmrT2FRNuiyoccipWYxM3eA@mail.gmail.com>

In my example function I did not evaluate the formula either, just a part of it.

If you leave off the envir and enclos arguments to eval in your
function you can get surprising (wrong) results.  E.g.,
  > afun(y ~ varnames)
  [[1]]
   [1] 10  9  8  7  6  5  4  3  2  1

  [[2]]
  [1] "y"        "varnames"

If you want to use the variables in data or environment(formula) and
some functions defined in your function, then you could make a child
environment of environment(formula), put your locally defined
functions in it, and use the child environment in the call to eval.
E.g., you code would become
afun2 <- function(formula, ...){

    varnames <- all.vars(formula)
    fenv <- environment(formula)

    n <- length(eval(as.name(varnames[1]), envir=fenv))
    childEnv <- new.env(parent=fenv)
    childEnv$fun <- function(x) x/n

    myterms <- terms(formula)
    eval(attr(myterms, 'variables'), envir=childEnv)
}

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 17, 2014 at 1:50 PM, Joris Meys <jorismeys at gmail.com> wrote:
> Thank you both, great ideas.  William, I see the point of using eval, but
> the problem is that I can't evaluate the formula itself yet. I need to know
> the length of these variables to create a function that is used to evaluate.
> So if I try to evaluate the formula in some way before I created the
> function, it will just return an error.
>
> Now I use the attribute variables of the formula terms to get the variables
> that -after some more manipulation- eventually will be the model matrix.
> Something like this :
>
> afun <- function(formula, ...){
>
>     varnames <- all.vars(formula)
>     fenv <- environment(formula)
>
>     txt <- paste('length(',varnames[1],')')
>     n <- eval(parse(text=txt), envir=fenv)
>
>     fun <- function(x) x/n
>
>     myterms <- terms(formula)
>     eval(attr(myterms, 'variables'))
>
> }
>
> And that should give:
>
>> x <- 1:10
>> y <- 10:1
>> z <- 11:20
>> afun(z ~ fun(x) + y)
> [[1]]
>  [1] 11 12 13 14 15 16 17 18 19 20
>
> [[2]]
>  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
>
> [[3]]
>  [1] 10  9  8  7  6  5  4  3  2  1
>
> It might be I'm walking to Paris over Singapore, but I couldn't find a
> better way to do it.
>
> Cheers
> Joris
>
> On Fri, Oct 17, 2014 at 10:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> I got the default value for getRHSLength's data argument wrong - it
>> should be NULL, not parent.env().
>>    getRHSLength <- function (formula, data = NULL)
>>    {
>>        rhsExpr <- formula[[length(formula)]]
>>        rhsValue <- eval(rhsExpr, envir = data, enclos =
>> environment(formula))
>>        length(rhsValue)
>>    }
>> so that the function firstHalf is found in the following
>>    > X <- 1:10
>>    >
>> getRHSLength((function(){firstHalf<-function(x)x[seq_len(floor(length(x)/2))];
>> ~firstHalf(X)})())
>>    [1] 5
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Oct 17, 2014 at 11:57 AM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>> > I would use eval(), but I think that most formula-using functions do
>> > it more like the following.
>> >
>> > getRHSLength <-
>> > function (formula, data = parent.frame())
>> > {
>> >     rhsExpr <- formula[[length(formula)]]
>> >     rhsValue <- eval(rhsExpr, envir = data, enclos =
>> > environment(formula))
>> >     length(rhsValue)
>> > }
>> >
>> > * use eval() instead of get() so you will find variables are in
>> > ancestral environments
>> > of envir (if envir is an environment), not just envir itself.
>> > * just evaluate the stuff in the formula using the non-standard
>> > evaluation frame,
>> > call length() in the current frame.  Otherwise, if  envir inherits
>> > directly from emptyenv() the 'length' function will not be found.
>> > * use envir=data so it looks first in the data argument for variables
>> > * the enclos argument is used if envir is not an environment and is used
>> > to
>> > find variables that are not in envir.
>> >
>> > Here are some examples:
>> >   > X <- 1:10
>> >   > getRHSLength(~X)
>> >   [1] 10
>> >   > getRHSLength(~X, data=data.frame(X=1:2))
>> >   [1] 2
>> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame())
>> >   [1] 4
>> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame(X=1:2))
>> >   [1] 2
>> >   > getRHSLength((function(){X <- 1:4; ~X})(),
>> > data=list2env(data.frame()))
>> >   [1] 10
>> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=emptyenv())
>> >   Error in eval(expr, envir, enclos) : object 'X' not found
>> >
>> > I think you will see the same lookups if you try analogous things with
>> > lm().
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> >
>> > On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com>
>> > wrote:
>> >> Dear R gurus,
>> >>
>> >> I need to know the length of a variable (let's call that X) that is
>> >> mentioned in a formula. So obviously I look for the environment from
>> >> which
>> >> the formula is called and then I have two options:
>> >>
>> >> - using eval(parse(text='length(X)'),
>> >>                     envir=environment(formula) )
>> >>
>> >> - using length(get('X'),
>> >>             envir=environment(formula) )
>> >>
>> >> a bit of benchmarking showed that the first option is about 20 times
>> >> slower, to that extent that if I repeat it 10,000 times I save more
>> >> than
>> >> half a second. So speed is not really an issue here.
>> >>
>> >> Personally I'd go for option 2 as that one is easier to read and does
>> >> the
>> >> job nicely, but with these functions I'm always a bit afraid that I'm
>> >> overseeing important details or side effects here (possibly memory
>> >> issues
>> >> when working with larger data).
>> >>
>> >> Anybody an idea what the dangers are of these methods, and which one is
>> >> the
>> >> most robust method?
>> >>
>> >> Thank you
>> >> Joris
>> >>
>> >> --
>> >> Joris Meys
>> >> Statistical consultant
>> >>
>> >> Ghent University
>> >> Faculty of Bioscience Engineering
>> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
>> >>
>> >> tel : +32 9 264 59 87
>> >> Joris.Meys at Ugent.be
>> >> -------------------------------
>> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From luke-tierney at uiowa.edu  Sat Oct 18 18:03:53 2014
From: luke-tierney at uiowa.edu (Tierney, Luke)
Date: Sat, 18 Oct 2014 16:03:53 +0000
Subject: [Rd] Making parent.env<- an error for package namespaces
	and	package imports
In-Reply-To: <CABz6aZeDDsjM-pmfGwRK220LLakd9OXPb3ArLP6uZDEaHp3akQ@mail.gmail.com>
References: <CABz6aZeDDsjM-pmfGwRK220LLakd9OXPb3ArLP6uZDEaHp3akQ@mail.gmail.com>
Message-ID: <89F8B209-C5DF-4665-80B7-EEA48BBEC4FF@uiowa.edu>

I'll look into it

Sent from my iPhone

> On Oct 17, 2014, at 1:13 AM, "Karl Millar" <kmillar at google.com> wrote:
> 
> I'd like to propose a change to the R language so that calling
> 'parent.env<-' on a package namespace or package imports is a runtime
> error.
> 
> Currently the documentation warns that it's dangerous behaviour and
> might go away:
>     The replacement function ?parent.env<-? is extremely dangerous as
>     it can be used to destructively change environments in ways that
>     violate assumptions made by the internal C code.  It may be
>     removed in the near future.
> 
> This change would both eliminate some potential dangerous behaviours,
> and make it significantly easier for runtime compilation systems to
> optimize symbol lookups for code in packages.
> 
> The following patch against current svn implements this functionality.
> It allows calls to 'parent.env<-' only until the namespace is locked,
> allowing the namespace to be built correctly while preventing user
> code from subsequently messing with it.
> 
> I'd also like to make calling parent.env<- on an environment on the
> call stack an error, for the same reasons, but it's not so obvious to
> me how to implement that efficiently right now.  Could we at least
> document that as being 'undefined behaviour'?
> 
> Thanks,
> 
> Karl
> 
> 
> Index: src/main/builtin.c
> ===================================================================
> --- src/main/builtin.c (revision 66783)
> +++ src/main/builtin.c (working copy)
> @@ -356,6 +356,24 @@
>     return( ENCLOS(arg) );
> }
> 
> +static Rboolean R_IsImportsEnv(SEXP env)
> +{
> +    if (isNull(env) || !isEnvironment(env))
> +        return FALSE;
> +    if (ENCLOS(env) != R_BaseNamespace)
> +        return FALSE;
> +    SEXP name = getAttrib(env, R_NameSymbol);
> +    if (!isString(name) || length(name) != 1)
> +        return FALSE;
> +
> +    const char *imports_prefix = "imports:";
> +    const char *name_string = CHAR(STRING_ELT(name, 0));
> +    if (!strncmp(name_string, imports_prefix, strlen(imports_prefix)))
> +        return TRUE;
> +    else
> +        return FALSE;
> +}
> +
> SEXP attribute_hidden do_parentenvgets(SEXP call, SEXP op, SEXP args, SEXP rho)
> {
>     SEXP env, parent;
> @@ -371,6 +389,10 @@
>  error(_("argument is not an environment"));
>     if( env == R_EmptyEnv )
>  error(_("can not set parent of the empty environment"));
> +    if (R_EnvironmentIsLocked(env) && R_IsNamespaceEnv(env))
> +      error(_("can not set the parent environment of a namespace"));
> +    if (R_EnvironmentIsLocked(env) && R_IsImportsEnv(env))
> +      error(_("can not set the parent environment of package imports"));
>     parent = CADR(args);
>     if (isNull(parent)) {
>  error(_("use of NULL environment is defunct"));
> ?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From jorismeys at gmail.com  Sat Oct 18 21:56:53 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 18 Oct 2014 21:56:53 +0200
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CAF8bMcYU94yeHesbcWt6nBPq9z+KmrT2FRNuiyoccipWYxM3eA@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CAF8bMcags=3t1ein3WALE0i-fFyfVunWhdk33sJUyXBK0dfj0g@mail.gmail.com>
	<CAF8bMcZ0s8kq-GkfVT-G9o-GvSKR_n6v51Ln0YV_0u6N8mbGZQ@mail.gmail.com>
	<CAO1zAVamZXVmL6O4xB5NN1HNm+0jrtCY+T=QttMJhoCa8oRjNQ@mail.gmail.com>
	<CAF8bMcYU94yeHesbcWt6nBPq9z+KmrT2FRNuiyoccipWYxM3eA@mail.gmail.com>
Message-ID: <CAO1zAVamqgVqq-zfHuiY47s-gd_au30-76J8sCc3oveVqb=whg@mail.gmail.com>

Thanks again William, I owe you one!
Cheers
Joris

On Fri, Oct 17, 2014 at 11:36 PM, William Dunlap <wdunlap at tibco.com> wrote:

> In my example function I did not evaluate the formula either, just a part
> of it.
>
> If you leave off the envir and enclos arguments to eval in your
> function you can get surprising (wrong) results.  E.g.,
>   > afun(y ~ varnames)
>   [[1]]
>    [1] 10  9  8  7  6  5  4  3  2  1
>
>   [[2]]
>   [1] "y"        "varnames"
>
> If you want to use the variables in data or environment(formula) and
> some functions defined in your function, then you could make a child
> environment of environment(formula), put your locally defined
> functions in it, and use the child environment in the call to eval.
> E.g., you code would become
> afun2 <- function(formula, ...){
>
>     varnames <- all.vars(formula)
>     fenv <- environment(formula)
>
>     n <- length(eval(as.name(varnames[1]), envir=fenv))
>     childEnv <- new.env(parent=fenv)
>     childEnv$fun <- function(x) x/n
>
>     myterms <- terms(formula)
>     eval(attr(myterms, 'variables'), envir=childEnv)
> }
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Oct 17, 2014 at 1:50 PM, Joris Meys <jorismeys at gmail.com> wrote:
> > Thank you both, great ideas.  William, I see the point of using eval, but
> > the problem is that I can't evaluate the formula itself yet. I need to
> know
> > the length of these variables to create a function that is used to
> evaluate.
> > So if I try to evaluate the formula in some way before I created the
> > function, it will just return an error.
> >
> > Now I use the attribute variables of the formula terms to get the
> variables
> > that -after some more manipulation- eventually will be the model matrix.
> > Something like this :
> >
> > afun <- function(formula, ...){
> >
> >     varnames <- all.vars(formula)
> >     fenv <- environment(formula)
> >
> >     txt <- paste('length(',varnames[1],')')
> >     n <- eval(parse(text=txt), envir=fenv)
> >
> >     fun <- function(x) x/n
> >
> >     myterms <- terms(formula)
> >     eval(attr(myterms, 'variables'))
> >
> > }
> >
> > And that should give:
> >
> >> x <- 1:10
> >> y <- 10:1
> >> z <- 11:20
> >> afun(z ~ fun(x) + y)
> > [[1]]
> >  [1] 11 12 13 14 15 16 17 18 19 20
> >
> > [[2]]
> >  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
> >
> > [[3]]
> >  [1] 10  9  8  7  6  5  4  3  2  1
> >
> > It might be I'm walking to Paris over Singapore, but I couldn't find a
> > better way to do it.
> >
> > Cheers
> > Joris
> >
> > On Fri, Oct 17, 2014 at 10:16 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >>
> >> I got the default value for getRHSLength's data argument wrong - it
> >> should be NULL, not parent.env().
> >>    getRHSLength <- function (formula, data = NULL)
> >>    {
> >>        rhsExpr <- formula[[length(formula)]]
> >>        rhsValue <- eval(rhsExpr, envir = data, enclos =
> >> environment(formula))
> >>        length(rhsValue)
> >>    }
> >> so that the function firstHalf is found in the following
> >>    > X <- 1:10
> >>    >
> >>
> getRHSLength((function(){firstHalf<-function(x)x[seq_len(floor(length(x)/2))];
> >> ~firstHalf(X)})())
> >>    [1] 5
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Fri, Oct 17, 2014 at 11:57 AM, William Dunlap <wdunlap at tibco.com>
> >> wrote:
> >> > I would use eval(), but I think that most formula-using functions do
> >> > it more like the following.
> >> >
> >> > getRHSLength <-
> >> > function (formula, data = parent.frame())
> >> > {
> >> >     rhsExpr <- formula[[length(formula)]]
> >> >     rhsValue <- eval(rhsExpr, envir = data, enclos =
> >> > environment(formula))
> >> >     length(rhsValue)
> >> > }
> >> >
> >> > * use eval() instead of get() so you will find variables are in
> >> > ancestral environments
> >> > of envir (if envir is an environment), not just envir itself.
> >> > * just evaluate the stuff in the formula using the non-standard
> >> > evaluation frame,
> >> > call length() in the current frame.  Otherwise, if  envir inherits
> >> > directly from emptyenv() the 'length' function will not be found.
> >> > * use envir=data so it looks first in the data argument for variables
> >> > * the enclos argument is used if envir is not an environment and is
> used
> >> > to
> >> > find variables that are not in envir.
> >> >
> >> > Here are some examples:
> >> >   > X <- 1:10
> >> >   > getRHSLength(~X)
> >> >   [1] 10
> >> >   > getRHSLength(~X, data=data.frame(X=1:2))
> >> >   [1] 2
> >> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame())
> >> >   [1] 4
> >> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=data.frame(X=1:2))
> >> >   [1] 2
> >> >   > getRHSLength((function(){X <- 1:4; ~X})(),
> >> > data=list2env(data.frame()))
> >> >   [1] 10
> >> >   > getRHSLength((function(){X <- 1:4; ~X})(), data=emptyenv())
> >> >   Error in eval(expr, envir, enclos) : object 'X' not found
> >> >
> >> > I think you will see the same lookups if you try analogous things with
> >> > lm().
> >> > Bill Dunlap
> >> > TIBCO Software
> >> > wdunlap tibco.com
> >> >
> >> >
> >> > On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com>
> >> > wrote:
> >> >> Dear R gurus,
> >> >>
> >> >> I need to know the length of a variable (let's call that X) that is
> >> >> mentioned in a formula. So obviously I look for the environment from
> >> >> which
> >> >> the formula is called and then I have two options:
> >> >>
> >> >> - using eval(parse(text='length(X)'),
> >> >>                     envir=environment(formula) )
> >> >>
> >> >> - using length(get('X'),
> >> >>             envir=environment(formula) )
> >> >>
> >> >> a bit of benchmarking showed that the first option is about 20 times
> >> >> slower, to that extent that if I repeat it 10,000 times I save more
> >> >> than
> >> >> half a second. So speed is not really an issue here.
> >> >>
> >> >> Personally I'd go for option 2 as that one is easier to read and does
> >> >> the
> >> >> job nicely, but with these functions I'm always a bit afraid that I'm
> >> >> overseeing important details or side effects here (possibly memory
> >> >> issues
> >> >> when working with larger data).
> >> >>
> >> >> Anybody an idea what the dangers are of these methods, and which one
> is
> >> >> the
> >> >> most robust method?
> >> >>
> >> >> Thank you
> >> >> Joris
> >> >>
> >> >> --
> >> >> Joris Meys
> >> >> Statistical consultant
> >> >>
> >> >> Ghent University
> >> >> Faculty of Bioscience Engineering
> >> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
> >> >>
> >> >> tel : +32 9 264 59 87
> >> >> Joris.Meys at Ugent.be
> >> >> -------------------------------
> >> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> >
> >
> > --
> > Joris Meys
> > Statistical consultant
> >
> > Ghent University
> > Faculty of Bioscience Engineering
> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >
> > tel : +32 9 264 59 87
> > Joris.Meys at Ugent.be
> > -------------------------------
> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Sun Oct 19 05:49:43 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sat, 18 Oct 2014 20:49:43 -0700
Subject: [Rd] Writing UTF8 on Windows
Message-ID: <CABFfbXubKtLaq=Xio0X2LXhM_bPTmz=PKaiimX3RCmzr6-PUjg@mail.gmail.com>

Recent functionality in jsonlite allows for streaming json to a user
supplied connection object, such as a file, pipe or socket. RFC7159
prescribes json must be encoded as unicode; ISO-8859 (including
latin1) is invalid. Hence I would like R to write strings as utf8,
irrespective of the type of connection, platform or locale.
Implementing this turns out to be unsurprisingly difficult on windows.

> string <- enc2utf8("Z?rich")
> Encoding(string)
[1] "UTF-8"

For example when writing the utf8 string to a binary utf8 binary
connection, the output seems to be latin1:

> con <- file("test1.txt", open="wb", encoding = "UTF-8")
> writeLines(string, con)
> close(con)
> system("file test1.txt")
test1.txt: ISO-8859 text
> readLines("test1.txt", encoding="UTF-8")
[1] "Z\xfcrich"

I am not quite sure if this is a bug or expected. To avoid this and
other problems, jsonlite uses the 'useBytes` argument, which is
supposed to suppress re-encoding when writing to the connection. This
is exactly what we need: use enc2utf8 to convert our string to utf8
and then pass it byte-by-byte to the connection:

> con <- file("test2.txt", open="wb", encoding = "UTF-8")
> writeLines(string, con, useBytes = TRUE)
> close(con)
> system("file test2.txt")
test2.txt: UTF-8 Unicode text
> readLines("test2.txt", encoding="UTF-8")
[1] "Z?rich"

However useByes results in incorrect output for non-binary
connections. Not sure what is the intention here but it looks as if
the string gets re-encoded one time too often:

> con <- file("test3.txt", open="w", encoding = "UTF-8")
> writeLines(string, con, useBytes = TRUE)
> close(con)
> system("file test3.txt")
test3.txt: UTF-8 Unicode text, with CRLF line terminators
> readLines("test3.txt", encoding="UTF-8")
[1] "Z??rich

Strangely we do get utf8 output of we set the encoding of the
connection to latin1. This suggests that there *is* some re-encoding
going on, in contrast to what the useBytes manual states.

> con <- file("test4.txt", open="w", encoding = "latin1")
> writeLines(string, con, useBytes = TRUE)
> close(con)
> system("file test4.txt")
test4.txt: UTF-8 Unicode text, with CRLF line terminators
> readLines("test4.txt", encoding="UTF-8")
[1] "Z?rich"

However useBytes is definitely not ignored either, because disabling
it will (now correctly) write latin1 again:

> con <- file("test5.txt", open="w", encoding = "latin1")
> writeLines(string, con, useBytes = FALSE)
> close(con)
> system("file test5.txt")
test5.txt: ISO-8859 text, with CRLF line terminators
> readLines("test5.txt", encoding="UTF-8")
[1] "Z\xfcrich"

I am going to stop here. My primary question is: what is the best
method to write a utf8 string as utf8 to an arbitrary connection
object, without any re-encoding, that works on any platform and
locale.


From nalimilan at club.fr  Sun Oct 19 21:32:04 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sun, 19 Oct 2014 21:32:04 +0200
Subject: [Rd] Writing UTF8 on Windows
In-Reply-To: <CABFfbXubKtLaq=Xio0X2LXhM_bPTmz=PKaiimX3RCmzr6-PUjg@mail.gmail.com>
References: <CABFfbXubKtLaq=Xio0X2LXhM_bPTmz=PKaiimX3RCmzr6-PUjg@mail.gmail.com>
Message-ID: <1413747124.8379.15.camel@milan>

Le samedi 18 octobre 2014 ? 20:49 -0700, Jeroen Ooms a ?crit :
> Recent functionality in jsonlite allows for streaming json to a user
> supplied connection object, such as a file, pipe or socket. RFC7159
> prescribes json must be encoded as unicode; ISO-8859 (including
> latin1) is invalid. Hence I would like R to write strings as utf8,
> irrespective of the type of connection, platform or locale.
> Implementing this turns out to be unsurprisingly difficult on windows.
> 
> > string <- enc2utf8("Z?rich")
> > Encoding(string)
> [1] "UTF-8"
> 
> For example when writing the utf8 string to a binary utf8 binary
> connection, the output seems to be latin1:
> 
> > con <- file("test1.txt", open="wb", encoding = "UTF-8")
> > writeLines(string, con)
> > close(con)
> > system("file test1.txt")
> test1.txt: ISO-8859 text
> > readLines("test1.txt", encoding="UTF-8")
> [1] "Z\xfcrich"
The encoding argument doesn't do what you (quite logically I should say)
expect. You should create a connection just like you did above, and call
readLines() on that.

That may not fix your problem, though, since 'file' says the file is
ISO-8859-1. But sometimes 'file' may be mistaken since many bytes are
common to both encodings, so better check.

> I am not quite sure if this is a bug or expected. To avoid this and
> other problems, jsonlite uses the 'useBytes` argument, which is
> supposed to suppress re-encoding when writing to the connection. This
> is exactly what we need: use enc2utf8 to convert our string to utf8
> and then pass it byte-by-byte to the connection:
> 
> > con <- file("test2.txt", open="wb", encoding = "UTF-8")
> > writeLines(string, con, useBytes = TRUE)
> > close(con)
> > system("file test2.txt")
> test2.txt: UTF-8 Unicode text
> > readLines("test2.txt", encoding="UTF-8")
> [1] "Z?rich"
> 
> However useByes results in incorrect output for non-binary
> connections. Not sure what is the intention here but it looks as if
> the string gets re-encoded one time too often:
> 
> > con <- file("test3.txt", open="w", encoding = "UTF-8")
> > writeLines(string, con, useBytes = TRUE)
> > close(con)
> > system("file test3.txt")
> test3.txt: UTF-8 Unicode text, with CRLF line terminators
> > readLines("test3.txt", encoding="UTF-8")
> [1] "Z??rich
Same here.

> Strangely we do get utf8 output of we set the encoding of the
> connection to latin1. This suggests that there *is* some re-encoding
> going on, in contrast to what the useBytes manual states.
> 
> > con <- file("test4.txt", open="w", encoding = "latin1")
> > writeLines(string, con, useBytes = TRUE)
> > close(con)
> > system("file test4.txt")
> test4.txt: UTF-8 Unicode text, with CRLF line terminators
> > readLines("test4.txt", encoding="UTF-8")
> [1] "Z?rich"
> 
> However useBytes is definitely not ignored either, because disabling
> it will (now correctly) write latin1 again:
> 
> > con <- file("test5.txt", open="w", encoding = "latin1")
> > writeLines(string, con, useBytes = FALSE)
> > close(con)
> > system("file test5.txt")
> test5.txt: ISO-8859 text, with CRLF line terminators
> > readLines("test5.txt", encoding="UTF-8")
> [1] "Z\xfcrich"
Same here: you're reading the ISO-8859-1 data, and then without
re-encoding, considering it as UTF-8. This cannot be correct.

> I am going to stop here. My primary question is: what is the best
> method to write a utf8 string as utf8 to an arbitrary connection
> object, without any re-encoding, that works on any platform and
> locale.
Have you tried using writeBin()? It's documentation seems to imply it
could do what you want. But maybe writeLines() is enough, as the
problems you had above are more about reading than about writing.

Others should be able to give you more informed answers about writing.


Regards


From murdoch.duncan at gmail.com  Tue Oct 21 10:17:14 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Oct 2014 04:17:14 -0400
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <CADwqtCPfQjy+A9mtxHNmJXzsvemLfqvRNscUzoj4m_rLeC1ZSw@mail.gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CADwqtCPfQjy+A9mtxHNmJXzsvemLfqvRNscUzoj4m_rLeC1ZSw@mail.gmail.com>
Message-ID: <5446168A.9090407@gmail.com>

On 17/10/2014, 2:23 PM, Gabriel Becker wrote:
> Joris,
> 
> For me
> 
> length(environment(form)[["x"]])
> 
> Was about twice as fast as
> 
> length(get("x",environment(form))))
> 
> In the year-old version of R (3.0.2) that I have on the virtual machine i'm
> currently using.

Those are different:  get() will look in parent environments, but
indexing an environment won't.

For the original question:  you really have no guarantee that the
length() function will do what you want if you evaluate it in an
environment set by the user, so the approach with get is more robust.

Duncan Murdoch

> 
> As for you, the eval method was much slower (though my factor was much
> larger than 20)
> 
>> system.time({thing <- replicate(10000,length(environment(form)[["x"]]))})
>    user  system elapsed
>   0.018   0.000   0.018
>> system.time({thing <-
> replicate(10000,length(get("x",environment(form))))})   user  system
> elapsed
>   0.031   0.000   0.033
>> system.time({thing <- replicate(10000,eval(parse(text = "length(x)"),
> envir=environment(form)))})
>    user  system elapsed
>   4.528   0.003   4.656
> 
> I can't speak this second to whether this pattern will hold in the more
> modern versions of R I typically use.
> 
> ~G
> 
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> 
> 
> 
> 
> On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com> wrote:
> 
>> Dear R gurus,
>>
>> I need to know the length of a variable (let's call that X) that is
>> mentioned in a formula. So obviously I look for the environment from which
>> the formula is called and then I have two options:
>>
>> - using eval(parse(text='length(X)'),
>>                     envir=environment(formula) )
>>
>> - using length(get('X'),
>>             envir=environment(formula) )
>>
>> a bit of benchmarking showed that the first option is about 20 times
>> slower, to that extent that if I repeat it 10,000 times I save more than
>> half a second. So speed is not really an issue here.
>>
>> Personally I'd go for option 2 as that one is easier to read and does the
>> job nicely, but with these functions I'm always a bit afraid that I'm
>> overseeing important details or side effects here (possibly memory issues
>> when working with larger data).
>>
>> Anybody an idea what the dangers are of these methods, and which one is the
>> most robust method?
>>
>> Thank you
>> Joris
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Mathematical Modelling, Statistics and Bio-Informatics
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
>


From jorismeys at gmail.com  Tue Oct 21 11:06:50 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 21 Oct 2014 11:06:50 +0200
Subject: [Rd] Most efficient way to check the length of a variable
 mentioned in a formula.
In-Reply-To: <5446168A.9090407@gmail.com>
References: <CAO1zAVY9At1wJY7AvDYwzq-Q-JpNcQ1PpDvnAZgLWP9RDDKj5Q@mail.gmail.com>
	<CADwqtCPfQjy+A9mtxHNmJXzsvemLfqvRNscUzoj4m_rLeC1ZSw@mail.gmail.com>
	<5446168A.9090407@gmail.com>
Message-ID: <CAO1zAVbUGydmdhMRhZUGgZ7g2H5ucX2whYrSh1XvaRzbp5=mbg@mail.gmail.com>

Hi Duncan,

thanks for your reaction. I'm not following completely though what you mean
with "no guarantee that the length() function will do what I want if I
evaluate it in an environment set by the user". I wasn't intending to give
the user the opportunity to set those environments, but is there something
I'm overlooking there?

Cheers
Joris

On Tue, Oct 21, 2014 at 10:17 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 17/10/2014, 2:23 PM, Gabriel Becker wrote:
> > Joris,
> >
> > For me
> >
> > length(environment(form)[["x"]])
> >
> > Was about twice as fast as
> >
> > length(get("x",environment(form))))
> >
> > In the year-old version of R (3.0.2) that I have on the virtual machine
> i'm
> > currently using.
>
> Those are different:  get() will look in parent environments, but
> indexing an environment won't.
>
> For the original question:  you really have no guarantee that the
> length() function will do what you want if you evaluate it in an
> environment set by the user, so the approach with get is more robust.
>
> Duncan Murdoch
>
> >
> > As for you, the eval method was much slower (though my factor was much
> > larger than 20)
> >
> >> system.time({thing <-
> replicate(10000,length(environment(form)[["x"]]))})
> >    user  system elapsed
> >   0.018   0.000   0.018
> >> system.time({thing <-
> > replicate(10000,length(get("x",environment(form))))})   user  system
> > elapsed
> >   0.031   0.000   0.033
> >> system.time({thing <- replicate(10000,eval(parse(text = "length(x)"),
> > envir=environment(form)))})
> >    user  system elapsed
> >   4.528   0.003   4.656
> >
> > I can't speak this second to whether this pattern will hold in the more
> > modern versions of R I typically use.
> >
> > ~G
> >
> >> sessionInfo()
> > R version 3.0.2 (2013-09-25)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >
> >
> >
> >
> >
> > On Fri, Oct 17, 2014 at 11:04 AM, Joris Meys <jorismeys at gmail.com>
> wrote:
> >
> >> Dear R gurus,
> >>
> >> I need to know the length of a variable (let's call that X) that is
> >> mentioned in a formula. So obviously I look for the environment from
> which
> >> the formula is called and then I have two options:
> >>
> >> - using eval(parse(text='length(X)'),
> >>                     envir=environment(formula) )
> >>
> >> - using length(get('X'),
> >>             envir=environment(formula) )
> >>
> >> a bit of benchmarking showed that the first option is about 20 times
> >> slower, to that extent that if I repeat it 10,000 times I save more than
> >> half a second. So speed is not really an issue here.
> >>
> >> Personally I'd go for option 2 as that one is easier to read and does
> the
> >> job nicely, but with these functions I'm always a bit afraid that I'm
> >> overseeing important details or side effects here (possibly memory
> issues
> >> when working with larger data).
> >>
> >> Anybody an idea what the dangers are of these methods, and which one is
> the
> >> most robust method?
> >>
> >> Thank you
> >> Joris
> >>
> >> --
> >> Joris Meys
> >> Statistical consultant
> >>
> >> Ghent University
> >> Faculty of Bioscience Engineering
> >> Department of Mathematical Modelling, Statistics and Bio-Informatics
> >>
> >> tel : +32 9 264 59 87
> >> Joris.Meys at Ugent.be
> >> -------------------------------
> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From 2012111007 at njau.edu.cn  Tue Oct 21 14:14:03 2014
From: 2012111007 at njau.edu.cn (=?GBK?B?u8ayqQ==?=)
Date: Tue, 21 Oct 2014 20:14:03 +0800 (CST)
Subject: [Rd] How can I use R-function in My C++ project ?
Message-ID: <1f74c14.d1e7.14932a0ddbf.Coremail.2012111007@njau.edu.cn>

Dear seniors:
   I am a student in Nanjing Agricultural University of China.


   I want to use the  function "optim"  of package stats in my C++ project. I have got the R.dll , R.def and R.lib,


but I can't find the function prototypes of "optim" in R.def. 
  
   How  can  I  do ?  Is the Method I call R function in C++ with R.dll feasible ?  I hope to get your help ! Thanks 


for reading my question.


Yours sincerely,


Bo Huang
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Oct 21 15:22:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Oct 2014 09:22:19 -0400
Subject: [Rd] How can I use R-function in My C++ project ?
In-Reply-To: <1f74c14.d1e7.14932a0ddbf.Coremail.2012111007@njau.edu.cn>
References: <1f74c14.d1e7.14932a0ddbf.Coremail.2012111007@njau.edu.cn>
Message-ID: <54465E0B.60709@gmail.com>

On 21/10/2014 8:14 AM, ?? wrote:
> Dear seniors:
>     I am a student in Nanjing Agricultural University of China.
>
>
>     I want to use the  function "optim"  of package stats in my C++ project. I have got the R.dll , R.def and R.lib,
>
>
> but I can't find the function prototypes of "optim" in R.def.
>    
>     How  can  I  do ?  Is the Method I call R function in C++ with R.dll feasible ?  I hope to get your help ! Thanks
>
>

See section 6.8, "Optimization", in the Writing R Extensions manual.   I 
believe these functions require all of R, not just the Rmath library 
documented in the previous section.  If you want your C++ project to be 
in control, it will need to act as a "front-end", documented in Chapter 8.

Duncan Murdoch


From nashjc at uottawa.ca  Wed Oct 22 14:18:01 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 22 Oct 2014 08:18:01 -0400
Subject: [Rd]  How can I use R-function in My C++ project ? (using optim)
In-Reply-To: <mailman.27.1413972008.5560.r-devel@r-project.org>
References: <mailman.27.1413972008.5560.r-devel@r-project.org>
Message-ID: <5447A079.1050905@uottawa.ca>

As the author of 3 of the 5 methods in optim, I think you may be wasting
your time if this is for performance. My reasons are given in

http://www.jstatsoft.org/v60/i02

Note that most of the speed benefits of compilation are found in the
objective and gradient function, with generally more minor improvements
in the method.

JN


On 14-10-22 06:00 AM, r-devel-request at r-project.org wrote:
> Date: Tue, 21 Oct 2014 20:14:03 +0800 (CST)
> From: ?? <2012111007 at njau.edu.cn>
> To: R-devel at r-project.org
> Subject: [Rd] How can I use R-function in My C++ project ?
> Message-ID: <1f74c14.d1e7.14932a0ddbf.Coremail.2012111007 at njau.edu.cn>
> Content-Type: text/plain; charset="UTF-8"
> 
> Dear seniors:
>    I am a student in Nanjing Agricultural University of China.
> 
> 
>    I want to use the  function "optim"  of package stats in my C++ project. I have got the R.dll , R.def and R.lib,
> 
> 
> but I can't find the function prototypes of "optim" in R.def. 
>   
>    How  can  I  do ?  Is the Method I call R function in C++ with R.dll feasible ?  I hope to get your help ! Thanks 
> 
> 
> for reading my question.
> 
> 
> Yours sincerely,
> 
> 
> Bo Huang
> 	[[alternative HTML version deleted]]


From user3855417 at gmail.com  Wed Oct 22 16:53:31 2014
From: user3855417 at gmail.com (SO User)
Date: Wed, 22 Oct 2014 16:53:31 +0200
Subject: [Rd] Using a custom memory allocation function in R
Message-ID: <CACrQQoLKCDJnzBhut3Uhc3JErfe+=UQA-0GMbBGQR0pz+o90pQ@mail.gmail.com>

Heads up: I posted this question on Stackoverflow yesterday
(http://stackoverflow.com/questions/26484103/using-a-custom-memory-allocation-function-in-r).
So far I haven?t gotten a response and I thought this could be an even
better place to ask such a question.

I would like to be able to use my own memory allocation function for
certain data structures (real valued vectors and arrays) in R. The
reason for this is that I need my data to be 64bit aligned and I would
like to use the numa library for having control over which memory node
is used (I'm working on compute nodes with four 12-core AMD Opteron
6174 CPUs).

Now I have two functions for allocating and freeing memory:
numa_alloc_onnode and numa_free(courtesy of
http://stackoverflow.com/questions/8154162/numa-aware-cache-aligned-memory-allocation).
I'm using R version 3.1.1, so I have access to the function
allocVector3(src/main/memory.c), which seems to me as the intended way
of adding a custom memory allocator. I also found the struct
R_allocator in src/include/R_ext

However it is not clear to me how to put these pieces together. Let's
say, in R, I want the result res of an evaluation such as

res <- Y - mean(Y)

to be saved in a memory area allocated with my own function, how would
I do this? Can I integrate allocVector3 directly at the R level? I
assume I have to go through the R-C interface. As far as I know, I
cannot just return a pointer to the allocated area, but have to pass
the result as an argument. So in R I call something like

n <- length(Y)
res <- numeric(length=1)
.Call("R_allocate_using_myalloc", n, res)
res <- Y - mean(Y)

and in C

#include <R.h>
#include <Rinternals.h>
#include <numa.h>

SEXP R_allocate_using_myalloc(SEXP R_n, SEXP R_res){

  PROTECT(R_n = coerceVector(R_n, INTSXP));
  PROTECT(R_res = coerceVector(R_res, REALSXP));
  int *restrict n = INTEGER(R_n);

  R_allocator_t myAllocator;
  myAllocator.mem_alloc = numa_alloc_onnode;
  myAllocator.mem_free = numa_free;
  myAllocator.res = NULL;
  myAllocator.data = ???;

  R_res = allocVector3(REALSXP, n, myAllocator);

  UNPROTECT(2);
  return R_res;
}

Unfortunately I cannot get beyond a variable has incomplete type
'R_allocator_t' compilation error (I had to remove the .data line
since I have no clue as to what I should put there). Also the function
signature for numa_alloc_onnode is (size_t size, int node). How do I
pass the number of the memory node to the numa_alloc_onnode? Is that
somehow done through the .data field? Does any of the above code make
sense? Is there an easier way of achieving what I want to? It seems a
bit odd to have to allocate a small vector in R and the change its
location in memory in C just to be able to both control the memory
allocation and have the vector available in R...

I'm trying to avoid using Rcpp, as I'm modifying a fairly large
package and do not want to convert all C calls and thought that mixing
different C interfaces could perform sub-optimally.

Any help is greatly appreciated.


From m.pacey at lancaster.ac.uk  Wed Oct 22 18:01:30 2014
From: m.pacey at lancaster.ac.uk (Pacey, Mike)
Date: Wed, 22 Oct 2014 16:01:30 +0000
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
Message-ID: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>

Hi folks,

I suspect this is a request for a sanity check than a bug report:

I've been successfully compiling an optimised version of R for several years using the Intel compiler and MKL. I've just test-run the new Intel 15.0 compiler suite, and I'm seeing a few numeric failures that I don't see using the same build method with Intel 13.0. I've attached the output of "make check". Build details are below.

The most notable failures are in lapack.R, though I see from the comments in the output that different lapack and blas libraries may produce different signs for some outputs which can be safely ignored. My linear algebra's a bit rusty, so I'd like a sanity check: can all the sign differences be safely ignored in the attached output? (And a possible RFC: at least for the purposes of make check, can the scripts output abs() values for all cases where sign isn't an issue?)

The other failures are in stats-Ex.R. It looks like most of the problem lines are outputs from a PCA-like function, so their sign differences might due to the eigenvalue exception comment in lapack.R.

The final failures are in the "Grand Total" lines from stats-Ex.R. The values differ in the 7th sig fig, so a pretty small relative error. I think I'm using compiler flags that rule out any fast-math imprecisions - so I'm wondering if this result is actually within the acceptable variation of the IEE 754 standard?

Build details:

OS is Scientific Linux 6.4, architecture is Westmere.

"icc -v" gives: icc version 15.0.0 (gcc version 4.4.7 compatibility)

Environment variables are:

export CC=icc
export CFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export FC=ifort
export F77=ifort
export FFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export FCFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export CXX=icpc
export CXXFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export JAVA_HOME=/etc/alternatives/java_sdk_1.6.0

Configure command is:

./configure --with-blas=-mkl=sequential --with-lapack=-mkl=sequential --disable-openmp --with-tcl-config=/usr/shared_apps/packages/tcl-8.5.12/lib/tclConfig.sh --with-tk-config=/usr/shared_apps/packages/tk-8.5.12/lib/tkConfig.sh

Regards,
Mike.

-----

Dr Mike Pacey,                                          Email: M.Pacey at lancaster.ac.uk<mailto:M.Pacey at lancaster.ac.uk>
HPC Manager,                                            Phone: 01524 510659
Information Systems Services,            Fax: 01524 594459
ISS Building, Lancaster University,
Lancaster LA1 4WA


From nakama at ki.rim.or.jp  Thu Oct 23 08:01:53 2014
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 23 Oct 2014 15:01:53 +0900
Subject: [Rd] Using a custom memory allocation function in R
In-Reply-To: <CACrQQoLKCDJnzBhut3Uhc3JErfe+=UQA-0GMbBGQR0pz+o90pQ@mail.gmail.com>
References: <CACrQQoLKCDJnzBhut3Uhc3JErfe+=UQA-0GMbBGQR0pz+o90pQ@mail.gmail.com>
Message-ID: <CAJqeyYYOcu0FmYA_Lkw6qCgXzx2UEBivUG-TecKbP2v3_hGOpQ@mail.gmail.com>

hello,
I do not understand your aim...
it not helpful in malloc_hook? example when I used hugepege is right here.

http://prs.ism.ac.jp/~nakama/ISM/ism.c

However, I think that you can more experiments in numaclt(see man numactl).

2014-10-22 23:53 GMT+09:00 SO User <user3855417 at gmail.com>:
> Heads up: I posted this question on Stackoverflow yesterday
> (http://stackoverflow.com/questions/26484103/using-a-custom-memory-allocation-function-in-r).
> So far I haven't gotten a response and I thought this could be an even
> better place to ask such a question.
>
> I would like to be able to use my own memory allocation function for
> certain data structures (real valued vectors and arrays) in R. The
> reason for this is that I need my data to be 64bit aligned and I would
> like to use the numa library for having control over which memory node
> is used (I'm working on compute nodes with four 12-core AMD Opteron
> 6174 CPUs).
>
> Now I have two functions for allocating and freeing memory:
> numa_alloc_onnode and numa_free(courtesy of
> http://stackoverflow.com/questions/8154162/numa-aware-cache-aligned-memory-allocation).
> I'm using R version 3.1.1, so I have access to the function
> allocVector3(src/main/memory.c), which seems to me as the intended way
> of adding a custom memory allocator. I also found the struct
> R_allocator in src/include/R_ext
>
> However it is not clear to me how to put these pieces together. Let's
> say, in R, I want the result res of an evaluation such as
>
> res <- Y - mean(Y)
>
> to be saved in a memory area allocated with my own function, how would
> I do this? Can I integrate allocVector3 directly at the R level? I
> assume I have to go through the R-C interface. As far as I know, I
> cannot just return a pointer to the allocated area, but have to pass
> the result as an argument. So in R I call something like
>
> n <- length(Y)
> res <- numeric(length=1)
> .Call("R_allocate_using_myalloc", n, res)
> res <- Y - mean(Y)
>
> and in C
>
> #include <R.h>
> #include <Rinternals.h>
> #include <numa.h>
>
> SEXP R_allocate_using_myalloc(SEXP R_n, SEXP R_res){
>
>   PROTECT(R_n = coerceVector(R_n, INTSXP));
>   PROTECT(R_res = coerceVector(R_res, REALSXP));
>   int *restrict n = INTEGER(R_n);
>
>   R_allocator_t myAllocator;
>   myAllocator.mem_alloc = numa_alloc_onnode;
>   myAllocator.mem_free = numa_free;
>   myAllocator.res = NULL;
>   myAllocator.data = ???;
>
>   R_res = allocVector3(REALSXP, n, myAllocator);
>
>   UNPROTECT(2);
>   return R_res;
> }
>
> Unfortunately I cannot get beyond a variable has incomplete type
> 'R_allocator_t' compilation error (I had to remove the .data line
> since I have no clue as to what I should put there). Also the function
> signature for numa_alloc_onnode is (size_t size, int node). How do I
> pass the number of the memory node to the numa_alloc_onnode? Is that
> somehow done through the .data field? Does any of the above code make
> sense? Is there an easier way of achieving what I want to? It seems a
> bit odd to have to allocate a small vector in R and the change its
> location in memory in C just to be able to both control the memory
> allocation and have the vector available in R...
>
> I'm trying to avoid using Rcpp, as I'm modifying a fairly large
> package and do not want to convert all C calls and thought that mixing
> different C interfaces could perform sub-optimally.
>
> Any help is greatly appreciated.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From m.pacey at lancaster.ac.uk  Thu Oct 23 10:19:35 2014
From: m.pacey at lancaster.ac.uk (Pacey, Mike)
Date: Thu, 23 Oct 2014 08:19:35 +0000
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
In-Reply-To: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>
References: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>
Message-ID: <737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>

As my attachment doesn't seem to have survived transit, I'm cut'n'pasting the relevant failures here:

Testing examples for package 'stats'
  comparing 'stats-Ex.Rout' to 'stats-Ex.Rout.save' ...
6466c6466
< Grand Mean: 291.5937
---
> Grand Mean: 291.5938
12881c12881
< Murder   -0.536  0.418  0.341  0.649
---
> Murder   -0.536  0.418 -0.341  0.649
12882c12882
< Assault  -0.583  0.188  0.268 -0.743
---
> Assault  -0.583  0.188 -0.268 -0.743
12883c12883
< UrbanPop -0.278 -0.873  0.378  0.134
---
> UrbanPop -0.278 -0.873 -0.378  0.134
12884c12884
< Rape     -0.543 -0.167 -0.818       
---
> Rape     -0.543 -0.167  0.818       
14628c14628
< Grand Mean: 291.5937
---
> Grand Mean: 291.5938
15777c15777
< Murder   -0.54   0.42   0.34   0.65 
---
> Murder   -0.54   0.42  -0.34   0.65 
15778c15778
< Assault  -0.58          0.27  -0.74 
---
> Assault  -0.58         -0.27  -0.74 
15779c15779
< UrbanPop -0.28  -0.87   0.38        
---
> UrbanPop -0.28  -0.87  -0.38        
15780c15780
< Rape     -0.54         -0.82        
---
> Rape     -0.54          0.82       


running code in 'lapack.R' ... OK
  comparing 'lapack.Rout' to './lapack.Rout.save' ...23,31c23,31
<  [1,] -0.7245 -0.6266 -0.27350  0.08527 -0.02074 -0.004025
<  [2,] -0.4282  0.1299  0.64294 -0.55047  0.27253  0.092816
<  [3,] -0.3122  0.2804  0.33633  0.31418 -0.61632 -0.440904
<  [4,] -0.2479  0.3142  0.06931  0.44667 -0.02945  0.530120
<  [5,] -0.2064  0.3141 -0.10786  0.30242  0.35567  0.237038
<  [6,] -0.1771  0.3027 -0.22106  0.09042  0.38879 -0.260449
<  [7,] -0.1553  0.2877 -0.29281 -0.11551  0.19286 -0.420945
<  [8,] -0.1384  0.2722 -0.33784 -0.29313 -0.11633 -0.160790
<  [9,] -0.1249  0.2571 -0.36543 -0.43885 -0.46497  0.434600
---
>  [1,] -0.7245  0.6266  0.27350 -0.08527  0.02074 -0.004025
>  [2,] -0.4282 -0.1299 -0.64294  0.55047 -0.27253  0.092816
>  [3,] -0.3122 -0.2804 -0.33633 -0.31418  0.61632 -0.440904
>  [4,] -0.2479 -0.3142 -0.06931 -0.44667  0.02945  0.530120
>  [5,] -0.2064 -0.3141  0.10786 -0.30242 -0.35567  0.237038
>  [6,] -0.1771 -0.3027  0.22106 -0.09042 -0.38879 -0.260449
>  [7,] -0.1553 -0.2877  0.29281  0.11551 -0.19286 -0.420945
>  [8,] -0.1384 -0.2722  0.33784  0.29313  0.11633 -0.160790
>  [9,] -0.1249 -0.2571  0.36543  0.43885  0.46497  0.434600
35,40c35,40
< [1,] -0.7365 -0.6225 -0.2550  0.06976 -0.01328 -0.001588
< [2,] -0.4433  0.1819  0.6867 -0.50860  0.19627  0.041117
< [3,] -0.3275  0.3509  0.2611  0.50474 -0.61606 -0.259216
< [4,] -0.2626  0.3922 -0.1044  0.43748  0.40834  0.638902
< [5,] -0.2204  0.3946 -0.3510 -0.01612  0.46428 -0.675827
< [6,] -0.1904  0.3832 -0.5111 -0.53856 -0.44664  0.257249
---
> [1,] -0.7365  0.6225  0.2550 -0.06976  0.01328 -0.001588
> [2,] -0.4433 -0.1819 -0.6867  0.50860 -0.19627  0.041117
> [3,] -0.3275 -0.3509 -0.2611 -0.50474  0.61606 -0.259216
> [4,] -0.2626 -0.3922  0.1044 -0.43748 -0.40834  0.638902
> [5,] -0.2204 -0.3946  0.3510  0.01612 -0.46428 -0.675827
> [6,] -0.1904 -0.3832  0.5111  0.53856  0.44664  0.257249


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Pacey, Mike
Sent: 22 October 2014 17:02
To: r-devel at r-project.org
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R

Hi folks,

I suspect this is a request for a sanity check than a bug report:

I've been successfully compiling an optimised version of R for several years using the Intel compiler and MKL. I've just test-run the new Intel 15.0 compiler suite, and I'm seeing a few numeric failures that I don't see using the same build method with Intel 13.0. I've attached the output of "make check". Build details are below.

The most notable failures are in lapack.R, though I see from the comments in the output that different lapack and blas libraries may produce different signs for some outputs which can be safely ignored. My linear algebra's a bit rusty, so I'd like a sanity check: can all the sign differences be safely ignored in the attached output? (And a possible RFC: at least for the purposes of make check, can the scripts output abs() values for all cases where sign isn't an issue?)

The other failures are in stats-Ex.R. It looks like most of the problem lines are outputs from a PCA-like function, so their sign differences might due to the eigenvalue exception comment in lapack.R.

The final failures are in the "Grand Total" lines from stats-Ex.R. The values differ in the 7th sig fig, so a pretty small relative error. I think I'm using compiler flags that rule out any fast-math imprecisions - so I'm wondering if this result is actually within the acceptable variation of the IEE 754 standard?

Build details:

OS is Scientific Linux 6.4, architecture is Westmere.

"icc -v" gives: icc version 15.0.0 (gcc version 4.4.7 compatibility)

Environment variables are:

export CC=icc
export CFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export FC=ifort
export F77=ifort
export FFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export FCFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export CXX=icpc
export CXXFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
export JAVA_HOME=/etc/alternatives/java_sdk_1.6.0

Configure command is:

./configure --with-blas=-mkl=sequential --with-lapack=-mkl=sequential --disable-openmp --with-tcl-config=/usr/shared_apps/packages/tcl-8.5.12/lib/tclConfig.sh --with-tk-config=/usr/shared_apps/packages/tk-8.5.12/lib/tkConfig.sh

Regards,
Mike.

-----

Dr Mike Pacey,                                          Email: M.Pacey at lancaster.ac.uk<mailto:M.Pacey at lancaster.ac.uk>
HPC Manager,                                            Phone: 01524 510659
Information Systems Services,            Fax: 01524 594459
ISS Building, Lancaster University,
Lancaster LA1 4WA


From ripley at stats.ox.ac.uk  Thu Oct 23 11:32:55 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Oct 2014 10:32:55 +0100
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
In-Reply-To: <737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>
References: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>
	<737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>
Message-ID: <5448CB47.7010504@stats.ox.ac.uk>

You are using the word 'failure' in a sense I do not recognize. 
Differences are not of themselves errors and not necessarily failures. 
I see 'OK', not 'ERROR' here.

For the record, other builds using MKL (but gcc not icc) show similar 
differences, and the top of lapack.R says

## NB: the signs of singular and eigenvectors are arbitrary,
## so there may be differences from the reference ouptut,
## especially when alternative BLAS are used.

and e.g. ?prcomp says

Note:

      The signs of the columns of the rotation matrix are arbitrary, and
      so may differ between different programs for PCA, and even between
      different builds of R.

So AFAICS this is all documented behaviour.


On 23/10/2014 09:19, Pacey, Mike wrote:
> As my attachment doesn't seem to have survived transit, I'm cut'n'pasting the relevant failures here:
>
> Testing examples for package 'stats'
>    comparing 'stats-Ex.Rout' to 'stats-Ex.Rout.save' ...
> 6466c6466
> < Grand Mean: 291.5937
> ---
>> Grand Mean: 291.5938
> 12881c12881
> < Murder   -0.536  0.418  0.341  0.649
> ---
>> Murder   -0.536  0.418 -0.341  0.649
> 12882c12882
> < Assault  -0.583  0.188  0.268 -0.743
> ---
>> Assault  -0.583  0.188 -0.268 -0.743
> 12883c12883
> < UrbanPop -0.278 -0.873  0.378  0.134
> ---
>> UrbanPop -0.278 -0.873 -0.378  0.134
> 12884c12884
> < Rape     -0.543 -0.167 -0.818
> ---
>> Rape     -0.543 -0.167  0.818
> 14628c14628
> < Grand Mean: 291.5937
> ---
>> Grand Mean: 291.5938
> 15777c15777
> < Murder   -0.54   0.42   0.34   0.65
> ---
>> Murder   -0.54   0.42  -0.34   0.65
> 15778c15778
> < Assault  -0.58          0.27  -0.74
> ---
>> Assault  -0.58         -0.27  -0.74
> 15779c15779
> < UrbanPop -0.28  -0.87   0.38
> ---
>> UrbanPop -0.28  -0.87  -0.38
> 15780c15780
> < Rape     -0.54         -0.82
> ---
>> Rape     -0.54          0.82
>
>
> running code in 'lapack.R' ... OK
>    comparing 'lapack.Rout' to './lapack.Rout.save' ...23,31c23,31
> <  [1,] -0.7245 -0.6266 -0.27350  0.08527 -0.02074 -0.004025
> <  [2,] -0.4282  0.1299  0.64294 -0.55047  0.27253  0.092816
> <  [3,] -0.3122  0.2804  0.33633  0.31418 -0.61632 -0.440904
> <  [4,] -0.2479  0.3142  0.06931  0.44667 -0.02945  0.530120
> <  [5,] -0.2064  0.3141 -0.10786  0.30242  0.35567  0.237038
> <  [6,] -0.1771  0.3027 -0.22106  0.09042  0.38879 -0.260449
> <  [7,] -0.1553  0.2877 -0.29281 -0.11551  0.19286 -0.420945
> <  [8,] -0.1384  0.2722 -0.33784 -0.29313 -0.11633 -0.160790
> <  [9,] -0.1249  0.2571 -0.36543 -0.43885 -0.46497  0.434600
> ---
>>   [1,] -0.7245  0.6266  0.27350 -0.08527  0.02074 -0.004025
>>   [2,] -0.4282 -0.1299 -0.64294  0.55047 -0.27253  0.092816
>>   [3,] -0.3122 -0.2804 -0.33633 -0.31418  0.61632 -0.440904
>>   [4,] -0.2479 -0.3142 -0.06931 -0.44667  0.02945  0.530120
>>   [5,] -0.2064 -0.3141  0.10786 -0.30242 -0.35567  0.237038
>>   [6,] -0.1771 -0.3027  0.22106 -0.09042 -0.38879 -0.260449
>>   [7,] -0.1553 -0.2877  0.29281  0.11551 -0.19286 -0.420945
>>   [8,] -0.1384 -0.2722  0.33784  0.29313  0.11633 -0.160790
>>   [9,] -0.1249 -0.2571  0.36543  0.43885  0.46497  0.434600
> 35,40c35,40
> < [1,] -0.7365 -0.6225 -0.2550  0.06976 -0.01328 -0.001588
> < [2,] -0.4433  0.1819  0.6867 -0.50860  0.19627  0.041117
> < [3,] -0.3275  0.3509  0.2611  0.50474 -0.61606 -0.259216
> < [4,] -0.2626  0.3922 -0.1044  0.43748  0.40834  0.638902
> < [5,] -0.2204  0.3946 -0.3510 -0.01612  0.46428 -0.675827
> < [6,] -0.1904  0.3832 -0.5111 -0.53856 -0.44664  0.257249
> ---
>> [1,] -0.7365  0.6225  0.2550 -0.06976  0.01328 -0.001588
>> [2,] -0.4433 -0.1819 -0.6867  0.50860 -0.19627  0.041117
>> [3,] -0.3275 -0.3509 -0.2611 -0.50474  0.61606 -0.259216
>> [4,] -0.2626 -0.3922  0.1044 -0.43748 -0.40834  0.638902
>> [5,] -0.2204 -0.3946  0.3510  0.01612 -0.46428 -0.675827
>> [6,] -0.1904 -0.3832  0.5111  0.53856  0.44664  0.257249
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Pacey, Mike
> Sent: 22 October 2014 17:02
> To: r-devel at r-project.org
> Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
>
> Hi folks,
>
> I suspect this is a request for a sanity check than a bug report:
>
> I've been successfully compiling an optimised version of R for several years using the Intel compiler and MKL. I've just test-run the new Intel 15.0 compiler suite, and I'm seeing a few numeric failures that I don't see using the same build method with Intel 13.0. I've attached the output of "make check". Build details are below.
>
> The most notable failures are in lapack.R, though I see from the comments in the output that different lapack and blas libraries may produce different signs for some outputs which can be safely ignored. My linear algebra's a bit rusty, so I'd like a sanity check: can all the sign differences be safely ignored in the attached output? (And a possible RFC: at least for the purposes of make check, can the scripts output abs() values for all cases where sign isn't an issue?)
>
> The other failures are in stats-Ex.R. It looks like most of the problem lines are outputs from a PCA-like function, so their sign differences might due to the eigenvalue exception comment in lapack.R.
>
> The final failures are in the "Grand Total" lines from stats-Ex.R. The values differ in the 7th sig fig, so a pretty small relative error. I think I'm using compiler flags that rule out any fast-math imprecisions - so I'm wondering if this result is actually within the acceptable variation of the IEE 754 standard?
>
> Build details:
>
> OS is Scientific Linux 6.4, architecture is Westmere.
>
> "icc -v" gives: icc version 15.0.0 (gcc version 4.4.7 compatibility)
>
> Environment variables are:
>
> export CC=icc
> export CFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export FC=ifort
> export F77=ifort
> export FFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export FCFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export CXX=icpc
> export CXXFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export JAVA_HOME=/etc/alternatives/java_sdk_1.6.0
>
> Configure command is:
>
> ./configure --with-blas=-mkl=sequential --with-lapack=-mkl=sequential --disable-openmp --with-tcl-config=/usr/shared_apps/packages/tcl-8.5.12/lib/tclConfig.sh --with-tk-config=/usr/shared_apps/packages/tk-8.5.12/lib/tkConfig.sh
>
> Regards,
> Mike.
>
> -----
>
> Dr Mike Pacey,                                          Email: M.Pacey at lancaster.ac.uk<mailto:M.Pacey at lancaster.ac.uk>
> HPC Manager,                                            Phone: 01524 510659
> Information Systems Services,            Fax: 01524 594459
> ISS Building, Lancaster University,
> Lancaster LA1 4WA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From plummerm at iarc.fr  Thu Oct 23 11:46:28 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 23 Oct 2014 09:46:28 +0000
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
In-Reply-To: <737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>
References: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>
	<737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>
Message-ID: <1414057588.3225.4.camel@braque.iarc.fr>

On Thu, 2014-10-23 at 08:19 +0000, Pacey, Mike wrote:
> As my attachment doesn't seem to have survived transit, I'm cut'n'pasting the relevant failures here:
> 
> Testing examples for package 'stats'
>   comparing 'stats-Ex.Rout' to 'stats-Ex.Rout.save' ...
> 6466c6466
> < Grand Mean: 291.5937
> ---
> > Grand Mean: 291.5938

I see the same thing, but it is not as bad as it looks. The actual value
is 291.59375 so a small amount of numerical error can make the rounding
to 4 decimal places go either way:

> print(fit[[1]]$coefficients, digits=16)
      (Intercept) 
291.5937500000002 

Note that MKL sacrifices reproducibility (and hence precision) for
speed. See more details here:

https://software.intel.com/en-us/articles/run-reproducibility-with-intel-mkl-and-the-intel-compilers

Martyn

> 12881c12881
> < Murder   -0.536  0.418  0.341  0.649
> ---
> > Murder   -0.536  0.418 -0.341  0.649
> 12882c12882
> < Assault  -0.583  0.188  0.268 -0.743
> ---
> > Assault  -0.583  0.188 -0.268 -0.743
> 12883c12883
> < UrbanPop -0.278 -0.873  0.378  0.134
> ---
> > UrbanPop -0.278 -0.873 -0.378  0.134
> 12884c12884
> < Rape     -0.543 -0.167 -0.818       
> ---
> > Rape     -0.543 -0.167  0.818       
> 14628c14628
> < Grand Mean: 291.5937
> ---
> > Grand Mean: 291.5938
> 15777c15777
> < Murder   -0.54   0.42   0.34   0.65 
> ---
> > Murder   -0.54   0.42  -0.34   0.65 
> 15778c15778
> < Assault  -0.58          0.27  -0.74 
> ---
> > Assault  -0.58         -0.27  -0.74 
> 15779c15779
> < UrbanPop -0.28  -0.87   0.38        
> ---
> > UrbanPop -0.28  -0.87  -0.38        
> 15780c15780
> < Rape     -0.54         -0.82        
> ---
> > Rape     -0.54          0.82       
> 
> 
> running code in 'lapack.R' ... OK
>   comparing 'lapack.Rout' to './lapack.Rout.save' ...23,31c23,31
> <  [1,] -0.7245 -0.6266 -0.27350  0.08527 -0.02074 -0.004025
> <  [2,] -0.4282  0.1299  0.64294 -0.55047  0.27253  0.092816
> <  [3,] -0.3122  0.2804  0.33633  0.31418 -0.61632 -0.440904
> <  [4,] -0.2479  0.3142  0.06931  0.44667 -0.02945  0.530120
> <  [5,] -0.2064  0.3141 -0.10786  0.30242  0.35567  0.237038
> <  [6,] -0.1771  0.3027 -0.22106  0.09042  0.38879 -0.260449
> <  [7,] -0.1553  0.2877 -0.29281 -0.11551  0.19286 -0.420945
> <  [8,] -0.1384  0.2722 -0.33784 -0.29313 -0.11633 -0.160790
> <  [9,] -0.1249  0.2571 -0.36543 -0.43885 -0.46497  0.434600
> ---
> >  [1,] -0.7245  0.6266  0.27350 -0.08527  0.02074 -0.004025
> >  [2,] -0.4282 -0.1299 -0.64294  0.55047 -0.27253  0.092816
> >  [3,] -0.3122 -0.2804 -0.33633 -0.31418  0.61632 -0.440904
> >  [4,] -0.2479 -0.3142 -0.06931 -0.44667  0.02945  0.530120
> >  [5,] -0.2064 -0.3141  0.10786 -0.30242 -0.35567  0.237038
> >  [6,] -0.1771 -0.3027  0.22106 -0.09042 -0.38879 -0.260449
> >  [7,] -0.1553 -0.2877  0.29281  0.11551 -0.19286 -0.420945
> >  [8,] -0.1384 -0.2722  0.33784  0.29313  0.11633 -0.160790
> >  [9,] -0.1249 -0.2571  0.36543  0.43885  0.46497  0.434600
> 35,40c35,40
> < [1,] -0.7365 -0.6225 -0.2550  0.06976 -0.01328 -0.001588
> < [2,] -0.4433  0.1819  0.6867 -0.50860  0.19627  0.041117
> < [3,] -0.3275  0.3509  0.2611  0.50474 -0.61606 -0.259216
> < [4,] -0.2626  0.3922 -0.1044  0.43748  0.40834  0.638902
> < [5,] -0.2204  0.3946 -0.3510 -0.01612  0.46428 -0.675827
> < [6,] -0.1904  0.3832 -0.5111 -0.53856 -0.44664  0.257249
> ---
> > [1,] -0.7365  0.6225  0.2550 -0.06976  0.01328 -0.001588
> > [2,] -0.4433 -0.1819 -0.6867  0.50860 -0.19627  0.041117
> > [3,] -0.3275 -0.3509 -0.2611 -0.50474  0.61606 -0.259216
> > [4,] -0.2626 -0.3922  0.1044 -0.43748 -0.40834  0.638902
> > [5,] -0.2204 -0.3946  0.3510  0.01612 -0.46428 -0.675827
> > [6,] -0.1904 -0.3832  0.5111  0.53856  0.44664  0.257249
> 
> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Pacey, Mike
> Sent: 22 October 2014 17:02
> To: r-devel at r-project.org
> Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
> 
> Hi folks,
> 
> I suspect this is a request for a sanity check than a bug report:
> 
> I've been successfully compiling an optimised version of R for several years using the Intel compiler and MKL. I've just test-run the new Intel 15.0 compiler suite, and I'm seeing a few numeric failures that I don't see using the same build method with Intel 13.0. I've attached the output of "make check". Build details are below.
> 
> The most notable failures are in lapack.R, though I see from the comments in the output that different lapack and blas libraries may produce different signs for some outputs which can be safely ignored. My linear algebra's a bit rusty, so I'd like a sanity check: can all the sign differences be safely ignored in the attached output? (And a possible RFC: at least for the purposes of make check, can the scripts output abs() values for all cases where sign isn't an issue?)
> 
> The other failures are in stats-Ex.R. It looks like most of the problem lines are outputs from a PCA-like function, so their sign differences might due to the eigenvalue exception comment in lapack.R.
> 
> The final failures are in the "Grand Total" lines from stats-Ex.R. The values differ in the 7th sig fig, so a pretty small relative error. I think I'm using compiler flags that rule out any fast-math imprecisions - so I'm wondering if this result is actually within the acceptable variation of the IEE 754 standard?
> 
> Build details:
> 
> OS is Scientific Linux 6.4, architecture is Westmere.
> 
> "icc -v" gives: icc version 15.0.0 (gcc version 4.4.7 compatibility)
> 
> Environment variables are:
> 
> export CC=icc
> export CFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export FC=ifort
> export F77=ifort
> export FFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export FCFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export CXX=icpc
> export CXXFLAGS="-O3 -xHOST -axCORE-AVX-I -fp-model precise"
> export JAVA_HOME=/etc/alternatives/java_sdk_1.6.0
> 
> Configure command is:
> 
> ./configure --with-blas=-mkl=sequential --with-lapack=-mkl=sequential --disable-openmp --with-tcl-config=/usr/shared_apps/packages/tcl-8.5.12/lib/tclConfig.sh --with-tk-config=/usr/shared_apps/packages/tk-8.5.12/lib/tkConfig.sh
> 
> Regards,
> Mike.
> 
> -----
> 
> Dr Mike Pacey,                                          Email: M.Pacey at lancaster.ac.uk<mailto:M.Pacey at lancaster.ac.uk>
> HPC Manager,                                            Phone: 01524 510659
> Information Systems Services,            Fax: 01524 594459
> ISS Building, Lancaster University,
> Lancaster LA1 4WA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From m.pacey at lancaster.ac.uk  Thu Oct 23 12:14:15 2014
From: m.pacey at lancaster.ac.uk (Pacey, Mike)
Date: Thu, 23 Oct 2014 10:14:15 +0000
Subject: [Rd] "make check" fails on lapack.R and stats-Ex.R
In-Reply-To: <1414057588.3225.4.camel@braque.iarc.fr>
References: <737F5642A586344CA8A35D4826EFE56A15F0C6A9@EX-1-MB2.lancs.local>
	<737F5642A586344CA8A35D4826EFE56A15F0C7AE@EX-1-MB2.lancs.local>
	<1414057588.3225.4.camel@braque.iarc.fr>
Message-ID: <737F5642A586344CA8A35D4826EFE56A15F0C9B9@EX-1-MB2.lancs.local>

Hi Martyn,

Thanks for the analysis on that, and I'll remember that test in future - I've not seen a rounding error quite so finely balanced before. I've been using the "-fp-model precise" advice referenced in that document for a while - apparently it wasn't sufficient for this case.

Thanks also to Brian for sanity checking the linear algebra results in a previous post, and apologies for my imprecise terminology.

Regards,
Mike.

-----Original Message-----
From: Martyn Plummer [mailto:plummerm at iarc.fr] 
Sent: 23 October 2014 10:46
To: Pacey, Mike
Cc: r-devel at r-project.org
Subject: Re: [Rd] "make check" fails on lapack.R and stats-Ex.R

On Thu, 2014-10-23 at 08:19 +0000, Pacey, Mike wrote:
> As my attachment doesn't seem to have survived transit, I'm cut'n'pasting the relevant failures here:
> 
> Testing examples for package 'stats'
>   comparing 'stats-Ex.Rout' to 'stats-Ex.Rout.save' ...
> 6466c6466
> < Grand Mean: 291.5937
> ---
> > Grand Mean: 291.5938

I see the same thing, but it is not as bad as it looks. The actual value is 291.59375 so a small amount of numerical error can make the rounding to 4 decimal places go either way:

> print(fit[[1]]$coefficients, digits=16)
      (Intercept)
291.5937500000002 

Note that MKL sacrifices reproducibility (and hence precision) for speed. See more details here:

https://software.intel.com/en-us/articles/run-reproducibility-with-intel-mkl-and-the-intel-compilers

Martyn


From simon.urbanek at r-project.org  Thu Oct 23 21:24:23 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 23 Oct 2014 15:24:23 -0400
Subject: [Rd] Using a custom memory allocation function in R
In-Reply-To: <CACrQQoLKCDJnzBhut3Uhc3JErfe+=UQA-0GMbBGQR0pz+o90pQ@mail.gmail.com>
References: <CACrQQoLKCDJnzBhut3Uhc3JErfe+=UQA-0GMbBGQR0pz+o90pQ@mail.gmail.com>
Message-ID: <07E6A54E-9428-4FC8-BE31-DDF64EE52053@r-project.org>

SO,

On Oct 22, 2014, at 10:53 AM, SO User <user3855417 at gmail.com> wrote:
> 
> Heads up: I posted this question on Stackoverflow yesterday
> (http://stackoverflow.com/questions/26484103/using-a-custom-memory-allocation-function-in-r).
> So far I haven?t gotten a response and I thought this could be an even
> better place to ask such a question.
> 
> I would like to be able to use my own memory allocation function for
> certain data structures (real valued vectors and arrays) in R. The
> reason for this is that I need my data to be 64bit aligned and I would
> like to use the numa library for having control over which memory node
> is used (I'm working on compute nodes with four 12-core AMD Opteron
> 6174 CPUs).
> 
> Now I have two functions for allocating and freeing memory:
> numa_alloc_onnode and numa_free(courtesy of
> http://stackoverflow.com/questions/8154162/numa-aware-cache-aligned-memory-allocation).
> I'm using R version 3.1.1, so I have access to the function
> allocVector3(src/main/memory.c), which seems to me as the intended way
> of adding a custom memory allocator. I also found the struct
> R_allocator in src/include/R_ext
> 
> However it is not clear to me how to put these pieces together. Let's
> say, in R, I want the result res of an evaluation such as
> 
> res <- Y - mean(Y)
> 
> to be saved in a memory area allocated with my own function, how would
> I do this? Can I integrate allocVector3 directly at the R level? I
> assume I have to go through the R-C interface. As far as I know, I
> cannot just return a pointer to the allocated area, but have to pass
> the result as an argument. So in R I call something like
> 
> n <- length(Y)
> res <- numeric(length=1)
> .Call("R_allocate_using_myalloc", n, res)
> res <- Y - mean(Y)
> 

That obviously won't work, because you're replacing your "res" with another binding - effectively removing anything you did. You could use something like

res <- .Call("R_allocate_using_myalloc", Y - mean(y))

if you wanted to convert "regular" R object into your own backed store.

However, the intent is typically to create objects with special backing store in your C code. One example are mmaped R objects - see
https://gist.github.com/s-u/6712c97ca74181f5a1a5
for an example.


> and in C
> 
> #include <R.h>
> #include <Rinternals.h>
> #include <numa.h>
> 

You are missing

#include <R_ext/Rallocators.h>



> SEXP R_allocate_using_myalloc(SEXP R_n, SEXP R_res){
> 
>  PROTECT(R_n = coerceVector(R_n, INTSXP));
>  PROTECT(R_res = coerceVector(R_res, REALSXP));
>  int *restrict n = INTEGER(R_n);
> 
>  R_allocator_t myAllocator;
>  myAllocator.mem_alloc = numa_alloc_onnode;
>  myAllocator.mem_free = numa_free;
>  myAllocator.res = NULL;
>  myAllocator.data = ???;
> 
>  R_res = allocVector3(REALSXP, n, myAllocator);
> 
>  UNPROTECT(2);
>  return R_res;
> }
> 
> Unfortunately I cannot get beyond a variable has incomplete type
> 'R_allocator_t' compilation error

Missed include above.


> (I had to remove the .data line
> since I have no clue as to what I should put there).

data is an opaque pointer that you can use for anything you want - R doesn't use it, it just passes it through so you can have auxiliary information attached to your allocation.


> Also the function
> signature for numa_alloc_onnode is (size_t size, int node). How do I
> pass the number of the memory node to the numa_alloc_onnode? Is that
> somehow done through the .data field?

Yes, you can supply it from your initiator function (just like the filename is passed in the mmap example).


> Does any of the above code make
> sense? Is there an easier way of achieving what I want to? It seems a
> bit odd to have to allocate a small vector in R and the change its
> location in memory in C just to be able to both control the memory
> allocation and have the vector available in R...
> 
> I'm trying to avoid using Rcpp, as I'm modifying a fairly large
> package and do not want to convert all C calls and thought that mixing
> different C interfaces could perform sub-optimally.
> 

AFAICT Rcpp wouldn't help you there - since it still has to go back to R for allocation of R objects.

Cheers,
Simon


> Any help is greatly appreciated.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Oct 24 05:10:19 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 23 Oct 2014 20:10:19 -0700
Subject: [Rd] No error when assigning values to an "empty"
	vector/matrix/array
Message-ID: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>

Assigning one or more values to a vector/matrix/array x for which
length(x) == 0 gives no error, e.g.

> x <- integer(0)
> x[] <- 1:2

> x <- matrix(nrow=0, ncol=1)
> x[] <- 1:2
> x[,1] <- 1:2

> x <- array(dim=c(0,1,1))
> x[] <- 1:2
> x[,1,1] <- 1:2

whereas

> x <- integer(1)
> x[] <- 1:2
Warning message:
In x[] <- 1:2 :
  number of items to replace is not a multiple of replacement length
> x <- matrix(nrow=1, ncol=1)
> x[] <- 1:2
Warning message:
In x[] <- 1:2 :
  number of items to replace is not a multiple of replacement length
> x[,1] <- 1:2
Error in x[, 1] <- 1:2 :
  number of items to replace is not a multiple of replacement length
> x <- array(dim=c(1,1,1))
> x[] <- 1:2
Warning message:
In x[] <- 1:2 :
  number of items to replace is not a multiple of replacement length
> x[,1,1] <- 1:2
Error in x[, 1, 1] <- 1:2 :
  number of items to replace is not a multiple of replacement length

Is this intended by design or is it a bug that should be reported?

/Henrik


From hpages at fhcrc.org  Fri Oct 24 10:58:44 2014
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 24 Oct 2014 01:58:44 -0700
Subject: [Rd] No error when assigning values to an "empty"
	vector/matrix/array
In-Reply-To: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>
References: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>
Message-ID: <544A14C4.6040608@fhcrc.org>

Hi Henrik,

On 10/23/2014 08:10 PM, Henrik Bengtsson wrote:
> Assigning one or more values to a vector/matrix/array x for which
> length(x) == 0 gives no error, e.g.
>
>> x <- integer(0)
>> x[] <- 1:2
>
>> x <- matrix(nrow=0, ncol=1)
>> x[] <- 1:2
>> x[,1] <- 1:2
>
>> x <- array(dim=c(0,1,1))
>> x[] <- 1:2
>> x[,1,1] <- 1:2
>
> whereas
>
>> x <- integer(1)
>> x[] <- 1:2
> Warning message:
> In x[] <- 1:2 :
>    number of items to replace is not a multiple of replacement length
>> x <- matrix(nrow=1, ncol=1)
>> x[] <- 1:2
> Warning message:
> In x[] <- 1:2 :
>    number of items to replace is not a multiple of replacement length
>> x[,1] <- 1:2
> Error in x[, 1] <- 1:2 :
>    number of items to replace is not a multiple of replacement length
>> x <- array(dim=c(1,1,1))
>> x[] <- 1:2
> Warning message:
> In x[] <- 1:2 :
>    number of items to replace is not a multiple of replacement length
>> x[,1,1] <- 1:2
> Error in x[, 1, 1] <- 1:2 :
>    number of items to replace is not a multiple of replacement length
>
> Is this intended by design or is it a bug that should be reported?

Since [<- supports truncating of the right value, why an exception
should be made when the left vector has length 0?

Also note that these warnings or errors are complaining that the number
of items to replace (left length) is not a multiple of replacement
length (right length). This suggests that when the left length is a
multiple of the right length, everything is fine.
And this is actually the case when the left length is 0. Because
0 is a multiple of anything. So in that case, the right value is
truncated to length 0 and no warning is issued. Makes sense to me.

Cheers,
H.

>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hb at biostat.ucsf.edu  Fri Oct 24 15:34:07 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 24 Oct 2014 06:34:07 -0700
Subject: [Rd] No error when assigning values to an "empty"
	vector/matrix/array
In-Reply-To: <544A14C4.6040608@fhcrc.org>
References: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>
	<544A14C4.6040608@fhcrc.org>
Message-ID: <CAFDcVCQ+EODm1LXHyfFAfC5a3YrSUwt3-RL30=5bxdQaiAEy1Q@mail.gmail.com>

On Oct 24, 2014 1:59 AM, "Herv? Pag?s" <hpages at fhcrc.org> wrote:
>
> Hi Henrik,
>
>
> On 10/23/2014 08:10 PM, Henrik Bengtsson wrote:
>>
>> Assigning one or more values to a vector/matrix/array x for which
>> length(x) == 0 gives no error, e.g.
>>
>>> x <- integer(0)
>>> x[] <- 1:2
>>
>>
>>> x <- matrix(nrow=0, ncol=1)
>>> x[] <- 1:2
>>> x[,1] <- 1:2
>>
>>
>>> x <- array(dim=c(0,1,1))
>>> x[] <- 1:2
>>> x[,1,1] <- 1:2
>>
>>
>> whereas
>>
>>> x <- integer(1)
>>> x[] <- 1:2
>>
>> Warning message:
>> In x[] <- 1:2 :
>>    number of items to replace is not a multiple of replacement length
>>>
>>> x <- matrix(nrow=1, ncol=1)
>>> x[] <- 1:2
>>
>> Warning message:
>> In x[] <- 1:2 :
>>    number of items to replace is not a multiple of replacement length
>>>
>>> x[,1] <- 1:2
>>
>> Error in x[, 1] <- 1:2 :
>>    number of items to replace is not a multiple of replacement length
>>>
>>> x <- array(dim=c(1,1,1))
>>> x[] <- 1:2
>>
>> Warning message:
>> In x[] <- 1:2 :
>>    number of items to replace is not a multiple of replacement length
>>>
>>> x[,1,1] <- 1:2
>>
>> Error in x[, 1, 1] <- 1:2 :
>>    number of items to replace is not a multiple of replacement length
>>
>> Is this intended by design or is it a bug that should be reported?
>
>
> Since [<- supports truncating of the right value, why an exception
> should be made when the left vector has length 0?
>
> Also note that these warnings or errors are complaining that the number
> of items to replace (left length) is not a multiple of replacement
> length (right length). This suggests that when the left length is a
> multiple of the right length, everything is fine.
> And this is actually the case when the left length is 0. Because
> 0 is a multiple of anything. So in that case, the right value is
> truncated to length 0 and no warning is issued. Makes sense to me.

Thanks Herv?, you gave the perfect explanation/rationale for this being
consistent.

Henrik

PS. The background to my question was that I had a function that populated
a zero-row matrix column by column with values. These values were in turn
generated by another function that incorrectly read all values available in
for when indeed requestion zero (treating NULL ["read all"] and integer(0)
["read none"] equally). An implementation error that indeed gave the
correct value in the end, although in an extremely inefficient way.

>
> Cheers,
> H.
>
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319

	[[alternative HTML version deleted]]


From enrico.bibbona at unito.it  Fri Oct 24 15:43:19 2014
From: enrico.bibbona at unito.it (Enrico Bibbona)
Date: Fri, 24 Oct 2014 15:43:19 +0200
Subject: [Rd] package checking apparently ok but R-forge version does not
	build
Message-ID: <CAFvnaTY83msttbcoxiKCCfbmvRHwB9johuYxxdX8c4F5CPWDmQ@mail.gmail.com>

Dear r developers,
I'm writing a set of new functions for an existing R package on R-forge
(called COGARCH).
I wrote the new R code (but still no documentation), and updated the
NAMESPACE file.
I installed it from my local repository and everything seems to work.
I checked the local repository and the check did not produces errors, but 2
warnings and 2 notes (I attach the log) one of which just tell that there
is no documentation and the other were already present in previous versions.
However on R-forge the package is in building stutus and actually it does
not build.
Any suggestion? Does everything depend on the missing documentation?
The best Enrico

-- 
Enrico Bibbona
Dipartimento di Matematica
Universit? di Torino
https://sites.google.com/site/enricobibbona/

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri Oct 24 15:58:06 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 24 Oct 2014 14:58:06 +0100
Subject: [Rd] No error when assigning values to an
	"empty"	vector/matrix/array
In-Reply-To: <CAFDcVCQ+EODm1LXHyfFAfC5a3YrSUwt3-RL30=5bxdQaiAEy1Q@mail.gmail.com>
References: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>
	<544A14C4.6040608@fhcrc.org>
	<CAFDcVCQ+EODm1LXHyfFAfC5a3YrSUwt3-RL30=5bxdQaiAEy1Q@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412CC4B4F@GOLD.corp.lgc-group.com>

> > Also note that these warnings or errors are complaining that the
> > number of items to replace (left length) is not a multiple of
> > replacement length (right length). This suggests that when the left
> > length is a multiple of the right length, everything is fine.
> > And this is actually the case when the left length is 0. Because
> > 0 is a multiple of anything. So in that case, the right value is
> > truncated to length 0 and no warning is issued. Makes sense to me.
> 
> Thanks Herv?, you gave the perfect explanation/rationale for this being
> consistent.

This explains why a check for exact multiple of replacement length does not trigger a warning, but surely that is not sensible in the length 0 case. In all other cases, this check warns when there will be truncation of the replacement, and that seems to me the sensible intent of the check. A silent truncation to nothing is surely not the intended behaviour.
I can't help feeling that the 'check for multiple of length' was a neat portmanteau check for several possible problems when recycling is allowed, but that the possibility of assigning to a length 0 object was not considered.

I'd suggest logging it as an issue to for R-core to at least look at and either to fix or to at least warn of in documentation.

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From S.Ellison at LGCGroup.com  Fri Oct 24 16:07:13 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 24 Oct 2014 15:07:13 +0100
Subject: [Rd] package checking apparently ok but R-forge version does
 not	build
In-Reply-To: <CAFvnaTY83msttbcoxiKCCfbmvRHwB9johuYxxdX8c4F5CPWDmQ@mail.gmail.com>
References: <CAFvnaTY83msttbcoxiKCCfbmvRHwB9johuYxxdX8c4F5CPWDmQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412CC4B5D@GOLD.corp.lgc-group.com>

> However on R-forge the package is in building stutus and actually it does not
> build.
> Any suggestion? Does everything depend on the missing documentation?
The advice I'd expect is to make sure there are neither errors no warnings, as CRAN guardians are (rightly) reluctant to tolerate either. And a package without documentation is unlikely to help anyone else much anyway - even the author, in six months time - so that really should be there.

A secondary issue might be a difference in R version; are you running your r cmd check with the R version currently used by R forge? The checks change over time and with R version.

Finally, have you checked the log on R forge to see whether the check is returning the same warnings/errors that you see locally?

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From Mike.Beddo at dataventures.com  Fri Oct 24 18:44:49 2014
From: Mike.Beddo at dataventures.com (Mike Beddo)
Date: Fri, 24 Oct 2014 16:44:49 +0000
Subject: [Rd] Error: Line starting 'Package: tools ...' is malformed!
Message-ID: <AA01911644A2F84FB4571C323FC45DD56A521455@TWIX.dataventures.local>

I'm building R-3.1.1 (64 bit) from source on AIX 7.1. It was going well until I hit this:

xlc_r -q64 -Wl,-brtl -Wl,-G -Wl,-bexpall -Wl,-bnoentry -lc -L/opt/freeware/lib64 -L/opt/freeware/lib -Wl,-blibpath:/opt/freeware/lib64:/opt/freeware/lib:/usr/lib:/lib -Wl,-bmaxdata:0x80000000 -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o -lm
make[6]: Entering directory `/home/meb/source/R-3.1.1/src/library/tools/src'
mkdir -p -- ../../../../library/tools/libs
make[6]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
make[5]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
make[4]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
Error: Line starting 'Package: tools ...' is malformed!
Execution halted
make[3]: *** [all] Error 1
make[3]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/meb/source/R-3.1.1/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/meb/source/R-3.1.1/src'
make: *** [R] Error 1
$ oslevel
7.1.0.0

Can someone help?

Thanks,

Mike


From hpages at fhcrc.org  Fri Oct 24 18:46:49 2014
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 24 Oct 2014 09:46:49 -0700
Subject: [Rd] No error when assigning values to an
	"empty"	vector/matrix/array
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED6412CC4B4F@GOLD.corp.lgc-group.com>
References: <CAFDcVCQWWDvfSmiapMWBJ75WmMzyAMYsndmJaJp1r=-uzG7yXQ@mail.gmail.com>	<544A14C4.6040608@fhcrc.org>	<CAFDcVCQ+EODm1LXHyfFAfC5a3YrSUwt3-RL30=5bxdQaiAEy1Q@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED6412CC4B4F@GOLD.corp.lgc-group.com>
Message-ID: <544A8279.1060706@fhcrc.org>

Hi,

On 10/24/2014 06:58 AM, S Ellison wrote:
>>> Also note that these warnings or errors are complaining that the
>>> number of items to replace (left length) is not a multiple of
>>> replacement length (right length). This suggests that when the left
>>> length is a multiple of the right length, everything is fine.
>>> And this is actually the case when the left length is 0. Because
>>> 0 is a multiple of anything. So in that case, the right value is
>>> truncated to length 0 and no warning is issued. Makes sense to me.
>>
>> Thanks Herv?, you gave the perfect explanation/rationale for this being
>> consistent.
>
> This explains why a check for exact multiple of replacement length does not trigger a warning, but surely that is not sensible in the length 0 case. In all other cases, this check warns when there will be truncation of the replacement, and that seems to me the sensible intent of the check. A silent truncation to nothing is surely not the intended behaviour.

Yes truncation should not be silent. But truncation to length zero
should not be seen as a special case either. What would be more
sensible is that [<- recognizes the 2 distinct situations that
deserve a warning:
   1. Truncation (i.e. when left length is < right length).
   2. Left length is > right length AND left length is not a multiple
      of right length.
Then the warning we get should be clear about which situation was
detected. So we would get a sensible warning all the time, even
when left length is 0.

H.

> I can't help feeling that the 'check for multiple of length' was a neat portmanteau check for several possible problems when recycling is allowed, but that the possibility of assigning to a length 0 object was not considered.
>
> I'd suggest logging it as an issue to for R-core to at least look at and either to fix or to at least warn of in documentation.
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:26}}


From Mike.Beddo at dataventures.com  Fri Oct 24 20:15:29 2014
From: Mike.Beddo at dataventures.com (Mike Beddo)
Date: Fri, 24 Oct 2014 18:15:29 +0000
Subject: [Rd] AIX build R-3.1.1 Matrix package fails
Message-ID: <AA01911644A2F84FB4571C323FC45DD56A521597@TWIX.dataventures.local>

Problems building the recommended packages from R-3.1.1 source:

** building package indices
Loading required package: Matrix
Error in dyn.load(file, DLLpath = DLLpath, ...) : 
  unable to load shared object '/home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so':
  rtld: 0712-001 Symbol dtrsv_ was referenced
      from module /home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712-001 Symbol dgemv_ was referenced
      from module /home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712-001 Symbol dtrsm_ was referenced
      from module /home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712-001 Symbol dgemm_ was referenced
      from module /home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712-001 Symbol ztrsv_ was referenced
      from module /home/meb/source/R-3.1.1/library/Matrix/libs/Matrix.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712
Error : require(Matrix) is not TRUE
ERROR: installing package indices failed
* removing '/home/meb/source/R-3.1.1/library/Matrix'
make[2]: *** [Matrix.ts] Error 1
make[2]: Leaving directory `/home/meb/source/R-3.1.1/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory `/home/meb/source/R-3.1.1/src/library/Recommended'
make: *** [stamp-recommended] Error 2

- Mike


From murdoch.duncan at gmail.com  Sat Oct 25 11:33:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 25 Oct 2014 05:33:56 -0400
Subject: [Rd] Error: Line starting 'Package: tools ...' is malformed!
In-Reply-To: <AA01911644A2F84FB4571C323FC45DD56A521455@TWIX.dataventures.local>
References: <AA01911644A2F84FB4571C323FC45DD56A521455@TWIX.dataventures.local>
Message-ID: <544B6E84.2050606@gmail.com>

On 24/10/2014, 12:44 PM, Mike Beddo wrote:
> I'm building R-3.1.1 (64 bit) from source on AIX 7.1. It was going well until I hit this:
> 
> xlc_r -q64 -Wl,-brtl -Wl,-G -Wl,-bexpall -Wl,-bnoentry -lc -L/opt/freeware/lib64 -L/opt/freeware/lib -Wl,-blibpath:/opt/freeware/lib64:/opt/freeware/lib:/usr/lib:/lib -Wl,-bmaxdata:0x80000000 -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o -lm
> make[6]: Entering directory `/home/meb/source/R-3.1.1/src/library/tools/src'
> mkdir -p -- ../../../../library/tools/libs
> make[6]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
> make[5]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
> make[4]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
> Error: Line starting 'Package: tools ...' is malformed!
> Execution halted
> make[3]: *** [all] Error 1
> make[3]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/meb/source/R-3.1.1/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/meb/source/R-3.1.1/src'
> make: *** [R] Error 1
> $ oslevel
> 7.1.0.0
> 
> Can someone help?

That error looks as though it is coming from R when it is trying to read
a DCF file, most likely the DESCRIPTION file for the tools package.
Have you edited that file?

Duncan Murdoch


From mmuurr at gmail.com  Mon Oct 27 02:49:01 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Sun, 26 Oct 2014 19:49:01 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
Message-ID: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>

Hi all, I have a question about finalizers...
I have a package that manages state for a few connections, and I'd
like to ensure that these connections are 'cleanly' closed upon either
(i) R quitting or (ii) an unloading of the package.
So, in a pared-down example package with a single R file, it looks
something like:

##### BEGIN PACKAGE CODE #####
.CONNS <- new.env(parent = emptyenv())
.CONNS$resource1 <- NULL
.CONNS$resource2 <- NULL
## some more .CONNS resources...

reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)

connect <- function(x) {
  ## here lies code to connect and update .CONNS[[x]]
}
disconnect <- function(x) {
  print(sprintf("disconnect(%s)", x))
  ## here lies code to disconnect and update .CONNS[[x]]
}
##### END PACKAGE CODE #####

The print(...) statement in disconnect(...) is there as a trace, as I
hoped that I'd see disconnect(...) being called when I quit (or
detach(..., unload = TRUE)).
But, it doesn't appear that disconnect(...) is ever called when the
package (and .CONNS) falls out of memory/scope (and I ran gc() after
detach(...), just to be sure).

In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
call inside an .onLoad function, but that didn't seem to work, either.

I'm guessing my use of reg.finalizer is way off-base here... but I
cannot infer from the reg.finalizer man page what I might be doing
wrong.
Is there a way to see, at the R-system level, what functions have been
registered as finalizers?

Thanks for any pointers!

-Murat


From csardi.gabor at gmail.com  Mon Oct 27 03:03:56 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 26 Oct 2014 22:03:56 -0400
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
Message-ID: <CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>

Hmmm, I guess you will want to put the actual objects that represent
the connections into the environment, at least this seems to be the
easiest to me. Btw. you need ls() to list the contents of an
environment, instead of names(). E.g.

e <- new.env()
e$foo <- 10
e$bar <- "aaa"
names(e)
#> NULL
ls(e)
#> [1] "bar" "foo"
reg.finalizer(e, function(x) { print(ls(x)) })
#> NULL
rm(e)
gc()
#> [1] "bar" "foo"
#>           used (Mb) gc trigger  (Mb) max used  (Mb)
#> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
#> Vcells 3752538 28.7    7930384  60.6  7930356  60.6

More precisely, you probably want to represent each connection as a
separate environment, with its own finalizer. Hope this helps,
Gabor

On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Hi all, I have a question about finalizers...
> I have a package that manages state for a few connections, and I'd
> like to ensure that these connections are 'cleanly' closed upon either
> (i) R quitting or (ii) an unloading of the package.
> So, in a pared-down example package with a single R file, it looks
> something like:
>
> ##### BEGIN PACKAGE CODE #####
> .CONNS <- new.env(parent = emptyenv())
> .CONNS$resource1 <- NULL
> .CONNS$resource2 <- NULL
> ## some more .CONNS resources...
>
> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)
>
> connect <- function(x) {
>   ## here lies code to connect and update .CONNS[[x]]
> }
> disconnect <- function(x) {
>   print(sprintf("disconnect(%s)", x))
>   ## here lies code to disconnect and update .CONNS[[x]]
> }
> ##### END PACKAGE CODE #####
>
> The print(...) statement in disconnect(...) is there as a trace, as I
> hoped that I'd see disconnect(...) being called when I quit (or
> detach(..., unload = TRUE)).
> But, it doesn't appear that disconnect(...) is ever called when the
> package (and .CONNS) falls out of memory/scope (and I ran gc() after
> detach(...), just to be sure).
>
> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
> call inside an .onLoad function, but that didn't seem to work, either.
>
> I'm guessing my use of reg.finalizer is way off-base here... but I
> cannot infer from the reg.finalizer man page what I might be doing
> wrong.
> Is there a way to see, at the R-system level, what functions have been
> registered as finalizers?
>
> Thanks for any pointers!
>
> -Murat
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mmuurr at gmail.com  Mon Oct 27 03:35:53 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Sun, 26 Oct 2014 20:35:53 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
Message-ID: <CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>

Ah, thanks for the ls() vs names() tip!
(But sadly, it didn't solve the issue... )

So, after some more tinkering, I believe the finalizer is being called
_sometimes_.
I changed the reg.finalizer(...) call to just this:

reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)

Now, when I load the package and detach(..., unload = TRUE), nothing prints.
And when I quit, nothing prints.

If I, however, create an environment on the workspace, like so:
> e <- new.env(parent = emptyenv())
> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
When I quit (or rm(e)), "bar" is printed.
But no "foo" (corresponding to same sequence of code, just in the
package instead).

BUT(!), when I _install_ the package, "foo" is printed at the end of
the "**testing if installed package can be loaded" installation
segment.
So, somehow the R script that tests for package loading/unloading is
triggering the finalizer (which is good).
Yet, I cannot seem to trigger it myself when either quitting or
forcing a package unload (which is bad).

Any ideas why the installation script would successfully trigger a
finalizer while standard unloading or quitting wouldn't?

Cheers and thanks!

-m

On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Hmmm, I guess you will want to put the actual objects that represent
> the connections into the environment, at least this seems to be the
> easiest to me. Btw. you need ls() to list the contents of an
> environment, instead of names(). E.g.
>
> e <- new.env()
> e$foo <- 10
> e$bar <- "aaa"
> names(e)
> #> NULL
> ls(e)
> #> [1] "bar" "foo"
> reg.finalizer(e, function(x) { print(ls(x)) })
> #> NULL
> rm(e)
> gc()
> #> [1] "bar" "foo"
> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>
> More precisely, you probably want to represent each connection as a
> separate environment, with its own finalizer. Hope this helps,
> Gabor
>
> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Hi all, I have a question about finalizers...
>> I have a package that manages state for a few connections, and I'd
>> like to ensure that these connections are 'cleanly' closed upon either
>> (i) R quitting or (ii) an unloading of the package.
>> So, in a pared-down example package with a single R file, it looks
>> something like:
>>
>> ##### BEGIN PACKAGE CODE #####
>> .CONNS <- new.env(parent = emptyenv())
>> .CONNS$resource1 <- NULL
>> .CONNS$resource2 <- NULL
>> ## some more .CONNS resources...
>>
>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)
>>
>> connect <- function(x) {
>>   ## here lies code to connect and update .CONNS[[x]]
>> }
>> disconnect <- function(x) {
>>   print(sprintf("disconnect(%s)", x))
>>   ## here lies code to disconnect and update .CONNS[[x]]
>> }
>> ##### END PACKAGE CODE #####
>>
>> The print(...) statement in disconnect(...) is there as a trace, as I
>> hoped that I'd see disconnect(...) being called when I quit (or
>> detach(..., unload = TRUE)).
>> But, it doesn't appear that disconnect(...) is ever called when the
>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>> detach(...), just to be sure).
>>
>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>> call inside an .onLoad function, but that didn't seem to work, either.
>>
>> I'm guessing my use of reg.finalizer is way off-base here... but I
>> cannot infer from the reg.finalizer man page what I might be doing
>> wrong.
>> Is there a way to see, at the R-system level, what functions have been
>> registered as finalizers?
>>
>> Thanks for any pointers!
>>
>> -Murat
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Mon Oct 27 03:53:43 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 26 Oct 2014 22:53:43 -0400
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
Message-ID: <CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>

Well, to be honest I don't understand fully what you are trying to do.
If you want to run code when the package is detached or when it is
unloaded, then use a hook:
http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks

If you want to run code when an object is freed, then use a finalizer.

Note that when you install a package, R runs all the code in the
package and only stores the results of the code in the installed
package. So if you create an object outside of a function in your
package, then only the object will be stored in the package, but not
the code that creates it. The object will be simply loaded when you
load the package, but it will not be re-created.

Now, I am not sure what happens if you set the finalizer on such an
object in the package. I can imagine that the finalizer will not be
saved into the package, and is only used once, when
building/installing the package. In this case you'll need to set the
finalizer in .onLoad().

Gabor

On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Ah, thanks for the ls() vs names() tip!
> (But sadly, it didn't solve the issue... )
>
> So, after some more tinkering, I believe the finalizer is being called
> _sometimes_.
> I changed the reg.finalizer(...) call to just this:
>
> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>
> Now, when I load the package and detach(..., unload = TRUE), nothing prints.
> And when I quit, nothing prints.
>
> If I, however, create an environment on the workspace, like so:
>> e <- new.env(parent = emptyenv())
>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
> When I quit (or rm(e)), "bar" is printed.
> But no "foo" (corresponding to same sequence of code, just in the
> package instead).
>
> BUT(!), when I _install_ the package, "foo" is printed at the end of
> the "**testing if installed package can be loaded" installation
> segment.
> So, somehow the R script that tests for package loading/unloading is
> triggering the finalizer (which is good).
> Yet, I cannot seem to trigger it myself when either quitting or
> forcing a package unload (which is bad).
>
> Any ideas why the installation script would successfully trigger a
> finalizer while standard unloading or quitting wouldn't?
>
> Cheers and thanks!
>
> -m
>
> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> Hmmm, I guess you will want to put the actual objects that represent
>> the connections into the environment, at least this seems to be the
>> easiest to me. Btw. you need ls() to list the contents of an
>> environment, instead of names(). E.g.
>>
>> e <- new.env()
>> e$foo <- 10
>> e$bar <- "aaa"
>> names(e)
>> #> NULL
>> ls(e)
>> #> [1] "bar" "foo"
>> reg.finalizer(e, function(x) { print(ls(x)) })
>> #> NULL
>> rm(e)
>> gc()
>> #> [1] "bar" "foo"
>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>>
>> More precisely, you probably want to represent each connection as a
>> separate environment, with its own finalizer. Hope this helps,
>> Gabor
>>
>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> Hi all, I have a question about finalizers...
>>> I have a package that manages state for a few connections, and I'd
>>> like to ensure that these connections are 'cleanly' closed upon either
>>> (i) R quitting or (ii) an unloading of the package.
>>> So, in a pared-down example package with a single R file, it looks
>>> something like:
>>>
>>> ##### BEGIN PACKAGE CODE #####
>>> .CONNS <- new.env(parent = emptyenv())
>>> .CONNS$resource1 <- NULL
>>> .CONNS$resource2 <- NULL
>>> ## some more .CONNS resources...
>>>
>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)
>>>
>>> connect <- function(x) {
>>>   ## here lies code to connect and update .CONNS[[x]]
>>> }
>>> disconnect <- function(x) {
>>>   print(sprintf("disconnect(%s)", x))
>>>   ## here lies code to disconnect and update .CONNS[[x]]
>>> }
>>> ##### END PACKAGE CODE #####
>>>
>>> The print(...) statement in disconnect(...) is there as a trace, as I
>>> hoped that I'd see disconnect(...) being called when I quit (or
>>> detach(..., unload = TRUE)).
>>> But, it doesn't appear that disconnect(...) is ever called when the
>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>>> detach(...), just to be sure).
>>>
>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>>> call inside an .onLoad function, but that didn't seem to work, either.
>>>
>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>>> cannot infer from the reg.finalizer man page what I might be doing
>>> wrong.
>>> Is there a way to see, at the R-system level, what functions have been
>>> registered as finalizers?
>>>
>>> Thanks for any pointers!
>>>
>>> -Murat
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mmuurr at gmail.com  Mon Oct 27 04:14:19 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Sun, 26 Oct 2014 21:14:19 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
Message-ID: <CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>

Ah (again)!
Even with my fumbling presentation of the issue, you gave me the hint
that solved it, thanks!

Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
it's not called once during package installation and then never again.
And once I switched to using ls() (instead of names()), everything
works as expected.

So, the package code effectively looks like so:

.CONNS <- new.env(parent = emptyenv())
.onLoad <- function(libname, pkgname) {
    reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
}
.disconnect <- function(x) {
    ## handle disconnection of .CONNS[[x]] here
}

Cheers and thanks!

-m




On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Well, to be honest I don't understand fully what you are trying to do.
> If you want to run code when the package is detached or when it is
> unloaded, then use a hook:
> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
>
> If you want to run code when an object is freed, then use a finalizer.
>
> Note that when you install a package, R runs all the code in the
> package and only stores the results of the code in the installed
> package. So if you create an object outside of a function in your
> package, then only the object will be stored in the package, but not
> the code that creates it. The object will be simply loaded when you
> load the package, but it will not be re-created.
>
> Now, I am not sure what happens if you set the finalizer on such an
> object in the package. I can imagine that the finalizer will not be
> saved into the package, and is only used once, when
> building/installing the package. In this case you'll need to set the
> finalizer in .onLoad().
>
> Gabor
>
> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Ah, thanks for the ls() vs names() tip!
>> (But sadly, it didn't solve the issue... )
>>
>> So, after some more tinkering, I believe the finalizer is being called
>> _sometimes_.
>> I changed the reg.finalizer(...) call to just this:
>>
>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>>
>> Now, when I load the package and detach(..., unload = TRUE), nothing prints.
>> And when I quit, nothing prints.
>>
>> If I, however, create an environment on the workspace, like so:
>>> e <- new.env(parent = emptyenv())
>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
>> When I quit (or rm(e)), "bar" is printed.
>> But no "foo" (corresponding to same sequence of code, just in the
>> package instead).
>>
>> BUT(!), when I _install_ the package, "foo" is printed at the end of
>> the "**testing if installed package can be loaded" installation
>> segment.
>> So, somehow the R script that tests for package loading/unloading is
>> triggering the finalizer (which is good).
>> Yet, I cannot seem to trigger it myself when either quitting or
>> forcing a package unload (which is bad).
>>
>> Any ideas why the installation script would successfully trigger a
>> finalizer while standard unloading or quitting wouldn't?
>>
>> Cheers and thanks!
>>
>> -m
>>
>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>> Hmmm, I guess you will want to put the actual objects that represent
>>> the connections into the environment, at least this seems to be the
>>> easiest to me. Btw. you need ls() to list the contents of an
>>> environment, instead of names(). E.g.
>>>
>>> e <- new.env()
>>> e$foo <- 10
>>> e$bar <- "aaa"
>>> names(e)
>>> #> NULL
>>> ls(e)
>>> #> [1] "bar" "foo"
>>> reg.finalizer(e, function(x) { print(ls(x)) })
>>> #> NULL
>>> rm(e)
>>> gc()
>>> #> [1] "bar" "foo"
>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>>>
>>> More precisely, you probably want to represent each connection as a
>>> separate environment, with its own finalizer. Hope this helps,
>>> Gabor
>>>
>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>>> Hi all, I have a question about finalizers...
>>>> I have a package that manages state for a few connections, and I'd
>>>> like to ensure that these connections are 'cleanly' closed upon either
>>>> (i) R quitting or (ii) an unloading of the package.
>>>> So, in a pared-down example package with a single R file, it looks
>>>> something like:
>>>>
>>>> ##### BEGIN PACKAGE CODE #####
>>>> .CONNS <- new.env(parent = emptyenv())
>>>> .CONNS$resource1 <- NULL
>>>> .CONNS$resource2 <- NULL
>>>> ## some more .CONNS resources...
>>>>
>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)
>>>>
>>>> connect <- function(x) {
>>>>   ## here lies code to connect and update .CONNS[[x]]
>>>> }
>>>> disconnect <- function(x) {
>>>>   print(sprintf("disconnect(%s)", x))
>>>>   ## here lies code to disconnect and update .CONNS[[x]]
>>>> }
>>>> ##### END PACKAGE CODE #####
>>>>
>>>> The print(...) statement in disconnect(...) is there as a trace, as I
>>>> hoped that I'd see disconnect(...) being called when I quit (or
>>>> detach(..., unload = TRUE)).
>>>> But, it doesn't appear that disconnect(...) is ever called when the
>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>>>> detach(...), just to be sure).
>>>>
>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>>>> call inside an .onLoad function, but that didn't seem to work, either.
>>>>
>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>>>> cannot infer from the reg.finalizer man page what I might be doing
>>>> wrong.
>>>> Is there a way to see, at the R-system level, what functions have been
>>>> registered as finalizers?
>>>>
>>>> Thanks for any pointers!
>>>>
>>>> -Murat
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Mon Oct 27 06:02:48 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 26 Oct 2014 22:02:48 -0700
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
	<CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
Message-ID: <CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>

On Sun, Oct 26, 2014 at 8:14 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Ah (again)!
> Even with my fumbling presentation of the issue, you gave me the hint
> that solved it, thanks!
>
> Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
> it's not called once during package installation and then never again.
> And once I switched to using ls() (instead of names()), everything
> works as expected.
>
> So, the package code effectively looks like so:
>
> .CONNS <- new.env(parent = emptyenv())
> .onLoad <- function(libname, pkgname) {
>     reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
> }
> .disconnect <- function(x) {
>     ## handle disconnection of .CONNS[[x]] here
> }

In your example above, I would be concerned about what happens if you
detach/unload your package, because then you're finalizer is still
registered and will be called whenever '.CONNS' is being garbage
collector (or there after).  However, the finalizer function calls
.disconnect(), which is no longer available.

Finalizers should be used with great care, because you're not in
control in what order things are occurring and what "resources" are
around when the finalizer function is eventually called and when it is
called.  I've been bitten by this a few times and it can be very hard
to reproduce and troubleshoot such bugs.  See also the 'Note' of
?reg.finalizer.

My $.02

/Henrik

>
> Cheers and thanks!
>
> -m
>
>
>
>
> On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> Well, to be honest I don't understand fully what you are trying to do.
>> If you want to run code when the package is detached or when it is
>> unloaded, then use a hook:
>> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
>>
>> If you want to run code when an object is freed, then use a finalizer.
>>
>> Note that when you install a package, R runs all the code in the
>> package and only stores the results of the code in the installed
>> package. So if you create an object outside of a function in your
>> package, then only the object will be stored in the package, but not
>> the code that creates it. The object will be simply loaded when you
>> load the package, but it will not be re-created.
>>
>> Now, I am not sure what happens if you set the finalizer on such an
>> object in the package. I can imagine that the finalizer will not be
>> saved into the package, and is only used once, when
>> building/installing the package. In this case you'll need to set the
>> finalizer in .onLoad().
>>
>> Gabor
>>
>> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> Ah, thanks for the ls() vs names() tip!
>>> (But sadly, it didn't solve the issue... )
>>>
>>> So, after some more tinkering, I believe the finalizer is being called
>>> _sometimes_.
>>> I changed the reg.finalizer(...) call to just this:
>>>
>>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>>>
>>> Now, when I load the package and detach(..., unload = TRUE), nothing prints.
>>> And when I quit, nothing prints.
>>>
>>> If I, however, create an environment on the workspace, like so:
>>>> e <- new.env(parent = emptyenv())
>>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
>>> When I quit (or rm(e)), "bar" is printed.
>>> But no "foo" (corresponding to same sequence of code, just in the
>>> package instead).
>>>
>>> BUT(!), when I _install_ the package, "foo" is printed at the end of
>>> the "**testing if installed package can be loaded" installation
>>> segment.
>>> So, somehow the R script that tests for package loading/unloading is
>>> triggering the finalizer (which is good).
>>> Yet, I cannot seem to trigger it myself when either quitting or
>>> forcing a package unload (which is bad).
>>>
>>> Any ideas why the installation script would successfully trigger a
>>> finalizer while standard unloading or quitting wouldn't?
>>>
>>> Cheers and thanks!
>>>
>>> -m
>>>
>>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>>> Hmmm, I guess you will want to put the actual objects that represent
>>>> the connections into the environment, at least this seems to be the
>>>> easiest to me. Btw. you need ls() to list the contents of an
>>>> environment, instead of names(). E.g.
>>>>
>>>> e <- new.env()
>>>> e$foo <- 10
>>>> e$bar <- "aaa"
>>>> names(e)
>>>> #> NULL
>>>> ls(e)
>>>> #> [1] "bar" "foo"
>>>> reg.finalizer(e, function(x) { print(ls(x)) })
>>>> #> NULL
>>>> rm(e)
>>>> gc()
>>>> #> [1] "bar" "foo"
>>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>>>>
>>>> More precisely, you probably want to represent each connection as a
>>>> separate environment, with its own finalizer. Hope this helps,
>>>> Gabor
>>>>
>>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>>>> Hi all, I have a question about finalizers...
>>>>> I have a package that manages state for a few connections, and I'd
>>>>> like to ensure that these connections are 'cleanly' closed upon either
>>>>> (i) R quitting or (ii) an unloading of the package.
>>>>> So, in a pared-down example package with a single R file, it looks
>>>>> something like:
>>>>>
>>>>> ##### BEGIN PACKAGE CODE #####
>>>>> .CONNS <- new.env(parent = emptyenv())
>>>>> .CONNS$resource1 <- NULL
>>>>> .CONNS$resource2 <- NULL
>>>>> ## some more .CONNS resources...
>>>>>
>>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect), onexit = TRUE)
>>>>>
>>>>> connect <- function(x) {
>>>>>   ## here lies code to connect and update .CONNS[[x]]
>>>>> }
>>>>> disconnect <- function(x) {
>>>>>   print(sprintf("disconnect(%s)", x))
>>>>>   ## here lies code to disconnect and update .CONNS[[x]]
>>>>> }
>>>>> ##### END PACKAGE CODE #####
>>>>>
>>>>> The print(...) statement in disconnect(...) is there as a trace, as I
>>>>> hoped that I'd see disconnect(...) being called when I quit (or
>>>>> detach(..., unload = TRUE)).
>>>>> But, it doesn't appear that disconnect(...) is ever called when the
>>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>>>>> detach(...), just to be sure).
>>>>>
>>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>>>>> call inside an .onLoad function, but that didn't seem to work, either.
>>>>>
>>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>>>>> cannot infer from the reg.finalizer man page what I might be doing
>>>>> wrong.
>>>>> Is there a way to see, at the R-system level, what functions have been
>>>>> registered as finalizers?
>>>>>
>>>>> Thanks for any pointers!
>>>>>
>>>>> -Murat
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mmuurr at gmail.com  Mon Oct 27 07:18:21 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 27 Oct 2014 00:18:21 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
	<CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
	<CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>
Message-ID: <CA+YV+Hxmy1eS0YXCcX9wqANmxHF+mah+WN6Pext=vATxpoEapg@mail.gmail.com>

Ah, good point, I hadn't thought of that detail.
Would moving reg.finalizer back outside of .onLoad and hooking it to the
package's environment itself work (more safely)?
Something like:
finalizerFunction <- ## cleanup code
reg.finalizer(parent.env(), finalizerFunction)

-m
 On Oct 26, 2014 11:03 PM, "Henrik Bengtsson" <hb at biostat.ucsf.edu> wrote:

> On Sun, Oct 26, 2014 at 8:14 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> > Ah (again)!
> > Even with my fumbling presentation of the issue, you gave me the hint
> > that solved it, thanks!
> >
> > Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
> > it's not called once during package installation and then never again.
> > And once I switched to using ls() (instead of names()), everything
> > works as expected.
> >
> > So, the package code effectively looks like so:
> >
> > .CONNS <- new.env(parent = emptyenv())
> > .onLoad <- function(libname, pkgname) {
> >     reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
> > }
> > .disconnect <- function(x) {
> >     ## handle disconnection of .CONNS[[x]] here
> > }
>
> In your example above, I would be concerned about what happens if you
> detach/unload your package, because then you're finalizer is still
> registered and will be called whenever '.CONNS' is being garbage
> collector (or there after).  However, the finalizer function calls
> .disconnect(), which is no longer available.
>
> Finalizers should be used with great care, because you're not in
> control in what order things are occurring and what "resources" are
> around when the finalizer function is eventually called and when it is
> called.  I've been bitten by this a few times and it can be very hard
> to reproduce and troubleshoot such bugs.  See also the 'Note' of
> ?reg.finalizer.
>
> My $.02
>
> /Henrik
>
> >
> > Cheers and thanks!
> >
> > -m
> >
> >
> >
> >
> > On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> >> Well, to be honest I don't understand fully what you are trying to do.
> >> If you want to run code when the package is detached or when it is
> >> unloaded, then use a hook:
> >> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
> >>
> >> If you want to run code when an object is freed, then use a finalizer.
> >>
> >> Note that when you install a package, R runs all the code in the
> >> package and only stores the results of the code in the installed
> >> package. So if you create an object outside of a function in your
> >> package, then only the object will be stored in the package, but not
> >> the code that creates it. The object will be simply loaded when you
> >> load the package, but it will not be re-created.
> >>
> >> Now, I am not sure what happens if you set the finalizer on such an
> >> object in the package. I can imagine that the finalizer will not be
> >> saved into the package, and is only used once, when
> >> building/installing the package. In this case you'll need to set the
> >> finalizer in .onLoad().
> >>
> >> Gabor
> >>
> >> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> >>> Ah, thanks for the ls() vs names() tip!
> >>> (But sadly, it didn't solve the issue... )
> >>>
> >>> So, after some more tinkering, I believe the finalizer is being called
> >>> _sometimes_.
> >>> I changed the reg.finalizer(...) call to just this:
> >>>
> >>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
> >>>
> >>> Now, when I load the package and detach(..., unload = TRUE), nothing
> prints.
> >>> And when I quit, nothing prints.
> >>>
> >>> If I, however, create an environment on the workspace, like so:
> >>>> e <- new.env(parent = emptyenv())
> >>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
> >>> When I quit (or rm(e)), "bar" is printed.
> >>> But no "foo" (corresponding to same sequence of code, just in the
> >>> package instead).
> >>>
> >>> BUT(!), when I _install_ the package, "foo" is printed at the end of
> >>> the "**testing if installed package can be loaded" installation
> >>> segment.
> >>> So, somehow the R script that tests for package loading/unloading is
> >>> triggering the finalizer (which is good).
> >>> Yet, I cannot seem to trigger it myself when either quitting or
> >>> forcing a package unload (which is bad).
> >>>
> >>> Any ideas why the installation script would successfully trigger a
> >>> finalizer while standard unloading or quitting wouldn't?
> >>>
> >>> Cheers and thanks!
> >>>
> >>> -m
> >>>
> >>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> >>>> Hmmm, I guess you will want to put the actual objects that represent
> >>>> the connections into the environment, at least this seems to be the
> >>>> easiest to me. Btw. you need ls() to list the contents of an
> >>>> environment, instead of names(). E.g.
> >>>>
> >>>> e <- new.env()
> >>>> e$foo <- 10
> >>>> e$bar <- "aaa"
> >>>> names(e)
> >>>> #> NULL
> >>>> ls(e)
> >>>> #> [1] "bar" "foo"
> >>>> reg.finalizer(e, function(x) { print(ls(x)) })
> >>>> #> NULL
> >>>> rm(e)
> >>>> gc()
> >>>> #> [1] "bar" "foo"
> >>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
> >>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
> >>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
> >>>>
> >>>> More precisely, you probably want to represent each connection as a
> >>>> separate environment, with its own finalizer. Hope this helps,
> >>>> Gabor
> >>>>
> >>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com>
> wrote:
> >>>>> Hi all, I have a question about finalizers...
> >>>>> I have a package that manages state for a few connections, and I'd
> >>>>> like to ensure that these connections are 'cleanly' closed upon
> either
> >>>>> (i) R quitting or (ii) an unloading of the package.
> >>>>> So, in a pared-down example package with a single R file, it looks
> >>>>> something like:
> >>>>>
> >>>>> ##### BEGIN PACKAGE CODE #####
> >>>>> .CONNS <- new.env(parent = emptyenv())
> >>>>> .CONNS$resource1 <- NULL
> >>>>> .CONNS$resource2 <- NULL
> >>>>> ## some more .CONNS resources...
> >>>>>
> >>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect),
> onexit = TRUE)
> >>>>>
> >>>>> connect <- function(x) {
> >>>>>   ## here lies code to connect and update .CONNS[[x]]
> >>>>> }
> >>>>> disconnect <- function(x) {
> >>>>>   print(sprintf("disconnect(%s)", x))
> >>>>>   ## here lies code to disconnect and update .CONNS[[x]]
> >>>>> }
> >>>>> ##### END PACKAGE CODE #####
> >>>>>
> >>>>> The print(...) statement in disconnect(...) is there as a trace, as I
> >>>>> hoped that I'd see disconnect(...) being called when I quit (or
> >>>>> detach(..., unload = TRUE)).
> >>>>> But, it doesn't appear that disconnect(...) is ever called when the
> >>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
> >>>>> detach(...), just to be sure).
> >>>>>
> >>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
> >>>>> call inside an .onLoad function, but that didn't seem to work,
> either.
> >>>>>
> >>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
> >>>>> cannot infer from the reg.finalizer man page what I might be doing
> >>>>> wrong.
> >>>>> Is there a way to see, at the R-system level, what functions have
> been
> >>>>> registered as finalizers?
> >>>>>
> >>>>> Thanks for any pointers!
> >>>>>
> >>>>> -Murat
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From musically.ut at gmail.com  Mon Oct 27 15:15:37 2014
From: musically.ut at gmail.com (Utkarsh Upadhyay)
Date: Mon, 27 Oct 2014 15:15:37 +0100
Subject: [Rd] Calling the original function after tweaking arguments is an
 incorrect use of the R-API?
Message-ID: <CALh3q9xKUge+efKC2v+uJzZ5gBz4ojFCD4xhpO0J2v5kkGz_wQ@mail.gmail.com>

Hi,

I am trying to create a small extension for R here for embedding the
current time on the R prompt:https://github.com/musically-ut/extPrompt

Things seem to be working overall, but R CMD check . raised a warning:

File '[truncated]..Rcheck/extPrompt/libs/extPrompt.so?: Found non-API call
> to R: ?ptr_R_ReadConsole?

Compiled code should not call non-API entry points in R.


The concerned file is this:
https://github.com/musically-ut/extPrompt/blob/master/src/extPrompt.c and
occurs on line 38, I think.

void extPrompt() {
>     // Initialize the plugin by replacing the R_ReadConsole function
>     old_R_ReadConsole = ptr_R_ReadConsole;
>     ptr_R_ReadConsole = extPrompt_ReadConsole;
>     // ...
> }
> int extPrompt_ReadConsole(const char *old_prompt, unsigned char *buf, int
> len,
>          int addtohistory) {
>     // ...
>     // Call the old function with the `new_prompt`
>     return (*old_R_ReadConsole)(new_prompt, buf, len, addtohistory);
> }


I am trying to make the R_ReadConsole API call. However, since a different
plugin (like mine) could have overridden it already, I do not want to
directly invoke R_ReadConsole but the function which previously was at
ptr_R_ReadConsole.

Is this an incorrect use of the API?

Also, any other feedback on the plugin is also welcome.

Thanks.

~
ut

PS: I had posted this question on StackOverflow a while back:
http://stackoverflow.com/questions/26335571/is-this-an-incorrect-use-of-the-r-api
If I receive a response, I will update the question with the appropriate
answer.

	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Mon Oct 27 18:10:26 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 27 Oct 2014 11:10:26 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CA+YV+Hxmy1eS0YXCcX9wqANmxHF+mah+WN6Pext=vATxpoEapg@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
	<CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
	<CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>
	<CA+YV+Hxmy1eS0YXCcX9wqANmxHF+mah+WN6Pext=vATxpoEapg@mail.gmail.com>
Message-ID: <CA+YV+HzwcDy6Wva76Fr6E+32ZCXWG+bf+RckOTNtuv4oeCsP_w@mail.gmail.com>

Eh, after some flailing, I think I solved it.
I _think_ this pattern should guarantee that the finalizer function is
still present when needed:

.STATE_CONTAINER <- new.env(parent = emptyenv())
.STATE_CONTAINER$some_state_variable <- ## some code
.STATE_CONTAINER$some_other_state_variable <- ## some code

.myFinalizer <- function(name_of_state_variable_to_clean_up)

.onLoad <- function(libname, pkgname) {
    reg.finalizer(
        e = parent.env(environment()),
        f = function(env) sapply(ls(env$.STATE_CONTAINER), .myFinalizer),
        onexit = TRUE)
}

This way, the finalizer is registered on the enclosing environment of
the .onLoad function, which should be the package environment itself.
And that means .myFinalizer should still be around when it's called
during q() or unload/gc().
Effectively, the finalizer is tied to the entire package, rather than
the state variable container(s), which might not be the most elegant
solution, but it should work well enough for most purposes.

Cheers and thanks for the advice,

-m

On Mon, Oct 27, 2014 at 12:18 AM, Murat Tasan <mmuurr at gmail.com> wrote:
> Ah, good point, I hadn't thought of that detail.
> Would moving reg.finalizer back outside of .onLoad and hooking it to the
> package's environment itself work (more safely)?
> Something like:
> finalizerFunction <- ## cleanup code
> reg.finalizer(parent.env(), finalizerFunction)
>
> -m
>
> On Oct 26, 2014 11:03 PM, "Henrik Bengtsson" <hb at biostat.ucsf.edu> wrote:
>>
>> On Sun, Oct 26, 2014 at 8:14 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> > Ah (again)!
>> > Even with my fumbling presentation of the issue, you gave me the hint
>> > that solved it, thanks!
>> >
>> > Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
>> > it's not called once during package installation and then never again.
>> > And once I switched to using ls() (instead of names()), everything
>> > works as expected.
>> >
>> > So, the package code effectively looks like so:
>> >
>> > .CONNS <- new.env(parent = emptyenv())
>> > .onLoad <- function(libname, pkgname) {
>> >     reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
>> > }
>> > .disconnect <- function(x) {
>> >     ## handle disconnection of .CONNS[[x]] here
>> > }
>>
>> In your example above, I would be concerned about what happens if you
>> detach/unload your package, because then you're finalizer is still
>> registered and will be called whenever '.CONNS' is being garbage
>> collector (or there after).  However, the finalizer function calls
>> .disconnect(), which is no longer available.
>>
>> Finalizers should be used with great care, because you're not in
>> control in what order things are occurring and what "resources" are
>> around when the finalizer function is eventually called and when it is
>> called.  I've been bitten by this a few times and it can be very hard
>> to reproduce and troubleshoot such bugs.  See also the 'Note' of
>> ?reg.finalizer.
>>
>> My $.02
>>
>> /Henrik
>>
>> >
>> > Cheers and thanks!
>> >
>> > -m
>> >
>> >
>> >
>> >
>> > On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> > wrote:
>> >> Well, to be honest I don't understand fully what you are trying to do.
>> >> If you want to run code when the package is detached or when it is
>> >> unloaded, then use a hook:
>> >> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
>> >>
>> >> If you want to run code when an object is freed, then use a finalizer.
>> >>
>> >> Note that when you install a package, R runs all the code in the
>> >> package and only stores the results of the code in the installed
>> >> package. So if you create an object outside of a function in your
>> >> package, then only the object will be stored in the package, but not
>> >> the code that creates it. The object will be simply loaded when you
>> >> load the package, but it will not be re-created.
>> >>
>> >> Now, I am not sure what happens if you set the finalizer on such an
>> >> object in the package. I can imagine that the finalizer will not be
>> >> saved into the package, and is only used once, when
>> >> building/installing the package. In this case you'll need to set the
>> >> finalizer in .onLoad().
>> >>
>> >> Gabor
>> >>
>> >> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> >>> Ah, thanks for the ls() vs names() tip!
>> >>> (But sadly, it didn't solve the issue... )
>> >>>
>> >>> So, after some more tinkering, I believe the finalizer is being called
>> >>> _sometimes_.
>> >>> I changed the reg.finalizer(...) call to just this:
>> >>>
>> >>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>> >>>
>> >>> Now, when I load the package and detach(..., unload = TRUE), nothing
>> >>> prints.
>> >>> And when I quit, nothing prints.
>> >>>
>> >>> If I, however, create an environment on the workspace, like so:
>> >>>> e <- new.env(parent = emptyenv())
>> >>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
>> >>> When I quit (or rm(e)), "bar" is printed.
>> >>> But no "foo" (corresponding to same sequence of code, just in the
>> >>> package instead).
>> >>>
>> >>> BUT(!), when I _install_ the package, "foo" is printed at the end of
>> >>> the "**testing if installed package can be loaded" installation
>> >>> segment.
>> >>> So, somehow the R script that tests for package loading/unloading is
>> >>> triggering the finalizer (which is good).
>> >>> Yet, I cannot seem to trigger it myself when either quitting or
>> >>> forcing a package unload (which is bad).
>> >>>
>> >>> Any ideas why the installation script would successfully trigger a
>> >>> finalizer while standard unloading or quitting wouldn't?
>> >>>
>> >>> Cheers and thanks!
>> >>>
>> >>> -m
>> >>>
>> >>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> >>> wrote:
>> >>>> Hmmm, I guess you will want to put the actual objects that represent
>> >>>> the connections into the environment, at least this seems to be the
>> >>>> easiest to me. Btw. you need ls() to list the contents of an
>> >>>> environment, instead of names(). E.g.
>> >>>>
>> >>>> e <- new.env()
>> >>>> e$foo <- 10
>> >>>> e$bar <- "aaa"
>> >>>> names(e)
>> >>>> #> NULL
>> >>>> ls(e)
>> >>>> #> [1] "bar" "foo"
>> >>>> reg.finalizer(e, function(x) { print(ls(x)) })
>> >>>> #> NULL
>> >>>> rm(e)
>> >>>> gc()
>> >>>> #> [1] "bar" "foo"
>> >>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>> >>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>> >>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>> >>>>
>> >>>> More precisely, you probably want to represent each connection as a
>> >>>> separate environment, with its own finalizer. Hope this helps,
>> >>>> Gabor
>> >>>>
>> >>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com>
>> >>>> wrote:
>> >>>>> Hi all, I have a question about finalizers...
>> >>>>> I have a package that manages state for a few connections, and I'd
>> >>>>> like to ensure that these connections are 'cleanly' closed upon
>> >>>>> either
>> >>>>> (i) R quitting or (ii) an unloading of the package.
>> >>>>> So, in a pared-down example package with a single R file, it looks
>> >>>>> something like:
>> >>>>>
>> >>>>> ##### BEGIN PACKAGE CODE #####
>> >>>>> .CONNS <- new.env(parent = emptyenv())
>> >>>>> .CONNS$resource1 <- NULL
>> >>>>> .CONNS$resource2 <- NULL
>> >>>>> ## some more .CONNS resources...
>> >>>>>
>> >>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect),
>> >>>>> onexit = TRUE)
>> >>>>>
>> >>>>> connect <- function(x) {
>> >>>>>   ## here lies code to connect and update .CONNS[[x]]
>> >>>>> }
>> >>>>> disconnect <- function(x) {
>> >>>>>   print(sprintf("disconnect(%s)", x))
>> >>>>>   ## here lies code to disconnect and update .CONNS[[x]]
>> >>>>> }
>> >>>>> ##### END PACKAGE CODE #####
>> >>>>>
>> >>>>> The print(...) statement in disconnect(...) is there as a trace, as
>> >>>>> I
>> >>>>> hoped that I'd see disconnect(...) being called when I quit (or
>> >>>>> detach(..., unload = TRUE)).
>> >>>>> But, it doesn't appear that disconnect(...) is ever called when the
>> >>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>> >>>>> detach(...), just to be sure).
>> >>>>>
>> >>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>> >>>>> call inside an .onLoad function, but that didn't seem to work,
>> >>>>> either.
>> >>>>>
>> >>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>> >>>>> cannot infer from the reg.finalizer man page what I might be doing
>> >>>>> wrong.
>> >>>>> Is there a way to see, at the R-system level, what functions have
>> >>>>> been
>> >>>>> registered as finalizers?
>> >>>>>
>> >>>>> Thanks for any pointers!
>> >>>>>
>> >>>>> -Murat
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-devel at r-project.org mailing list
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Mon Oct 27 18:27:41 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 27 Oct 2014 10:27:41 -0700
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CA+YV+HzwcDy6Wva76Fr6E+32ZCXWG+bf+RckOTNtuv4oeCsP_w@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
	<CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
	<CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>
	<CA+YV+Hxmy1eS0YXCcX9wqANmxHF+mah+WN6Pext=vATxpoEapg@mail.gmail.com>
	<CA+YV+HzwcDy6Wva76Fr6E+32ZCXWG+bf+RckOTNtuv4oeCsP_w@mail.gmail.com>
Message-ID: <CAFDcVCRpqos_hyNy5SgKs2NRE6UCTh9bfhGkqZONtGCuD53gjQ@mail.gmail.com>

...and don't forget to make sure all the function that .myFinalizer()
calls are also around. /Henrik

On Mon, Oct 27, 2014 at 10:10 AM, Murat Tasan <mmuurr at gmail.com> wrote:
> Eh, after some flailing, I think I solved it.
> I _think_ this pattern should guarantee that the finalizer function is
> still present when needed:
>
> .STATE_CONTAINER <- new.env(parent = emptyenv())
> .STATE_CONTAINER$some_state_variable <- ## some code
> .STATE_CONTAINER$some_other_state_variable <- ## some code
>
> .myFinalizer <- function(name_of_state_variable_to_clean_up)
>
> .onLoad <- function(libname, pkgname) {
>     reg.finalizer(
>         e = parent.env(environment()),
>         f = function(env) sapply(ls(env$.STATE_CONTAINER), .myFinalizer),
>         onexit = TRUE)
> }
>
> This way, the finalizer is registered on the enclosing environment of
> the .onLoad function, which should be the package environment itself.
> And that means .myFinalizer should still be around when it's called
> during q() or unload/gc().
> Effectively, the finalizer is tied to the entire package, rather than
> the state variable container(s), which might not be the most elegant
> solution, but it should work well enough for most purposes.
>
> Cheers and thanks for the advice,
>
> -m
>
> On Mon, Oct 27, 2014 at 12:18 AM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Ah, good point, I hadn't thought of that detail.
>> Would moving reg.finalizer back outside of .onLoad and hooking it to the
>> package's environment itself work (more safely)?
>> Something like:
>> finalizerFunction <- ## cleanup code
>> reg.finalizer(parent.env(), finalizerFunction)
>>
>> -m
>>
>> On Oct 26, 2014 11:03 PM, "Henrik Bengtsson" <hb at biostat.ucsf.edu> wrote:
>>>
>>> On Sun, Oct 26, 2014 at 8:14 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> > Ah (again)!
>>> > Even with my fumbling presentation of the issue, you gave me the hint
>>> > that solved it, thanks!
>>> >
>>> > Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
>>> > it's not called once during package installation and then never again.
>>> > And once I switched to using ls() (instead of names()), everything
>>> > works as expected.
>>> >
>>> > So, the package code effectively looks like so:
>>> >
>>> > .CONNS <- new.env(parent = emptyenv())
>>> > .onLoad <- function(libname, pkgname) {
>>> >     reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
>>> > }
>>> > .disconnect <- function(x) {
>>> >     ## handle disconnection of .CONNS[[x]] here
>>> > }
>>>
>>> In your example above, I would be concerned about what happens if you
>>> detach/unload your package, because then you're finalizer is still
>>> registered and will be called whenever '.CONNS' is being garbage
>>> collector (or there after).  However, the finalizer function calls
>>> .disconnect(), which is no longer available.
>>>
>>> Finalizers should be used with great care, because you're not in
>>> control in what order things are occurring and what "resources" are
>>> around when the finalizer function is eventually called and when it is
>>> called.  I've been bitten by this a few times and it can be very hard
>>> to reproduce and troubleshoot such bugs.  See also the 'Note' of
>>> ?reg.finalizer.
>>>
>>> My $.02
>>>
>>> /Henrik
>>>
>>> >
>>> > Cheers and thanks!
>>> >
>>> > -m
>>> >
>>> >
>>> >
>>> >
>>> > On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>>> > wrote:
>>> >> Well, to be honest I don't understand fully what you are trying to do.
>>> >> If you want to run code when the package is detached or when it is
>>> >> unloaded, then use a hook:
>>> >> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
>>> >>
>>> >> If you want to run code when an object is freed, then use a finalizer.
>>> >>
>>> >> Note that when you install a package, R runs all the code in the
>>> >> package and only stores the results of the code in the installed
>>> >> package. So if you create an object outside of a function in your
>>> >> package, then only the object will be stored in the package, but not
>>> >> the code that creates it. The object will be simply loaded when you
>>> >> load the package, but it will not be re-created.
>>> >>
>>> >> Now, I am not sure what happens if you set the finalizer on such an
>>> >> object in the package. I can imagine that the finalizer will not be
>>> >> saved into the package, and is only used once, when
>>> >> building/installing the package. In this case you'll need to set the
>>> >> finalizer in .onLoad().
>>> >>
>>> >> Gabor
>>> >>
>>> >> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> >>> Ah, thanks for the ls() vs names() tip!
>>> >>> (But sadly, it didn't solve the issue... )
>>> >>>
>>> >>> So, after some more tinkering, I believe the finalizer is being called
>>> >>> _sometimes_.
>>> >>> I changed the reg.finalizer(...) call to just this:
>>> >>>
>>> >>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>>> >>>
>>> >>> Now, when I load the package and detach(..., unload = TRUE), nothing
>>> >>> prints.
>>> >>> And when I quit, nothing prints.
>>> >>>
>>> >>> If I, however, create an environment on the workspace, like so:
>>> >>>> e <- new.env(parent = emptyenv())
>>> >>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
>>> >>> When I quit (or rm(e)), "bar" is printed.
>>> >>> But no "foo" (corresponding to same sequence of code, just in the
>>> >>> package instead).
>>> >>>
>>> >>> BUT(!), when I _install_ the package, "foo" is printed at the end of
>>> >>> the "**testing if installed package can be loaded" installation
>>> >>> segment.
>>> >>> So, somehow the R script that tests for package loading/unloading is
>>> >>> triggering the finalizer (which is good).
>>> >>> Yet, I cannot seem to trigger it myself when either quitting or
>>> >>> forcing a package unload (which is bad).
>>> >>>
>>> >>> Any ideas why the installation script would successfully trigger a
>>> >>> finalizer while standard unloading or quitting wouldn't?
>>> >>>
>>> >>> Cheers and thanks!
>>> >>>
>>> >>> -m
>>> >>>
>>> >>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>>> >>> wrote:
>>> >>>> Hmmm, I guess you will want to put the actual objects that represent
>>> >>>> the connections into the environment, at least this seems to be the
>>> >>>> easiest to me. Btw. you need ls() to list the contents of an
>>> >>>> environment, instead of names(). E.g.
>>> >>>>
>>> >>>> e <- new.env()
>>> >>>> e$foo <- 10
>>> >>>> e$bar <- "aaa"
>>> >>>> names(e)
>>> >>>> #> NULL
>>> >>>> ls(e)
>>> >>>> #> [1] "bar" "foo"
>>> >>>> reg.finalizer(e, function(x) { print(ls(x)) })
>>> >>>> #> NULL
>>> >>>> rm(e)
>>> >>>> gc()
>>> >>>> #> [1] "bar" "foo"
>>> >>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>>> >>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>>> >>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>>> >>>>
>>> >>>> More precisely, you probably want to represent each connection as a
>>> >>>> separate environment, with its own finalizer. Hope this helps,
>>> >>>> Gabor
>>> >>>>
>>> >>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com>
>>> >>>> wrote:
>>> >>>>> Hi all, I have a question about finalizers...
>>> >>>>> I have a package that manages state for a few connections, and I'd
>>> >>>>> like to ensure that these connections are 'cleanly' closed upon
>>> >>>>> either
>>> >>>>> (i) R quitting or (ii) an unloading of the package.
>>> >>>>> So, in a pared-down example package with a single R file, it looks
>>> >>>>> something like:
>>> >>>>>
>>> >>>>> ##### BEGIN PACKAGE CODE #####
>>> >>>>> .CONNS <- new.env(parent = emptyenv())
>>> >>>>> .CONNS$resource1 <- NULL
>>> >>>>> .CONNS$resource2 <- NULL
>>> >>>>> ## some more .CONNS resources...
>>> >>>>>
>>> >>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect),
>>> >>>>> onexit = TRUE)
>>> >>>>>
>>> >>>>> connect <- function(x) {
>>> >>>>>   ## here lies code to connect and update .CONNS[[x]]
>>> >>>>> }
>>> >>>>> disconnect <- function(x) {
>>> >>>>>   print(sprintf("disconnect(%s)", x))
>>> >>>>>   ## here lies code to disconnect and update .CONNS[[x]]
>>> >>>>> }
>>> >>>>> ##### END PACKAGE CODE #####
>>> >>>>>
>>> >>>>> The print(...) statement in disconnect(...) is there as a trace, as
>>> >>>>> I
>>> >>>>> hoped that I'd see disconnect(...) being called when I quit (or
>>> >>>>> detach(..., unload = TRUE)).
>>> >>>>> But, it doesn't appear that disconnect(...) is ever called when the
>>> >>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>>> >>>>> detach(...), just to be sure).
>>> >>>>>
>>> >>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>>> >>>>> call inside an .onLoad function, but that didn't seem to work,
>>> >>>>> either.
>>> >>>>>
>>> >>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>>> >>>>> cannot infer from the reg.finalizer man page what I might be doing
>>> >>>>> wrong.
>>> >>>>> Is there a way to see, at the R-system level, what functions have
>>> >>>>> been
>>> >>>>> registered as finalizers?
>>> >>>>>
>>> >>>>> Thanks for any pointers!
>>> >>>>>
>>> >>>>> -Murat
>>> >>>>>
>>> >>>>> ______________________________________________
>>> >>>>> R-devel at r-project.org mailing list
>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-devel at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Mon Oct 27 19:16:10 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 27 Oct 2014 11:16:10 -0700
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX
 Mavericks (10.9)?
Message-ID: <CAFDcVCROinQWV3AAfCD=MgMW8rm7OiixYwbdLjRm7TNJaCXD3w@mail.gmail.com>

I'm trying to help someone to troubleshoot possible OSX Yosemite
issues, but I've only got access to OSX (< 10.9) so I cannot check
myself.

When building/installing binary R packages, there are different
binaries depending on OSX version.  For instance, CRAN provides
different binaries for 'OS X Snow Leopard' and 'OS X Mavericks', e.g.
http://cran.r-project.org/web/packages/matrixStats/index.html.

What about the new OSX Yosemite?  From
http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite it
looks like its binaries are the same/compatible with those of 'OS X
Mavericks' - can someone please confirm this?  Another way to put it,
if a repository provides OSX Mavericks binaries will an OSX Yosemite
user install these or we s/he fall back to installing from source?

Thanks

Henrik


From dtenenba at fredhutch.org  Mon Oct 27 19:21:59 2014
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 27 Oct 2014 11:21:59 -0700 (PDT)
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for
 OSX Mavericks (10.9)?
In-Reply-To: <CAFDcVCROinQWV3AAfCD=MgMW8rm7OiixYwbdLjRm7TNJaCXD3w@mail.gmail.com>
Message-ID: <703565888.267337.1414434119147.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> To: "R-devel" <r-devel at r-project.org>
> Sent: Monday, October 27, 2014 11:16:10 AM
> Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX Mavericks (10.9)?
> 
> I'm trying to help someone to troubleshoot possible OSX Yosemite
> issues, but I've only got access to OSX (< 10.9) so I cannot check
> myself.
> 
> When building/installing binary R packages, there are different
> binaries depending on OSX version.  For instance, CRAN provides
> different binaries for 'OS X Snow Leopard' and 'OS X Mavericks', e.g.
> http://cran.r-project.org/web/packages/matrixStats/index.html.
> 
> What about the new OSX Yosemite?  From
> http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite
> it
> looks like its binaries are the same/compatible with those of 'OS X
> Mavericks' - can someone please confirm this?  Another way to put it,
> if a repository provides OSX Mavericks binaries will an OSX Yosemite
> user install these or we s/he fall back to installing from source?
> 

Yes, a Yosemite user will by default be installing packages built on Mavericks using the Mavericks build of R, and they should work.

Dan


> Thanks
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dtenenba at fredhutch.org  Mon Oct 27 19:23:38 2014
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 27 Oct 2014 11:23:38 -0700 (PDT)
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for
 OSX Mavericks (10.9)?
In-Reply-To: <703565888.267337.1414434119147.JavaMail.root@fredhutch.org>
Message-ID: <654154513.267459.1414434218820.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> To: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Monday, October 27, 2014 11:21:59 AM
> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX Mavericks (10.9)?
> 
> 
> 
> ----- Original Message -----
> > From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> > To: "R-devel" <r-devel at r-project.org>
> > Sent: Monday, October 27, 2014 11:16:10 AM
> > Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same
> > as for OSX Mavericks (10.9)?
> > 
> > I'm trying to help someone to troubleshoot possible OSX Yosemite
> > issues, but I've only got access to OSX (< 10.9) so I cannot check
> > myself.
> > 
> > When building/installing binary R packages, there are different
> > binaries depending on OSX version.  For instance, CRAN provides
> > different binaries for 'OS X Snow Leopard' and 'OS X Mavericks',
> > e.g.
> > http://cran.r-project.org/web/packages/matrixStats/index.html.
> > 
> > What about the new OSX Yosemite?  From
> > http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite
> > it
> > looks like its binaries are the same/compatible with those of 'OS X
> > Mavericks' - can someone please confirm this?  Another way to put
> > it,
> > if a repository provides OSX Mavericks binaries will an OSX
> > Yosemite
> > user install these or we s/he fall back to installing from source?
> > 
> 
> Yes, a Yosemite user will by default be installing packages built on
> Mavericks using the Mavericks build of R, and they should work.
> 

Provided of course that that Yosemite user is using the Mavericks build of R. They could also be using the Snow Leopard build of R which should also work, and would be installing by default packages build on Snow Leopard using the Snow Leopard build of R.

Dan


> Dan
> 
> 
> > Thanks
> > 
> > Henrik
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Mon Oct 27 20:21:49 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 27 Oct 2014 12:21:49 -0700
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for
 OSX Mavericks (10.9)?
In-Reply-To: <654154513.267459.1414434218820.JavaMail.root@fredhutch.org>
References: <703565888.267337.1414434119147.JavaMail.root@fredhutch.org>
	<654154513.267459.1414434218820.JavaMail.root@fredhutch.org>
Message-ID: <CAFDcVCT_=9EfVW=ZZy_Q7Nw7YZxJgmpveK1BUci7iDRtVdKsGQ@mail.gmail.com>

On Mon, Oct 27, 2014 at 11:23 AM, Dan Tenenbaum <dtenenba at fredhutch.org> wrote:
>
>
> ----- Original Message -----
>> From: "Dan Tenenbaum" <dtenenba at fredhutch.org>
>> To: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
>> Cc: "R-devel" <r-devel at r-project.org>
>> Sent: Monday, October 27, 2014 11:21:59 AM
>> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX Mavericks (10.9)?
>>
>>
>>
>> ----- Original Message -----
>> > From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
>> > To: "R-devel" <r-devel at r-project.org>
>> > Sent: Monday, October 27, 2014 11:16:10 AM
>> > Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same
>> > as for OSX Mavericks (10.9)?
>> >
>> > I'm trying to help someone to troubleshoot possible OSX Yosemite
>> > issues, but I've only got access to OSX (< 10.9) so I cannot check
>> > myself.
>> >
>> > When building/installing binary R packages, there are different
>> > binaries depending on OSX version.  For instance, CRAN provides
>> > different binaries for 'OS X Snow Leopard' and 'OS X Mavericks',
>> > e.g.
>> > http://cran.r-project.org/web/packages/matrixStats/index.html.
>> >
>> > What about the new OSX Yosemite?  From
>> > http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite
>> > it
>> > looks like its binaries are the same/compatible with those of 'OS X
>> > Mavericks' - can someone please confirm this?  Another way to put
>> > it,
>> > if a repository provides OSX Mavericks binaries will an OSX
>> > Yosemite
>> > user install these or we s/he fall back to installing from source?
>> >
>>
>> Yes, a Yosemite user will by default be installing packages built on
>> Mavericks using the Mavericks build of R, and they should work.
>>
>
> Provided of course that that Yosemite user is using the Mavericks build of R. They could also be using the Snow Leopard build of R which should also work, and would be installing by default packages build on Snow Leopard using the Snow Leopard build of R.

Thanks for this Dan.

As far as I understand, for an OSX user to install binary packages
option 'pkgType' has to be set to either "mac.binary" or
"mac.binary.mavericks".  A few questions for clarification:

Q. Is it the default that 'pkgType' be set to "mac.binary" on OSX (<
10.9) and to "mac.binary.mavericks" on OSX (>= 10.9)?

Q. Are you saying that if an OSX (>= 10.9) user uses
options(pkgType="mac.binary"), then install.packages() will install
the OSX 10.6 (Snow Leopard) binaries *and* that these binaries are
backward compatible and should work equally well?

Q. In other words, if a user have problems with a particular OSX 10.9
(Mavericks) binary, would a first step of troubleshooting be to ask
that user to try the OSX 10.6 (Snow Leopard) build?

Q. If a user has options(pkgType="mac.binary.mavericks"), but the
repository does not provide such binaries, will install.packages()
fall back to "mac.binary", or will it go directly to "source"?

/Henrik

PS. <rant>From a non-active OSX user, using names instead of numbers
to refer to versions is cute but insane. You need a very good memory
to keep track of the ordering of Snow Leopard, Leopard, Mavericks etc.
and it's not getting easier.</rant>  It would be great if R/BioC and
everyone else would always present the version number when talking
about OSX version and only use the name for redundancy.

>
> Dan
>
>
>> Dan
>>
>>
>> > Thanks
>> >
>> > Henrik
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From dtenenba at fredhutch.org  Mon Oct 27 20:33:50 2014
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 27 Oct 2014 12:33:50 -0700 (PDT)
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for
 OSX Mavericks (10.9)?
In-Reply-To: <CAFDcVCT_=9EfVW=ZZy_Q7Nw7YZxJgmpveK1BUci7iDRtVdKsGQ@mail.gmail.com>
Message-ID: <417165047.270497.1414438430656.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> Cc: "R-devel" <r-devel at r-project.org>
> Sent: Monday, October 27, 2014 12:21:49 PM
> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX Mavericks (10.9)?
> 
> On Mon, Oct 27, 2014 at 11:23 AM, Dan Tenenbaum
> <dtenenba at fredhutch.org> wrote:
> >
> >
> > ----- Original Message -----
> >> From: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> >> To: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> >> Cc: "R-devel" <r-devel at r-project.org>
> >> Sent: Monday, October 27, 2014 11:21:59 AM
> >> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the
> >> same as for OSX Mavericks (10.9)?
> >>
> >>
> >>
> >> ----- Original Message -----
> >> > From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> >> > To: "R-devel" <r-devel at r-project.org>
> >> > Sent: Monday, October 27, 2014 11:16:10 AM
> >> > Subject: [Rd] OSX Yosemite (10.10): Are package binaries the
> >> > same
> >> > as for OSX Mavericks (10.9)?
> >> >
> >> > I'm trying to help someone to troubleshoot possible OSX Yosemite
> >> > issues, but I've only got access to OSX (< 10.9) so I cannot
> >> > check
> >> > myself.
> >> >
> >> > When building/installing binary R packages, there are different
> >> > binaries depending on OSX version.  For instance, CRAN provides
> >> > different binaries for 'OS X Snow Leopard' and 'OS X Mavericks',
> >> > e.g.
> >> > http://cran.r-project.org/web/packages/matrixStats/index.html.
> >> >
> >> > What about the new OSX Yosemite?  From
> >> > http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite
> >> > it
> >> > looks like its binaries are the same/compatible with those of
> >> > 'OS X
> >> > Mavericks' - can someone please confirm this?  Another way to
> >> > put
> >> > it,
> >> > if a repository provides OSX Mavericks binaries will an OSX
> >> > Yosemite
> >> > user install these or we s/he fall back to installing from
> >> > source?
> >> >
> >>
> >> Yes, a Yosemite user will by default be installing packages built
> >> on
> >> Mavericks using the Mavericks build of R, and they should work.
> >>
> >
> > Provided of course that that Yosemite user is using the Mavericks
> > build of R. They could also be using the Snow Leopard build of R
> > which should also work, and would be installing by default
> > packages build on Snow Leopard using the Snow Leopard build of R.
> 
> Thanks for this Dan.
> 
> As far as I understand, for an OSX user to install binary packages
> option 'pkgType' has to be set to either "mac.binary" or
> "mac.binary.mavericks".  A few questions for clarification:
> 
> Q. Is it the default that 'pkgType' be set to "mac.binary" on OSX (<
> 10.9) and to "mac.binary.mavericks" on OSX (>= 10.9)?
> 

> Q. Are you saying that if an OSX (>= 10.9) user uses
> options(pkgType="mac.binary"), then install.packages() will install
> the OSX 10.6 (Snow Leopard) binaries *and* that these binaries are
> backward compatible and should work equally well?
> 
> Q. In other words, if a user have problems with a particular OSX 10.9
> (Mavericks) binary, would a first step of troubleshooting be to ask
> that user to try the OSX 10.6 (Snow Leopard) build?
> 
> Q. If a user has options(pkgType="mac.binary.mavericks"), but the
> repository does not provide such binaries, will install.packages()
> fall back to "mac.binary", or will it go directly to "source"?
> 


First of all, this should be on R-SIG-Mac. 

It all depends on what build of R you are using. You can be on Snow Leopard or later (including Mavericks and Yosemite)  and use the Snow Leopard build. The default package type will be mac.binary.

You can be on Mavericks or later and using the Mavericks build of R and your package type will by default be mac.binary.mavericks.

The two types of binary packages are NOT binary compatible! You should not mix and match them. (Technically, if a given package does not have native code in it, it should work, but you don't really want to go there.)

If you're using the Mavericks build of R and the repository does not provide mac.binary.mavericks packages, don't (see above) install mac.binary packages, install from source.

Dan



> /Henrik
> 
> PS. <rant>From a non-active OSX user, using names instead of numbers
> to refer to versions is cute but insane. You need a very good memory
> to keep track of the ordering of Snow Leopard, Leopard, Mavericks
> etc.
> and it's not getting easier.</rant>  It would be great if R/BioC and
> everyone else would always present the version number when talking
> about OSX version and only use the name for redundancy.
> 
> >
> > Dan
> >
> >
> >> Dan
> >>
> >>
> >> > Thanks
> >> >
> >> > Henrik
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>


From mmuurr at gmail.com  Mon Oct 27 22:23:58 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 27 Oct 2014 15:23:58 -0600
Subject: [Rd] proper use of reg.finalizer to close connections
In-Reply-To: <CAFDcVCRpqos_hyNy5SgKs2NRE6UCTh9bfhGkqZONtGCuD53gjQ@mail.gmail.com>
References: <CA+YV+HyRA0Yp5JCxUq4eMZxRAGnfJX3en44Ez1753OCWDUpQgg@mail.gmail.com>
	<CABtg=Kmj6vr=vZNGQWQEGyjq57TNfi=2v9nVvc4qxS3JZ8ShZg@mail.gmail.com>
	<CA+YV+Hz03WOqHb_43O3BoQR7p-HuqwiyazfVNttqNwmZR_AutA@mail.gmail.com>
	<CABtg=KnpGGb=ZaN2MdCD-jFKbZG3+KRu_G8PA6jd-VTS9J03zw@mail.gmail.com>
	<CA+YV+HweSQ6CkCmh2QFDkZKCZstOc_3sMjvUR2cTaF-y4BCjEg@mail.gmail.com>
	<CAFDcVCTKr4qsuT3ruc3-N8ESS=PAGYQCbtzWNRxyAmmpBsBWpA@mail.gmail.com>
	<CA+YV+Hxmy1eS0YXCcX9wqANmxHF+mah+WN6Pext=vATxpoEapg@mail.gmail.com>
	<CA+YV+HzwcDy6Wva76Fr6E+32ZCXWG+bf+RckOTNtuv4oeCsP_w@mail.gmail.com>
	<CAFDcVCRpqos_hyNy5SgKs2NRE6UCTh9bfhGkqZONtGCuD53gjQ@mail.gmail.com>
Message-ID: <CA+YV+Hyn6mu_bt19xm_Gz=T0C-OmhLAnxO+PZbw_T4sBCSSLkw@mail.gmail.com>

yup... for context, the finalizer code calls functions from packages
that are imported by my package.
so, i think (unless something else has gone seriously wrong), those
imported namespaces should still be available prior to my package's
unloading.
(and if imported namespaces are detached prior to the dependent
package's unloading, well, then, perhaps i'll just re-write all of
this in <insert your favorite other language here>.)

thanks again!

-m

On Mon, Oct 27, 2014 at 11:27 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> ...and don't forget to make sure all the function that .myFinalizer()
> calls are also around. /Henrik
>
> On Mon, Oct 27, 2014 at 10:10 AM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Eh, after some flailing, I think I solved it.
>> I _think_ this pattern should guarantee that the finalizer function is
>> still present when needed:
>>
>> .STATE_CONTAINER <- new.env(parent = emptyenv())
>> .STATE_CONTAINER$some_state_variable <- ## some code
>> .STATE_CONTAINER$some_other_state_variable <- ## some code
>>
>> .myFinalizer <- function(name_of_state_variable_to_clean_up)
>>
>> .onLoad <- function(libname, pkgname) {
>>     reg.finalizer(
>>         e = parent.env(environment()),
>>         f = function(env) sapply(ls(env$.STATE_CONTAINER), .myFinalizer),
>>         onexit = TRUE)
>> }
>>
>> This way, the finalizer is registered on the enclosing environment of
>> the .onLoad function, which should be the package environment itself.
>> And that means .myFinalizer should still be around when it's called
>> during q() or unload/gc().
>> Effectively, the finalizer is tied to the entire package, rather than
>> the state variable container(s), which might not be the most elegant
>> solution, but it should work well enough for most purposes.
>>
>> Cheers and thanks for the advice,
>>
>> -m
>>
>> On Mon, Oct 27, 2014 at 12:18 AM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> Ah, good point, I hadn't thought of that detail.
>>> Would moving reg.finalizer back outside of .onLoad and hooking it to the
>>> package's environment itself work (more safely)?
>>> Something like:
>>> finalizerFunction <- ## cleanup code
>>> reg.finalizer(parent.env(), finalizerFunction)
>>>
>>> -m
>>>
>>> On Oct 26, 2014 11:03 PM, "Henrik Bengtsson" <hb at biostat.ucsf.edu> wrote:
>>>>
>>>> On Sun, Oct 26, 2014 at 8:14 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>>> > Ah (again)!
>>>> > Even with my fumbling presentation of the issue, you gave me the hint
>>>> > that solved it, thanks!
>>>> >
>>>> > Yes, the reg.finalizer call needs to be wrapped in an .onLoad hook so
>>>> > it's not called once during package installation and then never again.
>>>> > And once I switched to using ls() (instead of names()), everything
>>>> > works as expected.
>>>> >
>>>> > So, the package code effectively looks like so:
>>>> >
>>>> > .CONNS <- new.env(parent = emptyenv())
>>>> > .onLoad <- function(libname, pkgname) {
>>>> >     reg.finalizer(.CONNS, function(x) sapply(ls(x), .disconnect))
>>>> > }
>>>> > .disconnect <- function(x) {
>>>> >     ## handle disconnection of .CONNS[[x]] here
>>>> > }
>>>>
>>>> In your example above, I would be concerned about what happens if you
>>>> detach/unload your package, because then you're finalizer is still
>>>> registered and will be called whenever '.CONNS' is being garbage
>>>> collector (or there after).  However, the finalizer function calls
>>>> .disconnect(), which is no longer available.
>>>>
>>>> Finalizers should be used with great care, because you're not in
>>>> control in what order things are occurring and what "resources" are
>>>> around when the finalizer function is eventually called and when it is
>>>> called.  I've been bitten by this a few times and it can be very hard
>>>> to reproduce and troubleshoot such bugs.  See also the 'Note' of
>>>> ?reg.finalizer.
>>>>
>>>> My $.02
>>>>
>>>> /Henrik
>>>>
>>>> >
>>>> > Cheers and thanks!
>>>> >
>>>> > -m
>>>> >
>>>> >
>>>> >
>>>> >
>>>> > On Sun, Oct 26, 2014 at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>> > wrote:
>>>> >> Well, to be honest I don't understand fully what you are trying to do.
>>>> >> If you want to run code when the package is detached or when it is
>>>> >> unloaded, then use a hook:
>>>> >> http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Load-hooks
>>>> >>
>>>> >> If you want to run code when an object is freed, then use a finalizer.
>>>> >>
>>>> >> Note that when you install a package, R runs all the code in the
>>>> >> package and only stores the results of the code in the installed
>>>> >> package. So if you create an object outside of a function in your
>>>> >> package, then only the object will be stored in the package, but not
>>>> >> the code that creates it. The object will be simply loaded when you
>>>> >> load the package, but it will not be re-created.
>>>> >>
>>>> >> Now, I am not sure what happens if you set the finalizer on such an
>>>> >> object in the package. I can imagine that the finalizer will not be
>>>> >> saved into the package, and is only used once, when
>>>> >> building/installing the package. In this case you'll need to set the
>>>> >> finalizer in .onLoad().
>>>> >>
>>>> >> Gabor
>>>> >>
>>>> >> On Sun, Oct 26, 2014 at 10:35 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>>> >>> Ah, thanks for the ls() vs names() tip!
>>>> >>> (But sadly, it didn't solve the issue... )
>>>> >>>
>>>> >>> So, after some more tinkering, I believe the finalizer is being called
>>>> >>> _sometimes_.
>>>> >>> I changed the reg.finalizer(...) call to just this:
>>>> >>>
>>>> >>> reg.finalizer(.CONNS, function(x) print("foo"), onexit  = TRUE)
>>>> >>>
>>>> >>> Now, when I load the package and detach(..., unload = TRUE), nothing
>>>> >>> prints.
>>>> >>> And when I quit, nothing prints.
>>>> >>>
>>>> >>> If I, however, create an environment on the workspace, like so:
>>>> >>>> e <- new.env(parent = emptyenv())
>>>> >>>> reg.finalizer(e, function(x) print("bar"), onexit = TRUE)
>>>> >>> When I quit (or rm(e)), "bar" is printed.
>>>> >>> But no "foo" (corresponding to same sequence of code, just in the
>>>> >>> package instead).
>>>> >>>
>>>> >>> BUT(!), when I _install_ the package, "foo" is printed at the end of
>>>> >>> the "**testing if installed package can be loaded" installation
>>>> >>> segment.
>>>> >>> So, somehow the R script that tests for package loading/unloading is
>>>> >>> triggering the finalizer (which is good).
>>>> >>> Yet, I cannot seem to trigger it myself when either quitting or
>>>> >>> forcing a package unload (which is bad).
>>>> >>>
>>>> >>> Any ideas why the installation script would successfully trigger a
>>>> >>> finalizer while standard unloading or quitting wouldn't?
>>>> >>>
>>>> >>> Cheers and thanks!
>>>> >>>
>>>> >>> -m
>>>> >>>
>>>> >>> On Sun, Oct 26, 2014 at 8:03 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>> >>> wrote:
>>>> >>>> Hmmm, I guess you will want to put the actual objects that represent
>>>> >>>> the connections into the environment, at least this seems to be the
>>>> >>>> easiest to me. Btw. you need ls() to list the contents of an
>>>> >>>> environment, instead of names(). E.g.
>>>> >>>>
>>>> >>>> e <- new.env()
>>>> >>>> e$foo <- 10
>>>> >>>> e$bar <- "aaa"
>>>> >>>> names(e)
>>>> >>>> #> NULL
>>>> >>>> ls(e)
>>>> >>>> #> [1] "bar" "foo"
>>>> >>>> reg.finalizer(e, function(x) { print(ls(x)) })
>>>> >>>> #> NULL
>>>> >>>> rm(e)
>>>> >>>> gc()
>>>> >>>> #> [1] "bar" "foo"
>>>> >>>> #>           used (Mb) gc trigger  (Mb) max used  (Mb)
>>>> >>>> #> Ncells 1528877 81.7    2564037 137.0  2564037 137.0
>>>> >>>> #> Vcells 3752538 28.7    7930384  60.6  7930356  60.6
>>>> >>>>
>>>> >>>> More precisely, you probably want to represent each connection as a
>>>> >>>> separate environment, with its own finalizer. Hope this helps,
>>>> >>>> Gabor
>>>> >>>>
>>>> >>>> On Sun, Oct 26, 2014 at 9:49 PM, Murat Tasan <mmuurr at gmail.com>
>>>> >>>> wrote:
>>>> >>>>> Hi all, I have a question about finalizers...
>>>> >>>>> I have a package that manages state for a few connections, and I'd
>>>> >>>>> like to ensure that these connections are 'cleanly' closed upon
>>>> >>>>> either
>>>> >>>>> (i) R quitting or (ii) an unloading of the package.
>>>> >>>>> So, in a pared-down example package with a single R file, it looks
>>>> >>>>> something like:
>>>> >>>>>
>>>> >>>>> ##### BEGIN PACKAGE CODE #####
>>>> >>>>> .CONNS <- new.env(parent = emptyenv())
>>>> >>>>> .CONNS$resource1 <- NULL
>>>> >>>>> .CONNS$resource2 <- NULL
>>>> >>>>> ## some more .CONNS resources...
>>>> >>>>>
>>>> >>>>> reg.finalizer(.CONNS, function(x) sapply(names(x), disconnect),
>>>> >>>>> onexit = TRUE)
>>>> >>>>>
>>>> >>>>> connect <- function(x) {
>>>> >>>>>   ## here lies code to connect and update .CONNS[[x]]
>>>> >>>>> }
>>>> >>>>> disconnect <- function(x) {
>>>> >>>>>   print(sprintf("disconnect(%s)", x))
>>>> >>>>>   ## here lies code to disconnect and update .CONNS[[x]]
>>>> >>>>> }
>>>> >>>>> ##### END PACKAGE CODE #####
>>>> >>>>>
>>>> >>>>> The print(...) statement in disconnect(...) is there as a trace, as
>>>> >>>>> I
>>>> >>>>> hoped that I'd see disconnect(...) being called when I quit (or
>>>> >>>>> detach(..., unload = TRUE)).
>>>> >>>>> But, it doesn't appear that disconnect(...) is ever called when the
>>>> >>>>> package (and .CONNS) falls out of memory/scope (and I ran gc() after
>>>> >>>>> detach(...), just to be sure).
>>>> >>>>>
>>>> >>>>> In a second 'shot-in-the-dark' attempt, I placed the reg.finalizer
>>>> >>>>> call inside an .onLoad function, but that didn't seem to work,
>>>> >>>>> either.
>>>> >>>>>
>>>> >>>>> I'm guessing my use of reg.finalizer is way off-base here... but I
>>>> >>>>> cannot infer from the reg.finalizer man page what I might be doing
>>>> >>>>> wrong.
>>>> >>>>> Is there a way to see, at the R-system level, what functions have
>>>> >>>>> been
>>>> >>>>> registered as finalizers?
>>>> >>>>>
>>>> >>>>> Thanks for any pointers!
>>>> >>>>>
>>>> >>>>> -Murat
>>>> >>>>>
>>>> >>>>> ______________________________________________
>>>> >>>>> R-devel at r-project.org mailing list
>>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> >>>
>>>> >>> ______________________________________________
>>>> >>> R-devel at r-project.org mailing list
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> >
>>>> > ______________________________________________
>>>> > R-devel at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Oct 28 10:32:42 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 10:32:42 +0100
Subject: [Rd] RFC: is.whole() ? {"how to judge if a variable is an integer"}
In-Reply-To: <CAF8bMcaAnGvZiTrrmMMnFX2Oe4iExCM8VxqqUOoHN6uGY44Xew@mail.gmail.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
	<8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
	<CAF8bMcaAnGvZiTrrmMMnFX2Oe4iExCM8VxqqUOoHN6uGY44Xew@mail.gmail.com>
Message-ID: <21583.25274.770806.923857@stat.math.ethz.ch>

Diverted to R-devel, as I'm requesting comments about a proposal
to add is.whole() to R just so this issue does not trail on for
centuries (;-), see below.

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Sat, 18 Oct 2014 10:33:05 -0700 writes:

    > 3. all.equal(a, as.integer(a))
    > Note that this one tests if 'a' can be stored accurately as a 32-bit signed
    > integer.  If you want to know if 'a' can be used as an accurate count, then
    > you want to test if a+1>a (use abs() in case a is negative).  E.g., try this
    > for a<-2^49-1, about 5*10^14.

    > You have to decide what properties of integers you are interested in.

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

good point, thank you, Bill.

This whole issue comes up about once year (at least), it seems to me,
and every time there are some good and some not so good propositions,
some aiming for vectorized / whole object solutions some, only
assuming scalar input.

Indeed, I'd claim that all three proposals cited below are not
good enough in one way or the other.... though one
could argue that a "tolerance = 0" version would be good enough,
and hence the    
    	  	  function(x) x %% 1  == 0
would be sufficient. 

In the CRAN package 'sfsmisc' (which I maintain), Alain Hauser 
recently added an

	 is.whole()

function which works "vectorized" and uses a 'tolerance' and
then all.equal(), but in better way than (most / all ?) what was proposed in
this thread (line 486 ff of 
 https://github.com/mmaechler/sfsmisc/blob/master/R/misc-goodies.R ).

Further, the CRAN packages
 'gmp'   ("infinite" precision integer and rational arithmetic) and
 'Rmpfr' ('infinite' precision floating point arithmetic) contain
an S3 generic  is.whole() function and methods for their own
number classes and a default method (( which "however" assumes
a tolerance of zero, the same as the  x %% 1 == 0 proposal)).

Given all this, the r-help and stackoverflow threads,
maybe we should decide that such an is.whole() function should
be added to R and maintained (by me for the time), so we do have
a better place to point people to, and well documented -- and
eventually "optimized" -- behavior ?

Personally I do think I'd want a "signature" of
    function (x, tolerance = sqrt(.Machine$double.eps))


Martin


    > On Sat, Oct 18, 2014 at 10:02 AM, PO SU <rhelpmaillist at 163.com> wrote:
    >> 
    >> Tks for your help, after investigate in your link, i find there seems three ways can be adoped:
    >> 1.    is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol)
    >> e.g. is.wholenumber(1)
    >> 2.   x%%1==0
    >> 
    >> 
    >> 3. all.equal(a, as.integer(a))
    >> 
    >> 
    >> and also included your last suggestion using floor. and also tks for other helpers?
    >> --
    >> 
    >> PO SU
    >> mail: desolator88 at 163.com
    >> Majored in Statistics from SJTU
    >> 
    >> At 2014-10-18 22:48:15, "Sergio Fonda" <sergio.fonda99 at gmail.com> wrote:
    >> 
    >> Sorry for my previous hurry misunderstanding.
    >> Try this link:
    >> http://stackoverflow.com/questions/3476782/how-to-check-if-the-number-is-integer
    >> 
    >> 2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:
    >> 
    >> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply, when i want to know 1 is an integer,  there seems no easy way to get the answer.
    >> 
    >> So, is there anyone happen to know it?
    >> 

    >> 
    >> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
    >> 
    >>>> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
    >> 
    >>> If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.
    >> 
    >>> 
    >> 
    >>> See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.
    >> 
    >>> 
    >> 
    >>> S


From murdoch.duncan at gmail.com  Tue Oct 28 11:48:07 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Oct 2014 06:48:07 -0400
Subject: [Rd] RFC: is.whole() ? {"how to judge if a variable is an
	integer"}
In-Reply-To: <21583.25274.770806.923857@stat.math.ethz.ch>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>	<8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>	<CAF8bMcaAnGvZiTrrmMMnFX2Oe4iExCM8VxqqUOoHN6uGY44Xew@mail.gmail.com>
	<21583.25274.770806.923857@stat.math.ethz.ch>
Message-ID: <544F7467.7030706@gmail.com>

On 28/10/2014, 5:32 AM, Martin Maechler wrote:
> Diverted to R-devel, as I'm requesting comments about a proposal
> to add is.whole() to R just so this issue does not trail on for
> centuries (;-), see below.
> 

I didn't read the thread in question, but I think Bill's comment is
crucial:  what properties of integers are you interested in testing?

One that comes up a lot is that some non-integral values print as
integers, and people get confused when using them as indices.  For
example, this prints results that surprise some people:

x <- 1:10
index <- 4 - 1.e-10
index
x[index]

I would think is.whole(index) should return FALSE here, but the sfsmisc
function defaults to a nonzero tolerance, and returns TRUE.

Duncan Murdoch

>>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>>     on Sat, 18 Oct 2014 10:33:05 -0700 writes:
> 
>     > 3. all.equal(a, as.integer(a))
>     > Note that this one tests if 'a' can be stored accurately as a 32-bit signed
>     > integer.  If you want to know if 'a' can be used as an accurate count, then
>     > you want to test if a+1>a (use abs() in case a is negative).  E.g., try this
>     > for a<-2^49-1, about 5*10^14.
> 
>     > You have to decide what properties of integers you are interested in.
> 
>     > Bill Dunlap
>     > TIBCO Software
>     > wdunlap tibco.com
> 
> good point, thank you, Bill.
> 
> This whole issue comes up about once year (at least), it seems to me,
> and every time there are some good and some not so good propositions,
> some aiming for vectorized / whole object solutions some, only
> assuming scalar input.
> 
> Indeed, I'd claim that all three proposals cited below are not
> good enough in one way or the other.... though one
> could argue that a "tolerance = 0" version would be good enough,
> and hence the    
>     	  	  function(x) x %% 1  == 0
> would be sufficient. 
> 
> In the CRAN package 'sfsmisc' (which I maintain), Alain Hauser 
> recently added an
> 
> 	 is.whole()
> 
> function which works "vectorized" and uses a 'tolerance' and
> then all.equal(), but in better way than (most / all ?) what was proposed in
> this thread (line 486 ff of 
>  https://github.com/mmaechler/sfsmisc/blob/master/R/misc-goodies.R ).
> 
> Further, the CRAN packages
>  'gmp'   ("infinite" precision integer and rational arithmetic) and
>  'Rmpfr' ('infinite' precision floating point arithmetic) contain
> an S3 generic  is.whole() function and methods for their own
> number classes and a default method (( which "however" assumes
> a tolerance of zero, the same as the  x %% 1 == 0 proposal)).
> 
> Given all this, the r-help and stackoverflow threads,
> maybe we should decide that such an is.whole() function should
> be added to R and maintained (by me for the time), so we do have
> a better place to point people to, and well documented -- and
> eventually "optimized" -- behavior ?
> 
> Personally I do think I'd want a "signature" of
>     function (x, tolerance = sqrt(.Machine$double.eps))
> 
> 
> Martin
> 
> 
>     > On Sat, Oct 18, 2014 at 10:02 AM, PO SU <rhelpmaillist at 163.com> wrote:
>     >> 
>     >> Tks for your help, after investigate in your link, i find there seems three ways can be adoped:
>     >> 1.    is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol)
>     >> e.g. is.wholenumber(1)
>     >> 2.   x%%1==0
>     >> 
>     >> 
>     >> 3. all.equal(a, as.integer(a))
>     >> 
>     >> 
>     >> and also included your last suggestion using floor. and also tks for other helpers?
>     >> --
>     >> 
>     >> PO SU
>     >> mail: desolator88 at 163.com
>     >> Majored in Statistics from SJTU
>     >> 
>     >> At 2014-10-18 22:48:15, "Sergio Fonda" <sergio.fonda99 at gmail.com> wrote:
>     >> 
>     >> Sorry for my previous hurry misunderstanding.
>     >> Try this link:
>     >> http://stackoverflow.com/questions/3476782/how-to-check-if-the-number-is-integer
>     >> 
>     >> 2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:
>     >> 
>     >> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply, when i want to know 1 is an integer,  there seems no easy way to get the answer.
>     >> 
>     >> So, is there anyone happen to know it?
>     >> 
> 
>     >> 
>     >> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
>     >> 
>     >>>> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
>     >> 
>     >>> If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.
>     >> 
>     >>> 
>     >> 
>     >>> See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.
>     >> 
>     >>> 
>     >> 
>     >>> S
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From therneau at mayo.edu  Tue Oct 28 13:44:20 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 28 Oct 2014 07:44:20 -0500
Subject: [Rd] is.whole()
In-Reply-To: <mailman.23.1414494007.30795.r-devel@r-project.org>
References: <mailman.23.1414494007.30795.r-devel@r-project.org>
Message-ID: <58e5f6$jc59de@ironport9.mayo.edu>

Martin,
   I can't imagine using such a function myself, the reason being that as Bill and Duncan 
point out, the correct answer depends on the situation.
   But given the regular reappearance of this topic, I think that perhaps creation of your 
function is a good idea, largely to function as a repository for the knowlege.  If one 
takes that view, then perhas the function has two optional arguments: "case" and 
"tolerance".  The first would choose a scenario of "exact", "numeric", "count", etc, where 
exact refers to Duncan's case, numeric to your default, and count to Bill's  a+1 > a.  The 
second argument would be rarely used.
    The primary point of the function would be the "Details" section of its manual page. 
Whenver the issue comes up the response could then be "see the is.whole() function and its 
documentation".

Terry T.

On 10/28/2014 06:00 AM, r-devel-request at r-project.org wrote:
> Diverted to R-devel, as I'm requesting comments about a proposal
> to add is.whole() to R just so this issue does not trail on for
> centuries (;-), see below.
>
>>>>>> >>>>>


From maechler at stat.math.ethz.ch  Tue Oct 28 16:14:07 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 16:14:07 +0100
Subject: [Rd] is.whole()
In-Reply-To: <58e5f6$jc59de@ironport9.mayo.edu>
References: <mailman.23.1414494007.30795.r-devel@r-project.org>
	<58e5f6$jc59de@ironport9.mayo.edu>
Message-ID: <21583.45759.32052.263888@stat.math.ethz.ch>

>>>>> Therneau, Terry M , Ph D <therneau at mayo.edu>
>>>>>     on Tue, 28 Oct 2014 07:44:20 -0500 writes:

    > Martin,
    > I can't imagine using such a function myself, the reason being that as Bill and Duncan 
    > point out, the correct answer depends on the situation.

yes, of course.
OTOH, if the function is used for argument checking inside
another function, using such an  is.whole(.)  may come as a
handy, and well readable {because self explaining} expression.

    > But given the regular reappearance of this topic, I think that perhaps creation of your 
    > function is a good idea, largely to function as a repository for the knowlege.  If one 
    > takes that view, then perhas the function has two optional arguments: "case" and 
    > "tolerance".  The first would choose a scenario of "exact", "numeric", "count", etc, where 
    > exact refers to Duncan's case, numeric to your default, and count to Bill's  a+1 > a.  The 
    > second argument would be rarely used.

    > The primary point of the function would be the "Details" section of its manual page. 
    > Whenver the issue comes up the response could then be "see the is.whole() function and its 
    > documentation".

    > Terry T.

Thank you, Duncan, and Terry,

Yes, indeed, a primary point of the function would just be that:
A coherent place to point to (and \link{.} to e.g. from the
as.integer help page).

Apropos optional arguments and their defaults: It may indeed be
a better (than sfsmisc::is.whole 's default) idea to use a
default tolerence = 0 rather than  sqrt(.Machine$double.eps). ..
and I think the argument / principle of thinking of what happens
when "integer - indexing" with such numbers is also aa good one.
That one has the drawback of asymmetry, i.e., of treating  
4 + 1e-10 very differently than
4 - 1e-10

Martin



    > On 10/28/2014 06:00 AM, r-devel-request at r-project.org wrote:
    >> Diverted to R-devel, as I'm requesting comments about a proposal
    >> to add is.whole() to R just so this issue does not trail on for
    >> centuries (;-), see below.
    >>


From 538280 at gmail.com  Tue Oct 28 18:47:36 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 28 Oct 2014 11:47:36 -0600
Subject: [Rd] is.whole()
In-Reply-To: <21583.45759.32052.263888@stat.math.ethz.ch>
References: <mailman.23.1414494007.30795.r-devel@r-project.org>
	<58e5f6$jc59de@ironport9.mayo.edu>
	<21583.45759.32052.263888@stat.math.ethz.ch>
Message-ID: <CAFEqCdyAR=1XvThYP9UVLfde9-_1kpaY7G4K1nrXh9MstuQTww@mail.gmail.com>

Just to anticipate future discussion from math purists (and hopefully
not to throw too much of a wrench in the works), what would be the
return of:

is.whole(-1)

or

is.whole(-1L)

?

I can see arguments for both TRUE and FALSE from both the math purity
group and the "what will happen when I try to use this for
subsetting?" group.

On Tue, Oct 28, 2014 at 9:14 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Therneau, Terry M , Ph D <therneau at mayo.edu>
>>>>>>     on Tue, 28 Oct 2014 07:44:20 -0500 writes:
>
>     > Martin,
>     > I can't imagine using such a function myself, the reason being that as Bill and Duncan
>     > point out, the correct answer depends on the situation.
>
> yes, of course.
> OTOH, if the function is used for argument checking inside
> another function, using such an  is.whole(.)  may come as a
> handy, and well readable {because self explaining} expression.
>
>     > But given the regular reappearance of this topic, I think that perhaps creation of your
>     > function is a good idea, largely to function as a repository for the knowlege.  If one
>     > takes that view, then perhas the function has two optional arguments: "case" and
>     > "tolerance".  The first would choose a scenario of "exact", "numeric", "count", etc, where
>     > exact refers to Duncan's case, numeric to your default, and count to Bill's  a+1 > a.  The
>     > second argument would be rarely used.
>
>     > The primary point of the function would be the "Details" section of its manual page.
>     > Whenver the issue comes up the response could then be "see the is.whole() function and its
>     > documentation".
>
>     > Terry T.
>
> Thank you, Duncan, and Terry,
>
> Yes, indeed, a primary point of the function would just be that:
> A coherent place to point to (and \link{.} to e.g. from the
> as.integer help page).
>
> Apropos optional arguments and their defaults: It may indeed be
> a better (than sfsmisc::is.whole 's default) idea to use a
> default tolerence = 0 rather than  sqrt(.Machine$double.eps). ..
> and I think the argument / principle of thinking of what happens
> when "integer - indexing" with such numbers is also aa good one.
> That one has the drawback of asymmetry, i.e., of treating
> 4 + 1e-10 very differently than
> 4 - 1e-10
>
> Martin
>
>
>
>     > On 10/28/2014 06:00 AM, r-devel-request at r-project.org wrote:
>     >> Diverted to R-devel, as I'm requesting comments about a proposal
>     >> to add is.whole() to R just so this issue does not trail on for
>     >> centuries (;-), see below.
>     >>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From hb at biostat.ucsf.edu  Tue Oct 28 19:58:44 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 28 Oct 2014 11:58:44 -0700
Subject: [Rd] OSX Yosemite (10.10): Are package binaries the same as for
 OSX Mavericks (10.9)?
In-Reply-To: <417165047.270497.1414438430656.JavaMail.root@fredhutch.org>
References: <CAFDcVCT_=9EfVW=ZZy_Q7Nw7YZxJgmpveK1BUci7iDRtVdKsGQ@mail.gmail.com>
	<417165047.270497.1414438430656.JavaMail.root@fredhutch.org>
Message-ID: <CAFDcVCRJXgjP=gmnreqJFEDhJrPVaUgqVMUkwNEaxX7EUOX1nA@mail.gmail.com>

On Mon, Oct 27, 2014 at 12:33 PM, Dan Tenenbaum <dtenenba at fredhutch.org> wrote:
>
>
> ----- Original Message -----
>> From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
>> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
>> Cc: "R-devel" <r-devel at r-project.org>
>> Sent: Monday, October 27, 2014 12:21:49 PM
>> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the same as for OSX Mavericks (10.9)?
>>
>> On Mon, Oct 27, 2014 at 11:23 AM, Dan Tenenbaum
>> <dtenenba at fredhutch.org> wrote:
>> >
>> >
>> > ----- Original Message -----
>> >> From: "Dan Tenenbaum" <dtenenba at fredhutch.org>
>> >> To: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
>> >> Cc: "R-devel" <r-devel at r-project.org>
>> >> Sent: Monday, October 27, 2014 11:21:59 AM
>> >> Subject: Re: [Rd] OSX Yosemite (10.10): Are package binaries the
>> >> same as for OSX Mavericks (10.9)?
>> >>
>> >>
>> >>
>> >> ----- Original Message -----
>> >> > From: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
>> >> > To: "R-devel" <r-devel at r-project.org>
>> >> > Sent: Monday, October 27, 2014 11:16:10 AM
>> >> > Subject: [Rd] OSX Yosemite (10.10): Are package binaries the
>> >> > same
>> >> > as for OSX Mavericks (10.9)?
>> >> >
>> >> > I'm trying to help someone to troubleshoot possible OSX Yosemite
>> >> > issues, but I've only got access to OSX (< 10.9) so I cannot
>> >> > check
>> >> > myself.
>> >> >
>> >> > When building/installing binary R packages, there are different
>> >> > binaries depending on OSX version.  For instance, CRAN provides
>> >> > different binaries for 'OS X Snow Leopard' and 'OS X Mavericks',
>> >> > e.g.
>> >> > http://cran.r-project.org/web/packages/matrixStats/index.html.
>> >> >
>> >> > What about the new OSX Yosemite?  From
>> >> > http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Yosemite
>> >> > it
>> >> > looks like its binaries are the same/compatible with those of
>> >> > 'OS X
>> >> > Mavericks' - can someone please confirm this?  Another way to
>> >> > put
>> >> > it,
>> >> > if a repository provides OSX Mavericks binaries will an OSX
>> >> > Yosemite
>> >> > user install these or we s/he fall back to installing from
>> >> > source?
>> >> >
>> >>
>> >> Yes, a Yosemite user will by default be installing packages built
>> >> on
>> >> Mavericks using the Mavericks build of R, and they should work.
>> >>
>> >
>> > Provided of course that that Yosemite user is using the Mavericks
>> > build of R. They could also be using the Snow Leopard build of R
>> > which should also work, and would be installing by default
>> > packages build on Snow Leopard using the Snow Leopard build of R.
>>
>> Thanks for this Dan.
>>
>> As far as I understand, for an OSX user to install binary packages
>> option 'pkgType' has to be set to either "mac.binary" or
>> "mac.binary.mavericks".  A few questions for clarification:
>>
>> Q. Is it the default that 'pkgType' be set to "mac.binary" on OSX (<
>> 10.9) and to "mac.binary.mavericks" on OSX (>= 10.9)?
>>
>
>> Q. Are you saying that if an OSX (>= 10.9) user uses
>> options(pkgType="mac.binary"), then install.packages() will install
>> the OSX 10.6 (Snow Leopard) binaries *and* that these binaries are
>> backward compatible and should work equally well?
>>
>> Q. In other words, if a user have problems with a particular OSX 10.9
>> (Mavericks) binary, would a first step of troubleshooting be to ask
>> that user to try the OSX 10.6 (Snow Leopard) build?
>>
>> Q. If a user has options(pkgType="mac.binary.mavericks"), but the
>> repository does not provide such binaries, will install.packages()
>> fall back to "mac.binary", or will it go directly to "source"?
>>
>
>
> First of all, this should be on R-SIG-Mac.

I considered that, but I'm also asking this as a package developer and
wonder what happens if someone installs my packages incorrectly and I
need to troubleshoot what's reported as a bugs but may not be, so I
though it would be more appropriate here.

>
> It all depends on what build of R you are using. You can be on Snow Leopard or later (including Mavericks and Yosemite)  and use the Snow Leopard build. The default package type will be mac.binary.
>
> You can be on Mavericks or later and using the Mavericks build of R and your package type will by default be mac.binary.mavericks.

Just for the record: I've verified that it is not possible to install
the Mavericks build of R on a pre-Mavericks OSX version by mistake; on
an OSX 10.6.8 machine I get:

$ wget http://r.research.att.com/mavericks/R-3.1-branch/R-3.1-branch-mavericks.pkg
$ sudo installer -pkg R-3.1-branch-mavericks.pkg -target "/"
...
installer: This build of R requires Mac OS X 10.9 or higher.
$

>
> The two types of binary packages are NOT binary compatible! You should not mix and match them. (Technically, if a given package does not have native code in it, it should work, but you don't really want to go there.)

I understand that packages without native code should work, but is
there a reason for why R and install.packages() allows such mix and
matching in the first place?  I've tested
install.packages("matrixStats", type="mac.binary.mavericks") on an OSX
10.6.8 machine and it install the package without complaints.
Wouldn't it be better then if it gave an error:

> install.packages("matrixStats", type="mac.binary.mavericks")
Installing package into '/Users/hb/Library/R/3.1/library'
(as 'lib' is unspecified)
Error in install.packages("matrixStats", type = "mac.binary.mavericks") :
  cannot install Mavericks binary packages on this platform

cf. install.packages("matrixStats", type = "win.binary")?

>
> If you're using the Mavericks build of R and the repository does not provide mac.binary.mavericks packages, don't (see above) install mac.binary packages, install from source.

Thanks for your answers they helped me a lot.

/Henrik

>
> Dan
>
>
>
>> /Henrik
>>
>> PS. <rant>From a non-active OSX user, using names instead of numbers
>> to refer to versions is cute but insane. You need a very good memory
>> to keep track of the ordering of Snow Leopard, Leopard, Mavericks
>> etc.
>> and it's not getting easier.</rant>  It would be great if R/BioC and
>> everyone else would always present the version number when talking
>> about OSX version and only use the name for redundancy.
>>
>> >
>> > Dan
>> >
>> >
>> >> Dan
>> >>
>> >>
>> >> > Thanks
>> >> >
>> >> > Henrik
>> >> >
>> >> > ______________________________________________
>> >> > R-devel at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>>


From patrick.a.oreilly at gmail.com  Wed Oct 29 12:31:20 2014
From: patrick.a.oreilly at gmail.com (Patrick O'Reilly)
Date: Wed, 29 Oct 2014 11:31:20 +0000
Subject: [Rd] terms function bug?
Message-ID: <CA+BxRLa3LO9BKxFDoJ2kfohE=T35-y2tHxC1w5qiGz40S53MRw@mail.gmail.com>

Hi,

I've noticed something strange when using the terms {stats} function.

R documentation describes the factors attribute of the terms.object as follows:

A matrix of variables by terms showing which variables appear in which terms.
The entries are 0 if the variable does not occur in the term, 1 if it does occur
and should be coded by contrasts, and 2 if it occurs and should be coded via
dummy variables for all levels (as when an intercept or lower-order term is
missing). If there are no terms other than an intercept and offsets, this is
numeric(0).
(http://stat.ethz.ch/R-manual/R-patched/library/stats/html/terms.object.html)

In the example below, I would expect Species to have a value of 2 since the
intercept is omitted. Indeed, when using model.matrix it is clear that Species
has been coded with dummy variables for all three levels.


f <- ~ -1 + Species

attr(terms(f, data=iris), "factors")
#        Species
#Species       1

levels(iris$Species)
#[1] "setosa"     "versicolor" "virginica"

colnames(model.matrix(f, iris))
#[1] "Speciessetosa"     "Speciesversicolor" "Speciesvirginica"


Is this a bug?

Many thanks in advance,

Pat


From winstonchang1 at gmail.com  Wed Oct 29 21:26:16 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Wed, 29 Oct 2014 15:26:16 -0500
Subject: [Rd] Unexpected behavior of identical() with language objects
Message-ID: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>

I ran into this and found the result very surprising:

identical( quote({ a }),  quote({ a }) )
# FALSE

It seems related to curly braces. For example, parens work fine:
identical( quote(( a )),  quote(( a )) )
# TRUE

Is this expected behavior? I can't seem to find anything in the help
for identical that relates to this.

-Winston


From josh.m.ulrich at gmail.com  Wed Oct 29 21:37:46 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 29 Oct 2014 15:37:46 -0500
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
Message-ID: <CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>

On Wed, Oct 29, 2014 at 3:26 PM, Winston Chang <winstonchang1 at gmail.com> wrote:
> I ran into this and found the result very surprising:
>
> identical( quote({ a }),  quote({ a }) )
> # FALSE
>
> It seems related to curly braces. For example, parens work fine:
> identical( quote(( a )),  quote(( a )) )
> # TRUE
>
> Is this expected behavior? I can't seem to find anything in the help
> for identical that relates to this.
>
It's not in ?identical, but ?Paren gives you some pointers.
str(quote((a))) and str(quote({a})) are also informative.

> -Winston
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From lorenz at usgs.gov  Wed Oct 29 21:44:31 2014
From: lorenz at usgs.gov (Lorenz, David)
Date: Wed, 29 Oct 2014 15:44:31 -0500
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
Message-ID: <CALxY2LcJzS18wh4_QPwmOnWJLvcwVM38y2b5y4djMjTh9fnSeQ@mail.gmail.com>

Fascinating! I tried the comparisons with all.equal(), expecting a
description of the difference, but TRUE was returned in both cases.
Dave


On Wed, Oct 29, 2014 at 3:26 PM, Winston Chang <winstonchang1 at gmail.com>
wrote:

> I ran into this and found the result very surprising:
>
> identical( quote({ a }),  quote({ a }) )
> # FALSE
>
> It seems related to curly braces. For example, parens work fine:
> identical( quote(( a )),  quote(( a )) )
> # TRUE
>
> Is this expected behavior? I can't seem to find anything in the help
> for identical that relates to this.
>
> -Winston
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Wed Oct 29 21:46:43 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 29 Oct 2014 15:46:43 -0500
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
	<CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>
Message-ID: <CABdHhvGtKp4-J6G--aJ1+Y-rNbugOtW0kzjuevvm_EdQTANnJw@mail.gmail.com>

>> Is this expected behavior? I can't seem to find anything in the help
>> for identical that relates to this.
>>
> It's not in ?identical, but ?Paren gives you some pointers.
> str(quote((a))) and str(quote({a})) are also informative.

Yes, looks like srcrefs are to blame:

x <- quote({ a })
y <- quote({ a })

identical(x, y)
# [1] FALSE

attr(x, "srcref") <- NULL
attr(x, "srcfile") <- NULL
attr(x, "wholeSrcref") <- NULL

attr(y, "srcref") <- NULL
attr(y, "srcfile") <- NULL
attr(y, "wholeSrcref") <- NULL
identical(x, y)
# [1] TRUE

Maybe identical() needs an ignore.srcref option? Normally when
comparing expressions or functions, you want to compare the code, not
it's textual representation.

Hadley

-- 
http://had.co.nz/


From winstonchang1 at gmail.com  Wed Oct 29 21:58:46 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Wed, 29 Oct 2014 15:58:46 -0500
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <CABdHhvGtKp4-J6G--aJ1+Y-rNbugOtW0kzjuevvm_EdQTANnJw@mail.gmail.com>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
	<CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>
	<CABdHhvGtKp4-J6G--aJ1+Y-rNbugOtW0kzjuevvm_EdQTANnJw@mail.gmail.com>
Message-ID: <CAFOpNVEnue7m5yViF6PzQ7jixZgykTZ+-h3+BxSm0Xz5JWtECw@mail.gmail.com>

Ah, I was using identical() to compare two function bodies. It returns
FALSE even when you remove srcrefs from the body:

f1 <- function(x) {
  if (TRUE) { x }
}
f2 <- function(x) {
  if (TRUE) { x }
}
f1b <- body(f1)
f2b <- body(f2)
attributes(f1b) <- NULL
attributes(f2b) <- NULL

# The bodies look the same with str()
str(f1b)
#  language {  if (TRUE) {; x; } }
str(f2b)
#  language {  if (TRUE) {; x; } }

identical(f1b, f2b)
# FALSE



What I didn't realize was that the curly brace inside the body also
independently captures srcrefs, but this isn't printed with str(f1b).
However, str() on a more targeted part of the object reveals them:
str(f1b[[2]][[3]])
# length 2 {  x }
#  - attr(*, "srcref")=List of 2
#   ..$ :Class 'srcref'  atomic [1:8] 2 13 2 13 13 13 2 2
#   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x452b2c0>
#   ..$ :Class 'srcref'  atomic [1:8] 2 15 2 15 15 15 2 2
#   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x452b2c0>
#  - attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment:
0x452b2c0>
#  - attr(*, "wholeSrcref")=Class 'srcref'  atomic [1:8] 1 0 2 17 0 17 1 2
#   .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x452b2c0>

-Winston

On Wed, Oct 29, 2014 at 3:46 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>> Is this expected behavior? I can't seem to find anything in the help
>>> for identical that relates to this.
>>>
>> It's not in ?identical, but ?Paren gives you some pointers.
>> str(quote((a))) and str(quote({a})) are also informative.
>
> Yes, looks like srcrefs are to blame:
>
> x <- quote({ a })
> y <- quote({ a })
>
> identical(x, y)
> # [1] FALSE
>
> attr(x, "srcref") <- NULL
> attr(x, "srcfile") <- NULL
> attr(x, "wholeSrcref") <- NULL
>
> attr(y, "srcref") <- NULL
> attr(y, "srcfile") <- NULL
> attr(y, "wholeSrcref") <- NULL
> identical(x, y)
> # [1] TRUE
>
> Maybe identical() needs an ignore.srcref option? Normally when
> comparing expressions or functions, you want to compare the code, not
> it's textual representation.
>
> Hadley
>
> --
> http://had.co.nz/


From hb at biostat.ucsf.edu  Wed Oct 29 22:16:54 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 29 Oct 2014 14:16:54 -0700
Subject: [Rd] Milestone: 6000 packages on CRAN
Message-ID: <CAFDcVCS2WimNZ8tG+Y_fd_1bYRZEhRgbw1cVjXuOv9Ap=WscLQ@mail.gmail.com>

Another 1000 packages were added to CRAN and this time in less than 12
months.  Today (2014-10-29) on The Comprehensive R Archive Network
(CRAN) [1]:

"Currently, the CRAN package repository features 6000 available packages."

Going from 5000 to 6000 packages took 355 days - which means that it's
on average was only ~8.5 hours between each new packages added.  It is
actually even be more frequent since dropped packages are not
accounted for.  The 6000 packages on CRAN are maintained by 3444
people [2].  Thanks to all package developers and to the CRAN Team for
handling all this!

You can give back by carefully reporting bugs to the maintainers and
properly citing any packages you use in your publications, cf.
citation("pkg name").

Milestones:

2014-10-29: 6000 packages [this post]
2013-11-08: 5000 packages [8]
2012-08-23: 4000 packages [7]
2011-05-12: 3000 packages [6]
2009-10-04: 2000 packages [5]
2007-04-12: 1000 packages [4]
2004-10-01: 500 packages [3,4]
2003-04-01: 250 packages [3,4]

[1] http://cran.r-project.org/web/packages/
[2] http://cran.r-project.org/web/checks/check_summary_by_maintainer.html
[3] Private data.
[4] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
[5] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
[6] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
[7] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
[8] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html

/Henrik

PS. These data are for CRAN only. There are many more packages
elsewhere, e.g. R-Forge, Bioconductor, Github etc.


From Mark.Bravington at csiro.au  Wed Oct 29 23:22:47 2014
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Wed, 29 Oct 2014 22:22:47 +0000
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <CAFOpNVEnue7m5yViF6PzQ7jixZgykTZ+-h3+BxSm0Xz5JWtECw@mail.gmail.com>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>
	<CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>
	<CABdHhvGtKp4-J6G--aJ1+Y-rNbugOtW0kzjuevvm_EdQTANnJw@mail.gmail.com>
	<CAFOpNVEnue7m5yViF6PzQ7jixZgykTZ+-h3+BxSm0Xz5JWtECw@mail.gmail.com>
Message-ID: <1D2694C7C3A6C04AA75E11C592A882E44F8EC38B@exmbx05-cdc.nexus.csiro.au>

[See below for full email trail-- Outlook has beaten me into submission]
> I ran into this and found the result very surprising:

> identical( quote({ a }),  quote({ a }) ) # FALSE
> <<...>>
> -Winston

> > Yes, looks like srcrefs are to blame:
> >
> > x <- quote({ a })
> > y <- quote({ a })
> >
> > identical(x, y)
> > # [1] FALSE
> <<...>>
> > Maybe identical() needs an ignore.srcref option? Normally when
> > comparing expressions or functions, you want to compare the code, not
> > it's textual representation.
> >
> > Hadley

What a great gotcha!

Seems to me it would be better to leave 'identical' alone and have a wrapper that you can call to strip any srcrefs. There is already 'utils::removeSource' but it doesn't work as-is with non-functions. The 5-minute hack below solves the particular example, but may well fall over with other cases--- not tested.

(This sort of thing reinforces my own feelings about 'srcref' as opposed to nice simple 'source'...)

Mark Bravington
CSIRO/Marine Lab/Hobart/Tas 7000/Australia

rmsrc <- function (fn) {
# based on utils::removeSource
    is.fun <- is.function( fn)
    if( (!is.fun && !is.language(fn)) || is.primitive(fn)) {
return(fn)
    }
    
    attr(fn, "source") <- NULL
    attr(fn, "srcref") <- NULL

    if( !is.fun) {
      fn <- as.function( list( fn))
    }

    attr(body(fn), "wholeSrcref") <- NULL
    attr(body(fn), "srcfile") <- NULL
    recurse <- function(part) {
        attr(part, "srcref") <- NULL
        if (is.language(part) && is.recursive(part)) {
            for (i in seq_along(part)) part[[i]] <- recurse(part[[i]])
        }
        part
    }
    body(fn) <- recurse(body(fn))
    
    if( !is.fun) {
return( body( fn))
    } else {
return( fn)
    }
}
#> identical( rmsrc( quote({a})), rmsrc( quote({a})))
#[1] TRUE 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Winston Chang
> Sent: Thursday, 30 October 2014 7:59 AM
> To: Hadley Wickham
> Cc: R Devel List
> Subject: Re: [Rd] Unexpected behavior of identical() with language objects
> 
> Ah, I was using identical() to compare two function bodies. It returns
> FALSE even when you remove srcrefs from the body:
> 
> f1 <- function(x) {
>   if (TRUE) { x }
> }
> f2 <- function(x) {
>   if (TRUE) { x }
> }
> f1b <- body(f1)
> f2b <- body(f2)
> attributes(f1b) <- NULL
> attributes(f2b) <- NULL
> 
> # The bodies look the same with str()
> str(f1b)
> #  language {  if (TRUE) {; x; } }
> str(f2b)
> #  language {  if (TRUE) {; x; } }
> 
> identical(f1b, f2b)
> # FALSE
> 
> 
> 
> What I didn't realize was that the curly brace inside the body also
> independently captures srcrefs, but this isn't printed with str(f1b).
> However, str() on a more targeted part of the object reveals them:
> str(f1b[[2]][[3]])
> # length 2 {  x }
> #  - attr(*, "srcref")=List of 2
> #   ..$ :Class 'srcref'  atomic [1:8] 2 13 2 13 13 13 2 2
> #   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
> <environment: 0x452b2c0>
> #   ..$ :Class 'srcref'  atomic [1:8] 2 15 2 15 15 15 2 2
> #   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
> <environment: 0x452b2c0>
> #  - attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment:
> 0x452b2c0>
> #  - attr(*, "wholeSrcref")=Class 'srcref'  atomic [1:8] 1 0 2 17 0 17 1 2
> #   .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
> <environment: 0x452b2c0>
> 
> -Winston
> 
> On Wed, Oct 29, 2014 at 3:46 PM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
> >>> Is this expected behavior? I can't seem to find anything in the help
> >>> for identical that relates to this.
> >>>
> >> It's not in ?identical, but ?Paren gives you some pointers.
> >> str(quote((a))) and str(quote({a})) are also informative.
> >
> > Yes, looks like srcrefs are to blame:
> >
> > x <- quote({ a })
> > y <- quote({ a })
> >
> > identical(x, y)
> > # [1] FALSE
> >
> > attr(x, "srcref") <- NULL
> > attr(x, "srcfile") <- NULL
> > attr(x, "wholeSrcref") <- NULL
> >
> > attr(y, "srcref") <- NULL
> > attr(y, "srcfile") <- NULL
> > attr(y, "wholeSrcref") <- NULL
> > identical(x, y)
> > # [1] TRUE
> >
> > Maybe identical() needs an ignore.srcref option? Normally when
> > comparing expressions or functions, you want to compare the code, not
> > it's textual representation.
> >
> > Hadley
> >
> > --
> > http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Oct 29 23:41:38 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Oct 2014 18:41:38 -0400
Subject: [Rd] Unexpected behavior of identical() with language objects
In-Reply-To: <1D2694C7C3A6C04AA75E11C592A882E44F8EC38B@exmbx05-cdc.nexus.csiro.au>
References: <CAFOpNVGxxqH0uYjouj6rG9b9LdbigQQbNDWgvS8NxhYnn61F8A@mail.gmail.com>	<CAPPM_gQJFLHPs__OwVyNuftkWz2X7+sn_LwRzfpgrT6qdg37nw@mail.gmail.com>	<CABdHhvGtKp4-J6G--aJ1+Y-rNbugOtW0kzjuevvm_EdQTANnJw@mail.gmail.com>	<CAFOpNVEnue7m5yViF6PzQ7jixZgykTZ+-h3+BxSm0Xz5JWtECw@mail.gmail.com>
	<1D2694C7C3A6C04AA75E11C592A882E44F8EC38B@exmbx05-cdc.nexus.csiro.au>
Message-ID: <54516D22.2020008@gmail.com>

On 29/10/2014, 6:22 PM, Mark.Bravington at csiro.au wrote:
> [See below for full email trail-- Outlook has beaten me into submission]
>> I ran into this and found the result very surprising:
> 
>> identical( quote({ a }),  quote({ a }) ) # FALSE
>> <<...>>
>> -Winston
> 
>>> Yes, looks like srcrefs are to blame:
>>>
>>> x <- quote({ a })
>>> y <- quote({ a })
>>>
>>> identical(x, y)
>>> # [1] FALSE
>> <<...>>
>>> Maybe identical() needs an ignore.srcref option? Normally when
>>> comparing expressions or functions, you want to compare the code, not
>>> it's textual representation.
>>>
>>> Hadley
> 
> What a great gotcha!
> 
> Seems to me it would be better to leave 'identical' alone and have a wrapper that you can call to strip any srcrefs. There is already 'utils::removeSource' but it doesn't work as-is with non-functions. The 5-minute hack below solves the particular example, but may well fall over with other cases--- not tested.

Sounds like utils::removeSource may need to be fixed, but until today
I'd never heard any complaints about it.

> (This sort of thing reinforces my own feelings about 'srcref' as opposed to nice simple 'source'...)

Nice simple 'source' can't do what srcrefs can do, for example report on
locations during debugging, or when run-time errors occur.

Duncan Murdoch

> 
> Mark Bravington
> CSIRO/Marine Lab/Hobart/Tas 7000/Australia
> 
> rmsrc <- function (fn) {
> # based on utils::removeSource
>     is.fun <- is.function( fn)
>     if( (!is.fun && !is.language(fn)) || is.primitive(fn)) {
> return(fn)
>     }
>     
>     attr(fn, "source") <- NULL
>     attr(fn, "srcref") <- NULL
> 
>     if( !is.fun) {
>       fn <- as.function( list( fn))
>     }
> 
>     attr(body(fn), "wholeSrcref") <- NULL
>     attr(body(fn), "srcfile") <- NULL
>     recurse <- function(part) {
>         attr(part, "srcref") <- NULL
>         if (is.language(part) && is.recursive(part)) {
>             for (i in seq_along(part)) part[[i]] <- recurse(part[[i]])
>         }
>         part
>     }
>     body(fn) <- recurse(body(fn))
>     
>     if( !is.fun) {
> return( body( fn))
>     } else {
> return( fn)
>     }
> }
> #> identical( rmsrc( quote({a})), rmsrc( quote({a})))
> #[1] TRUE 
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
>> On Behalf Of Winston Chang
>> Sent: Thursday, 30 October 2014 7:59 AM
>> To: Hadley Wickham
>> Cc: R Devel List
>> Subject: Re: [Rd] Unexpected behavior of identical() with language objects
>>
>> Ah, I was using identical() to compare two function bodies. It returns
>> FALSE even when you remove srcrefs from the body:
>>
>> f1 <- function(x) {
>>   if (TRUE) { x }
>> }
>> f2 <- function(x) {
>>   if (TRUE) { x }
>> }
>> f1b <- body(f1)
>> f2b <- body(f2)
>> attributes(f1b) <- NULL
>> attributes(f2b) <- NULL
>>
>> # The bodies look the same with str()
>> str(f1b)
>> #  language {  if (TRUE) {; x; } }
>> str(f2b)
>> #  language {  if (TRUE) {; x; } }
>>
>> identical(f1b, f2b)
>> # FALSE
>>
>>
>>
>> What I didn't realize was that the curly brace inside the body also
>> independently captures srcrefs, but this isn't printed with str(f1b).
>> However, str() on a more targeted part of the object reveals them:
>> str(f1b[[2]][[3]])
>> # length 2 {  x }
>> #  - attr(*, "srcref")=List of 2
>> #   ..$ :Class 'srcref'  atomic [1:8] 2 13 2 13 13 13 2 2
>> #   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>> <environment: 0x452b2c0>
>> #   ..$ :Class 'srcref'  atomic [1:8] 2 15 2 15 15 15 2 2
>> #   .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>> <environment: 0x452b2c0>
>> #  - attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment:
>> 0x452b2c0>
>> #  - attr(*, "wholeSrcref")=Class 'srcref'  atomic [1:8] 1 0 2 17 0 17 1 2
>> #   .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>> <environment: 0x452b2c0>
>>
>> -Winston
>>
>> On Wed, Oct 29, 2014 at 3:46 PM, Hadley Wickham <h.wickham at gmail.com>
>> wrote:
>>>>> Is this expected behavior? I can't seem to find anything in the help
>>>>> for identical that relates to this.
>>>>>
>>>> It's not in ?identical, but ?Paren gives you some pointers.
>>>> str(quote((a))) and str(quote({a})) are also informative.
>>>
>>> Yes, looks like srcrefs are to blame:
>>>
>>> x <- quote({ a })
>>> y <- quote({ a })
>>>
>>> identical(x, y)
>>> # [1] FALSE
>>>
>>> attr(x, "srcref") <- NULL
>>> attr(x, "srcfile") <- NULL
>>> attr(x, "wholeSrcref") <- NULL
>>>
>>> attr(y, "srcref") <- NULL
>>> attr(y, "srcfile") <- NULL
>>> attr(y, "wholeSrcref") <- NULL
>>> identical(x, y)
>>> # [1] TRUE
>>>
>>> Maybe identical() needs an ignore.srcref option? Normally when
>>> comparing expressions or functions, you want to compare the code, not
>>> it's textual representation.
>>>
>>> Hadley
>>>
>>> --
>>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Mike.Beddo at dataventures.com  Thu Oct 30 05:13:07 2014
From: Mike.Beddo at dataventures.com (Mike Beddo)
Date: Thu, 30 Oct 2014 04:13:07 +0000
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
Message-ID: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>

Greetings,

When I try "install.packages('Rcpp')" it fails when compiling api.cpp (line 39). This is Rcpp 0.11.3. I searched my filesystem, and indeed I do not have execinfo.h anywhere. After some effort, I got R build on AIX. Now I am trying to build the packages I need. Rcpp is crucial.

I first build R with the native IBM XL compilers, and Rcpp wouldn't build. That was because it wasn't a "GOOD COMPILER" (there's a directive in the Rcpp code that checks for various types of compilers). So I switched to building R with gcc/gfortran/g++ 4.8 and got past that point, but now blocked by the absence of "execinfo.h" header file.

Any ideas?

Thanks,

Mike


From friendly at yorku.ca  Thu Oct 30 20:11:11 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 30 Oct 2014 15:11:11 -0400
Subject: [Rd] 'library' or 'require' call not declared from: 'rgl'
Message-ID: <54528D4F.30008@yorku.ca>

I'm checking a new release of vcdExtra via win builder with R-devel 
2014-10-29 r66897
and have run into a Warning I don't know how to fix.

I have one S3 generic, mosaic3d() that uses rgl and don't want to have 
rgl always loaded
via Depends:.  Instead, the mosaic3d.default() method includes

   if (!require(rgl)) stop("rgl is required")

This always worked in the past, but in this testing cycle, I got a slew 
of "no visible global function definition for ..."
all rgl functions.

I revised DESCRIPTION to include:

Imports:  rgl

and NAMESPACE:

import(rgl)

All the "no visible global function definition ..." went away, but I'm 
stuck with

* checking dependencies in R code ... WARNING
'library' or 'require' call not declared from: 'rgl'
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

How can I solve this?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From simon.urbanek at r-project.org  Thu Oct 30 21:19:57 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 30 Oct 2014 16:19:57 -0400
Subject: [Rd] 'library' or 'require' call not declared from: 'rgl'
In-Reply-To: <54528D4F.30008@yorku.ca>
References: <54528D4F.30008@yorku.ca>
Message-ID: <AB1DE897-323E-4DD1-AC4F-363795A565C5@r-project.org>


> On Oct 30, 2014, at 3:11 PM, Michael Friendly <friendly at yorku.ca> wrote:
> 
> I'm checking a new release of vcdExtra via win builder with R-devel 2014-10-29 r66897
> and have run into a Warning I don't know how to fix.
> 
> I have one S3 generic, mosaic3d() that uses rgl and don't want to have rgl always loaded
> via Depends:.  Instead, the mosaic3d.default() method includes
> 
>  if (!require(rgl)) stop("rgl is required")
> 
> This always worked in the past, but in this testing cycle, I got a slew of "no visible global function definition for ..."
> all rgl functions.
> 
> I revised DESCRIPTION to include:
> 
> Imports:  rgl
> 
> and NAMESPACE:
> 
> import(rgl)
> 
> All the "no visible global function definition ..." went away, but I'm stuck with
> 
> * checking dependencies in R code ... WARNING
> 'library' or 'require' call not declared from: 'rgl'
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
> 
> How can I solve this?
> 

Did you intend rgl to be optional? If so, then you should use Suggests: instead. When you use Imports: it will load rgl automatically so require() does't make sense (since it will be always TRUE).

Cheers,
Simon


> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From friendly at yorku.ca  Thu Oct 30 22:18:40 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 30 Oct 2014 17:18:40 -0400
Subject: [Rd] 'library' or 'require' call not declared from: 'rgl'
In-Reply-To: <AB1DE897-323E-4DD1-AC4F-363795A565C5@r-project.org>
References: <54528D4F.30008@yorku.ca>
	<AB1DE897-323E-4DD1-AC4F-363795A565C5@r-project.org>
Message-ID: <5452AB30.7080809@yorku.ca>

On 10/30/2014 4:19 PM, Simon Urbanek wrote:
> Did you intend rgl to be optional? If so, then you should use Suggests: instead. When you use Imports: it will load rgl automatically so require() does't make sense (since it will be always TRUE).
>
I always had it as Suggests: rgl before.  But R-devel now gave be all 
those "no visible global function definition for ..."
messages.

Achim suggested using explicitly rgl:: everywhere.  That's quite ugly, 
but seems to work.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From lang at statistik.tu-dortmund.de  Thu Oct 30 11:04:41 2014
From: lang at statistik.tu-dortmund.de (Michel Lang)
Date: Thu, 30 Oct 2014 11:04:41 +0100
Subject: [Rd] RFC: is.whole() ? {"how to judge if a variable is an
	integer"}
In-Reply-To: <21583.25274.770806.923857@stat.math.ethz.ch>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
	<8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
	<CAF8bMcaAnGvZiTrrmMMnFX2Oe4iExCM8VxqqUOoHN6uGY44Xew@mail.gmail.com>
	<21583.25274.770806.923857@stat.math.ethz.ch>
Message-ID: <CAF6EP_4S+9KPzUaUBhsLz0FkFzsX3MboPw_-MTS+DO7qhL8dxA@mail.gmail.com>

2014-10-28 10:32 GMT+01:00 Martin Maechler <maechler at stat.math.ethz.ch>:

> Given all this, the r-help and stackoverflow threads,
> maybe we should decide that such an is.whole() function should
> be added to R and maintained (by me for the time), so we do have
> a better place to point people to, and well documented -- and
> eventually "optimized" -- behavior ?
>
> Personally I do think I'd want a "signature" of
>     function (x, tolerance = sqrt(.Machine$double.eps))

I've written some C code which in my opinion would be a good starting
point for an optimized version. The exported function in the checkmate
package is called "isIntegerish" and tests an SEXP to be "safely
convertible" to an INTSXP. You can find it here:
<https://github.com/mllg/checkmate/blob/master/src/is_integerish.c>.

Best,
Michel


From vakili.kaveh.email at gmail.com  Thu Oct 30 19:45:30 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Thu, 30 Oct 2014 19:45:30 +0100
Subject: [Rd] DIY Rtools?
In-Reply-To: <mailman.0.1414694361.8176.r-devel@r-project.org>
References: <mailman.0.1414694361.8176.r-devel@r-project.org>
Message-ID: <5452874A.4010408@gmail.com>

Dear List,

I'm currently working on an R package that
works great when compiled with GCC 4.8 under linux
but which doesn't seem to work so well when compiled
  by the win builder (http://win-builder.r-project.org/).

After asking around a bit, the primary culprit could be
the older version of GCC used in Rtools.

Now, for academic purposes, I would like to have
  a zip version of this package (not to distribute
through CRAN mind you, but to submit alongside
  the associated paper).

My questions are as follows:

-Am I correct to think that Rtool uses GCC 4.6.3?
-If so, is there a way to build windows runable R
package using a more recent version of GCC?

Thanks in advance for sharing your views on this,

Bests regards,


From murdoch.duncan at gmail.com  Thu Oct 30 22:54:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Oct 2014 17:54:08 -0400
Subject: [Rd] DIY Rtools?
In-Reply-To: <5452874A.4010408@gmail.com>
References: <mailman.0.1414694361.8176.r-devel@r-project.org>
	<5452874A.4010408@gmail.com>
Message-ID: <5452B380.7090102@gmail.com>

On 30/10/2014, 2:45 PM, kaveh wrote:
> Dear List,
> 
> I'm currently working on an R package that
> works great when compiled with GCC 4.8 under linux
> but which doesn't seem to work so well when compiled
>   by the win builder (http://win-builder.r-project.org/).
> 
> After asking around a bit, the primary culprit could be
> the older version of GCC used in Rtools.
> 
> Now, for academic purposes, I would like to have
>   a zip version of this package (not to distribute
> through CRAN mind you, but to submit alongside
>   the associated paper).
> 
> My questions are as follows:
> 
> -Am I correct to think that Rtool uses GCC 4.6.3?

Yes.

> -If so, is there a way to build windows runable R
> package using a more recent version of GCC?

Yes, you need to install one (I've been told they are available from the
MinGW-64 project) on your path, then just use it.  If it needs different
options from the ones that 4.6.3 needed, it will be slightly more work:
 you'll need to edit the Makefile, or Makevars, or MkRules.* files in
src/gnuwin32 to put those options in place.

Unlike other platforms, the Windows builds have no "configuration" step,
that's all done by hand (usually by Brian Ripley, thanks!).  If you
change to a different compiler, you may need to change some of that.

Our plans are to switch to a newer compiler before the release of R
3.2.0 in the spring, but I won't promise when new Rtools will be available.

Duncan Murdoch

> 
> Thanks in advance for sharing your views on this,
> 
> Bests regards,
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From vakili.kaveh.email at gmail.com  Thu Oct 30 22:55:11 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Thu, 30 Oct 2014 22:55:11 +0100
Subject: [Rd] DIY Rtools?
In-Reply-To: <5452B380.7090102@gmail.com>
References: <mailman.0.1414694361.8176.r-devel@r-project.org>
	<5452874A.4010408@gmail.com> <5452B380.7090102@gmail.com>
Message-ID: <5452B3BF.30809@gmail.com>

Thank you very much for all these infos!

Best regards,


On 2014-10-30 22:54, Duncan Murdoch wrote:
> On 30/10/2014, 2:45 PM, kaveh wrote:
>> Dear List,
>>
>> I'm currently working on an R package that
>> works great when compiled with GCC 4.8 under linux
>> but which doesn't seem to work so well when compiled
>>    by the win builder (http://win-builder.r-project.org/).
>>
>> After asking around a bit, the primary culprit could be
>> the older version of GCC used in Rtools.
>>
>> Now, for academic purposes, I would like to have
>>    a zip version of this package (not to distribute
>> through CRAN mind you, but to submit alongside
>>    the associated paper).
>>
>> My questions are as follows:
>>
>> -Am I correct to think that Rtool uses GCC 4.6.3?
> Yes.
>
>> -If so, is there a way to build windows runable R
>> package using a more recent version of GCC?
> Yes, you need to install one (I've been told they are available from the
> MinGW-64 project) on your path, then just use it.  If it needs different
> options from the ones that 4.6.3 needed, it will be slightly more work:
>   you'll need to edit the Makefile, or Makevars, or MkRules.* files in
> src/gnuwin32 to put those options in place.
>
> Unlike other platforms, the Windows builds have no "configuration" step,
> that's all done by hand (usually by Brian Ripley, thanks!).  If you
> change to a different compiler, you may need to change some of that.
>
> Our plans are to switch to a newer compiler before the release of R
> 3.2.0 in the spring, but I won't promise when new Rtools will be available.
>
> Duncan Murdoch
>
>> Thanks in advance for sharing your views on this,
>>
>> Bests regards,
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From plummerm at iarc.fr  Fri Oct 31 12:29:38 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Fri, 31 Oct 2014 11:29:38 +0000
Subject: [Rd] 'library' or 'require' call not declared from: 'rgl'
In-Reply-To: <5452AB30.7080809@yorku.ca>
References: <54528D4F.30008@yorku.ca>
	<AB1DE897-323E-4DD1-AC4F-363795A565C5@r-project.org>
	<5452AB30.7080809@yorku.ca>
Message-ID: <1414754978.17982.8.camel@braque.iarc.fr>

On Thu, 2014-10-30 at 17:18 -0400, Michael Friendly wrote:
> On 10/30/2014 4:19 PM, Simon Urbanek wrote:
> > Did you intend rgl to be optional? If so, then you should use
> Suggests: instead. When you use Imports: it will load rgl
> automatically so require() does't make sense (since it will be always
> TRUE).
> >
> I always had it as Suggests: rgl before.  But R-devel now gave be all 
> those "no visible global function definition for ..."
> messages.
> 
> Achim suggested using explicitly rgl:: everywhere.  That's quite ugly, 
> but seems to work.

I think you do want "Depends" rather than "Suggests" here. "Suggests" is
for when the other package does not need to be loaded for the user to
use your package, but the other package might be used in an example or
vignette.

In your package, the default method for a generic function that your
package defines calls functions from rgl. To me that means rgl should be
in "Depends", and the required functions from rgl should be imported in
the NAMESPACE file.

Martyn

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From dtenenba at fredhutch.org  Fri Oct 31 19:22:59 2014
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Fri, 31 Oct 2014 11:22:59 -0700 (PDT)
Subject: [Rd] proposed: minor change to error message
In-Reply-To: <700931469.478968.1414779587008.JavaMail.root@fredhutch.org>
Message-ID: <1482649333.479101.1414779779842.JavaMail.root@fredhutch.org>

When checking a package (call it "A") that has "Enhances: B" in DESCRIPTION, I get the message:

Package which this enhances but not available for checking: ?B?

Can this be changed to:

Package which enhances this but not available for checking: ?B?

?

Because really, B is not enhanced by A, B does not need A at all.

(Actually, for the same reason, Enhances should be EnhancedBy, but I am not suggesting changing that because I realize that is non-trivial.)

Thanks,
Dan


From jeroen.ooms at stat.ucla.edu  Fri Oct 31 23:58:38 2014
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Fri, 31 Oct 2014 15:58:38 -0700
Subject: [Rd] ScalarLogical and setAttrib
Message-ID: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>

Is it expected that attributes set on a LGLSXP created by
ScalarLogical will apply to all future objects created by
ScalarLogical as well? For example: the 'test1' function below returns
FALSE and 'test2' returns FALSE with an attribute:

  library(inline)
  test1 <- cfunction(body = 'return ScalarLogical(0);')
  test2 <- cfunction(body = '
    SEXP success = PROTECT(ScalarLogical(0));
    setAttrib(success, install("foo"), mkString("bar"));
    UNPROTECT(1);
    return success;
  ')

However after running test2(), then test1() will also return the attribute:

  > test1()
  [1] FALSE
  > test2()
  [1] FALSE
  attr(,"foo")
  [1] "bar"
  > test1()
  [1] FALSE
  attr(,"foo")
  [1] "bar"

It seems like ScalarLogical returns a singleton object, which is not
the case for ScalarInteger or ScalarReal. I am currently working
around this using duplicate(ScalarLogical(0)), but was quite surprised
by this behavior of ScalarLogical.


