From seth at userprimary.net  Thu Apr  1 00:38:53 2010
From: seth at userprimary.net (Seth Falcon)
Date: Wed, 31 Mar 2010 15:38:53 -0700
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <4BB3ACBF.8040409@u-paris10.fr>
References: <4BB3ACBF.8040409@u-paris10.fr>
Message-ID: <4BB3CEFD.2080302@userprimary.net>

On 3/31/10 1:12 PM, Christophe Genolini wrote:
> Hi the list,
> I am writing a package that happen to not be compatible with linux
> because I did not know that the function "savePlot" was available only
> on windows. Is there a list of "incompatible" function? How can I get
> this kind of information?

One way is to obtain a copy of the R sources and then grep the Rd files 
for '#ifdef'.

I don't claim this is convenient.

There has been discussion, and I believe general consensus, that we'd 
like to eliminate the conditional documentation.  This requires editing 
the Rd files to make the contents sensible (you can't just remove the 
#ifdef's).  Patches along these lines would be welcome.

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From hpages at fhcrc.org  Thu Apr  1 00:52:11 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 31 Mar 2010 15:52:11 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
Message-ID: <4BB3D21B.3030306@fhcrc.org>

Hi,

   > class(as(1:4, "numeric"))
   [1] "integer"

Surprising but an explanation could be that an integer
vector being a particular case of numeric vector, this
coercion has nothing to do because 1:4 is already numeric.
And indeed:

   > is.numeric(1:4)
   [1] TRUE
   > is.numeric(as(1:4, "numeric"))
   [1] TRUE

However, 'as(1:4, "numeric")' is inconsistent with

   > class(as.numeric(1:4))
   [1] "numeric"

And, even more confusing, if you look at the coerce,ANY,numeric
method:

   > selectMethod("coerce", c("integer", "numeric"))
   Method Definition:

   function (from, to, strict = TRUE)
   {
     value <- as.numeric(from)
     if (strict)
         attributes(value) <- NULL
     value
   }
   <environment: namespace:methods>

   Signatures:
           from      to
   target  "integer" "numeric"
   defined "ANY"     "numeric"

it calls as.numeric()!

So how can 'as(1:4, "numeric")' not return the same thing as
'as.numeric(1:4)' looks like a mystery to me. Could it be
conceivable that I found a bug?

Cheers,
H.


 > sessionInfo()
R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
x86_64-unknown-linux-gnu

locale:
  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cberry at tajo.ucsd.edu  Thu Apr  1 00:52:35 2010
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 31 Mar 2010 15:52:35 -0700
Subject: [Rd] Should as.complex(NaN) -> NA?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70002B76B26@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70002B76B26@NA-PA-VBE03.na.tibco.com>
Message-ID: <Pine.LNX.4.64.1003311548370.26451@tajo.ucsd.edu>

On Wed, 31 Mar 2010, William Dunlap wrote:

> I'm having trouble grokking complex NaN's.
> This first set examples using complex(re=NaN,im=NaN)
> give what I expect
>  > Re(complex(re=NaN, im=NaN))
>  [1] NaN
>  > Im(complex(re=NaN, im=NaN))
>  [1] NaN
>  > Arg(complex(re=NaN, im=NaN))
>  [1] NaN
>  > Mod(complex(re=NaN, im=NaN))
>  [1] NaN
>  > abs(complex(re=NaN, im=NaN))
>  [1] NaN
> and so do the following
>  > Re(complex(re=1, im=NaN))
>  [1] 1
>  > Im(complex(re=1, im=NaN))
>  [1] NaN
>  > Re(complex(re=NaN, im=1))
>  [1] NaN
>  > Im(complex(re=NaN, im=1))
>  [1] 1
> but I don't have a good mental model that explains
> why the following produce NA instead of NaN.

Just a guess here:

> as.complex(sqrt(as.complex(-1)))
[1] 0+1i
> as.complex(sqrt(-1))
[1] NA
Warning message:
In sqrt(-1) : NaNs produced

It protects from assuming that the latter truly is not a number.

Chuck


>  > as.complex(NaN)
>  [1] NA
>  > Im(complex(modulus=NaN, argument=NaN))
>  [1] NA
>  > Re(complex(modulus=NaN, argument=NaN))
>  [1] NA
>  > Re(1i * NaN)
>  [1] NA
>  > Im(1i * NaN)
>  [1] NA
>  > Re(NaN + 1i)
>  [1] NA
>  > Im(NaN + 1i)
>  [1] NA
>
> It may be that if as.complex(NaN), and its C equivalent,
> were changed to return complex(re=NaN,im=NaN) then the
> arithmetic examples would return NaN.  Is there a
> better way for me to model how NaN's in complex numbers
> should work or is this a bug?
>
> While I was looking into this I noticed a bug in str():
>  > str(NA_complex_)
>  Error in FUN(X[[1L]], ...) : subscript out of bounds
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From jmc at r-project.org  Thu Apr  1 01:52:51 2010
From: jmc at r-project.org (John Chambers)
Date: Wed, 31 Mar 2010 16:52:51 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB3D21B.3030306@fhcrc.org>
References: <4BB3D21B.3030306@fhcrc.org>
Message-ID: <4BB3E053.9020709@r-project.org>

The example is confusing and debatable, but not an obvious bug.  And 
your presentation of it is the cause of much of the confusion 
(unintentionally I'm sure).

First, slipping from the as() function to methods for the coerce() 
function might surprise a less experienced user.  And in fact, that is 
the point here.  If you look at the as() function, it jumps through 
several hoops and in particular selects a method from coerce in such a 
way as NOT to use inheritance on the from= argument.  (I think this 
makes sense in this case).  So I would assert that your selectMethod() 
output below came from a different session than the as(1:4, "numeric").

Starting from a clean session with R 2.10.1:

 > class(as(1:4,"numeric"))
[1] "integer"
 > selectMethod("coerce", c("integer","numeric"))
Method Definition:

function (from, to = "numeric", strict = TRUE)
if (strict) {
     class(from) <- "numeric"
     from
} else from
<environment: namespace:methods>

Signatures:
         from      to
target  "integer" "numeric"
defined "integer" "numeric"

Note, no call to as.numeric().  In a session without a previous call to 
as(), your selectMethod() call triggered a standard inherited method 
selection.  And if you had then gone on to as(), the result would have 
been different.

In a different clean session:


 > getMethod("coerce", c("integer", "numeric"))
Error in getMethod("coerce", c("integer", "numeric")) :
   No method found for function "coerce" and signature integer, numeric
 > selectMethod("coerce", c("integer", "numeric"))
Method Definition:

function (from, to, strict = TRUE)
{
     value <- as.numeric(from)
     if (strict)
         attributes(value) <- NULL
     value
}
<environment: namespace:methods>

Signatures:
         from      to
target  "integer" "numeric"
defined "ANY"     "numeric"
 > class(as(1:4,"numeric"))
[1] "numeric"

No argument about this being confusing.  Perhaps one should prohibit 
standard selectMethod() on coerce() but that seems a bit arcane to 
thwart folks like you!

Suggested improvements for the current implementation are welcome, so 
long as they consider the best definition of as() in the general sense.

Regards,
   John

On 3/31/10 3:52 PM, Herv? Pag?s wrote:
> Hi,
>
> > class(as(1:4, "numeric"))
>   [1] "integer"
>
> Surprising but an explanation could be that an integer
> vector being a particular case of numeric vector, this
> coercion has nothing to do because 1:4 is already numeric.
> And indeed:
>
> > is.numeric(1:4)
>   [1] TRUE
> > is.numeric(as(1:4, "numeric"))
>   [1] TRUE
>
> However, 'as(1:4, "numeric")' is inconsistent with
>
> > class(as.numeric(1:4))
>   [1] "numeric"
>
> And, even more confusing, if you look at the coerce,ANY,numeric
> method:
>
> > selectMethod("coerce", c("integer", "numeric"))
>   Method Definition:
>
>   function (from, to, strict = TRUE)
>   {
>     value <- as.numeric(from)
>     if (strict)
>         attributes(value) <- NULL
>     value
>   }
> <environment: namespace:methods>
>
>   Signatures:
>           from      to
>   target  "integer" "numeric"
>   defined "ANY"     "numeric"
>
> it calls as.numeric()!
>
> So how can 'as(1:4, "numeric")' not return the same thing as
> 'as.numeric(1:4)' looks like a mystery to me. Could it be
> conceivable that I found a bug?
>
> Cheers,
> H.
>
>
> > sessionInfo()
> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
> x86_64-unknown-linux-gnu
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>


From p_connolly at slingshot.co.nz  Thu Apr  1 09:00:50 2010
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 1 Apr 2010 20:00:50 +1300
Subject: [Rd] strptime(): on Linux system it seems to call system time?
In-Reply-To: <4BA50BE9.2030302@gmail.com>
References: <27112007B97C7B439E9BC5A8ADCFF345024976@EX2.GAINCapital.com>
	<4BA50BE9.2030302@gmail.com>
Message-ID: <20100401070050.GA4444@slingshot.co.nz>

On Sat, 20-Mar-2010 at 06:54PM +0100, Peter Dalgaard wrote:

[...]

|> It seems to be  completely system-dependent. On Fedora 9, I see
|> 
|>    user  system elapsed
|>   2.890   0.314   3.374
|> 
|> but on openSUSE 10.3 it is
|> 
|>    user  system elapsed
|>   3.924   6.992  10.917
|> 
|> At any rate, I suspect that this is an issue with the operating system
|> and its C libraries, not with R as such.

Were those 32 or 64 bit?

With Fedora 11 and AMD Athlon 2 Ghz, I get

   user  system elapsed 
  1.395   0.294   1.885 

with Mepis 7 on a Celeron 1.6 Ghz,

   user  system elapsed 
  3.890   5.896   9.845 

Both of those are 32 bit.  
Maybe 64 bit does things very differently.



-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From hpages at fhcrc.org  Thu Apr  1 09:31:30 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 01 Apr 2010 00:31:30 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB3E053.9020709@r-project.org>
References: <4BB3D21B.3030306@fhcrc.org> <4BB3E053.9020709@r-project.org>
Message-ID: <4BB44BD2.3000207@fhcrc.org>

Hi John,

John Chambers wrote:
> The example is confusing and debatable, but not an obvious bug.  And 
> your presentation of it is the cause of much of the confusion 
> (unintentionally I'm sure).
> 
> First, slipping from the as() function to methods for the coerce() 
> function might surprise a less experienced user.  And in fact, that is 
> the point here.  If you look at the as() function, it jumps through 
> several hoops and in particular selects a method from coerce in such a 
> way as NOT to use inheritance on the from= argument.  (I think this 
> makes sense in this case).  So I would assert that your selectMethod() 
> output below came from a different session than the as(1:4, "numeric").
> 
> Starting from a clean session with R 2.10.1:
> 
>  > class(as(1:4,"numeric"))
> [1] "integer"
>  > selectMethod("coerce", c("integer","numeric"))
> Method Definition:
> 
> function (from, to = "numeric", strict = TRUE)
> if (strict) {
>     class(from) <- "numeric"
>     from
> } else from
> <environment: namespace:methods>
> 
> Signatures:
>         from      to
> target  "integer" "numeric"
> defined "integer" "numeric"
> 
> Note, no call to as.numeric().  In a session without a previous call to 
> as(), your selectMethod() call triggered a standard inherited method 
> selection.  And if you had then gone on to as(), the result would have 
> been different.

Yes indeed. From a fresh start:

 > invisible(selectMethod("coerce", c("integer","numeric")))
 > class(as(1:4, "numeric"))
[1] "numeric"

But without the initial call to selectMethod(), as(1:4, "numeric")
returns an integer vector.

Sorry but it's hard for me to understand the reasons for having
such behaviour, especially when selectMethod() is described as a
function "to *look* for a method corresponding to a given generic
function and signature". Apparently it does more than just looking...

> 
> In a different clean session:
> 
> 
>  > getMethod("coerce", c("integer", "numeric"))
> Error in getMethod("coerce", c("integer", "numeric")) :
>   No method found for function "coerce" and signature integer, numeric
>  > selectMethod("coerce", c("integer", "numeric"))
> Method Definition:
> 
> function (from, to, strict = TRUE)
> {
>     value <- as.numeric(from)
>     if (strict)
>         attributes(value) <- NULL
>     value
> }
> <environment: namespace:methods>
> 
> Signatures:
>         from      to
> target  "integer" "numeric"
> defined "ANY"     "numeric"
>  > class(as(1:4,"numeric"))
> [1] "numeric"
> 
> No argument about this being confusing.  Perhaps one should prohibit 
> standard selectMethod() on coerce() but that seems a bit arcane to 
> thwart folks like you!
> 
> Suggested improvements for the current implementation are welcome, so 
> long as they consider the best definition of as() in the general sense.

So one problem seems to be that, on a fresh start, *both*
     as(1:4, "numeric")
and
     selectMethod("coerce", c("integer", "numeric"))
will cache a coerce method for the c("integer", "numeric") signature,
but they don't cache the *same* method!

The automatic method cached by 'as(1:4, "numeric")' seems to be
coming from:

   getClassDef("integer")@contains$numeric at coerce

Maybe one way to improve things would be to modify this part of
the class definition for "integer" so it is in sync with

   selectMethod("coerce", c("integer", "numeric")).

There are other situations where the coerce methods are not
in sync:

   > getClassDef("factor")@contains$integer at coerce
   function (from, strict = TRUE)
   {
     attributes(from) <- NULL
     from
   }
   <environment: namespace:methods>

   > selectMethod("coerce", c("factor", "integer"))
   Method Definition:

   function (from, to, strict = TRUE)
   {
     value <- as.integer(from)
     if (strict)
         attributes(value) <- NULL
     value
   }
   <environment: namespace:methods>

That isn't a problem here because both methods will produce
the same result but is there any reason why the former
couldn't use the same code as the latter?

A more radical approach would be to have a call to

   selectMethod("coerce", c("integer", "numeric"))

have the same effect on the table of coerce methods than a
call to

   as(1:4, "numeric")

i.e. the former will insert the same automatic method as the
latter. That means that all the hard work made by the as()
function in order to find/create/cache an appropriate method
would need to be moved to selectMethod() so in that function
'f="coerce"' would become a special case.
Then as() would become a 10 line function (or less) that would
basically delegate to selectMethod("coerce", ...) to do the hard
work. This solution seems better to me as it would then guarantee
consistency between what as() does and what
selectMethod("coerce", ...) says.

Cheers,
H.

> 
> Regards,
>   John
> 
> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>> Hi,
>>
>> > class(as(1:4, "numeric"))
>>   [1] "integer"
>>
>> Surprising but an explanation could be that an integer
>> vector being a particular case of numeric vector, this
>> coercion has nothing to do because 1:4 is already numeric.
>> And indeed:
>>
>> > is.numeric(1:4)
>>   [1] TRUE
>> > is.numeric(as(1:4, "numeric"))
>>   [1] TRUE
>>
>> However, 'as(1:4, "numeric")' is inconsistent with
>>
>> > class(as.numeric(1:4))
>>   [1] "numeric"
>>
>> And, even more confusing, if you look at the coerce,ANY,numeric
>> method:
>>
>> > selectMethod("coerce", c("integer", "numeric"))
>>   Method Definition:
>>
>>   function (from, to, strict = TRUE)
>>   {
>>     value <- as.numeric(from)
>>     if (strict)
>>         attributes(value) <- NULL
>>     value
>>   }
>> <environment: namespace:methods>
>>
>>   Signatures:
>>           from      to
>>   target  "integer" "numeric"
>>   defined "ANY"     "numeric"
>>
>> it calls as.numeric()!
>>
>> So how can 'as(1:4, "numeric")' not return the same thing as
>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>> conceivable that I found a bug?
>>
>> Cheers,
>> H.
>>
>>
>> > sessionInfo()
>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ripley at stats.ox.ac.uk  Thu Apr  1 10:38:12 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Apr 2010 09:38:12 +0100 (BST)
Subject: [Rd] strptime(): on Linux system it seems to call system time?
In-Reply-To: <20100401070050.GA4444@slingshot.co.nz>
References: <27112007B97C7B439E9BC5A8ADCFF345024976@EX2.GAINCapital.com>
	<4BA50BE9.2030302@gmail.com>
	<20100401070050.GA4444@slingshot.co.nz>
Message-ID: <alpine.LFD.2.00.1004010810410.4126@gannet.stats.ox.ac.uk>

Let me lay this to rest.  For some reason the OP did not use a 
vectorized call to strptime but 100000 individual calls (as well as 
making *false* claims about what strptime does and what is 'completely 
unnecessary', and seemingly being igorant of system.time()).

I do not believe this is ever an issue for well-written R code.

Each time strptime() is called it needs to find and set the timezone 
(as whether an input is valid or not and whether it is in DST depends 
on the timezone).  If tz = "", the default, it needs to ask the system 
what the current timezone is via the C call tzset.  On well-written C 
runtimes tzset caches and so is fast after the first time.  On some 
others it reads files such as /etc/localtime each time.

On my Linux system (x86_64 Fedora 12)

system.time(for (i in 1:100000) strptime("2010-03-10 17:00:00", "%F %H:%M:%S"))
    user  system elapsed
   1.048   0.222   2.086
system.time(strptime(rep("2010-03-10 17:00:00", 100000), "%F %H:%M:%S"))
    user  system elapsed
   0.371   0.184   0.579

whereas on my 2008 Mac laptop

    user  system elapsed
   7.402   0.015   7.441
    user  system elapsed
   6.689   0.013   6.716

and on my 2005 Windows laptop

    user  system elapsed
    2.47    0.00    2.47
    user  system elapsed
    1.39    0.00    1.40

(for which the credit is entirely due to the replacement code in R: 
Windows' datetime code is only used for strftime).

So looks like Apple could improve their POSIX datetime runtime, but 
I've never seen an R application where parsing dates took longer than 
reading the original posting (let alone the time taken to read some 
good books on how to time R code and write it efficiently).


On Thu, 1 Apr 2010, Patrick Connolly wrote:

> On Sat, 20-Mar-2010 at 06:54PM +0100, Peter Dalgaard wrote:
>
> [...]
>
> |> It seems to be  completely system-dependent. On Fedora 9, I see
> |>
> |>    user  system elapsed
> |>   2.890   0.314   3.374
> |>
> |> but on openSUSE 10.3 it is
> |>
> |>    user  system elapsed
> |>   3.924   6.992  10.917
> |>
> |> At any rate, I suspect that this is an issue with the operating system
> |> and its C libraries, not with R as such.
>
> Were those 32 or 64 bit?
>
> With Fedora 11 and AMD Athlon 2 Ghz, I get
>
>   user  system elapsed
>  1.395   0.294   1.885
>
> with Mepis 7 on a Celeron 1.6 Ghz,
>
>   user  system elapsed
>  3.890   5.896   9.845
>
> Both of those are 32 bit.
> Maybe 64 bit does things very differently.
>
>
>
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>   ___    Patrick Connolly
> {~._.~}                   Great minds discuss ideas
> _( Y )_  	         Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
> (_)-(_)  	                      ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Thu Apr  1 12:03:22 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 1 Apr 2010 12:03:22 +0200
Subject: [Rd] Is it valid to do x == Inf?
Message-ID: <j2n59d7961d1004010303ja372b671r8da5fc73ca62edb7@mail.gmail.com>

Hi,

I found in a bit of code the following test for infinity:

  if (x == Inf) ...

Is that valid, or should it be (as I always thought):

  if (is.infinite(x)) ...?

Does it depend on whether 'x' is float or integer?

My question is related to testing for missing values where is.na(x) is required.

/Henrik


From b.rowlingson at lancaster.ac.uk  Thu Apr  1 12:21:40 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 1 Apr 2010 11:21:40 +0100
Subject: [Rd] Is it valid to do x == Inf?
In-Reply-To: <j2n59d7961d1004010303ja372b671r8da5fc73ca62edb7@mail.gmail.com>
References: <j2n59d7961d1004010303ja372b671r8da5fc73ca62edb7@mail.gmail.com>
Message-ID: <k2xd8ad40b51004010321x5a1f0bcdi619c75103e6f9839@mail.gmail.com>

On Thu, Apr 1, 2010 at 11:03 AM, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Hi,
>
> I found in a bit of code the following test for infinity:
>
> ?if (x == Inf) ...
>
> Is that valid, or should it be (as I always thought):
>
> ?if (is.infinite(x)) ...?
>
> Does it depend on whether 'x' is float or integer?
>
> My question is related to testing for missing values where is.na(x) is required.

 Well, '-Inf' is infinite too:

 > is.infinite(-Inf)
 [1] TRUE

 but is not equal to Inf:

 > Inf == -Inf
 [1] FALSE

 Also, ?is.infinite says it is a generic method, so is.infinite(x)
could be doing anything, depending on x. I would say the best way of
testing if x is a numeric value of plus infinity would be to test
x==Inf.

 Also also, is.infinite (on a numeric vector) returns FALSE on NA, and
NaN, whereas x==Inf returns NA values for non nice-number inputs.

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From landronimirc at gmail.com  Thu Apr  1 13:09:56 2010
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 1 Apr 2010 12:09:56 +0100
Subject: [Rd] Make a donation via PayPal? (was: [R] Monetary support to the
	R-project)
Message-ID: <g2j68b1e2611004010409xcb438684ve240ace3a7bb93af@mail.gmail.com>

Dear R developers
I understand that this is not a proper r-devel message, but it still
touches to the organisation of the R project.

I would like to make a small donation to the project, but I am not
comfortable with sending my credit card details via post or mail and,
as echoed elsewhere on r-help, would prefer to go through a generally
accepted service such as PayPal.

Would there be any interest from the R project to implement this? Thank you
Liviu



On 3/8/10, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>  For companies and others wondering how to "give something back", it is
>  possible to support R and the R Foundation either through a donation:
>
>  http://www.r-project.org/ -> Foundation -> Donations
>  [http://www.r-project.org/foundation/donations.html]
>
>  or via a membership:
>
>  http://www.r-project.org/ -> Foundation -> Membership
>  [http://www.r-project.org/foundation/membership.html]
>
>  or both.
>


From ripley at stats.ox.ac.uk  Thu Apr  1 13:32:59 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Apr 2010 12:32:59 +0100 (BST)
Subject: [Rd] Make a donation via PayPal? (was: [R] Monetary support to
 the R-project)
In-Reply-To: <g2j68b1e2611004010409xcb438684ve240ace3a7bb93af@mail.gmail.com>
References: <g2j68b1e2611004010409xcb438684ve240ace3a7bb93af@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1004011222280.2193@gannet.stats.ox.ac.uk>

You need to ask the Treasurer of the R Foundation, who is Kurt Hornik 
(and who is on vacation).

On Thu, 1 Apr 2010, Liviu Andronic wrote:

> Dear R developers
> I understand that this is not a proper r-devel message, but it still
> touches to the organisation of the R project.

More the R Foundation, a legally separate entity.

> I would like to make a small donation to the project, but I am not
> comfortable with sending my credit card details via post or mail and,
> as echoed elsewhere on r-help, would prefer to go through a generally
> accepted service such as PayPal.

Depends on your country as to whether it is accepted at all, let alone 
'generally accepted'.  I've never seen an EU foundation which accepted 
it and there used at least to be legalities as to why.

> Would there be any interest from the R project to implement this? Thank you
> Liviu
>
>
>
> On 3/8/10, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>>  For companies and others wondering how to "give something back", it is
>>  possible to support R and the R Foundation either through a donation:
>>
>>  http://www.r-project.org/ -> Foundation -> Donations
>>  [http://www.r-project.org/foundation/donations.html]
>>
>>  or via a membership:
>>
>>  http://www.r-project.org/ -> Foundation -> Membership
>>  [http://www.r-project.org/foundation/membership.html]
>>
>>  or both.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Apr  1 17:19:24 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 01 Apr 2010 11:19:24 -0400
Subject: [Rd] RSS feeds now link to bug reports
Message-ID: <4BB4B97C.2080808@stats.uwo.ca>

Sometime last year Hadley Wickham suggested that the R daily news feed 
(http://developer.r-project.org/RSSfeeds.html) should link to bug 
reports.  Now that Simon has moved the bug reporting system to Bugzilla, 
this is finally possible, and I've just rebuilt the news items with 
those links in place.  For example, see the item under 2.11.0 BUG FIXES in

http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2010/04/01#n2010-04-01

Duncan Murdoch


From simon.urbanek at r-project.org  Thu Apr  1 17:37:49 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 1 Apr 2010 11:37:49 -0400
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <4BB3CEFD.2080302@userprimary.net>
References: <4BB3ACBF.8040409@u-paris10.fr> <4BB3CEFD.2080302@userprimary.net>
Message-ID: <514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>


On Mar 31, 2010, at 18:38 , Seth Falcon wrote:

> On 3/31/10 1:12 PM, Christophe Genolini wrote:
>> Hi the list,
>> I am writing a package that happen to not be compatible with linux
>> because I did not know that the function "savePlot" was available  
>> only
>> on windows. Is there a list of "incompatible" function? How can I get
>> this kind of information?
>
> One way is to obtain a copy of the R sources and then grep the Rd  
> files for '#ifdef'.
>
> I don't claim this is convenient.
>

nor sufficient - lot of it is simply in the windows directory (such as  
savePlot).
The safest approach right now is simply to read the documentation -  
savePlot does tell you that it works only for the Windows device. I'm  
not aware of an automated list (save for dumping the function lists  
per-package on each platform).

Cheers,
Simon


> There has been discussion, and I believe general consensus, that  
> we'd like to eliminate the conditional documentation.  This requires  
> editing the Rd files to make the contents sensible (you can't just  
> remove the #ifdef's).  Patches along these lines would be welcome.
>
> + seth
>
> -- 
> Seth Falcon | @sfalcon | http://userprimary.net/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From pgilbert at bank-banque-canada.ca  Thu Apr  1 17:59:44 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 1 Apr 2010 11:59:44 -0400
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>
References: <4BB3ACBF.8040409@u-paris10.fr> <4BB3CEFD.2080302@userprimary.net>
	<514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A0256A63B@EXMAIL2.bocad.bank-banque-canada.ca>

Since this seems more like a wish-list discussion, if someone actually
starts thinking about the issue I would like to add the following
somewhat related point:

It would be nice if there were a mechanism, in task views or that could
be used by task views, to avoid attempting to install packages that will
fail on the platform. The current ctv mechanism is difficult for system
administrators because they actually have to know enough about R
packages to decide which failures are ok and which ones are not.

Paul

>-----Original Message-----
>From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>project.org] On Behalf Of Simon Urbanek
>Sent: April 1, 2010 11:38 AM
>To: Seth Falcon
>Cc: r-devel at r-project.org
>Subject: Re: [Rd] Difference Linux / Windows
>
>
>On Mar 31, 2010, at 18:38 , Seth Falcon wrote:
>
>> On 3/31/10 1:12 PM, Christophe Genolini wrote:
>>> Hi the list,
>>> I am writing a package that happen to not be compatible with linux
>>> because I did not know that the function "savePlot" was available
>>> only
>>> on windows. Is there a list of "incompatible" function? How can I
get
>>> this kind of information?
>>
>> One way is to obtain a copy of the R sources and then grep the Rd
>> files for '#ifdef'.
>>
>> I don't claim this is convenient.
>>
>
>nor sufficient - lot of it is simply in the windows directory (such as
>savePlot).
>The safest approach right now is simply to read the documentation -
>savePlot does tell you that it works only for the Windows device. I'm
>not aware of an automated list (save for dumping the function lists
>per-package on each platform).
>
>Cheers,
>Simon
>
>
>> There has been discussion, and I believe general consensus, that
>> we'd like to eliminate the conditional documentation.  This requires
>> editing the Rd files to make the contents sensible (you can't just
>> remove the #ifdef's).  Patches along these lines would be welcome.
>>
>> + seth
>>
>> --
>> Seth Falcon | @sfalcon | http://userprimary.net/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From seth at userprimary.net  Thu Apr  1 18:45:48 2010
From: seth at userprimary.net (Seth Falcon)
Date: Thu, 01 Apr 2010 09:45:48 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB3E053.9020709@r-project.org>
References: <4BB3D21B.3030306@fhcrc.org> <4BB3E053.9020709@r-project.org>
Message-ID: <4BB4CDBC.90208@userprimary.net>

On 3/31/10 4:52 PM, John Chambers wrote:
> The example is confusing and debatable, but not an obvious bug.  And
> your presentation of it is the cause of much of the confusion
> (unintentionally I'm sure).

To restate the issue (I think):

In a new R session if you happen to call:

   selectMethod("coerce", c("integer", "numeric"))

*Before* having made a call like as(1:4, "numeric") then there is a 
side-effect of creating definition "A" of the integer => numeric coerce 
method.  From this point forward all calls to as(x, "numeric") when x is 
"integer" will return as.numeric(x).

If instead you do not call selectMethod, then when calling as(x, 
"numeric") for x "integer" you get definition "B", the documented 
behavior, which simply returns x.

Presumably there are other similar cases where this will be an issue.

So while I agree this could be considered obscure, this qualifies as a 
bug in my book.  It seems desirable that selectMethod not change the 
state of the system in a user-visible fashion.  And calling 
selectMethod, or any other function, should not alter dispatch unless 
documented to do so.

I'm also suspicious of the behavior of the strict argument:

 > class(as(1:4, "numeric"))
[1] "integer"
 > class(as(1:4, "numeric", strict = TRUE))
[1] "integer"
 > class(as(1:4, "numeric", strict = FALSE))
[1] "integer"

Is that intended?

+ seth


From tlumley at u.washington.edu  Thu Apr  1 18:46:51 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 1 Apr 2010 09:46:51 -0700 (PDT)
Subject: [Rd] Is it valid to do x == Inf?
In-Reply-To: <j2n59d7961d1004010303ja372b671r8da5fc73ca62edb7@mail.gmail.com>
Message-ID: <alpine.LRH.2.01.1004010946510.29508@hymn11.u.washington.edu>

On Thu, 1 Apr 2010, Henrik Bengtsson wrote:

> Hi,
>
> I found in a bit of code the following test for infinity:
>
>  if (x == Inf) ...
>
> Is that valid

Yes, if you don't want to also include -Inf

>, or should it be (as I always thought):
>
>  if (is.infinite(x)) ...?

If you don't want to distinguish Inf and -Inf

> Does it depend on whether 'x' is float or integer?

There isn't an integer infinity. Integer values larger than the maximum reprensentable give NA
eg > .Machine$integer.max+1L
[1] NA

> My question is related to testing for missing values where is.na(x) is required.

NA is different, because NA by its nature can't compare equal to anything: x==NA asks: "Is x equal to some number I don't know?", to which the answer is "Don't know".

x==Inf asks "Is x positive infinite?", which is a perfectly well-defined question.

     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From simon.urbanek at r-project.org  Thu Apr  1 18:50:52 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 1 Apr 2010 12:50:52 -0400
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <D611103AA7EE3B4DAE7F7D49C72B291A0256A63B@EXMAIL2.bocad.bank-banque-canada.ca>
References: <4BB3ACBF.8040409@u-paris10.fr> <4BB3CEFD.2080302@userprimary.net>
	<514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>
	<D611103AA7EE3B4DAE7F7D49C72B291A0256A63B@EXMAIL2.bocad.bank-banque-canada.ca>
Message-ID: <E3AE2CA6-8FBC-4CE0-BC12-87062B81D347@r-project.org>


On Apr 1, 2010, at 11:59 , Paul Gilbert wrote:

> Since this seems more like a wish-list discussion, if someone actually
> starts thinking about the issue I would like to add the following
> somewhat related point:
>
> It would be nice if there were a mechanism, in task views or that  
> could
> be used by task views, to avoid attempting to install packages that  
> will
> fail on the platform. The current ctv mechanism is difficult for  
> system
> administrators because they actually have to know enough about R
> packages to decide which failures are ok and which ones are not.
>

Well, that is an entirely different issue and it is easy since we  
already have the mechanism in place: OS_type.

Cheers,
Simon



>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Simon Urbanek
>> Sent: April 1, 2010 11:38 AM
>> To: Seth Falcon
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Difference Linux / Windows
>>
>>
>> On Mar 31, 2010, at 18:38 , Seth Falcon wrote:
>>
>>> On 3/31/10 1:12 PM, Christophe Genolini wrote:
>>>> Hi the list,
>>>> I am writing a package that happen to not be compatible with linux
>>>> because I did not know that the function "savePlot" was available
>>>> only
>>>> on windows. Is there a list of "incompatible" function? How can I
> get
>>>> this kind of information?
>>>
>>> One way is to obtain a copy of the R sources and then grep the Rd
>>> files for '#ifdef'.
>>>
>>> I don't claim this is convenient.
>>>
>>
>> nor sufficient - lot of it is simply in the windows directory (such  
>> as
>> savePlot).
>> The safest approach right now is simply to read the documentation -
>> savePlot does tell you that it works only for the Windows device. I'm
>> not aware of an automated list (save for dumping the function lists
>> per-package on each platform).
>>
>> Cheers,
>> Simon
>>
>>
>>> There has been discussion, and I believe general consensus, that
>>> we'd like to eliminate the conditional documentation.  This requires
>>> editing the Rd files to make the contents sensible (you can't just
>>> remove the #ifdef's).  Patches along these lines would be welcome.
>>>
>>> + seth
>>>
>>> --
>>> Seth Falcon | @sfalcon | http://userprimary.net/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> ======================================================================
>
> La version fran?aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential information,  
> and the Bank of
> Canada does not waive any related rights. Any distribution, use, or  
> copying of this
> email or the information it contains by other than the intended  
> recipient is
> unauthorized. If you received this email in error please delete it  
> immediately from
> your system and notify the sender promptly by email that you have  
> done so.
>
> ------------------------------------------------------------------------------------
>
> Le pr?sent courriel peut contenir de l'information privil?gi?e ou  
> confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent.  
> Toute diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il  
> contient par une
> personne autre que le ou les destinataires d?sign?s est interdite. 
> Si vous recevez
> ce courriel par erreur, veuillez le supprimer imm?diatement et  
> envoyer sans d?lai ?
> l'exp?diteur un message ?lectronique pour l'aviser que vous avez  
> ?limin? de votre
> ordinateur toute copie du courriel re?u.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ehlers at ucalgary.ca  Thu Apr  1 20:12:55 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Thu, 01 Apr 2010 12:12:55 -0600
Subject: [Rd] Minor typo in ?.Primitive
Message-ID: <4BB4E227.30406@ucalgary.ca>

The help page for .Primitive has this line:

## start quote
This function is almost never used: get(name, envir=basenv()) works 
equally well and ....
## end quote

basenv() should be baseenv().

Checked for r51392 and r51520.


  -Peter Ehlers


From jmc at r-project.org  Thu Apr  1 20:44:46 2010
From: jmc at r-project.org (John Chambers)
Date: Thu, 01 Apr 2010 11:44:46 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB44BD2.3000207@fhcrc.org>
References: <4BB3D21B.3030306@fhcrc.org> <4BB3E053.9020709@r-project.org>
	<4BB44BD2.3000207@fhcrc.org>
Message-ID: <4BB4E99E.9080601@r-project.org>

The point I was making was that as() is not just a synonym for selecting 
a method from coerce() by the usual inheritance rules.  I don't believe 
it should be, and the documentation emphasizes that inheritance is not 
used in the ordinary way.

If one were to start rewriting code (which I'm not suggesting) my 
preference would be to  have coerce() not be a generic function, 
eliminating the offending selectMethod() calls.

John


On 4/1/10 12:31 AM, Herv? Pag?s wrote:
> Hi John,
>
> John Chambers wrote:
>> The example is confusing and debatable, but not an obvious bug.  And
>> your presentation of it is the cause of much of the confusion
>> (unintentionally I'm sure).
>>
>> First, slipping from the as() function to methods for the coerce()
>> function might surprise a less experienced user.  And in fact, that
>> is the point here.  If you look at the as() function, it jumps
>> through several hoops and in particular selects a method from coerce
>> in such a way as NOT to use inheritance on the from= argument.  (I
>> think this makes sense in this case).  So I would assert that your
>> selectMethod() output below came from a different session than the
>> as(1:4, "numeric").
>>
>> Starting from a clean session with R 2.10.1:
>>
>> > class(as(1:4,"numeric"))
>> [1] "integer"
>> > selectMethod("coerce", c("integer","numeric"))
>> Method Definition:
>>
>> function (from, to = "numeric", strict = TRUE)
>> if (strict) {
>>     class(from) <- "numeric"
>>     from
>> } else from
>> <environment: namespace:methods>
>>
>> Signatures:
>>         from      to
>> target  "integer" "numeric"
>> defined "integer" "numeric"
>>
>> Note, no call to as.numeric().  In a session without a previous call
>> to as(), your selectMethod() call triggered a standard inherited
>> method selection.  And if you had then gone on to as(), the result
>> would have been different.
>
> Yes indeed. From a fresh start:
>
> > invisible(selectMethod("coerce", c("integer","numeric")))
> > class(as(1:4, "numeric"))
> [1] "numeric"
>
> But without the initial call to selectMethod(), as(1:4, "numeric")
> returns an integer vector.
>
> Sorry but it's hard for me to understand the reasons for having
> such behaviour, especially when selectMethod() is described as a
> function "to *look* for a method corresponding to a given generic
> function and signature". Apparently it does more than just looking...
>
>>
>> In a different clean session:
>>
>>
>> > getMethod("coerce", c("integer", "numeric"))
>> Error in getMethod("coerce", c("integer", "numeric")) :
>>   No method found for function "coerce" and signature integer, numeric
>> > selectMethod("coerce", c("integer", "numeric"))
>> Method Definition:
>>
>> function (from, to, strict = TRUE)
>> {
>>     value <- as.numeric(from)
>>     if (strict)
>>         attributes(value) <- NULL
>>     value
>> }
>> <environment: namespace:methods>
>>
>> Signatures:
>>         from      to
>> target  "integer" "numeric"
>> defined "ANY"     "numeric"
>> > class(as(1:4,"numeric"))
>> [1] "numeric"
>>
>> No argument about this being confusing.  Perhaps one should prohibit
>> standard selectMethod() on coerce() but that seems a bit arcane to
>> thwart folks like you!
>>
>> Suggested improvements for the current implementation are welcome, so
>> long as they consider the best definition of as() in the general sense.
>
> So one problem seems to be that, on a fresh start, *both*
>     as(1:4, "numeric")
> and
>     selectMethod("coerce", c("integer", "numeric"))
> will cache a coerce method for the c("integer", "numeric") signature,
> but they don't cache the *same* method!
>
> The automatic method cached by 'as(1:4, "numeric")' seems to be
> coming from:
>
>   getClassDef("integer")@contains$numeric at coerce
>
> Maybe one way to improve things would be to modify this part of
> the class definition for "integer" so it is in sync with
>
>   selectMethod("coerce", c("integer", "numeric")).
>
> There are other situations where the coerce methods are not
> in sync:
>
> > getClassDef("factor")@contains$integer at coerce
>   function (from, strict = TRUE)
>   {
>     attributes(from) <- NULL
>     from
>   }
> <environment: namespace:methods>
>
> > selectMethod("coerce", c("factor", "integer"))
>   Method Definition:
>
>   function (from, to, strict = TRUE)
>   {
>     value <- as.integer(from)
>     if (strict)
>         attributes(value) <- NULL
>     value
>   }
> <environment: namespace:methods>
>
> That isn't a problem here because both methods will produce
> the same result but is there any reason why the former
> couldn't use the same code as the latter?
>
> A more radical approach would be to have a call to
>
>   selectMethod("coerce", c("integer", "numeric"))
>
> have the same effect on the table of coerce methods than a
> call to
>
>   as(1:4, "numeric")
>
> i.e. the former will insert the same automatic method as the
> latter. That means that all the hard work made by the as()
> function in order to find/create/cache an appropriate method
> would need to be moved to selectMethod() so in that function
> 'f="coerce"' would become a special case.
> Then as() would become a 10 line function (or less) that would
> basically delegate to selectMethod("coerce", ...) to do the hard
> work. This solution seems better to me as it would then guarantee
> consistency between what as() does and what
> selectMethod("coerce", ...) says.
>
> Cheers,
> H.
>
>>
>> Regards,
>>   John
>>
>> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> > class(as(1:4, "numeric"))
>>>   [1] "integer"
>>>
>>> Surprising but an explanation could be that an integer
>>> vector being a particular case of numeric vector, this
>>> coercion has nothing to do because 1:4 is already numeric.
>>> And indeed:
>>>
>>> > is.numeric(1:4)
>>>   [1] TRUE
>>> > is.numeric(as(1:4, "numeric"))
>>>   [1] TRUE
>>>
>>> However, 'as(1:4, "numeric")' is inconsistent with
>>>
>>> > class(as.numeric(1:4))
>>>   [1] "numeric"
>>>
>>> And, even more confusing, if you look at the coerce,ANY,numeric
>>> method:
>>>
>>> > selectMethod("coerce", c("integer", "numeric"))
>>>   Method Definition:
>>>
>>>   function (from, to, strict = TRUE)
>>>   {
>>>     value <- as.numeric(from)
>>>     if (strict)
>>>         attributes(value) <- NULL
>>>     value
>>>   }
>>> <environment: namespace:methods>
>>>
>>>   Signatures:
>>>           from      to
>>>   target  "integer" "numeric"
>>>   defined "ANY"     "numeric"
>>>
>>> it calls as.numeric()!
>>>
>>> So how can 'as(1:4, "numeric")' not return the same thing as
>>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>>> conceivable that I found a bug?
>>>
>>> Cheers,
>>> H.
>>>
>>>
>>> > sessionInfo()
>>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>>> x86_64-unknown-linux-gnu
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>


From b.rowlingson at lancaster.ac.uk  Thu Apr  1 21:03:29 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 1 Apr 2010 20:03:29 +0100
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>
References: <4BB3ACBF.8040409@u-paris10.fr> <4BB3CEFD.2080302@userprimary.net>
	<514226B9-7D41-4A5F-9AEB-AFD1F4CA3784@r-project.org>
Message-ID: <u2kd8ad40b51004011203we2280b4asb11f92f76183442@mail.gmail.com>

On Thu, Apr 1, 2010 at 4:37 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Mar 31, 2010, at 18:38 , Seth Falcon wrote:
>
>> On 3/31/10 1:12 PM, Christophe Genolini wrote:
>>>
>>> Hi the list,
>>> I am writing a package that happen to not be compatible with linux
>>> because I did not know that the function "savePlot" was available only
>>> on windows. Is there a list of "incompatible" function? How can I get
>>> this kind of information?
>>
>> One way is to obtain a copy of the R sources and then grep the Rd files
>> for '#ifdef'.
>>
>> I don't claim this is convenient.
>>
>
> nor sufficient - lot of it is simply in the windows directory (such as
> savePlot).
> The safest approach right now is simply to read the documentation - savePlot
> does tell you that it works only for the Windows device. I'm not aware of an
> automated list (save for dumping the function lists per-package on each
> platform).

 It works only on the "windows()" device on the Windows platform. The
savePlot function *is* on the Linux platform (contrary to OP message,
modulo whether a mention of 'windows' meant the platform or the
device) but only for Cairo x11() devices.

Clear?

Barry


From jmc at r-project.org  Thu Apr  1 21:05:59 2010
From: jmc at r-project.org (John Chambers)
Date: Thu, 01 Apr 2010 12:05:59 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB4CDBC.90208@userprimary.net>
References: <4BB3D21B.3030306@fhcrc.org> <4BB3E053.9020709@r-project.org>
	<4BB4CDBC.90208@userprimary.net>
Message-ID: <4BB4EE97.2090606@r-project.org>

On 4/1/10 9:45 AM, Seth Falcon wrote:
> So while I agree this could be considered obscure, this qualifies as a 
> bug in my book.  It seems desirable that selectMethod not change the 
> state of the system in a user-visible fashion.  And calling 
> selectMethod, or any other function, should not alter dispatch unless 
> documented to do so.
As I said in my reply to Herv?, if a change is proposed, I'd prefer it 
to be to disallow the selectMethod() call by not making coerce() a 
generic, or at least not one visible outside the namespace.

Your general stricture on selectMethod() sounds good, except that the 
function has the optional argument useInheritance=.  Then it will always 
be possible to have different side effects depending on how 
selectMethod() is called.  I would have no difficulty in principle with 
making the side-effects ONLY when it's called in the standard way, as 
happens implicitly from method dispatch.  To do that, however, requires 
making the change suggested in my previous paragraph, otherwise the user 
can  still frustrate the current implementation of as().
>
> I'm also suspicious of the behavior of the strict argument:
>
> > class(as(1:4, "numeric"))
> [1] "integer"
> > class(as(1:4, "numeric", strict = TRUE))
> [1] "integer"
> > class(as(1:4, "numeric", strict = FALSE))
> [1] "integer"
>
> Is that intended?
In the part of my mail you cut out, you'll see that this has to do with 
the semantics of
   class(from) <- "numeric"
I have no strong feelings on that, if someone wants to implement and 
defend a change.

John
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Thu Apr  1 21:12:33 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 01 Apr 2010 15:12:33 -0400
Subject: [Rd] Difference Linux / Windows
In-Reply-To: <4BB3CEFD.2080302@userprimary.net>
References: <4BB3ACBF.8040409@u-paris10.fr> <4BB3CEFD.2080302@userprimary.net>
Message-ID: <4BB4F021.8000402@stats.uwo.ca>

On 31/03/2010 6:38 PM, Seth Falcon wrote:
> On 3/31/10 1:12 PM, Christophe Genolini wrote:
> > Hi the list,
> > I am writing a package that happen to not be compatible with linux
> > because I did not know that the function "savePlot" was available only
> > on windows. Is there a list of "incompatible" function? How can I get
> > this kind of information?
>
> One way is to obtain a copy of the R sources and then grep the Rd files 
> for '#ifdef'.
>
> I don't claim this is convenient.
>
> There has been discussion, and I believe general consensus, that we'd 
> like to eliminate the conditional documentation.  This requires editing 
> the Rd files to make the contents sensible (you can't just remove the 
> #ifdef's).  Patches along these lines would be welcome.

Producing those patches would be a lot of work even to incorporate, let 
alone write.  Another possibility is some sort of markup in the display 
to indicate platform-specific bits.  That would be a lot easier to 
implement; the hard part is the design. 

We have to design for 4 different output formats:  LaTeX, HTML, plain 
text, and executable example code.  We need to design for help files 
that display differently on different platforms, and for help files that 
only exist on a subset of the platforms.

Duncan Murdoch


From APeterhansl at GAINCapital.com  Thu Apr  1 14:54:15 2010
From: APeterhansl at GAINCapital.com (Alexander Peterhansl)
Date: Thu, 1 Apr 2010 08:54:15 -0400
Subject: [Rd] strptime(): on Linux system it seems to call system time?
In-Reply-To: <alpine.LFD.2.00.1004010810410.4126@gannet.stats.ox.ac.uk>
References: <27112007B97C7B439E9BC5A8ADCFF345024976@EX2.GAINCapital.com>
	<4BA50BE9.2030302@gmail.com>
	<20100401070050.GA4444@slingshot.co.nz>
	<alpine.LFD.2.00.1004010810410.4126@gannet.stats.ox.ac.uk>
Message-ID: <27112007B97C7B439E9BC5A8ADCFF3450249C4@EX2.GAINCapital.com>

Thanks for the two posts.

What if the timezone is set?  Then the issue of system calls for the
timezone falls away, no?
 
system.time(for (i in 1:100000) strptime("2010-03-10 17:00:00", "%F
%H:%M:%S", tz="DST"))

Output on Linux Box (64-bit R 2.10.1 running on Intel Xeon E5520 @
2.27GHz):
   user  system elapsed 
 3.096    3.252    6.371

ORIGINAL
   user  system elapsed 
   3.33    8.941    12.273

This is does speed up things considerably, but I still don't know for
what all that system time is used?  If I can trace system calls, I will
follow up.

As far as vectorization is concerned, this example was meant as
reproducible "toy" code to illustrate an issue in a more complex,
non-"vectorizable" setup.

Alex




-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Thursday, April 01, 2010 4:38 AM
To: Patrick Connolly
Cc: Peter Dalgaard; r-devel at r-project.org; Alexander Peterhansl
Subject: Re: [Rd] strptime(): on Linux system it seems to call system
time?

Let me lay this to rest.  For some reason the OP did not use a 
vectorized call to strptime but 100000 individual calls (as well as 
making *false* claims about what strptime does and what is 'completely 
unnecessary', and seemingly being igorant of system.time()).

I do not believe this is ever an issue for well-written R code.

Each time strptime() is called it needs to find and set the timezone 
(as whether an input is valid or not and whether it is in DST depends 
on the timezone).  If tz = "", the default, it needs to ask the system 
what the current timezone is via the C call tzset.  On well-written C 
runtimes tzset caches and so is fast after the first time.  On some 
others it reads files such as /etc/localtime each time.

On my Linux system (x86_64 Fedora 12)

system.time(for (i in 1:100000) strptime("2010-03-10 17:00:00", "%F
%H:%M:%S"))
    user  system elapsed
   1.048   0.222   2.086
system.time(strptime(rep("2010-03-10 17:00:00", 100000), "%F %H:%M:%S"))
    user  system elapsed
   0.371   0.184   0.579

whereas on my 2008 Mac laptop

    user  system elapsed
   7.402   0.015   7.441
    user  system elapsed
   6.689   0.013   6.716

and on my 2005 Windows laptop

    user  system elapsed
    2.47    0.00    2.47
    user  system elapsed
    1.39    0.00    1.40

(for which the credit is entirely due to the replacement code in R: 
Windows' datetime code is only used for strftime).

So looks like Apple could improve their POSIX datetime runtime, but 
I've never seen an R application where parsing dates took longer than 
reading the original posting (let alone the time taken to read some 
good books on how to time R code and write it efficiently).


On Thu, 1 Apr 2010, Patrick Connolly wrote:

> On Sat, 20-Mar-2010 at 06:54PM +0100, Peter Dalgaard wrote:
>
> [...]
>
> |> It seems to be  completely system-dependent. On Fedora 9, I see
> |>
> |>    user  system elapsed
> |>   2.890   0.314   3.374
> |>
> |> but on openSUSE 10.3 it is
> |>
> |>    user  system elapsed
> |>   3.924   6.992  10.917
> |>
> |> At any rate, I suspect that this is an issue with the operating
system
> |> and its C libraries, not with R as such.
>
> Were those 32 or 64 bit?
>
> With Fedora 11 and AMD Athlon 2 Ghz, I get
>
>   user  system elapsed
>  1.395   0.294   1.885
>
> with Mepis 7 on a Celeron 1.6 Ghz,
>
>   user  system elapsed
>  3.890   5.896   9.845
>
> Both of those are 32 bit.
> Maybe 64 bit does things very differently.
>
>
>
> -- 
>
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>   ___    Patrick Connolly
> {~._.~}                   Great minds discuss ideas
> _( Y )_  	         Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
> (_)-(_)  	                      ..... Eleanor Roosevelt
>
>
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hpages at fhcrc.org  Thu Apr  1 23:59:09 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 01 Apr 2010 14:59:09 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB4E99E.9080601@r-project.org>
References: <4BB3D21B.3030306@fhcrc.org> <4BB3E053.9020709@r-project.org>
	<4BB44BD2.3000207@fhcrc.org> <4BB4E99E.9080601@r-project.org>
Message-ID: <4BB5172D.7080905@fhcrc.org>

John Chambers wrote:
> The point I was making was that as() is not just a synonym for selecting 
> a method from coerce() by the usual inheritance rules.  I don't believe 
> it should be, and the documentation emphasizes that inheritance is not 
> used in the ordinary way.

I got this. If you look carefully at the change I'm suggesting for
selectMethod(), you will notice that I said that f="coerce" would
then need to become a special case.
In other words, when f="coerce", the usual inheritance rules are 
replaced by the rules that are currently implemented in as() and
described in its man page.
So to summarize: (1) the code in as() that is currently in charge of
selecting/creating/caching the most adequate coerce method is moved
to selectMethod(), (2) the sections in ?as that describe the rules
of this non-standard inheritance are moved to ?selectMethod.

> 
> If one were to start rewriting code (which I'm not suggesting) my 
> preference would be to  have coerce() not be a generic function, 
> eliminating the offending selectMethod() calls.

Then how one would know what as() is doing *exactly* i.e. which
coerce method was used or will be used in such or such situation?
showMethods()/selectMethod() are great tools because they allow the
developer to predict things and troubleshoot.

If you don't like putting the non-standard inheritance rules in
selectMethod() (when f="coerce") then you can always add something
like selectAsMethod() and put them here, and also add something
like showAsMethods(). I guess that's more or less what you are
saying when you propose to have coerce() not be a generic function,
at least not an usual one.
But it's important to expose selectAsMethod()/showAsMethods() to
the user. We absolutely need them!

Now I'm not sure I understand your concern about putting this
stuff in the existing selectMethod()/showMethods(). Why not just
ignore the useInheritance= arg when f="coerce"? Again, this would
be a special case anyway (and documented). The advantage of this
solution (over selectAsMethod()/showAsMethods()) is to avoid having
to introduce and expose 2 new names, so the user doesn't have to
switch between select*/show* tools depending on whether f="coerce"
or not.

H.

> 
> John
> 
> 
> On 4/1/10 12:31 AM, Herv? Pag?s wrote:
>> Hi John,
>>
>> John Chambers wrote:
>>> The example is confusing and debatable, but not an obvious bug.  And
>>> your presentation of it is the cause of much of the confusion
>>> (unintentionally I'm sure).
>>>
>>> First, slipping from the as() function to methods for the coerce()
>>> function might surprise a less experienced user.  And in fact, that
>>> is the point here.  If you look at the as() function, it jumps
>>> through several hoops and in particular selects a method from coerce
>>> in such a way as NOT to use inheritance on the from= argument.  (I
>>> think this makes sense in this case).  So I would assert that your
>>> selectMethod() output below came from a different session than the
>>> as(1:4, "numeric").
>>>
>>> Starting from a clean session with R 2.10.1:
>>>
>>> > class(as(1:4,"numeric"))
>>> [1] "integer"
>>> > selectMethod("coerce", c("integer","numeric"))
>>> Method Definition:
>>>
>>> function (from, to = "numeric", strict = TRUE)
>>> if (strict) {
>>>     class(from) <- "numeric"
>>>     from
>>> } else from
>>> <environment: namespace:methods>
>>>
>>> Signatures:
>>>         from      to
>>> target  "integer" "numeric"
>>> defined "integer" "numeric"
>>>
>>> Note, no call to as.numeric().  In a session without a previous call
>>> to as(), your selectMethod() call triggered a standard inherited
>>> method selection.  And if you had then gone on to as(), the result
>>> would have been different.
>>
>> Yes indeed. From a fresh start:
>>
>> > invisible(selectMethod("coerce", c("integer","numeric")))
>> > class(as(1:4, "numeric"))
>> [1] "numeric"
>>
>> But without the initial call to selectMethod(), as(1:4, "numeric")
>> returns an integer vector.
>>
>> Sorry but it's hard for me to understand the reasons for having
>> such behaviour, especially when selectMethod() is described as a
>> function "to *look* for a method corresponding to a given generic
>> function and signature". Apparently it does more than just looking...
>>
>>>
>>> In a different clean session:
>>>
>>>
>>> > getMethod("coerce", c("integer", "numeric"))
>>> Error in getMethod("coerce", c("integer", "numeric")) :
>>>   No method found for function "coerce" and signature integer, numeric
>>> > selectMethod("coerce", c("integer", "numeric"))
>>> Method Definition:
>>>
>>> function (from, to, strict = TRUE)
>>> {
>>>     value <- as.numeric(from)
>>>     if (strict)
>>>         attributes(value) <- NULL
>>>     value
>>> }
>>> <environment: namespace:methods>
>>>
>>> Signatures:
>>>         from      to
>>> target  "integer" "numeric"
>>> defined "ANY"     "numeric"
>>> > class(as(1:4,"numeric"))
>>> [1] "numeric"
>>>
>>> No argument about this being confusing.  Perhaps one should prohibit
>>> standard selectMethod() on coerce() but that seems a bit arcane to
>>> thwart folks like you!
>>>
>>> Suggested improvements for the current implementation are welcome, so
>>> long as they consider the best definition of as() in the general sense.
>>
>> So one problem seems to be that, on a fresh start, *both*
>>     as(1:4, "numeric")
>> and
>>     selectMethod("coerce", c("integer", "numeric"))
>> will cache a coerce method for the c("integer", "numeric") signature,
>> but they don't cache the *same* method!
>>
>> The automatic method cached by 'as(1:4, "numeric")' seems to be
>> coming from:
>>
>>   getClassDef("integer")@contains$numeric at coerce
>>
>> Maybe one way to improve things would be to modify this part of
>> the class definition for "integer" so it is in sync with
>>
>>   selectMethod("coerce", c("integer", "numeric")).
>>
>> There are other situations where the coerce methods are not
>> in sync:
>>
>> > getClassDef("factor")@contains$integer at coerce
>>   function (from, strict = TRUE)
>>   {
>>     attributes(from) <- NULL
>>     from
>>   }
>> <environment: namespace:methods>
>>
>> > selectMethod("coerce", c("factor", "integer"))
>>   Method Definition:
>>
>>   function (from, to, strict = TRUE)
>>   {
>>     value <- as.integer(from)
>>     if (strict)
>>         attributes(value) <- NULL
>>     value
>>   }
>> <environment: namespace:methods>
>>
>> That isn't a problem here because both methods will produce
>> the same result but is there any reason why the former
>> couldn't use the same code as the latter?
>>
>> A more radical approach would be to have a call to
>>
>>   selectMethod("coerce", c("integer", "numeric"))
>>
>> have the same effect on the table of coerce methods than a
>> call to
>>
>>   as(1:4, "numeric")
>>
>> i.e. the former will insert the same automatic method as the
>> latter. That means that all the hard work made by the as()
>> function in order to find/create/cache an appropriate method
>> would need to be moved to selectMethod() so in that function
>> 'f="coerce"' would become a special case.
>> Then as() would become a 10 line function (or less) that would
>> basically delegate to selectMethod("coerce", ...) to do the hard
>> work. This solution seems better to me as it would then guarantee
>> consistency between what as() does and what
>> selectMethod("coerce", ...) says.
>>
>> Cheers,
>> H.
>>
>>>
>>> Regards,
>>>   John
>>>
>>> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>>>> Hi,
>>>>
>>>> > class(as(1:4, "numeric"))
>>>>   [1] "integer"
>>>>
>>>> Surprising but an explanation could be that an integer
>>>> vector being a particular case of numeric vector, this
>>>> coercion has nothing to do because 1:4 is already numeric.
>>>> And indeed:
>>>>
>>>> > is.numeric(1:4)
>>>>   [1] TRUE
>>>> > is.numeric(as(1:4, "numeric"))
>>>>   [1] TRUE
>>>>
>>>> However, 'as(1:4, "numeric")' is inconsistent with
>>>>
>>>> > class(as.numeric(1:4))
>>>>   [1] "numeric"
>>>>
>>>> And, even more confusing, if you look at the coerce,ANY,numeric
>>>> method:
>>>>
>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>   Method Definition:
>>>>
>>>>   function (from, to, strict = TRUE)
>>>>   {
>>>>     value <- as.numeric(from)
>>>>     if (strict)
>>>>         attributes(value) <- NULL
>>>>     value
>>>>   }
>>>> <environment: namespace:methods>
>>>>
>>>>   Signatures:
>>>>           from      to
>>>>   target  "integer" "numeric"
>>>>   defined "ANY"     "numeric"
>>>>
>>>> it calls as.numeric()!
>>>>
>>>> So how can 'as(1:4, "numeric")' not return the same thing as
>>>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>>>> conceivable that I found a bug?
>>>>
>>>> Cheers,
>>>> H.
>>>>
>>>>
>>>> > sessionInfo()
>>>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>>>> x86_64-unknown-linux-gnu
>>>>
>>>> locale:
>>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>>
>>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jmc at r-project.org  Fri Apr  2 02:07:00 2010
From: jmc at r-project.org (John Chambers)
Date: Thu, 01 Apr 2010 17:07:00 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB5172D.7080905@fhcrc.org>
References: <4BB3D21B.3030306@fhcrc.org>
	<4BB3E053.9020709@r-project.org>	<4BB44BD2.3000207@fhcrc.org>
	<4BB4E99E.9080601@r-project.org> <4BB5172D.7080905@fhcrc.org>
Message-ID: <4BB53524.1020501@r-project.org>

The problem that you have exposed is that if one uses the *standard* 
form of selectMethod() on function "coerce", this could corrupt the 
intended set of methods used by as().  Of course, no one was expected to 
do this, but it's not caught or warned (as opposed to a direct call to 
coerce(), which does generate a warning).

If people think this is something of sufficient importance to put high 
on the fix-it list, contributions are welcome as always.

However, it seems a really bad idea to start making the definition of 
method selection by inheritance depend in an arbitrary way on which 
function is operated on.  Documenting what selection does is hard enough 
as it is.

A solution localized to the as() computation is to treat the mechanism 
involved in a call to setAsMethod  as something special, and provide 
whatever information is needed via showAsMethods(), or similar.  From a 
tutorial view, it might be good to emphasize that this is NOT the usual 
method dispatch--indeed, the present discussion supports that view.

Method selection in a functional language is a difficult concept, 
particularly for programmers coming from a standard OOP background.  If 
we're going to change it, let's aim to make it simpler, not more 
complicated.  What about getting rid of the kludgy argument 
useInheritance= in a future version, if nobody has a use for it other 
than in as()?  If you look at the code, you'll see that would simplify 
it significantly, and even speed up selection somewhat. There's a change 
I would be happy about!

John

On 4/1/10 2:59 PM, Herv? Pag?s wrote:
> John Chambers wrote:
>> The point I was making was that as() is not just a synonym for 
>> selecting a method from coerce() by the usual inheritance rules.  I 
>> don't believe it should be, and the documentation emphasizes that 
>> inheritance is not used in the ordinary way.
>
> I got this. If you look carefully at the change I'm suggesting for
> selectMethod(), you will notice that I said that f="coerce" would
> then need to become a special case.
> In other words, when f="coerce", the usual inheritance rules are 
> replaced by the rules that are currently implemented in as() and
> described in its man page.
> So to summarize: (1) the code in as() that is currently in charge of
> selecting/creating/caching the most adequate coerce method is moved
> to selectMethod(), (2) the sections in ?as that describe the rules
> of this non-standard inheritance are moved to ?selectMethod.
>
>>
>> If one were to start rewriting code (which I'm not suggesting) my 
>> preference would be to  have coerce() not be a generic function, 
>> eliminating the offending selectMethod() calls.
>
> Then how one would know what as() is doing *exactly* i.e. which
> coerce method was used or will be used in such or such situation?
> showMethods()/selectMethod() are great tools because they allow the
> developer to predict things and troubleshoot.
>
> If you don't like putting the non-standard inheritance rules in
> selectMethod() (when f="coerce") then you can always add something
> like selectAsMethod() and put them here, and also add something
> like showAsMethods(). I guess that's more or less what you are
> saying when you propose to have coerce() not be a generic function,
> at least not an usual one.
> But it's important to expose selectAsMethod()/showAsMethods() to
> the user. We absolutely need them!
>
> Now I'm not sure I understand your concern about putting this
> stuff in the existing selectMethod()/showMethods(). Why not just
> ignore the useInheritance= arg when f="coerce"? Again, this would
> be a special case anyway (and documented). The advantage of this
> solution (over selectAsMethod()/showAsMethods()) is to avoid having
> to introduce and expose 2 new names, so the user doesn't have to
> switch between select*/show* tools depending on whether f="coerce"
> or not.
>
> H.
>
>>
>> John
>>
>>
>> On 4/1/10 12:31 AM, Herv? Pag?s wrote:
>>> Hi John,
>>>
>>> John Chambers wrote:
>>>> The example is confusing and debatable, but not an obvious bug.  And
>>>> your presentation of it is the cause of much of the confusion
>>>> (unintentionally I'm sure).
>>>>
>>>> First, slipping from the as() function to methods for the coerce()
>>>> function might surprise a less experienced user.  And in fact, that
>>>> is the point here.  If you look at the as() function, it jumps
>>>> through several hoops and in particular selects a method from coerce
>>>> in such a way as NOT to use inheritance on the from= argument.  (I
>>>> think this makes sense in this case).  So I would assert that your
>>>> selectMethod() output below came from a different session than the
>>>> as(1:4, "numeric").
>>>>
>>>> Starting from a clean session with R 2.10.1:
>>>>
>>>> > class(as(1:4,"numeric"))
>>>> [1] "integer"
>>>> > selectMethod("coerce", c("integer","numeric"))
>>>> Method Definition:
>>>>
>>>> function (from, to = "numeric", strict = TRUE)
>>>> if (strict) {
>>>>     class(from) <- "numeric"
>>>>     from
>>>> } else from
>>>> <environment: namespace:methods>
>>>>
>>>> Signatures:
>>>>         from      to
>>>> target  "integer" "numeric"
>>>> defined "integer" "numeric"
>>>>
>>>> Note, no call to as.numeric().  In a session without a previous call
>>>> to as(), your selectMethod() call triggered a standard inherited
>>>> method selection.  And if you had then gone on to as(), the result
>>>> would have been different.
>>>
>>> Yes indeed. From a fresh start:
>>>
>>> > invisible(selectMethod("coerce", c("integer","numeric")))
>>> > class(as(1:4, "numeric"))
>>> [1] "numeric"
>>>
>>> But without the initial call to selectMethod(), as(1:4, "numeric")
>>> returns an integer vector.
>>>
>>> Sorry but it's hard for me to understand the reasons for having
>>> such behaviour, especially when selectMethod() is described as a
>>> function "to *look* for a method corresponding to a given generic
>>> function and signature". Apparently it does more than just looking...
>>>
>>>>
>>>> In a different clean session:
>>>>
>>>>
>>>> > getMethod("coerce", c("integer", "numeric"))
>>>> Error in getMethod("coerce", c("integer", "numeric")) :
>>>>   No method found for function "coerce" and signature integer, numeric
>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>> Method Definition:
>>>>
>>>> function (from, to, strict = TRUE)
>>>> {
>>>>     value <- as.numeric(from)
>>>>     if (strict)
>>>>         attributes(value) <- NULL
>>>>     value
>>>> }
>>>> <environment: namespace:methods>
>>>>
>>>> Signatures:
>>>>         from      to
>>>> target  "integer" "numeric"
>>>> defined "ANY"     "numeric"
>>>> > class(as(1:4,"numeric"))
>>>> [1] "numeric"
>>>>
>>>> No argument about this being confusing.  Perhaps one should prohibit
>>>> standard selectMethod() on coerce() but that seems a bit arcane to
>>>> thwart folks like you!
>>>>
>>>> Suggested improvements for the current implementation are welcome, so
>>>> long as they consider the best definition of as() in the general 
>>>> sense.
>>>
>>> So one problem seems to be that, on a fresh start, *both*
>>>     as(1:4, "numeric")
>>> and
>>>     selectMethod("coerce", c("integer", "numeric"))
>>> will cache a coerce method for the c("integer", "numeric") signature,
>>> but they don't cache the *same* method!
>>>
>>> The automatic method cached by 'as(1:4, "numeric")' seems to be
>>> coming from:
>>>
>>>   getClassDef("integer")@contains$numeric at coerce
>>>
>>> Maybe one way to improve things would be to modify this part of
>>> the class definition for "integer" so it is in sync with
>>>
>>>   selectMethod("coerce", c("integer", "numeric")).
>>>
>>> There are other situations where the coerce methods are not
>>> in sync:
>>>
>>> > getClassDef("factor")@contains$integer at coerce
>>>   function (from, strict = TRUE)
>>>   {
>>>     attributes(from) <- NULL
>>>     from
>>>   }
>>> <environment: namespace:methods>
>>>
>>> > selectMethod("coerce", c("factor", "integer"))
>>>   Method Definition:
>>>
>>>   function (from, to, strict = TRUE)
>>>   {
>>>     value <- as.integer(from)
>>>     if (strict)
>>>         attributes(value) <- NULL
>>>     value
>>>   }
>>> <environment: namespace:methods>
>>>
>>> That isn't a problem here because both methods will produce
>>> the same result but is there any reason why the former
>>> couldn't use the same code as the latter?
>>>
>>> A more radical approach would be to have a call to
>>>
>>>   selectMethod("coerce", c("integer", "numeric"))
>>>
>>> have the same effect on the table of coerce methods than a
>>> call to
>>>
>>>   as(1:4, "numeric")
>>>
>>> i.e. the former will insert the same automatic method as the
>>> latter. That means that all the hard work made by the as()
>>> function in order to find/create/cache an appropriate method
>>> would need to be moved to selectMethod() so in that function
>>> 'f="coerce"' would become a special case.
>>> Then as() would become a 10 line function (or less) that would
>>> basically delegate to selectMethod("coerce", ...) to do the hard
>>> work. This solution seems better to me as it would then guarantee
>>> consistency between what as() does and what
>>> selectMethod("coerce", ...) says.
>>>
>>> Cheers,
>>> H.
>>>
>>>>
>>>> Regards,
>>>>   John
>>>>
>>>> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>>>>> Hi,
>>>>>
>>>>> > class(as(1:4, "numeric"))
>>>>>   [1] "integer"
>>>>>
>>>>> Surprising but an explanation could be that an integer
>>>>> vector being a particular case of numeric vector, this
>>>>> coercion has nothing to do because 1:4 is already numeric.
>>>>> And indeed:
>>>>>
>>>>> > is.numeric(1:4)
>>>>>   [1] TRUE
>>>>> > is.numeric(as(1:4, "numeric"))
>>>>>   [1] TRUE
>>>>>
>>>>> However, 'as(1:4, "numeric")' is inconsistent with
>>>>>
>>>>> > class(as.numeric(1:4))
>>>>>   [1] "numeric"
>>>>>
>>>>> And, even more confusing, if you look at the coerce,ANY,numeric
>>>>> method:
>>>>>
>>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>>   Method Definition:
>>>>>
>>>>>   function (from, to, strict = TRUE)
>>>>>   {
>>>>>     value <- as.numeric(from)
>>>>>     if (strict)
>>>>>         attributes(value) <- NULL
>>>>>     value
>>>>>   }
>>>>> <environment: namespace:methods>
>>>>>
>>>>>   Signatures:
>>>>>           from      to
>>>>>   target  "integer" "numeric"
>>>>>   defined "ANY"     "numeric"
>>>>>
>>>>> it calls as.numeric()!
>>>>>
>>>>> So how can 'as(1:4, "numeric")' not return the same thing as
>>>>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>>>>> conceivable that I found a bug?
>>>>>
>>>>> Cheers,
>>>>> H.
>>>>>
>>>>>
>>>>> > sessionInfo()
>>>>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>>>>> x86_64-unknown-linux-gnu
>>>>>
>>>>> locale:
>>>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>>>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>>
>>>
>


From romain at r-enthusiasts.com  Fri Apr  2 12:17:29 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 02 Apr 2010 12:17:29 +0200
Subject: [Rd] inject html code into Rd file
Message-ID: <4BB5C439.9090505@r-enthusiasts.com>

Hello,

I'm trying to inject html code into an Rd file. For example :

\name{test}
\alias{test}
\title{test}
\description{
\if{html}{
\Sexpr[stage=render,results=text,echo=FALSE]{
	"<b>hello</b>"
}
}
}

when this file is rendered, instead of having "hello" in bold, I get 
<b>hello</b>, i.e. characters < and > are replaced with html entities : 
&lt; and &gt;

Is there a way to turn this off ?

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7
`- http://tr.im/O1wO : highlight 0.1-5


From murdoch at stats.uwo.ca  Fri Apr  2 13:07:03 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 02 Apr 2010 07:07:03 -0400
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB5C439.9090505@r-enthusiasts.com>
References: <4BB5C439.9090505@r-enthusiasts.com>
Message-ID: <4BB5CFD7.9000702@stats.uwo.ca>

On 02/04/2010 6:17 AM, Romain Francois wrote:
> Hello,
> 
> I'm trying to inject html code into an Rd file. For example :
> 
> \name{test}
> \alias{test}
> \title{test}
> \description{
> \if{html}{
> \Sexpr[stage=render,results=text,echo=FALSE]{
> 	"<b>hello</b>"
> }
> }
> }
> 
> when this file is rendered, instead of having "hello" in bold, I get 
> <b>hello</b>, i.e. characters < and > are replaced with html entities : 
> &lt; and &gt;
> 
> Is there a way to turn this off ?

Yes, if you wrap it in \out{}.  The example in the manual is

\if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}

Duncan Murdoch


From romain at r-enthusiasts.com  Fri Apr  2 13:13:18 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 02 Apr 2010 13:13:18 +0200
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB5CFD7.9000702@stats.uwo.ca>
References: <4BB5C439.9090505@r-enthusiasts.com>
	<4BB5CFD7.9000702@stats.uwo.ca>
Message-ID: <4BB5D14E.2070102@r-enthusiasts.com>

Le 02/04/10 13:07, Duncan Murdoch a ?crit :
> On 02/04/2010 6:17 AM, Romain Francois wrote:
>> Hello,
>>
>> I'm trying to inject html code into an Rd file. For example :
>>
>> \name{test}
>> \alias{test}
>> \title{test}
>> \description{
>> \if{html}{
>> \Sexpr[stage=render,results=text,echo=FALSE]{
>> "<b>hello</b>"
>> }
>> }
>> }
>>
>> when this file is rendered, instead of having "hello" in bold, I get
>> <b>hello</b>, i.e. characters < and > are replaced with html entities
>> : &lt; and &gt;
>>
>> Is there a way to turn this off ?
>
> Yes, if you wrap it in \out{}. The example in the manual is
>
> \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}
>
> Duncan Murdoch

yes, I saw that in WRE, I should have been more specific.


what if instead of a trivial string like "<b>hello</b>" the text is to 
be computed by some function. For example:

print( xtable( iris), type = "html" )

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7
`- http://tr.im/O1wO : highlight 0.1-5


From murdoch at stats.uwo.ca  Fri Apr  2 14:06:12 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 02 Apr 2010 08:06:12 -0400
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB5D14E.2070102@r-enthusiasts.com>
References: <4BB5C439.9090505@r-enthusiasts.com>
	<4BB5CFD7.9000702@stats.uwo.ca>
	<4BB5D14E.2070102@r-enthusiasts.com>
Message-ID: <4BB5DDB4.6070908@stats.uwo.ca>

On 02/04/2010 7:13 AM, Romain Francois wrote:
> Le 02/04/10 13:07, Duncan Murdoch a ?crit :
>> On 02/04/2010 6:17 AM, Romain Francois wrote:
>>> Hello,
>>>
>>> I'm trying to inject html code into an Rd file. For example :
>>>
>>> \name{test}
>>> \alias{test}
>>> \title{test}
>>> \description{
>>> \if{html}{
>>> \Sexpr[stage=render,results=text,echo=FALSE]{
>>> "<b>hello</b>"
>>> }
>>> }
>>> }
>>>
>>> when this file is rendered, instead of having "hello" in bold, I get
>>> <b>hello</b>, i.e. characters < and > are replaced with html entities
>>> : &lt; and &gt;
>>>
>>> Is there a way to turn this off ?
>> Yes, if you wrap it in \out{}. The example in the manual is
>>
>> \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}
>>
>> Duncan Murdoch
> 
> yes, I saw that in WRE, I should have been more specific.
> 
> 
> what if instead of a trivial string like "<b>hello</b>" the text is to 
> be computed by some function. For example:
> 
> print( xtable( iris), type = "html" )

I think this should do it:

\Sexpr[stage=render,results=rd,echo=FALSE]{
paste("\\out{", "<b>hello</b>, "}", sep="")}

but this stuff hasn't been tested much, so there might be problems...

Duncan Murdoch


From jmc at r-project.org  Fri Apr  2 18:36:38 2010
From: jmc at r-project.org (John Chambers)
Date: Fri, 02 Apr 2010 09:36:38 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB53524.1020501@r-project.org>
References: <4BB3D21B.3030306@fhcrc.org>	<4BB3E053.9020709@r-project.org>	<4BB44BD2.3000207@fhcrc.org>	<4BB4E99E.9080601@r-project.org>
	<4BB5172D.7080905@fhcrc.org> <4BB53524.1020501@r-project.org>
Message-ID: <4BB61D16.3030601@r-project.org>

One more (final?) note on this example. A simpler change that would 
eliminate the inconsistent result from as():

1.  Change the warning on direct calls to coerce() to an error.

2. Move the caching of inherited methods to the actual dispatch code, so 
selectMethod() itself has no side effect.

The example itself suggests that 1 is needed, since a direct call would 
use ordinary inheritance rules, not those imposed by as().

Unless there is an unnoticed issue with this, I'll make the change, to 
r-devel of course.

John

On 4/1/10 5:07 PM, John Chambers wrote:
> The problem that you have exposed is that if one uses the *standard* 
> form of selectMethod() on function "coerce", this could corrupt the 
> intended set of methods used by as().  Of course, no one was expected 
> to do this, but it's not caught or warned (as opposed to a direct call 
> to coerce(), which does generate a warning).
>
> If people think this is something of sufficient importance to put high 
> on the fix-it list, contributions are welcome as always.
>
> However, it seems a really bad idea to start making the definition of 
> method selection by inheritance depend in an arbitrary way on which 
> function is operated on.  Documenting what selection does is hard 
> enough as it is.
>
> A solution localized to the as() computation is to treat the mechanism 
> involved in a call to setAsMethod  as something special, and provide 
> whatever information is needed via showAsMethods(), or similar.  From 
> a tutorial view, it might be good to emphasize that this is NOT the 
> usual method dispatch--indeed, the present discussion supports that view.
>
> Method selection in a functional language is a difficult concept, 
> particularly for programmers coming from a standard OOP background.  
> If we're going to change it, let's aim to make it simpler, not more 
> complicated.  What about getting rid of the kludgy argument 
> useInheritance= in a future version, if nobody has a use for it other 
> than in as()?  If you look at the code, you'll see that would simplify 
> it significantly, and even speed up selection somewhat. There's a 
> change I would be happy about!
>
> John
>
> On 4/1/10 2:59 PM, Herv? Pag?s wrote:
>> John Chambers wrote:
>>> The point I was making was that as() is not just a synonym for 
>>> selecting a method from coerce() by the usual inheritance rules.  I 
>>> don't believe it should be, and the documentation emphasizes that 
>>> inheritance is not used in the ordinary way.
>>
>> I got this. If you look carefully at the change I'm suggesting for
>> selectMethod(), you will notice that I said that f="coerce" would
>> then need to become a special case.
>> In other words, when f="coerce", the usual inheritance rules are 
>> replaced by the rules that are currently implemented in as() and
>> described in its man page.
>> So to summarize: (1) the code in as() that is currently in charge of
>> selecting/creating/caching the most adequate coerce method is moved
>> to selectMethod(), (2) the sections in ?as that describe the rules
>> of this non-standard inheritance are moved to ?selectMethod.
>>
>>>
>>> If one were to start rewriting code (which I'm not suggesting) my 
>>> preference would be to  have coerce() not be a generic function, 
>>> eliminating the offending selectMethod() calls.
>>
>> Then how one would know what as() is doing *exactly* i.e. which
>> coerce method was used or will be used in such or such situation?
>> showMethods()/selectMethod() are great tools because they allow the
>> developer to predict things and troubleshoot.
>>
>> If you don't like putting the non-standard inheritance rules in
>> selectMethod() (when f="coerce") then you can always add something
>> like selectAsMethod() and put them here, and also add something
>> like showAsMethods(). I guess that's more or less what you are
>> saying when you propose to have coerce() not be a generic function,
>> at least not an usual one.
>> But it's important to expose selectAsMethod()/showAsMethods() to
>> the user. We absolutely need them!
>>
>> Now I'm not sure I understand your concern about putting this
>> stuff in the existing selectMethod()/showMethods(). Why not just
>> ignore the useInheritance= arg when f="coerce"? Again, this would
>> be a special case anyway (and documented). The advantage of this
>> solution (over selectAsMethod()/showAsMethods()) is to avoid having
>> to introduce and expose 2 new names, so the user doesn't have to
>> switch between select*/show* tools depending on whether f="coerce"
>> or not.
>>
>> H.
>>
>>>
>>> John
>>>
>>>
>>> On 4/1/10 12:31 AM, Herv? Pag?s wrote:
>>>> Hi John,
>>>>
>>>> John Chambers wrote:
>>>>> The example is confusing and debatable, but not an obvious bug.  And
>>>>> your presentation of it is the cause of much of the confusion
>>>>> (unintentionally I'm sure).
>>>>>
>>>>> First, slipping from the as() function to methods for the coerce()
>>>>> function might surprise a less experienced user.  And in fact, that
>>>>> is the point here.  If you look at the as() function, it jumps
>>>>> through several hoops and in particular selects a method from coerce
>>>>> in such a way as NOT to use inheritance on the from= argument.  (I
>>>>> think this makes sense in this case).  So I would assert that your
>>>>> selectMethod() output below came from a different session than the
>>>>> as(1:4, "numeric").
>>>>>
>>>>> Starting from a clean session with R 2.10.1:
>>>>>
>>>>> > class(as(1:4,"numeric"))
>>>>> [1] "integer"
>>>>> > selectMethod("coerce", c("integer","numeric"))
>>>>> Method Definition:
>>>>>
>>>>> function (from, to = "numeric", strict = TRUE)
>>>>> if (strict) {
>>>>>     class(from) <- "numeric"
>>>>>     from
>>>>> } else from
>>>>> <environment: namespace:methods>
>>>>>
>>>>> Signatures:
>>>>>         from      to
>>>>> target  "integer" "numeric"
>>>>> defined "integer" "numeric"
>>>>>
>>>>> Note, no call to as.numeric().  In a session without a previous call
>>>>> to as(), your selectMethod() call triggered a standard inherited
>>>>> method selection.  And if you had then gone on to as(), the result
>>>>> would have been different.
>>>>
>>>> Yes indeed. From a fresh start:
>>>>
>>>> > invisible(selectMethod("coerce", c("integer","numeric")))
>>>> > class(as(1:4, "numeric"))
>>>> [1] "numeric"
>>>>
>>>> But without the initial call to selectMethod(), as(1:4, "numeric")
>>>> returns an integer vector.
>>>>
>>>> Sorry but it's hard for me to understand the reasons for having
>>>> such behaviour, especially when selectMethod() is described as a
>>>> function "to *look* for a method corresponding to a given generic
>>>> function and signature". Apparently it does more than just looking...
>>>>
>>>>>
>>>>> In a different clean session:
>>>>>
>>>>>
>>>>> > getMethod("coerce", c("integer", "numeric"))
>>>>> Error in getMethod("coerce", c("integer", "numeric")) :
>>>>>   No method found for function "coerce" and signature integer, 
>>>>> numeric
>>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>> Method Definition:
>>>>>
>>>>> function (from, to, strict = TRUE)
>>>>> {
>>>>>     value <- as.numeric(from)
>>>>>     if (strict)
>>>>>         attributes(value) <- NULL
>>>>>     value
>>>>> }
>>>>> <environment: namespace:methods>
>>>>>
>>>>> Signatures:
>>>>>         from      to
>>>>> target  "integer" "numeric"
>>>>> defined "ANY"     "numeric"
>>>>> > class(as(1:4,"numeric"))
>>>>> [1] "numeric"
>>>>>
>>>>> No argument about this being confusing.  Perhaps one should prohibit
>>>>> standard selectMethod() on coerce() but that seems a bit arcane to
>>>>> thwart folks like you!
>>>>>
>>>>> Suggested improvements for the current implementation are welcome, so
>>>>> long as they consider the best definition of as() in the general 
>>>>> sense.
>>>>
>>>> So one problem seems to be that, on a fresh start, *both*
>>>>     as(1:4, "numeric")
>>>> and
>>>>     selectMethod("coerce", c("integer", "numeric"))
>>>> will cache a coerce method for the c("integer", "numeric") signature,
>>>> but they don't cache the *same* method!
>>>>
>>>> The automatic method cached by 'as(1:4, "numeric")' seems to be
>>>> coming from:
>>>>
>>>>   getClassDef("integer")@contains$numeric at coerce
>>>>
>>>> Maybe one way to improve things would be to modify this part of
>>>> the class definition for "integer" so it is in sync with
>>>>
>>>>   selectMethod("coerce", c("integer", "numeric")).
>>>>
>>>> There are other situations where the coerce methods are not
>>>> in sync:
>>>>
>>>> > getClassDef("factor")@contains$integer at coerce
>>>>   function (from, strict = TRUE)
>>>>   {
>>>>     attributes(from) <- NULL
>>>>     from
>>>>   }
>>>> <environment: namespace:methods>
>>>>
>>>> > selectMethod("coerce", c("factor", "integer"))
>>>>   Method Definition:
>>>>
>>>>   function (from, to, strict = TRUE)
>>>>   {
>>>>     value <- as.integer(from)
>>>>     if (strict)
>>>>         attributes(value) <- NULL
>>>>     value
>>>>   }
>>>> <environment: namespace:methods>
>>>>
>>>> That isn't a problem here because both methods will produce
>>>> the same result but is there any reason why the former
>>>> couldn't use the same code as the latter?
>>>>
>>>> A more radical approach would be to have a call to
>>>>
>>>>   selectMethod("coerce", c("integer", "numeric"))
>>>>
>>>> have the same effect on the table of coerce methods than a
>>>> call to
>>>>
>>>>   as(1:4, "numeric")
>>>>
>>>> i.e. the former will insert the same automatic method as the
>>>> latter. That means that all the hard work made by the as()
>>>> function in order to find/create/cache an appropriate method
>>>> would need to be moved to selectMethod() so in that function
>>>> 'f="coerce"' would become a special case.
>>>> Then as() would become a 10 line function (or less) that would
>>>> basically delegate to selectMethod("coerce", ...) to do the hard
>>>> work. This solution seems better to me as it would then guarantee
>>>> consistency between what as() does and what
>>>> selectMethod("coerce", ...) says.
>>>>
>>>> Cheers,
>>>> H.
>>>>
>>>>>
>>>>> Regards,
>>>>>   John
>>>>>
>>>>> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>>>>>> Hi,
>>>>>>
>>>>>> > class(as(1:4, "numeric"))
>>>>>>   [1] "integer"
>>>>>>
>>>>>> Surprising but an explanation could be that an integer
>>>>>> vector being a particular case of numeric vector, this
>>>>>> coercion has nothing to do because 1:4 is already numeric.
>>>>>> And indeed:
>>>>>>
>>>>>> > is.numeric(1:4)
>>>>>>   [1] TRUE
>>>>>> > is.numeric(as(1:4, "numeric"))
>>>>>>   [1] TRUE
>>>>>>
>>>>>> However, 'as(1:4, "numeric")' is inconsistent with
>>>>>>
>>>>>> > class(as.numeric(1:4))
>>>>>>   [1] "numeric"
>>>>>>
>>>>>> And, even more confusing, if you look at the coerce,ANY,numeric
>>>>>> method:
>>>>>>
>>>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>>>   Method Definition:
>>>>>>
>>>>>>   function (from, to, strict = TRUE)
>>>>>>   {
>>>>>>     value <- as.numeric(from)
>>>>>>     if (strict)
>>>>>>         attributes(value) <- NULL
>>>>>>     value
>>>>>>   }
>>>>>> <environment: namespace:methods>
>>>>>>
>>>>>>   Signatures:
>>>>>>           from      to
>>>>>>   target  "integer" "numeric"
>>>>>>   defined "ANY"     "numeric"
>>>>>>
>>>>>> it calls as.numeric()!
>>>>>>
>>>>>> So how can 'as(1:4, "numeric")' not return the same thing as
>>>>>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>>>>>> conceivable that I found a bug?
>>>>>>
>>>>>> Cheers,
>>>>>> H.
>>>>>>
>>>>>>
>>>>>> > sessionInfo()
>>>>>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>>>>>> x86_64-unknown-linux-gnu
>>>>>>
>>>>>> locale:
>>>>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>>>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>>>>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>>
>>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Fri Apr  2 21:15:43 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 02 Apr 2010 12:15:43 -0700
Subject: [Rd] as(1:4, "numeric") versus as.numeric(1:4, "numeric")
In-Reply-To: <4BB53524.1020501@r-project.org>
References: <4BB3D21B.3030306@fhcrc.org>	<4BB3E053.9020709@r-project.org>	<4BB44BD2.3000207@fhcrc.org>	<4BB4E99E.9080601@r-project.org>
	<4BB5172D.7080905@fhcrc.org> <4BB53524.1020501@r-project.org>
Message-ID: <4BB6425F.9090405@fhcrc.org>

Hi John,

John Chambers wrote:
> The problem that you have exposed is that if one uses the *standard* 
> form of selectMethod() on function "coerce", this could corrupt the 
> intended set of methods used by as().  Of course, no one was expected to 
> do this, but it's not caught or warned (as opposed to a direct call to 
> coerce(), which does generate a warning).
> 
> If people think this is something of sufficient importance to put high 
> on the fix-it list, contributions are welcome as always.
> 
> However, it seems a really bad idea to start making the definition of 
> method selection by inheritance depend in an arbitrary way on which 
> function is operated on.  Documenting what selection does is hard enough 
> as it is.

The *definition* of method selection is what it is. And it's a fact that
the rules are different for as(). Hence selectMethod("coerce", ...) or
selectAsMethod() should reflect this.

> 
> A solution localized to the as() computation is to treat the mechanism 
> involved in a call to setAsMethod  as something special, and provide 
> whatever information is needed via showAsMethods(), or similar.  From a 
> tutorial view, it might be good to emphasize that this is NOT the usual 
> method dispatch--indeed, the present discussion supports that view.
> 
> Method selection in a functional language is a difficult concept, 
> particularly for programmers coming from a standard OOP background.  If 
> we're going to change it, let's aim to make it simpler, not more 
> complicated.

Just to clarify, I'm not proposing to change the *rules* of method
selection. The standard rules would remain exactly the same, and
the special rules used by as() (specified in its man page) would
also remain exactly the same. What would change however is that
selectMethod("coerce", ...) would not be broken anymore i.e. it
would not corrupt the table of "coerce" methods anymore, and it
would return the right method (as specified in the specs).

I hope I made the point that it's not about making things more
complicated ;-)

> What about getting rid of the kludgy argument 
> useInheritance= in a future version, if nobody has a use for it other 
> than in as()?  If you look at the code, you'll see that would simplify 
> it significantly, and even speed up selection somewhat. There's a change 
> I would be happy about!

That sounds all good to me.

Thanks,
H.

> 
> John
> 
> On 4/1/10 2:59 PM, Herv? Pag?s wrote:
>> John Chambers wrote:
>>> The point I was making was that as() is not just a synonym for 
>>> selecting a method from coerce() by the usual inheritance rules.  I 
>>> don't believe it should be, and the documentation emphasizes that 
>>> inheritance is not used in the ordinary way.
>>
>> I got this. If you look carefully at the change I'm suggesting for
>> selectMethod(), you will notice that I said that f="coerce" would
>> then need to become a special case.
>> In other words, when f="coerce", the usual inheritance rules are 
>> replaced by the rules that are currently implemented in as() and
>> described in its man page.
>> So to summarize: (1) the code in as() that is currently in charge of
>> selecting/creating/caching the most adequate coerce method is moved
>> to selectMethod(), (2) the sections in ?as that describe the rules
>> of this non-standard inheritance are moved to ?selectMethod.
>>
>>>
>>> If one were to start rewriting code (which I'm not suggesting) my 
>>> preference would be to  have coerce() not be a generic function, 
>>> eliminating the offending selectMethod() calls.
>>
>> Then how one would know what as() is doing *exactly* i.e. which
>> coerce method was used or will be used in such or such situation?
>> showMethods()/selectMethod() are great tools because they allow the
>> developer to predict things and troubleshoot.
>>
>> If you don't like putting the non-standard inheritance rules in
>> selectMethod() (when f="coerce") then you can always add something
>> like selectAsMethod() and put them here, and also add something
>> like showAsMethods(). I guess that's more or less what you are
>> saying when you propose to have coerce() not be a generic function,
>> at least not an usual one.
>> But it's important to expose selectAsMethod()/showAsMethods() to
>> the user. We absolutely need them!
>>
>> Now I'm not sure I understand your concern about putting this
>> stuff in the existing selectMethod()/showMethods(). Why not just
>> ignore the useInheritance= arg when f="coerce"? Again, this would
>> be a special case anyway (and documented). The advantage of this
>> solution (over selectAsMethod()/showAsMethods()) is to avoid having
>> to introduce and expose 2 new names, so the user doesn't have to
>> switch between select*/show* tools depending on whether f="coerce"
>> or not.
>>
>> H.
>>
>>>
>>> John
>>>
>>>
>>> On 4/1/10 12:31 AM, Herv? Pag?s wrote:
>>>> Hi John,
>>>>
>>>> John Chambers wrote:
>>>>> The example is confusing and debatable, but not an obvious bug.  And
>>>>> your presentation of it is the cause of much of the confusion
>>>>> (unintentionally I'm sure).
>>>>>
>>>>> First, slipping from the as() function to methods for the coerce()
>>>>> function might surprise a less experienced user.  And in fact, that
>>>>> is the point here.  If you look at the as() function, it jumps
>>>>> through several hoops and in particular selects a method from coerce
>>>>> in such a way as NOT to use inheritance on the from= argument.  (I
>>>>> think this makes sense in this case).  So I would assert that your
>>>>> selectMethod() output below came from a different session than the
>>>>> as(1:4, "numeric").
>>>>>
>>>>> Starting from a clean session with R 2.10.1:
>>>>>
>>>>> > class(as(1:4,"numeric"))
>>>>> [1] "integer"
>>>>> > selectMethod("coerce", c("integer","numeric"))
>>>>> Method Definition:
>>>>>
>>>>> function (from, to = "numeric", strict = TRUE)
>>>>> if (strict) {
>>>>>     class(from) <- "numeric"
>>>>>     from
>>>>> } else from
>>>>> <environment: namespace:methods>
>>>>>
>>>>> Signatures:
>>>>>         from      to
>>>>> target  "integer" "numeric"
>>>>> defined "integer" "numeric"
>>>>>
>>>>> Note, no call to as.numeric().  In a session without a previous call
>>>>> to as(), your selectMethod() call triggered a standard inherited
>>>>> method selection.  And if you had then gone on to as(), the result
>>>>> would have been different.
>>>>
>>>> Yes indeed. From a fresh start:
>>>>
>>>> > invisible(selectMethod("coerce", c("integer","numeric")))
>>>> > class(as(1:4, "numeric"))
>>>> [1] "numeric"
>>>>
>>>> But without the initial call to selectMethod(), as(1:4, "numeric")
>>>> returns an integer vector.
>>>>
>>>> Sorry but it's hard for me to understand the reasons for having
>>>> such behaviour, especially when selectMethod() is described as a
>>>> function "to *look* for a method corresponding to a given generic
>>>> function and signature". Apparently it does more than just looking...
>>>>
>>>>>
>>>>> In a different clean session:
>>>>>
>>>>>
>>>>> > getMethod("coerce", c("integer", "numeric"))
>>>>> Error in getMethod("coerce", c("integer", "numeric")) :
>>>>>   No method found for function "coerce" and signature integer, numeric
>>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>> Method Definition:
>>>>>
>>>>> function (from, to, strict = TRUE)
>>>>> {
>>>>>     value <- as.numeric(from)
>>>>>     if (strict)
>>>>>         attributes(value) <- NULL
>>>>>     value
>>>>> }
>>>>> <environment: namespace:methods>
>>>>>
>>>>> Signatures:
>>>>>         from      to
>>>>> target  "integer" "numeric"
>>>>> defined "ANY"     "numeric"
>>>>> > class(as(1:4,"numeric"))
>>>>> [1] "numeric"
>>>>>
>>>>> No argument about this being confusing.  Perhaps one should prohibit
>>>>> standard selectMethod() on coerce() but that seems a bit arcane to
>>>>> thwart folks like you!
>>>>>
>>>>> Suggested improvements for the current implementation are welcome, so
>>>>> long as they consider the best definition of as() in the general 
>>>>> sense.
>>>>
>>>> So one problem seems to be that, on a fresh start, *both*
>>>>     as(1:4, "numeric")
>>>> and
>>>>     selectMethod("coerce", c("integer", "numeric"))
>>>> will cache a coerce method for the c("integer", "numeric") signature,
>>>> but they don't cache the *same* method!
>>>>
>>>> The automatic method cached by 'as(1:4, "numeric")' seems to be
>>>> coming from:
>>>>
>>>>   getClassDef("integer")@contains$numeric at coerce
>>>>
>>>> Maybe one way to improve things would be to modify this part of
>>>> the class definition for "integer" so it is in sync with
>>>>
>>>>   selectMethod("coerce", c("integer", "numeric")).
>>>>
>>>> There are other situations where the coerce methods are not
>>>> in sync:
>>>>
>>>> > getClassDef("factor")@contains$integer at coerce
>>>>   function (from, strict = TRUE)
>>>>   {
>>>>     attributes(from) <- NULL
>>>>     from
>>>>   }
>>>> <environment: namespace:methods>
>>>>
>>>> > selectMethod("coerce", c("factor", "integer"))
>>>>   Method Definition:
>>>>
>>>>   function (from, to, strict = TRUE)
>>>>   {
>>>>     value <- as.integer(from)
>>>>     if (strict)
>>>>         attributes(value) <- NULL
>>>>     value
>>>>   }
>>>> <environment: namespace:methods>
>>>>
>>>> That isn't a problem here because both methods will produce
>>>> the same result but is there any reason why the former
>>>> couldn't use the same code as the latter?
>>>>
>>>> A more radical approach would be to have a call to
>>>>
>>>>   selectMethod("coerce", c("integer", "numeric"))
>>>>
>>>> have the same effect on the table of coerce methods than a
>>>> call to
>>>>
>>>>   as(1:4, "numeric")
>>>>
>>>> i.e. the former will insert the same automatic method as the
>>>> latter. That means that all the hard work made by the as()
>>>> function in order to find/create/cache an appropriate method
>>>> would need to be moved to selectMethod() so in that function
>>>> 'f="coerce"' would become a special case.
>>>> Then as() would become a 10 line function (or less) that would
>>>> basically delegate to selectMethod("coerce", ...) to do the hard
>>>> work. This solution seems better to me as it would then guarantee
>>>> consistency between what as() does and what
>>>> selectMethod("coerce", ...) says.
>>>>
>>>> Cheers,
>>>> H.
>>>>
>>>>>
>>>>> Regards,
>>>>>   John
>>>>>
>>>>> On 3/31/10 3:52 PM, Herv? Pag?s wrote:
>>>>>> Hi,
>>>>>>
>>>>>> > class(as(1:4, "numeric"))
>>>>>>   [1] "integer"
>>>>>>
>>>>>> Surprising but an explanation could be that an integer
>>>>>> vector being a particular case of numeric vector, this
>>>>>> coercion has nothing to do because 1:4 is already numeric.
>>>>>> And indeed:
>>>>>>
>>>>>> > is.numeric(1:4)
>>>>>>   [1] TRUE
>>>>>> > is.numeric(as(1:4, "numeric"))
>>>>>>   [1] TRUE
>>>>>>
>>>>>> However, 'as(1:4, "numeric")' is inconsistent with
>>>>>>
>>>>>> > class(as.numeric(1:4))
>>>>>>   [1] "numeric"
>>>>>>
>>>>>> And, even more confusing, if you look at the coerce,ANY,numeric
>>>>>> method:
>>>>>>
>>>>>> > selectMethod("coerce", c("integer", "numeric"))
>>>>>>   Method Definition:
>>>>>>
>>>>>>   function (from, to, strict = TRUE)
>>>>>>   {
>>>>>>     value <- as.numeric(from)
>>>>>>     if (strict)
>>>>>>         attributes(value) <- NULL
>>>>>>     value
>>>>>>   }
>>>>>> <environment: namespace:methods>
>>>>>>
>>>>>>   Signatures:
>>>>>>           from      to
>>>>>>   target  "integer" "numeric"
>>>>>>   defined "ANY"     "numeric"
>>>>>>
>>>>>> it calls as.numeric()!
>>>>>>
>>>>>> So how can 'as(1:4, "numeric")' not return the same thing as
>>>>>> 'as.numeric(1:4)' looks like a mystery to me. Could it be
>>>>>> conceivable that I found a bug?
>>>>>>
>>>>>> Cheers,
>>>>>> H.
>>>>>>
>>>>>>
>>>>>> > sessionInfo()
>>>>>> R version 2.11.0 Under development (unstable) (2010-03-15 r51282)
>>>>>> x86_64-unknown-linux-gnu
>>>>>>
>>>>>> locale:
>>>>>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>>>>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>>>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
>>>>>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>>
>>>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ehlers at ucalgary.ca  Fri Apr  2 21:36:40 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 02 Apr 2010 13:36:40 -0600
Subject: [Rd] packages with DLLs under 2.12.0
Message-ID: <4BB64748.4090003@ucalgary.ca>

I realize that R-core must be busy with the imminent release of
2.11.0, so please consider this not urgent.

The NEWS file for 2.12.0 (Windows-specific) says, in part:

   For now, 32-bit packages with compiled code built under
   2.{10,11}.x can be used, but this will be disabled before
   release.

For me, this doesn't work without a tweak. For example,

 > library(mvtnorm)
#Error: package 'mvtnorm' is not installed for 'arch=i386'

I tested a few (6 or 7) other randomly selected packages
(bitops, igraph, ...) before wising up and looking at the
recommended and automatically installed packages like
lattice, etc. I see that the 'libs' folder now has an
'i386' subfolder where the DDLs reside.

Making that change by hand fixes the 'problem'.

 > sessionInfo()
R version 2.12.0 Under development (unstable) (2010-03-31 r51520)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
[5] LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] mvtnorm_0.9-9

loaded via a namespace (and not attached):
[1] tools_2.12.0

-- 
Peter Ehlers
University of Calgary


From murdoch at stats.uwo.ca  Sat Apr  3 02:04:32 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 02 Apr 2010 20:04:32 -0400
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB5DDB4.6070908@stats.uwo.ca>
References: <4BB5C439.9090505@r-enthusiasts.com>	<4BB5CFD7.9000702@stats.uwo.ca>	<4BB5D14E.2070102@r-enthusiasts.com>
	<4BB5DDB4.6070908@stats.uwo.ca>
Message-ID: <4BB68610.10901@stats.uwo.ca>

On 02/04/2010 8:06 AM, Duncan Murdoch wrote:
> On 02/04/2010 7:13 AM, Romain Francois wrote:
>> Le 02/04/10 13:07, Duncan Murdoch a ?crit :
>>> On 02/04/2010 6:17 AM, Romain Francois wrote:
>>>> Hello,
>>>>
>>>> I'm trying to inject html code into an Rd file. For example :
>>>>
>>>> \name{test}
>>>> \alias{test}
>>>> \title{test}
>>>> \description{
>>>> \if{html}{
>>>> \Sexpr[stage=render,results=text,echo=FALSE]{
>>>> "<b>hello</b>"
>>>> }
>>>> }
>>>> }
>>>>
>>>> when this file is rendered, instead of having "hello" in bold, I get
>>>> <b>hello</b>, i.e. characters < and > are replaced with html entities
>>>> : &lt; and &gt;
>>>>
>>>> Is there a way to turn this off ?
>>> Yes, if you wrap it in \out{}. The example in the manual is
>>>
>>> \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}
>>>
>>> Duncan Murdoch
>> yes, I saw that in WRE, I should have been more specific.
>>
>>
>> what if instead of a trivial string like "<b>hello</b>" the text is to 
>> be computed by some function. For example:
>>
>> print( xtable( iris), type = "html" )
> 
> I think this should do it:
> 
> \Sexpr[stage=render,results=rd,echo=FALSE]{
> paste("\\out{", "<b>hello</b>, "}", sep="")}
> 
> but this stuff hasn't been tested much, so there might be problems...

One problem is that the backslashes need to be escaped twice, so you'd want

  \Sexpr[stage=render,results=rd,echo=FALSE]{
  paste("\\\\out{", "<b>hello</b>, "}", sep="")}

and you'd probably want it wrapped in \if or \ifelse so that it doesn't 
show up in text or latex output:

  \Sexpr[stage=render,results=rd, 
echo=FALSE]{"\\\\if{html}{\\\\out{<b>hello</b>}}"}

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sat Apr  3 08:46:16 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 3 Apr 2010 07:46:16 +0100 (BST)
Subject: [Rd] packages with DLLs under 2.12.0
In-Reply-To: <4BB64748.4090003@ucalgary.ca>
References: <4BB64748.4090003@ucalgary.ca>
Message-ID: <alpine.LFD.2.00.1004030722540.3206@gannet.stats.ox.ac.uk>

That may have been true in r51520, but we are at r51566 and that does 
work as documented AFAICS.

Note though that this is only a temporary workaround, and it will go 
away once repositories are rebuilt for 2.12.0, and simply bulding the 
packages from sources would have worked.

On Fri, 2 Apr 2010, Peter Ehlers wrote:

> I realize that R-core must be busy with the imminent release of
> 2.11.0, so please consider this not urgent.

The advice for R-devel is always to try the latest version (preferably 
from SVN) and to wait a couple of days and try again if you find a 
problem, before reporting.

R-devel is particularly unstable at present as we work on merging the 
32- and 64-bit Windows distributions.  Unless you have a very good 
reason to use it, we suggest using 2.11.0 alpha etc until 2.11.0 is 
released.

> The NEWS file for 2.12.0 (Windows-specific) says, in part:

You mean the CHANGES file?

>  For now, 32-bit packages with compiled code built under
>  2.{10,11}.x can be used, but this will be disabled before
>  release.
>
> For me, this doesn't work without a tweak. For example,
>
>> library(mvtnorm)
> #Error: package 'mvtnorm' is not installed for 'arch=i386'
>
> I tested a few (6 or 7) other randomly selected packages
> (bitops, igraph, ...) before wising up and looking at the
> recommended and automatically installed packages like
> lattice, etc. I see that the 'libs' folder now has an
> 'i386' subfolder where the DDLs reside.
>
> Making that change by hand fixes the 'problem'.
>
>> sessionInfo()
> R version 2.12.0 Under development (unstable) (2010-03-31 r51520)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] mvtnorm_0.9-9
>
> loaded via a namespace (and not attached):
> [1] tools_2.12.0
>
> -- 
> Peter Ehlers
> University of Calgary
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain at r-enthusiasts.com  Sat Apr  3 10:11:35 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Sat, 03 Apr 2010 10:11:35 +0200
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB68610.10901@stats.uwo.ca>
References: <4BB5C439.9090505@r-enthusiasts.com>	<4BB5CFD7.9000702@stats.uwo.ca>	<4BB5D14E.2070102@r-enthusiasts.com>	<4BB5DDB4.6070908@stats.uwo.ca>
	<4BB68610.10901@stats.uwo.ca>
Message-ID: <4BB6F837.6030202@r-enthusiasts.com>

Le 03/04/10 02:04, Duncan Murdoch a ?crit :
>
> On 02/04/2010 8:06 AM, Duncan Murdoch wrote:
>> On 02/04/2010 7:13 AM, Romain Francois wrote:
>>> Le 02/04/10 13:07, Duncan Murdoch a ?crit :
>>>> On 02/04/2010 6:17 AM, Romain Francois wrote:
>>>>> Hello,
>>>>>
>>>>> I'm trying to inject html code into an Rd file. For example :
>>>>>
>>>>> \name{test}
>>>>> \alias{test}
>>>>> \title{test}
>>>>> \description{
>>>>> \if{html}{
>>>>> \Sexpr[stage=render,results=text,echo=FALSE]{
>>>>> "<b>hello</b>"
>>>>> }
>>>>> }
>>>>> }
>>>>>
>>>>> when this file is rendered, instead of having "hello" in bold, I get
>>>>> <b>hello</b>, i.e. characters < and > are replaced with html entities
>>>>> : &lt; and &gt;
>>>>>
>>>>> Is there a way to turn this off ?
>>>> Yes, if you wrap it in \out{}. The example in the manual is
>>>>
>>>> \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}
>>>>
>>>> Duncan Murdoch
>>> yes, I saw that in WRE, I should have been more specific.
>>>
>>>
>>> what if instead of a trivial string like "<b>hello</b>" the text is
>>> to be computed by some function. For example:
>>>
>>> print( xtable( iris), type = "html" )
>>
>> I think this should do it:
>>
>> \Sexpr[stage=render,results=rd,echo=FALSE]{
>> paste("\\out{", "<b>hello</b>, "}", sep="")}
>>
>> but this stuff hasn't been tested much, so there might be problems...
>
> One problem is that the backslashes need to be escaped twice, so you'd want
>
> \Sexpr[stage=render,results=rd,echo=FALSE]{
> paste("\\\\out{", "<b>hello</b>, "}", sep="")}
>
> and you'd probably want it wrapped in \if or \ifelse so that it doesn't
> show up in text or latex output:
>
> \Sexpr[stage=render,results=rd,
> echo=FALSE]{"\\\\if{html}{\\\\out{<b>hello</b>}}"}
>
> Duncan Murdoch

Thanks.
This gives one way to include images in a Rd file with data uri, here is 
a proof of concept (that depends on openssl to do the base 64 encoding):

img <- function(){
	tf <- tempfile()
	tf.out <- tempfile()
	png( tf, width = 500, height = 500)
	plot( 1:100, rnorm(100), pch = 21, bg = "red", cex =2 )
	dev.off()
	system( sprintf( 'openssl base64 -in "%s" -out "%s" ', tf, tf.out ) )
	sprintf( '\\out{<img src="data:image/png;base64,%s" />}',
		paste( readLines( tf.out), collapse = "\n" ) )
}

and the Rd file:

\name{test}
\alias{test}
\title{test}
\description{
\if{html}{
\Sexpr[stage=render,results=rd,echo=FALSE]{
	source( "test.R" )
	img()
}
}
}



It might be interesting to have something like results=asis or something.

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7
`- http://tr.im/O1wO : highlight 0.1-5


From xie at yihui.name  Sat Apr  3 21:46:37 2010
From: xie at yihui.name (Yihui Xie)
Date: Sat, 3 Apr 2010 14:46:37 -0500
Subject: [Rd] inject html code into Rd file
In-Reply-To: <4BB6F837.6030202@r-enthusiasts.com>
References: <4BB5C439.9090505@r-enthusiasts.com>
	<4BB5CFD7.9000702@stats.uwo.ca> <4BB5D14E.2070102@r-enthusiasts.com>
	<4BB5DDB4.6070908@stats.uwo.ca> <4BB68610.10901@stats.uwo.ca>
	<4BB6F837.6030202@r-enthusiasts.com>
Message-ID: <o2w89b6b8c91004031246l8bac6832w4c4eaeec226fe727@mail.gmail.com>

Sounds like a good idea. The RCurl package can also do the base64
encoding (depends on libcurl), e.g.

library(RCurl)
img <- function() {
    tf <- tempfile()
    tf.out <- tempfile()
    png(tf, width = 500, height = 500)
    plot(1:100, rnorm(100), pch = 21, bg = "red", cex = 2)
    dev.off()
    img <- readBin(tf, "raw", file.info(tf)[1, "size"])
    b64 <- base64Encode(img, "character")
    sprintf("<img src=\"data:image/png;base64,%s\" />", b64)
}
writeLines(img(), "test.html")

I saw your blog post today about your base64 package. My concern is IE
(<=7) does not support data uri...

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-6609 Web: http://yihui.name
Department of Statistics, Iowa State University
3211 Snedecor Hall, Ames, IA



On Sat, Apr 3, 2010 at 3:11 AM, Romain Francois
<romain at r-enthusiasts.com> wrote:
> Le 03/04/10 02:04, Duncan Murdoch a ?crit :
>>
>> On 02/04/2010 8:06 AM, Duncan Murdoch wrote:
>>>
>>> On 02/04/2010 7:13 AM, Romain Francois wrote:
>>>>
>>>> Le 02/04/10 13:07, Duncan Murdoch a ?crit :
>>>>>
>>>>> On 02/04/2010 6:17 AM, Romain Francois wrote:
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I'm trying to inject html code into an Rd file. For example :
>>>>>>
>>>>>> \name{test}
>>>>>> \alias{test}
>>>>>> \title{test}
>>>>>> \description{
>>>>>> \if{html}{
>>>>>> \Sexpr[stage=render,results=text,echo=FALSE]{
>>>>>> "<b>hello</b>"
>>>>>> }
>>>>>> }
>>>>>> }
>>>>>>
>>>>>> when this file is rendered, instead of having "hello" in bold, I get
>>>>>> <b>hello</b>, i.e. characters < and > are replaced with html entities
>>>>>> : &lt; and &gt;
>>>>>>
>>>>>> Is there a way to turn this off ?
>>>>>
>>>>> Yes, if you wrap it in \out{}. The example in the manual is
>>>>>
>>>>> \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}
>>>>>
>>>>> Duncan Murdoch
>>>>
>>>> yes, I saw that in WRE, I should have been more specific.
>>>>
>>>>
>>>> what if instead of a trivial string like "<b>hello</b>" the text is
>>>> to be computed by some function. For example:
>>>>
>>>> print( xtable( iris), type = "html" )
>>>
>>> I think this should do it:
>>>
>>> \Sexpr[stage=render,results=rd,echo=FALSE]{
>>> paste("\\out{", "<b>hello</b>, "}", sep="")}
>>>
>>> but this stuff hasn't been tested much, so there might be problems...
>>
>> One problem is that the backslashes need to be escaped twice, so you'd
>> want
>>
>> \Sexpr[stage=render,results=rd,echo=FALSE]{
>> paste("\\\\out{", "<b>hello</b>, "}", sep="")}
>>
>> and you'd probably want it wrapped in \if or \ifelse so that it doesn't
>> show up in text or latex output:
>>
>> \Sexpr[stage=render,results=rd,
>> echo=FALSE]{"\\\\if{html}{\\\\out{<b>hello</b>}}"}
>>
>> Duncan Murdoch
>
> Thanks.
> This gives one way to include images in a Rd file with data uri, here is a
> proof of concept (that depends on openssl to do the base 64 encoding):
>
> img <- function(){
> ? ? ? ?tf <- tempfile()
> ? ? ? ?tf.out <- tempfile()
> ? ? ? ?png( tf, width = 500, height = 500)
> ? ? ? ?plot( 1:100, rnorm(100), pch = 21, bg = "red", cex =2 )
> ? ? ? ?dev.off()
> ? ? ? ?system( sprintf( 'openssl base64 -in "%s" -out "%s" ', tf, tf.out ) )
> ? ? ? ?sprintf( '\\out{<img src="data:image/png;base64,%s" />}',
> ? ? ? ? ? ? ? ?paste( readLines( tf.out), collapse = "\n" ) )
> }
>
> and the Rd file:
>
> \name{test}
> \alias{test}
> \title{test}
> \description{
> \if{html}{
> \Sexpr[stage=render,results=rd,echo=FALSE]{
> ? ? ? ?source( "test.R" )
> ? ? ? ?img()
> }
> }
> }
>
>
>
> It might be interesting to have something like results=asis or something.
>
> Romain
>
> --
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://tr.im/OIXN : raster images and RImageJ
> |- http://tr.im/OcQe : Rcpp 0.7.7
> `- http://tr.im/O1wO : highlight 0.1-5
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From matloff at cs.ucdavis.edu  Sun Apr  4 00:34:35 2010
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 3 Apr 2010 15:34:35 -0700
Subject: [Rd] full copy on assignment?
Message-ID: <20100403223435.GA27306@laura>


Here's a basic question that doesn't seem to be completely answered in
the docs, and which unfortunately I've not had time to figure out by
wading through the R source code:

In a vector (or array) element assignment such as 

   z[3] <- 8 

is there in actuality a full rewriting of the entire vector pointed to
by z, as implied by

   z <- "[<-"(z,3,value=8)

Assume that an element of z has already being changed previously, so
that copy-on-change issues don't apply, with z being reassigned back to
the same memory address.

I seem to recall reading somewhere that recent R versions make some
attempt to avoid rewriting the entire vector, and my timing experiments
seem to suggest that it's true.  

So, is a full rewrite avoided?  And where in the source code is this
done?

Thanks.

Norm Matloff


From murdoch at stats.uwo.ca  Sun Apr  4 01:42:21 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 03 Apr 2010 19:42:21 -0400
Subject: [Rd] full copy on assignment?
In-Reply-To: <20100403223435.GA27306@laura>
References: <20100403223435.GA27306@laura>
Message-ID: <4BB7D25D.1040105@stats.uwo.ca>

On 03/04/2010 6:34 PM, Norm Matloff wrote:
> Here's a basic question that doesn't seem to be completely answered in
> the docs, and which unfortunately I've not had time to figure out by
> wading through the R source code:
> 
> In a vector (or array) element assignment such as 
> 
>    z[3] <- 8 
> 
> is there in actuality a full rewriting of the entire vector pointed to
> by z, as implied by
> 
>    z <- "[<-"(z,3,value=8)
> 
> Assume that an element of z has already being changed previously, so
> that copy-on-change issues don't apply, with z being reassigned back to
> the same memory address.
> 
> I seem to recall reading somewhere that recent R versions make some
> attempt to avoid rewriting the entire vector, and my timing experiments
> seem to suggest that it's true.  
> 
> So, is a full rewrite avoided?  And where in the source code is this
> done?

It depends.  User-written assignment functions can't avoid the copy. 
They act like the expansion

z <- "[<-"(z,3,value=8)

and in that, R can't tell that the newly created result of 
"[<-"(z,3,value=8) will later overwrite z.

However, if z is a regular vector without a class and you're using the 
built-in version of z[3] <- 8, it can take some shortcuts.  This happens 
in multiple places; one is around line 488 of subassign.c another is 
around line 1336.  In each of these places copies are made in some 
circumstances, but not in general.

Duncan Murdoch


From jmc at r-project.org  Sun Apr  4 02:54:58 2010
From: jmc at r-project.org (John Chambers)
Date: Sat, 03 Apr 2010 17:54:58 -0700
Subject: [Rd] full copy on assignment?
In-Reply-To: <4BB7D25D.1040105@stats.uwo.ca>
References: <20100403223435.GA27306@laura> <4BB7D25D.1040105@stats.uwo.ca>
Message-ID: <4BB7E362.3060304@r-project.org>

In particular, Duncan's comment applies in situations where the 
replacement is in a loop, obviously the case one worries about.

What happens in the stupid little function:

 > foo <- function(x) { for(i in seq_along(x)) x[i] <- x[i] +1; x}

for the case

 > y <- 1:1e6
 > y1 <- foo(y)

How often does y get duplicated? Hopefully not a million times.  One can 
look at this in gdb, by trapping calls to duplicate1.  The answer is:  
just once, to ensure that the object is local.  Then the duplicated 
version has only one reference and the primitive replacement doesn't 
copy it.

Unfortunately, as Duncan said, changing the definition to a user-written 
replacement function:

 > "sub<-" <- function(x,i, value){x[i]<- value; x}
 > foo <- function(x) { for(i in seq_along(x)) sub(x,i) <- x[i]+1; x}

does duplicate a million times, since every call to `sub<-` gets an 
argument with two references.

John



On 4/3/10 4:42 PM, Duncan Murdoch wrote:
> On 03/04/2010 6:34 PM, Norm Matloff wrote:
>> Here's a basic question that doesn't seem to be completely answered in
>> the docs, and which unfortunately I've not had time to figure out by
>> wading through the R source code:
>>
>> In a vector (or array) element assignment such as
>>    z[3] <- 8
>> is there in actuality a full rewriting of the entire vector pointed to
>> by z, as implied by
>>
>>    z <- "[<-"(z,3,value=8)
>>
>> Assume that an element of z has already being changed previously, so
>> that copy-on-change issues don't apply, with z being reassigned back to
>> the same memory address.
>>
>> I seem to recall reading somewhere that recent R versions make some
>> attempt to avoid rewriting the entire vector, and my timing experiments
>> seem to suggest that it's true.
>> So, is a full rewrite avoided?  And where in the source code is this
>> done?
>
> It depends.  User-written assignment functions can't avoid the copy. 
> They act like the expansion
>
> z <- "[<-"(z,3,value=8)
>
> and in that, R can't tell that the newly created result of 
> "[<-"(z,3,value=8) will later overwrite z.
>
> However, if z is a regular vector without a class and you're using the 
> built-in version of z[3] <- 8, it can take some shortcuts.  This 
> happens in multiple places; one is around line 488 of subassign.c 
> another is around line 1336.  In each of these places copies are made 
> in some circumstances, but not in general.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From matloff at cs.ucdavis.edu  Sun Apr  4 06:25:04 2010
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 3 Apr 2010 21:25:04 -0700
Subject: [Rd] full copy on assignment?
Message-ID: <20100404042504.GA14102@laura>


Thanks, Martin and Duncan, for the quick, cleary replies.

Norm


From matloff at cs.ucdavis.edu  Mon Apr  5 02:27:35 2010
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sun, 4 Apr 2010 17:27:35 -0700
Subject: [Rd] full copy on assignment?
In-Reply-To: <mailman.13.1270375206.14388.r-devel@r-project.org>
References: <mailman.13.1270375206.14388.r-devel@r-project.org>
Message-ID: <20100405002734.GA28962@laura>

Thanks very much.

By the way, I tried setting a GDB breakpoint at duplicate1(), with the
following:

  > x <- 1:10000000
  > x[3] <- 8
  > x[33] <- 88

I found that duplicate1() was called on both of the latter two lines.
I was a bit surprised, since change-on-write would seem to imply that
copying would be done in that second line but NOT on the third.
Moreover, system.time() gave 0.284 user time for the second and 0 on
the third.  YET duplicate1() WAS called on the third, and in stepping
through the code, there didn't seem to be an immediate exit.

Thanks to both John and Duncan for their comment on the fact that using
[<- directly is a very different situation.  That's not what I asked,
but the comment is useful to me for other reasons.

Norm

> Message: 4
> Date: Sat, 03 Apr 2010 17:54:58 -0700
> From: John Chambers <jmc at r-project.org>
> To: r-devel at r-project.org
> Subject: Re: [Rd] full copy on assignment?
...
...
> How often does y get duplicated? Hopefully not a million times.  One can 
> look at this in gdb, by trapping calls to duplicate1.  The answer is:  
> just once, to ensure that the object is local.  Then the duplicated 
> version has only one reference and the primitive replacement doesn't 
> copy it.
...


From mtmorgan at fhcrc.org  Mon Apr  5 03:17:01 2010
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 04 Apr 2010 18:17:01 -0700
Subject: [Rd] full copy on assignment?
In-Reply-To: <20100405002734.GA28962@laura>
References: <mailman.13.1270375206.14388.r-devel@r-project.org>
	<20100405002734.GA28962@laura>
Message-ID: <4BB93A0D.7080807@fhcrc.org>

On 04/04/2010 05:27 PM, Norm Matloff wrote:
> Thanks very much.
> 
> By the way, I tried setting a GDB breakpoint at duplicate1(), with the
> following:
> 
>   > x <- 1:10000000
>   > x[3] <- 8
>   > x[33] <- 88

Here's how I investigated this, with the last line somewhat surprising

  R -d gdb
  gdb> r
  ... cntrl-C
  gdb> break duplicate1
  gdb> commands
  > call Rf_PrintValue(s)
  > c
  > end
  gdb> c

  then

  x=5:1
  x[1L] = 1L # no copy
  x[1L] = 10 # type coercion, new alloc but no copy
  x[1] = 20 # copy of index (!)

Martin

> 
> I found that duplicate1() was called on both of the latter two lines.
> I was a bit surprised, since change-on-write would seem to imply that
> copying would be done in that second line but NOT on the third.
> Moreover, system.time() gave 0.284 user time for the second and 0 on
> the third.  YET duplicate1() WAS called on the third, and in stepping
> through the code, there didn't seem to be an immediate exit.
> 
> Thanks to both John and Duncan for their comment on the fact that using
> [<- directly is a very different situation.  That's not what I asked,
> but the comment is useful to me for other reasons.
> 
> Norm
> 
>> Message: 4
>> Date: Sat, 03 Apr 2010 17:54:58 -0700
>> From: John Chambers <jmc at r-project.org>
>> To: r-devel at r-project.org
>> Subject: Re: [Rd] full copy on assignment?
> ...
> ...
>> How often does y get duplicated? Hopefully not a million times.  One can 
>> look at this in gdb, by trapping calls to duplicate1.  The answer is:  
>> just once, to ensure that the object is local.  Then the duplicated 
>> version has only one reference and the primitive replacement doesn't 
>> copy it.
> ...
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From cgenolin at u-paris10.fr  Mon Apr  5 14:24:28 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 05 Apr 2010 14:24:28 +0200
Subject: [Rd] Microsoft conspiracy against R?
Message-ID: <4BB9D67C.5000500@u-paris10.fr>

Hi the list,
I am using getGraphicsEvent (pakage kml, function 'choice') to build a 
user friendly interface, but it seems that it is not linux/mac 
compatible. Is there anythink like getGraphicsEvent for R linux/mac?
Christophe


From maechler at stat.math.ethz.ch  Mon Apr  5 20:54:32 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 Apr 2010 20:54:32 +0200
Subject: [Rd] [R] library(): load library from a specified location
In-Reply-To: <d8ad40b51003301215s23c694bcneed18afea742755b@mail.gmail.com>
References: <4BB1D9F3.8060604@yahoo.de> <4BB1EA1B.901@yahoo.de>
	<9A373E73-1D70-43CB-81FC-63CE141A1B81@auckland.ac.nz>
	<d8ad40b51003301215s23c694bcneed18afea742755b@mail.gmail.com>
Message-ID: <19386.12776.371757.835142@cmath-5.math.ethz.ch>

[ re-diverted to R-devel ]

>>>>> Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>>>>>     on Tue, 30 Mar 2010 20:15:00 +0100 writes:

    > On Tue, Mar 30, 2010 at 7:58 PM, Rolf Turner
    > <r.turner at auckland.ac.nz> wrote:
    >> But ***please*** say ``load *package*'', not ``load
    >> library''. ?The *location* (collection of packages) from
    >> which you wish to load the given package is the
    >> ``library''.

    >  Anyone vote for deprecating the library() function and
    > renaming it use() or requiring require() instead?

I'm voting pro.   


We (R core) had planned to do this, probably about 5 to eight
years ago, then started discussing about possible features of
the new  use()  function, of making a package into an "object"
that you'd want to interrogate, ...
and then probably got tired  ;-)

With the many moons passed, I'd now tend to *not* add features,
but really renamed 'library' to 'use' 
and create a  library() with a deprecation message which then
simply calls use()...
and yes, I'd allow a very exceptionally long deprecation period
of two to five years before making library() defunct.

Martin

    >  I mean, when I go get a book out of our library, I don't
    > say "I'd like to library Case Studies in Spatial Point
    > Process Modelling".  Maybe we should use
    > 'borrow(package)'? Then it might be clear you were getting
    > a package from a library, and that you magically put it
    > back at the end of your R session....

    >  Slightly silly mood this evening



    > Barry

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    > read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From lawrence.michael at gene.com  Mon Apr  5 22:36:51 2010
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Mon, 5 Apr 2010 13:36:51 -0700
Subject: [Rd] Microsoft conspiracy against R?
In-Reply-To: <4BB9D67C.5000500@u-paris10.fr>
References: <4BB9D67C.5000500@u-paris10.fr>
Message-ID: <y2hacbd1aed1004051336i573c527dvb4b3fb4bf4cf313f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100405/bed169be/attachment.pl>

From cgenolin at u-paris10.fr  Tue Apr  6 09:27:44 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Tue, 06 Apr 2010 09:27:44 +0200
Subject: [Rd] Including a file in a Rd file
Message-ID: <4BBAE270.9020409@u-paris10.fr>

Hi all,
Is it possible to include a file in an .Rd file? For example, it might 
be convenient to write a file "author.Rd" and then include it in all the 
Rd file:

\author{
  \include{author.Rd}
}

Christophe


From therneau at mayo.edu  Tue Apr  6 17:44:27 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 06 Apr 2010 10:44:27 -0500
Subject: [Rd] Strange error
Message-ID: <1270568667.32050.17.camel@punchbuggy>

Someone just sent me a data set that causes the lmekin function, part of
the kinship package, to fail.  In chasing it down I get an error I have
never seen before.

fit <- lmekin(icam1 ~ factor(center) + age + factor(sex),
              random= ~1|iid, data=chaidata, varlist=kmat)
Error in Y - fitted : non-numeric argument to binary operator

Add the recover option, and the offending lines are
    fitted <- c(X %*% lfit$coef)  #fitted, on the original scale
    residuals <- Y - fitted

> options(error=recover)
> fit <- lmekin(icam1 ~ factor(center) + age + factor(sex),
+               random= ~1|iid, data=chaidata, varlist=kmat)
Error in Y - fitted : non-numeric argument to binary operator

Enter a frame number, or 0 to exit   

1: lmekin(icam1 ~ factor(center) + age + factor(sex), random = ~1 | iid,
data 

Selection: 
Enter an item from the menu, or 0 to exit
Selection: 1
Called from: eval(expr, envir, enclos)
Browse[1]> dim(X)
[1] 2601    6
Browse[1]> lfit$coef
    (Intercept) factor(center)2 factor(center)3 factor(center)4
age 
    217.9110997      -2.9079576      -0.2147915      -7.8141818
0.5210394 
   factor(sex)2 
      5.1384741 
Browse[1]>  X %*% lfit$coef
`__Deferred_Default_Marker__`

----------------------------------------------

  X is a model.matrix.  If I save the two objects and reload them into a
fresh R session the multiplication works just fine. 

  I haven't modified this code in several years, and it is widely used.
All the C code is shared with coxme. Subsetting the data, or modifing
the fixed effects has no impact on the error.  The same code runs in
Splus.  At the point of error the computations have finished and it is
putting together a result list: all of the results are correct.
Nevertheless, my best (only) guess is memory corruption.

Questions:
  Is this a rational guess?  Any others?
  Can you give any further insight on the error message?

Terry Therneau

sessionInfo()
R version 2.10.0 (2009-10-26) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grDevices datasets  splines   graphics  utils     stats
methods  
[8] base     

other attached packages:
[1] survival_2.35-9 rlocal_1.5.3   
>


From ligges at statistik.tu-dortmund.de  Tue Apr  6 18:14:59 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 06 Apr 2010 18:14:59 +0200
Subject: [Rd] Including a file in a Rd file
In-Reply-To: <4BBAE270.9020409@u-paris10.fr>
References: <4BBAE270.9020409@u-paris10.fr>
Message-ID: <4BBB5E03.7080005@statistik.tu-dortmund.de>



On 06.04.2010 09:27, Christophe Genolini wrote:
> Hi all,
> Is it possible to include a file in an .Rd file? For example, it might
> be convenient to write a file "author.Rd" and then include it in all the
> Rd file:

Not in that way, but you could perhaps arrange by using the new 
technology described in section "2.11 Dynamic pages" of the current 
devel version of the Writing R Extensions manual (untested).

Best wishes,
Uwe Ligges


>
> \author{
> \include{author.Rd}
> }
>
> Christophe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevin.r.coombes at gmail.com  Tue Apr  6 20:27:55 2010
From: kevin.r.coombes at gmail.com (Kevin Coombes)
Date: Tue, 06 Apr 2010 13:27:55 -0500
Subject: [Rd] [R] library(): load library from a specified location
In-Reply-To: <19386.12776.371757.835142@cmath-5.math.ethz.ch>
References: <4BB1D9F3.8060604@yahoo.de>
	<4BB1EA1B.901@yahoo.de>	<9A373E73-1D70-43CB-81FC-63CE141A1B81@auckland.ac.nz>	<d8ad40b51003301215s23c694bcneed18afea742755b@mail.gmail.com>
	<19386.12776.371757.835142@cmath-5.math.ethz.ch>
Message-ID: <4BBB7D2B.6090202@gmail.com>

If we're counting votes, then I vote "no".  And I'd be willing to help 
stuff the ballot box and even volunteer to count the final tallies in 
order to make sure that the "no" side wins.

I understand the logical argument in favor of "use" or "require" or 
"borrow". I am not swayed.

Backwards compatibility matters. A lot. This proposed change breaks an 
unfathomably large amount of existing code.  With zero gain in terms of 
performance or reliability.  It probably does not even help new users 
just learning the language, since they still have to be confused about 
why there are two functions that do almost the same thing in terms of 
loading packages.

Even with a "long deprecation" time, I don't see the value. Just train 
yourself to interpret
 > library(aPackage)
as the syntactic form of the thing in R that has the semantic meaning: 
"go to the library and bring back aPackage".

Curmudgeonly,
    Kevin

Martin Maechler wrote:
> [ re-diverted to R-devel ]
>
>   
>>>>>> Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>>>>>>     on Tue, 30 Mar 2010 20:15:00 +0100 writes:
>>>>>>             
>
>     > On Tue, Mar 30, 2010 at 7:58 PM, Rolf Turner
>     > <r.turner at auckland.ac.nz> wrote:
>     >> But ***please*** say ``load *package*'', not ``load
>     >> library''.  The *location* (collection of packages) from
>     >> which you wish to load the given package is the
>     >> ``library''.
>
>     >  Anyone vote for deprecating the library() function and
>     > renaming it use() or requiring require() instead?
>
> I'm voting pro.   
>
>
> We (R core) had planned to do this, probably about 5 to eight
> years ago, then started discussing about possible features of
> the new  use()  function, of making a package into an "object"
> that you'd want to interrogate, ...
> and then probably got tired  ;-)
>
> With the many moons passed, I'd now tend to *not* add features,
> but really renamed 'library' to 'use' 
> and create a  library() with a deprecation message which then
> simply calls use()...
> and yes, I'd allow a very exceptionally long deprecation period
> of two to five years before making library() defunct.
>
> Martin
>
>     >  I mean, when I go get a book out of our library, I don't
>     > say "I'd like to library Case Studies in Spatial Point
>     > Process Modelling".  Maybe we should use
>     > 'borrow(package)'? Then it might be clear you were getting
>     > a package from a library, and that you magically put it
>     > back at the end of your R session....
>
>     >  Slightly silly mood this evening
>
>
>
>     > Barry
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>     > read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From kjones at fishsciences.net  Wed Apr  7 01:12:07 2010
From: kjones at fishsciences.net (Kris Jones)
Date: Tue, 6 Apr 2010 16:12:07 -0700 (PDT)
Subject: [Rd] GAMs and survival data
In-Reply-To: <852725798.33019.1270595249496.JavaMail.root@mail.fishsciences.net>
Message-ID: <1822822534.33027.1270595527128.JavaMail.root@mail.fishsciences.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100406/9b81f996/attachment.pl>

From cgenolin at u-paris10.fr  Wed Apr  7 10:09:01 2010
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Wed, 07 Apr 2010 10:09:01 +0200
Subject: [Rd] generic '[' for a non-exported class
Message-ID: <4BBC3D9D.2080001@u-paris10.fr>

Hi all,
I define a S4 class 'foo'. I define '[' and '[<-' for it.
I do not want to export foo, so I do not put it in NAMESPACE.
I do not want to export '[' and '[<-' either (since the user can not use 
foo, no raison to give him access to '[' for foo).

But R CMD check does not agree with me and report an error:
Undocumented S4 methods:
  generic '[' and siglist 'foo'
  generic '[<-' and siglist 'foo'


Any solution ?
Christophe


From ggrothendieck at gmail.com  Wed Apr  7 13:31:26 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Apr 2010 07:31:26 -0400
Subject: [Rd] Additions to posting guide
Message-ID: <m2r971536df1004070431q7b650fccu6618ce4167e8cbd5@mail.gmail.com>

One user said he would have found it useful to have textConnection be
described in the posting guide since he was having problems creating a
self-contained post.

I suggest the following section be added:


How to post "commented, minimal, self-contained, reproducible code"
===================================================================

The footer of every message to r-help reminds the poster that postings
should include "commented, minimal, self-contained, reproducible code".

That means that

- responders can copy the code to the clipboard without further modification
  and paste it into their session to reproduce it.

- the data must be included and

- the data should be cut down to the smallest amount that will illustrate
  the problem.


To include the data:

- use dput(mydata).  That will output R source code whose value is the
  indicated data and you can then write:

	mydata <-

  where you place the output of dput to the right of the arrow.

- use textConnection.  An alternative in the case of data frames is to
  read in a text string like this:

  Lines <- "A,B,C
  1,2,x
  3,4,y"
  DF <- read.table(textConnection(Lines), header = TRUE)

  Using textConnection(Lines) in place of a file name causes the input to
  be taken from the indicated string and facilitates self-contained posts.


From ggrothendieck at gmail.com  Wed Apr  7 13:33:18 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Apr 2010 07:33:18 -0400
Subject: [Rd] Additions to posting guide
In-Reply-To: <m2r971536df1004070431q7b650fccu6618ce4167e8cbd5@mail.gmail.com>
References: <m2r971536df1004070431q7b650fccu6618ce4167e8cbd5@mail.gmail.com>
Message-ID: <u2p971536df1004070433y11e0166ar9cb7f7f949bf6d5a@mail.gmail.com>

e-letter, who had suggested that something about textConnection be
added, also suggested that warning against posting code that first
wipes out all variables in the workspace.

On Wed, Apr 7, 2010 at 7:31 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> One user said he would have found it useful to have textConnection be
> described in the posting guide since he was having problems creating a
> self-contained post.
>
> I suggest the following section be added:
>
>
> How to post "commented, minimal, self-contained, reproducible code"
> ===================================================================
>
> The footer of every message to r-help reminds the poster that postings
> should include "commented, minimal, self-contained, reproducible code".
>
> That means that
>
> - responders can copy the code to the clipboard without further modification
> ?and paste it into their session to reproduce it.
>
> - the data must be included and
>
> - the data should be cut down to the smallest amount that will illustrate
> ?the problem.
>
>
> To include the data:
>
> - use dput(mydata). ?That will output R source code whose value is the
> ?indicated data and you can then write:
>
> ? ? ? ?mydata <-
>
> ?where you place the output of dput to the right of the arrow.
>
> - use textConnection. ?An alternative in the case of data frames is to
> ?read in a text string like this:
>
> ?Lines <- "A,B,C
> ?1,2,x
> ?3,4,y"
> ?DF <- read.table(textConnection(Lines), header = TRUE)
>
> ?Using textConnection(Lines) in place of a file name causes the input to
> ?be taken from the indicated string and facilitates self-contained posts.
>


From seth at userprimary.net  Wed Apr  7 18:13:06 2010
From: seth at userprimary.net (Seth Falcon)
Date: Wed, 07 Apr 2010 09:13:06 -0700
Subject: [Rd] generic '[' for a non-exported class
In-Reply-To: <4BBC3D9D.2080001@u-paris10.fr>
References: <4BBC3D9D.2080001@u-paris10.fr>
Message-ID: <4BBCAF12.1030303@userprimary.net>

On 4/7/10 1:09 AM, Christophe Genolini wrote:
> Hi all,
> I define a S4 class 'foo'. I define '[' and '[<-' for it.
> I do not want to export foo, so I do not put it in NAMESPACE.
> I do not want to export '[' and '[<-' either (since the user can not use
> foo, no raison to give him access to '[' for foo).
>
> But R CMD check does not agree with me and report an error:
> Undocumented S4 methods:
> generic '[' and siglist 'foo'
> generic '[<-' and siglist 'foo'
>
>
> Any solution ?

You can document these on an internal API Rd page.  Create an Rd file 
like yourPkg-internal-api.Rd and add the appropriate \alias{} lines to it.

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From hb at stat.berkeley.edu  Wed Apr  7 18:42:18 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 7 Apr 2010 18:42:18 +0200
Subject: [Rd] generic '[' for a non-exported class
In-Reply-To: <4BBCAF12.1030303@userprimary.net>
References: <4BBC3D9D.2080001@u-paris10.fr> <4BBCAF12.1030303@userprimary.net>
Message-ID: <x2v59d7961d1004070942h2122eeb4nc16d4bf36c090551@mail.gmail.com>

On Wed, Apr 7, 2010 at 6:13 PM, Seth Falcon <seth at userprimary.net> wrote:
> On 4/7/10 1:09 AM, Christophe Genolini wrote:
>>
>> Hi all,
>> I define a S4 class 'foo'. I define '[' and '[<-' for it.
>> I do not want to export foo, so I do not put it in NAMESPACE.
>> I do not want to export '[' and '[<-' either (since the user can not use
>> foo, no raison to give him access to '[' for foo).
>>
>> But R CMD check does not agree with me and report an error:
>> Undocumented S4 methods:
>> generic '[' and siglist 'foo'
>> generic '[<-' and siglist 'foo'
>>
>>
>> Any solution ?
>
> You can document these on an internal API Rd page. ?Create an Rd file like
> yourPkg-internal-api.Rd and add the appropriate \alias{} lines to it.

...with Rd \keyword{internal} on that Rd page (so it does not show up
on the Rd help index page).

/Henrik

>
> + seth
>
> --
> Seth Falcon | @sfalcon | http://userprimary.net/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From berwin at maths.uwa.edu.au  Thu Apr  8 12:32:35 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 8 Apr 2010 18:32:35 +0800
Subject: [Rd] LOGICAL arguments in FORTRAN code
Message-ID: <20100408183235.4185aa65@bossiaea>

G'day all,

I just took over maintenance of the quadprog package from Kurt Hornik
and noticed that one of the FORTRAN routines has an argument that is
declared to be a LOGICAL.  The R code that calls this routine (via
the .Fortran interface) passes the argument down wrapped in a call to
as.logical().

This was fine (and as documented) under S-Plus 3.4, for which this code
was originally developed.  However, as far as I know, in R objects of
storage mode logical were always supposed to be passed to FORTRAN
arguments of type INTEGER; and that is what the current "Writing R
extension manual states".

Thus, given that the port of quadprog existed for quite some time, I
am wondering whether it is o.k. to pass R objects with storage mode
logical into FORTRAN code to arguments declared as LOGICAL?  Or should
the FORTRAN code be corrected to declare the argument in question as
INTEGER?   

Cheers,

	Berwin


From ripley at stats.ox.ac.uk  Thu Apr  8 13:40:45 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Apr 2010 12:40:45 +0100 (BST)
Subject: [Rd] LOGICAL arguments in FORTRAN code
In-Reply-To: <20100408183235.4185aa65@bossiaea>
References: <20100408183235.4185aa65@bossiaea>
Message-ID: <alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>

On Thu, 8 Apr 2010, Berwin A Turlach wrote:

> G'day all,
>
> I just took over maintenance of the quadprog package from Kurt Hornik
> and noticed that one of the FORTRAN routines has an argument that is
> declared to be a LOGICAL.  The R code that calls this routine (via
> the .Fortran interface) passes the argument down wrapped in a call to
> as.logical().
>
> This was fine (and as documented) under S-Plus 3.4, for which this code
> was originally developed.  However, as far as I know, in R objects of
> storage mode logical were always supposed to be passed to FORTRAN
> arguments of type INTEGER; and that is what the current "Writing R
> extension manual states".
>
> Thus, given that the port of quadprog existed for quite some time, I
> am wondering whether it is o.k. to pass R objects with storage mode
> logical into FORTRAN code to arguments declared as LOGICAL?  Or should
> the FORTRAN code be corrected to declare the argument in question as
> INTEGER?

The second to be safe.  This is not a question on the S-PLUS/R side 
but on the Fortran side.  A Fortran compiler may or may not use the 
same storage for integer and logical (and it may depend on compiler 
flags, although not on the compilers I just checked, gfortran and 
SunStudio f95).  S-PLUS ran on only a few platforms and with specified 
compilers.

>
> Cheers,
>
> 	Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Thu Apr  8 15:11:32 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 8 Apr 2010 21:11:32 +0800
Subject: [Rd] LOGICAL arguments in FORTRAN code
In-Reply-To: <alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>
References: <20100408183235.4185aa65@bossiaea>
	<alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>
Message-ID: <20100408211132.7a2ca4fd@absentia>

G'day Brian, 



On Thu, 8 Apr 2010 12:40:45 +0100 (BST)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Thu, 8 Apr 2010, Berwin A Turlach wrote:
[...]
> > Thus, given that the port of quadprog existed for quite some time, I
> > am wondering whether it is o.k. to pass R objects with storage mode
> > logical into FORTRAN code to arguments declared as LOGICAL?  Or
> > should the FORTRAN code be corrected to declare the argument in
> > question as INTEGER?
> 
> The second to be safe.  [...]

Thanks for the quick and informative response.  I will make the
necessary changes.

BTW, can I assume that if R passes down TRUE to the FORTRAN routine the
corresponding integer argument will be set to 1, and that it will be
set to zero if FALSE is passed down?  Likewise, can I assume that if at
the end of the FORTRAN routine the integer holds a value of zero, then
FALSE is passed back to R and if the integer holds any other value then
TRUE is passed back?  I don't remember ever reading any documentation
about this; and most documentation that I would search is not at hand
but back on the bookshelves of my office.....

Cheers,
	
	Berwin


From ripley at stats.ox.ac.uk  Thu Apr  8 15:22:36 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Apr 2010 14:22:36 +0100 (BST)
Subject: [Rd] LOGICAL arguments in FORTRAN code
In-Reply-To: <20100408211132.7a2ca4fd@absentia>
References: <20100408183235.4185aa65@bossiaea>
	<alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>
	<20100408211132.7a2ca4fd@absentia>
Message-ID: <alpine.LFD.2.00.1004081415280.6379@gannet.stats.ox.ac.uk>

On Thu, 8 Apr 2010, Berwin A Turlach wrote:

> G'day Brian,
>
>
>
> On Thu, 8 Apr 2010 12:40:45 +0100 (BST)
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On Thu, 8 Apr 2010, Berwin A Turlach wrote:
> [...]
>>> Thus, given that the port of quadprog existed for quite some time, I
>>> am wondering whether it is o.k. to pass R objects with storage mode
>>> logical into FORTRAN code to arguments declared as LOGICAL?  Or
>>> should the FORTRAN code be corrected to declare the argument in
>>> question as INTEGER?
>>
>> The second to be safe.  [...]
>
> Thanks for the quick and informative response.  I will make the
> necessary changes.
>
> BTW, can I assume that if R passes down TRUE to the FORTRAN routine the
> corresponding integer argument will be set to 1, and that it will be
> set to zero if FALSE is passed down?  Likewise, can I assume that if at
> the end of the FORTRAN routine the integer holds a value of zero, then
> FALSE is passed back to R and if the integer holds any other value then
> TRUE is passed back?  I don't remember ever reading any documentation
> about this; and most documentation that I would search is not at hand
> but back on the bookshelves of my office.....

NA_INTEGER is a possible value in both directions.  So R may send 0, 1 
or (if NAOK=TRUE) -2^31, and will copy back any value (but as 
a logical in R, it is intended that any value other than 0 and 
NA_LOGICAL is true).

Brian Ripley

>
> Cheers,
>
> 	Berwin
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Thu Apr  8 18:01:18 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 8 Apr 2010 09:01:18 -0700
Subject: [Rd] LOGICAL arguments in FORTRAN code
In-Reply-To: <alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>
References: <20100408183235.4185aa65@bossiaea>
	<alpine.LFD.2.00.1004081231530.21500@gannet.stats.ox.ac.uk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70002C3499C@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> Sent: Thursday, April 08, 2010 4:41 AM
> To: Berwin A Turlach
> Cc: r-devel
> Subject: Re: [Rd] LOGICAL arguments in FORTRAN code
> 
> On Thu, 8 Apr 2010, Berwin A Turlach wrote:
> 
> > G'day all,
> >
> > I just took over maintenance of the quadprog package from 
> Kurt Hornik
> > and noticed that one of the FORTRAN routines has an argument that is
> > declared to be a LOGICAL.  The R code that calls this routine (via
> > the .Fortran interface) passes the argument down wrapped in 
> a call to
> > as.logical().
> >
> > This was fine (and as documented) under S-Plus 3.4, for 
> which this code
> > was originally developed.  However, as far as I know, in R 
> objects of
> > storage mode logical were always supposed to be passed to FORTRAN
> > arguments of type INTEGER; and that is what the current "Writing R
> > extension manual states".
> >
> > Thus, given that the port of quadprog existed for quite some time, I
> > am wondering whether it is o.k. to pass R objects with storage mode
> > logical into FORTRAN code to arguments declared as LOGICAL? 
>  Or should
> > the FORTRAN code be corrected to declare the argument in question as
> > INTEGER?
> 
> The second to be safe.  This is not a question on the S-PLUS/R side 
> but on the Fortran side.  A Fortran compiler may or may not use the 
> same storage for integer and logical (and it may depend on compiler 
> flags, although not on the compilers I just checked, gfortran and 
> SunStudio f95).  S-PLUS ran on only a few platforms and with 
> specified 
> compilers.

I agree that avoiding LOGICAL's in arguments to Fortran
subroutines is a good idea.  Fortran compilers are prone
to do weird things when encoding LOGICAL values.  E.g.,
I vaguely recall that Apollo's compiler (c. 1990) encoded
.true. as 0 (all zeros) and .false. as -1 (all 1's) and
HP's compiler of the same era looked only at the 8th bit
from the left (no matter if you had a 1, 2, or 4 byte LOGICAL),
0 was .false. and 1 was .true.  S+'s .Fortran() took care of
these but you couldn't safely call Fortran code with such arguments
from C.   Avoid character arguments for similar reasons.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> 
> >
> > Cheers,
> >
> > 	Berwin
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From bolker at ufl.edu  Thu Apr  8 21:52:57 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 8 Apr 2010 19:52:57 +0000 (UTC)
Subject: [Rd] GAMs and survival data
References: <852725798.33019.1270595249496.JavaMail.root@mail.fishsciences.net>
	<1822822534.33027.1270595527128.JavaMail.root@mail.fishsciences.net>
Message-ID: <loom.20100408T214747-8@post.gmane.org>

Kris Jones <kjones <at> fishsciences.net> writes:

Quick answer: this question is inappropriate for the r devel*pment
list (intended for questions about code development, technical questions,
etc.).  The main r help list, or the r-sig-ecology list, would be better.

  It is true that GAMs are more flexible for nonlinear relationships,
although simple polynomial (e.g. quadratic) models in GLMS can be 
OK sometimes.

  Proportion data without denominators are not appropriate for
binomial modeling (where you have to have integer numbers surviving
out of a known integer number exposed).  You have a few choices,
none of which is quite as easy as binomial modeling -- beta regression,
transforming data (although this can mess up the shapes of your
responses to your predictors), modeling heteroscedasticity explicitly
(with family="quasi" in GLM/GAM or via weights argument in gls/gnls).

* Question 2: For this type of model (GAM), is there a simple way 
* of constructing an equation for the model
* (e.g., to come up with predicted values).

  You probably want to use the predict() functions provided with
mgcv/GAM.  It wouldn't hurt to read Simon Wood's book, either.

  Ben Bolker


From ronggui.huang at gmail.com  Fri Apr  9 09:59:17 2010
From: ronggui.huang at gmail.com (Wincent)
Date: Fri, 9 Apr 2010 15:59:17 +0800
Subject: [Rd] How to enable core dump?
Message-ID: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100409/dfc92614/attachment.pl>

From martin.becker at mx.uni-saarland.de  Fri Apr  9 10:36:45 2010
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Fri, 09 Apr 2010 10:36:45 +0200
Subject: [Rd] hist.default()$density
In-Reply-To: <4BB21610.90407@mx.uni-saarland.de>
References: <4BB21610.90407@mx.uni-saarland.de>
Message-ID: <4BBEE71D.1000500@mx.uni-saarland.de>

Dear developers,

since running 'example(hist)' produces
...
hist> sum(r$density * diff(r$breaks)) # == 1
[1] 0.9999999
...
I suppose that the current behaviour of hist() is not as intended (and 
documented).
So, please find attached (and inline below) a (trivial) patch for 
hist.default().

Best wishes
  Martin


Index: src/library/graphics/R/hist.R
===================================================================
--- src/library/graphics/R/hist.R    (revision 51652)
+++ src/library/graphics/R/hist.R    (working copy)
@@ -111,7 +111,7 @@
     stop("negative 'counts'. Internal Error in C-code for \"bincount\"")
     if (sum(counts) < n)
     stop("some 'x' not counted; maybe 'breaks' do not span range of 'x'")
-    dens <- counts/(n*h)
+    dens <- counts/(n*diff(breaks))
     mids <- 0.5 * (breaks[-1L] + breaks[-nB])
     r <- structure(list(breaks = breaks, counts = counts,
             intensities = dens,



Martin Becker wrote:
> Dear developers,
>
> the current implementation of hist.default() calculates 'density' (and 
> 'intensities') as
>  dens <- counts/(n*h)
> where h has been calculated before as
>  h <- diff(fuzzybreaks)
> which results in 'fuzzy' values for the density, see e.g.
>
> > tmp <- hist(1:10,breaks=c(-2.5,2.5,7.5,12.5),plot=FALSE)
> > print(tmp$density,digits=15)
> [1] 0.0399999920000016 0.1000000000000000 0.0600000000000000
>
> Since hist.default()$breaks are not the fuzzy breaks used for the 
> calculation of dens, the sum of the bins' area is significantly 
> different from 1 in many cases, see e.g.
>
> > print(sum(tmp$density*diff(tmp$breaks)),digits=15)
> [1] 0.999999960000008
>
> Is this intended, or should the calculation of dens read
>  dens <- counts/(n*diff(breaks))
> instead (or should hist.default()$breaks return the fuzzy breaks)?
>
> Best wishes
>   Martin
>
>


-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 217
66123 Saarbruecken
Germany

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: hist.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100409/d0c95a61/attachment.pl>

From pdalgd at gmail.com  Fri Apr  9 11:26:00 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 9 Apr 2010 11:26:00 +0200
Subject: [Rd] How to enable core dump?
In-Reply-To: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com>
References: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com>
Message-ID: <04169539-CB16-46F6-B50B-9E726487B992@gmail.com>


On Apr 9, 2010, at 9:59 AM, Wincent wrote:

> Dear all, I encountered a core dump like this,
> 
> (R:24072): Gdk-CRITICAL **: gdk_drawable_get_display: assertion
> `GDK_IS_DRAWABLE (drawable)' failed
> 
> *** caught segfault ***
> address 0x78, cause 'memory not mapped'
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 1
> aborting ...
> Segmentation fault
> 
> When I select 1, there is still no saved core dump. I guess because it is
> not enabled. May I ask how to enable this option? Thanks.

You need to set the resource limits before starting R.

Exactly how depends on your operating system (and you didn't tell), and the shell. With bash on unix-alikes, try "help ulimit" which will point you at "ulimit -c 20000" for max 20MB core files. 

> -- 
> Wincent Rong-gui HUANG
> Doctoral Candidate
> Dept of Public and Social Administration
> City University of Hong Kong
> http://asrr.r-forge.r-project.org/rghuang.html
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Fri Apr  9 11:28:17 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Apr 2010 10:28:17 +0100 (BST)
Subject: [Rd] How to enable core dump?
In-Reply-To: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com>
References: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1004091020440.21199@localhost>

On Fri, 9 Apr 2010, Wincent wrote:

> Dear all, I encountered a core dump like this,

Or it seems, *no* core dump!

> (R:24072): Gdk-CRITICAL **: gdk_drawable_get_display: assertion
> `GDK_IS_DRAWABLE (drawable)' failed
>
> *** caught segfault ***
> address 0x78, cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 1
> aborting ...
> Segmentation fault
>
> When I select 1, there is still no saved core dump. I guess because it is
> not enabled. May I ask how to enable this option? Thanks.

What are your OS and shell (R has not disabled it, but your OS 
probably has)?  The usual way to disable this is to set the limit on 
the coredumpsize to 0, and this seems a common default these days.

In csh, use e.g. limit coredumpsize 2000, in bash use e.g. ulimit -c 2000:
on my system the limits are in kbytes.

>
> -- 
> Wincent Rong-gui HUANG
> Doctoral Candidate
> Dept of Public and Social Administration
> City University of Hong Kong
> http://asrr.r-forge.r-project.org/rghuang.html
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ronggui.huang at gmail.com  Fri Apr  9 11:53:12 2010
From: ronggui.huang at gmail.com (Wincent)
Date: Fri, 9 Apr 2010 17:53:12 +0800
Subject: [Rd] How to enable core dump?
In-Reply-To: <alpine.LFD.2.00.1004091020440.21199@localhost>
References: <u2o38b9f0351004090059z26a104f8u776e85cfd43d7994@mail.gmail.com> 
	<alpine.LFD.2.00.1004091020440.21199@localhost>
Message-ID: <t2y38b9f0351004090253o5595576bm28f61827121f6fd2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100409/912cae4e/attachment.pl>

From danelliottster at gmail.com  Fri Apr  9 16:05:51 2010
From: danelliottster at gmail.com (Daniel Elliott)
Date: Fri, 9 Apr 2010 09:05:51 -0500
Subject: [Rd] Line breaks in mathematical formulae in Rd files
Message-ID: <h2xf08455591004090705i5bb31864mf19cfd4192362898@mail.gmail.com>

Hello,

I would like to implement the feature request described here:
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=13287.  I think
this is a very worthwhile feature.

However, I need just a little push in the right direction.  When I
added either a new command or change the old one to use eqnarray as
proposed, the "\\" newline characters were not properly passed to
latex - even when I escaped them both with something like "\\\\".

What is happening behind the scenes that I am not understanding that
is disallowing me from making this small change so I can use "\\" with
an equation array?

Thank you, very much, for any assistance.

- dan


From danelliottster at gmail.com  Fri Apr  9 16:12:56 2010
From: danelliottster at gmail.com (Daniel Elliott)
Date: Fri, 9 Apr 2010 09:12:56 -0500
Subject: [Rd] Line breaks in mathematical formulae in Rd files
In-Reply-To: <h2xf08455591004090705i5bb31864mf19cfd4192362898@mail.gmail.com>
References: <h2xf08455591004090705i5bb31864mf19cfd4192362898@mail.gmail.com>
Message-ID: <z2xf08455591004090712rdf7c57b9jf2cff84f1db051ad@mail.gmail.com>

Ok, this link to the feature request works:

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=13287


On Fri, Apr 9, 2010 at 9:05 AM, Daniel Elliott <danelliottster at gmail.com> wrote:
> Hello,
>
> I would like to implement the feature request described here:
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=13287. ?I think
> this is a very worthwhile feature.
>
> However, I need just a little push in the right direction. ?When I
> added either a new command or change the old one to use eqnarray as
> proposed, the "\\" newline characters were not properly passed to
> latex - even when I escaped them both with something like "\\\\".
>
> What is happening behind the scenes that I am not understanding that
> is disallowing me from making this small change so I can use "\\" with
> an equation array?
>
> Thank you, very much, for any assistance.
>
> - dan
>


From bolker at ufl.edu  Fri Apr  9 20:13:03 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 09 Apr 2010 14:13:03 -0400
Subject: [Rd] possible bug in tools:::getRemotePkgDepends ?
Message-ID: <4BBF6E2F.6040603@ufl.edu>

  Executive summary: getRemotePkgDepends seems to use the wrong default
string to (try to) download the CRAN package information.
========================

  Someone asked me about the behavior of tools::pkgDepends() , and in
investigating I discovered the following:

## tools:::getRemotePkgDepends
## undebug(tools:::getRemotePkgDepends)

tools::pkgDepends("GDD")
## Error in tools::pkgDepends("GDD") : package 'GDD' was not found
## (correct!)

tools::pkgDepends("GDD",local=FALSE)
## Warning: unable to access index for
##  repository http://mira.sunsite.utk.edu/CRAN
## ** should be OK, my settings work for update packages

## descending into the problem:

tools:::getRemotePkgDepends("GDD")  ## same warning
tools:::getRemotePkgDepends("GDD",contriburl=NULL) ## OK!
tools:::getRemotePkgDepends("GDD",

contriburl=utils::contrib.url(getOption("repos")))
## OK

I think the problem is that getRemotePkgDepends has
default contriburl = getOption("repos")
which returns the 'head' of the repository:

> getOption("repos")
                              CRAN
"http://mira.sunsite.utk.edu/CRAN"

rather than

contrib.url(getOption("repos"))
[1] "http://mira.sunsite.utk.edu/CRAN/src/contrib"

  Is this (as it seems to me) a bug?  Should I report it as such?



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 261 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100409/f524370f/attachment.bin>

From xieyihui at gmail.com  Sat Apr 10 05:25:21 2010
From: xieyihui at gmail.com (Yihui Xie)
Date: Fri, 9 Apr 2010 22:25:21 -0500
Subject: [Rd] Line breaks in mathematical formulae in Rd files
In-Reply-To: <h2xf08455591004090705i5bb31864mf19cfd4192362898@mail.gmail.com>
References: <h2xf08455591004090705i5bb31864mf19cfd4192362898@mail.gmail.com>
Message-ID: <t2m89b6b8c91004092025l6eedb85dn8a389db51ee27c92@mail.gmail.com>

Hi Dan,

With R 2.10.1 and MikTeX 2.8, the method I proposed still works for
me. You don't need to escape \ there: \\ is the right line break.

For the time being, I guess you have to write more than one \deqn{}'s
if you have a multiple-line equation.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-6609 Web: http://yihui.name
Department of Statistics, Iowa State University
3211 Snedecor Hall, Ames, IA



On Fri, Apr 9, 2010 at 9:05 AM, Daniel Elliott <danelliottster at gmail.com> wrote:
> Hello,
>
> I would like to implement the feature request described here:
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=13287. ?I think
> this is a very worthwhile feature.
>
> However, I need just a little push in the right direction. ?When I
> added either a new command or change the old one to use eqnarray as
> proposed, the "\\" newline characters were not properly passed to
> latex - even when I escaped them both with something like "\\\\".
>
> What is happening behind the scenes that I am not understanding that
> is disallowing me from making this small change so I can use "\\" with
> an equation array?
>
> Thank you, very much, for any assistance.
>
> - dan
>


From info at aghmed.fsnet.co.uk  Mon Apr 12 16:51:16 2010
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 12 Apr 2010 15:51:16 +0100
Subject: [Rd] R CMD check tells me 'no visible binding for global variable ',
 what does it mean?
Message-ID: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>

When I run R CMD check on a package I have recently started work on I 
get the following:

* checking R code for possible problems ... NOTE
addlinear: no visible binding for global variable 'x'

I appreciate that this is only a NOTE and so I assume is R's 
equivalent of 'This is perfectly legal but I wonder whether it is 
really what you intended' but I would like to understand it.

In the relevant function addlinear the following function is defined locally:

    orfun <- function(x, oddsratio) {1/(1+1/(oddsratio * (x/(1-x))))}

and then used later in curve

       curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)

These are the only occurrences of 'x'.

Is it just telling me that I have never assigned a value to x? Or is 
it more sinister than that? As far as I can tell the function does 
what I intended.


Michael Dewey
http://www.aghmed.fsnet.co.uk


From murdoch at stats.uwo.ca  Mon Apr 12 17:08:12 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 12 Apr 2010 11:08:12 -0400
Subject: [Rd] R CMD check tells me 'no visible binding for global
 variable ', what does it mean?
In-Reply-To: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
Message-ID: <4BC3375C.4060007@stats.uwo.ca>

On 12/04/2010 10:51 AM, Michael Dewey wrote:
> When I run R CMD check on a package I have recently started work on I 
> get the following:
>
> * checking R code for possible problems ... NOTE
> addlinear: no visible binding for global variable 'x'
>
> I appreciate that this is only a NOTE and so I assume is R's 
> equivalent of 'This is perfectly legal but I wonder whether it is 
> really what you intended' but I would like to understand it.
>
> In the relevant function addlinear the following function is defined locally:
>
>     orfun <- function(x, oddsratio) {1/(1+1/(oddsratio * (x/(1-x))))}
>
> and then used later in curve
>
>        curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>
> These are the only occurrences of 'x'.
>
> Is it just telling me that I have never assigned a value to x? Or is 
> it more sinister than that? As far as I can tell the function does 
> what I intended.

The curve() function evaluates the first argument in a strange way, and 
this confuses the code checking.  (The variable name "x" is special to 
curve().)

I think you can avoid the warning by rewriting that call to curve() as

curve(function(x) orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)

Duncan Murdoch


From hb at stat.berkeley.edu  Mon Apr 12 17:24:00 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 12 Apr 2010 17:24:00 +0200
Subject: [Rd] R CMD check tells me 'no visible binding for global
	variable ', what does it mean?
In-Reply-To: <4BC3375C.4060007@stats.uwo.ca>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
	<4BC3375C.4060007@stats.uwo.ca>
Message-ID: <m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>

On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/04/2010 10:51 AM, Michael Dewey wrote:
>>
>> When I run R CMD check on a package I have recently started work on I get
>> the following:
>>
>> * checking R code for possible problems ... NOTE
>> addlinear: no visible binding for global variable 'x'
>>
>> I appreciate that this is only a NOTE and so I assume is R's equivalent of
>> 'This is perfectly legal but I wonder whether it is really what you
>> intended' but I would like to understand it.
>>
>> In the relevant function addlinear the following function is defined
>> locally:
>>
>> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio * (x/(1-x))))}
>>
>> and then used later in curve
>>
>> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>>
>> These are the only occurrences of 'x'.
>>
>> Is it just telling me that I have never assigned a value to x? Or is it
>> more sinister than that? As far as I can tell the function does what I
>> intended.
>
> The curve() function evaluates the first argument in a strange way, and this
> confuses the code checking. ?(The variable name "x" is special to curve().)
>
> I think you can avoid the warning by rewriting that call to curve() as
>
> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to = 0.999, add =
> TRUE)

...or

x <- NULL; rm(x); # Dummy to trick R CMD check
curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)

/Henrik

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Mon Apr 12 19:27:06 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Apr 2010 10:27:06 -0700
Subject: [Rd] R CMD check tells me 'no visible binding for
	globalvariable ', what does it mean?
In-Reply-To: <m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk><4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
> Sent: Monday, April 12, 2010 8:24 AM
> To: Duncan Murdoch
> Cc: r-devel; Michael Dewey
> Subject: Re: [Rd] R CMD check tells me 'no visible binding 
> for globalvariable ', what does it mean?
> 
> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch 
> <murdoch at stats.uwo.ca> wrote:
> > On 12/04/2010 10:51 AM, Michael Dewey wrote:
> >>
> >> When I run R CMD check on a package I have recently 
> started work on I get
> >> the following:
> >>
> >> * checking R code for possible problems ... NOTE
> >> addlinear: no visible binding for global variable 'x'
> >>
> >> I appreciate that this is only a NOTE and so I assume is 
> R's equivalent of
> >> 'This is perfectly legal but I wonder whether it is really what you
> >> intended' but I would like to understand it.
> >>
> >> In the relevant function addlinear the following function 
> is defined
> >> locally:
> >>
> >> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio * 
> (x/(1-x))))}
> >>
> >> and then used later in curve
> >>
> >> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to = 
> 0.999, add = TRUE)
> >>
> >> These are the only occurrences of 'x'.
> >>
> >> Is it just telling me that I have never assigned a value 
> to x? Or is it
> >> more sinister than that? As far as I can tell the function 
> does what I
> >> intended.
> >
> > The curve() function evaluates the first argument in a 
> strange way, and this
> > confuses the code checking. ?(The variable name "x" is 
> special to curve().)
> >
> > I think you can avoid the warning by rewriting that call to 
> curve() as
> >
> > curve(function(x) orfun(x, exp(estimate)), from = 0.001, to 
> = 0.999, add =
> > TRUE)
> 
> ...or
> 
> x <- NULL; rm(x); # Dummy to trick R CMD check
> curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)

Or we could come up with a scheme to telling the usage checking functions
in codetools that some some or all arguments of certain functions
are evaluated in odd ways so it should not check them.  E.g.,
   irregularUsage(curve, expr)
   irregularUsage(lm, subset, formula) # subset and formula arguments of lm
   irregularUsage(expression, ...) # ... arguments to expression
Perhaps one could add such indications to the NAMESPACE file
or to a new file in a package.  The former is kludgy but the
latter requires changes to the packaging system.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  


> 
> /Henrik
> 
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From chuck at sharpsteen.net  Tue Apr 13 04:11:23 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Mon, 12 Apr 2010 18:11:23 -0800 (PST)
Subject: [Rd] Getting started with .C
In-Reply-To: <1271121727964-1837912.post@n4.nabble.com>
References: <1271121727964-1837912.post@n4.nabble.com>
Message-ID: <1271124683916-1837936.post@n4.nabble.com>



Jeff Brown wrote:
> 
> Hi,
> 
> I'm trying to learn to use .C, which lets one invoke compiled C code from
> within R.  To do that, one has to first get the C code into R as a shared
> object, which (I think) means first compiling it (with COMPILE or SHLIB)
> and then loading it (with dyn.load()).  
> 

I would suggest taking it a step further and building an R package to hold
your compiled code.  The pros are:

  *  It keeps the R wrapper scripts and other things you will end up
creating packaged together with your code.

  *  It handles compilation automagically during installation.

  *  It handles loading the dylib for you.

The only con I can think of is:

  *  It takes ~2 extra minutes of your time to set up.  But compared to
other languages I have used this is a ridiculously small price to pay for
the portability and organization offered by packages.

I wrote a post that goes through step-by-step how to do this for the .Call()
interface, including example code.  You can find it at:

 
http://n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.html#a1580423



In "Writing R Extensions", p. 79, they give the following example of a C
program for convolution of two vectors.  (The details aren't important; it's
just a function that does something to some stuff.)

void convolve (double *a, int *na, double *b, int *nb, double *ab) {
	int i, j, nab = *na + *nb - 1;
	for(i = 0; i < nab; i++)
		ab[i] = 0.0;
	for(i = 0; i < *na; i++)
		for(j = 0; j < *nb; j++)
			ab[i + j] += a[i] * b[j]
}



Jeff Brown wrote:
> 
> The document suggests calling it from R like this (again the details
> aren't important):
> 
> conv <- function(a, b) 
> 	.C("convolve",
> 		as.double(a), 
> 		as.integer(length(a)), 
> 		as.double(b), 
> 		as.integer(length(b)), 
> 		ab = double(length(a) + length(b) - 1))$ab
> 
> I wrote a file, "convolve.c", with nothing but the above C code in it.  I
> can't figure out how to compile it.  I don't understand the syntax (no
> parentheses?) and I always get the same information-free error message:
> 
>> list.files()
> [1] "AER"        "convolve.c" "sendmailR" 
>> R CMD SHLIB "compile.c"
> Error: syntax error
>> COMPILE "compile.c"
> Error: syntax error
>> R CMD SHLIB "compile"
> Error: syntax error
>> COMPILE "compile"
> Error: syntax error
>> R CMD SHLIB compile.c
> Error: syntax error
>> COMPILE compile.c
> Error: syntax error
>> R CMD SHLIB compile
> Error: syntax error
>> COMPILE compile
> Error: syntax error
> 
> I'm using an Intel MacBook Pro running Leopard.  At a console, typing "gcc
> --version" yields 4.2.1.  I know I'm supposed to be using version 4.2; I
> thought 4.2.1 would qualify, but please let me know if I'm wrong about
> that.
> 
> For guidance I've been relying on "Writing R Extensions", "R Installatino
> and Administration", the "R for Mac OS X Developer's Page", and the
> built-in help.  Please let me know if there are other important resources
> I've missed.
> 
> Many thanks,
> Jeff
> 

All R CMD commands must be executed at the command line- i.e. in a Windows
CMD shell or Unix/Linux bash shell.  They are not meant for use inside the R
interpreter.

Hope this helps!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://n4.nabble.com/Getting-started-with-C-tp1837912p1837936.html
Sent from the R devel mailing list archive at Nabble.com.


From edd at debian.org  Tue Apr 13 04:47:43 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 12 Apr 2010 21:47:43 -0500
Subject: [Rd] Getting started with .C
In-Reply-To: <1271124683916-1837936.post@n4.nabble.com>
References: <1271121727964-1837912.post@n4.nabble.com>
	<1271124683916-1837936.post@n4.nabble.com>
Message-ID: <19395.56143.11708.302649@ron.nulle.part>


On 12 April 2010 at 18:11, Sharpie wrote:
| Jeff Brown wrote:
| > I'm trying to learn to use .C, which lets one invoke compiled C code from
| > within R.  To do that, one has to first get the C code into R as a shared
| > object, which (I think) means first compiling it (with COMPILE or SHLIB)
| > and then loading it (with dyn.load()).  
| > 
| 
| I would suggest taking it a step further and building an R package to hold
| your compiled code.  The pros are:
| 
|   *  It keeps the R wrapper scripts and other things you will end up
| creating packaged together with your code.
| 
|   *  It handles compilation automagically during installation.
| 
|   *  It handles loading the dylib for you.

All good reasone, but see below for an even easier solution to get going.
 
| The only con I can think of is:
| 
|   *  It takes ~2 extra minutes of your time to set up.  But compared to
| other languages I have used this is a ridiculously small price to pay for
| the portability and organization offered by packages.
| 
| I wrote a post that goes through step-by-step how to do this for the .Call()
| interface, including example code.  You can find it at:
| 
|  
| http://n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.html#a1580423
| 
| 
| 
| In "Writing R Extensions", p. 79, they give the following example of a C
| program for convolution of two vectors.  (The details aren't important; it's
| just a function that does something to some stuff.)
| 
| void convolve (double *a, int *na, double *b, int *nb, double *ab) {
| 	int i, j, nab = *na + *nb - 1;
| 	for(i = 0; i < nab; i++)
| 		ab[i] = 0.0;
| 	for(i = 0; i < *na; i++)
| 		for(j = 0; j < *nb; j++)
| 			ab[i + j] += a[i] * b[j]
| }

And all this is even easier if you use the excellent inline package. No
Makefiles, no linking, no loading, it all "just works" on all three major
platforms:

 - define the code you want in a variable, here 'code'
   this does not include the function header

 - define the function signature

 - call the 'cfunction' from package inline to compile, link and load the 
   generated function

 - use it!

Here is a live example:

  R> library(inline)       # load inline
  R> code <- "int i, j, nab = *na + *nb - 1;
  +    for(i = 0; i < nab; i++)
  +      ab[i] = 0.0;
  +    for(i = 0; i < *na; i++) {
  +      for(j = 0; j < *nb; j++)
  +            ab[i + j] += a[i] * b[j];
  +          }"
  R> fun <- cfunction(signature(a="numeric", na="numeric", b="numeric", nb="numeric", ab="numeric"),
  +                  code, language="C", convention=".C")
  R> str(fun)              # check what the new fun object is
  Formal class 'CFunc' [package "inline"] with 2 slots
    ..@ .Data:function (a, na, b, nb, ab)  
    ..@ code : chr "#include <R.h>\n\n\nvoid file46e87ccd ( double * a, double * na, double * b, double * nb, double * ab ) {\nint i, j, nab = *na "| __truncated__
  R> fun( 1:10, 10, 4:12, 9, numeric(18))$ab
  [1]   4  13  28  50  80 119 168 228 300 372 400 413 410 390 352 295 218 120
  R> 

Voila, and we extended R at the command prompt.  I'd still recommed .Call
over .C, whether you use C++ (which I also recommend :) or C.

I have a number of examples for this in the 'Introduction to High-Performance
Computing with R' tutorials I have given the last few years, see the slides
at 

   http://dirk.eddelbuettel.com/presentations.html 

as well as the recent UCLA talks on more inline examples with Rcpp (if you
want C++).

Cheers, Dirk

-- 
  Registration is open for the 2nd International conference R / Finance 2010
  See http://www.RinFinance.com for details, and see you in Chicago in April!


From shotwelm at musc.edu  Tue Apr 13 05:27:24 2010
From: shotwelm at musc.edu (shotwelm)
Date: Mon, 12 Apr 2010 23:27:24 -0400
Subject: [Rd] Lapack, determinant, multivariate normal density,
	solution to	linear system, C language
Message-ID: <1271129244.10914.34.camel@deacon>

r-devel list,

I have recently written an R package that solves a linear least squares
problem, and computes the multivariate normal density function. The bulk
of the code is written in C, with interfacing code to the BLAS and
Lapack libraries. The motivation here is speed. I ran into a problem
computing the determinant of a symmetric matrix in packed storage.
Apparently, there are no explicit routines for this as part of Lapack.
While there IS an explicit routine for this in Linpack, I did not want
to use the older library. Also, right before I needed the determinant of
the matrix A, I had used the Lapack routine dspsv to solve the linear
system Ax=b, which does much of the work of computing a determinant
also. In fact, the solution I came up with involves the output of this
routine (which might be obvious to Lapack designers, but not me)

My modest Googleing turned up very little unique material (as is typical
with BLAS/Lapack/Linpack queries). Hence, I am writing the r-devel list
partly to document the solution I've come up with, but mainly to elicit
additional wisdom from seasoned R programmers.

My solution to the problem is illustrated in the appended discussion and
C code. Thanks for your input.

-Matt Shotwell

--------------

The Lapack routine dspsv solves the linear system of equations Ax=b,
where A is a symmetric matrix in packed storage format. The dspsv
function performs the factorization A=UDU', where U is a unitriangular
matrix and D is a block diagonal matrix where the blocks are of
dimension 1x1 or 2x2. In addition to the solution for x, the dspsv
function also returns the matrices U and D. The matrix D may then be
used to compute the determinant of A. Recall from linear algebra that
det(A) = det(UDU') = det(U)det(D)det(U'). Since U is unitriangular,
det(U) = 1. The determinant of D is the product of the determinants of
the diagonal blocks. If a diagonal block is of dimension 1x1, then the
determinant of the block is simply the value of the single element in
the block. If the diagonal block is of dimension 2x2 then the
determinant of the block may be computed according to the well-known
formula b11*b22-b12*b21, where bij is the value in the i'th row and j'th
column of the block.

  int i, q, info, *ipiv, one = 1;
  double *b, *A, *D, det;

  /* 
  ** A and D are upper triangular matrices in packed storage
  ** A[] = a00, a01, a11, a02, a12, a22, a03, a13, a23, a33, ...
  ** use the following macro to address the element in the 
  ** i'th row and j'th column for i <= j
  */
  #define UMAT(i, j) (i + j * ( j + 1 ) / 2)

  /* 
  ** additional code should be here
  ** - set q
  ** - allocate ipiv...
  ** - allocate and fill A and b... 
  */

  /* 
  ** solve Ax=b using A=UDU' factorization where 
  ** A represents a qxq matrix, b a 1xq vector.
  ** dspsv outputs the elements of the matrix D
  ** is upper triangular packed storage
  ** in the memory addressed by A. That is, A is
  ** replaced by D when dspsv returns.
  */
  F77_CALL(dspsv)("U", &q, &one, A, ipiv, b, &q, &info); 
  if( info > 0 ) { /*issue warning, system is singular*/ }
  if( info < 0 ) { /*issue error, invalid argument*/ }

  /* 
  ** compute the determinant det = det(A)
  ** if ipiv[i] > 0, then D(i,i) is a 1x1 block diagonal
  ** if ipiv[i] = ipiv[i-1] < 0, then D(i-1,i-1), 
  ** D(i-1,i), and D(i,i) form the upper triangle 
  ** of a 2x2 block diagonal
  */
  D = A;
  det = 1.0;
  for( i = 0; i < q; i++ ) { 
    if( ipiv[ i ] > 0 ) {
      det *= D[ UMAT(i,i) ];
    } else if( i > 0 && ipiv[ i ] < 0 && ipiv[ i-1 ] == ipiv[ i ] ) { 
      det *= D[ UMAT(i,i) ] * D[ UMAT(i-1,i-1) ] -\
             D[ UMAT(i-1,i) ] * D[ UMAT(i-1,i) ];
    }
  }


From rosselldavid at gmail.com  Tue Apr 13 10:16:14 2010
From: rosselldavid at gmail.com (David Rossell)
Date: Tue, 13 Apr 2010 10:16:14 +0200
Subject: [Rd] Multicore mapply
Message-ID: <k2y376b783d1004130116j5b7fac29k690d49012d5a88a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100413/b7c32667/attachment.pl>

From jgarcia at ija.csic.es  Tue Apr 13 12:42:46 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Tue, 13 Apr 2010 12:42:46 +0200 (CEST)
Subject: [Rd] .Fortran interface error
Message-ID: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>

Hi all,
I'm preparing a package which uses .Fortran to interface a Fortran 95
function. This F95 function simply receives the name of a file from R,
opens this file and forwards its content to a F95 module, which, in turn,
makes the real computation.  The F95 module is a pre-existing one and I'm
trying to use it in its actual state.

Thus, data transfer between R and this F95 module is made through scratch
system files (binary or ASCII), and R-F95 interface simply forwards a
pathed name to this module.

OS: openSUSE 10.3 (x86_64)
R version 2.10.1 (2009-12-14)

Then, I've put a demo which makes use of the function, but after model
execution (the F95 code) finishes correctly, and all output is read  back
properly by R (again through system files), R halts, and the following
message appears:

*** glibc detected *** /usr/local/lib64/R/bin/exec/R: free(): invalid
pointer: 0x00000000008a1aa0 ***

Could you give me any hint about where to look for errors?

Just to say that if instead of the R-f95 interface,

I compile the F95 code as executable "runhydro" an call it as:

>system(paste(bindirp,"runhydro",sep="/"))

everything is OK, while compilation as a dynamic library and access to the
F95 "big" module through the simple R-F95 interface:

>res <- .Fortran("runhydro",
                 runfile = as.character(mainfile[1]),
                 charsfile = nchar(mainfile[1]),
                 PACKAGE = "hydroarid"
               )

is what is giving the error (I could handle you the package)

Thanks and best regards,

Javier
---


From ripley at stats.ox.ac.uk  Tue Apr 13 13:15:40 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Apr 2010 12:15:40 +0100 (BST)
Subject: [Rd] .Fortran interface error
In-Reply-To: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>
References: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>
Message-ID: <alpine.LFD.2.00.1004131213290.17471@gannet.stats.ox.ac.uk>

Please try running this under valgrind (see 'Writing R Extensions'). 
The most likely cause is that the Fortran code is corrupting its or 
R's memory.  You may need a build of R set up to instrument R 
allocations (see the manual for details).

On Tue, 13 Apr 2010, jgarcia at ija.csic.es wrote:

> Hi all,
> I'm preparing a package which uses .Fortran to interface a Fortran 95
> function. This F95 function simply receives the name of a file from R,
> opens this file and forwards its content to a F95 module, which, in turn,
> makes the real computation.  The F95 module is a pre-existing one and I'm
> trying to use it in its actual state.
>
> Thus, data transfer between R and this F95 module is made through scratch
> system files (binary or ASCII), and R-F95 interface simply forwards a
> pathed name to this module.
>
> OS: openSUSE 10.3 (x86_64)
> R version 2.10.1 (2009-12-14)
>
> Then, I've put a demo which makes use of the function, but after model
> execution (the F95 code) finishes correctly, and all output is read  back
> properly by R (again through system files), R halts, and the following
> message appears:
>
> *** glibc detected *** /usr/local/lib64/R/bin/exec/R: free(): invalid
> pointer: 0x00000000008a1aa0 ***
>
> Could you give me any hint about where to look for errors?
>
> Just to say that if instead of the R-f95 interface,
>
> I compile the F95 code as executable "runhydro" an call it as:
>
>> system(paste(bindirp,"runhydro",sep="/"))
>
> everything is OK, while compilation as a dynamic library and access to the
> F95 "big" module through the simple R-F95 interface:
>
>> res <- .Fortran("runhydro",
>                 runfile = as.character(mainfile[1]),
>                 charsfile = nchar(mainfile[1]),
>                 PACKAGE = "hydroarid"
>               )
>
> is what is giving the error (I could handle you the package)
>
> Thanks and best regards,
>
> Javier
> ---
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jgarcia at ija.csic.es  Tue Apr 13 15:27:45 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Tue, 13 Apr 2010 15:27:45 +0200 (CEST)
Subject: [Rd] .Fortran interface error
In-Reply-To: <alpine.LFD.2.00.1004131213290.17471@gannet.stats.ox.ac.uk>
References: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>
	<alpine.LFD.2.00.1004131213290.17471@gannet.stats.ox.ac.uk>
Message-ID: <48252.86.0.54.218.1271165265.squirrel@paleo.ija.csic.es>

Hi,
I've stripped all the code, and it seems that any simple attempt to
open/close a file from fortran is the cause of the error, and the error
appears in f77 as well as in f95 code. Please, find attached a foo package
that reproduce the errors, it should build/check/install without any
problem (it does in my computer). If the code

 OPEN( UNIT=5, FILE=runfile, STATUS='OLD', ACTION='READ', &
       IOSTAT=status)
 WRITE (*,*) 'status:   ', status
 IF ( status == 0 ) THEN
   READ(5,'(A)') modelsel
   READ(5,'(A)') modelfile
   READ(5,'(A)') datdirpid
   CLOSE(5)

   WRITE (*,*) 'selected model:   ', modelsel
   WRITE (*,*) 'model input file: ', modelfile
   WRITE (*,*) 'datdirpid: ', datdirpid
 ELSE
   WRITE (*,1002) status
    1002 FORMAT (1X,'open runfile failed--status = ', I6)
   STOP
 END IF

is commented out in any of the two sources files (the f77 or the f95 one),
none of the two corresponding wrappers (as they appear in the examples)
give an error. Thus it seems clear that the operation causing it is the
OPEN/CLOSE. Without commenting out these pieces of code, everything seems
to work right but R halts after a call to the wrapper functions. I cannot
find any comment about this in the documentation. Please, could you tell
me if this is a known error?

Thanks,

Javier
---


> Please try running this under valgrind (see 'Writing R Extensions').
> The most likely cause is that the Fortran code is corrupting its or
> R's memory.  You may need a build of R set up to instrument R
> allocations (see the manual for details).
>
> On Tue, 13 Apr 2010, jgarcia at ija.csic.es wrote:
>
>> Hi all,
>> I'm preparing a package which uses .Fortran to interface a Fortran 95
>> function. This F95 function simply receives the name of a file from R,
>> opens this file and forwards its content to a F95 module, which, in
>> turn,
>> makes the real computation.  The F95 module is a pre-existing one and
>> I'm
>> trying to use it in its actual state.
>>
>> Thus, data transfer between R and this F95 module is made through
>> scratch
>> system files (binary or ASCII), and R-F95 interface simply forwards a
>> pathed name to this module.
>>
>> OS: openSUSE 10.3 (x86_64)
>> R version 2.10.1 (2009-12-14)
>>
>> Then, I've put a demo which makes use of the function, but after model
>> execution (the F95 code) finishes correctly, and all output is read
>> back
>> properly by R (again through system files), R halts, and the following
>> message appears:
>>
>> *** glibc detected *** /usr/local/lib64/R/bin/exec/R: free(): invalid
>> pointer: 0x00000000008a1aa0 ***
>>
>> Could you give me any hint about where to look for errors?
>>
>> Just to say that if instead of the R-f95 interface,
>>
>> I compile the F95 code as executable "runhydro" an call it as:
>>
>>> system(paste(bindirp,"runhydro",sep="/"))
>>
>> everything is OK, while compilation as a dynamic library and access to
>> the
>> F95 "big" module through the simple R-F95 interface:
>>
>>> res <- .Fortran("runhydro",
>>                 runfile = as.character(mainfile[1]),
>>                 charsfile = nchar(mainfile[1]),
>>                 PACKAGE = "hydroarid"
>>               )
>>
>> is what is giving the error (I could handle you the package)
>>
>> Thanks and best regards,
>>
>> Javier
>> ---
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: foofortran.tar.gz
Type: application/x-gzip
Size: 2908 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100413/90c9e4a4/attachment.gz>

From dopethatwantscash at yahoo.com  Tue Apr 13 04:42:33 2010
From: dopethatwantscash at yahoo.com (Jeff Brown)
Date: Mon, 12 Apr 2010 18:42:33 -0800 (PST)
Subject: [Rd] Getting started with .C
In-Reply-To: <1271124683916-1837936.post@n4.nabble.com>
References: <1271121727964-1837912.post@n4.nabble.com>
	<1271124683916-1837936.post@n4.nabble.com>
Message-ID: <857281.72015.qm@web110601.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100412/f7955d4e/attachment.pl>

From maechler at stat.math.ethz.ch  Tue Apr 13 18:34:23 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Apr 2010 18:34:23 +0200
Subject: [Rd] svn.r-project.org with new trusted certificate
Message-ID: <19396.40207.890732.459335@lynne.math.ethz.ch>

The SVN (Subversion) Server of the R-project, svn.r-project.org,
financed and run by the Math Department of ETH Zurich,
now has got it's own "validated" aka "trusted" SSL certificate,
mostly thanks to Simon Urbanek (R-core) and his employer, AT&T Labs.

This may mean that those of you who have been using the R
development sources, (or had scripts that read the logs, or ...)
may need to cache the new certificate by some one-time manual
interaction.

Martin Maechler, ETH Zurich


From osklyar at ahl.com  Tue Apr 13 18:56:23 2010
From: osklyar at ahl.com (Sklyar, Oleg (London))
Date: Tue, 13 Apr 2010 17:56:23 +0100
Subject: [Rd] Job: AHL Research Developer, R/python - top hedge fund,
 Oxford/London UK
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE430662AFA1@mildnpexmb01.maninvestments.ad.man.com>

Dear list subscribers,

this is posted in appreciation of the level of skill that subscribers to this mailing list enjoy and in no way to abuse it.

We are looking to hire a Research Developer with extensive R and/or python development skills. If interested (below), please contact me directly on osklyar at ahl.com:

Man Group / AHL Research Developer [3040]

Man is a world-leading alternative investment management business. With a broad range of funds for institutional and private investors globally, it is known for its performance, innovative product design and investor service.  Man's funds under management at the end of year 2009 were roughly at $42 billion.

The original business was founded in 1783. Today, Man Group plc is listed on the London Stock Exchange and is a member of the FTSE 100 Index with a market capitalisation of around ?4 billion.

Within Man AHL is a world-leading quantitative investment manager with an extensive history of performance and innovation. A pioneer in the application of systematic trading, we have been serving institutional and private clients since 1987. Further information can be found at www.ahl.com.

As part of its investment in quantitative finance research, Man Group and its quantitative investment manager AHL have established a Research Laboratory at Oxford. The Laboratory is sharing the same offices with the Oxford-Man Institute of Quantitative Finance encouraging interaction between academic and commercial researchers. It pursues commercially driven research programmes primarily focussed on the needs of AHL but collaborates with the Institute through seminars, workshops and informal discussions.

In our research we facilitate the use of the tools that are widely spread throughout the academic quantitative and statistical computing landscape, like Python and R. There is an immediate and on-going need to develop advanced and technologically modern computational tools and quantitative techniques to support the AHL research programmes. In addition, there are a number of potentially applicable Information Systems and Information Engineering academic research programmes, which require commercial evaluation and assessment.

Working in close cooperation with the AHL Research teams, both in Oxford and London, and the AHL Technology group in London, the successful candidate will design, develop and implement necessary software libraries and frameworks in R, Python and other languages to support the Oxford research team in technology topics and develop recommendations on the use of software configuration management in the AHL research projects.

Responsibilities:

- Design and develop software libraries and frameworks in R and Python to support the Laboratory's research activities and write corresponding documentation and example code

- Work with the AHL Technology and AHL Research teams to develop interfaces between various platforms, in particular Java, C/C++, R and Python to facilitate effective data and information exchange 

- Provide assistance, support and seminars to the researchers on the optimal use of R and Python libraries and Linux 

- Propose and implement algorithms to assist in data analysis tasks 

- Develop recommendations for the use of R and Python in research projects, code reuse and configuration management across the Laboratory and with the AHL Research technology to ensure maximum productivity 

- Collaborate with the Institute's computer science research team as required and keep up to date with the computer science research being undertaken at the Institute and in related University departments 

- Work with the AHL Technology Group to ensure that the technology experience and facilities at the Laboratory are fit for purpose 

- Act as the point of contact between the Oxford research staff and the London based AHL Technology group 

Requirements:

- PhD or experienced MSc/Part III in quantitative research in maths, science, engineering or computer science 

- Fluent R or Python and at least one of C, C++, or Java; confidence with Linux, Unix or similar 

- Mathematical skills to 1st year post-graduate and excellent analytical skills 

- Experience in statistical analysis and modelling, optimisation algorithms, data visualisation, preferably with relation to large data sets 

- Passion for computer science and statistics and its application to financial markets 

- Good communication and team working skills coupled with capability for innovative thinking 

Advantageous

- Knowledge of object oriented design, distributed computing, relational databases 

- Experience working with Beowulf-style Linux clusters, MPI, slurm, condor etc 

- Experience of software development in a dealer/trading desk environment 

Man Group, and all related entities, is an equal opportunity employer through the application of a policy of non-discrimination on the grounds of sex, marital or civil partner status, gender reassignment, sexual orientation, race, colour, ethnic or national origin, nationality, citizenship, disability, religion, religious or philosophical belief and age. 

Dr Oleg Sklyar
Research Technologist
AHL / Man Group plc
+44 (0)20 7144 3803
osklyar at ahl.com

**********************************************************************
 Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From chuck at sharpsteen.net  Tue Apr 13 20:49:00 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Tue, 13 Apr 2010 10:49:00 -0800 (PST)
Subject: [Rd] .Fortran interface error
In-Reply-To: <48252.86.0.54.218.1271165265.squirrel@paleo.ija.csic.es>
References: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>
	<alpine.LFD.2.00.1004131213290.17471@gannet.stats.ox.ac.uk>
	<48252.86.0.54.218.1271165265.squirrel@paleo.ija.csic.es>
Message-ID: <1271184540992-1838888.post@n4.nabble.com>



jgarcia-2 wrote:
> 
> Hi,
> I've stripped all the code, and it seems that any simple attempt to
> open/close a file from fortran is the cause of the error, and the error
> appears in f77 as well as in f95 code. Please, find attached a foo package
> that reproduce the errors, it should build/check/install without any
> problem (it does in my computer). If the code
> 
>  OPEN( UNIT=5, FILE=runfile, STATUS='OLD', ACTION='READ', &
>        IOSTAT=status)
>  WRITE (*,*) 'status:   ', status
>  IF ( status == 0 ) THEN
>    READ(5,'(A)') modelsel
>    READ(5,'(A)') modelfile
>    READ(5,'(A)') datdirpid
>    CLOSE(5)
> 
>    WRITE (*,*) 'selected model:   ', modelsel
>    WRITE (*,*) 'model input file: ', modelfile
>    WRITE (*,*) 'datdirpid: ', datdirpid
>  ELSE
>    WRITE (*,1002) status
>     1002 FORMAT (1X,'open runfile failed--status = ', I6)
>    STOP
>  END IF
> 
> is commented out in any of the two sources files (the f77 or the f95 one),
> none of the two corresponding wrappers (as they appear in the examples)
> give an error. Thus it seems clear that the operation causing it is the
> OPEN/CLOSE. Without commenting out these pieces of code, everything seems
> to work right but R halts after a call to the wrapper functions. I cannot
> find any comment about this in the documentation. Please, could you tell
> me if this is a known error?
> 
> Thanks,
> 
> Javier
> 

It looks like you may have some I/O collisions occurring.  Some Fortran
compilers treat unit 5 as being STDIN, so attempting to read from that
stream when the Fortran program is embedded may be giving R a headache.  I
would recommend either passing "modelsel", "modelfile" and "datadirpid" as
parameters from R, or reading from a file using a different unit number.

For output, instead of using write(*,*) you may need to use some of the R
output callbacks described in section 6.5.1 of "Writing R Extensions".

Hope this helps!

-Charlie



-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://n4.nabble.com/Fortran-interface-error-tp1838225p1838888.html
Sent from the R devel mailing list archive at Nabble.com.


From info at aghmed.fsnet.co.uk  Tue Apr 13 19:37:56 2010
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 13 Apr 2010 18:37:56 +0100
Subject: [Rd] Summary,
 was Re: R CMD check tells me 'no visible binding for global
 variable ', what does it mean?
In-Reply-To: <m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail .com>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
	<4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
Message-ID: <Zen-1O1lyU-0000d1-JH@smarthost02.mail.zen.net.uk>

At 16:24 12/04/2010, Henrik Bengtsson wrote:

>On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 12/04/2010 10:51 AM, Michael Dewey wrote:
> >>

Just to draw a line under it my comment inline below

> >> When I run R CMD check on a package I have recently started work on I get
> >> the following:
> >>
> >> * checking R code for possible problems ... NOTE
> >> addlinear: no visible binding for global variable 'x'
> >>
> >> I appreciate that this is only a NOTE and so I assume is R's equivalent of
> >> 'This is perfectly legal but I wonder whether it is really what you
> >> intended' but I would like to understand it.
> >>
> >> In the relevant function addlinear the following function is defined
> >> locally:
> >>
> >>    orfun <- function(x, oddsratio) {1/(1+1/(oddsratio * (x/(1-x))))}
> >>
> >> and then used later in curve
> >>
> >>       curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
> >>
> >> These are the only occurrences of 'x'.
> >>
> >> Is it just telling me that I have never assigned a value to x? Or is it
> >> more sinister than that? As far as I can tell the function does what I
> >> intended.
> >
> > The curve() function evaluates the first argument in a strange 
> way, and this
> > confuses the code checking.  (The variable name "x" is special to curve().)
> >
> > I think you can avoid the warning by rewriting that call to curve() as
> >
> > curve(function(x) orfun(x, exp(estimate)), from = 0.001, to = 0.999, add =
> > TRUE)

Yes, Duncan is correct that avoids the note.
I found this aesthetically more pleasing than Henrik's suggestion but 
other people's taste may be different.

Thanks for the prompt and interesting replies.

>...or
>
>x <- NULL; rm(x); # Dummy to trick R CMD check
>curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>
>/Henrik
>
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >

Michael Dewey
http://www.aghmed.fsnet.co.uk


From jgarcia at ija.csic.es  Tue Apr 13 22:20:33 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Tue, 13 Apr 2010 22:20:33 +0200 (CEST)
Subject: [Rd] .Fortran interface error
Message-ID: <42789.86.0.54.218.1271190033.squirrel@paleo.ija.csic.es>

Yes!!!!!!!! That's it! Thanks a lot!!!!!!
Changing UNIT=5 in the F95 code by UNIT=7 solves the collision.

Thank you very much Charlie, I've spent a lot of hours with this.

Still

R -d valgrind --vanilla < foofortran.Rcheck/foofortran-Ex.R

gives 3 errors (two "Invalid read of size 8" and one "Syscall param
write(buf) points to uninitialised byte(s)"), which are the same it gave
with UNIT=5. However, everything seems to work fine now in the normal
execution :-)

Thank you very much again

Javier
---

==25824== Memcheck, a memory error detector.
==25824== Copyright (C) 2002-2007, and GNU GPL'd, by Julian Seward et al.
==25824== Using LibVEX rev 1732, a library for dynamic binary translation.
==25824== Copyright (C) 2004-2007, and GNU GPL'd, by OpenWorks LLP.
==25824== Using valgrind-3.2.3, a dynamic binary instrumentation framework.
==25824== Copyright (C) 2000-2007, and GNU GPL'd, by Julian Seward et al.
==25824== For more details, rerun with: -v
==25824==

R version 2.10.1 (2009-12-14)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "foofortran"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('foofortran')
==25824== Invalid read of size 8
==25824==    at 0x401431B: (within /lib64/ld-2.6.1.so)
==25824==    by 0x4009631: (within /lib64/ld-2.6.1.so)
==25824==    by 0x5A9D804: (within /lib64/libc-2.6.1.so)
==25824==    by 0x57A3143: (within /lib64/libdl-2.6.1.so)
==25824==    by 0x400C8E5: (within /lib64/ld-2.6.1.so)
==25824==    by 0x57A336C: (within /lib64/libdl-2.6.1.so)
==25824==    by 0x57A30F9: dlsym (in /lib64/libdl-2.6.1.so)
==25824==    by 0x59871C: R_local_dlsym (dynload.c:216)
==25824==    by 0x4C9944: AddDLL (Rdynload.c:557)
==25824==    by 0x4CA073: do_dynload (Rdynload.c:893)
==25824==    by 0x428372: do_internal (names.c:1165)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==  Address 0x61BA068 is 16 bytes inside a block of size 18 alloc'd
==25824==    at 0x4C21D06: malloc (in
/usr/lib64/valgrind/amd64-linux/vgpreload_memcheck.so)
==25824==    by 0x4C9918: AddDLL (Rdynload.c:549)
==25824==    by 0x4CA073: do_dynload (Rdynload.c:893)
==25824==    by 0x428372: do_internal (names.c:1165)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x54F6AF: Rf_applyClosure (eval.c:699)
==25824==    by 0x54D105: Rf_eval (eval.c:508)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x54EE71: do_set (eval.c:1502)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x55157B: do_begin (eval.c:1245)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==
==25824== Invalid read of size 8
==25824==    at 0x4014DCE: (within /lib64/ld-2.6.1.so)
==25824==    by 0x400967A: (within /lib64/ld-2.6.1.so)
==25824==    by 0x5A9D804: (within /lib64/libc-2.6.1.so)
==25824==    by 0x57A3143: (within /lib64/libdl-2.6.1.so)
==25824==    by 0x400C8E5: (within /lib64/ld-2.6.1.so)
==25824==    by 0x57A336C: (within /lib64/libdl-2.6.1.so)
==25824==    by 0x57A30F9: dlsym (in /lib64/libdl-2.6.1.so)
==25824==    by 0x59871C: R_local_dlsym (dynload.c:216)
==25824==    by 0x4C9944: AddDLL (Rdynload.c:557)
==25824==    by 0x4CA073: do_dynload (Rdynload.c:893)
==25824==    by 0x428372: do_internal (names.c:1165)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==  Address 0x61BA068 is 16 bytes inside a block of size 18 alloc'd
==25824==    at 0x4C21D06: malloc (in
/usr/lib64/valgrind/amd64-linux/vgpreload_memcheck.so)
==25824==    by 0x4C9918: AddDLL (Rdynload.c:549)
==25824==    by 0x4CA073: do_dynload (Rdynload.c:893)
==25824==    by 0x428372: do_internal (names.c:1165)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x54F6AF: Rf_applyClosure (eval.c:699)
==25824==    by 0x54D105: Rf_eval (eval.c:508)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x54EE71: do_set (eval.c:1502)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==    by 0x55157B: do_begin (eval.c:1245)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
>
> assign(".oldSearch", search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("fooRf90")
> ### * fooRf90
>
> flush(stderr()); flush(stdout())
>
> ### Name: fooRf90
> ### Title: Sample Call to FORTRAN 90
> ### Aliases: fooRf90
>
> ### ** Examples
>
> x <- c(1:10)
> filename <- "anystring"
> res <- fooRf90(x, filename)
==25824==
==25824== Syscall param write(buf) points to uninitialised byte(s)
==25824==    at 0x5A5DC40: write (in /lib64/libc-2.6.1.so)
==25824==    by 0x50E8000: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E807D: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E8817: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E545C: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E597B: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E59D8: _gfortran_st_write_done (in
/usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x849CC02: foof90_ (ofoofunc.f90:18)
==25824==    by 0x5200FD: do_dotCode (dotcode.c:1724)
==25824==    by 0x54D3AB: Rf_eval (eval.c:490)
==25824==    by 0x54EE71: do_set (eval.c:1502)
==25824==    by 0x54D1E1: Rf_eval (eval.c:464)
==25824==  Address 0x404C3D3 is 171 bytes inside a block of size 8,344
alloc'd
==25824==    at 0x4C21D06: malloc (in
/usr/lib64/valgrind/amd64-linux/vgpreload_memcheck.so)
==25824==    by 0x5069D38: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E8269: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50E7A73: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x5069B37: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x50F9241: (within /usr/lib64/libgfortran.so.2.0.0)
==25824==    by 0x5066CF2: (within /usr/lib64/libgfortran.so.2.0.0)
 runfile:   anystring !"#$%&'&#65533;&#65533;&#65533;&#65533;06
                                   &#65533;&#65533;&#65533;&#1075;&#65533;'


&#9618;&#9618;
orunfile:   anystring


>
> jgarcia-2 wrote:
>>
>> Hi,
>> I've stripped all the code, and it seems that any simple attempt to
>> open/close a file from fortran is the cause of the error, and the error
>> appears in f77 as well as in f95 code. Please, find attached a foo
>> package
>> that reproduce the errors, it should build/check/install without any
>> problem (it does in my computer). If the code
>>
>>  OPEN( UNIT=5, FILE=runfile, STATUS='OLD', ACTION='READ', &
>>        IOSTAT=status)
>>  WRITE (*,*) 'status:   ', status
>>  IF ( status == 0 ) THEN
>>    READ(5,'(A)') modelsel
>>    READ(5,'(A)') modelfile
>>    READ(5,'(A)') datdirpid
>>    CLOSE(5)
>>
>>    WRITE (*,*) 'selected model:   ', modelsel
>>    WRITE (*,*) 'model input file: ', modelfile
>>    WRITE (*,*) 'datdirpid: ', datdirpid
>>  ELSE
>>    WRITE (*,1002) status
>>     1002 FORMAT (1X,'open runfile failed--status = ', I6)
>>    STOP
>>  END IF
>>
>> is commented out in any of the two sources files (the f77 or the f95
>> one),
>> none of the two corresponding wrappers (as they appear in the examples)
>> give an error. Thus it seems clear that the operation causing it is the
>> OPEN/CLOSE. Without commenting out these pieces of code, everything
>> seems
>> to work right but R halts after a call to the wrapper functions. I
>> cannot
>> find any comment about this in the documentation. Please, could you tell
>> me if this is a known error?
>>
>> Thanks,
>>
>> Javier
>>
>
> It looks like you may have some I/O collisions occurring.  Some Fortran
> compilers treat unit 5 as being STDIN, so attempting to read from that
> stream when the Fortran program is embedded may be giving R a headache.  I
> would recommend either passing "modelsel", "modelfile" and "datadirpid" as
> parameters from R, or reading from a file using a different unit number.
>
> For output, instead of using write(*,*) you may need to use some of the R
> output callbacks described in section 6.5.1 of "Writing R Extensions".
>
> Hope this helps!
>
> -Charlie
>
>
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
> --
> View this message in context:
> http://n4.nabble.com/Fortran-interface-error-tp1838225p1838888.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From chuck at sharpsteen.net  Tue Apr 13 23:06:47 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Tue, 13 Apr 2010 13:06:47 -0800 (PST)
Subject: [Rd] .Fortran interface error
In-Reply-To: <42789.86.0.54.218.1271190033.squirrel@paleo.ija.csic.es>
References: <48821.86.0.54.218.1271155366.squirrel@paleo.ija.csic.es>
	<42789.86.0.54.218.1271190033.squirrel@paleo.ija.csic.es>
Message-ID: <1271192807347-1839012.post@n4.nabble.com>



jgarcia-2 wrote:
> 
> Yes!!!!!!!! That's it! Thanks a lot!!!!!!
> Changing UNIT=5 in the F95 code by UNIT=7 solves the collision.
> 
> Thank you very much Charlie, I've spent a lot of hours with this.
> 

I'm glad it worked!

Google seems to indicate that units 0, 5, 6, 100, 101 and 102 are special in
Fortran.  However, the professor who taught me Fortran recommended using
unit numbers that were 11 or greater as his experience with several Fortran
compilers was that they tended to appropriate units <= 10 for their own uses
and this behavior was not well standardized.

I haven't been able to verify this myself, but there may be something to his
warning.


jgarcia-2 wrote:
> 
> Still
> 
> R -d valgrind --vanilla < foofortran.Rcheck/foofortran-Ex.R
> 
> gives 3 errors (two "Invalid read of size 8" and one "Syscall param
> write(buf) points to uninitialised byte(s)"), which are the same it gave
> with UNIT=5. However, everything seems to work fine now in the normal
> execution :-)
> 
> Thank you very much again
> 
> Javier
> 

I'm not well acquainted with valgrind so I can't offer any advice on this
part :(

Good luck!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://n4.nabble.com/Fortran-interface-error-tp1838225p1839012.html
Sent from the R devel mailing list archive at Nabble.com.


From chuck at sharpsteen.net  Wed Apr 14 04:02:33 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Tue, 13 Apr 2010 18:02:33 -0800 (PST)
Subject: [Rd] SHLIB works but inline compilation does not
In-Reply-To: <1271198486636-1839090.post@n4.nabble.com>
References: <1271198486636-1839090.post@n4.nabble.com>
Message-ID: <1271210553782-1839237.post@n4.nabble.com>



Jeff Brown wrote:
> 
> Hi,
> 
> I appear to be able to compile, load and call shared objects using SHLIB
> and .Call:
> 
>> code <- '#include <R.h>\n #include <Rdefines.h>\n SEXP f(){\n return
>> R_NilValue ; }' 
>> writeLines( code, "test.c" ) 
>> system( "R CMD SHLIB test.c" )
> gcc -arch i386 -std=gnu99
> -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/i386 
> -I/usr/local/include    -fPIC  -g -O2 -c test.c -o test.o
> gcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names
> -mmacosx-version-min=10.4 -undefined dynamic_lookup -single_module
> -multiply_defined suppress -L/usr/local/lib -o test.so test.o
> -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework
> -Wl,CoreFoundation
>> dyn.load( "test.so" ) 
>> .Call( "f" ) 
> NULL
> 
> The above follows Romaine-Francois 3's suggestion here:
> http://n4.nabble.com/I-can-t-run-the-example-shown-in-the-inline-package-td1774328.html#a1778838
> 
> However, when I try to use the "inline" package, I can't get it to work:
> 
>> code <- "
> + 	int i, j, nab = *na + *nb - 1; 
> + 	for(i = 0; i < nab; i++) 
> + 	  ab[i] = 0.0; 
> + 	for(i = 0; i < *na; i++) {
> + 	  for(j = 0; j < *nb; j++) 
> + 			  ab[i + j] += a[i] * b[j]; 
> + 	}"
>> fun <- cfunction(
> + 	signature(a="numeric", na="numeric", b="numeric", nb="numeric",
> ab="numeric"), 
> + 	code, 
> + 	language="C", 
> + 	convention=".C"	)
> 
> ERROR(s) during compilation: source code errors or compiler configuration
> errors!
> 
> Program source:
>   1: #include <R.h>
>   2: 
>   3: 
>   4: void file4431b782 ( double * a, double * na, double * b, double * nb,
> double * ab ) {
>   5: 
>   6: 	int i, j, nab = *na + *nb - 1; 
>   7: 	for(i = 0; i < nab; i++) 
>   8: 	  ab[i] = 0.0; 
>   9: 	for(i = 0; i < *na; i++) {
>  10: 	  for(j = 0; j < *nb; j++) 
>  11: 			  ab[i + j] += a[i] * b[j]; 
>  12: 	}
>  13: }
> Error in compileCode(f, code, language, verbose) : 
>   Compilation ERROR, function(s)/method(s) not created!
> 
> The C function above is the one from "Writing R Extensions", p. 79; the
> suggestion for how to compile it inline is from Dirk Eddelbuettel, at this
> thread:
> http://n4.nabble.com/Getting-started-with-C-td1837912.html#a1837912
> 
> R says it's either a source code or configuration error.  I got the code
> from "Writing R Extensions", and Dirk tried it out too.  But if it's a
> compilation error, then shouldn't the first method (with SHLIB) not work
> either?
> 
> I realize I could stick to the SHLIB method, which Charlie ("The Sharpie")
> Sharpsteen wrote up in fantastic detail here:
> http://n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.html#a1580423
> But there's so much more stuff I'll need to understand if I do it that way
> ...
> 
> I use an Intel MacBook Pro with OS X 10.6.2, XCode 3.2.1, gcc 4.2.1.
> 
> Thanks,
> Jeff
> 
> 

I could not reproduce this problem on my computer, OS X 10.6.3, gcc 4.2.1, R
2.10.1, inline 0.3.4:

code <- " 
int i, j, nab = *na + *nb - 1; 
for(i = 0; i < nab; i++) 
 ab[i] = 0.0; 
for(i = 0; i < *na; i++) { 
 for(j = 0; j < *nb; j++) 
 ab[i + j] += a[i] * b[j]; 
}" 

fun <- cfunction( 
signature(a="numeric", na="numeric", b="numeric", nb="numeric",
ab="numeric"), 
code, 
language="C", 
convention=".C" ) 

fun( 1:3, 3, 4:6, 3, double(5) )

$a
[1] 1 2 3

$na
[1] 3

$b
[1] 4 5 6

$nb
[1] 3

$ab
[1]  4 13 28 27 18


The only thing I can think of is that you may have a newline issue going on. 
Here's the dump of the code object:

dput(code)

" \nint i, j, nab = *na + *nb - 1; \nfor(i = 0; i < nab; i++) \n ab[i] =
0.0; \nfor(i = 0; i < *na; i++) { \n for(j = 0; j < *nb; j++) \n ab[i + j]
+= a[i] * b[j]; \n}"

Do you have newlines, \n, that are in different places?  An easy way to
check may be to copy the results of running dput() on your code object into
one file, mine into another and running diff.

Hope this helps!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://n4.nabble.com/SHLIB-works-but-inline-compilation-does-not-tp1839090p1839237.html
Sent from the R devel mailing list archive at Nabble.com.


From djsamperi at gmail.com  Wed Apr 14 07:50:54 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 14 Apr 2010 01:50:54 -0400
Subject: [Rd] Why no race condition when returning UNPROTECT-ed memory from
	C?
Message-ID: <j2wd4cf43b61004132250s14a6ee9cmc89be3266eb3e721@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100414/364bbb75/attachment.pl>

From pdalgd at gmail.com  Wed Apr 14 10:10:03 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 14 Apr 2010 10:10:03 +0200
Subject: [Rd] Why no race condition when returning UNPROTECT-ed memory
	from C?
In-Reply-To: <j2wd4cf43b61004132250s14a6ee9cmc89be3266eb3e721@mail.gmail.com>
References: <j2wd4cf43b61004132250s14a6ee9cmc89be3266eb3e721@mail.gmail.com>
Message-ID: <CFDC9CCA-8B00-4C13-BB26-4B77F536D862@gmail.com>


On Apr 14, 2010, at 7:50 AM, Dominick Samperi wrote:

> Consider the C (or C++) code called from the .Call interface:
> SEXP foo() {
>  SEXP *p = PROTECT(allocVector(REALSXP, 10));
>  ...
>  UNPROTECT(1);
>  return p;
> }
> 
> Why is there no danger that the allocated memory will be garbage
> collected after the UNPROTECT, but before the return of p?
> 
> I have used code like this for some time and have never had a
> problem, but I'm not sure if/why it is guaranteed to work.

Garbage collection is only triggered by allocation. The hard bit is to remember exactly which programming constructs might allocate something, but in the above, there aren't any. You need to watch out with the unprotected return value, though: fee(foo(), fum()) is a standard bug source if fum() allocates.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From osklyar at ahl.com  Wed Apr 14 10:21:38 2010
From: osklyar at ahl.com (Sklyar, Oleg (London))
Date: Wed, 14 Apr 2010 09:21:38 +0100
Subject: [Rd] Why no race condition when returning UNPROTECT-ed memory
 fromC?
In-Reply-To: <j2wd4cf43b61004132250s14a6ee9cmc89be3266eb3e721@mail.gmail.com>
References: <j2wd4cf43b61004132250s14a6ee9cmc89be3266eb3e721@mail.gmail.com>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE430662AFA7@mildnpexmb01.maninvestments.ad.man.com>

Because there is no second thread to do that, R is single threaded. The
gc could only be run from within another R API command or macro, but
there is none in between.

Best
Oleg

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3803
osklyar at maninvestments.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dominick Samperi
> Sent: 14 April 2010 06:51
> To: r-devel at r-project.org
> Subject: [Rd] Why no race condition when returning 
> UNPROTECT-ed memory fromC?
> 
> Consider the C (or C++) code called from the .Call interface:
> SEXP foo() {
>   SEXP *p = PROTECT(allocVector(REALSXP, 10));
>   ...
>   UNPROTECT(1);
>   return p;
> }
> 
> Why is there no danger that the allocated memory will be garbage
> collected after the UNPROTECT, but before the return of p?
> 
> I have used code like this for some time and have never had a
> problem, but I'm not sure if/why it is guaranteed to work.
> 
> Thanks,
> Dominick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

**********************************************************************
 Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From hb at stat.berkeley.edu  Thu Apr 15 08:26:41 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 15 Apr 2010 08:26:41 +0200
Subject: [Rd] CRAN: MacOS X binary: not available, see check log?
Message-ID: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com>

For a couple of days, MacOS X binaries are not build on CRAN (for my
recently uploaded packages only?):

The R.oo package is listed as "MacOS X binary: not available, see
check log?", but the 'check log' show no errors
URL: http://cran.r-project.org/web/packages/R.oo/

Is this a known issue?

/Henrik


From simon.urbanek at r-project.org  Thu Apr 15 15:45:31 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Apr 2010 09:45:31 -0400
Subject: [Rd] CRAN: MacOS X binary: not available, see check log?
In-Reply-To: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com>
References: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com>
Message-ID: <F9E52DA5-25C1-4860-AF53-BDBF1E8165B7@r-project.org>


On Apr 15, 2010, at 2:26 AM, Henrik Bengtsson wrote:

> For a couple of days, MacOS X binaries are not build on CRAN (for my
> recently uploaded packages only?):
> 

AFAICS your package was posted on Apr 13 so at the earliest it can be built in the Apr 14 run = yesterday. There was no Apr 14 run because the R build failed on Apr 13. I was chasing the subsequent issues yesterday and I think the latest R build is now working so today's package update should be on CRAN soon. Don't forget that packages have to swim across the Atlantic to get built and then back as binaries, so the migration can take a day or two ;).

Cheers,
Simon


> The R.oo package is listed as "MacOS X binary: not available, see
> check log?", but the 'check log' show no errors
> URL: http://cran.r-project.org/web/packages/R.oo/
> 
> Is this a known issue?
> 



> /Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From adrian at waddell.ch  Thu Apr 15 16:21:47 2010
From: adrian at waddell.ch (Adrian Waddell)
Date: Thu, 15 Apr 2010 10:21:47 -0400
Subject: [Rd] callNextMethod() and NAMESPACE
Message-ID: <4BC720FB.9080904@waddell.ch>

Hello there,

I define a accessor method for one of my classes, i.e.

setMethod(f = "[",
   signature = "NG_data",
     definition = function(x,i,j,drop){
        if(all(is.na(match(j,x at shortnames)) == FALSE)){
          return(x[,match(j,x at shortnames)])                           }else{
          callNextMethod()
        }
     }
)

where the class "NG_data" inherits from the "data.frame" class. Hence I 
added the line

exportMethods("[")

to my NAMESPACE file. After package building, installing and loading, I 
try to use this accessor method

myObject[,1]

but I get the error message:

Error in callNextMethod() : bad object found as method (class "function")

Interestingly, if I then execute the setMethod(f = "["...  in the 
command prompt

myObject[,1]

works. Does anybody has a clue what could go wrong?


Adrian Waddell


From patrick.giraudoux at univ-fcomte.fr  Thu Apr 15 18:06:46 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 15 Apr 2010 18:06:46 +0200
Subject: [Rd] =?iso-8859-1?q?=22=B0=22_not_accepted_under_MacOSX?=
Message-ID: <4BC73996.90309@univ-fcomte.fr>

I am developping a package (pgirmess) that since long does not go 
through CRAN MacOSX checks, just because I have this command in one of 
the examples.

text(mydata[,3],mydata[,4],paste(round(dirs,0),"?"),cex=0.7)

It makes:

<ERROR: re-encoding failure from encoding 'latin1'>
text(mydata[,3],mydata[,4],paste(round(dirs,0),"+
+
+
+ cleanEx()
+ nameEx("distNode")
Error: unexpected symbol in:
"cleanEx()
nameEx("distNode"
Execution halted

The description file (following some earlier recommandation) includes:
Encoding: latin1

Is there any way to make "?" accepted by MacOSX checks ?

Cheers,

Patrick


From ripley at stats.ox.ac.uk  Thu Apr 15 19:06:14 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Apr 2010 18:06:14 +0100 (BST)
Subject: [Rd] =?iso-8859-15?q?=22=B0=22_not_accepted_under_MacOSX?=
In-Reply-To: <4BC73996.90309@univ-fcomte.fr>
References: <4BC73996.90309@univ-fcomte.fr>
Message-ID: <alpine.LFD.2.00.1004151747020.11199@gannet.stats.ox.ac.uk>

The subject line is untrue.

We recommend in 'Writing R Extensions' that you encode such characters 
as \uxxxx sequences, in this case "\u00b0".  However, this is more 
likely to be a locale problem on the check server, as pgirmess checks 
out on my Mac.  In fact, the top of the log is

# using R version 2.11.0 beta (2010-04-12 r51689)
# using session charset: ASCII
# checking for file 'pgirmess/DESCRIPTION' ... OK
# this is package 'pgirmess' version '1.4.4'
# package encoding: latin1

and you cannot reencode latin1 to ASCII ....

I don't know why you would choose to use something that makes your 
package fail on many Japanese or Greek or Russian systems, and of 
course in C locales.  Plotmath is portable, and these days "\u00b0" is 
also pretty portable.

On Thu, 15 Apr 2010, Patrick Giraudoux wrote:

> I am developping a package (pgirmess) that since long does not go through 
> CRAN MacOSX checks, just because I have this command in one of the examples.
>
> text(mydata[,3],mydata[,4],paste(round(dirs,0),"?"),cex=0.7)
>
> It makes:
>
> <ERROR: re-encoding failure from encoding 'latin1'>
> text(mydata[,3],mydata[,4],paste(round(dirs,0),"+
> +
> +
> + cleanEx()
> + nameEx("distNode")
> Error: unexpected symbol in:
> "cleanEx()
> nameEx("distNode"
> Execution halted
>
> The description file (following some earlier recommandation) includes:
> Encoding: latin1
>
> Is there any way to make "?" accepted by MacOSX checks ?
>
> Cheers,
>
> Patrick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From patrick.giraudoux at univ-fcomte.fr  Thu Apr 15 19:21:45 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 15 Apr 2010 19:21:45 +0200
Subject: [Rd] =?iso-8859-1?q?=22=B0=22_not_accepted_under_MacOSX?=
In-Reply-To: <alpine.LFD.2.00.1004151747020.11199@gannet.stats.ox.ac.uk>
References: <4BC73996.90309@univ-fcomte.fr>
	<alpine.LFD.2.00.1004151747020.11199@gannet.stats.ox.ac.uk>
Message-ID: <4BC74B29.1080801@univ-fcomte.fr>

Prof Brian Ripley a ?crit :
> The subject line is untrue.
>
> We recommend in 'Writing R Extensions' that you encode such characters 
> as \uxxxx sequences, in this case "\u00b0".  However, this is more 
> likely to be a locale problem on the check server, as pgirmess checks 
> out on my Mac.  In fact, the top of the log is
>
> # using R version 2.11.0 beta (2010-04-12 r51689)
> # using session charset: ASCII
> # checking for file 'pgirmess/DESCRIPTION' ... OK
> # this is package 'pgirmess' version '1.4.4'
> # package encoding: latin1
>
> and you cannot reencode latin1 to ASCII ....
>
> I don't know why you would choose to use something that makes your 
> package fail on many Japanese or Greek or Russian systems, and of 
> course in C locales.  Plotmath is portable, and these days "\u00b0" is 
> also pretty portable.
>

Thanks a lot. Strictly speaking, I did not choose:  I was just not 
familiar with \uxxxx  encoding, and will document on it now I have a 
good hint to start with...

Thanks again,

Patrick


From luke at stat.uiowa.edu  Thu Apr 15 19:45:22 2010
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Thu, 15 Apr 2010 12:45:22 -0500 (CDT)
Subject: [Rd] R CMD check tells me 'no visible binding
 for	globalvariable ', what does it mean?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk><4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>

On Mon, 12 Apr 2010, William Dunlap wrote:

>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
>> Sent: Monday, April 12, 2010 8:24 AM
>> To: Duncan Murdoch
>> Cc: r-devel; Michael Dewey
>> Subject: Re: [Rd] R CMD check tells me 'no visible binding
>> for globalvariable ', what does it mean?
>>
>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
>> <murdoch at stats.uwo.ca> wrote:
>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
>>>>
>>>> When I run R CMD check on a package I have recently
>> started work on I get
>>>> the following:
>>>>
>>>> * checking R code for possible problems ... NOTE
>>>> addlinear: no visible binding for global variable 'x'
>>>>
>>>> I appreciate that this is only a NOTE and so I assume is
>> R's equivalent of
>>>> 'This is perfectly legal but I wonder whether it is really what you
>>>> intended' but I would like to understand it.
>>>>
>>>> In the relevant function addlinear the following function
>> is defined
>>>> locally:
>>>>
>>>> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
>> (x/(1-x))))}
>>>>
>>>> and then used later in curve
>>>>
>>>> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to =
>> 0.999, add = TRUE)
>>>>
>>>> These are the only occurrences of 'x'.
>>>>
>>>> Is it just telling me that I have never assigned a value
>> to x? Or is it
>>>> more sinister than that? As far as I can tell the function
>> does what I
>>>> intended.
>>>
>>> The curve() function evaluates the first argument in a
>> strange way, and this
>>> confuses the code checking. ?(The variable name "x" is
>> special to curve().)
>>>
>>> I think you can avoid the warning by rewriting that call to
>> curve() as
>>>
>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to
>> = 0.999, add =
>>> TRUE)
>>
>> ...or
>>
>> x <- NULL; rm(x); # Dummy to trick R CMD check
>> curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>
> Or we could come up with a scheme to telling the usage checking functions
> in codetools that some some or all arguments of certain functions
> are evaluated in odd ways so it should not check them.  E.g.,
>   irregularUsage(curve, expr)
>   irregularUsage(lm, subset, formula) # subset and formula arguments of lm
>   irregularUsage(expression, ...) # ... arguments to expression
> Perhaps one could add such indications to the NAMESPACE file
> or to a new file in a package.  The former is kludgy but the
> latter requires changes to the packaging system.
>

This is done at the moment in a very ad hoc way for functions in the
core packages.  I will make a note to add something for curve.  This
is an interesting case, as only the variable 'x' should be viewed as
special for code analysis purposes if I understand the intent in curve
properly.

Providing a mechanism for user functions to be annotated for code
analysis might be useful, and might help in making the handling of
core package functions with special evaluation rulesa little less ad
hloc.  On the other hand I'm not sure I want to do anything that
encourages further use of nonstantard evaluation in new code.

luke

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>>
>> /Henrik
>>
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From Mark.Bravington at csiro.au  Fri Apr 16 02:09:01 2010
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 16 Apr 2010 10:09:01 +1000
Subject: [Rd] R CMD check tells me 'no visible binding
	for	globalvariable ', what does it mean?
In-Reply-To: <alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk><4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>

Speaking as a copious generator of CMD CHECK notes: I don't see that there's a problem to be solved here-- i.e. I don't see why it's worth changing good code or adding conventions just to circumvent CMD CHECK notes. (If the code is bad, of course it should be changed!) As the original poster said, the CMD CHECK note is only a note, not a warning-- it's checking for "*possible* problems". With my packages, especially debug & mvbutils, CHECK issues 100s of lines of "notes", which (after inspection) I don't worry about-- they arise from RCMD CHECK not understanding my code (eg non-default scopings), not from coding errors. I would be very unhappy at having to add enormous amounts of "explanation" to the packages simply to alleviate a non-problem!

Similarly, some compilers give notes about possibly non-initialized variables etc, but these are often a result of the compiler not understanding the code. I do look at them, and decide whether there are problems that need fixing or not-- it's no big deal to ignore them if not useful. Presumably the RCMD CHECK notes are useful to some coders, in which case good; but nothing further really seems needed.

Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

luke at stat.uiowa.edu wrote:
> On Mon, 12 Apr 2010, William Dunlap wrote:
> 
>> 
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
>>> Sent: Monday, April 12, 2010 8:24 AM
>>> To: Duncan Murdoch
>>> Cc: r-devel; Michael Dewey
>>> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
>>> globalvariable ', what does it mean?
>>> 
>>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
>>> <murdoch at stats.uwo.ca> wrote:
>>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
>>>>> 
>>>>> When I run R CMD check on a package I have recently started work
>>>>> on I get the following: 
>>>>> 
>>>>> * checking R code for possible problems ... NOTE
>>>>> addlinear: no visible binding for global variable 'x'
>>>>> 
>>>>> I appreciate that this is only a NOTE and so I assume is R's
>>>>> equivalent of 'This is perfectly legal but I wonder whether it is
>>>>> really what you intended' but I would like to understand it.
>>>>> 
>>>>> In the relevant function addlinear the following function is
>>>>> defined locally: 
>>>>> 
>>>>> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
>>>>> (x/(1-x))))} 
>>>>> 
>>>>> and then used later in curve
>>>>> 
>>>>> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999,
>>>>> add = TRUE) 
>>>>> 
>>>>> These are the only occurrences of 'x'.
>>>>> 
>>>>> Is it just telling me that I have never assigned a value to x? Or
>>>>> is it more sinister than that? As far as I can tell the function
>>>>> does what I intended.
>>>> 
>>>> The curve() function evaluates the first argument in a strange
>>>> way, and this confuses the code checking. ?(The variable name "x"
>>>> is special to curve().) 
>>>> 
>>>> I think you can avoid the warning by rewriting that call to
>>>> curve() as 
>>>> 
>>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
>>>> 0.999, add = TRUE)
>>> 
>>> ...or
>>> 
>>> x <- NULL; rm(x); # Dummy to trick R CMD check curve(orfun(x,
>>> exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>> 
>> Or we could come up with a scheme to telling the usage checking
>> functions in codetools that some some or all arguments of certain
>> functions are evaluated in odd ways so it should not check them. 
>>   E.g.,   irregularUsage(curve, expr) irregularUsage(lm, subset,
>>   formula) # subset and formula arguments of lm
>> irregularUsage(expression, ...) # ... arguments to expression 
>> Perhaps one could add such indications to the NAMESPACE file or to a
>> new file in a package.  The former is kludgy but the latter requires
>> changes to the packaging system.
>> 
> 
> This is done at the moment in a very ad hoc way for functions in the
> core packages.  I will make a note to add something for curve.  This
> is an interesting case, as only the variable 'x' should be viewed as
> special for code analysis purposes if I understand the intent in
> curve properly.    
> 
> Providing a mechanism for user functions to be annotated for code
> analysis might be useful, and might help in making the handling of
> core package functions with special evaluation rulesa little less ad
> hloc.  On the other hand I'm not sure I want to do anything that
> encourages further use of nonstantard evaluation in new code.    
> 
> luke
> 
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>>> 
>>> /Henrik
>>> 
>>>> 
>>>> Duncan Murdoch
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

From hb at stat.berkeley.edu  Fri Apr 16 10:38:37 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 16 Apr 2010 10:38:37 +0200
Subject: [Rd] R CMD check tells me 'no visible binding for
	globalvariable ', what does it mean?
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
	<4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>
	<62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>
Message-ID: <p2m59d7961d1004160138h8533e07fk440efd44ff73619@mail.gmail.com>

I think what people are also thinking about is that the policy for
publishing a package on CRAN is that it have to pass R CMD check with
no errors, warnings *or* notes.  So, in that sense notes are no
different from warnings.

At least that's why I go about and add some rare ad hoc code patching
in my code.

/Henrik

On Fri, Apr 16, 2010 at 2:09 AM,  <Mark.Bravington at csiro.au> wrote:
> Speaking as a copious generator of CMD CHECK notes: I don't see that there's a problem to be solved here-- i.e. I don't see why it's worth changing good code or adding conventions just to circumvent CMD CHECK notes. (If the code is bad, of course it should be changed!) As the original poster said, the CMD CHECK note is only a note, not a warning-- it's checking for "*possible* problems". With my packages, especially debug & mvbutils, CHECK issues 100s of lines of "notes", which (after inspection) I don't worry about-- they arise from RCMD CHECK not understanding my code (eg non-default scopings), not from coding errors. I would be very unhappy at having to add enormous amounts of "explanation" to the packages simply to alleviate a non-problem!
>
> Similarly, some compilers give notes about possibly non-initialized variables etc, but these are often a result of the compiler not understanding the code. I do look at them, and decide whether there are problems that need fixing or not-- it's no big deal to ignore them if not useful. Presumably the RCMD CHECK notes are useful to some coders, in which case good; but nothing further really seems needed.
>
> Mark
>
> --
> Mark Bravington
> CSIRO Mathematical & Information Sciences
> Marine Laboratory
> Castray Esplanade
> Hobart 7001
> TAS
>
> ph (+61) 3 6232 5118
> fax (+61) 3 6232 5012
> mob (+61) 438 315 623
>
> luke at stat.uiowa.edu wrote:
>> On Mon, 12 Apr 2010, William Dunlap wrote:
>>
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
>>>> Sent: Monday, April 12, 2010 8:24 AM
>>>> To: Duncan Murdoch
>>>> Cc: r-devel; Michael Dewey
>>>> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
>>>> globalvariable ', what does it mean?
>>>>
>>>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
>>>> <murdoch at stats.uwo.ca> wrote:
>>>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
>>>>>>
>>>>>> When I run R CMD check on a package I have recently started work
>>>>>> on I get the following:
>>>>>>
>>>>>> * checking R code for possible problems ... NOTE
>>>>>> addlinear: no visible binding for global variable 'x'
>>>>>>
>>>>>> I appreciate that this is only a NOTE and so I assume is R's
>>>>>> equivalent of 'This is perfectly legal but I wonder whether it is
>>>>>> really what you intended' but I would like to understand it.
>>>>>>
>>>>>> In the relevant function addlinear the following function is
>>>>>> defined locally:
>>>>>>
>>>>>> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
>>>>>> (x/(1-x))))}
>>>>>>
>>>>>> and then used later in curve
>>>>>>
>>>>>> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999,
>>>>>> add = TRUE)
>>>>>>
>>>>>> These are the only occurrences of 'x'.
>>>>>>
>>>>>> Is it just telling me that I have never assigned a value to x? Or
>>>>>> is it more sinister than that? As far as I can tell the function
>>>>>> does what I intended.
>>>>>
>>>>> The curve() function evaluates the first argument in a strange
>>>>> way, and this confuses the code checking. ?(The variable name "x"
>>>>> is special to curve().)
>>>>>
>>>>> I think you can avoid the warning by rewriting that call to
>>>>> curve() as
>>>>>
>>>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
>>>>> 0.999, add = TRUE)
>>>>
>>>> ...or
>>>>
>>>> x <- NULL; rm(x); # Dummy to trick R CMD check curve(orfun(x,
>>>> exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>>>
>>> Or we could come up with a scheme to telling the usage checking
>>> functions in codetools that some some or all arguments of certain
>>> functions are evaluated in odd ways so it should not check them.
>>> ? E.g., ? irregularUsage(curve, expr) irregularUsage(lm, subset,
>>> ? formula) # subset and formula arguments of lm
>>> irregularUsage(expression, ...) # ... arguments to expression
>>> Perhaps one could add such indications to the NAMESPACE file or to a
>>> new file in a package. ?The former is kludgy but the latter requires
>>> changes to the packaging system.
>>>
>>
>> This is done at the moment in a very ad hoc way for functions in the
>> core packages. ?I will make a note to add something for curve. ?This
>> is an interesting case, as only the variable 'x' should be viewed as
>> special for code analysis purposes if I understand the intent in
>> curve properly.
>>
>> Providing a mechanism for user functions to be annotated for code
>> analysis might be useful, and might help in making the handling of
>> core package functions with special evaluation rulesa little less ad
>> hloc. ?On the other hand I'm not sure I want to do anything that
>> encourages further use of nonstantard evaluation in new code.
>>
>> luke
>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>>>
>>>> /Henrik
>>>>
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jfox at mcmaster.ca  Fri Apr 16 14:40:34 2010
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 16 Apr 2010 08:40:34 -0400
Subject: [Rd] R CMD check tells me 'no visible binding
	for	globalvariable ', what does it mean?
In-Reply-To: <p2m59d7961d1004160138h8533e07fk440efd44ff73619@mail.gmail.com>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>	<4BC3375C.4060007@stats.uwo.ca>	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>	<alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>	<62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>
	<p2m59d7961d1004160138h8533e07fk440efd44ff73619@mail.gmail.com>
Message-ID: <004501cadd62$02550420$06ff0c60$@ca>

Dear all,

I think that "notes" were introduced precisely to differentiate between
situations that may be innocuous and those that are more serious, the latter
producing "warnings" and "errors." The Rcmdr package, for example, generates
a whack of notes for code that works correctly and that I don't know how to
rewrite to get rid of the notes -- not to say that it would necessarily be
impossible to do so. Eliminating all packages that produce R CMD check notes
from CRAN is not a good idea, in my opinion.

Best,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of Henrik Bengtsson
> Sent: April-16-10 4:39 AM
> To: Mark.Bravington
> Cc: murdoch; luke; r-devel; info
> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
globalvariable
> ', what does it mean?
> 
> I think what people are also thinking about is that the policy for
> publishing a package on CRAN is that it have to pass R CMD check with
> no errors, warnings *or* notes.  So, in that sense notes are no
> different from warnings.
> 
> At least that's why I go about and add some rare ad hoc code patching
> in my code.
> 
> /Henrik
> 
> On Fri, Apr 16, 2010 at 2:09 AM,  <Mark.Bravington at csiro.au> wrote:
> > Speaking as a copious generator of CMD CHECK notes: I don't see that
> there's a problem to be solved here-- i.e. I don't see why it's worth
> changing good code or adding conventions just to circumvent CMD CHECK
notes.
> (If the code is bad, of course it should be changed!) As the original
poster
> said, the CMD CHECK note is only a note, not a warning-- it's checking for
> "*possible* problems". With my packages, especially debug & mvbutils,
CHECK
> issues 100s of lines of "notes", which (after inspection) I don't worry
> about-- they arise from RCMD CHECK not understanding my code (eg
non-default
> scopings), not from coding errors. I would be very unhappy at having to
add
> enormous amounts of "explanation" to the packages simply to alleviate a
non-
> problem!
> >
> > Similarly, some compilers give notes about possibly non-initialized
> variables etc, but these are often a result of the compiler not
understanding
> the code. I do look at them, and decide whether there are problems that
need
> fixing or not-- it's no big deal to ignore them if not useful. Presumably
the
> RCMD CHECK notes are useful to some coders, in which case good; but
nothing
> further really seems needed.
> >
> > Mark
> >
> > --
> > Mark Bravington
> > CSIRO Mathematical & Information Sciences
> > Marine Laboratory
> > Castray Esplanade
> > Hobart 7001
> > TAS
> >
> > ph (+61) 3 6232 5118
> > fax (+61) 3 6232 5012
> > mob (+61) 438 315 623
> >
> > luke at stat.uiowa.edu wrote:
> >> On Mon, 12 Apr 2010, William Dunlap wrote:
> >>
> >>>
> >>>> -----Original Message-----
> >>>> From: r-devel-bounces at r-project.org
> >>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
> >>>> Sent: Monday, April 12, 2010 8:24 AM
> >>>> To: Duncan Murdoch
> >>>> Cc: r-devel; Michael Dewey
> >>>> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
> >>>> globalvariable ', what does it mean?
> >>>>
> >>>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
> >>>> <murdoch at stats.uwo.ca> wrote:
> >>>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
> >>>>>>
> >>>>>> When I run R CMD check on a package I have recently started work
> >>>>>> on I get the following:
> >>>>>>
> >>>>>> * checking R code for possible problems ... NOTE
> >>>>>> addlinear: no visible binding for global variable 'x'
> >>>>>>
> >>>>>> I appreciate that this is only a NOTE and so I assume is R's
> >>>>>> equivalent of 'This is perfectly legal but I wonder whether it is
> >>>>>> really what you intended' but I would like to understand it.
> >>>>>>
> >>>>>> In the relevant function addlinear the following function is
> >>>>>> defined locally:
> >>>>>>
> >>>>>> ? ?orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
> >>>>>> (x/(1-x))))}
> >>>>>>
> >>>>>> and then used later in curve
> >>>>>>
> >>>>>> ? ? ? curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999,
> >>>>>> add = TRUE)
> >>>>>>
> >>>>>> These are the only occurrences of 'x'.
> >>>>>>
> >>>>>> Is it just telling me that I have never assigned a value to x? Or
> >>>>>> is it more sinister than that? As far as I can tell the function
> >>>>>> does what I intended.
> >>>>>
> >>>>> The curve() function evaluates the first argument in a strange
> >>>>> way, and this confuses the code checking. ?(The variable name "x"
> >>>>> is special to curve().)
> >>>>>
> >>>>> I think you can avoid the warning by rewriting that call to
> >>>>> curve() as
> >>>>>
> >>>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
> >>>>> 0.999, add = TRUE)
> >>>>
> >>>> ...or
> >>>>
> >>>> x <- NULL; rm(x); # Dummy to trick R CMD check curve(orfun(x,
> >>>> exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
> >>>
> >>> Or we could come up with a scheme to telling the usage checking
> >>> functions in codetools that some some or all arguments of certain
> >>> functions are evaluated in odd ways so it should not check them.
> >>> ? E.g., ? irregularUsage(curve, expr) irregularUsage(lm, subset,
> >>> ? formula) # subset and formula arguments of lm
> >>> irregularUsage(expression, ...) # ... arguments to expression
> >>> Perhaps one could add such indications to the NAMESPACE file or to a
> >>> new file in a package. ?The former is kludgy but the latter requires
> >>> changes to the packaging system.
> >>>
> >>
> >> This is done at the moment in a very ad hoc way for functions in the
> >> core packages. ?I will make a note to add something for curve. ?This
> >> is an interesting case, as only the variable 'x' should be viewed as
> >> special for code analysis purposes if I understand the intent in
> >> curve properly.
> >>
> >> Providing a mechanism for user functions to be annotated for code
> >> analysis might be useful, and might help in making the handling of
> >> core package functions with special evaluation rulesa little less ad
> >> hloc. ?On the other hand I'm not sure I want to do anything that
> >> encourages further use of nonstantard evaluation in new code.
> >>
> >> luke
> >>
> >>> Bill Dunlap
> >>> Spotfire, TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>>
> >>>>
> >>>> /Henrik
> >>>>
> >>>>>
> >>>>> Duncan Murdoch
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Apr 16 15:22:53 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Apr 2010 09:22:53 -0400
Subject: [Rd] R CMD check tells me 'no visible binding for
	globalvariable ', what does it mean?
In-Reply-To: <p2m59d7961d1004160138h8533e07fk440efd44ff73619@mail.gmail.com>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
	<4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>
	<62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>
	<p2m59d7961d1004160138h8533e07fk440efd44ff73619@mail.gmail.com>
Message-ID: <D339AF0D-50D9-4EE9-A07C-0D404B046F42@r-project.org>


On Apr 16, 2010, at 4:38 AM, Henrik Bengtsson wrote:

> I think what people are also thinking about is that the policy for
> publishing a package on CRAN is that it have to pass R CMD check with
> no errors, warnings *or* notes.  

Can you cite your reference, please? I see only (R-ext 1.5 Submitting a package to CRAN):

"Please ensure that you can run through the complete procedure with only warnings that you understand and have reasons not to eliminate. In principle, packages must pass R CMD check without warnings to be admitted to the main CRAN package area. If there are warnings you cannot eliminate (for example because you believe them to be spurious) send an explanatory note with your submission."

It talks explicitly about warnings, notes are not mentioned at all... That said, you should examine all notes and make sure they are not indications of problems.

Cheers,
Simon



> So, in that sense notes are no
> different from warnings.
> 
> At least that's why I go about and add some rare ad hoc code patching
> in my code.
> 
> /Henrik
> 
> On Fri, Apr 16, 2010 at 2:09 AM,  <Mark.Bravington at csiro.au> wrote:
>> Speaking as a copious generator of CMD CHECK notes: I don't see that there's a problem to be solved here-- i.e. I don't see why it's worth changing good code or adding conventions just to circumvent CMD CHECK notes. (If the code is bad, of course it should be changed!) As the original poster said, the CMD CHECK note is only a note, not a warning-- it's checking for "*possible* problems". With my packages, especially debug & mvbutils, CHECK issues 100s of lines of "notes", which (after inspection) I don't worry about-- they arise from RCMD CHECK not understanding my code (eg non-default scopings), not from coding errors. I would be very unhappy at having to add enormous amounts of "explanation" to the packages simply to alleviate a non-problem!
>> 
>> Similarly, some compilers give notes about possibly non-initialized variables etc, but these are often a result of the compiler not understanding the code. I do look at them, and decide whether there are problems that need fixing or not-- it's no big deal to ignore them if not useful. Presumably the RCMD CHECK notes are useful to some coders, in which case good; but nothing further really seems needed.
>> 
>> Mark
>> 
>> --
>> Mark Bravington
>> CSIRO Mathematical & Information Sciences
>> Marine Laboratory
>> Castray Esplanade
>> Hobart 7001
>> TAS
>> 
>> ph (+61) 3 6232 5118
>> fax (+61) 3 6232 5012
>> mob (+61) 438 315 623
>> 
>> luke at stat.uiowa.edu wrote:
>>> On Mon, 12 Apr 2010, William Dunlap wrote:
>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org
>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
>>>>> Sent: Monday, April 12, 2010 8:24 AM
>>>>> To: Duncan Murdoch
>>>>> Cc: r-devel; Michael Dewey
>>>>> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
>>>>> globalvariable ', what does it mean?
>>>>> 
>>>>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
>>>>> <murdoch at stats.uwo.ca> wrote:
>>>>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
>>>>>>> 
>>>>>>> When I run R CMD check on a package I have recently started work
>>>>>>> on I get the following:
>>>>>>> 
>>>>>>> * checking R code for possible problems ... NOTE
>>>>>>> addlinear: no visible binding for global variable 'x'
>>>>>>> 
>>>>>>> I appreciate that this is only a NOTE and so I assume is R's
>>>>>>> equivalent of 'This is perfectly legal but I wonder whether it is
>>>>>>> really what you intended' but I would like to understand it.
>>>>>>> 
>>>>>>> In the relevant function addlinear the following function is
>>>>>>> defined locally:
>>>>>>> 
>>>>>>>    orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
>>>>>>> (x/(1-x))))}
>>>>>>> 
>>>>>>> and then used later in curve
>>>>>>> 
>>>>>>>       curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999,
>>>>>>> add = TRUE)
>>>>>>> 
>>>>>>> These are the only occurrences of 'x'.
>>>>>>> 
>>>>>>> Is it just telling me that I have never assigned a value to x? Or
>>>>>>> is it more sinister than that? As far as I can tell the function
>>>>>>> does what I intended.
>>>>>> 
>>>>>> The curve() function evaluates the first argument in a strange
>>>>>> way, and this confuses the code checking.  (The variable name "x"
>>>>>> is special to curve().)
>>>>>> 
>>>>>> I think you can avoid the warning by rewriting that call to
>>>>>> curve() as
>>>>>> 
>>>>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
>>>>>> 0.999, add = TRUE)
>>>>> 
>>>>> ...or
>>>>> 
>>>>> x <- NULL; rm(x); # Dummy to trick R CMD check curve(orfun(x,
>>>>> exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
>>>> 
>>>> Or we could come up with a scheme to telling the usage checking
>>>> functions in codetools that some some or all arguments of certain
>>>> functions are evaluated in odd ways so it should not check them.
>>>>   E.g.,   irregularUsage(curve, expr) irregularUsage(lm, subset,
>>>>   formula) # subset and formula arguments of lm
>>>> irregularUsage(expression, ...) # ... arguments to expression
>>>> Perhaps one could add such indications to the NAMESPACE file or to a
>>>> new file in a package.  The former is kludgy but the latter requires
>>>> changes to the packaging system.
>>>> 
>>> 
>>> This is done at the moment in a very ad hoc way for functions in the
>>> core packages.  I will make a note to add something for curve.  This
>>> is an interesting case, as only the variable 'x' should be viewed as
>>> special for code analysis purposes if I understand the intent in
>>> curve properly.
>>> 
>>> Providing a mechanism for user functions to be annotated for code
>>> analysis might be useful, and might help in making the handling of
>>> core package functions with special evaluation rulesa little less ad
>>> hloc.  On the other hand I'm not sure I want to do anything that
>>> encourages further use of nonstantard evaluation in new code.
>>> 
>>> luke
>>> 
>>>> Bill Dunlap
>>>> Spotfire, TIBCO Software
>>>> wdunlap tibco.com
>>>> 
>>>> 
>>>>> 
>>>>> /Henrik
>>>>> 
>>>>>> 
>>>>>> Duncan Murdoch
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From therneau at mayo.edu  Fri Apr 16 16:16:02 2010
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 16 Apr 2010 09:16:02 -0500
Subject: [Rd] R CMD check tells me 'no visible binding for
	globalvariable'
In-Reply-To: <mailman.27.1271412010.6962.r-devel@r-project.org>
References: <mailman.27.1271412010.6962.r-devel@r-project.org>
Message-ID: <5DBE21404FF5E54C826BE1040C2CD031C918EE@msgebe52.mfad.mfroot.org>

Henrik wrote: 

I think what people are also thinking about is that the policy for
publishing a package on CRAN is that it have to pass R CMD check with
no errors, warnings *or* notes.  So, in that sense notes are no
different from warnings.
---------------------------------

Getting rid of these notes would be very hard in the survival package.
The population survival routines (survexp, pyears) that have to deal
with dates try to be very accommodating wrt the date format the user
chose, so have constructions like
   if (user date looks like a chron object) {
         calculation using chron functions
         }
   else if (is from the date package) {
        use mdy.date }
   else if (Date object)

etc

   Most of the functions inside the {} cause a warning note because of
course the necessary packages for each case are not present when
survival is built.  Since we deal with medical studies that span
multiple years or even decades, I and others in my group benefit
directly from this date handling: it was not added solely from a
humanitarian impulse.
   
  It's a minor nuisance, since I have to read through the messages after
each build to see if something I actually do need to worry about turns
up.  It has happened, in which case I'm thankful for the message.
(Although it would be nice if there were a way to generate more context.
Once one was for an undefined variable 'n', which was not easy to find
using a text editor.)

Terry Therneau

   


From ripley at stats.ox.ac.uk  Fri Apr 16 16:56:07 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Apr 2010 15:56:07 +0100 (BST)
Subject: [Rd] R CMD check tells me 'no visible binding for
 globalvariable'
In-Reply-To: <5DBE21404FF5E54C826BE1040C2CD031C918EE@msgebe52.mfad.mfroot.org>
References: <mailman.27.1271412010.6962.r-devel@r-project.org>
	<5DBE21404FF5E54C826BE1040C2CD031C918EE@msgebe52.mfad.mfroot.org>
Message-ID: <alpine.LFD.2.00.1004161548280.22295@localhost>

On Fri, 16 Apr 2010, Therneau, Terry M., Ph.D. wrote:

> 'Henrik' wrote:
>
> I think what people are also thinking about is that the policy for
> publishing a package on CRAN is that it have to pass R CMD check with
> no errors, warnings *or* notes.  So, in that sense notes are no
> different from warnings.

I think that policy is a figment of his imagination.  'NOTE' was 
introduced to allow tentative warnings: we for example note .Rd errors 
that we can correct and warn (so far) on those we cannot.

> ---------------------------------
>
> Getting rid of these notes would be very hard in the survival package.
> The population survival routines (survexp, pyears) that have to deal
> with dates try to be very accommodating wrt the date format the user
> chose, so have constructions like
>   if (user date looks like a chron object) {
>         calculation using chron functions
>         }
>   else if (is from the date package) {
>        use mdy.date }
>   else if (Date object)
>
> etc
>
>   Most of the functions inside the {} cause a warning note because of
> course the necessary packages for each case are not present when
> survival is built.  Since we deal with medical studies that span
> multiple years or even decades, I and others in my group benefit
> directly from this date handling: it was not added solely from a
> humanitarian impulse.
>
>  It's a minor nuisance, since I have to read through the messages after
> each build to see if something I actually do need to worry about turns
> up.  It has happened, in which case I'm thankful for the message.
> (Although it would be nice if there were a way to generate more context.
> Once one was for an undefined variable 'n', which was not easy to find
> using a text editor.)

We do load all the Depends and Suggests packages when doing the 
codetools checks, so I think that

Suggests: date, chron, timeDate

would solve this. It leaves

predict.coxph: no visible global function definition for ?labels.lm?
predict.coxph: no visible global function definition for ?Build.terms?
predict.survreg: no visible global function definition for ?labels.lm?
predict.survreg: no visible global function definition for  ?Build.terms?
survpenal.fit: no visible global function definition for ?new.frame?
survpenal.fit: possible error in get("coxlist1", frame = rho): unused
   argument(s) (frame = rho)
survpenal.fit: possible error in get("coxlist2", frame = rho): unused
   argument(s) (frame = rho)
survreg.fit: no visible global function definition for ?new.frame?

which are I think all from S-Plus specific code.

Brian Ripley


>
> Terry Therneau
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From tlumley at u.washington.edu  Fri Apr 16 17:51:57 2010
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 16 Apr 2010 08:51:57 -0700 (PDT)
Subject: [Rd] R CMD check tells me 'no visible binding for
 globalvariable ', what does it mean?
In-Reply-To: <D339AF0D-50D9-4EE9-A07C-0D404B046F42@r-project.org>
Message-ID: <alpine.LRH.2.01.1004160851570.28111@hymn32.u.washington.edu>

On Fri, 16 Apr 2010, Simon Urbanek wrote:

>
> On Apr 16, 2010, at 4:38 AM, Henrik Bengtsson wrote:
>
>> I think what people are also thinking about is that the policy for
>> publishing a package on CRAN is that it have to pass R CMD check with
>> no errors, warnings *or* notes.
>
> Can you cite your reference, please? I see only (R-ext 1.5 Submitting a package to CRAN):
>
> "Please ensure that you can run through the complete procedure with only warnings that you understand and have reasons not to eliminate. In principle, packages must pass R CMD check without warnings to be admitted to the main CRAN package area. If there are warnings you cannot eliminate (for example because you believe them to be spurious) send an explanatory note with your submission."
>
> It talks explicitly about warnings, notes are not mentioned at all... That said, you should examine all notes and make sure they are not indications of problems.
>

In my experience, if a package is new or previously checked without notes, the CRAN maintainers will likely ask you to look at them to make sure they aren't problems, but there isn't any difficulty in getting a package on CRAN if it has notes.  A whole lot of packages on CRAN have notes even when checked on r-release.

CMD check notes are the R equivalent of old-time lint warnings in C, and as the First Commandment says:
 	 Thou shalt run lint frequently and study its pronouncements with care, for verily its perception and judgement oft exceed thine.
and the prophet (Henry Spencer) expands on this:
  ``Study'' doth not mean mindless zeal to eradicate every byte of lint output-if for no other reason, because thou just canst not shut it up about some things-but that thou should know the cause of its unhappiness and understand what worrisome sign it tries to speak of.


          -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ligges at statistik.tu-dortmund.de  Fri Apr 16 18:05:07 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 16 Apr 2010 18:05:07 +0200
Subject: [Rd] winbuilder down
Message-ID: <4BC88AB3.9070908@statistik.tu-dortmund.de>

Please note that the "winbuilder" service will be down during the 
weekend (at least until sunday) due work on the power supply of the 
building.

Best wishes,
Uwe Ligges


From hb at stat.berkeley.edu  Fri Apr 16 19:03:20 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 16 Apr 2010 19:03:20 +0200
Subject: [Rd] R CMD check tells me 'no visible binding for
	globalvariable ', what does it mean?
In-Reply-To: <alpine.LRH.2.01.1004160851570.28111@hymn32.u.washington.edu>
References: <D339AF0D-50D9-4EE9-A07C-0D404B046F42@r-project.org>
	<alpine.LRH.2.01.1004160851570.28111@hymn32.u.washington.edu>
Message-ID: <u2u59d7961d1004161003sac3c1f63se8a8b2cf47ae5762@mail.gmail.com>

On Fri, Apr 16, 2010 at 5:51 PM, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 16 Apr 2010, Simon Urbanek wrote:
>
>>
>> On Apr 16, 2010, at 4:38 AM, Henrik Bengtsson wrote:
>>
>>> I think what people are also thinking about is that the policy for
>>> publishing a package on CRAN is that it have to pass R CMD check with
>>> no errors, warnings *or* notes.

WRONG: As already said by other, it is indeed possible to get packages
with 'notes' onto CRAN.

I have at some point in history became to believe this, but I went
back in my submission log and I only found one case and it is was more
Kurt H. kindly suggesting that I should fix an incorrectly formatted
license (reported as a NOTE).  Thanks for making me aware of this.

Sorry for adding noise!

/Henrik


>>
>> Can you cite your reference, please? I see only (R-ext 1.5 Submitting a
>> package to CRAN):
>>
>> "Please ensure that you can run through the complete procedure with only
>> warnings that you understand and have reasons not to eliminate. In
>> principle, packages must pass R CMD check without warnings to be admitted to
>> the main CRAN package area. If there are warnings you cannot eliminate (for
>> example because you believe them to be spurious) send an explanatory note
>> with your submission."
>>
>> It talks explicitly about warnings, notes are not mentioned at all... That
>> said, you should examine all notes and make sure they are not indications of
>> problems.
>>
>
> In my experience, if a package is new or previously checked without notes,
> the CRAN maintainers will likely ask you to look at them to make sure they
> aren't problems, but there isn't any difficulty in getting a package on CRAN
> if it has notes. ?A whole lot of packages on CRAN have notes even when
> checked on r-release.
>
> CMD check notes are the R equivalent of old-time lint warnings in C, and as
> the First Commandment says:
> ? ? ? ? Thou shalt run lint frequently and study its pronouncements with
> care, for verily its perception and judgement oft exceed thine.
> and the prophet (Henry Spencer) expands on this:
> ?``Study'' doth not mean mindless zeal to eradicate every byte of lint
> output-if for no other reason, because thou just canst not shut it up about
> some things-but that thou should know the cause of its unhappiness and
> understand what worrisome sign it tries to speak of.



>
>
> ? ? ? ? -thomas
>
> Thomas Lumley ? ? ? ? ? ? ? ? ? Assoc. Professor, Biostatistics
> tlumley at u.washington.edu ? ? ? ?University of Washington, Seattle
>
>


From baptiste.auguie at googlemail.com  Sat Apr 17 12:34:22 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sat, 17 Apr 2010 12:34:22 +0200
Subject: [Rd] grid.cap() requires more time?
Message-ID: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>

Dear all,

I am puzzled by the following behavior of the new grid.cap() function,
which appears to run out of time when capturing the output of a
graphic. It works fine if I introduce a Sys.sleep(1) before executing
more code,

library(grid)

quartz()
grid.circle(gp=gpar(fill="black"))
gg <- grid.cap()
dev.new()
grid.raster(gg) ## completely blank
gg[gg!="white"] ## indeed

quartz()
grid.circle(gp=gpar(fill="black"))
Sys.sleep(1)
gg <- grid.cap()
dev.new()
grid.raster(gg) ## OK
gg[gg!="white"]

I tried to see if the problem was limited to the quartz() device but
for some reason the x11() device is not working for me in this R
version,

capabilities(what = NULL)
    jpeg      png     tiff    tcltk      X11     aqua http/ftp
sockets   libxml     fifo   cledit    iconv      NLS  profmem    cairo
    TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
Warning message:
In doTryCatch(return(expr), name, parentenv, handler) :
  unable to load shared library
'/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
  dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
  Referenced from:
/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
  Reason: Incompatible library version: R_X11.so requires version
42.0.0 or later, but libpng12.0.dylib provides version 36.0.0

sessionInfo()
R version 2.11.0 RC (2010-04-16 r51754)
i386-apple-darwin9.8.0

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets
methods   base

loaded via a namespace (and not attached):
[1] tools_2.11.0

I would appreciate if someone could confirm this behavior. Pointers to
a fix for the x11() device on my machine are also welcome!

Best regards,

baptiste


From baptiste.auguie at googlemail.com  Sat Apr 17 12:44:44 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sat, 17 Apr 2010 12:44:44 +0200
Subject: [Rd] grid.cap() requires more time?
In-Reply-To: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
References: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
Message-ID: <v2ude4e29f51004170344lb6ee88f6id54f5358fb4e5610@mail.gmail.com>

I just figured out what the strange "noise" consisted of in the
captured output of my previous example, and this is another source of
curiosity for me,

quartz(width=0.1, height=0.1)
gg <- grid.cap()
dev.new()
grid.raster(gg)

Should grid.cap() really capture the resizing handle of the quartz() window?

Best regards,

baptiste

On 17 April 2010 12:34, baptiste auguie <baptiste.auguie at googlemail.com> wrote:
> Dear all,
>
> I am puzzled by the following behavior of the new grid.cap() function,
> which appears to run out of time when capturing the output of a
> graphic. It works fine if I introduce a Sys.sleep(1) before executing
> more code,
>
> library(grid)
>
> quartz()
> grid.circle(gp=gpar(fill="black"))
> gg <- grid.cap()
> dev.new()
> grid.raster(gg) ## completely blank
> gg[gg!="white"] ## indeed
>
> quartz()
> grid.circle(gp=gpar(fill="black"))
> Sys.sleep(1)
> gg <- grid.cap()
> dev.new()
> grid.raster(gg) ## OK
> gg[gg!="white"]
>
> I tried to see if the problem was limited to the quartz() device but
> for some reason the x11() device is not working for me in this R
> version,
>
> capabilities(what = NULL)
> ? ?jpeg ? ? ?png ? ? tiff ? ?tcltk ? ? ?X11 ? ? aqua http/ftp
> sockets ? libxml ? ? fifo ? cledit ? ?iconv ? ? ?NLS ?profmem ? ?cairo
> ? ?TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ?FALSE ? ? TRUE ? ? TRUE
> TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE
> Warning message:
> In doTryCatch(return(expr), name, parentenv, handler) :
> ?unable to load shared library
> '/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
> ?dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
> 6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
> ?Referenced from:
> /Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
> ?Reason: Incompatible library version: R_X11.so requires version
> 42.0.0 or later, but libpng12.0.dylib provides version 36.0.0
>
> sessionInfo()
> R version 2.11.0 RC (2010-04-16 r51754)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] grid ? ? ?stats ? ? graphics ?grDevices utils ? ? datasets
> methods ? base
>
> loaded via a namespace (and not attached):
> [1] tools_2.11.0
>
> I would appreciate if someone could confirm this behavior. Pointers to
> a fix for the x11() device on my machine are also welcome!
>
> Best regards,
>
> baptiste
>


From simon.urbanek at r-project.org  Sat Apr 17 18:51:43 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 17 Apr 2010 12:51:43 -0400
Subject: [Rd] grid.cap() requires more time?
In-Reply-To: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
References: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
Message-ID: <9FF50889-4C38-4AEF-A0C5-BD6BF8535B72@r-project.org>

Baptiste,

first, there is a mailing list specifically for Mac questions - R-SIG-Mac.

Now to your post - grid.cap captures the screen of the device which has two implications here:

a) Quartz is asynchronous -- i.e. is doesn't actually draw the content on screen until you're finished with drawing (for efficiency). Unfortunately R has no provision to tell the graphics device that it's done with drawing (you can always add another lines() etc.) so Quartz is simply guessing by measuring the time between draw commands. So when you run grid.cap while the output has not been drawn yet (i.e. immediately after the last drawing command) it will be empty as there is no content yet since Quartz is waiting for the end.

b) it will contain the resize mark because it is a screen shot so the mark is actually part of it (this is intentional).

If what you really want is a bitmap from the device, it's better to use quartz.save instead (followed by readPNG if you want the bitmap as raster) -- that actually re-runs the plot in a separate quartz device that is not on-screen so neither of the above are an issue. 

That said, you can file a) as a bug against Mac version of R (at https://bugs.r-project.org/ ) since grid.cap should actually trigger the flush before it does the capture. I cannot promise that the fix will make it to 2.11.0, though, because it may be non-trivial to trigger the asynchronous flush and wait for it without blocking something (I'll have to look).

Thanks,
Simon


On Apr 17, 2010, at 6:34 AM, baptiste auguie wrote:

> Dear all,
> 
> I am puzzled by the following behavior of the new grid.cap() function,
> which appears to run out of time when capturing the output of a
> graphic. It works fine if I introduce a Sys.sleep(1) before executing
> more code,
> 
> library(grid)
> 
> quartz()
> grid.circle(gp=gpar(fill="black"))
> gg <- grid.cap()
> dev.new()
> grid.raster(gg) ## completely blank
> gg[gg!="white"] ## indeed
> 
> quartz()
> grid.circle(gp=gpar(fill="black"))
> Sys.sleep(1)
> gg <- grid.cap()
> dev.new()
> grid.raster(gg) ## OK
> gg[gg!="white"]
> 
> I tried to see if the problem was limited to the quartz() device but
> for some reason the x11() device is not working for me in this R
> version,
> 
> capabilities(what = NULL)
>    jpeg      png     tiff    tcltk      X11     aqua http/ftp
> sockets   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>    TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
> TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> Warning message:
> In doTryCatch(return(expr), name, parentenv, handler) :
>  unable to load shared library
> '/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
>  dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
> 6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
>  Referenced from:
> /Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
>  Reason: Incompatible library version: R_X11.so requires version
> 42.0.0 or later, but libpng12.0.dylib provides version 36.0.0
> 
> sessionInfo()
> R version 2.11.0 RC (2010-04-16 r51754)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.11.0
> 
> I would appreciate if someone could confirm this behavior. Pointers to
> a fix for the x11() device on my machine are also welcome!
> 
> Best regards,
> 
> baptiste
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From baptiste.auguie at googlemail.com  Sat Apr 17 20:43:12 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sat, 17 Apr 2010 20:43:12 +0200
Subject: [Rd] grid.cap() requires more time?
In-Reply-To: <9FF50889-4C38-4AEF-A0C5-BD6BF8535B72@r-project.org>
References: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
	<9FF50889-4C38-4AEF-A0C5-BD6BF8535B72@r-project.org>
Message-ID: <m2sde4e29f51004171143q29bb45beia05a949702538ff5@mail.gmail.com>

Hi,

On 17 April 2010 18:51, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Baptiste,
>
> first, there is a mailing list specifically for Mac questions - R-SIG-Mac.
>

I wasn't sure if it was Mac-specific (OK, quartz() is but I could not
test x11()).

> Now to your post - grid.cap captures the screen of the device which has two implications here:
>
> a) Quartz is asynchronous -- i.e. is doesn't actually draw the content on screen until you're finished with drawing (for efficiency). Unfortunately R has no provision to tell the graphics device that it's done with drawing (you can always add another lines() etc.) so Quartz is simply guessing by measuring the time between draw commands. So when you run grid.cap while the output has not been drawn yet (i.e. immediately after the last drawing command) it will be empty as there is no content yet since Quartz is waiting for the end.

OK, that makes sense.

>
> b) it will contain the resize mark because it is a screen shot so the mark is actually part of it (this is intentional).

This design decision surprises me. Would it be possible to have an
option not to capture this mark as well?

>
> If what you really want is a bitmap from the device, it's better to use quartz.save instead (followed by readPNG if you want the bitmap as raster) -- that actually re-runs the plot in a separate quartz device that is not on-screen so neither of the above are an issue.

I thought the aim of grid.cap was to make it easier to capture a
bitmap copy (no need to create an external file). Is a screenshot more
useful?

>
> That said, you can file a) as a bug against Mac version of R (at https://bugs.r-project.org/ ) since grid.cap should actually trigger the flush before it does the capture. I cannot promise that the fix will make it to 2.11.0, though, because it may be non-trivial to trigger the asynchronous flush and wait for it without blocking something (I'll have to look).
>

Will do.

Thanks,

baptiste


> Thanks,
> Simon
>
>
> On Apr 17, 2010, at 6:34 AM, baptiste auguie wrote:
>
>> Dear all,
>>
>> I am puzzled by the following behavior of the new grid.cap() function,
>> which appears to run out of time when capturing the output of a
>> graphic. It works fine if I introduce a Sys.sleep(1) before executing
>> more code,
>>
>> library(grid)
>>
>> quartz()
>> grid.circle(gp=gpar(fill="black"))
>> gg <- grid.cap()
>> dev.new()
>> grid.raster(gg) ## completely blank
>> gg[gg!="white"] ## indeed
>>
>> quartz()
>> grid.circle(gp=gpar(fill="black"))
>> Sys.sleep(1)
>> gg <- grid.cap()
>> dev.new()
>> grid.raster(gg) ## OK
>> gg[gg!="white"]
>>
>> I tried to see if the problem was limited to the quartz() device but
>> for some reason the x11() device is not working for me in this R
>> version,
>>
>> capabilities(what = NULL)
>> ? ?jpeg ? ? ?png ? ? tiff ? ?tcltk ? ? ?X11 ? ? aqua http/ftp
>> sockets ? libxml ? ? fifo ? cledit ? ?iconv ? ? ?NLS ?profmem ? ?cairo
>> ? ?TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ?FALSE ? ? TRUE ? ? TRUE
>> TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE
>> Warning message:
>> In doTryCatch(return(expr), name, parentenv, handler) :
>> ?unable to load shared library
>> '/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
>> ?dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
>> 6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
>> ?Referenced from:
>> /Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
>> ?Reason: Incompatible library version: R_X11.so requires version
>> 42.0.0 or later, but libpng12.0.dylib provides version 36.0.0
>>
>> sessionInfo()
>> R version 2.11.0 RC (2010-04-16 r51754)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] grid ? ? ?stats ? ? graphics ?grDevices utils ? ? datasets
>> methods ? base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.11.0
>>
>> I would appreciate if someone could confirm this behavior. Pointers to
>> a fix for the x11() device on my machine are also welcome!
>>
>> Best regards,
>>
>> baptiste
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From simon.urbanek at r-project.org  Sat Apr 17 22:34:35 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 17 Apr 2010 16:34:35 -0400
Subject: [Rd] grid.cap() requires more time?
In-Reply-To: <m2sde4e29f51004171143q29bb45beia05a949702538ff5@mail.gmail.com>
References: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
	<9FF50889-4C38-4AEF-A0C5-BD6BF8535B72@r-project.org>
	<m2sde4e29f51004171143q29bb45beia05a949702538ff5@mail.gmail.com>
Message-ID: <D3E7038C-AA16-402B-A4DE-EA9DE9FF0676@r-project.org>

On Apr 17, 2010, at 2:43 PM, baptiste auguie wrote:

> Hi,
> 
> On 17 April 2010 18:51, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> Baptiste,
>> 
>> first, there is a mailing list specifically for Mac questions - R-SIG-Mac.
>> 
> 
> I wasn't sure if it was Mac-specific (OK, quartz() is but I could not
> test x11()).
> 
>> Now to your post - grid.cap captures the screen of the device which has two implications here:
>> 
>> a) Quartz is asynchronous -- i.e. is doesn't actually draw the content on screen until you're finished with drawing (for efficiency). Unfortunately R has no provision to tell the graphics device that it's done with drawing (you can always add another lines() etc.) so Quartz is simply guessing by measuring the time between draw commands. So when you run grid.cap while the output has not been drawn yet (i.e. immediately after the last drawing command) it will be empty as there is no content yet since Quartz is waiting for the end.
> 
> OK, that makes sense.
> 
>> 
>> b) it will contain the resize mark because it is a screen shot so the mark is actually part of it (this is intentional).
> 
> This design decision surprises me. Would it be possible to have an
> option not to capture this mark as well?
> 

I don't think so because the mark is part of the Quartz view - it is not something the device adds so it is not a "design decision". Again I can only repeat that if you want a re-play of the draw commands you should use that instead - it's a different task. 


>> 
>> If what you really want is a bitmap from the device, it's better to use quartz.save instead (followed by readPNG if you want the bitmap as raster) -- that actually re-runs the plot in a separate quartz device that is not on-screen so neither of the above are an issue.
> 
> I thought the aim of grid.cap was to make it easier to capture a
> bitmap copy (no need to create an external file). Is a screenshot more
> useful?

I didn't write grid.cap() so I don't know what the intention was, but "capturing a bitmap copy" is exactly the above (that is why it is called "capture" I suppose). What you are requesting is something different - creating a new bitmap using the same device settings and quartz.save does that. It would be trivial to add a parameter to quartz.save to return the bitmap directly instead of a file, but R did not have direct bitmap support so it was not requested so far.

Cheers,
Simon


>> 
>> That said, you can file a) as a bug against Mac version of R (at https://bugs.r-project.org/ ) since grid.cap should actually trigger the flush before it does the capture. I cannot promise that the fix will make it to 2.11.0, though, because it may be non-trivial to trigger the asynchronous flush and wait for it without blocking something (I'll have to look).
>> 
> 
> Will do.
> 
> Thanks,
> 
> baptiste
> 
> 
>> Thanks,
>> Simon
>> 
>> 
>> On Apr 17, 2010, at 6:34 AM, baptiste auguie wrote:
>> 
>>> Dear all,
>>> 
>>> I am puzzled by the following behavior of the new grid.cap() function,
>>> which appears to run out of time when capturing the output of a
>>> graphic. It works fine if I introduce a Sys.sleep(1) before executing
>>> more code,
>>> 
>>> library(grid)
>>> 
>>> quartz()
>>> grid.circle(gp=gpar(fill="black"))
>>> gg <- grid.cap()
>>> dev.new()
>>> grid.raster(gg) ## completely blank
>>> gg[gg!="white"] ## indeed
>>> 
>>> quartz()
>>> grid.circle(gp=gpar(fill="black"))
>>> Sys.sleep(1)
>>> gg <- grid.cap()
>>> dev.new()
>>> grid.raster(gg) ## OK
>>> gg[gg!="white"]
>>> 
>>> I tried to see if the problem was limited to the quartz() device but
>>> for some reason the x11() device is not working for me in this R
>>> version,
>>> 
>>> capabilities(what = NULL)
>>>    jpeg      png     tiff    tcltk      X11     aqua http/ftp
>>> sockets   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>>>    TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>>> TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
>>> Warning message:
>>> In doTryCatch(return(expr), name, parentenv, handler) :
>>>  unable to load shared library
>>> '/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
>>>  dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
>>> 6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
>>>  Referenced from:
>>> /Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
>>>  Reason: Incompatible library version: R_X11.so requires version
>>> 42.0.0 or later, but libpng12.0.dylib provides version 36.0.0
>>> 
>>> sessionInfo()
>>> R version 2.11.0 RC (2010-04-16 r51754)
>>> i386-apple-darwin9.8.0
>>> 
>>> locale:
>>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>> 
>>> attached base packages:
>>> [1] grid      stats     graphics  grDevices utils     datasets
>>> methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.11.0
>>> 
>>> I would appreciate if someone could confirm this behavior. Pointers to
>>> a fix for the x11() device on my machine are also welcome!
>>> 
>>> Best regards,
>>> 
>>> baptiste
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 


From baptiste.auguie at googlemail.com  Sun Apr 18 14:26:59 2010
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sun, 18 Apr 2010 14:26:59 +0200
Subject: [Rd] grid.cap() requires more time?
In-Reply-To: <D3E7038C-AA16-402B-A4DE-EA9DE9FF0676@r-project.org>
References: <o2kde4e29f51004170334y63ad9833n666b92518512961b@mail.gmail.com>
	<9FF50889-4C38-4AEF-A0C5-BD6BF8535B72@r-project.org>
	<m2sde4e29f51004171143q29bb45beia05a949702538ff5@mail.gmail.com>
	<D3E7038C-AA16-402B-A4DE-EA9DE9FF0676@r-project.org>
Message-ID: <i2pde4e29f51004180526k2e74836cm94d30994cd62302f@mail.gmail.com>

Hi,

I submitted a bug report today.

On 17 April 2010 22:34, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> On Apr 17, 2010, at 2:43 PM, baptiste auguie wrote:
>
>> Hi,
>>
>> On 17 April 2010 18:51, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>> Baptiste,
>>>
>>> first, there is a mailing list specifically for Mac questions - R-SIG-Mac.
>>>
>>
>> I wasn't sure if it was Mac-specific (OK, quartz() is but I could not
>> test x11()).
>>
>>> Now to your post - grid.cap captures the screen of the device which has two implications here:
>>>
>>> a) Quartz is asynchronous -- i.e. is doesn't actually draw the content on screen until you're finished with drawing (for efficiency). Unfortunately R has no provision to tell the graphics device that it's done with drawing (you can always add another lines() etc.) so Quartz is simply guessing by measuring the time between draw commands. So when you run grid.cap while the output has not been drawn yet (i.e. immediately after the last drawing command) it will be empty as there is no content yet since Quartz is waiting for the end.
>>
>> OK, that makes sense.
>>
>>>
>>> b) it will contain the resize mark because it is a screen shot so the mark is actually part of it (this is intentional).
>>
>> This design decision surprises me. Would it be possible to have an
>> option not to capture this mark as well?
>>
>
> I don't think so because the mark is part of the Quartz view - it is not something the device adds so it is not a "design decision". Again I can only repeat that if you want a re-play of the draw commands you should use that instead - it's a different task.
>
>
>>>
>>> If what you really want is a bitmap from the device, it's better to use quartz.save instead (followed by readPNG if you want the bitmap as raster) -- that actually re-runs the plot in a separate quartz device that is not on-screen so neither of the above are an issue.
>>
>> I thought the aim of grid.cap was to make it easier to capture a
>> bitmap copy (no need to create an external file). Is a screenshot more
>> useful?
>
> I didn't write grid.cap() so I don't know what the intention was, but "capturing a bitmap copy" is exactly the above (that is why it is called "capture" I suppose). What you are requesting is something different - creating a new bitmap using the same device settings and quartz.save does that. It would be trivial to add a parameter to quartz.save to return the bitmap directly instead of a file, but R did not have direct bitmap support so it was not requested so far.

This would be very useful, I think. In fact, it sounds like it might
be possible to convert  a set of graphical commands directly into a
raster representation, without creating an intermediate file nor
opening an interactive device window. That would be awesome.

Thanks,

baptiste

>
> Cheers,
> Simon
>
>
>>>
>>> That said, you can file a) as a bug against Mac version of R (at https://bugs.r-project.org/ ) since grid.cap should actually trigger the flush before it does the capture. I cannot promise that the fix will make it to 2.11.0, though, because it may be non-trivial to trigger the asynchronous flush and wait for it without blocking something (I'll have to look).
>>>
>>
>> Will do.
>>
>> Thanks,
>>
>> baptiste
>>
>>
>>> Thanks,
>>> Simon
>>>
>>>
>>> On Apr 17, 2010, at 6:34 AM, baptiste auguie wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am puzzled by the following behavior of the new grid.cap() function,
>>>> which appears to run out of time when capturing the output of a
>>>> graphic. It works fine if I introduce a Sys.sleep(1) before executing
>>>> more code,
>>>>
>>>> library(grid)
>>>>
>>>> quartz()
>>>> grid.circle(gp=gpar(fill="black"))
>>>> gg <- grid.cap()
>>>> dev.new()
>>>> grid.raster(gg) ## completely blank
>>>> gg[gg!="white"] ## indeed
>>>>
>>>> quartz()
>>>> grid.circle(gp=gpar(fill="black"))
>>>> Sys.sleep(1)
>>>> gg <- grid.cap()
>>>> dev.new()
>>>> grid.raster(gg) ## OK
>>>> gg[gg!="white"]
>>>>
>>>> I tried to see if the problem was limited to the quartz() device but
>>>> for some reason the x11() device is not working for me in this R
>>>> version,
>>>>
>>>> capabilities(what = NULL)
>>>> ? ?jpeg ? ? ?png ? ? tiff ? ?tcltk ? ? ?X11 ? ? aqua http/ftp
>>>> sockets ? libxml ? ? fifo ? cledit ? ?iconv ? ? ?NLS ?profmem ? ?cairo
>>>> ? ?TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ?FALSE ? ? TRUE ? ? TRUE
>>>> TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE
>>>> Warning message:
>>>> In doTryCatch(return(expr), name, parentenv, handler) :
>>>> ?unable to load shared library
>>>> '/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so':
>>>> ?dlopen(/Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so,
>>>> 6): Library not loaded: /usr/X11/lib/libpng12.0.dylib
>>>> ?Referenced from:
>>>> /Library/Frameworks/R.framework/Resources/modules/i386/R_X11.so
>>>> ?Reason: Incompatible library version: R_X11.so requires version
>>>> 42.0.0 or later, but libpng12.0.dylib provides version 36.0.0
>>>>
>>>> sessionInfo()
>>>> R version 2.11.0 RC (2010-04-16 r51754)
>>>> i386-apple-darwin9.8.0
>>>>
>>>> locale:
>>>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] grid ? ? ?stats ? ? graphics ?grDevices utils ? ? datasets
>>>> methods ? base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_2.11.0
>>>>
>>>> I would appreciate if someone could confirm this behavior. Pointers to
>>>> a fix for the x11() device on my machine are also welcome!
>>>>
>>>> Best regards,
>>>>
>>>> baptiste
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>>
>
>


From bolker at ufl.edu  Sun Apr 18 18:53:17 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 18 Apr 2010 12:53:17 -0400
Subject: [Rd] tiny typo in ?prop.test: "if" for "is"
Message-ID: <4BCB38FD.30301@ufl.edu>


  from revision 51769:

Index: prop.test.Rd
===================================================================
--- prop.test.Rd	(revision 51769)
+++ prop.test.Rd	(working copy)
@@ -60,7 +60,7 @@

   If there is only one group, then the null tested is that the
   underlying probability of success is \code{p}, or .5 if \code{p} is
-  not given.  The alternative is that the probability of success if less
+  not given.  The alternative is that the probability of success is less
   than, not equal to, or greater than \code{p} or 0.5, respectively, as
   specified by \code{alternative}.  A confidence interval for the
   underlying proportion with confidence level as specified by

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 261 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100418/f455c989/attachment.bin>

From wangxiang68 at gmail.com  Mon Apr 19 09:56:06 2010
From: wangxiang68 at gmail.com (wangxiang)
Date: Mon, 19 Apr 2010 15:56:06 +0800
Subject: [Rd] about gsoc ideas
Message-ID: <z2n64a692591004190056le058efb0y73ec13bcfdb78682@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100419/e9d6ec1e/attachment.pl>

From murdoch.duncan at gmail.com  Sun Apr 18 19:44:08 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 18 Apr 2010 13:44:08 -0400
Subject: [Rd] tiny typo in ?prop.test: "if" for "is"
Message-ID: <w2l7080e9581004181044h1a868b3bx8bb471b14db0937d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100418/c63d5c90/attachment.pl>

From info at aghmed.fsnet.co.uk  Mon Apr 19 13:48:16 2010
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 19 Apr 2010 12:48:16 +0100
Subject: [Rd] R CMD check tells me 'no visible binding for
 globalvariable ', what does it mean?
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nex
	us.csiro.au>
References: <Zen-1O1Kzf-0000MF-9i@smarthost01.mail.zen.net.uk>
	<4BC3375C.4060007@stats.uwo.ca>
	<m2t59d7961d1004120824uf78b2ff6td9b42b2a03e523e0@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002C34E95@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.1004151239120.12182@nokomis.stat.uiowa.edu>
	<62C82B39B8A85E4B95A18F7F7B852F8705658B333C@exvic-mbx03.nexus.csiro.au>
Message-ID: <Zen-1O3pST-0002On-RQ@smarthost01.mail.zen.net.uk>

At 01:09 16/04/2010, Mark.Bravington at csiro.au wrote:

>Speaking as a copious generator of CMD CHECK notes: I don't see that 
>there's a problem to be solved here-- i.e. I don't see why it's 
>worth changing good code or adding conventions just to circumvent 
>CMD CHECK notes. (If the code is bad, of course it should be 
>changed!) As the original poster said, the CMD CHECK note is only a 
>note, not a warning-- it's checking for "*possible* problems". With 
>my packages, especially debug & mvbutils, CHECK issues 100s of lines 
>of "notes", which (after inspection) I don't worry about-- they 
>arise from RCMD CHECK not understanding my code (eg non-default 
>scopings), not from coding errors. I would be very unhappy at having 
>to add enormous amounts of "explanation" to the packages simply to 
>alleviate a non-problem!
>
>Similarly, some compilers give notes about possibly non-initialized 
>variables etc, but these are often a result of the compiler not 
>understanding the code. I do look at them, and decide whether there 
>are problems that need fixing or not-- it's no big deal to ignore 
>them if not useful. Presumably the RCMD CHECK notes are useful to 
>some coders, in which case good; but nothing further really seems needed.

As the original poster can I endorse that, I was trying to improve my 
understanding. I was not worried by it.

Just to follow up on the suggestions made for eliminating the note I 
posted that Duncan's suggestion worked.

> >>>> I think you can avoid the warning by rewriting that call to
> >>>> curve() as
> >>>>
> >>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
> >>>> 0.999, add = TRUE)

  It does remove the note but then throws an error when called
Error in xy.coords(x, y) : 'x' and 'y' lengths differ

Henrik's suggestion of setting x to a value and then removing it 
works but in the light of the discussions I think I will just leave 
the note in place.

Thanks to everyone for their help and suggestions


>Mark
>
>--
>Mark Bravington
>CSIRO Mathematical & Information Sciences
>Marine Laboratory
>Castray Esplanade
>Hobart 7001
>TAS
>
>ph (+61) 3 6232 5118
>fax (+61) 3 6232 5012
>mob (+61) 438 315 623
>
>luke at stat.uiowa.edu wrote:
> > On Mon, 12 Apr 2010, William Dunlap wrote:
> >
> >>
> >>> -----Original Message-----
> >>> From: r-devel-bounces at r-project.org
> >>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Henrik Bengtsson
> >>> Sent: Monday, April 12, 2010 8:24 AM
> >>> To: Duncan Murdoch
> >>> Cc: r-devel; Michael Dewey
> >>> Subject: Re: [Rd] R CMD check tells me 'no visible binding for
> >>> globalvariable ', what does it mean?
> >>>
> >>> On Mon, Apr 12, 2010 at 5:08 PM, Duncan Murdoch
> >>> <murdoch at stats.uwo.ca> wrote:
> >>>> On 12/04/2010 10:51 AM, Michael Dewey wrote:
> >>>>>
> >>>>> When I run R CMD check on a package I have recently started work
> >>>>> on I get the following:
> >>>>>
> >>>>> * checking R code for possible problems ... NOTE
> >>>>> addlinear: no visible binding for global variable 'x'
> >>>>>
> >>>>> I appreciate that this is only a NOTE and so I assume is R's
> >>>>> equivalent of 'This is perfectly legal but I wonder whether it is
> >>>>> really what you intended' but I would like to understand it.
> >>>>>
> >>>>> In the relevant function addlinear the following function is
> >>>>> defined locally:
> >>>>>
> >>>>>    orfun <- function(x, oddsratio) {1/(1+1/(oddsratio *
> >>>>> (x/(1-x))))}
> >>>>>
> >>>>> and then used later in curve
> >>>>>
> >>>>>       curve(orfun(x, exp(estimate)), from = 0.001, to = 0.999,
> >>>>> add = TRUE)
> >>>>>
> >>>>> These are the only occurrences of 'x'.
> >>>>>
> >>>>> Is it just telling me that I have never assigned a value to x? Or
> >>>>> is it more sinister than that? As far as I can tell the function
> >>>>> does what I intended.
> >>>>
> >>>> The curve() function evaluates the first argument in a strange
> >>>> way, and this confuses the code checking.  (The variable name "x"
> >>>> is special to curve().)
> >>>>
> >>>> I think you can avoid the warning by rewriting that call to
> >>>> curve() as
> >>>>
> >>>> curve(function(x) orfun(x, exp(estimate)), from = 0.001, to =
> >>>> 0.999, add = TRUE)
> >>>
> >>> ...or
> >>>
> >>> x <- NULL; rm(x); # Dummy to trick R CMD check curve(orfun(x,
> >>> exp(estimate)), from = 0.001, to = 0.999, add = TRUE)
> >>
> >> Or we could come up with a scheme to telling the usage checking
> >> functions in codetools that some some or all arguments of certain
> >> functions are evaluated in odd ways so it should not check them.
> >>   E.g.,   irregularUsage(curve, expr) irregularUsage(lm, subset,
> >>   formula) # subset and formula arguments of lm
> >> irregularUsage(expression, ...) # ... arguments to expression
> >> Perhaps one could add such indications to the NAMESPACE file or to a
> >> new file in a package.  The former is kludgy but the latter requires
> >> changes to the packaging system.
> >>
> >
> > This is done at the moment in a very ad hoc way for functions in the
> > core packages.  I will make a note to add something for curve.  This
> > is an interesting case, as only the variable 'x' should be viewed as
> > special for code analysis purposes if I understand the intent in
> > curve properly.
> >
> > Providing a mechanism for user functions to be annotated for code
> > analysis might be useful, and might help in making the handling of
> > core package functions with special evaluation rulesa little less ad
> > hloc.  On the other hand I'm not sure I want to do anything that
> > encourages further use of nonstantard evaluation in new code.
> >
> > luke
> >
> >> Bill Dunlap
> >> Spotfire, TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >>>
> >>> /Henrik
> >>>
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel

Michael Dewey
http://www.aghmed.fsnet.co.uk


From mjhubisz at gmail.com  Mon Apr 19 16:39:25 2010
From: mjhubisz at gmail.com (Melissa Jane Hubisz)
Date: Mon, 19 Apr 2010 10:39:25 -0400
Subject: [Rd] transient memory allocation and external pointers
Message-ID: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>

Hello,
The Writing R extensions manual section 6.1.1 describes the transient
memory allocation function R_alloc, and states that memory allocated
by R_alloc is automatically freed after the .C or .Call function is
completed.  However, based on my understanding of R's memory handling,
as well as some test functions I have written, I suspect that this is
not quite accurate.  If the .Call function returns an external pointer
to something created with R_alloc, then this object seems to stick
around after the .Call function is completed, and is subject to
garbage collection once the external pointer object is removed.

Does anyone know, can I count on this behavior on any platform?  It
would certainly be useful for me.  ie, Can I create an external
pointer to something created with R_alloc, and trust that it will not
be free'd until the external pointer object is removed?  And if so,
should the manual be edited to describe this behavior?
Thanks,
Melissa Hubisz


From proebuck at mdanderson.org  Mon Apr 19 16:51:59 2010
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Mon, 19 Apr 2010 09:51:59 -0500
Subject: [Rd] Syncing window plot update events during long-running
	evaluation
Message-ID: <C7F1D83F.1577%proebuck@mdanderson.org>

I have two source packages, one normal and another a Tcl/Tk UI
for controlling the former. However, as all UI arguments are
passed to a single (potentially VERY long-running) function in
the normal package, all output shows up after the completion of
that function. I have a sort-of workaround for updating progress
on UI during this, but one issue remains consistent. Early in
the process, the normal package displays a graph so the user can
determine whether it is worthwhile to continue. Problem is that
the plot window shows up onscreen (empty) but never fills until
the everything is done, defeating its purpose; I need a means of
flushing pending R graphic events.

While trying to figure out how to fix this, I have noticed that
executing the browser() method allows the plot window to fill prior
to completion of the rest of the routine. Is there some means of
triggering a pause in R execution that can be immediately resumed?
Assuming browser() as a candidate, I would like to invoke it, then
immediately continue (without user interaction being required to
type 'cont').

I had hoped to use 'browser(expr=FALSE)' but that doesn't seem
to help. Any ideas appreciated.


From pgilbert at bank-banque-canada.ca  Mon Apr 19 17:12:27 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 19 Apr 2010 11:12:27 -0400
Subject: [Rd] utf8.def
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100419/d35d664a/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Apr 19 17:19:44 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Apr 2010 16:19:44 +0100 (BST)
Subject: [Rd] utf8.def
In-Reply-To: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>
References: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>
Message-ID: <alpine.LFD.2.00.1004191615500.27545@gannet.stats.ox.ac.uk>

On Mon, 19 Apr 2010, Paul Gilbert wrote:

> I am trying to check my packages with R-rc

And what is that?  Please do note what the posting guide says about 
giving accurate version information.

> and latex is failing to find utf8.def.  I presume my latex 
> installation is defective or too old, or is this file distributed 
> with R and I just don't have a path set correctly?

It is part of the required version of LaTeX. From the NEWS file for 
2.11.0:

     o	UTF-8 is now used for the reference manual and package
 	manuals.  This requires LaTeX '2005/12/01' or later.



>
> 
>
> Paul
>
> ______________
>
> 
>
> * checking PDF version of manual ... WARNING
>
> LaTeX errors when creating PDF version.
>
> This typically indicates Rd problems.
>
> LaTeX errors found:
>
> ! LaTeX Error: File `utf8.def' not found.
>
> 
>
> Type X to quit or <RETURN> to proceed,
>
> or enter new name. (Default extension: def)
>
> 
>
> ! Emergency stop.
>
> <read *>
>
> 
>
> l.118 \endinput
>
>               ^^M
>
> * checking PDF version of manual without index ... ERROR
>
> ====================================================================================
>
> La version fran??aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential information, and the Bank of
> Canada does not waive any related rights. Any distribution, use, or copying of this
> email or the information it contains by other than the intended recipient is
> unauthorized. If you received this email in error please delete it immediately from
> your system and notify the sender promptly by email that you have done so. 
>
> ------------------------------------------------------------------------------------
>
> Le pr??sent courriel peut contenir de l'information privil??gi??e ou confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
> personne autre que le ou les destinataires d??sign??s est interdite. Si vous recevez
> ce courriel par erreur, veuillez le supprimer imm??diatement et envoyer sans d??lai ??
> l'exp??diteur un message ??lectronique pour l'aviser que vous avez ??limin?? de votre
> ordinateur toute copie du courriel re??u.
>
> 	[[alternative HTML version deleted]]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Mon Apr 19 17:58:52 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 19 Apr 2010 11:58:52 -0400
Subject: [Rd] utf8.def
In-Reply-To: <alpine.LFD.2.00.1004191615500.27545@gannet.stats.ox.ac.uk>
References: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>
	<alpine.LFD.2.00.1004191615500.27545@gannet.stats.ox.ac.uk>
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A027D43A9@EXMAIL2.bocad.bank-banque-canada.ca>



>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Sent: April 19, 2010 11:20 AM
>To: Paul Gilbert
>Cc: r-devel at r-project.org
>Subject: Re: [Rd] utf8.def
>
>On Mon, 19 Apr 2010, Paul Gilbert wrote:
>
>> I am trying to check my packages with R-rc
>
>And what is that?  Please do note what the posting guide says about
>giving accurate version information.

R version 2.11.0 RC (2010-04-18 r51771)

>
>> and latex is failing to find utf8.def.  I presume my latex
>> installation is defective or too old, or is this file distributed
>> with R and I just don't have a path set correctly?
>
>It is part of the required version of LaTeX. From the NEWS file for
>2.11.0:
>
>     o	UTF-8 is now used for the reference manual and package
> 	manuals.  This requires LaTeX '2005/12/01' or later.
>

I'm a bit confused about the version numbering scheme for latex.
latex --version reports 
TeX (Web2C 7.4.5) 3.14159
kpathsea version 3.4.5

Is that LaTeX '2005/12/01' or later?

Does it make sense that R is building ok, and apparently using utf8.def
according to the NEWS extract, but my packages don't find it?

Thanks,
Paul

>>
>>
>> Paul
>>
>> ______________
>>
>>
>>
>> * checking PDF version of manual ... WARNING
>>
>> LaTeX errors when creating PDF version.
>>
>> This typically indicates Rd problems.
>>
>> LaTeX errors found:
>>
>> ! LaTeX Error: File `utf8.def' not found.
>>
>>
>>
>> Type X to quit or <RETURN> to proceed,
>>
>> or enter new name. (Default extension: def)
>>
>>
>>
>> ! Emergency stop.
>>
>> <read *>
>>
>>
>>
>> l.118 \endinput
>>
>>               ^^M
>>
>> * checking PDF version of manual without index ... ERROR
>>
>>
>=======================================================================
=
>============
>>
>> La version fran??aise suit le texte anglais.
>>
>>
----------------------------------------------------------------------
>--------------
>>
>> This email may contain privileged and/or confidential information,
and
>the Bank of
>> Canada does not waive any related rights. Any distribution, use, or
>copying of this
>> email or the information it contains by other than the intended
>recipient is
>> unauthorized. If you received this email in error please delete it
>immediately from
>> your system and notify the sender promptly by email that you have
done
>so.
>>
>>
----------------------------------------------------------------------
>--------------
>>
>> Le pr??sent courriel peut contenir de l'information privil??gi??e ou
>confidentielle.
>> La Banque du Canada ne renonce pas aux droits qui s'y rapportent.
>Toute diffusion,
>> utilisation ou copie de ce courriel ou des renseignements qu'il
>contient par une
>> personne autre que le ou les destinataires d??sign??s est interdite.
>Si vous recevez
>> ce courriel par erreur, veuillez le supprimer imm??diatement et
>envoyer sans d??lai ??
>> l'exp??diteur un message ??lectronique pour l'aviser que vous avez
>??limin?? de votre
>> ordinateur toute copie du courriel re??u.
>>
>> 	[[alternative HTML version deleted]]
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From simon.urbanek at r-project.org  Mon Apr 19 17:59:09 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 19 Apr 2010 11:59:09 -0400
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
Message-ID: <80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>


On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:

> Hello,
> The Writing R extensions manual section 6.1.1 describes the transient
> memory allocation function R_alloc, and states that memory allocated
> by R_alloc is automatically freed after the .C or .Call function is
> completed.  However, based on my understanding of R's memory handling,
> as well as some test functions I have written, I suspect that this is
> not quite accurate.  If the .Call function returns an external pointer
> to something created with R_alloc, then this object seems to stick
> around after the .Call function is completed, and is subject to
> garbage collection once the external pointer object is removed.
> 

Yes, because the regular rules for the lifetime of an R object apply since it is in fact an R object. It is subject to garbage collection so if you assign it anywhere its lifetime will be tied to that object (in your example EXTPTRSXP).

Although this is true in general (because that is the only way how it can be safely managed by the memory system), I'm not sure it is guaranteed by the API - i.e. it could be changed at any point to an arbitrary memory location which does not necessarily have that semantics. So you can decide to run with it but the fact that this is undocumented means it is not guaranteed to stay that way forever so you may need to change your code if it does.

Cheers,
Simon



> Does anyone know, can I count on this behavior on any platform?  It
> would certainly be useful for me.  ie, Can I create an external
> pointer to something created with R_alloc, and trust that it will not
> be free'd until the external pointer object is removed?  And if so,
> should the manual be edited to describe this behavior?
> Thanks,
> Melissa Hubisz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Mon Apr 19 18:13:40 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Apr 2010 17:13:40 +0100 (BST)
Subject: [Rd] utf8.def
In-Reply-To: <D611103AA7EE3B4DAE7F7D49C72B291A027D43A9@EXMAIL2.bocad.bank-banque-canada.ca>
References: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>
	<alpine.LFD.2.00.1004191615500.27545@gannet.stats.ox.ac.uk>
	<D611103AA7EE3B4DAE7F7D49C72B291A027D43A9@EXMAIL2.bocad.bank-banque-canada.ca>
Message-ID: <alpine.LFD.2.00.1004191706500.29696@gannet.stats.ox.ac.uk>

On Mon, 19 Apr 2010, Paul Gilbert wrote:

>
>
>> -----Original Message-----
>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> Sent: April 19, 2010 11:20 AM
>> To: Paul Gilbert
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] utf8.def
>>
>> On Mon, 19 Apr 2010, Paul Gilbert wrote:
>>
>>> I am trying to check my packages with R-rc
>>
>> And what is that?  Please do note what the posting guide says about
>> giving accurate version information.
>
> R version 2.11.0 RC (2010-04-18 r51771)
>
>>
>>> and latex is failing to find utf8.def.  I presume my latex
>>> installation is defective or too old, or is this file distributed
>>> with R and I just don't have a path set correctly?
>>
>> It is part of the required version of LaTeX. From the NEWS file for
>> 2.11.0:
>>
>>     o	UTF-8 is now used for the reference manual and package
>> 	manuals.  This requires LaTeX '2005/12/01' or later.
>>
>
> I'm a bit confused about the version numbering scheme for latex.
> latex --version reports
> TeX (Web2C 7.4.5) 3.14159
> kpathsea version 3.4.5
>
> Is that LaTeX '2005/12/01' or later?

LaTeX is not tex, and 'latex' is a link to 'tex' usually.

To get the LaTeX version, look further.  E.g  a LaTeX log might say

**refman.tex
(./refman.tex
LaTeX2e <2009/09/24>

(which is the current one, according to the TeXLive 2009 updater).

> Does it make sense that R is building ok, and apparently using utf8.def
> according to the NEWS extract, but my packages don't find it?

Well, did you build the reference manual?  It is not part of the 
default build (e.g. 'make pdf' is needed).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Mon Apr 19 18:44:25 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 19 Apr 2010 11:44:25 -0500
Subject: [Rd] Lapack, determinant, multivariate normal density,
	solution 	to linear system, C language
In-Reply-To: <1271129244.10914.34.camel@deacon>
References: <1271129244.10914.34.camel@deacon>
Message-ID: <i2m40e66e0b1004190944o56d89ee2hd8fd3fcfbc75f1e7@mail.gmail.com>

On Mon, Apr 12, 2010 at 10:27 PM, shotwelm <shotwelm at musc.edu> wrote:
> r-devel list,
>
> I have recently written an R package that solves a linear least squares
> problem, and computes the multivariate normal density function.

For both of those applications you can use a Cholesky decomposition of
the symmetric matrix.  If the Cholesky decomposition fails then you
have a singular least squares problem or a singular
variance-covariance matrix for your multivariate normal density
function.

Have you tried comparing the speed of your code to

prod(diag(chol(mm))^2

or, probably better, is to use the logarithm of the determinant

2 * sum(log(diag(chol(mm)))

If you use the Matrix package class dpoMatrix to solve the linear
system it will cache the results of the Cholesky decomposition when
solving the system so later evaluation of the determinant will be very
fast - although I suspect you would need to be working with matrices
of sizes in the hundreds or doing the same operation thousands of
times before you would notice a difference.

If you really insist on doing this in compiled code you just need to
call F77_CALL(dpotrf) then accumulate the product of the diagonal
elements of the resulting factor.

You could use packed storage but the slight advantage in memory usage
(at best, 1/2 of the full storage usage) is not worth the pain of
writing code to navigate the packed storage locations.

> The bulk
> of the code is written in C, with interfacing code to the BLAS and
> Lapack libraries. The motivation here is speed. I ran into a problem
> computing the determinant of a symmetric matrix in packed storage.
> Apparently, there are no explicit routines for this as part of Lapack.
> While there IS an explicit routine for this in Linpack, I did not want
> to use the older library. Also, right before I needed the determinant of
> the matrix A, I had used the Lapack routine dspsv to solve the linear
> system Ax=b, which does much of the work of computing a determinant
> also. In fact, the solution I came up with involves the output of this
> routine (which might be obvious to Lapack designers, but not me)
>
> My modest Googleing turned up very little unique material (as is typical
> with BLAS/Lapack/Linpack queries). Hence, I am writing the r-devel list
> partly to document the solution I've come up with, but mainly to elicit
> additional wisdom from seasoned R programmers.
>
> My solution to the problem is illustrated in the appended discussion and
> C code. Thanks for your input.
>
> -Matt Shotwell
>
> --------------
>
> The Lapack routine dspsv solves the linear system of equations Ax=b,
> where A is a symmetric matrix in packed storage format. The dspsv
> function performs the factorization A=UDU', where U is a unitriangular
> matrix and D is a block diagonal matrix where the blocks are of
> dimension 1x1 or 2x2. In addition to the solution for x, the dspsv
> function also returns the matrices U and D. The matrix D may then be
> used to compute the determinant of A. Recall from linear algebra that
> det(A) = det(UDU') = det(U)det(D)det(U'). Since U is unitriangular,
> det(U) = 1. The determinant of D is the product of the determinants of
> the diagonal blocks. If a diagonal block is of dimension 1x1, then the
> determinant of the block is simply the value of the single element in
> the block. If the diagonal block is of dimension 2x2 then the
> determinant of the block may be computed according to the well-known
> formula b11*b22-b12*b21, where bij is the value in the i'th row and j'th
> column of the block.
>
> ?int i, q, info, *ipiv, one = 1;
> ?double *b, *A, *D, det;
>
> ?/*
> ?** A and D are upper triangular matrices in packed storage
> ?** A[] = a00, a01, a11, a02, a12, a22, a03, a13, a23, a33, ...
> ?** use the following macro to address the element in the
> ?** i'th row and j'th column for i <= j
> ?*/
> ?#define UMAT(i, j) (i + j * ( j + 1 ) / 2)
>
> ?/*
> ?** additional code should be here
> ?** - set q
> ?** - allocate ipiv...
> ?** - allocate and fill A and b...
> ?*/
>
> ?/*
> ?** solve Ax=b using A=UDU' factorization where
> ?** A represents a qxq matrix, b a 1xq vector.
> ?** dspsv outputs the elements of the matrix D
> ?** is upper triangular packed storage
> ?** in the memory addressed by A. That is, A is
> ?** replaced by D when dspsv returns.
> ?*/
> ?F77_CALL(dspsv)("U", &q, &one, A, ipiv, b, &q, &info);
> ?if( info > 0 ) { /*issue warning, system is singular*/ }
> ?if( info < 0 ) { /*issue error, invalid argument*/ }
>
> ?/*
> ?** compute the determinant det = det(A)
> ?** if ipiv[i] > 0, then D(i,i) is a 1x1 block diagonal
> ?** if ipiv[i] = ipiv[i-1] < 0, then D(i-1,i-1),
> ?** D(i-1,i), and D(i,i) form the upper triangle
> ?** of a 2x2 block diagonal
> ?*/
> ?D = A;
> ?det = 1.0;
> ?for( i = 0; i < q; i++ ) {
> ? ?if( ipiv[ i ] > 0 ) {
> ? ? ?det *= D[ UMAT(i,i) ];
> ? ?} else if( i > 0 && ipiv[ i ] < 0 && ipiv[ i-1 ] == ipiv[ i ] ) {
> ? ? ?det *= D[ UMAT(i,i) ] * D[ UMAT(i-1,i-1) ] -\
> ? ? ? ? ? ? D[ UMAT(i-1,i) ] * D[ UMAT(i-1,i) ];
> ? ?}
> ?}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pgilbert at bank-banque-canada.ca  Mon Apr 19 18:47:32 2010
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 19 Apr 2010 12:47:32 -0400
Subject: [Rd] utf8.def
In-Reply-To: <alpine.LFD.2.00.1004191706500.29696@gannet.stats.ox.ac.uk>
References: <D611103AA7EE3B4DAE7F7D49C72B291A027D4328@EXMAIL2.bocad.bank-banque-canada.ca>
	<alpine.LFD.2.00.1004191615500.27545@gannet.stats.ox.ac.uk>
	<D611103AA7EE3B4DAE7F7D49C72B291A027D43A9@EXMAIL2.bocad.bank-banque-canada.ca>
	<alpine.LFD.2.00.1004191706500.29696@gannet.stats.ox.ac.uk>
Message-ID: <D611103AA7EE3B4DAE7F7D49C72B291A027D440A@EXMAIL2.bocad.bank-banque-canada.ca>

Thanks Brian. Yes, "make pdf" fails and my latex is too old
(2001/06/01).

Paul

>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Sent: April 19, 2010 12:14 PM
>To: Paul Gilbert
>Cc: r-devel at r-project.org
>Subject: RE: [Rd] utf8.def
>
>On Mon, 19 Apr 2010, Paul Gilbert wrote:
>
>>
>>
>>> -----Original Message-----
>>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>>> Sent: April 19, 2010 11:20 AM
>>> To: Paul Gilbert
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] utf8.def
>>>
>>> On Mon, 19 Apr 2010, Paul Gilbert wrote:
>>>
>>>> I am trying to check my packages with R-rc
>>>
>>> And what is that?  Please do note what the posting guide says about
>>> giving accurate version information.
>>
>> R version 2.11.0 RC (2010-04-18 r51771)
>>
>>>
>>>> and latex is failing to find utf8.def.  I presume my latex
>>>> installation is defective or too old, or is this file distributed
>>>> with R and I just don't have a path set correctly?
>>>
>>> It is part of the required version of LaTeX. From the NEWS file for
>>> 2.11.0:
>>>
>>>     o	UTF-8 is now used for the reference manual and package
>>> 	manuals.  This requires LaTeX '2005/12/01' or later.
>>>
>>
>> I'm a bit confused about the version numbering scheme for latex.
>> latex --version reports
>> TeX (Web2C 7.4.5) 3.14159
>> kpathsea version 3.4.5
>>
>> Is that LaTeX '2005/12/01' or later?
>
>LaTeX is not tex, and 'latex' is a link to 'tex' usually.
>
>To get the LaTeX version, look further.  E.g  a LaTeX log might say
>
>**refman.tex
>(./refman.tex
>LaTeX2e <2009/09/24>
>
>(which is the current one, according to the TeXLive 2009 updater).
>
>> Does it make sense that R is building ok, and apparently using
>utf8.def
>> according to the NEWS extract, but my packages don't find it?
>
>Well, did you build the reference manual?  It is not part of the
>default build (e.g. 'make pdf' is needed).
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From seth at userprimary.net  Mon Apr 19 19:22:24 2010
From: seth at userprimary.net (Seth Falcon)
Date: Mon, 19 Apr 2010 10:22:24 -0700
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
Message-ID: <4BCC9150.10700@userprimary.net>

On 4/19/10 8:59 AM, Simon Urbanek wrote:
>
> On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:
>
>> Hello,
>> The Writing R extensions manual section 6.1.1 describes the transient
>> memory allocation function R_alloc, and states that memory allocated
>> by R_alloc is automatically freed after the .C or .Call function is
>> completed.  However, based on my understanding of R's memory handling,
>> as well as some test functions I have written, I suspect that this is
>> not quite accurate.  If the .Call function returns an external pointer
>> to something created with R_alloc, then this object seems to stick
>> around after the .Call function is completed, and is subject to
>> garbage collection once the external pointer object is removed.
>>
>

> Yes, because the regular rules for the lifetime of an R object apply
> since it is in fact an R object. It is subject to garbage collection
> so if you assign it anywhere its lifetime will be tied to that object
> (in your example EXTPTRSXP).

I may be misunderstanding the question, but I think the answer is 
actually that it is *not* safe to put memory allocated via R_alloc into 
the external pointer address of an EXTPTRSXP.

Here's what I think Melissa is doing:

SEXP make_test_xp(SEXP s)
{
     SEXP ans;
     const char *s0 = CHAR(STRING_ELT(s, 0));
     char *buf = (char *)R_alloc(strlen(s0) + 1, sizeof(char));
     memcpy(buf, s0, strlen(s0) + 1);
     ans = R_MakeExternalPtr(buf, R_NilValue, R_NilValue);
     return ans;
}

The memory allocated by R_alloc is "released" at the end of the .Call 
via vmaxset(vmax).  Using R_alloc in this way will lead to memory 
corruption (it does for me when I made a simple test case).

For memory that really is external (not SEXP), then you should instead 
use Calloc and register a finalizer for the external pointer that will 
do any required cleanup and then call Free.

If instead you want to have an externally managed SEXP, you could put it 
in the protected slot of the external pointer, but then you should 
allocate it using standard R allocation functions.



+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From paboyoun at fhcrc.org  Tue Apr 20 01:31:31 2010
From: paboyoun at fhcrc.org (Patrick Aboyoun)
Date: Mon, 19 Apr 2010 16:31:31 -0700
Subject: [Rd] Issue with aggregate.ts and/or %\% on Windows
Message-ID: <4BCCE7D3.9000904@fhcrc.org>

I've stumbled across an issue with aggregate.ts that either is due to a 
misuse of %/% or something deeper relating to numerical precision on 
Windows. The test code is

x <- rep(6:10, 1:5)
as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))

On Linux and Mac I get the correct answer

 > x <- rep(6:10, 1:5)
 > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5)
[1]  7.2  8.8 10.0

 > sessionInfo()
R version 2.11.0 RC (2010-04-18 r51771)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


and on Windows I get an incorrect answer

 > x <- rep(6:10, 1:5)
 > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))
[1] 7.0 8.5 9.5

 > sessionInfo()
R version 2.11.0 beta (2010-04-11 r51685)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Walking through the aggregate.ts code I found this difference is due to 
what 1 %/% 0.2 produces on the different platforms.

On Mac and Linux I get

 > 1 %/% 0.2
[1] 5

and on Windows I get

 > 1 %/% 0.2
[1] 4


I don't know if %/% supports floating point operands so I'm not sure how 
to report this issue, but here it is anyway.


Patrick


From felix at nfrac.org  Tue Apr 20 02:41:44 2010
From: felix at nfrac.org (Felix Andrews)
Date: Tue, 20 Apr 2010 10:41:44 +1000
Subject: [Rd] bug in aggregate.ts
Message-ID: <l2n94730b8a1004191741gf57cafd7h84a78818a03c8087@mail.gmail.com>

Hi,

I am getting unexpected behaviour from aggregate.ts(). The 'ndeltat'
argument is effectively being reduced by 1 in some cases, even when it
is an integer, with the result that the blocks to be aggregated are
not of the expected size, and also that the end() of the aggregated
series is much later than the end() of the original series.

rawts <- ts(rep(1:10, each = 5), start = 1)

## ndeltat = 5, but splits into blocks of 4 rather than 5:

agts <- aggregate(rawts, ndeltat = 5,
             FUN = function(x) {str(x);mean(x)})
 int [1:4] 1 1 1 1
 int [1:4] 1 2 2 2
 int [1:4] 2 2 3 3
 int [1:4] 3 3 3 4
 int [1:4] 4 4 4 4
 int [1:4] 5 5 5 5
 int [1:4] 5 6 6 6
 int [1:4] 6 6 7 7
 int [1:4] 7 7 7 8
 int [1:4] 8 8 8 8
 int [1:4] 9 9 9 9
 int [1:4] 9 10 10 10

## Adding a small amount onto ndeltat bumps it up to blocks of 5:

agts2 <- aggregate(rawts, ndeltat = 5 + getOption("ts.eps") / 2,
             FUN = function(x) {str(x);mean(x)})
 int [1:5] 1 1 1 1 1
 int [1:5] 2 2 2 2 2
 int [1:5] 3 3 3 3 3
 int [1:5] 4 4 4 4 4
 int [1:5] 5 5 5 5 5
 int [1:5] 6 6 6 6 6
 int [1:5] 7 7 7 7 7
 int [1:5] 8 8 8 8 8
 int [1:5] 9 9 9 9 9
 int [1:5] 10 10 10 10 10

## Compare start / end / deltat / length for the two series.

sapply(list(`ndeltat=5` = agts, `ndeltat=5+` = agts2),
  function(x) c(start = start(x)[1], end = end(x)[1],
                   deltat = deltat(x), length = length(x)))

#        ndeltat=5 ndeltat=5+
# start          1   1.000000
# end           56  46.000045         ## `rawts` ends at 50
# deltat         5   5.000005
# length        12  10.000000


sessionInfo()
R version 2.11.0 RC (2010-04-18 r51771)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
[5] LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



-- 
Felix Andrews / ???
Postdoctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 4670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From felix at nfrac.org  Tue Apr 20 02:51:10 2010
From: felix at nfrac.org (Felix Andrews)
Date: Tue, 20 Apr 2010 10:51:10 +1000
Subject: [Rd] bug in aggregate.ts
In-Reply-To: <l2n94730b8a1004191741gf57cafd7h84a78818a03c8087@mail.gmail.com>
References: <l2n94730b8a1004191741gf57cafd7h84a78818a03c8087@mail.gmail.com>
Message-ID: <q2k94730b8a1004191751rb84e77a5y964a32c25ab79590@mail.gmail.com>

Sorry, I didn't notice Patrick Aboyoun's email reporting the same
issue just some minutes ago.


On 20 April 2010 10:41, Felix Andrews <felix at nfrac.org> wrote:
> Hi,
>
> I am getting unexpected behaviour from aggregate.ts(). The 'ndeltat'
> argument is effectively being reduced by 1 in some cases, even when it
> is an integer, with the result that the blocks to be aggregated are
> not of the expected size, and also that the end() of the aggregated
> series is much later than the end() of the original series.
>
> rawts <- ts(rep(1:10, each = 5), start = 1)
>
> ## ndeltat = 5, but splits into blocks of 4 rather than 5:
>
> agts <- aggregate(rawts, ndeltat = 5,
> ? ? ? ? ? ? FUN = function(x) {str(x);mean(x)})
> ?int [1:4] 1 1 1 1
> ?int [1:4] 1 2 2 2
> ?int [1:4] 2 2 3 3
> ?int [1:4] 3 3 3 4
> ?int [1:4] 4 4 4 4
> ?int [1:4] 5 5 5 5
> ?int [1:4] 5 6 6 6
> ?int [1:4] 6 6 7 7
> ?int [1:4] 7 7 7 8
> ?int [1:4] 8 8 8 8
> ?int [1:4] 9 9 9 9
> ?int [1:4] 9 10 10 10
>
> ## Adding a small amount onto ndeltat bumps it up to blocks of 5:
>
> agts2 <- aggregate(rawts, ndeltat = 5 + getOption("ts.eps") / 2,
> ? ? ? ? ? ? FUN = function(x) {str(x);mean(x)})
> ?int [1:5] 1 1 1 1 1
> ?int [1:5] 2 2 2 2 2
> ?int [1:5] 3 3 3 3 3
> ?int [1:5] 4 4 4 4 4
> ?int [1:5] 5 5 5 5 5
> ?int [1:5] 6 6 6 6 6
> ?int [1:5] 7 7 7 7 7
> ?int [1:5] 8 8 8 8 8
> ?int [1:5] 9 9 9 9 9
> ?int [1:5] 10 10 10 10 10
>
> ## Compare start / end / deltat / length for the two series.
>
> sapply(list(`ndeltat=5` = agts, `ndeltat=5+` = agts2),
> ?function(x) c(start = start(x)[1], end = end(x)[1],
> ? ? ? ? ? ? ? ? ? deltat = deltat(x), length = length(x)))
>
> # ? ? ? ?ndeltat=5 ndeltat=5+
> # start ? ? ? ? ?1 ? 1.000000
> # end ? ? ? ? ? 56 ?46.000045 ? ? ? ? ## `rawts` ends at 50
> # deltat ? ? ? ? 5 ? 5.000005
> # length ? ? ? ?12 ?10.000000
>
>
> sessionInfo()
> R version 2.11.0 RC (2010-04-18 r51771)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_Australia.1252 ?LC_CTYPE=English_Australia.1252
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
>
> --
> Felix Andrews / ???
> Postdoctoral Fellow
> Integrated Catchment Assessment and Management (iCAM) Centre
> Fenner School of Environment and Society [Bldg 48a]
> The Australian National University
> Canberra ACT 0200 Australia
> M: +61 410 400 963
> T: + 61 2 6125 4670
> E: felix.andrews at anu.edu.au
> CRICOS Provider No. 00120C
> --
> http://www.neurofractal.org/felix/
>



-- 
Felix Andrews / ???
Postdoctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 4670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From pdalgd at gmail.com  Tue Apr 20 07:20:08 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Tue, 20 Apr 2010 07:20:08 +0200
Subject: [Rd] Issue with aggregate.ts and/or %\% on Windows
In-Reply-To: <4BCCE7D3.9000904@fhcrc.org>
References: <4BCCE7D3.9000904@fhcrc.org>
Message-ID: <4BCD3988.1090800@gmail.com>

Patrick Aboyoun wrote:
> I've stumbled across an issue with aggregate.ts that either is due to a 
> misuse of %/% or something deeper relating to numerical precision on 
> Windows. The test code is
> 
> x <- rep(6:10, 1:5)
> as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))
> 
> On Linux and Mac I get the correct answer
> 
>  > x <- rep(6:10, 1:5)
>  > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5)
> [1]  7.2  8.8 10.0
> 
>  > sessionInfo()
> R version 2.11.0 RC (2010-04-18 r51771)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> and on Windows I get an incorrect answer
> 
>  > x <- rep(6:10, 1:5)
>  > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))
> [1] 7.0 8.5 9.5
> 
>  > sessionInfo()
> R version 2.11.0 beta (2010-04-11 r51685)
> i386-pc-mingw32
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> Walking through the aggregate.ts code I found this difference is due to 
> what 1 %/% 0.2 produces on the different platforms.
> 
> On Mac and Linux I get
> 
>  > 1 %/% 0.2
> [1] 5
> 
> and on Windows I get
> 
>  > 1 %/% 0.2
> [1] 4
> 
> 
> I don't know if %/% supports floating point operands so I'm not sure how 
> to report this issue, but here it is anyway.

It's not as straightforward as that. I get 4 on one (32 bit) Linux, and
5 on another (64 bit). Based on samples of size one, I wouldn't want to
conjecture that "bitness" is the root cause, but it is probably not the
OS per se, rather the CPU or compiler version.

It is even more insidious: I see on the SAME system

> 1%/%0.2
[1] 4
> 1/0.2==5
[1] TRUE

so it isn't just the usual precision issue.

Of course, exact calculations with floating-point numbers is "unsafe at
any speed",  but this is quite peculiar. Presumably, it comes about
because of intermediate storage in an extended precision register.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From d.rizopoulos at erasmusmc.nl  Tue Apr 20 08:57:30 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Tue, 20 Apr 2010 08:57:30 +0200
Subject: [Rd] Derivative of model formula
Message-ID: <4BCD505A.9030407@erasmusmc.nl>

Dear All,

I'd like to ask fro any pointers to code in any package out there that 
can (even partially) handle the following situation: say we have the 
linear model

# toy data
y <- rnorm(100)
time <- runif(100, 0, 5)
treat <- gl(2, 50, labels = c("placebo", "active"))
sex <- gl(2, 1, 100, labels = c("male", "female"))
bmi <- runif(100, 20, 35)

# linear model fit
lmFit <- lm(y ~ (time + I(time^2) + I(time^3))*sex + bmi*treat)


Now, I'd like to compute the derivative of the linear predictor with 
respect to 'time'. I thought of the following procedure:

step 1: create a new formula that is the derivative of the original 
formula wrt 'time'.

step 2: feed this to model.matrix().

step 3: multiple with the corresponding estimated coefficients.


Is this a reasonable way to attack this problem or is there another more 
optimal solution -- I'd like to obtain a solution as generalizable as 
possible.

Thanks in advance.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014


From hb at stat.berkeley.edu  Tue Apr 20 08:57:45 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 20 Apr 2010 08:57:45 +0200
Subject: [Rd] CRAN: MacOS X binary: not available, see check log?
In-Reply-To: <F9E52DA5-25C1-4860-AF53-BDBF1E8165B7@r-project.org>
References: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com> 
	<F9E52DA5-25C1-4860-AF53-BDBF1E8165B7@r-project.org>
Message-ID: <m2i59d7961d1004192357x13cba334ka0f4ad397c2faee4@mail.gmail.com>

Hi,

On Thu, Apr 15, 2010 at 3:45 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Apr 15, 2010, at 2:26 AM, Henrik Bengtsson wrote:
>
>> For a couple of days, MacOS X binaries are not build on CRAN (for my
>> recently uploaded packages only?):
>>
>
> AFAICS your package was posted on Apr 13 so at the earliest it can be built in the Apr 14 run = yesterday. There was no Apr 14 run because the R build failed on Apr 13. I was chasing the subsequent issues yesterday and I think the latest R build is now working so today's package update should be on CRAN soon. Don't forget that packages have to swim across the Atlantic to get built and then back as binaries, so the migration can take a day or two ;).

The R.oo doesn't like water and prefers the faster option of flying.
But it must have got stranded due to the ash cloud, because it hasn't
made the jump back and forth over pond yet. Any updates on next
available flight?

/Henrik

PS. The R.oo is a frequent flyer with lots of miles.


>
> Cheers,
> Simon
>
>
>> The R.oo package is listed as "MacOS X binary: not available, see
>> check log?", but the 'check log' show no errors
>> URL: http://cran.r-project.org/web/packages/R.oo/
>>
>> Is this a known issue?
>>
>
>
>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From hb at stat.berkeley.edu  Tue Apr 20 09:04:39 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 20 Apr 2010 09:04:39 +0200
Subject: [Rd] callNextMethod() and NAMESPACE
In-Reply-To: <4BC720FB.9080904@waddell.ch>
References: <4BC720FB.9080904@waddell.ch>
Message-ID: <k2r59d7961d1004200004j6cd197a6led23261ab0107cbf@mail.gmail.com>

It could be that you define the below in two different source files
and you are only updating the first and it is overwritten by the
second which you never edit? /Henrik

On Thu, Apr 15, 2010 at 4:21 PM, Adrian Waddell <adrian at waddell.ch> wrote:
> Hello there,
>
> I define a accessor method for one of my classes, i.e.
>
> setMethod(f = "[",
> ?signature = "NG_data",
> ? ?definition = function(x,i,j,drop){
> ? ? ? if(all(is.na(match(j,x at shortnames)) == FALSE)){
> ? ? ? ? return(x[,match(j,x at shortnames)]) ? ? ? ? ? ? ? ? ? ? ? ? ? }else{
> ? ? ? ? callNextMethod()
> ? ? ? }
> ? ?}
> )
>
> where the class "NG_data" inherits from the "data.frame" class. Hence I
> added the line
>
> exportMethods("[")
>
> to my NAMESPACE file. After package building, installing and loading, I try
> to use this accessor method
>
> myObject[,1]
>
> but I get the error message:
>
> Error in callNextMethod() : bad object found as method (class "function")
>
> Interestingly, if I then execute the setMethod(f = "["... ?in the command
> prompt
>
> myObject[,1]
>
> works. Does anybody has a clue what could go wrong?
>
>
> Adrian Waddell
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Apr 20 09:07:41 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Apr 2010 08:07:41 +0100 (BST)
Subject: [Rd] Issue with aggregate.ts and/or %\% on Windows
In-Reply-To: <4BCD3988.1090800@gmail.com>
References: <4BCCE7D3.9000904@fhcrc.org> <4BCD3988.1090800@gmail.com>
Message-ID: <alpine.LFD.2.00.1004200805270.15264@gannet.stats.ox.ac.uk>

However, in this case it is the use of %/% that is wrong: the fuzz 
ts.eps is supposed to be used.  Will alter (in R-devel for now).

On Tue, 20 Apr 2010, Peter Dalgaard wrote:

> Patrick Aboyoun wrote:
>> I've stumbled across an issue with aggregate.ts that either is due to a
>> misuse of %/% or something deeper relating to numerical precision on
>> Windows. The test code is
>>
>> x <- rep(6:10, 1:5)
>> as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))
>>
>> On Linux and Mac I get the correct answer
>>
>> > x <- rep(6:10, 1:5)
>> > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5)
>> [1]  7.2  8.8 10.0
>>
>> > sessionInfo()
>> R version 2.11.0 RC (2010-04-18 r51771)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> and on Windows I get an incorrect answer
>>
>> > x <- rep(6:10, 1:5)
>> > as.vector(aggregate(as.ts(x), FUN = mean, ndeltat = 5))
>> [1] 7.0 8.5 9.5
>>
>> > sessionInfo()
>> R version 2.11.0 beta (2010-04-11 r51685)
>> i386-pc-mingw32
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> Walking through the aggregate.ts code I found this difference is due to
>> what 1 %/% 0.2 produces on the different platforms.
>>
>> On Mac and Linux I get
>>
>> > 1 %/% 0.2
>> [1] 5
>>
>> and on Windows I get
>>
>> > 1 %/% 0.2
>> [1] 4
>>
>>
>> I don't know if %/% supports floating point operands so I'm not sure how
>> to report this issue, but here it is anyway.
>
> It's not as straightforward as that. I get 4 on one (32 bit) Linux, and
> 5 on another (64 bit). Based on samples of size one, I wouldn't want to
> conjecture that "bitness" is the root cause, but it is probably not the
> OS per se, rather the CPU or compiler version.
>
> It is even more insidious: I see on the SAME system
>
>> 1%/%0.2
> [1] 4
>> 1/0.2==5
> [1] TRUE
>
> so it isn't just the usual precision issue.
>
> Of course, exact calculations with floating-point numbers is "unsafe at
> any speed",  but this is quite peculiar. Presumably, it comes about
> because of intermediate storage in an extended precision register.
>
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mjhubisz at gmail.com  Tue Apr 20 15:24:05 2010
From: mjhubisz at gmail.com (Melissa Jane Hubisz)
Date: Tue, 20 Apr 2010 09:24:05 -0400
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <4BCC9150.10700@userprimary.net>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com> 
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
	<4BCC9150.10700@userprimary.net>
Message-ID: <r2m3aa2e7491004200624s2f1a0a28ofb5781dad86ee84d@mail.gmail.com>

Thanks for the responses.  Seth's example is indeed what I was trying
(hoping) to do, it seems to work on my system fine (ubuntu x86_64, R
2.10.1).  But if it doesn't work for him, then that definitely answers
my question.  I guess I'll have to go the Calloc/Free route.
Thanks,
Melissa

On Mon, Apr 19, 2010 at 1:22 PM, Seth Falcon <seth at userprimary.net> wrote:
> On 4/19/10 8:59 AM, Simon Urbanek wrote:
>>
>> On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:
>>
>>> Hello,
>>> The Writing R extensions manual section 6.1.1 describes the transient
>>> memory allocation function R_alloc, and states that memory allocated
>>> by R_alloc is automatically freed after the .C or .Call function is
>>> completed. ?However, based on my understanding of R's memory handling,
>>> as well as some test functions I have written, I suspect that this is
>>> not quite accurate. ?If the .Call function returns an external pointer
>>> to something created with R_alloc, then this object seems to stick
>>> around after the .Call function is completed, and is subject to
>>> garbage collection once the external pointer object is removed.
>>>
>>
>
>> Yes, because the regular rules for the lifetime of an R object apply
>> since it is in fact an R object. It is subject to garbage collection
>> so if you assign it anywhere its lifetime will be tied to that object
>> (in your example EXTPTRSXP).
>
> I may be misunderstanding the question, but I think the answer is actually
> that it is *not* safe to put memory allocated via R_alloc into the external
> pointer address of an EXTPTRSXP.
>
> Here's what I think Melissa is doing:
>
> SEXP make_test_xp(SEXP s)
> {
> ? ?SEXP ans;
> ? ?const char *s0 = CHAR(STRING_ELT(s, 0));
> ? ?char *buf = (char *)R_alloc(strlen(s0) + 1, sizeof(char));
> ? ?memcpy(buf, s0, strlen(s0) + 1);
> ? ?ans = R_MakeExternalPtr(buf, R_NilValue, R_NilValue);
> ? ?return ans;
> }
>
> The memory allocated by R_alloc is "released" at the end of the .Call via
> vmaxset(vmax). ?Using R_alloc in this way will lead to memory corruption (it
> does for me when I made a simple test case).
>
> For memory that really is external (not SEXP), then you should instead use
> Calloc and register a finalizer for the external pointer that will do any
> required cleanup and then call Free.
>
> If instead you want to have an externally managed SEXP, you could put it in
> the protected slot of the external pointer, but then you should allocate it
> using standard R allocation functions.
>
>
>
> + seth
>
> --
> Seth Falcon | @sfalcon | http://userprimary.net/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Tue Apr 20 15:58:54 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 20 Apr 2010 09:58:54 -0400
Subject: [Rd] CRAN: MacOS X binary: not available, see check log?
In-Reply-To: <m2i59d7961d1004192357x13cba334ka0f4ad397c2faee4@mail.gmail.com>
References: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com>
	<F9E52DA5-25C1-4860-AF53-BDBF1E8165B7@r-project.org>
	<m2i59d7961d1004192357x13cba334ka0f4ad397c2faee4@mail.gmail.com>
Message-ID: <7473F78E-9A3A-424F-9874-34B49DA9A788@r-project.org>


On Apr 20, 2010, at 2:57 AM, Henrik Bengtsson wrote:

> Hi,
> 
> On Thu, Apr 15, 2010 at 3:45 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Apr 15, 2010, at 2:26 AM, Henrik Bengtsson wrote:
>> 
>>> For a couple of days, MacOS X binaries are not build on CRAN (for my
>>> recently uploaded packages only?):
>>> 
>> 
>> AFAICS your package was posted on Apr 13 so at the earliest it can be built in the Apr 14 run = yesterday. There was no Apr 14 run because the R build failed on Apr 13. I was chasing the subsequent issues yesterday and I think the latest R build is now working so today's package update should be on CRAN soon. Don't forget that packages have to swim across the Atlantic to get built and then back as binaries, so the migration can take a day or two ;).
> 
> The R.oo doesn't like water and prefers the faster option of flying.
> But it must have got stranded due to the ash cloud, because it hasn't
> made the jump back and forth over pond yet. Any updates on next
> available flight?
> 

As you know the ashes over Iceland grounded all flight traffic from Europe, so we're in a pinch ;).

But seriously - R.oo is on CRAN for a while now:
http://cran.at.r-project.org/bin/macosx/leopard/contrib/2.11/R.oo_1.7.2.tgz

R.oo_1.7.2.tgz	13-Apr-2010 11:20	717K

Cheers,
Simon


> /Henrik
> 
> PS. The R.oo is a frequent flyer with lots of miles.
> 
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> The R.oo package is listed as "MacOS X binary: not available, see
>>> check log?", but the 'check log' show no errors
>>> URL: http://cran.r-project.org/web/packages/R.oo/
>>> 
>>> Is this a known issue?
>>> 
>> 
>> 
>> 
>>> /Henrik
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 


From simon.urbanek at r-project.org  Tue Apr 20 16:12:38 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 20 Apr 2010 10:12:38 -0400
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <4BCC9150.10700@userprimary.net>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
	<4BCC9150.10700@userprimary.net>
Message-ID: <FFA9D37C-B8D8-496F-87C2-49A31AD6B977@r-project.org>


On Apr 19, 2010, at 1:22 PM, Seth Falcon wrote:

> On 4/19/10 8:59 AM, Simon Urbanek wrote:
>> 
>> On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:
>> 
>>> Hello,
>>> The Writing R extensions manual section 6.1.1 describes the transient
>>> memory allocation function R_alloc, and states that memory allocated
>>> by R_alloc is automatically freed after the .C or .Call function is
>>> completed.  However, based on my understanding of R's memory handling,
>>> as well as some test functions I have written, I suspect that this is
>>> not quite accurate.  If the .Call function returns an external pointer
>>> to something created with R_alloc, then this object seems to stick
>>> around after the .Call function is completed, and is subject to
>>> garbage collection once the external pointer object is removed.
>>> 
>> 
> 
>> Yes, because the regular rules for the lifetime of an R object apply
>> since it is in fact an R object. It is subject to garbage collection
>> so if you assign it anywhere its lifetime will be tied to that object
>> (in your example EXTPTRSXP).
> 
> I may be misunderstanding the question, but I think the answer is actually that it is *not* safe to put memory allocated via R_alloc into the external pointer address of an EXTPTRSXP.
> 
> Here's what I think Melissa is doing:
> 
> SEXP make_test_xp(SEXP s)
> {
>    SEXP ans;
>    const char *s0 = CHAR(STRING_ELT(s, 0));
>    char *buf = (char *)R_alloc(strlen(s0) + 1, sizeof(char));
>    memcpy(buf, s0, strlen(s0) + 1);
>    ans = R_MakeExternalPtr(buf, R_NilValue, R_NilValue);
>    return ans;
> }
> 
> The memory allocated by R_alloc is "released" at the end of the .Call via vmaxset(vmax).  Using R_alloc in this way will lead to memory corruption (it does for me when I made a simple test case).
> 

Can you elaborate on that? (It's really tricky to test this since you cannot attach a finalizer to the allocated memory).

AFAICT the R_alloc allocates a regular R vector (raw or real depending on size) so the usual R object rules apply. Then it is attached to the VStack. If you also assign it to any other object accessible from the GC roots (before the VStack goes away) then even removing the VStack entry won't cause de-allocation because it will be flagged from the other root at mark time so it won't be garbage collected. VStack is not released blindly it is simply pruned and left to garbage collection to decide whether to release the objects or not.

That said, the lesson to Melissa is that you can simply allocate a raw vector with the same effect - there is no need to use R_alloc() in her case (is user code PROTECTing is sort of equivalent to the VStack used internally).

Cheers,
Simon



> For memory that really is external (not SEXP), then you should instead use Calloc and register a finalizer for the external pointer that will do any required cleanup and then call Free.
> 
> If instead you want to have an externally managed SEXP, you could put it in the protected slot of the external pointer, but then you should allocate it using standard R allocation functions.
> 
> 
> 
> + seth
> 
> -- 
> Seth Falcon | @sfalcon | http://userprimary.net/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Tue Apr 20 16:18:00 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 20 Apr 2010 10:18:00 -0400
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <FFA9D37C-B8D8-496F-87C2-49A31AD6B977@r-project.org>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
	<4BCC9150.10700@userprimary.net>
	<FFA9D37C-B8D8-496F-87C2-49A31AD6B977@r-project.org>
Message-ID: <5CA38840-1A92-4D73-B1AF-2C1D66399F55@r-project.org>


On Apr 20, 2010, at 10:12 AM, Simon Urbanek wrote:

> 
> On Apr 19, 2010, at 1:22 PM, Seth Falcon wrote:
> 
>> On 4/19/10 8:59 AM, Simon Urbanek wrote:
>>> 
>>> On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:
>>> 
>>>> Hello,
>>>> The Writing R extensions manual section 6.1.1 describes the transient
>>>> memory allocation function R_alloc, and states that memory allocated
>>>> by R_alloc is automatically freed after the .C or .Call function is
>>>> completed.  However, based on my understanding of R's memory handling,
>>>> as well as some test functions I have written, I suspect that this is
>>>> not quite accurate.  If the .Call function returns an external pointer
>>>> to something created with R_alloc, then this object seems to stick
>>>> around after the .Call function is completed, and is subject to
>>>> garbage collection once the external pointer object is removed.
>>>> 
>>> 
>> 
>>> Yes, because the regular rules for the lifetime of an R object apply
>>> since it is in fact an R object. It is subject to garbage collection
>>> so if you assign it anywhere its lifetime will be tied to that object
>>> (in your example EXTPTRSXP).
>> 
>> I may be misunderstanding the question, but I think the answer is actually that it is *not* safe to put memory allocated via R_alloc into the external pointer address of an EXTPTRSXP.
>> 
>> Here's what I think Melissa is doing:
>> 
>> SEXP make_test_xp(SEXP s)
>> {
>>   SEXP ans;
>>   const char *s0 = CHAR(STRING_ELT(s, 0));
>>   char *buf = (char *)R_alloc(strlen(s0) + 1, sizeof(char));
>>   memcpy(buf, s0, strlen(s0) + 1);
>>   ans = R_MakeExternalPtr(buf, R_NilValue, R_NilValue);
>>   return ans;
>> }
>> 
>> The memory allocated by R_alloc is "released" at the end of the .Call via vmaxset(vmax).  Using R_alloc in this way will lead to memory corruption (it does for me when I made a simple test case).
>> 
> 
> Can you elaborate on that? (It's really tricky to test this since you cannot attach a finalizer to the allocated memory).
> 
> AFAICT the R_alloc allocates a regular R vector (raw or real depending on size) so the usual R object rules apply. Then it is attached to the VStack. If you also assign it to any other object accessible from the GC roots (before the VStack goes away) then even removing the VStack entry won't cause de-allocation because it will be flagged from the other root at mark time so it won't be garbage collected. VStack is not released blindly it is simply pruned and left to garbage collection to decide whether to release the objects or not.
> 

Ah, I now see the issue - I missed the part that you're NOT using it as SEXP (tag/prot) in the EXTPTR but as void pointer in which case it is not traversed at GC time - point taken. If you assign it as SEXP anywhere (list, vector, etc.) then my point remains ;). But, again, use PROTECT(allocVector(RAWSXP, ..)) for the same yet safe effect.

Cheers,
Simon


> That said, the lesson to Melissa is that you can simply allocate a raw vector with the same effect - there is no need to use R_alloc() in her case (is user code PROTECTing is sort of equivalent to the VStack used internally).
> 
> Cheers,
> Simon
> 
> 
> 
>> For memory that really is external (not SEXP), then you should instead use Calloc and register a finalizer for the external pointer that will do any required cleanup and then call Free.
>> 
>> If instead you want to have an externally managed SEXP, you could put it in the protected slot of the external pointer, but then you should allocate it using standard R allocation functions.
>> 
>> 
>> 
>> + seth
>> 
>> -- 
>> Seth Falcon | @sfalcon | http://userprimary.net/
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From luke at stat.uiowa.edu  Tue Apr 20 16:28:16 2010
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Tue, 20 Apr 2010 09:28:16 -0500 (CDT)
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <FFA9D37C-B8D8-496F-87C2-49A31AD6B977@r-project.org>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
	<4BCC9150.10700@userprimary.net>
	<FFA9D37C-B8D8-496F-87C2-49A31AD6B977@r-project.org>
Message-ID: <alpine.LFD.2.00.1004200925360.12182@nokomis.stat.uiowa.edu>

On Tue, 20 Apr 2010, Simon Urbanek wrote:

>
> On Apr 19, 2010, at 1:22 PM, Seth Falcon wrote:
>
>> On 4/19/10 8:59 AM, Simon Urbanek wrote:
>>>
>>> On Apr 19, 2010, at 10:39 AM, Melissa Jane Hubisz wrote:
>>>
>>>> Hello,
>>>> The Writing R extensions manual section 6.1.1 describes the transient
>>>> memory allocation function R_alloc, and states that memory allocated
>>>> by R_alloc is automatically freed after the .C or .Call function is
>>>> completed.  However, based on my understanding of R's memory handling,
>>>> as well as some test functions I have written, I suspect that this is
>>>> not quite accurate.  If the .Call function returns an external pointer
>>>> to something created with R_alloc, then this object seems to stick
>>>> around after the .Call function is completed, and is subject to
>>>> garbage collection once the external pointer object is removed.
>>>>
>>>
>>
>>> Yes, because the regular rules for the lifetime of an R object apply
>>> since it is in fact an R object. It is subject to garbage collection
>>> so if you assign it anywhere its lifetime will be tied to that object
>>> (in your example EXTPTRSXP).
>>
>> I may be misunderstanding the question, but I think the answer is actually that it is *not* safe to put memory allocated via R_alloc into the external pointer address of an EXTPTRSXP.
>>
>> Here's what I think Melissa is doing:
>>
>> SEXP make_test_xp(SEXP s)
>> {
>>    SEXP ans;
>>    const char *s0 = CHAR(STRING_ELT(s, 0));
>>    char *buf = (char *)R_alloc(strlen(s0) + 1, sizeof(char));
>>    memcpy(buf, s0, strlen(s0) + 1);
>>    ans = R_MakeExternalPtr(buf, R_NilValue, R_NilValue);
>>    return ans;
>> }
>>
>> The memory allocated by R_alloc is "released" at the end of the .Call via vmaxset(vmax).  Using R_alloc in this way will lead to memory corruption (it does for me when I made a simple test case).
>>
>
> Can you elaborate on that? (It's really tricky to test this since you cannot attach a finalizer to the allocated memory).
>
> AFAICT the R_alloc allocates a regular R vector (raw or real depending on size) so the usual R object rules apply. Then it is attached to the VStack. If you also assign it to any other object accessible from the GC roots (before the VStack goes away) then even removing the VStack entry won't cause de-allocation because it will be flagged from the other root at mark time so it won't be garbage collected. VStack is not released blindly it is simply pruned and left to garbage collection to decide whether to release the objects or not.

But R_alloc returns the pointer to the data associated with the SEXPR
that goes in the vstack, and there is no official way to get from that
data pointer to the SEXPR.  So the allocation can't be GC protected by
anything done in the code that calls R_alloc.

In any case the implementation of R_alloc is not intended to be public
and could change.

luke

>
> That said, the lesson to Melissa is that you can simply allocate a raw vector with the same effect - there is no need to use R_alloc() in her case (is user code PROTECTing is sort of equivalent to the VStack used internally).
>
> Cheers,
> Simon
>
>
>
>> For memory that really is external (not SEXP), then you should instead use Calloc and register a finalizer for the external pointer that will do any required cleanup and then call Free.
>>
>> If instead you want to have an externally managed SEXP, you could put it in the protected slot of the external pointer, but then you should allocate it using standard R allocation functions.
>>
>>
>>
>> + seth
>>
>> --
>> Seth Falcon | @sfalcon | http://userprimary.net/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From blair.christian at gmail.com  Tue Apr 20 16:33:57 2010
From: blair.christian at gmail.com (Blair Christian)
Date: Tue, 20 Apr 2010 10:33:57 -0400
Subject: [Rd] Serial connections?
Message-ID: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>

Does anybody know if there is any support to read from serial ports?
I just got an arduino, and wanted to write some scripts for working
with real time streaming sensor data...

In base::connections documentation, it's not clear if there's an easy
way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
solutions.  I'm not sure how sockets work, but possibly there is a way
to pipe things to a buffer and read from a buffer in bash (in my linux
mind I have the thought of trying to redirect /dev/something to a
file, or symlinking a file to point to the hardware, but know that
there has to be some secret sauce to go from streaming in to a
readable file, but don't know what the missing components are).

Thoughts?


From hb at stat.berkeley.edu  Tue Apr 20 16:52:28 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 20 Apr 2010 16:52:28 +0200
Subject: [Rd] CRAN: MacOS X binary: not available, see check log?
In-Reply-To: <7473F78E-9A3A-424F-9874-34B49DA9A788@r-project.org>
References: <v2t59d7961d1004142326yb583c865m55e7837532b0d795@mail.gmail.com> 
	<F9E52DA5-25C1-4860-AF53-BDBF1E8165B7@r-project.org>
	<m2i59d7961d1004192357x13cba334ka0f4ad397c2faee4@mail.gmail.com>
	<7473F78E-9A3A-424F-9874-34B49DA9A788@r-project.org>
Message-ID: <l2o59d7961d1004200752oedc2182cp6bca9788543dd291@mail.gmail.com>

On Tue, Apr 20, 2010 at 3:58 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Apr 20, 2010, at 2:57 AM, Henrik Bengtsson wrote:
>
>> Hi,
>>
>> On Thu, Apr 15, 2010 at 3:45 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>>
>>> On Apr 15, 2010, at 2:26 AM, Henrik Bengtsson wrote:
>>>
>>>> For a couple of days, MacOS X binaries are not build on CRAN (for my
>>>> recently uploaded packages only?):
>>>>
>>>
>>> AFAICS your package was posted on Apr 13 so at the earliest it can be built in the Apr 14 run = yesterday. There was no Apr 14 run because the R build failed on Apr 13. I was chasing the subsequent issues yesterday and I think the latest R build is now working so today's package update should be on CRAN soon. Don't forget that packages have to swim across the Atlantic to get built and then back as binaries, so the migration can take a day or two ;).
>>
>> The R.oo doesn't like water and prefers the faster option of flying.
>> But it must have got stranded due to the ash cloud, because it hasn't
>> made the jump back and forth over pond yet. Any updates on next
>> available flight?
>>
>
> As you know the ashes over Iceland grounded all flight traffic from Europe, so we're in a pinch ;).
>
> But seriously - R.oo is on CRAN for a while now:
> http://cran.at.r-project.org/bin/macosx/leopard/contrib/2.11/R.oo_1.7.2.tgz
>
> R.oo_1.7.2.tgz ?13-Apr-2010 11:20 ? ? ? 717K

I see. So, install.packages() will work, and it is only the generated
package page that has a hiccup, cf.

http://cran.r-project.org/web/packages/R.oo/index.html

Thanks (with a deja vu)

/Henrik

>
> Cheers,
> Simon
>
>
>> /Henrik
>>
>> PS. The R.oo is a frequent flyer with lots of miles.
>>
>>
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>> The R.oo package is listed as "MacOS X binary: not available, see
>>>> check log?", but the 'check log' show no errors
>>>> URL: http://cran.r-project.org/web/packages/R.oo/
>>>>
>>>> Is this a known issue?
>>>>
>>>
>>>
>>>
>>>> /Henrik
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>>
>
>


From simon.urbanek at r-project.org  Tue Apr 20 17:05:01 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 20 Apr 2010 11:05:01 -0400
Subject: [Rd] Serial connections?
In-Reply-To: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
Message-ID: <F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>


On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:

> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> 

Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.

Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):

https://svn.rforge.net/C/trunk/tools/ttys.c

and then use something like

f=pipe("ttys /dev/tty.usbserial-X1234")

A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).

Cheers,
Simon

PS: From experience I can say that Arduinos are highly addictive so beware ;).


> In base::connections documentation, it's not clear if there's an easy
> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> solutions.  I'm not sure how sockets work, but possibly there is a way
> to pipe things to a buffer and read from a buffer in bash (in my linux
> mind I have the thought of trying to redirect /dev/something to a
> file, or symlinking a file to point to the hardware, but know that
> there has to be some secret sauce to go from streaming in to a
> readable file, but don't know what the missing components are).
> 
> Thoughts?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From shotwelm at musc.edu  Tue Apr 20 17:51:24 2010
From: shotwelm at musc.edu (shotwelm)
Date: Tue, 20 Apr 2010 11:51:24 -0400
Subject: [Rd] Serial connections?
In-Reply-To: <F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
Message-ID: <1271778684.14629.19.camel@deacon>

I've done some microcontroller work over serial also. Unfortunately,
interfacing with a serial port is system dependent, and the mechanisms
can be quite different, as you probably know. It appears that Simon has
a solution below that will work if you are willing to accept the default
baud rate (9600 is way too slow for good sensor data), parity, etc.. or
use external tools. On POSIX systems, you would need access to the
termios.h header and the system ioctl function in order to change these
settings. Although I'm not 100% sure, I don't think R has this
capability ... yet. 

I'm new to the list, but I'd be surprised if the R developers that have
been around awhile haven't already considered adding support for ioctls
and the POSIX terminal interface. This makes me wonder why it's not
there. If there is no good reason, I'm starting to see a series of R
packages (or core extensions) developing. With a package for ioctls, we
could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM
radio, tuners)...

When I collect sensor data over serial, I do it in python or write a
small C program to dump a single-column csv. Of course, R is excellent
for digital signal processing after that. Check out the DSP
( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I
collected with an Atmel uC. 

-Matt


On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
> 
> > Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> > 
> 
> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
> 
> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
> 
> https://svn.rforge.net/C/trunk/tools/ttys.c
> 
> and then use something like
> 
> f=pipe("ttys /dev/tty.usbserial-X1234")
> 
> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
> 
> Cheers,
> Simon
> 
> PS: From experience I can say that Arduinos are highly addictive so beware ;).
> 
> 
> > In base::connections documentation, it's not clear if there's an easy
> > way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> > solutions.  I'm not sure how sockets work, but possibly there is a way
> > to pipe things to a buffer and read from a buffer in bash (in my linux
> > mind I have the thought of trying to redirect /dev/something to a
> > file, or symlinking a file to point to the hardware, but know that
> > there has to be some secret sauce to go from streaming in to a
> > readable file, but don't know what the missing components are).
> > 
> > Thoughts?
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From seth at userprimary.net  Tue Apr 20 18:02:23 2010
From: seth at userprimary.net (Seth Falcon)
Date: Tue, 20 Apr 2010 09:02:23 -0700
Subject: [Rd] transient memory allocation and external pointers
In-Reply-To: <r2m3aa2e7491004200624s2f1a0a28ofb5781dad86ee84d@mail.gmail.com>
References: <u2z3aa2e7491004190739o1d6bcffbi997ac207d51865e0@mail.gmail.com>
	<80F422FF-8907-4F2F-9AA3-A40423629C61@r-project.org>
	<4BCC9150.10700@userprimary.net>
	<r2m3aa2e7491004200624s2f1a0a28ofb5781dad86ee84d@mail.gmail.com>
Message-ID: <4BCDD00F.5080401@userprimary.net>

On 4/20/10 6:24 AM, Melissa Jane Hubisz wrote:
> Thanks for the responses.  Seth's example is indeed what I was trying
> (hoping) to do, it seems to work on my system fine (ubuntu x86_64, R
> 2.10.1).  But if it doesn't work for him, then that definitely answers
> my question.  I guess I'll have to go the Calloc/Free route.

I expect that you could get your approach to not work on your system as 
well, you just have to try harder ;-)

Memory related bugs can be quite tricky, because incorrect code may run 
fine most of the time.  To trigger a problem, you need to have the right 
pattern of allocation such that data will be written over the memory 
that your invalid external pointer points to.

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From simon.urbanek at r-project.org  Tue Apr 20 22:42:17 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 20 Apr 2010 16:42:17 -0400
Subject: [Rd] Serial connections?
In-Reply-To: <1271778684.14629.19.camel@deacon>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
Message-ID: <121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>


On Apr 20, 2010, at 11:51 AM, shotwelm wrote:

> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data

[OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]


> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet. 
> 
> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.

Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc. 


> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
> 

Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...


> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC. 
> 

Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...

I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...

That's just my $0.02, though ...

Cheers,
Simon


> 
> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
>> 
>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
>>> 
>> 
>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
>> 
>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
>> 
>> https://svn.rforge.net/C/trunk/tools/ttys.c
>> 
>> and then use something like
>> 
>> f=pipe("ttys /dev/tty.usbserial-X1234")
>> 
>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
>> 
>> Cheers,
>> Simon
>> 
>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
>> 
>> 
>>> In base::connections documentation, it's not clear if there's an easy
>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
>>> solutions.  I'm not sure how sockets work, but possibly there is a way
>>> to pipe things to a buffer and read from a buffer in bash (in my linux
>>> mind I have the thought of trying to redirect /dev/something to a
>>> file, or symlinking a file to point to the hardware, but know that
>>> there has to be some secret sauce to go from streaming in to a
>>> readable file, but don't know what the missing components are).
>>> 
>>> Thoughts?
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From shotwelm at musc.edu  Wed Apr 21 03:17:04 2010
From: shotwelm at musc.edu (shotwelm)
Date: Tue, 20 Apr 2010 21:17:04 -0400
Subject: [Rd] Serial connections?
In-Reply-To: <121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
Message-ID: <1271812624.4569.69.camel@deacon>

Simon is right of course, there are plenty of sensors that would work
just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
theorem along these lines (Nyquist sampling theorem?). I think piping
the output to R is a clever solution. I added a few lines to the ttys.c
program so that the baud rate is a command line option (i.e. -B9600)
<http://biostatmatt.com/temp/ttys.c> and confirmed it will compile in
Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
addictive!

For an ioctl package, I was originally thinking of using file
descriptors directly. However, I agree this feels like subverting what
could be an extension of the connections API. Given that "everything is
a file" in POSIX systems, there may be an argument for an ioctl package
that is independent of the connections implementation, say to do things
that connections were not designed to do. For example, interfacing with
V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
read or write calls. But maybe it would just be better to pipe this type
of output to R also...

-Matt

On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
> 
> > I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
> 
> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
> 
> 
> > ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet. 
> > 
> > I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
> 
> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc. 
> 
> 
> > With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
> > 
> 
> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
> 
> 
> > When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC. 
> > 
> 
> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
> 
> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
> 
> That's just my $0.02, though ...
> 
> Cheers,
> Simon
> 
> 
> > 
> > On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
> >> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
> >> 
> >>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> >>> 
> >> 
> >> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
> >> 
> >> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
> >> 
> >> https://svn.rforge.net/C/trunk/tools/ttys.c
> >> 
> >> and then use something like
> >> 
> >> f=pipe("ttys /dev/tty.usbserial-X1234")
> >> 
> >> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
> >> 
> >> Cheers,
> >> Simon
> >> 
> >> PS: From experience I can say that Arduinos are highly addictive so beware ;).
> >> 
> >> 
> >>> In base::connections documentation, it's not clear if there's an easy
> >>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> >>> solutions.  I'm not sure how sockets work, but possibly there is a way
> >>> to pipe things to a buffer and read from a buffer in bash (in my linux
> >>> mind I have the thought of trying to redirect /dev/something to a
> >>> file, or symlinking a file to point to the hardware, but know that
> >>> there has to be some secret sauce to go from streaming in to a
> >>> readable file, but don't know what the missing components are).
> >>> 
> >>> Thoughts?
> >>> 
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> 
> >>> 
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
>


From phgrosjean at sciviews.org  Wed Apr 21 12:30:39 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 21 Apr 2010 12:30:39 +0200
Subject: [Rd] Serial connections?
In-Reply-To: <1271812624.4569.69.camel@deacon>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>	<1271778684.14629.19.camel@deacon>	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon>
Message-ID: <4BCED3CF.3070309@sciviews.org>

There is another option I use since a couple of years to pilot 
scientific devices, to program my chemostats, etc. and that is 
platform-independent: Tcl.

Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in 
R with the tcltk package.

It is really just a mather of a few lines of code in R to communicate 
through a serial port from R using Tcl. Something like:

require(tcltk)
.Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!

# There are many config parameters available here... just an example
.Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')

# Send a command to your device through the serial port
.Tcl('puts -nonewline $R_com1 {my_cmd}')

# Read a line of text from the serial port
line <- tclvalue(.Tcl('gets $R_com1'))

With a little bit more code, one can program Tcl to call R code 
automatically everytime new data is pushed by the connected device 
through the serial port. This is done using something like:

.Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')

Here, "Handler_com1" is a Tcl function. So, some care must be taken 
using tcltk's .Tcl.callback() to trigger the event on the R side. One 
way to deal with this easily is by using tclFun() from the tcltk2 package.

In tcltk2, there is also ?tclTaskSchedule that can be of interest in the 
context of serial port communication to trigger a R function in the 
background regularly and collect data actively from the serial port.

All these tools give me a lot a flexibility to communicate through the 
serial port from R,... and most importantly, to write my code in a 
portable way (tested on Windows XP and Linux Ubuntu).

If there is some interest in this approach, I could initiate a 'tclcom' 
R package on R-Forge and place there the code I have.

Best,

Philippe
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 21/04/10 03:17, shotwelm wrote:
> Simon is right of course, there are plenty of sensors that would work
> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
> theorem along these lines (Nyquist sampling theorem?). I think piping
> the output to R is a clever solution. I added a few lines to the ttys.c
> program so that the baud rate is a command line option (i.e. -B9600)
> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
> addictive!
>
> For an ioctl package, I was originally thinking of using file
> descriptors directly. However, I agree this feels like subverting what
> could be an extension of the connections API. Given that "everything is
> a file" in POSIX systems, there may be an argument for an ioctl package
> that is independent of the connections implementation, say to do things
> that connections were not designed to do. For example, interfacing with
> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
> read or write calls. But maybe it would just be better to pipe this type
> of output to R also...
>
> -Matt
>
> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
>>
>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
>>
>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
>>
>>
>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
>>>
>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
>>
>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
>>
>>
>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
>>>
>>
>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
>>
>>
>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
>>>
>>
>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
>>
>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
>>
>> That's just my $0.02, though ...
>>
>> Cheers,
>> Simon
>>
>>
>>>
>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
>>>>
>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
>>>>>
>>>>
>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
>>>>
>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
>>>>
>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
>>>>
>>>> and then use something like
>>>>
>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
>>>>
>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
>>>>
>>>>
>>>>> In base::connections documentation, it's not clear if there's an easy
>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
>>>>> mind I have the thought of trying to redirect /dev/something to a
>>>>> file, or symlinking a file to point to the hardware, but know that
>>>>> there has to be some secret sauce to go from streaming in to a
>>>>> readable file, but don't know what the missing components are).
>>>>>
>>>>> Thoughts?
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Wed Apr 21 13:37:15 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Apr 2010 12:37:15 +0100 (BST)
Subject: [Rd] New CRAN test platform - Sparc Solaris
Message-ID: <alpine.LFD.2.00.1004200655230.15264@gannet.stats.ox.ac.uk>

The CRAN package check page now shows results on Sparc Solaris 10 
using a server donated by Sun.

This box tests several different aspects from the existing Intel-based 
test boxes:

- the CPU is big-endian.

- it does not have extended-precision doubles in FPU registers.  (It 
does support long doubles if selected explicitly.)

- the C/C++ header set is from a different tradition.

- the Sun Studio compiler is used (as has been on one of the Linux 
boxes, and we may phase the latter out in due course).

- the toolset is AT&T-based Unix rather than GNU or BSD.  In 
particular Solaris make, sed and tar and an actual Bourne shell are 
used.

There is only a limited set of additional software installed.  A few 
things have had to be compiled with gcc, notably the packages using 
Gtk+ (and Solaris' own installation of Gtk+ is too old for RGtk2) and 
MCMCpack.

The server does not have a graphics card and this is causing some 
problems with the X11 installation, including bitmap devices and rgl, 
that we are still working on.

Amongst the package issues shown up are

- unterminated final lines in src/Makevars[.in] cause failures.

- there are many packages which require GNU make and fail to declare 
it.  These include Cairo JavaGD Rcpp RcppExamples RInside farmR 
highlight phyclust png rJava.

- the assumption that 'tar' accepts compressed archives (gdata).

- 60-odd C++ -using packages are not correct C++, often because they 
use GNU extensions or have missing headers (and C++ requires headers 
for prototypes), or use C99 functions that are not in C++ and hence 
not in the headers when used from C++ -- Solaris is rather strict 
about the latter.


Brian Ripley

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Wed Apr 21 14:07:19 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 08:07:19 -0400
Subject: [Rd] Serial connections?
In-Reply-To: <4BCED3CF.3070309@sciviews.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>	<1271778684.14629.19.camel@deacon>	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
Message-ID: <5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>

Philippe,

unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.

I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).

Cheers,
Simon



On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:

> There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
> 
> Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
> 
> It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
> 
> require(tcltk)
> .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
> 
> # There are many config parameters available here... just an example
> .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
> 
> # Send a command to your device through the serial port
> .Tcl('puts -nonewline $R_com1 {my_cmd}')
> 
> # Read a line of text from the serial port
> line <- tclvalue(.Tcl('gets $R_com1'))
> 
> With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
> 
> .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
> 
> Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
> 
> In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
> 
> All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
> 
> If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
> 
> Best,
> 
> Philippe
> ..............................................<?}))><........
> ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
> ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
> ) ) ) ) )   Mons University, Belgium
> ( ( ( ( (
> ..............................................................
> 
> On 21/04/10 03:17, shotwelm wrote:
>> Simon is right of course, there are plenty of sensors that would work
>> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
>> theorem along these lines (Nyquist sampling theorem?). I think piping
>> the output to R is a clever solution. I added a few lines to the ttys.c
>> program so that the baud rate is a command line option (i.e. -B9600)
>> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
>> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
>> addictive!
>> 
>> For an ioctl package, I was originally thinking of using file
>> descriptors directly. However, I agree this feels like subverting what
>> could be an extension of the connections API. Given that "everything is
>> a file" in POSIX systems, there may be an argument for an ioctl package
>> that is independent of the connections implementation, say to do things
>> that connections were not designed to do. For example, interfacing with
>> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
>> read or write calls. But maybe it would just be better to pipe this type
>> of output to R also...
>> 
>> -Matt
>> 
>> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
>>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
>>> 
>>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
>>> 
>>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
>>> 
>>> 
>>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
>>>> 
>>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
>>> 
>>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
>>> 
>>> 
>>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
>>>> 
>>> 
>>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
>>> 
>>> 
>>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
>>>> 
>>> 
>>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
>>> 
>>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
>>> 
>>> That's just my $0.02, though ...
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>>> 
>>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
>>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
>>>>> 
>>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
>>>>>> 
>>>>> 
>>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
>>>>> 
>>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
>>>>> 
>>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
>>>>> 
>>>>> and then use something like
>>>>> 
>>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
>>>>> 
>>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
>>>>> 
>>>>> Cheers,
>>>>> Simon
>>>>> 
>>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
>>>>> 
>>>>> 
>>>>>> In base::connections documentation, it's not clear if there's an easy
>>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
>>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
>>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
>>>>>> mind I have the thought of trying to redirect /dev/something to a
>>>>>> file, or symlinking a file to point to the hardware, but know that
>>>>>> there has to be some secret sauce to go from streaming in to a
>>>>>> readable file, but don't know what the missing components are).
>>>>>> 
>>>>>> Thoughts?
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> 
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 


From phgrosjean at sciviews.org  Wed Apr 21 14:44:19 2010
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 21 Apr 2010 14:44:19 +0200
Subject: [Rd] Serial connections?
In-Reply-To: <5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>	<1271778684.14629.19.camel@deacon>	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>	<1271812624.4569.69.camel@deacon>
	<4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
Message-ID: <4BCEF323.6020408@sciviews.org>

Simon,

I see what you mean, and I agree it would be nice to have a connection. 
That would be the natural way in S.

Yet, connections are driven by R. You cannot open a connection and let 
the connected device trigger some R code when data is available, don't you?

Otherwise, I don't understand your problem with "strings of code". A .R 
file also contains a series of "strings of code" interpreted by the R 
parser when you source() it. Just that code happens to be S. Here the 
code is Tcl. You can source as well a .tcl file with the same code if 
you prefer...

Best,

Philippe

On 21/04/10 14:07, Simon Urbanek wrote:
> Philippe,
>
> unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.
>
> I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).
>
> Cheers,
> Simon
>
>
>
> On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:
>
>> There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
>>
>> Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
>>
>> It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
>>
>> require(tcltk)
>> .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
>>
>> # There are many config parameters available here... just an example
>> .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
>>
>> # Send a command to your device through the serial port
>> .Tcl('puts -nonewline $R_com1 {my_cmd}')
>>
>> # Read a line of text from the serial port
>> line<- tclvalue(.Tcl('gets $R_com1'))
>>
>> With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
>>
>> .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
>>
>> Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
>>
>> In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
>>
>> All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
>>
>> If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
>>
>> Best,
>>
>> Philippe
>> ..............................................<?}))><........
>> ) ) ) ) )
>> ( ( ( ( (    Prof. Philippe Grosjean
>> ) ) ) ) )
>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>> ) ) ) ) )   Mons University, Belgium
>> ( ( ( ( (
>> ..............................................................
>>
>> On 21/04/10 03:17, shotwelm wrote:
>>> Simon is right of course, there are plenty of sensors that would work
>>> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
>>> theorem along these lines (Nyquist sampling theorem?). I think piping
>>> the output to R is a clever solution. I added a few lines to the ttys.c
>>> program so that the baud rate is a command line option (i.e. -B9600)
>>> <http://biostatmatt.com/temp/ttys.c>   and confirmed it will compile in
>>> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
>>> addictive!
>>>
>>> For an ioctl package, I was originally thinking of using file
>>> descriptors directly. However, I agree this feels like subverting what
>>> could be an extension of the connections API. Given that "everything is
>>> a file" in POSIX systems, there may be an argument for an ioctl package
>>> that is independent of the connections implementation, say to do things
>>> that connections were not designed to do. For example, interfacing with
>>> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
>>> read or write calls. But maybe it would just be better to pipe this type
>>> of output to R also...
>>>
>>> -Matt
>>>
>>> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
>>>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
>>>>
>>>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
>>>>
>>>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
>>>>
>>>>
>>>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
>>>>>
>>>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
>>>>
>>>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
>>>>
>>>>
>>>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
>>>>>
>>>>
>>>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
>>>>
>>>>
>>>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
>>>>>
>>>>
>>>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
>>>>
>>>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
>>>>
>>>> That's just my $0.02, though ...
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>>>
>>>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
>>>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
>>>>>>
>>>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
>>>>>>>
>>>>>>
>>>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
>>>>>>
>>>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
>>>>>>
>>>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
>>>>>>
>>>>>> and then use something like
>>>>>>
>>>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
>>>>>>
>>>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
>>>>>>
>>>>>> Cheers,
>>>>>> Simon
>>>>>>
>>>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
>>>>>>
>>>>>>
>>>>>>> In base::connections documentation, it's not clear if there's an easy
>>>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
>>>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
>>>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
>>>>>>> mind I have the thought of trying to redirect /dev/something to a
>>>>>>> file, or symlinking a file to point to the hardware, but know that
>>>>>>> there has to be some secret sauce to go from streaming in to a
>>>>>>> readable file, but don't know what the missing components are).
>>>>>>>
>>>>>>> Thoughts?
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From mdowle at mdowle.plus.com  Wed Apr 21 17:54:01 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 21 Apr 2010 16:54:01 +0100
Subject: [Rd] suggestion how to use memcpy in duplicate.c
Message-ID: <hqn72q$uev$1@dough.gmane.org>

>From copyVector in duplicate.c :

void copyVector(SEXP s, SEXP t)
{
    int i, ns, nt;
    nt = LENGTH(t);
    ns = LENGTH(s);
    switch (TYPEOF(s)) {
...
    case INTSXP:
    for (i = 0; i < ns; i++)
        INTEGER(s)[i] = INTEGER(t)[i % nt];
    break;
...

could that be replaced with :

    case INTSXP:
    for (i=0; i<ns/nt; i++)
        memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t), 
nt*sizeof(int));
    break;

and similar for the other types in copyVector.  This won't help regular 
vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR 
macro, see next suggestion below, but it should help copyMatrix which calls 
copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and 
dounzip.c (once).

For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it 
:

    <FIXME>: surely memcpy would be faster here?

which seems to refer to the for loop  :

    else { \
    int __i__; \
    type *__fp__ = fun(from), *__tp__ = fun(to); \
    for (__i__ = 0; __i__ < __n__; __i__++) \
      __tp__[__i__] = __fp__[__i__]; \
  } \

Could that loop be replaced by the following ?

   else { \
   memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
   }\

In the data.table package, dogroups.c uses this technique, so the principle 
is tested and works well so far.

Are there any road blocks preventing this change, or is anyone already 
working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and 
submit patch with timings, as before.  Comments/pointers much appreciated.

Matthew


From simon.urbanek at r-project.org  Wed Apr 21 19:45:37 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 13:45:37 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <hqn72q$uev$1@dough.gmane.org>
References: <hqn72q$uev$1@dough.gmane.org>
Message-ID: <2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org>

Matt,

On Apr 21, 2010, at 11:54 AM, Matthew Dowle wrote:

>> From copyVector in duplicate.c :
> 
> void copyVector(SEXP s, SEXP t)
> {
>    int i, ns, nt;
>    nt = LENGTH(t);
>    ns = LENGTH(s);
>    switch (TYPEOF(s)) {
> ...
>    case INTSXP:
>    for (i = 0; i < ns; i++)
>        INTEGER(s)[i] = INTEGER(t)[i % nt];
>    break;
> ...
> 
> could that be replaced with :
> 
>    case INTSXP:
>    for (i=0; i<ns/nt; i++)
>        memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t), 
> nt*sizeof(int));
>    break;
> 

Won't that miss the last incomplete chunk? (and please don't use DATAPTR on INTSXP even though the effect is currently the same)

In general it seems that the it depends on nt whether this is efficient or not since calls to short memcpy are expensive (very small nt that is).

 I ran some empirical tests to compare memcpy vs for() (x86_64, OS X) and the results were encouraging - depending on the size of the copied block the difference could be quite big:
tiny block (ca. n = 32 or less) - for() is faster
small block (n ~ 1k) - memcpy is ca. 8x faster
as the size increases the gap closes (presumably due to RAM bandwidth limitations) so for n = 512M it is ~30%.

Of course this is contingent on the implementation of memcpy, compiler, architecture etc. And will only matter if copying is what you do most of the time ...

Cheers,
Simon



> and similar for the other types in copyVector.  This won't help regular 
> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR 
> macro, see next suggestion below, but it should help copyMatrix which calls 
> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and 
> dounzip.c (once).
> 
> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it 
> :
> 
>    <FIXME>: surely memcpy would be faster here?
> 
> which seems to refer to the for loop  :
> 
>    else { \
>    int __i__; \
>    type *__fp__ = fun(from), *__tp__ = fun(to); \
>    for (__i__ = 0; __i__ < __n__; __i__++) \
>      __tp__[__i__] = __fp__[__i__]; \
>  } \
> 
> Could that loop be replaced by the following ?
> 
>   else { \
>   memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>   }\
> 
> In the data.table package, dogroups.c uses this technique, so the principle 
> is tested and works well so far.
> 
> Are there any road blocks preventing this change, or is anyone already 
> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and 
> submit patch with timings, as before.  Comments/pointers much appreciated.
> 
> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ggrothendieck at gmail.com  Wed Apr 21 20:00:33 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 21 Apr 2010 14:00:33 -0400
Subject: [Rd] Bugs? when dealing with contrasts
Message-ID: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>

R version 2.10.1 (2009-12-14)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Below are two cases where I don't seem to be getting contr.sum
contrasts even though they were specified.  Are these bugs?

The first case is an interaction between continuous and factor variables.

The second case contrasts= was specified as an arg to lm.  The second
works ok if we set the contrasts through options but not if we set it
through an lm argument.

>
> # 1. In this case I don't seem to be getting contr.sum contrasts:
>
> options(contrasts = c("contr.sum", "contr.poly"))
> getOption("contrasts")
[1] "contr.sum"  "contr.poly"
> scores <- rep(seq(-2, 2), 3); scores
 [1] -2 -1  0  1  2 -2 -1  0  1  2 -2 -1  0  1  2
> fac <- gl(3, 5); fac
 [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3
Levels: 1 2 3
>
> # I get this:
> model.matrix(~ scores:fac)
   (Intercept) scores:fac1 scores:fac2 scores:fac3
1            1          -2           0           0
2            1          -1           0           0
3            1           0           0           0
4            1           1           0           0
5            1           2           0           0
6            1           0          -2           0
7            1           0          -1           0
8            1           0           0           0
9            1           0           1           0
10           1           0           2           0
11           1           0           0          -2
12           1           0           0          -1
13           1           0           0           0
14           1           0           0           1
15           1           0           0           2
attr(,"assign")
[1] 0 1 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.sum"

>
> # But I was expecting this since I am using contr.sum
> cbind(1, model.matrix(~ fac)[,2:3] * scores)
     fac1 fac2
1  1   -2    0
2  1   -1    0
3  1    0    0
4  1    1    0
5  1    2    0
6  1    0   -2
7  1    0   -1
8  1    0    0
9  1    0    1
10 1    0    2
11 1    2    2
12 1    1    1
13 1    0    0
14 1   -1   -1
15 1   -2   -2
>
>
> # 2.
> # here I don't get contr.sum but rather get contr.treatment
> options(contrasts = c("contr.treatment", "contr.poly"))
> getOption("contrasts")
[1] "contr.treatment" "contr.poly"
> model.matrix(lm(seq(15) ~ fac, contrasts = c("contr.sum", "contr.poly")))
   (Intercept) fac2 fac3
1            1    0    0
2            1    0    0
3            1    0    0
4            1    0    0
5            1    0    0
6            1    1    0
7            1    1    0
8            1    1    0
9            1    1    0
10           1    1    0
11           1    0    1
12           1    0    1
13           1    0    1
14           1    0    1
15           1    0    1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.treatment"

> model.matrix(lm(seq(15) ~ fac)) # same
   (Intercept) fac2 fac3
1            1    0    0
2            1    0    0
3            1    0    0
4            1    0    0
5            1    0    0
6            1    1    0
7            1    1    0
8            1    1    0
9            1    1    0
10           1    1    0
11           1    0    1
12           1    0    1
13           1    0    1
14           1    0    1
15           1    0    1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.treatment"

>
> # I was expecting the first one to give me this
> options(contrasts = c("contr.sum", "contr.poly"))
> model.matrix(lm(seq(15) ~ fac))
   (Intercept) fac1 fac2
1            1    1    0
2            1    1    0
3            1    1    0
4            1    1    0
5            1    1    0
6            1    0    1
7            1    0    1
8            1    0    1
9            1    0    1
10           1    0    1
11           1   -1   -1
12           1   -1   -1
13           1   -1   -1
14           1   -1   -1
15           1   -1   -1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.sum"

>
> R.version.string
[1] "R version 2.10.1 (2009-12-14)"
> win.version()
[1] "Windows Vista (build 6002) Service Pack 2"


From seth at userprimary.net  Wed Apr 21 20:15:08 2010
From: seth at userprimary.net (Seth Falcon)
Date: Wed, 21 Apr 2010 11:15:08 -0700
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org>
References: <hqn72q$uev$1@dough.gmane.org>
	<2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org>
Message-ID: <4BCF40AC.1070408@userprimary.net>

On 4/21/10 10:45 AM, Simon Urbanek wrote:
> Won't that miss the last incomplete chunk? (and please don't use
> DATAPTR on INTSXP even though the effect is currently the same)
>
> In general it seems that the it depends on nt whether this is
> efficient or not since calls to short memcpy are expensive (very
> small nt that is).
>
> I ran some empirical tests to compare memcpy vs for() (x86_64, OS X)
> and the results were encouraging - depending on the size of the
> copied block the difference could be quite big: tiny block (ca. n =
> 32 or less) - for() is faster small block (n ~ 1k) - memcpy is ca. 8x
> faster as the size increases the gap closes (presumably due to RAM
> bandwidth limitations) so for n = 512M it is ~30%.
>

> Of course this is contingent on the implementation of memcpy,
> compiler, architecture etc. And will only matter if copying is what
> you do most of the time ...

Copying of vectors is something that I would expect to happen fairly 
often in many applications of R.

Is for() faster on small blocks by enough that one would want to branch 
based on size?

+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From romain at r-enthusiasts.com  Wed Apr 21 21:32:22 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 21 Apr 2010 21:32:22 +0200
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <hqn72q$uev$1@dough.gmane.org>
References: <hqn72q$uev$1@dough.gmane.org>
Message-ID: <4BCF52C6.8020303@r-enthusiasts.com>

Le 21/04/10 17:54, Matthew Dowle a ?crit :
>
>> From copyVector in duplicate.c :
>
> void copyVector(SEXP s, SEXP t)
> {
>      int i, ns, nt;
>      nt = LENGTH(t);
>      ns = LENGTH(s);
>      switch (TYPEOF(s)) {
> ...
>      case INTSXP:
>      for (i = 0; i<  ns; i++)
>          INTEGER(s)[i] = INTEGER(t)[i % nt];
>      break;
> ...
>
> could that be replaced with :
>
>      case INTSXP:
>      for (i=0; i<ns/nt; i++)
>          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t),
> nt*sizeof(int));
>      break;

or at least with something like this:

int* p_s = INTEGER(s) ;
int* p_t = INTEGER(t) ;
for( i=0 ; i < ns ; i++){
	p_s[i] = p_t[i % nt];
}

since expanding the INTEGER macro over and over has a price.

> and similar for the other types in copyVector.  This won't help regular
> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR
> macro, see next suggestion below, but it should help copyMatrix which calls
> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and
> dounzip.c (once).
>
> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it
> :
>
>      <FIXME>: surely memcpy would be faster here?
>
> which seems to refer to the for loop  :
>
>      else { \
>      int __i__; \
>      type *__fp__ = fun(from), *__tp__ = fun(to); \
>      for (__i__ = 0; __i__<  __n__; __i__++) \
>        __tp__[__i__] = __fp__[__i__]; \
>    } \
>
> Could that loop be replaced by the following ?
>
>     else { \
>     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>     }\
>
> In the data.table package, dogroups.c uses this technique, so the principle
> is tested and works well so far.
>
> Are there any road blocks preventing this change, or is anyone already
> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and
> submit patch with timings, as before.  Comments/pointers much appreciated.
>
> Matthew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/9aKDM9 : embed images in Rd documents
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7


From simon.urbanek at r-project.org  Wed Apr 21 21:35:15 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 15:35:15 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BCF40AC.1070408@userprimary.net>
References: <hqn72q$uev$1@dough.gmane.org>
	<2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org>
	<4BCF40AC.1070408@userprimary.net>
Message-ID: <65D21B93-A737-4A94-BDF4-AD7E90518AC0@r-project.org>


On Apr 21, 2010, at 2:15 PM, Seth Falcon wrote:

> On 4/21/10 10:45 AM, Simon Urbanek wrote:
>> Won't that miss the last incomplete chunk? (and please don't use
>> DATAPTR on INTSXP even though the effect is currently the same)
>> 
>> In general it seems that the it depends on nt whether this is
>> efficient or not since calls to short memcpy are expensive (very
>> small nt that is).
>> 
>> I ran some empirical tests to compare memcpy vs for() (x86_64, OS X)
>> and the results were encouraging - depending on the size of the
>> copied block the difference could be quite big: tiny block (ca. n =
>> 32 or less) - for() is faster small block (n ~ 1k) - memcpy is ca. 8x
>> faster as the size increases the gap closes (presumably due to RAM
>> bandwidth limitations) so for n = 512M it is ~30%.
>> 
> 
>> Of course this is contingent on the implementation of memcpy,
>> compiler, architecture etc. And will only matter if copying is what
>> you do most of the time ...
> 
> Copying of vectors is something that I would expect to happen fairly often in many applications of R.
> 
> Is for() faster on small blocks by enough that one would want to branch based on size?
> 

Good question. Given that the branching itself adds overhead possibly not. In the best case for() can be ~40% faster (for single-digit n) but that means billions of copies to make a difference (since the operation itself is so fast). The break-even point on my test machine is n=32 and when I added the branching it took 20% hit so I guess it's simply not worth it. The only case that may be worth branching is n:1 since that is likely a fairly common use (the branching penalty in copy routines is lower than comparing memcpy/for implementations since the branching can be done before the outer for loop so this may vary case-by-case).

Cheers,
Simon


From simon.urbanek at r-project.org  Wed Apr 21 21:39:58 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 15:39:58 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BCF52C6.8020303@r-enthusiasts.com>
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
Message-ID: <895C584E-A9E5-4E56-B300-8E351080DFEC@r-project.org>


On Apr 21, 2010, at 3:32 PM, Romain Francois wrote:

> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>> 
>>> From copyVector in duplicate.c :
>> 
>> void copyVector(SEXP s, SEXP t)
>> {
>>     int i, ns, nt;
>>     nt = LENGTH(t);
>>     ns = LENGTH(s);
>>     switch (TYPEOF(s)) {
>> ...
>>     case INTSXP:
>>     for (i = 0; i<  ns; i++)
>>         INTEGER(s)[i] = INTEGER(t)[i % nt];
>>     break;
>> ...
>> 
>> could that be replaced with :
>> 
>>     case INTSXP:
>>     for (i=0; i<ns/nt; i++)
>>         memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t),
>> nt*sizeof(int));
>>     break;
> 
> or at least with something like this:
> 
> int* p_s = INTEGER(s) ;
> int* p_t = INTEGER(t) ;
> for( i=0 ; i < ns ; i++){
> 	p_s[i] = p_t[i % nt];
> }
> 
> since expanding the INTEGER macro over and over has a price.
> 

... in packages, yes, but not in core R.

Cheers,
Simon


>> and similar for the other types in copyVector.  This won't help regular
>> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR
>> macro, see next suggestion below, but it should help copyMatrix which calls
>> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and
>> dounzip.c (once).
>> 
>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it
>> :
>> 
>>     <FIXME>: surely memcpy would be faster here?
>> 
>> which seems to refer to the for loop  :
>> 
>>     else { \
>>     int __i__; \
>>     type *__fp__ = fun(from), *__tp__ = fun(to); \
>>     for (__i__ = 0; __i__<  __n__; __i__++) \
>>       __tp__[__i__] = __fp__[__i__]; \
>>   } \
>> 
>> Could that loop be replaced by the following ?
>> 
>>    else { \
>>    memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>>    }\
>> 
>> In the data.table package, dogroups.c uses this technique, so the principle
>> is tested and works well so far.
>> 
>> Are there any road blocks preventing this change, or is anyone already
>> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and
>> submit patch with timings, as before.  Comments/pointers much appreciated.
>> 
>> Matthew
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://bit.ly/9aKDM9 : embed images in Rd documents
> |- http://tr.im/OIXN : raster images and RImageJ
> |- http://tr.im/OcQe : Rcpp 0.7.7
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From romain at r-enthusiasts.com  Wed Apr 21 22:13:24 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 21 Apr 2010 22:13:24 +0200
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <895C584E-A9E5-4E56-B300-8E351080DFEC@r-project.org>
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
	<895C584E-A9E5-4E56-B300-8E351080DFEC@r-project.org>
Message-ID: <4BCF5C64.2060701@r-enthusiasts.com>

Le 21/04/10 21:39, Simon Urbanek a ?crit :
>
>
> On Apr 21, 2010, at 3:32 PM, Romain Francois wrote:
>
>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>
>>>>  From copyVector in duplicate.c :
>>>
>>> void copyVector(SEXP s, SEXP t)
>>> {
>>>      int i, ns, nt;
>>>      nt = LENGTH(t);
>>>      ns = LENGTH(s);
>>>      switch (TYPEOF(s)) {
>>> ...
>>>      case INTSXP:
>>>      for (i = 0; i<   ns; i++)
>>>          INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>      break;
>>> ...
>>>
>>> could that be replaced with :
>>>
>>>      case INTSXP:
>>>      for (i=0; i<ns/nt; i++)
>>>          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t),
>>> nt*sizeof(int));
>>>      break;
>>
>> or at least with something like this:
>>
>> int* p_s = INTEGER(s) ;
>> int* p_t = INTEGER(t) ;
>> for( i=0 ; i<  ns ; i++){
>> 	p_s[i] = p_t[i % nt];
>> }
>>
>> since expanding the INTEGER macro over and over has a price.
>>
>
> ... in packages, yes, but not in core R.

Hmm. I was not talking about the overhead of the INTEGER function:

int *(INTEGER)(SEXP x) {
     if(TYPEOF(x) != INTSXP && TYPEOF(x) != LGLSXP)
	error("%s() can only be applied to a '%s', not a '%s'",
	      "INTEGER", "integer", type2char(TYPEOF(x)));
     return INTEGER(x);
}



but the one related to the macro.

#define INTEGER(x)	((int *) DATAPTR(x))
#define DATAPTR(x)	(((SEXPREC_ALIGN *) (x)) + 1)

so the loop expands to :

for (i = 0; i<   ns; i++)
           ((int *) (((SEXPREC_ALIGN *) (s)) + 1))[i] = ((int *) 
(((SEXPREC_ALIGN *) (t)) + 1))[i % nt];

I still believe grabbing the pointer just once for s and once for t is 
more efficient ...

> Cheers,
> Simon
>
>
>>> and similar for the other types in copyVector.  This won't help regular
>>> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR
>>> macro, see next suggestion below, but it should help copyMatrix which calls
>>> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and
>>> dounzip.c (once).
>>>
>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it
>>> :
>>>
>>>      <FIXME>: surely memcpy would be faster here?
>>>
>>> which seems to refer to the for loop  :
>>>
>>>      else { \
>>>      int __i__; \
>>>      type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>      for (__i__ = 0; __i__<   __n__; __i__++) \
>>>        __tp__[__i__] = __fp__[__i__]; \
>>>    } \
>>>
>>> Could that loop be replaced by the following ?
>>>
>>>     else { \
>>>     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>>>     }\
>>>
>>> In the data.table package, dogroups.c uses this technique, so the principle
>>> is tested and works well so far.
>>>
>>> Are there any road blocks preventing this change, or is anyone already
>>> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and
>>> submit patch with timings, as before.  Comments/pointers much appreciated.
>>>
>>> Matthew


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/9aKDM9 : embed images in Rd documents
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7


From pdalgd at gmail.com  Wed Apr 21 22:26:08 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 21 Apr 2010 22:26:08 +0200
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>
Message-ID: <4BCF5F60.7020203@gmail.com>

Gabor Grothendieck wrote:
> R version 2.10.1 (2009-12-14)
> Copyright (C) 2009 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> Below are two cases where I don't seem to be getting contr.sum
> contrasts even though they were specified.  Are these bugs?
> 
> The first case is an interaction between continuous and factor variables.
> 
> The second case contrasts= was specified as an arg to lm.  The second
> works ok if we set the contrasts through options but not if we set it
> through an lm argument.

In case #2, I think you just failed to read the help page.

> model.matrix(~fac, contrasts=list(fac="contr.sum"))
   (Intercept) fac1 fac2
1            1    1    0
2            1    1    0
3            1    1    0
4            1    1    0
5            1    1    0
6            1    0    1
7            1    0    1
8            1    0    1
9            1    0    1
10           1    0    1
11           1   -1   -1
12           1   -1   -1
13           1   -1   -1
14           1   -1   -1
15           1   -1   -1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.sum"

As for case #1, the rules are tricky in cases where interactions are
present without main effects, but AFAICS, what you observe is
essentially the same effect as

> model.matrix(~fac-1, contrasts=list(fac="contr.sum"))
   fac1 fac2 fac3
1     1    0    0
2     1    0    0
3     1    0    0
4     1    0    0
5     1    0    0
6     0    1    0
7     0    1    0
8     0    1    0
9     0    1    0
10    0    1    0
11    0    0    1
12    0    0    1
13    0    0    1
14    0    0    1
15    0    0    1
attr(,"assign")
[1] 1 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.sum"


I.e., that R reverts to using indicator variables when the intercept is
absent.

> 
>> # 1. In this case I don't seem to be getting contr.sum contrasts:
>>
>> options(contrasts = c("contr.sum", "contr.poly"))
>> getOption("contrasts")
> [1] "contr.sum"  "contr.poly"
>> scores <- rep(seq(-2, 2), 3); scores
>  [1] -2 -1  0  1  2 -2 -1  0  1  2 -2 -1  0  1  2
>> fac <- gl(3, 5); fac
>  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3
> Levels: 1 2 3
>> # I get this:
>> model.matrix(~ scores:fac)
>    (Intercept) scores:fac1 scores:fac2 scores:fac3
> 1            1          -2           0           0
> 2            1          -1           0           0
> 3            1           0           0           0
> 4            1           1           0           0
> 5            1           2           0           0
> 6            1           0          -2           0
> 7            1           0          -1           0
> 8            1           0           0           0
> 9            1           0           1           0
> 10           1           0           2           0
> 11           1           0           0          -2
> 12           1           0           0          -1
> 13           1           0           0           0
> 14           1           0           0           1
> 15           1           0           0           2
> attr(,"assign")
> [1] 0 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.sum"
> 
>> # But I was expecting this since I am using contr.sum
>> cbind(1, model.matrix(~ fac)[,2:3] * scores)
>      fac1 fac2
> 1  1   -2    0
> 2  1   -1    0
> 3  1    0    0
> 4  1    1    0
> 5  1    2    0
> 6  1    0   -2
> 7  1    0   -1
> 8  1    0    0
> 9  1    0    1
> 10 1    0    2
> 11 1    2    2
> 12 1    1    1
> 13 1    0    0
> 14 1   -1   -1
> 15 1   -2   -2
>>
>> # 2.
>> # here I don't get contr.sum but rather get contr.treatment
>> options(contrasts = c("contr.treatment", "contr.poly"))
>> getOption("contrasts")
> [1] "contr.treatment" "contr.poly"
>> model.matrix(lm(seq(15) ~ fac, contrasts = c("contr.sum", "contr.poly")))
>    (Intercept) fac2 fac3
> 1            1    0    0
> 2            1    0    0
> 3            1    0    0
> 4            1    0    0
> 5            1    0    0
> 6            1    1    0
> 7            1    1    0
> 8            1    1    0
> 9            1    1    0
> 10           1    1    0
> 11           1    0    1
> 12           1    0    1
> 13           1    0    1
> 14           1    0    1
> 15           1    0    1
> attr(,"assign")
> [1] 0 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.treatment"
> 
>> model.matrix(lm(seq(15) ~ fac)) # same
>    (Intercept) fac2 fac3
> 1            1    0    0
> 2            1    0    0
> 3            1    0    0
> 4            1    0    0
> 5            1    0    0
> 6            1    1    0
> 7            1    1    0
> 8            1    1    0
> 9            1    1    0
> 10           1    1    0
> 11           1    0    1
> 12           1    0    1
> 13           1    0    1
> 14           1    0    1
> 15           1    0    1
> attr(,"assign")
> [1] 0 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.treatment"
> 
>> # I was expecting the first one to give me this
>> options(contrasts = c("contr.sum", "contr.poly"))
>> model.matrix(lm(seq(15) ~ fac))
>    (Intercept) fac1 fac2
> 1            1    1    0
> 2            1    1    0
> 3            1    1    0
> 4            1    1    0
> 5            1    1    0
> 6            1    0    1
> 7            1    0    1
> 8            1    0    1
> 9            1    0    1
> 10           1    0    1
> 11           1   -1   -1
> 12           1   -1   -1
> 13           1   -1   -1
> 14           1   -1   -1
> 15           1   -1   -1
> attr(,"assign")
> [1] 0 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.sum"
> 
>> R.version.string
> [1] "R version 2.10.1 (2009-12-14)"
>> win.version()
> [1] "Windows Vista (build 6002) Service Pack 2"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Wed Apr 21 22:39:46 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 16:39:46 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BCF5C64.2060701@r-enthusiasts.com>
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
	<895C584E-A9E5-4E56-B300-8E351080DFEC@r-project.org>
	<4BCF5C64.2060701@r-enthusiasts.com>
Message-ID: <6557741D-7D2B-40C7-ABE9-C16CDECAE7DA@r-project.org>


On Apr 21, 2010, at 4:13 PM, Romain Francois wrote:

> Le 21/04/10 21:39, Simon Urbanek a ?crit :
>> 
>> 
>> On Apr 21, 2010, at 3:32 PM, Romain Francois wrote:
>> 
>>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>> 
>>>>> From copyVector in duplicate.c :
>>>> 
>>>> void copyVector(SEXP s, SEXP t)
>>>> {
>>>>     int i, ns, nt;
>>>>     nt = LENGTH(t);
>>>>     ns = LENGTH(s);
>>>>     switch (TYPEOF(s)) {
>>>> ...
>>>>     case INTSXP:
>>>>     for (i = 0; i<   ns; i++)
>>>>         INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>>     break;
>>>> ...
>>>> 
>>>> could that be replaced with :
>>>> 
>>>>     case INTSXP:
>>>>     for (i=0; i<ns/nt; i++)
>>>>         memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t),
>>>> nt*sizeof(int));
>>>>     break;
>>> 
>>> or at least with something like this:
>>> 
>>> int* p_s = INTEGER(s) ;
>>> int* p_t = INTEGER(t) ;
>>> for( i=0 ; i<  ns ; i++){
>>> 	p_s[i] = p_t[i % nt];
>>> }
>>> 
>>> since expanding the INTEGER macro over and over has a price.
>>> 
>> 
>> ... in packages, yes, but not in core R.
> 
> Hmm. I was not talking about the overhead of the INTEGER function:
> 
> int *(INTEGER)(SEXP x) {
>    if(TYPEOF(x) != INTSXP && TYPEOF(x) != LGLSXP)
> 	error("%s() can only be applied to a '%s', not a '%s'",
> 	      "INTEGER", "integer", type2char(TYPEOF(x)));
>    return INTEGER(x);
> }
> 
> 
> 
> but the one related to the macro.
> 
> #define INTEGER(x)	((int *) DATAPTR(x))
> #define DATAPTR(x)	(((SEXPREC_ALIGN *) (x)) + 1)
> 
> so the loop expands to :
> 
> for (i = 0; i<   ns; i++)
>          ((int *) (((SEXPREC_ALIGN *) (s)) + 1))[i] = ((int *) (((SEXPREC_ALIGN *) (t)) + 1))[i % nt];
> 
> I still believe grabbing the pointer just once for s and once for t is more efficient ...
> 

Nope, since everything involved is loop invariant so the pointer values don't change (you'd have to declare s or t volatile to prevent that).

Try using gcc -s and you'll see that the code is the same (depending on the version of gcc the order of the first comparison can change so technically the INTEGER(x) version can save one add instruction in the degenerate case and be faster(!) in old gcc).

Cheers,
Simon



>> 
>>>> and similar for the other types in copyVector.  This won't help regular
>>>> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR
>>>> macro, see next suggestion below, but it should help copyMatrix which calls
>>>> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and
>>>> dounzip.c (once).
>>>> 
>>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it
>>>> :
>>>> 
>>>>     <FIXME>: surely memcpy would be faster here?
>>>> 
>>>> which seems to refer to the for loop  :
>>>> 
>>>>     else { \
>>>>     int __i__; \
>>>>     type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>>     for (__i__ = 0; __i__<   __n__; __i__++) \
>>>>       __tp__[__i__] = __fp__[__i__]; \
>>>>   } \
>>>> 
>>>> Could that loop be replaced by the following ?
>>>> 
>>>>    else { \
>>>>    memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>>>>    }\
>>>> 
>>>> In the data.table package, dogroups.c uses this technique, so the principle
>>>> is tested and works well so far.
>>>> 
>>>> Are there any road blocks preventing this change, or is anyone already
>>>> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and
>>>> submit patch with timings, as before.  Comments/pointers much appreciated.
>>>> 
>>>> Matthew
> 
> 
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://bit.ly/9aKDM9 : embed images in Rd documents
> |- http://tr.im/OIXN : raster images and RImageJ
> |- http://tr.im/OcQe : Rcpp 0.7.7
> 
> 
> 


From ggrothendieck at gmail.com  Wed Apr 21 22:43:32 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 21 Apr 2010 16:43:32 -0400
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <4BCF5F60.7020203@gmail.com>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com> 
	<4BCF5F60.7020203@gmail.com>
Message-ID: <i2l971536df1004211343ibca0d37do8c2bd5470f43ba4f@mail.gmail.com>

On Wed, Apr 21, 2010 at 4:26 PM, Peter Dalgaard <pdalgd at gmail.com> wrote:
> As for case #1, the rules are tricky in cases where interactions are
> present without main effects, but AFAICS, what you observe is
> essentially the same effect as
>
>> model.matrix(~fac-1, contrasts=list(fac="contr.sum"))
> ? fac1 fac2 fac3
> 1 ? ? 1 ? ?0 ? ?0
> 2 ? ? 1 ? ?0 ? ?0
> 3 ? ? 1 ? ?0 ? ?0
> 4 ? ? 1 ? ?0 ? ?0
> 5 ? ? 1 ? ?0 ? ?0
> 6 ? ? 0 ? ?1 ? ?0
> 7 ? ? 0 ? ?1 ? ?0
> 8 ? ? 0 ? ?1 ? ?0
> 9 ? ? 0 ? ?1 ? ?0
> 10 ? ?0 ? ?1 ? ?0
> 11 ? ?0 ? ?0 ? ?1
> 12 ? ?0 ? ?0 ? ?1
> 13 ? ?0 ? ?0 ? ?1
> 14 ? ?0 ? ?0 ? ?1
> 15 ? ?0 ? ?0 ? ?1
> attr(,"assign")
> [1] 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.sum"
>
>
> I.e., that R reverts to using indicator variables when the intercept is
> absent.

Is there any nice way of getting contr.sum coding for the interaction
as opposed to the ugly code in my post that I used to force it? i.e.
cbind(1, model.matrix(~ fac)[,2:3] * scores)


From simon.urbanek at r-project.org  Wed Apr 21 22:48:08 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 21 Apr 2010 16:48:08 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <6557741D-7D2B-40C7-ABE9-C16CDECAE7DA@r-project.org>
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
	<895C584E-A9E5-4E56-B300-8E351080DFEC@r-project.org>
	<4BCF5C64.2060701@r-enthusiasts.com>
	<6557741D-7D2B-40C7-ABE9-C16CDECAE7DA@r-project.org>
Message-ID: <354C80AF-ECEA-4626-A229-29E4929B7676@r-project.org>


On Apr 21, 2010, at 4:39 PM, Simon Urbanek wrote:

> 
> On Apr 21, 2010, at 4:13 PM, Romain Francois wrote:
> 
>> Le 21/04/10 21:39, Simon Urbanek a ?crit :
>>> 
>>> 
>>> On Apr 21, 2010, at 3:32 PM, Romain Francois wrote:
>>> 
>>>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>>> 
>>>>>> From copyVector in duplicate.c :
>>>>> 
>>>>> void copyVector(SEXP s, SEXP t)
>>>>> {
>>>>>    int i, ns, nt;
>>>>>    nt = LENGTH(t);
>>>>>    ns = LENGTH(s);
>>>>>    switch (TYPEOF(s)) {
>>>>> ...
>>>>>    case INTSXP:
>>>>>    for (i = 0; i<   ns; i++)
>>>>>        INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>>>    break;
>>>>> ...
>>>>> 
>>>>> could that be replaced with :
>>>>> 
>>>>>    case INTSXP:
>>>>>    for (i=0; i<ns/nt; i++)
>>>>>        memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char *)DATAPTR(t),
>>>>> nt*sizeof(int));
>>>>>    break;
>>>> 
>>>> or at least with something like this:
>>>> 
>>>> int* p_s = INTEGER(s) ;
>>>> int* p_t = INTEGER(t) ;
>>>> for( i=0 ; i<  ns ; i++){
>>>> 	p_s[i] = p_t[i % nt];
>>>> }
>>>> 
>>>> since expanding the INTEGER macro over and over has a price.
>>>> 
>>> 
>>> ... in packages, yes, but not in core R.
>> 
>> Hmm. I was not talking about the overhead of the INTEGER function:
>> 
>> int *(INTEGER)(SEXP x) {
>>   if(TYPEOF(x) != INTSXP && TYPEOF(x) != LGLSXP)
>> 	error("%s() can only be applied to a '%s', not a '%s'",
>> 	      "INTEGER", "integer", type2char(TYPEOF(x)));
>>   return INTEGER(x);
>> }
>> 
>> 
>> 
>> but the one related to the macro.
>> 
>> #define INTEGER(x)	((int *) DATAPTR(x))
>> #define DATAPTR(x)	(((SEXPREC_ALIGN *) (x)) + 1)
>> 
>> so the loop expands to :
>> 
>> for (i = 0; i<   ns; i++)
>>         ((int *) (((SEXPREC_ALIGN *) (s)) + 1))[i] = ((int *) (((SEXPREC_ALIGN *) (t)) + 1))[i % nt];
>> 
>> I still believe grabbing the pointer just once for s and once for t is more efficient ...
>> 
> 
> Nope, since everything involved is loop invariant so the pointer values don't change (you'd have to declare s or t volatile to prevent that).
> 
> Try using gcc -s

Sorry, I meant gcc -S of course.


> and you'll see that the code is the same (depending on the version of gcc the order of the first comparison can change so technically the INTEGER(x) version can save one add instruction in the degenerate case and be faster(!) in old gcc

[the reason being that INTEGER(x) does not need to be evaluated if the loop is not entered whereas p_s and p_t are populated unconditionally - smarter compilers will notice that p_s/p_t are not used in that case and thus generate identical code in both cases]

Cheers,
Simon


> 
> 
>>> 
>>>>> and similar for the other types in copyVector.  This won't help regular
>>>>> vector copies, since those seem to be done by the DUPLICATE_ATOMIC_VECTOR
>>>>> macro, see next suggestion below, but it should help copyMatrix which calls
>>>>> copyVector, scan.c which calls copyVector on three lines, dcf.c (once) and
>>>>> dounzip.c (once).
>>>>> 
>>>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a comment next to it
>>>>> :
>>>>> 
>>>>>    <FIXME>: surely memcpy would be faster here?
>>>>> 
>>>>> which seems to refer to the for loop  :
>>>>> 
>>>>>    else { \
>>>>>    int __i__; \
>>>>>    type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>>>    for (__i__ = 0; __i__<   __n__; __i__++) \
>>>>>      __tp__[__i__] = __fp__[__i__]; \
>>>>>  } \
>>>>> 
>>>>> Could that loop be replaced by the following ?
>>>>> 
>>>>>   else { \
>>>>>   memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), __n__*sizeof(type)); \
>>>>>   }\
>>>>> 
>>>>> In the data.table package, dogroups.c uses this technique, so the principle
>>>>> is tested and works well so far.
>>>>> 
>>>>> Are there any road blocks preventing this change, or is anyone already
>>>>> working on it ?  If not then I'll try and test it (on Ubuntu 32bit) and
>>>>> submit patch with timings, as before.  Comments/pointers much appreciated.
>>>>> 
>>>>> Matthew
>> 
>> 
>> -- 
>> Romain Francois
>> Professional R Enthusiast
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>> |- http://bit.ly/9aKDM9 : embed images in Rd documents
>> |- http://tr.im/OIXN : raster images and RImageJ
>> |- http://tr.im/OcQe : Rcpp 0.7.7
>> 
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From wdunlap at tibco.com  Thu Apr 22 00:07:04 2010
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 21 Apr 2010 15:07:04 -0700
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BCF52C6.8020303@r-enthusiasts.com>
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>

If I were worried about the time this loop takes,
I would avoid using i%nt.  For the attached C code
compile with gcc 4.3.3 with -O2 I get 
  > # INTEGER() in loop
  > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
     user  system elapsed
    0.060   0.012   0.071

  > # INTEGER() before loop
  > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
     user  system elapsed
    0.076   0.008   0.086

  > # replace i%src_length in loop with j=0 before loop and
  > #    if(++j==src_length) j=0 ;
  > # in the loop.
  > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
     user  system elapsed
    0.024   0.028   0.050
  > identical(r1,r2) && identical(r2,r3)
  [1] TRUE

The C code is:
#define USE_RINTERNALS /* pretend we are in the R kernel */
#include <R.h>
#include <Rinternals.h>


SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int i,j ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    for(i=0;i<dest_length;i++) {
        INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
    }
    UNPROTECT(1) ;
    return s_dest ;
}
SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int *psrc = INTEGER(s_src) ;
    int *pdest ;
    int i ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    pdest = INTEGER(s_dest) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    /* end of boilerplate */
    for(i=0;i<dest_length;i++) {
        pdest[i] = psrc[i % src_length] ;
    }
    UNPROTECT(1) ;
    return s_dest ;
}
SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int *psrc = INTEGER(s_src) ;
    int *pdest ;
    int i,j ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    pdest = INTEGER(s_dest) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    /* end of boilerplate */
    for(j=0,i=0;i<dest_length;i++) {
        *pdest++ = psrc[j++] ;
        if (j==src_length) {
            j = 0 ;
        }
    }
    UNPROTECT(1) ;
    return s_dest ;
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
> Sent: Wednesday, April 21, 2010 12:32 PM
> To: Matthew Dowle
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
> 
> Le 21/04/10 17:54, Matthew Dowle a ?crit :
> >
> >> From copyVector in duplicate.c :
> >
> > void copyVector(SEXP s, SEXP t)
> > {
> >      int i, ns, nt;
> >      nt = LENGTH(t);
> >      ns = LENGTH(s);
> >      switch (TYPEOF(s)) {
> > ...
> >      case INTSXP:
> >      for (i = 0; i<  ns; i++)
> >          INTEGER(s)[i] = INTEGER(t)[i % nt];
> >      break;
> > ...
> >
> > could that be replaced with :
> >
> >      case INTSXP:
> >      for (i=0; i<ns/nt; i++)
> >          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char 
> *)DATAPTR(t),
> > nt*sizeof(int));
> >      break;
> 
> or at least with something like this:
> 
> int* p_s = INTEGER(s) ;
> int* p_t = INTEGER(t) ;
> for( i=0 ; i < ns ; i++){
> 	p_s[i] = p_t[i % nt];
> }
> 
> since expanding the INTEGER macro over and over has a price.
> 
> > and similar for the other types in copyVector.  This won't 
> help regular
> > vector copies, since those seem to be done by the 
> DUPLICATE_ATOMIC_VECTOR
> > macro, see next suggestion below, but it should help 
> copyMatrix which calls
> > copyVector, scan.c which calls copyVector on three lines, 
> dcf.c (once) and
> > dounzip.c (once).
> >
> > For the DUPLICATE_ATOMIC_VECTOR macro there is already a 
> comment next to it
> > :
> >
> >      <FIXME>: surely memcpy would be faster here?
> >
> > which seems to refer to the for loop  :
> >
> >      else { \
> >      int __i__; \
> >      type *__fp__ = fun(from), *__tp__ = fun(to); \
> >      for (__i__ = 0; __i__<  __n__; __i__++) \
> >        __tp__[__i__] = __fp__[__i__]; \
> >    } \
> >
> > Could that loop be replaced by the following ?
> >
> >     else { \
> >     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from), 
> __n__*sizeof(type)); \
> >     }\
> >
> > In the data.table package, dogroups.c uses this technique, 
> so the principle
> > is tested and works well so far.
> >
> > Are there any road blocks preventing this change, or is 
> anyone already
> > working on it ?  If not then I'll try and test it (on 
> Ubuntu 32bit) and
> > submit patch with timings, as before.  Comments/pointers 
> much appreciated.
> >
> > Matthew
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> 
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://bit.ly/9aKDM9 : embed images in Rd documents
> |- http://tr.im/OIXN : raster images and RImageJ
> |- http://tr.im/OcQe : Rcpp 0.7.7
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From djsamperi at gmail.com  Thu Apr 22 02:19:10 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 21 Apr 2010 20:19:10 -0400
Subject: [Rd] RUnit bug?
Message-ID: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100421/234fbcbe/attachment.pl>

From rusers.sh at gmail.com  Thu Apr 22 03:48:51 2010
From: rusers.sh at gmail.com (rusers.sh)
Date: Wed, 21 Apr 2010 21:48:51 -0400
Subject: [Rd] Question of R CMD check
Message-ID: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100421/485c95cd/attachment.pl>

From berwin at maths.uwa.edu.au  Thu Apr 22 05:38:48 2010
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 22 Apr 2010 11:38:48 +0800
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>
Message-ID: <20100422113848.1187240f@bossiaea>

G'day Gabor,

On Wed, 21 Apr 2010 14:00:33 -0400
Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> Below are two cases where I don't seem to be getting contr.sum
> contrasts even though they were specified.  Are these bugs?

Short answer: no. :)

> The first case is an interaction between continuous and factor
> variables.
> 
> The second case contrasts= was specified as an arg to lm.  The second
> works ok if we set the contrasts through options but not if we set it
> through an lm argument.
> 
> >
> > # 1. In this case I don't seem to be getting contr.sum contrasts:
> >
> > options(contrasts = c("contr.sum", "contr.poly"))
> > getOption("contrasts")
> [1] "contr.sum"  "contr.poly"
> > scores <- rep(seq(-2, 2), 3); scores
>  [1] -2 -1  0  1  2 -2 -1  0  1  2 -2 -1  0  1  2
> > fac <- gl(3, 5); fac
>  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3
> Levels: 1 2 3
> >
> > # I get this:
> > model.matrix(~ scores:fac)
>    (Intercept) scores:fac1 scores:fac2 scores:fac3
> 1            1          -2           0           0
> 2            1          -1           0           0
> 3            1           0           0           0
> 4            1           1           0           0
> 5            1           2           0           0
> 6            1           0          -2           0
> 7            1           0          -1           0
> 8            1           0           0           0
> 9            1           0           1           0
> 10           1           0           2           0
> 11           1           0           0          -2
> 12           1           0           0          -1
> 13           1           0           0           0
> 14           1           0           0           1
> 15           1           0           0           2
> attr(,"assign")
> [1] 0 1 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.sum"

When creating the model matrix, the various levels of a factor are
first coded as indicator variables (for creation of the main effects
and for creation of interactions).  The contrast matrix is then
applied to remove redundant columns from the design matrix; that is,
columns that are known to be redundant due to the *design* (i.e. model
formula as a whole), depending on whether data is available for all
levels of a factor (or combinations of levels if several factors are in
the model) you can still end up with a design matrix that does not have
full column rank.

In this case, since there is no main effect fac, the three columns that
are put into the design matrix due to the score:fac term do not create
a singularity, hence the contrast matrix is not applied to these three
columns.

The above description is probably a bit rough and lacking in detail (if
not even wrong in some details).  IMHO, the best explanation of how R
goes from the model formula to the actual design matrix (for linear
models) can still be found in MASS; though, if I am not mistaken,
current versions of R seem to proceed slightly different to that
description in more complicated models (i.e. several factors and
continuous explanatory variables).

> > # But I was expecting this since I am using contr.sum
> > cbind(1, model.matrix(~ fac)[,2:3] * scores)
>      fac1 fac2
> 1  1   -2    0
> 2  1   -1    0
> 3  1    0    0
> 4  1    1    0
> 5  1    2    0
> 6  1    0   -2
> 7  1    0   -1
> 8  1    0    0
> 9  1    0    1
> 10 1    0    2
> 11 1    2    2
> 12 1    1    1
> 13 1    0    0
> 14 1   -1   -1
> 15 1   -2   -2

If you wish to have the design matrix that contains the interaction
terms as if the model had the main effects too but without the columns
corresponding to the main effects, then just instruct R that you want
to have such a matrix:

R> model.matrix(~ scores*fac)[,-(2:4)]
   (Intercept) scores:fac1 scores:fac2
1            1          -2           0
2            1          -1           0
3            1           0           0
4            1           1           0
5            1           2           0
6            1           0          -2
7            1           0          -1
8            1           0           0
9            1           0           1
10           1           0           2
11           1           2           2
12           1           1           1
13           1           0           0
14           1          -1          -1
15           1          -2          -2

Though, I am not sure why one wants to fit such a model.  

> > # 2.
> > # here I don't get contr.sum but rather get contr.treatment
> > options(contrasts = c("contr.treatment", "contr.poly"))
> > getOption("contrasts")
> [1] "contr.treatment" "contr.poly"
> > model.matrix(lm(seq(15) ~ fac, contrasts = c("contr.sum",
> > "contr.poly")))
>    (Intercept) fac2 fac3
> 1            1    0    0
> 2            1    0    0
> 3            1    0    0
> 4            1    0    0
> 5            1    0    0
> 6            1    1    0
> 7            1    1    0
> 8            1    1    0
> 9            1    1    0
> 10           1    1    0
> 11           1    0    1
> 12           1    0    1
> 13           1    0    1
> 14           1    0    1
> 15           1    0    1
> attr(,"assign")
> [1] 0 1 1
> attr(,"contrasts")
> attr(,"contrasts")$fac
> [1] "contr.treatment"

No bug either, but wrong use of the optional argument "contrasts" for 
"lm".  Please read the help page of "lm", which points you to the help
page of "model.matrix.default", which contains pertinent examples; in
your case:

R> model.matrix(lm(seq(15) ~ fac, contrasts = list(fac="contr.sum")))  
   (Intercept) fac1 fac2
1            1    1    0
2            1    1    0
3            1    1    0
4            1    1    0
5            1    1    0
6            1    0    1
7            1    0    1
8            1    0    1
9            1    0    1
10           1    0    1
11           1   -1   -1
12           1   -1   -1
13           1   -1   -1
14           1   -1   -1
15           1   -1   -1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$fac
[1] "contr.sum"

HTH.

Cheers,

	Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)
School of Maths and Stats (M019)            +61 (8) 6488 3383 (self)
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin


From ggrothendieck at gmail.com  Thu Apr 22 06:26:07 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Apr 2010 00:26:07 -0400
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <20100422113848.1187240f@bossiaea>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com> 
	<20100422113848.1187240f@bossiaea>
Message-ID: <s2u971536df1004212126xb4b133a5l6ad338f30472b88e@mail.gmail.com>

On Wed, Apr 21, 2010 at 11:38 PM, Berwin A Turlach
<berwin at maths.uwa.edu.au> wrote:
>> > # But I was expecting this since I am using contr.sum
>> > cbind(1, model.matrix(~ fac)[,2:3] * scores)
>> ? ? ?fac1 fac2
>> 1 ?1 ? -2 ? ?0
>> 2 ?1 ? -1 ? ?0
>> 3 ?1 ? ?0 ? ?0
>> 4 ?1 ? ?1 ? ?0
>> 5 ?1 ? ?2 ? ?0
>> 6 ?1 ? ?0 ? -2
>> 7 ?1 ? ?0 ? -1
>> 8 ?1 ? ?0 ? ?0
>> 9 ?1 ? ?0 ? ?1
>> 10 1 ? ?0 ? ?2
>> 11 1 ? ?2 ? ?2
>> 12 1 ? ?1 ? ?1
>> 13 1 ? ?0 ? ?0
>> 14 1 ? -1 ? -1
>> 15 1 ? -2 ? -2
>
> If you wish to have the design matrix that contains the interaction
> terms as if the model had the main effects too but without the columns
> corresponding to the main effects, then just instruct R that you want
> to have such a matrix:
>
> R> model.matrix(~ scores*fac)[,-(2:4)]
> ? (Intercept) scores:fac1 scores:fac2
> 1 ? ? ? ? ? ?1 ? ? ? ? ?-2 ? ? ? ? ? 0
> 2 ? ? ? ? ? ?1 ? ? ? ? ?-1 ? ? ? ? ? 0
> 3 ? ? ? ? ? ?1 ? ? ? ? ? 0 ? ? ? ? ? 0
> 4 ? ? ? ? ? ?1 ? ? ? ? ? 1 ? ? ? ? ? 0
> 5 ? ? ? ? ? ?1 ? ? ? ? ? 2 ? ? ? ? ? 0
> 6 ? ? ? ? ? ?1 ? ? ? ? ? 0 ? ? ? ? ?-2
> 7 ? ? ? ? ? ?1 ? ? ? ? ? 0 ? ? ? ? ?-1
> 8 ? ? ? ? ? ?1 ? ? ? ? ? 0 ? ? ? ? ? 0
> 9 ? ? ? ? ? ?1 ? ? ? ? ? 0 ? ? ? ? ? 1
> 10 ? ? ? ? ? 1 ? ? ? ? ? 0 ? ? ? ? ? 2
> 11 ? ? ? ? ? 1 ? ? ? ? ? 2 ? ? ? ? ? 2
> 12 ? ? ? ? ? 1 ? ? ? ? ? 1 ? ? ? ? ? 1
> 13 ? ? ? ? ? 1 ? ? ? ? ? 0 ? ? ? ? ? 0
> 14 ? ? ? ? ? 1 ? ? ? ? ?-1 ? ? ? ? ?-1
> 15 ? ? ? ? ? 1 ? ? ? ? ?-2 ? ? ? ? ?-2
>
> Though, I am not sure why one wants to fit such a model.

To save on degrees of freedom.

I had reduced it to the minimum needed to illustrate but in fact its
closer to this (except the coding is not the one needed):

options(contrasts = c("contr.sum", "contr.poly"))
tab <- as.table(matrix(1:21, 7))
dimnames(tab) = list(X = letters[1:7], Y = LETTERS[1:3])
rr <- factor(row(tab))
cc <- factor(col(tab))
scores <- rep(seq(-3,3), 3)
model.matrix( ~ rr + cc + scores:cc)

so the main effects are rr and cc but scores takes the place of rr in
the interaction.

Your description of the process seems right since it would predict
that the following gives the required coding and it does:

model.matrix(~ scores*cc + rr)[,-2]

Thanks.


From pdalgd at gmail.com  Thu Apr 22 08:32:32 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 22 Apr 2010 08:32:32 +0200
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <i2l971536df1004211343ibca0d37do8c2bd5470f43ba4f@mail.gmail.com>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com>
	<4BCF5F60.7020203@gmail.com>
	<i2l971536df1004211343ibca0d37do8c2bd5470f43ba4f@mail.gmail.com>
Message-ID: <4BCFED80.30307@gmail.com>

Gabor Grothendieck wrote:
> On Wed, Apr 21, 2010 at 4:26 PM, Peter Dalgaard <pdalgd at gmail.com> wrote:
...
>> I.e., that R reverts to using indicator variables when the intercept is
>> absent.
> 
> Is there any nice way of getting contr.sum coding for the interaction
> as opposed to the ugly code in my post that I used to force it? i.e.
> cbind(1, model.matrix(~ fac)[,2:3] * scores)

I think not. In general, an interaction like ~fac:scores indicates three
lines with a common intercept and three different slopes, and changing
the parametrization is not supposed to change the model, whereas your
model inserts a restriction that the slopes sum to zero (if I understand
correctly). So if you want to fit "ugly" models, you get to do a little
ugly footwork.

(A similar, simpler, issue arises if you want to have a 2x2 design with
no effect in one column and/or one row (think clinical trial, placebo
vs. active, baseline vs. treated. You can only do this us explicit dummy
variables, not with the two classifications represented as factors.)


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From romain at r-enthusiasts.com  Thu Apr 22 09:51:59 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Thu, 22 Apr 2010 09:51:59 +0200
Subject: [Rd] RUnit bug?
In-Reply-To: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>
References: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>
Message-ID: <4BD0001F.7060009@r-enthusiasts.com>

Le 22/04/10 02:19, Dominick Samperi a ?crit :
>
> There appears to be a bug in RUnit.
>
> Given a testsuite testsuite.math, say, when I run:
>
> runTestSuite(testsuite.math)
>
> this works fine, provided there are no extraneous files in the
> unit test subdirectory.
>
> But if there are any Emacs temp files (with names that
> end with '~') then runTestSuite gets confused and tries to
> run functions from the temp files as well.

How do you define 'testsuite.math'. The default value of the 
testFileRegexp argument in defineTestSuite should rule these files out.

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/9aKDM9 : embed images in Rd documents
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7


From mdowle at mdowle.plus.com  Thu Apr 22 13:12:53 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 22 Apr 2010 12:12:53 +0100
Subject: [Rd] suggestion how to use memcpy in duplicate.c
References: <hqn72q$uev$1@dough.gmane.org><2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org><4BCF40AC.1070408@userprimary.net>
	<65D21B93-A737-4A94-BDF4-AD7E90518AC0@r-project.org>
Message-ID: <hqpavt$em$1@dough.gmane.org>


Is this a thumbs up for memcpy for DUPLICATE_ATOMIC_VECTOR at least ?

If there is further specific testing then let me know, happy to help, but 
you seem to have beaten me to it.

Matthew


"Simon Urbanek" <simon.urbanek at r-project.org> wrote in message 
news:65D21B93-A737-4A94-BDF4-AD7E90518AC0 at r-project.org...
>
> On Apr 21, 2010, at 2:15 PM, Seth Falcon wrote:
>
>> On 4/21/10 10:45 AM, Simon Urbanek wrote:
>>> Won't that miss the last incomplete chunk? (and please don't use
>>> DATAPTR on INTSXP even though the effect is currently the same)
>>>
>>> In general it seems that the it depends on nt whether this is
>>> efficient or not since calls to short memcpy are expensive (very
>>> small nt that is).
>>>
>>> I ran some empirical tests to compare memcpy vs for() (x86_64, OS X)
>>> and the results were encouraging - depending on the size of the
>>> copied block the difference could be quite big: tiny block (ca. n =
>>> 32 or less) - for() is faster small block (n ~ 1k) - memcpy is ca. 8x
>>> faster as the size increases the gap closes (presumably due to RAM
>>> bandwidth limitations) so for n = 512M it is ~30%.
>>>
>>
>>> Of course this is contingent on the implementation of memcpy,
>>> compiler, architecture etc. And will only matter if copying is what
>>> you do most of the time ...
>>
>> Copying of vectors is something that I would expect to happen fairly 
>> often in many applications of R.
>>
>> Is for() faster on small blocks by enough that one would want to branch 
>> based on size?
>>
>
> Good question. Given that the branching itself adds overhead possibly not. 
> In the best case for() can be ~40% faster (for single-digit n) but that 
> means billions of copies to make a difference (since the operation itself 
> is so fast). The break-even point on my test machine is n=32 and when I 
> added the branching it took 20% hit so I guess it's simply not worth it. 
> The only case that may be worth branching is n:1 since that is likely a 
> fairly common use (the branching penalty in copy routines is lower than 
> comparing memcpy/for implementations since the branching can be done 
> before the outer for loop so this may vary case-by-case).
>
> Cheers,
> Simon
>


From mdowle at mdowle.plus.com  Thu Apr 22 13:16:29 2010
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 22 Apr 2010 12:16:29 +0100
Subject: [Rd] suggestion how to use memcpy in duplicate.c
References: <hqn72q$uev$1@dough.gmane.org> <4BCF52C6.8020303@r-enthusiasts.com>
	<77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>
Message-ID: <hqpb6g$163$1@dough.gmane.org>


Just to add some clarification, the suggestion wasn't motivated by speeding 
up a length 3 vector being recycled 3.3 million times.  But its a good point 
that any change should not make that case slower.  I don't know how much 
vectorCopy is called really,  DUPLICATE_ATOMIC_VECTOR seems more 
significant, which doesn't recycle, and already had the FIXME next to it.

Where copyVector is passed a large source though, then memcpy should be 
faster than any of the methods using a for loop through each element 
(whether recycling or not),  allowing for the usual caveats. What are the 
timings like if you repeat the for loop 100 times to get a more robust 
timing ?  It needs to be a repeat around the for loop only, not the 
allocVector whose variance looks to be included in those timings below. Then 
increase the size of the source vector,  and compare to memcpy.

Matthew

"William Dunlap" <wdunlap at tibco.com> wrote in message 
news:77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA at NA-PA-VBE03.na.tibco.com...
If I were worried about the time this loop takes,
I would avoid using i%nt.  For the attached C code
compile with gcc 4.3.3 with -O2 I get
  > # INTEGER() in loop
  > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
     user  system elapsed
    0.060   0.012   0.071

  > # INTEGER() before loop
  > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
     user  system elapsed
    0.076   0.008   0.086

  > # replace i%src_length in loop with j=0 before loop and
  > #    if(++j==src_length) j=0 ;
  > # in the loop.
  > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
     user  system elapsed
    0.024   0.028   0.050
  > identical(r1,r2) && identical(r2,r3)
  [1] TRUE

The C code is:
#define USE_RINTERNALS /* pretend we are in the R kernel */
#include <R.h>
#include <Rinternals.h>


SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int i,j ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    for(i=0;i<dest_length;i++) {
        INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
    }
    UNPROTECT(1) ;
    return s_dest ;
}
SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int *psrc = INTEGER(s_src) ;
    int *pdest ;
    int i ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    pdest = INTEGER(s_dest) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    /* end of boilerplate */
    for(i=0;i<dest_length;i++) {
        pdest[i] = psrc[i % src_length] ;
    }
    UNPROTECT(1) ;
    return s_dest ;
}
SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
{
    int src_length = length(s_src) ;
    int dest_length = asInteger(s_dest_length) ;
    int *psrc = INTEGER(s_src) ;
    int *pdest ;
    int i,j ;
    SEXP s_dest ;
    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
    pdest = INTEGER(s_dest) ;
    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
    /* end of boilerplate */
    for(j=0,i=0;i<dest_length;i++) {
        *pdest++ = psrc[j++] ;
        if (j==src_length) {
            j = 0 ;
        }
    }
    UNPROTECT(1) ;
    return s_dest ;
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
> Sent: Wednesday, April 21, 2010 12:32 PM
> To: Matthew Dowle
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
>
> Le 21/04/10 17:54, Matthew Dowle a ?crit :
> >
> >> From copyVector in duplicate.c :
> >
> > void copyVector(SEXP s, SEXP t)
> > {
> >      int i, ns, nt;
> >      nt = LENGTH(t);
> >      ns = LENGTH(s);
> >      switch (TYPEOF(s)) {
> > ...
> >      case INTSXP:
> >      for (i = 0; i<  ns; i++)
> >          INTEGER(s)[i] = INTEGER(t)[i % nt];
> >      break;
> > ...
> >
> > could that be replaced with :
> >
> >      case INTSXP:
> >      for (i=0; i<ns/nt; i++)
> >          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char
> *)DATAPTR(t),
> > nt*sizeof(int));
> >      break;
>
> or at least with something like this:
>
> int* p_s = INTEGER(s) ;
> int* p_t = INTEGER(t) ;
> for( i=0 ; i < ns ; i++){
> p_s[i] = p_t[i % nt];
> }
>
> since expanding the INTEGER macro over and over has a price.
>
> > and similar for the other types in copyVector.  This won't
> help regular
> > vector copies, since those seem to be done by the
> DUPLICATE_ATOMIC_VECTOR
> > macro, see next suggestion below, but it should help
> copyMatrix which calls
> > copyVector, scan.c which calls copyVector on three lines,
> dcf.c (once) and
> > dounzip.c (once).
> >
> > For the DUPLICATE_ATOMIC_VECTOR macro there is already a
> comment next to it
> > :
> >
> >      <FIXME>: surely memcpy would be faster here?
> >
> > which seems to refer to the for loop  :
> >
> >      else { \
> >      int __i__; \
> >      type *__fp__ = fun(from), *__tp__ = fun(to); \
> >      for (__i__ = 0; __i__<  __n__; __i__++) \
> >        __tp__[__i__] = __fp__[__i__]; \
> >    } \
> >
> > Could that loop be replaced by the following ?
> >
> >     else { \
> >     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from),
> __n__*sizeof(type)); \
> >     }\
> >
> > In the data.table package, dogroups.c uses this technique,
> so the principle
> > is tested and works well so far.
> >
> > Are there any road blocks preventing this change, or is
> anyone already
> > working on it ?  If not then I'll try and test it (on
> Ubuntu 32bit) and
> > submit patch with timings, as before.  Comments/pointers
> much appreciated.
> >
> > Matthew
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
>
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://bit.ly/9aKDM9 : embed images in Rd documents
> |- http://tr.im/OIXN : raster images and RImageJ
> |- http://tr.im/OcQe : Rcpp 0.7.7
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Thu Apr 22 13:30:16 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 22 Apr 2010 07:30:16 -0400
Subject: [Rd] Bugs? when dealing with contrasts
In-Reply-To: <4BCFED80.30307@gmail.com>
References: <l2u971536df1004211100q9beecbep1bceb5bbbd3b8175@mail.gmail.com> 
	<4BCF5F60.7020203@gmail.com>
	<i2l971536df1004211343ibca0d37do8c2bd5470f43ba4f@mail.gmail.com>
	<4BCFED80.30307@gmail.com>
Message-ID: <h2k971536df1004220430y549b3aa3x9f6bfb6006c93d7b@mail.gmail.com>

On Thu, Apr 22, 2010 at 2:32 AM, Peter Dalgaard <pdalgd at gmail.com> wrote:
> Gabor Grothendieck wrote:
>> On Wed, Apr 21, 2010 at 4:26 PM, Peter Dalgaard <pdalgd at gmail.com> wrote:
> ...
>>> I.e., that R reverts to using indicator variables when the intercept is
>>> absent.
>>
>> Is there any nice way of getting contr.sum coding for the interaction
>> as opposed to the ugly code in my post that I used to force it? i.e.
>> cbind(1, model.matrix(~ fac)[,2:3] * scores)
>
> I think not. In general, an interaction like ~fac:scores indicates three
> lines with a common intercept and three different slopes, and changing
> the parametrization is not supposed to change the model, whereas your
> model inserts a restriction that the slopes sum to zero (if I understand
> correctly). So if you want to fit "ugly" models, you get to do a little
> ugly footwork.
>

OK. Thanks.  I guess that's fair.

> (A similar, simpler, issue arises if you want to have a 2x2 design with
> no effect in one column and/or one row (think clinical trial, placebo
> vs. active, baseline vs. treated. You can only do this us explicit dummy
> variables, not with the two classifications represented as factors.)
>
>
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk ?Priv: PDalgd at gmail.com
>


From simon.urbanek at r-project.org  Thu Apr 22 13:42:54 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 22 Apr 2010 07:42:54 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <hqpavt$em$1@dough.gmane.org>
References: <hqn72q$uev$1@dough.gmane.org><2AEC193A-10E8-4D25-89E3-38238E7F16E1@r-project.org><4BCF40AC.1070408@userprimary.net>
	<65D21B93-A737-4A94-BDF4-AD7E90518AC0@r-project.org>
	<hqpavt$em$1@dough.gmane.org>
Message-ID: <AD541236-1DE9-4417-A7AF-2F25162DA8D5@r-project.org>


On Apr 22, 2010, at 7:12 AM, Matthew Dowle wrote:

> 
> Is this a thumbs up for memcpy for DUPLICATE_ATOMIC_VECTOR at least ?
> 
> If there is further specific testing then let me know, happy to help, but 
> you seem to have beaten me to it.
> 

I was not volunteering to do anything - I was just looking at whether it makes sense to bother at all and pointing out the bugs in your code ;). I have a sufficiently long list of TODOs already :P

Cheers,
Simon


> 
> "Simon Urbanek" <simon.urbanek at r-project.org> wrote in message 
> news:65D21B93-A737-4A94-BDF4-AD7E90518AC0 at r-project.org...
>> 
>> On Apr 21, 2010, at 2:15 PM, Seth Falcon wrote:
>> 
>>> On 4/21/10 10:45 AM, Simon Urbanek wrote:
>>>> Won't that miss the last incomplete chunk? (and please don't use
>>>> DATAPTR on INTSXP even though the effect is currently the same)
>>>> 
>>>> In general it seems that the it depends on nt whether this is
>>>> efficient or not since calls to short memcpy are expensive (very
>>>> small nt that is).
>>>> 
>>>> I ran some empirical tests to compare memcpy vs for() (x86_64, OS X)
>>>> and the results were encouraging - depending on the size of the
>>>> copied block the difference could be quite big: tiny block (ca. n =
>>>> 32 or less) - for() is faster small block (n ~ 1k) - memcpy is ca. 8x
>>>> faster as the size increases the gap closes (presumably due to RAM
>>>> bandwidth limitations) so for n = 512M it is ~30%.
>>>> 
>>> 
>>>> Of course this is contingent on the implementation of memcpy,
>>>> compiler, architecture etc. And will only matter if copying is what
>>>> you do most of the time ...
>>> 
>>> Copying of vectors is something that I would expect to happen fairly 
>>> often in many applications of R.
>>> 
>>> Is for() faster on small blocks by enough that one would want to branch 
>>> based on size?
>>> 
>> 
>> Good question. Given that the branching itself adds overhead possibly not. 
>> In the best case for() can be ~40% faster (for single-digit n) but that 
>> means billions of copies to make a difference (since the operation itself 
>> is so fast). The break-even point on my test machine is n=32 and when I 
>> added the branching it took 20% hit so I guess it's simply not worth it. 
>> The only case that may be worth branching is n:1 since that is likely a 
>> fairly common use (the branching penalty in copy routines is lower than 
>> comparing memcpy/for implementations since the branching can be done 
>> before the outer for loop so this may vary case-by-case).
>> 
>> Cheers,
>> Simon
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From it-r-devel at ml.epigenomics.com  Thu Apr 22 19:45:37 2010
From: it-r-devel at ml.epigenomics.com (it-r-devel at ml.epigenomics.com)
Date: Thu, 22 Apr 2010 19:45:37 +0200
Subject: [Rd] RUnit bug?
In-Reply-To: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>
References: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>
Message-ID: <4BD08B41.2020707@epigenomics.com>


Romain has already given you the answer. As would have the help page
?defineTestSuite

Not a bug, but a user error, I assume.

  Matthias

Dominick Samperi wrote, On 04/22/10 02:19:
> There appears to be a bug in RUnit.
> 
> Given a testsuite testsuite.math, say, when I run:
> 
> runTestSuite(testsuite.math)
> 
> this works fine, provided there are no extraneous files in the
> unit test subdirectory.
> 
> But if there are any Emacs temp files (with names that
> end with '~') then runTestSuite gets confused and tries to
> run functions from the temp files as well.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Matthias Burger                       Project Manager/ Biostatistician
Epigenomics AG     Kleine Praesidentenstr. 1     10178 Berlin, Germany
phone:+49-30-24345-0                              fax:+49-30-24345-555
http://www.epigenomics.com             matthias.burger at epigenomics.com
--
Epigenomics AG Berlin             Amtsgericht Charlottenburg HRB 75861
Vorstand:                             Geert Nygaard (CEO/Vorsitzender)
                                              Oliver Schacht PhD (CFO)
Aufsichtsrat:     Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From chuck at sharpsteen.net  Thu Apr 22 21:04:07 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 22 Apr 2010 11:04:07 -0800 (PST)
Subject: [Rd] Rtools for building 64 bit windows packages
Message-ID: <1271963047049-2021034.post@n4.nabble.com>


Hello R developers,

I sincerely apologize if the answer to this question is clearly documented
somewhere, but I was unable to figure it out over my morning coffee.

I just downloaded today's release of R 2.11.0 and installed it on my Windows
7 64 bit VM.  I also downloaded the latest version of Rtools211 from
Professor Murdoch's site.   The first thing I attempted to do was build some
of my packages from source to check that they work with the new version.  I
got the following error message:

  making DLL ...
x86_64-w64-mingw32-gcc -I"C:/PROGRA~1/R/R-211~1.0-X/include"         -O2
-Wall  -std=gnu99 -c tikzDevice.c -o tikzDevice.o
x86_64-w64-mingw32-gcc: not found

This does not surprise me, R 2.11.0 is hot out of the forge and Rtools
probably hasn't been repacked to support the 64 bit version.  I gathered
from the Windows FAQ and the list archives that the MinGW-w64 project
supplies the compilers and linkers used by the 64 bit version- I visited
their site and found the selection of packages available for download...
confusing.

I guess what I'm asking: 

  * Do I use the Cygwin binaries?

  * If not, is there an officially "blessed" binary distribution of Windows
x86_64 compilers and binutils?

  * If not, do I build the x86_64 toolchain from the current HEAD, or is
there a specific revision that has been determined to be stable?


Thanks for your time and effort on maintaining and enhancing such a
wonderful language!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://r.789695.n4.nabble.com/Rtools-for-building-64-bit-windows-packages-tp2021034p2021034.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Thu Apr 22 22:34:43 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Apr 2010 16:34:43 -0400
Subject: [Rd] Rtools for building 64 bit windows packages
In-Reply-To: <1271963047049-2021034.post@n4.nabble.com>
References: <1271963047049-2021034.post@n4.nabble.com>
Message-ID: <4BD0B2E3.4040908@gmail.com>

On 22/04/2010 3:04 PM, Sharpie wrote:
> Hello R developers,
>
> I sincerely apologize if the answer to this question is clearly documented
> somewhere, but I was unable to figure it out over my morning coffee.
>
> I just downloaded today's release of R 2.11.0 and installed it on my Windows
> 7 64 bit VM.  I also downloaded the latest version of Rtools211 from
> Professor Murdoch's site.   The first thing I attempted to do was build some
> of my packages from source to check that they work with the new version.  I
> got the following error message:
>
>   making DLL ...
> x86_64-w64-mingw32-gcc -I"C:/PROGRA~1/R/R-211~1.0-X/include"         -O2
> -Wall  -std=gnu99 -c tikzDevice.c -o tikzDevice.o
> x86_64-w64-mingw32-gcc: not found
>
> This does not surprise me, R 2.11.0 is hot out of the forge and Rtools
> probably hasn't been repacked to support the 64 bit version.  I gathered
> from the Windows FAQ and the list archives that the MinGW-w64 project
> supplies the compilers and linkers used by the 64 bit version- I visited
> their site and found the selection of packages available for download...
> confusing.
>
> I guess what I'm asking: 
>
>   * Do I use the Cygwin binaries?
>   

You can use the Rtools for the stuff other than the compilers.  You need 
the MinGW 64 bit versions of the compilers; they are not nicely packaged 
yet, but the instructions for finding them are in the new version of the 
R-admin manual, in the section 3.3, "Building R for 64 bit Windows". 

Duncan Murdoch
>   * If not, is there an officially "blessed" binary distribution of Windows
> x86_64 compilers and binutils?
>   
>   * If not, do I build the x86_64 toolchain from the current HEAD, or is
> there a specific revision that has been determined to be stable?
>
>
> Thanks for your time and effort on maintaining and enhancing such a
> wonderful language!
>
> -Charlie
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
>


From chuck at sharpsteen.net  Thu Apr 22 23:06:02 2010
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 22 Apr 2010 13:06:02 -0800 (PST)
Subject: [Rd] Rtools for building 64 bit windows packages
In-Reply-To: <4BD0B2E3.4040908@gmail.com>
References: <1271963047049-2021034.post@n4.nabble.com>
	<4BD0B2E3.4040908@gmail.com>
Message-ID: <1271970362689-2022510.post@n4.nabble.com>



Duncan Murdoch-2 wrote:
> 
> You can use the Rtools for the stuff other than the compilers.  You need 
> the MinGW 64 bit versions of the compilers; they are not nicely packaged 
> yet, but the instructions for finding them are in the new version of the 
> R-admin manual, in the section 3.3, "Building R for 64 bit Windows". 
> 

Ahh, thank you Duncan- this was exactly the information I was looking for. 
When I looked in R-admin this morning, I skipped straight to Appendix D as I
wasn't interested in building R, just packages.

Thanks again!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://r.789695.n4.nabble.com/Rtools-for-building-64-bit-windows-packages-tp2021034p2022510.html
Sent from the R devel mailing list archive at Nabble.com.


From djsamperi at gmail.com  Thu Apr 22 23:25:43 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 22 Apr 2010 17:25:43 -0400
Subject: [Rd] RUnit bug?
In-Reply-To: <4BD0001F.7060009@r-enthusiasts.com>
References: <i2pd4cf43b61004211719ub28cdc53oc5a3281cd83d67ae@mail.gmail.com>
	<4BD0001F.7060009@r-enthusiasts.com>
Message-ID: <h2zd4cf43b61004221425od54c9f47ne513ee4fac37bd26@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100422/e60e4c5e/attachment.pl>

From spluque at gmail.com  Fri Apr 23 01:32:54 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 22 Apr 2010 18:32:54 -0500
Subject: [Rd] segfault with format.POSIXct()
Message-ID: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>

Hi,

I'm getting a segmentation fault as follows:

---<--------------------cut here---------------start------------------->---
R> begt <- as.POSIXct(strptime("10/01/2009 06:00:00", format="%d/%m/%Y %H:%M:%S"),
+                    tz="GMT")
R> tser <- seq(begt, by=5, length.out=91000)
R> tser.trunc <- format(tser)
Error: segfault from C stack overflow
---<--------------------cut here---------------end--------------------->---

With the following set up:

---<--------------------cut here---------------start------------------->---
R> sessionInfo()
R version 2.11.0 RC (2010-04-19 r51778) 
x86_64-pc-linux-gnu 

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] slmisc_0.7.3   lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.11.0
---<--------------------cut here---------------end--------------------->---


Reducing the size of the sequence in seq.POSIXct() to 90000 doesn't
cause a segfault, so it seems to be a memory issue.  Is this a bug?

Thanks,

-- 
Seb


From murdoch.duncan at gmail.com  Fri Apr 23 11:07:41 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Apr 2010 05:07:41 -0400
Subject: [Rd] Question of R CMD check
In-Reply-To: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>
Message-ID: <4BD1635D.7050802@gmail.com>

On 21/04/2010 9:48 PM, rusers.sh wrote:
> Hi all,
>     Today, i just installed the newest R version 2.10.1 and other necessary
> tools for building R package under windows,e.g. Rtools, perl. All are the
> newest version.
>   After the correct configuration under windows (configuration should be
> correct), i use it to re-check my old package. I found the following prolem
> when checking EXAMPLEs in each function, which did not exist before this
> re-installation.
> ########
> * checking examples ... ERROR
>  Running examples in 'stam-Ex.R' failed.
> ########
>   I used "\dontrun{} % enddontrun" in all the examples of my functions that
> should be no problem, i think. I checked my package before and did not find
> errors. I also browsed the checking results in 'stam-Ex.R'. It listed all
> the example codes in that file, something like this,
>   cleanEx(); nameEx("stcdt")
>   ### * stcdt
>   flush(stderr()); flush(stdout())
>   ###example codes
>
>   I did not met this problem before.  Any ideas on solving this?
>   Thanks a lot.
>
>   
You need to show us the end of the stam-Ex.Rout file.  It will contain 
the error message.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Fri Apr 23 13:31:14 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 23 Apr 2010 13:31:14 +0200
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
Message-ID: <4BD18502.7020505@statistik.tu-dortmund.de>

Works for me, both under Windows (32 and 64 bit) and Linux, although I 
have not package slmisc attached.

Uwe Ligges



On 23.04.2010 01:32, Sebastian P. Luque wrote:
> Hi,
>
> I'm getting a segmentation fault as follows:
>
> ---<--------------------cut here---------------start------------------->---
> R>  begt<- as.POSIXct(strptime("10/01/2009 06:00:00", format="%d/%m/%Y %H:%M:%S"),
> +                    tz="GMT")
> R>  tser<- seq(begt, by=5, length.out=91000)
> R>  tser.trunc<- format(tser)
> Error: segfault from C stack overflow
> ---<--------------------cut here---------------end--------------------->---
>
> With the following set up:
>
> ---<--------------------cut here---------------start------------------->---
> R>  sessionInfo()
> R version 2.11.0 RC (2010-04-19 r51778)
> x86_64-pc-linux-gnu
>
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] slmisc_0.7.3   lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.0
> ---<--------------------cut here---------------end--------------------->---
>
>
> Reducing the size of the sequence in seq.POSIXct() to 90000 doesn't
> cause a segfault, so it seems to be a memory issue.  Is this a bug?
>
> Thanks,
>


From murdoch.duncan at gmail.com  Fri Apr 23 13:46:10 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Apr 2010 07:46:10 -0400
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <4BD18502.7020505@statistik.tu-dortmund.de>
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
	<4BD18502.7020505@statistik.tu-dortmund.de>
Message-ID: <4BD18882.7060608@gmail.com>

On 23/04/2010 7:31 AM, Uwe Ligges wrote:
> Works for me, both under Windows (32 and 64 bit) and Linux, although I 
> have not package slmisc attached.
>   

I've just found that the bug 14267 is related to a POSIXlt formatting 
bug, so this is likely to be the same thing. 

Duncan Murdoch
> Uwe Ligges
>
>
>
> On 23.04.2010 01:32, Sebastian P. Luque wrote:
>   
>> Hi,
>>
>> I'm getting a segmentation fault as follows:
>>
>> ---<--------------------cut here---------------start------------------->---
>> R>  begt<- as.POSIXct(strptime("10/01/2009 06:00:00", format="%d/%m/%Y %H:%M:%S"),
>> +                    tz="GMT")
>> R>  tser<- seq(begt, by=5, length.out=91000)
>> R>  tser.trunc<- format(tser)
>> Error: segfault from C stack overflow
>> ---<--------------------cut here---------------end--------------------->---
>>
>> With the following set up:
>>
>> ---<--------------------cut here---------------start------------------->---
>> R>  sessionInfo()
>> R version 2.11.0 RC (2010-04-19 r51778)
>> x86_64-pc-linux-gnu
>>
>> locale:
>>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>   [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8    LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] slmisc_0.7.3   lattice_0.18-3
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.0
>> ---<--------------------cut here---------------end--------------------->---
>>
>>
>> Reducing the size of the sequence in seq.POSIXct() to 90000 doesn't
>> cause a segfault, so it seems to be a memory issue.  Is this a bug?
>>
>> Thanks,
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spluque at gmail.com  Fri Apr 23 14:48:25 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 23 Apr 2010 07:48:25 -0500
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <4BD18882.7060608@gmail.com> (Duncan Murdoch's message of "Fri,
	23 Apr 2010 07:46:10 -0400")
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
	<4BD18502.7020505@statistik.tu-dortmund.de>
	<4BD18882.7060608@gmail.com>
Message-ID: <87zl0u72sm.fsf@kolob.sebmags.homelinux.org>

On Fri, 23 Apr 2010 07:46:10 -0400,
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 23/04/2010 7:31 AM, Uwe Ligges wrote:
>> Works for me, both under Windows (32 and 64 bit) and Linux, although
>> I have not package slmisc attached.


> I've just found that the bug 14267 is related to a POSIXlt formatting
> bug, so this is likely to be the same thing.

I just tried with:

---<--------------------cut here---------------start------------------->---
R> sessionInfo()
R version 2.12.0 Under development (unstable) (2010-04-23 r51810) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8   
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
---<--------------------cut here---------------end--------------------->---

and using a sequence of 200000 worked without problems.  It doesn't seem
as if bug 14267 has been fixed in the 2.12.0 devel version above, but
something else might have fixed the C stack overflow I'm getting.

Thanks for the pointers!

-- 
Seb


From spluque at gmail.com  Fri Apr 23 14:50:23 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 23 Apr 2010 07:50:23 -0500
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <4BD18502.7020505@statistik.tu-dortmund.de> (Uwe Ligges's message
	of "Fri, 23 Apr 2010 13:31:14 +0200")
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
	<4BD18502.7020505@statistik.tu-dortmund.de>
Message-ID: <87vdbi72pc.fsf@kolob.sebmags.homelinux.org>

On Fri, 23 Apr 2010 13:31:14 +0200,
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> Works for me, both under Windows (32 and 64 bit) and Linux, although I
> have not package slmisc attached.

Is this with 2.11.0 ?  Thanks.

-- 
Seb


From pdalgd at gmail.com  Fri Apr 23 16:03:15 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 23 Apr 2010 16:03:15 +0200
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <87vdbi72pc.fsf@kolob.sebmags.homelinux.org>
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
	<4BD18502.7020505@statistik.tu-dortmund.de>
	<87vdbi72pc.fsf@kolob.sebmags.homelinux.org>
Message-ID: <A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com>


On Apr 23, 2010, at 2:50 PM, Sebastian P. Luque wrote:

> On Fri, 23 Apr 2010 13:31:14 +0200,
> Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
>> Works for me, both under Windows (32 and 64 bit) and Linux, although I
>> have not package slmisc attached.
> 
> Is this with 2.11.0 ?  Thanks.

I'm getting a bit further with bug 14267:

On OSX I am NOT seeing it with R-devel, although it is there with 2.11.0 Patched.

Running with a non-optimized compile, I can get some more information

It is happening on the i-th iteration of the loop in do_formatPOSIXlt with 

(gdb) p i
$4 = 86870

Unfortunately, it looks like a bigger exercise to get valgrind running on Snow Leopard -- too big for Friday afternoon anyway. However, the alloca() call on line 774 of src/main/datetime.c does look suspect to me. I can see that it was introduced with r51353 and has since disappeared in R-devel (r51398).
 

> -- 
> Seb
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri Apr 23 16:17:32 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Apr 2010 10:17:32 -0400
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com>
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>	<4BD18502.7020505@statistik.tu-dortmund.de>	<87vdbi72pc.fsf@kolob.sebmags.homelinux.org>
	<A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com>
Message-ID: <4BD1ABFC.5030101@gmail.com>

On 23/04/2010 10:03 AM, peter dalgaard wrote:
> On Apr 23, 2010, at 2:50 PM, Sebastian P. Luque wrote:
>
> > On Fri, 23 Apr 2010 13:31:14 +0200,
> > Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> > 
> >> Works for me, both under Windows (32 and 64 bit) and Linux, although I
> >> have not package slmisc attached.
> > 
> > Is this with 2.11.0 ?  Thanks.
>
> I'm getting a bit further with bug 14267:
>
> On OSX I am NOT seeing it with R-devel, although it is there with 2.11.0 Patched.
>
> Running with a non-optimized compile, I can get some more information
>
> It is happening on the i-th iteration of the loop in do_formatPOSIXlt with 
>
> (gdb) p i
> $4 = 86870
>
> Unfortunately, it looks like a bigger exercise to get valgrind running on Snow Leopard -- too big for Friday afternoon anyway. However, the alloca() call on line 774 of src/main/datetime.c does look suspect to me. I can see that it was introduced with r51353 and has since disappeared in R-devel (r51398).

I've just committed a patch for this on R-2-11-branch.  The problem was 
that the alloca() was within a loop, so it kept allocating more and more 
space until the end of the function call, and blew the stack. In 
R-devel, this was changed to the C99 construct of defining a variable 
sized array within a block, and that was fine, because it was released 
at the end of the block, not at the end of the function call.

Duncan Murdoch


From spluque at gmail.com  Fri Apr 23 16:24:22 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 23 Apr 2010 09:24:22 -0500
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com> (peter
	dalgaard's message of "Fri, 23 Apr 2010 16:03:15 +0200")
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>
	<4BD18502.7020505@statistik.tu-dortmund.de>
	<87vdbi72pc.fsf@kolob.sebmags.homelinux.org>
	<A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com>
Message-ID: <87aasu6ycp.fsf@kolob.sebmags.homelinux.org>

On Fri, 23 Apr 2010 16:03:15 +0200,
peter dalgaard <pdalgd at gmail.com> wrote:

> I'm getting a bit further with bug 14267: On OSX I am NOT seeing it
> with R-devel, although it is there with 2.11.0 Patched.

> Running with a non-optimized compile, I can get some more information

> It is happening on the i-th iteration of the loop in do_formatPOSIXlt
> with

> (gdb) p i $4 = 86870

> Unfortunately, it looks like a bigger exercise to get valgrind running
> on Snow Leopard -- too big for Friday afternoon anyway. However, the
> alloca() call on line 774 of src/main/datetime.c does look suspect to
> me. I can see that it was introduced with r51353 and has since
> disappeared in R-devel (r51398).

So it does seems as if this is all related to that bug, which somehow
got fixed in R-devel.

Thanks everyone,

-- 
Seb


From pdalgd at gmail.com  Fri Apr 23 16:36:02 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 23 Apr 2010 16:36:02 +0200
Subject: [Rd] segfault with format.POSIXct()
In-Reply-To: <4BD1ABFC.5030101@gmail.com>
References: <87r5m783mh.fsf@kolob.sebmags.homelinux.org>	<4BD18502.7020505@statistik.tu-dortmund.de>	<87vdbi72pc.fsf@kolob.sebmags.homelinux.org>
	<A2E661EF-ACF5-42AF-8ED8-35C5710CF8FA@gmail.com>
	<4BD1ABFC.5030101@gmail.com>
Message-ID: <04A1D6AB-6788-4E88-B413-2C122635C3F3@gmail.com>


On Apr 23, 2010, at 4:17 PM, Duncan Murdoch wrote:

> On 23/04/2010 10:03 AM, peter dalgaard wrote:
>> On Apr 23, 2010, at 2:50 PM, Sebastian P. Luque wrote:
>> 
>> > On Fri, 23 Apr 2010 13:31:14 +0200,
>> > Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>> > >> Works for me, both under Windows (32 and 64 bit) and Linux, although I
>> >> have not package slmisc attached.
>> > > Is this with 2.11.0 ?  Thanks.
>> 
>> I'm getting a bit further with bug 14267:
>> 
>> On OSX I am NOT seeing it with R-devel, although it is there with 2.11.0 Patched.
>> 
>> Running with a non-optimized compile, I can get some more information
>> 
>> It is happening on the i-th iteration of the loop in do_formatPOSIXlt with 
>> (gdb) p i
>> $4 = 86870
>> 
>> Unfortunately, it looks like a bigger exercise to get valgrind running on Snow Leopard -- too big for Friday afternoon anyway. However, the alloca() call on line 774 of src/main/datetime.c does look suspect to me. I can see that it was introduced with r51353 and has since disappeared in R-devel (r51398).
> 
> I've just committed a patch for this on R-2-11-branch.  The problem was that the alloca() was within a loop, so it kept allocating more and more space until the end of the function call, and blew the stack. In R-devel, this was changed to the C99 construct of defining a variable sized array within a block, and that was fine, because it was released at the end of the block, not at the end of the function call.

Yes, that's what I suspected. Thanks for the fix!

-p

> Duncan Murdoch

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Fri Apr 23 17:20:39 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 23 Apr 2010 10:20:39 -0500
Subject: [Rd] Deferred Default Marker
Message-ID: <1272036039.5556.17.camel@punchbuggy>

I've finally narrowed down a puzzling problem: here is the short test
case.

tmt34% R --vanilla

R version 2.10.0 (2009-10-26)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

> temp <- matrix(runif(50), ncol=2)
> t(temp) %*% temp
         [,1]     [,2]
[1,] 7.916016 6.049698
[2,] 6.049698 7.650694

> library(kinship)
Loading required package: survival
Loading required package: splines
Loading required package: nlme
Loading required package: lattice
> t(temp) %*% temp
`__Deferred_Default_Marker__`

-----------------------------------------

Within the library is a definition of %*% for bdsmatrix objects, which
is perhaps the issue.  But I'm only guessing since I don't have a clear
idea what the error message means.  Any hints are appreciated.

The new coxme/bsdmatrix packages need only a couple more functions to be
a complete replacement for kinship, at which point we will depreciate
it. (Pedigrees and plotting were finished last weekend!)  But I can't
quite do that yet. The error does not arise with these newer libraries.
There have been no changes to kinship for some time.

  Terry Therneau


> sessionInfo()
R version 2.10.0 (2009-10-26) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets
methods  
[8] base     
other attached packages:
[1] kinship_1.1.0-11 lattice_0.17-26  nlme_3.1-96      survival_2.35-9 

loaded via a namespace (and not attached):
[1] grid_2.10.0
>


From shotwelm at musc.edu  Fri Apr 23 19:11:34 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Fri, 23 Apr 2010 13:11:34 -0400
Subject: [Rd] Lapack, determinant, multivariate normal density,
	solution to linear system, C language
In-Reply-To: <i2m40e66e0b1004190944o56d89ee2hd8fd3fcfbc75f1e7@mail.gmail.com>
References: <1271129244.10914.34.camel@deacon>
	<i2m40e66e0b1004190944o56d89ee2hd8fd3fcfbc75f1e7@mail.gmail.com>
Message-ID: <1272042694.3797.46.camel@deacon>

Douglas, 

Thanks for your reply. I took your suggestion and tried the Cholesky
factorization with dppsv, the positive definite version of dspsv. I
found dppsv to be a great deal faster than dspsv, as might be expected
since dspsv uses a more complicated factorization. However, I ran into
trouble with computational singularities with dppsv. In this particular
case, I don't mind having least squares solutions that aren't unique.
The dspsv routine appears to be more robust in this regard. The speed is
sufficiently improved with dppsv that I opted to use both in the code,
trying dppsv first, then dspsv if dppsv fails.

I agree, packed storage was more trouble than it was worth in this case,
but yielded mild to moderate improvements in speed and memory usage.
Addressing the elements of a packed matrix can be complicated, but it
makes a difference whether it's upper packed, or lower packed. To
address each type of matrix, I use the following macros

//address upper triangular packed storage matrix
//a00, a01, a11, a02, a12, a22, a03, a13, a23, a33, ...
//0 <= i <= j < n
#define UMAT(i, j) (i + j * ( j + 1 ) / 2)

//address symmetric full storage (by column) matrix
//a00, a10, ..., an0, a01, a11, ..., an1, ...
//0 <= i, j < n
#define FMAT(i, j, n) (i + j * n)

//address lower triangular packed storage matrix
//a00, a10, ... ,an0, a11, a21, ..., an1, a22, a32, ...
//0 <= j <= i < n
#define LMAT(i, j, n) (i + j * ( 2 * n - j + 1 ) / 2)

Notice that UMAT doesn't require the matrix dimension n! Hence, when n
is retrieved from memory, it may be more efficient to address an upper
packed storage matrix than a full storage matrix. I'll have to test this
theory, though it's probably compiler dependent.

Thanks again,

-Matt

On Mon, 2010-04-19 at 12:44 -0400, Douglas Bates wrote:
> On Mon, Apr 12, 2010 at 10:27 PM, shotwelm <shotwelm at musc.edu> wrote:
> > r-devel list,
> >
> > I have recently written an R package that solves a linear least squares
> > problem, and computes the multivariate normal density function.
> 
> For both of those applications you can use a Cholesky decomposition of
> the symmetric matrix.  If the Cholesky decomposition fails then you
> have a singular least squares problem or a singular
> variance-covariance matrix for your multivariate normal density
> function.
> 
> Have you tried comparing the speed of your code to
> 
> prod(diag(chol(mm))^2
> 
> or, probably better, is to use the logarithm of the determinant
> 
> 2 * sum(log(diag(chol(mm)))
> 
> If you use the Matrix package class dpoMatrix to solve the linear
> system it will cache the results of the Cholesky decomposition when
> solving the system so later evaluation of the determinant will be very
> fast - although I suspect you would need to be working with matrices
> of sizes in the hundreds or doing the same operation thousands of
> times before you would notice a difference.
> 
> If you really insist on doing this in compiled code you just need to
> call F77_CALL(dpotrf) then accumulate the product of the diagonal
> elements of the resulting factor.
> 
> You could use packed storage but the slight advantage in memory usage
> (at best, 1/2 of the full storage usage) is not worth the pain of
> writing code to navigate the packed storage locations.
> 
> > The bulk
> > of the code is written in C, with interfacing code to the BLAS and
> > Lapack libraries. The motivation here is speed. I ran into a problem
> > computing the determinant of a symmetric matrix in packed storage.
> > Apparently, there are no explicit routines for this as part of Lapack.
> > While there IS an explicit routine for this in Linpack, I did not want
> > to use the older library. Also, right before I needed the determinant of
> > the matrix A, I had used the Lapack routine dspsv to solve the linear
> > system Ax=b, which does much of the work of computing a determinant
> > also. In fact, the solution I came up with involves the output of this
> > routine (which might be obvious to Lapack designers, but not me)
> >
> > My modest Googleing turned up very little unique material (as is typical
> > with BLAS/Lapack/Linpack queries). Hence, I am writing the r-devel list
> > partly to document the solution I've come up with, but mainly to elicit
> > additional wisdom from seasoned R programmers.
> >
> > My solution to the problem is illustrated in the appended discussion and
> > C code. Thanks for your input.
> >
> > -Matt Shotwell
> >
> > --------------
> >
> > The Lapack routine dspsv solves the linear system of equations Ax=b,
> > where A is a symmetric matrix in packed storage format. The dspsv
> > function performs the factorization A=UDU', where U is a unitriangular
> > matrix and D is a block diagonal matrix where the blocks are of
> > dimension 1x1 or 2x2. In addition to the solution for x, the dspsv
> > function also returns the matrices U and D. The matrix D may then be
> > used to compute the determinant of A. Recall from linear algebra that
> > det(A) = det(UDU') = det(U)det(D)det(U'). Since U is unitriangular,
> > det(U) = 1. The determinant of D is the product of the determinants of
> > the diagonal blocks. If a diagonal block is of dimension 1x1, then the
> > determinant of the block is simply the value of the single element in
> > the block. If the diagonal block is of dimension 2x2 then the
> > determinant of the block may be computed according to the well-known
> > formula b11*b22-b12*b21, where bij is the value in the i'th row and j'th
> > column of the block.
> >
> >  int i, q, info, *ipiv, one = 1;
> >  double *b, *A, *D, det;
> >
> >  /*
> >  ** A and D are upper triangular matrices in packed storage
> >  ** A[] = a00, a01, a11, a02, a12, a22, a03, a13, a23, a33, ...
> >  ** use the following macro to address the element in the
> >  ** i'th row and j'th column for i <= j
> >  */
> >  #define UMAT(i, j) (i + j * ( j + 1 ) / 2)
> >
> >  /*
> >  ** additional code should be here
> >  ** - set q
> >  ** - allocate ipiv...
> >  ** - allocate and fill A and b...
> >  */
> >
> >  /*
> >  ** solve Ax=b using A=UDU' factorization where
> >  ** A represents a qxq matrix, b a 1xq vector.
> >  ** dspsv outputs the elements of the matrix D
> >  ** is upper triangular packed storage
> >  ** in the memory addressed by A. That is, A is
> >  ** replaced by D when dspsv returns.
> >  */
> >  F77_CALL(dspsv)("U", &q, &one, A, ipiv, b, &q, &info);
> >  if( info > 0 ) { /*issue warning, system is singular*/ }
> >  if( info < 0 ) { /*issue error, invalid argument*/ }
> >
> >  /*
> >  ** compute the determinant det = det(A)
> >  ** if ipiv[i] > 0, then D(i,i) is a 1x1 block diagonal
> >  ** if ipiv[i] = ipiv[i-1] < 0, then D(i-1,i-1),
> >  ** D(i-1,i), and D(i,i) form the upper triangle
> >  ** of a 2x2 block diagonal
> >  */
> >  D = A;
> >  det = 1.0;
> >  for( i = 0; i < q; i++ ) {
> >    if( ipiv[ i ] > 0 ) {
> >      det *= D[ UMAT(i,i) ];
> >    } else if( i > 0 && ipiv[ i ] < 0 && ipiv[ i-1 ] == ipiv[ i ] ) {
> >      det *= D[ UMAT(i,i) ] * D[ UMAT(i-1,i-1) ] -\
> >             D[ UMAT(i-1,i) ] * D[ UMAT(i-1,i) ];
> >    }
> >  }
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From rusers.sh at gmail.com  Fri Apr 23 19:19:45 2010
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 23 Apr 2010 13:19:45 -0400
Subject: [Rd] Question of R CMD check
In-Reply-To: <4BD1635D.7050802@gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>
	<4BD1635D.7050802@gmail.com>
Message-ID: <s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100423/f13e3eba/attachment.pl>

From djsamperi at gmail.com  Fri Apr 23 20:42:47 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 23 Apr 2010 14:42:47 -0400
Subject: [Rd] Unresolved symbols when objects are in subdirectories?
Message-ID: <m2jd4cf43b61004231142x40fbd73dhfc3c9574dffa84b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100423/1677b9f7/attachment.pl>

From ehlers at ucalgary.ca  Fri Apr 23 21:15:07 2010
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 23 Apr 2010 13:15:07 -0600
Subject: [Rd] Deferred Default Marker
In-Reply-To: <1272036039.5556.17.camel@punchbuggy>
References: <1272036039.5556.17.camel@punchbuggy>
Message-ID: <4BD1F1BB.2050302@ucalgary.ca>

Terry,

I don't see the problem in R 2.11.0 or R 2.10.1 Patched
(session info for R 2.10.1 below) with Windows (Vista).
I do get warnings about kinship having been built under
R 2.11.0 when I use R 2.10.1.

But I notice that your version of kinship looks somewhat
dated. Is that intentional?

   -Peter Ehlers

 > sessionInfo()
R version 2.10.1 Patched (2010-01-05 r50896)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
[5] LC_TIME=English_Canada.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] kinship_1.1.0-23 lattice_0.18-3   nlme_3.1-96      survival_2.35-8

loaded via a namespace (and not attached):
[1] grid_2.10.1


On 2010-04-23 9:20, Terry Therneau wrote:
> I've finally narrowed down a puzzling problem: here is the short test
> case.
>
> tmt34% R --vanilla
>
> R version 2.10.0 (2009-10-26)
> Copyright (C) 2009 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
>> temp<- matrix(runif(50), ncol=2)
>> t(temp) %*% temp
>           [,1]     [,2]
> [1,] 7.916016 6.049698
> [2,] 6.049698 7.650694
>
>> library(kinship)
> Loading required package: survival
> Loading required package: splines
> Loading required package: nlme
> Loading required package: lattice
>> t(temp) %*% temp
> `__Deferred_Default_Marker__`
>
> -----------------------------------------
>
> Within the library is a definition of %*% for bdsmatrix objects, which
> is perhaps the issue.  But I'm only guessing since I don't have a clear
> idea what the error message means.  Any hints are appreciated.
>
> The new coxme/bsdmatrix packages need only a couple more functions to be
> a complete replacement for kinship, at which point we will depreciate
> it. (Pedigrees and plotting were finished last weekend!)  But I can't
> quite do that yet. The error does not arise with these newer libraries.
> There have been no changes to kinship for some time.
>
>    Terry Therneau
>
>
>> sessionInfo()
> R version 2.10.0 (2009-10-26)
> x86_64-unknown-linux-gnu
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets
> methods
> [8] base
> other attached packages:
> [1] kinship_1.1.0-11 lattice_0.17-26  nlme_3.1-96      survival_2.35-9
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.0
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Peter Ehlers
University of Calgary


From asr at ufl.edu  Fri Apr 23 22:18:46 2010
From: asr at ufl.edu (Allen S. Rout)
Date: Fri, 23 Apr 2010 16:18:46 -0400
Subject: [Rd] Patch submission (whoops).
Message-ID: <87och9q5w9.fsf@cornpone.cns.ufl.edu>



Greetings, and apologies for the braino leading to my first posting to
the general list.  I'm reposting here, and changing how I attached the
files; they were hard to work with in the other post. 


There's a coalescing group which is working to imitate Dirk's fine
translation of CRAN to APT, in the Fedora/Red-Hat flavored land.

One of the things we're trying to do is implement as much as is
possible in R directly, and use as much of the existing package
management infrastructure as we can.

To this end, I humbly submit a few small patches to that
infrastructure.

The first of the two patches below is the more important one; It adds
to 'getDependencies' an 'installed' option, defaulting to NULL.  This
permits us to specify a counterfactual set of "installed packages".
With this option in place, we can ask getDependencies "What would
someone need, to install this package, if they only had -thus-
installed".

In practice, -thus-, for us, attempts to be "just the base packages".


The second of the two patches is more cosmetic.  getDependencies is
quite verbose about what it's doing, and it would be nice to be able
to mask the merely informative messages.  The patch adds a 'verbose'
option, defaulting to TRUE.  This permits us to turn off the message()
about "Oh, I'm doing this too".  The second patch includes the
functionality of the first.

Currently, I'm using a copied-and-pasted version of getDependencies,
with my hacks in place and some moderately evil namespace traipsing to
get at the rest of the utilities.  I would much rather make use of the
code in situ.




From murdoch.duncan at gmail.com  Fri Apr 23 23:53:34 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Apr 2010 17:53:34 -0400
Subject: [Rd] Question of R CMD check
In-Reply-To: <s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>	
	<4BD1635D.7050802@gmail.com>
	<s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>
Message-ID: <4BD216DE.4070304@gmail.com>

On 23/04/2010 1:19 PM, rusers.sh wrote:
> Hi Duncan,
>   Thanks for reminding me. See below for the error information from *.Rout
> file
>   It seems that 'pkgname' was not found. I am not sure whether there is some
> problem with my functions or it is a little bug.
>   Thanks a lot.
> #######
>   
>> assign("ptime", proc.time(), pos = "CheckExEnv")
>> ## at least one package changes these via ps.options(), so do this
>> ## before loading the package.
>> ## Use postscript as incomplete files may be viewable, unlike PDF.
>> ## Choose a size that is close to on-screen devices, fix paper
>> grDevices::ps.options(width = 7, height = 7, paper = "a4", reset = TRUE)
>> grDevices::postscript(paste(pkgname, "-Ex.ps", sep=""))
>>     
> Error in paste(pkgname, "-Ex.ps", sep = "") : object 'pkgname' not found
> Calls: <Anonymous> -> checkIntFormat -> gsub -> paste
> Execution halted
>   

The very first line of stam-Ex.R should be

pkgname <- "stam"

Is it?  If not, I'd like to see the package; could you send me a copy?  
If it is, then something in one of your examples is messing with it.  Do 
you have any calls to rm() or remove() in your examples?

Duncan Murdoch
> 2010/4/23 Duncan Murdoch <murdoch.duncan at gmail.com>
>
>   
>> On 21/04/2010 9:48 PM, rusers.sh wrote:
>>
>>     
>>> Hi all,
>>>    Today, i just installed the newest R version 2.10.1 and other necessary
>>> tools for building R package under windows,e.g. Rtools, perl. All are the
>>> newest version.
>>>  After the correct configuration under windows (configuration should be
>>> correct), i use it to re-check my old package. I found the following
>>> prolem
>>> when checking EXAMPLEs in each function, which did not exist before this
>>> re-installation.
>>> ########
>>> * checking examples ... ERROR
>>>  Running examples in 'stam-Ex.R' failed.
>>> ########
>>>  I used "\dontrun{} % enddontrun" in all the examples of my functions that
>>> should be no problem, i think. I checked my package before and did not
>>> find
>>> errors. I also browsed the checking results in 'stam-Ex.R'. It listed all
>>> the example codes in that file, something like this,
>>>  cleanEx(); nameEx("stcdt")
>>>  ### * stcdt
>>>  flush(stderr()); flush(stdout())
>>>  ###example codes
>>>
>>>  I did not met this problem before.  Any ideas on solving this?
>>>  Thanks a lot.
>>>
>>>
>>>
>>>       
>> You need to show us the end of the stam-Ex.Rout file.  It will contain the
>> error message.
>>
>> Duncan Murdoch
>>
>>
>>     
>
>
>


From hpages at fhcrc.org  Sat Apr 24 02:30:09 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 23 Apr 2010 17:30:09 -0700
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <hqpb6g$163$1@dough.gmane.org>
References: <hqn72q$uev$1@dough.gmane.org>
	<4BCF52C6.8020303@r-enthusiasts.com>	<77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>
	<hqpb6g$163$1@dough.gmane.org>
Message-ID: <4BD23B91.9090707@fhcrc.org>

Hi Matthew,

Matthew Dowle wrote:
> Just to add some clarification, the suggestion wasn't motivated by speeding 
> up a length 3 vector being recycled 3.3 million times.  But its a good point 
> that any change should not make that case slower.  I don't know how much 
> vectorCopy is called really,  DUPLICATE_ATOMIC_VECTOR seems more 
> significant, which doesn't recycle, and already had the FIXME next to it.
> 
> Where copyVector is passed a large source though, then memcpy should be 
> faster than any of the methods using a for loop through each element 
> (whether recycling or not),  allowing for the usual caveats. What are the 
> timings like if you repeat the for loop 100 times to get a more robust 
> timing ?  It needs to be a repeat around the for loop only, not the 
> allocVector whose variance looks to be included in those timings below. Then 
> increase the size of the source vector,  and compare to memcpy.

On my system (DELL LATITUDE laptop with 64-bit 9.04 Ubuntu):

#include <stdio.h>
#include <string.h>
#include <stdlib.h>

void *memcpy2(char *dest, const char *src, size_t n)
{
         int i;

         for (i = 0; i < n; i++) *(dest++) = *(src++);
         return dest;
}

int main()
{
         int n, kmax, k;
         char *x, *y;

         n = 25000000;
	kmax = 100;
         x = (char *) malloc(n);
         y = (char *) malloc(n);
         for (k = 0; k < kmax; k++)
                 //memcpy2(y, x, n);
                 memcpy(y, x, n);
         return 0;
}

Benchmarks:

n = 25000000, kmax = 100, memcpy2:

   real	0m8.123s
   user	0m8.077s
   sys	0m0.040s

n = 25000000, k = 100, memcpy:

   real	0m1.076s
   user	0m1.004s
   sys	0m0.060s

n = 25000, kmax = 100000, memcpy2:

   real	0m8.033s
   user	0m8.005s
   sys	0m0.012s

n = 25000, kmax = 100000, memcpy:

   real	0m0.353s
   user	0m0.352s
   sys	0m0.000s

n = 25, kmax = 100000000, memcpy2:

   real	0m8.351s
   user	0m8.313s
   sys	0m0.008s

n = 25, kmax = 100000000, memcpy:

   real	0m0.628s
   user	0m0.624s
   sys	0m0.004s

So depending on the size of the memory area to copy, GNU memcpy() is
between 7.5x and 22x faster than using a for() loop. You can reasonably
expect that the authors of memcpy() have done their best to optimize
the code for most platforms they support, for big and small memory
areas, and that if there was a need to branch based on the size of the
area, that's already done *inside* memcpy() (I'm just speculating here,
I didn't look at memcpy's source code).

Cheers,
H.

> 
> Matthew
> 
> "William Dunlap" <wdunlap at tibco.com> wrote in message 
> news:77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA at NA-PA-VBE03.na.tibco.com...
> If I were worried about the time this loop takes,
> I would avoid using i%nt.  For the attached C code
> compile with gcc 4.3.3 with -O2 I get
>   > # INTEGER() in loop
>   > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
>      user  system elapsed
>     0.060   0.012   0.071
> 
>   > # INTEGER() before loop
>   > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
>      user  system elapsed
>     0.076   0.008   0.086
> 
>   > # replace i%src_length in loop with j=0 before loop and
>   > #    if(++j==src_length) j=0 ;
>   > # in the loop.
>   > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
>      user  system elapsed
>     0.024   0.028   0.050
>   > identical(r1,r2) && identical(r2,r3)
>   [1] TRUE
> 
> The C code is:
> #define USE_RINTERNALS /* pretend we are in the R kernel */
> #include <R.h>
> #include <Rinternals.h>
> 
> 
> SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
> {
>     int src_length = length(s_src) ;
>     int dest_length = asInteger(s_dest_length) ;
>     int i,j ;
>     SEXP s_dest ;
>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>     for(i=0;i<dest_length;i++) {
>         INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
>     }
>     UNPROTECT(1) ;
>     return s_dest ;
> }
> SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
> {
>     int src_length = length(s_src) ;
>     int dest_length = asInteger(s_dest_length) ;
>     int *psrc = INTEGER(s_src) ;
>     int *pdest ;
>     int i ;
>     SEXP s_dest ;
>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>     pdest = INTEGER(s_dest) ;
>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>     /* end of boilerplate */
>     for(i=0;i<dest_length;i++) {
>         pdest[i] = psrc[i % src_length] ;
>     }
>     UNPROTECT(1) ;
>     return s_dest ;
> }
> SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
> {
>     int src_length = length(s_src) ;
>     int dest_length = asInteger(s_dest_length) ;
>     int *psrc = INTEGER(s_src) ;
>     int *pdest ;
>     int i,j ;
>     SEXP s_dest ;
>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>     pdest = INTEGER(s_dest) ;
>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>     /* end of boilerplate */
>     for(j=0,i=0;i<dest_length;i++) {
>         *pdest++ = psrc[j++] ;
>         if (j==src_length) {
>             j = 0 ;
>         }
>     }
>     UNPROTECT(1) ;
>     return s_dest ;
> }
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
>> Sent: Wednesday, April 21, 2010 12:32 PM
>> To: Matthew Dowle
>> Cc: r-devel at stat.math.ethz.ch
>> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
>>
>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>> From copyVector in duplicate.c :
>>> void copyVector(SEXP s, SEXP t)
>>> {
>>>      int i, ns, nt;
>>>      nt = LENGTH(t);
>>>      ns = LENGTH(s);
>>>      switch (TYPEOF(s)) {
>>> ...
>>>      case INTSXP:
>>>      for (i = 0; i<  ns; i++)
>>>          INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>      break;
>>> ...
>>>
>>> could that be replaced with :
>>>
>>>      case INTSXP:
>>>      for (i=0; i<ns/nt; i++)
>>>          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char
>> *)DATAPTR(t),
>>> nt*sizeof(int));
>>>      break;
>> or at least with something like this:
>>
>> int* p_s = INTEGER(s) ;
>> int* p_t = INTEGER(t) ;
>> for( i=0 ; i < ns ; i++){
>> p_s[i] = p_t[i % nt];
>> }
>>
>> since expanding the INTEGER macro over and over has a price.
>>
>>> and similar for the other types in copyVector.  This won't
>> help regular
>>> vector copies, since those seem to be done by the
>> DUPLICATE_ATOMIC_VECTOR
>>> macro, see next suggestion below, but it should help
>> copyMatrix which calls
>>> copyVector, scan.c which calls copyVector on three lines,
>> dcf.c (once) and
>>> dounzip.c (once).
>>>
>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a
>> comment next to it
>>> :
>>>
>>>      <FIXME>: surely memcpy would be faster here?
>>>
>>> which seems to refer to the for loop  :
>>>
>>>      else { \
>>>      int __i__; \
>>>      type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>      for (__i__ = 0; __i__<  __n__; __i__++) \
>>>        __tp__[__i__] = __fp__[__i__]; \
>>>    } \
>>>
>>> Could that loop be replaced by the following ?
>>>
>>>     else { \
>>>     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from),
>> __n__*sizeof(type)); \
>>>     }\
>>>
>>> In the data.table package, dogroups.c uses this technique,
>> so the principle
>>> is tested and works well so far.
>>>
>>> Are there any road blocks preventing this change, or is
>> anyone already
>>> working on it ?  If not then I'll try and test it (on
>> Ubuntu 32bit) and
>>> submit patch with timings, as before.  Comments/pointers
>> much appreciated.
>>> Matthew
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> -- 
>> Romain Francois
>> Professional R Enthusiast
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>> |- http://bit.ly/9aKDM9 : embed images in Rd documents
>> |- http://tr.im/OIXN : raster images and RImageJ
>> |- http://tr.im/OcQe : Rcpp 0.7.7
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From rusers.sh at gmail.com  Sat Apr 24 02:35:48 2010
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 23 Apr 2010 20:35:48 -0400
Subject: [Rd] Question of R CMD check
In-Reply-To: <4BD216DE.4070304@gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>
	<4BD1635D.7050802@gmail.com>
	<s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>
	<4BD216DE.4070304@gmail.com>
Message-ID: <u2ia835c81e1004231735nd64de92aif591b5e63d2916f3@mail.gmail.com>

Hi Duncan,
  Enclosed is the example package and the checking results. No rm() or
remove() in the example. Before this re-installation of  R and other tools
(e.g. Rtools), there are no errors for package checking.
  Thanks.

2010/4/23 Duncan Murdoch <murdoch.duncan at gmail.com>

> On 23/04/2010 1:19 PM, rusers.sh wrote:
>
>> Hi Duncan,
>>  Thanks for reminding me. See below for the error information from *.Rout
>> file
>>  It seems that 'pkgname' was not found. I am not sure whether there is
>> some
>> problem with my functions or it is a little bug.
>>  Thanks a lot.
>> #######
>>
>>
>>> assign("ptime", proc.time(), pos = "CheckExEnv")
>>> ## at least one package changes these via ps.options(), so do this
>>> ## before loading the package.
>>> ## Use postscript as incomplete files may be viewable, unlike PDF.
>>> ## Choose a size that is close to on-screen devices, fix paper
>>> grDevices::ps.options(width = 7, height = 7, paper = "a4", reset = TRUE)
>>> grDevices::postscript(paste(pkgname, "-Ex.ps", sep=""))
>>>
>>>
>> Error in paste(pkgname, "-Ex.ps", sep = "") : object 'pkgname' not found
>> Calls: <Anonymous> -> checkIntFormat -> gsub -> paste
>> Execution halted
>>
>>
>
> The very first line of stam-Ex.R should be
>
> pkgname <- "stam"
>
> Is it?  If not, I'd like to see the package; could you send me a copy?  If
> it is, then something in one of your examples is messing with it.  Do you
> have any calls to rm() or remove() in your examples?
>
> Duncan Murdoch
>
>  2010/4/23 Duncan Murdoch <murdoch.duncan at gmail.com>
>>
>>
>>
>>> On 21/04/2010 9:48 PM, rusers.sh wrote:
>>>
>>>
>>>
>>>> Hi all,
>>>>   Today, i just installed the newest R version 2.10.1 and other
>>>> necessary
>>>> tools for building R package under windows,e.g. Rtools, perl. All are
>>>> the
>>>> newest version.
>>>>  After the correct configuration under windows (configuration should be
>>>> correct), i use it to re-check my old package. I found the following
>>>> prolem
>>>> when checking EXAMPLEs in each function, which did not exist before this
>>>> re-installation.
>>>> ########
>>>> * checking examples ... ERROR
>>>>  Running examples in 'stam-Ex.R' failed.
>>>> ########
>>>>  I used "\dontrun{} % enddontrun" in all the examples of my functions
>>>> that
>>>> should be no problem, i think. I checked my package before and did not
>>>> find
>>>> errors. I also browsed the checking results in 'stam-Ex.R'. It listed
>>>> all
>>>> the example codes in that file, something like this,
>>>>  cleanEx(); nameEx("stcdt")
>>>>  ### * stcdt
>>>>  flush(stderr()); flush(stdout())
>>>>  ###example codes
>>>>
>>>>  I did not met this problem before.  Any ideas on solving this?
>>>>  Thanks a lot.
>>>>
>>>>
>>>>
>>>>
>>>>
>>> You need to show us the end of the stam-Ex.Rout file.  It will contain
>>> the
>>> error message.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>
>


-- 
-----------------
Jane Chang
Queen's

From hpages at fhcrc.org  Sat Apr 24 03:21:59 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 23 Apr 2010 18:21:59 -0700
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BD23B91.9090707@fhcrc.org>
References: <hqn72q$uev$1@dough.gmane.org>	<4BCF52C6.8020303@r-enthusiasts.com>	<77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>	<hqpb6g$163$1@dough.gmane.org>
	<4BD23B91.9090707@fhcrc.org>
Message-ID: <4BD247B7.8080004@fhcrc.org>

Follow up...

Herv? Pag?s wrote:
> Hi Matthew,
> 
> Matthew Dowle wrote:
>> Just to add some clarification, the suggestion wasn't motivated by 
>> speeding up a length 3 vector being recycled 3.3 million times.  But 
>> its a good point that any change should not make that case slower.  I 
>> don't know how much vectorCopy is called really,  
>> DUPLICATE_ATOMIC_VECTOR seems more significant, which doesn't recycle, 
>> and already had the FIXME next to it.
>>
>> Where copyVector is passed a large source though, then memcpy should 
>> be faster than any of the methods using a for loop through each 
>> element (whether recycling or not),  allowing for the usual caveats. 
>> What are the timings like if you repeat the for loop 100 times to get 
>> a more robust timing ?  It needs to be a repeat around the for loop 
>> only, not the allocVector whose variance looks to be included in those 
>> timings below. Then increase the size of the source vector,  and 
>> compare to memcpy.
> 
> On my system (DELL LATITUDE laptop with 64-bit 9.04 Ubuntu):
> 
> #include <stdio.h>
> #include <string.h>
> #include <stdlib.h>
> 
> void *memcpy2(char *dest, const char *src, size_t n)
> {
>         int i;
> 
>         for (i = 0; i < n; i++) *(dest++) = *(src++);
>         return dest;
> }
> 
> int main()
> {
>         int n, kmax, k;
>         char *x, *y;
> 
>         n = 25000000;
>     kmax = 100;
>         x = (char *) malloc(n);
>         y = (char *) malloc(n);
>         for (k = 0; k < kmax; k++)
>                 //memcpy2(y, x, n);
>                 memcpy(y, x, n);
>         return 0;
> }
> 
> Benchmarks:
> 
> n = 25000000, kmax = 100, memcpy2:
> 
>   real    0m8.123s
>   user    0m8.077s
>   sys    0m0.040s
> 
> n = 25000000, k = 100, memcpy:
> 
>   real    0m1.076s
>   user    0m1.004s
>   sys    0m0.060s
> 
> n = 25000, kmax = 100000, memcpy2:
> 
>   real    0m8.033s
>   user    0m8.005s
>   sys    0m0.012s
> 
> n = 25000, kmax = 100000, memcpy:
> 
>   real    0m0.353s
>   user    0m0.352s
>   sys    0m0.000s
> 
> n = 25, kmax = 100000000, memcpy2:
> 
>   real    0m8.351s
>   user    0m8.313s
>   sys    0m0.008s
> 
> n = 25, kmax = 100000000, memcpy:
> 
>   real    0m0.628s
>   user    0m0.624s
>   sys    0m0.004s
> 
> So depending on the size of the memory area to copy, GNU memcpy() is
> between 7.5x and 22x faster than using a for() loop. You can reasonably
> expect that the authors of memcpy() have done their best to optimize
> the code for most platforms they support, for big and small memory
> areas, and that if there was a need to branch based on the size of the
> area, that's already done *inside* memcpy() (I'm just speculating here,
> I didn't look at memcpy's source code).

So for copying a vector of integer (with recycling of the source),
yes, a memcpy-based implementation is much faster, for long and small
vectors (even for a length 3 vector being recycled 3.3 million
times ;-) ), at least on my system:

nt = 3; ns = 10000000; kmax = 100; copy_ints:

   real	0m1.206s
   user	0m1.168s
   sys	0m0.040s

nt = 3; ns = 10000000; kmax = 100; copy_ints2:

   real	0m6.326s
   user	0m6.264s
   sys	0m0.052s


Code:
=======================================================================
#include <stdio.h>
#include <string.h>
#include <stdlib.h>

void memcpy_with_recycling_of_src(char *dest, size_t dest_nblocks,
				  const char *src, size_t src_nblocks,
				  size_t blocksize)
{
	int i, imax, q;
	size_t src_size;

	imax = dest_nblocks - src_nblocks;
	src_size = src_nblocks * blocksize;
	for (i = 0; i <= imax; i += src_nblocks) {
		memcpy(dest, src, src_size);
		dest += src_size;
		i += src_nblocks;
	}
	q = dest_nblocks - i;
	if (q > 0)
		memcpy(dest, src, q * blocksize);
	return;
}

void copy_ints(int *dest, int dest_length,
                const int *src, int src_length)
{
	memcpy_with_recycling_of_src((char *) dest, dest_length,
				     (char *) src, src_length,
				     sizeof(int));
}

/* the copyVector() way */
void copy_ints2(int *dest, int dest_length,
                 const int *src, int src_length)
{
	int i;

	for (i = 0; i < dest_length; i++)
		dest[i] = src[i % src_length];
}

int main()
{
	int nt, ns, kmax, k;
	int *t, *s;

	nt = 3;
	ns = 10000000;
	kmax = 100;
	t = (int *) malloc(nt * sizeof(int));
	s = (int *) malloc(ns * sizeof(int));
	for (k = 0; k < kmax; k++)
		//copy_ints(s, ns, t, nt);
		copy_ints2(s, ns, t, nt);
	return 0;
}

Note that the function that actually does the job is
memcpy_with_recycling_of_src(). It can be reused for copying
vectors with elements of an arbitrary size.

Cheers,
H.

> 
> Cheers,
> H.
> 
>>
>> Matthew
>>
>> "William Dunlap" <wdunlap at tibco.com> wrote in message 
>> news:77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA at NA-PA-VBE03.na.tibco.com...
>> If I were worried about the time this loop takes,
>> I would avoid using i%nt.  For the attached C code
>> compile with gcc 4.3.3 with -O2 I get
>>   > # INTEGER() in loop
>>   > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
>>      user  system elapsed
>>     0.060   0.012   0.071
>>
>>   > # INTEGER() before loop
>>   > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
>>      user  system elapsed
>>     0.076   0.008   0.086
>>
>>   > # replace i%src_length in loop with j=0 before loop and
>>   > #    if(++j==src_length) j=0 ;
>>   > # in the loop.
>>   > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
>>      user  system elapsed
>>     0.024   0.028   0.050
>>   > identical(r1,r2) && identical(r2,r3)
>>   [1] TRUE
>>
>> The C code is:
>> #define USE_RINTERNALS /* pretend we are in the R kernel */
>> #include <R.h>
>> #include <Rinternals.h>
>>
>>
>> SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
>> {
>>     int src_length = length(s_src) ;
>>     int dest_length = asInteger(s_dest_length) ;
>>     int i,j ;
>>     SEXP s_dest ;
>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>     for(i=0;i<dest_length;i++) {
>>         INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
>>     }
>>     UNPROTECT(1) ;
>>     return s_dest ;
>> }
>> SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
>> {
>>     int src_length = length(s_src) ;
>>     int dest_length = asInteger(s_dest_length) ;
>>     int *psrc = INTEGER(s_src) ;
>>     int *pdest ;
>>     int i ;
>>     SEXP s_dest ;
>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>     pdest = INTEGER(s_dest) ;
>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>     /* end of boilerplate */
>>     for(i=0;i<dest_length;i++) {
>>         pdest[i] = psrc[i % src_length] ;
>>     }
>>     UNPROTECT(1) ;
>>     return s_dest ;
>> }
>> SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
>> {
>>     int src_length = length(s_src) ;
>>     int dest_length = asInteger(s_dest_length) ;
>>     int *psrc = INTEGER(s_src) ;
>>     int *pdest ;
>>     int i,j ;
>>     SEXP s_dest ;
>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>     pdest = INTEGER(s_dest) ;
>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>     /* end of boilerplate */
>>     for(j=0,i=0;i<dest_length;i++) {
>>         *pdest++ = psrc[j++] ;
>>         if (j==src_length) {
>>             j = 0 ;
>>         }
>>     }
>>     UNPROTECT(1) ;
>>     return s_dest ;
>> }
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
>>> Sent: Wednesday, April 21, 2010 12:32 PM
>>> To: Matthew Dowle
>>> Cc: r-devel at stat.math.ethz.ch
>>> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
>>>
>>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>>> From copyVector in duplicate.c :
>>>> void copyVector(SEXP s, SEXP t)
>>>> {
>>>>      int i, ns, nt;
>>>>      nt = LENGTH(t);
>>>>      ns = LENGTH(s);
>>>>      switch (TYPEOF(s)) {
>>>> ...
>>>>      case INTSXP:
>>>>      for (i = 0; i<  ns; i++)
>>>>          INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>>      break;
>>>> ...
>>>>
>>>> could that be replaced with :
>>>>
>>>>      case INTSXP:
>>>>      for (i=0; i<ns/nt; i++)
>>>>          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char
>>> *)DATAPTR(t),
>>>> nt*sizeof(int));
>>>>      break;
>>> or at least with something like this:
>>>
>>> int* p_s = INTEGER(s) ;
>>> int* p_t = INTEGER(t) ;
>>> for( i=0 ; i < ns ; i++){
>>> p_s[i] = p_t[i % nt];
>>> }
>>>
>>> since expanding the INTEGER macro over and over has a price.
>>>
>>>> and similar for the other types in copyVector.  This won't
>>> help regular
>>>> vector copies, since those seem to be done by the
>>> DUPLICATE_ATOMIC_VECTOR
>>>> macro, see next suggestion below, but it should help
>>> copyMatrix which calls
>>>> copyVector, scan.c which calls copyVector on three lines,
>>> dcf.c (once) and
>>>> dounzip.c (once).
>>>>
>>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a
>>> comment next to it
>>>> :
>>>>
>>>>      <FIXME>: surely memcpy would be faster here?
>>>>
>>>> which seems to refer to the for loop  :
>>>>
>>>>      else { \
>>>>      int __i__; \
>>>>      type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>>      for (__i__ = 0; __i__<  __n__; __i__++) \
>>>>        __tp__[__i__] = __fp__[__i__]; \
>>>>    } \
>>>>
>>>> Could that loop be replaced by the following ?
>>>>
>>>>     else { \
>>>>     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from),
>>> __n__*sizeof(type)); \
>>>>     }\
>>>>
>>>> In the data.table package, dogroups.c uses this technique,
>>> so the principle
>>>> is tested and works well so far.
>>>>
>>>> Are there any road blocks preventing this change, or is
>>> anyone already
>>>> working on it ?  If not then I'll try and test it (on
>>> Ubuntu 32bit) and
>>>> submit patch with timings, as before.  Comments/pointers
>>> much appreciated.
>>>> Matthew
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> -- 
>>> Romain Francois
>>> Professional R Enthusiast
>>> +33(0) 6 28 91 30 30
>>> http://romainfrancois.blog.free.fr
>>> |- http://bit.ly/9aKDM9 : embed images in Rd documents
>>> |- http://tr.im/OIXN : raster images and RImageJ
>>> |- http://tr.im/OcQe : Rcpp 0.7.7
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Sat Apr 24 05:58:24 2010
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 23 Apr 2010 20:58:24 -0700
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BD247B7.8080004@fhcrc.org>
References: <hqn72q$uev$1@dough.gmane.org>	<4BCF52C6.8020303@r-enthusiasts.com>	<77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>	<hqpb6g$163$1@dough.gmane.org>	<4BD23B91.9090707@fhcrc.org>
	<4BD247B7.8080004@fhcrc.org>
Message-ID: <4BD26C60.2050209@fhcrc.org>

Herv? Pag?s wrote:
[...]
> Code:
> =======================================================================
> #include <stdio.h>
> #include <string.h>
> #include <stdlib.h>
> 
> void memcpy_with_recycling_of_src(char *dest, size_t dest_nblocks,
>                   const char *src, size_t src_nblocks,
>                   size_t blocksize)
> {
>     int i, imax, q;
>     size_t src_size;
> 
>     imax = dest_nblocks - src_nblocks;
>     src_size = src_nblocks * blocksize;
>     for (i = 0; i <= imax; i += src_nblocks) {
>         memcpy(dest, src, src_size);
>         dest += src_size;
>         i += src_nblocks;
           ^^^^^^^^^^^^^^^^^
           //i += src_nblocks;

oops, take this out!

Of course copy_ints is twice slower now but is still
about 2.5x faster than copy_ints2 (the copyVector
way) for copying a length 3 vector recycled 3.3 million
times. For a length 1000 vector being recycled 25 times,
it's about 17x faster.

Cheers,
H.

>     }
>     q = dest_nblocks - i;
>     if (q > 0)
>         memcpy(dest, src, q * blocksize);
>     return;
> }
> 
> void copy_ints(int *dest, int dest_length,
>                const int *src, int src_length)
> {
>     memcpy_with_recycling_of_src((char *) dest, dest_length,
>                      (char *) src, src_length,
>                      sizeof(int));
> }
> 
> /* the copyVector() way */
> void copy_ints2(int *dest, int dest_length,
>                 const int *src, int src_length)
> {
>     int i;
> 
>     for (i = 0; i < dest_length; i++)
>         dest[i] = src[i % src_length];
> }
> 
> int main()
> {
>     int nt, ns, kmax, k;
>     int *t, *s;
> 
>     nt = 3;
>     ns = 10000000;
>     kmax = 100;
>     t = (int *) malloc(nt * sizeof(int));
>     s = (int *) malloc(ns * sizeof(int));
>     for (k = 0; k < kmax; k++)
>         //copy_ints(s, ns, t, nt);
>         copy_ints2(s, ns, t, nt);
>     return 0;
> }
> 
> Note that the function that actually does the job is
> memcpy_with_recycling_of_src(). It can be reused for copying
> vectors with elements of an arbitrary size.
> 
> Cheers,
> H.
> 
>>
>> Cheers,
>> H.
>>
>>>
>>> Matthew
>>>
>>> "William Dunlap" <wdunlap at tibco.com> wrote in message 
>>> news:77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA at NA-PA-VBE03.na.tibco.com... 
>>>
>>> If I were worried about the time this loop takes,
>>> I would avoid using i%nt.  For the attached C code
>>> compile with gcc 4.3.3 with -O2 I get
>>>   > # INTEGER() in loop
>>>   > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
>>>      user  system elapsed
>>>     0.060   0.012   0.071
>>>
>>>   > # INTEGER() before loop
>>>   > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
>>>      user  system elapsed
>>>     0.076   0.008   0.086
>>>
>>>   > # replace i%src_length in loop with j=0 before loop and
>>>   > #    if(++j==src_length) j=0 ;
>>>   > # in the loop.
>>>   > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
>>>      user  system elapsed
>>>     0.024   0.028   0.050
>>>   > identical(r1,r2) && identical(r2,r3)
>>>   [1] TRUE
>>>
>>> The C code is:
>>> #define USE_RINTERNALS /* pretend we are in the R kernel */
>>> #include <R.h>
>>> #include <Rinternals.h>
>>>
>>>
>>> SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
>>> {
>>>     int src_length = length(s_src) ;
>>>     int dest_length = asInteger(s_dest_length) ;
>>>     int i,j ;
>>>     SEXP s_dest ;
>>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>     for(i=0;i<dest_length;i++) {
>>>         INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
>>>     }
>>>     UNPROTECT(1) ;
>>>     return s_dest ;
>>> }
>>> SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
>>> {
>>>     int src_length = length(s_src) ;
>>>     int dest_length = asInteger(s_dest_length) ;
>>>     int *psrc = INTEGER(s_src) ;
>>>     int *pdest ;
>>>     int i ;
>>>     SEXP s_dest ;
>>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>     pdest = INTEGER(s_dest) ;
>>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>     /* end of boilerplate */
>>>     for(i=0;i<dest_length;i++) {
>>>         pdest[i] = psrc[i % src_length] ;
>>>     }
>>>     UNPROTECT(1) ;
>>>     return s_dest ;
>>> }
>>> SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
>>> {
>>>     int src_length = length(s_src) ;
>>>     int dest_length = asInteger(s_dest_length) ;
>>>     int *psrc = INTEGER(s_src) ;
>>>     int *pdest ;
>>>     int i,j ;
>>>     SEXP s_dest ;
>>>     PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>     pdest = INTEGER(s_dest) ;
>>>     if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>     /* end of boilerplate */
>>>     for(j=0,i=0;i<dest_length;i++) {
>>>         *pdest++ = psrc[j++] ;
>>>         if (j==src_length) {
>>>             j = 0 ;
>>>         }
>>>     }
>>>     UNPROTECT(1) ;
>>>     return s_dest ;
>>> }
>>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
>>>> Sent: Wednesday, April 21, 2010 12:32 PM
>>>> To: Matthew Dowle
>>>> Cc: r-devel at stat.math.ethz.ch
>>>> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
>>>>
>>>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>>>> From copyVector in duplicate.c :
>>>>> void copyVector(SEXP s, SEXP t)
>>>>> {
>>>>>      int i, ns, nt;
>>>>>      nt = LENGTH(t);
>>>>>      ns = LENGTH(s);
>>>>>      switch (TYPEOF(s)) {
>>>>> ...
>>>>>      case INTSXP:
>>>>>      for (i = 0; i<  ns; i++)
>>>>>          INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>>>      break;
>>>>> ...
>>>>>
>>>>> could that be replaced with :
>>>>>
>>>>>      case INTSXP:
>>>>>      for (i=0; i<ns/nt; i++)
>>>>>          memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char
>>>> *)DATAPTR(t),
>>>>> nt*sizeof(int));
>>>>>      break;
>>>> or at least with something like this:
>>>>
>>>> int* p_s = INTEGER(s) ;
>>>> int* p_t = INTEGER(t) ;
>>>> for( i=0 ; i < ns ; i++){
>>>> p_s[i] = p_t[i % nt];
>>>> }
>>>>
>>>> since expanding the INTEGER macro over and over has a price.
>>>>
>>>>> and similar for the other types in copyVector.  This won't
>>>> help regular
>>>>> vector copies, since those seem to be done by the
>>>> DUPLICATE_ATOMIC_VECTOR
>>>>> macro, see next suggestion below, but it should help
>>>> copyMatrix which calls
>>>>> copyVector, scan.c which calls copyVector on three lines,
>>>> dcf.c (once) and
>>>>> dounzip.c (once).
>>>>>
>>>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a
>>>> comment next to it
>>>>> :
>>>>>
>>>>>      <FIXME>: surely memcpy would be faster here?
>>>>>
>>>>> which seems to refer to the for loop  :
>>>>>
>>>>>      else { \
>>>>>      int __i__; \
>>>>>      type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>>>      for (__i__ = 0; __i__<  __n__; __i__++) \
>>>>>        __tp__[__i__] = __fp__[__i__]; \
>>>>>    } \
>>>>>
>>>>> Could that loop be replaced by the following ?
>>>>>
>>>>>     else { \
>>>>>     memcpy((char *)DATAPTR(to), (char *)DATAPTR(from),
>>>> __n__*sizeof(type)); \
>>>>>     }\
>>>>>
>>>>> In the data.table package, dogroups.c uses this technique,
>>>> so the principle
>>>>> is tested and works well so far.
>>>>>
>>>>> Are there any road blocks preventing this change, or is
>>>> anyone already
>>>>> working on it ?  If not then I'll try and test it (on
>>>> Ubuntu 32bit) and
>>>>> submit patch with timings, as before.  Comments/pointers
>>>> much appreciated.
>>>>> Matthew
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>> -- 
>>>> Romain Francois
>>>> Professional R Enthusiast
>>>> +33(0) 6 28 91 30 30
>>>> http://romainfrancois.blog.free.fr
>>>> |- http://bit.ly/9aKDM9 : embed images in Rd documents
>>>> |- http://tr.im/OIXN : raster images and RImageJ
>>>> |- http://tr.im/OcQe : Rcpp 0.7.7
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Sat Apr 24 17:20:02 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 24 Apr 2010 11:20:02 -0400
Subject: [Rd] suggestion how to use memcpy in duplicate.c
In-Reply-To: <4BD247B7.8080004@fhcrc.org>
References: <hqn72q$uev$1@dough.gmane.org>	<4BCF52C6.8020303@r-enthusiasts.com>	<77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA@NA-PA-VBE03.na.tibco.com>	<hqpb6g$163$1@dough.gmane.org>
	<4BD23B91.9090707@fhcrc.org> <4BD247B7.8080004@fhcrc.org>
Message-ID: <2D943083-E3F5-44B2-BA66-DC1B4398C0F1@r-project.org>

Herve,

I think you code just confirms what I said -- for small nt for() wins, otherwise memcpy wins. Taking your measurements (they are a bit crude since they measure overhead as well):

ginaz:sandbox$ time ./hmc.mc 1

real	0m7.294s
user	0m7.239s
sys	0m0.054s
ginaz:sandbox$ time ./hmc 1

real	0m3.773s
user	0m3.746s
sys	0m0.024s

so for() is about 2x faster

ginaz:sandbox$ time ./hmc 3

real	0m4.751s
user	0m4.718s
sys	0m0.023s
ginaz:sandbox$ time ./hmc.mc 3

real	0m3.098s
user	0m3.051s
sys	0m0.045s

memcpy is about 50% faster.

It also proves me right when I said we should only special-case the common case of scalar recycling and use memcpy for everything else.

Cheers,
Simon




On Apr 23, 2010, at 9:21 PM, Herv? Pag?s wrote:

> Follow up...
> 
> Herv? Pag?s wrote:
>> Hi Matthew,
>> Matthew Dowle wrote:
>>> Just to add some clarification, the suggestion wasn't motivated by speeding up a length 3 vector being recycled 3.3 million times.  But its a good point that any change should not make that case slower.  I don't know how much vectorCopy is called really,  DUPLICATE_ATOMIC_VECTOR seems more significant, which doesn't recycle, and already had the FIXME next to it.
>>> 
>>> Where copyVector is passed a large source though, then memcpy should be faster than any of the methods using a for loop through each element (whether recycling or not),  allowing for the usual caveats. What are the timings like if you repeat the for loop 100 times to get a more robust timing ?  It needs to be a repeat around the for loop only, not the allocVector whose variance looks to be included in those timings below. Then increase the size of the source vector,  and compare to memcpy.
>> On my system (DELL LATITUDE laptop with 64-bit 9.04 Ubuntu):
>> #include <stdio.h>
>> #include <string.h>
>> #include <stdlib.h>
>> void *memcpy2(char *dest, const char *src, size_t n)
>> {
>>        int i;
>>        for (i = 0; i < n; i++) *(dest++) = *(src++);
>>        return dest;
>> }
>> int main()
>> {
>>        int n, kmax, k;
>>        char *x, *y;
>>        n = 25000000;
>>    kmax = 100;
>>        x = (char *) malloc(n);
>>        y = (char *) malloc(n);
>>        for (k = 0; k < kmax; k++)
>>                //memcpy2(y, x, n);
>>                memcpy(y, x, n);
>>        return 0;
>> }
>> Benchmarks:
>> n = 25000000, kmax = 100, memcpy2:
>>  real    0m8.123s
>>  user    0m8.077s
>>  sys    0m0.040s
>> n = 25000000, k = 100, memcpy:
>>  real    0m1.076s
>>  user    0m1.004s
>>  sys    0m0.060s
>> n = 25000, kmax = 100000, memcpy2:
>>  real    0m8.033s
>>  user    0m8.005s
>>  sys    0m0.012s
>> n = 25000, kmax = 100000, memcpy:
>>  real    0m0.353s
>>  user    0m0.352s
>>  sys    0m0.000s
>> n = 25, kmax = 100000000, memcpy2:
>>  real    0m8.351s
>>  user    0m8.313s
>>  sys    0m0.008s
>> n = 25, kmax = 100000000, memcpy:
>>  real    0m0.628s
>>  user    0m0.624s
>>  sys    0m0.004s
>> So depending on the size of the memory area to copy, GNU memcpy() is
>> between 7.5x and 22x faster than using a for() loop. You can reasonably
>> expect that the authors of memcpy() have done their best to optimize
>> the code for most platforms they support, for big and small memory
>> areas, and that if there was a need to branch based on the size of the
>> area, that's already done *inside* memcpy() (I'm just speculating here,
>> I didn't look at memcpy's source code).
> 
> So for copying a vector of integer (with recycling of the source),
> yes, a memcpy-based implementation is much faster, for long and small
> vectors (even for a length 3 vector being recycled 3.3 million
> times ;-) ), at least on my system:
> 
> nt = 3; ns = 10000000; kmax = 100; copy_ints:
> 
>  real	0m1.206s
>  user	0m1.168s
>  sys	0m0.040s
> 
> nt = 3; ns = 10000000; kmax = 100; copy_ints2:
> 
>  real	0m6.326s
>  user	0m6.264s
>  sys	0m0.052s
> 
> 
> Code:
> =======================================================================
> #include <stdio.h>
> #include <string.h>
> #include <stdlib.h>
> 
> void memcpy_with_recycling_of_src(char *dest, size_t dest_nblocks,
> 				  const char *src, size_t src_nblocks,
> 				  size_t blocksize)
> {
> 	int i, imax, q;
> 	size_t src_size;
> 
> 	imax = dest_nblocks - src_nblocks;
> 	src_size = src_nblocks * blocksize;
> 	for (i = 0; i <= imax; i += src_nblocks) {
> 		memcpy(dest, src, src_size);
> 		dest += src_size;
> 		i += src_nblocks;
> 	}
> 	q = dest_nblocks - i;
> 	if (q > 0)
> 		memcpy(dest, src, q * blocksize);
> 	return;
> }
> 
> void copy_ints(int *dest, int dest_length,
>               const int *src, int src_length)
> {
> 	memcpy_with_recycling_of_src((char *) dest, dest_length,
> 				     (char *) src, src_length,
> 				     sizeof(int));
> }
> 
> /* the copyVector() way */
> void copy_ints2(int *dest, int dest_length,
>                const int *src, int src_length)
> {
> 	int i;
> 
> 	for (i = 0; i < dest_length; i++)
> 		dest[i] = src[i % src_length];
> }
> 
> int main()
> {
> 	int nt, ns, kmax, k;
> 	int *t, *s;
> 
> 	nt = 3;
> 	ns = 10000000;
> 	kmax = 100;
> 	t = (int *) malloc(nt * sizeof(int));
> 	s = (int *) malloc(ns * sizeof(int));
> 	for (k = 0; k < kmax; k++)
> 		//copy_ints(s, ns, t, nt);
> 		copy_ints2(s, ns, t, nt);
> 	return 0;
> }
> 
> Note that the function that actually does the job is
> memcpy_with_recycling_of_src(). It can be reused for copying
> vectors with elements of an arbitrary size.
> 
> Cheers,
> H.
> 
>> Cheers,
>> H.
>>> 
>>> Matthew
>>> 
>>> "William Dunlap" <wdunlap at tibco.com> wrote in message news:77EB52C6DD32BA4D87471DCD70C8D70002CE6BFA at NA-PA-VBE03.na.tibco.com...
>>> If I were worried about the time this loop takes,
>>> I would avoid using i%nt.  For the attached C code
>>> compile with gcc 4.3.3 with -O2 I get
>>>  > # INTEGER() in loop
>>>  > system.time( r1 <- .Call("my_rep1", 1:3, 1e7) )
>>>     user  system elapsed
>>>    0.060   0.012   0.071
>>> 
>>>  > # INTEGER() before loop
>>>  > system.time( r2 <- .Call("my_rep2", 1:3, 1e7) )
>>>     user  system elapsed
>>>    0.076   0.008   0.086
>>> 
>>>  > # replace i%src_length in loop with j=0 before loop and
>>>  > #    if(++j==src_length) j=0 ;
>>>  > # in the loop.
>>>  > system.time( r3 <- .Call("my_rep3", 1:3, 1e7) )
>>>     user  system elapsed
>>>    0.024   0.028   0.050
>>>  > identical(r1,r2) && identical(r2,r3)
>>>  [1] TRUE
>>> 
>>> The C code is:
>>> #define USE_RINTERNALS /* pretend we are in the R kernel */
>>> #include <R.h>
>>> #include <Rinternals.h>
>>> 
>>> 
>>> SEXP my_rep1(SEXP s_src, SEXP s_dest_length)
>>> {
>>>    int src_length = length(s_src) ;
>>>    int dest_length = asInteger(s_dest_length) ;
>>>    int i,j ;
>>>    SEXP s_dest ;
>>>    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>    for(i=0;i<dest_length;i++) {
>>>        INTEGER(s_dest)[i] = INTEGER(s_src)[i % src_length] ;
>>>    }
>>>    UNPROTECT(1) ;
>>>    return s_dest ;
>>> }
>>> SEXP my_rep2(SEXP s_src, SEXP s_dest_length)
>>> {
>>>    int src_length = length(s_src) ;
>>>    int dest_length = asInteger(s_dest_length) ;
>>>    int *psrc = INTEGER(s_src) ;
>>>    int *pdest ;
>>>    int i ;
>>>    SEXP s_dest ;
>>>    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>    pdest = INTEGER(s_dest) ;
>>>    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>    /* end of boilerplate */
>>>    for(i=0;i<dest_length;i++) {
>>>        pdest[i] = psrc[i % src_length] ;
>>>    }
>>>    UNPROTECT(1) ;
>>>    return s_dest ;
>>> }
>>> SEXP my_rep3(SEXP s_src, SEXP s_dest_length)
>>> {
>>>    int src_length = length(s_src) ;
>>>    int dest_length = asInteger(s_dest_length) ;
>>>    int *psrc = INTEGER(s_src) ;
>>>    int *pdest ;
>>>    int i,j ;
>>>    SEXP s_dest ;
>>>    PROTECT(s_dest = allocVector(INTSXP, dest_length)) ;
>>>    pdest = INTEGER(s_dest) ;
>>>    if(TYPEOF(s_src) != INTSXP) error("src must be integer data") ;
>>>    /* end of boilerplate */
>>>    for(j=0,i=0;i<dest_length;i++) {
>>>        *pdest++ = psrc[j++] ;
>>>        if (j==src_length) {
>>>            j = 0 ;
>>>        }
>>>    }
>>>    UNPROTECT(1) ;
>>>    return s_dest ;
>>> }
>>> 
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>> 
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Romain Francois
>>>> Sent: Wednesday, April 21, 2010 12:32 PM
>>>> To: Matthew Dowle
>>>> Cc: r-devel at stat.math.ethz.ch
>>>> Subject: Re: [Rd] suggestion how to use memcpy in duplicate.c
>>>> 
>>>> Le 21/04/10 17:54, Matthew Dowle a ?crit :
>>>>>> From copyVector in duplicate.c :
>>>>> void copyVector(SEXP s, SEXP t)
>>>>> {
>>>>>     int i, ns, nt;
>>>>>     nt = LENGTH(t);
>>>>>     ns = LENGTH(s);
>>>>>     switch (TYPEOF(s)) {
>>>>> ...
>>>>>     case INTSXP:
>>>>>     for (i = 0; i<  ns; i++)
>>>>>         INTEGER(s)[i] = INTEGER(t)[i % nt];
>>>>>     break;
>>>>> ...
>>>>> 
>>>>> could that be replaced with :
>>>>> 
>>>>>     case INTSXP:
>>>>>     for (i=0; i<ns/nt; i++)
>>>>>         memcpy((char *)DATAPTR(s)+i*nt*sizeof(int), (char
>>>> *)DATAPTR(t),
>>>>> nt*sizeof(int));
>>>>>     break;
>>>> or at least with something like this:
>>>> 
>>>> int* p_s = INTEGER(s) ;
>>>> int* p_t = INTEGER(t) ;
>>>> for( i=0 ; i < ns ; i++){
>>>> p_s[i] = p_t[i % nt];
>>>> }
>>>> 
>>>> since expanding the INTEGER macro over and over has a price.
>>>> 
>>>>> and similar for the other types in copyVector.  This won't
>>>> help regular
>>>>> vector copies, since those seem to be done by the
>>>> DUPLICATE_ATOMIC_VECTOR
>>>>> macro, see next suggestion below, but it should help
>>>> copyMatrix which calls
>>>>> copyVector, scan.c which calls copyVector on three lines,
>>>> dcf.c (once) and
>>>>> dounzip.c (once).
>>>>> 
>>>>> For the DUPLICATE_ATOMIC_VECTOR macro there is already a
>>>> comment next to it
>>>>> :
>>>>> 
>>>>>     <FIXME>: surely memcpy would be faster here?
>>>>> 
>>>>> which seems to refer to the for loop  :
>>>>> 
>>>>>     else { \
>>>>>     int __i__; \
>>>>>     type *__fp__ = fun(from), *__tp__ = fun(to); \
>>>>>     for (__i__ = 0; __i__<  __n__; __i__++) \
>>>>>       __tp__[__i__] = __fp__[__i__]; \
>>>>>   } \
>>>>> 
>>>>> Could that loop be replaced by the following ?
>>>>> 
>>>>>    else { \
>>>>>    memcpy((char *)DATAPTR(to), (char *)DATAPTR(from),
>>>> __n__*sizeof(type)); \
>>>>>    }\
>>>>> 
>>>>> In the data.table package, dogroups.c uses this technique,
>>>> so the principle
>>>>> is tested and works well so far.
>>>>> 
>>>>> Are there any road blocks preventing this change, or is
>>>> anyone already
>>>>> working on it ?  If not then I'll try and test it (on
>>>> Ubuntu 32bit) and
>>>>> submit patch with timings, as before.  Comments/pointers
>>>> much appreciated.
>>>>> Matthew
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>> 
>>>> -- 
>>>> Romain Francois
>>>> Professional R Enthusiast
>>>> +33(0) 6 28 91 30 30
>>>> http://romainfrancois.blog.free.fr
>>>> |- http://bit.ly/9aKDM9 : embed images in Rd documents
>>>> |- http://tr.im/OIXN : raster images and RImageJ
>>>> |- http://tr.im/OcQe : Rcpp 0.7.7
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From cbrown at opendatagroup.com  Sat Apr 24 19:15:15 2010
From: cbrown at opendatagroup.com (Christopher Brown)
Date: Sat, 24 Apr 2010 10:15:15 -0700
Subject: [Rd] S4 Inheritance of environments
Message-ID: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>

I looked through the documentation and the mailing lists and could not
find an answer to this.  My apologies if it has already been answered.
 If it has, a pointer to the relevant discussion would be greatly
appreciated.

Creating S4 classes containing environments exhibits unexpected
behavior/features.? These have a different in two ways:

1) slotName for the data: ".xData" instead of ".Data" and do not respond to the
2) Response to the is.* function seems to indicate that the object
does not know of its inheritance.  ( Notably, the inherits function
works as expected. )

Here is a working illustration:

> #  LIST
> setClass( 'inheritList', contains='list')
[1] "inheritList"
> inList <- new( 'inheritList' )
> class( inList )
[1] "inheritList"
attr(,"package")
[1] ".GlobalEnv"
> is.list( inList )          # TRUE
[1] TRUE
> slotNames(inList)          # ".Data"
[1] ".Data"
> inherits(inList, 'list' )  # TRUE
[1] TRUE
>
>
> # ENVIRONMENT
> setClass( 'inheritEnv', contains='environment' )
Defining type "environment" as a superclass via class ".environment"
[1] "inheritEnv"
> inEnv <- new( 'inheritEnv' )
> class(inEnv)
[1] "inheritEnv"
attr(,"package")
[1] ".GlobalEnv"
> is.environment(inEnv)             # FALSE
[1] FALSE
> slotNames(inEnv)                  # ".xData"
[1] ".xData"
> inherits(inEnv, 'environment' )   # TRUE
[1] TRUE

My questions is whether this behavior is a bug? By design?  A work
around?  Etc.?

Thanks kindly for your reply,

Chris


the Open Data Group
?http://www.opendatagroup.com
?http://blog.opendatagroup.com


From rdpeng at gmail.com  Sun Apr 25 03:07:51 2010
From: rdpeng at gmail.com (Roger Peng)
Date: Sat, 24 Apr 2010 21:07:51 -0400
Subject: [Rd] S4 Inheritance of environments
In-Reply-To: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
References: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
Message-ID: <y2t66f3bd911004241807mbc1342a2k564466de5ee942b8@mail.gmail.com>

I think using 'is(inEnv, "environment")' produces the answer you
expect. Can't explain the other anomalies though.

-roger

On Sat, Apr 24, 2010 at 1:15 PM, Christopher Brown
<cbrown at opendatagroup.com> wrote:
> I looked through the documentation and the mailing lists and could not
> find an answer to this. ?My apologies if it has already been answered.
> ?If it has, a pointer to the relevant discussion would be greatly
> appreciated.
>
> Creating S4 classes containing environments exhibits unexpected
> behavior/features.? These have a different in two ways:
>
> 1) slotName for the data: ".xData" instead of ".Data" and do not respond to the
> 2) Response to the is.* function seems to indicate that the object
> does not know of its inheritance. ?( Notably, the inherits function
> works as expected. )
>
> Here is a working illustration:
>
>> # ?LIST
>> setClass( 'inheritList', contains='list')
> [1] "inheritList"
>> inList <- new( 'inheritList' )
>> class( inList )
> [1] "inheritList"
> attr(,"package")
> [1] ".GlobalEnv"
>> is.list( inList ) ? ? ? ? ?# TRUE
> [1] TRUE
>> slotNames(inList) ? ? ? ? ?# ".Data"
> [1] ".Data"
>> inherits(inList, 'list' ) ?# TRUE
> [1] TRUE
>>
>>
>> # ENVIRONMENT
>> setClass( 'inheritEnv', contains='environment' )
> Defining type "environment" as a superclass via class ".environment"
> [1] "inheritEnv"
>> inEnv <- new( 'inheritEnv' )
>> class(inEnv)
> [1] "inheritEnv"
> attr(,"package")
> [1] ".GlobalEnv"
>> is.environment(inEnv) ? ? ? ? ? ? # FALSE
> [1] FALSE
>> slotNames(inEnv) ? ? ? ? ? ? ? ? ?# ".xData"
> [1] ".xData"
>> inherits(inEnv, 'environment' ) ? # TRUE
> [1] TRUE
>
> My questions is whether this behavior is a bug? By design? ?A work
> around? ?Etc.?
>
> Thanks kindly for your reply,
>
> Chris
>
>
> the Open Data Group
> ?http://www.opendatagroup.com
> ?http://blog.opendatagroup.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From murdoch.duncan at gmail.com  Sun Apr 25 13:09:08 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 25 Apr 2010 07:09:08 -0400
Subject: [Rd] S4 Inheritance of environments
In-Reply-To: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
References: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
Message-ID: <4BD422D4.7000601@gmail.com>

On 24/04/2010 1:15 PM, Christopher Brown wrote:
> I looked through the documentation and the mailing lists and could not
> find an answer to this.  My apologies if it has already been answered.
>  If it has, a pointer to the relevant discussion would be greatly
> appreciated.
>   

Environments are unusual in that they are reference objects:  if e is an 
environment, and you assign f <- e, then f refers to the same object as 
e does.  This is unusual in R, where most objects are copied on 
assignment (logically, not always physically).  It means that attributes 
on environments behave strangely:  if you put an attribute on e and 
remove the same attribute from f, it is gone from e too.  We've 
discussed removing the possibility of putting attributes on environments 
(just as you can't put attributes on NULL), but haven't done so yet.

What you should do if you want to use an environment in the way you're 
using it is to put it in a container.  For S4, that could mean using an 
environment as a slot, or inheriting from an object like list(e), rather 
than directly from e.

Duncan Murdoch
> Creating S4 classes containing environments exhibits unexpected
> behavior/features.  These have a different in two ways:
>
> 1) slotName for the data: ".xData" instead of ".Data" and do not respond to the
> 2) Response to the is.* function seems to indicate that the object
> does not know of its inheritance.  ( Notably, the inherits function
> works as expected. )
>
> Here is a working illustration:
>
>   
>> #  LIST
>> setClass( 'inheritList', contains='list')
>>     
> [1] "inheritList"
>   
>> inList <- new( 'inheritList' )
>> class( inList )
>>     
> [1] "inheritList"
> attr(,"package")
> [1] ".GlobalEnv"
>   
>> is.list( inList )          # TRUE
>>     
> [1] TRUE
>   
>> slotNames(inList)          # ".Data"
>>     
> [1] ".Data"
>   
>> inherits(inList, 'list' )  # TRUE
>>     
> [1] TRUE
>   
>> # ENVIRONMENT
>> setClass( 'inheritEnv', contains='environment' )
>>     
> Defining type "environment" as a superclass via class ".environment"
> [1] "inheritEnv"
>   
>> inEnv <- new( 'inheritEnv' )
>> class(inEnv)
>>     
> [1] "inheritEnv"
> attr(,"package")
> [1] ".GlobalEnv"
>   
>> is.environment(inEnv)             # FALSE
>>     
> [1] FALSE
>   
>> slotNames(inEnv)                  # ".xData"
>>     
> [1] ".xData"
>   
>> inherits(inEnv, 'environment' )   # TRUE
>>     
> [1] TRUE
>
> My questions is whether this behavior is a bug? By design?  A work
> around?  Etc.?
>
> Thanks kindly for your reply,
>
> Chris
>
>
> the Open Data Group
>  http://www.opendatagroup.com
>  http://blog.opendatagroup.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at stat.berkeley.edu  Sun Apr 25 14:00:54 2010
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sun, 25 Apr 2010 14:00:54 +0200
Subject: [Rd] S4 Inheritance of environments
In-Reply-To: <4BD422D4.7000601@gmail.com>
References: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com> 
	<4BD422D4.7000601@gmail.com>
Message-ID: <x2n59d7961d1004250500ja07dfec2sfc568721e0753525@mail.gmail.com>

On Sun, Apr 25, 2010 at 1:09 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/04/2010 1:15 PM, Christopher Brown wrote:
>>
>> I looked through the documentation and the mailing lists and could not
>> find an answer to this. ?My apologies if it has already been answered.
>> ?If it has, a pointer to the relevant discussion would be greatly
>> appreciated.
>>
>
> Environments are unusual in that they are reference objects: ?if e is an
> environment, and you assign f <- e, then f refers to the same object as e
> does. ?This is unusual in R, where most objects are copied on assignment
> (logically, not always physically). ?It means that attributes on
> environments behave strangely: ?if you put an attribute on e and remove the
> same attribute from f, it is gone from e too. ?We've discussed removing the
> possibility of putting attributes on environments (just as you can't put
> attributes on NULL), but haven't done so yet.
>
> What you should do if you want to use an environment in the way you're using
> it is to put it in a container. ?For S4, that could mean using an
> environment as a slot, or inheriting from an object like list(e), rather
> than directly from e.

I can confirm these reported issues.  FYI, what Duncan is suggesting
is exactly the design behind the Object class (encapsulates an
environment) in the R.oo package.  The difference is that it is
working with S3.  It's been working flawlessly for > 9 years.  Others
have had idea to do the same but with S4, but I'm not sure if that
ever took of.

/Henrik
(R.oo author)
>
> Duncan Murdoch
>>
>> Creating S4 classes containing environments exhibits unexpected
>> behavior/features. ?These have a different in two ways:
>>
>> 1) slotName for the data: ".xData" instead of ".Data" and do not respond
>> to the
>> 2) Response to the is.* function seems to indicate that the object
>> does not know of its inheritance. ?( Notably, the inherits function
>> works as expected. )
>>
>> Here is a working illustration:
>>
>>
>>>
>>> # ?LIST
>>> setClass( 'inheritList', contains='list')
>>>
>>
>> [1] "inheritList"
>>
>>>
>>> inList <- new( 'inheritList' )
>>> class( inList )
>>>
>>
>> [1] "inheritList"
>> attr(,"package")
>> [1] ".GlobalEnv"
>>
>>>
>>> is.list( inList ) ? ? ? ? ?# TRUE
>>>
>>
>> [1] TRUE
>>
>>>
>>> slotNames(inList) ? ? ? ? ?# ".Data"
>>>
>>
>> [1] ".Data"
>>
>>>
>>> inherits(inList, 'list' ) ?# TRUE
>>>
>>
>> [1] TRUE
>>
>>>
>>> # ENVIRONMENT
>>> setClass( 'inheritEnv', contains='environment' )
>>>
>>
>> Defining type "environment" as a superclass via class ".environment"
>> [1] "inheritEnv"
>>
>>>
>>> inEnv <- new( 'inheritEnv' )
>>> class(inEnv)
>>>
>>
>> [1] "inheritEnv"
>> attr(,"package")
>> [1] ".GlobalEnv"
>>
>>>
>>> is.environment(inEnv) ? ? ? ? ? ? # FALSE
>>>
>>
>> [1] FALSE
>>
>>>
>>> slotNames(inEnv) ? ? ? ? ? ? ? ? ?# ".xData"
>>>
>>
>> [1] ".xData"
>>
>>>
>>> inherits(inEnv, 'environment' ) ? # TRUE
>>>
>>
>> [1] TRUE
>>
>> My questions is whether this behavior is a bug? By design? ?A work
>> around? ?Etc.?
>>
>> Thanks kindly for your reply,
>>
>> Chris
>>
>>
>> the Open Data Group
>> ?http://www.opendatagroup.com
>> ?http://blog.opendatagroup.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From groemping at bht-berlin.de  Sun Apr 25 18:57:59 2010
From: groemping at bht-berlin.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Sun, 25 Apr 2010 18:57:59 +0200
Subject: [Rd] Miktex does not work with R CMD check
Message-ID: <4BD47497.2080203@bht-berlin.de>

Dear DevelopeRs,

the issue I am stuck with (I am on Windows, R-2.11): My Miktex (version 
2.8) does not work with R CMD check, although Miktex on its own can 
pdflatex the tex-file in the Rcheck directory. (This issue has been 
going on for a while, and now, after having updated to R-2.11, I finally 
want to get it fixed.) Although I have found several similar posts, none 
of the answers appears to solve my problem, which seems to be 
path-related. In case it is relevant: in the past, I did have issues 
with paths to "my documents" because these contain a German Umlaut on my 
computer, which is why I moved all R packages to the directory c:/rtests.

I would appreciate any help on this issue. The relevant portion of R CMD 
check and the content of Rdlatex.log are included below.

Best regards,
Ulrike

The end of the R CMD check output looks like this:

* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
* checking PDF version of manual without index ... ERROR
LaTeX error when running command:
  Rcmd.exe Rd2dvi --batch --no-preview --pdf
    --build-dir=C:/WINDOWS/Temp/Rd2dvi611638299 --no-clean --no-index -o
    DoE.base-manual.pdf >/dev/null 2>&1 C:/rtests/DoE.base.Rcheck/DoE.base
Re-running with no redirection of stdout/stderr.

The file Rdlatex.log contains the following text:

Hmm ... looks like a package
latex.exe: A required file system path could not be retrieved.
latex.exe: Data: 28
Creating pdf output from LaTeX ...
pdflatex.exe: A required file system path could not be retrieved.
pdflatex.exe: Data: 28
Error in running pdflatex command ('pdflatex')
You may want to clean up by 'rm -rf C:/WINDOWS/Temp/Rd2dvi611638299'


From rusers.sh at gmail.com  Sun Apr 25 20:33:39 2010
From: rusers.sh at gmail.com (rusers.sh)
Date: Sun, 25 Apr 2010 14:33:39 -0400
Subject: [Rd] Question of R CMD check
In-Reply-To: <u2ia835c81e1004231735nd64de92aif591b5e63d2916f3@mail.gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>
	<4BD1635D.7050802@gmail.com>
	<s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>
	<4BD216DE.4070304@gmail.com>
	<u2ia835c81e1004231735nd64de92aif591b5e63d2916f3@mail.gmail.com>
Message-ID: <k2ya835c81e1004251133z5272d463i221bebb154cbeca9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100425/2e4321fe/attachment.pl>

From HodgessE at uhd.edu  Sun Apr 25 20:48:06 2010
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sun, 25 Apr 2010 13:48:06 -0500
Subject: [Rd] problem with Rcmdr Plugins
Message-ID: <101CBF5360343B45B9C9B0B05D71474C25B3F0@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100425/6d1291ce/attachment.pl>

From HodgessE at uhd.edu  Sun Apr 25 20:55:38 2010
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sun, 25 Apr 2010 13:55:38 -0500
Subject: [Rd] a side note to the Rcmdr issue
Message-ID: <101CBF5360343B45B9C9B0B05D71474C25B3F1@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100425/8a4546b8/attachment.pl>

From jfox at mcmaster.ca  Sun Apr 25 21:46:35 2010
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 25 Apr 2010 15:46:35 -0400
Subject: [Rd] a side note to the Rcmdr issue
In-Reply-To: <101CBF5360343B45B9C9B0B05D71474C25B3F1@BALI.uhd.campus>
References: <101CBF5360343B45B9C9B0B05D71474C25B3F1@BALI.uhd.campus>
Message-ID: <003201cae4b0$03993630$0acba290$@ca>

Dear Erin,

Unlike in previous version of R for Windows, the package list is
alphabetized with uppercase letters preceding lowercase letters. Thus look
under uppercase "R" and then lowercase "c".

Regards,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of Hodgess, Erin
> Sent: April-25-10 2:56 PM
> To: r-devel at r-project.org
> Subject: [Rd] a side note to the Rcmdr issue
> 
> Hi again.
> 
> On Windows, when I try to use the "install packages" from the menu, there
is
> no Rcmdr and no RcmdrPlugins to be seen.
> 
> thanks,
> Erin
> 
> 
> Erin M. Hodgess, PhD
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Sun Apr 25 21:54:04 2010
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 25 Apr 2010 15:54:04 -0400
Subject: [Rd] problem with Rcmdr Plugins
In-Reply-To: <101CBF5360343B45B9C9B0B05D71474C25B3F0@BALI.uhd.campus>
References: <101CBF5360343B45B9C9B0B05D71474C25B3F0@BALI.uhd.campus>
Message-ID: <003301cae4b1$0ef768c0$2ce63a40$@ca>

Dear Erin,

I'm not sure why this is a problem with R 2.11.0 and not with earlier
versions (I'm sure that someone else will be able to answer), but it is
unnecessary for your plug-in package to require rgl, since rgl is already
loaded by the Rcmdr package at startup if it is present. The same is true of
tseries, abind, and MASS.

I hope this helps,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of Hodgess, Erin
> Sent: April-25-10 2:48 PM
> To: r-devel at r-project.org
> Subject: [Rd] problem with Rcmdr Plugins
> 
> Dear R Development People:
> 
> I have written a couple of plugins for Rcmdr and they do not seem to work
> with R-2.11.0.
> 
> Here is the output:
> > library(RcmdrPlugin.epack)
> Loading required package: Rcmdr
> Loading required package: tcltk
> Loading Tcl/Tk interface ... done
> Loading required package: car
> --- Please select a CRAN mirror for use in this session ---
> 
> Rcmdr Version 1.5-4
> 
> 
> Attaching package: 'Rcmdr'
> 
> The following object(s) are masked from 'package:tcltk':
> 
>     tclvalue
> 
> Loading required package: rgl
> Loading required package: TeachingDemos
> Loading required package: tseries
> Loading required package: quadprog
> Loading required package: zoo
> 
>     'tseries' version: 0.10-22
> 
>     'tseries' is a package for time series analysis and computational
>     finance.
> 
>     See 'library(help="tseries")' for details.
> 
> Loading required package: abind
> Loading required package: MASS
> Error : package 'rgl' is required by 'RcmdrPlugin.epack' so will not be
> detached
> Error in library(RcmdrPlugin.epack) :
>   .First.lib failed for 'RcmdrPlugin.epack'
> >
> 
> This is on a Windows XP.  I'm downloading the Rcmdr requirements on a
Linux
> machine as we speak.
> 
> Have you run into this please?
> Thanks,
> Erin
> 
> 
> Erin M. Hodgess, PhD
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Mon Apr 26 00:38:54 2010
From: jmc at r-project.org (John Chambers)
Date: Sun, 25 Apr 2010 15:38:54 -0700
Subject: [Rd] S4 Inheritance of environments
In-Reply-To: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
References: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
Message-ID: <4BD4C47E.3020401@r-project.org>

In addition to Duncan Murdoch's explanation, this is discussed in the 
documentation for "Classes" (briefly):
.....

Extending a basic type this way allows objects to use old-style code for 
the corresponding type as well as S4 methods. Any basic type can be used 
for .Data, but a few types are treated differently because they do not 
behave like ordinary objects; for example, "NULL", environments, and 
external pointers. Classes extend these types by using a specially named 
slot, itself inherited from an internally defined S4 class. Inheritance 
from the nonstandard object type then requires an actual computation, 
rather than the "simple" inclusion for other types and classes. The 
intent is that programmers will not need to take account of the 
mechanism, but one implication is that you should not explicitly use the 
type of an S4 object that extends an arbitrary object type. Use is and 
similar functions instead.

.......


The code for is.environment() is presumably using the type, whereas 
inherits() takes account of the indirect mechanism.

Generally, you should be able to deal with inheritance from environments 
in a natural way.

John


On 4/24/10 10:15 AM, Christopher Brown wrote:
> I looked through the documentation and the mailing lists and could not
> find an answer to this.  My apologies if it has already been answered.
>   If it has, a pointer to the relevant discussion would be greatly
> appreciated.
>
> Creating S4 classes containing environments exhibits unexpected
> behavior/features.  These have a different in two ways:
>
> 1) slotName for the data: ".xData" instead of ".Data" and do not respond to the
> 2) Response to the is.* function seems to indicate that the object
> does not know of its inheritance.  ( Notably, the inherits function
> works as expected. )
>
> Here is a working illustration:
>
>> #  LIST
>> setClass( 'inheritList', contains='list')
> [1] "inheritList"
>> inList<- new( 'inheritList' )
>> class( inList )
> [1] "inheritList"
> attr(,"package")
> [1] ".GlobalEnv"
>> is.list( inList )          # TRUE
> [1] TRUE
>> slotNames(inList)          # ".Data"
> [1] ".Data"
>> inherits(inList, 'list' )  # TRUE
> [1] TRUE
>>
>>
>> # ENVIRONMENT
>> setClass( 'inheritEnv', contains='environment' )
> Defining type "environment" as a superclass via class ".environment"
> [1] "inheritEnv"
>> inEnv<- new( 'inheritEnv' )
>> class(inEnv)
> [1] "inheritEnv"
> attr(,"package")
> [1] ".GlobalEnv"
>> is.environment(inEnv)             # FALSE
> [1] FALSE
>> slotNames(inEnv)                  # ".xData"
> [1] ".xData"
>> inherits(inEnv, 'environment' )   # TRUE
> [1] TRUE
>
> My questions is whether this behavior is a bug? By design?  A work
> around?  Etc.?
>
> Thanks kindly for your reply,
>
> Chris
>
>
> the Open Data Group
>   http://www.opendatagroup.com
>   http://blog.opendatagroup.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Mon Apr 26 10:29:58 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Apr 2010 09:29:58 +0100 (BST)
Subject: [Rd] a side note to the Rcmdr issue
In-Reply-To: <003201cae4b0$03993630$0acba290$@ca>
References: <101CBF5360343B45B9C9B0B05D71474C25B3F1@BALI.uhd.campus>
	<003201cae4b0$03993630$0acba290$@ca>
Message-ID: <alpine.LFD.2.00.1004260922330.4671@gannet.stats.ox.ac.uk>

On Sun, 25 Apr 2010, John Fox wrote:

> Dear Erin,
>
> Unlike in previous version of R for Windows, the package list is
> alphabetized with uppercase letters preceding lowercase letters. Thus look
> under uppercase "R" and then lowercase "c".

Actually, that is not the case: the list is in whatever order the 
repositories provide, ordered by repository, and in previous versions 
of R it was sorted in the locale (which as you are both most likely in 
a Windows American English locale, would sort the way John describes).

It's a somewhat accidental result of removing support for bundles that 
the list was no longer sorted, and I'll add the sort back.

>
> Regards,
> John
>
> --------------------------------
> John Fox
> Senator William McMaster
>  Professor of Social Statistics
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> web: socserv.mcmaster.ca/jfox
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On
>> Behalf Of Hodgess, Erin
>> Sent: April-25-10 2:56 PM
>> To: r-devel at r-project.org
>> Subject: [Rd] a side note to the Rcmdr issue
>>
>> Hi again.
>>
>> On Windows, when I try to use the "install packages" from the menu, there
> is
>> no Rcmdr and no RcmdrPlugins to be seen.
>>
>> thanks,
>> Erin
>>
>>
>> Erin M. Hodgess, PhD
>> Associate Professor
>> Department of Computer and Mathematical Sciences
>> University of Houston - Downtown
>> mailto: hodgesse at uhd.edu
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jinghuazhao at hotmail.com  Mon Apr 26 12:33:03 2010
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Mon, 26 Apr 2010 10:33:03 +0000
Subject: [Rd] Deferred Default Marker
In-Reply-To: <1272036039.5556.17.camel@punchbuggy>
References: <1272036039.5556.17.camel@punchbuggy>
Message-ID: <COL105-W18F9DFA01ABF9DDB512A1FA5040@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100426/9fd50677/attachment.pl>

From jinghuazhao at hotmail.com  Mon Apr 26 12:55:00 2010
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Mon, 26 Apr 2010 10:55:00 +0000
Subject: [Rd] some queries over cross-compilation
In-Reply-To: <COL105-W18F9DFA01ABF9DDB512A1FA5040@phx.gbl>
References: <1272036039.5556.17.camel@punchbuggy>,
	<COL105-W18F9DFA01ABF9DDB512A1FA5040@phx.gbl>
Message-ID: <COL105-W416430DF1FD78171051E45A5040@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100426/1d122a19/attachment.pl>

From stefan_theussl at gmx.at  Mon Apr 26 13:47:11 2010
From: stefan_theussl at gmx.at (=?iso-8859-1?Q?=22Stefan_Peter_Theu=DFl=22?=)
Date: Mon, 26 Apr 2010 13:47:11 +0200
Subject: [Rd] CRAN master, R-Forge, R-Project websites down
Message-ID: <20100426114711.177770@gmx.net>

Dear R users and developers,

Due to a failure of the electrical system, the IT services (also hosting R-project related websites) of the WU (Vienna University of Economics and Business) are currently unavailable. 

Affected websites and services are: CRAN master (cran.r-project.org), the R-project website (www.r-project.org) and R-Forge (r-forge.r-project.org). 

The R binaries and sources as well as packages can still be downloaded by any CRAN mirrors distributed all over the world. Please select a different mirror than "Austria" in R (GUI).

We apologize for any inconvenience.

Best regards,
Stefan Theussl
-- 
GMX.at - ?sterreichs FreeMail-Dienst mit ?ber 2 Mio Mitgliedern
E-Mail, SMS & mehr! Kostenlos: http://portal.gmx.net/de/go/atfreemail


From ligges at statistik.tu-dortmund.de  Mon Apr 26 13:58:00 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 26 Apr 2010 13:58:00 +0200
Subject: [Rd] Question of R CMD check
In-Reply-To: <k2ya835c81e1004251133z5272d463i221bebb154cbeca9@mail.gmail.com>
References: <x2ta835c81e1004211848l29dafef3k798392d254a15533@mail.gmail.com>	<4BD1635D.7050802@gmail.com>	<s2ka835c81e1004231019n4a6e11dft134194f90ff9e532@mail.gmail.com>	<4BD216DE.4070304@gmail.com>	<u2ia835c81e1004231735nd64de92aif591b5e63d2916f3@mail.gmail.com>
	<k2ya835c81e1004251133z5272d463i221bebb154cbeca9@mail.gmail.com>
Message-ID: <4BD57FC8.4050604@statistik.tu-dortmund.de>



On 25.04.2010 20:33, rusers.sh wrote:
> Hi all,
>    I find the problem.See below.
>    Today, i installed the newest R-VERSION2.11.0 for checking. Different
> error occurred. I checked the log and found 'Hmisc' package caused this. At
> present, binary package was not provided. After i installed an old version
> of 'Hmisc' package, it works very well.
>    I think there should be no problem for R. It may be caused by
> the dependent  package 'Hmisc' that has no newest binary package in the
> CRAN. Sorry about this.


As discussed on R-help (?) before, Hmsic is not available as a Windows 
binary since it fails checks under current R-release.

Uwe Ligges


> 2010/4/23 rusers.sh<rusers.sh at gmail.com>
>
>> Hi Duncan,
>>    Enclosed is the example package and the checking results. No rm() or
>> remove() in the example. Before this re-installation of  R and other tools
>> (e.g. Rtools), there are no errors for package checking.
>>    Thanks.
>>
>>
>> 2010/4/23 Duncan Murdoch<murdoch.duncan at gmail.com>
>>
>>> On 23/04/2010 1:19 PM, rusers.sh wrote:
>>>
>>>> Hi Duncan,
>>>>   Thanks for reminding me. See below for the error information from *.Rout
>>>> file
>>>>   It seems that 'pkgname' was not found. I am not sure whether there is
>>>> some
>>>> problem with my functions or it is a little bug.
>>>>   Thanks a lot.
>>>> #######
>>>>
>>>>
>>>>> assign("ptime", proc.time(), pos = "CheckExEnv")
>>>>> ## at least one package changes these via ps.options(), so do this
>>>>> ## before loading the package.
>>>>> ## Use postscript as incomplete files may be viewable, unlike PDF.
>>>>> ## Choose a size that is close to on-screen devices, fix paper
>>>>> grDevices::ps.options(width = 7, height = 7, paper = "a4", reset = TRUE)
>>>>> grDevices::postscript(paste(pkgname, "-Ex.ps", sep=""))
>>>>>
>>>>>
>>>> Error in paste(pkgname, "-Ex.ps", sep = "") : object 'pkgname' not found
>>>> Calls:<Anonymous>  ->  checkIntFormat ->  gsub ->  paste
>>>> Execution halted
>>>>
>>>>
>>>
>>> The very first line of stam-Ex.R should be
>>>
>>> pkgname<- "stam"
>>>
>>> Is it?  If not, I'd like to see the package; could you send me a copy?  If
>>> it is, then something in one of your examples is messing with it.  Do you
>>> have any calls to rm() or remove() in your examples?
>>>
>>> Duncan Murdoch
>>>
>>>   2010/4/23 Duncan Murdoch<murdoch.duncan at gmail.com>
>>>>
>>>>
>>>>
>>>>> On 21/04/2010 9:48 PM, rusers.sh wrote:
>>>>>
>>>>>
>>>>>
>>>>>> Hi all,
>>>>>>    Today, i just installed the newest R version 2.10.1 and other
>>>>>> necessary
>>>>>> tools for building R package under windows,e.g. Rtools, perl. All are
>>>>>> the
>>>>>> newest version.
>>>>>>   After the correct configuration under windows (configuration should be
>>>>>> correct), i use it to re-check my old package. I found the following
>>>>>> prolem
>>>>>> when checking EXAMPLEs in each function, which did not exist before
>>>>>> this
>>>>>> re-installation.
>>>>>> ########
>>>>>> * checking examples ... ERROR
>>>>>>   Running examples in 'stam-Ex.R' failed.
>>>>>> ########
>>>>>>   I used "\dontrun{} % enddontrun" in all the examples of my functions
>>>>>> that
>>>>>> should be no problem, i think. I checked my package before and did not
>>>>>> find
>>>>>> errors. I also browsed the checking results in 'stam-Ex.R'. It listed
>>>>>> all
>>>>>> the example codes in that file, something like this,
>>>>>>   cleanEx(); nameEx("stcdt")
>>>>>>   ### * stcdt
>>>>>>   flush(stderr()); flush(stdout())
>>>>>>   ###example codes
>>>>>>
>>>>>>   I did not met this problem before.  Any ideas on solving this?
>>>>>>   Thanks a lot.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>> You need to show us the end of the stam-Ex.Rout file.  It will contain
>>>>> the
>>>>> error message.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>> --
>> -----------------
>> Jane Chang
>> Queen's
>>
>
>
>


From ligges at statistik.tu-dortmund.de  Mon Apr 26 14:04:32 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 26 Apr 2010 14:04:32 +0200
Subject: [Rd] some queries over cross-compilation
In-Reply-To: <COL105-W416430DF1FD78171051E45A5040@phx.gbl>
References: <1272036039.5556.17.camel@punchbuggy>,
	<COL105-W18F9DFA01ABF9DDB512A1FA5040@phx.gbl>
	<COL105-W416430DF1FD78171051E45A5040@phx.gbl>
Message-ID: <4BD58150.3010402@statistik.tu-dortmund.de>

Cross compiling support has been dropped.
If you want to have it, please patch the sources yourself.
If you just want to get a Windows biunary of one package and you do not 
have a Windows machine around, you may use the service at:
http://win-builder.r-project.org/

Uwe Ligges



On 26.04.2010 12:55, jing hua zhao wrote:
>
> Dear R developers,
>
> I ran into some problems that I wish to get around.
>
> Following the recommendation from "Building R for Windows" (Duncan's site) I was able to obtain some files from Brian's site for relevant tools for cross-compile. Initially I was able to cross-compile Windows packages happily with the setup I had based on R 2.7.0  (essentially as described in cran.r-project.org/doc/contrib/cross-build.pdf) but got it entirely muddled up with R 2.11.0. I found this was actually not officially supported from R 2.9.0.
>
> I then found I cannot even remove the Tcl directory (8-5-8) even I move or rename it. Is there a way to do that?
>
> I wonder if there is an equivalent of i586-mingw32 (x86_64-w64-mingw32-) or I have to customise that myself. I got errors at various stage and at one time  i586-mingw32-nm could not recognise ch2inv.o that was generated. Perhaps I would get some headway with alternative. Perhaps I would need also reestablish my R 2.7.0 cross-compile to see if my initial build was just a fake.
>
> Many thanks,
>
>
> Jing Hua
>   		 	   		
> _________________________________________________________________
>
> We want to hear all your funny, exciting and crazy Hotmail stories. Tell us now
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jinghuazhao at hotmail.com  Mon Apr 26 14:26:50 2010
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Mon, 26 Apr 2010 12:26:50 +0000
Subject: [Rd] some queries over cross-compilation
In-Reply-To: <4BD58150.3010402@statistik.tu-dortmund.de>
References: <1272036039.5556.17.camel@punchbuggy>,
	<COL105-W18F9DFA01ABF9DDB512A1FA5040@phx.gbl>
	<COL105-W416430DF1FD78171051E45A5040@phx.gbl>,
	<4BD58150.3010402@statistik.tu-dortmund.de>
Message-ID: <COL105-W31882193EA13F581F5FB24A5040@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100426/e60eaa3a/attachment.pl>

From stefan_theussl at gmx.at  Mon Apr 26 16:09:52 2010
From: stefan_theussl at gmx.at (=?iso-8859-1?Q?=22Stefan_Peter_Theu=DFl=22?=)
Date: Mon, 26 Apr 2010 16:09:52 +0200
Subject: [Rd] Update: working mirrors and services due to IT failure at WU
Message-ID: <20100426140952.249390@gmx.net>

Dear R community,

The only working mirror under a separate subdomain in the zone r-project.org is cran.us.r-project.org. Some mirrors are just virtualhosts on the master server and thus cannot be resolved via DNS. These are:
cran.au.r-project.org
cran.br.r-project.org
cran.ca.r-project.org
cran.ch.r-project.org
cran.de.r-project.org
cran.dk.r-project.org
cran.fr.r-project.org
cran.it.r-project.org
cran.pt.r-project.org
cran.uk.r-project.org
cran.za.r-project.org

Please *use any other mirror* from the mirror list to download documentation and software.

Other services not affected:

bugs.r-project.org, developer.r-project.org, ess.r-project.org, search.r-project.org, svn.r-project.org, wiki.r-project.org, win-builder.r-project.org

According to the IT Service Center a downtime of at least 24 hours is expected. Further information about the incident will be provided at http://wu.ac.at/.

Best regards,
Stefan Theussl
-- 
GMX.at - ?sterreichs FreeMail-Dienst mit ?ber 2 Mio Mitgliedern
E-Mail, SMS & mehr! Kostenlos: http://portal.gmx.net/de/go/atfreemail


From therneau at mayo.edu  Mon Apr 26 16:52:50 2010
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 26 Apr 2010 09:52:50 -0500
Subject: [Rd] Deferred Default Marker
In-Reply-To: <4BD1F1BB.2050302@ucalgary.ca>
References: <1272036039.5556.17.camel@punchbuggy>
	<4BD1F1BB.2050302@ucalgary.ca>
Message-ID: <1272293570.28958.7.camel@punchbuggy>

Peter, 
  There was no particular reason for an older kinship; just hadn't
downloaded it in a while.  I grabbed a private copy just now and the
error went away, R 2.10.0. I remain curious as to what the message was
about, but not enough for either of us to do any work to find out.
   I've sent off a message to have a sysadmin update our servers with
the new copy of the library. 

  Thanks for looking at it.
       Terry

--------- begin included message------------

I don't see the problem in R 2.11.0 or R 2.10.1 Patched
(session info for R 2.10.1 below) with Windows (Vista).
I do get warnings about kinship having been built under
R 2.11.0 when I use R 2.10.1.

But I notice that your version of kinship looks somewhat
dated. Is that intentional?

   -Peter Ehlers


From kasperdanielhansen at gmail.com  Mon Apr 26 17:15:59 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 26 Apr 2010 11:15:59 -0400
Subject: [Rd] 00LOCK and nfs
Message-ID: <s2le780c0971004260815we5156859v293d5b3a6ffd9890@mail.gmail.com>

I am running into a problem with the 00LOCK file and .nfs files.  It
seemed to be caused by the following
  R is installed on NFS
  user A has loaded pkg_A containing a dynamically loaded library
  user B (the administrator) runs install.packages("pkg_A")
  as the final part of the installation process the 00LOCK directory is removed
  this creates a .nfs file because user A has the dynamic library open
  this .nfs file cannot be removed until user A exits R
  because of this, 00LOCK cannot be removed, and if the
install.packages call is going to install packages after pkg_A, they
fail

Now, while there are certainly open questions concerning this, I have
a pretty good idea of the problem, and I even have some ideas on how
to fix it.

But before I spent more time on this, I would like to hear how other
people handle this.  In my analysis, this is a problem whenever you
have R installed on NFS, this R is used by multiple users and you
often run update.packages to keep the installation current.  There
must be plenty of people out there who do this.  In other words:
someone else must have had this problem before (and presumably fixed
it).  I don't know much (anything) about NFS, so perhaps this is
caused by our NFS setup.

Comments, before I spent more hours looking into this?

Thanks,
Kasper


From shotwelm at musc.edu  Mon Apr 26 18:28:03 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Mon, 26 Apr 2010 12:28:03 -0400
Subject: [Rd] serial connection patch
In-Reply-To: <5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
Message-ID: <1272299283.3901.57.camel@deacon>

All, 

Our discussion of serial interfaces last week motivated me to dig into
the R connections API. In short, I spent the weekend writing a patch for
version 2.11.0 that adds a serial connection. I posted a blog entry that
gives instructions for applying, configuring, and compiling the patched
version <http://biostatmatt.com/archives/112>.

The patch currently only enables a serial connection for POSIX compliant
OSs. It should NOT be considered well tested, though I feel it is fairly
safe. I would really like to hear from someone who can try it on Mac OS
X (and Windows to ensure that it has the correct 'null' behavior).

Briefly, the connection utilizes (and checks for) the termios.h header.
I opted not to extend the 'file' connection in a manner similar to the
'pipe' connection because this might not be suitable under Win32. Hence,
there are new read, write, flush, open, and close methods and a struct
serialconn for the serial connection. Opens are non-blocking and binary
only. Serial parameters can be passed when the connection is created. I
overloaded the summary method in order for the user to see the serial
settings.

I've done my best to be consistent and conforming with the connections
API and coding style. However, I would be great if someone with more
experience with the R API (Simon? :)) would take a critical look at the
design and coding of the new connection. If this is something that the R
community would like to pursue, I'd like to work on support for Windows
serial interfaces. Below is a link to the patch file and the output of
diffstat.

<http://biostatmatt.com/R/R-2.11.0-serial.patch>


file                                |  mod 	ins	del
------------------------------------------------------------
configure.ac                        |    2 	1 +	1 -
src/include/Internal.h              |    2 	2 +	0 -
src/library/base/R/connections.R    |   10 	10 +	0 -
src/library/base/man/connections.Rd |   60 	49 +	11 -
src/main/connections.c              |  379 	379 +	0 -
src/main/names.c                    |    2 	2 +	0 -


P.S. connections.c is the largest file in src/main/, before and after
the patch. Making the 379 additions increased the file size by 6.9%
(10.7kB). Adding Windows support should increase the file size by a
lesser amount.

-Matt

On Wed, 2010-04-21 at 08:07 -0400, Simon Urbanek wrote:
> Philippe,
> 
> unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.
> 
> I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).
> 
> Cheers,
> Simon
> 
> 
> 
> On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:
> 
> > There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
> > 
> > Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
> > 
> > It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
> > 
> > require(tcltk)
> > .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
> > 
> > # There are many config parameters available here... just an example
> > .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
> > 
> > # Send a command to your device through the serial port
> > .Tcl('puts -nonewline $R_com1 {my_cmd}')
> > 
> > # Read a line of text from the serial port
> > line <- tclvalue(.Tcl('gets $R_com1'))
> > 
> > With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
> > 
> > .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
> > 
> > Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
> > 
> > In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
> > 
> > All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
> > 
> > If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
> > 
> > Best,
> > 
> > Philippe
> > ..............................................<?}))><........
> > ) ) ) ) )
> > ( ( ( ( (    Prof. Philippe Grosjean
> > ) ) ) ) )
> > ( ( ( ( (    Numerical Ecology of Aquatic Systems
> > ) ) ) ) )   Mons University, Belgium
> > ( ( ( ( (
> > ..............................................................
> > 
> > On 21/04/10 03:17, shotwelm wrote:
> >> Simon is right of course, there are plenty of sensors that would work
> >> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
> >> theorem along these lines (Nyquist sampling theorem?). I think piping
> >> the output to R is a clever solution. I added a few lines to the ttys.c
> >> program so that the baud rate is a command line option (i.e. -B9600)
> >> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
> >> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
> >> addictive!
> >> 
> >> For an ioctl package, I was originally thinking of using file
> >> descriptors directly. However, I agree this feels like subverting what
> >> could be an extension of the connections API. Given that "everything is
> >> a file" in POSIX systems, there may be an argument for an ioctl package
> >> that is independent of the connections implementation, say to do things
> >> that connections were not designed to do. For example, interfacing with
> >> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
> >> read or write calls. But maybe it would just be better to pipe this type
> >> of output to R also...
> >> 
> >> -Matt
> >> 
> >> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
> >>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
> >>> 
> >>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
> >>> 
> >>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
> >>> 
> >>> 
> >>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
> >>>> 
> >>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
> >>> 
> >>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
> >>> 
> >>> 
> >>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
> >>>> 
> >>> 
> >>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
> >>> 
> >>> 
> >>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
> >>>> 
> >>> 
> >>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
> >>> 
> >>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
> >>> 
> >>> That's just my $0.02, though ...
> >>> 
> >>> Cheers,
> >>> Simon
> >>> 
> >>> 
> >>>> 
> >>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
> >>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
> >>>>> 
> >>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> >>>>>> 
> >>>>> 
> >>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
> >>>>> 
> >>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
> >>>>> 
> >>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
> >>>>> 
> >>>>> and then use something like
> >>>>> 
> >>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
> >>>>> 
> >>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
> >>>>> 
> >>>>> Cheers,
> >>>>> Simon
> >>>>> 
> >>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
> >>>>> 
> >>>>> 
> >>>>>> In base::connections documentation, it's not clear if there's an easy
> >>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> >>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
> >>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
> >>>>>> mind I have the thought of trying to redirect /dev/something to a
> >>>>>> file, or symlinking a file to point to the hardware, but know that
> >>>>>> there has to be some secret sauce to go from streaming in to a
> >>>>>> readable file, but don't know what the missing components are).
> >>>>>> 
> >>>>>> Thoughts?
> >>>>>> 
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>> 
> >>>>>> 
> >>>>> 
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> 
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> 
> >>>> 
> >>> 
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> >> 
> > 
> > 
>


From brechbuehler at gmail.com  Mon Apr 26 19:54:16 2010
From: brechbuehler at gmail.com (=?ISO-8859-1?Q?Christian_Brechb=FChler?=)
Date: Mon, 26 Apr 2010 13:54:16 -0400
Subject: [Rd] 00LOCK and nfs
In-Reply-To: <s2le780c0971004260815we5156859v293d5b3a6ffd9890@mail.gmail.com>
References: <s2le780c0971004260815we5156859v293d5b3a6ffd9890@mail.gmail.com>
Message-ID: <l2kc0177e5a1004261054k3775628fyb6c1fd154707dd91@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100426/bf221561/attachment.pl>

From simon.urbanek at r-project.org  Mon Apr 26 20:18:00 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 26 Apr 2010 14:18:00 -0400
Subject: [Rd] serial connection patch
In-Reply-To: <1272299283.3901.57.camel@deacon>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
	<1272299283.3901.57.camel@deacon>
Message-ID: <7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>

Matt,

thanks for you efforts. We cannot directly use your patch due to licensing issues (please note the licenses in the files you are modifying - I don't think anyone can currently use the patch and redistribute the resulting R; also/or we may possibly need to clarify that the work is either done on behalf of the R-foundation or the copyright is assigned to R-foundation or something similar so future licensing issues can be solved by the Foundation since that is the copyright holder of most of R).

Apart from that, the overall structure looks good, but the devil is in the details. It does not quite work for me on OS X (any read/writes just hang in the same way that it would if you used a file connection on the tty device) - I don't think it is as simple (AFAIR you have to make sure you open it such that it doesn't become the controlling terminal). Also it would definitely need "blocking" argument like most other connections have.

In general I don't think serial is the right name (and scope) here - what we're really looking for a is a tty connection (and serial just an application of it). What you have so far is a file connection with setserial functionality on it - and I think that may be more easily done by really using setserial on the already implemented file connection. The difference with tty is the other parts such as flow control, modes etc. It's much more work to expose those, but I think that is what the direction would be. In fact it could well be that tty is simply file connection + termio so you don't have to re-invent the wheel (under the hood). Also that would give you many aspects for free since you could inherit from file at the R level.

I hope it helps. I was thinking about the above but in the end decided to back off once I was looking at the flood of parameters you have to take care of in tty. But it would be nice if someone did that ;).

Cheers,
Simon


On Apr 26, 2010, at 12:28 PM, Matt Shotwell wrote:

> All, 
> 
> Our discussion of serial interfaces last week motivated me to dig into
> the R connections API. In short, I spent the weekend writing a patch for
> version 2.11.0 that adds a serial connection. I posted a blog entry that
> gives instructions for applying, configuring, and compiling the patched
> version <http://biostatmatt.com/archives/112>.
> 
> The patch currently only enables a serial connection for POSIX compliant
> OSs. It should NOT be considered well tested, though I feel it is fairly
> safe. I would really like to hear from someone who can try it on Mac OS
> X (and Windows to ensure that it has the correct 'null' behavior).
> 
> Briefly, the connection utilizes (and checks for) the termios.h header.
> I opted not to extend the 'file' connection in a manner similar to the
> 'pipe' connection because this might not be suitable under Win32. Hence,
> there are new read, write, flush, open, and close methods and a struct
> serialconn for the serial connection. Opens are non-blocking and binary
> only. Serial parameters can be passed when the connection is created. I
> overloaded the summary method in order for the user to see the serial
> settings.
> 
> I've done my best to be consistent and conforming with the connections
> API and coding style. However, I would be great if someone with more
> experience with the R API (Simon? :)) would take a critical look at the
> design and coding of the new connection. If this is something that the R
> community would like to pursue, I'd like to work on support for Windows
> serial interfaces. Below is a link to the patch file and the output of
> diffstat.
> 
> <http://biostatmatt.com/R/R-2.11.0-serial.patch>
> 
> 
> file                                |  mod 	ins	del
> ------------------------------------------------------------
> configure.ac                        |    2 	1 +	1 -
> src/include/Internal.h              |    2 	2 +	0 -
> src/library/base/R/connections.R    |   10 	10 +	0 -
> src/library/base/man/connections.Rd |   60 	49 +	11 -
> src/main/connections.c              |  379 	379 +	0 -
> src/main/names.c                    |    2 	2 +	0 -
> 
> 
> P.S. connections.c is the largest file in src/main/, before and after
> the patch. Making the 379 additions increased the file size by 6.9%
> (10.7kB). Adding Windows support should increase the file size by a
> lesser amount.
> 
> -Matt
> 
> On Wed, 2010-04-21 at 08:07 -0400, Simon Urbanek wrote:
>> Philippe,
>> 
>> unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.
>> 
>> I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:
>> 
>>> There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
>>> 
>>> Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
>>> 
>>> It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
>>> 
>>> require(tcltk)
>>> .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
>>> 
>>> # There are many config parameters available here... just an example
>>> .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
>>> 
>>> # Send a command to your device through the serial port
>>> .Tcl('puts -nonewline $R_com1 {my_cmd}')
>>> 
>>> # Read a line of text from the serial port
>>> line <- tclvalue(.Tcl('gets $R_com1'))
>>> 
>>> With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
>>> 
>>> .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
>>> 
>>> Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
>>> 
>>> In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
>>> 
>>> All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
>>> 
>>> If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
>>> 
>>> Best,
>>> 
>>> Philippe
>>> ..............................................<?}))><........
>>> ) ) ) ) )
>>> ( ( ( ( (    Prof. Philippe Grosjean
>>> ) ) ) ) )
>>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>>> ) ) ) ) )   Mons University, Belgium
>>> ( ( ( ( (
>>> ..............................................................
>>> 
>>> On 21/04/10 03:17, shotwelm wrote:
>>>> Simon is right of course, there are plenty of sensors that would work
>>>> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
>>>> theorem along these lines (Nyquist sampling theorem?). I think piping
>>>> the output to R is a clever solution. I added a few lines to the ttys.c
>>>> program so that the baud rate is a command line option (i.e. -B9600)
>>>> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
>>>> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
>>>> addictive!
>>>> 
>>>> For an ioctl package, I was originally thinking of using file
>>>> descriptors directly. However, I agree this feels like subverting what
>>>> could be an extension of the connections API. Given that "everything is
>>>> a file" in POSIX systems, there may be an argument for an ioctl package
>>>> that is independent of the connections implementation, say to do things
>>>> that connections were not designed to do. For example, interfacing with
>>>> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
>>>> read or write calls. But maybe it would just be better to pipe this type
>>>> of output to R also...
>>>> 
>>>> -Matt
>>>> 
>>>> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
>>>>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
>>>>> 
>>>>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
>>>>> 
>>>>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
>>>>> 
>>>>> 
>>>>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
>>>>>> 
>>>>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
>>>>> 
>>>>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
>>>>> 
>>>>> 
>>>>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
>>>>>> 
>>>>> 
>>>>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
>>>>> 
>>>>> 
>>>>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
>>>>>> 
>>>>> 
>>>>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
>>>>> 
>>>>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
>>>>> 
>>>>> That's just my $0.02, though ...
>>>>> 
>>>>> Cheers,
>>>>> Simon
>>>>> 
>>>>> 
>>>>>> 
>>>>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
>>>>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
>>>>>>> 
>>>>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
>>>>>>>> 
>>>>>>> 
>>>>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
>>>>>>> 
>>>>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
>>>>>>> 
>>>>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
>>>>>>> 
>>>>>>> and then use something like
>>>>>>> 
>>>>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
>>>>>>> 
>>>>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> Simon
>>>>>>> 
>>>>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
>>>>>>> 
>>>>>>> 
>>>>>>>> In base::connections documentation, it's not clear if there's an easy
>>>>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
>>>>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
>>>>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
>>>>>>>> mind I have the thought of trying to redirect /dev/something to a
>>>>>>>> file, or symlinking a file to point to the hardware, but know that
>>>>>>>> there has to be some secret sauce to go from streaming in to a
>>>>>>>> readable file, but don't know what the missing components are).
>>>>>>>> 
>>>>>>>> Thoughts?
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at bht-berlin.de  Mon Apr 26 20:48:15 2010
From: groemping at bht-berlin.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Mon, 26 Apr 2010 20:48:15 +0200
Subject: [Rd] Bug in calculation of overdispersion for quasibinomial grouped
 data ?
Message-ID: <4BD5DFEF.2030505@bht-berlin.de>

Dear list,

in preparing a lecture, I have created an example for the same data in 
grouped and ungrouped form (the well-known Titanic data). The code 
included below shows that the overdispersion estimates are strongly 
different for the two approaches.
If the overdispersion parameter FI is seen as a multiplyer for the 
variance, the estimate should the same from grouped and ungrouped data, 
as far as I can see. With the typical pearson residual approach to 
estimating FI and a mean response modeled with number of trials given in 
weights, this is not the case. The function overdisp.weighted below 
shows how estimation of overdispersion would have to be modified 
(intended for demonstrating the formula, not the programming) in a 
quasibinomial model with grouped data in order to yield the same 
estimate (up to a slight difference, presumably for numerical reasons) 
as for the ungrouped model.

Best regards,
Ulrike

## the standard way of estimating FI
overdisp <- function(fit) sum(residuals(fit, 
type="pearson")^2)/fit$df.residual
## the proposed way of estimating FI for grouped data
overdisp.weighted <- function(fit){
       yi.mean <- fit$model[,1]
       fiti <- fitted(fit)
       ni <- weights(fit)
       dfr <- sum(ni)-(fit$df.null-fit$df.residual+1)
       (sum(residuals(fit, type="pearson")^2) + 
sum(ni*yi.mean*(1-yi.mean)/(fiti*(1-fiti))))/dfr
}

### grouped data
require(alr3)
titanic

### Individual data
require(epitools)
titanic.lang <- expand.table(Titanic)
head(titanic.lang)

### quasi-binomial logistic model for grouped data
gruppmod <- glm(Surv/N~Class+Age+Sex, family=quasibinomial,
    data=titanic, weights=N)
summary(gruppmod)
overdisp(gruppmod)
overdisp.weighted(gruppmod)

### quasi-binomial logistic model for individual data
indivmod <- glm(Survived~Class+Age+Sex, family=quasibinomial,
    data=titanic.lang)
summary(indivmod)
overdisp(indivmod)

-- 
***********************************************
* Ulrike Groemping                            *
* BHT Berlin - University of Applied Sciences *
***********************************************
* +49 (30) 39404863 (Home Office)             *
* +49 (30) 4504 5127 (BHT)                    *
***********************************************
* http://prof.tfh-berlin.de/groemping         *
* groemping at bht-berlin.de                     *


From kasperdanielhansen at gmail.com  Mon Apr 26 21:05:20 2010
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 26 Apr 2010 15:05:20 -0400
Subject: [Rd] 00LOCK and nfs
In-Reply-To: <l2kc0177e5a1004261054k3775628fyb6c1fd154707dd91@mail.gmail.com>
References: <s2le780c0971004260815we5156859v293d5b3a6ffd9890@mail.gmail.com>
	<l2kc0177e5a1004261054k3775628fyb6c1fd154707dd91@mail.gmail.com>
Message-ID: <y2le780c0971004261205i39f069dt379690211f8f8a7f@mail.gmail.com>

2010/4/26 Christian Brechb?hler <brechbuehler at gmail.com>:
>
>
> On Mon, Apr 26, 2010 at 11:15 AM, Kasper Daniel Hansen
> <kasperdanielhansen at gmail.com> wrote:
>>
>> I am running into a problem with the 00LOCK file and .nfs files. ?It
>> seemed to be caused by the following
>> ?R is installed on NFS
>> ?user A has loaded pkg_A containing a dynamically loaded library
>> ?user B (the administrator) runs install.packages("pkg_A")
>> ?as the final part of the installation process the 00LOCK directory is
>> removed
>> ?this creates a .nfs file because user A has the dynamic library open
>> ?this .nfs file cannot be removed until user A exits R
>> ?because of this, 00LOCK cannot be removed, and if the
>> install.packages call is going to install packages after pkg_A, they
>> fail
>
> Yup, I've seen that.? The program "lsof" can be useful to find which process
> has the library open.
> User A does not need to exit R; it's enough to detach(package:pkg_A);
> library(pkg_A);.

I have now done more careful experimentation with a colleague so I
have more than 1 user, and my earlier description was wrong.  I can
reliably trigger this 00LOCK problem if a single user does
library(pkg_A) and then in a separate R session does
install.packages(pkg_A).

I cannot reliable trigger it if
1) the library() and install.packages() were done by the same user,
but on different nodes
2) the library() and install.packages() were done by different users, same node
3) the library() and install.packages() were done by different users,
different nodes

I believe I have run into this problem with 00LOCK when I only had one
R session running (the one doing the install.packages), so I am
beginning to believe that what I seem to run into is a race problem.
But I could of course be wrong.

Kasper


From edd at debian.org  Mon Apr 26 22:27:29 2010
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 26 Apr 2010 15:27:29 -0500
Subject: [Rd] R and the Google Summer of Code 2010 -- Please welcome our new
	students!
Message-ID: <19413.63281.305534.617889@ron.nulle.part>


Earlier today Google finalised student / mentor pairings and allocations for
the Google Summer of Code 2010 (GSoC 2010).  The R Project is happy to
announce that the following students have been accepted:

   Colin Rundel, "rgeos - an R wrapper for GEOS", mentored by Roger Bivand of
      the Norges Handelshoyskole, Norway

   Ian Fellows, "A GUI for Graphics using ggplot2 and Deducer", mentored by
      Hadley Wickham of Rice University, USA

   Chidambaram Annamalai, "rdx - Automatic Differentiation in R", mentored by
      John Nash of University of Ottawa, Canada

   Yasuhisa Yoshida, "NoSQL interface for R", mentored by Dirk Eddelbuettel,
      Chicago, USA

   Felix Schoenbrodt, "Social Relations Analyses in R", mentored by Stefan
      Schmukle, Universitaet Muenster, Germany

   Details about all proposals are on the R Wiki page for the GSoC 2010 at
   http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2010

The R Project is honoured to have received its highest number of student
allocations yet, and looks forward to an exciting Summer of Code.  Please
join me in welcoming our new students.

At this time, I would also like to thank all the other students who have
applied for working with R in this Summer of Code. With a limited number of
available slots, not all proposals can be accepted -- but I hope that those
not lucky enough to have been granted a slot will continue to work with R and
towards making contributions within the R world. 

I would also like to express my thanks to all other mentors who provided for
a record number of proposals.  Without mentors and their project ideas we
would not have a Summer of Code -- so hopefully we will see you again next
year. 

   Regards,  

   Dirk (acting as R/GSoC 2010 admin)


-- 
  Regards, Dirk


From groemping at bht-berlin.de  Mon Apr 26 22:36:13 2010
From: groemping at bht-berlin.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Mon, 26 Apr 2010 22:36:13 +0200
Subject: [Rd] Bug in calculation of overdispersion for quasibinomial
	grouped
Message-ID: <4BD5F93D.2050201@bht-berlin.de>

A quick addition:

SAS PROC LOGISTIC with option SCALE=PEARSON only calculates what R 
calculates in the grouped version; this is forced by refusing to 
calculate a FI estimate for ungrouped data, unless an AGGREGATE option 
is specified.

Apparently, SAS has decided for one model (not the one I am most 
familiar with), while the R version makes the model decision depend on 
the format of the data. As the family in glm is called quasibinomial, I 
would have expected it to conduct the adhoc adjustment.

Best, Ulrike

-- 
***********************************************
* Ulrike Groemping                            *
* BHT Berlin - University of Applied Sciences *
***********************************************
* +49 (30) 39404863 (Home Office)             *
* +49 (30) 4504 5127 (BHT)                    *
***********************************************
* http://prof.tfh-berlin.de/groemping         *
* groemping at bht-berlin.de                     *


From cbrown at opendatagroup.com  Tue Apr 27 00:58:00 2010
From: cbrown at opendatagroup.com (Christopher Brown)
Date: Mon, 26 Apr 2010 15:58:00 -0700
Subject: [Rd] S4 Inheritance of environments
In-Reply-To: <4BD4C47E.3020401@r-project.org>
References: <g2j5832a2d11004241015u7087d1ecye95136b7b178b236@mail.gmail.com>
	<4BD4C47E.3020401@r-project.org>
Message-ID: <h2n5832a2d11004261558z9dbcf56qacf2d0431572336a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100426/a647eeaa/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Apr 27 13:08:47 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 27 Apr 2010 13:08:47 +0200
Subject: [Rd] Miktex does not work with R CMD check
In-Reply-To: <4BD47497.2080203@bht-berlin.de>
References: <4BD47497.2080203@bht-berlin.de>
Message-ID: <4BD6C5BF.5080606@statistik.tu-dortmund.de>

Ulrike,

I just upgraded to the full MikTeX 2.8 distribution from today (still on 
2.7 before) and checking my tuneR package worked fine.
Hence  Which package are you referring to?

Best wishes,
Uwe


On 25.04.2010 18:57, Ulrike Gr?mping wrote:
> Dear DevelopeRs,
>
> the issue I am stuck with (I am on Windows, R-2.11): My Miktex (version
> 2.8) does not work with R CMD check, although Miktex on its own can
> pdflatex the tex-file in the Rcheck directory. (This issue has been
> going on for a while, and now, after having updated to R-2.11, I finally
> want to get it fixed.) Although I have found several similar posts, none
> of the answers appears to solve my problem, which seems to be
> path-related. In case it is relevant: in the past, I did have issues
> with paths to "my documents" because these contain a German Umlaut on my
> computer, which is why I moved all R packages to the directory c:/rtests.
>
> I would appreciate any help on this issue. The relevant portion of R CMD
> check and the content of Rdlatex.log are included below.
>
> Best regards,
> Ulrike
>
> The end of the R CMD check output looks like this:
>
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> * checking PDF version of manual without index ... ERROR
> LaTeX error when running command:
> Rcmd.exe Rd2dvi --batch --no-preview --pdf
> --build-dir=C:/WINDOWS/Temp/Rd2dvi611638299 --no-clean --no-index -o
> DoE.base-manual.pdf >/dev/null 2>&1 C:/rtests/DoE.base.Rcheck/DoE.base
> Re-running with no redirection of stdout/stderr.
>
> The file Rdlatex.log contains the following text:
>
> Hmm ... looks like a package
> latex.exe: A required file system path could not be retrieved.
> latex.exe: Data: 28
> Creating pdf output from LaTeX ...
> pdflatex.exe: A required file system path could not be retrieved.
> pdflatex.exe: Data: 28
> Error in running pdflatex command ('pdflatex')
> You may want to clean up by 'rm -rf C:/WINDOWS/Temp/Rd2dvi611638299'
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at bht-berlin.de  Tue Apr 27 13:51:29 2010
From: groemping at bht-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Tue, 27 Apr 2010 13:51:29 +0200
Subject: [Rd] Miktex does not work with R CMD check
In-Reply-To: <4BD6C5BF.5080606@statistik.tu-dortmund.de>
References: <4BD47497.2080203@bht-berlin.de>
	<4BD6C5BF.5080606@statistik.tu-dortmund.de>
Message-ID: <4BD6CFC1.8060408@bht-berlin.de>

Uwe,

I think it must be some problem on my computer, it happens for all my 
packages in R CMD check. I don't use TeX for anything else (if I can 
avoid it), therefore it might be something stupid that a regular 
TeX-user would never think about. However, it can't be a completely 
wrong setup of MikTeX, since direct application of pdflatex to 
pkg-manual.tex works without problems.

Best regards,
Ulrike

Uwe Ligges schrieb:
> Ulrike,
>
> I just upgraded to the full MikTeX 2.8 distribution from today (still 
> on 2.7 before) and checking my tuneR package worked fine.
> Hence  Which package are you referring to?
>
> Best wishes,
> Uwe
>
>
> On 25.04.2010 18:57, Ulrike Gr?mping wrote:
>> Dear DevelopeRs,
>>
>> the issue I am stuck with (I am on Windows, R-2.11): My Miktex (version
>> 2.8) does not work with R CMD check, although Miktex on its own can
>> pdflatex the tex-file in the Rcheck directory. (This issue has been
>> going on for a while, and now, after having updated to R-2.11, I finally
>> want to get it fixed.) Although I have found several similar posts, none
>> of the answers appears to solve my problem, which seems to be
>> path-related. In case it is relevant: in the past, I did have issues
>> with paths to "my documents" because these contain a German Umlaut on my
>> computer, which is why I moved all R packages to the directory 
>> c:/rtests.
>>
>> I would appreciate any help on this issue. The relevant portion of R CMD
>> check and the content of Rdlatex.log are included below.
>>
>> Best regards,
>> Ulrike
>>
>> The end of the R CMD check output looks like this:
>>
>> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
>> This typically indicates Rd problems.
>> * checking PDF version of manual without index ... ERROR
>> LaTeX error when running command:
>> Rcmd.exe Rd2dvi --batch --no-preview --pdf
>> --build-dir=C:/WINDOWS/Temp/Rd2dvi611638299 --no-clean --no-index -o
>> DoE.base-manual.pdf >/dev/null 2>&1 C:/rtests/DoE.base.Rcheck/DoE.base
>> Re-running with no redirection of stdout/stderr.
>>
>> The file Rdlatex.log contains the following text:
>>
>> Hmm ... looks like a package
>> latex.exe: A required file system path could not be retrieved.
>> latex.exe: Data: 28
>> Creating pdf output from LaTeX ...
>> pdflatex.exe: A required file system path could not be retrieved.
>> pdflatex.exe: Data: 28
>> Error in running pdflatex command ('pdflatex')
>> You may want to clean up by 'rm -rf C:/WINDOWS/Temp/Rd2dvi611638299'
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From shotwelm at musc.edu  Tue Apr 27 14:32:59 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Tue, 27 Apr 2010 08:32:59 -0400
Subject: [Rd] serial connection patch
In-Reply-To: <7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
	<1272299283.3901.57.camel@deacon>
	<7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>
Message-ID: <1272371579.4721.35.camel@deacon>

Simon, 

Thanks for reviewing it! All the modified files are under the GPL
version 2 (except the configure script). According to the GPLv2, I am
granted permission to modify and redistribute the code as long as I make
a notice in the files of their modification and the date (which I have
not done yet). As I understand (I'm not lawyer), the copyright is
necessary for, and does not alter the terms of the GPLv2. Is there
something specific you're thinking of that invalidates this?

I updated the patch to open with O_NOCTTY to prevent opening the tty as
the controlling terminal. Looks like this is default in BSD and GNU but
maybe not in OS X. I'd like to hear how it goes if you try it again. 

I see the rationale for a tty (in scope) connection. As you observed,
there are lots of options. However, some of them are designed to be used
when the terminal IS the controlling terminal, for example, if you were
writing a program like getty, so barring the use of R as a job control
shell (which would be cool also, but probably not in the scope of R),
some of the options need not be exposed. For instance, canonical mode
may never be necessary/appropriate. But it would be cool to use RTS/CTS,
XON/XOFF, blocking, and some of the other stuff that is not there yet. I
have some ideas on how to expose these features concisely.

I'll continue to work on this as time permits (i.e. probably at
weekend), with consideration for your suggestions. Thanks again,

-Matt



On Mon, 2010-04-26 at 14:18 -0400, Simon Urbanek wrote: 
> Matt,
> 
> thanks for you efforts. We cannot directly use your patch due to licensing issues (please note the licenses in the files you are modifying - I don't think anyone can currently use the patch and redistribute the resulting R; also/or we may possibly need to clarify that the work is either done on behalf of the R-foundation or the copyright is assigned to R-foundation or something similar so future licensing issues can be solved by the Foundation since that is the copyright holder of most of R).
> 
> Apart from that, the overall structure looks good, but the devil is in the details. It does not quite work for me on OS X (any read/writes just hang in the same way that it would if you used a file connection on the tty device) - I don't think it is as simple (AFAIR you have to make sure you open it such that it doesn't become the controlling terminal). Also it would definitely need "blocking" argument like most other connections have.
> 
> In general I don't think serial is the right name (and scope) here - what we're really looking for a is a tty connection (and serial just an application of it). What you have so far is a file connection with setserial functionality on it - and I think that may be more easily done by really using setserial on the already implemented file connection. The difference with tty is the other parts such as flow control, modes etc. It's much more work to expose those, but I think that is what the direction would be. In fact it could well be that tty is simply file connection + termio so you don't have to re-invent the wheel (under the hood). Also that would give you many aspects for free since you could inherit from file at the R level.
> 
> I hope it helps. I was thinking about the above but in the end decided to back off once I was looking at the flood of parameters you have to take care of in tty. But it would be nice if someone did that ;).
> 
> Cheers,
> Simon
> 
> 
> On Apr 26, 2010, at 12:28 PM, Matt Shotwell wrote:
> 
> > All,
> >
> > Our discussion of serial interfaces last week motivated me to dig into
> > the R connections API. In short, I spent the weekend writing a patch for
> > version 2.11.0 that adds a serial connection. I posted a blog entry that
> > gives instructions for applying, configuring, and compiling the patched
> > version <http://biostatmatt.com/archives/112>.
> >
> > The patch currently only enables a serial connection for POSIX compliant
> > OSs. It should NOT be considered well tested, though I feel it is fairly
> > safe. I would really like to hear from someone who can try it on Mac OS
> > X (and Windows to ensure that it has the correct 'null' behavior).
> >
> > Briefly, the connection utilizes (and checks for) the termios.h header.
> > I opted not to extend the 'file' connection in a manner similar to the
> > 'pipe' connection because this might not be suitable under Win32. Hence,
> > there are new read, write, flush, open, and close methods and a struct
> > serialconn for the serial connection. Opens are non-blocking and binary
> > only. Serial parameters can be passed when the connection is created. I
> > overloaded the summary method in order for the user to see the serial
> > settings.
> >
> > I've done my best to be consistent and conforming with the connections
> > API and coding style. However, I would be great if someone with more
> > experience with the R API (Simon? :)) would take a critical look at the
> > design and coding of the new connection. If this is something that the R
> > community would like to pursue, I'd like to work on support for Windows
> > serial interfaces. Below is a link to the patch file and the output of
> > diffstat.
> >
> > <http://biostatmatt.com/R/R-2.11.0-serial.patch>
> >
> >
> > file                                |  mod    ins     del
> > ------------------------------------------------------------
> > configure.ac                        |    2    1 +     1 -
> > src/include/Internal.h              |    2    2 +     0 -
> > src/library/base/R/connections.R    |   10    10 +    0 -
> > src/library/base/man/connections.Rd |   60    49 +    11 -
> > src/main/connections.c              |  379    379 +   0 -
> > src/main/names.c                    |    2    2 +     0 -
> >
> >
> > P.S. connections.c is the largest file in src/main/, before and after
> > the patch. Making the 379 additions increased the file size by 6.9%
> > (10.7kB). Adding Windows support should increase the file size by a
> > lesser amount.
> >
> > -Matt
> >
> > On Wed, 2010-04-21 at 08:07 -0400, Simon Urbanek wrote:
> >> Philippe,
> >>
> >> unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.
> >>
> >> I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).
> >>
> >> Cheers,
> >> Simon
> >>
> >>
> >>
> >> On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:
> >>
> >>> There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
> >>>
> >>> Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
> >>>
> >>> It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
> >>>
> >>> require(tcltk)
> >>> .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
> >>>
> >>> # There are many config parameters available here... just an example
> >>> .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
> >>>
> >>> # Send a command to your device through the serial port
> >>> .Tcl('puts -nonewline $R_com1 {my_cmd}')
> >>>
> >>> # Read a line of text from the serial port
> >>> line <- tclvalue(.Tcl('gets $R_com1'))
> >>>
> >>> With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
> >>>
> >>> .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
> >>>
> >>> Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
> >>>
> >>> In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
> >>>
> >>> All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
> >>>
> >>> If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
> >>>
> >>> Best,
> >>>
> >>> Philippe
> >>> ..............................................<?}))><........
> >>> ) ) ) ) )
> >>> ( ( ( ( (    Prof. Philippe Grosjean
> >>> ) ) ) ) )
> >>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
> >>> ) ) ) ) )   Mons University, Belgium
> >>> ( ( ( ( (
> >>> ..............................................................
> >>>
> >>> On 21/04/10 03:17, shotwelm wrote:
> >>>> Simon is right of course, there are plenty of sensors that would work
> >>>> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
> >>>> theorem along these lines (Nyquist sampling theorem?). I think piping
> >>>> the output to R is a clever solution. I added a few lines to the ttys.c
> >>>> program so that the baud rate is a command line option (i.e. -B9600)
> >>>> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
> >>>> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
> >>>> addictive!
> >>>>
> >>>> For an ioctl package, I was originally thinking of using file
> >>>> descriptors directly. However, I agree this feels like subverting what
> >>>> could be an extension of the connections API. Given that "everything is
> >>>> a file" in POSIX systems, there may be an argument for an ioctl package
> >>>> that is independent of the connections implementation, say to do things
> >>>> that connections were not designed to do. For example, interfacing with
> >>>> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
> >>>> read or write calls. But maybe it would just be better to pipe this type
> >>>> of output to R also...
> >>>>
> >>>> -Matt
> >>>>
> >>>> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
> >>>>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
> >>>>>
> >>>>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
> >>>>>
> >>>>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
> >>>>>
> >>>>>
> >>>>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
> >>>>>>
> >>>>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
> >>>>>
> >>>>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
> >>>>>
> >>>>>
> >>>>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
> >>>>>>
> >>>>>
> >>>>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
> >>>>>
> >>>>>
> >>>>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
> >>>>>>
> >>>>>
> >>>>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
> >>>>>
> >>>>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
> >>>>>
> >>>>> That's just my $0.02, though ...
> >>>>>
> >>>>> Cheers,
> >>>>> Simon
> >>>>>
> >>>>>
> >>>>>>
> >>>>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
> >>>>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
> >>>>>>>
> >>>>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> >>>>>>>>
> >>>>>>>
> >>>>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
> >>>>>>>
> >>>>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
> >>>>>>>
> >>>>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
> >>>>>>>
> >>>>>>> and then use something like
> >>>>>>>
> >>>>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
> >>>>>>>
> >>>>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
> >>>>>>>
> >>>>>>> Cheers,
> >>>>>>> Simon
> >>>>>>>
> >>>>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
> >>>>>>>
> >>>>>>>
> >>>>>>>> In base::connections documentation, it's not clear if there's an easy
> >>>>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> >>>>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
> >>>>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
> >>>>>>>> mind I have the thought of trying to redirect /dev/something to a
> >>>>>>>> file, or symlinking a file to point to the hardware, but know that
> >>>>>>>> there has to be some secret sauce to go from streaming in to a
> >>>>>>>> readable file, but don't know what the missing components are).
> >>>>>>>>
> >>>>>>>> Thoughts?
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-devel at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>>>
> >>>>>>>>
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-devel at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>
> >>>>>>
> >>>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>>
> >>>
> >>>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Apr 27 14:42:42 2010
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Apr 2010 08:42:42 -0400
Subject: [Rd] serial connection patch
In-Reply-To: <1272371579.4721.35.camel@deacon>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>	<1271778684.14629.19.camel@deacon>	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>	<1271812624.4569.69.camel@deacon>
	<4BCED3CF.3070309@sciviews.org>	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>	<1272299283.3901.57.camel@deacon>	<7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>
	<1272371579.4721.35.camel@deacon>
Message-ID: <4BD6DBC2.7040405@gmail.com>

On 27/04/2010 8:32 AM, Matt Shotwell wrote:
> Simon, 
>
> Thanks for reviewing it! All the modified files are under the GPL
> version 2 (except the configure script). According to the GPLv2, I am
> granted permission to modify and redistribute the code as long as I make
> a notice in the files of their modification and the date (which I have
> not done yet). As I understand (I'm not lawyer), the copyright is
> necessary for, and does not alter the terms of the GPLv2. Is there
> something specific you're thinking of that invalidates this?
>   

I don't know what Simon noticed, but I saw that you had indicated a GPL 
v3 license on the web page.  GPL2 is not compatible with GPL3, so that 
makes your contribution unusable by us.

Duncan Murdoch

> I updated the patch to open with O_NOCTTY to prevent opening the tty as
> the controlling terminal. Looks like this is default in BSD and GNU but
> maybe not in OS X. I'd like to hear how it goes if you try it again. 
>
> I see the rationale for a tty (in scope) connection. As you observed,
> there are lots of options. However, some of them are designed to be used
> when the terminal IS the controlling terminal, for example, if you were
> writing a program like getty, so barring the use of R as a job control
> shell (which would be cool also, but probably not in the scope of R),
> some of the options need not be exposed. For instance, canonical mode
> may never be necessary/appropriate. But it would be cool to use RTS/CTS,
> XON/XOFF, blocking, and some of the other stuff that is not there yet. I
> have some ideas on how to expose these features concisely.
>
> I'll continue to work on this as time permits (i.e. probably at
> weekend), with consideration for your suggestions. Thanks again,
>
> -Matt
>
>
>
> On Mon, 2010-04-26 at 14:18 -0400, Simon Urbanek wrote: 
> > Matt,
> > 
> > thanks for you efforts. We cannot directly use your patch due to licensing issues (please note the licenses in the files you are modifying - I don't think anyone can currently use the patch and redistribute the resulting R; also/or we may possibly need to clarify that the work is either done on behalf of the R-foundation or the copyright is assigned to R-foundation or something similar so future licensing issues can be solved by the Foundation since that is the copyright holder of most of R).
> > 
> > Apart from that, the overall structure looks good, but the devil is in the details. It does not quite work for me on OS X (any read/writes just hang in the same way that it would if you used a file connection on the tty device) - I don't think it is as simple (AFAIR you have to make sure you open it such that it doesn't become the controlling terminal). Also it would definitely need "blocking" argument like most other connections have.
> > 
> > In general I don't think serial is the right name (and scope) here - what we're really looking for a is a tty connection (and serial just an application of it). What you have so far is a file connection with setserial functionality on it - and I think that may be more easily done by really using setserial on the already implemented file connection. The difference with tty is the other parts such as flow control, modes etc. It's much more work to expose those, but I think that is what the direction would be. In fact it could well be that tty is simply file connection + termio so you don't have to re-invent the wheel (under the hood). Also that would give you many aspects for free since you could inherit from file at the R level.
> > 
> > I hope it helps. I was thinking about the above but in the end decided to back off once I was looking at the flood of parameters you have to take care of in tty. But it would be nice if someone did that ;).
> > 
> > Cheers,
> > Simon
> > 
> > 
> > On Apr 26, 2010, at 12:28 PM, Matt Shotwell wrote:
> > 
> > > All,
> > >
> > > Our discussion of serial interfaces last week motivated me to dig into
> > > the R connections API. In short, I spent the weekend writing a patch for
> > > version 2.11.0 that adds a serial connection. I posted a blog entry that
> > > gives instructions for applying, configuring, and compiling the patched
> > > version <http://biostatmatt.com/archives/112>.
> > >
> > > The patch currently only enables a serial connection for POSIX compliant
> > > OSs. It should NOT be considered well tested, though I feel it is fairly
> > > safe. I would really like to hear from someone who can try it on Mac OS
> > > X (and Windows to ensure that it has the correct 'null' behavior).
> > >
> > > Briefly, the connection utilizes (and checks for) the termios.h header.
> > > I opted not to extend the 'file' connection in a manner similar to the
> > > 'pipe' connection because this might not be suitable under Win32. Hence,
> > > there are new read, write, flush, open, and close methods and a struct
> > > serialconn for the serial connection. Opens are non-blocking and binary
> > > only. Serial parameters can be passed when the connection is created. I
> > > overloaded the summary method in order for the user to see the serial
> > > settings.
> > >
> > > I've done my best to be consistent and conforming with the connections
> > > API and coding style. However, I would be great if someone with more
> > > experience with the R API (Simon? :)) would take a critical look at the
> > > design and coding of the new connection. If this is something that the R
> > > community would like to pursue, I'd like to work on support for Windows
> > > serial interfaces. Below is a link to the patch file and the output of
> > > diffstat.
> > >
> > > <http://biostatmatt.com/R/R-2.11.0-serial.patch>
> > >
> > >
> > > file                                |  mod    ins     del
> > > ------------------------------------------------------------
> > > configure.ac                        |    2    1 +     1 -
> > > src/include/Internal.h              |    2    2 +     0 -
> > > src/library/base/R/connections.R    |   10    10 +    0 -
> > > src/library/base/man/connections.Rd |   60    49 +    11 -
> > > src/main/connections.c              |  379    379 +   0 -
> > > src/main/names.c                    |    2    2 +     0 -
> > >
> > >
> > > P.S. connections.c is the largest file in src/main/, before and after
> > > the patch. Making the 379 additions increased the file size by 6.9%
> > > (10.7kB). Adding Windows support should increase the file size by a
> > > lesser amount.
> > >
> > > -Matt
> > >
> > > On Wed, 2010-04-21 at 08:07 -0400, Simon Urbanek wrote:
> > >> Philippe,
> > >>
> > >> unfortunately that approach has one major drawback - it does not give you a connection. As I said in the previous e-mail it is fairly easy to talk to a tty directly, but the challenge is to turn it into a connection. I don't like the Tcl approach for several reasons, one of them being that it's entirely unnatural since you have to construct strings of code -- you could as well use rJava and Java serial connections which has a little more friendly syntax (but I wouldn't recommend that, either) or any other language R interfaces to.
> > >>
> > >> I was thinking about it a bit and I may be tempted to have a dab at a tty connection, but I still would not want to mess with ioctl (the other part Matt mentioned).
> > >>
> > >> Cheers,
> > >> Simon
> > >>
> > >>
> > >>
> > >> On Apr 21, 2010, at 6:30 AM, Philippe Grosjean wrote:
> > >>
> > >>> There is another option I use since a couple of years to pilot scientific devices, to program my chemostats, etc. and that is platform-independent: Tcl.
> > >>>
> > >>> Tcl i/o design is excellent and very robust, and Tcl/Tk is integrated in R with the tcltk package.
> > >>>
> > >>> It is really just a mather of a few lines of code in R to communicate through a serial port from R using Tcl. Something like:
> > >>>
> > >>> require(tcltk)
> > >>> .Tcl('set R_com1 [open "com1" r+]') # Works on Windows too!
> > >>>
> > >>> # There are many config parameters available here... just an example
> > >>> .Tcl('fconfigure $R_com1 -mode "9600,n,8,1" -buffering none -blocking 0')
> > >>>
> > >>> # Send a command to your device through the serial port
> > >>> .Tcl('puts -nonewline $R_com1 {my_cmd}')
> > >>>
> > >>> # Read a line of text from the serial port
> > >>> line <- tclvalue(.Tcl('gets $R_com1'))
> > >>>
> > >>> With a little bit more code, one can program Tcl to call R code automatically everytime new data is pushed by the connected device through the serial port. This is done using something like:
> > >>>
> > >>> .Tcl('fileevent $R_com1 readable [list Handler_com1 $R_com1]')
> > >>>
> > >>> Here, "Handler_com1" is a Tcl function. So, some care must be taken using tcltk's .Tcl.callback() to trigger the event on the R side. One way to deal with this easily is by using tclFun() from the tcltk2 package.
> > >>>
> > >>> In tcltk2, there is also ?tclTaskSchedule that can be of interest in the context of serial port communication to trigger a R function in the background regularly and collect data actively from the serial port.
> > >>>
> > >>> All these tools give me a lot a flexibility to communicate through the serial port from R,... and most importantly, to write my code in a portable way (tested on Windows XP and Linux Ubuntu).
> > >>>
> > >>> If there is some interest in this approach, I could initiate a 'tclcom' R package on R-Forge and place there the code I have.
> > >>>
> > >>> Best,
> > >>>
> > >>> Philippe
> > >>> ..............................................<?}))><........
> > >>> ) ) ) ) )
> > >>> ( ( ( ( (    Prof. Philippe Grosjean
> > >>> ) ) ) ) )
> > >>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
> > >>> ) ) ) ) )   Mons University, Belgium
> > >>> ( ( ( ( (
> > >>> ..............................................................
> > >>>
> > >>> On 21/04/10 03:17, shotwelm wrote:
> > >>>> Simon is right of course, there are plenty of sensors that would work
> > >>>> just fine at 9600 baud (like a thermistor rigged to an ADC). There's a
> > >>>> theorem along these lines (Nyquist sampling theorem?). I think piping
> > >>>> the output to R is a clever solution. I added a few lines to the ttys.c
> > >>>> program so that the baud rate is a command line option (i.e. -B9600)
> > >>>> <http://biostatmatt.com/temp/ttys.c>  and confirmed it will compile in
> > >>>> Linux (2.6.30). Maybe it will save a step. Microcontrollers really are
> > >>>> addictive!
> > >>>>
> > >>>> For an ioctl package, I was originally thinking of using file
> > >>>> descriptors directly. However, I agree this feels like subverting what
> > >>>> could be an extension of the connections API. Given that "everything is
> > >>>> a file" in POSIX systems, there may be an argument for an ioctl package
> > >>>> that is independent of the connections implementation, say to do things
> > >>>> that connections were not designed to do. For example, interfacing with
> > >>>> V4L2 devices usually involves many ioctl calls, an mmap call, but rarely
> > >>>> read or write calls. But maybe it would just be better to pipe this type
> > >>>> of output to R also...
> > >>>>
> > >>>> -Matt
> > >>>>
> > >>>> On Tue, 2010-04-20 at 16:42 -0400, Simon Urbanek wrote:
> > >>>>> On Apr 20, 2010, at 11:51 AM, shotwelm wrote:
> > >>>>>
> > >>>>>> I've done some microcontroller work over serial also. Unfortunately, interfacing with a serial port is system dependent, and the mechanisms can be quite different, as you probably know. It appears that Simon has a solution below that will work if you are willing to accept the default baud rate (9600 is way too slow for good sensor data
> > >>>>>
> > >>>>> [OT: define "good" ;) - good doesn't mean fast - besides it won't be any good if it is too fast to be meaningfully processed -- that's a different story, though :P - and it is trivial to change so the solution works in general]
> > >>>>>
> > >>>>>
> > >>>>>> ), parity, etc.. or use external tools. On POSIX systems, you would need access to the termios.h header and the system ioctl function in order to change these settings. Although I'm not 100% sure, I don't think R has this capability ... yet.
> > >>>>>>
> > >>>>>> I'm new to the list, but I'd be surprised if the R developers that have been around awhile haven't already considered adding support for ioctls and the POSIX terminal interface. This makes me wonder why it's not there. If there is no good reason, I'm starting to see a series of R packages (or core extensions) developing.
> > >>>>>
> > >>>>> Good luck ;). The issue is that connections are inherently backend-independent which implies that packages have no access to connection internals as they can change at any time. This means that you can't enhance them without putting the enhancements into R itself. This implies that you have to make a strong case since you need a volunteer in R-core to maintain that code etc.
> > >>>>>
> > >>>>>
> > >>>>>> With a package for ioctls, we could use all sorts of cool stuff, like Video4Linux2 (webcams, HAM radio, tuners)...
> > >>>>>>
> > >>>>>
> > >>>>> Ioctls are highly system-specific which is orthogonal to the design of connections. You could probably hack together a FD-based access system but it would not be compatible with connections (unless you exploit undocumented things if possible at all ...). Also ioctls can change the stream semantics entirely thus breaking anything that deals with the FD assuming some defined state ...
> > >>>>>
> > >>>>>
> > >>>>>> When I collect sensor data over serial, I do it in python or write a small C program to dump a single-column csv. Of course, R is excellent for digital signal processing after that. Check out the DSP ( http://biostatmatt.com/archives/78 ) I did in R with some ECG data I collected with an Atmel uC.
> > >>>>>>
> > >>>>>
> > >>>>> Well, we're back to calling tools to do the interfacing like the ttys (I do prefer pipe to intermediate files)... It's not that complicated and has several benefits (implicit parallelization, process separation in case things go wrong etc.) so it is not obvious that it's a bad thing ...
> > >>>>>
> > >>>>> I suspect that we're simply suck until the connection API is either exposed or re-written so packages can provide new connections types or extend existing one. Again, this is not trivial especially when you start messing with ioctl since it's easy to depart from defined behavior in that case ... That said, I agree that expanding connections is useful so some progress there would be desirable - but the "how" and "who" is not clear to me ...
> > >>>>>
> > >>>>> That's just my $0.02, though ...
> > >>>>>
> > >>>>> Cheers,
> > >>>>> Simon
> > >>>>>
> > >>>>>
> > >>>>>>
> > >>>>>> On Tue, 2010-04-20 at 11:05 -0400, Simon Urbanek wrote:
> > >>>>>>> On Apr 20, 2010, at 10:33 AM, Blair Christian wrote:
> > >>>>>>>
> > >>>>>>>> Does anybody know if there is any support to read from serial ports? I just got an arduino, and wanted to write some scripts for working with real time streaming sensor data...
> > >>>>>>>>
> > >>>>>>>
> > >>>>>>> Yes (I have Arduinos reporting measurements from all sensors in the house to R on my iMac which produces plots that are synchronized with my webserver). In principle you can simply use /dev/tty.usb... and read from it. In most cases the default setting is already fine (9600,n,8,1 on Mac) or you can use tools the set it up in advance (setserial on Linux etc.) so you don't have to worry about setting up the serial from R.
> > >>>>>>>
> > >>>>>>> Depending on your OS you may be able to read from the serial device directly with a regular file connection or you can use a pipe connection to a tool which pipes out from the tty to stdout (written for a Mac but may work on other unices):
> > >>>>>>>
> > >>>>>>> https://svn.rforge.net/C/trunk/tools/ttys.c
> > >>>>>>>
> > >>>>>>> and then use something like
> > >>>>>>>
> > >>>>>>> f=pipe("ttys /dev/tty.usbserial-X1234")
> > >>>>>>>
> > >>>>>>> A rather handy option -d prepends current time to each line so you can track output over time. I have some more tools for this (even allowing you to share form Arduino output with several computers or even send remote commands to your Arduino including encryption etc ...).
> > >>>>>>>
> > >>>>>>> Cheers,
> > >>>>>>> Simon
> > >>>>>>>
> > >>>>>>> PS: From experience I can say that Arduinos are highly addictive so beware ;).
> > >>>>>>>
> > >>>>>>>
> > >>>>>>>> In base::connections documentation, it's not clear if there's an easy
> > >>>>>>>> way to do this?  Any ideas on hacking it?  I'm open to win/linux/mac
> > >>>>>>>> solutions.  I'm not sure how sockets work, but possibly there is a way
> > >>>>>>>> to pipe things to a buffer and read from a buffer in bash (in my linux
> > >>>>>>>> mind I have the thought of trying to redirect /dev/something to a
> > >>>>>>>> file, or symlinking a file to point to the hardware, but know that
> > >>>>>>>> there has to be some secret sauce to go from streaming in to a
> > >>>>>>>> readable file, but don't know what the missing components are).
> > >>>>>>>>
> > >>>>>>>> Thoughts?
> > >>>>>>>>
> > >>>>>>>> ______________________________________________
> > >>>>>>>> R-devel at r-project.org mailing list
> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>
> > >>>>>>> ______________________________________________
> > >>>>>>> R-devel at r-project.org mailing list
> > >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-devel at r-project.org mailing list
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>>>>
> > >>>>>>
> > >>>>>
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-devel at r-project.org mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>>
> > >>>>
> > >>>
> > >>>
> > >>
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pd.mes at cbs.dk  Tue Apr 27 15:33:40 2010
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Tue, 27 Apr 2010 15:33:40 +0200
Subject: [Rd] serial connection patch
In-Reply-To: <4BD6DBC2.7040405@gmail.com>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
	<1272299283.3901.57.camel@deacon>
	<7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>
	<1272371579.4721.35.camel@deacon> <4BD6DBC2.7040405@gmail.com>
Message-ID: <DDC342F3-56B2-4199-95B0-CEFDC387F0A5@cbs.dk>


On Apr 27, 2010, at 2:42 PM, Duncan Murdoch wrote:

> On 27/04/2010 8:32 AM, Matt Shotwell wrote:
>> Simon, 
>> Thanks for reviewing it! All the modified files are under the GPL
>> version 2 (except the configure script). According to the GPLv2, I am
>> granted permission to modify and redistribute the code as long as I make
>> a notice in the files of their modification and the date (which I have
>> not done yet). As I understand (I'm not lawyer), the copyright is
>> necessary for, and does not alter the terms of the GPLv2. Is there
>> something specific you're thinking of that invalidates this?
>>  
> 
> I don't know what Simon noticed, but I saw that you had indicated a GPL v3 license on the web page.  GPL2 is not compatible with GPL3, so that makes your contribution unusable by us.

Yes, this is a bit messy, but some got sufficiently annoyed by the added restrictions of GPL3 that they insist on keeping their contributions GPL2, so adding GPL3-only stuff is off limits. 

I don't think we have a problem with merging user contributions that are licensed "GPL2 or later". A copyright transfer gives some legal clarification, but is only really required in case the R Foundation wants to (dual-) relicense under a GPL incompatible license, or need to be able to legally defend users' code against infringement. The former is highly unlikely, and it would require major disentanglement in other areas anyway, and I don't see contributions of this order of magnitude as a target of legal dispute either. 

> 
> Duncan Murdoch

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From shotwelm at musc.edu  Tue Apr 27 16:16:15 2010
From: shotwelm at musc.edu (Matt Shotwell)
Date: Tue, 27 Apr 2010 10:16:15 -0400
Subject: [Rd] serial connection patch
In-Reply-To: <DDC342F3-56B2-4199-95B0-CEFDC387F0A5@cbs.dk>
References: <u2i6c35a4fc1004200733rc5cbfamc721f1ea7409e008@mail.gmail.com>
	<F2253EB4-D23D-4694-B236-2406CA8D92B7@r-project.org>
	<1271778684.14629.19.camel@deacon>
	<121B27F2-8129-4599-9C97-A881EE25525E@r-project.org>
	<1271812624.4569.69.camel@deacon> <4BCED3CF.3070309@sciviews.org>
	<5CEA8415-2B0B-4B72-A3AD-FBB0F2473DC1@r-project.org>
	<1272299283.3901.57.camel@deacon>
	<7A7340FA-EA0E-4F98-9C08-A4B6358668F6@r-project.org>
	<1272371579.4721.35.camel@deacon> <4BD6DBC2.7040405@gmail.com>
	<DDC342F3-56B2-4199-95B0-CEFDC387F0A5@cbs.dk>
Message-ID: <1272377775.4721.54.camel@deacon>

Oh, I just put that there for the bit about "WITHOUT ANY WARRANTY" :). I
am satisfied with GPLv2 and have updated the license notice to reflect a
change from GPLv3 to GPLv2 or later.

-Matt

On Tue, 2010-04-27 at 09:33 -0400, Peter Dalgaard wrote:
> On Apr 27, 2010, at 2:42 PM, Duncan Murdoch wrote:
> 
> > On 27/04/2010 8:32 AM, Matt Shotwell wrote:
> >> Simon, 
> >> Thanks for reviewing it! All the modified files are under the GPL
> >> version 2 (except the configure script). According to the GPLv2, I am
> >> granted permission to modify and redistribute the code as long as I make
> >> a notice in the files of their modification and the date (which I have
> >> not done yet). As I understand (I'm not lawyer), the copyright is
> >> necessary for, and does not alter the terms of the GPLv2. Is there
> >> something specific you're thinking of that invalidates this?
> >>  
> > 
> > I don't know what Simon noticed, but I saw that you had indicated a GPL v3 license on the web page.  GPL2 is not compatible with GPL3, so that makes your contribution unusable by us.
> 
> Yes, this is a bit messy, but some got sufficiently annoyed by the added restrictions of GPL3 that they insist on keeping their contributions GPL2, so adding GPL3-only stuff is off limits. 
> 
> I don't think we have a problem with merging user contributions that are licensed "GPL2 or later". A copyright transfer gives some legal clarification, but is only really required in case the R Foundation wants to (dual-) relicense under a GPL incompatible license, or need to be able to legally defend users' code against infringement. The former is highly unlikely, and it would require major disentanglement in other areas anyway, and I don't see contributions of this order of magnitude as a target of legal dispute either. 
> 
> > 
> > Duncan Murdoch
>


From tplate at acm.org  Tue Apr 27 16:36:17 2010
From: tplate at acm.org (Tony Plate)
Date: Tue, 27 Apr 2010 08:36:17 -0600
Subject: [Rd] 00LOCK and nfs
In-Reply-To: <y2le780c0971004261205i39f069dt379690211f8f8a7f@mail.gmail.com>
References: <s2le780c0971004260815we5156859v293d5b3a6ffd9890@mail.gmail.com>	<l2kc0177e5a1004261054k3775628fyb6c1fd154707dd91@mail.gmail.com>
	<y2le780c0971004261205i39f069dt379690211f8f8a7f@mail.gmail.com>
Message-ID: <4BD6F661.10409@acm.org>

I have some tools and an R package that together provide a solution to 
the problem of updating an R package while it is attached in one or more 
running R sessions (whether on the same machine or not.)  The technique 
is to always create a new directory for the newly installed package, so 
that existing installed packages are never overwritten.  The tricky part 
is to manage this in a way that is transparent to the user, which is 
what the package accomplishes.  If this is any interest in this I could 
make it available; email me privately or respond on the list.

-- Tony Plate

On 4/26/2010 1:05 PM, Kasper Daniel Hansen wrote:
> 2010/4/26 Christian Brechb?hler<brechbuehler at gmail.com>:
>    
>>
>> On Mon, Apr 26, 2010 at 11:15 AM, Kasper Daniel Hansen
>> <kasperdanielhansen at gmail.com>  wrote:
>>      
>>> I am running into a problem with the 00LOCK file and .nfs files.  It
>>> seemed to be caused by the following
>>>   R is installed on NFS
>>>   user A has loaded pkg_A containing a dynamically loaded library
>>>   user B (the administrator) runs install.packages("pkg_A")
>>>   as the final part of the installation process the 00LOCK directory is
>>> removed
>>>   this creates a .nfs file because user A has the dynamic library open
>>>   this .nfs file cannot be removed until user A exits R
>>>   because of this, 00LOCK cannot be removed, and if the
>>> install.packages call is going to install packages after pkg_A, they
>>> fail
>>>        
>> Yup, I've seen that.  The program "lsof" can be useful to find which process
>> has the library open.
>> User A does not need to exit R; it's enough to detach(package:pkg_A);
>> library(pkg_A);.
>>      
> I have now done more careful experimentation with a colleague so I
> have more than 1 user, and my earlier description was wrong.  I can
> reliably trigger this 00LOCK problem if a single user does
> library(pkg_A) and then in a separate R session does
> install.packages(pkg_A).
>
> I cannot reliable trigger it if
> 1) the library() and install.packages() were done by the same user,
> but on different nodes
> 2) the library() and install.packages() were done by different users, same node
> 3) the library() and install.packages() were done by different users,
> different nodes
>
> I believe I have run into this problem with 00LOCK when I only had one
> R session running (the one doing the install.packages), so I am
> beginning to believe that what I seem to run into is a race problem.
> But I could of course be wrong.
>
> Kasper
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From Greg.Snow at imail.org  Tue Apr 27 18:54:13 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 27 Apr 2010 10:54:13 -0600
Subject: [Rd] Should mcnemar.test use as.factor instead of factor
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6335257C79@LP-EXMBVS10.CO.IHC.COM>

I am working with the mcnemar.test function and the help does not show a maintainer/author, but it is part of the stats package.

My issue is that I want to use the test on 2 variables with possible values of 0:3, in one of the tests one of the variables does not have any 3's, so to make sure that the matrix is square I do:

> x <- factor(x, levels=0:3)
> y <- factor(y, levels=0:3)

If I run mcnemar.test on the table of x and y then everything works fine, but if I pass in x and y without running table first then I get an error about both variables needing to have the same number of levels (which they did when I passed them in).  The problem occurs because the function when handed the raw data does its own conversion to factor using the factor function which drops the unused level in the one variable.  A simple fix should be to replace the call to factor with a call to as.factor (which will not change anything for variables that are already factors and therefore not drop levels).  I cannot imagine any code that would break from this change, but that could just be a lack of imagination on my part.

So, can anyone think of a reason not to change factor to as.factor?

Is this worth a bug report/enhancement request?



> sessionInfo()
R version 2.11.0 (2010-04-22) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.11.0

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


From marianagomez1976 at yahoo.com.ar  Tue Apr 27 19:38:32 2010
From: marianagomez1976 at yahoo.com.ar (Mariana Gomez)
Date: Tue, 27 Apr 2010 10:38:32 -0700 (PDT)
Subject: [Rd] Consulta
Message-ID: <539837.65099.qm@web34301.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100427/2061b1c8/attachment.pl>

From vaishanjur at gmail.com  Tue Apr 27 19:52:30 2010
From: vaishanjur at gmail.com (Vaish Anjur)
Date: Tue, 27 Apr 2010 10:52:30 -0700
Subject: [Rd] Unable to compile crc32_x86.S on windows (R-2.10.1).
Message-ID: <u2r987de8581004271052zbb3f0f18heb28d3a2ae7838d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100427/1730a7f6/attachment.pl>

From djsamperi at gmail.com  Tue Apr 27 22:16:05 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 27 Apr 2010 16:16:05 -0400
Subject: [Rd] Resolving functions using R's namespace mechanism can double
	runtime
Message-ID: <g2gd4cf43b61004271316p316d0d64ya9e53412b8a8df73@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100427/39ad739b/attachment.pl>

From seth at userprimary.net  Tue Apr 27 22:33:06 2010
From: seth at userprimary.net (Seth Falcon)
Date: Tue, 27 Apr 2010 13:33:06 -0700
Subject: [Rd] Resolving functions using R's namespace mechanism can
 double runtime
In-Reply-To: <g2gd4cf43b61004271316p316d0d64ya9e53412b8a8df73@mail.gmail.com>
References: <g2gd4cf43b61004271316p316d0d64ya9e53412b8a8df73@mail.gmail.com>
Message-ID: <4BD74A02.8080901@userprimary.net>

On 4/27/10 1:16 PM, Dominick Samperi wrote:
> It appears that the runtime for an R script can more than double if a few
> references to a function foo() are replaced by more explict references
> of the form pkgname::foo().
>
> The more explicit references are of course required when two
> loaded packages define the same function.
>
> I can understand why use of this mechanism is not free in an
> interpreted environment like R, but the cost seems rather high.

`::` is a function, so there is going to be overhead.  OTOH, there is no 
reason to pay for the lookup more than once.  For example at startup, 
you could do:

myfoo <- pkgname::foo

And then later call myfoo() and I don't think you will see the added cost.

You can formalize the above approach in package code by renaming 
function in the importFrom directive where I believe you can do:

importFrom(pkgname, myfoo=foo)


+ seth

-- 
Seth Falcon | @sfalcon | http://userprimary.net/


From romain at r-enthusiasts.com  Tue Apr 27 22:38:45 2010
From: romain at r-enthusiasts.com (Romain Francois)
Date: Tue, 27 Apr 2010 22:38:45 +0200
Subject: [Rd] Resolving functions using R's namespace mechanism can
 double runtime
In-Reply-To: <g2gd4cf43b61004271316p316d0d64ya9e53412b8a8df73@mail.gmail.com>
References: <g2gd4cf43b61004271316p316d0d64ya9e53412b8a8df73@mail.gmail.com>
Message-ID: <4BD74B55.7070004@r-enthusiasts.com>


Le 27/04/10 22:16, Dominick Samperi a ?crit :
> It appears that the runtime for an R script can more than double if a few
> references to a function foo() are replaced by more explict references
> of the form pkgname::foo().

It would probably help your question if you provide some benchmarks.

a::b is just a shortcut for `::`( a, b ).

> The more explicit references are of course required when two
> loaded packages define the same function.

Not really. You can :
- resolve once: my_foo <- pkgname::foo
- import the variable into your namespace using the importFrom namespace 
directive.

> I can understand why use of this mechanism is not free in an
> interpreted environment like R, but the cost seems rather high.
>
> Dominick

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/9aKDM9 : embed images in Rd documents
|- http://tr.im/OIXN : raster images and RImageJ
|- http://tr.im/OcQe : Rcpp 0.7.7


From kjetilbrinchmannhalvorsen at gmail.com  Wed Apr 28 00:45:58 2010
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Tue, 27 Apr 2010 18:45:58 -0400
Subject: [Rd] Consulta
In-Reply-To: <539837.65099.qm@web34301.mail.mud.yahoo.com>
References: <539837.65099.qm@web34301.mail.mud.yahoo.com>
Message-ID: <z2g556e90a81004271545ycb94d47o9735b69d0dec8c82@mail.gmail.com>

Mariana:

First, this post has nothing to do with future development of R, and
so should be sent to R-help, not R-devel.

Second, for questions in spanish you should consider the list R-help-es

kjetil

On Tue, Apr 27, 2010 at 1:38 PM, Mariana Gomez
<marianagomez1976 at yahoo.com.ar> wrote:
> Estoy escribiendo una funci?n en R para an?lisis de modelos lineales y tengo problemas al ejecutarla porque dicha funci?n usa otra funci?n, tambi?n creada por mi, y cuando ejecuto al primera me dice que no encuentra la segunda. Ambas funciones est?n guardadas en la carpeta work y al entrar al programa siempre cambio el directorio a work. No s? cual es el problema, si est? mal el search-path o es algo que me falta definir correctamente. Muchas gracias
>
> No s? si entienden espa?ol as? que a continuaci?n tratar? de explicar mi problema en ingl?s.
> Here is the same in english:
> I am writing a function
> ?in R for analysis of linear models and I have run into problems because
> ?the function uses another function, also created by me, and when I run
> the first the program said that can not found the second. Both features are stored in the work
> folder and wen I enter the program always change the directory to work. I do not know what the problem is, if the search-path
> is wrong or something I need to define properly. Thank you very much
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From russellkanderson at gmail.com  Wed Apr 28 06:01:10 2010
From: russellkanderson at gmail.com (rkanderson)
Date: Tue, 27 Apr 2010 21:01:10 -0700 (PDT)
Subject: [Rd] Recent examples of calling R from .net managed code
Message-ID: <1272427270992-2068586.post@n4.nabble.com>


Are there any recent examples of calling R from C#?.   The examples that I
have found are all using deprecated function.
-- 
View this message in context: http://r.789695.n4.nabble.com/Recent-examples-of-calling-R-from-net-managed-code-tp2068586p2068586.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Wed Apr 28 10:40:15 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Apr 2010 09:40:15 +0100 (BST)
Subject: [Rd] Unable to compile crc32_x86.S on windows (R-2.10.1).
In-Reply-To: <u2r987de8581004271052zbb3f0f18heb28d3a2ae7838d0@mail.gmail.com>
References: <u2r987de8581004271052zbb3f0f18heb28d3a2ae7838d0@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1004280935510.16237@gannet.stats.ox.ac.uk>

On Tue, 27 Apr 2010, Vaish Anjur wrote:

> Thank you for any pointers.

Learn what .S means?  For some reason you tried to compile .s*, and 
although that happens to match on your benighted OS, .s and .S are not 
the same.

I have no idea why you are asking here.  That file is not part of R 
and you have not told us where you found it.  There is a file of that 
name as part of a *copy of xzutils* shipped with the R sources, and R 
compiles it correctly: and you can read the sources for yourself to 
see how it does it.

>
> Windows XP
> **
> *# as -version
> GNU assembler (GNU Binutils) 2.19.1
> Copyright 2007 Free Software Foundation, Inc.
> This program is free software; you may redistribute it under the terms of
> the GNU General Public License version 3 or later.
> This program has absolutely no warranty.
> This assembler was configured for a target of `mingw32'.*
> **
> **
> *as   -o crc32_x86.o crc32_x86.s*
>
> crc32_x86.S: Assembler messages:
> crc32_x86.S:80: Warning: .type pseudo-op used outside of .def/.endef
> ignored.
> crc32_x86.S:80: Error: junk at end of line, first unrecognized character is
> `L'
> crc32_x86.S:83: Error: invalid character '(' in mnemonic
> crc32_x86.S:118: Error: junk at end of line, first unrecognized character is
> `|'
>
> crc32_x86.S:137: Error: invalid character '(' in mnemonic
> crc32_x86.S:160: Error: invalid character '(' in mnemonic
> crc32_x86.S:271: Error: invalid character '(' in mnemonic
> crc32_x86.S:279: Error: bad or irreducible absolute expression
> crc32_x86.S:279: Error: junk at end of line, first unrecognized character is
> `,'
>
> crc32_x86.S:281: Error: unknown pseudo-op: `.indirect_symbol'
> crc32_x86.S:293: Warning: .size pseudo-op used outside of .def/.endef
> ignored.
> crc32_x86.S:293: Error: junk at end of line, first unrecognized character is
> `L'
>
> crc32_x86.S:302: Error: junk at end of line, first unrecognized character is
> `-'
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 28 11:54:43 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Apr 2010 10:54:43 +0100 (BST)
Subject: [Rd] Should mcnemar.test use as.factor instead of factor
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6335257C79@LP-EXMBVS10.CO.IHC.COM>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6335257C79@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.00.1004281053110.32704@gannet.stats.ox.ac.uk>

On Tue, 27 Apr 2010, Greg Snow wrote:

> I am working with the mcnemar.test function and the help does not show a maintainer/author, but it is part of the stats package.
>
> My issue is that I want to use the test on 2 variables with possible 
> values of 0:3, in one of the tests one of the variables does not 
> have any 3's, so to make sure that the matrix is square I do:
>
>> x <- factor(x, levels=0:3)
>> y <- factor(y, levels=0:3)
>
> If I run mcnemar.test on the table of x and y then everything works fine, but if I pass in x and y without running table first then I get an error about both variables needing to have the same number of levels (which they did when I passed them in).  The problem occurs because the function when handed the raw data does its own conversion to factor using the factor function which drops the unused level in the one variable.  A simple fix should be to replace the call to factor with a call to as.factor (which will not change anything for variables that are already factors and therefore not drop levels).  I cannot imagine any code that would break from this change, but that could just be a lack of imagination on my part.
>
> So, can anyone think of a reason not to change factor to as.factor?

Given the description

   If \code{x} is a matrix, it is taken as a two-dimensional contingency
   table, and hence its entries should be nonnegative integers.
   Otherwise, both \code{x} and \code{y} must be vectors of the same
   length.  Incomplete cases are removed, the vectors are coerced into
   factor objects, and the contingency table is computed from these.

it should 'coerce'.

> Is this worth a bug report/enhancement request?

Not necessary, I'll change this in R-patched.  Thanks for pointing it 
out.

>
>
>
>> sessionInfo()
> R version 2.11.0 (2010-04-22)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.11.0
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murray.efford at otago.ac.nz  Wed Apr 28 14:12:48 2010
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Thu, 29 Apr 2010 00:12:48 +1200
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
Message-ID: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>

I construct a pdf package manual in Windows 7 using
R CMD Rd2dvi --pdf --no-preview [packagename]
Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.

I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
Murray Efford

From ripley at stats.ox.ac.uk  Wed Apr 28 14:29:33 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Apr 2010 13:29:33 +0100 (BST)
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
Message-ID: <alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>

Hmm, the construction of the PDF is done by pdlatex/hyperref, not by 
R.  What latex setup is this, and (guessing it is some version of 
MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our 
.tex file to PDF is managed entirely by texi2dvi.exe, and my guess is 
that it has done too few passes.  You should be able to verify that by 
using Rd2pdf --no-clean and running texi2dvi yourself on the saved 
.tex file.  Most likely running pdflatex on the .tex one more time 
will resolve this, so if you want to check texi2dvi.exe you would need 
to copy the .tex elsewhere.

(The less likely alternative is that this is managed by 
tools::texi2dvi and it is doing too few passes.)

If you have not already done so it would be worth checking that your 
latex setup is fully updated: latex package hyperref is involved and 
that is updated very frequently (more than weekly).

On Thu, 29 Apr 2010, Murray Efford wrote:

> I construct a pdf package manual in Windows 7 using
> R CMD Rd2dvi --pdf --no-preview [packagename]
> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>
> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
> Murray Efford
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murray.efford at otago.ac.nz  Wed Apr 28 14:54:07 2010
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Thu, 29 Apr 2010 00:54:07 +1200
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>,
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>
Message-ID: <E67251526203864DABCB7237DAC8EB2D904C8DA81E@MAIL2.registry.otago.ac.nz>

Many thanks. I'm using MiKTeX 2.8 which has texi2dvi.exe. I'll follow up on this when I can track down the tex file in the morning.
Murray

________________________________________
From: Prof Brian Ripley [ripley at stats.ox.ac.uk]
Sent: Thursday, 29 April 2010 12:29 a.m.
To: Murray Efford
Cc: r-devel at r-project.org
Subject: Re: [Rd] Rd2dvi pagination of index  in pdf manual

Hmm, the construction of the PDF is done by pdlatex/hyperref, not by
R.  What latex setup is this, and (guessing it is some version of
MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our
.tex file to PDF is managed entirely by texi2dvi.exe, and my guess is
that it has done too few passes.  You should be able to verify that by
using Rd2pdf --no-clean and running texi2dvi yourself on the saved
.tex file.  Most likely running pdflatex on the .tex one more time
will resolve this, so if you want to check texi2dvi.exe you would need
to copy the .tex elsewhere.

(The less likely alternative is that this is managed by
tools::texi2dvi and it is doing too few passes.)

If you have not already done so it would be worth checking that your
latex setup is fully updated: latex package hyperref is involved and
that is updated very frequently (more than weekly).

On Thu, 29 Apr 2010, Murray Efford wrote:

> I construct a pdf package manual in Windows 7 using
> R CMD Rd2dvi --pdf --no-preview [packagename]
> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>
> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
> Murray Efford
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pdalgd at gmail.com  Wed Apr 28 15:06:44 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 28 Apr 2010 15:06:44 +0200
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>
Message-ID: <FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>


On Apr 28, 2010, at 2:29 PM, Prof Brian Ripley wrote:

> Hmm, the construction of the PDF is done by pdlatex/hyperref, not by R.  What latex setup is this, and (guessing it is some version of MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our .tex file to PDF is managed entirely by texi2dvi.exe, and my guess is that it has done too few passes.  You should be able to verify that by using Rd2pdf --no-clean and running texi2dvi yourself on the saved .tex file.  Most likely running pdflatex on the .tex one more time will resolve this, so if you want to check texi2dvi.exe you would need to copy the .tex elsewhere.
> 
> (The less likely alternative is that this is managed by tools::texi2dvi and it is doing too few passes.)
> 
> If you have not already done so it would be worth checking that your latex setup is fully updated: latex package hyperref is involved and that is updated very frequently (more than weekly).

I'm seeing the same issue with ISwR. It looks like a generic LaTeX issue where we need to wait with the makeindex step until the TOC is in place. An easy fix would be to hand-edit the Rd2dvi script to make an extra pass. E.g. replace

if test "${out_ext}" = pdf; then
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1

with 

if test "${out_ext}" = pdf; then
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 &&
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1

and similarly for the non-pdf case, if you care.


> 
> On Thu, 29 Apr 2010, Murray Efford wrote:
> 
>> I construct a pdf package manual in Windows 7 using
>> R CMD Rd2dvi --pdf --no-preview [packagename]
>> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>> 
>> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
>> Murray Efford
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Wed Apr 28 16:17:46 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Apr 2010 15:17:46 +0100 (BST)
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>
	<FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
Message-ID: <alpine.LFD.2.00.1004281516020.20982@gannet.stats.ox.ac.uk>

Yes, I'm sorry I told you how vignettes are made.  It was/is the 
intention to use the same mechanism for package manuals, but it seems 
we did not get there when this was worked on last summer.

On Wed, 28 Apr 2010, peter dalgaard wrote:

>
> On Apr 28, 2010, at 2:29 PM, Prof Brian Ripley wrote:
>
>> Hmm, the construction of the PDF is done by pdlatex/hyperref, not by R.  What latex setup is this, and (guessing it is some version of MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our .tex file to PDF is managed entirely by texi2dvi.exe, and my guess is that it has done too few passes.  You should be able to verify that by using Rd2pdf --no-clean and running texi2dvi yourself on the saved .tex file.  Most likely running pdflatex on the .tex one more time will resolve this, so if you want to check texi2dvi.exe you would need to copy the .tex elsewhere.
>>
>> (The less likely alternative is that this is managed by tools::texi2dvi and it is doing too few passes.)
>>
>> If you have not already done so it would be worth checking that your latex setup is fully updated: latex package hyperref is involved and that is updated very frequently (more than weekly).
>
> I'm seeing the same issue with ISwR. It looks like a generic LaTeX issue where we need to wait with the makeindex step until the TOC is in place. An easy fix would be to hand-edit the Rd2dvi script to make an extra pass. E.g. replace
>
> if test "${out_ext}" = pdf; then
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1
>
> with
>
> if test "${out_ext}" = pdf; then
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 &&
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1
>
> and similarly for the non-pdf case, if you care.
>
>
>>
>> On Thu, 29 Apr 2010, Murray Efford wrote:
>>
>>> I construct a pdf package manual in Windows 7 using
>>> R CMD Rd2dvi --pdf --no-preview [packagename]
>>> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>>>
>>> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
>>> Murray Efford
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murray.efford at otago.ac.nz  Wed Apr 28 23:39:31 2010
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Thu, 29 Apr 2010 09:39:31 +1200
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>,
	<FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
Message-ID: <E67251526203864DABCB7237DAC8EB2D904C8DA820@MAIL2.registry.otago.ac.nz>

Peter's solution works perfectly. Thanks. Maybe this should be standard.
Murray

________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Thursday, 29 April 2010 1:06 a.m.
To: Prof Brian Ripley
Cc: Murray Efford; r-devel at r-project.org
Subject: Re: [Rd] Rd2dvi pagination of index  in pdf manual

On Apr 28, 2010, at 2:29 PM, Prof Brian Ripley wrote:

> Hmm, the construction of the PDF is done by pdlatex/hyperref, not by R.  What latex setup is this, and (guessing it is some version of MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our .tex file to PDF is managed entirely by texi2dvi.exe, and my guess is that it has done too few passes.  You should be able to verify that by using Rd2pdf --no-clean and running texi2dvi yourself on the saved .tex file.  Most likely running pdflatex on the .tex one more time will resolve this, so if you want to check texi2dvi.exe you would need to copy the .tex elsewhere.
>
> (The less likely alternative is that this is managed by tools::texi2dvi and it is doing too few passes.)
>
> If you have not already done so it would be worth checking that your latex setup is fully updated: latex package hyperref is involved and that is updated very frequently (more than weekly).

I'm seeing the same issue with ISwR. It looks like a generic LaTeX issue where we need to wait with the makeindex step until the TOC is in place. An easy fix would be to hand-edit the Rd2dvi script to make an extra pass. E.g. replace

if test "${out_ext}" = pdf; then
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1

with

if test "${out_ext}" = pdf; then
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 &&
  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1

and similarly for the non-pdf case, if you care.


>
> On Thu, 29 Apr 2010, Murray Efford wrote:
>
>> I construct a pdf package manual in Windows 7 using
>> R CMD Rd2dvi --pdf --no-preview [packagename]
>> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>>
>> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
>> Murray Efford
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

From felix at nfrac.org  Thu Apr 29 02:04:33 2010
From: felix at nfrac.org (Felix Andrews)
Date: Thu, 29 Apr 2010 10:04:33 +1000
Subject: [Rd] bug in cut.POSIXt(..., breaks = <numeric>) and cut.Date
Message-ID: <q2k94730b8a1004281704kfc24652q15a56e4571a28e37@mail.gmail.com>

x <- seq(as.POSIXct("2000-01-01"), by = "days", length = 20)

cut(x, breaks = 3)
# Error in `levels<-.factor`(`*tmp*`, value = character(0)) :
#   number of levels differs

cut(as.Date(x), breaks = 3)
# Error in `levels<-.factor`(`*tmp*`, value = character(0)) :
#   number of levels differs



Index: base/R/datetime.R
===================================================================
--- base/R/datetime.R   (revision 51857)
+++ base/R/datetime.R   (working copy)
@@ -775,7 +775,11 @@
         }
     } else stop("invalid specification of 'breaks'")
     res <- cut(unclass(x), unclass(breaks), labels = labels, right =
right, ...)
-    if(is.null(labels)) levels(res) <- as.character(breaks[-length(breaks)])
+    if(is.null(labels)) {
+        if (is.numeric(breaks))
+            levels(res) <- as.character(x[!duplicated(res)])
+        else levels(res) <- as.character(breaks[-length(breaks)])
+    }
     res
 }

Index: base/R/dates.R
===================================================================
--- base/R/dates.R      (revision 51857)
+++ base/R/dates.R      (working copy)
@@ -362,7 +362,11 @@
     } else stop("invalid specification of 'breaks'")
     res <- cut(unclass(x), unclass(breaks), labels = labels,
                right = right, ...)
-    if(is.null(labels)) levels(res) <- as.character(breaks[-length(breaks)])
+    if(is.null(labels)) {
+        if (is.numeric(breaks))
+            levels(res) <- as.character(x[!duplicated(res)])
+        else levels(res) <- as.character(breaks[-length(breaks)])
+    }
     res
 }



Regards
-Felix

-- 
Felix Andrews / ???
Postdoctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 4670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From ripley at stats.ox.ac.uk  Thu Apr 29 06:25:15 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Apr 2010 05:25:15 +0100 (BST)
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <E67251526203864DABCB7237DAC8EB2D904C8DA820@MAIL2.registry.otago.ac.nz>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>,
	<FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
	<E67251526203864DABCB7237DAC8EB2D904C8DA820@MAIL2.registry.otago.ac.nz>
Message-ID: <alpine.LFD.2.00.1004290524210.31533@gannet.stats.ox.ac.uk>

On Thu, 29 Apr 2010, Murray Efford wrote:

> Peter's solution works perfectly. Thanks. Maybe this should be standard.

It is for now, but the intention is to use the more general solution 
of texi2dvi.


> Murray
>
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Thursday, 29 April 2010 1:06 a.m.
> To: Prof Brian Ripley
> Cc: Murray Efford; r-devel at r-project.org
> Subject: Re: [Rd] Rd2dvi pagination of index  in pdf manual
>
> On Apr 28, 2010, at 2:29 PM, Prof Brian Ripley wrote:
>
>> Hmm, the construction of the PDF is done by pdlatex/hyperref, not by R.  What latex setup is this, and (guessing it is some version of MiKTeX) does it have a texi2dvi.exe?  If so, the conversion from our .tex file to PDF is managed entirely by texi2dvi.exe, and my guess is that it has done too few passes.  You should be able to verify that by using Rd2pdf --no-clean and running texi2dvi yourself on the saved .tex file.  Most likely running pdflatex on the .tex one more time will resolve this, so if you want to check texi2dvi.exe you would need to copy the .tex elsewhere.
>>
>> (The less likely alternative is that this is managed by tools::texi2dvi and it is doing too few passes.)
>>
>> If you have not already done so it would be worth checking that your latex setup is fully updated: latex package hyperref is involved and that is updated very frequently (more than weekly).
>
> I'm seeing the same issue with ISwR. It looks like a generic LaTeX issue where we need to wait with the makeindex step until the TOC is in place. An easy fix would be to hand-edit the Rd2dvi script to make an extra pass. E.g. replace
>
> if test "${out_ext}" = pdf; then
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1
>
> with
>
> if test "${out_ext}" = pdf; then
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 &&
>  ${R_PDFLATEXCMD} ${R_TEXOPTS} Rd2 || status=1
>
> and similarly for the non-pdf case, if you care.
>
>
>>
>> On Thu, 29 Apr 2010, Murray Efford wrote:
>>
>>> I construct a pdf package manual in Windows 7 using
>>> R CMD Rd2dvi --pdf --no-preview [packagename]
>>> Page numbers are listed correctly under 'R topics documented' at the front, but incorrectly (offset by -2 pages) in the Index at the back. Following the hyperlinked page numbers in the Index takes you to the wrong page. 2 pages happens to be the length of the package overview man page inserted (out of alphabetical order) after 'R topics documented'.
>>>
>>> I'd be grateful for suggestions on what might be causing this and how I might fix it. I'm using R 2.10.1 and Rtools 2.10.1.
>>> Murray Efford
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Thu Apr 29 11:30:39 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 29 Apr 2010 11:30:39 +0200
Subject: [Rd] Rd2dvi pagination of index  in pdf manual
In-Reply-To: <alpine.LFD.2.00.1004290524210.31533@gannet.stats.ox.ac.uk>
References: <E67251526203864DABCB7237DAC8EB2D904C8DA81C@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004281316290.14977@gannet.stats.ox.ac.uk>,
	<FB5C77F3-C2E6-4B70-8E63-66D040DAFC4C@cbs.dk>
	<E67251526203864DABCB7237DAC8EB2D904C8DA820@MAIL2.registry.otago.ac.nz>
	<alpine.LFD.2.00.1004290524210.31533@gannet.stats.ox.ac.uk>
Message-ID: <2125EF57-D34F-47E5-B66E-C516065BB493@gmail.com>


On Apr 29, 2010, at 6:25 AM, Prof Brian Ripley wrote:

> On Thu, 29 Apr 2010, Murray Efford wrote:
> 
>> Peter's solution works perfectly. Thanks. Maybe this should be standard.
> 
> It is for now, but the intention is to use the more general solution of texi2dvi.
> 

Thanks, Brian.

I'm not actually sure that we need the fourth pdflatex pass (i.e., maybe makeindex just kicked in too soon), so the fix was defensive. It will do for now, though, if things are going to change.

-pd
-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bolker at ufl.edu  Thu Apr 29 14:29:18 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 29 Apr 2010 12:29:18 +0000 (UTC)
Subject: [Rd] bug in cut.POSIXt(..., breaks = &lt; numeric&gt;
	) and cut.Date
References: <q2k94730b8a1004281704kfc24652q15a56e4571a28e37@mail.gmail.com>
Message-ID: <loom.20100429T142823-659@post.gmane.org>

Felix Andrews <felix <at> nfrac.org> writes:

> 
> x <- seq(as.POSIXct("2000-01-01"), by = "days", length = 20)
> 
> cut(x, breaks = 3)
> # Error in `levels<-.factor`(`*tmp*`, value = character(0)) :
> #   number of levels differs
> 
> cut(as.Date(x), breaks = 3)
> # Error in `levels<-.factor`(`*tmp*`, value = character(0)) :
> #   number of levels differs


  Is this the same?

http://article.gmane.org/gmane.comp.lang.r.devel/22155/match=cut+posixt


From nakama at ki.rim.or.jp  Thu Apr 29 17:26:44 2010
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Fri, 30 Apr 2010 00:26:44 +0900
Subject: [Rd] small mistake of tcltk
Message-ID: <j2sdc41e1261004290826l467c7fa8v5fc443565bb4223f@mail.gmail.com>

Hi,

All Japanese encoding was all right if fixed the following.

--- R-2.11.0.orig/src/library/tcltk/src/tcltk.c	2010-03-31
07:10:02.000000000 +0900
+++ R-2.11.0.work/src/library/tcltk/src/tcltk.c	2010-04-29
23:48:55.000000000 +0900
@@ -349,7 +349,7 @@
 	    elem = Tcl_NewObj();
 	    Tcl_DStringInit(&s_ds);
 	    s = Tcl_ExternalToUtfDString(encoding,
-					 (Cchar *) translateChar(STRING_ELT(val, i)),
+					 (Cchar *) translateCharUTF8(STRING_ELT(val, i)),
 					 -1, &s_ds);
 	    Tcl_SetStringObj(elem, s, -1);
 	    Tcl_DStringFree(&s_ds);

-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From hamid.khalili at gmail.com  Thu Apr 29 17:39:25 2010
From: hamid.khalili at gmail.com (Hamid Khalili)
Date: Thu, 29 Apr 2010 17:39:25 +0200
Subject: [Rd] R CMD check Error after R CMD build for R-2.11.0
Message-ID: <v2hb1c1eb501004290839m41c0bf5mac8c3ebd75ab7add@mail.gmail.com>

Dear UseR,

I get an error when I run "R CMD check" on my .tar.gz file package,
and I don't  understand why since I don't obtain any error with "R CMD
check" on the package directory. Do you have any idea ?

$ sudo ./R-2.11.0/bin/R CMD check eqtl_1.1.tar.gz

and

$ sudo ./R-2.11.0/bin/R CMD --check-subdirs=no eqtl_1.1.tar.gz

return an Error

* checking for working pdflatex ... OK
* using log directory '/home/hkhalili/Desktop/eqtl.Rcheck'
* using R version 2.11.0 (2010-04-22)
* using session charset: UTF-8
* checking for file 'eqtl/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'eqtl' version '1.1'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'eqtl' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking data for non-ASCII characters ... OK
* checking examples ... ERROR
Running examples in 'eqtl-Ex.R' failed.
The error most likely occurred in:

> ### * Rsq.2.array
>
> flush(stderr()); flush(stdout())
>
> ### Name: Rsq.2.array
> ### Title: Add R square data to peak.array data frame
> ### Aliases: Rsq.2.array
>
> ### ** Examples
>
> data(seed10);
>
> # Genome scan and QTL detection
> out.em <- scanone(seed10, pheno.col=1:50, model='normal', method='em');
Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
  Dropping 263 individuals with missing phenotypes.

Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
  Dropping 263 individuals with missing phenotypes.

Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
  Dropping 263 individuals with missing phenotypes.

> out.peak <- define.peak(out.em, 'all');
Error: could not find function "define.peak"
Execution halted

The Warnings in checkcovar are normal warnings (from the required
package 'qtl'). The function "define.peak" is part of the package I'm
checking (eqtl) and its Rd and R files are checked before
"Rsq.2.array" function without any Error.
The functions' example running the same commands line with define.peak
didn't return any Error.

$ sudo ./R-2.11.0/bin/R CMD  check --check-subdirs=yes eqtl

and

$ sudo ./R-2.11.0/bin/R CMD check eqtl/

return no error

* checking for working pdflatex ... OK
* using log directory '/home/hkhalili/Desktop/eqtl.Rcheck'
* using R version 2.11.0 (2010-04-22)
* using session charset: UTF-8
* checking for file 'eqtl/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'eqtl' version '1.1'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'eqtl' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking data for non-ASCII characters ... OK
* checking examples ... OK
* checking PDF version of manual ... OK

$ ./R-2.11.0/bin/R CMD build /media/HAMID/eqtl
* checking for file '/media/HAMID/eqtl/DESCRIPTION' ... OK
* preparing '/media/HAMID/eqtl':
* checking DESCRIPTION meta-information ... OK
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'eqtl_1.1.tar.gz'


> sessionInfo()
R version 2.11.0 (2010-04-22)
x86_64-unknown-linux-gnu

locale:
 [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=fr_FR.UTF-8
 [7] LC_PAPER=fr_FR.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> version
               _
platform       x86_64-unknown-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          11.0
year           2010
month          04
day            22
svn rev        51801
language       R
version.string R version 2.11.0 (2010-04-22)

$ ll /media/HAMID/eqtl/man/
total 100
-rwx------ 1 hkhalili hkhalili 17244 2010-04-29 12:21 AA.brief.introduction.Rd
-rwx------ 1 hkhalili hkhalili  3076 2010-04-28 17:21 A.importing.data.Rd
-rwx------ 1 hkhalili hkhalili  1789 2010-04-28 17:21 ATH.coord.Rd
-rwx------ 1 hkhalili hkhalili  1107 2010-04-29 12:22 BSpgmap.Rd
-rwx------ 1 hkhalili hkhalili  3314 2010-04-29 11:32 calc.adef.Rd
-rwx------ 1 hkhalili hkhalili  3496 2010-04-28 17:21 calc.Rsq.Rd
-rwx------ 1 hkhalili hkhalili  1848 2010-04-28 17:21 cim.peak.Rd
-rwx------ 1 hkhalili hkhalili  4630 2010-04-29 13:04 classify.qtl.Rd
-rwx------ 1 hkhalili hkhalili  2136 2010-04-29 11:27 cleanphe.Rd
-rwx------ 1 hkhalili hkhalili  1684 2010-04-28 17:21 cover.peak.Rd
-rwx------ 1 hkhalili hkhalili  8680 2010-04-29 13:54 define.peak.Rd
-rwx------ 1 hkhalili hkhalili  1654 2010-04-28 17:21 drop.peakfeat.Rd
-rwx------ 1 hkhalili hkhalili   403 2010-04-28 17:21 eqtlversion.Rd
-rwx------ 1 hkhalili hkhalili  4260 2010-04-28 17:21 genoplot.Rd
-rwx------ 1 hkhalili hkhalili  2117 2010-04-28 17:21 gpt.Rd
-rwx------ 1 hkhalili hkhalili  3401 2010-04-28 17:21 localize.qtl.Rd
-rwx------ 1 hkhalili hkhalili  1177 2010-04-29 11:31 map.peak.Rd
-rwx------ 1 hkhalili hkhalili   782 2010-04-28 17:21 mnames.map.Rd
-rwx------ 1 hkhalili hkhalili  3123 2010-04-28 17:21 peak.2.array.Rd
-rwx------ 1 hkhalili hkhalili  2219 2010-04-28 17:21 peaksummary.Rd
-rwx------ 1 hkhalili hkhalili  1404 2010-04-28 17:21 plotRsq.Rd
-rwx------ 1 hkhalili hkhalili   979 2010-04-28 17:21 pseudo.map.Rd
-rwx------ 1 hkhalili hkhalili  2072 2010-04-29 14:52 Rsq.2.array.Rd
-rwx------ 1 hkhalili hkhalili  1354 2010-04-28 17:21 seed10.Rd
-rwx------ 1 hkhalili hkhalili  1830 2010-04-28 17:21 wash.covar.Rd

ll /media/HAMID/eqtl/r/
total 90
-rwx------ 1 hkhalili hkhalili  4239 2010-04-28 17:21 calc.adef.R
-rwx------ 1 hkhalili hkhalili  4667 2010-04-28 17:21 calc.Rsq.R
-rwx------ 1 hkhalili hkhalili  2848 2010-04-28 17:21 cim.peak.R
-rwx------ 1 hkhalili hkhalili  4969 2010-04-28 17:21 classify.qtl.R
-rwx------ 1 hkhalili hkhalili  1273 2010-04-28 17:21 cleanphe.r
-rwx------ 1 hkhalili hkhalili  2579 2010-04-28 17:21 cover.peak.R
-rwx------ 1 hkhalili hkhalili 11051 2010-04-28 17:21 define.peak.R
-rwx------ 1 hkhalili hkhalili  1534 2010-04-28 17:21 drop.peakfeat.R
-rwx------ 1 hkhalili hkhalili   104 2010-04-28 17:21 eqtlversion.R
-rwx------ 1 hkhalili hkhalili  9538 2010-04-28 17:21 genoplot.r
-rwx------ 1 hkhalili hkhalili  1872 2010-04-28 17:21 gpt.r
-rwx------ 1 hkhalili hkhalili  5534 2010-04-28 17:21 localize.qtl.R
-rwx------ 1 hkhalili hkhalili  1195 2010-04-28 17:21 map.peak.R
-rwx------ 1 hkhalili hkhalili   827 2010-04-28 17:21 mnames.map.R
-rwx------ 1 hkhalili hkhalili  1760 2010-04-28 17:21 peak.2.array.R
-rwx------ 1 hkhalili hkhalili 11483 2010-04-28 17:21 peaksummary.R
-rwx------ 1 hkhalili hkhalili  1659 2010-04-28 17:21 plotRsq.R
-rwx------ 1 hkhalili hkhalili   928 2010-04-28 17:21 pseudo.map.R
-rwx------ 1 hkhalili hkhalili  1841 2010-04-28 17:21 Rsq.2.array.R
-rwx------ 1 hkhalili hkhalili  3790 2010-04-28 17:21 wash.covar.R


Do you have any ideas in which direction I could search ?

thanks a lot,
sincerely,

-- 
Hamid Khalili


From ligges at statistik.tu-dortmund.de  Thu Apr 29 19:13:54 2010
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 29 Apr 2010 19:13:54 +0200
Subject: [Rd] R CMD check Error after R CMD build for R-2.11.0
In-Reply-To: <v2hb1c1eb501004290839m41c0bf5mac8c3ebd75ab7add@mail.gmail.com>
References: <v2hb1c1eb501004290839m41c0bf5mac8c3ebd75ab7add@mail.gmail.com>
Message-ID: <4BD9BE52.7050507@statistik.tu-dortmund.de>



On 29.04.2010 17:39, Hamid Khalili wrote:
> Dear UseR,
>
> I get an error when I run "R CMD check" on my .tar.gz file package,
> and I don't  understand why since I don't obtain any error with "R CMD
> check" on the package directory. Do you have any idea ?
>
> $ sudo ./R-2.11.0/bin/R CMD check eqtl_1.1.tar.gz
>
> and
>
> $ sudo ./R-2.11.0/bin/R CMD --check-subdirs=no eqtl_1.1.tar.gz
>
> return an Error
>
> * checking for working pdflatex ... OK
> * using log directory '/home/hkhalili/Desktop/eqtl.Rcheck'
> * using R version 2.11.0 (2010-04-22)
> * using session charset: UTF-8
> * checking for file 'eqtl/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'eqtl' version '1.1'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'eqtl' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking data for non-ASCII characters ... OK
> * checking examples ... ERROR
> Running examples in 'eqtl-Ex.R' failed.
> The error most likely occurred in:
>
>> ### * Rsq.2.array
>>
>> flush(stderr()); flush(stdout())
>>
>> ### Name: Rsq.2.array
>> ### Title: Add R square data to peak.array data frame
>> ### Aliases: Rsq.2.array
>>
>> ### ** Examples
>>
>> data(seed10);
>>
>> # Genome scan and QTL detection
>> out.em<- scanone(seed10, pheno.col=1:50, model='normal', method='em');
> Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
>    Dropping 263 individuals with missing phenotypes.
>
> Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
>    Dropping 263 individuals with missing phenotypes.
>
> Warning in checkcovar(cross, pheno.col, addcovar, intcovar, perm.strata,  :
>    Dropping 263 individuals with missing phenotypes.
>
>> out.peak<- define.peak(out.em, 'all');
> Error: could not find function "define.peak"
> Execution halted
>
> The Warnings in checkcovar are normal warnings (from the required
> package 'qtl'). The function "define.peak" is part of the package I'm
> checking (eqtl) and its Rd and R files are checked before
> "Rsq.2.array" function without any Error.

Are you sure about the spelling? Do you have a namespace and forgot to 
export?

Uwe Ligges


> The functions' example running the same commands line with define.peak
> didn't return any Error.
>
> $ sudo ./R-2.11.0/bin/R CMD  check --check-subdirs=yes eqtl
>
> and
>
> $ sudo ./R-2.11.0/bin/R CMD check eqtl/
>
> return no error
>
> * checking for working pdflatex ... OK
> * using log directory '/home/hkhalili/Desktop/eqtl.Rcheck'
> * using R version 2.11.0 (2010-04-22)
> * using session charset: UTF-8
> * checking for file 'eqtl/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'eqtl' version '1.1'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'eqtl' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking data for non-ASCII characters ... OK
> * checking examples ... OK
> * checking PDF version of manual ... OK
>
> $ ./R-2.11.0/bin/R CMD build /media/HAMID/eqtl
> * checking for file '/media/HAMID/eqtl/DESCRIPTION' ... OK
> * preparing '/media/HAMID/eqtl':
> * checking DESCRIPTION meta-information ... OK
> * removing junk files
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'eqtl_1.1.tar.gz'
>
>
>> sessionInfo()
> R version 2.11.0 (2010-04-22)
> x86_64-unknown-linux-gnu
>
> locale:
>   [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
>   [5] LC_MONETARY=C              LC_MESSAGES=fr_FR.UTF-8
>   [7] LC_PAPER=fr_FR.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>> version
>                 _
> platform       x86_64-unknown-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          2
> minor          11.0
> year           2010
> month          04
> day            22
> svn rev        51801
> language       R
> version.string R version 2.11.0 (2010-04-22)
>
> $ ll /media/HAMID/eqtl/man/
> total 100
> -rwx------ 1 hkhalili hkhalili 17244 2010-04-29 12:21 AA.brief.introduction.Rd
> -rwx------ 1 hkhalili hkhalili  3076 2010-04-28 17:21 A.importing.data.Rd
> -rwx------ 1 hkhalili hkhalili  1789 2010-04-28 17:21 ATH.coord.Rd
> -rwx------ 1 hkhalili hkhalili  1107 2010-04-29 12:22 BSpgmap.Rd
> -rwx------ 1 hkhalili hkhalili  3314 2010-04-29 11:32 calc.adef.Rd
> -rwx------ 1 hkhalili hkhalili  3496 2010-04-28 17:21 calc.Rsq.Rd
> -rwx------ 1 hkhalili hkhalili  1848 2010-04-28 17:21 cim.peak.Rd
> -rwx------ 1 hkhalili hkhalili  4630 2010-04-29 13:04 classify.qtl.Rd
> -rwx------ 1 hkhalili hkhalili  2136 2010-04-29 11:27 cleanphe.Rd
> -rwx------ 1 hkhalili hkhalili  1684 2010-04-28 17:21 cover.peak.Rd
> -rwx------ 1 hkhalili hkhalili  8680 2010-04-29 13:54 define.peak.Rd
> -rwx------ 1 hkhalili hkhalili  1654 2010-04-28 17:21 drop.peakfeat.Rd
> -rwx------ 1 hkhalili hkhalili   403 2010-04-28 17:21 eqtlversion.Rd
> -rwx------ 1 hkhalili hkhalili  4260 2010-04-28 17:21 genoplot.Rd
> -rwx------ 1 hkhalili hkhalili  2117 2010-04-28 17:21 gpt.Rd
> -rwx------ 1 hkhalili hkhalili  3401 2010-04-28 17:21 localize.qtl.Rd
> -rwx------ 1 hkhalili hkhalili  1177 2010-04-29 11:31 map.peak.Rd
> -rwx------ 1 hkhalili hkhalili   782 2010-04-28 17:21 mnames.map.Rd
> -rwx------ 1 hkhalili hkhalili  3123 2010-04-28 17:21 peak.2.array.Rd
> -rwx------ 1 hkhalili hkhalili  2219 2010-04-28 17:21 peaksummary.Rd
> -rwx------ 1 hkhalili hkhalili  1404 2010-04-28 17:21 plotRsq.Rd
> -rwx------ 1 hkhalili hkhalili   979 2010-04-28 17:21 pseudo.map.Rd
> -rwx------ 1 hkhalili hkhalili  2072 2010-04-29 14:52 Rsq.2.array.Rd
> -rwx------ 1 hkhalili hkhalili  1354 2010-04-28 17:21 seed10.Rd
> -rwx------ 1 hkhalili hkhalili  1830 2010-04-28 17:21 wash.covar.Rd
>
> ll /media/HAMID/eqtl/r/
> total 90
> -rwx------ 1 hkhalili hkhalili  4239 2010-04-28 17:21 calc.adef.R
> -rwx------ 1 hkhalili hkhalili  4667 2010-04-28 17:21 calc.Rsq.R
> -rwx------ 1 hkhalili hkhalili  2848 2010-04-28 17:21 cim.peak.R
> -rwx------ 1 hkhalili hkhalili  4969 2010-04-28 17:21 classify.qtl.R
> -rwx------ 1 hkhalili hkhalili  1273 2010-04-28 17:21 cleanphe.r
> -rwx------ 1 hkhalili hkhalili  2579 2010-04-28 17:21 cover.peak.R
> -rwx------ 1 hkhalili hkhalili 11051 2010-04-28 17:21 define.peak.R
> -rwx------ 1 hkhalili hkhalili  1534 2010-04-28 17:21 drop.peakfeat.R
> -rwx------ 1 hkhalili hkhalili   104 2010-04-28 17:21 eqtlversion.R
> -rwx------ 1 hkhalili hkhalili  9538 2010-04-28 17:21 genoplot.r
> -rwx------ 1 hkhalili hkhalili  1872 2010-04-28 17:21 gpt.r
> -rwx------ 1 hkhalili hkhalili  5534 2010-04-28 17:21 localize.qtl.R
> -rwx------ 1 hkhalili hkhalili  1195 2010-04-28 17:21 map.peak.R
> -rwx------ 1 hkhalili hkhalili   827 2010-04-28 17:21 mnames.map.R
> -rwx------ 1 hkhalili hkhalili  1760 2010-04-28 17:21 peak.2.array.R
> -rwx------ 1 hkhalili hkhalili 11483 2010-04-28 17:21 peaksummary.R
> -rwx------ 1 hkhalili hkhalili  1659 2010-04-28 17:21 plotRsq.R
> -rwx------ 1 hkhalili hkhalili   928 2010-04-28 17:21 pseudo.map.R
> -rwx------ 1 hkhalili hkhalili  1841 2010-04-28 17:21 Rsq.2.array.R
> -rwx------ 1 hkhalili hkhalili  3790 2010-04-28 17:21 wash.covar.R
>
>
> Do you have any ideas in which direction I could search ?
>
> thanks a lot,
> sincerely,
>


From djsamperi at gmail.com  Fri Apr 30 07:03:18 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 30 Apr 2010 01:03:18 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
Message-ID: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100430/ddf9a6b1/attachment.pl>

From chiefmurphy at gmail.com  Fri Apr 30 09:16:01 2010
From: chiefmurphy at gmail.com (Daniel Murphy)
Date: Fri, 30 Apr 2010 00:16:01 -0700
Subject: [Rd] S4 method execution time
Message-ID: <o2r48f8cced1004300016t994e3429l2b23dae96e3c19d3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100430/df4637aa/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Apr 30 09:56:21 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Apr 2010 08:56:21 +0100 (BST)
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1004300840020.19781@gannet.stats.ox.ac.uk>

On Fri, 30 Apr 2010, Dominick Samperi wrote:

> The R docs say that there are two methods that the C programmer can
> allocate memory, one where R automatically frees the memory on
> return from .C/.Call, and the other where the user takes responsibility
> for freeing the storage. Both methods involve using R-provided
> functions.
>
> What happens when the user uses the standard "new" allocator?

Standard in C++, not C, that is.

> What about when a C++ application uses STL and that library
> allocates memory? In both of these cases the R-provided functions
> are not used (to my knowledge), yet I have not seen any problems.

Then you have been fortunate, maybe because you work on a very limited 
range of compilers and OSes?  I have been plagued by this on modern 
Windows toolchains where it seems that dynamically linked C++ code 
only works if called from a C++ main program (and R is a C main 
program).

> How is the memory that R manages and garbage collects kept
> separate from the memory that is allocated on the C++ side
> quite independently of what R is doing?

R does not use C++.  So the 'C++ side' is entirely in the packages 
which choose to use it, and they manage their own memory usage via 
the C++ runtime they are linked to.  Basically R mallocs all the 
memory it uses, and the hope is that the C++ runtime does not
interfere with malloc (and of course it is in practice also obtaining 
memory by malloc or its equivalent).

> Thanks,
> Dominick
>
> 	[[alternative HTML version deleted]]

[Please do note that what the posting guide asked you NOT to do.]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Apr 30 10:03:09 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Apr 2010 09:03:09 +0100 (BST)
Subject: [Rd] S4 method execution time
In-Reply-To: <o2r48f8cced1004300016t994e3429l2b23dae96e3c19d3@mail.gmail.com>
References: <o2r48f8cced1004300016t994e3429l2b23dae96e3c19d3@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1004300856590.19781@gannet.stats.ox.ac.uk>

On Fri, 30 Apr 2010, Daniel Murphy wrote:

> Hello:
>
> I have written some an elementary S4 classes around a matrix to strengthen
> control of some key attributes. When I run a fairly elementary function
> ("f") on the matrix outside the class it runs instantaneously (elapsed
> system.time = 0) but when I setMethod "f" on myClass -- returning an
> instance of myClass -- it runs perceptibly slower (elapsed system.time =
> .06). I suspect my initialization and/or validity functions are
> inefficiently written. I thought I read in this list of a function that will
> trace the execution time of each of the functions called during the
> evaluation of an R expression, but now I can't find that message. Is there
> such a function, or was I mistaken?

Maybe Rprof?   That is certainly the tool I would use, and it is 
described in 'Writing R Extensions'.

But we do know that S4 methods do have a significant overhead: OTOH 
there is caching going on and so a lot of this overhead is on first 
use.  So you may find that your 'toy' test does not scale to a real 
problem (surely you have difficulty perceiving 60ms, literally the 
blink of an eye?).

>
> Thank you.
>
> Dan Murphy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Apr 30 10:20:14 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Apr 2010 09:20:14 +0100 (BST)
Subject: [Rd] Likely disruption to R-devel builds on Windows
Message-ID: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>

We are planning to phase in some major changes to the R build process 
on Windows shortly, so expect problems and temporary unavailability of 
binary builds of R and of packages, and if you are building from 
sources, check out the latest version of the R-admin manual (in the 
sources) for the current state.

The planned changes are

- to move the 32-bit builds to MinGW's recent release of gcc 4.5.0 
(but with static linking of the Fortran and C++ runtimes: dynamic 
linking of C++ in packages crashes R).

- to merge the 32-bit and 64-bit builds into a single installer and 
(for at least 98% of CRAN) a single binary for each package.

NB: R-devel is not due for release until ca October and changes such 
as this are done early in the development cycle to allow plenty of 
time for them to be bedded down.  Please do take seriously the 
description as

R version 2.12.0 Under development (unstable) (2010-04-29 r51864)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hamid.khalili at gmail.com  Fri Apr 30 12:06:56 2010
From: hamid.khalili at gmail.com (Hamid Khalili)
Date: Fri, 30 Apr 2010 12:06:56 +0200
Subject: [Rd] R CMD check Error after R CMD build for R-2.11.0
In-Reply-To: <4BD9BE52.7050507@statistik.tu-dortmund.de>
References: <v2hb1c1eb501004290839m41c0bf5mac8c3ebd75ab7add@mail.gmail.com>
	<4BD9BE52.7050507@statistik.tu-dortmund.de>
Message-ID: <i2jb1c1eb501004300306geae2f044gb79dc11972b48244@mail.gmail.com>

I'm really sorry that I had to disturb you (for nothing) because
everything looks fine now ( why ??). After I build  again the package
with search() in the "Rsq.2.array" examples, I didn't get any Error.

The only things that I changed it's the directory where is build the package.

The package directory path is located on a different drive (USB KEY)
from where it was build (HARDRIVE).This return the Error.
Now I build the package on the same drive (both in the USB KEY).

I try it with the last stable version R-2.11.0 and the patched version
Patched (2010-04-28 r51857)

/media/HAMID$ ~/Desktop/R-2.11.0/bin/R CMD build eqtl/
* checking for file 'eqtl/DESCRIPTION' ... OK
* preparing 'eqtl':
* checking DESCRIPTION meta-information ... OK
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'eqtl_1.1.tar.gz'

/media/HAMID$ ~/Desktop/R-2.11.0/bin/R CMD check eqtl_1.1.tar.gz
* checking for working pdflatex ... OK
* using log directory '/media/HAMID/eqtl.Rcheck'
* using R version 2.11.0 (2010-04-22)
* using session charset: UTF-8
* checking for file 'eqtl/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'eqtl' version '1.1'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'eqtl' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking data for non-ASCII characters ... OK
* checking examples ... OK
* checking PDF version of manual ... OK

It doesn't really look to be a user autorisation problems. Do you
think it's a problem related only to my computer or should I report it
as a bug ?

thks a lot,


From simon.urbanek at r-project.org  Fri Apr 30 15:00:24 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 30 Apr 2010 09:00:24 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
Message-ID: <491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>

Brian's answer was pretty exhaustive - just one more note that is indirectly related to memory management: C++ exception handling does interfere with R's error handling (and vice versa) so in general STL is very dangerous and best avoided in R. In addition, remember that regular local object rules are broken because you are not guaranteed to leave a function the regular way so there is a high danger of leaks and inconsistencies when using C++ memory management unless you specifically account for that. That said, I have written C++ code that works in R but you have to be very, very careful and think twice about using any complex C++ libraries since they are unlikely written in R-safe way.

Cheers,
Simon


On Apr 30, 2010, at 1:03 AM, Dominick Samperi wrote:

> The R docs say that there are two methods that the C programmer can
> allocate memory, one where R automatically frees the memory on
> return from .C/.Call, and the other where the user takes responsibility
> for freeing the storage. Both methods involve using R-provided
> functions.
> 
> What happens when the user uses the standard "new" allocator?
> What about when a C++ application uses STL and that library
> allocates memory? In both of these cases the R-provided functions
> are not used (to my knowledge), yet I have not seen any problems.
> 
> How is the memory that R manages and garbage collects kept
> separate from the memory that is allocated on the C++ side
> quite independently of what R is doing?
> 
> Thanks,
> Dominick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Fri Apr 30 15:03:29 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 30 Apr 2010 09:03:29 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>
Message-ID: <F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>


On Apr 30, 2010, at 4:20 AM, Prof Brian Ripley wrote:

> We are planning to phase in some major changes to the R build process on Windows shortly, so expect problems and temporary unavailability of binary builds of R and of packages, and if you are building from sources, check out the latest version of the R-admin manual (in the sources) for the current state.
> 

To make sure no one has an excuse for not reading the current manuals - they are available (built nightly) at

http://r.research.att.com/man/

Cheers,
Simon


> The planned changes are
> 
> - to move the 32-bit builds to MinGW's recent release of gcc 4.5.0 (but with static linking of the Fortran and C++ runtimes: dynamic linking of C++ in packages crashes R).
> 
> - to merge the 32-bit and 64-bit builds into a single installer and (for at least 98% of CRAN) a single binary for each package.
> 
> NB: R-devel is not due for release until ca October and changes such as this are done early in the development cycle to allow plenty of time for them to be bedded down.  Please do take seriously the description as
> 
> R version 2.12.0 Under development (unstable) (2010-04-29 r51864)
>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ggrothendieck at gmail.com  Fri Apr 30 15:16:15 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Apr 2010 09:16:15 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk> 
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
Message-ID: <s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>

Some easy way to find out what has changed would be desirable here.

On Fri, Apr 30, 2010 at 9:03 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Apr 30, 2010, at 4:20 AM, Prof Brian Ripley wrote:
>
>> We are planning to phase in some major changes to the R build process on Windows shortly, so expect problems and temporary unavailability of binary builds of R and of packages, and if you are building from sources, check out the latest version of the R-admin manual (in the sources) for the current state.
>>
>
> To make sure no one has an excuse for not reading the current manuals - they are available (built nightly) at
>
> http://r.research.att.com/man/
>
> Cheers,
> Simon
>
>
>> The planned changes are
>>
>> - to move the 32-bit builds to MinGW's recent release of gcc 4.5.0 (but with static linking of the Fortran and C++ runtimes: dynamic linking of C++ in packages crashes R).
>>
>> - to merge the 32-bit and 64-bit builds into a single installer and (for at least 98% of CRAN) a single binary for each package.
>>
>> NB: R-devel is not due for release until ca October and changes such as this are done early in the development cycle to allow plenty of time for them to be bedded down. ?Please do take seriously the description as
>>
>> R version 2.12.0 Under development (unstable) (2010-04-29 r51864)
>> ? ? ? ? ? ? ? ? ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>
>> --
>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Fri Apr 30 16:22:07 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 30 Apr 2010 09:22:07 -0500
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk> 
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
Message-ID: <h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com>

Maybe Duncan could apply the same script that's being used for RNEWS
to the manuals?  An RSS feed of changes to the manuals would be really
useful.

Hadley

On Fri, Apr 30, 2010 at 8:16 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Some easy way to find out what has changed would be desirable here.
>
> On Fri, Apr 30, 2010 at 9:03 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>>
>> On Apr 30, 2010, at 4:20 AM, Prof Brian Ripley wrote:
>>
>>> We are planning to phase in some major changes to the R build process on Windows shortly, so expect problems and temporary unavailability of binary builds of R and of packages, and if you are building from sources, check out the latest version of the R-admin manual (in the sources) for the current state.
>>>
>>
>> To make sure no one has an excuse for not reading the current manuals - they are available (built nightly) at
>>
>> http://r.research.att.com/man/
>>
>> Cheers,
>> Simon
>>
>>
>>> The planned changes are
>>>
>>> - to move the 32-bit builds to MinGW's recent release of gcc 4.5.0 (but with static linking of the Fortran and C++ runtimes: dynamic linking of C++ in packages crashes R).
>>>
>>> - to merge the 32-bit and 64-bit builds into a single installer and (for at least 98% of CRAN) a single binary for each package.
>>>
>>> NB: R-devel is not due for release until ca October and changes such as this are done early in the development cycle to allow plenty of time for them to be bedded down. ?Please do take seriously the description as
>>>
>>> R version 2.12.0 Under development (unstable) (2010-04-29 r51864)
>>> ? ? ? ? ? ? ? ? ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From murdoch at stats.uwo.ca  Fri Apr 30 16:39:28 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Apr 2010 10:39:28 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
 builds on Windows]
In-Reply-To: <h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com>
Message-ID: <4BDAEBA0.1010903@stats.uwo.ca>

On 30/04/2010 10:22 AM, hadley wickham wrote:
> Maybe Duncan could apply the same script that's being used for RNEWS
> to the manuals?  An RSS feed of changes to the manuals would be really
> useful.
>   

My script is very NEWS specific.  The manuals would be harder.  You 
could get the diffs from svn pretty easily, but displaying them would be 
trickier:  do you display the diffs in the .texi source, or convert to 
HTML and display the diffs there, or what?  How much context around 
them?  Not impossible, but not trivial.

Duncan


> Hadley
>
> On Fri, Apr 30, 2010 at 8:16 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> > Some easy way to find out what has changed would be desirable here.
> >
> > On Fri, Apr 30, 2010 at 9:03 AM, Simon Urbanek
> > <simon.urbanek at r-project.org> wrote:
> >>
> >> On Apr 30, 2010, at 4:20 AM, Prof Brian Ripley wrote:
> >>
> >>> We are planning to phase in some major changes to the R build process on Windows shortly, so expect problems and temporary unavailability of binary builds of R and of packages, and if you are building from sources, check out the latest version of the R-admin manual (in the sources) for the current state.
> >>>
> >>
> >> To make sure no one has an excuse for not reading the current manuals - they are available (built nightly) at
> >>
> >> http://r.research.att.com/man/
> >>
> >> Cheers,
> >> Simon
> >>
> >>
> >>> The planned changes are
> >>>
> >>> - to move the 32-bit builds to MinGW's recent release of gcc 4.5.0 (but with static linking of the Fortran and C++ runtimes: dynamic linking of C++ in packages crashes R).
> >>>
> >>> - to merge the 32-bit and 64-bit builds into a single installer and (for at least 98% of CRAN) a single binary for each package.
> >>>
> >>> NB: R-devel is not due for release until ca October and changes such as this are done early in the development cycle to allow plenty of time for them to be bedded down.  Please do take seriously the description as
> >>>
> >>> R version 2.12.0 Under development (unstable) (2010-04-29 r51864)
> >>>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> >>>
> >>> --
> >>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>
>


From ggrothendieck at gmail.com  Fri Apr 30 16:48:34 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Apr 2010 10:48:34 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <4BDAEBA0.1010903@stats.uwo.ca>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk> 
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com> 
	<4BDAEBA0.1010903@stats.uwo.ca>
Message-ID: <q2z971536df1004300748ucf5c4fc0t7d5b6d66c972a651@mail.gmail.com>

On Fri, Apr 30, 2010 at 10:39 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 30/04/2010 10:22 AM, hadley wickham wrote:
>>
>> Maybe Duncan could apply the same script that's being used for RNEWS
>> to the manuals? ?An RSS feed of changes to the manuals would be really
>> useful.
>>
>
> My script is very NEWS specific. ?The manuals would be harder. ?You could
> get the diffs from svn pretty easily, but displaying them would be trickier:
> ?do you display the diffs in the .texi source, or convert to HTML and
> display the diffs there, or what? ?How much context around them? ?Not
> impossible, but not trivial.
>

Just making the source diffs easily accessible would be sufficient IMHO.

For example, go to this page:
   http://rwiki.sciviews.org/doku.php?do=recent
and click on any of the eyeglass symbols.


From h.wickham at gmail.com  Fri Apr 30 16:59:30 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 30 Apr 2010 09:59:30 -0500
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <4BDAEBA0.1010903@stats.uwo.ca>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk> 
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com> 
	<4BDAEBA0.1010903@stats.uwo.ca>
Message-ID: <m2pf8e6ff051004300759va73c50d4j2776a9318fbd09c2@mail.gmail.com>

> My script is very NEWS specific. ?The manuals would be harder. ?You could
> get the diffs from svn pretty easily, but displaying them would be trickier:
> ?do you display the diffs in the .texi source, or convert to HTML and
> display the diffs there, or what? ?How much context around them? ?Not
> impossible, but not trivial.

I suspect the best combination of ease and quality of output would be
to output the texi to plain text, and then diff that.   I really like
the existing RNEWS format, but I guess you split the news into
individual entries and only display those with any changes.  It would
be a bit harder to do with general output, although maybe splitting
into paragraphs would be sufficient.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From murdoch at stats.uwo.ca  Fri Apr 30 17:01:55 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Apr 2010 11:01:55 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
 builds on Windows]
In-Reply-To: <q2z971536df1004300748ucf5c4fc0t7d5b6d66c972a651@mail.gmail.com>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com>
	<4BDAEBA0.1010903@stats.uwo.ca>
	<q2z971536df1004300748ucf5c4fc0t7d5b6d66c972a651@mail.gmail.com>
Message-ID: <4BDAF0E3.1060003@stats.uwo.ca>

On 30/04/2010 10:48 AM, Gabor Grothendieck wrote:
> On Fri, Apr 30, 2010 at 10:39 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 30/04/2010 10:22 AM, hadley wickham wrote:
> >>
> >> Maybe Duncan could apply the same script that's being used for RNEWS
> >> to the manuals?  An RSS feed of changes to the manuals would be really
> >> useful.
> >>
> >
> > My script is very NEWS specific.  The manuals would be harder.  You could
> > get the diffs from svn pretty easily, but displaying them would be trickier:
> >  do you display the diffs in the .texi source, or convert to HTML and
> > display the diffs there, or what?  How much context around them?  Not
> > impossible, but not trivial.
> >
>
> Just making the source diffs easily accessible would be sufficient IMHO.

That's already available, but not too pretty.  E.g.

svn log -v https://svn.r-project.org/R/trunk/doc/manual | less

will show something like

------------------------------------------------------------------------
r51865 | ripley | 2010-04-30 00:56:00 -0400 (Fri, 30 Apr 2010) | 1 line
Changed paths:
   M /trunk/doc/manual/R-admin.texi
   M /trunk/src/gnuwin32/CHANGES
   M /trunk/src/library/tools/R/install.R

tests starssrc/library/tools/R/install.R
------------------------------------------------------------------------
r51858 | ripley | 2010-04-29 00:51:01 -0400 (Thu, 29 Apr 2010) | 1 line
Changed paths:
   M /trunk/doc/manual/R-exts.texi

tweak wording
------------------------------------------------------------------------
r51854 | ripley | 2010-04-28 10:41:26 -0400 (Wed, 28 Apr 2010) | 1 line
Changed paths:
   M /trunk/doc/manual/R-exts.texi

more on portability
 (etc.)

and for particular details, you can do something like

svn diff -c 51858 https://svn.r-project.org/R/trunk/doc/manual

which will give

Index: R-exts.texi
===================================================================
--- R-exts.texi (revision 51857)
+++ R-exts.texi (revision 51858)
@@ -10813,10 +10813,10 @@

 The @R{} for Windows installers have for a long time allowed the value
 of @code{R_HOME} to be recorded in the Windows Registry: this is
-optional but the default. Where is it is recorded has changed over the
-years to allow for multiple versions of @R{} to be installed at once,
-and as from @R{} 2.11.0, to allow 32- and 64-bit versions of @R{} to be
-installed on the same machine.
+optional but selected by default.  @emph{Where} is it is recorded has
+changed over the years to allow for multiple versions of @R{} to be
+installed at once, and as from @R{} 2.11.0, to allow 32- and 64-bit
+versions of @R{} to be installed on the same machine.

 The basic Registry location is @code{Software\R-core\R}.  For an
 administrative install this is under @code{HKEY_LOCAL_MACHINE} and on a

The non-trivial part is converting it into a nice display like what you 
pointed out in the Wiki.

Duncan Murdoch


From tal.galili at gmail.com  Fri Apr 30 15:13:26 2010
From: tal.galili at gmail.com (Tal Galili)
Date: Fri, 30 Apr 2010 16:13:26 +0300
Subject: [Rd] Request - adding recycled "lwd" parameter to polygon
In-Reply-To: <k2p440d7af41004290124o3ecf392fo79be4d0ab3701d0c@mail.gmail.com>
References: <k2p440d7af41004290124o3ecf392fo79be4d0ab3701d0c@mail.gmail.com>
Message-ID: <g2w440d7af41004300613h13fa952an6077d6fe6ac4b13b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100430/07831c1c/attachment.pl>

From jaiganesh.balasubramanian at gmail.com  Fri Apr 30 19:32:48 2010
From: jaiganesh.balasubramanian at gmail.com (Jaiganesh Balasubramanian)
Date: Fri, 30 Apr 2010 13:32:48 -0400
Subject: [Rd] RInside & child threads
Message-ID: <v2oc376fef21004301032g719cbd54r29cee7c6d0df7c12@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20100430/c29f07fe/attachment.pl>

From djsamperi at gmail.com  Fri Apr 30 19:40:12 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 30 Apr 2010 13:40:12 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
	<491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
Message-ID: <u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>

Simon,

Just to be sure that I understand, are you suggesting that the R-safe way to do
things is to not use STL, and to not use C++ memory management and
exception handling? How can you leave a function in an irregular way without
triggering a seg fault or something like that, in which case there is no chance
for recovery anyway?

In my experience the C++ exception stack seems to
unwind properly before returning to R when there is an exception, and memory
that is allocated by C++ functions seems to maintain its integrity and does
not interfere with R's memory management.

It would be helpful if you could specify what kind of interference you
are referring to here between C++ exception handling and R's error
handling, and why STL is dangerous and best avoided in R. I have
used STL with R for a long time and have experienced no problems.

The fact that R has a C main may be problematic because C++ static
initializers may not be called properly, but the fact that packages are
usually loaded dynamically complicates this picture. The dynamic
library itself may take care of calling the static initializers (I'm not
sure about this, and this is probably OS-dependent). One possible
work-around would be to compile the first few lines (a stub) of
R main using the C++ compiler, leaving everything else as is
and compiled using the C compiler (at least until CXXR is widely
available).

Since C++ (and STL) are very popular it would be helpful for developers
to have a better idea of the benefits and risks of using these tools
with R.

Thanks,
Dominick

On Fri, Apr 30, 2010 at 9:00 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Brian's answer was pretty exhaustive - just one more note that is indirectly related to memory management: C++ exception handling does interfere with R's error handling (and vice versa) so in general STL is very dangerous and best avoided in R. In addition, remember that regular local object rules are broken because you are not guaranteed to leave a function the regular way so there is a high danger of leaks and inconsistencies when using C++ memory management unless you specifically account for that. That said, I have written C++ code that works in R but you have to be very, very careful and think twice about using any complex C++ libraries since they are unlikely written in R-safe way.
>
> Cheers,
> Simon
>
>
> On Apr 30, 2010, at 1:03 AM, Dominick Samperi wrote:
>
>> The R docs say that there are two methods that the C programmer can
>> allocate memory, one where R automatically frees the memory on
>> return from .C/.Call, and the other where the user takes responsibility
>> for freeing the storage. Both methods involve using R-provided
>> functions.
>>
>> What happens when the user uses the standard "new" allocator?
>> What about when a C++ application uses STL and that library
>> allocates memory? In both of these cases the R-provided functions
>> are not used (to my knowledge), yet I have not seen any problems.
>>
>> How is the memory that R manages and garbage collects kept
>> separate from the memory that is allocated on the C++ side
>> quite independently of what R is doing?
>>
>> Thanks,
>> Dominick
>>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From ggrothendieck at gmail.com  Fri Apr 30 20:11:50 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Apr 2010 14:11:50 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
	builds on Windows]
In-Reply-To: <4BDAF0E3.1060003@stats.uwo.ca>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk> 
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com> 
	<4BDAEBA0.1010903@stats.uwo.ca>
	<q2z971536df1004300748ucf5c4fc0t7d5b6d66c972a651@mail.gmail.com>
	<4BDAF0E3.1060003@stats.uwo.ca>
Message-ID: <h2r971536df1004301111tdf0dadcdsbfee62ec3e204d16@mail.gmail.com>

On Fri, Apr 30, 2010 at 11:01 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 30/04/2010 10:48 AM, Gabor Grothendieck wrote:
>>
>> On Fri, Apr 30, 2010 at 10:39 AM, Duncan Murdoch <murdoch at stats.uwo.ca>
>> wrote:
>> > On 30/04/2010 10:22 AM, hadley wickham wrote:
>> >>
>> >> Maybe Duncan could apply the same script that's being used for RNEWS
>> >> to the manuals? ?An RSS feed of changes to the manuals would be really
>> >> useful.
>> >>
>> >
>> > My script is very NEWS specific. ?The manuals would be harder. ?You
>> > could
>> > get the diffs from svn pretty easily, but displaying them would be
>> > trickier:
>> > ?do you display the diffs in the .texi source, or convert to HTML and
>> > display the diffs there, or what? ?How much context around them? ?Not
>> > impossible, but not trivial.

If you could mirror the manuals to googlecode you would automatically
get an HTML interface to the diffs. e.g.

http://code.google.com/p/sqldf/source/list


From simon.urbanek at r-project.org  Fri Apr 30 20:12:46 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 30 Apr 2010 14:12:46 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
	<491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
	<u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>
Message-ID: <F58D45DC-69AB-43C5-B6E4-CE5C87354DBE@r-project.org>

Dominick,

On Apr 30, 2010, at 1:40 PM, Dominick Samperi wrote:

> Just to be sure that I understand, are you suggesting that the R-safe way to do things is to not use STL, and to not use C++ memory management and exception handling? How can you leave a function in an irregular way without triggering a seg fault or something like that, in which case there is no chance for recovery anyway?
> 
> In my experience the C++ exception stack seems to unwind properly before returning to R when there is an exception, and memory that is allocated by C++ functions seems to maintain its integrity and does not interfere with R's memory management.
> 
> It would be helpful if you could specify what kind of interference you are referring to here between C++ exception handling and R's error handling, and why STL is dangerous and best avoided in R. I have used STL with R for a long time and have experienced no problems.
> 

There are essentially two issues here that I had in mind.

1) C++ exception handling and R exceptions handling both use setjmp/longjmp with the assumption that no one else does the same. That assumption is voided when both are used so interleaving them will cause problems (you're fine if you can guarantee that they always stack but that's not always easy to achieve yet easy to miss).

2) C++ compilers assume that you cannot leave the context of a function in unusual ways. But you can, namely if an R error is raised. This affects (among others) locally allocated objects.


On 1:

You cannot interleave R error handling and C++ exceptions. For example if there is a chance of a C++ exception you must guarantee that the exception won't leave the R context that you are in. This is easily demonstrated because R check the consistency (see ex.1). Vice versa the consequences are not easily visible, because C++ provides no tracking, but is equally fatal. If you raise R exception from C++ it does not clean up whatever C++ exception context you were it and bypasses it. But there are even more grave consequences:

On 2:

If you any R error from within C++ code you'll break the assumption of C++ that it has control over the entry/exit point of a function. Take a really trivial example:

void foo() {
Object o;
// some other code ....
error("blah")

normally, the life of o is controlled by C++ and it will correctly execute its destructor when you leave the function. However, the error call in R will cause it to bypass that, the object won't be destroyed even though it was allocated on the stack. Although it's obvious in the example above, pretty much all R API function can raise errors so the same applies to any R API call - direct or indirect. As a consequence you pretty much cannot call R API function from C++ unless you are very, very careful (don't forget that C++ does a lot of things behind your back such as initializing objects, exception contexts etc. which you technically have no control over).


As I said in my post, you can write safe C++ code, but you have to be very careful. But the point about libraries is that you have no control over what they do, so you cannot know whether they will interact in a bad way with R or not. STL is an example where only the interface is defined, the implementations are not and vary by OS, compiler etc. This makes it pretty much impossible to use it reliably since the fact that it will work on one implementation doesn't mean that it will work on another since it is the implementation details that will bite you. (I know that we had reports of things breaking due to STL but I don't remember what implementation/OS it was)

[The above issue are only the ones I was pointing out, there may be others that are not covered here].

Cheers,
Simon




---- R context vs C++ exception example 


> dyn.load("stl.so")
> .Call("bar")
something went wrong somewhere in C++...
Warning: stack imbalance in '.Call', 2 then 4
NULL

-- what happens is that this really corrupts the R call stack since the C++ exception mechanism bypassed R's call stack so R is now is an inconsistent state. The same can be invoked vice-versa (and is more common - using error in C++ will do it) but that's harder to show because you would have to track C++ allocations to see that you're leaking objects all over the place. That is also the reason why it's hard to find unless it's too late (and things may *appear* to work for some time while they are not).


----stl.cc:

#include <Rinternals.h>
#include <vector>

using namespace std;

extern "C" SEXP foo() {
 vector <int> a;
 a.resize(-1);
 return R_NilValue;
}

extern "C" SEXP bar() {
 try {
   // lots of other C++ code here ...                                          
   eval(lang2(install(".Call"),mkString("foo")), R_GlobalEnv);
 } catch (...) {
   REprintf("something went wrong somewhere in C++...\n");
 }
 return R_NilValue;
}

> The fact that R has a C main may be problematic because C++ static
> initializers may not be called properly, but the fact that packages are
> usually loaded dynamically complicates this picture. The dynamic
> library itself may take care of calling the static initializers (I'm not
> sure about this, and this is probably OS-dependent). One possible
> work-around would be to compile the first few lines (a stub) of
> R main using the C++ compiler, leaving everything else as is
> and compiled using the C compiler (at least until CXXR is widely
> available).
> 
> Since C++ (and STL) are very popular it would be helpful for developers
> to have a better idea of the benefits and risks of using these tools
> with R.
> 
> Thanks,
> Dominick
> 
> On Fri, Apr 30, 2010 at 9:00 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Brian's answer was pretty exhaustive - just one more note that is indirectly related to memory management: C++ exception handling does interfere with R's error handling (and vice versa) so in general STL is very dangerous and best avoided in R. In addition, remember that regular local object rules are broken because you are not guaranteed to leave a function the regular way so there is a high danger of leaks and inconsistencies when using C++ memory management unless you specifically account for that. That said, I have written C++ code that works in R but you have to be very, very careful and think twice about using any complex C++ libraries since they are unlikely written in R-safe way.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> On Apr 30, 2010, at 1:03 AM, Dominick Samperi wrote:
>> 
>>> The R docs say that there are two methods that the C programmer can
>>> allocate memory, one where R automatically frees the memory on
>>> return from .C/.Call, and the other where the user takes responsibility
>>> for freeing the storage. Both methods involve using R-provided
>>> functions.
>>> 
>>> What happens when the user uses the standard "new" allocator?
>>> What about when a C++ application uses STL and that library
>>> allocates memory? In both of these cases the R-provided functions
>>> are not used (to my knowledge), yet I have not seen any problems.
>>> 
>>> How is the memory that R manages and garbage collects kept
>>> separate from the memory that is allocated on the C++ side
>>> quite independently of what R is doing?
>>> 
>>> Thanks,
>>> Dominick
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 


From murdoch at stats.uwo.ca  Fri Apr 30 20:16:27 2010
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 30 Apr 2010 14:16:27 -0400
Subject: [Rd] Most recent R manuals [Was: Likely disruption to R-devel
 builds on Windows]
In-Reply-To: <h2r971536df1004301111tdf0dadcdsbfee62ec3e204d16@mail.gmail.com>
References: <alpine.LFD.2.00.1004291656360.2955@gannet.stats.ox.ac.uk>
	<F1BDC7C9-1303-4532-B68F-FF781837B50B@r-project.org>
	<s2m971536df1004300616z4fd80933x859f0f8b90e3e84c@mail.gmail.com>
	<h2zf8e6ff051004300722i7cbba0a6nbe63da492cebf039@mail.gmail.com>
	<4BDAEBA0.1010903@stats.uwo.ca>
	<q2z971536df1004300748ucf5c4fc0t7d5b6d66c972a651@mail.gmail.com>
	<4BDAF0E3.1060003@stats.uwo.ca>
	<h2r971536df1004301111tdf0dadcdsbfee62ec3e204d16@mail.gmail.com>
Message-ID: <4BDB1E7B.4000104@stats.uwo.ca>

On 30/04/2010 2:11 PM, Gabor Grothendieck wrote:
> On Fri, Apr 30, 2010 at 11:01 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 30/04/2010 10:48 AM, Gabor Grothendieck wrote:
> >>
> >> On Fri, Apr 30, 2010 at 10:39 AM, Duncan Murdoch <murdoch at stats.uwo.ca>
> >> wrote:
> >> > On 30/04/2010 10:22 AM, hadley wickham wrote:
> >> >>
> >> >> Maybe Duncan could apply the same script that's being used for RNEWS
> >> >> to the manuals?  An RSS feed of changes to the manuals would be really
> >> >> useful.
> >> >>
> >> >
> >> > My script is very NEWS specific.  The manuals would be harder.  You
> >> > could
> >> > get the diffs from svn pretty easily, but displaying them would be
> >> > trickier:
> >> >  do you display the diffs in the .texi source, or convert to HTML and
> >> > display the diffs there, or what?  How much context around them?  Not
> >> > impossible, but not trivial.
>
> If you could mirror the manuals to googlecode you would automatically
> get an HTML interface to the diffs. e.g.
>
> http://code.google.com/p/sqldf/source/list
Go for it.  You've got more experience with googlecode than I do.

Duncan Murdoch


From djsamperi at gmail.com  Fri Apr 30 20:51:53 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 30 Apr 2010 14:51:53 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <F58D45DC-69AB-43C5-B6E4-CE5C87354DBE@r-project.org>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
	<491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
	<u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>
	<F58D45DC-69AB-43C5-B6E4-CE5C87354DBE@r-project.org>
Message-ID: <l2yd4cf43b61004301151vaa9e8229i48641cffbb53c653@mail.gmail.com>

Thanks for the clarification Simon,

I think it is safe (R-safe?) to say that if there are no exceptions or errors
on either side, then it is highly likely that everything is fine.

When there are errors or exceptions, it is probably NOT safe to try to
recover. Better to terminate the R session, insert some debug print statements
(or breakpoints), and try to figure out what caused the problem.

In other words, it works when it works.

This does not address the static initializer issue.

The good news is that R with C++/STL seems to work most of the
time, on all of the architectures for which CRAN builds a binary.

Thanks again,
Dominick

On Fri, Apr 30, 2010 at 2:12 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Dominick,
>
> On Apr 30, 2010, at 1:40 PM, Dominick Samperi wrote:
>
>> Just to be sure that I understand, are you suggesting that the R-safe way to do things is to not use STL, and to not use C++ memory management and exception handling? How can you leave a function in an irregular way without triggering a seg fault or something like that, in which case there is no chance for recovery anyway?
>>
>> In my experience the C++ exception stack seems to unwind properly before returning to R when there is an exception, and memory that is allocated by C++ functions seems to maintain its integrity and does not interfere with R's memory management.
>>
>> It would be helpful if you could specify what kind of interference you are referring to here between C++ exception handling and R's error handling, and why STL is dangerous and best avoided in R. I have used STL with R for a long time and have experienced no problems.
>>
>
> There are essentially two issues here that I had in mind.
>
> 1) C++ exception handling and R exceptions handling both use setjmp/longjmp with the assumption that no one else does the same. That assumption is voided when both are used so interleaving them will cause problems (you're fine if you can guarantee that they always stack but that's not always easy to achieve yet easy to miss).
>
> 2) C++ compilers assume that you cannot leave the context of a function in unusual ways. But you can, namely if an R error is raised. This affects (among others) locally allocated objects.
>
>
> On 1:
>
> You cannot interleave R error handling and C++ exceptions. For example if there is a chance of a C++ exception you must guarantee that the exception won't leave the R context that you are in. This is easily demonstrated because R check the consistency (see ex.1). Vice versa the consequences are not easily visible, because C++ provides no tracking, but is equally fatal. If you raise R exception from C++ it does not clean up whatever C++ exception context you were it and bypasses it. But there are even more grave consequences:
>
> On 2:
>
> If you any R error from within C++ code you'll break the assumption of C++ that it has control over the entry/exit point of a function. Take a really trivial example:
>
> void foo() {
> Object o;
> // some other code ....
> error("blah")
>
> normally, the life of o is controlled by C++ and it will correctly execute its destructor when you leave the function. However, the error call in R will cause it to bypass that, the object won't be destroyed even though it was allocated on the stack. Although it's obvious in the example above, pretty much all R API function can raise errors so the same applies to any R API call - direct or indirect. As a consequence you pretty much cannot call R API function from C++ unless you are very, very careful (don't forget that C++ does a lot of things behind your back such as initializing objects, exception contexts etc. which you technically have no control over).
>
>
> As I said in my post, you can write safe C++ code, but you have to be very careful. But the point about libraries is that you have no control over what they do, so you cannot know whether they will interact in a bad way with R or not. STL is an example where only the interface is defined, the implementations are not and vary by OS, compiler etc. This makes it pretty much impossible to use it reliably since the fact that it will work on one implementation doesn't mean that it will work on another since it is the implementation details that will bite you. (I know that we had reports of things breaking due to STL but I don't remember what implementation/OS it was)
>
> [The above issue are only the ones I was pointing out, there may be others that are not covered here].
>
> Cheers,
> Simon
>
>
>
>
> ---- R context vs C++ exception example
>
>
>> dyn.load("stl.so")
>> .Call("bar")
> something went wrong somewhere in C++...
> Warning: stack imbalance in '.Call', 2 then 4
> NULL
>
> -- what happens is that this really corrupts the R call stack since the C++ exception mechanism bypassed R's call stack so R is now is an inconsistent state. The same can be invoked vice-versa (and is more common - using error in C++ will do it) but that's harder to show because you would have to track C++ allocations to see that you're leaking objects all over the place. That is also the reason why it's hard to find unless it's too late (and things may *appear* to work for some time while they are not).
>
>
> ----stl.cc:
>
> #include <Rinternals.h>
> #include <vector>
>
> using namespace std;
>
> extern "C" SEXP foo() {
> ?vector <int> a;
> ?a.resize(-1);
> ?return R_NilValue;
> }
>
> extern "C" SEXP bar() {
> ?try {
> ? // lots of other C++ code here ...
> ? eval(lang2(install(".Call"),mkString("foo")), R_GlobalEnv);
> ?} catch (...) {
> ? REprintf("something went wrong somewhere in C++...\n");
> ?}
> ?return R_NilValue;
> }
>
>> The fact that R has a C main may be problematic because C++ static
>> initializers may not be called properly, but the fact that packages are
>> usually loaded dynamically complicates this picture. The dynamic
>> library itself may take care of calling the static initializers (I'm not
>> sure about this, and this is probably OS-dependent). One possible
>> work-around would be to compile the first few lines (a stub) of
>> R main using the C++ compiler, leaving everything else as is
>> and compiled using the C compiler (at least until CXXR is widely
>> available).
>>
>> Since C++ (and STL) are very popular it would be helpful for developers
>> to have a better idea of the benefits and risks of using these tools
>> with R.
>>
>> Thanks,
>> Dominick
>>
>> On Fri, Apr 30, 2010 at 9:00 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> Brian's answer was pretty exhaustive - just one more note that is indirectly related to memory management: C++ exception handling does interfere with R's error handling (and vice versa) so in general STL is very dangerous and best avoided in R. In addition, remember that regular local object rules are broken because you are not guaranteed to leave a function the regular way so there is a high danger of leaks and inconsistencies when using C++ memory management unless you specifically account for that. That said, I have written C++ code that works in R but you have to be very, very careful and think twice about using any complex C++ libraries since they are unlikely written in R-safe way.
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>> On Apr 30, 2010, at 1:03 AM, Dominick Samperi wrote:
>>>
>>>> The R docs say that there are two methods that the C programmer can
>>>> allocate memory, one where R automatically frees the memory on
>>>> return from .C/.Call, and the other where the user takes responsibility
>>>> for freeing the storage. Both methods involve using R-provided
>>>> functions.
>>>>
>>>> What happens when the user uses the standard "new" allocator?
>>>> What about when a C++ application uses STL and that library
>>>> allocates memory? In both of these cases the R-provided functions
>>>> are not used (to my knowledge), yet I have not seen any problems.
>>>>
>>>> How is the memory that R manages and garbage collects kept
>>>> separate from the memory that is allocated on the C++ side
>>>> quite independently of what R is doing?
>>>>
>>>> Thanks,
>>>> Dominick
>>>>
>>>> ? ? ? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>>
>
>


From simon.urbanek at r-project.org  Fri Apr 30 21:10:27 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 30 Apr 2010 15:10:27 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <l2yd4cf43b61004301151vaa9e8229i48641cffbb53c653@mail.gmail.com>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
	<491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
	<u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>
	<F58D45DC-69AB-43C5-B6E4-CE5C87354DBE@r-project.org>
	<l2yd4cf43b61004301151vaa9e8229i48641cffbb53c653@mail.gmail.com>
Message-ID: <1342B552-E181-45CC-9149-DD1C9C931959@r-project.org>

Dominick,

On Apr 30, 2010, at 2:51 PM, Dominick Samperi wrote:

> Thanks for the clarification Simon,
> 
> I think it is safe (R-safe?) to say that if there are no exceptions or errors
> on either side, then it is highly likely that everything is fine.
> 

I think so - at least on the exceptions topic. 


> When there are errors or exceptions, it is probably NOT safe to try to
> recover. Better to terminate the R session, insert some debug print statements
> (or breakpoints), and try to figure out what caused the problem.
> 

At the minimalistic level, yes. You can do better e.g. by tracking your objects, allocating only on the heap and so on, but the above will make sure there is no unexpected memory corruption or leakage (the hard way ;)).


> In other words, it works when it works.
> 
> This does not address the static initializer issue.
> 

Indeed. As I said, using heap objects (explicit initialization) does solve that issue, but you have to be again wary of other libraries which may still use static initializers.


> The good news is that R with C++/STL seems to work most of the
> time, on all of the architectures for which CRAN builds a binary.
> 

I would expect that as far as you can separate the setup part (creating output R objects etc.) from the C++ work (which won't callback into R and will catch all its exceptions) you should be safe. The danger is that in theory STL may create some object to keep beyond the scope of the call but hopefully it won't.

Cheers,
Simon



> 
> 
> On Fri, Apr 30, 2010 at 2:12 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Dominick,
>> 
>> On Apr 30, 2010, at 1:40 PM, Dominick Samperi wrote:
>> 
>>> Just to be sure that I understand, are you suggesting that the R-safe way to do things is to not use STL, and to not use C++ memory management and exception handling? How can you leave a function in an irregular way without triggering a seg fault or something like that, in which case there is no chance for recovery anyway?
>>> 
>>> In my experience the C++ exception stack seems to unwind properly before returning to R when there is an exception, and memory that is allocated by C++ functions seems to maintain its integrity and does not interfere with R's memory management.
>>> 
>>> It would be helpful if you could specify what kind of interference you are referring to here between C++ exception handling and R's error handling, and why STL is dangerous and best avoided in R. I have used STL with R for a long time and have experienced no problems.
>>> 
>> 
>> There are essentially two issues here that I had in mind.
>> 
>> 1) C++ exception handling and R exceptions handling both use setjmp/longjmp with the assumption that no one else does the same. That assumption is voided when both are used so interleaving them will cause problems (you're fine if you can guarantee that they always stack but that's not always easy to achieve yet easy to miss).
>> 
>> 2) C++ compilers assume that you cannot leave the context of a function in unusual ways. But you can, namely if an R error is raised. This affects (among others) locally allocated objects.
>> 
>> 
>> On 1:
>> 
>> You cannot interleave R error handling and C++ exceptions. For example if there is a chance of a C++ exception you must guarantee that the exception won't leave the R context that you are in. This is easily demonstrated because R check the consistency (see ex.1). Vice versa the consequences are not easily visible, because C++ provides no tracking, but is equally fatal. If you raise R exception from C++ it does not clean up whatever C++ exception context you were it and bypasses it. But there are even more grave consequences:
>> 
>> On 2:
>> 
>> If you any R error from within C++ code you'll break the assumption of C++ that it has control over the entry/exit point of a function. Take a really trivial example:
>> 
>> void foo() {
>> Object o;
>> // some other code ....
>> error("blah")
>> 
>> normally, the life of o is controlled by C++ and it will correctly execute its destructor when you leave the function. However, the error call in R will cause it to bypass that, the object won't be destroyed even though it was allocated on the stack. Although it's obvious in the example above, pretty much all R API function can raise errors so the same applies to any R API call - direct or indirect. As a consequence you pretty much cannot call R API function from C++ unless you are very, very careful (don't forget that C++ does a lot of things behind your back such as initializing objects, exception contexts etc. which you technically have no control over).
>> 
>> 
>> As I said in my post, you can write safe C++ code, but you have to be very careful. But the point about libraries is that you have no control over what they do, so you cannot know whether they will interact in a bad way with R or not. STL is an example where only the interface is defined, the implementations are not and vary by OS, compiler etc. This makes it pretty much impossible to use it reliably since the fact that it will work on one implementation doesn't mean that it will work on another since it is the implementation details that will bite you. (I know that we had reports of things breaking due to STL but I don't remember what implementation/OS it was)
>> 
>> [The above issue are only the ones I was pointing out, there may be others that are not covered here].
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> 
>> ---- R context vs C++ exception example
>> 
>> 
>>> dyn.load("stl.so")
>>> .Call("bar")
>> something went wrong somewhere in C++...
>> Warning: stack imbalance in '.Call', 2 then 4
>> NULL
>> 
>> -- what happens is that this really corrupts the R call stack since the C++ exception mechanism bypassed R's call stack so R is now is an inconsistent state. The same can be invoked vice-versa (and is more common - using error in C++ will do it) but that's harder to show because you would have to track C++ allocations to see that you're leaking objects all over the place. That is also the reason why it's hard to find unless it's too late (and things may *appear* to work for some time while they are not).
>> 
>> 
>> ----stl.cc:
>> 
>> #include <Rinternals.h>
>> #include <vector>
>> 
>> using namespace std;
>> 
>> extern "C" SEXP foo() {
>>  vector <int> a;
>>  a.resize(-1);
>>  return R_NilValue;
>> }
>> 
>> extern "C" SEXP bar() {
>>  try {
>>   // lots of other C++ code here ...
>>   eval(lang2(install(".Call"),mkString("foo")), R_GlobalEnv);
>>  } catch (...) {
>>   REprintf("something went wrong somewhere in C++...\n");
>>  }
>>  return R_NilValue;
>> }
>> 
>>> The fact that R has a C main may be problematic because C++ static
>>> initializers may not be called properly, but the fact that packages are
>>> usually loaded dynamically complicates this picture. The dynamic
>>> library itself may take care of calling the static initializers (I'm not
>>> sure about this, and this is probably OS-dependent). One possible
>>> work-around would be to compile the first few lines (a stub) of
>>> R main using the C++ compiler, leaving everything else as is
>>> and compiled using the C compiler (at least until CXXR is widely
>>> available).
>>> 
>>> Since C++ (and STL) are very popular it would be helpful for developers
>>> to have a better idea of the benefits and risks of using these tools
>>> with R.
>>> 
>>> Thanks,
>>> Dominick
>>> 
>>> On Fri, Apr 30, 2010 at 9:00 AM, Simon Urbanek
>>> <simon.urbanek at r-project.org> wrote:
>>>> Brian's answer was pretty exhaustive - just one more note that is indirectly related to memory management: C++ exception handling does interfere with R's error handling (and vice versa) so in general STL is very dangerous and best avoided in R. In addition, remember that regular local object rules are broken because you are not guaranteed to leave a function the regular way so there is a high danger of leaks and inconsistencies when using C++ memory management unless you specifically account for that. That said, I have written C++ code that works in R but you have to be very, very careful and think twice about using any complex C++ libraries since they are unlikely written in R-safe way.
>>>> 
>>>> Cheers,
>>>> Simon
>>>> 
>>>> 
>>>> On Apr 30, 2010, at 1:03 AM, Dominick Samperi wrote:
>>>> 
>>>>> The R docs say that there are two methods that the C programmer can
>>>>> allocate memory, one where R automatically frees the memory on
>>>>> return from .C/.Call, and the other where the user takes responsibility
>>>>> for freeing the storage. Both methods involve using R-provided
>>>>> functions.
>>>>> 
>>>>> What happens when the user uses the standard "new" allocator?
>>>>> What about when a C++ application uses STL and that library
>>>>> allocates memory? In both of these cases the R-provided functions
>>>>> are not used (to my knowledge), yet I have not seen any problems.
>>>>> 
>>>>> How is the memory that R manages and garbage collects kept
>>>>> separate from the memory that is allocated on the C++ side
>>>>> quite independently of what R is doing?
>>>>> 
>>>>> Thanks,
>>>>> Dominick
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>> 
>>>> 
>>> 
>>> 
>> 
>> 
> 
> 


From djsamperi at gmail.com  Fri Apr 30 22:38:11 2010
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 30 Apr 2010 16:38:11 -0400
Subject: [Rd] Memory allocation in C/C++ vs R?
In-Reply-To: <1342B552-E181-45CC-9149-DD1C9C931959@r-project.org>
References: <m2qd4cf43b61004292203x8265d834wb1d42c483813d55d@mail.gmail.com>
	<491D8740-466D-4442-B6BE-942A9C423CD0@r-project.org>
	<u2vd4cf43b61004301040jc5a99578k9b44b41e7b414b0a@mail.gmail.com>
	<F58D45DC-69AB-43C5-B6E4-CE5C87354DBE@r-project.org>
	<l2yd4cf43b61004301151vaa9e8229i48641cffbb53c653@mail.gmail.com>
	<1342B552-E181-45CC-9149-DD1C9C931959@r-project.org>
Message-ID: <p2rd4cf43b61004301338j1d90aa24v9262f4cf1f7d9f3d@mail.gmail.com>

> Indeed. As I said, using heap objects (explicit initialization) does solve that issue, but you have to be again wary of other libraries which may still use static initializers.

I just did a little test and found, in the case of gcc/g++, that a
main C main program linked with a C++ library
that has static intializers works just fine. The sequence of commands was:

g++ -fpic -c mylib.cpp
g++ -shared -o foo.so mylib.o
gcc mylibtest foo.so

It appears that the runtime system / shared library loading process
makes sure that the static initializers for
classes defined in mylib.so are run before the C program defined in
mylibtest.c is started.

Of course, we knew this already ("it works when it works"), but this
shows, at least in the case of gcc/g++,
what is going on. But as you have pointed out, the whole process is
OS-dependent and may not work
as smoothly on other platforms.

Dominnick


From lwollman at symmetricom.com  Fri Apr 30 18:46:59 2010
From: lwollman at symmetricom.com (Lester Wollman)
Date: Fri, 30 Apr 2010 09:46:59 -0700
Subject: [Rd] Possible bug in POSIX classes for R 2.11.0?
Message-ID: <EA27D7728FE1E84BB71A329047339137045E39E8@sjmail2.symmetricom.com>

To the R development team;

I found an unusual behavior in zoo when I upgraded to R 2.11.0 - it abruptly terminated when I performed certain operations on large zoo objects.  I sent an e-mail to Achim Zeileis and he said this was a potential bug that I should report to the R development team.  The details are given below in the thread below.  Basically, I can crash R with this code:

library(zoo)
x <- runif(140000, 2009, 2010)
x <- as.yearmon(x)
table(x)

This will not crash with a vector of size 130000.

Achim got it to crash with the following code that did not use zoo:

x <- rep(as.Date("1970-01-01"), 140000)
y <- as.POSIXlt(x)
z <- format(y, "%d")

I did find a work around, so this is no longer an immediate problem for me, but it would be better if the problem didn't exist in the first place.  Thank you for your help.

Lester Wollman
Corporate Statistician
Symmetricom, Inc.
Lwollman at symmetricom.com



-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at] 
Sent: Thursday, April 29, 2010 1:16 PM
To: Lester Wollman
Subject: Re: Unusual behavior of zoo and R2.11.0 - simple operation on large zoo object crashes R

Lester,

thanks for the report. The problem does not seem to be in "zoo" but in the 
new POSIX classes and/or their their coercion from "Date".

The following should reproduce your crash:

x <- rep(as.Date("1970-01-01"), 140000)
y <- as.POSIXlt(x)
z <- format(y, "%d")

The reason is probably that R-core changed the internals of all the POSIX 
stuff. Furthermore, this problem appears to be fixed in 2.12.0 (the 
current devel version). Maybe you can ask on R-devel whether this is a 
know issue (my guess is that it is).

Thanks for the report && best wishes,
Z

On Thu, 29 Apr 2010, Lester Wollman wrote:

> 
> Achim,
> 
> ?
> 
> I found unusual behavior, or even possibly a bug, ?in zoo.? When I run the
> code below, R crashes.? There is no error message,? R simply exits with no
> warning.
> 
> ?
> 
> ?
> 
> library(zoo)
> 
> x <- runif(140000, 2009, 2010)? ???# Random days in 2009
> 
> x <- as.yearmon(x)?????????????? ??# This works
> 
> table(x)???????????????????????? ??# ?This crashes.?print(x) also crashes R. summary(x) does not
> 
> 
> ?
> 
> ?
> 
> However, if I change the number of random dates to 130000, there is no
> problem.
> 
> ?
> 
> I have been using zoo for a few years with no problems, ?including using
> code similar to the one above.? I did just upgrade to R 2.11.0 and this is
> my first use of zoo for a large vector since the upgrade.
> 
> ?
> 
> I cannot tell if the problem is with zoo or R or my machine.? I tried
> installing zoo from CRAN instead of R-Forge, but that did not help.?
> Increasing the memory limit to 3G did not help either.
> 
> ?
> 
> I attached relevant (and irrelevant) system information below.? I am using R
> with Tinn-R and Tinn-R loads some packages (Hmisc, R2HTML, etc.)
> 
> ?
> 
> Thank you for your help.
> 
> ?
> 
> ?
> 
> Lester Wollman
> 
> Corporate Statistician
> 
> Symmetricom, Inc.
> 
> lwollman at symmetricom.com
> 
> ?
> 
> ?
> 
> ?
> 
> ?
> 
> > sessionInfo()
> 
> ?
> 
> R version 2.11.0 (2010-04-22)
> 
> i386-pc-mingw32
> 
> ?
> 
> locale:
> 
> [1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
> States.1252??? LC_MONETARY=English_United States.1252
> 
> [4] LC_NUMERIC=C?????????????????????????? LC_TIME=English_United
> States.1252???
> 
> ?
> 
> attached base packages:
> 
> [1] grDevices datasets? splines?? graphics? stats???? tcltk???? utils????
> methods?? base????
> 
> ?
> 
> other attached packages:
> 
> [1] svSocket_0.9-48 TinnR_1.0.3???? R2HTML_2.0.0??? Hmisc_3.7-0????
> survival_2.35-8
> 
> ?
> 
> loaded via a namespace (and not attached):
> 
> [1] cluster_1.12.3 grid_2.11.0??? lattice_0.18-5 svMisc_0.9-57
> 
> ?
> 
> ?
> 
> System Information:
> 
> Windows XP Professional Version 2002 Service Pack 3
> 
> ?
> 
> Computer Information:
> 
> Dell with Intel CPU
> 
> T2600 @ 2.16 GHz, 1G of RAM
> 
> ?
> 
> ?
> 
> ?
> 
> zoo information
> 
> > packageDescription("zoo")
> 
> Package: zoo
> 
> Version: 1.6-3
> 
> Date: 2010-02-22
> 
> Title: Z's ordered observations
> 
> Author: Achim Zeileis, Gabor Grothendieck, Felix Andrews
> 
> Maintainer: Achim Zeileis <Achim.Zeileis at R-project.org>
> 
> Description: An S3 class with methods for totally ordered indexed
> observations. It is particularly aimed at irregular time series of numeric
> vectors/matrices and factors. zoo's key design goals are independence of a
> particular index/date/time class and consistency with ts and base R by
> providing methods to extend standard generics.
> 
> Depends: R (>= 2.10.0), stats
> 
> Suggests: coda, chron, DAAG, fCalendar, fSeries, fts, its, lattice,
> strucchange, timeDate, timeSeries, tis, tseries, xts
> 
> Imports: stats, utils, graphics, grDevices, lattice (>= 0.18-1)
> 
> LazyLoad: yes
> 
> License: GPL-2
> 
> URL: http://R-Forge.R-project.org/projects/zoo/
> 
> Repository: R-Forge
> 
> Repository/R-Forge/Project: zoo
> 
> Repository/R-Forge/Revision: 688
> 
> Date/Publication: 2010-03-20 02:29:04
> 
> Packaged: 2010-03-20 21:59:26 UTC; rforge
> 
> Built: R 2.11.0; ; 2010-03-22 14:03:33 UTC; windows
> 
> ?
> 
> -- File: C:/PROGRA~1/STATIS~1/R2110/library/zoo/Meta/package.rds
> 
> 
>


