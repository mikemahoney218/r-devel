From ripley at stats.ox.ac.uk  Sun Jan  1 14:28:48 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Jan 2017 13:28:48 +0000
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
Message-ID: <ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>

On 29/12/2016 15:55, Simon Urbanek wrote:
> The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h. Should be now fixed in R-devel - please check if that works for you.

Rconfig.h would be appropriate if Rinterface.h is being included from C 
code using the same compiler as used for R.  But as Rinterface.h is 
intended for use by alternative front ends there is no guarantee that 
they use the same compiler (and some use C++).

This was documented in the manual:

'Note that uintptr_t is a C99 type for which a substitute is defined in 
R, so your code needs to define HAVE_UINTPTR_T appropriately.'

AFAICS if you comply, there will not be a conflict.

Also note that is only an issue if CSTACK_DEFNS is defined, not the 
default and not mentioned here.



> Thanks,
> Simon
>
>
>
>> On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com> wrote:
>>
>> Hi,
>>
>> I was recently pointed out that a definition in Rinterface.h can be conflicting
>> with a definition in stdint.h:
>>
>> /usr/include/R/Rinterface.h has:
>> typedef unsigned long uintptr_t;
>>
>> /usr/include/stdint.h has:
>> typedef unsigned int uintptr_t;
>> (when 32bit platform complete definition is:
>>
>> #if __WORDSIZE == 64
>> # ifndef __intptr_t_defined
>> typedef long int                intptr_t;
>> #  define __intptr_t_defined
>> # endif
>> typedef unsigned long int       uintptr_t;
>> #else
>> # ifndef __intptr_t_defined
>> typedef int                     intptr_t;
>> #  define __intptr_t_defined
>> # endif
>> typedef unsigned int            uintptr_t;
>> #endif
>>
>> )
>>
>> Is this expected ? Shouldn't R rely on the definition in stdint.h

But there need not be one in stdint.h, as the type is optional in 
C99/C11/C++11 and likely not present in C++98.

>> rather than define its own ?
>>
>>
>> (report for the issue:
>> https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-compile-with-python-360-on-32
>> )
>>
>>
>> Laurent
>>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From edd at debian.org  Sun Jan  1 19:29:44 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 1 Jan 2017 12:29:44 -0600
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
	<ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
Message-ID: <22633.19096.701756.331496@max.nulle.part>


On 1 January 2017 at 13:28, Prof Brian Ripley wrote:
| On 29/12/2016 15:55, Simon Urbanek wrote:
| > The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h. Should be now fixed in R-devel - please check if that works for you.
| 
| Rconfig.h would be appropriate if Rinterface.h is being included from C 
| code using the same compiler as used for R.  But as Rinterface.h is 
| intended for use by alternative front ends there is no guarantee that 
| they use the same compiler (and some use C++).
| 
| This was documented in the manual:
| 
| 'Note that uintptr_t is a C99 type for which a substitute is defined in 
| R, so your code needs to define HAVE_UINTPTR_T appropriately.'
| 
| AFAICS if you comply, there will not be a conflict.
| 
| Also note that is only an issue if CSTACK_DEFNS is defined, not the 
| default and not mentioned here.

Relatedly: Any good way about "using the same compiler as used for R"?

I write one package exposing some internal R API for wider use
in a package (RApiSerialize, used eg by RcppRedis) and like that scheme. I
might do the same for date/time/timezone logic but this hinges on these
settings (among other things).

Any good ideas how to go about this?  So far I mostly use 'don't ask don't
tell' and rely on the compiler to actually fail when something doesn't hold.
We can probably do better...

Best wishes to all useRs and devRs in 2017.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From lgautier at gmail.com  Sun Jan  1 23:12:53 2017
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 1 Jan 2017 17:12:53 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
	<ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
Message-ID: <CA+JCgN0MVVkWU2-bp900K2OiPeaVuki0HjyJULssJBVMysNGAw@mail.gmail.com>

2017-01-01 8:28 GMT-05:00 Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> On 29/12/2016 15:55, Simon Urbanek wrote:
>
>> The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback
>> with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h.
>> Should be now fixed in R-devel - please check if that works for you.
>>
>
> Rconfig.h would be appropriate if Rinterface.h is being included from C
> code using the same compiler as used for R.  But as Rinterface.h is
> intended for use by alternative front ends there is no guarantee that they
> use the same compiler (and some use C++).
>

Isn't the changing libc/glibc not recommended anyway (without also changing
to a matching kernel) ? If so, is this a realistic concern compared to the
compiler version issues (mentioned by Dirk) ? In that case, what about
simplifying the documentation and usage to "use the same compiler or
undefined behaviour may occur"


> This was documented in the manual:
>
> 'Note that uintptr_t is a C99 type for which a substitute is defined in R,
> so your code needs to define HAVE_UINTPTR_T appropriately.'
>
> AFAICS if you comply, there will not be a conflict.
>
> Also note that is only an issue if CSTACK_DEFNS is defined, not the
> default and not mentioned here.
>
>
>
>
> Thanks,
>> Simon
>>
>>
>>
>> On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com> wrote:
>>> (...)
>>>
>>> Is this expected ? Shouldn't R rely on the definition in stdint.h
>>>
>>
> But there need not be one in stdint.h, as the type is optional in
> C99/C11/C++11 and likely not present in C++98.


AFAIUI stdin.h is part of C99:
https://en.wikipedia.org/wiki/C_standard_library#Header_files

While at it, it is not exactly like C99 is the latest thing in town.
Wouldn't relying on it give an opportunity to simplify the code base ?




Laurent



>
> rather than define its own ?
>>>
>>>
>>> (report for the issue:
>>> https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-compile
>>> -with-python-360-on-32
>>> )
>>>
>>>
>>> Laurent
>>>
>>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
>

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Mon Jan  2 01:42:04 2017
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 1 Jan 2017 19:42:04 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <CA+JCgN0MVVkWU2-bp900K2OiPeaVuki0HjyJULssJBVMysNGAw@mail.gmail.com>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
	<ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
	<CA+JCgN0MVVkWU2-bp900K2OiPeaVuki0HjyJULssJBVMysNGAw@mail.gmail.com>
Message-ID: <936D1F9E-EB13-4D35-AA0D-F46492C22801@r-project.org>


> On Jan 1, 2017, at 5:12 PM, Laurent Gautier <lgautier at gmail.com> wrote:
> 
> 
> 
> 2017-01-01 8:28 GMT-05:00 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On 29/12/2016 15:55, Simon Urbanek wrote:
> The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h. Should be now fixed in R-devel - please check if that works for you.
> 
> Rconfig.h would be appropriate if Rinterface.h is being included from C code using the same compiler as used for R.  But as Rinterface.h is intended for use by alternative front ends there is no guarantee that they use the same compiler (and some use C++).
> 
> Isn't the changing libc/glibc not recommended anyway (without also changing to a matching kernel) ? If so, is this a realistic concern compared to the compiler version issues (mentioned by Dirk) ? In that case, what about simplifying the documentation and usage to "use the same compiler or undefined behaviour may occur"
> 

Unfortunately people often mix up different compilers (note this has nothing to do with glibc or the kernel!) - mixing up C and C++ is very common. Also there are specialized compilers for some applications (MPI etc.). So, yes, it is a realistic concern that I've seen more often than you'd think.


> 
> This was documented in the manual:
> 
> 'Note that uintptr_t is a C99 type for which a substitute is defined in R, so your code needs to define HAVE_UINTPTR_T appropriately.'
> 
> AFAICS if you comply, there will not be a conflict.
> 
> Also note that is only an issue if CSTACK_DEFNS is defined, not the default and not mentioned here.
> 
> 
> 
> 
> Thanks,
> Simon
> 
> 
> 
> On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com> wrote:
> (...)
> 
> Is this expected ? Shouldn't R rely on the definition in stdint.h
> 
> But there need not be one in stdint.h, as the type is optional in C99/C11/C++11 and likely not present in C++98.
> 
> AFAIUI stdin.h is part of C99: https://en.wikipedia.org/wiki/C_standard_library#Header_files 
> 
> While at it, it is not exactly like C99 is the latest thing in town. Wouldn't relying on it give an opportunity to simplify the code base ?
> 
> 
> 
> 
> Laurent
> 
> 
> 
> 
> rather than define its own ?
> 
> 
> (report for the issue:
> https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-compile-with-python-360-on-32
> )
> 
> 
> Laurent
> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 


From lgautier at gmail.com  Mon Jan  2 01:50:48 2017
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 1 Jan 2017 19:50:48 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <936D1F9E-EB13-4D35-AA0D-F46492C22801@r-project.org>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
	<ebab4eb6-e739-badb-1af1-ffc77bbb5847@stats.ox.ac.uk>
	<CA+JCgN0MVVkWU2-bp900K2OiPeaVuki0HjyJULssJBVMysNGAw@mail.gmail.com>
	<936D1F9E-EB13-4D35-AA0D-F46492C22801@r-project.org>
Message-ID: <CA+JCgN0pxaN32r9xbZb4nSF6kGri7zv9pWneXCmVGpA_XpvpNw@mail.gmail.com>

My comment is about the definition of HAVE_UINTPTR_T in Rconfig.h. stdint.h
is coming with (g)libc, therefore unlikely to change/appear/disappear
(unless kernel and a bit of the OS changes), therefore may not be a
realistic concern. On the other hand mixing compilers is frequent, but this
is not doing much to prevent it.

2017-01-01 19:42 GMT-05:00 Simon Urbanek <simon.urbanek at r-project.org>:

>
> > On Jan 1, 2017, at 5:12 PM, Laurent Gautier <lgautier at gmail.com> wrote:
> >
> >
> >
> > 2017-01-01 8:28 GMT-05:00 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> > On 29/12/2016 15:55, Simon Urbanek wrote:
> > The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback
> with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h.
> Should be now fixed in R-devel - please check if that works for you.
> >
> > Rconfig.h would be appropriate if Rinterface.h is being included from C
> code using the same compiler as used for R.  But as Rinterface.h is
> intended for use by alternative front ends there is no guarantee that they
> use the same compiler (and some use C++).
> >
> > Isn't the changing libc/glibc not recommended anyway (without also
> changing to a matching kernel) ? If so, is this a realistic concern
> compared to the compiler version issues (mentioned by Dirk) ? In that case,
> what about simplifying the documentation and usage to "use the same
> compiler or undefined behaviour may occur"
> >
>
> Unfortunately people often mix up different compilers (note this has
> nothing to do with glibc or the kernel!) - mixing up C and C++ is very
> common. Also there are specialized compilers for some applications (MPI
> etc.). So, yes, it is a realistic concern that I've seen more often than
> you'd think.
>
>
> >
> > This was documented in the manual:
> >
> > 'Note that uintptr_t is a C99 type for which a substitute is defined in
> R, so your code needs to define HAVE_UINTPTR_T appropriately.'
> >
> > AFAICS if you comply, there will not be a conflict.
> >
> > Also note that is only an issue if CSTACK_DEFNS is defined, not the
> default and not mentioned here.
> >
> >
> >
> >
> > Thanks,
> > Simon
> >
> >
> >
> > On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com>
> wrote:
> > (...)
> >
> > Is this expected ? Shouldn't R rely on the definition in stdint.h
> >
> > But there need not be one in stdint.h, as the type is optional in
> C99/C11/C++11 and likely not present in C++98.
> >
> > AFAIUI stdin.h is part of C99: https://en.wikipedia.org/wiki/
> C_standard_library#Header_files
> >
> > While at it, it is not exactly like C99 is the latest thing in town.
> Wouldn't relying on it give an opportunity to simplify the code base ?
> >
> >
> >
> >
> > Laurent
> >
> >
> >
> >
> > rather than define its own ?
> >
> >
> > (report for the issue:
> > https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-
> compile-with-python-360-on-32
> > )
> >
> >
> > Laurent
> >
> >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Emeritus Professor of Applied Statistics, University of Oxford
> >
>
>

	[[alternative HTML version deleted]]


From s.starke at hzdr.de  Mon Jan  2 08:53:03 2017
From: s.starke at hzdr.de (Sebastian Starke)
Date: Mon, 2 Jan 2017 08:53:03 +0100
Subject: [Rd] varimax implementation in stats package
Message-ID: <997c2d29-d3fb-e930-bfe7-fc93b4fbdbfb@hzdr.de>

Hello,

recently I was looking at the implementation of the "varimax" rotation 
procedure from the "stats" package and to me it looks quite different 
from the algorithm originally suggested by Kaiser in 1958.

The R procedure iteratively uses singular value decompositions of some 
matrices whereas Kaiser proposed to iteratively compute rotation 
matrices between all pairs of factors which does not seem to happen ( at 
least not explicitely ) in the R version.

My question now is whether R uses a completely different approach than 
Kaiser (if so, then could you please point me to a publication or 
explanation of the algorithm used since I wasn't able to find any) or if 
it is the Kaiser method just well hidden under quite a bit of clever 
linear algebra ( explanations on why the methods are equal is also 
appreciated).

Thanks for any hints or clarifications!

With best regards

Sebastian Starke


From pdalgd at gmail.com  Mon Jan  2 15:16:07 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Jan 2017 15:16:07 +0100
Subject: [Rd] varimax implementation in stats package
In-Reply-To: <997c2d29-d3fb-e930-bfe7-fc93b4fbdbfb@hzdr.de>
References: <997c2d29-d3fb-e930-bfe7-fc93b4fbdbfb@hzdr.de>
Message-ID: <A1EFF837-49A9-4C85-BB2F-DDD0F03CF1CB@gmail.com>

factanal() was originally in MASS which is support software for Venables & Ripley (2002). They have Bartholomew & Knott (1999) as the main reference for factor analysis, so that would be a place to look (I don't have it to hand). 

At any rate, varimax optimizes a well-defined criterion, so the "only" thing to do is to verify that the algorithm does that, not that it is somehow equivalent to any other algorithm. On the face of it, I would guess that it is derived ab initio, there is nothing pairwise about the code.

-pd

On 02 Jan 2017, at 08:53 , Sebastian Starke <s.starke at hzdr.de> wrote:

> Hello,
> 
> recently I was looking at the implementation of the "varimax" rotation procedure from the "stats" package and to me it looks quite different from the algorithm originally suggested by Kaiser in 1958.
> 
> The R procedure iteratively uses singular value decompositions of some matrices whereas Kaiser proposed to iteratively compute rotation matrices between all pairs of factors which does not seem to happen ( at least not explicitely ) in the R version.
> 
> My question now is whether R uses a completely different approach than Kaiser (if so, then could you please point me to a publication or explanation of the algorithm used since I wasn't able to find any) or if it is the Kaiser method just well hidden under quite a bit of clever linear algebra ( explanations on why the methods are equal is also appreciated).
> 
> Thanks for any hints or clarifications!
> 
> With best regards
> 
> Sebastian Starke
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From henrik.bengtsson at gmail.com  Mon Jan  2 20:29:22 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 2 Jan 2017 11:29:22 -0800
Subject: [Rd] utils::ls.str(): Partial argument name 'digits' to seq()
	(should be digits.d?)
Message-ID: <CAFDcVCSrm0TV2w5v4wb+rcyRH7QEdCbHVB-7KKuk9CVM0BK6gw@mail.gmail.com>

Should utils::ls.str() be updated as:

svn diff src/library/utils/R/str.R
Index: src/library/utils/R/str.R
===================================================================
--- src/library/utils/R/str.R (revision 71879)
+++ src/library/utils/R/str.R (working copy)
@@ -622,7 +622,7 @@
         args$digits.d <- NULL
     }
     strargs <- c(list(max.level = max.level, give.attr = give.attr,
-                      digits = digits), args)
+                      digits.d = digits), args)
     for(nam in x) {
  cat(nam, ": ")
  ## check missingness, e.g. inside debug(.) :

Example:

$ R --quiet --vanilla
> options(warnPartialMatchArgs = TRUE, warn = 2)
> x <- 1
> ls.str()
x : Error in str.default(o, ...) :
  (converted from warning) partial argument match of 'digits' to 'digits.d'
> traceback()
10: doWithOneRestart(return(expr), restart)
9: withOneRestart(expr, restarts[[1L]])
8: withRestarts({
       .Internal(.signalCondition(simpleWarning(msg, call), msg,
           call))
       .Internal(.dfltWarn(msg, call))
   }, muffleWarning = function() NULL)
7: .signalSimpleWarning("partial argument match of 'digits' to 'digits.d'",
       quote(str.default(o, ...)))
6: str.default(o, ...)
5: str(o, ...)
4: (function (...)
   str(o, ...))(max.level = 1, give.attr = FALSE, digits = 3)
3: do.call(strO, strargs, quote = is.call(o) || is.symbol(o))
2: print.ls_str(x)
1: function (x, ...)
   UseMethod("print")(x)

/Henrik


From maechler at stat.math.ethz.ch  Tue Jan  3 09:42:40 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Jan 2017 09:42:40 +0100
Subject: [Rd] utils::ls.str(): Partial argument name 'digits' to
	seq()	(should be digits.d?)
In-Reply-To: <CAFDcVCSrm0TV2w5v4wb+rcyRH7QEdCbHVB-7KKuk9CVM0BK6gw@mail.gmail.com>
References: <CAFDcVCSrm0TV2w5v4wb+rcyRH7QEdCbHVB-7KKuk9CVM0BK6gw@mail.gmail.com>
Message-ID: <22635.25600.990336.324982@stat.math.ethz.ch>

You are right (though picky).  I have updated it now.

Thank you Henrik!
Martin

> Should utils::ls.str() be updated as:

> svn diff src/library/utils/R/str.R
> Index: src/library/utils/R/str.R
> ===================================================================
> --- src/library/utils/R/str.R (revision 71879)
> +++ src/library/utils/R/str.R (working copy)
> @@ -622,7 +622,7 @@
>          args$digits.d <- NULL
>      }
>      strargs <- c(list(max.level = max.level, give.attr = give.attr,
> -                      digits = digits), args)
> +                      digits.d = digits), args)
>      for(nam in x) {
>   cat(nam, ": ")


[.......]


From lukas.stadler at oracle.com  Tue Jan  3 13:26:16 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Tue, 3 Jan 2017 13:26:16 +0100
Subject: [Rd] .Internal for functions in distn.R
Message-ID: <89385F26-8396-4172-8FF3-B34C025B4A91@oracle.com>

Hi,

the functions in distn.R were converted from .Internal to .External ([1], in 2012), and to .Call ([2], in 2014).
They are still listed as .Internal in names.c, although they are not used in that way.

Shouldn?t they be removed?
There?s quite some simplification to be had, e.g., do_math3 could go away and do_math2 would be simpler.

If that makes sense (I may be missing something?), I?d be happy to create a patch that does this.

Best,
 Lukas

[1] https://github.com/wch/r-source/commit/e430853d37cda69505e7452ddceb06a2008821d2 <https://github.com/wch/r-source/commit/e430853d37cda69505e7452ddceb06a2008821d2>
[2] https://github.com/wch/r-source/commit/34fa67ca4c1dae13ed6a2ad74af7dbb27c8f3cb2 <https://github.com/wch/r-source/commit/34fa67ca4c1dae13ed6a2ad74af7dbb27c8f3cb2>
	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Tue Jan  3 14:21:25 2017
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 3 Jan 2017 07:21:25 -0600 (CST)
Subject: [Rd] .Internal for functions in distn.R
In-Reply-To: <89385F26-8396-4172-8FF3-B34C025B4A91@oracle.com>
References: <89385F26-8396-4172-8FF3-B34C025B4A91@oracle.com>
Message-ID: <alpine.DEB.2.20.1701030720300.2652@luke-Latitude>

The .Internal support in the C code is still i use for experimental
purposes.

Best,

luke

On Tue, 3 Jan 2017, Lukas Stadler wrote:

> Hi,
>
> the functions in distn.R were converted from .Internal to .External ([1], in 2012), and to .Call ([2], in 2014).
> They are still listed as .Internal in names.c, although they are not used in that way.
>
> Shouldn?t they be removed?
> There?s quite some simplification to be had, e.g., do_math3 could go away and do_math2 would be simpler.
>
> If that makes sense (I may be missing something?), I?d be happy to create a patch that does this.
>
> Best,
> Lukas
>
> [1] https://github.com/wch/r-source/commit/e430853d37cda69505e7452ddceb06a2008821d2 <https://github.com/wch/r-source/commit/e430853d37cda69505e7452ddceb06a2008821d2>
> [2] https://github.com/wch/r-source/commit/34fa67ca4c1dae13ed6a2ad74af7dbb27c8f3cb2 <https://github.com/wch/r-source/commit/34fa67ca4c1dae13ed6a2ad74af7dbb27c8f3cb2>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From pdalgd at gmail.com  Tue Jan  3 15:36:07 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 3 Jan 2017 15:36:07 +0100
Subject: [Rd] [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
Message-ID: <387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>

Possibly so. 

However, the ZeroMQ libraries do exist for Windows, so it might be possible to get the package working there. However, CRAN probably won't have the libraries, so cannot produce a binary package, and it is also quite possible that the package author is not a Windows person. 

At the very least, you'll need some familiarity with the Windows toolchain and be prepared to apply a fair amount of elbow grease.

-pd

(crosspost to r-help removed)

On 29 Dec 2016, at 22:04 , Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear Jeff,
> 
> Thank you for your fast and kind reply. When you say that you do not think
> this can be done on windows, then I would have to use something like Ubuntu
> or Linux?
> 
> Best regards
> 
> Paul
> 
> 2016-12-29 16:00 GMT-05:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> 
>> Read the system requirements [1]. I don't think you can do this on windows.
>> 
>> [1] https://cran.r-project.org/web/packages/rzmq/index.html
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On December 29, 2016 12:23:26 PM PST, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>> After connecting to a mirror, I typed the following command:
>>> 
>>> install.packages("rzqm")
>>> 
>>> but I received the following message:
>>> 
>>> ERROR: compilation failed for package 'rzmq'
>>> 
>>> removing 'E:/Documents/R/win-library/3.3/rzmq'
>>> 
>>> package which is only available in source form, and may need
>>> compilation of
>>> C/C++/Fortran: 'rzmq'
>>> These will not be installed
>>> 
>>> The computer environment is Windows 8 64x bits
>>> 
>>> 
>>> Any help and/or guidance will be greatly appreciated
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From armstrong.whit at gmail.com  Tue Jan  3 15:53:22 2017
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 3 Jan 2017 09:53:22 -0500
Subject: [Rd] [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
	<387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
Message-ID: <CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>

Hi, Paul.

I maintian the rzmq project.

love to get it running on windows, but zmq doesn't play nicely with R's
mingw.

These guys have taken the approach of building the entire zmq library
inside the R package:
https://github.com/snoweye/pbdZMQ

I suggest you give it a try. or if you want to attempt to compile libzmq
sources for windows w/ R's mingw, that would be welcome.

-Whit


On Tue, Jan 3, 2017 at 9:36 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Possibly so.
>
> However, the ZeroMQ libraries do exist for Windows, so it might be
> possible to get the package working there. However, CRAN probably won't
> have the libraries, so cannot produce a binary package, and it is also
> quite possible that the package author is not a Windows person.
>
> At the very least, you'll need some familiarity with the Windows toolchain
> and be prepared to apply a fair amount of elbow grease.
>
> -pd
>
> (crosspost to r-help removed)
>
> On 29 Dec 2016, at 22:04 , Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > Dear Jeff,
> >
> > Thank you for your fast and kind reply. When you say that you do not
> think
> > this can be done on windows, then I would have to use something like
> Ubuntu
> > or Linux?
> >
> > Best regards
> >
> > Paul
> >
> > 2016-12-29 16:00 GMT-05:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> >
> >> Read the system requirements [1]. I don't think you can do this on
> windows.
> >>
> >> [1] https://cran.r-project.org/web/packages/rzmq/index.html
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On December 29, 2016 12:23:26 PM PST, Paul Bernal <
> paulbernal07 at gmail.com>
> >> wrote:
> >>> After connecting to a mirror, I typed the following command:
> >>>
> >>> install.packages("rzqm")
> >>>
> >>> but I received the following message:
> >>>
> >>> ERROR: compilation failed for package 'rzmq'
> >>>
> >>> removing 'E:/Documents/R/win-library/3.3/rzmq'
> >>>
> >>> package which is only available in source form, and may need
> >>> compilation of
> >>> C/C++/Fortran: 'rzmq'
> >>> These will not be installed
> >>>
> >>> The computer environment is Windows 8 64x bits
> >>>
> >>>
> >>> Any help and/or guidance will be greatly appreciated
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From mick.jordan at oracle.com  Tue Jan  3 16:57:15 2017
From: mick.jordan at oracle.com (Mick Jordan)
Date: Tue, 3 Jan 2017 07:57:15 -0800
Subject: [Rd] seq.int/seq.default
Message-ID: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>

This is a message for someone familiar with the implementation.

Superficially the R code for seq.default and the C code for seq.int 
appear to be semantically very similar. My question is whether, in fact, 
it is intended that behave identically for all inputs. I have found two 
cases so far where they differ, first that seq.int will coerce a 
character string to a real (via Rf_asReal) whereas seq.default appears 
to coerce it to NA and then throws an error:

 > seq.default("2", "5")
Error in seq.default("2", "5") : 'from' cannot be NA, NaN or infinite
 > seq.int("2", "5")
[1] 2 3 4 5
 >

and second, that the error messages for non-numeric arguments differ:

seq.default(to=quote(b), by=2)
Error in is.finite(to) : default method not implemented for type 'symbol'

seq.int(to=quote(b), by=2)
Error in seq.int(to = quote(b), by = 2) :
   'to' cannot be NA, NaN or infinite


Please reply off list.

Thanks
Mick Jordan


From jeroenooms at gmail.com  Tue Jan  3 17:32:43 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 3 Jan 2017 17:32:43 +0100
Subject: [Rd] [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
	<387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
	<CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
Message-ID: <CABFfbXvbE24gsqDSvCEmf6XrYX4mCiGt+Y4ESnLmLtqs7VEzcQ@mail.gmail.com>

On Tue, Jan 3, 2017 at 3:53 PM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>
> I maintian the rzmq project.
>
> love to get it running on windows, but zmq doesn't play nicely with R's
> mingw.

It's fairly easy to link against the libraries from rwinlib:
https://github.com/rwinlib/zeromq. I'll send you a pull request later
this week to fix the binary packages for win+mac.


From armstrong.whit at gmail.com  Tue Jan  3 18:07:10 2017
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 3 Jan 2017 12:07:10 -0500
Subject: [Rd] [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CABFfbXvbE24gsqDSvCEmf6XrYX4mCiGt+Y4ESnLmLtqs7VEzcQ@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
	<387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
	<CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
	<CABFfbXvbE24gsqDSvCEmf6XrYX4mCiGt+Y4ESnLmLtqs7VEzcQ@mail.gmail.com>
Message-ID: <CAMi=pg41MC5RB0wr3E1e4YDttW5pc-ptb7e8p8JboQRxHi98Dg@mail.gmail.com>

sounds great!

On Tue, Jan 3, 2017 at 11:32 AM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> On Tue, Jan 3, 2017 at 3:53 PM, Whit Armstrong <armstrong.whit at gmail.com>
> wrote:
> >
> > I maintian the rzmq project.
> >
> > love to get it running on windows, but zmq doesn't play nicely with R's
> > mingw.
>
> It's fairly easy to link against the libraries from rwinlib:
> https://github.com/rwinlib/zeromq. I'll send you a pull request later
> this week to fix the binary packages for win+mac.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Jan  4 04:02:15 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 3 Jan 2017 19:02:15 -0800
Subject: [Rd] cat(s,
 file): infinite loop of "invalid char string in output conversion"
 warnings with UTF-8 encoding
Message-ID: <CAFDcVCThDV5sej-cEm2fZ2ET2q=gX+skCiWbptjQoHfKPiww5A@mail.gmail.com>

The below code snippet gives a single warning:

  Warning message:
  In cat(s, file = tempfile()) : invalid char string in output conversion

when n <= 10001, whereas with n >= 10002 it appears to be generating
the same warning in an infinite loop in the call to cat().

n <- 10002L

r <- raw(length = n)
r[] <- charToRaw(" ")
r[length(r)] <- as.raw(0xa9)
s <- rawToChar(r)

message("Encoding: native.enc")
options(encoding = "native.enc")
cat(s, file = tempfile())

message("Encoding: UTF-8")
options(encoding = "UTF-8")
cat(s, file = tempfile())

message("DONE")


Here cat() never returns. The R process runs at 100% CPU, it does not
appear to increase it's memory usage, and the call can be interrupted:

^C
There were 50 or more warnings (use warnings() to see the first 50)
> traceback()
8: "factor" %in% attrib[["class", exact = TRUE]]
7: structure(list(message = as.character(message), call = call),
       class = class)
6: simpleWarning(msg, call)
5: doWithOneRestart(return(expr), restart)
4: withOneRestart(expr, restarts[[1L]])
3: withRestarts({
       .Internal(.signalCondition(simpleWarning(msg, call), msg,
           call))
       .Internal(.dfltWarn(msg, call))
   }, muffleWarning = function() NULL)
2: .signalSimpleWarning("invalid char string in output conversion",
       quote(cat(s, file = tempfile())))
1: cat(s, file = tempfile())


## SOME TROUBLESHOOTING

Using options(warn = 1) shows that the "invalid char string in output
conversion" warning is outputted over and over in an infinite loop.
This warning is generated by dummy_vfprintf() defined in
src/main/connections.c
(https://github.com/wch/r-source/blob/R-3-3-branch/src/main/connections.c#L370);

# define BUFSIZE 10000
int dummy_vfprintf(Rconnection con, const char *format, va_list ap)
{
    [...]
    if(ires == (size_t)(-1) && errno != E2BIG)
        /* is this safe? */
        warning(_("invalid char string in output conversion"));
    [...]
}

Note BUFSIZE, note the comment /* is this safe? */ (by Brian Ripley on
2005-01-05).



## SESSION DETAILS

I can reproduce this on R 2.11.0, R 3.3.2 and R devel on Linux.  It
does not occur on R 3.3.2 for Windows under Linux Wine.

> sessionInfo()
R version 2.11.0 (2010-04-22)
x86_64-unknown-linux-gnu

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> sessionInfo()
R Under development (unstable) (2017-01-02 r71875)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.0


From maechler at stat.math.ethz.ch  Wed Jan  4 10:26:45 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Jan 2017 10:26:45 +0100
Subject: [Rd] seq.int/seq.default
In-Reply-To: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
Message-ID: <22636.49109.884523.191528@stat.math.ethz.ch>

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Tue, 3 Jan 2017 07:57:15 -0800 writes:

    > This is a message for someone familiar with the implementation.
    > Superficially the R code for seq.default and the C code for seq.int 
    > appear to be semantically very similar. My question is whether, in fact, 
    > it is intended that behave identically for all inputs. 

Strictly speaking, "no":  As usual, RT?Manual (;-)

The help page says in the very first paragraph ('Description'):

  ?seq? is a standard generic with a default method.
  ?seq.int? is a primitive which can be much faster but has a few restrictions. 

    > I have found two cases so far where they differ, first
    > that seq.int will coerce a character string to a real (via
    > Rf_asReal) whereas seq.default appears to coerce it to NA
    > and then throws an error:

    >> seq.default("2", "5")
    > Error in seq.default("2", "5") : 'from' cannot be NA, NaN or infinite
    >> seq.int("2", "5")
    > [1] 2 3 4 5
    >> 

this may be a bit surprising (if one does _not_ look at the code),
indeed, notably because seq.int() is mentioned to have more
restrictions than seq() which here calls seq.default().
"Surprising" also when considering

   > "2":"5"
   [1] 2 3 4 5

and the documentation of ':' claims 'from:to' to be the same as
rep(from,to)  apart from the case of factors.

--- I am considering a small change in  seq.default()
which would make it work for this case, compatibly with ":" and seq.int().


    > and second, that the error messages for non-numeric arguments differ:

which I find fine... if the functions where meant to be
identical, we (the R developers) would be silly to have both,
notably as the ".int" suffix  has emerged as confusing the
majority of useRs (who don't read help pages).

Rather it has been meant as saying "internal" (including "fast") also for other
such R functions, but the suffix of course is a potential clash
with S3 method naming schemes _and_ the fact that 'int' is used
as type name for integer in other languages, notably C. 

    > seq.default(to=quote(b), by=2)
    > Error in is.finite(to) : default method not implemented for type 'symbol'

which I find a very appropriate and helpful message

    > seq.int(to=quote(b), by=2)
    > Error in seq.int(to = quote(b), by = 2) :
    > 'to' cannot be NA, NaN or infinite

which is true, as well, and there's no "default method" to be
mentioned, but you are right that it would be nicer if the
message mentioned 'symbol' as well.

    > Please reply off list.

[which I understand as that we should  CC you (which of course is
 netiquette to do)]

Martin Maechler
ETH Zurich


From mick.jordan at oracle.com  Wed Jan  4 17:15:03 2017
From: mick.jordan at oracle.com (Mick Jordan)
Date: Wed, 4 Jan 2017 08:15:03 -0800
Subject: [Rd] seq.int/seq.default
In-Reply-To: <22636.49109.884523.191528@stat.math.ethz.ch>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
	<22636.49109.884523.191528@stat.math.ethz.ch>
Message-ID: <688b761b-650b-2df6-da61-56f144939f9b@oracle.com>

On 1/4/17 1:26 AM, Martin Maechler wrote:
>>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>>      on Tue, 3 Jan 2017 07:57:15 -0800 writes:
>      > This is a message for someone familiar with the implementation.
>      > Superficially the R code for seq.default and the C code for seq.int
>      > appear to be semantically very similar. My question is whether, in fact,
>      > it is intended that behave identically for all inputs.
>
> Strictly speaking, "no":  As usual, RT?Manual (;-)
>
> The help page says in the very first paragraph ('Description'):
>
>    ?seq? is a standard generic with a default method.
>    ?seq.int? is a primitive which can be much faster but has a few restrictions.
>
>      > I have found two cases so far where they differ, first
>      > that seq.int will coerce a character string to a real (via
>      > Rf_asReal) whereas seq.default appears to coerce it to NA
>      > and then throws an error:
>
>      >> seq.default("2", "5")
>      > Error in seq.default("2", "5") : 'from' cannot be NA, NaN or infinite
>      >> seq.int("2", "5")
>      > [1] 2 3 4 5
>      >>
>
> this may be a bit surprising (if one does _not_ look at the code),
> indeed, notably because seq.int() is mentioned to have more
> restrictions than seq() which here calls seq.default().
> "Surprising" also when considering
>
>     > "2":"5"
>     [1] 2 3 4 5
>
> and the documentation of ':' claims 'from:to' to be the same as
> rep(from,to)  apart from the case of factors.
>
> --- I am considering a small change in  seq.default()
> which would make it work for this case, compatibly with ":" and seq.int().
>
>
>      > and second, that the error messages for non-numeric arguments differ:
>
> which I find fine... if the functions where meant to be
> identical, we (the R developers) would be silly to have both,
> notably as the ".int" suffix  has emerged as confusing the
> majority of useRs (who don't read help pages).
>
> Rather it has been meant as saying "internal" (including "fast") also for other
> such R functions, but the suffix of course is a potential clash
> with S3 method naming schemes _and_ the fact that 'int' is used
> as type name for integer in other languages, notably C.
>
>      > seq.default(to=quote(b), by=2)
>      > Error in is.finite(to) : default method not implemented for type 'symbol'
>
> which I find a very appropriate and helpful message
>
>      > seq.int(to=quote(b), by=2)
>      > Error in seq.int(to = quote(b), by = 2) :
>      > 'to' cannot be NA, NaN or infinite
>
> which is true, as well, and there's no "default method" to be
> mentioned, but you are right that it would be nicer if the
> message mentioned 'symbol' as well.
Thanks for the clarifications. It was surprising that seq.int supported 
more types than seq.default. I was expecting the reverse.

BTW, There are a couple of, admittedly odd, cases, exposed by brute 
force testing, where seq.int will actually return "missing", which I 
presume is not intended, and seq.default behaves differently, vis:

 > seq.default(to=1,by=2)
[1] 1
 > seq.int(to=1,by=2)

 > > x <- seq.int(to=1,by=2)
 > x
Error: argument "x" is missing, with no default

Lines 792 and 799 of seq.c return the incoming argument (as opposed to a 
value based on its coercion to double via asReal) and this can, as in 
the above example, be "missing".

>
>      > Please reply off list.
>
> [which I understand as that we should  CC you (which of course is
>   netiquette to do)]
>
Yes

Thanks
Mick Jordan


From mick.jordan at oracle.com  Wed Jan  4 21:49:41 2017
From: mick.jordan at oracle.com (Mick Jordan)
Date: Wed, 4 Jan 2017 12:49:41 -0800
Subject: [Rd] seq.int/seq.default
In-Reply-To: <688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
	<22636.49109.884523.191528@stat.math.ethz.ch>
	<688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
Message-ID: <88fcb2a7-d2a0-10af-cc03-c04ac20bec2f@oracle.com>

On 1/4/17 8:15 AM, Mick Jordan wrote:

Here is another difference that I am guessing is unintended.

 > y <- seq.int(1L, 3L, length.out=2)
 > typeof(y)
[1] "double"
 > x <- seq.default(1L, 3L, length.out=2)
 > typeof(x)
[1] "integer"

The if (by == R_MissingArg) branch at line 842 doesn't contain a check 
for "all INTSXP" unlike the if (to == R_MissingArg) branch.

Mick


From maechler at stat.math.ethz.ch  Thu Jan  5 12:39:29 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Jan 2017 12:39:29 +0100
Subject: [Rd] seq.int/seq.default
In-Reply-To: <688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
	<22636.49109.884523.191528@stat.math.ethz.ch>
	<688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
Message-ID: <22638.12401.631032.418795@stat.math.ethz.ch>

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Wed, 4 Jan 2017 08:15:03 -0800 writes:

    > On 1/4/17 1:26 AM, Martin Maechler wrote:
    >>>>>>> Mick Jordan <mick.jordan at oracle.com>
    >>>>>>> on Tue, 3 Jan 2017 07:57:15 -0800 writes:
    >> > This is a message for someone familiar with the implementation.
    >> > Superficially the R code for seq.default and the C code for seq.int
    >> > appear to be semantically very similar. My question is whether, in fact,
    >> > it is intended that behave identically for all inputs.
    >> 
    >> Strictly speaking, "no":  As usual, RT?Manual (;-)
    >> 
    >> The help page says in the very first paragraph ('Description'):
    >> 
    >> ?seq? is a standard generic with a default method.
    >> ?seq.int? is a primitive which can be much faster but has a few restrictions.
    >> 
    >> > I have found two cases so far where they differ, first
    >> > that seq.int will coerce a character string to a real (via
    >> > Rf_asReal) whereas seq.default appears to coerce it to NA
    >> > and then throws an error:
    >> 
    >> >> seq.default("2", "5")
    >> > Error in seq.default("2", "5") : 'from' cannot be NA, NaN or infinite
    >> >> seq.int("2", "5")
    >> > [1] 2 3 4 5
    >> >>
    >> 
    >> this may be a bit surprising (if one does _not_ look at the code),
    >> indeed, notably because seq.int() is mentioned to have more
    >> restrictions than seq() which here calls seq.default().
    >> "Surprising" also when considering
    >> 
    >> > "2":"5"
    >> [1] 2 3 4 5
    >> 
    >> and the documentation of ':' claims 'from:to' to be the same as
    >> rep(from,to)  apart from the case of factors.
    >> 
    >> --- I am considering a small change in  seq.default()
    >> which would make it work for this case, compatibly with ":" and seq.int().
    >> 
    >> 
    >> > and second, that the error messages for non-numeric arguments differ:
    >> 
    >> which I find fine... if the functions where meant to be
    >> identical, we (the R developers) would be silly to have both,
    >> notably as the ".int" suffix  has emerged as confusing the
    >> majority of useRs (who don't read help pages).
    >> 
    >> Rather it has been meant as saying "internal" (including "fast") also for other
    >> such R functions, but the suffix of course is a potential clash
    >> with S3 method naming schemes _and_ the fact that 'int' is used
    >> as type name for integer in other languages, notably C.
    >> 
    >> > seq.default(to=quote(b), by=2)
    >> > Error in is.finite(to) : default method not implemented for type 'symbol'
    >> 
    >> which I find a very appropriate and helpful message
    >> 
    >> > seq.int(to=quote(b), by=2)
    >> > Error in seq.int(to = quote(b), by = 2) :
    >> > 'to' cannot be NA, NaN or infinite
    >> 
    >> which is true, as well, and there's no "default method" to be
    >> mentioned, but you are right that it would be nicer if the
    >> message mentioned 'symbol' as well.

    > Thanks for the clarifications. It was surprising that seq.int supported 
    > more types than seq.default. I was expecting the reverse.

exactly, me too!

    > BTW, There are a couple of, admittedly odd, cases, exposed by brute 
    > force testing, where seq.int will actually return "missing", which I 
    > presume is not intended, and seq.default behaves differently, vis:

    >> seq.default(to=1,by=2)
    > [1] 1
    >> seq.int(to=1,by=2)

    >> > x <- seq.int(to=1,by=2)
    >> x
    > Error: argument "x" is missing, with no default

    > Lines 792 and 799 of seq.c return the incoming argument (as opposed to a 
    > value based on its coercion to double via asReal) and this can, as in 
    > the above example, be "missing".

    > Thanks
    > Mick Jordan

Thanks a lot, Mick -- you are right!

I'm fixing these  (the line numbers have greatly changed in the
mean time: Remember we work with "R-devel", i.e., the "trunk" :
always available at
https://svn.r-project.org/R/trunk/src/main/seq.c

Martin Maechler
ETH Zurich


From maechler at stat.math.ethz.ch  Thu Jan  5 12:40:28 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Jan 2017 12:40:28 +0100
Subject: [Rd] seq.int/seq.default
In-Reply-To: <88fcb2a7-d2a0-10af-cc03-c04ac20bec2f@oracle.com>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
	<22636.49109.884523.191528@stat.math.ethz.ch>
	<688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
	<88fcb2a7-d2a0-10af-cc03-c04ac20bec2f@oracle.com>
Message-ID: <22638.12460.519843.335008@stat.math.ethz.ch>

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Wed, 4 Jan 2017 12:49:41 -0800 writes:

    > On 1/4/17 8:15 AM, Mick Jordan wrote:
    > Here is another difference that I am guessing is unintended.

    >> y <- seq.int(1L, 3L, length.out=2)
    >> typeof(y)
    > [1] "double"
    >> x <- seq.default(1L, 3L, length.out=2)
    >> typeof(x)
    > [1] "integer"

    > The if (by == R_MissingArg) branch at line 842 doesn't contain a check 
    > for "all INTSXP" unlike the if (to == R_MissingArg) branch.

    > Mick

I'll look at this case, too,
thank you once more!


From wdunlap at tibco.com  Fri Jan  6 06:15:17 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Jan 2017 21:15:17 -0800
Subject: [Rd] strsplit(perl=TRUE),
	gregexpr(perl=TRUE) very slow for long strings
Message-ID: <CAF8bMcaRw-8-XtG7B6Os+SM8MZusPGq+rGxV8cjPqHsHM5svRQ@mail.gmail.com>

While doing some speed testing I noticed that in R-3.2.3 the perl=TRUE
variants of strsplit() and gregexpr() took time proportional to the
square of the number of pattern matches in their input strings.  E.g.,
the attached test function times gsub, strsplit, and gregexpr, with
perl TRUE (PCRE) and FALSE (TRE), when the input string contains 'n'
matches to the given pattern.  Notice the quadratic (in n) time growth
for the StrSplitPCRE and RegExprPCRE columns.

> regex.perf.test(N=2^(11:20))

              N SubTRE SubPCRE StrSplitTRE StrSplitPCRE RegExprTRE RegExprPCRE

elapsed    2048   0.00    0.00        0.00         0.00       0.00        0.00
elapsed    4096   0.00    0.00        0.01         0.00       0.00        0.00
elapsed    8192   0.00    0.00        0.00         0.01       0.00        0.01
elapsed   16384   0.02    0.00        0.00         0.05       0.02        0.08
elapsed   32768   0.00    0.00        0.01         0.16       0.00        0.29
elapsed   65536   0.02    0.01        0.04         0.59       0.01        0.96
elapsed  131072   0.03    0.02        0.08         2.37       0.05        2.43
elapsed  262144   0.06    0.04        0.17         9.58       0.10        9.61
elapsed  524288   0.14    0.05        0.36        39.14       0.21       38.58
elapsed 1048576   0.30    0.08        0.52       155.50       0.40      155.43

I have not looked at R's code, but it is possible that the problem is
caused by PCRE repeatedly scanning (once per match) the entire input
string to make sure it is valid UTF-8.  If so, adding
PCRE_NO_UTF8_CHECK to the flags given to pcre_exec would solve the
problem.  Perhaps R is already doing that in gsub(perl=TRUE).

Here is the test function:

regex.perf.test <- function(N=c(1e4, 2e4, 4e4, 8e4)) {
  makeTestString <- function(n) paste(collapse="",  rep("ab", n))
  s <- lapply(N, makeTestString)
  fns <- list(SubTRE=function(si) gsub("a", "", si, perl=FALSE),
              SubPCRE=function(si) gsub("a", "", si, perl=TRUE),
              StrSplitTRE=function(si) strsplit(si, "a", perl=FALSE),
              StrSplitPCRE=function(si) strsplit(si, "a", perl=TRUE),
              RegExprTRE=function(si) gregexpr("a", si, perl=FALSE),
              RegExprPCRE=function(si) gregexpr("a", si, perl=TRUE))
  times <- lapply(fns, function(fn) sapply(s, function(si)
system.time(fn(si))["elapsed"]))
  do.call("cbind", c(list(N=N), times))
}

Bill Dunlap
TIBCO Software
wdunlap tibco.com


From maechler at stat.math.ethz.ch  Fri Jan  6 18:23:28 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 6 Jan 2017 18:23:28 +0100
Subject: [Rd] seq.int/seq.default
In-Reply-To: <22638.12401.631032.418795@stat.math.ethz.ch>
References: <03f5806e-6656-233a-c7f0-ebe25f3160c8@oracle.com>
	<22636.49109.884523.191528@stat.math.ethz.ch>
	<688b761b-650b-2df6-da61-56f144939f9b@oracle.com>
	<22638.12401.631032.418795@stat.math.ethz.ch>
Message-ID: <22639.53904.605481.520096@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 5 Jan 2017 12:39:29 +0100 writes:

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Wed, 4 Jan 2017 08:15:03 -0800 writes:

    >> On 1/4/17 1:26 AM, Martin Maechler wrote:
    >>>>>>>> Mick Jordan <mick.jordan at oracle.com> on Tue, 3 Jan
    >>>>>>>> 2017 07:57:15 -0800 writes:
    >>> > This is a message for someone familiar with the
    >>> implementation.  > Superficially the R code for
    >>> seq.default and the C code for seq.int > appear to be
    >>> semantically very similar. My question is whether, in
    >>> fact, > it is intended that behave identically for all
    >>> inputs.
    >>> 
    >>> Strictly speaking, "no": As usual, RT?Manual (;-)
    >>> 
    >>> The help page says in the very first paragraph
    >>> ('Description'):
    >>> 
    >>> ?seq? is a standard generic with a default method.
    >>> ?seq.int? is a primitive which can be much faster but
    >>> has a few restrictions.
    >>> 
    >>> > I have found two cases so far where they differ, first
    >>> > that seq.int will coerce a character string to a real
    >>> (via > Rf_asReal) whereas seq.default appears to coerce
    >>> it to NA > and then throws an error:
    >>> 
    >>> >> seq.default("2", "5") > Error in seq.default("2",
    >>> "5") : 'from' cannot be NA, NaN or infinite >>
    >>> seq.int("2", "5") > [1] 2 3 4 5
    >>> >>
    >>> 
    >>> this may be a bit surprising (if one does _not_ look at
    >>> the code), indeed, notably because seq.int() is
    >>> mentioned to have more restrictions than seq() which
    >>> here calls seq.default().  "Surprising" also when
    >>> considering
    >>> 
    >>> > "2":"5" [1] 2 3 4 5
    >>> 
    >>> and the documentation of ':' claims 'from:to' to be the
    >>> same as rep(from,to) apart from the case of factors.
    >>> 
    >>> --- I am considering a small change in seq.default()
    >>> which would make it work for this case, compatibly with
    >>> ":" and seq.int().
    >>> 
    >>> 
    >>> > and second, that the error messages for non-numeric
    >>> arguments differ:
    >>> 
    >>> which I find fine... if the functions where meant to be
    >>> identical, we (the R developers) would be silly to have
    >>> both, notably as the ".int" suffix has emerged as
    >>> confusing the majority of useRs (who don't read help
    >>> pages).
    >>> 
    >>> Rather it has been meant as saying "internal" (including
    >>> "fast") also for other such R functions, but the suffix
    >>> of course is a potential clash with S3 method naming
    >>> schemes _and_ the fact that 'int' is used as type name
    >>> for integer in other languages, notably C.
    >>> 
    >>> > seq.default(to=quote(b), by=2) > Error in
    >>> is.finite(to) : default method not implemented for type
    >>> 'symbol'
    >>> 
    >>> which I find a very appropriate and helpful message
    >>> 
    >>> > seq.int(to=quote(b), by=2) > Error in seq.int(to =
    >>> quote(b), by = 2) : > 'to' cannot be NA, NaN or infinite
    >>> 
    >>> which is true, as well, and there's no "default method"
    >>> to be mentioned, but you are right that it would be
    >>> nicer if the message mentioned 'symbol' as well.

    >> Thanks for the clarifications. It was surprising that
    >> seq.int supported more types than seq.default. I was
    >> expecting the reverse.

    > exactly, me too!

    >> BTW, There are a couple of, admittedly odd, cases,
    >> exposed by brute force testing, where seq.int will
    >> actually return "missing", which I presume is not
    >> intended, and seq.default behaves differently, vis:

    >>> seq.default(to=1,by=2)
    >> [1] 1
    >>> seq.int(to=1,by=2)

    >>> > x <- seq.int(to=1,by=2) x
    >> Error: argument "x" is missing, with no default

    >> Lines 792 and 799 of seq.c return the incoming argument
    >> (as opposed to a value based on its coercion to double
    >> via asReal) and this can, as in the above example, be
    >> "missing".

    >> Thanks Mick Jordan

    > Thanks a lot, Mick -- you are right!

    > I'm fixing these (the line numbers have greatly changed in
    > the mean time: Remember we work with "R-devel", i.e., the
    > "trunk" : always available at
    > https://svn.r-project.org/R/trunk/src/main/seq.c

This has happened in the mean time (and more is planned for
another error message).

And there's this --- where I'm pretty sure we want an error for
seq.default() as well :

> seq.int(1,7, by=1:2)
Error: 'by' must be of length 1

> seq(1,7, by=1:2)
[1] 1 3 3 7 5 7 7
Warning messages:
1: In if (n < 0L) stop("wrong sign in 'by' argument") :
  the condition has length > 1 and only the first element will be used
2: In if (n > .Machine$integer.max) stop("'by' argument is much too small") :
  the condition has length > 1 and only the first element will be used
3: In 0L:n : numerical expression has 2 elements: only the first used
4: In (0L:n) * by :
  longer object length is not a multiple of shorter object length
5: In if (by > 0) pmin(x, to) else pmax(x, to) :
  the condition has length > 1 and only the first element will be used
>


From robert.s.cohn at intel.com  Sat Jan  7 17:41:42 2017
From: robert.s.cohn at intel.com (Cohn, Robert S)
Date: Sat, 7 Jan 2017 16:41:42 +0000
Subject: [Rd] accelerating matrix multiply
Message-ID: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>

I am using R to multiply some large (30k x 30k double) matrices on a 64 core machine (xeon phi).  I added some timers to src/main/array.c to see where the time is going. All of the time is being spent in the matprod function, most of that time is spent in dgemm. 15 seconds is in matprod in some code that is checking if there are NaNs.

> system.time (C <- B %*% A)
nancheck: wall time 15.240282s
? dgemm: wall time 43.111064s
matprod: wall time 58.351572s
??? user?? system? elapsed 
2710.154?? 20.999?? 58.398

The NaN checking code is not being vectorized because of the early exit when NaN is detected:

	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
	 * The test is only O(n) here.
	 */
	for (R_xlen_t i = 0; i < NRX*ncx; i++)
	    if (ISNAN(x[i])) {have_na = TRUE; break;}
	if (!have_na)
	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
		if (ISNAN(y[i])) {have_na = TRUE; break;}

I tried deleting the 'break'. By inspecting the asm code, I verified that the loop was not being vectorized before, but now is vectorized. Total time goes down:

system.time (C <- B %*% A)
nancheck: wall time 1.898667s
? dgemm: wall time 43.913621s
matprod: wall time 45.812468s
?? user?? system? elapsed 
2727.877?? 20.723?? 45.859

The break accelerates the case when there is a NaN, at the expense of the much more common case when there isn't a NaN. If a NaN is detected, it doesn't call dgemm and calls its own matrix multiply, which makes the NaN check time insignificant so I doubt the early exit provides any benefit.

I was a little surprised that the O(n) NaN check is costly compared to the O(n**2) dgemm that follows. I think the reason is that nan check is single thread and not vectorized, and my machine can do 2048 floating point ops/cycle when you consider the cores/dual issue/8 way SIMD/muladd, and the constant factor will be significant for even large matrices.

Would you consider deleting the breaks? I can submit a patch if that will help. Thanks.

Robert


From radford at cs.toronto.edu  Mon Jan  9 01:59:37 2017
From: radford at cs.toronto.edu (Radford Neal)
Date: Sun, 8 Jan 2017 19:59:37 -0500
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <mailman.9.1483873203.26475.r-devel@r-project.org>
References: <mailman.9.1483873203.26475.r-devel@r-project.org>
Message-ID: <20170109005937.GA13784@cs.toronto.edu>

> From: "Cohn, Robert S" <robert.s.cohn at intel.com>
>
> I am using R to multiply some large (30k x 30k double) matrices on a
>  64 core machine (xeon phi).  I added some timers to
>  src/main/array.c to see where the time is going. All of the time is
>  being spent in the matprod function, most of that time is spent in
>  dgemm. 15 seconds is in matprod in some code that is checking if
>  there are NaNs.
>
> The NaN checking code is not being vectorized...

This can be a problem with big matrices when lots of cores are used
for the actual multiply, but is even more of a problem when at least
one of the matrices is small (eg, a vector-matrix multiply), in which
case the NaN check can dominate, slowing the operation by up to a
factor of about ten.

I pointed this problem out over six years ago, and provided a 
patch that greatly speeds up many matrix multiplies (see
http://www.cs.utoronto.ca/~radford/R-mods.html).  But this
improvement has not been incorporated into R Core versions of R.

Since then, a more elaborate solution to the problem of NaN checks has
been incorporated into my pqR version of R (see pqR-project.org).  The
documentation on this approach can be found with help("%*%") if you're
running pqR, or you can just look at the source for this help file in
the pqR source code repository, at

https://github.com/radfordneal/pqR/blob/Release-2016-10-24/src/library/base/man/matmult.Rd

    Radford


From spencer.graves at prodsyse.com  Mon Jan  9 10:53:20 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 9 Jan 2017 03:53:20 -0600
Subject: [Rd] problem with print.generic(x)deparse(substitute(x))
Message-ID: <f96d2039-6760-6cff-c42d-bda85015f7e0@prodsyse.com>

Hi, All:


       I'm having trouble getting deparse(substitute(x)) inside 
print.generic to consistently


       I'm having trouble getting a print.something to work 
consistently.  Consider the following toy example:


# Define an object of class 'dum'
k <- 1
class(k) <- 'dum'
str(k) # as expected

# Define print.dum
print.dum <- function(x, ...)
   deparse(substitute(x))

print(k) # Prints "k" as expected
#####**** THE FOLLOWING PRINTS NOTHING:
k # Why?


### Thanks,
### Spencer Graves

sessionInfo()

R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.2

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils
[5] datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.2


From pdalgd at gmail.com  Mon Jan  9 11:24:15 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 9 Jan 2017 11:24:15 +0100
Subject: [Rd] problem with print.generic(x)deparse(substitute(x))
In-Reply-To: <f96d2039-6760-6cff-c42d-bda85015f7e0@prodsyse.com>
References: <f96d2039-6760-6cff-c42d-bda85015f7e0@prodsyse.com>
Message-ID: <0E4497A7-60AF-4804-8BD9-66836198A7AE@gmail.com>


On 09 Jan 2017, at 10:53 , Spencer Graves <spencer.graves at prodsyse.com> wrote:

> # Define an object of class 'dum'
> k <- 1
> class(k) <- 'dum'
> str(k) # as expected
> 
> # Define print.dum
> print.dum <- function(x, ...)
>  deparse(substitute(x))
> 
> print(k) # Prints "k" as expected
> #####**** THE FOLLOWING PRINTS NOTHING:
> k # Why?


Because it doesn't work that way...

First of all, your print.dum relies on autoprinting of its return value, it doesn't print anything itself. That's not how one usually writes print methods: You should print something and (usually) return the argument invisibly. 

Autoprinting calls the print method to do the actual printing and returns the object invisibly, irrespective of the return value from the print method. To wit:

> k
> dput(.Last.value)
structure(1, class = "dum")

(Trying to print the return value would invite infinite looping.)

However, there's another catch: deparse(substitute(...)) relies on knowing the argument to print() before evaluation, but autoprinting does not retain that information, it just looks at the object that has been computed and passes it to the relevant print method, so you get this effect:

> print.dum <- function(x, ...)
+  print(deparse(substitute(x)))
> k
[1] "x"

-pd



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at prodsyse.com  Mon Jan  9 15:19:49 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 9 Jan 2017 08:19:49 -0600
Subject: [Rd] problem with print.generic(x)deparse(substitute(x))
In-Reply-To: <0E4497A7-60AF-4804-8BD9-66836198A7AE@gmail.com>
References: <f96d2039-6760-6cff-c42d-bda85015f7e0@prodsyse.com>
	<0E4497A7-60AF-4804-8BD9-66836198A7AE@gmail.com>
Message-ID: <3cf3250f-f6bd-b3d1-a442-f2611bd41d86@prodsyse.com>

Hi, Peter et al.:


On 2017-01-09 4:24 AM, peter dalgaard wrote:
> On 09 Jan 2017, at 10:53 , Spencer Graves <spencer.graves at prodsyse.com> wrote:
>
>> # Define an object of class 'dum'
>> k <- 1
>> class(k) <- 'dum'
>> str(k) # as expected
>>
>> # Define print.dum
>> print.dum <- function(x, ...)
>>   deparse(substitute(x))
>>
>> print(k) # Prints "k" as expected
>> #####**** THE FOLLOWING PRINTS NOTHING:
>> k # Why?
>
> Because it doesn't work that way...
>
> First of all, your print.dum relies on autoprinting of its return value, it doesn't print anything itself. That's not how one usually writes print methods: You should print something and (usually) return the argument invisibly.
>
> Autoprinting calls the print method to do the actual printing and returns the object invisibly, irrespective of the return value from the print method. To wit:
>
>> k
>> dput(.Last.value)
> structure(1, class = "dum")
>
> (Trying to print the return value would invite infinite looping.)
>
> However, there's another catch: deparse(substitute(...)) relies on knowing the argument to print() before evaluation, but autoprinting does not retain that information, it just looks at the object that has been computed and passes it to the relevant print method, so you get this effect:
>
>> print.dum <- function(x, ...)
> +  print(deparse(substitute(x)))
>> k
> [1] "x"

       Thanks.  Permit me to ask my real question:  Is there a way to 
modify print.findFn{sos} so I can print "k" in the second line of the 
HTML from the following:


(k <- findFn('spline', 1))


       Currently, the HTML starts as follows:


findFunction Results
call: findFn(string = "spline", maxPages = 1)


       I want it to start as follows:


findFn Results

call: (k <- findFn(string = "spline", maxPages = 1))
For a package summary:  installPackages(k); writeFindFn2xls(k)


       When I added "ds <- deparse(substitute(x))" to "print.findFn", I 
got ds = "x", not "k" from "(k <- findFn('spline', 1))" and from "k" by 
itself (autoprint) but "x" from "print(k)".  Thanks to Peter for 
explaining this problem.  Is there a work around?


       Spencer

> -pd
>
>
>


From spencer.graves at prodsyse.com  Mon Jan  9 16:01:04 2017
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 9 Jan 2017 09:01:04 -0600
Subject: [Rd] problem with print.generic(x)deparse(substitute(x))
In-Reply-To: <3cf3250f-f6bd-b3d1-a442-f2611bd41d86@prodsyse.com>
References: <f96d2039-6760-6cff-c42d-bda85015f7e0@prodsyse.com>
	<0E4497A7-60AF-4804-8BD9-66836198A7AE@gmail.com>
	<3cf3250f-f6bd-b3d1-a442-f2611bd41d86@prodsyse.com>
Message-ID: <d671cc8d-0d11-58f5-61e3-d798f3021df6@prodsyse.com>



On 2017-01-09 8:19 AM, Spencer Graves wrote:
> Hi, Peter et al.:
>
>
> On 2017-01-09 4:24 AM, peter dalgaard wrote:
>> On 09 Jan 2017, at 10:53 , Spencer Graves 
>> <spencer.graves at prodsyse.com> wrote:
>>
>>> # Define an object of class 'dum'
>>> k <- 1
>>> class(k) <- 'dum'
>>> str(k) # as expected
>>>
>>> # Define print.dum
>>> print.dum <- function(x, ...)
>>>   deparse(substitute(x))
>>>
>>> print(k) # Prints "k" as expected
>>> #####**** THE FOLLOWING PRINTS NOTHING:
>>> k # Why?
>>
>> Because it doesn't work that way...
>>
>> First of all, your print.dum relies on autoprinting of its return 
>> value, it doesn't print anything itself. That's not how one usually 
>> writes print methods: You should print something and (usually) return 
>> the argument invisibly.
>>
>> Autoprinting calls the print method to do the actual printing and 
>> returns the object invisibly, irrespective of the return value from 
>> the print method. To wit:
>>
>>> k
>>> dput(.Last.value)
>> structure(1, class = "dum")
>>
>> (Trying to print the return value would invite infinite looping.)
>>
>> However, there's another catch: deparse(substitute(...)) relies on 
>> knowing the argument to print() before evaluation, but autoprinting 
>> does not retain that information, it just looks at the object that 
>> has been computed and passes it to the relevant print method, so you 
>> get this effect:
>>
>>> print.dum <- function(x, ...)
>> +  print(deparse(substitute(x)))
>>> k
>> [1] "x"
>
>       Thanks.  Permit me to ask my real question:  Is there a way to 
> modify print.findFn{sos} so I can print "k" in the second line of the 
> HTML from the following:
>
>
> (k <- findFn('spline', 1))
>
>
>       Currently, the HTML starts as follows:
>
>
> findFunction Results
> call: findFn(string = "spline", maxPages = 1)
>
>
>       I want it to start as follows:
>
>
> findFn Results
>
> call: (k <- findFn(string = "spline", maxPages = 1))
> For a package summary:  installPackages(k); writeFindFn2xls(k)
>
>
>       When I added "ds <- deparse(substitute(x))" to "print.findFn", I 
> got ds = "x", not "k" from "(k <- findFn('spline', 1))" and from "k" 
> by itself (autoprint) but 

> "k" [correction;  please excuse] from "print(k)". Thanks to Peter for 
> explaining this problem.  Is there a work around?
>
>
>       Spencer
>
>> -pd
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Jan 10 17:59:26 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Jan 2017 17:59:26 +0100
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
References: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
Message-ID: <22645.4846.737709.296789@stat.math.ethz.ch>

>>>>> Cohn, Robert S <robert.s.cohn at intel.com>
>>>>>     on Sat, 7 Jan 2017 16:41:42 +0000 writes:

> I am using R to multiply some large (30k x 30k double)
> matrices on a 64 core machine (xeon phi).  I added some timers
> to src/main/array.c to see where the time is going. All of the
> time is being spent in the matprod function, most of that time
> is spent in dgemm. 15 seconds is in matprod in some code that
> is checking if there are NaNs.

> > system.time (C <- B %*% A)
> nancheck: wall time 15.240282s
>    dgemm: wall time 43.111064s
>  matprod: wall time 58.351572s
>     user   system  elapsed 
> 2710.154   20.999   58.398
> 
> The NaN checking code is not being vectorized because of the
> early exit when NaN is detected:
> 
> 	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
> 	 * The test is only O(n) here.
> 	 */
> 	for (R_xlen_t i = 0; i < NRX*ncx; i++)
> 	    if (ISNAN(x[i])) {have_na = TRUE; break;}
> 	if (!have_na)
> 	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
> 		if (ISNAN(y[i])) {have_na = TRUE; break;}
> 
> I tried deleting the 'break'. By inspecting the asm code, I
> verified that the loop was not being vectorized before, but
> now is vectorized. Total time goes down:
> 
> system.time (C <- B %*% A)
> nancheck: wall time  1.898667s
>    dgemm: wall time 43.913621s
>  matprod: wall time 45.812468s
>     user   system  elapsed 
> 2727.877   20.723   45.859
> 
> The break accelerates the case when there is a NaN, at the
> expense of the much more common case when there isn't a
> NaN. If a NaN is detected, it doesn't call dgemm and calls its
> own matrix multiply, which makes the NaN check time
> insignificant so I doubt the early exit provides any benefit.
> 
> I was a little surprised that the O(n) NaN check is costly
> compared to the O(n**2) dgemm that follows. I think the reason
> is that nan check is single thread and not vectorized, and my
> machine can do 2048 floating point ops/cycle when you consider
> the cores/dual issue/8 way SIMD/muladd, and the constant
> factor will be significant for even large matrices.
> 
> Would you consider deleting the breaks? I can submit a patch
> if that will help. Thanks.
> 
> Robert

Thank you Robert for bringing the issue up ("again", possibly).
Within R core, some have seen somewhat similar timing on some
platforms (gcc) .. but much less dramatical differences e.g. on
macOS with clang.

As seen in the source code you cite above, the current
implementation was triggered by a nasty BLAS bug .. actually
also showing up only on some platforms, possibly depending on
runtime libraries in addition to the compilers used.

Do you have R code (including set.seed(.) if relevant) to show
on how to generate the large square matrices you've mentioned in
the beginning?  So we get to some reproducible benchmarks?

With best regards,
Martin Maechler


From jeroenooms at gmail.com  Tue Jan 10 20:48:42 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 10 Jan 2017 20:48:42 +0100
Subject: [Rd] [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CABFfbXvbE24gsqDSvCEmf6XrYX4mCiGt+Y4ESnLmLtqs7VEzcQ@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
	<387A70D9-B6F6-47CD-8E44-DC0B0ED47F10@gmail.com>
	<CAMi=pg7mO=qJnvGFtqoc_vxXwCoo3JBpGYbjqsuzVFVuQSd2MA@mail.gmail.com>
	<CABFfbXvbE24gsqDSvCEmf6XrYX4mCiGt+Y4ESnLmLtqs7VEzcQ@mail.gmail.com>
Message-ID: <CABFfbXtSOHuyU2cb-+rzRW2ZvE3=xZH1b3Pmv39zHs3PbK-zxA@mail.gmail.com>

For those following this thread: rzmq binary packages for Mac and
Windows are now available from CRAN.


On Tue, Jan 3, 2017 at 5:32 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> On Tue, Jan 3, 2017 at 3:53 PM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>>
>> I maintian the rzmq project.
>>
>> love to get it running on windows, but zmq doesn't play nicely with R's
>> mingw.
>
> It's fairly easy to link against the libraries from rwinlib:
> https://github.com/rwinlib/zeromq. I'll send you a pull request later
> this week to fix the binary packages for win+mac.


From frederik at ofb.net  Wed Jan 11 02:48:55 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 10 Jan 2017 17:48:55 -0800
Subject: [Rd] bug with strptime, %OS, and "."
Message-ID: <20170111014855.GI29294@ofb.net>

Hi R Devel,

I just ran into a corner case with 'strptime'. Recall that the "%OS"
conversion accepts fractional seconds:

> strptime("17_35_14.01234.mp3","%H_%M_%OS.mp3")$sec
[1] 14.01234

Unfortunately for my application it seems to be "greedy", in that it
tries to parse a decimal point which might belong to the rest of the
format:

> strptime("17_35_14.mp3","%H_%M_%OS.mp3")
[1] NA

If I use "_" instead of ".", then it works:

> strptime("17_35_14_mp3","%H_%M_%OS_mp3")
[1] "2017-01-10 17:35:14 PST"

Perhaps a low priority, but seems like a bug to me...

Thanks,

Frederick


From edd at debian.org  Wed Jan 11 03:13:21 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 10 Jan 2017 20:13:21 -0600
Subject: [Rd] bug with strptime, %OS, and "."
In-Reply-To: <20170111014855.GI29294@ofb.net>
References: <20170111014855.GI29294@ofb.net>
Message-ID: <22645.38081.776727.305032@max.nulle.part>


On 10 January 2017 at 17:48, frederik at ofb.net wrote:
| Hi R Devel,
| 
| I just ran into a corner case with 'strptime'. Recall that the "%OS"
| conversion accepts fractional seconds:
| 
| > strptime("17_35_14.01234.mp3","%H_%M_%OS.mp3")$sec
| [1] 14.01234
| 
| Unfortunately for my application it seems to be "greedy", in that it
| tries to parse a decimal point which might belong to the rest of the
| format:
| 
| > strptime("17_35_14.mp3","%H_%M_%OS.mp3")
| [1] NA

Maybe just don't use the optional O:

   R> strptime("17_35_14.mp3","%H_%M_%S.mp3")$sec
   [1] 14
   R> 
   R> strptime("17_35_14.mp3","%H_%M_%S.mp3")
   [1] "2017-01-10 17:35:14 CST"
   R>
   
Dirk
 
| If I use "_" instead of ".", then it works:
| 
| > strptime("17_35_14_mp3","%H_%M_%OS_mp3")
| [1] "2017-01-10 17:35:14 PST"
| 
| Perhaps a low priority, but seems like a bug to me...
| 
| Thanks,
| 
| Frederick
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From frederik at ofb.net  Wed Jan 11 03:58:57 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 10 Jan 2017 18:58:57 -0800
Subject: [Rd] bug with strptime, %OS, and "."
In-Reply-To: <22645.38081.776727.305032@max.nulle.part>
References: <20170111014855.GI29294@ofb.net>
	<22645.38081.776727.305032@max.nulle.part>
Message-ID: <20170111025857.GJ29294@ofb.net>

On Tue, Jan 10, 2017 at 08:13:21PM -0600, Dirk Eddelbuettel wrote:
> 
> On 10 January 2017 at 17:48, frederik at ofb.net wrote:
> | Hi R Devel,
> | 
> | I just ran into a corner case with 'strptime'. Recall that the "%OS"
> | conversion accepts fractional seconds:
> | 
> | > strptime("17_35_14.01234.mp3","%H_%M_%OS.mp3")$sec
> | [1] 14.01234
> | 
> | Unfortunately for my application it seems to be "greedy", in that it
> | tries to parse a decimal point which might belong to the rest of the
> | format:
> | 
> | > strptime("17_35_14.mp3","%H_%M_%OS.mp3")
> | [1] NA
> 
> Maybe just don't use the optional O:
> 
>    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")$sec
>    [1] 14
>    R> 
>    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")
>    [1] "2017-01-10 17:35:14 CST"
>    R>

For my application I wanted to be able to accept both formats,
"14.mp3" and "14.01234.mp3". Since "14" and "14.01234" both parse as
numbers, I thought "%OS" should accept both.

Yes, I can work around it fairly easily.

Frederick


From alexhoward at nova.org.za  Wed Jan 11 11:33:18 2017
From: alexhoward at nova.org.za (Alex Ivan Howard)
Date: Wed, 11 Jan 2017 12:33:18 +0200
Subject: [Rd] R 'base' returning 0 as sum of NAs
Message-ID: <CAKvBZF2WBbUStVMowSjEv9hRTaR4YEKB=_mEVP=SKWjwsnzbOA@mail.gmail.com>

Dear R Team

The following line returns 0 (zero) as answer:
sum(c(NA_real_, NA_real_, NA_real_, NA_real_), na.rm = TRUE)

One would, however, have expected it to return 'NaN', as is the case with
function 'mean':

> mean(c(NA_real_, NA_real_, NA_real_, NA_real_), na.rm = TRUE)
[1] NaN

The problem in other words:
I have a vector filled with missing numbers. I run the 'sum' function on
it, but instruct it to remove all missing values first. Consequently, the
sum function is left with an empty numeric vector. There is nothing to sum
over, so it shouldn't actually be able to return a concrete numeric value?
Shouldn't it thus rather return either NA ('unknown'/'missing') or - in the
fashion of the mean function - NaN ('not a number')?

With the current state of affairs, the sum function poses the grave danger
of introducing zeros to one's data (and subsequently other values as well,
as soon as the zeros get taken up in further calculations).

I hope my e-mail finds you well and I wish the R team all of the best for
2017 :)

Kind regards

Alex I. Howard

Web: www.nova.org.za
Phone: +27 (0) 44 695 0749
VoiP: +27 (0) 87 751 3490
Fax:         +27 (0) 86 538 7958

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Jan 11 12:50:09 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Jan 2017 06:50:09 -0500
Subject: [Rd] R 'base' returning 0 as sum of NAs
In-Reply-To: <CAKvBZF2WBbUStVMowSjEv9hRTaR4YEKB=_mEVP=SKWjwsnzbOA@mail.gmail.com>
References: <CAKvBZF2WBbUStVMowSjEv9hRTaR4YEKB=_mEVP=SKWjwsnzbOA@mail.gmail.com>
Message-ID: <4214d41e-9216-36bb-7aac-3d8042020aca@gmail.com>

On 11/01/2017 5:33 AM, Alex Ivan Howard wrote:
> Dear R Team
>
> The following line returns 0 (zero) as answer:
> sum(c(NA_real_, NA_real_, NA_real_, NA_real_), na.rm = TRUE)
>
> One would, however, have expected it to return 'NaN', as is the case with
> function 'mean':
>
>> mean(c(NA_real_, NA_real_, NA_real_, NA_real_), na.rm = TRUE)
> [1] NaN
>

The two expressions are long versions of

sum(numeric())
mean(numeric())

It is reasonable that an empty sum is zero.  The mean is 0/0, so NaN is 
reasonable.

If this doesn't suit your needs, then you should put in special checks 
for empty datasets.

Duncan Murdoch

> The problem in other words:
> I have a vector filled with missing numbers. I run the 'sum' function on
> it, but instruct it to remove all missing values first. Consequently, the
> sum function is left with an empty numeric vector. There is nothing to sum
> over, so it shouldn't actually be able to return a concrete numeric value?
> Shouldn't it thus rather return either NA ('unknown'/'missing') or - in the
> fashion of the mean function - NaN ('not a number')?
>
> With the current state of affairs, the sum function poses the grave danger
> of introducing zeros to one's data (and subsequently other values as well,
> as soon as the zeros get taken up in further calculations).
>
> I hope my e-mail finds you well and I wish the R team all of the best for
> 2017 :)
>
> Kind regards
>
> Alex I. Howard
>
> Web: www.nova.org.za
> Phone: +27 (0) 44 695 0749
> VoiP: +27 (0) 87 751 3490
> Fax:         +27 (0) 86 538 7958
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From robert.s.cohn at intel.com  Wed Jan 11 14:28:17 2017
From: robert.s.cohn at intel.com (Cohn, Robert S)
Date: Wed, 11 Jan 2017 13:28:17 +0000
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <22645.4846.737709.296789@stat.math.ethz.ch>
References: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
	<22645.4846.737709.296789@stat.math.ethz.ch>
Message-ID: <017981773BBEDE44A0F34FBEE7EAF2DA324843A4@ORSMSX113.amr.corp.intel.com>

> Do you have R code (including set.seed(.) if relevant) to show on how to generate
> the large square matrices you've mentioned in the beginning?  So we get to some
> reproducible benchmarks?


Hi Martin,

Here is the program I used. I only generate 2 random numbers and reuse them to make the benchmark run faster. Let me know if there is something I can do to help--alternate benchmarks, tests, experiments with compilers other than icc.

MKL LAPACK behavior is undefined for NaN's so I left the check in, just made it more efficient on a CPU with SIMD. Thanks for looking at this.

set.seed (1)
m <- 30000
n <- 30000
A <- matrix (runif(2),nrow=m,ncol=n)
B <- matrix (runif(2),nrow=m,ncol=n)
print(typeof(A[1,2]))
print(A[1,2])

# Matrix multiply
system.time (C <- B %*% A)
system.time (C <- B %*% A)
system.time (C <- B %*% A)

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Sent: Tuesday, January 10, 2017 8:59 AM
To: Cohn, Robert S <robert.s.cohn at intel.com>
Cc: r-devel at r-project.org
Subject: Re: [Rd] accelerating matrix multiply

>>>>> Cohn, Robert S <robert.s.cohn at intel.com>
>>>>>     on Sat, 7 Jan 2017 16:41:42 +0000 writes:

> I am using R to multiply some large (30k x 30k double) matrices on a 
> 64 core machine (xeon phi).  I added some timers to src/main/array.c 
> to see where the time is going. All of the time is being spent in the 
> matprod function, most of that time is spent in dgemm. 15 seconds is 
> in matprod in some code that is checking if there are NaNs.

> > system.time (C <- B %*% A)
> nancheck: wall time 15.240282s
>    dgemm: wall time 43.111064s
>  matprod: wall time 58.351572s
>     user   system  elapsed 
> 2710.154   20.999   58.398
> 
> The NaN checking code is not being vectorized because of the early 
> exit when NaN is detected:
> 
> 	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
> 	 * The test is only O(n) here.
> 	 */
> 	for (R_xlen_t i = 0; i < NRX*ncx; i++)
> 	    if (ISNAN(x[i])) {have_na = TRUE; break;}
> 	if (!have_na)
> 	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
> 		if (ISNAN(y[i])) {have_na = TRUE; break;}
> 
> I tried deleting the 'break'. By inspecting the asm code, I verified 
> that the loop was not being vectorized before, but now is vectorized. 
> Total time goes down:
> 
> system.time (C <- B %*% A)
> nancheck: wall time  1.898667s
>    dgemm: wall time 43.913621s
>  matprod: wall time 45.812468s
>     user   system  elapsed 
> 2727.877   20.723   45.859
> 
> The break accelerates the case when there is a NaN, at the expense of 
> the much more common case when there isn't a NaN. If a NaN is 
> detected, it doesn't call dgemm and calls its own matrix multiply, 
> which makes the NaN check time insignificant so I doubt the early exit 
> provides any benefit.
> 
> I was a little surprised that the O(n) NaN check is costly compared to 
> the O(n**2) dgemm that follows. I think the reason is that nan check 
> is single thread and not vectorized, and my machine can do 2048 
> floating point ops/cycle when you consider the cores/dual issue/8 way 
> SIMD/muladd, and the constant factor will be significant for even 
> large matrices.
> 
> Would you consider deleting the breaks? I can submit a patch if that 
> will help. Thanks.
> 
> Robert

Thank you Robert for bringing the issue up ("again", possibly).
Within R core, some have seen somewhat similar timing on some platforms (gcc) .. but much less dramatical differences e.g. on macOS with clang.

As seen in the source code you cite above, the current implementation was triggered by a nasty BLAS bug .. actually also showing up only on some platforms, possibly depending on runtime libraries in addition to the compilers used.

Do you have R code (including set.seed(.) if relevant) to show on how to generate the large square matrices you've mentioned in the beginning?  So we get to some reproducible benchmarks?

With best regards,
Martin Maechler


From scupton at nps.edu  Wed Jan 11 14:36:07 2017
From: scupton at nps.edu (Upton, Stephen (Steve) (CIV))
Date: Wed, 11 Jan 2017 13:36:07 +0000
Subject: [Rd] bug with strptime, %OS, and "."
In-Reply-To: <20170111025857.GJ29294@ofb.net>
References: <20170111014855.GI29294@ofb.net>
	<22645.38081.776727.305032@max.nulle.part>
	<20170111025857.GJ29294@ofb.net>
Message-ID: <C750A9148B73B84EB6293187A5F7DA75D9208E8B@GROWLER.ern.nps.edu>

Works for me:
> strptime("17_35_14.01234.mp3","%H_%M_%OS")$sec
[1] 14.01234
> strptime("17_35_14.mp3","%H_%M_%OS")$sec
[1] 14

Just leave off the ".mp3" in your time pattern.

Relevant section from the help ("Details") for strptime:
strptime converts character vectors to class "POSIXlt": its input x is first
converted by as.character. Each input string is processed as far as
necessary for the format specified: any trailing characters are ignored.

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Stephen C. Upton
Faculty Associate - Research
SEED (Simulation Experiments & Efficient Designs) Center
Operations Research Department
Naval Postgraduate School
Mobile: 804-994-4257
NIPR: scupton at nps.edu
SIPR: uptonsc at nps.navy.smil.mil
SEED Center web site: http://harvest.nps.edu
-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
frederik at ofb.net
Sent: Tuesday, January 10, 2017 9:59 PM
To: Dirk Eddelbuettel
Cc: R-devel
Subject: Re: [Rd] bug with strptime, %OS, and "."

On Tue, Jan 10, 2017 at 08:13:21PM -0600, Dirk Eddelbuettel wrote:
> 
> On 10 January 2017 at 17:48, frederik at ofb.net wrote:
> | Hi R Devel,
> | 
> | I just ran into a corner case with 'strptime'. Recall that the "%OS"
> | conversion accepts fractional seconds:
> | 
> | > strptime("17_35_14.01234.mp3","%H_%M_%OS.mp3")$sec
> | [1] 14.01234
> | 
> | Unfortunately for my application it seems to be "greedy", in that it 
> | tries to parse a decimal point which might belong to the rest of the
> | format:
> | 
> | > strptime("17_35_14.mp3","%H_%M_%OS.mp3")
> | [1] NA
> 
> Maybe just don't use the optional O:
> 
>    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")$sec
>    [1] 14
>    R> 
>    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")
>    [1] "2017-01-10 17:35:14 CST"
>    R>

For my application I wanted to be able to accept both formats, "14.mp3" and
"14.01234.mp3". Since "14" and "14.01234" both parse as numbers, I thought
"%OS" should accept both.

Yes, I can work around it fairly easily.

Frederick

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From frederik at ofb.net  Thu Jan 12 22:59:11 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Thu, 12 Jan 2017 13:59:11 -0800
Subject: [Rd] bug with strptime, %OS, and "."
In-Reply-To: <C750A9148B73B84EB6293187A5F7DA75D9208E8B@GROWLER.ern.nps.edu>
References: <20170111014855.GI29294@ofb.net>
	<22645.38081.776727.305032@max.nulle.part>
	<20170111025857.GJ29294@ofb.net>
	<C750A9148B73B84EB6293187A5F7DA75D9208E8B@GROWLER.ern.nps.edu>
Message-ID: <20170112215911.GP29294@ofb.net>

Thanks for the reply. That's a creative way to do it, but I wanted to
use the same format string for both parsing and formatting my file
name.

I figured I should just put this on the bug tracker in case someone is
editing strptime at some point in the distant future:

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17208

I also made a related bug asking for e.g. "%OS6" to be accepted by
strptime.

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17209

Cheers,

Frederick

On Wed, Jan 11, 2017 at 01:36:07PM +0000, Upton, Stephen (Steve) (CIV) wrote:
> Works for me:
> > strptime("17_35_14.01234.mp3","%H_%M_%OS")$sec
> [1] 14.01234
> > strptime("17_35_14.mp3","%H_%M_%OS")$sec
> [1] 14
> 
> Just leave off the ".mp3" in your time pattern.
> 
> Relevant section from the help ("Details") for strptime:
> strptime converts character vectors to class "POSIXlt": its input x is first
> converted by as.character. Each input string is processed as far as
> necessary for the format specified: any trailing characters are ignored.
> 
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Stephen C. Upton
> Faculty Associate - Research
> SEED (Simulation Experiments & Efficient Designs) Center
> Operations Research Department
> Naval Postgraduate School
> Mobile: 804-994-4257
> NIPR: scupton at nps.edu
> SIPR: uptonsc at nps.navy.smil.mil
> SEED Center web site: http://harvest.nps.edu
> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
> frederik at ofb.net
> Sent: Tuesday, January 10, 2017 9:59 PM
> To: Dirk Eddelbuettel
> Cc: R-devel
> Subject: Re: [Rd] bug with strptime, %OS, and "."
> 
> On Tue, Jan 10, 2017 at 08:13:21PM -0600, Dirk Eddelbuettel wrote:
> > 
> > On 10 January 2017 at 17:48, frederik at ofb.net wrote:
> > | Hi R Devel,
> > | 
> > | I just ran into a corner case with 'strptime'. Recall that the "%OS"
> > | conversion accepts fractional seconds:
> > | 
> > | > strptime("17_35_14.01234.mp3","%H_%M_%OS.mp3")$sec
> > | [1] 14.01234
> > | 
> > | Unfortunately for my application it seems to be "greedy", in that it 
> > | tries to parse a decimal point which might belong to the rest of the
> > | format:
> > | 
> > | > strptime("17_35_14.mp3","%H_%M_%OS.mp3")
> > | [1] NA
> > 
> > Maybe just don't use the optional O:
> > 
> >    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")$sec
> >    [1] 14
> >    R> 
> >    R> strptime("17_35_14.mp3","%H_%M_%S.mp3")
> >    [1] "2017-01-10 17:35:14 CST"
> >    R>
> 
> For my application I wanted to be able to accept both formats, "14.mp3" and
> "14.01234.mp3". Since "14" and "14.01234" both parse as numbers, I thought
> "%OS" should accept both.
> 
> Yes, I can work around it fairly easily.
> 
> Frederick
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From geyer at umn.edu  Fri Jan 13 20:25:45 2017
From: geyer at umn.edu (Charles Geyer)
Date: Fri, 13 Jan 2017 13:25:45 -0600
Subject: [Rd] calling native routines in another package (Sec 5.4.2 of
	Writing R Extensions)
Message-ID: <CAKctRd32RUVntt4GD4G4DyzXwXPu4Vg4cmexO4T0ZpuW8v77CQ@mail.gmail.com>

I just (apparently) figured out how to do the stuff described in
Section 5.4.2 of
Writing R Extensions.  I put my test toy packages on github
<https://github.com/cjgeyer/linkingTo> for anyone to copy.  If anyone
cares to read the README and the bits of code it links to and tell me
anywhere I am wrong, I would be grateful.

But the main point of this e-mail is a complaint about that section of
Writing R Extensions.  It says (even in R-devel) "A CRAN example of
the use of this mechanism is package lme4, which links to Matrix." but
that does not appear to be true anymore.  I cannot see any inclusion
of headers from Matrix in lme4 nor any call to R_GetCCallable.  I did
find the file inst/include/Matrix_stubs.c in the Matrix package
somewhat helpful (although mystifying at first).

So this can be considered a documentation bug report (if I am
correct).  Do I need to do an official bugzilla one?

Just a further check.  lme4 (1.1-12) does not have Matrix in the
LinkingTo field of its DESCRIPTION file, so headers from Matrix cannot
be used.  And

    grep R_Get *.[ch]*

in the src directory of lme4 returns nothing.


From charlie at stat.umn.edu  Fri Jan 13 21:21:10 2017
From: charlie at stat.umn.edu (Charles Geyer)
Date: Fri, 13 Jan 2017 14:21:10 -0600
Subject: [Rd] unlicense
Message-ID: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>

I would like the unlicense (http://unlicense.org/) added to R
licenses.  Does anyone else think that worthwhile?

-- 
Charles Geyer
Professor, School of Statistics
Resident Fellow, Minnesota Center for Philosophy of Science
University of Minnesota
charlie at stat.umn.edu


From avraham.adler at gmail.com  Fri Jan 13 21:30:03 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 13 Jan 2017 20:30:03 +0000
Subject: [Rd] unlicense
In-Reply-To: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
Message-ID: <CAL6gwnJhmL-fB2gpLWfnEi59k+3sZtVYj5vJiXDa6-Neo0jhJw@mail.gmail.com>

A number of years ago I asked here for the ISC to be added and was told you
have to ask CRAN, not Rd.

Good luck,

Avi

On Fri, Jan 13, 2017 at 3:22 PM Charles Geyer <charlie at stat.umn.edu> wrote:

> I would like the unlicense (http://unlicense.org/) added to R
>
> licenses.  Does anyone else think that worthwhile?
>
>
>
> --
>
> Charles Geyer
>
> Professor, School of Statistics
>
> Resident Fellow, Minnesota Center for Philosophy of Science
>
> University of Minnesota
>
> charlie at stat.umn.edu
>
>
>
> ______________________________________________
>
> R-devel at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Jan 13 21:58:15 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 13 Jan 2017 14:58:15 -0600
Subject: [Rd] calling native routines in another package (Sec 5.4.2
	of	Writing R Extensions)
In-Reply-To: <CAKctRd32RUVntt4GD4G4DyzXwXPu4Vg4cmexO4T0ZpuW8v77CQ@mail.gmail.com>
References: <CAKctRd32RUVntt4GD4G4DyzXwXPu4Vg4cmexO4T0ZpuW8v77CQ@mail.gmail.com>
Message-ID: <22649.16231.36234.410307@max.nulle.part>


On 13 January 2017 at 13:25, Charles Geyer wrote:
| I just (apparently) figured out how to do the stuff described in
| Section 5.4.2 of
| Writing R Extensions.  I put my test toy packages on github
| <https://github.com/cjgeyer/linkingTo> for anyone to copy.  If anyone
| cares to read the README and the bits of code it links to and tell me
| anywhere I am wrong, I would be grateful.
| 
| But the main point of this e-mail is a complaint about that section of
| Writing R Extensions.  It says (even in R-devel) "A CRAN example of
| the use of this mechanism is package lme4, which links to Matrix." but
| that does not appear to be true anymore.  I cannot see any inclusion
| of headers from Matrix in lme4 nor any call to R_GetCCallable.  I did
| find the file inst/include/Matrix_stubs.c in the Matrix package
| somewhat helpful (although mystifying at first).
| 
| So this can be considered a documentation bug report (if I am
| correct).  Do I need to do an official bugzilla one?
| 
| Just a further check.  lme4 (1.1-12) does not have Matrix in the
| LinkingTo field of its DESCRIPTION file, so headers from Matrix cannot
| be used.  And
| 
|     grep R_Get *.[ch]*
| 
| in the src directory of lme4 returns nothing.

There are a few other packages doing this

RcppXts uses exported C code from xts [1]
RcppRedis users export C code from RApiSerialize
RcppKalman uses expm
Vincent Goulet just release expint which offers an API

Dirk

[1] Vincent and I went over this recently when he prepared expint. While I
(re-)wrote a large part of the xts header for use by RcppXts and others, I
didn't leave my name in the header so Jeff got author credits for expint
instead.  C'est la vie.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Sat Jan 14 01:19:47 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Jan 2017 19:19:47 -0500
Subject: [Rd] unlicense
In-Reply-To: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
Message-ID: <09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>

On 13/01/2017 3:21 PM, Charles Geyer wrote:
> I would like the unlicense (http://unlicense.org/) added to R
> licenses.  Does anyone else think that worthwhile?
>

That's a question for you to answer, not to ask.  Who besides you thinks 
that it's a good license for open source software?

If it is recognized by the OSF or FSF or some other authority as a FOSS 
license, then CRAN would probably also recognize it.  If not, then CRAN 
doesn't have the resources to evaluate it and so is unlikely to 
recognize it.

Duncan Murdoch


From frederik at ofb.net  Sat Jan 14 02:43:16 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Fri, 13 Jan 2017 17:43:16 -0800
Subject: [Rd] unlicense
In-Reply-To: <09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
Message-ID: <20170114014316.GA29294@ofb.net>

I don't see why Charles' question should be taken as anything other
than an honest request for information.

As for me, I've never heard of this license, but if CRAN doesn't have
an option to license software in the public domain, then I would
support the inclusion of some such option.

FWIW, searching for "public domain software license" on Google turns
up unlicense.org as the second result.

Frederick

On Fri, Jan 13, 2017 at 07:19:47PM -0500, Duncan Murdoch wrote:
> On 13/01/2017 3:21 PM, Charles Geyer wrote:
> > I would like the unlicense (http://unlicense.org/) added to R
> > licenses.  Does anyone else think that worthwhile?
> > 
> 
> That's a question for you to answer, not to ask.  Who besides you thinks
> that it's a good license for open source software?
> 
> If it is recognized by the OSF or FSF or some other authority as a FOSS
> license, then CRAN would probably also recognize it.  If not, then CRAN
> doesn't have the resources to evaluate it and so is unlikely to recognize
> it.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Sat Jan 14 07:26:26 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 14 Jan 2017 00:26:26 -0600
Subject: [Rd] unlicense
In-Reply-To: <20170114014316.GA29294@ofb.net>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<20170114014316.GA29294@ofb.net>
Message-ID: <22649.50322.481199.611486@max.nulle.part>


On 13 January 2017 at 17:43, frederik at ofb.net wrote:
| I don't see why Charles' question should be taken as anything other
| than an honest request for information.
| 
| As for me, I've never heard of this license, but if CRAN doesn't have
| an option to license software in the public domain, then I would
| support the inclusion of some such option.
| 
| FWIW, searching for "public domain software license" on Google turns
| up unlicense.org as the second result.

You missed the gist of Duncan's post: unless/until a body with authority on
which licenses interoperate blesses this one, it is not on the radar.

In short, it has to be compatible with other key OSS licenses. The
documentation put forward says nothing about that, which is a problem.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From deepayan.sarkar at gmail.com  Sat Jan 14 07:53:14 2017
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sat, 14 Jan 2017 12:23:14 +0530
Subject: [Rd] unlicense
In-Reply-To: <09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
Message-ID: <CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>

On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>
>> I would like the unlicense (http://unlicense.org/) added to R
>> licenses.  Does anyone else think that worthwhile?
>>
>
> That's a question for you to answer, not to ask.  Who besides you thinks
> that it's a good license for open source software?
>
> If it is recognized by the OSF or FSF or some other authority as a FOSS
> license, then CRAN would probably also recognize it.  If not, then CRAN
> doesn't have the resources to evaluate it and so is unlikely to recognize
> it.

Unlicense is listed in https://spdx.org/licenses/

Debian does include software "licensed" like this, and seems to think
this is one way (not the only one) of declaring something to be
"public domain".  The first two examples I found:

https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1

This follows the format explained in
https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
which does not explicitly include Unlicense, but does include CC0,
which AFAICT is meant to formally license something so that it is
equivalent to being in the public domain. R does include CC0 as a
shorthand (e.g., geoknife).

https://www.debian.org/legal/licenses/ says that

<quote>

Licenses currently found in Debian main include:

- ...
- ...
- public domain (not a license, strictly speaking)

</quote>

The equivalent for CRAN would probably be something like "License:
public-domain + file LICENSE".

-Deepayan

> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sat Jan 14 09:10:20 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Jan 2017 09:10:20 +0100
Subject: [Rd] unlicense
In-Reply-To: <CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
Message-ID: <c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>

Dear all,

from "Writing R Extensions":

The string ?Unlimited?, meaning that there are no restrictions on 
distribution or use other than those imposed by relevant laws (including 
copyright laws).

If a package license restricts a base license (where permitted, e.g., 
using GPL-3 or AGPL-3 with an attribution clause), the additional terms 
should be placed in file LICENSE (or LICENCE), and the string ?+ file 
LICENSE? (or ?+ file LICENCE?, respectively) should be appended to the
corresponding individual license specification.
...
Please note in particular that ?Public domain? is not a valid license, 
since it is not recognized in some jurisdictions."

So perhaps you aim for
License: Unlimited

Best,
Uwe Ligges




On 14.01.2017 07:53, Deepayan Sarkar wrote:
> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>>
>>> I would like the unlicense (http://unlicense.org/) added to R
>>> licenses.  Does anyone else think that worthwhile?
>>>
>>
>> That's a question for you to answer, not to ask.  Who besides you thinks
>> that it's a good license for open source software?
>>
>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>> license, then CRAN would probably also recognize it.  If not, then CRAN
>> doesn't have the resources to evaluate it and so is unlikely to recognize
>> it.
>
> Unlicense is listed in https://spdx.org/licenses/
>
> Debian does include software "licensed" like this, and seems to think
> this is one way (not the only one) of declaring something to be
> "public domain".  The first two examples I found:
>
> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
> https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1
>
> This follows the format explained in
> https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
> which does not explicitly include Unlicense, but does include CC0,
> which AFAICT is meant to formally license something so that it is
> equivalent to being in the public domain. R does include CC0 as a
> shorthand (e.g., geoknife).
>
> https://www.debian.org/legal/licenses/ says that
>
> <quote>
>
> Licenses currently found in Debian main include:
>
> - ...
> - ...
> - public domain (not a license, strictly speaking)
>
> </quote>
>
> The equivalent for CRAN would probably be something like "License:
> public-domain + file LICENSE".
>
> -Deepayan
>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From geyer at umn.edu  Sat Jan 14 06:52:13 2017
From: geyer at umn.edu (Charles Geyer)
Date: Fri, 13 Jan 2017 23:52:13 -0600
Subject: [Rd] unlicense
In-Reply-To: <20170114014316.GA29294@ofb.net>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<20170114014316.GA29294@ofb.net>
Message-ID: <CAKctRd2nz6MDxDGNPOBj-uvmXgrNaZeg9gjTHfPQSvjOCrz8NA@mail.gmail.com>

Actually, CRAN does have an alternative to this.  "License: Unlimited"
can be used in the DESCRIPTION file, but does less than the cited
"unlicense".

On Fri, Jan 13, 2017 at 7:43 PM,  <frederik at ofb.net> wrote:
> I don't see why Charles' question should be taken as anything other
> than an honest request for information.
>
> As for me, I've never heard of this license, but if CRAN doesn't have
> an option to license software in the public domain, then I would
> support the inclusion of some such option.
>
> FWIW, searching for "public domain software license" on Google turns
> up unlicense.org as the second result.
>
> Frederick
>
> On Fri, Jan 13, 2017 at 07:19:47PM -0500, Duncan Murdoch wrote:
>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>> > I would like the unlicense (http://unlicense.org/) added to R
>> > licenses.  Does anyone else think that worthwhile?
>> >
>>
>> That's a question for you to answer, not to ask.  Who besides you thinks
>> that it's a good license for open source software?
>>
>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>> license, then CRAN would probably also recognize it.  If not, then CRAN
>> doesn't have the resources to evaluate it and so is unlikely to recognize
>> it.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From tomas.kalibera at gmail.com  Mon Jan 16 17:59:32 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 16 Jan 2017 17:59:32 +0100
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <017981773BBEDE44A0F34FBEE7EAF2DA324843A4@ORSMSX113.amr.corp.intel.com>
References: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
	<22645.4846.737709.296789@stat.math.ethz.ch>
	<017981773BBEDE44A0F34FBEE7EAF2DA324843A4@ORSMSX113.amr.corp.intel.com>
Message-ID: <a50549b3-0c3a-4acb-80a9-e7b2b78930d9@gmail.com>


Hi Robert,

thanks for the report and your suggestions how to make the NaN checks 
faster.

Based on my experiments it seems that the "break" in the loop actually 
can have positive impact on performance even in the common case when we 
don't have NaNs. With gcc on linux (corei7), where isnan is inlined, the 
"break" version uses a conditional jump while the "nobreak" version uses 
a conditional move. The conditional jump is faster because it takes 
advantage of the branch prediction. Neither of the two versions is 
vectorized (only scalar SSE instructions used).

How do you run R on Xeon Phi? Do you offload the NaN checks to the Phi 
coprocessor? So far I tried without offloading to Phi, icc could 
vectorize the "nobreak" version, but the performance of it was the same 
as "break".

For my experiments I extracted NaN checks into a function. This was the 
"break" version (same performance as the current code):

static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
   for (R_xlen_t i = 0; i < n; i++)
     if (ISNAN(x[i])) return TRUE;
   return FALSE;
}

And this was the "nobreak" version:

static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
   Rboolean has = FALSE;
   for (R_xlen_t i = 0; i < n; i++)
     if (ISNAN(x[i])) has=TRUE;
   return has;
}

Thanks,
Tomas

On 01/11/2017 02:28 PM, Cohn, Robert S wrote:
>> Do you have R code (including set.seed(.) if relevant) to show on how to generate
>> the large square matrices you've mentioned in the beginning?  So we get to some
>> reproducible benchmarks?
>
> Hi Martin,
>
> Here is the program I used. I only generate 2 random numbers and reuse them to make the benchmark run faster. Let me know if there is something I can do to help--alternate benchmarks, tests, experiments with compilers other than icc.
>
> MKL LAPACK behavior is undefined for NaN's so I left the check in, just made it more efficient on a CPU with SIMD. Thanks for looking at this.
>
> set.seed (1)
> m <- 30000
> n <- 30000
> A <- matrix (runif(2),nrow=m,ncol=n)
> B <- matrix (runif(2),nrow=m,ncol=n)
> print(typeof(A[1,2]))
> print(A[1,2])
>
> # Matrix multiply
> system.time (C <- B %*% A)
> system.time (C <- B %*% A)
> system.time (C <- B %*% A)
>
> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Tuesday, January 10, 2017 8:59 AM
> To: Cohn, Robert S <robert.s.cohn at intel.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] accelerating matrix multiply
>
>>>>>> Cohn, Robert S <robert.s.cohn at intel.com>
>>>>>>      on Sat, 7 Jan 2017 16:41:42 +0000 writes:
>> I am using R to multiply some large (30k x 30k double) matrices on a
>> 64 core machine (xeon phi).  I added some timers to src/main/array.c
>> to see where the time is going. All of the time is being spent in the
>> matprod function, most of that time is spent in dgemm. 15 seconds is
>> in matprod in some code that is checking if there are NaNs.
>>> system.time (C <- B %*% A)
>> nancheck: wall time 15.240282s
>>     dgemm: wall time 43.111064s
>>   matprod: wall time 58.351572s
>>      user   system  elapsed
>> 2710.154   20.999   58.398
>>
>> The NaN checking code is not being vectorized because of the early
>> exit when NaN is detected:
>>
>> 	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
>> 	 * The test is only O(n) here.
>> 	 */
>> 	for (R_xlen_t i = 0; i < NRX*ncx; i++)
>> 	    if (ISNAN(x[i])) {have_na = TRUE; break;}
>> 	if (!have_na)
>> 	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
>> 		if (ISNAN(y[i])) {have_na = TRUE; break;}
>>
>> I tried deleting the 'break'. By inspecting the asm code, I verified
>> that the loop was not being vectorized before, but now is vectorized.
>> Total time goes down:
>>
>> system.time (C <- B %*% A)
>> nancheck: wall time  1.898667s
>>     dgemm: wall time 43.913621s
>>   matprod: wall time 45.812468s
>>      user   system  elapsed
>> 2727.877   20.723   45.859
>>
>> The break accelerates the case when there is a NaN, at the expense of
>> the much more common case when there isn't a NaN. If a NaN is
>> detected, it doesn't call dgemm and calls its own matrix multiply,
>> which makes the NaN check time insignificant so I doubt the early exit
>> provides any benefit.
>>
>> I was a little surprised that the O(n) NaN check is costly compared to
>> the O(n**2) dgemm that follows. I think the reason is that nan check
>> is single thread and not vectorized, and my machine can do 2048
>> floating point ops/cycle when you consider the cores/dual issue/8 way
>> SIMD/muladd, and the constant factor will be significant for even
>> large matrices.
>>
>> Would you consider deleting the breaks? I can submit a patch if that
>> will help. Thanks.
>>
>> Robert
> Thank you Robert for bringing the issue up ("again", possibly).
> Within R core, some have seen somewhat similar timing on some platforms (gcc) .. but much less dramatical differences e.g. on macOS with clang.
>
> As seen in the source code you cite above, the current implementation was triggered by a nasty BLAS bug .. actually also showing up only on some platforms, possibly depending on runtime libraries in addition to the compilers used.
>
> Do you have R code (including set.seed(.) if relevant) to show on how to generate the large square matrices you've mentioned in the beginning?  So we get to some reproducible benchmarks?
>
> With best regards,
> Martin Maechler
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From robert.s.cohn at intel.com  Mon Jan 16 18:32:04 2017
From: robert.s.cohn at intel.com (Cohn, Robert S)
Date: Mon, 16 Jan 2017 17:32:04 +0000
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <a50549b3-0c3a-4acb-80a9-e7b2b78930d9@gmail.com>
References: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
	<22645.4846.737709.296789@stat.math.ethz.ch>
	<017981773BBEDE44A0F34FBEE7EAF2DA324843A4@ORSMSX113.amr.corp.intel.com>
	<a50549b3-0c3a-4acb-80a9-e7b2b78930d9@gmail.com>
Message-ID: <017981773BBEDE44A0F34FBEE7EAF2DA32488223@ORSMSX113.amr.corp.intel.com>

Hi Tomas,

Can you share the full code for your benchmark, compiler options, and performance results so that I can try to reproduce them? There are a lot of variables that can affect the results. Private email is fine if it is too much for the mailing list.

I am measuring on Knight's Landing (KNL) that was released in November. KNL is not a co-processor so no offload is necessary. R executes directly on the Phi, which looks like a multi-core machine with 64 cores.

Robert

-----Original Message-----
From: Tomas Kalibera [mailto:tomas.kalibera at gmail.com] 
Sent: Monday, January 16, 2017 12:00 PM
To: Cohn, Robert S <robert.s.cohn at intel.com>
Cc: r-devel at r-project.org
Subject: Re: [Rd] accelerating matrix multiply


Hi Robert,

thanks for the report and your suggestions how to make the NaN checks faster.

Based on my experiments it seems that the "break" in the loop actually can have positive impact on performance even in the common case when we don't have NaNs. With gcc on linux (corei7), where isnan is inlined, the "break" version uses a conditional jump while the "nobreak" version uses a conditional move. The conditional jump is faster because it takes advantage of the branch prediction. Neither of the two versions is vectorized (only scalar SSE instructions used).

How do you run R on Xeon Phi? Do you offload the NaN checks to the Phi coprocessor? So far I tried without offloading to Phi, icc could vectorize the "nobreak" version, but the performance of it was the same as "break".

For my experiments I extracted NaN checks into a function. This was the "break" version (same performance as the current code):

static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
   for (R_xlen_t i = 0; i < n; i++)
     if (ISNAN(x[i])) return TRUE;
   return FALSE;
}

And this was the "nobreak" version:

static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
   Rboolean has = FALSE;
   for (R_xlen_t i = 0; i < n; i++)
     if (ISNAN(x[i])) has=TRUE;
   return has;
}

Thanks,
Tomas

On 01/11/2017 02:28 PM, Cohn, Robert S wrote:
>> Do you have R code (including set.seed(.) if relevant) to show on how 
>> to generate the large square matrices you've mentioned in the 
>> beginning?  So we get to some reproducible benchmarks?
>
> Hi Martin,
>
> Here is the program I used. I only generate 2 random numbers and reuse them to make the benchmark run faster. Let me know if there is something I can do to help--alternate benchmarks, tests, experiments with compilers other than icc.
>
> MKL LAPACK behavior is undefined for NaN's so I left the check in, just made it more efficient on a CPU with SIMD. Thanks for looking at this.
>
> set.seed (1)
> m <- 30000
> n <- 30000
> A <- matrix (runif(2),nrow=m,ncol=n)
> B <- matrix (runif(2),nrow=m,ncol=n)
> print(typeof(A[1,2]))
> print(A[1,2])
>
> # Matrix multiply
> system.time (C <- B %*% A)
> system.time (C <- B %*% A)
> system.time (C <- B %*% A)
>
> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Tuesday, January 10, 2017 8:59 AM
> To: Cohn, Robert S <robert.s.cohn at intel.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] accelerating matrix multiply
>
>>>>>> Cohn, Robert S <robert.s.cohn at intel.com>
>>>>>>      on Sat, 7 Jan 2017 16:41:42 +0000 writes:
>> I am using R to multiply some large (30k x 30k double) matrices on a
>> 64 core machine (xeon phi).  I added some timers to src/main/array.c 
>> to see where the time is going. All of the time is being spent in the 
>> matprod function, most of that time is spent in dgemm. 15 seconds is 
>> in matprod in some code that is checking if there are NaNs.
>>> system.time (C <- B %*% A)
>> nancheck: wall time 15.240282s
>>     dgemm: wall time 43.111064s
>>   matprod: wall time 58.351572s
>>      user   system  elapsed
>> 2710.154   20.999   58.398
>>
>> The NaN checking code is not being vectorized because of the early 
>> exit when NaN is detected:
>>
>> 	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
>> 	 * The test is only O(n) here.
>> 	 */
>> 	for (R_xlen_t i = 0; i < NRX*ncx; i++)
>> 	    if (ISNAN(x[i])) {have_na = TRUE; break;}
>> 	if (!have_na)
>> 	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
>> 		if (ISNAN(y[i])) {have_na = TRUE; break;}
>>
>> I tried deleting the 'break'. By inspecting the asm code, I verified 
>> that the loop was not being vectorized before, but now is vectorized.
>> Total time goes down:
>>
>> system.time (C <- B %*% A)
>> nancheck: wall time  1.898667s
>>     dgemm: wall time 43.913621s
>>   matprod: wall time 45.812468s
>>      user   system  elapsed
>> 2727.877   20.723   45.859
>>
>> The break accelerates the case when there is a NaN, at the expense of 
>> the much more common case when there isn't a NaN. If a NaN is 
>> detected, it doesn't call dgemm and calls its own matrix multiply, 
>> which makes the NaN check time insignificant so I doubt the early 
>> exit provides any benefit.
>>
>> I was a little surprised that the O(n) NaN check is costly compared 
>> to the O(n**2) dgemm that follows. I think the reason is that nan 
>> check is single thread and not vectorized, and my machine can do 2048 
>> floating point ops/cycle when you consider the cores/dual issue/8 way 
>> SIMD/muladd, and the constant factor will be significant for even 
>> large matrices.
>>
>> Would you consider deleting the breaks? I can submit a patch if that 
>> will help. Thanks.
>>
>> Robert
> Thank you Robert for bringing the issue up ("again", possibly).
> Within R core, some have seen somewhat similar timing on some platforms (gcc) .. but much less dramatical differences e.g. on macOS with clang.
>
> As seen in the source code you cite above, the current implementation was triggered by a nasty BLAS bug .. actually also showing up only on some platforms, possibly depending on runtime libraries in addition to the compilers used.
>
> Do you have R code (including set.seed(.) if relevant) to show on how to generate the large square matrices you've mentioned in the beginning?  So we get to some reproducible benchmarks?
>
> With best regards,
> Martin Maechler
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From frederik at ofb.net  Tue Jan 17 03:20:58 2017
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 16 Jan 2017 18:20:58 -0800
Subject: [Rd] strptime("1","%m") returns NA
In-Reply-To: <20170111014855.GI29294@ofb.net>
References: <20170111014855.GI29294@ofb.net>
Message-ID: <20170117022058.GB29294@ofb.net>

Hi R Devel,

I wrote some code which depends on 'strptime' being able to parse an
incomplete date, like this:

> base::strptime("2016","%Y")
[1] "2016-01-14 PST"

The above works - although it's odd that it gives the month and day
for Sys.time(). I might expect it to set them both to zero as the GNU
libc strptime does on my system, or to use January 1 which would also
be reasonable.

When I specify the month, however, I get NA:

> base::strptime("2016-12","%Y-%m")
[1] NA
> base::strptime("1", "%m")
[1] NA

Any reason for this to be the case?

I reported a bug here:

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17212

but I don't think I'm getting emails from Bugzilla so maybe best to
ping me if anyone replies there instead.

I've just written a simple reimplementation of 'strptime' for my own
use; I hope this bug report may be useful to others.

Thank you,

Frederick


From krzysztof at nus.edu.sg  Tue Jan 17 02:50:24 2017
From: krzysztof at nus.edu.sg (Krzysztof Banas)
Date: Tue, 17 Jan 2017 01:50:24 +0000
Subject: [Rd] bug in rbind?
Message-ID: <D1E6227CBC482446B2D877554FCD338C2CCB4982@MBX01A.stf.nus.edu.sg>

I suspect there may be a bug in base::rbind.data.frame

Below there is minimal example of the problem:

m <- matrix (1:12, 3)
dfm <- data.frame (c = 1 : 3, m = I (m))
str (dfm)

m.names <- m
rownames (m.names) <- letters [1:3]
dfm.names <- data.frame (c = 1 : 3, m = I (m.names))
str (dfm.names)

rbind (m, m.names)
rbind (m.names, m)
rbind (dfm, dfm.names)

#not working
rbind (dfm.names, dfm)

Error in rbind(deparse.level, ...) : replacement has length zero

rbind (dfm, dfm.names)$m


     [,1] [,2] [,3] [,4]

<NA>    1    4    7   10

<NA>    2    5    8   11

<NA>    3    6    9   12

a       1    4    7   10

b       2    5    8   11

c       3    6    9   12



________________________________

Important: This email is confidential and may be privileged. If you are not the intended recipient, please delete it and notify us immediately; you should not copy or use it for any purpose, nor disclose its contents to any other person. Thank you.

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Tue Jan 17 12:37:18 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 17 Jan 2017 12:37:18 +0100
Subject: [Rd] accelerating matrix multiply
In-Reply-To: <017981773BBEDE44A0F34FBEE7EAF2DA32488223@ORSMSX113.amr.corp.intel.com>
References: <017981773BBEDE44A0F34FBEE7EAF2DA32481C23@ORSMSX113.amr.corp.intel.com>
	<22645.4846.737709.296789@stat.math.ethz.ch>
	<017981773BBEDE44A0F34FBEE7EAF2DA324843A4@ORSMSX113.amr.corp.intel.com>
	<a50549b3-0c3a-4acb-80a9-e7b2b78930d9@gmail.com>
	<017981773BBEDE44A0F34FBEE7EAF2DA32488223@ORSMSX113.amr.corp.intel.com>
Message-ID: <81254378-9c84-89b6-d0de-631c3ac19fdf@gmail.com>

Hi Robert,

I've run more experiments (and yes, the code is probably too long for 
the list). The tradeoffs are platform dependent. The "nobreak" version 
is slower than "break" on a corei7 (i7-3610QM), it is faster on opteron 
(6282) and it is about the same on Xeon (E5-2640, E5-2670 even though 
seen slower for big vectors).

It may be hard to get a universally better version. Still, a version 
that performs fastest on platforms I checked, and sometimes by a lot - 
about 2x faster than default - is

Rboolean hasNaN_pairsum(double *x, R_xlen_t n)
{
     if ((n&1) != 0 && ISNAN(x[0]))
         return TRUE;
     for (int i = n&1; i < n; i += 2)
         if (ISNAN(x[i]+x[i+1])) /* may also return TRUE for +-Inf */
             return TRUE;
     return FALSE;
}

It may also return "true" when some elements are Inf, but that is 
safe/conservative for this purpose, and actually the MKL disclaimer 
suggests we should be checking for Inf anyway.
This version is from pqR (except that pqR would check also the 
individual arguments of the sum, it the sum is found to have NaN).
Does it perform well on Knights Landing?

Best
Tomas


On 01/16/2017 06:32 PM, Cohn, Robert S wrote:
> Hi Tomas,
>
> Can you share the full code for your benchmark, compiler options, and performance results so that I can try to reproduce them? There are a lot of variables that can affect the results. Private email is fine if it is too much for the mailing list.
>
> I am measuring on Knight's Landing (KNL) that was released in November. KNL is not a co-processor so no offload is necessary. R executes directly on the Phi, which looks like a multi-core machine with 64 cores.
>
> Robert
>
> -----Original Message-----
> From: Tomas Kalibera [mailto:tomas.kalibera at gmail.com]
> Sent: Monday, January 16, 2017 12:00 PM
> To: Cohn, Robert S <robert.s.cohn at intel.com>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] accelerating matrix multiply
>
>
> Hi Robert,
>
> thanks for the report and your suggestions how to make the NaN checks faster.
>
> Based on my experiments it seems that the "break" in the loop actually can have positive impact on performance even in the common case when we don't have NaNs. With gcc on linux (corei7), where isnan is inlined, the "break" version uses a conditional jump while the "nobreak" version uses a conditional move. The conditional jump is faster because it takes advantage of the branch prediction. Neither of the two versions is vectorized (only scalar SSE instructions used).
>
> How do you run R on Xeon Phi? Do you offload the NaN checks to the Phi coprocessor? So far I tried without offloading to Phi, icc could vectorize the "nobreak" version, but the performance of it was the same as "break".
>
> For my experiments I extracted NaN checks into a function. This was the "break" version (same performance as the current code):
>
> static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
>     for (R_xlen_t i = 0; i < n; i++)
>       if (ISNAN(x[i])) return TRUE;
>     return FALSE;
> }
>
> And this was the "nobreak" version:
>
> static __attribute__ ((noinline)) Rboolean hasNA(double *x, int n) {
>     Rboolean has = FALSE;
>     for (R_xlen_t i = 0; i < n; i++)
>       if (ISNAN(x[i])) has=TRUE;
>     return has;
> }
>
> Thanks,
> Tomas
>
> On 01/11/2017 02:28 PM, Cohn, Robert S wrote:
>>> Do you have R code (including set.seed(.) if relevant) to show on how
>>> to generate the large square matrices you've mentioned in the
>>> beginning?  So we get to some reproducible benchmarks?
>> Hi Martin,
>>
>> Here is the program I used. I only generate 2 random numbers and reuse them to make the benchmark run faster. Let me know if there is something I can do to help--alternate benchmarks, tests, experiments with compilers other than icc.
>>
>> MKL LAPACK behavior is undefined for NaN's so I left the check in, just made it more efficient on a CPU with SIMD. Thanks for looking at this.
>>
>> set.seed (1)
>> m <- 30000
>> n <- 30000
>> A <- matrix (runif(2),nrow=m,ncol=n)
>> B <- matrix (runif(2),nrow=m,ncol=n)
>> print(typeof(A[1,2]))
>> print(A[1,2])
>>
>> # Matrix multiply
>> system.time (C <- B %*% A)
>> system.time (C <- B %*% A)
>> system.time (C <- B %*% A)
>>
>> -----Original Message-----
>> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
>> Sent: Tuesday, January 10, 2017 8:59 AM
>> To: Cohn, Robert S <robert.s.cohn at intel.com>
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] accelerating matrix multiply
>>
>>>>>>> Cohn, Robert S <robert.s.cohn at intel.com>
>>>>>>>       on Sat, 7 Jan 2017 16:41:42 +0000 writes:
>>> I am using R to multiply some large (30k x 30k double) matrices on a
>>> 64 core machine (xeon phi).  I added some timers to src/main/array.c
>>> to see where the time is going. All of the time is being spent in the
>>> matprod function, most of that time is spent in dgemm. 15 seconds is
>>> in matprod in some code that is checking if there are NaNs.
>>>> system.time (C <- B %*% A)
>>> nancheck: wall time 15.240282s
>>>      dgemm: wall time 43.111064s
>>>    matprod: wall time 58.351572s
>>>       user   system  elapsed
>>> 2710.154   20.999   58.398
>>>
>>> The NaN checking code is not being vectorized because of the early
>>> exit when NaN is detected:
>>>
>>> 	/* Don't trust the BLAS to handle NA/NaNs correctly: PR#4582
>>> 	 * The test is only O(n) here.
>>> 	 */
>>> 	for (R_xlen_t i = 0; i < NRX*ncx; i++)
>>> 	    if (ISNAN(x[i])) {have_na = TRUE; break;}
>>> 	if (!have_na)
>>> 	    for (R_xlen_t i = 0; i < NRY*ncy; i++)
>>> 		if (ISNAN(y[i])) {have_na = TRUE; break;}
>>>
>>> I tried deleting the 'break'. By inspecting the asm code, I verified
>>> that the loop was not being vectorized before, but now is vectorized.
>>> Total time goes down:
>>>
>>> system.time (C <- B %*% A)
>>> nancheck: wall time  1.898667s
>>>      dgemm: wall time 43.913621s
>>>    matprod: wall time 45.812468s
>>>       user   system  elapsed
>>> 2727.877   20.723   45.859
>>>
>>> The break accelerates the case when there is a NaN, at the expense of
>>> the much more common case when there isn't a NaN. If a NaN is
>>> detected, it doesn't call dgemm and calls its own matrix multiply,
>>> which makes the NaN check time insignificant so I doubt the early
>>> exit provides any benefit.
>>>
>>> I was a little surprised that the O(n) NaN check is costly compared
>>> to the O(n**2) dgemm that follows. I think the reason is that nan
>>> check is single thread and not vectorized, and my machine can do 2048
>>> floating point ops/cycle when you consider the cores/dual issue/8 way
>>> SIMD/muladd, and the constant factor will be significant for even
>>> large matrices.
>>>
>>> Would you consider deleting the breaks? I can submit a patch if that
>>> will help. Thanks.
>>>
>>> Robert
>> Thank you Robert for bringing the issue up ("again", possibly).
>> Within R core, some have seen somewhat similar timing on some platforms (gcc) .. but much less dramatical differences e.g. on macOS with clang.
>>
>> As seen in the source code you cite above, the current implementation was triggered by a nasty BLAS bug .. actually also showing up only on some platforms, possibly depending on runtime libraries in addition to the compilers used.
>>
>> Do you have R code (including set.seed(.) if relevant) to show on how to generate the large square matrices you've mentioned in the beginning?  So we get to some reproducible benchmarks?
>>
>> With best regards,
>> Martin Maechler
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From plummerm at iarc.fr  Tue Jan 17 14:35:35 2017
From: plummerm at iarc.fr (Martyn Plummer)
Date: Tue, 17 Jan 2017 13:35:35 +0000
Subject: [Rd] strptime("1","%m") returns NA
In-Reply-To: <20170117022058.GB29294@ofb.net>
References: <20170111014855.GI29294@ofb.net>	 <20170117022058.GB29294@ofb.net>
Message-ID: <1484660111.26811.26.camel@iarc.fr>

Hi Frederik,

On Mon, 2017-01-16 at 18:20 -0800, frederik at ofb.net wrote:
> Hi R Devel,
> 
> I wrote some code which depends on 'strptime' being able to parse an
> incomplete date, like this:
> 
> > 
> > base::strptime("2016","%Y")
> [1] "2016-01-14 PST"
> 
> The above works - although it's odd that it gives the month and day
> for Sys.time(). I might expect it to set them both to zero as the GNU
> libc strptime does on my system, or to use January 1 which would also
> be reasonable.

From the help page for strptime:

"For ?strptime? the input string need not specify the date completely:
it is assumed that unspecified seconds, minutes or hours are zero, and
an unspecified year, month or day is the current one."
?
> When I specify the month, however, I get NA:
> 
> > 
> > base::strptime("2016-12","%Y-%m")
> [1] NA
> > 
> > base::strptime("1", "%m")
> [1] NA
> 
> Any reason for this to be the case?

Also from the help page:

"(However, if a month is specified, the day of that month has to be
specified by ?%d? or ?%e? since the current day of the month need not
be valid for the specified month.)"

If strptime("2016-2", "%Y-%m") just filled in the current day then it
would give valid output when called on the 1st to the 28th of each
month, but would give either invalid output or fail when called on the
29th to the 31st of any month. This would be a nightmare to debug. The
current behaviour lets you know there is a logical problem with your
input.

> I reported a bug here:
> 
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17212
> 
> but I don't think I'm getting emails from Bugzilla so maybe best to
> ping me if anyone replies there instead.

See the general guidance on submitting bug reports:

"Code doing something unexpected is not necessarily a bug - make sure to carefully review the documentation for the function you are calling to see if the behaviour it exhibits is what it was designed to do, even if it?s not what you want."

https://www.r-project.org/bugs.html


Martyn

> I've just written a simple reimplementation of 'strptime' for my own
> use; I hope this bug report may be useful to others.
> 
> Thank you,
> 
> Frederick
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From mikko.korpela at helsinki.fi  Tue Jan 17 14:38:58 2017
From: mikko.korpela at helsinki.fi (Mikko Korpela)
Date: Tue, 17 Jan 2017 15:38:58 +0200
Subject: [Rd] parallel::detectCores() bug on Raspberry Pi B+
In-Reply-To: <cc0d1047-de96-d6a0-0254-f54a2bedb7ec@gmail.com>
References: <cc0d1047-de96-d6a0-0254-f54a2bedb7ec@gmail.com>
Message-ID: <56dd3f28-687f-5b5e-8a38-2afa771b9d7f@helsinki.fi>

On 10/12/16 00:22, Paul Gilbert wrote:
> In R 3.3.2 detectCores() in package parallel reports 2 rather than 1 on
> Raspberry Pi B+ running Raspbian. (This report is just 'for the record'.
> The model is superseded and I think no longer produced.)  The problem
> seems to be caused by
>
>  grep processor /proc/cpuinfo
> processor    : 0
> model name    : ARMv6-compatible processor rev 7 (v6l)
>
> (On Raspberry Pi 2 and 3 there is no error because the model name lines are
>
>  model name    : ARMv7 Processor rev 5 (v7l)
>  model name    : ARMv7 Processor rev 4 (v7l)
> )

I posted a related bug report to R bugzilla, 
<https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17213>. The patch 
included in that report is mainly about detecting physical CPUs across 
multiple CPU sockets, but should also fix this issue.

-- 
Mikko Korpela
Department of Geosciences and Geography
University of Helsinki


From kmillar at google.com  Wed Jan 18 00:13:51 2017
From: kmillar at google.com (Karl Millar)
Date: Tue, 17 Jan 2017 15:13:51 -0800
Subject: [Rd] unlicense
In-Reply-To: <c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
Message-ID: <CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>

Please don't use 'Unlimited' or 'Unlimited + ...'.

Google's lawyers don't recognize 'Unlimited' as being open-source, so
our policy doesn't allow us to use such packages due to lack of an
acceptable license.  To our lawyers, 'Unlimited + file LICENSE' means
something very different than it presumably means to Uwe.

Thanks,

Karl

On Sat, Jan 14, 2017 at 12:10 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
> Dear all,
>
> from "Writing R Extensions":
>
> The string ?Unlimited?, meaning that there are no restrictions on
> distribution or use other than those imposed by relevant laws (including
> copyright laws).
>
> If a package license restricts a base license (where permitted, e.g., using
> GPL-3 or AGPL-3 with an attribution clause), the additional terms should be
> placed in file LICENSE (or LICENCE), and the string ?+ file LICENSE? (or ?+
> file LICENCE?, respectively) should be appended to the
> corresponding individual license specification.
> ...
> Please note in particular that ?Public domain? is not a valid license, since
> it is not recognized in some jurisdictions."
>
> So perhaps you aim for
> License: Unlimited
>
> Best,
> Uwe Ligges
>
>
>
>
>
> On 14.01.2017 07:53, Deepayan Sarkar wrote:
>>
>> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>
>>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>>>
>>>>
>>>> I would like the unlicense (http://unlicense.org/) added to R
>>>> licenses.  Does anyone else think that worthwhile?
>>>>
>>>
>>> That's a question for you to answer, not to ask.  Who besides you thinks
>>> that it's a good license for open source software?
>>>
>>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>>> license, then CRAN would probably also recognize it.  If not, then CRAN
>>> doesn't have the resources to evaluate it and so is unlikely to recognize
>>> it.
>>
>>
>> Unlicense is listed in https://spdx.org/licenses/
>>
>> Debian does include software "licensed" like this, and seems to think
>> this is one way (not the only one) of declaring something to be
>> "public domain".  The first two examples I found:
>>
>> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
>>
>> https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1
>>
>> This follows the format explained in
>>
>> https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
>> which does not explicitly include Unlicense, but does include CC0,
>> which AFAICT is meant to formally license something so that it is
>> equivalent to being in the public domain. R does include CC0 as a
>> shorthand (e.g., geoknife).
>>
>> https://www.debian.org/legal/licenses/ says that
>>
>> <quote>
>>
>> Licenses currently found in Debian main include:
>>
>> - ...
>> - ...
>> - public domain (not a license, strictly speaking)
>>
>> </quote>
>>
>> The equivalent for CRAN would probably be something like "License:
>> public-domain + file LICENSE".
>>
>> -Deepayan
>>
>>> Duncan Murdoch
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Jan 18 00:35:10 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 18 Jan 2017 00:35:10 +0100
Subject: [Rd] unlicense
In-Reply-To: <CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
Message-ID: <a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>



On 18.01.2017 00:13, Karl Millar wrote:
> Please don't use 'Unlimited' or 'Unlimited + ...'.
>
> Google's lawyers don't recognize 'Unlimited' as being open-source, so
> our policy doesn't allow us to use such packages due to lack of an
> acceptable license.  To our lawyers, 'Unlimited + file LICENSE' means
> something very different than it presumably means to Uwe.


Karl,

thanks for this comment. What we like to hear now is a suggestion what 
the maintainer is supposed to do to get what he aims at, as we already 
know that "freeware" does not work at all and was hard enough to get to 
the "Unlimited" options.

We have many CRAN requests asking for what they should write for 
"freeware". Can we get an opinion from your layers which standard 
license comes closest to what these maintainers probably aim at and will 
work more or less globally, i.e. not only in the US?

Best,
Uwe



> Thanks,
>
> Karl
>
> On Sat, Jan 14, 2017 at 12:10 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>> Dear all,
>>
>> from "Writing R Extensions":
>>
>> The string ?Unlimited?, meaning that there are no restrictions on
>> distribution or use other than those imposed by relevant laws (including
>> copyright laws).
>>
>> If a package license restricts a base license (where permitted, e.g., using
>> GPL-3 or AGPL-3 with an attribution clause), the additional terms should be
>> placed in file LICENSE (or LICENCE), and the string ?+ file LICENSE? (or ?+
>> file LICENCE?, respectively) should be appended to the
>> corresponding individual license specification.
>> ...
>> Please note in particular that ?Public domain? is not a valid license, since
>> it is not recognized in some jurisdictions."
>>
>> So perhaps you aim for
>> License: Unlimited
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>
>> On 14.01.2017 07:53, Deepayan Sarkar wrote:
>>>
>>> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>>>>
>>>>>
>>>>> I would like the unlicense (http://unlicense.org/) added to R
>>>>> licenses.  Does anyone else think that worthwhile?
>>>>>
>>>>
>>>> That's a question for you to answer, not to ask.  Who besides you thinks
>>>> that it's a good license for open source software?
>>>>
>>>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>>>> license, then CRAN would probably also recognize it.  If not, then CRAN
>>>> doesn't have the resources to evaluate it and so is unlikely to recognize
>>>> it.
>>>
>>>
>>> Unlicense is listed in https://spdx.org/licenses/
>>>
>>> Debian does include software "licensed" like this, and seems to think
>>> this is one way (not the only one) of declaring something to be
>>> "public domain".  The first two examples I found:
>>>
>>> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
>>>
>>> https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1
>>>
>>> This follows the format explained in
>>>
>>> https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
>>> which does not explicitly include Unlicense, but does include CC0,
>>> which AFAICT is meant to formally license something so that it is
>>> equivalent to being in the public domain. R does include CC0 as a
>>> shorthand (e.g., geoknife).
>>>
>>> https://www.debian.org/legal/licenses/ says that
>>>
>>> <quote>
>>>
>>> Licenses currently found in Debian main include:
>>>
>>> - ...
>>> - ...
>>> - public domain (not a license, strictly speaking)
>>>
>>> </quote>
>>>
>>> The equivalent for CRAN would probably be something like "License:
>>> public-domain + file LICENSE".
>>>
>>> -Deepayan
>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kmillar at google.com  Wed Jan 18 02:32:04 2017
From: kmillar at google.com (Karl Millar)
Date: Tue, 17 Jan 2017 17:32:04 -0800
Subject: [Rd] unlicense
In-Reply-To: <a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
Message-ID: <CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>

Unfortunately, our lawyers say that they can't give legal advice in
this context.

My question would be, what are people looking for that the MIT or
2-clause BSD license don't provide?  They're short, clear, widely
accepted and very permissive.  Another possibility might be to
dual-license packages with both an OSI-approved license and
whatever-else-you-like, e.g.  'MIT | <my_unusual_license>', but IIUC
there's a bunch more complexity there than just using an OSI-approved
license.

Karl


On Tue, Jan 17, 2017 at 3:35 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 18.01.2017 00:13, Karl Millar wrote:
>>
>> Please don't use 'Unlimited' or 'Unlimited + ...'.
>>
>> Google's lawyers don't recognize 'Unlimited' as being open-source, so
>> our policy doesn't allow us to use such packages due to lack of an
>> acceptable license.  To our lawyers, 'Unlimited + file LICENSE' means
>> something very different than it presumably means to Uwe.
>
>
>
> Karl,
>
> thanks for this comment. What we like to hear now is a suggestion what the
> maintainer is supposed to do to get what he aims at, as we already know that
> "freeware" does not work at all and was hard enough to get to the
> "Unlimited" options.
>
> We have many CRAN requests asking for what they should write for "freeware".
> Can we get an opinion from your layers which standard license comes closest
> to what these maintainers probably aim at and will work more or less
> globally, i.e. not only in the US?
>
> Best,
> Uwe
>
>
>
>
>> Thanks,
>>
>> Karl
>>
>> On Sat, Jan 14, 2017 at 12:10 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de> wrote:
>>>
>>> Dear all,
>>>
>>> from "Writing R Extensions":
>>>
>>> The string ?Unlimited?, meaning that there are no restrictions on
>>> distribution or use other than those imposed by relevant laws (including
>>> copyright laws).
>>>
>>> If a package license restricts a base license (where permitted, e.g.,
>>> using
>>> GPL-3 or AGPL-3 with an attribution clause), the additional terms should
>>> be
>>> placed in file LICENSE (or LICENCE), and the string ?+ file LICENSE? (or
>>> ?+
>>> file LICENCE?, respectively) should be appended to the
>>> corresponding individual license specification.
>>> ...
>>> Please note in particular that ?Public domain? is not a valid license,
>>> since
>>> it is not recognized in some jurisdictions."
>>>
>>> So perhaps you aim for
>>> License: Unlimited
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>
>>>
>>>
>>> On 14.01.2017 07:53, Deepayan Sarkar wrote:
>>>>
>>>>
>>>> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> wrote:
>>>>>
>>>>>
>>>>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> I would like the unlicense (http://unlicense.org/) added to R
>>>>>> licenses.  Does anyone else think that worthwhile?
>>>>>>
>>>>>
>>>>> That's a question for you to answer, not to ask.  Who besides you
>>>>> thinks
>>>>> that it's a good license for open source software?
>>>>>
>>>>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>>>>> license, then CRAN would probably also recognize it.  If not, then CRAN
>>>>> doesn't have the resources to evaluate it and so is unlikely to
>>>>> recognize
>>>>> it.
>>>>
>>>>
>>>>
>>>> Unlicense is listed in https://spdx.org/licenses/
>>>>
>>>> Debian does include software "licensed" like this, and seems to think
>>>> this is one way (not the only one) of declaring something to be
>>>> "public domain".  The first two examples I found:
>>>>
>>>> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
>>>>
>>>>
>>>> https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1
>>>>
>>>> This follows the format explained in
>>>>
>>>>
>>>> https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
>>>> which does not explicitly include Unlicense, but does include CC0,
>>>> which AFAICT is meant to formally license something so that it is
>>>> equivalent to being in the public domain. R does include CC0 as a
>>>> shorthand (e.g., geoknife).
>>>>
>>>> https://www.debian.org/legal/licenses/ says that
>>>>
>>>> <quote>
>>>>
>>>> Licenses currently found in Debian main include:
>>>>
>>>> - ...
>>>> - ...
>>>> - public domain (not a license, strictly speaking)
>>>>
>>>> </quote>
>>>>
>>>> The equivalent for CRAN would probably be something like "License:
>>>> public-domain + file LICENSE".
>>>>
>>>> -Deepayan
>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevinushey at gmail.com  Wed Jan 18 04:46:43 2017
From: kevinushey at gmail.com (Kevin Ushey)
Date: Tue, 17 Jan 2017 22:46:43 -0500
Subject: [Rd] unlicense
In-Reply-To: <CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
Message-ID: <CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>

The Free Software Foundation maintains a list of free and GPL-compatible
software licenses here:

https://www.gnu.org/licenses/license-list.en.html#Unlicense

It appears that Unlicense is considered a free and GPL-compatible license;
however, the page does suggest using CC0 instead (which is indeed a license
approved / recognized by CRAN). CC0 appears to be the primary license
recommended by the FSF for software intended for the public domain.

On Tue, Jan 17, 2017 at 8:32 PM, Karl Millar via R-devel <
r-devel at r-project.org> wrote:

> Unfortunately, our lawyers say that they can't give legal advice in
> this context.
>
> My question would be, what are people looking for that the MIT or
> 2-clause BSD license don't provide?  They're short, clear, widely
> accepted and very permissive.  Another possibility might be to
> dual-license packages with both an OSI-approved license and
> whatever-else-you-like, e.g.  'MIT | <my_unusual_license>', but IIUC
> there's a bunch more complexity there than just using an OSI-approved
> license.
>
> Karl
>
>
> On Tue, Jan 17, 2017 at 3:35 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
> >
> >
> > On 18.01.2017 00:13, Karl Millar wrote:
> >>
> >> Please don't use 'Unlimited' or 'Unlimited + ...'.
> >>
> >> Google's lawyers don't recognize 'Unlimited' as being open-source, so
> >> our policy doesn't allow us to use such packages due to lack of an
> >> acceptable license.  To our lawyers, 'Unlimited + file LICENSE' means
> >> something very different than it presumably means to Uwe.
> >
> >
> >
> > Karl,
> >
> > thanks for this comment. What we like to hear now is a suggestion what
> the
> > maintainer is supposed to do to get what he aims at, as we already know
> that
> > "freeware" does not work at all and was hard enough to get to the
> > "Unlimited" options.
> >
> > We have many CRAN requests asking for what they should write for
> "freeware".
> > Can we get an opinion from your layers which standard license comes
> closest
> > to what these maintainers probably aim at and will work more or less
> > globally, i.e. not only in the US?
> >
> > Best,
> > Uwe
> >
> >
> >
> >
> >> Thanks,
> >>
> >> Karl
> >>
> >> On Sat, Jan 14, 2017 at 12:10 AM, Uwe Ligges
> >> <ligges at statistik.tu-dortmund.de> wrote:
> >>>
> >>> Dear all,
> >>>
> >>> from "Writing R Extensions":
> >>>
> >>> The string ?Unlimited?, meaning that there are no restrictions on
> >>> distribution or use other than those imposed by relevant laws
> (including
> >>> copyright laws).
> >>>
> >>> If a package license restricts a base license (where permitted, e.g.,
> >>> using
> >>> GPL-3 or AGPL-3 with an attribution clause), the additional terms
> should
> >>> be
> >>> placed in file LICENSE (or LICENCE), and the string ?+ file LICENSE?
> (or
> >>> ?+
> >>> file LICENCE?, respectively) should be appended to the
> >>> corresponding individual license specification.
> >>> ...
> >>> Please note in particular that ?Public domain? is not a valid license,
> >>> since
> >>> it is not recognized in some jurisdictions."
> >>>
> >>> So perhaps you aim for
> >>> License: Unlimited
> >>>
> >>> Best,
> >>> Uwe Ligges
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> On 14.01.2017 07:53, Deepayan Sarkar wrote:
> >>>>
> >>>>
> >>>> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
> >>>> <murdoch.duncan at gmail.com> wrote:
> >>>>>
> >>>>>
> >>>>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> I would like the unlicense (http://unlicense.org/) added to R
> >>>>>> licenses.  Does anyone else think that worthwhile?
> >>>>>>
> >>>>>
> >>>>> That's a question for you to answer, not to ask.  Who besides you
> >>>>> thinks
> >>>>> that it's a good license for open source software?
> >>>>>
> >>>>> If it is recognized by the OSF or FSF or some other authority as a
> FOSS
> >>>>> license, then CRAN would probably also recognize it.  If not, then
> CRAN
> >>>>> doesn't have the resources to evaluate it and so is unlikely to
> >>>>> recognize
> >>>>> it.
> >>>>
> >>>>
> >>>>
> >>>> Unlicense is listed in https://spdx.org/licenses/
> >>>>
> >>>> Debian does include software "licensed" like this, and seems to think
> >>>> this is one way (not the only one) of declaring something to be
> >>>> "public domain".  The first two examples I found:
> >>>>
> >>>> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
> >>>>
> >>>>
> >>>> https://tracker.debian.org/media/packages/w/wiredtiger/
> copyright-2.6.1%2Bds-1
> >>>>
> >>>> This follows the format explained in
> >>>>
> >>>>
> >>>> https://www.debian.org/doc/packaging-manuals/copyright-
> format/1.0/#license-specification,
> >>>> which does not explicitly include Unlicense, but does include CC0,
> >>>> which AFAICT is meant to formally license something so that it is
> >>>> equivalent to being in the public domain. R does include CC0 as a
> >>>> shorthand (e.g., geoknife).
> >>>>
> >>>> https://www.debian.org/legal/licenses/ says that
> >>>>
> >>>> <quote>
> >>>>
> >>>> Licenses currently found in Debian main include:
> >>>>
> >>>> - ...
> >>>> - ...
> >>>> - public domain (not a license, strictly speaking)
> >>>>
> >>>> </quote>
> >>>>
> >>>> The equivalent for CRAN would probably be something like "License:
> >>>> public-domain + file LICENSE".
> >>>>
> >>>> -Deepayan
> >>>>
> >>>>> Duncan Murdoch
> >>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From brian at braverock.com  Wed Jan 18 14:23:39 2017
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 18 Jan 2017 07:23:39 -0600
Subject: [Rd] unlicense
In-Reply-To: <CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
	<CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>
Message-ID: <1484745819.15208.18.camel@braverock.com>


On Tue, 2017-01-17 at 22:46 -0500, Kevin Ushey wrote:
> It appears that Unlicense is considered a free and GPL-compatible
> license; however, the page does suggest using CC0 instead (which is
> indeed a license approved / recognized by CRAN). CC0 appears to be
> the primary license recommended by the FSF for software intended for
> the public domain.

I'd second the recommendation for CC0. ?Lawyers at IP-restrictive firms
I've worked for in the past have been OK with this license.

?- Brian


From charlie at stat.umn.edu  Wed Jan 18 15:12:10 2017
From: charlie at stat.umn.edu (Charles Geyer)
Date: Wed, 18 Jan 2017 08:12:10 -0600
Subject: [Rd] unlicense
In-Reply-To: <1484745819.15208.18.camel@braverock.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
	<CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>
	<1484745819.15208.18.camel@braverock.com>
Message-ID: <CAKctRd13M842zRptxHWg4YtnpR1dS=0KCjqNmarqKhXw3Ma6jA@mail.gmail.com>

In that case, perhaps the question could be changed to could CC0 be
added to the list of R licences.  Right now the only CC licence that
is in the R licenses is CC-BY-SA-4.0.

On Wed, Jan 18, 2017 at 7:23 AM, Brian G. Peterson <brian at braverock.com> wrote:
>
> On Tue, 2017-01-17 at 22:46 -0500, Kevin Ushey wrote:
>> It appears that Unlicense is considered a free and GPL-compatible
>> license; however, the page does suggest using CC0 instead (which is
>> indeed a license approved / recognized by CRAN). CC0 appears to be
>> the primary license recommended by the FSF for software intended for
>> the public domain.
>
> I'd second the recommendation for CC0.  Lawyers at IP-restrictive firms
> I've worked for in the past have been OK with this license.
>
>  - Brian
>



-- 
Charles Geyer
Professor, School of Statistics
Resident Fellow, Minnesota Center for Philosophy of Science
University of Minnesota
charlie at stat.umn.edu


From pdalgd at gmail.com  Wed Jan 18 15:22:22 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Jan 2017 15:22:22 +0100
Subject: [Rd] unlicense
In-Reply-To: <CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
Message-ID: <475752B0-71C0-4D5D-BB36-B09C35BF8D07@gmail.com>

Probably, one side of the issue is that people are unaware of the dangers of overly permissive statements, like the infamous "collection copyright" which originally applied to collections of medieval music by anonymous composers, but extends to the individual items, so that you can't (say) photocopy "Greensleeves" for classroom use without infringing. 

However, this has also been applied to software collections harvested from the public domain; the notorious example being the Numerical Recipes book claiming licenses to use the subroutines it contained. This is the sort of thing that makes IP lawyers uncomfortable with anything except well standardized licenses.

-pd

On 18 Jan 2017, at 02:32 , Karl Millar via R-devel <r-devel at r-project.org> wrote:

> Unfortunately, our lawyers say that they can't give legal advice in
> this context.
> 
> My question would be, what are people looking for that the MIT or
> 2-clause BSD license don't provide?  They're short, clear, widely
> accepted and very permissive.  Another possibility might be to
> dual-license packages with both an OSI-approved license and
> whatever-else-you-like, e.g.  'MIT | <my_unusual_license>', but IIUC
> there's a bunch more complexity there than just using an OSI-approved
> license.
> 
> Karl
> 
> 
> On Tue, Jan 17, 2017 at 3:35 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>> 
>> 
>> On 18.01.2017 00:13, Karl Millar wrote:
>>> 
>>> Please don't use 'Unlimited' or 'Unlimited + ...'.
>>> 
>>> Google's lawyers don't recognize 'Unlimited' as being open-source, so
>>> our policy doesn't allow us to use such packages due to lack of an
>>> acceptable license.  To our lawyers, 'Unlimited + file LICENSE' means
>>> something very different than it presumably means to Uwe.
>> 
>> 
>> 
>> Karl,
>> 
>> thanks for this comment. What we like to hear now is a suggestion what the
>> maintainer is supposed to do to get what he aims at, as we already know that
>> "freeware" does not work at all and was hard enough to get to the
>> "Unlimited" options.
>> 
>> We have many CRAN requests asking for what they should write for "freeware".
>> Can we get an opinion from your layers which standard license comes closest
>> to what these maintainers probably aim at and will work more or less
>> globally, i.e. not only in the US?
>> 
>> Best,
>> Uwe
>> 
>> 
>> 
>> 
>>> Thanks,
>>> 
>>> Karl
>>> 
>>> On Sat, Jan 14, 2017 at 12:10 AM, Uwe Ligges
>>> <ligges at statistik.tu-dortmund.de> wrote:
>>>> 
>>>> Dear all,
>>>> 
>>>> from "Writing R Extensions":
>>>> 
>>>> The string ?Unlimited?, meaning that there are no restrictions on
>>>> distribution or use other than those imposed by relevant laws (including
>>>> copyright laws).
>>>> 
>>>> If a package license restricts a base license (where permitted, e.g.,
>>>> using
>>>> GPL-3 or AGPL-3 with an attribution clause), the additional terms should
>>>> be
>>>> placed in file LICENSE (or LICENCE), and the string ?+ file LICENSE? (or
>>>> ?+
>>>> file LICENCE?, respectively) should be appended to the
>>>> corresponding individual license specification.
>>>> ...
>>>> Please note in particular that ?Public domain? is not a valid license,
>>>> since
>>>> it is not recognized in some jurisdictions."
>>>> 
>>>> So perhaps you aim for
>>>> License: Unlimited
>>>> 
>>>> Best,
>>>> Uwe Ligges
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On 14.01.2017 07:53, Deepayan Sarkar wrote:
>>>>> 
>>>>> 
>>>>> On Sat, Jan 14, 2017 at 5:49 AM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com> wrote:
>>>>>> 
>>>>>> 
>>>>>> On 13/01/2017 3:21 PM, Charles Geyer wrote:
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> I would like the unlicense (http://unlicense.org/) added to R
>>>>>>> licenses.  Does anyone else think that worthwhile?
>>>>>>> 
>>>>>> 
>>>>>> That's a question for you to answer, not to ask.  Who besides you
>>>>>> thinks
>>>>>> that it's a good license for open source software?
>>>>>> 
>>>>>> If it is recognized by the OSF or FSF or some other authority as a FOSS
>>>>>> license, then CRAN would probably also recognize it.  If not, then CRAN
>>>>>> doesn't have the resources to evaluate it and so is unlikely to
>>>>>> recognize
>>>>>> it.
>>>>> 
>>>>> 
>>>>> 
>>>>> Unlicense is listed in https://spdx.org/licenses/
>>>>> 
>>>>> Debian does include software "licensed" like this, and seems to think
>>>>> this is one way (not the only one) of declaring something to be
>>>>> "public domain".  The first two examples I found:
>>>>> 
>>>>> https://tracker.debian.org/media/packages/r/rasqal/copyright-0.9.29-1
>>>>> 
>>>>> 
>>>>> https://tracker.debian.org/media/packages/w/wiredtiger/copyright-2.6.1%2Bds-1
>>>>> 
>>>>> This follows the format explained in
>>>>> 
>>>>> 
>>>>> https://www.debian.org/doc/packaging-manuals/copyright-format/1.0/#license-specification,
>>>>> which does not explicitly include Unlicense, but does include CC0,
>>>>> which AFAICT is meant to formally license something so that it is
>>>>> equivalent to being in the public domain. R does include CC0 as a
>>>>> shorthand (e.g., geoknife).
>>>>> 
>>>>> https://www.debian.org/legal/licenses/ says that
>>>>> 
>>>>> <quote>
>>>>> 
>>>>> Licenses currently found in Debian main include:
>>>>> 
>>>>> - ...
>>>>> - ...
>>>>> - public domain (not a license, strictly speaking)
>>>>> 
>>>>> </quote>
>>>>> 
>>>>> The equivalent for CRAN would probably be something like "License:
>>>>> public-domain + file LICENSE".
>>>>> 
>>>>> -Deepayan
>>>>> 
>>>>>> Duncan Murdoch
>>>>>> 
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Kurt.Hornik at wu.ac.at  Wed Jan 18 16:44:07 2017
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Wed, 18 Jan 2017 16:44:07 +0100
Subject: [Rd] unlicense
In-Reply-To: <CAKctRd13M842zRptxHWg4YtnpR1dS=0KCjqNmarqKhXw3Ma6jA@mail.gmail.com>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
	<CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>
	<1484745819.15208.18.camel@braverock.com>
	<CAKctRd13M842zRptxHWg4YtnpR1dS=0KCjqNmarqKhXw3Ma6jA@mail.gmail.com>
Message-ID: <22655.36167.116176.881303@aragorn.wu.ac.at>

>>>>> Charles Geyer writes:

> In that case, perhaps the question could be changed to could CC0 be
> added to the list of R licences.  Right now the only CC licence that
> is in the R licenses is CC-BY-SA-4.0.

Hmm, I see

Name: CC0
FSF: free_and_GPLv3_compatible (https://www.gnu.org/licenses/license-list.html#CC0)
OSI: NA (https://opensource.org/faq#cc-zero)
URL: https://creativecommons.org/publicdomain/zero/1.0/legalcode
FOSS: yes

in the R license db ...

-k

> On Wed, Jan 18, 2017 at 7:23 AM, Brian G. Peterson <brian at braverock.com> wrote:
>> 
>> On Tue, 2017-01-17 at 22:46 -0500, Kevin Ushey wrote:
>>> It appears that Unlicense is considered a free and GPL-compatible
>>> license; however, the page does suggest using CC0 instead (which is
>>> indeed a license approved / recognized by CRAN). CC0 appears to be
>>> the primary license recommended by the FSF for software intended for
>>> the public domain.
>> 
>> I'd second the recommendation for CC0.  Lawyers at IP-restrictive firms
>> I've worked for in the past have been OK with this license.
>> 
>> - Brian
>> 



> -- 
> Charles Geyer
> Professor, School of Statistics
> Resident Fellow, Minnesota Center for Philosophy of Science
> University of Minnesota
> charlie at stat.umn.edu

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From charlie at stat.umn.edu  Wed Jan 18 18:09:02 2017
From: charlie at stat.umn.edu (Charles Geyer)
Date: Wed, 18 Jan 2017 11:09:02 -0600
Subject: [Rd] unlicense
In-Reply-To: <22655.36167.116176.881303@aragorn.wu.ac.at>
References: <CAKctRd3bWPGhzN3McdJQovTthUt=AYVQV3g-ZKNvEt5jZ1JnmA@mail.gmail.com>
	<09cb536a-cdba-1eeb-b6a0-4bad571032bd@gmail.com>
	<CADfFDC5HB+qCk0it_AW9wuHSHdDqJ-rRW=NeL=S3SYrPR5GZ1g@mail.gmail.com>
	<c9c4e11d-4476-ed46-3ff7-ed68c3a83145@statistik.tu-dortmund.de>
	<CABz6aZdx9PXcU2fRtXRyJ_k_7BVW+jjTcnka_2o2zvNW+8KQUg@mail.gmail.com>
	<a9b2554d-8b7e-06b5-8786-26d53e1971a5@statistik.tu-dortmund.de>
	<CABz6aZevNNXpSZUY-OxQe+JJZe9OKufnVFExEr7rQ7QHVnT2NQ@mail.gmail.com>
	<CAJXgQP1DU_18xfLhMrqC=qvpcb77s5m3c5rEymLwr7vLikK3UA@mail.gmail.com>
	<1484745819.15208.18.camel@braverock.com>
	<CAKctRd13M842zRptxHWg4YtnpR1dS=0KCjqNmarqKhXw3Ma6jA@mail.gmail.com>
	<22655.36167.116176.881303@aragorn.wu.ac.at>
Message-ID: <CAKctRd3tdp2U-7MwZaTHh3L3+VRM1_o0DpgkxsgauQ=VSW36Wg@mail.gmail.com>

I was looking at https://www.r-project.org/Licenses/ which is first
when you google for "R licenses".  Silly me.  Kurt says I should have
been looking at share/licenses/license.db in the R source tree.
Thanks.  I'm satisfied now.

I don't have any CRAN packages with "Unlimited" on them, but I do have
some on github that are just examples for teaching.  I'll change them
to CC0.

On Wed, Jan 18, 2017 at 9:44 AM, Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:
>>>>>> Charles Geyer writes:
>
>> In that case, perhaps the question could be changed to could CC0 be
>> added to the list of R licences.  Right now the only CC licence that
>> is in the R licenses is CC-BY-SA-4.0.
>
> Hmm, I see
>
> Name: CC0
> FSF: free_and_GPLv3_compatible (https://www.gnu.org/licenses/license-list.html#CC0)
> OSI: NA (https://opensource.org/faq#cc-zero)
> URL: https://creativecommons.org/publicdomain/zero/1.0/legalcode
> FOSS: yes
>
> in the R license db ...
>
> -k
>
>> On Wed, Jan 18, 2017 at 7:23 AM, Brian G. Peterson <brian at braverock.com> wrote:
>>>
>>> On Tue, 2017-01-17 at 22:46 -0500, Kevin Ushey wrote:
>>>> It appears that Unlicense is considered a free and GPL-compatible
>>>> license; however, the page does suggest using CC0 instead (which is
>>>> indeed a license approved / recognized by CRAN). CC0 appears to be
>>>> the primary license recommended by the FSF for software intended for
>>>> the public domain.
>>>
>>> I'd second the recommendation for CC0.  Lawyers at IP-restrictive firms
>>> I've worked for in the past have been OK with this license.
>>>
>>> - Brian
>>>
>
>
>
>> --
>> Charles Geyer
>> Professor, School of Statistics
>> Resident Fellow, Minnesota Center for Philosophy of Science
>> University of Minnesota
>> charlie at stat.umn.edu
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Charles Geyer
Professor, School of Statistics
Resident Fellow, Minnesota Center for Philosophy of Science
University of Minnesota
charlie at stat.umn.edu


From nalimilan at club.fr  Thu Jan 19 13:58:31 2017
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 19 Jan 2017 13:58:31 +0100
Subject: [Rd] xtabs(), factors and NAs
Message-ID: <1484830711.8924.41.camel@club.fr>

Hi all,

I know this issue has been discussed a few times in the past already,
but Martin Maechler suggested in a bug report [1] that I raise it here.

Basically, there is no (easy) way of printing NAs for all variables
when calling xtabs() on factors. Passing 'exclude=NULL,
na.action=na.pass' works for character vectors, but not for factors.

> test <- data.frame(x=c("a",NA))
> xtabs(~ x, exclude=NULL,
na.action=na.pass, data=test)
x
a?
1?

> test <- data.frame(x=factor(c("a",NA)))
> xtabs(~ x, exclude=NULL,
na.action=na.pass, data=test)
x
a?
1?


Even if it's documented, this inconsistency is annoying. When checking
data, it is often useful to print all NA values temporarily, without
calling addNA() individually on all crossed variables.

Would it make sense to add a new argument similar to table()'s useNA
which would behave the same for all input vector types?


Regards


1: https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14630


From lukas.stadler at oracle.com  Fri Jan 20 14:52:01 2017
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Fri, 20 Jan 2017 14:52:01 +0100
Subject: [Rd] NaN behavior of cumsum
Message-ID: <9A7219BE-A728-45E0-B02E-E1834841D749@oracle.com>

Hi!

I noticed that cumsum behaves different than the other cumulative functions wrt. NaN values:
> values <- c(1,2,NaN,1)
> for ( f in c(cumsum, cumprod, cummin, cummax)) print(f(values))
[1]  1  3 NA NA
[1]   1   2 NaN NaN
[1]   1   1 NaN NaN
[1]   1   2 NaN NaN

The reason is that cumsum (in cum.c:33) contains an explicit check for ISNAN.
Is that intentional?
IMHO, ISNA would be better (because it would make the behavior consistent with the other functions).

- Lukas

From nicolas.paris at aphp.fr  Fri Jan 20 15:33:35 2017
From: nicolas.paris at aphp.fr (Nicolas Paris)
Date: Fri, 20 Jan 2017 15:33:35 +0100
Subject: [Rd] How to handle INT8 data
Message-ID: <20170120143335.GE9661@aphp.fr>

Hello r users,

I have to deal with int8 data with R. AFAIK  R does only handle int4
with `as.integer` function [1]. I wonder:
1. what is the better approach to handle int8 ? `as.character` ?
`as.numeric` ?
2. is there any plan to handle int8 in the future ? As you might know,
int4 is to small to deal with earth population right now.

Thanks for you ideas,

int8 eg:

     human_id      
----------------------
 -1311071933951566764
 -4708675461424073238
 -6865005668390999818
  5578000650960353108
 -3219674686933841021
 -6469229889308771589
  -606871692563545028
 -8199987422425699249
  -463287495999648233
  7675955260644241951

reference:
1. https://www.r-bloggers.com/r-in-a-64-bit-world/

-- 
Nicolas PARIS


From gmbecker at ucdavis.edu  Fri Jan 20 16:19:14 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 20 Jan 2017 07:19:14 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120143335.GE9661@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
Message-ID: <CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>

I am not on R-core, so cannot speak to future plans to internally support
int8 (though my impression is that there aren't any, at least none that are
close to fruition).

The standard way of dealing with whole numbers too big to fit in an integer
is to put them in a numeric (double down in C land). this can represent
integers up to 2^53 without loss of precision see (
http://stackoverflow.com/questions/1848700/biggest-integer-that-can-be-stored-in-a-double).
This is how long vector indices are (currently) implemented in R. If it's
good enough for indices it's probably good enough for whatever you need
them for.

Hope that helps.

~G


On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Hello r users,
>
> I have to deal with int8 data with R. AFAIK  R does only handle int4
> with `as.integer` function [1]. I wonder:
> 1. what is the better approach to handle int8 ? `as.character` ?
> `as.numeric` ?
> 2. is there any plan to handle int8 in the future ? As you might know,
> int4 is to small to deal with earth population right now.
>
> Thanks for you ideas,
>
> int8 eg:
>
>      human_id
> ----------------------
>  -1311071933951566764
>  -4708675461424073238
>  -6865005668390999818
>   5578000650960353108
>  -3219674686933841021
>  -6469229889308771589
>   -606871692563545028
>  -8199987422425699249
>   -463287495999648233
>   7675955260644241951
>
> reference:
> 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>
> --
> Nicolas PARIS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From murray at stokely.org  Fri Jan 20 18:09:33 2017
From: murray at stokely.org (Murray Stokely)
Date: Fri, 20 Jan 2017 09:09:33 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
Message-ID: <CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>

The lack of 64 bit integer support causes lots of problems when dealing
with certain types of data where the loss of precision from coercing to 53
bits with double is unacceptable.

Two packages were developed to deal with this:  int64 and bit64.

You may need to find archival versions of these packages if they've fallen
off cran.

Murray (mobile phone)

On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu> wrote:

I am not on R-core, so cannot speak to future plans to internally support
int8 (though my impression is that there aren't any, at least none that are
close to fruition).

The standard way of dealing with whole numbers too big to fit in an integer
is to put them in a numeric (double down in C land). this can represent
integers up to 2^53 without loss of precision see (
http://stackoverflow.com/questions/1848700/biggest-
integer-that-can-be-stored-in-a-double).
This is how long vector indices are (currently) implemented in R. If it's
good enough for indices it's probably good enough for whatever you need
them for.

Hope that helps.

~G


On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Hello r users,
>
> I have to deal with int8 data with R. AFAIK  R does only handle int4
> with `as.integer` function [1]. I wonder:
> 1. what is the better approach to handle int8 ? `as.character` ?
> `as.numeric` ?
> 2. is there any plan to handle int8 in the future ? As you might know,
> int4 is to small to deal with earth population right now.
>
> Thanks for you ideas,
>
> int8 eg:
>
>      human_id
> ----------------------
>  -1311071933951566764
>  -4708675461424073238
>  -6865005668390999818
>   5578000650960353108
>  -3219674686933841021
>  -6469229889308771589
>   -606871692563545028
>  -8199987422425699249
>   -463287495999648233
>   7675955260644241951
>
> reference:
> 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>
> --
> Nicolas PARIS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



--
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From nicolas.paris at aphp.fr  Fri Jan 20 18:17:33 2017
From: nicolas.paris at aphp.fr (Nicolas Paris)
Date: Fri, 20 Jan 2017 18:17:33 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
Message-ID: <20170120171733.GB32106@aphp.fr>

Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
> The lack of 64 bit integer support causes lots of problems when dealing with
> certain types of data where the loss of precision from coercing to 53 bits with
> double is unacceptable.

Hello Murray,
Do you mean, by eg. -1311071933951566764 loses in precision during 
as.numeric(-1311071933951566764) process ?
Thanks,
> 
> Two packages were developed to deal with this:  int64 and bit64.
> 
> You may need to find archival versions of these packages if they've fallen off
> cran.
> 
> Murray (mobile phone)
> 
> On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu> wrote:
> 
>     I am not on R-core, so cannot speak to future plans to internally support
>     int8 (though my impression is that there aren't any, at least none that are
>     close to fruition).
> 
>     The standard way of dealing with whole numbers too big to fit in an integer
>     is to put them in a numeric (double down in C land). this can represent
>     integers up to 2^53 without loss of precision see (
>     http://stackoverflow.com/questions/1848700/biggest-
>     integer-that-can-be-stored-in-a-double).
>     This is how long vector indices are (currently) implemented in R. If it's
>     good enough for indices it's probably good enough for whatever you need
>     them for.
> 
>     Hope that helps.
> 
>     ~G
> 
> 
>     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
>     wrote:
> 
>     > Hello r users,
>     >
>     > I have to deal with int8 data with R. AFAIK  R does only handle int4
>     > with `as.integer` function [1]. I wonder:
>     > 1. what is the better approach to handle int8 ? `as.character` ?
>     > `as.numeric` ?
>     > 2. is there any plan to handle int8 in the future ? As you might know,
>     > int4 is to small to deal with earth population right now.
>     >
>     > Thanks for you ideas,
>     >
>     > int8 eg:
>     >
>     >      human_id
>     > ----------------------
>     >  -1311071933951566764
>     >  -4708675461424073238
>     >  -6865005668390999818
>     >   5578000650960353108
>     >  -3219674686933841021
>     >  -6469229889308771589
>     >   -606871692563545028
>     >  -8199987422425699249
>     >   -463287495999648233
>     >   7675955260644241951
>     >
>     > reference:
>     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>     >
>     > --
>     > Nicolas PARIS
>     >
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >
> 
> 
> 
>     --
>     Gabriel Becker, PhD
>     Associate Scientist (Bioinformatics)
>     Genentech Research
> 
>             [[alternative HTML version deleted]]
> 
>     ______________________________________________
>     R-devel at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Nicolas PARIS


From wdunlap at tibco.com  Fri Jan 20 18:16:42 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Jan 2017 09:16:42 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120143335.GE9661@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
Message-ID: <CAF8bMcbB6mnDv=enrh8KYjXhRzUX1uaSdp2Ly9=DFv-ST5CRuw@mail.gmail.com>

If these are identifiers, store them as strings.  If not, what sort of
calculations do you plan on doing with them?
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr> wrote:
> Hello r users,
>
> I have to deal with int8 data with R. AFAIK  R does only handle int4
> with `as.integer` function [1]. I wonder:
> 1. what is the better approach to handle int8 ? `as.character` ?
> `as.numeric` ?
> 2. is there any plan to handle int8 in the future ? As you might know,
> int4 is to small to deal with earth population right now.
>
> Thanks for you ideas,
>
> int8 eg:
>
>      human_id
> ----------------------
>  -1311071933951566764
>  -4708675461424073238
>  -6865005668390999818
>   5578000650960353108
>  -3219674686933841021
>  -6469229889308771589
>   -606871692563545028
>  -8199987422425699249
>   -463287495999648233
>   7675955260644241951
>
> reference:
> 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>
> --
> Nicolas PARIS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nicolas.paris at aphp.fr  Fri Jan 20 18:28:11 2017
From: nicolas.paris at aphp.fr (Nicolas Paris)
Date: Fri, 20 Jan 2017 18:28:11 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAF8bMcbB6mnDv=enrh8KYjXhRzUX1uaSdp2Ly9=DFv-ST5CRuw@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CAF8bMcbB6mnDv=enrh8KYjXhRzUX1uaSdp2Ly9=DFv-ST5CRuw@mail.gmail.com>
Message-ID: <20170120172811.GC32106@aphp.fr>

Right, they are identifiers.

Storing them as String has drawbacks:
- huge to store in memory
- slow to process
- huge to index (by eg data.table columns indexes)

Why not storing them as numeric ?

Thanks,

Le 20 janv. 2017 ? 18h16, William Dunlap ?crivait :
> If these are identifiers, store them as strings.  If not, what sort of
> calculations do you plan on doing with them?
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr> wrote:
> > Hello r users,
> >
> > I have to deal with int8 data with R. AFAIK  R does only handle int4
> > with `as.integer` function [1]. I wonder:
> > 1. what is the better approach to handle int8 ? `as.character` ?
> > `as.numeric` ?
> > 2. is there any plan to handle int8 in the future ? As you might know,
> > int4 is to small to deal with earth population right now.
> >
> > Thanks for you ideas,
> >
> > int8 eg:
> >
> >      human_id
> > ----------------------
> >  -1311071933951566764
> >  -4708675461424073238
> >  -6865005668390999818
> >   5578000650960353108
> >  -3219674686933841021
> >  -6469229889308771589
> >   -606871692563545028
> >  -8199987422425699249
> >   -463287495999648233
> >   7675955260644241951
> >
> > reference:
> > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
> >
> > --
> > Nicolas PARIS
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Nicolas PARIS
Responsable R & D
WIND - PACTE, H?pital Rothschild ( RTH )
Courriel : nicolas.paris at aphp.fr
Tel : 01 48 04 21 07


From murray at stokely.org  Fri Jan 20 18:29:24 2017
From: murray at stokely.org (Murray Stokely)
Date: Fri, 20 Jan 2017 09:29:24 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
Message-ID: <CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>

2^53 == 2^53+1
TRUE

Which makes joining or grouping data sets with 64 bit identifiers
problematic.

Murray (mobile)

On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:

Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
> The lack of 64 bit integer support causes lots of problems when dealing
with
> certain types of data where the loss of precision from coercing to 53
bits with
> double is unacceptable.

Hello Murray,
Do you mean, by eg. -1311071933951566764 loses in precision during
as.numeric(-1311071933951566764) process ?
Thanks,
>
> Two packages were developed to deal with this:  int64 and bit64.
>
> You may need to find archival versions of these packages if they've
fallen off
> cran.
>
> Murray (mobile phone)
>
> On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu> wrote:
>
>     I am not on R-core, so cannot speak to future plans to internally
support
>     int8 (though my impression is that there aren't any, at least none
that are
>     close to fruition).
>
>     The standard way of dealing with whole numbers too big to fit in an
integer
>     is to put them in a numeric (double down in C land). this can
represent
>     integers up to 2^53 without loss of precision see (
>     http://stackoverflow.com/questions/1848700/biggest-
>     integer-that-can-be-stored-in-a-double).
>     This is how long vector indices are (currently) implemented in R. If
it's
>     good enough for indices it's probably good enough for whatever you
need
>     them for.
>
>     Hope that helps.
>
>     ~G
>
>
>     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
>     wrote:
>
>     > Hello r users,
>     >
>     > I have to deal with int8 data with R. AFAIK  R does only handle int4
>     > with `as.integer` function [1]. I wonder:
>     > 1. what is the better approach to handle int8 ? `as.character` ?
>     > `as.numeric` ?
>     > 2. is there any plan to handle int8 in the future ? As you might
know,
>     > int4 is to small to deal with earth population right now.
>     >
>     > Thanks for you ideas,
>     >
>     > int8 eg:
>     >
>     >      human_id
>     > ----------------------
>     >  -1311071933951566764
>     >  -4708675461424073238
>     >  -6865005668390999818
>     >   5578000650960353108
>     >  -3219674686933841021
>     >  -6469229889308771589
>     >   -606871692563545028
>     >  -8199987422425699249
>     >   -463287495999648233
>     >   7675955260644241951
>     >
>     > reference:
>     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>     >
>     > --
>     > Nicolas PARIS
>     >
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >
>
>
>
>     --
>     Gabriel Becker, PhD
>     Associate Scientist (Bioinformatics)
>     Genentech Research
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-devel at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

--
Nicolas PARIS

	[[alternative HTML version deleted]]


From nicolas.paris at aphp.fr  Fri Jan 20 18:47:55 2017
From: nicolas.paris at aphp.fr (Nicolas Paris)
Date: Fri, 20 Jan 2017 18:47:55 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
Message-ID: <20170120174755.GE32106@aphp.fr>

Well I definitely cannot use them as numeric because join is the main
reason of those identifiers.

About int64 and bit64 packages, it's not a solution, because I am
releasing a dataset for external users. I cannot ask them to install a
package in order to exploit them.

I have to be very carefull when releasing the data. If a user just use
read.csv functions, they by default cast the identifiers as numeric.

$ more res.csv
"col1";"col2"
"-1311071933951566764";"toto"
"-1311071933951566764";"tata"


> read.table("res.csv",sep=";",header=T)
           col1 col2
1 -1.311072e+18 toto
2 -1.311072e+18 tata

>sapply(read.table("res.csv",sep=";",header=T),class)
     col1      col2
"numeric"  "factor"

> read.table("res.csv",sep=";",header=T,colClasses="character")
col1 col2
1 -1311071933951566764 toto
2 -1311071933951566764 tata

Am I comdemned to provide a R script with the data in order to exploit the dataset ?

Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
> 2^53 == 2^53+1
> TRUE
> 
> Which makes joining or grouping data sets with 64 bit identifiers problematic.
> 
> Murray (mobile)
> 
> On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:
> 
>     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
>     > The lack of 64 bit integer support causes lots of problems when dealing
>     with
>     > certain types of data where the loss of precision from coercing to 53
>     bits with
>     > double is unacceptable.
> 
>     Hello Murray,
>     Do you mean, by eg. -1311071933951566764 loses in precision during
>     as.numeric(-1311071933951566764) process ?
>     Thanks,
>     >
>     > Two packages were developed to deal with this:  int64 and bit64.
>     >
>     > You may need to find archival versions of these packages if they've
>     fallen off
>     > cran.
>     >
>     > Murray (mobile phone)
>     >
>     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu> wrote:
>     >
>     >     I am not on R-core, so cannot speak to future plans to internally
>     support
>     >     int8 (though my impression is that there aren't any, at least none
>     that are
>     >     close to fruition).
>     >
>     >     The standard way of dealing with whole numbers too big to fit in an
>     integer
>     >     is to put them in a numeric (double down in C land). this can
>     represent
>     >     integers up to 2^53 without loss of precision see (
>     >     http://stackoverflow.com/questions/1848700/biggest-
>     >     integer-that-can-be-stored-in-a-double).
>     >     This is how long vector indices are (currently) implemented in R. If
>     it's
>     >     good enough for indices it's probably good enough for whatever you
>     need
>     >     them for.
>     >
>     >     Hope that helps.
>     >
>     >     ~G
>     >
>     >
>     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr
>     >
>     >     wrote:
>     >
>     >     > Hello r users,
>     >     >
>     >     > I have to deal with int8 data with R. AFAIK  R does only handle
>     int4
>     >     > with `as.integer` function [1]. I wonder:
>     >     > 1. what is the better approach to handle int8 ? `as.character` ?
>     >     > `as.numeric` ?
>     >     > 2. is there any plan to handle int8 in the future ? As you might
>     know,
>     >     > int4 is to small to deal with earth population right now.
>     >     >
>     >     > Thanks for you ideas,
>     >     >
>     >     > int8 eg:
>     >     >
>     >     >      human_id
>     >     > ----------------------
>     >     >  -1311071933951566764
>     >     >  -4708675461424073238
>     >     >  -6865005668390999818
>     >     >   5578000650960353108
>     >     >  -3219674686933841021
>     >     >  -6469229889308771589
>     >     >   -606871692563545028
>     >     >  -8199987422425699249
>     >     >   -463287495999648233
>     >     >   7675955260644241951
>     >     >
>     >     > reference:
>     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>     >     >
>     >     > --
>     >     > Nicolas PARIS
>     >     >
>     >     > ______________________________________________
>     >     > R-devel at r-project.org mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >     >
>     >
>     >
>     >
>     >     --
>     >     Gabriel Becker, PhD
>     >     Associate Scientist (Bioinformatics)
>     >     Genentech Research
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     ______________________________________________
>     >     R-devel at r-project.org mailing list
>     >     https://stat.ethz.ch/mailman/listinfo/r-devel
>     >
>     >
> 
>     --
>     Nicolas PARIS
> 
> 

-- 
Nicolas PARIS


From gmbecker at ucdavis.edu  Fri Jan 20 18:57:04 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 20 Jan 2017 09:57:04 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120174755.GE32106@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
Message-ID: <CADwqtCOPLc7gw_jtKqj4+obA2EVSTxALoHOjZzBRvBv9BcMz9Q@mail.gmail.com>

How many unique idenfiiers do you have?

If they are large (in terms of bytes) but you don't have that many of them
(eg the total possible number you'll ever have is < INT_MAX), you could
store them as factors. You get the speed of integers but the labeling of
full "precision" strings.  Factors are fast for joins.

~G

On Fri, Jan 20, 2017 at 9:47 AM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Well I definitely cannot use them as numeric because join is the main
> reason of those identifiers.
>
> About int64 and bit64 packages, it's not a solution, because I am
> releasing a dataset for external users. I cannot ask them to install a
> package in order to exploit them.
>
> I have to be very carefull when releasing the data. If a user just use
> read.csv functions, they by default cast the identifiers as numeric.
>
> $ more res.csv
> "col1";"col2"
> "-1311071933951566764";"toto"
> "-1311071933951566764";"tata"
>
>
> > read.table("res.csv",sep=";",header=T)
>            col1 col2
> 1 -1.311072e+18 toto
> 2 -1.311072e+18 tata
>
> >sapply(read.table("res.csv",sep=";",header=T),class)
>      col1      col2
> "numeric"  "factor"
>
> > read.table("res.csv",sep=";",header=T,colClasses="character")
> col1 col2
> 1 -1311071933951566764 toto
> 2 -1311071933951566764 tata
>
> Am I comdemned to provide a R script with the data in order to exploit the
> dataset ?
>
> Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
> > 2^53 == 2^53+1
> > TRUE
> >
> > Which makes joining or grouping data sets with 64 bit identifiers
> problematic.
> >
> > Murray (mobile)
> >
> > On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:
> >
> >     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
> >     > The lack of 64 bit integer support causes lots of problems when
> dealing
> >     with
> >     > certain types of data where the loss of precision from coercing to
> 53
> >     bits with
> >     > double is unacceptable.
> >
> >     Hello Murray,
> >     Do you mean, by eg. -1311071933951566764 loses in precision during
> >     as.numeric(-1311071933951566764) process ?
> >     Thanks,
> >     >
> >     > Two packages were developed to deal with this:  int64 and bit64.
> >     >
> >     > You may need to find archival versions of these packages if they've
> >     fallen off
> >     > cran.
> >     >
> >     > Murray (mobile phone)
> >     >
> >     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu>
> wrote:
> >     >
> >     >     I am not on R-core, so cannot speak to future plans to
> internally
> >     support
> >     >     int8 (though my impression is that there aren't any, at least
> none
> >     that are
> >     >     close to fruition).
> >     >
> >     >     The standard way of dealing with whole numbers too big to fit
> in an
> >     integer
> >     >     is to put them in a numeric (double down in C land). this can
> >     represent
> >     >     integers up to 2^53 without loss of precision see (
> >     >     http://stackoverflow.com/questions/1848700/biggest-
> >     >     integer-that-can-be-stored-in-a-double).
> >     >     This is how long vector indices are (currently) implemented in
> R. If
> >     it's
> >     >     good enough for indices it's probably good enough for whatever
> you
> >     need
> >     >     them for.
> >     >
> >     >     Hope that helps.
> >     >
> >     >     ~G
> >     >
> >     >
> >     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <
> nicolas.paris at aphp.fr
> >     >
> >     >     wrote:
> >     >
> >     >     > Hello r users,
> >     >     >
> >     >     > I have to deal with int8 data with R. AFAIK  R does only
> handle
> >     int4
> >     >     > with `as.integer` function [1]. I wonder:
> >     >     > 1. what is the better approach to handle int8 ?
> `as.character` ?
> >     >     > `as.numeric` ?
> >     >     > 2. is there any plan to handle int8 in the future ? As you
> might
> >     know,
> >     >     > int4 is to small to deal with earth population right now.
> >     >     >
> >     >     > Thanks for you ideas,
> >     >     >
> >     >     > int8 eg:
> >     >     >
> >     >     >      human_id
> >     >     > ----------------------
> >     >     >  -1311071933951566764
> >     >     >  -4708675461424073238
> >     >     >  -6865005668390999818
> >     >     >   5578000650960353108
> >     >     >  -3219674686933841021
> >     >     >  -6469229889308771589
> >     >     >   -606871692563545028
> >     >     >  -8199987422425699249
> >     >     >   -463287495999648233
> >     >     >   7675955260644241951
> >     >     >
> >     >     > reference:
> >     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
> >     >     >
> >     >     > --
> >     >     > Nicolas PARIS
> >     >     >
> >     >     > ______________________________________________
> >     >     > R-devel at r-project.org mailing list
> >     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >     >
> >     >
> >     >
> >     >
> >     >     --
> >     >     Gabriel Becker, PhD
> >     >     Associate Scientist (Bioinformatics)
> >     >     Genentech Research
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     ______________________________________________
> >     >     R-devel at r-project.org mailing list
> >     >     https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >
> >     >
> >
> >     --
> >     Nicolas PARIS
> >
> >
>
> --
> Nicolas PARIS
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jan 20 18:59:36 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 20 Jan 2017 18:59:36 +0100
Subject: [Rd] xtabs(), factors and NAs
In-Reply-To: <1484830711.8924.41.camel@club.fr>
References: <1484830711.8924.41.camel@club.fr>
Message-ID: <22658.20488.544863.616323@stat.math.ethz.ch>

>>>>> Milan Bouchet-Valat <nalimilan at club.fr>
>>>>>     on Thu, 19 Jan 2017 13:58:31 +0100 writes:

> Hi all,
> I know this issue has been discussed a few times in the past already,
> but Martin Maechler suggested in a bug report [1] that I raise it here.
> 
> Basically, there is no (easy) way of printing NAs for all variables
> when calling xtabs() on factors. Passing 'exclude=NULL,
> na.action=na.pass' works for character vectors, but not for factors.
> 
[ yes, but your example below is *not* showing that ... so may be
  a bit confusing !]  {Reason: stringsAsFactors etc}

> > test <- data.frame(x=c("a",NA))
> > xtabs(~ x, exclude=NULL,
> na.action=na.pass, data=test)
> x
> a?
> 1?
> 
> > test <- data.frame(x=factor(c("a",NA)))
> > xtabs(~ x, exclude=NULL,
> na.action=na.pass, data=test)
> x
> a?
> 1?
> 
> 
> Even if it's documented, this inconsistency is annoying. When checking
> data, it is often useful to print all NA values temporarily, without
> calling addNA() individually on all crossed variables.

  {Note this is not (just) about print()ing; the issue is
   about the resulting *object*.}
> 
> Would it make sense to add a new argument similar to table()'s useNA
> which would behave the same for all input vector types?

You have to be aware that  table()  has been changed since R
3.3.2, i.e., is different in R-devel and hence will be different
in R 3.4.0.
table()'s handling of NAs has become very involved /
sophisticated(*), and currently I'd rather like to keep
xtabs()'s behavior much simpler. 

Interestingly, after starting to play with data containing NA's and
  xtabs(*, na.action=na.pass)
I have already detected bugs (for sparse=TRUE) and cases where
the current xtabs() behavior seems dubious to me.
So, the issue is --- as so often --- more involved than assumed initially.

We (R core) will probably do something, but do need more time
before we can promise anything more...

Thank you for raising the issue,
Martin Maechler, ETH Zurich


*) R-devel sources always current at
   https://svn.r-project.org/R/trunk/src/library/base/R/table.R

> 
> Regards

> [1] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14630


From nicolas.paris at aphp.fr  Fri Jan 20 19:05:31 2017
From: nicolas.paris at aphp.fr (Nicolas Paris)
Date: Fri, 20 Jan 2017 19:05:31 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CADwqtCOPLc7gw_jtKqj4+obA2EVSTxALoHOjZzBRvBv9BcMz9Q@mail.gmail.com>
References: <CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
	<CADwqtCOPLc7gw_jtKqj4+obA2EVSTxALoHOjZzBRvBv9BcMz9Q@mail.gmail.com>
Message-ID: <20170120180531.GF32106@aphp.fr>

Hi, 

I do have < INT_MAX.
This looks attractive but since they are unique identifiers, storing
them as factor will be likely to be counter-productive. (a string
version + an int32 for each)

I was looking to https://cran.r-project.org/web/packages/csvread/index.html
This looks like a good feet for my needs. 
Any chances such an external package for int64 would be integrated in core ?


Le 20 janv. 2017 ? 18h57, Gabriel Becker ?crivait :
> How many unique idenfiiers do you have?
> 
> If they are large (in terms of bytes) but you don't have that many of them (eg
> the total possible number you'll ever have is < INT_MAX), you could store them
> as factors. You get the speed of integers but the labeling of full "precision"
> strings.  Factors are fast for joins.
> 
> ~G
> 
> On Fri, Jan 20, 2017 at 9:47 AM, Nicolas Paris <nicolas.paris at aphp.fr> wrote:
> 
>     Well I definitely cannot use them as numeric because join is the main
>     reason of those identifiers.
> 
>     About int64 and bit64 packages, it's not a solution, because I am
>     releasing a dataset for external users. I cannot ask them to install a
>     package in order to exploit them.
> 
>     I have to be very carefull when releasing the data. If a user just use
>     read.csv functions, they by default cast the identifiers as numeric.
> 
>     $ more res.csv
>     "col1";"col2"
>     "-1311071933951566764";"toto"
>     "-1311071933951566764";"tata"
> 
> 
>     > read.table("res.csv",sep=";",header=T)
>                col1 col2
>     1 -1.311072e+18 toto
>     2 -1.311072e+18 tata
> 
>     >sapply(read.table("res.csv",sep=";",header=T),class)
>          col1      col2
>     "numeric"  "factor"
> 
>     > read.table("res.csv",sep=";",header=T,colClasses="character")
>     col1 col2
>     1 -1311071933951566764 toto
>     2 -1311071933951566764 tata
> 
>     Am I comdemned to provide a R script with the data in order to exploit the
>     dataset ?
> 
>     Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
>     > 2^53 == 2^53+1
>     > TRUE
>     >
>     > Which makes joining or grouping data sets with 64 bit identifiers
>     problematic.
>     >
>     > Murray (mobile)
>     >
>     > On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:
>     >
>     >     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
>     >     > The lack of 64 bit integer support causes lots of problems when
>     dealing
>     >     with
>     >     > certain types of data where the loss of precision from coercing to
>     53
>     >     bits with
>     >     > double is unacceptable.
>     >
>     >     Hello Murray,
>     >     Do you mean, by eg. -1311071933951566764 loses in precision during
>     >     as.numeric(-1311071933951566764) process ?
>     >     Thanks,
>     >     >
>     >     > Two packages were developed to deal with this:  int64 and bit64.
>     >     >
>     >     > You may need to find archival versions of these packages if they've
>     >     fallen off
>     >     > cran.
>     >     >
>     >     > Murray (mobile phone)
>     >     >
>     >     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu>
>     wrote:
>     >     >
>     >     >     I am not on R-core, so cannot speak to future plans to
>     internally
>     >     support
>     >     >     int8 (though my impression is that there aren't any, at least
>     none
>     >     that are
>     >     >     close to fruition).
>     >     >
>     >     >     The standard way of dealing with whole numbers too big to fit
>     in an
>     >     integer
>     >     >     is to put them in a numeric (double down in C land). this can
>     >     represent
>     >     >     integers up to 2^53 without loss of precision see (
>     >     >     http://stackoverflow.com/questions/1848700/biggest-
>     >     >     integer-that-can-be-stored-in-a-double).
>     >     >     This is how long vector indices are (currently) implemented in
>     R. If
>     >     it's
>     >     >     good enough for indices it's probably good enough for whatever
>     you
>     >     need
>     >     >     them for.
>     >     >
>     >     >     Hope that helps.
>     >     >
>     >     >     ~G
>     >     >
>     >     >
>     >     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <
>     nicolas.paris at aphp.fr
>     >     >
>     >     >     wrote:
>     >     >
>     >     >     > Hello r users,
>     >     >     >
>     >     >     > I have to deal with int8 data with R. AFAIK  R does only
>     handle
>     >     int4
>     >     >     > with `as.integer` function [1]. I wonder:
>     >     >     > 1. what is the better approach to handle int8 ? `as.character
>     ` ?
>     >     >     > `as.numeric` ?
>     >     >     > 2. is there any plan to handle int8 in the future ? As you
>     might
>     >     know,
>     >     >     > int4 is to small to deal with earth population right now.
>     >     >     >
>     >     >     > Thanks for you ideas,
>     >     >     >
>     >     >     > int8 eg:
>     >     >     >
>     >     >     >      human_id
>     >     >     > ----------------------
>     >     >     >  -1311071933951566764
>     >     >     >  -4708675461424073238
>     >     >     >  -6865005668390999818
>     >     >     >   5578000650960353108
>     >     >     >  -3219674686933841021
>     >     >     >  -6469229889308771589
>     >     >     >   -606871692563545028
>     >     >     >  -8199987422425699249
>     >     >     >   -463287495999648233
>     >     >     >   7675955260644241951
>     >     >     >
>     >     >     > reference:
>     >     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>     >     >     >
>     >     >     > --
>     >     >     > Nicolas PARIS
>     >     >     >
>     >     >     > ______________________________________________
>     >     >     > R-devel at r-project.org mailing list
>     >     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >     >     >
>     >     >
>     >     >
>     >     >
>     >     >     --
>     >     >     Gabriel Becker, PhD
>     >     >     Associate Scientist (Bioinformatics)
>     >     >     Genentech Research
>     >     >
>     >     >             [[alternative HTML version deleted]]
>     >     >
>     >     >     ______________________________________________
>     >     >     R-devel at r-project.org mailing list
>     >     >     https://stat.ethz.ch/mailman/listinfo/r-devel
>     >     >
>     >     >
>     >
>     >     --
>     >     Nicolas PARIS
>     >
>     >
> 
>     --
>     Nicolas PARIS
> 
> 
> 
> 
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research

-- 
Nicolas PARIS
Responsable R & D
WIND - PACTE, H?pital Rothschild ( RTH )
Courriel : nicolas.paris at aphp.fr
Tel : 01 48 04 21 07


From haverty.peter at gene.com  Fri Jan 20 18:59:58 2017
From: haverty.peter at gene.com (Peter Haverty)
Date: Fri, 20 Jan 2017 09:59:58 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120174755.GE32106@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
Message-ID: <CAGh0NYrfkRg3QekHtYSpYrdd+BPCrU86Z0bEsgCxEiwsRxqirQ@mail.gmail.com>

For what it is worth, I would be extremely pleased to R's integer type go
to 64bit.  A signed 32bit integer is just a bit too small to index into the
~3 billion position human genome.  The "work arounds" that have arisen for
this specific issue are surprisingly complex.

Pete

____________________
Peter M. Haverty, Ph.D.
Genentech, Inc.
phaverty at gene.com

On Fri, Jan 20, 2017 at 9:47 AM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Well I definitely cannot use them as numeric because join is the main
> reason of those identifiers.
>
> About int64 and bit64 packages, it's not a solution, because I am
> releasing a dataset for external users. I cannot ask them to install a
> package in order to exploit them.
>
> I have to be very carefull when releasing the data. If a user just use
> read.csv functions, they by default cast the identifiers as numeric.
>
> $ more res.csv
> "col1";"col2"
> "-1311071933951566764";"toto"
> "-1311071933951566764";"tata"
>
>
> > read.table("res.csv",sep=";",header=T)
>            col1 col2
> 1 -1.311072e+18 toto
> 2 -1.311072e+18 tata
>
> >sapply(read.table("res.csv",sep=";",header=T),class)
>      col1      col2
> "numeric"  "factor"
>
> > read.table("res.csv",sep=";",header=T,colClasses="character")
> col1 col2
> 1 -1311071933951566764 toto
> 2 -1311071933951566764 tata
>
> Am I comdemned to provide a R script with the data in order to exploit the
> dataset ?
>
> Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
> > 2^53 == 2^53+1
> > TRUE
> >
> > Which makes joining or grouping data sets with 64 bit identifiers
> problematic.
> >
> > Murray (mobile)
> >
> > On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:
> >
> >     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
> >     > The lack of 64 bit integer support causes lots of problems when
> dealing
> >     with
> >     > certain types of data where the loss of precision from coercing to
> 53
> >     bits with
> >     > double is unacceptable.
> >
> >     Hello Murray,
> >     Do you mean, by eg. -1311071933951566764 loses in precision during
> >     as.numeric(-1311071933951566764) process ?
> >     Thanks,
> >     >
> >     > Two packages were developed to deal with this:  int64 and bit64.
> >     >
> >     > You may need to find archival versions of these packages if they've
> >     fallen off
> >     > cran.
> >     >
> >     > Murray (mobile phone)
> >     >
> >     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu>
> wrote:
> >     >
> >     >     I am not on R-core, so cannot speak to future plans to
> internally
> >     support
> >     >     int8 (though my impression is that there aren't any, at least
> none
> >     that are
> >     >     close to fruition).
> >     >
> >     >     The standard way of dealing with whole numbers too big to fit
> in an
> >     integer
> >     >     is to put them in a numeric (double down in C land). this can
> >     represent
> >     >     integers up to 2^53 without loss of precision see (
> >     >     http://stackoverflow.com/questions/1848700/biggest-
> >     >     integer-that-can-be-stored-in-a-double).
> >     >     This is how long vector indices are (currently) implemented in
> R. If
> >     it's
> >     >     good enough for indices it's probably good enough for whatever
> you
> >     need
> >     >     them for.
> >     >
> >     >     Hope that helps.
> >     >
> >     >     ~G
> >     >
> >     >
> >     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <
> nicolas.paris at aphp.fr
> >     >
> >     >     wrote:
> >     >
> >     >     > Hello r users,
> >     >     >
> >     >     > I have to deal with int8 data with R. AFAIK  R does only
> handle
> >     int4
> >     >     > with `as.integer` function [1]. I wonder:
> >     >     > 1. what is the better approach to handle int8 ?
> `as.character` ?
> >     >     > `as.numeric` ?
> >     >     > 2. is there any plan to handle int8 in the future ? As you
> might
> >     know,
> >     >     > int4 is to small to deal with earth population right now.
> >     >     >
> >     >     > Thanks for you ideas,
> >     >     >
> >     >     > int8 eg:
> >     >     >
> >     >     >      human_id
> >     >     > ----------------------
> >     >     >  -1311071933951566764
> >     >     >  -4708675461424073238
> >     >     >  -6865005668390999818
> >     >     >   5578000650960353108
> >     >     >  -3219674686933841021
> >     >     >  -6469229889308771589
> >     >     >   -606871692563545028
> >     >     >  -8199987422425699249
> >     >     >   -463287495999648233
> >     >     >   7675955260644241951
> >     >     >
> >     >     > reference:
> >     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
> >     >     >
> >     >     > --
> >     >     > Nicolas PARIS
> >     >     >
> >     >     > ______________________________________________
> >     >     > R-devel at r-project.org mailing list
> >     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >     >
> >     >
> >     >
> >     >
> >     >     --
> >     >     Gabriel Becker, PhD
> >     >     Associate Scientist (Bioinformatics)
> >     >     Genentech Research
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     ______________________________________________
> >     >     R-devel at r-project.org mailing list
> >     >     https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >
> >     >
> >
> >     --
> >     Nicolas PARIS
> >
> >
>
> --
> Nicolas PARIS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Fri Jan 20 19:16:14 2017
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 20 Jan 2017 10:16:14 -0800
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120180531.GF32106@aphp.fr>
References: <CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
	<CADwqtCOPLc7gw_jtKqj4+obA2EVSTxALoHOjZzBRvBv9BcMz9Q@mail.gmail.com>
	<20170120180531.GF32106@aphp.fr>
Message-ID: <CADwqtCPV97tPz_GT3+u1PUxStn3HwthEVh_ic8nf=E0HjUBYnA@mail.gmail.com>

I, again, can't speak for R-core so I may be wrong about any of this and
they are welcome to correct me but it seems unlikely that they would
integrate a package that defines 64 bit integers in R into the core of R
 without making the changes necessary to provide 64 bit integers as a
fundamental (atomic vector) type. I know this has come up before and they
have been reluctant to make the changes necessary.

As Pete points out, they could "simply" change integers in R to always be
64 bit, though that would make all* (to an extent) integer vectors in R
take up twice as much memory as they do now.

I should also mention that even if R-core did take up this cause, it
wouldn't happen quickly enough for what you probably need. I would guess we
would be talking months or year(s) (i.e. the next non-patch R versions at
the earliest, and likely the one after that >1yr out).

One pragmatic solution (other than the factors which is what I Would
probably do) would be to only distribute your data as an R data package
which depends on csvread or similar.

~G

On Fri, Jan 20, 2017 at 10:05 AM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Hi,
>
> I do have < INT_MAX.
> This looks attractive but since they are unique identifiers, storing
> them as factor will be likely to be counter-productive. (a string
> version + an int32 for each)
>
> I was looking to https://cran.r-project.org/web/packages/csvread/index.
> html
> This looks like a good feet for my needs.
> Any chances such an external package for int64 would be integrated in core
> ?
>
>
> Le 20 janv. 2017 ? 18h57, Gabriel Becker ?crivait :
> > How many unique idenfiiers do you have?
> >
> > If they are large (in terms of bytes) but you don't have that many of
> them (eg
> > the total possible number you'll ever have is < INT_MAX), you could
> store them
> > as factors. You get the speed of integers but the labeling of full
> "precision"
> > strings.  Factors are fast for joins.
> >
> > ~G
> >
> > On Fri, Jan 20, 2017 at 9:47 AM, Nicolas Paris <nicolas.paris at aphp.fr>
> wrote:
> >
> >     Well I definitely cannot use them as numeric because join is the main
> >     reason of those identifiers.
> >
> >     About int64 and bit64 packages, it's not a solution, because I am
> >     releasing a dataset for external users. I cannot ask them to install
> a
> >     package in order to exploit them.
> >
> >     I have to be very carefull when releasing the data. If a user just
> use
> >     read.csv functions, they by default cast the identifiers as numeric.
> >
> >     $ more res.csv
> >     "col1";"col2"
> >     "-1311071933951566764";"toto"
> >     "-1311071933951566764";"tata"
> >
> >
> >     > read.table("res.csv",sep=";",header=T)
> >                col1 col2
> >     1 -1.311072e+18 toto
> >     2 -1.311072e+18 tata
> >
> >     >sapply(read.table("res.csv",sep=";",header=T),class)
> >          col1      col2
> >     "numeric"  "factor"
> >
> >     > read.table("res.csv",sep=";",header=T,colClasses="character")
> >     col1 col2
> >     1 -1311071933951566764 toto
> >     2 -1311071933951566764 tata
> >
> >     Am I comdemned to provide a R script with the data in order to
> exploit the
> >     dataset ?
> >
> >     Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
> >     > 2^53 == 2^53+1
> >     > TRUE
> >     >
> >     > Which makes joining or grouping data sets with 64 bit identifiers
> >     problematic.
> >     >
> >     > Murray (mobile)
> >     >
> >     > On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr>
> wrote:
> >     >
> >     >     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
> >     >     > The lack of 64 bit integer support causes lots of problems
> when
> >     dealing
> >     >     with
> >     >     > certain types of data where the loss of precision from
> coercing to
> >     53
> >     >     bits with
> >     >     > double is unacceptable.
> >     >
> >     >     Hello Murray,
> >     >     Do you mean, by eg. -1311071933951566764 loses in precision
> during
> >     >     as.numeric(-1311071933951566764) process ?
> >     >     Thanks,
> >     >     >
> >     >     > Two packages were developed to deal with this:  int64 and
> bit64.
> >     >     >
> >     >     > You may need to find archival versions of these packages if
> they've
> >     >     fallen off
> >     >     > cran.
> >     >     >
> >     >     > Murray (mobile phone)
> >     >     >
> >     >     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <
> gmbecker at ucdavis.edu>
> >     wrote:
> >     >     >
> >     >     >     I am not on R-core, so cannot speak to future plans to
> >     internally
> >     >     support
> >     >     >     int8 (though my impression is that there aren't any, at
> least
> >     none
> >     >     that are
> >     >     >     close to fruition).
> >     >     >
> >     >     >     The standard way of dealing with whole numbers too big
> to fit
> >     in an
> >     >     integer
> >     >     >     is to put them in a numeric (double down in C land).
> this can
> >     >     represent
> >     >     >     integers up to 2^53 without loss of precision see (
> >     >     >     http://stackoverflow.com/questions/1848700/biggest-
> >     >     >     integer-that-can-be-stored-in-a-double).
> >     >     >     This is how long vector indices are (currently)
> implemented in
> >     R. If
> >     >     it's
> >     >     >     good enough for indices it's probably good enough for
> whatever
> >     you
> >     >     need
> >     >     >     them for.
> >     >     >
> >     >     >     Hope that helps.
> >     >     >
> >     >     >     ~G
> >     >     >
> >     >     >
> >     >     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <
> >     nicolas.paris at aphp.fr
> >     >     >
> >     >     >     wrote:
> >     >     >
> >     >     >     > Hello r users,
> >     >     >     >
> >     >     >     > I have to deal with int8 data with R. AFAIK  R does
> only
> >     handle
> >     >     int4
> >     >     >     > with `as.integer` function [1]. I wonder:
> >     >     >     > 1. what is the better approach to handle int8 ?
> `as.character
> >     ` ?
> >     >     >     > `as.numeric` ?
> >     >     >     > 2. is there any plan to handle int8 in the future ? As
> you
> >     might
> >     >     know,
> >     >     >     > int4 is to small to deal with earth population right
> now.
> >     >     >     >
> >     >     >     > Thanks for you ideas,
> >     >     >     >
> >     >     >     > int8 eg:
> >     >     >     >
> >     >     >     >      human_id
> >     >     >     > ----------------------
> >     >     >     >  -1311071933951566764
> >     >     >     >  -4708675461424073238
> >     >     >     >  -6865005668390999818
> >     >     >     >   5578000650960353108
> >     >     >     >  -3219674686933841021
> >     >     >     >  -6469229889308771589
> >     >     >     >   -606871692563545028
> >     >     >     >  -8199987422425699249
> >     >     >     >   -463287495999648233
> >     >     >     >   7675955260644241951
> >     >     >     >
> >     >     >     > reference:
> >     >     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
> >     >     >     >
> >     >     >     > --
> >     >     >     > Nicolas PARIS
> >     >     >     >
> >     >     >     > ______________________________________________
> >     >     >     > R-devel at r-project.org mailing list
> >     >     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >     >     >
> >     >     >
> >     >     >
> >     >     >
> >     >     >     --
> >     >     >     Gabriel Becker, PhD
> >     >     >     Associate Scientist (Bioinformatics)
> >     >     >     Genentech Research
> >     >     >
> >     >     >             [[alternative HTML version deleted]]
> >     >     >
> >     >     >     ______________________________________________
> >     >     >     R-devel at r-project.org mailing list
> >     >     >     https://stat.ethz.ch/mailman/listinfo/r-devel
> >     >     >
> >     >     >
> >     >
> >     >     --
> >     >     Nicolas PARIS
> >     >
> >     >
> >
> >     --
> >     Nicolas PARIS
> >
> >
> >
> >
> > --
> > Gabriel Becker, PhD
> > Associate Scientist (Bioinformatics)
> > Genentech Research
>
> --
> Nicolas PARIS
> Responsable R & D
> WIND - PACTE, H?pital Rothschild ( RTH )
> Courriel : nicolas.paris at aphp.fr
> Tel : 01 48 04 21 07
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From willem at wligtenberg.nl  Fri Jan 20 20:28:32 2017
From: willem at wligtenberg.nl (Willem Ligtenberg)
Date: Fri, 20 Jan 2017 20:28:32 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120174755.GE32106@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
Message-ID: <8426e22e-6060-c0d5-b0c0-9403192f8938@wligtenberg.nl>

You might want to use a data.table then.
It will automatically detect that it is a 64 bit int.
Although also in that case the user will have to install the data.table
package.
(which is a good idea anyway in my opinion :) )

It will then obviously allow you to join tables.

Willem

On 20-01-17 18:47, Nicolas Paris wrote:
> Well I definitely cannot use them as numeric because join is the main
> reason of those identifiers.
>
> About int64 and bit64 packages, it's not a solution, because I am
> releasing a dataset for external users. I cannot ask them to install a
> package in order to exploit them.
>
> I have to be very carefull when releasing the data. If a user just use
> read.csv functions, they by default cast the identifiers as numeric.
>
> $ more res.csv
> "col1";"col2"
> "-1311071933951566764";"toto"
> "-1311071933951566764";"tata"
>
>
>> read.table("res.csv",sep=";",header=T)
>            col1 col2
> 1 -1.311072e+18 toto
> 2 -1.311072e+18 tata
>
>> sapply(read.table("res.csv",sep=";",header=T),class)
>      col1      col2
> "numeric"  "factor"
>
>> read.table("res.csv",sep=";",header=T,colClasses="character")
> col1 col2
> 1 -1311071933951566764 toto
> 2 -1311071933951566764 tata
>
> Am I comdemned to provide a R script with the data in order to exploit the dataset ?
>
> Le 20 janv. 2017 ? 18h29, Murray Stokely ?crivait :
>> 2^53 == 2^53+1
>> TRUE
>>
>> Which makes joining or grouping data sets with 64 bit identifiers problematic.
>>
>> Murray (mobile)
>>
>> On Jan 20, 2017 9:15 AM, "Nicolas Paris" <nicolas.paris at aphp.fr> wrote:
>>
>>     Le 20 janv. 2017 ? 18h09, Murray Stokely ?crivait :
>>     > The lack of 64 bit integer support causes lots of problems when dealing
>>     with
>>     > certain types of data where the loss of precision from coercing to 53
>>     bits with
>>     > double is unacceptable.
>>
>>     Hello Murray,
>>     Do you mean, by eg. -1311071933951566764 loses in precision during
>>     as.numeric(-1311071933951566764) process ?
>>     Thanks,
>>     >
>>     > Two packages were developed to deal with this:  int64 and bit64.
>>     >
>>     > You may need to find archival versions of these packages if they've
>>     fallen off
>>     > cran.
>>     >
>>     > Murray (mobile phone)
>>     >
>>     > On Jan 20, 2017 7:20 AM, "Gabriel Becker" <gmbecker at ucdavis.edu> wrote:
>>     >
>>     >     I am not on R-core, so cannot speak to future plans to internally
>>     support
>>     >     int8 (though my impression is that there aren't any, at least none
>>     that are
>>     >     close to fruition).
>>     >
>>     >     The standard way of dealing with whole numbers too big to fit in an
>>     integer
>>     >     is to put them in a numeric (double down in C land). this can
>>     represent
>>     >     integers up to 2^53 without loss of precision see (
>>     >     http://stackoverflow.com/questions/1848700/biggest-
>>     >     integer-that-can-be-stored-in-a-double).
>>     >     This is how long vector indices are (currently) implemented in R. If
>>     it's
>>     >     good enough for indices it's probably good enough for whatever you
>>     need
>>     >     them for.
>>     >
>>     >     Hope that helps.
>>     >
>>     >     ~G
>>     >
>>     >
>>     >     On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr
>>     >
>>     >     wrote:
>>     >
>>     >     > Hello r users,
>>     >     >
>>     >     > I have to deal with int8 data with R. AFAIK  R does only handle
>>     int4
>>     >     > with `as.integer` function [1]. I wonder:
>>     >     > 1. what is the better approach to handle int8 ? `as.character` ?
>>     >     > `as.numeric` ?
>>     >     > 2. is there any plan to handle int8 in the future ? As you might
>>     know,
>>     >     > int4 is to small to deal with earth population right now.
>>     >     >
>>     >     > Thanks for you ideas,
>>     >     >
>>     >     > int8 eg:
>>     >     >
>>     >     >      human_id
>>     >     > ----------------------
>>     >     >  -1311071933951566764
>>     >     >  -4708675461424073238
>>     >     >  -6865005668390999818
>>     >     >   5578000650960353108
>>     >     >  -3219674686933841021
>>     >     >  -6469229889308771589
>>     >     >   -606871692563545028
>>     >     >  -8199987422425699249
>>     >     >   -463287495999648233
>>     >     >   7675955260644241951
>>     >     >
>>     >     > reference:
>>     >     > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>>     >     >
>>     >     > --
>>     >     > Nicolas PARIS
>>     >     >
>>     >     > ______________________________________________
>>     >     > R-devel at r-project.org mailing list
>>     >     > https://stat.ethz.ch/mailman/listinfo/r-devel
>>     >     >
>>     >
>>     >
>>     >
>>     >     --
>>     >     Gabriel Becker, PhD
>>     >     Associate Scientist (Bioinformatics)
>>     >     Genentech Research
>>     >
>>     >             [[alternative HTML version deleted]]
>>     >
>>     >     ______________________________________________
>>     >     R-devel at r-project.org mailing list
>>     >     https://stat.ethz.ch/mailman/listinfo/r-devel
>>     >
>>     >
>>
>>     --
>>     Nicolas PARIS
>>
>>


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20170120/41f83b05/attachment.bin>

From edd at debian.org  Fri Jan 20 20:29:15 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 20 Jan 2017 13:29:15 -0600
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120180531.GF32106@aphp.fr>
References: <CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
	<20170120171733.GB32106@aphp.fr>
	<CAECWzi+yYJCEX=RKRdPqhP_ohq+nsK8sDBM0uXizws_wcMhy+Q@mail.gmail.com>
	<CAECWziLNW+JrRw2Lg09Msp1JiJ6oiYiYhfmaoWebuYEcg7zsnQ@mail.gmail.com>
	<CAECWziLek1eYyYqSjks=bRxSqrWSCr5XurE5LqgDnL5+OoWZEQ@mail.gmail.com>
	<20170120174755.GE32106@aphp.fr>
	<CADwqtCOPLc7gw_jtKqj4+obA2EVSTxALoHOjZzBRvBv9BcMz9Q@mail.gmail.com>
	<20170120180531.GF32106@aphp.fr>
Message-ID: <22658.25867.717004.52124@max.nulle.part>


Not sure how we got from int8 to int64 ... but for what it is worth, I
recently a) needed 64-bit integers to represent nanosecond timestamps (which
then became the still new-ish CRAN package 'nanotime') and b) found the
support in package bit64 for its bit64::integer64 to be easy too use and
performant -- plus c) the data.table package reads/writes these well.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kasperdanielhansen at gmail.com  Fri Jan 20 20:51:40 2017
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 20 Jan 2017 14:51:40 -0500
Subject: [Rd] How to handle INT8 data
In-Reply-To: <20170120172811.GC32106@aphp.fr>
References: <20170120143335.GE9661@aphp.fr>
	<CAF8bMcbB6mnDv=enrh8KYjXhRzUX1uaSdp2Ly9=DFv-ST5CRuw@mail.gmail.com>
	<20170120172811.GC32106@aphp.fr>
Message-ID: <CAC2h7uuw8FLjQJdZArbcMLnVzGiNk6zPtSFMQatUcrUMxDHmEw@mail.gmail.com>

Have you benchmarked these potential drawbacks for your usecase? Eg. memory
depends on the structure of the identifies, given how R stores characters
internally.

Given all the issues raised here, I would 100% provide a script for reading
the data into R, if this is for distribution.

Best,
Kasper

On Fri, Jan 20, 2017 at 12:28 PM, Nicolas Paris <nicolas.paris at aphp.fr>
wrote:

> Right, they are identifiers.
>
> Storing them as String has drawbacks:
> - huge to store in memory
> - slow to process
> - huge to index (by eg data.table columns indexes)
>
> Why not storing them as numeric ?
>
> Thanks,
>
> Le 20 janv. 2017 ? 18h16, William Dunlap ?crivait :
> > If these are identifiers, store them as strings.  If not, what sort of
> > calculations do you plan on doing with them?
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> > On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
> wrote:
> > > Hello r users,
> > >
> > > I have to deal with int8 data with R. AFAIK  R does only handle int4
> > > with `as.integer` function [1]. I wonder:
> > > 1. what is the better approach to handle int8 ? `as.character` ?
> > > `as.numeric` ?
> > > 2. is there any plan to handle int8 in the future ? As you might know,
> > > int4 is to small to deal with earth population right now.
> > >
> > > Thanks for you ideas,
> > >
> > > int8 eg:
> > >
> > >      human_id
> > > ----------------------
> > >  -1311071933951566764
> > >  -4708675461424073238
> > >  -6865005668390999818
> > >   5578000650960353108
> > >  -3219674686933841021
> > >  -6469229889308771589
> > >   -606871692563545028
> > >  -8199987422425699249
> > >   -463287495999648233
> > >   7675955260644241951
> > >
> > > reference:
> > > 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
> > >
> > > --
> > > Nicolas PARIS
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Nicolas PARIS
> Responsable R & D
> WIND - PACTE, H?pital Rothschild ( RTH )
> Courriel : nicolas.paris at aphp.fr
> Tel : 01 48 04 21 07
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Sat Jan 21 13:10:44 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sat, 21 Jan 2017 13:10:44 +0100
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CAECWziKyK2_EW9M7s-6qz6GOyWWRXZpAoTo8aroCWwkoOrBbMA@mail.gmail.com>
	<CAECWziL2yBNBPpbj2-nQaCMv4W+C7ncGK_23Eh146R3F5BvM-A@mail.gmail.com>
	<CAECWziKVhF93xSFdxFN2Gvc4JuG8ms1TrDTNJC-cTzr7+cZA7Q@mail.gmail.com>
Message-ID: <CABFfbXsgiyNKuaAw1JtZRM5KZAyHef_M-xJLbbEV0ZQLM7W5EQ@mail.gmail.com>

On Fri, Jan 20, 2017 at 6:09 PM, Murray Stokely <murray at stokely.org> wrote:
> The lack of 64 bit integer support causes lots of problems when dealing
> with certain types of data where the loss of precision from coercing to 53
> bits with double is unacceptable.
>
> Two packages were developed to deal with this:  int64 and bit64.

Don't forget packages for large arbitrary large numbers such as Rmpfr
and openssl.

  x <- openssl::bignum("12345678987654321")
  x^10

The risk of storing int64 as a double (e.g. in bit64) is that it might
easily be mistaken for a completely different value via unclass() or
Rf_isNumeric() or so.


From nalimilan at club.fr  Sat Jan 21 14:42:56 2017
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 21 Jan 2017 14:42:56 +0100
Subject: [Rd] xtabs(), factors and NAs
In-Reply-To: <22658.20488.544863.616323@stat.math.ethz.ch>
References: <1484830711.8924.41.camel@club.fr>
	<22658.20488.544863.616323@stat.math.ethz.ch>
Message-ID: <1485006176.18648.5.camel@club.fr>

Le vendredi 20 janvier 2017 ? 18:59 +0100, Martin Maechler a ?crit?:
> > > > > > > > > > > > Milan Bouchet-Valat <nalimilan at club.fr>
> > > > > > ????on Thu, 19 Jan 2017 13:58:31 +0100 writes:
> > Hi all,
> > I know this issue has been discussed a few times in the past already,
> > but Martin Maechler suggested in a bug report [1] that I raise it here.
> > 
> > Basically, there is no (easy) way of printing NAs for all variables
> > when calling xtabs() on factors. Passing 'exclude=NULL,
> > na.action=na.pass' works for character vectors, but not for factors.
> > 
> 
> [ yes, but your example below is *not* showing that ... so may be
> ? a bit confusing !]??{Reason: stringsAsFactors etc}
Yes, sorry, that illustrates why?one should never try to make an
example prettier in the last minute. For reference, here's the correct
example:

> test <- data.frame(x=c("a",NA), stringsAsFactors=FALSE)
> xtabs(~ x, exclude=NULL, na.action=na.pass, data=test)
x
???a <NA>?
???1????1?

> test <- data.frame(x=factor(c("a",NA)))
> xtabs(~ x, exclude=NULL, na.action=na.pass, data=test)
x
a?
1?


> > > test <- data.frame(x=c("a",NA))
> > > xtabs(~ x, exclude=NULL,
> > 
> > na.action=na.pass, data=test)
> > x
> > a?
> > 1?
> > 
> > > test <- data.frame(x=factor(c("a",NA)))
> > > xtabs(~ x, exclude=NULL,
> > 
> > na.action=na.pass, data=test)
> > x
> > a?
> > 1?
> > 
> > 
> > Even if it's documented, this inconsistency is annoying. When checking
> > data, it is often useful to print all NA values temporarily, without
> > calling addNA() individually on all crossed variables.
> 
> ? {Note this is not (just) about print()ing; the issue is
> ???about the resulting *object*.}
> > 
> > Would it make sense to add a new argument similar to table()'s useNA
> > which would behave the same for all input vector types?
> 
> You have to be aware that??table()??has been changed since R
> 3.3.2, i.e., is different in R-devel and hence will be different
> in R 3.4.0.
> table()'s handling of NAs has become very involved /
> sophisticated(*), and currently I'd rather like to keep
> xtabs()'s behavior much simpler.?
> 
> Interestingly, after starting to play with data containing NA's and
> ? xtabs(*, na.action=na.pass)
> I have already detected bugs (for sparse=TRUE) and cases where
> the current xtabs() behavior seems dubious to me.
> So, the issue is --- as so often --- more involved than assumed initially.
> 
> We (R core) will probably do something, but do need more time
> before we can promise anything more...
OK, thanks. Given for how long this behavior has existed, there's
certainly no hurry...


Regards

> Thank you for raising the issue,
> Martin Maechler, ETH Zurich
> 
> 
> *) R-devel sources always current at
> ???https://svn.r-project.org/R/trunk/src/library/base/R/table.R
> 
> > 
> > Regards
> > [1] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14630


From h.wickham at gmail.com  Sat Jan 21 17:56:31 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 21 Jan 2017 10:56:31 -0600
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
Message-ID: <CABdHhvFYWmL5hXrsjHtU_uB+ipS8KWkMgp3gmr0ZF7xDgw28Gw@mail.gmail.com>

To summarise this thread, there are basically three ways of handling int64 in R:

* coerce to character
* coerce to double
* store in double

There is no ideal solution, and each have pros and cons that I've
attempted to summarise below.

## Coerce to character

This is the easiest approach if the data is used as identifiers. It
will have some performance drawbacks when loading and will require
additional memory. It should not have negative performance
implications once the data has been loaded because R has a global
string pool so string comparisons only require a single pointer
comparison (assuming they have the same encoding)

## Coerce to double

This is the easiest approach if your integers are in the range
[-(2^53), 2^53] or you can tolerate some minor loss of precision.

## Store in a double

This technique takes advantage of the fact that doubles and int64s are
the same size, so you can store the binary representation of an int64
in a double. This will effectively be garbage if you treat the vector
as if it is a double, so it requires adding an S3 class and overriding
every generic function with a custom method. Not all functions are
generic, and internal C code will not know about the special class, so
this has the danger of code silently interpreting the data
incorrectly.

This is the approach taken by the bit64 package (and, I believe, the
int64 package, but since that's been archived it's not worth
considering.

Hadley

On Fri, Jan 20, 2017 at 9:19 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> I am not on R-core, so cannot speak to future plans to internally support
> int8 (though my impression is that there aren't any, at least none that are
> close to fruition).
>
> The standard way of dealing with whole numbers too big to fit in an integer
> is to put them in a numeric (double down in C land). this can represent
> integers up to 2^53 without loss of precision see (
> http://stackoverflow.com/questions/1848700/biggest-integer-that-can-be-stored-in-a-double).
> This is how long vector indices are (currently) implemented in R. If it's
> good enough for indices it's probably good enough for whatever you need
> them for.
>
> Hope that helps.
>
> ~G
>
>
> On Fri, Jan 20, 2017 at 6:33 AM, Nicolas Paris <nicolas.paris at aphp.fr>
> wrote:
>
>> Hello r users,
>>
>> I have to deal with int8 data with R. AFAIK  R does only handle int4
>> with `as.integer` function [1]. I wonder:
>> 1. what is the better approach to handle int8 ? `as.character` ?
>> `as.numeric` ?
>> 2. is there any plan to handle int8 in the future ? As you might know,
>> int4 is to small to deal with earth population right now.
>>
>> Thanks for you ideas,
>>
>> int8 eg:
>>
>>      human_id
>> ----------------------
>>  -1311071933951566764
>>  -4708675461424073238
>>  -6865005668390999818
>>   5578000650960353108
>>  -3219674686933841021
>>  -6469229889308771589
>>   -606871692563545028
>>  -8199987422425699249
>>   -463287495999648233
>>   7675955260644241951
>>
>> reference:
>> 1. https://www.r-bloggers.com/r-in-a-64-bit-world/
>>
>> --
>> Nicolas PARIS
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker, PhD
> Associate Scientist (Bioinformatics)
> Genentech Research
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://hadley.nz


From josh.m.ulrich at gmail.com  Sat Jan 21 18:58:18 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 21 Jan 2017 11:58:18 -0600
Subject: [Rd] bug in rbind?
In-Reply-To: <D1E6227CBC482446B2D877554FCD338C2CCB4982@MBX01A.stf.nus.edu.sg>
References: <D1E6227CBC482446B2D877554FCD338C2CCB4982@MBX01A.stf.nus.edu.sg>
Message-ID: <CAPPM_gRThYFANgAwxb-9fa4=X4qRE80gH3SGESnxWEe-DzVRqg@mail.gmail.com>

I'm not sure whether or not this is a bug, but I did isolate the line
where the error is thrown:
src/library/base/R/dataframe.R:1395.
https://github.com/wch/r-source/blob/01374c3c367fa12f555fd354f735a6e16e5bd98e/src/library/base/R/dataframe.R#L1395

The error is thrown because the line attempts to set a subset of the
rownames to NULL, which fails.

R> options(error = recover)
R> rbind(dfm.names, dfm)
Error in rownames(value[[jj]])[ri] <- rownames(xij) :
  replacement has length zero

Enter a frame number, or 0 to exit

1: rbind(dfm.names, dfm)
2: rbind(deparse.level, ...)

Selection: 2
Called from: top level
Browse[1]> rownames(value[[jj]])
[1] "a" "b" "c" NA  NA  NA
Browse[1]> rownames(xij)
NULL
Browse[1]> ri
[1] 4 5 6
Browse[1]> rownames(value[[jj]])[ri]
[1] NA NA NA


On Mon, Jan 16, 2017 at 7:50 PM, Krzysztof Banas <krzysztof at nus.edu.sg> wrote:
> I suspect there may be a bug in base::rbind.data.frame
>
> Below there is minimal example of the problem:
>
> m <- matrix (1:12, 3)
> dfm <- data.frame (c = 1 : 3, m = I (m))
> str (dfm)
>
> m.names <- m
> rownames (m.names) <- letters [1:3]
> dfm.names <- data.frame (c = 1 : 3, m = I (m.names))
> str (dfm.names)
>
> rbind (m, m.names)
> rbind (m.names, m)
> rbind (dfm, dfm.names)
>
> #not working
> rbind (dfm.names, dfm)
>
> Error in rbind(deparse.level, ...) : replacement has length zero
>
> rbind (dfm, dfm.names)$m
>
>
>      [,1] [,2] [,3] [,4]
>
> <NA>    1    4    7   10
>
> <NA>    2    5    8   11
>
> <NA>    3    6    9   12
>
> a       1    4    7   10
>
> b       2    5    8   11
>
> c       3    6    9   12
>
>
>
> ________________________________
>
> Important: This email is confidential and may be privileged. If you are not the intended recipient, please delete it and notify us immediately; you should not copy or use it for any purpose, nor disclose its contents to any other person. Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From edd at debian.org  Sat Jan 21 19:04:28 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 21 Jan 2017 12:04:28 -0600
Subject: [Rd] How to handle INT8 data
In-Reply-To: <CABdHhvFYWmL5hXrsjHtU_uB+ipS8KWkMgp3gmr0ZF7xDgw28Gw@mail.gmail.com>
References: <20170120143335.GE9661@aphp.fr>
	<CADwqtCONJBR+N_skH2ONWLBPvimNKyyCTDPzLbxvONxKPJfdeA@mail.gmail.com>
	<CABdHhvFYWmL5hXrsjHtU_uB+ipS8KWkMgp3gmr0ZF7xDgw28Gw@mail.gmail.com>
Message-ID: <22659.41644.866046.444445@max.nulle.part>


On 21 January 2017 at 10:56, Hadley Wickham wrote:
| To summarise this thread, there are basically three ways of handling int64 in R:
| 
| * coerce to character
| * coerce to double
| * store in double
| 
| ## Coerce to character

Serious performance loss.
 
| ## Coerce to double

Serious precision + functionality loss.

Rember, int64, not int53, is what we are after. That that is what other
systems we want to interop with have (bigtable indices).

| ## Store in a double

Best approach in my book, and done in bit64::integer.

| This is the approach taken by the bit64 package (and, I believe, the

Incorrect.

That used an S4 class with two int32. The bit64 package has a bit on
comparison. But as int64 is abandonware it doesn't matter either way.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From tomas.kalibera at gmail.com  Tue Jan 24 10:32:53 2017
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 24 Jan 2017 10:32:53 +0100
Subject: [Rd] NaN behavior of cumsum
In-Reply-To: <9A7219BE-A728-45E0-B02E-E1834841D749@oracle.com>
References: <9A7219BE-A728-45E0-B02E-E1834841D749@oracle.com>
Message-ID: <315b7608-3ddf-f6a4-e283-f485a22c194a@gmail.com>

Hi Lukas,

thanks for the report. I've changed cumsum so that it is now consistent 
with cumprod wrt to NA/NaN propagation.
Now NaN is not turned into NA unnecessarily.

Still please be aware that generally NaNs may become NAs in R (on some 
platforms/compilers)
?NaN says

"Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
which of those two is not guaranteed and may depend on the R
platform (since compilers may re-order computations)."

Best
Tomas

On 01/20/2017 02:52 PM, Lukas Stadler wrote:
> Hi!
>
> I noticed that cumsum behaves different than the other cumulative functions wrt. NaN values:
>> values <- c(1,2,NaN,1)
>> for ( f in c(cumsum, cumprod, cummin, cummax)) print(f(values))
> [1]  1  3 NA NA
> [1]   1   2 NaN NaN
> [1]   1   1 NaN NaN
> [1]   1   2 NaN NaN
>
> The reason is that cumsum (in cum.c:33) contains an explicit check for ISNAN.
> Is that intentional?
> IMHO, ISNA would be better (because it would make the behavior consistent with the other functions).
>
> - Lukas
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Wed Jan 25 04:06:03 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 24 Jan 2017 19:06:03 -0800
Subject: [Rd] parallel::mc*: Is it possible for a child process to know it
	is a fork?
Message-ID: <CAFDcVCRtpGfSvUxyQKSoufWLCAeXVCTMpn6x9WFL9F1SJh68AA@mail.gmail.com>

When using multicore-forking of the parallel package, is it possible
for a child process to know that it is a fork?  Something like:

  parallel::mclapply(1:10, FUN = function(i) { test_if_running_in_a_fork() })

I'm looking into ways to protect against further parallel processes
(including threads), which not necessarily are created via the
parallel:mc* API, are being spawned off recursively.  For instance,
there are several packages that by default perform multi-threaded
processing using native code, but I'm not sure there's a way for such
package to avoid running in multi-threaded mode if running in a forked
child R processes.  Imagine

  y <- parallel::mclapply(1:10, FUN = function(i) {
     somepkg::threaded_calculation_using_all_cores()
  })

where the developer of `somepkg` is off no control whether user calls
it via mclapply() or via lapply().   I can see how the user of
mclapply() / lapply() can pass on this information, but that's not
safe and it might not be that the user is aware that deep down in the
dependency hierarchy there's one or more functions that do
multi-thread/process processing.

Thanks,

Henrik


From jeroenooms at gmail.com  Wed Jan 25 05:10:41 2017
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 24 Jan 2017 20:10:41 -0800
Subject: [Rd] parallel::mc*: Is it possible for a child process to know
 it is a fork?
In-Reply-To: <CAFDcVCRtpGfSvUxyQKSoufWLCAeXVCTMpn6x9WFL9F1SJh68AA@mail.gmail.com>
References: <CAFDcVCRtpGfSvUxyQKSoufWLCAeXVCTMpn6x9WFL9F1SJh68AA@mail.gmail.com>
Message-ID: <CABFfbXu-VkzaGJqmkNUDk7GvXgF0T6SazukGFza9PSmozBs5fA@mail.gmail.com>

On Tue, Jan 24, 2017 at 7:06 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> When using multicore-forking of the parallel package, is it possible
> for a child process to know that it is a fork?

R internally uses R_isForkedChild to prevent certain operations within
the fork. However I don't think this is exported anywhere. You could
do something like:

  extern Rboolean R_isForkedChild;
  SEXP is_forked(){
    return ScalarLogical(R_isForkedChild);
  }

But that won't be allowed on CRAN:

* checking compiled code ... NOTE
  Found non-API call to R: ?R_isForkedChild?
  Compiled code should not call non-API entry points in R.

Another method would be to look at getppid(2) and getpgid(2) to lookup
the parent-id and group-id of the current process and test if it
matches that of the (parent) R process.

If you are only interested in limiting further parallelization within
the fork, perhaps you can simply use parallel::mcaffinity to restrict
the forked process to a single core.


From csardi.gabor at gmail.com  Wed Jan 25 15:04:59 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 25 Jan 2017 14:04:59 +0000
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <CABtg=Kno5kv+YcisXc+UmEQv0xS33re3MGOZXYus=U=qeGz9Dw@mail.gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
	<22612.5114.200686.241246@max.nulle.part>
	<CABz6aZfAHMVLNo2hnYk8j8mjLyqq2LXvAUmqLVnj7cE7E8dQtw@mail.gmail.com>
	<4bc01854-5884-3566-d300-1675ecca518c@gmail.com>
	<CABtg=Kno5kv+YcisXc+UmEQv0xS33re3MGOZXYus=U=qeGz9Dw@mail.gmail.com>
Message-ID: <CABtg=KniXWFtJRD=SYbJWz-nWaMEdsBbTuOKCVGNmTk117MsKg@mail.gmail.com>

FWIW I wrote a tool that tests which dependencies of a package are
build-time dependencies:
https://github.com/r-hub/builddeps

It is not very smart, just "brute-force", really. It tries to install the
package several times, leaving out one dependency at a time, and if the
installation fails, then the missing package is a build-time dependency.
(First it tries with the LinkingTo dependencies only, and if that succeeds,
then these are the only build time dependncies.)

It does download all dependent packages, and runs R CMD install several
times, so it is expensive. It is better to run it with binary packages.

It is mostly trivial, except that
1) it needs to edit DESCRIPTION and NAMESPACE to omit a dependency.
DESCRIPTION is easy, NAMESPACE somewhat more difficult, because there is a
parser for it, but no "writer".
2) the dependencies need to be considered in a topological order, otherwise
one gets wrong answers.

I wrote this mainly for R-hub, to know which binary packages need to be
rebuilt after a package update, but if you use it and have feedback, please
email me or open an issue in the GitHub repo.

Gabor

On Fri, Dec 16, 2016 at 9:27 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
wrote:

> I think that this problem is actually more general than just ABI
> versioning. The common definition of ABI refers to compiled code, but
> with R packages similar problems might happen (and they to happen)
> without any compiled code.
>
> I think the key issue is the concept of build-time dependencies. While
> R packages usually does not distinguish between build-time and
> run-time dependencies, they still do exist, and I think ideally we
> would need to treat them differently.
>
> AFAIK LinkingTo is the only form of a build-time dependency, that is
> completely explicit, so it is relatively easy to handle. The other
> frequent of build-time dependency is a function call to the other
> package, that happens at install time. E.g. with references or R6*
> classes you frequently include code like this in yourpackage:
>
> myclass <- R6::R6Class(...)
>
> and this code is evaluated at install time. So if the R6 package is
> updated, the installed version myclass in yourpackage is not affected
> at all. In fact, if the new version of R6 is not compatible with the
> myclass object created by the old version, then yourpackage will be
> broken. (This AFAIK cannot happen with R6, so it is not the best
> example, but it can happen in other similar cases.)
>
> The key here is that R6 is a build-time dependency of yourpackage,
> similarly to packages linking to (i.e. LinkingTo) Rpp.
>
> Another possible type of build-time dependency is if you put objects
> from another package in yourpackage. E.g.
>
> myfun <- otherpkg::fun
>
> Then a copy of otherpkg::fun will be saved in yourpackage. If you
> install a new version of otherpkg, yourpackage is unaffected, and if
> otherpkg::fun uses some (possibly internal) API from otherpkg, that
> has changed in the new version of otherpkg, you might easily end up
> with a broken yourpackage again.
>
> I think one lesson is to avoid running code at install time. This is
> not a new thing, AFAIR it is even mentioned in 'Writing R extensions'.
> Instead of running code at install time, you might consider running it
> in `.onLoad()`, and then these "problems" go away. But you obviously
> cannot always avoid it.
>
> Gabor
>
> * I think the R6 package is great, and I am not speaking in any way
> against it. I just needed an example, and I know R6 much better than
> reference classes, or other similar packages.
>

	[[alternative HTML version deleted]]


From florent.angly at gmail.com  Wed Jan 25 16:31:45 2017
From: florent.angly at gmail.com (Florent Angly)
Date: Wed, 25 Jan 2017 16:31:45 +0100
Subject: [Rd] Undefined behavior of head() and tail() with n = 0
Message-ID: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>

Hi all,

The documentation for head() and tail() describes the behavior of
these generic functions when n is strictly positive (n > 0) and
strictly negative (n < 0). How these functions work when given a zero
value is not defined.

Both GNU command-line utilities head and tail behave differently with +0 and -0:
http://man7.org/linux/man-pages/man1/head.1.html
http://man7.org/linux/man-pages/man1/tail.1.html

Since R supports signed zeros (1/+0 != 1/-0) and the R head() and
tail() functions are modeled after their GNU counterparts, I would
expect the R functions to distinguish between +0 and -0

> tail(1:5, n=0)
integer(0)
> tail(1:5, n=1)
[1] 5
> tail(1:5, n=2)
[1] 4 5

> tail(1:5, n=-2)
[1] 3 4 5
> tail(1:5, n=-1)
[1] 2 3 4 5
> tail(1:5, n=-0)
integer(0)  # expected 1:5

> head(1:5, n=0)
integer(0)
> head(1:5, n=1)
[1] 1
> head(1:5, n=2)
[1] 1 2

> head(1:5, n=-2)
[1] 1 2 3
> head(1:5, n=-1)
[1] 1 2 3 4
> head(1:5, n=-0)
integer(0)  # expected 1:5

For both head() and tail(), I expected 1:5 as output but got
integer(0). I obtained similar results using a data.frame and a
function as x argument.

An easy fix would be to explicitly state in the documentation what n =
0 does, and that there is no practical difference between -0 and +0.
However, in my eyes, the better approach would be implement support
for -0 and document it. What do you think?

Best,

Florent


PS/ My sessionInfo() gives:
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Switzerland.1252
LC_CTYPE=German_Switzerland.1252
LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
 LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jan 25 21:22:09 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Wed, 25 Jan 2017 20:22:09 +0000
Subject: [Rd] help(clusterApply) (parallel package)
Message-ID: <43df4d20f4ee43489ec0304aa02975c2@UM-MAIL3216.unimaas.nl>

Hello,

In help(clusterApply) of the 'parallel' package, it says:

"clusterApply calls fun on the first node with arguments seq[[1]] and ..., on the second node with seq[[2]] and ..., and so on, recycling nodes as needed."

But the argument that is iterated over in clusterApply() is called 'x' not 'seq', so shouldn't it read x[[1]], x[[2]], and so on?

Also, 'x' doesn't have to be a vector ("x - a vector for clusterApply and clusterApplyLB, a matrix for parRapply and parCapply."), it just needs to be an object for which x[[1]], x[[2]], ... works (e.g., a data frame works just fine).

"clusterApplyLB is a load balancing version of clusterApply. If the length p of seq is not greater than the number of nodes n, then a job is sent to p nodes." Again, shouldn't that say "If the length p of x"?

And finally, "For clusterApply and clusterApplyLB, a list the same length as seq." Again, 'x' instead of 'seq'?

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    


From henrik.bengtsson at gmail.com  Wed Jan 25 22:42:47 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 25 Jan 2017 13:42:47 -0800
Subject: [Rd] parallel::mc*: Is it possible for a child process to know
 it is a fork?
In-Reply-To: <CABFfbXu-VkzaGJqmkNUDk7GvXgF0T6SazukGFza9PSmozBs5fA@mail.gmail.com>
References: <CAFDcVCRtpGfSvUxyQKSoufWLCAeXVCTMpn6x9WFL9F1SJh68AA@mail.gmail.com>
	<CABFfbXu-VkzaGJqmkNUDk7GvXgF0T6SazukGFza9PSmozBs5fA@mail.gmail.com>
Message-ID: <CAFDcVCQLgv3At278h7E2CLAd2qttsaUHTq2cMMwMPACEWtANKg@mail.gmail.com>

On Tue, Jan 24, 2017 at 8:10 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> On Tue, Jan 24, 2017 at 7:06 PM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> When using multicore-forking of the parallel package, is it possible
>> for a child process to know that it is a fork?
>
> R internally uses R_isForkedChild to prevent certain operations within
> the fork. However I don't think this is exported anywhere. You could
> do something like:
>
>   extern Rboolean R_isForkedChild;
>   SEXP is_forked(){
>     return ScalarLogical(R_isForkedChild);
>   }
>
> But that won't be allowed on CRAN:
>
> * checking compiled code ... NOTE
>   Found non-API call to R: ?R_isForkedChild?
>   Compiled code should not call non-API entry points in R.

Yes, that's a bummer.  It could be useful to have this exposed.  It's
used by several core packages, not just 'parallel' itself;

$ grep -F R_isForkedChild -r --include="*.h"
src/include/Defn.h:extern Rboolean R_isForkedChild INI_as(FALSE); /*
was this forked? */

$ grep -F R_isForkedChild -r --include="*.c"
src/library/tcltk/src/tcltk_unix.c://extern Rboolean R_isForkedChild;
src/library/tcltk/src/tcltk_unix.c:    if (!R_isForkedChild && !Tcl_lock
src/library/parallel/src/fork.c:#include <Defn.h> // for R_isForkedChild
src/library/parallel/src/fork.c: R_isForkedChild = 1;
src/modules/X11/devX11.c:    while (!R_isForkedChild && displayOpen &&
XPending(display)) {
src/modules/X11/devX11.c:    if(R_isForkedChild)
src/unix/sys-unix.c:    if (ptr_R_ProcessEvents && !R_isForkedChild)
ptr_R_ProcessEvents();

>
> Another method would be to look at getppid(2) and getpgid(2) to lookup
> the parent-id and group-id of the current process and test if it
> matches that of the (parent) R process.

I'm not 100% sure I follow.  Is the idea similar to the following in R?

ppid <- Sys.getpid()
is_child <- parallel::mclapply(1:10, FUN = function(i) { Sys.getpid() != ppid })

How can the child process know 'ppid'?  getppid would give the parent
PID for any process, which could be a non-R process.

>
> If you are only interested in limiting further parallelization within
> the fork, perhaps you can simply use parallel::mcaffinity to restrict
> the forked process to a single core.

This is tied to parallelization via parallel::mc*, correct?  That is,
is it only parallel:::mcfork() that respects those settings or does
this go down deeper in the OS such that it affects forking / threading
on a more general level?

Thanks for your pointers and suggestions,

Henrik


From maechler at stat.math.ethz.ch  Thu Jan 26 10:53:45 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 26 Jan 2017 10:53:45 +0100
Subject: [Rd] Undefined behavior of head() and tail() with n = 0
In-Reply-To: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
Message-ID: <22665.50985.353259.677262@stat.math.ethz.ch>

>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>     on Wed, 25 Jan 2017 16:31:45 +0100 writes:

    > Hi all,
    > The documentation for head() and tail() describes the behavior of
    > these generic functions when n is strictly positive (n > 0) and
    > strictly negative (n < 0). How these functions work when given a zero
    > value is not defined.

    > Both GNU command-line utilities head and tail behave differently with +0 and -0:
    > http://man7.org/linux/man-pages/man1/head.1.html
    > http://man7.org/linux/man-pages/man1/tail.1.html

    > Since R supports signed zeros (1/+0 != 1/-0) 

whoa, whoa, .. slow down --  The above is misleading!

Rather read in  ?Arithmetic (*the* reference to consult for such issues),
where the 2nd part of the following section

 || Implementation limits:
 || 
 ||      [..............]
 || 
 ||      Another potential issue is signed zeroes: on IEC 60659 platforms
 ||      there are two zeroes with internal representations differing by
 ||      sign.  Where possible R treats them as the same, but for example
 ||      direct output from C code often does not do so and may output
 ||      ?-0.0? (and on Windows whether it does so or not depends on the
 ||      version of Windows).  One place in R where the difference might be
 ||      seen is in division by zero: ?1/x? is ?Inf? or ?-Inf? depending on
 ||      the sign of zero ?x?.  Another place is ?identical(0, -0, num.eq =
 ||      FALSE)?.

says the *contrary* ( __Where possible R treats them as the same__ ):
We do _not_ want to distinguish -0 and +0,
but there are cases where it is inavoidable

And there are good reasons (mathematics !!) for this.

I'm pretty sure that it would be quite a mistake to start
differentiating it here...  but of course we can continue
discussing here if you like.

Martin Maechler
ETH Zurich and R Core


    > and the R head() and tail() functions are modeled after
    > their GNU counterparts, I would expect the R functions to
    > distinguish between +0 and -0

    >> tail(1:5, n=0)
    > integer(0)
    >> tail(1:5, n=1)
    > [1] 5
    >> tail(1:5, n=2)
    > [1] 4 5

    >> tail(1:5, n=-2)
    > [1] 3 4 5
    >> tail(1:5, n=-1)
    > [1] 2 3 4 5
    >> tail(1:5, n=-0)
    > integer(0)  # expected 1:5

    >> head(1:5, n=0)
    > integer(0)
    >> head(1:5, n=1)
    > [1] 1
    >> head(1:5, n=2)
    > [1] 1 2

    >> head(1:5, n=-2)
    > [1] 1 2 3
    >> head(1:5, n=-1)
    > [1] 1 2 3 4
    >> head(1:5, n=-0)
    > integer(0)  # expected 1:5

    > For both head() and tail(), I expected 1:5 as output but got
    > integer(0). I obtained similar results using a data.frame and a
    > function as x argument.

    > An easy fix would be to explicitly state in the documentation what n =
    > 0 does, and that there is no practical difference between -0 and +0.
    > However, in my eyes, the better approach would be implement support
    > for -0 and document it. What do you think?

    > Best,

    > Florent


    > PS/ My sessionInfo() gives:
    > R version 3.3.2 (2016-10-31)
    > Platform: x86_64-w64-mingw32/x64 (64-bit)
    > Running under: Windows 7 x64 (build 7601) Service Pack 1

    > locale:
    > [1] LC_COLLATE=German_Switzerland.1252
    > LC_CTYPE=German_Switzerland.1252
    > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
    > LC_TIME=German_Switzerland.1252

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Jan 26 11:42:27 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 26 Jan 2017 11:42:27 +0100
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <22665.50985.353259.677262@stat.math.ethz.ch>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
Message-ID: <22665.53907.178714.742585@stat.math.ethz.ch>

Last week, we've talked here about "xtabs(), factors and NAs",
 ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html

In the mean time, I've spent several hours on the issue
and also committed changes to R-devel "in two iterations".

In the case there is a *Left* hand side part to xtabs() formula,
see the help page example using 'esoph',
it uses  tapply(...,  FUN = sum)   and
I now think there is a missing feature in tapply() there, which
I am proposing to change. 

Look at a small example:

> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
, , N = 3

   L
n   A B C D E F
  1 1 2 0 0 0 0
  2 0 0 1 2 0 0
  3 0 0 0 0 2 2

> DN <- D2; DN[1,"N"] <- NA; DN
   n L  N
2  1 A NA
3  1 B  3
4  1 B  3
6  2 C  3
7  2 D  3
8  2 D  3
9  3 E  3
10 3 E  3
11 3 F  3
12 3 F  3
> with(DN, tapply(N, list(n,L), FUN=sum))
   A  B  C  D  E  F
1 NA  6 NA NA NA NA
2 NA NA  3  6 NA NA
3 NA NA NA NA  6  6
>  

and as you can see, the resulting matrix has NAs, all the same
NA_real_, but semantically of two different kinds:

1) at ["1", "A"], the  NA  comes from the NA in 'N'
2) all other NAs come from the fact that there is no such factor combination
   *and* from the fact that tapply() uses

   array(dim = .., dimnames = ...)

i.e., initializes the array with NAs  (see definition of 'array').

My proposition is the following patch to  tapply(), adding a new
option 'init.value':

-----------------------------------------------------------------------------
 
-tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
+tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
 {
     FUN <- if (!is.null(FUN)) match.fun(FUN)
     if (!is.list(INDEX)) INDEX <- list(INDEX)
@@ -44,7 +44,7 @@
     index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
     ans <- lapply(X = ans[index], FUN = FUN, ...)
     if (simplify && all(lengths(ans) == 1L)) {
-	ansmat <- array(dim = extent, dimnames = namelist)
+	ansmat <- array(init.value, dim = extent, dimnames = namelist)
 	ans <- unlist(ans, recursive = FALSE)
     } else {
 	ansmat <- array(vector("list", prod(extent)),

-----------------------------------------------------------------------------

With that, I can set the initial value to '0' instead of array's
default of NA :

> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
   A B C D E F
1 NA 6 0 0 0 0
2  0 0 3 6 0 0
3  0 0 0 0 6 6
> 

which now has 0 counts and NA  as is desirable to be used inside
xtabs().

All fine... and would not be worth a posting to R-devel,
except for this:

The change will not be 100% back compatible -- by necessity: any new argument for
tapply() will make that argument name not available to be
specified (via '...') for 'FUN'.  The new function would be

> str(tapply)
function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)  

where the '...' are passed FUN(),  and with the new signature,
'init.value' then won't be passed to FUN  "anymore" (compared to
R <= 3.3.x).

For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
the probability the arg name is used in other functions).


Opinions?

Thank you in advance,
Martin


From rob.vech87 at gmail.com  Thu Jan 26 11:02:06 2017
From: rob.vech87 at gmail.com (rob vech)
Date: Thu, 26 Jan 2017 11:02:06 +0100
Subject: [Rd] strptime bug
Message-ID: <70325e6b-6d54-8172-3915-bbfc8d5cd837@gmail.com>

Dear developer list,
I want to submit the following problem that seems like a bug, as 
confirmed by an other user [1], related to date-time parsing:
Here a simple script:

# that works:
as.numeric(as.POSIXlt(strptime('2016-03-27 01:05:50', format='%Y-%m-%d 
%H:%M:%S')))

# that not (it returns NA):
as.numeric(as.POSIXlt(strptime('2016-03-27 02:05:50', format='%Y-%m-%d 
%H:%M:%S')))

# it works again
as.numeric(as.POSIXlt(strptime('2016-03-27 03:05:50', format='%Y-%m-%d 
%H:%M:%S')))

I made several test and the problem seems to be related to the couple 
"2016-03-27" as date and "2" as hour. It seems not to be related to the 
datetime format.

There is a similar bug on bugzilla [2] but in my case I cannot replicate it.

My OS is Win 7 and R v3.3.2.

Thank you

rob


[1] https://stat.ethz.ch/pipermail/r-help/2017-January/444468.html

[2] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16764


	[[alternative HTML version deleted]]


From georgi.boshnakov at manchester.ac.uk  Thu Jan 26 13:54:06 2017
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 26 Jan 2017 12:54:06 +0000
Subject: [Rd] :  strptime bug
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018B01F7A9@MBXP01.ds.man.ac.uk>

Hi,

You don't give the time zone but this is probably due to the clock jumping by one hour when switching to summer time. In UK this happens at 1am and on that day there is no such thing as 01:05, etc.,  see eg https://www.timeanddate.com/time/change/uk/london
In your time zone this probably happens at 2am.

Georgi Boshnakov

------------------------------

Message: 7
Date: Thu, 26 Jan 2017 11:02:06 +0100
From: rob vech <rob.vech87 at gmail.com>
To: r-devel at r-project.org
Subject: [Rd] strptime bug
Message-ID: <70325e6b-6d54-8172-3915-bbfc8d5cd837 at gmail.com>
Content-Type: text/plain; charset="UTF-8"

Dear developer list,
I want to submit the following problem that seems like a bug, as confirmed by an other user [1], related to date-time parsing:
Here a simple script:

# that works:
as.numeric(as.POSIXlt(strptime('2016-03-27 01:05:50', format='%Y-%m-%d
%H:%M:%S')))

# that not (it returns NA):
as.numeric(as.POSIXlt(strptime('2016-03-27 02:05:50', format='%Y-%m-%d
%H:%M:%S')))

# it works again
as.numeric(as.POSIXlt(strptime('2016-03-27 03:05:50', format='%Y-%m-%d
%H:%M:%S')))

I made several test and the problem seems to be related to the couple "2016-03-27" as date and "2" as hour. It seems not to be related to the datetime format.

There is a similar bug on bugzilla [2] but in my case I cannot replicate it.

My OS is Win 7 and R v3.3.2.

Thank you

rob


[1] https://stat.ethz.ch/pipermail/r-help/2017-January/444468.html

[2] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16764


	[[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------

End of R-devel Digest, Vol 167, Issue 23


From wdunlap at tibco.com  Thu Jan 26 16:47:39 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Jan 2017 07:47:39 -0800
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <22665.53907.178714.742585@stat.math.ethz.ch>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
Message-ID: <CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>

It would be cool if the default for tapply's init.value could be
FUN(X[0]), so it would be 0 for FUN=sum or FUN=length, TRUE for
FUN=all, -Inf for FUN=max, etc.  But that would take time and would
break code for which FUN did not work on length-0 objects.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 26, 2017 at 2:42 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> Last week, we've talked here about "xtabs(), factors and NAs",
>  ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html
>
> In the mean time, I've spent several hours on the issue
> and also committed changes to R-devel "in two iterations".
>
> In the case there is a *Left* hand side part to xtabs() formula,
> see the help page example using 'esoph',
> it uses  tapply(...,  FUN = sum)   and
> I now think there is a missing feature in tapply() there, which
> I am proposing to change.
>
> Look at a small example:
>
>> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
> , , N = 3
>
>    L
> n   A B C D E F
>   1 1 2 0 0 0 0
>   2 0 0 1 2 0 0
>   3 0 0 0 0 2 2
>
>> DN <- D2; DN[1,"N"] <- NA; DN
>    n L  N
> 2  1 A NA
> 3  1 B  3
> 4  1 B  3
> 6  2 C  3
> 7  2 D  3
> 8  2 D  3
> 9  3 E  3
> 10 3 E  3
> 11 3 F  3
> 12 3 F  3
>> with(DN, tapply(N, list(n,L), FUN=sum))
>    A  B  C  D  E  F
> 1 NA  6 NA NA NA NA
> 2 NA NA  3  6 NA NA
> 3 NA NA NA NA  6  6
>>
>
> and as you can see, the resulting matrix has NAs, all the same
> NA_real_, but semantically of two different kinds:
>
> 1) at ["1", "A"], the  NA  comes from the NA in 'N'
> 2) all other NAs come from the fact that there is no such factor combination
>    *and* from the fact that tapply() uses
>
>    array(dim = .., dimnames = ...)
>
> i.e., initializes the array with NAs  (see definition of 'array').
>
> My proposition is the following patch to  tapply(), adding a new
> option 'init.value':
>
> -----------------------------------------------------------------------------
>
> -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
> +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>  {
>      FUN <- if (!is.null(FUN)) match.fun(FUN)
>      if (!is.list(INDEX)) INDEX <- list(INDEX)
> @@ -44,7 +44,7 @@
>      index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
>      ans <- lapply(X = ans[index], FUN = FUN, ...)
>      if (simplify && all(lengths(ans) == 1L)) {
> -       ansmat <- array(dim = extent, dimnames = namelist)
> +       ansmat <- array(init.value, dim = extent, dimnames = namelist)
>         ans <- unlist(ans, recursive = FALSE)
>      } else {
>         ansmat <- array(vector("list", prod(extent)),
>
> -----------------------------------------------------------------------------
>
> With that, I can set the initial value to '0' instead of array's
> default of NA :
>
>> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
>    A B C D E F
> 1 NA 6 0 0 0 0
> 2  0 0 3 6 0 0
> 3  0 0 0 0 6 6
>>
>
> which now has 0 counts and NA  as is desirable to be used inside
> xtabs().
>
> All fine... and would not be worth a posting to R-devel,
> except for this:
>
> The change will not be 100% back compatible -- by necessity: any new argument for
> tapply() will make that argument name not available to be
> specified (via '...') for 'FUN'.  The new function would be
>
>> str(tapply)
> function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>
> where the '...' are passed FUN(),  and with the new signature,
> 'init.value' then won't be passed to FUN  "anymore" (compared to
> R <= 3.3.x).
>
> For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
> the probability the arg name is used in other functions).
>
>
> Opinions?
>
> Thank you in advance,
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Jan 26 16:51:49 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Jan 2017 07:51:49 -0800
Subject: [Rd] Undefined behavior of head() and tail() with n = 0
In-Reply-To: <22665.50985.353259.677262@stat.math.ethz.ch>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
Message-ID: <CAF8bMcbOHu=xVmcmLgrkhrfkrmTqo6wp3HH+zDaLvv6DOuyh-g@mail.gmail.com>

In addition, signed zeroes only exist for floating point numbers - the
bit patterns for as.integer(0) and as.integer(-0) are identical.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 26, 2017 at 1:53 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>>     on Wed, 25 Jan 2017 16:31:45 +0100 writes:
>
>     > Hi all,
>     > The documentation for head() and tail() describes the behavior of
>     > these generic functions when n is strictly positive (n > 0) and
>     > strictly negative (n < 0). How these functions work when given a zero
>     > value is not defined.
>
>     > Both GNU command-line utilities head and tail behave differently with +0 and -0:
>     > http://man7.org/linux/man-pages/man1/head.1.html
>     > http://man7.org/linux/man-pages/man1/tail.1.html
>
>     > Since R supports signed zeros (1/+0 != 1/-0)
>
> whoa, whoa, .. slow down --  The above is misleading!
>
> Rather read in  ?Arithmetic (*the* reference to consult for such issues),
> where the 2nd part of the following section
>
>  || Implementation limits:
>  ||
>  ||      [..............]
>  ||
>  ||      Another potential issue is signed zeroes: on IEC 60659 platforms
>  ||      there are two zeroes with internal representations differing by
>  ||      sign.  Where possible R treats them as the same, but for example
>  ||      direct output from C code often does not do so and may output
>  ||      ?-0.0? (and on Windows whether it does so or not depends on the
>  ||      version of Windows).  One place in R where the difference might be
>  ||      seen is in division by zero: ?1/x? is ?Inf? or ?-Inf? depending on
>  ||      the sign of zero ?x?.  Another place is ?identical(0, -0, num.eq =
>  ||      FALSE)?.
>
> says the *contrary* ( __Where possible R treats them as the same__ ):
> We do _not_ want to distinguish -0 and +0,
> but there are cases where it is inavoidable
>
> And there are good reasons (mathematics !!) for this.
>
> I'm pretty sure that it would be quite a mistake to start
> differentiating it here...  but of course we can continue
> discussing here if you like.
>
> Martin Maechler
> ETH Zurich and R Core
>
>
>     > and the R head() and tail() functions are modeled after
>     > their GNU counterparts, I would expect the R functions to
>     > distinguish between +0 and -0
>
>     >> tail(1:5, n=0)
>     > integer(0)
>     >> tail(1:5, n=1)
>     > [1] 5
>     >> tail(1:5, n=2)
>     > [1] 4 5
>
>     >> tail(1:5, n=-2)
>     > [1] 3 4 5
>     >> tail(1:5, n=-1)
>     > [1] 2 3 4 5
>     >> tail(1:5, n=-0)
>     > integer(0)  # expected 1:5
>
>     >> head(1:5, n=0)
>     > integer(0)
>     >> head(1:5, n=1)
>     > [1] 1
>     >> head(1:5, n=2)
>     > [1] 1 2
>
>     >> head(1:5, n=-2)
>     > [1] 1 2 3
>     >> head(1:5, n=-1)
>     > [1] 1 2 3 4
>     >> head(1:5, n=-0)
>     > integer(0)  # expected 1:5
>
>     > For both head() and tail(), I expected 1:5 as output but got
>     > integer(0). I obtained similar results using a data.frame and a
>     > function as x argument.
>
>     > An easy fix would be to explicitly state in the documentation what n =
>     > 0 does, and that there is no practical difference between -0 and +0.
>     > However, in my eyes, the better approach would be implement support
>     > for -0 and document it. What do you think?
>
>     > Best,
>
>     > Florent
>
>
>     > PS/ My sessionInfo() gives:
>     > R version 3.3.2 (2016-10-31)
>     > Platform: x86_64-w64-mingw32/x64 (64-bit)
>     > Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>     > locale:
>     > [1] LC_COLLATE=German_Switzerland.1252
>     > LC_CTYPE=German_Switzerland.1252
>     > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>     > LC_TIME=German_Switzerland.1252
>
>     > attached base packages:
>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Thu Jan 26 16:57:08 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 26 Jan 2017 07:57:08 -0800
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
	<CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>
Message-ID: <CAFDcVCTHwE8TjE8RGRBsesQwutzsaUw4souVFW-eRi+i4rwQJw@mail.gmail.com>

On a related note, the storage mode should try to match ans[[1]] (or
unlist:ed and) when allocating 'ansmat' to avoid coercion and hence a full
copy.

Henrik


On Jan 26, 2017 07:50, "William Dunlap via R-devel" <r-devel at r-project.org>
wrote:

It would be cool if the default for tapply's init.value could be
FUN(X[0]), so it would be 0 for FUN=sum or FUN=length, TRUE for
FUN=all, -Inf for FUN=max, etc.  But that would take time and would
break code for which FUN did not work on length-0 objects.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jan 26, 2017 at 2:42 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> Last week, we've talked here about "xtabs(), factors and NAs",
>  ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html
>
> In the mean time, I've spent several hours on the issue
> and also committed changes to R-devel "in two iterations".
>
> In the case there is a *Left* hand side part to xtabs() formula,
> see the help page example using 'esoph',
> it uses  tapply(...,  FUN = sum)   and
> I now think there is a missing feature in tapply() there, which
> I am proposing to change.
>
> Look at a small example:
>
>> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]),
N=3)[-c(1,5), ]; xtabs(~., D2)
> , , N = 3
>
>    L
> n   A B C D E F
>   1 1 2 0 0 0 0
>   2 0 0 1 2 0 0
>   3 0 0 0 0 2 2
>
>> DN <- D2; DN[1,"N"] <- NA; DN
>    n L  N
> 2  1 A NA
> 3  1 B  3
> 4  1 B  3
> 6  2 C  3
> 7  2 D  3
> 8  2 D  3
> 9  3 E  3
> 10 3 E  3
> 11 3 F  3
> 12 3 F  3
>> with(DN, tapply(N, list(n,L), FUN=sum))
>    A  B  C  D  E  F
> 1 NA  6 NA NA NA NA
> 2 NA NA  3  6 NA NA
> 3 NA NA NA NA  6  6
>>
>
> and as you can see, the resulting matrix has NAs, all the same
> NA_real_, but semantically of two different kinds:
>
> 1) at ["1", "A"], the  NA  comes from the NA in 'N'
> 2) all other NAs come from the fact that there is no such factor
combination
>    *and* from the fact that tapply() uses
>
>    array(dim = .., dimnames = ...)
>
> i.e., initializes the array with NAs  (see definition of 'array').
>
> My proposition is the following patch to  tapply(), adding a new
> option 'init.value':
>
> ------------------------------------------------------------
-----------------
>
> -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
> +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify
= TRUE)
>  {
>      FUN <- if (!is.null(FUN)) match.fun(FUN)
>      if (!is.list(INDEX)) INDEX <- list(INDEX)
> @@ -44,7 +44,7 @@
>      index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
>      ans <- lapply(X = ans[index], FUN = FUN, ...)
>      if (simplify && all(lengths(ans) == 1L)) {
> -       ansmat <- array(dim = extent, dimnames = namelist)
> +       ansmat <- array(init.value, dim = extent, dimnames = namelist)
>         ans <- unlist(ans, recursive = FALSE)
>      } else {
>         ansmat <- array(vector("list", prod(extent)),
>
> ------------------------------------------------------------
-----------------
>
> With that, I can set the initial value to '0' instead of array's
> default of NA :
>
>> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
>    A B C D E F
> 1 NA 6 0 0 0 0
> 2  0 0 3 6 0 0
> 3  0 0 0 0 6 6
>>
>
> which now has 0 counts and NA  as is desirable to be used inside
> xtabs().
>
> All fine... and would not be worth a posting to R-devel,
> except for this:
>
> The change will not be 100% back compatible -- by necessity: any new
argument for
> tapply() will make that argument name not available to be
> specified (via '...') for 'FUN'.  The new function would be
>
>> str(tapply)
> function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>
> where the '...' are passed FUN(),  and with the new signature,
> 'init.value' then won't be passed to FUN  "anymore" (compared to
> R <= 3.3.x).
>
> For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
> the probability the arg name is used in other functions).
>
>
> Opinions?
>
> Thank you in advance,
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From rob.vech87 at gmail.com  Thu Jan 26 19:35:50 2017
From: rob.vech87 at gmail.com (rob vech)
Date: Thu, 26 Jan 2017 19:35:50 +0100
Subject: [Rd] :  strptime bug [no more!]
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E018B01F7A9@MBXP01.ds.man.ac.uk>
References: <438D2EC9EAFE5946B2D5864670EA468E018B01F7A9@MBXP01.ds.man.ac.uk>
Message-ID: <148c37d5-76cf-de38-3b7e-0caed158ec52@gmail.com>

Thank you Georg!
It definitely resolves the problem!
Adding the correct time zone (tz='GMT') returns a valid number as my 
data are in solar time.
rob

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jan 27 09:34:09 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 27 Jan 2017 09:34:09 +0100
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <CAFDcVCTHwE8TjE8RGRBsesQwutzsaUw4souVFW-eRi+i4rwQJw@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
	<CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>
	<CAFDcVCTHwE8TjE8RGRBsesQwutzsaUw4souVFW-eRi+i4rwQJw@mail.gmail.com>
Message-ID: <22667.1537.5752.108228@stat.math.ethz.ch>


    > On Jan 26, 2017 07:50, "William Dunlap via R-devel" <r-devel at r-project.org>
    > wrote:

    > It would be cool if the default for tapply's init.value could be
    > FUN(X[0]), so it would be 0 for FUN=sum or FUN=length, TRUE for
    > FUN=all, -Inf for FUN=max, etc.  But that would take time and would
    > break code for which FUN did not work on length-0 objects.

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

I had the same idea (after my first post), so I agree that would
be nice. One could argue it would take time only if the user is too lazy
to specify the value,  and we could use 
   tryCatch(FUN(X[0]), error = NA)
to safeguard against those functions that fail for 0 length arg.

But I think the main reason for _not_ setting such a default is
back-compatibility.  In my proposal, the new argument would not
be any change by default and so all current uses of tapply()
would remain unchanged.

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Thu, 26 Jan 2017 07:57:08 -0800 writes:

    > On a related note, the storage mode should try to match ans[[1]] (or
    > unlist:ed and) when allocating 'ansmat' to avoid coercion and hence a full
    > copy.

Yes, related indeed; and would fall "in line" with Bill's idea.
OTOH, it could be implemented independently,
by something like

   if(missing(init.value))
     init.value <-
       if(length(ans)) as.vector(NA, mode=storage.mode(ans[[1]]))
       else NA

.............

A colleague proposed to use the shorter argument name 'default'
instead of 'init.value'  which indeed maybe more natural and
still not too often used as "non-first" argument in  FUN(.).

Thank you for the constructive feedback!
Martin

    > On Thu, Jan 26, 2017 at 2:42 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> Last week, we've talked here about "xtabs(), factors and NAs",
    -> https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html
    >> 
    >> In the mean time, I've spent several hours on the issue
    >> and also committed changes to R-devel "in two iterations".
    >> 
    >> In the case there is a *Left* hand side part to xtabs() formula,
    >> see the help page example using 'esoph',
    >> it uses  tapply(...,  FUN = sum)   and
    >> I now think there is a missing feature in tapply() there, which
    >> I am proposing to change.
    >> 
    >> Look at a small example:
    >> 
    >>> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]),
    > N=3)[-c(1,5), ]; xtabs(~., D2)
    >> , , N = 3
    >> 
    >> L
    >> n   A B C D E F
    >> 1 1 2 0 0 0 0
    >> 2 0 0 1 2 0 0
    >> 3 0 0 0 0 2 2
    >> 
    >>> DN <- D2; DN[1,"N"] <- NA; DN
    >> n L  N
    >> 2  1 A NA
    >> 3  1 B  3
    >> 4  1 B  3
    >> 6  2 C  3
    >> 7  2 D  3
    >> 8  2 D  3
    >> 9  3 E  3
    >> 10 3 E  3
    >> 11 3 F  3
    >> 12 3 F  3
    >>> with(DN, tapply(N, list(n,L), FUN=sum))
    >> A  B  C  D  E  F
    >> 1 NA  6 NA NA NA NA
    >> 2 NA NA  3  6 NA NA
    >> 3 NA NA NA NA  6  6
    >>> 
    >> 
    >> and as you can see, the resulting matrix has NAs, all the same
    >> NA_real_, but semantically of two different kinds:
    >> 
    >> 1) at ["1", "A"], the  NA  comes from the NA in 'N'
    >> 2) all other NAs come from the fact that there is no such factor
    > combination
    >> *and* from the fact that tapply() uses
    >> 
    >> array(dim = .., dimnames = ...)
    >> 
    >> i.e., initializes the array with NAs  (see definition of 'array').
    >> 
    >> My proposition is the following patch to  tapply(), adding a new
    >> option 'init.value':
    >> 
    >> ------------------------------------------------------------
    > -----------------
    >> 
    >> -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
    >> +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify
    > = TRUE)
    >> {
    >> FUN <- if (!is.null(FUN)) match.fun(FUN)
    >> if (!is.list(INDEX)) INDEX <- list(INDEX)
    >> @@ -44,7 +44,7 @@
    >> index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
    >> ans <- lapply(X = ans[index], FUN = FUN, ...)
    >> if (simplify && all(lengths(ans) == 1L)) {
    >> -       ansmat <- array(dim = extent, dimnames = namelist)
    >> +       ansmat <- array(init.value, dim = extent, dimnames = namelist)
    >> ans <- unlist(ans, recursive = FALSE)
    >> } else {
    >> ansmat <- array(vector("list", prod(extent)),
    >> 
    >> ------------------------------------------------------------
    > -----------------
    >> 
    >> With that, I can set the initial value to '0' instead of array's
    >> default of NA :
    >> 
    >>> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
    >> A B C D E F
    >> 1 NA 6 0 0 0 0
    >> 2  0 0 3 6 0 0
    >> 3  0 0 0 0 6 6
    >>> 
    >> 
    >> which now has 0 counts and NA  as is desirable to be used inside
    >> xtabs().
    >> 
    >> All fine... and would not be worth a posting to R-devel,
    >> except for this:
    >> 
    >> The change will not be 100% back compatible -- by necessity: any new
    > argument for
    >> tapply() will make that argument name not available to be
    >> specified (via '...') for 'FUN'.  The new function would be
    >> 
    >>> str(tapply)
    >> function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
    >> 
    >> where the '...' are passed FUN(),  and with the new signature,
    >> 'init.value' then won't be passed to FUN  "anymore" (compared to
    >> R <= 3.3.x).
    >> 
    >> For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
    >> the probability the arg name is used in other functions).
    >> 
    >> 
    >> Opinions?
    >> 
    >> Thank you in advance,
    >> Martin
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel

    > [[alternative HTML version deleted]]


From florent.angly at gmail.com  Fri Jan 27 10:24:39 2017
From: florent.angly at gmail.com (Florent Angly)
Date: Fri, 27 Jan 2017 10:24:39 +0100
Subject: [Rd] Undefined behavior of head() and tail() with n = 0
In-Reply-To: <CAF8bMcbOHu=xVmcmLgrkhrfkrmTqo6wp3HH+zDaLvv6DOuyh-g@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<CAF8bMcbOHu=xVmcmLgrkhrfkrmTqo6wp3HH+zDaLvv6DOuyh-g@mail.gmail.com>
Message-ID: <CAOiMVK1_nXVddDVnhq958P=D9DZa5LT_m4YRuQuMOE_ozz2XNw@mail.gmail.com>

Martin, I agree with you that +0 and -0 should generally be treated as
equal, and R does a fine job in this respect. The Wikipedia article on
signed zero (https://en.wikipedia.org/wiki/Signed_zero) echoes this
view but also highlights that +0 and -0 can be treated differently in
particular situations, including their interpretation as mathematical
limits (as in the 1/-0 case). Indeed, the main question here is
whether head() and tail() represent a special case that would benefit
from differentiating between +0 and -0.

We can break down the discussion into two problems:
A/ the discrepancy between the implementation of R head() and tail()
and the documentation of these functions (where the use of zero is not
documented and thus not permissible),
B/ the discrepancy between the implementation of R head() and tail()
and their GNU equivalent (which allow zeros and differentiate between
-0 and +0, i.e. head takes "0" and "-0", tail takes "0" and "+0").

There are several possible solutions to address these discrepancies:

1/ Leave the code as-is but document its behavior with respect to zero
(zeros allowed, with negative zeros treated like positive zeros).
Advantages: This is the path of least resistance, and discrepancy A is fixed.
Disadvantages: Discrepancy B remains (but is documented).

2/ Leave the documentation as-is but reflect this in code by not
allowing zeros at all.
Advantages: Discrepancy A is fixed.
Disadvantages: Discrepancy B remains in some form (but is documented).
Need to deprecate the usage of +0 (which was not clearly documented
but may have been assumed by users).

3/ Update the code and documentation to differentiate between +0 and -0.
Advantages: In my eyes, this is the ideal solution since discrepancy A
and (most of) B are resolved.
Disadvantages: It is unclear how to implement this solution and the
implications it may have on backward compatibility:
   a/ Allow -0 (as double). But is it supported on all platforms used
by R (see ?Arithmetic)? William has raised the issue that negative
zero cannot be represented as an integer. Should head() and tail()
then strictly check double input (while forbidding integers)?
   b/ The input could always be as character. This would allow to
mirror even more closely GNU tail (where the prefix "+" is used to
invert the meaning of n). This probably involves a fair amount of work
and careful handling of deprecation.



On 26 January 2017 at 16:51, William Dunlap <wdunlap at tibco.com> wrote:
> In addition, signed zeroes only exist for floating point numbers - the
> bit patterns for as.integer(0) and as.integer(-0) are identical.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Jan 26, 2017 at 1:53 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>>>     on Wed, 25 Jan 2017 16:31:45 +0100 writes:
>>
>>     > Hi all,
>>     > The documentation for head() and tail() describes the behavior of
>>     > these generic functions when n is strictly positive (n > 0) and
>>     > strictly negative (n < 0). How these functions work when given a zero
>>     > value is not defined.
>>
>>     > Both GNU command-line utilities head and tail behave differently with +0 and -0:
>>     > http://man7.org/linux/man-pages/man1/head.1.html
>>     > http://man7.org/linux/man-pages/man1/tail.1.html
>>
>>     > Since R supports signed zeros (1/+0 != 1/-0)
>>
>> whoa, whoa, .. slow down --  The above is misleading!
>>
>> Rather read in  ?Arithmetic (*the* reference to consult for such issues),
>> where the 2nd part of the following section
>>
>>  || Implementation limits:
>>  ||
>>  ||      [..............]
>>  ||
>>  ||      Another potential issue is signed zeroes: on IEC 60659 platforms
>>  ||      there are two zeroes with internal representations differing by
>>  ||      sign.  Where possible R treats them as the same, but for example
>>  ||      direct output from C code often does not do so and may output
>>  ||      ?-0.0? (and on Windows whether it does so or not depends on the
>>  ||      version of Windows).  One place in R where the difference might be
>>  ||      seen is in division by zero: ?1/x? is ?Inf? or ?-Inf? depending on
>>  ||      the sign of zero ?x?.  Another place is ?identical(0, -0, num.eq =
>>  ||      FALSE)?.
>>
>> says the *contrary* ( __Where possible R treats them as the same__ ):
>> We do _not_ want to distinguish -0 and +0,
>> but there are cases where it is inavoidable
>>
>> And there are good reasons (mathematics !!) for this.
>>
>> I'm pretty sure that it would be quite a mistake to start
>> differentiating it here...  but of course we can continue
>> discussing here if you like.
>>
>> Martin Maechler
>> ETH Zurich and R Core
>>
>>
>>     > and the R head() and tail() functions are modeled after
>>     > their GNU counterparts, I would expect the R functions to
>>     > distinguish between +0 and -0
>>
>>     >> tail(1:5, n=0)
>>     > integer(0)
>>     >> tail(1:5, n=1)
>>     > [1] 5
>>     >> tail(1:5, n=2)
>>     > [1] 4 5
>>
>>     >> tail(1:5, n=-2)
>>     > [1] 3 4 5
>>     >> tail(1:5, n=-1)
>>     > [1] 2 3 4 5
>>     >> tail(1:5, n=-0)
>>     > integer(0)  # expected 1:5
>>
>>     >> head(1:5, n=0)
>>     > integer(0)
>>     >> head(1:5, n=1)
>>     > [1] 1
>>     >> head(1:5, n=2)
>>     > [1] 1 2
>>
>>     >> head(1:5, n=-2)
>>     > [1] 1 2 3
>>     >> head(1:5, n=-1)
>>     > [1] 1 2 3 4
>>     >> head(1:5, n=-0)
>>     > integer(0)  # expected 1:5
>>
>>     > For both head() and tail(), I expected 1:5 as output but got
>>     > integer(0). I obtained similar results using a data.frame and a
>>     > function as x argument.
>>
>>     > An easy fix would be to explicitly state in the documentation what n =
>>     > 0 does, and that there is no practical difference between -0 and +0.
>>     > However, in my eyes, the better approach would be implement support
>>     > for -0 and document it. What do you think?
>>
>>     > Best,
>>
>>     > Florent
>>
>>
>>     > PS/ My sessionInfo() gives:
>>     > R version 3.3.2 (2016-10-31)
>>     > Platform: x86_64-w64-mingw32/x64 (64-bit)
>>     > Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>>     > locale:
>>     > [1] LC_COLLATE=German_Switzerland.1252
>>     > LC_CTYPE=German_Switzerland.1252
>>     > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>     > LC_TIME=German_Switzerland.1252
>>
>>     > attached base packages:
>>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>     > ______________________________________________
>>     > R-devel at r-project.org mailing list
>>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Jan 27 14:55:38 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 27 Jan 2017 14:55:38 +0100
Subject: [Rd] Undefined behavior of head() and tail() with n = 0
In-Reply-To: <CAOiMVK1_nXVddDVnhq958P=D9DZa5LT_m4YRuQuMOE_ozz2XNw@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<CAF8bMcbOHu=xVmcmLgrkhrfkrmTqo6wp3HH+zDaLvv6DOuyh-g@mail.gmail.com>
	<CAOiMVK1_nXVddDVnhq958P=D9DZa5LT_m4YRuQuMOE_ozz2XNw@mail.gmail.com>
Message-ID: <22667.20826.884987.233214@stat.math.ethz.ch>

Dear Florent,

thank you for striving to clearly disentangle and present the
issue below.
That is a nice "role model" way of approaching such topics!

>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>     on Fri, 27 Jan 2017 10:24:39 +0100 writes:

    > Martin, I agree with you that +0 and -0 should generally be treated as
    > equal, and R does a fine job in this respect. The Wikipedia article on
    > signed zero (https://en.wikipedia.org/wiki/Signed_zero) echoes this
    > view but also highlights that +0 and -0 can be treated differently in
    > particular situations, including their interpretation as mathematical
    > limits (as in the 1/-0 case). Indeed, the main question here is
    > whether head() and tail() represent a special case that would benefit
    > from differentiating between +0 and -0.

    > We can break down the discussion into two problems:
    > A/ the discrepancy between the implementation of R head() and tail()
    > and the documentation of these functions (where the use of zero is not
    > documented and thus not permissible),

Ehm, no, in R (and many other software systems),

  "not documented" does *NOT* entail "not permissible"


    > B/ the discrepancy between the implementation of R head() and tail()
    > and their GNU equivalent (which allow zeros and differentiate between
    > -0 and +0, i.e. head takes "0" and "-0", tail takes "0" and "+0").

This discrepancy, as you mention later comes from the fact that
basically, these arguments are strings in the Unix tools (GNU being a
special case of Unix, here) and integers in R.

Below, I'm giving my personal view of the issue:

    > There are several possible solutions to address these discrepancies:

    > 1/ Leave the code as-is but document its behavior with respect to zero
    > (zeros allowed, with negative zeros treated like positive zeros).
    > Advantages: This is the path of least resistance, and discrepancy A is fixed.
    > Disadvantages: Discrepancy B remains (but is documented).

That would be my "clear" choice.


    > 2/ Leave the documentation as-is but reflect this in code by not
    > allowing zeros at all.
    > Advantages: Discrepancy A is fixed.
    > Disadvantages: Discrepancy B remains in some form (but is documented).
    > Need to deprecate the usage of +0 (which was not clearly documented
    > but may have been assumed by users).

2/ looks "uniformly inferior" to 1/ to me


    > 3/ Update the code and documentation to differentiate between +0 and -0.
    > Advantages: In my eyes, this is the ideal solution since discrepancy A
    > and (most of) B are resolved.
    > Disadvantages: It is unclear how to implement this solution and the
    > implications it may have on backward compatibility:
    > a/ Allow -0 (as double). But is it supported on all platforms used
    > by R (see ?Arithmetic)? William has raised the issue that negative
    > zero cannot be represented as an integer. Should head() and tail()
    > then strictly check double input (while forbidding integers)?
    > b/ The input could always be as character. This would allow to
    > mirror even more closely GNU tail (where the prefix "+" is used to
    > invert the meaning of n). This probably involves a fair amount of work
    > and careful handling of deprecation.

3/ involves quite a few complications, and in my view, your
   advantages are not even getting close to counter-weigh the drawbacks.


    > On 26 January 2017 at 16:51, William Dunlap <wdunlap at tibco.com> wrote:
    >> In addition, signed zeroes only exist for floating point numbers - the
    >> bit patterns for as.integer(0) and as.integer(-0) are identical.

indeed!

    >> Bill Dunlap
    >> TIBCO Software
    >> wdunlap tibco.com
    >> 
    >> 
    >> On Thu, Jan 26, 2017 at 1:53 AM, Martin Maechler
    >> <maechler at stat.math.ethz.ch> wrote:
    >>>>>>>> Florent Angly <florent.angly at gmail.com>
    >>>>>>>> on Wed, 25 Jan 2017 16:31:45 +0100 writes:
    >>> 
    >>> > Hi all,
    >>> > The documentation for head() and tail() describes the behavior of
    >>> > these generic functions when n is strictly positive (n > 0) and
    >>> > strictly negative (n < 0). How these functions work when given a zero
    >>> > value is not defined.
    >>> 
    >>> > Both GNU command-line utilities head and tail behave differently with +0 and -0:
    >>> > http://man7.org/linux/man-pages/man1/head.1.html
    >>> > http://man7.org/linux/man-pages/man1/tail.1.html
    >>> 
    >>> > Since R supports signed zeros (1/+0 != 1/-0)
    >>> 
    >>> whoa, whoa, .. slow down --  The above is misleading!
    >>> 
    >>> Rather read in  ?Arithmetic (*the* reference to consult for such issues),
    >>> where the 2nd part of the following section
    >>> 
    >>> || Implementation limits:
    >>> ||
    >>> ||      [..............]
    >>> ||
    >>> ||      Another potential issue is signed zeroes: on IEC 60659 platforms
    >>> ||      there are two zeroes with internal representations differing by
    >>> ||      sign.  Where possible R treats them as the same, but for example
    >>> ||      direct output from C code often does not do so and may output
    >>> ||      ?-0.0? (and on Windows whether it does so or not depends on the
    >>> ||      version of Windows).  One place in R where the difference might be
    >>> ||      seen is in division by zero: ?1/x? is ?Inf? or ?-Inf? depending on
    >>> ||      the sign of zero ?x?.  Another place is ?identical(0, -0, num.eq =
    >>> ||      FALSE)?.
    >>> 
    >>> says the *contrary* ( __Where possible R treats them as the same__ ):
    >>> We do _not_ want to distinguish -0 and +0,
    >>> but there are cases where it is inavoidable
    >>> 
    >>> And there are good reasons (mathematics !!) for this.
    >>> 
    >>> I'm pretty sure that it would be quite a mistake to start
    >>> differentiating it here...  but of course we can continue
    >>> discussing here if you like.
    >>> 
    >>> Martin Maechler
    >>> ETH Zurich and R Core
    >>> 
    >>> 
    >>> > and the R head() and tail() functions are modeled after
    >>> > their GNU counterparts, I would expect the R functions to
    >>> > distinguish between +0 and -0
    >>> 
    >>> >> tail(1:5, n=0)
    >>> > integer(0)
    >>> >> tail(1:5, n=1)
    >>> > [1] 5
    >>> >> tail(1:5, n=2)
    >>> > [1] 4 5
    >>> 
    >>> >> tail(1:5, n=-2)
    >>> > [1] 3 4 5
    >>> >> tail(1:5, n=-1)
    >>> > [1] 2 3 4 5
    >>> >> tail(1:5, n=-0)
    >>> > integer(0)  # expected 1:5
    >>> 
    >>> >> head(1:5, n=0)
    >>> > integer(0)
    >>> >> head(1:5, n=1)
    >>> > [1] 1
    >>> >> head(1:5, n=2)
    >>> > [1] 1 2
    >>> 
    >>> >> head(1:5, n=-2)
    >>> > [1] 1 2 3
    >>> >> head(1:5, n=-1)
    >>> > [1] 1 2 3 4
    >>> >> head(1:5, n=-0)
    >>> > integer(0)  # expected 1:5
    >>> 
    >>> > For both head() and tail(), I expected 1:5 as output but got
    >>> > integer(0). I obtained similar results using a data.frame and a
    >>> > function as x argument.
    >>> 
    >>> > An easy fix would be to explicitly state in the documentation what n =
    >>> > 0 does, and that there is no practical difference between -0 and +0.
    >>> > However, in my eyes, the better approach would be implement support
    >>> > for -0 and document it. What do you think?
    >>> 
    >>> > Best,
    >>> 
    >>> > Florent
    >>> 
    >>> 
    >>> > PS/ My sessionInfo() gives:
    >>> > R version 3.3.2 (2016-10-31)
    >>> > Platform: x86_64-w64-mingw32/x64 (64-bit)
    >>> > Running under: Windows 7 x64 (build 7601) Service Pack 1
    >>> 
    >>> > locale:
    >>> > [1] LC_COLLATE=German_Switzerland.1252
    >>> > LC_CTYPE=German_Switzerland.1252
    >>> > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
    >>> > LC_TIME=German_Switzerland.1252
    >>> 
    >>> > attached base packages:
    >>> > [1] stats     graphics  grDevices utils     datasets  methods   base
    >>> 
    >>> > ______________________________________________
    >>> > R-devel at r-project.org mailing list
    >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel


From danielrenato at lycos.com  Fri Jan 27 15:30:11 2017
From: danielrenato at lycos.com (danielrenato at lycos.com)
Date: Fri, 27 Jan 2017 14:30:11 +0000
Subject: [Rd] Suggestion: barplot function
Message-ID: <519488518da576043b52b5bd2c962a7a@lycos.com>

Hello developers folks!

First, congratulations for the wonderful work with R.

For science, barplots with error bars are very important. We were 
wondering that is so easy to use the boxplot function:

boxplot(Spores~treatment, col=treatment_colors)

But there is no such function for barplots with standard deviation or 
standard error. It becomes a "journey" to plot a simple graph (e.g. 
https://www.r-bloggers.com/building-barplots-with-error-bars/).

The same way that is easy to use the boxplot function, do you think it 
is possible to upgrade the barplot function: i.e.: 
barplot(Spores~treatment, error.bar=standard_error, 
col=treatment_colors)

Thank you so much!
Daniel, FU-Berlin


From ggrothendieck at gmail.com  Fri Jan 27 16:20:18 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 27 Jan 2017 10:20:18 -0500
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <22665.53907.178714.742585@stat.math.ethz.ch>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
Message-ID: <CAP01uR=awhRXnsRZW1ZNeMDMPj3x7+Pi=4v4hU5bFwVYrPokoQ@mail.gmail.com>

If xtabs is enhanced then as.data.frame.table may also need to be
modified so that it continues to be usable as an inverse, at least to
the degree feasible.


On Thu, Jan 26, 2017 at 5:42 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> Last week, we've talked here about "xtabs(), factors and NAs",
>  ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html
>
> In the mean time, I've spent several hours on the issue
> and also committed changes to R-devel "in two iterations".
>
> In the case there is a *Left* hand side part to xtabs() formula,
> see the help page example using 'esoph',
> it uses  tapply(...,  FUN = sum)   and
> I now think there is a missing feature in tapply() there, which
> I am proposing to change.
>
> Look at a small example:
>
>> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
> , , N = 3
>
>    L
> n   A B C D E F
>   1 1 2 0 0 0 0
>   2 0 0 1 2 0 0
>   3 0 0 0 0 2 2
>
>> DN <- D2; DN[1,"N"] <- NA; DN
>    n L  N
> 2  1 A NA
> 3  1 B  3
> 4  1 B  3
> 6  2 C  3
> 7  2 D  3
> 8  2 D  3
> 9  3 E  3
> 10 3 E  3
> 11 3 F  3
> 12 3 F  3
>> with(DN, tapply(N, list(n,L), FUN=sum))
>    A  B  C  D  E  F
> 1 NA  6 NA NA NA NA
> 2 NA NA  3  6 NA NA
> 3 NA NA NA NA  6  6
>>
>
> and as you can see, the resulting matrix has NAs, all the same
> NA_real_, but semantically of two different kinds:
>
> 1) at ["1", "A"], the  NA  comes from the NA in 'N'
> 2) all other NAs come from the fact that there is no such factor combination
>    *and* from the fact that tapply() uses
>
>    array(dim = .., dimnames = ...)
>
> i.e., initializes the array with NAs  (see definition of 'array').
>
> My proposition is the following patch to  tapply(), adding a new
> option 'init.value':
>
> -----------------------------------------------------------------------------
>
> -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
> +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>  {
>      FUN <- if (!is.null(FUN)) match.fun(FUN)
>      if (!is.list(INDEX)) INDEX <- list(INDEX)
> @@ -44,7 +44,7 @@
>      index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
>      ans <- lapply(X = ans[index], FUN = FUN, ...)
>      if (simplify && all(lengths(ans) == 1L)) {
> -       ansmat <- array(dim = extent, dimnames = namelist)
> +       ansmat <- array(init.value, dim = extent, dimnames = namelist)
>         ans <- unlist(ans, recursive = FALSE)
>      } else {
>         ansmat <- array(vector("list", prod(extent)),
>
> -----------------------------------------------------------------------------
>
> With that, I can set the initial value to '0' instead of array's
> default of NA :
>
>> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
>    A B C D E F
> 1 NA 6 0 0 0 0
> 2  0 0 3 6 0 0
> 3  0 0 0 0 6 6
>>
>
> which now has 0 counts and NA  as is desirable to be used inside
> xtabs().
>
> All fine... and would not be worth a posting to R-devel,
> except for this:
>
> The change will not be 100% back compatible -- by necessity: any new argument for
> tapply() will make that argument name not available to be
> specified (via '...') for 'FUN'.  The new function would be
>
>> str(tapply)
> function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>
> where the '...' are passed FUN(),  and with the new signature,
> 'init.value' then won't be passed to FUN  "anymore" (compared to
> R <= 3.3.x).
>
> For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
> the probability the arg name is used in other functions).
>
>
> Opinions?
>
> Thank you in advance,
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From marc_schwartz at me.com  Fri Jan 27 16:27:43 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 27 Jan 2017 09:27:43 -0600
Subject: [Rd] Suggestion: barplot function
In-Reply-To: <519488518da576043b52b5bd2c962a7a@lycos.com>
References: <519488518da576043b52b5bd2c962a7a@lycos.com>
Message-ID: <CA798A7B-B6C5-407B-9F1D-72CD080CE2C7@me.com>


> On Jan 27, 2017, at 8:30 AM, danielrenato at lycos.com wrote:
> 
> Hello developers folks!
> 
> First, congratulations for the wonderful work with R.
> 
> For science, barplots with error bars are very important. We were wondering that is so easy to use the boxplot function:
> 
> boxplot(Spores~treatment, col=treatment_colors)
> 
> But there is no such function for barplots with standard deviation or standard error. It becomes a "journey" to plot a simple graph (e.g. https://www.r-bloggers.com/building-barplots-with-error-bars/).
> 
> The same way that is easy to use the boxplot function, do you think it is possible to upgrade the barplot function: i.e.: barplot(Spores~treatment, error.bar=standard_error, col=treatment_colors)
> 
> Thank you so much!
> Daniel, FU-Berlin


Hi,

With the caveat that I do not speak on behalf of R Core:

Boxplots are specifically designed to include "whiskers" (NOT error bars) that aid to visually describe the distribution of continuous data. The whiskers do not represent standard deviations (SDs). Thus, that the boxplot() function contains the code to draw the whiskers automatically is not relevant to barplot().

Barplots are best used to visually present tabulations of categorical data (e.g. counts or percentages), in which case, the "error" bars would typically represent binomial or similar confidence intervals. Even there, many will advocate that dotplots be used instead as a better presentation format, as barplots, much like pie charts, have a high "ink to data" ratio.

Barplots should not really be used to present continuous data (e.g. means and SDs).

You will find a great deal of disagreement with your premise that barplots with error bars are very important to science. If you do a Google search for "Dynamite Plot", especially where only the upper error bar is included, you will find a variety of critical discussions on that point, such as:

  http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TatsukiRcode/Poster3.pdf <http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TatsukiRcode/Poster3.pdf>

You pointed to one example of how easy it is to actually add error bars to a barplot in R, and that approach, of incrementally building plots using multiple functions, is an integral part of R's philosophy. There is also an example in ?barplot.

Generally, R's default approaches to most analyses are extremely well reasoned. Thus, if you don't see something in a function by default, there is generally strong logic behind what is being done, or as in this case, not being done.

If you wanted to, it would be a reasonable exercise for you to create your own plotting function that wraps barplot() and either segments() or arrows() in a single function call, where you can pass arguments that contain the values for the various components and draw the plot as you desire. That is how a lot of R code is created.

There are other graphic functions in R packages, such as ggplot2 (https://www.r-bloggers.com/using-r-barplot-with-ggplot2/ <https://www.r-bloggers.com/using-r-barplot-with-ggplot2/>) and others on CRAN that offer methods to add error bars to barplots that others have created if you wanted to research those.

As a result of all of the above, I am not sure that, after all these years, error bars would be added to barplot() as a standard feature.

Regards,

Marc Schwartz


	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Fri Jan 27 17:36:59 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Fri, 27 Jan 2017 16:36:59 +0000 (UTC)
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
References: <1734424796.377877.1485535019296.ref@mail.yahoo.com>
Message-ID: <1734424796.377877.1485535019296@mail.yahoo.com>

The "no factor combination" case is distinguishable by 'tapply' with simplify=FALSE.

> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)
> D2 <- D2[-c(1,5), ]
> DN <- D2; DN[1,"N"] <- NA
> with(DN, tapply(N, list(n,L), FUN=sum, simplify=FALSE))
  A    B    C    D    E    F
1 NA   6    NULL NULL NULL NULL
2 NULL NULL 3    6    NULL NULL
3 NULL NULL NULL NULL 6    6


There is an old related discussion starting on https://stat.ethz.ch/pipermail/r-devel/2007-November/047338.html .

----------------------------------
Last week, we've talked here about "xtabs(), factors and NAs",
 ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html

In the mean time, I've spent several hours on the issue
and also committed changes to R-devel "in two iterations".

In the case there is a *Left* hand side part to xtabs() formula,
see the help page example using 'esoph',
it uses  tapply(...,  FUN = sum)   and
I now think there is a missing feature in tapply() there, which
I am proposing to change. 

Look at a small example:

> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
, , N = 3

   L
n   A B C D E F
  1 1 2 0 0 0 0
  2 0 0 1 2 0 0
  3 0 0 0 0 2 2

> DN <- D2; DN[1,"N"] <- NA; DN
   n L  N
2  1 A NA
3  1 B  3
4  1 B  3
6  2 C  3
7  2 D  3
8  2 D  3
9  3 E  3
10 3 E  3
11 3 F  3
12 3 F  3
> with(DN, tapply(N, list(n,L), FUN=sum))
   A  B  C  D  E  F
1 NA  6 NA NA NA NA
2 NA NA  3  6 NA NA
3 NA NA NA NA  6  6
>  

and as you can see, the resulting matrix has NAs, all the same
NA_real_, but semantically of two different kinds:

1) at ["1", "A"], the  NA  comes from the NA in 'N'
2) all other NAs come from the fact that there is no such factor combination
   *and* from the fact that tapply() uses

   array(dim = .., dimnames = ...)

i.e., initializes the array with NAs  (see definition of 'array').

My proposition is the following patch to  tapply(), adding a new
option 'init.value':

-----------------------------------------------------------------------------
 
-tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
+tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
 {
     FUN <- if (!is.null(FUN)) match.fun(FUN)
     if (!is.list(INDEX)) INDEX <- list(INDEX)
@@ -44,7 +44,7 @@
     index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
     ans <- lapply(X = ans[index], FUN = FUN, ...)
     if (simplify && all(lengths(ans) == 1L)) {
-	ansmat <- array(dim = extent, dimnames = namelist)
+	ansmat <- array(init.value, dim = extent, dimnames = namelist)
 	ans <- unlist(ans, recursive = FALSE)
     } else {
 	ansmat <- array(vector("list", prod(extent)),

-----------------------------------------------------------------------------

With that, I can set the initial value to '0' instead of array's
default of NA :

> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
   A B C D E F
1 NA 6 0 0 0 0
2  0 0 3 6 0 0
3  0 0 0 0 6 6
> 

which now has 0 counts and NA  as is desirable to be used inside
xtabs().

All fine... and would not be worth a posting to R-devel,
except for this:

The change will not be 100% back compatible -- by necessity: any new argument for
tapply() will make that argument name not available to be
specified (via '...') for 'FUN'.  The new function would be

> str(tapply)
function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)  

where the '...' are passed FUN(),  and with the new signature,
'init.value' then won't be passed to FUN  "anymore" (compared to
R <= 3.3.x).

For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
the probability the arg name is used in other functions).


Opinions?

Thank you in advance,
Martin


From suharto_anggono at yahoo.com  Fri Jan 27 17:36:59 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Fri, 27 Jan 2017 16:36:59 +0000 (UTC)
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
References: <1734424796.377877.1485535019296.ref@mail.yahoo.com>
Message-ID: <1734424796.377877.1485535019296@mail.yahoo.com>

The "no factor combination" case is distinguishable by 'tapply' with simplify=FALSE.

> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)
> D2 <- D2[-c(1,5), ]
> DN <- D2; DN[1,"N"] <- NA
> with(DN, tapply(N, list(n,L), FUN=sum, simplify=FALSE))
  A    B    C    D    E    F
1 NA   6    NULL NULL NULL NULL
2 NULL NULL 3    6    NULL NULL
3 NULL NULL NULL NULL 6    6


There is an old related discussion starting on https://stat.ethz.ch/pipermail/r-devel/2007-November/047338.html .

----------------------------------
Last week, we've talked here about "xtabs(), factors and NAs",
 ->  https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html

In the mean time, I've spent several hours on the issue
and also committed changes to R-devel "in two iterations".

In the case there is a *Left* hand side part to xtabs() formula,
see the help page example using 'esoph',
it uses  tapply(...,  FUN = sum)   and
I now think there is a missing feature in tapply() there, which
I am proposing to change. 

Look at a small example:

> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
, , N = 3

   L
n   A B C D E F
  1 1 2 0 0 0 0
  2 0 0 1 2 0 0
  3 0 0 0 0 2 2

> DN <- D2; DN[1,"N"] <- NA; DN
   n L  N
2  1 A NA
3  1 B  3
4  1 B  3
6  2 C  3
7  2 D  3
8  2 D  3
9  3 E  3
10 3 E  3
11 3 F  3
12 3 F  3
> with(DN, tapply(N, list(n,L), FUN=sum))
   A  B  C  D  E  F
1 NA  6 NA NA NA NA
2 NA NA  3  6 NA NA
3 NA NA NA NA  6  6
>  

and as you can see, the resulting matrix has NAs, all the same
NA_real_, but semantically of two different kinds:

1) at ["1", "A"], the  NA  comes from the NA in 'N'
2) all other NAs come from the fact that there is no such factor combination
   *and* from the fact that tapply() uses

   array(dim = .., dimnames = ...)

i.e., initializes the array with NAs  (see definition of 'array').

My proposition is the following patch to  tapply(), adding a new
option 'init.value':

-----------------------------------------------------------------------------
 
-tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
+tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
 {
     FUN <- if (!is.null(FUN)) match.fun(FUN)
     if (!is.list(INDEX)) INDEX <- list(INDEX)
@@ -44,7 +44,7 @@
     index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
     ans <- lapply(X = ans[index], FUN = FUN, ...)
     if (simplify && all(lengths(ans) == 1L)) {
-	ansmat <- array(dim = extent, dimnames = namelist)
+	ansmat <- array(init.value, dim = extent, dimnames = namelist)
 	ans <- unlist(ans, recursive = FALSE)
     } else {
 	ansmat <- array(vector("list", prod(extent)),

-----------------------------------------------------------------------------

With that, I can set the initial value to '0' instead of array's
default of NA :

> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
   A B C D E F
1 NA 6 0 0 0 0
2  0 0 3 6 0 0
3  0 0 0 0 6 6
> 

which now has 0 counts and NA  as is desirable to be used inside
xtabs().

All fine... and would not be worth a posting to R-devel,
except for this:

The change will not be 100% back compatible -- by necessity: any new argument for
tapply() will make that argument name not available to be
specified (via '...') for 'FUN'.  The new function would be

> str(tapply)
function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)  

where the '...' are passed FUN(),  and with the new signature,
'init.value' then won't be passed to FUN  "anymore" (compared to
R <= 3.3.x).

For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
the probability the arg name is used in other functions).


Opinions?

Thank you in advance,
Martin


From maechler at stat.math.ethz.ch  Fri Jan 27 18:01:22 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 27 Jan 2017 18:01:22 +0100
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <1734424796.377877.1485535019296@mail.yahoo.com>
References: <1734424796.377877.1485535019296.ref@mail.yahoo.com>
	<1734424796.377877.1485535019296@mail.yahoo.com>
Message-ID: <22667.31970.353800.821867@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Fri, 27 Jan 2017 16:36:59 +0000 writes:

    > The "no factor combination" case is distinguishable by 'tapply' with simplify=FALSE.
    >> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)
    >> D2 <- D2[-c(1,5), ]
    >> DN <- D2; DN[1,"N"] <- NA
    >> with(DN, tapply(N, list(n,L), FUN=sum, simplify=FALSE))
    > A    B    C    D    E    F
    > 1 NA   6    NULL NULL NULL NULL
    > 2 NULL NULL 3    6    NULL NULL
    > 3 NULL NULL NULL NULL 6    6

Yes, I know that simplify=FALSE  behaves differently, it returns
a list with dim & dimnames, sometimes also called a "list - matrix"
... and it *can* be used instead, but to be useful needs to be
post processed and that overall is somewhat inefficient and ugly.


    > There is an old related discussion starting on https://stat.ethz.ch/pipermail/r-devel/2007-November/047338.html .

Thank you, indeed, for finding that. There Andrew Robinson did
raise the same issue, but his proposed solution was not much
back compatible and I think was primarily dismissed because of that.

Martin

    > ----------------------------------
    > Last week, we've talked here about "xtabs(), factors and NAs",
    -> https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html

    > In the mean time, I've spent several hours on the issue
    > and also committed changes to R-devel "in two iterations".

    > In the case there is a *Left* hand side part to xtabs() formula,
    > see the help page example using 'esoph',
    > it uses  tapply(...,  FUN = sum)   and
    > I now think there is a missing feature in tapply() there, which
    > I am proposing to change. 

    > Look at a small example:

    >> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]), N=3)[-c(1,5), ]; xtabs(~., D2)
    > , , N = 3

    > L
    > n   A B C D E F
    > 1 1 2 0 0 0 0
    > 2 0 0 1 2 0 0
    > 3 0 0 0 0 2 2

    >> DN <- D2; DN[1,"N"] <- NA; DN
    > n L  N
    > 2  1 A NA
    > 3  1 B  3
    > 4  1 B  3
    > 6  2 C  3
    > 7  2 D  3
    > 8  2 D  3
    > 9  3 E  3
    > 10 3 E  3
    > 11 3 F  3
    > 12 3 F  3
    >> with(DN, tapply(N, list(n,L), FUN=sum))
    > A  B  C  D  E  F
    > 1 NA  6 NA NA NA NA
    > 2 NA NA  3  6 NA NA
    > 3 NA NA NA NA  6  6
    >> 

    > and as you can see, the resulting matrix has NAs, all the same
    > NA_real_, but semantically of two different kinds:

    > 1) at ["1", "A"], the  NA  comes from the NA in 'N'
    > 2) all other NAs come from the fact that there is no such factor combination
    > *and* from the fact that tapply() uses

    > array(dim = .., dimnames = ...)

    > i.e., initializes the array with NAs  (see definition of 'array').

    > My proposition is the following patch to  tapply(), adding a new
    > option 'init.value':

    > -----------------------------------------------------------------------------
 
    > -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
    > +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
    > {
    > FUN <- if (!is.null(FUN)) match.fun(FUN)
    > if (!is.list(INDEX)) INDEX <- list(INDEX)
    > @@ -44,7 +44,7 @@
    > index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
    > ans <- lapply(X = ans[index], FUN = FUN, ...)
    > if (simplify && all(lengths(ans) == 1L)) {
    > -	ansmat <- array(dim = extent, dimnames = namelist)
    > +	ansmat <- array(init.value, dim = extent, dimnames = namelist)
    > ans <- unlist(ans, recursive = FALSE)
    > } else {
    > ansmat <- array(vector("list", prod(extent)),

    > -----------------------------------------------------------------------------

    > With that, I can set the initial value to '0' instead of array's
    > default of NA :

    >> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
    > A B C D E F
    > 1 NA 6 0 0 0 0
    > 2  0 0 3 6 0 0
    > 3  0 0 0 0 6 6
    >> 

    > which now has 0 counts and NA  as is desirable to be used inside
    > xtabs().

    > All fine... and would not be worth a posting to R-devel,
    > except for this:

    > The change will not be 100% back compatible -- by necessity: any new argument for
    > tapply() will make that argument name not available to be
    > specified (via '...') for 'FUN'.  The new function would be

    >> str(tapply)
    > function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)  

    > where the '...' are passed FUN(),  and with the new signature,
    > 'init.value' then won't be passed to FUN  "anymore" (compared to
    > R <= 3.3.x).

    > For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
    > the probability the arg name is used in other functions).


    > Opinions?

    > Thank you in advance,
    > Martin

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Fri Jan 27 18:46:15 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 27 Jan 2017 09:46:15 -0800
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <22667.1537.5752.108228@stat.math.ethz.ch>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
	<CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>
	<CAFDcVCTHwE8TjE8RGRBsesQwutzsaUw4souVFW-eRi+i4rwQJw@mail.gmail.com>
	<22667.1537.5752.108228@stat.math.ethz.ch>
Message-ID: <CAFDcVCTCYn=qXHrw4pmovPbR7hjKd2+yjEmky-uMSCSDr+uqXw@mail.gmail.com>

On Fri, Jan 27, 2017 at 12:34 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
>     > On Jan 26, 2017 07:50, "William Dunlap via R-devel" <r-devel at r-project.org>
>     > wrote:
>
>     > It would be cool if the default for tapply's init.value could be
>     > FUN(X[0]), so it would be 0 for FUN=sum or FUN=length, TRUE for
>     > FUN=all, -Inf for FUN=max, etc.  But that would take time and would
>     > break code for which FUN did not work on length-0 objects.
>
>     > Bill Dunlap
>     > TIBCO Software
>     > wdunlap tibco.com
>
> I had the same idea (after my first post), so I agree that would
> be nice. One could argue it would take time only if the user is too lazy
> to specify the value,  and we could use
>    tryCatch(FUN(X[0]), error = NA)
> to safeguard against those functions that fail for 0 length arg.
>
> But I think the main reason for _not_ setting such a default is
> back-compatibility.  In my proposal, the new argument would not
> be any change by default and so all current uses of tapply()
> would remain unchanged.
>
>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>>     on Thu, 26 Jan 2017 07:57:08 -0800 writes:
>
>     > On a related note, the storage mode should try to match ans[[1]] (or
>     > unlist:ed and) when allocating 'ansmat' to avoid coercion and hence a full
>     > copy.
>
> Yes, related indeed; and would fall "in line" with Bill's idea.
> OTOH, it could be implemented independently,
> by something like
>
>    if(missing(init.value))
>      init.value <-
>        if(length(ans)) as.vector(NA, mode=storage.mode(ans[[1]]))
>        else NA

I would probably do something like:

  ans <- unlist(ans, recursive = FALSE, use.names = FALSE)
  if (length(ans)) storage.mode(init.value) <- storage.mode(ans[[1]])
  ansmat <- array(init.value, dim = extent, dimnames = namelist)

instead.  That completely avoids having to use missing() and the value
of 'init.value' will be coerced later if not done upfront.  use.names
= FALSE speeds up unlist().

/Henrik

>
> .............
>
> A colleague proposed to use the shorter argument name 'default'
> instead of 'init.value'  which indeed maybe more natural and
> still not too often used as "non-first" argument in  FUN(.).
>
> Thank you for the constructive feedback!
> Martin
>
>     > On Thu, Jan 26, 2017 at 2:42 AM, Martin Maechler
>     > <maechler at stat.math.ethz.ch> wrote:
>     >> Last week, we've talked here about "xtabs(), factors and NAs",
>     -> https://stat.ethz.ch/pipermail/r-devel/2017-January/073621.html
>     >>
>     >> In the mean time, I've spent several hours on the issue
>     >> and also committed changes to R-devel "in two iterations".
>     >>
>     >> In the case there is a *Left* hand side part to xtabs() formula,
>     >> see the help page example using 'esoph',
>     >> it uses  tapply(...,  FUN = sum)   and
>     >> I now think there is a missing feature in tapply() there, which
>     >> I am proposing to change.
>     >>
>     >> Look at a small example:
>     >>
>     >>> D2 <- data.frame(n = gl(3,4), L = gl(6,2, labels=LETTERS[1:6]),
>     > N=3)[-c(1,5), ]; xtabs(~., D2)
>     >> , , N = 3
>     >>
>     >> L
>     >> n   A B C D E F
>     >> 1 1 2 0 0 0 0
>     >> 2 0 0 1 2 0 0
>     >> 3 0 0 0 0 2 2
>     >>
>     >>> DN <- D2; DN[1,"N"] <- NA; DN
>     >> n L  N
>     >> 2  1 A NA
>     >> 3  1 B  3
>     >> 4  1 B  3
>     >> 6  2 C  3
>     >> 7  2 D  3
>     >> 8  2 D  3
>     >> 9  3 E  3
>     >> 10 3 E  3
>     >> 11 3 F  3
>     >> 12 3 F  3
>     >>> with(DN, tapply(N, list(n,L), FUN=sum))
>     >> A  B  C  D  E  F
>     >> 1 NA  6 NA NA NA NA
>     >> 2 NA NA  3  6 NA NA
>     >> 3 NA NA NA NA  6  6
>     >>>
>     >>
>     >> and as you can see, the resulting matrix has NAs, all the same
>     >> NA_real_, but semantically of two different kinds:
>     >>
>     >> 1) at ["1", "A"], the  NA  comes from the NA in 'N'
>     >> 2) all other NAs come from the fact that there is no such factor
>     > combination
>     >> *and* from the fact that tapply() uses
>     >>
>     >> array(dim = .., dimnames = ...)
>     >>
>     >> i.e., initializes the array with NAs  (see definition of 'array').
>     >>
>     >> My proposition is the following patch to  tapply(), adding a new
>     >> option 'init.value':
>     >>
>     >> ------------------------------------------------------------
>     > -----------------
>     >>
>     >> -tapply <- function (X, INDEX, FUN = NULL, ..., simplify = TRUE)
>     >> +tapply <- function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify
>     > = TRUE)
>     >> {
>     >> FUN <- if (!is.null(FUN)) match.fun(FUN)
>     >> if (!is.list(INDEX)) INDEX <- list(INDEX)
>     >> @@ -44,7 +44,7 @@
>     >> index <- as.logical(lengths(ans))  # equivalently, lengths(ans) > 0L
>     >> ans <- lapply(X = ans[index], FUN = FUN, ...)
>     >> if (simplify && all(lengths(ans) == 1L)) {
>     >> -       ansmat <- array(dim = extent, dimnames = namelist)
>     >> +       ansmat <- array(init.value, dim = extent, dimnames = namelist)
>     >> ans <- unlist(ans, recursive = FALSE)
>     >> } else {
>     >> ansmat <- array(vector("list", prod(extent)),
>     >>
>     >> ------------------------------------------------------------
>     > -----------------
>     >>
>     >> With that, I can set the initial value to '0' instead of array's
>     >> default of NA :
>     >>
>     >>> with(DN, tapply(N, list(n,L), FUN=sum, init.value=0))
>     >> A B C D E F
>     >> 1 NA 6 0 0 0 0
>     >> 2  0 0 3 6 0 0
>     >> 3  0 0 0 0 6 6
>     >>>
>     >>
>     >> which now has 0 counts and NA  as is desirable to be used inside
>     >> xtabs().
>     >>
>     >> All fine... and would not be worth a posting to R-devel,
>     >> except for this:
>     >>
>     >> The change will not be 100% back compatible -- by necessity: any new
>     > argument for
>     >> tapply() will make that argument name not available to be
>     >> specified (via '...') for 'FUN'.  The new function would be
>     >>
>     >>> str(tapply)
>     >> function (X, INDEX, FUN = NULL, ..., init.value = NA, simplify = TRUE)
>     >>
>     >> where the '...' are passed FUN(),  and with the new signature,
>     >> 'init.value' then won't be passed to FUN  "anymore" (compared to
>     >> R <= 3.3.x).
>     >>
>     >> For that reason, we could use   'INIT.VALUE' instead (possibly decreasing
>     >> the probability the arg name is used in other functions).
>     >>
>     >>
>     >> Opinions?
>     >>
>     >> Thank you in advance,
>     >> Martin
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>     > [[alternative HTML version deleted]]
>


From zhengda1936 at gmail.com  Fri Jan 27 22:28:43 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Fri, 27 Jan 2017 16:28:43 -0500
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
Message-ID: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>

Hello,

I'm trying to submit my package to CRAN. When I read the policy, it says:
Package authors should make all reasonable efforts to provide
cross-platform portable code. Packages will not normally be accepted
that do not run on at least two of the major R platforms.

What major R platforms does this policy refer to?
Currently, my package runs in Ubuntu. If it works on both Ubuntu and
Redhat, does it count as two platforms?

Thanks,
Da


From murdoch.duncan at gmail.com  Fri Jan 27 22:36:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2017 16:36:42 -0500
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
Message-ID: <6e69496c-dba4-36d3-af20-7d9c99cb06a5@gmail.com>

On 27/01/2017 4:28 PM, Da Zheng wrote:
> Hello,
>
> I'm trying to submit my package to CRAN. When I read the policy, it says:
> Package authors should make all reasonable efforts to provide
> cross-platform portable code. Packages will not normally be accepted
> that do not run on at least two of the major R platforms.
>
> What major R platforms does this policy refer to?
> Currently, my package runs in Ubuntu. If it works on both Ubuntu and
> Redhat, does it count as two platforms?

No, those are both Linux.  Try to get it to run on Windows and Mac OS as 
well (and if possible, Solaris).

If you don't have access to Windows, submit it to
win-builder.r-project.org for testing.  Mac OS and Solaris are currently 
harder to test without setting up your own local systems.  Maybe someone 
else will report on available test systems for those platforms.

Duncan Murdoch


From marc_schwartz at me.com  Fri Jan 27 22:39:51 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 27 Jan 2017 15:39:51 -0600
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
Message-ID: <D2E02308-90D3-441C-BEE5-2CEAB9F44F11@me.com>


> On Jan 27, 2017, at 3:28 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> 
> Hello,
> 
> I'm trying to submit my package to CRAN. When I read the policy, it says:
> Package authors should make all reasonable efforts to provide
> cross-platform portable code. Packages will not normally be accepted
> that do not run on at least two of the major R platforms.
> 
> What major R platforms does this policy refer to?
> Currently, my package runs in Ubuntu. If it works on both Ubuntu and
> Redhat, does it count as two platforms?
> 
> Thanks,
> Da


Hi,

A couple of comments:

1. For future reference, this query would have been better sent to R-Package-Devel, which is focused on this topic:

  https://stat.ethz.ch/mailman/listinfo/r-package-devel


2. "Major platforms" would typically refer to Linux, Windows and macOS. So Ubuntu and RH would be within Linux as a single platform.


Regards,

Marc Schwartz
 

From csardi.gabor at gmail.com  Fri Jan 27 22:54:19 2017
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 27 Jan 2017 21:54:19 +0000
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
Message-ID: <CABtg=Knrrc5Pv6nc=mQaefafo_Q1dvgTQViTo+M0mhd1qKanFA@mail.gmail.com>

On Fri, Jan 27, 2017 at 9:28 PM, Da Zheng <zhengda1936 at gmail.com> wrote:

> Hello,
>
> I'm trying to submit my package to CRAN. When I read the policy, it says:
> Package authors should make all reasonable efforts to provide
> cross-platform portable code. Packages will not normally be accepted
> that do not run on at least two of the major R platforms.
>
> What major R platforms does this policy refer to?
>

Linux, macOS, Windows.


> Currently, my package runs in Ubuntu. If it works on both Ubuntu and
> Redhat, does it count as two platforms?
>

I think that Linux is just one. Is it hard to make it work on macOS?

I am not saying that if it is Linux-only then it definitely cannot make it
to CRAN.
A CRAN maintainer will decide that.

Gabor


>
> Thanks,
> Da
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Jan 27 23:17:07 2017
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Jan 2017 16:17:07 -0600
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <CABtg=Knrrc5Pv6nc=mQaefafo_Q1dvgTQViTo+M0mhd1qKanFA@mail.gmail.com>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
	<CABtg=Knrrc5Pv6nc=mQaefafo_Q1dvgTQViTo+M0mhd1qKanFA@mail.gmail.com>
Message-ID: <22667.50915.347144.956573@max.nulle.part>


On 27 January 2017 at 21:54, G?bor Cs?rdi wrote:
| On Fri, Jan 27, 2017 at 9:28 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
| > What major R platforms does this policy refer to?
| >
| 
| Linux, macOS, Windows.
| 
| 
| > Currently, my package runs in Ubuntu. If it works on both Ubuntu and
| > Redhat, does it count as two platforms?
| >
| 
| I think that Linux is just one. Is it hard to make it work on macOS?
| 
| I am not saying that if it is Linux-only then it definitely cannot make it
| to CRAN.
| A CRAN maintainer will decide that.

Gabor is *way* too modest here to not mention the *fabulous* tool he has
written (with the [financial] support of the R Consortium):  R Hub.

These days I just do    'rhub::check_for_cran()'   and four tests launch
covering the three required OSs as well as the required r-devel and r-release
versions.  Results tickle in within minutes by mail; the windows one (which
is slowest) is also display.  You need a one-time token handshake.

I strongly recommend the service.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From henrik.bengtsson at gmail.com  Fri Jan 27 23:40:33 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 27 Jan 2017 14:40:33 -0800
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <22667.50915.347144.956573@max.nulle.part>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
	<CABtg=Knrrc5Pv6nc=mQaefafo_Q1dvgTQViTo+M0mhd1qKanFA@mail.gmail.com>
	<22667.50915.347144.956573@max.nulle.part>
Message-ID: <CAFDcVCRYgNMmwNSx25DUaxBS=NDYKsWbLNd=vkRWa6vSajCWPA@mail.gmail.com>

Second this.  As the CRAN Policies suggests, there's also the very
handy winbuilder service (https://win-builder.r-project.org/) you can
use to check your package on Windows.  This service has been a
valuable workhorse for years.

We should also mention the continuous integration (CI) services
provided for free by Travis (Linux and macOS) and AppVeyor (Windows)
in combination with GitHub (or GitLab, ...).  By adding simple
.travis.yml and appveyor.yml to your Git repos (e.g.
https://github.com/HenrikBengtsson/globals), they run R CMD check
--as-cran and covr::package_coverage() etc for you more or less on the
fly, e.g.

* https://travis-ci.org/HenrikBengtsson/globals
* https://ci.appveyor.com/project/HenrikBengtsson/globals

/Henrik

PS. Thanks to everyone who made all of the above possible.

On Fri, Jan 27, 2017 at 2:17 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 27 January 2017 at 21:54, G?bor Cs?rdi wrote:
> | On Fri, Jan 27, 2017 at 9:28 PM, Da Zheng <zhengda1936 at gmail.com> wrote:
> | > What major R platforms does this policy refer to?
> | >
> |
> | Linux, macOS, Windows.
> |
> |
> | > Currently, my package runs in Ubuntu. If it works on both Ubuntu and
> | > Redhat, does it count as two platforms?
> | >
> |
> | I think that Linux is just one. Is it hard to make it work on macOS?
> |
> | I am not saying that if it is Linux-only then it definitely cannot make it
> | to CRAN.
> | A CRAN maintainer will decide that.
>
> Gabor is *way* too modest here to not mention the *fabulous* tool he has
> written (with the [financial] support of the R Consortium):  R Hub.
>
> These days I just do    'rhub::check_for_cran()'   and four tests launch
> covering the three required OSs as well as the required r-devel and r-release
> versions.  Results tickle in within minutes by mail; the windows one (which
> is slowest) is also display.  You need a one-time token handshake.
>
> I strongly recommend the service.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rmcgehee at walleyetrading.net  Fri Jan 27 23:41:10 2017
From: rmcgehee at walleyetrading.net (Robert McGehee)
Date: Fri, 27 Jan 2017 22:41:10 +0000
Subject: [Rd] Matrix package breaks as.matrix method
Message-ID: <30D28A63376088428E8318DD67FD407F705B2E@ny-mailstore1.walleyetrading.net>

Hi,
The Matrix package and the as.matrix method do not seem to be compatible inside of a package.

Here's an example. I've created a simple package "mat" that defines an eponymous class and as.matrix method on that class. All is well, unless that package has the Matrix package in its Depends or Imports (and imports, e.g. the "Diagonal" function). Then my as.matrix method stops working, even if I'm not using any part of the Matrix package.

Here's an example on R 3.3.2:

First, create an empty package "mat" (e.g. with package.skeleton) with one file in mat/R/mat.R with the following contents:

setClass("mat", representation(H="matrix"))
mat <- function(H) new("mat", H=H)
setMethod("as.matrix", signature("mat"), function(x, ...) crossprod(x at H))
testmat <- function() {
    H <- matrix(1:3, 1, 3)
    M <- mat(H)
    as.matrix(M)
}

Then install the mat package :
> require(mat)
> testmat()
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    4    6
[3,]    3    6    9

All works fine!

Now add "Depends: Matrix" into the package's DESCRIPTION file (alternatively add "Imports: Matrix" and 'importFrom("Matrix","Diagonal")' in the NAMESPACE).

Try again:
> require(mat)
> testmat()
Error in as.vector(data) : 
  no method for coercing this S4 class to a vector

Bug? If not, can anyone provide a work around? In my case, I'd like to mix matrix and Matrix functions in my package, but am obviously having difficulty.

I've come across a somewhat similar report on stackoverflow http://stackoverflow.com/questions/13812373/overloading-operator-in-r-s4-classes-and-matrix-package regarding defining the "+" operator with the Matrix package, but I don't think the solution or the problem quite applies.

Thanks in advance, Robert

> R.version
               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          3.2                         
year           2016                        
month          10                          
day            31                          
svn rev        71607                       
language       R                           
version.string R version 3.3.2 (2016-10-31)
nickname       Sincere Pumpkin Patch       


From henrik.bengtsson at gmail.com  Sat Jan 28 03:52:33 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 27 Jan 2017 18:52:33 -0800
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN
Message-ID: <CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA@mail.gmail.com>

Continuing the tradition to post millennia milestones on CRAN:

So, it happened. Today (January 27, 2017 PCT) CRAN reached 10,000 packages [1].

Needless to say, the rate with which new packages are added to CRAN
keeps increasing and so does the number of contributors (maintainers).
Somewhere out there, there are ~3 persons who are about to submit
their first packages to CRAN today and ~3 persons who will submit
another package of theirs. And by the amazing work of the CRAN team,
these packages are inspected and quality controlled before going live
- which often happens within a day or so.

As usual and it can't be said too many times: A big thank you to the
CRAN team, to the R core, to all package developers, to our friendly
community, to everyone out there helping others, and to various online
services that simplify package development. We can all give back by
carefully reporting bugs to the maintainers, properly citing packages
we use in publications (see citation("pkg")), and help newcomers to
use R.


Milestones:

2017-01-27 10000 pkgs (+6.3/day over 158 days) 5845 mnts (+3.5/day)
2016-08-22 9000 pkgs (+5.7/day over 175 days) 5289 mnts (+5.8/day)
2016-02-29 8000 pkgs (+5.0/day over 201 days) 4279 mnts (+0.7/day)
2015-08-12 7000 pkgs (+3.4/day over 287 days) 4130 mnts (+2.4/day)
2014-10-29 6000 pkgs (+3.0/day over 335 days) 3444 mnts (+1.6/day)
2013-11-08 5000 pkgs (+2.7/day over 442 days) 2900 mnts (+1.2/day)
2012-08-23 4000 pkgs (+2.1/day over 469 days) 2350 mnts
2011-05-12 3000 pkgs (+1.7/day over 585 days)
2009-10-04 2000 pkgs (+1.1/day over 906 days)
2007-04-12 1000 pkgs
2004-10-01 500 pkgs
2003-04-01 250 pkgs
2002-09-17 68 pkgs
1997-04-23 12 pkgs

These data are for CRAN only [1-13]. There are many more packages
elsewhere, e.g. Bioconductor, GitHub, R-Forge etc.

[1] http://cran.r-project.org/web/packages/
[2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
[3] http://www.r-pkg.org/
[4] Private data
[5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
[6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
[7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
[8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
[9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
[10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
[11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
[12] https://stat.ethz.ch/pipermail/r-devel/2016-February/072388.html
[13] https://stat.ethz.ch/pipermail/r-devel/2016-August/073011.html

All the best,

Henrik
(just a user)


From ravi.varadhan at jhu.edu  Sat Jan 28 15:17:41 2017
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 28 Jan 2017 14:17:41 +0000
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN
In-Reply-To: <CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA@mail.gmail.com>
References: <CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA@mail.gmail.com>
Message-ID: <1485613040439.81624@jhu.edu>

Amazing!  

I join Henrik in expressing my humble gratitude to all the R and CRAN gurus like Brian Ripley, Duncan Murdoch, Luke Tierney, Martin Maechler, Uwe Ligges, Kurt Hornik, Peter Dalgaard, Simon Urbanek, and many others.  

Thank you & Best regards,
Ravi
________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Henrik Bengtsson <henrik.bengtsson at gmail.com>
Sent: Friday, January 27, 2017 9:52 PM
To: R-devel
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN

Continuing the tradition to post millennia milestones on CRAN:

So, it happened. Today (January 27, 2017 PCT) CRAN reached 10,000 packages [1].

Needless to say, the rate with which new packages are added to CRAN
keeps increasing and so does the number of contributors (maintainers).
Somewhere out there, there are ~3 persons who are about to submit
their first packages to CRAN today and ~3 persons who will submit
another package of theirs. And by the amazing work of the CRAN team,
these packages are inspected and quality controlled before going live
- which often happens within a day or so.

As usual and it can't be said too many times: A big thank you to the
CRAN team, to the R core, to all package developers, to our friendly
community, to everyone out there helping others, and to various online
services that simplify package development. We can all give back by
carefully reporting bugs to the maintainers, properly citing packages
we use in publications (see citation("pkg")), and help newcomers to
use R.


Milestones:

2017-01-27 10000 pkgs (+6.3/day over 158 days) 5845 mnts (+3.5/day)
2016-08-22 9000 pkgs (+5.7/day over 175 days) 5289 mnts (+5.8/day)
2016-02-29 8000 pkgs (+5.0/day over 201 days) 4279 mnts (+0.7/day)
2015-08-12 7000 pkgs (+3.4/day over 287 days) 4130 mnts (+2.4/day)
2014-10-29 6000 pkgs (+3.0/day over 335 days) 3444 mnts (+1.6/day)
2013-11-08 5000 pkgs (+2.7/day over 442 days) 2900 mnts (+1.2/day)
2012-08-23 4000 pkgs (+2.1/day over 469 days) 2350 mnts
2011-05-12 3000 pkgs (+1.7/day over 585 days)
2009-10-04 2000 pkgs (+1.1/day over 906 days)
2007-04-12 1000 pkgs
2004-10-01 500 pkgs
2003-04-01 250 pkgs
2002-09-17 68 pkgs
1997-04-23 12 pkgs

These data are for CRAN only [1-13]. There are many more packages
elsewhere, e.g. Bioconductor, GitHub, R-Forge etc.

[1] http://cran.r-project.org/web/packages/
[2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
[3] http://www.r-pkg.org/
[4] Private data
[5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
[6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
[7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
[8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
[9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
[10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
[11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
[12] https://stat.ethz.ch/pipermail/r-devel/2016-February/072388.html
[13] https://stat.ethz.ch/pipermail/r-devel/2016-August/073011.html

All the best,

Henrik
(just a user)

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Jan 28 16:55:35 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 Jan 2017 16:55:35 +0100
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <CAFDcVCTCYn=qXHrw4pmovPbR7hjKd2+yjEmky-uMSCSDr+uqXw@mail.gmail.com>
References: <CAOiMVK1mhMHyBk0Bf1+z1W6aKE3FDeF_oRFAO+ccdDktwEUgNg@mail.gmail.com>
	<22665.50985.353259.677262@stat.math.ethz.ch>
	<22665.53907.178714.742585@stat.math.ethz.ch>
	<CAF8bMcb-+D-hmoKYrtLmjXXh_5BUNg2DHVS99BgvZ_fgU7W0yw@mail.gmail.com>
	<CAFDcVCTHwE8TjE8RGRBsesQwutzsaUw4souVFW-eRi+i4rwQJw@mail.gmail.com>
	<22667.1537.5752.108228@stat.math.ethz.ch>
	<CAFDcVCTCYn=qXHrw4pmovPbR7hjKd2+yjEmky-uMSCSDr+uqXw@mail.gmail.com>
Message-ID: <22668.48887.93419.698242@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Fri, 27 Jan 2017 09:46:15 -0800 writes:

    > On Fri, Jan 27, 2017 at 12:34 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> > On Jan 26, 2017 07:50, "William Dunlap via R-devel"
    >> <r-devel at r-project.org> > wrote:
    >> 
    >> > It would be cool if the default for tapply's init.value
    >> could be > FUN(X[0]), so it would be 0 for FUN=sum or
    >> FUN=length, TRUE for > FUN=all, -Inf for FUN=max, etc.
    >> But that would take time and would > break code for which
    >> FUN did not work on length-0 objects.
    >> 
    >> > Bill Dunlap > TIBCO Software > wdunlap tibco.com
    >> 
    >> I had the same idea (after my first post), so I agree
    >> that would be nice. One could argue it would take time
    >> only if the user is too lazy to specify the value, and we
    >> could use tryCatch(FUN(X[0]), error = NA) to safeguard
    >> against those functions that fail for 0 length arg.
    >> 
    >> But I think the main reason for _not_ setting such a
    >> default is back-compatibility.  In my proposal, the new
    >> argument would not be any change by default and so all
    >> current uses of tapply() would remain unchanged.
    >> 
    >>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> on
    >>>>>>> Thu, 26 Jan 2017 07:57:08 -0800 writes:
    >> 
    >> > On a related note, the storage mode should try to match
    >> ans[[1]] (or > unlist:ed and) when allocating 'ansmat' to
    >> avoid coercion and hence a full > copy.
    >> 
    >> Yes, related indeed; and would fall "in line" with Bill's
    >> idea.  OTOH, it could be implemented independently, by
    >> something like
    >> 
    >> if(missing(init.value)) init.value <- if(length(ans))
    >> as.vector(NA, mode=storage.mode(ans[[1]])) else NA

> I would probably do something like:

>   ans <- unlist(ans, recursive = FALSE, use.names = FALSE)
>   if (length(ans)) storage.mode(init.value) <- storage.mode(ans[[1]])
>   ansmat <- array(init.value, dim = extent, dimnames = namelist)

> instead.  That completely avoids having to use missing() and the value
> of 'init.value' will be coerced later if not done upfront.  use.names
> = FALSE speeds up unlist().

Thank you, Henrik.
That's a good idea to do the unlist() first, and with 'use.names=FALSE'.
I'll copy that.

On the other hand, "brutally" modifying  'init.value' (now called 'default')
even when the user has specified it is not acceptable I think.
You are right that it would be coerced anyway subsequently, but
the coercion will happen in whatever method of  `[<-` will be
appropriate.
Good S3 and S4 programmers will write such methods for their classes.

For that reason, I'm even more conservative now, only fiddle in
case of an atomic 'ans' and make use of the corresponding '['
method rather than as.vector(.) ... because that will fulfill
the following new regression test {not fulfilled in current R}:

identical(tapply(1:3, 1:3, as.raw),
	  array(as.raw(1:3), 3L, dimnames=list(1:3)))

Also, I've done a few more things -- treating if(.) . else . as a
function call, etc  and now committed as  rev 72040  to
R-devel... really wanting to get this out.

We can bet if there will be ripples in (visible) package space,
I give it relatively high chance for no ripples (and much higher
chance for problems with the more aggressive proposal..)

Thank you again, for your "thinking along" and constructive
suggestions.

Martin


From zhengda1936 at gmail.com  Sat Jan 28 21:53:28 2017
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sat, 28 Jan 2017 15:53:28 -0500
Subject: [Rd] cross-platform portable code in CRAN Repository Policy
In-Reply-To: <CAFDcVCRYgNMmwNSx25DUaxBS=NDYKsWbLNd=vkRWa6vSajCWPA@mail.gmail.com>
References: <CAFLer82+NGwcc6mCnr18QmkLrO_td03jiKyyMZaEeJtDbBh8tw@mail.gmail.com>
	<CABtg=Knrrc5Pv6nc=mQaefafo_Q1dvgTQViTo+M0mhd1qKanFA@mail.gmail.com>
	<22667.50915.347144.956573@max.nulle.part>
	<CAFDcVCRYgNMmwNSx25DUaxBS=NDYKsWbLNd=vkRWa6vSajCWPA@mail.gmail.com>
Message-ID: <CAFLer834YWoY94eeHHuhqyo_L=WfHyaCweYVxEUUAQ1HTS0oAA@mail.gmail.com>

Thank you very much for all your responses. It's very clear to me what I
need to do and what service I should use for testing now.

Thanks,
Da

On Fri, Jan 27, 2017 at 5:40 PM, Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Second this.  As the CRAN Policies suggests, there's also the very
> handy winbuilder service (https://win-builder.r-project.org/) you can
> use to check your package on Windows.  This service has been a
> valuable workhorse for years.
>
> We should also mention the continuous integration (CI) services
> provided for free by Travis (Linux and macOS) and AppVeyor (Windows)
> in combination with GitHub (or GitLab, ...).  By adding simple
> .travis.yml and appveyor.yml to your Git repos (e.g.
> https://github.com/HenrikBengtsson/globals), they run R CMD check
> --as-cran and covr::package_coverage() etc for you more or less on the
> fly, e.g.
>
> * https://travis-ci.org/HenrikBengtsson/globals
> * https://ci.appveyor.com/project/HenrikBengtsson/globals
>
> /Henrik
>
> PS. Thanks to everyone who made all of the above possible.
>
> On Fri, Jan 27, 2017 at 2:17 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> > On 27 January 2017 at 21:54, G?bor Cs?rdi wrote:
> > | On Fri, Jan 27, 2017 at 9:28 PM, Da Zheng <zhengda1936 at gmail.com>
> wrote:
> > | > What major R platforms does this policy refer to?
> > | >
> > |
> > | Linux, macOS, Windows.
> > |
> > |
> > | > Currently, my package runs in Ubuntu. If it works on both Ubuntu and
> > | > Redhat, does it count as two platforms?
> > | >
> > |
> > | I think that Linux is just one. Is it hard to make it work on macOS?
> > |
> > | I am not saying that if it is Linux-only then it definitely cannot
> make it
> > | to CRAN.
> > | A CRAN maintainer will decide that.
> >
> > Gabor is *way* too modest here to not mention the *fabulous* tool he has
> > written (with the [financial] support of the R Consortium):  R Hub.
> >
> > These days I just do    'rhub::check_for_cran()'   and four tests launch
> > covering the three required OSs as well as the required r-devel and
> r-release
> > versions.  Results tickle in within minutes by mail; the windows one
> (which
> > is slowest) is also display.  You need a one-time token handshake.
> >
> > I strongly recommend the service.
> >
> > Dirk
> >
> > --
> > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sun Jan 29 10:42:57 2017
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Jan 2017 09:42:57 +0000
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN
In-Reply-To: <CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA@mail.gmail.com>
References: <CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA@mail.gmail.com>
Message-ID: <641979f7-ab6d-f932-f570-ef69a9c50dba@stats.ox.ac.uk>

On 28/01/2017 02:52, Henrik Bengtsson wrote:
> Continuing the tradition to post millennia milestones on CRAN:
>
> So, it happened. Today (January 27, 2017 PCT) CRAN reached 10,000 packages [1].

I predicted (rather tongue-in-check) at UseR! 2011 that we would have 
this 'for Christmas 2016', at a time when there were 3200 CRAN packages. 
  My expectation was to be much farther off ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From georgi.boshnakov at manchester.ac.uk  Sun Jan 29 19:39:41 2017
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Sun, 29 Jan 2017 18:39:41 +0000
Subject: [Rd] R-devel Digest, Vol 167, Issue 25
In-Reply-To: <mailman.23.1485601202.7001.r-devel@r-project.org>
References: <mailman.23.1485601202.7001.r-devel@r-project.org>
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018B01FAA3@MBXP01.ds.man.ac.uk>

Hi,

Short answer: import 'as.matrix'  and export your method(s) for it. From WRE:

"All S4 classes to be used outside the package need to be listed in an exportClasses directive. Alternatively, they can be specified using exportClassPattern.(46) in the same style as for exportPattern. To export methods for generics from other packages an exportMethods directive can be used."

Details: the precise details depend on what exactly is in your NAMESPACE file. 
The curious difference you observe is due to the fact that as.matrix is defined in 'base' as S3 generic.  
When you set an S4 method for it you effectively create your own as.matrix S4 generic and your settings in NAMESPACE probably export everything you "own".

When you depend on package 'Matrix',  'as.matrix' is made S4 generic by it and you are defining a method for 
An imported function, so you need to use exportMethods (see the above excerpt), otherwise your method is not exported. (Indeed, in your example the arror is from array() in the default method).

Note also that it matters where you define the test function. I am pretty sure that you defined it in the global workspace (not in the package) to get the error.

It is very useful practice to run 'R CMD check' (or its devtools equivalent). In this case it would have warned you to import as.matrix. Also, to make your life easier during initial development, import the whole 'Matrix' and when things work think about cleaning up and importing only stuff that you need.

 
Best regards,
Georgi Boshnakov

------------------------------

Message: 15
Date: Fri, 27 Jan 2017 22:41:10 +0000
From: Robert McGehee <rmcgehee at walleyetrading.net>
To: "r-devel at r-project.org" <r-devel at r-project.org>
Subject: [Rd] Matrix package breaks as.matrix method
Message-ID:
	<30D28A63376088428E8318DD67FD407F705B2E at ny-mailstore1.walleyetrading.net>
	
Content-Type: text/plain; charset="us-ascii"

Hi,
The Matrix package and the as.matrix method do not seem to be compatible inside of a package.

Here's an example. I've created a simple package "mat" that defines an eponymous class and as.matrix method on that class. All is well, unless that package has the Matrix package in its Depends or Imports (and imports, e.g. the "Diagonal" function). Then my as.matrix method stops working, even if I'm not using any part of the Matrix package.

Here's an example on R 3.3.2:

First, create an empty package "mat" (e.g. with package.skeleton) with one file in mat/R/mat.R with the following contents:

setClass("mat", representation(H="matrix"))
mat <- function(H) new("mat", H=H)
setMethod("as.matrix", signature("mat"), function(x, ...) crossprod(x at H))
testmat <- function() {
    H <- matrix(1:3, 1, 3)
    M <- mat(H)
    as.matrix(M)
}

Then install the mat package :
> require(mat)
> testmat()
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    4    6
[3,]    3    6    9

All works fine!

Now add "Depends: Matrix" into the package's DESCRIPTION file (alternatively add "Imports: Matrix" and 'importFrom("Matrix","Diagonal")' in the NAMESPACE).

Try again:
> require(mat)
> testmat()
Error in as.vector(data) : 
  no method for coercing this S4 class to a vector

Bug? If not, can anyone provide a work around? In my case, I'd like to mix matrix and Matrix functions in my package, but am obviously having difficulty.

I've come across a somewhat similar report on stackoverflow http://stackoverflow.com/questions/13812373/overloading-operator-in-r-s4-classes-and-matrix-package regarding defining the "+" operator with the Matrix package, but I don't think the solution or the problem quite applies.

Thanks in advance, Robert

> R.version
               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          3.2                         
year           2016                        
month          10                          
day            31                          
svn rev        71607                       
language       R                           
version.string R version 3.3.2 (2016-10-31)
nickname       Sincere Pumpkin Patch       



------------------------------

Message: 16
Date: Fri, 27 Jan 2017 18:52:33 -0800
From: Henrik Bengtsson <henrik.bengtsson at gmail.com>
To: R-devel <r-devel at r-project.org>
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN
Message-ID:
	<CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Continuing the tradition to post millennia milestones on CRAN:

So, it happened. Today (January 27, 2017 PCT) CRAN reached 10,000 packages [1].

Needless to say, the rate with which new packages are added to CRAN
keeps increasing and so does the number of contributors (maintainers).
Somewhere out there, there are ~3 persons who are about to submit
their first packages to CRAN today and ~3 persons who will submit
another package of theirs. And by the amazing work of the CRAN team,
these packages are inspected and quality controlled before going live
- which often happens within a day or so.

As usual and it can't be said too many times: A big thank you to the
CRAN team, to the R core, to all package developers, to our friendly
community, to everyone out there helping others, and to various online
services that simplify package development. We can all give back by
carefully reporting bugs to the maintainers, properly citing packages
we use in publications (see citation("pkg")), and help newcomers to
use R.


Milestones:

2017-01-27 10000 pkgs (+6.3/day over 158 days) 5845 mnts (+3.5/day)
2016-08-22 9000 pkgs (+5.7/day over 175 days) 5289 mnts (+5.8/day)
2016-02-29 8000 pkgs (+5.0/day over 201 days) 4279 mnts (+0.7/day)
2015-08-12 7000 pkgs (+3.4/day over 287 days) 4130 mnts (+2.4/day)
2014-10-29 6000 pkgs (+3.0/day over 335 days) 3444 mnts (+1.6/day)
2013-11-08 5000 pkgs (+2.7/day over 442 days) 2900 mnts (+1.2/day)
2012-08-23 4000 pkgs (+2.1/day over 469 days) 2350 mnts
2011-05-12 3000 pkgs (+1.7/day over 585 days)
2009-10-04 2000 pkgs (+1.1/day over 906 days)
2007-04-12 1000 pkgs
2004-10-01 500 pkgs
2003-04-01 250 pkgs
2002-09-17 68 pkgs
1997-04-23 12 pkgs

These data are for CRAN only [1-13]. There are many more packages
elsewhere, e.g. Bioconductor, GitHub, R-Forge etc.

[1] http://cran.r-project.org/web/packages/
[2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
[3] http://www.r-pkg.org/
[4] Private data
[5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
[6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
[7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
[8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
[9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
[10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
[11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
[12] https://stat.ethz.ch/pipermail/r-devel/2016-February/072388.html
[13] https://stat.ethz.ch/pipermail/r-devel/2016-August/073011.html

All the best,

Henrik
(just a user)



------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------

End of R-devel Digest, Vol 167, Issue 25


From rmcgehee at walleyetrading.net  Mon Jan 30 15:38:02 2017
From: rmcgehee at walleyetrading.net (Robert McGehee)
Date: Mon, 30 Jan 2017 14:38:02 +0000
Subject: [Rd] Matrix package breaks as.matrix method
Message-ID: <30D28A63376088428E8318DD67FD407F706C28@ny-mailstore1.walleyetrading.net>

Georgi,
Brilliant, thank you very much for the helpful reply and explanation! I added 'importFrom("Matrix","as.matrix")'  to my NAMESPACE and all worked fine! As my 'as.matrix' method is used entirely internally to the 'testmat' function (and not "used outside the package"), I don't think I actually need to export it. In my case, testmat is defined inside the package, and not in the global workspace (nothing is defined in the global workspace in my example).
 
To your point that I should just "import the 'Matrix'", I thought adding Matrix to the Depends field in the DESCRIPTION would do that for me, but apparently I need to study the WRE manual more thoroughly, as it clearly does not. 

It's also worth pointing out that R CMD check did not actually warn that I should have imported as.matrix, at least in the case where I have 'Depends: Matrix' in DESCRIPTION and only 'exportPattern("^[[:alpha:]]+")' in the NAMESPACE file. 

Last, for anyone who took issue, apologies for implying a bug where none exists, or that there was something wrong with Matrix or S4.

Thanks again, 
Robert

-----Original Message-----
From: Georgi Boshnakov [mailto:georgi.boshnakov at manchester.ac.uk] 
Sent: Sunday, January 29, 2017 1:40 PM
To: r-devel at r-project.org
Cc: Robert McGehee <rmcgehee at walleyetrading.net>
Subject: RE: R-devel Digest, Vol 167, Issue 25

Hi,

Short answer: import 'as.matrix'  and export your method(s) for it. From WRE:

"All S4 classes to be used outside the package need to be listed in an exportClasses directive. Alternatively, they can be specified using exportClassPattern.(46) in the same style as for exportPattern. To export methods for generics from other packages an exportMethods directive can be used."

Details: the precise details depend on what exactly is in your NAMESPACE file. 
The curious difference you observe is due to the fact that as.matrix is defined in 'base' as S3 generic.  
When you set an S4 method for it you effectively create your own as.matrix S4 generic and your settings in NAMESPACE probably export everything you "own".

When you depend on package 'Matrix',  'as.matrix' is made S4 generic by it and you are defining a method for An imported function, so you need to use exportMethods (see the above excerpt), otherwise your method is not exported. (Indeed, in your example the arror is from array() in the default method).

Note also that it matters where you define the test function. I am pretty sure that you defined it in the global workspace (not in the package) to get the error.

It is very useful practice to run 'R CMD check' (or its devtools equivalent). In this case it would have warned you to import as.matrix. Also, to make your life easier during initial development, import the whole 'Matrix' and when things work think about cleaning up and importing only stuff that you need.

 
Best regards,
Georgi Boshnakov

------------------------------

Message: 15
Date: Fri, 27 Jan 2017 22:41:10 +0000
From: Robert McGehee <rmcgehee at walleyetrading.net>
To: "r-devel at r-project.org" <r-devel at r-project.org>
Subject: [Rd] Matrix package breaks as.matrix method
Message-ID:
	<30D28A63376088428E8318DD67FD407F705B2E at ny-mailstore1.walleyetrading.net>
	
Content-Type: text/plain; charset="us-ascii"

Hi,
The Matrix package and the as.matrix method do not seem to be compatible inside of a package.

Here's an example. I've created a simple package "mat" that defines an eponymous class and as.matrix method on that class. All is well, unless that package has the Matrix package in its Depends or Imports (and imports, e.g. the "Diagonal" function). Then my as.matrix method stops working, even if I'm not using any part of the Matrix package.

Here's an example on R 3.3.2:

First, create an empty package "mat" (e.g. with package.skeleton) with one file in mat/R/mat.R with the following contents:

setClass("mat", representation(H="matrix")) mat <- function(H) new("mat", H=H) setMethod("as.matrix", signature("mat"), function(x, ...) crossprod(x at H)) testmat <- function() {
    H <- matrix(1:3, 1, 3)
    M <- mat(H)
    as.matrix(M)
}

Then install the mat package :
> require(mat)
> testmat()
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    2    4    6
[3,]    3    6    9

All works fine!

Now add "Depends: Matrix" into the package's DESCRIPTION file (alternatively add "Imports: Matrix" and 'importFrom("Matrix","Diagonal")' in the NAMESPACE).

Try again:
> require(mat)
> testmat()
Error in as.vector(data) : 
  no method for coercing this S4 class to a vector

Bug? If not, can anyone provide a work around? In my case, I'd like to mix matrix and Matrix functions in my package, but am obviously having difficulty.

I've come across a somewhat similar report on stackoverflow http://stackoverflow.com/questions/13812373/overloading-operator-in-r-s4-classes-and-matrix-package regarding defining the "+" operator with the Matrix package, but I don't think the solution or the problem quite applies.

Thanks in advance, Robert

> R.version
               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          3.2                         
year           2016                        
month          10                          
day            31                          
svn rev        71607                       
language       R                           
version.string R version 3.3.2 (2016-10-31)
nickname       Sincere Pumpkin Patch       



------------------------------

Message: 16
Date: Fri, 27 Jan 2017 18:52:33 -0800
From: Henrik Bengtsson <henrik.bengtsson at gmail.com>
To: R-devel <r-devel at r-project.org>
Subject: [Rd] Subject: Milestone: 10000 packages on CRAN
Message-ID:
	<CAFDcVCRC6pp3Humv7o48AerZ10Ox0bnxuo3COydzaGfCY17DUA at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Continuing the tradition to post millennia milestones on CRAN:

So, it happened. Today (January 27, 2017 PCT) CRAN reached 10,000 packages [1].

Needless to say, the rate with which new packages are added to CRAN keeps increasing and so does the number of contributors (maintainers).
Somewhere out there, there are ~3 persons who are about to submit their first packages to CRAN today and ~3 persons who will submit another package of theirs. And by the amazing work of the CRAN team, these packages are inspected and quality controlled before going live
- which often happens within a day or so.

As usual and it can't be said too many times: A big thank you to the CRAN team, to the R core, to all package developers, to our friendly community, to everyone out there helping others, and to various online services that simplify package development. We can all give back by carefully reporting bugs to the maintainers, properly citing packages we use in publications (see citation("pkg")), and help newcomers to use R.


Milestones:

2017-01-27 10000 pkgs (+6.3/day over 158 days) 5845 mnts (+3.5/day)
2016-08-22 9000 pkgs (+5.7/day over 175 days) 5289 mnts (+5.8/day)
2016-02-29 8000 pkgs (+5.0/day over 201 days) 4279 mnts (+0.7/day)
2015-08-12 7000 pkgs (+3.4/day over 287 days) 4130 mnts (+2.4/day)
2014-10-29 6000 pkgs (+3.0/day over 335 days) 3444 mnts (+1.6/day)
2013-11-08 5000 pkgs (+2.7/day over 442 days) 2900 mnts (+1.2/day)
2012-08-23 4000 pkgs (+2.1/day over 469 days) 2350 mnts
2011-05-12 3000 pkgs (+1.7/day over 585 days)
2009-10-04 2000 pkgs (+1.1/day over 906 days)
2007-04-12 1000 pkgs
2004-10-01 500 pkgs
2003-04-01 250 pkgs
2002-09-17 68 pkgs
1997-04-23 12 pkgs

These data are for CRAN only [1-13]. There are many more packages elsewhere, e.g. Bioconductor, GitHub, R-Forge etc.

[1] http://cran.r-project.org/web/packages/
[2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
[3] http://www.r-pkg.org/
[4] Private data
[5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
[6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
[7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
[8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
[9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
[10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
[11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
[12] https://stat.ethz.ch/pipermail/r-devel/2016-February/072388.html
[13] https://stat.ethz.ch/pipermail/r-devel/2016-August/073011.html

All the best,

Henrik
(just a user)



------------------------------

Subject: Digest Footer

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------

End of R-devel Digest, Vol 167, Issue 25


From suharto_anggono at yahoo.com  Tue Jan 31 16:43:53 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Tue, 31 Jan 2017 15:43:53 +0000 (UTC)
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
References: <27386751.2682508.1485877433132.ref@mail.yahoo.com>
Message-ID: <27386751.2682508.1485877433132@mail.yahoo.com>

Function 'aggregate.data.frame' in R has taken a different route. With drop=FALSE, the function is also applied to subset corresponding to combination of grouping variables that doesn't appear in the data (example 2 in https://stat.ethz.ch/pipermail/r-devel/2017-January/073678.html).

Because 'default' is used only when simplification happens, putting 'default' after 'simplify' in the argument list may be more logical. Anyway, it doesn't affect call to 'tapply' because the argument 'default' must be specified by name.

With the code using
if(missing(default)) ,
I consider the stated default value of 'default',
default = NA ,
misleading because the code doesn't use it. Also,
tapply(1:3, 1:3, as.raw)
is not the same as
tapply(1:3, 1:3, as.raw, default = NA) .
The accurate statement is the code in
if(missing(default)) ,
but it involves the local variable 'ans'.

As far as I know, the result of function 'array' in is not a classed object and the default method of? `[<-` will be used in the 'tapply' code portion.

As far as I know, the result of 'lapply' is a list without class. So, 'unlist' applied to it uses the default method and the 'unlist' result is a vector or a factor.

With the change, the result of
tapply(1:3, 1:3, factor, levels=3:1)
is of mode "character". The value is from the internal code, not from the factor levels. It is worse than before the change, where it is really the internal code, integer.
In the documentation, the description of argument 'simplify' says: "If 'TRUE' (the default), then if 'FUN' always returns a scalar, 'tapply' returns an array with the mode of the scalar."

To initialize array, a zero-length vector can also be used.

For 'xtabs', I think that it is better if the result has storage mode "integer" if 'sum' results are of storage mode "integer", as in R 3.3.2. As 'default' argument for 'tapply', 'xtabs' can use 0L, or use 0L or 0 depending on storage mode of the summed quantity.

----------------------------
>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Fri, 27 Jan 2017 09:46:15 -0800 writes:

    > On Fri, Jan 27, 2017 at 12:34 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> > On Jan 26, 2017 07:50, "William Dunlap via R-devel"
    >> <r-devel at r-project.org> > wrote:
    >> 
    >> > It would be cool if the default for tapply's init.value
    >> could be > FUN(X[0]), so it would be 0 for FUN=sum or
    >> FUN=length, TRUE for > FUN=all, -Inf for FUN=max, etc.
    >> But that would take time and would > break code for which
    >> FUN did not work on length-0 objects.
    >> 
    >> > Bill Dunlap > TIBCO Software > wdunlap tibco.com
    >> 
    >> I had the same idea (after my first post), so I agree
    >> that would be nice. One could argue it would take time
    >> only if the user is too lazy to specify the value, and we
    >> could use tryCatch(FUN(X[0]), error = NA) to safeguard
    >> against those functions that fail for 0 length arg.
    >> 
    >> But I think the main reason for _not_ setting such a
    >> default is back-compatibility.  In my proposal, the new
    >> argument would not be any change by default and so all
    >> current uses of tapply() would remain unchanged.
    >> 
    >>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> on
    >>>>>>> Thu, 26 Jan 2017 07:57:08 -0800 writes:
    >> 
    >> > On a related note, the storage mode should try to match
    >> ans[[1]] (or > unlist:ed and) when allocating 'ansmat' to
    >> avoid coercion and hence a full > copy.
    >> 
    >> Yes, related indeed; and would fall "in line" with Bill's
    >> idea.  OTOH, it could be implemented independently, by
    >> something like
    >> 
    >> if(missing(init.value)) init.value <- if(length(ans))
    >> as.vector(NA, mode=storage.mode(ans[[1]])) else NA

> I would probably do something like:

>   ans <- unlist(ans, recursive = FALSE, use.names = FALSE)
>   if (length(ans)) storage.mode(init.value) <- storage.mode(ans[[1]])
>   ansmat <- array(init.value, dim = extent, dimnames = namelist)

> instead.  That completely avoids having to use missing() and the value
> of 'init.value' will be coerced later if not done upfront.  use.names
> = FALSE speeds up unlist().

Thank you, Henrik.
That's a good idea to do the unlist() first, and with 'use.names=FALSE'.
I'll copy that.

On the other hand, "brutally" modifying  'init.value' (now called 'default')
even when the user has specified it is not acceptable I think.
You are right that it would be coerced anyway subsequently, but
the coercion will happen in whatever method of  `[<-` will be
appropriate.
Good S3 and S4 programmers will write such methods for their classes.

For that reason, I'm even more conservative now, only fiddle in
case of an atomic 'ans' and make use of the corresponding '['
method rather than as.vector(.) ... because that will fulfill
the following new regression test {not fulfilled in current R}:

identical(tapply(1:3, 1:3, as.raw),
	  array(as.raw(1:3), 3L, dimnames=list(1:3)))

Also, I've done a few more things -- treating if(.) . else . as a
function call, etc  and now committed as  rev 72040  to
R-devel... really wanting to get this out.

We can bet if there will be ripples in (visible) package space,
I give it relatively high chance for no ripples (and much higher
chance for problems with the more aggressive proposal..)

Thank you again, for your "thinking along" and constructive
suggestions.

Martin


From suharto_anggono at yahoo.com  Tue Jan 31 16:43:53 2017
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Tue, 31 Jan 2017 15:43:53 +0000 (UTC)
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
References: <27386751.2682508.1485877433132.ref@mail.yahoo.com>
Message-ID: <27386751.2682508.1485877433132@mail.yahoo.com>

Function 'aggregate.data.frame' in R has taken a different route. With drop=FALSE, the function is also applied to subset corresponding to combination of grouping variables that doesn't appear in the data (example 2 in https://stat.ethz.ch/pipermail/r-devel/2017-January/073678.html).

Because 'default' is used only when simplification happens, putting 'default' after 'simplify' in the argument list may be more logical. Anyway, it doesn't affect call to 'tapply' because the argument 'default' must be specified by name.

With the code using
if(missing(default)) ,
I consider the stated default value of 'default',
default = NA ,
misleading because the code doesn't use it. Also,
tapply(1:3, 1:3, as.raw)
is not the same as
tapply(1:3, 1:3, as.raw, default = NA) .
The accurate statement is the code in
if(missing(default)) ,
but it involves the local variable 'ans'.

As far as I know, the result of function 'array' in is not a classed object and the default method of? `[<-` will be used in the 'tapply' code portion.

As far as I know, the result of 'lapply' is a list without class. So, 'unlist' applied to it uses the default method and the 'unlist' result is a vector or a factor.

With the change, the result of
tapply(1:3, 1:3, factor, levels=3:1)
is of mode "character". The value is from the internal code, not from the factor levels. It is worse than before the change, where it is really the internal code, integer.
In the documentation, the description of argument 'simplify' says: "If 'TRUE' (the default), then if 'FUN' always returns a scalar, 'tapply' returns an array with the mode of the scalar."

To initialize array, a zero-length vector can also be used.

For 'xtabs', I think that it is better if the result has storage mode "integer" if 'sum' results are of storage mode "integer", as in R 3.3.2. As 'default' argument for 'tapply', 'xtabs' can use 0L, or use 0L or 0 depending on storage mode of the summed quantity.

----------------------------
>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Fri, 27 Jan 2017 09:46:15 -0800 writes:

    > On Fri, Jan 27, 2017 at 12:34 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> > On Jan 26, 2017 07:50, "William Dunlap via R-devel"
    >> <r-devel at r-project.org> > wrote:
    >> 
    >> > It would be cool if the default for tapply's init.value
    >> could be > FUN(X[0]), so it would be 0 for FUN=sum or
    >> FUN=length, TRUE for > FUN=all, -Inf for FUN=max, etc.
    >> But that would take time and would > break code for which
    >> FUN did not work on length-0 objects.
    >> 
    >> > Bill Dunlap > TIBCO Software > wdunlap tibco.com
    >> 
    >> I had the same idea (after my first post), so I agree
    >> that would be nice. One could argue it would take time
    >> only if the user is too lazy to specify the value, and we
    >> could use tryCatch(FUN(X[0]), error = NA) to safeguard
    >> against those functions that fail for 0 length arg.
    >> 
    >> But I think the main reason for _not_ setting such a
    >> default is back-compatibility.  In my proposal, the new
    >> argument would not be any change by default and so all
    >> current uses of tapply() would remain unchanged.
    >> 
    >>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com> on
    >>>>>>> Thu, 26 Jan 2017 07:57:08 -0800 writes:
    >> 
    >> > On a related note, the storage mode should try to match
    >> ans[[1]] (or > unlist:ed and) when allocating 'ansmat' to
    >> avoid coercion and hence a full > copy.
    >> 
    >> Yes, related indeed; and would fall "in line" with Bill's
    >> idea.  OTOH, it could be implemented independently, by
    >> something like
    >> 
    >> if(missing(init.value)) init.value <- if(length(ans))
    >> as.vector(NA, mode=storage.mode(ans[[1]])) else NA

> I would probably do something like:

>   ans <- unlist(ans, recursive = FALSE, use.names = FALSE)
>   if (length(ans)) storage.mode(init.value) <- storage.mode(ans[[1]])
>   ansmat <- array(init.value, dim = extent, dimnames = namelist)

> instead.  That completely avoids having to use missing() and the value
> of 'init.value' will be coerced later if not done upfront.  use.names
> = FALSE speeds up unlist().

Thank you, Henrik.
That's a good idea to do the unlist() first, and with 'use.names=FALSE'.
I'll copy that.

On the other hand, "brutally" modifying  'init.value' (now called 'default')
even when the user has specified it is not acceptable I think.
You are right that it would be coerced anyway subsequently, but
the coercion will happen in whatever method of  `[<-` will be
appropriate.
Good S3 and S4 programmers will write such methods for their classes.

For that reason, I'm even more conservative now, only fiddle in
case of an atomic 'ans' and make use of the corresponding '['
method rather than as.vector(.) ... because that will fulfill
the following new regression test {not fulfilled in current R}:

identical(tapply(1:3, 1:3, as.raw),
	  array(as.raw(1:3), 3L, dimnames=list(1:3)))

Also, I've done a few more things -- treating if(.) . else . as a
function call, etc  and now committed as  rev 72040  to
R-devel... really wanting to get this out.

We can bet if there will be ripples in (visible) package space,
I give it relatively high chance for no ripples (and much higher
chance for problems with the more aggressive proposal..)

Thank you again, for your "thinking along" and constructive
suggestions.

Martin


From thmsroh at gmail.com  Tue Jan 31 17:39:50 2017
From: thmsroh at gmail.com (Thomas Roh)
Date: Tue, 31 Jan 2017 10:39:50 -0600
Subject: [Rd] rnbinom Returns Error that says optional argument is missing
Message-ID: <CAOyPvYCF2rnQWe+h2-kPcbBQ7_NVxAePi0H-EJu8a_8F0jEMtg@mail.gmail.com>

I am trying to reset the default arguments in the rnbinom function with the
following example code:

params <- c("size" = 1, "mu" = 1)
formals(rnbinom)[names(params)] <- params
rnbinom(n = 10)

It returns the following:

Error in rnbinom(n = 10) : argument "prob" is missing, with no default

If I set the defaults with this code:

params <- c("size" = 1, "prob" = .5)
formals(rnbinom)[names(params)] <- params
rnbinom(n = 10)

The function works correctly. The documentation specifies that you can set
mu or prob with size. I understand that the problem lies in default
arguments are evaluated as missing, but it seems unintentional that setting
"prob" and "size" defaults will actually evaluate.

Here is the function call:

function (n, size, prob, mu)

{

    if (!missing(mu)) {

        if (!missing(prob))

            stop("'prob' and 'mu' both specified")

        .Call(C_rnbinom_mu, n, size, mu)

    }

    else .Call(C_rnbinom, n, size, prob)

}





-- 
Thomas Roh
thmsroh at gmail.com

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Tue Jan 31 18:14:23 2017
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 31 Jan 2017 18:14:23 +0100
Subject: [Rd] rnbinom Returns Error that says optional argument is
	missing
In-Reply-To: <CAOyPvYCF2rnQWe+h2-kPcbBQ7_NVxAePi0H-EJu8a_8F0jEMtg@mail.gmail.com>
References: <CAOyPvYCF2rnQWe+h2-kPcbBQ7_NVxAePi0H-EJu8a_8F0jEMtg@mail.gmail.com>
Message-ID: <CAO1zAVZ30GSFiW2RhaF=40RizyfvNir-tN_NMS7XFYQkqs4DVA@mail.gmail.com>

Hi Thomas,

This seems fully expected behaviour. Obviously unspecified arguments are
evaluated as missing regardless of a default value. So if you set mu as a
default, the function will call C_rnbinom with n, size and prob. As prob is
not specified you get the error one would expect. Specifying a default
value for prob also makes rnbinom call C_rnbinom, but in this case there is
a prob value so it works.

I don't know what you consider "unintentional", but everything works as
expected and imho as intended as well. Changing formals to a function comes
with no guarantees, and setting a default value for an argument that
previously had none, comes with the risk of breaking things (like you
noticed)

If you want to use a default value for mu, you have to change the body of
the function as well, eg:

> formals(rnbinom)[c('size','mu')] <- c(1,1)
> body(rnbinom) <- quote(.Call(C_rnbinom_mu, n, size, mu))
> rnbinom(10)
 [1] 0 4 2 0 3 0 4 0 0 2

That's really hacking away and something I would never suggest to people,
but it works.

Hope this explains
Cheers
Joris


On Tue, Jan 31, 2017 at 5:39 PM, Thomas Roh <thmsroh at gmail.com> wrote:

> I am trying to reset the default arguments in the rnbinom function with the
> following example code:
>
> params <- c("size" = 1, "mu" = 1)
> formals(rnbinom)[names(params)] <- params
> rnbinom(n = 10)
>
> It returns the following:
>
> Error in rnbinom(n = 10) : argument "prob" is missing, with no default
>
> If I set the defaults with this code:
>
> params <- c("size" = 1, "prob" = .5)
> formals(rnbinom)[names(params)] <- params
> rnbinom(n = 10)
>
> The function works correctly. The documentation specifies that you can set
> mu or prob with size. I understand that the problem lies in default
> arguments are evaluated as missing, but it seems unintentional that setting
> "prob" and "size" defaults will actually evaluate.
>
> Here is the function call:
>
> function (n, size, prob, mu)
>
> {
>
>     if (!missing(mu)) {
>
>         if (!missing(prob))
>
>             stop("'prob' and 'mu' both specified")
>
>         .Call(C_rnbinom_mu, n, size, mu)
>
>     }
>
>     else .Call(C_rnbinom, n, size, prob)
>
> }
>
>
>
>
>
> --
> Thomas Roh
> thmsroh at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Jan 31 18:14:41 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Jan 2017 18:14:41 +0100
Subject: [Rd] RFC: tapply(*, ..., init.value = NA)
In-Reply-To: <27386751.2682508.1485877433132@mail.yahoo.com>
References: <22668.48887.93419.698242@stat.math.ethz.ch>
	<CAFDcVCTCYn=qXHrw4pmovPbR7hjKd2+yjEmky-uMSCSDr+uqXw@mail.gmail.com>
	<27386751.2682508.1485877433132@mail.yahoo.com>
Message-ID: <22672.50689.531065.366985@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Tue, 31 Jan 2017 15:43:53 +0000 writes:

    > Function 'aggregate.data.frame' in R has taken a different route. With drop=FALSE, the function is also applied to subset corresponding to combination of grouping variables that doesn't appear in the data (example 2 in https://stat.ethz.ch/pipermail/r-devel/2017-January/073678.html).

Interesting point (I couldn't easily find 'the example 2' though).
However, aggregate.data.frame() is a considerably more
sophisticated function and one goal was to change tapply() as
little as possible for compatibility (and maintenance!) reasons .

> Because 'default' is used only when simplification happens, putting 'default' after 'simplify' in the argument list may be more logical. 

Yes, from this point of view, you are right; I had thought about
that too; on the other hand, it belongs "closely" to the 'FUN'
and I think that's why I had decided not to change the proposal..

> Anyway, it doesn't affect call to 'tapply' because the argument 'default' must be specified by name.

Exactly.. so we keep the order as is.

    > With the code using
    >    if(missing(default)) ,
    > I consider the stated default value of 'default',
    >    default = NA ,
    > misleading because the code doesn't use it. 

I know and I also had thought about it and decided to keep it 
in the spirit of "self documentation" because  "in spirit", the
default still *is* NA.

    > Also,
    >  tapply(1:3, 1:3, as.raw)
    > is not the same as
    >  tapply(1:3, 1:3, as.raw, default = NA) .
    > The accurate statement is the code in
    > if(missing(default)) ,
    > but it involves the local variable 'ans'.

exactly.  But putting that whole expression in there would look
confusing to those using  str(tapply), args(tapply) or similar
inspection to quickly get a glimpse of the function user "interface".
That's why we typically don't do that and rather slightly cheat
with the formal default, for the above "didactical" purposes.

If you are puristic about this, then missing() should almost never
be used when the function argument has a formal default.

I don't have a too strong opinion here, and we do have quite a
few other cases, where the formal default argument is not always
used because of   if(missing(.))  clauses.

I think I could be convinced to drop the '= NA' from the formal
argument list..


    > As far as I know, the result of function 'array' in is not a classed object and the default method of? `[<-` will be used in the 'tapply' code portion.

    > As far as I know, the result of 'lapply' is a list without class. So, 'unlist' applied to it uses the default method and the 'unlist' result is a vector or a factor.

You may be right here
  ((or not:  If a package author makes array() into an S3 generic and defines
    S3method(array, *) and she or another make tapply() into a
    generic with methods,  are we really sure that this code
    would not be used ??))

still, the as.raw example did not easily work without a warning
when using as.vector() .. or similar.

    > With the change, the result of

    > tapply(1:3, 1:3, factor, levels=3:1)

    > is of mode "character". The value is from the internal code, not from the factor levels. It is worse than before the change, where it is really the internal code, integer.

I agree that this change is not desirable.
One could argue that it was quite a "lucky coincidence" that the previous
code returned the internal integer codes though..


    > In the documentation, the description of argument 'simplify' says: "If 'TRUE' (the default), then if 'FUN' always returns a scalar, 'tapply' returns an array with the mode of the scalar."


    > To initialize array, a zero-length vector can also be used.

yes, of course; but my  ans[0L][1L]  had the purpose to get the
correct mode specific version of NA .. which works for raw (by
getting '00' because "raw" has *no* NA!).

So it seems I need an additional   !is.factor(ans)  there ...
a bit ugly.


---------

> For 'xtabs', I think that it is better if the result has storage mode "integer" if 'sum' results are of storage mode "integer", as in R 3.3.2. 

you are right, that *is* preferable

>  As 'default' argument for 'tapply', 'xtabs' can use 0L, or use 0L or 0 depending on storage mode of the summed quantity.

indeed, that will be an improvement there!


From avraham.adler at gmail.com  Tue Jan 31 18:56:06 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 31 Jan 2017 12:56:06 -0500
Subject: [Rd] Unexpected EOF in R-patched_2017-01-30
Message-ID: <CAL6gwnKsEuqyEKG+AdxC+skraNiqV7MB0PorEsvXrXWCzO-sEg@mail.gmail.com>

Hello.

When trying to unpack today's version of R-patched, I get the following error:

C:\R>tar -xf R-patched_2017-01-30.tar.gz

gzip: stdin: unexpected end of file
tar: Unexpected EOF in archive
tar: Unexpected EOF in archive
tar: Error is not recoverable: exiting now

I got the same error for R-patched_2017-01-30.tar.gz but not for R-3.3.2.tar.gz.

Thank you,

Avi


From pdalgd at gmail.com  Tue Jan 31 21:30:43 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 31 Jan 2017 21:30:43 +0100
Subject: [Rd] Unexpected EOF in R-patched_2017-01-30
In-Reply-To: <CAL6gwnKsEuqyEKG+AdxC+skraNiqV7MB0PorEsvXrXWCzO-sEg@mail.gmail.com>
References: <CAL6gwnKsEuqyEKG+AdxC+skraNiqV7MB0PorEsvXrXWCzO-sEg@mail.gmail.com>
Message-ID: <91204991-E540-4EE7-A895-6A31B1456091@gmail.com>


> On 31 Jan 2017, at 18:56 , Avraham Adler <avraham.adler at gmail.com> wrote:
> 
> Hello.
> 
> When trying to unpack today's version of R-patched,

From which source? The files from cran.r-project.org seems OK, both those in src/base-prerelease and those from ETHZ. Also, is it not "tar -xfz" when reading a compressed file?

-pd 

> I get the following error:
> 
> C:\R>tar -xf R-patched_2017-01-30.tar.gz
> 
> gzip: stdin: unexpected end of file
> tar: Unexpected EOF in archive
> tar: Unexpected EOF in archive
> tar: Error is not recoverable: exiting now
> 
> I got the same error for R-patched_2017-01-30.tar.gz but not for R-3.3.2.tar.gz.
> 
> Thank you,
> 
> Avi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From avraham.adler at gmail.com  Tue Jan 31 22:07:20 2017
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 31 Jan 2017 16:07:20 -0500
Subject: [Rd] Unexpected EOF in R-patched_2017-01-30
In-Reply-To: <91204991-E540-4EE7-A895-6A31B1456091@gmail.com>
References: <CAL6gwnKsEuqyEKG+AdxC+skraNiqV7MB0PorEsvXrXWCzO-sEg@mail.gmail.com>
	<91204991-E540-4EE7-A895-6A31B1456091@gmail.com>
Message-ID: <CAL6gwnJW0vFVLrO8xmQdmZ648GUrgNECk+LsKJhZ3PR41g+S0Q@mail.gmail.com>

On Tue, Jan 31, 2017 at 3:30 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 31 Jan 2017, at 18:56 , Avraham Adler <avraham.adler at gmail.com> wrote:
>>
>> Hello.
>>
>> When trying to unpack today's version of R-patched,
>
> From which source? The files from cran.r-project.org seems OK, both those in src/base-prerelease and those from ETHZ. Also, is it not "tar -xfz" when reading a compressed file?
>
> -pd

>From <https://stat.ethz.ch/R/daily/>

Also, while passing z is not in the instructions given in Installation
and Administration [1], I tried passing -xzf and it did not work. I
believe f has to be last if the file name follows immediately.

[1]  <https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Getting-the-source-files>

Thanks,

Avi

>> I get the following error:
>>
>> C:\R>tar -xf R-patched_2017-01-30.tar.gz
>>
>> gzip: stdin: unexpected end of file
>> tar: Unexpected EOF in archive
>> tar: Unexpected EOF in archive
>> tar: Error is not recoverable: exiting now
>>
>> I got the same error for R-patched_2017-01-30.tar.gz but not for R-3.3.2.tar.gz.
>>
>> Thank you,
>>
>> Avi
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>


