From jorismeys at gmail.com  Wed Apr  1 19:21:34 2015
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 1 Apr 2015 19:21:34 +0200
Subject: [Rd] evaluation in transform versus within
Message-ID: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>

Dear list members,

I'm a bit confused about the evaluation of expressions using with() or
within() versus subset() and transform(). I always teach my students to use
with() and within() because of the warning mentioned in the helppages of
subset() and transform(). Both functions use nonstandard evaluation and are
to be used only interactively.

I've never seen that warning on the help page of with() and within(), so I
assumed both functions can safely be used in functions and packages. I've
now been told that both functions pose the same risk as subset() and
transform().

Looking at the source code I've noticed the extra step:

e <- evalq(environment(), data, parent)

which, at least according to my understanding, should ensure that the
functions follow the standard evaluation rules. Could somebody with more
knowledge than I have shed a bit of light on this issue?

Thank you
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Wed Apr  1 19:35:40 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 1 Apr 2015 10:35:40 -0700
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
Message-ID: <CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>

Joris,


The second argument to evalq is envir, so that line says, roughly, "call
environment() to generate me a new environment within the environment
defined by data".

Note that that is is only generating e, the environment that expr will be
evaluated within in the next line (the call to eval). This means that expr
is evaluated in an environment which is inside the environment defined by
data, so you get non-standard evaluation in that symbols defined in data
will be available to expr earlier in symbol lookup than those in the
environment that within() was called from.

This is easy to confirm from the behavior of these functions:

> df = data.frame(x = 1:10, y = rnorm(10))
> x = "I'm a character"
> mean(x)
[1] NA
Warning message:
In mean.default(x) : argument is not numeric or logical: returning NA
> within(df, mean.x <- mean(x))
    x            y mean.x
1   1  0.396758869    5.5
2   2  0.945679050    5.5
3   3  1.980039723    5.5
4   4 -0.187059706    5.5
5   5  0.008220067    5.5
6   6  0.451175885    5.5
7   7 -0.262064017    5.5
8   8 -0.652301191    5.5
9   9  0.673609455    5.5
10 10 -0.075590905    5.5
> with(df, mean(x))
[1] 5.5

P.S. this is probably an r-help question.

Best,
~G




On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Dear list members,
>
> I'm a bit confused about the evaluation of expressions using with() or
> within() versus subset() and transform(). I always teach my students to use
> with() and within() because of the warning mentioned in the helppages of
> subset() and transform(). Both functions use nonstandard evaluation and are
> to be used only interactively.
>
> I've never seen that warning on the help page of with() and within(), so I
> assumed both functions can safely be used in functions and packages. I've
> now been told that both functions pose the same risk as subset() and
> transform().
>
> Looking at the source code I've noticed the extra step:
>
> e <- evalq(environment(), data, parent)
>
> which, at least according to my understanding, should ensure that the
> functions follow the standard evaluation rules. Could somebody with more
> knowledge than I have shed a bit of light on this issue?
>
> Thank you
> Joris
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr  1 19:55:26 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 Apr 2015 13:55:26 -0400
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
Message-ID: <551C310E.3060101@gmail.com>

On 01/04/2015 1:35 PM, Gabriel Becker wrote:
> Joris,
>
>
> The second argument to evalq is envir, so that line says, roughly, "call
> environment() to generate me a new environment within the environment
> defined by data".

I think that's not quite right.  environment() returns the current 
environment, it doesn't create a new one.  It is evalq() that created a 
new environment from data, and environment() just returns it.

Here's what happens.  I've put the code first, the description of what 
happens on the line below.

     parent <- parent.frame()

Get the environment from which within.data.frame was called.

     e <- evalq(environment(), data, parent)

Create a new environment containing the columns of data, with the parent 
being the environment where we were called.
Return it and store it in e.

     eval(substitute(expr), e)

Evaluate the expression in this new environment.

     l <- as.list(e)

Convert it to a list.

     l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]

Delete NULL entries from the list.

     nD <- length(del <- setdiff(names(data), (nl <- names(l))))

Find out if any columns were deleted.

     data[nl] <- l

Set the columns of data to the values from the list.

     if (nD)
         data[del] <- if (nD == 1)
             NULL
         else vector("list", nD)
     data

Delete the columns from data which were deleted from the list.


>
> Note that that is is only generating e, the environment that expr will be
> evaluated within in the next line (the call to eval). This means that expr
> is evaluated in an environment which is inside the environment defined by
> data, so you get non-standard evaluation in that symbols defined in data
> will be available to expr earlier in symbol lookup than those in the
> environment that within() was called from.

This again sounds like there are two environments created, when really 
there's just one, but the last part is correct.

Duncan Murdoch

>
> This is easy to confirm from the behavior of these functions:
>
> > df = data.frame(x = 1:10, y = rnorm(10))
> > x = "I'm a character"
> > mean(x)
> [1] NA
> Warning message:
> In mean.default(x) : argument is not numeric or logical: returning NA
> > within(df, mean.x <- mean(x))
>      x            y mean.x
> 1   1  0.396758869    5.5
> 2   2  0.945679050    5.5
> 3   3  1.980039723    5.5
> 4   4 -0.187059706    5.5
> 5   5  0.008220067    5.5
> 6   6  0.451175885    5.5
> 7   7 -0.262064017    5.5
> 8   8 -0.652301191    5.5
> 9   9  0.673609455    5.5
> 10 10 -0.075590905    5.5
> > with(df, mean(x))
> [1] 5.5
>
> P.S. this is probably an r-help question.
>
> Best,
> ~G
>
>
>
>
> On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys <jorismeys at gmail.com> wrote:
>
> > Dear list members,
> >
> > I'm a bit confused about the evaluation of expressions using with() or
> > within() versus subset() and transform(). I always teach my students to use
> > with() and within() because of the warning mentioned in the helppages of
> > subset() and transform(). Both functions use nonstandard evaluation and are
> > to be used only interactively.
> >
> > I've never seen that warning on the help page of with() and within(), so I
> > assumed both functions can safely be used in functions and packages. I've
> > now been told that both functions pose the same risk as subset() and
> > transform().
> >
> > Looking at the source code I've noticed the extra step:
> >
> > e <- evalq(environment(), data, parent)
> >
> > which, at least according to my understanding, should ensure that the
> > functions follow the standard evaluation rules. Could somebody with more
> > knowledge than I have shed a bit of light on this issue?
> >
> > Thank you
> > Joris
> >
> > --
> > Joris Meys
> > Statistical consultant
> >
> > Ghent University
> > Faculty of Bioscience Engineering
> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >
> > tel :  +32 (0)9 264 61 79
> > Joris.Meys at Ugent.be
> > -------------------------------
> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>


From gmbecker at ucdavis.edu  Wed Apr  1 20:05:59 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 1 Apr 2015 11:05:59 -0700
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <551C310E.3060101@gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
	<551C310E.3060101@gmail.com>
Message-ID: <CADwqtCMA75u2451H6L+GjiuEm5fHb4iove+D0XpCVb9aPeZSdQ@mail.gmail.com>

Ah, of course. Embarassing, the "environment" and "new.env" wires got
crossed in my head somehow.

Joris - The take away, as Duncan's point suggests, is that e (which is
where expr is evaluated) is the "environment form" of data. So that's why
the lookup hits things in data before anything else.

Sorry for the unintentional obfuscation.

~G


On Wed, Apr 1, 2015 at 10:55 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 01/04/2015 1:35 PM, Gabriel Becker wrote:
>
>> Joris,
>>
>>
>> The second argument to evalq is envir, so that line says, roughly, "call
>> environment() to generate me a new environment within the environment
>> defined by data".
>>
>
> I think that's not quite right.  environment() returns the current
> environment, it doesn't create a new one.  It is evalq() that created a new
> environment from data, and environment() just returns it.
>
> Here's what happens.  I've put the code first, the description of what
> happens on the line below.
>
>     parent <- parent.frame()
>
> Get the environment from which within.data.frame was called.
>
>     e <- evalq(environment(), data, parent)
>
> Create a new environment containing the columns of data, with the parent
> being the environment where we were called.
> Return it and store it in e.
>
>     eval(substitute(expr), e)
>
> Evaluate the expression in this new environment.
>
>     l <- as.list(e)
>
> Convert it to a list.
>
>     l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]
>
> Delete NULL entries from the list.
>
>     nD <- length(del <- setdiff(names(data), (nl <- names(l))))
>
> Find out if any columns were deleted.
>
>     data[nl] <- l
>
> Set the columns of data to the values from the list.
>
>     if (nD)
>         data[del] <- if (nD == 1)
>             NULL
>         else vector("list", nD)
>     data
>
> Delete the columns from data which were deleted from the list.
>
>
>
>> Note that that is is only generating e, the environment that expr will be
>> evaluated within in the next line (the call to eval). This means that expr
>> is evaluated in an environment which is inside the environment defined by
>> data, so you get non-standard evaluation in that symbols defined in data
>> will be available to expr earlier in symbol lookup than those in the
>> environment that within() was called from.
>>
>
> This again sounds like there are two environments created, when really
> there's just one, but the last part is correct.
>
> Duncan Murdoch
>
>
>
>> This is easy to confirm from the behavior of these functions:
>>
>> > df = data.frame(x = 1:10, y = rnorm(10))
>> > x = "I'm a character"
>> > mean(x)
>> [1] NA
>> Warning message:
>> In mean.default(x) : argument is not numeric or logical: returning NA
>> > within(df, mean.x <- mean(x))
>>      x            y mean.x
>> 1   1  0.396758869    5.5
>> 2   2  0.945679050    5.5
>> 3   3  1.980039723    5.5
>> 4   4 -0.187059706    5.5
>> 5   5  0.008220067    5.5
>> 6   6  0.451175885    5.5
>> 7   7 -0.262064017    5.5
>> 8   8 -0.652301191    5.5
>> 9   9  0.673609455    5.5
>> 10 10 -0.075590905    5.5
>> > with(df, mean(x))
>> [1] 5.5
>>
>> P.S. this is probably an r-help question.
>>
>> Best,
>> ~G
>>
>>
>>
>>
>> On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys <jorismeys at gmail.com> wrote:
>>
>> > Dear list members,
>> >
>> > I'm a bit confused about the evaluation of expressions using with() or
>> > within() versus subset() and transform(). I always teach my students to
>> use
>> > with() and within() because of the warning mentioned in the helppages of
>> > subset() and transform(). Both functions use nonstandard evaluation and
>> are
>> > to be used only interactively.
>> >
>> > I've never seen that warning on the help page of with() and within(),
>> so I
>> > assumed both functions can safely be used in functions and packages.
>> I've
>> > now been told that both functions pose the same risk as subset() and
>> > transform().
>> >
>> > Looking at the source code I've noticed the extra step:
>> >
>> > e <- evalq(environment(), data, parent)
>> >
>> > which, at least according to my understanding, should ensure that the
>> > functions follow the standard evaluation rules. Could somebody with more
>> > knowledge than I have shed a bit of light on this issue?
>> >
>> > Thank you
>> > Joris
>> >
>> > --
>> > Joris Meys
>> > Statistical consultant
>> >
>> > Ghent University
>> > Faculty of Bioscience Engineering
>> > Department of Mathematical Modelling, Statistics and Bio-Informatics
>> >
>> > tel :  +32 (0)9 264 61 79
>> > Joris.Meys at Ugent.be
>> > -------------------------------
>> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>>
>


-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Wed Apr  1 20:33:43 2015
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 1 Apr 2015 20:33:43 +0200
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <551C310E.3060101@gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
	<551C310E.3060101@gmail.com>
Message-ID: <CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>

Thank you for the insights. I understood as much from the code, but I can't
really see how this can cause a problem when using with() or within()
within a package or a function. The environments behave like I would
expect, as does the evaluation of the arguments. The second argument is
supposed to be an expression, so I would expect that expression to be
evaluated in the data frame first.

I believed the warning in subset() and transform() refers to the
consequences of using the dotted argument and the evaluation thereof inside
the function, but I might have misunderstood this. I've always considered
within() the programming equivalent of the convenience function
transform().

Sorry for using the r-devel list, but I reckoned this could have
consequences for package developers like me. More explicitly: if within()
poses the same risk as transform() (which I'm still not sure of), a warning
on the help page of within() would be suited imho.  I will use the r-help
list in the future.

Kind regards
Joris

On Wed, Apr 1, 2015 at 7:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 01/04/2015 1:35 PM, Gabriel Becker wrote:
>
>> Joris,
>>
>>
>> The second argument to evalq is envir, so that line says, roughly, "call
>> environment() to generate me a new environment within the environment
>> defined by data".
>>
>
> I think that's not quite right.  environment() returns the current
> environment, it doesn't create a new one.  It is evalq() that created a new
> environment from data, and environment() just returns it.
>
> Here's what happens.  I've put the code first, the description of what
> happens on the line below.
>
>     parent <- parent.frame()
>
> Get the environment from which within.data.frame was called.
>
>     e <- evalq(environment(), data, parent)
>
> Create a new environment containing the columns of data, with the parent
> being the environment where we were called.
> Return it and store it in e.
>
>     eval(substitute(expr), e)
>
> Evaluate the expression in this new environment.
>
>     l <- as.list(e)
>
> Convert it to a list.
>
>     l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]
>
> Delete NULL entries from the list.
>
>     nD <- length(del <- setdiff(names(data), (nl <- names(l))))
>
> Find out if any columns were deleted.
>
>     data[nl] <- l
>
> Set the columns of data to the values from the list.
>
>     if (nD)
>         data[del] <- if (nD == 1)
>             NULL
>         else vector("list", nD)
>     data
>
> Delete the columns from data which were deleted from the list.
>
>
>
>> Note that that is is only generating e, the environment that expr will be
>> evaluated within in the next line (the call to eval). This means that expr
>> is evaluated in an environment which is inside the environment defined by
>> data, so you get non-standard evaluation in that symbols defined in data
>> will be available to expr earlier in symbol lookup than those in the
>> environment that within() was called from.
>>
>
> This again sounds like there are two environments created, when really
> there's just one, but the last part is correct.
>
> Duncan Murdoch
>
>
>
>> This is easy to confirm from the behavior of these functions:
>>
>> > df = data.frame(x = 1:10, y = rnorm(10))
>> > x = "I'm a character"
>> > mean(x)
>> [1] NA
>> Warning message:
>> In mean.default(x) : argument is not numeric or logical: returning NA
>> > within(df, mean.x <- mean(x))
>>      x            y mean.x
>> 1   1  0.396758869    5.5
>> 2   2  0.945679050    5.5
>> 3   3  1.980039723    5.5
>> 4   4 -0.187059706    5.5
>> 5   5  0.008220067    5.5
>> 6   6  0.451175885    5.5
>> 7   7 -0.262064017    5.5
>> 8   8 -0.652301191    5.5
>> 9   9  0.673609455    5.5
>> 10 10 -0.075590905    5.5
>> > with(df, mean(x))
>> [1] 5.5
>>
>> P.S. this is probably an r-help question.
>>
>> Best,
>> ~G
>>
>>
>>
>>
>> On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys <jorismeys at gmail.com> wrote:
>>
>> > Dear list members,
>> >
>> > I'm a bit confused about the evaluation of expressions using with() or
>> > within() versus subset() and transform(). I always teach my students to
>> use
>> > with() and within() because of the warning mentioned in the helppages of
>> > subset() and transform(). Both functions use nonstandard evaluation and
>> are
>> > to be used only interactively.
>> >
>> > I've never seen that warning on the help page of with() and within(),
>> so I
>> > assumed both functions can safely be used in functions and packages.
>> I've
>> > now been told that both functions pose the same risk as subset() and
>> > transform().
>> >
>> > Looking at the source code I've noticed the extra step:
>> >
>> > e <- evalq(environment(), data, parent)
>> >
>> > which, at least according to my understanding, should ensure that the
>> > functions follow the standard evaluation rules. Could somebody with more
>> > knowledge than I have shed a bit of light on this issue?
>> >
>> > Thank you
>> > Joris
>> >
>> > --
>> > Joris Meys
>> > Statistical consultant
>> >
>> > Ghent University
>> > Faculty of Bioscience Engineering
>> > Department of Mathematical Modelling, Statistics and Bio-Informatics
>> >
>> > tel :  +32 (0)9 264 61 79
>> > Joris.Meys at Ugent.be
>> > -------------------------------
>> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Wed Apr  1 20:52:23 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 1 Apr 2015 11:52:23 -0700
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
	<551C310E.3060101@gmail.com>
	<CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>
Message-ID: <CAOQ5NycWbyGHhVb+iojRxk4KOwM4=AswpzR8yx0WtQ3hshvJpg@mail.gmail.com>

There is no important difference between transform() and within(). They
have the same pitfalls. If your general code is unable to guarantee the
scope of the symbol resolution, the behavior of the code is unlikely to be
very predictable.

I've explored some solutions in the S4Vectors package, see the
S4Vectors:::safeEval. We use that for subset(), etc, on the core Bioc data
structures. Basically, the user is encouraged to escape symbols that should
be resolved in the enclosing environment (not data) with the .() notation
of bquote(). This clarifies the expectations of the programmer and protects
against problems. Later, active bindings are (optionally) employed to catch
any attempts at resolving a symbol in the enclosing environment, which
results in a warning. Just an experiment; feedback welcome.

Michael


On Wed, Apr 1, 2015 at 11:33 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Thank you for the insights. I understood as much from the code, but I can't
> really see how this can cause a problem when using with() or within()
> within a package or a function. The environments behave like I would
> expect, as does the evaluation of the arguments. The second argument is
> supposed to be an expression, so I would expect that expression to be
> evaluated in the data frame first.
>
> I believed the warning in subset() and transform() refers to the
> consequences of using the dotted argument and the evaluation thereof inside
> the function, but I might have misunderstood this. I've always considered
> within() the programming equivalent of the convenience function
> transform().
>
> Sorry for using the r-devel list, but I reckoned this could have
> consequences for package developers like me. More explicitly: if within()
> poses the same risk as transform() (which I'm still not sure of), a warning
> on the help page of within() would be suited imho.  I will use the r-help
> list in the future.
>
> Kind regards
> Joris
>
> On Wed, Apr 1, 2015 at 7:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 01/04/2015 1:35 PM, Gabriel Becker wrote:
> >
> >> Joris,
> >>
> >>
> >> The second argument to evalq is envir, so that line says, roughly, "call
> >> environment() to generate me a new environment within the environment
> >> defined by data".
> >>
> >
> > I think that's not quite right.  environment() returns the current
> > environment, it doesn't create a new one.  It is evalq() that created a
> new
> > environment from data, and environment() just returns it.
> >
> > Here's what happens.  I've put the code first, the description of what
> > happens on the line below.
> >
> >     parent <- parent.frame()
> >
> > Get the environment from which within.data.frame was called.
> >
> >     e <- evalq(environment(), data, parent)
> >
> > Create a new environment containing the columns of data, with the parent
> > being the environment where we were called.
> > Return it and store it in e.
> >
> >     eval(substitute(expr), e)
> >
> > Evaluate the expression in this new environment.
> >
> >     l <- as.list(e)
> >
> > Convert it to a list.
> >
> >     l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]
> >
> > Delete NULL entries from the list.
> >
> >     nD <- length(del <- setdiff(names(data), (nl <- names(l))))
> >
> > Find out if any columns were deleted.
> >
> >     data[nl] <- l
> >
> > Set the columns of data to the values from the list.
> >
> >     if (nD)
> >         data[del] <- if (nD == 1)
> >             NULL
> >         else vector("list", nD)
> >     data
> >
> > Delete the columns from data which were deleted from the list.
> >
> >
> >
> >> Note that that is is only generating e, the environment that expr will
> be
> >> evaluated within in the next line (the call to eval). This means that
> expr
> >> is evaluated in an environment which is inside the environment defined
> by
> >> data, so you get non-standard evaluation in that symbols defined in data
> >> will be available to expr earlier in symbol lookup than those in the
> >> environment that within() was called from.
> >>
> >
> > This again sounds like there are two environments created, when really
> > there's just one, but the last part is correct.
> >
> > Duncan Murdoch
> >
> >
> >
> >> This is easy to confirm from the behavior of these functions:
> >>
> >> > df = data.frame(x = 1:10, y = rnorm(10))
> >> > x = "I'm a character"
> >> > mean(x)
> >> [1] NA
> >> Warning message:
> >> In mean.default(x) : argument is not numeric or logical: returning NA
> >> > within(df, mean.x <- mean(x))
> >>      x            y mean.x
> >> 1   1  0.396758869    5.5
> >> 2   2  0.945679050    5.5
> >> 3   3  1.980039723    5.5
> >> 4   4 -0.187059706    5.5
> >> 5   5  0.008220067    5.5
> >> 6   6  0.451175885    5.5
> >> 7   7 -0.262064017    5.5
> >> 8   8 -0.652301191    5.5
> >> 9   9  0.673609455    5.5
> >> 10 10 -0.075590905    5.5
> >> > with(df, mean(x))
> >> [1] 5.5
> >>
> >> P.S. this is probably an r-help question.
> >>
> >> Best,
> >> ~G
> >>
> >>
> >>
> >>
> >> On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys <jorismeys at gmail.com>
> wrote:
> >>
> >> > Dear list members,
> >> >
> >> > I'm a bit confused about the evaluation of expressions using with() or
> >> > within() versus subset() and transform(). I always teach my students
> to
> >> use
> >> > with() and within() because of the warning mentioned in the helppages
> of
> >> > subset() and transform(). Both functions use nonstandard evaluation
> and
> >> are
> >> > to be used only interactively.
> >> >
> >> > I've never seen that warning on the help page of with() and within(),
> >> so I
> >> > assumed both functions can safely be used in functions and packages.
> >> I've
> >> > now been told that both functions pose the same risk as subset() and
> >> > transform().
> >> >
> >> > Looking at the source code I've noticed the extra step:
> >> >
> >> > e <- evalq(environment(), data, parent)
> >> >
> >> > which, at least according to my understanding, should ensure that the
> >> > functions follow the standard evaluation rules. Could somebody with
> more
> >> > knowledge than I have shed a bit of light on this issue?
> >> >
> >> > Thank you
> >> > Joris
> >> >
> >> > --
> >> > Joris Meys
> >> > Statistical consultant
> >> >
> >> > Ghent University
> >> > Faculty of Bioscience Engineering
> >> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >> >
> >> > tel :  +32 (0)9 264 61 79
> >> > Joris.Meys at Ugent.be
> >> > -------------------------------
> >> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >>
> >>
> >>
> >>
> >
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr  1 21:18:39 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 Apr 2015 15:18:39 -0400
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>	<551C310E.3060101@gmail.com>
	<CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>
Message-ID: <551C448F.4010809@gmail.com>

On 01/04/2015 2:33 PM, Joris Meys wrote:
> Thank you for the insights. I understood as much from the code, but I 
> can't really see how this can cause a problem when using with() or 
> within() within a package or a function. The environments behave like 
> I would expect, as does the evaluation of the arguments. The second 
> argument is supposed to be an expression, so I would expect that 
> expression to be evaluated in the data frame first.

I don't know the context within which you were told that they are 
problematic, but one issue is that it makes typo detection harder, since 
the code analysis won't see typos.

For example:

df <- data.frame(col1 = 1)
global <- 3

with(df, col1 + global)  # fine
with(df, col1 + Global)  # typo, but still no warning

whereas

df$col1 + global  # fine
df$col1 + Global # "no visible binding for global variable 'Global'"

and of course you'll get in a real mess later with the with() code if 
you add a column named "global" to your dataframe.

Duncan Murdoch

>
> I believed the warning in subset() and transform() refers to the 
> consequences of using the dotted argument and the evaluation thereof 
> inside the function, but I might have misunderstood this. I've always 
> considered within() the programming equivalent of the convenience 
> function transform().
>
> Sorry for using the r-devel list, but I reckoned this could have 
> consequences for package developers like me. More explicitly: if 
> within() poses the same risk as transform() (which I'm still not sure 
> of), a warning on the help page of within() would be suited imho.  I 
> will use the r-help list in the future.
>
> Kind regards
> Joris
>
> On Wed, Apr 1, 2015 at 7:55 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 01/04/2015 1:35 PM, Gabriel Becker wrote:
>
>         Joris,
>
>
>         The second argument to evalq is envir, so that line says,
>         roughly, "call
>         environment() to generate me a new environment within the
>         environment
>         defined by data".
>
>
>     I think that's not quite right.  environment() returns the current
>     environment, it doesn't create a new one.  It is evalq() that
>     created a new environment from data, and environment() just
>     returns it.
>
>     Here's what happens.  I've put the code first, the description of
>     what happens on the line below.
>
>         parent <- parent.frame()
>
>     Get the environment from which within.data.frame was called.
>
>         e <- evalq(environment(), data, parent)
>
>     Create a new environment containing the columns of data, with the
>     parent being the environment where we were called.
>     Return it and store it in e.
>
>         eval(substitute(expr), e)
>
>     Evaluate the expression in this new environment.
>
>         l <- as.list(e)
>
>     Convert it to a list.
>
>         l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]
>
>     Delete NULL entries from the list.
>
>         nD <- length(del <- setdiff(names(data), (nl <- names(l))))
>
>     Find out if any columns were deleted.
>
>         data[nl] <- l
>
>     Set the columns of data to the values from the list.
>
>         if (nD)
>             data[del] <- if (nD == 1)
>                 NULL
>             else vector("list", nD)
>         data
>
>     Delete the columns from data which were deleted from the list.
>
>
>
>         Note that that is is only generating e, the environment that
>         expr will be
>         evaluated within in the next line (the call to eval). This
>         means that expr
>         is evaluated in an environment which is inside the environment
>         defined by
>         data, so you get non-standard evaluation in that symbols
>         defined in data
>         will be available to expr earlier in symbol lookup than those
>         in the
>         environment that within() was called from.
>
>
>     This again sounds like there are two environments created, when
>     really there's just one, but the last part is correct.
>
>     Duncan Murdoch
>
>
>
>         This is easy to confirm from the behavior of these functions:
>
>         > df = data.frame(x = 1:10, y = rnorm(10))
>         > x = "I'm a character"
>         > mean(x)
>         [1] NA
>         Warning message:
>         In mean.default(x) : argument is not numeric or logical:
>         returning NA
>         > within(df, mean.x <- mean(x))
>              x            y mean.x
>         1   1  0.396758869    5.5
>         2   2  0.945679050    5.5
>         3   3  1.980039723    5.5
>         4   4 -0.187059706    5.5
>         5   5  0.008220067    5.5
>         6   6  0.451175885    5.5
>         7   7 -0.262064017    5.5
>         8   8 -0.652301191    5.5
>         9   9  0.673609455    5.5
>         10 10 -0.075590905    5.5
>         > with(df, mean(x))
>         [1] 5.5
>
>         P.S. this is probably an r-help question.
>
>         Best,
>         ~G
>
>
>
>
>         On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys
>         <jorismeys at gmail.com <mailto:jorismeys at gmail.com>> wrote:
>
>         > Dear list members,
>         >
>         > I'm a bit confused about the evaluation of expressions using
>         with() or
>         > within() versus subset() and transform(). I always teach my
>         students to use
>         > with() and within() because of the warning mentioned in the
>         helppages of
>         > subset() and transform(). Both functions use nonstandard
>         evaluation and are
>         > to be used only interactively.
>         >
>         > I've never seen that warning on the help page of with() and
>         within(), so I
>         > assumed both functions can safely be used in functions and
>         packages. I've
>         > now been told that both functions pose the same risk as
>         subset() and
>         > transform().
>         >
>         > Looking at the source code I've noticed the extra step:
>         >
>         > e <- evalq(environment(), data, parent)
>         >
>         > which, at least according to my understanding, should ensure
>         that the
>         > functions follow the standard evaluation rules. Could
>         somebody with more
>         > knowledge than I have shed a bit of light on this issue?
>         >
>         > Thank you
>         > Joris
>         >
>         > --
>         > Joris Meys
>         > Statistical consultant
>         >
>         > Ghent University
>         > Faculty of Bioscience Engineering
>         > Department of Mathematical Modelling, Statistics and
>         Bio-Informatics
>         >
>         > tel : +32 (0)9 264 61 79 <tel:%2B32%20%280%299%20264%2061%2079>
>         > Joris.Meys at Ugent.be
>         > -------------------------------
>         > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>         >
>         >         [[alternative HTML version deleted]]
>         >
>         > ______________________________________________
>         > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing
>         list
>         > https://stat.ethz.ch/mailman/listinfo/r-devel
>         >
>
>
>
>
>
>
>
> -- 
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Wed Apr  1 22:38:12 2015
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 1 Apr 2015 22:38:12 +0200
Subject: [Rd] evaluation in transform versus within
In-Reply-To: <551C448F.4010809@gmail.com>
References: <CAO1zAVZ+QB8q2xpHeHTXMW9tku=DEUuqRZOmW_d=8Z3FT3vvrQ@mail.gmail.com>
	<CADwqtCNcq3FJShu1Bi47jiHa_2b6s-UKnwUeLrJmw-etf=RJMw@mail.gmail.com>
	<551C310E.3060101@gmail.com>
	<CAO1zAVaqMrWLMJxaF+6z1TCLmFuW9PRn=PfJ6+5LU8kKZ=QcBg@mail.gmail.com>
	<551C448F.4010809@gmail.com>
Message-ID: <CAO1zAVaG4C7JrW0EO8KFyy3g4ypJvAFi4rVidLQDySLxMVzPTg@mail.gmail.com>

Thanks all, I see where I misunderstood the issue. I would like to suggest
though to add a similar warning to the help page of with() and within()
like there is already on subset() and transform().

Cheers
Joris

On Wed, Apr 1, 2015 at 9:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 01/04/2015 2:33 PM, Joris Meys wrote:
>
>> Thank you for the insights. I understood as much from the code, but I
>> can't really see how this can cause a problem when using with() or within()
>> within a package or a function. The environments behave like I would
>> expect, as does the evaluation of the arguments. The second argument is
>> supposed to be an expression, so I would expect that expression to be
>> evaluated in the data frame first.
>>
>
> I don't know the context within which you were told that they are
> problematic, but one issue is that it makes typo detection harder, since
> the code analysis won't see typos.
>
> For example:
>
> df <- data.frame(col1 = 1)
> global <- 3
>
> with(df, col1 + global)  # fine
> with(df, col1 + Global)  # typo, but still no warning
>
> whereas
>
> df$col1 + global  # fine
> df$col1 + Global # "no visible binding for global variable 'Global'"
>
> and of course you'll get in a real mess later with the with() code if you
> add a column named "global" to your dataframe.
>
> Duncan Murdoch
>
>
>> I believed the warning in subset() and transform() refers to the
>> consequences of using the dotted argument and the evaluation thereof inside
>> the function, but I might have misunderstood this. I've always considered
>> within() the programming equivalent of the convenience function transform().
>>
>> Sorry for using the r-devel list, but I reckoned this could have
>> consequences for package developers like me. More explicitly: if within()
>> poses the same risk as transform() (which I'm still not sure of), a warning
>> on the help page of within() would be suited imho.  I will use the r-help
>> list in the future.
>>
>> Kind regards
>> Joris
>>
>> On Wed, Apr 1, 2015 at 7:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 01/04/2015 1:35 PM, Gabriel Becker wrote:
>>
>>         Joris,
>>
>>
>>         The second argument to evalq is envir, so that line says,
>>         roughly, "call
>>         environment() to generate me a new environment within the
>>         environment
>>         defined by data".
>>
>>
>>     I think that's not quite right.  environment() returns the current
>>     environment, it doesn't create a new one.  It is evalq() that
>>     created a new environment from data, and environment() just
>>     returns it.
>>
>>     Here's what happens.  I've put the code first, the description of
>>     what happens on the line below.
>>
>>         parent <- parent.frame()
>>
>>     Get the environment from which within.data.frame was called.
>>
>>         e <- evalq(environment(), data, parent)
>>
>>     Create a new environment containing the columns of data, with the
>>     parent being the environment where we were called.
>>     Return it and store it in e.
>>
>>         eval(substitute(expr), e)
>>
>>     Evaluate the expression in this new environment.
>>
>>         l <- as.list(e)
>>
>>     Convert it to a list.
>>
>>         l <- l[!vapply(l, is.null, NA, USE.NAMES = FALSE)]
>>
>>     Delete NULL entries from the list.
>>
>>         nD <- length(del <- setdiff(names(data), (nl <- names(l))))
>>
>>     Find out if any columns were deleted.
>>
>>         data[nl] <- l
>>
>>     Set the columns of data to the values from the list.
>>
>>         if (nD)
>>             data[del] <- if (nD == 1)
>>                 NULL
>>             else vector("list", nD)
>>         data
>>
>>     Delete the columns from data which were deleted from the list.
>>
>>
>>
>>         Note that that is is only generating e, the environment that
>>         expr will be
>>         evaluated within in the next line (the call to eval). This
>>         means that expr
>>         is evaluated in an environment which is inside the environment
>>         defined by
>>         data, so you get non-standard evaluation in that symbols
>>         defined in data
>>         will be available to expr earlier in symbol lookup than those
>>         in the
>>         environment that within() was called from.
>>
>>
>>     This again sounds like there are two environments created, when
>>     really there's just one, but the last part is correct.
>>
>>     Duncan Murdoch
>>
>>
>>
>>         This is easy to confirm from the behavior of these functions:
>>
>>         > df = data.frame(x = 1:10, y = rnorm(10))
>>         > x = "I'm a character"
>>         > mean(x)
>>         [1] NA
>>         Warning message:
>>         In mean.default(x) : argument is not numeric or logical:
>>         returning NA
>>         > within(df, mean.x <- mean(x))
>>              x            y mean.x
>>         1   1  0.396758869    5.5
>>         2   2  0.945679050    5.5
>>         3   3  1.980039723    5.5
>>         4   4 -0.187059706    5.5
>>         5   5  0.008220067    5.5
>>         6   6  0.451175885    5.5
>>         7   7 -0.262064017    5.5
>>         8   8 -0.652301191    5.5
>>         9   9  0.673609455    5.5
>>         10 10 -0.075590905    5.5
>>         > with(df, mean(x))
>>         [1] 5.5
>>
>>         P.S. this is probably an r-help question.
>>
>>         Best,
>>         ~G
>>
>>
>>
>>
>>         On Wed, Apr 1, 2015 at 10:21 AM, Joris Meys
>>         <jorismeys at gmail.com <mailto:jorismeys at gmail.com>> wrote:
>>
>>         > Dear list members,
>>         >
>>         > I'm a bit confused about the evaluation of expressions using
>>         with() or
>>         > within() versus subset() and transform(). I always teach my
>>         students to use
>>         > with() and within() because of the warning mentioned in the
>>         helppages of
>>         > subset() and transform(). Both functions use nonstandard
>>         evaluation and are
>>         > to be used only interactively.
>>         >
>>         > I've never seen that warning on the help page of with() and
>>         within(), so I
>>         > assumed both functions can safely be used in functions and
>>         packages. I've
>>         > now been told that both functions pose the same risk as
>>         subset() and
>>         > transform().
>>         >
>>         > Looking at the source code I've noticed the extra step:
>>         >
>>         > e <- evalq(environment(), data, parent)
>>         >
>>         > which, at least according to my understanding, should ensure
>>         that the
>>         > functions follow the standard evaluation rules. Could
>>         somebody with more
>>         > knowledge than I have shed a bit of light on this issue?
>>         >
>>         > Thank you
>>         > Joris
>>         >
>>         > --
>>         > Joris Meys
>>         > Statistical consultant
>>         >
>>         > Ghent University
>>         > Faculty of Bioscience Engineering
>>         > Department of Mathematical Modelling, Statistics and
>>         Bio-Informatics
>>         >
>>         > tel : +32 (0)9 264 61 79 <tel:%2B32%20%280%299%20264%2061%2079>
>>         > Joris.Meys at Ugent.be
>>         > -------------------------------
>>         > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>         >
>>         >         [[alternative HTML version deleted]]
>>         >
>>         > ______________________________________________
>>         > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing
>>         list
>>         > https://stat.ethz.ch/mailman/listinfo/r-devel
>>         >
>>
>>
>>
>>
>>
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Mathematical Modelling, Statistics and Bio-Informatics
>>
>> tel :  +32 (0)9 264 61 79
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Fri Apr  3 01:33:38 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 2 Apr 2015 16:33:38 -0700 (PDT)
Subject: [Rd] request: check version requirements of Suggests package during
 R CMD build if install required
In-Reply-To: <1595441362.1047554.1428017435605.JavaMail.root@fredhutch.org>
Message-ID: <550567055.1047562.1428017618917.JavaMail.root@fredhutch.org>

Hello,

Say a package (call it pkgA) has this in its DESCRIPTION file:

Suggests: foo (>= 1.2.3)

And yet I only have version 1.2.2 of foo installed, which does not include coolFunction(). pkgA's vignette has this code chunk:

library(foo)
coolFunction()

When I run R CMD build on my package, it will fail, saying that coolFunction() could not be found, but I would prefer it say (like it does in R CMD check):

Package required and available but unsuitable version: 'foo'

This only needs to happen (and only should happen) if R CMD build determines that it needs to install the package (i.e. there is a vignette or there are R expressions in man pages).

I understand that Suggests is sort of a catch all and the package may be used in examples, not in the vignette at all. But the reason for my request is that the error message about coolFunction() being missing seems misleading and doesn't tell me what I really need to do, whereas the proposed message would. 

And if I ran R CMD check first I would know what to do, but I typically run build first, and more importantly, so does the Bioconductor build system, so a package developer looking at our build report would never see the more informative message.

Then R-exts section 1.1.3 would also need to be updated from:

"The ?Suggests? field .... Version requirements can be specified, and will be used by R CMD check (and R CMD build, if package installation is necessary)."

Thanks,
Dan


From aravindjayaramanagri at gmail.com  Tue Apr  7 13:28:46 2015
From: aravindjayaramanagri at gmail.com (Aravind Jayaraman)
Date: Tue, 7 Apr 2015 16:58:46 +0530
Subject: [Rd] Package compilation woes on submission.
Message-ID: <CA+0rMgk_T_n4RPni5Ve37pZA3skYObPAq3rZ0o5J1Rvitweafg@mail.gmail.com>

Hello,

I am trying to submit a new package to CRAN. I had checked the
packages with R-devel and R-release in windows 7 local and ubuntu
12.04 local. The package has a C file in src folder which successfully
compiled in all the cases (there were few trivial warnings).

I had submitted the package last week and was asked to resubmit with
few changes in the description file.

However upon resubmission today, the C code failed to compile in the
reviewer's system throwing several errors.

I rechecked the package with windows 7 and ubuntu as before and there
were no errors. I tried winbuilder with R-release as well as R 3.2.0
beta again without any errors.

The only difference that I could understand was that the compiler used
by me as well as winbuilder is gcc while that in case of the reviewer
is clang.

In such a case, how should I proceed with the submission?

-- 
J.Aravind
Germplasm Conservation Division
ICAR-National Bureau of Plant Genetic Resources
New Delhi - 110 012


From henrik.bengtsson at ucsf.edu  Tue Apr  7 18:53:58 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 7 Apr 2015 09:53:58 -0700
Subject: [Rd] Package compilation woes on submission.
In-Reply-To: <CA+0rMgk_T_n4RPni5Ve37pZA3skYObPAq3rZ0o5J1Rvitweafg@mail.gmail.com>
References: <CA+0rMgk_T_n4RPni5Ve37pZA3skYObPAq3rZ0o5J1Rvitweafg@mail.gmail.com>
Message-ID: <CAFDcVCTVD5KF9rQWWgT=N3PBHy_2Km3ZAW5KD1hkn6mTQYPA5g@mail.gmail.com>

I've been there too.  The clang compiler does useful validation and
troubleshooting of your code in addition to what you get with gcc.  I
recommend installing/trying it as a complement to your default setup.

It has a -c option for "Only run preprocess, compile, and assemble
steps" allowing you do check you code as:

    clang -c -pedantic -Wall -I$(R_HOME)/include/ src/*.c

I wouldn't be surprised if this would be enough for you to identify
and fix the problematic code.

Hope this helps

Henrik



On Tue, Apr 7, 2015 at 4:28 AM, Aravind Jayaraman
<aravindjayaramanagri at gmail.com> wrote:
> Hello,
>
> I am trying to submit a new package to CRAN. I had checked the
> packages with R-devel and R-release in windows 7 local and ubuntu
> 12.04 local. The package has a C file in src folder which successfully
> compiled in all the cases (there were few trivial warnings).
>
> I had submitted the package last week and was asked to resubmit with
> few changes in the description file.
>
> However upon resubmission today, the C code failed to compile in the
> reviewer's system throwing several errors.
>
> I rechecked the package with windows 7 and ubuntu as before and there
> were no errors. I tried winbuilder with R-release as well as R 3.2.0
> beta again without any errors.
>
> The only difference that I could understand was that the compiler used
> by me as well as winbuilder is gcc while that in case of the reviewer
> is clang.
>
> In such a case, how should I proceed with the submission?
>
> --
> J.Aravind
> Germplasm Conservation Division
> ICAR-National Bureau of Plant Genetic Resources
> New Delhi - 110 012
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jesper.gadin at gmail.com  Wed Apr  8 18:51:54 2015
From: jesper.gadin at gmail.com (=?UTF-8?Q?Jesper_G=C3=A5din?=)
Date: Wed, 8 Apr 2015 18:51:54 +0200
Subject: [Rd] PCRE, and setting C-,
	LD- and CPP-FLAGS for a local r-devel installation
Message-ID: <CAPmAPXMqVRgx0kSFM=cr1WUX6CDQb6cUxpTeeV3=2k0EA0cV=g@mail.gmail.com>

Hello,

Got some at the time surprising errors some days ago when building a local
r-devel installation on a cluster, with apparent outdated or missing dev
versions of some files. After reading the r-devel news (
https://developer.r-project.org/blosxom.cgi/R-devel/NEWS), it turned out
that " Use of the included versions of ?zlib?, ?bzlib?, ?xz? and PCRE is
deprecated: these are frozen and will eventually be removed. ", and so I
should have expected these errors.

Without being admin, I cannot system wide install or update the software
needed to get the correct headers and libs. So I have to specify all flags
myself. It went well with zlib, bzlib and xz, but not for pcre, which just
does not want to work for me.

My latest ./configure flag creation looks like this:

#bzip2,zlib and xz
bzip2_LD="/gulo/glob/jesper/software/bzip2-1.0.6"
bzip2_CF="/gulo/glob/jesper/software/bzip2-1.0.6"
zlib_LD="/gulo/glob/jesper/software/zlib-1.2.8"
zlib_CF="/gulo/glob/jesper/software/zlib-1.2.8"
xz_CF="/usr/include"
xz_LD="/home/jesper/glob/software/xz/build/lib"

#PCRE
pcre="pcre-8.36"
pcre_CF1="/home/jesper/glob/software/$pcre/build/include"
pcre_CF2="/home/jesper/glob/software/$pcre/sljit"
pcre_CF3="/home/jesper/glob/software/$pcre"
pcre_CF4="/usr/include"

#The pcre was built like this:
./../configure --prefix=/home/jesper/glob/software/pcre-8.36/build
--enable-utf8 --enable-unicode-properties
make CPPFLAGS=-I/usr/include
make install

#step into the correct folder and then run ./configure
cd /home/jesper/glob/software/2015-04-08-r-devel/build
srcdir=".."
$srcdir/configure \
    LDFLAGS="-L$bzip2_LD -L$zlib_LD -L$xz_LD -L$pcre_LD"\
    CFLAGS="-I$bzip2_CF -I$zlib_CF -I$xz_CF" \
    CPPFLAGS="-I$pcre_CF1 -I$pcre_CF2 -I$pcre_CF3 -I$pcre_CF4"

#the last rows of the ouput are
checking for pcre_fullinfo in -lpcre... yes
checking pcre.h usability... yes
checking pcre.h presence... yes
checking for pcre.h... yes
checking pcre/pcre.h usability... no
checking pcre/pcre.h presence... no
checking for pcre/pcre.h... no
checking if PCRE version >= 8.10, < 10.0 and has UTF-8 support... no
checking whether PCRE support suffices... configure: error: pcre library
and headers are required


Hopefully, this is an easy question you. Have spent quite some time
understanding the meaning of the flags and installing software-dependencies
like a maniac. It has been very educative, but am now very much looking
forward to your answers.

/Jesper

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Thu Apr  9 12:36:20 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 09 Apr 2015 11:36:20 +0100
Subject: [Rd] PCRE, and setting C-,
 LD- and CPP-FLAGS for a local r-devel installation
In-Reply-To: <CAPmAPXMqVRgx0kSFM=cr1WUX6CDQb6cUxpTeeV3=2k0EA0cV=g@mail.gmail.com>
References: <CAPmAPXMqVRgx0kSFM=cr1WUX6CDQb6cUxpTeeV3=2k0EA0cV=g@mail.gmail.com>
Message-ID: <55265624.9000502@stats.ox.ac.uk>

On 08/04/2015 17:51, Jesper G?din wrote:
> Hello,
>
> Got some at the time surprising errors some days ago when building a local
> r-devel installation on a cluster, with apparent outdated or missing dev
> versions of some files. After reading the r-devel news (
> https://developer.r-project.org/blosxom.cgi/R-devel/NEWS), it turned out
> that " Use of the included versions of ?zlib?, ?bzlib?, ?xz? and PCRE is
> deprecated: these are frozen and will eventually be removed. ", and so I

Actually, the NEWS item is

     ? The included versions of zlib, bzip2, xz and PCRE have been
       removed, so system versions are required (see the ?R Installation
       and Administration? manual).

At this stage you could have as well tried to install R 3.2.0RC ... 
R-devel has not yet diverged much.

> should have expected these errors.

The failure is

 > checking if PCRE version >= 8.10, < 10.0 and has UTF-8 support... no

Look in config.log to be sure (nothing is easy without that), but it 
looks like the problem is the last condition.  For 8.36 --enable-utf8 is 
a synonym for the preferred --enable-utf and so should have worked.

>
> Without being admin, I cannot system wide install or update the software
> needed to get the correct headers and libs. So I have to specify all flags
> myself. It went well with zlib, bzlib and xz, but not for pcre, which just
> does not want to work for me.
>
> My latest ./configure flag creation looks like this:
>
> #bzip2,zlib and xz
> bzip2_LD="/gulo/glob/jesper/software/bzip2-1.0.6"
> bzip2_CF="/gulo/glob/jesper/software/bzip2-1.0.6"
> zlib_LD="/gulo/glob/jesper/software/zlib-1.2.8"
> zlib_CF="/gulo/glob/jesper/software/zlib-1.2.8"
> xz_CF="/usr/include"
> xz_LD="/home/jesper/glob/software/xz/build/lib"
>
> #PCRE
> pcre="pcre-8.36"
> pcre_CF1="/home/jesper/glob/software/$pcre/build/include"
> pcre_CF2="/home/jesper/glob/software/$pcre/sljit"
> pcre_CF3="/home/jesper/glob/software/$pcre"
> pcre_CF4="/usr/include"
>
> #The pcre was built like this:
> ./../configure --prefix=/home/jesper/glob/software/pcre-8.36/build
> --enable-utf8 --enable-unicode-properties
> make CPPFLAGS=-I/usr/include
> make install
>
> #step into the correct folder and then run ./configure
> cd /home/jesper/glob/software/2015-04-08-r-devel/build
> srcdir=".."
> $srcdir/configure \
>      LDFLAGS="-L$bzip2_LD -L$zlib_LD -L$xz_LD -L$pcre_LD"\
>      CFLAGS="-I$bzip2_CF -I$zlib_CF -I$xz_CF" \
>      CPPFLAGS="-I$pcre_CF1 -I$pcre_CF2 -I$pcre_CF3 -I$pcre_CF4"
>
> #the last rows of the ouput are
> checking for pcre_fullinfo in -lpcre... yes
> checking pcre.h usability... yes
> checking pcre.h presence... yes
> checking for pcre.h... yes
> checking pcre/pcre.h usability... no
> checking pcre/pcre.h presence... no
> checking for pcre/pcre.h... no
> checking if PCRE version >= 8.10, < 10.0 and has UTF-8 support... no
> checking whether PCRE support suffices... configure: error: pcre library
> and headers are required
>
>
> Hopefully, this is an easy question you. Have spent quite some time
> understanding the meaning of the flags and installing software-dependencies
> like a maniac. It has been very educative, but am now very much looking
> forward to your answers.
>
> /Jesper


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From wdunlap at tibco.com  Fri Apr 10 01:13:28 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Apr 2015 16:13:28 -0700
Subject: [Rd] typo in R-exts.html section 6.9
Message-ID: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>

In 'Writing R Extensions' section 6.9 there is the paragraph

There are interfaces (defined in header R_ext/Applic.h) for definite and
for indefinite integrals. ?Indefinite? means that at least one of the
integration boundaries is not finite.

An indefinite integral usually means an antiderivative, not an integral
over an infinite spread.  Should that first sentence end with 'for
integrals over finite and infinite ranges' and the second sentence omitted?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From hj at jhu.edu  Fri Apr 10 05:39:44 2015
From: hj at jhu.edu (Harris A. Jaffee)
Date: Thu, 9 Apr 2015 23:39:44 -0400
Subject: [Rd] typo in R-exts.html section 6.9
In-Reply-To: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>
References: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>
Message-ID: <17E24C54-B36B-4185-A199-04B2E9933D4B@jhu.edu>

I agree, and the text is less than ideal in several other places.
But I don't especially like your phrase 'infinite range', even
though the idea is right.  I think the necessary terminology
already exists.  How about something like this?

 There are interfaces (defined in header R_ext/Applic.h) for definite
 ("proper") and for _improper_ integrals, improper meaning that at 
 least one of the limits of integration is infinite.

Moving ahead, I would use Definite and Improper for "Finite:" and
"Indefinite:".

> On Apr 9, 2015, at 7:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> In 'Writing R Extensions' section 6.9 there is the paragraph
> 
> There are interfaces (defined in header R_ext/Applic.h) for definite and
> for indefinite integrals. ?Indefinite? means that at least one of the
> integration boundaries is not finite.
> 
> An indefinite integral usually means an antiderivative, not an integral
> over an infinite spread.  Should that first sentence end with 'for
> integrals over finite and infinite ranges' and the second sentence omitted?
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Fri Apr 10 16:28:06 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Apr 2015 16:28:06 +0200
Subject: [Rd] RFC: sigma() in package:stats ?
Message-ID: <21799.56822.92675.629735@stat.math.ethz.ch>

I'm proposing to add something like this to the  stats package :

----------------------------------------------------------

### "The" sigma in lm/nls - "like" models:

sigma <- function(object, ...) UseMethod("sigma")

## works whenever deviance(), nobs() and coef() do fine:
sigma.default <- function (object, use.fallback=TRUE, ...)
    sqrt(deviance(object, ...) /
             (nobs(object, use.fallback=use.fallback) - length(coef(object))))

----------------------------------------------------------

[Yes, even though I am known to love S4 classes, and also
 methods, I propose an S3 generic here because it should go
 along with other typical S3 generics and methods, such as 
 coef(), vcov(), ...
]

The main reason/motivation for (something like) this is to
provide encapsulation / abstraction for the following :

Different (S3 and S4) fitted model objects use different ways to store
the \hat\sigma (or \sqrt{\hat{\sigma^2}} - formally not quite
the same !) as part of their object, and if I use methods which
compare models, putting these into tables, etc,
it is much nicer to use sigma(.) instead of having to use
model-specific extractors.

If I'm searching in our large collection of installed packages,
I'm seeing

  > help.search("^sigma$")
  Help files with alias or concept or title matching ?^sigma$? using regular
  expression matching:


  AdaptFitOS::sigma           Extract estimated varying residual variance
    Aliases: sigma
  distrEllipse::MVNormParameter-class
			      Paramter of a multivariate normal distribution
    Aliases: sigma
  dlmodeler::dlmodeler.fit    Fitting function for a model (MLE, MSE, MAD, sigma)
    Concepts: sigma
  elliptic::WeierstrassP      Weierstrass P and related functions
    Aliases: sigma
  gcExplorer::sigma           E. coli Sigma Factors and Global Regulators
    Aliases: sigma
  investr::Sigma              Extract residual standard error
    Aliases: Sigma
  lme4::sigma                 Extract residual standard error
    Aliases: sigma
  mbest::predict.mhglm        Prediction
    Aliases: sigma
  nlmeU::sigma                Extract scale parameter sigma from a model fit
    Aliases: sigma
  numbers::sigma              Divisor Functions
    Aliases: sigma
  pmclust::PARAM              A Set of Parameters in Model-Based Clustering.
    Aliases: SIGMA
  qualityTools::sigma         Get and set methods
    Aliases: sigma
  robustbase::sigma           Extract Residual Standard Error 'Sigma'
    Aliases: sigma
  rugarch::uGARCHfit-class    class: Univariate GARCH Fit Class
    Aliases: sigma
  shapes::distCholesky        Internal function(s)
    Aliases: sigma

which also shows to the curious why I am making this
proposition: I'm co-author of both the  'lme4' and 'robustbase' packages
which already make use of this.

Note that the default method would already work for
lm(), nls(), and (some) glm() model fits.
It may still make sense to use a slightly faster more explicit 
sigma.ls() method,  but that's not the topic of this
conversation, I think.

Martin Maechler,
ETH Zurich and R Core


From jeroenooms at gmail.com  Sat Apr 11 03:49:46 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Fri, 10 Apr 2015 18:49:46 -0700
Subject: [Rd] Testing R packages on Solaris Studio
In-Reply-To: <CABFfbXvC0NbkOYUpopNP8BF5txio9Zw_KUtF1bWrMV0XEHq3rQ@mail.gmail.com>
References: <CABFfbXvC0NbkOYUpopNP8BF5txio9Zw_KUtF1bWrMV0XEHq3rQ@mail.gmail.com>
Message-ID: <CABFfbXufBK7i2d-2E6a_xBY+mBkv4uTpZbrxNu1E8-pt=yepGg@mail.gmail.com>

I prepared a vm image to make testing on Solaris a bit easier. It is
based of the official Oracle Solaris 11.2 VM template and includes two
preinstalled versions of R, two compilers and some other software:

 - Solaris Studio 12.3
 - Oracle R Distribution aka ORD (uses Solaris Studio)
 - OpenCSW:
   * r_base (uses GCC)
   * gcc4g++ and gcc4gfortran
   * git
   * vim

The image is distributed in the open ova format and should work in
most virtualization environments. More information is available on
http://bit.ly/r-solaris-readme.

That said, I still have not figured out how to build Rcpp and RJSONIO
with ORD/SolarisStudio. They compile without problems using
r_base/gcc, but with ORD I still get the same errors described below.
I would be very interested to learn how CRAN builds/tests these
packages on Solaris.



On Thu, Jan 8, 2015 at 12:52 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> I have setup a Solaris server to test packages before submitting to
> CRAN, in order to catch problems that might not reveal themselves on
> Fedora, Debian, OSX or Windows. The machine runs a Solaris 11.2 vm
> with Solaris Studio 12.3.
>
> I was able to compile current r-devel using the suggested environment
> variables from "R Installation and Administration" and:
>
>   ./configure --prefix=/opt/R-devel --with-blas='-library=sunperf' --with-lapack
>
> All works great (fast too), except for some CRAN packages with c++
> code won't build. The compiler itself works, most packages (including
> e.g. MCMCpack) build OK. However packages like Rcpp and RJSONIO fail
> with errors shown here:
> https://gist.github.com/jeroenooms/f1b6a172320a32f59c82.
>
> I tried installing with GNU make, but that does not seem to be the problem
>
>   configure.vars = "MAKE=/opt/csw/bin/gmake"
>
> I am aware that I can work around it by compiling with gcc instead of
> solaris studio, but I would specifically like to replicate the setup
> from CRAN.
>
> Which additional args/vars/dependencies do I need to make Rcpp and
> RJSONIO build as they do on the CRAN Solaris server?
>
>> sessionInfo()
> R Under development (unstable) (2015-01-07 r67351)
> Platform: i386-pc-solaris2.11 (32-bit)
> Running under: Solaris 11
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tcltk_3.2.0 tools_3.2.0


From csardi.gabor at gmail.com  Sat Apr 11 04:39:05 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 10 Apr 2015 22:39:05 -0400
Subject: [Rd] Testing R packages on Solaris Studio
In-Reply-To: <CABFfbXufBK7i2d-2E6a_xBY+mBkv4uTpZbrxNu1E8-pt=yepGg@mail.gmail.com>
References: <CABFfbXvC0NbkOYUpopNP8BF5txio9Zw_KUtF1bWrMV0XEHq3rQ@mail.gmail.com>
	<CABFfbXufBK7i2d-2E6a_xBY+mBkv4uTpZbrxNu1E8-pt=yepGg@mail.gmail.com>
Message-ID: <CABtg=K=6WnqY9KiTtv3vgsoT6oQ19s+dq5XQ7n+gQhZ_cLi45A@mail.gmail.com>

Hi Jeroen,

do you really need ORD? Rcpp works without problems for me on Solaris,
using the Solaris Studio 12.4 compilers, and R compiled from source, on the
Solaris machine. So I guess them problem must be ORD?

Gabor



On Fri, Apr 10, 2015 at 9:49 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:

> I prepared a vm image to make testing on Solaris a bit easier. It is
> based of the official Oracle Solaris 11.2 VM template and includes two
> preinstalled versions of R, two compilers and some other software:
>
>  - Solaris Studio 12.3
>  - Oracle R Distribution aka ORD (uses Solaris Studio)
>  - OpenCSW:
>    * r_base (uses GCC)
>    * gcc4g++ and gcc4gfortran
>    * git
>    * vim
>
> The image is distributed in the open ova format and should work in
> most virtualization environments. More information is available on
> http://bit.ly/r-solaris-readme.
>
> That said, I still have not figured out how to build Rcpp and RJSONIO
> with ORD/SolarisStudio. They compile without problems using
> r_base/gcc, but with ORD I still get the same errors described below.
> I would be very interested to learn how CRAN builds/tests these
> packages on Solaris.
>
>
>
> On Thu, Jan 8, 2015 at 12:52 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> > I have setup a Solaris server to test packages before submitting to
> > CRAN, in order to catch problems that might not reveal themselves on
> > Fedora, Debian, OSX or Windows. The machine runs a Solaris 11.2 vm
> > with Solaris Studio 12.3.
> >
> > I was able to compile current r-devel using the suggested environment
> > variables from "R Installation and Administration" and:
> >
> >   ./configure --prefix=/opt/R-devel --with-blas='-library=sunperf'
> --with-lapack
> >
> > All works great (fast too), except for some CRAN packages with c++
> > code won't build. The compiler itself works, most packages (including
> > e.g. MCMCpack) build OK. However packages like Rcpp and RJSONIO fail
> > with errors shown here:
> > https://gist.github.com/jeroenooms/f1b6a172320a32f59c82.
> >
> > I tried installing with GNU make, but that does not seem to be the
> problem
> >
> >   configure.vars = "MAKE=/opt/csw/bin/gmake"
> >
> > I am aware that I can work around it by compiling with gcc instead of
> > solaris studio, but I would specifically like to replicate the setup
> > from CRAN.
> >
> > Which additional args/vars/dependencies do I need to make Rcpp and
> > RJSONIO build as they do on the CRAN Solaris server?
> >
> >> sessionInfo()
> > R Under development (unstable) (2015-01-07 r67351)
> > Platform: i386-pc-solaris2.11 (32-bit)
> > Running under: Solaris 11
> >
> > locale:
> > [1] C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tcltk_3.2.0 tools_3.2.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Apr 11 09:44:20 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 11 Apr 2015 09:44:20 +0200
Subject: [Rd] typo in R-exts.html section 6.9
In-Reply-To: <17E24C54-B36B-4185-A199-04B2E9933D4B@jhu.edu>
References: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>
	<17E24C54-B36B-4185-A199-04B2E9933D4B@jhu.edu>
Message-ID: <D65D5D03-9467-487E-B71F-8CA9CA0863C6@gmail.com>

[I think this didn't reach the list yesterday due to a server problem in Zurich. Apologies if it is a duplicate.]

On 10 Apr 2015, at 05:39 , Harris A. Jaffee <hj at jhu.edu> wrote:

> I agree, and the text is less than ideal in several other places.
> But I don't especially like your phrase 'infinite range', even
> though the idea is right.  I think the necessary terminology
> already exists.  How about something like this?
> 
> There are interfaces (defined in header R_ext/Applic.h) for definite
> ("proper") and for _improper_ integrals, improper meaning that at 
> least one of the limits of integration is infinite.

Nope. Improper integrals are a subset of definite integrals. E.g., the very first explicit integral in Mathematical Handbook's section on definite integrals, under the heading "Definite integrals involving rational or irrational expressions" is \int_0^\infty dx/(x^2+a^2) = \pi/2a. Also, an integral can be improper even when it is over a finite interval if there is an internal singularity.

But the whole thing depends on which version of integration theory you adopt. Lebesgue integration doesn't really bother with distinguishing between finite and infinite ranges of integration and proper/improper, it just has some functions where the integral is undefined.  

For the purposes of "Writing R Extensions", I'd say that "integrals over finite and infinite intervals" should do fine. A fair amount of the complexity of numerical integration has to be glossed over anyway. The existing text is clearly wrong, of course.

-pd


> 
> Moving ahead, I would use Definite and Improper for "Finite:" and
> "Indefinite:".
> 
>> On Apr 9, 2015, at 7:13 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> 
>> In 'Writing R Extensions' section 6.9 there is the paragraph
>> 
>> There are interfaces (defined in header R_ext/Applic.h) for definite and
>> for indefinite integrals. ?Indefinite? means that at least one of the
>> integration boundaries is not finite.
>> 
>> An indefinite integral usually means an antiderivative, not an integral
>> over an infinite spread.  Should that first sentence end with 'for
>> integrals over finite and infinite ranges' and the second sentence omitted?
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Sun Apr 12 17:26:19 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 12 Apr 2015 11:26:19 -0400
Subject: [Rd] misspellings
Message-ID: <552A8E9B.60906@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Against my better judgment I'm going to point out that "misspelled"
is misspelled in the package-checking messages (at least according to
the OED, the American Heritage Dictionary, and Google,which have it
with no hyphen; further, "mis-spelled" gets 275K Google hits,
"misspelled" gets 11.3 million): from src/library/tools/QC.R,

QC.R:6570:    ## Check for possibly mis-spelled field names.
QC.R:7164:          c("\nPossibly mis-spelled words in DESCRIPTION:",
QC.R:7173:          c("\nUnknown, possibly mis-spelled, fields in
DESCRIPTION:",
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVKo6bAAoJEOCV5YRblxUHa2MH/Ayku+YQmksC7d/rpX5cCY7a
l4XVfScjiyKT00pzvfWrmvnrmAxDwnrHj2GLb5PouLPalFm6GmjY7/BthiRDq7KI
M+Kf1D8W+MV1PcOBdS0IslDmBNdsZzoTaGw+LYxGbAKsjoQ/OUMewt2nbF83P4fN
tfTTm6FpubFhXlVGW/H+1laZO9gwiZktB3WHxP4ww7tEgglNbmA3dLRom9tltFjy
VXLiV4obpIknl7B8JnhgxA22KyKTOX/u8bDhX4bEQVKWJ3Wn4eHKOAVVXlo45kOM
D1rDnpW2XvdBQC4D0OHkvx/KQ7gk77mOYmwhGCZ6O2aac5QSVp/0yNXQQ36eIh8=
=jhHg
-----END PGP SIGNATURE-----


From jesper.gadin at gmail.com  Mon Apr 13 13:26:04 2015
From: jesper.gadin at gmail.com (=?UTF-8?Q?Jesper_G=C3=A5din?=)
Date: Mon, 13 Apr 2015 13:26:04 +0200
Subject: [Rd] PCRE, and setting C-,
 LD- and CPP-FLAGS for a local r-devel installation (Part 2)
Message-ID: <CAPmAPXMvOCbKmN+cDw49xtf8VQXBWDCXm2Wi8c-8mMVspmWuMA@mail.gmail.com>

Hi!

I'm sorry I could not reply on the original message (
https://stat.ethz.ch/pipermail/r-devel/2015-April/070943.html), while I
wasn't a subscriber of the r-devel mail-list. But I got the ./configure to
work in the end. See below for the solution.

./configure 'LDFLAGS=-R/glob/jesper/software/bzip2-1.0.6/
-R/glob/jesper/software/zlib-1.2.8 -L/glob/jesper/software/bzip2-1.0.6
-L/glob/jesper/software/zlib-1.2.8
-L/glob/jesper/software/xz-5.2.1/bin/lib/
-R/glob/jesper/software/xz-5.2.1/bin/lib
-L/glob/jesper/software/pcre-8.36/build/lib
-R/glob/jesper/software/pcre-8.36/build/lib'
CFLAGS='-I/glob/jesper/software/bzip2-1.0.6/
-I/glob/jesper/software/zlib-1.2.8/
-I//glob/jesper/software/xz-5.2.1/bin/include/
-I/glob/jesper/software/pcre-8.36/build/include'
--without-recommended-packages

Jesper

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Mon Apr 13 22:19:34 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 13 Apr 2015 20:19:34 +0000
Subject: [Rd] typo in R-exts.html section 6.9
In-Reply-To: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>
References: <CAF8bMcbCtP78rA1hstR4RsUkVu=GrF-gyr80fUMug=gb5CtDsQ@mail.gmail.com>
Message-ID: <fb525b772197494abb7cbb35c63d6dbe@DOM-EB1-2013.win.ad.jhu.edu>

You are correct that indefinite means an antiderivative.  A definite integral has both limits specified.  Technically correct terms are:  proper and improper definite integrals (although improper integrals are not synonymous with, but include integrals with an infinite range).  Your suggestion is perfectly fine.

Ravi

-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
Sent: Thursday, April 09, 2015 7:13 PM
To: r-devel at r-project.org
Subject: [Rd] typo in R-exts.html section 6.9

In 'Writing R Extensions' section 6.9 there is the paragraph

There are interfaces (defined in header R_ext/Applic.h) for definite and for indefinite integrals. ?Indefinite? means that at least one of the integration boundaries is not finite.

An indefinite integral usually means an antiderivative, not an integral over an infinite spread.  Should that first sentence end with 'for integrals over finite and infinite ranges' and the second sentence omitted?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From hpages at fredhutch.org  Tue Apr 14 07:19:50 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 13 Apr 2015 22:19:50 -0700
Subject: [Rd] behavior of as.integer("5000000000")
Message-ID: <552CA376.7000601@fredhutch.org>

Hi,

   > as.integer("5000000000")
   [1] 2147483647
   Warning message:
   inaccurate integer conversion in coercion

   > as.integer("-5000000000")
   [1] NA
   Warning message:
   inaccurate integer conversion in coercion

Is this a bug or a feature? The man page suggests it's the latter:

   ?as.integer? attempts to coerce its argument to be of integer
   type.  The answer will be ?NA? unless the coercion succeeds.

even though someone could always argue that coercion of "5000000000"
succeeded (for some definition of "succeed").

Also is there any reason why the warning message is different than
with:

   > as.integer(-5000000000)
   [1] NA
   Warning message:
   NAs introduced by coercion

In the case of as.integer("-5000000000"), it's not really that the
conversion was "inaccurate", it's a little bit worse than that. And
knowing that NAs where introduced by coercion is important.

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From avraham.adler at gmail.com  Tue Apr 14 08:24:19 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 14 Apr 2015 02:24:19 -0400
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <552CA376.7000601@fredhutch.org>
References: <552CA376.7000601@fredhutch.org>
Message-ID: <CAL6gwn+a-XKgv3sBSoHYmF=z0x8RxqyghvOuKAo+re0dactkDw@mail.gmail.com>

On Tue, Apr 14, 2015 at 1:19 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi,
>
>   > as.integer("5000000000")
>   [1] 2147483647
>   Warning message:
>   inaccurate integer conversion in coercion
>
>   > as.integer("-5000000000")
>   [1] NA
>   Warning message:
>   inaccurate integer conversion in coercion
>
> Is this a bug or a feature? The man page suggests it's the latter:


Hello, Herv?

Per help("as.integer"): "Note that current implementations of R use
32-bit integers for integer vectors, so the range of representable
integers is restricted to about +/-2*10^9: doubles can hold much
larger integers."

5000000000 ~ 2^32.2 > 2^32 > 2*10^9

Avi


>
>   ?as.integer? attempts to coerce its argument to be of integer
>   type.  The answer will be ?NA? unless the coercion succeeds.
>
> even though someone could always argue that coercion of "5000000000"
> succeeded (for some definition of "succeed").
>
> Also is there any reason why the warning message is different than
> with:
>
>   > as.integer(-5000000000)
>   [1] NA
>   Warning message:
>   NAs introduced by coercion
>
> In the case of as.integer("-5000000000"), it's not really that the
> conversion was "inaccurate", it's a little bit worse than that. And
> knowing that NAs where introduced by coercion is important.
>
> Thanks,
> H.
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Tue Apr 14 08:32:18 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Apr 2015 08:32:18 +0200
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <552CA376.7000601@fredhutch.org>
References: <552CA376.7000601@fredhutch.org>
Message-ID: <21804.46194.893705.440976@stat.math.ethz.ch>


> Hi,
>    > as.integer("5000000000")
>    [1] 2147483647
>    Warning message:
>    inaccurate integer conversion in coercion

>    > as.integer("-5000000000")
>    [1] NA
>    Warning message:
>    inaccurate integer conversion in coercion

> Is this a bug or a feature? The man page suggests it's the
> latter:

I think you mean the "former", a bug.

and I agree entirely, see the following  " 2 x 2 " comparison :

  > N <- 5000000000000 * 8^-(0:7)
  > as.integer(N)
  [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
  Warning message:
  NAs introduced by coercion 
  > as.integer(-N)
  [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
  [8]    -2384185
  Warning message:
  NAs introduced by coercion 
  > as.integer(as.character(N))
  [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
  Warning message:
  inaccurate integer conversion in coercion 
  > as.integer(as.character(-N))
  [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
  [8]    -2384185
  Warning message:
  inaccurate integer conversion in coercion 



>    ?as.integer? attempts to coerce its argument to be of integer
>    type.  The answer will be ?NA? unless the coercion succeeds.

> even though someone could always argue that coercion of "5000000000"
> succeeded (for some definition of "succeed").

> Also is there any reason why the warning message is different than
> with:

>    > as.integer(-5000000000)
>    [1] NA
>    Warning message:
>    NAs introduced by coercion

> In the case of as.integer("-5000000000"), it's not really that the
> conversion was "inaccurate", it's a little bit worse than that. And
> knowing that NAs where introduced by coercion is important.

Yes.   
The message is less a problem than the bug, but I agree we
should try to improve it.

Martin


> -- 
> Herv? Pag?s
> ...................


From hpages at fredhutch.org  Tue Apr 14 08:36:14 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 13 Apr 2015 23:36:14 -0700
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <21804.46194.893705.440976@stat.math.ethz.ch>
References: <552CA376.7000601@fredhutch.org>
	<21804.46194.893705.440976@stat.math.ethz.ch>
Message-ID: <552CB55E.9030306@fredhutch.org>

On 04/13/2015 11:32 PM, Martin Maechler wrote:
>
>> Hi,
>>     > as.integer("5000000000")
>>     [1] 2147483647
>>     Warning message:
>>     inaccurate integer conversion in coercion
>
>>     > as.integer("-5000000000")
>>     [1] NA
>>     Warning message:
>>     inaccurate integer conversion in coercion
>
>> Is this a bug or a feature? The man page suggests it's the
>> latter:
>
> I think you mean the "former", a bug.
>
> and I agree entirely, see the following  " 2 x 2 " comparison :
>
>    > N <- 5000000000000 * 8^-(0:7)
>    > as.integer(N)
>    [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
>    Warning message:
>    NAs introduced by coercion
>    > as.integer(-N)
>    [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>    [8]    -2384185
>    Warning message:
>    NAs introduced by coercion
>    > as.integer(as.character(N))
>    [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
>    Warning message:
>    inaccurate integer conversion in coercion
>    > as.integer(as.character(-N))
>    [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>    [8]    -2384185
>    Warning message:
>    inaccurate integer conversion in coercion
>
>
>
>>     ?as.integer? attempts to coerce its argument to be of integer
>>     type.  The answer will be ?NA? unless the coercion succeeds.
>
>> even though someone could always argue that coercion of "5000000000"
>> succeeded (for some definition of "succeed").
>
>> Also is there any reason why the warning message is different than
>> with:
>
>>     > as.integer(-5000000000)
>>     [1] NA
>>     Warning message:
>>     NAs introduced by coercion
>
>> In the case of as.integer("-5000000000"), it's not really that the
>> conversion was "inaccurate", it's a little bit worse than that. And
>> knowing that NAs where introduced by coercion is important.
>
> Yes.
> The message is less a problem than the bug, but I agree we
> should try to improve it.

Sounds good. Thanks Martin,

H.

>
> Martin
>
>
>> --
>> Herv? Pag?s
>> ...................

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jeroenooms at gmail.com  Wed Apr 15 03:29:51 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 14 Apr 2015 18:29:51 -0700
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
Message-ID: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>

We recently started noticing freezes that appear only on 32bit systems
(both linux and windows) with a relatively recent versions of R 3.2.0,
including the RC. It looks like the problem can be traced back to the use
of R_ObjectTables (see R_ext/Callbacks.h)

The problem is a bit difficult to reproduce because it does not appear on
x64 and because the official R interface to this functionality, the
RObjectTables package from OmegaHat, is no longer maintained. I created a
slightly updated version of RObjectTables package (added a NAMESPACE file)
to reproduce the problem:

  devtools::install_github("jeroenooms/RObjectTables")

The problem can be triggered using the included example from the
DirectoryObjectTable manual.

  library(RObjectTables)
  db <- DirectoryObjectTable(tempdir())
  dbwrite(db, "x", 1:10)
  dbwrite(db, "y", letters[1:3])
  dbobjects(db)
  dbread(db, "x")
  attach(newRFunctionTable(db), name = "myRData")

Things work as expected up till dbread(), but once the object-table is
attached, R freezes on 32bit whereas it works as expected on 64bit.

The same problem appears for other packages that are calling the object
tables C interfaces directly without using the RObjectTables R package.

	[[alternative HTML version deleted]]


From snowyfox at 163.com  Wed Apr 15 03:40:45 2015
From: snowyfox at 163.com (=?GBK?B?xLrI59Gp?=)
Date: Wed, 15 Apr 2015 09:40:45 +0800 (CST)
Subject: [Rd] Embedded R with interactive support
Message-ID: <409db461.24eb.14cbabc4f13.Coremail.snowyfox@163.com>

Hi, 
      I am embedding R in my C++ application, when I try to evaluate(""demo(image)"), and run this command, it show a new window to display a multiple frames image, yet it just flash to the last frame, I have no chance to view other frames.


      I see if I run in the RGUI application, it seems it called GA_NewFrameConfirm(), and wait for a keyboard/mouse event to display next frame. I search in R source code, and it seems depends on how the device got inited, see in GADeviceDriver, the "clickToConfirm" argument. Since I have no idea of how to debug into R(I try to build R from source on windows, yet fail with errors, fail to build R.dll, I think it would be better if someone could tell me how to get R.pdb(for R-3.1.2)), is there any start up arguments for Rf_initEmbeddedR to enable this feature? Thanks.


	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Wed Apr 15 08:11:01 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 14 Apr 2015 23:11:01 -0700
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
In-Reply-To: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
References: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
Message-ID: <CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>

On Tue, Apr 14, 2015 at 6:29 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
> Things work as expected up till dbread(), but once the object-table is
> attached, R freezes on 32bit whereas it works as expected on 64bit.

Debugging this some more, it looks like the freeze appears at the very
end of the attach function, when it calls length(names(value)) on the
newly created object-tables environment. At this stage, calling
ls(value) gives the expected output, but calling names(value) or
length(value) triggers the freeze.

The NEWS file does mention that R 3.2.0 introduces some changes to
names(env) internals. Could it be that this somehow conflicts with the
object tables hooks?


From snowyfox at 163.com  Wed Apr 15 11:15:48 2015
From: snowyfox at 163.com (=?GBK?B?xLrI59Gp?=)
Date: Wed, 15 Apr 2015 17:15:48 +0800 (CST)
Subject: [Rd] R_Visible for embedded R, version 2.13.2
Message-ID: <1de641d9.b13c.14cbc5cea91.Coremail.snowyfox@163.com>

Hi, 


     I am embedding R in a C++ application, and if I use R.dll of version 3.1.2, I can see R_Visible is exported, so I can access this variable in my C++ code, after call:
     SEXP pRes = OR_INVOKE(R_tryEval)(VECTOR_ELT(pEval, 0), OR_VAR(R_GlobalEnv), &nError);


    I use "if(R_Visible)" to decide whether I need to call PrintValue(pRes) to echo the result in my application.


    But in R.dll of version 2.13.2, R_Visible is not an exported symbol, and I can not access it with GetProcAddress(), I wonder whether there is any workaround to decide if I need to call PrintValue() to display the result.


   BTW: I see there is a workaround to query R_FunTab table to decide whether need to call PrintValue, yet this symbol is not exported in R.dll of version 2.13.2....
	[[alternative HTML version deleted]]


From dtemplelang at ucdavis.edu  Wed Apr 15 19:57:58 2015
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Wed, 15 Apr 2015 10:57:58 -0700
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
In-Reply-To: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
References: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
Message-ID: <552EA6A6.2020806@ucdavis.edu>

Thanks for the report.
I'll take a look at this, but it will take a week or so before I have time.

Best,
 Duncan

On 4/14/15 6:29 PM, Jeroen Ooms wrote:
> We recently started noticing freezes that appear only on 32bit systems
> (both linux and windows) with a relatively recent versions of R 3.2.0,
> including the RC. It looks like the problem can be traced back to the use
> of R_ObjectTables (see R_ext/Callbacks.h)
> 
> The problem is a bit difficult to reproduce because it does not appear on
> x64 and because the official R interface to this functionality, the
> RObjectTables package from OmegaHat, is no longer maintained. I created a
> slightly updated version of RObjectTables package (added a NAMESPACE file)
> to reproduce the problem:
> 
>   devtools::install_github("jeroenooms/RObjectTables")
> 
> The problem can be triggered using the included example from the
> DirectoryObjectTable manual.
> 
>   library(RObjectTables)
>   db <- DirectoryObjectTable(tempdir())
>   dbwrite(db, "x", 1:10)
>   dbwrite(db, "y", letters[1:3])
>   dbobjects(db)
>   dbread(db, "x")
>   attach(newRFunctionTable(db), name = "myRData")
> 
> Things work as expected up till dbread(), but once the object-table is
> attached, R freezes on 32bit whereas it works as expected on 64bit.
> 
> The same problem appears for other packages that are calling the object
> tables C interfaces directly without using the RObjectTables R package.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Director, Data Sciences Initiative, UC Davis
Professor, Dept. of Statistics, UC Davis

http://datascience.ucdavis.edu
http://www.stat.ucdavis.edu/~duncan


From maechler at ada-1.stat.math.ethz.ch  Wed Apr 15 21:04:30 2015
From: maechler at ada-1.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 15 Apr 2015 21:04:30 +0200
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
In-Reply-To: <CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>
References: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
	<CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>
Message-ID: <21806.46654.91771.225303@stat.math.ethz.ch>

>>>>> Jeroen Ooms <jeroenooms at gmail.com>
>>>>>     on Tue, 14 Apr 2015 23:11:01 -0700 writes:

    > On Tue, Apr 14, 2015 at 6:29 PM, Jeroen Ooms
    > <jeroenooms at gmail.com> wrote:
    >> Things work as expected up till dbread(), but once the
    >> object-table is attached, R freezes on 32bit whereas it
    >> works as expected on 64bit.

    > Debugging this some more, it looks like the freeze appears
    > at the very end of the attach function, when it calls
    > length(names(value)) on the newly created object-tables
    > environment. At this stage, calling ls(value) gives the
    > expected output, but calling names(value) or length(value)
    > triggers the freeze.

Well, attach() itself has been modified since R 3.1.x; it now
does use  
     length(names(value))    where  value <- .Internal(attach(..))

where as before it used

    length(ls(envir = value, all.names = TRUE))

and the new code is considerably faster for regular cases,
but as you say is not correctly working for the special
RobjectsTables stuff.

Maybe this helps to find a last minute patch to that part in the
R 3.2.0 RC sources ?

    > The NEWS file does mention that R 3.2.0 introduces some
    > changes to names(env) internals. Could it be that this
    > somehow conflicts with the object tables hooks?

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at ada-1.stat.math.ethz.ch  Wed Apr 15 21:44:47 2015
From: maechler at ada-1.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 15 Apr 2015 21:44:47 +0200
Subject: [Rd] RFC: sigma() in package:stats ?
In-Reply-To: <21799.56822.92675.629735@stat.math.ethz.ch>
References: <21799.56822.92675.629735@stat.math.ethz.ch>
Message-ID: <21806.49071.435230.749633@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at lynne.stat.math.ethz.ch>
>>>>>     on Fri, 10 Apr 2015 16:28:06 +0200 writes:

    > I'm proposing to add something like this to the stats
    > package :
    > ----------------------------------------------------------

    > ### "The" sigma in lm/nls - "like" models:

    > sigma <- function(object, ...) UseMethod("sigma")

    > ## works whenever deviance(), nobs() and coef() do fine:
    > sigma.default <- function (object, use.fallback=TRUE, ...)
    >   sqrt(deviance(object, ...) / 
    >               (nobs(object, use.fallback=use.fallback) - length(coef(object))))

    > ----------------------------------------------------------

    > [Yes, even though I am known to love S4 classes, and also
    > methods, I propose an S3 generic here because it should go
    > along with other typical S3 generics and methods, such as
    > coef(), vcov(), ...  ]

    > The main reason/motivation for (something like) this is to
    > provide encapsulation / abstraction for the following :

    > Different (S3 and S4) fitted model objects use different
    > ways to store the \hat\sigma (or \sqrt{\hat{\sigma^2}} -
    > formally not quite the same !) as part of their object,
    > and if I use methods which compare models, putting these
    > into tables, etc, it is much nicer to use sigma(.) instead
    > of having to use model-specific extractors.

No reaction at all....  which also means no opposition...

so I'll commit this to R-devel (--> R 3.3.0 in about one year),
and probably will live with the consequences :-)

Martin



    > If I'm searching in our large collection of installed
    > packages, I'm seeing

    >> help.search("^sigma$")
    > Help files with alias or concept or title matching ?^sigma$? using regular
    > expression matching:

    > AdaptFitOS::sigma           Extract estimated varying residual variance
    > Aliases: sigma
    > distrEllipse::MVNormParameter-class
    > Paramter of a multivariate normal distribution
    > Aliases: sigma
    > dlmodeler::dlmodeler.fit    Fitting function for a model (MLE, MSE, MAD, sigma)
    > Concepts: sigma
    > elliptic::WeierstrassP      Weierstrass P and related functions
    > Aliases: sigma
    > gcExplorer::sigma           E. coli Sigma Factors and Global Regulators
    > Aliases: sigma
    > investr::Sigma              Extract residual standard error
    > Aliases: Sigma
    > lme4::sigma                 Extract residual standard error
    > Aliases: sigma
    > mbest::predict.mhglm        Prediction
    > Aliases: sigma
    > nlmeU::sigma                Extract scale parameter sigma from a model fit
    > Aliases: sigma
    > numbers::sigma              Divisor Functions
    > Aliases: sigma
    > pmclust::PARAM              A Set of Parameters in Model-Based Clustering.
    > Aliases: SIGMA
    > qualityTools::sigma         Get and set methods
    > Aliases: sigma
    > robustbase::sigma           Extract Residual Standard Error 'Sigma'
    > Aliases: sigma
    > rugarch::uGARCHfit-class    class: Univariate GARCH Fit Class
    > Aliases: sigma
    > shapes::distCholesky        Internal function(s)
    > Aliases: sigma

    > which also shows to the curious why I am making this
    > proposition: I'm co-author of both the  'lme4' and 'robustbase' packages
    > which already make use of this.

    > Note that the default method would already work for
    > lm(), nls(), and (some) glm() model fits.
    > It may still make sense to use a slightly faster more explicit 
    > sigma.ls() method,  but that's not the topic of this
    > conversation, I think.

    > Martin Maechler,
    > ETH Zurich and R Core

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Wed Apr 15 21:48:16 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 15 Apr 2015 12:48:16 -0700
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
In-Reply-To: <21806.46654.91771.225303@stat.math.ethz.ch>
References: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
	<CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>
	<21806.46654.91771.225303@stat.math.ethz.ch>
Message-ID: <CABFfbXt1tpuCQ3f_LQ5BymgoYXnK=m2OrcPDo9AGdY2j__GOZA@mail.gmail.com>

On Wed, Apr 15, 2015 at 12:04 PM, Martin Maechler
<maechler at ada-1.stat.math.ethz.ch> wrote:
> Maybe this helps to find a last minute patch to that part in the
> R 3.2.0 RC sources ?

Perhaps, as a stopgap measure, we could add something like this to
attach before it calls length(names(value)):

if(is(value, "UserDefinedDatabase"))
  return(invisible(value))

It is still unclear to my what the underlying problem is and why it
only appears on 32bit. But at least this would prevent R from freezing
when loading packages that use object tables.


From nicola.lunardon at hotmail.it  Thu Apr 16 09:02:01 2015
From: nicola.lunardon at hotmail.it (bstr)
Date: Thu, 16 Apr 2015 00:02:01 -0700 (PDT)
Subject: [Rd] Call R function in C in "optim fashion"
Message-ID: <1429167721769-4705924.post@n4.nabble.com>

I am trying to extend an R package which is totally written in C. I have the
following issue: in the C code I want to make a call to an R defined
function as optim routine does. Nevertheless, when I try to trace down the
main steps in optim, I am (more or less) able to follow the steps in the C
source code, but as soon as I try to understand how optim is called from R
(via .External2) I cannot even figure out what is the link between the
arguments passed through .External2 to optim. Specificaly, in
src/library/stats/src/optim.c we have the following

SEXP optim(SEXP call, SEXP op, SEXP args, SEXP rho)

and in src/library/stats/R/optim.R we have that optim is called in this way
(at least this is what I suppose to be the call)

.External2(C_optim, par, fn1, gr1, method, con, lower, upper)

How arguments call, op, args and rho are passed to optim by .External2?





--
View this message in context: http://r.789695.n4.nabble.com/Call-R-function-in-C-in-optim-fashion-tp4705924.html
Sent from the R devel mailing list archive at Nabble.com.


From Matt_Younce at cinfin.com  Thu Apr 16 18:32:04 2015
From: Matt_Younce at cinfin.com (Younce, Matt)
Date: Thu, 16 Apr 2015 16:32:04 +0000
Subject: [Rd] Does (will) CRAN provide consistent integrity verification
Message-ID: <99E625C1AFD93E4C988AE822E15BED528F003CAB@CORPEXMHQPCF002.cinfin.com>

Intended Audience:  CRAN administrators, maintainers and R Package Developers.
Does anyone know of consistent methods (or plans for near future) to verify integrity of downloaded R package binaries from CRAN?
The purpose is to foster a high degree of trust in the validity of downloaded binaries from CRAN.
For example Apache projects mostly provide something like MD5, SHA1, SHA256, or signing with GnuPG, etc., as in http://www.apache.org/dev/release-signing.
I have noticed that several R package zip files do contain MD5 strings, but not all do, and not as a separate download link.  Besides, MD5 is not the preferred method.
What role in the administration of CRAN would be best positioned to guide and assist R package developers (and/or repository administrators) to provide a simple reliable method?
Without such features, the alternatives for many risk adverse entities would be to resort to vendor releases of R which can be cost prohibitive.
Several recent articles underscore the need is here now, so I am hoping (and probably a growing number are also hoping) there is some way to currently or easily achieve this without resorting to a big dollar vendor.
Thanks very much for your help,
Matt Younce


	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Fri Apr 17 00:23:45 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 16 Apr 2015 15:23:45 -0700 (PDT)
Subject: [Rd] Does (will) CRAN provide consistent integrity verification
In-Reply-To: <99E625C1AFD93E4C988AE822E15BED528F003CAB@CORPEXMHQPCF002.cinfin.com>
Message-ID: <786884143.1457016.1429223025871.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Matt Younce" <Matt_Younce at cinfin.com>
> To: r-devel at r-project.org
> Sent: Thursday, April 16, 2015 9:32:04 AM
> Subject: [Rd] Does (will) CRAN provide consistent integrity verification
> 
> Intended Audience:  CRAN administrators, maintainers and R Package
> Developers.
> Does anyone know of consistent methods (or plans for near future) to
> verify integrity of downloaded R package binaries from CRAN?
> The purpose is to foster a high degree of trust in the validity of
> downloaded binaries from CRAN.
> For example Apache projects mostly provide something like MD5, SHA1,
> SHA256, or signing with GnuPG, etc., as in
> http://www.apache.org/dev/release-signing.

And all of this is probably irrelevant unless packages can be downloaded over HTTPS.

Dan


> I have noticed that several R package zip files do contain MD5
> strings, but not all do, and not as a separate download link.
>  Besides, MD5 is not the preferred method.
> What role in the administration of CRAN would be best positioned to
> guide and assist R package developers (and/or repository
> administrators) to provide a simple reliable method?
> Without such features, the alternatives for many risk adverse
> entities would be to resort to vendor releases of R which can be
> cost prohibitive.
> Several recent articles underscore the need is here now, so I am
> hoping (and probably a growing number are also hoping) there is some
> way to currently or easily achieve this without resorting to a big
> dollar vendor.
> Thanks very much for your help,
> Matt Younce
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wickedpuppy at gmail.com  Fri Apr 17 02:13:51 2015
From: wickedpuppy at gmail.com (billy am)
Date: Fri, 17 Apr 2015 08:13:51 +0800
Subject: [Rd] Does (will) CRAN provide consistent integrity verification
In-Reply-To: <786884143.1457016.1429223025871.JavaMail.root@fredhutch.org>
References: <99E625C1AFD93E4C988AE822E15BED528F003CAB@CORPEXMHQPCF002.cinfin.com>
	<786884143.1457016.1429223025871.JavaMail.root@fredhutch.org>
Message-ID: <CAJ_FNV6OJ0DPOCPQ9AkKf-4WbAS4=WJJ2WDObx1qONo+4rJx+g@mail.gmail.com>

Agreed.  R-project.org and mirrors should be using https.

Billy
On 17 Apr 2015 06:26, "Dan Tenenbaum" <dtenenba at fredhutch.org> wrote:

>
>
> ----- Original Message -----
> > From: "Matt Younce" <Matt_Younce at cinfin.com>
> > To: r-devel at r-project.org
> > Sent: Thursday, April 16, 2015 9:32:04 AM
> > Subject: [Rd] Does (will) CRAN provide consistent integrity verification
> >
> > Intended Audience:  CRAN administrators, maintainers and R Package
> > Developers.
> > Does anyone know of consistent methods (or plans for near future) to
> > verify integrity of downloaded R package binaries from CRAN?
> > The purpose is to foster a high degree of trust in the validity of
> > downloaded binaries from CRAN.
> > For example Apache projects mostly provide something like MD5, SHA1,
> > SHA256, or signing with GnuPG, etc., as in
> > http://www.apache.org/dev/release-signing.
>
> And all of this is probably irrelevant unless packages can be downloaded
> over HTTPS.
>
> Dan
>
>
> > I have noticed that several R package zip files do contain MD5
> > strings, but not all do, and not as a separate download link.
> >  Besides, MD5 is not the preferred method.
> > What role in the administration of CRAN would be best positioned to
> > guide and assist R package developers (and/or repository
> > administrators) to provide a simple reliable method?
> > Without such features, the alternatives for many risk adverse
> > entities would be to resort to vendor releases of R which can be
> > cost prohibitive.
> > Several recent articles underscore the need is here now, so I am
> > hoping (and probably a growing number are also hoping) there is some
> > way to currently or easily achieve this without resorting to a big
> > dollar vendor.
> > Thanks very much for your help,
> > Matt Younce
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From mick.jordan at oracle.com  Fri Apr 17 06:19:14 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 16 Apr 2015 21:19:14 -0700
Subject: [Rd] Redefining {
Message-ID: <553089C2.8040309@oracle.com>

I am curious if anyone knows of R code where the "{" function is 
redefined in a useful way. Or "(" for that matter.

Thanks
Mick


From maechler at lynne.stat.math.ethz.ch  Fri Apr 17 15:49:35 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Apr 2015 15:49:35 +0200
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <552CB55E.9030306@fredhutch.org>
References: <552CA376.7000601@fredhutch.org>
	<21804.46194.893705.440976@stat.math.ethz.ch>
	<552CB55E.9030306@fredhutch.org>
Message-ID: <21809.3951.814845.844579@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Mon, 13 Apr 2015 23:36:14 -0700 writes:

    > On 04/13/2015 11:32 PM, Martin Maechler wrote:
    >> 
    >>> Hi,
    >>> > as.integer("5000000000")
    >>> [1] 2147483647
    >>> Warning message:
    >>> inaccurate integer conversion in coercion
    >> 
    >>> > as.integer("-5000000000")
    >>> [1] NA
    >>> Warning message:
    >>> inaccurate integer conversion in coercion
    >> 
    >>> Is this a bug or a feature? The man page suggests it's the
    >>> latter:
    >> 
    >> I think you mean the "former", a bug.
    >> 
    >> and I agree entirely, see the following  " 2 x 2 " comparison :
    >> 
    >> > N <- 5000000000000 * 8^-(0:7)
    >> > as.integer(N)
    >> [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
    >> Warning message:
    >> NAs introduced by coercion
    >> > as.integer(-N)
    >> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
    >> [8]    -2384185
    >> Warning message:
    >> NAs introduced by coercion
    >> > as.integer(as.character(N))
    >> [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
    >> Warning message:
    >> inaccurate integer conversion in coercion
    >> > as.integer(as.character(-N))
    >> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
    >> [8]    -2384185
    >> Warning message:
    >> inaccurate integer conversion in coercion
    >> 
    >> 
    >> 
    >>> ?as.integer? attempts to coerce its argument to be of integer
    >>> type.  The answer will be ?NA? unless the coercion succeeds.
    >> 
    >>> even though someone could always argue that coercion of "5000000000"
    >>> succeeded (for some definition of "succeed").
    >> 
    >>> Also is there any reason why the warning message is different than
    >>> with:
    >> 
    >>> > as.integer(-5000000000)
    >>> [1] NA
    >>> Warning message:
    >>> NAs introduced by coercion
    >> 
    >>> In the case of as.integer("-5000000000"), it's not really that the
    >>> conversion was "inaccurate", it's a little bit worse than that. And
    >>> knowing that NAs where introduced by coercion is important.
    >> 
    >> Yes.
    >> The message is less a problem than the bug, but I agree we
    >> should try to improve it.

    > Sounds good. Thanks Martin,

I've committed a change to R-devel now, such that also this case
returns NA with a warning, actually for the moment with both the
old warning and the   'NAs introduced by coercion' warning.
The "nice thing" about the old warning is that it explicitly
mentions integer coercion.

I currently think we should keep that property, and I'd propose
to completely drop the 
   "inaccurate integer conversion in coercion"
warning (it is not used anywhere else currently) and replace it
in this and other as.integer(.) cases with

  'NAs introduced by integer coercion'

(or something similar. ... improvements / proposals are welcome).

BTW, the fact that as.integer("-5000000000") did produce an NA
instead of -2147483647 so it would have been compatible with as.integer("5000000000")
was just another coincidence, namely that we "currently" code NA_integer_
by INT_MIN (for 32 bit integers, INT_MIN = 2147483648 = 2^31)
[[but your C code must not rely on that, it is an implementation detail!]]

Martin


From pdalgd at gmail.com  Fri Apr 17 16:26:17 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 17 Apr 2015 16:26:17 +0200
Subject: [Rd] Redefining {
In-Reply-To: <553089C2.8040309@oracle.com>
References: <553089C2.8040309@oracle.com>
Message-ID: <BDC022E9-C548-425B-B232-EB93DE217153@gmail.com>


On 17 Apr 2015, at 06:19 , Mick Jordan <mick.jordan at oracle.com> wrote:

> I am curious if anyone knows of R code where the "{" function is redefined in a useful way. Or "(" for that matter.

I sincerely would hope not....

Incidentally, I seem to recall that during the design of (new?) S, it was at some point the intention to specify vectors as (7, 9, 13) or [7, 9, 13] but the resulting semantic issues led the developers to choose the pure functional form c(7, 9, 13). 


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Fri Apr 17 16:49:04 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Apr 2015 07:49:04 -0700
Subject: [Rd] Redefining {
In-Reply-To: <553089C2.8040309@oracle.com>
References: <553089C2.8040309@oracle.com>
Message-ID: <CAF8bMca2y9X6XhFGYHaX8KrR6d1Z8cEN_OgOiOcLJyspTQz8mA@mail.gmail.com>

One could redefine the "{" function with something like
    `{` <- function(...) simplify2array(list(...))
but then you would have to live with the syntax it requires
(semicolons for separators instead of commas)
   > {1; 2; 3}
   [1] 1 2 3
   > {{11;12;13}; {21;22;23}; {31;32;33}}
        [,1] [,2] [,3]
   [1,]   11   21   31
   [2,]   12   22   32
   [3,]   13   23   33

I have not seen this in any "real" code.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 16, 2015 at 9:19 PM, Mick Jordan <mick.jordan at oracle.com> wrote:

> I am curious if anyone knows of R code where the "{" function is redefined
> in a useful way. Or "(" for that matter.
>
> Thanks
> Mick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Apr 17 16:55:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Apr 2015 07:55:16 -0700
Subject: [Rd] Redefining {
In-Reply-To: <CAF8bMca2y9X6XhFGYHaX8KrR6d1Z8cEN_OgOiOcLJyspTQz8mA@mail.gmail.com>
References: <553089C2.8040309@oracle.com>
	<CAF8bMca2y9X6XhFGYHaX8KrR6d1Z8cEN_OgOiOcLJyspTQz8mA@mail.gmail.com>
Message-ID: <CAF8bMcaiRVcam-+CRn1oZcL=ZABde8eMWVqWVj0cimR9ZQ6Qsg@mail.gmail.com>

Redefining operators can be useful in translating R syntax
to some other language.  E.g., dplyr does that sort of thing
to translate to sql.  It puts the altered definition into an environment
that is used only for such translation so it doesn't mess up
other functions.
   > dplyr::base_scalar$`{`
   function (x)
   {
       build_sql("(", x, ")")
   }
   <environment: namespace:dplyr>



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 17, 2015 at 7:49 AM, William Dunlap <wdunlap at tibco.com> wrote:

> One could redefine the "{" function with something like
>     `{` <- function(...) simplify2array(list(...))
> but then you would have to live with the syntax it requires
> (semicolons for separators instead of commas)
>    > {1; 2; 3}
>    [1] 1 2 3
>    > {{11;12;13}; {21;22;23}; {31;32;33}}
>         [,1] [,2] [,3]
>    [1,]   11   21   31
>    [2,]   12   22   32
>    [3,]   13   23   33
>
> I have not seen this in any "real" code.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Apr 16, 2015 at 9:19 PM, Mick Jordan <mick.jordan at oracle.com>
> wrote:
>
>> I am curious if anyone knows of R code where the "{" function is
>> redefined in a useful way. Or "(" for that matter.
>>
>> Thanks
>> Mick
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Fri Apr 17 17:24:04 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Apr 2015 17:24:04 +0200
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <21809.3951.814845.844579@stat.math.ethz.ch>
References: <552CA376.7000601@fredhutch.org>
	<21804.46194.893705.440976@stat.math.ethz.ch>
	<552CB55E.9030306@fredhutch.org>
	<21809.3951.814845.844579@stat.math.ethz.ch>
Message-ID: <21809.9620.436176.757177@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at lynne.stat.math.ethz.ch>
>>>>>     on Fri, 17 Apr 2015 15:49:35 +0200 writes:

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Mon, 13 Apr 2015 23:36:14 -0700 writes:

    >> On 04/13/2015 11:32 PM, Martin Maechler wrote:
    >>> 
    >>>> Hi,
    >>>> > as.integer("5000000000")
    >>>> [1] 2147483647
    >>>> Warning message:
    >>>> inaccurate integer conversion in coercion
    >>> 
    >>>> > as.integer("-5000000000")
    >>>> [1] NA
    >>>> Warning message:
    >>>> inaccurate integer conversion in coercion
    >>> 
    >>>> Is this a bug or a feature? The man page suggests it's the
    >>>> latter:
    >>> 
    >>> I think you mean the "former", a bug.
    >>> 
    >>> and I agree entirely, see the following  " 2 x 2 " comparison :
    >>> 
    >>> > N <- 5000000000000 * 8^-(0:7)
    >>> > as.integer(N)
    >>> [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
    >>> Warning message:
    >>> NAs introduced by coercion
    >>> > as.integer(-N)
    >>> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
    >>> [8]    -2384185
    >>> Warning message:
    >>> NAs introduced by coercion
    >>> > as.integer(as.character(N))
    >>> [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
    >>> Warning message:
    >>> inaccurate integer conversion in coercion
    >>> > as.integer(as.character(-N))
    >>> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
    >>> [8]    -2384185
    >>> Warning message:
    >>> inaccurate integer conversion in coercion
    >>> 
    >>> 
    >>> 
    >>>> ?as.integer? attempts to coerce its argument to be of integer
    >>>> type.  The answer will be ?NA? unless the coercion succeeds.
    >>> 
    >>>> even though someone could always argue that coercion of "5000000000"
    >>>> succeeded (for some definition of "succeed").
    >>> 
    >>>> Also is there any reason why the warning message is different than
    >>>> with:
    >>> 
    >>>> > as.integer(-5000000000)
    >>>> [1] NA
    >>>> Warning message:
    >>>> NAs introduced by coercion
    >>> 
    >>>> In the case of as.integer("-5000000000"), it's not really that the
    >>>> conversion was "inaccurate", it's a little bit worse than that. And
    >>>> knowing that NAs where introduced by coercion is important.
    >>> 
    >>> Yes.
    >>> The message is less a problem than the bug, but I agree we
    >>> should try to improve it.

    >> Sounds good. Thanks Martin,

    > I've committed a change to R-devel now, such that also this case
    > returns NA with a warning, actually for the moment with both the
    > old warning and the   'NAs introduced by coercion' warning.
    > The "nice thing" about the old warning is that it explicitly
    > mentions integer coercion.

    > I currently think we should keep that property, and I'd propose
    > to completely drop the 
    > "inaccurate integer conversion in coercion"
    > warning (it is not used anywhere else currently) and replace it
    > in this and other as.integer(.) cases with

    > 'NAs introduced by integer coercion'

    > (or something similar. ... improvements / proposals are welcome).

Replying to myself:

I've found 

     'NAs introduced by coercion to integer range'

to be even more "on spot", and so will commit it for today.
Of course, amendment proposals are still welcome.

Martin



    > BTW, the fact that as.integer("-5000000000") did produce an NA
    > instead of -2147483647 so it would have been compatible with as.integer("5000000000")
    > was just another coincidence, namely that we "currently" code NA_integer_
    > by INT_MIN (for 32 bit integers, INT_MIN = 2147483648 = 2^31)
    > [[but your C code must not rely on that, it is an implementation detail!]]

    > Martin


From hpages at fredhutch.org  Fri Apr 17 19:04:20 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 17 Apr 2015 10:04:20 -0700
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <21809.3951.814845.844579@stat.math.ethz.ch>
References: <552CA376.7000601@fredhutch.org>	<21804.46194.893705.440976@stat.math.ethz.ch>	<552CB55E.9030306@fredhutch.org>
	<21809.3951.814845.844579@stat.math.ethz.ch>
Message-ID: <55313D14.2050201@fredhutch.org>

Hi Martin,

On 04/17/2015 06:49 AM, Martin Maechler wrote:
>>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>>      on Mon, 13 Apr 2015 23:36:14 -0700 writes:
>
>      > On 04/13/2015 11:32 PM, Martin Maechler wrote:
>      >>
>      >>> Hi,
>      >>> > as.integer("5000000000")
>      >>> [1] 2147483647
>      >>> Warning message:
>      >>> inaccurate integer conversion in coercion
>      >>
>      >>> > as.integer("-5000000000")
>      >>> [1] NA
>      >>> Warning message:
>      >>> inaccurate integer conversion in coercion
>      >>
>      >>> Is this a bug or a feature? The man page suggests it's the
>      >>> latter:
>      >>
>      >> I think you mean the "former", a bug.
>      >>
>      >> and I agree entirely, see the following  " 2 x 2 " comparison :
>      >>
>      >> > N <- 5000000000000 * 8^-(0:7)
>      >> > as.integer(N)
>      >> [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
>      >> Warning message:
>      >> NAs introduced by coercion
>      >> > as.integer(-N)
>      >> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>      >> [8]    -2384185
>      >> Warning message:
>      >> NAs introduced by coercion
>      >> > as.integer(as.character(N))
>      >> [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
>      >> Warning message:
>      >> inaccurate integer conversion in coercion
>      >> > as.integer(as.character(-N))
>      >> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>      >> [8]    -2384185
>      >> Warning message:
>      >> inaccurate integer conversion in coercion
>      >>
>      >>
>      >>
>      >>> ?as.integer? attempts to coerce its argument to be of integer
>      >>> type.  The answer will be ?NA? unless the coercion succeeds.
>      >>
>      >>> even though someone could always argue that coercion of "5000000000"
>      >>> succeeded (for some definition of "succeed").
>      >>
>      >>> Also is there any reason why the warning message is different than
>      >>> with:
>      >>
>      >>> > as.integer(-5000000000)
>      >>> [1] NA
>      >>> Warning message:
>      >>> NAs introduced by coercion
>      >>
>      >>> In the case of as.integer("-5000000000"), it's not really that the
>      >>> conversion was "inaccurate", it's a little bit worse than that. And
>      >>> knowing that NAs where introduced by coercion is important.
>      >>
>      >> Yes.
>      >> The message is less a problem than the bug, but I agree we
>      >> should try to improve it.
>
>      > Sounds good. Thanks Martin,
>
> I've committed a change to R-devel now, such that also this case
> returns NA with a warning, actually for the moment with both the
> old warning and the   'NAs introduced by coercion' warning.
> The "nice thing" about the old warning is that it explicitly
> mentions integer coercion.
>
> I currently think we should keep that property, and I'd propose
> to completely drop the
>     "inaccurate integer conversion in coercion"
> warning (it is not used anywhere else currently) and replace it
> in this and other as.integer(.) cases with
>
>    'NAs introduced by integer coercion'
>
> (or something similar. ... improvements / proposals are welcome).

Thanks. That's a much better warning message.

>
> BTW, the fact that as.integer("-5000000000") did produce an NA
> instead of -2147483647 so it would have been compatible with as.integer("5000000000")
> was just another coincidence, namely that we "currently" code NA_integer_
> by INT_MIN (for 32 bit integers, INT_MIN = 2147483648 = 2^31)
> [[but your C code must not rely on that, it is an implementation detail!]]

Yeah, I suspected that.

Thanks for the fix.

H.

>
> Martin
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Fri Apr 17 19:12:02 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 17 Apr 2015 10:12:02 -0700
Subject: [Rd] behavior of as.integer("5000000000")
In-Reply-To: <21809.9620.436176.757177@stat.math.ethz.ch>
References: <552CA376.7000601@fredhutch.org>	<21804.46194.893705.440976@stat.math.ethz.ch>	<552CB55E.9030306@fredhutch.org>	<21809.3951.814845.844579@stat.math.ethz.ch>
	<21809.9620.436176.757177@stat.math.ethz.ch>
Message-ID: <55313EE2.7020302@fredhutch.org>



On 04/17/2015 08:24 AM, Martin Maechler wrote:
>>>>>> Martin Maechler <maechler at lynne.stat.math.ethz.ch>
>>>>>>      on Fri, 17 Apr 2015 15:49:35 +0200 writes:
>
>>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>>      on Mon, 13 Apr 2015 23:36:14 -0700 writes:
>
>      >> On 04/13/2015 11:32 PM, Martin Maechler wrote:
>      >>>
>      >>>> Hi,
>      >>>> > as.integer("5000000000")
>      >>>> [1] 2147483647
>      >>>> Warning message:
>      >>>> inaccurate integer conversion in coercion
>      >>>
>      >>>> > as.integer("-5000000000")
>      >>>> [1] NA
>      >>>> Warning message:
>      >>>> inaccurate integer conversion in coercion
>      >>>
>      >>>> Is this a bug or a feature? The man page suggests it's the
>      >>>> latter:
>      >>>
>      >>> I think you mean the "former", a bug.
>      >>>
>      >>> and I agree entirely, see the following  " 2 x 2 " comparison :
>      >>>
>      >>> > N <- 5000000000000 * 8^-(0:7)
>      >>> > as.integer(N)
>      >>> [1]         NA         NA         NA         NA 1220703125  152587890   19073486    2384185
>      >>> Warning message:
>      >>> NAs introduced by coercion
>      >>> > as.integer(-N)
>      >>> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>      >>> [8]    -2384185
>      >>> Warning message:
>      >>> NAs introduced by coercion
>      >>> > as.integer(as.character(N))
>      >>> [1] 2147483647 2147483647 2147483647 2147483647 1220703125  152587890   19073486    2384185
>      >>> Warning message:
>      >>> inaccurate integer conversion in coercion
>      >>> > as.integer(as.character(-N))
>      >>> [1]          NA          NA          NA          NA -1220703125  -152587890   -19073486
>      >>> [8]    -2384185
>      >>> Warning message:
>      >>> inaccurate integer conversion in coercion
>      >>>
>      >>>
>      >>>
>      >>>> ?as.integer? attempts to coerce its argument to be of integer
>      >>>> type.  The answer will be ?NA? unless the coercion succeeds.
>      >>>
>      >>>> even though someone could always argue that coercion of "5000000000"
>      >>>> succeeded (for some definition of "succeed").
>      >>>
>      >>>> Also is there any reason why the warning message is different than
>      >>>> with:
>      >>>
>      >>>> > as.integer(-5000000000)
>      >>>> [1] NA
>      >>>> Warning message:
>      >>>> NAs introduced by coercion
>      >>>
>      >>>> In the case of as.integer("-5000000000"), it's not really that the
>      >>>> conversion was "inaccurate", it's a little bit worse than that. And
>      >>>> knowing that NAs where introduced by coercion is important.
>      >>>
>      >>> Yes.
>      >>> The message is less a problem than the bug, but I agree we
>      >>> should try to improve it.
>
>      >> Sounds good. Thanks Martin,
>
>      > I've committed a change to R-devel now, such that also this case
>      > returns NA with a warning, actually for the moment with both the
>      > old warning and the   'NAs introduced by coercion' warning.
>      > The "nice thing" about the old warning is that it explicitly
>      > mentions integer coercion.
>
>      > I currently think we should keep that property, and I'd propose
>      > to completely drop the
>      > "inaccurate integer conversion in coercion"
>      > warning (it is not used anywhere else currently) and replace it
>      > in this and other as.integer(.) cases with
>
>      > 'NAs introduced by integer coercion'
>
>      > (or something similar. ... improvements / proposals are welcome).
>
> Replying to myself:
>
> I've found
>
>       'NAs introduced by coercion to integer range'

I like that we see "coercion *to* integer" instead of just
"integer coercion" because the former indicates the direction
of the coercion. I'm not that convinced with the "range" thing
though. I think

   as.integer(c("78", "a34", "-5000000000"))

should emit only one warning and not try to categorize the
reasons for getting an NA.

Thanks,
H.

>
> to be even more "on spot", and so will commit it for today.
> Of course, amendment proposals are still welcome.
>
> Martin
>
>
>
>      > BTW, the fact that as.integer("-5000000000") did produce an NA
>      > instead of -2147483647 so it would have been compatible with as.integer("5000000000")
>      > was just another coincidence, namely that we "currently" code NA_integer_
>      > by INT_MIN (for 32 bit integers, INT_MIN = 2147483648 = 2^31)
>      > [[but your C code must not rely on that, it is an implementation detail!]]
>
>      > Martin
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From djsamperi at gmail.com  Fri Apr 17 21:09:30 2015
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 17 Apr 2015 15:09:30 -0400
Subject: [Rd] R-3.2.0 Fedora 21 heads up
Message-ID: <CADUbQ5gHmy5iMN-brSSnSCU57UQTV0DVyDOR4nHAgdZjMhy0hg@mail.gmail.com>

FYI, with R-3.2.0 the configure options --with-system-zib=yes
--with-system-bzlib=yes --with-system-pcre=yes become the default
(according to Peter Dalgaard), so the devel versions of these
libraries must be installed under Fedora to prevent unresolved
references.


From pdalgd at gmail.com  Fri Apr 17 21:43:12 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 17 Apr 2015 21:43:12 +0200
Subject: [Rd] R-3.2.0 Fedora 21 heads up
In-Reply-To: <CADUbQ5gHmy5iMN-brSSnSCU57UQTV0DVyDOR4nHAgdZjMhy0hg@mail.gmail.com>
References: <CADUbQ5gHmy5iMN-brSSnSCU57UQTV0DVyDOR4nHAgdZjMhy0hg@mail.gmail.com>
Message-ID: <E3065AC1-2849-444E-8114-EE245E6618C2@gmail.com>


> On 17 Apr 2015, at 21:09 , Dominick Samperi <djsamperi at gmail.com> wrote:
> 
> FYI, with R-3.2.0 the configure options --with-system-zib=yes
> --with-system-bzlib=yes --with-system-pcre=yes become the default
> (according to Peter Dalgaard), so the devel versions of these
> libraries must be installed under Fedora to prevent unresolved
> references.
> 

Also according to the NEWS file, one may add...

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hpages at fredhutch.org  Sat Apr 18 03:05:06 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 17 Apr 2015 18:05:06 -0700
Subject: [Rd] truncated warning messages
Message-ID: <5531ADC2.8000804@fredhutch.org>

Hi,

I was installing hundreds of packages on a machine with a single call to
install.packages() and after a long time the call to install.packages()
finally returned with the following warnings and errors:

Warning messages:
1: packages ?hgu133aprobe?, ?hgu95av2.db?, ?BSgenome.Celegans.UCSC.ce2?, 
?BSgenome.Mmusculus.UCSC.mm10?, 
?BSgenome.Dmelanogaster.UCSC.dm3.masked?, 
?BSgenome.Hsapiens.UCSC.hg18.masked?, 
?BSgenome.Hsapiens.UCSC.hg19.masked?, 
?BSgenome.Mmusculus.UCSC.mm9.masked?, 
?BSgenome.Scerevisiae.UCSC.sacCer2?, ?BSgenome.Hsapiens.NCBI.GRCh38?, 
?BSgenome.Rnorvegicus.UCSC.rn5?, ?drosophila2probe?, ?hgu95av2probe?, 
?hgu95av2cdf?, ?SNPlocs.Hsapiens.dbSNP.20100427?, 
?SNPlocs.Hsapiens.dbSNP.20101109?, ?SNPlocs.Hsapiens.dbSNP.20110815?, 
?SNPlocs.Hsapiens.dbSNP141.GRCh38?, 
?XtraSNPlocs.Hsapiens.dbSNP141.GRCh38?, ?org.Sc.sgd.db?, ?org.Mm.eg.db?, 
?org.At.tair.db?, ?hom.Hs.inp.db?, ?GO.db?, 
?TxDb.Hsapiens.UCSC.hg18.knownGene?, 
?TxDb.Hsapiens.UCSC.hg19.knownGene?, 
?TxDb.Hsapiens.UCSC.hg38.knownGene?, 
?TxDb.Mmusculus.UCSC.mm9.knownGene?, 
?TxDb.Mmusculus.UCSC.mm10.knownGene?, ?TxDb.Dmelanogaster.UCSC. [... 
truncated]
2: In install.packages(pkgs = doing, lib = lib, ...) :
   installation of package ?humanStemCell? had non-zero exit status
3: In install.packages(pkgs = doing, lib = lib, ...) :
   installation of package ?AnnotationForge? had non-zero exit status

As you can see the warning message is truncated so I can't see what
happened to these packages. What about having a message like

   package(s) not available: pkg1, pkg2, pkg3, etc...

so when it's truncated we don't loose the important part of the story?

I guess the same kind of change could be made to the other warning
messages, and, more generally, to any warning/error message obtained
by injecting an arbitrary (and potentially long) list of strings.

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jeroenooms at gmail.com  Sat Apr 18 05:25:58 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Fri, 17 Apr 2015 20:25:58 -0700
Subject: [Rd] truncated warning messages
In-Reply-To: <5531ADC2.8000804@fredhutch.org>
References: <5531ADC2.8000804@fredhutch.org>
Message-ID: <CABFfbXt6FChediGhi7FMsnOGMGaz4cSHGfZkqU_JKMXPuyTt3A@mail.gmail.com>

On Fri, Apr 17, 2015 at 6:05 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> As you can see the warning message is truncated so I can't see what
> happened to these packages.


In this case you could also increase options("warning.length")

	[[alternative HTML version deleted]]


From daroczig at rapporter.net  Sun Apr 19 23:18:29 2015
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Sun, 19 Apr 2015 14:18:29 -0700
Subject: [Rd] quieting the "apparent S3 methods" warning
In-Reply-To: <550C3F7A.8030406@skyeome.net>
References: <550C3F7A.8030406@skyeome.net>
Message-ID: <CAPvvxJUc6M8aHUkOis93=xmMOro1vd9MkdaK6frd0togV3zdcA@mail.gmail.com>

Dear All,

I have a similar issue that I would like to resolve before submitting a new
version of a package to CRAN: I have a "pander" S3 method and a function
called "pander.return", which a wrapper around the first (capturing the
output of "pander"). Now I'm aware of the fact, that it should have been
called rather "pander_return", but this decision was made 3 years ago, and
I cannot rename it without breaking functionality in the depending packages.

Is there any way in the means of added roxygen tag, direct edits to the Rd
or NAMESPACE file so that I can remove the "Found the following apparent S3
methods exported but not registered" NOTE from "R-devel CMD check
--as/cran"?

Thank you,
Gergely

On Fri, Mar 20, 2015 at 8:40 AM, Skye Bender-deMoll <skyebend at skyeome.net>
wrote:

> Dear R-devel,
>  Recent versions of R CMD check have been flagging apparent S3 methods
> that are not registered in the NAMESPACE as such.  In most situations this
> is very helpful.  However, I have few cases in existing packages where we
> have unfortunately named functions using a "." in them that makes them
> appear as S3 methods when they are not.
>
> As there is no existing class corresponding to the last suffix of the
> function, I could quiet the warning by registering the "fake" S3 function,
> but this seems contrary to the intent and not very future-proof.
>
> Is there a way to register methods as "non-S3 methods" so as to block any
> potential S3 dispatch? Or is there any other way to quiet the warning?  In
> the long term, I imagine we can deprecate the function and replace it with
> a better name?
>
> best,
>  -skye
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From ivan.popivanov at gmail.com  Sun Apr 19 23:09:22 2015
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Sun, 19 Apr 2015 21:09:22 +0000
Subject: [Rd] Adding lock capabilities to parallel?
Message-ID: <CAK7-yAgfvK-9cNwNjXr+esoXW8x8JTB6UZ03m=VNQ73C+H3j0Q@mail.gmail.com>

Hello,

Sometime ago I had to solve the problem of writing to common files from
parallel R processes. For the synchronization, I created a small package (
https://r-forge.r-project.org/projects/flock/) to perform a lock/unlock
between different processes. My feeling is that this is something that
belongs to the parallel package.

There is at least one other package (synchronicity -
http://cran.r-project.org/web/packages/synchronicity/index.html) providing
similar (and more) functionality.

Regards,
Ivan

From hpages at fredhutch.org  Mon Apr 20 07:00:09 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Sun, 19 Apr 2015 22:00:09 -0700
Subject: [Rd] truncated warning messages
In-Reply-To: <CABFfbXt6FChediGhi7FMsnOGMGaz4cSHGfZkqU_JKMXPuyTt3A@mail.gmail.com>
References: <5531ADC2.8000804@fredhutch.org>
	<CABFfbXt6FChediGhi7FMsnOGMGaz4cSHGfZkqU_JKMXPuyTt3A@mail.gmail.com>
Message-ID: <553487D9.2010409@fredhutch.org>

On 04/17/2015 08:25 PM, Jeroen Ooms wrote:
>
> On Fri, Apr 17, 2015 at 6:05 PM, Herv? Pag?s <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     As you can see the warning message is truncated so I can't see what
>     happened to these packages.
>
>
> In this case you could also increase options("warning.length")
>

and re-run my install.packages() command (which took about 30 minutes
to run) with the hope that this time I'll be able to see the entire
message? Even setting warning.length to the max (8170 on my machine),
might not be enough. Note that the workaround I used was to re-run
the command on only 1 of the packages listed in the warning message.
That does work and is quick!

Kind of a secondary point to me previous post is that displaying a
listing of thousand of things is not that useful, especially when you
cannot even copy/paste it to re-use at the command line (because of
the fancy quotes). But that's another story...

Cheers,
H.


From pperry at stern.nyu.edu  Mon Apr 20 18:34:26 2015
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Mon, 20 Apr 2015 12:34:26 -0400
Subject: [Rd] Fix for bug in arima function
Message-ID: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>

There is currently a bug in the arima function. Namely, for arima models with differencing or seasonal differencing, the innovation variance estimator uses the wrong denominator whenever xreg is non-null. This is the case, for example, when fitting an ARIMA(p,1,q) model with a drift term (common in financial applications). I reported the bug (and a fix) at https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16278 , but my report may have fallen through the cracks due to the timing around the 3.2.0 release.

The bug was introduced in the patch displayed here:

https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0

The fix is very simple:

https://github.com/patperry/r-source/commit/c1701c05ad91d5631eef196c2007ad9897b01f85

I?ve posted a script that demonstrates the bug at

https://gist.github.com/patperry/90a388b056e09cf6a51b

Please let me know if there?s anything I can do to help get this fix incorporated.


--
Patrick Perry
Assistant Professor
Stern School of Business
New York University


From pdalgd at gmail.com  Tue Apr 21 13:34:43 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Apr 2015 13:34:43 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
Message-ID: <C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>

The bug repository is like an elephant: It doesn't forget, but the gestation period is long.

In the present case, it is clear that something is not right, but someone needs to have sufficient recall and insight to check that your proposed fix is not unfixing a deliberate change. We should get to it eventually. (For some value of "we" not including "me"...)

-pd

On 20 Apr 2015, at 18:34 , Patrick Perry <pperry at stern.nyu.edu> wrote:

> There is currently a bug in the arima function. Namely, for arima models with differencing or seasonal differencing, the innovation variance estimator uses the wrong denominator whenever xreg is non-null. This is the case, for example, when fitting an ARIMA(p,1,q) model with a drift term (common in financial applications). I reported the bug (and a fix) at https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16278 , but my report may have fallen through the cracks due to the timing around the 3.2.0 release.
> 
> The bug was introduced in the patch displayed here:
> 
> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
> 
> The fix is very simple:
> 
> https://github.com/patperry/r-source/commit/c1701c05ad91d5631eef196c2007ad9897b01f85
> 
> I?ve posted a script that demonstrates the bug at
> 
> https://gist.github.com/patperry/90a388b056e09cf6a51b
> 
> Please let me know if there?s anything I can do to help get this fix incorporated.
> 
> 
> --
> Patrick Perry
> Assistant Professor
> Stern School of Business
> New York University
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From howarth.mailing.lists at gmail.com  Tue Apr 21 16:52:52 2015
From: howarth.mailing.lists at gmail.com (Jack Howarth)
Date: Tue, 21 Apr 2015 10:52:52 -0400
Subject: [Rd] Bug 15899 - Omitted 'extern' on 'R_running_as_main_program'
 after refactor can cause linker errors for applications embedding R
Message-ID: <CADtEn-2PtjhiVh+D75pbwCoSstkBsQP0wKdxOw79G=p4amEOWg@mail.gmail.com>

Is there any plans for addressing the regression...

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15899

in the 3.2.1 release? In the fink project, I had to resort to creating a
fixincludes subdirectory containg a local copy of the offending
Rinterface.h header with the missing extern on the declaration of
R_running_as_main_program restored in order to suppress duplicate symbols
during the rstudio build...

https://support.rstudio.com/hc/communities/public/questions/203671967-duplicate-R-running-as-main-program-break-linkage-of-rstudio-desktop-0-98-1103-against-R-3-2-0?locale=en-us

	[[alternative HTML version deleted]]


From andy.jacobson at noaa.gov  Tue Apr 21 19:46:40 2015
From: andy.jacobson at noaa.gov (Andy Jacobson (NOAA Affiliate))
Date: Tue, 21 Apr 2015 11:46:40 -0600
Subject: [Rd] shlib problems with Intel compiler
Message-ID: <9D2F27BD-240B-419F-8C0A-CCC3B1B4D680@noaa.gov>

Hi,

I'm encountering trouble compiling caTools_1.17.1.tar.gz and e1071_1.6-4.tar.gz on a Linux system using the Intel compiler suite.  14 other packages I generally use installed without any trouble.  I notice both of these trouble packages have a C++ component, so I wonder if that might be the issue.  Below, there's information on my platform, compiler, and some diagnostic output showing the errors.

Advice appreciated!

Thanks,

Andy



Intel compiler suite:  icc (ICC) 14.0.2 20140120

sessionInfo() reports:

R version 3.1.3 (2015-03-09)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux Server release 6.5 (Santiago)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.3


Abbreviated versions of the output from R CMD INSTALL:

For caTools:

* installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
* installing *source* package ?caTools? ...
** package ?caTools? successfully unpacked and MD5 sums checked
** libs
icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c Gif2R.cpp -o Gif2R.o
icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c GifTools.cpp -o GifTools.o
icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c runfunc.c -o runfunc.o
icpc -L/usr/local/lib64 -o caTools.so Gif2R.o GifTools.o runfunc.o
/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
(.text+0x20): undefined reference to `main'
Gif2R.o: In function `imwritegif':
/tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:19: undefined reference to `R_chk_calloc'
/tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:23: undefined reference to `R_chk_free'
... (many more R_* undefined references)

For e1071:

* installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
* installing *source* package ?e1071? ...
** package ?e1071? successfully unpacked and MD5 sums checked
checking for C++ compiler default output file name... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether icpc accepts -g... yes
** libs
icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c Rsvm.c -o Rsvm.o
icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cmeans.c -o cmeans.o
icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cshell.c -o cshell.o
icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c floyd.c -o floyd.o
icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c svm.cpp -o svm.o
icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o svm.o
/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
(.text+0x20): undefined reference to `main'
Rsvm.o: In function `do_cross_validation':
/tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:91: undefined reference to `GetRNGstate'
/tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:94: undefined reference to `unif_rand'
/tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:106: undefined reference to `PutRNGstate'
... (many more undefined references)




-- 
Andy Jacobson
andy.jacobson at noaa.gov

NOAA Earth System Research Lab
Global Monitoring Division
325 Broadway R/GMD1
Boulder, Colorado 80305

303/578-2237


From tkeitt at utexas.edu  Tue Apr 21 19:53:05 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Tue, 21 Apr 2015 12:53:05 -0500
Subject: [Rd] Typo in src/scripts/config
Message-ID: <CANnL8gpea-5DrDq3_d0JWvBO3i=NT0Q4+5DoLxe8nfRP-Pw_MQ@mail.gmail.com>

Was writing a short R script to modify compile flags and saw this typo:

Index: config
===================================================================
--- config (revision 68217)
+++ config (working copy)
@@ -61,7 +61,7 @@
   CXX1X         C++ compiler command for C++11 code
   CXX1XSTD      flag used to enable C++11 support
   CXX1XFLAGS    C++11 compiler flags
-  CXX1XXPICFLAGS
+  CXX1XPICFLAGS
                 special flags for compiling C++11 code to be turned into
                 a shared library
   DYLIB_EXT file extension (including '.') for dynamic libraries

-- 
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Apr 21 20:13:51 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Apr 2015 20:13:51 +0200
Subject: [Rd] Typo in src/scripts/config
In-Reply-To: <CANnL8gpea-5DrDq3_d0JWvBO3i=NT0Q4+5DoLxe8nfRP-Pw_MQ@mail.gmail.com>
References: <CANnL8gpea-5DrDq3_d0JWvBO3i=NT0Q4+5DoLxe8nfRP-Pw_MQ@mail.gmail.com>
Message-ID: <4B2ECE76-2656-4265-B886-CC1F89081648@gmail.com>

Fixed in R-patched and R-devel. Thanks.

(In case it wasn't obvious, the typo was in the usage output; there was no actual malfunction.)

-pd

> On 21 Apr 2015, at 19:53 , Tim Keitt <tkeitt at utexas.edu> wrote:
> 
> Was writing a short R script to modify compile flags and saw this typo:
> 
> Index: config
> ===================================================================
> --- config (revision 68217)
> +++ config (working copy)
> @@ -61,7 +61,7 @@
>   CXX1X         C++ compiler command for C++11 code
>   CXX1XSTD      flag used to enable C++11 support
>   CXX1XFLAGS    C++11 compiler flags
> -  CXX1XXPICFLAGS
> +  CXX1XPICFLAGS
>                 special flags for compiling C++11 code to be turned into
>                 a shared library
>   DYLIB_EXT file extension (including '.') for dynamic libraries
> 
> -- 
> http://www.keittlab.org/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luke-tierney at uiowa.edu  Tue Apr 21 21:35:06 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 21 Apr 2015 14:35:06 -0500
Subject: [Rd] RObjectTables freezes in R 3.2.0 RC on 32bit systems
In-Reply-To: <CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>
References: <CABFfbXtH_TLkGTPtFYtvmZvehN1rCXkb8_Ly_g4OJHOmZJK93g@mail.gmail.com>
	<CABFfbXvany5FnEi20aeR6BU2NLB54BLNFZhYJNnnSpVFjeZ0Jg@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1504211433100.2737@luke-Latitude>

Looks like names() never worked on object tables on any platfom; the
failure was just more obvious on 32-bit systems than on 64-bit ones.
This is now fixed in R-devel and R-patched.

Best,

luke

On Wed, 15 Apr 2015, Jeroen Ooms wrote:

> On Tue, Apr 14, 2015 at 6:29 PM, Jeroen Ooms <jeroenooms at gmail.com> wrote:
>> Things work as expected up till dbread(), but once the object-table is
>> attached, R freezes on 32bit whereas it works as expected on 64bit.
>
> Debugging this some more, it looks like the freeze appears at the very
> end of the attach function, when it calls length(names(value)) on the
> newly created object-tables environment. At this stage, calling
> ls(value) gives the expected output, but calling names(value) or
> length(value) triggers the freeze.
>
> The NEWS file does mention that R 3.2.0 introduces some changes to
> names(env) internals. Could it be that this somehow conflicts with the
> object tables hooks?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From bbolker at gmail.com  Wed Apr 22 01:23:04 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Apr 2015 19:23:04 -0400
Subject: [Rd] alternate licensing for package data?
Message-ID: <5536DBD8.7070500@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  Does anyone have speculations about the implications of the GPL for
data included in a package, or more generally for restricting use of data?

  The specific use case is that I have a package which is otherwise
GPL (version unspecified at present).  There are various data sets
included, but they are all essentially in the public domain.  I'm
thinking about including another data set, but the original author of
that data might like to impose some reasonable restrictions (e.g.
please don't use in an academic publication without explicit
permission ...)  Would such rules be expected to be compatible with
CRAN rules?  Will having the package be "GPL except for file XXX, see
LICENSE" mess things up horribly?

  I can of course make the data available for download and include a
link, and/or make a special package that contains only these data, but
it would seem to be more convenient for end users, and more
future-proof, to put everything in one place.

  I know I will eventually need to take this up with CRAN, but I'm
looking for reasonably informed opinions/suggestions ...

  cheers
    Ben Bolker


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVNtvYAAoJEOCV5YRblxUHh90H/0GgmeF1wzRmPYndxYRWXegv
bKlkmibRBvUwfBsv1BzPmiQ08Hs+eZp4NnP6Wh7TigfAZlvkl8hq0rHr/RWzY+XT
Fo8xkeuydVk3vxSdunHpl10gnGDjb845MSigL+W7X587xAY5wmB9+QzuudNaIL2U
URR+jp3OG0Np1mJQX/7lVMi34L71cT7jZKTaBiFLzYJB1x0RvE+xXqGoj+NcNVqA
zYjUWyYCzPfCJJVCI+DsbLUgnWKTYYsWEq1lWabE2HKfqio2pInbQSOtdw6s3VX/
kwvQU4WOhJYHedmzNNsWBnpm04gbIrK71i9FN7Iw5kNQjbsqAN7YPZ6rD1GsjGE=
=Gos/
-----END PGP SIGNATURE-----


From plummerm at iarc.fr  Wed Apr 22 11:02:33 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 22 Apr 2015 09:02:33 +0000
Subject: [Rd] alternate licensing for package data?
In-Reply-To: <5536DBD8.7070500@mcmaster.ca>
References: <5536DBD8.7070500@mcmaster.ca>
Message-ID: <1429693353.24336.15.camel@iarc.fr>

I think this is covered well by the CRAN repository policy:
http://cran.r-project.org/web/packages/policies.html 

The two key license requirements are that: 
1) CRAN must have a perpetual license to distribute the package
2) The package license should be listed here: 
https://svn.r-project.org/R/trunk/share/licenses/license.db
Packages with licenses not included in that list are generally not
accepted.

However, there are exceptions, and you can find some by searching for
"non-commercial site:cran.r-project.org" on Google. See also section
1.1.2 of the Writing R Extensions manual for an explanation.

Personally, I would not want to add the extra complexity to a package
that is otherwise GPL.

Martyn

On Tue, 2015-04-21 at 19:23 -0400, Ben Bolker wrote:
>   Does anyone have speculations about the implications of the GPL for
> data included in a package, or more generally for restricting use of data?
> 
>   The specific use case is that I have a package which is otherwise
> GPL (version unspecified at present).  There are various data sets
> included, but they are all essentially in the public domain.  I'm
> thinking about including another data set, but the original author of
> that data might like to impose some reasonable restrictions (e.g.
> please don't use in an academic publication without explicit
> permission ...)  Would such rules be expected to be compatible with
> CRAN rules?  Will having the package be "GPL except for file XXX, see
> LICENSE" mess things up horribly?
> 
>   I can of course make the data available for download and include a
> link, and/or make a special package that contains only these data, but
> it would seem to be more convenient for end users, and more
> future-proof, to put everything in one place.
> 
>   I know I will eventually need to take this up with CRAN, but I'm
> looking for reasonably informed opinions/suggestions ...
> 
>   cheers
>     Ben Bolker
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From Roger.Bivand at nhh.no  Wed Apr 22 13:34:56 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 22 Apr 2015 11:34:56 +0000
Subject: [Rd] alternate licensing for package data?
References: <5536DBD8.7070500@mcmaster.ca> <1429693353.24336.15.camel@iarc.fr>
Message-ID: <loom.20150422T132021-624@post.gmane.org>

Martyn Plummer <plummerm <at> iarc.fr> writes:

> 
> I think this is covered well by the CRAN repository policy:
> http://cran.r-project.org/web/packages/policies.html 
> 
> The two key license requirements are that: 
> 1) CRAN must have a perpetual license to distribute the package
> 2) The package license should be listed here: 
> https://svn.r-project.org/R/trunk/share/licenses/license.db
> Packages with licenses not included in that list are generally not
> accepted.
> 
...
> 
> Personally, I would not want to add the extra complexity to a package
> that is otherwise GPL.
> 
> Martyn
> 
> On Tue, 2015-04-21 at 19:23 -0400, Ben Bolker wrote:
> >   Does anyone have speculations about the implications of the GPL for
> > data included in a package, or more generally for restricting use of data?
> > 
...
While I agree with Martyn with respect to code, documentation, and
vignettes, the point Ben raises is relevant and not obvious. Data sets in
say GLP-licensed packages are on occasion challenged by Debian packagers
where it isn't obvious that GPL is appropriate. Some spatial packages are
not accepted for packaging as is because of included data, data that is
needed to run realistic examples. 

The problem could be picky packagers, but it is also reasonable that
well-known example data sets could be licensed differently.
share/licenses/license.db lists for example CC BY-SA 4.0 as both FOSS and
extensible but free_and_GPLv3_incompatible. One possibility I examined when
challenged was to place all such data files in a separate package, for
example under a CC license accepted by CRAN - I didn't complete the task,
but understand Ben's question as applying to the same question.

Roger

> > 
> >   cheers
> >     Ben Bolker
> > 
> > 

>


From brian at braverock.com  Wed Apr 22 14:32:58 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 22 Apr 2015 07:32:58 -0500
Subject: [Rd] alternate licensing for package data?
In-Reply-To: <loom.20150422T132021-624@post.gmane.org>
References: <5536DBD8.7070500@mcmaster.ca> <1429693353.24336.15.camel@iarc.fr>
	<loom.20150422T132021-624@post.gmane.org>
Message-ID: <1429705978.14129.16.camel@brian-rcg.priv.dvtrading.co>

On Wed, 2015-04-22 at 11:34 +0000, Roger Bivand wrote:
> Martyn Plummer <plummerm <at> iarc.fr> writes:
> 
> > 
> > I think this is covered well by the CRAN repository policy:
> > http://cran.r-project.org/web/packages/policies.html 
> > 
> > The two key license requirements are that: 
> > 1) CRAN must have a perpetual license to distribute the package
> > 2) The package license should be listed here: 
> > https://svn.r-project.org/R/trunk/share/licenses/license.db
> > Packages with licenses not included in that list are generally not
> > accepted.
> > 
> ...
> > 
> > Personally, I would not want to add the extra complexity to a package
> > that is otherwise GPL.
> > 
> > Martyn
> > 
> > On Tue, 2015-04-21 at 19:23 -0400, Ben Bolker wrote:
> > >   Does anyone have speculations about the implications of the GPL for
> > > data included in a package, or more generally for restricting use of data?
> > > 
> ...
> While I agree with Martyn with respect to code, documentation, and
> vignettes, the point Ben raises is relevant and not obvious. Data sets in
> say GLP-licensed packages are on occasion challenged by Debian packagers
> where it isn't obvious that GPL is appropriate. Some spatial packages are
> not accepted for packaging as is because of included data, data that is
> needed to run realistic examples. 
> 
> The problem could be picky packagers, but it is also reasonable that
> well-known example data sets could be licensed differently.
> share/licenses/license.db lists for example CC BY-SA 4.0 as both FOSS and
> extensible but free_and_GPLv3_incompatible. One possibility I examined when
> challenged was to place all such data files in a separate package, for
> example under a CC license accepted by CRAN - I didn't complete the task,
> but understand Ben's question as applying to the same question.

It is also clearly possible to license data files differently than the
package.  GPL is copyleft for compiled code.  R data files are not
compiled/linked into the package, they are included in a tarball or zip
file.  As such, the copyleft provision of GPL doesn't necessarily apply
to non-compiled files in the package collection, and isn't necessarily
intended to apply (the Gnu licenses page suggests not using GPL for
data).

Whether CRAN or Debian packagers would accept a open but mixed code/data
license scheme is not for me to say, but I don't see any impediments
from the licenses themselves.


-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From maechler at lynne.stat.math.ethz.ch  Wed Apr 22 14:56:46 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Apr 2015 14:56:46 +0200
Subject: [Rd] Bug 15899 - Omitted 'extern' on
 'R_running_as_main_program' after refactor can cause linker errors for
 applications embedding R
In-Reply-To: <CADtEn-2PtjhiVh+D75pbwCoSstkBsQP0wKdxOw79G=p4amEOWg@mail.gmail.com>
References: <CADtEn-2PtjhiVh+D75pbwCoSstkBsQP0wKdxOw79G=p4amEOWg@mail.gmail.com>
Message-ID: <21815.39566.918836.925090@stat.math.ethz.ch>

>>>>> Jack Howarth <howarth.mailing.lists at gmail.com>
>>>>>     on Tue, 21 Apr 2015 10:52:52 -0400 writes:

    > Is there any plans for addressing the regression...
    > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15899

    > in the 3.2.1 release? In the fink project, I had to resort to creating a
    > fixincludes subdirectory containg a local copy of the offending
    > Rinterface.h header with the missing extern on the declaration of

I have addressed it now,  for the moment for R-devel only.
I will port the patch to "R 3.2 patched" (which should become R
3.2.1 eventualy) if there are no problems, issues with it.

Thank you for the reminder.

Martin Maechler


From edd at debian.org  Wed Apr 22 15:29:33 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 22 Apr 2015 08:29:33 -0500
Subject: [Rd] alternate licensing for package data?
In-Reply-To: <loom.20150422T132021-624@post.gmane.org>
References: <5536DBD8.7070500@mcmaster.ca> <1429693353.24336.15.camel@iarc.fr>
	<loom.20150422T132021-624@post.gmane.org>
Message-ID: <21815.41533.407735.131468@max.nulle.part>


On 22 April 2015 at 11:34, Roger Bivand wrote:
| While I agree with Martyn with respect to code, documentation, and
| vignettes, the point Ben raises is relevant and not obvious. Data sets in
| say GLP-licensed packages are on occasion challenged by Debian packagers

Not generally the packagers (who get frustrated by this like everybody else)
but by the "ftp-masters" teams who look over what gets into the Archive. 

They are the license reviewers, and gate-keepers.

In several cases we (ie "packagers") had to write README.sources to document
origins of datasets.  That is generally a little silly as ... R itself
already enforces in the .Rd files. So for the packages where I had to do that
the README.sources effectively becomes a forward reference to the R docs.
But then again the ftp-masters review _thousands_ of packages and having to
help their workflow is a small burden.

In general, nitpicky licensing issue have been discussed (to mindnumbing
length) on the debian-legal list. Those interested in the issue may want to
peruse or search the archive:
    http://news.gmane.org/gmane.linux.debian.devel.legal

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From plummerm at iarc.fr  Wed Apr 22 17:30:22 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 22 Apr 2015 15:30:22 +0000
Subject: [Rd] shlib problems with Intel compiler
In-Reply-To: <9D2F27BD-240B-419F-8C0A-CCC3B1B4D680@noaa.gov>
References: <9D2F27BD-240B-419F-8C0A-CCC3B1B4D680@noaa.gov>
Message-ID: <1429716621.24336.53.camel@iarc.fr>

On Tue, 2015-04-21 at 11:46 -0600, Andy Jacobson (NOAA Affiliate) wrote:
> Hi,
> 
> I'm encountering trouble compiling caTools_1.17.1.tar.gz and
> e1071_1.6-4.tar.gz on a Linux system using the Intel compiler suite.
> 14 other packages I generally use installed without any trouble.  I
> notice both of these trouble packages have a C++ component, so I
> wonder if that might be the issue.  Below, there's information on my
> platform, compiler, and some diagnostic output showing the errors.
> 
> Advice appreciated!
> 
> Thanks,
> 
> Andy

There are two things missing when R tries to create the shared object
file on this line:

icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o
svm.o

Firstly, the compiler flag "-shared" is missing. It tells the compiler
to build a shared object instead of an executable. Secondly the linker
flag "-lR" is missing, along with the "-L" flag that tells the linker
where to find the shared R library.

To find out what went wrong, you should share the configuration you used
when building R.

Martyn

> 
> 
> Intel compiler suite:  icc (ICC) 14.0.2 20140120
> 
> sessionInfo() reports:
> 
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> Running under: Red Hat Enterprise Linux Server release 6.5 (Santiago)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.3
> 
> 
> Abbreviated versions of the output from R CMD INSTALL:
> 
> For caTools:
> 
> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
> * installing *source* package ?caTools? ...
> ** package ?caTools? successfully unpacked and MD5 sums checked
> ** libs
> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c Gif2R.cpp -o Gif2R.o
> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c GifTools.cpp -o GifTools.o
> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c runfunc.c -o runfunc.o
> icpc -L/usr/local/lib64 -o caTools.so Gif2R.o GifTools.o runfunc.o
> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
> (.text+0x20): undefined reference to `main'
> Gif2R.o: In function `imwritegif':
> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:19: undefined reference to `R_chk_calloc'
> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:23: undefined reference to `R_chk_free'
> ... (many more R_* undefined references)
> 
> For e1071:
> 
> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
> * installing *source* package ?e1071? ...
> ** package ?e1071? successfully unpacked and MD5 sums checked
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables... 
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether icpc accepts -g... yes
> ** libs
> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c Rsvm.c -o Rsvm.o
> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cmeans.c -o cmeans.o
> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cshell.c -o cshell.o
> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c floyd.c -o floyd.o
> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c svm.cpp -o svm.o
> icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o svm.o
> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
> (.text+0x20): undefined reference to `main'
> Rsvm.o: In function `do_cross_validation':
> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:91: undefined reference to `GetRNGstate'
> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:94: undefined reference to `unif_rand'
> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:106: undefined reference to `PutRNGstate'
> ... (many more undefined references)
> 
> 
> 
> 


From andy.jacobson at noaa.gov  Wed Apr 22 18:40:19 2015
From: andy.jacobson at noaa.gov (Andy Jacobson (NOAA Affiliate))
Date: Wed, 22 Apr 2015 10:40:19 -0600
Subject: [Rd] shlib problems with Intel compiler
In-Reply-To: <1429716621.24336.53.camel@iarc.fr>
References: <9D2F27BD-240B-419F-8C0A-CCC3B1B4D680@noaa.gov>
	<1429716621.24336.53.camel@iarc.fr>
Message-ID: <4DD36A5A-17CB-4AC8-9935-3C1A89CD683D@noaa.gov>

Hi Martyn,

Thanks for your insight, that seems pretty direct.  Unfortunately, I did not compile this version of R (it's on a large supercomputer system and this version of R was installed by the admins).  Using "R CMD config", I see the following relevant settings:

DYLIB_LD = icc -std=gnu99
DYLIB_LDFLAGS = -shared -openmp
LDFLAGS = -L/opt/compilers/intel/cce/9.1.039/lib -L/opt/compilers/intel/fce/9.1.033/lib -L/usr/local/lib64
SHLIB_CXXLD = icpc
SHLIB_CXXLDFLAGS = 
SHLIB_LD = icc -std=gnu99
SHLIB_LDFLAGS = -shared

It looks like the SHLIB_CXXLDFLAGS is missing the "-shared -lR -L<loc-of-libR>".  It's a mystery to me how R was built and configured such that it has incomplete/incorrect flags.

By trial and error I figured out how to use a .R/Makevars setting to add the required flags to SHLIB_CXXLDFLAGS.  (It sure would have been useful to have a reference about the syntax and variable names that the Makevars file can contain...is that documented somewhere?)

I wonder if the recommendation for "-lR" is correct.  None of the other packages are compiled with that flag, and everything seems to compile and load OK in R without using that.

Best Regards,

Andy

> On Apr 22, 2015, at 9:30 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
> 
> On Tue, 2015-04-21 at 11:46 -0600, Andy Jacobson (NOAA Affiliate) wrote:
>> Hi,
>> 
>> I'm encountering trouble compiling caTools_1.17.1.tar.gz and
>> e1071_1.6-4.tar.gz on a Linux system using the Intel compiler suite.
>> 14 other packages I generally use installed without any trouble.  I
>> notice both of these trouble packages have a C++ component, so I
>> wonder if that might be the issue.  Below, there's information on my
>> platform, compiler, and some diagnostic output showing the errors.
>> 
>> Advice appreciated!
>> 
>> Thanks,
>> 
>> Andy
> 
> There are two things missing when R tries to create the shared object
> file on this line:
> 
> icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o
> svm.o
> 
> Firstly, the compiler flag "-shared" is missing. It tells the compiler
> to build a shared object instead of an executable. Secondly the linker
> flag "-lR" is missing, along with the "-L" flag that tells the linker
> where to find the shared R library.
> 
> To find out what went wrong, you should share the configuration you used
> when building R.
> 
> Martyn
> 
>> 
>> 
>> Intel compiler suite:  icc (ICC) 14.0.2 20140120
>> 
>> sessionInfo() reports:
>> 
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Running under: Red Hat Enterprise Linux Server release 6.5 (Santiago)
>> 
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base     
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.3
>> 
>> 
>> Abbreviated versions of the output from R CMD INSTALL:
>> 
>> For caTools:
>> 
>> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
>> * installing *source* package ?caTools? ...
>> ** package ?caTools? successfully unpacked and MD5 sums checked
>> ** libs
>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c Gif2R.cpp -o Gif2R.o
>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c GifTools.cpp -o GifTools.o
>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c runfunc.c -o runfunc.o
>> icpc -L/usr/local/lib64 -o caTools.so Gif2R.o GifTools.o runfunc.o
>> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
>> (.text+0x20): undefined reference to `main'
>> Gif2R.o: In function `imwritegif':
>> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:19: undefined reference to `R_chk_calloc'
>> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:23: undefined reference to `R_chk_free'
>> ... (many more R_* undefined references)
>> 
>> For e1071:
>> 
>> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
>> * installing *source* package ?e1071? ...
>> ** package ?e1071? successfully unpacked and MD5 sums checked
>> checking for C++ compiler default output file name... a.out
>> checking whether the C++ compiler works... yes
>> checking whether we are cross compiling... no
>> checking for suffix of executables... 
>> checking for suffix of object files... o
>> checking whether we are using the GNU C++ compiler... yes
>> checking whether icpc accepts -g... yes
>> ** libs
>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c Rsvm.c -o Rsvm.o
>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cmeans.c -o cmeans.o
>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cshell.c -o cshell.o
>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c floyd.c -o floyd.o
>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c svm.cpp -o svm.o
>> icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o svm.o
>> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
>> (.text+0x20): undefined reference to `main'
>> Rsvm.o: In function `do_cross_validation':
>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:91: undefined reference to `GetRNGstate'
>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:94: undefined reference to `unif_rand'
>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:106: undefined reference to `PutRNGstate'
>> ... (many more undefined references)
>> 
>> 
>> 
>> 
> 

-- 
Andy Jacobson
andy.jacobson at noaa.gov

NOAA Earth System Research Lab
Global Monitoring Division
325 Broadway R/GMD1
Boulder, Colorado 80305

303/578-2237


From plummerm at iarc.fr  Wed Apr 22 19:01:48 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 22 Apr 2015 17:01:48 +0000
Subject: [Rd] shlib problems with Intel compiler
In-Reply-To: <4DD36A5A-17CB-4AC8-9935-3C1A89CD683D@noaa.gov>
References: <9D2F27BD-240B-419F-8C0A-CCC3B1B4D680@noaa.gov>
	<1429716621.24336.53.camel@iarc.fr>,
	<4DD36A5A-17CB-4AC8-9935-3C1A89CD683D@noaa.gov>
Message-ID: <99C26525-2F66-44DB-B17B-63E5B86846B3@iarc.fr>

I was assuming that R was configured with --enable-R-shlib but if that's not the case then you don't need it.

Martyn


> On 22 Apr 2015, at 18:40, Andy Jacobson (NOAA Affiliate) <andy.jacobson at noaa.gov> wrote:
> 
> Hi Martyn,
> 
> Thanks for your insight, that seems pretty direct.  Unfortunately, I did not compile this version of R (it's on a large supercomputer system and this version of R was installed by the admins).  Using "R CMD config", I see the following relevant settings:
> 
> DYLIB_LD = icc -std=gnu99
> DYLIB_LDFLAGS = -shared -openmp
> LDFLAGS = -L/opt/compilers/intel/cce/9.1.039/lib -L/opt/compilers/intel/fce/9.1.033/lib -L/usr/local/lib64
> SHLIB_CXXLD = icpc
> SHLIB_CXXLDFLAGS = 
> SHLIB_LD = icc -std=gnu99
> SHLIB_LDFLAGS = -shared
> 
> It looks like the SHLIB_CXXLDFLAGS is missing the "-shared -lR -L<loc-of-libR>".  It's a mystery to me how R was built and configured such that it has incomplete/incorrect flags.
> 
> By trial and error I figured out how to use a .R/Makevars setting to add the required flags to SHLIB_CXXLDFLAGS.  (It sure would have been useful to have a reference about the syntax and variable names that the Makevars file can contain...is that documented somewhere?)
> 
> I wonder if the recommendation for "-lR" is correct.  None of the other packages are compiled with that flag, and everything seems to compile and load OK in R without using that.
> 
> Best Regards,
> 
> Andy
> 
>> On Apr 22, 2015, at 9:30 AM, Martyn Plummer <plummerm at iarc.fr> wrote:
>> 
>> On Tue, 2015-04-21 at 11:46 -0600, Andy Jacobson (NOAA Affiliate) wrote:
>>> Hi,
>>> 
>>> I'm encountering trouble compiling caTools_1.17.1.tar.gz and
>>> e1071_1.6-4.tar.gz on a Linux system using the Intel compiler suite.
>>> 14 other packages I generally use installed without any trouble.  I
>>> notice both of these trouble packages have a C++ component, so I
>>> wonder if that might be the issue.  Below, there's information on my
>>> platform, compiler, and some diagnostic output showing the errors.
>>> 
>>> Advice appreciated!
>>> 
>>> Thanks,
>>> 
>>> Andy
>> 
>> There are two things missing when R tries to create the shared object
>> file on this line:
>> 
>> icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o
>> svm.o
>> 
>> Firstly, the compiler flag "-shared" is missing. It tells the compiler
>> to build a shared object instead of an executable. Secondly the linker
>> flag "-lR" is missing, along with the "-L" flag that tells the linker
>> where to find the shared R library.
>> 
>> To find out what went wrong, you should share the configuration you used
>> when building R.
>> 
>> Martyn
>> 
>>> 
>>> 
>>> Intel compiler suite:  icc (ICC) 14.0.2 20140120
>>> 
>>> sessionInfo() reports:
>>> 
>>> R version 3.1.3 (2015-03-09)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>> Running under: Red Hat Enterprise Linux Server release 6.5 (Santiago)
>>> 
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base     
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.1.3
>>> 
>>> 
>>> Abbreviated versions of the output from R CMD INSTALL:
>>> 
>>> For caTools:
>>> 
>>> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
>>> * installing *source* package ?caTools? ...
>>> ** package ?caTools? successfully unpacked and MD5 sums checked
>>> ** libs
>>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c Gif2R.cpp -o Gif2R.o
>>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c GifTools.cpp -o GifTools.o
>>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c runfunc.c -o runfunc.o
>>> icpc -L/usr/local/lib64 -o caTools.so Gif2R.o GifTools.o runfunc.o
>>> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
>>> (.text+0x20): undefined reference to `main'
>>> Gif2R.o: In function `imwritegif':
>>> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:19: undefined reference to `R_chk_calloc'
>>> /tmp/RtmpEfnBsm/R.INSTALL17c3a7327d4fb/caTools/src/Gif2R.cpp:23: undefined reference to `R_chk_free'
>>> ... (many more R_* undefined references)
>>> 
>>> For e1071:
>>> 
>>> * installing to library ?/scratch3/BMC/co2/lib/R-3.1/x86_64-unknown-linux-gnu?
>>> * installing *source* package ?e1071? ...
>>> ** package ?e1071? successfully unpacked and MD5 sums checked
>>> checking for C++ compiler default output file name... a.out
>>> checking whether the C++ compiler works... yes
>>> checking whether we are cross compiling... no
>>> checking for suffix of executables... 
>>> checking for suffix of object files... o
>>> checking whether we are using the GNU C++ compiler... yes
>>> checking whether icpc accepts -g... yes
>>> ** libs
>>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c Rsvm.c -o Rsvm.o
>>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cmeans.c -o cmeans.o
>>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c cshell.c -o cshell.o
>>> icc -std=gnu99 -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -wd188 -ip -fp-model precise  -c floyd.c -o floyd.o
>>> icpc -I/apps/R/3.1.3-intel/lib64/R/include -DNDEBUG  -I/usr/local/include    -fpic  -g -O3 -fp-model precise  -c svm.cpp -o svm.o
>>> icpc -L/usr/local/lib64 -o e1071.so Rsvm.o cmeans.o cshell.o floyd.o svm.o
>>> /usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../lib64/crt1.o: In function `_start':
>>> (.text+0x20): undefined reference to `main'
>>> Rsvm.o: In function `do_cross_validation':
>>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:91: undefined reference to `GetRNGstate'
>>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:94: undefined reference to `unif_rand'
>>> /tmp/Rtmp9h7iYE/R.INSTALL1d9615a42180e/e1071/src/Rsvm.c:106: undefined reference to `PutRNGstate'
>>> ... (many more undefined references)
> 
> -- 
> Andy Jacobson
> andy.jacobson at noaa.gov
> 
> NOAA Earth System Research Lab
> Global Monitoring Division
> 325 Broadway R/GMD1
> Boulder, Colorado 80305
> 
> 303/578-2237
> 
> 
> 
> 
> 
> 
-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From bbolker at gmail.com  Wed Apr 22 22:49:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Apr 2015 20:49:45 +0000
Subject: [Rd] alternate licensing for package data?
References: <5536DBD8.7070500@mcmaster.ca> <1429693353.24336.15.camel@iarc.fr>
	<loom.20150422T132021-624@post.gmane.org>
	<21815.41533.407735.131468@max.nulle.part>
Message-ID: <loom.20150422T224135-91@post.gmane.org>

Dirk Eddelbuettel <edd <at> debian.org> writes:

> On 22 April 2015 at 11:34, Roger Bivand wrote:
> | While I agree with Martyn with respect to code, documentation, and
> | vignettes, the point Ben raises is relevant and not obvious. Data sets in
> | say GLP-licensed packages are on occasion challenged by Debian packagers

        [GPL]
 
> Not generally the packagers (who get frustrated by this like everybody else)
> but by the "ftp-masters" teams who look over what gets into the Archive. 
> 
> They are the license reviewers, and gate-keepers.
> 
> In several cases we (ie "packagers") had to write README.sources to document
> origins of datasets.  That is generally a little silly as ... R itself
> already enforces in the .Rd files. So for the packages where I had to do that
> the README.sources effectively becomes a forward reference to the R docs.
> But then again the ftp-masters review _thousands_ of packages and having to
> help their workflow is a small burden.
> 
> In general, nitpicky licensing issue have been discussed (to mindnumbing
> length) on the debian-legal list. Those interested in the issue may want to
> peruse or search the archive:
>     http://news.gmane.org/gmane.linux.debian.devel.legal
> 
> Dirk

Thanks for the information, everyone!  I think I'm just going to
handle it the sloppy way, providing a .Rd file containing
documentation and a URL for the data set.  This is not particularly
good for long-term maintenance, but it seems silly to try to get a
separate package onto CRAN for a *single* (small) data set.

  For what it's worth, I've been informed by the CRAN maintainers
that 

> 'license' is singular in the CRAN policies, something people
  sometimes overlook.
> A package must have a single licence that applies to all of the
  package (even if alternative licences are offered for all or part),
  so "GPL except for file XXX" is not viable.


From avraham.adler at gmail.com  Wed Apr 22 23:15:16 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Wed, 22 Apr 2015 17:15:16 -0400
Subject: [Rd] alternate licensing for package data?
In-Reply-To: <loom.20150422T224135-91@post.gmane.org>
References: <5536DBD8.7070500@mcmaster.ca> <1429693353.24336.15.camel@iarc.fr>
	<loom.20150422T132021-624@post.gmane.org>
	<21815.41533.407735.131468@max.nulle.part>
	<loom.20150422T224135-91@post.gmane.org>
Message-ID: <CAL6gwn+vJMo6Ys47e_bV9=3n7+jQkD-bB98fKg_DHCJsBmqWTw@mail.gmail.com>

To get around this last problem, perhaps you can take advantage of
CRAN's suggestion regarding large data files [1] where they say
"[w]here a large amount of data is required (even after compression),
consideration should be given to a separate data-only package which
can be updated only rarely (since older versions of packages are
archived in perpetuity)." This would allow you to have a different
license for the data package than for the main package. Whether CRAN
will except a file + LICENSE with "please only use academically" or a
CC-BY-NC, is a different question.

Avi

[1] <http://cran.r-project.org/web/packages/policies.html#Source-packages>

On Wed, Apr 22, 2015 at 4:49 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Dirk Eddelbuettel <edd <at> debian.org> writes:
>
>> On 22 April 2015 at 11:34, Roger Bivand wrote:
>> | While I agree with Martyn with respect to code, documentation, and
>> | vignettes, the point Ben raises is relevant and not obvious. Data sets in
>> | say GLP-licensed packages are on occasion challenged by Debian packagers
>
>         [GPL]
>
>> Not generally the packagers (who get frustrated by this like everybody else)
>> but by the "ftp-masters" teams who look over what gets into the Archive.
>>
>> They are the license reviewers, and gate-keepers.
>>
>> In several cases we (ie "packagers") had to write README.sources to document
>> origins of datasets.  That is generally a little silly as ... R itself
>> already enforces in the .Rd files. So for the packages where I had to do that
>> the README.sources effectively becomes a forward reference to the R docs.
>> But then again the ftp-masters review _thousands_ of packages and having to
>> help their workflow is a small burden.
>>
>> In general, nitpicky licensing issue have been discussed (to mindnumbing
>> length) on the debian-legal list. Those interested in the issue may want to
>> peruse or search the archive:
>>     http://news.gmane.org/gmane.linux.debian.devel.legal
>>
>> Dirk
>
> Thanks for the information, everyone!  I think I'm just going to
> handle it the sloppy way, providing a .Rd file containing
> documentation and a URL for the data set.  This is not particularly
> good for long-term maintenance, but it seems silly to try to get a
> separate package onto CRAN for a *single* (small) data set.
>
>   For what it's worth, I've been informed by the CRAN maintainers
> that
>
>> 'license' is singular in the CRAN policies, something people
>   sometimes overlook.
>> A package must have a single licence that applies to all of the
>   package (even if alternative licences are offered for all or part),
>   so "GPL except for file XXX" is not viable.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Thu Apr 23 18:58:14 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 23 Apr 2015 11:58:14 -0500
Subject: [Rd] model frames and update()
Message-ID: <2f3a88$gj54c@ironport10.mayo.edu>

This issue has arisen within my anova.coxph routine, but is as easily illustrated with glm.

testdata <- data.frame(y= 1:5,
                        n= c(8,10,6,20,14),
                        sex = c(0,1,0,1,1),
                        age = c(30,20,35,25,40))

fit <- glm(cbind(y,n) ~ age + sex, binomial, data=testdata, model=TRUE)
saveit <- fit$model

update(fit, .~. - age, data=saveit)
Error in cbind(y, n) : object 'y' not found

One would hope that a saved model frame is precisely the thing that would work best. The 
issue of course is that "cbind(y, n)" is the name of the first variable in saveit, and it 
is not being properly quoted somewhere down the line.  The same issue can occur on the 
right hand side.  "Save the model frame in case you need to refit something next month" is 
does not appear to be a safe approach to reproducable research.

fit2 <- glm(y ~ sex + log(age), poisson, testdata)
save2 <- fit2$model
update(fit2, . ~ . - sex, data=save2)  # fails
glm(y ~ log(age), poisson, save2)      # fails


I can work around this in my anova, but I wanted to not rebuild the frame if it is already 
present.   It looks like model.matrix plus attr(x, 'assign') time -- a bit harder to read, 
but that looks like what anova.glm is doing.  Is there a way to make update work?

The current code, BTW, starts by building its own frame using results of terms.inner, 
which solves the above issue nicely and update() works as expected.  But it isn't robust 
to scoping issues.  (As pointed out yesterday by a user: lapply of a function that 
contained coxph followed by anova gives a variable not found error.)  It also ignores 
saved model frames; thus the rewrite.

Terry T


From edd at debian.org  Thu Apr 23 21:52:20 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Apr 2015 14:52:20 -0500
Subject: [Rd] CRAN submit page down
Message-ID: <21817.19828.808634.260781@max.nulle.part>


Andrie noticed that first, and I can confirm: from our end, it looks as if
the backend to http://cran.r-project.org/submit.html is currently down.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wdunlap at tibco.com  Thu Apr 23 22:24:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Apr 2015 13:24:16 -0700
Subject: [Rd] model frames and update()
In-Reply-To: <2f3a88$gj54c@ironport10.mayo.edu>
References: <2f3a88$gj54c@ironport10.mayo.edu>
Message-ID: <CAF8bMcbmqedKvw8h9fQZD7H2P-7XvbB0zQKC=knU4CPYNg6S3Q@mail.gmail.com>

> "Save the model frame in case you need to refit something next month"
> does not appear to be a safe approach to reproducible research.

Is this a standard recommendation?  It will not work in many cases.  E.g.,
if
you use lm() to model the sum of some variables the model.frame contains
only the sum, not the addends so you cannot later change an addend and refit
the model.
  > d <- data.frame(y1=1:5,y2=sin(1:5),x1=log(1:5))
  > fit <- lm(y1+y2 ~ x1, data=d, model=TRUE)
  > fit$model
     y1 + y2        x1
  1 1.841471 0.0000000
  2 2.909297 0.6931472
  3 3.141120 1.0986123
  4 3.243198 1.3862944
  5 4.041076 1.6094379
(The same happens if you use a function like abs(x) on
the right side of the formula.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 23, 2015 at 9:58 AM, Therneau, Terry M., Ph.D. <
therneau at mayo.edu> wrote:

> This issue has arisen within my anova.coxph routine, but is as easily
> illustrated with glm.
>
> testdata <- data.frame(y= 1:5,
>                        n= c(8,10,6,20,14),
>                        sex = c(0,1,0,1,1),
>                        age = c(30,20,35,25,40))
>
> fit <- glm(cbind(y,n) ~ age + sex, binomial, data=testdata, model=TRUE)
> saveit <- fit$model
>
> update(fit, .~. - age, data=saveit)
> Error in cbind(y, n) : object 'y' not found
>
> One would hope that a saved model frame is precisely the thing that would
> work best. The issue of course is that "cbind(y, n)" is the name of the
> first variable in saveit, and it is not being properly quoted somewhere
> down the line.  The same issue can occur on the right hand side.  "Save the
> model frame in case you need to refit something next month" is does not
> appear to be a safe approach to reproducable research.
>
> fit2 <- glm(y ~ sex + log(age), poisson, testdata)
> save2 <- fit2$model
> update(fit2, . ~ . - sex, data=save2)  # fails
> glm(y ~ log(age), poisson, save2)      # fails
>
>
> I can work around this in my anova, but I wanted to not rebuild the frame
> if it is already present.   It looks like model.matrix plus attr(x,
> 'assign') time -- a bit harder to read, but that looks like what anova.glm
> is doing.  Is there a way to make update work?
>
> The current code, BTW, starts by building its own frame using results of
> terms.inner, which solves the above issue nicely and update() works as
> expected.  But it isn't robust to scoping issues.  (As pointed out
> yesterday by a user: lapply of a function that contained coxph followed by
> anova gives a variable not found error.)  It also ignores saved model
> frames; thus the rewrite.
>
> Terry T
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Apr 23 22:24:36 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Apr 2015 20:24:36 +0000
Subject: [Rd] model frames and update()
References: <2f3a88$gj54c@ironport10.mayo.edu>
Message-ID: <loom.20150423T215957-898@post.gmane.org>

Therneau, Terry M., Ph.D. <therneau <at> mayo.edu> writes:

>  This issue has arisen within my anova.coxph routine, but is as
> easily illustrated with glm.
 
> testdata <- data.frame(y= 1:5,
>                         n= c(8,10,6,20,14),
>                         sex = c(0,1,0,1,1),
>                         age = c(30,20,35,25,40))
> 
> fit <- glm(cbind(y,n) ~ age + sex, binomial, data=testdata, model=TRUE)
> saveit <- fit$model
> 
> update(fit, .~. - age, data=saveit)
> Error in cbind(y, n) : object 'y' not found
 
> One would hope that a saved model frame is precisely the thing that
> would work best. The issue of course is that "cbind(y, n)" is the
> name of the first variable in saveit, and it is not being properly
> quoted somewhere down the line.  The same issue can occur on the
> right hand side.  "Save the model frame in case you need to refit
> something next month" is does not appear to be a safe approach to
> reproducable research.
 
> fit2 <- glm(y ~ sex + log(age), poisson, testdata)
> save2 <- fit2$model
> update(fit2, . ~ . - sex, data=save2)  # fails
> glm(y ~ log(age), poisson, save2)      # fails
 
> I can work around this in my anova, but I wanted to not rebuild the
> frame if it is already present.  It looks like model.matrix plus
> attr(x, 'assign') time -- a bit harder to read, but that looks like
> what anova.glm is doing.  Is there a way to make update work?
 
> The current code, BTW, starts by building its own frame using
> results of terms.inner, which solves the above issue nicely and
> update() works as expected.  But it isn't robust to scoping issues.
> (As pointed out yesterday by a user: lapply of a function that
> contained coxph followed by anova gives a variable not found error.)
> It also ignores saved model frames; thus the rewrite.  Terry T
 
I started to complain about this sort of thing last month, at

http://article.gmane.org/gmane.comp.lang.r.devel/37805

I was speaking of updating more generally (which might change
anything, not just the formula), but I complained that

   * we could try to use the model frame (which is stored already),
but there are issues with this (the basis of a whole separate rant)
because the model frame stores something in between predictor
variables and input variables. For example

   d <- data.frame(y=1:10,x=runif(10))
   names(model.frame(lm(y~log(x),data=d)))
   ## "y" "log(x)"

So if we wanted to do something like update to "y ~ sqrt(x)",
it wouldn't work ...

  A mini-version of that rant is that I find the model frame structure
quite awkward -- it contains neither what I would call _input_
variables (actual measured things that live in columns in the original
data frame) nor _predictor_ variables (columns associated with
parameters in the model, i.e. columns of the model matrix).  It seems
to me that life would be much easier if the model frame contained just
the intersection of all.vars(formula) with the column names of the
original data set (and with NA values dropped according to
na.action()). I appreciate that this is a potentially difficult design
problem with ramifications that I don't understand, but ... Martin
Maechler tried to explain the rationale for the design to me once, but
I didn't manage to understand his argument (so I have since forgotten
it).

On the other end, it would be nice (in some dream world) to have
the capability to associate a model with a *reference* to a model
frame; consider the situation where one is fitting 10 or 20 different
models to a large data set, ending up with many copies (I'm not
100% sure, but I think that using model.frame() will end up creating
an internal copy of the data even if it's not technically modified)
of the same gigantic data ...

  Ben Bolker


From Achim.Zeileis at uibk.ac.at  Thu Apr 23 22:28:59 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 23 Apr 2015 22:28:59 +0200 (CEST)
Subject: [Rd] model frames and update()
In-Reply-To: <2f3a88$gj54c@ironport10.mayo.edu>
References: <2f3a88$gj54c@ironport10.mayo.edu>
Message-ID: <alpine.DEB.2.11.1504232211550.1677@paninaro.uibk.ac.at>

On Thu, 23 Apr 2015, Therneau, Terry M., Ph.D. wrote:

> This issue has arisen within my anova.coxph routine, but is as easily 
> illustrated with glm.
>
> testdata <- data.frame(y= 1:5,
>                       n= c(8,10,6,20,14),
>                       sex = c(0,1,0,1,1),
>                       age = c(30,20,35,25,40))
>
> fit <- glm(cbind(y,n) ~ age + sex, binomial, data=testdata, model=TRUE)
> saveit <- fit$model
>
> update(fit, .~. - age, data=saveit)
> Error in cbind(y, n) : object 'y' not found
>
> One would hope that a saved model frame is precisely the thing that 
> would work best. The issue of course is that "cbind(y, n)" is the name 
> of the first variable in saveit, and it is not being properly quoted 
> somewhere down the line.  The same issue can occur on the right hand 
> side.  "Save the model frame in case you need to refit something next 
> month" is does not appear to be a safe approach to reproducable 
> research.

If you want to re-run the same call (which is what the default update 
method does), then you need to save the original data not the 
pre-processed model frame. However, the model frame still has all the 
information you need - but has already evaluated all transformations 
(cbind, log, etc.).

> fit2 <- glm(y ~ sex + log(age), poisson, testdata)
> save2 <- fit2$model
> update(fit2, . ~ . - sex, data=save2)  # fails
> glm(y ~ log(age), poisson, save2)      # fails
>
> I can work around this in my anova, but I wanted to not rebuild the 
> frame if it is already present.  It looks like model.matrix plus attr(x, 
> 'assign') time -- a bit harder to read, but that looks like what 
> anova.glm is doing. Is there a way to make update work?

If you have the model.frame() plus an update formula you could internally 
extract the response, model matrix and weights, e.g.,

## original fit
fit <- glm(cbind(y,n) ~ log(age) + sex, family = binomial,
   data = testdata)

## original model frame
mf <- fit$model

## update formula
up <- . ~ . - sex

## new terms
mt <- update(terms(mf), up)

## response y, matrix x, weights w (NULL here)
y <- model.response(mf)
x <- model.matrix(mt, mf)
w <- model.weights(mf)
## offset could be added similarly

And then you can call glm.fit() or coxph.fit() if you can get the family 
from the original fit.

One should still check that the update formula does not change the 
response (to something which may or may not exist in the model frame). 
Possibly, one could try to get certain control arguments from the original 
glm fit (but probably not 'start').

Maybe this helps... (But I can understand that the issues of data frame 
vs. model frame can be quite a nuisance when programming model utilities 
:))

> The current code, BTW, starts by building its own frame using results of 
> terms.inner, which solves the above issue nicely and update() works as 
> expected.  But it isn't robust to scoping issues.  (As pointed out 
> yesterday by a user: lapply of a function that contained coxph followed 
> by anova gives a variable not found error.)  It also ignores saved model 
> frames; thus the rewrite.
>
> Terry T
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at lynne.stat.math.ethz.ch  Fri Apr 24 12:06:23 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Apr 2015 12:06:23 +0200
Subject: [Rd] Development version of R: Improved nchar(),
	nzchar() but changed API
Message-ID: <21818.5535.219883.604245@stat.math.ethz.ch>

Those of you who track R development closely,
will have noticed yesterday's commit of enhanced versions of 
nchar() and nzchar().

------------------------------------------------------------------------
r68254 | maechler | 2015-04-23 18:06:37 +0200 (Thu, 23 Apr 2015) | 1 line
Changed paths:
   M doc/NEWS.Rd
   M src/library/base/R/New-Internal.R
   M src/library/base/R/zzz.R
   M src/library/base/man/nchar.Rd
   M src/main/character.c
   M src/main/names.c
   M tests/reg-tests-1a.R

nchar(x) now gives NA for character NAs, configurably via nchar(x, keepNA=*); analogously for nzchar()
------------------------------------------------------------------------

Enhanced via the new argument  'keepNA' (a logical, i.e., TRUE/FALSE/NA),
but also *not* backward compatible in the current
implementation.  Here's how it works [currently], showing the (input and output
of the slightly abridged) example(nchar):

> x <- c("asfef", "qwerty", "yuiop[", "b", "stuff.blah.yech")
> x[3] <- NA; x
[1] "asfef"           "qwerty"          NA                "b"              
[5] "stuff.blah.yech"
> nchar(x, keepNA= TRUE) #  5  6 NA  1 15
[1]  5  6 NA  1 15
> nchar(x, keepNA=FALSE) #  5  6  2  1 15
[1]  5  6  2  1 15
> stopifnot(identical(nchar(x     ), nchar(x, keepNA= TRUE)),
            identical(nchar(x, "w"), nchar(x, keepNA=FALSE)))
> 

The main reason for the change: it is more logical
that  NA_character_ in x  are transformed to  NA_integer_ in the result,
which is what happens with 'keepNA = TRUE', which can be
translated as "keep/preserve the NA's that were in x (the main argument)".

If you use  nchar(x, type = "words"),  or its short form  nchar(x, "w")
you implicitly ask for  'keepNA = FALSE',
because "words" is about output / formatting / etc, and there,
you'd typically want 

        nchar(c("ABC", NA),  "words") 

to give      3  2   -- which is what happens unconditionally in R <= 3.2.0.

We've found quite a few CRAN packages to "break" (R CMD check)
for R-devel r68254, because I had clearly underestimated the
number of places where current R code was built on assuming the
"pre-R-devel" (aka "current R") semantics of nchar() and
nzchar() which for R <= 3.2.0 say

  Value: 
       For ?nchar?, an integer vector giving the sizes of each element,
       __currently__ always ?2? for missing values (for ?NA?).

 (my emphasis added to  "currently").

As package authors, when using R-devel you may wait a day when
you see problems with R-devel (that you don't see with R 3.2.0),
but you should become aware of the slightly changed semantics of
nchar() and nzchar().

Longer term, the change should have made R more "internally coherent",
namely vectorized R functions preserving NA's by default.

Martin Maechler,
ETH Zurich


From therneau at mayo.edu  Fri Apr 24 14:42:22 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 24 Apr 2015 07:42:22 -0500
Subject: [Rd] model.frames and update
In-Reply-To: <mailman.27.1429869606.22958.r-devel@r-project.org>
References: <mailman.27.1429869606.22958.r-devel@r-project.org>
Message-ID: <2f3a88$go6a0@ironport10.mayo.edu>

I've gotton some good responses; thanks for the input. I'll proceed with my repairs down 
another path.

An underlying question then is "if the model frame is near useless, as the responses 
indicate, then why do all the standard methods save it (lm, glm, ..)"?   I suspect the 
answer is that it helps hide (some of) the negative consquences of how formulas are scoped.

Terry T.



On 04/24/2015 05:00 AM, r-devel-request at r-project.org wrote:
> I started to complain about this sort of thing last month, at
>
> http://article.gmane.org/gmane.comp.lang.r.devel/37805
>
> I was speaking of updating more generally (which might change
> anything, not just the formula), but I complained that
>
>     * we could try to use the model frame (which is stored already),
> but there are issues with this (the basis of a whole separate rant)
> because the model frame stores something in between predictor
> variables and input variables. For example
>
>     d <- data.frame(y=1:10,x=runif(10))
>     names(model.frame(lm(y~log(x),data=d)))
>     ## "y" "log(x)"
>
> So if we wanted to do something like update to "y ~ sqrt(x)",
> it wouldn't work ...


From gokcen.eraslan at gmail.com  Fri Apr 24 14:02:51 2015
From: gokcen.eraslan at gmail.com (=?UTF-8?B?R8O2a8OnZW4gRXJhc2xhbg==?=)
Date: Fri, 24 Apr 2015 14:02:51 +0200
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <21818.5535.219883.604245@stat.math.ethz.ch>
References: <21818.5535.219883.604245@stat.math.ethz.ch>
Message-ID: <553A30EB.1040809@gmail.com>

Hi,

On 2015-04-24 12:06, Martin Maechler wrote:
> Those of you who track R development closely,

I don't want to hijack the thread but is there an easy way to track R 
commits via e.g. an r-commits mail list (like this[1]) driven by a 
subversion post-commit hook script? It would be quite nice for those who 
want to follow every commit on daily basis.

> will have noticed yesterday's commit of enhanced versions of
> nchar() and nzchar().
>
>
>...
 >
> Martin Maechler,
> ETH Zurich
>

[1] https://mail.python.org/pipermail/python-checkins/2015-April/thread.html

Goekcen.


From csardi.gabor at gmail.com  Fri Apr 24 15:34:59 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 24 Apr 2015 09:34:59 -0400
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <553A30EB.1040809@gmail.com>
References: <21818.5535.219883.604245@stat.math.ethz.ch>
	<553A30EB.1040809@gmail.com>
Message-ID: <CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>

On Fri, Apr 24, 2015 at 8:02 AM, G?k?en Eraslan <gokcen.eraslan at gmail.com>
wrote:
[...]

> I don't want to hijack the thread but is there an easy way to track R
> commits via e.g. an r-commits mail list (like this[1]) driven by a
> subversion post-commit hook script? It would be quite nice for those who
> want to follow every commit on daily basis.
>

You can watch (see 'Watch" on top right) this repo:
https://github.com/wch/r-source

Gabor

[...]

	[[alternative HTML version deleted]]


From gokcen.eraslan at gmail.com  Fri Apr 24 15:59:09 2015
From: gokcen.eraslan at gmail.com (=?UTF-8?B?R8O2a8OnZW4gRXJhc2xhbg==?=)
Date: Fri, 24 Apr 2015 15:59:09 +0200
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
References: <21818.5535.219883.604245@stat.math.ethz.ch>	<553A30EB.1040809@gmail.com>
	<CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
Message-ID: <553A4C2D.9010901@gmail.com>

Hi,

On 2015-04-24 15:34, G?bor Cs?rdi wrote:
> On Fri, Apr 24, 2015 at 8:02 AM, G?k?en Eraslan
> <gokcen.eraslan at gmail.com <mailto:gokcen.eraslan at gmail.com>> wrote:
> [...]
>
>     I don't want to hijack the thread but is there an easy way to track
>     R commits via e.g. an r-commits mail list (like this[1]) driven by a
>     subversion post-commit hook script? It would be quite nice for those
>     who want to follow every commit on daily basis.
>
>
> You can watch (see 'Watch" on top right) this repo:
> https://github.com/wch/r-source
>

But "Watch" only notifies when there are new pull requests and issues, 
which doesn't make sense for the r-source repository. Following Github 
Atom feed[1] sounds better, however the feed only provides commit 
messages not the diffs.

Goekcen.

> Gabor
>
> [...]


[1] https://github.com/wch/r-source/commits/trunk.atom


From csardi.gabor at gmail.com  Fri Apr 24 16:08:57 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 24 Apr 2015 10:08:57 -0400
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <553A4C2D.9010901@gmail.com>
References: <21818.5535.219883.604245@stat.math.ethz.ch>
	<553A30EB.1040809@gmail.com>
	<CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
	<553A4C2D.9010901@gmail.com>
Message-ID: <CABtg=Kmh68=ykX0EHC99sz5Y-Do3iS9LAX6romf4a7xXOpzxug@mail.gmail.com>

On Fri, Apr 24, 2015 at 9:59 AM, G?k?en Eraslan <gokcen.eraslan at gmail.com>
wrote:
[...]

>
> But "Watch" only notifies when there are new pull requests and issues,
> which doesn't make sense for the r-source repository. Following Github Atom
> feed[1] sounds better, however the feed only provides commit messages not
> the diffs.
>

Right, sorry, I misremembered. It seems that you cannot get emails for
commits from Github, at least without the repo admin doing something, or
using an external service.

You can get an RSS/Atom feed, however, if that's good:
https://github.com/wch/r-source/commits/master.atom

Gabor

[...]

	[[alternative HTML version deleted]]


From nashjc at uottawa.ca  Fri Apr 24 17:35:21 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 24 Apr 2015 11:35:21 -0400
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
 function name
Message-ID: <553A62B9.3070709@uottawa.ca>

I was preparing a fix for a minor glitch in my optimx package and R CMD
check gave an error that the title was not in title case. It is

A Replacement and Extension of the optim() Function

R CMD check suggests the incorrect form

A Replacement and Extension of the Optim() Function

'Writing R Extensions' suggests single quotes, i.e.,

A Replacement and Extension of the 'optim()' Function

which R CMD check still complains about.

I have found

A Replacement and Extension of the _optim()_ Function

does not get the complaint, but I'm not sure the underscore is allowed.

Given that I've obeyed the RTFM rule, I'm wondering what to do now.

On a related matter, I'm finding the reverse dependency check for optimx
takes a very long time and sometimes stalls for reasons I have not yet
sorted out. I run it in virtual machines for R3.2 and R-devel. Possibly
optimx needs so many packages I'm hitting memory or disk limits. Perhaps
off-list discussion could suggest a way to set up a reverse check
server. I'd be willing to help on such a project, which might be helpful
for many developers.

JN


From bbolker at gmail.com  Fri Apr 24 22:44:57 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Apr 2015 20:44:57 +0000
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
	function name
References: <553A62B9.3070709@uottawa.ca>
Message-ID: <loom.20150424T224308-950@post.gmane.org>

Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:

> 
> I was preparing a fix for a minor glitch in my optimx package and R CMD
> check gave an error that the title was not in title case. 

  [snip] to make Gmane happy ...

> I have found
> 
> A Replacement and Extension of the _optim()_ Function
> 
> does not get the complaint, but I'm not sure the underscore is allowed.
> 
> Given that I've obeyed the RTFM rule, I'm wondering what to do now.

  Presumably you should ask the CRAN maintainers?  That seems to
be the only possible answer -- I don't think anyone else can guess 
very accurately ...

  Ben Bolker


From ligges at statistik.tu-dortmund.de  Sat Apr 25 00:17:09 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 25 Apr 2015 00:17:09 +0200
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
 function name
In-Reply-To: <loom.20150424T224308-950@post.gmane.org>
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
Message-ID: <553AC0E5.4000305@statistik.tu-dortmund.de>



On 24.04.2015 22:44, Ben Bolker wrote:
> Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
>
>>
>> I was preparing a fix for a minor glitch in my optimx package and R CMD
>> check gave an error that the title was not in title case.
>
>    [snip] to make Gmane happy ...
>
>> I have found
>>
>> A Replacement and Extension of the _optim()_ Function
>>
>> does not get the complaint, but I'm not sure the underscore is allowed.
>>
>> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
>
>    Presumably you should ask the CRAN maintainers?  That seems to
> be the only possible answer -- I don't think anyone else can guess
> very accurately ...

 From WRE:

"Refer to other packages and external software in single quotes, and to 
book titles (and similar) in double quotes."

Other non-English usage (as documented for the Description field; this 
inlcudes function names) can also be used in single quotes.

Best,
Uwe Ligges


>
>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bbolker at gmail.com  Sat Apr 25 01:13:15 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Apr 2015 23:13:15 +0000
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
	function name
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
	<553AC0E5.4000305@statistik.tu-dortmund.de>
Message-ID: <loom.20150425T011011-15@post.gmane.org>

Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:

> 
> 
> On 24.04.2015 22:44, Ben Bolker wrote:
> > Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
> >
> >>
> >> I was preparing a fix for a minor glitch in my optimx package and R CMD
> >> check gave an error that the title was not in title case.
> >
> >    [snip] to make Gmane happy ...
> >
> >> I have found
> >>
> >> A Replacement and Extension of the _optim()_ Function
> >>
> >> does not get the complaint, but I'm not sure the underscore is allowed.
> >>
> >> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
> >
> >    Presumably you should ask the CRAN maintainers?  That seems to
> > be the only possible answer -- I don't think anyone else can guess
> > very accurately ...
> 
>  From WRE:
> 
> "Refer to other packages and external software in single quotes, and to 
> book titles (and similar) in double quotes."
> 
> Other non-English usage (as documented for the Description field; this 
> inlcudes function names) can also be used in single quotes.
> 
> Best,
> Uwe Ligges

  Does this then constitute a bug in the package-checking code?
  
  With a just-updated R-devel, for a test case I get:

The Title field should be in title case, current version then in title case:
?Support Functions and Data for "Ecological Models and Data" plus 'optim()'?
?Support Functions and Data for "Ecological Models and Data" Plus 'Optim()'?

(while I'm nit-picking, I will say that the first time I got a version
of this error a few weeks ago, it took me two or three tries to parse
what "..., current version then in title case" meant.  It is perfectly
correct, I just found it really hard to understand ...)

  cheers
    Ben Bolker


From nashjc at uottawa.ca  Sat Apr 25 13:11:47 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 25 Apr 2015 07:11:47 -0400
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
 function name
In-Reply-To: <553AC0E5.4000305@statistik.tu-dortmund.de>
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
	<553AC0E5.4000305@statistik.tu-dortmund.de>
Message-ID: <553B7673.7020201@uottawa.ca>

Hendrik pointed out it was the parentheses that gave the complaint.
Single quotes and no parentheses seem to satisfy R CMD check. Perhaps
that needs to be in the WRE.

However, I have for some time used the parentheses to distinguish
functions from packages. optim() is a function, optimx a package.
Is this something CRAN should be thinking about? I would argue greater
benefit to users than title case.

JN


On 15-04-24 06:17 PM, Uwe Ligges wrote:
> 
> 
> On 24.04.2015 22:44, Ben Bolker wrote:
>> Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
>>
>>>
>>> I was preparing a fix for a minor glitch in my optimx package and R CMD
>>> check gave an error that the title was not in title case.
>>
>>    [snip] to make Gmane happy ...
>>
>>> I have found
>>>
>>> A Replacement and Extension of the _optim()_ Function
>>>
>>> does not get the complaint, but I'm not sure the underscore is allowed.
>>>
>>> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
>>
>>    Presumably you should ask the CRAN maintainers?  That seems to
>> be the only possible answer -- I don't think anyone else can guess
>> very accurately ...
> 
> From WRE:
> 
> "Refer to other packages and external software in single quotes, and to
> book titles (and similar) in double quotes."
> 
> Other non-English usage (as documented for the Description field; this
> inlcudes function names) can also be used in single quotes.
> 
> Best,
> Uwe Ligges
> 
> 
>>
>>    Ben Bolker
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From pdalgd at gmail.com  Sat Apr 25 13:57:43 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 25 Apr 2015 13:57:43 +0200
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
	function namei
In-Reply-To: <553B7673.7020201@uottawa.ca>
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
	<553AC0E5.4000305@statistik.tu-dortmund.de>
	<553B7673.7020201@uottawa.ca>
Message-ID: <BB74F403-5D7F-4C1E-A5A1-A95F9DF2A2DD@gmail.com>


> On 25 Apr 2015, at 13:11 , Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
> 
> Hendrik pointed out it was the parentheses that gave the complaint.
> Single quotes and no parentheses seem to satisfy R CMD check. Perhaps
> that needs to be in the WRE.

Well, it is in ?toTitleCase:

     ...However, unknown
     technical terms will be capitalized unless they are single words
     enclosed in single quotes: names of packages and libraries should
     be quoted in titles.

..and it is the "single word" bit that gets you. AFAICT, the issue is that it splits the text into words and then looks for words that begin and end with a single quote. And parentheses count as word separators, so the quotes of 'optim()' end up in two different words. 

It's one of those things that aren't easy to fix: Presumably you do want capitalization within parentheses so we can't just not let them be separators, and we can't just look for sets of single quotes with arbitrary content because they get used inside ordinary text (e.g. the beginning of this paragraph contains 's one of those things that aren'). So either we need more heuristics, like only counting () as separators when preceded by or preceding a space, or some sort of explicit escape mechanism, like BibTeX's {foo}.

> 
> However, I have for some time used the parentheses to distinguish
> functions from packages. optim() is a function, optimx a package.
> Is this something CRAN should be thinking about? I would argue greater
> benefit to users than title case.
> 
> JN
> 
> 
> On 15-04-24 06:17 PM, Uwe Ligges wrote:
>> 
>> 
>> On 24.04.2015 22:44, Ben Bolker wrote:
>>> Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
>>> 
>>>> 
>>>> I was preparing a fix for a minor glitch in my optimx package and R CMD
>>>> check gave an error that the title was not in title case.
>>> 
>>>   [snip] to make Gmane happy ...
>>> 
>>>> I have found
>>>> 
>>>> A Replacement and Extension of the _optim()_ Function
>>>> 
>>>> does not get the complaint, but I'm not sure the underscore is allowed.
>>>> 
>>>> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
>>> 
>>>   Presumably you should ask the CRAN maintainers?  That seems to
>>> be the only possible answer -- I don't think anyone else can guess
>>> very accurately ...
>> 
>> From WRE:
>> 
>> "Refer to other packages and external software in single quotes, and to
>> book titles (and similar) in double quotes."
>> 
>> Other non-English usage (as documented for the Description field; this
>> inlcudes function names) can also be used in single quotes.
>> 
>> Best,
>> Uwe Ligges
>> 
>> 
>>> 
>>>   Ben Bolker
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nashjc at uottawa.ca  Sat Apr 25 14:07:18 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 25 Apr 2015 08:07:18 -0400
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
 function namei
In-Reply-To: <BB74F403-5D7F-4C1E-A5A1-A95F9DF2A2DD@gmail.com>
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
	<553AC0E5.4000305@statistik.tu-dortmund.de>
	<553B7673.7020201@uottawa.ca>
	<BB74F403-5D7F-4C1E-A5A1-A95F9DF2A2DD@gmail.com>
Message-ID: <553B8376.7040802@uottawa.ca>

How about allowing underscore? (I believe WRE is silent on this, and I
have not tried submitting a package with underscore in the title.) As I
pointed out in my OP, _optim()_ works. And we have the advantage that we
can distinguish package from function.

The purpose of consistent editing is surely to provide the affordances
that save us from needing extra documentation, as per Donald Norman's
excellent discussions on Design of Everyday Things, or Turn Signals are
the Facial Expressions of Automobiles. Changing the name of a function
in a case-sensitive computing language may not be a bug, but it is
asking for trouble.

JN

On 15-04-25 07:57 AM, peter dalgaard wrote:
> 
>> On 25 Apr 2015, at 13:11 , Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
>>
>> Hendrik pointed out it was the parentheses that gave the complaint.
>> Single quotes and no parentheses seem to satisfy R CMD check. Perhaps
>> that needs to be in the WRE.
> 
> Well, it is in ?toTitleCase:
> 
>      ...However, unknown
>      technical terms will be capitalized unless they are single words
>      enclosed in single quotes: names of packages and libraries should
>      be quoted in titles.
> 
> ..and it is the "single word" bit that gets you. AFAICT, the issue is that it splits the text into words and then looks for words that begin and end with a single quote. And parentheses count as word separators, so the quotes of 'optim()' end up in two different words. 
> 
> It's one of those things that aren't easy to fix: Presumably you do want capitalization within parentheses so we can't just not let them be separators, and we can't just look for sets of single quotes with arbitrary content because they get used inside ordinary text (e.g. the beginning of this paragraph contains 's one of those things that aren'). So either we need more heuristics, like only counting () as separators when preceded by or preceding a space, or some sort of explicit escape mechanism, like BibTeX's {foo}.
> 
>>
>> However, I have for some time used the parentheses to distinguish
>> functions from packages. optim() is a function, optimx a package.
>> Is this something CRAN should be thinking about? I would argue greater
>> benefit to users than title case.
>>
>> JN
>>
>>
>> On 15-04-24 06:17 PM, Uwe Ligges wrote:
>>>
>>>
>>> On 24.04.2015 22:44, Ben Bolker wrote:
>>>> Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
>>>>
>>>>>
>>>>> I was preparing a fix for a minor glitch in my optimx package and R CMD
>>>>> check gave an error that the title was not in title case.
>>>>
>>>>   [snip] to make Gmane happy ...
>>>>
>>>>> I have found
>>>>>
>>>>> A Replacement and Extension of the _optim()_ Function
>>>>>
>>>>> does not get the complaint, but I'm not sure the underscore is allowed.
>>>>>
>>>>> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
>>>>
>>>>   Presumably you should ask the CRAN maintainers?  That seems to
>>>> be the only possible answer -- I don't think anyone else can guess
>>>> very accurately ...
>>>
>>> From WRE:
>>>
>>> "Refer to other packages and external software in single quotes, and to
>>> book titles (and similar) in double quotes."
>>>
>>> Other non-English usage (as documented for the Description field; this
>>> inlcudes function names) can also be used in single quotes.
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>>
>>>>   Ben Bolker
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From henrik.bengtsson at ucsf.edu  Sat Apr 25 17:08:52 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 25 Apr 2015 08:08:52 -0700
Subject: [Rd] Title case in DESCRIPTION for package where a word is a
 function namei
In-Reply-To: <553B8376.7040802@uottawa.ca>
References: <553A62B9.3070709@uottawa.ca>
	<loom.20150424T224308-950@post.gmane.org>
	<553AC0E5.4000305@statistik.tu-dortmund.de>
	<553B7673.7020201@uottawa.ca>
	<BB74F403-5D7F-4C1E-A5A1-A95F9DF2A2DD@gmail.com>
	<553B8376.7040802@uottawa.ca>
Message-ID: <CAFDcVCTb7bkUuf8Jg3v8JH11FJkdJv15mSJi-WU_ixujC2A+_g@mail.gmail.com>

On Apr 25, 2015 05:07, "Prof J C Nash (U30A)" <nashjc at uottawa.ca> wrote:
>
> How about allowing underscore? (I believe WRE is silent on this, and I
> have not tried submitting a package with underscore in the title.) As I
> pointed out in my OP, _optim()_ works. And we have the advantage that we
> can distinguish package from function.

Backticks also works (and also happens to be what Markdown use for inline code);

> title <- "A Replacement and Extension of the `optim()` Function"
> title == tools::toTitleCase(title)
[1] TRUE

Henrik

>
> The purpose of consistent editing is surely to provide the affordances
> that save us from needing extra documentation, as per Donald Norman's
> excellent discussions on Design of Everyday Things, or Turn Signals are
> the Facial Expressions of Automobiles. Changing the name of a function
> in a case-sensitive computing language may not be a bug, but it is
> asking for trouble.
>
> JN
>
> On 15-04-25 07:57 AM, peter dalgaard wrote:
> >
> >> On 25 Apr 2015, at 13:11 , Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
> >>
> >> Hendrik pointed out it was the parentheses that gave the complaint.
> >> Single quotes and no parentheses seem to satisfy R CMD check. Perhaps
> >> that needs to be in the WRE.
> >
> > Well, it is in ?toTitleCase:
> >
> >      ...However, unknown
> >      technical terms will be capitalized unless they are single words
> >      enclosed in single quotes: names of packages and libraries should
> >      be quoted in titles.
> >
> > ..and it is the "single word" bit that gets you. AFAICT, the issue is that it splits the text into words and then looks for words that begin and end with a single quote. And parentheses count as word separators, so the quotes of 'optim()' end up in two different words.
> >
> > It's one of those things that aren't easy to fix: Presumably you do want capitalization within parentheses so we can't just not let them be separators, and we can't just look for sets of single quotes with arbitrary content because they get used inside ordinary text (e.g. the beginning of this paragraph contains 's one of those things that aren'). So either we need more heuristics, like only counting () as separators when preceded by or preceding a space, or some sort of explicit escape mechanism, like BibTeX's {foo}.
> >
> >>
> >> However, I have for some time used the parentheses to distinguish
> >> functions from packages. optim() is a function, optimx a package.
> >> Is this something CRAN should be thinking about? I would argue greater
> >> benefit to users than title case.
> >>
> >> JN
> >>
> >>
> >> On 15-04-24 06:17 PM, Uwe Ligges wrote:
> >>>
> >>>
> >>> On 24.04.2015 22:44, Ben Bolker wrote:
> >>>> Prof J C Nash (U30A <nashjc <at> uottawa.ca> writes:
> >>>>
> >>>>>
> >>>>> I was preparing a fix for a minor glitch in my optimx package and R CMD
> >>>>> check gave an error that the title was not in title case.
> >>>>
> >>>>   [snip] to make Gmane happy ...
> >>>>
> >>>>> I have found
> >>>>>
> >>>>> A Replacement and Extension of the _optim()_ Function
> >>>>>
> >>>>> does not get the complaint, but I'm not sure the underscore is allowed.
> >>>>>
> >>>>> Given that I've obeyed the RTFM rule, I'm wondering what to do now.
> >>>>
> >>>>   Presumably you should ask the CRAN maintainers?  That seems to
> >>>> be the only possible answer -- I don't think anyone else can guess
> >>>> very accurately ...
> >>>
> >>> From WRE:
> >>>
> >>> "Refer to other packages and external software in single quotes, and to
> >>> book titles (and similar) in double quotes."
> >>>
> >>> Other non-English usage (as documented for the Description field; this
> >>> inlcudes function names) can also be used in single quotes.
> >>>
> >>> Best,
> >>> Uwe Ligges
> >>>
> >>>
> >>>>
> >>>>   Ben Bolker
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cloos at jhcloos.com  Sat Apr 25 23:06:41 2015
From: cloos at jhcloos.com (James Cloos)
Date: Sat, 25 Apr 2015 17:06:41 -0400
Subject: [Rd] Development version of R: Improved nchar(),
	nzchar() but changed API
In-Reply-To: <CABtg=Kmh68=ykX0EHC99sz5Y-Do3iS9LAX6romf4a7xXOpzxug@mail.gmail.com>
	(=?iso-8859-1?Q?=22G=E1bor_Cs=E1rdi=22's?= message of "Fri, 24 Apr 2015
	10:08:57 -0400")
References: <21818.5535.219883.604245@stat.math.ethz.ch>
	<553A30EB.1040809@gmail.com>
	<CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
	<553A4C2D.9010901@gmail.com>
	<CABtg=Kmh68=ykX0EHC99sz5Y-Do3iS9LAX6romf4a7xXOpzxug@mail.gmail.com>
Message-ID: <m34mo3udcu.fsf@carbon.jhcloos.org>

>>>>> "GC" == G?bor Cs?rdi <csardi.gabor at gmail.com> writes:

GC> You can get an RSS/Atom feed, however, if that's good:
GC> https://github.com/wch/r-source/commits/master.atom

That is available in gwene/gmane as:

     gwene.com.github.wch.r-source.commits.trunk

-JimC
-- 
James Cloos <cloos at jhcloos.com>         OpenPGP: 0x997A9F17ED7DAEA6


From lists at revelle.net  Sun Apr 26 13:23:30 2015
From: lists at revelle.net (William Revelle)
Date: Sun, 26 Apr 2015 06:23:30 -0500
Subject: [Rd] CRAN submit page down
In-Reply-To: <21817.19828.808634.260781@max.nulle.part>
References: <21817.19828.808634.260781@max.nulle.part>
Message-ID: <8D920B76-17B5-4C25-9549-507118E4512E@revelle.net>

This still seems to be the case.  

I tried uploading the most recent version of psych and got as far as the Step 3 page which says that it has sent out an email.
However, although normally this step takes agout 1 minute, nothing has happened for 16 hours.

Should we just use the old system of uploading to the ftp site and sending a confirming email?

Thanks of course to the CRAN maintainers without whom this amazing system would not exist.


Bill

> On Apr 23, 2015, at 2:52 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
> 
> Andrie noticed that first, and I can confirm: from our end, it looks as if
> the backend to http://cran.r-project.org/submit.html is currently down.
> 
> Dirk
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From ligges at statistik.tu-dortmund.de  Sun Apr 26 19:53:47 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 26 Apr 2015 19:53:47 +0200
Subject: [Rd] CRAN submit page down
In-Reply-To: <8D920B76-17B5-4C25-9549-507118E4512E@revelle.net>
References: <21817.19828.808634.260781@max.nulle.part>
	<8D920B76-17B5-4C25-9549-507118E4512E@revelle.net>
Message-ID: <553D262B.4040301@statistik.tu-dortmund.de>



On 26.04.2015 13:23, William Revelle wrote:
> This still seems to be the case.
>
> I tried uploading the most recent version of psych and got as far as the Step 3 page which says that it has sent out an email.
> However, although normally this step takes agout 1 minute, nothing has happened for 16 hours.
>
> Should we just use the old system of uploading to the ftp site and sending a confirming email?
>
> Thanks of course to the CRAN maintainers without whom this amazing system would not exist.

The sysadmins in Vienna will try to fix the problems on Monday.

The submission page says so now.

I'd be happy if non-urgent package submissions can be deferred until the 
web submission page is working again. In case of really urgent 
submissions, please go ahead with ftp uploads but *please* send the 
mails in the format the CRAN team asks for in the CRAN policies.

Thanks, sorry for the inconvenience and best wishes,
Uwe Ligges



>
> Bill
>
>> On Apr 23, 2015, at 2:52 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>>
>> Andrie noticed that first, and I can confirm: from our end, it looks as if
>> the backend to http://cran.r-project.org/submit.html is currently down.
>>
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> William Revelle		           http://personality-project.org/revelle.html
> Professor			           http://personality-project.org
> Department of Psychology   http://www.wcas.northwestern.edu/psych/
> Northwestern University	   http://www.northwestern.edu/
> Use R for psychology             http://personality-project.org/r
> It is 3 minutes to midnight	   http://www.thebulletin.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mark.vanderloo at gmail.com  Mon Apr 27 10:26:32 2015
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Mon, 27 Apr 2015 10:26:32 +0200
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <m34mo3udcu.fsf@carbon.jhcloos.org>
References: <21818.5535.219883.604245@stat.math.ethz.ch>
	<553A30EB.1040809@gmail.com>
	<CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
	<553A4C2D.9010901@gmail.com>
	<CABtg=Kmh68=ykX0EHC99sz5Y-Do3iS9LAX6romf4a7xXOpzxug@mail.gmail.com>
	<m34mo3udcu.fsf@carbon.jhcloos.org>
Message-ID: <CAOKDuOjh6YOsz-fnZM48Qp3QF+_6-uYPw5jNZOBVrjx1M70B4g@mail.gmail.com>

Dear Martin,

Does the work on nchar mean that bugs #16090 and #16091 will be resolved
[1,2]?

Thanks,
Mark

[1] https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16090
[2] https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16091





On Sat, Apr 25, 2015 at 11:06 PM, James Cloos <cloos at jhcloos.com> wrote:

> >>>>> "GC" == G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
>
> GC> You can get an RSS/Atom feed, however, if that's good:
> GC> https://github.com/wch/r-source/commits/master.atom
>
> That is available in gwene/gmane as:
>
>      gwene.com.github.wch.r-source.commits.trunk
>
> -JimC
> --
> James Cloos <cloos at jhcloos.com>         OpenPGP: 0x997A9F17ED7DAEA6
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Apr 27 13:48:59 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 27 Apr 2015 06:48:59 -0500
Subject: [Rd] Inconsistency when naming a vector
Message-ID: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>

Sometimes the absence of a name is maked by an NA:

x <- 1:2
names(x)[[1]] <- "a"
names(x)
# [1] "a" NA

Whereas other times its

y <- c(a = 1, 2)
names(y)
# [1] "a" ""

Is this deliberate? The help for names() is a bit murky, but an
example shows the NA behaviour.

Hadley

-- 
http://had.co.nz/


From msuzen at gmail.com  Mon Apr 27 15:08:09 2015
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 27 Apr 2015 14:08:09 +0100
Subject: [Rd] Inconsistency when naming a vector
In-Reply-To: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
References: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
Message-ID: <CAPtbhHzDnoP1VPxeGiSrojY3Sav4Y8qtq_5rqHyizef=+tmHPg@mail.gmail.com>

There is no inconsistency. Documentation of `names` says "...value
should be a character vector of up to the same length as x..."
In the first definition your character vector is not the same length
as length of x, so you enforce NA by not defining value[2]

x <- 1:2
value<-c("a")
value[2]
[1] NA

where as in the second case, R uses default value "", from `names`
documentation "..The name "" is special: it is used to indicate that
there is no name associated with an element.". Since you defined the
first one, it internally assigns "" to non-defined names to match the
length of the vector.


From kevinushey at gmail.com  Mon Apr 27 15:30:11 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 27 Apr 2015 06:30:11 -0700
Subject: [Rd] Inconsistency when naming a vector
In-Reply-To: <CAPtbhHzDnoP1VPxeGiSrojY3Sav4Y8qtq_5rqHyizef=+tmHPg@mail.gmail.com>
References: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
	<CAPtbhHzDnoP1VPxeGiSrojY3Sav4Y8qtq_5rqHyizef=+tmHPg@mail.gmail.com>
Message-ID: <CAJXgQP0rTF3aTNhMYhUOGJNva73_0wrT3Z-rP6s+mjG0uUSL9A@mail.gmail.com>

In `?names`:

     If ?value? is shorter than ?x?, it is extended by character ?NA?s
     to the length of ?x?.

So it is as documented.

That said, it's somewhat surprising that both NA and "" serve as a
placeholder for a 'missing name'; I believe they're treated
identically by R under the hood (e.g. in subsetting operations) but
there may be some subtle cases where they're not.


On Mon, Apr 27, 2015 at 6:08 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:
>
> There is no inconsistency. Documentation of `names` says "...value
> should be a character vector of up to the same length as x..."
> In the first definition your character vector is not the same length
> as length of x, so you enforce NA by not defining value[2]
>
> x <- 1:2
> value<-c("a")
> value[2]
> [1] NA
>
> where as in the second case, R uses default value "", from `names`
> documentation "..The name "" is special: it is used to indicate that
> there is no name associated with an element.". Since you defined the
> first one, it internally assigns "" to non-defined names to match the
> length of the vector.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Mon Apr 27 15:33:35 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 27 Apr 2015 15:33:35 +0200
Subject: [Rd] Inconsistency when naming a vector
In-Reply-To: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
References: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
Message-ID: <084BAB92-4002-421D-BCE5-B38FAD88CCFE@gmail.com>


> On 27 Apr 2015, at 13:48 , Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> Sometimes the absence of a name is maked by an NA:
> 
> x <- 1:2
> names(x)[[1]] <- "a"
> names(x)
> # [1] "a" NA
> 
> Whereas other times its
> 
> y <- c(a = 1, 2)
> names(y)
> # [1] "a" ""
> 
> Is this deliberate? The help for names() is a bit murky, but an
> example shows the NA behaviour.

I think it is 

(a) impossible to change
(b) at least somewhat coherent

The situation is partially due to the fact that character-NA is a relative latecomer to the language. In the beginning, there was no real distinction between NA and "NA", causing issues when abbreviating Noradrenaline, North America, Nelson Anderson, etc. At some point, it was decided to fix things up, as far as possible in a backawards compatible way. Some common idioms were retained but others were changed to comply with the rules for other vector types.

We have the empty string convention on (AFAICT) all constructor usages:

c(a=1, 3) 
list(a=1, 3)
cbind(a=1, 3)

and also in the lists implied by argument matching

> f <- function(...) names(match.call(expand.dots=TRUE))
> f(a=1,3)
[1] ""  "a" "" 

In contrast, assignment forms have the NA convention. This is consistent with the general rules for complex assignment. E.g. we have

> a <- "a"
> a[[5]] <- "b"
> a
[1] "a" NA  NA  NA  "b"

and even

> a <- NULL
> a[[5]] <- "a"
> a
[1] NA  NA  NA  NA  "a"

also, we have

> l <- list(1,2,3)
> names(l) <- c("a","b")
> l
$a
[1] 1

$b
[1] 2

$<NA>
[1] 3

and we do want to obey general rules like

names(l)[[2]] <- "a" 

being (nearly) equivalent to

`*tmp*`<- names(l)
`*tmp*`[[2]] <- "a"
names(l) <- `*tmp*`


- pd

> 
> Hadley
> 
> -- 
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lists at revelle.net  Mon Apr 27 16:46:42 2015
From: lists at revelle.net (William Revelle)
Date: Mon, 27 Apr 2015 09:46:42 -0500
Subject: [Rd] CRAN submit page down
In-Reply-To: <553D262B.4040301@statistik.tu-dortmund.de>
References: <21817.19828.808634.260781@max.nulle.part>
	<8D920B76-17B5-4C25-9549-507118E4512E@revelle.net>
	<553D262B.4040301@statistik.tu-dortmund.de>
Message-ID: <99FCD075-9885-4852-A076-FCDE48FAB6D9@revelle.net>

Thanks.

It is up again.

Bill

> On Apr 26, 2015, at 12:53 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
> 
> 
> On 26.04.2015 13:23, William Revelle wrote:
>> This still seems to be the case.
>> 
>> I tried uploading the most recent version of psych and got as far as the Step 3 page which says that it has sent out an email.
>> However, although normally this step takes agout 1 minute, nothing has happened for 16 hours.
>> 
>> Should we just use the old system of uploading to the ftp site and sending a confirming email?
>> 
>> Thanks of course to the CRAN maintainers without whom this amazing system would not exist.
> 
> The sysadmins in Vienna will try to fix the problems on Monday.
> 
> The submission page says so now.
> 
> I'd be happy if non-urgent package submissions can be deferred until the web submission page is working again. In case of really urgent submissions, please go ahead with ftp uploads but *please* send the mails in the format the CRAN team asks for in the CRAN policies.
> 
> Thanks, sorry for the inconvenience and best wishes,
> Uwe Ligges
> 
> 
> 
>> 
>> Bill
>> 
>>> On Apr 23, 2015, at 2:52 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>> 
>>> 
>>> Andrie noticed that first, and I can confirm: from our end, it looks as if
>>> the backend to http://cran.r-project.org/submit.html is currently down.
>>> 
>>> Dirk
>>> 
>>> --
>>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> William Revelle		           http://personality-project.org/revelle.html
>> Professor			           http://personality-project.org
>> Department of Psychology   http://www.wcas.northwestern.edu/psych/
>> Northwestern University	   http://www.northwestern.edu/
>> Use R for psychology             http://personality-project.org/r
>> It is 3 minutes to midnight	   http://www.thebulletin.org
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From maechler at lynne.stat.math.ethz.ch  Mon Apr 27 17:08:51 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Apr 2015 17:08:51 +0200
Subject: [Rd] Development version of R: Improved nchar(),
 nzchar() but changed API
In-Reply-To: <CAOKDuOjh6YOsz-fnZM48Qp3QF+_6-uYPw5jNZOBVrjx1M70B4g@mail.gmail.com>
References: <21818.5535.219883.604245@stat.math.ethz.ch>
	<553A30EB.1040809@gmail.com>
	<CABtg=KnAie_87Y4ZbH=V_mctHqaY+08==e8EgOq=upuD6wvYLA@mail.gmail.com>
	<553A4C2D.9010901@gmail.com>
	<CABtg=Kmh68=ykX0EHC99sz5Y-Do3iS9LAX6romf4a7xXOpzxug@mail.gmail.com>
	<m34mo3udcu.fsf@carbon.jhcloos.org>
	<CAOKDuOjh6YOsz-fnZM48Qp3QF+_6-uYPw5jNZOBVrjx1M70B4g@mail.gmail.com>
Message-ID: <21822.20739.30595.42966@stat.math.ethz.ch>

>>>>> Mark van der Loo <mark.vanderloo at gmail.com>
>>>>>     on Mon, 27 Apr 2015 10:26:32 +0200 writes:

    > Dear Martin, Does the work on nchar mean that bugs #16090
    > and #16091 will be resolved [1,2]?

    > Thanks, Mark

    > [1] https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16090
    > [2] https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16091

Dear Mark,

no, the changes I've been talking about are not related to the
above.
I'm not savvy on multi-byte / UTF-8 encodings and so left these
in the capable hands of fellow R core members.

But thank you for bringing  the hijacked thread back on track ..

My proposed changes -- after amendments -- are said to break 19
CRAN packages (i.e., R CMD check of these) and about a dozen
Bioconductor packages  (the latter being somewhat less relevant as
 bioconductor packages will only have to work for the R 3.2.x
 series for almost half a year.)

It seems that most breakages are from things like

    if(nchar(someString) > 0)

which now gives an error if someString is NA (i.e. NA_character_)
but I'm currently arguing that this (error) is desirable,
because NA means <missing> or <anything> and hence a character
NA could well be the empty string.

Also it seems, that much of the breaking code could have become
more efficient and reliable (*) if the programmeRs had used
nzchar(), i.e., instead of the above, faster and more reliable
is
    if(nzchar(someString))

Note that nzchar() also gains the new 'keepNA' argument, but the
plan is to set the default there to  'keepNA = FALSE', i.e.,
100% back compatible.

--
(*) because nchar(x) already now can give NA when x contains
    invalid multibyte characters.

Martin


From h.wickham at gmail.com  Tue Apr 28 18:21:53 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 28 Apr 2015 11:21:53 -0500
Subject: [Rd] install.packages no longer respects quiet = TRUE ?
Message-ID: <CABdHhvGW+wgAJHnHzRwGEFks8Mr+_XXc1Gi1poAn0OpzBTr4dA@mail.gmail.com>

> install.packages("plyr", quiet = T)

trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.2/plyr_1.8.2.tgz'
Content type 'application/x-gzip' length 855795 bytes (835 KB)
==================================================
downloaded 835 KB


The downloaded binary packages are in
/tmp/RtmpOcorLA/downloaded_packages


I don't have R 3.1.3 handy, but I'm pretty sure this used to produce no output.

Hadley

-- 
http://had.co.nz/


From h.wickham at gmail.com  Tue Apr 28 18:24:42 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 28 Apr 2015 11:24:42 -0500
Subject: [Rd] Inconsistency when naming a vector
In-Reply-To: <084BAB92-4002-421D-BCE5-B38FAD88CCFE@gmail.com>
References: <CABdHhvGLwS8RbZ9QXtHjr=NoSHyEqMKcUDh7598jNMFUKKit2A@mail.gmail.com>
	<084BAB92-4002-421D-BCE5-B38FAD88CCFE@gmail.com>
Message-ID: <CABdHhvEssHLsK_+41sH-0S6vQjBTDfcO3OWkAkGp_E1KdTTZFQ@mail.gmail.com>

On Mon, Apr 27, 2015 at 8:33 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 27 Apr 2015, at 13:48 , Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>> Sometimes the absence of a name is maked by an NA:
>>
>> x <- 1:2
>> names(x)[[1]] <- "a"
>> names(x)
>> # [1] "a" NA
>>
>> Whereas other times its
>>
>> y <- c(a = 1, 2)
>> names(y)
>> # [1] "a" ""
>>
>> Is this deliberate? The help for names() is a bit murky, but an
>> example shows the NA behaviour.
>
> I think it is
>
> (a) impossible to change
> (b) at least somewhat coherent
>
> The situation is partially due to the fact that character-NA is a relative latecomer to the language. In the beginning, there was no real distinction between NA and "NA", causing issues when abbreviating Noradrenaline, North America, Nelson Anderson, etc. At some point, it was decided to fix things up, as far as possible in a backawards compatible way. Some common idioms were retained but others were changed to comply with the rules for other vector types.
>
> We have the empty string convention on (AFAICT) all constructor usages:
>
> c(a=1, 3)
> list(a=1, 3)
> cbind(a=1, 3)
>
> and also in the lists implied by argument matching
>
>> f <- function(...) names(match.call(expand.dots=TRUE))
>> f(a=1,3)
> [1] ""  "a" ""
>
> In contrast, assignment forms have the NA convention. This is consistent with the general rules for complex assignment. E.g. we have
>

Ah, that explanation makes sense. Thanks.

It would be helpful to have a isNamed function that abstracted over
all these differences:

isNamed <- function(x) {
 nms <- names(x)
 if (is.null(nms)) return(rep(FALSE, length(x))

 !is.na(x) && x != ""
}

Hadley


-- 
http://had.co.nz/


From edd at debian.org  Tue Apr 28 18:41:07 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 28 Apr 2015 11:41:07 -0500
Subject: [Rd] install.packages no longer respects quiet = TRUE ?
In-Reply-To: <CABdHhvGW+wgAJHnHzRwGEFks8Mr+_XXc1Gi1poAn0OpzBTr4dA@mail.gmail.com>
References: <CABdHhvGW+wgAJHnHzRwGEFks8Mr+_XXc1Gi1poAn0OpzBTr4dA@mail.gmail.com>
Message-ID: <21823.47139.250132.626547@max.nulle.part>


On 28 April 2015 at 11:21, Hadley Wickham wrote:
| > install.packages("plyr", quiet = T)
| 
| trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.2/plyr_1.8.2.tgz'
| Content type 'application/x-gzip' length 855795 bytes (835 KB)
| ==================================================
| downloaded 835 KB
| 
| 
| The downloaded binary packages are in
| /tmp/RtmpOcorLA/downloaded_packages
| 
| 
| I don't have R 3.1.3 handy, but I'm pretty sure this used to produce no output.

Canot replicate with R 3.2.0 on Ubuntu, and it doesn't matter if I use T or TRUE.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ripley at stats.ox.ac.uk  Tue Apr 28 19:20:53 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Apr 2015 18:20:53 +0100
Subject: [Rd] install.packages no longer respects quiet = TRUE ?
In-Reply-To: <21823.47139.250132.626547@max.nulle.part>
References: <CABdHhvGW+wgAJHnHzRwGEFks8Mr+_XXc1Gi1poAn0OpzBTr4dA@mail.gmail.com>
	<21823.47139.250132.626547@max.nulle.part>
Message-ID: <553FC175.407@stats.ox.ac.uk>

> On 28 April 2015 at 11:21, Hadley Wickham wrote:
> | > install.packages("plyr", quiet = T)
> |
> | trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.2/plyr_1.8.2.tgz'
> | Content type 'application/x-gzip' length 855795 bytes (835 KB)
> | ==================================================
> | downloaded 835 KB
> |
> |
> | The downloaded binary packages are in
> | /tmp/RtmpOcorLA/downloaded_packages
> |
> |
> | I don't have R 3.1.3 handy, but I'm pretty sure this used to produce no output.

First, the description is

    quiet: logical: if true, reduce the amount of output.

not 'no output'.

This 'change' is seen only for installs of binary packages.  The 
difference is that the default is now type = "both", and 3.1.3 used type 
= 'binary': adding type = "binary" produces what you expected in 3.2.0, 
and type = "both" is already quieter in R-patched.

(Note that it is rather difficult to test install.packages for Mac 
binaries prior to release as that relies on a 'CRAN distribution' which 
pretty much has to be the default version on the machine.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From greg at warnes.net  Tue Apr 28 21:11:12 2015
From: greg at warnes.net (Gregory Warnes)
Date: Tue, 28 Apr 2015 15:11:12 -0400
Subject: [Rd] Add first() and last() to utils?
Message-ID: <CAKorm_sj04vU-zZCrcL7f2ATworD4MkSuACbP92nPfBvnMC_VQ@mail.gmail.com>

Hi all,

I've been using first() and last() for some time instead of x[1] and
x[length(x)] for vectors, and I gradually added methods for lists,
matrices, and data.frames.

In preparing the next release of the 'gdata' package (2.16.1) I settled on
these definitions, which harness the existing methods for head() and tail():

# Simply call 'first' or 'last' with a different default value for 'n'.
first <- function(x, n=1, ...) head(x, n=n, ...)
last  <- function(x, n=1, ...) tail(x, n=n, ...)


This works nicely, but Brian noted that packages 'data.table' and 'xts'
also provide functions/S3 methods for head() and/or tail().

Would it make sense to add these definitions to package 'utils' to make
them generally available?

-Greg

-- 
"Whereas true religion and good morals are the only solid foundations of
public liberty and happiness . . . it is hereby earnestly recommended to
the several States to take the most effectual measures for the
encouragement thereof." Continental Congress, 1778

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Tue Apr 28 22:04:35 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 28 Apr 2015 16:04:35 -0400
Subject: [Rd] R CMD check and missing imports from base packages
Message-ID: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>

When a symbol in a package is resolved, R looks into the package's
environment, and then into the package's imports environment. Then, if the
symbol is still not resolved, it looks into the base package. So far so
good.

If still not found, it follows the 'search()' path, starting with the
global environment and then all attached packages, finishing with base and
recommended packages.

This can be a problem if a package uses a function from a base package, but
it does not formally import it via the NAMESPACE file. If another package
on the search path also defines a function with the same name, then this
second function will be called.

E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
also defines 'density()', and 'igraph' is on the search path, then
'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.

I think that for a better solution, either
1) the search path should not be used at all to resolve symbols in
packages, or
2) only base packages should be searched.

I realize that this is something that is not easy to change, especially 1)
would break a lot of packages. But maybe at least 'R CMD check' could
report these cases. Currently it reports missing imports for non-base
packages only. Is it reasonable to have a NOTE for missing imports from
base packages as well?

[As usual, please fix me if I am missing or misunderstood something.]

Thank you, Best,
Gabor

	[[alternative HTML version deleted]]


From mick.jordan at oracle.com  Wed Apr 29 03:11:54 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Tue, 28 Apr 2015 18:11:54 -0700
Subject: [Rd] --interactive and -f/-e
Message-ID: <55402FDA.5070203@oracle.com>

I was surprised by this:

R --interactive -e 'interactive()'

bash-3.2$ R -q -e 'interactive()' --interactive
 > interactive()
[1] FALSE
 >

as the command options document says that --interactive should force 
interactive=TRUE:

" When *R* is run in a terminal (via |Rterm.exe| on Windows), it assumes 
that it is interactive if ?stdin? is connected to a (pseudo-)terminal 
and not if ?stdin? is redirected to a file or pipe. Command-line options 
--interactive (Unix) and --ess (Windows, |Rterm.exe|) override the 
default assumption"

But the code in system.c does this:

R_Interactive = R_Interactive && (force_interactive || isatty(0));

R_Interactive is set to FALSE in the -e/-f processing, and 
force_interactive is set to TRUE in the --interactive processing, so 
there is no way that it can ever override -e/-f. It seems that 
--interactive can only have an effect for something like a pipe. Is this 
actually the expected behavior?

Mick Jordan




	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Wed Apr 29 12:20:22 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Apr 2015 12:20:22 +0200
Subject: [Rd] --interactive and -f/-e
In-Reply-To: <55402FDA.5070203@oracle.com>
References: <55402FDA.5070203@oracle.com>
Message-ID: <21824.45158.644065.729614@stat.math.ethz.ch>

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Tue, 28 Apr 2015 18:11:54 -0700 writes:

    > I was surprised by this:
    > R --interactive -e 'interactive()'

    > bash-3.2$ R -q -e 'interactive()' --interactive
    >> interactive()
    > [1] FALSE
    >> 

    > as the command options document says that --interactive should force 
    > interactive=TRUE:

    > " When *R* is run in a terminal (via |Rterm.exe| on Windows), it assumes 
    > that it is interactive if ?stdin? is connected to a (pseudo-)terminal 
    > and not if ?stdin? is redirected to a file or pipe. Command-line options 
    > --interactive (Unix) and --ess (Windows, |Rterm.exe|) override the 
    > default assumption"

    > But the code in system.c does this:

    > R_Interactive = R_Interactive && (force_interactive || isatty(0));

    > R_Interactive is set to FALSE in the -e/-f processing, and 
    > force_interactive is set to TRUE in the --interactive processing, so 
    > there is no way that it can ever override -e/-f. It seems that 
    > --interactive can only have an effect for something like a pipe. Is this 
    > actually the expected behavior?

I did not write the code, but maybe "yes".

It may also seem a bit peculiar that it matters *where* on the
commandline --interactive is given :

	R -q -e 'interactive()' --interactive

behaves quite differently from	

	R --interactive -q -e 'interactive()'
and	R -q --interactive -e 'interactive()'

the latter two behaving equally, and indeed just starting R
interactively and not obeying the '-e ..' part(s)  at all.

Reading the source shows that -e is really just a short cut for
-f / --file=*, because -e writes to a tempfile and then proceeds
as -f (with the tempfile).

As you mentioned "something like a pipe": '--interactive' does
work fine when R is reading from stdin, not just via a pipe,

  $ echo 'interactive(); 1+1' | R --interactive --vanilla -q
  > interactive(); 1+1
  [1] TRUE
  [1] 2
  > 
  $ 

but of course, e.g., also by explicitly reading a file from stdin : 

  $ echo 'interactive(); commandArgs()' > /tmp/e1.R
  $ R --interactive --vanilla -q  < /tmp/e1.R
  > interactive(); commandArgs()
  [1] TRUE
  [1] "/........../bin/exec/R"
  [2] "--interactive"                                   
  [3] "--vanilla"                                       
  [4] "-q"                                              
  > 
  $ echo 'x <- 1:7; interactive(); x' > /tmp/e2.R
  $ R --interactive --vanilla -q  < /tmp/e2.R
  > x <- 1:7; interactive(); x
  [1] TRUE
  [1] 1 2 3 4 5 6 7
  > 
  $ 

So, in principle it should not seem hard to make --interactive
work for '-e' and '-f' as well, but I don't see quickly how.
Just changing the line in unix/system.c you've mentioned above
is clearly not enough.

Martin Maechler
ETH Zurich


From h.wickham at gmail.com  Wed Apr 29 18:35:47 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 29 Apr 2015 11:35:47 -0500
Subject: [Rd] R CMD INSTALL and windows paths with ampersands
Message-ID: <CABdHhvGoi2TCe8DhBNTmd5PSjDNpjrY1ySc0x1og8tdWA=gcpw@mail.gmail.com>

mkdir "A&"
R
# install.packages("pkgKitten")
pkgKitten::kitten("aPackage", "A&")
q()
R CMD INSTALL "A&"

gives

Warning invalid package A
(not the absence of the ampersand)

I'm reasonably certain this is a bug - I don't think ampersands should
require any additional escaping when already double quoted.

Note that

R CMD INSTALL "A^&"

does work

Hadley

-- 
http://had.co.nz/


From winstonchang1 at gmail.com  Wed Apr 29 18:53:46 2015
From: winstonchang1 at gmail.com (Winston Chang)
Date: Wed, 29 Apr 2015 11:53:46 -0500
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
Message-ID: <CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>

On Tue, Apr 28, 2015 at 3:04 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>
>
> E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
> also defines 'density()', and 'igraph' is on the search path, then
> 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.


Just to be clear: you mean that this happens when ggplot2 contains a
call like 'density()', not 'stats::density()' (but the intention is to
call stats::density()), right?

-Winston


From nalimilan at club.fr  Wed Apr 29 18:57:29 2015
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 29 Apr 2015 18:57:29 +0200
Subject: [Rd] Formula evaluation, environments and attached packages
Message-ID: <1430326649.21653.144.camel@club.fr>

Hi!

Some time ago, I replaced calls to library() with calls to
requireNamespace() in my package logmult, in order to follow the new
CRAN policies. But I just noticed it broke jackknife/bootstrap using
several workers via package parallel.

The reason is that I'm running model replicates on the workers, and the
formula includes non-standard terms like Mult() which are provided by
gnm. If gnm is not attached to the global namespace, these functions are
not found.

What would be the best solution to fix this? I tried changing the
environment of the formula to be gnm's namespace, but so far I failed.

Here's a reproducer using only gnm:

> dat <- structure(c(326, 688, 343, 98, 38, 116, 84, 48, 241, 584, 909, 
+ 403, 110, 188, 412, 681, 3, 4, 26, 85), .Dim = 4:5, .Dimnames = structure(list(
+     Eye = c("Blue", "Light", "Medium", "Dark"), Hair = c("Fair", 
+     "Red", "Medium", "Dark", "Black")), .Names = c("Eye", "Hair"
+ )), class="table")
> 
> f <- Freq ~ Eye + Hair + Mult(Eye, Hair)
> gnm::gnm(f, family=poisson, data=dat)
Error in which(sapply(variables, function(x) { : 
  error in evaluating the argument 'x' in selecting a method for function 'which':
Error in get(as.character(FUN), mode = "function", envir = envir) : 
  object 'Mult' of mode 'function' was not found

# Failed attempt by setting the environment
> environment(f) <- loadNamespace("gnm")
> environment(f)                        
<environment: namespace:gnm>
> gnm::gnm(f, family=poisson, data=dat)
Error in which(sapply(variables, function(x) { : 
  error in evaluating the argument 'x' in selecting a method for function 'which':
Error in get(as.character(FUN), mode = "function", envir = envir) : 
  object 'Mult' of mode 'function' was not found


Thanks for your help


From csardi.gabor at gmail.com  Wed Apr 29 19:00:14 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 13:00:14 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
Message-ID: <CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>

On Wed, Apr 29, 2015 at 12:53 PM, Winston Chang <winstonchang1 at gmail.com>
wrote:

> On Tue, Apr 28, 2015 at 3:04 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> >
> >
> > E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
> > also defines 'density()', and 'igraph' is on the search path, then
> > 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
>
>
> Just to be clear: you mean that this happens when ggplot2 contains a
> call like 'density()', not 'stats::density()' (but the intention is to
> call stats::density()), right?
>

Yes, exactly as you say, I am sorry for the confusion. This is actually a
real example:
https://github.com/hadley/ggplot2/issues/1041

Gabor


>
> -Winston
>

	[[alternative HTML version deleted]]


From ht at heatherturner.net  Wed Apr 29 19:27:18 2015
From: ht at heatherturner.net (Heather Turner)
Date: Wed, 29 Apr 2015 18:27:18 +0100
Subject: [Rd] Formula evaluation, environments and attached packages
In-Reply-To: <1430326649.21653.144.camel@club.fr>
References: <1430326649.21653.144.camel@club.fr>
Message-ID: <1430328438.3742979.260277237.3AB262D7@webmail.messagingengine.com>

Hi Milan,

I expect I may be able to do something about the way the terms are
evaluated, to ensure the evaluation is done in the gnm namespace (while
still ensuring the variables can be found!).

In the meantime, I think the following will work:

Mult <- gnm::Mult
 f <- Freq ~ Eye + Hair + Mult(Eye, Hair)
gnm::gnm(f, family=poisson, data=dat)

Hope that helps,

Heather

On Wed, Apr 29, 2015, at 05:57 PM, Milan Bouchet-Valat wrote:
> Hi!
> 
> Some time ago, I replaced calls to library() with calls to
> requireNamespace() in my package logmult, in order to follow the new
> CRAN policies. But I just noticed it broke jackknife/bootstrap using
> several workers via package parallel.
> 
> The reason is that I'm running model replicates on the workers, and the
> formula includes non-standard terms like Mult() which are provided by
> gnm. If gnm is not attached to the global namespace, these functions are
> not found.
> 
> What would be the best solution to fix this? I tried changing the
> environment of the formula to be gnm's namespace, but so far I failed.
> 
> Here's a reproducer using only gnm:
> 
> > dat <- structure(c(326, 688, 343, 98, 38, 116, 84, 48, 241, 584, 909, 
> + 403, 110, 188, 412, 681, 3, 4, 26, 85), .Dim = 4:5, .Dimnames =
> structure(list(
> +     Eye = c("Blue", "Light", "Medium", "Dark"), Hair = c("Fair", 
> +     "Red", "Medium", "Dark", "Black")), .Names = c("Eye", "Hair"
> + )), class="table")
> > 
> > f <- Freq ~ Eye + Hair + Mult(Eye, Hair)
> > gnm::gnm(f, family=poisson, data=dat)
> Error in which(sapply(variables, function(x) { : 
>   error in evaluating the argument 'x' in selecting a method for function
>   'which':
> Error in get(as.character(FUN), mode = "function", envir = envir) : 
>   object 'Mult' of mode 'function' was not found
> 
> # Failed attempt by setting the environment
> > environment(f) <- loadNamespace("gnm")
> > environment(f)                        
> <environment: namespace:gnm>
> > gnm::gnm(f, family=poisson, data=dat)
> Error in which(sapply(variables, function(x) { : 
>   error in evaluating the argument 'x' in selecting a method for function
>   'which':
> Error in get(as.character(FUN), mode = "function", envir = envir) : 
>   object 'Mult' of mode 'function' was not found
> 
> 
> Thanks for your help


From nalimilan at club.fr  Wed Apr 29 19:37:50 2015
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 29 Apr 2015 19:37:50 +0200
Subject: [Rd] Formula evaluation, environments and attached packages
In-Reply-To: <1430328438.3742979.260277237.3AB262D7@webmail.messagingengine.com>
References: <1430326649.21653.144.camel@club.fr>
	<1430328438.3742979.260277237.3AB262D7@webmail.messagingengine.com>
Message-ID: <1430329070.21653.150.camel@club.fr>

Le mercredi 29 avril 2015 ? 18:27 +0100, Heather Turner a ?crit :
> Hi Milan,
> 
> I expect I may be able to do something about the way the terms are
> evaluated, to ensure the evaluation is done in the gnm namespace (while
> still ensuring the variables can be found!).
> 
> In the meantime, I think the following will work:
> 
> Mult <- gnm::Mult
>  f <- Freq ~ Eye + Hair + Mult(Eye, Hair)
> gnm::gnm(f, family=poisson, data=dat)
Indeed, that's a good trick, waiting for a more general solution.


Regards

> Hope that helps,
> 
> Heather
> 
> On Wed, Apr 29, 2015, at 05:57 PM, Milan Bouchet-Valat wrote:
> > Hi!
> > 
> > Some time ago, I replaced calls to library() with calls to
> > requireNamespace() in my package logmult, in order to follow the new
> > CRAN policies. But I just noticed it broke jackknife/bootstrap using
> > several workers via package parallel.
> > 
> > The reason is that I'm running model replicates on the workers, and the
> > formula includes non-standard terms like Mult() which are provided by
> > gnm. If gnm is not attached to the global namespace, these functions are
> > not found.
> > 
> > What would be the best solution to fix this? I tried changing the
> > environment of the formula to be gnm's namespace, but so far I failed.
> > 
> > Here's a reproducer using only gnm:
> > 
> > > dat <- structure(c(326, 688, 343, 98, 38, 116, 84, 48, 241, 584, 909, 
> > + 403, 110, 188, 412, 681, 3, 4, 26, 85), .Dim = 4:5, .Dimnames =
> > structure(list(
> > +     Eye = c("Blue", "Light", "Medium", "Dark"), Hair = c("Fair", 
> > +     "Red", "Medium", "Dark", "Black")), .Names = c("Eye", "Hair"
> > + )), class="table")
> > > 
> > > f <- Freq ~ Eye + Hair + Mult(Eye, Hair)
> > > gnm::gnm(f, family=poisson, data=dat)
> > Error in which(sapply(variables, function(x) { : 
> >   error in evaluating the argument 'x' in selecting a method for function
> >   'which':
> > Error in get(as.character(FUN), mode = "function", envir = envir) : 
> >   object 'Mult' of mode 'function' was not found
> > 
> > # Failed attempt by setting the environment
> > > environment(f) <- loadNamespace("gnm")
> > > environment(f)                        
> > <environment: namespace:gnm>
> > > gnm::gnm(f, family=poisson, data=dat)
> > Error in which(sapply(variables, function(x) { : 
> >   error in evaluating the argument 'x' in selecting a method for function
> >   'which':
> > Error in get(as.character(FUN), mode = "function", envir = envir) : 
> >   object 'Mult' of mode 'function' was not found
> > 
> > 
> > Thanks for your help


From gmbecker at ucdavis.edu  Wed Apr 29 19:45:31 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 29 Apr 2015 10:45:31 -0700
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>
Message-ID: <CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>

Gabor,

To play devil's advocate a bit,  why not just have the package formally
import the functions it wants to use (or the whole package if that is
easier)? Also, if your package Depends on another package, instead of
importing it (e.g. because the end user will need functions in it in order
to meaningfully use your functions), I imagine you *want* to hit symbols in
that package before base, right? Otherwise the Depends mechanism becomes
somewhat crippled because you'd need to import symbols from packages you
Depend on, at least in certain cases.

You don't want to require people to import things like the assignment
operator, or "if", or a bunch of other things in the base package (and
probably not the stuff in grDevices either, though from your description
they would in principle need to do that now).

But why should stats not require an import if you want to guarantee that
you get the density function from stats and not from somewhere else? Isn't
that what ImportFrom is for? Is the reason that it is loaded automatically?

Best,
~G

On Wed, Apr 29, 2015 at 10:00 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
wrote:

> On Wed, Apr 29, 2015 at 12:53 PM, Winston Chang <winstonchang1 at gmail.com>
> wrote:
>
> > On Tue, Apr 28, 2015 at 3:04 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> > wrote:
> > >
> > >
> > > E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
> > > also defines 'density()', and 'igraph' is on the search path, then
> > > 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
> >
> >
> > Just to be clear: you mean that this happens when ggplot2 contains a
> > call like 'density()', not 'stats::density()' (but the intention is to
> > call stats::density()), right?
> >
>
> Yes, exactly as you say, I am sorry for the confusion. This is actually a
> real example:
> https://github.com/hadley/ggplot2/issues/1041
>
> Gabor
>
>
> >
> > -Winston
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Wed Apr 29 19:57:09 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 13:57:09 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>
	<CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
Message-ID: <CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>

On Wed, Apr 29, 2015 at 1:45 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> Gabor,
>
> To play devil's advocate a bit,  why not just have the package formally
> import the functions it wants to use (or the whole package if that is
> easier)?
>

This is exactly my goal. And to facilitate this, R CMD check could remind
you if you forgot to do the formal import.

You don't want to require people to import things like the assignment
> operator, or "if", or a bunch of other things in the base package (and
> probably not the stuff in grDevices either, though from your description
> they would in principle need to do that now).
>

I am not talking about the 'base' package, only the other base packages.
(The base package is special, it is searched before the attached packages,
so it is probably fine.)

Yes, I suggest people import stuff from grDevices explicitly. Because if
they don't, their package might break if used together with other packages.
And this is not a theoretical issue, in the past couple of weeks I have
seen this happening three times.

But why should stats not require an import if you want to guarantee that
> you get the density function from stats and not from somewhere else? Isn't
> that what ImportFrom is for? Is the reason that it is loaded automatically?
>

That's exactly what I am saying, sorry if it was not clear. I want to
"require" format imports from base packages (except from _the_ base
package, maybe).

Yes, people can do this already. But why not help them with a NOTE if they
don't know that this is good practice, or they just simply forget?

Gabor


>
> Best,
> ~G
>
> On Wed, Apr 29, 2015 at 10:00 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
>
>> On Wed, Apr 29, 2015 at 12:53 PM, Winston Chang <winstonchang1 at gmail.com>
>> wrote:
>>
>> > On Tue, Apr 28, 2015 at 3:04 PM, G?bor Cs?rdi <csardi.gabor at gmail.com>
>> > wrote:
>> > >
>> > >
>> > > E.g. if package 'ggplot2' uses 'stats::density()', and package
>> 'igraph'
>> > > also defines 'density()', and 'igraph' is on the search path, then
>> > > 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
>> >
>> >
>> > Just to be clear: you mean that this happens when ggplot2 contains a
>> > call like 'density()', not 'stats::density()' (but the intention is to
>> > call stats::density()), right?
>> >
>>
>> Yes, exactly as you say, I am sorry for the confusion. This is actually a
>> real example:
>> https://github.com/hadley/ggplot2/issues/1041
>>
>> Gabor
>>
>>
>> >
>> > -Winston
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker, PhD
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech, Inc.
>

	[[alternative HTML version deleted]]


From b.fischer at dkfz-heidelberg.de  Wed Apr 29 20:22:44 2015
From: b.fischer at dkfz-heidelberg.de (Fischer, Bernd)
Date: Wed, 29 Apr 2015 20:22:44 +0200
Subject: [Rd] dimnames returned by function apply
Message-ID: <99ED4CB4-AF79-421F-B7A0-3BBFB8F5FCD6@dkfz.de>

Dear all,

I noticed that the dimnames returned by apply are different in the new release.

In the following example. The returned row-names are c(?S?,?T?), but shouldn?t they be c(?X?,?Y?) as in the old release?

Best,

Bernd

>X = array(1:8, dim=c(4,2))
>dimnames(X) = list(c("A","B","C","D"),c("S","T"))
>apply(X, 1, function(x) { c(X=x[1]*5,Y=x[2]*5) } )

   A  B  C  D
S  5 10 15 20
T 25 30 35 40

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-apple-darwin14.3.0 (64-bit)
Running under: OS X 10.10.3 (Yosemite)

locale:
[1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     


From bbolker at gmail.com  Wed Apr 29 21:07:45 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Apr 2015 15:07:45 -0400
Subject: [Rd] model.matrix and na.action
Message-ID: <55412C01.8050004@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  I've finally been able to piece this together, but I wonder if I've
got it right/whether there is anywhere the behaviour of `model.matrix`
with respect to `na.action` is more *explicitly* documented.

  * model.matrix() respects the 'na.action' argument associated with
its data.
  * If the 'data' argument is a model frame with an "na.action"
attribute, then that is used.
  * If the 'data' argument is _not_ a model frame (which does go
against the implicit suggestion of ?model.matrix), model.frame() is
used on the data, which means that by default the global na.option
setting is used.
 * the intended design is that one should first construct the model
frame using an explicit `na.action` and then pass it to `model.matrix`.

  (After spending a few hours figuring this out and constructing the
e-mail, it has turned from a question into a request for confirmation
... I do think a couple of extra sentences of explication in the
documentation for dummies like me wouldn't hurt, I would be happy to
submit a documentation patch if that seems worthwhile.)

- --------
  I've tried looking through model.matrix.default and through the
modelmatrix function in src/library/stats/src/model.c , but it's
pretty hairy ...

  Related discussion:

http://stackoverflow.com/questions/5616210/model-matrix-with-na-action-null

http://stackoverflow.com/questions/6447708/model-matrix-generates-fewer-rows-than-original-data-frame

https://stat.ethz.ch/pipermail/r-help/2008-December/183509.html

https://stat.ethz.ch/pipermail/r-help/2001-August/014483.html (BDR
says here "?model.matrix does tell you the second argument should be
the result of model.frame, which is a pretty strong hint." ...)

==========


mm <- function(newdata,form=~x,na.action=na.pass,set.opts=FALSE) {
    if (set.opts) {
        op <- options(na.action=na.action)
        on.exit(options(op))
    }
    ## try with raw data and with model.frame with na.action specified
    X1 <- model.matrix(form, mfnew <- model.frame(newdata,
                                                 na.action=na.action))
    X2 <- model.matrix(form, newdata)
    return(c(any(is.na(X1[,"x"])),any(is.na(X2[,"x"]))))
}

options("na.action")  ## na.omit
d <- data.frame(x=c(NA,NA,1:5))
mm(d)  ## TRUE FALSE
mm(d,set.opts=TRUE)  ## TRUE TRUE
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVQSwBAAoJEOCV5YRblxUHr8gIAIEUEuZ0nbNQGmslpnEuLEiB
mdGVemWFXSUzs/+267GxBj5LvIi3SqOfYe6nMPd6VPHB8HSAzl3Spln+6a13U566
sgNq6dmqApDOjTNGklskA1VcjPHGMx3AOANjGnObQUfLti8G+y+CYV6NnnzoT23q
eeBUobwDqs/nfWkgiQcPY2iVQYGs6q03S4jJtyFkJgs3Wqn6croIXwUFAZIsjvmp
wf6BxvFFZEtAkDHdO3nC/LtOjkeh/TBnvXjzmfI9jlyiI0wkLrdd4hoXt3TmL94y
L3nXvHf0Ntb74Gyjg9o4dGU3Gl6iZTRsW7Dqbz9PdYOWGUnQ/t5BftO3dOpKvHU=
=GZR8
-----END PGP SIGNATURE-----


From murdoch.duncan at gmail.com  Wed Apr 29 21:24:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Apr 2015 15:24:02 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>	<CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
	<CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
Message-ID: <55412FD2.3060809@gmail.com>

On 29/04/2015 1:57 PM, G?bor Cs?rdi wrote:
> On Wed, Apr 29, 2015 at 1:45 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
>
> > Gabor,
> >
> > To play devil's advocate a bit,  why not just have the package formally
> > import the functions it wants to use (or the whole package if that is
> > easier)?
> >
>
> This is exactly my goal. And to facilitate this, R CMD check could remind
> you if you forgot to do the formal import.
>
> You don't want to require people to import things like the assignment
> > operator, or "if", or a bunch of other things in the base package (and
> > probably not the stuff in grDevices either, though from your description
> > they would in principle need to do that now).
> >
>
> I am not talking about the 'base' package, only the other base packages.
> (The base package is special, it is searched before the attached packages,
> so it is probably fine.)
>
> Yes, I suggest people import stuff from grDevices explicitly. Because if
> they don't, their package might break if used together with other packages.
> And this is not a theoretical issue, in the past couple of weeks I have
> seen this happening three times.
>
> But why should stats not require an import if you want to guarantee that
> > you get the density function from stats and not from somewhere else? Isn't
> > that what ImportFrom is for? Is the reason that it is loaded automatically?
> >
>
> That's exactly what I am saying, sorry if it was not clear. I want to
> "require" format imports from base packages (except from _the_ base
> package, maybe).
>
> Yes, people can do this already. But why not help them with a NOTE if they
> don't know that this is good practice, or they just simply forget?

I suspect the reason for this is historical:  at the time that the 
current warning was added, it would have flagged too many packages as 
problematic.  People do complain when base R makes changes that force 
them to change their packages.  Perhaps that decision should be 
reconsidered now.

Duncan Murdoch


From jpnolan at american.edu  Wed Apr 29 21:28:02 2015
From: jpnolan at american.edu (John Nolan)
Date: Wed, 29 Apr 2015 15:28:02 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>	<CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
	<CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
Message-ID: <OFBEB0DE6D.5E0665DE-ON85257E36.006374E7-85257E36.006AE5CF@american.edu>

All,

Here are two ideas on this:

1. have R CMD check show how every external function reference gets 
resolved.
2. have R CMD check warn anytime there is a potential name conflict, e.g. 
density( ) coming from either igraph or stats, and show how it was 
resolved.

Either could be an option.  I guess there are potential problems with 
conditional loading of libraries where a function could be  resolved 
differently depending on some decision made at run time, but 1. or 2. 
might be useful for the standard case.

John 
 ..............................................................
 John P. Nolan
 Math/Stat Department
 227 Gray Hall,   American University
 4400 Massachusetts Avenue, NW
 Washington, DC 20016-8050

 jpnolan at american.edu       voice: 202.885.3140 
 web: academic2.american.edu/~jpnolan
 ..............................................................



From:   G?bor Cs?rdi <csardi.gabor at gmail.com>
To:     Gabriel Becker <gmbecker at ucdavis.edu>, 
Cc:     "r-devel at r-project.org" <r-devel at r-project.org>
Date:   04/29/2015 01:57 PM
Subject:        Re: [Rd] R CMD check and missing imports from base 
packages
Sent by:        "R-devel" <r-devel-bounces at r-project.org>



On Wed, Apr 29, 2015 at 1:45 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> Gabor,
>
> To play devil's advocate a bit,  why not just have the package formally
> import the functions it wants to use (or the whole package if that is
> easier)?
>

This is exactly my goal. And to facilitate this, R CMD check could remind
you if you forgot to do the formal import.

You don't want to require people to import things like the assignment
> operator, or "if", or a bunch of other things in the base package (and
> probably not the stuff in grDevices either, though from your description
> they would in principle need to do that now).
>

I am not talking about the 'base' package, only the other base packages.
(The base package is special, it is searched before the attached packages,
so it is probably fine.)

Yes, I suggest people import stuff from grDevices explicitly. Because if
they don't, their package might break if used together with other 
packages.
And this is not a theoretical issue, in the past couple of weeks I have
seen this happening three times.

But why should stats not require an import if you want to guarantee that
> you get the density function from stats and not from somewhere else? 
Isn't
> that what ImportFrom is for? Is the reason that it is loaded 
automatically?
>

That's exactly what I am saying, sorry if it was not clear. I want to
"require" format imports from base packages (except from _the_ base
package, maybe).

Yes, people can do this already. But why not help them with a NOTE if they
don't know that this is good practice, or they just simply forget?

Gabor


>
> Best,
> ~G
>
> On Wed, Apr 29, 2015 at 10:00 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
>
>> On Wed, Apr 29, 2015 at 12:53 PM, Winston Chang 
<winstonchang1 at gmail.com>
>> wrote:
>>
>> > On Tue, Apr 28, 2015 at 3:04 PM, G?bor Cs?rdi 
<csardi.gabor at gmail.com>
>> > wrote:
>> > >
>> > >
>> > > E.g. if package 'ggplot2' uses 'stats::density()', and package
>> 'igraph'
>> > > also defines 'density()', and 'igraph' is on the search path, then
>> > > 'ggplot2' will call 'igraph::density()' instead of 
'stats::density()'.
>> >
>> >
>> > Just to be clear: you mean that this happens when ggplot2 contains a
>> > call like 'density()', not 'stats::density()' (but the intention is 
to
>> > call stats::density()), right?
>> >
>>
>> Yes, exactly as you say, I am sorry for the confusion. This is actually 
a
>> real example:
>> https://github.com/hadley/ggplot2/issues/1041
>>
>> Gabor
>>
>>
>> >
>> > -Winston
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker, PhD
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech, Inc.
>

                 [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Wed Apr 29 21:45:14 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 15:45:14 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <OFBEB0DE6D.5E0665DE-ON85257E36.006374E7-85257E36.006AE5CF@american.edu>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>
	<CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
	<CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
	<OFBEB0DE6D.5E0665DE-ON85257E36.006374E7-85257E36.006AE5CF@american.edu>
Message-ID: <CABtg=Kk3PS9nO2ZdLMjmVM=uM-bzuSFJcD6R2deh09m2qXx2pA@mail.gmail.com>

On Wed, Apr 29, 2015 at 3:28 PM, John Nolan <jpnolan at american.edu> wrote:
[...]

> 1. have R CMD check show how every external function reference gets
> resolved.
>

That's not possible, because it depends on the currently attached packages,
and even on the order of their attachment.


> 2. have R CMD check warn anytime there is a potential name conflict, e.g.
> density( ) coming from either igraph or stats, and show how it was resolved.
>

Also not possible in practice, because it would need to check too many
packages. But it would not be a good solution in my opinion, anyway,
because you probably don't want people having to deal with these issues. I
surely don't. For the developer of a single package, it should be
completely irrelevant how many other packages use the same function names.

Gabor

[...]

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Wed Apr 29 21:51:36 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 15:51:36 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <55412FD2.3060809@gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<CAFOpNVEipQH5RMo3nJ3yrUmtkAd-58ZhikSUwcHNijxv=SjKqQ@mail.gmail.com>
	<CABtg=Kne=YoFcCJz8ZWd2AviveSQxW+T7NU4rexLMKokpC3ugA@mail.gmail.com>
	<CADwqtCNsZgtnbf4hXw5jVLRkr+bOgr7kU68JVRTw9NZc+MyvOQ@mail.gmail.com>
	<CABtg=KkOAdRh_EjDYhj9-AaToMfv0kMWLuD=g=f-aem0GJNndg@mail.gmail.com>
	<55412FD2.3060809@gmail.com>
Message-ID: <CABtg=Km7kGSpqxk+xmr7Aa=cd7_6iFj1fFbbnV6GYFKZeeSzkA@mail.gmail.com>

On Wed, Apr 29, 2015 at 3:24 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
[...]

> Yes, people can do this already. But why not help them with a NOTE if they
>> don't know that this is good practice, or they just simply forget?
>>
>
> I suspect the reason for this is historical:  at the time that the current
> warning was added, it would have flagged too many packages as problematic.
> People do complain when base R makes changes that force them to change
> their packages.  Perhaps that decision should be reconsidered now.


Thanks for considering this. I definitely think that with the number of
packages increasing, sooner or later this will be a (more) serious issue.
In some cases it is also hard(er) to work around with detaching and
re-attaching packages.

I think a NOTE would be probably enough, because probably a lot of packages
have these issues.

Also, people would not need to change their package _now_. Only if and when
they submit new versions. But that's CRAN's decision, not mine.

Gabor

[...]

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Wed Apr 29 22:24:58 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 29 Apr 2015 13:24:58 -0700
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
Message-ID: <55413E1A.9030804@fredhutch.org>

On 04/28/2015 01:04 PM, G?bor Cs?rdi wrote:
> When a symbol in a package is resolved, R looks into the package's
> environment, and then into the package's imports environment. Then, if the
> symbol is still not resolved, it looks into the base package. So far so
> good.
>
> If still not found, it follows the 'search()' path, starting with the
> global environment and then all attached packages, finishing with base and
> recommended packages.
>
> This can be a problem if a package uses a function from a base package, but
> it does not formally import it via the NAMESPACE file. If another package
> on the search path also defines a function with the same name, then this
> second function will be called.
>
> E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
> also defines 'density()', and 'igraph' is on the search path, then
> 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.

stats::density() is an S3 generic, so igraph would define an S3 method, right? 
And in general a developer would avoid masking a function in a base package, so 
as not to require the user to distinguish between stats::density() and 
igraph::density(). Maybe the example is not meant literally.

Being able to easily flag non-imported, non-base symbols would definitely 
improve the robustness of package code, even if not helping the end user 
disambiguate duplicate symbols.

Martin Morgan

>
> I think that for a better solution, either
> 1) the search path should not be used at all to resolve symbols in
> packages, or
> 2) only base packages should be searched.
>
> I realize that this is something that is not easy to change, especially 1)
> would break a lot of packages. But maybe at least 'R CMD check' could
> report these cases. Currently it reports missing imports for non-base
> packages only. Is it reasonable to have a NOTE for missing imports from
> base packages as well?
>
> [As usual, please fix me if I am missing or misunderstood something.]
>
> Thank you, Best,
> Gabor
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From csardi.gabor at gmail.com  Wed Apr 29 22:39:47 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 16:39:47 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <55413E1A.9030804@fredhutch.org>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<55413E1A.9030804@fredhutch.org>
Message-ID: <CABtg=K=gY_zkpy_LSYGT-UtGDcbm60o4O5FD4v1TBx59W6VmKA@mail.gmail.com>

On Wed, Apr 29, 2015 at 4:24 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 04/28/2015 01:04 PM, G?bor Cs?rdi wrote:
>
[...]

> E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
>> also defines 'density()', and 'igraph' is on the search path, then
>> 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
>>
>
> stats::density() is an S3 generic, so igraph would define an S3 method,
> right? And in general a developer would avoid masking a function in a base
> package, so as not to require the user to distinguish between
> stats::density() and igraph::density(). Maybe the example is not meant
> literally.
>

Yes, maybe this is not the best example. I would not go into the details
here, because they are not really important for the current discussion.


> Being able to easily flag non-imported, non-base symbols would definitely
> improve the robustness of package code, even if not helping the end user
> disambiguate duplicate symbols.
>

In 'non-base' I assume you mean the single base package.

Just to address the second part, I think the end-user does not have to deal
with this. (Unless it is buggy like it is now.) The fact that ggplot2 calls
density() is not the user's concern.

Gabor

[...]

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Apr 29 23:38:49 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Apr 2015 14:38:49 -0700
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <55413E1A.9030804@fredhutch.org>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<55413E1A.9030804@fredhutch.org>
Message-ID: <CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>

> And in general a developer would avoid masking a function
> in a base package, so as not to require the user to distinguish
> between stats::density() and igraph::density(). Maybe the
> example is not meant literally.

The 'filter' function in the popular 'dplyr' package masks the one
that has been in the stats package forever, and they have nothing
in common, so that may give you an example.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Apr 29, 2015 at 1:24 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 04/28/2015 01:04 PM, G?bor Cs?rdi wrote:
>
>> When a symbol in a package is resolved, R looks into the package's
>> environment, and then into the package's imports environment. Then, if the
>> symbol is still not resolved, it looks into the base package. So far so
>> good.
>>
>> If still not found, it follows the 'search()' path, starting with the
>> global environment and then all attached packages, finishing with base and
>> recommended packages.
>>
>> This can be a problem if a package uses a function from a base package,
>> but
>> it does not formally import it via the NAMESPACE file. If another package
>> on the search path also defines a function with the same name, then this
>> second function will be called.
>>
>> E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
>> also defines 'density()', and 'igraph' is on the search path, then
>> 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
>>
>
> stats::density() is an S3 generic, so igraph would define an S3 method,
> right? And in general a developer would avoid masking a function in a base
> package, so as not to require the user to distinguish between
> stats::density() and igraph::density(). Maybe the example is not meant
> literally.
>
> Being able to easily flag non-imported, non-base symbols would definitely
> improve the robustness of package code, even if not helping the end user
> disambiguate duplicate symbols.
>
> Martin Morgan
>
>
>> I think that for a better solution, either
>> 1) the search path should not be used at all to resolve symbols in
>> packages, or
>> 2) only base packages should be searched.
>>
>> I realize that this is something that is not easy to change, especially 1)
>> would break a lot of packages. But maybe at least 'R CMD check' could
>> report these cases. Currently it reports missing imports for non-base
>> packages only. Is it reasonable to have a NOTE for missing imports from
>> base packages as well?
>>
>> [As usual, please fix me if I am missing or misunderstood something.]
>>
>> Thank you, Best,
>> Gabor
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From pgilbert902 at gmail.com  Thu Apr 30 02:12:42 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 29 Apr 2015 20:12:42 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>	<55413E1A.9030804@fredhutch.org>
	<CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>
Message-ID: <5541737A.10205@gmail.com>



On 04/29/2015 05:38 PM, William Dunlap wrote:
>> And in general a developer would avoid masking a function
>> in a base package, so as not to require the user to distinguish
>> between stats::density() and igraph::density(). Maybe the
>> example is not meant literally.
>
> The 'filter' function in the popular 'dplyr' package masks the one
> that has been in the stats package forever, and they have nothing
> in common, so that may give you an example.

As I recall, several packages mask the simulate generic in stats, if you 
are looking for examples.

Paul Gilbert

>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Apr 29, 2015 at 1:24 PM, Martin Morgan <mtmorgan at fredhutch.org>
> wrote:
>
>> On 04/28/2015 01:04 PM, G?bor Cs?rdi wrote:
>>
>>> When a symbol in a package is resolved, R looks into the package's
>>> environment, and then into the package's imports environment. Then, if the
>>> symbol is still not resolved, it looks into the base package. So far so
>>> good.
>>>
>>> If still not found, it follows the 'search()' path, starting with the
>>> global environment and then all attached packages, finishing with base and
>>> recommended packages.
>>>
>>> This can be a problem if a package uses a function from a base package,
>>> but
>>> it does not formally import it via the NAMESPACE file. If another package
>>> on the search path also defines a function with the same name, then this
>>> second function will be called.
>>>
>>> E.g. if package 'ggplot2' uses 'stats::density()', and package 'igraph'
>>> also defines 'density()', and 'igraph' is on the search path, then
>>> 'ggplot2' will call 'igraph::density()' instead of 'stats::density()'.
>>>
>>
>> stats::density() is an S3 generic, so igraph would define an S3 method,
>> right? And in general a developer would avoid masking a function in a base
>> package, so as not to require the user to distinguish between
>> stats::density() and igraph::density(). Maybe the example is not meant
>> literally.
>>
>> Being able to easily flag non-imported, non-base symbols would definitely
>> improve the robustness of package code, even if not helping the end user
>> disambiguate duplicate symbols.
>>
>> Martin Morgan
>>
>>
>>> I think that for a better solution, either
>>> 1) the search path should not be used at all to resolve symbols in
>>> packages, or
>>> 2) only base packages should be searched.
>>>
>>> I realize that this is something that is not easy to change, especially 1)
>>> would break a lot of packages. But maybe at least 'R CMD check' could
>>> report these cases. Currently it reports missing imports for non-base
>>> packages only. Is it reasonable to have a NOTE for missing imports from
>>> base packages as well?
>>>
>>> [As usual, please fix me if I am missing or misunderstood something.]
>>>
>>> Thank you, Best,
>>> Gabor
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> --
>> Computational Biology / Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N.
>> PO Box 19024 Seattle, WA 98109
>>
>> Location: Arnold Building M1 B861
>> Phone: (206) 667-2793
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Thu Apr 30 05:07:09 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 29 Apr 2015 23:07:09 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <5541737A.10205@gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<55413E1A.9030804@fredhutch.org>
	<CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>
	<5541737A.10205@gmail.com>
Message-ID: <CABtg=KnThd61TgaFmRutS=eOPUFXsPnLzHJK=Vg_T60gcP-yWA@mail.gmail.com>

On Wed, Apr 29, 2015 at 8:12 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
> As I recall, several packages mask the simulate generic in stats, if you
> are looking for examples.
>

FWIW, here is a list of base* functions masked** by CRAN packages:
https://github.com/gaborcsardi/rfunctions/blob/master/rfunctions.md
Look at the long table in the end. simulate indeed comes up 16 times. (But
read ** below.)

* This only includes functions in base packages that are attached by
default.
** The CRAN function names were taken from the manual page aliases, so a
couple of them are not really function names, and some of them are probably
not masking anything, but defining an S3 generic. This was a lot simpler
than going over the namespaces of all CRAN packages.

It seems that several base functions are masked, by several packages. I
would need to get a better CRAN function list, though.

Gabor

[...]


> Paul Gilbert
>

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Thu Apr 30 09:44:41 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 Apr 2015 09:44:41 +0200
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <CABtg=KnThd61TgaFmRutS=eOPUFXsPnLzHJK=Vg_T60gcP-yWA@mail.gmail.com>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<55413E1A.9030804@fredhutch.org>
	<CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>
	<5541737A.10205@gmail.com>
	<CABtg=KnThd61TgaFmRutS=eOPUFXsPnLzHJK=Vg_T60gcP-yWA@mail.gmail.com>
Message-ID: <21825.56681.241681.166313@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Wed, 29 Apr 2015 23:07:09 -0400 writes:

    > On Wed, Apr 29, 2015 at 8:12 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
    >> 
    >> As I recall, several packages mask the simulate generic in stats, if you
    >> are looking for examples.
    >> 

    > FWIW, here is a list of base* functions masked** by CRAN packages:
    > https://github.com/gaborcsardi/rfunctions/blob/master/rfunctions.md
    > Look at the long table in the end. simulate indeed comes up 16 times. (But
    > read ** below.)

    > * This only includes functions in base packages that are attached by
    > default.
    > ** The CRAN function names were taken from the manual page aliases, so a
    > couple of them are not really function names, and some of them are probably
    > not masking anything, but defining an S3 generic. This was a lot simpler
    > than going over the namespaces of all CRAN packages.

    > It seems that several base functions are masked, by several packages. I
    > would need to get a better CRAN function list, though.

Thank you Gabor.

As Martin Morgan observed, many of these will be methods, S3 and
S3 and there is often no conflict and no masking at all for all
these, so I am claiming that your "statistics" are quite a bit
biased, and probably most of the more common names are proper
methods.

There is another issue, I've wanted to raise,
exemplified by my Rmpfr package [interface to the MPFR C library
for high-accuracy floating point computations]:

As it defines "mpfr"-ified versions of standard R functions 
many of which are *not* generic, it must mask them.

E.g, currently, the following "are masked" messages (when
attaching Rmpfr) are unavoidable

  Attaching package: ?Rmpfr?

  The following objects are masked from ?package:stats?:

      dbinom, dnorm, dpois, pnorm

  The following objects are masked from ?package:base?:

      pmax, pmin

(Currently, there are also 'cbind' and 'rbind' being masked in
 order to work with  mpfr-number matrices ... but that should in
 principle be avoidable)

I think these "... are masked" messages are still appropriate:  After all,
pnorm() will really be taken from Rmpfr instead of from stats,
and the user should know that she is trusting the author of
Rmpfr (me) to do the right thing, when she calls pnorm(), namely
to call the equivalent stats::pnorm() for standard numbers, and
to call the MPFR-library code for mpfr-numbers.

- - - - - - - - - - - - - - - - - - - - - - - - 

Now the above may have almost nothing to do with the original
subject.  If I have understood your main point correctly, you are
suggesting that  'R CMD check' should start putting out a NOTE
when package code calls a function from one of a set of
"standard packages" (*) and the package author failed to use an  
	importFrom(<standard pkg>, <function>)
in his/her NAMESPACE.

I agree that this would be useful. 
Actually, I think we have something like this in place already...
but maybe not strictly enough (?)

(*) IIUC, you suggested to use 
   "standard packages" := packages which are attached by default
   in R, apart from package 'base' because that does come
   immediately after the imports anyway (and because you cannot
   explicity import from base).


Martin Maechler
ETH Zurich


From maechler at lynne.stat.math.ethz.ch  Thu Apr 30 18:23:58 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 Apr 2015 18:23:58 +0200
Subject: [Rd] dimnames returned by function apply
In-Reply-To: <99ED4CB4-AF79-421F-B7A0-3BBFB8F5FCD6@dkfz.de>
References: <99ED4CB4-AF79-421F-B7A0-3BBFB8F5FCD6@dkfz.de>
Message-ID: <21826.22302.30563.549567@stat.math.ethz.ch>

>>>>> Fischer, Bernd <b.fischer at dkfz-heidelberg.de>
>>>>>     on Wed, 29 Apr 2015 20:22:44 +0200 writes:

    > Dear all,
    > I noticed that the dimnames returned by apply are different in the new release.

    > In the following example. The returned row-names are c(?S?,?T?), but shouldn?t they be c(?X?,?Y?) as in the old release?

Not quite : They were   c("X.S", "Y.T")

Still 

.

..

...

....  

.....

......

............ ---> Tada !! 


  Congratulations on your finding the first "bad" bug in R 3.2.0 !
  "bad": a true regression, i.e., a bug not present in earlier versions of R.

I'm almost sure it is my fault, and I'm going to look into fixing it!

For the curious ones: It was introduced with the following
new feature (which implied fixing apply()'s treatment of named dimnames):

    ? apply(m, 2, identity) is now the same as the matrix m when it has
      _named_ row names.

    > Best,
    > Bernd

Thank you, Bernd, for the report!

Martin Maechler,
ETH Zurich


    >> X = array(1:8, dim=c(4,2))
    >> dimnames(X) = list(c("A","B","C","D"),c("S","T"))
    >> apply(X, 1, function(x) { c(X=x[1]*5,Y=x[2]*5) } )

    > A  B  C  D
    > S  5 10 15 20
    > T 25 30 35 40

    >> sessionInfo()
    > R version 3.2.0 (2015-04-16)

    [...........]


From mick.jordan at oracle.com  Thu Apr 30 20:25:38 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 30 Apr 2015 11:25:38 -0700
Subject: [Rd] --interactive and -f/-e
In-Reply-To: <21824.45158.644065.729614@stat.math.ethz.ch>
References: <55402FDA.5070203@oracle.com>
	<21824.45158.644065.729614@stat.math.ethz.ch>
Message-ID: <554273A2.9010406@oracle.com>

On 4/29/15 3:20 AM, Martin Maechler wrote:
>>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>>      on Tue, 28 Apr 2015 18:11:54 -0700 writes:
>
>
> So, in principle it should not seem hard to make --interactive
> work for '-e' and '-f' as well, but I don't see quickly how.
> Just changing the line in unix/system.c you've mentioned above
> is clearly not enough.
>
> Martin Maechler
> ETH Zurich
>
Thanks for the detailed assessment. When implementing a feature (I'm on 
the FastR project) I usually go by what the manual says, then check it 
against GnuR, and then if they don't match, read the source code. I'd be 
just as happy for the manual to be fixed rather than the code.

Mick


From maechler at ion-3.math.ethz.ch  Thu Apr 30 23:39:48 2015
From: maechler at ion-3.math.ethz.ch (Martin Maechler)
Date: Thu, 30 Apr 2015 23:39:48 +0200
Subject: [Rd] dimnames returned by function apply
In-Reply-To: <21826.22302.30563.549567@stat.math.ethz.ch>
References: <99ED4CB4-AF79-421F-B7A0-3BBFB8F5FCD6@dkfz.de>
	<21826.22302.30563.549567@stat.math.ethz.ch>
Message-ID: <21826.41252.233170.851695@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at lynne.stat.math.ethz.ch>
>>>>>     on Thu, 30 Apr 2015 18:23:58 +0200 writes:

>>>>> Fischer, Bernd <b.fischer at dkfz-heidelberg.de>
>>>>>     on Wed, 29 Apr 2015 20:22:44 +0200 writes:

    >> Dear all, I noticed that the dimnames returned by apply
    >> are different in the new release.

    >> In the following example. The returned row-names are
    >> c(?S?,?T?), but shouldn?t they be c(?X?,?Y?) as in the
    >> old release?

    > Not quite : They were c("X.S", "Y.T")

    > Still

    [............]

    >   Congratulations on your finding the first "bad" bug in R
    > 3.2.0 !  "bad": a true regression, i.e., a bug not present
    > in earlier versions of R.

    > I'm almost sure it is my fault, and I'm going to look into
    > fixing it!

Fix committed to R-devel and R-patched, svn revision 
68282 and 68283, respectively.

So if you get R 3.2.0 patched in a day or so, you'll get a
version of apply() which behaves as previously in this case.

Martin Maechler


    > For the curious ones: It was introduced with the following
    > new feature (which implied fixing apply()'s treatment of
    > named dimnames):

    >     ? apply(m, 2, identity) is now the same as the matrix
    > m when it has _named_ row names.

    >> Best, Bernd

    > Thank you, Bernd, for the report!

    > Martin Maechler, ETH Zurich


    >>> X = array(1:8, dim=c(4,2)) dimnames(X) =
    >>> list(c("A","B","C","D"),c("S","T")) apply(X, 1,
    >>> function(x) { c(X=x[1]*5,Y=x[2]*5) } )

    >> A B C D S 5 10 15 20 T 25 30 35 40

    >>> sessionInfo()
    >> R version 3.2.0 (2015-04-16)

    >     [...........]


